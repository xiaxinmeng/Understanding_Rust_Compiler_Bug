{"sha": "1008aaae5821ce38975495c76d93b004888f2ed5", "node_id": "MDY6Q29tbWl0NzI0NzEyOjEwMDhhYWFlNTgyMWNlMzg5NzU0OTVjNzZkOTNiMDA0ODg4ZjJlZDU=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2021-02-02T18:59:27Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2021-02-03T11:26:23Z"}, "message": "Make architecture more informative\n\nCall out boundaries and invariants", "tree": {"sha": "ee7f8e67bf73bc5acac04d775c16db9d57a4d0d8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ee7f8e67bf73bc5acac04d775c16db9d57a4d0d8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1008aaae5821ce38975495c76d93b004888f2ed5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1008aaae5821ce38975495c76d93b004888f2ed5", "html_url": "https://github.com/rust-lang/rust/commit/1008aaae5821ce38975495c76d93b004888f2ed5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1008aaae5821ce38975495c76d93b004888f2ed5/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7e66cde76460d61cb19a19e4bb7bc1f6642e993d", "url": "https://api.github.com/repos/rust-lang/rust/commits/7e66cde76460d61cb19a19e4bb7bc1f6642e993d", "html_url": "https://github.com/rust-lang/rust/commit/7e66cde76460d61cb19a19e4bb7bc1f6642e993d"}], "stats": {"total": 518, "additions": 317, "deletions": 201}, "files": [{"sha": "9c0af68e36529dcad1f9fc2b159654e707f15382", "filename": "docs/dev/README.md", "status": "modified", "additions": 3, "deletions": 88, "changes": 91, "blob_url": "https://github.com/rust-lang/rust/blob/1008aaae5821ce38975495c76d93b004888f2ed5/docs%2Fdev%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/1008aaae5821ce38975495c76d93b004888f2ed5/docs%2Fdev%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2Fdev%2FREADME.md?ref=1008aaae5821ce38975495c76d93b004888f2ed5", "patch": "@@ -9,8 +9,9 @@ $ cargo test\n \n should be enough to get you started!\n \n-To learn more about how rust-analyzer works, see\n-[./architecture.md](./architecture.md) document.\n+To learn more about how rust-analyzer works, see [./architecture.md](./architecture.md) document.\n+It also explains the high-level layout of the source code.\n+Do skim through that document.\n \n We also publish rustdoc docs to pages:\n \n@@ -99,25 +100,6 @@ I don't have a specific workflow for this case.\n Additionally, I use `cargo run --release -p rust-analyzer -- analysis-stats path/to/some/rust/crate` to run a batch analysis.\n This is primarily useful for performance optimizations, or for bug minimization.\n \n-## Parser Tests\n-\n-Tests for the parser (`parser`) live in the `syntax` crate (see `test_data` directory).\n-There are two kinds of tests:\n-\n-* Manually written test cases in `parser/ok` and `parser/err`\n-* \"Inline\" tests in `parser/inline` (these are generated) from comments in `parser` crate.\n-\n-The purpose of inline tests is not to achieve full coverage by test cases, but to explain to the reader of the code what each particular `if` and `match` is responsible for.\n-If you are tempted to add a large inline test, it might be a good idea to leave only the simplest example in place, and move the test to a manual `parser/ok` test.\n-\n-To update test data, run with `UPDATE_EXPECT` variable:\n-\n-```bash\n-env UPDATE_EXPECT=1 cargo qt\n-```\n-\n-After adding a new inline test you need to run `cargo xtest codegen` and also update the test data as described above.\n-\n ## TypeScript Tests\n \n If you change files under `editors/code` and would like to run the tests and linter, install npm and run:\n@@ -128,73 +110,6 @@ npm ci\n npm run lint\n ```\n \n-# Code organization\n-\n-All Rust code lives in the `crates` top-level directory, and is organized as a single Cargo workspace.\n-The `editors` top-level directory contains code for integrating with editors.\n-Currently, it contains the plugin for VS Code (in TypeScript).\n-The `docs` top-level directory contains both developer and user documentation.\n-\n-We have some automation infra in Rust in the `xtask` package.\n-It contains stuff like formatting checking, code generation and powers `cargo xtask install`.\n-The latter syntax is achieved with the help of cargo aliases (see `.cargo` directory).\n-\n-# Architecture Invariants\n-\n-This section tries to document high-level design constraints, which are not\n-always obvious from the low-level code.\n-\n-## Incomplete syntax trees\n-\n-Syntax trees are by design incomplete and do not enforce well-formedness.\n-If an AST method returns an `Option`, it *can* be `None` at runtime, even if this is forbidden by the grammar.\n-\n-## LSP independence\n-\n-rust-analyzer is independent from LSP.\n-It provides features for a hypothetical perfect Rust-specific IDE client.\n-Internal representations are lowered to LSP in the `rust-analyzer` crate (the only crate which is allowed to use LSP types).\n-\n-## IDE/Compiler split\n-\n-There's a semi-hard split between \"compiler\" and \"IDE\", at the `hir` crate.\n-Compiler derives new facts about source code.\n-It explicitly acknowledges that not all info is available (i.e. you can't look at types during name resolution).\n-\n-IDE assumes that all information is available at all times.\n-\n-IDE should use only types from `hir`, and should not depend on the underling compiler types.\n-`hir` is a facade.\n-\n-## IDE API\n-\n-The main IDE crate (`ide`) uses \"Plain Old Data\" for the API.\n-Rather than talking in definitions and references, it talks in Strings and textual offsets.\n-In general, API is centered around UI concerns -- the result of the call is what the user sees in the editor, and not what the compiler sees underneath.\n-The results are 100% Rust specific though.\n-Shout outs to LSP developers for popularizing the idea that \"UI\" is a good place to draw a boundary at.\n-\n-## LSP is stateless\n-\n-The protocol is implemented in the mostly stateless way.\n-A good mental model is HTTP, which doesn't store per-client state, and instead relies on devices like cookies to maintain an illusion of state.\n-If some action requires multi-step protocol, each step should be self-contained.\n-\n-A good example here is code action resolving process.\n-TO display the lightbulb, we compute the list of code actions without computing edits.\n-Figuring out the edit is done in a separate `codeAction/resolve` call.\n-Rather than storing some `lazy_edit: Box<dyn FnOnce() -> Edit>` somewhere, we use a string ID of action to re-compute the list of actions during the resolve process.\n-(See [this post](https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html) for more details.)\n-The benefit here is that, generally speaking, the state of the world might change between `codeAction` and `codeAction` resolve requests, so any closure we store might become invalid.\n-\n-While we don't currently implement any complicated refactors with complex GUI, I imagine we'd use the same techniques for refactors.\n-After clicking each \"Next\" button during refactor, the client would send all the info which server needs to re-recreate the context from scratch.\n-\n-## CI\n-\n-CI does not test rust-analyzer, CI is a core part of rust-analyzer, and is maintained with above average standard of quality.\n-CI is reproducible -- it can only be broken by changes to files in this repository, any dependence on externalities is a bug.\n-\n # Code Style & Review Process\n \n Do see [./style.md](./style.md)."}, {"sha": "feda20dd739650607d8055590e079028b88f1ea7", "filename": "docs/dev/architecture.md", "status": "modified", "additions": 314, "deletions": 113, "changes": 427, "blob_url": "https://github.com/rust-lang/rust/blob/1008aaae5821ce38975495c76d93b004888f2ed5/docs%2Fdev%2Farchitecture.md", "raw_url": "https://github.com/rust-lang/rust/raw/1008aaae5821ce38975495c76d93b004888f2ed5/docs%2Fdev%2Farchitecture.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2Fdev%2Farchitecture.md?ref=1008aaae5821ce38975495c76d93b004888f2ed5", "patch": "@@ -1,174 +1,375 @@\n # Architecture\n \n This document describes the high-level architecture of rust-analyzer.\n-If you want to familiarize yourself with the code base, you are just\n-in the right place!\n+If you want to familiarize yourself with the code base, you are just in the right place!\n \n-See also the [guide](./guide.md), which walks through a particular snapshot of\n-rust-analyzer code base.\n+See also the [guide](./guide.md), which walks through a particular snapshot of rust-analyzer code base.\n \n-Yet another resource is this playlist with videos about various parts of the\n-analyzer:\n+Yet another resource is this playlist with videos about various parts of the analyzer:\n \n https://www.youtube.com/playlist?list=PL85XCvVPmGQho7MZkdW-wtPtuJcFpzycE\n \n-Note that the guide and videos are pretty dated, this document should be in\n-generally fresher.\n+Note that the guide and videos are pretty dated, this document should be in generally fresher.\n \n-## The Big Picture\n+See also this implementation-oriented blog posts:\n+\n+* https://rust-analyzer.github.io/blog/2019/11/13/find-usages.html\n+* https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html\n+* https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html\n+* https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html\n+* https://rust-analyzer.github.io/blog/2020/10/24/introducing-ungrammar.html\n+\n+## Bird's Eye View\n \n ![](https://user-images.githubusercontent.com/1711539/50114578-e8a34280-0255-11e9-902c-7cfc70747966.png)\n \n-On the highest level, rust-analyzer is a thing which accepts input source code\n-from the client and produces a structured semantic model of the code.\n+On the highest level, rust-analyzer is a thing which accepts input source code from the client and produces a structured semantic model of the code.\n+\n+More specifically, input data consists of a set of test files (`(PathBuf, String)` pairs) and information about project structure, captured in the so called `CrateGraph`.\n+The crate graph specifies which files are crate roots, which cfg flags are specified for each crate and what dependencies exist between the crates.\n+This the input (ground) state.\n+The analyzer keeps all this input data in memory and never does any IO.\n+Because the input data are source code, which typically measures in tens of megabytes at most, keeping everything in memory is OK.\n+\n+A \"structured semantic model\" is basically an object-oriented representation of modules, functions and types which appear in the source code.\n+This representation is fully \"resolved\": all expressions have types, all references are bound to declarations, etc.\n+This is derived state.\n+\n+The client can submit a small delta of input data (typically, a change to a single file) and get a fresh code model which accounts for changes.\n \n-More specifically, input data consists of a set of test files (`(PathBuf,\n-String)` pairs) and information about project structure, captured in the so\n-called `CrateGraph`. The crate graph specifies which files are crate roots,\n-which cfg flags are specified for each crate and what dependencies exist between\n-the crates. The analyzer keeps all this input data in memory and never does any\n-IO. Because the input data are source code, which typically measures in tens of\n-megabytes at most, keeping everything in memory is OK.\n+The underlying engine makes sure that model is computed lazily (on-demand) and can be quickly updated for small modifications.\n \n-A \"structured semantic model\" is basically an object-oriented representation of\n-modules, functions and types which appear in the source code. This representation\n-is fully \"resolved\": all expressions have types, all references are bound to\n-declarations, etc.\n \n-The client can submit a small delta of input data (typically, a change to a\n-single file) and get a fresh code model which accounts for changes.\n+## Code Map\n \n-The underlying engine makes sure that model is computed lazily (on-demand) and\n-can be quickly updated for small modifications.\n+This section talks briefly about various important directories an data structures.\n+Pay attention to the **Architecture Invariant** sections.\n+They often talk about things which are deliberately absent in the source code.\n \n+Note also which crates are **API Boundaries**.\n+Remember, [rules at the boundary are different](https://www.tedinski.com/2018/02/06/system-boundaries.html).\n \n-## Code generation\n+### `xtask`\n \n-Some of the components of this repository are generated through automatic\n-processes. `cargo xtask codegen` runs all generation tasks. Generated code is\n-committed to the git repository.\n+This is rust-analyzer's \"build system\".\n+We use cargo to compile rust code, but there are also various other tasks, like release management or local installation.\n+They are handled by Rust code in the xtask directory.\n \n-In particular, `cargo xtask codegen` generates:\n+### `editors/code`\n \n-1. [`syntax_kind/generated`](https://github.com/rust-analyzer/rust-analyzer/blob/a0be39296d2925972cacd9fbf8b5fb258fad6947/crates/ra_parser/src/syntax_kind/generated.rs)\n-  -- the set of terminals and non-terminals of rust grammar.\n+VS Code plugin.\n \n-2. [`ast/generated`](https://github.com/rust-analyzer/rust-analyzer/blob/a0be39296d2925972cacd9fbf8b5fb258fad6947/crates/ra_syntax/src/ast/generated.rs)\n-  -- AST data structure.\n+### `libs/`\n \n-3. [`doc_tests/generated`](https://github.com/rust-analyzer/rust-analyzer/blob/a0be39296d2925972cacd9fbf8b5fb258fad6947/crates/assists/src/doc_tests/generated.rs),\n-  [`test_data/parser/inline`](https://github.com/rust-analyzer/rust-analyzer/tree/a0be39296d2925972cacd9fbf8b5fb258fad6947/crates/ra_syntax/test_data/parser/inline)\n-  -- tests for assists and the parser.\n+rust-analyzer independent libraries which we publish to crates.io.\n+It not heavily utilized at the moment.\n \n-The source for 1 and 2 is in [`ast_src.rs`](https://github.com/rust-analyzer/rust-analyzer/blob/a0be39296d2925972cacd9fbf8b5fb258fad6947/xtask/src/ast_src.rs).\n+### `crates/parser`\n \n-## Code Walk-Through\n+It is a hand-written recursive descent parser, which produces a sequence of events like \"start node X\", \"finish node Y\".\n+It works similarly to\n+[kotlin's parser](https://github.com/JetBrains/kotlin/blob/4d951de616b20feca92f3e9cc9679b2de9e65195/compiler/frontend/src/org/jetbrains/kotlin/parsing/KotlinParsing.java),\n+which is a good source of inspiration for dealing with syntax errors and incomplete input.\n+Original [libsyntax parser](https://github.com/rust-lang/rust/blob/6b99adeb11313197f409b4f7c4083c2ceca8a4fe/src/libsyntax/parse/parser.rs) is what we use for the definition of the Rust language.\n+`TreeSink` and `TokenSource` traits bridge the tree-agnostic parser from `grammar` with `rowan` trees.\n \n-### `crates/ra_syntax`, `crates/parser`\n+**Architecture Invariant:** the parser is independent of the particular tree structure and particular representation of the tokens.\n+It transforms one flat stream of events into another flat stream of events.\n+Token independence allows us to pares out both text-based source code and `tt`-based macro input.\n+Tree independence allows us to more easily vary the syntax tree implementation.\n+It should also unlock efficient light-parsing approaches.\n+For example, you can extract the set of names defined in a file (for typo correction) without building a syntax tree.\n \n-Rust syntax tree structure and parser. See\n-[RFC](https://github.com/rust-lang/rfcs/pull/2256) and [./syntax.md](./syntax.md) for some design notes.\n+**Architecture Invariant:** parsing never fails, the parser produces `(T, Vec<Error>)` rather than `Result<T, Error>`.\n+\n+### `crates/syntax`\n+\n+Rust syntax tree structure and parser.\n+See [RFC](https://github.com/rust-lang/rfcs/pull/2256) and [./syntax.md](./syntax.md) for some design notes.\n \n - [rowan](https://github.com/rust-analyzer/rowan) library is used for constructing syntax trees.\n-- `grammar` module is the actual parser. It is a hand-written recursive descent parser, which\n-  produces a sequence of events like \"start node X\", \"finish node Y\". It works similarly to [kotlin's parser](https://github.com/JetBrains/kotlin/blob/4d951de616b20feca92f3e9cc9679b2de9e65195/compiler/frontend/src/org/jetbrains/kotlin/parsing/KotlinParsing.java),\n-  which is a good source of inspiration for dealing with syntax errors and incomplete input. Original [libsyntax parser](https://github.com/rust-lang/rust/blob/6b99adeb11313197f409b4f7c4083c2ceca8a4fe/src/libsyntax/parse/parser.rs)\n-  is what we use for the definition of the Rust language.\n-- `TreeSink` and `TokenSource` traits bridge the tree-agnostic parser from `grammar` with `rowan` trees.\n - `ast` provides a type safe API on top of the raw `rowan` tree.\n-- `ast_src` description of the grammar, which is used to generate `syntax_kinds`\n-  and `ast` modules, using `cargo xtask codegen` command.\n+- `ungrammar` description of the grammar, which is used to generate `syntax_kinds` and `ast` modules, using `cargo xtask codegen` command.\n+\n+Tests for ra_syntax are mostly data-driven.\n+`test_data/parser` contains subdirectories with a bunch of `.rs` (test vectors) and `.txt` files with corresponding syntax trees.\n+During testing, we check `.rs` against `.txt`.\n+If the `.txt` file is missing, it is created (this is how you update tests).\n+Additionally, running `cargo xtask codegen` will walk the grammar module and collect all `// test test_name` comments into files inside `test_data/parser/inline` directory.\n+\n+To update test data, run with `UPDATE_EXPECT` variable:\n \n-Tests for ra_syntax are mostly data-driven: `test_data/parser` contains subdirectories with a bunch of `.rs`\n-(test vectors) and `.txt` files with corresponding syntax trees. During testing, we check\n-`.rs` against `.txt`. If the `.txt` file is missing, it is created (this is how you update\n-tests). Additionally, running `cargo xtask codegen` will walk the grammar module and collect\n-all `// test test_name` comments into files inside `test_data/parser/inline` directory.\n+```bash\n+env UPDATE_EXPECT=1 cargo qt\n+```\n \n-Note\n-[`api_walkthrough`](https://github.com/rust-analyzer/rust-analyzer/blob/2fb6af89eb794f775de60b82afe56b6f986c2a40/crates/ra_syntax/src/lib.rs#L190-L348)\n+After adding a new inline test you need to run `cargo xtest codegen` and also update the test data as described above.\n+\n+Note  [`api_walkthrough`](https://github.com/rust-analyzer/rust-analyzer/blob/2fb6af89eb794f775de60b82afe56b6f986c2a40/crates/ra_syntax/src/lib.rs#L190-L348)\n in particular: it shows off various methods of working with syntax tree.\n \n-See [#93](https://github.com/rust-analyzer/rust-analyzer/pull/93) for an example PR which\n-fixes a bug in the grammar.\n+See [#93](https://github.com/rust-analyzer/rust-analyzer/pull/93) for an example PR which fixes a bug in the grammar.\n+\n+**Architecture Invariant:** `syntax` crate is completely independent from the rest of rust-analyzer, it knows nothing about salsa or LSP.\n+This is important because it is possible to useful tooling using only syntax tree.\n+Without semantic information, you don't need to be able to _build_ code, which makes the tooling more robust.\n+See also https://web.stanford.edu/~mlfbrown/paper.pdf.\n+You can view the `syntax` crate as an entry point to rust-analyzer.\n+`sytax` crate is an **API Boundary**.\n+\n+**Architecture Invariant:** syntax tree is a value type.\n+The tree is fully determined by the contents of its syntax nodes, it doesn't need global context (like an interner) and doesn't store semantic info.\n+Using the tree as a store for semantic info is convenient in traditional compilers, but doesn't work nicely in the IDE.\n+Specifically, assists and refactors require transforming syntax trees, and that becomes awkward if you need to do something with the semantic info.\n+\n+**Architecture Invariant:** syntax tree is build for a single file.\n+This is to enable parallel parsing of all files.\n+\n+**Architecture Invariant:**  Syntax trees are by design incomplete and do not enforce well-formedness.\n+If an AST method returns an `Option`, it *can* be `None` at runtime, even if this is forbidden by the grammar.\n \n ### `crates/base_db`\n \n-We use the [salsa](https://github.com/salsa-rs/salsa) crate for incremental and\n-on-demand computation. Roughly, you can think of salsa as a key-value store, but\n-it also can compute derived values using specified functions. The `base_db` crate\n-provides basic infrastructure for interacting with salsa. Crucially, it\n-defines most of the \"input\" queries: facts supplied by the client of the\n-analyzer. Reading the docs of the `base_db::input` module should be useful:\n-everything else is strictly derived from those inputs.\n+We use the [salsa](https://github.com/salsa-rs/salsa) crate for incremental and on-demand computation.\n+Roughly, you can think of salsa as a key-value store, but it also can compute derived values using specified functions. The `base_db` crate provides basic infrastructure for interacting with salsa.\n+Crucially, it defines most of the \"input\" queries: facts supplied by the client of the analyzer.\n+Reading the docs of the `base_db::input` module should be useful: everything else is strictly derived from those inputs.\n+\n+**Architecture Invariant:** particularities of the build system are *not* the part of the ground state.\n+In particular, `base_db` knows nothing about cargo.\n+The `CrateGraph` structure is used to represent the dependencies between the crates abstractly.\n+\n+**Architecture Invariant:** `base_db` doesn't know about file system and file paths.\n+Files are represented with opaque `FileId`, there's no operation to get an `std::path::Path` out of the `FileId`.\n+\n+### `crates/hir_expand`, `crates/hir_def`, `crates/hir_ty`\n+\n+These crates are the *brain* of rust-analyzer.\n+This is the compiler part of the IDE.\n \n-### `crates/hir*` crates\n+`hir_xxx` crates have a strong ECS flavor, in that they work with raw ids and directly query the database.\n+There's little abstraction here.\n+These crates integrate deeply with salsa and chalk.\n \n-HIR provides high-level \"object oriented\" access to Rust code.\n+Name resolution, macro expansion and type inference all happen here.\n+These crates also define various intermediate representations of the core.\n \n-The principal difference between HIR and syntax trees is that HIR is bound to a\n-particular crate instance. That is, it has cfg flags and features applied. So,\n-the relation between syntax and HIR is many-to-one. The `source_binder` module\n-is responsible for guessing a HIR for a particular source position.\n+`ItemTree` condenses a single `SyntaxTree` into a \"summary\" data structure, which is stable over modifications to function bodies.\n \n-Underneath, HIR works on top of salsa, using a `HirDatabase` trait.\n+`DefMap` contains the module tree of a crate and stores module scopes.\n \n-`hir_xxx` crates have a strong ECS flavor, in that they work with raw ids and\n-directly query the database.\n+`Body` stores information about expressions.\n \n-The top-level `hir` fa\u00e7ade crate wraps ids into a more OO-flavored API.\n+**Architecture Invariant:** this crates are not, and will never be, an api boundary.\n+\n+**Architecture Invariant:** these creates explicitly care about being incremental.\n+The core invariant we maintain is \"typing inside a function's body never invalidates global derived data\".\n+Ie, if you change body of `foo`, all facts about `bar` should remain intact.\n+\n+**Architecture Invariant:** hir exists only in context of particular crate instance with specific CFG flags.\n+The same syntax may produce several instances of HIR if the crate participates in the crate graph more than once.\n+\n+### `crates/hir`\n+\n+The top-level `hir` crate is an **API Boundary**.\n+If you think about \"using rust-analyzer as a library\", `hir` crate is most likely the fa\u00e7ade you'll be talking to.\n+\n+It wraps ECS-style internal API into a more OO-flavored API (with an extra `db` argument for each call).\n+\n+**Architecture Invariant:** `hir` provides a static, fully resolved view of the code.\n+While internal `hir_*` crates _compute_ things, `hir`, from the outside, looks like an inert data structure.\n+\n+`hir` also handles the delicate task of going from syntax to the corresponding `hir`.\n+Remember that the mapping here is one-to-many.\n+See `Semantics` type and `source_to_def` module.\n+\n+Note in particular a curious recursive structure in `source_to_def`.\n+We first resolve the parent _syntax_ node to the parent _hir_ element.\n+Then we ask the _hir_ parent what _syntax_ children does it have.\n+Then we look for our node in the set of children.\n+\n+This is the heart of many IDE features, like goto definition, which start with figuring out a hir node at the cursor.\n+This is some kind of (yet unnamed) uber-IDE pattern, as it is present in Roslyn and Kotlin as well.\n \n ### `crates/ide`\n \n-A stateful library for analyzing many Rust files as they change. `AnalysisHost`\n-is a mutable entity (clojure's atom) which holds the current state, incorporates\n-changes and hands out `Analysis` --- an immutable and consistent snapshot of\n-the world state at a point in time, which actually powers analysis.\n+The `ide` crate build's on top of `hir` semantic model to provide high-level IDE features like completion or goto definition.\n+It is an **API Boundary**.\n+If you want to use IDE parts of rust-analyzer via LSP, custom flatbuffers-based protocol or just as a library in your text editor, this is the right API.\n \n-One interesting aspect of analysis is its support for cancellation. When a\n-change is applied to `AnalysisHost`, first all currently active snapshots are\n-canceled. Only after all snapshots are dropped the change actually affects the\n-database.\n+**Architecture Invariant:** `ide` crate's API is build out of POD types with public fields.\n+The API uses editor's terminology, it talks about offsets and string labels rathe than in terms of definitions or types.\n+It is effectively the view in MVC and viewmodel in [MVVM](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93viewmodel).\n+All arguments and return types are conceptually serializable.\n+In particular, syntax tress and and hir types are generally absent from the API (but are used heavily in the implementation).\n+Shout outs to LSP developers for popularizing the idea that \"UI\" is a good place to draw a boundary at.\n \n-APIs in this crate are IDE centric: they take text offsets as input and produce\n-offsets and strings as output. This works on top of rich code model powered by\n-`hir`.\n+`ide` is also the first crate which has the notion of change over time.\n+`AnalysisHost` is a state to which you can transactonally `apply_change`.\n+`Analysis` is an immutable snapshot of the state.\n+\n+Internally, `ide` is split across several crates. `ide_assists`, `ide_completion` and `ide_ssr` implement large isolated features.\n+`ide_db` implements common IDE functionality (notably, reference search is implemented here).\n+The `ide` contains a public API/fa\u00e7ade, as well as implementation for a plethora of smaller features.\n+\n+**Architecture Invariant:** `ide` crate strives to provide a _perfect_ API.\n+Although at the moment it has only one consumer, the LSP server, LSP *does not* influence it's API design.\n+Instead, we keep in mind a hypothetical _ideal_ client -- an IDE tailored specifically for rust, every nook and cranny of which is packed with Rust-specific goodies.\n \n ### `crates/rust-analyzer`\n \n-An LSP implementation which wraps `ide` into a language server protocol.\n+This crate defines the `rust-analyzer` binary, so it is the **entry point**.\n+It implements the language server.\n+\n+**Architecture Invariant:** `rust-analyzer` is the only crate that knows about LSP and JSON serialization.\n+If you want to expose a datastructure `X` from ide to LSP, don't make it serializable.\n+Instead, create a serializable counterpart in `rust-analyzer` crate and manually convert between the two.\n+\n+`GlobalState` is the state of the server.\n+The `main_loop` defines the server event loop which accepts requests and sends responses.\n+Requests that modify the state or might block user's typing are handled on the main thread.\n+All other requests are processed in background.\n+\n+**Architecture Invariant:** the server is stateless, a-la HTTP.\n+Sometimes state needs to be preserved between requests.\n+For example, \"what is the `edit` for the fifth's completion item of the last completion edit?\".\n+For this, the second request should include enough info to re-create the context from scratch.\n+This generally means including all the parameters of the original request.\n+\n+`reload` module contains the code that handles configuration and Cargo.toml changes.\n+This is a tricky business.\n+\n+**Architecture Invariant:** `rust-analyzer` should be partially available even when the build is broken.\n+Reloading process should not prevent IDE features from working.\n+\n+### `crates/toolchain`, `crates/project_model`, `crates/flycheck`\n \n-### `crates/vfs`\n+These crates deal with invoking `cargo` to learn about project structure and get compiler errors for the \"check on save\" feature.\n \n-Although `hir` and `ide` don't do any IO, we need to be able to read\n-files from disk at the end of the day. This is what `vfs` does. It also\n-manages overlays: \"dirty\" files in the editor, whose \"true\" contents is\n-different from data on disk. \n+They use `crates/path` heavily instead of `std::path`.\n+A single `rust-analyzer` process can serve many projects, so it is important that server's current directory does not leak.\n \n-## Testing Infrastructure\n+### `crates/mbe`, `crated/tt`, `crates/proc_macro_api`, `crates/proc_macro_srv`\n \n-Rust Analyzer has three interesting [systems\n-boundaries](https://www.tedinski.com/2018/04/10/making-tests-a-positive-influence-on-design.html)\n-to concentrate tests on.\n+These crates implement macros as token tree -> token tree transforms.\n+They are independent from the rest of the code.\n \n-The outermost boundary is the `rust-analyzer` crate, which defines an LSP\n-interface in terms of stdio. We do integration testing of this component, by\n-feeding it with a stream of LSP requests and checking responses. These tests are\n-known as \"heavy\", because they interact with Cargo and read real files from\n-disk. For this reason, we try to avoid writing too many tests on this boundary:\n-in a statically typed language, it's hard to make an error in the protocol\n-itself if messages are themselves typed.\n+### `crates/vfs`, `crates/vfs-notify`\n \n-The middle, and most important, boundary is `ide`. Unlike\n-`rust-analyzer`, which exposes API, `ide` uses Rust API and is intended to\n-use by various tools. Typical test creates an `AnalysisHost`, calls some\n-`Analysis` functions and compares the results against expectation.\n+These crates implement a virtual fils system.\n+They provide consistent snapshots of the underlying file system and insulate messy OS paths.\n \n-The innermost and most elaborate boundary is `hir`. It has a much richer\n-vocabulary of types than `ide`, but the basic testing setup is the same: we\n-create a database, run some queries, assert result.\n+**Architecture Invariant:** vfs doesn't assume a single unified file system.\n+IE, a single rust-analyzer process can act as a remote server for two different machines, where the same `/tmp/foo.rs` path points to different files.\n+For this reason, all path APIs generally take some existing path as a \"file system witness\".\n+\n+### `crates/stdx`\n+\n+This crate contains various non-rust-analyzer specific utils, which could have been in std.\n+\n+### `crates/profile`\n+\n+This crate contains utilities for CPU and memory profiling.\n+\n+\n+## Cross-Cutting Concerns\n+\n+This sections talks about the things which are everywhere and nowhere in particular.\n+\n+### Code generation\n+\n+Some of the components of this repository are generated through automatic processes.\n+`cargo xtask codegen` runs all generation tasks.\n+Generated code is generally committed to the git repository.\n+There are tests to check that the generated code is fresh.\n+\n+In particular, we generate:\n+\n+* API for working with syntax trees (`syntax::ast`, the `ungrammar` crate).\n+* Various sections of the manual:\n+\n+    * features\n+    * assists\n+    * config\n+\n+* Documentation tests for assists\n+\n+**Architecture Invariant:** we avoid bootstrapping.\n+For codegen we need to parse Rust code.\n+Using rust-analyzer for that would work and would be fun, but it would also complicate the build process a lot.\n+For that reason, we use syn and manual string parsing.\n+\n+### Cancellation\n+\n+Let's say that the IDE is in the process of computing syntax highlighting, when the user types `foo`.\n+What should happen?\n+`rust-analyzer`s answer is that the highlighting process should be cancelled -- its results are now stale, and it also blocks modification of the inputs.\n+\n+The salsa database maintains a global revision counter.\n+When applying a change, salsa bumps this counter and waits until all other threads using salsa finish.\n+If a thread does salsa-based computation and notices that the counter is incremented, it panics with a special value (see `Canceled::throw`).\n+That is, rust-analyzer requires unwinding.\n+\n+`ide` is the boundary where the panic is caught and transformed into a `Result<T, Cancelled>`.\n+\n+### Testing\n+\n+Rust Analyzer has three interesting [systems boundaries](https://www.tedinski.com/2018/04/10/making-tests-a-positive-influence-on-design.html) to concentrate tests on.\n+\n+The outermost boundary is the `rust-analyzer` crate, which defines an LSP interface in terms of stdio.\n+We do integration testing of this component, by feeding it with a stream of LSP requests and checking responses.\n+These tests are known as \"heavy\", because they interact with Cargo and read real files from disk.\n+For this reason, we try to avoid writing too many tests on this boundary: in a statically typed language, it's hard to make an error in the protocol itself if messages are themselves typed.\n+Heavy tests are only run when `RUN_SLOW_TESTS` env var is set.\n+\n+The middle, and most important, boundary is `ide`.\n+Unlike `rust-analyzer`, which exposes API, `ide` uses Rust API and is intended to use by various tools.\n+Typical test creates an `AnalysisHost`, calls some `Analysis` functions and compares the results against expectation.\n+\n+The innermost and most elaborate boundary is `hir`.\n+It has a much richer vocabulary of types than `ide`, but the basic testing setup is the same: we create a database, run some queries, assert result.\n \n For comparisons, we use the `expect` crate for snapshot testing.\n \n-To test various analysis corner cases and avoid forgetting about old tests, we\n-use so-called marks. See the `marks` module in the `test_utils` crate for more.\n+To test various analysis corner cases and avoid forgetting about old tests, we use so-called marks.\n+See the `marks` module in the `test_utils` crate for more.\n+\n+**Architecture Invariant:** rust-analyzer tests do not use libcore or libstd.\n+All required library code must be a part of the tests.\n+This ensures fast test execution.\n+\n+**Architecture Invariant:** tests are data driven and do not test API.\n+Tests which directly call various API functions are a liability, because they make refactoring the API significantly more complicated.\n+So most of the tests look like this:\n+\n+```rust\n+fn check(input: &str, expect: expect_test::Expect) {\n+    // The single place that actually exercises a particular API\n+}\n+\n+\n+#[test]\n+fn foo() {\n+    check(\"foo\", expect![[\"bar\"]]);\n+}\n+\n+#[test]\n+fn spam() {\n+    check(\"spam\", expect![[\"eggs\"]]);\n+}\n+// ...and a hundred more tests that don't care about the specific API at all.\n+```\n+\n+To specify input data, we use a single string literal in a special format, which can describe a set of rust files.\n+See the `Fixture` type.\n+\n+**Architecture Invariant:** all code invariants are tested by `#[test]` tests.\n+There's no additional checks in CI, formatting and tidy tests are run with `cargo test`.\n+\n+**Architecture Invariant:** tests do not depend on any kind of external resources, they are perfectly reproducible.\n+\n+### Observability\n+\n+I've run out of steam here :)\n+rust-analyzer is a long-running process, so its important to understand what's going on inside.\n+We have hierarchical profiler (`RA_PROFILER=1`) and object counting (`RA_COUNT=1`)."}]}