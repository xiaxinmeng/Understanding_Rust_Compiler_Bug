{"sha": "0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBkNTU0MTM5YWQ3YTU0YmJkNTlhNTE2NmNjM2U5ZmY3ODQyYzUyNjY=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-03-02T01:29:40Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-03-03T02:15:39Z"}, "message": "Fix fallout in unit tests.", "tree": {"sha": "965d2d7db4fdb713e86ec4f8e32c0b543c175451", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/965d2d7db4fdb713e86ec4f8e32c0b543c175451"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "html_url": "https://github.com/rust-lang/rust/commit/0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a02c18aa524cf330237ec9d8dba202ad91904a88", "url": "https://api.github.com/repos/rust-lang/rust/commits/a02c18aa524cf330237ec9d8dba202ad91904a88", "html_url": "https://github.com/rust-lang/rust/commit/a02c18aa524cf330237ec9d8dba202ad91904a88"}], "stats": {"total": 98, "additions": 45, "deletions": 53}, "files": [{"sha": "c00d2952b3b425bcc87e6ac78be0bf9719c53a2c", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 29, "deletions": 29, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "patch": "@@ -598,7 +598,6 @@ pub fn integer_lit(s: &str, suffix: Option<Symbol>, sd: &Handler, sp: Span) -> a\n #[cfg(test)]\n mod tests {\n     use super::*;\n-    use std::rc::Rc;\n     use syntax_pos::{self, Span, BytePos, Pos, NO_EXPANSION};\n     use codemap::Spanned;\n     use ast::{self, Ident, PatKind};\n@@ -609,7 +608,7 @@ mod tests {\n     use print::pprust::item_to_string;\n     use ptr::P;\n     use tokenstream::{self, TokenTree};\n-    use util::parser_testing::{string_to_tts, string_to_parser};\n+    use util::parser_testing::{string_to_stream, string_to_parser};\n     use util::parser_testing::{string_to_expr, string_to_item, string_to_stmt};\n     use util::ThinVec;\n \n@@ -654,7 +653,8 @@ mod tests {\n     // check the token-tree-ization of macros\n     #[test]\n     fn string_to_tts_macro () {\n-        let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_string());\n+        let tts: Vec<_> =\n+            string_to_stream(\"macro_rules! zip (($a)=>($a))\".to_string()).trees().collect();\n         let tts: &[TokenTree] = &tts[..];\n \n         match (tts.len(), tts.get(0), tts.get(1), tts.get(2), tts.get(3)) {\n@@ -667,7 +667,7 @@ mod tests {\n             )\n             if name_macro_rules.name == \"macro_rules\"\n             && name_zip.name == \"zip\" => {\n-                let tts = &macro_delimed.tts[..];\n+                let tts = &macro_delimed.stream().trees().collect::<Vec<_>>();\n                 match (tts.len(), tts.get(0), tts.get(1), tts.get(2)) {\n                     (\n                         3,\n@@ -676,17 +676,17 @@ mod tests {\n                         Some(&TokenTree::Delimited(_, ref second_delimed)),\n                     )\n                     if macro_delimed.delim == token::Paren => {\n-                        let tts = &first_delimed.tts[..];\n+                        let tts = &first_delimed.stream().trees().collect::<Vec<_>>();\n                         match (tts.len(), tts.get(0), tts.get(1)) {\n                             (\n                                 2,\n                                 Some(&TokenTree::Token(_, token::Dollar)),\n                                 Some(&TokenTree::Token(_, token::Ident(ident))),\n                             )\n                             if first_delimed.delim == token::Paren && ident.name == \"a\" => {},\n-                            _ => panic!(\"value 3: {:?}\", **first_delimed),\n+                            _ => panic!(\"value 3: {:?}\", *first_delimed),\n                         }\n-                        let tts = &second_delimed.tts[..];\n+                        let tts = &second_delimed.stream().trees().collect::<Vec<_>>();\n                         match (tts.len(), tts.get(0), tts.get(1)) {\n                             (\n                                 2,\n@@ -695,10 +695,10 @@ mod tests {\n                             )\n                             if second_delimed.delim == token::Paren\n                             && ident.name == \"a\" => {},\n-                            _ => panic!(\"value 4: {:?}\", **second_delimed),\n+                            _ => panic!(\"value 4: {:?}\", *second_delimed),\n                         }\n                     },\n-                    _ => panic!(\"value 2: {:?}\", **macro_delimed),\n+                    _ => panic!(\"value 2: {:?}\", *macro_delimed),\n                 }\n             },\n             _ => panic!(\"value: {:?}\",tts),\n@@ -707,31 +707,31 @@ mod tests {\n \n     #[test]\n     fn string_to_tts_1() {\n-        let tts = string_to_tts(\"fn a (b : i32) { b; }\".to_string());\n+        let tts = string_to_stream(\"fn a (b : i32) { b; }\".to_string());\n \n-        let expected = vec![\n-            TokenTree::Token(sp(0, 2), token::Ident(Ident::from_str(\"fn\"))),\n-            TokenTree::Token(sp(3, 4), token::Ident(Ident::from_str(\"a\"))),\n+        let expected = TokenStream::concat(vec![\n+            TokenTree::Token(sp(0, 2), token::Ident(Ident::from_str(\"fn\"))).into(),\n+            TokenTree::Token(sp(3, 4), token::Ident(Ident::from_str(\"a\"))).into(),\n             TokenTree::Delimited(\n                 sp(5, 14),\n-                Rc::new(tokenstream::Delimited {\n+                tokenstream::Delimited {\n                     delim: token::DelimToken::Paren,\n-                    tts: vec![\n-                        TokenTree::Token(sp(6, 7), token::Ident(Ident::from_str(\"b\"))),\n-                        TokenTree::Token(sp(8, 9), token::Colon),\n-                        TokenTree::Token(sp(10, 13), token::Ident(Ident::from_str(\"i32\"))),\n-                    ],\n-                })),\n+                    tts: TokenStream::concat(vec![\n+                        TokenTree::Token(sp(6, 7), token::Ident(Ident::from_str(\"b\"))).into(),\n+                        TokenTree::Token(sp(8, 9), token::Colon).into(),\n+                        TokenTree::Token(sp(10, 13), token::Ident(Ident::from_str(\"i32\"))).into(),\n+                    ]).into(),\n+                }).into(),\n             TokenTree::Delimited(\n                 sp(15, 21),\n-                Rc::new(tokenstream::Delimited {\n+                tokenstream::Delimited {\n                     delim: token::DelimToken::Brace,\n-                    tts: vec![\n-                        TokenTree::Token(sp(17, 18), token::Ident(Ident::from_str(\"b\"))),\n-                        TokenTree::Token(sp(18, 19), token::Semi),\n-                    ],\n-                }))\n-        ];\n+                    tts: TokenStream::concat(vec![\n+                        TokenTree::Token(sp(17, 18), token::Ident(Ident::from_str(\"b\"))).into(),\n+                        TokenTree::Token(sp(18, 19), token::Semi).into(),\n+                    ]).into(),\n+                }).into()\n+        ]);\n \n         assert_eq!(tts, expected);\n     }\n@@ -974,8 +974,8 @@ mod tests {\n         let expr = parse::parse_expr_from_source_str(\"foo\".to_string(),\n             \"foo!( fn main() { body } )\".to_string(), &sess).unwrap();\n \n-        let tts = match expr.node {\n-            ast::ExprKind::Mac(ref mac) => mac.node.tts.clone(),\n+        let tts: Vec<_> = match expr.node {\n+            ast::ExprKind::Mac(ref mac) => mac.node.stream().trees().collect(),\n             _ => panic!(\"not a macro\"),\n         };\n "}, {"sha": "2da442a1a53da752fe2ed2bdffd413599afe91dd", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 3, "deletions": 11, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "patch": "@@ -409,10 +409,10 @@ mod tests {\n     use syntax::ast::Ident;\n     use syntax_pos::{Span, BytePos, NO_EXPANSION};\n     use parse::token::Token;\n-    use util::parser_testing::string_to_tts;\n+    use util::parser_testing::string_to_stream;\n \n     fn string_to_ts(string: &str) -> TokenStream {\n-        string_to_tts(string.to_owned()).into_iter().collect()\n+        string_to_stream(string.to_owned())\n     }\n \n     fn sp(a: u32, b: u32) -> Span {\n@@ -428,20 +428,12 @@ mod tests {\n         let test_res = string_to_ts(\"foo::bar::baz\");\n         let test_fst = string_to_ts(\"foo::bar\");\n         let test_snd = string_to_ts(\"::baz\");\n-        let eq_res = TokenStream::concat([test_fst, test_snd].iter().cloned());\n+        let eq_res = TokenStream::concat(vec![test_fst, test_snd]);\n         assert_eq!(test_res.trees().count(), 5);\n         assert_eq!(eq_res.trees().count(), 5);\n         assert_eq!(test_res.eq_unspanned(&eq_res), true);\n     }\n \n-    #[test]\n-    fn test_from_to_bijection() {\n-        let test_start = string_to_tts(\"foo::bar(baz)\".to_string());\n-        let ts = test_start.iter().cloned().collect::<TokenStream>();\n-        let test_end: Vec<TokenTree> = ts.trees().collect();\n-        assert_eq!(test_start, test_end)\n-    }\n-\n     #[test]\n     fn test_to_from_bijection() {\n         let test_start = string_to_ts(\"foo::bar(baz)\");"}, {"sha": "51eb295b502a70bd764ede600fbbc877025742c4", "filename": "src/libsyntax/util/parser_testing.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser_testing.rs?ref=0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "patch": "@@ -9,17 +9,17 @@\n // except according to those terms.\n \n use ast::{self, Ident};\n-use parse::{ParseSess,PResult,filemap_to_tts};\n+use parse::{ParseSess, PResult, filemap_to_stream};\n use parse::{lexer, new_parser_from_source_str};\n use parse::parser::Parser;\n use ptr::P;\n-use tokenstream;\n+use tokenstream::TokenStream;\n use std::iter::Peekable;\n \n /// Map a string to tts, using a made-up filename:\n-pub fn string_to_tts(source_str: String) -> Vec<tokenstream::TokenTree> {\n+pub fn string_to_stream(source_str: String) -> TokenStream {\n     let ps = ParseSess::new();\n-    filemap_to_tts(&ps, ps.codemap().new_filemap(\"bogofile\".to_string(), None, source_str))\n+    filemap_to_stream(&ps, ps.codemap().new_filemap(\"bogofile\".to_string(), None, source_str))\n }\n \n /// Map string to parser (via tts)"}, {"sha": "5139b68bce7fd0d6686aa3293ee75697567c5c7f", "filename": "src/test/run-pass-fulldeps/ast_stmt_expr_attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Ftest%2Frun-pass-fulldeps%2Fast_stmt_expr_attr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Ftest%2Frun-pass-fulldeps%2Fast_stmt_expr_attr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fast_stmt_expr_attr.rs?ref=0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "patch": "@@ -18,7 +18,7 @@ use syntax::ast::*;\n use syntax::attr::*;\n use syntax::ast;\n use syntax::parse;\n-use syntax::parse::{ParseSess,filemap_to_tts, PResult};\n+use syntax::parse::{ParseSess, PResult};\n use syntax::parse::new_parser_from_source_str;\n use syntax::parse::parser::Parser;\n use syntax::parse::token;"}, {"sha": "2f94a440e72da3ca5342883acb0d1660ce27e28c", "filename": "src/test/run-pass-fulldeps/auxiliary/cond_plugin.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs?ref=0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "patch": "@@ -32,13 +32,13 @@ pub fn plugin_registrar(reg: &mut Registry) {\n \n fn cond(input: TokenStream) -> TokenStream {\n     let mut conds = Vec::new();\n-    let mut input = input.trees();\n+    let mut input = input.trees().peekable();\n     while let Some(tree) = input.next() {\n-        let cond: TokenStream = match *tree {\n-            TokenTree::Delimited(_, ref delimited) => delimited.tts.iter().cloned().collect(),\n+        let mut cond = match tree {\n+            TokenTree::Delimited(_, ref delimited) => delimited.stream(),\n             _ => panic!(\"Invalid input\"),\n         };\n-        let mut trees = cond.trees().cloned();\n+        let mut trees = cond.trees();\n         let test = trees.next();\n         let rhs = trees.collect::<TokenStream>();\n         if rhs.is_empty() {"}, {"sha": "134e36c587bede9bd15684f3dc20c3fc0c3cf91d", "filename": "src/test/run-pass-fulldeps/auxiliary/plugin_args.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fplugin_args.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fplugin_args.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fplugin_args.rs?ref=0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "patch": "@@ -26,7 +26,7 @@ use syntax::print::pprust;\n use syntax::ptr::P;\n use syntax::symbol::Symbol;\n use syntax_pos::Span;\n-use syntax::tokenstream;\n+use syntax::tokenstream::TokenStream;\n use rustc_plugin::Registry;\n \n struct Expander {\n@@ -37,7 +37,7 @@ impl TTMacroExpander for Expander {\n     fn expand<'cx>(&self,\n                    ecx: &'cx mut ExtCtxt,\n                    sp: Span,\n-                   _: &[tokenstream::TokenTree]) -> Box<MacResult+'cx> {\n+                   _: TokenStream) -> Box<MacResult+'cx> {\n         let args = self.args.iter().map(|i| pprust::meta_list_item_to_string(i))\n             .collect::<Vec<_>>().join(\", \");\n         MacEager::expr(ecx.expr_str(sp, Symbol::intern(&args)))"}, {"sha": "c9fa96b83c280a6d9325bef110aab04a74332fc4", "filename": "src/test/run-pass-fulldeps/auxiliary/procedural_mbe_matching.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0d554139ad7a54bbd59a5166cc3e9ff7842c5266/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs?ref=0d554139ad7a54bbd59a5166cc3e9ff7842c5266", "patch": "@@ -35,8 +35,8 @@ fn expand_mbe_matches(cx: &mut ExtCtxt, _: Span, args: &[TokenTree])\n         -> Box<MacResult + 'static> {\n \n     let mbe_matcher = quote_tokens!(cx, $$matched:expr, $$($$pat:pat)|+);\n-    let mbe_matcher = quoted::parse(&mbe_matcher, true, cx.parse_sess);\n-    let map = match TokenTree::parse(cx, &mbe_matcher, args) {\n+    let mbe_matcher = quoted::parse(mbe_matcher.into_iter().collect(), true, cx.parse_sess);\n+    let map = match TokenTree::parse(cx, &mbe_matcher, args.iter().cloned().collect()) {\n         Success(map) => map,\n         Failure(_, tok) => {\n             panic!(\"expected Success, but got Failure: {}\", parse_failure_msg(tok));"}]}