{"sha": "afd4b81c8642016dcb3a641d45a1258193dab958", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFmZDRiODFjODY0MjAxNmRjYjNhNjQxZDQ1YTEyNTgxOTNkYWI5NTg=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-06-01T07:44:01Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-06-01T07:44:01Z"}, "message": "Auto merge of #42263 - alexcrichton:fix-copies, r=Mark-Simulacrum\n\nrustbuild: Fix copying duplicate crates into the sysroot\n\nAfter compiling a project (e.g. libstd, libtest, or librustc) rustbuild needs to\ncopy over all artifacts into the sysroot of the compiler it's assembling.\nUnfortunately rustbuild doesn't know precisely what files to copy! Today it has\na heuristic where it just looks at the most recent version of all files that\nlook like rlibs/dylibs and copies those over. This unfortunately leads to bugs\nwith different versions of the same crate as seen in #42261.\n\nThis commit updates rustbuild's strategy of copying artifacts to work off the\nlist of artifacts produced by `cargo build --message-format=json`. The build\nsystem will now parse json messages coming out of Cargo to watch for files being\ngenerated, and then it'll only copy over those precise files.\n\nNote that there's still a bit of weird logic where Cargo prints that it's\ncreating `libstd.rlib` where we actually want `libstd-xxxxx.rlib`, so we still\ndo a bit of \"most recent file\" probing for those. This commit should take care\nof the crates.io dependency issues, however, as they're all copied over\nprecisely.\n\nCloses #42261", "tree": {"sha": "2f84b4f26526c60ea1c49d9d5f0164a44cb537ab", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2f84b4f26526c60ea1c49d9d5f0164a44cb537ab"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/afd4b81c8642016dcb3a641d45a1258193dab958", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/afd4b81c8642016dcb3a641d45a1258193dab958", "html_url": "https://github.com/rust-lang/rust/commit/afd4b81c8642016dcb3a641d45a1258193dab958", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/afd4b81c8642016dcb3a641d45a1258193dab958/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "38efb2e1ccf210b0108d2b88ee9d4ddcd8e91a3a", "url": "https://api.github.com/repos/rust-lang/rust/commits/38efb2e1ccf210b0108d2b88ee9d4ddcd8e91a3a", "html_url": "https://github.com/rust-lang/rust/commit/38efb2e1ccf210b0108d2b88ee9d4ddcd8e91a3a"}, {"sha": "2dab1e21509c4ffa8f1ea93d4a70c5a33cc6fe1d", "url": "https://api.github.com/repos/rust-lang/rust/commits/2dab1e21509c4ffa8f1ea93d4a70c5a33cc6fe1d", "html_url": "https://github.com/rust-lang/rust/commit/2dab1e21509c4ffa8f1ea93d4a70c5a33cc6fe1d"}], "stats": {"total": 262, "additions": 178, "deletions": 84}, "files": [{"sha": "e11f7bd089f6c78ea8149981d0ea114816f6b3cc", "filename": "src/bootstrap/bin/rustc.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/afd4b81c8642016dcb3a641d45a1258193dab958/src%2Fbootstrap%2Fbin%2Frustc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/afd4b81c8642016dcb3a641d45a1258193dab958/src%2Fbootstrap%2Fbin%2Frustc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fbin%2Frustc.rs?ref=afd4b81c8642016dcb3a641d45a1258193dab958", "patch": "@@ -56,6 +56,13 @@ fn main() {\n         }\n     }\n \n+    // Drop `--error-format json` because despite our desire for json messages\n+    // from Cargo we don't want any from rustc itself.\n+    if let Some(n) = args.iter().position(|n| n == \"--error-format\") {\n+        args.remove(n);\n+        args.remove(n);\n+    }\n+\n     // Detect whether or not we're a build script depending on whether --target\n     // is passed (a bit janky...)\n     let target = args.windows(2)"}, {"sha": "114948f0cf278dd240cb39ebf53322812e2ea7ba", "filename": "src/bootstrap/compile.rs", "status": "modified", "additions": 171, "deletions": 84, "changes": 255, "blob_url": "https://github.com/rust-lang/rust/blob/afd4b81c8642016dcb3a641d45a1258193dab958/src%2Fbootstrap%2Fcompile.rs", "raw_url": "https://github.com/rust-lang/rust/raw/afd4b81c8642016dcb3a641d45a1258193dab958/src%2Fbootstrap%2Fcompile.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fcompile.rs?ref=afd4b81c8642016dcb3a641d45a1258193dab958", "patch": "@@ -16,14 +16,17 @@\n //! compiler. This module is also responsible for assembling the sysroot as it\n //! goes along from the output of the previous stage.\n \n-use std::collections::HashMap;\n+use std::env;\n use std::fs::{self, File};\n+use std::io::BufReader;\n+use std::io::prelude::*;\n use std::path::{Path, PathBuf};\n-use std::process::Command;\n-use std::env;\n+use std::process::{Command, Stdio};\n+use std::str;\n \n use build_helper::{output, mtime, up_to_date};\n use filetime::FileTime;\n+use rustc_serialize::json;\n \n use channel::GitInfo;\n use util::{exe, libdir, is_dylib, copy};\n@@ -84,8 +87,9 @@ pub fn std(build: &Build, target: &str, compiler: &Compiler) {\n         }\n     }\n \n-    build.run(&mut cargo);\n-    update_mtime(build, &libstd_stamp(build, &compiler, target));\n+    run_cargo(build,\n+              &mut cargo,\n+              &libstd_stamp(build, &compiler, target));\n }\n \n /// Link all libstd rlibs/dylibs into the sysroot location.\n@@ -106,11 +110,8 @@ pub fn std_link(build: &Build,\n              compiler.host,\n              target_compiler.host,\n              target);\n-    let libdir = build.sysroot_libdir(&target_compiler, target);\n-    let out_dir = build.cargo_out(&compiler, Mode::Libstd, target);\n-\n-    t!(fs::create_dir_all(&libdir));\n-    add_to_sysroot(&out_dir, &libdir);\n+    let libdir = build.sysroot_libdir(target_compiler, target);\n+    add_to_sysroot(&libdir, &libstd_stamp(build, compiler, target));\n \n     if target.contains(\"musl\") && !target.contains(\"mips\") {\n         copy_musl_third_party_objects(build, target, &libdir);\n@@ -201,8 +202,9 @@ pub fn test(build: &Build, target: &str, compiler: &Compiler) {\n     }\n     cargo.arg(\"--manifest-path\")\n          .arg(build.src.join(\"src/libtest/Cargo.toml\"));\n-    build.run(&mut cargo);\n-    update_mtime(build, &libtest_stamp(build, compiler, target));\n+    run_cargo(build,\n+              &mut cargo,\n+              &libtest_stamp(build, compiler, target));\n }\n \n /// Same as `std_link`, only for libtest\n@@ -216,9 +218,8 @@ pub fn test_link(build: &Build,\n              compiler.host,\n              target_compiler.host,\n              target);\n-    let libdir = build.sysroot_libdir(&target_compiler, target);\n-    let out_dir = build.cargo_out(&compiler, Mode::Libtest, target);\n-    add_to_sysroot(&out_dir, &libdir);\n+    add_to_sysroot(&build.sysroot_libdir(target_compiler, target),\n+                   &libtest_stamp(build, compiler, target));\n }\n \n /// Build the compiler.\n@@ -294,8 +295,9 @@ pub fn rustc(build: &Build, target: &str, compiler: &Compiler) {\n     if let Some(ref s) = build.config.rustc_default_ar {\n         cargo.env(\"CFG_DEFAULT_AR\", s);\n     }\n-    build.run(&mut cargo);\n-    update_mtime(build, &librustc_stamp(build, compiler, target));\n+    run_cargo(build,\n+              &mut cargo,\n+              &librustc_stamp(build, compiler, target));\n }\n \n /// Same as `std_link`, only for librustc\n@@ -309,9 +311,8 @@ pub fn rustc_link(build: &Build,\n              compiler.host,\n              target_compiler.host,\n              target);\n-    let libdir = build.sysroot_libdir(&target_compiler, target);\n-    let out_dir = build.cargo_out(&compiler, Mode::Librustc, target);\n-    add_to_sysroot(&out_dir, &libdir);\n+    add_to_sysroot(&build.sysroot_libdir(target_compiler, target),\n+                   &librustc_stamp(build, compiler, target));\n }\n \n /// Cargo's output path for the standard library in a given stage, compiled\n@@ -397,39 +398,17 @@ pub fn assemble_rustc(build: &Build, stage: u32, host: &str) {\n \n /// Link some files into a rustc sysroot.\n ///\n-/// For a particular stage this will link all of the contents of `out_dir`\n-/// into the sysroot of the `host` compiler, assuming the artifacts are\n-/// compiled for the specified `target`.\n-fn add_to_sysroot(out_dir: &Path, sysroot_dst: &Path) {\n-    // Collect the set of all files in the dependencies directory, keyed\n-    // off the name of the library. We assume everything is of the form\n-    // `foo-<hash>.{rlib,so,...}`, and there could be multiple different\n-    // `<hash>` values for the same name (of old builds).\n-    let mut map = HashMap::new();\n-    for file in t!(fs::read_dir(out_dir.join(\"deps\"))).map(|f| t!(f)) {\n-        let filename = file.file_name().into_string().unwrap();\n-\n-        // We're only interested in linking rlibs + dylibs, other things like\n-        // unit tests don't get linked in\n-        if !filename.ends_with(\".rlib\") &&\n-           !filename.ends_with(\".lib\") &&\n-           !is_dylib(&filename) {\n+/// For a particular stage this will link the file listed in `stamp` into the\n+/// `sysroot_dst` provided.\n+fn add_to_sysroot(sysroot_dst: &Path, stamp: &Path) {\n+    t!(fs::create_dir_all(&sysroot_dst));\n+    let mut contents = Vec::new();\n+    t!(t!(File::open(stamp)).read_to_end(&mut contents));\n+    for part in contents.split(|b| *b == 0) {\n+        if part.is_empty() {\n             continue\n         }\n-        let file = file.path();\n-        let dash = filename.find(\"-\").unwrap();\n-        let key = (filename[..dash].to_string(),\n-                   file.extension().unwrap().to_owned());\n-        map.entry(key).or_insert(Vec::new())\n-           .push(file.clone());\n-    }\n-\n-    // For all hash values found, pick the most recent one to move into the\n-    // sysroot, that should be the one we just built.\n-    for (_, paths) in map {\n-        let (_, path) = paths.iter().map(|path| {\n-            (mtime(&path).seconds(), path)\n-        }).max().unwrap();\n+        let path = Path::new(t!(str::from_utf8(part)));\n         copy(&path, &sysroot_dst.join(path.file_name().unwrap()));\n     }\n }\n@@ -490,40 +469,148 @@ pub fn tool(build: &Build, stage: u32, target: &str, tool: &str) {\n     build.run(&mut cargo);\n }\n \n-/// Updates the mtime of a stamp file if necessary, only changing it if it's\n-/// older than some other library file in the same directory.\n-///\n-/// We don't know what file Cargo is going to output (because there's a hash in\n-/// the file name) but we know where it's going to put it. We use this helper to\n-/// detect changes to that output file by looking at the modification time for\n-/// all files in a directory and updating the stamp if any are newer.\n-///\n-/// Note that we only consider Rust libraries as that's what we're interested in\n-/// propagating changes from. Files like executables are tracked elsewhere.\n-fn update_mtime(build: &Build, path: &Path) {\n-    let entries = match path.parent().unwrap().join(\"deps\").read_dir() {\n-        Ok(entries) => entries,\n-        Err(_) => return,\n-    };\n-    let files = entries.map(|e| t!(e)).filter(|e| t!(e.file_type()).is_file());\n-    let files = files.filter(|e| {\n-        let filename = e.file_name();\n-        let filename = filename.to_str().unwrap();\n-        filename.ends_with(\".rlib\") ||\n-            filename.ends_with(\".lib\") ||\n-            is_dylib(&filename)\n-    });\n-    let max = files.max_by_key(|entry| {\n-        let meta = t!(entry.metadata());\n-        FileTime::from_last_modification_time(&meta)\n-    });\n-    let max = match max {\n-        Some(max) => max,\n-        None => return,\n+fn run_cargo(build: &Build, cargo: &mut Command, stamp: &Path) {\n+    // Instruct Cargo to give us json messages on stdout, critically leaving\n+    // stderr as piped so we can get those pretty colors.\n+    cargo.arg(\"--message-format\").arg(\"json\")\n+         .stdout(Stdio::piped());\n+    build.verbose(&format!(\"running: {:?}\", cargo));\n+    let mut child = match cargo.spawn() {\n+        Ok(child) => child,\n+        Err(e) => panic!(\"failed to execute command: {:?}\\nerror: {}\", cargo, e),\n     };\n \n-    if mtime(&max.path()) > mtime(path) {\n-        build.verbose(&format!(\"updating {:?} as {:?} changed\", path, max.path()));\n-        t!(File::create(path));\n+    // `target_root_dir` looks like $dir/$target/release\n+    let target_root_dir = stamp.parent().unwrap();\n+    // `target_deps_dir` looks like $dir/$target/release/deps\n+    let target_deps_dir = target_root_dir.join(\"deps\");\n+    // `host_root_dir` looks like $dir/release\n+    let host_root_dir = target_root_dir.parent().unwrap() // chop off `release`\n+                                       .parent().unwrap() // chop off `$target`\n+                                       .join(target_root_dir.file_name().unwrap());\n+\n+    // Spawn Cargo slurping up its JSON output. We'll start building up the\n+    // `deps` array of all files it generated along with a `toplevel` array of\n+    // files we need to probe for later.\n+    let mut deps = Vec::new();\n+    let mut toplevel = Vec::new();\n+    let stdout = BufReader::new(child.stdout.take().unwrap());\n+    for line in stdout.lines() {\n+        let line = t!(line);\n+        let json = if line.starts_with(\"{\") {\n+            t!(line.parse::<json::Json>())\n+        } else {\n+            // If this was informational, just print it out and continue\n+            println!(\"{}\", line);\n+            continue\n+        };\n+        if json.find(\"reason\").and_then(|j| j.as_string()) != Some(\"compiler-artifact\") {\n+            continue\n+        }\n+        for filename in json[\"filenames\"].as_array().unwrap() {\n+            let filename = filename.as_string().unwrap();\n+            // Skip files like executables\n+            if !filename.ends_with(\".rlib\") &&\n+               !filename.ends_with(\".lib\") &&\n+               !is_dylib(&filename) {\n+                continue\n+            }\n+\n+            let filename = Path::new(filename);\n+\n+            // If this was an output file in the \"host dir\" we don't actually\n+            // worry about it, it's not relevant for us.\n+            if filename.starts_with(&host_root_dir) {\n+                continue\n+\n+            // If this was output in the `deps` dir then this is a precise file\n+            // name (hash included) so we start tracking it.\n+            } else if filename.starts_with(&target_deps_dir) {\n+                deps.push(filename.to_path_buf());\n+\n+            // Otherwise this was a \"top level artifact\" which right now doesn't\n+            // have a hash in the name, but there's a version of this file in\n+            // the `deps` folder which *does* have a hash in the name. That's\n+            // the one we'll want to we'll probe for it later.\n+            } else {\n+                toplevel.push((filename.file_stem().unwrap()\n+                                       .to_str().unwrap().to_string(),\n+                               filename.extension().unwrap().to_owned()\n+                                       .to_str().unwrap().to_string()));\n+            }\n+        }\n+    }\n+\n+    // Make sure Cargo actually succeeded after we read all of its stdout.\n+    let status = t!(child.wait());\n+    if !status.success() {\n+        panic!(\"command did not execute successfully: {:?}\\n\\\n+                expected success, got: {}\",\n+               cargo,\n+               status);\n+    }\n+\n+    // Ok now we need to actually find all the files listed in `toplevel`. We've\n+    // got a list of prefix/extensions and we basically just need to find the\n+    // most recent file in the `deps` folder corresponding to each one.\n+    let contents = t!(target_deps_dir.read_dir())\n+        .map(|e| t!(e))\n+        .map(|e| (e.path(), e.file_name().into_string().unwrap(), t!(e.metadata())))\n+        .collect::<Vec<_>>();\n+    for (prefix, extension) in toplevel {\n+        let candidates = contents.iter().filter(|&&(_, ref filename, _)| {\n+            filename.starts_with(&prefix[..]) &&\n+                filename[prefix.len()..].starts_with(\"-\") &&\n+                filename.ends_with(&extension[..])\n+        });\n+        let max = candidates.max_by_key(|&&(_, _, ref metadata)| {\n+            FileTime::from_last_modification_time(metadata)\n+        });\n+        let path_to_add = match max {\n+            Some(triple) => triple.0.to_str().unwrap(),\n+            None => panic!(\"no output generated for {:?} {:?}\", prefix, extension),\n+        };\n+        if is_dylib(path_to_add) {\n+            let candidate = format!(\"{}.lib\", path_to_add);\n+            let candidate = PathBuf::from(candidate);\n+            if candidate.exists() {\n+                deps.push(candidate);\n+            }\n+        }\n+        deps.push(path_to_add.into());\n+    }\n+\n+    // Now we want to update the contents of the stamp file, if necessary. First\n+    // we read off the previous contents along with its mtime. If our new\n+    // contents (the list of files to copy) is different or if any dep's mtime\n+    // is newer then we rewrite the stamp file.\n+    deps.sort();\n+    let mut stamp_contents = Vec::new();\n+    if let Ok(mut f) = File::open(stamp) {\n+        t!(f.read_to_end(&mut stamp_contents));\n+    }\n+    let stamp_mtime = mtime(&stamp);\n+    let mut new_contents = Vec::new();\n+    let mut max = None;\n+    let mut max_path = None;\n+    for dep in deps {\n+        let mtime = mtime(&dep);\n+        if Some(mtime) > max {\n+            max = Some(mtime);\n+            max_path = Some(dep.clone());\n+        }\n+        new_contents.extend(dep.to_str().unwrap().as_bytes());\n+        new_contents.extend(b\"\\0\");\n+    }\n+    let max = max.unwrap();\n+    let max_path = max_path.unwrap();\n+    if stamp_contents == new_contents && max <= stamp_mtime {\n+        return\n+    }\n+    if max > stamp_mtime {\n+        build.verbose(&format!(\"updating {:?} as {:?} changed\", stamp, max_path));\n+    } else {\n+        build.verbose(&format!(\"updating {:?} as deps changed\", stamp));\n     }\n+    t!(t!(File::create(stamp)).write_all(&new_contents));\n }"}]}