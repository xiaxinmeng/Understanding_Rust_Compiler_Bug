{"sha": "16c6594f34cd0bb30596b5f5175cd4b6fa7c5e5d", "node_id": "C_kwDOAAsO6NoAKDE2YzY1OTRmMzRjZDBiYjMwNTk2YjVmNTE3NWNkNGI2ZmE3YzVlNWQ", "commit": {"author": {"name": "Matthias Kr\u00fcger", "email": "matthias.krueger@famsik.de", "date": "2022-03-03T19:01:45Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2022-03-03T19:01:45Z"}, "message": "Rollup merge of #94547 - nnethercote:parse_tt-cleanups, r=petrochenkov\n\n`parse_tt` cleanups\n\nI've been looking closely at this code, and saw some opportunities to improve its readability.\n\nr? ```````@petrochenkov```````", "tree": {"sha": "d48e4b4476b8da878540fe7d587d53585b2c92e3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d48e4b4476b8da878540fe7d587d53585b2c92e3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/16c6594f34cd0bb30596b5f5175cd4b6fa7c5e5d", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJiIRCZCRBK7hj4Ov3rIwAABlgIAAgW0lqIDbZRwqBhwQxv1u60\nZjXsz9RrBcg9DY5OBpf2QyydL5Su4d/7M+KvsGzS0cqndBh6CUhsnUT7qvXOzZTo\ncrMejcPuIQou5Pmmuo9qMZ76wWBaTOR6FYkro7KuxNbvgxnh64b9h8BOMXH9pTlM\nUWulIjNLdGwlaOLTwVLZFof1X4cnjgZ7Dla0rB01C8HyhYeSs2Gg+zqx2ZWZKEGh\ndFk6O4EaHoOKIAfDDicoLeKNgzkzz6hXxEFPTxOp0ClEaRCnZb305yRxyzxIoQAd\nquO+zw33ilkhwV6we6LptFCB52+VGIIz6Ce+8bGg7hOUUU5PFW5Rzw6cf0mxAdE=\n=iV8d\n-----END PGP SIGNATURE-----\n", "payload": "tree d48e4b4476b8da878540fe7d587d53585b2c92e3\nparent fec7a790888f103b8aa5374e7ddba50295ba64ec\nparent 97eb1b4669b893bf01cbc362e82ee10cfe8aff1c\nauthor Matthias Kr\u00fcger <matthias.krueger@famsik.de> 1646334105 +0100\ncommitter GitHub <noreply@github.com> 1646334105 +0100\n\nRollup merge of #94547 - nnethercote:parse_tt-cleanups, r=petrochenkov\n\n`parse_tt` cleanups\n\nI've been looking closely at this code, and saw some opportunities to improve its readability.\n\nr? ```````@petrochenkov```````\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/16c6594f34cd0bb30596b5f5175cd4b6fa7c5e5d", "html_url": "https://github.com/rust-lang/rust/commit/16c6594f34cd0bb30596b5f5175cd4b6fa7c5e5d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/16c6594f34cd0bb30596b5f5175cd4b6fa7c5e5d/comments", "author": {"login": "matthiaskrgr", "id": 476013, "node_id": "MDQ6VXNlcjQ3NjAxMw==", "avatar_url": "https://avatars.githubusercontent.com/u/476013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthiaskrgr", "html_url": "https://github.com/matthiaskrgr", "followers_url": "https://api.github.com/users/matthiaskrgr/followers", "following_url": "https://api.github.com/users/matthiaskrgr/following{/other_user}", "gists_url": "https://api.github.com/users/matthiaskrgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthiaskrgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthiaskrgr/subscriptions", "organizations_url": "https://api.github.com/users/matthiaskrgr/orgs", "repos_url": "https://api.github.com/users/matthiaskrgr/repos", "events_url": "https://api.github.com/users/matthiaskrgr/events{/privacy}", "received_events_url": "https://api.github.com/users/matthiaskrgr/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fec7a790888f103b8aa5374e7ddba50295ba64ec", "url": "https://api.github.com/repos/rust-lang/rust/commits/fec7a790888f103b8aa5374e7ddba50295ba64ec", "html_url": "https://github.com/rust-lang/rust/commit/fec7a790888f103b8aa5374e7ddba50295ba64ec"}, {"sha": "97eb1b4669b893bf01cbc362e82ee10cfe8aff1c", "url": "https://api.github.com/repos/rust-lang/rust/commits/97eb1b4669b893bf01cbc362e82ee10cfe8aff1c", "html_url": "https://github.com/rust-lang/rust/commit/97eb1b4669b893bf01cbc362e82ee10cfe8aff1c"}], "stats": {"total": 216, "additions": 115, "deletions": 101}, "files": [{"sha": "bb36dfd793d4a03bb3a8b96a50b281661323079f", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 115, "deletions": 101, "changes": 216, "blob_url": "https://github.com/rust-lang/rust/blob/16c6594f34cd0bb30596b5f5175cd4b6fa7c5e5d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/16c6594f34cd0bb30596b5f5175cd4b6fa7c5e5d/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=16c6594f34cd0bb30596b5f5175cd4b6fa7c5e5d", "patch": "@@ -154,7 +154,7 @@ type NamedMatchVec = SmallVec<[NamedMatch; 4]>;\n /// lifetime. By separating `'tt` from `'root`, we can show that.\n #[derive(Clone)]\n struct MatcherPos<'root, 'tt> {\n-    /// The token or sequence of tokens that make up the matcher\n+    /// The token or sequence of tokens that make up the matcher. `elts` is short for \"elements\".\n     top_elts: TokenTreeOrTokenTreeSlice<'tt>,\n \n     /// The position of the \"dot\" in this matcher\n@@ -184,17 +184,8 @@ struct MatcherPos<'root, 'tt> {\n     /// in this matcher.\n     match_hi: usize,\n \n-    // The following fields are used if we are matching a repetition. If we aren't, they should be\n-    // `None`.\n-    /// The KleeneOp of this sequence if we are in a repetition.\n-    seq_op: Option<mbe::KleeneOp>,\n-\n-    /// The separator if we are in a repetition.\n-    sep: Option<Token>,\n-\n-    /// The \"parent\" matcher position if we are in a repetition. That is, the matcher position just\n-    /// before we enter the sequence.\n-    up: Option<MatcherPosHandle<'root, 'tt>>,\n+    /// This field is only used if we are matching a repetition.\n+    repetition: Option<MatcherPosRepetition<'root, 'tt>>,\n \n     /// Specifically used to \"unzip\" token trees. By \"unzip\", we mean to unwrap the delimiters from\n     /// a delimited token tree (e.g., something wrapped in `(` `)`) or to get the contents of a doc\n@@ -207,14 +198,58 @@ struct MatcherPos<'root, 'tt> {\n     stack: SmallVec<[MatcherTtFrame<'tt>; 1]>,\n }\n \n+// This type is used a lot. Make sure it doesn't unintentionally get bigger.\n+#[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n+rustc_data_structures::static_assert_size!(MatcherPos<'_, '_>, 192);\n+\n impl<'root, 'tt> MatcherPos<'root, 'tt> {\n+    /// Generates the top-level matcher position in which the \"dot\" is before the first token of\n+    /// the matcher `ms`.\n+    fn new(ms: &'tt [TokenTree]) -> Self {\n+        let match_idx_hi = count_names(ms);\n+        MatcherPos {\n+            // Start with the top level matcher given to us.\n+            top_elts: TtSeq(ms),\n+\n+            // The \"dot\" is before the first token of the matcher.\n+            idx: 0,\n+\n+            // Initialize `matches` to a bunch of empty `Vec`s -- one for each metavar in\n+            // `top_elts`. `match_lo` for `top_elts` is 0 and `match_hi` is `match_idx_hi`.\n+            // `match_cur` is 0 since we haven't actually matched anything yet.\n+            matches: create_matches(match_idx_hi),\n+            match_lo: 0,\n+            match_cur: 0,\n+            match_hi: match_idx_hi,\n+\n+            // Haven't descended into any delimiters, so this is empty.\n+            stack: smallvec![],\n+\n+            // Haven't descended into any sequences, so this is `None`.\n+            repetition: None,\n+        }\n+    }\n+\n     /// Adds `m` as a named match for the `idx`-th metavar.\n     fn push_match(&mut self, idx: usize, m: NamedMatch) {\n         let matches = Lrc::make_mut(&mut self.matches[idx]);\n         matches.push(m);\n     }\n }\n \n+#[derive(Clone)]\n+struct MatcherPosRepetition<'root, 'tt> {\n+    /// The KleeneOp of this sequence.\n+    seq_op: mbe::KleeneOp,\n+\n+    /// The separator.\n+    sep: Option<Token>,\n+\n+    /// The \"parent\" matcher position. That is, the matcher position just before we enter the\n+    /// sequence.\n+    up: MatcherPosHandle<'root, 'tt>,\n+}\n+\n // Lots of MatcherPos instances are created at runtime. Allocating them on the\n // heap is slow. Furthermore, using SmallVec<MatcherPos> to allocate them all\n // on the stack is also slow, because MatcherPos is quite a large type and\n@@ -258,6 +293,12 @@ impl<'root, 'tt> DerefMut for MatcherPosHandle<'root, 'tt> {\n     }\n }\n \n+enum EofItems<'root, 'tt> {\n+    None,\n+    One(MatcherPosHandle<'root, 'tt>),\n+    Multiple,\n+}\n+\n /// Represents the possible results of an attempted parse.\n crate enum ParseResult<T> {\n     /// Parsed successfully.\n@@ -300,35 +341,6 @@ fn create_matches(len: usize) -> Box<[Lrc<NamedMatchVec>]> {\n     .into_boxed_slice()\n }\n \n-/// Generates the top-level matcher position in which the \"dot\" is before the first token of the\n-/// matcher `ms`.\n-fn initial_matcher_pos<'root, 'tt>(ms: &'tt [TokenTree]) -> MatcherPos<'root, 'tt> {\n-    let match_idx_hi = count_names(ms);\n-    let matches = create_matches(match_idx_hi);\n-    MatcherPos {\n-        // Start with the top level matcher given to us\n-        top_elts: TtSeq(ms), // \"elts\" is an abbr. for \"elements\"\n-        // The \"dot\" is before the first token of the matcher\n-        idx: 0,\n-\n-        // Initialize `matches` to a bunch of empty `Vec`s -- one for each metavar in `top_elts`.\n-        // `match_lo` for `top_elts` is 0 and `match_hi` is `matches.len()`. `match_cur` is 0 since\n-        // we haven't actually matched anything yet.\n-        matches,\n-        match_lo: 0,\n-        match_cur: 0,\n-        match_hi: match_idx_hi,\n-\n-        // Haven't descended into any delimiters, so empty stack\n-        stack: smallvec![],\n-\n-        // Haven't descended into any sequences, so both of these are `None`.\n-        seq_op: None,\n-        sep: None,\n-        up: None,\n-    }\n-}\n-\n /// `NamedMatch` is a pattern-match result for a single `token::MATCH_NONTERMINAL`:\n /// so it is associated with a single ident in a parse, and all\n /// `MatchedNonterminal`s in the `NamedMatch` have the same non-terminal type\n@@ -475,10 +487,10 @@ fn inner_parse_loop<'root, 'tt>(\n     sess: &ParseSess,\n     cur_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n     next_items: &mut Vec<MatcherPosHandle<'root, 'tt>>,\n-    eof_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n     bb_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n+    eof_items: &mut EofItems<'root, 'tt>,\n     token: &Token,\n-) -> ParseResult<()> {\n+) -> Result<(), (rustc_span::Span, String)> {\n     // Pop items from `cur_items` until it is empty.\n     while let Some(mut item) = cur_items.pop() {\n         // When unzipped trees end, remove them. This corresponds to backtracking out of a\n@@ -504,7 +516,7 @@ fn inner_parse_loop<'root, 'tt>(\n             // We are repeating iff there is a parent. If the matcher is inside of a repetition,\n             // then we could be at the end of a sequence or at the beginning of the next\n             // repetition.\n-            if item.up.is_some() {\n+            if let Some(repetition) = &item.repetition {\n                 // At this point, regardless of whether there is a separator, we should add all\n                 // matches from the complete repetition of the sequence to the shared, top-level\n                 // `matches` list (actually, `up.matches`, which could itself not be the top-level,\n@@ -515,7 +527,7 @@ fn inner_parse_loop<'root, 'tt>(\n                 // NOTE: removing the condition `idx == len` allows trailing separators.\n                 if idx == len {\n                     // Get the `up` matcher\n-                    let mut new_pos = item.up.clone().unwrap();\n+                    let mut new_pos = repetition.up.clone();\n \n                     // Add matches from this repetition to the `matches` of `up`\n                     for idx in item.match_lo..item.match_hi {\n@@ -530,32 +542,33 @@ fn inner_parse_loop<'root, 'tt>(\n                 }\n \n                 // Check if we need a separator.\n-                if idx == len && item.sep.is_some() {\n+                if idx == len && repetition.sep.is_some() {\n                     // We have a separator, and it is the current token. We can advance past the\n                     // separator token.\n-                    if item.sep.as_ref().map_or(false, |sep| token_name_eq(token, sep)) {\n+                    if repetition.sep.as_ref().map_or(false, |sep| token_name_eq(token, sep)) {\n                         item.idx += 1;\n                         next_items.push(item);\n                     }\n-                }\n-                // We don't need a separator. Move the \"dot\" back to the beginning of the matcher\n-                // and try to match again UNLESS we are only allowed to have _one_ repetition.\n-                else if item.seq_op != Some(mbe::KleeneOp::ZeroOrOne) {\n+                } else if repetition.seq_op != mbe::KleeneOp::ZeroOrOne {\n+                    // We don't need a separator. Move the \"dot\" back to the beginning of the\n+                    // matcher and try to match again UNLESS we are only allowed to have _one_\n+                    // repetition.\n                     item.match_cur = item.match_lo;\n                     item.idx = 0;\n                     cur_items.push(item);\n                 }\n+            } else {\n+                // If we are not in a repetition, then being at the end of a matcher means that we\n+                // have reached the potential end of the input.\n+                *eof_items = match eof_items {\n+                    EofItems::None => EofItems::One(item),\n+                    EofItems::One(_) | EofItems::Multiple => EofItems::Multiple,\n+                }\n             }\n-            // If we are not in a repetition, then being at the end of a matcher means that we have\n-            // reached the potential end of the input.\n-            else {\n-                eof_items.push(item);\n-            }\n-        }\n-        // We are in the middle of a matcher.\n-        else {\n-            // Look at what token in the matcher we are trying to match the current token (`token`)\n-            // against. Depending on that, we may generate new items.\n+        } else {\n+            // We are in the middle of a matcher. Look at what token in the matcher we are trying\n+            // to match the current token (`token`) against. Depending on that, we may generate new\n+            // items.\n             match item.top_elts.get_tt(idx) {\n                 // Need to descend into a sequence\n                 TokenTree::Sequence(sp, seq) => {\n@@ -578,22 +591,24 @@ fn inner_parse_loop<'root, 'tt>(\n                     let matches = create_matches(item.matches.len());\n                     cur_items.push(MatcherPosHandle::Box(Box::new(MatcherPos {\n                         stack: smallvec![],\n-                        sep: seq.separator.clone(),\n-                        seq_op: Some(seq.kleene.op),\n                         idx: 0,\n                         matches,\n                         match_lo: item.match_cur,\n                         match_cur: item.match_cur,\n                         match_hi: item.match_cur + seq.num_captures,\n-                        up: Some(item),\n+                        repetition: Some(MatcherPosRepetition {\n+                            up: item,\n+                            sep: seq.separator.clone(),\n+                            seq_op: seq.kleene.op,\n+                        }),\n                         top_elts: Tt(TokenTree::Sequence(sp, seq)),\n                     })));\n                 }\n \n                 // We need to match a metavar (but the identifier is invalid)... this is an error\n                 TokenTree::MetaVarDecl(span, _, None) => {\n                     if sess.missing_fragment_specifiers.borrow_mut().remove(&span).is_some() {\n-                        return Error(span, \"missing fragment specifier\".to_string());\n+                        return Err((span, \"missing fragment specifier\".to_string()));\n                     }\n                 }\n \n@@ -641,7 +656,7 @@ fn inner_parse_loop<'root, 'tt>(\n     }\n \n     // Yay a successful parse (so far)!\n-    Success(())\n+    Ok(())\n }\n \n /// Use the given sequence of token trees (`ms`) as a matcher. Match the token\n@@ -659,17 +674,18 @@ pub(super) fn parse_tt(\n     //\n     // This MatcherPos instance is allocated on the stack. All others -- and\n     // there are frequently *no* others! -- are allocated on the heap.\n-    let mut initial = initial_matcher_pos(ms);\n+    let mut initial = MatcherPos::new(ms);\n     let mut cur_items = smallvec![MatcherPosHandle::Ref(&mut initial)];\n     let mut next_items = Vec::new();\n \n     loop {\n+        assert!(next_items.is_empty());\n+\n         // Matcher positions black-box parsed by parser.rs (`parser`)\n         let mut bb_items = SmallVec::new();\n \n         // Matcher positions that would be valid if the macro invocation was over now\n-        let mut eof_items = SmallVec::new();\n-        assert!(next_items.is_empty());\n+        let mut eof_items = EofItems::None;\n \n         // Process `cur_items` until either we have finished the input or we need to get some\n         // parsing from the black-box parser done. The result is that `next_items` will contain a\n@@ -678,37 +694,34 @@ pub(super) fn parse_tt(\n             parser.sess,\n             &mut cur_items,\n             &mut next_items,\n-            &mut eof_items,\n             &mut bb_items,\n+            &mut eof_items,\n             &parser.token,\n         ) {\n-            Success(_) => {}\n-            Failure(token, msg) => return Failure(token, msg),\n-            Error(sp, msg) => return Error(sp, msg),\n-            ErrorReported => return ErrorReported,\n+            Ok(()) => {}\n+            Err((sp, msg)) => return Error(sp, msg),\n         }\n \n         // inner parse loop handled all cur_items, so it's empty\n         assert!(cur_items.is_empty());\n \n-        // We need to do some post processing after the `inner_parser_loop`.\n+        // We need to do some post processing after the `inner_parse_loop`.\n         //\n         // Error messages here could be improved with links to original rules.\n \n         // If we reached the EOF, check that there is EXACTLY ONE possible matcher. Otherwise,\n         // either the parse is ambiguous (which should never happen) or there is a syntax error.\n         if parser.token == token::Eof {\n-            if eof_items.len() == 1 {\n-                let matches =\n-                    eof_items[0].matches.iter_mut().map(|dv| Lrc::make_mut(dv).pop().unwrap());\n-                return nameize(parser.sess, ms, matches);\n-            } else if eof_items.len() > 1 {\n-                return Error(\n-                    parser.token.span,\n-                    \"ambiguity: multiple successful parses\".to_string(),\n-                );\n-            } else {\n-                return Failure(\n+            return match eof_items {\n+                EofItems::One(mut eof_item) => {\n+                    let matches =\n+                        eof_item.matches.iter_mut().map(|dv| Lrc::make_mut(dv).pop().unwrap());\n+                    nameize(parser.sess, ms, matches)\n+                }\n+                EofItems::Multiple => {\n+                    Error(parser.token.span, \"ambiguity: multiple successful parses\".to_string())\n+                }\n+                EofItems::None => Failure(\n                     Token::new(\n                         token::Eof,\n                         if parser.token.span.is_dummy() {\n@@ -718,22 +731,23 @@ pub(super) fn parse_tt(\n                         },\n                     ),\n                     \"missing tokens in macro arguments\",\n-                );\n-            }\n+                ),\n+            };\n         }\n-        // Performance hack: eof_items may share matchers via Rc with other things that we want\n-        // to modify. Dropping eof_items now may drop these refcounts to 1, preventing an\n-        // unnecessary implicit clone later in Rc::make_mut.\n+        // Performance hack: `eof_items` may share matchers via `Rc` with other things that we want\n+        // to modify. Dropping `eof_items` now may drop these refcounts to 1, preventing an\n+        // unnecessary implicit clone later in `Rc::make_mut`.\n         drop(eof_items);\n \n         // If there are no possible next positions AND we aren't waiting for the black-box parser,\n         // then there is a syntax error.\n         if bb_items.is_empty() && next_items.is_empty() {\n             return Failure(parser.token.clone(), \"no rules expected this token in macro call\");\n         }\n-        // Another possibility is that we need to call out to parse some rust nonterminal\n-        // (black-box) parser. However, if there is not EXACTLY ONE of these, something is wrong.\n-        else if (!bb_items.is_empty() && !next_items.is_empty()) || bb_items.len() > 1 {\n+\n+        if (!bb_items.is_empty() && !next_items.is_empty()) || bb_items.len() > 1 {\n+            // We need to call out to parse some rust nonterminal (black-box) parser. But something\n+            // is wrong, because there is not EXACTLY ONE of these.\n             let nts = bb_items\n                 .iter()\n                 .map(|item| match item.top_elts.get_tt(item.idx) {\n@@ -755,15 +769,15 @@ pub(super) fn parse_tt(\n                 ),\n             );\n         }\n-        // Dump all possible `next_items` into `cur_items` for the next iteration.\n-        else if !next_items.is_empty() {\n-            // Now process the next token\n+\n+        if !next_items.is_empty() {\n+            // Dump all possible `next_items` into `cur_items` for the next iteration. Then process\n+            // the next token.\n             cur_items.extend(next_items.drain(..));\n             parser.to_mut().bump();\n-        }\n-        // Finally, we have the case where we need to call the black-box parser to get some\n-        // nonterminal.\n-        else {\n+        } else {\n+            // Finally, we have the case where we need to call the black-box parser to get some\n+            // nonterminal.\n             assert_eq!(bb_items.len(), 1);\n \n             let mut item = bb_items.pop().unwrap();"}]}