{"sha": "4c8cc141863274683681a6fa3d5d4e0230780c66", "node_id": "MDY6Q29tbWl0NzI0NzEyOjRjOGNjMTQxODYzMjc0NjgzNjgxYTZmYTNkNWQ0ZTAyMzA3ODBjNjY=", "commit": {"author": {"name": "Wesley Wiser", "email": "wwiser@gmail.com", "date": "2019-02-13T13:13:30Z"}, "committer": {"name": "Wesley Wiser", "email": "wwiser@gmail.com", "date": "2019-03-10T15:10:55Z"}, "message": "Replace TimeLine with SelfProfiler", "tree": {"sha": "427ecfcfd5b62a1287d9ff11799c247fc600b05a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/427ecfcfd5b62a1287d9ff11799c247fc600b05a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4c8cc141863274683681a6fa3d5d4e0230780c66", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4c8cc141863274683681a6fa3d5d4e0230780c66", "html_url": "https://github.com/rust-lang/rust/commit/4c8cc141863274683681a6fa3d5d4e0230780c66", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4c8cc141863274683681a6fa3d5d4e0230780c66/comments", "author": {"login": "wesleywiser", "id": 831192, "node_id": "MDQ6VXNlcjgzMTE5Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/831192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wesleywiser", "html_url": "https://github.com/wesleywiser", "followers_url": "https://api.github.com/users/wesleywiser/followers", "following_url": "https://api.github.com/users/wesleywiser/following{/other_user}", "gists_url": "https://api.github.com/users/wesleywiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/wesleywiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wesleywiser/subscriptions", "organizations_url": "https://api.github.com/users/wesleywiser/orgs", "repos_url": "https://api.github.com/users/wesleywiser/repos", "events_url": "https://api.github.com/users/wesleywiser/events{/privacy}", "received_events_url": "https://api.github.com/users/wesleywiser/received_events", "type": "User", "site_admin": false}, "committer": {"login": "wesleywiser", "id": 831192, "node_id": "MDQ6VXNlcjgzMTE5Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/831192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wesleywiser", "html_url": "https://github.com/wesleywiser", "followers_url": "https://api.github.com/users/wesleywiser/followers", "following_url": "https://api.github.com/users/wesleywiser/following{/other_user}", "gists_url": "https://api.github.com/users/wesleywiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/wesleywiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wesleywiser/subscriptions", "organizations_url": "https://api.github.com/users/wesleywiser/orgs", "repos_url": "https://api.github.com/users/wesleywiser/repos", "events_url": "https://api.github.com/users/wesleywiser/events{/privacy}", "received_events_url": "https://api.github.com/users/wesleywiser/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "913ad6d1f092c70049934ba538d342d295d35997", "url": "https://api.github.com/repos/rust-lang/rust/commits/913ad6d1f092c70049934ba538d342d295d35997", "html_url": "https://github.com/rust-lang/rust/commit/913ad6d1f092c70049934ba538d342d295d35997"}], "stats": {"total": 590, "additions": 155, "deletions": 435}, "files": [{"sha": "681dffc0116e3d2941165dcc3f19e28c9254993b", "filename": "src/librustc/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flib.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -136,7 +136,6 @@ pub mod util {\n     pub mod common;\n     pub mod ppaux;\n     pub mod nodemap;\n-    pub mod time_graph;\n     pub mod profiling;\n     pub mod bug;\n }"}, {"sha": "2739a30a291352e79bdca861ae5b6ea1d2335002", "filename": "src/librustc/util/profiling.rs", "status": "modified", "additions": 23, "deletions": 8, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc%2Futil%2Fprofiling.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc%2Futil%2Fprofiling.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fprofiling.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -1,3 +1,4 @@\n+use std::borrow::Cow;\n use std::fs;\n use std::io::{BufWriter, Write};\n use std::mem;\n@@ -20,12 +21,12 @@ pub enum ProfileCategory {\n     Other,\n }\n \n-#[derive(Clone, Copy, Debug, Eq, PartialEq)]\n+#[derive(Clone, Debug, Eq, PartialEq)]\n pub enum ProfilerEvent {\n     QueryStart { query_name: &'static str, category: ProfileCategory, time: u64 },\n     QueryEnd { query_name: &'static str, category: ProfileCategory, time: u64 },\n-    GenericActivityStart { category: ProfileCategory, time: u64 },\n-    GenericActivityEnd { category: ProfileCategory, time: u64 },\n+    GenericActivityStart { category: ProfileCategory, label: Cow<'static, str>, time: u64 },\n+    GenericActivityEnd { category: ProfileCategory, label: Cow<'static, str>, time: u64 },\n     IncrementalLoadResultStart { query_name: &'static str, time: u64 },\n     IncrementalLoadResultEnd { query_name: &'static str, time: u64 },\n     QueryCacheHit { query_name: &'static str, category: ProfileCategory, time: u64 },\n@@ -75,17 +76,27 @@ impl SelfProfiler {\n     }\n \n     #[inline]\n-    pub fn start_activity(&mut self, category: ProfileCategory) {\n+    pub fn start_activity(\n+        &mut self,\n+        category: ProfileCategory,\n+        label: impl Into<Cow<'static, str>>,\n+    ) {\n         self.record(ProfilerEvent::GenericActivityStart {\n             category,\n+            label: label.into(),\n             time: self.get_time_from_start(),\n         })\n     }\n \n     #[inline]\n-    pub fn end_activity(&mut self, category: ProfileCategory) {\n+    pub fn end_activity(\n+        &mut self,\n+        category: ProfileCategory,\n+        label: impl Into<Cow<'static, str>>,\n+    ) {\n         self.record(ProfilerEvent::GenericActivityEnd {\n             category,\n+            label: label.into(),\n             time: self.get_time_from_start(),\n         })\n     }\n@@ -273,11 +284,12 @@ impl SelfProfiler {\n                             nanos,\n                             thread_id,\n                         ).unwrap(),\n-                    GenericActivityStart { category, time: _ } =>\n+                    GenericActivityStart { category, label, time: _ } =>\n                         write!(file,\n                             \"{{\n                                 \\\"GenericActivityStart\\\": {{\\\n                                     \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"label\\\": \\\"{}\\\",\\\n                                     \\\"time\\\": {{\\\n                                         \\\"secs\\\": {},\\\n                                         \\\"nanos\\\": {}\\\n@@ -286,15 +298,17 @@ impl SelfProfiler {\n                                 }}\\\n                             }}\",\n                             category,\n+                            label,\n                             secs,\n                             nanos,\n                             thread_id,\n                         ).unwrap(),\n-                    GenericActivityEnd { category, time: _ } =>\n+                    GenericActivityEnd { category, label, time: _ } =>\n                         write!(file,\n                             \"{{\\\n                                 \\\"GenericActivityEnd\\\": {{\\\n                                     \\\"category\\\": \\\"{:?}\\\",\\\n+                                    \\\"label\\\": \\\"{}\\\",\\\n                                     \\\"time\\\": {{\\\n                                         \\\"secs\\\": {},\\\n                                         \\\"nanos\\\": {}\\\n@@ -303,6 +317,7 @@ impl SelfProfiler {\n                                 }}\\\n                             }}\",\n                             category,\n+                            label,\n                             secs,\n                             nanos,\n                             thread_id,\n@@ -418,7 +433,7 @@ impl SelfProfiler {\n                             secs,\n                             nanos,\n                             thread_id,\n-                        ).unwrap()\n+                        ).unwrap(),\n                 }\n             }\n         }"}, {"sha": "4dd383fd234ac693861008330a89dcbc1e80662d", "filename": "src/librustc/util/time_graph.rs", "status": "removed", "additions": 0, "deletions": 268, "changes": 268, "blob_url": "https://github.com/rust-lang/rust/blob/913ad6d1f092c70049934ba538d342d295d35997/src%2Flibrustc%2Futil%2Ftime_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/913ad6d1f092c70049934ba538d342d295d35997/src%2Flibrustc%2Futil%2Ftime_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Ftime_graph.rs?ref=913ad6d1f092c70049934ba538d342d295d35997", "patch": "@@ -1,268 +0,0 @@\n-use rustc_data_structures::fx::FxHashMap;\n-use std::fs::File;\n-use std::io::prelude::*;\n-use std::marker::PhantomData;\n-use std::mem;\n-use std::sync::{Arc, Mutex};\n-use std::time::Instant;\n-\n-const OUTPUT_WIDTH_IN_PX: u64 = 1000;\n-const TIME_LINE_HEIGHT_IN_PX: u64 = 20;\n-const TIME_LINE_HEIGHT_STRIDE_IN_PX: usize = 30;\n-\n-#[derive(Clone)]\n-struct Timing {\n-    start: Instant,\n-    end: Instant,\n-    work_package_kind: WorkPackageKind,\n-    name: String,\n-    events: Vec<(String, Instant)>,\n-}\n-\n-#[derive(Clone, Copy, Hash, Eq, PartialEq, Debug)]\n-pub struct TimelineId(pub usize);\n-\n-#[derive(Clone)]\n-struct PerThread {\n-    timings: Vec<Timing>,\n-    open_work_package: Option<(Instant, WorkPackageKind, String)>,\n-}\n-\n-#[derive(Clone)]\n-pub struct TimeGraph {\n-    data: Arc<Mutex<FxHashMap<TimelineId, PerThread>>>,\n-}\n-\n-#[derive(Clone, Copy)]\n-pub struct WorkPackageKind(pub &'static [&'static str]);\n-\n-pub struct Timeline {\n-    token: Option<RaiiToken>,\n-}\n-\n-struct RaiiToken {\n-    graph: TimeGraph,\n-    timeline: TimelineId,\n-    events: Vec<(String, Instant)>,\n-    // The token must not be Send:\n-    _marker: PhantomData<*const ()>\n-}\n-\n-\n-impl Drop for RaiiToken {\n-    fn drop(&mut self) {\n-        self.graph.end(self.timeline, mem::replace(&mut self.events, Vec::new()));\n-    }\n-}\n-\n-impl TimeGraph {\n-    pub fn new() -> TimeGraph {\n-        TimeGraph {\n-            data: Arc::new(Mutex::new(FxHashMap::default()))\n-        }\n-    }\n-\n-    pub fn start(&self,\n-                 timeline: TimelineId,\n-                 work_package_kind: WorkPackageKind,\n-                 name: &str) -> Timeline {\n-        {\n-            let mut table = self.data.lock().unwrap();\n-\n-            let data = table.entry(timeline).or_insert(PerThread {\n-                timings: Vec::new(),\n-                open_work_package: None,\n-            });\n-\n-            assert!(data.open_work_package.is_none());\n-            data.open_work_package = Some((Instant::now(), work_package_kind, name.to_string()));\n-        }\n-\n-        Timeline {\n-            token: Some(RaiiToken {\n-                graph: self.clone(),\n-                timeline,\n-                events: Vec::new(),\n-                _marker: PhantomData,\n-            }),\n-        }\n-    }\n-\n-    fn end(&self, timeline: TimelineId, events: Vec<(String, Instant)>) {\n-        let end = Instant::now();\n-\n-        let mut table = self.data.lock().unwrap();\n-        let data = table.get_mut(&timeline).unwrap();\n-\n-        if let Some((start, work_package_kind, name)) = data.open_work_package.take() {\n-            data.timings.push(Timing {\n-                start,\n-                end,\n-                work_package_kind,\n-                name,\n-                events,\n-            });\n-        } else {\n-            bug!(\"end timing without start?\")\n-        }\n-    }\n-\n-    pub fn dump(&self, output_filename: &str) {\n-        let table = self.data.lock().unwrap();\n-\n-        for data in table.values() {\n-            assert!(data.open_work_package.is_none());\n-        }\n-\n-        let mut threads: Vec<PerThread> =\n-            table.values().map(|data| data.clone()).collect();\n-\n-        threads.sort_by_key(|timeline| timeline.timings[0].start);\n-\n-        let earliest_instant = threads[0].timings[0].start;\n-        let latest_instant = threads.iter()\n-                                       .map(|timeline| timeline.timings\n-                                                               .last()\n-                                                               .unwrap()\n-                                                               .end)\n-                                       .max()\n-                                       .unwrap();\n-        let max_distance = distance(earliest_instant, latest_instant);\n-\n-        let mut file = File::create(format!(\"{}.html\", output_filename)).unwrap();\n-\n-        writeln!(file, \"\n-            <html>\n-            <head>\n-                <style>\n-                    #threads a {{\n-                        position: absolute;\n-                        overflow: hidden;\n-                    }}\n-                    #threads {{\n-                        height: {total_height}px;\n-                        width: {width}px;\n-                    }}\n-\n-                    .timeline {{\n-                        display: none;\n-                        width: {width}px;\n-                        position: relative;\n-                    }}\n-\n-                    .timeline:target {{\n-                        display: block;\n-                    }}\n-\n-                    .event {{\n-                        position: absolute;\n-                    }}\n-                </style>\n-            </head>\n-            <body>\n-                <div id='threads'>\n-        \",\n-            total_height = threads.len() * TIME_LINE_HEIGHT_STRIDE_IN_PX,\n-            width = OUTPUT_WIDTH_IN_PX,\n-        ).unwrap();\n-\n-        let mut color = 0;\n-        for (line_index, thread) in threads.iter().enumerate() {\n-            let line_top = line_index * TIME_LINE_HEIGHT_STRIDE_IN_PX;\n-\n-            for span in &thread.timings {\n-                let start = distance(earliest_instant, span.start);\n-                let end = distance(earliest_instant, span.end);\n-\n-                let start = normalize(start, max_distance, OUTPUT_WIDTH_IN_PX);\n-                let end = normalize(end, max_distance, OUTPUT_WIDTH_IN_PX);\n-\n-                let colors = span.work_package_kind.0;\n-\n-                writeln!(file, \"<a href='#timing{}'\n-                                   style='top:{}px; \\\n-                                          left:{}px; \\\n-                                          width:{}px; \\\n-                                          height:{}px; \\\n-                                          background:{};'>{}</a>\",\n-                    color,\n-                    line_top,\n-                    start,\n-                    end - start,\n-                    TIME_LINE_HEIGHT_IN_PX,\n-                    colors[color % colors.len()],\n-                    span.name,\n-                    ).unwrap();\n-\n-                color += 1;\n-            }\n-        }\n-\n-        writeln!(file, \"\n-            </div>\n-        \").unwrap();\n-\n-        let mut idx = 0;\n-        for thread in threads.iter() {\n-            for timing in &thread.timings {\n-                let colors = timing.work_package_kind.0;\n-                let height = TIME_LINE_HEIGHT_STRIDE_IN_PX * timing.events.len();\n-                writeln!(file, \"<div class='timeline'\n-                                     id='timing{}'\n-                                     style='background:{};height:{}px;'>\",\n-                         idx,\n-                         colors[idx % colors.len()],\n-                         height).unwrap();\n-                idx += 1;\n-                let max = distance(timing.start, timing.end);\n-                for (i, &(ref event, time)) in timing.events.iter().enumerate() {\n-                    let i = i as u64;\n-                    let time = distance(timing.start, time);\n-                    let at = normalize(time, max, OUTPUT_WIDTH_IN_PX);\n-                    writeln!(file, \"<span class='event'\n-                                          style='left:{}px;\\\n-                                                 top:{}px;'>{}</span>\",\n-                             at,\n-                             TIME_LINE_HEIGHT_IN_PX * i,\n-                             event).unwrap();\n-                }\n-                writeln!(file, \"</div>\").unwrap();\n-            }\n-        }\n-\n-        writeln!(file, \"\n-            </body>\n-            </html>\n-        \").unwrap();\n-    }\n-}\n-\n-impl Timeline {\n-    pub fn noop() -> Timeline {\n-        Timeline { token: None }\n-    }\n-\n-    /// Record an event which happened at this moment on this timeline.\n-    ///\n-    /// Events are displayed in the eventual HTML output where you can click on\n-    /// a particular timeline and it'll expand to all of the events that\n-    /// happened on that timeline. This can then be used to drill into a\n-    /// particular timeline and see what events are happening and taking the\n-    /// most time.\n-    pub fn record(&mut self, name: &str) {\n-        if let Some(ref mut token) = self.token {\n-            token.events.push((name.to_string(), Instant::now()));\n-        }\n-    }\n-}\n-\n-fn distance(zero: Instant, x: Instant) -> u64 {\n-\n-    let duration = x.duration_since(zero);\n-    (duration.as_secs() * 1_000_000_000 + duration.subsec_nanos() as u64) // / div\n-}\n-\n-fn normalize(distance: u64, max: u64, max_pixels: u64) -> u64 {\n-    (max_pixels * distance) / max\n-}\n-"}, {"sha": "84c652ff238afb4914a1f96e12cc814287554eb9", "filename": "src/librustc_codegen_llvm/back/lto.rs", "status": "modified", "additions": 14, "deletions": 30, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -3,7 +3,6 @@ use crate::back::write::{self, DiagnosticHandlers, with_llvm_pmb, save_temp_bitc\n     to_llvm_opt_settings};\n use crate::llvm::archive_ro::ArchiveRO;\n use crate::llvm::{self, True, False};\n-use crate::time_graph::Timeline;\n use crate::{ModuleLlvm, LlvmCodegenBackend};\n use rustc_codegen_ssa::back::symbol_export;\n use rustc_codegen_ssa::back::write::{ModuleConfig, CodegenContext, FatLTOInput};\n@@ -16,6 +15,7 @@ use rustc::hir::def_id::LOCAL_CRATE;\n use rustc::middle::exported_symbols::SymbolExportLevel;\n use rustc::session::config::{self, Lto};\n use rustc::util::common::time_ext;\n+use rustc::util::profiling::ProfileCategory;\n use rustc_data_structures::fx::FxHashMap;\n use rustc_codegen_ssa::{ModuleCodegen, ModuleKind};\n \n@@ -37,7 +37,6 @@ pub fn crate_type_allows_lto(crate_type: config::CrateType) -> bool {\n }\n \n fn prepare_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n-               timeline: &mut Timeline,\n                diag_handler: &Handler)\n     -> Result<(Vec<CString>, Vec<(SerializedModule<ModuleBuffer>, CString)>), FatalError>\n {\n@@ -68,7 +67,8 @@ fn prepare_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         .iter()\n         .filter_map(symbol_filter)\n         .collect::<Vec<CString>>();\n-    timeline.record(\"whitelist\");\n+    let _timer = cgcx.profile_activity(ProfileCategory::Codegen,\n+                                       \"generate_symbol_white_list_for_thinlto\");\n     info!(\"{} symbols to preserve in this crate\", symbol_white_list.len());\n \n     // If we're performing LTO for the entire crate graph, then for each of our\n@@ -97,6 +97,8 @@ fn prepare_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         }\n \n         for &(cnum, ref path) in cgcx.each_linked_rlib_for_lto.iter() {\n+            let _timer = cgcx.profile_activity(ProfileCategory::Codegen,\n+                                               format!(\"load: {}\", path.display()));\n             let exported_symbols = cgcx.exported_symbols\n                 .as_ref().expect(\"needs exported symbols for LTO\");\n             symbol_white_list.extend(\n@@ -121,7 +123,6 @@ fn prepare_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                 let bc = SerializedModule::FromRlib(bc);\n                 upstream_modules.push((bc, CString::new(id).unwrap()));\n             }\n-            timeline.record(&format!(\"load: {}\", path.display()));\n         }\n     }\n \n@@ -132,12 +133,11 @@ fn prepare_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n /// for further optimization.\n pub(crate) fn run_fat(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                       modules: Vec<FatLTOInput<LlvmCodegenBackend>>,\n-                      cached_modules: Vec<(SerializedModule<ModuleBuffer>, WorkProduct)>,\n-                      timeline: &mut Timeline)\n+                      cached_modules: Vec<(SerializedModule<ModuleBuffer>, WorkProduct)>)\n     -> Result<LtoModuleCodegen<LlvmCodegenBackend>, FatalError>\n {\n     let diag_handler = cgcx.create_diag_handler();\n-    let (symbol_white_list, upstream_modules) = prepare_lto(cgcx, timeline, &diag_handler)?;\n+    let (symbol_white_list, upstream_modules) = prepare_lto(cgcx, &diag_handler)?;\n     let symbol_white_list = symbol_white_list.iter()\n                                              .map(|c| c.as_ptr())\n                                              .collect::<Vec<_>>();\n@@ -148,7 +148,6 @@ pub(crate) fn run_fat(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         cached_modules,\n         upstream_modules,\n         &symbol_white_list,\n-        timeline,\n     )\n }\n \n@@ -157,12 +156,11 @@ pub(crate) fn run_fat(cgcx: &CodegenContext<LlvmCodegenBackend>,\n /// can simply be copied over from the incr. comp. cache.\n pub(crate) fn run_thin(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                        modules: Vec<(String, ThinBuffer)>,\n-                       cached_modules: Vec<(SerializedModule<ModuleBuffer>, WorkProduct)>,\n-                       timeline: &mut Timeline)\n+                       cached_modules: Vec<(SerializedModule<ModuleBuffer>, WorkProduct)>)\n     -> Result<(Vec<LtoModuleCodegen<LlvmCodegenBackend>>, Vec<WorkProduct>), FatalError>\n {\n     let diag_handler = cgcx.create_diag_handler();\n-    let (symbol_white_list, upstream_modules) = prepare_lto(cgcx, timeline, &diag_handler)?;\n+    let (symbol_white_list, upstream_modules) = prepare_lto(cgcx, &diag_handler)?;\n     let symbol_white_list = symbol_white_list.iter()\n                                              .map(|c| c.as_ptr())\n                                              .collect::<Vec<_>>();\n@@ -175,8 +173,7 @@ pub(crate) fn run_thin(cgcx: &CodegenContext<LlvmCodegenBackend>,\n              modules,\n              upstream_modules,\n              cached_modules,\n-             &symbol_white_list,\n-             timeline)\n+             &symbol_white_list)\n }\n \n pub(crate) fn prepare_thin(\n@@ -192,8 +189,7 @@ fn fat_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n            mut modules: Vec<FatLTOInput<LlvmCodegenBackend>>,\n            cached_modules: Vec<(SerializedModule<ModuleBuffer>, WorkProduct)>,\n            mut serialized_modules: Vec<(SerializedModule<ModuleBuffer>, CString)>,\n-           symbol_white_list: &[*const libc::c_char],\n-           timeline: &mut Timeline)\n+           symbol_white_list: &[*const libc::c_char])\n     -> Result<LtoModuleCodegen<LlvmCodegenBackend>, FatalError>\n {\n     info!(\"going for a fat lto\");\n@@ -303,7 +299,6 @@ fn fat_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                     write::llvm_err(&diag_handler, &msg)\n                 })\n             })?;\n-            timeline.record(&format!(\"link {:?}\", name));\n             serialized_bitcode.push(bc_decoded);\n         }\n         drop(linker);\n@@ -325,7 +320,6 @@ fn fat_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             }\n             save_temp_bitcode(&cgcx, &module, \"lto.after-nounwind\");\n         }\n-        timeline.record(\"passes\");\n     }\n \n     Ok(LtoModuleCodegen::Fat {\n@@ -395,8 +389,7 @@ fn thin_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             modules: Vec<(String, ThinBuffer)>,\n             serialized_modules: Vec<(SerializedModule<ModuleBuffer>, CString)>,\n             cached_modules: Vec<(SerializedModule<ModuleBuffer>, WorkProduct)>,\n-            symbol_white_list: &[*const libc::c_char],\n-            timeline: &mut Timeline)\n+            symbol_white_list: &[*const libc::c_char])\n     -> Result<(Vec<LtoModuleCodegen<LlvmCodegenBackend>>, Vec<WorkProduct>), FatalError>\n {\n     unsafe {\n@@ -422,7 +415,6 @@ fn thin_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             });\n             thin_buffers.push(buffer);\n             module_names.push(cname);\n-            timeline.record(&name);\n         }\n \n         // FIXME: All upstream crates are deserialized internally in the\n@@ -475,7 +467,6 @@ fn thin_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         })?;\n \n         info!(\"thin LTO data created\");\n-        timeline.record(\"data\");\n \n         let import_map = if cgcx.incr_comp_session_dir.is_some() {\n             ThinLTOImports::from_thin_lto_data(data)\n@@ -486,7 +477,6 @@ fn thin_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             ThinLTOImports::default()\n         };\n         info!(\"thin LTO import map loaded\");\n-        timeline.record(\"import-map-loaded\");\n \n         let data = ThinData(data);\n \n@@ -691,7 +681,6 @@ impl Drop for ThinBuffer {\n pub unsafe fn optimize_thin_module(\n     thin_module: &mut ThinModule<LlvmCodegenBackend>,\n     cgcx: &CodegenContext<LlvmCodegenBackend>,\n-    timeline: &mut Timeline\n ) -> Result<ModuleCodegen<ModuleLlvm>, FatalError> {\n     let diag_handler = cgcx.create_diag_handler();\n     let tm = (cgcx.tm_factory.0)().map_err(|e| {\n@@ -738,9 +727,10 @@ pub unsafe fn optimize_thin_module(\n         // Like with \"fat\" LTO, get some better optimizations if landing pads\n         // are disabled by removing all landing pads.\n         if cgcx.no_landing_pads {\n+            let _timer = cgcx.profile_activity(ProfileCategory::Codegen,\n+                                               \"LLVM_remove_landing_pads\");\n             llvm::LLVMRustMarkAllFunctionsNounwind(llmod);\n             save_temp_bitcode(&cgcx, &module, \"thin-lto-after-nounwind\");\n-            timeline.record(\"nounwind\");\n         }\n \n         // Up next comes the per-module local analyses that we do for Thin LTO.\n@@ -756,25 +746,21 @@ pub unsafe fn optimize_thin_module(\n             return Err(write::llvm_err(&diag_handler, msg))\n         }\n         save_temp_bitcode(cgcx, &module, \"thin-lto-after-rename\");\n-        timeline.record(\"rename\");\n         if !llvm::LLVMRustPrepareThinLTOResolveWeak(thin_module.shared.data.0, llmod) {\n             let msg = \"failed to prepare thin LTO module\";\n             return Err(write::llvm_err(&diag_handler, msg))\n         }\n         save_temp_bitcode(cgcx, &module, \"thin-lto-after-resolve\");\n-        timeline.record(\"resolve\");\n         if !llvm::LLVMRustPrepareThinLTOInternalize(thin_module.shared.data.0, llmod) {\n             let msg = \"failed to prepare thin LTO module\";\n             return Err(write::llvm_err(&diag_handler, msg))\n         }\n         save_temp_bitcode(cgcx, &module, \"thin-lto-after-internalize\");\n-        timeline.record(\"internalize\");\n         if !llvm::LLVMRustPrepareThinLTOImport(thin_module.shared.data.0, llmod) {\n             let msg = \"failed to prepare thin LTO module\";\n             return Err(write::llvm_err(&diag_handler, msg))\n         }\n         save_temp_bitcode(cgcx, &module, \"thin-lto-after-import\");\n-        timeline.record(\"import\");\n \n         // Ok now this is a bit unfortunate. This is also something you won't\n         // find upstream in LLVM's ThinLTO passes! This is a hack for now to\n@@ -807,7 +793,6 @@ pub unsafe fn optimize_thin_module(\n         // fixed in LLVM.\n         llvm::LLVMRustThinLTOPatchDICompileUnit(llmod, cu1);\n         save_temp_bitcode(cgcx, &module, \"thin-lto-after-patch\");\n-        timeline.record(\"patch\");\n \n         // Alright now that we've done everything related to the ThinLTO\n         // analysis it's time to run some optimizations! Here we use the same\n@@ -818,7 +803,6 @@ pub unsafe fn optimize_thin_module(\n         let config = cgcx.config(module.kind);\n         run_pass_manager(cgcx, &module, config, true);\n         save_temp_bitcode(cgcx, &module, \"thin-lto-after-pm\");\n-        timeline.record(\"thin-done\");\n     }\n     Ok(module)\n }"}, {"sha": "dc4dd4e39e17b502da7a0213e9ef92dceb03d150", "filename": "src/librustc_codegen_llvm/back/write.rs", "status": "modified", "additions": 31, "deletions": 27, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -3,7 +3,6 @@ use crate::back::bytecode::{self, RLIB_BYTECODE_EXTENSION};\n use crate::back::lto::ThinBuffer;\n use crate::base;\n use crate::consts;\n-use crate::time_graph::Timeline;\n use crate::llvm::{self, DiagnosticInfo, PassManager, SMDiagnostic};\n use crate::llvm_util;\n use crate::ModuleLlvm;\n@@ -19,6 +18,7 @@ use rustc::session::Session;\n use rustc::ty::TyCtxt;\n use rustc_codegen_ssa::{ModuleCodegen, CompiledModule};\n use rustc::util::common::time_ext;\n+use rustc::util::profiling::ProfileCategory;\n use rustc_fs_util::{path_to_c_string, link_or_copy};\n use rustc_data_structures::small_c_str::SmallCStr;\n use errors::{Handler, FatalError};\n@@ -305,8 +305,7 @@ unsafe extern \"C\" fn diagnostic_handler(info: &DiagnosticInfo, user: *mut c_void\n pub(crate) unsafe fn optimize(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                    diag_handler: &Handler,\n                    module: &ModuleCodegen<ModuleLlvm>,\n-                   config: &ModuleConfig,\n-                   timeline: &mut Timeline)\n+                   config: &ModuleConfig)\n     -> Result<(), FatalError>\n {\n     let llmod = module.module_llvm.llmod();\n@@ -415,19 +414,24 @@ pub(crate) unsafe fn optimize(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         diag_handler.abort_if_errors();\n \n         // Finally, run the actual optimization passes\n-        time_ext(config.time_passes,\n-                 None,\n-                 &format!(\"llvm function passes [{}]\", module_name.unwrap()),\n-                 || {\n-            llvm::LLVMRustRunFunctionPassManager(fpm, llmod)\n-        });\n-        timeline.record(\"fpm\");\n-        time_ext(config.time_passes,\n-                 None,\n-                 &format!(\"llvm module passes [{}]\", module_name.unwrap()),\n-                 || {\n-            llvm::LLVMRunPassManager(mpm, llmod)\n-        });\n+        {\n+            let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_function_passes\");\n+            time_ext(config.time_passes,\n+                        None,\n+                        &format!(\"llvm function passes [{}]\", module_name.unwrap()),\n+                        || {\n+                llvm::LLVMRustRunFunctionPassManager(fpm, llmod)\n+            });\n+        }\n+        {\n+            let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_module_passes\");\n+            time_ext(config.time_passes,\n+                    None,\n+                    &format!(\"llvm module passes [{}]\", module_name.unwrap()),\n+                    || {\n+                llvm::LLVMRunPassManager(mpm, llmod)\n+            });\n+        }\n \n         // Deallocate managers that we're now done with\n         llvm::LLVMDisposePassManager(fpm);\n@@ -439,11 +443,10 @@ pub(crate) unsafe fn optimize(cgcx: &CodegenContext<LlvmCodegenBackend>,\n pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                   diag_handler: &Handler,\n                   module: ModuleCodegen<ModuleLlvm>,\n-                  config: &ModuleConfig,\n-                  timeline: &mut Timeline)\n+                  config: &ModuleConfig)\n     -> Result<CompiledModule, FatalError>\n {\n-    timeline.record(\"codegen\");\n+    let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"codegen\");\n     {\n         let llmod = module.module_llvm.llmod();\n         let llcx = &*module.module_llvm.llcx;\n@@ -494,29 +497,30 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n \n \n         if write_bc || config.emit_bc_compressed || config.embed_bitcode {\n+            let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_make_bitcode\");\n             let thin = ThinBuffer::new(llmod);\n             let data = thin.data();\n-            timeline.record(\"make-bc\");\n \n             if write_bc {\n+                let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_emit_bitcode\");\n                 if let Err(e) = fs::write(&bc_out, data) {\n                     diag_handler.err(&format!(\"failed to write bytecode: {}\", e));\n                 }\n-                timeline.record(\"write-bc\");\n             }\n \n             if config.embed_bitcode {\n+                let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_embed_bitcode\");\n                 embed_bitcode(cgcx, llcx, llmod, Some(data));\n-                timeline.record(\"embed-bc\");\n             }\n \n             if config.emit_bc_compressed {\n+                let _timer = cgcx.profile_activity(ProfileCategory::Codegen,\n+                                                   \"LLVM_compress_bitcode\");\n                 let dst = bc_out.with_extension(RLIB_BYTECODE_EXTENSION);\n                 let data = bytecode::encode(&module.name, data);\n                 if let Err(e) = fs::write(&dst, data) {\n                     diag_handler.err(&format!(\"failed to write bytecode: {}\", e));\n                 }\n-                timeline.record(\"compress-bc\");\n             }\n         } else if config.embed_bitcode_marker {\n             embed_bitcode(cgcx, llcx, llmod, None);\n@@ -525,6 +529,7 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         time_ext(config.time_passes, None, &format!(\"codegen passes [{}]\", module_name.unwrap()),\n             || -> Result<(), FatalError> {\n             if config.emit_ir {\n+                let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_emit_ir\");\n                 let out = cgcx.output_filenames.temp_path(OutputType::LlvmAssembly, module_name);\n                 let out = path_to_c_string(&out);\n \n@@ -563,10 +568,10 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                     llvm::LLVMRustPrintModule(cpm, llmod, out.as_ptr(), demangle_callback);\n                     llvm::LLVMDisposePassManager(cpm);\n                 });\n-                timeline.record(\"ir\");\n             }\n \n             if config.emit_asm || asm_to_obj {\n+                let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_emit_asm\");\n                 let path = cgcx.output_filenames.temp_path(OutputType::Assembly, module_name);\n \n                 // We can't use the same module for asm and binary output, because that triggers\n@@ -581,19 +586,18 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                     write_output_file(diag_handler, tm, cpm, llmod, &path,\n                                       llvm::FileType::AssemblyFile)\n                 })?;\n-                timeline.record(\"asm\");\n             }\n \n             if write_obj {\n+                let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_emit_obj\");\n                 with_codegen(tm, llmod, config.no_builtins, |cpm| {\n                     write_output_file(diag_handler, tm, cpm, llmod, &obj_out,\n                                       llvm::FileType::ObjectFile)\n                 })?;\n-                timeline.record(\"obj\");\n             } else if asm_to_obj {\n+                let _timer = cgcx.profile_activity(ProfileCategory::Codegen, \"LLVM_asm_to_obj\");\n                 let assembly = cgcx.output_filenames.temp_path(OutputType::Assembly, module_name);\n                 run_assembler(cgcx, diag_handler, &assembly, &obj_out);\n-                timeline.record(\"asm_to_obj\");\n \n                 if !config.emit_asm && !cgcx.save_temps {\n                     drop(fs::remove_file(&assembly));"}, {"sha": "0a295c202e655418ed8fcb87d697dc941e63c0b2", "filename": "src/librustc_codegen_llvm/lib.rs", "status": "modified", "additions": 7, "deletions": 14, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_llvm%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_llvm%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Flib.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -53,7 +53,6 @@ use rustc_codegen_ssa::back::lto::{SerializedModule, LtoModuleCodegen, ThinModul\n use rustc_codegen_ssa::CompiledModule;\n use errors::{FatalError, Handler};\n use rustc::dep_graph::WorkProduct;\n-use rustc::util::time_graph::Timeline;\n use syntax_pos::symbol::InternedString;\n use rustc::mir::mono::Stats;\n pub use llvm_util::target_features;\n@@ -66,7 +65,6 @@ use rustc::middle::cstore::{EncodedMetadata, MetadataLoader};\n use rustc::session::Session;\n use rustc::session::config::{OutputFilenames, OutputType, PrintRequest, OptLevel};\n use rustc::ty::{self, TyCtxt};\n-use rustc::util::time_graph;\n use rustc::util::profiling::ProfileCategory;\n use rustc::util::common::ErrorReported;\n use rustc_mir::monomorphize;\n@@ -167,42 +165,37 @@ impl WriteBackendMethods for LlvmCodegenBackend {\n         cgcx: &CodegenContext<Self>,\n         modules: Vec<FatLTOInput<Self>>,\n         cached_modules: Vec<(SerializedModule<Self::ModuleBuffer>, WorkProduct)>,\n-        timeline: &mut Timeline\n     ) -> Result<LtoModuleCodegen<Self>, FatalError> {\n-        back::lto::run_fat(cgcx, modules, cached_modules, timeline)\n+        back::lto::run_fat(cgcx, modules, cached_modules)\n     }\n     fn run_thin_lto(\n         cgcx: &CodegenContext<Self>,\n         modules: Vec<(String, Self::ThinBuffer)>,\n         cached_modules: Vec<(SerializedModule<Self::ModuleBuffer>, WorkProduct)>,\n-        timeline: &mut Timeline\n     ) -> Result<(Vec<LtoModuleCodegen<Self>>, Vec<WorkProduct>), FatalError> {\n-        back::lto::run_thin(cgcx, modules, cached_modules, timeline)\n+        back::lto::run_thin(cgcx, modules, cached_modules)\n     }\n     unsafe fn optimize(\n         cgcx: &CodegenContext<Self>,\n         diag_handler: &Handler,\n         module: &ModuleCodegen<Self::Module>,\n         config: &ModuleConfig,\n-        timeline: &mut Timeline\n     ) -> Result<(), FatalError> {\n-        back::write::optimize(cgcx, diag_handler, module, config, timeline)\n+        back::write::optimize(cgcx, diag_handler, module, config)\n     }\n     unsafe fn optimize_thin(\n         cgcx: &CodegenContext<Self>,\n         thin: &mut ThinModule<Self>,\n-        timeline: &mut Timeline\n     ) -> Result<ModuleCodegen<Self::Module>, FatalError> {\n-        back::lto::optimize_thin_module(thin, cgcx, timeline)\n+        back::lto::optimize_thin_module(thin, cgcx)\n     }\n     unsafe fn codegen(\n         cgcx: &CodegenContext<Self>,\n         diag_handler: &Handler,\n         module: ModuleCodegen<Self::Module>,\n         config: &ModuleConfig,\n-        timeline: &mut Timeline\n     ) -> Result<CompiledModule, FatalError> {\n-        back::write::codegen(cgcx, diag_handler, module, config, timeline)\n+        back::write::codegen(cgcx, diag_handler, module, config)\n     }\n     fn prepare_thin(\n         module: ModuleCodegen<Self::Module>\n@@ -336,12 +329,12 @@ impl CodegenBackend for LlvmCodegenBackend {\n \n         // Run the linker on any artifacts that resulted from the LLVM run.\n         // This should produce either a finished executable or library.\n-        sess.profiler(|p| p.start_activity(ProfileCategory::Linking));\n+        sess.profiler(|p| p.start_activity(ProfileCategory::Linking, \"link_crate\"));\n         time(sess, \"linking\", || {\n             back::link::link_binary(sess, &codegen_results,\n                                     outputs, &codegen_results.crate_name.as_str());\n         });\n-        sess.profiler(|p| p.end_activity(ProfileCategory::Linking));\n+        sess.profiler(|p| p.end_activity(ProfileCategory::Linking, \"link_crate\"));\n \n         // Now that we won't touch anything in the incremental compilation directory\n         // any more, we can finalize it (which involves renaming it)"}, {"sha": "47e5d9af33ba40d2e9c39300ef30825ddbe178af", "filename": "src/librustc_codegen_ssa/back/lto.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_ssa%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_ssa%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Flto.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -2,7 +2,6 @@ use super::write::CodegenContext;\n use crate::traits::*;\n use crate::ModuleCodegen;\n \n-use rustc::util::time_graph::Timeline;\n use rustc_errors::FatalError;\n \n use std::sync::Arc;\n@@ -67,19 +66,17 @@ impl<B: WriteBackendMethods> LtoModuleCodegen<B> {\n     pub unsafe fn optimize(\n         &mut self,\n         cgcx: &CodegenContext<B>,\n-        timeline: &mut Timeline\n     ) -> Result<ModuleCodegen<B::Module>, FatalError> {\n         match *self {\n             LtoModuleCodegen::Fat { ref mut module, .. } => {\n                 let module = module.take().unwrap();\n                 {\n                     let config = cgcx.config(module.kind);\n                     B::run_lto_pass_manager(cgcx, &module, config, false);\n-                    timeline.record(\"fat-done\");\n                 }\n                 Ok(module)\n             }\n-            LtoModuleCodegen::Thin(ref mut thin) => B::optimize_thin(cgcx, thin, timeline),\n+            LtoModuleCodegen::Thin(ref mut thin) => B::optimize_thin(cgcx, thin),\n         }\n     }\n "}, {"sha": "859dfb99d92b8598306d5af13c6fdfef1c218ed8", "filename": "src/librustc_codegen_ssa/back/write.rs", "status": "modified", "additions": 65, "deletions": 48, "changes": 113, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -15,11 +15,10 @@ use rustc::middle::cstore::EncodedMetadata;\n use rustc::session::config::{self, OutputFilenames, OutputType, Passes, Sanitizer, Lto};\n use rustc::session::Session;\n use rustc::util::nodemap::FxHashMap;\n-use rustc::util::time_graph::{self, TimeGraph, Timeline};\n use rustc::hir::def_id::{CrateNum, LOCAL_CRATE};\n use rustc::ty::TyCtxt;\n use rustc::util::common::{time_depth, set_time_depth, print_time_passes_entry};\n-use rustc::util::profiling::SelfProfiler;\n+use rustc::util::profiling::{ProfileCategory, SelfProfiler};\n use rustc_fs_util::link_or_copy;\n use rustc_data_structures::svh::Svh;\n use rustc_errors::{Handler, Level, DiagnosticBuilder, FatalError, DiagnosticId};\n@@ -33,6 +32,7 @@ use jobserver::{Client, Acquired};\n use parking_lot::Mutex as PlMutex;\n \n use std::any::Any;\n+use std::borrow::Cow;\n use std::fs;\n use std::io;\n use std::mem;\n@@ -197,6 +197,40 @@ impl<B: WriteBackendMethods> Clone for TargetMachineFactory<B> {\n     }\n }\n \n+pub struct ProfileGenericActivityTimer {\n+    profiler: Option<Arc<PlMutex<SelfProfiler>>>,\n+    category: ProfileCategory,\n+    label: Cow<'static, str>,\n+}\n+\n+impl ProfileGenericActivityTimer {\n+    pub fn start(\n+        profiler: Option<Arc<PlMutex<SelfProfiler>>>,\n+        category: ProfileCategory,\n+        label: Cow<'static, str>,\n+    ) -> ProfileGenericActivityTimer {\n+        if let Some(profiler) = &profiler {\n+            let mut p = profiler.lock();\n+            p.start_activity(category, label.clone());\n+        }\n+\n+        ProfileGenericActivityTimer {\n+            profiler,\n+            category,\n+            label,\n+        }\n+    }\n+}\n+\n+impl Drop for ProfileGenericActivityTimer {\n+    fn drop(&mut self) {\n+        if let Some(profiler) = &self.profiler {\n+            let mut p = profiler.lock();\n+            p.end_activity(self.category, self.label.clone());\n+        }\n+    }\n+}\n+\n /// Additional resources used by optimize_and_codegen (not module specific)\n #[derive(Clone)]\n pub struct CodegenContext<B: WriteBackendMethods> {\n@@ -238,9 +272,6 @@ pub struct CodegenContext<B: WriteBackendMethods> {\n     pub cgu_reuse_tracker: CguReuseTracker,\n     // Channel back to the main control thread to send messages to\n     pub coordinator_send: Sender<Box<dyn Any + Send>>,\n-    // A reference to the TimeGraph so we can register timings. None means that\n-    // measuring is disabled.\n-    pub time_graph: Option<TimeGraph>,\n     // The assembler command if no_integrated_as option is enabled, None otherwise\n     pub assembler_cmd: Option<Arc<AssemblerCommand>>\n }\n@@ -277,6 +308,14 @@ impl<B: WriteBackendMethods> CodegenContext<B> {\n             self.profiler_active(f)\n         }\n     }\n+\n+    pub fn profile_activity(\n+        &self,\n+        category: ProfileCategory,\n+        label: impl Into<Cow<'static, str>>,\n+    ) -> ProfileGenericActivityTimer {\n+        ProfileGenericActivityTimer::start(self.profiler.clone(), category, label.into())\n+    }\n }\n \n fn generate_lto_work<B: ExtraBackendMethods>(\n@@ -285,37 +324,36 @@ fn generate_lto_work<B: ExtraBackendMethods>(\n     needs_thin_lto: Vec<(String, B::ThinBuffer)>,\n     import_only_modules: Vec<(SerializedModule<B::ModuleBuffer>, WorkProduct)>\n ) -> Vec<(WorkItem<B>, u64)> {\n-    let mut timeline = cgcx.time_graph.as_ref().map(|tg| {\n-        tg.start(CODEGEN_WORKER_TIMELINE,\n-                 CODEGEN_WORK_PACKAGE_KIND,\n-                 \"generate lto\")\n-    }).unwrap_or(Timeline::noop());\n+    cgcx.profile(|p| p.start_activity(ProfileCategory::Linking, \"codegen_run_lto\"));\n \n     let (lto_modules, copy_jobs) = if !needs_fat_lto.is_empty() {\n         assert!(needs_thin_lto.is_empty());\n         let lto_module = B::run_fat_lto(\n             cgcx,\n             needs_fat_lto,\n             import_only_modules,\n-            &mut timeline,\n         )\n         .unwrap_or_else(|e| e.raise());\n         (vec![lto_module], vec![])\n     } else {\n         assert!(needs_fat_lto.is_empty());\n-        B::run_thin_lto(cgcx, needs_thin_lto, import_only_modules, &mut timeline)\n+        B::run_thin_lto(cgcx, needs_thin_lto, import_only_modules)\n             .unwrap_or_else(|e| e.raise())\n     };\n \n-    lto_modules.into_iter().map(|module| {\n+    let result = lto_modules.into_iter().map(|module| {\n         let cost = module.cost();\n         (WorkItem::LTO(module), cost)\n     }).chain(copy_jobs.into_iter().map(|wp| {\n         (WorkItem::CopyPostLtoArtifacts(CachedModuleCodegen {\n             name: wp.cgu_name.clone(),\n             source: wp,\n         }), 0)\n-    })).collect()\n+    })).collect();\n+\n+    cgcx.profile(|p| p.end_activity(ProfileCategory::Linking, \"codegen_run_lto\"));\n+\n+    result\n }\n \n pub struct CompiledModules {\n@@ -345,7 +383,6 @@ fn need_pre_lto_bitcode_for_incr_comp(sess: &Session) -> bool {\n pub fn start_async_codegen<B: ExtraBackendMethods>(\n     backend: B,\n     tcx: TyCtxt<'_, '_, '_>,\n-    time_graph: Option<TimeGraph>,\n     metadata: EncodedMetadata,\n     coordinator_receive: Receiver<Box<dyn Any + Send>>,\n     total_cgus: usize\n@@ -469,7 +506,6 @@ pub fn start_async_codegen<B: ExtraBackendMethods>(\n                                                   coordinator_receive,\n                                                   total_cgus,\n                                                   sess.jobserver.clone(),\n-                                                  time_graph.clone(),\n                                                   Arc::new(modules_config),\n                                                   Arc::new(metadata_config),\n                                                   Arc::new(allocator_config));\n@@ -483,7 +519,6 @@ pub fn start_async_codegen<B: ExtraBackendMethods>(\n         linker_info,\n         crate_info,\n \n-        time_graph,\n         coordinator_send: tcx.tx_to_llvm_workers.lock().clone(),\n         codegen_worker_receive,\n         shared_emitter_main,\n@@ -728,19 +763,18 @@ pub enum FatLTOInput<B: WriteBackendMethods> {\n fn execute_work_item<B: ExtraBackendMethods>(\n     cgcx: &CodegenContext<B>,\n     work_item: WorkItem<B>,\n-    timeline: &mut Timeline\n ) -> Result<WorkItemResult<B>, FatalError> {\n     let module_config = cgcx.config(work_item.module_kind());\n \n     match work_item {\n         WorkItem::Optimize(module) => {\n-            execute_optimize_work_item(cgcx, module, module_config, timeline)\n+            execute_optimize_work_item(cgcx, module, module_config)\n         }\n         WorkItem::CopyPostLtoArtifacts(module) => {\n-            execute_copy_from_cache_work_item(cgcx, module, module_config, timeline)\n+            execute_copy_from_cache_work_item(cgcx, module, module_config)\n         }\n         WorkItem::LTO(module) => {\n-            execute_lto_work_item(cgcx, module, module_config, timeline)\n+            execute_lto_work_item(cgcx, module, module_config)\n         }\n     }\n }\n@@ -756,12 +790,11 @@ fn execute_optimize_work_item<B: ExtraBackendMethods>(\n     cgcx: &CodegenContext<B>,\n     module: ModuleCodegen<B::Module>,\n     module_config: &ModuleConfig,\n-    timeline: &mut Timeline\n ) -> Result<WorkItemResult<B>, FatalError> {\n     let diag_handler = cgcx.create_diag_handler();\n \n     unsafe {\n-        B::optimize(cgcx, &diag_handler, &module, module_config, timeline)?;\n+        B::optimize(cgcx, &diag_handler, &module, module_config)?;\n     }\n \n     // After we've done the initial round of optimizations we need to\n@@ -818,7 +851,7 @@ fn execute_optimize_work_item<B: ExtraBackendMethods>(\n     Ok(match lto_type {\n         ComputedLtoType::No => {\n             let module = unsafe {\n-                B::codegen(cgcx, &diag_handler, module, module_config, timeline)?\n+                B::codegen(cgcx, &diag_handler, module, module_config)?\n             };\n             WorkItemResult::Compiled(module)\n         }\n@@ -854,7 +887,6 @@ fn execute_copy_from_cache_work_item<B: ExtraBackendMethods>(\n     cgcx: &CodegenContext<B>,\n     module: CachedModuleCodegen,\n     module_config: &ModuleConfig,\n-    _: &mut Timeline\n ) -> Result<WorkItemResult<B>, FatalError> {\n     let incr_comp_session_dir = cgcx.incr_comp_session_dir\n                                     .as_ref()\n@@ -916,13 +948,12 @@ fn execute_lto_work_item<B: ExtraBackendMethods>(\n     cgcx: &CodegenContext<B>,\n     mut module: lto::LtoModuleCodegen<B>,\n     module_config: &ModuleConfig,\n-    timeline: &mut Timeline\n ) -> Result<WorkItemResult<B>, FatalError> {\n     let diag_handler = cgcx.create_diag_handler();\n \n     unsafe {\n-        let module = module.optimize(cgcx, timeline)?;\n-        let module = B::codegen(cgcx, &diag_handler, module, module_config, timeline)?;\n+        let module = module.optimize(cgcx)?;\n+        let module = B::codegen(cgcx, &diag_handler, module, module_config)?;\n         Ok(WorkItemResult::Compiled(module))\n     }\n }\n@@ -977,7 +1008,6 @@ fn start_executing_work<B: ExtraBackendMethods>(\n     coordinator_receive: Receiver<Box<dyn Any + Send>>,\n     total_cgus: usize,\n     jobserver: Client,\n-    time_graph: Option<TimeGraph>,\n     modules_config: Arc<ModuleConfig>,\n     metadata_config: Arc<ModuleConfig>,\n     allocator_config: Arc<ModuleConfig>\n@@ -1065,7 +1095,6 @@ fn start_executing_work<B: ExtraBackendMethods>(\n         cgu_reuse_tracker: sess.cgu_reuse_tracker.clone(),\n         coordinator_send,\n         diag_emitter: shared_emitter.clone(),\n-        time_graph,\n         output_filenames: tcx.output_filenames(LOCAL_CRATE),\n         regular_module_config: modules_config,\n         metadata_module_config: metadata_config,\n@@ -1570,12 +1599,6 @@ fn start_executing_work<B: ExtraBackendMethods>(\n }\n \n pub const CODEGEN_WORKER_ID: usize = ::std::usize::MAX;\n-pub const CODEGEN_WORKER_TIMELINE: time_graph::TimelineId =\n-    time_graph::TimelineId(CODEGEN_WORKER_ID);\n-pub const CODEGEN_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n-    time_graph::WorkPackageKind(&[\"#DE9597\", \"#FED1D3\", \"#FDC5C7\", \"#B46668\", \"#88494B\"]);\n-const LLVM_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n-    time_graph::WorkPackageKind(&[\"#7DB67A\", \"#C6EEC4\", \"#ACDAAA\", \"#579354\", \"#3E6F3C\"]);\n \n fn spawn_work<B: ExtraBackendMethods>(\n     cgcx: CodegenContext<B>,\n@@ -1625,13 +1648,12 @@ fn spawn_work<B: ExtraBackendMethods>(\n         // as a diagnostic was already sent off to the main thread - just\n         // surface that there was an error in this worker.\n         bomb.result = {\n-            let timeline = cgcx.time_graph.as_ref().map(|tg| {\n-                tg.start(time_graph::TimelineId(cgcx.worker),\n-                         LLVM_WORK_PACKAGE_KIND,\n-                         &work.name())\n-            });\n-            let mut timeline = timeline.unwrap_or(Timeline::noop());\n-            execute_work_item(&cgcx, work, &mut timeline).ok()\n+            let label = work.name();\n+            cgcx.profile(|p| p.start_activity(ProfileCategory::Codegen, label.clone()));\n+            let result = execute_work_item(&cgcx, work).ok();\n+            cgcx.profile(|p| p.end_activity(ProfileCategory::Codegen, label));\n+\n+            result\n         };\n     });\n }\n@@ -1785,7 +1807,6 @@ pub struct OngoingCodegen<B: ExtraBackendMethods> {\n     pub windows_subsystem: Option<String>,\n     pub linker_info: LinkerInfo,\n     pub crate_info: CrateInfo,\n-    pub time_graph: Option<TimeGraph>,\n     pub coordinator_send: Sender<Box<dyn Any + Send>>,\n     pub codegen_worker_receive: Receiver<Message<B>>,\n     pub shared_emitter_main: SharedEmitterMain,\n@@ -1814,10 +1835,6 @@ impl<B: ExtraBackendMethods> OngoingCodegen<B> {\n \n         sess.abort_if_errors();\n \n-        if let Some(time_graph) = self.time_graph {\n-            time_graph.dump(&format!(\"{}-timings\", self.crate_name));\n-        }\n-\n         let work_products =\n             copy_all_cgu_workproducts_to_incr_comp_cache_dir(sess,\n                                                              &compiled_modules);"}, {"sha": "48743be3a2551375d48fe74ae674c6306265a949", "filename": "src/librustc_codegen_ssa/base.rs", "status": "modified", "additions": 6, "deletions": 21, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_ssa%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_ssa%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fbase.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -29,7 +29,6 @@ use rustc::util::profiling::ProfileCategory;\n use rustc::session::config::{self, EntryFnType, Lto};\n use rustc::session::Session;\n use rustc_mir::monomorphize::item::DefPathBasedNames;\n-use rustc::util::time_graph;\n use rustc_mir::monomorphize::Instance;\n use rustc_mir::monomorphize::partitioning::{CodegenUnit, CodegenUnitExt};\n use rustc::util::nodemap::FxHashMap;\n@@ -528,11 +527,6 @@ pub fn maybe_create_entry_wrapper<'a, 'tcx: 'a, Bx: BuilderMethods<'a, 'tcx>>(\n }\n \n pub const CODEGEN_WORKER_ID: usize = ::std::usize::MAX;\n-pub const CODEGEN_WORKER_TIMELINE: time_graph::TimelineId =\n-    time_graph::TimelineId(CODEGEN_WORKER_ID);\n-pub const CODEGEN_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n-    time_graph::WorkPackageKind(&[\"#DE9597\", \"#FED1D3\", \"#FDC5C7\", \"#B46668\", \"#88494B\"]);\n-\n \n pub fn codegen_crate<B: ExtraBackendMethods>(\n     backend: B,\n@@ -545,7 +539,7 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n     let cgu_name_builder = &mut CodegenUnitNameBuilder::new(tcx);\n \n     // Codegen the metadata.\n-    tcx.sess.profiler(|p| p.start_activity(ProfileCategory::Codegen));\n+    tcx.sess.profiler(|p| p.start_activity(ProfileCategory::Codegen, \"codegen crate metadata\"));\n \n     let metadata_cgu_name = cgu_name_builder.build_cgu_name(LOCAL_CRATE,\n                                                             &[\"crate\"],\n@@ -555,27 +549,20 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n     let metadata = time(tcx.sess, \"write metadata\", || {\n         backend.write_metadata(tcx, &mut metadata_llvm_module)\n     });\n-    tcx.sess.profiler(|p| p.end_activity(ProfileCategory::Codegen));\n+    tcx.sess.profiler(|p| p.end_activity(ProfileCategory::Codegen, \"codegen crate metadata\"));\n \n     let metadata_module = ModuleCodegen {\n         name: metadata_cgu_name,\n         module_llvm: metadata_llvm_module,\n         kind: ModuleKind::Metadata,\n     };\n \n-    let time_graph = if tcx.sess.opts.debugging_opts.codegen_time_graph {\n-        Some(time_graph::TimeGraph::new())\n-    } else {\n-        None\n-    };\n-\n     // Skip crate items and just output metadata in -Z no-codegen mode.\n     if tcx.sess.opts.debugging_opts.no_codegen ||\n        !tcx.sess.opts.output_types.should_codegen() {\n         let ongoing_codegen = start_async_codegen(\n             backend,\n             tcx,\n-            time_graph,\n             metadata,\n             rx,\n             1);\n@@ -609,7 +596,6 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n     let ongoing_codegen = start_async_codegen(\n         backend.clone(),\n         tcx,\n-        time_graph.clone(),\n         metadata,\n         rx,\n         codegen_units.len());\n@@ -676,15 +662,14 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n \n         match cgu_reuse {\n             CguReuse::No => {\n-                let _timing_guard = time_graph.as_ref().map(|time_graph| {\n-                    time_graph.start(CODEGEN_WORKER_TIMELINE,\n-                                     CODEGEN_WORK_PACKAGE_KIND,\n-                                     &format!(\"codegen {}\", cgu.name()))\n-                });\n+                tcx.sess.profiler(|p| p.start_activity(ProfileCategory::Codegen,\n+                                                       format!(\"codegen {}\", cgu.name())));\n                 let start_time = Instant::now();\n                 let stats = backend.compile_codegen_unit(tcx, *cgu.name());\n                 all_stats.extend(stats);\n                 total_codegen_time += start_time.elapsed();\n+                tcx.sess.profiler(|p| p.end_activity(ProfileCategory::Codegen,\n+                                                     format!(\"codegen {}\", cgu.name())));\n                 false\n             }\n             CguReuse::PreLto => {"}, {"sha": "23bb7179557b910540b148dbaad92e497fa6af21", "filename": "src/librustc_codegen_ssa/traits/write.rs", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_ssa%2Ftraits%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_codegen_ssa%2Ftraits%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Ftraits%2Fwrite.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -3,7 +3,6 @@ use crate::back::write::{CodegenContext, ModuleConfig, FatLTOInput};\n use crate::{CompiledModule, ModuleCodegen};\n \n use rustc::dep_graph::WorkProduct;\n-use rustc::util::time_graph::Timeline;\n use rustc_errors::{FatalError, Handler};\n \n pub trait WriteBackendMethods: 'static + Sized + Clone {\n@@ -20,7 +19,6 @@ pub trait WriteBackendMethods: 'static + Sized + Clone {\n         cgcx: &CodegenContext<Self>,\n         modules: Vec<FatLTOInput<Self>>,\n         cached_modules: Vec<(SerializedModule<Self::ModuleBuffer>, WorkProduct)>,\n-        timeline: &mut Timeline,\n     ) -> Result<LtoModuleCodegen<Self>, FatalError>;\n     /// Performs thin LTO by performing necessary global analysis and returning two\n     /// lists, one of the modules that need optimization and another for modules that\n@@ -29,27 +27,23 @@ pub trait WriteBackendMethods: 'static + Sized + Clone {\n         cgcx: &CodegenContext<Self>,\n         modules: Vec<(String, Self::ThinBuffer)>,\n         cached_modules: Vec<(SerializedModule<Self::ModuleBuffer>, WorkProduct)>,\n-        timeline: &mut Timeline,\n     ) -> Result<(Vec<LtoModuleCodegen<Self>>, Vec<WorkProduct>), FatalError>;\n     fn print_pass_timings(&self);\n     unsafe fn optimize(\n         cgcx: &CodegenContext<Self>,\n         diag_handler: &Handler,\n         module: &ModuleCodegen<Self::Module>,\n         config: &ModuleConfig,\n-        timeline: &mut Timeline,\n     ) -> Result<(), FatalError>;\n     unsafe fn optimize_thin(\n         cgcx: &CodegenContext<Self>,\n         thin: &mut ThinModule<Self>,\n-        timeline: &mut Timeline,\n     ) -> Result<ModuleCodegen<Self::Module>, FatalError>;\n     unsafe fn codegen(\n         cgcx: &CodegenContext<Self>,\n         diag_handler: &Handler,\n         module: ModuleCodegen<Self::Module>,\n         config: &ModuleConfig,\n-        timeline: &mut Timeline,\n     ) -> Result<CompiledModule, FatalError>;\n     fn prepare_thin(\n         module: ModuleCodegen<Self::Module>"}, {"sha": "5bb47bda17b330902442dd3735d8ea326d4ed813", "filename": "src/librustc_interface/passes.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_interface%2Fpasses.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_interface%2Fpasses.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Fpasses.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -67,15 +67,15 @@ pub fn parse<'a>(sess: &'a Session, input: &Input) -> PResult<'a, ast::Crate> {\n         .set_continue_after_error(sess.opts.debugging_opts.continue_parse_after_error);\n     hygiene::set_default_edition(sess.edition());\n \n-    sess.profiler(|p| p.start_activity(ProfileCategory::Parsing));\n+    sess.profiler(|p| p.start_activity(ProfileCategory::Parsing, \"parsing\"));\n     let krate = time(sess, \"parsing\", || match *input {\n         Input::File(ref file) => parse::parse_crate_from_file(file, &sess.parse_sess),\n         Input::Str {\n             ref input,\n             ref name,\n         } => parse::parse_crate_from_source_str(name.clone(), input.clone(), &sess.parse_sess),\n     })?;\n-    sess.profiler(|p| p.end_activity(ProfileCategory::Parsing));\n+    sess.profiler(|p| p.end_activity(ProfileCategory::Parsing, \"parsing\"));\n \n     sess.diagnostic().set_continue_after_error(true);\n \n@@ -374,7 +374,7 @@ fn configure_and_expand_inner<'a>(\n     syntax_ext::register_builtins(&mut resolver, plugin_info.syntax_exts);\n \n     // Expand all macros\n-    sess.profiler(|p| p.start_activity(ProfileCategory::Expansion));\n+    sess.profiler(|p| p.start_activity(ProfileCategory::Expansion, \"macro expansion\"));\n     krate = time(sess, \"expansion\", || {\n         // Windows dlls do not have rpaths, so they don't know how to find their\n         // dependencies. It's up to us to tell the system where to find all the\n@@ -449,7 +449,7 @@ fn configure_and_expand_inner<'a>(\n         }\n         krate\n     });\n-    sess.profiler(|p| p.end_activity(ProfileCategory::Expansion));\n+    sess.profiler(|p| p.end_activity(ProfileCategory::Expansion, \"macro expansion\"));\n \n     time(sess, \"maybe building test harness\", || {\n         syntax::test::modify_for_testing(\n@@ -1018,9 +1018,9 @@ pub fn start_codegen<'tcx>(\n         ::rustc::middle::dependency_format::calculate(tcx)\n     });\n \n-    tcx.sess.profiler(|p| p.start_activity(ProfileCategory::Codegen));\n+    tcx.sess.profiler(|p| p.start_activity(ProfileCategory::Codegen, \"codegen crate\"));\n     let codegen = time(tcx.sess, \"codegen\", move || codegen_backend.codegen_crate(tcx, rx));\n-    tcx.sess.profiler(|p| p.end_activity(ProfileCategory::Codegen));\n+    tcx.sess.profiler(|p| p.end_activity(ProfileCategory::Codegen, \"codegen crate\"));\n \n     if log_enabled!(::log::Level::Info) {\n         println!(\"Post-codegen\");"}, {"sha": "cbed7d26a9950b413a68448e16c37179d05efe4a", "filename": "src/librustc_typeck/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_typeck%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c8cc141863274683681a6fa3d5d4e0230780c66/src%2Flibrustc_typeck%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Flib.rs?ref=4c8cc141863274683681a6fa3d5d4e0230780c66", "patch": "@@ -317,7 +317,7 @@ pub fn provide(providers: &mut Providers<'_>) {\n pub fn check_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>)\n                              -> Result<(), ErrorReported>\n {\n-    tcx.sess.profiler(|p| p.start_activity(ProfileCategory::TypeChecking));\n+    tcx.sess.profiler(|p| p.start_activity(ProfileCategory::TypeChecking, \"type-check crate\"));\n \n     // this ensures that later parts of type checking can assume that items\n     // have valid types and not error\n@@ -368,7 +368,7 @@ pub fn check_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>)\n     check_unused::check_crate(tcx);\n     check_for_entry_fn(tcx);\n \n-    tcx.sess.profiler(|p| p.end_activity(ProfileCategory::TypeChecking));\n+    tcx.sess.profiler(|p| p.end_activity(ProfileCategory::TypeChecking, \"type-check crate\"));\n \n     if tcx.sess.err_count() == 0 {\n         Ok(())"}]}