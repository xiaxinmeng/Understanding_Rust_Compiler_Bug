{"sha": "2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI2OTdlY2FhNjQ1NzA4NDFmMGVkMmEzY2E1YmMwMmNmNDFkY2NjNGE=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-08T07:58:02Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-08T07:58:02Z"}, "message": "Use SubtreeWalker instread of flatten TtToken", "tree": {"sha": "4d1e37b88e7322abc247cf42915714cee91a5a7e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4d1e37b88e7322abc247cf42915714cee91a5a7e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a", "html_url": "https://github.com/rust-lang/rust/commit/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a7254201df07fb929ca689857d7472564d484c3e", "url": "https://api.github.com/repos/rust-lang/rust/commits/a7254201df07fb929ca689857d7472564d484c3e", "html_url": "https://github.com/rust-lang/rust/commit/a7254201df07fb929ca689857d7472564d484c3e"}], "stats": {"total": 679, "additions": 421, "deletions": 258}, "files": [{"sha": "a21ea4dbcbda4a94ea007841536f30bfba5f3d88", "filename": "crates/ra_mbe/src/lib.rs", "status": "modified", "additions": 31, "deletions": 3, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/crates%2Fra_mbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/crates%2Fra_mbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Flib.rs?ref=2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a", "patch": "@@ -383,8 +383,22 @@ SOURCE_FILE@[0; 40)\n         assert_eq!(to_literal(&stm_tokens[15 + 3]).text, \"\\\"rust1\\\"\");\n     }\n \n-    /// The following tests are port from intellij-rust directly\n-    /// https://github.com/intellij-rust/intellij-rust/blob/c4e9feee4ad46e7953b1948c112533360b6087bb/src/test/kotlin/org/rust/lang/core/macros/RsMacroExpansionTest.kt\n+    #[test]\n+    fn test_two_idents() {\n+        let rules = create_rules(\n+            r#\"\n+        macro_rules! foo {\n+            ($ i:ident, $ j:ident) => {\n+                fn foo() { let a = $ i; let b = $j; }\n+            }\n+        }\n+\"#,\n+        );\n+        assert_expansion(&rules, \"foo! { foo, bar }\", \"fn foo () {let a = foo ; let b = bar ;}\");\n+    }\n+\n+    // The following tests are port from intellij-rust directly\n+    // https://github.com/intellij-rust/intellij-rust/blob/c4e9feee4ad46e7953b1948c112533360b6087bb/src/test/kotlin/org/rust/lang/core/macros/RsMacroExpansionTest.kt\n \n     #[test]\n     fn test_path() {\n@@ -401,7 +415,21 @@ SOURCE_FILE@[0; 40)\n         assert_expansion(\n             &rules,\n             \"foo! { bar::<u8>::baz::<u8> }\",\n-            \"fn foo () {let a = bar :: < u8 > :: baz :: < u8 > ;}\",\n+            \"fn foo () {let a = bar ::< u8 > ::baz ::< u8 > ;}\",\n+        );\n+    }\n+\n+    #[test]\n+    fn test_two_paths() {\n+        let rules = create_rules(\n+            r#\"\n+        macro_rules! foo {\n+            ($ i:path, $ j:path) => {\n+                fn foo() { let a = $ i; let b = $j; }\n+            }\n+        }\n+\"#,\n         );\n+        assert_expansion(&rules, \"foo! { foo, bar }\", \"fn foo () {let a = foo ; let b = bar ;}\");\n     }\n }"}, {"sha": "f198c8224c05650069004827696365ec039e7db6", "filename": "crates/ra_mbe/src/subtree_parser.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs?ref=2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a", "patch": "@@ -18,12 +18,12 @@ impl TreeSink for OffsetTokenSink {\n \n pub(crate) struct Parser<'a> {\n     subtree: &'a tt::Subtree,\n-    pos: &'a mut usize,\n+    cur_pos: &'a mut usize,\n }\n \n impl<'a> Parser<'a> {\n-    pub fn new(pos: &'a mut usize, subtree: &'a tt::Subtree) -> Parser<'a> {\n-        Parser { pos, subtree }\n+    pub fn new(cur_pos: &'a mut usize, subtree: &'a tt::Subtree) -> Parser<'a> {\n+        Parser { cur_pos, subtree }\n     }\n \n     pub fn parse_path(self) -> Option<tt::TokenTree> {\n@@ -35,7 +35,7 @@ impl<'a> Parser<'a> {\n         F: FnOnce(&dyn TokenSource, &mut dyn TreeSink),\n     {\n         let mut src = SubtreeTokenSource::new(self.subtree);\n-        src.advance(*self.pos, true);\n+        src.start_from_nth(*self.cur_pos);\n         let mut sink = OffsetTokenSink { token_pos: 0 };\n \n         f(&src, &mut sink);\n@@ -44,7 +44,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn finish(self, parsed_token: usize, src: &mut SubtreeTokenSource) -> Option<tt::TokenTree> {\n-        let res = src.bump_n(parsed_token, self.pos);\n+        let res = src.bump_n(parsed_token, self.cur_pos);\n         let res: Vec<_> = res.into_iter().cloned().collect();\n \n         match res.len() {"}, {"sha": "9dd475f2c284ca104a6413cec470b2fc7001f7c1", "filename": "crates/ra_mbe/src/subtree_source.rs", "status": "modified", "additions": 379, "deletions": 244, "changes": 623, "blob_url": "https://github.com/rust-lang/rust/blob/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs?ref=2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a", "patch": "@@ -1,115 +1,328 @@\n use ra_parser::{TokenSource};\n use ra_syntax::{classify_literal, SmolStr, SyntaxKind, SyntaxKind::*};\n+use std::cell::{RefCell};\n \n-#[derive(Debug)]\n+#[derive(Debug, Clone, Eq, PartialEq)]\n struct TtToken {\n     pub kind: SyntaxKind,\n     pub is_joint_to_next: bool,\n     pub text: SmolStr,\n     pub n_tokens: usize,\n }\n \n-/// Querier let outside to query internal tokens as string\n-pub(crate) struct Querier<'a> {\n-    src: &'a SubtreeTokenSource<'a>,\n+#[derive(Debug, Clone, Eq, PartialEq)]\n+enum WalkIndex {\n+    DelimiterBegin(Option<TtToken>),\n+    Token(usize, Option<TtToken>),\n+    DelimiterEnd(Option<TtToken>),\n+    Eof,\n }\n \n-impl<'a> Querier<'a> {\n-    pub(crate) fn token(&self, uidx: usize) -> (SyntaxKind, &SmolStr) {\n-        let tkn = &self.src.tokens[uidx];\n-        (tkn.kind, &tkn.text)\n+impl<'a> SubTreeWalker<'a> {\n+    fn new(subtree: &tt::Subtree) -> SubTreeWalker {\n+        let mut res = SubTreeWalker {\n+            pos: 0,\n+            stack: vec![],\n+            idx: WalkIndex::Eof,\n+            last_steps: vec![],\n+            subtree,\n+        };\n+\n+        res.reset();\n+        res\n+    }\n+\n+    fn reset(&mut self) {\n+        self.pos = 0;\n+        self.stack = vec![(self.subtree, None)];\n+        self.idx = WalkIndex::DelimiterBegin(convert_delim(self.subtree.delimiter, false));\n+        self.last_steps = vec![];\n+\n+        while self.is_empty_delimiter() {\n+            self.forward_unchecked();\n+        }\n+    }\n+\n+    // This funciton will fast forward the pos cursor,\n+    // Such that backward will stop at `start_pos` point\n+    fn start_from_nth(&mut self, start_pos: usize) {\n+        self.reset();\n+        self.pos = start_pos;\n+        self.idx = self.walk_token(start_pos, false);\n+\n+        while self.is_empty_delimiter() {\n+            self.forward_unchecked();\n+        }\n+    }\n+\n+    fn current(&self) -> Option<&TtToken> {\n+        match &self.idx {\n+            WalkIndex::DelimiterBegin(t) => t.as_ref(),\n+            WalkIndex::Token(_, t) => t.as_ref(),\n+            WalkIndex::DelimiterEnd(t) => t.as_ref(),\n+            WalkIndex::Eof => None,\n+        }\n+    }\n+\n+    fn is_empty_delimiter(&self) -> bool {\n+        match &self.idx {\n+            WalkIndex::DelimiterBegin(None) => true,\n+            WalkIndex::DelimiterEnd(None) => true,\n+            _ => false,\n+        }\n+    }\n+\n+    fn backward(&mut self) {\n+        if self.last_steps.is_empty() {\n+            return;\n+        }\n+        self.pos -= 1;\n+        loop {\n+            self.backward_unchecked();\n+            // Skip Empty delimiter\n+            if self.last_steps.is_empty() || !self.is_empty_delimiter() {\n+                break;\n+            }\n+        }\n+    }\n+\n+    fn backward_unchecked(&mut self) {\n+        if self.last_steps.is_empty() {\n+            return;\n+        }\n+\n+        let last_step = self.last_steps.pop().unwrap();\n+        let do_walk_token = match self.idx {\n+            WalkIndex::DelimiterBegin(_) => None,\n+            WalkIndex::Token(u, _) => Some(u),\n+            WalkIndex::DelimiterEnd(_) => {\n+                let (top, _) = self.stack.last().unwrap();\n+                Some(top.token_trees.len())\n+            }\n+            WalkIndex::Eof => None,\n+        };\n+\n+        self.idx = match do_walk_token {\n+            Some(u) if last_step > u => WalkIndex::DelimiterBegin(convert_delim(\n+                self.stack.last().unwrap().0.delimiter,\n+                false,\n+            )),\n+            Some(u) => self.walk_token(u - last_step, true),\n+            None => match self.idx {\n+                WalkIndex::Eof => {\n+                    self.stack.push((self.subtree, None));\n+                    WalkIndex::DelimiterEnd(convert_delim(\n+                        self.stack.last().unwrap().0.delimiter,\n+                        true,\n+                    ))\n+                }\n+                _ => {\n+                    let (_, last_top_idx) = self.stack.pop().unwrap();\n+                    assert!(!self.stack.is_empty());\n+\n+                    match last_top_idx.unwrap() {\n+                        0 => WalkIndex::DelimiterBegin(convert_delim(\n+                            self.stack.last().unwrap().0.delimiter,\n+                            false,\n+                        )),\n+                        c => self.walk_token(c - 1, true),\n+                    }\n+                }\n+            },\n+        };\n+    }\n+\n+    fn forward(&mut self) {\n+        self.pos += 1;\n+        loop {\n+            self.forward_unchecked();\n+            if !self.is_empty_delimiter() {\n+                break;\n+            }\n+        }\n+    }\n+\n+    fn forward_unchecked(&mut self) {\n+        if self.idx == WalkIndex::Eof {\n+            return;\n+        }\n+\n+        let step = self.current().map(|x| x.n_tokens).unwrap_or(1);\n+        self.last_steps.push(step);\n+\n+        let do_walk_token = match self.idx {\n+            WalkIndex::DelimiterBegin(_) => Some(0),\n+            WalkIndex::Token(u, _) => Some(u + step),\n+            WalkIndex::DelimiterEnd(_) => None,\n+            _ => unreachable!(),\n+        };\n+\n+        let (top, _) = self.stack.last().unwrap();\n+\n+        self.idx = match do_walk_token {\n+            Some(u) if u >= top.token_trees.len() => {\n+                WalkIndex::DelimiterEnd(convert_delim(self.stack.last().unwrap().0.delimiter, true))\n+            }\n+            Some(u) => self.walk_token(u, false),\n+            None => {\n+                let (_, last_top_idx) = self.stack.pop().unwrap();\n+                match self.stack.last() {\n+                    Some(top) => match last_top_idx.unwrap() {\n+                        idx if idx + 1 >= top.0.token_trees.len() => {\n+                            WalkIndex::DelimiterEnd(convert_delim(top.0.delimiter, true))\n+                        }\n+                        idx => self.walk_token(idx + 1, false),\n+                    },\n+\n+                    None => WalkIndex::Eof,\n+                }\n+            }\n+        };\n+    }\n+\n+    fn walk_token(&mut self, pos: usize, backward: bool) -> WalkIndex {\n+        let (top, _) = self.stack.last().unwrap();\n+        match &top.token_trees[pos] {\n+            tt::TokenTree::Subtree(subtree) => {\n+                self.stack.push((subtree, Some(pos)));\n+                let delim = convert_delim(self.stack.last().unwrap().0.delimiter, backward);\n+                if backward {\n+                    WalkIndex::DelimiterEnd(delim)\n+                } else {\n+                    WalkIndex::DelimiterBegin(delim)\n+                }\n+            }\n+            tt::TokenTree::Leaf(leaf) => WalkIndex::Token(pos, Some(self.walk_leaf(leaf, pos))),\n+        }\n+    }\n+\n+    fn walk_leaf(&mut self, leaf: &tt::Leaf, pos: usize) -> TtToken {\n+        match leaf {\n+            tt::Leaf::Literal(l) => convert_literal(l),\n+            tt::Leaf::Ident(ident) => convert_ident(ident),\n+            tt::Leaf::Punct(punct) => {\n+                let (top, _) = self.stack.last().unwrap();\n+                convert_punct(punct, top, pos)\n+            }\n+        }\n     }\n }\n \n-pub(crate) struct SubtreeTokenSource<'a> {\n-    tt_pos: usize,\n-    tokens: Vec<TtToken>,\n-    subtree: &'a tt::Subtree,\n+pub(crate) trait Querier {\n+    fn token(&self, uidx: usize) -> (SyntaxKind, SmolStr);\n }\n \n-impl<'a> SubtreeTokenSource<'a> {\n-    pub fn new(subtree: &tt::Subtree) -> SubtreeTokenSource {\n-        SubtreeTokenSource { tokens: TtTokenBuilder::build(subtree), tt_pos: 0, subtree }\n+// A wrapper class for ref cell\n+pub(crate) struct WalkerOwner<'a> {\n+    walker: RefCell<SubTreeWalker<'a>>,\n+    offset: usize,\n+}\n+\n+impl<'a> WalkerOwner<'a> {\n+    fn token_idx<'b>(&self, pos: usize) -> Option<TtToken> {\n+        self.set_walker_pos(pos);\n+        self.walker.borrow().current().cloned()\n     }\n \n-    // Advance token source and skip the first delimiter\n-    pub fn advance(&mut self, n_token: usize, skip_first_delimiter: bool) {\n-        if skip_first_delimiter {\n-            self.tt_pos += 1;\n-        }\n+    fn start_from_nth(&mut self, pos: usize) {\n+        self.offset = pos;\n+        self.walker.borrow_mut().start_from_nth(pos);\n+    }\n \n-        // Matching `TtToken` cursor to `tt::TokenTree` cursor\n-        // It is because TtToken is not One to One mapping to tt::Token\n-        // There are 3 case (`TtToken` <=> `tt::TokenTree`) :\n-        // * One to One =>  ident, single char punch\n-        // * Many to One => `tt::TokenTree::SubTree`\n-        // * One to Many => multibyte punct\n-        //\n-        // Such that we cannot simpliy advance the cursor\n-        // We have to bump it one by one\n-        let mut pos = 0;\n-        while pos < n_token {\n-            pos += self.bump(&self.subtree.token_trees[pos]);\n+    fn set_walker_pos(&self, mut pos: usize) {\n+        pos += self.offset;\n+        let mut walker = self.walker.borrow_mut();\n+        while pos > walker.pos {\n+            walker.forward();\n+        }\n+        while pos < walker.pos {\n+            walker.backward();\n         }\n+        assert!(pos == walker.pos);\n     }\n \n-    pub fn querier(&self) -> Querier {\n-        Querier { src: self }\n+    fn new(subtree: &'a tt::Subtree) -> Self {\n+        WalkerOwner { walker: RefCell::new(SubTreeWalker::new(subtree)), offset: 0 }\n     }\n \n-    pub(crate) fn bump_n(\n-        &mut self,\n-        n_tt_tokens: usize,\n-        token_pos: &mut usize,\n-    ) -> Vec<&tt::TokenTree> {\n+    fn collect_token_tree(&mut self, n: usize) -> Vec<&tt::TokenTree> {\n+        self.start_from_nth(self.offset);\n+\n         let mut res = vec![];\n-        // Matching `TtToken` cursor to `tt::TokenTree` cursor\n-        // It is because TtToken is not One to One mapping to tt::Token\n-        // There are 3 case (`TtToken` <=> `tt::TokenTree`) :\n-        // * One to One =>  ident, single char punch\n-        // * Many to One => `tt::TokenTree::SubTree`\n-        // * One to Many => multibyte punct\n-        //\n-        // Such that we cannot simpliy advance the cursor\n-        // We have to bump it one by one\n-        let next_pos = self.tt_pos + n_tt_tokens;\n-\n-        while self.tt_pos < next_pos {\n-            let current = &self.subtree.token_trees[*token_pos];\n-            let n = self.bump(current);\n-            res.extend((0..n).map(|i| &self.subtree.token_trees[*token_pos + i]));\n-            *token_pos += n;\n+        let mut walker = self.walker.borrow_mut();\n+\n+        while walker.pos - self.offset < n {\n+            if let WalkIndex::Token(u, tt) = &walker.idx {\n+                if walker.stack.len() == 1 {\n+                    // We only collect the topmost child\n+                    res.push(&walker.stack[0].0.token_trees[*u]);\n+                    if let Some(tt) = tt {\n+                        for i in 0..tt.n_tokens - 1 {\n+                            res.push(&walker.stack[0].0.token_trees[u + i]);\n+                        }\n+                    }\n+                }\n+            }\n+\n+            walker.forward();\n         }\n \n         res\n     }\n+}\n+\n+impl<'a> Querier for WalkerOwner<'a> {\n+    fn token(&self, uidx: usize) -> (SyntaxKind, SmolStr) {\n+        let tkn = self.token_idx(uidx).unwrap();\n+        (tkn.kind, tkn.text)\n+    }\n+}\n+\n+pub(crate) struct SubtreeTokenSource<'a> {\n+    walker: WalkerOwner<'a>,\n+}\n+\n+impl<'a> SubtreeTokenSource<'a> {\n+    pub fn new(subtree: &tt::Subtree) -> SubtreeTokenSource {\n+        SubtreeTokenSource { walker: WalkerOwner::new(subtree) }\n+    }\n+\n+    pub fn start_from_nth(&mut self, n: usize) {\n+        self.walker.start_from_nth(n);\n+    }\n \n-    fn count(&self, tt: &tt::TokenTree) -> usize {\n-        assert!(!self.tokens.is_empty());\n-        TtTokenBuilder::count_tt_tokens(tt, None)\n+    pub fn querier<'b>(&'a self) -> &'b WalkerOwner<'a>\n+    where\n+        'a: 'b,\n+    {\n+        &self.walker\n     }\n \n-    fn bump(&mut self, tt: &tt::TokenTree) -> usize {\n-        let cur = &self.tokens[self.tt_pos];\n-        let n_tokens = cur.n_tokens;\n-        self.tt_pos += self.count(tt);\n-        n_tokens\n+    pub(crate) fn bump_n(\n+        &mut self,\n+        parsed_tokens: usize,\n+        cursor_pos: &mut usize,\n+    ) -> Vec<&tt::TokenTree> {\n+        let res = self.walker.collect_token_tree(parsed_tokens);\n+        *cursor_pos += res.len();\n+\n+        res\n     }\n }\n \n impl<'a> TokenSource for SubtreeTokenSource<'a> {\n     fn token_kind(&self, pos: usize) -> SyntaxKind {\n-        if let Some(tok) = self.tokens.get(self.tt_pos + pos) {\n+        if let Some(tok) = self.walker.token_idx(pos) {\n             tok.kind\n         } else {\n             SyntaxKind::EOF\n         }\n     }\n     fn is_token_joint_to_next(&self, pos: usize) -> bool {\n-        self.tokens[self.tt_pos + pos].is_joint_to_next\n+        self.walker.token_idx(pos).unwrap().is_joint_to_next\n     }\n     fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n-        self.tokens[self.tt_pos + pos].text == *kw\n+        self.walker.token_idx(pos).unwrap().text == *kw\n     }\n }\n \n@@ -136,10 +349,6 @@ where\n         TokenPeek { iter: itertools::multipeek(iter) }\n     }\n \n-    pub fn next(&mut self) -> Option<&tt::TokenTree> {\n-        self.iter.next()\n-    }\n-\n     fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n         if p.spacing != tt::Spacing::Joint {\n             return None;\n@@ -162,191 +371,117 @@ where\n     }\n }\n \n-struct TtTokenBuilder {\n-    tokens: Vec<TtToken>,\n-}\n-\n-impl TtTokenBuilder {\n-    fn build(sub: &tt::Subtree) -> Vec<TtToken> {\n-        let mut res = TtTokenBuilder { tokens: vec![] };\n-        res.convert_subtree(sub);\n-        res.tokens\n-    }\n-\n-    fn convert_subtree(&mut self, sub: &tt::Subtree) {\n-        self.push_delim(sub.delimiter, false);\n-        let mut peek = TokenPeek::new(sub.token_trees.iter());\n-        while let Some(tt) = peek.iter.next() {\n-            self.convert_tt(tt, &mut peek);\n+fn convert_multi_char_punct<'b, I>(\n+    p: &tt::Punct,\n+    iter: &mut TokenPeek<'b, I>,\n+) -> Option<(SyntaxKind, bool, &'static str, usize)>\n+where\n+    I: Iterator<Item = &'b tt::TokenTree>,\n+{\n+    if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n+        if let Some((kind, text)) = match m {\n+            ('<', '<', '=') => Some((SHLEQ, \"<<=\")),\n+            ('>', '>', '=') => Some((SHREQ, \">>=\")),\n+            ('.', '.', '.') => Some((DOTDOTDOT, \"...\")),\n+            ('.', '.', '=') => Some((DOTDOTEQ, \"..=\")),\n+            _ => None,\n+        } {\n+            return Some((kind, is_joint_to_next, text, 3));\n         }\n-        self.push_delim(sub.delimiter, true)\n     }\n \n-    fn convert_tt<'b, I>(&mut self, tt: &tt::TokenTree, iter: &mut TokenPeek<'b, I>)\n-    where\n-        I: Iterator<Item = &'b tt::TokenTree>,\n-    {\n-        match tt {\n-            tt::TokenTree::Leaf(token) => self.convert_token(token, iter),\n-            tt::TokenTree::Subtree(sub) => self.convert_subtree(sub),\n+    if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n+        if let Some((kind, text)) = match m {\n+            ('<', '<') => Some((SHL, \"<<\")),\n+            ('>', '>') => Some((SHR, \">>\")),\n+\n+            ('|', '|') => Some((PIPEPIPE, \"||\")),\n+            ('&', '&') => Some((AMPAMP, \"&&\")),\n+            ('%', '=') => Some((PERCENTEQ, \"%=\")),\n+            ('*', '=') => Some((STAREQ, \"*=\")),\n+            ('/', '=') => Some((SLASHEQ, \"/=\")),\n+            ('^', '=') => Some((CARETEQ, \"^=\")),\n+\n+            ('&', '=') => Some((AMPEQ, \"&=\")),\n+            ('|', '=') => Some((PIPEEQ, \"|=\")),\n+            ('-', '=') => Some((MINUSEQ, \"-=\")),\n+            ('+', '=') => Some((PLUSEQ, \"+=\")),\n+            ('>', '=') => Some((GTEQ, \">=\")),\n+            ('<', '=') => Some((LTEQ, \"<=\")),\n+\n+            ('-', '>') => Some((THIN_ARROW, \"->\")),\n+            ('!', '=') => Some((NEQ, \"!=\")),\n+            ('=', '>') => Some((FAT_ARROW, \"=>\")),\n+            ('=', '=') => Some((EQEQ, \"==\")),\n+            ('.', '.') => Some((DOTDOT, \"..\")),\n+            (':', ':') => Some((COLONCOLON, \"::\")),\n+\n+            _ => None,\n+        } {\n+            return Some((kind, is_joint_to_next, text, 2));\n         }\n     }\n \n-    fn convert_token<'b, I>(&mut self, token: &tt::Leaf, iter: &mut TokenPeek<'b, I>)\n-    where\n-        I: Iterator<Item = &'b tt::TokenTree>,\n-    {\n-        let tok = match token {\n-            tt::Leaf::Literal(l) => TtToken {\n-                kind: classify_literal(&l.text).unwrap().kind,\n-                is_joint_to_next: false,\n-                text: l.text.clone(),\n-                n_tokens: 1,\n-            },\n-            tt::Leaf::Punct(p) => {\n-                if let Some((kind, is_joint_to_next, text, size)) =\n-                    Self::convert_multi_char_punct(p, iter)\n-                {\n-                    for _ in 0..size - 1 {\n-                        iter.next();\n-                    }\n-\n-                    TtToken { kind, is_joint_to_next, text: text.into(), n_tokens: size }\n-                } else {\n-                    let kind = match p.char {\n-                        // lexer may produce combpund tokens for these ones\n-                        '.' => DOT,\n-                        ':' => COLON,\n-                        '=' => EQ,\n-                        '!' => EXCL,\n-                        '-' => MINUS,\n-                        c => SyntaxKind::from_char(c).unwrap(),\n-                    };\n-                    let text = {\n-                        let mut buf = [0u8; 4];\n-                        let s: &str = p.char.encode_utf8(&mut buf);\n-                        SmolStr::new(s)\n-                    };\n-                    TtToken {\n-                        kind,\n-                        is_joint_to_next: p.spacing == tt::Spacing::Joint,\n-                        text,\n-                        n_tokens: 1,\n-                    }\n-                }\n-            }\n-            tt::Leaf::Ident(ident) => {\n-                let kind = SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT);\n-                TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n-            }\n-        };\n-        self.tokens.push(tok)\n-    }\n-\n-    fn convert_multi_char_punct<'b, I>(\n-        p: &tt::Punct,\n-        iter: &mut TokenPeek<'b, I>,\n-    ) -> Option<(SyntaxKind, bool, &'static str, usize)>\n-    where\n-        I: Iterator<Item = &'b tt::TokenTree>,\n-    {\n-        if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n-            if let Some((kind, text)) = match m {\n-                ('<', '<', '=') => Some((SHLEQ, \"<<=\")),\n-                ('>', '>', '=') => Some((SHREQ, \">>=\")),\n-                ('.', '.', '.') => Some((DOTDOTDOT, \"...\")),\n-                ('.', '.', '=') => Some((DOTDOTEQ, \"..=\")),\n-                _ => None,\n-            } {\n-                return Some((kind, is_joint_to_next, text, 3));\n-            }\n-        }\n+    None\n+}\n \n-        if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n-            if let Some((kind, text)) = match m {\n-                ('<', '<') => Some((SHL, \"<<\")),\n-                ('>', '>') => Some((SHR, \">>\")),\n-\n-                ('|', '|') => Some((PIPEPIPE, \"||\")),\n-                ('&', '&') => Some((AMPAMP, \"&&\")),\n-                ('%', '=') => Some((PERCENTEQ, \"%=\")),\n-                ('*', '=') => Some((STAREQ, \"*=\")),\n-                ('/', '=') => Some((SLASHEQ, \"/=\")),\n-                ('^', '=') => Some((CARETEQ, \"^=\")),\n-\n-                ('&', '=') => Some((AMPEQ, \"&=\")),\n-                ('|', '=') => Some((PIPEEQ, \"|=\")),\n-                ('-', '=') => Some((MINUSEQ, \"-=\")),\n-                ('+', '=') => Some((PLUSEQ, \"+=\")),\n-                ('>', '=') => Some((GTEQ, \">=\")),\n-                ('<', '=') => Some((LTEQ, \"<=\")),\n-\n-                ('-', '>') => Some((THIN_ARROW, \"->\")),\n-                ('!', '=') => Some((NEQ, \"!=\")),\n-                ('=', '>') => Some((FAT_ARROW, \"=>\")),\n-                ('=', '=') => Some((EQEQ, \"==\")),\n-                ('.', '.') => Some((DOTDOT, \"..\")),\n-                (':', ':') => Some((COLONCOLON, \"::\")),\n-\n-                _ => None,\n-            } {\n-                return Some((kind, is_joint_to_next, text, 2));\n-            }\n-        }\n+struct SubTreeWalker<'a> {\n+    pos: usize,\n+    stack: Vec<(&'a tt::Subtree, Option<usize>)>,\n+    idx: WalkIndex,\n+    last_steps: Vec<usize>,\n+    subtree: &'a tt::Subtree,\n+}\n \n-        None\n-    }\n+fn convert_delim(d: tt::Delimiter, closing: bool) -> Option<TtToken> {\n+    let (kinds, texts) = match d {\n+        tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n+        tt::Delimiter::Brace => ([L_CURLY, R_CURLY], \"{}\"),\n+        tt::Delimiter::Bracket => ([L_BRACK, R_BRACK], \"[]\"),\n+        tt::Delimiter::None => return None,\n+    };\n+\n+    let idx = closing as usize;\n+    let kind = kinds[idx];\n+    let text = &texts[idx..texts.len() - (1 - idx)];\n+    Some(TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 })\n+}\n \n-    fn push_delim(&mut self, d: tt::Delimiter, closing: bool) {\n-        let (kinds, texts) = match d {\n-            tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n-            tt::Delimiter::Brace => ([L_CURLY, R_CURLY], \"{}\"),\n-            tt::Delimiter::Bracket => ([L_BRACK, R_BRACK], \"[]\"),\n-            tt::Delimiter::None => return,\n-        };\n-        let idx = closing as usize;\n-        let kind = kinds[idx];\n-        let text = &texts[idx..texts.len() - (1 - idx)];\n-        let tok = TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 };\n-        self.tokens.push(tok)\n-    }\n-\n-    fn skip_sibling_leaf(leaf: &tt::Leaf, iter: &mut std::slice::Iter<tt::TokenTree>) {\n-        if let tt::Leaf::Punct(p) = leaf {\n-            let mut peek = TokenPeek::new(iter);\n-            if let Some((_, _, _, size)) = TtTokenBuilder::convert_multi_char_punct(p, &mut peek) {\n-                for _ in 0..size - 1 {\n-                    peek.next();\n-                }\n-            }\n-        }\n+fn convert_literal(l: &tt::Literal) -> TtToken {\n+    TtToken {\n+        kind: classify_literal(&l.text).unwrap().kind,\n+        is_joint_to_next: false,\n+        text: l.text.clone(),\n+        n_tokens: 1,\n     }\n+}\n \n-    fn count_tt_tokens(\n-        tt: &tt::TokenTree,\n-        iter: Option<&mut std::slice::Iter<tt::TokenTree>>,\n-    ) -> usize {\n-        match tt {\n-            tt::TokenTree::Subtree(sub_tree) => {\n-                let mut iter = sub_tree.token_trees.iter();\n-                let mut count = match sub_tree.delimiter {\n-                    tt::Delimiter::None => 0,\n-                    _ => 2,\n-                };\n-\n-                while let Some(tt) = iter.next() {\n-                    count += Self::count_tt_tokens(&tt, Some(&mut iter));\n-                }\n-                count\n-            }\n-\n-            tt::TokenTree::Leaf(leaf) => {\n-                iter.map(|iter| {\n-                    Self::skip_sibling_leaf(leaf, iter);\n-                });\n+fn convert_ident(ident: &tt::Ident) -> TtToken {\n+    let kind = SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT);\n+    TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n+}\n \n-                1\n-            }\n-        }\n+fn convert_punct(p: &tt::Punct, parent: &tt::Subtree, next: usize) -> TtToken {\n+    let iter = parent.token_trees[next..].iter();\n+    let mut peek = TokenPeek::new(iter);\n+\n+    if let Some((kind, is_joint_to_next, text, size)) = convert_multi_char_punct(p, &mut peek) {\n+        TtToken { kind, is_joint_to_next, text: text.into(), n_tokens: size }\n+    } else {\n+        let kind = match p.char {\n+            // lexer may produce combpund tokens for these ones\n+            '.' => DOT,\n+            ':' => COLON,\n+            '=' => EQ,\n+            '!' => EXCL,\n+            '-' => MINUS,\n+            c => SyntaxKind::from_char(c).unwrap(),\n+        };\n+        let text = {\n+            let mut buf = [0u8; 4];\n+            let s: &str = p.char.encode_utf8(&mut buf);\n+            SmolStr::new(s)\n+        };\n+        TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text, n_tokens: 1 }\n     }\n }"}, {"sha": "19c17bd550b953db767a1e7ff4d5c753f4d3bb85", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=2697ecaa64570841f0ed2a3ca5bc02cf41dccc4a", "patch": "@@ -105,16 +105,16 @@ fn convert_tt(\n     Some(res)\n }\n \n-struct TtTreeSink<'a> {\n+struct TtTreeSink<'a, Q: Querier> {\n     buf: String,\n-    src_querier: Querier<'a>,\n+    src_querier: &'a Q,\n     text_pos: TextUnit,\n     token_pos: usize,\n     inner: SyntaxTreeBuilder,\n }\n \n-impl<'a> TtTreeSink<'a> {\n-    fn new(src_querier: Querier<'a>) -> TtTreeSink {\n+impl<'a, Q: Querier> TtTreeSink<'a, Q> {\n+    fn new(src_querier: &'a Q) -> Self {\n         TtTreeSink {\n             buf: String::new(),\n             src_querier,\n@@ -125,10 +125,10 @@ impl<'a> TtTreeSink<'a> {\n     }\n }\n \n-impl<'a> TreeSink for TtTreeSink<'a> {\n+impl<'a, Q: Querier> TreeSink for TtTreeSink<'a, Q> {\n     fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {\n         for _ in 0..n_tokens {\n-            self.buf += self.src_querier.token(self.token_pos).1;\n+            self.buf += &self.src_querier.token(self.token_pos).1;\n             self.token_pos += 1;\n         }\n         self.text_pos += TextUnit::of_str(&self.buf);"}]}