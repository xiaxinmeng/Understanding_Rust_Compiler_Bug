{"sha": "f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "node_id": "MDY6Q29tbWl0NzI0NzEyOmYxOTEzZTJhMzA1ZjJhZDlhNjU1Y2IwYTA4Y2JjZTg4NmUzN2FjMjc=", "commit": {"author": {"name": "Stjepan Glavina", "email": "stjepang@gmail.com", "date": "2017-03-17T14:05:44Z"}, "committer": {"name": "Stjepan Glavina", "email": "stjepang@gmail.com", "date": "2017-03-21T19:46:20Z"}, "message": "Implement feature sort_unstable", "tree": {"sha": "3ff054772465aa3189eb4822d876408c2107c62c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3ff054772465aa3189eb4822d876408c2107c62c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "html_url": "https://github.com/rust-lang/rust/commit/f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/comments", "author": null, "committer": null, "parents": [{"sha": "58c701f5c7dc26d9b55c631006ece52abe1ddce2", "url": "https://api.github.com/repos/rust-lang/rust/commits/58c701f5c7dc26d9b55c631006ece52abe1ddce2", "html_url": "https://github.com/rust-lang/rust/commit/58c701f5c7dc26d9b55c631006ece52abe1ddce2"}], "stats": {"total": 1080, "additions": 967, "deletions": 113}, "files": [{"sha": "42064e9ca575056b9811ce91cec267ac75ed055d", "filename": "src/libcollections/benches/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollections%2Fbenches%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollections%2Fbenches%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fbenches%2Flib.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -11,6 +11,7 @@\n #![deny(warnings)]\n \n #![feature(rand)]\n+#![feature(sort_unstable)]\n #![feature(test)]\n \n extern crate test;"}, {"sha": "7195a9f9bf2c6ad53134af4398c2b92bb41b96f7", "filename": "src/libcollections/benches/slice.rs", "status": "modified", "additions": 61, "deletions": 49, "changes": 110, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollections%2Fbenches%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollections%2Fbenches%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fbenches%2Fslice.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -169,6 +169,7 @@ fn random_inserts(b: &mut Bencher) {\n         }\n     })\n }\n+\n #[bench]\n fn random_removes(b: &mut Bencher) {\n     let mut rng = thread_rng();\n@@ -216,65 +217,76 @@ fn gen_mostly_descending(len: usize) -> Vec<u64> {\n     v\n }\n \n-fn gen_big_random(len: usize) -> Vec<[u64; 16]> {\n+fn gen_strings(len: usize) -> Vec<String> {\n     let mut rng = thread_rng();\n-    rng.gen_iter().map(|x| [x; 16]).take(len).collect()\n-}\n-\n-fn gen_big_ascending(len: usize) -> Vec<[u64; 16]> {\n-    (0..len as u64).map(|x| [x; 16]).take(len).collect()\n+    let mut v = vec![];\n+    for _ in 0..len {\n+        let n = rng.gen::<usize>() % 20 + 1;\n+        v.push(rng.gen_ascii_chars().take(n).collect());\n+    }\n+    v\n }\n \n-fn gen_big_descending(len: usize) -> Vec<[u64; 16]> {\n-    (0..len as u64).rev().map(|x| [x; 16]).take(len).collect()\n+fn gen_big_random(len: usize) -> Vec<[u64; 16]> {\n+    let mut rng = thread_rng();\n+    rng.gen_iter().map(|x| [x; 16]).take(len).collect()\n }\n \n-macro_rules! sort_bench {\n-    ($name:ident, $gen:expr, $len:expr) => {\n+macro_rules! sort {\n+    ($f:ident, $name:ident, $gen:expr, $len:expr) => {\n         #[bench]\n         fn $name(b: &mut Bencher) {\n-            b.iter(|| $gen($len).sort());\n+            b.iter(|| $gen($len).$f());\n             b.bytes = $len * mem::size_of_val(&$gen(1)[0]) as u64;\n         }\n     }\n }\n \n-sort_bench!(sort_small_random, gen_random, 10);\n-sort_bench!(sort_small_ascending, gen_ascending, 10);\n-sort_bench!(sort_small_descending, gen_descending, 10);\n-\n-sort_bench!(sort_small_big_random, gen_big_random, 10);\n-sort_bench!(sort_small_big_ascending, gen_big_ascending, 10);\n-sort_bench!(sort_small_big_descending, gen_big_descending, 10);\n-\n-sort_bench!(sort_medium_random, gen_random, 100);\n-sort_bench!(sort_medium_ascending, gen_ascending, 100);\n-sort_bench!(sort_medium_descending, gen_descending, 100);\n-\n-sort_bench!(sort_large_random, gen_random, 10000);\n-sort_bench!(sort_large_ascending, gen_ascending, 10000);\n-sort_bench!(sort_large_descending, gen_descending, 10000);\n-sort_bench!(sort_large_mostly_ascending, gen_mostly_ascending, 10000);\n-sort_bench!(sort_large_mostly_descending, gen_mostly_descending, 10000);\n-\n-sort_bench!(sort_large_big_random, gen_big_random, 10000);\n-sort_bench!(sort_large_big_ascending, gen_big_ascending, 10000);\n-sort_bench!(sort_large_big_descending, gen_big_descending, 10000);\n+macro_rules! sort_expensive {\n+    ($f:ident, $name:ident, $gen:expr, $len:expr) => {\n+        #[bench]\n+        fn $name(b: &mut Bencher) {\n+            b.iter(|| {\n+                let mut v = $gen($len);\n+                let mut count = 0;\n+                v.$f(|a: &u64, b: &u64| {\n+                    count += 1;\n+                    if count % 1_000_000_000 == 0 {\n+                        panic!(\"should not happen\");\n+                    }\n+                    (*a as f64).cos().partial_cmp(&(*b as f64).cos()).unwrap()\n+                });\n+                black_box(count);\n+            });\n+            b.bytes = $len as u64 * mem::size_of::<u64>() as u64;\n+        }\n+    }\n+}\n \n-#[bench]\n-fn sort_large_random_expensive(b: &mut Bencher) {\n-    let len = 10000;\n-    b.iter(|| {\n-        let mut v = gen_random(len);\n-        let mut count = 0;\n-        v.sort_by(|a: &u64, b: &u64| {\n-            count += 1;\n-            if count % 1_000_000_000 == 0 {\n-                panic!(\"should not happen\");\n-            }\n-            (*a as f64).cos().partial_cmp(&(*b as f64).cos()).unwrap()\n-        });\n-        black_box(count);\n-    });\n-    b.bytes = len as u64 * mem::size_of::<u64>() as u64;\n-}\n\\ No newline at end of file\n+sort!(sort, sort_small_ascending, gen_ascending, 10);\n+sort!(sort, sort_small_descending, gen_descending, 10);\n+sort!(sort, sort_small_random, gen_random, 10);\n+sort!(sort, sort_small_big_random, gen_big_random, 10);\n+sort!(sort, sort_medium_random, gen_random, 100);\n+sort!(sort, sort_large_ascending, gen_ascending, 10000);\n+sort!(sort, sort_large_descending, gen_descending, 10000);\n+sort!(sort, sort_large_mostly_ascending, gen_mostly_ascending, 10000);\n+sort!(sort, sort_large_mostly_descending, gen_mostly_descending, 10000);\n+sort!(sort, sort_large_random, gen_random, 10000);\n+sort!(sort, sort_large_big_random, gen_big_random, 10000);\n+sort!(sort, sort_large_strings, gen_strings, 10000);\n+sort_expensive!(sort_by, sort_large_random_expensive, gen_random, 10000);\n+\n+sort!(sort_unstable, sort_unstable_small_ascending, gen_ascending, 10);\n+sort!(sort_unstable, sort_unstable_small_descending, gen_descending, 10);\n+sort!(sort_unstable, sort_unstable_small_random, gen_random, 10);\n+sort!(sort_unstable, sort_unstable_small_big_random, gen_big_random, 10);\n+sort!(sort_unstable, sort_unstable_medium_random, gen_random, 100);\n+sort!(sort_unstable, sort_unstable_large_ascending, gen_ascending, 10000);\n+sort!(sort_unstable, sort_unstable_large_descending, gen_descending, 10000);\n+sort!(sort_unstable, sort_unstable_large_mostly_ascending, gen_mostly_ascending, 10000);\n+sort!(sort_unstable, sort_unstable_large_mostly_descending, gen_mostly_descending, 10000);\n+sort!(sort_unstable, sort_unstable_large_random, gen_random, 10000);\n+sort!(sort_unstable, sort_unstable_large_big_random, gen_big_random, 10000);\n+sort!(sort_unstable, sort_unstable_large_strings, gen_strings, 10000);\n+sort_expensive!(sort_unstable_by, sort_unstable_large_random_expensive, gen_random, 10000);"}, {"sha": "9809db77f080e82f872a42fc782681f6a0f81412", "filename": "src/libcollections/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollections%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollections%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Flib.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -52,6 +52,7 @@\n #![feature(shared)]\n #![feature(slice_get_slice)]\n #![feature(slice_patterns)]\n+#![feature(sort_unstable)]\n #![feature(specialization)]\n #![feature(staged_api)]\n #![feature(str_internals)]"}, {"sha": "c915d8b9e563d532486525b4d00b61157232bd63", "filename": "src/libcollections/slice.rs", "status": "modified", "additions": 128, "deletions": 28, "changes": 156, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollections%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollections%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fslice.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -1092,6 +1092,39 @@ impl<T> [T] {\n         merge_sort(self, |a, b| a.lt(b));\n     }\n \n+    /// Sorts the slice using `compare` to compare elements.\n+    ///\n+    /// This sort is stable (i.e. does not reorder equal elements) and `O(n log n)` worst-case.\n+    ///\n+    /// # Current implementation\n+    ///\n+    /// The current algorithm is an adaptive, iterative merge sort inspired by\n+    /// [timsort](https://en.wikipedia.org/wiki/Timsort).\n+    /// It is designed to be very fast in cases where the slice is nearly sorted, or consists of\n+    /// two or more sorted sequences concatenated one after another.\n+    ///\n+    /// Also, it allocates temporary storage half the size of `self`, but for short slices a\n+    /// non-allocating insertion sort is used instead.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// let mut v = [5, 4, 1, 3, 2];\n+    /// v.sort_by(|a, b| a.cmp(b));\n+    /// assert!(v == [1, 2, 3, 4, 5]);\n+    ///\n+    /// // reverse sorting\n+    /// v.sort_by(|a, b| b.cmp(a));\n+    /// assert!(v == [5, 4, 3, 2, 1]);\n+    /// ```\n+    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n+    #[inline]\n+    pub fn sort_by<F>(&mut self, mut compare: F)\n+        where F: FnMut(&T, &T) -> Ordering\n+    {\n+        merge_sort(self, |a, b| compare(a, b) == Less);\n+    }\n+\n     /// Sorts the slice using `f` to extract a key to compare elements by.\n     ///\n     /// This sort is stable (i.e. does not reorder equal elements) and `O(n log n)` worst-case.\n@@ -1122,37 +1155,112 @@ impl<T> [T] {\n         merge_sort(self, |a, b| f(a).lt(&f(b)));\n     }\n \n-    /// Sorts the slice using `compare` to compare elements.\n+    /// Sorts the slice, but may not preserve the order of equal elements.\n     ///\n-    /// This sort is stable (i.e. does not reorder equal elements) and `O(n log n)` worst-case.\n+    /// This sort is unstable (i.e. may reorder equal elements), in-place (i.e. does not allocate),\n+    /// and `O(n log n)` worst-case.\n     ///\n     /// # Current implementation\n     ///\n-    /// The current algorithm is an adaptive, iterative merge sort inspired by\n-    /// [timsort](https://en.wikipedia.org/wiki/Timsort).\n-    /// It is designed to be very fast in cases where the slice is nearly sorted, or consists of\n-    /// two or more sorted sequences concatenated one after another.\n+    /// The current algorithm is based on Orson Peters' [pdqsort][pattern-defeating quicksort],\n+    /// which is a quicksort variant designed to be very fast on certain kinds of patterns,\n+    /// sometimes achieving linear time. It is randomized but deterministic, and falls back to\n+    /// heapsort on degenerate inputs.\n     ///\n-    /// Also, it allocates temporary storage half the size of `self`, but for short slices a\n-    /// non-allocating insertion sort is used instead.\n+    /// It is generally faster than stable sorting, except in a few special cases, e.g. when the\n+    /// slice consists of several concatenated sorted sequences.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// let mut v = [-5, 4, 1, -3, 2];\n+    ///\n+    /// v.sort_unstable();\n+    /// assert!(v == [-5, -3, 1, 2, 4]);\n+    /// ```\n+    ///\n+    /// [pdqsort]: https://github.com/orlp/pdqsort\n+    // FIXME #40585: Mention `sort_unstable` in the documentation for `sort`.\n+    #[unstable(feature = \"sort_unstable\", issue = \"40585\")]\n+    #[inline]\n+    pub fn sort_unstable(&mut self)\n+        where T: Ord\n+    {\n+        core_slice::SliceExt::sort_unstable(self);\n+    }\n+\n+    /// Sorts the slice using `compare` to compare elements, but may not preserve the order of\n+    /// equal elements.\n+    ///\n+    /// This sort is unstable (i.e. may reorder equal elements), in-place (i.e. does not allocate),\n+    /// and `O(n log n)` worst-case.\n+    ///\n+    /// # Current implementation\n+    ///\n+    /// The current algorithm is based on Orson Peters' [pdqsort][pattern-defeating quicksort],\n+    /// which is a quicksort variant designed to be very fast on certain kinds of patterns,\n+    /// sometimes achieving linear time. It is randomized but deterministic, and falls back to\n+    /// heapsort on degenerate inputs.\n+    ///\n+    /// It is generally faster than stable sorting, except in a few special cases, e.g. when the\n+    /// slice consists of several concatenated sorted sequences.\n     ///\n     /// # Examples\n     ///\n     /// ```\n     /// let mut v = [5, 4, 1, 3, 2];\n-    /// v.sort_by(|a, b| a.cmp(b));\n+    /// v.sort_unstable_by(|a, b| a.cmp(b));\n     /// assert!(v == [1, 2, 3, 4, 5]);\n     ///\n     /// // reverse sorting\n-    /// v.sort_by(|a, b| b.cmp(a));\n+    /// v.sort_unstable_by(|a, b| b.cmp(a));\n     /// assert!(v == [5, 4, 3, 2, 1]);\n     /// ```\n-    #[stable(feature = \"rust1\", since = \"1.0.0\")]\n+    ///\n+    /// [pdqsort]: https://github.com/orlp/pdqsort\n+    // FIXME #40585: Mention `sort_unstable_by` in the documentation for `sort_by`.\n+    #[unstable(feature = \"sort_unstable\", issue = \"40585\")]\n     #[inline]\n-    pub fn sort_by<F>(&mut self, mut compare: F)\n+    pub fn sort_unstable_by<F>(&mut self, compare: F)\n         where F: FnMut(&T, &T) -> Ordering\n     {\n-        merge_sort(self, |a, b| compare(a, b) == Less);\n+        core_slice::SliceExt::sort_unstable_by(self, compare);\n+    }\n+\n+    /// Sorts the slice using `f` to extract a key to compare elements by, but may not preserve the\n+    /// order of equal elements.\n+    ///\n+    /// This sort is unstable (i.e. may reorder equal elements), in-place (i.e. does not allocate),\n+    /// and `O(n log n)` worst-case.\n+    ///\n+    /// # Current implementation\n+    ///\n+    /// The current algorithm is based on Orson Peters' [pdqsort][pattern-defeating quicksort],\n+    /// which is a quicksort variant designed to be very fast on certain kinds of patterns,\n+    /// sometimes achieving linear time. It is randomized but deterministic, and falls back to\n+    /// heapsort on degenerate inputs.\n+    ///\n+    /// It is generally faster than stable sorting, except in a few special cases, e.g. when the\n+    /// slice consists of several concatenated sorted sequences.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// let mut v = [-5i32, 4, 1, -3, 2];\n+    ///\n+    /// v.sort_unstable_by_key(|k| k.abs());\n+    /// assert!(v == [1, 2, -3, 4, -5]);\n+    ///\n+    /// [pdqsort]: https://github.com/orlp/pdqsort\n+    /// ```\n+    // FIXME #40585: Mention `sort_unstable_by_key` in the documentation for `sort_by_key`.\n+    #[unstable(feature = \"sort_unstable\", issue = \"40585\")]\n+    #[inline]\n+    pub fn sort_unstable_by_key<B, F>(&mut self, f: F)\n+        where F: FnMut(&T) -> B,\n+              B: Ord\n+    {\n+        core_slice::SliceExt::sort_unstable_by_key(self, f);\n     }\n \n     /// Copies the elements from `src` into `self`.\n@@ -1553,28 +1661,20 @@ unsafe fn merge<T, F>(v: &mut [T], mid: usize, buf: *mut T, is_less: &mut F)\n fn merge_sort<T, F>(v: &mut [T], mut is_less: F)\n     where F: FnMut(&T, &T) -> bool\n {\n+    // Slices of up to this length get sorted using insertion sort.\n+    const MAX_INSERTION: usize = 16;\n+    // Very short runs are extended using insertion sort to span at least this many elements.\n+    const MIN_RUN: usize = 8;\n+\n     // Sorting has no meaningful behavior on zero-sized types.\n     if size_of::<T>() == 0 {\n         return;\n     }\n \n-    // FIXME #12092: These numbers are platform-specific and need more extensive testing/tuning.\n-    //\n-    // If `v` has length up to `max_insertion`, simply switch to insertion sort because it is going\n-    // to perform better than merge sort. For bigger types `T`, the threshold is smaller.\n-    //\n-    // Short runs are extended using insertion sort to span at least `min_run` elements, in order\n-    // to improve performance.\n-    let (max_insertion, min_run) = if size_of::<T>() <= 2 * mem::size_of::<usize>() {\n-        (64, 32)\n-    } else {\n-        (32, 16)\n-    };\n-\n     let len = v.len();\n \n     // Short arrays get sorted in-place via insertion sort to avoid allocations.\n-    if len <= max_insertion {\n+    if len <= MAX_INSERTION {\n         if len >= 2 {\n             for i in (0..len-1).rev() {\n                 insert_head(&mut v[i..], &mut is_less);\n@@ -1618,7 +1718,7 @@ fn merge_sort<T, F>(v: &mut [T], mut is_less: F)\n \n         // Insert some more elements into the run if it's too short. Insertion sort is faster than\n         // merge sort on short sequences, so this significantly improves performance.\n-        while start > 0 && end - start < min_run {\n+        while start > 0 && end - start < MIN_RUN {\n             start -= 1;\n             insert_head(&mut v[start..end], &mut is_less);\n         }"}, {"sha": "00d4dbe9c0458fc36e50bb73eddd14af471abca8", "filename": "src/libcollectionstest/slice.rs", "status": "modified", "additions": 4, "deletions": 10, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollectionstest%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcollectionstest%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollectionstest%2Fslice.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -399,9 +399,10 @@ fn test_sort() {\n         }\n     }\n \n-    // shouldn't panic\n-    let mut v: [i32; 0] = [];\n-    v.sort();\n+    // Should not panic.\n+    [0i32; 0].sort();\n+    [(); 10].sort();\n+    [(); 100].sort();\n \n     let mut v = [0xDEADBEEFu64];\n     v.sort();\n@@ -441,13 +442,6 @@ fn test_sort_stability() {\n     }\n }\n \n-#[test]\n-fn test_sort_zero_sized_type() {\n-    // Should not panic.\n-    [(); 10].sort();\n-    [(); 100].sort();\n-}\n-\n #[test]\n fn test_concat() {\n     let v: [Vec<i32>; 0] = [];"}, {"sha": "af61342749319655b6803d3afb66e33a4eb77ba6", "filename": "src/libcore/lib.rs", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcore%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcore%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Flib.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -71,26 +71,27 @@\n #![feature(asm)]\n #![feature(associated_type_defaults)]\n #![feature(cfg_target_feature)]\n+#![feature(cfg_target_has_atomic)]\n #![feature(concat_idents)]\n #![feature(const_fn)]\n-#![feature(cfg_target_has_atomic)]\n #![feature(custom_attribute)]\n #![feature(fundamental)]\n+#![feature(i128_type)]\n #![feature(inclusive_range_syntax)]\n #![feature(intrinsics)]\n #![feature(lang_items)]\n+#![feature(never_type)]\n #![feature(no_core)]\n #![feature(on_unimplemented)]\n #![feature(optin_builtin_traits)]\n-#![feature(unwind_attributes)]\n+#![feature(prelude_import)]\n #![feature(repr_simd, platform_intrinsics)]\n #![feature(rustc_attrs)]\n #![feature(specialization)]\n #![feature(staged_api)]\n #![feature(unboxed_closures)]\n-#![feature(never_type)]\n-#![feature(i128_type)]\n-#![feature(prelude_import)]\n+#![feature(untagged_unions)]\n+#![feature(unwind_attributes)]\n \n #[prelude_import]\n #[allow(unused)]"}, {"sha": "53cbdd84c3a8d84b20651adc2a90b966301f7115", "filename": "src/libcore/slice/mod.rs", "status": "renamed", "additions": 95, "deletions": 17, "changes": 112, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcore%2Fslice%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcore%2Fslice%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fslice%2Fmod.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -1,4 +1,4 @@\n-// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n+// Copyright 2012-2017 The Rust Project Developers. See the COPYRIGHT\n // file at the top-level directory of this distribution and at\n // http://rust-lang.org/COPYRIGHT.\n //\n@@ -51,6 +51,8 @@ use mem;\n use marker::{Copy, Send, Sync, Sized, self};\n use iter_private::TrustedRandomAccess;\n \n+mod sort;\n+\n #[repr(C)]\n struct Repr<T> {\n     pub data: *const T,\n@@ -71,86 +73,119 @@ pub trait SliceExt {\n \n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn split_at(&self, mid: usize) -> (&[Self::Item], &[Self::Item]);\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn iter(&self) -> Iter<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn split<P>(&self, pred: P) -> Split<Self::Item, P>\n-                    where P: FnMut(&Self::Item) -> bool;\n+        where P: FnMut(&Self::Item) -> bool;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn splitn<P>(&self, n: usize, pred: P) -> SplitN<Self::Item, P>\n-                     where P: FnMut(&Self::Item) -> bool;\n+        where P: FnMut(&Self::Item) -> bool;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn rsplitn<P>(&self,  n: usize, pred: P) -> RSplitN<Self::Item, P>\n-                      where P: FnMut(&Self::Item) -> bool;\n+        where P: FnMut(&Self::Item) -> bool;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn windows(&self, size: usize) -> Windows<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn chunks(&self, size: usize) -> Chunks<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn get<I>(&self, index: I) -> Option<&I::Output>\n         where I: SliceIndex<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn first(&self) -> Option<&Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn split_first(&self) -> Option<(&Self::Item, &[Self::Item])>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn split_last(&self) -> Option<(&Self::Item, &[Self::Item])>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn last(&self) -> Option<&Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     unsafe fn get_unchecked<I>(&self, index: I) -> &I::Output\n         where I: SliceIndex<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn as_ptr(&self) -> *const Self::Item;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn binary_search<Q: ?Sized>(&self, x: &Q) -> Result<usize, usize>\n         where Self::Item: Borrow<Q>,\n               Q: Ord;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn binary_search_by<'a, F>(&'a self, f: F) -> Result<usize, usize>\n         where F: FnMut(&'a Self::Item) -> Ordering;\n+\n     #[stable(feature = \"slice_binary_search_by_key\", since = \"1.10.0\")]\n     fn binary_search_by_key<'a, B, F, Q: ?Sized>(&'a self, b: &Q, f: F) -> Result<usize, usize>\n         where F: FnMut(&'a Self::Item) -> B,\n               B: Borrow<Q>,\n               Q: Ord;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn len(&self) -> usize;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn is_empty(&self) -> bool { self.len() == 0 }\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn get_mut<I>(&mut self, index: I) -> Option<&mut I::Output>\n         where I: SliceIndex<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn iter_mut(&mut self) -> IterMut<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn first_mut(&mut self) -> Option<&mut Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn split_first_mut(&mut self) -> Option<(&mut Self::Item, &mut [Self::Item])>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn split_last_mut(&mut self) -> Option<(&mut Self::Item, &mut [Self::Item])>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn last_mut(&mut self) -> Option<&mut Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn split_mut<P>(&mut self, pred: P) -> SplitMut<Self::Item, P>\n-                        where P: FnMut(&Self::Item) -> bool;\n+        where P: FnMut(&Self::Item) -> bool;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn splitn_mut<P>(&mut self, n: usize, pred: P) -> SplitNMut<Self::Item, P>\n-                     where P: FnMut(&Self::Item) -> bool;\n+        where P: FnMut(&Self::Item) -> bool;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn rsplitn_mut<P>(&mut self,  n: usize, pred: P) -> RSplitNMut<Self::Item, P>\n-                      where P: FnMut(&Self::Item) -> bool;\n+        where P: FnMut(&Self::Item) -> bool;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn chunks_mut(&mut self, chunk_size: usize) -> ChunksMut<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn swap(&mut self, a: usize, b: usize);\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn split_at_mut(&mut self, mid: usize) -> (&mut [Self::Item], &mut [Self::Item]);\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn reverse(&mut self);\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     unsafe fn get_unchecked_mut<I>(&mut self, index: I) -> &mut I::Output\n         where I: SliceIndex<Self::Item>;\n+\n     #[stable(feature = \"core\", since = \"1.6.0\")]\n     fn as_mut_ptr(&mut self) -> *mut Self::Item;\n \n@@ -165,8 +200,22 @@ pub trait SliceExt {\n \n     #[stable(feature = \"clone_from_slice\", since = \"1.7.0\")]\n     fn clone_from_slice(&mut self, src: &[Self::Item]) where Self::Item: Clone;\n+\n     #[stable(feature = \"copy_from_slice\", since = \"1.9.0\")]\n     fn copy_from_slice(&mut self, src: &[Self::Item]) where Self::Item: Copy;\n+\n+    #[unstable(feature = \"sort_unstable\", issue = \"40585\")]\n+    fn sort_unstable(&mut self)\n+        where Self::Item: Ord;\n+\n+    #[unstable(feature = \"sort_unstable\", issue = \"40585\")]\n+    fn sort_unstable_by<F>(&mut self, compare: F)\n+        where F: FnMut(&Self::Item, &Self::Item) -> Ordering;\n+\n+    #[unstable(feature = \"sort_unstable\", issue = \"40585\")]\n+    fn sort_unstable_by_key<B, F>(&mut self, f: F)\n+        where F: FnMut(&Self::Item) -> B,\n+              B: Ord;\n }\n \n // Use macros to be generic over const/mut\n@@ -238,7 +287,9 @@ impl<T> SliceExt for [T] {\n     }\n \n     #[inline]\n-    fn split<P>(&self, pred: P) -> Split<T, P> where P: FnMut(&T) -> bool {\n+    fn split<P>(&self, pred: P) -> Split<T, P>\n+        where P: FnMut(&T) -> bool\n+    {\n         Split {\n             v: self,\n             pred: pred,\n@@ -247,8 +298,8 @@ impl<T> SliceExt for [T] {\n     }\n \n     #[inline]\n-    fn splitn<P>(&self, n: usize, pred: P) -> SplitN<T, P> where\n-        P: FnMut(&T) -> bool,\n+    fn splitn<P>(&self, n: usize, pred: P) -> SplitN<T, P>\n+        where P: FnMut(&T) -> bool\n     {\n         SplitN {\n             inner: GenericSplitN {\n@@ -260,8 +311,8 @@ impl<T> SliceExt for [T] {\n     }\n \n     #[inline]\n-    fn rsplitn<P>(&self, n: usize, pred: P) -> RSplitN<T, P> where\n-        P: FnMut(&T) -> bool,\n+    fn rsplitn<P>(&self, n: usize, pred: P) -> RSplitN<T, P>\n+        where P: FnMut(&T) -> bool\n     {\n         RSplitN {\n             inner: GenericSplitN {\n@@ -422,13 +473,15 @@ impl<T> SliceExt for [T] {\n     }\n \n     #[inline]\n-    fn split_mut<P>(&mut self, pred: P) -> SplitMut<T, P> where P: FnMut(&T) -> bool {\n+    fn split_mut<P>(&mut self, pred: P) -> SplitMut<T, P>\n+        where P: FnMut(&T) -> bool\n+    {\n         SplitMut { v: self, pred: pred, finished: false }\n     }\n \n     #[inline]\n-    fn splitn_mut<P>(&mut self, n: usize, pred: P) -> SplitNMut<T, P> where\n-        P: FnMut(&T) -> bool\n+    fn splitn_mut<P>(&mut self, n: usize, pred: P) -> SplitNMut<T, P>\n+        where P: FnMut(&T) -> bool\n     {\n         SplitNMut {\n             inner: GenericSplitN {\n@@ -450,7 +503,7 @@ impl<T> SliceExt for [T] {\n                 invert: true\n             }\n         }\n-   }\n+    }\n \n     #[inline]\n     fn chunks_mut(&mut self, chunk_size: usize) -> ChunksMut<T> {\n@@ -512,7 +565,10 @@ impl<T> SliceExt for [T] {\n         m >= n && needle == &self[m-n..]\n     }\n \n-    fn binary_search<Q: ?Sized>(&self, x: &Q) -> Result<usize, usize> where T: Borrow<Q>, Q: Ord {\n+    fn binary_search<Q: ?Sized>(&self, x: &Q) -> Result<usize, usize>\n+        where T: Borrow<Q>,\n+              Q: Ord\n+    {\n         self.binary_search_by(|p| p.borrow().cmp(x))\n     }\n \n@@ -548,6 +604,28 @@ impl<T> SliceExt for [T] {\n     {\n         self.binary_search_by(|k| f(k).borrow().cmp(b))\n     }\n+\n+    #[inline]\n+    fn sort_unstable(&mut self)\n+        where Self::Item: Ord\n+    {\n+        sort::quicksort(self, |a, b| a.lt(b));\n+    }\n+\n+    #[inline]\n+    fn sort_unstable_by<F>(&mut self, mut compare: F)\n+        where F: FnMut(&Self::Item, &Self::Item) -> Ordering\n+    {\n+        sort::quicksort(self, |a, b| compare(a, b) == Ordering::Less);\n+    }\n+\n+    #[inline]\n+    fn sort_unstable_by_key<B, F>(&mut self, mut f: F)\n+        where F: FnMut(&Self::Item) -> B,\n+              B: Ord\n+    {\n+        sort::quicksort(self, |a, b| f(a).lt(&f(b)));\n+    }\n }\n \n #[stable(feature = \"rust1\", since = \"1.0.0\")]", "previous_filename": "src/libcore/slice.rs"}, {"sha": "7c751b5c5a38659e89ad38a40691a61019b36383", "filename": "src/libcore/slice/sort.rs", "status": "added", "additions": 628, "deletions": 0, "changes": 628, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcore%2Fslice%2Fsort.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcore%2Fslice%2Fsort.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fslice%2Fsort.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -0,0 +1,628 @@\n+// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! Slice sorting\n+//!\n+//! This module contains an sort algorithm based on Orson Peters' pattern-defeating quicksort,\n+//! published at: https://github.com/orlp/pdqsort\n+//!\n+//! Unstable sorting is compatible with libcore because it doesn't allocate memory, unlike our\n+//! stable sorting implementation.\n+\n+#![unstable(feature = \"sort_unstable\", issue = \"40585\")]\n+\n+use cmp;\n+use mem;\n+use ptr;\n+\n+/// Holds a value, but never drops it.\n+#[allow(unions_with_drop_fields)]\n+union NoDrop<T> {\n+    value: T\n+}\n+\n+/// When dropped, copies from `src` into `dest`.\n+struct CopyOnDrop<T> {\n+    src: *mut T,\n+    dest: *mut T,\n+}\n+\n+impl<T> Drop for CopyOnDrop<T> {\n+    fn drop(&mut self) {\n+        unsafe { ptr::copy_nonoverlapping(self.src, self.dest, 1); }\n+    }\n+}\n+\n+/// Sorts a slice using insertion sort, which is `O(n^2)` worst-case.\n+fn insertion_sort<T, F>(v: &mut [T], is_less: &mut F)\n+    where F: FnMut(&T, &T) -> bool\n+{\n+    let len = v.len();\n+\n+    for i in 1..len {\n+        unsafe {\n+            if is_less(v.get_unchecked(i), v.get_unchecked(i - 1)) {\n+                // There are three ways to implement insertion here:\n+                //\n+                // 1. Swap adjacent elements until the first one gets to its final destination.\n+                //    However, this way we copy data around more than is necessary. If elements are\n+                //    big structures (costly to copy), this method will be slow.\n+                //\n+                // 2. Iterate until the right place for the first element is found. Then shift the\n+                //    elements succeeding it to make room for it and finally place it into the\n+                //    remaining hole. This is a good method.\n+                //\n+                // 3. Copy the first element into a temporary variable. Iterate until the right\n+                //    place for it is found. As we go along, copy every traversed element into the\n+                //    slot preceding it. Finally, copy data from the temporary variable into the\n+                //    remaining hole. This method is very good. Benchmarks demonstrated slightly\n+                //    better performance than with the 2nd method.\n+                //\n+                // All methods were benchmarked, and the 3rd showed best results. So we chose that\n+                // one.\n+                let mut tmp = NoDrop { value: ptr::read(v.get_unchecked(i)) };\n+\n+                // Intermediate state of the insertion process is always tracked by `hole`, which\n+                // serves two purposes:\n+                // 1. Protects integrity of `v` from panics in `is_less`.\n+                // 2. Fills the remaining hole in `v` in the end.\n+                //\n+                // Panic safety:\n+                //\n+                // If `is_less` panics at any point during the process, `hole` will get dropped and\n+                // fill the hole in `v` with `tmp`, thus ensuring that `v` still holds every object\n+                // it initially held exactly once.\n+                let mut hole = CopyOnDrop {\n+                    src: &mut tmp.value,\n+                    dest: v.get_unchecked_mut(i - 1),\n+                };\n+                ptr::copy_nonoverlapping(v.get_unchecked(i - 1), v.get_unchecked_mut(i), 1);\n+\n+                for h in (0..i-1).rev() {\n+                    if !is_less(&tmp.value, v.get_unchecked(h)) {\n+                        break;\n+                    }\n+                    ptr::copy_nonoverlapping(v.get_unchecked(h), v.get_unchecked_mut(h + 1), 1);\n+                    hole.dest = v.get_unchecked_mut(h);\n+                }\n+                // `hole` gets dropped and thus copies `tmp` into the remaining hole in `v`.\n+            }\n+        }\n+    }\n+}\n+\n+/// Sorts `v` using heapsort, which guarantees `O(n log n)` worst-case.\n+#[cold]\n+fn heapsort<T, F>(v: &mut [T], is_less: &mut F)\n+    where F: FnMut(&T, &T) -> bool\n+{\n+    // This binary heap respects the invariant `parent >= child`.\n+    let mut sift_down = |v: &mut [T], mut node| {\n+        loop {\n+            // Children of `node`:\n+            let left = 2 * node + 1;\n+            let right = 2 * node + 2;\n+\n+            // Choose the greater child.\n+            let greater = if right < v.len() && is_less(&v[left], &v[right]) {\n+                right\n+            } else {\n+                left\n+            };\n+\n+            // Stop if the invariant holds at `node`.\n+            if greater >= v.len() || !is_less(&v[node], &v[greater]) {\n+                break;\n+            }\n+\n+            // Swap `node` with the greater child, move one step down, and continue sifting.\n+            v.swap(node, greater);\n+            node = greater;\n+        }\n+    };\n+\n+    // Build the heap in linear time.\n+    for i in (0 .. v.len() / 2).rev() {\n+        sift_down(v, i);\n+    }\n+\n+    // Pop maximal elements from the heap.\n+    for i in (1 .. v.len()).rev() {\n+        v.swap(0, i);\n+        sift_down(&mut v[..i], 0);\n+    }\n+}\n+\n+/// Partitions `v` into elements smaller than `pivot`, followed by elements greater than or equal\n+/// to `pivot`.\n+///\n+/// Returns the number of elements smaller than `pivot`.\n+///\n+/// Partitioning is performed block-by-block in order to minimize the cost of branching operations.\n+/// This idea is presented in the [BlockQuicksort][pdf] paper.\n+///\n+/// [pdf]: http://drops.dagstuhl.de/opus/volltexte/2016/6389/pdf/LIPIcs-ESA-2016-38.pdf\n+fn partition_in_blocks<T, F>(v: &mut [T], pivot: &T, is_less: &mut F) -> usize\n+    where F: FnMut(&T, &T) -> bool\n+{\n+    // Number of elements in a typical block.\n+    const BLOCK: usize = 128;\n+\n+    // The partitioning algorithm repeats the following steps until completion:\n+    //\n+    // 1. Trace a block from the left side to identify elements greater than or equal to the pivot.\n+    // 2. Trace a block from the right side to identify elements less than the pivot.\n+    // 3. Exchange the identified elements between the left and right side.\n+    //\n+    // We keep the following variables for a block of elements:\n+    //\n+    // 1. `block` - Number of elements in the block.\n+    // 2. `start` - Start pointer into the `offsets` array.\n+    // 3. `end` - End pointer into the `offsets` array.\n+    // 4. `offsets - Indices of out-of-order elements within the block.\n+\n+    // The current block on the left side: `v[l .. l + block_l]`.\n+    let mut l = v.as_mut_ptr();\n+    let mut block_l = BLOCK;\n+    let mut start_l = ptr::null_mut();\n+    let mut end_l = ptr::null_mut();\n+    let mut offsets_l: [u8; BLOCK] = unsafe { mem::uninitialized() };\n+\n+    // The current block on the right side: `v[r - block_r .. r]`.\n+    let mut r = unsafe { l.offset(v.len() as isize) };\n+    let mut block_r = BLOCK;\n+    let mut start_r = ptr::null_mut();\n+    let mut end_r = ptr::null_mut();\n+    let mut offsets_r: [u8; BLOCK] = unsafe { mem::uninitialized() };\n+\n+    // Returns the number of elements between pointers `l` (inclusive) and `r` (exclusive).\n+    fn width<T>(l: *mut T, r: *mut T) -> usize {\n+        assert!(mem::size_of::<T>() > 0);\n+        (r as usize - l as usize) / mem::size_of::<T>()\n+    }\n+\n+    loop {\n+        // We are done with partitioning block-by-block when `l` and `r` get very close. Then we do\n+        // some patch-up work in order to partition the remaining elements in between.\n+        let is_done = width(l, r) <= 2 * BLOCK;\n+\n+        if is_done {\n+            // Number of remaining elements (still not compared to the pivot).\n+            let mut rem = width(l, r);\n+            if start_l < end_l || start_r < end_r {\n+                rem -= BLOCK;\n+            }\n+\n+            // Adjust block sizes so that the left and right block don't overlap, but get perfectly\n+            // aligned to cover the whole remaining gap.\n+            if start_l < end_l {\n+                block_r = rem;\n+            } else if start_r < end_r {\n+                block_l = rem;\n+            } else {\n+                block_l = rem / 2;\n+                block_r = rem - block_l;\n+            }\n+            debug_assert!(block_l <= BLOCK && block_r <= BLOCK);\n+            debug_assert!(width(l, r) == block_l + block_r);\n+        }\n+\n+        if start_l == end_l {\n+            // Trace `block_l` elements from the left side.\n+            start_l = offsets_l.as_mut_ptr();\n+            end_l = offsets_l.as_mut_ptr();\n+            let mut elem = l;\n+\n+            for i in 0..block_l {\n+                unsafe {\n+                    // Branchless comparison.\n+                    *end_l = i as u8;\n+                    end_l = end_l.offset(!is_less(&*elem, pivot) as isize);\n+                    elem = elem.offset(1);\n+                }\n+            }\n+        }\n+\n+        if start_r == end_r {\n+            // Trace `block_r` elements from the right side.\n+            start_r = offsets_r.as_mut_ptr();\n+            end_r = offsets_r.as_mut_ptr();\n+            let mut elem = r;\n+\n+            for i in 0..block_r {\n+                unsafe {\n+                    // Branchless comparison.\n+                    elem = elem.offset(-1);\n+                    *end_r = i as u8;\n+                    end_r = end_r.offset(is_less(&*elem, pivot) as isize);\n+                }\n+            }\n+        }\n+\n+        // Number of out-of-order elements to swap between the left and right side.\n+        let count = cmp::min(width(start_l, end_l), width(start_r, end_r));\n+\n+        if count > 0 {\n+            macro_rules! left { () => { l.offset(*start_l as isize) } }\n+            macro_rules! right { () => { r.offset(-(*start_r as isize) - 1) } }\n+\n+            // Instead of swapping one pair at the time, it is more efficient to perform a cyclic\n+            // permutation. This is not strictly equivalent to swapping, but produces a similar\n+            // result using fewer memory operations.\n+            unsafe {\n+                let tmp = ptr::read(left!());\n+                ptr::copy_nonoverlapping(right!(), left!(), 1);\n+\n+                for _ in 1..count {\n+                    start_l = start_l.offset(1);\n+                    ptr::copy_nonoverlapping(left!(), right!(), 1);\n+                    start_r = start_r.offset(1);\n+                    ptr::copy_nonoverlapping(right!(), left!(), 1);\n+                }\n+\n+                ptr::copy_nonoverlapping(&tmp, right!(), 1);\n+                mem::forget(tmp);\n+                start_l = start_l.offset(1);\n+                start_r = start_r.offset(1);\n+            }\n+        }\n+\n+        if start_l == end_l {\n+            // All out-of-order elements in the left block were moved. Move to the next block.\n+            l = unsafe { l.offset(block_l as isize) };\n+        }\n+\n+        if start_r == end_r {\n+            // All out-of-order elements in the right block were moved. Move to the previous block.\n+            r = unsafe { r.offset(-(block_r as isize)) };\n+        }\n+\n+        if is_done {\n+            break;\n+        }\n+    }\n+\n+    // All that remains now is at most one block (either the left or the right) with out-of-order\n+    // elements that need to be moved. Such remaining elements can be simply shifted to the end\n+    // within their block.\n+\n+    if start_l < end_l {\n+        // The left block remains.\n+        // Move it's remaining out-of-order elements to the far right.\n+        debug_assert_eq!(width(l, r), block_l);\n+        while start_l < end_l {\n+            unsafe {\n+                end_l = end_l.offset(-1);\n+                ptr::swap(l.offset(*end_l as isize), r.offset(-1));\n+                r = r.offset(-1);\n+            }\n+        }\n+        width(v.as_mut_ptr(), r)\n+    } else if start_r < end_r {\n+        // The right block remains.\n+        // Move it's remaining out-of-order elements to the far left.\n+        debug_assert_eq!(width(l, r), block_r);\n+        while start_r < end_r {\n+            unsafe {\n+                end_r = end_r.offset(-1);\n+                ptr::swap(l, r.offset(-(*end_r as isize) - 1));\n+                l = l.offset(1);\n+            }\n+        }\n+        width(v.as_mut_ptr(), l)\n+    } else {\n+        // Nothing else to do, we're done.\n+        width(v.as_mut_ptr(), l)\n+    }\n+}\n+\n+/// Partitions `v` into elements smaller than `v[pivot]`, followed by elements greater than or\n+/// equal to `v[pivot]`.\n+///\n+/// Returns a tuple of:\n+///\n+/// 1. Number of elements smaller than `v[pivot]`.\n+/// 2. True if `v` was already partitioned.\n+fn partition<T, F>(v: &mut [T], pivot: usize, is_less: &mut F) -> (usize, bool)\n+    where F: FnMut(&T, &T) -> bool\n+{\n+    let (mid, was_partitioned) = {\n+        // Place the pivot at the beginning of slice.\n+        v.swap(0, pivot);\n+        let (pivot, v) = v.split_at_mut(1);\n+        let pivot = &mut pivot[0];\n+\n+        // Read the pivot into a stack-allocated variable for efficiency. If a following comparison\n+        // operation panics, the pivot will be automatically written back into the slice.\n+        let mut tmp = NoDrop { value: unsafe { ptr::read(pivot) } };\n+        let _pivot_guard = CopyOnDrop {\n+            src: unsafe { &mut tmp.value },\n+            dest: pivot,\n+        };\n+        let pivot = unsafe { &tmp.value };\n+\n+        // Find the first pair of out-of-order elements.\n+        let mut l = 0;\n+        let mut r = v.len();\n+        unsafe {\n+            // Find the first element greater then or equal to the pivot.\n+            while l < r && is_less(v.get_unchecked(l), pivot) {\n+                l += 1;\n+            }\n+\n+            // Find the last element lesser that the pivot.\n+            while l < r && !is_less(v.get_unchecked(r - 1), pivot) {\n+                r -= 1;\n+            }\n+        }\n+\n+        (l + partition_in_blocks(&mut v[l..r], pivot, is_less), l >= r)\n+\n+        // `_pivot_guard` goes out of scope and writes the pivot (which is a stack-allocated\n+        // variable) back into the slice where it originally was. This step is critical in ensuring\n+        // safety!\n+    };\n+\n+    // Place the pivot between the two partitions.\n+    v.swap(0, mid);\n+\n+    (mid, was_partitioned)\n+}\n+\n+/// Partitions `v` into elements equal to `v[pivot]` followed by elements greater than `v[pivot]`.\n+///\n+/// Returns the number of elements equal to the pivot. It is assumed that `v` does not contain\n+/// elements smaller than the pivot.\n+fn partition_equal<T, F>(v: &mut [T], pivot: usize, is_less: &mut F) -> usize\n+    where F: FnMut(&T, &T) -> bool\n+{\n+    // Place the pivot at the beginning of slice.\n+    v.swap(0, pivot);\n+    let (pivot, v) = v.split_at_mut(1);\n+    let pivot = &mut pivot[0];\n+\n+    // Read the pivot into a stack-allocated variable for efficiency. If a following comparison\n+    // operation panics, the pivot will be automatically written back into the slice.\n+    let mut tmp = NoDrop { value: unsafe { ptr::read(pivot) } };\n+    let _pivot_guard = CopyOnDrop {\n+        src: unsafe { &mut tmp.value },\n+        dest: pivot,\n+    };\n+    let pivot = unsafe { &tmp.value };\n+\n+    // Now partition the slice.\n+    let mut l = 0;\n+    let mut r = v.len();\n+    loop {\n+        unsafe {\n+            // Find the first element greater that the pivot.\n+            while l < r && !is_less(pivot, v.get_unchecked(l)) {\n+                l += 1;\n+            }\n+\n+            // Find the last element equal to the pivot.\n+            while l < r && is_less(pivot, v.get_unchecked(r - 1)) {\n+                r -= 1;\n+            }\n+\n+            // Are we done?\n+            if l >= r {\n+                break;\n+            }\n+\n+            // Swap the found pair of out-of-order elements.\n+            r -= 1;\n+            ptr::swap(v.get_unchecked_mut(l), v.get_unchecked_mut(r));\n+            l += 1;\n+        }\n+    }\n+\n+    // We found `l` elements equal to the pivot. Add 1 to account for the pivot itself.\n+    l + 1\n+\n+    // `_pivot_guard` goes out of scope and writes the pivot (which is a stack-allocated variable)\n+    // back into the slice where it originally was. This step is critical in ensuring safety!\n+}\n+\n+/// Scatters some elements around in an attempt to break patterns that might cause imbalanced\n+/// partitions in quicksort.\n+#[cold]\n+fn break_patterns<T>(v: &mut [T]) {\n+    let len = v.len();\n+\n+    if len >= 8 {\n+        // A random number will be taken modulo this one. The modulus is a power of two so that we\n+        // can simply take bitwise \"and\", thus avoiding costly CPU operations.\n+        let modulus = (len / 4).next_power_of_two();\n+        debug_assert!(modulus >= 1 && modulus <= len / 2);\n+\n+        // Pseudorandom number generation from the \"Xorshift RNGs\" paper by George Marsaglia.\n+        let mut random = len;\n+        random ^= random << 13;\n+        random ^= random >> 17;\n+        random ^= random << 5;\n+        random &= modulus - 1;\n+        debug_assert!(random < len / 2);\n+\n+        // The first index.\n+        let a = len / 4 * 2;\n+        debug_assert!(a >= 1 && a < len - 2);\n+\n+        // The second index.\n+        let b = len / 4 + random;\n+        debug_assert!(b >= 1 && b < len - 2);\n+\n+        // Swap neighbourhoods of `a` and `b`.\n+        for i in 0..3 {\n+            v.swap(a - 1 + i, b - 1 + i);\n+        }\n+    }\n+}\n+\n+/// Chooses a pivot in `v` and returns it's index.\n+///\n+/// Elements in `v` might be reordered in the process.\n+fn choose_pivot<T, F>(v: &mut [T], is_less: &mut F) -> usize\n+    where F: FnMut(&T, &T) -> bool\n+{\n+    // Minimal length to choose the median-of-medians method.\n+    // Shorter slices use the simple median-of-three method.\n+    const SHORTEST_MEDIAN_OF_MEDIANS: usize = 90;\n+    // Maximal number of swaps that can be performed in this function.\n+    const MAX_SWAPS: usize = 4 * 3;\n+\n+    let len = v.len();\n+\n+    // Three indices near which we are going to choose a pivot.\n+    let mut a = len / 4 * 1;\n+    let mut b = len / 4 * 2;\n+    let mut c = len / 4 * 3;\n+\n+    // Counts the total number of swaps we are about to perform while sorting indices.\n+    let mut swaps = 0;\n+\n+    if len >= 8 {\n+        // Swaps indices so that `v[a] <= v[b]`.\n+        let mut sort2 = |a: &mut usize, b: &mut usize| unsafe {\n+            if is_less(v.get_unchecked(*b), v.get_unchecked(*a)) {\n+                ptr::swap(a, b);\n+                swaps += 1;\n+            }\n+        };\n+\n+        // Swaps indices so that `v[a] <= v[b] <= v[c]`.\n+        let mut sort3 = |a: &mut usize, b: &mut usize, c: &mut usize| {\n+            sort2(a, b);\n+            sort2(b, c);\n+            sort2(a, b);\n+        };\n+\n+        if len >= SHORTEST_MEDIAN_OF_MEDIANS {\n+            // Finds the median of `v[a - 1], v[a], v[a + 1]` and stores the index into `a`.\n+            let mut sort_adjacent = |a: &mut usize| {\n+                let tmp = *a;\n+                sort3(&mut (tmp - 1), a, &mut (tmp + 1));\n+            };\n+\n+            // Find medians in the neighborhoods of `a`, `b`, and `c`.\n+            sort_adjacent(&mut a);\n+            sort_adjacent(&mut b);\n+            sort_adjacent(&mut c);\n+        }\n+\n+        // Find the median among `a`, `b`, and `c`.\n+        sort3(&mut a, &mut b, &mut c);\n+    }\n+\n+    if swaps < MAX_SWAPS {\n+        b\n+    } else {\n+        // The maximal number of swaps was performed. Chances are the slice is descending or mostly\n+        // descending, so reversing will probably help sort it faster.\n+        v.reverse();\n+        len - 1 - b\n+    }\n+}\n+\n+/// Sorts `v` recursively.\n+///\n+/// If the slice had a predecessor in the original array, it is specified as `pred`.\n+///\n+/// `limit` is the number of allowed imbalanced partitions before switching to `heapsort`. If zero,\n+/// this function will immediately switch to heapsort.\n+fn recurse<'a, T, F>(mut v: &'a mut [T], is_less: &mut F, mut pred: Option<&'a T>, mut limit: usize)\n+    where F: FnMut(&T, &T) -> bool\n+{\n+    // Slices of up to this length get sorted using insertion sort.\n+    const MAX_INSERTION: usize = 16;\n+\n+    // This is `true` if the last partitioning was balanced.\n+    let mut was_balanced = true;\n+\n+    loop {\n+        let len = v.len();\n+\n+        // Very short slices get sorted using insertion sort.\n+        if len <= MAX_INSERTION {\n+            insertion_sort(v, is_less);\n+            return;\n+        }\n+\n+        // If too many bad pivot choices were made, simply fall back to heapsort in order to\n+        // guarantee `O(n log n)` worst-case.\n+        if limit == 0 {\n+            heapsort(v, is_less);\n+            return;\n+        }\n+\n+        // If the last partitioning was imbalanced, try breaking patterns in the slice by shuffling\n+        // some elements around. Hopefully we'll choose a better pivot this time.\n+        if !was_balanced {\n+            break_patterns(v);\n+            limit -= 1;\n+        }\n+\n+        let pivot = choose_pivot(v, is_less);\n+\n+        // If the chosen pivot is equal to the predecessor, then it's the smallest element in the\n+        // slice. Partition the slice into elements equal to and elements greater than the pivot.\n+        // This case is usually hit when the slice contains many duplicate elements.\n+        if let Some(p) = pred {\n+            if !is_less(p, &v[pivot]) {\n+                let mid = partition_equal(v, pivot, is_less);\n+\n+                // Continue sorting elements greater than the pivot.\n+                v = &mut {v}[mid..];\n+                continue;\n+            }\n+        }\n+\n+        let (mid, was_partitioned) = partition(v, pivot, is_less);\n+        was_balanced = cmp::min(mid, len - mid) >= len / 8;\n+\n+        // If the partitioning is decently balanced and the slice was already partitioned, there\n+        // are good chances it is also completely sorted. If so, we're done.\n+        if was_balanced && was_partitioned && v.windows(2).all(|w| !is_less(&w[1], &w[0])) {\n+            return;\n+        }\n+\n+        // Split the slice into `left`, `pivot`, and `right`.\n+        let (left, right) = {v}.split_at_mut(mid);\n+        let (pivot, right) = right.split_at_mut(1);\n+        let pivot = &pivot[0];\n+\n+        // Recurse into the shorter side only in order to minimize the total number of recursive\n+        // calls and consume less stack space. Then just continue with the longer side (this is\n+        // akin to tail recursion).\n+        if left.len() < right.len() {\n+            recurse(left, is_less, pred, limit);\n+            v = right;\n+            pred = Some(pivot);\n+        } else {\n+            recurse(right, is_less, Some(pivot), limit);\n+            v = left;\n+        }\n+    }\n+}\n+\n+/// Sorts `v` using pattern-defeating quicksort, which is `O(n log n)` worst-case.\n+pub fn quicksort<T, F>(v: &mut [T], mut is_less: F)\n+    where F: FnMut(&T, &T) -> bool\n+{\n+    // Sorting has no meaningful behavior on zero-sized types.\n+    if mem::size_of::<T>() == 0 {\n+        return;\n+    }\n+\n+    // Limit the number of imbalanced partitions to `floor(log2(len)) + 2`.\n+    let limit = mem::size_of::<usize>() * 8 - v.len().leading_zeros() as usize + 1;\n+\n+    recurse(v, &mut is_less, None, limit);\n+}"}, {"sha": "e8dbbd55df25923c8ab8eeda451775102cbc3ef2", "filename": "src/libcoretest/lib.rs", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcoretest%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcoretest%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcoretest%2Flib.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -19,18 +19,22 @@\n #![feature(decode_utf8)]\n #![feature(fixed_size_array)]\n #![feature(flt2dec)]\n+#![feature(fmt_internals)]\n #![feature(libc)]\n+#![feature(move_cell)]\n #![feature(nonzero)]\n+#![feature(ordering_chaining)]\n+#![feature(ptr_unaligned)]\n #![feature(rand)]\n #![feature(raw)]\n #![feature(sip_hash_13)]\n #![feature(slice_patterns)]\n+#![feature(sort_unstable)]\n #![feature(step_by)]\n #![feature(test)]\n #![feature(try_from)]\n #![feature(unicode)]\n #![feature(unique)]\n-#![feature(fmt_internals)]\n \n extern crate core;\n extern crate test;"}, {"sha": "b51bae4db225196225f356b746ec6c07e8f498a0", "filename": "src/libcoretest/slice.rs", "status": "modified", "additions": 38, "deletions": 3, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcoretest%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f1913e2a305f2ad9a655cb0a08cbce886e37ac27/src%2Flibcoretest%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcoretest%2Fslice.rs?ref=f1913e2a305f2ad9a655cb0a08cbce886e37ac27", "patch": "@@ -9,6 +9,7 @@\n // except according to those terms.\n \n use core::result::Result::{Ok, Err};\n+use rand::{Rng, XorShiftRng};\n \n #[test]\n fn test_binary_search() {\n@@ -139,9 +140,6 @@ fn test_chunks_mut_last() {\n     assert_eq!(c2.last().unwrap()[0], 4);\n }\n \n-\n-\n-\n #[test]\n fn test_windows_count() {\n     let v: &[i32] = &[0, 1, 2, 3, 4, 5];\n@@ -224,3 +222,40 @@ fn get_unchecked_mut_range() {\n         assert_eq!(v.get_unchecked_mut(1..4), &mut [1, 2, 3][..]);\n     }\n }\n+\n+#[test]\n+fn sort_unstable() {\n+    let mut v = [0; 600];\n+    let mut v1 = [0; 600];\n+    let mut rng = XorShiftRng::new_unseeded();\n+\n+    for len in (2..25).chain(500..510) {\n+        for &modulus in &[10, 1000] {\n+            for _ in 0..100 {\n+                for i in 0..len {\n+                    let num = rng.gen::<i32>() % modulus;\n+                    v[i] = num;\n+                    v1[i] = num;\n+                }\n+\n+                v.sort_unstable();\n+                assert!(v.windows(2).all(|w| w[0] <= w[1]));\n+\n+                v1.sort_unstable_by(|a, b| a.cmp(b));\n+                assert!(v1.windows(2).all(|w| w[0] <= w[1]));\n+\n+                v1.sort_unstable_by(|a, b| b.cmp(a));\n+                assert!(v1.windows(2).all(|w| w[0] >= w[1]));\n+            }\n+        }\n+    }\n+\n+    // Should not panic.\n+    [0i32; 0].sort_unstable();\n+    [(); 10].sort_unstable();\n+    [(); 100].sort_unstable();\n+\n+    let mut v = [0xDEADBEEFu64];\n+    v.sort_unstable();\n+    assert!(v == [0xDEADBEEF]);\n+}"}]}