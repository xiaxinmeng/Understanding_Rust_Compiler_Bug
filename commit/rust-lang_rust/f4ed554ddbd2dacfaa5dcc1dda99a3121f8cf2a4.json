{"sha": "f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY0ZWQ1NTRkZGJkMmRhY2ZhYTVkY2MxZGRhOTlhMzEyMWY4Y2YyYTQ=", "commit": {"author": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2013-05-30T01:22:28Z"}, "committer": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2013-05-30T01:22:28Z"}, "message": "Merge remote-tracking branch 'brson/io' into incoming\n\nConflicts:\n\tsrc/libstd/rt/sched.rs", "tree": {"sha": "45f24486e6f2d6d39928462e40d2c4b5f3de2154", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/45f24486e6f2d6d39928462e40d2c4b5f3de2154"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "html_url": "https://github.com/rust-lang/rust/commit/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bd30285c8467b33b6fea16be79198f7492107af3", "url": "https://api.github.com/repos/rust-lang/rust/commits/bd30285c8467b33b6fea16be79198f7492107af3", "html_url": "https://github.com/rust-lang/rust/commit/bd30285c8467b33b6fea16be79198f7492107af3"}, {"sha": "134bb0f3eeed69bbf6dc672bbbfbc802f1a018a9", "url": "https://api.github.com/repos/rust-lang/rust/commits/134bb0f3eeed69bbf6dc672bbbfbc802f1a018a9", "html_url": "https://github.com/rust-lang/rust/commit/134bb0f3eeed69bbf6dc672bbbfbc802f1a018a9"}], "stats": {"total": 1016, "additions": 816, "deletions": 200}, "files": [{"sha": "ebfa9e263ef805f09874fbf9ed92481be2308b01", "filename": "src/libstd/rt/comm.rs", "status": "modified", "additions": 20, "deletions": 3, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fcomm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fcomm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fcomm.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -22,6 +22,7 @@ use ops::Drop;\n use kinds::Owned;\n use rt::sched::{Scheduler, Coroutine};\n use rt::local::Local;\n+use rt::rtio::EventLoop;\n use unstable::intrinsics::{atomic_xchg, atomic_load};\n use util::Void;\n use comm::{GenericChan, GenericSmartChan, GenericPort, Peekable};\n@@ -158,7 +159,7 @@ impl<T> PortOne<T> {\n \n         // Switch to the scheduler to put the ~Task into the Packet state.\n         let sched = Local::take::<Scheduler>();\n-        do sched.deschedule_running_task_and_then |task| {\n+        do sched.deschedule_running_task_and_then |sched, task| {\n             unsafe {\n                 // Atomically swap the task pointer into the Packet state, issuing\n                 // an acquire barrier to prevent reordering of the subsequent read\n@@ -172,9 +173,15 @@ impl<T> PortOne<T> {\n                     }\n                     STATE_ONE => {\n                         // Channel is closed. Switch back and check the data.\n+                        // NB: We have to drop back into the scheduler event loop here\n+                        // instead of switching immediately back or we could end up\n+                        // triggering infinite recursion on the scheduler's stack.\n                         let task: ~Coroutine = cast::transmute(task_as_state);\n-                        let sched = Local::take::<Scheduler>();\n-                        sched.resume_task_immediately(task);\n+                        let task = Cell(task);\n+                        do sched.event_loop.callback {\n+                            let sched = Local::take::<Scheduler>();\n+                            sched.resume_task_immediately(task.take());\n+                        }\n                     }\n                     _ => util::unreachable()\n                 }\n@@ -614,5 +621,15 @@ mod test {\n             }\n         }\n     }\n+\n+    #[test]\n+    fn recv_a_lot() {\n+        // Regression test that we don't run out of stack in scheduler context\n+        do run_in_newsched_task {\n+            let (port, chan) = stream();\n+            for 10000.times { chan.send(()) }\n+            for 10000.times { port.recv() }\n+        }\n+    }\n }\n "}, {"sha": "ffff54f00bbe7b90f662f7300824dbec76c87fe9", "filename": "src/libstd/rt/local.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Flocal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Flocal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flocal.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -85,30 +85,31 @@ impl Local for IoFactoryObject {\n \n #[cfg(test)]\n mod test {\n+    use rt::test::*;\n     use rt::sched::Scheduler;\n     use rt::uv::uvio::UvEventLoop;\n     use super::*;\n \n     #[test]\n     fn thread_local_scheduler_smoke_test() {\n-        let scheduler = ~UvEventLoop::new_scheduler();\n+        let scheduler = ~new_test_uv_sched();\n         Local::put(scheduler);\n         let _scheduler: ~Scheduler = Local::take();\n     }\n \n     #[test]\n     fn thread_local_scheduler_two_instances() {\n-        let scheduler = ~UvEventLoop::new_scheduler();\n+        let scheduler = ~new_test_uv_sched();\n         Local::put(scheduler);\n         let _scheduler: ~Scheduler = Local::take();\n-        let scheduler = ~UvEventLoop::new_scheduler();\n+        let scheduler = ~new_test_uv_sched();\n         Local::put(scheduler);\n         let _scheduler: ~Scheduler = Local::take();\n     }\n \n     #[test]\n     fn borrow_smoke_test() {\n-        let scheduler = ~UvEventLoop::new_scheduler();\n+        let scheduler = ~new_test_uv_sched();\n         Local::put(scheduler);\n         unsafe {\n             let _scheduler: *mut Scheduler = Local::unsafe_borrow();"}, {"sha": "21711bbe84c7095acb0e99a620aba116112d1e6c", "filename": "src/libstd/rt/message_queue.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fmessage_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fmessage_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmessage_queue.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -8,6 +8,9 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+//! A concurrent queue that supports multiple producers and a\n+//! single consumer.\n+\n use container::Container;\n use kinds::Owned;\n use vec::OwnedVector;"}, {"sha": "1113d7abe7dcb3c8d2091fcf9287ea5ee840c40d", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 13, "deletions": 7, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -88,6 +88,9 @@ mod work_queue;\n /// A parallel queue.\n mod message_queue;\n \n+/// A parallel data structure for tracking sleeping schedulers.\n+mod sleeper_list;\n+\n /// Stack segments and caching.\n mod stack;\n \n@@ -145,12 +148,17 @@ pub mod thread_local_storage;\n pub fn start(_argc: int, _argv: **u8, crate_map: *u8, main: ~fn()) -> int {\n \n     use self::sched::{Scheduler, Coroutine};\n+    use self::work_queue::WorkQueue;\n     use self::uv::uvio::UvEventLoop;\n+    use self::sleeper_list::SleeperList;\n \n     init(crate_map);\n \n     let loop_ = ~UvEventLoop::new();\n-    let mut sched = ~Scheduler::new(loop_);\n+    let work_queue = WorkQueue::new();\n+    let sleepers = SleeperList::new();\n+    let mut sched = ~Scheduler::new(loop_, work_queue, sleepers);\n+    sched.no_sleep = true;\n     let main_task = ~Coroutine::new(&mut sched.stack_pool, main);\n \n     sched.enqueue_task(main_task);\n@@ -221,20 +229,18 @@ fn test_context() {\n     use rt::uv::uvio::UvEventLoop;\n     use cell::Cell;\n     use rt::local::Local;\n+    use rt::test::new_test_uv_sched;\n \n     assert_eq!(context(), OldTaskContext);\n     do run_in_bare_thread {\n         assert_eq!(context(), GlobalContext);\n-        let mut sched = ~UvEventLoop::new_scheduler();\n+        let mut sched = ~new_test_uv_sched();\n         let task = ~do Coroutine::new(&mut sched.stack_pool) {\n             assert_eq!(context(), TaskContext);\n             let sched = Local::take::<Scheduler>();\n-            do sched.deschedule_running_task_and_then() |task| {\n+            do sched.deschedule_running_task_and_then() |sched, task| {\n                 assert_eq!(context(), SchedulerContext);\n-                let task = Cell(task);\n-                do Local::borrow::<Scheduler> |sched| {\n-                    sched.enqueue_task(task.take());\n-                }\n+                sched.enqueue_task(task);\n             }\n         };\n         sched.enqueue_task(task);"}, {"sha": "fa657555f3aa0fc6f8012a9ad164746f7a1ae6a1", "filename": "src/libstd/rt/rtio.rs", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Frtio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Frtio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Frtio.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -18,6 +18,7 @@ use rt::uv::uvio;\n // XXX: ~object doesn't work currently so these are some placeholder\n // types to use instead\n pub type EventLoopObject = uvio::UvEventLoop;\n+pub type RemoteCallbackObject = uvio::UvRemoteCallback;\n pub type IoFactoryObject = uvio::UvIoFactory;\n pub type RtioTcpStreamObject = uvio::UvTcpStream;\n pub type RtioTcpListenerObject = uvio::UvTcpListener;\n@@ -26,10 +27,20 @@ pub trait EventLoop {\n     fn run(&mut self);\n     fn callback(&mut self, ~fn());\n     fn callback_ms(&mut self, ms: u64, ~fn());\n+    fn remote_callback(&mut self, ~fn()) -> ~RemoteCallbackObject;\n     /// The asynchronous I/O services. Not all event loops may provide one\n     fn io<'a>(&'a mut self) -> Option<&'a mut IoFactoryObject>;\n }\n \n+pub trait RemoteCallback {\n+    /// Trigger the remote callback. Note that the number of times the callback\n+    /// is run is not guaranteed. All that is guaranteed is that, after calling 'fire',\n+    /// the callback will be called at least once, but multiple callbacks may be coalesced\n+    /// and callbacks may be called more often requested. Destruction also triggers the\n+    /// callback.\n+    fn fire(&mut self);\n+}\n+\n pub trait IoFactory {\n     fn tcp_connect(&mut self, addr: IpAddr) -> Result<~RtioTcpStreamObject, IoError>;\n     fn tcp_bind(&mut self, addr: IpAddr) -> Result<~RtioTcpListenerObject, IoError>;"}, {"sha": "089c95cd7cd532c8a81140b8c0024ae6a68e40c2", "filename": "src/libstd/rt/sched.rs", "status": "modified", "additions": 266, "deletions": 63, "changes": 329, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fsched.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -12,21 +12,44 @@ use option::*;\n use sys;\n use cast::transmute;\n use cell::Cell;\n+use clone::Clone;\n \n+use super::sleeper_list::SleeperList;\n use super::work_queue::WorkQueue;\n use super::stack::{StackPool, StackSegment};\n-use super::rtio::{EventLoop, EventLoopObject};\n+use super::rtio::{EventLoop, EventLoopObject, RemoteCallbackObject};\n use super::context::Context;\n use super::task::Task;\n+use super::message_queue::MessageQueue;\n use rt::local_ptr;\n use rt::local::Local;\n+use rt::rtio::{IoFactoryObject, RemoteCallback};\n \n /// The Scheduler is responsible for coordinating execution of Coroutines\n /// on a single thread. When the scheduler is running it is owned by\n /// thread local storage and the running task is owned by the\n /// scheduler.\n pub struct Scheduler {\n+    /// A queue of available work. Under a work-stealing policy there\n+    /// is one per Scheduler.\n     priv work_queue: WorkQueue<~Coroutine>,\n+    /// The queue of incoming messages from other schedulers.\n+    /// These are enqueued by SchedHandles after which a remote callback\n+    /// is triggered to handle the message.\n+    priv message_queue: MessageQueue<SchedMessage>,\n+    /// A shared list of sleeping schedulers. We'll use this to wake\n+    /// up schedulers when pushing work onto the work queue.\n+    priv sleeper_list: SleeperList,\n+    /// Indicates that we have previously pushed a handle onto the\n+    /// SleeperList but have not yet received the Wake message.\n+    /// Being `true` does not necessarily mean that the scheduler is\n+    /// not active since there are multiple event sources that may\n+    /// wake the scheduler. It just prevents the scheduler from pushing\n+    /// multiple handles onto the sleeper list.\n+    priv sleepy: bool,\n+    /// A flag to indicate we've received the shutdown message and should\n+    /// no longer try to go to sleep, but exit instead.\n+    no_sleep: bool,\n     stack_pool: StackPool,\n     /// The event loop used to drive the scheduler and perform I/O\n     event_loop: ~EventLoopObject,\n@@ -40,16 +63,25 @@ pub struct Scheduler {\n     priv cleanup_job: Option<CleanupJob>\n }\n \n-// XXX: Some hacks to put a &fn in Scheduler without borrowck\n-// complaining\n-type UnsafeTaskReceiver = sys::Closure;\n-trait ClosureConverter {\n-    fn from_fn(&fn(~Coroutine)) -> Self;\n-    fn to_fn(self) -> &fn(~Coroutine);\n+pub struct SchedHandle {\n+    priv remote: ~RemoteCallbackObject,\n+    priv queue: MessageQueue<SchedMessage>\n }\n-impl ClosureConverter for UnsafeTaskReceiver {\n-    fn from_fn(f: &fn(~Coroutine)) -> UnsafeTaskReceiver { unsafe { transmute(f) } }\n-    fn to_fn(self) -> &fn(~Coroutine) { unsafe { transmute(self) } }\n+\n+pub struct Coroutine {\n+    /// The segment of stack on which the task is currently running or,\n+    /// if the task is blocked, on which the task will resume execution\n+    priv current_stack_segment: StackSegment,\n+    /// These are always valid when the task is not running, unless\n+    /// the task is dead\n+    priv saved_context: Context,\n+    /// The heap, GC, unwinding, local storage, logging\n+    task: ~Task\n+}\n+\n+pub enum SchedMessage {\n+    Wake,\n+    Shutdown\n }\n \n enum CleanupJob {\n@@ -61,18 +93,25 @@ pub impl Scheduler {\n \n     fn in_task_context(&self) -> bool { self.current_task.is_some() }\n \n-    fn new(event_loop: ~EventLoopObject) -> Scheduler {\n+    fn new(event_loop: ~EventLoopObject,\n+           work_queue: WorkQueue<~Coroutine>,\n+           sleeper_list: SleeperList)\n+        -> Scheduler {\n \n         // Lazily initialize the runtime TLS key\n         local_ptr::init_tls_key();\n \n         Scheduler {\n+            sleeper_list: sleeper_list,\n+            message_queue: MessageQueue::new(),\n+            sleepy: false,\n+            no_sleep: false,\n             event_loop: event_loop,\n-            work_queue: WorkQueue::new(),\n+            work_queue: work_queue,\n             stack_pool: StackPool::new(),\n             saved_context: Context::empty(),\n             current_task: None,\n-            cleanup_job: None\n+            cleanup_job: None,\n         }\n     }\n \n@@ -102,24 +141,117 @@ pub impl Scheduler {\n         return sched;\n     }\n \n+    fn run_sched_once() {\n+\n+        let sched = Local::take::<Scheduler>();\n+        if sched.interpret_message_queue() {\n+            // We performed a scheduling action. There may be other work\n+            // to do yet, so let's try again later.\n+            let mut sched = Local::take::<Scheduler>();\n+            sched.event_loop.callback(Scheduler::run_sched_once);\n+            Local::put(sched);\n+            return;\n+        }\n+\n+        let sched = Local::take::<Scheduler>();\n+        if sched.resume_task_from_queue() {\n+            // We performed a scheduling action. There may be other work\n+            // to do yet, so let's try again later.\n+            let mut sched = Local::take::<Scheduler>();\n+            sched.event_loop.callback(Scheduler::run_sched_once);\n+            Local::put(sched);\n+            return;\n+        }\n+\n+        // If we got here then there was no work to do.\n+        // Generate a SchedHandle and push it to the sleeper list so\n+        // somebody can wake us up later.\n+        rtdebug!(\"no work to do\");\n+        let mut sched = Local::take::<Scheduler>();\n+        if !sched.sleepy && !sched.no_sleep {\n+            rtdebug!(\"sleeping\");\n+            sched.sleepy = true;\n+            let handle = sched.make_handle();\n+            sched.sleeper_list.push(handle);\n+        } else {\n+            rtdebug!(\"not sleeping\");\n+        }\n+        Local::put(sched);\n+    }\n+\n+    fn make_handle(&mut self) -> SchedHandle {\n+        let remote = self.event_loop.remote_callback(Scheduler::run_sched_once);\n+\n+        return SchedHandle {\n+            remote: remote,\n+            queue: self.message_queue.clone()\n+        };\n+    }\n+\n     /// Schedule a task to be executed later.\n     ///\n     /// Pushes the task onto the work stealing queue and tells the event loop\n     /// to run it later. Always use this instead of pushing to the work queue\n     /// directly.\n     fn enqueue_task(&mut self, task: ~Coroutine) {\n         self.work_queue.push(task);\n-        self.event_loop.callback(resume_task_from_queue);\n+        self.event_loop.callback(Scheduler::run_sched_once);\n \n-        fn resume_task_from_queue() {\n-            let scheduler = Local::take::<Scheduler>();\n-            scheduler.resume_task_from_queue();\n+        // We've made work available. Notify a sleeping scheduler.\n+        match self.sleeper_list.pop() {\n+            Some(handle) => {\n+                let mut handle = handle;\n+                handle.send(Wake)\n+            }\n+            None => (/* pass */)\n         }\n     }\n \n     // * Scheduler-context operations\n \n-    fn resume_task_from_queue(~self) {\n+    fn interpret_message_queue(~self) -> bool {\n+        assert!(!self.in_task_context());\n+\n+        rtdebug!(\"looking for scheduler messages\");\n+\n+        let mut this = self;\n+        match this.message_queue.pop() {\n+            Some(Wake) => {\n+                rtdebug!(\"recv Wake message\");\n+                this.sleepy = false;\n+                Local::put(this);\n+                return true;\n+            }\n+            Some(Shutdown) => {\n+                rtdebug!(\"recv Shutdown message\");\n+                if this.sleepy {\n+                    // There may be an outstanding handle on the sleeper list.\n+                    // Pop them all to make sure that's not the case.\n+                    loop {\n+                        match this.sleeper_list.pop() {\n+                            Some(handle) => {\n+                                let mut handle = handle;\n+                                handle.send(Wake);\n+                            }\n+                            None => (/* pass */)\n+                        }\n+                    }\n+                }\n+                // No more sleeping. After there are no outstanding event loop\n+                // references we will shut down.\n+                this.no_sleep = true;\n+                this.sleepy = false;\n+                Local::put(this);\n+                return true;\n+            }\n+            None => {\n+                Local::put(this);\n+                return false;\n+            }\n+        }\n+    }\n+\n+    fn resume_task_from_queue(~self) -> bool {\n         assert!(!self.in_task_context());\n \n         rtdebug!(\"looking in work queue for task to schedule\");\n@@ -129,10 +261,12 @@ pub impl Scheduler {\n             Some(task) => {\n                 rtdebug!(\"resuming task from work queue\");\n                 this.resume_task_immediately(task);\n+                return true;\n             }\n             None => {\n                 rtdebug!(\"no tasks in queue\");\n                 Local::put(this);\n+                return false;\n             }\n         }\n     }\n@@ -146,11 +280,9 @@ pub impl Scheduler {\n \n         rtdebug!(\"ending running task\");\n \n-        do self.deschedule_running_task_and_then |dead_task| {\n+        do self.deschedule_running_task_and_then |sched, dead_task| {\n             let dead_task = Cell(dead_task);\n-            do Local::borrow::<Scheduler> |sched| {\n-                dead_task.take().recycle(&mut sched.stack_pool);\n-            }\n+            dead_task.take().recycle(&mut sched.stack_pool);\n         }\n \n         abort!(\"control reached end of task\");\n@@ -159,22 +291,18 @@ pub impl Scheduler {\n     fn schedule_new_task(~self, task: ~Coroutine) {\n         assert!(self.in_task_context());\n \n-        do self.switch_running_tasks_and_then(task) |last_task| {\n+        do self.switch_running_tasks_and_then(task) |sched, last_task| {\n             let last_task = Cell(last_task);\n-            do Local::borrow::<Scheduler> |sched| {\n-                sched.enqueue_task(last_task.take());\n-            }\n+            sched.enqueue_task(last_task.take());\n         }\n     }\n \n     fn schedule_task(~self, task: ~Coroutine) {\n         assert!(self.in_task_context());\n \n-        do self.switch_running_tasks_and_then(task) |last_task| {\n+        do self.switch_running_tasks_and_then(task) |sched, last_task| {\n             let last_task = Cell(last_task);\n-            do Local::borrow::<Scheduler> |sched| {\n-                sched.enqueue_task(last_task.take());\n-            }\n+            sched.enqueue_task(last_task.take());\n         }\n     }\n \n@@ -218,15 +346,20 @@ pub impl Scheduler {\n     /// The closure here is a *stack* closure that lives in the\n     /// running task.  It gets transmuted to the scheduler's lifetime\n     /// and called while the task is blocked.\n-    fn deschedule_running_task_and_then(~self, f: &fn(~Coroutine)) {\n+    ///\n+    /// This passes a Scheduler pointer to the fn after the context switch\n+    /// in order to prevent that fn from performing further scheduling operations.\n+    /// Doing further scheduling could easily result in infinite recursion.\n+    fn deschedule_running_task_and_then(~self, f: &fn(&mut Scheduler, ~Coroutine)) {\n         let mut this = self;\n         assert!(this.in_task_context());\n \n         rtdebug!(\"blocking task\");\n \n         unsafe {\n             let blocked_task = this.current_task.swap_unwrap();\n-            let f_fake_region = transmute::<&fn(~Coroutine), &fn(~Coroutine)>(f);\n+            let f_fake_region = transmute::<&fn(&mut Scheduler, ~Coroutine),\n+                                            &fn(&mut Scheduler, ~Coroutine)>(f);\n             let f_opaque = ClosureConverter::from_fn(f_fake_region);\n             this.enqueue_cleanup_job(GiveTask(blocked_task, f_opaque));\n         }\n@@ -248,14 +381,18 @@ pub impl Scheduler {\n     /// Switch directly to another task, without going through the scheduler.\n     /// You would want to think hard about doing this, e.g. if there are\n     /// pending I/O events it would be a bad idea.\n-    fn switch_running_tasks_and_then(~self, next_task: ~Coroutine, f: &fn(~Coroutine)) {\n+    fn switch_running_tasks_and_then(~self, next_task: ~Coroutine,\n+                                     f: &fn(&mut Scheduler, ~Coroutine)) {\n         let mut this = self;\n         assert!(this.in_task_context());\n \n         rtdebug!(\"switching tasks\");\n \n         let old_running_task = this.current_task.swap_unwrap();\n-        let f_fake_region = unsafe { transmute::<&fn(~Coroutine), &fn(~Coroutine)>(f) };\n+        let f_fake_region = unsafe {\n+            transmute::<&fn(&mut Scheduler, ~Coroutine),\n+                        &fn(&mut Scheduler, ~Coroutine)>(f)\n+        };\n         let f_opaque = ClosureConverter::from_fn(f_fake_region);\n         this.enqueue_cleanup_job(GiveTask(old_running_task, f_opaque));\n         this.current_task = Some(next_task);\n@@ -292,7 +429,7 @@ pub impl Scheduler {\n         let cleanup_job = self.cleanup_job.swap_unwrap();\n         match cleanup_job {\n             DoNothing => { }\n-            GiveTask(task, f) => (f.to_fn())(task)\n+            GiveTask(task, f) => (f.to_fn())(self, task)\n         }\n     }\n \n@@ -336,17 +473,11 @@ pub impl Scheduler {\n     }\n }\n \n-static MIN_STACK_SIZE: uint = 10000000; // XXX: Too much stack\n-\n-pub struct Coroutine {\n-    /// The segment of stack on which the task is currently running or,\n-    /// if the task is blocked, on which the task will resume execution\n-    priv current_stack_segment: StackSegment,\n-    /// These are always valid when the task is not running, unless\n-    /// the task is dead\n-    priv saved_context: Context,\n-    /// The heap, GC, unwinding, local storage, logging\n-    task: ~Task\n+impl SchedHandle {\n+    pub fn send(&mut self, msg: SchedMessage) {\n+        self.queue.push(msg);\n+        self.remote.fire();\n+    }\n }\n \n pub impl Coroutine {\n@@ -357,6 +488,9 @@ pub impl Coroutine {\n     fn with_task(stack_pool: &mut StackPool,\n                   task: ~Task,\n                   start: ~fn()) -> Coroutine {\n+\n+        static MIN_STACK_SIZE: uint = 10000000; // XXX: Too much stack\n+\n         let start = Coroutine::build_start_wrapper(start);\n         let mut stack = stack_pool.take_segment(MIN_STACK_SIZE);\n         // NB: Context holds a pointer to that ~fn\n@@ -400,6 +534,18 @@ pub impl Coroutine {\n     }\n }\n \n+// XXX: Some hacks to put a &fn in Scheduler without borrowck\n+// complaining\n+type UnsafeTaskReceiver = sys::Closure;\n+trait ClosureConverter {\n+    fn from_fn(&fn(&mut Scheduler, ~Coroutine)) -> Self;\n+    fn to_fn(self) -> &fn(&mut Scheduler, ~Coroutine);\n+}\n+impl ClosureConverter for UnsafeTaskReceiver {\n+    fn from_fn(f: &fn(&mut Scheduler, ~Coroutine)) -> UnsafeTaskReceiver { unsafe { transmute(f) } }\n+    fn to_fn(self) -> &fn(&mut Scheduler, ~Coroutine) { unsafe { transmute(self) } }\n+}\n+\n #[cfg(test)]\n mod test {\n     use int;\n@@ -410,14 +556,15 @@ mod test {\n     use rt::local::Local;\n     use rt::test::*;\n     use super::*;\n+    use rt::thread::Thread;\n \n     #[test]\n     fn test_simple_scheduling() {\n         do run_in_bare_thread {\n             let mut task_ran = false;\n             let task_ran_ptr: *mut bool = &mut task_ran;\n \n-            let mut sched = ~UvEventLoop::new_scheduler();\n+            let mut sched = ~new_test_uv_sched();\n             let task = ~do Coroutine::new(&mut sched.stack_pool) {\n                 unsafe { *task_ran_ptr = true; }\n             };\n@@ -434,7 +581,7 @@ mod test {\n             let mut task_count = 0;\n             let task_count_ptr: *mut int = &mut task_count;\n \n-            let mut sched = ~UvEventLoop::new_scheduler();\n+            let mut sched = ~new_test_uv_sched();\n             for int::range(0, total) |_| {\n                 let task = ~do Coroutine::new(&mut sched.stack_pool) {\n                     unsafe { *task_count_ptr = *task_count_ptr + 1; }\n@@ -452,19 +599,17 @@ mod test {\n             let mut count = 0;\n             let count_ptr: *mut int = &mut count;\n \n-            let mut sched = ~UvEventLoop::new_scheduler();\n+            let mut sched = ~new_test_uv_sched();\n             let task1 = ~do Coroutine::new(&mut sched.stack_pool) {\n                 unsafe { *count_ptr = *count_ptr + 1; }\n                 let mut sched = Local::take::<Scheduler>();\n                 let task2 = ~do Coroutine::new(&mut sched.stack_pool) {\n                     unsafe { *count_ptr = *count_ptr + 1; }\n                 };\n                 // Context switch directly to the new task\n-                do sched.switch_running_tasks_and_then(task2) |task1| {\n+                do sched.switch_running_tasks_and_then(task2) |sched, task1| {\n                     let task1 = Cell(task1);\n-                    do Local::borrow::<Scheduler> |sched| {\n-                        sched.enqueue_task(task1.take());\n-                    }\n+                    sched.enqueue_task(task1.take());\n                 }\n                 unsafe { *count_ptr = *count_ptr + 1; }\n             };\n@@ -481,7 +626,7 @@ mod test {\n             let mut count = 0;\n             let count_ptr: *mut int = &mut count;\n \n-            let mut sched = ~UvEventLoop::new_scheduler();\n+            let mut sched = ~new_test_uv_sched();\n \n             let start_task = ~do Coroutine::new(&mut sched.stack_pool) {\n                 run_task(count_ptr);\n@@ -510,16 +655,14 @@ mod test {\n     #[test]\n     fn test_block_task() {\n         do run_in_bare_thread {\n-            let mut sched = ~UvEventLoop::new_scheduler();\n+            let mut sched = ~new_test_uv_sched();\n             let task = ~do Coroutine::new(&mut sched.stack_pool) {\n                 let sched = Local::take::<Scheduler>();\n                 assert!(sched.in_task_context());\n-                do sched.deschedule_running_task_and_then() |task| {\n+                do sched.deschedule_running_task_and_then() |sched, task| {\n                     let task = Cell(task);\n-                    do Local::borrow::<Scheduler> |sched| {\n-                        assert!(!sched.in_task_context());\n-                        sched.enqueue_task(task.take());\n-                    }\n+                    assert!(!sched.in_task_context());\n+                    sched.enqueue_task(task.take());\n                 }\n             };\n             sched.enqueue_task(task);\n@@ -536,18 +679,78 @@ mod test {\n         do run_in_newsched_task {\n             do spawn {\n                 let sched = Local::take::<Scheduler>();\n-                do sched.deschedule_running_task_and_then |task| {\n-                    let mut sched = Local::take::<Scheduler>();\n+                do sched.deschedule_running_task_and_then |sched, task| {\n                     let task = Cell(task);\n                     do sched.event_loop.callback_ms(10) {\n                         rtdebug!(\"in callback\");\n                         let mut sched = Local::take::<Scheduler>();\n                         sched.enqueue_task(task.take());\n                         Local::put(sched);\n                     }\n-                    Local::put(sched);\n                 }\n             }\n         }\n     }\n+\n+    #[test]\n+    fn handle() {\n+        use rt::comm::*;\n+\n+        do run_in_bare_thread {\n+            let (port, chan) = oneshot::<()>();\n+            let port_cell = Cell(port);\n+            let chan_cell = Cell(chan);\n+            let mut sched1 = ~new_test_uv_sched();\n+            let handle1 = sched1.make_handle();\n+            let handle1_cell = Cell(handle1);\n+            let task1 = ~do Coroutine::new(&mut sched1.stack_pool) {\n+                chan_cell.take().send(());\n+            };\n+            sched1.enqueue_task(task1);\n+\n+            let mut sched2 = ~new_test_uv_sched();\n+            let task2 = ~do Coroutine::new(&mut sched2.stack_pool) {\n+                port_cell.take().recv();\n+                // Release the other scheduler's handle so it can exit\n+                handle1_cell.take();\n+            };\n+            sched2.enqueue_task(task2);\n+\n+            let sched1_cell = Cell(sched1);\n+            let _thread1 = do Thread::start {\n+                let mut sched1 = sched1_cell.take();\n+                sched1.run();\n+            };\n+\n+            let sched2_cell = Cell(sched2);\n+            let _thread2 = do Thread::start {\n+                let mut sched2 = sched2_cell.take();\n+                sched2.run();\n+            };\n+        }\n+    }\n+\n+    #[test]\n+    fn multithreading() {\n+        use rt::comm::*;\n+        use iter::Times;\n+        use vec::OwnedVector;\n+        use container::Container;\n+\n+        do run_in_mt_newsched_task {\n+            let mut ports = ~[];\n+            for 10.times {\n+                let (port, chan) = oneshot();\n+                let chan_cell = Cell(chan);\n+                do spawntask_later {\n+                    chan_cell.take().send(());\n+                }\n+                ports.push(port);\n+            }\n+\n+            while !ports.is_empty() {\n+                ports.pop().recv();\n+            }\n+        }\n+    }\n }"}, {"sha": "dfcac8eb088f7853819b333d502310cd7f811fb2", "filename": "src/libstd/rt/sleeper_list.rs", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fsleeper_list.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fsleeper_list.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fsleeper_list.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -0,0 +1,55 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! Maintains a shared list of sleeping schedulers. Schedulers\n+//! use this to wake each other up.\n+\n+use container::Container;\n+use vec::OwnedVector;\n+use option::{Option, Some, None};\n+use cell::Cell;\n+use unstable::sync::{Exclusive, exclusive};\n+use rt::sched::{Scheduler, SchedHandle};\n+use clone::Clone;\n+\n+pub struct SleeperList {\n+    priv stack: ~Exclusive<~[SchedHandle]>\n+}\n+\n+impl SleeperList {\n+    pub fn new() -> SleeperList {\n+        SleeperList {\n+            stack: ~exclusive(~[])\n+        }\n+    }\n+\n+    pub fn push(&mut self, handle: SchedHandle) {\n+        let handle = Cell(handle);\n+        self.stack.with(|s| s.push(handle.take()));\n+    }\n+\n+    pub fn pop(&mut self) -> Option<SchedHandle> {\n+        do self.stack.with |s| {\n+            if !s.is_empty() {\n+                Some(s.pop())\n+            } else {\n+                None\n+            }\n+        }\n+    }\n+}\n+\n+impl Clone for SleeperList {\n+    fn clone(&self) -> SleeperList {\n+        SleeperList {\n+            stack: self.stack.clone()\n+        }\n+    }\n+}\n\\ No newline at end of file"}, {"sha": "16b0aef5e266bfffc53061d23a2b572c69b4a281", "filename": "src/libstd/rt/test.rs", "status": "modified", "additions": 89, "deletions": 26, "changes": 115, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftest.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -9,13 +9,32 @@\n // except according to those terms.\n \n use uint;\n-use option::*;\n+use option::{Option, Some, None};\n use cell::Cell;\n+use clone::Clone;\n+use container::Container;\n+use old_iter::MutableIter;\n+use vec::OwnedVector;\n use result::{Result, Ok, Err};\n+use unstable::run_in_bare_thread;\n use super::io::net::ip::{IpAddr, Ipv4};\n use rt::task::Task;\n use rt::thread::Thread;\n use rt::local::Local;\n+use rt::sched::{Scheduler, Coroutine};\n+use rt::sleeper_list::SleeperList;\n+use rt::work_queue::WorkQueue;\n+\n+pub fn new_test_uv_sched() -> Scheduler {\n+    use rt::uv::uvio::UvEventLoop;\n+    use rt::work_queue::WorkQueue;\n+    use rt::sleeper_list::SleeperList;\n+\n+    let mut sched = Scheduler::new(~UvEventLoop::new(), WorkQueue::new(), SleeperList::new());\n+    // Don't wait for the Shutdown message\n+    sched.no_sleep = true;\n+    return sched;\n+}\n \n /// Creates a new scheduler in a new thread and runs a task in it,\n /// then waits for the scheduler to exit. Failure of the task\n@@ -28,7 +47,7 @@ pub fn run_in_newsched_task(f: ~fn()) {\n     let f = Cell(f);\n \n     do run_in_bare_thread {\n-        let mut sched = ~UvEventLoop::new_scheduler();\n+        let mut sched = ~new_test_uv_sched();\n         let task = ~Coroutine::with_task(&mut sched.stack_pool,\n                                          ~Task::without_unwinding(),\n                                          f.take());\n@@ -37,6 +56,64 @@ pub fn run_in_newsched_task(f: ~fn()) {\n     }\n }\n \n+/// Create more than one scheduler and run a function in a task\n+/// in one of the schedulers. The schedulers will stay alive\n+/// until the function `f` returns.\n+pub fn run_in_mt_newsched_task(f: ~fn()) {\n+    use rt::uv::uvio::UvEventLoop;\n+    use rt::sched::Shutdown;\n+\n+    let f_cell = Cell(f);\n+\n+    do run_in_bare_thread {\n+        static N: uint = 2;\n+\n+        let sleepers = SleeperList::new();\n+        let work_queue = WorkQueue::new();\n+\n+        let mut handles = ~[];\n+        let mut scheds = ~[];\n+\n+        for uint::range(0, N) |i| {\n+            let loop_ = ~UvEventLoop::new();\n+            let mut sched = ~Scheduler::new(loop_, work_queue.clone(), sleepers.clone());\n+            let handle = sched.make_handle();\n+            handles.push(handle);\n+            scheds.push(sched);\n+        }\n+\n+        let f_cell = Cell(f_cell.take());\n+        let handles = Cell(handles);\n+        let main_task = ~do Coroutine::new(&mut scheds[0].stack_pool) {\n+            f_cell.take()();\n+\n+            let mut handles = handles.take();\n+            // Tell schedulers to exit\n+            for handles.each_mut |handle| {\n+                handle.send(Shutdown);\n+            }\n+        };\n+\n+        scheds[0].enqueue_task(main_task);\n+\n+        let mut threads = ~[];\n+\n+        while !scheds.is_empty() {\n+            let sched = scheds.pop();\n+            let sched_cell = Cell(sched);\n+            let thread = do Thread::start {\n+                let mut sched = sched_cell.take();\n+                sched.run();\n+            };\n+\n+            threads.push(thread);\n+        }\n+\n+        // Wait for schedulers\n+        let _threads = threads;\n+    }\n+}\n+\n /// Test tasks will abort on failure instead of unwinding\n pub fn spawntask(f: ~fn()) {\n     use super::sched::*;\n@@ -45,11 +122,7 @@ pub fn spawntask(f: ~fn()) {\n     let task = ~Coroutine::with_task(&mut sched.stack_pool,\n                                      ~Task::without_unwinding(),\n                                      f);\n-    do sched.switch_running_tasks_and_then(task) |task| {\n-        let task = Cell(task);\n-        let sched = Local::take::<Scheduler>();\n-        sched.schedule_new_task(task.take());\n-    }\n+    sched.schedule_new_task(task);\n }\n \n /// Create a new task and run it right now. Aborts on failure\n@@ -60,11 +133,8 @@ pub fn spawntask_immediately(f: ~fn()) {\n     let task = ~Coroutine::with_task(&mut sched.stack_pool,\n                                      ~Task::without_unwinding(),\n                                      f);\n-    do sched.switch_running_tasks_and_then(task) |task| {\n-        let task = Cell(task);\n-        do Local::borrow::<Scheduler> |sched| {\n-            sched.enqueue_task(task.take());\n-        }\n+    do sched.switch_running_tasks_and_then(task) |sched, task| {\n+        sched.enqueue_task(task);\n     }\n }\n \n@@ -95,11 +165,8 @@ pub fn spawntask_random(f: ~fn()) {\n                                      f);\n \n     if run_now {\n-        do sched.switch_running_tasks_and_then(task) |task| {\n-            let task = Cell(task);\n-            do Local::borrow::<Scheduler> |sched| {\n-                sched.enqueue_task(task.take());\n-            }\n+        do sched.switch_running_tasks_and_then(task) |sched, task| {\n+            sched.enqueue_task(task);\n         }\n     } else {\n         sched.enqueue_task(task);\n@@ -122,27 +189,23 @@ pub fn spawntask_try(f: ~fn()) -> Result<(), ()> {\n     // Switch to the scheduler\n     let f = Cell(Cell(f));\n     let sched = Local::take::<Scheduler>();\n-    do sched.deschedule_running_task_and_then() |old_task| {\n+    do sched.deschedule_running_task_and_then() |sched, old_task| {\n         let old_task = Cell(old_task);\n         let f = f.take();\n-        let mut sched = Local::take::<Scheduler>();\n         let new_task = ~do Coroutine::new(&mut sched.stack_pool) {\n             do (|| {\n                 (f.take())()\n             }).finally {\n                 // Check for failure then resume the parent task\n                 unsafe { *failed_ptr = task::failing(); }\n                 let sched = Local::take::<Scheduler>();\n-                do sched.switch_running_tasks_and_then(old_task.take()) |new_task| {\n-                    let new_task = Cell(new_task);\n-                    do Local::borrow::<Scheduler> |sched| {\n-                        sched.enqueue_task(new_task.take());\n-                    }\n+                do sched.switch_running_tasks_and_then(old_task.take()) |sched, new_task| {\n+                    sched.enqueue_task(new_task);\n                 }\n             }\n         };\n \n-        sched.resume_task_immediately(new_task);\n+        sched.enqueue_task(new_task);\n     }\n \n     if !failed { Ok(()) } else { Err(()) }\n@@ -155,7 +218,7 @@ pub fn spawntask_thread(f: ~fn()) -> Thread {\n \n     let f = Cell(f);\n     let thread = do Thread::start {\n-        let mut sched = ~UvEventLoop::new_scheduler();\n+        let mut sched = ~new_test_uv_sched();\n         let task = ~Coroutine::with_task(&mut sched.stack_pool,\n                                          ~Task::without_unwinding(),\n                                          f.take());"}, {"sha": "4482a92d916aaf683c7d9a97b5fe7d25b776b6bf", "filename": "src/libstd/rt/tube.rs", "status": "modified", "additions": 14, "deletions": 20, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Ftube.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Ftube.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftube.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -72,7 +72,7 @@ impl<T> Tube<T> {\n                 assert!(self.p.refcount() > 1); // There better be somebody to wake us up\n                 assert!((*state).blocked_task.is_none());\n                 let sched = Local::take::<Scheduler>();\n-                do sched.deschedule_running_task_and_then |task| {\n+                do sched.deschedule_running_task_and_then |_, task| {\n                     (*state).blocked_task = Some(task);\n                 }\n                 rtdebug!(\"waking after tube recv\");\n@@ -107,11 +107,10 @@ mod test {\n             let tube_clone = tube.clone();\n             let tube_clone_cell = Cell(tube_clone);\n             let sched = Local::take::<Scheduler>();\n-            do sched.deschedule_running_task_and_then |task| {\n+            do sched.deschedule_running_task_and_then |sched, task| {\n                 let mut tube_clone = tube_clone_cell.take();\n                 tube_clone.send(1);\n-                let sched = Local::take::<Scheduler>();\n-                sched.resume_task_immediately(task);\n+                sched.enqueue_task(task);\n             }\n \n             assert!(tube.recv() == 1);\n@@ -123,21 +122,17 @@ mod test {\n         do run_in_newsched_task {\n             let mut tube: Tube<int> = Tube::new();\n             let tube_clone = tube.clone();\n-            let tube_clone = Cell(Cell(Cell(tube_clone)));\n+            let tube_clone = Cell(tube_clone);\n             let sched = Local::take::<Scheduler>();\n-            do sched.deschedule_running_task_and_then |task| {\n-                let tube_clone = tube_clone.take();\n-                do Local::borrow::<Scheduler> |sched| {\n-                    let tube_clone = tube_clone.take();\n-                    do sched.event_loop.callback {\n-                        let mut tube_clone = tube_clone.take();\n-                        // The task should be blocked on this now and\n-                        // sending will wake it up.\n-                        tube_clone.send(1);\n-                    }\n+            do sched.deschedule_running_task_and_then |sched, task| {\n+                let tube_clone = Cell(tube_clone.take());\n+                do sched.event_loop.callback {\n+                    let mut tube_clone = tube_clone.take();\n+                    // The task should be blocked on this now and\n+                    // sending will wake it up.\n+                    tube_clone.send(1);\n                 }\n-                let sched = Local::take::<Scheduler>();\n-                sched.resume_task_immediately(task);\n+                sched.enqueue_task(task);\n             }\n \n             assert!(tube.recv() == 1);\n@@ -153,7 +148,7 @@ mod test {\n             let tube_clone = tube.clone();\n             let tube_clone = Cell(tube_clone);\n             let sched = Local::take::<Scheduler>();\n-            do sched.deschedule_running_task_and_then |task| {\n+            do sched.deschedule_running_task_and_then |sched, task| {\n                 callback_send(tube_clone.take(), 0);\n \n                 fn callback_send(tube: Tube<int>, i: int) {\n@@ -172,8 +167,7 @@ mod test {\n                     }\n                 }\n \n-                let sched = Local::take::<Scheduler>();\n-                sched.resume_task_immediately(task);\n+                sched.enqueue_task(task);\n             }\n \n             for int::range(0, MAX) |i| {"}, {"sha": "6ed06cc10b78a56b12b169f513b0007540d0c5c1", "filename": "src/libstd/rt/uv/async.rs", "status": "added", "additions": 105, "deletions": 0, "changes": 105, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fuv%2Fasync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fuv%2Fasync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fasync.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -0,0 +1,105 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use libc::{c_int, c_void};\n+use option::Some;\n+use rt::uv::uvll;\n+use rt::uv::uvll::UV_ASYNC;\n+use rt::uv::{Watcher, Loop, NativeHandle, AsyncCallback, NullCallback};\n+use rt::uv::WatcherInterop;\n+use rt::uv::status_to_maybe_uv_error;\n+\n+pub struct AsyncWatcher(*uvll::uv_async_t);\n+impl Watcher for AsyncWatcher { }\n+\n+impl AsyncWatcher {\n+    pub fn new(loop_: &mut Loop, cb: AsyncCallback) -> AsyncWatcher {\n+        unsafe {\n+            let handle = uvll::malloc_handle(UV_ASYNC);\n+            assert!(handle.is_not_null());\n+            let mut watcher: AsyncWatcher = NativeHandle::from_native_handle(handle);\n+            watcher.install_watcher_data();\n+            let data = watcher.get_watcher_data();\n+            data.async_cb = Some(cb);\n+            assert_eq!(0, uvll::async_init(loop_.native_handle(), handle, async_cb));\n+            return watcher;\n+        }\n+\n+        extern fn async_cb(handle: *uvll::uv_async_t, status: c_int) {\n+            let mut watcher: AsyncWatcher = NativeHandle::from_native_handle(handle);\n+            let status = status_to_maybe_uv_error(watcher.native_handle(), status);\n+            let data = watcher.get_watcher_data();\n+            let cb = data.async_cb.get_ref();\n+            (*cb)(watcher, status);\n+        }\n+    }\n+\n+    pub fn send(&mut self) {\n+        unsafe {\n+            let handle = self.native_handle();\n+            uvll::async_send(handle);\n+        }\n+    }\n+\n+    pub fn close(self, cb: NullCallback) {\n+        let mut this = self;\n+        let data = this.get_watcher_data();\n+        assert!(data.close_cb.is_none());\n+        data.close_cb = Some(cb);\n+\n+        unsafe {\n+            uvll::close(self.native_handle(), close_cb);\n+        }\n+\n+        extern fn close_cb(handle: *uvll::uv_stream_t) {\n+            let mut watcher: AsyncWatcher = NativeHandle::from_native_handle(handle);\n+            {\n+                let data = watcher.get_watcher_data();\n+                data.close_cb.swap_unwrap()();\n+            }\n+            watcher.drop_watcher_data();\n+            unsafe { uvll::free_handle(handle as *c_void); }\n+        }\n+    }\n+}\n+\n+impl NativeHandle<*uvll::uv_async_t> for AsyncWatcher {\n+    fn from_native_handle(handle: *uvll::uv_async_t) -> AsyncWatcher {\n+        AsyncWatcher(handle)\n+    }\n+    fn native_handle(&self) -> *uvll::uv_async_t {\n+        match self { &AsyncWatcher(ptr) => ptr }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+\n+    use super::*;\n+    use rt::uv::Loop;\n+    use unstable::run_in_bare_thread;\n+    use rt::thread::Thread;\n+    use cell::Cell;\n+\n+    #[test]\n+    fn smoke_test() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            let watcher = AsyncWatcher::new(&mut loop_, |w, _| w.close(||()) );\n+            let watcher_cell = Cell(watcher);\n+            let _thread = do Thread::start {\n+                let mut watcher = watcher_cell.take();\n+                watcher.send();\n+            };\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+}"}, {"sha": "a81ab48696a36f192b02ad5e8cc883171a5b2a12", "filename": "src/libstd/rt/uv/idle.rs", "status": "modified", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fuv%2Fidle.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fuv%2Fidle.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fidle.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -89,3 +89,65 @@ impl NativeHandle<*uvll::uv_idle_t> for IdleWatcher {\n         match self { &IdleWatcher(ptr) => ptr }\n     }\n }\n+\n+#[cfg(test)]\n+mod test {\n+\n+    use rt::uv::Loop;\n+    use super::*;\n+    use unstable::run_in_bare_thread;\n+\n+    #[test]\n+    #[ignore(reason = \"valgrind - loop destroyed before watcher?\")]\n+    fn idle_new_then_close() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            let idle_watcher = { IdleWatcher::new(&mut loop_) };\n+            idle_watcher.close(||());\n+        }\n+    }\n+\n+    #[test]\n+    fn idle_smoke_test() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n+            let mut count = 10;\n+            let count_ptr: *mut int = &mut count;\n+            do idle_watcher.start |idle_watcher, status| {\n+                let mut idle_watcher = idle_watcher;\n+                assert!(status.is_none());\n+                if unsafe { *count_ptr == 10 } {\n+                    idle_watcher.stop();\n+                    idle_watcher.close(||());\n+                } else {\n+                    unsafe { *count_ptr = *count_ptr + 1; }\n+                }\n+            }\n+            loop_.run();\n+            loop_.close();\n+            assert_eq!(count, 10);\n+        }\n+    }\n+\n+    #[test]\n+    fn idle_start_stop_start() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n+            do idle_watcher.start |idle_watcher, status| {\n+                let mut idle_watcher = idle_watcher;\n+                assert!(status.is_none());\n+                idle_watcher.stop();\n+                do idle_watcher.start |idle_watcher, status| {\n+                    assert!(status.is_none());\n+                    let mut idle_watcher = idle_watcher;\n+                    idle_watcher.stop();\n+                    idle_watcher.close(||());\n+                }\n+            }\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+}"}, {"sha": "5f9e56608149f80a44ee4b4b82f55321ebc10717", "filename": "src/libstd/rt/uv/mod.rs", "status": "modified", "additions": 7, "deletions": 56, "changes": 63, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fuv%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fuv%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fmod.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -57,6 +57,7 @@ pub use self::file::FsRequest;\n pub use self::net::{StreamWatcher, TcpWatcher};\n pub use self::idle::IdleWatcher;\n pub use self::timer::TimerWatcher;\n+pub use self::async::AsyncWatcher;\n \n /// The implementation of `rtio` for libuv\n pub mod uvio;\n@@ -68,6 +69,7 @@ pub mod file;\n pub mod net;\n pub mod idle;\n pub mod timer;\n+pub mod async;\n \n /// XXX: Loop(*handle) is buggy with destructors. Normal structs\n /// with dtors may not be destructured, but tuple structs can,\n@@ -125,6 +127,7 @@ pub type IdleCallback = ~fn(IdleWatcher, Option<UvError>);\n pub type ConnectionCallback = ~fn(StreamWatcher, Option<UvError>);\n pub type FsCallback = ~fn(FsRequest, Option<UvError>);\n pub type TimerCallback = ~fn(TimerWatcher, Option<UvError>);\n+pub type AsyncCallback = ~fn(AsyncWatcher, Option<UvError>);\n \n \n /// Callbacks used by StreamWatchers, set as custom data on the foreign handle\n@@ -135,7 +138,8 @@ struct WatcherData {\n     close_cb: Option<NullCallback>,\n     alloc_cb: Option<AllocCallback>,\n     idle_cb: Option<IdleCallback>,\n-    timer_cb: Option<TimerCallback>\n+    timer_cb: Option<TimerCallback>,\n+    async_cb: Option<AsyncCallback>\n }\n \n pub trait WatcherInterop {\n@@ -164,7 +168,8 @@ impl<H, W: Watcher + NativeHandle<*H>> WatcherInterop for W {\n                 close_cb: None,\n                 alloc_cb: None,\n                 idle_cb: None,\n-                timer_cb: None\n+                timer_cb: None,\n+                async_cb: None\n             };\n             let data = transmute::<~WatcherData, *c_void>(data);\n             uvll::set_data_for_uv_handle(self.native_handle(), data);\n@@ -364,57 +369,3 @@ fn loop_smoke_test() {\n         loop_.close();\n     }\n }\n-\n-#[test]\n-#[ignore(reason = \"valgrind - loop destroyed before watcher?\")]\n-fn idle_new_then_close() {\n-    do run_in_bare_thread {\n-        let mut loop_ = Loop::new();\n-        let idle_watcher = { IdleWatcher::new(&mut loop_) };\n-        idle_watcher.close(||());\n-    }\n-}\n-\n-#[test]\n-fn idle_smoke_test() {\n-    do run_in_bare_thread {\n-        let mut loop_ = Loop::new();\n-        let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n-        let mut count = 10;\n-        let count_ptr: *mut int = &mut count;\n-        do idle_watcher.start |idle_watcher, status| {\n-            let mut idle_watcher = idle_watcher;\n-            assert!(status.is_none());\n-            if unsafe { *count_ptr == 10 } {\n-                idle_watcher.stop();\n-                idle_watcher.close(||());\n-            } else {\n-                unsafe { *count_ptr = *count_ptr + 1; }\n-            }\n-        }\n-        loop_.run();\n-        loop_.close();\n-        assert_eq!(count, 10);\n-    }\n-}\n-\n-#[test]\n-fn idle_start_stop_start() {\n-    do run_in_bare_thread {\n-        let mut loop_ = Loop::new();\n-        let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n-        do idle_watcher.start |idle_watcher, status| {\n-            let mut idle_watcher = idle_watcher;\n-            assert!(status.is_none());\n-            idle_watcher.stop();\n-            do idle_watcher.start |idle_watcher, status| {\n-                assert!(status.is_none());\n-                let mut idle_watcher = idle_watcher;\n-                idle_watcher.stop();\n-                idle_watcher.close(||());\n-            }\n-        }\n-        loop_.run();\n-        loop_.close();\n-    }\n-}"}, {"sha": "1ee6504d11fc5354e63a42d0d0a4b9d2307c9e07", "filename": "src/libstd/rt/uv/uvio.rs", "status": "modified", "additions": 97, "deletions": 21, "changes": 118, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -12,6 +12,7 @@ use option::*;\n use result::*;\n use ops::Drop;\n use cell::{Cell, empty_cell};\n+use cast;\n use cast::transmute;\n use clone::Clone;\n use rt::io::IoError;\n@@ -23,6 +24,9 @@ use rt::sched::Scheduler;\n use rt::io::{standard_error, OtherIoError};\n use rt::tube::Tube;\n use rt::local::Local;\n+use rt::work_queue::WorkQueue;\n+use unstable::sync::{UnsafeAtomicRcBox, AtomicInt};\n+use unstable::intrinsics;\n \n #[cfg(test)] use container::Container;\n #[cfg(test)] use uint;\n@@ -39,11 +43,6 @@ pub impl UvEventLoop {\n             uvio: UvIoFactory(Loop::new())\n         }\n     }\n-\n-    /// A convenience constructor\n-    fn new_scheduler() -> Scheduler {\n-        Scheduler::new(~UvEventLoop::new())\n-    }\n }\n \n impl Drop for UvEventLoop {\n@@ -82,6 +81,10 @@ impl EventLoop for UvEventLoop {\n         }\n     }\n \n+    fn remote_callback(&mut self, f: ~fn()) -> ~RemoteCallbackObject {\n+        ~UvRemoteCallback::new(self.uvio.uv_loop(), f)\n+    }\n+\n     fn io<'a>(&'a mut self) -> Option<&'a mut IoFactoryObject> {\n         Some(&mut self.uvio)\n     }\n@@ -101,6 +104,85 @@ fn test_callback_run_once() {\n     }\n }\n \n+pub struct UvRemoteCallback {\n+    // The uv async handle for triggering the callback\n+    async: AsyncWatcher,\n+    // An atomic flag to tell the callback to exit,\n+    // set from the dtor.\n+    exit_flag: UnsafeAtomicRcBox<AtomicInt>\n+}\n+\n+impl UvRemoteCallback {\n+    pub fn new(loop_: &mut Loop, f: ~fn()) -> UvRemoteCallback {\n+        let exit_flag = UnsafeAtomicRcBox::new(AtomicInt::new(0));\n+        let exit_flag_clone = exit_flag.clone();\n+        let async = do AsyncWatcher::new(loop_) |watcher, status| {\n+            assert!(status.is_none());\n+            f();\n+            let exit_flag_ptr = exit_flag_clone.get();\n+            unsafe {\n+                if (*exit_flag_ptr).load() == 1 {\n+                    watcher.close(||());\n+                }\n+            }\n+        };\n+        UvRemoteCallback {\n+            async: async,\n+            exit_flag: exit_flag\n+        }\n+    }\n+}\n+\n+impl RemoteCallback for UvRemoteCallback {\n+    fn fire(&mut self) { self.async.send() }\n+}\n+\n+impl Drop for UvRemoteCallback {\n+    fn finalize(&self) {\n+        unsafe {\n+            let mut this: &mut UvRemoteCallback = cast::transmute_mut(self);\n+            let exit_flag_ptr = this.exit_flag.get();\n+            (*exit_flag_ptr).store(1);\n+            this.async.send();\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test_remote {\n+    use super::*;\n+    use cell;\n+    use cell::Cell;\n+    use rt::test::*;\n+    use rt::thread::Thread;\n+    use rt::tube::Tube;\n+    use rt::rtio::EventLoop;\n+    use rt::local::Local;\n+    use rt::sched::Scheduler;\n+\n+    #[test]\n+    fn test_uv_remote() {\n+        do run_in_newsched_task {\n+            let mut tube = Tube::new();\n+            let tube_clone = tube.clone();\n+            let remote_cell = cell::empty_cell();\n+            do Local::borrow::<Scheduler>() |sched| {\n+                let tube_clone = tube_clone.clone();\n+                let tube_clone_cell = Cell(tube_clone);\n+                let remote = do sched.event_loop.remote_callback {\n+                    tube_clone_cell.take().send(1);\n+                };\n+                remote_cell.put_back(remote);\n+            }\n+            let _thread = do Thread::start {\n+                remote_cell.take().fire();\n+            };\n+\n+            assert!(tube.recv() == 1);\n+        }\n+    }\n+}\n+\n pub struct UvIoFactory(Loop);\n \n pub impl UvIoFactory {\n@@ -123,12 +205,10 @@ impl IoFactory for UvIoFactory {\n         assert!(scheduler.in_task_context());\n \n         // Block this task and take ownership, switch to scheduler context\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |sched, task| {\n \n             rtdebug!(\"connect: entered scheduler context\");\n-            do Local::borrow::<Scheduler> |scheduler| {\n-                assert!(!scheduler.in_task_context());\n-            }\n+            assert!(!sched.in_task_context());\n             let mut tcp_watcher = TcpWatcher::new(self.uv_loop());\n             let task_cell = Cell(task);\n \n@@ -168,7 +248,7 @@ impl IoFactory for UvIoFactory {\n             Ok(_) => Ok(~UvTcpListener::new(watcher)),\n             Err(uverr) => {\n                 let scheduler = Local::take::<Scheduler>();\n-                do scheduler.deschedule_running_task_and_then |task| {\n+                do scheduler.deschedule_running_task_and_then |_, task| {\n                     let task_cell = Cell(task);\n                     do watcher.as_stream().close {\n                         let scheduler = Local::take::<Scheduler>();\n@@ -204,7 +284,7 @@ impl Drop for UvTcpListener {\n     fn finalize(&self) {\n         let watcher = self.watcher();\n         let scheduler = Local::take::<Scheduler>();\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |_, task| {\n             let task_cell = Cell(task);\n             do watcher.as_stream().close {\n                 let scheduler = Local::take::<Scheduler>();\n@@ -266,7 +346,7 @@ impl Drop for UvTcpStream {\n         rtdebug!(\"closing tcp stream\");\n         let watcher = self.watcher();\n         let scheduler = Local::take::<Scheduler>();\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |_, task| {\n             let task_cell = Cell(task);\n             do watcher.close {\n                 let scheduler = Local::take::<Scheduler>();\n@@ -285,11 +365,9 @@ impl RtioTcpStream for UvTcpStream {\n         assert!(scheduler.in_task_context());\n         let watcher = self.watcher();\n         let buf_ptr: *&mut [u8] = &buf;\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |sched, task| {\n             rtdebug!(\"read: entered scheduler context\");\n-            do Local::borrow::<Scheduler> |scheduler| {\n-                assert!(!scheduler.in_task_context());\n-            }\n+            assert!(!sched.in_task_context());\n             let mut watcher = watcher;\n             let task_cell = Cell(task);\n             // XXX: We shouldn't reallocate these callbacks every\n@@ -331,7 +409,7 @@ impl RtioTcpStream for UvTcpStream {\n         assert!(scheduler.in_task_context());\n         let watcher = self.watcher();\n         let buf_ptr: *&[u8] = &buf;\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |_, task| {\n             let mut watcher = watcher;\n             let task_cell = Cell(task);\n             let buf = unsafe { slice_to_uv_buf(*buf_ptr) };\n@@ -425,11 +503,9 @@ fn test_read_and_block() {\n                 // Yield to the other task in hopes that it\n                 // will trigger a read callback while we are\n                 // not ready for it\n-                do scheduler.deschedule_running_task_and_then |task| {\n+                do scheduler.deschedule_running_task_and_then |sched, task| {\n                     let task = Cell(task);\n-                    do Local::borrow::<Scheduler> |scheduler| {\n-                        scheduler.enqueue_task(task.take());\n-                    }\n+                    sched.enqueue_task(task.take());\n                 }\n             }\n "}, {"sha": "6085ca1a482eea82f06f26780c493b19af726703", "filename": "src/libstd/unstable/sync.rs", "status": "modified", "additions": 69, "deletions": 0, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Funstable%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4/src%2Flibstd%2Funstable%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Fsync.rs?ref=f4ed554ddbd2dacfaa5dcc1dda99a3121f8cf2a4", "patch": "@@ -205,8 +205,53 @@ extern {\n     fn rust_unlock_little_lock(lock: rust_little_lock);\n }\n \n+/* *********************************************************************/\n+\n+//FIXME: #5042 This should be replaced by proper atomic type\n+pub struct AtomicUint {\n+    priv inner: uint\n+}\n+\n+impl AtomicUint {\n+    pub fn new(val: uint) -> AtomicUint { AtomicUint { inner: val } }\n+    pub fn load(&self) -> uint {\n+        unsafe { intrinsics::atomic_load(cast::transmute(self)) as uint }\n+    }\n+    pub fn store(&mut self, val: uint) {\n+        unsafe { intrinsics::atomic_store(cast::transmute(self), val as int); }\n+    }\n+    pub fn add(&mut self, val: int) -> uint {\n+        unsafe { intrinsics::atomic_xadd(cast::transmute(self), val as int) as uint }\n+    }\n+    pub fn cas(&mut self, old:uint, new: uint) -> uint {\n+        unsafe { intrinsics::atomic_cxchg(cast::transmute(self), old as int, new as int) as uint }\n+    }\n+}\n+\n+pub struct AtomicInt {\n+    priv inner: int\n+}\n+\n+impl AtomicInt {\n+    pub fn new(val: int) -> AtomicInt { AtomicInt { inner: val } }\n+    pub fn load(&self) -> int {\n+        unsafe { intrinsics::atomic_load(&self.inner) }\n+    }\n+    pub fn store(&mut self, val: int) {\n+        unsafe { intrinsics::atomic_store(&mut self.inner, val); }\n+    }\n+    pub fn add(&mut self, val: int) -> int {\n+        unsafe { intrinsics::atomic_xadd(&mut self.inner, val) }\n+    }\n+    pub fn cas(&mut self, old: int, new: int) -> int {\n+        unsafe { intrinsics::atomic_cxchg(&mut self.inner, old, new) }\n+    }\n+}\n+\n+\n #[cfg(test)]\n mod tests {\n+    use super::*;\n     use comm;\n     use super::exclusive;\n     use task;\n@@ -258,4 +303,28 @@ mod tests {\n             assert_eq!(*one, 1);\n         }\n     }\n+\n+    #[test]\n+    fn atomic_int_smoke_test() {\n+        let mut i = AtomicInt::new(0);\n+        i.store(10);\n+        assert!(i.load() == 10);\n+        assert!(i.add(1) == 10);\n+        assert!(i.load() == 11);\n+        assert!(i.cas(11, 12) == 11);\n+        assert!(i.cas(11, 13) == 12);\n+        assert!(i.load() == 12);\n+    }\n+\n+    #[test]\n+    fn atomic_uint_smoke_test() {\n+        let mut i = AtomicUint::new(0);\n+        i.store(10);\n+        assert!(i.load() == 10);\n+        assert!(i.add(1) == 10);\n+        assert!(i.load() == 11);\n+        assert!(i.cas(11, 12) == 11);\n+        assert!(i.cas(11, 13) == 12);\n+        assert!(i.load() == 12);\n+    }\n }"}]}