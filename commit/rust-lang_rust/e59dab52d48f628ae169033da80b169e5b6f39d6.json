{"sha": "e59dab52d48f628ae169033da80b169e5b6f39d6", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU1OWRhYjUyZDQ4ZjYyOGFlMTY5MDMzZGE4MGIxNjllNWI2ZjM5ZDY=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-10-09T08:57:26Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-10-09T08:57:26Z"}, "message": "Auto merge of #65198 - nnethercote:fix-65080, r=Mark-Simulacrum\n\nSpeed up `TokenStream` concatenation\n\nThis PR fixes the quadratic behaviour identified in #65080.\n\nr? @Mark-Simulacrum", "tree": {"sha": "a72aca91f803edb690a6d95db1a7816ad4e67c6d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a72aca91f803edb690a6d95db1a7816ad4e67c6d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e59dab52d48f628ae169033da80b169e5b6f39d6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e59dab52d48f628ae169033da80b169e5b6f39d6", "html_url": "https://github.com/rust-lang/rust/commit/e59dab52d48f628ae169033da80b169e5b6f39d6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e59dab52d48f628ae169033da80b169e5b6f39d6/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "275cf4bcacad3fbe5539ecd5840462793ae46eec", "url": "https://api.github.com/repos/rust-lang/rust/commits/275cf4bcacad3fbe5539ecd5840462793ae46eec", "html_url": "https://github.com/rust-lang/rust/commit/275cf4bcacad3fbe5539ecd5840462793ae46eec"}, {"sha": "75e0078a1703448a19e25eac85daaa5a4e6e68ac", "url": "https://api.github.com/repos/rust-lang/rust/commits/75e0078a1703448a19e25eac85daaa5a4e6e68ac", "html_url": "https://github.com/rust-lang/rust/commit/75e0078a1703448a19e25eac85daaa5a4e6e68ac"}], "stats": {"total": 141, "additions": 80, "deletions": 61}, "files": [{"sha": "bef12ed4fadafc22d88d48a3670b3020651b1107", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 80, "deletions": 61, "changes": 141, "blob_url": "https://github.com/rust-lang/rust/blob/e59dab52d48f628ae169033da80b169e5b6f39d6/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e59dab52d48f628ae169033da80b169e5b6f39d6/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=e59dab52d48f628ae169033da80b169e5b6f39d6", "patch": "@@ -249,20 +249,47 @@ impl TokenStream {\n             0 => TokenStream::empty(),\n             1 => streams.pop().unwrap(),\n             _ => {\n-                // rust-lang/rust#57735: pre-allocate vector to avoid\n-                // quadratic blow-up due to on-the-fly reallocations.\n-                let tree_count = streams.iter()\n-                    .map(|ts| match &ts.0 { None => 0, Some(s) => s.len() })\n+                // We are going to extend the first stream in `streams` with\n+                // the elements from the subsequent streams. This requires\n+                // using `make_mut()` on the first stream, and in practice this\n+                // doesn't cause cloning 99.9% of the time.\n+                //\n+                // One very common use case is when `streams` has two elements,\n+                // where the first stream has any number of elements within\n+                // (often 1, but sometimes many more) and the second stream has\n+                // a single element within.\n+\n+                // Determine how much the first stream will be extended.\n+                // Needed to avoid quadratic blow up from on-the-fly\n+                // reallocations (#57735).\n+                let num_appends = streams.iter()\n+                    .skip(1)\n+                    .map(|ts| ts.len())\n                     .sum();\n-                let mut vec = Vec::with_capacity(tree_count);\n \n-                for stream in streams {\n-                    match stream.0 {\n-                        None => {},\n-                        Some(stream2) => vec.extend(stream2.iter().cloned()),\n+                // Get the first stream. If it's `None`, create an empty\n+                // stream.\n+                let mut iter = streams.drain();\n+                let mut first_stream_lrc = match iter.next().unwrap().0 {\n+                    Some(first_stream_lrc) => first_stream_lrc,\n+                    None => Lrc::new(vec![]),\n+                };\n+\n+                // Append the elements to the first stream, after reserving\n+                // space for them.\n+                let first_vec_mut = Lrc::make_mut(&mut first_stream_lrc);\n+                first_vec_mut.reserve(num_appends);\n+                for stream in iter {\n+                    if let Some(stream) = stream.0 {\n+                        first_vec_mut.extend(stream.iter().cloned());\n                     }\n                 }\n-                TokenStream::new(vec)\n+\n+                // Create the final `TokenStream`.\n+                match first_vec_mut.len() {\n+                    0 => TokenStream(None),\n+                    _ => TokenStream(Some(first_stream_lrc)),\n+                }\n             }\n         }\n     }\n@@ -363,25 +390,6 @@ impl TokenStream {\n                     .collect())\n         }))\n     }\n-\n-    fn first_tree_and_joint(&self) -> Option<TreeAndJoint> {\n-        self.0.as_ref().map(|stream| {\n-            stream.first().unwrap().clone()\n-        })\n-    }\n-\n-    fn last_tree_if_joint(&self) -> Option<TokenTree> {\n-        match self.0 {\n-            None => None,\n-            Some(ref stream) => {\n-                if let (tree, Joint) = stream.last().unwrap() {\n-                    Some(tree.clone())\n-                } else {\n-                    None\n-                }\n-            }\n-        }\n-    }\n }\n \n // 99.5%+ of the time we have 1 or 2 elements in this vector.\n@@ -394,18 +402,49 @@ impl TokenStreamBuilder {\n     }\n \n     pub fn push<T: Into<TokenStream>>(&mut self, stream: T) {\n-        let stream = stream.into();\n-        let last_tree_if_joint = self.0.last().and_then(TokenStream::last_tree_if_joint);\n-        if let Some(TokenTree::Token(last_token)) = last_tree_if_joint {\n-            if let Some((TokenTree::Token(token), is_joint)) = stream.first_tree_and_joint() {\n-                if let Some(glued_tok) = last_token.glue(&token) {\n-                    let last_stream = self.0.pop().unwrap();\n-                    self.push_all_but_last_tree(&last_stream);\n-                    let glued_tt = TokenTree::Token(glued_tok);\n-                    let glued_tokenstream = TokenStream::new(vec![(glued_tt, is_joint)]);\n-                    self.0.push(glued_tokenstream);\n-                    self.push_all_but_first_tree(&stream);\n-                    return\n+        let mut stream = stream.into();\n+\n+        // If `self` is not empty and the last tree within the last stream is a\n+        // token tree marked with `Joint`...\n+        if let Some(TokenStream(Some(ref mut last_stream_lrc))) = self.0.last_mut() {\n+            if let Some((TokenTree::Token(last_token), Joint)) = last_stream_lrc.last() {\n+\n+                // ...and `stream` is not empty and the first tree within it is\n+                // a token tree...\n+                if let TokenStream(Some(ref mut stream_lrc)) = stream {\n+                    if let Some((TokenTree::Token(token), is_joint)) = stream_lrc.first() {\n+\n+                        // ...and the two tokens can be glued together...\n+                        if let Some(glued_tok) = last_token.glue(&token) {\n+\n+                            // ...then do so, by overwriting the last token\n+                            // tree in `self` and removing the first token tree\n+                            // from `stream`. This requires using `make_mut()`\n+                            // on the last stream in `self` and on `stream`,\n+                            // and in practice this doesn't cause cloning 99.9%\n+                            // of the time.\n+\n+                            // Overwrite the last token tree with the merged\n+                            // token.\n+                            let last_vec_mut = Lrc::make_mut(last_stream_lrc);\n+                            *last_vec_mut.last_mut().unwrap() =\n+                                (TokenTree::Token(glued_tok), *is_joint);\n+\n+                            // Remove the first token tree from `stream`. (This\n+                            // is almost always the only tree in `stream`.)\n+                            let stream_vec_mut = Lrc::make_mut(stream_lrc);\n+                            stream_vec_mut.remove(0);\n+\n+                            // Don't push `stream` if it's empty -- that could\n+                            // block subsequent token gluing, by getting\n+                            // between two token trees that should be glued\n+                            // together.\n+                            if !stream.is_empty() {\n+                                self.0.push(stream);\n+                            }\n+                            return;\n+                        }\n+                    }\n                 }\n             }\n         }\n@@ -415,26 +454,6 @@ impl TokenStreamBuilder {\n     pub fn build(self) -> TokenStream {\n         TokenStream::from_streams(self.0)\n     }\n-\n-    fn push_all_but_last_tree(&mut self, stream: &TokenStream) {\n-        if let Some(ref streams) = stream.0 {\n-            let len = streams.len();\n-            match len {\n-                1 => {}\n-                _ => self.0.push(TokenStream(Some(Lrc::new(streams[0 .. len - 1].to_vec())))),\n-            }\n-        }\n-    }\n-\n-    fn push_all_but_first_tree(&mut self, stream: &TokenStream) {\n-        if let Some(ref streams) = stream.0 {\n-            let len = streams.len();\n-            match len {\n-                1 => {}\n-                _ => self.0.push(TokenStream(Some(Lrc::new(streams[1 .. len].to_vec())))),\n-            }\n-        }\n-    }\n }\n \n #[derive(Clone)]"}]}