{"sha": "7d9ea39de6d59fe59e628ef72983315e944412dc", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdkOWVhMzlkZTZkNTlmZTU5ZTYyOGVmNzI5ODMzMTVlOTQ0NDEyZGM=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2021-05-04T18:49:00Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2021-05-04T19:40:59Z"}, "message": "Cleanups", "tree": {"sha": "a772d18b4068393ad987888bd3ee09d37976a6c0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a772d18b4068393ad987888bd3ee09d37976a6c0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7d9ea39de6d59fe59e628ef72983315e944412dc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7d9ea39de6d59fe59e628ef72983315e944412dc", "html_url": "https://github.com/rust-lang/rust/commit/7d9ea39de6d59fe59e628ef72983315e944412dc", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7d9ea39de6d59fe59e628ef72983315e944412dc/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "010e4c8fe018d703aac38c54307ddbee35edc380", "url": "https://api.github.com/repos/rust-lang/rust/commits/010e4c8fe018d703aac38c54307ddbee35edc380", "html_url": "https://github.com/rust-lang/rust/commit/010e4c8fe018d703aac38c54307ddbee35edc380"}], "stats": {"total": 273, "additions": 134, "deletions": 139}, "files": [{"sha": "5ea41ba782591d0e9aa47f80cca9ce969f716eee", "filename": "crates/hir_expand/src/db.rs", "status": "modified", "additions": 134, "deletions": 139, "changes": 273, "blob_url": "https://github.com/rust-lang/rust/blob/7d9ea39de6d59fe59e628ef72983315e944412dc/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d9ea39de6d59fe59e628ef72983315e944412dc/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fdb.rs?ref=7d9ea39de6d59fe59e628ef72983315e944412dc", "patch": "@@ -89,26 +89,25 @@ pub trait AstDatabase: SourceDatabase {\n \n     #[salsa::transparent]\n     fn parse_or_expand(&self, file_id: HirFileId) -> Option<SyntaxNode>;\n-\n-    #[salsa::interned]\n-    fn intern_macro(&self, macro_call: MacroCallLoc) -> LazyMacroId;\n-    fn macro_arg_text(&self, id: MacroCallId) -> Option<GreenNode>;\n-    #[salsa::transparent]\n-    fn macro_arg(&self, id: MacroCallId) -> Option<Arc<(tt::Subtree, mbe::TokenMap)>>;\n-    fn macro_def(&self, id: MacroDefId) -> Option<Arc<(TokenExpander, mbe::TokenMap)>>;\n     fn parse_macro_expansion(\n         &self,\n         macro_file: MacroFile,\n     ) -> ExpandResult<Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>>;\n-    fn macro_expand(&self, macro_call: MacroCallId) -> ExpandResult<Option<Arc<tt::Subtree>>>;\n-\n-    /// Firewall query that returns the error from the `macro_expand` query.\n-    fn macro_expand_error(&self, macro_call: MacroCallId) -> Option<ExpandError>;\n \n+    #[salsa::interned]\n+    fn intern_macro(&self, macro_call: MacroCallLoc) -> LazyMacroId;\n     #[salsa::interned]\n     fn intern_eager_expansion(&self, eager: EagerCallLoc) -> EagerMacroId;\n \n+    #[salsa::transparent]\n+    fn macro_arg(&self, id: MacroCallId) -> Option<Arc<(tt::Subtree, mbe::TokenMap)>>;\n+    fn macro_arg_text(&self, id: MacroCallId) -> Option<GreenNode>;\n+    fn macro_def(&self, id: MacroDefId) -> Option<Arc<(TokenExpander, mbe::TokenMap)>>;\n+\n+    fn macro_expand(&self, macro_call: MacroCallId) -> ExpandResult<Option<Arc<tt::Subtree>>>;\n     fn expand_proc_macro(&self, call: MacroCallId) -> Result<tt::Subtree, mbe::ExpandError>;\n+    /// Firewall query that returns the error from the `macro_expand` query.\n+    fn macro_expand_error(&self, macro_call: MacroCallId) -> Option<ExpandError>;\n \n     fn hygiene_frame(&self, file_id: HirFileId) -> Arc<HygieneFrame>;\n }\n@@ -129,20 +128,140 @@ pub fn expand_hypothetical(\n         token_to_map.text_range().checked_sub(hypothetical_args.syntax().text_range().start())?;\n     let token_id = tmap_1.token_by_range(range)?;\n     let macro_def = expander(db, actual_macro_call)?;\n-    let (node, tmap_2) =\n-        parse_macro_with_arg(db, macro_file, Some(std::sync::Arc::new((tt, tmap_1)))).value?;\n+\n+    let hypothetical_expansion =\n+        macro_expand_with_arg(db, macro_file.macro_call_id, Some(Arc::new((tt, tmap_1))));\n+    let (node, tmap_2) = expansion_to_syntax(db, macro_file, hypothetical_expansion).value?;\n+\n     let token_id = macro_def.0.map_id_down(token_id);\n     let range = tmap_2.range_by_token(token_id)?.by_kind(token_to_map.kind())?;\n     let token = node.syntax_node().covering_element(range).into_token()?;\n     Some((node.syntax_node(), token))\n }\n \n fn ast_id_map(db: &dyn AstDatabase, file_id: HirFileId) -> Arc<AstIdMap> {\n-    let map =\n-        db.parse_or_expand(file_id).map_or_else(AstIdMap::default, |it| AstIdMap::from_source(&it));\n+    let map = db.parse_or_expand(file_id).map(|it| AstIdMap::from_source(&it)).unwrap_or_default();\n     Arc::new(map)\n }\n \n+fn parse_or_expand(db: &dyn AstDatabase, file_id: HirFileId) -> Option<SyntaxNode> {\n+    match file_id.0 {\n+        HirFileIdRepr::FileId(file_id) => Some(db.parse(file_id).tree().syntax().clone()),\n+        HirFileIdRepr::MacroFile(macro_file) => {\n+            db.parse_macro_expansion(macro_file).value.map(|(it, _)| it.syntax_node())\n+        }\n+    }\n+}\n+\n+fn parse_macro_expansion(\n+    db: &dyn AstDatabase,\n+    macro_file: MacroFile,\n+) -> ExpandResult<Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>> {\n+    let result = db.macro_expand(macro_file.macro_call_id);\n+    expansion_to_syntax(db, macro_file, result)\n+}\n+\n+fn expansion_to_syntax(\n+    db: &dyn AstDatabase,\n+    macro_file: MacroFile,\n+    result: ExpandResult<Option<Arc<tt::Subtree>>>,\n+) -> ExpandResult<Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>> {\n+    let _p = profile::span(\"parse_macro_expansion\");\n+\n+    if let Some(err) = &result.err {\n+        // Note:\n+        // The final goal we would like to make all parse_macro success,\n+        // such that the following log will not call anyway.\n+        match macro_file.macro_call_id {\n+            MacroCallId::LazyMacro(id) => {\n+                let loc: MacroCallLoc = db.lookup_intern_macro(id);\n+                let node = loc.kind.node(db);\n+\n+                // collect parent information for warning log\n+                let parents = std::iter::successors(loc.kind.file_id().call_node(db), |it| {\n+                    it.file_id.call_node(db)\n+                })\n+                .map(|n| format!(\"{:#}\", n.value))\n+                .collect::<Vec<_>>()\n+                .join(\"\\n\");\n+\n+                log::warn!(\n+                    \"fail on macro_parse: (reason: {:?} macro_call: {:#}) parents: {}\",\n+                    err,\n+                    node.value,\n+                    parents\n+                );\n+            }\n+            _ => {\n+                log::warn!(\"fail on macro_parse: (reason: {:?})\", err);\n+            }\n+        }\n+    }\n+    let tt = match result.value {\n+        Some(tt) => tt,\n+        None => return ExpandResult { value: None, err: result.err },\n+    };\n+\n+    let fragment_kind = to_fragment_kind(db, macro_file.macro_call_id);\n+\n+    log::debug!(\"expanded = {}\", tt.as_debug_string());\n+    log::debug!(\"kind = {:?}\", fragment_kind);\n+\n+    let (parse, rev_token_map) = match mbe::token_tree_to_syntax_node(&tt, fragment_kind) {\n+        Ok(it) => it,\n+        Err(err) => {\n+            log::debug!(\n+                \"failed to parse expanstion to {:?} = {}\",\n+                fragment_kind,\n+                tt.as_debug_string()\n+            );\n+            return ExpandResult::only_err(err);\n+        }\n+    };\n+\n+    match result.err {\n+        Some(err) => {\n+            // Safety check for recursive identity macro.\n+            let node = parse.syntax_node();\n+            let file: HirFileId = macro_file.into();\n+            let call_node = match file.call_node(db) {\n+                Some(it) => it,\n+                None => {\n+                    return ExpandResult::only_err(err);\n+                }\n+            };\n+            if is_self_replicating(&node, &call_node.value) {\n+                return ExpandResult::only_err(err);\n+            } else {\n+                ExpandResult { value: Some((parse, Arc::new(rev_token_map))), err: Some(err) }\n+            }\n+        }\n+        None => {\n+            log::debug!(\"parse = {:?}\", parse.syntax_node().kind());\n+            ExpandResult { value: Some((parse, Arc::new(rev_token_map))), err: None }\n+        }\n+    }\n+}\n+\n+fn macro_arg(db: &dyn AstDatabase, id: MacroCallId) -> Option<Arc<(tt::Subtree, mbe::TokenMap)>> {\n+    let arg = db.macro_arg_text(id)?;\n+    let (tt, tmap) = mbe::syntax_node_to_token_tree(&SyntaxNode::new_root(arg));\n+    Some(Arc::new((tt, tmap)))\n+}\n+\n+fn macro_arg_text(db: &dyn AstDatabase, id: MacroCallId) -> Option<GreenNode> {\n+    let id = match id {\n+        MacroCallId::LazyMacro(id) => id,\n+        MacroCallId::EagerMacro(_id) => {\n+            // FIXME: support macro_arg for eager macro\n+            return None;\n+        }\n+    };\n+    let loc = db.lookup_intern_macro(id);\n+    let arg = loc.kind.arg(db)?;\n+    Some(arg.green())\n+}\n+\n fn macro_def(db: &dyn AstDatabase, id: MacroDefId) -> Option<Arc<(TokenExpander, mbe::TokenMap)>> {\n     match id.kind {\n         MacroDefKind::Declarative(ast_id) => match ast_id.to_node(db) {\n@@ -186,25 +305,6 @@ fn macro_def(db: &dyn AstDatabase, id: MacroDefId) -> Option<Arc<(TokenExpander,\n     }\n }\n \n-fn macro_arg_text(db: &dyn AstDatabase, id: MacroCallId) -> Option<GreenNode> {\n-    let id = match id {\n-        MacroCallId::LazyMacro(id) => id,\n-        MacroCallId::EagerMacro(_id) => {\n-            // FIXME: support macro_arg for eager macro\n-            return None;\n-        }\n-    };\n-    let loc = db.lookup_intern_macro(id);\n-    let arg = loc.kind.arg(db)?;\n-    Some(arg.green())\n-}\n-\n-fn macro_arg(db: &dyn AstDatabase, id: MacroCallId) -> Option<Arc<(tt::Subtree, mbe::TokenMap)>> {\n-    let arg = db.macro_arg_text(id)?;\n-    let (tt, tmap) = mbe::syntax_node_to_token_tree(&SyntaxNode::new_root(arg));\n-    Some(Arc::new((tt, tmap)))\n-}\n-\n fn macro_expand(db: &dyn AstDatabase, id: MacroCallId) -> ExpandResult<Option<Arc<tt::Subtree>>> {\n     macro_expand_with_arg(db, id, None)\n }\n@@ -299,111 +399,6 @@ fn expand_proc_macro(\n     expander.expand(db, loc.krate, &macro_arg.0)\n }\n \n-fn parse_or_expand(db: &dyn AstDatabase, file_id: HirFileId) -> Option<SyntaxNode> {\n-    match file_id.0 {\n-        HirFileIdRepr::FileId(file_id) => Some(db.parse(file_id).tree().syntax().clone()),\n-        HirFileIdRepr::MacroFile(macro_file) => {\n-            db.parse_macro_expansion(macro_file).value.map(|(it, _)| it.syntax_node())\n-        }\n-    }\n-}\n-\n-fn parse_macro_expansion(\n-    db: &dyn AstDatabase,\n-    macro_file: MacroFile,\n-) -> ExpandResult<Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>> {\n-    parse_macro_with_arg(db, macro_file, None)\n-}\n-\n-fn parse_macro_with_arg(\n-    db: &dyn AstDatabase,\n-    macro_file: MacroFile,\n-    arg: Option<Arc<(tt::Subtree, mbe::TokenMap)>>,\n-) -> ExpandResult<Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>> {\n-    let macro_call_id = macro_file.macro_call_id;\n-    let result = if let Some(arg) = arg {\n-        macro_expand_with_arg(db, macro_call_id, Some(arg))\n-    } else {\n-        db.macro_expand(macro_call_id)\n-    };\n-\n-    let _p = profile::span(\"parse_macro_expansion\");\n-\n-    if let Some(err) = &result.err {\n-        // Note:\n-        // The final goal we would like to make all parse_macro success,\n-        // such that the following log will not call anyway.\n-        match macro_call_id {\n-            MacroCallId::LazyMacro(id) => {\n-                let loc: MacroCallLoc = db.lookup_intern_macro(id);\n-                let node = loc.kind.node(db);\n-\n-                // collect parent information for warning log\n-                let parents = std::iter::successors(loc.kind.file_id().call_node(db), |it| {\n-                    it.file_id.call_node(db)\n-                })\n-                .map(|n| format!(\"{:#}\", n.value))\n-                .collect::<Vec<_>>()\n-                .join(\"\\n\");\n-\n-                log::warn!(\n-                    \"fail on macro_parse: (reason: {:?} macro_call: {:#}) parents: {}\",\n-                    err,\n-                    node.value,\n-                    parents\n-                );\n-            }\n-            _ => {\n-                log::warn!(\"fail on macro_parse: (reason: {:?})\", err);\n-            }\n-        }\n-    }\n-    let tt = match result.value {\n-        Some(tt) => tt,\n-        None => return ExpandResult { value: None, err: result.err },\n-    };\n-\n-    let fragment_kind = to_fragment_kind(db, macro_call_id);\n-\n-    log::debug!(\"expanded = {}\", tt.as_debug_string());\n-    log::debug!(\"kind = {:?}\", fragment_kind);\n-\n-    let (parse, rev_token_map) = match mbe::token_tree_to_syntax_node(&tt, fragment_kind) {\n-        Ok(it) => it,\n-        Err(err) => {\n-            log::debug!(\n-                \"failed to parse expanstion to {:?} = {}\",\n-                fragment_kind,\n-                tt.as_debug_string()\n-            );\n-            return ExpandResult::only_err(err);\n-        }\n-    };\n-\n-    match result.err {\n-        Some(err) => {\n-            // Safety check for recursive identity macro.\n-            let node = parse.syntax_node();\n-            let file: HirFileId = macro_file.into();\n-            let call_node = match file.call_node(db) {\n-                Some(it) => it,\n-                None => {\n-                    return ExpandResult::only_err(err);\n-                }\n-            };\n-            if is_self_replicating(&node, &call_node.value) {\n-                return ExpandResult::only_err(err);\n-            } else {\n-                ExpandResult { value: Some((parse, Arc::new(rev_token_map))), err: Some(err) }\n-            }\n-        }\n-        None => {\n-            log::debug!(\"parse = {:?}\", parse.syntax_node().kind());\n-            ExpandResult { value: Some((parse, Arc::new(rev_token_map))), err: None }\n-        }\n-    }\n-}\n-\n fn is_self_replicating(from: &SyntaxNode, to: &SyntaxNode) -> bool {\n     if diff(from, to).is_empty() {\n         return true;"}]}