{"sha": "f39039e6e5ab4ff3010e2d133d12e44d1cfcb631", "node_id": "MDY6Q29tbWl0NzI0NzEyOmYzOTAzOWU2ZTVhYjRmZjMwMTBlMmQxMzNkMTJlNDRkMWNmY2I2MzE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2016-09-18T07:48:51Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2016-09-18T07:48:51Z"}, "message": "Auto merge of #36527 - nnethercote:last_token_kind, r=jseyfried\n\nOptimize the parser's last token handling.\n\nThe parser currently makes a heap copy of the last token in four cases:\nidentifiers, paths, doc comments, and commas. The identifier and\ninterpolation cases are unused, and for doc comments and commas we only\nneed to record their presence, not their value.\n\nThis commit consolidates the last token handling and avoids the\nunnecessary copies by replacing `last_token`, `last_token_eof`, and\n`last_token_interpolated` with a new field `last_token_kind`. This\nsimplifies the parser slightly and speeds up parsing on some files by\n3--4%.", "tree": {"sha": "46b4d4014fb9acf227a0c6db49b4c53310f077ec", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/46b4d4014fb9acf227a0c6db49b4c53310f077ec"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f39039e6e5ab4ff3010e2d133d12e44d1cfcb631", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f39039e6e5ab4ff3010e2d133d12e44d1cfcb631", "html_url": "https://github.com/rust-lang/rust/commit/f39039e6e5ab4ff3010e2d133d12e44d1cfcb631", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f39039e6e5ab4ff3010e2d133d12e44d1cfcb631/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0b03ba1f5545ac1e8c434346de29c41aba82837e", "url": "https://api.github.com/repos/rust-lang/rust/commits/0b03ba1f5545ac1e8c434346de29c41aba82837e", "html_url": "https://github.com/rust-lang/rust/commit/0b03ba1f5545ac1e8c434346de29c41aba82837e"}, {"sha": "8075d546069e9fc850beb846747c43e9ee55e175", "url": "https://api.github.com/repos/rust-lang/rust/commits/8075d546069e9fc850beb846747c43e9ee55e175", "html_url": "https://github.com/rust-lang/rust/commit/8075d546069e9fc850beb846747c43e9ee55e175"}], "stats": {"total": 82, "additions": 39, "deletions": 43}, "files": [{"sha": "5cd4a046577169fa2ab3dab113261c7ab830ecb6", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 39, "deletions": 43, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/f39039e6e5ab4ff3010e2d133d12e44d1cfcb631/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f39039e6e5ab4ff3010e2d133d12e44d1cfcb631/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=f39039e6e5ab4ff3010e2d133d12e44d1cfcb631", "patch": "@@ -237,6 +237,15 @@ fn maybe_append(mut lhs: Vec<Attribute>, rhs: Option<Vec<Attribute>>)\n     lhs\n }\n \n+#[derive(PartialEq)]\n+enum LastTokenKind {\n+    DocComment,\n+    Comma,\n+    Interpolated,\n+    Eof,\n+    Other,\n+}\n+\n /* ident is handled by common.rs */\n \n pub struct Parser<'a> {\n@@ -248,10 +257,8 @@ pub struct Parser<'a> {\n     /// the span of the prior token:\n     pub last_span: Span,\n     pub cfg: CrateConfig,\n-    /// the previous token or None (only stashed sometimes).\n-    pub last_token: Option<Box<token::Token>>,\n-    last_token_interpolated: bool,\n-    last_token_eof: bool,\n+    /// the previous token kind\n+    last_token_kind: LastTokenKind,\n     pub buffer: [TokenAndSpan; 4],\n     pub buffer_start: isize,\n     pub buffer_end: isize,\n@@ -362,9 +369,7 @@ impl<'a> Parser<'a> {\n             token: tok0.tok,\n             span: span,\n             last_span: span,\n-            last_token: None,\n-            last_token_interpolated: false,\n-            last_token_eof: false,\n+            last_token_kind: LastTokenKind::Other,\n             buffer: [\n                 placeholder.clone(),\n                 placeholder.clone(),\n@@ -500,7 +505,7 @@ impl<'a> Parser<'a> {\n                                  expr: PResult<'a, P<Expr>>)\n                                  -> PResult<'a, (Span, P<Expr>)> {\n         expr.map(|e| {\n-            if self.last_token_interpolated {\n+            if self.last_token_kind == LastTokenKind::Interpolated {\n                 (self.last_span, e)\n             } else {\n                 (e.span, e)\n@@ -520,21 +525,19 @@ impl<'a> Parser<'a> {\n                 self.bug(\"ident interpolation not converted to real token\");\n             }\n             _ => {\n-                let last_token = self.last_token.clone().map(|t| *t);\n-                Err(match last_token {\n-                    Some(token::DocComment(_)) => self.span_fatal_help(self.last_span,\n+                Err(if self.last_token_kind == LastTokenKind::DocComment {\n+                    self.span_fatal_help(self.last_span,\n                         \"found a documentation comment that doesn't document anything\",\n                         \"doc comments must come before what they document, maybe a comment was \\\n-                        intended with `//`?\"),\n-                    _ => {\n+                        intended with `//`?\")\n+                    } else {\n                         let mut err = self.fatal(&format!(\"expected identifier, found `{}`\",\n                                                           self.this_token_to_string()));\n                         if self.token == token::Underscore {\n                             err.note(\"`_` is a wildcard pattern, not an identifier\");\n                         }\n                         err\n-                    }\n-                })\n+                    })\n             }\n         }\n     }\n@@ -925,26 +928,22 @@ impl<'a> Parser<'a> {\n \n     /// Advance the parser by one token\n     pub fn bump(&mut self) {\n-        if self.last_token_eof {\n+        if self.last_token_kind == LastTokenKind::Eof {\n             // Bumping after EOF is a bad sign, usually an infinite loop.\n             self.bug(\"attempted to bump the parser past EOF (may be stuck in a loop)\");\n         }\n \n-        if self.token == token::Eof {\n-            self.last_token_eof = true;\n-        }\n-\n         self.last_span = self.span;\n-        // Stash token for error recovery (sometimes; clone is not necessarily cheap).\n-        self.last_token = if self.token.is_ident() ||\n-                          self.token.is_path() ||\n-                          self.token.is_doc_comment() ||\n-                          self.token == token::Comma {\n-            Some(Box::new(self.token.clone()))\n-        } else {\n-            None\n+\n+        // Record last token kind for possible error recovery.\n+        self.last_token_kind = match self.token {\n+            token::DocComment(..) => LastTokenKind::DocComment,\n+            token::Comma => LastTokenKind::Comma,\n+            token::Interpolated(..) => LastTokenKind::Interpolated,\n+            token::Eof => LastTokenKind::Eof,\n+            _ => LastTokenKind::Other,\n         };\n-        self.last_token_interpolated = self.token.is_interpolated();\n+\n         let next = if self.buffer_start == self.buffer_end {\n             self.reader.real_token()\n         } else {\n@@ -981,11 +980,10 @@ impl<'a> Parser<'a> {\n                      lo: BytePos,\n                      hi: BytePos) {\n         self.last_span = mk_sp(self.span.lo, lo);\n-        // It would be incorrect to just stash current token, but fortunately\n-        // for tokens currently using `bump_with`, last_token will be of no\n-        // use anyway.\n-        self.last_token = None;\n-        self.last_token_interpolated = false;\n+        // It would be incorrect to record the kind of the current token, but\n+        // fortunately for tokens currently using `bump_with`, the\n+        // last_token_kind will be of no use anyway.\n+        self.last_token_kind = LastTokenKind::Other;\n         self.span = mk_sp(lo, hi);\n         self.token = next;\n         self.expected_tokens.clear();\n@@ -2950,7 +2948,7 @@ impl<'a> Parser<'a> {\n         self.expected_tokens.push(TokenType::Operator);\n         while let Some(op) = AssocOp::from_token(&self.token) {\n \n-            let lhs_span = if self.last_token_interpolated {\n+            let lhs_span = if self.last_token_kind == LastTokenKind::Interpolated {\n                 self.last_span\n             } else {\n                 lhs.span\n@@ -4012,13 +4010,13 @@ impl<'a> Parser<'a> {\n                 None => {\n                     let unused_attrs = |attrs: &[_], s: &mut Self| {\n                         if attrs.len() > 0 {\n-                            let last_token = s.last_token.clone().map(|t| *t);\n-                            match last_token {\n-                                Some(token::DocComment(_)) => s.span_err_help(s.last_span,\n+                            if s.last_token_kind == LastTokenKind::DocComment {\n+                                s.span_err_help(s.last_span,\n                                     \"found a documentation comment that doesn't document anything\",\n                                     \"doc comments must come before what they document, maybe a \\\n-                                    comment was intended with `//`?\"),\n-                                _ => s.span_err(s.span, \"expected statement after outer attribute\"),\n+                                    comment was intended with `//`?\");\n+                            } else {\n+                                s.span_err(s.span, \"expected statement after outer attribute\");\n                             }\n                         }\n                     };\n@@ -4308,9 +4306,7 @@ impl<'a> Parser<'a> {\n \n         let missing_comma = !lifetimes.is_empty() &&\n                             !self.token.is_like_gt() &&\n-                            self.last_token\n-                                .as_ref().map_or(true,\n-                                                 |x| &**x != &token::Comma);\n+                            self.last_token_kind != LastTokenKind::Comma;\n \n         if missing_comma {\n "}]}