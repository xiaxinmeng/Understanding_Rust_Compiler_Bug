{"sha": "0c981875e46763a9b3cd53443bf73dfd3e291d18", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBjOTgxODc1ZTQ2NzYzYTliM2NkNTM0NDNiZjczZGZkM2UyOTFkMTg=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2015-01-21T17:13:51Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2015-01-21T17:13:51Z"}, "message": "rollup merge of #21340: pshc/libsyntax-no-more-ints\n\nCollaboration with @rylev!\n\nI didn't change `int` in the [quasi-quoter](https://github.com/pshc/rust/blob/99ae1a30f3ca28c0f7e431620560d30e44627124/src/libsyntax/ext/quote.rs#L328), because I'm not sure if there will be adverse effects.\n\nAddresses #21095.", "tree": {"sha": "b0d1f49551beab62865f5945d588a8a65931c9f5", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b0d1f49551beab62865f5945d588a8a65931c9f5"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0c981875e46763a9b3cd53443bf73dfd3e291d18", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0c981875e46763a9b3cd53443bf73dfd3e291d18", "html_url": "https://github.com/rust-lang/rust/commit/0c981875e46763a9b3cd53443bf73dfd3e291d18", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0c981875e46763a9b3cd53443bf73dfd3e291d18/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5da25386b3e70a5a538f75fbd5b42a8db04dd93d", "url": "https://api.github.com/repos/rust-lang/rust/commits/5da25386b3e70a5a538f75fbd5b42a8db04dd93d", "html_url": "https://github.com/rust-lang/rust/commit/5da25386b3e70a5a538f75fbd5b42a8db04dd93d"}, {"sha": "3c32cd1be27f321658382e39d34f5d993d99ae8b", "url": "https://api.github.com/repos/rust-lang/rust/commits/3c32cd1be27f321658382e39d34f5d993d99ae8b", "html_url": "https://github.com/rust-lang/rust/commit/3c32cd1be27f321658382e39d34f5d993d99ae8b"}], "stats": {"total": 976, "additions": 488, "deletions": 488}, "files": [{"sha": "59b6520216df025c984589e9b37fe803b5f1c547", "filename": "src/librustc/lint/builtin.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc%2Flint%2Fbuiltin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc%2Flint%2Fbuiltin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flint%2Fbuiltin.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -1329,7 +1329,7 @@ impl UnusedMut {\n                 let ident = path1.node;\n                 if let ast::BindByValue(ast::MutMutable) = mode {\n                     if !token::get_ident(ident).get().starts_with(\"_\") {\n-                        match mutables.entry(ident.name.uint()) {\n+                        match mutables.entry(ident.name.usize()) {\n                             Vacant(entry) => { entry.insert(vec![id]); },\n                             Occupied(mut entry) => { entry.get_mut().push(id); },\n                         }"}, {"sha": "8427c471eee322e2038903af0897df853b31ee3a", "filename": "src/librustc/util/ppaux.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc%2Futil%2Fppaux.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc%2Futil%2Fppaux.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fppaux.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -164,7 +164,7 @@ pub fn explain_region_and_span(cx: &ctxt, region: ty::Region)\n     fn explain_span(cx: &ctxt, heading: &str, span: Span)\n                     -> (String, Option<Span>) {\n         let lo = cx.sess.codemap().lookup_char_pos_adj(span.lo);\n-        (format!(\"the {} at {}:{}\", heading, lo.line, lo.col.to_uint()),\n+        (format!(\"the {} at {}:{}\", heading, lo.line, lo.col.to_usize()),\n          Some(span))\n     }\n }"}, {"sha": "e6173e3ab8e4381879de9826729c8c49d0225d2d", "filename": "src/librustc_resolve/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_resolve%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_resolve%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Flib.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -1967,7 +1967,7 @@ impl<'a, 'tcx> Resolver<'a, 'tcx> {\n                     let module_name = self.module_to_string(&*search_module);\n                     let mut span = span;\n                     let msg = if \"???\" == &module_name[] {\n-                        span.hi = span.lo + Pos::from_uint(segment_name.get().len());\n+                        span.hi = span.lo + Pos::from_usize(segment_name.get().len());\n \n                         match search_parent_externals(name,\n                                                      &self.current_module) {"}, {"sha": "97b3cda006bf7b36441b53b188ac58aacd105c8b", "filename": "src/librustc_trans/save/span_utils.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_trans%2Fsave%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_trans%2Fsave%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fsave%2Fspan_utils.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -40,8 +40,8 @@ impl<'a> SpanUtils<'a> {\n         format!(\"file_name,{},file_line,{},file_col,{},extent_start,{},extent_start_bytes,{},\\\n                  file_line_end,{},file_col_end,{},extent_end,{},extent_end_bytes,{}\",\n                 lo_loc.file.name,\n-                lo_loc.line, lo_loc.col.to_uint(), lo_pos.to_uint(), lo_pos_byte.to_uint(),\n-                hi_loc.line, hi_loc.col.to_uint(), hi_pos.to_uint(), hi_pos_byte.to_uint())\n+                lo_loc.line, lo_loc.col.to_usize(), lo_pos.to_usize(), lo_pos_byte.to_usize(),\n+                hi_loc.line, hi_loc.col.to_usize(), hi_pos.to_usize(), hi_pos_byte.to_usize())\n     }\n \n     // sub_span starts at span.lo, so we need to adjust the positions etc."}, {"sha": "8a7630e63016c7e44eb3d9fe29870a5ab2381e9f", "filename": "src/librustc_trans/trans/common.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_trans%2Ftrans%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_trans%2Ftrans%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fcommon.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -275,7 +275,7 @@ pub fn return_type_is_void(ccx: &CrateContext, ty: Ty) -> bool {\n /// Generates a unique symbol based off the name given. This is used to create\n /// unique symbols for things like closures.\n pub fn gensym_name(name: &str) -> PathElem {\n-    let num = token::gensym(name).uint();\n+    let num = token::gensym(name).usize();\n     // use one colon which will get translated to a period by the mangler, and\n     // we're guaranteed that `num` is globally unique for this crate.\n     PathName(token::gensym(&format!(\"{}:{}\", name, num)[]))\n@@ -848,7 +848,7 @@ pub fn C_cstr(cx: &CrateContext, s: InternedString, null_terminated: bool) -> Va\n                                                 !null_terminated as Bool);\n \n         let gsym = token::gensym(\"str\");\n-        let buf = CString::from_vec(format!(\"str{}\", gsym.uint()).into_bytes());\n+        let buf = CString::from_vec(format!(\"str{}\", gsym.usize()).into_bytes());\n         let g = llvm::LLVMAddGlobal(cx.llmod(), val_ty(sc).to_ref(), buf.as_ptr());\n         llvm::LLVMSetInitializer(g, sc);\n         llvm::LLVMSetGlobalConstant(g, True);\n@@ -873,7 +873,7 @@ pub fn C_binary_slice(cx: &CrateContext, data: &[u8]) -> ValueRef {\n         let lldata = C_bytes(cx, data);\n \n         let gsym = token::gensym(\"binary\");\n-        let name = format!(\"binary{}\", gsym.uint());\n+        let name = format!(\"binary{}\", gsym.usize());\n         let name = CString::from_vec(name.into_bytes());\n         let g = llvm::LLVMAddGlobal(cx.llmod(), val_ty(lldata).to_ref(),\n                                     name.as_ptr());"}, {"sha": "e3194817dd3f2af6eeaa27250cc6fd0dc2dffc75", "filename": "src/librustc_trans/trans/debuginfo.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_trans%2Ftrans%2Fdebuginfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_trans%2Ftrans%2Fdebuginfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fdebuginfo.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -1204,7 +1204,7 @@ pub fn set_source_location(fcx: &FunctionContext,\n \n                 set_debug_location(cx, DebugLocation::new(scope,\n                                                           loc.line,\n-                                                          loc.col.to_uint()));\n+                                                          loc.col.to_usize()));\n             } else {\n                 set_debug_location(cx, UnknownLocation);\n             }\n@@ -1716,7 +1716,7 @@ fn declare_local<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n \n     set_debug_location(cx, DebugLocation::new(scope_metadata,\n                                               loc.line,\n-                                              loc.col.to_uint()));\n+                                              loc.col.to_usize()));\n     unsafe {\n         let instr = llvm::LLVMDIBuilderInsertDeclareAtEnd(\n             DIB(cx),\n@@ -3279,7 +3279,7 @@ fn create_scope_map(cx: &CrateContext,\n                 parent_scope,\n                 file_metadata,\n                 loc.line as c_uint,\n-                loc.col.to_uint() as c_uint)\n+                loc.col.to_usize() as c_uint)\n         };\n \n         scope_stack.push(ScopeStackEntry { scope_metadata: scope_metadata,\n@@ -3401,7 +3401,7 @@ fn create_scope_map(cx: &CrateContext,\n                                 parent_scope,\n                                 file_metadata,\n                                 loc.line as c_uint,\n-                                loc.col.to_uint() as c_uint)\n+                                loc.col.to_usize() as c_uint)\n                         };\n \n                         scope_stack.push(ScopeStackEntry {"}, {"sha": "712f5fa53c958f30acf14d73deae6f1a2cee1e77", "filename": "src/librustc_trans/trans/meth.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_trans%2Ftrans%2Fmeth.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustc_trans%2Ftrans%2Fmeth.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fmeth.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -785,7 +785,7 @@ pub fn make_vtable<I: Iterator<Item=ValueRef>>(ccx: &CrateContext,\n     unsafe {\n         let tbl = C_struct(ccx, &components[], false);\n         let sym = token::gensym(\"vtable\");\n-        let buf = CString::from_vec(format!(\"vtable{}\", sym.uint()).into_bytes());\n+        let buf = CString::from_vec(format!(\"vtable{}\", sym.usize()).into_bytes());\n         let vt_gvar = llvm::LLVMAddGlobal(ccx.llmod(), val_ty(tbl).to_ref(),\n                                           buf.as_ptr());\n         llvm::LLVMSetInitializer(vt_gvar, tbl);"}, {"sha": "adc3a2401a5f3df3a22a281aeab154eea20e85d5", "filename": "src/librustdoc/clean/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustdoc%2Fclean%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibrustdoc%2Fclean%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Fmod.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -1872,9 +1872,9 @@ impl Clean<Span> for syntax::codemap::Span {\n         Span {\n             filename: filename.to_string(),\n             loline: lo.line,\n-            locol: lo.col.to_uint(),\n+            locol: lo.col.to_usize(),\n             hiline: hi.line,\n-            hicol: hi.col.to_uint(),\n+            hicol: hi.col.to_usize(),\n         }\n     }\n }"}, {"sha": "72b9d4d1e63f2ee777d4cabdb5f0d63cfa55a1ec", "filename": "src/libsyntax/abi.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fabi.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fabi.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fabi.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -105,8 +105,8 @@ pub fn all_names() -> Vec<&'static str> {\n \n impl Abi {\n     #[inline]\n-    pub fn index(&self) -> uint {\n-        *self as uint\n+    pub fn index(&self) -> usize {\n+        *self as usize\n     }\n \n     #[inline]"}, {"sha": "b57c08a772723bc068b57f221e4c46d2a71c5d63", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -95,7 +95,7 @@ impl Ident {\n \n     pub fn encode_with_hygiene(&self) -> String {\n         format!(\"\\x00name_{},ctxt_{}\\x00\",\n-                self.name.uint(),\n+                self.name.usize(),\n                 self.ctxt)\n     }\n }\n@@ -152,7 +152,7 @@ impl PartialEq for Ident {\n \n /// A SyntaxContext represents a chain of macro-expandings\n /// and renamings. Each macro expansion corresponds to\n-/// a fresh uint\n+/// a fresh usize\n \n // I'm representing this syntax context as an index into\n // a table, in order to work around a compiler bug\n@@ -181,9 +181,9 @@ impl Name {\n         }\n     }\n \n-    pub fn uint(&self) -> uint {\n+    pub fn usize(&self) -> usize {\n         let Name(nm) = *self;\n-        nm as uint\n+        nm as usize\n     }\n \n     pub fn ident(&self) -> Ident {\n@@ -740,7 +740,7 @@ pub enum Expr_ {\n     ExprAssign(P<Expr>, P<Expr>),\n     ExprAssignOp(BinOp, P<Expr>, P<Expr>),\n     ExprField(P<Expr>, SpannedIdent),\n-    ExprTupField(P<Expr>, Spanned<uint>),\n+    ExprTupField(P<Expr>, Spanned<usize>),\n     ExprIndex(P<Expr>, P<Expr>),\n     ExprRange(Option<P<Expr>>, Option<P<Expr>>),\n \n@@ -839,7 +839,7 @@ pub struct SequenceRepetition {\n     /// Whether the sequence can be repeated zero (*), or one or more times (+)\n     pub op: KleeneOp,\n     /// The number of `MatchNt`s that appear in the sequence (and subsequences)\n-    pub num_captures: uint,\n+    pub num_captures: usize,\n }\n \n /// A Kleene-style [repetition operator](http://en.wikipedia.org/wiki/Kleene_star)\n@@ -878,7 +878,7 @@ pub enum TokenTree {\n }\n \n impl TokenTree {\n-    pub fn len(&self) -> uint {\n+    pub fn len(&self) -> usize {\n         match *self {\n             TtToken(_, token::DocComment(_)) => 2,\n             TtToken(_, token::SpecialVarNt(..)) => 2,\n@@ -893,7 +893,7 @@ impl TokenTree {\n         }\n     }\n \n-    pub fn get_tt(&self, index: uint) -> TokenTree {\n+    pub fn get_tt(&self, index: usize) -> TokenTree {\n         match (self, index) {\n             (&TtToken(sp, token::DocComment(_)), 0) => {\n                 TtToken(sp, token::Pound)\n@@ -963,7 +963,7 @@ pub enum Mac_ {\n #[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Show, Copy)]\n pub enum StrStyle {\n     CookedStr,\n-    RawStr(uint)\n+    RawStr(usize)\n }\n \n pub type Lit = Spanned<Lit_>;\n@@ -992,7 +992,7 @@ pub enum LitIntType {\n }\n \n impl LitIntType {\n-    pub fn suffix_len(&self) -> uint {\n+    pub fn suffix_len(&self) -> usize {\n         match *self {\n             UnsuffixedIntLit(_) => 0,\n             SignedIntLit(s, _) => s.suffix_len(),\n@@ -1113,7 +1113,7 @@ impl fmt::String for IntTy {\n }\n \n impl IntTy {\n-    pub fn suffix_len(&self) -> uint {\n+    pub fn suffix_len(&self) -> usize {\n         match *self {\n             TyIs(true) /* i */ => 1,\n             TyIs(false) /* is */ | TyI8 => 2,\n@@ -1146,7 +1146,7 @@ impl PartialEq for UintTy {\n }\n \n impl UintTy {\n-    pub fn suffix_len(&self) -> uint {\n+    pub fn suffix_len(&self) -> usize {\n         match *self {\n             TyUs(true) /* u */ => 1,\n             TyUs(false) /* us */ | TyU8 => 2,\n@@ -1186,7 +1186,7 @@ impl fmt::String for FloatTy {\n }\n \n impl FloatTy {\n-    pub fn suffix_len(&self) -> uint {\n+    pub fn suffix_len(&self) -> usize {\n         match *self {\n             TyF32 | TyF64 => 3, // add F128 handling here\n         }\n@@ -1274,7 +1274,7 @@ pub enum Ty_ {\n     TyPtr(MutTy),\n     /// A reference (`&'a T` or `&'a mut T`)\n     TyRptr(Option<Lifetime>, MutTy),\n-    /// A bare function (e.g. `fn(uint) -> bool`)\n+    /// A bare function (e.g. `fn(usize) -> bool`)\n     TyBareFn(P<BareFnTy>),\n     /// A tuple (`(A, B, C, D,...)`)\n     TyTup(Vec<P<Ty>> ),\n@@ -1571,7 +1571,7 @@ pub enum AttrStyle {\n }\n \n #[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Show, Copy)]\n-pub struct AttrId(pub uint);\n+pub struct AttrId(pub usize);\n \n /// Doc-comments are promoted to attributes that have is_sugared_doc = true\n #[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Show)]"}, {"sha": "d57a1356def0ec53c8e4564853284c112d4d94e6", "filename": "src/libsyntax/ast_map/mod.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fast_map%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fast_map%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_map%2Fmod.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -264,12 +264,12 @@ pub struct Map<'ast> {\n }\n \n impl<'ast> Map<'ast> {\n-    fn entry_count(&self) -> uint {\n+    fn entry_count(&self) -> usize {\n         self.map.borrow().len()\n     }\n \n     fn find_entry(&self, id: NodeId) -> Option<MapEntry<'ast>> {\n-        self.map.borrow().get(id as uint).map(|e| *e)\n+        self.map.borrow().get(id as usize).map(|e| *e)\n     }\n \n     pub fn krate(&self) -> &'ast Crate {\n@@ -652,7 +652,7 @@ impl<'a, 'ast> Iterator for NodesMatchingSuffix<'a, 'ast> {\n     fn next(&mut self) -> Option<NodeId> {\n         loop {\n             let idx = self.idx;\n-            if idx as uint >= self.map.entry_count() {\n+            if idx as usize >= self.map.entry_count() {\n                 return None;\n             }\n             self.idx += 1;\n@@ -744,10 +744,10 @@ impl<'ast> NodeCollector<'ast> {\n     fn insert_entry(&mut self, id: NodeId, entry: MapEntry<'ast>) {\n         debug!(\"ast_map: {:?} => {:?}\", id, entry);\n         let len = self.map.len();\n-        if id as uint >= len {\n-            self.map.extend(repeat(NotPresent).take(id as uint - len + 1));\n+        if id as usize >= len {\n+            self.map.extend(repeat(NotPresent).take(id as usize - len + 1));\n         }\n-        self.map[id as uint] = entry;\n+        self.map[id as usize] = entry;\n     }\n \n     fn insert(&mut self, id: NodeId, node: Node<'ast>) {"}, {"sha": "34fd498322c0f86ddcbef527f571c617413d307e", "filename": "src/libsyntax/ast_util.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fast_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fast_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_util.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -156,7 +156,7 @@ pub fn int_ty_max(t: IntTy) -> u64 {\n }\n \n /// Get a string representation of an unsigned int type, with its value.\n-/// We want to avoid \"42uint\" in favor of \"42u\"\n+/// We want to avoid \"42u\" in favor of \"42us\". \"42uint\" is right out.\n pub fn uint_ty_to_string(t: UintTy, val: Option<u64>) -> String {\n     let s = match t {\n         TyUs(true) if val.is_some() => \"u\",\n@@ -319,25 +319,25 @@ pub fn struct_field_visibility(field: ast::StructField) -> Visibility {\n }\n \n /// Maps a binary operator to its precedence\n-pub fn operator_prec(op: ast::BinOp) -> uint {\n+pub fn operator_prec(op: ast::BinOp) -> usize {\n   match op {\n       // 'as' sits here with 12\n-      BiMul | BiDiv | BiRem     => 11u,\n-      BiAdd | BiSub             => 10u,\n-      BiShl | BiShr             =>  9u,\n-      BiBitAnd                  =>  8u,\n-      BiBitXor                  =>  7u,\n-      BiBitOr                   =>  6u,\n-      BiLt | BiLe | BiGe | BiGt | BiEq | BiNe => 3u,\n-      BiAnd                     =>  2u,\n-      BiOr                      =>  1u\n+      BiMul | BiDiv | BiRem     => 11us,\n+      BiAdd | BiSub             => 10us,\n+      BiShl | BiShr             =>  9us,\n+      BiBitAnd                  =>  8us,\n+      BiBitXor                  =>  7us,\n+      BiBitOr                   =>  6us,\n+      BiLt | BiLe | BiGe | BiGt | BiEq | BiNe => 3us,\n+      BiAnd                     =>  2us,\n+      BiOr                      =>  1us\n   }\n }\n \n /// Precedence of the `as` operator, which is a binary operator\n /// not appearing in the prior table.\n #[allow(non_upper_case_globals)]\n-pub static as_prec: uint = 12u;\n+pub static as_prec: usize = 12us;\n \n pub fn empty_generics() -> Generics {\n     Generics {"}, {"sha": "8f58b7694b6fb3763a7318517ede958544052433", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -170,7 +170,7 @@ pub fn mk_word_item(name: InternedString) -> P<MetaItem> {\n     P(dummy_spanned(MetaWord(name)))\n }\n \n-thread_local! { static NEXT_ATTR_ID: Cell<uint> = Cell::new(0) }\n+thread_local! { static NEXT_ATTR_ID: Cell<usize> = Cell::new(0) }\n \n pub fn mk_attr_id() -> AttrId {\n     let id = NEXT_ATTR_ID.with(|slot| {"}, {"sha": "a5e10f42750b8be8966895a409774ba9ec98de13", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 41, "deletions": 41, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -30,8 +30,8 @@ use libc::c_uint;\n use serialize::{Encodable, Decodable, Encoder, Decoder};\n \n pub trait Pos {\n-    fn from_uint(n: uint) -> Self;\n-    fn to_uint(&self) -> uint;\n+    fn from_usize(n: usize) -> Self;\n+    fn to_usize(&self) -> usize;\n }\n \n /// A byte offset. Keep this small (currently 32-bits), as AST contains\n@@ -43,50 +43,50 @@ pub struct BytePos(pub u32);\n /// is not equivalent to a character offset. The CodeMap will convert BytePos\n /// values to CharPos values as necessary.\n #[derive(Copy, PartialEq, Hash, PartialOrd, Show)]\n-pub struct CharPos(pub uint);\n+pub struct CharPos(pub usize);\n \n // FIXME: Lots of boilerplate in these impls, but so far my attempts to fix\n // have been unsuccessful\n \n impl Pos for BytePos {\n-    fn from_uint(n: uint) -> BytePos { BytePos(n as u32) }\n-    fn to_uint(&self) -> uint { let BytePos(n) = *self; n as uint }\n+    fn from_usize(n: usize) -> BytePos { BytePos(n as u32) }\n+    fn to_usize(&self) -> usize { let BytePos(n) = *self; n as usize }\n }\n \n impl Add for BytePos {\n     type Output = BytePos;\n \n     fn add(self, rhs: BytePos) -> BytePos {\n-        BytePos((self.to_uint() + rhs.to_uint()) as u32)\n+        BytePos((self.to_usize() + rhs.to_usize()) as u32)\n     }\n }\n \n impl Sub for BytePos {\n     type Output = BytePos;\n \n     fn sub(self, rhs: BytePos) -> BytePos {\n-        BytePos((self.to_uint() - rhs.to_uint()) as u32)\n+        BytePos((self.to_usize() - rhs.to_usize()) as u32)\n     }\n }\n \n impl Pos for CharPos {\n-    fn from_uint(n: uint) -> CharPos { CharPos(n) }\n-    fn to_uint(&self) -> uint { let CharPos(n) = *self; n }\n+    fn from_usize(n: usize) -> CharPos { CharPos(n) }\n+    fn to_usize(&self) -> usize { let CharPos(n) = *self; n }\n }\n \n impl Add for CharPos {\n     type Output = CharPos;\n \n     fn add(self, rhs: CharPos) -> CharPos {\n-        CharPos(self.to_uint() + rhs.to_uint())\n+        CharPos(self.to_usize() + rhs.to_usize())\n     }\n }\n \n impl Sub for CharPos {\n     type Output = CharPos;\n \n     fn sub(self, rhs: CharPos) -> CharPos {\n-        CharPos(self.to_uint() - rhs.to_uint())\n+        CharPos(self.to_usize() - rhs.to_usize())\n     }\n }\n \n@@ -173,7 +173,7 @@ pub struct Loc {\n     /// Information about the original source\n     pub file: Rc<FileMap>,\n     /// The (1-based) line number\n-    pub line: uint,\n+    pub line: usize,\n     /// The (0-based) column offset\n     pub col: CharPos\n }\n@@ -183,13 +183,13 @@ pub struct Loc {\n // perhaps they should just be removed.\n pub struct LocWithOpt {\n     pub filename: FileName,\n-    pub line: uint,\n+    pub line: usize,\n     pub col: CharPos,\n     pub file: Option<Rc<FileMap>>,\n }\n \n // used to be structural records. Better names, anyone?\n-pub struct FileMapAndLine { pub fm: Rc<FileMap>, pub line: uint }\n+pub struct FileMapAndLine { pub fm: Rc<FileMap>, pub line: usize }\n pub struct FileMapAndBytePos { pub fm: Rc<FileMap>, pub pos: BytePos }\n \n /// The syntax with which a macro was invoked.\n@@ -258,7 +258,7 @@ pub type FileName = String;\n \n pub struct FileLines {\n     pub file: Rc<FileMap>,\n-    pub lines: Vec<uint>\n+    pub lines: Vec<usize>\n }\n \n /// Identifies an offset of a multi-byte character in a FileMap\n@@ -267,7 +267,7 @@ pub struct MultiByteChar {\n     /// The absolute offset of the character in the CodeMap\n     pub pos: BytePos,\n     /// The number of bytes, >=2\n-    pub bytes: uint,\n+    pub bytes: usize,\n }\n \n /// A single source in the CodeMap\n@@ -306,11 +306,11 @@ impl FileMap {\n \n     /// get a line from the list of pre-computed line-beginnings\n     ///\n-    pub fn get_line(&self, line_number: uint) -> Option<String> {\n+    pub fn get_line(&self, line_number: usize) -> Option<String> {\n         let lines = self.lines.borrow();\n         lines.get(line_number).map(|&line| {\n             let begin: BytePos = line - self.start_pos;\n-            let begin = begin.to_uint();\n+            let begin = begin.to_usize();\n             let slice = &self.src[begin..];\n             match slice.find('\\n') {\n                 Some(e) => &slice[..e],\n@@ -319,7 +319,7 @@ impl FileMap {\n         })\n     }\n \n-    pub fn record_multibyte_char(&self, pos: BytePos, bytes: uint) {\n+    pub fn record_multibyte_char(&self, pos: BytePos, bytes: usize) {\n         assert!(bytes >=2 && bytes <= 4);\n         let mbc = MultiByteChar {\n             pos: pos,\n@@ -351,7 +351,7 @@ impl CodeMap {\n         let mut files = self.files.borrow_mut();\n         let start_pos = match files.last() {\n             None => 0,\n-            Some(last) => last.start_pos.to_uint() + last.src.len(),\n+            Some(last) => last.start_pos.to_usize() + last.src.len(),\n         };\n \n         // Remove utf-8 BOM if any.\n@@ -374,7 +374,7 @@ impl CodeMap {\n         let filemap = Rc::new(FileMap {\n             name: filename,\n             src: src.to_string(),\n-            start_pos: Pos::from_uint(start_pos),\n+            start_pos: Pos::from_usize(start_pos),\n             lines: RefCell::new(Vec::new()),\n             multibyte_chars: RefCell::new(Vec::new()),\n         });\n@@ -389,7 +389,7 @@ impl CodeMap {\n         (format!(\"<{}:{}:{}>\",\n                  pos.file.name,\n                  pos.line,\n-                 pos.col.to_uint() + 1)).to_string()\n+                 pos.col.to_usize() + 1)).to_string()\n     }\n \n     /// Lookup source information about a BytePos\n@@ -417,9 +417,9 @@ impl CodeMap {\n         return (format!(\"{}:{}:{}: {}:{}\",\n                         lo.filename,\n                         lo.line,\n-                        lo.col.to_uint() + 1,\n+                        lo.col.to_usize() + 1,\n                         hi.line,\n-                        hi.col.to_uint() + 1)).to_string()\n+                        hi.col.to_usize() + 1)).to_string()\n     }\n \n     pub fn span_to_filename(&self, sp: Span) -> FileName {\n@@ -430,7 +430,7 @@ impl CodeMap {\n         let lo = self.lookup_char_pos(sp.lo);\n         let hi = self.lookup_char_pos(sp.hi);\n         let mut lines = Vec::new();\n-        for i in range(lo.line - 1u, hi.line as uint) {\n+        for i in range(lo.line - 1us, hi.line as usize) {\n             lines.push(i);\n         };\n         FileLines {file: lo.file, lines: lines}\n@@ -447,7 +447,7 @@ impl CodeMap {\n         if begin.fm.start_pos != end.fm.start_pos {\n             None\n         } else {\n-            Some((&begin.fm.src[begin.pos.to_uint()..end.pos.to_uint()]).to_string())\n+            Some((&begin.fm.src[begin.pos.to_usize()..end.pos.to_usize()]).to_string())\n         }\n     }\n \n@@ -484,24 +484,24 @@ impl CodeMap {\n                 total_extra_bytes += mbc.bytes - 1;\n                 // We should never see a byte position in the middle of a\n                 // character\n-                assert!(bpos.to_uint() >= mbc.pos.to_uint() + mbc.bytes);\n+                assert!(bpos.to_usize() >= mbc.pos.to_usize() + mbc.bytes);\n             } else {\n                 break;\n             }\n         }\n \n-        assert!(map.start_pos.to_uint() + total_extra_bytes <= bpos.to_uint());\n-        CharPos(bpos.to_uint() - map.start_pos.to_uint() - total_extra_bytes)\n+        assert!(map.start_pos.to_usize() + total_extra_bytes <= bpos.to_usize());\n+        CharPos(bpos.to_usize() - map.start_pos.to_usize() - total_extra_bytes)\n     }\n \n-    fn lookup_filemap_idx(&self, pos: BytePos) -> uint {\n+    fn lookup_filemap_idx(&self, pos: BytePos) -> usize {\n         let files = self.files.borrow();\n         let files = &*files;\n         let len = files.len();\n-        let mut a = 0u;\n+        let mut a = 0us;\n         let mut b = len;\n-        while b - a > 1u {\n-            let m = (a + b) / 2u;\n+        while b - a > 1us {\n+            let m = (a + b) / 2us;\n             if files[m].start_pos > pos {\n                 b = m;\n             } else {\n@@ -520,13 +520,13 @@ impl CodeMap {\n             }\n             if a == 0 {\n                 panic!(\"position {} does not resolve to a source location\",\n-                      pos.to_uint());\n+                      pos.to_usize());\n             }\n             a -= 1;\n         }\n         if a >= len {\n             panic!(\"position {} does not resolve to a source location\",\n-                  pos.to_uint())\n+                  pos.to_usize())\n         }\n \n         return a;\n@@ -537,12 +537,12 @@ impl CodeMap {\n \n         let files = self.files.borrow();\n         let f = (*files)[idx].clone();\n-        let mut a = 0u;\n+        let mut a = 0us;\n         {\n             let lines = f.lines.borrow();\n             let mut b = lines.len();\n-            while b - a > 1u {\n-                let m = (a + b) / 2u;\n+            while b - a > 1us {\n+                let m = (a + b) / 2us;\n                 if (*lines)[m] > pos { b = m; } else { a = m; }\n             }\n         }\n@@ -551,7 +551,7 @@ impl CodeMap {\n \n     fn lookup_pos(&self, pos: BytePos) -> Loc {\n         let FileMapAndLine {fm: f, line: a} = self.lookup_line(pos);\n-        let line = a + 1u; // Line numbers start at 1\n+        let line = a + 1us; // Line numbers start at 1\n         let chpos = self.bytepos_to_file_charpos(pos);\n         let linebpos = (*f.lines.borrow())[a];\n         let linechpos = self.bytepos_to_file_charpos(linebpos);\n@@ -579,7 +579,7 @@ impl CodeMap {\n     {\n         match id {\n             NO_EXPANSION => f(None),\n-            ExpnId(i) => f(Some(&(*self.expansions.borrow())[i as uint]))\n+            ExpnId(i) => f(Some(&(*self.expansions.borrow())[i as usize]))\n         }\n     }\n \n@@ -762,7 +762,7 @@ mod test {\n \n         assert_eq!(file_lines.file.name, \"blork.rs\");\n         assert_eq!(file_lines.lines.len(), 1);\n-        assert_eq!(file_lines.lines[0], 1u);\n+        assert_eq!(file_lines.lines[0], 1us);\n     }\n \n     #[test]"}, {"sha": "c17ad058ada66c8663a3a4a806a131eb68afb44f", "filename": "src/libsyntax/diagnostic.rs", "status": "modified", "additions": 20, "deletions": 20, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fdiagnostic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fdiagnostic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostic.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -26,7 +26,7 @@ use term::WriterWrapper;\n use term;\n \n /// maximum number of lines we will print for each error; arbitrary.\n-static MAX_LINES: uint = 6u;\n+static MAX_LINES: usize = 6us;\n \n #[derive(Clone, Copy)]\n pub enum RenderSpan {\n@@ -141,7 +141,7 @@ impl SpanHandler {\n /// (fatal, bug, unimpl) may cause immediate exit,\n /// others log errors for later reporting.\n pub struct Handler {\n-    err_count: Cell<uint>,\n+    err_count: Cell<usize>,\n     emit: RefCell<Box<Emitter + Send>>,\n }\n \n@@ -155,20 +155,20 @@ impl Handler {\n         self.bump_err_count();\n     }\n     pub fn bump_err_count(&self) {\n-        self.err_count.set(self.err_count.get() + 1u);\n+        self.err_count.set(self.err_count.get() + 1us);\n     }\n-    pub fn err_count(&self) -> uint {\n+    pub fn err_count(&self) -> usize {\n         self.err_count.get()\n     }\n     pub fn has_errors(&self) -> bool {\n-        self.err_count.get()> 0u\n+        self.err_count.get() > 0us\n     }\n     pub fn abort_if_errors(&self) {\n         let s;\n         match self.err_count.get() {\n-          0u => return,\n-          1u => s = \"aborting due to previous error\".to_string(),\n-          _  => {\n+          0us => return,\n+          1us => s = \"aborting due to previous error\".to_string(),\n+          _   => {\n             s = format!(\"aborting due to {} previous errors\",\n                         self.err_count.get());\n           }\n@@ -452,7 +452,7 @@ fn highlight_lines(err: &mut EmitterWriter,\n     let mut elided = false;\n     let mut display_lines = &lines.lines[];\n     if display_lines.len() > MAX_LINES {\n-        display_lines = &display_lines[0u..MAX_LINES];\n+        display_lines = &display_lines[0us..MAX_LINES];\n         elided = true;\n     }\n     // Print the offending lines\n@@ -463,32 +463,32 @@ fn highlight_lines(err: &mut EmitterWriter,\n         }\n     }\n     if elided {\n-        let last_line = display_lines[display_lines.len() - 1u];\n-        let s = format!(\"{}:{} \", fm.name, last_line + 1u);\n+        let last_line = display_lines[display_lines.len() - 1us];\n+        let s = format!(\"{}:{} \", fm.name, last_line + 1us);\n         try!(write!(&mut err.dst, \"{0:1$}...\\n\", \"\", s.len()));\n     }\n \n     // FIXME (#3260)\n     // If there's one line at fault we can easily point to the problem\n-    if lines.lines.len() == 1u {\n+    if lines.lines.len() == 1us {\n         let lo = cm.lookup_char_pos(sp.lo);\n-        let mut digits = 0u;\n-        let mut num = (lines.lines[0] + 1u) / 10u;\n+        let mut digits = 0us;\n+        let mut num = (lines.lines[0] + 1us) / 10us;\n \n         // how many digits must be indent past?\n-        while num > 0u { num /= 10u; digits += 1u; }\n+        while num > 0us { num /= 10us; digits += 1us; }\n \n         // indent past |name:## | and the 0-offset column location\n-        let left = fm.name.len() + digits + lo.col.to_uint() + 3u;\n+        let left = fm.name.len() + digits + lo.col.to_usize() + 3us;\n         let mut s = String::new();\n         // Skip is the number of characters we need to skip because they are\n         // part of the 'filename:line ' part of the previous line.\n-        let skip = fm.name.len() + digits + 3u;\n+        let skip = fm.name.len() + digits + 3us;\n         for _ in range(0, skip) {\n             s.push(' ');\n         }\n         if let Some(orig) = fm.get_line(lines.lines[0]) {\n-            for pos in range(0u, left - skip) {\n+            for pos in range(0us, left - skip) {\n                 let cur_char = orig.as_bytes()[pos] as char;\n                 // Whenever a tab occurs on the previous line, we insert one on\n                 // the error-point-squiggly-line as well (instead of a space).\n@@ -506,7 +506,7 @@ fn highlight_lines(err: &mut EmitterWriter,\n         let hi = cm.lookup_char_pos(sp.hi);\n         if hi.col != lo.col {\n             // the ^ already takes up one space\n-            let num_squigglies = hi.col.to_uint() - lo.col.to_uint() - 1u;\n+            let num_squigglies = hi.col.to_usize() - lo.col.to_usize() - 1us;\n             for _ in range(0, num_squigglies) {\n                 s.push('~');\n             }\n@@ -555,7 +555,7 @@ fn custom_highlight_lines(w: &mut EmitterWriter,\n     let last_line_start = format!(\"{}:{} \", fm.name, lines[lines.len()-1]+1);\n     let hi = cm.lookup_char_pos(sp.hi);\n     // Span seems to use half-opened interval, so subtract 1\n-    let skip = last_line_start.len() + hi.col.to_uint() - 1;\n+    let skip = last_line_start.len() + hi.col.to_usize() - 1;\n     let mut s = String::new();\n     for _ in range(0, skip) {\n         s.push(' ');"}, {"sha": "9128bc05f6f3d48f038d3de752499281cfa77511", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -548,7 +548,7 @@ pub struct ExtCtxt<'a> {\n     pub exported_macros: Vec<ast::MacroDef>,\n \n     pub syntax_env: SyntaxEnv,\n-    pub recursion_count: uint,\n+    pub recursion_count: usize,\n }\n \n impl<'a> ExtCtxt<'a> {"}, {"sha": "8773c0f2f79b8825c4cf4138bb0902d6b530c535", "filename": "src/libsyntax/ext/build.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbuild.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -116,7 +116,7 @@ pub trait AstBuilder {\n     fn expr_mut_addr_of(&self, sp: Span, e: P<ast::Expr>) -> P<ast::Expr>;\n     fn expr_field_access(&self, span: Span, expr: P<ast::Expr>, ident: ast::Ident) -> P<ast::Expr>;\n     fn expr_tup_field_access(&self, sp: Span, expr: P<ast::Expr>,\n-                             idx: uint) -> P<ast::Expr>;\n+                             idx: usize) -> P<ast::Expr>;\n     fn expr_call(&self, span: Span, expr: P<ast::Expr>, args: Vec<P<ast::Expr>>) -> P<ast::Expr>;\n     fn expr_call_ident(&self, span: Span, id: ast::Ident, args: Vec<P<ast::Expr>>) -> P<ast::Expr>;\n     fn expr_call_global(&self, sp: Span, fn_path: Vec<ast::Ident>,\n@@ -134,8 +134,8 @@ pub trait AstBuilder {\n \n     fn expr_lit(&self, sp: Span, lit: ast::Lit_) -> P<ast::Expr>;\n \n-    fn expr_uint(&self, span: Span, i: uint) -> P<ast::Expr>;\n-    fn expr_int(&self, sp: Span, i: int) -> P<ast::Expr>;\n+    fn expr_usize(&self, span: Span, i: usize) -> P<ast::Expr>;\n+    fn expr_int(&self, sp: Span, i: isize) -> P<ast::Expr>;\n     fn expr_u8(&self, sp: Span, u: u8) -> P<ast::Expr>;\n     fn expr_bool(&self, sp: Span, value: bool) -> P<ast::Expr>;\n \n@@ -579,17 +579,17 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n     fn expr_field_access(&self, sp: Span, expr: P<ast::Expr>, ident: ast::Ident) -> P<ast::Expr> {\n         let field_name = token::get_ident(ident);\n         let field_span = Span {\n-            lo: sp.lo - Pos::from_uint(field_name.get().len()),\n+            lo: sp.lo - Pos::from_usize(field_name.get().len()),\n             hi: sp.hi,\n             expn_id: sp.expn_id,\n         };\n \n         let id = Spanned { node: ident, span: field_span };\n         self.expr(sp, ast::ExprField(expr, id))\n     }\n-    fn expr_tup_field_access(&self, sp: Span, expr: P<ast::Expr>, idx: uint) -> P<ast::Expr> {\n+    fn expr_tup_field_access(&self, sp: Span, expr: P<ast::Expr>, idx: usize) -> P<ast::Expr> {\n         let field_span = Span {\n-            lo: sp.lo - Pos::from_uint(idx.to_string().len()),\n+            lo: sp.lo - Pos::from_usize(idx.to_string().len()),\n             hi: sp.hi,\n             expn_id: sp.expn_id,\n         };\n@@ -641,10 +641,10 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n     fn expr_lit(&self, sp: Span, lit: ast::Lit_) -> P<ast::Expr> {\n         self.expr(sp, ast::ExprLit(P(respan(sp, lit))))\n     }\n-    fn expr_uint(&self, span: Span, i: uint) -> P<ast::Expr> {\n+    fn expr_usize(&self, span: Span, i: usize) -> P<ast::Expr> {\n         self.expr_lit(span, ast::LitInt(i as u64, ast::UnsignedIntLit(ast::TyUs(false))))\n     }\n-    fn expr_int(&self, sp: Span, i: int) -> P<ast::Expr> {\n+    fn expr_int(&self, sp: Span, i: isize) -> P<ast::Expr> {\n         self.expr_lit(sp, ast::LitInt(i as u64, ast::SignedIntLit(ast::TyIs(false),\n                                                                   ast::Sign::new(i))))\n     }\n@@ -710,7 +710,7 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n         let loc = self.codemap().lookup_char_pos(span.lo);\n         let expr_file = self.expr_str(span,\n                                       token::intern_and_get_ident(&loc.file.name[]));\n-        let expr_line = self.expr_uint(span, loc.line);\n+        let expr_line = self.expr_usize(span, loc.line);\n         let expr_file_line_tuple = self.expr_tuple(span, vec!(expr_file, expr_line));\n         let expr_file_line_ptr = self.expr_addr_of(span, expr_file_line_tuple);\n         self.expr_call_global("}, {"sha": "e458bd58e8b6a8cb51a1865f7bdc033f565d9330", "filename": "src/libsyntax/ext/deriving/decodable.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -114,7 +114,7 @@ fn decodable_substructure(cx: &mut ExtCtxt, trait_span: Span,\n                 cx.expr_try(span,\n                     cx.expr_method_call(span, blkdecoder.clone(), read_struct_field,\n                                         vec!(cx.expr_str(span, name),\n-                                          cx.expr_uint(span, field),\n+                                          cx.expr_usize(span, field),\n                                           exprdecode.clone())))\n             });\n             let result = cx.expr_ok(trait_span, result);\n@@ -123,7 +123,7 @@ fn decodable_substructure(cx: &mut ExtCtxt, trait_span: Span,\n                                 cx.ident_of(\"read_struct\"),\n                                 vec!(\n                 cx.expr_str(trait_span, token::get_ident(substr.type_ident)),\n-                cx.expr_uint(trait_span, nfields),\n+                cx.expr_usize(trait_span, nfields),\n                 cx.lambda_expr_1(trait_span, result, blkarg)\n             ))\n         }\n@@ -143,14 +143,14 @@ fn decodable_substructure(cx: &mut ExtCtxt, trait_span: Span,\n                                                    path,\n                                                    parts,\n                                                    |cx, span, _, field| {\n-                    let idx = cx.expr_uint(span, field);\n+                    let idx = cx.expr_usize(span, field);\n                     cx.expr_try(span,\n                         cx.expr_method_call(span, blkdecoder.clone(), rvariant_arg,\n                                             vec!(idx, exprdecode.clone())))\n                 });\n \n                 arms.push(cx.arm(v_span,\n-                                 vec!(cx.pat_lit(v_span, cx.expr_uint(v_span, i))),\n+                                 vec!(cx.pat_lit(v_span, cx.expr_usize(v_span, i))),\n                                  decoded));\n             }\n \n@@ -179,14 +179,14 @@ fn decodable_substructure(cx: &mut ExtCtxt, trait_span: Span,\n \n /// Create a decoder for a single enum variant/struct:\n /// - `outer_pat_path` is the path to this enum variant/struct\n-/// - `getarg` should retrieve the `uint`-th field with name `@str`.\n+/// - `getarg` should retrieve the `usize`-th field with name `@str`.\n fn decode_static_fields<F>(cx: &mut ExtCtxt,\n                            trait_span: Span,\n                            outer_pat_path: ast::Path,\n                            fields: &StaticFields,\n                            mut getarg: F)\n                            -> P<Expr> where\n-    F: FnMut(&mut ExtCtxt, Span, InternedString, uint) -> P<Expr>,\n+    F: FnMut(&mut ExtCtxt, Span, InternedString, usize) -> P<Expr>,\n {\n     match *fields {\n         Unnamed(ref fields) => {"}, {"sha": "f8fdd8575bd67dce5246129daa8c631d277ab422", "filename": "src/libsyntax/ext/deriving/default.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fdefault.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fdefault.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fdefault.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -79,7 +79,7 @@ fn default_substructure(cx: &mut ExtCtxt, trait_span: Span, substr: &Substructur\n         StaticEnum(..) => {\n             cx.span_err(trait_span, \"`Default` cannot be derived for enums, only structs\");\n             // let compilation continue\n-            cx.expr_uint(trait_span, 0)\n+            cx.expr_usize(trait_span, 0)\n         }\n         _ => cx.span_bug(trait_span, \"Non-static method in `derive(Default)`\")\n     };"}, {"sha": "4c78a7b6a0cfefaf7cb6b7840cd5ac964e885e93", "filename": "src/libsyntax/ext/deriving/encodable.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fencodable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fencodable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fencodable.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -16,7 +16,7 @@\n //!\n //! ```ignore\n //! #[derive(Encodable, Decodable)]\n-//! struct Node { id: uint }\n+//! struct Node { id: usize }\n //! ```\n //!\n //! would generate two implementations like:\n@@ -27,7 +27,7 @@\n //!         s.emit_struct(\"Node\", 1, |this| {\n //!             this.emit_struct_field(\"id\", 0, |this| {\n //!                 Encodable::encode(&self.id, this)\n-//!                 /* this.emit_uint(self.id) can also be used */\n+//!                 /* this.emit_usize(self.id) can also be used */\n //!             })\n //!         })\n //!     }\n@@ -192,7 +192,7 @@ fn encodable_substructure(cx: &mut ExtCtxt, trait_span: Span,\n                 let call = cx.expr_method_call(span, blkencoder.clone(),\n                                                emit_struct_field,\n                                                vec!(cx.expr_str(span, name),\n-                                                 cx.expr_uint(span, i),\n+                                                 cx.expr_usize(span, i),\n                                                  lambda));\n \n                 // last call doesn't need a try!\n@@ -218,7 +218,7 @@ fn encodable_substructure(cx: &mut ExtCtxt, trait_span: Span,\n                                 cx.ident_of(\"emit_struct\"),\n                                 vec!(\n                 cx.expr_str(trait_span, token::get_ident(substr.type_ident)),\n-                cx.expr_uint(trait_span, fields.len()),\n+                cx.expr_usize(trait_span, fields.len()),\n                 blk\n             ))\n         }\n@@ -239,7 +239,7 @@ fn encodable_substructure(cx: &mut ExtCtxt, trait_span: Span,\n                 let lambda = cx.lambda_expr_1(span, enc, blkarg);\n                 let call = cx.expr_method_call(span, blkencoder.clone(),\n                                                emit_variant_arg,\n-                                               vec!(cx.expr_uint(span, i),\n+                                               vec!(cx.expr_usize(span, i),\n                                                  lambda));\n                 let call = if i != last {\n                     cx.expr_try(span, call)\n@@ -262,8 +262,8 @@ fn encodable_substructure(cx: &mut ExtCtxt, trait_span: Span,\n             let call = cx.expr_method_call(trait_span, blkencoder,\n                                            cx.ident_of(\"emit_enum_variant\"),\n                                            vec!(name,\n-                                             cx.expr_uint(trait_span, idx),\n-                                             cx.expr_uint(trait_span, fields.len()),\n+                                             cx.expr_usize(trait_span, idx),\n+                                             cx.expr_usize(trait_span, fields.len()),\n                                              blk));\n             let blk = cx.lambda_expr_1(trait_span, call, blkarg);\n             let ret = cx.expr_method_call(trait_span,"}, {"sha": "583f316289ff94bf2f61881cd653a105efc0143b", "filename": "src/libsyntax/ext/deriving/generic/mod.rs", "status": "modified", "additions": 24, "deletions": 24, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fmod.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -28,7 +28,7 @@\n //! arguments:\n //!\n //! - `Struct`, when `Self` is a struct (including tuple structs, e.g\n-//!   `struct T(int, char)`).\n+//!   `struct T(i32, char)`).\n //! - `EnumMatching`, when `Self` is an enum and all the arguments are the\n //!   same variant of the enum (e.g. `Some(1)`, `Some(3)` and `Some(4)`)\n //! - `EnumNonMatchingCollapsed` when `Self` is an enum and the arguments\n@@ -54,17 +54,17 @@\n //! following snippet\n //!\n //! ```rust\n-//! struct A { x : int }\n+//! struct A { x : i32 }\n //!\n-//! struct B(int);\n+//! struct B(i32);\n //!\n //! enum C {\n-//!     C0(int),\n-//!     C1 { x: int }\n+//!     C0(i32),\n+//!     C1 { x: i32 }\n //! }\n //! ```\n //!\n-//! The `int`s in `B` and `C0` don't have an identifier, so the\n+//! The `i32`s in `B` and `C0` don't have an identifier, so the\n //! `Option<ident>`s would be `None` for them.\n //!\n //! In the static cases, the structure is summarised, either into the just\n@@ -90,8 +90,8 @@\n //! trait PartialEq {\n //!     fn eq(&self, other: &Self);\n //! }\n-//! impl PartialEq for int {\n-//!     fn eq(&self, other: &int) -> bool {\n+//! impl PartialEq for i32 {\n+//!     fn eq(&self, other: &i32) -> bool {\n //!         *self == *other\n //!     }\n //! }\n@@ -117,7 +117,7 @@\n //!\n //! ```{.text}\n //! Struct(vec![FieldInfo {\n-//!           span: <span of `int`>,\n+//!           span: <span of `i32`>,\n //!           name: None,\n //!           self_: <expr for &a>\n //!           other: vec![<expr for &b>]\n@@ -132,7 +132,7 @@\n //! ```{.text}\n //! EnumMatching(0, <ast::Variant for C0>,\n //!              vec![FieldInfo {\n-//!                 span: <span of int>\n+//!                 span: <span of i32>\n //!                 name: None,\n //!                 self_: <expr for &a>,\n //!                 other: vec![<expr for &b>]\n@@ -179,7 +179,7 @@\n //! StaticStruct(<ast::StructDef of B>, Unnamed(vec![<span of x>]))\n //!\n //! StaticEnum(<ast::EnumDef of C>,\n-//!            vec![(<ident of C0>, <span of C0>, Unnamed(vec![<span of int>])),\n+//!            vec![(<ident of C0>, <span of C0>, Unnamed(vec![<span of i32>])),\n //!                 (<ident of C1>, <span of C1>, Named(vec![(<ident of x>, <span of x>)]))])\n //! ```\n \n@@ -294,7 +294,7 @@ pub enum SubstructureFields<'a> {\n     /// Matching variants of the enum: variant index, ast::Variant,\n     /// fields: the field name is only non-`None` in the case of a struct\n     /// variant.\n-    EnumMatching(uint, &'a ast::Variant, Vec<FieldInfo>),\n+    EnumMatching(usize, &'a ast::Variant, Vec<FieldInfo>),\n \n     /// Non-matching variants of the enum, but with all state hidden from\n     /// the consequent code.  The first component holds `Ident`s for all of\n@@ -719,7 +719,7 @@ impl<'a> MethodDef<'a> {\n \n     /// ```\n     /// #[derive(PartialEq)]\n-    /// struct A { x: int, y: int }\n+    /// struct A { x: i32, y: i32 }\n     ///\n     /// // equivalent to:\n     /// impl PartialEq for A {\n@@ -748,7 +748,7 @@ impl<'a> MethodDef<'a> {\n         let mut raw_fields = Vec::new(); // ~[[fields of self],\n                                  // [fields of next Self arg], [etc]]\n         let mut patterns = Vec::new();\n-        for i in range(0u, self_args.len()) {\n+        for i in range(0us, self_args.len()) {\n             let struct_path= cx.path(DUMMY_SP, vec!( type_ident ));\n             let (pat, ident_expr) =\n                 trait_.create_struct_pattern(cx,\n@@ -825,7 +825,7 @@ impl<'a> MethodDef<'a> {\n     /// #[derive(PartialEq)]\n     /// enum A {\n     ///     A1,\n-    ///     A2(int)\n+    ///     A2(i32)\n     /// }\n     ///\n     /// // is equivalent to\n@@ -837,8 +837,8 @@ impl<'a> MethodDef<'a> {\n     ///             (&A2(ref __self_0),\n     ///              &A2(ref __arg_1_0)) => (*__self_0).eq(&(*__arg_1_0)),\n     ///             _ => {\n-    ///                 let __self_vi = match *self { A1(..) => 0u, A2(..) => 1u };\n-    ///                 let __arg_1_vi = match *__arg_1 { A1(..) => 0u, A2(..) => 1u };\n+    ///                 let __self_vi = match *self { A1(..) => 0us, A2(..) => 1us };\n+    ///                 let __arg_1_vi = match *__arg_1 { A1(..) => 0us, A2(..) => 1us };\n     ///                 false\n     ///             }\n     ///         }\n@@ -882,8 +882,8 @@ impl<'a> MethodDef<'a> {\n     ///   (Variant2, Variant2, Variant2) => ... // delegate Matching on Variant2\n     ///   ...\n     ///   _ => {\n-    ///     let __this_vi = match this { Variant1 => 0u, Variant2 => 1u, ... };\n-    ///     let __that_vi = match that { Variant1 => 0u, Variant2 => 1u, ... };\n+    ///     let __this_vi = match this { Variant1 => 0us, Variant2 => 1us, ... };\n+    ///     let __that_vi = match that { Variant1 => 0us, Variant2 => 1us, ... };\n     ///     ... // catch-all remainder can inspect above variant index values.\n     ///   }\n     /// }\n@@ -915,7 +915,7 @@ impl<'a> MethodDef<'a> {\n             .collect::<Vec<ast::Ident>>();\n \n         // The `vi_idents` will be bound, solely in the catch-all, to\n-        // a series of let statements mapping each self_arg to a uint\n+        // a series of let statements mapping each self_arg to a usize\n         // corresponding to its variant index.\n         let vi_idents: Vec<ast::Ident> = self_arg_names.iter()\n             .map(|name| { let vi_suffix = format!(\"{}_vi\", &name[]);\n@@ -1039,19 +1039,19 @@ impl<'a> MethodDef<'a> {\n                 }).collect();\n \n             // Build a series of let statements mapping each self_arg\n-            // to a uint corresponding to its variant index.\n+            // to a usize corresponding to its variant index.\n             // i.e. for `enum E<T> { A, B(1), C(T, T) }`, and a deriving\n             // with three Self args, builds three statements:\n             //\n             // ```\n             // let __self0_vi = match   self {\n-            //     A => 0u, B(..) => 1u, C(..) => 2u\n+            //     A => 0us, B(..) => 1us, C(..) => 2us\n             // };\n             // let __self1_vi = match __arg1 {\n-            //     A => 0u, B(..) => 1u, C(..) => 2u\n+            //     A => 0us, B(..) => 1us, C(..) => 2us\n             // };\n             // let __self2_vi = match __arg2 {\n-            //     A => 0u, B(..) => 1u, C(..) => 2u\n+            //     A => 0us, B(..) => 1us, C(..) => 2us\n             // };\n             // ```\n             let mut index_let_stmts: Vec<P<ast::Stmt>> = Vec::new();"}, {"sha": "85682d41b5ff65cffcdb971ca178d9d9d10c244e", "filename": "src/libsyntax/ext/deriving/generic/ty.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fty.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -32,7 +32,7 @@ pub enum PtrTy<'a> {\n     Raw(ast::Mutability),\n }\n \n-/// A path, e.g. `::std::option::Option::<int>` (global). Has support\n+/// A path, e.g. `::std::option::Option::<i32>` (global). Has support\n /// for type parameters and a lifetime.\n #[derive(Clone)]\n pub struct Path<'a> {\n@@ -91,7 +91,7 @@ pub enum Ty<'a> {\n     /// &/Box/ Ty\n     Ptr(Box<Ty<'a>>, PtrTy<'a>),\n     /// mod::mod::Type<[lifetime], [Params...]>, including a plain type\n-    /// parameter, and things like `int`\n+    /// parameter, and things like `i32`\n     Literal(Path<'a>),\n     /// includes unit\n     Tuple(Vec<Ty<'a>> )"}, {"sha": "8dac864c2ae3b689b9a89e38b3faa13f57c44b4d", "filename": "src/libsyntax/ext/deriving/hash.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fhash.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Fhash.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fhash.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -89,7 +89,7 @@ fn hash_substructure(cx: &mut ExtCtxt, trait_span: Span, substr: &Substructure)\n             // iteration function.\n             let discriminant = match variant.node.disr_expr {\n                 Some(ref d) => d.clone(),\n-                None => cx.expr_uint(trait_span, index)\n+                None => cx.expr_usize(trait_span, index)\n             };\n \n             stmts.push(call_hash(trait_span, discriminant));"}, {"sha": "bb902d7059c87b8aeacd4bd5eaa76e51f37b48b1", "filename": "src/libsyntax/ext/deriving/rand.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Frand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fderiving%2Frand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Frand.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -80,10 +80,10 @@ fn rand_substructure(cx: &mut ExtCtxt, trait_span: Span, substr: &Substructure)\n             if variants.is_empty() {\n                 cx.span_err(trait_span, \"`Rand` cannot be derived for enums with no variants\");\n                 // let compilation continue\n-                return cx.expr_uint(trait_span, 0);\n+                return cx.expr_usize(trait_span, 0);\n             }\n \n-            let variant_count = cx.expr_uint(trait_span, variants.len());\n+            let variant_count = cx.expr_usize(trait_span, variants.len());\n \n             let rand_name = cx.path_all(trait_span,\n                                         true,\n@@ -115,7 +115,7 @@ fn rand_substructure(cx: &mut ExtCtxt, trait_span: Span, substr: &Substructure)\n                                               variant_count);\n \n             let mut arms = variants.iter().enumerate().map(|(i, &(ident, v_span, ref summary))| {\n-                let i_expr = cx.expr_uint(v_span, i);\n+                let i_expr = cx.expr_usize(v_span, i);\n                 let pat = cx.pat_lit(v_span, i_expr);\n \n                 let path = cx.path(v_span, vec![substr.type_ident, ident]);"}, {"sha": "9f6bf352b040443609c0c30943259b5f8b0656d7", "filename": "src/libsyntax/ext/env.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fenv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fenv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fenv.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -104,7 +104,7 @@ pub fn expand_env<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n     let e = match os::getenv(var.get()) {\n         None => {\n             cx.span_err(sp, msg.get());\n-            cx.expr_uint(sp, 0)\n+            cx.expr_usize(sp, 0)\n         }\n         Some(s) => cx.expr_str(sp, token::intern_and_get_ident(&s[]))\n     };"}, {"sha": "9aa602b39b4f6ec463908a923e6b4e1c2ee18777", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 28, "deletions": 28, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -273,7 +273,7 @@ fn expand_mac_invoc<T, F, G>(mac: ast::Mac, span: codemap::Span,\n         // in this file.\n         // Token-tree macros:\n         MacInvocTT(pth, tts, _) => {\n-            if pth.segments.len() > 1u {\n+            if pth.segments.len() > 1us {\n                 fld.cx.span_err(pth.span,\n                                 \"expected macro name without module \\\n                                 separators\");\n@@ -844,7 +844,7 @@ fn expand_pat(p: P<ast::Pat>, fld: &mut MacroExpander) -> P<ast::Pat> {\n             },\n             _ => unreachable!()\n         };\n-        if pth.segments.len() > 1u {\n+        if pth.segments.len() > 1us {\n             fld.cx.span_err(pth.span, \"expected macro name without module separators\");\n             return DummyResult::raw_pat(span);\n         }\n@@ -1311,7 +1311,7 @@ fn new_span(cx: &ExtCtxt, sp: Span) -> Span {\n pub struct ExpansionConfig {\n     pub crate_name: String,\n     pub enable_quotes: bool,\n-    pub recursion_limit: uint,\n+    pub recursion_limit: usize,\n }\n \n impl ExpansionConfig {\n@@ -1507,7 +1507,7 @@ mod test {\n     #[should_fail]\n     #[test] fn macros_cant_escape_fns_test () {\n         let src = \"fn bogus() {macro_rules! z (() => (3+4));}\\\n-                   fn inty() -> int { z!() }\".to_string();\n+                   fn inty() -> i32 { z!() }\".to_string();\n         let sess = parse::new_parse_sess();\n         let crate_ast = parse::parse_crate_from_source_str(\n             \"<test>\".to_string(),\n@@ -1521,7 +1521,7 @@ mod test {\n     #[should_fail]\n     #[test] fn macros_cant_escape_mods_test () {\n         let src = \"mod foo {macro_rules! z (() => (3+4));}\\\n-                   fn inty() -> int { z!() }\".to_string();\n+                   fn inty() -> i32 { z!() }\".to_string();\n         let sess = parse::new_parse_sess();\n         let crate_ast = parse::parse_crate_from_source_str(\n             \"<test>\".to_string(),\n@@ -1533,7 +1533,7 @@ mod test {\n     // macro_use modules should allow macros to escape\n     #[test] fn macros_can_escape_flattened_mods_test () {\n         let src = \"#[macro_use] mod foo {macro_rules! z (() => (3+4));}\\\n-                   fn inty() -> int { z!() }\".to_string();\n+                   fn inty() -> i32 { z!() }\".to_string();\n         let sess = parse::new_parse_sess();\n         let crate_ast = parse::parse_crate_from_source_str(\n             \"<test>\".to_string(),\n@@ -1564,8 +1564,8 @@ mod test {\n     // should be able to use a bound identifier as a literal in a macro definition:\n     #[test] fn self_macro_parsing(){\n         expand_crate_str(\n-            \"macro_rules! foo ((zz) => (287u;));\n-            fn f(zz : int) {foo!(zz);}\".to_string()\n+            \"macro_rules! foo ((zz) => (287;));\n+            fn f(zz: i32) {foo!(zz);}\".to_string()\n             );\n     }\n \n@@ -1595,29 +1595,29 @@ mod test {\n     // in principle, you might want to control this boolean on a per-varref basis,\n     // but that would make things even harder to understand, and might not be\n     // necessary for thorough testing.\n-    type RenamingTest = (&'static str, Vec<Vec<uint>>, bool);\n+    type RenamingTest = (&'static str, Vec<Vec<usize>>, bool);\n \n     #[test]\n     fn automatic_renaming () {\n         let tests: Vec<RenamingTest> =\n             vec!(// b & c should get new names throughout, in the expr too:\n-                (\"fn a() -> int { let b = 13; let c = b; b+c }\",\n+                (\"fn a() -> i32 { let b = 13; let c = b; b+c }\",\n                  vec!(vec!(0,1),vec!(2)), false),\n                 // both x's should be renamed (how is this causing a bug?)\n-                (\"fn main () {let x: int = 13;x;}\",\n+                (\"fn main () {let x: i32 = 13;x;}\",\n                  vec!(vec!(0)), false),\n                 // the use of b after the + should be renamed, the other one not:\n-                (\"macro_rules! f (($x:ident) => (b + $x)); fn a() -> int { let b = 13; f!(b)}\",\n+                (\"macro_rules! f (($x:ident) => (b + $x)); fn a() -> i32 { let b = 13; f!(b)}\",\n                  vec!(vec!(1)), false),\n                 // the b before the plus should not be renamed (requires marks)\n-                (\"macro_rules! f (($x:ident) => ({let b=9; ($x + b)})); fn a() -> int { f!(b)}\",\n+                (\"macro_rules! f (($x:ident) => ({let b=9; ($x + b)})); fn a() -> i32 { f!(b)}\",\n                  vec!(vec!(1)), false),\n                 // the marks going in and out of letty should cancel, allowing that $x to\n                 // capture the one following the semicolon.\n                 // this was an awesome test case, and caught a *lot* of bugs.\n                 (\"macro_rules! letty(($x:ident) => (let $x = 15;));\n                   macro_rules! user(($x:ident) => ({letty!($x); $x}));\n-                  fn main() -> int {user!(z)}\",\n+                  fn main() -> i32 {user!(z)}\",\n                  vec!(vec!(0)), false)\n                 );\n         for (idx,s) in tests.iter().enumerate() {\n@@ -1680,13 +1680,13 @@ mod test {\n     // can't write this test case until we have macro-generating macros.\n \n     // method arg hygiene\n-    // method expands to fn get_x(&self_0, x_1:int) {self_0 + self_2 + x_3 + x_1}\n+    // method expands to fn get_x(&self_0, x_1: i32) {self_0 + self_2 + x_3 + x_1}\n     #[test] fn method_arg_hygiene(){\n         run_renaming_test(\n             &(\"macro_rules! inject_x (()=>(x));\n               macro_rules! inject_self (()=>(self));\n               struct A;\n-              impl A{fn get_x(&self, x: int) {self + inject_self!() + inject_x!() + x;} }\",\n+              impl A{fn get_x(&self, x: i32) {self + inject_self!() + inject_x!() + x;} }\",\n               vec!(vec!(0),vec!(3)),\n               true),\n             0)\n@@ -1706,21 +1706,21 @@ mod test {\n     }\n \n     // item fn hygiene\n-    // expands to fn q(x_1:int){fn g(x_2:int){x_2 + x_1};}\n+    // expands to fn q(x_1: i32){fn g(x_2: i32){x_2 + x_1};}\n     #[test] fn issue_9383(){\n         run_renaming_test(\n-            &(\"macro_rules! bad_macro (($ex:expr) => (fn g(x:int){ x + $ex }));\n-              fn q(x:int) { bad_macro!(x); }\",\n+            &(\"macro_rules! bad_macro (($ex:expr) => (fn g(x: i32){ x + $ex }));\n+              fn q(x: i32) { bad_macro!(x); }\",\n               vec!(vec!(1),vec!(0)),true),\n             0)\n     }\n \n     // closure arg hygiene (ExprClosure)\n-    // expands to fn f(){(|x_1 : int| {(x_2 + x_1)})(3);}\n+    // expands to fn f(){(|x_1 : i32| {(x_2 + x_1)})(3);}\n     #[test] fn closure_arg_hygiene(){\n         run_renaming_test(\n             &(\"macro_rules! inject_x (()=>(x));\n-            fn f(){(|x : int| {(inject_x!() + x)})(3);}\",\n+            fn f(){(|x : i32| {(inject_x!() + x)})(3);}\",\n               vec!(vec!(1)),\n               true),\n             0)\n@@ -1729,7 +1729,7 @@ mod test {\n     // macro_rules in method position. Sadly, unimplemented.\n     #[test] fn macro_in_method_posn(){\n         expand_crate_str(\n-            \"macro_rules! my_method (() => (fn thirteen(&self) -> int {13}));\n+            \"macro_rules! my_method (() => (fn thirteen(&self) -> i32 {13}));\n             struct A;\n             impl A{ my_method!(); }\n             fn f(){A.thirteen;}\".to_string());\n@@ -1749,7 +1749,7 @@ mod test {\n     }\n \n     // run one of the renaming tests\n-    fn run_renaming_test(t: &RenamingTest, test_idx: uint) {\n+    fn run_renaming_test(t: &RenamingTest, test_idx: usize) {\n         let invalid_name = token::special_idents::invalid.name;\n         let (teststr, bound_connections, bound_ident_check) = match *t {\n             (ref str,ref conns, bic) => (str.to_string(), conns.clone(), bic)\n@@ -1876,7 +1876,7 @@ foo_module!();\n     // it's the name of a 0-ary variant, and that 'i' appears twice in succession.\n     #[test]\n     fn crate_bindings_test(){\n-        let the_crate = string_to_crate(\"fn main (a : int) -> int {|b| {\n+        let the_crate = string_to_crate(\"fn main (a: i32) -> i32 {|b| {\n         match 34 {None => 3, Some(i) | i => j, Foo{k:z,l:y} => \\\"banana\\\"}} }\".to_string());\n         let idents = crate_bindings(&the_crate);\n         assert_eq!(idents, strs_to_idents(vec!(\"a\",\"b\",\"None\",\"i\",\"i\",\"z\",\"y\")));\n@@ -1885,10 +1885,10 @@ foo_module!();\n     // test the IdentRenamer directly\n     #[test]\n     fn ident_renamer_test () {\n-        let the_crate = string_to_crate(\"fn f(x : int){let x = x; x}\".to_string());\n+        let the_crate = string_to_crate(\"fn f(x: i32){let x = x; x}\".to_string());\n         let f_ident = token::str_to_ident(\"f\");\n         let x_ident = token::str_to_ident(\"x\");\n-        let int_ident = token::str_to_ident(\"int\");\n+        let int_ident = token::str_to_ident(\"i32\");\n         let renames = vec!((x_ident,Name(16)));\n         let mut renamer = IdentRenamer{renames: &renames};\n         let renamed_crate = renamer.fold_crate(the_crate);\n@@ -1900,10 +1900,10 @@ foo_module!();\n     // test the PatIdentRenamer; only PatIdents get renamed\n     #[test]\n     fn pat_ident_renamer_test () {\n-        let the_crate = string_to_crate(\"fn f(x : int){let x = x; x}\".to_string());\n+        let the_crate = string_to_crate(\"fn f(x: i32){let x = x; x}\".to_string());\n         let f_ident = token::str_to_ident(\"f\");\n         let x_ident = token::str_to_ident(\"x\");\n-        let int_ident = token::str_to_ident(\"int\");\n+        let int_ident = token::str_to_ident(\"i32\");\n         let renames = vec!((x_ident,Name(16)));\n         let mut renamer = PatIdentRenamer{renames: &renames};\n         let renamed_crate = renamer.fold_crate(the_crate);"}, {"sha": "068c7ec08672ab10ed3dc6d5b007312c4910dad8", "filename": "src/libsyntax/ext/format.rs", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fformat.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -31,7 +31,7 @@ enum ArgumentType {\n }\n \n enum Position {\n-    Exact(uint),\n+    Exact(usize),\n     Named(String),\n }\n \n@@ -61,11 +61,11 @@ struct Context<'a, 'b:'a> {\n     /// Stays `true` if all formatting parameters are default (as in \"{}{}\").\n     all_pieces_simple: bool,\n \n-    name_positions: HashMap<String, uint>,\n+    name_positions: HashMap<String, usize>,\n \n     /// Updated as arguments are consumed or methods are entered\n-    nest_level: uint,\n-    next_arg: uint,\n+    nest_level: usize,\n+    next_arg: usize,\n }\n \n /// Parses the arguments from the given list of tokens, returning None\n@@ -326,11 +326,11 @@ impl<'a, 'b> Context<'a, 'b> {\n         match c {\n             parse::CountIs(i) => {\n                 self.ecx.expr_call_global(sp, Context::rtpath(self.ecx, \"CountIs\"),\n-                                          vec!(self.ecx.expr_uint(sp, i)))\n+                                          vec!(self.ecx.expr_usize(sp, i)))\n             }\n             parse::CountIsParam(i) => {\n                 self.ecx.expr_call_global(sp, Context::rtpath(self.ecx, \"CountIsParam\"),\n-                                          vec!(self.ecx.expr_uint(sp, i)))\n+                                          vec!(self.ecx.expr_usize(sp, i)))\n             }\n             parse::CountImplied => {\n                 let path = self.ecx.path_global(sp, Context::rtpath(self.ecx,\n@@ -349,7 +349,7 @@ impl<'a, 'b> Context<'a, 'b> {\n                 };\n                 let i = i + self.args.len();\n                 self.ecx.expr_call_global(sp, Context::rtpath(self.ecx, \"CountIsParam\"),\n-                                          vec!(self.ecx.expr_uint(sp, i)))\n+                                          vec!(self.ecx.expr_usize(sp, i)))\n             }\n         }\n     }\n@@ -382,7 +382,7 @@ impl<'a, 'b> Context<'a, 'b> {\n                     }\n                     parse::ArgumentIs(i) => {\n                         self.ecx.expr_call_global(sp, Context::rtpath(self.ecx, \"ArgumentIs\"),\n-                                                  vec!(self.ecx.expr_uint(sp, i)))\n+                                                  vec!(self.ecx.expr_usize(sp, i)))\n                     }\n                     // Named arguments are converted to positional arguments at\n                     // the end of the list of arguments\n@@ -393,7 +393,7 @@ impl<'a, 'b> Context<'a, 'b> {\n                         };\n                         let i = i + self.args.len();\n                         self.ecx.expr_call_global(sp, Context::rtpath(self.ecx, \"ArgumentIs\"),\n-                                                  vec!(self.ecx.expr_uint(sp, i)))\n+                                                  vec!(self.ecx.expr_usize(sp, i)))\n                     }\n                 };\n \n@@ -432,7 +432,7 @@ impl<'a, 'b> Context<'a, 'b> {\n                     }\n                 };\n                 let align = self.ecx.expr_path(align);\n-                let flags = self.ecx.expr_uint(sp, arg.format.flags);\n+                let flags = self.ecx.expr_usize(sp, arg.format.flags);\n                 let prec = self.trans_count(arg.format.precision);\n                 let width = self.trans_count(arg.format.width);\n                 let path = self.ecx.path_global(sp, Context::rtpath(self.ecx, \"FormatSpec\"));"}, {"sha": "7adc443759fe87624bd861e6a4ad1cab2af74ed5", "filename": "src/libsyntax/ext/mtwt.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fmtwt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fmtwt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmtwt.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -187,7 +187,7 @@ fn resolve_internal(id: Ident,\n     }\n \n     let resolved = {\n-        let result = (*table.table.borrow())[id.ctxt as uint];\n+        let result = (*table.table.borrow())[id.ctxt as usize];\n         match result {\n             EmptyCtxt => id.name,\n             // ignore marks here:\n@@ -231,7 +231,7 @@ fn marksof_internal(ctxt: SyntaxContext,\n     let mut result = Vec::new();\n     let mut loopvar = ctxt;\n     loop {\n-        let table_entry = (*table.table.borrow())[loopvar as uint];\n+        let table_entry = (*table.table.borrow())[loopvar as usize];\n         match table_entry {\n             EmptyCtxt => {\n                 return result;\n@@ -258,7 +258,7 @@ fn marksof_internal(ctxt: SyntaxContext,\n /// FAILS when outside is not a mark.\n pub fn outer_mark(ctxt: SyntaxContext) -> Mrk {\n     with_sctable(|sctable| {\n-        match (*sctable.table.borrow())[ctxt as uint] {\n+        match (*sctable.table.borrow())[ctxt as usize] {\n             Mark(mrk, _) => mrk,\n             _ => panic!(\"can't retrieve outer mark when outside is not a mark\")\n         }\n@@ -330,7 +330,7 @@ mod tests {\n         let mut result = Vec::new();\n         loop {\n             let table = table.table.borrow();\n-            match (*table)[sc as uint] {\n+            match (*table)[sc as usize] {\n                 EmptyCtxt => {return result;},\n                 Mark(mrk,tail) => {\n                     result.push(M(mrk));\n@@ -398,7 +398,7 @@ mod tests {\n          assert_eq! (marksof_internal (ans, stopname,&t), vec!(16));}\n         // rename where stop doesn't match:\n         { let chain = vec!(M(9),\n-                        R(id(name1.uint() as u32,\n+                        R(id(name1.usize() as u32,\n                              apply_mark_internal (4, EMPTY_CTXT,&mut t)),\n                           Name(100101102)),\n                         M(14));\n@@ -407,7 +407,7 @@ mod tests {\n         // rename where stop does match\n         { let name1sc = apply_mark_internal(4, EMPTY_CTXT, &mut t);\n          let chain = vec!(M(9),\n-                       R(id(name1.uint() as u32, name1sc),\n+                       R(id(name1.usize() as u32, name1sc),\n                          stopname),\n                        M(14));\n          let ans = unfold_test_sc(chain,EMPTY_CTXT,&mut t);"}, {"sha": "5339c3d77c656e4d3dc3022cb7723c8e6c78f74f", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -588,7 +588,7 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n         }\n \n         token::Literal(token::StrRaw(ident, n), suf) => {\n-            return mk_lit!(\"StrRaw\", suf, mk_name(cx, sp, ident.ident()), cx.expr_uint(sp, n))\n+            return mk_lit!(\"StrRaw\", suf, mk_name(cx, sp, ident.ident()), cx.expr_usize(sp, n))\n         }\n \n         token::Ident(ident, style) => {\n@@ -716,7 +716,7 @@ fn expand_tts(cx: &ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n     // try removing it when enough of them are gone.\n \n     let mut p = cx.new_parser_from_tts(tts);\n-    p.quote_depth += 1u;\n+    p.quote_depth += 1us;\n \n     let cx_expr = p.parse_expr();\n     if !p.eat(&token::Comma) {"}, {"sha": "a74adbf40851565929b38512893cbc2fef3b5965", "filename": "src/libsyntax/ext/source_util.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fsource_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Fsource_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fsource_util.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -35,7 +35,7 @@ pub fn expand_line(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n     let topmost = cx.original_span_in_file();\n     let loc = cx.codemap().lookup_char_pos(topmost.lo);\n \n-    base::MacExpr::new(cx.expr_uint(topmost, loc.line))\n+    base::MacExpr::new(cx.expr_usize(topmost, loc.line))\n }\n \n /* column!(): expands to the current column number */\n@@ -45,7 +45,7 @@ pub fn expand_column(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n \n     let topmost = cx.original_span_in_file();\n     let loc = cx.codemap().lookup_char_pos(topmost.lo);\n-    base::MacExpr::new(cx.expr_uint(topmost, loc.col.to_uint()))\n+    base::MacExpr::new(cx.expr_usize(topmost, loc.col.to_usize()))\n }\n \n /// file!(): expands to the current filename */"}, {"sha": "d115f2ed6208265b7b69646471585caffe173f9d", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 26, "deletions": 26, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -110,14 +110,14 @@ enum TokenTreeOrTokenTreeVec {\n }\n \n impl TokenTreeOrTokenTreeVec {\n-    fn len(&self) -> uint {\n+    fn len(&self) -> usize {\n         match self {\n             &TtSeq(ref v) => v.len(),\n             &Tt(ref tt) => tt.len(),\n         }\n     }\n \n-    fn get_tt(&self, index: uint) -> TokenTree {\n+    fn get_tt(&self, index: usize) -> TokenTree {\n         match self {\n             &TtSeq(ref v) => v[index].clone(),\n             &Tt(ref tt) => tt.get_tt(index),\n@@ -129,24 +129,24 @@ impl TokenTreeOrTokenTreeVec {\n #[derive(Clone)]\n struct MatcherTtFrame {\n     elts: TokenTreeOrTokenTreeVec,\n-    idx: uint,\n+    idx: usize,\n }\n \n #[derive(Clone)]\n pub struct MatcherPos {\n     stack: Vec<MatcherTtFrame>,\n     top_elts: TokenTreeOrTokenTreeVec,\n     sep: Option<Token>,\n-    idx: uint,\n+    idx: usize,\n     up: Option<Box<MatcherPos>>,\n     matches: Vec<Vec<Rc<NamedMatch>>>,\n-    match_lo: uint,\n-    match_cur: uint,\n-    match_hi: uint,\n+    match_lo: usize,\n+    match_cur: usize,\n+    match_hi: usize,\n     sp_lo: BytePos,\n }\n \n-pub fn count_names(ms: &[TokenTree]) -> uint {\n+pub fn count_names(ms: &[TokenTree]) -> usize {\n     ms.iter().fold(0, |count, elt| {\n         count + match elt {\n             &TtSequence(_, ref seq) => {\n@@ -171,11 +171,11 @@ pub fn initial_matcher_pos(ms: Rc<Vec<TokenTree>>, sep: Option<Token>, lo: ByteP\n         stack: vec![],\n         top_elts: TtSeq(ms),\n         sep: sep,\n-        idx: 0u,\n+        idx: 0us,\n         up: None,\n         matches: matches,\n-        match_lo: 0u,\n-        match_cur: 0u,\n+        match_lo: 0us,\n+        match_cur: 0us,\n         match_hi: match_idx_hi,\n         sp_lo: lo\n     }\n@@ -206,7 +206,7 @@ pub enum NamedMatch {\n pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n             -> HashMap<Ident, Rc<NamedMatch>> {\n     fn n_rec(p_s: &ParseSess, m: &TokenTree, res: &[Rc<NamedMatch>],\n-             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>, idx: &mut uint) {\n+             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>, idx: &mut usize) {\n         match m {\n             &TtSequence(_, ref seq) => {\n                 for next_m in seq.tts.iter() {\n@@ -238,7 +238,7 @@ pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n         }\n     }\n     let mut ret_val = HashMap::new();\n-    let mut idx = 0u;\n+    let mut idx = 0us;\n     for m in ms.iter() { n_rec(p_s, m, res, &mut ret_val, &mut idx) }\n     ret_val\n }\n@@ -383,7 +383,7 @@ pub fn parse(sess: &ParseSess,\n                         if seq.op == ast::ZeroOrMore {\n                             let mut new_ei = ei.clone();\n                             new_ei.match_cur += seq.num_captures;\n-                            new_ei.idx += 1u;\n+                            new_ei.idx += 1us;\n                             //we specifically matched zero repeats.\n                             for idx in range(ei.match_cur, ei.match_cur + seq.num_captures) {\n                                 (&mut new_ei.matches[idx]).push(Rc::new(MatchedSeq(vec![], sp)));\n@@ -398,7 +398,7 @@ pub fn parse(sess: &ParseSess,\n                         cur_eis.push(box MatcherPos {\n                             stack: vec![],\n                             sep: seq.separator.clone(),\n-                            idx: 0u,\n+                            idx: 0us,\n                             matches: matches,\n                             match_lo: ei_t.match_cur,\n                             match_cur: ei_t.match_cur,\n@@ -442,20 +442,20 @@ pub fn parse(sess: &ParseSess,\n \n         /* error messages here could be improved with links to orig. rules */\n         if token_name_eq(&tok, &token::Eof) {\n-            if eof_eis.len() == 1u {\n+            if eof_eis.len() == 1us {\n                 let mut v = Vec::new();\n                 for dv in (&mut eof_eis[0]).matches.iter_mut() {\n                     v.push(dv.pop().unwrap());\n                 }\n                 return Success(nameize(sess, ms, &v[]));\n-            } else if eof_eis.len() > 1u {\n+            } else if eof_eis.len() > 1us {\n                 return Error(sp, \"ambiguity: multiple successful parses\".to_string());\n             } else {\n                 return Failure(sp, \"unexpected end of macro invocation\".to_string());\n             }\n         } else {\n-            if (bb_eis.len() > 0u && next_eis.len() > 0u)\n-                || bb_eis.len() > 1u {\n+            if (bb_eis.len() > 0us && next_eis.len() > 0us)\n+                || bb_eis.len() > 1us {\n                 let nts = bb_eis.iter().map(|ei| {\n                     match ei.top_elts.get_tt(ei.idx) {\n                       TtToken(_, MatchNt(bind, name, _, _)) => {\n@@ -469,12 +469,12 @@ pub fn parse(sess: &ParseSess,\n                     \"local ambiguity: multiple parsing options: \\\n                      built-in NTs {} or {} other options.\",\n                     nts, next_eis.len()).to_string());\n-            } else if bb_eis.len() == 0u && next_eis.len() == 0u {\n+            } else if bb_eis.len() == 0us && next_eis.len() == 0us {\n                 return Failure(sp, format!(\"no rules expected the token `{}`\",\n                             pprust::token_to_string(&tok)).to_string());\n-            } else if next_eis.len() > 0u {\n+            } else if next_eis.len() > 0us {\n                 /* Now process the next token */\n-                while next_eis.len() > 0u {\n+                while next_eis.len() > 0us {\n                     cur_eis.push(next_eis.pop().unwrap());\n                 }\n                 rdr.next_token();\n@@ -488,7 +488,7 @@ pub fn parse(sess: &ParseSess,\n                     let match_cur = ei.match_cur;\n                     (&mut ei.matches[match_cur]).push(Rc::new(MatchedNonterminal(\n                         parse_nt(&mut rust_parser, name_string.get()))));\n-                    ei.idx += 1u;\n+                    ei.idx += 1us;\n                     ei.match_cur += 1;\n                   }\n                   _ => panic!()\n@@ -501,16 +501,16 @@ pub fn parse(sess: &ParseSess,\n             }\n         }\n \n-        assert!(cur_eis.len() > 0u);\n+        assert!(cur_eis.len() > 0us);\n     }\n }\n \n pub fn parse_nt(p: &mut Parser, name: &str) -> Nonterminal {\n     match name {\n         \"tt\" => {\n-            p.quote_depth += 1u; //but in theory, non-quoted tts might be useful\n+            p.quote_depth += 1us; //but in theory, non-quoted tts might be useful\n             let res = token::NtTT(P(p.parse_token_tree()));\n-            p.quote_depth -= 1u;\n+            p.quote_depth -= 1us;\n             return res;\n         }\n         _ => {}"}, {"sha": "0bf20b8f3e1514c829ede4aa92a71b27e1349970", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -27,7 +27,7 @@ use std::collections::HashMap;\n #[derive(Clone)]\n struct TtFrame {\n     forest: TokenTree,\n-    idx: uint,\n+    idx: usize,\n     dotdotdoted: bool,\n     sep: Option<Token>,\n }\n@@ -43,8 +43,8 @@ pub struct TtReader<'a> {\n \n     // Some => return imported_from as the next token\n     crate_name_next: Option<Span>,\n-    repeat_idx: Vec<uint>,\n-    repeat_len: Vec<uint>,\n+    repeat_idx: Vec<usize>,\n+    repeat_len: Vec<usize>,\n     /* cached: */\n     pub cur_tok: Token,\n     pub cur_span: Span,\n@@ -124,7 +124,7 @@ fn lookup_cur_matched(r: &TtReader, name: Ident) -> Option<Rc<NamedMatch>> {\n #[derive(Clone)]\n enum LockstepIterSize {\n     LisUnconstrained,\n-    LisConstraint(uint, Ident),\n+    LisConstraint(usize, Ident),\n     LisContradiction(String),\n }\n \n@@ -223,7 +223,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 r.repeat_len.pop();\n             }\n         } else { /* repeat */\n-            *r.repeat_idx.last_mut().unwrap() += 1u;\n+            *r.repeat_idx.last_mut().unwrap() += 1us;\n             r.stack.last_mut().unwrap().idx = 0;\n             match r.stack.last().unwrap().sep.clone() {\n                 Some(tk) => {"}, {"sha": "a876b3780601b500bfdee61effc4e26255e42ae5", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -174,8 +174,8 @@ pub trait Folder : Sized {\n         noop_fold_ident(i, self)\n     }\n \n-    fn fold_uint(&mut self, i: uint) -> uint {\n-        noop_fold_uint(i, self)\n+    fn fold_usize(&mut self, i: usize) -> usize {\n+        noop_fold_usize(i, self)\n     }\n \n     fn fold_path(&mut self, p: Path) -> Path {\n@@ -505,7 +505,7 @@ pub fn noop_fold_ident<T: Folder>(i: Ident, _: &mut T) -> Ident {\n     i\n }\n \n-pub fn noop_fold_uint<T: Folder>(i: uint, _: &mut T) -> uint {\n+pub fn noop_fold_usize<T: Folder>(i: usize, _: &mut T) -> usize {\n     i\n }\n \n@@ -1371,7 +1371,7 @@ pub fn noop_fold_expr<T: Folder>(Expr {id, node, span}: Expr, folder: &mut T) ->\n             }\n             ExprTupField(el, ident) => {\n                 ExprTupField(folder.fold_expr(el),\n-                             respan(ident.span, folder.fold_uint(ident.node)))\n+                             respan(ident.span, folder.fold_usize(ident.node)))\n             }\n             ExprIndex(el, er) => {\n                 ExprIndex(folder.fold_expr(el), folder.fold_expr(er))"}, {"sha": "2799696e8eb2f4eca364c4336511c46b455d0524", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -22,7 +22,7 @@ use print::pprust;\n use std::io;\n use std::str;\n use std::string::String;\n-use std::uint;\n+use std::usize;\n \n #[derive(Clone, Copy, PartialEq)]\n pub enum CommentStyle {\n@@ -62,7 +62,7 @@ pub fn doc_comment_style(comment: &str) -> ast::AttrStyle {\n pub fn strip_doc_comment_decoration(comment: &str) -> String {\n     /// remove whitespace-only lines from the start/end of lines\n     fn vertical_trim(lines: Vec<String> ) -> Vec<String> {\n-        let mut i = 0u;\n+        let mut i = 0us;\n         let mut j = lines.len();\n         // first line of all-stars should be omitted\n         if lines.len() > 0 &&\n@@ -87,7 +87,7 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n \n     /// remove a \"[ \\t]*\\*\" block from each line, if possible\n     fn horizontal_trim(lines: Vec<String> ) -> Vec<String> {\n-        let mut i = uint::MAX;\n+        let mut i = usize::MAX;\n         let mut can_trim = true;\n         let mut first = true;\n         for line in lines.iter() {\n@@ -132,7 +132,7 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n     }\n \n     if comment.starts_with(\"/*\") {\n-        let lines = comment[3u..(comment.len() - 2u)]\n+        let lines = comment[3us..(comment.len() - 2us)]\n             .lines_any()\n             .map(|s| s.to_string())\n             .collect::<Vec<String> >();\n@@ -158,7 +158,7 @@ fn push_blank_line_comment(rdr: &StringReader, comments: &mut Vec<Comment>) {\n fn consume_whitespace_counting_blank_lines(rdr: &mut StringReader,\n                                            comments: &mut Vec<Comment>) {\n     while is_whitespace(rdr.curr) && !rdr.is_eof() {\n-        if rdr.col == CharPos(0u) && rdr.curr_is('\\n') {\n+        if rdr.col == CharPos(0us) && rdr.curr_is('\\n') {\n             push_blank_line_comment(rdr, &mut *comments);\n         }\n         rdr.bump();\n@@ -206,10 +206,10 @@ fn read_line_comments(rdr: &mut StringReader, code_to_the_left: bool,\n /// Returns None if the first col chars of s contain a non-whitespace char.\n /// Otherwise returns Some(k) where k is first char offset after that leading\n /// whitespace.  Note k may be outside bounds of s.\n-fn all_whitespace(s: &str, col: CharPos) -> Option<uint> {\n+fn all_whitespace(s: &str, col: CharPos) -> Option<usize> {\n     let len = s.len();\n-    let mut col = col.to_uint();\n-    let mut cursor: uint = 0;\n+    let mut col = col.to_usize();\n+    let mut cursor: usize = 0;\n     while col > 0 && cursor < len {\n         let r: str::CharRange = s.char_range_at(cursor);\n         if !r.ch.is_whitespace() {\n@@ -267,7 +267,7 @@ fn read_block_comment(rdr: &mut StringReader,\n         assert!(!curr_line.contains_char('\\n'));\n         lines.push(curr_line);\n     } else {\n-        let mut level: int = 1;\n+        let mut level: isize = 1;\n         while level > 0 {\n             debug!(\"=== block comment level {}\", level);\n             if rdr.is_eof() {\n@@ -305,7 +305,7 @@ fn read_block_comment(rdr: &mut StringReader,\n \n     let mut style = if code_to_the_left { Trailing } else { Isolated };\n     rdr.consume_non_eol_whitespace();\n-    if !rdr.is_eof() && !rdr.curr_is('\\n') && lines.len() == 1u {\n+    if !rdr.is_eof() && !rdr.curr_is('\\n') && lines.len() == 1us {\n         style = Mixed;\n     }\n     debug!(\"<<< block comment\");\n@@ -399,9 +399,9 @@ mod test {\n     }\n \n     #[test] fn test_block_doc_comment_3() {\n-        let comment = \"/**\\n let a: *int;\\n *a = 5;\\n*/\";\n+        let comment = \"/**\\n let a: *i32;\\n *a = 5;\\n*/\";\n         let stripped = strip_doc_comment_decoration(comment);\n-        assert_eq!(stripped, \" let a: *int;\\n *a = 5;\");\n+        assert_eq!(stripped, \" let a: *i32;\\n *a = 5;\");\n     }\n \n     #[test] fn test_block_doc_comment_4() {"}, {"sha": "d18bf5549750eefcf7fc2a67eb942234515570da", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 30, "deletions": 30, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -212,8 +212,8 @@ impl<'a> StringReader<'a> {\n     /// offending string to the error message\n     fn fatal_span_verbose(&self, from_pos: BytePos, to_pos: BytePos, mut m: String) -> ! {\n         m.push_str(\": \");\n-        let from = self.byte_offset(from_pos).to_uint();\n-        let to = self.byte_offset(to_pos).to_uint();\n+        let from = self.byte_offset(from_pos).to_usize();\n+        let to = self.byte_offset(to_pos).to_usize();\n         m.push_str(&self.filemap.src[from..to]);\n         self.fatal_span_(from_pos, to_pos, &m[]);\n     }\n@@ -272,14 +272,14 @@ impl<'a> StringReader<'a> {\n         F: FnOnce(&str) -> T,\n     {\n         f(self.filemap.src.slice(\n-                self.byte_offset(start).to_uint(),\n-                self.byte_offset(end).to_uint()))\n+                self.byte_offset(start).to_usize(),\n+                self.byte_offset(end).to_usize()))\n     }\n \n     /// Converts CRLF to LF in the given string, raising an error on bare CR.\n     fn translate_crlf<'b>(&self, start: BytePos,\n                           s: &'b str, errmsg: &'b str) -> CowString<'b> {\n-        let mut i = 0u;\n+        let mut i = 0us;\n         while i < s.len() {\n             let str::CharRange { ch, next } = s.char_range_at(i);\n             if ch == '\\r' {\n@@ -295,7 +295,7 @@ impl<'a> StringReader<'a> {\n         return s.into_cow();\n \n         fn translate_crlf_(rdr: &StringReader, start: BytePos,\n-                        s: &str, errmsg: &str, mut i: uint) -> String {\n+                        s: &str, errmsg: &str, mut i: usize) -> String {\n             let mut buf = String::with_capacity(s.len());\n             let mut j = 0;\n             while i < s.len() {\n@@ -321,20 +321,20 @@ impl<'a> StringReader<'a> {\n     /// discovered, add it to the FileMap's list of line start offsets.\n     pub fn bump(&mut self) {\n         self.last_pos = self.pos;\n-        let current_byte_offset = self.byte_offset(self.pos).to_uint();\n+        let current_byte_offset = self.byte_offset(self.pos).to_usize();\n         if current_byte_offset < self.filemap.src.len() {\n             assert!(self.curr.is_some());\n             let last_char = self.curr.unwrap();\n             let next = self.filemap\n                           .src\n                           .char_range_at(current_byte_offset);\n             let byte_offset_diff = next.next - current_byte_offset;\n-            self.pos = self.pos + Pos::from_uint(byte_offset_diff);\n+            self.pos = self.pos + Pos::from_usize(byte_offset_diff);\n             self.curr = Some(next.ch);\n-            self.col = self.col + CharPos(1u);\n+            self.col = self.col + CharPos(1us);\n             if last_char == '\\n' {\n                 self.filemap.next_line(self.last_pos);\n-                self.col = CharPos(0u);\n+                self.col = CharPos(0us);\n             }\n \n             if byte_offset_diff > 1 {\n@@ -346,7 +346,7 @@ impl<'a> StringReader<'a> {\n     }\n \n     pub fn nextch(&self) -> Option<char> {\n-        let offset = self.byte_offset(self.pos).to_uint();\n+        let offset = self.byte_offset(self.pos).to_usize();\n         if offset < self.filemap.src.len() {\n             Some(self.filemap.src.char_at(offset))\n         } else {\n@@ -359,7 +359,7 @@ impl<'a> StringReader<'a> {\n     }\n \n     pub fn nextnextch(&self) -> Option<char> {\n-        let offset = self.byte_offset(self.pos).to_uint();\n+        let offset = self.byte_offset(self.pos).to_usize();\n         let s = self.filemap.src.as_slice();\n         if offset >= s.len() { return None }\n         let str::CharRange { next, .. } = s.char_range_at(offset);\n@@ -472,7 +472,7 @@ impl<'a> StringReader<'a> {\n                 cmap.files.borrow_mut().push(self.filemap.clone());\n                 let loc = cmap.lookup_char_pos_adj(self.last_pos);\n                 debug!(\"Skipping a shebang\");\n-                if loc.line == 1u && loc.col == CharPos(0u) {\n+                if loc.line == 1us && loc.col == CharPos(0us) {\n                     // FIXME: Add shebang \"token\", return it\n                     let start = self.last_pos;\n                     while !self.curr_is('\\n') && !self.is_eof() { self.bump(); }\n@@ -519,7 +519,7 @@ impl<'a> StringReader<'a> {\n         let is_doc_comment = self.curr_is('*') || self.curr_is('!');\n         let start_bpos = self.last_pos - BytePos(2);\n \n-        let mut level: int = 1;\n+        let mut level: isize = 1;\n         let mut has_cr = false;\n         while level > 0 {\n             if self.is_eof() {\n@@ -645,8 +645,8 @@ impl<'a> StringReader<'a> {\n \n     /// Scan through any digits (base `radix`) or underscores, and return how\n     /// many digits there were.\n-    fn scan_digits(&mut self, radix: uint) -> uint {\n-        let mut len = 0u;\n+    fn scan_digits(&mut self, radix: usize) -> usize {\n+        let mut len = 0us;\n         loop {\n             let c = self.curr;\n             if c == Some('_') { debug!(\"skipping a _\"); self.bump(); continue; }\n@@ -724,7 +724,7 @@ impl<'a> StringReader<'a> {\n     /// Scan over `n_digits` hex digits, stopping at `delim`, reporting an\n     /// error if too many or too few digits are encountered.\n     fn scan_hex_digits(&mut self,\n-                       n_digits: uint,\n+                       n_digits: usize,\n                        delim: char,\n                        below_0x7f_only: bool)\n                        -> bool {\n@@ -799,14 +799,14 @@ impl<'a> StringReader<'a> {\n                                 if self.curr == Some('{') {\n                                     self.scan_unicode_escape(delim)\n                                 } else {\n-                                    let res = self.scan_hex_digits(4u, delim, false);\n+                                    let res = self.scan_hex_digits(4us, delim, false);\n                                     let sp = codemap::mk_sp(escaped_pos, self.last_pos);\n                                     self.old_escape_warning(sp);\n                                     res\n                                 }\n                             }\n                             'U' if !ascii_only => {\n-                                let res = self.scan_hex_digits(8u, delim, false);\n+                                let res = self.scan_hex_digits(8us, delim, false);\n                                 let sp = codemap::mk_sp(escaped_pos, self.last_pos);\n                                 self.old_escape_warning(sp);\n                                 res\n@@ -877,7 +877,7 @@ impl<'a> StringReader<'a> {\n     fn scan_unicode_escape(&mut self, delim: char) -> bool {\n         self.bump(); // past the {\n         let start_bpos = self.last_pos;\n-        let mut count: uint = 0;\n+        let mut count = 0us;\n         let mut accum_int = 0;\n \n         while !self.curr_is('}') && count <= 6 {\n@@ -935,13 +935,13 @@ impl<'a> StringReader<'a> {\n \n     /// Check that a base is valid for a floating literal, emitting a nice\n     /// error if it isn't.\n-    fn check_float_base(&mut self, start_bpos: BytePos, last_bpos: BytePos, base: uint) {\n+    fn check_float_base(&mut self, start_bpos: BytePos, last_bpos: BytePos, base: usize) {\n         match base {\n-            16u => self.err_span_(start_bpos, last_bpos, \"hexadecimal float literal is not \\\n-                                 supported\"),\n-            8u => self.err_span_(start_bpos, last_bpos, \"octal float literal is not supported\"),\n-            2u => self.err_span_(start_bpos, last_bpos, \"binary float literal is not supported\"),\n-            _ => ()\n+            16us => self.err_span_(start_bpos, last_bpos, \"hexadecimal float literal is not \\\n+                                   supported\"),\n+            8us => self.err_span_(start_bpos, last_bpos, \"octal float literal is not supported\"),\n+            2us => self.err_span_(start_bpos, last_bpos, \"binary float literal is not supported\"),\n+            _   => ()\n         }\n     }\n \n@@ -1189,7 +1189,7 @@ impl<'a> StringReader<'a> {\n           'r' => {\n             let start_bpos = self.last_pos;\n             self.bump();\n-            let mut hash_count = 0u;\n+            let mut hash_count = 0us;\n             while self.curr_is('#') {\n                 self.bump();\n                 hash_count += 1;\n@@ -1374,7 +1374,7 @@ impl<'a> StringReader<'a> {\n     fn scan_raw_byte_string(&mut self) -> token::Lit {\n         let start_bpos = self.last_pos;\n         self.bump();\n-        let mut hash_count = 0u;\n+        let mut hash_count = 0us;\n         while self.curr_is('#') {\n             self.bump();\n             hash_count += 1;\n@@ -1616,9 +1616,9 @@ mod test {\n         test!(\"1.0\", Float, \"1.0\");\n         test!(\"1.0e10\", Float, \"1.0e10\");\n \n-        assert_eq!(setup(&mk_sh(), \"2u\".to_string()).next_token().tok,\n+        assert_eq!(setup(&mk_sh(), \"2us\".to_string()).next_token().tok,\n                    token::Literal(token::Integer(token::intern(\"2\")),\n-                                  Some(token::intern(\"u\"))));\n+                                  Some(token::intern(\"us\"))));\n         assert_eq!(setup(&mk_sh(), \"r###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n                    token::Literal(token::StrRaw(token::intern(\"raw\"), 3),\n                                   Some(token::intern(\"suffix\"))));"}, {"sha": "28adba7eee7fa79fdf19963fc64ffa085c403994", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 26, "deletions": 26, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -181,7 +181,7 @@ pub fn parse_tts_from_source_str(name: String,\n         name,\n         source\n     );\n-    p.quote_depth += 1u;\n+    p.quote_depth += 1us;\n     // right now this is re-creating the token trees from ... token trees.\n     maybe_aborted(p.parse_all_token_trees(),p)\n }\n@@ -324,7 +324,7 @@ pub mod with_hygiene {\n             name,\n             source\n         );\n-        p.quote_depth += 1u;\n+        p.quote_depth += 1us;\n         // right now this is re-creating the token trees from ... token trees.\n         maybe_aborted(p.parse_all_token_trees(),p)\n     }\n@@ -373,7 +373,7 @@ pub fn maybe_aborted<T>(result: T, mut p: Parser) -> T {\n /// Rather than just accepting/rejecting a given literal, unescapes it as\n /// well. Can take any slice prefixed by a character escape. Returns the\n /// character and the number of characters consumed.\n-pub fn char_lit(lit: &str) -> (char, int) {\n+pub fn char_lit(lit: &str) -> (char, isize) {\n     use std::{num, char};\n \n     let mut chars = lit.chars();\n@@ -400,19 +400,19 @@ pub fn char_lit(lit: &str) -> (char, int) {\n     let msg = format!(\"lexer should have rejected a bad character escape {}\", lit);\n     let msg2 = &msg[];\n \n-    fn esc(len: uint, lit: &str) -> Option<(char, int)> {\n+    fn esc(len: usize, lit: &str) -> Option<(char, isize)> {\n         num::from_str_radix(&lit[2..len], 16)\n         .and_then(char::from_u32)\n-        .map(|x| (x, len as int))\n+        .map(|x| (x, len as isize))\n     }\n \n-    let unicode_escape = |&: | -> Option<(char, int)>\n+    let unicode_escape = |&: | -> Option<(char, isize)>\n         if lit.as_bytes()[2] == b'{' {\n             let idx = lit.find('}').expect(msg2);\n             let subslice = &lit[3..idx];\n             num::from_str_radix(subslice, 16)\n                 .and_then(char::from_u32)\n-                .map(|x| (x, subslice.chars().count() as int + 4))\n+                .map(|x| (x, subslice.chars().count() as isize + 4))\n         } else {\n             esc(6, lit)\n         };\n@@ -436,7 +436,7 @@ pub fn str_lit(lit: &str) -> String {\n     let error = |&: i| format!(\"lexer should have rejected {} at {}\", lit, i);\n \n     /// Eat everything up to a non-whitespace\n-    fn eat<'a>(it: &mut iter::Peekable<(uint, char), str::CharIndices<'a>>) {\n+    fn eat<'a>(it: &mut iter::Peekable<(usize, char), str::CharIndices<'a>>) {\n         loop {\n             match it.peek().map(|x| x.1) {\n                 Some(' ') | Some('\\n') | Some('\\r') | Some('\\t') => {\n@@ -567,13 +567,13 @@ pub fn float_lit(s: &str, suffix: Option<&str>, sd: &SpanHandler, sp: Span) -> a\n }\n \n /// Parse a string representing a byte literal into its final form. Similar to `char_lit`\n-pub fn byte_lit(lit: &str) -> (u8, uint) {\n+pub fn byte_lit(lit: &str) -> (u8, usize) {\n     let err = |&: i| format!(\"lexer accepted invalid byte literal {} step {}\", lit, i);\n \n     if lit.len() == 1 {\n         (lit.as_bytes()[0], 1)\n     } else {\n-        assert!(lit.as_bytes()[0] == b'\\\\', err(0i));\n+        assert!(lit.as_bytes()[0] == b'\\\\', err(0is));\n         let b = match lit.as_bytes()[1] {\n             b'\"' => b'\"',\n             b'n' => b'\\n',\n@@ -605,7 +605,7 @@ pub fn binary_lit(lit: &str) -> Rc<Vec<u8>> {\n     let error = |&: i| format!(\"lexer should have rejected {} at {}\", lit, i);\n \n     /// Eat everything up to a non-whitespace\n-    fn eat<'a, I: Iterator<Item=(uint, u8)>>(it: &mut iter::Peekable<(uint, u8), I>) {\n+    fn eat<'a, I: Iterator<Item=(usize, u8)>>(it: &mut iter::Peekable<(usize, u8), I>) {\n         loop {\n             match it.peek().map(|x| x.1) {\n                 Some(b' ') | Some(b'\\n') | Some(b'\\r') | Some(b'\\t') => {\n@@ -683,9 +683,9 @@ pub fn integer_lit(s: &str, suffix: Option<&str>, sd: &SpanHandler, sp: Span) ->\n     match suffix {\n         Some(suf) if looks_like_width_suffix(&['f'], suf) => {\n             match base {\n-                16u => sd.span_err(sp, \"hexadecimal float literal is not supported\"),\n-                8u => sd.span_err(sp, \"octal float literal is not supported\"),\n-                2u => sd.span_err(sp, \"binary float literal is not supported\"),\n+                16us => sd.span_err(sp, \"hexadecimal float literal is not supported\"),\n+                8us => sd.span_err(sp, \"octal float literal is not supported\"),\n+                2us => sd.span_err(sp, \"binary float literal is not supported\"),\n                 _ => ()\n             }\n             let ident = token::intern_and_get_ident(&*s);\n@@ -854,7 +854,7 @@ mod test {\n \n     #[test]\n     fn string_to_tts_1 () {\n-        let tts = string_to_tts(\"fn a (b : int) { b; }\".to_string());\n+        let tts = string_to_tts(\"fn a (b : i32) { b; }\".to_string());\n         assert_eq!(json::encode(&tts),\n         \"[\\\n     {\\\n@@ -918,7 +918,7 @@ mod test {\n                             {\\\n                                 \\\"variant\\\":\\\"Ident\\\",\\\n                                 \\\"fields\\\":[\\\n-                                    \\\"int\\\",\\\n+                                    \\\"i32\\\",\\\n                                     \\\"Plain\\\"\\\n                                 ]\\\n                             }\\\n@@ -1030,8 +1030,8 @@ mod test {\n \n     // check the contents of the tt manually:\n     #[test] fn parse_fundecl () {\n-        // this test depends on the intern order of \"fn\" and \"int\"\n-        assert!(string_to_item(\"fn a (b : int) { b; }\".to_string()) ==\n+        // this test depends on the intern order of \"fn\" and \"i32\"\n+        assert_eq!(string_to_item(\"fn a (b : i32) { b; }\".to_string()),\n                   Some(\n                       P(ast::Item{ident:str_to_ident(\"a\"),\n                             attrs:Vec::new(),\n@@ -1045,7 +1045,7 @@ mod test {\n                                         segments: vec!(\n                                             ast::PathSegment {\n                                                 identifier:\n-                                                    str_to_ident(\"int\"),\n+                                                    str_to_ident(\"i32\"),\n                                                 parameters: ast::PathParameters::none(),\n                                             }\n                                         ),\n@@ -1158,19 +1158,19 @@ mod test {\n \n     #[test] fn span_of_self_arg_pat_idents_are_correct() {\n \n-        let srcs = [\"impl z { fn a (&self, &myarg: int) {} }\",\n-                    \"impl z { fn a (&mut self, &myarg: int) {} }\",\n-                    \"impl z { fn a (&'a self, &myarg: int) {} }\",\n-                    \"impl z { fn a (self, &myarg: int) {} }\",\n-                    \"impl z { fn a (self: Foo, &myarg: int) {} }\",\n+        let srcs = [\"impl z { fn a (&self, &myarg: i32) {} }\",\n+                    \"impl z { fn a (&mut self, &myarg: i32) {} }\",\n+                    \"impl z { fn a (&'a self, &myarg: i32) {} }\",\n+                    \"impl z { fn a (self, &myarg: i32) {} }\",\n+                    \"impl z { fn a (self: Foo, &myarg: i32) {} }\",\n                     ];\n \n         for &src in srcs.iter() {\n             let spans = get_spans_of_pat_idents(src);\n             let Span{ lo, hi, .. } = spans[0];\n-            assert!(\"self\" == &src[lo.to_uint()..hi.to_uint()],\n+            assert!(\"self\" == &src[lo.to_usize()..hi.to_usize()],\n                     \"\\\"{}\\\" != \\\"self\\\". src=\\\"{}\\\"\",\n-                    &src[lo.to_uint()..hi.to_uint()], src)\n+                    &src[lo.to_usize()..hi.to_usize()], src)\n         }\n     }\n "}, {"sha": "a3600506057af8737ff9b1e3c7b73d73005f6bfb", "filename": "src/libsyntax/parse/obsolete.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fobsolete.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -62,7 +62,7 @@ impl<'a> ParserObsoleteMethods for parser::Parser<'a> {\n                 \"use a `move ||` expression instead\",\n             ),\n             ObsoleteSyntax::ClosureType => (\n-                \"`|uint| -> bool` closure type syntax\",\n+                \"`|usize| -> bool` closure type syntax\",\n                 \"use unboxed closures instead, no type annotation needed\"\n             ),\n             ObsoleteSyntax::Sized => ("}, {"sha": "1a296d39360f32ddfc168c0ef6b1ed07532c4dd8", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 28, "deletions": 28, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -291,11 +291,11 @@ pub struct Parser<'a> {\n     /// the previous token or None (only stashed sometimes).\n     pub last_token: Option<Box<token::Token>>,\n     pub buffer: [TokenAndSpan; 4],\n-    pub buffer_start: int,\n-    pub buffer_end: int,\n-    pub tokens_consumed: uint,\n+    pub buffer_start: isize,\n+    pub buffer_end: isize,\n+    pub tokens_consumed: usize,\n     pub restrictions: Restrictions,\n-    pub quote_depth: uint, // not (yet) related to the quasiquoter\n+    pub quote_depth: usize, // not (yet) related to the quasiquoter\n     pub reader: Box<Reader+'a>,\n     pub interner: Rc<token::IdentInterner>,\n     /// The set of seen errors about obsolete syntax. Used to suppress\n@@ -768,7 +768,7 @@ impl<'a> Parser<'a> {\n         // would encounter a `>` and stop. This lets the parser handle trailing\n         // commas in generic parameters, because it can stop either after\n         // parsing a type or after parsing a comma.\n-        for i in iter::count(0u, 1) {\n+        for i in iter::count(0us, 1) {\n             if self.check(&token::Gt)\n                 || self.token == token::BinOp(token::Shr)\n                 || self.token == token::Ge\n@@ -933,9 +933,9 @@ impl<'a> Parser<'a> {\n             self.reader.real_token()\n         } else {\n             // Avoid token copies with `replace`.\n-            let buffer_start = self.buffer_start as uint;\n-            let next_index = (buffer_start + 1) & 3 as uint;\n-            self.buffer_start = next_index as int;\n+            let buffer_start = self.buffer_start as usize;\n+            let next_index = (buffer_start + 1) & 3 as usize;\n+            self.buffer_start = next_index as isize;\n \n             let placeholder = TokenAndSpan {\n                 tok: token::Underscore,\n@@ -945,7 +945,7 @@ impl<'a> Parser<'a> {\n         };\n         self.span = next.sp;\n         self.token = next.tok;\n-        self.tokens_consumed += 1u;\n+        self.tokens_consumed += 1us;\n         self.expected_tokens.clear();\n         // check after each token\n         self.check_unknown_macro_variable();\n@@ -967,21 +967,21 @@ impl<'a> Parser<'a> {\n         self.token = next;\n         self.span = mk_sp(lo, hi);\n     }\n-    pub fn buffer_length(&mut self) -> int {\n+    pub fn buffer_length(&mut self) -> isize {\n         if self.buffer_start <= self.buffer_end {\n             return self.buffer_end - self.buffer_start;\n         }\n         return (4 - self.buffer_start) + self.buffer_end;\n     }\n-    pub fn look_ahead<R, F>(&mut self, distance: uint, f: F) -> R where\n+    pub fn look_ahead<R, F>(&mut self, distance: usize, f: F) -> R where\n         F: FnOnce(&token::Token) -> R,\n     {\n-        let dist = distance as int;\n+        let dist = distance as isize;\n         while self.buffer_length() < dist {\n-            self.buffer[self.buffer_end as uint] = self.reader.real_token();\n+            self.buffer[self.buffer_end as usize] = self.reader.real_token();\n             self.buffer_end = (self.buffer_end + 1) & 3;\n         }\n-        f(&self.buffer[((self.buffer_start + dist - 1) & 3) as uint].tok)\n+        f(&self.buffer[((self.buffer_start + dist - 1) & 3) as usize].tok)\n     }\n     pub fn fatal(&mut self, m: &str) -> ! {\n         self.sess.span_diagnostic.span_fatal(self.span, m)\n@@ -1496,7 +1496,7 @@ impl<'a> Parser<'a> {\n             self.expect(&token::OpenDelim(token::Bracket));\n             let t = self.parse_ty_sum();\n \n-            // Parse the `; e` in `[ int; e ]`\n+            // Parse the `; e` in `[ i32; e ]`\n             // where `e` is a const expression\n             let t = match self.maybe_parse_fixed_length_of_vec() {\n                 None => TyVec(t),\n@@ -2084,7 +2084,7 @@ impl<'a> Parser<'a> {\n         ExprField(expr, ident)\n     }\n \n-    pub fn mk_tup_field(&mut self, expr: P<Expr>, idx: codemap::Spanned<uint>) -> ast::Expr_ {\n+    pub fn mk_tup_field(&mut self, expr: P<Expr>, idx: codemap::Spanned<usize>) -> ast::Expr_ {\n         ExprTupField(expr, idx)\n     }\n \n@@ -2483,7 +2483,7 @@ impl<'a> Parser<'a> {\n                     hi = self.span.hi;\n                     self.bump();\n \n-                    let index = n.as_str().parse::<uint>();\n+                    let index = n.as_str().parse::<usize>();\n                     match index {\n                         Some(n) => {\n                             let id = spanned(dot, hi, n);\n@@ -2509,7 +2509,7 @@ impl<'a> Parser<'a> {\n                         };\n                         self.span_help(last_span,\n                             &format!(\"try parenthesizing the first index; e.g., `(foo.{}){}`\",\n-                                    float.trunc() as uint,\n+                                    float.trunc() as usize,\n                                     &float.fract().to_string()[1..])[]);\n                     }\n                     self.abort_if_errors();\n@@ -2636,7 +2636,7 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn check_unknown_macro_variable(&mut self) {\n-        if self.quote_depth == 0u {\n+        if self.quote_depth == 0us {\n             match self.token {\n                 token::SubstNt(name, _) =>\n                     self.fatal(&format!(\"unknown macro variable `{}`\",\n@@ -2705,7 +2705,7 @@ impl<'a> Parser<'a> {\n                                     token_str)[])\n                 },\n                 /* we ought to allow different depths of unquotation */\n-                token::Dollar | token::SubstNt(..) if p.quote_depth > 0u => {\n+                token::Dollar | token::SubstNt(..) if p.quote_depth > 0us => {\n                     p.parse_unquoted()\n                 }\n                 _ => {\n@@ -2863,7 +2863,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse an expression of binops of at least min_prec precedence\n-    pub fn parse_more_binops(&mut self, lhs: P<Expr>, min_prec: uint) -> P<Expr> {\n+    pub fn parse_more_binops(&mut self, lhs: P<Expr>, min_prec: usize) -> P<Expr> {\n         if self.expr_is_complete(&*lhs) { return lhs; }\n \n         // Prevent dynamic borrow errors later on by limiting the\n@@ -4795,7 +4795,7 @@ impl<'a> Parser<'a> {\n          Some(attrs))\n     }\n \n-    /// Parse a::B<String,int>\n+    /// Parse a::B<String,i32>\n     fn parse_trait_ref(&mut self) -> TraitRef {\n         ast::TraitRef {\n             path: self.parse_path(LifetimeAndTypesWithoutColons),\n@@ -4814,7 +4814,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Parse for<'l> a::B<String,int>\n+    /// Parse for<'l> a::B<String,i32>\n     fn parse_poly_trait_ref(&mut self) -> PolyTraitRef {\n         let lifetime_defs = self.parse_late_bound_lifetime_defs();\n \n@@ -5071,7 +5071,7 @@ impl<'a> Parser<'a> {\n             }\n         }\n \n-        if first && attrs_remaining_len > 0u {\n+        if first && attrs_remaining_len > 0us {\n             // We parsed attributes for the first item but didn't find it\n             let last_span = self.last_span;\n             self.span_err(last_span,\n@@ -5668,7 +5668,7 @@ impl<'a> Parser<'a> {\n             return IoviItem(item);\n         }\n         if self.token.is_keyword(keywords::Unsafe) &&\n-            self.look_ahead(1u, |t| t.is_keyword(keywords::Trait))\n+            self.look_ahead(1us, |t| t.is_keyword(keywords::Trait))\n         {\n             // UNSAFE TRAIT ITEM\n             self.expect_keyword(keywords::Unsafe);\n@@ -5685,7 +5685,7 @@ impl<'a> Parser<'a> {\n             return IoviItem(item);\n         }\n         if self.token.is_keyword(keywords::Unsafe) &&\n-            self.look_ahead(1u, |t| t.is_keyword(keywords::Impl))\n+            self.look_ahead(1us, |t| t.is_keyword(keywords::Impl))\n         {\n             // IMPL ITEM\n             self.expect_keyword(keywords::Unsafe);\n@@ -5715,7 +5715,7 @@ impl<'a> Parser<'a> {\n             return IoviItem(item);\n         }\n         if self.token.is_keyword(keywords::Unsafe)\n-            && self.look_ahead(1u, |t| *t != token::OpenDelim(token::Brace)) {\n+            && self.look_ahead(1us, |t| *t != token::OpenDelim(token::Brace)) {\n             // UNSAFE FUNCTION ITEM\n             self.bump();\n             let abi = if self.eat_keyword(keywords::Extern) {\n@@ -6019,7 +6019,7 @@ impl<'a> Parser<'a> {\n                 }\n             }\n         }\n-        let mut rename_to = path[path.len() - 1u];\n+        let mut rename_to = path[path.len() - 1us];\n         let path = ast::Path {\n             span: mk_sp(lo, self.last_span.hi),\n             global: false,"}, {"sha": "e3762bb011c7b29a138d6f130dbc399636cece4b", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -83,9 +83,9 @@ pub enum Lit {\n     Integer(ast::Name),\n     Float(ast::Name),\n     Str_(ast::Name),\n-    StrRaw(ast::Name, uint), /* raw str delimited by n hash symbols */\n+    StrRaw(ast::Name, usize), /* raw str delimited by n hash symbols */\n     Binary(ast::Name),\n-    BinaryRaw(ast::Name, uint), /* raw binary str delimited by n hash symbols */\n+    BinaryRaw(ast::Name, usize), /* raw binary str delimited by n hash symbols */\n }\n \n impl Lit {\n@@ -724,7 +724,7 @@ pub fn intern(s: &str) -> ast::Name {\n     get_ident_interner().intern(s)\n }\n \n-/// gensym's a new uint, using the current interner.\n+/// gensym's a new usize, using the current interner.\n #[inline]\n pub fn gensym(s: &str) -> ast::Name {\n     get_ident_interner().gensym(s)\n@@ -757,7 +757,7 @@ pub fn fresh_name(src: &ast::Ident) -> ast::Name {\n \n // create a fresh mark.\n pub fn fresh_mark() -> ast::Mrk {\n-    gensym(\"mark\").uint() as u32\n+    gensym(\"mark\").usize() as u32\n }\n \n #[cfg(test)]"}, {"sha": "0b1bd282941084fa59c3d5a3c923ea130c2c8e7a", "filename": "src/libsyntax/print/pp.rs", "status": "modified", "additions": 63, "deletions": 63, "changes": 126, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fprint%2Fpp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fprint%2Fpp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpp.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -31,7 +31,7 @@\n //!\n //! In particular you'll see a certain amount of churn related to INTEGER vs.\n //! CARDINAL in the Mesa implementation. Mesa apparently interconverts the two\n-//! somewhat readily? In any case, I've used uint for indices-in-buffers and\n+//! somewhat readily? In any case, I've used usize for indices-in-buffers and\n //! ints for character-sizes-and-indentation-offsets. This respects the need\n //! for ints to \"go negative\" while carrying a pending-calculation balance, and\n //! helps differentiate all the numbers flying around internally (slightly).\n@@ -71,19 +71,19 @@ pub enum Breaks {\n \n #[derive(Clone, Copy)]\n pub struct BreakToken {\n-    offset: int,\n-    blank_space: int\n+    offset: isize,\n+    blank_space: isize\n }\n \n #[derive(Clone, Copy)]\n pub struct BeginToken {\n-    offset: int,\n+    offset: isize,\n     breaks: Breaks\n }\n \n #[derive(Clone)]\n pub enum Token {\n-    String(String, int),\n+    String(String, isize),\n     Break(BreakToken),\n     Begin(BeginToken),\n     End,\n@@ -122,25 +122,25 @@ pub fn tok_str(token: &Token) -> String {\n }\n \n pub fn buf_str(toks: &[Token],\n-               szs: &[int],\n-               left: uint,\n-               right: uint,\n-               lim: uint)\n+               szs: &[isize],\n+               left: usize,\n+               right: usize,\n+               lim: usize)\n                -> String {\n     let n = toks.len();\n     assert_eq!(n, szs.len());\n     let mut i = left;\n     let mut l = lim;\n     let mut s = string::String::from_str(\"[\");\n-    while i != right && l != 0u {\n-        l -= 1u;\n+    while i != right && l != 0us {\n+        l -= 1us;\n         if i != left {\n             s.push_str(\", \");\n         }\n         s.push_str(&format!(\"{}={}\",\n                            szs[i],\n                            tok_str(&toks[i]))[]);\n-        i += 1u;\n+        i += 1us;\n         i %= n;\n     }\n     s.push(']');\n@@ -155,25 +155,25 @@ pub enum PrintStackBreak {\n \n #[derive(Copy)]\n pub struct PrintStackElem {\n-    offset: int,\n+    offset: isize,\n     pbreak: PrintStackBreak\n }\n \n-static SIZE_INFINITY: int = 0xffff;\n+static SIZE_INFINITY: isize = 0xffff;\n \n-pub fn mk_printer(out: Box<io::Writer+'static>, linewidth: uint) -> Printer {\n+pub fn mk_printer(out: Box<io::Writer+'static>, linewidth: usize) -> Printer {\n     // Yes 3, it makes the ring buffers big enough to never\n     // fall behind.\n-    let n: uint = 3 * linewidth;\n+    let n: usize = 3 * linewidth;\n     debug!(\"mk_printer {}\", linewidth);\n     let token: Vec<Token> = repeat(Token::Eof).take(n).collect();\n-    let size: Vec<int> = repeat(0i).take(n).collect();\n-    let scan_stack: Vec<uint> = repeat(0u).take(n).collect();\n+    let size: Vec<isize> = repeat(0is).take(n).collect();\n+    let scan_stack: Vec<usize> = repeat(0us).take(n).collect();\n     Printer {\n         out: out,\n         buf_len: n,\n-        margin: linewidth as int,\n-        space: linewidth as int,\n+        margin: linewidth as isize,\n+        space: linewidth as isize,\n         left: 0,\n         right: 0,\n         token: token,\n@@ -267,40 +267,40 @@ pub fn mk_printer(out: Box<io::Writer+'static>, linewidth: uint) -> Printer {\n /// called 'print'.\n pub struct Printer {\n     pub out: Box<io::Writer+'static>,\n-    buf_len: uint,\n+    buf_len: usize,\n     /// Width of lines we're constrained to\n-    margin: int,\n+    margin: isize,\n     /// Number of spaces left on line\n-    space: int,\n+    space: isize,\n     /// Index of left side of input stream\n-    left: uint,\n+    left: usize,\n     /// Index of right side of input stream\n-    right: uint,\n+    right: usize,\n     /// Ring-buffer stream goes through\n     token: Vec<Token> ,\n     /// Ring-buffer of calculated sizes\n-    size: Vec<int> ,\n+    size: Vec<isize> ,\n     /// Running size of stream \"...left\"\n-    left_total: int,\n+    left_total: isize,\n     /// Running size of stream \"...right\"\n-    right_total: int,\n+    right_total: isize,\n     /// Pseudo-stack, really a ring too. Holds the\n     /// primary-ring-buffers index of the Begin that started the\n     /// current block, possibly with the most recent Break after that\n     /// Begin (if there is any) on top of it. Stuff is flushed off the\n     /// bottom as it becomes irrelevant due to the primary ring-buffer\n     /// advancing.\n-    scan_stack: Vec<uint> ,\n+    scan_stack: Vec<usize> ,\n     /// Top==bottom disambiguator\n     scan_stack_empty: bool,\n     /// Index of top of scan_stack\n-    top: uint,\n+    top: usize,\n     /// Index of bottom of scan_stack\n-    bottom: uint,\n+    bottom: usize,\n     /// Stack of blocks-in-progress being flushed by print\n     print_stack: Vec<PrintStackElem> ,\n     /// Buffered indentation to avoid writing trailing whitespace\n-    pending_indentation: int,\n+    pending_indentation: isize,\n }\n \n impl Printer {\n@@ -326,8 +326,8 @@ impl Printer {\n             if self.scan_stack_empty {\n                 self.left_total = 1;\n                 self.right_total = 1;\n-                self.left = 0u;\n-                self.right = 0u;\n+                self.left = 0us;\n+                self.right = 0us;\n             } else { self.advance_right(); }\n             debug!(\"pp Begin({})/buffer ~[{},{}]\",\n                    b.offset, self.left, self.right);\n@@ -355,8 +355,8 @@ impl Printer {\n             if self.scan_stack_empty {\n                 self.left_total = 1;\n                 self.right_total = 1;\n-                self.left = 0u;\n-                self.right = 0u;\n+                self.left = 0us;\n+                self.right = 0us;\n             } else { self.advance_right(); }\n             debug!(\"pp Break({})/buffer ~[{},{}]\",\n                    b.offset, self.left, self.right);\n@@ -405,43 +405,43 @@ impl Printer {\n         }\n         Ok(())\n     }\n-    pub fn scan_push(&mut self, x: uint) {\n+    pub fn scan_push(&mut self, x: usize) {\n         debug!(\"scan_push {}\", x);\n         if self.scan_stack_empty {\n             self.scan_stack_empty = false;\n         } else {\n-            self.top += 1u;\n+            self.top += 1us;\n             self.top %= self.buf_len;\n             assert!((self.top != self.bottom));\n         }\n         self.scan_stack[self.top] = x;\n     }\n-    pub fn scan_pop(&mut self) -> uint {\n+    pub fn scan_pop(&mut self) -> usize {\n         assert!((!self.scan_stack_empty));\n         let x = self.scan_stack[self.top];\n         if self.top == self.bottom {\n             self.scan_stack_empty = true;\n         } else {\n-            self.top += self.buf_len - 1u; self.top %= self.buf_len;\n+            self.top += self.buf_len - 1us; self.top %= self.buf_len;\n         }\n         return x;\n     }\n-    pub fn scan_top(&mut self) -> uint {\n+    pub fn scan_top(&mut self) -> usize {\n         assert!((!self.scan_stack_empty));\n         return self.scan_stack[self.top];\n     }\n-    pub fn scan_pop_bottom(&mut self) -> uint {\n+    pub fn scan_pop_bottom(&mut self) -> usize {\n         assert!((!self.scan_stack_empty));\n         let x = self.scan_stack[self.bottom];\n         if self.top == self.bottom {\n             self.scan_stack_empty = true;\n         } else {\n-            self.bottom += 1u; self.bottom %= self.buf_len;\n+            self.bottom += 1us; self.bottom %= self.buf_len;\n         }\n         return x;\n     }\n     pub fn advance_right(&mut self) {\n-        self.right += 1u;\n+        self.right += 1us;\n         self.right %= self.buf_len;\n         assert!((self.right != self.left));\n     }\n@@ -471,15 +471,15 @@ impl Printer {\n                 break;\n             }\n \n-            self.left += 1u;\n+            self.left += 1us;\n             self.left %= self.buf_len;\n \n             left_size = self.size[self.left];\n         }\n \n         Ok(())\n     }\n-    pub fn check_stack(&mut self, k: int) {\n+    pub fn check_stack(&mut self, k: isize) {\n         if !self.scan_stack_empty {\n             let x = self.scan_top();\n             match self.token[x] {\n@@ -506,21 +506,21 @@ impl Printer {\n             }\n         }\n     }\n-    pub fn print_newline(&mut self, amount: int) -> io::IoResult<()> {\n+    pub fn print_newline(&mut self, amount: isize) -> io::IoResult<()> {\n         debug!(\"NEWLINE {}\", amount);\n         let ret = write!(self.out, \"\\n\");\n         self.pending_indentation = 0;\n         self.indent(amount);\n         return ret;\n     }\n-    pub fn indent(&mut self, amount: int) {\n+    pub fn indent(&mut self, amount: isize) {\n         debug!(\"INDENT {}\", amount);\n         self.pending_indentation += amount;\n     }\n     pub fn get_top(&mut self) -> PrintStackElem {\n         let print_stack = &mut self.print_stack;\n         let n = print_stack.len();\n-        if n != 0u {\n+        if n != 0us {\n             (*print_stack)[n - 1]\n         } else {\n             PrintStackElem {\n@@ -536,7 +536,7 @@ impl Printer {\n         }\n         write!(self.out, \"{}\", s)\n     }\n-    pub fn print(&mut self, token: Token, l: int) -> io::IoResult<()> {\n+    pub fn print(&mut self, token: Token, l: isize) -> io::IoResult<()> {\n         debug!(\"print {} {} (remaining line space={})\", tok_str(&token), l,\n                self.space);\n         debug!(\"{}\", buf_str(&self.token[],\n@@ -565,7 +565,7 @@ impl Printer {\n           Token::End => {\n             debug!(\"print End -> pop End\");\n             let print_stack = &mut self.print_stack;\n-            assert!((print_stack.len() != 0u));\n+            assert!((print_stack.len() != 0us));\n             print_stack.pop().unwrap();\n             Ok(())\n           }\n@@ -620,25 +620,25 @@ impl Printer {\n // Convenience functions to talk to the printer.\n //\n // \"raw box\"\n-pub fn rbox(p: &mut Printer, indent: uint, b: Breaks) -> io::IoResult<()> {\n+pub fn rbox(p: &mut Printer, indent: usize, b: Breaks) -> io::IoResult<()> {\n     p.pretty_print(Token::Begin(BeginToken {\n-        offset: indent as int,\n+        offset: indent as isize,\n         breaks: b\n     }))\n }\n \n-pub fn ibox(p: &mut Printer, indent: uint) -> io::IoResult<()> {\n+pub fn ibox(p: &mut Printer, indent: usize) -> io::IoResult<()> {\n     rbox(p, indent, Breaks::Inconsistent)\n }\n \n-pub fn cbox(p: &mut Printer, indent: uint) -> io::IoResult<()> {\n+pub fn cbox(p: &mut Printer, indent: usize) -> io::IoResult<()> {\n     rbox(p, indent, Breaks::Consistent)\n }\n \n-pub fn break_offset(p: &mut Printer, n: uint, off: int) -> io::IoResult<()> {\n+pub fn break_offset(p: &mut Printer, n: usize, off: isize) -> io::IoResult<()> {\n     p.pretty_print(Token::Break(BreakToken {\n         offset: off,\n-        blank_space: n as int\n+        blank_space: n as isize\n     }))\n }\n \n@@ -651,7 +651,7 @@ pub fn eof(p: &mut Printer) -> io::IoResult<()> {\n }\n \n pub fn word(p: &mut Printer, wrd: &str) -> io::IoResult<()> {\n-    p.pretty_print(Token::String(/* bad */ wrd.to_string(), wrd.len() as int))\n+    p.pretty_print(Token::String(/* bad */ wrd.to_string(), wrd.len() as isize))\n }\n \n pub fn huge_word(p: &mut Printer, wrd: &str) -> io::IoResult<()> {\n@@ -662,23 +662,23 @@ pub fn zero_word(p: &mut Printer, wrd: &str) -> io::IoResult<()> {\n     p.pretty_print(Token::String(/* bad */ wrd.to_string(), 0))\n }\n \n-pub fn spaces(p: &mut Printer, n: uint) -> io::IoResult<()> {\n+pub fn spaces(p: &mut Printer, n: usize) -> io::IoResult<()> {\n     break_offset(p, n, 0)\n }\n \n pub fn zerobreak(p: &mut Printer) -> io::IoResult<()> {\n-    spaces(p, 0u)\n+    spaces(p, 0us)\n }\n \n pub fn space(p: &mut Printer) -> io::IoResult<()> {\n-    spaces(p, 1u)\n+    spaces(p, 1us)\n }\n \n pub fn hardbreak(p: &mut Printer) -> io::IoResult<()> {\n-    spaces(p, SIZE_INFINITY as uint)\n+    spaces(p, SIZE_INFINITY as usize)\n }\n \n-pub fn hardbreak_tok_offset(off: int) -> Token {\n+pub fn hardbreak_tok_offset(off: isize) -> Token {\n     Token::Break(BreakToken {offset: off, blank_space: SIZE_INFINITY})\n }\n "}, {"sha": "4010f43386516373c4a76a11d70aa2c20a6f2cd8", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 45, "deletions": 45, "changes": 90, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -54,8 +54,8 @@ impl PpAnn for NoAnn {}\n \n #[derive(Copy)]\n pub struct CurrentCommentAndLiteral {\n-    cur_cmnt: uint,\n-    cur_lit: uint,\n+    cur_cmnt: usize,\n+    cur_lit: usize,\n }\n \n pub struct State<'a> {\n@@ -92,10 +92,10 @@ pub fn rust_printer_annotated<'a>(writer: Box<io::Writer+'static>,\n }\n \n #[allow(non_upper_case_globals)]\n-pub const indent_unit: uint = 4u;\n+pub const indent_unit: usize = 4us;\n \n #[allow(non_upper_case_globals)]\n-pub const default_columns: uint = 78u;\n+pub const default_columns: usize = 78us;\n \n /// Requires you to pass an input filename and reader so that\n /// it can scan the input text for comments and literals to\n@@ -381,7 +381,7 @@ pub fn block_to_string(blk: &ast::Block) -> String {\n         // containing cbox, will be closed by print-block at }\n         try!(s.cbox(indent_unit));\n         // head-ibox, will be closed by print-block after {\n-        try!(s.ibox(0u));\n+        try!(s.ibox(0us));\n         s.print_block(blk)\n     })\n }\n@@ -459,7 +459,7 @@ fn needs_parentheses(expr: &ast::Expr) -> bool {\n }\n \n impl<'a> State<'a> {\n-    pub fn ibox(&mut self, u: uint) -> IoResult<()> {\n+    pub fn ibox(&mut self, u: usize) -> IoResult<()> {\n         self.boxes.push(pp::Breaks::Inconsistent);\n         pp::ibox(&mut self.s, u)\n     }\n@@ -469,13 +469,13 @@ impl<'a> State<'a> {\n         pp::end(&mut self.s)\n     }\n \n-    pub fn cbox(&mut self, u: uint) -> IoResult<()> {\n+    pub fn cbox(&mut self, u: usize) -> IoResult<()> {\n         self.boxes.push(pp::Breaks::Consistent);\n         pp::cbox(&mut self.s, u)\n     }\n \n     // \"raw box\"\n-    pub fn rbox(&mut self, u: uint, b: pp::Breaks) -> IoResult<()> {\n+    pub fn rbox(&mut self, u: usize, b: pp::Breaks) -> IoResult<()> {\n         self.boxes.push(b);\n         pp::rbox(&mut self.s, u, b)\n     }\n@@ -514,13 +514,13 @@ impl<'a> State<'a> {\n     }\n \n     pub fn bclose_(&mut self, span: codemap::Span,\n-                   indented: uint) -> IoResult<()> {\n+                   indented: usize) -> IoResult<()> {\n         self.bclose_maybe_open(span, indented, true)\n     }\n     pub fn bclose_maybe_open (&mut self, span: codemap::Span,\n-                              indented: uint, close_box: bool) -> IoResult<()> {\n+                              indented: usize, close_box: bool) -> IoResult<()> {\n         try!(self.maybe_print_comment(span.hi));\n-        try!(self.break_offset_if_not_bol(1u, -(indented as int)));\n+        try!(self.break_offset_if_not_bol(1us, -(indented as isize)));\n         try!(word(&mut self.s, \"}\"));\n         if close_box {\n             try!(self.end()); // close the outer-box\n@@ -567,8 +567,8 @@ impl<'a> State<'a> {\n         if !self.is_bol() { try!(space(&mut self.s)); }\n         Ok(())\n     }\n-    pub fn break_offset_if_not_bol(&mut self, n: uint,\n-                                   off: int) -> IoResult<()> {\n+    pub fn break_offset_if_not_bol(&mut self, n: usize,\n+                                   off: isize) -> IoResult<()> {\n         if !self.is_bol() {\n             break_offset(&mut self.s, n, off)\n         } else {\n@@ -595,7 +595,7 @@ impl<'a> State<'a> {\n     pub fn commasep<T, F>(&mut self, b: Breaks, elts: &[T], mut op: F) -> IoResult<()> where\n         F: FnMut(&mut State, &T) -> IoResult<()>,\n     {\n-        try!(self.rbox(0u, b));\n+        try!(self.rbox(0us, b));\n         let mut first = true;\n         for elt in elts.iter() {\n             if first { first = false; } else { try!(self.word_space(\",\")); }\n@@ -613,13 +613,13 @@ impl<'a> State<'a> {\n         F: FnMut(&mut State, &T) -> IoResult<()>,\n         G: FnMut(&T) -> codemap::Span,\n     {\n-        try!(self.rbox(0u, b));\n+        try!(self.rbox(0us, b));\n         let len = elts.len();\n-        let mut i = 0u;\n+        let mut i = 0us;\n         for elt in elts.iter() {\n             try!(self.maybe_print_comment(get_span(elt).hi));\n             try!(op(self, elt));\n-            i += 1u;\n+            i += 1us;\n             if i < len {\n                 try!(word(&mut self.s, \",\"));\n                 try!(self.maybe_print_trailing_comment(get_span(elt),\n@@ -670,7 +670,7 @@ impl<'a> State<'a> {\n \n     pub fn print_type(&mut self, ty: &ast::Ty) -> IoResult<()> {\n         try!(self.maybe_print_comment(ty.span.lo));\n-        try!(self.ibox(0u));\n+        try!(self.ibox(0us));\n         match ty.node {\n             ast::TyVec(ref ty) => {\n                 try!(word(&mut self.s, \"[\"));\n@@ -871,7 +871,7 @@ impl<'a> State<'a> {\n             }\n             ast::ItemTy(ref ty, ref params) => {\n                 try!(self.ibox(indent_unit));\n-                try!(self.ibox(0u));\n+                try!(self.ibox(0us));\n                 try!(self.word_nbsp(&visibility_qualified(item.vis, \"type\")[]));\n                 try!(self.print_ident(item.ident));\n                 try!(self.print_generics(params));\n@@ -1262,7 +1262,7 @@ impl<'a> State<'a> {\n \n     pub fn print_outer_attributes(&mut self,\n                                   attrs: &[ast::Attribute]) -> IoResult<()> {\n-        let mut count = 0u;\n+        let mut count = 0us;\n         for attr in attrs.iter() {\n             match attr.node.style {\n                 ast::AttrOuter => {\n@@ -1280,7 +1280,7 @@ impl<'a> State<'a> {\n \n     pub fn print_inner_attributes(&mut self,\n                                   attrs: &[ast::Attribute]) -> IoResult<()> {\n-        let mut count = 0u;\n+        let mut count = 0us;\n         for attr in attrs.iter() {\n             match attr.node.style {\n                 ast::AttrInner => {\n@@ -1355,7 +1355,7 @@ impl<'a> State<'a> {\n     }\n \n     pub fn print_block_unclosed_indent(&mut self, blk: &ast::Block,\n-                                       indented: uint) -> IoResult<()> {\n+                                       indented: usize) -> IoResult<()> {\n         self.print_block_maybe_unclosed(blk, indented, &[], false)\n     }\n \n@@ -1367,7 +1367,7 @@ impl<'a> State<'a> {\n \n     pub fn print_block_maybe_unclosed(&mut self,\n                                       blk: &ast::Block,\n-                                      indented: uint,\n+                                      indented: usize,\n                                       attrs: &[ast::Attribute],\n                                       close_box: bool) -> IoResult<()> {\n         match blk.rules {\n@@ -1404,8 +1404,8 @@ impl<'a> State<'a> {\n                 match _else.node {\n                     // \"another else-if\"\n                     ast::ExprIf(ref i, ref then, ref e) => {\n-                        try!(self.cbox(indent_unit - 1u));\n-                        try!(self.ibox(0u));\n+                        try!(self.cbox(indent_unit - 1us));\n+                        try!(self.ibox(0us));\n                         try!(word(&mut self.s, \" else if \"));\n                         try!(self.print_expr(&**i));\n                         try!(space(&mut self.s));\n@@ -1414,8 +1414,8 @@ impl<'a> State<'a> {\n                     }\n                     // \"another else-if-let\"\n                     ast::ExprIfLet(ref pat, ref expr, ref then, ref e) => {\n-                        try!(self.cbox(indent_unit - 1u));\n-                        try!(self.ibox(0u));\n+                        try!(self.cbox(indent_unit - 1us));\n+                        try!(self.ibox(0us));\n                         try!(word(&mut self.s, \" else if let \"));\n                         try!(self.print_pat(&**pat));\n                         try!(space(&mut self.s));\n@@ -1427,8 +1427,8 @@ impl<'a> State<'a> {\n                     }\n                     // \"final else\"\n                     ast::ExprBlock(ref b) => {\n-                        try!(self.cbox(indent_unit - 1u));\n-                        try!(self.ibox(0u));\n+                        try!(self.cbox(indent_unit - 1us));\n+                        try!(self.ibox(0us));\n                         try!(word(&mut self.s, \" else \"));\n                         self.print_block(&**b)\n                     }\n@@ -1594,7 +1594,7 @@ impl<'a> State<'a> {\n         try!(self.print_expr(&*args[0]));\n         try!(word(&mut self.s, \".\"));\n         try!(self.print_ident(ident.node));\n-        if tys.len() > 0u {\n+        if tys.len() > 0us {\n             try!(word(&mut self.s, \"::<\"));\n             try!(self.commasep(Inconsistent, tys,\n                                |s, ty| s.print_type(&**ty)));\n@@ -1765,7 +1765,7 @@ impl<'a> State<'a> {\n                 // containing cbox, will be closed by print-block at }\n                 try!(self.cbox(indent_unit));\n                 // head-box, will be closed by print-block after {\n-                try!(self.ibox(0u));\n+                try!(self.ibox(0us));\n                 try!(self.print_block(&**blk));\n             }\n             ast::ExprAssign(ref lhs, ref rhs) => {\n@@ -1789,7 +1789,7 @@ impl<'a> State<'a> {\n             ast::ExprTupField(ref expr, id) => {\n                 try!(self.print_expr(&**expr));\n                 try!(word(&mut self.s, \".\"));\n-                try!(self.print_uint(id.node));\n+                try!(self.print_usize(id.node));\n             }\n             ast::ExprIndex(ref expr, ref index) => {\n                 try!(self.print_expr(&**expr));\n@@ -1951,7 +1951,7 @@ impl<'a> State<'a> {\n         self.ann.post(self, NodeIdent(&ident))\n     }\n \n-    pub fn print_uint(&mut self, i: uint) -> IoResult<()> {\n+    pub fn print_usize(&mut self, i: usize) -> IoResult<()> {\n         word(&mut self.s, &i.to_string()[])\n     }\n \n@@ -2142,7 +2142,7 @@ impl<'a> State<'a> {\n                     },\n                     |f| f.node.pat.span));\n                 if etc {\n-                    if fields.len() != 0u { try!(self.word_space(\",\")); }\n+                    if fields.len() != 0us { try!(self.word_space(\",\")); }\n                     try!(word(&mut self.s, \"..\"));\n                 }\n                 try!(space(&mut self.s));\n@@ -2209,7 +2209,7 @@ impl<'a> State<'a> {\n             try!(space(&mut self.s));\n         }\n         try!(self.cbox(indent_unit));\n-        try!(self.ibox(0u));\n+        try!(self.ibox(0us));\n         try!(self.print_outer_attributes(&arm.attrs[]));\n         let mut first = true;\n         for p in arm.pats.iter() {\n@@ -2295,7 +2295,7 @@ impl<'a> State<'a> {\n         -> IoResult<()> {\n         // It is unfortunate to duplicate the commasep logic, but we want the\n         // self type and the args all in the same box.\n-        try!(self.rbox(0u, Inconsistent));\n+        try!(self.rbox(0us, Inconsistent));\n         let mut first = true;\n         for &explicit_self in opt_explicit_self.iter() {\n             let m = match explicit_self {\n@@ -2470,7 +2470,7 @@ impl<'a> State<'a> {\n         try!(word(&mut self.s, \"<\"));\n \n         let mut ints = Vec::new();\n-        for i in range(0u, total) {\n+        for i in range(0us, total) {\n             ints.push(i);\n         }\n \n@@ -2788,7 +2788,7 @@ impl<'a> State<'a> {\n                 if span.hi < (*cmnt).pos && (*cmnt).pos < next &&\n                     span_line.line == comment_line.line {\n                         try!(self.print_comment(cmnt));\n-                        self.cur_cmnt_and_lit.cur_cmnt += 1u;\n+                        self.cur_cmnt_and_lit.cur_cmnt += 1us;\n                     }\n             }\n             _ => ()\n@@ -2806,7 +2806,7 @@ impl<'a> State<'a> {\n             match self.next_comment() {\n                 Some(ref cmnt) => {\n                     try!(self.print_comment(cmnt));\n-                    self.cur_cmnt_and_lit.cur_cmnt += 1u;\n+                    self.cur_cmnt_and_lit.cur_cmnt += 1us;\n                 }\n                 _ => break\n             }\n@@ -2888,7 +2888,7 @@ impl<'a> State<'a> {\n                 while self.cur_cmnt_and_lit.cur_lit < lits.len() {\n                     let ltrl = (*lits)[self.cur_cmnt_and_lit.cur_lit].clone();\n                     if ltrl.pos > pos { return None; }\n-                    self.cur_cmnt_and_lit.cur_lit += 1u;\n+                    self.cur_cmnt_and_lit.cur_lit += 1us;\n                     if ltrl.pos == pos { return Some(ltrl); }\n                 }\n                 None\n@@ -2903,7 +2903,7 @@ impl<'a> State<'a> {\n                 Some(ref cmnt) => {\n                     if (*cmnt).pos < pos {\n                         try!(self.print_comment(cmnt));\n-                        self.cur_cmnt_and_lit.cur_cmnt += 1u;\n+                        self.cur_cmnt_and_lit.cur_cmnt += 1us;\n                     } else { break; }\n                 }\n                 _ => break\n@@ -2916,7 +2916,7 @@ impl<'a> State<'a> {\n                          cmnt: &comments::Comment) -> IoResult<()> {\n         match cmnt.style {\n             comments::Mixed => {\n-                assert_eq!(cmnt.lines.len(), 1u);\n+                assert_eq!(cmnt.lines.len(), 1us);\n                 try!(zerobreak(&mut self.s));\n                 try!(word(&mut self.s, &cmnt.lines[0][]));\n                 zerobreak(&mut self.s)\n@@ -2935,11 +2935,11 @@ impl<'a> State<'a> {\n             }\n             comments::Trailing => {\n                 try!(word(&mut self.s, \" \"));\n-                if cmnt.lines.len() == 1u {\n+                if cmnt.lines.len() == 1us {\n                     try!(word(&mut self.s, &cmnt.lines[0][]));\n                     hardbreak(&mut self.s)\n                 } else {\n-                    try!(self.ibox(0u));\n+                    try!(self.ibox(0us));\n                     for line in cmnt.lines.iter() {\n                         if !line.is_empty() {\n                             try!(word(&mut self.s, &line[]));\n@@ -3047,7 +3047,7 @@ impl<'a> State<'a> {\n     }\n }\n \n-fn repeat(s: &str, n: uint) -> String { iter::repeat(s).take(n).collect() }\n+fn repeat(s: &str, n: usize) -> String { iter::repeat(s).take(n).collect() }\n \n #[cfg(test)]\n mod test {"}, {"sha": "3022b2b41b7fc38d1e269cf0ed05a9a296162768", "filename": "src/libsyntax/test.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftest.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -339,8 +339,8 @@ fn is_bench_fn(cx: &TestCtxt, i: &ast::Item) -> bool {\n                 let tparm_cnt = generics.ty_params.len();\n                 // NB: inadequate check, but we're running\n                 // well before resolve, can't get too deep.\n-                input_cnt == 1u\n-                    && no_output && tparm_cnt == 0u\n+                input_cnt == 1us\n+                    && no_output && tparm_cnt == 0us\n             }\n           _ => false\n         }"}, {"sha": "66b225f30dd8af39b374c9f1f317fb26affef038", "filename": "src/libsyntax/util/interner.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Futil%2Finterner.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Futil%2Finterner.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Finterner.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! An \"interner\" is a data structure that associates values with uint tags and\n+//! An \"interner\" is a data structure that associates values with usize tags and\n //! allows bidirectional lookup; i.e. given a value, one can easily find the\n //! type, and vice versa.\n \n@@ -70,10 +70,10 @@ impl<T: Eq + Hash<Hasher> + Clone + 'static> Interner<T> {\n \n     pub fn get(&self, idx: Name) -> T {\n         let vect = self.vect.borrow();\n-        (*vect)[idx.uint()].clone()\n+        (*vect)[idx.usize()].clone()\n     }\n \n-    pub fn len(&self) -> uint {\n+    pub fn len(&self) -> usize {\n         let vect = self.vect.borrow();\n         (*vect).len()\n     }\n@@ -190,16 +190,16 @@ impl StrInterner {\n         let new_idx = Name(self.len() as u32);\n         // leave out of map to avoid colliding\n         let mut vect = self.vect.borrow_mut();\n-        let existing = (*vect)[idx.uint()].clone();\n+        let existing = (*vect)[idx.usize()].clone();\n         vect.push(existing);\n         new_idx\n     }\n \n     pub fn get(&self, idx: Name) -> RcStr {\n-        (*self.vect.borrow())[idx.uint()].clone()\n+        (*self.vect.borrow())[idx.usize()].clone()\n     }\n \n-    pub fn len(&self) -> uint {\n+    pub fn len(&self) -> usize {\n         self.vect.borrow().len()\n     }\n "}, {"sha": "5466b7337e776dce97788e008c15d2d50d23ec97", "filename": "src/libsyntax/util/parser_testing.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser_testing.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -130,10 +130,10 @@ pub fn matches_codepattern(a : &str, b : &str) -> bool {\n     }\n }\n \n-/// Given a string and an index, return the first uint >= idx\n+/// Given a string and an index, return the first usize >= idx\n /// that is a non-ws-char or is outside of the legal range of\n /// the string.\n-fn scan_for_non_ws_or_end(a : &str, idx: uint) -> uint {\n+fn scan_for_non_ws_or_end(a : &str, idx: usize) -> usize {\n     let mut i = idx;\n     let len = a.len();\n     while (i < len) && (is_whitespace(a.char_at(i))) {"}, {"sha": "d8bac19805b27eb5000e74292a159a7443b0ab98", "filename": "src/libsyntax/util/small_vector.rs", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Futil%2Fsmall_vector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Flibsyntax%2Futil%2Fsmall_vector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fsmall_vector.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -89,7 +89,7 @@ impl<T> SmallVector<T> {\n         }\n     }\n \n-    pub fn get<'a>(&'a self, idx: uint) -> &'a T {\n+    pub fn get<'a>(&'a self, idx: usize) -> &'a T {\n         match self.repr {\n             One(ref v) if idx == 0 => v,\n             Many(ref vs) => &vs[idx],\n@@ -126,7 +126,7 @@ impl<T> SmallVector<T> {\n         IntoIter { repr: repr }\n     }\n \n-    pub fn len(&self) -> uint {\n+    pub fn len(&self) -> usize {\n         match self.repr {\n             Zero => 0,\n             One(..) => 1,\n@@ -165,7 +165,7 @@ impl<T> Iterator for IntoIter<T> {\n         }\n     }\n \n-    fn size_hint(&self) -> (uint, Option<uint>) {\n+    fn size_hint(&self) -> (usize, Option<usize>) {\n         match self.repr {\n             ZeroIterator => (0, Some(0)),\n             OneIterator(..) => (1, Some(1)),\n@@ -191,17 +191,17 @@ mod test {\n \n     #[test]\n     fn test_len() {\n-        let v: SmallVector<int> = SmallVector::zero();\n+        let v: SmallVector<isize> = SmallVector::zero();\n         assert_eq!(0, v.len());\n \n-        assert_eq!(1, SmallVector::one(1i).len());\n-        assert_eq!(5, SmallVector::many(vec!(1i, 2, 3, 4, 5)).len());\n+        assert_eq!(1, SmallVector::one(1is).len());\n+        assert_eq!(5, SmallVector::many(vec!(1is, 2, 3, 4, 5)).len());\n     }\n \n     #[test]\n     fn test_push_get() {\n         let mut v = SmallVector::zero();\n-        v.push(1i);\n+        v.push(1is);\n         assert_eq!(1, v.len());\n         assert_eq!(&1, v.get(0));\n         v.push(2);\n@@ -214,7 +214,7 @@ mod test {\n \n     #[test]\n     fn test_from_iter() {\n-        let v: SmallVector<int> = (vec!(1i, 2, 3)).into_iter().collect();\n+        let v: SmallVector<isize> = (vec![1is, 2, 3]).into_iter().collect();\n         assert_eq!(3, v.len());\n         assert_eq!(&1, v.get(0));\n         assert_eq!(&2, v.get(1));\n@@ -224,31 +224,31 @@ mod test {\n     #[test]\n     fn test_move_iter() {\n         let v = SmallVector::zero();\n-        let v: Vec<int> = v.into_iter().collect();\n+        let v: Vec<isize> = v.into_iter().collect();\n         assert_eq!(Vec::new(), v);\n \n-        let v = SmallVector::one(1i);\n-        assert_eq!(vec!(1i), v.into_iter().collect::<Vec<_>>());\n+        let v = SmallVector::one(1is);\n+        assert_eq!(vec!(1is), v.into_iter().collect::<Vec<_>>());\n \n-        let v = SmallVector::many(vec!(1i, 2i, 3i));\n-        assert_eq!(vec!(1i, 2i, 3i), v.into_iter().collect::<Vec<_>>());\n+        let v = SmallVector::many(vec!(1is, 2is, 3is));\n+        assert_eq!(vec!(1is, 2is, 3is), v.into_iter().collect::<Vec<_>>());\n     }\n \n     #[test]\n     #[should_fail]\n     fn test_expect_one_zero() {\n-        let _: int = SmallVector::zero().expect_one(\"\");\n+        let _: isize = SmallVector::zero().expect_one(\"\");\n     }\n \n     #[test]\n     #[should_fail]\n     fn test_expect_one_many() {\n-        SmallVector::many(vec!(1i, 2)).expect_one(\"\");\n+        SmallVector::many(vec!(1is, 2)).expect_one(\"\");\n     }\n \n     #[test]\n     fn test_expect_one_one() {\n-        assert_eq!(1i, SmallVector::one(1i).expect_one(\"\"));\n-        assert_eq!(1i, SmallVector::many(vec!(1i)).expect_one(\"\"));\n+        assert_eq!(1is, SmallVector::one(1is).expect_one(\"\"));\n+        assert_eq!(1is, SmallVector::many(vec!(1is)).expect_one(\"\"));\n     }\n }"}, {"sha": "a4edc607279012f3d21a180f3a0bf7d816658e86", "filename": "src/test/auxiliary/roman_numerals.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c981875e46763a9b3cd53443bf73dfd3e291d18/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Froman_numerals.rs?ref=0c981875e46763a9b3cd53443bf73dfd3e291d18", "patch": "@@ -20,7 +20,7 @@ use syntax::codemap::Span;\n use syntax::parse::token;\n use syntax::ast::{TokenTree, TtToken};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacExpr};\n-use syntax::ext::build::AstBuilder;  // trait for expr_uint\n+use syntax::ext::build::AstBuilder;  // trait for expr_usize\n use rustc::plugin::Registry;\n \n // WARNING WARNING WARNING WARNING WARNING\n@@ -61,7 +61,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         }\n     }\n \n-    MacExpr::new(cx.expr_uint(sp, total))\n+    MacExpr::new(cx.expr_usize(sp, total))\n }\n \n #[plugin_registrar]"}]}