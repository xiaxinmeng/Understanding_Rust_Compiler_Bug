{"sha": "fa2ac6646233384deb6ff694da4e3b674a187cd0", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZhMmFjNjY0NjIzMzM4NGRlYjZmZjY5NGRhNGUzYjY3NGExODdjZDA=", "commit": {"author": {"name": "Niko Matsakis", "email": "niko@alum.mit.edu", "date": "2012-05-16T16:35:56Z"}, "committer": {"name": "Niko Matsakis", "email": "niko@alum.mit.edu", "date": "2012-05-16T16:42:38Z"}, "message": "add a large comment on how infer works", "tree": {"sha": "e1281790663c6eb46296fc3fe45b4bd0cdce6b60", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e1281790663c6eb46296fc3fe45b4bd0cdce6b60"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fa2ac6646233384deb6ff694da4e3b674a187cd0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fa2ac6646233384deb6ff694da4e3b674a187cd0", "html_url": "https://github.com/rust-lang/rust/commit/fa2ac6646233384deb6ff694da4e3b674a187cd0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fa2ac6646233384deb6ff694da4e3b674a187cd0/comments", "author": {"login": "nikomatsakis", "id": 155238, "node_id": "MDQ6VXNlcjE1NTIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/155238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikomatsakis", "html_url": "https://github.com/nikomatsakis", "followers_url": "https://api.github.com/users/nikomatsakis/followers", "following_url": "https://api.github.com/users/nikomatsakis/following{/other_user}", "gists_url": "https://api.github.com/users/nikomatsakis/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikomatsakis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikomatsakis/subscriptions", "organizations_url": "https://api.github.com/users/nikomatsakis/orgs", "repos_url": "https://api.github.com/users/nikomatsakis/repos", "events_url": "https://api.github.com/users/nikomatsakis/events{/privacy}", "received_events_url": "https://api.github.com/users/nikomatsakis/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nikomatsakis", "id": 155238, "node_id": "MDQ6VXNlcjE1NTIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/155238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikomatsakis", "html_url": "https://github.com/nikomatsakis", "followers_url": "https://api.github.com/users/nikomatsakis/followers", "following_url": "https://api.github.com/users/nikomatsakis/following{/other_user}", "gists_url": "https://api.github.com/users/nikomatsakis/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikomatsakis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikomatsakis/subscriptions", "organizations_url": "https://api.github.com/users/nikomatsakis/orgs", "repos_url": "https://api.github.com/users/nikomatsakis/repos", "events_url": "https://api.github.com/users/nikomatsakis/events{/privacy}", "received_events_url": "https://api.github.com/users/nikomatsakis/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "558be3a70f20072b415f7436b3130462caefa63a", "url": "https://api.github.com/repos/rust-lang/rust/commits/558be3a70f20072b415f7436b3130462caefa63a", "html_url": "https://github.com/rust-lang/rust/commit/558be3a70f20072b415f7436b3130462caefa63a"}], "stats": {"total": 195, "additions": 179, "deletions": 16}, "files": [{"sha": "75125cfabb9d524b1fc3fea84143fa805938a4ea", "filename": "src/rustc/middle/typeck/infer.rs", "status": "modified", "additions": 179, "deletions": 16, "changes": 195, "blob_url": "https://github.com/rust-lang/rust/blob/fa2ac6646233384deb6ff694da4e3b674a187cd0/src%2Frustc%2Fmiddle%2Ftypeck%2Finfer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa2ac6646233384deb6ff694da4e3b674a187cd0/src%2Frustc%2Fmiddle%2Ftypeck%2Finfer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frustc%2Fmiddle%2Ftypeck%2Finfer.rs?ref=fa2ac6646233384deb6ff694da4e3b674a187cd0", "patch": "@@ -1,3 +1,147 @@\n+/*\n+\n+# Type inference engine\n+\n+This is loosely based on standard HM-type inference, but with an\n+extension to try and accommodate subtyping.  There is nothing\n+principled about this extension; it's sound---I hope!---but it's a\n+heuristic, ultimately, and does not guarantee that it finds a valid\n+typing even if one exists (in fact, there are known scenarios where it\n+fails, some of which may eventually become problematic).\n+\n+## Key idea\n+\n+The main change is that each type variable T is associated with a\n+lower-bound L and an upper-bound U.  L and U begin as bottom and top,\n+respectively, but gradually narrow in response to new constraints\n+being introduced.  When a variable is finally resolved to a concrete\n+type, it can (theoretically) select any type that is a supertype of L\n+and a subtype of U.\n+\n+There are several critical invariants which we maintain:\n+\n+- the upper-bound of a variable only becomes lower and the lower-bound\n+  only becomes higher over time;\n+- the lower-bound L is always a subtype of the upper bound U;\n+- the lower-bound L and upper-bound U never refer to other type variables,\n+  but only to types (though those types may contain type variables).\n+\n+> An aside: if the terms upper- and lower-bound confuse you, think of\n+> \"supertype\" and \"subtype\".  The upper-bound is a \"supertype\"\n+> (super=upper in Latin, or something like that anyway) and the lower-bound\n+> is a \"subtype\" (sub=lower in Latin).  I find it helps to visualize\n+> a simple class hierarchy, like Java minus interfaces and\n+> primitive types.  The class Object is at the root (top) and other\n+> types lie in between.  The bottom type is then the Null type.\n+> So the tree looks like:\n+>\n+>             Object\n+>             /    \\\n+>         String   Other\n+>             \\    /\n+>             (null)\n+>\n+> So the upper bound type is the \"supertype\" and the lower bound is the\n+> \"subtype\" (also, super and sub mean upper and lower in Latin, or something\n+> like that anyway).\n+\n+## Satisfying constraints\n+\n+At a primitive level, there is only one form of constraint that the\n+inference understands: a subtype relation.  So the outside world can\n+say \"make type A a subtype of type B\".  If there are variables\n+involved, the inferencer will adjust their upper- and lower-bounds as\n+needed to ensure that this relation is satisfied. (We also allow \"make\n+type A equal to type B\", but this is translated into \"A <: B\" and \"B\n+<: A\")\n+\n+As stated above, we always maintain the invariant that type bounds\n+never refer to other variables.  This keeps the inference relatively\n+simple, avoiding the scenario of having a kind of graph where we have\n+to pump constraints along and reach a fixed point, but it does impose\n+some heuristics in the case where the user is relating two type\n+variables A <: B.\n+\n+The key point when relating type variables is that we do not know whta\n+type the variable represents, but we must make some change that will\n+ensure that, whatever types A and B are resolved to, they are resolved\n+to types which have a subtype relation.\n+\n+There are basically two options here:\n+\n+- we can merge A and B.  Basically we make them the same variable.\n+  The lower bound of this new variable is LUB(LB(A), LB(B)) and\n+  the upper bound is GLB(UB(A), UB(B)).\n+\n+- we can adjust the bounds of A and B.  Because we do not allow\n+  type variables to appear in each other's bounds, this only works if A\n+  and B have appropriate bounds.  But if we can ensure that UB(A) <: LB(B),\n+  then we know that whatever happens A and B will be resolved to types with\n+  the appropriate relation.\n+\n+Our current technique is to *try* (transactionally) to relate the\n+existing bounds of A and B, if there are any (i.e., if `UB(A) != top\n+&& LB(B) != bot`).  If that succeeds, we're done.  If it fails, then\n+we merge A and B into same variable.\n+\n+This is not clearly the correct course.  For example, if `UB(A) !=\n+top` but `LB(B) == bot`, we could conceivably set `LB(B)` to `UB(A)`\n+and leave the variables unmerged.  This is sometimes the better\n+course, it depends on the program.\n+\n+The main case which fails today that I would like to support is:\n+\n+    fn foo<T>(x: T, y: T) { ... }\n+\n+    fn bar() {\n+        let x: @mut int = @mut 3;\n+        let y: @int = @3;\n+        foo(x, y);\n+    }\n+\n+In principle, the inferencer ought to find that the parameter `T` to\n+`foo(x, y)` is `@const int`.  Today, however, it does not; this is\n+because the type variable `T` is merged with the type variable for\n+`X`, and thus inherits its UB/LB of `@mut int`.  This leaves no\n+flexibility for `T` to later adjust to accommodate `@int`.\n+\n+## Transactional support\n+\n+Whenever we adjust merge variables or adjust their bounds, we always\n+keep a record of the old value.  This allows the changes to be undone.\n+\n+## Regions\n+\n+I've only talked about type variables here, but region variables\n+follow the same principle.  They have upper- and lower-bounds.  A\n+region A is a subregion of a region B if A being valid implies that B\n+is valid.  This basically corresponds to the block nesting structure:\n+the regions for outer block scopes are superregions of those for inner\n+block scopes.\n+\n+## GLB/LUB\n+\n+Computing the greatest-lower-bound and least-upper-bound of two\n+types/regions is generally straightforward except when type variables\n+are involved. In that case, we follow a similar \"try to use the bounds\n+when possible but otherwise merge the variables\" strategy.  In other\n+words, `GLB(A, B)` where `A` and `B` are variables will often result\n+in `A` and `B` being merged and the result being `A`.\n+\n+## Type assignment\n+\n+We have a notion of assignability which differs somewhat from\n+subtyping; in particular it may cause region borrowing to occur.  See\n+the big comment later in this file on Type Assignment for specifics.\n+\n+# Implementation details\n+\n+We make use of a trait-like impementation strategy to consolidate\n+duplicated code between subtypes, GLB, and LUB computations.  See the\n+section on \"Type Combining\" below for details.\n+\n+*/\n+\n import std::smallintmap;\n import std::smallintmap::smallintmap;\n import std::smallintmap::map;\n@@ -914,27 +1058,46 @@ impl assignment for infer_ctxt {\n // ______________________________________________________________________\n // Type combining\n //\n-// There are three type combiners, sub, lub, and gub.  `sub` is a bit\n-// different from the other two: it takes two types and makes the first\n-// a subtype of the other, or fails if this cannot be done.  It does\n-// return a new type but its return value is meaningless---it is only\n-// there to allow for greater code reuse.\n-//\n-// `lub` and `glb` compute the Least Upper Bound and Greatest Lower\n-// Bound respectively of two types `a` and `b`.  The LUB is a mutual\n-// supertype type `c` where `a <: c` and `b <: c`.  As the name\n-// implies, it tries to pick the most precise `c` possible.  The GLB\n-// is a mutual subtype, aiming for the most general such type\n-// possible.  Both computations may fail.\n+// There are three type combiners, sub, lub, and gub.  Each implements\n+// the interface `combine` contains methods for combining two\n+// instances of various things and yielding a new instance.  These\n+// combiner methods always yield a `result<T>`---failure is propagated\n+// upward using `chain()` methods.\n //\n // There is a lot of common code for these operations, which is\n // abstracted out into functions named `super_X()` which take a combiner\n // instance as the first parameter.  This would be better implemented\n-// using traits.\n+// using traits.  For this system to work properly, you should not\n+// call the `super_X(foo, ...)` functions directly, but rather call\n+// `foo.X(...)`.  The implemtation of `X()` can then choose to delegate\n+// to the `super` routine or to do other things.\n+//\n+// In reality, the sub operation is rather different from lub/glb, but\n+// they are combined into one interface to avoid duplication (they\n+// used to be separate but there were many bugs because there were two\n+// copies of most routines.\n+//\n+// The differences are:\n+//\n+// - when making two things have a sub relationship, the order of the\n+//   arguments is significant (a <: b) and the return value of the\n+//   combine functions is largely irrelevant.  The important thing is\n+//   whether the action succeeds or fails.  If it succeeds, then side\n+//   effects have been committed into the type variables.\n+//\n+// - for GLB/LUB, the order of arguments is not significant (GLB(a,b) ==\n+//   GLB(b,a)) and the return value is important (it is the GLB).  Of\n+//   course GLB/LUB may also have side effects.\n+//\n+// Contravariance\n //\n-// The `super_X()` top-level items work for *sub, lub, and glb*: any\n-// operation which varies will be dynamically dispatched using a\n-// `self.Y()` operation.\n+// When you are relating two things which have a contravariant\n+// relationship, you should use `contratys()` or `contraregions()`,\n+// rather than inversing the order of arguments!  This is necessary\n+// because the order of arguments is not relevant for LUB and GLB.  It\n+// is also useful to track which value is the \"expected\" value in\n+// terms of error reporting, although we do not do that properly right\n+// now.\n \n type cres<T> = result<T,ty::type_err>;\n "}]}