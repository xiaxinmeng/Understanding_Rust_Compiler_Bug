{"sha": "f2023ac599c38a59f86552089e6791c5a73412d3", "node_id": "MDY6Q29tbWl0NzI0NzEyOmYyMDIzYWM1OTljMzhhNTlmODY1NTIwODllNjc5MWM1YTczNDEyZDM=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-10-02T06:08:24Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-10-02T06:08:24Z"}, "message": "Auto merge of #64981 - tmandry:rollup-slfkhay, r=tmandry\n\nRollup of 11 pull requests\n\nSuccessful merges:\n\n - #64649 (Avoid ICE on return outside of fn with literal array)\n - #64722 (Make all alt builders produce parallel-enabled compilers)\n - #64801 (Avoid `chain()` in `find_constraint_paths_between_regions()`.)\n - #64805 (Still more `ObligationForest` improvements.)\n - #64840 (SelfProfiler API refactoring and part one of event review)\n - #64885 (use try_fold instead of try_for_each to reduce compile time)\n - #64942 (Fix clippy warnings)\n - #64952 (Update cargo.)\n - #64974 (Fix zebra-striping in generic dataflow visualization)\n - #64978 (Fully clear `HandlerInner` in `Handler::reset_err_count`)\n - #64979 (Update books)\n\nFailed merges:\n\n - #64959 (syntax: improve parameter without type suggestions)\n\nr? @ghost", "tree": {"sha": "e2ebd2336ca270269b57cc3660640339a182c0c2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e2ebd2336ca270269b57cc3660640339a182c0c2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f2023ac599c38a59f86552089e6791c5a73412d3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f2023ac599c38a59f86552089e6791c5a73412d3", "html_url": "https://github.com/rust-lang/rust/commit/f2023ac599c38a59f86552089e6791c5a73412d3", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f2023ac599c38a59f86552089e6791c5a73412d3/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ff191b54cc8a95e3bfc7ae5f8f9984f934758165", "url": "https://api.github.com/repos/rust-lang/rust/commits/ff191b54cc8a95e3bfc7ae5f8f9984f934758165", "html_url": "https://github.com/rust-lang/rust/commit/ff191b54cc8a95e3bfc7ae5f8f9984f934758165"}, {"sha": "0878ca51f08d20499e04feda142c5e0ab44a628b", "url": "https://api.github.com/repos/rust-lang/rust/commits/0878ca51f08d20499e04feda142c5e0ab44a628b", "html_url": "https://github.com/rust-lang/rust/commit/0878ca51f08d20499e04feda142c5e0ab44a628b"}], "stats": {"total": 1131, "additions": 635, "deletions": 496}, "files": [{"sha": "80364515a7cca509dc7f1468c482c748b42d20a9", "filename": "Cargo.lock", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -265,7 +265,7 @@ dependencies = [\n \n [[package]]\n name = \"cargo\"\n-version = \"0.40.0\"\n+version = \"0.41.0\"\n dependencies = [\n  \"atty\",\n  \"bytesize\",\n@@ -600,7 +600,7 @@ checksum = \"e7ca8a5221364ef15ce201e8ed2f609fc312682a8f4e0e3d4aa5879764e0fa3b\"\n \n [[package]]\n name = \"crates-io\"\n-version = \"0.28.0\"\n+version = \"0.29.0\"\n dependencies = [\n  \"curl\",\n  \"failure\",\n@@ -730,25 +730,24 @@ dependencies = [\n \n [[package]]\n name = \"curl\"\n-version = \"0.4.21\"\n+version = \"0.4.24\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"a85f2f95f2bd277d316d1aa8a477687ab4a6942258c7db7c89c187534669979c\"\n+checksum = \"d08ad3cb89d076a36b0ce5749eec2c9964f70c0c58480ab6b75a91ec4fc206d8\"\n dependencies = [\n  \"curl-sys\",\n- \"kernel32-sys\",\n  \"libc\",\n  \"openssl-probe\",\n  \"openssl-sys\",\n  \"schannel\",\n  \"socket2\",\n- \"winapi 0.2.8\",\n+ \"winapi 0.3.6\",\n ]\n \n [[package]]\n name = \"curl-sys\"\n-version = \"0.4.18\"\n+version = \"0.4.22\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"9d91a0052d5b982887d8e829bee0faffc7218ea3c6ebd3d6c2c8f678a93c9a42\"\n+checksum = \"2e9a9a4e417722876332136a00cacf92c2ceb331fab4b52b6a1ad16c6cd79255\"\n dependencies = [\n  \"cc\",\n  \"libc\","}, {"sha": "0d5ea371245e42cabb533daa5d0256cca8031633", "filename": "src/ci/run.sh", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Fci%2Frun.sh", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Fci%2Frun.sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fci%2Frun.sh?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -55,6 +55,9 @@ if [ \"$DEPLOY$DEPLOY_ALT\" = \"1\" ]; then\n   if [ \"$NO_LLVM_ASSERTIONS\" = \"1\" ]; then\n     RUST_CONFIGURE_ARGS=\"$RUST_CONFIGURE_ARGS --disable-llvm-assertions\"\n   elif [ \"$DEPLOY_ALT\" != \"\" ]; then\n+    if [ \"$NO_PARALLEL_COMPILER\" = \"\" ]; then\n+      RUST_CONFIGURE_ARGS=\"$RUST_CONFIGURE_ARGS --set rust.parallel-compiler\"\n+    fi\n     RUST_CONFIGURE_ARGS=\"$RUST_CONFIGURE_ARGS --enable-llvm-assertions\"\n     RUST_CONFIGURE_ARGS=\"$RUST_CONFIGURE_ARGS --set rust.verify-llvm-ir\"\n   fi"}, {"sha": "04806c80be0f54b1290287e3f85e84bdfc0b6ec7", "filename": "src/doc/book", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": null, "raw_url": null, "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Fbook?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1 +1 @@\n-Subproject commit 871416b85c1a73717d65d6f4a9ea29e5aef3db0e\n+Subproject commit 04806c80be0f54b1290287e3f85e84bdfc0b6ec7"}, {"sha": "320d232b206edecb67489316f71a14e31dbc6c08", "filename": "src/doc/reference", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": null, "raw_url": null, "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Freference?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1 +1 @@\n-Subproject commit fa5dfb832ef8a7568e17dabf612f486d641ff4ac\n+Subproject commit 320d232b206edecb67489316f71a14e31dbc6c08"}, {"sha": "a6288e7407a6c4c19ea29de6d43f40c803883f21", "filename": "src/doc/rust-by-example", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": null, "raw_url": null, "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Frust-by-example?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1 +1 @@\n-Subproject commit 67cfbf31df880728dcf7cb35b15b028ec92caf31\n+Subproject commit a6288e7407a6c4c19ea29de6d43f40c803883f21"}, {"sha": "66d27a275192e69e16c9b292387f5f60df69b591", "filename": "src/libarena/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibarena%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibarena%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibarena%2Flib.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -500,7 +500,7 @@ impl DroplessArena {\n                 // though it was supposed to give us `len`\n                 return slice::from_raw_parts_mut(mem, i);\n             }\n-            ptr::write(mem.offset(i as isize), value.unwrap());\n+            ptr::write(mem.add(i), value.unwrap());\n             i += 1;\n         }\n     }"}, {"sha": "a272035150a1587f7551b38de7f8663e1c5290f5", "filename": "src/libcore/iter/traits/iterator.rs", "status": "modified", "additions": 14, "deletions": 13, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibcore%2Fiter%2Ftraits%2Fiterator.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibcore%2Fiter%2Ftraits%2Fiterator.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fiter%2Ftraits%2Fiterator.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1859,14 +1859,13 @@ pub trait Iterator {\n         Self: Sized, F: FnMut(Self::Item) -> bool\n     {\n         #[inline]\n-        fn check<T>(mut f: impl FnMut(T) -> bool) -> impl FnMut(T) -> LoopState<(), ()> {\n-            move |x| {\n+        fn check<T>(mut f: impl FnMut(T) -> bool) -> impl FnMut((), T) -> LoopState<(), ()> {\n+            move |(), x| {\n                 if f(x) { LoopState::Continue(()) }\n                 else { LoopState::Break(()) }\n             }\n         }\n-\n-        self.try_for_each(check(f)) == LoopState::Continue(())\n+        self.try_fold((), check(f)) == LoopState::Continue(())\n     }\n \n     /// Tests if any element of the iterator matches a predicate.\n@@ -1913,14 +1912,14 @@ pub trait Iterator {\n         F: FnMut(Self::Item) -> bool\n     {\n         #[inline]\n-        fn check<T>(mut f: impl FnMut(T) -> bool) -> impl FnMut(T) -> LoopState<(), ()> {\n-            move |x| {\n+        fn check<T>(mut f: impl FnMut(T) -> bool) -> impl FnMut((), T) -> LoopState<(), ()> {\n+            move |(), x| {\n                 if f(x) { LoopState::Break(()) }\n                 else { LoopState::Continue(()) }\n             }\n         }\n \n-        self.try_for_each(check(f)) == LoopState::Break(())\n+        self.try_fold((), check(f)) == LoopState::Break(())\n     }\n \n     /// Searches for an element of an iterator that satisfies a predicate.\n@@ -1972,14 +1971,16 @@ pub trait Iterator {\n         P: FnMut(&Self::Item) -> bool,\n     {\n         #[inline]\n-        fn check<T>(mut predicate: impl FnMut(&T) -> bool) -> impl FnMut(T) -> LoopState<(), T> {\n-            move |x| {\n+        fn check<T>(\n+            mut predicate: impl FnMut(&T) -> bool\n+        ) -> impl FnMut((), T) -> LoopState<(), T> {\n+            move |(), x| {\n                 if predicate(&x) { LoopState::Break(x) }\n                 else { LoopState::Continue(()) }\n             }\n         }\n \n-        self.try_for_each(check(predicate)).break_value()\n+        self.try_fold((), check(predicate)).break_value()\n     }\n \n     /// Applies function to the elements of iterator and returns\n@@ -2004,14 +2005,14 @@ pub trait Iterator {\n         F: FnMut(Self::Item) -> Option<B>,\n     {\n         #[inline]\n-        fn check<T, B>(mut f: impl FnMut(T) -> Option<B>) -> impl FnMut(T) -> LoopState<(), B> {\n-            move |x| match f(x) {\n+        fn check<T, B>(mut f: impl FnMut(T) -> Option<B>) -> impl FnMut((), T) -> LoopState<(), B> {\n+            move |(), x| match f(x) {\n                 Some(x) => LoopState::Break(x),\n                 None => LoopState::Continue(()),\n             }\n         }\n \n-        self.try_for_each(check(f)).break_value()\n+        self.try_fold((), check(f)).break_value()\n     }\n \n     /// Searches for an element in an iterator, returning its index."}, {"sha": "2771ce69b9e0df747c6a4cac4f33bbe17b1e1666", "filename": "src/librustc/session/config.rs", "status": "modified", "additions": 16, "deletions": 3, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Fsession%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Fsession%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fconfig.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -805,6 +805,7 @@ macro_rules! options {\n         pub const parse_list: Option<&str> = Some(\"a space-separated list of strings\");\n         pub const parse_opt_list: Option<&str> = Some(\"a space-separated list of strings\");\n         pub const parse_opt_comma_list: Option<&str> = Some(\"a comma-separated list of strings\");\n+        pub const parse_threads: Option<&str> = Some(\"a number\");\n         pub const parse_uint: Option<&str> = Some(\"a number\");\n         pub const parse_passes: Option<&str> =\n             Some(\"a space-separated list of passes, or `all`\");\n@@ -948,6 +949,14 @@ macro_rules! options {\n             }\n         }\n \n+        fn parse_threads(slot: &mut usize, v: Option<&str>) -> bool {\n+            match v.and_then(|s| s.parse().ok()) {\n+                Some(0) => { *slot = ::num_cpus::get(); true },\n+                Some(i) => { *slot = i; true },\n+                None => false\n+            }\n+        }\n+\n         fn parse_uint(slot: &mut usize, v: Option<&str>) -> bool {\n             match v.and_then(|s| s.parse().ok()) {\n                 Some(i) => { *slot = i; true },\n@@ -1251,7 +1260,11 @@ options! {DebuggingOptions, DebuggingSetter, basic_debugging_options,\n         \"prints the LLVM optimization passes being run\"),\n     ast_json: bool = (false, parse_bool, [UNTRACKED],\n         \"print the AST as JSON and halt\"),\n-    threads: Option<usize> = (None, parse_opt_uint, [UNTRACKED],\n+    // We default to 1 here since we want to behave like\n+    // a sequential compiler for now. This'll likely be adjusted\n+    // in the future. Note that -Zthreads=0 is the way to get\n+    // the num_cpus behavior.\n+    threads: usize = (1, parse_threads, [UNTRACKED],\n         \"use a thread pool with N threads\"),\n     ast_json_noexpand: bool = (false, parse_bool, [UNTRACKED],\n         \"print the pre-expansion AST as JSON and halt\"),\n@@ -2146,14 +2159,14 @@ pub fn build_session_options_and_crate_config(\n         }\n     }\n \n-    if debugging_opts.threads == Some(0) {\n+    if debugging_opts.threads == 0 {\n         early_error(\n             error_format,\n             \"value for threads must be a positive non-zero integer\",\n         );\n     }\n \n-    if debugging_opts.threads.unwrap_or(1) > 1 && debugging_opts.fuel.is_some() {\n+    if debugging_opts.threads > 1 && debugging_opts.fuel.is_some() {\n         early_error(\n             error_format,\n             \"optimization fuel is incompatible with multiple threads\","}, {"sha": "f22445f5d4744765c8f8c705d914edec6e929548", "filename": "src/librustc/session/mod.rs", "status": "modified", "additions": 4, "deletions": 28, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Fsession%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Fsession%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fmod.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -32,7 +32,7 @@ use syntax::source_map;\n use syntax::parse::{self, ParseSess};\n use syntax::symbol::Symbol;\n use syntax_pos::{MultiSpan, Span};\n-use crate::util::profiling::SelfProfiler;\n+use crate::util::profiling::{SelfProfiler, SelfProfilerRef};\n \n use rustc_target::spec::{PanicStrategy, RelroLevel, Target, TargetTriple};\n use rustc_data_structures::flock;\n@@ -129,7 +129,7 @@ pub struct Session {\n     pub profile_channel: Lock<Option<mpsc::Sender<ProfileQueriesMsg>>>,\n \n     /// Used by `-Z self-profile`.\n-    pub self_profiling: Option<Arc<SelfProfiler>>,\n+    pub prof: SelfProfilerRef,\n \n     /// Some measurements that are being gathered during compilation.\n     pub perf_stats: PerfStats,\n@@ -835,24 +835,6 @@ impl Session {\n         }\n     }\n \n-    #[inline(never)]\n-    #[cold]\n-    fn profiler_active<F: FnOnce(&SelfProfiler) -> ()>(&self, f: F) {\n-        match &self.self_profiling {\n-            None => bug!(\"profiler_active() called but there was no profiler active\"),\n-            Some(profiler) => {\n-                f(&profiler);\n-            }\n-        }\n-    }\n-\n-    #[inline(always)]\n-    pub fn profiler<F: FnOnce(&SelfProfiler) -> ()>(&self, f: F) {\n-        if unlikely!(self.self_profiling.is_some()) {\n-            self.profiler_active(f)\n-        }\n-    }\n-\n     pub fn print_perf_stats(&self) {\n         println!(\n             \"Total time spent computing symbol hashes:      {}\",\n@@ -896,16 +878,10 @@ impl Session {\n         ret\n     }\n \n-    /// Returns the number of query threads that should be used for this\n-    /// compilation\n-    pub fn threads_from_count(query_threads: Option<usize>) -> usize {\n-        query_threads.unwrap_or(::num_cpus::get())\n-    }\n-\n     /// Returns the number of query threads that should be used for this\n     /// compilation\n     pub fn threads(&self) -> usize {\n-        Self::threads_from_count(self.opts.debugging_opts.threads)\n+        self.opts.debugging_opts.threads\n     }\n \n     /// Returns the number of codegen units that should be used for this\n@@ -1257,7 +1233,7 @@ fn build_session_(\n         imported_macro_spans: OneThread::new(RefCell::new(FxHashMap::default())),\n         incr_comp_session: OneThread::new(RefCell::new(IncrCompSession::NotInitialized)),\n         cgu_reuse_tracker,\n-        self_profiling: self_profiler,\n+        prof: SelfProfilerRef::new(self_profiler),\n         profile_channel: Lock::new(None),\n         perf_stats: PerfStats {\n             symbol_hash_time: Lock::new(Duration::from_secs(0)),"}, {"sha": "5f1a17e4a9521b32422a1e2c4db8f72d0c207d9a", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -45,6 +45,7 @@ use crate::ty::CanonicalPolyFnSig;\n use crate::util::common::ErrorReported;\n use crate::util::nodemap::{DefIdMap, DefIdSet, ItemLocalMap, ItemLocalSet};\n use crate::util::nodemap::{FxHashMap, FxHashSet};\n+use crate::util::profiling::SelfProfilerRef;\n \n use errors::DiagnosticBuilder;\n use arena::SyncDroplessArena;\n@@ -1030,6 +1031,8 @@ pub struct GlobalCtxt<'tcx> {\n \n     pub dep_graph: DepGraph,\n \n+    pub prof: SelfProfilerRef,\n+\n     /// Common objects.\n     pub common: Common<'tcx>,\n \n@@ -1260,6 +1263,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             arena: WorkerLocal::new(|_| Arena::default()),\n             interners,\n             dep_graph,\n+            prof: s.prof.clone(),\n             common,\n             types: common_types,\n             lifetimes: common_lifetimes,"}, {"sha": "955f1447c55b67c3d61aeec068a2860accd35b65", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 11, "deletions": 15, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -112,7 +112,7 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n             let mut lock = cache.get_shard_by_value(key).lock();\n             if let Some(value) = lock.results.get(key) {\n                 profq_msg!(tcx, ProfileQueriesMsg::CacheHit);\n-                tcx.sess.profiler(|p| p.record_query_hit(Q::NAME));\n+                tcx.prof.query_cache_hit(Q::NAME);\n                 let result = (value.value.clone(), value.index);\n                 #[cfg(debug_assertions)]\n                 {\n@@ -128,7 +128,7 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n                             // in another thread has completed. Record how long we wait in the\n                             // self-profiler.\n                             #[cfg(parallel_compiler)]\n-                            tcx.sess.profiler(|p| p.query_blocked_start(Q::NAME));\n+                            tcx.prof.query_blocked_start(Q::NAME);\n \n                             job.clone()\n                         },\n@@ -170,7 +170,7 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n             #[cfg(parallel_compiler)]\n             {\n                 let result = job.r#await(tcx, span);\n-                tcx.sess.profiler(|p| p.query_blocked_end(Q::NAME));\n+                tcx.prof.query_blocked_end(Q::NAME);\n \n                 if let Err(cycle) = result {\n                     return TryGetJob::Cycle(Q::handle_cycle_error(tcx, cycle));\n@@ -382,8 +382,9 @@ impl<'tcx> TyCtxt<'tcx> {\n         }\n \n         if Q::ANON {\n+\n             profq_msg!(self, ProfileQueriesMsg::ProviderBegin);\n-            self.sess.profiler(|p| p.start_query(Q::NAME));\n+            let prof_timer = self.prof.query_provider(Q::NAME);\n \n             let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n                 self.start_query(job.job.clone(), diagnostics, |tcx| {\n@@ -393,7 +394,7 @@ impl<'tcx> TyCtxt<'tcx> {\n                 })\n             });\n \n-            self.sess.profiler(|p| p.end_query(Q::NAME));\n+            drop(prof_timer);\n             profq_msg!(self, ProfileQueriesMsg::ProviderEnd);\n \n             self.dep_graph.read_index(dep_node_index);\n@@ -451,9 +452,8 @@ impl<'tcx> TyCtxt<'tcx> {\n         // First we try to load the result from the on-disk cache.\n         let result = if Q::cache_on_disk(self, key.clone(), None) &&\n                         self.sess.opts.debugging_opts.incremental_queries {\n-            self.sess.profiler(|p| p.incremental_load_result_start(Q::NAME));\n+            let _prof_timer = self.prof.incr_cache_loading(Q::NAME);\n             let result = Q::try_load_from_disk(self, prev_dep_node_index);\n-            self.sess.profiler(|p| p.incremental_load_result_end(Q::NAME));\n \n             // We always expect to find a cached result for things that\n             // can be forced from `DepNode`.\n@@ -469,21 +469,17 @@ impl<'tcx> TyCtxt<'tcx> {\n \n         let result = if let Some(result) = result {\n             profq_msg!(self, ProfileQueriesMsg::CacheHit);\n-            self.sess.profiler(|p| p.record_query_hit(Q::NAME));\n-\n             result\n         } else {\n             // We could not load a result from the on-disk cache, so\n             // recompute.\n-\n-            self.sess.profiler(|p| p.start_query(Q::NAME));\n+            let _prof_timer = self.prof.query_provider(Q::NAME);\n \n             // The dep-graph for this computation is already in-place.\n             let result = self.dep_graph.with_ignore(|| {\n                 Q::compute(self, key)\n             });\n \n-            self.sess.profiler(|p| p.end_query(Q::NAME));\n             result\n         };\n \n@@ -551,7 +547,7 @@ impl<'tcx> TyCtxt<'tcx> {\n                 key, dep_node);\n \n         profq_msg!(self, ProfileQueriesMsg::ProviderBegin);\n-        self.sess.profiler(|p| p.start_query(Q::NAME));\n+        let prof_timer = self.prof.query_provider(Q::NAME);\n \n         let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n             self.start_query(job.job.clone(), diagnostics, |tcx| {\n@@ -571,7 +567,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             })\n         });\n \n-        self.sess.profiler(|p| p.end_query(Q::NAME));\n+        drop(prof_timer);\n         profq_msg!(self, ProfileQueriesMsg::ProviderEnd);\n \n         if unlikely!(self.sess.opts.debugging_opts.query_dep_graph) {\n@@ -619,7 +615,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             let _ = self.get_query::<Q>(DUMMY_SP, key);\n         } else {\n             profq_msg!(self, ProfileQueriesMsg::CacheHit);\n-            self.sess.profiler(|p| p.record_query_hit(Q::NAME));\n+            self.prof.query_cache_hit(Q::NAME);\n         }\n     }\n "}, {"sha": "bd02e7f5a14a16507e6b8b9444b83037d9fcb486", "filename": "src/librustc/util/profiling.rs", "status": "modified", "additions": 237, "deletions": 89, "changes": 326, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Futil%2Fprofiling.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc%2Futil%2Fprofiling.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fprofiling.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1,9 +1,9 @@\n-use std::borrow::Cow;\n use std::error::Error;\n use std::fs;\n use std::mem::{self, Discriminant};\n use std::path::Path;\n use std::process;\n+use std::sync::Arc;\n use std::thread::ThreadId;\n use std::u32;\n \n@@ -62,6 +62,206 @@ fn thread_id_to_u64(tid: ThreadId) -> u64 {\n     unsafe { mem::transmute::<ThreadId, u64>(tid) }\n }\n \n+\n+/// A reference to the SelfProfiler. It can be cloned and sent across thread\n+/// boundaries at will.\n+#[derive(Clone)]\n+pub struct SelfProfilerRef {\n+    // This field is `None` if self-profiling is disabled for the current\n+    // compilation session.\n+    profiler: Option<Arc<SelfProfiler>>,\n+\n+    // We store the filter mask directly in the reference because that doesn't\n+    // cost anything and allows for filtering with checking if the profiler is\n+    // actually enabled.\n+    event_filter_mask: EventFilter,\n+}\n+\n+impl SelfProfilerRef {\n+\n+    pub fn new(profiler: Option<Arc<SelfProfiler>>) -> SelfProfilerRef {\n+        // If there is no SelfProfiler then the filter mask is set to NONE,\n+        // ensuring that nothing ever tries to actually access it.\n+        let event_filter_mask = profiler\n+            .as_ref()\n+            .map(|p| p.event_filter_mask)\n+            .unwrap_or(EventFilter::NONE);\n+\n+        SelfProfilerRef {\n+            profiler,\n+            event_filter_mask,\n+        }\n+    }\n+\n+    // This shim makes sure that calls only get executed if the filter mask\n+    // lets them pass. It also contains some trickery to make sure that\n+    // code is optimized for non-profiling compilation sessions, i.e. anything\n+    // past the filter check is never inlined so it doesn't clutter the fast\n+    // path.\n+    #[inline(always)]\n+    fn exec<F>(&self, event_filter: EventFilter, f: F) -> TimingGuard<'_>\n+        where F: for<'a> FnOnce(&'a SelfProfiler) -> TimingGuard<'a>\n+    {\n+        #[inline(never)]\n+        fn cold_call<F>(profiler_ref: &SelfProfilerRef, f: F) -> TimingGuard<'_>\n+            where F: for<'a> FnOnce(&'a SelfProfiler) -> TimingGuard<'a>\n+        {\n+            let profiler = profiler_ref.profiler.as_ref().unwrap();\n+            f(&**profiler)\n+        }\n+\n+        if unlikely!(self.event_filter_mask.contains(event_filter)) {\n+            cold_call(self, f)\n+        } else {\n+            TimingGuard::none()\n+        }\n+    }\n+\n+    /// Start profiling a generic activity. Profiling continues until the\n+    /// TimingGuard returned from this call is dropped.\n+    #[inline(always)]\n+    pub fn generic_activity(&self, event_id: &str) -> TimingGuard<'_> {\n+        self.exec(EventFilter::GENERIC_ACTIVITIES, |profiler| {\n+            let event_id = profiler.profiler.alloc_string(event_id);\n+            TimingGuard::start(\n+                profiler,\n+                profiler.generic_activity_event_kind,\n+                event_id\n+            )\n+        })\n+    }\n+\n+    /// Start profiling a generic activity. Profiling continues until\n+    /// `generic_activity_end` is called. The RAII-based `generic_activity`\n+    /// usually is the better alternative.\n+    #[inline(always)]\n+    pub fn generic_activity_start(&self, event_id: &str) {\n+        self.non_guard_generic_event(\n+            |profiler| profiler.generic_activity_event_kind,\n+            |profiler| profiler.profiler.alloc_string(event_id),\n+            EventFilter::GENERIC_ACTIVITIES,\n+            TimestampKind::Start,\n+        );\n+    }\n+\n+    /// End profiling a generic activity that was started with\n+    /// `generic_activity_start`. The RAII-based `generic_activity` usually is\n+    /// the better alternative.\n+    #[inline(always)]\n+    pub fn generic_activity_end(&self, event_id: &str) {\n+        self.non_guard_generic_event(\n+            |profiler| profiler.generic_activity_event_kind,\n+            |profiler| profiler.profiler.alloc_string(event_id),\n+            EventFilter::GENERIC_ACTIVITIES,\n+            TimestampKind::End,\n+        );\n+    }\n+\n+    /// Start profiling a query provider. Profiling continues until the\n+    /// TimingGuard returned from this call is dropped.\n+    #[inline(always)]\n+    pub fn query_provider(&self, query_name: QueryName) -> TimingGuard<'_> {\n+        self.exec(EventFilter::QUERY_PROVIDERS, |profiler| {\n+            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n+            TimingGuard::start(profiler, profiler.query_event_kind, event_id)\n+        })\n+    }\n+\n+    /// Record a query in-memory cache hit.\n+    #[inline(always)]\n+    pub fn query_cache_hit(&self, query_name: QueryName) {\n+        self.non_guard_query_event(\n+            |profiler| profiler.query_cache_hit_event_kind,\n+            query_name,\n+            EventFilter::QUERY_CACHE_HITS,\n+            TimestampKind::Instant,\n+        );\n+    }\n+\n+    /// Start profiling a query being blocked on a concurrent execution.\n+    /// Profiling continues until `query_blocked_end` is called.\n+    #[inline(always)]\n+    pub fn query_blocked_start(&self, query_name: QueryName) {\n+        self.non_guard_query_event(\n+            |profiler| profiler.query_blocked_event_kind,\n+            query_name,\n+            EventFilter::QUERY_BLOCKED,\n+            TimestampKind::Start,\n+        );\n+    }\n+\n+    /// End profiling a query being blocked on a concurrent execution.\n+    #[inline(always)]\n+    pub fn query_blocked_end(&self, query_name: QueryName) {\n+        self.non_guard_query_event(\n+            |profiler| profiler.query_blocked_event_kind,\n+            query_name,\n+            EventFilter::QUERY_BLOCKED,\n+            TimestampKind::End,\n+        );\n+    }\n+\n+    /// Start profiling how long it takes to load a query result from the\n+    /// incremental compilation on-disk cache. Profiling continues until the\n+    /// TimingGuard returned from this call is dropped.\n+    #[inline(always)]\n+    pub fn incr_cache_loading(&self, query_name: QueryName) -> TimingGuard<'_> {\n+        self.exec(EventFilter::INCR_CACHE_LOADS, |profiler| {\n+            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n+            TimingGuard::start(\n+                profiler,\n+                profiler.incremental_load_result_event_kind,\n+                event_id\n+            )\n+        })\n+    }\n+\n+    #[inline(always)]\n+    fn non_guard_query_event(\n+        &self,\n+        event_kind: fn(&SelfProfiler) -> StringId,\n+        query_name: QueryName,\n+        event_filter: EventFilter,\n+        timestamp_kind: TimestampKind\n+    ) {\n+        drop(self.exec(event_filter, |profiler| {\n+            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n+            let thread_id = thread_id_to_u64(std::thread::current().id());\n+\n+            profiler.profiler.record_event(\n+                event_kind(profiler),\n+                event_id,\n+                thread_id,\n+                timestamp_kind,\n+            );\n+\n+            TimingGuard::none()\n+        }));\n+    }\n+\n+    #[inline(always)]\n+    fn non_guard_generic_event<F: FnOnce(&SelfProfiler) -> StringId>(\n+        &self,\n+        event_kind: fn(&SelfProfiler) -> StringId,\n+        event_id: F,\n+        event_filter: EventFilter,\n+        timestamp_kind: TimestampKind\n+    ) {\n+        drop(self.exec(event_filter, |profiler| {\n+            let thread_id = thread_id_to_u64(std::thread::current().id());\n+\n+            profiler.profiler.record_event(\n+                event_kind(profiler),\n+                event_id(profiler),\n+                thread_id,\n+                timestamp_kind,\n+            );\n+\n+            TimingGuard::none()\n+        }));\n+    }\n+}\n+\n pub struct SelfProfiler {\n     profiler: Profiler,\n     event_filter_mask: EventFilter,\n@@ -143,103 +343,51 @@ impl SelfProfiler {\n         let id = SelfProfiler::get_query_name_string_id(query_name);\n         self.profiler.alloc_string_with_reserved_id(id, query_name.as_str());\n     }\n+}\n \n-    #[inline]\n-    pub fn start_activity(\n-        &self,\n-        label: impl Into<Cow<'static, str>>,\n-    ) {\n-        if self.event_filter_mask.contains(EventFilter::GENERIC_ACTIVITIES) {\n-            self.record(&label.into(), self.generic_activity_event_kind, TimestampKind::Start);\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn end_activity(\n-        &self,\n-        label: impl Into<Cow<'static, str>>,\n-    ) {\n-        if self.event_filter_mask.contains(EventFilter::GENERIC_ACTIVITIES) {\n-            self.record(&label.into(), self.generic_activity_event_kind, TimestampKind::End);\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn record_query_hit(&self, query_name: QueryName) {\n-        if self.event_filter_mask.contains(EventFilter::QUERY_CACHE_HITS) {\n-            self.record_query(query_name, self.query_cache_hit_event_kind, TimestampKind::Instant);\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn start_query(&self, query_name: QueryName) {\n-        if self.event_filter_mask.contains(EventFilter::QUERY_PROVIDERS) {\n-            self.record_query(query_name, self.query_event_kind, TimestampKind::Start);\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn end_query(&self, query_name: QueryName) {\n-        if self.event_filter_mask.contains(EventFilter::QUERY_PROVIDERS) {\n-            self.record_query(query_name, self.query_event_kind, TimestampKind::End);\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn incremental_load_result_start(&self, query_name: QueryName) {\n-        if self.event_filter_mask.contains(EventFilter::INCR_CACHE_LOADS) {\n-            self.record_query(\n-                query_name,\n-                self.incremental_load_result_event_kind,\n-                TimestampKind::Start\n-            );\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn incremental_load_result_end(&self, query_name: QueryName) {\n-        if self.event_filter_mask.contains(EventFilter::INCR_CACHE_LOADS) {\n-            self.record_query(\n-                query_name,\n-                self.incremental_load_result_event_kind,\n-                TimestampKind::End\n-            );\n-        }\n-    }\n+#[must_use]\n+pub struct TimingGuard<'a>(Option<TimingGuardInternal<'a>>);\n \n-    #[inline]\n-    pub fn query_blocked_start(&self, query_name: QueryName) {\n-        if self.event_filter_mask.contains(EventFilter::QUERY_BLOCKED) {\n-            self.record_query(query_name, self.query_blocked_event_kind, TimestampKind::Start);\n-        }\n-    }\n+struct TimingGuardInternal<'a> {\n+    raw_profiler: &'a Profiler,\n+    event_id: StringId,\n+    event_kind: StringId,\n+    thread_id: u64,\n+}\n \n+impl<'a> TimingGuard<'a> {\n     #[inline]\n-    pub fn query_blocked_end(&self, query_name: QueryName) {\n-        if self.event_filter_mask.contains(EventFilter::QUERY_BLOCKED) {\n-            self.record_query(query_name, self.query_blocked_event_kind, TimestampKind::End);\n-        }\n+    pub fn start(\n+        profiler: &'a SelfProfiler,\n+        event_kind: StringId,\n+        event_id: StringId,\n+    ) -> TimingGuard<'a> {\n+        let thread_id = thread_id_to_u64(std::thread::current().id());\n+        let raw_profiler = &profiler.profiler;\n+        raw_profiler.record_event(event_kind, event_id, thread_id, TimestampKind::Start);\n+\n+        TimingGuard(Some(TimingGuardInternal {\n+            raw_profiler,\n+            event_kind,\n+            event_id,\n+            thread_id,\n+        }))\n     }\n \n     #[inline]\n-    fn record(&self, event_id: &str, event_kind: StringId, timestamp_kind: TimestampKind) {\n-        let thread_id = thread_id_to_u64(std::thread::current().id());\n-\n-        let event_id = self.profiler.alloc_string(event_id);\n-        self.profiler.record_event(event_kind, event_id, thread_id, timestamp_kind);\n+    pub fn none() -> TimingGuard<'a> {\n+        TimingGuard(None)\n     }\n+}\n \n+impl<'a> Drop for TimingGuardInternal<'a> {\n     #[inline]\n-    fn record_query(\n-        &self,\n-        query_name: QueryName,\n-        event_kind: StringId,\n-        timestamp_kind: TimestampKind,\n-    ) {\n-        let dep_node_name = SelfProfiler::get_query_name_string_id(query_name);\n-\n-        let thread_id = thread_id_to_u64(std::thread::current().id());\n-\n-        self.profiler.record_event(event_kind, dep_node_name, thread_id, timestamp_kind);\n+    fn drop(&mut self) {\n+        self.raw_profiler.record_event(\n+            self.event_kind,\n+            self.event_id,\n+            self.thread_id,\n+            TimestampKind::End\n+        );\n     }\n }"}, {"sha": "4abb86a5251a5e997e915f1d904a0dbeaa9b72d4", "filename": "src/librustc_apfloat/ieee.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_apfloat%2Fieee.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_apfloat%2Fieee.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_apfloat%2Fieee.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1199,8 +1199,8 @@ impl<S: Semantics> Float for IeeeFloat<S> {\n         }\n \n         // Handle a leading minus sign.\n-        let minus = s.starts_with(\"-\");\n-        if minus || s.starts_with(\"+\") {\n+        let minus = s.starts_with('-');\n+        if minus || s.starts_with('+') {\n             s = &s[1..];\n             if s.is_empty() {\n                 return Err(ParseError(\"String has no digits\"));"}, {"sha": "c4368d2cb8b45df859f68b601512e617ae352702", "filename": "src/librustc_codegen_llvm/back/lto.rs", "status": "modified", "additions": 62, "deletions": 43, "changes": 105, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -62,11 +62,13 @@ fn prepare_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n     };\n     let exported_symbols = cgcx.exported_symbols\n         .as_ref().expect(\"needs exported symbols for LTO\");\n-    let mut symbol_white_list = exported_symbols[&LOCAL_CRATE]\n-        .iter()\n-        .filter_map(symbol_filter)\n-        .collect::<Vec<CString>>();\n-    let _timer = cgcx.profile_activity(\"generate_symbol_white_list_for_thinlto\");\n+    let mut symbol_white_list = {\n+        let _timer = cgcx.prof.generic_activity(\"LLVM_lto_generate_symbol_white_list\");\n+        exported_symbols[&LOCAL_CRATE]\n+            .iter()\n+            .filter_map(symbol_filter)\n+            .collect::<Vec<CString>>()\n+    };\n     info!(\"{} symbols to preserve in this crate\", symbol_white_list.len());\n \n     // If we're performing LTO for the entire crate graph, then for each of our\n@@ -95,14 +97,17 @@ fn prepare_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         }\n \n         for &(cnum, ref path) in cgcx.each_linked_rlib_for_lto.iter() {\n-            let _timer = cgcx.profile_activity(format!(\"load: {}\", path.display()));\n             let exported_symbols = cgcx.exported_symbols\n                 .as_ref().expect(\"needs exported symbols for LTO\");\n-            symbol_white_list.extend(\n-                exported_symbols[&cnum]\n-                    .iter()\n-                    .filter_map(symbol_filter));\n+            {\n+                let _timer = cgcx.prof.generic_activity(\"LLVM_lto_generate_symbol_white_list\");\n+                symbol_white_list.extend(\n+                    exported_symbols[&cnum]\n+                        .iter()\n+                        .filter_map(symbol_filter));\n+            }\n \n+            let _timer = cgcx.prof.generic_activity(\"LLVM_lto_load_upstream_bitcode\");\n             let archive = ArchiveRO::open(&path).expect(\"wanted an rlib\");\n             let bytecodes = archive.iter().filter_map(|child| {\n                 child.ok().and_then(|c| c.name().map(|name| (name, c)))\n@@ -189,6 +194,7 @@ fn fat_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n            symbol_white_list: &[*const libc::c_char])\n     -> Result<LtoModuleCodegen<LlvmCodegenBackend>, FatalError>\n {\n+    let _timer = cgcx.prof.generic_activity(\"LLVM_fat_lto_build_monolithic_module\");\n     info!(\"going for a fat lto\");\n \n     // Sort out all our lists of incoming modules into two lists.\n@@ -287,6 +293,7 @@ fn fat_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         // save and persist everything with the original module.\n         let mut linker = Linker::new(llmod);\n         for (bc_decoded, name) in serialized_modules {\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_fat_lto_link_module\");\n             info!(\"linking {:?}\", name);\n             time_ext(cgcx.time_passes, None, &format!(\"ll link {:?}\", name), || {\n                 let data = bc_decoded.data();\n@@ -388,6 +395,7 @@ fn thin_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             symbol_white_list: &[*const libc::c_char])\n     -> Result<(Vec<LtoModuleCodegen<LlvmCodegenBackend>>, Vec<WorkProduct>), FatalError>\n {\n+    let _timer = cgcx.prof.generic_activity(\"LLVM_thin_lto_global_analysis\");\n     unsafe {\n         info!(\"going for that thin, thin LTO\");\n \n@@ -601,16 +609,6 @@ impl ModuleBuffer {\n             llvm::LLVMRustModuleBufferCreate(m)\n         })\n     }\n-\n-    pub fn parse<'a>(\n-        &self,\n-        name: &str,\n-        cx: &'a llvm::Context,\n-        handler: &Handler,\n-    ) -> Result<&'a llvm::Module, FatalError> {\n-        let name = CString::new(name).unwrap();\n-        parse_module(cx, &name, self.data(), handler)\n-    }\n }\n \n impl ModuleBufferMethods for ModuleBuffer {\n@@ -723,7 +721,7 @@ pub unsafe fn optimize_thin_module(\n         // Like with \"fat\" LTO, get some better optimizations if landing pads\n         // are disabled by removing all landing pads.\n         if cgcx.no_landing_pads {\n-            let _timer = cgcx.profile_activity(\"LLVM_remove_landing_pads\");\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_thin_lto_remove_landing_pads\");\n             llvm::LLVMRustMarkAllFunctionsNounwind(llmod);\n             save_temp_bitcode(&cgcx, &module, \"thin-lto-after-nounwind\");\n         }\n@@ -736,26 +734,41 @@ pub unsafe fn optimize_thin_module(\n         //\n         // You can find some more comments about these functions in the LLVM\n         // bindings we've got (currently `PassWrapper.cpp`)\n-        if !llvm::LLVMRustPrepareThinLTORename(thin_module.shared.data.0, llmod) {\n-            let msg = \"failed to prepare thin LTO module\";\n-            return Err(write::llvm_err(&diag_handler, msg))\n+        {\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_thin_lto_rename\");\n+            if !llvm::LLVMRustPrepareThinLTORename(thin_module.shared.data.0, llmod) {\n+                let msg = \"failed to prepare thin LTO module\";\n+                return Err(write::llvm_err(&diag_handler, msg))\n+            }\n+            save_temp_bitcode(cgcx, &module, \"thin-lto-after-rename\");\n         }\n-        save_temp_bitcode(cgcx, &module, \"thin-lto-after-rename\");\n-        if !llvm::LLVMRustPrepareThinLTOResolveWeak(thin_module.shared.data.0, llmod) {\n-            let msg = \"failed to prepare thin LTO module\";\n-            return Err(write::llvm_err(&diag_handler, msg))\n+\n+        {\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_thin_lto_resolve_weak\");\n+            if !llvm::LLVMRustPrepareThinLTOResolveWeak(thin_module.shared.data.0, llmod) {\n+                let msg = \"failed to prepare thin LTO module\";\n+                return Err(write::llvm_err(&diag_handler, msg))\n+            }\n+            save_temp_bitcode(cgcx, &module, \"thin-lto-after-resolve\");\n         }\n-        save_temp_bitcode(cgcx, &module, \"thin-lto-after-resolve\");\n-        if !llvm::LLVMRustPrepareThinLTOInternalize(thin_module.shared.data.0, llmod) {\n-            let msg = \"failed to prepare thin LTO module\";\n-            return Err(write::llvm_err(&diag_handler, msg))\n+\n+        {\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_thin_lto_internalize\");\n+            if !llvm::LLVMRustPrepareThinLTOInternalize(thin_module.shared.data.0, llmod) {\n+                let msg = \"failed to prepare thin LTO module\";\n+                return Err(write::llvm_err(&diag_handler, msg))\n+            }\n+            save_temp_bitcode(cgcx, &module, \"thin-lto-after-internalize\");\n         }\n-        save_temp_bitcode(cgcx, &module, \"thin-lto-after-internalize\");\n-        if !llvm::LLVMRustPrepareThinLTOImport(thin_module.shared.data.0, llmod) {\n-            let msg = \"failed to prepare thin LTO module\";\n-            return Err(write::llvm_err(&diag_handler, msg))\n+\n+        {\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_thin_lto_import\");\n+            if !llvm::LLVMRustPrepareThinLTOImport(thin_module.shared.data.0, llmod) {\n+                let msg = \"failed to prepare thin LTO module\";\n+                return Err(write::llvm_err(&diag_handler, msg))\n+            }\n+            save_temp_bitcode(cgcx, &module, \"thin-lto-after-import\");\n         }\n-        save_temp_bitcode(cgcx, &module, \"thin-lto-after-import\");\n \n         // Ok now this is a bit unfortunate. This is also something you won't\n         // find upstream in LLVM's ThinLTO passes! This is a hack for now to\n@@ -786,18 +799,24 @@ pub unsafe fn optimize_thin_module(\n         // not too much) but for now at least gets LLVM to emit valid DWARF (or\n         // so it appears). Hopefully we can remove this once upstream bugs are\n         // fixed in LLVM.\n-        llvm::LLVMRustThinLTOPatchDICompileUnit(llmod, cu1);\n-        save_temp_bitcode(cgcx, &module, \"thin-lto-after-patch\");\n+        {\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_thin_lto_patch_debuginfo\");\n+            llvm::LLVMRustThinLTOPatchDICompileUnit(llmod, cu1);\n+            save_temp_bitcode(cgcx, &module, \"thin-lto-after-patch\");\n+        }\n \n         // Alright now that we've done everything related to the ThinLTO\n         // analysis it's time to run some optimizations! Here we use the same\n         // `run_pass_manager` as the \"fat\" LTO above except that we tell it to\n         // populate a thin-specific pass manager, which presumably LLVM treats a\n         // little differently.\n-        info!(\"running thin lto passes over {}\", module.name);\n-        let config = cgcx.config(module.kind);\n-        run_pass_manager(cgcx, &module, config, true);\n-        save_temp_bitcode(cgcx, &module, \"thin-lto-after-pm\");\n+        {\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_thin_lto_optimize\");\n+            info!(\"running thin lto passes over {}\", module.name);\n+            let config = cgcx.config(module.kind);\n+            run_pass_manager(cgcx, &module, config, true);\n+            save_temp_bitcode(cgcx, &module, \"thin-lto-after-pm\");\n+        }\n     }\n     Ok(module)\n }"}, {"sha": "78db90b57b53d4ed968ccd1f5e21d96a775be45c", "filename": "src/librustc_codegen_llvm/back/write.rs", "status": "modified", "additions": 14, "deletions": 11, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -306,6 +306,8 @@ pub(crate) unsafe fn optimize(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                    config: &ModuleConfig)\n     -> Result<(), FatalError>\n {\n+    let _timer = cgcx.prof.generic_activity(\"LLVM_module_optimize\");\n+\n     let llmod = module.module_llvm.llmod();\n     let llcx = &*module.module_llvm.llcx;\n     let tm = &*module.module_llvm.tm;\n@@ -423,7 +425,7 @@ pub(crate) unsafe fn optimize(cgcx: &CodegenContext<LlvmCodegenBackend>,\n \n         // Finally, run the actual optimization passes\n         {\n-            let _timer = cgcx.profile_activity(\"LLVM_function_passes\");\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_module_optimize_function_passes\");\n             time_ext(config.time_passes,\n                         None,\n                         &format!(\"llvm function passes [{}]\", module_name.unwrap()),\n@@ -432,7 +434,7 @@ pub(crate) unsafe fn optimize(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             });\n         }\n         {\n-            let _timer = cgcx.profile_activity(\"LLVM_module_passes\");\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_module_optimize_module_passes\");\n             time_ext(config.time_passes,\n                     None,\n                     &format!(\"llvm module passes [{}]\", module_name.unwrap()),\n@@ -454,7 +456,7 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                   config: &ModuleConfig)\n     -> Result<CompiledModule, FatalError>\n {\n-    let _timer = cgcx.profile_activity(\"codegen\");\n+    let _timer = cgcx.prof.generic_activity(\"LLVM_module_codegen\");\n     {\n         let llmod = module.module_llvm.llmod();\n         let llcx = &*module.module_llvm.llcx;\n@@ -505,25 +507,26 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n \n \n         if write_bc || config.emit_bc_compressed || config.embed_bitcode {\n-            let _timer = cgcx.profile_activity(\"LLVM_make_bitcode\");\n+            let _timer = cgcx.prof.generic_activity(\"LLVM_module_codegen_make_bitcode\");\n             let thin = ThinBuffer::new(llmod);\n             let data = thin.data();\n \n             if write_bc {\n-                let _timer = cgcx.profile_activity(\"LLVM_emit_bitcode\");\n+                let _timer = cgcx.prof.generic_activity(\"LLVM_module_codegen_emit_bitcode\");\n                 if let Err(e) = fs::write(&bc_out, data) {\n                     let msg = format!(\"failed to write bytecode to {}: {}\", bc_out.display(), e);\n                     diag_handler.err(&msg);\n                 }\n             }\n \n             if config.embed_bitcode {\n-                let _timer = cgcx.profile_activity(\"LLVM_embed_bitcode\");\n+                let _timer = cgcx.prof.generic_activity(\"LLVM_module_codegen_embed_bitcode\");\n                 embed_bitcode(cgcx, llcx, llmod, Some(data));\n             }\n \n             if config.emit_bc_compressed {\n-                let _timer = cgcx.profile_activity(\"LLVM_compress_bitcode\");\n+                let _timer =\n+                    cgcx.prof.generic_activity(\"LLVM_module_codegen_emit_compressed_bitcode\");\n                 let dst = bc_out.with_extension(RLIB_BYTECODE_EXTENSION);\n                 let data = bytecode::encode(&module.name, data);\n                 if let Err(e) = fs::write(&dst, data) {\n@@ -538,7 +541,7 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n         time_ext(config.time_passes, None, &format!(\"codegen passes [{}]\", module_name.unwrap()),\n             || -> Result<(), FatalError> {\n             if config.emit_ir {\n-                let _timer = cgcx.profile_activity(\"LLVM_emit_ir\");\n+                let _timer = cgcx.prof.generic_activity(\"LLVM_module_codegen_emit_ir\");\n                 let out = cgcx.output_filenames.temp_path(OutputType::LlvmAssembly, module_name);\n                 let out_c = path_to_c_string(&out);\n \n@@ -585,7 +588,7 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             }\n \n             if config.emit_asm || asm_to_obj {\n-                let _timer = cgcx.profile_activity(\"LLVM_emit_asm\");\n+                let _timer = cgcx.prof.generic_activity(\"LLVM_module_codegen_emit_asm\");\n                 let path = cgcx.output_filenames.temp_path(OutputType::Assembly, module_name);\n \n                 // We can't use the same module for asm and binary output, because that triggers\n@@ -603,13 +606,13 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             }\n \n             if write_obj {\n-                let _timer = cgcx.profile_activity(\"LLVM_emit_obj\");\n+                let _timer = cgcx.prof.generic_activity(\"LLVM_module_codegen_emit_obj\");\n                 with_codegen(tm, llmod, config.no_builtins, |cpm| {\n                     write_output_file(diag_handler, tm, cpm, llmod, &obj_out,\n                                       llvm::FileType::ObjectFile)\n                 })?;\n             } else if asm_to_obj {\n-                let _timer = cgcx.profile_activity(\"LLVM_asm_to_obj\");\n+                let _timer = cgcx.prof.generic_activity(\"LLVM_module_codegen_asm_to_obj\");\n                 let assembly = cgcx.output_filenames.temp_path(OutputType::Assembly, module_name);\n                 run_assembler(cgcx, diag_handler, &assembly, &obj_out);\n "}, {"sha": "bd7d0d4017dce471ca700efef316014b1e5aace6", "filename": "src/librustc_codegen_llvm/base.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_llvm%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_llvm%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fbase.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -108,6 +108,7 @@ pub fn compile_codegen_unit(\n     cgu_name: InternedString,\n     tx_to_llvm_workers: &std::sync::mpsc::Sender<Box<dyn std::any::Any + Send>>,\n ) {\n+    let prof_timer = tcx.prof.generic_activity(\"codegen_module\");\n     let start_time = Instant::now();\n \n     let dep_node = tcx.codegen_unit(cgu_name).codegen_dep_node(tcx);\n@@ -119,6 +120,7 @@ pub fn compile_codegen_unit(\n         dep_graph::hash_result,\n     );\n     let time_to_codegen = start_time.elapsed();\n+    drop(prof_timer);\n \n     // We assume that the cost to run LLVM on a CGU is proportional to\n     // the time we needed for codegenning it."}, {"sha": "87eab484fafc697bddefc47f6273e59bee5b11b5", "filename": "src/librustc_codegen_llvm/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_llvm%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_llvm%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Flib.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -324,8 +324,9 @@ impl CodegenBackend for LlvmCodegenBackend {\n \n         // Run the linker on any artifacts that resulted from the LLVM run.\n         // This should produce either a finished executable or library.\n-        sess.profiler(|p| p.start_activity(\"link_crate\"));\n         time(sess, \"linking\", || {\n+            let _prof_timer = sess.prof.generic_activity(\"link_crate\");\n+\n             use rustc_codegen_ssa::back::link::link_binary;\n             use crate::back::archive::LlvmArchiveBuilder;\n \n@@ -338,7 +339,6 @@ impl CodegenBackend for LlvmCodegenBackend {\n                 target_cpu,\n             );\n         });\n-        sess.profiler(|p| p.end_activity(\"link_crate\"));\n \n         // Now that we won't touch anything in the incremental compilation directory\n         // any more, we can finalize it (which involves renaming it)"}, {"sha": "f1cfac270332223d80d3a766bd22889208a934f2", "filename": "src/librustc_codegen_ssa/back/write.rs", "status": "modified", "additions": 11, "deletions": 67, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -19,7 +19,7 @@ use rustc::util::nodemap::FxHashMap;\n use rustc::hir::def_id::{CrateNum, LOCAL_CRATE};\n use rustc::ty::TyCtxt;\n use rustc::util::common::{time_depth, set_time_depth, print_time_passes_entry};\n-use rustc::util::profiling::SelfProfiler;\n+use rustc::util::profiling::SelfProfilerRef;\n use rustc_fs_util::link_or_copy;\n use rustc_data_structures::svh::Svh;\n use rustc_errors::{Handler, Level, FatalError, DiagnosticId};\n@@ -31,7 +31,6 @@ use syntax_pos::symbol::{Symbol, sym};\n use jobserver::{Client, Acquired};\n \n use std::any::Any;\n-use std::borrow::Cow;\n use std::fs;\n use std::io;\n use std::mem;\n@@ -196,42 +195,13 @@ impl<B: WriteBackendMethods> Clone for TargetMachineFactory<B> {\n     }\n }\n \n-pub struct ProfileGenericActivityTimer {\n-    profiler: Option<Arc<SelfProfiler>>,\n-    label: Cow<'static, str>,\n-}\n-\n-impl ProfileGenericActivityTimer {\n-    pub fn start(\n-        profiler: Option<Arc<SelfProfiler>>,\n-        label: Cow<'static, str>,\n-    ) -> ProfileGenericActivityTimer {\n-        if let Some(profiler) = &profiler {\n-            profiler.start_activity(label.clone());\n-        }\n-\n-        ProfileGenericActivityTimer {\n-            profiler,\n-            label,\n-        }\n-    }\n-}\n-\n-impl Drop for ProfileGenericActivityTimer {\n-    fn drop(&mut self) {\n-        if let Some(profiler) = &self.profiler {\n-            profiler.end_activity(self.label.clone());\n-        }\n-    }\n-}\n-\n /// Additional resources used by optimize_and_codegen (not module specific)\n #[derive(Clone)]\n pub struct CodegenContext<B: WriteBackendMethods> {\n     // Resources needed when running LTO\n     pub backend: B,\n     pub time_passes: bool,\n-    pub profiler: Option<Arc<SelfProfiler>>,\n+    pub prof: SelfProfilerRef,\n     pub lto: Lto,\n     pub no_landing_pads: bool,\n     pub save_temps: bool,\n@@ -283,31 +253,6 @@ impl<B: WriteBackendMethods> CodegenContext<B> {\n             ModuleKind::Allocator => &self.allocator_module_config,\n         }\n     }\n-\n-    #[inline(never)]\n-    #[cold]\n-    fn profiler_active<F: FnOnce(&SelfProfiler) -> ()>(&self, f: F) {\n-        match &self.profiler {\n-            None => bug!(\"profiler_active() called but there was no profiler active\"),\n-            Some(profiler) => {\n-                f(&*profiler);\n-            }\n-        }\n-    }\n-\n-    #[inline(always)]\n-    pub fn profile<F: FnOnce(&SelfProfiler) -> ()>(&self, f: F) {\n-        if unlikely!(self.profiler.is_some()) {\n-            self.profiler_active(f)\n-        }\n-    }\n-\n-    pub fn profile_activity(\n-        &self,\n-        label: impl Into<Cow<'static, str>>,\n-    ) -> ProfileGenericActivityTimer {\n-        ProfileGenericActivityTimer::start(self.profiler.clone(), label.into())\n-    }\n }\n \n fn generate_lto_work<B: ExtraBackendMethods>(\n@@ -316,7 +261,7 @@ fn generate_lto_work<B: ExtraBackendMethods>(\n     needs_thin_lto: Vec<(String, B::ThinBuffer)>,\n     import_only_modules: Vec<(SerializedModule<B::ModuleBuffer>, WorkProduct)>\n ) -> Vec<(WorkItem<B>, u64)> {\n-    cgcx.profile(|p| p.start_activity(\"codegen_run_lto\"));\n+    let _prof_timer = cgcx.prof.generic_activity(\"codegen_run_lto\");\n \n     let (lto_modules, copy_jobs) = if !needs_fat_lto.is_empty() {\n         assert!(needs_thin_lto.is_empty());\n@@ -343,8 +288,6 @@ fn generate_lto_work<B: ExtraBackendMethods>(\n         }), 0)\n     })).collect();\n \n-    cgcx.profile(|p| p.end_activity(\"codegen_run_lto\"));\n-\n     result\n }\n \n@@ -380,6 +323,9 @@ pub fn start_async_codegen<B: ExtraBackendMethods>(\n ) -> OngoingCodegen<B> {\n     let (coordinator_send, coordinator_receive) = channel();\n     let sess = tcx.sess;\n+\n+    sess.prof.generic_activity_start(\"codegen_and_optimize_crate\");\n+\n     let crate_name = tcx.crate_name(LOCAL_CRATE);\n     let crate_hash = tcx.crate_hash(LOCAL_CRATE);\n     let no_builtins = attr::contains_name(&tcx.hir().krate().attrs, sym::no_builtins);\n@@ -1088,7 +1034,7 @@ fn start_executing_work<B: ExtraBackendMethods>(\n         save_temps: sess.opts.cg.save_temps,\n         opts: Arc::new(sess.opts.clone()),\n         time_passes: sess.time_extended(),\n-        profiler: sess.self_profiling.clone(),\n+        prof: sess.prof.clone(),\n         exported_symbols,\n         plugin_passes: sess.plugin_llvm_passes.borrow().clone(),\n         remark: sess.opts.cg.remark.clone(),\n@@ -1645,12 +1591,8 @@ fn spawn_work<B: ExtraBackendMethods>(\n         // as a diagnostic was already sent off to the main thread - just\n         // surface that there was an error in this worker.\n         bomb.result = {\n-            let label = work.name();\n-            cgcx.profile(|p| p.start_activity(label.clone()));\n-            let result = execute_work_item(&cgcx, work).ok();\n-            cgcx.profile(|p| p.end_activity(label));\n-\n-            result\n+            let _prof_timer = cgcx.prof.generic_activity(&work.name());\n+            execute_work_item(&cgcx, work).ok()\n         };\n     });\n }\n@@ -1835,6 +1777,8 @@ impl<B: ExtraBackendMethods> OngoingCodegen<B> {\n             self.backend.print_pass_timings()\n         }\n \n+        sess.prof.generic_activity_end(\"codegen_and_optimize_crate\");\n+\n         (CodegenResults {\n             crate_name: self.crate_name,\n             crate_hash: self.crate_hash,"}, {"sha": "935087714a7ebb3b170b13f639cca83bbff43a58", "filename": "src/librustc_codegen_ssa/base.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_ssa%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_ssa%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fbase.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -559,7 +559,7 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n \n     if need_metadata_module {\n         // Codegen the encoded metadata.\n-        tcx.sess.profiler(|p| p.start_activity(\"codegen crate metadata\"));\n+        let _prof_timer = tcx.prof.generic_activity(\"codegen_crate_metadata\");\n \n         let metadata_cgu_name = cgu_name_builder.build_cgu_name(LOCAL_CRATE,\n                                                                 &[\"crate\"],\n@@ -570,7 +570,6 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n             backend.write_compressed_metadata(tcx, &ongoing_codegen.metadata,\n                                               &mut metadata_llvm_module);\n         });\n-        tcx.sess.profiler(|p| p.end_activity(\"codegen crate metadata\"));\n \n         let metadata_module = ModuleCodegen {\n             name: metadata_cgu_name,\n@@ -599,11 +598,9 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n \n         match cgu_reuse {\n             CguReuse::No => {\n-                tcx.sess.profiler(|p| p.start_activity(format!(\"codegen {}\", cgu.name())));\n                 let start_time = Instant::now();\n                 backend.compile_codegen_unit(tcx, *cgu.name(), &ongoing_codegen.coordinator_send);\n                 total_codegen_time += start_time.elapsed();\n-                tcx.sess.profiler(|p| p.end_activity(format!(\"codegen {}\", cgu.name())));\n                 false\n             }\n             CguReuse::PreLto => {"}, {"sha": "5017a60ca699a2cd83303bc2ac92dec92e85a6f4", "filename": "src/librustc_codegen_ssa/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_ssa%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_codegen_ssa%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Flib.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -21,7 +21,6 @@\n \n #[macro_use] extern crate log;\n #[macro_use] extern crate rustc;\n-#[macro_use] extern crate rustc_data_structures;\n #[macro_use] extern crate syntax;\n \n use std::path::PathBuf;"}, {"sha": "c438a8558a7045f375e3c9b3fd1c1556c63718bd", "filename": "src/librustc_data_structures/graph/implementation/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_data_structures%2Fgraph%2Fimplementation%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_data_structures%2Fgraph%2Fimplementation%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fgraph%2Fimplementation%2Fmod.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -303,11 +303,11 @@ pub struct AdjacentEdges<'g, N, E> {\n \n impl<'g, N: Debug, E: Debug> AdjacentEdges<'g, N, E> {\n     fn targets(self) -> impl Iterator<Item = NodeIndex> + 'g {\n-        self.into_iter().map(|(_, edge)| edge.target)\n+        self.map(|(_, edge)| edge.target)\n     }\n \n     fn sources(self) -> impl Iterator<Item = NodeIndex> + 'g {\n-        self.into_iter().map(|(_, edge)| edge.source)\n+        self.map(|(_, edge)| edge.source)\n     }\n }\n "}, {"sha": "958ab617cb315b71bf64e505da245d7f8b02f120", "filename": "src/librustc_data_structures/obligation_forest/mod.rs", "status": "modified", "additions": 94, "deletions": 119, "changes": 213, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_data_structures%2Fobligation_forest%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_data_structures%2Fobligation_forest%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fobligation_forest%2Fmod.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -151,9 +151,8 @@ pub struct ObligationForest<O: ForestObligation> {\n     /// comments in `process_obligation` for details.\n     active_cache: FxHashMap<O::Predicate, usize>,\n \n-    /// A scratch vector reused in various operations, to avoid allocating new\n-    /// vectors.\n-    scratch: RefCell<Vec<usize>>,\n+    /// A vector reused in compress(), to avoid allocating new vectors.\n+    node_rewrites: RefCell<Vec<usize>>,\n \n     obligation_tree_id_generator: ObligationTreeIdGenerator,\n \n@@ -235,10 +234,6 @@ enum NodeState {\n     /// This obligation was resolved to an error. Error nodes are\n     /// removed from the vector by the compression step.\n     Error,\n-\n-    /// This is a temporary state used in DFS loops to detect cycles,\n-    /// it should not exist outside of these DFSes.\n-    OnDfsStack,\n }\n \n #[derive(Debug)]\n@@ -279,7 +274,7 @@ impl<O: ForestObligation> ObligationForest<O> {\n             nodes: vec![],\n             done_cache: Default::default(),\n             active_cache: Default::default(),\n-            scratch: RefCell::new(vec![]),\n+            node_rewrites: RefCell::new(vec![]),\n             obligation_tree_id_generator: (0..).map(ObligationTreeId),\n             error_cache: Default::default(),\n         }\n@@ -305,9 +300,10 @@ impl<O: ForestObligation> ObligationForest<O> {\n \n         match self.active_cache.entry(obligation.as_predicate().clone()) {\n             Entry::Occupied(o) => {\n+                let index = *o.get();\n                 debug!(\"register_obligation_at({:?}, {:?}) - duplicate of {:?}!\",\n-                       obligation, parent, o.get());\n-                let node = &mut self.nodes[*o.get()];\n+                       obligation, parent, index);\n+                let node = &mut self.nodes[index];\n                 if let Some(parent_index) = parent {\n                     // If the node is already in `active_cache`, it has already\n                     // had its chance to be marked with a parent. So if it's\n@@ -342,7 +338,8 @@ impl<O: ForestObligation> ObligationForest<O> {\n                 if already_failed {\n                     Err(())\n                 } else {\n-                    v.insert(self.nodes.len());\n+                    let new_index = self.nodes.len();\n+                    v.insert(new_index);\n                     self.nodes.push(Node::new(parent, obligation, obligation_tree_id));\n                     Ok(())\n                 }\n@@ -352,15 +349,16 @@ impl<O: ForestObligation> ObligationForest<O> {\n \n     /// Converts all remaining obligations to the given error.\n     pub fn to_errors<E: Clone>(&mut self, error: E) -> Vec<Error<O, E>> {\n-        let mut errors = vec![];\n-        for (index, node) in self.nodes.iter().enumerate() {\n-            if let NodeState::Pending = node.state.get() {\n-                errors.push(Error {\n+        let errors = self.nodes.iter().enumerate()\n+            .filter(|(_index, node)| node.state.get() == NodeState::Pending)\n+            .map(|(index, _node)| {\n+                Error {\n                     error: error.clone(),\n                     backtrace: self.error_at(index),\n-                });\n-            }\n-        }\n+                }\n+            })\n+            .collect();\n+\n         let successful_obligations = self.compress(DoCompleted::Yes);\n         assert!(successful_obligations.unwrap().is_empty());\n         errors\n@@ -370,15 +368,14 @@ impl<O: ForestObligation> ObligationForest<O> {\n     pub fn map_pending_obligations<P, F>(&self, f: F) -> Vec<P>\n         where F: Fn(&O) -> P\n     {\n-        self.nodes\n-            .iter()\n-            .filter(|n| n.state.get() == NodeState::Pending)\n-            .map(|n| f(&n.obligation))\n+        self.nodes.iter()\n+            .filter(|node| node.state.get() == NodeState::Pending)\n+            .map(|node| f(&node.obligation))\n             .collect()\n     }\n \n-    fn insert_into_error_cache(&mut self, node_index: usize) {\n-        let node = &self.nodes[node_index];\n+    fn insert_into_error_cache(&mut self, index: usize) {\n+        let node = &self.nodes[index];\n         self.error_cache\n             .entry(node.obligation_tree_id)\n             .or_default()\n@@ -408,10 +405,10 @@ impl<O: ForestObligation> ObligationForest<O> {\n             // `self.active_cache`. This means that `self.active_cache` can get\n             // out of sync with `nodes`. It's not very common, but it does\n             // happen, and code in `compress` has to allow for it.\n-            let result = match node.state.get() {\n-                NodeState::Pending => processor.process_obligation(&mut node.obligation),\n-                _ => continue\n-            };\n+            if node.state.get() != NodeState::Pending {\n+                continue;\n+            }\n+            let result = processor.process_obligation(&mut node.obligation);\n \n             debug!(\"process_obligations: node {} got result {:?}\", index, result);\n \n@@ -476,64 +473,53 @@ impl<O: ForestObligation> ObligationForest<O> {\n     fn process_cycles<P>(&self, processor: &mut P)\n         where P: ObligationProcessor<Obligation=O>\n     {\n-        let mut stack = self.scratch.replace(vec![]);\n-        debug_assert!(stack.is_empty());\n+        let mut stack = vec![];\n \n         debug!(\"process_cycles()\");\n \n         for (index, node) in self.nodes.iter().enumerate() {\n             // For some benchmarks this state test is extremely\n             // hot. It's a win to handle the no-op cases immediately to avoid\n             // the cost of the function call.\n-            match node.state.get() {\n-                // Match arms are in order of frequency. Pending, Success and\n-                // Waiting dominate; the others are rare.\n-                NodeState::Pending => {},\n-                NodeState::Success => self.find_cycles_from_node(&mut stack, processor, index),\n-                NodeState::Waiting | NodeState::Done | NodeState::Error => {},\n-                NodeState::OnDfsStack => self.find_cycles_from_node(&mut stack, processor, index),\n+            if node.state.get() == NodeState::Success {\n+                self.find_cycles_from_node(&mut stack, processor, index);\n             }\n         }\n \n         debug!(\"process_cycles: complete\");\n \n         debug_assert!(stack.is_empty());\n-        self.scratch.replace(stack);\n     }\n \n     fn find_cycles_from_node<P>(&self, stack: &mut Vec<usize>, processor: &mut P, index: usize)\n         where P: ObligationProcessor<Obligation=O>\n     {\n         let node = &self.nodes[index];\n-        match node.state.get() {\n-            NodeState::OnDfsStack => {\n-                let rpos = stack.iter().rposition(|&n| n == index).unwrap();\n-                processor.process_backedge(stack[rpos..].iter().map(GetObligation(&self.nodes)),\n-                                           PhantomData);\n-            }\n-            NodeState::Success => {\n-                node.state.set(NodeState::OnDfsStack);\n-                stack.push(index);\n-                for &index in node.dependents.iter() {\n-                    self.find_cycles_from_node(stack, processor, index);\n+        if node.state.get() == NodeState::Success {\n+            match stack.iter().rposition(|&n| n == index) {\n+                None => {\n+                    stack.push(index);\n+                    for &index in node.dependents.iter() {\n+                        self.find_cycles_from_node(stack, processor, index);\n+                    }\n+                    stack.pop();\n+                    node.state.set(NodeState::Done);\n+                }\n+                Some(rpos) => {\n+                    // Cycle detected.\n+                    processor.process_backedge(\n+                        stack[rpos..].iter().map(GetObligation(&self.nodes)),\n+                        PhantomData\n+                    );\n                 }\n-                stack.pop();\n-                node.state.set(NodeState::Done);\n-            },\n-            NodeState::Waiting | NodeState::Pending => {\n-                // This node is still reachable from some pending node. We\n-                // will get to it when they are all processed.\n-            }\n-            NodeState::Done | NodeState::Error => {\n-                // Already processed that node.\n             }\n-        };\n+        }\n     }\n \n     /// Returns a vector of obligations for `p` and all of its\n     /// ancestors, putting them into the error state in the process.\n     fn error_at(&self, mut index: usize) -> Vec<O> {\n-        let mut error_stack = self.scratch.replace(vec![]);\n+        let mut error_stack: Vec<usize> = vec![];\n         let mut trace = vec![];\n \n         loop {\n@@ -554,23 +540,32 @@ impl<O: ForestObligation> ObligationForest<O> {\n \n         while let Some(index) = error_stack.pop() {\n             let node = &self.nodes[index];\n-            match node.state.get() {\n-                NodeState::Error => continue,\n-                _ => node.state.set(NodeState::Error),\n+            if node.state.get() != NodeState::Error {\n+                node.state.set(NodeState::Error);\n+                error_stack.extend(node.dependents.iter());\n             }\n-\n-            error_stack.extend(node.dependents.iter());\n         }\n \n-        self.scratch.replace(error_stack);\n         trace\n     }\n \n     // This always-inlined function is for the hot call site.\n     #[inline(always)]\n     fn inlined_mark_neighbors_as_waiting_from(&self, node: &Node<O>) {\n         for &index in node.dependents.iter() {\n-            self.mark_as_waiting_from(&self.nodes[index]);\n+            let node = &self.nodes[index];\n+            match node.state.get() {\n+                NodeState::Waiting | NodeState::Error => {}\n+                NodeState::Success => {\n+                    node.state.set(NodeState::Waiting);\n+                    // This call site is cold.\n+                    self.uninlined_mark_neighbors_as_waiting_from(node);\n+                }\n+                NodeState::Pending | NodeState::Done => {\n+                    // This call site is cold.\n+                    self.uninlined_mark_neighbors_as_waiting_from(node);\n+                }\n+            }\n         }\n     }\n \n@@ -596,37 +591,28 @@ impl<O: ForestObligation> ObligationForest<O> {\n         }\n     }\n \n-    fn mark_as_waiting_from(&self, node: &Node<O>) {\n-        match node.state.get() {\n-            NodeState::Waiting | NodeState::Error | NodeState::OnDfsStack => return,\n-            NodeState::Success => node.state.set(NodeState::Waiting),\n-            NodeState::Pending | NodeState::Done => {},\n-        }\n-\n-        // This call site is cold.\n-        self.uninlined_mark_neighbors_as_waiting_from(node);\n-    }\n-\n-    /// Compresses the vector, removing all popped nodes. This adjusts\n-    /// the indices and hence invalidates any outstanding\n-    /// indices. Cannot be used during a transaction.\n+    /// Compresses the vector, removing all popped nodes. This adjusts the\n+    /// indices and hence invalidates any outstanding indices.\n     ///\n     /// Beforehand, all nodes must be marked as `Done` and no cycles\n     /// on these nodes may be present. This is done by e.g., `process_cycles`.\n     #[inline(never)]\n     fn compress(&mut self, do_completed: DoCompleted) -> Option<Vec<O>> {\n-        let nodes_len = self.nodes.len();\n-        let mut node_rewrites: Vec<_> = self.scratch.replace(vec![]);\n-        node_rewrites.extend(0..nodes_len);\n+        let orig_nodes_len = self.nodes.len();\n+        let mut node_rewrites: Vec<_> = self.node_rewrites.replace(vec![]);\n+        debug_assert!(node_rewrites.is_empty());\n+        node_rewrites.extend(0..orig_nodes_len);\n         let mut dead_nodes = 0;\n+        let mut removed_done_obligations: Vec<O> = vec![];\n \n-        // Now move all popped nodes to the end. Try to keep the order.\n+        // Now move all Done/Error nodes to the end, preserving the order of\n+        // the Pending/Waiting nodes.\n         //\n         // LOOP INVARIANT:\n         //     self.nodes[0..index - dead_nodes] are the first remaining nodes\n         //     self.nodes[index - dead_nodes..index] are all dead\n         //     self.nodes[index..] are unchanged\n-        for index in 0..self.nodes.len() {\n+        for index in 0..orig_nodes_len {\n             let node = &self.nodes[index];\n             match node.state.get() {\n                 NodeState::Pending | NodeState::Waiting => {\n@@ -637,7 +623,7 @@ impl<O: ForestObligation> ObligationForest<O> {\n                 }\n                 NodeState::Done => {\n                     // This lookup can fail because the contents of\n-                    // `self.active_cache` is not guaranteed to match those of\n+                    // `self.active_cache` are not guaranteed to match those of\n                     // `self.nodes`. See the comment in `process_obligation`\n                     // for more details.\n                     if let Some((predicate, _)) =\n@@ -647,61 +633,50 @@ impl<O: ForestObligation> ObligationForest<O> {\n                     } else {\n                         self.done_cache.insert(node.obligation.as_predicate().clone());\n                     }\n-                    node_rewrites[index] = nodes_len;\n+                    if do_completed == DoCompleted::Yes {\n+                        // Extract the success stories.\n+                        removed_done_obligations.push(node.obligation.clone());\n+                    }\n+                    node_rewrites[index] = orig_nodes_len;\n                     dead_nodes += 1;\n                 }\n                 NodeState::Error => {\n                     // We *intentionally* remove the node from the cache at this point. Otherwise\n                     // tests must come up with a different type on every type error they\n                     // check against.\n                     self.active_cache.remove(node.obligation.as_predicate());\n-                    node_rewrites[index] = nodes_len;\n-                    dead_nodes += 1;\n                     self.insert_into_error_cache(index);\n+                    node_rewrites[index] = orig_nodes_len;\n+                    dead_nodes += 1;\n                 }\n-                NodeState::OnDfsStack | NodeState::Success => unreachable!()\n+                NodeState::Success => unreachable!()\n             }\n         }\n \n-        // No compression needed.\n-        if dead_nodes == 0 {\n-            node_rewrites.truncate(0);\n-            self.scratch.replace(node_rewrites);\n-            return if do_completed == DoCompleted::Yes { Some(vec![]) } else { None };\n+        if dead_nodes > 0 {\n+            // Remove the dead nodes and rewrite indices.\n+            self.nodes.truncate(orig_nodes_len - dead_nodes);\n+            self.apply_rewrites(&node_rewrites);\n         }\n \n-        // Pop off all the nodes we killed and extract the success stories.\n-        let successful = if do_completed == DoCompleted::Yes {\n-            Some((0..dead_nodes)\n-                .map(|_| self.nodes.pop().unwrap())\n-                .flat_map(|node| {\n-                    match node.state.get() {\n-                        NodeState::Error => None,\n-                        NodeState::Done => Some(node.obligation),\n-                        _ => unreachable!()\n-                    }\n-                })\n-                .collect())\n-        } else {\n-            self.nodes.truncate(self.nodes.len() - dead_nodes);\n-            None\n-        };\n-        self.apply_rewrites(&node_rewrites);\n-\n         node_rewrites.truncate(0);\n-        self.scratch.replace(node_rewrites);\n+        self.node_rewrites.replace(node_rewrites);\n \n-        successful\n+        if do_completed == DoCompleted::Yes {\n+            Some(removed_done_obligations)\n+        } else {\n+            None\n+        }\n     }\n \n     fn apply_rewrites(&mut self, node_rewrites: &[usize]) {\n-        let nodes_len = node_rewrites.len();\n+        let orig_nodes_len = node_rewrites.len();\n \n         for node in &mut self.nodes {\n             let mut i = 0;\n             while i < node.dependents.len() {\n                 let new_index = node_rewrites[node.dependents[i]];\n-                if new_index >= nodes_len {\n+                if new_index >= orig_nodes_len {\n                     node.dependents.swap_remove(i);\n                     if i == 0 && node.has_parent {\n                         // We just removed the parent.\n@@ -718,7 +693,7 @@ impl<O: ForestObligation> ObligationForest<O> {\n         // removal of nodes within `compress` can fail. See above.\n         self.active_cache.retain(|_predicate, index| {\n             let new_index = node_rewrites[*index];\n-            if new_index >= nodes_len {\n+            if new_index >= orig_nodes_len {\n                 false\n             } else {\n                 *index = new_index;"}, {"sha": "54b6f6d0adc6cd2a1b01400263e075faeef6347a", "filename": "src/librustc_data_structures/obligation_forest/tests.rs", "status": "modified", "additions": 21, "deletions": 7, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_data_structures%2Fobligation_forest%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_data_structures%2Fobligation_forest%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fobligation_forest%2Ftests.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -116,7 +116,9 @@ fn push_pop() {\n                 _ => unreachable!(),\n             }\n         }, |_| {}), DoCompleted::Yes);\n-    assert_eq!(ok.unwrap(), vec![\"A.3\", \"A.1\", \"A.3.i\"]);\n+    let mut ok = ok.unwrap();\n+    ok.sort();\n+    assert_eq!(ok, vec![\"A.1\", \"A.3\", \"A.3.i\"]);\n     assert_eq!(err,\n                vec![Error {\n                         error: \"A is for apple\",\n@@ -132,7 +134,9 @@ fn push_pop() {\n                 _ => panic!(\"unexpected obligation {:?}\", obligation),\n             }\n         }, |_| {}), DoCompleted::Yes);\n-    assert_eq!(ok.unwrap(), vec![\"D.2.i\", \"D.2\"]);\n+    let mut ok = ok.unwrap();\n+    ok.sort();\n+    assert_eq!(ok, vec![\"D.2\", \"D.2.i\"]);\n     assert_eq!(err,\n                vec![Error {\n                         error: \"D is for dumb\",\n@@ -172,7 +176,9 @@ fn success_in_grandchildren() {\n                 _ => unreachable!(),\n             }\n         }, |_| {}), DoCompleted::Yes);\n-    assert_eq!(ok.unwrap(), vec![\"A.3\", \"A.1\"]);\n+    let mut ok = ok.unwrap();\n+    ok.sort();\n+    assert_eq!(ok, vec![\"A.1\", \"A.3\"]);\n     assert!(err.is_empty());\n \n     let Outcome { completed: ok, errors: err, .. } =\n@@ -193,7 +199,9 @@ fn success_in_grandchildren() {\n                 _ => unreachable!(),\n             }\n         }, |_| {}), DoCompleted::Yes);\n-    assert_eq!(ok.unwrap(), vec![\"A.2.i.a\", \"A.2.i\", \"A.2\", \"A\"]);\n+    let mut ok = ok.unwrap();\n+    ok.sort();\n+    assert_eq!(ok, vec![\"A\", \"A.2\", \"A.2.i\", \"A.2.i.a\"]);\n     assert!(err.is_empty());\n \n     let Outcome { completed: ok, errors: err, .. } =\n@@ -261,7 +269,9 @@ fn diamond() {\n             }\n         }, |_|{}), DoCompleted::Yes);\n     assert_eq!(d_count, 1);\n-    assert_eq!(ok.unwrap(), vec![\"D\", \"A.2\", \"A.1\", \"A\"]);\n+    let mut ok = ok.unwrap();\n+    ok.sort();\n+    assert_eq!(ok, vec![\"A\", \"A.1\", \"A.2\", \"D\"]);\n     assert_eq!(err.len(), 0);\n \n     let errors = forest.to_errors(());\n@@ -323,7 +333,9 @@ fn done_dependency() {\n                 _ => unreachable!(),\n             }\n         }, |_|{}), DoCompleted::Yes);\n-    assert_eq!(ok.unwrap(), vec![\"C: Sized\", \"B: Sized\", \"A: Sized\"]);\n+    let mut ok = ok.unwrap();\n+    ok.sort();\n+    assert_eq!(ok, vec![\"A: Sized\", \"B: Sized\", \"C: Sized\"]);\n     assert_eq!(err.len(), 0);\n \n     forest.register_obligation(\"(A,B,C): Sized\");\n@@ -361,7 +373,9 @@ fn orphan() {\n                 _ => unreachable!(),\n             }\n         }, |_|{}), DoCompleted::Yes);\n-    assert_eq!(ok.unwrap(), vec![\"C2\", \"C1\"]);\n+    let mut ok = ok.unwrap();\n+    ok.sort();\n+    assert_eq!(ok, vec![\"C1\", \"C2\"]);\n     assert_eq!(err.len(), 0);\n \n     let Outcome { completed: ok, errors: err, .. } ="}, {"sha": "f9dc13ce97eea79c6fed0db0a275736922038518", "filename": "src/librustc_errors/lib.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_errors%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_errors%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_errors%2Flib.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -469,14 +469,17 @@ impl Handler {\n     /// NOTE: *do not* call this function from rustc. It is only meant to be called from external\n     /// tools that want to reuse a `Parser` cleaning the previously emitted diagnostics as well as\n     /// the overall count of emitted error diagnostics.\n-    // FIXME: this does not clear inner entirely\n     pub fn reset_err_count(&self) {\n         let mut inner = self.inner.borrow_mut();\n-        // actually frees the underlying memory (which `clear` would not do)\n-        inner.emitted_diagnostics = Default::default();\n-        inner.deduplicated_err_count = 0;\n         inner.err_count = 0;\n-        inner.stashed_diagnostics.clear();\n+        inner.deduplicated_err_count = 0;\n+\n+        // actually free the underlying memory (which `clear` would not do)\n+        inner.delayed_span_bugs = Default::default();\n+        inner.taught_diagnostics = Default::default();\n+        inner.emitted_diagnostic_codes = Default::default();\n+        inner.emitted_diagnostics = Default::default();\n+        inner.stashed_diagnostics = Default::default();\n     }\n \n     /// Stash a given diagnostic with the given `Span` and `StashKey` as the key for later stealing."}, {"sha": "6af065513ee0dccf9f6f00343ea1a491bb335bb5", "filename": "src/librustc_incremental/persist/save.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -28,6 +28,8 @@ pub fn save_dep_graph(tcx: TyCtxt<'_>) {\n \n         join(move || {\n             if tcx.sess.opts.debugging_opts.incremental_queries {\n+                let _timer = tcx.prof.generic_activity(\"incr_comp_persist_result_cache\");\n+\n                 time(sess, \"persist query result cache\", || {\n                     save_in(sess,\n                             query_cache_path,\n@@ -36,6 +38,8 @@ pub fn save_dep_graph(tcx: TyCtxt<'_>) {\n             }\n         }, || {\n             time(sess, \"persist dep-graph\", || {\n+                let _timer = tcx.prof.generic_activity(\"incr_comp_persist_dep_graph\");\n+\n                 save_in(sess,\n                         dep_graph_path,\n                         |e| {\n@@ -135,6 +139,7 @@ fn encode_dep_graph(tcx: TyCtxt<'_>, encoder: &mut Encoder) {\n \n     // Encode the graph data.\n     let serialized_graph = time(tcx.sess, \"getting serialized graph\", || {\n+        let _timer = tcx.prof.generic_activity(\"incr_comp_serialize_dep_graph\");\n         tcx.dep_graph.serialize()\n     });\n \n@@ -214,6 +219,7 @@ fn encode_dep_graph(tcx: TyCtxt<'_>, encoder: &mut Encoder) {\n     }\n \n     time(tcx.sess, \"encoding serialized graph\", || {\n+        let _timer = tcx.prof.generic_activity(\"incr_comp_encode_serialized_dep_graph\");\n         serialized_graph.encode(encoder).unwrap();\n     });\n }"}, {"sha": "8c49e0dde0dcd3729468d4fa4a8e23f3f1a82db6", "filename": "src/librustc_index/bit_set.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_index%2Fbit_set.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_index%2Fbit_set.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_index%2Fbit_set.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -621,7 +621,7 @@ impl<'a, T: Idx> Iterator for HybridIter<'a, T> {\n \n     fn next(&mut self) -> Option<T> {\n         match self {\n-            HybridIter::Sparse(sparse) => sparse.next().map(|e| *e),\n+            HybridIter::Sparse(sparse) => sparse.next().copied(),\n             HybridIter::Dense(dense) => dense.next(),\n         }\n     }"}, {"sha": "dae8fb242d58cd69cada05ce9ed638480bcfd3d7", "filename": "src/librustc_interface/interface.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_interface%2Finterface.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_interface%2Finterface.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Finterface.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -147,5 +147,8 @@ where\n     F: FnOnce() -> R + Send,\n     R: Send,\n {\n-    util::spawn_thread_pool(edition, None, &None, f)\n+    // the 1 here is duplicating code in config.opts.debugging_opts.threads\n+    // which also defaults to 1; it ultimately doesn't matter as the default\n+    // isn't threaded, and just ignores this parameter\n+    util::spawn_thread_pool(edition, 1, &None, f)\n }"}, {"sha": "0055e0a8b2e880b335b2cb845bf009f6fc2c5e18", "filename": "src/librustc_interface/passes.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_interface%2Fpasses.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_interface%2Fpasses.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Fpasses.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -59,15 +59,17 @@ use std::rc::Rc;\n pub fn parse<'a>(sess: &'a Session, input: &Input) -> PResult<'a, ast::Crate> {\n     sess.diagnostic()\n         .set_continue_after_error(sess.opts.debugging_opts.continue_parse_after_error);\n-    sess.profiler(|p| p.start_activity(\"parsing\"));\n-    let krate = time(sess, \"parsing\", || match *input {\n-        Input::File(ref file) => parse::parse_crate_from_file(file, &sess.parse_sess),\n-        Input::Str {\n-            ref input,\n-            ref name,\n-        } => parse::parse_crate_from_source_str(name.clone(), input.clone(), &sess.parse_sess),\n+    let krate = time(sess, \"parsing\", || {\n+        let _prof_timer = sess.prof.generic_activity(\"parse_crate\");\n+\n+        match *input {\n+            Input::File(ref file) => parse::parse_crate_from_file(file, &sess.parse_sess),\n+            Input::Str {\n+                ref input,\n+                ref name,\n+            } => parse::parse_crate_from_source_str(name.clone(), input.clone(), &sess.parse_sess),\n+        }\n     })?;\n-    sess.profiler(|p| p.end_activity(\"parsing\"));\n \n     sess.diagnostic().set_continue_after_error(true);\n \n@@ -355,8 +357,8 @@ fn configure_and_expand_inner<'a>(\n     );\n \n     // Expand all macros\n-    sess.profiler(|p| p.start_activity(\"macro expansion\"));\n     krate = time(sess, \"expansion\", || {\n+        let _prof_timer = sess.prof.generic_activity(\"macro_expand_crate\");\n         // Windows dlls do not have rpaths, so they don't know how to find their\n         // dependencies. It's up to us to tell the system where to find all the\n         // dependent dlls. Note that this uses cfg!(windows) as opposed to\n@@ -430,7 +432,6 @@ fn configure_and_expand_inner<'a>(\n         }\n         krate\n     });\n-    sess.profiler(|p| p.end_activity(\"macro expansion\"));\n \n     time(sess, \"maybe building test harness\", || {\n         syntax_ext::test_harness::inject(\n@@ -1071,11 +1072,10 @@ pub fn start_codegen<'tcx>(\n         encode_and_write_metadata(tcx, outputs)\n     });\n \n-    tcx.sess.profiler(|p| p.start_activity(\"codegen crate\"));\n     let codegen = time(tcx.sess, \"codegen\", move || {\n+        let _prof_timer = tcx.prof.generic_activity(\"codegen_crate\");\n         codegen_backend.codegen_crate(tcx, metadata, need_metadata_module)\n     });\n-    tcx.sess.profiler(|p| p.end_activity(\"codegen crate\"));\n \n     if log_enabled!(::log::Level::Info) {\n         println!(\"Post-codegen\");"}, {"sha": "b05bad554f406e803213e4c0fbb134411601dfa2", "filename": "src/librustc_interface/util.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_interface%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_interface%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Futil.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -173,7 +173,7 @@ pub fn scoped_thread<F: FnOnce() -> R + Send, R: Send>(cfg: thread::Builder, f:\n #[cfg(not(parallel_compiler))]\n pub fn spawn_thread_pool<F: FnOnce() -> R + Send, R: Send>(\n     edition: Edition,\n-    _threads: Option<usize>,\n+    _threads: usize,\n     stderr: &Option<Arc<Mutex<Vec<u8>>>>,\n     f: F,\n ) -> R {\n@@ -198,7 +198,7 @@ pub fn spawn_thread_pool<F: FnOnce() -> R + Send, R: Send>(\n #[cfg(parallel_compiler)]\n pub fn spawn_thread_pool<F: FnOnce() -> R + Send, R: Send>(\n     edition: Edition,\n-    threads: Option<usize>,\n+    threads: usize,\n     stderr: &Option<Arc<Mutex<Vec<u8>>>>,\n     f: F,\n ) -> R {\n@@ -209,7 +209,7 @@ pub fn spawn_thread_pool<F: FnOnce() -> R + Send, R: Send>(\n     let mut config = ThreadPoolBuilder::new()\n         .acquire_thread_handler(jobserver::acquire_thread)\n         .release_thread_handler(jobserver::release_thread)\n-        .num_threads(Session::threads_from_count(threads))\n+        .num_threads(threads)\n         .deadlock_handler(|| unsafe { ty::query::handle_deadlock() });\n \n     if let Some(size) = get_stack_size() {"}, {"sha": "502da588d19a261f1479709848759b771877aeb7", "filename": "src/librustc_mir/borrow_check/nll/region_infer/error_reporting/mod.rs", "status": "modified", "additions": 21, "deletions": 18, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Ferror_reporting%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Ferror_reporting%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fborrow_check%2Fnll%2Fregion_infer%2Ferror_reporting%2Fmod.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1,5 +1,4 @@\n use crate::borrow_check::nll::constraints::OutlivesConstraint;\n-use crate::borrow_check::nll::region_infer::AppliedMemberConstraint;\n use crate::borrow_check::nll::region_infer::RegionInferenceContext;\n use crate::borrow_check::nll::type_check::Locations;\n use crate::borrow_check::nll::universal_regions::DefiningTy;\n@@ -253,29 +252,33 @@ impl<'tcx> RegionInferenceContext<'tcx> {\n             let outgoing_edges_from_graph = self.constraint_graph\n                 .outgoing_edges(r, &self.constraints, fr_static);\n \n-\n-            // But member constraints can also give rise to `'r: 'x`\n-            // edges that were not part of the graph initially, so\n-            // watch out for those.\n-            let outgoing_edges_from_picks = self.applied_member_constraints(r)\n-                .iter()\n-                .map(|&AppliedMemberConstraint { min_choice, member_constraint_index, .. }| {\n-                    let p_c = &self.member_constraints[member_constraint_index];\n-                    OutlivesConstraint {\n-                        sup: r,\n-                        sub: min_choice,\n-                        locations: Locations::All(p_c.definition_span),\n-                        category: ConstraintCategory::OpaqueType,\n-                    }\n-                });\n-\n-            for constraint in outgoing_edges_from_graph.chain(outgoing_edges_from_picks) {\n+            // Always inline this closure because it can be hot.\n+            let mut handle_constraint = #[inline(always)] |constraint: OutlivesConstraint| {\n                 debug_assert_eq!(constraint.sup, r);\n                 let sub_region = constraint.sub;\n                 if let Trace::NotVisited = context[sub_region] {\n                     context[sub_region] = Trace::FromOutlivesConstraint(constraint);\n                     deque.push_back(sub_region);\n                 }\n+            };\n+\n+            // This loop can be hot.\n+            for constraint in outgoing_edges_from_graph {\n+                handle_constraint(constraint);\n+            }\n+\n+            // Member constraints can also give rise to `'r: 'x` edges that\n+            // were not part of the graph initially, so watch out for those.\n+            // (But they are extremely rare; this loop is very cold.)\n+            for constraint in self.applied_member_constraints(r) {\n+                let p_c = &self.member_constraints[constraint.member_constraint_index];\n+                let constraint = OutlivesConstraint {\n+                    sup: r,\n+                    sub: constraint.min_choice,\n+                    locations: Locations::All(p_c.definition_span),\n+                    category: ConstraintCategory::OpaqueType,\n+                };\n+                handle_constraint(constraint);\n             }\n         }\n "}, {"sha": "47ace8f33ecacecea50a6b8035c5fc39a03e55bd", "filename": "src/librustc_mir/dataflow/generic/graphviz.rs", "status": "modified", "additions": 20, "deletions": 19, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_mir%2Fdataflow%2Fgeneric%2Fgraphviz.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_mir%2Fdataflow%2Fgeneric%2Fgraphviz.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fdataflow%2Fgeneric%2Fgraphviz.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -165,25 +165,25 @@ where\n         block: BasicBlock,\n     ) -> io::Result<()> {\n         //   Sample output:\n-        //   +-+--------------------------------------------------+\n-        // A |                         bb4                        |\n-        //   +-+----------------------------------+---------------+\n-        // B |               MIR                  |     STATE     |\n-        //   +-+----------------------------------+---------------+\n-        // C | | (on entry)                       | {_0,_2,_3}    |\n-        //   +-+----------------------------------+---------------+\n-        // D |0|  0: StorageLive(_7)              |               |\n-        //   +-+----------------------------------+---------------+\n-        //   |1|  1: StorageLive(_8)              |               |\n-        //   +-+----------------------------------+---------------+\n-        //   |2|  2: _8 = &mut _1                 | +_8           |\n-        //   +-+----------------------------------+---------------+\n-        // E |T| _7 = const Foo::twiddle(move _8) | -_8           |\n-        //   +-+----------------------------------+---------------+\n-        // F | | (on unwind)                      | {_0,_2,_3,_7} |\n-        //   +-+----------------------------------+---------------+\n-        //   | | (on successful return)           | +_7           |\n-        //   +-+----------------------------------+---------------+\n+        //   +-+-----------------------------------------------+\n+        // A |                      bb4                        |\n+        //   +-+----------------------------------+------------+\n+        // B |                MIR                 |   STATE    |\n+        //   +-+----------------------------------+------------+\n+        // C | | (on entry)                       | {_0,_2,_3} |\n+        //   +-+----------------------------------+------------+\n+        // D |0| StorageLive(_7)                  |            |\n+        //   +-+----------------------------------+------------+\n+        //   |1| StorageLive(_8)                  |            |\n+        //   +-+----------------------------------+------------+\n+        //   |2| _8 = &mut _1                     | +_8        |\n+        //   +-+----------------------------------+------------+\n+        // E |T| _4 = const Foo::twiddle(move _2) | -_2        |\n+        //   +-+----------------------------------+------------+\n+        // F | | (on unwind)                      | {_0,_3,_8} |\n+        //   +-+----------------------------------+------------+\n+        //   | | (on successful return)           | +_4        |\n+        //   +-+----------------------------------+------------+\n \n         write!(\n             w,\n@@ -211,6 +211,7 @@ where\n         )?;\n \n         // C: Entry state\n+        self.bg = Background::Light;\n         self.results.seek_to_block_start(block);\n         self.write_row_with_curr_state(w, \"\", \"(on entry)\")?;\n         self.prev_state.overwrite(self.results.get());"}, {"sha": "81c08ee87e985ecab89b9f4b78ac868ef94d1282", "filename": "src/librustc_mir/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_mir%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_mir%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Flib.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -25,6 +25,7 @@ Rust MIR: a lowered representation of Rust. Also: an experiment!\n #![feature(mem_take)]\n #![feature(associated_type_bounds)]\n #![feature(range_is_empty)]\n+#![feature(stmt_expr_attributes)]\n \n #![recursion_limit=\"256\"]\n "}, {"sha": "7a8a209a5350cfa4dd27053ec9672746e29a4ce3", "filename": "src/librustc_typeck/check/writeback.rs", "status": "modified", "additions": 20, "deletions": 3, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_typeck%2Fcheck%2Fwriteback.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_typeck%2Fcheck%2Fwriteback.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fwriteback.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -190,9 +190,26 @@ impl<'cx, 'tcx> WritebackCx<'cx, 'tcx> {\n         if let hir::ExprKind::Index(ref base, ref index) = e.kind {\n             let mut tables = self.fcx.tables.borrow_mut();\n \n-            // All valid indexing looks like this; might encounter non-valid indexes at this point\n-            if let ty::Ref(_, base_ty, _) = tables.expr_ty_adjusted(&base).kind {\n-                let index_ty = tables.expr_ty_adjusted(&index);\n+            // All valid indexing looks like this; might encounter non-valid indexes at this point.\n+            let base_ty = tables.expr_ty_adjusted_opt(&base).map(|t| &t.kind);\n+            if base_ty.is_none() {\n+                // When encountering `return [0][0]` outside of a `fn` body we can encounter a base\n+                // that isn't in the type table. We assume more relevant errors have already been\n+                // emitted, so we delay an ICE if none have. (#64638)\n+                self.tcx().sess.delay_span_bug(e.span, &format!(\"bad base: `{:?}`\", base));\n+            }\n+            if let Some(ty::Ref(_, base_ty, _)) = base_ty {\n+                let index_ty = tables.expr_ty_adjusted_opt(&index).unwrap_or_else(|| {\n+                    // When encountering `return [0][0]` outside of a `fn` body we would attempt\n+                    // to access an unexistend index. We assume that more relevant errors will\n+                    // already have been emitted, so we only gate on this with an ICE if no\n+                    // error has been emitted. (#64638)\n+                    self.tcx().sess.delay_span_bug(\n+                        e.span,\n+                        &format!(\"bad index {:?} for base: `{:?}`\", index, base),\n+                    );\n+                    self.fcx.tcx.types.err\n+                });\n                 let index_ty = self.fcx.resolve_vars_if_possible(&index_ty);\n \n                 if base_ty.builtin_index().is_some() && index_ty == self.fcx.tcx.types.usize {"}, {"sha": "26a8f79b8d8315df83321766d6f8b72b3cadc161", "filename": "src/librustc_typeck/lib.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_typeck%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibrustc_typeck%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Flib.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -295,7 +295,7 @@ pub fn provide(providers: &mut Providers<'_>) {\n }\n \n pub fn check_crate(tcx: TyCtxt<'_>) -> Result<(), ErrorReported> {\n-    tcx.sess.profiler(|p| p.start_activity(\"type-check crate\"));\n+    let _prof_timer = tcx.prof.generic_activity(\"type_check_crate\");\n \n     // this ensures that later parts of type checking can assume that items\n     // have valid types and not error\n@@ -347,8 +347,6 @@ pub fn check_crate(tcx: TyCtxt<'_>) -> Result<(), ErrorReported> {\n     check_unused::check_crate(tcx);\n     check_for_entry_fn(tcx);\n \n-    tcx.sess.profiler(|p| p.end_activity(\"type-check crate\"));\n-\n     if tcx.sess.err_count() == 0 {\n         Ok(())\n     } else {"}, {"sha": "d2e360f5e20fd972cb5baa1b521ca1df2de664c8", "filename": "src/libserialize/json.rs", "status": "modified", "additions": 10, "deletions": 11, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibserialize%2Fjson.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Flibserialize%2Fjson.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibserialize%2Fjson.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1053,12 +1053,12 @@ impl Json {\n     /// a value associated with the provided key is found. If no value is found\n     /// or the Json value is not an Object, returns `None`.\n     pub fn search(&self, key: &str) -> Option<&Json> {\n-        match self {\n-            &Json::Object(ref map) => {\n+        match *self {\n+            Json::Object(ref map) => {\n                 match map.get(key) {\n                     Some(json_value) => Some(json_value),\n                     None => {\n-                        for (_, v) in map {\n+                        for v in map.values() {\n                             match v.search(key) {\n                                 x if x.is_some() => return x,\n                                 _ => ()\n@@ -1487,12 +1487,12 @@ impl<T: Iterator<Item=char>> Parser<T> {\n     }\n \n     fn parse_number(&mut self) -> JsonEvent {\n-        let mut neg = false;\n-\n-        if self.ch_is('-') {\n+        let neg = if self.ch_is('-') {\n             self.bump();\n-            neg = true;\n-        }\n+            true\n+        } else {\n+            false\n+        };\n \n         let res = match self.parse_u64() {\n             Ok(res) => res,\n@@ -2162,10 +2162,9 @@ impl crate::Decoder for Decoder {\n         let s = self.read_str()?;\n         {\n             let mut it = s.chars();\n-            match (it.next(), it.next()) {\n+            if let (Some(c), None) = (it.next(), it.next()) {\n                 // exactly one character\n-                (Some(c), None) => return Ok(c),\n-                _ => ()\n+                return Ok(c);\n             }\n         }\n         Err(ExpectedError(\"single character string\".to_owned(), s.to_string()))"}, {"sha": "a62e5bf8d3c622fe19d3f31b05b994aa9bcbd6d6", "filename": "src/test/ui/issues/issue-64620.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Ftest%2Fui%2Fissues%2Fissue-64620.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Ftest%2Fui%2Fissues%2Fissue-64620.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fissues%2Fissue-64620.rs?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -0,0 +1,5 @@\n+enum Bug {\n+    V1 = return [0][0] //~ERROR return statement outside of function body\n+}\n+\n+fn main() {}"}, {"sha": "f40ac4de32d5981426db6c54f4f285715aed09c3", "filename": "src/test/ui/issues/issue-64620.stderr", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Ftest%2Fui%2Fissues%2Fissue-64620.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Ftest%2Fui%2Fissues%2Fissue-64620.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fissues%2Fissue-64620.stderr?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -0,0 +1,9 @@\n+error[E0572]: return statement outside of function body\n+  --> $DIR/issue-64620.rs:2:10\n+   |\n+LL |     V1 = return [0][0]\n+   |          ^^^^^^^^^^^^^\n+\n+error: aborting due to previous error\n+\n+For more information about this error, try `rustc --explain E0572`."}, {"sha": "8b0561d68f12eeb1d72e07ceef464ebf6032a1bc", "filename": "src/tools/cargo", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": null, "raw_url": null, "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fcargo?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1 +1 @@\n-Subproject commit ab6fa8908c9b6c8f7e2249231c395eebfbc49891\n+Subproject commit 8b0561d68f12eeb1d72e07ceef464ebf6032a1bc"}, {"sha": "8dc9ba96d57c5705b99a18a380d41579e9d2d675", "filename": "src/tools/rls", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": null, "raw_url": null, "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Frls?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -1 +1 @@\n-Subproject commit 80a1d340f7d65b466bd3e0513c6b4b53498de2ff\n+Subproject commit 8dc9ba96d57c5705b99a18a380d41579e9d2d675"}, {"sha": "a78cbdc2c4c6afb0fa31909496d0a1db949521b1", "filename": "src/tools/rustc-workspace-hack/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Ftools%2Frustc-workspace-hack%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/f2023ac599c38a59f86552089e6791c5a73412d3/src%2Ftools%2Frustc-workspace-hack%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Frustc-workspace-hack%2FCargo.toml?ref=f2023ac599c38a59f86552089e6791c5a73412d3", "patch": "@@ -24,6 +24,7 @@ features = [\n   \"jobapi\",\n   \"jobapi2\",\n   \"knownfolders\",\n+  \"libloaderapi\",\n   \"lmcons\",\n   \"memoryapi\",\n   \"minschannel\","}]}