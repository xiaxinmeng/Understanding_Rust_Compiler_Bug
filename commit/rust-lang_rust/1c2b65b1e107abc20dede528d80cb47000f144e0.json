{"sha": "1c2b65b1e107abc20dede528d80cb47000f144e0", "node_id": "MDY6Q29tbWl0NzI0NzEyOjFjMmI2NWIxZTEwN2FiYzIwZGVkZTUyOGQ4MGNiNDcwMDBmMTQ0ZTA=", "commit": {"author": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2020-05-29T04:19:11Z"}, "committer": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2020-05-29T04:19:11Z"}, "message": "Revert \"Move  functions to librustc_parse\"\n\nThis reverts commit 7a4c1865fb2f58c57e3f09645515dec8be3022c6.", "tree": {"sha": "cccb864626c3a7d961c29e65eec6f2170aa33045", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/cccb864626c3a7d961c29e65eec6f2170aa33045"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1c2b65b1e107abc20dede528d80cb47000f144e0", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE7J9Gc3TfBwj2K399tAh+UQ6YsWQFAl7QjUAACgkQtAh+UQ6Y\nsWRMmQ//ZGvZpqEeXgI7po8gy5vLTxum48dYCbDZEr+AWjz7Ef56isZxMPsF8qFP\nq1jhT7PRjXHcVATxhY+jbuzoKt9Xwn/pg3sVZ3gCgvwqKSW4nrbHkTLwEDbkNja+\nUwpLwkupSPTIc/9Ug7G+lWv2Xva0gchteZpwT5tr1vzkcjo0+bXGHjlqwMO8/qbF\nnRz3DxmCBIinXFXul1wd149/TylD8FgX758SSOvLyZMaC2bTw83yoZzpsLg2gaBb\nJYnE14KpVYNXWqDb2YggnbGLaFjGUL297oquR3N4rCBoFyWYsmAhH44s2UoYZUAY\nTnAXY1etaIDt37b8J5kTeThACW8IaEBlqsCcYvxWE6a6t2dQoQS5juwBeo//0Y1N\nbaqaJ+HhLIJgPj6eaIvYA2lK2s6Q2LjUZpeLaFMF2O+2o9cJ2rxiuEo1az/BZDjq\nghMa7jkMdKTrbckcNAHbNetwYpbidfCel0/YpypAZQK5S3zPXadnPZ8KC6vuKpZN\n3LZogxVmUiqFCEMJ9d110BtYMZertAPT8ABwvAojmTMb+HDFgGoMmVKbbeFvO67K\nujeqzlU42whOYqAQMtExd1Cy3jo/UgjMphfEPtJZUW9yUox2Xt3A/X/wRquJNPEK\nwrTxukYKlTlZAfo/AGQusQJbG+zsXEphvN7STWJ2ld+UuJ0eY3s=\n=tULi\n-----END PGP SIGNATURE-----", "payload": "tree cccb864626c3a7d961c29e65eec6f2170aa33045\nparent 1ae7de9a52d295a6c3d21af1915fc95951193b83\nauthor Aaron Hill <aa1ronham@gmail.com> 1590725951 -0400\ncommitter Aaron Hill <aa1ronham@gmail.com> 1590725951 -0400\n\nRevert \"Move  functions to librustc_parse\"\n\nThis reverts commit 7a4c1865fb2f58c57e3f09645515dec8be3022c6.\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1c2b65b1e107abc20dede528d80cb47000f144e0", "html_url": "https://github.com/rust-lang/rust/commit/1c2b65b1e107abc20dede528d80cb47000f144e0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1c2b65b1e107abc20dede528d80cb47000f144e0/comments", "author": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1ae7de9a52d295a6c3d21af1915fc95951193b83", "url": "https://api.github.com/repos/rust-lang/rust/commits/1ae7de9a52d295a6c3d21af1915fc95951193b83", "html_url": "https://github.com/rust-lang/rust/commit/1ae7de9a52d295a6c3d21af1915fc95951193b83"}], "stats": {"total": 302, "additions": 179, "deletions": 123}, "files": [{"sha": "a5b9c2a95bbea14074f4fbf7d03257bf65432cde", "filename": "src/librustc_ast/token.rs", "status": "modified", "additions": 56, "deletions": 0, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/1c2b65b1e107abc20dede528d80cb47000f144e0/src%2Flibrustc_ast%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1c2b65b1e107abc20dede528d80cb47000f144e0/src%2Flibrustc_ast%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast%2Ftoken.rs?ref=1c2b65b1e107abc20dede528d80cb47000f144e0", "patch": "@@ -673,6 +673,62 @@ impl Token {\n \n         Some(Token::new(kind, self.span.to(joint.span)))\n     }\n+\n+    // See comments in `Nonterminal::to_tokenstream` for why we care about\n+    // *probably* equal here rather than actual equality\n+    crate fn probably_equal_for_proc_macro(&self, other: &Token) -> bool {\n+        if mem::discriminant(&self.kind) != mem::discriminant(&other.kind) {\n+            return false;\n+        }\n+        match (&self.kind, &other.kind) {\n+            (&Eq, &Eq)\n+            | (&Lt, &Lt)\n+            | (&Le, &Le)\n+            | (&EqEq, &EqEq)\n+            | (&Ne, &Ne)\n+            | (&Ge, &Ge)\n+            | (&Gt, &Gt)\n+            | (&AndAnd, &AndAnd)\n+            | (&OrOr, &OrOr)\n+            | (&Not, &Not)\n+            | (&Tilde, &Tilde)\n+            | (&At, &At)\n+            | (&Dot, &Dot)\n+            | (&DotDot, &DotDot)\n+            | (&DotDotDot, &DotDotDot)\n+            | (&DotDotEq, &DotDotEq)\n+            | (&Comma, &Comma)\n+            | (&Semi, &Semi)\n+            | (&Colon, &Colon)\n+            | (&ModSep, &ModSep)\n+            | (&RArrow, &RArrow)\n+            | (&LArrow, &LArrow)\n+            | (&FatArrow, &FatArrow)\n+            | (&Pound, &Pound)\n+            | (&Dollar, &Dollar)\n+            | (&Question, &Question)\n+            | (&Whitespace, &Whitespace)\n+            | (&Comment, &Comment)\n+            | (&Eof, &Eof) => true,\n+\n+            (&BinOp(a), &BinOp(b)) | (&BinOpEq(a), &BinOpEq(b)) => a == b,\n+\n+            (&OpenDelim(a), &OpenDelim(b)) | (&CloseDelim(a), &CloseDelim(b)) => a == b,\n+\n+            (&DocComment(a), &DocComment(b)) | (&Shebang(a), &Shebang(b)) => a == b,\n+\n+            (&Literal(a), &Literal(b)) => a == b,\n+\n+            (&Lifetime(a), &Lifetime(b)) => a == b,\n+            (&Ident(a, b), &Ident(c, d)) => {\n+                b == d && (a == c || a == kw::DollarCrate || c == kw::DollarCrate)\n+            }\n+\n+            (&Interpolated(_), &Interpolated(_)) => false,\n+\n+            _ => panic!(\"forgot to add a token?\"),\n+        }\n+    }\n }\n \n impl PartialEq<TokenKind> for Token {"}, {"sha": "075aaa7e5bc013dd5b0d9744d6ec73efda73de18", "filename": "src/librustc_ast/tokenstream.rs", "status": "modified", "additions": 121, "deletions": 0, "changes": 121, "blob_url": "https://github.com/rust-lang/rust/blob/1c2b65b1e107abc20dede528d80cb47000f144e0/src%2Flibrustc_ast%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1c2b65b1e107abc20dede528d80cb47000f144e0/src%2Flibrustc_ast%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast%2Ftokenstream.rs?ref=1c2b65b1e107abc20dede528d80cb47000f144e0", "patch": "@@ -68,6 +68,23 @@ impl TokenTree {\n         }\n     }\n \n+    // See comments in `Nonterminal::to_tokenstream` for why we care about\n+    // *probably* equal here rather than actual equality\n+    //\n+    // This is otherwise the same as `eq_unspanned`, only recursing with a\n+    // different method.\n+    pub fn probably_equal_for_proc_macro(&self, other: &TokenTree) -> bool {\n+        match (self, other) {\n+            (TokenTree::Token(token), TokenTree::Token(token2)) => {\n+                token.probably_equal_for_proc_macro(token2)\n+            }\n+            (TokenTree::Delimited(_, delim, tts), TokenTree::Delimited(_, delim2, tts2)) => {\n+                delim == delim2 && tts.probably_equal_for_proc_macro(&tts2)\n+            }\n+            _ => false,\n+        }\n+    }\n+\n     /// Retrieves the TokenTree's span.\n     pub fn span(&self) -> Span {\n         match self {\n@@ -290,7 +307,111 @@ impl TokenStream {\n         t1.next().is_none() && t2.next().is_none()\n     }\n \n+    // See comments in `Nonterminal::to_tokenstream` for why we care about\n+    // *probably* equal here rather than actual equality\n+    //\n+    // This is otherwise the same as `eq_unspanned`, only recursing with a\n+    // different method.\n+    pub fn probably_equal_for_proc_macro(&self, other: &TokenStream) -> bool {\n+        // When checking for `probably_eq`, we ignore certain tokens that aren't\n+        // preserved in the AST. Because they are not preserved, the pretty\n+        // printer arbitrarily adds or removes them when printing as token\n+        // streams, making a comparison between a token stream generated from an\n+        // AST and a token stream which was parsed into an AST more reliable.\n+        fn semantic_tree(tree: &TokenTree) -> bool {\n+            if let TokenTree::Token(token) = tree {\n+                if let\n+                    // The pretty printer tends to add trailing commas to\n+                    // everything, and in particular, after struct fields.\n+                    | token::Comma\n+                    // The pretty printer emits `NoDelim` as whitespace.\n+                    | token::OpenDelim(DelimToken::NoDelim)\n+                    | token::CloseDelim(DelimToken::NoDelim)\n+                    // The pretty printer collapses many semicolons into one.\n+                    | token::Semi\n+                    // The pretty printer collapses whitespace arbitrarily and can\n+                    // introduce whitespace from `NoDelim`.\n+                    | token::Whitespace\n+                    // The pretty printer can turn `$crate` into `::crate_name`\n+                    | token::ModSep = token.kind {\n+                    return false;\n+                }\n+            }\n+            true\n+        }\n \n+        // When comparing two `TokenStream`s, we ignore the `IsJoint` information.\n+        //\n+        // However, `rustc_parse::lexer::tokentrees::TokenStreamBuilder` will\n+        // use `Token.glue` on adjacent tokens with the proper `IsJoint`.\n+        // Since we are ignoreing `IsJoint`, a 'glued' token (e.g. `BinOp(Shr)`)\n+        // and its 'split'/'unglued' compoenents (e.g. `Gt, Gt`) are equivalent\n+        // when determining if two `TokenStream`s are 'probably equal'.\n+        //\n+        // Therefore, we use `break_two_token_op` to convert all tokens\n+        // to the 'unglued' form (if it exists). This ensures that two\n+        // `TokenStream`s which differ only in how their tokens are glued\n+        // will be considered 'probably equal', which allows us to keep spans.\n+        //\n+        // This is important when the original `TokenStream` contained\n+        // extra spaces (e.g. `f :: < Vec < _ > > ( ) ;'). These extra spaces\n+        // will be omitted when we pretty-print, which can cause the original\n+        // and reparsed `TokenStream`s to differ in the assignment of `IsJoint`,\n+        // leading to some tokens being 'glued' together in one stream but not\n+        // the other. See #68489 for more details.\n+        fn break_tokens(tree: TokenTree) -> impl Iterator<Item = TokenTree> {\n+            // In almost all cases, we should have either zero or one levels\n+            // of 'unglueing'. However, in some unusual cases, we may need\n+            // to iterate breaking tokens mutliple times. For example:\n+            // '[BinOpEq(Shr)] => [Gt, Ge] -> [Gt, Gt, Eq]'\n+            let mut token_trees: SmallVec<[_; 2]>;\n+            if let TokenTree::Token(token) = &tree {\n+                let mut out = SmallVec::<[_; 2]>::new();\n+                out.push(token.clone());\n+                // Iterate to fixpoint:\n+                // * We start off with 'out' containing our initial token, and `temp` empty\n+                // * If we are able to break any tokens in `out`, then `out` will have\n+                //   at least one more element than 'temp', so we will try to break tokens\n+                //   again.\n+                // * If we cannot break any tokens in 'out', we are done\n+                loop {\n+                    let mut temp = SmallVec::<[_; 2]>::new();\n+                    let mut changed = false;\n+\n+                    for token in out.into_iter() {\n+                        if let Some((first, second)) = token.kind.break_two_token_op() {\n+                            temp.push(Token::new(first, DUMMY_SP));\n+                            temp.push(Token::new(second, DUMMY_SP));\n+                            changed = true;\n+                        } else {\n+                            temp.push(token);\n+                        }\n+                    }\n+                    out = temp;\n+                    if !changed {\n+                        break;\n+                    }\n+                }\n+                token_trees = out.into_iter().map(|t| TokenTree::Token(t)).collect();\n+                if token_trees.len() != 1 {\n+                    debug!(\"break_tokens: broke {:?} to {:?}\", tree, token_trees);\n+                }\n+            } else {\n+                token_trees = SmallVec::new();\n+                token_trees.push(tree);\n+            }\n+            token_trees.into_iter()\n+        }\n+\n+        let mut t1 = self.trees().filter(semantic_tree).flat_map(break_tokens);\n+        let mut t2 = other.trees().filter(semantic_tree).flat_map(break_tokens);\n+        for (t1, t2) in t1.by_ref().zip(t2.by_ref()) {\n+            if !t1.probably_equal_for_proc_macro(&t2) {\n+                return false;\n+            }\n+        }\n+        t1.next().is_none() && t2.next().is_none()\n+    }\n \n     pub fn map_enumerated<F: FnMut(usize, TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n         TokenStream(Lrc::new("}, {"sha": "182de85857e5e6bdcfcd93e1cea27d5f75945be5", "filename": "src/librustc_parse/lib.rs", "status": "modified", "additions": 2, "deletions": 123, "changes": 125, "blob_url": "https://github.com/rust-lang/rust/blob/1c2b65b1e107abc20dede528d80cb47000f144e0/src%2Flibrustc_parse%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1c2b65b1e107abc20dede528d80cb47000f144e0/src%2Flibrustc_parse%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Flib.rs?ref=1c2b65b1e107abc20dede528d80cb47000f144e0", "patch": "@@ -7,18 +7,16 @@\n #![feature(or_patterns)]\n \n use rustc_ast::ast;\n-use rustc_ast::token::{self, Nonterminal, Token, TokenKind, DelimToken};\n+use rustc_ast::token::{self, Nonterminal};\n use rustc_ast::tokenstream::{self, TokenStream, TokenTree};\n use rustc_ast_pretty::pprust;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::{Diagnostic, FatalError, Level, PResult};\n use rustc_session::parse::ParseSess;\n use rustc_span::{FileName, SourceFile, Span};\n-use rustc_span::symbol::kw;\n \n use std::path::Path;\n use std::str;\n-use std::mem;\n \n use log::info;\n \n@@ -308,7 +306,7 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n     // modifications, including adding/removing typically non-semantic\n     // tokens such as extra braces and commas, don't happen.\n     if let Some(tokens) = tokens {\n-        if tokenstream_probably_equal_for_proc_macro(&tokens, &tokens_for_real) {\n+        if tokens.probably_equal_for_proc_macro(&tokens_for_real) {\n             return tokens;\n         }\n         info!(\n@@ -383,122 +381,3 @@ fn prepend_attrs(\n     builder.push(tokens.clone());\n     Some(builder.build())\n }\n-\n-// See comments in `Nonterminal::to_tokenstream` for why we care about\n-// *probably* equal here rather than actual equality\n-//\n-// This is otherwise the same as `eq_unspanned`, only recursing with a\n-// different method.\n-pub fn tokenstream_probably_equal_for_proc_macro(first: &TokenStream, other: &TokenStream) -> bool {\n-    // When checking for `probably_eq`, we ignore certain tokens that aren't\n-    // preserved in the AST. Because they are not preserved, the pretty\n-    // printer arbitrarily adds or removes them when printing as token\n-    // streams, making a comparison between a token stream generated from an\n-    // AST and a token stream which was parsed into an AST more reliable.\n-    fn semantic_tree(tree: &TokenTree) -> bool {\n-        if let TokenTree::Token(token) = tree {\n-            if let\n-                // The pretty printer tends to add trailing commas to\n-                // everything, and in particular, after struct fields.\n-                | token::Comma\n-                // The pretty printer emits `NoDelim` as whitespace.\n-                | token::OpenDelim(DelimToken::NoDelim)\n-                | token::CloseDelim(DelimToken::NoDelim)\n-                // The pretty printer collapses many semicolons into one.\n-                | token::Semi\n-                // The pretty printer collapses whitespace arbitrarily and can\n-                // introduce whitespace from `NoDelim`.\n-                | token::Whitespace\n-                // The pretty printer can turn `$crate` into `::crate_name`\n-                | token::ModSep = token.kind {\n-                return false;\n-            }\n-        }\n-        true\n-    }\n-\n-    let mut t1 = first.trees().filter(semantic_tree);\n-    let mut t2 = other.trees().filter(semantic_tree);\n-    for (t1, t2) in t1.by_ref().zip(t2.by_ref()) {\n-        if !tokentree_probably_equal_for_proc_macro(&t1, &t2) {\n-            return false;\n-        }\n-    }\n-    t1.next().is_none() && t2.next().is_none()\n-}\n-\n-// See comments in `Nonterminal::to_tokenstream` for why we care about\n-// *probably* equal here rather than actual equality\n-crate fn token_probably_equal_for_proc_macro(first: &Token, other: &Token) -> bool {\n-    use TokenKind::*;\n-\n-    if mem::discriminant(&first.kind) != mem::discriminant(&other.kind) {\n-        return false;\n-    }\n-    match (&first.kind, &other.kind) {\n-        (&Eq, &Eq)\n-        | (&Lt, &Lt)\n-        | (&Le, &Le)\n-        | (&EqEq, &EqEq)\n-        | (&Ne, &Ne)\n-        | (&Ge, &Ge)\n-        | (&Gt, &Gt)\n-        | (&AndAnd, &AndAnd)\n-        | (&OrOr, &OrOr)\n-        | (&Not, &Not)\n-        | (&Tilde, &Tilde)\n-        | (&At, &At)\n-        | (&Dot, &Dot)\n-        | (&DotDot, &DotDot)\n-        | (&DotDotDot, &DotDotDot)\n-        | (&DotDotEq, &DotDotEq)\n-        | (&Comma, &Comma)\n-        | (&Semi, &Semi)\n-        | (&Colon, &Colon)\n-        | (&ModSep, &ModSep)\n-        | (&RArrow, &RArrow)\n-        | (&LArrow, &LArrow)\n-        | (&FatArrow, &FatArrow)\n-        | (&Pound, &Pound)\n-        | (&Dollar, &Dollar)\n-        | (&Question, &Question)\n-        | (&Whitespace, &Whitespace)\n-        | (&Comment, &Comment)\n-        | (&Eof, &Eof) => true,\n-\n-        (&BinOp(a), &BinOp(b)) | (&BinOpEq(a), &BinOpEq(b)) => a == b,\n-\n-        (&OpenDelim(a), &OpenDelim(b)) | (&CloseDelim(a), &CloseDelim(b)) => a == b,\n-\n-        (&DocComment(a), &DocComment(b)) | (&Shebang(a), &Shebang(b)) => a == b,\n-\n-        (&Literal(a), &Literal(b)) => a == b,\n-\n-        (&Lifetime(a), &Lifetime(b)) => a == b,\n-        (&Ident(a, b), &Ident(c, d)) => {\n-            b == d && (a == c || a == kw::DollarCrate || c == kw::DollarCrate)\n-        }\n-\n-        (&Interpolated(_), &Interpolated(_)) => false,\n-\n-        _ => panic!(\"forgot to add a token?\"),\n-    }\n-}\n-\n-\n-// See comments in `Nonterminal::to_tokenstream` for why we care about\n-// *probably* equal here rather than actual equality\n-//\n-// This is otherwise the same as `eq_unspanned`, only recursing with a\n-// different method.\n-pub fn tokentree_probably_equal_for_proc_macro(first: &TokenTree, other: &TokenTree) -> bool {\n-    match (first, other) {\n-        (TokenTree::Token(token), TokenTree::Token(token2)) => {\n-            token_probably_equal_for_proc_macro(token, token2)\n-        }\n-        (TokenTree::Delimited(_, delim, tts), TokenTree::Delimited(_, delim2, tts2)) => {\n-            delim == delim2 && tokenstream_probably_equal_for_proc_macro(&tts, &tts2)\n-        }\n-        _ => false,\n-    }\n-}"}]}