{"sha": "c23408751c43ea7e349d8cf27472e546214acef6", "node_id": "MDY6Q29tbWl0NzI0NzEyOmMyMzQwODc1MWM0M2VhN2UzNDlkOGNmMjc0NzJlNTQ2MjE0YWNlZjY=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-04T19:39:54Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-04T19:39:54Z"}, "message": "Add multi-byte token support in tkn tree to ast", "tree": {"sha": "f31d692c8785a6b8f492f2f0220d499d8d2db39f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f31d692c8785a6b8f492f2f0220d499d8d2db39f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c23408751c43ea7e349d8cf27472e546214acef6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c23408751c43ea7e349d8cf27472e546214acef6", "html_url": "https://github.com/rust-lang/rust/commit/c23408751c43ea7e349d8cf27472e546214acef6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c23408751c43ea7e349d8cf27472e546214acef6/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7713416477fd59348ad60d44f0ec3a3aebcf4b9f", "url": "https://api.github.com/repos/rust-lang/rust/commits/7713416477fd59348ad60d44f0ec3a3aebcf4b9f", "html_url": "https://github.com/rust-lang/rust/commit/7713416477fd59348ad60d44f0ec3a3aebcf4b9f"}], "stats": {"total": 159, "additions": 139, "deletions": 20}, "files": [{"sha": "a1431282160d56960b933d066f210babf115d529", "filename": "Cargo.lock", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c23408751c43ea7e349d8cf27472e546214acef6/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/c23408751c43ea7e349d8cf27472e546214acef6/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=c23408751c43ea7e349d8cf27472e546214acef6", "patch": "@@ -1040,6 +1040,7 @@ dependencies = [\n name = \"ra_mbe\"\n version = \"0.1.0\"\n dependencies = [\n+ \"itertools 0.8.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"ra_parser 0.1.0\",\n  \"ra_syntax 0.1.0\",\n  \"ra_tt 0.1.0\","}, {"sha": "1d0c2a340ffa80b183d42ac3a6ed1af335814e07", "filename": "crates/ra_mbe/Cargo.toml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c23408751c43ea7e349d8cf27472e546214acef6/crates%2Fra_mbe%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/c23408751c43ea7e349d8cf27472e546214acef6/crates%2Fra_mbe%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2FCargo.toml?ref=c23408751c43ea7e349d8cf27472e546214acef6", "patch": "@@ -8,5 +8,5 @@ authors = [\"rust-analyzer developers\"]\n ra_syntax = { path = \"../ra_syntax\" }\n ra_parser = { path = \"../ra_parser\" }\n tt = { path = \"../ra_tt\", package = \"ra_tt\" }\n-\n+itertools = \"0.8.0\"\n rustc-hash = \"1.0.0\""}, {"sha": "b7e8d34da5e14a9a476a489269b6bfb2b108fc5a", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 137, "deletions": 19, "changes": 156, "blob_url": "https://github.com/rust-lang/rust/blob/c23408751c43ea7e349d8cf27472e546214acef6/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c23408751c43ea7e349d8cf27472e546214acef6/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=c23408751c43ea7e349d8cf27472e546214acef6", "patch": "@@ -113,6 +113,51 @@ struct TtToken {\n     text: SmolStr,\n }\n \n+// Some helper functions\n+fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n+    if let tt::TokenTree::Leaf(tt::Leaf::Punct(pp)) = tt {\n+        return Some(pp);\n+    }\n+    None\n+}\n+\n+struct TokenPeek<'a, I>\n+where\n+    I: Iterator<Item = &'a tt::TokenTree>,\n+{\n+    iter: itertools::MultiPeek<I>,\n+}\n+\n+impl<'a, I> TokenPeek<'a, I>\n+where\n+    I: Iterator<Item = &'a tt::TokenTree>,\n+{\n+    fn next(&mut self) -> Option<&tt::TokenTree> {\n+        self.iter.next()\n+    }\n+\n+    fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n+        if p.spacing != tt::Spacing::Joint {\n+            return None;\n+        }\n+\n+        self.iter.reset_peek();\n+        let p1 = to_punct(self.iter.peek()?)?;\n+        Some(((p.char, p1.char), p1.spacing == tt::Spacing::Joint))\n+    }\n+\n+    fn current_punct3(&mut self, p: &tt::Punct) -> Option<((char, char, char), bool)> {\n+        self.current_punct2(p).and_then(|((p0, p1), last_joint)| {\n+            if !last_joint {\n+                None\n+            } else {\n+                let p2 = to_punct(*self.iter.peek()?)?;\n+                Some(((p0, p1, p2.char), p2.spacing == tt::Spacing::Joint))\n+            }\n+        })\n+    }\n+}\n+\n impl TtTokenSource {\n     fn new(tt: &tt::Subtree) -> TtTokenSource {\n         let mut res = TtTokenSource { tokens: Vec::new() };\n@@ -121,38 +166,53 @@ impl TtTokenSource {\n     }\n     fn convert_subtree(&mut self, sub: &tt::Subtree) {\n         self.push_delim(sub.delimiter, false);\n-        sub.token_trees.iter().for_each(|tt| self.convert_tt(tt));\n+        let mut peek = TokenPeek { iter: itertools::multipeek(sub.token_trees.iter()) };\n+        while let Some(tt) = peek.iter.next() {\n+            self.convert_tt(tt, &mut peek);\n+        }\n         self.push_delim(sub.delimiter, true)\n     }\n-    fn convert_tt(&mut self, tt: &tt::TokenTree) {\n+\n+    fn convert_tt<'a, I>(&mut self, tt: &tt::TokenTree, iter: &mut TokenPeek<'a, I>)\n+    where\n+        I: Iterator<Item = &'a tt::TokenTree>,\n+    {\n         match tt {\n-            tt::TokenTree::Leaf(token) => self.convert_token(token),\n+            tt::TokenTree::Leaf(token) => self.convert_token(token, iter),\n             tt::TokenTree::Subtree(sub) => self.convert_subtree(sub),\n         }\n     }\n-    fn convert_token(&mut self, token: &tt::Leaf) {\n+\n+    fn convert_token<'a, I>(&mut self, token: &tt::Leaf, iter: &mut TokenPeek<'a, I>)\n+    where\n+        I: Iterator<Item = &'a tt::TokenTree>,\n+    {\n         let tok = match token {\n             tt::Leaf::Literal(l) => TtToken {\n                 kind: SyntaxKind::INT_NUMBER, // FIXME\n                 is_joint_to_next: false,\n                 text: l.text.clone(),\n             },\n             tt::Leaf::Punct(p) => {\n-                let kind = match p.char {\n-                    // lexer may produce combpund tokens for these ones\n-                    '.' => DOT,\n-                    ':' => COLON,\n-                    '=' => EQ,\n-                    '!' => EXCL,\n-                    '-' => MINUS,\n-                    c => SyntaxKind::from_char(c).unwrap(),\n-                };\n-                let text = {\n-                    let mut buf = [0u8; 4];\n-                    let s: &str = p.char.encode_utf8(&mut buf);\n-                    SmolStr::new(s)\n-                };\n-                TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text }\n+                if let Some(tt) = Self::convert_multi_char_punct(p, iter) {\n+                    tt\n+                } else {\n+                    let kind = match p.char {\n+                        // lexer may produce combpund tokens for these ones\n+                        '.' => DOT,\n+                        ':' => COLON,\n+                        '=' => EQ,\n+                        '!' => EXCL,\n+                        '-' => MINUS,\n+                        c => SyntaxKind::from_char(c).unwrap(),\n+                    };\n+                    let text = {\n+                        let mut buf = [0u8; 4];\n+                        let s: &str = p.char.encode_utf8(&mut buf);\n+                        SmolStr::new(s)\n+                    };\n+                    TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text }\n+                }\n             }\n             tt::Leaf::Ident(ident) => {\n                 let kind = SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT);\n@@ -161,6 +221,64 @@ impl TtTokenSource {\n         };\n         self.tokens.push(tok)\n     }\n+\n+    fn convert_multi_char_punct<'a, I>(\n+        p: &tt::Punct,\n+        iter: &mut TokenPeek<'a, I>,\n+    ) -> Option<TtToken>\n+    where\n+        I: Iterator<Item = &'a tt::TokenTree>,\n+    {\n+        if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n+            if let Some((kind, text)) = match m {\n+                ('<', '<', '=') => Some((SHLEQ, \"<<=\".into())),\n+                ('>', '>', '=') => Some((SHREQ, \">>=\".into())),\n+                ('.', '.', '.') => Some((DOTDOTDOT, \"...\".into())),\n+                ('.', '.', '=') => Some((DOTDOTEQ, \"..=\".into())),\n+                _ => None,\n+            } {\n+                iter.next();\n+                iter.next();\n+                return Some(TtToken { kind, is_joint_to_next, text });\n+            }\n+        }\n+\n+        if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n+            if let Some((kind, text)) = match m {\n+                ('<', '<') => Some((SHL, \"<<\".into())),\n+                ('>', '>') => Some((SHR, \">>\".into())),\n+\n+                ('|', '|') => Some((PIPEPIPE, \"||\".into())),\n+                ('&', '&') => Some((AMPAMP, \"&&\".into())),\n+                ('%', '=') => Some((PERCENTEQ, \"%=\".into())),\n+                ('*', '=') => Some((STAREQ, \"*=\".into())),\n+                ('/', '=') => Some((SLASHEQ, \"/=\".into())),\n+                ('^', '=') => Some((CARETEQ, \"^=\".into())),\n+\n+                ('&', '=') => Some((AMPEQ, \"&=\".into())),\n+                ('|', '=') => Some((PIPEEQ, \"|=\".into())),\n+                ('-', '=') => Some((MINUSEQ, \"-=\".into())),\n+                ('+', '=') => Some((PLUSEQ, \"+=\".into())),\n+                ('>', '=') => Some((GTEQ, \">=\".into())),\n+                ('<', '=') => Some((LTEQ, \"<=\".into())),\n+\n+                ('-', '>') => Some((THIN_ARROW, \"->\".into())),\n+                ('!', '=') => Some((NEQ, \"!=\".into())),\n+                ('=', '>') => Some((FAT_ARROW, \"=>\".into())),\n+                ('=', '=') => Some((EQEQ, \"==\".into())),\n+                ('.', '.') => Some((DOTDOT, \"..\".into())),\n+                (':', ':') => Some((COLONCOLON, \"::\".into())),\n+\n+                _ => None,\n+            } {\n+                iter.next();\n+                return Some(TtToken { kind, is_joint_to_next, text });\n+            }\n+        }\n+\n+        None\n+    }\n+\n     fn push_delim(&mut self, d: tt::Delimiter, closing: bool) {\n         let (kinds, texts) = match d {\n             tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),"}]}