{"sha": "d2df07c425f9b390c33e0ac31674ce4794352b3a", "node_id": "C_kwDOAAsO6NoAKGQyZGYwN2M0MjVmOWIzOTBjMzNlMGFjMzE2NzRjZTQ3OTQzNTJiM2E", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-09-09T07:15:53Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-09-09T07:25:38Z"}, "message": "Rename `{Create,Lazy}TokenStream` as `{To,Lazy}AttrTokenStream`.\n\n`To` is better than `Create` for indicating that this is a non-consuming\nconversion, rather than creating something out of nothing.\n\nAnd the addition of `Attr` is because the current names makes them sound\nlike they relate to `TokenStream`, but really they relate to\n`AttrTokenStream`.", "tree": {"sha": "b8e36ff352f2ca9a6ae20f65cfc6d648d1857942", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b8e36ff352f2ca9a6ae20f65cfc6d648d1857942"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d2df07c425f9b390c33e0ac31674ce4794352b3a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d2df07c425f9b390c33e0ac31674ce4794352b3a", "html_url": "https://github.com/rust-lang/rust/commit/d2df07c425f9b390c33e0ac31674ce4794352b3a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d2df07c425f9b390c33e0ac31674ce4794352b3a/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f6c9e1df5937a8f4dad6739368e4eb5ed453dddd", "url": "https://api.github.com/repos/rust-lang/rust/commits/f6c9e1df5937a8f4dad6739368e4eb5ed453dddd", "html_url": "https://github.com/rust-lang/rust/commit/f6c9e1df5937a8f4dad6739368e4eb5ed453dddd"}], "stats": {"total": 165, "additions": 84, "deletions": 81}, "files": [{"sha": "c9354dbb684ac86868744896bf3beb1fc1edaa1a", "filename": "compiler/rustc_ast/src/ast.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -24,7 +24,7 @@ pub use UnsafeSource::*;\n \n use crate::ptr::P;\n use crate::token::{self, CommentKind, Delimiter};\n-use crate::tokenstream::{DelimSpan, LazyTokenStream, TokenStream};\n+use crate::tokenstream::{DelimSpan, LazyAttrTokenStream, TokenStream};\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n use rustc_data_structures::stack::ensure_sufficient_stack;\n use rustc_data_structures::sync::Lrc;\n@@ -92,7 +92,7 @@ pub struct Path {\n     /// The segments in the path: the things separated by `::`.\n     /// Global paths begin with `kw::PathRoot`.\n     pub segments: Vec<PathSegment>,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl PartialEq<Symbol> for Path {\n@@ -564,7 +564,7 @@ pub struct Block {\n     /// Distinguishes between `unsafe { ... }` and `{ ... }`.\n     pub rules: BlockCheckMode,\n     pub span: Span,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n     /// The following *isn't* a parse error, but will cause multiple errors in following stages.\n     /// ```compile_fail\n     /// let x = {\n@@ -583,7 +583,7 @@ pub struct Pat {\n     pub id: NodeId,\n     pub kind: PatKind,\n     pub span: Span,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl Pat {\n@@ -967,8 +967,8 @@ impl Stmt {\n     /// a trailing semicolon.\n     ///\n     /// This only modifies the parsed AST struct, not the attached\n-    /// `LazyTokenStream`. The parser is responsible for calling\n-    /// `CreateTokenStream::add_trailing_semi` when there is actually\n+    /// `LazyAttrTokenStream`. The parser is responsible for calling\n+    /// `ToAttrTokenStream::add_trailing_semi` when there is actually\n     /// a semicolon in the tokenstream.\n     pub fn add_trailing_semicolon(mut self) -> Self {\n         self.kind = match self.kind {\n@@ -1014,7 +1014,7 @@ pub struct MacCallStmt {\n     pub mac: P<MacCall>,\n     pub style: MacStmtStyle,\n     pub attrs: AttrVec,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n #[derive(Clone, Copy, PartialEq, Encodable, Decodable, Debug)]\n@@ -1039,7 +1039,7 @@ pub struct Local {\n     pub kind: LocalKind,\n     pub span: Span,\n     pub attrs: AttrVec,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n #[derive(Clone, Encodable, Decodable, Debug)]\n@@ -1138,7 +1138,7 @@ pub struct Expr {\n     pub kind: ExprKind,\n     pub span: Span,\n     pub attrs: AttrVec,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl Expr {\n@@ -1997,7 +1997,7 @@ pub struct Ty {\n     pub id: NodeId,\n     pub kind: TyKind,\n     pub span: Span,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl Clone for Ty {\n@@ -2562,7 +2562,7 @@ impl<D: Decoder> Decodable<D> for AttrId {\n pub struct AttrItem {\n     pub path: Path,\n     pub args: MacArgs,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n /// A list of attributes.\n@@ -2582,7 +2582,7 @@ pub struct Attribute {\n #[derive(Clone, Encodable, Decodable, Debug)]\n pub struct NormalAttr {\n     pub item: AttrItem,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n #[derive(Clone, Encodable, Decodable, Debug)]\n@@ -2633,7 +2633,7 @@ impl PolyTraitRef {\n pub struct Visibility {\n     pub kind: VisibilityKind,\n     pub span: Span,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n #[derive(Clone, Encodable, Decodable, Debug)]\n@@ -2719,7 +2719,7 @@ pub struct Item<K = ItemKind> {\n     ///\n     /// Note that the tokens here do not include the outer attributes, but will\n     /// include inner attributes.\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl Item {"}, {"sha": "1b31be07f7ad1b1cc8cdb93b80fc463ab7d8e64b", "filename": "compiler/rustc_ast/src/ast_traits.rs", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -4,7 +4,7 @@\n \n use crate::ptr::P;\n use crate::token::Nonterminal;\n-use crate::tokenstream::LazyTokenStream;\n+use crate::tokenstream::LazyAttrTokenStream;\n use crate::{Arm, Crate, ExprField, FieldDef, GenericParam, Param, PatField, Variant};\n use crate::{AssocItem, Expr, ForeignItem, Item, NodeId};\n use crate::{AttrItem, AttrKind, Block, Pat, Path, Ty, Visibility};\n@@ -124,18 +124,18 @@ impl HasSpan for AttrItem {\n \n /// A trait for AST nodes having (or not having) collected tokens.\n pub trait HasTokens {\n-    fn tokens(&self) -> Option<&LazyTokenStream>;\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>>;\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream>;\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>>;\n }\n \n macro_rules! impl_has_tokens {\n     ($($T:ty),+ $(,)?) => {\n         $(\n             impl HasTokens for $T {\n-                fn tokens(&self) -> Option<&LazyTokenStream> {\n+                fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n                     self.tokens.as_ref()\n                 }\n-                fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+                fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n                     Some(&mut self.tokens)\n                 }\n             }\n@@ -147,10 +147,10 @@ macro_rules! impl_has_tokens_none {\n     ($($T:ty),+ $(,)?) => {\n         $(\n             impl HasTokens for $T {\n-                fn tokens(&self) -> Option<&LazyTokenStream> {\n+                fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n                     None\n                 }\n-                fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+                fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n                     None\n                 }\n             }\n@@ -162,25 +162,25 @@ impl_has_tokens!(AssocItem, AttrItem, Block, Expr, ForeignItem, Item, Pat, Path,\n impl_has_tokens_none!(Arm, ExprField, FieldDef, GenericParam, Param, PatField, Variant);\n \n impl<T: AstDeref<Target: HasTokens>> HasTokens for T {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         self.ast_deref().tokens()\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         self.ast_deref_mut().tokens_mut()\n     }\n }\n \n impl<T: HasTokens> HasTokens for Option<T> {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         self.as_ref().and_then(|inner| inner.tokens())\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         self.as_mut().and_then(|inner| inner.tokens_mut())\n     }\n }\n \n impl HasTokens for StmtKind {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         match self {\n             StmtKind::Local(local) => local.tokens.as_ref(),\n             StmtKind::Item(item) => item.tokens(),\n@@ -189,7 +189,7 @@ impl HasTokens for StmtKind {\n             StmtKind::MacCall(mac) => mac.tokens.as_ref(),\n         }\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         match self {\n             StmtKind::Local(local) => Some(&mut local.tokens),\n             StmtKind::Item(item) => item.tokens_mut(),\n@@ -201,24 +201,24 @@ impl HasTokens for StmtKind {\n }\n \n impl HasTokens for Stmt {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         self.kind.tokens()\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         self.kind.tokens_mut()\n     }\n }\n \n impl HasTokens for Attribute {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         match &self.kind {\n             AttrKind::Normal(normal) => normal.tokens.as_ref(),\n             kind @ AttrKind::DocComment(..) => {\n                 panic!(\"Called tokens on doc comment attr {:?}\", kind)\n             }\n         }\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         Some(match &mut self.kind {\n             AttrKind::Normal(normal) => &mut normal.tokens,\n             kind @ AttrKind::DocComment(..) => {\n@@ -229,7 +229,7 @@ impl HasTokens for Attribute {\n }\n \n impl HasTokens for Nonterminal {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         match self {\n             Nonterminal::NtItem(item) => item.tokens(),\n             Nonterminal::NtStmt(stmt) => stmt.tokens(),\n@@ -243,7 +243,7 @@ impl HasTokens for Nonterminal {\n             Nonterminal::NtIdent(..) | Nonterminal::NtLifetime(..) => None,\n         }\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         match self {\n             Nonterminal::NtItem(item) => item.tokens_mut(),\n             Nonterminal::NtStmt(stmt) => stmt.tokens_mut(),"}, {"sha": "a40508494cdc1d93f349eee8420ae02ddde2f306", "filename": "compiler/rustc_ast/src/attr/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -8,7 +8,7 @@ use crate::ast::{Path, PathSegment};\n use crate::ptr::P;\n use crate::token::{self, CommentKind, Delimiter, Token};\n use crate::tokenstream::{DelimSpan, Spacing, TokenTree};\n-use crate::tokenstream::{LazyTokenStream, TokenStream};\n+use crate::tokenstream::{LazyAttrTokenStream, TokenStream};\n use crate::util::comments;\n \n use rustc_index::bit_set::GrowableBitSet;\n@@ -301,7 +301,7 @@ impl Attribute {\n                 .tokens\n                 .as_ref()\n                 .unwrap_or_else(|| panic!(\"attribute is missing tokens: {:?}\", self))\n-                .create_token_stream()\n+                .to_attr_token_stream()\n                 .to_tokenstream(),\n             AttrKind::DocComment(comment_kind, data) => TokenStream::new(vec![TokenTree::Token(\n                 Token::new(token::DocComment(comment_kind, self.style, data), self.span),\n@@ -353,7 +353,7 @@ pub fn mk_attr(style: AttrStyle, path: Path, args: MacArgs, span: Span) -> Attri\n \n pub fn mk_attr_from_item(\n     item: AttrItem,\n-    tokens: Option<LazyTokenStream>,\n+    tokens: Option<LazyAttrTokenStream>,\n     style: AttrStyle,\n     span: Span,\n ) -> Attribute {"}, {"sha": "ad68d6e755e0287d5eedda3eef87d57e9e72798f", "filename": "compiler/rustc_ast/src/mut_visit.rs", "status": "modified", "additions": 7, "deletions": 4, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -697,17 +697,20 @@ pub fn visit_attr_tts<T: MutVisitor>(AttrTokenStream(tts): &mut AttrTokenStream,\n     }\n }\n \n-pub fn visit_lazy_tts_opt_mut<T: MutVisitor>(lazy_tts: Option<&mut LazyTokenStream>, vis: &mut T) {\n+pub fn visit_lazy_tts_opt_mut<T: MutVisitor>(\n+    lazy_tts: Option<&mut LazyAttrTokenStream>,\n+    vis: &mut T,\n+) {\n     if T::VISIT_TOKENS {\n         if let Some(lazy_tts) = lazy_tts {\n-            let mut tts = lazy_tts.create_token_stream();\n+            let mut tts = lazy_tts.to_attr_token_stream();\n             visit_attr_tts(&mut tts, vis);\n-            *lazy_tts = LazyTokenStream::new(tts);\n+            *lazy_tts = LazyAttrTokenStream::new(tts);\n         }\n     }\n }\n \n-pub fn visit_lazy_tts<T: MutVisitor>(lazy_tts: &mut Option<LazyTokenStream>, vis: &mut T) {\n+pub fn visit_lazy_tts<T: MutVisitor>(lazy_tts: &mut Option<LazyAttrTokenStream>, vis: &mut T) {\n     visit_lazy_tts_opt_mut(lazy_tts.as_mut(), vis);\n }\n "}, {"sha": "875cd620dfc6ccb759f8394803651620168f382c", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 21, "deletions": 21, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -121,12 +121,12 @@ where\n     }\n }\n \n-pub trait CreateTokenStream: sync::Send + sync::Sync {\n-    fn create_token_stream(&self) -> AttrTokenStream;\n+pub trait ToAttrTokenStream: sync::Send + sync::Sync {\n+    fn to_attr_token_stream(&self) -> AttrTokenStream;\n }\n \n-impl CreateTokenStream for AttrTokenStream {\n-    fn create_token_stream(&self) -> AttrTokenStream {\n+impl ToAttrTokenStream for AttrTokenStream {\n+    fn to_attr_token_stream(&self) -> AttrTokenStream {\n         self.clone()\n     }\n }\n@@ -135,40 +135,40 @@ impl CreateTokenStream for AttrTokenStream {\n /// of an actual `TokenStream` until it is needed.\n /// `Box` is here only to reduce the structure size.\n #[derive(Clone)]\n-pub struct LazyTokenStream(Lrc<Box<dyn CreateTokenStream>>);\n+pub struct LazyAttrTokenStream(Lrc<Box<dyn ToAttrTokenStream>>);\n \n-impl LazyTokenStream {\n-    pub fn new(inner: impl CreateTokenStream + 'static) -> LazyTokenStream {\n-        LazyTokenStream(Lrc::new(Box::new(inner)))\n+impl LazyAttrTokenStream {\n+    pub fn new(inner: impl ToAttrTokenStream + 'static) -> LazyAttrTokenStream {\n+        LazyAttrTokenStream(Lrc::new(Box::new(inner)))\n     }\n \n-    pub fn create_token_stream(&self) -> AttrTokenStream {\n-        self.0.create_token_stream()\n+    pub fn to_attr_token_stream(&self) -> AttrTokenStream {\n+        self.0.to_attr_token_stream()\n     }\n }\n \n-impl fmt::Debug for LazyTokenStream {\n+impl fmt::Debug for LazyAttrTokenStream {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        write!(f, \"LazyTokenStream({:?})\", self.create_token_stream())\n+        write!(f, \"LazyAttrTokenStream({:?})\", self.to_attr_token_stream())\n     }\n }\n \n-impl<S: Encoder> Encodable<S> for LazyTokenStream {\n+impl<S: Encoder> Encodable<S> for LazyAttrTokenStream {\n     fn encode(&self, s: &mut S) {\n         // Used by AST json printing.\n-        Encodable::encode(&self.create_token_stream(), s);\n+        Encodable::encode(&self.to_attr_token_stream(), s);\n     }\n }\n \n-impl<D: Decoder> Decodable<D> for LazyTokenStream {\n+impl<D: Decoder> Decodable<D> for LazyAttrTokenStream {\n     fn decode(_d: &mut D) -> Self {\n-        panic!(\"Attempted to decode LazyTokenStream\");\n+        panic!(\"Attempted to decode LazyAttrTokenStream\");\n     }\n }\n \n-impl<CTX> HashStable<CTX> for LazyTokenStream {\n+impl<CTX> HashStable<CTX> for LazyAttrTokenStream {\n     fn hash_stable(&self, _hcx: &mut CTX, _hasher: &mut StableHasher) {\n-        panic!(\"Attempted to compute stable hash for LazyTokenStream\");\n+        panic!(\"Attempted to compute stable hash for LazyAttrTokenStream\");\n     }\n }\n \n@@ -224,7 +224,7 @@ impl AttrTokenStream {\n \n                     let mut target_tokens: Vec<_> = data\n                         .tokens\n-                        .create_token_stream()\n+                        .to_attr_token_stream()\n                         .to_tokenstream()\n                         .0\n                         .iter()\n@@ -296,7 +296,7 @@ pub struct AttributesData {\n     pub attrs: AttrVec,\n     /// The underlying tokens for the attribute target that `attrs`\n     /// are applied to\n-    pub tokens: LazyTokenStream,\n+    pub tokens: LazyAttrTokenStream,\n }\n \n /// A `TokenStream` is an abstract sequence of tokens, organized into [`TokenTree`]s.\n@@ -431,7 +431,7 @@ impl TokenStream {\n         };\n         let attrs = node.attrs();\n         let attr_stream = if attrs.is_empty() {\n-            tokens.create_token_stream()\n+            tokens.to_attr_token_stream()\n         } else {\n             let attr_data =\n                 AttributesData { attrs: attrs.iter().cloned().collect(), tokens: tokens.clone() };"}, {"sha": "7d30596a936f9b70cf7d841ee19bd406270cecda", "filename": "compiler/rustc_expand/src/config.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -4,7 +4,7 @@ use rustc_ast::ptr::P;\n use rustc_ast::token::{Delimiter, Token, TokenKind};\n use rustc_ast::tokenstream::{AttrTokenStream, AttrTokenTree};\n use rustc_ast::tokenstream::{DelimSpan, Spacing};\n-use rustc_ast::tokenstream::{LazyTokenStream, TokenTree};\n+use rustc_ast::tokenstream::{LazyAttrTokenStream, TokenTree};\n use rustc_ast::NodeId;\n use rustc_ast::{self as ast, AttrStyle, Attribute, HasAttrs, HasTokens, MetaItem};\n use rustc_attr as attr;\n@@ -259,8 +259,8 @@ impl<'a> StripUnconfigured<'a> {\n     fn try_configure_tokens<T: HasTokens>(&self, node: &mut T) {\n         if self.config_tokens {\n             if let Some(Some(tokens)) = node.tokens_mut() {\n-                let attr_stream = tokens.create_token_stream();\n-                *tokens = LazyTokenStream::new(self.configure_tokens(&attr_stream));\n+                let attr_stream = tokens.to_attr_token_stream();\n+                *tokens = LazyAttrTokenStream::new(self.configure_tokens(&attr_stream));\n             }\n         }\n     }\n@@ -295,8 +295,8 @@ impl<'a> StripUnconfigured<'a> {\n                     data.attrs.flat_map_in_place(|attr| self.process_cfg_attr(attr));\n \n                     if self.in_cfg(&data.attrs) {\n-                        data.tokens = LazyTokenStream::new(\n-                            self.configure_tokens(&data.tokens.create_token_stream()),\n+                        data.tokens = LazyAttrTokenStream::new(\n+                            self.configure_tokens(&data.tokens.to_attr_token_stream()),\n                         );\n                         Some(AttrTokenTree::Attributes(data)).into_iter()\n                     } else {\n@@ -420,10 +420,10 @@ impl<'a> StripUnconfigured<'a> {\n             item.tokens\n                 .as_ref()\n                 .unwrap_or_else(|| panic!(\"Missing tokens for {:?}\", item))\n-                .create_token_stream(),\n+                .to_attr_token_stream(),\n         );\n         trees.push(bracket_group);\n-        let tokens = Some(LazyTokenStream::new(AttrTokenStream::new(trees)));\n+        let tokens = Some(LazyAttrTokenStream::new(AttrTokenStream::new(trees)));\n         let attr = attr::mk_attr_from_item(item, tokens, attr.style, item_span);\n         if attr.has_name(sym::crate_type) {\n             self.sess.parse_sess.buffer_lint("}, {"sha": "a37f828eafb9b4241d411fe1325b07107aa2f42e", "filename": "compiler/rustc_parse/src/parser/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -301,7 +301,7 @@ impl<'a> Parser<'a> {\n             if let Some(attr) = attr {\n                 let end_pos: u32 = self.token_cursor.num_next_calls.try_into().unwrap();\n                 // If we are currently capturing tokens, mark the location of this inner attribute.\n-                // If capturing ends up creating a `LazyTokenStream`, we will include\n+                // If capturing ends up creating a `LazyAttrTokenStream`, we will include\n                 // this replace range with it, removing the inner attribute from the final\n                 // `AttrTokenStream`. Inner attributes are stored in the parsed AST note.\n                 // During macro expansion, they are selectively inserted back into the"}, {"sha": "5fdafd187c660cab801a81ddb70768b36740d7cc", "filename": "compiler/rustc_parse/src/parser/attr_wrapper.rs", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -1,7 +1,7 @@\n use super::{Capturing, FlatToken, ForceCollect, Parser, ReplaceRange, TokenCursor, TrailingToken};\n use rustc_ast::token::{self, Delimiter, Token, TokenKind};\n-use rustc_ast::tokenstream::{AttrTokenStream, AttributesData, CreateTokenStream};\n-use rustc_ast::tokenstream::{AttrTokenTree, DelimSpan, LazyTokenStream, Spacing};\n+use rustc_ast::tokenstream::{AttrTokenStream, AttributesData, ToAttrTokenStream};\n+use rustc_ast::tokenstream::{AttrTokenTree, DelimSpan, LazyAttrTokenStream, Spacing};\n use rustc_ast::{self as ast};\n use rustc_ast::{AttrVec, Attribute, HasAttrs, HasTokens};\n use rustc_errors::PResult;\n@@ -88,7 +88,7 @@ fn has_cfg_or_cfg_attr(attrs: &[Attribute]) -> bool {\n // This also makes `Parser` very cheap to clone, since\n // there is no intermediate collection buffer to clone.\n #[derive(Clone)]\n-struct LazyTokenStreamImpl {\n+struct LazyAttrTokenStreamImpl {\n     start_token: (Token, Spacing),\n     cursor_snapshot: TokenCursor,\n     num_calls: usize,\n@@ -97,10 +97,10 @@ struct LazyTokenStreamImpl {\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(LazyTokenStreamImpl, 144);\n+rustc_data_structures::static_assert_size!(LazyAttrTokenStreamImpl, 144);\n \n-impl CreateTokenStream for LazyTokenStreamImpl {\n-    fn create_token_stream(&self) -> AttrTokenStream {\n+impl ToAttrTokenStream for LazyAttrTokenStreamImpl {\n+    fn to_attr_token_stream(&self) -> AttrTokenStream {\n         // The token produced by the final call to `{,inlined_}next` was not\n         // actually consumed by the callback. The combination of chaining the\n         // initial token and using `take` produces the desired result - we\n@@ -179,7 +179,7 @@ impl CreateTokenStream for LazyTokenStreamImpl {\n impl<'a> Parser<'a> {\n     /// Records all tokens consumed by the provided callback,\n     /// including the current token. These tokens are collected\n-    /// into a `LazyTokenStream`, and returned along with the result\n+    /// into a `LazyAttrTokenStream`, and returned along with the result\n     /// of the callback.\n     ///\n     /// Note: If your callback consumes an opening delimiter\n@@ -297,7 +297,7 @@ impl<'a> Parser<'a> {\n \n         // If we 'broke' the last token (e.g. breaking a '>>' token to two '>' tokens),\n         // then extend the range of captured tokens to include it, since the parser\n-        // was not actually bumped past it. When the `LazyTokenStream` gets converted\n+        // was not actually bumped past it. When the `LazyAttrTokenStream` gets converted\n         // into an `AttrTokenStream`, we will create the proper token.\n         if self.token_cursor.break_last_token {\n             assert_eq!(\n@@ -316,7 +316,7 @@ impl<'a> Parser<'a> {\n             Box::new([])\n         } else {\n             // Grab any replace ranges that occur *inside* the current AST node.\n-            // We will perform the actual replacement when we convert the `LazyTokenStream`\n+            // We will perform the actual replacement when we convert the `LazyAttrTokenStream`\n             // to an `AttrTokenStream`.\n             let start_calls: u32 = cursor_snapshot_next_calls.try_into().unwrap();\n             self.capture_state.replace_ranges[replace_ranges_start..replace_ranges_end]\n@@ -329,7 +329,7 @@ impl<'a> Parser<'a> {\n                 .collect()\n         };\n \n-        let tokens = LazyTokenStream::new(LazyTokenStreamImpl {\n+        let tokens = LazyAttrTokenStream::new(LazyAttrTokenStreamImpl {\n             start_token,\n             num_calls,\n             cursor_snapshot,"}, {"sha": "4cb198561e0adaf0c6d97d1e65ca4f096fc86d43", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2df07c425f9b390c33e0ac31674ce4794352b3a/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=d2df07c425f9b390c33e0ac31674ce4794352b3a", "patch": "@@ -237,7 +237,7 @@ struct TokenCursor {\n     // the trailing `>>` token. The `break_last_token`\n     // field is used to track this token - it gets\n     // appended to the captured stream when\n-    // we evaluate a `LazyTokenStream`\n+    // we evaluate a `LazyAttrTokenStream`.\n     break_last_token: bool,\n }\n \n@@ -1465,7 +1465,7 @@ pub fn emit_unclosed_delims(unclosed_delims: &mut Vec<UnmatchedBrace>, sess: &Pa\n }\n \n /// A helper struct used when building an `AttrTokenStream` from\n-/// a `LazyTokenStream`. Both delimiter and non-delimited tokens\n+/// a `LazyAttrTokenStream`. Both delimiter and non-delimited tokens\n /// are stored as `FlatToken::Token`. A vector of `FlatToken`s\n /// is then 'parsed' to build up an `AttrTokenStream` with nested\n /// `AttrTokenTree::Delimited` tokens."}]}