{"sha": "9fd75f52877a3e23a7b9a6a9675f37a42340a428", "node_id": "MDY6Q29tbWl0NzI0NzEyOjlmZDc1ZjUyODc3YTNlMjNhN2I5YTZhOTY3NWYzN2E0MjM0MGE0Mjg=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-09-22T16:17:30Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-09-22T17:37:59Z"}, "message": "pull mbe token tree definition up", "tree": {"sha": "b61049a88481ac78c3fcad7294c1097edbd8083b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b61049a88481ac78c3fcad7294c1097edbd8083b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/9fd75f52877a3e23a7b9a6a9675f37a42340a428", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/9fd75f52877a3e23a7b9a6a9675f37a42340a428", "html_url": "https://github.com/rust-lang/rust/commit/9fd75f52877a3e23a7b9a6a9675f37a42340a428", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/9fd75f52877a3e23a7b9a6a9675f37a42340a428/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "636b3543c27e1eba301605afd2143fc96fd14431", "url": "https://api.github.com/repos/rust-lang/rust/commits/636b3543c27e1eba301605afd2143fc96fd14431", "html_url": "https://github.com/rust-lang/rust/commit/636b3543c27e1eba301605afd2143fc96fd14431"}], "stats": {"total": 477, "additions": 243, "deletions": 234}, "files": [{"sha": "c18b8918ff1e39936dfef6e8c7b5e1890395879b", "filename": "src/libsyntax/ext/mbe.rs", "status": "modified", "additions": 156, "deletions": 0, "changes": 156, "blob_url": "https://github.com/rust-lang/rust/blob/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmbe.rs?ref=9fd75f52877a3e23a7b9a6a9675f37a42340a428", "patch": "@@ -8,3 +8,159 @@ crate mod macro_check;\n crate mod macro_parser;\n crate mod macro_rules;\n crate mod quoted;\n+\n+use crate::ast;\n+use crate::parse::token::{self, Token, TokenKind};\n+use crate::tokenstream::{DelimSpan};\n+\n+use syntax_pos::{BytePos, Span};\n+\n+use rustc_data_structures::sync::Lrc;\n+\n+/// Contains the sub-token-trees of a \"delimited\" token tree, such as the contents of `(`. Note\n+/// that the delimiter itself might be `NoDelim`.\n+#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n+crate struct Delimited {\n+    crate delim: token::DelimToken,\n+    crate tts: Vec<TokenTree>,\n+}\n+\n+impl Delimited {\n+    /// Returns a `self::TokenTree` with a `Span` corresponding to the opening delimiter.\n+    crate fn open_tt(&self, span: Span) -> TokenTree {\n+        let open_span = if span.is_dummy() {\n+            span\n+        } else {\n+            span.with_hi(span.lo() + BytePos(self.delim.len() as u32))\n+        };\n+        TokenTree::token(token::OpenDelim(self.delim), open_span)\n+    }\n+\n+    /// Returns a `self::TokenTree` with a `Span` corresponding to the closing delimiter.\n+    crate fn close_tt(&self, span: Span) -> TokenTree {\n+        let close_span = if span.is_dummy() {\n+            span\n+        } else {\n+            span.with_lo(span.hi() - BytePos(self.delim.len() as u32))\n+        };\n+        TokenTree::token(token::CloseDelim(self.delim), close_span)\n+    }\n+}\n+\n+#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n+crate struct SequenceRepetition {\n+    /// The sequence of token trees\n+    crate tts: Vec<TokenTree>,\n+    /// The optional separator\n+    crate separator: Option<Token>,\n+    /// Whether the sequence can be repeated zero (*), or one or more times (+)\n+    crate kleene: KleeneToken,\n+    /// The number of `Match`s that appear in the sequence (and subsequences)\n+    crate num_captures: usize,\n+}\n+\n+#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Debug, Copy)]\n+crate struct KleeneToken {\n+    crate span: Span,\n+    crate op: KleeneOp,\n+}\n+\n+impl KleeneToken {\n+    crate fn new(op: KleeneOp, span: Span) -> KleeneToken {\n+        KleeneToken { span, op }\n+    }\n+}\n+\n+/// A Kleene-style [repetition operator](http://en.wikipedia.org/wiki/Kleene_star)\n+/// for token sequences.\n+#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n+crate enum KleeneOp {\n+    /// Kleene star (`*`) for zero or more repetitions\n+    ZeroOrMore,\n+    /// Kleene plus (`+`) for one or more repetitions\n+    OneOrMore,\n+    /// Kleene optional (`?`) for zero or one reptitions\n+    ZeroOrOne,\n+}\n+\n+/// Similar to `tokenstream::TokenTree`, except that `$i`, `$i:ident`, and `$(...)`\n+/// are \"first-class\" token trees. Useful for parsing macros.\n+#[derive(Debug, Clone, PartialEq, RustcEncodable, RustcDecodable)]\n+crate enum TokenTree {\n+    Token(Token),\n+    Delimited(DelimSpan, Lrc<Delimited>),\n+    /// A kleene-style repetition sequence\n+    Sequence(DelimSpan, Lrc<SequenceRepetition>),\n+    /// e.g., `$var`\n+    MetaVar(Span, ast::Ident),\n+    /// e.g., `$var:expr`. This is only used in the left hand side of MBE macros.\n+    MetaVarDecl(\n+        Span,\n+        ast::Ident, /* name to bind */\n+        ast::Ident, /* kind of nonterminal */\n+    ),\n+}\n+\n+impl TokenTree {\n+    /// Return the number of tokens in the tree.\n+    crate fn len(&self) -> usize {\n+        match *self {\n+            TokenTree::Delimited(_, ref delimed) => match delimed.delim {\n+                token::NoDelim => delimed.tts.len(),\n+                _ => delimed.tts.len() + 2,\n+            },\n+            TokenTree::Sequence(_, ref seq) => seq.tts.len(),\n+            _ => 0,\n+        }\n+    }\n+\n+    /// Returns `true` if the given token tree is delimited.\n+    crate fn is_delimited(&self) -> bool {\n+        match *self {\n+            TokenTree::Delimited(..) => true,\n+            _ => false,\n+        }\n+    }\n+\n+    /// Returns `true` if the given token tree is a token of the given kind.\n+    crate fn is_token(&self, expected_kind: &TokenKind) -> bool {\n+        match self {\n+            TokenTree::Token(Token { kind: actual_kind, .. }) => actual_kind == expected_kind,\n+            _ => false,\n+        }\n+    }\n+\n+    /// Gets the `index`-th sub-token-tree. This only makes sense for delimited trees and sequences.\n+    crate fn get_tt(&self, index: usize) -> TokenTree {\n+        match (self, index) {\n+            (&TokenTree::Delimited(_, ref delimed), _) if delimed.delim == token::NoDelim => {\n+                delimed.tts[index].clone()\n+            }\n+            (&TokenTree::Delimited(span, ref delimed), _) => {\n+                if index == 0 {\n+                    return delimed.open_tt(span.open);\n+                }\n+                if index == delimed.tts.len() + 1 {\n+                    return delimed.close_tt(span.close);\n+                }\n+                delimed.tts[index - 1].clone()\n+            }\n+            (&TokenTree::Sequence(_, ref seq), _) => seq.tts[index].clone(),\n+            _ => panic!(\"Cannot expand a token tree\"),\n+        }\n+    }\n+\n+    /// Retrieves the `TokenTree`'s span.\n+    crate fn span(&self) -> Span {\n+        match *self {\n+            TokenTree::Token(Token { span, .. })\n+            | TokenTree::MetaVar(span, _)\n+            | TokenTree::MetaVarDecl(span, _, _) => span,\n+            TokenTree::Delimited(span, _) | TokenTree::Sequence(span, _) => span.entire(),\n+        }\n+    }\n+\n+    crate fn token(kind: TokenKind, span: Span) -> TokenTree {\n+        TokenTree::Token(Token::new(kind, span))\n+    }\n+}"}, {"sha": "a3750e5c46945097d545618dff754560dd2b75b9", "filename": "src/libsyntax/ext/mbe/macro_check.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_check.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_check.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_check.rs?ref=9fd75f52877a3e23a7b9a6a9675f37a42340a428", "patch": "@@ -106,7 +106,7 @@\n //! bound.\n use crate::ast::NodeId;\n use crate::early_buffered_lints::BufferedEarlyLintId;\n-use crate::ext::mbe::quoted::{KleeneToken, TokenTree};\n+use crate::ext::mbe::{KleeneToken, TokenTree};\n use crate::parse::token::TokenKind;\n use crate::parse::token::{DelimToken, Token};\n use crate::parse::ParseSess;"}, {"sha": "35fc6cf21b80e32f72ded6c495bdd5736cd2cbed", "filename": "src/libsyntax/ext/mbe/macro_parser.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_parser.rs?ref=9fd75f52877a3e23a7b9a6a9675f37a42340a428", "patch": "@@ -75,7 +75,7 @@ crate use ParseResult::*;\n use TokenTreeOrTokenTreeSlice::*;\n \n use crate::ast::{Ident, Name};\n-use crate::ext::mbe::quoted::{self, TokenTree};\n+use crate::ext::mbe::{self, TokenTree};\n use crate::parse::{Directory, ParseSess};\n use crate::parse::parser::{Parser, PathStyle};\n use crate::parse::token::{self, DocComment, Nonterminal, Token};\n@@ -195,7 +195,7 @@ struct MatcherPos<'root, 'tt> {\n     // `None`.\n \n     /// The KleeneOp of this sequence if we are in a repetition.\n-    seq_op: Option<quoted::KleeneOp>,\n+    seq_op: Option<mbe::KleeneOp>,\n \n     /// The separator if we are in a repetition.\n     sep: Option<Token>,\n@@ -532,7 +532,7 @@ fn inner_parse_loop<'root, 'tt>(\n                 }\n                 // We don't need a separator. Move the \"dot\" back to the beginning of the matcher\n                 // and try to match again UNLESS we are only allowed to have _one_ repetition.\n-                else if item.seq_op != Some(quoted::KleeneOp::ZeroOrOne) {\n+                else if item.seq_op != Some(mbe::KleeneOp::ZeroOrOne) {\n                     item.match_cur = item.match_lo;\n                     item.idx = 0;\n                     cur_items.push(item);\n@@ -555,8 +555,8 @@ fn inner_parse_loop<'root, 'tt>(\n                     // implicitly disallowing OneOrMore from having 0 matches here. Thus, that will\n                     // result in a \"no rules expected token\" error by virtue of this matcher not\n                     // working.\n-                    if seq.kleene.op == quoted::KleeneOp::ZeroOrMore\n-                        || seq.kleene.op == quoted::KleeneOp::ZeroOrOne\n+                    if seq.kleene.op == mbe::KleeneOp::ZeroOrMore\n+                        || seq.kleene.op == mbe::KleeneOp::ZeroOrOne\n                     {\n                         let mut new_item = item.clone();\n                         new_item.match_cur += seq.num_captures;"}, {"sha": "2ec171a7fb5910f6ac5e270197ba1436f2893933", "filename": "src/libsyntax/ext/mbe/macro_rules.rs", "status": "modified", "additions": 58, "deletions": 58, "changes": 116, "blob_url": "https://github.com/rust-lang/rust/blob/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmbe%2Fmacro_rules.rs?ref=9fd75f52877a3e23a7b9a6a9675f37a42340a428", "patch": "@@ -4,11 +4,11 @@ use crate::edition::Edition;\n use crate::ext::base::{DummyResult, ExtCtxt, MacResult, TTMacroExpander};\n use crate::ext::base::{SyntaxExtension, SyntaxExtensionKind};\n use crate::ext::expand::{AstFragment, AstFragmentKind};\n+use crate::ext::mbe;\n use crate::ext::mbe::macro_check;\n use crate::ext::mbe::macro_parser::{parse, parse_failure_msg};\n use crate::ext::mbe::macro_parser::{Error, Failure, Success};\n use crate::ext::mbe::macro_parser::{MatchedNonterminal, MatchedSeq};\n-use crate::ext::mbe::quoted;\n use crate::ext::mbe::transcribe::transcribe;\n use crate::feature_gate::Features;\n use crate::parse::parser::Parser;\n@@ -135,8 +135,8 @@ struct MacroRulesMacroExpander {\n     name: ast::Ident,\n     span: Span,\n     transparency: Transparency,\n-    lhses: Vec<quoted::TokenTree>,\n-    rhses: Vec<quoted::TokenTree>,\n+    lhses: Vec<mbe::TokenTree>,\n+    rhses: Vec<mbe::TokenTree>,\n     valid: bool,\n }\n \n@@ -169,8 +169,8 @@ fn generic_extension<'cx>(\n     name: ast::Ident,\n     transparency: Transparency,\n     arg: TokenStream,\n-    lhses: &[quoted::TokenTree],\n-    rhses: &[quoted::TokenTree],\n+    lhses: &[mbe::TokenTree],\n+    rhses: &[mbe::TokenTree],\n ) -> Box<dyn MacResult + 'cx> {\n     if cx.trace_macros() {\n         trace_macros_note(cx, sp, format!(\"expanding `{}! {{ {} }}`\", name, arg));\n@@ -182,15 +182,15 @@ fn generic_extension<'cx>(\n     for (i, lhs) in lhses.iter().enumerate() {\n         // try each arm's matchers\n         let lhs_tt = match *lhs {\n-            quoted::TokenTree::Delimited(_, ref delim) => &delim.tts[..],\n+            mbe::TokenTree::Delimited(_, ref delim) => &delim.tts[..],\n             _ => cx.span_bug(sp, \"malformed macro lhs\"),\n         };\n \n         match TokenTree::parse(cx, lhs_tt, arg.clone()) {\n             Success(named_matches) => {\n                 let rhs = match rhses[i] {\n                     // ignore delimiters\n-                    quoted::TokenTree::Delimited(_, ref delimed) => delimed.tts.clone(),\n+                    mbe::TokenTree::Delimited(_, ref delimed) => delimed.tts.clone(),\n                     _ => cx.span_bug(sp, \"malformed macro rhs\"),\n                 };\n                 let arm_span = rhses[i].span();\n@@ -258,7 +258,7 @@ fn generic_extension<'cx>(\n         for lhs in lhses {\n             // try each arm's matchers\n             let lhs_tt = match *lhs {\n-                quoted::TokenTree::Delimited(_, ref delim) => &delim.tts[..],\n+                mbe::TokenTree::Delimited(_, ref delim) => &delim.tts[..],\n                 _ => continue,\n             };\n             match TokenTree::parse(cx, lhs_tt, arg.clone()) {\n@@ -312,32 +312,32 @@ pub fn compile_declarative_macro(\n     // ...quasiquoting this would be nice.\n     // These spans won't matter, anyways\n     let argument_gram = vec![\n-        quoted::TokenTree::Sequence(\n+        mbe::TokenTree::Sequence(\n             DelimSpan::dummy(),\n-            Lrc::new(quoted::SequenceRepetition {\n+            Lrc::new(mbe::SequenceRepetition {\n                 tts: vec![\n-                    quoted::TokenTree::MetaVarDecl(def.span, lhs_nm, tt_spec),\n-                    quoted::TokenTree::token(token::FatArrow, def.span),\n-                    quoted::TokenTree::MetaVarDecl(def.span, rhs_nm, tt_spec),\n+                    mbe::TokenTree::MetaVarDecl(def.span, lhs_nm, tt_spec),\n+                    mbe::TokenTree::token(token::FatArrow, def.span),\n+                    mbe::TokenTree::MetaVarDecl(def.span, rhs_nm, tt_spec),\n                 ],\n                 separator: Some(Token::new(\n                     if body.legacy { token::Semi } else { token::Comma },\n                     def.span,\n                 )),\n-                kleene: quoted::KleeneToken::new(quoted::KleeneOp::OneOrMore, def.span),\n+                kleene: mbe::KleeneToken::new(mbe::KleeneOp::OneOrMore, def.span),\n                 num_captures: 2,\n             }),\n         ),\n         // to phase into semicolon-termination instead of semicolon-separation\n-        quoted::TokenTree::Sequence(\n+        mbe::TokenTree::Sequence(\n             DelimSpan::dummy(),\n-            Lrc::new(quoted::SequenceRepetition {\n-                tts: vec![quoted::TokenTree::token(\n+            Lrc::new(mbe::SequenceRepetition {\n+                tts: vec![mbe::TokenTree::token(\n                     if body.legacy { token::Semi } else { token::Comma },\n                     def.span,\n                 )],\n                 separator: None,\n-                kleene: quoted::KleeneToken::new(quoted::KleeneOp::ZeroOrMore, def.span),\n+                kleene: mbe::KleeneToken::new(mbe::KleeneOp::ZeroOrMore, def.span),\n                 num_captures: 0,\n             }),\n         ),\n@@ -367,7 +367,7 @@ pub fn compile_declarative_macro(\n             .map(|m| {\n                 if let MatchedNonterminal(ref nt) = *m {\n                     if let NtTT(ref tt) = **nt {\n-                        let tt = quoted::parse(\n+                        let tt = mbe::quoted::parse(\n                             tt.clone().into(),\n                             true,\n                             sess,\n@@ -384,7 +384,7 @@ pub fn compile_declarative_macro(\n                 }\n                 sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n             })\n-            .collect::<Vec<quoted::TokenTree>>(),\n+            .collect::<Vec<mbe::TokenTree>>(),\n         _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\"),\n     };\n \n@@ -394,7 +394,7 @@ pub fn compile_declarative_macro(\n             .map(|m| {\n                 if let MatchedNonterminal(ref nt) = *m {\n                     if let NtTT(ref tt) = **nt {\n-                        return quoted::parse(\n+                        return mbe::quoted::parse(\n                             tt.clone().into(),\n                             false,\n                             sess,\n@@ -409,7 +409,7 @@ pub fn compile_declarative_macro(\n                 }\n                 sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n             })\n-            .collect::<Vec<quoted::TokenTree>>(),\n+            .collect::<Vec<mbe::TokenTree>>(),\n         _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured rhs\"),\n     };\n \n@@ -454,11 +454,11 @@ fn check_lhs_nt_follows(\n     sess: &ParseSess,\n     features: &Features,\n     attrs: &[ast::Attribute],\n-    lhs: &quoted::TokenTree,\n+    lhs: &mbe::TokenTree,\n ) -> bool {\n     // lhs is going to be like TokenTree::Delimited(...), where the\n     // entire lhs is those tts. Or, it can be a \"bare sequence\", not wrapped in parens.\n-    if let quoted::TokenTree::Delimited(_, ref tts) = *lhs {\n+    if let mbe::TokenTree::Delimited(_, ref tts) = *lhs {\n         check_matcher(sess, features, attrs, &tts.tts)\n     } else {\n         let msg = \"invalid macro matcher; matchers must be contained in balanced delimiters\";\n@@ -471,8 +471,8 @@ fn check_lhs_nt_follows(\n \n /// Checks that the lhs contains no repetition which could match an empty token\n /// tree, because then the matcher would hang indefinitely.\n-fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n-    use quoted::TokenTree;\n+fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[mbe::TokenTree]) -> bool {\n+    use mbe::TokenTree;\n     for tt in tts {\n         match *tt {\n             TokenTree::Token(..) | TokenTree::MetaVar(..) | TokenTree::MetaVarDecl(..) => (),\n@@ -486,8 +486,8 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n                     && seq.tts.iter().all(|seq_tt| match *seq_tt {\n                         TokenTree::MetaVarDecl(_, _, id) => id.name == sym::vis,\n                         TokenTree::Sequence(_, ref sub_seq) => {\n-                            sub_seq.kleene.op == quoted::KleeneOp::ZeroOrMore\n-                                || sub_seq.kleene.op == quoted::KleeneOp::ZeroOrOne\n+                            sub_seq.kleene.op == mbe::KleeneOp::ZeroOrMore\n+                                || sub_seq.kleene.op == mbe::KleeneOp::ZeroOrOne\n                         }\n                         _ => false,\n                     })\n@@ -506,9 +506,9 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n     true\n }\n \n-fn check_rhs(sess: &ParseSess, rhs: &quoted::TokenTree) -> bool {\n+fn check_rhs(sess: &ParseSess, rhs: &mbe::TokenTree) -> bool {\n     match *rhs {\n-        quoted::TokenTree::Delimited(..) => return true,\n+        mbe::TokenTree::Delimited(..) => return true,\n         _ => sess.span_diagnostic.span_err(rhs.span(), \"macro rhs must be delimited\"),\n     }\n     false\n@@ -518,7 +518,7 @@ fn check_matcher(\n     sess: &ParseSess,\n     features: &Features,\n     attrs: &[ast::Attribute],\n-    matcher: &[quoted::TokenTree],\n+    matcher: &[mbe::TokenTree],\n ) -> bool {\n     let first_sets = FirstSets::new(matcher);\n     let empty_suffix = TokenSet::empty();\n@@ -550,8 +550,8 @@ struct FirstSets {\n }\n \n impl FirstSets {\n-    fn new(tts: &[quoted::TokenTree]) -> FirstSets {\n-        use quoted::TokenTree;\n+    fn new(tts: &[mbe::TokenTree]) -> FirstSets {\n+        use mbe::TokenTree;\n \n         let mut sets = FirstSets { first: FxHashMap::default() };\n         build_recur(&mut sets, tts);\n@@ -598,8 +598,8 @@ impl FirstSets {\n \n                         // Reverse scan: Sequence comes before `first`.\n                         if subfirst.maybe_empty\n-                            || seq_rep.kleene.op == quoted::KleeneOp::ZeroOrMore\n-                            || seq_rep.kleene.op == quoted::KleeneOp::ZeroOrOne\n+                            || seq_rep.kleene.op == mbe::KleeneOp::ZeroOrMore\n+                            || seq_rep.kleene.op == mbe::KleeneOp::ZeroOrOne\n                         {\n                             // If sequence is potentially empty, then\n                             // union them (preserving first emptiness).\n@@ -619,8 +619,8 @@ impl FirstSets {\n \n     // walks forward over `tts` until all potential FIRST tokens are\n     // identified.\n-    fn first(&self, tts: &[quoted::TokenTree]) -> TokenSet {\n-        use quoted::TokenTree;\n+    fn first(&self, tts: &[mbe::TokenTree]) -> TokenSet {\n+        use mbe::TokenTree;\n \n         let mut first = TokenSet::empty();\n         for tt in tts.iter() {\n@@ -656,8 +656,8 @@ impl FirstSets {\n                     assert!(first.maybe_empty);\n                     first.add_all(subfirst);\n                     if subfirst.maybe_empty\n-                        || seq_rep.kleene.op == quoted::KleeneOp::ZeroOrMore\n-                        || seq_rep.kleene.op == quoted::KleeneOp::ZeroOrOne\n+                        || seq_rep.kleene.op == mbe::KleeneOp::ZeroOrMore\n+                        || seq_rep.kleene.op == mbe::KleeneOp::ZeroOrOne\n                     {\n                         // Continue scanning for more first\n                         // tokens, but also make sure we\n@@ -678,7 +678,7 @@ impl FirstSets {\n     }\n }\n \n-// A set of `quoted::TokenTree`s, which may include `TokenTree::Match`s\n+// A set of `mbe::TokenTree`s, which may include `TokenTree::Match`s\n // (for macro-by-example syntactic variables). It also carries the\n // `maybe_empty` flag; that is true if and only if the matcher can\n // match an empty token sequence.\n@@ -690,7 +690,7 @@ impl FirstSets {\n // (Notably, we must allow for *-op to occur zero times.)\n #[derive(Clone, Debug)]\n struct TokenSet {\n-    tokens: Vec<quoted::TokenTree>,\n+    tokens: Vec<mbe::TokenTree>,\n     maybe_empty: bool,\n }\n \n@@ -702,13 +702,13 @@ impl TokenSet {\n \n     // Returns the set `{ tok }` for the single-token (and thus\n     // non-empty) sequence [tok].\n-    fn singleton(tok: quoted::TokenTree) -> Self {\n+    fn singleton(tok: mbe::TokenTree) -> Self {\n         TokenSet { tokens: vec![tok], maybe_empty: false }\n     }\n \n     // Changes self to be the set `{ tok }`.\n     // Since `tok` is always present, marks self as non-empty.\n-    fn replace_with(&mut self, tok: quoted::TokenTree) {\n+    fn replace_with(&mut self, tok: mbe::TokenTree) {\n         self.tokens.clear();\n         self.tokens.push(tok);\n         self.maybe_empty = false;\n@@ -723,15 +723,15 @@ impl TokenSet {\n     }\n \n     // Adds `tok` to the set for `self`, marking sequence as non-empy.\n-    fn add_one(&mut self, tok: quoted::TokenTree) {\n+    fn add_one(&mut self, tok: mbe::TokenTree) {\n         if !self.tokens.contains(&tok) {\n             self.tokens.push(tok);\n         }\n         self.maybe_empty = false;\n     }\n \n     // Adds `tok` to the set for `self`. (Leaves `maybe_empty` flag alone.)\n-    fn add_one_maybe(&mut self, tok: quoted::TokenTree) {\n+    fn add_one_maybe(&mut self, tok: mbe::TokenTree) {\n         if !self.tokens.contains(&tok) {\n             self.tokens.push(tok);\n         }\n@@ -772,10 +772,10 @@ fn check_matcher_core(\n     features: &Features,\n     attrs: &[ast::Attribute],\n     first_sets: &FirstSets,\n-    matcher: &[quoted::TokenTree],\n+    matcher: &[mbe::TokenTree],\n     follow: &TokenSet,\n ) -> TokenSet {\n-    use quoted::TokenTree;\n+    use mbe::TokenTree;\n \n     let mut last = TokenSet::empty();\n \n@@ -950,8 +950,8 @@ fn check_matcher_core(\n     last\n }\n \n-fn token_can_be_followed_by_any(tok: &quoted::TokenTree) -> bool {\n-    if let quoted::TokenTree::MetaVarDecl(_, _, frag_spec) = *tok {\n+fn token_can_be_followed_by_any(tok: &mbe::TokenTree) -> bool {\n+    if let mbe::TokenTree::MetaVarDecl(_, _, frag_spec) = *tok {\n         frag_can_be_followed_by_any(frag_spec.name)\n     } else {\n         // (Non NT's can always be followed by anthing in matchers.)\n@@ -997,8 +997,8 @@ enum IsInFollow {\n /// break macros that were relying on that binary operator as a\n /// separator.\n // when changing this do not forget to update doc/book/macros.md!\n-fn is_in_follow(tok: &quoted::TokenTree, frag: Symbol) -> IsInFollow {\n-    use quoted::TokenTree;\n+fn is_in_follow(tok: &mbe::TokenTree, frag: Symbol) -> IsInFollow {\n+    use mbe::TokenTree;\n \n     if let TokenTree::Token(Token { kind: token::CloseDelim(_), .. }) = *tok {\n         // closing a token tree can never be matched by any fragment;\n@@ -1116,10 +1116,10 @@ fn has_legal_fragment_specifier(\n     sess: &ParseSess,\n     features: &Features,\n     attrs: &[ast::Attribute],\n-    tok: &quoted::TokenTree,\n+    tok: &mbe::TokenTree,\n ) -> Result<(), String> {\n     debug!(\"has_legal_fragment_specifier({:?})\", tok);\n-    if let quoted::TokenTree::MetaVarDecl(_, _, ref frag_spec) = *tok {\n+    if let mbe::TokenTree::MetaVarDecl(_, _, ref frag_spec) = *tok {\n         let frag_span = tok.span();\n         if !is_legal_fragment_specifier(sess, features, attrs, frag_spec.name, frag_span) {\n             return Err(frag_spec.to_string());\n@@ -1160,13 +1160,13 @@ fn is_legal_fragment_specifier(\n     }\n }\n \n-fn quoted_tt_to_string(tt: &quoted::TokenTree) -> String {\n+fn quoted_tt_to_string(tt: &mbe::TokenTree) -> String {\n     match *tt {\n-        quoted::TokenTree::Token(ref token) => crate::print::pprust::token_to_string(&token),\n-        quoted::TokenTree::MetaVar(_, name) => format!(\"${}\", name),\n-        quoted::TokenTree::MetaVarDecl(_, name, kind) => format!(\"${}:{}\", name, kind),\n+        mbe::TokenTree::Token(ref token) => crate::print::pprust::token_to_string(&token),\n+        mbe::TokenTree::MetaVar(_, name) => format!(\"${}\", name),\n+        mbe::TokenTree::MetaVarDecl(_, name, kind) => format!(\"${}:{}\", name, kind),\n         _ => panic!(\n-            \"unexpected quoted::TokenTree::{{Sequence or Delimited}} \\\n+            \"unexpected mbe::TokenTree::{{Sequence or Delimited}} \\\n              in follow set checker\"\n         ),\n     }"}, {"sha": "82289d7449d36c47257719e7e2ac3b574049f77a", "filename": "src/libsyntax/ext/mbe/quoted.rs", "status": "modified", "additions": 4, "deletions": 151, "changes": 155, "blob_url": "https://github.com/rust-lang/rust/blob/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmbe%2Fquoted.rs?ref=9fd75f52877a3e23a7b9a6a9675f37a42340a428", "patch": "@@ -1,166 +1,19 @@\n use crate::ast;\n use crate::ast::NodeId;\n use crate::ext::mbe::macro_parser;\n+use crate::ext::mbe::{TokenTree, KleeneOp, KleeneToken, SequenceRepetition, Delimited};\n use crate::feature_gate::Features;\n-use crate::parse::token::{self, Token, TokenKind};\n+use crate::parse::token::{self, Token};\n use crate::parse::ParseSess;\n use crate::print::pprust;\n use crate::symbol::kw;\n-use crate::tokenstream::{self, DelimSpan};\n+use crate::tokenstream;\n \n-use syntax_pos::{edition::Edition, BytePos, Span};\n+use syntax_pos::{edition::Edition, Span};\n \n use rustc_data_structures::sync::Lrc;\n use std::iter::Peekable;\n \n-/// Contains the sub-token-trees of a \"delimited\" token tree, such as the contents of `(`. Note\n-/// that the delimiter itself might be `NoDelim`.\n-#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n-crate struct Delimited {\n-    crate delim: token::DelimToken,\n-    crate tts: Vec<TokenTree>,\n-}\n-\n-impl Delimited {\n-    /// Returns a `self::TokenTree` with a `Span` corresponding to the opening delimiter.\n-    crate fn open_tt(&self, span: Span) -> TokenTree {\n-        let open_span = if span.is_dummy() {\n-            span\n-        } else {\n-            span.with_hi(span.lo() + BytePos(self.delim.len() as u32))\n-        };\n-        TokenTree::token(token::OpenDelim(self.delim), open_span)\n-    }\n-\n-    /// Returns a `self::TokenTree` with a `Span` corresponding to the closing delimiter.\n-    crate fn close_tt(&self, span: Span) -> TokenTree {\n-        let close_span = if span.is_dummy() {\n-            span\n-        } else {\n-            span.with_lo(span.hi() - BytePos(self.delim.len() as u32))\n-        };\n-        TokenTree::token(token::CloseDelim(self.delim), close_span)\n-    }\n-}\n-\n-#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n-crate struct SequenceRepetition {\n-    /// The sequence of token trees\n-    crate tts: Vec<TokenTree>,\n-    /// The optional separator\n-    crate separator: Option<Token>,\n-    /// Whether the sequence can be repeated zero (*), or one or more times (+)\n-    crate kleene: KleeneToken,\n-    /// The number of `Match`s that appear in the sequence (and subsequences)\n-    crate num_captures: usize,\n-}\n-\n-#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Debug, Copy)]\n-crate struct KleeneToken {\n-    crate span: Span,\n-    crate op: KleeneOp,\n-}\n-\n-impl KleeneToken {\n-    crate fn new(op: KleeneOp, span: Span) -> KleeneToken {\n-        KleeneToken { span, op }\n-    }\n-}\n-\n-/// A Kleene-style [repetition operator](http://en.wikipedia.org/wiki/Kleene_star)\n-/// for token sequences.\n-#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n-crate enum KleeneOp {\n-    /// Kleene star (`*`) for zero or more repetitions\n-    ZeroOrMore,\n-    /// Kleene plus (`+`) for one or more repetitions\n-    OneOrMore,\n-    /// Kleene optional (`?`) for zero or one reptitions\n-    ZeroOrOne,\n-}\n-\n-/// Similar to `tokenstream::TokenTree`, except that `$i`, `$i:ident`, and `$(...)`\n-/// are \"first-class\" token trees. Useful for parsing macros.\n-#[derive(Debug, Clone, PartialEq, RustcEncodable, RustcDecodable)]\n-crate enum TokenTree {\n-    Token(Token),\n-    Delimited(DelimSpan, Lrc<Delimited>),\n-    /// A kleene-style repetition sequence\n-    Sequence(DelimSpan, Lrc<SequenceRepetition>),\n-    /// e.g., `$var`\n-    MetaVar(Span, ast::Ident),\n-    /// e.g., `$var:expr`. This is only used in the left hand side of MBE macros.\n-    MetaVarDecl(\n-        Span,\n-        ast::Ident, /* name to bind */\n-        ast::Ident, /* kind of nonterminal */\n-    ),\n-}\n-\n-impl TokenTree {\n-    /// Return the number of tokens in the tree.\n-    crate fn len(&self) -> usize {\n-        match *self {\n-            TokenTree::Delimited(_, ref delimed) => match delimed.delim {\n-                token::NoDelim => delimed.tts.len(),\n-                _ => delimed.tts.len() + 2,\n-            },\n-            TokenTree::Sequence(_, ref seq) => seq.tts.len(),\n-            _ => 0,\n-        }\n-    }\n-\n-    /// Returns `true` if the given token tree is delimited.\n-    crate fn is_delimited(&self) -> bool {\n-        match *self {\n-            TokenTree::Delimited(..) => true,\n-            _ => false,\n-        }\n-    }\n-\n-    /// Returns `true` if the given token tree is a token of the given kind.\n-    crate fn is_token(&self, expected_kind: &TokenKind) -> bool {\n-        match self {\n-            TokenTree::Token(Token { kind: actual_kind, .. }) => actual_kind == expected_kind,\n-            _ => false,\n-        }\n-    }\n-\n-    /// Gets the `index`-th sub-token-tree. This only makes sense for delimited trees and sequences.\n-    crate fn get_tt(&self, index: usize) -> TokenTree {\n-        match (self, index) {\n-            (&TokenTree::Delimited(_, ref delimed), _) if delimed.delim == token::NoDelim => {\n-                delimed.tts[index].clone()\n-            }\n-            (&TokenTree::Delimited(span, ref delimed), _) => {\n-                if index == 0 {\n-                    return delimed.open_tt(span.open);\n-                }\n-                if index == delimed.tts.len() + 1 {\n-                    return delimed.close_tt(span.close);\n-                }\n-                delimed.tts[index - 1].clone()\n-            }\n-            (&TokenTree::Sequence(_, ref seq), _) => seq.tts[index].clone(),\n-            _ => panic!(\"Cannot expand a token tree\"),\n-        }\n-    }\n-\n-    /// Retrieves the `TokenTree`'s span.\n-    crate fn span(&self) -> Span {\n-        match *self {\n-            TokenTree::Token(Token { span, .. })\n-            | TokenTree::MetaVar(span, _)\n-            | TokenTree::MetaVarDecl(span, _, _) => span,\n-            TokenTree::Delimited(span, _) | TokenTree::Sequence(span, _) => span.entire(),\n-        }\n-    }\n-\n-    crate fn token(kind: TokenKind, span: Span) -> TokenTree {\n-        TokenTree::Token(Token::new(kind, span))\n-    }\n-}\n-\n /// Takes a `tokenstream::TokenStream` and returns a `Vec<self::TokenTree>`. Specifically, this\n /// takes a generic `TokenStream`, such as is used in the rest of the compiler, and returns a\n /// collection of `TokenTree` for use in parsing a macro."}, {"sha": "ba818ebd35c7fdb1aac48e40b0417b7abfb59e51", "filename": "src/libsyntax/ext/mbe/transcribe.rs", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs?ref=9fd75f52877a3e23a7b9a6a9675f37a42340a428", "patch": "@@ -1,7 +1,7 @@\n use crate::ast::{Ident, Mac};\n use crate::ext::base::ExtCtxt;\n+use crate::ext::mbe;\n use crate::ext::mbe::macro_parser::{MatchedNonterminal, MatchedSeq, NamedMatch};\n-use crate::ext::mbe::quoted;\n use crate::mut_visit::{self, MutVisitor};\n use crate::parse::token::{self, NtTT, Token};\n use crate::tokenstream::{DelimSpan, TokenStream, TokenTree, TreeAndJoint};\n@@ -38,22 +38,22 @@ impl Marker {\n \n /// An iterator over the token trees in a delimited token tree (`{ ... }`) or a sequence (`$(...)`).\n enum Frame {\n-    Delimited { forest: Lrc<quoted::Delimited>, idx: usize, span: DelimSpan },\n-    Sequence { forest: Lrc<quoted::SequenceRepetition>, idx: usize, sep: Option<Token> },\n+    Delimited { forest: Lrc<mbe::Delimited>, idx: usize, span: DelimSpan },\n+    Sequence { forest: Lrc<mbe::SequenceRepetition>, idx: usize, sep: Option<Token> },\n }\n \n impl Frame {\n     /// Construct a new frame around the delimited set of tokens.\n-    fn new(tts: Vec<quoted::TokenTree>) -> Frame {\n-        let forest = Lrc::new(quoted::Delimited { delim: token::NoDelim, tts });\n+    fn new(tts: Vec<mbe::TokenTree>) -> Frame {\n+        let forest = Lrc::new(mbe::Delimited { delim: token::NoDelim, tts });\n         Frame::Delimited { forest, idx: 0, span: DelimSpan::dummy() }\n     }\n }\n \n impl Iterator for Frame {\n-    type Item = quoted::TokenTree;\n+    type Item = mbe::TokenTree;\n \n-    fn next(&mut self) -> Option<quoted::TokenTree> {\n+    fn next(&mut self) -> Option<mbe::TokenTree> {\n         match *self {\n             Frame::Delimited { ref forest, ref mut idx, .. } => {\n                 *idx += 1;\n@@ -90,7 +90,7 @@ impl Iterator for Frame {\n pub(super) fn transcribe(\n     cx: &ExtCtxt<'_>,\n     interp: &FxHashMap<Ident, NamedMatch>,\n-    src: Vec<quoted::TokenTree>,\n+    src: Vec<mbe::TokenTree>,\n     transparency: Transparency,\n ) -> TokenStream {\n     // Nothing for us to transcribe...\n@@ -178,7 +178,7 @@ pub(super) fn transcribe(\n             // We are descending into a sequence. We first make sure that the matchers in the RHS\n             // and the matches in `interp` have the same shape. Otherwise, either the caller or the\n             // macro writer has made a mistake.\n-            seq @ quoted::TokenTree::Sequence(..) => {\n+            seq @ mbe::TokenTree::Sequence(..) => {\n                 match lockstep_iter_size(&seq, interp, &repeats) {\n                     LockstepIterSize::Unconstrained => {\n                         cx.span_fatal(\n@@ -199,15 +199,15 @@ pub(super) fn transcribe(\n                     LockstepIterSize::Constraint(len, _) => {\n                         // We do this to avoid an extra clone above. We know that this is a\n                         // sequence already.\n-                        let (sp, seq) = if let quoted::TokenTree::Sequence(sp, seq) = seq {\n+                        let (sp, seq) = if let mbe::TokenTree::Sequence(sp, seq) = seq {\n                             (sp, seq)\n                         } else {\n                             unreachable!()\n                         };\n \n                         // Is the repetition empty?\n                         if len == 0 {\n-                            if seq.kleene.op == quoted::KleeneOp::OneOrMore {\n+                            if seq.kleene.op == mbe::KleeneOp::OneOrMore {\n                                 // FIXME: this really ought to be caught at macro definition\n                                 // time... It happens when the Kleene operator in the matcher and\n                                 // the body for the same meta-variable do not match.\n@@ -232,7 +232,7 @@ pub(super) fn transcribe(\n             }\n \n             // Replace the meta-var with the matched token tree from the invocation.\n-            quoted::TokenTree::MetaVar(mut sp, mut ident) => {\n+            mbe::TokenTree::MetaVar(mut sp, mut ident) => {\n                 // Find the matched nonterminal from the macro invocation, and use it to replace\n                 // the meta-var.\n                 if let Some(cur_matched) = lookup_cur_matched(ident, interp, &repeats) {\n@@ -269,22 +269,22 @@ pub(super) fn transcribe(\n             // We will produce all of the results of the inside of the `Delimited` and then we will\n             // jump back out of the Delimited, pop the result_stack and add the new results back to\n             // the previous results (from outside the Delimited).\n-            quoted::TokenTree::Delimited(mut span, delimited) => {\n+            mbe::TokenTree::Delimited(mut span, delimited) => {\n                 marker.visit_delim_span(&mut span);\n                 stack.push(Frame::Delimited { forest: delimited, idx: 0, span });\n                 result_stack.push(mem::take(&mut result));\n             }\n \n             // Nothing much to do here. Just push the token to the result, being careful to\n             // preserve syntax context.\n-            quoted::TokenTree::Token(token) => {\n+            mbe::TokenTree::Token(token) => {\n                 let mut tt = TokenTree::Token(token);\n                 marker.visit_tt(&mut tt);\n                 result.push(tt.into());\n             }\n \n             // There should be no meta-var declarations in the invocation of a macro.\n-            quoted::TokenTree::MetaVarDecl(..) => panic!(\"unexpected `TokenTree::MetaVarDecl\"),\n+            mbe::TokenTree::MetaVarDecl(..) => panic!(\"unexpected `TokenTree::MetaVarDecl\"),\n         }\n     }\n }\n@@ -368,11 +368,11 @@ impl LockstepIterSize {\n /// `lookup_cur_matched` will return `None`, which is why this still works even in the presnece of\n /// multiple nested matcher sequences.\n fn lockstep_iter_size(\n-    tree: &quoted::TokenTree,\n+    tree: &mbe::TokenTree,\n     interpolations: &FxHashMap<Ident, NamedMatch>,\n     repeats: &[(usize, usize)],\n ) -> LockstepIterSize {\n-    use quoted::TokenTree;\n+    use mbe::TokenTree;\n     match *tree {\n         TokenTree::Delimited(_, ref delimed) => {\n             delimed.tts.iter().fold(LockstepIterSize::Unconstrained, |size, tt| {"}, {"sha": "fd87f8a1f678a3d83d108698ca17e9c27a575c93", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9fd75f52877a3e23a7b9a6a9675f37a42340a428/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=9fd75f52877a3e23a7b9a6a9675f37a42340a428", "patch": "@@ -14,7 +14,7 @@\n //! ownership of the original.\n \n use crate::ext::base;\n-use crate::ext::mbe::{macro_parser, quoted};\n+use crate::ext::mbe::{self, macro_parser};\n use crate::parse::Directory;\n use crate::parse::token::{self, DelimToken, Token, TokenKind};\n use crate::print::pprust;\n@@ -64,7 +64,7 @@ where\n \n impl TokenTree {\n     /// Use this token tree as a matcher to parse given tts.\n-    crate fn parse(cx: &base::ExtCtxt<'_>, mtch: &[quoted::TokenTree], tts: TokenStream)\n+    crate fn parse(cx: &base::ExtCtxt<'_>, mtch: &[mbe::TokenTree], tts: TokenStream)\n                  -> macro_parser::NamedParseResult {\n         // `None` is because we're not interpolating\n         let directory = Directory {"}]}