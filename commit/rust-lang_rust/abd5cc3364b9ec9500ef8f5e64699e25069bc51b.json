{"sha": "abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFiZDVjYzMzNjRiOWVjOTUwMGVmOGY1ZTY0Njk5ZTI1MDY5YmM1MWI=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2018-08-31T13:18:08Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2018-08-31T13:22:52Z"}, "message": "Always add all modules to the global ThinLTO module analysis when compiling incrementally.", "tree": {"sha": "d2cbe1a0ae30864067529fc06697c181fe18e276", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d2cbe1a0ae30864067529fc06697c181fe18e276"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "html_url": "https://github.com/rust-lang/rust/commit/abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "64a738d8ce457b8d9b3a750ca61835214b6b438c", "url": "https://api.github.com/repos/rust-lang/rust/commits/64a738d8ce457b8d9b3a750ca61835214b6b438c", "html_url": "https://github.com/rust-lang/rust/commit/64a738d8ce457b8d9b3a750ca61835214b6b438c"}], "stats": {"total": 531, "additions": 170, "deletions": 361}, "files": [{"sha": "defb5b9869d822f9d37e73775daa80738bf41b6d", "filename": "src/Cargo.lock", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "patch": "@@ -1198,6 +1198,15 @@ dependencies = [\n  \"libc 0.2.43 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]\n \n+[[package]]\n+name = \"memmap\"\n+version = \"0.6.2\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+dependencies = [\n+ \"libc 0.2.43 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"winapi 0.3.5 (registry+https://github.com/rust-lang/crates.io-index)\",\n+]\n+\n [[package]]\n name = \"memoffset\"\n version = \"0.2.1\"\n@@ -2029,6 +2038,7 @@ name = \"rustc_codegen_llvm\"\n version = \"0.0.0\"\n dependencies = [\n  \"cc 1.0.22 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"memmap 0.6.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"num_cpus 1.8.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc-demangle 0.1.9 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc_llvm 0.0.0\",\n@@ -3151,6 +3161,7 @@ source = \"registry+https://github.com/rust-lang/crates.io-index\"\n \"checksum matches 0.1.8 (registry+https://github.com/rust-lang/crates.io-index)\" = \"7ffc5c5338469d4d3ea17d269fa8ea3512ad247247c30bd2df69e68309ed0a08\"\n \"checksum mdbook 0.1.7 (registry+https://github.com/rust-lang/crates.io-index)\" = \"90b5a8d7e341ceee5db3882a06078d42661ddcfa2b3687319cc5da76ec4e782f\"\n \"checksum memchr 2.0.2 (registry+https://github.com/rust-lang/crates.io-index)\" = \"a3b4142ab8738a78c51896f704f83c11df047ff1bda9a92a661aa6361552d93d\"\n+\"checksum memmap 0.6.2 (registry+https://github.com/rust-lang/crates.io-index)\" = \"e2ffa2c986de11a9df78620c01eeaaf27d94d3ff02bf81bfcca953102dd0c6ff\"\n \"checksum memoffset 0.2.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"0f9dc261e2b62d7a622bf416ea3c5245cdd5d9a7fcc428c0d06804dfce1775b3\"\n \"checksum minifier 0.0.19 (registry+https://github.com/rust-lang/crates.io-index)\" = \"9908ed7c62f990c21ab41fdca53a864a3ada0da69d8729c4de727b397e27bc11\"\n \"checksum miniz-sys 0.1.10 (registry+https://github.com/rust-lang/crates.io-index)\" = \"609ce024854aeb19a0ef7567d348aaa5a746b32fb72e336df7fcc16869d7e2b4\""}, {"sha": "4df0fc443a27c6ed2fcc246cc607fad247f12adb", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "patch": "@@ -883,7 +883,6 @@ pub enum WorkProductFileKind {\n     Object,\n     Bytecode,\n     BytecodeCompressed,\n-    PreThinLtoBytecode,\n }\n \n pub(super) struct CurrentDepGraph {"}, {"sha": "6936a3067800d5139be9b20734dac80ed84c6740", "filename": "src/librustc_codegen_llvm/back/lto.rs", "status": "modified", "additions": 97, "deletions": 138, "changes": 235, "blob_url": "https://github.com/rust-lang/rust/blob/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs?ref=abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "patch": "@@ -11,33 +11,29 @@\n use back::bytecode::{DecodedBytecode, RLIB_BYTECODE_EXTENSION};\n use back::symbol_export;\n use back::write::{ModuleConfig, with_llvm_pmb, CodegenContext};\n-use back::write::{self, DiagnosticHandlers};\n+use back::write::{self, DiagnosticHandlers, pre_lto_bitcode_filename};\n use errors::{FatalError, Handler};\n use llvm::archive_ro::ArchiveRO;\n use llvm::{True, False};\n use llvm;\n use memmap;\n+use rustc::dep_graph::WorkProduct;\n use rustc::hir::def_id::LOCAL_CRATE;\n use rustc::middle::exported_symbols::SymbolExportLevel;\n use rustc::session::config::{self, Lto};\n use rustc::util::common::time_ext;\n-use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n+use rustc_data_structures::fx::FxHashMap;\n use time_graph::Timeline;\n use {ModuleCodegen, ModuleLlvm, ModuleKind};\n \n use libc;\n \n use std::ffi::{CStr, CString};\n use std::fs::File;\n-use std::io;\n-use std::mem;\n-use std::path::Path;\n use std::ptr;\n use std::slice;\n use std::sync::Arc;\n \n-pub const THIN_LTO_IMPORTS_INCR_COMP_FILE_NAME: &str = \"thin-lto-imports.bin\";\n-\n pub fn crate_type_allows_lto(crate_type: config::CrateType) -> bool {\n     match crate_type {\n         config::CrateType::Executable |\n@@ -105,11 +101,16 @@ impl LtoModuleCodegen {\n     }\n }\n \n+/// Performs LTO, which in the case of full LTO means merging all modules into\n+/// a single one and returning it for further optimizing. For ThinLTO, it will\n+/// do the global analysis necessary and return two lists, one of the modules\n+/// the need optimization and another for modules that can simply be copied over\n+/// from the incr. comp. cache.\n pub(crate) fn run(cgcx: &CodegenContext,\n                   modules: Vec<ModuleCodegen>,\n-                  import_only_modules: Vec<(SerializedModule, CString)>,\n+                  cached_modules: Vec<(SerializedModule, WorkProduct)>,\n                   timeline: &mut Timeline)\n-    -> Result<Vec<LtoModuleCodegen>, FatalError>\n+    -> Result<(Vec<LtoModuleCodegen>, Vec<WorkProduct>), FatalError>\n {\n     let diag_handler = cgcx.create_diag_handler();\n     let export_threshold = match cgcx.lto {\n@@ -202,13 +203,14 @@ pub(crate) fn run(cgcx: &CodegenContext,\n     match cgcx.lto {\n         Lto::Yes | // `-C lto` == fat LTO by default\n         Lto::Fat => {\n-            assert!(import_only_modules.is_empty());\n-            fat_lto(cgcx,\n-                    &diag_handler,\n-                    modules,\n-                    upstream_modules,\n-                    &symbol_white_list,\n-                    timeline)\n+            assert!(cached_modules.is_empty());\n+            let opt_jobs = fat_lto(cgcx,\n+                                  &diag_handler,\n+                                  modules,\n+                                  upstream_modules,\n+                                  &symbol_white_list,\n+                                  timeline);\n+            opt_jobs.map(|opt_jobs| (opt_jobs, vec![]))\n         }\n         Lto::Thin |\n         Lto::ThinLocal => {\n@@ -220,7 +222,7 @@ pub(crate) fn run(cgcx: &CodegenContext,\n                      &diag_handler,\n                      modules,\n                      upstream_modules,\n-                     import_only_modules,\n+                     cached_modules,\n                      &symbol_white_list,\n                      timeline)\n         }\n@@ -388,14 +390,19 @@ fn thin_lto(cgcx: &CodegenContext,\n             diag_handler: &Handler,\n             modules: Vec<ModuleCodegen>,\n             serialized_modules: Vec<(SerializedModule, CString)>,\n-            import_only_modules: Vec<(SerializedModule, CString)>,\n+            cached_modules: Vec<(SerializedModule, WorkProduct)>,\n             symbol_white_list: &[*const libc::c_char],\n             timeline: &mut Timeline)\n-    -> Result<Vec<LtoModuleCodegen>, FatalError>\n+    -> Result<(Vec<LtoModuleCodegen>, Vec<WorkProduct>), FatalError>\n {\n     unsafe {\n         info!(\"going for that thin, thin LTO\");\n \n+        let green_modules: FxHashMap<_, _> = cached_modules\n+            .iter()\n+            .map(|&(_, ref wp)| (wp.cgu_name.clone(), wp.clone()))\n+            .collect();\n+\n         let mut thin_buffers = Vec::new();\n         let mut module_names = Vec::new();\n         let mut thin_modules = Vec::new();\n@@ -411,6 +418,28 @@ fn thin_lto(cgcx: &CodegenContext,\n             info!(\"local module: {} - {}\", i, module.name);\n             let name = CString::new(module.name.clone()).unwrap();\n             let buffer = ThinBuffer::new(module.module_llvm.llmod());\n+\n+            // We emit the module after having serialized it into a ThinBuffer\n+            // because only then it will contain the ThinLTO module summary.\n+            if let Some(ref incr_comp_session_dir) = cgcx.incr_comp_session_dir {\n+                if cgcx.config(module.kind).emit_pre_thin_lto_bc {\n+                    use std::io::Write;\n+\n+                    let path = incr_comp_session_dir\n+                        .join(pre_lto_bitcode_filename(&module.name));\n+                    let mut file = File::create(&path).unwrap_or_else(|e| {\n+                        panic!(\"Failed to create pre-lto-bitcode file `{}`: {}\",\n+                               path.display(),\n+                               e);\n+                    });\n+                    file.write_all(buffer.data()).unwrap_or_else(|e| {\n+                        panic!(\"Error writing pre-lto-bitcode file `{}`: {}\",\n+                               path.display(),\n+                               e);\n+                    });\n+                }\n+            }\n+\n             thin_modules.push(llvm::ThinLTOModule {\n                 identifier: name.as_ptr(),\n                 data: buffer.data().as_ptr(),\n@@ -438,24 +467,13 @@ fn thin_lto(cgcx: &CodegenContext,\n         //        looking at upstream modules entirely sometimes (the contents,\n         //        we must always unconditionally look at the index).\n         let mut serialized = Vec::new();\n-        for (module, name) in serialized_modules {\n-            info!(\"foreign module {:?}\", name);\n-            thin_modules.push(llvm::ThinLTOModule {\n-                identifier: name.as_ptr(),\n-                data: module.data().as_ptr(),\n-                len: module.data().len(),\n-            });\n-            serialized.push(module);\n-            module_names.push(name);\n-        }\n \n-        // All the modules collected up to this point we actually want to\n-        // optimize. The `import_only_modules` below need to be in the list of\n-        // available modules but we don't need to run optimizations for them\n-        // since we already have their optimized version cached.\n-        let modules_to_optimize = module_names.len();\n-        for (module, name) in import_only_modules {\n-            info!(\"foreign module {:?}\", name);\n+        let cached_modules = cached_modules.into_iter().map(|(sm, wp)| {\n+            (sm, CString::new(wp.cgu_name).unwrap())\n+        });\n+\n+        for (module, name) in serialized_modules.into_iter().chain(cached_modules) {\n+            info!(\"upstream or cached module {:?}\", name);\n             thin_modules.push(llvm::ThinLTOModule {\n                 identifier: name.as_ptr(),\n                 data: module.data().as_ptr(),\n@@ -465,6 +483,9 @@ fn thin_lto(cgcx: &CodegenContext,\n             module_names.push(name);\n         }\n \n+        // Sanity check\n+        assert_eq!(thin_modules.len(), module_names.len());\n+\n         // Delegate to the C++ bindings to create some data here. Once this is a\n         // tried-and-true interface we may wish to try to upstream some of this\n         // to LLVM itself, right now we reimplement a lot of what they do\n@@ -478,30 +499,7 @@ fn thin_lto(cgcx: &CodegenContext,\n             write::llvm_err(&diag_handler, \"failed to prepare thin LTO context\".to_string())\n         })?;\n \n-        // Save the ThinLTO import information for incremental compilation.\n-        if let Some(ref incr_comp_session_dir) = cgcx.incr_comp_session_dir {\n-            let path = incr_comp_session_dir.join(THIN_LTO_IMPORTS_INCR_COMP_FILE_NAME);\n-\n-            // The import information from the current compilation session. It\n-            // does not contain info about modules that have been loaded from\n-            // the cache instead of having been recompiled...\n-            let current_imports = ThinLTOImports::from_thin_lto_data(data);\n-\n-            // ... so we load this additional information from the previous\n-            // cache file if necessary.\n-            let imports = if path.exists() {\n-                let prev_imports = ThinLTOImports::load_from_file(&path).unwrap();\n-                prev_imports.update(current_imports, &module_names)\n-            } else {\n-                current_imports\n-            };\n-\n-            if let Err(err) = imports.save_to_file(&path) {\n-                let msg = format!(\"Error while writing ThinLTO import data: {}\",\n-                                  err);\n-                return Err(write::llvm_err(&diag_handler, msg));\n-            }\n-        }\n+        let import_map = ThinLTOImports::from_thin_lto_data(data);\n \n         let data = ThinData(data);\n         info!(\"thin LTO data created\");\n@@ -517,12 +515,36 @@ fn thin_lto(cgcx: &CodegenContext,\n             serialized_modules: serialized,\n             module_names,\n         });\n-        Ok((0..modules_to_optimize).map(|i| {\n-            LtoModuleCodegen::Thin(ThinModule {\n+\n+        let mut copy_jobs = vec![];\n+        let mut opt_jobs = vec![];\n+\n+        for (module_index, module_name) in shared.module_names.iter().enumerate() {\n+            let module_name = module_name_to_str(module_name);\n+\n+            if green_modules.contains_key(module_name) {\n+                let mut imports_all_green = true;\n+                for imported_module in import_map.modules_imported_by(module_name) {\n+                    if !green_modules.contains_key(imported_module) {\n+                        imports_all_green = false;\n+                        break\n+                    }\n+                }\n+\n+                if imports_all_green {\n+                    let work_product = green_modules[module_name].clone();\n+                    copy_jobs.push(work_product);\n+                    continue\n+                }\n+            }\n+\n+            opt_jobs.push(LtoModuleCodegen::Thin(ThinModule {\n                 shared: shared.clone(),\n-                idx: i,\n-            })\n-        }).collect())\n+                idx: module_index,\n+            }));\n+        }\n+\n+        Ok((opt_jobs, copy_jobs))\n     }\n }\n \n@@ -850,44 +872,12 @@ pub struct ThinLTOImports {\n }\n \n impl ThinLTOImports {\n-    pub fn new() -> ThinLTOImports {\n-        ThinLTOImports {\n-            imports: FxHashMap(),\n-        }\n-    }\n-\n     pub fn modules_imported_by(&self, llvm_module_name: &str) -> &[String] {\n         self.imports.get(llvm_module_name).map(|v| &v[..]).unwrap_or(&[])\n     }\n \n-    pub fn update(mut self, new: ThinLTOImports, module_names: &[CString]) -> ThinLTOImports {\n-        let module_names: FxHashSet<_> = module_names.iter().map(|name| {\n-            name.clone().into_string().unwrap()\n-        }).collect();\n-\n-        // Remove all modules that don't exist anymore.\n-        self.imports.retain(|k, _| module_names.contains(k));\n-\n-        // Overwrite old values\n-        for (importing_module, imported_modules) in new.imports {\n-            self.imports.insert(importing_module, imported_modules);\n-        }\n-\n-        self\n-    }\n-\n     /// Load the ThinLTO import map from ThinLTOData.\n     unsafe fn from_thin_lto_data(data: *const llvm::ThinLTOData) -> ThinLTOImports {\n-        fn module_name_to_str(c_str: &CStr) -> &str {\n-            match c_str.to_str() {\n-                Ok(s) => s,\n-                Err(e) => {\n-                    bug!(\"Encountered non-utf8 LLVM module name `{}`: {}\",\n-                        c_str.to_string_lossy(),\n-                        e)\n-                }\n-            }\n-        }\n         unsafe extern \"C\" fn imported_module_callback(payload: *mut libc::c_void,\n                                                       importing_module_name: *const libc::c_char,\n                                                       imported_module_name: *const libc::c_char) {\n@@ -896,6 +886,7 @@ impl ThinLTOImports {\n             let importing_module_name = module_name_to_str(&importing_module_name);\n             let imported_module_name = CStr::from_ptr(imported_module_name);\n             let imported_module_name = module_name_to_str(&imported_module_name);\n+\n             if !map.imports.contains_key(importing_module_name) {\n                 map.imports.insert(importing_module_name.to_owned(), vec![]);\n             }\n@@ -913,47 +904,15 @@ impl ThinLTOImports {\n                                               &mut map as *mut _ as *mut libc::c_void);\n         map\n     }\n+}\n \n-    pub fn save_to_file(&self, path: &Path) -> io::Result<()> {\n-        use std::io::Write;\n-        let file = File::create(path)?;\n-        let mut writer = io::BufWriter::new(file);\n-        for (importing_module_name, imported_modules) in &self.imports {\n-            writeln!(writer, \"{}\", importing_module_name)?;\n-            for imported_module in imported_modules {\n-                writeln!(writer, \"  {}\", imported_module)?;\n-            }\n-            writeln!(writer)?;\n-        }\n-        Ok(())\n-    }\n-\n-    pub fn load_from_file(path: &Path) -> io::Result<ThinLTOImports> {\n-        use std::io::BufRead;\n-        let mut imports = FxHashMap();\n-        let mut current_module = None;\n-        let mut current_imports = vec![];\n-        let file = File::open(path)?;\n-        for line in io::BufReader::new(file).lines() {\n-            let line = line?;\n-            if line.is_empty() {\n-                let importing_module = current_module\n-                    .take()\n-                    .expect(\"Importing module not set\");\n-                imports.insert(importing_module,\n-                               mem::replace(&mut current_imports, vec![]));\n-            } else if line.starts_with(\" \") {\n-                // This is an imported module\n-                assert_ne!(current_module, None);\n-                current_imports.push(line.trim().to_string());\n-            } else {\n-                // This is the beginning of a new module\n-                assert_eq!(current_module, None);\n-                current_module = Some(line.trim().to_string());\n-            }\n+fn module_name_to_str(c_str: &CStr) -> &str {\n+    match c_str.to_str() {\n+        Ok(s) => s,\n+        Err(e) => {\n+            bug!(\"Encountered non-utf8 LLVM module name `{}`: {}\",\n+                c_str.to_string_lossy(),\n+                e)\n         }\n-        Ok(ThinLTOImports {\n-            imports\n-        })\n     }\n-}\n+}\n\\ No newline at end of file"}, {"sha": "9c0f4c3979008dd94abe91e855dd0384b77520ba", "filename": "src/librustc_codegen_llvm/back/write.rs", "status": "modified", "additions": 28, "deletions": 126, "changes": 154, "blob_url": "https://github.com/rust-lang/rust/blob/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs?ref=abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "patch": "@@ -28,7 +28,7 @@ use rustc::util::nodemap::FxHashMap;\n use time_graph::{self, TimeGraph, Timeline};\n use llvm::{self, DiagnosticInfo, PassManager, SMDiagnostic};\n use llvm_util;\n-use {CodegenResults, ModuleCodegen, CompiledModule, ModuleKind, ModuleLlvm,\n+use {CodegenResults, ModuleCodegen, CompiledModule, ModuleKind, // ModuleLlvm,\n      CachedModuleCodegen};\n use CrateInfo;\n use rustc::hir::def_id::{CrateNum, LOCAL_CRATE};\n@@ -228,8 +228,8 @@ pub struct ModuleConfig {\n     pgo_use: String,\n \n     // Flags indicating which outputs to produce.\n+    pub emit_pre_thin_lto_bc: bool,\n     emit_no_opt_bc: bool,\n-    emit_pre_thin_lto_bc: bool,\n     emit_bc: bool,\n     emit_bc_compressed: bool,\n     emit_lto_bc: bool,\n@@ -625,34 +625,36 @@ unsafe fn optimize(cgcx: &CodegenContext,\n         // Deallocate managers that we're now done with\n         llvm::LLVMDisposePassManager(fpm);\n         llvm::LLVMDisposePassManager(mpm);\n-\n-        if config.emit_pre_thin_lto_bc {\n-            let out = cgcx.output_filenames.temp_path_ext(PRE_THIN_LTO_BC_EXT,\n-                                                          module_name);\n-            let out = path2cstr(&out);\n-            llvm::LLVMWriteBitcodeToFile(llmod, out.as_ptr());\n-        }\n     }\n     Ok(())\n }\n \n fn generate_lto_work(cgcx: &CodegenContext,\n                      modules: Vec<ModuleCodegen>,\n-                     import_only_modules: Vec<(SerializedModule, CString)>)\n+                     import_only_modules: Vec<(SerializedModule, WorkProduct)>)\n     -> Vec<(WorkItem, u64)>\n {\n     let mut timeline = cgcx.time_graph.as_ref().map(|tg| {\n         tg.start(CODEGEN_WORKER_TIMELINE,\n                  CODEGEN_WORK_PACKAGE_KIND,\n                  \"generate lto\")\n     }).unwrap_or(Timeline::noop());\n-    let lto_modules = lto::run(cgcx, modules, import_only_modules, &mut timeline)\n+    let (lto_modules, copy_jobs) = lto::run(cgcx, modules, import_only_modules, &mut timeline)\n         .unwrap_or_else(|e| e.raise());\n \n-    lto_modules.into_iter().map(|module| {\n+    let lto_modules = lto_modules.into_iter().map(|module| {\n         let cost = module.cost();\n         (WorkItem::LTO(module), cost)\n-    }).collect()\n+    });\n+\n+    let copy_jobs = copy_jobs.into_iter().map(|wp| {\n+        (WorkItem::CopyPostLtoArtifacts(CachedModuleCodegen {\n+            name: wp.cgu_name.clone(),\n+            source: wp,\n+        }), 0)\n+    });\n+\n+    lto_modules.chain(copy_jobs).collect()\n }\n \n unsafe fn codegen(cgcx: &CodegenContext,\n@@ -1083,7 +1085,6 @@ pub fn start_async_codegen(tcx: TyCtxt,\n fn copy_all_cgu_workproducts_to_incr_comp_cache_dir(\n     sess: &Session,\n     compiled_modules: &CompiledModules,\n-    output_filenames: &OutputFilenames,\n ) -> FxHashMap<WorkProductId, WorkProduct> {\n     let mut work_products = FxHashMap::default();\n \n@@ -1104,13 +1105,6 @@ fn copy_all_cgu_workproducts_to_incr_comp_cache_dir(\n             files.push((WorkProductFileKind::BytecodeCompressed, path.clone()));\n         }\n \n-        let pre_thin_lto_bytecode_path =\n-            output_filenames.temp_path_ext(PRE_THIN_LTO_BC_EXT, Some(&module.name));\n-\n-        if pre_thin_lto_bytecode_path.exists() {\n-            files.push((WorkProductFileKind::PreThinLtoBytecode, pre_thin_lto_bytecode_path));\n-        }\n-\n         if let Some((id, product)) =\n                 copy_cgu_workproducts_to_incr_comp_cache_dir(sess, &module.name, &files) {\n             work_products.insert(id, product);\n@@ -1285,9 +1279,6 @@ enum WorkItem {\n     /// Copy the post-LTO artifacts from the incremental cache to the output\n     /// directory.\n     CopyPostLtoArtifacts(CachedModuleCodegen),\n-    /// Load the pre-LTO version of a module from the incremental cache, so it\n-    /// can be run through LTO again.\n-    LoadPreLtoModule(CachedModuleCodegen),\n     /// Perform (Thin)LTO on the given module.\n     LTO(lto::LtoModuleCodegen),\n }\n@@ -1297,15 +1288,13 @@ impl WorkItem {\n         match *self {\n             WorkItem::Optimize(ref m) => m.kind,\n             WorkItem::CopyPostLtoArtifacts(_) |\n-            WorkItem::LoadPreLtoModule(_) |\n             WorkItem::LTO(_) => ModuleKind::Regular,\n         }\n     }\n \n     fn name(&self) -> String {\n         match *self {\n             WorkItem::Optimize(ref m) => format!(\"optimize: {}\", m.name),\n-            WorkItem::LoadPreLtoModule(ref m) => format!(\"load pre-lto module: {}\", m.name),\n             WorkItem::CopyPostLtoArtifacts(ref m) => format!(\"copy post LTO artifacts: {}\", m.name),\n             WorkItem::LTO(ref m) => format!(\"lto: {}\", m.name()),\n         }\n@@ -1326,9 +1315,6 @@ fn execute_work_item(cgcx: &CodegenContext,\n         work_item @ WorkItem::Optimize(_) => {\n             execute_optimize_work_item(cgcx, work_item, timeline)\n         }\n-        work_item @ WorkItem::LoadPreLtoModule(_) => {\n-            execute_load_pre_lto_mod_work_item(cgcx, work_item, timeline)\n-        }\n         work_item @ WorkItem::CopyPostLtoArtifacts(_) => {\n             execute_copy_from_cache_work_item(cgcx, work_item, timeline)\n         }\n@@ -1454,9 +1440,6 @@ fn execute_copy_from_cache_work_item(cgcx: &CodegenContext,\n                 bytecode_compressed = Some(path.clone());\n                 path\n             }\n-            WorkProductFileKind::PreThinLtoBytecode => {\n-                continue;\n-            }\n         };\n         let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n                                            &saved_file);\n@@ -1509,69 +1492,6 @@ fn execute_lto_work_item(cgcx: &CodegenContext,\n     }\n }\n \n-fn execute_load_pre_lto_mod_work_item(cgcx: &CodegenContext,\n-                                      work_item: WorkItem,\n-                                      _: &mut Timeline)\n-    -> Result<WorkItemResult, FatalError>\n-{\n-    let module = if let WorkItem::LoadPreLtoModule(module) = work_item {\n-        module\n-    } else {\n-        bug!(\"execute_load_pre_lto_mod_work_item() called with wrong WorkItem kind.\")\n-    };\n-\n-    let work_product = module.source.clone();\n-    let incr_comp_session_dir = cgcx.incr_comp_session_dir\n-                                    .as_ref()\n-                                    .unwrap();\n-\n-    let filename = pre_lto_bitcode_filename(&work_product);\n-    let bc_path = in_incr_comp_dir(&incr_comp_session_dir, &filename);\n-\n-    let file = fs::File::open(&bc_path).unwrap_or_else(|e| {\n-        panic!(\"failed to open bitcode file `{}`: {}\",\n-                           bc_path.display(),\n-                           e);\n-    });\n-\n-    let module_llvm = unsafe {\n-        let data = ::memmap::Mmap::map(&file).unwrap_or_else(|e| {\n-            panic!(\"failed to create mmap for bitcode file `{}`: {}\",\n-                               bc_path.display(),\n-                               e);\n-        });\n-\n-        let llcx = llvm::LLVMRustContextCreate(cgcx.fewer_names);\n-        let mod_name_c = SmallCStr::new(&module.name);\n-        let llmod_raw = match llvm::LLVMRustParseBitcodeForThinLTO(\n-            llcx,\n-            data.as_ptr(),\n-            data.len(),\n-            mod_name_c.as_ptr(),\n-        ) {\n-            Some(m) => m as *const _,\n-            None => {\n-                panic!(\"failed to parse bitcode for thin LTO module `{}`\",\n-                        module.name);\n-            }\n-        };\n-\n-        let tm = (cgcx.tm_factory)().unwrap();\n-\n-        ModuleLlvm {\n-            llmod_raw,\n-            llcx,\n-            tm,\n-        }\n-    };\n-\n-    Ok(WorkItemResult::NeedsLTO(ModuleCodegen {\n-        name: module.name.to_string(),\n-        module_llvm,\n-        kind: ModuleKind::Regular,\n-    }))\n-}\n-\n enum Message {\n     Token(io::Result<Acquired>),\n     NeedsLTO {\n@@ -1588,7 +1508,7 @@ enum Message {\n     },\n     AddImportOnlyModule {\n         module_data: SerializedModule,\n-        module_name: CString,\n+        work_product: WorkProduct,\n     },\n     CodegenComplete,\n     CodegenItem,\n@@ -1893,6 +1813,7 @@ fn start_executing_work(tcx: TyCtxt,\n               work_items.len() > 0 ||\n               running > 0 ||\n               needs_lto.len() > 0 ||\n+              lto_import_only_modules.len() > 0 ||\n               main_thread_worker_state != MainThreadWorkerState::Idle {\n \n             // While there are still CGUs to be codegened, the coordinator has\n@@ -1932,7 +1853,7 @@ fn start_executing_work(tcx: TyCtxt,\n                    running == 0 &&\n                    main_thread_worker_state == MainThreadWorkerState::Idle {\n                     assert!(!started_lto);\n-                    assert!(needs_lto.len() > 0);\n+                    assert!(needs_lto.len() + lto_import_only_modules.len() > 0);\n                     started_lto = true;\n                     let modules = mem::replace(&mut needs_lto, Vec::new());\n                     let import_only_modules =\n@@ -2104,10 +2025,13 @@ fn start_executing_work(tcx: TyCtxt,\n                     free_worker_ids.push(worker_id);\n                     needs_lto.push(result);\n                 }\n-                Message::AddImportOnlyModule { module_data, module_name } => {\n+                Message::AddImportOnlyModule { module_data, work_product } => {\n                     assert!(!started_lto);\n                     assert!(!codegen_done);\n-                    lto_import_only_modules.push((module_data, module_name));\n+                    assert_eq!(main_thread_worker_state,\n+                               MainThreadWorkerState::Codegenning);\n+                    lto_import_only_modules.push((module_data, work_product));\n+                    main_thread_worker_state = MainThreadWorkerState::Idle;\n                 }\n                 Message::Done { result: Err(()), worker_id: _ } => {\n                     shared_emitter.fatal(\"aborting due to worker thread failure\");\n@@ -2483,8 +2407,7 @@ impl OngoingCodegen {\n \n         let work_products =\n             copy_all_cgu_workproducts_to_incr_comp_cache_dir(sess,\n-                                                             &compiled_modules,\n-                                                             &self.output_filenames);\n+                                                             &compiled_modules);\n         produce_final_output_artifacts(sess,\n                                        &compiled_modules,\n                                        &self.output_filenames);\n@@ -2565,19 +2488,7 @@ pub(crate) fn submit_post_lto_module_to_llvm(tcx: TyCtxt,\n \n pub(crate) fn submit_pre_lto_module_to_llvm(tcx: TyCtxt,\n                                             module: CachedModuleCodegen) {\n-    let llvm_work_item = WorkItem::LoadPreLtoModule(module);\n-\n-    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone {\n-        llvm_work_item,\n-        // We don't know the size of the module, but just loading will have smaller\n-        // cost than optimizing.\n-        cost: 10,\n-    })));\n-}\n-\n-pub(crate) fn submit_import_only_module_to_llvm(tcx: TyCtxt,\n-                                                module: CachedModuleCodegen) {\n-    let filename = pre_lto_bitcode_filename(&module.source);\n+    let filename = pre_lto_bitcode_filename(&module.name);\n     let bc_path = in_incr_comp_dir_sess(tcx.sess, &filename);\n     let file = fs::File::open(&bc_path).unwrap_or_else(|e| {\n         panic!(\"failed to open bitcode file `{}`: {}\", bc_path.display(), e)\n@@ -2592,21 +2503,12 @@ pub(crate) fn submit_import_only_module_to_llvm(tcx: TyCtxt,\n     // Schedule the module to be loaded\n     drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::AddImportOnlyModule {\n         module_data: SerializedModule::FromUncompressedFile(mmap, file),\n-        module_name: CString::new(module.name.clone()).unwrap(),\n+        work_product: module.source,\n     })));\n-\n-    // Note: We also schedule for the cached files to be copied to the output\n-    // directory\n-    submit_post_lto_module_to_llvm(tcx, module);\n }\n \n-fn pre_lto_bitcode_filename(wp: &WorkProduct) -> String {\n-    wp.saved_files\n-      .iter()\n-      .find(|&&(kind, _)| kind == WorkProductFileKind::PreThinLtoBytecode)\n-      .map(|&(_, ref filename)| filename.clone())\n-      .unwrap_or_else(|| panic!(\"Couldn't find pre-thin-lto bytecode for `{}`\",\n-                                wp.cgu_name))\n+pub(super) fn pre_lto_bitcode_filename(module_name: &str) -> String {\n+    format!(\"{}.{}\", module_name, PRE_THIN_LTO_BC_EXT)\n }\n \n fn msvc_imps_needed(tcx: TyCtxt) -> bool {"}, {"sha": "c1f6006e684be595bdcaabae0eb29f22c5209f40", "filename": "src/librustc_codegen_llvm/base.rs", "status": "modified", "additions": 34, "deletions": 95, "changes": 129, "blob_url": "https://github.com/rust-lang/rust/blob/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc_codegen_llvm%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc_codegen_llvm%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fbase.rs?ref=abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "patch": "@@ -29,7 +29,6 @@ use super::ModuleKind;\n use super::CachedModuleCodegen;\n \n use abi;\n-use back::lto;\n use back::write::{self, OngoingCodegen};\n use llvm::{self, TypeKind, get_param};\n use metadata;\n@@ -45,7 +44,7 @@ use rustc::middle::cstore::{self, LinkagePreference};\n use rustc::middle::exported_symbols;\n use rustc::util::common::{time, print_time_passes_entry};\n use rustc::util::profiling::ProfileCategory;\n-use rustc::session::config::{self, DebugInfo, EntryFnType};\n+use rustc::session::config::{self, DebugInfo, EntryFnType, Lto};\n use rustc::session::Session;\n use rustc_incremental;\n use allocator;\n@@ -698,77 +697,48 @@ pub fn iter_globals(llmod: &'ll llvm::Module) -> ValueIter<'ll> {\n     }\n }\n \n-#[derive(Debug, PartialEq)]\n+#[derive(Debug)]\n enum CguReUsable {\n-    No,\n-    PreThinLto,\n-    PostThinLto,\n-    PostThinLtoButImportedFrom,\n+    PreLto,\n+    PostLto,\n+    No\n }\n \n fn determine_cgu_reuse<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                 codegen_units: &[Arc<CodegenUnit<'tcx>>])\n-                                 -> FxHashMap<InternedString, CguReUsable> {\n+                                 cgu: &CodegenUnit<'tcx>)\n+                                 -> CguReUsable {\n     if !tcx.dep_graph.is_fully_enabled() {\n-        return codegen_units.iter()\n-                            .map(|cgu| (cgu.name().clone(), CguReUsable::No))\n-                            .collect();\n+        return CguReUsable::No\n     }\n \n-    let thin_lto_imports = load_thin_lto_imports(tcx.sess);\n-\n-    let mut reusable_cgus = FxHashMap();\n-    let mut green_cgus = FxHashMap();\n-    let mut need_for_importing = FxHashSet();\n-\n-    for cgu in codegen_units {\n-        let work_product_id = &cgu.work_product_id();\n-        if tcx.dep_graph.previous_work_product(work_product_id).is_none() {\n-            // We don't have anything cached for this CGU. This can happen\n-            // if the CGU did not exist in the previous session.\n-            reusable_cgus.insert(cgu.name().clone(), CguReUsable::No);\n-            continue\n-        };\n-        // Try to mark the CGU as green\n-        let dep_node = cgu.codegen_dep_node(tcx);\n-        assert!(!tcx.dep_graph.dep_node_exists(&dep_node),\n-            \"CompileCodegenUnit dep-node for CGU `{}` already exists before marking.\",\n-            cgu.name());\n-\n-        if tcx.dep_graph.try_mark_green(tcx, &dep_node).is_some() {\n-            // We can re-use either the pre- or the post-thinlto state\n-            green_cgus.insert(cgu.name().to_string(), cgu);\n-        } else {\n-            // We definitely cannot re-use this CGU\n-            reusable_cgus.insert(cgu.name().clone(), CguReUsable::No);\n-\n-            let imported_cgus = thin_lto_imports.modules_imported_by(&cgu.name().as_str());\n-            need_for_importing.extend(imported_cgus.iter().cloned());\n-        }\n+    let work_product_id = &cgu.work_product_id();\n+    if tcx.dep_graph.previous_work_product(work_product_id).is_none() {\n+        // We don't have anything cached for this CGU. This can happen\n+        // if the CGU did not exist in the previous session.\n+        return CguReUsable::No\n     }\n \n-    // Now we know all CGUs that have not changed themselves. Next we need to\n-    // check if anything they imported via ThinLTO has changed.\n-    for (cgu_name, cgu) in &green_cgus {\n-        let imported_cgus = thin_lto_imports.modules_imported_by(cgu_name);\n-        let all_imports_green = imported_cgus.iter().all(|imported_cgu| {\n-            green_cgus.contains_key(&imported_cgu[..])\n-        });\n-        if all_imports_green {\n-            reusable_cgus.insert(cgu.name().clone(), CguReUsable::PostThinLto);\n+    // Try to mark the CGU as green. If it we can do so, it means that nothing\n+    // affecting the LLVM module has changed and we can re-use a cached version.\n+    // If we compile with any kind of LTO, this means we can re-use the bitcode\n+    // of the Pre-LTO stage (possibly also the Post-LTO version but we'll only\n+    // know that later). If we are not doing LTO, there is only one optimized\n+    // version of each module, so we re-use that.\n+    let dep_node = cgu.codegen_dep_node(tcx);\n+    assert!(!tcx.dep_graph.dep_node_exists(&dep_node),\n+        \"CompileCodegenUnit dep-node for CGU `{}` already exists before marking.\",\n+        cgu.name());\n+\n+    if tcx.dep_graph.try_mark_green(tcx, &dep_node).is_some() {\n+        // We can re-use either the pre- or the post-thinlto state\n+        if tcx.sess.lto() != Lto::No {\n+            CguReUsable::PreLto\n         } else {\n-            reusable_cgus.insert(cgu.name().clone(), CguReUsable::PreThinLto);\n-            need_for_importing.extend(imported_cgus.iter().cloned());\n-        }\n-    }\n-\n-    for (name, state) in reusable_cgus.iter_mut() {\n-        if *state == CguReUsable::PostThinLto && need_for_importing.contains(&name.as_str()[..]) {\n-            *state = CguReUsable::PostThinLtoButImportedFrom;\n+            CguReUsable::PostLto\n         }\n+    } else {\n+        CguReUsable::No\n     }\n-\n-    reusable_cgus\n }\n \n pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n@@ -920,13 +890,11 @@ pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     let mut total_codegen_time = Duration::new(0, 0);\n     let mut all_stats = Stats::default();\n \n-    let cgu_reuse = determine_cgu_reuse(tcx, &codegen_units);\n-\n     for cgu in codegen_units.into_iter() {\n         ongoing_codegen.wait_for_signal_to_codegen_item();\n         ongoing_codegen.check_for_errors(tcx.sess);\n \n-        let loaded_from_cache = match cgu_reuse[cgu.name()] {\n+        let loaded_from_cache = match determine_cgu_reuse(tcx, &cgu) {\n             CguReUsable::No => {\n                 let _timing_guard = time_graph.as_ref().map(|time_graph| {\n                     time_graph.start(write::CODEGEN_WORKER_TIMELINE,\n@@ -939,21 +907,14 @@ pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                 total_codegen_time += start_time.elapsed();\n                 false\n             }\n-            CguReUsable::PreThinLto => {\n+            CguReUsable::PreLto => {\n                 write::submit_pre_lto_module_to_llvm(tcx, CachedModuleCodegen {\n                     name: cgu.name().to_string(),\n                     source: cgu.work_product(tcx),\n                 });\n                 true\n             }\n-            CguReUsable::PostThinLtoButImportedFrom => {\n-                write::submit_import_only_module_to_llvm(tcx, CachedModuleCodegen {\n-                    name: cgu.name().to_string(),\n-                    source: cgu.work_product(tcx),\n-                });\n-                true\n-            }\n-            CguReUsable::PostThinLto => {\n+            CguReUsable::PostLto => {\n                 write::submit_post_lto_module_to_llvm(tcx, CachedModuleCodegen {\n                     name: cgu.name().to_string(),\n                     source: cgu.work_product(tcx),\n@@ -1391,28 +1352,6 @@ pub fn visibility_to_llvm(linkage: Visibility) -> llvm::Visibility {\n     }\n }\n \n-fn load_thin_lto_imports(sess: &Session) -> lto::ThinLTOImports {\n-    if sess.opts.incremental.is_none() {\n-        return lto::ThinLTOImports::new();\n-    }\n-\n-    let path = rustc_incremental::in_incr_comp_dir_sess(\n-        sess,\n-        lto::THIN_LTO_IMPORTS_INCR_COMP_FILE_NAME\n-    );\n-    if !path.exists() {\n-        return lto::ThinLTOImports::new();\n-    }\n-    match lto::ThinLTOImports::load_from_file(&path) {\n-        Ok(imports) => imports,\n-        Err(e) => {\n-            let msg = format!(\"Error while trying to load ThinLTO import data \\\n-                               for incremental compilation: {}\", e);\n-            sess.fatal(&msg)\n-        }\n-    }\n-}\n-\n // FIXME(mw): Anything that is produced via DepGraph::with_task() must implement\n //            the HashStable trait. Normally DepGraph::with_task() calls are\n //            hidden behind queries, but CGU creation is a special case in two"}, {"sha": "cfe59b1f672623d59a884283d87f8c075cca9939", "filename": "src/librustc_incremental/persist/work_product.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs", "raw_url": "https://github.com/rust-lang/rust/raw/abd5cc3364b9ec9500ef8f5e64699e25069bc51b/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs?ref=abd5cc3364b9ec9500ef8f5e64699e25069bc51b", "patch": "@@ -36,7 +36,6 @@ pub fn copy_cgu_workproducts_to_incr_comp_cache_dir(\n                      WorkProductFileKind::Object => \"o\",\n                      WorkProductFileKind::Bytecode => \"bc\",\n                      WorkProductFileKind::BytecodeCompressed => \"bc.z\",\n-                     WorkProductFileKind::PreThinLtoBytecode => \"pre-thinlto.bc\",\n                  };\n                  let file_name = format!(\"{}.{}\", cgu_name, extension);\n                  let path_in_incr_dir = in_incr_comp_dir_sess(sess, &file_name);"}]}