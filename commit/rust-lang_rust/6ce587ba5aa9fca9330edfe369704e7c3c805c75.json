{"sha": "6ce587ba5aa9fca9330edfe369704e7c3c805c75", "node_id": "C_kwDOAAsO6NoAKDZjZTU4N2JhNWFhOWZjYTkzMzBlZGZlMzY5NzA0ZTdjM2M4MDVjNzU", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2021-12-12T14:58:45Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2021-12-12T15:31:05Z"}, "message": "parser tests work", "tree": {"sha": "73b0f65fe08a3fab2ab50e1bec0a4f20611f4d5e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/73b0f65fe08a3fab2ab50e1bec0a4f20611f4d5e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6ce587ba5aa9fca9330edfe369704e7c3c805c75", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6ce587ba5aa9fca9330edfe369704e7c3c805c75", "html_url": "https://github.com/rust-lang/rust/commit/6ce587ba5aa9fca9330edfe369704e7c3c805c75", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6ce587ba5aa9fca9330edfe369704e7c3c805c75/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "26bfd6023ffbc7fbd66bc4857e6c74b35e7fc9b4", "url": "https://api.github.com/repos/rust-lang/rust/commits/26bfd6023ffbc7fbd66bc4857e6c74b35e7fc9b4", "html_url": "https://github.com/rust-lang/rust/commit/26bfd6023ffbc7fbd66bc4857e6c74b35e7fc9b4"}], "stats": {"total": 232, "additions": 92, "deletions": 140}, "files": [{"sha": "1e9f59fa530a0e49af0501075e16ba29cf05e6bf", "filename": "crates/parser/src/lib.rs", "status": "modified", "additions": 1, "deletions": 30, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fparser%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fparser%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fparser%2Fsrc%2Flib.rs?ref=6ce587ba5aa9fca9330edfe369704e7c3c805c75", "patch": "@@ -24,40 +24,11 @@ mod tokens;\n \n pub(crate) use token_set::TokenSet;\n \n-pub use syntax_kind::SyntaxKind;\n-\n-use crate::tokens::Tokens;\n+pub use crate::{syntax_kind::SyntaxKind, tokens::Tokens};\n \n #[derive(Debug, Clone, PartialEq, Eq, Hash)]\n pub struct ParseError(pub Box<String>);\n \n-/// `TokenSource` abstracts the source of the tokens parser operates on.\n-///\n-/// Hopefully this will allow us to treat text and token trees in the same way!\n-pub trait TokenSource {\n-    fn current(&self) -> Token;\n-\n-    /// Lookahead n token\n-    fn lookahead_nth(&self, n: usize) -> Token;\n-\n-    /// bump cursor to next token\n-    fn bump(&mut self);\n-\n-    /// Is the current token a specified keyword?\n-    fn is_keyword(&self, kw: &str) -> bool;\n-}\n-\n-/// `Token` abstracts the cursor of `TokenSource` operates on.\n-#[derive(Debug, Copy, Clone, Eq, PartialEq)]\n-pub struct Token {\n-    /// What is the current token?\n-    pub kind: SyntaxKind,\n-\n-    /// Is the current token joined to the next one (`> >` vs `>>`).\n-    pub is_jointed_to_next: bool,\n-    pub contextual_kw: SyntaxKind,\n-}\n-\n /// `TreeSink` abstracts details of a particular syntax tree implementation.\n pub trait TreeSink {\n     /// Adds new token to the current branch."}, {"sha": "601a5792afde7f6de675533cc5544c383fd65ea3", "filename": "crates/parser/src/syntax_kind/generated.rs", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs?ref=6ce587ba5aa9fca9330edfe369704e7c3c805c75", "patch": "@@ -334,6 +334,18 @@ impl SyntaxKind {\n         };\n         Some(kw)\n     }\n+    pub fn from_contextual_keyword(ident: &str) -> Option<SyntaxKind> {\n+        let kw = match ident {\n+            \"auto\" => AUTO_KW,\n+            \"default\" => DEFAULT_KW,\n+            \"existential\" => EXISTENTIAL_KW,\n+            \"union\" => UNION_KW,\n+            \"raw\" => RAW_KW,\n+            \"macro_rules\" => MACRO_RULES_KW,\n+            _ => return None,\n+        };\n+        Some(kw)\n+    }\n     pub fn from_char(c: char) -> Option<SyntaxKind> {\n         let tok = match c {\n             ';' => SEMICOLON,"}, {"sha": "4f10956070f7b3a764d0536afd34679a2e471a60", "filename": "crates/parser/src/tokens.rs", "status": "modified", "additions": 19, "deletions": 7, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fparser%2Fsrc%2Ftokens.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fparser%2Fsrc%2Ftokens.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fparser%2Fsrc%2Ftokens.rs?ref=6ce587ba5aa9fca9330edfe369704e7c3c805c75", "patch": "@@ -1,8 +1,19 @@\n-use crate::{SyntaxKind, Token};\n+use crate::SyntaxKind;\n \n #[allow(non_camel_case_types)]\n type bits = u64;\n \n+/// `Token` abstracts the cursor of `TokenSource` operates on.\n+#[derive(Debug, Copy, Clone, Eq, PartialEq)]\n+pub(crate) struct Token {\n+    /// What is the current token?\n+    pub(crate) kind: SyntaxKind,\n+\n+    /// Is the current token joined to the next one (`> >` vs `>>`).\n+    pub(crate) is_jointed_to_next: bool,\n+    pub(crate) contextual_kw: SyntaxKind,\n+}\n+\n /// Main input to the parser.\n ///\n /// A sequence of tokens represented internally as a struct of arrays.\n@@ -49,13 +60,14 @@ impl Tokens {\n         self.kind.len()\n     }\n     pub(crate) fn get(&self, idx: usize) -> Token {\n-        if idx > self.len() {\n-            return self.eof();\n+        if idx < self.len() {\n+            let kind = self.kind[idx];\n+            let is_jointed_to_next = self.get_joint(idx);\n+            let contextual_kw = self.contextual_kw[idx];\n+            Token { kind, is_jointed_to_next, contextual_kw }\n+        } else {\n+            self.eof()\n         }\n-        let kind = self.kind[idx];\n-        let is_jointed_to_next = self.get_joint(idx);\n-        let contextual_kw = self.contextual_kw[idx];\n-        Token { kind, is_jointed_to_next, contextual_kw }\n     }\n \n     #[cold]"}, {"sha": "652668e80b20d7cb401218ed9a8e3c3bf4beb04f", "filename": "crates/syntax/src/parsing.rs", "status": "modified", "additions": 32, "deletions": 13, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fsyntax%2Fsrc%2Fparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fsyntax%2Fsrc%2Fparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Fparsing.rs?ref=6ce587ba5aa9fca9330edfe369704e7c3c805c75", "patch": "@@ -2,25 +2,23 @@\n //! incremental reparsing.\n \n pub(crate) mod lexer;\n-mod text_token_source;\n mod text_tree_sink;\n mod reparsing;\n \n use parser::SyntaxKind;\n-use text_token_source::TextTokenSource;\n use text_tree_sink::TextTreeSink;\n \n use crate::{syntax_node::GreenNode, AstNode, SyntaxError, SyntaxNode};\n \n pub(crate) use crate::parsing::{lexer::*, reparsing::incremental_reparse};\n \n pub(crate) fn parse_text(text: &str) -> (GreenNode, Vec<SyntaxError>) {\n-    let (tokens, lexer_errors) = tokenize(text);\n+    let (lexer_tokens, lexer_errors) = tokenize(text);\n+    let parser_tokens = to_parser_tokens(text, &lexer_tokens);\n \n-    let mut token_source = TextTokenSource::new(text, &tokens);\n-    let mut tree_sink = TextTreeSink::new(text, &tokens);\n+    let mut tree_sink = TextTreeSink::new(text, &lexer_tokens);\n \n-    parser::parse_source_file(&mut token_source, &mut tree_sink);\n+    parser::parse_source_file(&parser_tokens, &mut tree_sink);\n \n     let (tree, mut parser_errors) = tree_sink.finish();\n     parser_errors.extend(lexer_errors);\n@@ -33,26 +31,47 @@ pub(crate) fn parse_text_as<T: AstNode>(\n     text: &str,\n     entry_point: parser::ParserEntryPoint,\n ) -> Result<T, ()> {\n-    let (tokens, lexer_errors) = tokenize(text);\n+    let (lexer_tokens, lexer_errors) = tokenize(text);\n     if !lexer_errors.is_empty() {\n         return Err(());\n     }\n \n-    let mut token_source = TextTokenSource::new(text, &tokens);\n-    let mut tree_sink = TextTreeSink::new(text, &tokens);\n+    let parser_tokens = to_parser_tokens(text, &lexer_tokens);\n+\n+    let mut tree_sink = TextTreeSink::new(text, &lexer_tokens);\n \n     // TextTreeSink assumes that there's at least some root node to which it can attach errors and\n     // tokens. We arbitrarily give it a SourceFile.\n     use parser::TreeSink;\n     tree_sink.start_node(SyntaxKind::SOURCE_FILE);\n-    parser::parse(&mut token_source, &mut tree_sink, entry_point);\n+    parser::parse(&parser_tokens, &mut tree_sink, entry_point);\n     tree_sink.finish_node();\n \n-    let (tree, parser_errors) = tree_sink.finish();\n-    use parser::TokenSource;\n-    if !parser_errors.is_empty() || token_source.current().kind != SyntaxKind::EOF {\n+    let (tree, parser_errors, eof) = tree_sink.finish_eof();\n+    if !parser_errors.is_empty() || !eof {\n         return Err(());\n     }\n \n     SyntaxNode::new_root(tree).first_child().and_then(T::cast).ok_or(())\n }\n+\n+pub(crate) fn to_parser_tokens(text: &str, lexer_tokens: &[lexer::Token]) -> ::parser::Tokens {\n+    let mut off = 0;\n+    let mut res = parser::Tokens::default();\n+    let mut was_joint = true;\n+    for t in lexer_tokens {\n+        if t.kind.is_trivia() {\n+            was_joint = false;\n+        } else if t.kind == SyntaxKind::IDENT {\n+            let token_text = &text[off..][..usize::from(t.len)];\n+            let contextual_kw =\n+                SyntaxKind::from_contextual_keyword(token_text).unwrap_or(SyntaxKind::IDENT);\n+            res.push_ident(contextual_kw);\n+        } else {\n+            res.push(was_joint, t.kind);\n+            was_joint = true;\n+        }\n+        off += usize::from(t.len);\n+    }\n+    res\n+}"}, {"sha": "62f39a934724287f398ca222df463e80c95861a3", "filename": "crates/syntax/src/parsing/reparsing.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fsyntax%2Fsrc%2Fparsing%2Freparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fsyntax%2Fsrc%2Fparsing%2Freparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Fparsing%2Freparsing.rs?ref=6ce587ba5aa9fca9330edfe369704e7c3c805c75", "patch": "@@ -12,8 +12,8 @@ use text_edit::Indel;\n use crate::{\n     parsing::{\n         lexer::{lex_single_syntax_kind, tokenize, Token},\n-        text_token_source::TextTokenSource,\n         text_tree_sink::TextTreeSink,\n+        to_parser_tokens,\n     },\n     syntax_node::{GreenNode, GreenToken, NodeOrToken, SyntaxElement, SyntaxNode},\n     SyntaxError,\n@@ -91,14 +91,14 @@ fn reparse_block(\n     let (node, reparser) = find_reparsable_node(root, edit.delete)?;\n     let text = get_text_after_edit(node.clone().into(), edit);\n \n-    let (tokens, new_lexer_errors) = tokenize(&text);\n-    if !is_balanced(&tokens) {\n+    let (lexer_tokens, new_lexer_errors) = tokenize(&text);\n+    if !is_balanced(&lexer_tokens) {\n         return None;\n     }\n+    let parser_tokens = to_parser_tokens(&text, &lexer_tokens);\n \n-    let mut token_source = TextTokenSource::new(&text, &tokens);\n-    let mut tree_sink = TextTreeSink::new(&text, &tokens);\n-    reparser.parse(&mut token_source, &mut tree_sink);\n+    let mut tree_sink = TextTreeSink::new(&text, &lexer_tokens);\n+    reparser.parse(&parser_tokens, &mut tree_sink);\n \n     let (green, mut new_parser_errors) = tree_sink.finish();\n     new_parser_errors.extend(new_lexer_errors);"}, {"sha": "11dfc63a65bb16f89e5d5e7d66ac38940dfd60d9", "filename": "crates/syntax/src/parsing/text_token_source.rs", "status": "removed", "additions": 0, "deletions": 82, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/26bfd6023ffbc7fbd66bc4857e6c74b35e7fc9b4/crates%2Fsyntax%2Fsrc%2Fparsing%2Ftext_token_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/26bfd6023ffbc7fbd66bc4857e6c74b35e7fc9b4/crates%2Fsyntax%2Fsrc%2Fparsing%2Ftext_token_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Fparsing%2Ftext_token_source.rs?ref=26bfd6023ffbc7fbd66bc4857e6c74b35e7fc9b4", "patch": "@@ -1,82 +0,0 @@\n-//! See `TextTokenSource` docs.\n-\n-use parser::TokenSource;\n-\n-use crate::{parsing::lexer::Token, SyntaxKind::EOF, TextRange, TextSize};\n-\n-/// Implementation of `parser::TokenSource` that takes tokens from source code text.\n-pub(crate) struct TextTokenSource<'t> {\n-    text: &'t str,\n-    /// token and its start position (non-whitespace/comment tokens)\n-    /// ```non-rust\n-    ///  struct Foo;\n-    ///  ^------^--^-\n-    ///  |      |    \\________\n-    ///  |      \\____         \\\n-    ///  |           \\         |\n-    ///  (struct, 0) (Foo, 7) (;, 10)\n-    /// ```\n-    /// `[(struct, 0), (Foo, 7), (;, 10)]`\n-    token_offset_pairs: Vec<(Token, TextSize)>,\n-\n-    /// Current token and position\n-    curr: (parser::Token, usize),\n-}\n-\n-impl<'t> TokenSource for TextTokenSource<'t> {\n-    fn current(&self) -> parser::Token {\n-        self.curr.0\n-    }\n-\n-    fn lookahead_nth(&self, n: usize) -> parser::Token {\n-        mk_token(self.curr.1 + n, &self.token_offset_pairs)\n-    }\n-\n-    fn bump(&mut self) {\n-        if self.curr.0.kind == EOF {\n-            return;\n-        }\n-\n-        let pos = self.curr.1 + 1;\n-        self.curr = (mk_token(pos, &self.token_offset_pairs), pos);\n-    }\n-\n-    fn is_keyword(&self, kw: &str) -> bool {\n-        self.token_offset_pairs\n-            .get(self.curr.1)\n-            .map_or(false, |(token, offset)| &self.text[TextRange::at(*offset, token.len)] == kw)\n-    }\n-}\n-\n-fn mk_token(pos: usize, token_offset_pairs: &[(Token, TextSize)]) -> parser::Token {\n-    let (kind, is_jointed_to_next) = match token_offset_pairs.get(pos) {\n-        Some((token, offset)) => (\n-            token.kind,\n-            token_offset_pairs\n-                .get(pos + 1)\n-                .map_or(false, |(_, next_offset)| offset + token.len == *next_offset),\n-        ),\n-        None => (EOF, false),\n-    };\n-    parser::Token { kind, is_jointed_to_next }\n-}\n-\n-impl<'t> TextTokenSource<'t> {\n-    /// Generate input from tokens(expect comment and whitespace).\n-    pub(crate) fn new(text: &'t str, raw_tokens: &'t [Token]) -> TextTokenSource<'t> {\n-        let token_offset_pairs: Vec<_> = raw_tokens\n-            .iter()\n-            .filter_map({\n-                let mut len = 0.into();\n-                move |token| {\n-                    let pair = if token.kind.is_trivia() { None } else { Some((*token, len)) };\n-                    len += token.len;\n-                    pair\n-                }\n-            })\n-            .collect();\n-\n-        let first = mk_token(0, &token_offset_pairs);\n-        TextTokenSource { text, token_offset_pairs, curr: (first, 0) }\n-    }\n-}"}, {"sha": "c1792199fdc85f852c999c638810a7c99e0553fc", "filename": "crates/syntax/src/parsing/text_tree_sink.rs", "status": "modified", "additions": 10, "deletions": 2, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fsyntax%2Fsrc%2Fparsing%2Ftext_tree_sink.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fsyntax%2Fsrc%2Fparsing%2Ftext_tree_sink.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Fparsing%2Ftext_tree_sink.rs?ref=6ce587ba5aa9fca9330edfe369704e7c3c805c75", "patch": "@@ -104,7 +104,7 @@ impl<'a> TextTreeSink<'a> {\n         }\n     }\n \n-    pub(super) fn finish(mut self) -> (GreenNode, Vec<SyntaxError>) {\n+    pub(super) fn finish_eof(mut self) -> (GreenNode, Vec<SyntaxError>, bool) {\n         match mem::replace(&mut self.state, State::Normal) {\n             State::PendingFinish => {\n                 self.eat_trivias();\n@@ -113,7 +113,15 @@ impl<'a> TextTreeSink<'a> {\n             State::PendingStart | State::Normal => unreachable!(),\n         }\n \n-        self.inner.finish_raw()\n+        let (node, errors) = self.inner.finish_raw();\n+        let is_eof = self.token_pos == self.tokens.len();\n+\n+        (node, errors, is_eof)\n+    }\n+\n+    pub(super) fn finish(self) -> (GreenNode, Vec<SyntaxError>) {\n+        let (node, errors, _eof) = self.finish_eof();\n+        (node, errors)\n     }\n \n     fn eat_trivias(&mut self) {"}, {"sha": "c66edadc3ce768ccf1a7de07a050182da6bb98b4", "filename": "crates/syntax/src/tests/sourcegen_ast.rs", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_ast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6ce587ba5aa9fca9330edfe369704e7c3c805c75/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_ast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Ftests%2Fsourcegen_ast.rs?ref=6ce587ba5aa9fca9330edfe369704e7c3c805c75", "patch": "@@ -359,6 +359,10 @@ fn generate_syntax_kinds(grammar: KindsSrc<'_>) -> String {\n     let full_keywords =\n         full_keywords_values.iter().map(|kw| format_ident!(\"{}_KW\", to_upper_snake_case(kw)));\n \n+    let contextual_keywords_values = &grammar.contextual_keywords;\n+    let contextual_keywords =\n+        contextual_keywords_values.iter().map(|kw| format_ident!(\"{}_KW\", to_upper_snake_case(kw)));\n+\n     let all_keywords_values =\n         grammar.keywords.iter().chain(grammar.contextual_keywords.iter()).collect::<Vec<_>>();\n     let all_keywords_idents = all_keywords_values.iter().map(|kw| format_ident!(\"{}\", kw));\n@@ -428,6 +432,14 @@ fn generate_syntax_kinds(grammar: KindsSrc<'_>) -> String {\n                 Some(kw)\n             }\n \n+            pub fn from_contextual_keyword(ident: &str) -> Option<SyntaxKind> {\n+                let kw = match ident {\n+                    #(#contextual_keywords_values => #contextual_keywords,)*\n+                    _ => return None,\n+                };\n+                Some(kw)\n+            }\n+\n             pub fn from_char(c: char) -> Option<SyntaxKind> {\n                 let tok = match c {\n                     #(#single_byte_tokens_values => #single_byte_tokens,)*"}]}