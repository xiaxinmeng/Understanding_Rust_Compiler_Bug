{"sha": "546c052d225d41cd31f610e87a20f15cd0fa8e3c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU0NmMwNTJkMjI1ZDQxY2QzMWY2MTBlODdhMjBmMTVjZDBmYThlM2M=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2016-04-16T01:12:02Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2016-04-24T17:59:44Z"}, "message": "syntax: Get rid of token::IdentStyle", "tree": {"sha": "d2d1bb3b10895f266c2d5137c7aba8f8515583af", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d2d1bb3b10895f266c2d5137c7aba8f8515583af"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/546c052d225d41cd31f610e87a20f15cd0fa8e3c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/546c052d225d41cd31f610e87a20f15cd0fa8e3c", "html_url": "https://github.com/rust-lang/rust/commit/546c052d225d41cd31f610e87a20f15cd0fa8e3c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/546c052d225d41cd31f610e87a20f15cd0fa8e3c/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8dbf8f5f0a26a8f80f895294532ad567c156beb3", "url": "https://api.github.com/repos/rust-lang/rust/commits/8dbf8f5f0a26a8f80f895294532ad567c156beb3", "html_url": "https://github.com/rust-lang/rust/commit/8dbf8f5f0a26a8f80f895294532ad567c156beb3"}], "stats": {"total": 294, "additions": 111, "deletions": 183}, "files": [{"sha": "2f0ae540fbf07c7d1d4a2db33155ac6d253c95d9", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -147,7 +147,7 @@ fn write_source(sess: &parse::ParseSess,\n             }\n \n             // keywords are also included in the identifier set\n-            token::Ident(ident, _is_mod_sep) => {\n+            token::Ident(ident) => {\n                 match &*ident.name.as_str() {\n                     \"ref\" | \"mut\" => \"kw-2\",\n "}, {"sha": "0e825b8c2fe3c9f4c06e015778a938fb80975d51", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -1206,8 +1206,7 @@ impl TokenTree {\n                 TokenTree::Delimited(sp, Rc::new(Delimited {\n                     delim: token::Bracket,\n                     open_span: sp,\n-                    tts: vec![TokenTree::Token(sp, token::Ident(token::str_to_ident(\"doc\"),\n-                                                                token::Plain)),\n+                    tts: vec![TokenTree::Token(sp, token::Ident(token::str_to_ident(\"doc\"))),\n                               TokenTree::Token(sp, token::Eq),\n                               TokenTree::Token(sp, token::Literal(\n                                   token::StrRaw(token::intern(&stripped), num_of_hashes), None))],\n@@ -1225,14 +1224,13 @@ impl TokenTree {\n             }\n             (&TokenTree::Token(sp, token::SpecialVarNt(var)), _) => {\n                 let v = [TokenTree::Token(sp, token::Dollar),\n-                         TokenTree::Token(sp, token::Ident(token::str_to_ident(var.as_str()),\n-                                                  token::Plain))];\n+                         TokenTree::Token(sp, token::Ident(token::str_to_ident(var.as_str())))];\n                 v[index].clone()\n             }\n-            (&TokenTree::Token(sp, token::MatchNt(name, kind, name_st, kind_st)), _) => {\n-                let v = [TokenTree::Token(sp, token::SubstNt(name, name_st)),\n+            (&TokenTree::Token(sp, token::MatchNt(name, kind)), _) => {\n+                let v = [TokenTree::Token(sp, token::SubstNt(name)),\n                          TokenTree::Token(sp, token::Colon),\n-                         TokenTree::Token(sp, token::Ident(kind, kind_st))];\n+                         TokenTree::Token(sp, token::Ident(kind))];\n                 v[index].clone()\n             }\n             (&TokenTree::Sequence(_, ref seq), _) => {"}, {"sha": "26088b1242e2a326d3eac0ee476148a754d5ee5d", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -54,7 +54,7 @@ pub fn expand_diagnostic_used<'cx>(ecx: &'cx mut ExtCtxt,\n                                    token_tree: &[TokenTree])\n                                    -> Box<MacResult+'cx> {\n     let code = match (token_tree.len(), token_tree.get(0)) {\n-        (1, Some(&TokenTree::Token(_, token::Ident(code, _)))) => code,\n+        (1, Some(&TokenTree::Token(_, token::Ident(code)))) => code,\n         _ => unreachable!()\n     };\n \n@@ -92,10 +92,10 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt,\n         token_tree.get(1),\n         token_tree.get(2)\n     ) {\n-        (1, Some(&TokenTree::Token(_, token::Ident(ref code, _))), None, None) => {\n+        (1, Some(&TokenTree::Token(_, token::Ident(ref code))), None, None) => {\n             (code, None)\n         },\n-        (3, Some(&TokenTree::Token(_, token::Ident(ref code, _))),\n+        (3, Some(&TokenTree::Token(_, token::Ident(ref code))),\n             Some(&TokenTree::Token(_, token::Comma)),\n             Some(&TokenTree::Token(_, token::Literal(token::StrRaw(description, _), None)))) => {\n             (code, Some(description))\n@@ -160,9 +160,9 @@ pub fn expand_build_diagnostic_array<'cx>(ecx: &'cx mut ExtCtxt,\n     let (crate_name, name) = match (&token_tree[0], &token_tree[2]) {\n         (\n             // Crate name.\n-            &TokenTree::Token(_, token::Ident(ref crate_name, _)),\n+            &TokenTree::Token(_, token::Ident(ref crate_name)),\n             // DIAGNOSTICS ident.\n-            &TokenTree::Token(_, token::Ident(ref name, _))\n+            &TokenTree::Token(_, token::Ident(ref name))\n         ) => (*&crate_name, name),\n         _ => unreachable!()\n     };"}, {"sha": "9734b49ba7ce29f653539e0851a3583414c0d86b", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 6, "deletions": 19, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -72,7 +72,7 @@ pub mod rt {\n \n     impl ToTokens for ast::Ident {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(DUMMY_SP, token::Ident(*self, token::Plain))]\n+            vec![TokenTree::Token(DUMMY_SP, token::Ident(*self))]\n         }\n     }\n \n@@ -646,14 +646,10 @@ fn expr_mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n                            cx.expr_usize(sp, n))\n         }\n \n-        token::Ident(ident, style) => {\n+        token::Ident(ident) => {\n             return cx.expr_call(sp,\n                                 mk_token_path(cx, sp, \"Ident\"),\n-                                vec![mk_ident(cx, sp, ident),\n-                                     match style {\n-                                        ModName => mk_token_path(cx, sp, \"ModName\"),\n-                                        Plain   => mk_token_path(cx, sp, \"Plain\"),\n-                                     }]);\n+                                vec![mk_ident(cx, sp, ident)]);\n         }\n \n         token::Lifetime(ident) => {\n@@ -668,19 +664,10 @@ fn expr_mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n                                 vec!(mk_name(cx, sp, ast::Ident::with_empty_ctxt(ident))));\n         }\n \n-        token::MatchNt(name, kind, namep, kindp) => {\n+        token::MatchNt(name, kind) => {\n             return cx.expr_call(sp,\n                                 mk_token_path(cx, sp, \"MatchNt\"),\n-                                vec!(mk_ident(cx, sp, name),\n-                                     mk_ident(cx, sp, kind),\n-                                     match namep {\n-                                        ModName => mk_token_path(cx, sp, \"ModName\"),\n-                                        Plain   => mk_token_path(cx, sp, \"Plain\"),\n-                                     },\n-                                     match kindp {\n-                                        ModName => mk_token_path(cx, sp, \"ModName\"),\n-                                        Plain   => mk_token_path(cx, sp, \"Plain\"),\n-                                     }));\n+                                vec![mk_ident(cx, sp, name), mk_ident(cx, sp, kind)]);\n         }\n \n         token::Interpolated(_) => panic!(\"quote! with interpolated token\"),\n@@ -722,7 +709,7 @@ fn expr_mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n \n fn statements_mk_tt(cx: &ExtCtxt, tt: &TokenTree, matcher: bool) -> Vec<ast::Stmt> {\n     match *tt {\n-        TokenTree::Token(sp, SubstNt(ident, _)) => {\n+        TokenTree::Token(sp, SubstNt(ident)) => {\n             // tt.extend($ident.to_tokens(ext_cx))\n \n             let e_to_toks ="}, {"sha": "8b33bbd37000d0af32cc9aac23dee967475a6417", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -216,7 +216,7 @@ pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n                     n_rec(p_s, next_m, res, ret_val, idx)?;\n                 }\n             }\n-            TokenTree::Token(sp, MatchNt(bind_name, _, _, _)) => {\n+            TokenTree::Token(sp, MatchNt(bind_name, _)) => {\n                 match ret_val.entry(bind_name.name) {\n                     Vacant(spot) => {\n                         spot.insert(res[*idx].clone());\n@@ -263,7 +263,7 @@ pub type PositionalParseResult = ParseResult<Vec<Rc<NamedMatch>>>;\n /// unhygienic comparison)\n pub fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n     match (t1,t2) {\n-        (&token::Ident(id1,_),&token::Ident(id2,_))\n+        (&token::Ident(id1),&token::Ident(id2))\n         | (&token::Lifetime(id1),&token::Lifetime(id2)) =>\n             id1.name == id2.name,\n         _ => *t1 == *t2\n@@ -451,7 +451,7 @@ pub fn parse(sess: &ParseSess,\n             if (!bb_eis.is_empty() && !next_eis.is_empty())\n                 || bb_eis.len() > 1 {\n                 let nts = bb_eis.iter().map(|ei| match ei.top_elts.get_tt(ei.idx) {\n-                    TokenTree::Token(_, MatchNt(bind, name, _, _)) => {\n+                    TokenTree::Token(_, MatchNt(bind, name)) => {\n                         format!(\"{} ('{}')\", name, bind)\n                     }\n                     _ => panic!()\n@@ -479,7 +479,7 @@ pub fn parse(sess: &ParseSess,\n \n                 let mut ei = bb_eis.pop().unwrap();\n                 match ei.top_elts.get_tt(ei.idx) {\n-                    TokenTree::Token(span, MatchNt(_, ident, _, _)) => {\n+                    TokenTree::Token(span, MatchNt(_, ident)) => {\n                         let match_cur = ei.match_cur;\n                         (&mut ei.matches[match_cur]).push(Rc::new(MatchedNonterminal(\n                             parse_nt(&mut rust_parser, span, &ident.name.as_str()))));\n@@ -534,9 +534,9 @@ pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         \"ty\" => token::NtTy(panictry!(p.parse_ty())),\n         // this could be handled like a token, since it is one\n         \"ident\" => match p.token {\n-            token::Ident(sn,b) => {\n+            token::Ident(sn) => {\n                 p.bump();\n-                token::NtIdent(Box::new(Spanned::<Ident>{node: sn, span: p.span}),b)\n+                token::NtIdent(Box::new(Spanned::<Ident>{node: sn, span: p.span}))\n             }\n             _ => {\n                 let token_str = pprust::token_to_string(&p.token);"}, {"sha": "abb17de47eae43c489b9c67982b721059de75869", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 10, "deletions": 12, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -244,8 +244,8 @@ pub fn compile<'cx>(cx: &'cx mut ExtCtxt,\n     // $( $lhs:tt => $rhs:tt );+\n     // ...quasiquoting this would be nice.\n     // These spans won't matter, anyways\n-    let match_lhs_tok = MatchNt(lhs_nm, special_idents::tt, token::Plain, token::Plain);\n-    let match_rhs_tok = MatchNt(rhs_nm, special_idents::tt, token::Plain, token::Plain);\n+    let match_lhs_tok = MatchNt(lhs_nm, special_idents::tt);\n+    let match_rhs_tok = MatchNt(rhs_nm, special_idents::tt);\n     let argument_gram = vec!(\n         TokenTree::Sequence(DUMMY_SP,\n                    Rc::new(ast::SequenceRepetition {\n@@ -415,7 +415,7 @@ fn check_matcher_old<'a, I>(cx: &mut ExtCtxt, matcher: I, follow: &Token, on_fai\n     let mut tokens = matcher.peekable();\n     while let Some(token) = tokens.next() {\n         last = match *token {\n-            TokenTree::Token(sp, MatchNt(ref name, ref frag_spec, _, _)) => {\n+            TokenTree::Token(sp, MatchNt(ref name, ref frag_spec)) => {\n                 // ii. If T is a simple NT, look ahead to the next token T' in\n                 // M. If T' is in the set FOLLOW(NT), continue. Else; reject.\n                 if can_be_followed_by_any(&frag_spec.name.as_str()) {\n@@ -881,7 +881,7 @@ fn check_matcher_core(cx: &mut ExtCtxt,\n         // Now `last` holds the complete set of NT tokens that could\n         // end the sequence before SUFFIX. Check that every one works with `suffix`.\n         'each_last: for &(_sp, ref t) in &last.tokens {\n-            if let MatchNt(ref name, ref frag_spec, _, _) = *t {\n+            if let MatchNt(ref name, ref frag_spec) = *t {\n                 for &(sp, ref next_token) in &suffix_first.tokens {\n                     match is_in_follow(cx, next_token, &frag_spec.name.as_str()) {\n                         Err(msg) => {\n@@ -917,9 +917,8 @@ fn check_matcher_core(cx: &mut ExtCtxt,\n     last\n }\n \n-\n fn token_can_be_followed_by_any(tok: &Token) -> bool {\n-    if let &MatchNt(_, ref frag_spec, _, _) = tok {\n+    if let &MatchNt(_, ref frag_spec) = tok {\n         frag_can_be_followed_by_any(&frag_spec.name.as_str())\n     } else {\n         // (Non NT's can always be followed by anthing in matchers.)\n@@ -1005,18 +1004,17 @@ fn is_in_follow(_: &ExtCtxt, tok: &Token, frag: &str) -> Result<bool, String> {\n             \"pat\" => {\n                 match *tok {\n                     FatArrow | Comma | Eq | BinOp(token::Or) => Ok(true),\n-                    Ident(i, _) if (i.name.as_str() == \"if\" ||\n-                                    i.name.as_str() == \"in\") => Ok(true),\n+                    Ident(i) if (i.name.as_str() == \"if\" ||\n+                                 i.name.as_str() == \"in\") => Ok(true),\n                     _ => Ok(false)\n                 }\n             },\n             \"path\" | \"ty\" => {\n                 match *tok {\n                     OpenDelim(token::DelimToken::Brace) | OpenDelim(token::DelimToken::Bracket) |\n                     Comma | FatArrow | Colon | Eq | Gt | Semi | BinOp(token::Or) => Ok(true),\n-                    MatchNt(_, ref frag, _, _) if frag.name.as_str() == \"block\" => Ok(true),\n-                    Ident(i, _) if (i.name.as_str() == \"as\" ||\n-                                    i.name.as_str() == \"where\") => Ok(true),\n+                    MatchNt(_, ref frag) if frag.name.as_str() == \"block\" => Ok(true),\n+                    Ident(i) if i.name.as_str() == \"as\" || i.name.as_str() == \"where\" => Ok(true),\n                     _ => Ok(false)\n                 }\n             },\n@@ -1036,7 +1034,7 @@ fn is_in_follow(_: &ExtCtxt, tok: &Token, frag: &str) -> Result<bool, String> {\n \n fn has_legal_fragment_specifier(tok: &Token) -> Result<(), String> {\n     debug!(\"has_legal_fragment_specifier({:?})\", tok);\n-    if let &MatchNt(_, ref frag_spec, _, _) = tok {\n+    if let &MatchNt(_, ref frag_spec) = tok {\n         let s = &frag_spec.name.as_str();\n         if !is_legal_fragment_specifier(s) {\n             return Err(s.to_string());"}, {"sha": "7f53d0f412cca268cccabc3382e56e64fc0aef82", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -161,7 +161,7 @@ fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n                 size + lockstep_iter_size(tt, r)\n             })\n         },\n-        TokenTree::Token(_, SubstNt(name, _)) | TokenTree::Token(_, MatchNt(name, _, _, _)) =>\n+        TokenTree::Token(_, SubstNt(name)) | TokenTree::Token(_, MatchNt(name, _)) =>\n             match lookup_cur_matched(r, name) {\n                 Some(matched) => match *matched {\n                     MatchedNonterminal(_) => LisUnconstrained,\n@@ -186,7 +186,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n             None => (),\n             Some(sp) => {\n                 r.cur_span = sp;\n-                r.cur_tok = token::Ident(r.imported_from.unwrap(), token::Plain);\n+                r.cur_tok = token::Ident(r.imported_from.unwrap());\n                 return ret_val;\n             },\n         }\n@@ -278,12 +278,12 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 }\n             }\n             // FIXME #2887: think about span stuff here\n-            TokenTree::Token(sp, SubstNt(ident, namep)) => {\n+            TokenTree::Token(sp, SubstNt(ident)) => {\n                 r.stack.last_mut().unwrap().idx += 1;\n                 match lookup_cur_matched(r, ident) {\n                     None => {\n                         r.cur_span = sp;\n-                        r.cur_tok = SubstNt(ident, namep);\n+                        r.cur_tok = SubstNt(ident);\n                         return ret_val;\n                         // this can't be 0 length, just like TokenTree::Delimited\n                     }\n@@ -292,9 +292,9 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                             // sidestep the interpolation tricks for ident because\n                             // (a) idents can be in lots of places, so it'd be a pain\n                             // (b) we actually can, since it's a token.\n-                            MatchedNonterminal(NtIdent(ref sn, b)) => {\n+                            MatchedNonterminal(NtIdent(ref sn)) => {\n                                 r.cur_span = sn.span;\n-                                r.cur_tok = token::Ident(sn.node, b);\n+                                r.cur_tok = token::Ident(sn.node);\n                                 return ret_val;\n                             }\n                             MatchedNonterminal(ref other_whole_nt) => {"}, {"sha": "69c420902c8a0724ad97ae1cd91edfa7e8f953ba", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 5, "deletions": 12, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -610,17 +610,11 @@ pub fn noop_fold_tts<T: Folder>(tts: &[TokenTree], fld: &mut T) -> Vec<TokenTree\n // apply ident folder if it's an ident, apply other folds to interpolated nodes\n pub fn noop_fold_token<T: Folder>(t: token::Token, fld: &mut T) -> token::Token {\n     match t {\n-        token::Ident(id, followed_by_colons) => {\n-            token::Ident(fld.fold_ident(id), followed_by_colons)\n-        }\n+        token::Ident(id) => token::Ident(fld.fold_ident(id)),\n         token::Lifetime(id) => token::Lifetime(fld.fold_ident(id)),\n         token::Interpolated(nt) => token::Interpolated(fld.fold_interpolated(nt)),\n-        token::SubstNt(ident, namep) => {\n-            token::SubstNt(fld.fold_ident(ident), namep)\n-        }\n-        token::MatchNt(name, kind, namep, kindp) => {\n-            token::MatchNt(fld.fold_ident(name), fld.fold_ident(kind), namep, kindp)\n-        }\n+        token::SubstNt(ident) => token::SubstNt(fld.fold_ident(ident)),\n+        token::MatchNt(name, kind) => token::MatchNt(fld.fold_ident(name), fld.fold_ident(kind)),\n         _ => t\n     }\n }\n@@ -664,9 +658,8 @@ pub fn noop_fold_interpolated<T: Folder>(nt: token::Nonterminal, fld: &mut T)\n         token::NtPat(pat) => token::NtPat(fld.fold_pat(pat)),\n         token::NtExpr(expr) => token::NtExpr(fld.fold_expr(expr)),\n         token::NtTy(ty) => token::NtTy(fld.fold_ty(ty)),\n-        token::NtIdent(id, is_mod_name) =>\n-            token::NtIdent(Box::new(Spanned::<Ident>{node: fld.fold_ident(id.node), .. *id}),\n-                           is_mod_name),\n+        token::NtIdent(id) =>\n+            token::NtIdent(Box::new(Spanned::<Ident>{node: fld.fold_ident(id.node), ..*id})),\n         token::NtMeta(meta_item) => token::NtMeta(fld.fold_meta_item(meta_item)),\n         token::NtPath(path) => token::NtPath(Box::new(fld.fold_path(*path))),\n         token::NtTT(tt) => token::NtTT(P(fld.fold_tt(&tt))),"}, {"sha": "265a432ae8267536062dc56309e3c96b5d79b6c0", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 10, "deletions": 25, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -1039,11 +1039,7 @@ impl<'a> StringReader<'a> {\n                     token::Underscore\n                 } else {\n                     // FIXME: perform NFKC normalization here. (Issue #2253)\n-                    if self.curr_is(':') && self.nextch_is(':') {\n-                        token::Ident(str_to_ident(string), token::ModName)\n-                    } else {\n-                        token::Ident(str_to_ident(string), token::Plain)\n-                    }\n+                    token::Ident(str_to_ident(string))\n                 }\n             });\n         }\n@@ -1231,8 +1227,7 @@ impl<'a> StringReader<'a> {\n                     let keyword_checking_ident = self.with_str_from(start, |lifetime_name| {\n                         str_to_ident(lifetime_name)\n                     });\n-                    let keyword_checking_token = &token::Ident(keyword_checking_ident,\n-                                                               token::Plain);\n+                    let keyword_checking_token = &token::Ident(keyword_checking_ident);\n                     let last_bpos = self.last_pos;\n                     if keyword_checking_token.is_keyword(token::keywords::SelfValue) {\n                         self.err_span_(start,\n@@ -1687,7 +1682,7 @@ mod tests {\n         assert_eq!(string_reader.next_token().tok, token::Whitespace);\n         let tok1 = string_reader.next_token();\n         let tok2 = TokenAndSpan {\n-            tok: token::Ident(id, token::Plain),\n+            tok: token::Ident(id),\n             sp: Span {\n                 lo: BytePos(21),\n                 hi: BytePos(23),\n@@ -1701,7 +1696,7 @@ mod tests {\n         // read another token:\n         let tok3 = string_reader.next_token();\n         let tok4 = TokenAndSpan {\n-            tok: token::Ident(str_to_ident(\"main\"), token::Plain),\n+            tok: token::Ident(str_to_ident(\"main\")),\n             sp: Span {\n                 lo: BytePos(24),\n                 hi: BytePos(28),\n@@ -1722,50 +1717,40 @@ mod tests {\n     }\n \n     // make the identifier by looking up the string in the interner\n-    fn mk_ident(id: &str, style: token::IdentStyle) -> token::Token {\n-        token::Ident(str_to_ident(id), style)\n+    fn mk_ident(id: &str) -> token::Token {\n+        token::Ident(str_to_ident(id))\n     }\n \n     #[test]\n     fn doublecolonparsing() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a b\".to_string()),\n-                           vec![mk_ident(\"a\", token::Plain),\n-                                token::Whitespace,\n-                                mk_ident(\"b\", token::Plain)]);\n+                           vec![mk_ident(\"a\"), token::Whitespace, mk_ident(\"b\")]);\n     }\n \n     #[test]\n     fn dcparsing_2() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a::b\".to_string()),\n-                           vec![mk_ident(\"a\", token::ModName),\n-                                token::ModSep,\n-                                mk_ident(\"b\", token::Plain)]);\n+                           vec![mk_ident(\"a\"), token::ModSep, mk_ident(\"b\")]);\n     }\n \n     #[test]\n     fn dcparsing_3() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a ::b\".to_string()),\n-                           vec![mk_ident(\"a\", token::Plain),\n-                                token::Whitespace,\n-                                token::ModSep,\n-                                mk_ident(\"b\", token::Plain)]);\n+                           vec![mk_ident(\"a\"), token::Whitespace, token::ModSep, mk_ident(\"b\")]);\n     }\n \n     #[test]\n     fn dcparsing_4() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a:: b\".to_string()),\n-                           vec![mk_ident(\"a\", token::ModName),\n-                                token::ModSep,\n-                                token::Whitespace,\n-                                mk_ident(\"b\", token::Plain)]);\n+                           vec![mk_ident(\"a\"), token::ModSep, token::Whitespace, mk_ident(\"b\")]);\n     }\n \n     #[test]"}, {"sha": "7534683a206ffb63e7354fd057efb404ad5b1f36", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 11, "deletions": 23, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -734,9 +734,9 @@ mod tests {\n         match (tts.len(), tts.get(0), tts.get(1), tts.get(2), tts.get(3)) {\n             (\n                 4,\n-                Some(&TokenTree::Token(_, token::Ident(name_macro_rules, token::Plain))),\n+                Some(&TokenTree::Token(_, token::Ident(name_macro_rules))),\n                 Some(&TokenTree::Token(_, token::Not)),\n-                Some(&TokenTree::Token(_, token::Ident(name_zip, token::Plain))),\n+                Some(&TokenTree::Token(_, token::Ident(name_zip))),\n                 Some(&TokenTree::Delimited(_, ref macro_delimed)),\n             )\n             if name_macro_rules.name.as_str() == \"macro_rules\"\n@@ -755,7 +755,7 @@ mod tests {\n                             (\n                                 2,\n                                 Some(&TokenTree::Token(_, token::Dollar)),\n-                                Some(&TokenTree::Token(_, token::Ident(ident, token::Plain))),\n+                                Some(&TokenTree::Token(_, token::Ident(ident))),\n                             )\n                             if first_delimed.delim == token::Paren\n                             && ident.name.as_str() == \"a\" => {},\n@@ -766,7 +766,7 @@ mod tests {\n                             (\n                                 2,\n                                 Some(&TokenTree::Token(_, token::Dollar)),\n-                                Some(&TokenTree::Token(_, token::Ident(ident, token::Plain))),\n+                                Some(&TokenTree::Token(_, token::Ident(ident))),\n                             )\n                             if second_delimed.delim == token::Paren\n                             && ident.name.as_str() == \"a\" => {},\n@@ -785,26 +785,17 @@ mod tests {\n         let tts = string_to_tts(\"fn a (b : i32) { b; }\".to_string());\n \n         let expected = vec![\n-            TokenTree::Token(sp(0, 2),\n-                         token::Ident(str_to_ident(\"fn\"),\n-                         token::IdentStyle::Plain)),\n-            TokenTree::Token(sp(3, 4),\n-                         token::Ident(str_to_ident(\"a\"),\n-                         token::IdentStyle::Plain)),\n+            TokenTree::Token(sp(0, 2), token::Ident(str_to_ident(\"fn\"))),\n+            TokenTree::Token(sp(3, 4), token::Ident(str_to_ident(\"a\"))),\n             TokenTree::Delimited(\n                 sp(5, 14),\n                 Rc::new(ast::Delimited {\n                     delim: token::DelimToken::Paren,\n                     open_span: sp(5, 6),\n                     tts: vec![\n-                        TokenTree::Token(sp(6, 7),\n-                                     token::Ident(str_to_ident(\"b\"),\n-                                     token::IdentStyle::Plain)),\n-                        TokenTree::Token(sp(8, 9),\n-                                     token::Colon),\n-                        TokenTree::Token(sp(10, 13),\n-                                     token::Ident(str_to_ident(\"i32\"),\n-                                     token::IdentStyle::Plain)),\n+                        TokenTree::Token(sp(6, 7), token::Ident(str_to_ident(\"b\"))),\n+                        TokenTree::Token(sp(8, 9), token::Colon),\n+                        TokenTree::Token(sp(10, 13), token::Ident(str_to_ident(\"i32\"))),\n                     ],\n                     close_span: sp(13, 14),\n                 })),\n@@ -814,11 +805,8 @@ mod tests {\n                     delim: token::DelimToken::Brace,\n                     open_span: sp(15, 16),\n                     tts: vec![\n-                        TokenTree::Token(sp(17, 18),\n-                                     token::Ident(str_to_ident(\"b\"),\n-                                     token::IdentStyle::Plain)),\n-                        TokenTree::Token(sp(18, 19),\n-                                     token::Semi)\n+                        TokenTree::Token(sp(17, 18), token::Ident(str_to_ident(\"b\"))),\n+                        TokenTree::Token(sp(18, 19), token::Semi),\n                     ],\n                     close_span: sp(20, 21),\n                 }))"}, {"sha": "71f059de0414557bf1d53f735c6e32453ecb1760", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 14, "deletions": 18, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -567,7 +567,7 @@ impl<'a> Parser<'a> {\n         }\n         self.check_reserved_keywords();\n         match self.token {\n-            token::Ident(i, _) => {\n+            token::Ident(i) => {\n                 self.bump();\n                 Ok(i)\n             }\n@@ -629,9 +629,8 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn check_contextual_keyword(&mut self, ident: Ident) -> bool {\n-        let tok = token::Ident(ident, token::Plain);\n-        self.expected_tokens.push(TokenType::Token(tok));\n-        if let token::Ident(ref cur_ident, _) = self.token {\n+        self.expected_tokens.push(TokenType::Token(token::Ident(ident)));\n+        if let token::Ident(ref cur_ident) = self.token {\n             cur_ident.name == ident.name\n         } else {\n             false\n@@ -1699,7 +1698,7 @@ impl<'a> Parser<'a> {\n \n     pub fn parse_path_segment_ident(&mut self) -> PResult<'a, ast::Ident> {\n         match self.token {\n-            token::Ident(sid, _) if self.token.is_path_segment_keyword() => {\n+            token::Ident(sid) if self.token.is_path_segment_keyword() => {\n                 self.bump();\n                 Ok(sid)\n             }\n@@ -2564,7 +2563,7 @@ impl<'a> Parser<'a> {\n             // expr.f\n             if self.eat(&token::Dot) {\n                 match self.token {\n-                  token::Ident(i, _) => {\n+                  token::Ident(i) => {\n                     let dot_pos = self.last_span.hi;\n                     hi = self.span.hi;\n                     self.bump();\n@@ -2661,7 +2660,7 @@ impl<'a> Parser<'a> {\n     // Parse unquoted tokens after a `$` in a token tree\n     fn parse_unquoted(&mut self) -> PResult<'a, TokenTree> {\n         let mut sp = self.span;\n-        let (name, namep) = match self.token {\n+        let name = match self.token {\n             token::Dollar => {\n                 self.bump();\n \n@@ -2686,14 +2685,12 @@ impl<'a> Parser<'a> {\n                     return Ok(TokenTree::Token(sp, SpecialVarNt(SpecialMacroVar::CrateMacroVar)));\n                 } else {\n                     sp = mk_sp(sp.lo, self.span.hi);\n-                    let namep = match self.token { token::Ident(_, p) => p, _ => token::Plain };\n-                    let name = self.parse_ident()?;\n-                    (name, namep)\n+                    self.parse_ident()?\n                 }\n             }\n-            token::SubstNt(name, namep) => {\n+            token::SubstNt(name) => {\n                 self.bump();\n-                (name, namep)\n+                name\n             }\n             _ => unreachable!()\n         };\n@@ -2703,18 +2700,17 @@ impl<'a> Parser<'a> {\n                                                                 !t.is_reserved_keyword()) {\n             self.bump();\n             sp = mk_sp(sp.lo, self.span.hi);\n-            let kindp = match self.token { token::Ident(_, p) => p, _ => token::Plain };\n             let nt_kind = self.parse_ident()?;\n-            Ok(TokenTree::Token(sp, MatchNt(name, nt_kind, namep, kindp)))\n+            Ok(TokenTree::Token(sp, MatchNt(name, nt_kind)))\n         } else {\n-            Ok(TokenTree::Token(sp, SubstNt(name, namep)))\n+            Ok(TokenTree::Token(sp, SubstNt(name)))\n         }\n     }\n \n     pub fn check_unknown_macro_variable(&mut self) {\n         if self.quote_depth == 0 {\n             match self.token {\n-                token::SubstNt(name, _) =>\n+                token::SubstNt(name) =>\n                     self.fatal(&format!(\"unknown macro variable `{}`\", name)).emit(),\n                 _ => {}\n             }\n@@ -4614,7 +4610,7 @@ impl<'a> Parser<'a> {\n \n     fn expect_self_ident(&mut self) -> PResult<'a, ast::Ident> {\n         match self.token {\n-            token::Ident(id, _) if id.name == special_idents::self_.name => {\n+            token::Ident(id) if id.name == special_idents::self_.name => {\n                 self.bump();\n                 Ok(id)\n             },\n@@ -4927,7 +4923,7 @@ impl<'a> Parser<'a> {\n             Visibility::Inherited => (),\n             _ => {\n                 let is_macro_rules: bool = match self.token {\n-                    token::Ident(sid, _) => sid.name == intern(\"macro_rules\"),\n+                    token::Ident(sid) => sid.name == intern(\"macro_rules\"),\n                     _ => false,\n                 };\n                 if is_macro_rules {"}, {"sha": "76bd0f66cd8f4390fda0b9950c85381233261450", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 24, "deletions": 32, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -11,7 +11,6 @@\n pub use self::BinOpToken::*;\n pub use self::Nonterminal::*;\n pub use self::DelimToken::*;\n-pub use self::IdentStyle::*;\n pub use self::Lit::*;\n pub use self::Token::*;\n \n@@ -51,13 +50,6 @@ pub enum DelimToken {\n     Brace,\n }\n \n-#[derive(Clone, RustcEncodable, RustcDecodable, PartialEq, Eq, Hash, Debug, Copy)]\n-pub enum IdentStyle {\n-    /// `::` follows the identifier with no whitespace in-between.\n-    ModName,\n-    Plain,\n-}\n-\n #[derive(Clone, RustcEncodable, RustcDecodable, PartialEq, Eq, Hash, Debug, Copy)]\n pub enum SpecialMacroVar {\n     /// `$crate` will be filled in with the name of the crate a macro was\n@@ -139,7 +131,7 @@ pub enum Token {\n     Literal(Lit, Option<ast::Name>),\n \n     /* Name components */\n-    Ident(ast::Ident, IdentStyle),\n+    Ident(ast::Ident),\n     Underscore,\n     Lifetime(ast::Ident),\n \n@@ -150,10 +142,10 @@ pub enum Token {\n     DocComment(ast::Name),\n     // In left-hand-sides of MBE macros:\n     /// Parse a nonterminal (name to bind, name of NT, styles of their idents)\n-    MatchNt(ast::Ident, ast::Ident, IdentStyle, IdentStyle),\n+    MatchNt(ast::Ident, ast::Ident),\n     // In right-hand-sides of MBE macros:\n     /// A syntactic variable that will be filled in by macro expansion.\n-    SubstNt(ast::Ident, IdentStyle),\n+    SubstNt(ast::Ident),\n     /// A macro variable with special meaning.\n     SpecialVarNt(SpecialMacroVar),\n \n@@ -279,51 +271,51 @@ impl Token {\n     /// Returns `true` if the token is a given keyword, `kw`.\n     pub fn is_keyword(&self, kw: keywords::Keyword) -> bool {\n         match *self {\n-            Ident(id, _) => id.name == kw.to_name(),\n+            Ident(id) => id.name == kw.to_name(),\n             _ => false,\n         }\n     }\n \n     pub fn is_path_segment_keyword(&self) -> bool {\n         match *self {\n-            Ident(id, _) => id.name == SUPER_KEYWORD_NAME ||\n-                            id.name == SELF_KEYWORD_NAME ||\n-                            id.name == SELF_TYPE_KEYWORD_NAME,\n+            Ident(id) => id.name == SUPER_KEYWORD_NAME ||\n+                         id.name == SELF_KEYWORD_NAME ||\n+                         id.name == SELF_TYPE_KEYWORD_NAME,\n             _ => false,\n         }\n     }\n \n     /// Returns `true` if the token is either a strict or reserved keyword.\n     pub fn is_any_keyword(&self) -> bool {\n         match *self {\n-            Ident(id, _) => id.name == SELF_KEYWORD_NAME ||\n-                            id.name == STATIC_KEYWORD_NAME ||\n-                            id.name == SUPER_KEYWORD_NAME ||\n-                            id.name == SELF_TYPE_KEYWORD_NAME ||\n-                            id.name >= STRICT_KEYWORD_START &&\n-                            id.name <= RESERVED_KEYWORD_FINAL,\n+            Ident(id) => id.name == SELF_KEYWORD_NAME ||\n+                         id.name == STATIC_KEYWORD_NAME ||\n+                         id.name == SUPER_KEYWORD_NAME ||\n+                         id.name == SELF_TYPE_KEYWORD_NAME ||\n+                         id.name >= STRICT_KEYWORD_START &&\n+                         id.name <= RESERVED_KEYWORD_FINAL,\n             _ => false\n         }\n     }\n \n     /// Returns `true` if the token is either a strict keyword.\n     pub fn is_strict_keyword(&self) -> bool {\n         match *self {\n-            Ident(id, _) => id.name == SELF_KEYWORD_NAME ||\n-                            id.name == STATIC_KEYWORD_NAME ||\n-                            id.name == SUPER_KEYWORD_NAME ||\n-                            id.name == SELF_TYPE_KEYWORD_NAME ||\n-                            id.name >= STRICT_KEYWORD_START &&\n-                            id.name <= STRICT_KEYWORD_FINAL,\n+            Ident(id) => id.name == SELF_KEYWORD_NAME ||\n+                         id.name == STATIC_KEYWORD_NAME ||\n+                         id.name == SUPER_KEYWORD_NAME ||\n+                         id.name == SELF_TYPE_KEYWORD_NAME ||\n+                         id.name >= STRICT_KEYWORD_START &&\n+                         id.name <= STRICT_KEYWORD_FINAL,\n             _ => false,\n         }\n     }\n \n     /// Returns `true` if the token is either a keyword reserved for possible future use.\n     pub fn is_reserved_keyword(&self) -> bool {\n         match *self {\n-            Ident(id, _) => id.name >= RESERVED_KEYWORD_START &&\n-                            id.name <= RESERVED_KEYWORD_FINAL,\n+            Ident(id) => id.name >= RESERVED_KEYWORD_START &&\n+                         id.name <= RESERVED_KEYWORD_FINAL,\n             _ => false,\n         }\n     }\n@@ -333,7 +325,7 @@ impl Token {\n     /// See `styntax::ext::mtwt`.\n     pub fn mtwt_eq(&self, other : &Token) -> bool {\n         match (self, other) {\n-            (&Ident(id1,_), &Ident(id2,_)) | (&Lifetime(id1), &Lifetime(id2)) =>\n+            (&Ident(id1), &Ident(id2)) | (&Lifetime(id1), &Lifetime(id2)) =>\n                 mtwt::resolve(id1) == mtwt::resolve(id2),\n             _ => *self == *other\n         }\n@@ -349,7 +341,7 @@ pub enum Nonterminal {\n     NtPat(P<ast::Pat>),\n     NtExpr(P<ast::Expr>),\n     NtTy(P<ast::Ty>),\n-    NtIdent(Box<ast::SpannedIdent>, IdentStyle),\n+    NtIdent(Box<ast::SpannedIdent>),\n     /// Stuff inside brackets for attributes\n     NtMeta(P<ast::MetaItem>),\n     NtPath(Box<ast::Path>),\n@@ -743,6 +735,6 @@ mod tests {\n         assert!(Gt.mtwt_eq(&Gt));\n         let a = str_to_ident(\"bac\");\n         let a1 = mark_ident(a,92);\n-        assert!(Ident(a, ModName).mtwt_eq(&Ident(a1, Plain)));\n+        assert!(Ident(a).mtwt_eq(&Ident(a1)));\n     }\n }"}, {"sha": "4fe076b3a7b517ef8b6331a8b3bcda53d775a4b6", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 5, "deletions": 14, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -270,14 +270,14 @@ pub fn token_to_string(tok: &Token) -> String {\n         }\n \n         /* Name components */\n-        token::Ident(s, _)          => s.to_string(),\n+        token::Ident(s)             => s.to_string(),\n         token::Lifetime(s)          => s.to_string(),\n         token::Underscore           => \"_\".to_string(),\n \n         /* Other */\n         token::DocComment(s)        => s.to_string(),\n-        token::SubstNt(s, _)        => format!(\"${}\", s),\n-        token::MatchNt(s, t, _, _)  => format!(\"${}:{}\", s, t),\n+        token::SubstNt(s)           => format!(\"${}\", s),\n+        token::MatchNt(s, t)        => format!(\"${}:{}\", s, t),\n         token::Eof                  => \"<eof>\".to_string(),\n         token::Whitespace           => \" \".to_string(),\n         token::Comment              => \"/* */\".to_string(),\n@@ -294,7 +294,7 @@ pub fn token_to_string(tok: &Token) -> String {\n             token::NtBlock(ref e)       => block_to_string(&e),\n             token::NtStmt(ref e)        => stmt_to_string(&e),\n             token::NtPat(ref e)         => pat_to_string(&e),\n-            token::NtIdent(ref e, _)    => ident_to_string(e.node),\n+            token::NtIdent(ref e)       => ident_to_string(e.node),\n             token::NtTT(ref e)          => tt_to_string(&e),\n             token::NtArm(ref e)         => arm_to_string(&e),\n             token::NtImplItem(ref e)    => impl_item_to_string(&e),\n@@ -1488,20 +1488,11 @@ impl<'a> State<'a> {\n \n     pub fn print_tts(&mut self, tts: &[ast::TokenTree]) -> io::Result<()> {\n         self.ibox(0)?;\n-        let mut suppress_space = false;\n         for (i, tt) in tts.iter().enumerate() {\n-            if i != 0 && !suppress_space {\n+            if i != 0 {\n                 space(&mut self.s)?;\n             }\n             self.print_tt(tt)?;\n-            // There should be no space between the module name and the following `::` in paths,\n-            // otherwise imported macros get re-parsed from crate metadata incorrectly (#20701)\n-            suppress_space = match *tt {\n-                TokenTree::Token(_, token::Ident(_, token::ModName)) |\n-                TokenTree::Token(_, token::MatchNt(_, _, _, token::ModName)) |\n-                TokenTree::Token(_, token::SubstNt(_, token::ModName)) => true,\n-                _ => false\n-            }\n         }\n         self.end()\n     }"}, {"sha": "dce808756cf6a0a2ee0a89cb425a00b2ba75d981", "filename": "src/libsyntax_ext/concat_idents.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax_ext%2Fconcat_idents.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax_ext%2Fconcat_idents.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fconcat_idents.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -40,7 +40,7 @@ pub fn expand_syntax_ext<'cx>(cx: &mut ExtCtxt, sp: Span, tts: &[TokenTree])\n             }\n         } else {\n             match *e {\n-                TokenTree::Token(_, token::Ident(ident, _)) => {\n+                TokenTree::Token(_, token::Ident(ident)) => {\n                     res_str.push_str(&ident.name.as_str())\n                 },\n                 _ => {"}, {"sha": "c8341a057a1c9a7c5890000e3c75f2665146ecfc", "filename": "src/libsyntax_ext/format.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax_ext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Flibsyntax_ext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fformat.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -106,7 +106,7 @@ fn parse_args(ecx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n         if named || (p.token.is_ident() && p.look_ahead(1, |t| *t == token::Eq)) {\n             named = true;\n             let ident = match p.token {\n-                token::Ident(i, _) => {\n+                token::Ident(i) => {\n                     p.bump();\n                     i\n                 }"}, {"sha": "839ece49c3eb5d4c90cf2fea1321e2c98af91890", "filename": "src/test/auxiliary/roman_numerals.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/546c052d225d41cd31f610e87a20f15cd0fa8e3c/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Froman_numerals.rs?ref=546c052d225d41cd31f610e87a20f15cd0fa8e3c", "patch": "@@ -48,7 +48,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n     }\n \n     let text = match args[0] {\n-        TokenTree::Token(_, token::Ident(s, _)) => s.to_string(),\n+        TokenTree::Token(_, token::Ident(s)) => s.to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}]}