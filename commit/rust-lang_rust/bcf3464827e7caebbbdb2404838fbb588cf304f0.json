{"sha": "bcf3464827e7caebbbdb2404838fbb588cf304f0", "node_id": "MDY6Q29tbWl0NzI0NzEyOmJjZjM0NjQ4MjdlN2NhZWJiYmRiMjQwNDgzOGZiYjU4OGNmMzA0ZjA=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-05-31T11:26:40Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-05-31T11:26:40Z"}, "message": "auto merge of #14556 : sfackler/rust/kill-workcache, r=alexcrichton\n\nThis was only ever used by rustpkg and is very unmaintained.\r\n\r\n[breaking-change]", "tree": {"sha": "a9059b9f02fc81b840bf59aafa34165009237db1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a9059b9f02fc81b840bf59aafa34165009237db1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bcf3464827e7caebbbdb2404838fbb588cf304f0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bcf3464827e7caebbbdb2404838fbb588cf304f0", "html_url": "https://github.com/rust-lang/rust/commit/bcf3464827e7caebbbdb2404838fbb588cf304f0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bcf3464827e7caebbbdb2404838fbb588cf304f0/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2652ba1505051160b946830c69c960ed283851d8", "url": "https://api.github.com/repos/rust-lang/rust/commits/2652ba1505051160b946830c69c960ed283851d8", "html_url": "https://github.com/rust-lang/rust/commit/2652ba1505051160b946830c69c960ed283851d8"}, {"sha": "c56c286b108d05b4f08d3246eb6dd1e9d64a5437", "url": "https://api.github.com/repos/rust-lang/rust/commits/c56c286b108d05b4f08d3246eb6dd1e9d64a5437", "html_url": "https://github.com/rust-lang/rust/commit/c56c286b108d05b4f08d3246eb6dd1e9d64a5437"}], "stats": {"total": 538, "additions": 1, "deletions": 537}, "files": [{"sha": "cccbfe0dd4ff2347b560f4bc4574db907c50404d", "filename": "mk/crates.mk", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/bcf3464827e7caebbbdb2404838fbb588cf304f0/mk%2Fcrates.mk", "raw_url": "https://github.com/rust-lang/rust/raw/bcf3464827e7caebbbdb2404838fbb588cf304f0/mk%2Fcrates.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fcrates.mk?ref=bcf3464827e7caebbbdb2404838fbb588cf304f0", "patch": "@@ -51,7 +51,7 @@\n \n TARGET_CRATES := libc std green rustuv native flate arena glob term semver \\\n                  uuid serialize sync getopts collections num test time rand \\\n-\t\t workcache url log regex graphviz core rlibc alloc debug\n+                 url log regex graphviz core rlibc alloc debug\n HOST_CRATES := syntax rustc rustdoc fourcc hexfloat regex_macros fmt_macros\n CRATES := $(TARGET_CRATES) $(HOST_CRATES)\n TOOLS := compiletest rustdoc rustc\n@@ -88,7 +88,6 @@ DEPS_test := std collections getopts serialize term time regex\n DEPS_time := std serialize sync\n DEPS_rand := core\n DEPS_url := std collections\n-DEPS_workcache := std serialize collections log\n DEPS_log := std sync\n DEPS_regex := std collections\n DEPS_regex_macros = syntax std regex"}, {"sha": "7c3fc18dd04123db0482fb0c0921837d0253d845", "filename": "src/libworkcache/lib.rs", "status": "removed", "additions": 0, "deletions": 535, "changes": 535, "blob_url": "https://github.com/rust-lang/rust/blob/2652ba1505051160b946830c69c960ed283851d8/src%2Flibworkcache%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2652ba1505051160b946830c69c960ed283851d8/src%2Flibworkcache%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibworkcache%2Flib.rs?ref=2652ba1505051160b946830c69c960ed283851d8", "patch": "@@ -1,535 +0,0 @@\n-// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! A simple function caching system.\n-//!\n-//! This is a loose clone of the [fbuild build system](https://github.com/felix-lang/fbuild),\n-//! made a touch more generic (not wired to special cases on files) and much\n-//! less metaprogram-y due to rust's comparative weakness there, relative to\n-//! python.\n-//!\n-//! It's based around _imperative builds_ that happen to have some function\n-//! calls cached. That is, it's _just_ a mechanism for describing cached\n-//! functions. This makes it much simpler and smaller than a \"build system\"\n-//! that produces an IR and evaluates it. The evaluation order is normal\n-//! function calls. Some of them just return really quickly.\n-//!\n-//! A cached function consumes and produces a set of _works_. A work has a\n-//! name, a kind (that determines how the value is to be checked for\n-//! freshness) and a value. Works must also be (de)serializable. Some\n-//! examples of works:\n-//!\n-//!    kind   name    value\n-//!   ------------------------\n-//!    cfg    os      linux\n-//!    file   foo.c   <sha1>\n-//!    url    foo.com <etag>\n-//!\n-//! Works are conceptually single units, but we store them most of the time\n-//! in maps of the form (type,name) => value. These are WorkMaps.\n-//!\n-//! A cached function divides the works it's interested in into inputs and\n-//! outputs, and subdivides those into declared (input) works and\n-//! discovered (input and output) works.\n-//!\n-//! A _declared_ input or is one that is given to the workcache before\n-//! any work actually happens, in the \"prep\" phase. Even when a function's\n-//! work-doing part (the \"exec\" phase) never gets called, it has declared\n-//! inputs, which can be checked for freshness (and potentially\n-//! used to determine that the function can be skipped).\n-//!\n-//! The workcache checks _all_ works for freshness, but uses the set of\n-//! discovered outputs from the _previous_ exec (which it will re-discover\n-//! and re-record each time the exec phase runs).\n-//!\n-//! Therefore the discovered works cached in the db might be a\n-//! mis-approximation of the current discoverable works, but this is ok for\n-//! the following reason: we assume that if an artifact A changed from\n-//! depending on B,C,D to depending on B,C,D,E, then A itself changed (as\n-//! part of the change-in-dependencies), so we will be ok.\n-//!\n-//! Each function has a single discriminated output work called its _result_.\n-//! This is only different from other works in that it is returned, by value,\n-//! from a call to the cacheable function; the other output works are used in\n-//! passing to invalidate dependencies elsewhere in the cache, but do not\n-//! otherwise escape from a function invocation. Most functions only have one\n-//! output work anyways.\n-//!\n-//! A database (the central store of a workcache) stores a mappings:\n-//!\n-//! (fn_name,{declared_input}) => ({discovered_input},\n-//!                                {discovered_output},result)\n-//!\n-//! (Note: fbuild, which workcache is based on, has the concept of a declared\n-//! output as separate from a discovered output. This distinction exists only\n-//! as an artifact of how fbuild works: via annotations on function types\n-//! and metaprogramming, with explicit dependency declaration as a fallback.\n-//! Workcache is more explicit about dependencies, and as such treats all\n-//! outputs the same, as discovered-during-the-last-run.)\n-\n-#![crate_id = \"workcache#0.11.0-pre\"]\n-#![crate_type = \"rlib\"]\n-#![crate_type = \"dylib\"]\n-#![license = \"MIT/ASL2\"]\n-#![doc(html_logo_url = \"http://www.rust-lang.org/logos/rust-logo-128x128-blk-v2.png\",\n-       html_favicon_url = \"http://www.rust-lang.org/favicon.ico\",\n-       html_root_url = \"http://doc.rust-lang.org/\")]\n-#![feature(phase)]\n-#![allow(visible_private_types)]\n-#![deny(deprecated_owned_vector)]\n-\n-#[phase(syntax, link)] extern crate log;\n-extern crate serialize;\n-extern crate collections;\n-extern crate sync;\n-\n-use serialize::json;\n-use serialize::json::ToJson;\n-use serialize::{Encoder, Encodable, Decoder, Decodable};\n-use sync::{Arc, RWLock};\n-use collections::TreeMap;\n-use std::str;\n-use std::io;\n-use std::io::{File, MemWriter};\n-\n-#[deriving(Clone, PartialEq, Encodable, Decodable, PartialOrd, TotalOrd, TotalEq)]\n-struct WorkKey {\n-    kind: String,\n-    name: String\n-}\n-\n-impl WorkKey {\n-    pub fn new(kind: &str, name: &str) -> WorkKey {\n-        WorkKey {\n-            kind: kind.to_string(),\n-            name: name.to_string(),\n-        }\n-    }\n-}\n-\n-// FIXME #8883: The key should be a WorkKey and not a String.\n-// This is working around some JSON weirdness.\n-#[deriving(Clone, PartialEq, Encodable, Decodable)]\n-struct WorkMap(TreeMap<String, KindMap>);\n-\n-#[deriving(Clone, PartialEq, Encodable, Decodable)]\n-struct KindMap(TreeMap<String, String>);\n-\n-impl WorkMap {\n-    fn new() -> WorkMap { WorkMap(TreeMap::new()) }\n-\n-    fn insert_work_key(&mut self, k: WorkKey, val: String) {\n-        let WorkKey { kind, name } = k;\n-        let WorkMap(ref mut map) = *self;\n-        match map.find_mut(&name) {\n-            Some(&KindMap(ref mut m)) => { m.insert(kind, val); return; }\n-            None => ()\n-        }\n-        let mut new_map = TreeMap::new();\n-        new_map.insert(kind, val);\n-        map.insert(name, KindMap(new_map));\n-    }\n-}\n-\n-pub struct Database {\n-    db_filename: Path,\n-    db_cache: TreeMap<String, String>,\n-    pub db_dirty: bool,\n-}\n-\n-impl Database {\n-\n-    pub fn new(p: Path) -> Database {\n-        let mut rslt = Database {\n-            db_filename: p,\n-            db_cache: TreeMap::new(),\n-            db_dirty: false\n-        };\n-        if rslt.db_filename.exists() {\n-            rslt.load();\n-        }\n-        rslt\n-    }\n-\n-    pub fn prepare(&self,\n-                   fn_name: &str,\n-                   declared_inputs: &WorkMap)\n-                   -> Option<(WorkMap, WorkMap, String)> {\n-        let k = json_encode(&(fn_name, declared_inputs));\n-        match self.db_cache.find(&k) {\n-            None => None,\n-            Some(v) => Some(json_decode(v.as_slice()))\n-        }\n-    }\n-\n-    pub fn cache(&mut self,\n-                 fn_name: &str,\n-                 declared_inputs: &WorkMap,\n-                 discovered_inputs: &WorkMap,\n-                 discovered_outputs: &WorkMap,\n-                 result: &str) {\n-        let k = json_encode(&(fn_name, declared_inputs));\n-        let v = json_encode(&(discovered_inputs,\n-                              discovered_outputs,\n-                              result));\n-        self.db_cache.insert(k,v);\n-        self.db_dirty = true\n-    }\n-\n-    // FIXME #4330: This should have &mut self and should set self.db_dirty to false.\n-    fn save(&self) -> io::IoResult<()> {\n-        let mut f = File::create(&self.db_filename);\n-\n-        // FIXME(pcwalton): Yuck.\n-        let mut new_db_cache = TreeMap::new();\n-        for (ref k, ref v) in self.db_cache.iter() {\n-            new_db_cache.insert((*k).to_string(), (*v).to_string());\n-        }\n-\n-        new_db_cache.to_json().to_pretty_writer(&mut f)\n-    }\n-\n-    fn load(&mut self) {\n-        assert!(!self.db_dirty);\n-        assert!(self.db_filename.exists());\n-        match File::open(&self.db_filename) {\n-            Err(e) => fail!(\"Couldn't load workcache database {}: {}\",\n-                            self.db_filename.display(),\n-                            e),\n-            Ok(mut stream) => {\n-                match json::from_reader(&mut stream) {\n-                    Err(e) => fail!(\"Couldn't parse workcache database (from file {}): {}\",\n-                                    self.db_filename.display(), e.to_str()),\n-                    Ok(r) => {\n-                        let mut decoder = json::Decoder::new(r);\n-                        self.db_cache = Decodable::decode(&mut decoder).unwrap();\n-                    }\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl Drop for Database {\n-    fn drop(&mut self) {\n-        if self.db_dirty {\n-            // FIXME: is failing the right thing to do here\n-            self.save().unwrap();\n-        }\n-    }\n-}\n-\n-pub type FreshnessMap = TreeMap<String,extern fn(&str,&str)->bool>;\n-\n-#[deriving(Clone)]\n-pub struct Context {\n-    pub db: Arc<RWLock<Database>>,\n-    cfg: Arc<json::Object>,\n-    /// Map from kinds (source, exe, url, etc.) to a freshness function.\n-    /// The freshness function takes a name (e.g. file path) and value\n-    /// (e.g. hash of file contents) and determines whether it's up-to-date.\n-    /// For example, in the file case, this would read the file off disk,\n-    /// hash it, and return the result of comparing the given hash and the\n-    /// read hash for equality.\n-    freshness: Arc<FreshnessMap>\n-}\n-\n-pub struct Prep<'a> {\n-    ctxt: &'a Context,\n-    fn_name: &'a str,\n-    declared_inputs: WorkMap,\n-}\n-\n-pub struct Exec {\n-    discovered_inputs: WorkMap,\n-    discovered_outputs: WorkMap\n-}\n-\n-enum Work<'a, T> {\n-    WorkValue(T),\n-    WorkFromTask(&'a Prep<'a>, Receiver<(Exec, T)>),\n-}\n-\n-fn json_encode<'a, T:Encodable<json::Encoder<'a>, io::IoError>>(t: &T) -> String {\n-    let mut writer = MemWriter::new();\n-    let mut encoder = json::Encoder::new(&mut writer as &mut io::Writer);\n-    let _ = t.encode(&mut encoder);\n-    str::from_utf8(writer.unwrap().as_slice()).unwrap().to_string()\n-}\n-\n-// FIXME(#5121)\n-fn json_decode<T:Decodable<json::Decoder, json::DecoderError>>(s: &str) -> T {\n-    debug!(\"json decoding: {}\", s);\n-    let j = json::from_str(s).unwrap();\n-    let mut decoder = json::Decoder::new(j);\n-    Decodable::decode(&mut decoder).unwrap()\n-}\n-\n-impl Context {\n-\n-    pub fn new(db: Arc<RWLock<Database>>,\n-               cfg: Arc<json::Object>) -> Context {\n-        Context::new_with_freshness(db, cfg, Arc::new(TreeMap::new()))\n-    }\n-\n-    pub fn new_with_freshness(db: Arc<RWLock<Database>>,\n-                              cfg: Arc<json::Object>,\n-                              freshness: Arc<FreshnessMap>) -> Context {\n-        Context {\n-            db: db,\n-            cfg: cfg,\n-            freshness: freshness\n-        }\n-    }\n-\n-    pub fn prep<'a>(&'a self, fn_name: &'a str) -> Prep<'a> {\n-        Prep::new(self, fn_name)\n-    }\n-\n-    pub fn with_prep<'a,\n-                     T>(\n-                     &'a self,\n-                     fn_name: &'a str,\n-                     blk: |p: &mut Prep| -> T)\n-                     -> T {\n-        let mut p = self.prep(fn_name);\n-        blk(&mut p)\n-    }\n-\n-}\n-\n-impl Exec {\n-    pub fn discover_input(&mut self,\n-                          dependency_kind: &str,\n-                          dependency_name: &str,\n-                          dependency_val: &str) {\n-        debug!(\"Discovering input {} {} {}\", dependency_kind, dependency_name, dependency_val);\n-        self.discovered_inputs.insert_work_key(WorkKey::new(dependency_kind, dependency_name),\n-                                 dependency_val.to_string());\n-    }\n-    pub fn discover_output(&mut self,\n-                           dependency_kind: &str,\n-                           dependency_name: &str,\n-                           dependency_val: &str) {\n-        debug!(\"Discovering output {} {} {}\", dependency_kind, dependency_name, dependency_val);\n-        self.discovered_outputs.insert_work_key(WorkKey::new(dependency_kind, dependency_name),\n-                                 dependency_val.to_string());\n-    }\n-\n-    // returns pairs of (kind, name)\n-    pub fn lookup_discovered_inputs(&self) -> Vec<(String, String)> {\n-        let mut rs = vec![];\n-        let WorkMap(ref discovered_inputs) = self.discovered_inputs;\n-        for (k, v) in discovered_inputs.iter() {\n-            let KindMap(ref vmap) = *v;\n-            for (k1, _) in vmap.iter() {\n-                rs.push((k1.clone(), k.clone()));\n-            }\n-        }\n-        rs\n-    }\n-}\n-\n-impl<'a> Prep<'a> {\n-    fn new(ctxt: &'a Context, fn_name: &'a str) -> Prep<'a> {\n-        Prep {\n-            ctxt: ctxt,\n-            fn_name: fn_name,\n-            declared_inputs: WorkMap::new()\n-        }\n-    }\n-\n-    pub fn lookup_declared_inputs(&self) -> Vec<String> {\n-        let mut rs = vec![];\n-        let WorkMap(ref declared_inputs) = self.declared_inputs;\n-        for (_, v) in declared_inputs.iter() {\n-            let KindMap(ref vmap) = *v;\n-            for (inp, _) in vmap.iter() {\n-                rs.push(inp.clone());\n-            }\n-        }\n-        rs\n-    }\n-}\n-\n-impl<'a> Prep<'a> {\n-    pub fn declare_input(&mut self, kind: &str, name: &str, val: &str) {\n-        debug!(\"Declaring input {} {} {}\", kind, name, val);\n-        self.declared_inputs.insert_work_key(WorkKey::new(kind, name),\n-                                 val.to_string());\n-    }\n-\n-    fn is_fresh(&self, cat: &str, kind: &str, name: &str, val: &str) -> bool {\n-        let k = kind.to_string();\n-        let f = self.ctxt.freshness.deref().find(&k);\n-        debug!(\"freshness for: {}/{}/{}/{}\", cat, kind, name, val)\n-        let fresh = match f {\n-            None => fail!(\"missing freshness-function for '{}'\", kind),\n-            Some(f) => (*f)(name, val)\n-        };\n-        if fresh {\n-            info!(\"{} {}:{} is fresh\", cat, kind, name);\n-        } else {\n-            info!(\"{} {}:{} is not fresh\", cat, kind, name);\n-        }\n-        fresh\n-    }\n-\n-    fn all_fresh(&self, cat: &str, map: &WorkMap) -> bool {\n-        let WorkMap(ref map) = *map;\n-        for (k_name, kindmap) in map.iter() {\n-            let KindMap(ref kindmap_) = *kindmap;\n-            for (k_kind, v) in kindmap_.iter() {\n-               if !self.is_fresh(cat,\n-                                 k_kind.as_slice(),\n-                                 k_name.as_slice(),\n-                                 v.as_slice()) {\n-                  return false;\n-            }\n-          }\n-        }\n-        return true;\n-    }\n-\n-    pub fn exec<'a, T:Send +\n-        Encodable<json::Encoder<'a>, io::IoError> +\n-        Decodable<json::Decoder, json::DecoderError>>(\n-            &'a self, blk: proc(&mut Exec):Send -> T) -> T {\n-        self.exec_work(blk).unwrap()\n-    }\n-\n-    fn exec_work<'a, T:Send +\n-        Encodable<json::Encoder<'a>, io::IoError> +\n-        Decodable<json::Decoder, json::DecoderError>>( // FIXME(#5121)\n-            &'a self, blk: proc(&mut Exec):Send -> T) -> Work<'a, T> {\n-        let mut bo = Some(blk);\n-\n-        debug!(\"exec_work: looking up {}\", self.fn_name);\n-        let cached = {\n-            let db = self.ctxt.db.deref().read();\n-            db.deref().prepare(self.fn_name, &self.declared_inputs)\n-        };\n-\n-        match cached {\n-            Some((ref disc_in, ref disc_out, ref res))\n-            if self.all_fresh(\"declared input\",&self.declared_inputs) &&\n-               self.all_fresh(\"discovered input\", disc_in) &&\n-               self.all_fresh(\"discovered output\", disc_out) => {\n-                debug!(\"Cache hit!\");\n-                debug!(\"Trying to decode: {}\", *res);\n-                Work::from_value(json_decode(res.as_slice()))\n-            }\n-\n-            _ => {\n-                debug!(\"Cache miss!\");\n-                let (tx, rx) = channel();\n-                let blk = bo.take_unwrap();\n-\n-                // FIXME: What happens if the task fails?\n-                spawn(proc() {\n-                    let mut exe = Exec {\n-                        discovered_inputs: WorkMap::new(),\n-                        discovered_outputs: WorkMap::new(),\n-                    };\n-                    let v = blk(&mut exe);\n-                    tx.send((exe, v));\n-                });\n-                Work::from_task(self, rx)\n-            }\n-        }\n-    }\n-}\n-\n-impl<'a, T:Send +\n-       Encodable<json::Encoder<'a>, io::IoError> +\n-       Decodable<json::Decoder, json::DecoderError>>\n-    Work<'a, T> { // FIXME(#5121)\n-\n-    pub fn from_value(elt: T) -> Work<'a, T> {\n-        WorkValue(elt)\n-    }\n-    pub fn from_task(prep: &'a Prep<'a>, port: Receiver<(Exec, T)>)\n-        -> Work<'a, T> {\n-        WorkFromTask(prep, port)\n-    }\n-\n-    pub fn unwrap(self) -> T {\n-        match self {\n-            WorkValue(v) => v,\n-            WorkFromTask(prep, port) => {\n-                let (exe, v) = port.recv();\n-                let s = json_encode(&v);\n-                let mut db = prep.ctxt.db.deref().write();\n-                db.deref_mut().cache(prep.fn_name,\n-                                     &prep.declared_inputs,\n-                                     &exe.discovered_inputs,\n-                                     &exe.discovered_outputs,\n-                                     s.as_slice());\n-                v\n-            }\n-        }\n-    }\n-}\n-\n-\n-#[test]\n-#[cfg(not(target_os=\"android\"))] // FIXME(#10455)\n-fn test() {\n-    use std::os;\n-    use std::io::{fs, Command};\n-    use std::str::from_utf8;\n-\n-    // Create a path to a new file 'filename' in the directory in which\n-    // this test is running.\n-    fn make_path(filename: String) -> Path {\n-        let pth = os::self_exe_path().expect(\"workcache::test failed\").with_filename(filename);\n-        if pth.exists() {\n-            fs::unlink(&pth).unwrap();\n-        }\n-        return pth;\n-    }\n-\n-    let pth = make_path(\"foo.c\".to_string());\n-    File::create(&pth).write(bytes!(\"int main() { return 0; }\")).unwrap();\n-\n-    let db_path = make_path(\"db.json\".to_string());\n-\n-    let cx = Context::new(Arc::new(RWLock::new(Database::new(db_path))),\n-                          Arc::new(TreeMap::new()));\n-\n-    let s = cx.with_prep(\"test1\", |prep| {\n-\n-        let subcx = cx.clone();\n-        let pth = pth.clone();\n-\n-        let contents = File::open(&pth).read_to_end().unwrap();\n-        let file_content = from_utf8(contents.as_slice()).unwrap()\n-                                                         .to_string();\n-\n-        // FIXME (#9639): This needs to handle non-utf8 paths\n-        prep.declare_input(\"file\",\n-                           pth.as_str().unwrap(),\n-                           file_content.as_slice());\n-        prep.exec(proc(_exe) {\n-            let out = make_path(\"foo.o\".to_string());\n-            let compiler = if cfg!(windows) {\"gcc\"} else {\"cc\"};\n-            Command::new(compiler).arg(pth).arg(\"-o\").arg(out.clone()).status().unwrap();\n-\n-            let _proof_of_concept = subcx.prep(\"subfn\");\n-            // Could run sub-rules inside here.\n-\n-            // FIXME (#9639): This needs to handle non-utf8 paths\n-            out.as_str().unwrap().to_string()\n-        })\n-    });\n-\n-    println!(\"{}\", s);\n-}"}]}