{"sha": "fa36f960687c41caf5b260ab7610ebd83a7860dd", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZhMzZmOTYwNjg3YzQxY2FmNWIyNjBhYjc2MTBlYmQ4M2E3ODYwZGQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-07-27T01:54:27Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-07-27T01:54:27Z"}, "message": "Auto merge of #72121 - Aaron1011:final-hygiene-rebase, r=petrochenkov\n\nSerialize span hygiene data\n\nFixes #68686\nFixes #70963\n\nThis PR serializies global hygiene data into both the incremental compilation cache and the crate metadata. This allows hygiene information to be preserved across compilation sessions (both incremental and cross-crate).\n\nWhen serializing a `SyntaxContext`, we simply write out the raw id from the current compilation session. Whenever we deserialize a `SyntaxContext`, we 'remap' the id to a fresh id in our current compilation session, and load the associated `SyntaxContextData`.\n\nAs a result, some 'upstream' `SyntaxContextData` will end up getting duplicated in 'downstream' crates. This only happens when we actually need to use an 'upstream' `SyntaxContext`, which occurs when we deserialize a `Span` that requires it.\n\nWe serialize an `ExpnData` into the metadata of the crate which generated it. An `ExpnId` is serialized as a reference into the crate which 'owns' the corresponding `ExpnData`, which avoids duplication in downstream crates.\n\nI've included a macros 2.0 test which requires hygiene serialization to compile successfully.\n\nTODO:\n\n- [x] <strike>Determine how many additional `DefId`s we end up creating for `ExpnId`s - this may be significant for `libcore`, which uses macros heavily. Alternatively, we could try to compute a `DefPathHash` without making a corresponding `DefId` - however, this might significantly complicate the implementation.</strike> (We no longer create `DefId`s)\n- [x] Investigate the overhead of duplicating `SyntaxContextData` in crate metadata.\n- [x] Investigate how `resolve_crate_root` behaves with deserialized hygiene data - the current logic may be wrong.\n- [x] Add additional tests. The effects of this PR are usually only noticeable when working with headache-inducing macro expansions (e.g. macros expanding to macros), so there are lots of corner cases to test.\n- [x] Determine what to do about this:\n\nhttps://github.com/rust-lang/rust/blob/4774f9b523c942cb5c0236542b5bcac76f6b6b9a/src/librustc_resolve/build_reduced_graph.rs#L892\n\n- [x] Determine if we need to do anything here - I think the fact that `src/test/ui/hygiene/cross_crate_hygiene.rs` passes means that this is working.\n\nhttps://github.com/rust-lang/rust/blob/3d5d0f898c2f3998e50c2180c6202f193c3acdbc/src/librustc_resolve/imports.rs#L1389-L1392", "tree": {"sha": "93aa6b04f449b0df769013c971cd791b0481304e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/93aa6b04f449b0df769013c971cd791b0481304e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fa36f960687c41caf5b260ab7610ebd83a7860dd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fa36f960687c41caf5b260ab7610ebd83a7860dd", "html_url": "https://github.com/rust-lang/rust/commit/fa36f960687c41caf5b260ab7610ebd83a7860dd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fa36f960687c41caf5b260ab7610ebd83a7860dd/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c70986264b4d534e35992fc64ecd9139700b5071", "url": "https://api.github.com/repos/rust-lang/rust/commits/c70986264b4d534e35992fc64ecd9139700b5071", "html_url": "https://github.com/rust-lang/rust/commit/c70986264b4d534e35992fc64ecd9139700b5071"}, {"sha": "f7235a898a150ce77a214f51c30f9ac8bd8864a5", "url": "https://api.github.com/repos/rust-lang/rust/commits/f7235a898a150ce77a214f51c30f9ac8bd8864a5", "html_url": "https://github.com/rust-lang/rust/commit/f7235a898a150ce77a214f51c30f9ac8bd8864a5"}], "stats": {"total": 1524, "additions": 1166, "deletions": 358}, "files": [{"sha": "abd5df537db99f14354b4ce904ab43d03cfc3e14", "filename": "src/librustc_ast_lowering/expr.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_ast_lowering%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_ast_lowering%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast_lowering%2Fexpr.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -9,7 +9,8 @@ use rustc_data_structures::thin_vec::ThinVec;\n use rustc_errors::struct_span_err;\n use rustc_hir as hir;\n use rustc_hir::def::Res;\n-use rustc_span::source_map::{respan, DesugaringKind, ForLoopLoc, Span, Spanned};\n+use rustc_span::hygiene::ForLoopLoc;\n+use rustc_span::source_map::{respan, DesugaringKind, Span, Spanned};\n use rustc_span::symbol::{sym, Ident, Symbol};\n use rustc_target::asm;\n use std::collections::hash_map::Entry;"}, {"sha": "daa75d423249aa4da01bb6146224a041acb36f2f", "filename": "src/librustc_expand/base.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_expand%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_expand%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_expand%2Fbase.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -13,7 +13,7 @@ use rustc_data_structures::sync::{self, Lrc};\n use rustc_errors::{DiagnosticBuilder, ErrorReported};\n use rustc_parse::{self, nt_to_tokenstream, parser, MACRO_ARGUMENTS};\n use rustc_session::{parse::ParseSess, Limit};\n-use rustc_span::def_id::DefId;\n+use rustc_span::def_id::{DefId, LOCAL_CRATE};\n use rustc_span::edition::Edition;\n use rustc_span::hygiene::{AstPass, ExpnData, ExpnId, ExpnKind};\n use rustc_span::source_map::SourceMap;\n@@ -873,6 +873,8 @@ impl SyntaxExtension {\n             local_inner_macros: self.local_inner_macros,\n             edition: self.edition,\n             macro_def_id,\n+            krate: LOCAL_CRATE,\n+            orig_id: None,\n         }\n     }\n }"}, {"sha": "e4c0fcaa298d282032bc662666997c1fa36d5ea1", "filename": "src/librustc_expand/expand.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_expand%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_expand%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_expand%2Fexpand.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -1,7 +1,7 @@\n use crate::base::*;\n use crate::config::StripUnconfigured;\n use crate::configure;\n-use crate::hygiene::{ExpnData, ExpnId, ExpnKind, SyntaxContext};\n+use crate::hygiene::{ExpnData, ExpnKind, SyntaxContext};\n use crate::mbe::macro_rules::annotate_err_with_kind;\n use crate::module::{parse_external_mod, push_directory, Directory, DirectoryOwnership};\n use crate::placeholders::{placeholder, PlaceholderExpander};\n@@ -28,7 +28,7 @@ use rustc_session::parse::{feature_err, ParseSess};\n use rustc_session::Limit;\n use rustc_span::source_map::respan;\n use rustc_span::symbol::{sym, Ident, Symbol};\n-use rustc_span::{FileName, Span, DUMMY_SP};\n+use rustc_span::{ExpnId, FileName, Span, DUMMY_SP};\n \n use smallvec::{smallvec, SmallVec};\n use std::io::ErrorKind;"}, {"sha": "724b4123fab6c9243857d92b2733ee52e5547b9f", "filename": "src/librustc_metadata/creader.rs", "status": "modified", "additions": 21, "deletions": 15, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Fcreader.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Fcreader.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcreader.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -307,11 +307,16 @@ impl<'a> CrateLoader<'a> {\n         let private_dep =\n             self.sess.opts.externs.get(&name.as_str()).map(|e| e.is_private_dep).unwrap_or(false);\n \n-        info!(\"register crate `{}` (private_dep = {})\", crate_root.name(), private_dep);\n-\n         // Claim this crate number and cache it\n         let cnum = self.cstore.alloc_new_crate_num();\n \n+        info!(\n+            \"register crate `{}` (cnum = {}. private_dep = {})\",\n+            crate_root.name(),\n+            cnum,\n+            private_dep\n+        );\n+\n         // Maintain a reference to the top most crate.\n         // Stash paths for top-most crate locally if necessary.\n         let crate_paths;\n@@ -339,22 +344,21 @@ impl<'a> CrateLoader<'a> {\n             None\n         };\n \n-        self.cstore.set_crate_data(\n+        let crate_metadata = CrateMetadata::new(\n+            self.sess,\n+            metadata,\n+            crate_root,\n+            raw_proc_macros,\n             cnum,\n-            CrateMetadata::new(\n-                self.sess,\n-                metadata,\n-                crate_root,\n-                raw_proc_macros,\n-                cnum,\n-                cnum_map,\n-                dep_kind,\n-                source,\n-                private_dep,\n-                host_hash,\n-            ),\n+            cnum_map,\n+            dep_kind,\n+            source,\n+            private_dep,\n+            host_hash,\n         );\n \n+        self.cstore.set_crate_data(cnum, crate_metadata);\n+\n         Ok(cnum)\n     }\n \n@@ -569,6 +573,8 @@ impl<'a> CrateLoader<'a> {\n             let cnum = self.maybe_resolve_crate(dep.name, dep_kind, Some((root, &dep)))?;\n             crate_num_map.push(cnum);\n         }\n+\n+        debug!(\"resolve_crate_deps: cnum_map for {:?} is {:?}\", krate, crate_num_map);\n         Ok(crate_num_map)\n     }\n "}, {"sha": "d4add2ab7ade0898ab5f086f57c9c3f65849049d", "filename": "src/librustc_metadata/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Flib.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -9,6 +9,7 @@\n #![feature(proc_macro_internals)]\n #![feature(min_specialization)]\n #![feature(stmt_expr_attributes)]\n+#![feature(never_type)]\n #![recursion_limit = \"256\"]\n \n extern crate proc_macro;"}, {"sha": "df4bb2502cbebcaaef99932e391d0185ec297fdd", "filename": "src/librustc_metadata/rmeta/decoder.rs", "status": "modified", "additions": 76, "deletions": 2, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -32,18 +32,21 @@ use rustc_middle::ty::{self, Ty, TyCtxt};\n use rustc_middle::util::common::record_time;\n use rustc_serialize::{opaque, Decodable, Decoder, SpecializedDecoder, UseSpecializedDecodable};\n use rustc_session::Session;\n+use rustc_span::hygiene::ExpnDataDecodeMode;\n use rustc_span::source_map::{respan, Spanned};\n use rustc_span::symbol::{sym, Ident, Symbol};\n-use rustc_span::{self, hygiene::MacroKind, BytePos, Pos, Span, DUMMY_SP};\n+use rustc_span::{self, hygiene::MacroKind, BytePos, ExpnId, Pos, Span, SyntaxContext, DUMMY_SP};\n \n use log::debug;\n use proc_macro::bridge::client::ProcMacro;\n+use std::cell::Cell;\n use std::io;\n use std::mem;\n use std::num::NonZeroUsize;\n use std::path::Path;\n \n pub use cstore_impl::{provide, provide_extern};\n+use rustc_span::hygiene::HygieneDecodeContext;\n \n mod cstore_impl;\n \n@@ -106,6 +109,13 @@ crate struct CrateMetadata {\n     /// The hash for the host proc macro. Used to support `-Z dual-proc-macro`.\n     host_hash: Option<Svh>,\n \n+    /// Additional data used for decoding `HygieneData` (e.g. `SyntaxContext`\n+    /// and `ExpnId`).\n+    /// Note that we store a `HygieneDecodeContext` for each `CrateMetadat`. This is\n+    /// because `SyntaxContext` ids are not globally unique, so we need\n+    /// to track which ids we've decoded on a per-crate basis.\n+    hygiene_context: HygieneDecodeContext,\n+\n     // --- Data used only for improving diagnostics ---\n     /// Information about the `extern crate` item or path that caused this crate to be loaded.\n     /// If this is `None`, then the crate was injected (e.g., by the allocator).\n@@ -411,6 +421,7 @@ impl<'a, 'tcx> SpecializedDecoder<Span> for DecodeContext<'a, 'tcx> {\n \n         let lo = BytePos::decode(self)?;\n         let len = BytePos::decode(self)?;\n+        let ctxt = SyntaxContext::decode(self)?;\n         let hi = lo + len;\n \n         let sess = if let Some(sess) = self.sess {\n@@ -524,7 +535,7 @@ impl<'a, 'tcx> SpecializedDecoder<Span> for DecodeContext<'a, 'tcx> {\n         let hi =\n             (hi + source_file.translated_source_file.start_pos) - source_file.original_start_pos;\n \n-        Ok(Span::with_root_ctxt(lo, hi))\n+        Ok(Span::new(lo, hi, ctxt))\n     }\n }\n \n@@ -1120,6 +1131,14 @@ impl<'a, 'tcx> CrateMetadataRef<'a> {\n         !self.is_proc_macro(id) && self.root.tables.mir.get(self, id).is_some()\n     }\n \n+    fn module_expansion(&self, id: DefIndex, sess: &Session) -> ExpnId {\n+        if let EntryKind::Mod(m) = self.kind(id) {\n+            m.decode((self, sess)).expansion\n+        } else {\n+            panic!(\"Expected module, found {:?}\", self.local_def_id(id))\n+        }\n+    }\n+\n     fn get_optimized_mir(&self, tcx: TyCtxt<'tcx>, id: DefIndex) -> Body<'tcx> {\n         self.root\n             .tables\n@@ -1652,6 +1671,7 @@ impl CrateMetadata {\n             private_dep,\n             host_hash,\n             extern_crate: Lock::new(None),\n+            hygiene_context: Default::default(),\n         }\n     }\n \n@@ -1784,3 +1804,57 @@ fn macro_kind(raw: &ProcMacro) -> MacroKind {\n         ProcMacro::Bang { .. } => MacroKind::Bang,\n     }\n }\n+\n+impl<'a, 'tcx> SpecializedDecoder<SyntaxContext> for DecodeContext<'a, 'tcx> {\n+    fn specialized_decode(&mut self) -> Result<SyntaxContext, Self::Error> {\n+        let cdata = self.cdata();\n+        let sess = self.sess.unwrap();\n+        let cname = cdata.root.name;\n+        rustc_span::hygiene::decode_syntax_context(self, &cdata.hygiene_context, |_, id| {\n+            debug!(\"SpecializedDecoder<SyntaxContext>: decoding {}\", id);\n+            Ok(cdata\n+                .root\n+                .syntax_contexts\n+                .get(&cdata, id)\n+                .unwrap_or_else(|| panic!(\"Missing SyntaxContext {:?} for crate {:?}\", id, cname))\n+                .decode((&cdata, sess)))\n+        })\n+    }\n+}\n+\n+impl<'a, 'tcx> SpecializedDecoder<ExpnId> for DecodeContext<'a, 'tcx> {\n+    fn specialized_decode(&mut self) -> Result<ExpnId, Self::Error> {\n+        let local_cdata = self.cdata();\n+        let sess = self.sess.unwrap();\n+        let expn_cnum = Cell::new(None);\n+        let get_ctxt = |cnum| {\n+            expn_cnum.set(Some(cnum));\n+            if cnum == LOCAL_CRATE {\n+                &local_cdata.hygiene_context\n+            } else {\n+                &local_cdata.cstore.get_crate_data(cnum).cdata.hygiene_context\n+            }\n+        };\n+\n+        rustc_span::hygiene::decode_expn_id(\n+            self,\n+            ExpnDataDecodeMode::Metadata(get_ctxt),\n+            |_this, index| {\n+                let cnum = expn_cnum.get().unwrap();\n+                // Lookup local `ExpnData`s in our own crate data. Foreign `ExpnData`s\n+                // are stored in the owning crate, to avoid duplication.\n+                let crate_data = if cnum == LOCAL_CRATE {\n+                    local_cdata\n+                } else {\n+                    local_cdata.cstore.get_crate_data(cnum)\n+                };\n+                Ok(crate_data\n+                    .root\n+                    .expn_data\n+                    .get(&crate_data, index)\n+                    .unwrap()\n+                    .decode((&crate_data, sess)))\n+            },\n+        )\n+    }\n+}"}, {"sha": "e51862be9a86fde19f8bf13abde658cf4de8e5a2", "filename": "src/librustc_metadata/rmeta/decoder/cstore_impl.rs", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fdecoder%2Fcstore_impl.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -21,9 +21,10 @@ use rustc_middle::ty::{self, TyCtxt};\n use rustc_session::utils::NativeLibKind;\n use rustc_session::{CrateDisambiguator, Session};\n use rustc_span::source_map::{self, Span, Spanned};\n-use rustc_span::symbol::{Ident, Symbol};\n+use rustc_span::symbol::Symbol;\n \n use rustc_data_structures::sync::Lrc;\n+use rustc_span::ExpnId;\n use smallvec::SmallVec;\n use std::any::Any;\n \n@@ -417,13 +418,7 @@ impl CStore {\n             attr::mark_used(attr);\n         }\n \n-        let ident = data\n-            .def_key(id.index)\n-            .disambiguated_data\n-            .data\n-            .get_opt_name()\n-            .map(Ident::with_dummy_span) // FIXME: cross-crate hygiene\n-            .expect(\"no name in load_macro\");\n+        let ident = data.item_ident(id.index, sess);\n \n         LoadedMacro::MacroDef(\n             ast::Item {\n@@ -454,6 +449,10 @@ impl CStore {\n     pub fn item_generics_num_lifetimes(&self, def_id: DefId, sess: &Session) -> usize {\n         self.get_crate_data(def_id.krate).get_generics(def_id.index, sess).own_counts().lifetimes\n     }\n+\n+    pub fn module_expansion_untracked(&self, def_id: DefId, sess: &Session) -> ExpnId {\n+        self.get_crate_data(def_id.krate).module_expansion(def_id.index, sess)\n+    }\n }\n \n impl CrateStore for CStore {"}, {"sha": "dc8d14a44f806ee06ff01cc92a46d9a8d3a4d9ea", "filename": "src/librustc_metadata/rmeta/encoder.rs", "status": "modified", "additions": 120, "deletions": 33, "changes": 153, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -1,4 +1,4 @@\n-use crate::rmeta::table::FixedSizeEncoding;\n+use crate::rmeta::table::{FixedSizeEncoding, TableBuilder};\n use crate::rmeta::*;\n \n use log::{debug, trace};\n@@ -30,15 +30,16 @@ use rustc_middle::ty::codec::{self as ty_codec, TyEncoder};\n use rustc_middle::ty::{self, SymbolName, Ty, TyCtxt};\n use rustc_serialize::{opaque, Encodable, Encoder, SpecializedEncoder, UseSpecializedEncodable};\n use rustc_session::config::CrateType;\n+use rustc_span::hygiene::{ExpnDataEncodeMode, HygieneEncodeContext};\n use rustc_span::source_map::Spanned;\n use rustc_span::symbol::{sym, Ident, Symbol};\n-use rustc_span::{self, ExternalSource, FileName, SourceFile, Span};\n+use rustc_span::{self, ExternalSource, FileName, SourceFile, Span, SyntaxContext};\n use rustc_target::abi::VariantIdx;\n use std::hash::Hash;\n use std::num::NonZeroUsize;\n use std::path::Path;\n \n-struct EncodeContext<'tcx> {\n+struct EncodeContext<'a, 'tcx> {\n     opaque: opaque::Encoder,\n     tcx: TyCtxt<'tcx>,\n \n@@ -66,6 +67,7 @@ struct EncodeContext<'tcx> {\n     // with a result containing a foreign `Span`.\n     required_source_files: Option<GrowableBitSet<usize>>,\n     is_proc_macro: bool,\n+    hygiene_ctxt: &'a HygieneEncodeContext,\n }\n \n macro_rules! encoder_methods {\n@@ -76,7 +78,7 @@ macro_rules! encoder_methods {\n     }\n }\n \n-impl<'tcx> Encoder for EncodeContext<'tcx> {\n+impl<'a, 'tcx> Encoder for EncodeContext<'a, 'tcx> {\n     type Error = <opaque::Encoder as Encoder>::Error;\n \n     #[inline]\n@@ -107,13 +109,13 @@ impl<'tcx> Encoder for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx, T> SpecializedEncoder<Lazy<T, ()>> for EncodeContext<'tcx> {\n+impl<'a, 'tcx, T> SpecializedEncoder<Lazy<T, ()>> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, lazy: &Lazy<T>) -> Result<(), Self::Error> {\n         self.emit_lazy_distance(*lazy)\n     }\n }\n \n-impl<'tcx, T> SpecializedEncoder<Lazy<[T], usize>> for EncodeContext<'tcx> {\n+impl<'a, 'tcx, T> SpecializedEncoder<Lazy<[T], usize>> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, lazy: &Lazy<[T]>) -> Result<(), Self::Error> {\n         self.emit_usize(lazy.meta)?;\n         if lazy.meta == 0 {\n@@ -123,7 +125,7 @@ impl<'tcx, T> SpecializedEncoder<Lazy<[T], usize>> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx, I: Idx, T> SpecializedEncoder<Lazy<Table<I, T>, usize>> for EncodeContext<'tcx>\n+impl<'a, 'tcx, I: Idx, T> SpecializedEncoder<Lazy<Table<I, T>, usize>> for EncodeContext<'a, 'tcx>\n where\n     Option<T>: FixedSizeEncoding,\n {\n@@ -133,14 +135,14 @@ where\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<CrateNum> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<CrateNum> for EncodeContext<'a, 'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, cnum: &CrateNum) -> Result<(), Self::Error> {\n         self.emit_u32(cnum.as_u32())\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<DefId> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<DefId> for EncodeContext<'a, 'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, def_id: &DefId) -> Result<(), Self::Error> {\n         let DefId { krate, index } = *def_id;\n@@ -150,14 +152,31 @@ impl<'tcx> SpecializedEncoder<DefId> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<DefIndex> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<SyntaxContext> for EncodeContext<'a, 'tcx> {\n+    fn specialized_encode(&mut self, ctxt: &SyntaxContext) -> Result<(), Self::Error> {\n+        rustc_span::hygiene::raw_encode_syntax_context(*ctxt, &self.hygiene_ctxt, self)\n+    }\n+}\n+\n+impl<'a, 'tcx> SpecializedEncoder<ExpnId> for EncodeContext<'a, 'tcx> {\n+    fn specialized_encode(&mut self, expn: &ExpnId) -> Result<(), Self::Error> {\n+        rustc_span::hygiene::raw_encode_expn_id(\n+            *expn,\n+            &mut self.hygiene_ctxt,\n+            ExpnDataEncodeMode::Metadata,\n+            self,\n+        )\n+    }\n+}\n+\n+impl<'a, 'tcx> SpecializedEncoder<DefIndex> for EncodeContext<'a, 'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, def_index: &DefIndex) -> Result<(), Self::Error> {\n         self.emit_u32(def_index.as_u32())\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<Span> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<Span> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, span: &Span) -> Result<(), Self::Error> {\n         if span.is_dummy() {\n             return TAG_INVALID_SPAN.encode(self);\n@@ -234,26 +253,58 @@ impl<'tcx> SpecializedEncoder<Span> for EncodeContext<'tcx> {\n         let len = hi - lo;\n         len.encode(self)?;\n \n+        // Don't serialize any `SyntaxContext`s from a proc-macro crate,\n+        // since we don't load proc-macro dependencies during serialization.\n+        // This means that any hygiene information from macros used *within*\n+        // a proc-macro crate (e.g. invoking a macro that expands to a proc-macro\n+        // definition) will be lost.\n+        //\n+        // This can show up in two ways:\n+        //\n+        // 1. Any hygiene information associated with identifier of\n+        // a proc macro (e.g. `#[proc_macro] pub fn $name`) will be lost.\n+        // Since proc-macros can only be invoked from a different crate,\n+        // real code should never need to care about this.\n+        //\n+        // 2. Using `Span::def_site` or `Span::mixed_site` will not\n+        // include any hygiene information associated with the defintion\n+        // site. This means that a proc-macro cannot emit a `$crate`\n+        // identifier which resolves to one of its dependencies,\n+        // which also should never come up in practice.\n+        //\n+        // Additionally, this affects `Span::parent`, and any other\n+        // span inspection APIs that would otherwise allow traversing\n+        // the `SyntaxContexts` associated with a span.\n+        //\n+        // None of these user-visible effects should result in any\n+        // cross-crate inconsistencies (getting one behavior in the same\n+        // crate, and a different behavior in another crate) due to the\n+        // limited surface that proc-macros can expose.\n+        if self.is_proc_macro {\n+            SyntaxContext::root().encode(self)?;\n+        } else {\n+            span.ctxt.encode(self)?;\n+        }\n+\n         if tag == TAG_VALID_SPAN_FOREIGN {\n             // This needs to be two lines to avoid holding the `self.source_file_cache`\n             // while calling `cnum.encode(self)`\n             let cnum = self.source_file_cache.0.cnum;\n             cnum.encode(self)?;\n         }\n-        Ok(())\n \n-        // Don't encode the expansion context.\n+        Ok(())\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<LocalDefId> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<LocalDefId> for EncodeContext<'a, 'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, def_id: &LocalDefId) -> Result<(), Self::Error> {\n         self.specialized_encode(&def_id.to_def_id())\n     }\n }\n \n-impl<'a, 'b, 'tcx> SpecializedEncoder<&'a ty::TyS<'b>> for EncodeContext<'tcx>\n+impl<'a, 'b, 'c, 'tcx> SpecializedEncoder<&'a ty::TyS<'b>> for EncodeContext<'c, 'tcx>\n where\n     &'a ty::TyS<'b>: UseSpecializedEncodable,\n {\n@@ -264,7 +315,7 @@ where\n     }\n }\n \n-impl<'b, 'tcx> SpecializedEncoder<ty::Predicate<'b>> for EncodeContext<'tcx> {\n+impl<'a, 'b, 'tcx> SpecializedEncoder<ty::Predicate<'b>> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, predicate: &ty::Predicate<'b>) -> Result<(), Self::Error> {\n         debug_assert!(self.tcx.lift(predicate).is_some());\n         let predicate =\n@@ -275,7 +326,7 @@ impl<'b, 'tcx> SpecializedEncoder<ty::Predicate<'b>> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<interpret::AllocId> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<interpret::AllocId> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, alloc_id: &interpret::AllocId) -> Result<(), Self::Error> {\n         use std::collections::hash_map::Entry;\n         let index = match self.interpret_allocs.entry(*alloc_id) {\n@@ -292,13 +343,13 @@ impl<'tcx> SpecializedEncoder<interpret::AllocId> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<Fingerprint> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<Fingerprint> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, f: &Fingerprint) -> Result<(), Self::Error> {\n         f.encode_opaque(&mut self.opaque)\n     }\n }\n \n-impl<'tcx, T> SpecializedEncoder<mir::ClearCrossCrate<T>> for EncodeContext<'tcx>\n+impl<'a, 'tcx, T> SpecializedEncoder<mir::ClearCrossCrate<T>> for EncodeContext<'a, 'tcx>\n where\n     mir::ClearCrossCrate<T>: UseSpecializedEncodable,\n {\n@@ -307,25 +358,25 @@ where\n     }\n }\n \n-impl<'tcx> TyEncoder for EncodeContext<'tcx> {\n+impl<'a, 'tcx> TyEncoder for EncodeContext<'a, 'tcx> {\n     fn position(&self) -> usize {\n         self.opaque.position()\n     }\n }\n \n /// Helper trait to allow overloading `EncodeContext::lazy` for iterators.\n trait EncodeContentsForLazy<T: ?Sized + LazyMeta> {\n-    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'tcx>) -> T::Meta;\n+    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'a, 'tcx>) -> T::Meta;\n }\n \n impl<T: Encodable> EncodeContentsForLazy<T> for &T {\n-    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'tcx>) {\n+    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'a, 'tcx>) {\n         self.encode(ecx).unwrap()\n     }\n }\n \n impl<T: Encodable> EncodeContentsForLazy<T> for T {\n-    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'tcx>) {\n+    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'a, 'tcx>) {\n         self.encode(ecx).unwrap()\n     }\n }\n@@ -335,7 +386,7 @@ where\n     I: IntoIterator,\n     I::Item: EncodeContentsForLazy<T>,\n {\n-    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'tcx>) -> usize {\n+    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'a, 'tcx>) -> usize {\n         self.into_iter().map(|value| value.encode_contents_for_lazy(ecx)).count()\n     }\n }\n@@ -352,7 +403,7 @@ macro_rules! record {\n     }};\n }\n \n-impl<'tcx> EncodeContext<'tcx> {\n+impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n     fn emit_lazy_distance<T: ?Sized + LazyMeta>(\n         &mut self,\n         lazy: Lazy<T>,\n@@ -478,6 +529,7 @@ impl<'tcx> EncodeContext<'tcx> {\n \n         let mut i = self.position();\n \n+        // Encode the crate deps\n         let crate_deps = self.encode_crate_deps();\n         let dylib_dependency_formats = self.encode_dylib_dependency_formats();\n         let dep_bytes = self.position() - i;\n@@ -556,12 +608,23 @@ impl<'tcx> EncodeContext<'tcx> {\n         let proc_macro_data_bytes = self.position() - i;\n \n         // Encode exported symbols info. This is prefetched in `encode_metadata` so we encode\n-        // this late to give the prefetching as much time as possible to complete.\n+        // this as late as possible to give the prefetching as much time as possible to complete.\n         i = self.position();\n         let exported_symbols = tcx.exported_symbols(LOCAL_CRATE);\n         let exported_symbols = self.encode_exported_symbols(&exported_symbols);\n         let exported_symbols_bytes = self.position() - i;\n \n+        // Encode the hygiene data,\n+        // IMPORTANT: this *must* be the last thing that we encode (other than `SourceMap`). The process\n+        // of encoding other items (e.g. `optimized_mir`) may cause us to load\n+        // data from the incremental cache. If this causes us to deserialize a `Span`,\n+        // then we may load additional `SyntaxContext`s into the global `HygieneData`.\n+        // Therefore, we need to encode the hygiene data last to ensure that we encode\n+        // any `SyntaxContext`s that might be used.\n+        i = self.position();\n+        let (syntax_contexts, expn_data) = self.encode_hygiene();\n+        let hygiene_bytes = self.position() - i;\n+\n         // Encode source_map. This needs to be done last,\n         // since encoding `Span`s tells us which `SourceFiles` we actually\n         // need to encode.\n@@ -618,6 +681,8 @@ impl<'tcx> EncodeContext<'tcx> {\n             exported_symbols,\n             interpret_alloc_index,\n             tables,\n+            syntax_contexts,\n+            expn_data,\n         });\n \n         let total_bytes = self.position();\n@@ -643,6 +708,7 @@ impl<'tcx> EncodeContext<'tcx> {\n             println!(\" proc-macro-data-bytes: {}\", proc_macro_data_bytes);\n             println!(\"            item bytes: {}\", item_bytes);\n             println!(\"           table bytes: {}\", tables_bytes);\n+            println!(\"         hygiene bytes: {}\", hygiene_bytes);\n             println!(\"            zero bytes: {}\", zero_bytes);\n             println!(\"           total bytes: {}\", total_bytes);\n         }\n@@ -651,7 +717,7 @@ impl<'tcx> EncodeContext<'tcx> {\n     }\n }\n \n-impl EncodeContext<'tcx> {\n+impl EncodeContext<'a, 'tcx> {\n     fn encode_variances_of(&mut self, def_id: DefId) {\n         debug!(\"EncodeContext::encode_variances_of({:?})\", def_id);\n         record!(self.tables.variances[def_id] <- &self.tcx.variances_of(def_id)[..]);\n@@ -752,11 +818,12 @@ impl EncodeContext<'tcx> {\n         vis: &hir::Visibility<'_>,\n     ) {\n         let tcx = self.tcx;\n-        let def_id = tcx.hir().local_def_id(id);\n+        let local_def_id = tcx.hir().local_def_id(id);\n+        let def_id = local_def_id.to_def_id();\n         debug!(\"EncodeContext::encode_info_for_mod({:?})\", def_id);\n \n         let data = ModData {\n-            reexports: match tcx.module_exports(def_id) {\n+            reexports: match tcx.module_exports(local_def_id) {\n                 Some(exports) => {\n                     let hir_map = self.tcx.hir();\n                     self.lazy(\n@@ -767,10 +834,9 @@ impl EncodeContext<'tcx> {\n                 }\n                 _ => Lazy::empty(),\n             },\n+            expansion: tcx.hir().definitions().expansion_that_defined(local_def_id),\n         };\n \n-        let def_id = def_id.to_def_id();\n-\n         record!(self.tables.kind[def_id] <- EntryKind::Mod(self.lazy(data)));\n         record!(self.tables.visibility[def_id] <- ty::Visibility::from_hir(vis, id, self.tcx));\n         record!(self.tables.span[def_id] <- self.tcx.def_span(def_id));\n@@ -1425,6 +1491,25 @@ impl EncodeContext<'tcx> {\n         self.lazy(foreign_modules.iter().cloned())\n     }\n \n+    fn encode_hygiene(&mut self) -> (SyntaxContextTable, ExpnDataTable) {\n+        let mut syntax_contexts: TableBuilder<_, _> = Default::default();\n+        let mut expn_data_table: TableBuilder<_, _> = Default::default();\n+\n+        let _: Result<(), !> = self.hygiene_ctxt.encode(\n+            &mut (&mut *self, &mut syntax_contexts, &mut expn_data_table),\n+            |(this, syntax_contexts, _), index, ctxt_data| {\n+                syntax_contexts.set(index, this.lazy(ctxt_data));\n+                Ok(())\n+            },\n+            |(this, _, expn_data_table), index, expn_data| {\n+                expn_data_table.set(index, this.lazy(expn_data));\n+                Ok(())\n+            },\n+        );\n+\n+        (syntax_contexts.encode(&mut self.opaque), expn_data_table.encode(&mut self.opaque))\n+    }\n+\n     fn encode_proc_macros(&mut self) -> Option<Lazy<[DefIndex]>> {\n         let is_proc_macro = self.tcx.sess.crate_types().contains(&CrateType::ProcMacro);\n         if is_proc_macro {\n@@ -1614,7 +1699,7 @@ impl EncodeContext<'tcx> {\n }\n \n // FIXME(eddyb) make metadata encoding walk over all definitions, instead of HIR.\n-impl Visitor<'tcx> for EncodeContext<'tcx> {\n+impl Visitor<'tcx> for EncodeContext<'a, 'tcx> {\n     type Map = Map<'tcx>;\n \n     fn nested_visit_map(&mut self) -> NestedVisitorMap<Self::Map> {\n@@ -1652,7 +1737,7 @@ impl Visitor<'tcx> for EncodeContext<'tcx> {\n     }\n }\n \n-impl EncodeContext<'tcx> {\n+impl EncodeContext<'a, 'tcx> {\n     fn encode_fields(&mut self, adt_def: &ty::AdtDef) {\n         for (variant_index, variant) in adt_def.variants.iter_enumerated() {\n             for (field_index, _field) in variant.fields.iter().enumerate() {\n@@ -1906,6 +1991,7 @@ fn encode_metadata_impl(tcx: TyCtxt<'_>) -> EncodedMetadata {\n     encoder.emit_raw_bytes(&[0, 0, 0, 0]);\n \n     let source_map_files = tcx.sess.source_map().files();\n+    let hygiene_ctxt = HygieneEncodeContext::default();\n \n     let mut ecx = EncodeContext {\n         opaque: encoder,\n@@ -1919,6 +2005,7 @@ fn encode_metadata_impl(tcx: TyCtxt<'_>) -> EncodedMetadata {\n         interpret_allocs_inverse: Default::default(),\n         required_source_files: Some(GrowableBitSet::with_capacity(source_map_files.len())),\n         is_proc_macro: tcx.sess.crate_types().contains(&CrateType::ProcMacro),\n+        hygiene_ctxt: &hygiene_ctxt,\n     };\n     drop(source_map_files);\n "}, {"sha": "55ef66f1939c4e1a18c79db4e4cf7d24f16d6929", "filename": "src/librustc_metadata/rmeta/mod.rs", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fmod.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -20,14 +20,15 @@ use rustc_session::config::SymbolManglingVersion;\n use rustc_session::CrateDisambiguator;\n use rustc_span::edition::Edition;\n use rustc_span::symbol::{Ident, Symbol};\n-use rustc_span::{self, Span};\n+use rustc_span::{self, ExpnData, ExpnId, Span};\n use rustc_target::spec::{PanicStrategy, TargetTriple};\n \n use std::marker::PhantomData;\n use std::num::NonZeroUsize;\n \n pub use decoder::{provide, provide_extern};\n crate use decoder::{CrateMetadata, CrateNumMap, MetadataBlob};\n+use rustc_span::hygiene::SyntaxContextData;\n \n mod decoder;\n mod encoder;\n@@ -168,6 +169,9 @@ macro_rules! Lazy {\n     ($T:ty) => {Lazy<$T, ()>};\n }\n \n+type SyntaxContextTable = Lazy<Table<u32, Lazy<SyntaxContextData>>>;\n+type ExpnDataTable = Lazy<Table<u32, Lazy<ExpnData>>>;\n+\n #[derive(RustcEncodable, RustcDecodable)]\n crate struct CrateRoot<'tcx> {\n     name: Symbol,\n@@ -202,6 +206,10 @@ crate struct CrateRoot<'tcx> {\n     proc_macro_data: Option<Lazy<[DefIndex]>>,\n \n     exported_symbols: Lazy!([(ExportedSymbol<'tcx>, SymbolExportLevel)]),\n+\n+    syntax_contexts: SyntaxContextTable,\n+    expn_data: ExpnDataTable,\n+\n     source_map: Lazy<[rustc_span::SourceFile]>,\n \n     compiler_builtins: bool,\n@@ -322,6 +330,7 @@ struct RenderedConst(String);\n #[derive(RustcEncodable, RustcDecodable)]\n struct ModData {\n     reexports: Lazy<[Export<hir::HirId>]>,\n+    expansion: ExpnId,\n }\n \n #[derive(RustcEncodable, RustcDecodable)]"}, {"sha": "e1d0a0dbf2ffa2c77d37bfb554300622a7d425c7", "filename": "src/librustc_metadata/rmeta/table.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Ftable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_metadata%2Frmeta%2Ftable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Ftable.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -155,7 +155,7 @@ impl<I: Idx, T> TableBuilder<I, T>\n where\n     Option<T>: FixedSizeEncoding,\n {\n-    pub(super) fn set(&mut self, i: I, value: T) {\n+    pub(crate) fn set(&mut self, i: I, value: T) {\n         // FIXME(eddyb) investigate more compact encodings for sparse tables.\n         // On the PR @michaelwoerister mentioned:\n         // > Space requirements could perhaps be optimized by using the HAMT `popcnt`\n@@ -170,7 +170,7 @@ where\n         Some(value).write_to_bytes_at(&mut self.bytes, i);\n     }\n \n-    pub(super) fn encode(&self, buf: &mut Encoder) -> Lazy<Table<I, T>> {\n+    pub(crate) fn encode(&self, buf: &mut Encoder) -> Lazy<Table<I, T>> {\n         let pos = buf.position();\n         buf.emit_raw_bytes(&self.bytes);\n         Lazy::from_position_and_meta(NonZeroUsize::new(pos as usize).unwrap(), self.bytes.len())"}, {"sha": "19a7d2ec2218dd2222c574f96a57959e083b58b5", "filename": "src/librustc_middle/ich/hcx.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_middle%2Fich%2Fhcx.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_middle%2Fich%2Fhcx.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Fich%2Fhcx.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -14,6 +14,7 @@ use rustc_span::source_map::SourceMap;\n use rustc_span::symbol::Symbol;\n use rustc_span::{BytePos, CachingSourceMapView, SourceFile};\n \n+use rustc_span::def_id::{CrateNum, CRATE_DEF_INDEX};\n use smallvec::SmallVec;\n use std::cmp::Ord;\n \n@@ -229,6 +230,12 @@ impl<'a> rustc_span::HashStableContext for StableHashingContext<'a> {\n         self.hash_spans\n     }\n \n+    #[inline]\n+    fn hash_crate_num(&mut self, cnum: CrateNum, hasher: &mut StableHasher) {\n+        let hcx = self;\n+        hcx.def_path_hash(DefId { krate: cnum, index: CRATE_DEF_INDEX }).hash_stable(hcx, hasher);\n+    }\n+\n     #[inline]\n     fn hash_def_id(&mut self, def_id: DefId, hasher: &mut StableHasher) {\n         let hcx = self;"}, {"sha": "c2d177b69b6b95409d95d90593de14b12f9a70d4", "filename": "src/librustc_middle/ich/impls_hir.rs", "status": "modified", "additions": 0, "deletions": 7, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_middle%2Fich%2Fimpls_hir.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_middle%2Fich%2Fimpls_hir.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Fich%2Fimpls_hir.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -147,13 +147,6 @@ impl<'a> ToStableHashKey<StableHashingContext<'a>> for LocalDefId {\n     }\n }\n \n-impl<'a> HashStable<StableHashingContext<'a>> for CrateNum {\n-    #[inline]\n-    fn hash_stable(&self, hcx: &mut StableHashingContext<'a>, hasher: &mut StableHasher) {\n-        hcx.def_path_hash(DefId { krate: *self, index: CRATE_DEF_INDEX }).hash_stable(hcx, hasher);\n-    }\n-}\n-\n impl<'a> ToStableHashKey<StableHashingContext<'a>> for CrateNum {\n     type KeyType = DefPathHash;\n "}, {"sha": "25e5379881e70ad56df532f2490a61f1a028e74e", "filename": "src/librustc_middle/lint.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_middle%2Flint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_middle%2Flint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Flint.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -346,6 +346,6 @@ pub fn in_external_macro(sess: &Session, span: Span) -> bool {\n             // Dummy span for the `def_site` means it's an external macro.\n             expn_data.def_site.is_dummy() || sess.source_map().is_imported(expn_data.def_site)\n         }\n-        ExpnKind::Macro(..) => true, // definitely a plugin\n+        ExpnKind::Macro { .. } => true, // definitely a plugin\n     }\n }"}, {"sha": "643fbe793ab8072540f6ca078aa4b279e6768877", "filename": "src/librustc_middle/ty/query/on_disk_cache.rs", "status": "modified", "additions": 154, "deletions": 72, "changes": 226, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -17,22 +17,24 @@ use rustc_serialize::{\n     UseSpecializedDecodable, UseSpecializedEncodable,\n };\n use rustc_session::{CrateDisambiguator, Session};\n-use rustc_span::hygiene::{ExpnId, SyntaxContext};\n+use rustc_span::hygiene::{\n+    ExpnDataDecodeMode, ExpnDataEncodeMode, ExpnId, HygieneDecodeContext, HygieneEncodeContext,\n+    SyntaxContext, SyntaxContextData,\n+};\n use rustc_span::source_map::{SourceMap, StableSourceFileId};\n use rustc_span::symbol::Ident;\n use rustc_span::CachingSourceMapView;\n-use rustc_span::{BytePos, SourceFile, Span, DUMMY_SP};\n+use rustc_span::{BytePos, ExpnData, SourceFile, Span, DUMMY_SP};\n use std::mem;\n \n const TAG_FILE_FOOTER: u128 = 0xC0FFEE_C0FFEE_C0FFEE_C0FFEE_C0FFEE;\n \n-const TAG_NO_EXPN_DATA: u8 = 0;\n-const TAG_EXPN_DATA_SHORTHAND: u8 = 1;\n-const TAG_EXPN_DATA_INLINE: u8 = 2;\n-\n const TAG_VALID_SPAN: u8 = 0;\n const TAG_INVALID_SPAN: u8 = 1;\n \n+const TAG_SYNTAX_CONTEXT: u8 = 0;\n+const TAG_EXPN_DATA: u8 = 1;\n+\n /// Provides an interface to incremental compilation data cached from the\n /// previous compilation session. This data will eventually include the results\n /// of a few selected queries (like `typeck` and `mir_optimized`) and\n@@ -53,7 +55,6 @@ pub struct OnDiskCache<'sess> {\n \n     // Caches that are populated lazily during decoding.\n     file_index_to_file: Lock<FxHashMap<SourceFileIndex, Lrc<SourceFile>>>,\n-    synthetic_syntax_contexts: Lock<FxHashMap<AbsoluteBytePos, SyntaxContext>>,\n \n     // A map from dep-node to the position of the cached query result in\n     // `serialized_data`.\n@@ -64,9 +65,28 @@ pub struct OnDiskCache<'sess> {\n     prev_diagnostics_index: FxHashMap<SerializedDepNodeIndex, AbsoluteBytePos>,\n \n     alloc_decoding_state: AllocDecodingState,\n+\n+    // A map from syntax context ids to the position of their associated\n+    // `SyntaxContextData`. We use a `u32` instead of a `SyntaxContext`\n+    // to represent the fact that we are storing *encoded* ids. When we decode\n+    // a `SyntaxContext`, a new id will be allocated from the global `HygieneData`,\n+    // which will almost certainly be different than the serialized id.\n+    syntax_contexts: FxHashMap<u32, AbsoluteBytePos>,\n+    // A map from the `DefPathHash` of an `ExpnId` to the position\n+    // of their associated `ExpnData`. Ideally, we would store a `DefId`,\n+    // but we need to decode this before we've constructed a `TyCtxt` (which\n+    // makes it difficult to decode a `DefId`).\n+\n+    // Note that these `DefPathHashes` correspond to both local and foreign\n+    // `ExpnData` (e.g `ExpnData.krate` may not be `LOCAL_CRATE`). Alternatively,\n+    // we could look up the `ExpnData` from the metadata of foreign crates,\n+    // but it seemed easier to have `OnDiskCache` be independent of the `CStore`.\n+    expn_data: FxHashMap<u32, AbsoluteBytePos>,\n+    // Additional information used when decoding hygiene data.\n+    hygiene_context: HygieneDecodeContext,\n }\n \n-// This type is used only for (de-)serialization.\n+// This type is used only for serialization and deserialization.\n #[derive(RustcEncodable, RustcDecodable)]\n struct Footer {\n     file_index_to_stable_id: FxHashMap<SourceFileIndex, StableSourceFileId>,\n@@ -75,6 +95,10 @@ struct Footer {\n     diagnostics_index: EncodedQueryResultIndex,\n     // The location of all allocations.\n     interpret_alloc_index: Vec<u32>,\n+    // See `OnDiskCache.syntax_contexts`\n+    syntax_contexts: FxHashMap<u32, AbsoluteBytePos>,\n+    // See `OnDiskCache.expn_data`\n+    expn_data: FxHashMap<u32, AbsoluteBytePos>,\n }\n \n type EncodedQueryResultIndex = Vec<(SerializedDepNodeIndex, AbsoluteBytePos)>;\n@@ -116,6 +140,7 @@ impl<'sess> OnDiskCache<'sess> {\n \n             // Decode the file footer, which contains all the lookup tables, etc.\n             decoder.set_position(footer_pos);\n+\n             decode_tagged(&mut decoder, TAG_FILE_FOOTER)\n                 .expect(\"error while trying to decode footer position\")\n         };\n@@ -130,8 +155,10 @@ impl<'sess> OnDiskCache<'sess> {\n             current_diagnostics: Default::default(),\n             query_result_index: footer.query_result_index.into_iter().collect(),\n             prev_diagnostics_index: footer.diagnostics_index.into_iter().collect(),\n-            synthetic_syntax_contexts: Default::default(),\n             alloc_decoding_state: AllocDecodingState::new(footer.interpret_alloc_index),\n+            syntax_contexts: footer.syntax_contexts,\n+            expn_data: footer.expn_data,\n+            hygiene_context: Default::default(),\n         }\n     }\n \n@@ -146,8 +173,10 @@ impl<'sess> OnDiskCache<'sess> {\n             current_diagnostics: Default::default(),\n             query_result_index: Default::default(),\n             prev_diagnostics_index: Default::default(),\n-            synthetic_syntax_contexts: Default::default(),\n             alloc_decoding_state: AllocDecodingState::new(Vec::new()),\n+            syntax_contexts: FxHashMap::default(),\n+            expn_data: FxHashMap::default(),\n+            hygiene_context: Default::default(),\n         }\n     }\n \n@@ -175,16 +204,18 @@ impl<'sess> OnDiskCache<'sess> {\n                 (file_to_file_index, file_index_to_stable_id)\n             };\n \n+            let hygiene_encode_context = HygieneEncodeContext::default();\n+\n             let mut encoder = CacheEncoder {\n                 tcx,\n                 encoder,\n                 type_shorthands: Default::default(),\n                 predicate_shorthands: Default::default(),\n-                expn_data_shorthands: Default::default(),\n                 interpret_allocs: Default::default(),\n                 interpret_allocs_inverse: Vec::new(),\n                 source_map: CachingSourceMapView::new(tcx.sess.source_map()),\n                 file_to_file_index,\n+                hygiene_context: &hygiene_encode_context,\n             };\n \n             // Load everything into memory so we can write it out to the on-disk\n@@ -264,7 +295,29 @@ impl<'sess> OnDiskCache<'sess> {\n                 })\n                 .collect();\n \n-            // Encode the file footer.\n+            let mut syntax_contexts = FxHashMap::default();\n+            let mut expn_ids = FxHashMap::default();\n+\n+            // Encode all hygiene data (`SyntaxContextData` and `ExpnData`) from the current\n+            // session.\n+\n+            hygiene_encode_context.encode(\n+                &mut encoder,\n+                |encoder, index, ctxt_data| {\n+                    let pos = AbsoluteBytePos::new(encoder.position());\n+                    encoder.encode_tagged(TAG_SYNTAX_CONTEXT, ctxt_data)?;\n+                    syntax_contexts.insert(index, pos);\n+                    Ok(())\n+                },\n+                |encoder, index, expn_data| {\n+                    let pos = AbsoluteBytePos::new(encoder.position());\n+                    encoder.encode_tagged(TAG_EXPN_DATA, expn_data)?;\n+                    expn_ids.insert(index, pos);\n+                    Ok(())\n+                },\n+            )?;\n+\n+            // `Encode the file footer.\n             let footer_pos = encoder.position() as u64;\n             encoder.encode_tagged(\n                 TAG_FILE_FOOTER,\n@@ -274,6 +327,8 @@ impl<'sess> OnDiskCache<'sess> {\n                     query_result_index,\n                     diagnostics_index,\n                     interpret_alloc_index,\n+                    syntax_contexts,\n+                    expn_data: expn_ids,\n                 },\n             )?;\n \n@@ -367,6 +422,21 @@ impl<'sess> OnDiskCache<'sess> {\n     {\n         let pos = index.get(&dep_node_index).cloned()?;\n \n+        self.with_decoder(tcx, pos, |decoder| match decode_tagged(decoder, dep_node_index) {\n+            Ok(v) => Some(v),\n+            Err(e) => bug!(\"could not decode cached {}: {}\", debug_tag, e),\n+        })\n+    }\n+\n+    fn with_decoder<'tcx, T, F: FnOnce(&mut CacheDecoder<'sess, 'tcx>) -> T>(\n+        &'sess self,\n+        tcx: TyCtxt<'tcx>,\n+        pos: AbsoluteBytePos,\n+        f: F,\n+    ) -> T\n+    where\n+        T: Decodable,\n+    {\n         let cnum_map =\n             self.cnum_map.get_or_init(|| Self::compute_cnum_map(tcx, &self.prev_cnums[..]));\n \n@@ -375,16 +445,14 @@ impl<'sess> OnDiskCache<'sess> {\n             opaque: opaque::Decoder::new(&self.serialized_data[..], pos.to_usize()),\n             source_map: self.source_map,\n             cnum_map,\n-            synthetic_syntax_contexts: &self.synthetic_syntax_contexts,\n             file_index_to_file: &self.file_index_to_file,\n             file_index_to_stable_id: &self.file_index_to_stable_id,\n             alloc_decoding_session: self.alloc_decoding_state.new_decoding_session(),\n+            syntax_contexts: &self.syntax_contexts,\n+            expn_data: &self.expn_data,\n+            hygiene_context: &self.hygiene_context,\n         };\n-\n-        match decode_tagged(&mut decoder, dep_node_index) {\n-            Ok(v) => Some(v),\n-            Err(e) => bug!(\"could not decode cached {}: {}\", debug_tag, e),\n-        }\n+        f(&mut decoder)\n     }\n \n     // This function builds mapping from previous-session-`CrateNum` to\n@@ -430,10 +498,12 @@ struct CacheDecoder<'a, 'tcx> {\n     opaque: opaque::Decoder<'a>,\n     source_map: &'a SourceMap,\n     cnum_map: &'a IndexVec<CrateNum, Option<CrateNum>>,\n-    synthetic_syntax_contexts: &'a Lock<FxHashMap<AbsoluteBytePos, SyntaxContext>>,\n     file_index_to_file: &'a Lock<FxHashMap<SourceFileIndex, Lrc<SourceFile>>>,\n     file_index_to_stable_id: &'a FxHashMap<SourceFileIndex, StableSourceFileId>,\n     alloc_decoding_session: AllocDecodingSession<'a>,\n+    syntax_contexts: &'a FxHashMap<u32, AbsoluteBytePos>,\n+    expn_data: &'a FxHashMap<u32, AbsoluteBytePos>,\n+    hygiene_context: &'a HygieneDecodeContext,\n }\n \n impl<'a, 'tcx> CacheDecoder<'a, 'tcx> {\n@@ -577,6 +647,43 @@ impl<'a, 'tcx> TyDecoder<'tcx> for CacheDecoder<'a, 'tcx> {\n \n implement_ty_decoder!(CacheDecoder<'a, 'tcx>);\n \n+impl<'a, 'tcx> SpecializedDecoder<SyntaxContext> for CacheDecoder<'a, 'tcx> {\n+    fn specialized_decode(&mut self) -> Result<SyntaxContext, Self::Error> {\n+        let syntax_contexts = self.syntax_contexts;\n+        rustc_span::hygiene::decode_syntax_context(self, self.hygiene_context, |this, id| {\n+            // This closure is invoked if we haven't already decoded the data for the `SyntaxContext` we are deserializing.\n+            // We look up the position of the associated `SyntaxData` and decode it.\n+            let pos = syntax_contexts.get(&id).unwrap();\n+            this.with_position(pos.to_usize(), |decoder| {\n+                let data: SyntaxContextData = decode_tagged(decoder, TAG_SYNTAX_CONTEXT)?;\n+                Ok(data)\n+            })\n+        })\n+    }\n+}\n+\n+impl<'a, 'tcx> SpecializedDecoder<ExpnId> for CacheDecoder<'a, 'tcx> {\n+    fn specialized_decode(&mut self) -> Result<ExpnId, Self::Error> {\n+        let expn_data = self.expn_data;\n+        rustc_span::hygiene::decode_expn_id(\n+            self,\n+            ExpnDataDecodeMode::incr_comp(self.hygiene_context),\n+            |this, index| {\n+                // This closure is invoked if we haven't already decoded the data for the `ExpnId` we are deserializing.\n+                // We look up the position of the associated `ExpnData` and decode it.\n+                let pos = expn_data\n+                    .get(&index)\n+                    .unwrap_or_else(|| panic!(\"Bad index {:?} (map {:?})\", index, expn_data));\n+\n+                this.with_position(pos.to_usize(), |decoder| {\n+                    let data: ExpnData = decode_tagged(decoder, TAG_EXPN_DATA)?;\n+                    Ok(data)\n+                })\n+            },\n+        )\n+    }\n+}\n+\n impl<'a, 'tcx> SpecializedDecoder<interpret::AllocId> for CacheDecoder<'a, 'tcx> {\n     fn specialized_decode(&mut self) -> Result<interpret::AllocId, Self::Error> {\n         let alloc_decoding_session = self.alloc_decoding_session;\n@@ -598,48 +705,13 @@ impl<'a, 'tcx> SpecializedDecoder<Span> for CacheDecoder<'a, 'tcx> {\n         let line_lo = usize::decode(self)?;\n         let col_lo = BytePos::decode(self)?;\n         let len = BytePos::decode(self)?;\n+        let ctxt = SyntaxContext::decode(self)?;\n \n         let file_lo = self.file_index_to_file(file_lo_index);\n         let lo = file_lo.lines[line_lo - 1] + col_lo;\n         let hi = lo + len;\n \n-        let expn_data_tag = u8::decode(self)?;\n-\n-        // FIXME(mw): This method does not restore `ExpnData::parent` or\n-        // `SyntaxContextData::prev_ctxt` or `SyntaxContextData::opaque`. These things\n-        // don't seem to be used after HIR lowering, so everything should be fine\n-        // until we want incremental compilation to serialize Spans that we need\n-        // full hygiene information for.\n-        let location = || Span::with_root_ctxt(lo, hi);\n-        let recover_from_expn_data = |this: &Self, expn_data, transparency, pos| {\n-            let span = location().fresh_expansion_with_transparency(expn_data, transparency);\n-            this.synthetic_syntax_contexts.borrow_mut().insert(pos, span.ctxt());\n-            span\n-        };\n-        Ok(match expn_data_tag {\n-            TAG_NO_EXPN_DATA => location(),\n-            TAG_EXPN_DATA_INLINE => {\n-                let (expn_data, transparency) = Decodable::decode(self)?;\n-                recover_from_expn_data(\n-                    self,\n-                    expn_data,\n-                    transparency,\n-                    AbsoluteBytePos::new(self.opaque.position()),\n-                )\n-            }\n-            TAG_EXPN_DATA_SHORTHAND => {\n-                let pos = AbsoluteBytePos::decode(self)?;\n-                let cached_ctxt = self.synthetic_syntax_contexts.borrow().get(&pos).cloned();\n-                if let Some(ctxt) = cached_ctxt {\n-                    Span::new(lo, hi, ctxt)\n-                } else {\n-                    let (expn_data, transparency) =\n-                        self.with_position(pos.to_usize(), |this| Decodable::decode(this))?;\n-                    recover_from_expn_data(self, expn_data, transparency, pos)\n-                }\n-            }\n-            _ => unreachable!(),\n-        })\n+        Ok(Span::new(lo, hi, ctxt))\n     }\n }\n \n@@ -695,11 +767,11 @@ struct CacheEncoder<'a, 'tcx, E: ty_codec::TyEncoder> {\n     encoder: &'a mut E,\n     type_shorthands: FxHashMap<Ty<'tcx>, usize>,\n     predicate_shorthands: FxHashMap<ty::Predicate<'tcx>, usize>,\n-    expn_data_shorthands: FxHashMap<ExpnId, AbsoluteBytePos>,\n     interpret_allocs: FxHashMap<interpret::AllocId, usize>,\n     interpret_allocs_inverse: Vec<interpret::AllocId>,\n     source_map: CachingSourceMapView<'tcx>,\n     file_to_file_index: FxHashMap<*const SourceFile, SourceFileIndex>,\n+    hygiene_context: &'a HygieneEncodeContext,\n }\n \n impl<'a, 'tcx, E> CacheEncoder<'a, 'tcx, E>\n@@ -750,6 +822,29 @@ where\n     }\n }\n \n+impl<'a, 'tcx, E> SpecializedEncoder<SyntaxContext> for CacheEncoder<'a, 'tcx, E>\n+where\n+    E: 'a + TyEncoder,\n+{\n+    fn specialized_encode(&mut self, ctxt: &SyntaxContext) -> Result<(), Self::Error> {\n+        rustc_span::hygiene::raw_encode_syntax_context(*ctxt, self.hygiene_context, self)\n+    }\n+}\n+\n+impl<'a, 'tcx, E> SpecializedEncoder<ExpnId> for CacheEncoder<'a, 'tcx, E>\n+where\n+    E: 'a + TyEncoder,\n+{\n+    fn specialized_encode(&mut self, expn: &ExpnId) -> Result<(), Self::Error> {\n+        rustc_span::hygiene::raw_encode_expn_id(\n+            *expn,\n+            self.hygiene_context,\n+            ExpnDataEncodeMode::IncrComp,\n+            self,\n+        )\n+    }\n+}\n+\n impl<'a, 'tcx, E> SpecializedEncoder<Span> for CacheEncoder<'a, 'tcx, E>\n where\n     E: 'a + TyEncoder,\n@@ -779,21 +874,8 @@ where\n         line_lo.encode(self)?;\n         col_lo.encode(self)?;\n         len.encode(self)?;\n-\n-        if span_data.ctxt == SyntaxContext::root() {\n-            TAG_NO_EXPN_DATA.encode(self)\n-        } else {\n-            let (expn_id, transparency, expn_data) = span_data.ctxt.outer_mark_with_data();\n-            if let Some(pos) = self.expn_data_shorthands.get(&expn_id).cloned() {\n-                TAG_EXPN_DATA_SHORTHAND.encode(self)?;\n-                pos.encode(self)\n-            } else {\n-                TAG_EXPN_DATA_INLINE.encode(self)?;\n-                let pos = AbsoluteBytePos::new(self.position());\n-                self.expn_data_shorthands.insert(expn_id, pos);\n-                (expn_data, transparency).encode(self)\n-            }\n-        }\n+        span_data.ctxt.encode(self)?;\n+        Ok(())\n     }\n }\n "}, {"sha": "737fd13812058bc9ab3aa1373a857a686260947e", "filename": "src/librustc_resolve/build_reduced_graph.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -35,7 +35,7 @@ use rustc_middle::ty;\n use rustc_span::hygiene::{ExpnId, MacroKind};\n use rustc_span::source_map::{respan, Spanned};\n use rustc_span::symbol::{kw, sym, Ident, Symbol};\n-use rustc_span::{Span, DUMMY_SP};\n+use rustc_span::Span;\n \n use log::debug;\n use std::cell::Cell;\n@@ -130,8 +130,8 @@ impl<'a> Resolver<'a> {\n             parent,\n             kind,\n             def_id,\n-            ExpnId::root(),\n-            DUMMY_SP,\n+            self.cstore().module_expansion_untracked(def_id, &self.session),\n+            self.cstore().get_span_untracked(def_id, &self.session),\n         ));\n         self.extern_module_map.insert(def_id, module);\n         module\n@@ -888,7 +888,7 @@ impl<'a, 'b> BuildReducedGraphVisitor<'a, 'b> {\n     fn build_reduced_graph_for_external_crate_res(&mut self, child: Export<NodeId>) {\n         let parent = self.parent_scope.module;\n         let Export { ident, res, vis, span } = child;\n-        let expansion = ExpnId::root(); // FIXME(jseyfried) intercrate hygiene\n+        let expansion = self.parent_scope.expansion;\n         // Record primary definitions.\n         match res {\n             Res::Def(kind @ (DefKind::Mod | DefKind::Enum | DefKind::Trait), def_id) => {"}, {"sha": "dfc50a30c121e4965c5f9b1ff8da7bb5102afb42", "filename": "src/librustc_resolve/lib.rs", "status": "modified", "additions": 33, "deletions": 3, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_resolve%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_resolve%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Flib.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -434,7 +434,7 @@ impl ModuleKind {\n ///\n /// Multiple bindings in the same module can have the same key (in a valid\n /// program) if all but one of them come from glob imports.\n-#[derive(Copy, Clone, PartialEq, Eq, Hash)]\n+#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n struct BindingKey {\n     /// The identifier for the binding, aways the `normalize_to_macros_2_0` version of the\n     /// identifier.\n@@ -1988,6 +1988,7 @@ impl<'a> Resolver<'a> {\n     }\n \n     fn resolve_crate_root(&mut self, ident: Ident) -> Module<'a> {\n+        debug!(\"resolve_crate_root({:?})\", ident);\n         let mut ctxt = ident.span.ctxt();\n         let mark = if ident.name == kw::DollarCrate {\n             // When resolving `$crate` from a `macro_rules!` invoked in a `macro`,\n@@ -1997,6 +1998,10 @@ impl<'a> Resolver<'a> {\n             // definitions actually produced by `macro` and `macro` definitions produced by\n             // `macro_rules!`, but at least such configurations are not stable yet.\n             ctxt = ctxt.normalize_to_macro_rules();\n+            debug!(\n+                \"resolve_crate_root: marks={:?}\",\n+                ctxt.marks().into_iter().map(|(i, t)| (i.expn_data(), t)).collect::<Vec<_>>()\n+            );\n             let mut iter = ctxt.marks().into_iter().rev().peekable();\n             let mut result = None;\n             // Find the last opaque mark from the end if it exists.\n@@ -2008,6 +2013,11 @@ impl<'a> Resolver<'a> {\n                     break;\n                 }\n             }\n+            debug!(\n+                \"resolve_crate_root: found opaque mark {:?} {:?}\",\n+                result,\n+                result.map(|r| r.expn_data())\n+            );\n             // Then find the last semi-transparent mark from the end if it exists.\n             for (mark, transparency) in iter {\n                 if transparency == Transparency::SemiTransparent {\n@@ -2016,16 +2026,36 @@ impl<'a> Resolver<'a> {\n                     break;\n                 }\n             }\n+            debug!(\n+                \"resolve_crate_root: found semi-transparent mark {:?} {:?}\",\n+                result,\n+                result.map(|r| r.expn_data())\n+            );\n             result\n         } else {\n+            debug!(\"resolve_crate_root: not DollarCrate\");\n             ctxt = ctxt.normalize_to_macros_2_0();\n             ctxt.adjust(ExpnId::root())\n         };\n         let module = match mark {\n             Some(def) => self.macro_def_scope(def),\n-            None => return self.graph_root,\n+            None => {\n+                debug!(\n+                    \"resolve_crate_root({:?}): found no mark (ident.span = {:?})\",\n+                    ident, ident.span\n+                );\n+                return self.graph_root;\n+            }\n         };\n-        self.get_module(DefId { index: CRATE_DEF_INDEX, ..module.normal_ancestor_id })\n+        let module = self.get_module(DefId { index: CRATE_DEF_INDEX, ..module.normal_ancestor_id });\n+        debug!(\n+            \"resolve_crate_root({:?}): got module {:?} ({:?}) (ident.span = {:?})\",\n+            ident,\n+            module,\n+            module.kind.name(),\n+            ident.span\n+        );\n+        module\n     }\n \n     fn resolve_self(&mut self, ctxt: &mut SyntaxContext, module: Module<'a>) -> Module<'a> {"}, {"sha": "0751dbb027ae2045cf522519dbd0474a0559456b", "filename": "src/librustc_save_analysis/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_save_analysis%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_save_analysis%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Flib.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -789,7 +789,7 @@ impl<'tcx> SaveContext<'tcx> {\n         let callee = span.source_callee()?;\n \n         let mac_name = match callee.kind {\n-            ExpnKind::Macro(mac_kind, name) => match mac_kind {\n+            ExpnKind::Macro(kind, name) => match kind {\n                 MacroKind::Bang => name,\n \n                 // Ignore attribute macros, their spans are usually mangled"}, {"sha": "a874f81868f153ab6f373101b30136841687b10e", "filename": "src/librustc_span/def_id.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_span%2Fdef_id.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_span%2Fdef_id.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_span%2Fdef_id.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -247,3 +247,9 @@ impl<CTX: HashStableContext> HashStable<CTX> for DefId {\n         hcx.hash_def_id(*self, hasher)\n     }\n }\n+\n+impl<CTX: HashStableContext> HashStable<CTX> for CrateNum {\n+    fn hash_stable(&self, hcx: &mut CTX, hasher: &mut StableHasher) {\n+        hcx.hash_crate_num(*self, hasher)\n+    }\n+}"}, {"sha": "13bc1751831b977cabe33711938f791b3a93e2a5", "filename": "src/librustc_span/hygiene.rs", "status": "modified", "additions": 368, "deletions": 25, "changes": 393, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_span%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_span%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_span%2Fhygiene.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -24,24 +24,27 @@\n // because getting it wrong can lead to nested `HygieneData::with` calls that\n // trigger runtime aborts. (Fortunately these are obvious and easy to fix.)\n \n-use crate::def_id::{DefId, CRATE_DEF_INDEX};\n use crate::edition::Edition;\n use crate::symbol::{kw, sym, Symbol};\n use crate::SESSION_GLOBALS;\n use crate::{Span, DUMMY_SP};\n \n-use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::sync::Lrc;\n+use crate::def_id::{CrateNum, DefId, CRATE_DEF_INDEX, LOCAL_CRATE};\n+use log::*;\n+use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n+use rustc_data_structures::sync::{Lock, Lrc};\n use rustc_macros::HashStable_Generic;\n-use rustc_serialize::{Decodable, Decoder, Encodable, Encoder};\n+use rustc_serialize::{\n+    Decodable, Decoder, Encodable, Encoder, UseSpecializedDecodable, UseSpecializedEncodable,\n+};\n use std::fmt;\n \n /// A `SyntaxContext` represents a chain of pairs `(ExpnId, Transparency)` named \"marks\".\n #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]\n pub struct SyntaxContext(u32);\n \n-#[derive(Debug)]\n-struct SyntaxContextData {\n+#[derive(Debug, RustcEncodable, RustcDecodable, Clone)]\n+pub struct SyntaxContextData {\n     outer_expn: ExpnId,\n     outer_transparency: Transparency,\n     parent: SyntaxContext,\n@@ -77,6 +80,8 @@ pub enum Transparency {\n     Opaque,\n }\n \n+pub(crate) const NUM_TRANSPARENCIES: usize = 3;\n+\n impl ExpnId {\n     pub fn fresh(expn_data: Option<ExpnData>) -> Self {\n         HygieneData::with(|data| data.fresh_expn(expn_data))\n@@ -104,10 +109,11 @@ impl ExpnId {\n     }\n \n     #[inline]\n-    pub fn set_expn_data(self, expn_data: ExpnData) {\n+    pub fn set_expn_data(self, mut expn_data: ExpnData) {\n         HygieneData::with(|data| {\n             let old_expn_data = &mut data.expn_data[self.0 as usize];\n             assert!(old_expn_data.is_none(), \"expansion data is reset for an expansion ID\");\n+            expn_data.orig_id.replace(self.as_u32()).expect_none(\"orig_id should be None\");\n             *old_expn_data = Some(expn_data);\n         })\n     }\n@@ -143,7 +149,7 @@ impl ExpnId {\n }\n \n #[derive(Debug)]\n-crate struct HygieneData {\n+pub struct HygieneData {\n     /// Each expansion should have an associated expansion data, but sometimes there's a delay\n     /// between creation of an expansion ID and obtaining its data (e.g. macros are collected\n     /// first and then resolved later), so we use an `Option` here.\n@@ -154,13 +160,16 @@ crate struct HygieneData {\n \n impl HygieneData {\n     crate fn new(edition: Edition) -> Self {\n+        let mut root_data = ExpnData::default(\n+            ExpnKind::Root,\n+            DUMMY_SP,\n+            edition,\n+            Some(DefId::local(CRATE_DEF_INDEX)),\n+        );\n+        root_data.orig_id = Some(0);\n+\n         HygieneData {\n-            expn_data: vec![Some(ExpnData::default(\n-                ExpnKind::Root,\n-                DUMMY_SP,\n-                edition,\n-                Some(DefId::local(CRATE_DEF_INDEX)),\n-            ))],\n+            expn_data: vec![Some(root_data)],\n             syntax_context_data: vec![SyntaxContextData {\n                 outer_expn: ExpnId::root(),\n                 outer_transparency: Transparency::Opaque,\n@@ -173,13 +182,17 @@ impl HygieneData {\n         }\n     }\n \n-    fn with<T, F: FnOnce(&mut HygieneData) -> T>(f: F) -> T {\n+    pub fn with<T, F: FnOnce(&mut HygieneData) -> T>(f: F) -> T {\n         SESSION_GLOBALS.with(|session_globals| f(&mut *session_globals.hygiene_data.borrow_mut()))\n     }\n \n-    fn fresh_expn(&mut self, expn_data: Option<ExpnData>) -> ExpnId {\n+    fn fresh_expn(&mut self, mut expn_data: Option<ExpnData>) -> ExpnId {\n+        let raw_id = self.expn_data.len() as u32;\n+        if let Some(data) = expn_data.as_mut() {\n+            data.orig_id.replace(raw_id).expect_none(\"orig_id should be None\");\n+        }\n         self.expn_data.push(expn_data);\n-        ExpnId(self.expn_data.len() as u32 - 1)\n+        ExpnId(raw_id)\n     }\n \n     fn expn_data(&self, expn_id: ExpnId) -> &ExpnData {\n@@ -226,6 +239,7 @@ impl HygieneData {\n     fn marks(&self, mut ctxt: SyntaxContext) -> Vec<(ExpnId, Transparency)> {\n         let mut marks = Vec::new();\n         while ctxt != SyntaxContext::root() {\n+            debug!(\"marks: getting parent of {:?}\", ctxt);\n             marks.push(self.outer_mark(ctxt));\n             ctxt = self.parent_ctxt(ctxt);\n         }\n@@ -234,8 +248,14 @@ impl HygieneData {\n     }\n \n     fn walk_chain(&self, mut span: Span, to: SyntaxContext) -> Span {\n+        debug!(\"walk_chain({:?}, {:?})\", span, to);\n+        debug!(\"walk_chain: span ctxt = {:?}\", span.ctxt());\n         while span.from_expansion() && span.ctxt() != to {\n-            span = self.expn_data(self.outer_expn(span.ctxt())).call_site;\n+            let outer_expn = self.outer_expn(span.ctxt());\n+            debug!(\"walk_chain({:?}): outer_expn={:?}\", span, outer_expn);\n+            let expn_data = self.expn_data(outer_expn);\n+            debug!(\"walk_chain({:?}): expn_data={:?}\", span, expn_data);\n+            span = expn_data.call_site;\n         }\n         span\n     }\n@@ -682,8 +702,25 @@ pub struct ExpnData {\n     /// The `DefId` of the macro being invoked,\n     /// if this `ExpnData` corresponds to a macro invocation\n     pub macro_def_id: Option<DefId>,\n+    /// The crate that originally created this `ExpnData. During\n+    /// metadata serialization, we only encode `ExpnData`s that were\n+    /// created locally - when our serialized metadata is decoded,\n+    /// foreign `ExpnId`s will have their `ExpnData` looked up\n+    /// from the crate specified by `Crate\n+    pub krate: CrateNum,\n+    /// The raw that this `ExpnData` had in its original crate.\n+    /// An `ExpnData` can be created before being assigned an `ExpnId`,\n+    /// so this might be `None` until `set_expn_data` is called\n+    // This is used only for serialization/deserialization purposes:\n+    // two `ExpnData`s that differ only in their `orig_id` should\n+    // be considered equivalent.\n+    #[stable_hasher(ignore)]\n+    pub orig_id: Option<u32>,\n }\n \n+// This would require special handling of `orig_id` and `parent`\n+impl !PartialEq for ExpnData {}\n+\n impl ExpnData {\n     /// Constructs expansion data with default properties.\n     pub fn default(\n@@ -702,6 +739,8 @@ impl ExpnData {\n             local_inner_macros: false,\n             edition,\n             macro_def_id,\n+            krate: LOCAL_CRATE,\n+            orig_id: None,\n         }\n     }\n \n@@ -789,7 +828,7 @@ impl MacroKind {\n }\n \n /// The kind of AST transform.\n-#[derive(Clone, Copy, PartialEq, Debug, RustcEncodable, RustcDecodable, HashStable_Generic)]\n+#[derive(Clone, Copy, Debug, PartialEq, RustcEncodable, RustcDecodable, HashStable_Generic)]\n pub enum AstPass {\n     StdImports,\n     TestHarness,\n@@ -847,14 +886,318 @@ impl DesugaringKind {\n     }\n }\n \n-impl Encodable for ExpnId {\n-    fn encode<E: Encoder>(&self, _: &mut E) -> Result<(), E::Error> {\n-        Ok(()) // FIXME(jseyfried) intercrate hygiene\n+impl UseSpecializedEncodable for ExpnId {}\n+impl UseSpecializedDecodable for ExpnId {}\n+\n+#[derive(Default)]\n+pub struct HygieneEncodeContext {\n+    /// All `SyntaxContexts` for which we have writen `SyntaxContextData` into crate metadata.\n+    /// This is `None` after we finish encoding `SyntaxContexts`, to ensure\n+    /// that we don't accidentally try to encode any more `SyntaxContexts`\n+    serialized_ctxts: Lock<FxHashSet<SyntaxContext>>,\n+    /// The `SyntaxContexts` that we have serialized (e.g. as a result of encoding `Spans`)\n+    /// in the most recent 'round' of serializnig. Serializing `SyntaxContextData`\n+    /// may cause us to serialize more `SyntaxContext`s, so serialize in a loop\n+    /// until we reach a fixed point.\n+    latest_ctxts: Lock<FxHashSet<SyntaxContext>>,\n+\n+    serialized_expns: Lock<FxHashSet<ExpnId>>,\n+\n+    latest_expns: Lock<FxHashSet<ExpnId>>,\n+}\n+\n+impl HygieneEncodeContext {\n+    pub fn encode<\n+        T,\n+        R,\n+        F: FnMut(&mut T, u32, &SyntaxContextData) -> Result<(), R>,\n+        G: FnMut(&mut T, u32, &ExpnData) -> Result<(), R>,\n+    >(\n+        &self,\n+        encoder: &mut T,\n+        mut encode_ctxt: F,\n+        mut encode_expn: G,\n+    ) -> Result<(), R> {\n+        // When we serialize a `SyntaxContextData`, we may end up serializing\n+        // a `SyntaxContext` that we haven't seen before\n+        while !self.latest_ctxts.lock().is_empty() || !self.latest_expns.lock().is_empty() {\n+            debug!(\n+                \"encode_hygiene: Serializing a round of {:?} SyntaxContextDatas: {:?}\",\n+                self.latest_ctxts.lock().len(),\n+                self.latest_ctxts\n+            );\n+\n+            // Consume the current round of SyntaxContexts.\n+            // Drop the lock() temporary early\n+            let latest_ctxts = { std::mem::take(&mut *self.latest_ctxts.lock()) };\n+\n+            // It's fine to iterate over a HashMap, because the serialization\n+            // of the table that we insert data into doesn't depend on insertion\n+            // order\n+            for_all_ctxts_in(latest_ctxts.into_iter(), |(index, ctxt, data)| {\n+                if self.serialized_ctxts.lock().insert(ctxt) {\n+                    encode_ctxt(encoder, index, data)?;\n+                }\n+                Ok(())\n+            })?;\n+\n+            let latest_expns = { std::mem::take(&mut *self.latest_expns.lock()) };\n+\n+            for_all_expns_in(latest_expns.into_iter(), |index, expn, data| {\n+                if self.serialized_expns.lock().insert(expn) {\n+                    encode_expn(encoder, index, data)?;\n+                }\n+                Ok(())\n+            })?;\n+        }\n+        debug!(\"encode_hygiene: Done serializing SyntaxContextData\");\n+        Ok(())\n+    }\n+}\n+\n+#[derive(Default)]\n+/// Additional information used to assist in decoding hygiene data\n+pub struct HygieneDecodeContext {\n+    // Maps serialized `SyntaxContext` ids to a `SyntaxContext` in the current\n+    // global `HygieneData`. When we deserialize a `SyntaxContext`, we need to create\n+    // a new id in the global `HygieneData`. This map tracks the ID we end up picking,\n+    // so that multiple occurences of the same serialized id are decoded to the same\n+    // `SyntaxContext`\n+    remapped_ctxts: Lock<Vec<Option<SyntaxContext>>>,\n+    // The same as `remapepd_ctxts`, but for `ExpnId`s\n+    remapped_expns: Lock<Vec<Option<ExpnId>>>,\n+}\n+\n+pub fn decode_expn_id<\n+    'a,\n+    D: Decoder,\n+    F: FnOnce(&mut D, u32) -> Result<ExpnData, D::Error>,\n+    G: FnOnce(CrateNum) -> &'a HygieneDecodeContext,\n+>(\n+    d: &mut D,\n+    mode: ExpnDataDecodeMode<'a, G>,\n+    decode_data: F,\n+) -> Result<ExpnId, D::Error> {\n+    let index = u32::decode(d)?;\n+    let context = match mode {\n+        ExpnDataDecodeMode::IncrComp(context) => context,\n+        ExpnDataDecodeMode::Metadata(get_context) => {\n+            let krate = CrateNum::decode(d)?;\n+            get_context(krate)\n+        }\n+    };\n+\n+    // Do this after decoding, so that we decode a `CrateNum`\n+    // if necessary\n+    if index == ExpnId::root().as_u32() {\n+        debug!(\"decode_expn_id: deserialized root\");\n+        return Ok(ExpnId::root());\n+    }\n+\n+    let outer_expns = &context.remapped_expns;\n+\n+    // Ensure that the lock() temporary is dropped early\n+    {\n+        if let Some(expn_id) = outer_expns.lock().get(index as usize).copied().flatten() {\n+            return Ok(expn_id);\n+        }\n+    }\n+\n+    // Don't decode the data inside `HygieneData::with`, since we need to recursively decode\n+    // other ExpnIds\n+    let mut expn_data = decode_data(d, index)?;\n+\n+    let expn_id = HygieneData::with(|hygiene_data| {\n+        let expn_id = ExpnId(hygiene_data.expn_data.len() as u32);\n+\n+        // If we just deserialized an `ExpnData` owned by\n+        // the local crate, its `orig_id` will be stale,\n+        // so we need to update it to its own value.\n+        // This only happens when we deserialize the incremental cache,\n+        // since a crate will never decode its own metadata.\n+        if expn_data.krate == LOCAL_CRATE {\n+            expn_data.orig_id = Some(expn_id.0);\n+        }\n+\n+        hygiene_data.expn_data.push(Some(expn_data));\n+\n+        let mut expns = outer_expns.lock();\n+        let new_len = index as usize + 1;\n+        if expns.len() < new_len {\n+            expns.resize(new_len, None);\n+        }\n+        expns[index as usize] = Some(expn_id);\n+        drop(expns);\n+        expn_id\n+    });\n+    return Ok(expn_id);\n+}\n+\n+// Decodes `SyntaxContext`, using the provided `HygieneDecodeContext`\n+// to track which `SyntaxContext`s we have already decoded.\n+// The provided closure will be invoked to deserialize a `SyntaxContextData`\n+// if we haven't already seen the id of the `SyntaxContext` we are deserializing.\n+pub fn decode_syntax_context<\n+    D: Decoder,\n+    F: FnOnce(&mut D, u32) -> Result<SyntaxContextData, D::Error>,\n+>(\n+    d: &mut D,\n+    context: &HygieneDecodeContext,\n+    decode_data: F,\n+) -> Result<SyntaxContext, D::Error> {\n+    let raw_id: u32 = Decodable::decode(d)?;\n+    if raw_id == 0 {\n+        debug!(\"decode_syntax_context: deserialized root\");\n+        // The root is special\n+        return Ok(SyntaxContext::root());\n+    }\n+\n+    let outer_ctxts = &context.remapped_ctxts;\n+\n+    // Ensure that the lock() temporary is dropped early\n+    {\n+        if let Some(ctxt) = outer_ctxts.lock().get(raw_id as usize).copied().flatten() {\n+            return Ok(ctxt);\n+        }\n+    }\n+\n+    // Allocate and store SyntaxContext id *before* calling the decoder function,\n+    // as the SyntaxContextData may reference itself.\n+    let new_ctxt = HygieneData::with(|hygiene_data| {\n+        let new_ctxt = SyntaxContext(hygiene_data.syntax_context_data.len() as u32);\n+        // Push a dummy SyntaxContextData to ensure that nobody else can get the\n+        // same ID as us. This will be overwritten after call `decode_Data`\n+        hygiene_data.syntax_context_data.push(SyntaxContextData {\n+            outer_expn: ExpnId::root(),\n+            outer_transparency: Transparency::Transparent,\n+            parent: SyntaxContext::root(),\n+            opaque: SyntaxContext::root(),\n+            opaque_and_semitransparent: SyntaxContext::root(),\n+            dollar_crate_name: kw::Invalid,\n+        });\n+        let mut ctxts = outer_ctxts.lock();\n+        let new_len = raw_id as usize + 1;\n+        if ctxts.len() < new_len {\n+            ctxts.resize(new_len, None);\n+        }\n+        ctxts[raw_id as usize] = Some(new_ctxt);\n+        drop(ctxts);\n+        new_ctxt\n+    });\n+\n+    // Don't try to decode data while holding the lock, since we need to\n+    // be able to recursively decode a SyntaxContext\n+    let mut ctxt_data = decode_data(d, raw_id)?;\n+    // Reset `dollar_crate_name` so that it will be updated by `update_dollar_crate_names`\n+    // We don't care what the encoding crate set this to - we want to resolve it\n+    // from the perspective of the current compilation session\n+    ctxt_data.dollar_crate_name = kw::DollarCrate;\n+\n+    // Overwrite the dummy data with our decoded SyntaxContextData\n+    HygieneData::with(|hygiene_data| {\n+        let dummy = std::mem::replace(\n+            &mut hygiene_data.syntax_context_data[new_ctxt.as_u32() as usize],\n+            ctxt_data,\n+        );\n+        // Make sure nothing weird happening while `decode_data` was running\n+        assert_eq!(dummy.dollar_crate_name, kw::Invalid);\n+    });\n+\n+    return Ok(new_ctxt);\n+}\n+\n+pub fn num_syntax_ctxts() -> usize {\n+    HygieneData::with(|data| data.syntax_context_data.len())\n+}\n+\n+pub fn for_all_ctxts_in<E, F: FnMut((u32, SyntaxContext, &SyntaxContextData)) -> Result<(), E>>(\n+    ctxts: impl Iterator<Item = SyntaxContext>,\n+    mut f: F,\n+) -> Result<(), E> {\n+    let all_data: Vec<_> = HygieneData::with(|data| {\n+        ctxts.map(|ctxt| (ctxt, data.syntax_context_data[ctxt.0 as usize].clone())).collect()\n+    });\n+    for (ctxt, data) in all_data.into_iter() {\n+        f((ctxt.0, ctxt, &data))?;\n     }\n+    Ok(())\n }\n \n-impl Decodable for ExpnId {\n-    fn decode<D: Decoder>(_: &mut D) -> Result<Self, D::Error> {\n-        Ok(ExpnId::root()) // FIXME(jseyfried) intercrate hygiene\n+pub fn for_all_expns_in<E, F: FnMut(u32, ExpnId, &ExpnData) -> Result<(), E>>(\n+    expns: impl Iterator<Item = ExpnId>,\n+    mut f: F,\n+) -> Result<(), E> {\n+    let all_data: Vec<_> = HygieneData::with(|data| {\n+        expns.map(|expn| (expn, data.expn_data[expn.0 as usize].clone())).collect()\n+    });\n+    for (expn, data) in all_data.into_iter() {\n+        f(expn.0, expn, &data.unwrap_or_else(|| panic!(\"Missing data for {:?}\", expn)))?;\n+    }\n+    Ok(())\n+}\n+pub fn for_all_data<E, F: FnMut((u32, SyntaxContext, &SyntaxContextData)) -> Result<(), E>>(\n+    mut f: F,\n+) -> Result<(), E> {\n+    let all_data = HygieneData::with(|data| data.syntax_context_data.clone());\n+    for (i, data) in all_data.into_iter().enumerate() {\n+        f((i as u32, SyntaxContext(i as u32), &data))?;\n     }\n+    Ok(())\n }\n+\n+pub fn for_all_expn_data<E, F: FnMut(u32, &ExpnData) -> Result<(), E>>(mut f: F) -> Result<(), E> {\n+    let all_data = HygieneData::with(|data| data.expn_data.clone());\n+    for (i, data) in all_data.into_iter().enumerate() {\n+        f(i as u32, &data.unwrap_or_else(|| panic!(\"Missing ExpnData!\")))?;\n+    }\n+    Ok(())\n+}\n+\n+pub fn raw_encode_syntax_context<E: Encoder>(\n+    ctxt: SyntaxContext,\n+    context: &HygieneEncodeContext,\n+    e: &mut E,\n+) -> Result<(), E::Error> {\n+    if !context.serialized_ctxts.lock().contains(&ctxt) {\n+        context.latest_ctxts.lock().insert(ctxt);\n+    }\n+    ctxt.0.encode(e)\n+}\n+\n+pub fn raw_encode_expn_id<E: Encoder>(\n+    expn: ExpnId,\n+    context: &HygieneEncodeContext,\n+    mode: ExpnDataEncodeMode,\n+    e: &mut E,\n+) -> Result<(), E::Error> {\n+    if !context.serialized_expns.lock().contains(&expn) {\n+        context.latest_expns.lock().insert(expn);\n+    }\n+    match mode {\n+        ExpnDataEncodeMode::IncrComp => expn.0.encode(e),\n+        ExpnDataEncodeMode::Metadata => {\n+            let data = expn.expn_data();\n+            data.orig_id.expect(\"Missing orig_id\").encode(e)?;\n+            data.krate.encode(e)\n+        }\n+    }\n+}\n+\n+pub enum ExpnDataEncodeMode {\n+    IncrComp,\n+    Metadata,\n+}\n+\n+pub enum ExpnDataDecodeMode<'a, F: FnOnce(CrateNum) -> &'a HygieneDecodeContext> {\n+    IncrComp(&'a HygieneDecodeContext),\n+    Metadata(F),\n+}\n+\n+impl<'a> ExpnDataDecodeMode<'a, Box<dyn FnOnce(CrateNum) -> &'a HygieneDecodeContext>> {\n+    pub fn incr_comp(ctxt: &'a HygieneDecodeContext) -> Self {\n+        ExpnDataDecodeMode::IncrComp(ctxt)\n+    }\n+}\n+\n+impl UseSpecializedEncodable for SyntaxContext {}\n+impl UseSpecializedDecodable for SyntaxContext {}"}, {"sha": "7087dc80b1daf5a88298301d4106d6af6c4ff1f6", "filename": "src/librustc_span/lib.rs", "status": "modified", "additions": 48, "deletions": 14, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_span%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Flibrustc_span%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_span%2Flib.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -12,6 +12,8 @@\n #![feature(nll)]\n #![feature(optin_builtin_traits)]\n #![feature(min_specialization)]\n+#![feature(option_expect_none)]\n+#![feature(refcell_take)]\n \n // FIXME(#56935): Work around ICEs during cross-compilation.\n #[allow(unused)]\n@@ -30,8 +32,8 @@ pub mod edition;\n use edition::Edition;\n pub mod hygiene;\n pub use hygiene::SyntaxContext;\n-use hygiene::Transparency;\n pub use hygiene::{DesugaringKind, ExpnData, ExpnId, ExpnKind, ForLoopLoc, MacroKind};\n+use hygiene::{Transparency, NUM_TRANSPARENCIES};\n pub mod def_id;\n use def_id::{CrateNum, DefId, LOCAL_CRATE};\n mod span_encoding;\n@@ -44,7 +46,6 @@ mod analyze_source_file;\n pub mod fatal_error;\n \n use rustc_data_structures::fingerprint::Fingerprint;\n-use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n use rustc_data_structures::sync::{Lock, Lrc};\n \n@@ -86,6 +87,9 @@ impl SessionGlobals {\n     }\n }\n \n+// If this ever becomes non thread-local, `decode_syntax_context`\n+// and `decode_expn_id` will need to be updated to handle concurrent\n+// deserialization.\n scoped_tls::scoped_thread_local!(pub static SESSION_GLOBALS: SessionGlobals);\n \n // FIXME: Perhaps this should not implement Rustc{Decodable, Encodable}\n@@ -1733,8 +1737,9 @@ fn lookup_line(lines: &[BytePos], pos: BytePos) -> isize {\n /// This is a hack to allow using the `HashStable_Generic` derive macro\n /// instead of implementing everything in librustc_middle.\n pub trait HashStableContext {\n-    fn hash_spans(&self) -> bool;\n     fn hash_def_id(&mut self, _: DefId, hasher: &mut StableHasher);\n+    fn hash_crate_num(&mut self, _: CrateNum, hasher: &mut StableHasher);\n+    fn hash_spans(&self) -> bool;\n     fn byte_pos_to_line_and_col(\n         &mut self,\n         byte: BytePos,\n@@ -1757,15 +1762,14 @@ where\n     fn hash_stable(&self, ctx: &mut CTX, hasher: &mut StableHasher) {\n         const TAG_VALID_SPAN: u8 = 0;\n         const TAG_INVALID_SPAN: u8 = 1;\n-        const TAG_EXPANSION: u8 = 0;\n-        const TAG_NO_EXPANSION: u8 = 1;\n \n         if !ctx.hash_spans() {\n             return;\n         }\n \n         if *self == DUMMY_SP {\n-            return std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+            std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+            return;\n         }\n \n         // If this is not an empty or invalid span, we want to hash the last\n@@ -1775,12 +1779,16 @@ where\n         let (file_lo, line_lo, col_lo) = match ctx.byte_pos_to_line_and_col(span.lo) {\n             Some(pos) => pos,\n             None => {\n-                return std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+                std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+                span.ctxt.hash_stable(ctx, hasher);\n+                return;\n             }\n         };\n \n         if !file_lo.contains(span.hi) {\n-            return std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+            std::hash::Hash::hash(&TAG_INVALID_SPAN, hasher);\n+            span.ctxt.hash_stable(ctx, hasher);\n+            return;\n         }\n \n         std::hash::Hash::hash(&TAG_VALID_SPAN, hasher);\n@@ -1793,8 +1801,16 @@ where\n         let len = ((span.hi - span.lo).0 as u64) << 32;\n         let line_col_len = col | line | len;\n         std::hash::Hash::hash(&line_col_len, hasher);\n+        span.ctxt.hash_stable(ctx, hasher);\n+    }\n+}\n \n-        if span.ctxt == SyntaxContext::root() {\n+impl<CTX: HashStableContext> HashStable<CTX> for SyntaxContext {\n+    fn hash_stable(&self, ctx: &mut CTX, hasher: &mut StableHasher) {\n+        const TAG_EXPANSION: u8 = 0;\n+        const TAG_NO_EXPANSION: u8 = 1;\n+\n+        if *self == SyntaxContext::root() {\n             TAG_NO_EXPANSION.hash_stable(ctx, hasher);\n         } else {\n             TAG_EXPANSION.hash_stable(ctx, hasher);\n@@ -1803,21 +1819,39 @@ where\n             // times, we cache a stable hash of it and hash that instead of\n             // recursing every time.\n             thread_local! {\n-                static CACHE: RefCell<FxHashMap<hygiene::ExpnId, u64>> = Default::default();\n+                static CACHE: RefCell<Vec<Option<[Option<u64>; NUM_TRANSPARENCIES]>>> = Default::default();\n             }\n \n             let sub_hash: u64 = CACHE.with(|cache| {\n-                let expn_id = span.ctxt.outer_expn();\n+                let (expn_id, transparency, _) = self.outer_mark_with_data();\n+                let index = expn_id.as_u32() as usize;\n \n-                if let Some(&sub_hash) = cache.borrow().get(&expn_id) {\n-                    return sub_hash;\n+                if let Some(sub_hash_cache) = cache.borrow().get(index).copied().flatten() {\n+                    if let Some(sub_hash) = sub_hash_cache[transparency as usize] {\n+                        return sub_hash;\n+                    }\n                 }\n \n+                let new_len = index + 1;\n+\n                 let mut hasher = StableHasher::new();\n                 expn_id.expn_data().hash_stable(ctx, &mut hasher);\n+                transparency.hash_stable(ctx, &mut hasher);\n+\n                 let sub_hash: Fingerprint = hasher.finish();\n                 let sub_hash = sub_hash.to_smaller_hash();\n-                cache.borrow_mut().insert(expn_id, sub_hash);\n+\n+                let mut cache = cache.borrow_mut();\n+                if cache.len() < new_len {\n+                    cache.resize(new_len, None);\n+                }\n+                if let Some(mut sub_hash_cache) = cache[index] {\n+                    sub_hash_cache[transparency as usize] = Some(sub_hash);\n+                } else {\n+                    let mut sub_hash_cache = [None; NUM_TRANSPARENCIES];\n+                    sub_hash_cache[transparency as usize] = Some(sub_hash);\n+                    cache[index] = Some(sub_hash_cache);\n+                }\n                 sub_hash\n             });\n "}, {"sha": "91a9f63d39bfe4b71db6e64546facf39e06b249d", "filename": "src/test/incremental/hygiene/auxiliary/cached_hygiene.rs", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fincremental%2Fhygiene%2Fauxiliary%2Fcached_hygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fincremental%2Fhygiene%2Fauxiliary%2Fcached_hygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fhygiene%2Fauxiliary%2Fcached_hygiene.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -0,0 +1,36 @@\n+// revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n+\n+// We use #[inline(always)] to ensure that the downstream crate\n+// will always load the MIR for these functions\n+\n+#![feature(rustc_attrs)]\n+\n+#[allow(unused)]\n+macro_rules! first_macro {\n+    () => {\n+        println!(\"New call!\");\n+    }\n+}\n+\n+#[rustc_dirty(label=\"typeck\", cfg=\"rpass2\")]\n+#[inline(always)]\n+pub fn changed_fn() {\n+    // This will cause additional hygiene to be generate,\n+    // which will cause the SyntaxContext/ExpnId raw ids to be\n+    // different when we write out `my_fn` to the crate metadata.\n+    #[cfg(rpass2)]\n+    first_macro!();\n+}\n+\n+macro_rules! print_loc {\n+    () => {\n+        println!(\"Caller loc: {}\", std::panic::Location::caller());\n+    }\n+}\n+\n+#[rustc_clean(cfg=\"rpass2\")]\n+#[inline(always)]\n+pub fn unchanged_fn() {\n+    print_loc!();\n+}"}, {"sha": "8124141418bc3cfbe53396a658f9e5077fbccc84", "filename": "src/test/incremental/hygiene/load_cached_hygiene.rs", "status": "added", "additions": 48, "deletions": 0, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fincremental%2Fhygiene%2Fload_cached_hygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fincremental%2Fhygiene%2Fload_cached_hygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fhygiene%2Fload_cached_hygiene.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -0,0 +1,48 @@\n+// revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n+// aux-build:cached_hygiene.rs\n+\n+// This tests the folllowing scenario\n+// 1. A foreign crate is compiled with incremental compilation.\n+//    This causes hygiene information to be saved to the incr cache.\n+// 2. One function is the foreign crate is modified. This causes the\n+//    optimized mir for an unmodified function to be loaded from the\n+//    incremental cache and written out to the crate metadata.\n+// 3. In the process of loading and writing out this function's MIR,\n+//    we load hygiene information from the incremental cache and\n+//    write it to our metadata.\n+// 4. This hygiene information is loaded by another crate (this file)\n+\n+// Previously, this situation would cause hygiene identifiers\n+// (SyntaxContexts and ExpnIds) to get corrupted when we tried to\n+// serialize the hygiene information loaded from the incr cache into\n+// the metadata. Specifically, we were not resetting `orig_id`\n+// for an `EpxnData` generate in the current crate, which would cause\n+// us to serialize the `ExpnId` pointing to a garbage location in\n+// the metadata.\n+\n+#![feature(rustc_attrs)]\n+\n+#![rustc_partition_reused(module=\"load_cached_hygiene-call_unchanged_function\", cfg=\"rpass2\")]\n+#![rustc_partition_codegened(module=\"load_cached_hygiene-call_changed_function\", cfg=\"rpass2\")]\n+\n+\n+extern crate cached_hygiene;\n+\n+pub mod call_unchanged_function {\n+\n+    pub fn unchanged() {\n+        cached_hygiene::unchanged_fn();\n+    }\n+}\n+\n+pub mod call_changed_function {\n+    pub fn changed() {\n+        cached_hygiene::changed_fn();\n+    }\n+}\n+\n+pub fn main() {\n+    call_unchanged_function::unchanged();\n+    call_changed_function::changed();\n+}"}, {"sha": "3df6450fd3e1453b5ee79d8658a4fb3548d909a0", "filename": "src/test/ui/hygiene/auxiliary/needs_hygiene.rs", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fneeds_hygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fneeds_hygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fneeds_hygiene.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -0,0 +1,5 @@\n+#![feature(decl_macro)]\n+macro x() { struct MyStruct; }\n+\n+x!();\n+x!();"}, {"sha": "e5caa0f9cf80938dbfe59648599727840012a668", "filename": "src/test/ui/hygiene/auxiliary/nested-dollar-crate.rs", "status": "added", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fnested-dollar-crate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fnested-dollar-crate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fauxiliary%2Fnested-dollar-crate.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -0,0 +1,14 @@\n+pub const IN_DEF_CRATE: &str = \"In def crate!\";\n+\n+macro_rules! make_it {\n+    () => {\n+        #[macro_export]\n+        macro_rules! inner {\n+            () => {\n+                $crate::IN_DEF_CRATE\n+            }\n+        }\n+    }\n+}\n+\n+make_it!();"}, {"sha": "75742960b7e3ccafef7b7725be18502395658955", "filename": "src/test/ui/hygiene/cross_crate_hygiene.rs", "status": "added", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fcross_crate_hygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fcross_crate_hygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fcross_crate_hygiene.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -0,0 +1,8 @@\n+// check-pass\n+// aux-build:needs_hygiene.rs\n+\n+extern crate needs_hygiene;\n+\n+use needs_hygiene::*;\n+\n+fn main() {}"}, {"sha": "e8703bc77ee8b3175ed865764d76a9d3c5d02461", "filename": "src/test/ui/hygiene/nested-dollar-crate.rs", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fnested-dollar-crate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fnested-dollar-crate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fnested-dollar-crate.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -0,0 +1,9 @@\n+// aux-build:nested-dollar-crate.rs\n+// edition:2018\n+// run-pass\n+\n+extern crate nested_dollar_crate;\n+\n+fn main() {\n+    assert_eq!(nested_dollar_crate::inner!(), \"In def crate!\");\n+}"}, {"sha": "5cf169dfb141bdf68ac262e12b65e28f89ec441f", "filename": "src/test/ui/hygiene/panic-location.rs", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -0,0 +1,10 @@\n+// run-fail\n+// check-run-results\n+// exec-env:RUST_BACKTRACE=0\n+//\n+// Regression test for issue #70963\n+// The captured stderr from this test reports a location\n+// inside `VecDeque::with_capacity`, instead of `<::core::macros::panic macros>`\n+fn main() {\n+    std::collections::VecDeque::<String>::with_capacity(!0);\n+}"}, {"sha": "abdccf63b52f8c9c77e143829d094f1e453b4f02", "filename": "src/test/ui/hygiene/panic-location.run.stderr", "status": "added", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.run.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.run.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fhygiene%2Fpanic-location.run.stderr?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -0,0 +1,2 @@\n+thread 'main' panicked at 'capacity overflow', $SRC_DIR/liballoc/collections/vec_deque.rs:LL:COL\n+note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace"}, {"sha": "3c851b6de2a1ac8f624780246c37871dcce3da86", "filename": "src/test/ui/proc-macro/auxiliary/make-macro.rs", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fmake-macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fmake-macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fmake-macro.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -6,7 +6,13 @@ macro_rules! make_it {\n         #[proc_macro]\n         pub fn $name(input: TokenStream) -> TokenStream {\n             println!(\"Def site: {:?}\", Span::def_site());\n-            input\n+            println!(\"Input: {:?}\", input);\n+            let new: TokenStream = input.into_iter().map(|mut t| {\n+                t.set_span(Span::def_site());\n+                t\n+            }).collect();\n+            println!(\"Respanned: {:?}\", new);\n+            new\n         }\n     };\n }"}, {"sha": "0a9b9887d95535fd9ba4627ed12e1ce5ee1b86a1", "filename": "src/test/ui/proc-macro/auxiliary/meta-macro.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fmeta-macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fmeta-macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fmeta-macro.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -10,3 +10,6 @@ extern crate make_macro;\n use proc_macro::{TokenStream, Span};\n \n make_macro::make_it!(print_def_site);\n+\n+#[proc_macro]\n+pub fn dummy(input: TokenStream) -> TokenStream { input }"}, {"sha": "9ce90e42069fbd7820fd938fcb2733bbf79090ab", "filename": "src/test/ui/proc-macro/dollar-crate-issue-57089.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -5,6 +5,7 @@\n // Anonymize unstable non-dummy spans while still showing dummy spans `0..0`.\n // normalize-stdout-test \"bytes\\([^0]\\w*\\.\\.(\\w+)\\)\" -> \"bytes(LO..$1)\"\n // normalize-stdout-test \"bytes\\((\\w+)\\.\\.[^0]\\w*\\)\" -> \"bytes($1..HI)\"\n+// normalize-stdout-test \"#\\d+\" -> \"#CTXT\"\n \n #[macro_use]\n extern crate test_macros;"}, {"sha": "c36c75603876ddeadb17244f2436ba04fac2ada1", "filename": "src/test/ui/proc-macro/dollar-crate-issue-57089.stdout", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-57089.stdout?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -2,79 +2,79 @@ PRINT-BANG INPUT (DISPLAY): struct M($crate :: S) ;\n PRINT-BANG INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"M\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct A($crate :: S) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]"}, {"sha": "2a9ff4c20cdec9530b4481aab0d1c9726a1fab01", "filename": "src/test/ui/proc-macro/dollar-crate-issue-62325.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -6,6 +6,7 @@\n // Anonymize unstable non-dummy spans while still showing dummy spans `0..0`.\n // normalize-stdout-test \"bytes\\([^0]\\w*\\.\\.(\\w+)\\)\" -> \"bytes(LO..$1)\"\n // normalize-stdout-test \"bytes\\((\\w+)\\.\\.[^0]\\w*\\)\" -> \"bytes($1..HI)\"\n+// normalize-stdout-test \"#\\d+\" -> \"#CTXT\"\n \n #[macro_use]\n extern crate test_macros;"}, {"sha": "456940b89da2b04026afd0526e21748e00110bda", "filename": "src/test/ui/proc-macro/dollar-crate-issue-62325.stdout", "status": "modified", "additions": 22, "deletions": 22, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate-issue-62325.stdout?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -2,109 +2,109 @@ PRINT-ATTR INPUT (DISPLAY): struct A(identity ! ($crate :: S)) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"identity\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"$crate\",\n-                        span: #3 bytes(LO..HI),\n+                        span: #CTXT bytes(LO..HI),\n                     },\n                     Punct {\n                         ch: ':',\n                         spacing: Joint,\n-                        span: #3 bytes(LO..HI),\n+                        span: #CTXT bytes(LO..HI),\n                     },\n                     Punct {\n                         ch: ':',\n                         spacing: Alone,\n-                        span: #3 bytes(LO..HI),\n+                        span: #CTXT bytes(LO..HI),\n                     },\n                     Ident {\n                         ident: \"S\",\n-                        span: #3 bytes(LO..HI),\n+                        span: #CTXT bytes(LO..HI),\n                     },\n                 ],\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct B(identity ! ($crate :: S)) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #10 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"B\",\n-        span: #10 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"identity\",\n-                span: #10 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: #10 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"$crate\",\n-                        span: #10 bytes(LO..HI),\n+                        span: #CTXT bytes(LO..HI),\n                     },\n                     Punct {\n                         ch: ':',\n                         spacing: Joint,\n-                        span: #10 bytes(LO..HI),\n+                        span: #CTXT bytes(LO..HI),\n                     },\n                     Punct {\n                         ch: ':',\n                         spacing: Alone,\n-                        span: #10 bytes(LO..HI),\n+                        span: #CTXT bytes(LO..HI),\n                     },\n                     Ident {\n                         ident: \"S\",\n-                        span: #10 bytes(LO..HI),\n+                        span: #CTXT bytes(LO..HI),\n                     },\n                 ],\n-                span: #10 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #10 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #10 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]"}, {"sha": "1a5223d3d4190c24ae1be664cd39b8ffba625e13", "filename": "src/test/ui/proc-macro/dollar-crate.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -6,6 +6,7 @@\n // Anonymize unstable non-dummy spans while still showing dummy spans `0..0`.\n // normalize-stdout-test \"bytes\\([^0]\\w*\\.\\.(\\w+)\\)\" -> \"bytes(LO..$1)\"\n // normalize-stdout-test \"bytes\\((\\w+)\\.\\.[^0]\\w*\\)\" -> \"bytes($1..HI)\"\n+// normalize-stdout-test \"#\\d+\" -> \"#CTXT\"\n \n #[macro_use]\n extern crate test_macros;"}, {"sha": "deef102afb2d9faad8fc8623eb5e713f0645c1ff", "filename": "src/test/ui/proc-macro/dollar-crate.stdout", "status": "modified", "additions": 48, "deletions": 48, "changes": 96, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fdollar-crate.stdout?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -2,239 +2,239 @@ PRINT-BANG INPUT (DISPLAY): struct M($crate :: S) ;\n PRINT-BANG INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"M\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct A($crate :: S) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]\n PRINT-DERIVE INPUT (DISPLAY): struct D($crate :: S) ;\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"D\",\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #3 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #3 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]\n PRINT-BANG INPUT (DISPLAY): struct M($crate :: S) ;\n PRINT-BANG INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"M\",\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct A($crate :: S) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]\n PRINT-DERIVE INPUT (DISPLAY): struct D($crate :: S) ;\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Ident {\n         ident: \"D\",\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Ident {\n                 ident: \"$crate\",\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Joint,\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n             Ident {\n                 ident: \"S\",\n-                span: #13 bytes(LO..HI),\n+                span: #CTXT bytes(LO..HI),\n             },\n         ],\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #13 bytes(LO..HI),\n+        span: #CTXT bytes(LO..HI),\n     },\n ]"}, {"sha": "41c829d9d889945bdef0227c3065ed767823b89a", "filename": "src/test/ui/proc-macro/input-interpolated.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -1,6 +1,7 @@\n // Check what token streams proc macros see when interpolated tokens are passed to them as input.\n \n // check-pass\n+// normalize-stdout-test \"#\\d+\" -> \"#CTXT\"\n // aux-build:test-macros.rs\n \n #[macro_use]"}, {"sha": "d98f52249a7812d837f077a7f25032d012fac089", "filename": "src/test/ui/proc-macro/input-interpolated.stdout", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Finput-interpolated.stdout?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -5,61 +5,61 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         stream: TokenStream [\n             Ident {\n                 ident: \"A\",\n-                span: #0 bytes(402..403),\n+                span: #CTXT bytes(445..446),\n             },\n         ],\n-        span: #3 bytes(269..271),\n+        span: #CTXT bytes(312..314),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): const A : u8 = 0 ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"const\",\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n     Punct {\n         ch: ':',\n         spacing: Alone,\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n     Ident {\n         ident: \"u8\",\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n     Punct {\n         ch: '=',\n         spacing: Alone,\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n     Literal {\n         kind: Integer,\n         symbol: \"0\",\n         suffix: None,\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n ]\n PRINT-DERIVE INPUT (DISPLAY): struct A { }\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n     Ident {\n         ident: \"A\",\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [],\n-        span: #0 bytes(0..0),\n+        span: #CTXT bytes(0..0),\n     },\n ]"}, {"sha": "4b1787453cb55c6609d675ab4651fc21dff8adba", "filename": "src/test/ui/proc-macro/meta-macro-hygiene.rs", "status": "modified", "additions": 16, "deletions": 3, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -1,13 +1,26 @@\n // aux-build:make-macro.rs\n // aux-build:meta-macro.rs\n // edition:2018\n-// compile-flags: -Z span-debug -Z unpretty=expanded,hygiene\n+// compile-flags: -Z span-debug -Z macro-backtrace\n // check-pass\n+// normalize-stdout-test \"#\\d+\" -> \"#CTXT\"\n // normalize-stdout-test \"\\d+#\" -> \"0#\"\n-// ^ We don't care about symbol ids, so set them all to 0\n+//\n+// We don't care about symbol ids, so we set them all to 0\n // in the stdout\n extern crate meta_macro;\n \n+macro_rules! produce_it {\n+    () => {\n+        // `print_def_site!` will respan the `$crate` identifier\n+        // with `Span::def_site()`. This should cause it to resolve\n+        // relative to `meta_macro`, *not* `make_macro` (despite\n+        // the fact that that `print_def_site` is produced by\n+        // a `macro_rules!` macro in `make_macro`).\n+        meta_macro::print_def_site!($crate::dummy!());\n+    }\n+}\n+\n fn main() {\n-    meta_macro::print_def_site!();\n+    produce_it!();\n }"}, {"sha": "e162bdd7fc090594f60006c972d7d37e80b517fc", "filename": "src/test/ui/proc-macro/meta-macro-hygiene.stdout", "status": "modified", "additions": 3, "deletions": 32, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro-hygiene.stdout?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -1,32 +1,3 @@\n-Def site: $DIR/auxiliary/make-macro.rs:7:9: 10:10 (#3)\n-#![feature /* 0#0 */(prelude_import)]\n-#[prelude_import /* 0#1 */]\n-use std /* 0#1 */::prelude /* 0#1 */::v1 /* 0#1 */::*;\n-#[macro_use /* 0#1 */]\n-extern crate std /* 0#1 */;\n-// aux-build:make-macro.rs\n-// aux-build:meta-macro.rs\n-// edition:2018\n-// compile-flags: -Z span-debug -Z unpretty=expanded,hygiene\n-// check-pass\n-// normalize-stdout-test \"\\d+#\" -> \"0#\"\n-// ^ We don't care about symbol ids, so set them all to 0\n-// in the stdout\n-extern crate meta_macro /* 0#0 */;\n-\n-fn main /* 0#0 */() { }\n-\n-/*\n-Expansions:\n-0: parent: ExpnId(0), call_site_ctxt: #0, def_site_ctxt: #0, kind: Root\n-1: parent: ExpnId(0), call_site_ctxt: #0, def_site_ctxt: #0, kind: AstPass(StdImports)\n-2: parent: ExpnId(0), call_site_ctxt: #0, def_site_ctxt: #0, kind: Macro(Bang, \"meta_macro::print_def_site\")\n-\n-SyntaxContexts:\n-#0: parent: #0, outer_mark: (ExpnId(0), Opaque)\n-#1: parent: #0, outer_mark: (ExpnId(1), Opaque)\n-#2: parent: #0, outer_mark: (ExpnId(1), Transparent)\n-#3: parent: #0, outer_mark: (ExpnId(2), Opaque)\n-#4: parent: #0, outer_mark: (ExpnId(2), Transparent)\n-#5: parent: #0, outer_mark: (ExpnId(2), SemiTransparent)\n-*/\n+Def site: $DIR/auxiliary/make-macro.rs:7:9: 16:10 (#CTXT)\n+Input: TokenStream [Ident { ident: \"$crate\", span: $DIR/meta-macro-hygiene.rs:20:37: 20:43 (#CTXT) }, Punct { ch: ':', spacing: Joint, span: $DIR/meta-macro-hygiene.rs:20:43: 20:45 (#CTXT) }, Punct { ch: ':', spacing: Alone, span: $DIR/meta-macro-hygiene.rs:20:43: 20:45 (#CTXT) }, Ident { ident: \"dummy\", span: $DIR/meta-macro-hygiene.rs:20:45: 20:50 (#CTXT) }, Punct { ch: '!', spacing: Alone, span: $DIR/meta-macro-hygiene.rs:20:50: 20:51 (#CTXT) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: $DIR/meta-macro-hygiene.rs:20:51: 20:53 (#CTXT) }]\n+Respanned: TokenStream [Ident { ident: \"$crate\", span: $DIR/auxiliary/make-macro.rs:7:9: 16:10 (#CTXT) }, Punct { ch: ':', spacing: Joint, span: $DIR/auxiliary/make-macro.rs:7:9: 16:10 (#CTXT) }, Punct { ch: ':', spacing: Alone, span: $DIR/auxiliary/make-macro.rs:7:9: 16:10 (#CTXT) }, Ident { ident: \"dummy\", span: $DIR/auxiliary/make-macro.rs:7:9: 16:10 (#CTXT) }, Punct { ch: '!', spacing: Alone, span: $DIR/auxiliary/make-macro.rs:7:9: 16:10 (#CTXT) }, Group { delimiter: Parenthesis, stream: TokenStream [], span: $DIR/auxiliary/make-macro.rs:7:9: 16:10 (#CTXT) }]"}, {"sha": "579e232c0d92beb64b22619cc16fbc1ed97cef04", "filename": "src/test/ui/proc-macro/meta-macro.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -2,6 +2,7 @@\n // aux-build:meta-macro.rs\n // edition:2018\n // compile-flags: -Z span-debug\n+// normalize-stdout-test \"#\\d+\" -> \"#CTXT\"\n // run-pass\n \n extern crate meta_macro;"}, {"sha": "a9847a25d9273df411e8f47b084d2834529ef07e", "filename": "src/test/ui/proc-macro/meta-macro.stdout", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fmeta-macro.stdout?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -1 +1,3 @@\n-Def site: $DIR/auxiliary/make-macro.rs:7:9: 10:10 (#3)\n+Def site: $DIR/auxiliary/make-macro.rs:7:9: 16:10 (#CTXT)\n+Input: TokenStream []\n+Respanned: TokenStream []"}, {"sha": "62c3dd84ce1a4b4172ef8df8a4e28178471344c1", "filename": "src/test/ui/proc-macro/nested-macro-rules.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -2,6 +2,7 @@\n // aux-build:nested-macro-rules.rs\n // aux-build:test-macros.rs\n // compile-flags: -Z span-debug\n+// normalize-stdout-test \"#\\d+\" -> \"#CTXT\"\n // edition:2018\n \n extern crate nested_macro_rules;"}, {"sha": "337b9863def1b0c5b00e7fa7877aeb0bd699f58b", "filename": "src/test/ui/proc-macro/nested-macro-rules.stdout", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fnested-macro-rules.stdout?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -5,10 +5,10 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         stream: TokenStream [\n             Ident {\n                 ident: \"FirstStruct\",\n-                span: $DIR/auxiliary/nested-macro-rules.rs:15:14: 15:25 (#3),\n+                span: $DIR/auxiliary/nested-macro-rules.rs:15:14: 15:25 (#CTXT),\n             },\n         ],\n-        span: $DIR/auxiliary/nested-macro-rules.rs:9:27: 9:32 (#3),\n+        span: $DIR/auxiliary/nested-macro-rules.rs:9:27: 9:32 (#CTXT),\n     },\n ]\n PRINT-BANG INPUT (DISPLAY): SecondStruct\n@@ -18,9 +18,9 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         stream: TokenStream [\n             Ident {\n                 ident: \"SecondStruct\",\n-                span: $DIR/nested-macro-rules.rs:18:38: 18:50 (#9),\n+                span: $DIR/nested-macro-rules.rs:19:38: 19:50 (#CTXT),\n             },\n         ],\n-        span: $DIR/auxiliary/nested-macro-rules.rs:9:27: 9:32 (#8),\n+        span: $DIR/auxiliary/nested-macro-rules.rs:9:27: 9:32 (#CTXT),\n     },\n ]"}, {"sha": "1dc8796de90f9df7ac62bda677f20df004923cfe", "filename": "src/test/ui/proc-macro/nodelim-groups.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.rs?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -1,6 +1,7 @@\n // run-pass\n // aux-build:test-macros.rs\n // compile-flags: -Z span-debug\n+// normalize-stdout-test \"#\\d+\" -> \"#CTXT\"\n // edition:2018\n //\n // Tests the pretty-printing behavior of inserting `NoDelim` groups"}, {"sha": "79cdf2b53b52e8481cf28af9e5891bf61d0f89ab", "filename": "src/test/ui/proc-macro/nodelim-groups.stdout", "status": "modified", "additions": 27, "deletions": 27, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/fa36f960687c41caf5b260ab7610ebd83a7860dd/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fnodelim-groups.stdout?ref=fa36f960687c41caf5b260ab7610ebd83a7860dd", "patch": "@@ -4,7 +4,7 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         kind: Str,\n         symbol: \"hi\",\n         suffix: None,\n-        span: $DIR/nodelim-groups.rs:13:42: 13:46 (#3),\n+        span: $DIR/nodelim-groups.rs:14:42: 14:46 (#CTXT),\n     },\n     Group {\n         delimiter: None,\n@@ -13,12 +13,12 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:17:16: 17:17 (#0),\n+                span: $DIR/nodelim-groups.rs:18:16: 18:17 (#CTXT),\n             },\n             Punct {\n                 ch: '+',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:17:18: 17:19 (#0),\n+                span: $DIR/nodelim-groups.rs:18:18: 18:19 (#CTXT),\n             },\n             Group {\n                 delimiter: Parenthesis,\n@@ -27,24 +27,24 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                         kind: Integer,\n                         symbol: \"25\",\n                         suffix: None,\n-                        span: $DIR/nodelim-groups.rs:17:21: 17:23 (#0),\n+                        span: $DIR/nodelim-groups.rs:18:21: 18:23 (#CTXT),\n                     },\n                 ],\n-                span: $DIR/nodelim-groups.rs:17:20: 17:24 (#0),\n+                span: $DIR/nodelim-groups.rs:18:20: 18:24 (#CTXT),\n             },\n             Punct {\n                 ch: '+',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:17:25: 17:26 (#0),\n+                span: $DIR/nodelim-groups.rs:18:25: 18:26 (#CTXT),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:17:27: 17:28 (#0),\n+                span: $DIR/nodelim-groups.rs:18:27: 18:28 (#CTXT),\n             },\n         ],\n-        span: $DIR/nodelim-groups.rs:13:47: 13:51 (#3),\n+        span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n     },\n     Group {\n         delimiter: Parenthesis,\n@@ -53,21 +53,21 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:53: 13:54 (#3),\n+                span: $DIR/nodelim-groups.rs:14:53: 14:54 (#CTXT),\n             },\n             Punct {\n                 ch: '+',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:55: 13:56 (#3),\n+                span: $DIR/nodelim-groups.rs:14:55: 14:56 (#CTXT),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:57: 13:58 (#3),\n+                span: $DIR/nodelim-groups.rs:14:57: 14:58 (#CTXT),\n             },\n         ],\n-        span: $DIR/nodelim-groups.rs:13:52: 13:59 (#3),\n+        span: $DIR/nodelim-groups.rs:14:52: 14:59 (#CTXT),\n     },\n ]\n PRINT-BANG INPUT (DISPLAY): \"hi\" \"hello\".len() + \"world\".len() (1 + 1)\n@@ -77,7 +77,7 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n         kind: Str,\n         symbol: \"hi\",\n         suffix: None,\n-        span: $DIR/nodelim-groups.rs:13:42: 13:46 (#8),\n+        span: $DIR/nodelim-groups.rs:14:42: 14:46 (#CTXT),\n     },\n     Group {\n         delimiter: None,\n@@ -86,49 +86,49 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 kind: Str,\n                 symbol: \"hello\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n             Punct {\n                 ch: '.',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n             Ident {\n                 ident: \"len\",\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [],\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n             Punct {\n                 ch: '+',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n             Literal {\n                 kind: Str,\n                 symbol: \"world\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n             Punct {\n                 ch: '.',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n             Ident {\n                 ident: \"len\",\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [],\n-                span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+                span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n             },\n         ],\n-        span: $DIR/nodelim-groups.rs:13:47: 13:51 (#8),\n+        span: $DIR/nodelim-groups.rs:14:47: 14:51 (#CTXT),\n     },\n     Group {\n         delimiter: Parenthesis,\n@@ -137,20 +137,20 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:53: 13:54 (#8),\n+                span: $DIR/nodelim-groups.rs:14:53: 14:54 (#CTXT),\n             },\n             Punct {\n                 ch: '+',\n                 spacing: Alone,\n-                span: $DIR/nodelim-groups.rs:13:55: 13:56 (#8),\n+                span: $DIR/nodelim-groups.rs:14:55: 14:56 (#CTXT),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/nodelim-groups.rs:13:57: 13:58 (#8),\n+                span: $DIR/nodelim-groups.rs:14:57: 14:58 (#CTXT),\n             },\n         ],\n-        span: $DIR/nodelim-groups.rs:13:52: 13:59 (#8),\n+        span: $DIR/nodelim-groups.rs:14:52: 14:59 (#CTXT),\n     },\n ]"}]}