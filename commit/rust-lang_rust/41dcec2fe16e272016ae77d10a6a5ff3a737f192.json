{"sha": "41dcec2fe16e272016ae77d10a6a5ff3a737f192", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQxZGNlYzJmZTE2ZTI3MjAxNmFlNzdkMTBhNmE1ZmYzYTczN2YxOTI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-07-10T01:28:46Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-07-10T01:28:46Z"}, "message": "auto merge of #7265 : brson/rust/io-upstream, r=brson\n\nr? @graydon, @nikomatsakis, @pcwalton, or @catamorphism\r\n\r\nSorry this is so huge, but it's been accumulating for about a month. There's lots of stuff here, mostly oriented toward enabling multithreaded scheduling and improving compatibility between the old and new runtimes. Adds task pinning so that we can create the 'platform thread' in servo.\r\n\r\n[Here](https://github.com/brson/rust/blob/e1555f9b5628af2b6c6ed344cad621399cb7684d/src/libstd/rt/mod.rs#L201) is the current runtime setup code.\r\n\r\nAbout half of this has already been reviewed.", "tree": {"sha": "6eebc49e7033a0d696c93c8e23d7caeb28d4eca1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6eebc49e7033a0d696c93c8e23d7caeb28d4eca1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/41dcec2fe16e272016ae77d10a6a5ff3a737f192", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/41dcec2fe16e272016ae77d10a6a5ff3a737f192", "html_url": "https://github.com/rust-lang/rust/commit/41dcec2fe16e272016ae77d10a6a5ff3a737f192", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/41dcec2fe16e272016ae77d10a6a5ff3a737f192/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "137d1fb210a844a76f89d7355a1aaf9f7a88af33", "url": "https://api.github.com/repos/rust-lang/rust/commits/137d1fb210a844a76f89d7355a1aaf9f7a88af33", "html_url": "https://github.com/rust-lang/rust/commit/137d1fb210a844a76f89d7355a1aaf9f7a88af33"}, {"sha": "413d51e32debf0c3f7dda2434b64d73585df21ef", "url": "https://api.github.com/repos/rust-lang/rust/commits/413d51e32debf0c3f7dda2434b64d73585df21ef", "html_url": "https://github.com/rust-lang/rust/commit/413d51e32debf0c3f7dda2434b64d73585df21ef"}], "stats": {"total": 7735, "additions": 5646, "deletions": 2089}, "files": [{"sha": "1c6e2a25c01b7298d5c40d65c5747b66c33dd076", "filename": "src/libextra/test.rs", "status": "modified", "additions": 4, "deletions": 13, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibextra%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibextra%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Ftest.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -36,14 +36,6 @@ use std::u64;\n use std::uint;\n use std::vec;\n \n-pub mod rustrt {\n-    use std::libc::size_t;\n-\n-    #[abi = \"cdecl\"]\n-    pub extern {\n-        pub unsafe fn rust_sched_threads() -> size_t;\n-    }\n-}\n \n // The name of a test. By convention this follows the rules for rust\n // paths; i.e. it should be a series of identifiers separated by double\n@@ -493,11 +485,10 @@ static SCHED_OVERCOMMIT : uint = 1;\n static SCHED_OVERCOMMIT : uint = 4u;\n \n fn get_concurrency() -> uint {\n-    unsafe {\n-        let threads = rustrt::rust_sched_threads() as uint;\n-        if threads == 1 { 1 }\n-        else { threads * SCHED_OVERCOMMIT }\n-    }\n+    use std::rt;\n+    let threads = rt::util::default_sched_threads();\n+    if threads == 1 { 1 }\n+    else { threads * SCHED_OVERCOMMIT }\n }\n \n #[allow(non_implicitly_copyable_typarams)]"}, {"sha": "dfd39af093d96df0ad4e638203d80942d816d626", "filename": "src/libstd/at_vec.rs", "status": "modified", "additions": 48, "deletions": 26, "changes": 74, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fat_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fat_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fat_vec.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -22,23 +22,6 @@ use vec::{ImmutableVector, OwnedVector};\n /// Code for dealing with @-vectors. This is pretty incomplete, and\n /// contains a bunch of duplication from the code for ~-vectors.\n \n-pub mod rustrt {\n-    use libc;\n-    use vec;\n-    #[cfg(stage0)]\n-    use intrinsic::{TyDesc};\n-    #[cfg(not(stage0))]\n-    use unstable::intrinsics::{TyDesc};\n-\n-    #[abi = \"cdecl\"]\n-    #[link_name = \"rustrt\"]\n-    pub extern {\n-        pub unsafe fn vec_reserve_shared_actual(t: *TyDesc,\n-                                                v: **vec::raw::VecRepr,\n-                                                n: libc::size_t);\n-    }\n-}\n-\n /// Returns the number of elements the vector can hold without reallocating\n #[inline]\n pub fn capacity<T>(v: @[T]) -> uint {\n@@ -192,18 +175,17 @@ pub mod traits {\n pub mod traits {}\n \n pub mod raw {\n-    use at_vec::{capacity, rustrt};\n+    use at_vec::capacity;\n+    use cast;\n     use cast::{transmute, transmute_copy};\n     use libc;\n     use ptr;\n     use sys;\n     use uint;\n-    use unstable::intrinsics::{move_val_init};\n+    use unstable::intrinsics;\n+    use unstable::intrinsics::{move_val_init, TyDesc};\n     use vec;\n-    #[cfg(stage0)]\n-    use intrinsic::{get_tydesc};\n-    #[cfg(not(stage0))]\n-    use unstable::intrinsics::{get_tydesc};\n+    use vec::UnboxedVecRepr;\n \n     pub type VecRepr = vec::raw::VecRepr;\n     pub type SliceRepr = vec::raw::SliceRepr;\n@@ -264,9 +246,49 @@ pub mod raw {\n     pub unsafe fn reserve<T>(v: &mut @[T], n: uint) {\n         // Only make the (slow) call into the runtime if we have to\n         if capacity(*v) < n {\n-            let ptr: **VecRepr = transmute(v);\n-            rustrt::vec_reserve_shared_actual(get_tydesc::<T>(),\n-                                              ptr, n as libc::size_t);\n+            let ptr: *mut *mut VecRepr = transmute(v);\n+            let ty = intrinsics::get_tydesc::<T>();\n+            // XXX transmute shouldn't be necessary\n+            let ty = cast::transmute(ty);\n+            return reserve_raw(ty, ptr, n);\n+        }\n+    }\n+\n+    // Implementation detail. Shouldn't be public\n+    #[allow(missing_doc)]\n+    pub fn reserve_raw(ty: *TyDesc, ptr: *mut *mut VecRepr, n: uint) {\n+\n+        unsafe {\n+            let size_in_bytes = n * (*ty).size;\n+            if size_in_bytes > (**ptr).unboxed.alloc {\n+                let total_size = size_in_bytes + sys::size_of::<UnboxedVecRepr>();\n+                // XXX: UnboxedVecRepr has an extra u8 at the end\n+                let total_size = total_size - sys::size_of::<u8>();\n+                (*ptr) = local_realloc(*ptr as *(), total_size) as *mut VecRepr;\n+                (**ptr).unboxed.alloc = size_in_bytes;\n+            }\n+        }\n+\n+        fn local_realloc(ptr: *(), size: uint) -> *() {\n+            use rt;\n+            use rt::OldTaskContext;\n+            use rt::local::Local;\n+            use rt::task::Task;\n+\n+            if rt::context() == OldTaskContext {\n+                unsafe {\n+                    return rust_local_realloc(ptr, size as libc::size_t);\n+                }\n+\n+                extern {\n+                    #[fast_ffi]\n+                    fn rust_local_realloc(ptr: *(), size: libc::size_t) -> *();\n+                }\n+            } else {\n+                do Local::borrow::<Task, *()> |task| {\n+                    task.heap.realloc(ptr as *libc::c_void, size) as *()\n+                }\n+            }\n         }\n     }\n "}, {"sha": "abda76c9ca66054c10c11967e1168fc91b2c56af", "filename": "src/libstd/cleanup.rs", "status": "modified", "additions": 15, "deletions": 102, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fcleanup.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fcleanup.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcleanup.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -10,105 +10,13 @@\n \n #[doc(hidden)];\n \n-use libc::{c_char, intptr_t, uintptr_t};\n+use libc::c_void;\n use ptr::{mut_null};\n use repr::BoxRepr;\n use cast::transmute;\n use unstable::intrinsics::TyDesc;\n-#[cfg(not(test))] use unstable::lang::clear_task_borrow_list;\n \n-/**\n- * Runtime structures\n- *\n- * NB: These must match the representation in the C++ runtime.\n- */\n-\n-type TaskID = uintptr_t;\n-\n-struct StackSegment { priv opaque: () }\n-struct Scheduler { priv opaque: () }\n-struct SchedulerLoop { priv opaque: () }\n-struct Kernel { priv opaque: () }\n-struct Env { priv opaque: () }\n-struct AllocHeader { priv opaque: () }\n-struct MemoryRegion { priv opaque: () }\n-\n-#[cfg(target_arch=\"x86\")]\n-struct Registers {\n-    data: [u32, ..16]\n-}\n-\n-#[cfg(target_arch=\"arm\")]\n-#[cfg(target_arch=\"mips\")]\n-struct Registers {\n-    data: [u32, ..32]\n-}\n-\n-#[cfg(target_arch=\"x86\")]\n-#[cfg(target_arch=\"arm\")]\n-#[cfg(target_arch=\"mips\")]\n-struct Context {\n-    regs: Registers,\n-    next: *Context,\n-    pad: [u32, ..3]\n-}\n-\n-#[cfg(target_arch=\"x86_64\")]\n-struct Registers {\n-    data: [u64, ..22]\n-}\n-\n-#[cfg(target_arch=\"x86_64\")]\n-struct Context {\n-    regs: Registers,\n-    next: *Context,\n-    pad: uintptr_t\n-}\n-\n-struct BoxedRegion {\n-    env: *Env,\n-    backing_region: *MemoryRegion,\n-    live_allocs: *BoxRepr\n-}\n-\n-#[cfg(target_arch=\"x86\")]\n-#[cfg(target_arch=\"arm\")]\n-#[cfg(target_arch=\"mips\")]\n-struct Task {\n-    // Public fields\n-    refcount: intptr_t,                 // 0\n-    id: TaskID,                         // 4\n-    pad: [u32, ..2],                    // 8\n-    ctx: Context,                       // 16\n-    stack_segment: *StackSegment,       // 96\n-    runtime_sp: uintptr_t,              // 100\n-    scheduler: *Scheduler,              // 104\n-    scheduler_loop: *SchedulerLoop,     // 108\n-\n-    // Fields known only to the runtime\n-    kernel: *Kernel,                    // 112\n-    name: *c_char,                      // 116\n-    list_index: i32,                    // 120\n-    boxed_region: BoxedRegion           // 128\n-}\n-\n-#[cfg(target_arch=\"x86_64\")]\n-struct Task {\n-    // Public fields\n-    refcount: intptr_t,\n-    id: TaskID,\n-    ctx: Context,\n-    stack_segment: *StackSegment,\n-    runtime_sp: uintptr_t,\n-    scheduler: *Scheduler,\n-    scheduler_loop: *SchedulerLoop,\n-\n-    // Fields known only to the runtime\n-    kernel: *Kernel,\n-    name: *c_char,\n-    list_index: i32,\n-    boxed_region: BoxedRegion\n-}\n+type DropGlue<'self> = &'self fn(**TyDesc, *c_void);\n \n /*\n  * Box annihilation\n@@ -127,9 +35,9 @@ unsafe fn each_live_alloc(read_next_before: bool,\n     //! Walks the internal list of allocations\n \n     use managed;\n+    use rt::local_heap;\n \n-    let task: *Task = transmute(rustrt::rust_get_task());\n-    let box = (*task).boxed_region.live_allocs;\n+    let box = local_heap::live_allocs();\n     let mut box: *mut BoxRepr = transmute(copy box);\n     while box != mut_null() {\n         let next_before = transmute(copy (*box).header.next);\n@@ -151,7 +59,13 @@ unsafe fn each_live_alloc(read_next_before: bool,\n \n #[cfg(unix)]\n fn debug_mem() -> bool {\n-    ::rt::env::get().debug_mem\n+    use rt;\n+    use rt::OldTaskContext;\n+    // XXX: Need to port the environment struct to newsched\n+    match rt::context() {\n+        OldTaskContext => ::rt::env::get().debug_mem,\n+        _ => false\n+    }\n }\n \n #[cfg(windows)]\n@@ -173,13 +87,12 @@ unsafe fn call_drop_glue(tydesc: *TyDesc, data: *i8) {\n }\n \n /// Destroys all managed memory (i.e. @ boxes) held by the current task.\n-#[cfg(not(test))]\n-#[lang=\"annihilate\"]\n pub unsafe fn annihilate() {\n-    use unstable::lang::local_free;\n+    use rt::local_heap::local_free;\n     use io::WriterUtil;\n     use io;\n     use libc;\n+    use rt::borrowck;\n     use sys;\n     use managed;\n \n@@ -191,7 +104,7 @@ pub unsafe fn annihilate() {\n \n     // Quick hack: we need to free this list upon task exit, and this\n     // is a convenient place to do it.\n-    clear_task_borrow_list();\n+    borrowck::clear_task_borrow_list();\n \n     // Pass 1: Make all boxes immortal.\n     //\n@@ -213,7 +126,7 @@ pub unsafe fn annihilate() {\n     // callback, as the original value may have been freed.\n     for each_live_alloc(false) |box, uniq| {\n         if !uniq {\n-            let tydesc = (*box).header.type_desc;\n+            let tydesc: *TyDesc = transmute(copy (*box).header.type_desc);\n             let data = transmute(&(*box).data);\n             call_drop_glue(tydesc, data);\n         }"}, {"sha": "1bb0ff044fe980f5b927994daad399bac2968266", "filename": "src/libstd/comm.rs", "status": "modified", "additions": 25, "deletions": 15, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fcomm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fcomm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -220,48 +220,58 @@ impl<T: Send> Peekable<T> for PortSet<T> {\n \n /// A channel that can be shared between many senders.\n pub struct SharedChan<T> {\n-    ch: Exclusive<pipesy::Chan<T>>\n+    inner: Either<Exclusive<pipesy::Chan<T>>, rtcomm::SharedChan<T>>\n }\n \n impl<T: Send> SharedChan<T> {\n     /// Converts a `chan` into a `shared_chan`.\n     pub fn new(c: Chan<T>) -> SharedChan<T> {\n         let Chan { inner } = c;\n         let c = match inner {\n-            Left(c) => c,\n-            Right(_) => fail!(\"SharedChan not implemented\")\n+            Left(c) => Left(exclusive(c)),\n+            Right(c) => Right(rtcomm::SharedChan::new(c))\n         };\n-        SharedChan { ch: exclusive(c) }\n+        SharedChan { inner: c }\n     }\n }\n \n impl<T: Send> GenericChan<T> for SharedChan<T> {\n     fn send(&self, x: T) {\n-        unsafe {\n-            let mut xx = Some(x);\n-            do self.ch.with_imm |chan| {\n-                let x = replace(&mut xx, None);\n-                chan.send(x.unwrap())\n+        match self.inner {\n+            Left(ref chan) => {\n+                unsafe {\n+                    let mut xx = Some(x);\n+                    do chan.with_imm |chan| {\n+                        let x = replace(&mut xx, None);\n+                        chan.send(x.unwrap())\n+                    }\n+                }\n             }\n+            Right(ref chan) => chan.send(x)\n         }\n     }\n }\n \n impl<T: Send> GenericSmartChan<T> for SharedChan<T> {\n     fn try_send(&self, x: T) -> bool {\n-        unsafe {\n-            let mut xx = Some(x);\n-            do self.ch.with_imm |chan| {\n-                let x = replace(&mut xx, None);\n-                chan.try_send(x.unwrap())\n+        match self.inner {\n+            Left(ref chan) => {\n+                unsafe {\n+                    let mut xx = Some(x);\n+                    do chan.with_imm |chan| {\n+                        let x = replace(&mut xx, None);\n+                        chan.try_send(x.unwrap())\n+                    }\n+                }\n             }\n+            Right(ref chan) => chan.try_send(x)\n         }\n     }\n }\n \n impl<T: Send> ::clone::Clone for SharedChan<T> {\n     fn clone(&self) -> SharedChan<T> {\n-        SharedChan { ch: self.ch.clone() }\n+        SharedChan { inner: self.inner.clone() }\n     }\n }\n "}, {"sha": "743b71e33ea802538f05886227f53a0ec8d28ab6", "filename": "src/libstd/logging.rs", "status": "modified", "additions": 20, "deletions": 4, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Flogging.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Flogging.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Flogging.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -11,13 +11,20 @@\n //! Logging\n \n use option::*;\n+use os;\n use either::*;\n+use rt;\n+use rt::OldTaskContext;\n use rt::logging::{Logger, StdErrLogger};\n \n /// Turns on logging to stdout globally\n pub fn console_on() {\n-    unsafe {\n-        rustrt::rust_log_console_on();\n+    if rt::context() == OldTaskContext {\n+        unsafe {\n+            rustrt::rust_log_console_on();\n+        }\n+    } else {\n+        rt::logging::console_on();\n     }\n }\n \n@@ -29,8 +36,17 @@ pub fn console_on() {\n  * the RUST_LOG environment variable\n  */\n pub fn console_off() {\n-    unsafe {\n-        rustrt::rust_log_console_off();\n+    // If RUST_LOG is set then the console can't be turned off\n+    if os::getenv(\"RUST_LOG\").is_some() {\n+        return;\n+    }\n+\n+    if rt::context() == OldTaskContext {\n+        unsafe {\n+            rustrt::rust_log_console_off();\n+        }\n+    } else {\n+        rt::logging::console_off();\n     }\n }\n "}, {"sha": "7748c43efcd28b7eddf8fd356061d9e4f2c0a715", "filename": "src/libstd/macros.rs", "status": "modified", "additions": 12, "deletions": 20, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fmacros.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -10,18 +10,16 @@\n \n #[macro_escape];\n \n+macro_rules! rterrln (\n+    ($( $arg:expr),+) => ( {\n+        ::rt::util::dumb_println(fmt!( $($arg),+ ));\n+    } )\n+)\n+\n // Some basic logging\n macro_rules! rtdebug_ (\n     ($( $arg:expr),+) => ( {\n-        dumb_println(fmt!( $($arg),+ ));\n-\n-        fn dumb_println(s: &str) {\n-            use io::WriterUtil;\n-            let dbg = ::libc::STDERR_FILENO as ::io::fd_t;\n-            dbg.write_str(s);\n-            dbg.write_str(\"\\n\");\n-        }\n-\n+        rterrln!( $($arg),+ )\n     } )\n )\n \n@@ -33,21 +31,15 @@ macro_rules! rtdebug (\n macro_rules! rtassert (\n     ( $arg:expr ) => ( {\n         if !$arg {\n-            abort!(\"assertion failed: %s\", stringify!($arg));\n+            rtabort!(\"assertion failed: %s\", stringify!($arg));\n         }\n     } )\n )\n \n-macro_rules! abort(\n-    ($( $msg:expr),+) => ( {\n-        rtdebug!($($msg),+);\n-\n-        do_abort();\n \n-        // NB: This is in a fn to avoid putting the `unsafe` block in a macro,\n-        // which causes spurious 'unnecessary unsafe block' warnings.\n-        fn do_abort() -> ! {\n-            unsafe { ::libc::abort(); }\n-        }\n+macro_rules! rtabort(\n+    ($( $msg:expr),+) => ( {\n+        ::rt::util::abort(fmt!($($msg),+));\n     } )\n )\n+"}, {"sha": "fc7f2742470b9d652170d226d59856e6ea59e722", "filename": "src/libstd/os.rs", "status": "modified", "additions": 24, "deletions": 6, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fos.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fos.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fos.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -741,6 +741,7 @@ pub fn list_dir(p: &Path) -> ~[~str] {\n                 as_utf16_p\n             };\n             use rt::global_heap::malloc_raw;\n+\n             #[nolink]\n             extern {\n                 unsafe fn rust_list_dir_wfd_size() -> libc::size_t;\n@@ -1134,8 +1135,15 @@ pub fn last_os_error() -> ~str {\n  * ignored and the process exits with the default failure status\n  */\n pub fn set_exit_status(code: int) {\n-    unsafe {\n-        rustrt::rust_set_exit_status(code as libc::intptr_t);\n+    use rt;\n+    use rt::OldTaskContext;\n+\n+    if rt::context() == OldTaskContext {\n+        unsafe {\n+            rustrt::rust_set_exit_status(code as libc::intptr_t);\n+        }\n+    } else {\n+        rt::util::set_exit_status(code);\n     }\n }\n \n@@ -1165,10 +1173,20 @@ pub fn real_args() -> ~[~str] {\n #[cfg(target_os = \"android\")]\n #[cfg(target_os = \"freebsd\")]\n pub fn real_args() -> ~[~str] {\n-    unsafe {\n-        let argc = rustrt::rust_get_argc();\n-        let argv = rustrt::rust_get_argv();\n-        load_argc_and_argv(argc, argv)\n+    use rt;\n+    use rt::TaskContext;\n+\n+    if rt::context() == TaskContext {\n+        match rt::args::clone() {\n+            Some(args) => args,\n+            None => fail!(\"process arguments not initialized\")\n+        }\n+    } else {\n+        unsafe {\n+            let argc = rustrt::rust_get_argc();\n+            let argv = rustrt::rust_get_argv();\n+            load_argc_and_argv(argc, argv)\n+        }\n     }\n }\n "}, {"sha": "75ee4f381f6ef6c454f8f351cf670c6f16812570", "filename": "src/libstd/rt/args.rs", "status": "added", "additions": 125, "deletions": 0, "changes": 125, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fargs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fargs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fargs.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -0,0 +1,125 @@\n+// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! Global storage for command line arguments\n+//!\n+//! The current incarnation of the Rust runtime expects for\n+//! the processes `argc` and `argv` arguments to be stored\n+//! in a globally-accessible location for use by the `os` module.\n+//!\n+//! XXX: Would be nice for this to not exist.\n+//! XXX: This has a lot of C glue for lack of globals.\n+\n+use libc;\n+use option::{Option, Some, None};\n+use str;\n+use uint;\n+use unstable::finally::Finally;\n+use util;\n+\n+/// One-time global initialization.\n+pub unsafe fn init(argc: int, argv: **u8) {\n+    let args = load_argc_and_argv(argc, argv);\n+    put(args);\n+}\n+\n+/// One-time global cleanup.\n+pub fn cleanup() {\n+    rtassert!(take().is_some());\n+}\n+\n+/// Take the global arguments from global storage.\n+pub fn take() -> Option<~[~str]> {\n+    with_lock(|| unsafe {\n+        let ptr = get_global_ptr();\n+        let val = util::replace(&mut *ptr, None);\n+        val.map(|s: &~~[~str]| (**s).clone())\n+    })\n+}\n+\n+/// Give the global arguments to global storage.\n+///\n+/// It is an error if the arguments already exist.\n+pub fn put(args: ~[~str]) {\n+    with_lock(|| unsafe {\n+        let ptr = get_global_ptr();\n+        rtassert!((*ptr).is_none());\n+        (*ptr) = Some(~args.clone());\n+    })\n+}\n+\n+/// Make a clone of the global arguments.\n+pub fn clone() -> Option<~[~str]> {\n+    with_lock(|| unsafe {\n+        let ptr = get_global_ptr();\n+        (*ptr).map(|s: &~~[~str]| (**s).clone())\n+    })\n+}\n+\n+fn with_lock<T>(f: &fn() -> T) -> T {\n+    do (|| {\n+        unsafe {\n+            rust_take_global_args_lock();\n+            f()\n+        }\n+    }).finally {\n+        unsafe {\n+            rust_drop_global_args_lock();\n+        }\n+    }\n+}\n+\n+fn get_global_ptr() -> *mut Option<~~[~str]> {\n+    unsafe { rust_get_global_args_ptr() }\n+}\n+\n+// Copied from `os`.\n+unsafe fn load_argc_and_argv(argc: int, argv: **u8) -> ~[~str] {\n+    let mut args = ~[];\n+    for uint::range(0, argc as uint) |i| {\n+        args.push(str::raw::from_c_str(*(argv as **libc::c_char).offset(i)));\n+    }\n+    return args;\n+}\n+\n+extern {\n+    fn rust_take_global_args_lock();\n+    fn rust_drop_global_args_lock();\n+    fn rust_get_global_args_ptr() -> *mut Option<~~[~str]>;\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use option::{Some, None};\n+    use super::*;\n+    use unstable::finally::Finally;\n+\n+    #[test]\n+    fn smoke_test() {\n+        // Preserve the actual global state.\n+        let saved_value = take();\n+\n+        let expected = ~[~\"happy\", ~\"today?\"];\n+\n+        put(expected.clone());\n+        assert!(clone() == Some(expected.clone()));\n+        assert!(take() == Some(expected.clone()));\n+        assert!(take() == None);\n+\n+        do (|| {\n+        }).finally {\n+            // Restore the actual global state.\n+            match saved_value {\n+                Some(ref args) => put(args.clone()),\n+                None => ()\n+            }\n+        }\n+    }\n+}"}, {"sha": "60df2d5c11ba2420014ea55a1443449da2a8dbcc", "filename": "src/libstd/rt/borrowck.rs", "status": "added", "additions": 283, "deletions": 0, "changes": 283, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fborrowck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fborrowck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fborrowck.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -0,0 +1,283 @@\n+// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use cast::transmute;\n+use libc::{c_char, c_void, size_t, STDERR_FILENO};\n+use io;\n+use io::{Writer, WriterUtil};\n+use managed::raw::BoxRepr;\n+use option::{Option, None, Some};\n+use uint;\n+use str;\n+use str::OwnedStr;\n+use sys;\n+use vec::ImmutableVector;\n+\n+#[allow(non_camel_case_types)]\n+type rust_task = c_void;\n+\n+pub static FROZEN_BIT: uint = 1 << (uint::bits - 1);\n+pub static MUT_BIT: uint = 1 << (uint::bits - 2);\n+static ALL_BITS: uint = FROZEN_BIT | MUT_BIT;\n+\n+#[deriving(Eq)]\n+struct BorrowRecord {\n+    box: *mut BoxRepr,\n+    file: *c_char,\n+    line: size_t\n+}\n+\n+fn try_take_task_borrow_list() -> Option<~[BorrowRecord]> {\n+    unsafe {\n+        let cur_task: *rust_task = rust_try_get_task();\n+        if cur_task.is_not_null() {\n+            let ptr = rust_take_task_borrow_list(cur_task);\n+            if ptr.is_null() {\n+                None\n+            } else {\n+                let v: ~[BorrowRecord] = transmute(ptr);\n+                Some(v)\n+            }\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+fn swap_task_borrow_list(f: &fn(~[BorrowRecord]) -> ~[BorrowRecord]) {\n+    unsafe {\n+        let cur_task: *rust_task = rust_try_get_task();\n+        if cur_task.is_not_null() {\n+            let mut borrow_list: ~[BorrowRecord] = {\n+                let ptr = rust_take_task_borrow_list(cur_task);\n+                if ptr.is_null() { ~[] } else { transmute(ptr) }\n+            };\n+            borrow_list = f(borrow_list);\n+            rust_set_task_borrow_list(cur_task, transmute(borrow_list));\n+        }\n+    }\n+}\n+\n+pub unsafe fn clear_task_borrow_list() {\n+    // pub because it is used by the box annihilator.\n+    let _ = try_take_task_borrow_list();\n+}\n+\n+unsafe fn fail_borrowed(box: *mut BoxRepr, file: *c_char, line: size_t) {\n+    debug_borrow(\"fail_borrowed: \", box, 0, 0, file, line);\n+\n+    match try_take_task_borrow_list() {\n+        None => { // not recording borrows\n+            let msg = \"borrowed\";\n+            do str::as_buf(msg) |msg_p, _| {\n+                sys::begin_unwind_(msg_p as *c_char, file, line);\n+            }\n+        }\n+        Some(borrow_list) => { // recording borrows\n+            let mut msg = ~\"borrowed\";\n+            let mut sep = \" at \";\n+            for borrow_list.rev_iter().advance |entry| {\n+                if entry.box == box {\n+                    msg.push_str(sep);\n+                    let filename = str::raw::from_c_str(entry.file);\n+                    msg.push_str(filename);\n+                    msg.push_str(fmt!(\":%u\", entry.line as uint));\n+                    sep = \" and at \";\n+                }\n+            }\n+            do str::as_buf(msg) |msg_p, _| {\n+                sys::begin_unwind_(msg_p as *c_char, file, line)\n+            }\n+        }\n+    }\n+}\n+\n+/// Because this code is so perf. sensitive, use a static constant so that\n+/// debug printouts are compiled out most of the time.\n+static ENABLE_DEBUG: bool = false;\n+\n+#[inline]\n+unsafe fn debug_borrow<T>(tag: &'static str,\n+                          p: *const T,\n+                          old_bits: uint,\n+                          new_bits: uint,\n+                          filename: *c_char,\n+                          line: size_t) {\n+    //! A useful debugging function that prints a pointer + tag + newline\n+    //! without allocating memory.\n+\n+    if ENABLE_DEBUG && ::rt::env::get().debug_borrow {\n+        debug_borrow_slow(tag, p, old_bits, new_bits, filename, line);\n+    }\n+\n+    unsafe fn debug_borrow_slow<T>(tag: &'static str,\n+                                   p: *const T,\n+                                   old_bits: uint,\n+                                   new_bits: uint,\n+                                   filename: *c_char,\n+                                   line: size_t) {\n+        let dbg = STDERR_FILENO as io::fd_t;\n+        dbg.write_str(tag);\n+        dbg.write_hex(p as uint);\n+        dbg.write_str(\" \");\n+        dbg.write_hex(old_bits);\n+        dbg.write_str(\" \");\n+        dbg.write_hex(new_bits);\n+        dbg.write_str(\" \");\n+        dbg.write_cstr(filename);\n+        dbg.write_str(\":\");\n+        dbg.write_hex(line as uint);\n+        dbg.write_str(\"\\n\");\n+    }\n+}\n+\n+trait DebugPrints {\n+    fn write_hex(&self, val: uint);\n+    unsafe fn write_cstr(&self, str: *c_char);\n+}\n+\n+impl DebugPrints for io::fd_t {\n+    fn write_hex(&self, mut i: uint) {\n+        let letters = ['0', '1', '2', '3', '4', '5', '6', '7', '8',\n+                       '9', 'a', 'b', 'c', 'd', 'e', 'f'];\n+        static UINT_NIBBLES: uint = ::uint::bytes << 1;\n+        let mut buffer = [0_u8, ..UINT_NIBBLES+1];\n+        let mut c = UINT_NIBBLES;\n+        while c > 0 {\n+            c -= 1;\n+            buffer[c] = letters[i & 0xF] as u8;\n+            i >>= 4;\n+        }\n+        self.write(buffer.slice(0, UINT_NIBBLES));\n+    }\n+\n+    unsafe fn write_cstr(&self, p: *c_char) {\n+        use libc::strlen;\n+        use vec;\n+\n+        let len = strlen(p);\n+        let p: *u8 = transmute(p);\n+        do vec::raw::buf_as_slice(p, len as uint) |s| {\n+            self.write(s);\n+        }\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn borrow_as_imm(a: *u8, file: *c_char, line: size_t) -> uint {\n+    let a: *mut BoxRepr = transmute(a);\n+    let old_ref_count = (*a).header.ref_count;\n+    let new_ref_count = old_ref_count | FROZEN_BIT;\n+\n+    debug_borrow(\"borrow_as_imm:\", a, old_ref_count, new_ref_count, file, line);\n+\n+    if (old_ref_count & MUT_BIT) != 0 {\n+        fail_borrowed(a, file, line);\n+    }\n+\n+    (*a).header.ref_count = new_ref_count;\n+\n+    old_ref_count\n+}\n+\n+#[inline]\n+pub unsafe fn borrow_as_mut(a: *u8, file: *c_char, line: size_t) -> uint {\n+    let a: *mut BoxRepr = transmute(a);\n+    let old_ref_count = (*a).header.ref_count;\n+    let new_ref_count = old_ref_count | MUT_BIT | FROZEN_BIT;\n+\n+    debug_borrow(\"borrow_as_mut:\", a, old_ref_count, new_ref_count, file, line);\n+\n+    if (old_ref_count & (MUT_BIT|FROZEN_BIT)) != 0 {\n+        fail_borrowed(a, file, line);\n+    }\n+\n+    (*a).header.ref_count = new_ref_count;\n+\n+    old_ref_count\n+}\n+\n+pub unsafe fn record_borrow(a: *u8, old_ref_count: uint,\n+                            file: *c_char, line: size_t) {\n+    if (old_ref_count & ALL_BITS) == 0 {\n+        // was not borrowed before\n+        let a: *mut BoxRepr = transmute(a);\n+        debug_borrow(\"record_borrow:\", a, old_ref_count, 0, file, line);\n+        do swap_task_borrow_list |borrow_list| {\n+            let mut borrow_list = borrow_list;\n+            borrow_list.push(BorrowRecord {box: a, file: file, line: line});\n+            borrow_list\n+        }\n+    }\n+}\n+\n+pub unsafe fn unrecord_borrow(a: *u8, old_ref_count: uint,\n+                              file: *c_char, line: size_t) {\n+    if (old_ref_count & ALL_BITS) == 0 {\n+        // was not borrowed before, so we should find the record at\n+        // the end of the list\n+        let a: *mut BoxRepr = transmute(a);\n+        debug_borrow(\"unrecord_borrow:\", a, old_ref_count, 0, file, line);\n+        do swap_task_borrow_list |borrow_list| {\n+            let mut borrow_list = borrow_list;\n+            assert!(!borrow_list.is_empty());\n+            let br = borrow_list.pop();\n+            if br.box != a || br.file != file || br.line != line {\n+                let err = fmt!(\"wrong borrow found, br=%?\", br);\n+                do str::as_buf(err) |msg_p, _| {\n+                    sys::begin_unwind_(msg_p as *c_char, file, line)\n+                }\n+            }\n+            borrow_list\n+        }\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn return_to_mut(a: *u8, orig_ref_count: uint,\n+                            file: *c_char, line: size_t) {\n+    // Sometimes the box is null, if it is conditionally frozen.\n+    // See e.g. #4904.\n+    if !a.is_null() {\n+        let a: *mut BoxRepr = transmute(a);\n+        let old_ref_count = (*a).header.ref_count;\n+        let new_ref_count =\n+            (old_ref_count & !ALL_BITS) | (orig_ref_count & ALL_BITS);\n+\n+        debug_borrow(\"return_to_mut:\",\n+                     a, old_ref_count, new_ref_count, file, line);\n+\n+        (*a).header.ref_count = new_ref_count;\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn check_not_borrowed(a: *u8,\n+                                 file: *c_char,\n+                                 line: size_t) {\n+    let a: *mut BoxRepr = transmute(a);\n+    let ref_count = (*a).header.ref_count;\n+    debug_borrow(\"check_not_borrowed:\", a, ref_count, 0, file, line);\n+    if (ref_count & FROZEN_BIT) != 0 {\n+        fail_borrowed(a, file, line);\n+    }\n+}\n+\n+\n+extern {\n+    #[rust_stack]\n+    pub fn rust_take_task_borrow_list(task: *rust_task) -> *c_void;\n+\n+    #[rust_stack]\n+    pub fn rust_set_task_borrow_list(task: *rust_task, map: *c_void);\n+\n+    #[rust_stack]\n+    pub fn rust_try_get_task() -> *rust_task;\n+}"}, {"sha": "fba6171129762254094300d1618bfcbf6eb6dca0", "filename": "src/libstd/rt/comm.rs", "status": "modified", "additions": 318, "deletions": 23, "changes": 341, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fcomm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fcomm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fcomm.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -19,13 +19,16 @@ use option::*;\n use cast;\n use util;\n use ops::Drop;\n+use rt::task::Task;\n use kinds::Send;\n-use rt::sched::{Scheduler, Coroutine};\n+use rt::sched::Scheduler;\n use rt::local::Local;\n-use unstable::intrinsics::{atomic_xchg, atomic_load};\n+use unstable::atomics::{AtomicUint, AtomicOption, SeqCst};\n+use unstable::sync::UnsafeAtomicRcBox;\n use util::Void;\n use comm::{GenericChan, GenericSmartChan, GenericPort, Peekable};\n use cell::Cell;\n+use clone::Clone;\n \n /// A combined refcount / ~Task pointer.\n ///\n@@ -34,14 +37,14 @@ use cell::Cell;\n /// * 2 - both endpoints are alive\n /// * 1 - either the sender or the receiver is dead, determined by context\n /// * <ptr> - A pointer to a blocked Task that can be transmuted to ~Task\n-type State = int;\n+type State = uint;\n \n static STATE_BOTH: State = 2;\n static STATE_ONE: State = 1;\n \n /// The heap-allocated structure shared between two endpoints.\n struct Packet<T> {\n-    state: State,\n+    state: AtomicUint,\n     payload: Option<T>,\n }\n \n@@ -70,7 +73,7 @@ pub struct PortOneHack<T> {\n \n pub fn oneshot<T: Send>() -> (PortOne<T>, ChanOne<T>) {\n     let packet: ~Packet<T> = ~Packet {\n-        state: STATE_BOTH,\n+        state: AtomicUint::new(STATE_BOTH),\n         payload: None\n     };\n \n@@ -114,20 +117,30 @@ impl<T> ChanOne<T> {\n             // reordering of the payload write. This also issues an\n             // acquire barrier that keeps the subsequent access of the\n             // ~Task pointer from being reordered.\n-            let oldstate = atomic_xchg(&mut (*packet).state, STATE_ONE);\n+            let oldstate = (*packet).state.swap(STATE_ONE, SeqCst);\n             match oldstate {\n                 STATE_BOTH => {\n                     // Port is not waiting yet. Nothing to do\n+                    do Local::borrow::<Scheduler, ()> |sched| {\n+                        rtdebug!(\"non-rendezvous send\");\n+                        sched.metrics.non_rendezvous_sends += 1;\n+                    }\n                 }\n                 STATE_ONE => {\n+                    do Local::borrow::<Scheduler, ()> |sched| {\n+                        rtdebug!(\"rendezvous send\");\n+                        sched.metrics.rendezvous_sends += 1;\n+                    }\n                     // Port has closed. Need to clean up.\n                     let _packet: ~Packet<T> = cast::transmute(this.inner.void_packet);\n                     recvr_active = false;\n                 }\n                 task_as_state => {\n                     // Port is blocked. Wake it up.\n-                    let recvr: ~Coroutine = cast::transmute(task_as_state);\n-                    let sched = Local::take::<Scheduler>();\n+                    let recvr: ~Task = cast::transmute(task_as_state);\n+                    let mut sched = Local::take::<Scheduler>();\n+                    rtdebug!(\"rendezvous send\");\n+                    sched.metrics.rendezvous_sends += 1;\n                     sched.schedule_task(recvr);\n                 }\n             }\n@@ -158,23 +171,30 @@ impl<T> PortOne<T> {\n \n         // Switch to the scheduler to put the ~Task into the Packet state.\n         let sched = Local::take::<Scheduler>();\n-        do sched.deschedule_running_task_and_then |task| {\n+        do sched.deschedule_running_task_and_then |sched, task| {\n             unsafe {\n                 // Atomically swap the task pointer into the Packet state, issuing\n                 // an acquire barrier to prevent reordering of the subsequent read\n                 // of the payload. Also issues a release barrier to prevent reordering\n                 // of any previous writes to the task structure.\n                 let task_as_state: State = cast::transmute(task);\n-                let oldstate = atomic_xchg(&mut (*packet).state, task_as_state);\n+                let oldstate = (*packet).state.swap(task_as_state, SeqCst);\n                 match oldstate {\n                     STATE_BOTH => {\n                         // Data has not been sent. Now we're blocked.\n+                        rtdebug!(\"non-rendezvous recv\");\n+                        sched.metrics.non_rendezvous_recvs += 1;\n                     }\n                     STATE_ONE => {\n+                        rtdebug!(\"rendezvous recv\");\n+                        sched.metrics.rendezvous_recvs += 1;\n+\n                         // Channel is closed. Switch back and check the data.\n-                        let task: ~Coroutine = cast::transmute(task_as_state);\n-                        let sched = Local::take::<Scheduler>();\n-                        sched.resume_task_immediately(task);\n+                        // NB: We have to drop back into the scheduler event loop here\n+                        // instead of switching immediately back or we could end up\n+                        // triggering infinite recursion on the scheduler's stack.\n+                        let task: ~Task = cast::transmute(task_as_state);\n+                        sched.enqueue_task(task);\n                     }\n                     _ => util::unreachable()\n                 }\n@@ -210,7 +230,7 @@ impl<T> Peekable<T> for PortOne<T> {\n     fn peek(&self) -> bool {\n         unsafe {\n             let packet: *mut Packet<T> = self.inner.packet();\n-            let oldstate = atomic_load(&mut (*packet).state);\n+            let oldstate = (*packet).state.load(SeqCst);\n             match oldstate {\n                 STATE_BOTH => false,\n                 STATE_ONE => (*packet).payload.is_some(),\n@@ -227,7 +247,7 @@ impl<T> Drop for ChanOneHack<T> {\n \n         unsafe {\n             let this = cast::transmute_mut(self);\n-            let oldstate = atomic_xchg(&mut (*this.packet()).state, STATE_ONE);\n+            let oldstate = (*this.packet()).state.swap(STATE_ONE, SeqCst);\n             match oldstate {\n                 STATE_BOTH => {\n                     // Port still active. It will destroy the Packet.\n@@ -238,7 +258,7 @@ impl<T> Drop for ChanOneHack<T> {\n                 task_as_state => {\n                     // The port is blocked waiting for a message we will never send. Wake it.\n                     assert!((*this.packet()).payload.is_none());\n-                    let recvr: ~Coroutine = cast::transmute(task_as_state);\n+                    let recvr: ~Task = cast::transmute(task_as_state);\n                     let sched = Local::take::<Scheduler>();\n                     sched.schedule_task(recvr);\n                 }\n@@ -254,7 +274,7 @@ impl<T> Drop for PortOneHack<T> {\n \n         unsafe {\n             let this = cast::transmute_mut(self);\n-            let oldstate = atomic_xchg(&mut (*this.packet()).state, STATE_ONE);\n+            let oldstate = (*this.packet()).state.swap(STATE_ONE, SeqCst);\n             match oldstate {\n                 STATE_BOTH => {\n                     // Chan still active. It will destroy the packet.\n@@ -295,16 +315,19 @@ struct StreamPayload<T> {\n     next: PortOne<StreamPayload<T>>\n }\n \n+type StreamChanOne<T> = ChanOne<StreamPayload<T>>;\n+type StreamPortOne<T> = PortOne<StreamPayload<T>>;\n+\n /// A channel with unbounded size.\n pub struct Chan<T> {\n     // FIXME #5372. Using Cell because we don't take &mut self\n-    next: Cell<ChanOne<StreamPayload<T>>>\n+    next: Cell<StreamChanOne<T>>\n }\n \n /// An port with unbounded size.\n pub struct Port<T> {\n     // FIXME #5372. Using Cell because we don't take &mut self\n-    next: Cell<PortOne<StreamPayload<T>>>\n+    next: Cell<StreamPortOne<T>>\n }\n \n pub fn stream<T: Send>() -> (Port<T>, Chan<T>) {\n@@ -357,6 +380,136 @@ impl<T> Peekable<T> for Port<T> {\n     }\n }\n \n+pub struct SharedChan<T> {\n+    // Just like Chan, but a shared AtomicOption instead of Cell\n+    priv next: UnsafeAtomicRcBox<AtomicOption<StreamChanOne<T>>>\n+}\n+\n+impl<T> SharedChan<T> {\n+    pub fn new(chan: Chan<T>) -> SharedChan<T> {\n+        let next = chan.next.take();\n+        let next = AtomicOption::new(~next);\n+        SharedChan { next: UnsafeAtomicRcBox::new(next) }\n+    }\n+}\n+\n+impl<T: Send> GenericChan<T> for SharedChan<T> {\n+    fn send(&self, val: T) {\n+        self.try_send(val);\n+    }\n+}\n+\n+impl<T: Send> GenericSmartChan<T> for SharedChan<T> {\n+    fn try_send(&self, val: T) -> bool {\n+        unsafe {\n+            let (next_pone, next_cone) = oneshot();\n+            let cone = (*self.next.get()).swap(~next_cone, SeqCst);\n+            cone.unwrap().try_send(StreamPayload { val: val, next: next_pone })\n+        }\n+    }\n+}\n+\n+impl<T> Clone for SharedChan<T> {\n+    fn clone(&self) -> SharedChan<T> {\n+        SharedChan {\n+            next: self.next.clone()\n+        }\n+    }\n+}\n+\n+pub struct SharedPort<T> {\n+    // The next port on which we will receive the next port on which we will receive T\n+    priv next_link: UnsafeAtomicRcBox<AtomicOption<PortOne<StreamPortOne<T>>>>\n+}\n+\n+impl<T> SharedPort<T> {\n+    pub fn new(port: Port<T>) -> SharedPort<T> {\n+        // Put the data port into a new link pipe\n+        let next_data_port = port.next.take();\n+        let (next_link_port, next_link_chan) = oneshot();\n+        next_link_chan.send(next_data_port);\n+        let next_link = AtomicOption::new(~next_link_port);\n+        SharedPort { next_link: UnsafeAtomicRcBox::new(next_link) }\n+    }\n+}\n+\n+impl<T: Send> GenericPort<T> for SharedPort<T> {\n+    fn recv(&self) -> T {\n+        match self.try_recv() {\n+            Some(val) => val,\n+            None => {\n+                fail!(\"receiving on a closed channel\");\n+            }\n+        }\n+    }\n+\n+    fn try_recv(&self) -> Option<T> {\n+        unsafe {\n+            let (next_link_port, next_link_chan) = oneshot();\n+            let link_port = (*self.next_link.get()).swap(~next_link_port, SeqCst);\n+            let link_port = link_port.unwrap();\n+            let data_port = link_port.recv();\n+            let (next_data_port, res) = match data_port.try_recv() {\n+                Some(StreamPayload { val, next }) => {\n+                    (next, Some(val))\n+                }\n+                None => {\n+                    let (next_data_port, _) = oneshot();\n+                    (next_data_port, None)\n+                }\n+            };\n+            next_link_chan.send(next_data_port);\n+            return res;\n+        }\n+    }\n+}\n+\n+impl<T> Clone for SharedPort<T> {\n+    fn clone(&self) -> SharedPort<T> {\n+        SharedPort {\n+            next_link: self.next_link.clone()\n+        }\n+    }\n+}\n+\n+// XXX: Need better name\n+type MegaPipe<T> = (SharedPort<T>, SharedChan<T>);\n+\n+pub fn megapipe<T: Send>() -> MegaPipe<T> {\n+    let (port, chan) = stream();\n+    (SharedPort::new(port), SharedChan::new(chan))\n+}\n+\n+impl<T: Send> GenericChan<T> for MegaPipe<T> {\n+    fn send(&self, val: T) {\n+        match *self {\n+            (_, ref c) => c.send(val)\n+        }\n+    }\n+}\n+\n+impl<T: Send> GenericSmartChan<T> for MegaPipe<T> {\n+    fn try_send(&self, val: T) -> bool {\n+        match *self {\n+            (_, ref c) => c.try_send(val)\n+        }\n+    }\n+}\n+\n+impl<T: Send> GenericPort<T> for MegaPipe<T> {\n+    fn recv(&self) -> T {\n+        match *self {\n+            (ref p, _) => p.recv()\n+        }\n+    }\n+\n+    fn try_recv(&self) -> Option<T> {\n+        match *self {\n+            (ref p, _) => p.try_recv()\n+        }\n+    }\n+}\n+\n #[cfg(test)]\n mod test {\n     use super::*;\n@@ -402,6 +555,8 @@ mod test {\n                 { let _c = chan; }\n                 port.recv();\n             };\n+            // What is our res?\n+            rtdebug!(\"res is: %?\", res.is_err());\n             assert!(res.is_err());\n         }\n     }\n@@ -584,7 +739,7 @@ mod test {\n     #[test]\n     fn stream_send_recv_stress() {\n         for stress_factor().times {\n-            do run_in_newsched_task {\n+            do run_in_mt_newsched_task {\n                 let (port, chan) = stream::<~int>();\n \n                 send(chan, 0);\n@@ -594,18 +749,18 @@ mod test {\n                     if i == 10 { return }\n \n                     let chan_cell = Cell::new(chan);\n-                    let _thread = do spawntask_thread {\n+                    do spawntask_random {\n                         let chan = chan_cell.take();\n                         chan.send(~i);\n                         send(chan, i + 1);\n-                    };\n+                    }\n                 }\n \n                 fn recv(port: Port<~int>, i: int) {\n                     if i == 10 { return }\n \n                     let port_cell = Cell::new(port);\n-                    let _thread = do spawntask_thread {\n+                    do spawntask_random {\n                         let port = port_cell.take();\n                         assert!(port.recv() == ~i);\n                         recv(port, i + 1);\n@@ -614,4 +769,144 @@ mod test {\n             }\n         }\n     }\n+\n+    #[test]\n+    fn recv_a_lot() {\n+        // Regression test that we don't run out of stack in scheduler context\n+        do run_in_newsched_task {\n+            let (port, chan) = stream();\n+            for 10000.times { chan.send(()) }\n+            for 10000.times { port.recv() }\n+        }\n+    }\n+\n+    #[test]\n+    fn shared_chan_stress() {\n+        do run_in_mt_newsched_task {\n+            let (port, chan) = stream();\n+            let chan = SharedChan::new(chan);\n+            let total = stress_factor() + 100;\n+            for total.times {\n+                let chan_clone = chan.clone();\n+                do spawntask_random {\n+                    chan_clone.send(());\n+                }\n+            }\n+\n+            for total.times {\n+                port.recv();\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn shared_port_stress() {\n+        do run_in_mt_newsched_task {\n+            // XXX: Removing these type annotations causes an ICE\n+            let (end_port, end_chan) = stream::<()>();\n+            let (port, chan) = stream::<()>();\n+            let end_chan = SharedChan::new(end_chan);\n+            let port = SharedPort::new(port);\n+            let total = stress_factor() + 100;\n+            for total.times {\n+                let end_chan_clone = end_chan.clone();\n+                let port_clone = port.clone();\n+                do spawntask_random {\n+                    port_clone.recv();\n+                    end_chan_clone.send(());\n+                }\n+            }\n+\n+            for total.times {\n+                chan.send(());\n+            }\n+\n+            for total.times {\n+                end_port.recv();\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn shared_port_close_simple() {\n+        do run_in_mt_newsched_task {\n+            let (port, chan) = stream::<()>();\n+            let port = SharedPort::new(port);\n+            { let _chan = chan; }\n+            assert!(port.try_recv().is_none());\n+        }\n+    }\n+\n+    #[test]\n+    fn shared_port_close() {\n+        do run_in_mt_newsched_task {\n+            let (end_port, end_chan) = stream::<bool>();\n+            let (port, chan) = stream::<()>();\n+            let end_chan = SharedChan::new(end_chan);\n+            let port = SharedPort::new(port);\n+            let chan = SharedChan::new(chan);\n+            let send_total = 10;\n+            let recv_total = 20;\n+            do spawntask_random {\n+                for send_total.times {\n+                    let chan_clone = chan.clone();\n+                    do spawntask_random {\n+                        chan_clone.send(());\n+                    }\n+                }\n+            }\n+            let end_chan_clone = end_chan.clone();\n+            do spawntask_random {\n+                for recv_total.times {\n+                    let port_clone = port.clone();\n+                    let end_chan_clone = end_chan_clone.clone();\n+                    do spawntask_random {\n+                        let recvd = port_clone.try_recv().is_some();\n+                        end_chan_clone.send(recvd);\n+                    }\n+                }\n+            }\n+\n+            let mut recvd = 0;\n+            for recv_total.times {\n+                recvd += if end_port.recv() { 1 } else { 0 };\n+            }\n+\n+            assert!(recvd == send_total);\n+        }\n+    }\n+\n+    #[test]\n+    fn megapipe_stress() {\n+        use rand;\n+        use rand::RngUtil;\n+\n+        do run_in_mt_newsched_task {\n+            let (end_port, end_chan) = stream::<()>();\n+            let end_chan = SharedChan::new(end_chan);\n+            let pipe = megapipe();\n+            let total = stress_factor() + 10;\n+            let mut rng = rand::rng();\n+            for total.times {\n+                let msgs = rng.gen_uint_range(0, 10);\n+                let pipe_clone = pipe.clone();\n+                let end_chan_clone = end_chan.clone();\n+                do spawntask_random {\n+                    for msgs.times {\n+                        pipe_clone.send(());\n+                    }\n+                    for msgs.times {\n+                        pipe_clone.recv();\n+                    }\n+                }\n+\n+                end_chan_clone.send(());\n+            }\n+\n+            for total.times {\n+                end_port.recv();\n+            }\n+        }\n+    }\n+\n }"}, {"sha": "68e57dd49407ad356762223e966a65b63d31ad39", "filename": "src/libstd/rt/global_heap.rs", "status": "modified", "additions": 11, "deletions": 1, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fglobal_heap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fglobal_heap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fglobal_heap.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use libc::{c_char, c_void, size_t, uintptr_t, free, malloc, realloc};\n+use libc::{c_void, c_char, size_t, uintptr_t, free, malloc, realloc};\n use managed::raw::{BoxHeaderRepr, BoxRepr};\n use unstable::intrinsics::TyDesc;\n use sys::size_of;\n@@ -95,6 +95,11 @@ pub unsafe fn vector_exchange_malloc(align: u32, size: uintptr_t) -> *c_char {\n // FIXME: #7496\n #[cfg(not(test))]\n #[lang=\"closure_exchange_malloc\"]\n+#[inline]\n+pub unsafe fn closure_exchange_malloc_(td: *c_char, size: uintptr_t) -> *c_char {\n+    closure_exchange_malloc(td, size)\n+}\n+\n #[inline]\n pub unsafe fn closure_exchange_malloc(td: *c_char, size: uintptr_t) -> *c_char {\n     let td = td as *TyDesc;\n@@ -115,6 +120,11 @@ pub unsafe fn closure_exchange_malloc(td: *c_char, size: uintptr_t) -> *c_char {\n // inside a landing pad may corrupt the state of the exception handler.\n #[cfg(not(test))]\n #[lang=\"exchange_free\"]\n+#[inline]\n+pub unsafe fn exchange_free_(ptr: *c_char) {\n+    exchange_free(ptr)\n+}\n+\n #[inline]\n pub unsafe fn exchange_free(ptr: *c_char) {\n     free(ptr as *c_void);"}, {"sha": "3a93fd705436e2ae00b24fe0313b78ee5a8c0820", "filename": "src/libstd/rt/io/net/ip.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fio%2Fnet%2Fip.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fio%2Fnet%2Fip.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Fnet%2Fip.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -8,7 +8,10 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+type Port = u16;\n+\n+#[deriving(Eq, TotalEq)]\n pub enum IpAddr {\n-    Ipv4(u8, u8, u8, u8, u16),\n-    Ipv6\n+    Ipv4(u8, u8, u8, u8, Port),\n+    Ipv6(u16, u16, u16, u16, u16, u16, u16, u16, Port)\n }"}, {"sha": "2425c909bf3d8b0a4a09a9ebdb5a9dde0ec698a9", "filename": "src/libstd/rt/io/net/tcp.rs", "status": "modified", "additions": 209, "deletions": 31, "changes": 240, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fio%2Fnet%2Ftcp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fio%2Fnet%2Ftcp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Fnet%2Ftcp.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -18,15 +18,11 @@ use rt::rtio::{IoFactory, IoFactoryObject,\n                RtioTcpStream, RtioTcpStreamObject};\n use rt::local::Local;\n \n-pub struct TcpStream {\n-    rtstream: ~RtioTcpStreamObject\n-}\n+pub struct TcpStream(~RtioTcpStreamObject);\n \n impl TcpStream {\n     fn new(s: ~RtioTcpStreamObject) -> TcpStream {\n-        TcpStream {\n-            rtstream: s\n-        }\n+        TcpStream(s)\n     }\n \n     pub fn connect(addr: IpAddr) -> Option<TcpStream> {\n@@ -38,22 +34,19 @@ impl TcpStream {\n         };\n \n         match stream {\n-            Ok(s) => {\n-                Some(TcpStream::new(s))\n-            }\n+            Ok(s) => Some(TcpStream::new(s)),\n             Err(ioerr) => {\n                 rtdebug!(\"failed to connect: %?\", ioerr);\n                 io_error::cond.raise(ioerr);\n-                return None;\n+                None\n             }\n         }\n     }\n }\n \n impl Reader for TcpStream {\n     fn read(&mut self, buf: &mut [u8]) -> Option<uint> {\n-        let bytes_read = self.rtstream.read(buf);\n-        match bytes_read {\n+        match (**self).read(buf) {\n             Ok(read) => Some(read),\n             Err(ioerr) => {\n                 // EOF is indicated by returning None\n@@ -70,8 +63,7 @@ impl Reader for TcpStream {\n \n impl Writer for TcpStream {\n     fn write(&mut self, buf: &[u8]) {\n-        let res = self.rtstream.write(buf);\n-        match res {\n+        match (**self).write(buf) {\n             Ok(_) => (),\n             Err(ioerr) => {\n                 io_error::cond.raise(ioerr);\n@@ -82,9 +74,7 @@ impl Writer for TcpStream {\n     fn flush(&mut self) { fail!() }\n }\n \n-pub struct TcpListener {\n-    rtlistener: ~RtioTcpListenerObject,\n-}\n+pub struct TcpListener(~RtioTcpListenerObject);\n \n impl TcpListener {\n     pub fn bind(addr: IpAddr) -> Option<TcpListener> {\n@@ -93,11 +83,7 @@ impl TcpListener {\n             (*io).tcp_bind(addr)\n         };\n         match listener {\n-            Ok(l) => {\n-                Some(TcpListener {\n-                    rtlistener: l\n-                })\n-            }\n+            Ok(l) => Some(TcpListener(l)),\n             Err(ioerr) => {\n                 io_error::cond.raise(ioerr);\n                 return None;\n@@ -108,8 +94,7 @@ impl TcpListener {\n \n impl Listener<TcpStream> for TcpListener {\n     fn accept(&mut self) -> Option<TcpStream> {\n-        let rtstream = self.rtlistener.accept();\n-        match rtstream {\n+        match (**self).accept() {\n             Ok(s) => {\n                 Some(TcpStream::new(s))\n             }\n@@ -163,7 +148,7 @@ mod test {\n     }\n \n     #[test]\n-    fn smoke_test() {\n+    fn smoke_test_ip4() {\n         do run_in_newsched_task {\n             let addr = next_test_ip4();\n \n@@ -183,7 +168,27 @@ mod test {\n     }\n \n     #[test]\n-    fn read_eof() {\n+    fn smoke_test_ip6() {\n+        do run_in_newsched_task {\n+            let addr = next_test_ip6();\n+\n+            do spawntask_immediately {\n+                let mut listener = TcpListener::bind(addr);\n+                let mut stream = listener.accept();\n+                let mut buf = [0];\n+                stream.read(buf);\n+                assert!(buf[0] == 99);\n+            }\n+\n+            do spawntask_immediately {\n+                let mut stream = TcpStream::connect(addr);\n+                stream.write([99]);\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn read_eof_ip4() {\n         do run_in_newsched_task {\n             let addr = next_test_ip4();\n \n@@ -203,7 +208,27 @@ mod test {\n     }\n \n     #[test]\n-    fn read_eof_twice() {\n+    fn read_eof_ip6() {\n+        do run_in_newsched_task {\n+            let addr = next_test_ip6();\n+\n+            do spawntask_immediately {\n+                let mut listener = TcpListener::bind(addr);\n+                let mut stream = listener.accept();\n+                let mut buf = [0];\n+                let nread = stream.read(buf);\n+                assert!(nread.is_none());\n+            }\n+\n+            do spawntask_immediately {\n+                let _stream = TcpStream::connect(addr);\n+                // Close\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn read_eof_twice_ip4() {\n         do run_in_newsched_task {\n             let addr = next_test_ip4();\n \n@@ -225,7 +250,29 @@ mod test {\n     }\n \n     #[test]\n-    fn write_close() {\n+    fn read_eof_twice_ip6() {\n+        do run_in_newsched_task {\n+            let addr = next_test_ip6();\n+\n+            do spawntask_immediately {\n+                let mut listener = TcpListener::bind(addr);\n+                let mut stream = listener.accept();\n+                let mut buf = [0];\n+                let nread = stream.read(buf);\n+                assert!(nread.is_none());\n+                let nread = stream.read(buf);\n+                assert!(nread.is_none());\n+            }\n+\n+            do spawntask_immediately {\n+                let _stream = TcpStream::connect(addr);\n+                // Close\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn write_close_ip4() {\n         do run_in_newsched_task {\n             let addr = next_test_ip4();\n \n@@ -254,7 +301,36 @@ mod test {\n     }\n \n     #[test]\n-    fn multiple_connect_serial() {\n+    fn write_close_ip6() {\n+        do run_in_newsched_task {\n+            let addr = next_test_ip6();\n+\n+            do spawntask_immediately {\n+                let mut listener = TcpListener::bind(addr);\n+                let mut stream = listener.accept();\n+                let buf = [0];\n+                loop {\n+                    let mut stop = false;\n+                    do io_error::cond.trap(|e| {\n+                        // NB: ECONNRESET on linux, EPIPE on mac\n+                        assert!(e.kind == ConnectionReset || e.kind == BrokenPipe);\n+                        stop = true;\n+                    }).in {\n+                        stream.write(buf);\n+                    }\n+                    if stop { break }\n+                }\n+            }\n+\n+            do spawntask_immediately {\n+                let _stream = TcpStream::connect(addr);\n+                // Close\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn multiple_connect_serial_ip4() {\n         do run_in_newsched_task {\n             let addr = next_test_ip4();\n             let max = 10;\n@@ -279,7 +355,32 @@ mod test {\n     }\n \n     #[test]\n-    fn multiple_connect_interleaved_greedy_schedule() {\n+    fn multiple_connect_serial_ip6() {\n+        do run_in_newsched_task {\n+            let addr = next_test_ip6();\n+            let max = 10;\n+\n+            do spawntask_immediately {\n+                let mut listener = TcpListener::bind(addr);\n+                for max.times {\n+                    let mut stream = listener.accept();\n+                    let mut buf = [0];\n+                    stream.read(buf);\n+                    assert_eq!(buf[0], 99);\n+                }\n+            }\n+\n+            do spawntask_immediately {\n+                for max.times {\n+                    let mut stream = TcpStream::connect(addr);\n+                    stream.write([99]);\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn multiple_connect_interleaved_greedy_schedule_ip4() {\n         do run_in_newsched_task {\n             let addr = next_test_ip4();\n             static MAX: int = 10;\n@@ -318,7 +419,46 @@ mod test {\n     }\n \n     #[test]\n-    fn multiple_connect_interleaved_lazy_schedule() {\n+    fn multiple_connect_interleaved_greedy_schedule_ip6() {\n+        do run_in_newsched_task {\n+            let addr = next_test_ip6();\n+            static MAX: int = 10;\n+\n+            do spawntask_immediately {\n+                let mut listener = TcpListener::bind(addr);\n+                for int::range(0, MAX) |i| {\n+                    let stream = Cell::new(listener.accept());\n+                    rtdebug!(\"accepted\");\n+                    // Start another task to handle the connection\n+                    do spawntask_immediately {\n+                        let mut stream = stream.take();\n+                        let mut buf = [0];\n+                        stream.read(buf);\n+                        assert!(buf[0] == i as u8);\n+                        rtdebug!(\"read\");\n+                    }\n+                }\n+            }\n+\n+            connect(0, addr);\n+\n+            fn connect(i: int, addr: IpAddr) {\n+                if i == MAX { return }\n+\n+                do spawntask_immediately {\n+                    rtdebug!(\"connecting\");\n+                    let mut stream = TcpStream::connect(addr);\n+                    // Connect again before writing\n+                    connect(i + 1, addr);\n+                    rtdebug!(\"writing\");\n+                    stream.write([i as u8]);\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn multiple_connect_interleaved_lazy_schedule_ip4() {\n         do run_in_newsched_task {\n             let addr = next_test_ip4();\n             static MAX: int = 10;\n@@ -355,5 +495,43 @@ mod test {\n             }\n         }\n     }\n+    #[test]\n+    fn multiple_connect_interleaved_lazy_schedule_ip6() {\n+        do run_in_newsched_task {\n+            let addr = next_test_ip6();\n+            static MAX: int = 10;\n+\n+            do spawntask_immediately {\n+                let mut listener = TcpListener::bind(addr);\n+                for int::range(0, MAX) |_| {\n+                    let stream = Cell::new(listener.accept());\n+                    rtdebug!(\"accepted\");\n+                    // Start another task to handle the connection\n+                    do spawntask_later {\n+                        let mut stream = stream.take();\n+                        let mut buf = [0];\n+                        stream.read(buf);\n+                        assert!(buf[0] == 99);\n+                        rtdebug!(\"read\");\n+                    }\n+                }\n+            }\n+\n+            connect(0, addr);\n+\n+            fn connect(i: int, addr: IpAddr) {\n+                if i == MAX { return }\n+\n+                do spawntask_later {\n+                    rtdebug!(\"connecting\");\n+                    let mut stream = TcpStream::connect(addr);\n+                    // Connect again before writing\n+                    connect(i + 1, addr);\n+                    rtdebug!(\"writing\");\n+                    stream.write([99]);\n+                }\n+            }\n+        }\n+    }\n \n }"}, {"sha": "f3b5278357392d94fbdecebea5b6ef025d7c4f61", "filename": "src/libstd/rt/io/net/udp.rs", "status": "modified", "additions": 225, "deletions": 16, "changes": 241, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fio%2Fnet%2Fudp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fio%2Fnet%2Fudp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fio%2Fnet%2Fudp.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -8,38 +8,247 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use prelude::*;\n-use super::super::*;\n-use super::ip::IpAddr;\n+use option::{Option, Some, None};\n+use result::{Ok, Err};\n+use rt::io::net::ip::IpAddr;\n+use rt::io::{Reader, Writer};\n+use rt::io::{io_error, read_error, EndOfFile};\n+use rt::rtio::{RtioUdpSocketObject, RtioUdpSocket, IoFactory, IoFactoryObject};\n+use rt::local::Local;\n \n-pub struct UdpStream;\n+pub struct UdpSocket(~RtioUdpSocketObject);\n \n-impl UdpStream {\n-    pub fn connect(_addr: IpAddr) -> Option<UdpStream> {\n-        fail!()\n+impl UdpSocket {\n+    pub fn bind(addr: IpAddr) -> Option<UdpSocket> {\n+        let socket = unsafe { (*Local::unsafe_borrow::<IoFactoryObject>()).udp_bind(addr) };\n+        match socket {\n+            Ok(s) => Some(UdpSocket(s)),\n+            Err(ioerr) => {\n+                io_error::cond.raise(ioerr);\n+                None\n+            }\n+        }\n+    }\n+\n+    pub fn recvfrom(&self, buf: &mut [u8]) -> Option<(uint, IpAddr)> {\n+        match (**self).recvfrom(buf) {\n+            Ok((nread, src)) => Some((nread, src)),\n+            Err(ioerr) => {\n+                // EOF is indicated by returning None\n+                if ioerr.kind != EndOfFile {\n+                    read_error::cond.raise(ioerr);\n+                }\n+                None\n+            }\n+        }\n+    }\n+\n+    pub fn sendto(&self, buf: &[u8], dst: IpAddr) {\n+        match (**self).sendto(buf, dst) {\n+            Ok(_) => (),\n+            Err(ioerr) => io_error::cond.raise(ioerr),\n+        }\n+    }\n+\n+    pub fn connect(self, other: IpAddr) -> UdpStream {\n+        UdpStream { socket: self, connectedTo: other }\n     }\n }\n \n+pub struct UdpStream {\n+    socket: UdpSocket,\n+    connectedTo: IpAddr\n+}\n+\n+impl UdpStream {\n+    pub fn as_socket<T>(&self, f: &fn(&UdpSocket) -> T) -> T { f(&self.socket) }\n+\n+    pub fn disconnect(self) -> UdpSocket { self.socket }\n+}\n+\n impl Reader for UdpStream {\n-    fn read(&mut self, _buf: &mut [u8]) -> Option<uint> { fail!() }\n+    fn read(&mut self, buf: &mut [u8]) -> Option<uint> {\n+        do self.as_socket |sock| {\n+            match sock.recvfrom(buf) {\n+                Some((_nread, src)) if src != self.connectedTo => Some(0),\n+                Some((nread, _src)) => Some(nread),\n+                None => None,\n+            }\n+        }\n+    }\n \n     fn eof(&mut self) -> bool { fail!() }\n }\n \n impl Writer for UdpStream {\n-    fn write(&mut self, _buf: &[u8]) { fail!() }\n+    fn write(&mut self, buf: &[u8]) {\n+        do self.as_socket |sock| {\n+            sock.sendto(buf, self.connectedTo);\n+        }\n+    }\n \n     fn flush(&mut self) { fail!() }\n }\n \n-pub struct UdpListener;\n+#[cfg(test)]\n+mod test {\n+    use super::*;\n+    use rt::test::*;\n+    use rt::io::net::ip::Ipv4;\n+    use rt::io::*;\n+    use option::{Some, None};\n \n-impl UdpListener {\n-    pub fn bind(_addr: IpAddr) -> Option<UdpListener> {\n-        fail!()\n+    #[test]  #[ignore]\n+    fn bind_error() {\n+        do run_in_newsched_task {\n+            let mut called = false;\n+            do io_error::cond.trap(|e| {\n+                assert!(e.kind == PermissionDenied);\n+                called = true;\n+            }).in {\n+                let addr = Ipv4(0, 0, 0, 0, 1);\n+                let socket = UdpSocket::bind(addr);\n+                assert!(socket.is_none());\n+            }\n+            assert!(called);\n+        }\n     }\n-}\n \n-impl Listener<UdpStream> for UdpListener {\n-    fn accept(&mut self) -> Option<UdpStream> { fail!() }\n+    #[test]\n+    fn socket_smoke_test_ip4() {\n+        do run_in_newsched_task {\n+            let server_ip = next_test_ip4();\n+            let client_ip = next_test_ip4();\n+\n+            do spawntask_immediately {\n+                match UdpSocket::bind(server_ip) {\n+                    Some(server) => {\n+                        let mut buf = [0];\n+                        match server.recvfrom(buf) {\n+                            Some((nread, src)) => {\n+                                assert_eq!(nread, 1);\n+                                assert_eq!(buf[0], 99);\n+                                assert_eq!(src, client_ip);\n+                            }\n+                            None => fail!()\n+                        }\n+                    }\n+                    None => fail!()\n+                }\n+            }\n+\n+            do spawntask_immediately {\n+                match UdpSocket::bind(client_ip) {\n+                    Some(client) => client.sendto([99], server_ip),\n+                    None => fail!()\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn socket_smoke_test_ip6() {\n+        do run_in_newsched_task {\n+            let server_ip = next_test_ip6();\n+            let client_ip = next_test_ip6();\n+\n+            do spawntask_immediately {\n+                match UdpSocket::bind(server_ip) {\n+                    Some(server) => {\n+                        let mut buf = [0];\n+                        match server.recvfrom(buf) {\n+                            Some((nread, src)) => {\n+                                assert_eq!(nread, 1);\n+                                assert_eq!(buf[0], 99);\n+                                assert_eq!(src, client_ip);\n+                            }\n+                            None => fail!()\n+                        }\n+                    }\n+                    None => fail!()\n+                }\n+            }\n+\n+            do spawntask_immediately {\n+                match UdpSocket::bind(client_ip) {\n+                    Some(client) => client.sendto([99], server_ip),\n+                    None => fail!()\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn stream_smoke_test_ip4() {\n+        do run_in_newsched_task {\n+            let server_ip = next_test_ip4();\n+            let client_ip = next_test_ip4();\n+\n+            do spawntask_immediately {\n+                match UdpSocket::bind(server_ip) {\n+                    Some(server) => {\n+                        let server = ~server;\n+                        let mut stream = server.connect(client_ip);\n+                        let mut buf = [0];\n+                        match stream.read(buf) {\n+                            Some(nread) => {\n+                                assert_eq!(nread, 1);\n+                                assert_eq!(buf[0], 99);\n+                            }\n+                            None => fail!()\n+                        }\n+                    }\n+                    None => fail!()\n+                }\n+            }\n+\n+            do spawntask_immediately {\n+                match UdpSocket::bind(client_ip) {\n+                    Some(client) => {\n+                        let client = ~client;\n+                        let mut stream = client.connect(server_ip);\n+                        stream.write([99]);\n+                    }\n+                    None => fail!()\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn stream_smoke_test_ip6() {\n+        do run_in_newsched_task {\n+            let server_ip = next_test_ip6();\n+            let client_ip = next_test_ip6();\n+\n+            do spawntask_immediately {\n+                match UdpSocket::bind(server_ip) {\n+                    Some(server) => {\n+                        let server = ~server;\n+                        let mut stream = server.connect(client_ip);\n+                        let mut buf = [0];\n+                        match stream.read(buf) {\n+                            Some(nread) => {\n+                                assert_eq!(nread, 1);\n+                                assert_eq!(buf[0], 99);\n+                            }\n+                            None => fail!()\n+                        }\n+                    }\n+                    None => fail!()\n+                }\n+            }\n+\n+            do spawntask_immediately {\n+                match UdpSocket::bind(client_ip) {\n+                    Some(client) => {\n+                        let client = ~client;\n+                        let mut stream = client.connect(server_ip);\n+                        stream.write([99]);\n+                    }\n+                    None => fail!()\n+                }\n+            }\n+        }\n+    }\n }"}, {"sha": "8073c4a75b88bff88e1abe4338872f291798a317", "filename": "src/libstd/rt/join_latch.rs", "status": "added", "additions": 645, "deletions": 0, "changes": 645, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fjoin_latch.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fjoin_latch.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fjoin_latch.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -0,0 +1,645 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! The JoinLatch is a concurrent type that establishes the task\n+//! tree and propagates failure.\n+//!\n+//! Each task gets a JoinLatch that is derived from the JoinLatch\n+//! of its parent task. Every latch must be released by either calling\n+//! the non-blocking `release` method or the task-blocking `wait` method.\n+//! Releasing a latch does not complete until all of its child latches\n+//! complete.\n+//!\n+//! Latches carry a `success` flag that is set to `false` during task\n+//! failure and is propagated both from children to parents and parents\n+//! to children. The status af this flag may be queried for the purposes\n+//! of linked failure.\n+//!\n+//! In addition to failure propagation the task tree serves to keep the\n+//! default task schedulers alive. The runtime only sends the shutdown\n+//! message to schedulers once the root task exits.\n+//!\n+//! Under this scheme tasks that terminate before their children become\n+//! 'zombies' since they may not exit until their children do. Zombie\n+//! tasks are 'tombstoned' as `Tombstone(~JoinLatch)` and the tasks\n+//! themselves allowed to terminate.\n+//!\n+//! XXX: Propagate flag from parents to children.\n+//! XXX: Tombstoning actually doesn't work.\n+//! XXX: This could probably be done in a way that doesn't leak tombstones\n+//!      longer than the life of the child tasks.\n+\n+use comm::{GenericPort, Peekable, GenericSmartChan};\n+use clone::Clone;\n+use container::Container;\n+use option::{Option, Some, None};\n+use ops::Drop;\n+use rt::comm::{SharedChan, Port, stream};\n+use rt::local::Local;\n+use rt::sched::Scheduler;\n+use unstable::atomics::{AtomicUint, SeqCst};\n+use util;\n+use vec::OwnedVector;\n+\n+// FIXME #7026: Would prefer this to be an enum\n+pub struct JoinLatch {\n+    priv parent: Option<ParentLink>,\n+    priv child: Option<ChildLink>,\n+    closed: bool,\n+}\n+\n+// Shared between parents and all their children.\n+struct SharedState {\n+    /// Reference count, held by a parent and all children.\n+    count: AtomicUint,\n+    success: bool\n+}\n+\n+struct ParentLink {\n+    shared: *mut SharedState,\n+    // For communicating with the parent.\n+    chan: SharedChan<Message>\n+}\n+\n+struct ChildLink {\n+    shared: ~SharedState,\n+    // For receiving from children.\n+    port: Port<Message>,\n+    chan: SharedChan<Message>,\n+    // Prevents dropping the child SharedState reference counts multiple times.\n+    dropped_child: bool\n+}\n+\n+// Messages from child latches to parent.\n+enum Message {\n+    Tombstone(~JoinLatch),\n+    ChildrenTerminated\n+}\n+\n+impl JoinLatch {\n+    pub fn new_root() -> ~JoinLatch {\n+        let this = ~JoinLatch {\n+            parent: None,\n+            child: None,\n+            closed: false\n+        };\n+        rtdebug!(\"new root latch %x\", this.id());\n+        return this;\n+    }\n+\n+    fn id(&self) -> uint {\n+        unsafe { ::cast::transmute(&*self) }\n+    }\n+\n+    pub fn new_child(&mut self) -> ~JoinLatch {\n+        rtassert!(!self.closed);\n+\n+        if self.child.is_none() {\n+            // This is the first time spawning a child\n+            let shared = ~SharedState {\n+                count: AtomicUint::new(1),\n+                success: true\n+            };\n+            let (port, chan) = stream();\n+            let chan = SharedChan::new(chan);\n+            let child = ChildLink {\n+                shared: shared,\n+                port: port,\n+                chan: chan,\n+                dropped_child: false\n+            };\n+            self.child = Some(child);\n+        }\n+\n+        let child_link: &mut ChildLink = self.child.get_mut_ref();\n+        let shared_state: *mut SharedState = &mut *child_link.shared;\n+\n+        child_link.shared.count.fetch_add(1, SeqCst);\n+\n+        let child = ~JoinLatch {\n+            parent: Some(ParentLink {\n+                shared: shared_state,\n+                chan: child_link.chan.clone()\n+            }),\n+            child: None,\n+            closed: false\n+        };\n+        rtdebug!(\"NEW child latch %x\", child.id());\n+        return child;\n+    }\n+\n+    pub fn release(~self, local_success: bool) {\n+        // XXX: This should not block, but there's a bug in the below\n+        // code that I can't figure out.\n+        self.wait(local_success);\n+    }\n+\n+    // XXX: Should not require ~self\n+    fn release_broken(~self, local_success: bool) {\n+        rtassert!(!self.closed);\n+\n+        rtdebug!(\"releasing %x\", self.id());\n+\n+        let id = self.id();\n+        let _ = id; // XXX: `id` is only used in debug statements so appears unused\n+        let mut this = self;\n+        let mut child_success = true;\n+        let mut children_done = false;\n+\n+        if this.child.is_some() {\n+            rtdebug!(\"releasing children\");\n+            let child_link: &mut ChildLink = this.child.get_mut_ref();\n+            let shared: &mut SharedState = &mut *child_link.shared;\n+\n+            if !child_link.dropped_child {\n+                let last_count = shared.count.fetch_sub(1, SeqCst);\n+                rtdebug!(\"child count before sub %u %x\", last_count, id);\n+                if last_count == 1 {\n+                    assert!(child_link.chan.try_send(ChildrenTerminated));\n+                }\n+                child_link.dropped_child = true;\n+            }\n+\n+            // Wait for messages from children\n+            let mut tombstones = ~[];\n+            loop {\n+                if child_link.port.peek() {\n+                    match child_link.port.recv() {\n+                        Tombstone(t) => {\n+                            tombstones.push(t);\n+                        },\n+                        ChildrenTerminated => {\n+                            children_done = true;\n+                            break;\n+                        }\n+                    }\n+                } else {\n+                    break\n+                }\n+            }\n+\n+            rtdebug!(\"releasing %u tombstones %x\", tombstones.len(), id);\n+\n+            // Try to release the tombstones. Those that still have\n+            // outstanding will be re-enqueued.  When this task's\n+            // parents release their latch we'll end up back here\n+            // trying them again.\n+            while !tombstones.is_empty() {\n+                tombstones.pop().release(true);\n+            }\n+\n+            if children_done {\n+                let count = shared.count.load(SeqCst);\n+                assert!(count == 0);\n+                // self_count is the acquire-read barrier\n+                child_success = shared.success;\n+            }\n+        } else {\n+            children_done = true;\n+        }\n+\n+        let total_success = local_success && child_success;\n+\n+        rtassert!(this.parent.is_some());\n+\n+        unsafe {\n+            {\n+                let parent_link: &mut ParentLink = this.parent.get_mut_ref();\n+                let shared: *mut SharedState = parent_link.shared;\n+\n+                if !total_success {\n+                    // parent_count is the write-wait barrier\n+                    (*shared).success = false;\n+                }\n+            }\n+\n+            if children_done {\n+                rtdebug!(\"children done\");\n+                do Local::borrow::<Scheduler, ()> |sched| {\n+                    sched.metrics.release_tombstone += 1;\n+                }\n+                {\n+                    rtdebug!(\"RELEASING parent %x\", id);\n+                    let parent_link: &mut ParentLink = this.parent.get_mut_ref();\n+                    let shared: *mut SharedState = parent_link.shared;\n+                    let last_count = (*shared).count.fetch_sub(1, SeqCst);\n+                    rtdebug!(\"count before parent sub %u %x\", last_count, id);\n+                    if last_count == 1 {\n+                        assert!(parent_link.chan.try_send(ChildrenTerminated));\n+                    }\n+                }\n+                this.closed = true;\n+                util::ignore(this);\n+            } else {\n+                rtdebug!(\"children not done\");\n+                rtdebug!(\"TOMBSTONING %x\", id);\n+                do Local::borrow::<Scheduler, ()> |sched| {\n+                    sched.metrics.release_no_tombstone += 1;\n+                }\n+                let chan = {\n+                    let parent_link: &mut ParentLink = this.parent.get_mut_ref();\n+                    parent_link.chan.clone()\n+                };\n+                assert!(chan.try_send(Tombstone(this)));\n+            }\n+        }\n+    }\n+\n+    // XXX: Should not require ~self\n+    pub fn wait(~self, local_success: bool) -> bool {\n+        rtassert!(!self.closed);\n+\n+        rtdebug!(\"WAITING %x\", self.id());\n+\n+        let mut this = self;\n+        let mut child_success = true;\n+\n+        if this.child.is_some() {\n+            rtdebug!(\"waiting for children\");\n+            let child_link: &mut ChildLink = this.child.get_mut_ref();\n+            let shared: &mut SharedState = &mut *child_link.shared;\n+\n+            if !child_link.dropped_child {\n+                let last_count = shared.count.fetch_sub(1, SeqCst);\n+                rtdebug!(\"child count before sub %u\", last_count);\n+                if last_count == 1 {\n+                    assert!(child_link.chan.try_send(ChildrenTerminated));\n+                }\n+                child_link.dropped_child = true;\n+            }\n+\n+            // Wait for messages from children\n+            loop {\n+                match child_link.port.recv() {\n+                    Tombstone(t) => {\n+                        t.wait(true);\n+                    }\n+                    ChildrenTerminated => break\n+                }\n+            }\n+\n+            let count = shared.count.load(SeqCst);\n+            if count != 0 { ::io::println(fmt!(\"%u\", count)); }\n+            assert!(count == 0);\n+            // self_count is the acquire-read barrier\n+            child_success = shared.success;\n+        }\n+\n+        let total_success = local_success && child_success;\n+\n+        if this.parent.is_some() {\n+            rtdebug!(\"releasing parent\");\n+            unsafe {\n+                let parent_link: &mut ParentLink = this.parent.get_mut_ref();\n+                let shared: *mut SharedState = parent_link.shared;\n+\n+                if !total_success {\n+                    // parent_count is the write-wait barrier\n+                    (*shared).success = false;\n+                }\n+\n+                let last_count = (*shared).count.fetch_sub(1, SeqCst);\n+                rtdebug!(\"count before parent sub %u\", last_count);\n+                if last_count == 1 {\n+                    assert!(parent_link.chan.try_send(ChildrenTerminated));\n+                }\n+            }\n+        }\n+\n+        this.closed = true;\n+        util::ignore(this);\n+\n+        return total_success;\n+    }\n+}\n+\n+impl Drop for JoinLatch {\n+    fn drop(&self) {\n+        rtdebug!(\"DESTROYING %x\", self.id());\n+        rtassert!(self.closed);\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+    use super::*;\n+    use cell::Cell;\n+    use container::Container;\n+    use iter::Times;\n+    use rt::test::*;\n+    use rand;\n+    use rand::RngUtil;\n+    use vec::{CopyableVector, ImmutableVector};\n+\n+    #[test]\n+    fn success_immediately() {\n+        do run_in_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+\n+            let child_latch = latch.new_child();\n+            let child_latch = Cell::new(child_latch);\n+            do spawntask_immediately {\n+                let child_latch = child_latch.take();\n+                assert!(child_latch.wait(true));\n+            }\n+\n+            assert!(latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn success_later() {\n+        do run_in_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+\n+            let child_latch = latch.new_child();\n+            let child_latch = Cell::new(child_latch);\n+            do spawntask_later {\n+                let child_latch = child_latch.take();\n+                assert!(child_latch.wait(true));\n+            }\n+\n+            assert!(latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn mt_success() {\n+        do run_in_mt_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+\n+            for 10.times {\n+                let child_latch = latch.new_child();\n+                let child_latch = Cell::new(child_latch);\n+                do spawntask_random {\n+                    let child_latch = child_latch.take();\n+                    assert!(child_latch.wait(true));\n+                }\n+            }\n+\n+            assert!(latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn mt_failure() {\n+        do run_in_mt_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+\n+            let spawn = |status| {\n+                let child_latch = latch.new_child();\n+                let child_latch = Cell::new(child_latch);\n+                do spawntask_random {\n+                    let child_latch = child_latch.take();\n+                    child_latch.wait(status);\n+                }\n+            };\n+\n+            for 10.times { spawn(true) }\n+            spawn(false);\n+            for 10.times { spawn(true) }\n+\n+            assert!(!latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn mt_multi_level_success() {\n+        do run_in_mt_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+\n+            fn child(latch: &mut JoinLatch, i: int) {\n+                let child_latch = latch.new_child();\n+                let child_latch = Cell::new(child_latch);\n+                do spawntask_random {\n+                    let mut child_latch = child_latch.take();\n+                    if i != 0 {\n+                        child(&mut *child_latch, i - 1);\n+                        child_latch.wait(true);\n+                    } else {\n+                        child_latch.wait(true);\n+                    }\n+                }\n+            }\n+\n+            child(&mut *latch, 10);\n+\n+            assert!(latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn mt_multi_level_failure() {\n+        do run_in_mt_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+\n+            fn child(latch: &mut JoinLatch, i: int) {\n+                let child_latch = latch.new_child();\n+                let child_latch = Cell::new(child_latch);\n+                do spawntask_random {\n+                    let mut child_latch = child_latch.take();\n+                    if i != 0 {\n+                        child(&mut *child_latch, i - 1);\n+                        child_latch.wait(false);\n+                    } else {\n+                        child_latch.wait(true);\n+                    }\n+                }\n+            }\n+\n+            child(&mut *latch, 10);\n+\n+            assert!(!latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn release_child() {\n+        do run_in_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+            let child_latch = latch.new_child();\n+            let child_latch = Cell::new(child_latch);\n+\n+            do spawntask_immediately {\n+                let latch = child_latch.take();\n+                latch.release(false);\n+            }\n+\n+            assert!(!latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn release_child_tombstone() {\n+        do run_in_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+            let child_latch = latch.new_child();\n+            let child_latch = Cell::new(child_latch);\n+\n+            do spawntask_immediately {\n+                let mut latch = child_latch.take();\n+                let child_latch = latch.new_child();\n+                let child_latch = Cell::new(child_latch);\n+                do spawntask_later {\n+                    let latch = child_latch.take();\n+                    latch.release(false);\n+                }\n+                latch.release(true);\n+            }\n+\n+            assert!(!latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn release_child_no_tombstone() {\n+        do run_in_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+            let child_latch = latch.new_child();\n+            let child_latch = Cell::new(child_latch);\n+\n+            do spawntask_later {\n+                let mut latch = child_latch.take();\n+                let child_latch = latch.new_child();\n+                let child_latch = Cell::new(child_latch);\n+                do spawntask_immediately {\n+                    let latch = child_latch.take();\n+                    latch.release(false);\n+                }\n+                latch.release(true);\n+            }\n+\n+            assert!(!latch.wait(true));\n+        }\n+    }\n+\n+    #[test]\n+    fn release_child_tombstone_stress() {\n+        fn rand_orders() -> ~[bool] {\n+            let mut v = ~[false,.. 5];\n+            v[0] = true;\n+            let mut rng = rand::rng();\n+            return rng.shuffle(v);\n+        }\n+\n+        fn split_orders(orders: &[bool]) -> (~[bool], ~[bool]) {\n+            if orders.is_empty() {\n+                return (~[], ~[]);\n+            } else if orders.len() <= 2 {\n+                return (orders.to_owned(), ~[]);\n+            }\n+            let mut rng = rand::rng();\n+            let n = rng.gen_uint_range(1, orders.len());\n+            let first = orders.slice(0, n).to_owned();\n+            let last = orders.slice(n, orders.len()).to_owned();\n+            assert!(first.len() + last.len() == orders.len());\n+            return (first, last);\n+        }\n+\n+        for stress_factor().times {\n+            do run_in_newsched_task {\n+                fn doit(latch: &mut JoinLatch, orders: ~[bool], depth: uint) {\n+                    let (my_orders, remaining_orders) = split_orders(orders);\n+                    rtdebug!(\"(my_orders, remaining): %?\", (&my_orders, &remaining_orders));\n+                    rtdebug!(\"depth: %u\", depth);\n+                    let mut remaining_orders = remaining_orders;\n+                    let mut num = 0;\n+                    for my_orders.iter().advance |&order| {\n+                        let child_latch = latch.new_child();\n+                        let child_latch = Cell::new(child_latch);\n+                        let (child_orders, remaining) = split_orders(remaining_orders);\n+                        rtdebug!(\"(child_orders, remaining): %?\", (&child_orders, &remaining));\n+                        remaining_orders = remaining;\n+                        let child_orders = Cell::new(child_orders);\n+                        let child_num = num;\n+                        let _ = child_num; // XXX unused except in rtdebug!\n+                        do spawntask_random {\n+                            rtdebug!(\"depth %u num %u\", depth, child_num);\n+                            let mut child_latch = child_latch.take();\n+                            let child_orders = child_orders.take();\n+                            doit(&mut *child_latch, child_orders, depth + 1);\n+                            child_latch.release(order);\n+                        }\n+\n+                        num += 1;\n+                    }\n+                }\n+\n+                let mut latch = JoinLatch::new_root();\n+                let orders = rand_orders();\n+                rtdebug!(\"orders: %?\", orders);\n+\n+                doit(&mut *latch, orders, 0);\n+\n+                assert!(!latch.wait(true));\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn whateverman() {\n+        struct Order {\n+            immediate: bool,\n+            succeed: bool,\n+            orders: ~[Order]\n+        }\n+        fn next(latch: &mut JoinLatch, orders: ~[Order]) {\n+            for orders.iter().advance |order| {\n+                let suborders = copy order.orders;\n+                let child_latch = Cell::new(latch.new_child());\n+                let succeed = order.succeed;\n+                if order.immediate {\n+                    do spawntask_immediately {\n+                        let mut child_latch = child_latch.take();\n+                        next(&mut *child_latch, copy suborders);\n+                        rtdebug!(\"immediate releasing\");\n+                        child_latch.release(succeed);\n+                    }\n+                } else {\n+                    do spawntask_later {\n+                        let mut child_latch = child_latch.take();\n+                        next(&mut *child_latch, copy suborders);\n+                        rtdebug!(\"later releasing\");\n+                        child_latch.release(succeed);\n+                    }\n+                }\n+            }\n+        }\n+\n+        do run_in_newsched_task {\n+            let mut latch = JoinLatch::new_root();\n+            let orders = ~[ Order { // 0 0\n+                immediate: true,\n+                succeed: true,\n+                orders: ~[ Order { // 1 0\n+                    immediate: true,\n+                    succeed: false,\n+                    orders: ~[ Order { // 2 0\n+                        immediate: false,\n+                        succeed: false,\n+                        orders: ~[ Order { // 3 0\n+                            immediate: true,\n+                            succeed: false,\n+                            orders: ~[]\n+                        }, Order { // 3 1\n+                            immediate: false,\n+                            succeed: false,\n+                            orders: ~[]\n+                        }]\n+                    }]\n+                }]\n+            }];\n+\n+            next(&mut *latch, orders);\n+            assert!(!latch.wait(true));\n+        }\n+    }\n+}\n+"}, {"sha": "b47bbf3edf0bb99042a6696ff54296eed7b7d19a", "filename": "src/libstd/rt/local.rs", "status": "modified", "additions": 71, "deletions": 32, "changes": 103, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Flocal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Flocal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flocal.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -13,12 +13,13 @@ use rt::sched::Scheduler;\n use rt::task::Task;\n use rt::local_ptr;\n use rt::rtio::{EventLoop, IoFactoryObject};\n+//use borrow::to_uint;\n \n pub trait Local {\n     fn put(value: ~Self);\n     fn take() -> ~Self;\n     fn exists() -> bool;\n-    fn borrow(f: &fn(&mut Self));\n+    fn borrow<T>(f: &fn(&mut Self) -> T) -> T;\n     unsafe fn unsafe_borrow() -> *mut Self;\n     unsafe fn try_unsafe_borrow() -> Option<*mut Self>;\n }\n@@ -27,36 +28,53 @@ impl Local for Scheduler {\n     fn put(value: ~Scheduler) { unsafe { local_ptr::put(value) }}\n     fn take() -> ~Scheduler { unsafe { local_ptr::take() } }\n     fn exists() -> bool { local_ptr::exists() }\n-    fn borrow(f: &fn(&mut Scheduler)) { unsafe { local_ptr::borrow(f) } }\n+    fn borrow<T>(f: &fn(&mut Scheduler) -> T) -> T {\n+        let mut res: Option<T> = None;\n+        let res_ptr: *mut Option<T> = &mut res;\n+        unsafe {\n+            do local_ptr::borrow |sched| {\n+//                rtdebug!(\"successfully unsafe borrowed sched pointer\");\n+                let result = f(sched);\n+                *res_ptr = Some(result);\n+            }\n+        }\n+        match res {\n+            Some(r) => { r }\n+            None => rtabort!(\"function failed!\")\n+        }\n+    }\n     unsafe fn unsafe_borrow() -> *mut Scheduler { local_ptr::unsafe_borrow() }\n-    unsafe fn try_unsafe_borrow() -> Option<*mut Scheduler> { abort!(\"unimpl\") }\n+    unsafe fn try_unsafe_borrow() -> Option<*mut Scheduler> { rtabort!(\"unimpl\") }\n }\n \n impl Local for Task {\n-    fn put(_value: ~Task) { abort!(\"unimpl\") }\n-    fn take() -> ~Task { abort!(\"unimpl\") }\n-    fn exists() -> bool { abort!(\"unimpl\") }\n-    fn borrow(f: &fn(&mut Task)) {\n-        do Local::borrow::<Scheduler> |sched| {\n+    fn put(_value: ~Task) { rtabort!(\"unimpl\") }\n+    fn take() -> ~Task { rtabort!(\"unimpl\") }\n+    fn exists() -> bool { rtabort!(\"unimpl\") }\n+    fn borrow<T>(f: &fn(&mut Task) -> T) -> T {\n+        do Local::borrow::<Scheduler, T> |sched| {\n+//            rtdebug!(\"sched about to grab current_task\");\n             match sched.current_task {\n                 Some(~ref mut task) => {\n-                    f(&mut *task.task)\n+//                    rtdebug!(\"current task pointer: %x\", to_uint(task));\n+//                    rtdebug!(\"current task heap pointer: %x\", to_uint(&task.heap));\n+                    f(task)\n                 }\n                 None => {\n-                    abort!(\"no scheduler\")\n+                    rtabort!(\"no scheduler\")\n                 }\n             }\n         }\n     }\n     unsafe fn unsafe_borrow() -> *mut Task {\n         match (*Local::unsafe_borrow::<Scheduler>()).current_task {\n             Some(~ref mut task) => {\n-                let s: *mut Task = &mut *task.task;\n+                let s: *mut Task = &mut *task;\n                 return s;\n             }\n             None => {\n                 // Don't fail. Infinite recursion\n-                abort!(\"no scheduler\")\n+                rtabort!(\"no scheduler\")\n             }\n         }\n     }\n@@ -71,48 +89,69 @@ impl Local for Task {\n \n // XXX: This formulation won't work once ~IoFactoryObject is a real trait pointer\n impl Local for IoFactoryObject {\n-    fn put(_value: ~IoFactoryObject) { abort!(\"unimpl\") }\n-    fn take() -> ~IoFactoryObject { abort!(\"unimpl\") }\n-    fn exists() -> bool { abort!(\"unimpl\") }\n-    fn borrow(_f: &fn(&mut IoFactoryObject)) { abort!(\"unimpl\") }\n+    fn put(_value: ~IoFactoryObject) { rtabort!(\"unimpl\") }\n+    fn take() -> ~IoFactoryObject { rtabort!(\"unimpl\") }\n+    fn exists() -> bool { rtabort!(\"unimpl\") }\n+    fn borrow<T>(_f: &fn(&mut IoFactoryObject) -> T) -> T { rtabort!(\"unimpl\") }\n     unsafe fn unsafe_borrow() -> *mut IoFactoryObject {\n         let sched = Local::unsafe_borrow::<Scheduler>();\n         let io: *mut IoFactoryObject = (*sched).event_loop.io().unwrap();\n         return io;\n     }\n-    unsafe fn try_unsafe_borrow() -> Option<*mut IoFactoryObject> { abort!(\"unimpl\") }\n+    unsafe fn try_unsafe_borrow() -> Option<*mut IoFactoryObject> { rtabort!(\"unimpl\") }\n }\n \n #[cfg(test)]\n mod test {\n+    use unstable::run_in_bare_thread;\n+    use rt::test::*;\n     use rt::sched::Scheduler;\n-    use rt::uv::uvio::UvEventLoop;\n     use super::*;\n \n     #[test]\n     fn thread_local_scheduler_smoke_test() {\n-        let scheduler = ~UvEventLoop::new_scheduler();\n-        Local::put(scheduler);\n-        let _scheduler: ~Scheduler = Local::take();\n+        do run_in_bare_thread {\n+            let scheduler = ~new_test_uv_sched();\n+            Local::put(scheduler);\n+            let _scheduler: ~Scheduler = Local::take();\n+        }\n     }\n \n     #[test]\n     fn thread_local_scheduler_two_instances() {\n-        let scheduler = ~UvEventLoop::new_scheduler();\n-        Local::put(scheduler);\n-        let _scheduler: ~Scheduler = Local::take();\n-        let scheduler = ~UvEventLoop::new_scheduler();\n-        Local::put(scheduler);\n-        let _scheduler: ~Scheduler = Local::take();\n+        do run_in_bare_thread {\n+            let scheduler = ~new_test_uv_sched();\n+            Local::put(scheduler);\n+            let _scheduler: ~Scheduler = Local::take();\n+            let scheduler = ~new_test_uv_sched();\n+            Local::put(scheduler);\n+            let _scheduler: ~Scheduler = Local::take();\n+        }\n     }\n \n     #[test]\n     fn borrow_smoke_test() {\n-        let scheduler = ~UvEventLoop::new_scheduler();\n-        Local::put(scheduler);\n-        unsafe {\n-            let _scheduler: *mut Scheduler = Local::unsafe_borrow();\n+        do run_in_bare_thread {\n+            let scheduler = ~new_test_uv_sched();\n+            Local::put(scheduler);\n+            unsafe {\n+                let _scheduler: *mut Scheduler = Local::unsafe_borrow();\n+            }\n+            let _scheduler: ~Scheduler = Local::take();\n         }\n-        let _scheduler: ~Scheduler = Local::take();\n     }\n+\n+    #[test]\n+    fn borrow_with_return() {\n+        do run_in_bare_thread {\n+            let scheduler = ~new_test_uv_sched();\n+            Local::put(scheduler);\n+            let res = do Local::borrow::<Scheduler,bool> |_sched| {\n+                true\n+            };\n+            assert!(res);\n+            let _scheduler: ~Scheduler = Local::take();\n+        }\n+    }\n+\n }"}, {"sha": "c909bdb62850aa7d51d5ff31bfedd62aad4f4ba8", "filename": "src/libstd/rt/local_heap.rs", "status": "modified", "additions": 58, "deletions": 1, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Flocal_heap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Flocal_heap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flocal_heap.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -10,11 +10,24 @@\n \n //! The local, garbage collected heap\n \n+use libc;\n use libc::{c_void, uintptr_t, size_t};\n use ops::Drop;\n+use repr::BoxRepr;\n+use rt;\n+use rt::OldTaskContext;\n+use rt::local::Local;\n+use rt::task::Task;\n \n type MemoryRegion = c_void;\n-type BoxedRegion = c_void;\n+\n+struct Env { priv opaque: () }\n+\n+struct BoxedRegion {\n+    env: *Env,\n+    backing_region: *MemoryRegion,\n+    live_allocs: *BoxRepr\n+}\n \n pub type OpaqueBox = c_void;\n pub type TypeDesc = c_void;\n@@ -49,6 +62,12 @@ impl LocalHeap {\n         }\n     }\n \n+    pub fn realloc(&mut self, ptr: *OpaqueBox, size: uint) -> *OpaqueBox {\n+        unsafe {\n+            return rust_boxed_region_realloc(self.boxed_region, ptr, size as size_t);\n+        }\n+    }\n+\n     pub fn free(&mut self, box: *OpaqueBox) {\n         unsafe {\n             return rust_boxed_region_free(self.boxed_region, box);\n@@ -65,6 +84,40 @@ impl Drop for LocalHeap {\n     }\n }\n \n+// A little compatibility function\n+pub unsafe fn local_free(ptr: *libc::c_char) {\n+    match rt::context() {\n+        OldTaskContext => {\n+            rust_upcall_free_noswitch(ptr);\n+\n+            extern {\n+                #[fast_ffi]\n+                unsafe fn rust_upcall_free_noswitch(ptr: *libc::c_char);\n+            }\n+        }\n+        _ => {\n+            do Local::borrow::<Task,()> |task| {\n+                task.heap.free(ptr as *libc::c_void);\n+            }\n+        }\n+    }\n+}\n+\n+pub fn live_allocs() -> *BoxRepr {\n+    let region = match rt::context() {\n+        OldTaskContext => {\n+            unsafe { rust_current_boxed_region() }\n+        }\n+        _ => {\n+            do Local::borrow::<Task, *BoxedRegion> |task| {\n+                task.heap.boxed_region\n+            }\n+        }\n+    };\n+\n+    return unsafe { (*region).live_allocs };\n+}\n+\n extern {\n     fn rust_new_memory_region(synchronized: uintptr_t,\n                                detailed_leaks: uintptr_t,\n@@ -76,5 +129,9 @@ extern {\n     fn rust_boxed_region_malloc(region: *BoxedRegion,\n                                 td: *TypeDesc,\n                                 size: size_t) -> *OpaqueBox;\n+    fn rust_boxed_region_realloc(region: *BoxedRegion,\n+                                 ptr: *OpaqueBox,\n+                                 size: size_t) -> *OpaqueBox;\n     fn rust_boxed_region_free(region: *BoxedRegion, box: *OpaqueBox);\n+    fn rust_current_boxed_region() -> *BoxedRegion;\n }"}, {"sha": "cd7c5daa444d7998970024b414c145ed22491cab", "filename": "src/libstd/rt/local_ptr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Flocal_ptr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Flocal_ptr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flocal_ptr.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -109,7 +109,7 @@ pub unsafe fn unsafe_borrow<T>() -> *mut T {\n fn tls_key() -> tls::Key {\n     match maybe_tls_key() {\n         Some(key) => key,\n-        None => abort!(\"runtime tls key not initialized\")\n+        None => rtabort!(\"runtime tls key not initialized\")\n     }\n }\n "}, {"sha": "84186180aa6500d8dcb4ac6d30b06c4d3b07be95", "filename": "src/libstd/rt/logging.rs", "status": "modified", "additions": 16, "deletions": 4, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Flogging.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Flogging.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flogging.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -9,6 +9,7 @@\n // except according to those terms.\n \n use either::*;\n+use libc;\n \n pub trait Logger {\n     fn log(&mut self, msg: Either<~str, &'static str>);\n@@ -20,6 +21,10 @@ impl Logger for StdErrLogger {\n     fn log(&mut self, msg: Either<~str, &'static str>) {\n         use io::{Writer, WriterUtil};\n \n+        if !should_log_console() {\n+            return;\n+        }\n+\n         let s: &str = match msg {\n             Left(ref s) => {\n                 let s: &str = *s;\n@@ -44,7 +49,6 @@ pub fn init(crate_map: *u8) {\n     use str;\n     use ptr;\n     use option::{Some, None};\n-    use libc::c_char;\n \n     let log_spec = os::getenv(\"RUST_LOG\");\n     match log_spec {\n@@ -61,8 +65,16 @@ pub fn init(crate_map: *u8) {\n             }\n         }\n     }\n+}\n \n-    extern {\n-        fn rust_update_log_settings(crate_map: *u8, settings: *c_char);\n-    }\n+pub fn console_on() { unsafe { rust_log_console_on() } }\n+pub fn console_off() { unsafe { rust_log_console_off() } }\n+fn should_log_console() -> bool { unsafe { rust_should_log_console() != 0 } }\n+\n+extern {\n+    fn rust_update_log_settings(crate_map: *u8, settings: *libc::c_char);\n+    fn rust_log_console_on();\n+    fn rust_log_console_off();\n+    fn rust_should_log_console() -> libc::uintptr_t;\n }\n+"}, {"sha": "6ef07577415d348389623831e47cab26f04b6628", "filename": "src/libstd/rt/message_queue.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fmessage_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fmessage_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmessage_queue.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -8,6 +8,9 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+//! A concurrent queue that supports multiple producers and a\n+//! single consumer.\n+\n use container::Container;\n use kinds::Send;\n use vec::OwnedVector;"}, {"sha": "b0c0fa5d708623d216bdfb58bdf6947da29ada29", "filename": "src/libstd/rt/metrics.rs", "status": "added", "additions": 98, "deletions": 0, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fmetrics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fmetrics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmetrics.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -0,0 +1,98 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use to_str::ToStr;\n+\n+pub struct SchedMetrics {\n+    // The number of times executing `run_sched_once`.\n+    turns: uint,\n+    // The number of turns that received a message.\n+    messages_received: uint,\n+    // The number of turns that ran a task from the queue.\n+    tasks_resumed_from_queue: uint,\n+    // The number of turns that found no work to perform.\n+    wasted_turns: uint,\n+    // The number of times the scheduler went to sleep.\n+    sleepy_times: uint,\n+    // Context switches from the scheduler into a task.\n+    context_switches_sched_to_task: uint,\n+    // Context switches from a task into the scheduler.\n+    context_switches_task_to_sched: uint,\n+    // Context switches from a task to a task.\n+    context_switches_task_to_task: uint,\n+    // Message sends that unblock the receiver\n+    rendezvous_sends: uint,\n+    // Message sends that do not unblock the receiver\n+    non_rendezvous_sends: uint,\n+    // Message receives that do not block the receiver\n+    rendezvous_recvs: uint,\n+    // Message receives that block the receiver\n+    non_rendezvous_recvs: uint,\n+    // JoinLatch releases that create tombstones\n+    release_tombstone: uint,\n+    // JoinLatch releases that do not create tombstones\n+    release_no_tombstone: uint,\n+}\n+\n+impl SchedMetrics {\n+    pub fn new() -> SchedMetrics {\n+        SchedMetrics {\n+            turns: 0,\n+            messages_received: 0,\n+            tasks_resumed_from_queue: 0,\n+            wasted_turns: 0,\n+            sleepy_times: 0,\n+            context_switches_sched_to_task: 0,\n+            context_switches_task_to_sched: 0,\n+            context_switches_task_to_task: 0,\n+            rendezvous_sends: 0,\n+            non_rendezvous_sends: 0,\n+            rendezvous_recvs: 0,\n+            non_rendezvous_recvs: 0,\n+            release_tombstone: 0,\n+            release_no_tombstone: 0\n+        }\n+    }\n+}\n+\n+impl ToStr for SchedMetrics {\n+    fn to_str(&self) -> ~str {\n+        fmt!(\"turns: %u\\n\\\n+              messages_received: %u\\n\\\n+              tasks_resumed_from_queue: %u\\n\\\n+              wasted_turns: %u\\n\\\n+              sleepy_times: %u\\n\\\n+              context_switches_sched_to_task: %u\\n\\\n+              context_switches_task_to_sched: %u\\n\\\n+              context_switches_task_to_task: %u\\n\\\n+              rendezvous_sends: %u\\n\\\n+              non_rendezvous_sends: %u\\n\\\n+              rendezvous_recvs: %u\\n\\\n+              non_rendezvous_recvs: %u\\n\\\n+              release_tombstone: %u\\n\\\n+              release_no_tombstone: %u\\n\\\n+              \",\n+             self.turns,\n+             self.messages_received,\n+             self.tasks_resumed_from_queue,\n+             self.wasted_turns,\n+             self.sleepy_times,\n+             self.context_switches_sched_to_task,\n+             self.context_switches_task_to_sched,\n+             self.context_switches_task_to_task,\n+             self.rendezvous_sends,\n+             self.non_rendezvous_sends,\n+             self.rendezvous_recvs,\n+             self.non_rendezvous_recvs,\n+             self.release_tombstone,\n+             self.release_no_tombstone\n+        )\n+    }\n+}\n\\ No newline at end of file"}, {"sha": "51f4737ef85fb0561cbd4472d2b1b02633e48cf7", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 161, "deletions": 28, "changes": 189, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -55,8 +55,27 @@ Several modules in `core` are clients of `rt`:\n */\n \n #[doc(hidden)];\n-\n+#[deny(unused_imports)];\n+#[deny(unused_mut)];\n+#[deny(unused_variable)];\n+#[deny(unused_unsafe)];\n+\n+use cell::Cell;\n+use clone::Clone;\n+use container::Container;\n+use iter::Times;\n+use iterator::IteratorUtil;\n+use option::Some;\n use ptr::RawPtr;\n+use rt::sched::{Scheduler, Shutdown};\n+use rt::sleeper_list::SleeperList;\n+use rt::task::Task;\n+use rt::thread::Thread;\n+use rt::work_queue::WorkQueue;\n+use rt::uv::uvio::UvEventLoop;\n+use unstable::atomics::{AtomicInt, SeqCst};\n+use unstable::sync::UnsafeAtomicRcBox;\n+use vec::{OwnedVector, MutableVector};\n \n /// The global (exchange) heap.\n pub mod global_heap;\n@@ -88,6 +107,9 @@ mod work_queue;\n /// A parallel queue.\n mod message_queue;\n \n+/// A parallel data structure for tracking sleeping schedulers.\n+mod sleeper_list;\n+\n /// Stack segments and caching.\n mod stack;\n \n@@ -101,7 +123,7 @@ mod thread;\n pub mod env;\n \n /// The local, managed heap\n-mod local_heap;\n+pub mod local_heap;\n \n /// The Logger trait and implementations\n pub mod logging;\n@@ -127,6 +149,20 @@ pub mod local_ptr;\n /// Bindings to pthread/windows thread-local storage.\n pub mod thread_local_storage;\n \n+/// For waiting on child tasks.\n+pub mod join_latch;\n+\n+pub mod metrics;\n+\n+// FIXME #5248 shouldn't be pub\n+/// Just stuff\n+pub mod util;\n+\n+// Global command line argument storage\n+pub mod args;\n+\n+// Support for dynamic borrowck\n+pub mod borrowck;\n \n /// Set up a default runtime configuration, given compiler-supplied arguments.\n ///\n@@ -142,27 +178,128 @@ pub mod thread_local_storage;\n /// # Return value\n ///\n /// The return value is used as the process return code. 0 on success, 101 on error.\n-pub fn start(_argc: int, _argv: **u8, crate_map: *u8, main: ~fn()) -> int {\n+pub fn start(argc: int, argv: **u8, crate_map: *u8, main: ~fn()) -> int {\n \n-    use self::sched::{Scheduler, Coroutine};\n-    use self::uv::uvio::UvEventLoop;\n+    init(argc, argv, crate_map);\n+    let exit_code = run(main);\n+    cleanup();\n \n-    init(crate_map);\n+    return exit_code;\n+}\n \n-    let loop_ = ~UvEventLoop::new();\n-    let mut sched = ~Scheduler::new(loop_);\n-    let main_task = ~Coroutine::new(&mut sched.stack_pool, main);\n+/// One-time runtime initialization.\n+///\n+/// Initializes global state, including frobbing\n+/// the crate's logging flags, registering GC\n+/// metadata, and storing the process arguments.\n+pub fn init(argc: int, argv: **u8, crate_map: *u8) {\n+    // XXX: Derefing these pointers is not safe.\n+    // Need to propagate the unsafety to `start`.\n+    unsafe {\n+        args::init(argc, argv);\n+        logging::init(crate_map);\n+        rust_update_gc_metadata(crate_map);\n+    }\n \n-    sched.enqueue_task(main_task);\n-    sched.run();\n+    extern {\n+        fn rust_update_gc_metadata(crate_map: *u8);\n+    }\n+}\n \n-    return 0;\n+/// One-time runtime cleanup.\n+pub fn cleanup() {\n+    args::cleanup();\n }\n \n-/// One-time runtime initialization. Currently all this does is set up logging\n-/// based on the RUST_LOG environment variable.\n-pub fn init(crate_map: *u8) {\n-    logging::init(crate_map);\n+/// Execute the main function in a scheduler.\n+///\n+/// Configures the runtime according to the environment, by default\n+/// using a task scheduler with the same number of threads as cores.\n+/// Returns a process exit code.\n+pub fn run(main: ~fn()) -> int {\n+\n+    static DEFAULT_ERROR_CODE: int = 101;\n+\n+    let nthreads = util::default_sched_threads();\n+\n+    // The shared list of sleeping schedulers. Schedulers wake each other\n+    // occassionally to do new work.\n+    let sleepers = SleeperList::new();\n+    // The shared work queue. Temporary until work stealing is implemented.\n+    let work_queue = WorkQueue::new();\n+\n+    // The schedulers.\n+    let mut scheds = ~[];\n+    // Handles to the schedulers. When the main task ends these will be\n+    // sent the Shutdown message to terminate the schedulers.\n+    let mut handles = ~[];\n+\n+    for nthreads.times {\n+        // Every scheduler is driven by an I/O event loop.\n+        let loop_ = ~UvEventLoop::new();\n+        let mut sched = ~Scheduler::new(loop_, work_queue.clone(), sleepers.clone());\n+        let handle = sched.make_handle();\n+\n+        scheds.push(sched);\n+        handles.push(handle);\n+    }\n+\n+    // Create a shared cell for transmitting the process exit\n+    // code from the main task to this function.\n+    let exit_code = UnsafeAtomicRcBox::new(AtomicInt::new(0));\n+    let exit_code_clone = exit_code.clone();\n+\n+    // When the main task exits, after all the tasks in the main\n+    // task tree, shut down the schedulers and set the exit code.\n+    let handles = Cell::new(handles);\n+    let on_exit: ~fn(bool) = |exit_success| {\n+\n+        let mut handles = handles.take();\n+        for handles.mut_iter().advance |handle| {\n+            handle.send(Shutdown);\n+        }\n+\n+        unsafe {\n+            let exit_code = if exit_success {\n+                use rt::util;\n+\n+                // If we're exiting successfully, then return the global\n+                // exit status, which can be set programmatically.\n+                util::get_exit_status()\n+            } else {\n+                DEFAULT_ERROR_CODE\n+            };\n+            (*exit_code_clone.get()).store(exit_code, SeqCst);\n+        }\n+    };\n+\n+    // Create and enqueue the main task.\n+    let main_cell = Cell::new(main);\n+    let mut main_task = ~Task::new_root(&mut scheds[0].stack_pool,\n+                                    main_cell.take());\n+    main_task.on_exit = Some(on_exit);\n+    scheds[0].enqueue_task(main_task);\n+\n+    // Run each scheduler in a thread.\n+    let mut threads = ~[];\n+    while !scheds.is_empty() {\n+        let sched = scheds.pop();\n+        let sched_cell = Cell::new(sched);\n+        let thread = do Thread::start {\n+            let sched = sched_cell.take();\n+            sched.run();\n+        };\n+\n+        threads.push(thread);\n+    }\n+\n+    // Wait for schedulers\n+    { let _threads = threads; }\n+\n+    // Return the exit code\n+    unsafe {\n+        (*exit_code.get()).load(SeqCst)\n+    }\n }\n \n /// Possible contexts in which Rust code may be executing.\n@@ -194,8 +331,8 @@ pub fn context() -> RuntimeContext {\n         return OldTaskContext;\n     } else {\n         if Local::exists::<Scheduler>() {\n-            let context = ::cell::Cell::new_empty();\n-            do Local::borrow::<Scheduler> |sched| {\n+            let context = Cell::new_empty();\n+            do Local::borrow::<Scheduler, ()> |sched| {\n                 if sched.in_task_context() {\n                     context.put_back(TaskContext);\n                 } else {\n@@ -217,24 +354,20 @@ pub fn context() -> RuntimeContext {\n #[test]\n fn test_context() {\n     use unstable::run_in_bare_thread;\n-    use self::sched::{Scheduler, Coroutine};\n-    use rt::uv::uvio::UvEventLoop;\n-    use cell::Cell;\n+    use self::sched::{Scheduler};\n     use rt::local::Local;\n+    use rt::test::new_test_uv_sched;\n \n     assert_eq!(context(), OldTaskContext);\n     do run_in_bare_thread {\n         assert_eq!(context(), GlobalContext);\n-        let mut sched = ~UvEventLoop::new_scheduler();\n-        let task = ~do Coroutine::new(&mut sched.stack_pool) {\n+        let mut sched = ~new_test_uv_sched();\n+        let task = ~do Task::new_root(&mut sched.stack_pool) {\n             assert_eq!(context(), TaskContext);\n             let sched = Local::take::<Scheduler>();\n-            do sched.deschedule_running_task_and_then() |task| {\n+            do sched.deschedule_running_task_and_then() |sched, task| {\n                 assert_eq!(context(), SchedulerContext);\n-                let task = Cell::new(task);\n-                do Local::borrow::<Scheduler> |sched| {\n-                    sched.enqueue_task(task.take());\n-                }\n+                sched.enqueue_task(task);\n             }\n         };\n         sched.enqueue_task(task);"}, {"sha": "6bf352ee1447f94a65aa88aca71af961a8a1990b", "filename": "src/libstd/rt/rtio.rs", "status": "modified", "additions": 45, "deletions": 4, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Frtio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Frtio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Frtio.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -18,28 +18,69 @@ use rt::uv::uvio;\n // XXX: ~object doesn't work currently so these are some placeholder\n // types to use instead\n pub type EventLoopObject = uvio::UvEventLoop;\n+pub type RemoteCallbackObject = uvio::UvRemoteCallback;\n pub type IoFactoryObject = uvio::UvIoFactory;\n pub type RtioTcpStreamObject = uvio::UvTcpStream;\n pub type RtioTcpListenerObject = uvio::UvTcpListener;\n+pub type RtioUdpSocketObject = uvio::UvUdpSocket;\n \n pub trait EventLoop {\n     fn run(&mut self);\n     fn callback(&mut self, ~fn());\n     fn callback_ms(&mut self, ms: u64, ~fn());\n+    fn remote_callback(&mut self, ~fn()) -> ~RemoteCallbackObject;\n     /// The asynchronous I/O services. Not all event loops may provide one\n     fn io<'a>(&'a mut self) -> Option<&'a mut IoFactoryObject>;\n }\n \n+pub trait RemoteCallback {\n+    /// Trigger the remote callback. Note that the number of times the callback\n+    /// is run is not guaranteed. All that is guaranteed is that, after calling 'fire',\n+    /// the callback will be called at least once, but multiple callbacks may be coalesced\n+    /// and callbacks may be called more often requested. Destruction also triggers the\n+    /// callback.\n+    fn fire(&mut self);\n+}\n+\n pub trait IoFactory {\n     fn tcp_connect(&mut self, addr: IpAddr) -> Result<~RtioTcpStreamObject, IoError>;\n     fn tcp_bind(&mut self, addr: IpAddr) -> Result<~RtioTcpListenerObject, IoError>;\n+    fn udp_bind(&mut self, addr: IpAddr) -> Result<~RtioUdpSocketObject, IoError>;\n }\n \n-pub trait RtioTcpListener {\n+pub trait RtioTcpListener : RtioSocket {\n     fn accept(&mut self) -> Result<~RtioTcpStreamObject, IoError>;\n+    fn accept_simultaneously(&self);\n+    fn dont_accept_simultaneously(&self);\n+}\n+\n+pub trait RtioTcpStream : RtioSocket {\n+    fn read(&self, buf: &mut [u8]) -> Result<uint, IoError>;\n+    fn write(&self, buf: &[u8]) -> Result<(), IoError>;\n+    fn peer_name(&self) -> IpAddr;\n+    fn control_congestion(&self);\n+    fn nodelay(&self);\n+    fn keepalive(&self, delay_in_seconds: uint);\n+    fn letdie(&self);\n+}\n+\n+pub trait RtioSocket {\n+    fn socket_name(&self) -> IpAddr;\n }\n \n-pub trait RtioTcpStream {\n-    fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError>;\n-    fn write(&mut self, buf: &[u8]) -> Result<(), IoError>;\n+pub trait RtioUdpSocket : RtioSocket {\n+    fn recvfrom(&self, buf: &mut [u8]) -> Result<(uint, IpAddr), IoError>;\n+    fn sendto(&self, buf: &[u8], dst: IpAddr) -> Result<(), IoError>;\n+\n+    fn join_multicast(&self, multi: IpAddr);\n+    fn leave_multicast(&self, multi: IpAddr);\n+\n+    fn loop_multicast_locally(&self);\n+    fn dont_loop_multicast_locally(&self);\n+\n+    fn multicast_time_to_live(&self, ttl: int);\n+    fn time_to_live(&self, ttl: int);\n+\n+    fn hear_broadcasts(&self);\n+    fn ignore_broadcasts(&self);\n }"}, {"sha": "6e9aef77730519068c7173e65103adb7e99208a4", "filename": "src/libstd/rt/sched.rs", "status": "modified", "additions": 741, "deletions": 152, "changes": 893, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fsched.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -11,67 +11,118 @@\n use option::*;\n use sys;\n use cast::transmute;\n-use cell::Cell;\n+use clone::Clone;\n \n+use super::sleeper_list::SleeperList;\n use super::work_queue::WorkQueue;\n-use super::stack::{StackPool, StackSegment};\n-use super::rtio::{EventLoop, EventLoopObject};\n+use super::stack::{StackPool};\n+use super::rtio::{EventLoop, EventLoopObject, RemoteCallbackObject};\n use super::context::Context;\n-use super::task::Task;\n+use super::task::{Task, AnySched, Sched};\n+use super::message_queue::MessageQueue;\n use rt::local_ptr;\n use rt::local::Local;\n+use rt::rtio::RemoteCallback;\n+use rt::metrics::SchedMetrics;\n+use borrow::{to_uint};\n \n /// The Scheduler is responsible for coordinating execution of Coroutines\n /// on a single thread. When the scheduler is running it is owned by\n /// thread local storage and the running task is owned by the\n /// scheduler.\n+///\n+/// XXX: This creates too many callbacks to run_sched_once, resulting\n+/// in too much allocation and too many events.\n pub struct Scheduler {\n-    priv work_queue: WorkQueue<~Coroutine>,\n+    /// A queue of available work. Under a work-stealing policy there\n+    /// is one per Scheduler.\n+    priv work_queue: WorkQueue<~Task>,\n+    /// The queue of incoming messages from other schedulers.\n+    /// These are enqueued by SchedHandles after which a remote callback\n+    /// is triggered to handle the message.\n+    priv message_queue: MessageQueue<SchedMessage>,\n+    /// A shared list of sleeping schedulers. We'll use this to wake\n+    /// up schedulers when pushing work onto the work queue.\n+    priv sleeper_list: SleeperList,\n+    /// Indicates that we have previously pushed a handle onto the\n+    /// SleeperList but have not yet received the Wake message.\n+    /// Being `true` does not necessarily mean that the scheduler is\n+    /// not active since there are multiple event sources that may\n+    /// wake the scheduler. It just prevents the scheduler from pushing\n+    /// multiple handles onto the sleeper list.\n+    priv sleepy: bool,\n+    /// A flag to indicate we've received the shutdown message and should\n+    /// no longer try to go to sleep, but exit instead.\n+    no_sleep: bool,\n     stack_pool: StackPool,\n     /// The event loop used to drive the scheduler and perform I/O\n     event_loop: ~EventLoopObject,\n     /// The scheduler's saved context.\n     /// Always valid when a task is executing, otherwise not\n     priv saved_context: Context,\n     /// The currently executing task\n-    current_task: Option<~Coroutine>,\n+    current_task: Option<~Task>,\n     /// An action performed after a context switch on behalf of the\n     /// code running before the context switch\n-    priv cleanup_job: Option<CleanupJob>\n+    priv cleanup_job: Option<CleanupJob>,\n+    metrics: SchedMetrics,\n+    /// Should this scheduler run any task, or only pinned tasks?\n+    run_anything: bool\n }\n \n-// XXX: Some hacks to put a &fn in Scheduler without borrowck\n-// complaining\n-type UnsafeTaskReceiver = sys::Closure;\n-trait ClosureConverter {\n-    fn from_fn(&fn(~Coroutine)) -> Self;\n-    fn to_fn(self) -> &fn(~Coroutine);\n+pub struct SchedHandle {\n+    priv remote: ~RemoteCallbackObject,\n+    priv queue: MessageQueue<SchedMessage>,\n+    sched_id: uint\n }\n-impl ClosureConverter for UnsafeTaskReceiver {\n-    fn from_fn(f: &fn(~Coroutine)) -> UnsafeTaskReceiver { unsafe { transmute(f) } }\n-    fn to_fn(self) -> &fn(~Coroutine) { unsafe { transmute(self) } }\n+\n+pub enum SchedMessage {\n+    Wake,\n+    Shutdown,\n+    PinnedTask(~Task)\n }\n \n enum CleanupJob {\n     DoNothing,\n-    GiveTask(~Coroutine, UnsafeTaskReceiver)\n+    GiveTask(~Task, UnsafeTaskReceiver)\n }\n \n impl Scheduler {\n     pub fn in_task_context(&self) -> bool { self.current_task.is_some() }\n \n-    pub fn new(event_loop: ~EventLoopObject) -> Scheduler {\n+    pub fn sched_id(&self) -> uint { to_uint(self) }\n+\n+    pub fn new(event_loop: ~EventLoopObject,\n+               work_queue: WorkQueue<~Task>,\n+               sleeper_list: SleeperList)\n+        -> Scheduler {\n+\n+        Scheduler::new_special(event_loop, work_queue, sleeper_list, true)\n+\n+    }\n+\n+    pub fn new_special(event_loop: ~EventLoopObject,\n+                       work_queue: WorkQueue<~Task>,\n+                       sleeper_list: SleeperList,\n+                       run_anything: bool)\n+        -> Scheduler {\n \n         // Lazily initialize the runtime TLS key\n         local_ptr::init_tls_key();\n \n         Scheduler {\n+            sleeper_list: sleeper_list,\n+            message_queue: MessageQueue::new(),\n+            sleepy: false,\n+            no_sleep: false,\n             event_loop: event_loop,\n-            work_queue: WorkQueue::new(),\n+            work_queue: work_queue,\n             stack_pool: StackPool::new(),\n             saved_context: Context::empty(),\n             current_task: None,\n-            cleanup_job: None\n+            cleanup_job: None,\n+            metrics: SchedMetrics::new(),\n+            run_anything: run_anything\n         }\n     }\n \n@@ -84,6 +135,11 @@ impl Scheduler {\n \n         let mut self_sched = self;\n \n+        // Always run through the scheduler loop at least once so that\n+        // we enter the sleep state and can then be woken up by other\n+        // schedulers.\n+        self_sched.event_loop.callback(Scheduler::run_sched_once);\n+\n         unsafe {\n             let event_loop: *mut ~EventLoopObject = {\n                 let event_loop: *mut ~EventLoopObject = &mut self_sched.event_loop;\n@@ -96,46 +152,261 @@ impl Scheduler {\n             (*event_loop).run();\n         }\n \n+        rtdebug!(\"run taking sched\");\n         let sched = Local::take::<Scheduler>();\n-        assert!(sched.work_queue.is_empty());\n+        // XXX: Reenable this once we're using a per-scheduler queue. With a shared\n+        // queue this is not true\n+        //assert!(sched.work_queue.is_empty());\n+        rtdebug!(\"scheduler metrics: %s\\n\", {\n+            use to_str::ToStr;\n+            sched.metrics.to_str()\n+        });\n         return sched;\n     }\n \n+    fn run_sched_once() {\n+\n+        let mut sched = Local::take::<Scheduler>();\n+        sched.metrics.turns += 1;\n+\n+        // First, check the message queue for instructions.\n+        // XXX: perf. Check for messages without atomics.\n+        // It's ok if we miss messages occasionally, as long as\n+        // we sync and check again before sleeping.\n+        if sched.interpret_message_queue() {\n+            // We performed a scheduling action. There may be other work\n+            // to do yet, so let's try again later.\n+            rtdebug!(\"run_sched_once, interpret_message_queue taking sched\");\n+            let mut sched = Local::take::<Scheduler>();\n+            sched.metrics.messages_received += 1;\n+            sched.event_loop.callback(Scheduler::run_sched_once);\n+            Local::put(sched);\n+            return;\n+        }\n+\n+        // Now, look in the work queue for tasks to run\n+        rtdebug!(\"run_sched_once taking\");\n+        let sched = Local::take::<Scheduler>();\n+        if sched.resume_task_from_queue() {\n+            // We performed a scheduling action. There may be other work\n+            // to do yet, so let's try again later.\n+            do Local::borrow::<Scheduler, ()> |sched| {\n+                sched.metrics.tasks_resumed_from_queue += 1;\n+                sched.event_loop.callback(Scheduler::run_sched_once);\n+            }\n+            return;\n+        }\n+\n+        // If we got here then there was no work to do.\n+        // Generate a SchedHandle and push it to the sleeper list so\n+        // somebody can wake us up later.\n+        rtdebug!(\"no work to do\");\n+        do Local::borrow::<Scheduler, ()> |sched| {\n+            sched.metrics.wasted_turns += 1;\n+            if !sched.sleepy && !sched.no_sleep {\n+                rtdebug!(\"sleeping\");\n+                sched.metrics.sleepy_times += 1;\n+                sched.sleepy = true;\n+                let handle = sched.make_handle();\n+                sched.sleeper_list.push(handle);\n+            } else {\n+                rtdebug!(\"not sleeping\");\n+            }\n+        }\n+    }\n+\n+    pub fn make_handle(&mut self) -> SchedHandle {\n+        let remote = self.event_loop.remote_callback(Scheduler::run_sched_once);\n+\n+        return SchedHandle {\n+            remote: remote,\n+            queue: self.message_queue.clone(),\n+            sched_id: self.sched_id()\n+        };\n+    }\n+\n     /// Schedule a task to be executed later.\n     ///\n-    /// Pushes the task onto the work stealing queue and tells the event loop\n-    /// to run it later. Always use this instead of pushing to the work queue\n-    /// directly.\n-    pub fn enqueue_task(&mut self, task: ~Coroutine) {\n-        self.work_queue.push(task);\n-        self.event_loop.callback(resume_task_from_queue);\n+    /// Pushes the task onto the work stealing queue and tells the\n+    /// event loop to run it later. Always use this instead of pushing\n+    /// to the work queue directly.\n+    pub fn enqueue_task(&mut self, task: ~Task) {\n \n-        fn resume_task_from_queue() {\n-            let scheduler = Local::take::<Scheduler>();\n-            scheduler.resume_task_from_queue();\n-        }\n+        // We don't want to queue tasks that belong on other threads,\n+        // so we send them home at enqueue time.\n+\n+        // The borrow checker doesn't like our disassembly of the\n+        // Coroutine struct and partial use and mutation of the\n+        // fields. So completely disassemble here and stop using?\n+\n+        // XXX perf: I think we might be able to shuffle this code to\n+        // only destruct when we need to.\n+\n+        rtdebug!(\"a task was queued on: %u\", self.sched_id());\n+\n+        let this = self;\n+\n+        // We push the task onto our local queue clone.\n+        this.work_queue.push(task);\n+        this.event_loop.callback(Scheduler::run_sched_once);\n+\n+        // We've made work available. Notify a\n+        // sleeping scheduler.\n+\n+        // XXX: perf. Check for a sleeper without\n+        // synchronizing memory.  It's not critical\n+        // that we always find it.\n+\n+        // XXX: perf. If there's a sleeper then we\n+        // might as well just send it the task\n+        // directly instead of pushing it to the\n+        // queue. That is essentially the intent here\n+        // and it is less work.\n+        match this.sleeper_list.pop() {\n+            Some(handle) => {\n+                let mut handle = handle;\n+                handle.send(Wake)\n+            }\n+            None => { (/* pass */) }\n+        };\n     }\n \n     // * Scheduler-context operations\n \n-    pub fn resume_task_from_queue(~self) {\n+    fn interpret_message_queue(~self) -> bool {\n         assert!(!self.in_task_context());\n \n-        rtdebug!(\"looking in work queue for task to schedule\");\n+        rtdebug!(\"looking for scheduler messages\");\n \n         let mut this = self;\n-        match this.work_queue.pop() {\n-            Some(task) => {\n-                rtdebug!(\"resuming task from work queue\");\n+        match this.message_queue.pop() {\n+            Some(PinnedTask(task)) => {\n+                rtdebug!(\"recv BiasedTask message in sched: %u\",\n+                         this.sched_id());\n+                let mut task = task;\n+                task.home = Some(Sched(this.make_handle()));\n                 this.resume_task_immediately(task);\n+                return true;\n+            }\n+\n+            Some(Wake) => {\n+                rtdebug!(\"recv Wake message\");\n+                this.sleepy = false;\n+                Local::put(this);\n+                return true;\n+            }\n+            Some(Shutdown) => {\n+                rtdebug!(\"recv Shutdown message\");\n+                if this.sleepy {\n+                    // There may be an outstanding handle on the\n+                    // sleeper list.  Pop them all to make sure that's\n+                    // not the case.\n+                    loop {\n+                        match this.sleeper_list.pop() {\n+                            Some(handle) => {\n+                                let mut handle = handle;\n+                                handle.send(Wake);\n+                            }\n+                            None => break\n+                        }\n+                    }\n+                }\n+                // No more sleeping. After there are no outstanding\n+                // event loop references we will shut down.\n+                this.no_sleep = true;\n+                this.sleepy = false;\n+                Local::put(this);\n+                return true;\n             }\n             None => {\n-                rtdebug!(\"no tasks in queue\");\n                 Local::put(this);\n+                return false;\n+            }\n+        }\n+    }\n+\n+    /// Given an input Coroutine sends it back to its home scheduler.\n+    fn send_task_home(task: ~Task) {\n+        let mut task = task;\n+        let mut home = task.home.swap_unwrap();\n+        match home {\n+            Sched(ref mut home_handle) => {\n+                home_handle.send(PinnedTask(task));\n+            }\n+            AnySched => {\n+                rtabort!(\"error: cannot send anysched task home\");\n             }\n         }\n     }\n \n+    // Resume a task from the queue - but also take into account that\n+    // it might not belong here.\n+    fn resume_task_from_queue(~self) -> bool {\n+        assert!(!self.in_task_context());\n+\n+        rtdebug!(\"looking in work queue for task to schedule\");\n+        let mut this = self;\n+\n+        // The borrow checker imposes the possibly absurd requirement\n+        // that we split this into two match expressions. This is due\n+        // to the inspection of the internal bits of task, as that\n+        // can't be in scope when we act on task.\n+        match this.work_queue.pop() {\n+            Some(task) => {\n+                let action_id = {\n+                    let home = &task.home;\n+                    match home {\n+                        &Some(Sched(ref home_handle))\n+                        if home_handle.sched_id != this.sched_id() => {\n+                            SendHome\n+                        }\n+                        &Some(AnySched) if this.run_anything => {\n+                            ResumeNow\n+                        }\n+                        &Some(AnySched) => {\n+                            Requeue\n+                        }\n+                        &Some(Sched(_)) => {\n+                            ResumeNow\n+                        }\n+                        &None => {\n+                            Homeless\n+                        }\n+                    }\n+                };\n+\n+                match action_id {\n+                    SendHome => {\n+                        rtdebug!(\"sending task home\");\n+                        Scheduler::send_task_home(task);\n+                        Local::put(this);\n+                        return false;\n+                    }\n+                    ResumeNow => {\n+                        rtdebug!(\"resuming now\");\n+                        this.resume_task_immediately(task);\n+                        return true;\n+                    }\n+                    Requeue => {\n+                        rtdebug!(\"re-queueing\")\n+                        this.enqueue_task(task);\n+                        Local::put(this);\n+                        return false;\n+                    }\n+                    Homeless => {\n+                        rtabort!(\"task home was None!\");\n+                    }\n+                }\n+            }\n+\n+            None => {\n+               rtdebug!(\"no tasks in queue\");\n+               Local::put(this);\n+               return false;\n+           }\n+        }\n+    }\n+\n     // * Task-context operations\n \n     /// Called by a running task to end execution, after which it will\n@@ -145,45 +416,51 @@ impl Scheduler {\n \n         rtdebug!(\"ending running task\");\n \n-        do self.deschedule_running_task_and_then |dead_task| {\n-            let dead_task = Cell::new(dead_task);\n-            do Local::borrow::<Scheduler> |sched| {\n-                dead_task.take().recycle(&mut sched.stack_pool);\n-            }\n+        do self.deschedule_running_task_and_then |sched, dead_task| {\n+            let mut dead_task = dead_task;\n+            let coroutine = dead_task.coroutine.swap_unwrap();\n+            coroutine.recycle(&mut sched.stack_pool);\n         }\n \n-        abort!(\"control reached end of task\");\n+        rtabort!(\"control reached end of task\");\n     }\n \n-    pub fn schedule_new_task(~self, task: ~Coroutine) {\n+    pub fn schedule_task(~self, task: ~Task) {\n         assert!(self.in_task_context());\n \n-        do self.switch_running_tasks_and_then(task) |last_task| {\n-            let last_task = Cell::new(last_task);\n-            do Local::borrow::<Scheduler> |sched| {\n-                sched.enqueue_task(last_task.take());\n-            }\n-        }\n-    }\n+        // is the task home?\n+        let is_home = task.is_home_no_tls(&self);\n \n-    pub fn schedule_task(~self, task: ~Coroutine) {\n-        assert!(self.in_task_context());\n+        // does the task have a home?\n+        let homed = task.homed();\n \n-        do self.switch_running_tasks_and_then(task) |last_task| {\n-            let last_task = Cell::new(last_task);\n-            do Local::borrow::<Scheduler> |sched| {\n-                sched.enqueue_task(last_task.take());\n+        let mut this = self;\n+\n+        if is_home || (!homed && this.run_anything) {\n+            // here we know we are home, execute now OR we know we\n+            // aren't homed, and that this sched doesn't care\n+            do this.switch_running_tasks_and_then(task) |sched, last_task| {\n+                sched.enqueue_task(last_task);\n             }\n+        } else if !homed && !this.run_anything {\n+            // the task isn't homed, but it can't be run here\n+            this.enqueue_task(task);\n+            Local::put(this);\n+        } else {\n+            // task isn't home, so don't run it here, send it home\n+            Scheduler::send_task_home(task);\n+            Local::put(this);\n         }\n     }\n \n     // Core scheduling ops\n \n-    pub fn resume_task_immediately(~self, task: ~Coroutine) {\n+    pub fn resume_task_immediately(~self, task: ~Task) {\n         let mut this = self;\n         assert!(!this.in_task_context());\n \n         rtdebug!(\"scheduling a task\");\n+        this.metrics.context_switches_sched_to_task += 1;\n \n         // Store the task in the scheduler so it can be grabbed later\n         this.current_task = Some(task);\n@@ -217,15 +494,21 @@ impl Scheduler {\n     /// The closure here is a *stack* closure that lives in the\n     /// running task.  It gets transmuted to the scheduler's lifetime\n     /// and called while the task is blocked.\n-    pub fn deschedule_running_task_and_then(~self, f: &fn(~Coroutine)) {\n+    ///\n+    /// This passes a Scheduler pointer to the fn after the context switch\n+    /// in order to prevent that fn from performing further scheduling operations.\n+    /// Doing further scheduling could easily result in infinite recursion.\n+    pub fn deschedule_running_task_and_then(~self, f: &fn(&mut Scheduler, ~Task)) {\n         let mut this = self;\n         assert!(this.in_task_context());\n \n         rtdebug!(\"blocking task\");\n+        this.metrics.context_switches_task_to_sched += 1;\n \n         unsafe {\n             let blocked_task = this.current_task.swap_unwrap();\n-            let f_fake_region = transmute::<&fn(~Coroutine), &fn(~Coroutine)>(f);\n+            let f_fake_region = transmute::<&fn(&mut Scheduler, ~Task),\n+                                            &fn(&mut Scheduler, ~Task)>(f);\n             let f_opaque = ClosureConverter::from_fn(f_fake_region);\n             this.enqueue_cleanup_job(GiveTask(blocked_task, f_opaque));\n         }\n@@ -247,16 +530,19 @@ impl Scheduler {\n     /// Switch directly to another task, without going through the scheduler.\n     /// You would want to think hard about doing this, e.g. if there are\n     /// pending I/O events it would be a bad idea.\n-    pub fn switch_running_tasks_and_then(~self,\n-                                         next_task: ~Coroutine,\n-                                         f: &fn(~Coroutine)) {\n+    pub fn switch_running_tasks_and_then(~self, next_task: ~Task,\n+                                         f: &fn(&mut Scheduler, ~Task)) {\n         let mut this = self;\n         assert!(this.in_task_context());\n \n         rtdebug!(\"switching tasks\");\n+        this.metrics.context_switches_task_to_task += 1;\n \n         let old_running_task = this.current_task.swap_unwrap();\n-        let f_fake_region = unsafe { transmute::<&fn(~Coroutine), &fn(~Coroutine)>(f) };\n+        let f_fake_region = unsafe {\n+            transmute::<&fn(&mut Scheduler, ~Task),\n+                        &fn(&mut Scheduler, ~Task)>(f)\n+        };\n         let f_opaque = ClosureConverter::from_fn(f_fake_region);\n         this.enqueue_cleanup_job(GiveTask(old_running_task, f_opaque));\n         this.current_task = Some(next_task);\n@@ -293,7 +579,7 @@ impl Scheduler {\n         let cleanup_job = self.cleanup_job.swap_unwrap();\n         match cleanup_job {\n             DoNothing => { }\n-            GiveTask(task, f) => (f.to_fn())(task)\n+            GiveTask(task, f) => (f.to_fn())(self, task)\n         }\n     }\n \n@@ -322,12 +608,22 @@ impl Scheduler {\n         // because borrowck thinks the three patterns are conflicting\n         // borrows\n         unsafe {\n-            let last_task = transmute::<Option<&Coroutine>, Option<&mut Coroutine>>(last_task);\n+            let last_task = transmute::<Option<&Task>, Option<&mut Task>>(last_task);\n             let last_task_context = match last_task {\n-                Some(t) => Some(&mut t.saved_context), None => None\n+                Some(t) => {\n+                    Some(&mut t.coroutine.get_mut_ref().saved_context)\n+                }\n+                None => {\n+                    None\n+                }\n             };\n             let next_task_context = match self.current_task {\n-                Some(ref mut t) => Some(&mut t.saved_context), None => None\n+                Some(ref mut t) => {\n+                    Some(&mut t.coroutine.get_mut_ref().saved_context)\n+                }\n+                None => {\n+                    None\n+                }\n             };\n             // XXX: These transmutes can be removed after snapshot\n             return (transmute(&mut self.saved_context),\n@@ -337,89 +633,248 @@ impl Scheduler {\n     }\n }\n \n-static MIN_STACK_SIZE: uint = 10000000; // XXX: Too much stack\n-\n-pub struct Coroutine {\n-    /// The segment of stack on which the task is currently running or,\n-    /// if the task is blocked, on which the task will resume execution\n-    priv current_stack_segment: StackSegment,\n-    /// These are always valid when the task is not running, unless\n-    /// the task is dead\n-    priv saved_context: Context,\n-    /// The heap, GC, unwinding, local storage, logging\n-    task: ~Task\n+// The cases for the below function.\n+enum ResumeAction {\n+    SendHome,\n+    Requeue,\n+    ResumeNow,\n+    Homeless\n }\n \n-impl Coroutine {\n-    pub fn new(stack_pool: &mut StackPool, start: ~fn()) -> Coroutine {\n-        Coroutine::with_task(stack_pool, ~Task::new(), start)\n-    }\n-\n-    pub fn with_task(stack_pool: &mut StackPool,\n-                     task: ~Task,\n-                     start: ~fn()) -> Coroutine {\n-        let start = Coroutine::build_start_wrapper(start);\n-        let mut stack = stack_pool.take_segment(MIN_STACK_SIZE);\n-        // NB: Context holds a pointer to that ~fn\n-        let initial_context = Context::new(start, &mut stack);\n-        return Coroutine {\n-            current_stack_segment: stack,\n-            saved_context: initial_context,\n-            task: task\n-        };\n-    }\n-\n-    fn build_start_wrapper(start: ~fn()) -> ~fn() {\n-        // XXX: The old code didn't have this extra allocation\n-        let wrapper: ~fn() = || {\n-            // This is the first code to execute after the initial\n-            // context switch to the task. The previous context may\n-            // have asked us to do some cleanup.\n-            unsafe {\n-                let sched = Local::unsafe_borrow::<Scheduler>();\n-                (*sched).run_cleanup_job();\n-\n-                let sched = Local::unsafe_borrow::<Scheduler>();\n-                let task = (*sched).current_task.get_mut_ref();\n-                // FIXME #6141: shouldn't neet to put `start()` in another closure\n-                task.task.run(||start());\n-            }\n-\n-            let sched = Local::take::<Scheduler>();\n-            sched.terminate_current_task();\n-        };\n-        return wrapper;\n+impl SchedHandle {\n+    pub fn send(&mut self, msg: SchedMessage) {\n+        self.queue.push(msg);\n+        self.remote.fire();\n     }\n+}\n \n-    /// Destroy the task and try to reuse its components\n-    pub fn recycle(~self, stack_pool: &mut StackPool) {\n-        match self {\n-            ~Coroutine {current_stack_segment, _} => {\n-                stack_pool.give_segment(current_stack_segment);\n-            }\n-        }\n-    }\n+// XXX: Some hacks to put a &fn in Scheduler without borrowck\n+// complaining\n+type UnsafeTaskReceiver = sys::Closure;\n+trait ClosureConverter {\n+    fn from_fn(&fn(&mut Scheduler, ~Task)) -> Self;\n+    fn to_fn(self) -> &fn(&mut Scheduler, ~Task);\n }\n+impl ClosureConverter for UnsafeTaskReceiver {\n+    fn from_fn(f: &fn(&mut Scheduler, ~Task)) -> UnsafeTaskReceiver { unsafe { transmute(f) } }\n+    fn to_fn(self) -> &fn(&mut Scheduler, ~Task) { unsafe { transmute(self) } }\n+}\n+\n \n #[cfg(test)]\n mod test {\n     use int;\n     use cell::Cell;\n-    use rt::uv::uvio::UvEventLoop;\n     use unstable::run_in_bare_thread;\n     use task::spawn;\n     use rt::local::Local;\n     use rt::test::*;\n     use super::*;\n+    use rt::thread::Thread;\n+    use borrow::to_uint;\n+    use rt::task::{Task,Sched};\n+\n+    // Confirm that a sched_id actually is the uint form of the\n+    // pointer to the scheduler struct.\n+    #[test]\n+    fn simple_sched_id_test() {\n+        do run_in_bare_thread {\n+            let sched = ~new_test_uv_sched();\n+            assert!(to_uint(sched) == sched.sched_id());\n+        }\n+    }\n+\n+    // Compare two scheduler ids that are different, this should never\n+    // fail but may catch a mistake someday.\n+    #[test]\n+    fn compare_sched_id_test() {\n+        do run_in_bare_thread {\n+            let sched_one = ~new_test_uv_sched();\n+            let sched_two = ~new_test_uv_sched();\n+            assert!(sched_one.sched_id() != sched_two.sched_id());\n+        }\n+    }\n+\n+    // A simple test to check if a homed task run on a single\n+    // scheduler ends up executing while home.\n+    #[test]\n+    fn test_home_sched() {\n+        do run_in_bare_thread {\n+            let mut task_ran = false;\n+            let task_ran_ptr: *mut bool = &mut task_ran;\n+            let mut sched = ~new_test_uv_sched();\n+\n+            let sched_handle = sched.make_handle();\n+            let sched_id = sched.sched_id();\n+\n+            let task = ~do Task::new_root_homed(&mut sched.stack_pool,\n+                                                 Sched(sched_handle)) {\n+                unsafe { *task_ran_ptr = true };\n+                let sched = Local::take::<Scheduler>();\n+                assert!(sched.sched_id() == sched_id);\n+                Local::put::<Scheduler>(sched);\n+            };\n+            sched.enqueue_task(task);\n+            sched.run();\n+            assert!(task_ran);\n+        }\n+    }\n+\n+    // A test for each state of schedule_task\n+    #[test]\n+    fn test_schedule_home_states() {\n+\n+        use rt::uv::uvio::UvEventLoop;\n+        use rt::sched::Shutdown;\n+        use rt::sleeper_list::SleeperList;\n+        use rt::work_queue::WorkQueue;\n+\n+        do run_in_bare_thread {\n+\n+            let sleepers = SleeperList::new();\n+            let work_queue = WorkQueue::new();\n+\n+            // our normal scheduler\n+            let mut normal_sched = ~Scheduler::new(\n+                ~UvEventLoop::new(),\n+                work_queue.clone(),\n+                sleepers.clone());\n+\n+            let normal_handle = Cell::new(normal_sched.make_handle());\n+\n+            // our special scheduler\n+            let mut special_sched = ~Scheduler::new_special(\n+                ~UvEventLoop::new(),\n+                work_queue.clone(),\n+                sleepers.clone(),\n+                true);\n+\n+            let special_handle = Cell::new(special_sched.make_handle());\n+            let special_handle2 = Cell::new(special_sched.make_handle());\n+            let special_id = special_sched.sched_id();\n+            let t1_handle = special_sched.make_handle();\n+            let t4_handle = special_sched.make_handle();\n+\n+            let t1f = ~do Task::new_root_homed(&mut special_sched.stack_pool,\n+                                               Sched(t1_handle)) || {\n+                let is_home = Task::is_home_using_id(special_id);\n+                rtdebug!(\"t1 should be home: %b\", is_home);\n+                assert!(is_home);\n+            };\n+            let t1f = Cell::new(t1f);\n+\n+            let t2f = ~do Task::new_root(&mut normal_sched.stack_pool) {\n+                let on_special = Task::on_special();\n+                rtdebug!(\"t2 should not be on special: %b\", on_special);\n+                assert!(!on_special);\n+            };\n+            let t2f = Cell::new(t2f);\n+\n+            let t3f = ~do Task::new_root(&mut normal_sched.stack_pool) {\n+                // not on special\n+                let on_special = Task::on_special();\n+                rtdebug!(\"t3 should not be on special: %b\", on_special);\n+                assert!(!on_special);\n+            };\n+            let t3f = Cell::new(t3f);\n+\n+            let t4f = ~do Task::new_root_homed(&mut special_sched.stack_pool,\n+                                          Sched(t4_handle)) {\n+                // is home\n+                let home = Task::is_home_using_id(special_id);\n+                rtdebug!(\"t4 should be home: %b\", home);\n+                assert!(home);\n+            };\n+            let t4f = Cell::new(t4f);\n+\n+            // we have four tests, make them as closures\n+            let t1: ~fn() = || {\n+                // task is home on special\n+                let task = t1f.take();\n+                let sched = Local::take::<Scheduler>();\n+                sched.schedule_task(task);\n+            };\n+            let t2: ~fn() = || {\n+                // not homed, task doesn't care\n+                let task = t2f.take();\n+                let sched = Local::take::<Scheduler>();\n+                sched.schedule_task(task);\n+            };\n+            let t3: ~fn() = || {\n+                // task not homed, must leave\n+                let task = t3f.take();\n+                let sched = Local::take::<Scheduler>();\n+                sched.schedule_task(task);\n+            };\n+            let t4: ~fn() = || {\n+                // task not home, send home\n+                let task = t4f.take();\n+                let sched = Local::take::<Scheduler>();\n+                sched.schedule_task(task);\n+            };\n+\n+            let t1 = Cell::new(t1);\n+            let t2 = Cell::new(t2);\n+            let t3 = Cell::new(t3);\n+            let t4 = Cell::new(t4);\n+\n+            // build a main task that runs our four tests\n+            let main_task = ~do Task::new_root(&mut normal_sched.stack_pool) {\n+                // the two tasks that require a normal start location\n+                t2.take()();\n+                t4.take()();\n+                normal_handle.take().send(Shutdown);\n+                special_handle.take().send(Shutdown);\n+            };\n+\n+            // task to run the two \"special start\" tests\n+            let special_task = ~do Task::new_root_homed(\n+                &mut special_sched.stack_pool,\n+                Sched(special_handle2.take())) {\n+                t1.take()();\n+                t3.take()();\n+            };\n+\n+            // enqueue the main tasks\n+            normal_sched.enqueue_task(special_task);\n+            normal_sched.enqueue_task(main_task);\n+\n+            let nsched_cell = Cell::new(normal_sched);\n+            let normal_thread = do Thread::start {\n+                let sched = nsched_cell.take();\n+                sched.run();\n+            };\n+\n+            let ssched_cell = Cell::new(special_sched);\n+            let special_thread = do Thread::start {\n+                let sched = ssched_cell.take();\n+                sched.run();\n+            };\n+\n+            // wait for the end\n+            let _thread1 = normal_thread;\n+            let _thread2 = special_thread;\n+\n+        }\n+    }\n+\n+    // Do it a lot\n+    #[test]\n+    fn test_stress_schedule_task_states() {\n+        let n = stress_factor() * 120;\n+        for int::range(0,n as int) |_| {\n+            test_schedule_home_states();\n+        }\n+    }\n \n     #[test]\n     fn test_simple_scheduling() {\n         do run_in_bare_thread {\n             let mut task_ran = false;\n             let task_ran_ptr: *mut bool = &mut task_ran;\n \n-            let mut sched = ~UvEventLoop::new_scheduler();\n-            let task = ~do Coroutine::new(&mut sched.stack_pool) {\n+            let mut sched = ~new_test_uv_sched();\n+            let task = ~do Task::new_root(&mut sched.stack_pool) {\n                 unsafe { *task_ran_ptr = true; }\n             };\n             sched.enqueue_task(task);\n@@ -435,9 +890,9 @@ mod test {\n             let mut task_count = 0;\n             let task_count_ptr: *mut int = &mut task_count;\n \n-            let mut sched = ~UvEventLoop::new_scheduler();\n+            let mut sched = ~new_test_uv_sched();\n             for int::range(0, total) |_| {\n-                let task = ~do Coroutine::new(&mut sched.stack_pool) {\n+                let task = ~do Task::new_root(&mut sched.stack_pool) {\n                     unsafe { *task_count_ptr = *task_count_ptr + 1; }\n                 };\n                 sched.enqueue_task(task);\n@@ -453,19 +908,17 @@ mod test {\n             let mut count = 0;\n             let count_ptr: *mut int = &mut count;\n \n-            let mut sched = ~UvEventLoop::new_scheduler();\n-            let task1 = ~do Coroutine::new(&mut sched.stack_pool) {\n+            let mut sched = ~new_test_uv_sched();\n+            let task1 = ~do Task::new_root(&mut sched.stack_pool) {\n                 unsafe { *count_ptr = *count_ptr + 1; }\n                 let mut sched = Local::take::<Scheduler>();\n-                let task2 = ~do Coroutine::new(&mut sched.stack_pool) {\n+                let task2 = ~do Task::new_root(&mut sched.stack_pool) {\n                     unsafe { *count_ptr = *count_ptr + 1; }\n                 };\n                 // Context switch directly to the new task\n-                do sched.switch_running_tasks_and_then(task2) |task1| {\n+                do sched.switch_running_tasks_and_then(task2) |sched, task1| {\n                     let task1 = Cell::new(task1);\n-                    do Local::borrow::<Scheduler> |sched| {\n-                        sched.enqueue_task(task1.take());\n-                    }\n+                    sched.enqueue_task(task1.take());\n                 }\n                 unsafe { *count_ptr = *count_ptr + 1; }\n             };\n@@ -482,9 +935,9 @@ mod test {\n             let mut count = 0;\n             let count_ptr: *mut int = &mut count;\n \n-            let mut sched = ~UvEventLoop::new_scheduler();\n+            let mut sched = ~new_test_uv_sched();\n \n-            let start_task = ~do Coroutine::new(&mut sched.stack_pool) {\n+            let start_task = ~do Task::new_root(&mut sched.stack_pool) {\n                 run_task(count_ptr);\n             };\n             sched.enqueue_task(start_task);\n@@ -493,8 +946,8 @@ mod test {\n             assert_eq!(count, MAX);\n \n             fn run_task(count_ptr: *mut int) {\n-                do Local::borrow::<Scheduler> |sched| {\n-                    let task = ~do Coroutine::new(&mut sched.stack_pool) {\n+                do Local::borrow::<Scheduler, ()> |sched| {\n+                    let task = ~do Task::new_root(&mut sched.stack_pool) {\n                         unsafe {\n                             *count_ptr = *count_ptr + 1;\n                             if *count_ptr != MAX {\n@@ -511,16 +964,14 @@ mod test {\n     #[test]\n     fn test_block_task() {\n         do run_in_bare_thread {\n-            let mut sched = ~UvEventLoop::new_scheduler();\n-            let task = ~do Coroutine::new(&mut sched.stack_pool) {\n+            let mut sched = ~new_test_uv_sched();\n+            let task = ~do Task::new_root(&mut sched.stack_pool) {\n                 let sched = Local::take::<Scheduler>();\n                 assert!(sched.in_task_context());\n-                do sched.deschedule_running_task_and_then() |task| {\n+                do sched.deschedule_running_task_and_then() |sched, task| {\n                     let task = Cell::new(task);\n-                    do Local::borrow::<Scheduler> |sched| {\n-                        assert!(!sched.in_task_context());\n-                        sched.enqueue_task(task.take());\n-                    }\n+                    assert!(!sched.in_task_context());\n+                    sched.enqueue_task(task.take());\n                 }\n             };\n             sched.enqueue_task(task);\n@@ -537,18 +988,156 @@ mod test {\n         do run_in_newsched_task {\n             do spawn {\n                 let sched = Local::take::<Scheduler>();\n-                do sched.deschedule_running_task_and_then |task| {\n-                    let mut sched = Local::take::<Scheduler>();\n+                do sched.deschedule_running_task_and_then |sched, task| {\n                     let task = Cell::new(task);\n                     do sched.event_loop.callback_ms(10) {\n                         rtdebug!(\"in callback\");\n                         let mut sched = Local::take::<Scheduler>();\n                         sched.enqueue_task(task.take());\n                         Local::put(sched);\n                     }\n-                    Local::put(sched);\n                 }\n             }\n         }\n     }\n+\n+    #[test]\n+    fn handle() {\n+        use rt::comm::*;\n+\n+        do run_in_bare_thread {\n+            let (port, chan) = oneshot::<()>();\n+            let port_cell = Cell::new(port);\n+            let chan_cell = Cell::new(chan);\n+            let mut sched1 = ~new_test_uv_sched();\n+            let handle1 = sched1.make_handle();\n+            let handle1_cell = Cell::new(handle1);\n+            let task1 = ~do Task::new_root(&mut sched1.stack_pool) {\n+                chan_cell.take().send(());\n+            };\n+            sched1.enqueue_task(task1);\n+\n+            let mut sched2 = ~new_test_uv_sched();\n+            let task2 = ~do Task::new_root(&mut sched2.stack_pool) {\n+                port_cell.take().recv();\n+                // Release the other scheduler's handle so it can exit\n+                handle1_cell.take();\n+            };\n+            sched2.enqueue_task(task2);\n+\n+            let sched1_cell = Cell::new(sched1);\n+            let _thread1 = do Thread::start {\n+                let sched1 = sched1_cell.take();\n+                sched1.run();\n+            };\n+\n+            let sched2_cell = Cell::new(sched2);\n+            let _thread2 = do Thread::start {\n+                let sched2 = sched2_cell.take();\n+                sched2.run();\n+            };\n+        }\n+    }\n+\n+    #[test]\n+    fn multithreading() {\n+        use rt::comm::*;\n+        use iter::Times;\n+        use vec::OwnedVector;\n+        use container::Container;\n+\n+        do run_in_mt_newsched_task {\n+            let mut ports = ~[];\n+            for 10.times {\n+                let (port, chan) = oneshot();\n+                let chan_cell = Cell::new(chan);\n+                do spawntask_later {\n+                    chan_cell.take().send(());\n+                }\n+                ports.push(port);\n+            }\n+\n+            while !ports.is_empty() {\n+                ports.pop().recv();\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn thread_ring() {\n+        use rt::comm::*;\n+        use comm::{GenericPort, GenericChan};\n+\n+        do run_in_mt_newsched_task {\n+            let (end_port, end_chan) = oneshot();\n+\n+            let n_tasks = 10;\n+            let token = 2000;\n+\n+            let (p, ch1) = stream();\n+            let mut p = p;\n+            ch1.send((token, end_chan));\n+            let mut i = 2;\n+            while i <= n_tasks {\n+                let (next_p, ch) = stream();\n+                let imm_i = i;\n+                let imm_p = p;\n+                do spawntask_random {\n+                    roundtrip(imm_i, n_tasks, &imm_p, &ch);\n+                };\n+                p = next_p;\n+                i += 1;\n+            }\n+            let imm_p = p;\n+            let imm_ch = ch1;\n+            do spawntask_random {\n+                roundtrip(1, n_tasks, &imm_p, &imm_ch);\n+            }\n+\n+            end_port.recv();\n+        }\n+\n+        fn roundtrip(id: int, n_tasks: int,\n+                     p: &Port<(int, ChanOne<()>)>, ch: &Chan<(int, ChanOne<()>)>) {\n+            while (true) {\n+                match p.recv() {\n+                    (1, end_chan) => {\n+                        debug!(\"%d\\n\", id);\n+                        end_chan.send(());\n+                        return;\n+                    }\n+                    (token, end_chan) => {\n+                        debug!(\"thread: %d   got token: %d\", id, token);\n+                        ch.send((token - 1, end_chan));\n+                        if token <= n_tasks {\n+                            return;\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn start_closure_dtor() {\n+        use ops::Drop;\n+\n+        // Regression test that the `start` task entrypoint can\n+        // contain dtors that use task resources\n+        do run_in_newsched_task {\n+            struct S { field: () }\n+\n+            impl Drop for S {\n+                fn drop(&self) {\n+                    let _foo = @0;\n+                }\n+            }\n+\n+            let s = S { field: () };\n+\n+            do spawntask {\n+                let _ss = &s;\n+            }\n+        }\n+    }\n }"}, {"sha": "3d6e9ef5635e5ac48908477d40203ac7d838bf8f", "filename": "src/libstd/rt/sleeper_list.rs", "status": "added", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fsleeper_list.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fsleeper_list.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fsleeper_list.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -0,0 +1,59 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! Maintains a shared list of sleeping schedulers. Schedulers\n+//! use this to wake each other up.\n+\n+use container::Container;\n+use vec::OwnedVector;\n+use option::{Option, Some, None};\n+use cell::Cell;\n+use unstable::sync::{Exclusive, exclusive};\n+use rt::sched::SchedHandle;\n+use clone::Clone;\n+\n+pub struct SleeperList {\n+    priv stack: ~Exclusive<~[SchedHandle]>\n+}\n+\n+impl SleeperList {\n+    pub fn new() -> SleeperList {\n+        SleeperList {\n+            stack: ~exclusive(~[])\n+        }\n+    }\n+\n+    pub fn push(&mut self, handle: SchedHandle) {\n+        let handle = Cell::new(handle);\n+        unsafe {\n+            self.stack.with(|s| s.push(handle.take()));\n+        }\n+    }\n+\n+    pub fn pop(&mut self) -> Option<SchedHandle> {\n+        unsafe {\n+            do self.stack.with |s| {\n+                if !s.is_empty() {\n+                    Some(s.pop())\n+                } else {\n+                    None\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+impl Clone for SleeperList {\n+    fn clone(&self) -> SleeperList {\n+        SleeperList {\n+            stack: self.stack.clone()\n+        }\n+    }\n+}\n\\ No newline at end of file"}, {"sha": "b4f4c1b3e35b9bf72ade5a81a00cc2c3b93788fa", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 264, "deletions": 20, "changes": 284, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -15,20 +15,45 @@\n \n use borrow;\n use cast::transmute;\n+use cleanup;\n use libc::{c_void, uintptr_t};\n use ptr;\n use prelude::*;\n+use option::{Option, Some, None};\n use rt::local::Local;\n use rt::logging::StdErrLogger;\n use super::local_heap::LocalHeap;\n+use rt::sched::{Scheduler, SchedHandle};\n+use rt::join_latch::JoinLatch;\n+use rt::stack::{StackSegment, StackPool};\n+use rt::context::Context;\n+use cell::Cell;\n \n pub struct Task {\n     heap: LocalHeap,\n     gc: GarbageCollector,\n     storage: LocalStorage,\n     logger: StdErrLogger,\n-    unwinder: Option<Unwinder>,\n-    destroyed: bool\n+    unwinder: Unwinder,\n+    home: Option<SchedHome>,\n+    join_latch: Option<~JoinLatch>,\n+    on_exit: Option<~fn(bool)>,\n+    destroyed: bool,\n+    coroutine: Option<~Coroutine>\n+}\n+\n+pub struct Coroutine {\n+    /// The segment of stack on which the task is currently running or\n+    /// if the task is blocked, on which the task will resume\n+    /// execution.\n+    priv current_stack_segment: StackSegment,\n+    /// Always valid if the task is alive and not running.\n+    saved_context: Context\n+}\n+\n+pub enum SchedHome {\n+    AnySched,\n+    Sched(SchedHandle)\n }\n \n pub struct GarbageCollector;\n@@ -39,73 +64,227 @@ pub struct Unwinder {\n }\n \n impl Task {\n-    pub fn new() -> Task {\n+\n+    pub fn new_root(stack_pool: &mut StackPool,\n+                    start: ~fn()) -> Task {\n+        Task::new_root_homed(stack_pool, AnySched, start)\n+    }\n+\n+    pub fn new_child(&mut self,\n+                     stack_pool: &mut StackPool,\n+                     start: ~fn()) -> Task {\n+        self.new_child_homed(stack_pool, AnySched, start)\n+    }\n+\n+    pub fn new_root_homed(stack_pool: &mut StackPool,\n+                          home: SchedHome,\n+                          start: ~fn()) -> Task {\n         Task {\n             heap: LocalHeap::new(),\n             gc: GarbageCollector,\n             storage: LocalStorage(ptr::null(), None),\n             logger: StdErrLogger,\n-            unwinder: Some(Unwinder { unwinding: false }),\n-            destroyed: false\n+            unwinder: Unwinder { unwinding: false },\n+            home: Some(home),\n+            join_latch: Some(JoinLatch::new_root()),\n+            on_exit: None,\n+            destroyed: false,\n+            coroutine: Some(~Coroutine::new(stack_pool, start))\n         }\n     }\n \n-    pub fn without_unwinding() -> Task {\n+    pub fn new_child_homed(&mut self,\n+                           stack_pool: &mut StackPool,\n+                           home: SchedHome,\n+                           start: ~fn()) -> Task {\n         Task {\n             heap: LocalHeap::new(),\n             gc: GarbageCollector,\n             storage: LocalStorage(ptr::null(), None),\n             logger: StdErrLogger,\n-            unwinder: None,\n-            destroyed: false\n+            home: Some(home),\n+            unwinder: Unwinder { unwinding: false },\n+            join_latch: Some(self.join_latch.get_mut_ref().new_child()),\n+            on_exit: None,\n+            destroyed: false,\n+            coroutine: Some(~Coroutine::new(stack_pool, start))\n         }\n     }\n \n+    pub fn give_home(&mut self, new_home: SchedHome) {\n+        self.home = Some(new_home);\n+    }\n+\n     pub fn run(&mut self, f: &fn()) {\n         // This is just an assertion that `run` was called unsafely\n         // and this instance of Task is still accessible.\n-        do Local::borrow::<Task> |task| {\n+        do Local::borrow::<Task, ()> |task| {\n             assert!(borrow::ref_eq(task, self));\n         }\n \n-        match self.unwinder {\n-            Some(ref mut unwinder) => {\n-                // If there's an unwinder then set up the catch block\n-                unwinder.try(f);\n+        self.unwinder.try(f);\n+        self.destroy();\n+\n+        // Wait for children. Possibly report the exit status.\n+        let local_success = !self.unwinder.unwinding;\n+        let join_latch = self.join_latch.swap_unwrap();\n+        match self.on_exit {\n+            Some(ref on_exit) => {\n+                let success = join_latch.wait(local_success);\n+                (*on_exit)(success);\n             }\n             None => {\n-                // Otherwise, just run the body\n-                f()\n+                join_latch.release(local_success);\n             }\n         }\n-        self.destroy();\n     }\n \n-    /// Must be called manually before finalization to clean up\n+    /// must be called manually before finalization to clean up\n     /// thread-local resources. Some of the routines here expect\n     /// Task to be available recursively so this must be\n     /// called unsafely, without removing Task from\n     /// thread-local-storage.\n     fn destroy(&mut self) {\n-        // This is just an assertion that `destroy` was called unsafely\n-        // and this instance of Task is still accessible.\n-        do Local::borrow::<Task> |task| {\n+\n+        do Local::borrow::<Task, ()> |task| {\n             assert!(borrow::ref_eq(task, self));\n         }\n+\n         match self.storage {\n             LocalStorage(ptr, Some(ref dtor)) => {\n                 (*dtor)(ptr)\n             }\n             _ => ()\n         }\n+\n+        // Destroy remaining boxes\n+        unsafe { cleanup::annihilate(); }\n+\n         self.destroyed = true;\n     }\n+\n+    /// Check if *task* is currently home.\n+    pub fn is_home(&self) -> bool {\n+        do Local::borrow::<Scheduler,bool> |sched| {\n+            match self.home {\n+                Some(AnySched) => { false }\n+                Some(Sched(SchedHandle { sched_id: ref id, _ })) => {\n+                    *id == sched.sched_id()\n+                }\n+                None => { rtabort!(\"task home of None\") }\n+            }\n+        }\n+    }\n+\n+    pub fn is_home_no_tls(&self, sched: &~Scheduler) -> bool {\n+        match self.home {\n+            Some(AnySched) => { false }\n+            Some(Sched(SchedHandle { sched_id: ref id, _ })) => {\n+                *id == sched.sched_id()\n+            }\n+            None => {rtabort!(\"task home of None\") }\n+        }\n+    }\n+\n+    pub fn is_home_using_id(sched_id: uint) -> bool {\n+        do Local::borrow::<Task,bool> |task| {\n+            match task.home {\n+                Some(Sched(SchedHandle { sched_id: ref id, _ })) => {\n+                    *id == sched_id\n+                }\n+                Some(AnySched) => { false }\n+                None => { rtabort!(\"task home of None\") }\n+            }\n+        }\n+    }\n+\n+    /// Check if this *task* has a home.\n+    pub fn homed(&self) -> bool {\n+        match self.home {\n+            Some(AnySched) => { false }\n+            Some(Sched(_)) => { true }\n+            None => {\n+                rtabort!(\"task home of None\")\n+            }\n+        }\n+    }\n+\n+    /// On a special scheduler?\n+    pub fn on_special() -> bool {\n+        do Local::borrow::<Scheduler,bool> |sched| {\n+            !sched.run_anything\n+        }\n+    }\n+\n }\n \n impl Drop for Task {\n     fn drop(&self) { assert!(self.destroyed) }\n }\n \n+// Coroutines represent nothing more than a context and a stack\n+// segment.\n+\n+impl Coroutine {\n+\n+    pub fn new(stack_pool: &mut StackPool, start: ~fn()) -> Coroutine {\n+        static MIN_STACK_SIZE: uint = 100000; // XXX: Too much stack\n+\n+        let start = Coroutine::build_start_wrapper(start);\n+        let mut stack = stack_pool.take_segment(MIN_STACK_SIZE);\n+        let initial_context = Context::new(start, &mut stack);\n+        Coroutine {\n+            current_stack_segment: stack,\n+            saved_context: initial_context\n+        }\n+    }\n+\n+    fn build_start_wrapper(start: ~fn()) -> ~fn() {\n+        let start_cell = Cell::new(start);\n+        let wrapper: ~fn() = || {\n+            // First code after swap to this new context. Run our\n+            // cleanup job.\n+            unsafe {\n+                let sched = Local::unsafe_borrow::<Scheduler>();\n+                (*sched).run_cleanup_job();\n+\n+                let sched = Local::unsafe_borrow::<Scheduler>();\n+                let task = (*sched).current_task.get_mut_ref();\n+\n+                do task.run {\n+                    // N.B. Removing `start` from the start wrapper\n+                    // closure by emptying a cell is critical for\n+                    // correctness. The ~Task pointer, and in turn the\n+                    // closure used to initialize the first call\n+                    // frame, is destroyed in the scheduler context,\n+                    // not task context. So any captured closures must\n+                    // not contain user-definable dtors that expect to\n+                    // be in task context. By moving `start` out of\n+                    // the closure, all the user code goes our of\n+                    // scope while the task is still running.\n+                    let start = start_cell.take();\n+                    start();\n+                };\n+            }\n+\n+            let sched = Local::take::<Scheduler>();\n+            sched.terminate_current_task();\n+        };\n+        return wrapper;\n+    }\n+\n+    /// Destroy coroutine and try to reuse stack segment.\n+    pub fn recycle(~self, stack_pool: &mut StackPool) {\n+        match self {\n+            ~Coroutine { current_stack_segment, _ } => {\n+                stack_pool.give_segment(current_stack_segment);\n+            }\n+        }\n+    }\n+\n+}\n+\n+\n // Just a sanity check to make sure we are catching a Rust-thrown exception\n static UNWIND_TOKEN: uintptr_t = 839147;\n \n@@ -184,8 +363,10 @@ mod test {\n     fn unwind() {\n         do run_in_newsched_task() {\n             let result = spawntask_try(||());\n+            rtdebug!(\"trying first assert\");\n             assert!(result.is_ok());\n             let result = spawntask_try(|| fail!());\n+            rtdebug!(\"trying second assert\");\n             assert!(result.is_err());\n         }\n     }\n@@ -227,4 +408,67 @@ mod test {\n             assert!(port.recv() == 10);\n         }\n     }\n+\n+    #[test]\n+    fn comm_shared_chan() {\n+        use comm::*;\n+\n+        do run_in_newsched_task() {\n+            let (port, chan) = stream();\n+            let chan = SharedChan::new(chan);\n+            chan.send(10);\n+            assert!(port.recv() == 10);\n+        }\n+    }\n+\n+    #[test]\n+    fn linked_failure() {\n+        do run_in_newsched_task() {\n+            let res = do spawntask_try {\n+                spawntask_random(|| fail!());\n+            };\n+            assert!(res.is_err());\n+        }\n+    }\n+\n+    #[test]\n+    fn heap_cycles() {\n+        use option::{Option, Some, None};\n+\n+        do run_in_newsched_task {\n+            struct List {\n+                next: Option<@mut List>,\n+            }\n+\n+            let a = @mut List { next: None };\n+            let b = @mut List { next: Some(a) };\n+\n+            a.next = Some(b);\n+        }\n+    }\n+\n+    // XXX: This is a copy of test_future_result in std::task.\n+    // It can be removed once the scheduler is turned on by default.\n+    #[test]\n+    fn future_result() {\n+        do run_in_newsched_task {\n+            use option::{Some, None};\n+            use task::*;\n+\n+            let mut result = None;\n+            let mut builder = task();\n+            builder.future_result(|r| result = Some(r));\n+            do builder.spawn {}\n+            assert_eq!(result.unwrap().recv(), Success);\n+\n+            result = None;\n+            let mut builder = task();\n+            builder.future_result(|r| result = Some(r));\n+            builder.unlinked();\n+            do builder.spawn {\n+                fail!();\n+            }\n+            assert_eq!(result.unwrap().recv(), Failure);\n+        }\n+    }\n }"}, {"sha": "f4b9269e8cd48fef7e483cba8148472d0d1839d8", "filename": "src/libstd/rt/test.rs", "status": "modified", "additions": 284, "deletions": 84, "changes": 368, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftest.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -8,75 +8,185 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use libc;\n use uint;\n-use option::*;\n+use option::{Some, None};\n use cell::Cell;\n-use result::{Result, Ok, Err};\n-use super::io::net::ip::{IpAddr, Ipv4};\n-use rt::task::Task;\n-use rt::thread::Thread;\n+use clone::Clone;\n+use container::Container;\n+use iterator::IteratorUtil;\n+use vec::{OwnedVector, MutableVector};\n+use super::io::net::ip::{IpAddr, Ipv4, Ipv6};\n+use rt::sched::Scheduler;\n use rt::local::Local;\n+use unstable::run_in_bare_thread;\n+use rt::thread::Thread;\n+use rt::task::Task;\n+use rt::uv::uvio::UvEventLoop;\n+use rt::work_queue::WorkQueue;\n+use rt::sleeper_list::SleeperList;\n+use rt::task::{Sched};\n+use rt::comm::oneshot;\n+use result::{Result, Ok, Err};\n+\n+pub fn new_test_uv_sched() -> Scheduler {\n+\n+    let mut sched = Scheduler::new(~UvEventLoop::new(),\n+                                   WorkQueue::new(),\n+                                   SleeperList::new());\n+    // Don't wait for the Shutdown message\n+    sched.no_sleep = true;\n+    return sched;\n+}\n \n /// Creates a new scheduler in a new thread and runs a task in it,\n /// then waits for the scheduler to exit. Failure of the task\n /// will abort the process.\n pub fn run_in_newsched_task(f: ~fn()) {\n-    use super::sched::*;\n-    use unstable::run_in_bare_thread;\n-    use rt::uv::uvio::UvEventLoop;\n-\n     let f = Cell::new(f);\n \n     do run_in_bare_thread {\n-        let mut sched = ~UvEventLoop::new_scheduler();\n-        let task = ~Coroutine::with_task(&mut sched.stack_pool,\n-                                         ~Task::without_unwinding(),\n-                                         f.take());\n+        let mut sched = ~new_test_uv_sched();\n+        let on_exit: ~fn(bool) = |exit_status| rtassert!(exit_status);\n+        let mut task = ~Task::new_root(&mut sched.stack_pool,\n+                                       f.take());\n+        rtdebug!(\"newsched_task: %x\", to_uint(task));\n+        task.on_exit = Some(on_exit);\n         sched.enqueue_task(task);\n         sched.run();\n     }\n }\n \n+/// Create more than one scheduler and run a function in a task\n+/// in one of the schedulers. The schedulers will stay alive\n+/// until the function `f` returns.\n+pub fn run_in_mt_newsched_task(f: ~fn()) {\n+    use os;\n+    use from_str::FromStr;\n+    use rt::sched::Shutdown;\n+    use rt::util;\n+\n+    let f_cell = Cell::new(f);\n+\n+    do run_in_bare_thread {\n+        let nthreads = match os::getenv(\"RUST_TEST_THREADS\") {\n+            Some(nstr) => FromStr::from_str(nstr).get(),\n+            None => {\n+                // Using more threads than cores in test code\n+                // to force the OS to preempt them frequently.\n+                // Assuming that this help stress test concurrent types.\n+                util::num_cpus() * 2\n+            }\n+        };\n+\n+        let sleepers = SleeperList::new();\n+        let work_queue = WorkQueue::new();\n+\n+        let mut handles = ~[];\n+        let mut scheds = ~[];\n+\n+        for uint::range(0, nthreads) |_| {\n+            let loop_ = ~UvEventLoop::new();\n+            let mut sched = ~Scheduler::new(loop_,\n+                                            work_queue.clone(),\n+                                            sleepers.clone());\n+            let handle = sched.make_handle();\n+\n+            handles.push(handle);\n+            scheds.push(sched);\n+        }\n+\n+        let f_cell = Cell::new(f_cell.take());\n+        let handles = Cell::new(handles);\n+        let on_exit: ~fn(bool) = |exit_status| {\n+            let mut handles = handles.take();\n+            // Tell schedulers to exit\n+            for handles.mut_iter().advance |handle| {\n+                handle.send(Shutdown);\n+            }\n+\n+            rtassert!(exit_status);\n+        };\n+        let mut main_task = ~Task::new_root(&mut scheds[0].stack_pool,\n+                                        f_cell.take());\n+        main_task.on_exit = Some(on_exit);\n+        scheds[0].enqueue_task(main_task);\n+\n+        let mut threads = ~[];\n+\n+        while !scheds.is_empty() {\n+            let sched = scheds.pop();\n+            let sched_cell = Cell::new(sched);\n+            let thread = do Thread::start {\n+                let sched = sched_cell.take();\n+                sched.run();\n+            };\n+\n+            threads.push(thread);\n+        }\n+\n+        // Wait for schedulers\n+        let _threads = threads;\n+    }\n+\n+}\n+\n /// Test tasks will abort on failure instead of unwinding\n pub fn spawntask(f: ~fn()) {\n     use super::sched::*;\n+    let f = Cell::new(f);\n \n-    let mut sched = Local::take::<Scheduler>();\n-    let task = ~Coroutine::with_task(&mut sched.stack_pool,\n-                                     ~Task::without_unwinding(),\n-                                     f);\n-    do sched.switch_running_tasks_and_then(task) |task| {\n-        let task = Cell::new(task);\n-        let sched = Local::take::<Scheduler>();\n-        sched.schedule_new_task(task.take());\n-    }\n+    let task = unsafe {\n+        let sched = Local::unsafe_borrow::<Scheduler>();\n+        rtdebug!(\"spawntask taking the scheduler from TLS\");\n+\n+\n+        do Local::borrow::<Task, ~Task>() |running_task| {\n+            ~running_task.new_child(&mut (*sched).stack_pool, f.take())\n+        }\n+    };\n+\n+    rtdebug!(\"new task pointer: %x\", to_uint(task));\n+\n+    let sched = Local::take::<Scheduler>();\n+    rtdebug!(\"spawntask scheduling the new task\");\n+    sched.schedule_task(task);\n }\n \n+\n /// Create a new task and run it right now. Aborts on failure\n pub fn spawntask_immediately(f: ~fn()) {\n     use super::sched::*;\n \n-    let mut sched = Local::take::<Scheduler>();\n-    let task = ~Coroutine::with_task(&mut sched.stack_pool,\n-                                     ~Task::without_unwinding(),\n-                                     f);\n-    do sched.switch_running_tasks_and_then(task) |task| {\n-        let task = Cell::new(task);\n-        do Local::borrow::<Scheduler> |sched| {\n-            sched.enqueue_task(task.take());\n+    let f = Cell::new(f);\n+\n+    let task = unsafe {\n+        let sched = Local::unsafe_borrow::<Scheduler>();\n+        do Local::borrow::<Task, ~Task>() |running_task| {\n+            ~running_task.new_child(&mut (*sched).stack_pool,\n+                                    f.take())\n         }\n+    };\n+\n+    let sched = Local::take::<Scheduler>();\n+    do sched.switch_running_tasks_and_then(task) |sched, task| {\n+        sched.enqueue_task(task);\n     }\n }\n \n /// Create a new task and run it right now. Aborts on failure\n pub fn spawntask_later(f: ~fn()) {\n     use super::sched::*;\n+    let f = Cell::new(f);\n \n-    let mut sched = Local::take::<Scheduler>();\n-    let task = ~Coroutine::with_task(&mut sched.stack_pool,\n-                                     ~Task::without_unwinding(),\n-                                     f);\n+    let task = unsafe {\n+        let sched = Local::unsafe_borrow::<Scheduler>();\n+        do Local::borrow::<Task, ~Task>() |running_task| {\n+            ~running_task.new_child(&mut (*sched).stack_pool, f.take())\n+        }\n+    };\n \n+    let mut sched = Local::take::<Scheduler>();\n     sched.enqueue_task(task);\n     Local::put(sched);\n }\n@@ -86,101 +196,191 @@ pub fn spawntask_random(f: ~fn()) {\n     use super::sched::*;\n     use rand::{Rand, rng};\n \n-    let mut rng = rng();\n-    let run_now: bool = Rand::rand(&mut rng);\n+    let f = Cell::new(f);\n+\n+    let task = unsafe {\n+        let sched = Local::unsafe_borrow::<Scheduler>();\n+        do Local::borrow::<Task, ~Task>() |running_task| {\n+            ~running_task.new_child(&mut (*sched).stack_pool,\n+                                    f.take())\n+\n+        }\n+    };\n \n     let mut sched = Local::take::<Scheduler>();\n-    let task = ~Coroutine::with_task(&mut sched.stack_pool,\n-                                     ~Task::without_unwinding(),\n-                                     f);\n+\n+    let mut rng = rng();\n+    let run_now: bool = Rand::rand(&mut rng);\n \n     if run_now {\n-        do sched.switch_running_tasks_and_then(task) |task| {\n-            let task = Cell::new(task);\n-            do Local::borrow::<Scheduler> |sched| {\n-                sched.enqueue_task(task.take());\n-            }\n+        do sched.switch_running_tasks_and_then(task) |sched, task| {\n+            sched.enqueue_task(task);\n         }\n     } else {\n         sched.enqueue_task(task);\n         Local::put(sched);\n     }\n }\n \n+/// Spawn a task, with the current scheduler as home, and queue it to\n+/// run later.\n+pub fn spawntask_homed(scheds: &mut ~[~Scheduler], f: ~fn()) {\n+    use super::sched::*;\n+    use rand::{rng, RngUtil};\n+    let mut rng = rng();\n+\n+    let task = {\n+        let sched = &mut scheds[rng.gen_int_range(0,scheds.len() as int)];\n+        let handle = sched.make_handle();\n+        let home_id = handle.sched_id;\n \n-/// Spawn a task and wait for it to finish, returning whether it completed successfully or failed\n+        // now that we know where this is going, build a new function\n+        // that can assert it is in the right place\n+        let af: ~fn() = || {\n+            do Local::borrow::<Scheduler,()>() |sched| {\n+                rtdebug!(\"home_id: %u, runtime loc: %u\",\n+                         home_id,\n+                         sched.sched_id());\n+                assert!(home_id == sched.sched_id());\n+            };\n+            f()\n+        };\n+\n+        ~Task::new_root_homed(&mut sched.stack_pool,\n+                              Sched(handle),\n+                              af)\n+    };\n+    let dest_sched = &mut scheds[rng.gen_int_range(0,scheds.len() as int)];\n+    // enqueue it for future execution\n+    dest_sched.enqueue_task(task);\n+}\n+\n+/// Spawn a task and wait for it to finish, returning whether it\n+/// completed successfully or failed\n pub fn spawntask_try(f: ~fn()) -> Result<(), ()> {\n     use cell::Cell;\n     use super::sched::*;\n-    use task;\n-    use unstable::finally::Finally;\n \n-    // Our status variables will be filled in from the scheduler context\n-    let mut failed = false;\n-    let failed_ptr: *mut bool = &mut failed;\n+    let f = Cell::new(f);\n \n-    // Switch to the scheduler\n-    let f = Cell::new(Cell::new(f));\n-    let sched = Local::take::<Scheduler>();\n-    do sched.deschedule_running_task_and_then() |old_task| {\n-        let old_task = Cell::new(old_task);\n-        let f = f.take();\n-        let mut sched = Local::take::<Scheduler>();\n-        let new_task = ~do Coroutine::new(&mut sched.stack_pool) {\n-            do (|| {\n-                (f.take())()\n-            }).finally {\n-                // Check for failure then resume the parent task\n-                unsafe { *failed_ptr = task::failing(); }\n-                let sched = Local::take::<Scheduler>();\n-                do sched.switch_running_tasks_and_then(old_task.take()) |new_task| {\n-                    let new_task = Cell::new(new_task);\n-                    do Local::borrow::<Scheduler> |sched| {\n-                        sched.enqueue_task(new_task.take());\n-                    }\n-                }\n-            }\n-        };\n+    let (port, chan) = oneshot();\n+    let chan = Cell::new(chan);\n+    let on_exit: ~fn(bool) = |exit_status| chan.take().send(exit_status);\n+    let mut new_task = unsafe {\n+        let sched = Local::unsafe_borrow::<Scheduler>();\n+        do Local::borrow::<Task, ~Task> |_running_task| {\n \n-        sched.resume_task_immediately(new_task);\n+            // I don't understand why using a child task here fails. I\n+            // think the fail status is propogating back up the task\n+            // tree and triggering a fail for the parent, which we\n+            // aren't correctly expecting.\n+\n+            // ~running_task.new_child(&mut (*sched).stack_pool,\n+            ~Task::new_root(&mut (*sched).stack_pool,\n+                           f.take())\n+        }\n+    };\n+    new_task.on_exit = Some(on_exit);\n+\n+    let sched = Local::take::<Scheduler>();\n+    do sched.switch_running_tasks_and_then(new_task) |sched, old_task| {\n+        sched.enqueue_task(old_task);\n     }\n \n-    if !failed { Ok(()) } else { Err(()) }\n+    rtdebug!(\"enqueued the new task, now waiting on exit_status\");\n+\n+    let exit_status = port.recv();\n+    if exit_status { Ok(()) } else { Err(()) }\n }\n \n // Spawn a new task in a new scheduler and return a thread handle.\n pub fn spawntask_thread(f: ~fn()) -> Thread {\n     use rt::sched::*;\n-    use rt::uv::uvio::UvEventLoop;\n \n     let f = Cell::new(f);\n+\n+    let task = unsafe {\n+        let sched = Local::unsafe_borrow::<Scheduler>();\n+        do Local::borrow::<Task, ~Task>() |running_task| {\n+            ~running_task.new_child(&mut (*sched).stack_pool,\n+                                    f.take())\n+        }\n+    };\n+\n+    let task = Cell::new(task);\n+\n     let thread = do Thread::start {\n-        let mut sched = ~UvEventLoop::new_scheduler();\n-        let task = ~Coroutine::with_task(&mut sched.stack_pool,\n-                                         ~Task::without_unwinding(),\n-                                         f.take());\n-        sched.enqueue_task(task);\n+        let mut sched = ~new_test_uv_sched();\n+        sched.enqueue_task(task.take());\n         sched.run();\n     };\n     return thread;\n }\n \n+\n /// Get a port number, starting at 9600, for use in tests\n pub fn next_test_port() -> u16 {\n     unsafe {\n-        return rust_dbg_next_port() as u16;\n+        return rust_dbg_next_port(base_port() as libc::uintptr_t) as u16;\n     }\n     extern {\n-        fn rust_dbg_next_port() -> ::libc::uintptr_t;\n+        fn rust_dbg_next_port(base: libc::uintptr_t) -> libc::uintptr_t;\n     }\n }\n \n-/// Get a unique localhost:port pair starting at 9600\n+/// Get a unique IPv4 localhost:port pair starting at 9600\n pub fn next_test_ip4() -> IpAddr {\n     Ipv4(127, 0, 0, 1, next_test_port())\n }\n \n-/// Get a constant that represents the number of times to repeat stress tests. Default 1.\n+/// Get a unique IPv6 localhost:port pair starting at 9600\n+pub fn next_test_ip6() -> IpAddr {\n+    Ipv6(0, 0, 0, 0, 0, 0, 0, 1, next_test_port())\n+}\n+\n+/*\n+XXX: Welcome to MegaHack City.\n+\n+The bots run multiple builds at the same time, and these builds\n+all want to use ports. This function figures out which workspace\n+it is running in and assigns a port range based on it.\n+*/\n+fn base_port() -> uint {\n+    use os;\n+    use str::StrSlice;\n+    use to_str::ToStr;\n+    use vec::ImmutableVector;\n+\n+    let base = 9600u;\n+    let range = 1000;\n+\n+    let bases = [\n+        (\"32-opt\", base + range * 1),\n+        (\"32-noopt\", base + range * 2),\n+        (\"64-opt\", base + range * 3),\n+        (\"64-noopt\", base + range * 4),\n+        (\"64-opt-vg\", base + range * 5),\n+        (\"all-opt\", base + range * 6),\n+        (\"snap3\", base + range * 7),\n+        (\"dist\", base + range * 8)\n+    ];\n+\n+    let path = os::getcwd().to_str();\n+\n+    let mut final_base = base;\n+\n+    for bases.iter().advance |&(dir, base)| {\n+        if path.contains(dir) {\n+            final_base = base;\n+            break;\n+        }\n+    }\n+\n+    return final_base;\n+}\n+\n+/// Get a constant that represents the number of times to repeat\n+/// stress tests. Default 1.\n pub fn stress_factor() -> uint {\n     use os::getenv;\n "}, {"sha": "013eb438c3657f1d7a34da7d8f216a593b5f288c", "filename": "src/libstd/rt/tube.rs", "status": "modified", "additions": 18, "deletions": 23, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Ftube.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Ftube.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftube.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -16,14 +16,15 @@\n use option::*;\n use clone::Clone;\n use super::rc::RC;\n-use rt::sched::{Scheduler, Coroutine};\n+use rt::sched::Scheduler;\n use rt::{context, TaskContext, SchedulerContext};\n use rt::local::Local;\n+use rt::task::Task;\n use vec::OwnedVector;\n use container::Container;\n \n struct TubeState<T> {\n-    blocked_task: Option<~Coroutine>,\n+    blocked_task: Option<~Task>,\n     buf: ~[T]\n }\n \n@@ -72,7 +73,7 @@ impl<T> Tube<T> {\n                 assert!(self.p.refcount() > 1); // There better be somebody to wake us up\n                 assert!((*state).blocked_task.is_none());\n                 let sched = Local::take::<Scheduler>();\n-                do sched.deschedule_running_task_and_then |task| {\n+                do sched.deschedule_running_task_and_then |_, task| {\n                     (*state).blocked_task = Some(task);\n                 }\n                 rtdebug!(\"waking after tube recv\");\n@@ -107,11 +108,10 @@ mod test {\n             let tube_clone = tube.clone();\n             let tube_clone_cell = Cell::new(tube_clone);\n             let sched = Local::take::<Scheduler>();\n-            do sched.deschedule_running_task_and_then |task| {\n+            do sched.deschedule_running_task_and_then |sched, task| {\n                 let mut tube_clone = tube_clone_cell.take();\n                 tube_clone.send(1);\n-                let sched = Local::take::<Scheduler>();\n-                sched.resume_task_immediately(task);\n+                sched.enqueue_task(task);\n             }\n \n             assert!(tube.recv() == 1);\n@@ -123,21 +123,17 @@ mod test {\n         do run_in_newsched_task {\n             let mut tube: Tube<int> = Tube::new();\n             let tube_clone = tube.clone();\n-            let tube_clone = Cell::new(Cell::new(Cell::new(tube_clone)));\n+            let tube_clone = Cell::new(tube_clone);\n             let sched = Local::take::<Scheduler>();\n-            do sched.deschedule_running_task_and_then |task| {\n-                let tube_clone = tube_clone.take();\n-                do Local::borrow::<Scheduler> |sched| {\n-                    let tube_clone = tube_clone.take();\n-                    do sched.event_loop.callback {\n-                        let mut tube_clone = tube_clone.take();\n-                        // The task should be blocked on this now and\n-                        // sending will wake it up.\n-                        tube_clone.send(1);\n-                    }\n+            do sched.deschedule_running_task_and_then |sched, task| {\n+                let tube_clone = Cell::new(tube_clone.take());\n+                do sched.event_loop.callback {\n+                    let mut tube_clone = tube_clone.take();\n+                    // The task should be blocked on this now and\n+                    // sending will wake it up.\n+                    tube_clone.send(1);\n                 }\n-                let sched = Local::take::<Scheduler>();\n-                sched.resume_task_immediately(task);\n+                sched.enqueue_task(task);\n             }\n \n             assert!(tube.recv() == 1);\n@@ -153,14 +149,14 @@ mod test {\n             let tube_clone = tube.clone();\n             let tube_clone = Cell::new(tube_clone);\n             let sched = Local::take::<Scheduler>();\n-            do sched.deschedule_running_task_and_then |task| {\n+            do sched.deschedule_running_task_and_then |sched, task| {\n                 callback_send(tube_clone.take(), 0);\n \n                 fn callback_send(tube: Tube<int>, i: int) {\n                     if i == 100 { return; }\n \n                     let tube = Cell::new(Cell::new(tube));\n-                    do Local::borrow::<Scheduler> |sched| {\n+                    do Local::borrow::<Scheduler, ()> |sched| {\n                         let tube = tube.take();\n                         do sched.event_loop.callback {\n                             let mut tube = tube.take();\n@@ -172,8 +168,7 @@ mod test {\n                     }\n                 }\n \n-                let sched = Local::take::<Scheduler>();\n-                sched.resume_task_immediately(task);\n+                sched.enqueue_task(task);\n             }\n \n             for int::range(0, MAX) |i| {"}, {"sha": "a1169954688b097356aeeefdabd39ce00be43f3e", "filename": "src/libstd/rt/util.rs", "status": "added", "additions": 121, "deletions": 0, "changes": 121, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Futil.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -0,0 +1,121 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use container::Container;\n+use from_str::FromStr;\n+use iterator::IteratorUtil;\n+use libc;\n+use option::{Some, None};\n+use os;\n+use str::StrSlice;\n+\n+/// Get the number of cores available\n+pub fn num_cpus() -> uint {\n+    unsafe {\n+        return rust_get_num_cpus();\n+    }\n+\n+    extern {\n+        fn rust_get_num_cpus() -> libc::uintptr_t;\n+    }\n+}\n+\n+/// Get's the number of scheduler threads requested by the environment\n+/// either `RUST_THREADS` or `num_cpus`.\n+pub fn default_sched_threads() -> uint {\n+    match os::getenv(\"RUST_THREADS\") {\n+        Some(nstr) => FromStr::from_str(nstr).get(),\n+        None => num_cpus()\n+    }\n+}\n+\n+pub fn dumb_println(s: &str) {\n+    use io::WriterUtil;\n+    let dbg = ::libc::STDERR_FILENO as ::io::fd_t;\n+    dbg.write_str(s);\n+    dbg.write_str(\"\\n\");\n+}\n+\n+pub fn abort(msg: &str) -> ! {\n+    let msg = if !msg.is_empty() { msg } else { \"aborted\" };\n+    let hash = msg.iter().fold(0, |accum, val| accum + (val as uint) );\n+    let quote = match hash % 10 {\n+        0 => \"\n+It was from the artists and poets that the pertinent answers came, and I\n+know that panic would have broken loose had they been able to compare notes.\n+As it was, lacking their original letters, I half suspected the compiler of\n+having asked leading questions, or of having edited the correspondence in\n+corroboration of what he had latently resolved to see.\",\n+        1 => \"\n+There are not many persons who know what wonders are opened to them in the\n+stories and visions of their youth; for when as children we listen and dream,\n+we think but half-formed thoughts, and when as men we try to remember, we are\n+dulled and prosaic with the poison of life. But some of us awake in the night\n+with strange phantasms of enchanted hills and gardens, of fountains that sing\n+in the sun, of golden cliffs overhanging murmuring seas, of plains that stretch\n+down to sleeping cities of bronze and stone, and of shadowy companies of heroes\n+that ride caparisoned white horses along the edges of thick forests; and then\n+we know that we have looked back through the ivory gates into that world of\n+wonder which was ours before we were wise and unhappy.\",\n+        2 => \"\n+Instead of the poems I had hoped for, there came only a shuddering blackness\n+and ineffable loneliness; and I saw at last a fearful truth which no one had\n+ever dared to breathe before \u2014 the unwhisperable secret of secrets \u2014 The fact\n+that this city of stone and stridor is not a sentient perpetuation of Old New\n+York as London is of Old London and Paris of Old Paris, but that it is in fact\n+quite dead, its sprawling body imperfectly embalmed and infested with queer\n+animate things which have nothing to do with it as it was in life.\",\n+        3 => \"\n+The ocean ate the last of the land and poured into the smoking gulf, thereby\n+giving up all it had ever conquered. From the new-flooded lands it flowed\n+again, uncovering death and decay; and from its ancient and immemorial bed it\n+trickled loathsomely, uncovering nighted secrets of the years when Time was\n+young and the gods unborn. Above the waves rose weedy remembered spires. The\n+moon laid pale lilies of light on dead London, and Paris stood up from its damp\n+grave to be sanctified with star-dust. Then rose spires and monoliths that were\n+weedy but not remembered; terrible spires and monoliths of lands that men never\n+knew were lands...\",\n+        4 => \"\n+There was a night when winds from unknown spaces whirled us irresistibly into\n+limitless vacum beyond all thought and entity. Perceptions of the most\n+maddeningly untransmissible sort thronged upon us; perceptions of infinity\n+which at the time convulsed us with joy, yet which are now partly lost to my\n+memory and partly incapable of presentation to others.\",\n+        _ => \"You've met with a terrible fate, haven't you?\"\n+    };\n+    rterrln!(\"%s\", \"\");\n+    rterrln!(\"%s\", quote);\n+    rterrln!(\"%s\", \"\");\n+    rterrln!(\"fatal runtime error: %s\", msg);\n+\n+    unsafe { libc::abort(); }\n+}\n+\n+pub fn set_exit_status(code: int) {\n+\n+    unsafe {\n+        return rust_set_exit_status_newrt(code as libc::uintptr_t);\n+    }\n+\n+    extern {\n+        fn rust_set_exit_status_newrt(code: libc::uintptr_t);\n+    }\n+}\n+\n+pub fn get_exit_status() -> int {\n+\n+    unsafe {\n+        return rust_get_exit_status_newrt() as int;\n+    }\n+\n+    extern {\n+        fn rust_get_exit_status_newrt() -> libc::uintptr_t;\n+    }\n+}\n\\ No newline at end of file"}, {"sha": "f3d1024024ff80dc918dc21d5c154d85fd31dab7", "filename": "src/libstd/rt/uv/async.rs", "status": "added", "additions": 105, "deletions": 0, "changes": 105, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fasync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fasync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fasync.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -0,0 +1,105 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use libc::{c_int, c_void};\n+use option::Some;\n+use rt::uv::uvll;\n+use rt::uv::uvll::UV_ASYNC;\n+use rt::uv::{Watcher, Loop, NativeHandle, AsyncCallback, NullCallback};\n+use rt::uv::WatcherInterop;\n+use rt::uv::status_to_maybe_uv_error;\n+\n+pub struct AsyncWatcher(*uvll::uv_async_t);\n+impl Watcher for AsyncWatcher { }\n+\n+impl AsyncWatcher {\n+    pub fn new(loop_: &mut Loop, cb: AsyncCallback) -> AsyncWatcher {\n+        unsafe {\n+            let handle = uvll::malloc_handle(UV_ASYNC);\n+            assert!(handle.is_not_null());\n+            let mut watcher: AsyncWatcher = NativeHandle::from_native_handle(handle);\n+            watcher.install_watcher_data();\n+            let data = watcher.get_watcher_data();\n+            data.async_cb = Some(cb);\n+            assert_eq!(0, uvll::async_init(loop_.native_handle(), handle, async_cb));\n+            return watcher;\n+        }\n+\n+        extern fn async_cb(handle: *uvll::uv_async_t, status: c_int) {\n+            let mut watcher: AsyncWatcher = NativeHandle::from_native_handle(handle);\n+            let status = status_to_maybe_uv_error(watcher.native_handle(), status);\n+            let data = watcher.get_watcher_data();\n+            let cb = data.async_cb.get_ref();\n+            (*cb)(watcher, status);\n+        }\n+    }\n+\n+    pub fn send(&mut self) {\n+        unsafe {\n+            let handle = self.native_handle();\n+            uvll::async_send(handle);\n+        }\n+    }\n+\n+    pub fn close(self, cb: NullCallback) {\n+        let mut this = self;\n+        let data = this.get_watcher_data();\n+        assert!(data.close_cb.is_none());\n+        data.close_cb = Some(cb);\n+\n+        unsafe {\n+            uvll::close(self.native_handle(), close_cb);\n+        }\n+\n+        extern fn close_cb(handle: *uvll::uv_stream_t) {\n+            let mut watcher: AsyncWatcher = NativeHandle::from_native_handle(handle);\n+            {\n+                let data = watcher.get_watcher_data();\n+                data.close_cb.swap_unwrap()();\n+            }\n+            watcher.drop_watcher_data();\n+            unsafe { uvll::free_handle(handle as *c_void); }\n+        }\n+    }\n+}\n+\n+impl NativeHandle<*uvll::uv_async_t> for AsyncWatcher {\n+    fn from_native_handle(handle: *uvll::uv_async_t) -> AsyncWatcher {\n+        AsyncWatcher(handle)\n+    }\n+    fn native_handle(&self) -> *uvll::uv_async_t {\n+        match self { &AsyncWatcher(ptr) => ptr }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+\n+    use super::*;\n+    use rt::uv::Loop;\n+    use unstable::run_in_bare_thread;\n+    use rt::thread::Thread;\n+    use cell::Cell;\n+\n+    #[test]\n+    fn smoke_test() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            let watcher = AsyncWatcher::new(&mut loop_, |w, _| w.close(||()) );\n+            let watcher_cell = Cell::new(watcher);\n+            let _thread = do Thread::start {\n+                let mut watcher = watcher_cell.take();\n+                watcher.send();\n+            };\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+}"}, {"sha": "a3630c9b9bf8d6df54da4e9e95a650542a60a89a", "filename": "src/libstd/rt/uv/idle.rs", "status": "modified", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fidle.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fidle.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fidle.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -90,3 +90,65 @@ impl NativeHandle<*uvll::uv_idle_t> for IdleWatcher {\n         match self { &IdleWatcher(ptr) => ptr }\n     }\n }\n+\n+#[cfg(test)]\n+mod test {\n+\n+    use rt::uv::Loop;\n+    use super::*;\n+    use unstable::run_in_bare_thread;\n+\n+    #[test]\n+    #[ignore(reason = \"valgrind - loop destroyed before watcher?\")]\n+    fn idle_new_then_close() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            let idle_watcher = { IdleWatcher::new(&mut loop_) };\n+            idle_watcher.close(||());\n+        }\n+    }\n+\n+    #[test]\n+    fn idle_smoke_test() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n+            let mut count = 10;\n+            let count_ptr: *mut int = &mut count;\n+            do idle_watcher.start |idle_watcher, status| {\n+                let mut idle_watcher = idle_watcher;\n+                assert!(status.is_none());\n+                if unsafe { *count_ptr == 10 } {\n+                    idle_watcher.stop();\n+                    idle_watcher.close(||());\n+                } else {\n+                    unsafe { *count_ptr = *count_ptr + 1; }\n+                }\n+            }\n+            loop_.run();\n+            loop_.close();\n+            assert_eq!(count, 10);\n+        }\n+    }\n+\n+    #[test]\n+    fn idle_start_stop_start() {\n+        do run_in_bare_thread {\n+            let mut loop_ = Loop::new();\n+            let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n+            do idle_watcher.start |idle_watcher, status| {\n+                let mut idle_watcher = idle_watcher;\n+                assert!(status.is_none());\n+                idle_watcher.stop();\n+                do idle_watcher.start |idle_watcher, status| {\n+                    assert!(status.is_none());\n+                    let mut idle_watcher = idle_watcher;\n+                    idle_watcher.stop();\n+                    idle_watcher.close(||());\n+                }\n+            }\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+}"}, {"sha": "0eaf0dd3ab6495e794f417ed4c78d0dfab56a28c", "filename": "src/libstd/rt/uv/mod.rs", "status": "modified", "additions": 15, "deletions": 57, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fmod.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -47,15 +47,17 @@ use libc::{c_void, c_int, size_t, malloc, free};\n use cast::transmute;\n use ptr::null;\n use unstable::finally::Finally;\n+use rt::io::net::ip::IpAddr;\n \n use rt::io::IoError;\n \n #[cfg(test)] use unstable::run_in_bare_thread;\n \n pub use self::file::FsRequest;\n-pub use self::net::{StreamWatcher, TcpWatcher};\n+pub use self::net::{StreamWatcher, TcpWatcher, UdpWatcher};\n pub use self::idle::IdleWatcher;\n pub use self::timer::TimerWatcher;\n+pub use self::async::AsyncWatcher;\n \n /// The implementation of `rtio` for libuv\n pub mod uvio;\n@@ -67,6 +69,7 @@ pub mod file;\n pub mod net;\n pub mod idle;\n pub mod timer;\n+pub mod async;\n \n /// XXX: Loop(*handle) is buggy with destructors. Normal structs\n /// with dtors may not be destructured, but tuple structs can,\n@@ -124,6 +127,9 @@ pub type IdleCallback = ~fn(IdleWatcher, Option<UvError>);\n pub type ConnectionCallback = ~fn(StreamWatcher, Option<UvError>);\n pub type FsCallback = ~fn(FsRequest, Option<UvError>);\n pub type TimerCallback = ~fn(TimerWatcher, Option<UvError>);\n+pub type AsyncCallback = ~fn(AsyncWatcher, Option<UvError>);\n+pub type UdpReceiveCallback = ~fn(UdpWatcher, int, Buf, IpAddr, uint, Option<UvError>);\n+pub type UdpSendCallback = ~fn(UdpWatcher, Option<UvError>);\n \n \n /// Callbacks used by StreamWatchers, set as custom data on the foreign handle\n@@ -134,7 +140,10 @@ struct WatcherData {\n     close_cb: Option<NullCallback>,\n     alloc_cb: Option<AllocCallback>,\n     idle_cb: Option<IdleCallback>,\n-    timer_cb: Option<TimerCallback>\n+    timer_cb: Option<TimerCallback>,\n+    async_cb: Option<AsyncCallback>,\n+    udp_recv_cb: Option<UdpReceiveCallback>,\n+    udp_send_cb: Option<UdpSendCallback>\n }\n \n pub trait WatcherInterop {\n@@ -163,7 +172,10 @@ impl<H, W: Watcher + NativeHandle<*H>> WatcherInterop for W {\n                 close_cb: None,\n                 alloc_cb: None,\n                 idle_cb: None,\n-                timer_cb: None\n+                timer_cb: None,\n+                async_cb: None,\n+                udp_recv_cb: None,\n+                udp_send_cb: None\n             };\n             let data = transmute::<~WatcherData, *c_void>(data);\n             uvll::set_data_for_uv_handle(self.native_handle(), data);\n@@ -348,57 +360,3 @@ fn loop_smoke_test() {\n         loop_.close();\n     }\n }\n-\n-#[test]\n-#[ignore(reason = \"valgrind - loop destroyed before watcher?\")]\n-fn idle_new_then_close() {\n-    do run_in_bare_thread {\n-        let mut loop_ = Loop::new();\n-        let idle_watcher = { IdleWatcher::new(&mut loop_) };\n-        idle_watcher.close(||());\n-    }\n-}\n-\n-#[test]\n-fn idle_smoke_test() {\n-    do run_in_bare_thread {\n-        let mut loop_ = Loop::new();\n-        let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n-        let mut count = 10;\n-        let count_ptr: *mut int = &mut count;\n-        do idle_watcher.start |idle_watcher, status| {\n-            let mut idle_watcher = idle_watcher;\n-            assert!(status.is_none());\n-            if unsafe { *count_ptr == 10 } {\n-                idle_watcher.stop();\n-                idle_watcher.close(||());\n-            } else {\n-                unsafe { *count_ptr = *count_ptr + 1; }\n-            }\n-        }\n-        loop_.run();\n-        loop_.close();\n-        assert_eq!(count, 10);\n-    }\n-}\n-\n-#[test]\n-fn idle_start_stop_start() {\n-    do run_in_bare_thread {\n-        let mut loop_ = Loop::new();\n-        let mut idle_watcher = { IdleWatcher::new(&mut loop_) };\n-        do idle_watcher.start |idle_watcher, status| {\n-            let mut idle_watcher = idle_watcher;\n-            assert!(status.is_none());\n-            idle_watcher.stop();\n-            do idle_watcher.start |idle_watcher, status| {\n-                assert!(status.is_none());\n-                let mut idle_watcher = idle_watcher;\n-                idle_watcher.stop();\n-                idle_watcher.close(||());\n-            }\n-        }\n-        loop_.run();\n-        loop_.close();\n-    }\n-}"}, {"sha": "6d096f9885a7d7fe5f04fac28d99e170d6a67292", "filename": "src/libstd/rt/uv/net.rs", "status": "modified", "additions": 566, "deletions": 91, "changes": 657, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fnet.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fnet.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fnet.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -9,35 +9,151 @@\n // except according to those terms.\n \n use prelude::*;\n-use libc::{size_t, ssize_t, c_int, c_void};\n+use libc::{size_t, ssize_t, c_int, c_void, c_uint};\n use rt::uv::uvll;\n use rt::uv::uvll::*;\n-use rt::uv::{AllocCallback, ConnectionCallback, ReadCallback};\n+use rt::uv::{AllocCallback, ConnectionCallback, ReadCallback, UdpReceiveCallback, UdpSendCallback};\n use rt::uv::{Loop, Watcher, Request, UvError, Buf, NativeHandle, NullCallback,\n              status_to_maybe_uv_error};\n use rt::io::net::ip::{IpAddr, Ipv4, Ipv6};\n use rt::uv::last_uv_error;\n+use vec;\n+use str;\n+use from_str::{FromStr};\n+use num;\n+\n+enum UvIpAddr {\n+    UvIpv4(*sockaddr_in),\n+    UvIpv6(*sockaddr_in6),\n+}\n \n-fn ip4_as_uv_ip4<T>(addr: IpAddr, f: &fn(*sockaddr_in) -> T) -> T {\n-    match addr {\n-        Ipv4(a, b, c, d, p) => {\n-            unsafe {\n-                let addr = malloc_ip4_addr(fmt!(\"%u.%u.%u.%u\",\n-                                                a as uint,\n-                                                b as uint,\n-                                                c as uint,\n-                                                d as uint), p as int);\n-                do (|| {\n-                    f(addr)\n-                }).finally {\n-                    free_ip4_addr(addr);\n-                }\n-            }\n+fn sockaddr_to_UvIpAddr(addr: *uvll::sockaddr) -> UvIpAddr {\n+    unsafe {\n+        assert!((is_ip4_addr(addr) || is_ip6_addr(addr)));\n+        assert!(!(is_ip4_addr(addr) && is_ip6_addr(addr)));\n+        match addr {\n+            _ if is_ip4_addr(addr) => UvIpv4(as_sockaddr_in(addr)),\n+            _ if is_ip6_addr(addr) => UvIpv6(as_sockaddr_in6(addr)),\n+            _ => fail!(),\n         }\n-        Ipv6 => fail!()\n     }\n }\n \n+fn ip_as_uv_ip<T>(addr: IpAddr, f: &fn(UvIpAddr) -> T) -> T {\n+    let malloc = match addr {\n+        Ipv4(*) => malloc_ip4_addr,\n+        Ipv6(*) => malloc_ip6_addr,\n+    };\n+    let wrap = match addr {\n+        Ipv4(*) => UvIpv4,\n+        Ipv6(*) => UvIpv6,\n+    };\n+    let ip_str = match addr {\n+        Ipv4(x1, x2, x3, x4, _) =>\n+            fmt!(\"%u.%u.%u.%u\", x1 as uint, x2 as uint, x3 as uint, x4 as uint),\n+        Ipv6(x1, x2, x3, x4, x5, x6, x7, x8, _) =>\n+            fmt!(\"%x:%x:%x:%x:%x:%x:%x:%x\",\n+                  x1 as uint, x2 as uint, x3 as uint, x4 as uint,\n+                  x5 as uint, x6 as uint, x7 as uint, x8 as uint),\n+    };\n+    let port = match addr {\n+        Ipv4(_, _, _, _, p) | Ipv6(_, _, _, _, _, _, _, _, p) => p as int\n+    };\n+    let free = match addr {\n+        Ipv4(*) => free_ip4_addr,\n+        Ipv6(*) => free_ip6_addr,\n+    };\n+\n+    let addr = unsafe { malloc(ip_str, port) };\n+    do (|| {\n+        f(wrap(addr))\n+    }).finally {\n+        unsafe { free(addr) };\n+    }\n+}\n+\n+fn uv_ip_as_ip<T>(addr: UvIpAddr, f: &fn(IpAddr) -> T) -> T {\n+    let ip_size = match addr {\n+        UvIpv4(*) => 4/*groups of*/ * 3/*digits separated by*/ + 3/*periods*/,\n+        UvIpv6(*) => 8/*groups of*/ * 4/*hex digits separated by*/ + 7 /*colons*/,\n+    };\n+    let ip_name = {\n+        let buf = vec::from_elem(ip_size + 1 /*null terminated*/, 0u8);\n+        unsafe {\n+            match addr {\n+                UvIpv4(addr) => uvll::ip4_name(addr, vec::raw::to_ptr(buf), ip_size as size_t),\n+                UvIpv6(addr) => uvll::ip6_name(addr, vec::raw::to_ptr(buf), ip_size as size_t),\n+            }\n+        };\n+        buf\n+    };\n+    let ip_port = unsafe {\n+        let port = match addr {\n+            UvIpv4(addr) => uvll::ip4_port(addr),\n+            UvIpv6(addr) => uvll::ip6_port(addr),\n+        };\n+        port as u16\n+    };\n+    let ip_str = str::from_bytes_slice(ip_name).trim_right_chars(&'\\x00');\n+    let ip = match addr {\n+        UvIpv4(*) => {\n+            let ip: ~[u8] =\n+                ip_str.split_iter('.')\n+                      .transform(|s: &str| -> u8 { FromStr::from_str(s).unwrap() })\n+                      .collect();\n+            assert_eq!(ip.len(), 4);\n+            Ipv4(ip[0], ip[1], ip[2], ip[3], ip_port)\n+        },\n+        UvIpv6(*) => {\n+            let ip: ~[u16] = {\n+                let expand_shorthand_and_convert = |s: &str| -> ~[~[u16]] {\n+                    let convert_each_segment = |s: &str| -> ~[u16] {\n+                        let read_hex_segment = |s: &str| -> u16 {\n+                            num::FromStrRadix::from_str_radix(s, 16u).unwrap()\n+                        };\n+                        match s {\n+                            \"\" => ~[],\n+                            s => s.split_iter(':').transform(read_hex_segment).collect(),\n+                        }\n+                    };\n+                    s.split_str_iter(\"::\").transform(convert_each_segment).collect()\n+                };\n+                match expand_shorthand_and_convert(ip_str) {\n+                    [x] => x, // no shorthand found\n+                    [l, r] => l + vec::from_elem(8 - l.len() - r.len(), 0u16) + r, // fill the gap\n+                    _ => fail!(), // impossible. only one shorthand allowed.\n+                }\n+            };\n+            assert_eq!(ip.len(), 8);\n+            Ipv6(ip[0], ip[1], ip[2], ip[3], ip[4], ip[5], ip[6], ip[7], ip_port)\n+        },\n+    };\n+\n+    // finally run the closure\n+    f(ip)\n+}\n+\n+fn uv_ip_to_ip(addr: UvIpAddr) -> IpAddr {\n+    use util;\n+    uv_ip_as_ip(addr, util::id)\n+}\n+\n+#[cfg(test)]\n+#[test]\n+fn test_ip4_conversion() {\n+    use rt;\n+    let ip4 = rt::test::next_test_ip4();\n+    assert_eq!(ip4, ip_as_uv_ip(ip4, uv_ip_to_ip));\n+}\n+\n+#[cfg(test)]\n+#[test]\n+fn test_ip6_conversion() {\n+    use rt;\n+    let ip6 = rt::test::next_test_ip6();\n+    assert_eq!(ip6, ip_as_uv_ip(ip6, uv_ip_to_ip));\n+}\n+\n // uv_stream t is the parent class of uv_tcp_t, uv_pipe_t, uv_tty_t\n // and uv_file_t\n pub struct StreamWatcher(*uvll::uv_stream_t);\n@@ -51,22 +167,19 @@ impl StreamWatcher {\n             data.read_cb = Some(cb);\n         }\n \n-        let handle = self.native_handle();\n-        unsafe { uvll::read_start(handle, alloc_cb, read_cb); }\n+        unsafe { uvll::read_start(self.native_handle(), alloc_cb, read_cb); }\n \n         extern fn alloc_cb(stream: *uvll::uv_stream_t, suggested_size: size_t) -> Buf {\n             let mut stream_watcher: StreamWatcher = NativeHandle::from_native_handle(stream);\n-            let data = stream_watcher.get_watcher_data();\n-            let alloc_cb = data.alloc_cb.get_ref();\n+            let alloc_cb = stream_watcher.get_watcher_data().alloc_cb.get_ref();\n             return (*alloc_cb)(suggested_size as uint);\n         }\n \n         extern fn read_cb(stream: *uvll::uv_stream_t, nread: ssize_t, buf: Buf) {\n             rtdebug!(\"buf addr: %x\", buf.base as uint);\n             rtdebug!(\"buf len: %d\", buf.len as int);\n             let mut stream_watcher: StreamWatcher = NativeHandle::from_native_handle(stream);\n-            let data = stream_watcher.get_watcher_data();\n-            let cb = data.read_cb.get_ref();\n+            let cb = stream_watcher.get_watcher_data().read_cb.get_ref();\n             let status = status_to_maybe_uv_error(stream, nread as c_int);\n             (*cb)(stream_watcher, nread as int, buf, status);\n         }\n@@ -88,22 +201,15 @@ impl StreamWatcher {\n         }\n \n         let req = WriteRequest::new();\n-        let bufs = [buf];\n         unsafe {\n-            assert!(0 == uvll::write(req.native_handle(),\n-                                     self.native_handle(),\n-                                     bufs, write_cb));\n+        assert_eq!(0, uvll::write(req.native_handle(), self.native_handle(), [buf], write_cb));\n         }\n \n         extern fn write_cb(req: *uvll::uv_write_t, status: c_int) {\n             let write_request: WriteRequest = NativeHandle::from_native_handle(req);\n             let mut stream_watcher = write_request.stream();\n             write_request.delete();\n-            let cb = {\n-                let data = stream_watcher.get_watcher_data();\n-                let cb = data.write_cb.swap_unwrap();\n-                cb\n-            };\n+            let cb = stream_watcher.get_watcher_data().write_cb.swap_unwrap();\n             let status = status_to_maybe_uv_error(stream_watcher.native_handle(), status);\n             cb(stream_watcher, status);\n         }\n@@ -112,9 +218,7 @@ impl StreamWatcher {\n     pub fn accept(&mut self, stream: StreamWatcher) {\n         let self_handle = self.native_handle() as *c_void;\n         let stream_handle = stream.native_handle() as *c_void;\n-        unsafe {\n-            assert_eq!(0, uvll::accept(self_handle, stream_handle));\n-        }\n+        assert_eq!(0, unsafe { uvll::accept(self_handle, stream_handle) } );\n     }\n \n     pub fn close(self, cb: NullCallback) {\n@@ -129,19 +233,15 @@ impl StreamWatcher {\n \n         extern fn close_cb(handle: *uvll::uv_stream_t) {\n             let mut stream_watcher: StreamWatcher = NativeHandle::from_native_handle(handle);\n-            {\n-                let data = stream_watcher.get_watcher_data();\n-                data.close_cb.swap_unwrap()();\n-            }\n+            stream_watcher.get_watcher_data().close_cb.swap_unwrap()();\n             stream_watcher.drop_watcher_data();\n             unsafe { free_handle(handle as *c_void) }\n         }\n     }\n }\n \n impl NativeHandle<*uvll::uv_stream_t> for StreamWatcher {\n-    fn from_native_handle(\n-        handle: *uvll::uv_stream_t) -> StreamWatcher {\n+    fn from_native_handle(handle: *uvll::uv_stream_t) -> StreamWatcher {\n         StreamWatcher(handle)\n     }\n     fn native_handle(&self) -> *uvll::uv_stream_t {\n@@ -153,7 +253,7 @@ pub struct TcpWatcher(*uvll::uv_tcp_t);\n impl Watcher for TcpWatcher { }\n \n impl TcpWatcher {\n-    pub fn new(loop_: &mut Loop) -> TcpWatcher {\n+    pub fn new(loop_: &Loop) -> TcpWatcher {\n         unsafe {\n             let handle = malloc_handle(UV_TCP);\n             assert!(handle.is_not_null());\n@@ -165,20 +265,17 @@ impl TcpWatcher {\n     }\n \n     pub fn bind(&mut self, address: IpAddr) -> Result<(), UvError> {\n-        match address {\n-            Ipv4(*) => {\n-                do ip4_as_uv_ip4(address) |addr| {\n-                    let result = unsafe {\n-                        uvll::tcp_bind(self.native_handle(), addr)\n-                    };\n-                    if result == 0 {\n-                        Ok(())\n-                    } else {\n-                        Err(last_uv_error(self))\n-                    }\n+        do ip_as_uv_ip(address) |addr| {\n+            let result = unsafe {\n+                match addr {\n+                    UvIpv4(addr) => uvll::tcp_bind(self.native_handle(), addr),\n+                    UvIpv6(addr) => uvll::tcp_bind6(self.native_handle(), addr),\n                 }\n+            };\n+            match result {\n+                0 => Ok(()),\n+                _ => Err(last_uv_error(self)),\n             }\n-            _ => fail!()\n         }\n     }\n \n@@ -188,27 +285,23 @@ impl TcpWatcher {\n             self.get_watcher_data().connect_cb = Some(cb);\n \n             let connect_handle = ConnectRequest::new().native_handle();\n-            match address {\n-                Ipv4(*) => {\n-                    do ip4_as_uv_ip4(address) |addr| {\n-                        rtdebug!(\"connect_t: %x\", connect_handle as uint);\n-                        assert!(0 == uvll::tcp_connect(connect_handle,\n-                                                            self.native_handle(),\n-                                                            addr, connect_cb));\n-                    }\n-                }\n-                _ => fail!()\n+            rtdebug!(\"connect_t: %x\", connect_handle as uint);\n+            do ip_as_uv_ip(address) |addr| {\n+                let result = match addr {\n+                    UvIpv4(addr) => uvll::tcp_connect(connect_handle,\n+                                                      self.native_handle(), addr, connect_cb),\n+                    UvIpv6(addr) => uvll::tcp_connect6(connect_handle,\n+                                                       self.native_handle(), addr, connect_cb),\n+                };\n+                assert_eq!(0, result);\n             }\n \n             extern fn connect_cb(req: *uvll::uv_connect_t, status: c_int) {\n                 rtdebug!(\"connect_t: %x\", req as uint);\n                 let connect_request: ConnectRequest = NativeHandle::from_native_handle(req);\n                 let mut stream_watcher = connect_request.stream();\n                 connect_request.delete();\n-                let cb: ConnectionCallback = {\n-                    let data = stream_watcher.get_watcher_data();\n-                    data.connect_cb.swap_unwrap()\n-                };\n+                let cb = stream_watcher.get_watcher_data().connect_cb.swap_unwrap();\n                 let status = status_to_maybe_uv_error(stream_watcher.native_handle(), status);\n                 cb(stream_watcher, status);\n             }\n@@ -225,15 +318,13 @@ impl TcpWatcher {\n         unsafe {\n             static BACKLOG: c_int = 128; // XXX should be configurable\n             // XXX: This can probably fail\n-            assert!(0 == uvll::listen(self.native_handle(),\n-                                           BACKLOG, connection_cb));\n+            assert_eq!(0, uvll::listen(self.native_handle(), BACKLOG, connection_cb));\n         }\n \n         extern fn connection_cb(handle: *uvll::uv_stream_t, status: c_int) {\n             rtdebug!(\"connection_cb\");\n             let mut stream_watcher: StreamWatcher = NativeHandle::from_native_handle(handle);\n-            let data = stream_watcher.get_watcher_data();\n-            let cb = data.connect_cb.get_ref();\n+            let cb = stream_watcher.get_watcher_data().connect_cb.get_ref();\n             let status = status_to_maybe_uv_error(handle, status);\n             (*cb)(stream_watcher, status);\n         }\n@@ -253,19 +344,144 @@ impl NativeHandle<*uvll::uv_tcp_t> for TcpWatcher {\n     }\n }\n \n+pub struct UdpWatcher(*uvll::uv_udp_t);\n+impl Watcher for UdpWatcher { }\n+\n+impl UdpWatcher {\n+    pub fn new(loop_: &Loop) -> UdpWatcher {\n+        unsafe {\n+            let handle = malloc_handle(UV_UDP);\n+            assert!(handle.is_not_null());\n+            assert_eq!(0, uvll::udp_init(loop_.native_handle(), handle));\n+            let mut watcher: UdpWatcher = NativeHandle::from_native_handle(handle);\n+            watcher.install_watcher_data();\n+            return watcher;\n+        }\n+    }\n+\n+    pub fn bind(&self, address: IpAddr) -> Result<(), UvError> {\n+        do ip_as_uv_ip(address) |addr| {\n+            let result = unsafe {\n+                match addr {\n+                    UvIpv4(addr) => uvll::udp_bind(self.native_handle(), addr, 0u32),\n+                    UvIpv6(addr) => uvll::udp_bind6(self.native_handle(), addr, 0u32),\n+                }\n+            };\n+            match result {\n+                0 => Ok(()),\n+                _ => Err(last_uv_error(self)),\n+            }\n+        }\n+    }\n+\n+    pub fn recv_start(&self, alloc: AllocCallback, cb: UdpReceiveCallback) {\n+        {\n+            let mut this = *self;\n+            let data = this.get_watcher_data();\n+            data.alloc_cb = Some(alloc);\n+            data.udp_recv_cb = Some(cb);\n+        }\n+\n+        unsafe { uvll::udp_recv_start(self.native_handle(), alloc_cb, recv_cb); }\n+\n+        extern fn alloc_cb(handle: *uvll::uv_udp_t, suggested_size: size_t) -> Buf {\n+            let mut udp_watcher: UdpWatcher = NativeHandle::from_native_handle(handle);\n+            let alloc_cb = udp_watcher.get_watcher_data().alloc_cb.get_ref();\n+            return (*alloc_cb)(suggested_size as uint);\n+        }\n+\n+        extern fn recv_cb(handle: *uvll::uv_udp_t, nread: ssize_t, buf: Buf,\n+                          addr: *uvll::sockaddr, flags: c_uint) {\n+            // When there's no data to read the recv callback can be a no-op.\n+            // This can happen if read returns EAGAIN/EWOULDBLOCK. By ignoring\n+            // this we just drop back to kqueue and wait for the next callback.\n+            if nread == 0 {\n+                return;\n+            }\n+\n+            rtdebug!(\"buf addr: %x\", buf.base as uint);\n+            rtdebug!(\"buf len: %d\", buf.len as int);\n+            let mut udp_watcher: UdpWatcher = NativeHandle::from_native_handle(handle);\n+            let cb = udp_watcher.get_watcher_data().udp_recv_cb.get_ref();\n+            let status = status_to_maybe_uv_error(handle, nread as c_int);\n+            let addr = uv_ip_to_ip(sockaddr_to_UvIpAddr(addr));\n+            (*cb)(udp_watcher, nread as int, buf, addr, flags as uint, status);\n+        }\n+    }\n+\n+    pub fn recv_stop(&self) {\n+        unsafe { uvll::udp_recv_stop(self.native_handle()); }\n+    }\n+\n+    pub fn send(&self, buf: Buf, address: IpAddr, cb: UdpSendCallback) {\n+        {\n+            let mut this = *self;\n+            let data = this.get_watcher_data();\n+            assert!(data.udp_send_cb.is_none());\n+            data.udp_send_cb = Some(cb);\n+        }\n+\n+        let req = UdpSendRequest::new();\n+        do ip_as_uv_ip(address) |addr| {\n+            let result = unsafe {\n+                match addr {\n+                    UvIpv4(addr) => uvll::udp_send(req.native_handle(),\n+                                                   self.native_handle(), [buf], addr, send_cb),\n+                    UvIpv6(addr) => uvll::udp_send6(req.native_handle(),\n+                                                    self.native_handle(), [buf], addr, send_cb),\n+                }\n+            };\n+            assert_eq!(0, result);\n+        }\n+\n+        extern fn send_cb(req: *uvll::uv_udp_send_t, status: c_int) {\n+            let send_request: UdpSendRequest = NativeHandle::from_native_handle(req);\n+            let mut udp_watcher = send_request.handle();\n+            send_request.delete();\n+            let cb = udp_watcher.get_watcher_data().udp_send_cb.swap_unwrap();\n+            let status = status_to_maybe_uv_error(udp_watcher.native_handle(), status);\n+            cb(udp_watcher, status);\n+        }\n+    }\n+\n+    pub fn close(self, cb: NullCallback) {\n+        {\n+            let mut this = self;\n+            let data = this.get_watcher_data();\n+            assert!(data.close_cb.is_none());\n+            data.close_cb = Some(cb);\n+        }\n+\n+        unsafe { uvll::close(self.native_handle(), close_cb); }\n+\n+        extern fn close_cb(handle: *uvll::uv_udp_t) {\n+            let mut udp_watcher: UdpWatcher = NativeHandle::from_native_handle(handle);\n+            udp_watcher.get_watcher_data().close_cb.swap_unwrap()();\n+            udp_watcher.drop_watcher_data();\n+            unsafe { free_handle(handle as *c_void) }\n+        }\n+    }\n+}\n+\n+impl NativeHandle<*uvll::uv_udp_t> for UdpWatcher {\n+    fn from_native_handle(handle: *uvll::uv_udp_t) -> UdpWatcher {\n+        UdpWatcher(handle)\n+    }\n+    fn native_handle(&self) -> *uvll::uv_udp_t {\n+        match self { &UdpWatcher(ptr) => ptr }\n+    }\n+}\n+\n // uv_connect_t is a subclass of uv_req_t\n struct ConnectRequest(*uvll::uv_connect_t);\n impl Request for ConnectRequest { }\n \n impl ConnectRequest {\n \n     fn new() -> ConnectRequest {\n-        let connect_handle = unsafe {\n-            malloc_req(UV_CONNECT)\n-        };\n+        let connect_handle = unsafe { malloc_req(UV_CONNECT) };\n         assert!(connect_handle.is_not_null());\n-        let connect_handle = connect_handle as *uvll::uv_connect_t;\n-        ConnectRequest(connect_handle)\n+        ConnectRequest(connect_handle as *uvll::uv_connect_t)\n     }\n \n     fn stream(&self) -> StreamWatcher {\n@@ -281,8 +497,7 @@ impl ConnectRequest {\n }\n \n impl NativeHandle<*uvll::uv_connect_t> for ConnectRequest {\n-    fn from_native_handle(\n-        handle: *uvll:: uv_connect_t) -> ConnectRequest {\n+    fn from_native_handle(handle: *uvll:: uv_connect_t) -> ConnectRequest {\n         ConnectRequest(handle)\n     }\n     fn native_handle(&self) -> *uvll::uv_connect_t {\n@@ -296,12 +511,9 @@ impl Request for WriteRequest { }\n \n impl WriteRequest {\n     pub fn new() -> WriteRequest {\n-        let write_handle = unsafe {\n-            malloc_req(UV_WRITE)\n-        };\n+        let write_handle = unsafe { malloc_req(UV_WRITE) };\n         assert!(write_handle.is_not_null());\n-        let write_handle = write_handle as *uvll::uv_write_t;\n-        WriteRequest(write_handle)\n+        WriteRequest(write_handle as *uvll::uv_write_t)\n     }\n \n     pub fn stream(&self) -> StreamWatcher {\n@@ -325,6 +537,36 @@ impl NativeHandle<*uvll::uv_write_t> for WriteRequest {\n     }\n }\n \n+pub struct UdpSendRequest(*uvll::uv_udp_send_t);\n+impl Request for UdpSendRequest { }\n+\n+impl UdpSendRequest {\n+    pub fn new() -> UdpSendRequest {\n+        let send_handle = unsafe { malloc_req(UV_UDP_SEND) };\n+        assert!(send_handle.is_not_null());\n+        UdpSendRequest(send_handle as *uvll::uv_udp_send_t)\n+    }\n+\n+    pub fn handle(&self) -> UdpWatcher {\n+        let send_request_handle = unsafe {\n+            uvll::get_udp_handle_from_send_req(self.native_handle())\n+        };\n+        NativeHandle::from_native_handle(send_request_handle)\n+    }\n+\n+    pub fn delete(self) {\n+        unsafe { free_req(self.native_handle() as *c_void) }\n+    }\n+}\n+\n+impl NativeHandle<*uvll::uv_udp_send_t> for UdpSendRequest {\n+    fn from_native_handle(handle: *uvll::uv_udp_send_t) -> UdpSendRequest {\n+        UdpSendRequest(handle)\n+    }\n+    fn native_handle(&self) -> *uvll::uv_udp_send_t {\n+        match self { &UdpSendRequest(ptr) => ptr }\n+    }\n+}\n \n #[cfg(test)]\n mod test {\n@@ -339,7 +581,7 @@ mod test {\n     use rt::uv::{vec_from_uv_buf, vec_to_uv_buf, slice_to_uv_buf};\n \n     #[test]\n-    fn connect_close() {\n+    fn connect_close_ip4() {\n         do run_in_bare_thread() {\n             let mut loop_ = Loop::new();\n             let mut tcp_watcher = { TcpWatcher::new(&mut loop_) };\n@@ -357,7 +599,51 @@ mod test {\n     }\n \n     #[test]\n-    fn listen() {\n+    fn connect_close_ip6() {\n+        do run_in_bare_thread() {\n+            let mut loop_ = Loop::new();\n+            let mut tcp_watcher = { TcpWatcher::new(&mut loop_) };\n+            // Connect to a port where nobody is listening\n+            let addr = next_test_ip6();\n+            do tcp_watcher.connect(addr) |stream_watcher, status| {\n+                rtdebug!(\"tcp_watcher.connect!\");\n+                assert!(status.is_some());\n+                assert_eq!(status.get().name(), ~\"ECONNREFUSED\");\n+                stream_watcher.close(||());\n+            }\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+\n+    #[test]\n+    fn udp_bind_close_ip4() {\n+        do run_in_bare_thread() {\n+            let mut loop_ = Loop::new();\n+            let udp_watcher = { UdpWatcher::new(&mut loop_) };\n+            let addr = next_test_ip4();\n+            udp_watcher.bind(addr);\n+            udp_watcher.close(||());\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+\n+    #[test]\n+    fn udp_bind_close_ip6() {\n+        do run_in_bare_thread() {\n+            let mut loop_ = Loop::new();\n+            let udp_watcher = { UdpWatcher::new(&mut loop_) };\n+            let addr = next_test_ip6();\n+            udp_watcher.bind(addr);\n+            udp_watcher.close(||());\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+\n+    #[test]\n+    fn listen_ip4() {\n         do run_in_bare_thread() {\n             static MAX: int = 10;\n             let mut loop_ = Loop::new();\n@@ -366,10 +652,82 @@ mod test {\n             server_tcp_watcher.bind(addr);\n             let loop_ = loop_;\n             rtdebug!(\"listening\");\n-            do server_tcp_watcher.listen |server_stream_watcher, status| {\n+            do server_tcp_watcher.listen |mut server_stream_watcher, status| {\n+                rtdebug!(\"listened!\");\n+                assert!(status.is_none());\n+                let mut loop_ = loop_;\n+                let client_tcp_watcher = TcpWatcher::new(&mut loop_);\n+                let mut client_tcp_watcher = client_tcp_watcher.as_stream();\n+                server_stream_watcher.accept(client_tcp_watcher);\n+                let count_cell = Cell::new(0);\n+                let server_stream_watcher = server_stream_watcher;\n+                rtdebug!(\"starting read\");\n+                let alloc: AllocCallback = |size| {\n+                    vec_to_uv_buf(vec::from_elem(size, 0))\n+                };\n+                do client_tcp_watcher.read_start(alloc) |stream_watcher, nread, buf, status| {\n+\n+                    rtdebug!(\"i'm reading!\");\n+                    let buf = vec_from_uv_buf(buf);\n+                    let mut count = count_cell.take();\n+                    if status.is_none() {\n+                        rtdebug!(\"got %d bytes\", nread);\n+                        let buf = buf.unwrap();\n+                        for buf.slice(0, nread as uint).iter().advance() |byte| {\n+                            assert!(*byte == count as u8);\n+                            rtdebug!(\"%u\", *byte as uint);\n+                            count += 1;\n+                        }\n+                    } else {\n+                        assert_eq!(count, MAX);\n+                        do stream_watcher.close {\n+                            server_stream_watcher.close(||());\n+                        }\n+                    }\n+                    count_cell.put_back(count);\n+                }\n+            }\n+\n+            let _client_thread = do Thread::start {\n+                rtdebug!(\"starting client thread\");\n+                let mut loop_ = Loop::new();\n+                let mut tcp_watcher = { TcpWatcher::new(&mut loop_) };\n+                do tcp_watcher.connect(addr) |mut stream_watcher, status| {\n+                    rtdebug!(\"connecting\");\n+                    assert!(status.is_none());\n+                    let msg = ~[0, 1, 2, 3, 4, 5, 6 ,7 ,8, 9];\n+                    let buf = slice_to_uv_buf(msg);\n+                    let msg_cell = Cell::new(msg);\n+                    do stream_watcher.write(buf) |stream_watcher, status| {\n+                        rtdebug!(\"writing\");\n+                        assert!(status.is_none());\n+                        let msg_cell = Cell::new(msg_cell.take());\n+                        stream_watcher.close(||ignore(msg_cell.take()));\n+                    }\n+                }\n+                loop_.run();\n+                loop_.close();\n+            };\n+\n+            let mut loop_ = loop_;\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+\n+    #[test]\n+    fn listen_ip6() {\n+        do run_in_bare_thread() {\n+            static MAX: int = 10;\n+            let mut loop_ = Loop::new();\n+            let mut server_tcp_watcher = { TcpWatcher::new(&mut loop_) };\n+            let addr = next_test_ip6();\n+            server_tcp_watcher.bind(addr);\n+            let loop_ = loop_;\n+            rtdebug!(\"listening\");\n+            do server_tcp_watcher.listen |mut server_stream_watcher, status| {\n                 rtdebug!(\"listened!\");\n                 assert!(status.is_none());\n-                let mut server_stream_watcher = server_stream_watcher;\n                 let mut loop_ = loop_;\n                 let client_tcp_watcher = TcpWatcher::new(&mut loop_);\n                 let mut client_tcp_watcher = client_tcp_watcher.as_stream();\n@@ -409,10 +767,9 @@ mod test {\n                 rtdebug!(\"starting client thread\");\n                 let mut loop_ = Loop::new();\n                 let mut tcp_watcher = { TcpWatcher::new(&mut loop_) };\n-                do tcp_watcher.connect(addr) |stream_watcher, status| {\n+                do tcp_watcher.connect(addr) |mut stream_watcher, status| {\n                     rtdebug!(\"connecting\");\n                     assert!(status.is_none());\n-                    let mut stream_watcher = stream_watcher;\n                     let msg = ~[0, 1, 2, 3, 4, 5, 6 ,7 ,8, 9];\n                     let buf = slice_to_uv_buf(msg);\n                     let msg_cell = Cell::new(msg);\n@@ -432,4 +789,122 @@ mod test {\n             loop_.close();\n         }\n     }\n+\n+    #[test]\n+    fn udp_recv_ip4() {\n+        do run_in_bare_thread() {\n+            static MAX: int = 10;\n+            let mut loop_ = Loop::new();\n+            let server_addr = next_test_ip4();\n+            let client_addr = next_test_ip4();\n+\n+            let server = UdpWatcher::new(&loop_);\n+            assert!(server.bind(server_addr).is_ok());\n+\n+            rtdebug!(\"starting read\");\n+            let alloc: AllocCallback = |size| {\n+                vec_to_uv_buf(vec::from_elem(size, 0))\n+            };\n+\n+            do server.recv_start(alloc) |server, nread, buf, src, flags, status| {\n+                server.recv_stop();\n+                rtdebug!(\"i'm reading!\");\n+                assert!(status.is_none());\n+                assert_eq!(flags, 0);\n+                assert_eq!(src, client_addr);\n+\n+                let buf = vec_from_uv_buf(buf);\n+                let mut count = 0;\n+                rtdebug!(\"got %d bytes\", nread);\n+\n+                let buf = buf.unwrap();\n+                for buf.slice(0, nread as uint).iter().advance() |&byte| {\n+                    assert!(byte == count as u8);\n+                    rtdebug!(\"%u\", byte as uint);\n+                    count += 1;\n+                }\n+                assert_eq!(count, MAX);\n+\n+                server.close(||{});\n+            }\n+\n+            do Thread::start {\n+                let mut loop_ = Loop::new();\n+                let client = UdpWatcher::new(&loop_);\n+                assert!(client.bind(client_addr).is_ok());\n+                let msg = ~[0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n+                let buf = slice_to_uv_buf(msg);\n+                do client.send(buf, server_addr) |client, status| {\n+                    rtdebug!(\"writing\");\n+                    assert!(status.is_none());\n+                    client.close(||{});\n+                }\n+\n+                loop_.run();\n+                loop_.close();\n+            };\n+\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n+\n+    #[test]\n+    fn udp_recv_ip6() {\n+        do run_in_bare_thread() {\n+            static MAX: int = 10;\n+            let mut loop_ = Loop::new();\n+            let server_addr = next_test_ip6();\n+            let client_addr = next_test_ip6();\n+\n+            let server = UdpWatcher::new(&loop_);\n+            assert!(server.bind(server_addr).is_ok());\n+\n+            rtdebug!(\"starting read\");\n+            let alloc: AllocCallback = |size| {\n+                vec_to_uv_buf(vec::from_elem(size, 0))\n+            };\n+\n+            do server.recv_start(alloc) |server, nread, buf, src, flags, status| {\n+                server.recv_stop();\n+                rtdebug!(\"i'm reading!\");\n+                assert!(status.is_none());\n+                assert_eq!(flags, 0);\n+                assert_eq!(src, client_addr);\n+\n+                let buf = vec_from_uv_buf(buf);\n+                let mut count = 0;\n+                rtdebug!(\"got %d bytes\", nread);\n+\n+                let buf = buf.unwrap();\n+                for buf.slice(0, nread as uint).iter().advance() |&byte| {\n+                    assert!(byte == count as u8);\n+                    rtdebug!(\"%u\", byte as uint);\n+                    count += 1;\n+                }\n+                assert_eq!(count, MAX);\n+\n+                server.close(||{});\n+            }\n+\n+            do Thread::start {\n+                let mut loop_ = Loop::new();\n+                let client = UdpWatcher::new(&loop_);\n+                assert!(client.bind(client_addr).is_ok());\n+                let msg = ~[0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n+                let buf = slice_to_uv_buf(msg);\n+                do client.send(buf, server_addr) |client, status| {\n+                    rtdebug!(\"writing\");\n+                    assert!(status.is_none());\n+                    client.close(||{});\n+                }\n+\n+                loop_.run();\n+                loop_.close();\n+            };\n+\n+            loop_.run();\n+            loop_.close();\n+        }\n+    }\n }"}, {"sha": "5d0c64c6867827d872d2363f4624df90209750ea", "filename": "src/libstd/rt/uv/uvio.rs", "status": "modified", "additions": 394, "deletions": 51, "changes": 445, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -12,6 +12,7 @@ use option::*;\n use result::*;\n use ops::Drop;\n use cell::Cell;\n+use cast;\n use cast::transmute;\n use clone::Clone;\n use rt::io::IoError;\n@@ -23,11 +24,15 @@ use rt::sched::Scheduler;\n use rt::io::{standard_error, OtherIoError};\n use rt::tube::Tube;\n use rt::local::Local;\n+use unstable::sync::{Exclusive, exclusive};\n \n #[cfg(test)] use container::Container;\n #[cfg(test)] use uint;\n #[cfg(test)] use unstable::run_in_bare_thread;\n-#[cfg(test)] use rt::test::*;\n+#[cfg(test)] use rt::test::{spawntask_immediately,\n+                            next_test_ip4,\n+                            run_in_newsched_task};\n+\n \n pub struct UvEventLoop {\n     uvio: UvIoFactory\n@@ -39,11 +44,6 @@ impl UvEventLoop {\n             uvio: UvIoFactory(Loop::new())\n         }\n     }\n-\n-    /// A convenience constructor\n-    pub fn new_scheduler() -> Scheduler {\n-        Scheduler::new(~UvEventLoop::new())\n-    }\n }\n \n impl Drop for UvEventLoop {\n@@ -63,9 +63,8 @@ impl EventLoop for UvEventLoop {\n \n     fn callback(&mut self, f: ~fn()) {\n         let mut idle_watcher =  IdleWatcher::new(self.uvio.uv_loop());\n-        do idle_watcher.start |idle_watcher, status| {\n+        do idle_watcher.start |mut idle_watcher, status| {\n             assert!(status.is_none());\n-            let mut idle_watcher = idle_watcher;\n             idle_watcher.stop();\n             idle_watcher.close(||());\n             f();\n@@ -81,6 +80,10 @@ impl EventLoop for UvEventLoop {\n         }\n     }\n \n+    fn remote_callback(&mut self, f: ~fn()) -> ~RemoteCallbackObject {\n+        ~UvRemoteCallback::new(self.uvio.uv_loop(), f)\n+    }\n+\n     fn io<'a>(&'a mut self) -> Option<&'a mut IoFactoryObject> {\n         Some(&mut self.uvio)\n     }\n@@ -100,6 +103,89 @@ fn test_callback_run_once() {\n     }\n }\n \n+pub struct UvRemoteCallback {\n+    // The uv async handle for triggering the callback\n+    async: AsyncWatcher,\n+    // A flag to tell the callback to exit, set from the dtor. This is\n+    // almost never contested - only in rare races with the dtor.\n+    exit_flag: Exclusive<bool>\n+}\n+\n+impl UvRemoteCallback {\n+    pub fn new(loop_: &mut Loop, f: ~fn()) -> UvRemoteCallback {\n+        let exit_flag = exclusive(false);\n+        let exit_flag_clone = exit_flag.clone();\n+        let async = do AsyncWatcher::new(loop_) |watcher, status| {\n+            assert!(status.is_none());\n+            f();\n+            unsafe {\n+                do exit_flag_clone.with_imm |&should_exit| {\n+                    if should_exit {\n+                        watcher.close(||());\n+                    }\n+                }\n+            }\n+        };\n+        UvRemoteCallback {\n+            async: async,\n+            exit_flag: exit_flag\n+        }\n+    }\n+}\n+\n+impl RemoteCallback for UvRemoteCallback {\n+    fn fire(&mut self) { self.async.send() }\n+}\n+\n+impl Drop for UvRemoteCallback {\n+    fn drop(&self) {\n+        unsafe {\n+            let this: &mut UvRemoteCallback = cast::transmute_mut(self);\n+            do this.exit_flag.with |should_exit| {\n+                // NB: These two things need to happen atomically. Otherwise\n+                // the event handler could wake up due to a *previous*\n+                // signal and see the exit flag, destroying the handle\n+                // before the final send.\n+                *should_exit = true;\n+                this.async.send();\n+            }\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test_remote {\n+    use cell::Cell;\n+    use rt::test::*;\n+    use rt::thread::Thread;\n+    use rt::tube::Tube;\n+    use rt::rtio::EventLoop;\n+    use rt::local::Local;\n+    use rt::sched::Scheduler;\n+\n+    #[test]\n+    fn test_uv_remote() {\n+        do run_in_newsched_task {\n+            let mut tube = Tube::new();\n+            let tube_clone = tube.clone();\n+            let remote_cell = Cell::new_empty();\n+            do Local::borrow::<Scheduler, ()>() |sched| {\n+                let tube_clone = tube_clone.clone();\n+                let tube_clone_cell = Cell::new(tube_clone);\n+                let remote = do sched.event_loop.remote_callback {\n+                    tube_clone_cell.take().send(1);\n+                };\n+                remote_cell.put_back(remote);\n+            }\n+            let _thread = do Thread::start {\n+                remote_cell.take().fire();\n+            };\n+\n+            assert!(tube.recv() == 1);\n+        }\n+    }\n+}\n+\n pub struct UvIoFactory(Loop);\n \n impl UvIoFactory {\n@@ -122,12 +208,10 @@ impl IoFactory for UvIoFactory {\n         assert!(scheduler.in_task_context());\n \n         // Block this task and take ownership, switch to scheduler context\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |sched, task| {\n \n             rtdebug!(\"connect: entered scheduler context\");\n-            do Local::borrow::<Scheduler> |scheduler| {\n-                assert!(!scheduler.in_task_context());\n-            }\n+            assert!(!sched.in_task_context());\n             let mut tcp_watcher = TcpWatcher::new(self.uv_loop());\n             let task_cell = Cell::new(task);\n \n@@ -136,7 +220,7 @@ impl IoFactory for UvIoFactory {\n                 rtdebug!(\"connect: in connect callback\");\n                 if status.is_none() {\n                     rtdebug!(\"status is none\");\n-                    let res = Ok(~UvTcpStream { watcher: stream_watcher });\n+                    let res = Ok(~UvTcpStream(stream_watcher));\n \n                     // Store the stream in the task's stack\n                     unsafe { (*result_cell_ptr).put_back(res); }\n@@ -167,7 +251,7 @@ impl IoFactory for UvIoFactory {\n             Ok(_) => Ok(~UvTcpListener::new(watcher)),\n             Err(uverr) => {\n                 let scheduler = Local::take::<Scheduler>();\n-                do scheduler.deschedule_running_task_and_then |task| {\n+                do scheduler.deschedule_running_task_and_then |_, task| {\n                     let task_cell = Cell::new(task);\n                     do watcher.as_stream().close {\n                         let scheduler = Local::take::<Scheduler>();\n@@ -178,6 +262,24 @@ impl IoFactory for UvIoFactory {\n             }\n         }\n     }\n+\n+    fn udp_bind(&mut self, addr: IpAddr) -> Result<~RtioUdpSocketObject, IoError> {\n+        let /*mut*/ watcher = UdpWatcher::new(self.uv_loop());\n+        match watcher.bind(addr) {\n+            Ok(_) => Ok(~UvUdpSocket(watcher)),\n+            Err(uverr) => {\n+                let scheduler = Local::take::<Scheduler>();\n+                do scheduler.deschedule_running_task_and_then |_, task| {\n+                    let task_cell = Cell::new(task);\n+                    do watcher.close {\n+                        let scheduler = Local::take::<Scheduler>();\n+                        scheduler.resume_task_immediately(task_cell.take());\n+                    }\n+                }\n+                Err(uv_error_to_io_error(uverr))\n+            }\n+        }\n+    }\n }\n \n // FIXME #6090: Prefer newtype structs but Drop doesn't work\n@@ -203,7 +305,7 @@ impl Drop for UvTcpListener {\n     fn drop(&self) {\n         let watcher = self.watcher();\n         let scheduler = Local::take::<Scheduler>();\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |_, task| {\n             let task_cell = Cell::new(task);\n             do watcher.as_stream().close {\n                 let scheduler = Local::take::<Scheduler>();\n@@ -213,6 +315,11 @@ impl Drop for UvTcpListener {\n     }\n }\n \n+impl RtioSocket for UvTcpListener {\n+    // XXX implement\n+    fn socket_name(&self) -> IpAddr { fail!(); }\n+}\n+\n impl RtioTcpListener for UvTcpListener {\n \n     fn accept(&mut self) -> Result<~RtioTcpStreamObject, IoError> {\n@@ -229,15 +336,14 @@ impl RtioTcpListener for UvTcpListener {\n \n         let incoming_streams_cell = Cell::new(incoming_streams_cell.take());\n         let mut server_tcp_watcher = server_tcp_watcher;\n-        do server_tcp_watcher.listen |server_stream_watcher, status| {\n+        do server_tcp_watcher.listen |mut server_stream_watcher, status| {\n             let maybe_stream = if status.is_none() {\n-                let mut server_stream_watcher = server_stream_watcher;\n                 let mut loop_ = server_stream_watcher.event_loop();\n                 let client_tcp_watcher = TcpWatcher::new(&mut loop_);\n                 let client_tcp_watcher = client_tcp_watcher.as_stream();\n                 // XXX: Need's to be surfaced in interface\n                 server_stream_watcher.accept(client_tcp_watcher);\n-                Ok(~UvTcpStream { watcher: client_tcp_watcher })\n+                Ok(~UvTcpStream(client_tcp_watcher))\n             } else {\n                 Err(standard_error(OtherIoError))\n             };\n@@ -249,60 +355,58 @@ impl RtioTcpListener for UvTcpListener {\n \n         return self.incoming_streams.recv();\n     }\n-}\n \n-// FIXME #6090: Prefer newtype structs but Drop doesn't work\n-pub struct UvTcpStream {\n-    watcher: StreamWatcher\n+    // XXX implement\n+    fn accept_simultaneously(&self) { fail!(); }\n+    fn dont_accept_simultaneously(&self) { fail!(); }\n }\n \n-impl UvTcpStream {\n-    fn watcher(&self) -> StreamWatcher { self.watcher }\n-}\n+// FIXME #6090: Prefer newtype structs but Drop doesn't work\n+pub struct UvTcpStream(StreamWatcher);\n \n impl Drop for UvTcpStream {\n     fn drop(&self) {\n         rtdebug!(\"closing tcp stream\");\n-        let watcher = self.watcher();\n         let scheduler = Local::take::<Scheduler>();\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |_, task| {\n             let task_cell = Cell::new(task);\n-            do watcher.close {\n+            do self.close {\n                 let scheduler = Local::take::<Scheduler>();\n                 scheduler.resume_task_immediately(task_cell.take());\n             }\n         }\n     }\n }\n \n+impl RtioSocket for UvTcpStream {\n+    // XXX implement\n+    fn socket_name(&self) -> IpAddr { fail!(); }\n+}\n+\n impl RtioTcpStream for UvTcpStream {\n-    fn read(&mut self, buf: &mut [u8]) -> Result<uint, IoError> {\n+    fn read(&self, buf: &mut [u8]) -> Result<uint, IoError> {\n         let result_cell = Cell::new_empty();\n         let result_cell_ptr: *Cell<Result<uint, IoError>> = &result_cell;\n \n         let scheduler = Local::take::<Scheduler>();\n         assert!(scheduler.in_task_context());\n-        let watcher = self.watcher();\n         let buf_ptr: *&mut [u8] = &buf;\n-        do scheduler.deschedule_running_task_and_then |task| {\n+        do scheduler.deschedule_running_task_and_then |sched, task| {\n             rtdebug!(\"read: entered scheduler context\");\n-            do Local::borrow::<Scheduler> |scheduler| {\n-                assert!(!scheduler.in_task_context());\n-            }\n-            let mut watcher = watcher;\n+            assert!(!sched.in_task_context());\n             let task_cell = Cell::new(task);\n             // XXX: We shouldn't reallocate these callbacks every\n             // call to read\n             let alloc: AllocCallback = |_| unsafe {\n                 slice_to_uv_buf(*buf_ptr)\n             };\n-            do watcher.read_start(alloc) |watcher, nread, _buf, status| {\n+            let mut watcher = **self;\n+            do watcher.read_start(alloc) |mut watcher, nread, _buf, status| {\n \n                 // Stop reading so that no read callbacks are\n                 // triggered before the user calls `read` again.\n                 // XXX: Is there a performance impact to calling\n                 // stop here?\n-                let mut watcher = watcher;\n                 watcher.read_stop();\n \n                 let result = if status.is_none() {\n@@ -323,17 +427,16 @@ impl RtioTcpStream for UvTcpStream {\n         return result_cell.take();\n     }\n \n-    fn write(&mut self, buf: &[u8]) -> Result<(), IoError> {\n+    fn write(&self, buf: &[u8]) -> Result<(), IoError> {\n         let result_cell = Cell::new_empty();\n         let result_cell_ptr: *Cell<Result<(), IoError>> = &result_cell;\n         let scheduler = Local::take::<Scheduler>();\n         assert!(scheduler.in_task_context());\n-        let watcher = self.watcher();\n         let buf_ptr: *&[u8] = &buf;\n-        do scheduler.deschedule_running_task_and_then |task| {\n-            let mut watcher = watcher;\n+        do scheduler.deschedule_running_task_and_then |_, task| {\n             let task_cell = Cell::new(task);\n             let buf = unsafe { slice_to_uv_buf(*buf_ptr) };\n+            let mut watcher = **self;\n             do watcher.write(buf) |_watcher, status| {\n                 let result = if status.is_none() {\n                     Ok(())\n@@ -351,6 +454,112 @@ impl RtioTcpStream for UvTcpStream {\n         assert!(!result_cell.is_empty());\n         return result_cell.take();\n     }\n+\n+    // XXX implement\n+    fn peer_name(&self) -> IpAddr { fail!(); }\n+    fn control_congestion(&self) { fail!(); }\n+    fn nodelay(&self) { fail!(); }\n+    fn keepalive(&self, _delay_in_seconds: uint) { fail!(); }\n+    fn letdie(&self) { fail!(); }\n+}\n+\n+pub struct UvUdpSocket(UdpWatcher);\n+\n+impl Drop for UvUdpSocket {\n+    fn drop(&self) {\n+        rtdebug!(\"closing udp socket\");\n+        let scheduler = Local::take::<Scheduler>();\n+        do scheduler.deschedule_running_task_and_then |_, task| {\n+            let task_cell = Cell::new(task);\n+            do self.close {\n+                let scheduler = Local::take::<Scheduler>();\n+                scheduler.resume_task_immediately(task_cell.take());\n+            }\n+        }\n+    }\n+}\n+\n+impl RtioSocket for UvUdpSocket {\n+    // XXX implement\n+    fn socket_name(&self) -> IpAddr { fail!(); }\n+}\n+\n+impl RtioUdpSocket for UvUdpSocket {\n+    fn recvfrom(&self, buf: &mut [u8]) -> Result<(uint, IpAddr), IoError> {\n+        let result_cell = Cell::new_empty();\n+        let result_cell_ptr: *Cell<Result<(uint, IpAddr), IoError>> = &result_cell;\n+\n+        let scheduler = Local::take::<Scheduler>();\n+        assert!(scheduler.in_task_context());\n+        let buf_ptr: *&mut [u8] = &buf;\n+        do scheduler.deschedule_running_task_and_then |sched, task| {\n+            rtdebug!(\"recvfrom: entered scheduler context\");\n+            assert!(!sched.in_task_context());\n+            let task_cell = Cell::new(task);\n+            let alloc: AllocCallback = |_| unsafe { slice_to_uv_buf(*buf_ptr) };\n+            do self.recv_start(alloc) |watcher, nread, _buf, addr, flags, status| {\n+                let _ = flags; // XXX add handling for partials?\n+\n+                watcher.recv_stop();\n+\n+                let result = match status {\n+                    None => {\n+                        assert!(nread >= 0);\n+                        Ok((nread as uint, addr))\n+                    }\n+                    Some(err) => Err(uv_error_to_io_error(err))\n+                };\n+\n+                unsafe { (*result_cell_ptr).put_back(result); }\n+\n+                let scheduler = Local::take::<Scheduler>();\n+                scheduler.resume_task_immediately(task_cell.take());\n+            }\n+        }\n+\n+        assert!(!result_cell.is_empty());\n+        return result_cell.take();\n+    }\n+\n+    fn sendto(&self, buf: &[u8], dst: IpAddr) -> Result<(), IoError> {\n+        let result_cell = Cell::new_empty();\n+        let result_cell_ptr: *Cell<Result<(), IoError>> = &result_cell;\n+        let scheduler = Local::take::<Scheduler>();\n+        assert!(scheduler.in_task_context());\n+        let buf_ptr: *&[u8] = &buf;\n+        do scheduler.deschedule_running_task_and_then |_, task| {\n+            let task_cell = Cell::new(task);\n+            let buf = unsafe { slice_to_uv_buf(*buf_ptr) };\n+            do self.send(buf, dst) |_watcher, status| {\n+\n+                let result = match status {\n+                    None => Ok(()),\n+                    Some(err) => Err(uv_error_to_io_error(err)),\n+                };\n+\n+                unsafe { (*result_cell_ptr).put_back(result); }\n+\n+                let scheduler = Local::take::<Scheduler>();\n+                scheduler.resume_task_immediately(task_cell.take());\n+            }\n+        }\n+\n+        assert!(!result_cell.is_empty());\n+        return result_cell.take();\n+    }\n+\n+    // XXX implement\n+    fn join_multicast(&self, _multi: IpAddr) { fail!(); }\n+    fn leave_multicast(&self, _multi: IpAddr) { fail!(); }\n+\n+    fn loop_multicast_locally(&self) { fail!(); }\n+    fn dont_loop_multicast_locally(&self) { fail!(); }\n+\n+    fn multicast_time_to_live(&self, _ttl: int) { fail!(); }\n+    fn time_to_live(&self, _ttl: int) { fail!(); }\n+\n+    fn hear_broadcasts(&self) { fail!(); }\n+    fn ignore_broadcasts(&self) { fail!(); }\n }\n \n #[test]\n@@ -365,6 +574,18 @@ fn test_simple_io_no_connect() {\n     }\n }\n \n+#[test]\n+fn test_simple_udp_io_bind_only() {\n+    do run_in_newsched_task {\n+        unsafe {\n+            let io = Local::unsafe_borrow::<IoFactoryObject>();\n+            let addr = next_test_ip4();\n+            let maybe_socket = (*io).udp_bind(addr);\n+            assert!(maybe_socket.is_ok());\n+        }\n+    }\n+}\n+\n #[test]\n fn test_simple_tcp_server_and_client() {\n     do run_in_newsched_task {\n@@ -375,7 +596,7 @@ fn test_simple_tcp_server_and_client() {\n             unsafe {\n                 let io = Local::unsafe_borrow::<IoFactoryObject>();\n                 let mut listener = (*io).tcp_bind(addr).unwrap();\n-                let mut stream = listener.accept().unwrap();\n+                let stream = listener.accept().unwrap();\n                 let mut buf = [0, .. 2048];\n                 let nread = stream.read(buf).unwrap();\n                 assert_eq!(nread, 8);\n@@ -389,13 +610,44 @@ fn test_simple_tcp_server_and_client() {\n         do spawntask_immediately {\n             unsafe {\n                 let io = Local::unsafe_borrow::<IoFactoryObject>();\n-                let mut stream = (*io).tcp_connect(addr).unwrap();\n+                let stream = (*io).tcp_connect(addr).unwrap();\n                 stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n             }\n         }\n     }\n }\n \n+#[test]\n+fn test_simple_udp_server_and_client() {\n+    do run_in_newsched_task {\n+        let server_addr = next_test_ip4();\n+        let client_addr = next_test_ip4();\n+\n+        do spawntask_immediately {\n+            unsafe {\n+                let io = Local::unsafe_borrow::<IoFactoryObject>();\n+                let server_socket = (*io).udp_bind(server_addr).unwrap();\n+                let mut buf = [0, .. 2048];\n+                let (nread,src) = server_socket.recvfrom(buf).unwrap();\n+                assert_eq!(nread, 8);\n+                for uint::range(0, nread) |i| {\n+                    rtdebug!(\"%u\", buf[i] as uint);\n+                    assert_eq!(buf[i], i as u8);\n+                }\n+                assert_eq!(src, client_addr);\n+            }\n+        }\n+\n+        do spawntask_immediately {\n+            unsafe {\n+                let io = Local::unsafe_borrow::<IoFactoryObject>();\n+                let client_socket = (*io).udp_bind(client_addr).unwrap();\n+                client_socket.sendto([0, 1, 2, 3, 4, 5, 6, 7], server_addr);\n+            }\n+        }\n+    }\n+}\n+\n #[test] #[ignore(reason = \"busted\")]\n fn test_read_and_block() {\n     do run_in_newsched_task {\n@@ -404,7 +656,7 @@ fn test_read_and_block() {\n         do spawntask_immediately {\n             let io = unsafe { Local::unsafe_borrow::<IoFactoryObject>() };\n             let mut listener = unsafe { (*io).tcp_bind(addr).unwrap() };\n-            let mut stream = listener.accept().unwrap();\n+            let stream = listener.accept().unwrap();\n             let mut buf = [0, .. 2048];\n \n             let expected = 32;\n@@ -424,11 +676,9 @@ fn test_read_and_block() {\n                 // Yield to the other task in hopes that it\n                 // will trigger a read callback while we are\n                 // not ready for it\n-                do scheduler.deschedule_running_task_and_then |task| {\n+                do scheduler.deschedule_running_task_and_then |sched, task| {\n                     let task = Cell::new(task);\n-                    do Local::borrow::<Scheduler> |scheduler| {\n-                        scheduler.enqueue_task(task.take());\n-                    }\n+                    sched.enqueue_task(task.take());\n                 }\n             }\n \n@@ -439,7 +689,7 @@ fn test_read_and_block() {\n         do spawntask_immediately {\n             unsafe {\n                 let io = Local::unsafe_borrow::<IoFactoryObject>();\n-                let mut stream = (*io).tcp_connect(addr).unwrap();\n+                let stream = (*io).tcp_connect(addr).unwrap();\n                 stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n                 stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n                 stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n@@ -460,7 +710,7 @@ fn test_read_read_read() {\n             unsafe {\n                 let io = Local::unsafe_borrow::<IoFactoryObject>();\n                 let mut listener = (*io).tcp_bind(addr).unwrap();\n-                let mut stream = listener.accept().unwrap();\n+                let stream = listener.accept().unwrap();\n                 let buf = [1, .. 2048];\n                 let mut total_bytes_written = 0;\n                 while total_bytes_written < MAX {\n@@ -473,7 +723,7 @@ fn test_read_read_read() {\n         do spawntask_immediately {\n             unsafe {\n                 let io = Local::unsafe_borrow::<IoFactoryObject>();\n-                let mut stream = (*io).tcp_connect(addr).unwrap();\n+                let stream = (*io).tcp_connect(addr).unwrap();\n                 let mut buf = [0, .. 2048];\n                 let mut total_bytes_read = 0;\n                 while total_bytes_read < MAX {\n@@ -489,3 +739,96 @@ fn test_read_read_read() {\n         }\n     }\n }\n+\n+#[test]\n+fn test_udp_twice() {\n+    do run_in_newsched_task {\n+        let server_addr = next_test_ip4();\n+        let client_addr = next_test_ip4();\n+\n+        do spawntask_immediately {\n+            unsafe {\n+                let io = Local::unsafe_borrow::<IoFactoryObject>();\n+                let client = (*io).udp_bind(client_addr).unwrap();\n+                assert!(client.sendto([1], server_addr).is_ok());\n+                assert!(client.sendto([2], server_addr).is_ok());\n+            }\n+        }\n+\n+        do spawntask_immediately {\n+            unsafe {\n+                let io = Local::unsafe_borrow::<IoFactoryObject>();\n+                let server = (*io).udp_bind(server_addr).unwrap();\n+                let mut buf1 = [0];\n+                let mut buf2 = [0];\n+                let (nread1, src1) = server.recvfrom(buf1).unwrap();\n+                let (nread2, src2) = server.recvfrom(buf2).unwrap();\n+                assert_eq!(nread1, 1);\n+                assert_eq!(nread2, 1);\n+                assert_eq!(src1, client_addr);\n+                assert_eq!(src2, client_addr);\n+                assert_eq!(buf1[0], 1);\n+                assert_eq!(buf2[0], 2);\n+            }\n+        }\n+    }\n+}\n+\n+#[test]\n+fn test_udp_many_read() {\n+    do run_in_newsched_task {\n+        let server_out_addr = next_test_ip4();\n+        let server_in_addr = next_test_ip4();\n+        let client_out_addr = next_test_ip4();\n+        let client_in_addr = next_test_ip4();\n+        static MAX: uint = 500_000;\n+\n+        do spawntask_immediately {\n+            unsafe {\n+                let io = Local::unsafe_borrow::<IoFactoryObject>();\n+                let server_out = (*io).udp_bind(server_out_addr).unwrap();\n+                let server_in = (*io).udp_bind(server_in_addr).unwrap();\n+                let msg = [1, .. 2048];\n+                let mut total_bytes_sent = 0;\n+                let mut buf = [1];\n+                while buf[0] == 1 {\n+                    // send more data\n+                    assert!(server_out.sendto(msg, client_in_addr).is_ok());\n+                    total_bytes_sent += msg.len();\n+                    // check if the client has received enough\n+                    let res = server_in.recvfrom(buf);\n+                    assert!(res.is_ok());\n+                    let (nread, src) = res.unwrap();\n+                    assert_eq!(nread, 1);\n+                    assert_eq!(src, client_out_addr);\n+                }\n+                assert!(total_bytes_sent >= MAX);\n+            }\n+        }\n+\n+        do spawntask_immediately {\n+            unsafe {\n+                let io = Local::unsafe_borrow::<IoFactoryObject>();\n+                let client_out = (*io).udp_bind(client_out_addr).unwrap();\n+                let client_in = (*io).udp_bind(client_in_addr).unwrap();\n+                let mut total_bytes_recv = 0;\n+                let mut buf = [0, .. 2048];\n+                while total_bytes_recv < MAX {\n+                    // ask for more\n+                    assert!(client_out.sendto([1], server_in_addr).is_ok());\n+                    // wait for data\n+                    let res = client_in.recvfrom(buf);\n+                    assert!(res.is_ok());\n+                    let (nread, src) = res.unwrap();\n+                    assert_eq!(src, server_out_addr);\n+                    total_bytes_recv += nread;\n+                    for uint::range(0, nread) |i| {\n+                        assert_eq!(buf[i], 1);\n+                    }\n+                }\n+                // tell the server we're done\n+                assert!(client_out.sendto([0], server_in_addr).is_ok());\n+            }\n+        }\n+    }\n+}"}, {"sha": "62bf8f27af93de00b3f4838719a8096dd01598e9", "filename": "src/libstd/rt/uv/uvll.rs", "status": "modified", "additions": 171, "deletions": 49, "changes": 220, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fuvll.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Frt%2Fuv%2Fuvll.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fuvll.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -60,17 +60,24 @@ pub type uv_handle_t = c_void;\n pub type uv_loop_t = c_void;\n pub type uv_idle_t = c_void;\n pub type uv_tcp_t = c_void;\n+pub type uv_udp_t = c_void;\n pub type uv_connect_t = c_void;\n pub type uv_write_t = c_void;\n pub type uv_async_t = c_void;\n pub type uv_timer_t = c_void;\n pub type uv_stream_t = c_void;\n pub type uv_fs_t = c_void;\n+pub type uv_udp_send_t = c_void;\n \n pub type uv_idle_cb = *u8;\n+pub type uv_alloc_cb = *u8;\n+pub type uv_udp_send_cb = *u8;\n+pub type uv_udp_recv_cb = *u8;\n \n+pub type sockaddr = c_void;\n pub type sockaddr_in = c_void;\n pub type sockaddr_in6 = c_void;\n+pub type uv_membership = c_void;\n \n #[deriving(Eq)]\n pub enum uv_handle_type {\n@@ -187,31 +194,88 @@ pub unsafe fn idle_stop(handle: *uv_idle_t) -> c_int {\n     rust_uv_idle_stop(handle)\n }\n \n+pub unsafe fn udp_init(loop_handle: *uv_loop_t, handle: *uv_udp_t) -> c_int {\n+    return rust_uv_udp_init(loop_handle, handle);\n+}\n+\n+pub unsafe fn udp_bind(server: *uv_udp_t, addr: *sockaddr_in, flags: c_uint) -> c_int {\n+    return rust_uv_udp_bind(server, addr, flags);\n+}\n+\n+pub unsafe fn udp_bind6(server: *uv_udp_t, addr: *sockaddr_in6, flags: c_uint) -> c_int {\n+    return rust_uv_udp_bind6(server, addr, flags);\n+}\n+\n+pub unsafe fn udp_send<T>(req: *uv_udp_send_t, handle: *T, buf_in: &[uv_buf_t],\n+                          addr: *sockaddr_in, cb: uv_udp_send_cb) -> c_int {\n+    let buf_ptr = vec::raw::to_ptr(buf_in);\n+    let buf_cnt = buf_in.len() as i32;\n+    return rust_uv_udp_send(req, handle as *c_void, buf_ptr, buf_cnt, addr, cb);\n+}\n+\n+pub unsafe fn udp_send6<T>(req: *uv_udp_send_t, handle: *T, buf_in: &[uv_buf_t],\n+                          addr: *sockaddr_in6, cb: uv_udp_send_cb) -> c_int {\n+    let buf_ptr = vec::raw::to_ptr(buf_in);\n+    let buf_cnt = buf_in.len() as i32;\n+    return rust_uv_udp_send6(req, handle as *c_void, buf_ptr, buf_cnt, addr, cb);\n+}\n+\n+pub unsafe fn udp_recv_start(server: *uv_udp_t, on_alloc: uv_alloc_cb,\n+                             on_recv: uv_udp_recv_cb) -> c_int {\n+    return rust_uv_udp_recv_start(server, on_alloc, on_recv);\n+}\n+\n+pub unsafe fn udp_recv_stop(server: *uv_udp_t) -> c_int {\n+    return rust_uv_udp_recv_stop(server);\n+}\n+\n+pub unsafe fn get_udp_handle_from_send_req(send_req: *uv_udp_send_t) -> *uv_udp_t {\n+    return rust_uv_get_udp_handle_from_send_req(send_req);\n+}\n+\n+pub unsafe fn udp_get_sockname(handle: *uv_udp_t, name: *sockaddr_in) -> c_int {\n+    return rust_uv_udp_getsockname(handle, name);\n+}\n+\n+pub unsafe fn udp_get_sockname6(handle: *uv_udp_t, name: *sockaddr_in6) -> c_int {\n+    return rust_uv_udp_getsockname6(handle, name);\n+}\n+\n+pub unsafe fn udp_set_membership(handle: *uv_udp_t, multicast_addr: *c_char,\n+                                 interface_addr: *c_char, membership: uv_membership) -> c_int {\n+    return rust_uv_udp_set_membership(handle, multicast_addr, interface_addr, membership);\n+}\n+\n+pub unsafe fn udp_set_multicast_loop(handle: *uv_udp_t, on: c_int) -> c_int {\n+    return rust_uv_udp_set_multicast_loop(handle, on);\n+}\n+\n+pub unsafe fn udp_set_multicast_ttl(handle: *uv_udp_t, ttl: c_int) -> c_int {\n+    return rust_uv_udp_set_multicast_ttl(handle, ttl);\n+}\n+\n+pub unsafe fn udp_set_broadcast(handle: *uv_udp_t, on: c_int) -> c_int {\n+    return rust_uv_udp_set_broadcast(handle, on);\n+}\n+\n pub unsafe fn tcp_init(loop_handle: *c_void, handle: *uv_tcp_t) -> c_int {\n     return rust_uv_tcp_init(loop_handle, handle);\n }\n \n-// FIXME ref #2064\n-pub unsafe fn tcp_connect(connect_ptr: *uv_connect_t,\n-                          tcp_handle_ptr: *uv_tcp_t,\n-                          addr_ptr: *sockaddr_in,\n-                          after_connect_cb: *u8) -> c_int {\n-    return rust_uv_tcp_connect(connect_ptr, tcp_handle_ptr,\n-                                       after_connect_cb, addr_ptr);\n+pub unsafe fn tcp_connect(connect_ptr: *uv_connect_t, tcp_handle_ptr: *uv_tcp_t,\n+                          addr_ptr: *sockaddr_in, after_connect_cb: *u8) -> c_int {\n+    return rust_uv_tcp_connect(connect_ptr, tcp_handle_ptr, after_connect_cb, addr_ptr);\n }\n-// FIXME ref #2064\n-pub unsafe fn tcp_connect6(connect_ptr: *uv_connect_t,\n-                           tcp_handle_ptr: *uv_tcp_t,\n-                           addr_ptr: *sockaddr_in6,\n-                           after_connect_cb: *u8) -> c_int {\n-    return rust_uv_tcp_connect6(connect_ptr, tcp_handle_ptr,\n-                                        after_connect_cb, addr_ptr);\n+\n+pub unsafe fn tcp_connect6(connect_ptr: *uv_connect_t, tcp_handle_ptr: *uv_tcp_t,\n+                           addr_ptr: *sockaddr_in6, after_connect_cb: *u8) -> c_int {\n+    return rust_uv_tcp_connect6(connect_ptr, tcp_handle_ptr, after_connect_cb, addr_ptr);\n }\n-// FIXME ref #2064\n+\n pub unsafe fn tcp_bind(tcp_server_ptr: *uv_tcp_t, addr_ptr: *sockaddr_in) -> c_int {\n     return rust_uv_tcp_bind(tcp_server_ptr, addr_ptr);\n }\n-// FIXME ref #2064\n+\n pub unsafe fn tcp_bind6(tcp_server_ptr: *uv_tcp_t, addr_ptr: *sockaddr_in6) -> c_int {\n     return rust_uv_tcp_bind6(tcp_server_ptr, addr_ptr);\n }\n@@ -224,6 +288,26 @@ pub unsafe fn tcp_getpeername6(tcp_handle_ptr: *uv_tcp_t, name: *sockaddr_in6) -\n     return rust_uv_tcp_getpeername6(tcp_handle_ptr, name);\n }\n \n+pub unsafe fn tcp_getsockname(handle: *uv_tcp_t, name: *sockaddr_in) -> c_int {\n+    return rust_uv_tcp_getsockname(handle, name);\n+}\n+\n+pub unsafe fn tcp_getsockname6(handle: *uv_tcp_t, name: *sockaddr_in6) -> c_int {\n+    return rust_uv_tcp_getsockname6(handle, name);\n+}\n+\n+pub unsafe fn tcp_nodelay(handle: *uv_tcp_t, enable: c_int) -> c_int {\n+    return rust_uv_tcp_nodelay(handle, enable);\n+}\n+\n+pub unsafe fn tcp_keepalive(handle: *uv_tcp_t, enable: c_int, delay: c_uint) -> c_int {\n+    return rust_uv_tcp_keepalive(handle, enable, delay);\n+}\n+\n+pub unsafe fn tcp_simultaneous_accepts(handle: *uv_tcp_t, enable: c_int) -> c_int {\n+    return rust_uv_tcp_simultaneous_accepts(handle, enable);\n+}\n+\n pub unsafe fn listen<T>(stream: *T, backlog: c_int, cb: *u8) -> c_int {\n     return rust_uv_listen(stream as *c_void, backlog, cb);\n }\n@@ -237,7 +321,7 @@ pub unsafe fn write<T>(req: *uv_write_t, stream: *T, buf_in: &[uv_buf_t], cb: *u\n     let buf_cnt = buf_in.len() as i32;\n     return rust_uv_write(req as *c_void, stream as *c_void, buf_ptr, buf_cnt, cb);\n }\n-pub unsafe fn read_start(stream: *uv_stream_t, on_alloc: *u8, on_read: *u8) -> c_int {\n+pub unsafe fn read_start(stream: *uv_stream_t, on_alloc: uv_alloc_cb, on_read: *u8) -> c_int {\n     return rust_uv_read_start(stream as *c_void, on_alloc, on_read);\n }\n \n@@ -281,6 +365,22 @@ pub unsafe fn timer_stop(timer_ptr: *uv_timer_t) -> c_int {\n     return rust_uv_timer_stop(timer_ptr);\n }\n \n+pub unsafe fn is_ip4_addr(addr: *sockaddr) -> bool {\n+    match rust_uv_is_ipv4_sockaddr(addr) { 0 => false, _ => true }\n+}\n+\n+pub unsafe fn is_ip6_addr(addr: *sockaddr) -> bool {\n+    match rust_uv_is_ipv6_sockaddr(addr) { 0 => false, _ => true }\n+}\n+\n+pub unsafe fn as_sockaddr_in(addr: *sockaddr) -> *sockaddr_in {\n+    return rust_uv_sockaddr_as_sockaddr_in(addr);\n+}\n+\n+pub unsafe fn as_sockaddr_in6(addr: *sockaddr) -> *sockaddr_in6 {\n+    return rust_uv_sockaddr_as_sockaddr_in6(addr);\n+}\n+\n pub unsafe fn malloc_ip4_addr(ip: &str, port: int) -> *sockaddr_in {\n     do str::as_c_str(ip) |ip_buf| {\n         rust_uv_ip4_addrp(ip_buf as *u8, port as libc::c_int)\n@@ -300,6 +400,22 @@ pub unsafe fn free_ip6_addr(addr: *sockaddr_in6) {\n     rust_uv_free_ip6_addr(addr);\n }\n \n+pub unsafe fn ip4_name(addr: *sockaddr_in, dst: *u8, size: size_t) -> c_int {\n+    return rust_uv_ip4_name(addr, dst, size);\n+}\n+\n+pub unsafe fn ip6_name(addr: *sockaddr_in6, dst: *u8, size: size_t) -> c_int {\n+    return rust_uv_ip6_name(addr, dst, size);\n+}\n+\n+pub unsafe fn ip4_port(addr: *sockaddr_in) -> c_uint {\n+   return rust_uv_ip4_port(addr);\n+}\n+\n+pub unsafe fn ip6_port(addr: *sockaddr_in6) -> c_uint {\n+    return rust_uv_ip6_port(addr);\n+}\n+\n // data access helpers\n pub unsafe fn get_loop_for_uv_handle<T>(handle: *T) -> *c_void {\n     return rust_uv_get_loop_for_uv_handle(handle as *c_void);\n@@ -384,16 +500,11 @@ extern {\n     fn rust_uv_idle_stop(handle: *uv_idle_t) -> c_int;\n \n     fn rust_uv_async_send(handle: *uv_async_t);\n-    fn rust_uv_async_init(loop_handle: *c_void,\n-                          async_handle: *uv_async_t,\n-                          cb: *u8) -> c_int;\n+    fn rust_uv_async_init(loop_handle: *c_void, async_handle: *uv_async_t, cb: *u8) -> c_int;\n     fn rust_uv_tcp_init(loop_handle: *c_void, handle_ptr: *uv_tcp_t) -> c_int;\n-    // FIXME ref #2604 .. ?\n     fn rust_uv_buf_init(out_buf: *uv_buf_t, base: *u8, len: size_t);\n     fn rust_uv_last_error(loop_handle: *c_void) -> uv_err_t;\n-    // FIXME ref #2064\n     fn rust_uv_strerror(err: *uv_err_t) -> *c_char;\n-    // FIXME ref #2064\n     fn rust_uv_err_name(err: *uv_err_t) -> *c_char;\n     fn rust_uv_ip4_addrp(ip: *u8, port: c_int) -> *sockaddr_in;\n     fn rust_uv_ip6_addrp(ip: *u8, port: c_int) -> *sockaddr_in6;\n@@ -403,40 +514,51 @@ extern {\n     fn rust_uv_ip6_name(src: *sockaddr_in6, dst: *u8, size: size_t) -> c_int;\n     fn rust_uv_ip4_port(src: *sockaddr_in) -> c_uint;\n     fn rust_uv_ip6_port(src: *sockaddr_in6) -> c_uint;\n-    // FIXME ref #2064\n-    fn rust_uv_tcp_connect(connect_ptr: *uv_connect_t,\n-                           tcp_handle_ptr: *uv_tcp_t,\n-                           after_cb: *u8,\n+    fn rust_uv_tcp_connect(req: *uv_connect_t, handle: *uv_tcp_t, cb: *u8,\n                            addr: *sockaddr_in) -> c_int;\n-    // FIXME ref #2064\n     fn rust_uv_tcp_bind(tcp_server: *uv_tcp_t, addr: *sockaddr_in) -> c_int;\n-    // FIXME ref #2064\n-    fn rust_uv_tcp_connect6(connect_ptr: *uv_connect_t,\n-                            tcp_handle_ptr: *uv_tcp_t,\n-                            after_cb: *u8,\n+    fn rust_uv_tcp_connect6(req: *uv_connect_t, handle: *uv_tcp_t, cb: *u8,\n                             addr: *sockaddr_in6) -> c_int;\n-    // FIXME ref #2064\n     fn rust_uv_tcp_bind6(tcp_server: *uv_tcp_t, addr: *sockaddr_in6) -> c_int;\n-    fn rust_uv_tcp_getpeername(tcp_handle_ptr: *uv_tcp_t,\n-                               name: *sockaddr_in) -> c_int;\n-    fn rust_uv_tcp_getpeername6(tcp_handle_ptr: *uv_tcp_t,\n-                                name: *sockaddr_in6) ->c_int;\n+    fn rust_uv_tcp_getpeername(tcp_handle_ptr: *uv_tcp_t, name: *sockaddr_in) -> c_int;\n+    fn rust_uv_tcp_getpeername6(tcp_handle_ptr: *uv_tcp_t, name: *sockaddr_in6) ->c_int;\n+    fn rust_uv_tcp_getsockname(handle: *uv_tcp_t, name: *sockaddr_in) -> c_int;\n+    fn rust_uv_tcp_getsockname6(handle: *uv_tcp_t, name: *sockaddr_in6) -> c_int;\n+    fn rust_uv_tcp_nodelay(handle: *uv_tcp_t, enable: c_int) -> c_int;\n+    fn rust_uv_tcp_keepalive(handle: *uv_tcp_t, enable: c_int, delay: c_uint) -> c_int;\n+    fn rust_uv_tcp_simultaneous_accepts(handle: *uv_tcp_t, enable: c_int) -> c_int;\n+\n+    fn rust_uv_udp_init(loop_handle: *uv_loop_t, handle_ptr: *uv_udp_t) -> c_int;\n+    fn rust_uv_udp_bind(server: *uv_udp_t, addr: *sockaddr_in, flags: c_uint) -> c_int;\n+    fn rust_uv_udp_bind6(server: *uv_udp_t, addr: *sockaddr_in6, flags: c_uint) -> c_int;\n+    fn rust_uv_udp_send(req: *uv_udp_send_t, handle: *uv_udp_t, buf_in: *uv_buf_t,\n+                        buf_cnt: c_int, addr: *sockaddr_in, cb: *u8) -> c_int;\n+    fn rust_uv_udp_send6(req: *uv_udp_send_t, handle: *uv_udp_t, buf_in: *uv_buf_t,\n+                         buf_cnt: c_int, addr: *sockaddr_in6, cb: *u8) -> c_int;\n+    fn rust_uv_udp_recv_start(server: *uv_udp_t, on_alloc: *u8, on_recv: *u8) -> c_int;\n+    fn rust_uv_udp_recv_stop(server: *uv_udp_t) -> c_int;\n+    fn rust_uv_get_udp_handle_from_send_req(req: *uv_udp_send_t) -> *uv_udp_t;\n+    fn rust_uv_udp_getsockname(handle: *uv_udp_t, name: *sockaddr_in) -> c_int;\n+    fn rust_uv_udp_getsockname6(handle: *uv_udp_t, name: *sockaddr_in6) -> c_int;\n+    fn rust_uv_udp_set_membership(handle: *uv_udp_t, multicast_addr: *c_char,\n+                                  interface_addr: *c_char, membership: uv_membership) -> c_int;\n+    fn rust_uv_udp_set_multicast_loop(handle: *uv_udp_t, on: c_int) -> c_int;\n+    fn rust_uv_udp_set_multicast_ttl(handle: *uv_udp_t, ttl: c_int) -> c_int;\n+    fn rust_uv_udp_set_broadcast(handle: *uv_udp_t, on: c_int) -> c_int;\n+\n+    fn rust_uv_is_ipv4_sockaddr(addr: *sockaddr) -> c_int;\n+    fn rust_uv_is_ipv6_sockaddr(addr: *sockaddr) -> c_int;\n+    fn rust_uv_sockaddr_as_sockaddr_in(addr: *sockaddr) -> *sockaddr_in;\n+    fn rust_uv_sockaddr_as_sockaddr_in6(addr: *sockaddr) -> *sockaddr_in6;\n+\n     fn rust_uv_listen(stream: *c_void, backlog: c_int, cb: *u8) -> c_int;\n     fn rust_uv_accept(server: *c_void, client: *c_void) -> c_int;\n-    fn rust_uv_write(req: *c_void,\n-                     stream: *c_void,\n-                     buf_in: *uv_buf_t,\n-                     buf_cnt: c_int,\n+    fn rust_uv_write(req: *c_void, stream: *c_void, buf_in: *uv_buf_t, buf_cnt: c_int,\n                      cb: *u8) -> c_int;\n-    fn rust_uv_read_start(stream: *c_void,\n-                          on_alloc: *u8,\n-                          on_read: *u8) -> c_int;\n+    fn rust_uv_read_start(stream: *c_void, on_alloc: *u8, on_read: *u8) -> c_int;\n     fn rust_uv_read_stop(stream: *c_void) -> c_int;\n-    fn rust_uv_timer_init(loop_handle: *c_void,\n-                          timer_handle: *uv_timer_t) -> c_int;\n-    fn rust_uv_timer_start(timer_handle: *uv_timer_t,\n-                           cb: *u8,\n-                           timeout: libc::uint64_t,\n+    fn rust_uv_timer_init(loop_handle: *c_void, timer_handle: *uv_timer_t) -> c_int;\n+    fn rust_uv_timer_start(timer_handle: *uv_timer_t, cb: *u8, timeout: libc::uint64_t,\n                            repeat: libc::uint64_t) -> c_int;\n     fn rust_uv_timer_stop(handle: *uv_timer_t) -> c_int;\n "}, {"sha": "0187ad3abf51751ce92ca3d47421bc0b48763759", "filename": "src/libstd/rt/uvio.rs", "status": "removed", "additions": 0, "deletions": 458, "changes": 458, "blob_url": "https://github.com/rust-lang/rust/blob/137d1fb210a844a76f89d7355a1aaf9f7a88af33/src%2Flibstd%2Frt%2Fuvio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/137d1fb210a844a76f89d7355a1aaf9f7a88af33/src%2Flibstd%2Frt%2Fuvio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuvio.rs?ref=137d1fb210a844a76f89d7355a1aaf9f7a88af33", "patch": "@@ -1,458 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use option::*;\n-use result::*;\n-\n-use super::io::net::ip::IpAddr;\n-use super::uv::*;\n-use super::rtio::*;\n-use ops::Drop;\n-use cell::Cell;\n-use cast::transmute;\n-use super::sched::{Scheduler, local_sched};\n-\n-#[cfg(test)] use container::Container;\n-#[cfg(test)] use uint;\n-#[cfg(test)] use unstable::run_in_bare_thread;\n-#[cfg(test)] use super::test::*;\n-\n-pub struct UvEventLoop {\n-    uvio: UvIoFactory\n-}\n-\n-impl UvEventLoop {\n-    pub fn new() -> UvEventLoop {\n-        UvEventLoop {\n-            uvio: UvIoFactory(Loop::new())\n-        }\n-    }\n-\n-    /// A convenience constructor\n-    pub fn new_scheduler() -> Scheduler {\n-        Scheduler::new(~UvEventLoop::new())\n-    }\n-}\n-\n-impl Drop for UvEventLoop {\n-    fn drop(&self) {\n-        // XXX: Need mutable finalizer\n-        let this = unsafe {\n-            transmute::<&UvEventLoop, &mut UvEventLoop>(self)\n-        };\n-        this.uvio.uv_loop().close();\n-    }\n-}\n-\n-impl EventLoop for UvEventLoop {\n-\n-    fn run(&mut self) {\n-        self.uvio.uv_loop().run();\n-    }\n-\n-    fn callback(&mut self, f: ~fn()) {\n-        let mut idle_watcher =  IdleWatcher::new(self.uvio.uv_loop());\n-        do idle_watcher.start |idle_watcher, status| {\n-            assert!(status.is_none());\n-            let mut idle_watcher = idle_watcher;\n-            idle_watcher.stop();\n-            idle_watcher.close();\n-            f();\n-        }\n-    }\n-\n-    fn io<'a>(&'a mut self) -> Option<&'a mut IoFactoryObject> {\n-        Some(&mut self.uvio)\n-    }\n-}\n-\n-#[test]\n-fn test_callback_run_once() {\n-    do run_in_bare_thread {\n-        let mut event_loop = UvEventLoop::new();\n-        let mut count = 0;\n-        let count_ptr: *mut int = &mut count;\n-        do event_loop.callback {\n-            unsafe { *count_ptr += 1 }\n-        }\n-        event_loop.run();\n-        assert!(count == 1);\n-    }\n-}\n-\n-pub struct UvIoFactory(Loop);\n-\n-impl UvIoFactory {\n-    pub fn uv_loop<'a>(&'a mut self) -> &'a mut Loop {\n-        match self { &UvIoFactory(ref mut ptr) => ptr }\n-    }\n-}\n-\n-impl IoFactory for UvIoFactory {\n-    // Connect to an address and return a new stream\n-    // NB: This blocks the task waiting on the connection.\n-    // It would probably be better to return a future\n-    fn connect(&mut self, addr: IpAddr) -> Option<~StreamObject> {\n-        // Create a cell in the task to hold the result. We will fill\n-        // the cell before resuming the task.\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Option<~StreamObject>> = &result_cell;\n-\n-        let scheduler = local_sched::take();\n-        assert!(scheduler.in_task_context());\n-\n-        // Block this task and take ownership, switch to scheduler context\n-        do scheduler.deschedule_running_task_and_then |task| {\n-\n-            rtdebug!(\"connect: entered scheduler context\");\n-            do local_sched::borrow |scheduler| {\n-                assert!(!scheduler.in_task_context());\n-            }\n-            let mut tcp_watcher = TcpWatcher::new(self.uv_loop());\n-            let task_cell = Cell::new(task);\n-\n-            // Wait for a connection\n-            do tcp_watcher.connect(addr) |stream_watcher, status| {\n-                rtdebug!(\"connect: in connect callback\");\n-                let maybe_stream = if status.is_none() {\n-                    rtdebug!(\"status is none\");\n-                    Some(~UvStream(stream_watcher))\n-                } else {\n-                    rtdebug!(\"status is some\");\n-                    stream_watcher.close(||());\n-                    None\n-                };\n-\n-                // Store the stream in the task's stack\n-                unsafe { (*result_cell_ptr).put_back(maybe_stream); }\n-\n-                // Context switch\n-                let scheduler = local_sched::take();\n-                scheduler.resume_task_immediately(task_cell.take());\n-            }\n-        }\n-\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n-    }\n-\n-    fn bind(&mut self, addr: IpAddr) -> Option<~TcpListenerObject> {\n-        let mut watcher = TcpWatcher::new(self.uv_loop());\n-        watcher.bind(addr);\n-        return Some(~UvTcpListener(watcher));\n-    }\n-}\n-\n-pub struct UvTcpListener(TcpWatcher);\n-\n-impl UvTcpListener {\n-    fn watcher(&self) -> TcpWatcher {\n-        match self { &UvTcpListener(w) => w }\n-    }\n-\n-    fn close(&self) {\n-        // XXX: Need to wait until close finishes before returning\n-        self.watcher().as_stream().close(||());\n-    }\n-}\n-\n-impl Drop for UvTcpListener {\n-    fn drop(&self) {\n-        // XXX: Again, this never gets called. Use .close() instead\n-        //self.watcher().as_stream().close(||());\n-    }\n-}\n-\n-impl TcpListener for UvTcpListener {\n-\n-    fn listen(&mut self) -> Option<~StreamObject> {\n-        rtdebug!(\"entering listen\");\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Option<~StreamObject>> = &result_cell;\n-\n-        let server_tcp_watcher = self.watcher();\n-\n-        let scheduler = local_sched::take();\n-        assert!(scheduler.in_task_context());\n-\n-        do scheduler.deschedule_running_task_and_then |task| {\n-            let task_cell = Cell::new(task);\n-            let mut server_tcp_watcher = server_tcp_watcher;\n-            do server_tcp_watcher.listen |server_stream_watcher, status| {\n-                let maybe_stream = if status.is_none() {\n-                    let mut server_stream_watcher = server_stream_watcher;\n-                    let mut loop_ = loop_from_watcher(&server_stream_watcher);\n-                    let client_tcp_watcher = TcpWatcher::new(&mut loop_).as_stream();\n-                    // XXX: Needs to be surfaced in interface\n-                    server_stream_watcher.accept(client_tcp_watcher);\n-                    Some(~UvStream::new(client_tcp_watcher))\n-                } else {\n-                    None\n-                };\n-\n-                unsafe { (*result_cell_ptr).put_back(maybe_stream); }\n-\n-                rtdebug!(\"resuming task from listen\");\n-                // Context switch\n-                let scheduler = local_sched::take();\n-                scheduler.resume_task_immediately(task_cell.take());\n-            }\n-        }\n-\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n-    }\n-}\n-\n-pub struct UvStream(StreamWatcher);\n-\n-impl UvStream {\n-    fn new(watcher: StreamWatcher) -> UvStream {\n-        UvStream(watcher)\n-    }\n-\n-    fn watcher(&self) -> StreamWatcher {\n-        match self { &UvStream(w) => w }\n-    }\n-\n-    // XXX: finalize isn't working for ~UvStream???\n-    fn close(&self) {\n-        // XXX: Need to wait until this finishes before returning\n-        self.watcher().close(||());\n-    }\n-}\n-\n-impl Drop for UvStream {\n-    fn drop(&self) {\n-        rtdebug!(\"closing stream\");\n-        //self.watcher().close(||());\n-    }\n-}\n-\n-impl Stream for UvStream {\n-    fn read(&mut self, buf: &mut [u8]) -> Result<uint, ()> {\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<uint, ()>> = &result_cell;\n-\n-        let scheduler = local_sched::take();\n-        assert!(scheduler.in_task_context());\n-        let watcher = self.watcher();\n-        let buf_ptr: *&mut [u8] = &buf;\n-        do scheduler.deschedule_running_task_and_then |task| {\n-            rtdebug!(\"read: entered scheduler context\");\n-            do local_sched::borrow |scheduler| {\n-                assert!(!scheduler.in_task_context());\n-            }\n-            let mut watcher = watcher;\n-            let task_cell = Cell::new(task);\n-            // XXX: We shouldn't reallocate these callbacks every\n-            // call to read\n-            let alloc: AllocCallback = |_| unsafe {\n-                slice_to_uv_buf(*buf_ptr)\n-            };\n-            do watcher.read_start(alloc) |watcher, nread, _buf, status| {\n-\n-                // Stop reading so that no read callbacks are\n-                // triggered before the user calls `read` again.\n-                // XXX: Is there a performance impact to calling\n-                // stop here?\n-                let mut watcher = watcher;\n-                watcher.read_stop();\n-\n-                let result = if status.is_none() {\n-                    assert!(nread >= 0);\n-                    Ok(nread as uint)\n-                } else {\n-                    Err(())\n-                };\n-\n-                unsafe { (*result_cell_ptr).put_back(result); }\n-\n-                let scheduler = local_sched::take();\n-                scheduler.resume_task_immediately(task_cell.take());\n-            }\n-        }\n-\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n-    }\n-\n-    fn write(&mut self, buf: &[u8]) -> Result<(), ()> {\n-        let result_cell = Cell::new_empty();\n-        let result_cell_ptr: *Cell<Result<(), ()>> = &result_cell;\n-        let scheduler = local_sched::take();\n-        assert!(scheduler.in_task_context());\n-        let watcher = self.watcher();\n-        let buf_ptr: *&[u8] = &buf;\n-        do scheduler.deschedule_running_task_and_then |task| {\n-            let mut watcher = watcher;\n-            let task_cell = Cell::new(task);\n-            let buf = unsafe { &*buf_ptr };\n-            // XXX: OMGCOPIES\n-            let buf = buf.to_vec();\n-            do watcher.write(buf) |_watcher, status| {\n-                let result = if status.is_none() {\n-                    Ok(())\n-                } else {\n-                    Err(())\n-                };\n-\n-                unsafe { (*result_cell_ptr).put_back(result); }\n-\n-                let scheduler = local_sched::take();\n-                scheduler.resume_task_immediately(task_cell.take());\n-            }\n-        }\n-\n-        assert!(!result_cell.is_empty());\n-        return result_cell.take();\n-    }\n-}\n-\n-#[test]\n-fn test_simple_io_no_connect() {\n-    do run_in_newsched_task {\n-        let io = unsafe { local_sched::unsafe_borrow_io() };\n-        let addr = next_test_ip4();\n-        let maybe_chan = io.connect(addr);\n-        assert!(maybe_chan.is_none());\n-    }\n-}\n-\n-#[test]\n-fn test_simple_tcp_server_and_client() {\n-    do run_in_newsched_task {\n-        let addr = next_test_ip4();\n-\n-        // Start the server first so it's listening when we connect\n-        do spawntask_immediately {\n-            unsafe {\n-                let io = local_sched::unsafe_borrow_io();\n-                let mut listener = io.bind(addr).unwrap();\n-                let mut stream = listener.listen().unwrap();\n-                let mut buf = [0, .. 2048];\n-                let nread = stream.read(buf).unwrap();\n-                assert!(nread == 8);\n-                for uint::range(0, nread) |i| {\n-                    rtdebug!(\"%u\", buf[i] as uint);\n-                    assert!(buf[i] == i as u8);\n-                }\n-                stream.close();\n-                listener.close();\n-            }\n-        }\n-\n-        do spawntask_immediately {\n-            unsafe {\n-                let io = local_sched::unsafe_borrow_io();\n-                let mut stream = io.connect(addr).unwrap();\n-                stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-                stream.close();\n-            }\n-        }\n-    }\n-}\n-\n-#[test] #[ignore(reason = \"busted\")]\n-fn test_read_and_block() {\n-    do run_in_newsched_task {\n-        let addr = next_test_ip4();\n-\n-        do spawntask_immediately {\n-            let io = unsafe { local_sched::unsafe_borrow_io() };\n-            let mut listener = io.bind(addr).unwrap();\n-            let mut stream = listener.listen().unwrap();\n-            let mut buf = [0, .. 2048];\n-\n-            let expected = 32;\n-            let mut current = 0;\n-            let mut reads = 0;\n-\n-            while current < expected {\n-                let nread = stream.read(buf).unwrap();\n-                for uint::range(0, nread) |i| {\n-                    let val = buf[i] as uint;\n-                    assert!(val == current % 8);\n-                    current += 1;\n-                }\n-                reads += 1;\n-\n-                let scheduler = local_sched::take();\n-                // Yield to the other task in hopes that it\n-                // will trigger a read callback while we are\n-                // not ready for it\n-                do scheduler.deschedule_running_task_and_then |task| {\n-                    let task = Cell::new(task);\n-                    do local_sched::borrow |scheduler| {\n-                        scheduler.task_queue.push_back(task.take());\n-                    }\n-                }\n-            }\n-\n-            // Make sure we had multiple reads\n-            assert!(reads > 1);\n-\n-            stream.close();\n-            listener.close();\n-        }\n-\n-        do spawntask_immediately {\n-            let io = unsafe { local_sched::unsafe_borrow_io() };\n-            let mut stream = io.connect(addr).unwrap();\n-            stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-            stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-            stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-            stream.write([0, 1, 2, 3, 4, 5, 6, 7]);\n-            stream.close();\n-        }\n-\n-    }\n-}\n-\n-#[test]\n-fn test_read_read_read() {\n-    do run_in_newsched_task {\n-        let addr = next_test_ip4();\n-        static MAX: uint = 500000;\n-\n-        do spawntask_immediately {\n-            unsafe {\n-                let io = local_sched::unsafe_borrow_io();\n-                let mut listener = io.bind(addr).unwrap();\n-                let mut stream = listener.listen().unwrap();\n-                let buf = [1, .. 2048];\n-                let mut total_bytes_written = 0;\n-                while total_bytes_written < MAX {\n-                    stream.write(buf);\n-                    total_bytes_written += buf.len();\n-                }\n-                stream.close();\n-                listener.close();\n-            }\n-        }\n-\n-        do spawntask_immediately {\n-            let io = unsafe { local_sched::unsafe_borrow_io() };\n-            let mut stream = io.connect(addr).unwrap();\n-            let mut buf = [0, .. 2048];\n-            let mut total_bytes_read = 0;\n-            while total_bytes_read < MAX {\n-                let nread = stream.read(buf).unwrap();\n-                rtdebug!(\"read %u bytes\", nread as uint);\n-                total_bytes_read += nread;\n-                for uint::range(0, nread) |i| {\n-                    assert!(buf[i] == 1);\n-                }\n-            }\n-            rtdebug!(\"read %u bytes total\", total_bytes_read as uint);\n-            stream.close();\n-        }\n-    }\n-}"}, {"sha": "0d298bde6b50875d04d565f66af17f2670707805", "filename": "src/libstd/rt/uvll.rs", "status": "removed", "additions": 0, "deletions": 443, "changes": 443, "blob_url": "https://github.com/rust-lang/rust/blob/137d1fb210a844a76f89d7355a1aaf9f7a88af33/src%2Flibstd%2Frt%2Fuvll.rs", "raw_url": "https://github.com/rust-lang/rust/raw/137d1fb210a844a76f89d7355a1aaf9f7a88af33/src%2Flibstd%2Frt%2Fuvll.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuvll.rs?ref=137d1fb210a844a76f89d7355a1aaf9f7a88af33", "patch": "@@ -1,443 +0,0 @@\n-// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-/*!\n- * Low-level bindings to the libuv library.\n- *\n- * This module contains a set of direct, 'bare-metal' wrappers around\n- * the libuv C-API.\n- *\n- * We're not bothering yet to redefine uv's structs as Rust structs\n- * because they are quite large and change often between versions.\n- * The maintenance burden is just too high. Instead we use the uv's\n- * `uv_handle_size` and `uv_req_size` to find the correct size of the\n- * structs and allocate them on the heap. This can be revisited later.\n- *\n- * There are also a collection of helper functions to ease interacting\n- * with the low-level API.\n- *\n- * As new functionality, existant in uv.h, is added to the rust stdlib,\n- * the mappings should be added in this module.\n- */\n-\n-#[allow(non_camel_case_types)]; // C types\n-\n-use libc::{size_t, c_int, c_uint, c_void, c_char, uintptr_t};\n-use libc::{malloc, free};\n-use prelude::*;\n-\n-pub struct uv_err_t {\n-    code: c_int,\n-    sys_errno_: c_int\n-}\n-\n-pub struct uv_buf_t {\n-    base: *u8,\n-    len: libc::size_t,\n-}\n-\n-pub type uv_handle_t = c_void;\n-pub type uv_loop_t = c_void;\n-pub type uv_idle_t = c_void;\n-pub type uv_tcp_t = c_void;\n-pub type uv_connect_t = c_void;\n-pub type uv_write_t = c_void;\n-pub type uv_async_t = c_void;\n-pub type uv_timer_t = c_void;\n-pub type uv_stream_t = c_void;\n-pub type uv_fs_t = c_void;\n-\n-pub type uv_idle_cb = *u8;\n-\n-pub type sockaddr_in = c_void;\n-pub type sockaddr_in6 = c_void;\n-\n-#[deriving(Eq)]\n-pub enum uv_handle_type {\n-    UV_UNKNOWN_HANDLE,\n-    UV_ASYNC,\n-    UV_CHECK,\n-    UV_FS_EVENT,\n-    UV_FS_POLL,\n-    UV_HANDLE,\n-    UV_IDLE,\n-    UV_NAMED_PIPE,\n-    UV_POLL,\n-    UV_PREPARE,\n-    UV_PROCESS,\n-    UV_STREAM,\n-    UV_TCP,\n-    UV_TIMER,\n-    UV_TTY,\n-    UV_UDP,\n-    UV_SIGNAL,\n-    UV_FILE,\n-    UV_HANDLE_TYPE_MAX\n-}\n-\n-#[deriving(Eq)]\n-pub enum uv_req_type {\n-    UV_UNKNOWN_REQ,\n-    UV_REQ,\n-    UV_CONNECT,\n-    UV_WRITE,\n-    UV_SHUTDOWN,\n-    UV_UDP_SEND,\n-    UV_FS,\n-    UV_WORK,\n-    UV_GETADDRINFO,\n-    UV_REQ_TYPE_MAX\n-}\n-\n-pub unsafe fn malloc_handle(handle: uv_handle_type) -> *c_void {\n-    assert!(handle != UV_UNKNOWN_HANDLE && handle != UV_HANDLE_TYPE_MAX);\n-    let size = rust_uv_handle_size(handle as uint);\n-    let p = malloc(size);\n-    assert!(p.is_not_null());\n-    return p;\n-}\n-\n-pub unsafe fn free_handle(v: *c_void) {\n-    free(v)\n-}\n-\n-pub unsafe fn malloc_req(req: uv_req_type) -> *c_void {\n-    assert!(req != UV_UNKNOWN_REQ && req != UV_REQ_TYPE_MAX);\n-    let size = rust_uv_req_size(req as uint);\n-    let p = malloc(size);\n-    assert!(p.is_not_null());\n-    return p;\n-}\n-\n-pub unsafe fn free_req(v: *c_void) {\n-    free(v)\n-}\n-\n-#[test]\n-fn handle_sanity_check() {\n-    unsafe {\n-        assert!(UV_HANDLE_TYPE_MAX as uint == rust_uv_handle_type_max());\n-    }\n-}\n-\n-#[test]\n-fn request_sanity_check() {\n-    unsafe {\n-        assert!(UV_REQ_TYPE_MAX as uint == rust_uv_req_type_max());\n-    }\n-}\n-\n-pub unsafe fn loop_new() -> *c_void {\n-    return rust_uv_loop_new();\n-}\n-\n-pub unsafe fn loop_delete(loop_handle: *c_void) {\n-    rust_uv_loop_delete(loop_handle);\n-}\n-\n-pub unsafe fn run(loop_handle: *c_void) {\n-    rust_uv_run(loop_handle);\n-}\n-\n-pub unsafe fn close<T>(handle: *T, cb: *u8) {\n-    rust_uv_close(handle as *c_void, cb);\n-}\n-\n-pub unsafe fn walk(loop_handle: *c_void, cb: *u8, arg: *c_void) {\n-    rust_uv_walk(loop_handle, cb, arg);\n-}\n-\n-pub unsafe fn idle_new() -> *uv_idle_t {\n-    rust_uv_idle_new()\n-}\n-\n-pub unsafe fn idle_delete(handle: *uv_idle_t) {\n-    rust_uv_idle_delete(handle)\n-}\n-\n-pub unsafe fn idle_init(loop_handle: *uv_loop_t, handle: *uv_idle_t) -> c_int {\n-    rust_uv_idle_init(loop_handle, handle)\n-}\n-\n-pub unsafe fn idle_start(handle: *uv_idle_t, cb: uv_idle_cb) -> c_int {\n-    rust_uv_idle_start(handle, cb)\n-}\n-\n-pub unsafe fn idle_stop(handle: *uv_idle_t) -> c_int {\n-    rust_uv_idle_stop(handle)\n-}\n-\n-pub unsafe fn tcp_init(loop_handle: *c_void, handle: *uv_tcp_t) -> c_int {\n-    return rust_uv_tcp_init(loop_handle, handle);\n-}\n-\n-// FIXME ref #2064\n-pub unsafe fn tcp_connect(connect_ptr: *uv_connect_t,\n-                          tcp_handle_ptr: *uv_tcp_t,\n-                          addr_ptr: *sockaddr_in,\n-                          after_connect_cb: *u8) -> c_int {\n-    return rust_uv_tcp_connect(connect_ptr, tcp_handle_ptr,\n-                                       after_connect_cb, addr_ptr);\n-}\n-// FIXME ref #2064\n-pub unsafe fn tcp_connect6(connect_ptr: *uv_connect_t,\n-                           tcp_handle_ptr: *uv_tcp_t,\n-                           addr_ptr: *sockaddr_in6,\n-                           after_connect_cb: *u8) -> c_int {\n-    return rust_uv_tcp_connect6(connect_ptr, tcp_handle_ptr,\n-                                        after_connect_cb, addr_ptr);\n-}\n-// FIXME ref #2064\n-pub unsafe fn tcp_bind(tcp_server_ptr: *uv_tcp_t, addr_ptr: *sockaddr_in) -> c_int {\n-    return rust_uv_tcp_bind(tcp_server_ptr, addr_ptr);\n-}\n-// FIXME ref #2064\n-pub unsafe fn tcp_bind6(tcp_server_ptr: *uv_tcp_t, addr_ptr: *sockaddr_in6) -> c_int {\n-    return rust_uv_tcp_bind6(tcp_server_ptr, addr_ptr);\n-}\n-\n-pub unsafe fn tcp_getpeername(tcp_handle_ptr: *uv_tcp_t, name: *sockaddr_in) -> c_int {\n-    return rust_uv_tcp_getpeername(tcp_handle_ptr, name);\n-}\n-\n-pub unsafe fn tcp_getpeername6(tcp_handle_ptr: *uv_tcp_t, name: *sockaddr_in6) ->c_int {\n-    return rust_uv_tcp_getpeername6(tcp_handle_ptr, name);\n-}\n-\n-pub unsafe fn listen<T>(stream: *T, backlog: c_int, cb: *u8) -> c_int {\n-    return rust_uv_listen(stream as *c_void, backlog, cb);\n-}\n-\n-pub unsafe fn accept(server: *c_void, client: *c_void) -> c_int {\n-    return rust_uv_accept(server as *c_void, client as *c_void);\n-}\n-\n-pub unsafe fn write<T>(req: *uv_write_t, stream: *T, buf_in: &[uv_buf_t], cb: *u8) -> c_int {\n-    let buf_ptr = vec::raw::to_ptr(buf_in);\n-    let buf_cnt = buf_in.len() as i32;\n-    return rust_uv_write(req as *c_void, stream as *c_void, buf_ptr, buf_cnt, cb);\n-}\n-pub unsafe fn read_start(stream: *uv_stream_t, on_alloc: *u8, on_read: *u8) -> c_int {\n-    return rust_uv_read_start(stream as *c_void, on_alloc, on_read);\n-}\n-\n-pub unsafe fn read_stop(stream: *uv_stream_t) -> c_int {\n-    return rust_uv_read_stop(stream as *c_void);\n-}\n-\n-pub unsafe fn last_error(loop_handle: *c_void) -> uv_err_t {\n-    return rust_uv_last_error(loop_handle);\n-}\n-\n-pub unsafe fn strerror(err: *uv_err_t) -> *c_char {\n-    return rust_uv_strerror(err);\n-}\n-pub unsafe fn err_name(err: *uv_err_t) -> *c_char {\n-    return rust_uv_err_name(err);\n-}\n-\n-pub unsafe fn async_init(loop_handle: *c_void, async_handle: *uv_async_t, cb: *u8) -> c_int {\n-    return rust_uv_async_init(loop_handle, async_handle, cb);\n-}\n-\n-pub unsafe fn async_send(async_handle: *uv_async_t) {\n-    return rust_uv_async_send(async_handle);\n-}\n-pub unsafe fn buf_init(input: *u8, len: uint) -> uv_buf_t {\n-    let out_buf = uv_buf_t { base: ptr::null(), len: 0 as size_t };\n-    let out_buf_ptr = ptr::to_unsafe_ptr(&out_buf);\n-    rust_uv_buf_init(out_buf_ptr, input, len as size_t);\n-    return out_buf;\n-}\n-\n-pub unsafe fn timer_init(loop_ptr: *c_void, timer_ptr: *uv_timer_t) -> c_int {\n-    return rust_uv_timer_init(loop_ptr, timer_ptr);\n-}\n-pub unsafe fn timer_start(timer_ptr: *uv_timer_t, cb: *u8, timeout: uint,\n-                          repeat: uint) -> c_int {\n-    return rust_uv_timer_start(timer_ptr, cb, timeout as c_uint, repeat as c_uint);\n-}\n-pub unsafe fn timer_stop(timer_ptr: *uv_timer_t) -> c_int {\n-    return rust_uv_timer_stop(timer_ptr);\n-}\n-\n-pub unsafe fn malloc_ip4_addr(ip: &str, port: int) -> *sockaddr_in {\n-    do str::as_c_str(ip) |ip_buf| {\n-        rust_uv_ip4_addrp(ip_buf as *u8, port as libc::c_int)\n-    }\n-}\n-pub unsafe fn malloc_ip6_addr(ip: &str, port: int) -> *sockaddr_in6 {\n-    do str::as_c_str(ip) |ip_buf| {\n-        rust_uv_ip6_addrp(ip_buf as *u8, port as libc::c_int)\n-    }\n-}\n-\n-pub unsafe fn free_ip4_addr(addr: *sockaddr_in) {\n-    rust_uv_free_ip4_addr(addr);\n-}\n-\n-pub unsafe fn free_ip6_addr(addr: *sockaddr_in6) {\n-    rust_uv_free_ip6_addr(addr);\n-}\n-\n-// data access helpers\n-pub unsafe fn get_loop_for_uv_handle<T>(handle: *T) -> *c_void {\n-    return rust_uv_get_loop_for_uv_handle(handle as *c_void);\n-}\n-pub unsafe fn get_stream_handle_from_connect_req(connect: *uv_connect_t) -> *uv_stream_t {\n-    return rust_uv_get_stream_handle_from_connect_req(connect);\n-}\n-pub unsafe fn get_stream_handle_from_write_req(write_req: *uv_write_t) -> *uv_stream_t {\n-    return rust_uv_get_stream_handle_from_write_req(write_req);\n-}\n-pub unsafe fn get_data_for_uv_loop(loop_ptr: *c_void) -> *c_void {\n-    rust_uv_get_data_for_uv_loop(loop_ptr)\n-}\n-pub unsafe fn set_data_for_uv_loop(loop_ptr: *c_void, data: *c_void) {\n-    rust_uv_set_data_for_uv_loop(loop_ptr, data);\n-}\n-pub unsafe fn get_data_for_uv_handle<T>(handle: *T) -> *c_void {\n-    return rust_uv_get_data_for_uv_handle(handle as *c_void);\n-}\n-pub unsafe fn set_data_for_uv_handle<T, U>(handle: *T, data: *U) {\n-    rust_uv_set_data_for_uv_handle(handle as *c_void, data as *c_void);\n-}\n-pub unsafe fn get_data_for_req<T>(req: *T) -> *c_void {\n-    return rust_uv_get_data_for_req(req as *c_void);\n-}\n-pub unsafe fn set_data_for_req<T, U>(req: *T, data: *U) {\n-    rust_uv_set_data_for_req(req as *c_void, data as *c_void);\n-}\n-pub unsafe fn get_base_from_buf(buf: uv_buf_t) -> *u8 {\n-    return rust_uv_get_base_from_buf(buf);\n-}\n-pub unsafe fn get_len_from_buf(buf: uv_buf_t) -> size_t {\n-    return rust_uv_get_len_from_buf(buf);\n-}\n-pub unsafe fn malloc_buf_base_of(suggested_size: size_t) -> *u8 {\n-    return rust_uv_malloc_buf_base_of(suggested_size);\n-}\n-pub unsafe fn free_base_of_buf(buf: uv_buf_t) {\n-    rust_uv_free_base_of_buf(buf);\n-}\n-\n-pub unsafe fn get_last_err_info(uv_loop: *c_void) -> ~str {\n-    let err = last_error(uv_loop);\n-    let err_ptr = ptr::to_unsafe_ptr(&err);\n-    let err_name = str::raw::from_c_str(err_name(err_ptr));\n-    let err_msg = str::raw::from_c_str(strerror(err_ptr));\n-    return fmt!(\"LIBUV ERROR: name: %s msg: %s\",\n-                    err_name, err_msg);\n-}\n-\n-pub unsafe fn get_last_err_data(uv_loop: *c_void) -> uv_err_data {\n-    let err = last_error(uv_loop);\n-    let err_ptr = ptr::to_unsafe_ptr(&err);\n-    let err_name = str::raw::from_c_str(err_name(err_ptr));\n-    let err_msg = str::raw::from_c_str(strerror(err_ptr));\n-    uv_err_data { err_name: err_name, err_msg: err_msg }\n-}\n-\n-pub struct uv_err_data {\n-    err_name: ~str,\n-    err_msg: ~str,\n-}\n-\n-extern {\n-\n-    fn rust_uv_handle_size(type_: uintptr_t) -> size_t;\n-    fn rust_uv_req_size(type_: uintptr_t) -> size_t;\n-    fn rust_uv_handle_type_max() -> uintptr_t;\n-    fn rust_uv_req_type_max() -> uintptr_t;\n-\n-    // libuv public API\n-    fn rust_uv_loop_new() -> *c_void;\n-    fn rust_uv_loop_delete(lp: *c_void);\n-    fn rust_uv_run(loop_handle: *c_void);\n-    fn rust_uv_close(handle: *c_void, cb: *u8);\n-    fn rust_uv_walk(loop_handle: *c_void, cb: *u8, arg: *c_void);\n-\n-    fn rust_uv_idle_new() -> *uv_idle_t;\n-    fn rust_uv_idle_delete(handle: *uv_idle_t);\n-    fn rust_uv_idle_init(loop_handle: *uv_loop_t, handle: *uv_idle_t) -> c_int;\n-    fn rust_uv_idle_start(handle: *uv_idle_t, cb: uv_idle_cb) -> c_int;\n-    fn rust_uv_idle_stop(handle: *uv_idle_t) -> c_int;\n-\n-    fn rust_uv_async_send(handle: *uv_async_t);\n-    fn rust_uv_async_init(loop_handle: *c_void,\n-                          async_handle: *uv_async_t,\n-                          cb: *u8) -> c_int;\n-    fn rust_uv_tcp_init(loop_handle: *c_void, handle_ptr: *uv_tcp_t) -> c_int;\n-    // FIXME ref #2604 .. ?\n-    fn rust_uv_buf_init(out_buf: *uv_buf_t, base: *u8, len: size_t);\n-    fn rust_uv_last_error(loop_handle: *c_void) -> uv_err_t;\n-    // FIXME ref #2064\n-    fn rust_uv_strerror(err: *uv_err_t) -> *c_char;\n-    // FIXME ref #2064\n-    fn rust_uv_err_name(err: *uv_err_t) -> *c_char;\n-    fn rust_uv_ip4_addrp(ip: *u8, port: c_int) -> *sockaddr_in;\n-    fn rust_uv_ip6_addrp(ip: *u8, port: c_int) -> *sockaddr_in6;\n-    fn rust_uv_free_ip4_addr(addr: *sockaddr_in);\n-    fn rust_uv_free_ip6_addr(addr: *sockaddr_in6);\n-    fn rust_uv_ip4_name(src: *sockaddr_in, dst: *u8, size: size_t) -> c_int;\n-    fn rust_uv_ip6_name(src: *sockaddr_in6, dst: *u8, size: size_t) -> c_int;\n-    fn rust_uv_ip4_port(src: *sockaddr_in) -> c_uint;\n-    fn rust_uv_ip6_port(src: *sockaddr_in6) -> c_uint;\n-    // FIXME ref #2064\n-    fn rust_uv_tcp_connect(connect_ptr: *uv_connect_t,\n-                           tcp_handle_ptr: *uv_tcp_t,\n-                           after_cb: *u8,\n-                           addr: *sockaddr_in) -> c_int;\n-    // FIXME ref #2064\n-    fn rust_uv_tcp_bind(tcp_server: *uv_tcp_t, addr: *sockaddr_in) -> c_int;\n-    // FIXME ref #2064\n-    fn rust_uv_tcp_connect6(connect_ptr: *uv_connect_t,\n-                            tcp_handle_ptr: *uv_tcp_t,\n-                            after_cb: *u8,\n-                            addr: *sockaddr_in6) -> c_int;\n-    // FIXME ref #2064\n-    fn rust_uv_tcp_bind6(tcp_server: *uv_tcp_t, addr: *sockaddr_in6) -> c_int;\n-    fn rust_uv_tcp_getpeername(tcp_handle_ptr: *uv_tcp_t,\n-                               name: *sockaddr_in) -> c_int;\n-    fn rust_uv_tcp_getpeername6(tcp_handle_ptr: *uv_tcp_t,\n-                                name: *sockaddr_in6) ->c_int;\n-    fn rust_uv_listen(stream: *c_void, backlog: c_int, cb: *u8) -> c_int;\n-    fn rust_uv_accept(server: *c_void, client: *c_void) -> c_int;\n-    fn rust_uv_write(req: *c_void,\n-                     stream: *c_void,\n-                     buf_in: *uv_buf_t,\n-                     buf_cnt: c_int,\n-                     cb: *u8) -> c_int;\n-    fn rust_uv_read_start(stream: *c_void,\n-                          on_alloc: *u8,\n-                          on_read: *u8) -> c_int;\n-    fn rust_uv_read_stop(stream: *c_void) -> c_int;\n-    fn rust_uv_timer_init(loop_handle: *c_void,\n-                          timer_handle: *uv_timer_t) -> c_int;\n-    fn rust_uv_timer_start(timer_handle: *uv_timer_t,\n-                           cb: *u8,\n-                           timeout: c_uint,\n-                           repeat: c_uint) -> c_int;\n-    fn rust_uv_timer_stop(handle: *uv_timer_t) -> c_int;\n-\n-    fn rust_uv_malloc_buf_base_of(sug_size: size_t) -> *u8;\n-    fn rust_uv_free_base_of_buf(buf: uv_buf_t);\n-    fn rust_uv_get_stream_handle_from_connect_req(connect_req: *uv_connect_t) -> *uv_stream_t;\n-    fn rust_uv_get_stream_handle_from_write_req(write_req: *uv_write_t) -> *uv_stream_t;\n-    fn rust_uv_get_loop_for_uv_handle(handle: *c_void) -> *c_void;\n-    fn rust_uv_get_data_for_uv_loop(loop_ptr: *c_void) -> *c_void;\n-    fn rust_uv_set_data_for_uv_loop(loop_ptr: *c_void, data: *c_void);\n-    fn rust_uv_get_data_for_uv_handle(handle: *c_void) -> *c_void;\n-    fn rust_uv_set_data_for_uv_handle(handle: *c_void, data: *c_void);\n-    fn rust_uv_get_data_for_req(req: *c_void) -> *c_void;\n-    fn rust_uv_set_data_for_req(req: *c_void, data: *c_void);\n-    fn rust_uv_get_base_from_buf(buf: uv_buf_t) -> *u8;\n-    fn rust_uv_get_len_from_buf(buf: uv_buf_t) -> size_t;\n-}"}, {"sha": "9f72f941bde9b2cdb779e3fa5476fdc00b20f4fc", "filename": "src/libstd/sys.rs", "status": "modified", "additions": 16, "deletions": 10, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fsys.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fsys.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -12,7 +12,6 @@\n \n #[allow(missing_doc)];\n \n-use option::{Some, None};\n use cast;\n use gc;\n use io;\n@@ -151,10 +150,12 @@ impl FailWithCause for &'static str {\n \n // FIXME #4427: Temporary until rt::rt_fail_ goes away\n pub fn begin_unwind_(msg: *c_char, file: *c_char, line: size_t) -> ! {\n-    use option::Option;\n+    use cell::Cell;\n+    use either::Left;\n     use rt::{context, OldTaskContext, TaskContext};\n-    use rt::task::{Task, Unwinder};\n+    use rt::task::Task;\n     use rt::local::Local;\n+    use rt::logging::Logger;\n \n     let context = context();\n     match context {\n@@ -171,24 +172,29 @@ pub fn begin_unwind_(msg: *c_char, file: *c_char, line: size_t) -> ! {\n                 let msg = str::raw::from_c_str(msg);\n                 let file = str::raw::from_c_str(file);\n \n-                let outmsg = fmt!(\"%s at line %i of file %s\", msg, line as int, file);\n+                let outmsg = fmt!(\"task failed at '%s', %s:%i\",\n+                                  msg, file, line as int);\n \n                 // XXX: Logging doesn't work correctly in non-task context because it\n                 // invokes the local heap\n                 if context == TaskContext {\n-                    error!(outmsg);\n+                    // XXX: Logging doesn't work here - the check to call the log\n+                    // function never passes - so calling the log function directly.\n+                    let outmsg = Cell::new(outmsg);\n+                    do Local::borrow::<Task, ()> |task| {\n+                        task.logger.log(Left(outmsg.take()));\n+                    }\n                 } else {\n-                    rtdebug!(\"%s\", outmsg);\n+                    rterrln!(\"%s\", outmsg);\n                 }\n \n                 gc::cleanup_stack_for_failure();\n \n                 let task = Local::unsafe_borrow::<Task>();\n-                let unwinder: &mut Option<Unwinder> = &mut (*task).unwinder;\n-                match *unwinder {\n-                    Some(ref mut unwinder) => unwinder.begin_unwind(),\n-                    None => abort!(\"failure without unwinder. aborting process\")\n+                if (*task).unwinder.unwinding {\n+                    rtabort!(\"unwinding again\");\n                 }\n+                (*task).unwinder.begin_unwind();\n             }\n         }\n     }"}, {"sha": "5a3ff10ae83e66263ead7fe3cedc6d5b1e59f7fc", "filename": "src/libstd/task/mod.rs", "status": "modified", "additions": 22, "deletions": 17, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Ftask%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Ftask%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fmod.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -497,11 +497,26 @@ pub fn try<T:Send>(f: ~fn() -> T) -> Result<T,()> {\n pub fn yield() {\n     //! Yield control to the task scheduler\n \n+    use rt::{context, OldTaskContext};\n+    use rt::local::Local;\n+    use rt::sched::Scheduler;\n+\n     unsafe {\n-        let task_ = rt::rust_get_task();\n-        let killed = rt::rust_task_yield(task_);\n-        if killed && !failing() {\n-            fail!(\"killed\");\n+        match context() {\n+            OldTaskContext => {\n+                let task_ = rt::rust_get_task();\n+                let killed = rt::rust_task_yield(task_);\n+                if killed && !failing() {\n+                    fail!(\"killed\");\n+                }\n+            }\n+            _ => {\n+                // XXX: What does yield really mean in newsched?\n+                let sched = Local::take::<Scheduler>();\n+                do sched.deschedule_running_task_and_then |sched, task| {\n+                    sched.enqueue_task(task);\n+                }\n+            }\n         }\n     }\n }\n@@ -520,20 +535,9 @@ pub fn failing() -> bool {\n             }\n         }\n         _ => {\n-            let mut unwinding = false;\n-            do Local::borrow::<Task> |local| {\n-                unwinding = match local.unwinder {\n-                    Some(unwinder) => {\n-                        unwinder.unwinding\n-                    }\n-                    None => {\n-                        // Because there is no unwinder we can't be unwinding.\n-                        // (The process will abort on failure)\n-                        false\n-                    }\n-                }\n+            do Local::borrow::<Task, bool> |local| {\n+                local.unwinder.unwinding\n             }\n-            return unwinding;\n         }\n     }\n }\n@@ -1191,3 +1195,4 @@ fn test_simple_newsched_spawn() {\n         spawn(||())\n     }\n }\n+"}, {"sha": "bcb7e06bf1f744c2cf51fa640d2f439e591759a7", "filename": "src/libstd/task/spawn.rs", "status": "modified", "additions": 34, "deletions": 4, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Ftask%2Fspawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Ftask%2Fspawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fspawn.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -91,6 +91,7 @@ use uint;\n use util;\n use unstable::sync::{Exclusive, exclusive};\n use rt::local::Local;\n+use rt::task::Task;\n use iterator::IteratorUtil;\n \n #[cfg(test)] use task::default_task_opts;\n@@ -581,12 +582,41 @@ pub fn spawn_raw(opts: TaskOpts, f: ~fn()) {\n     }\n }\n \n-fn spawn_raw_newsched(_opts: TaskOpts, f: ~fn()) {\n+fn spawn_raw_newsched(mut opts: TaskOpts, f: ~fn()) {\n     use rt::sched::*;\n \n-    let mut sched = Local::take::<Scheduler>();\n-    let task = ~Coroutine::new(&mut sched.stack_pool, f);\n-    sched.schedule_new_task(task);\n+    let f = Cell::new(f);\n+\n+    let mut task = unsafe {\n+        let sched = Local::unsafe_borrow::<Scheduler>();\n+        rtdebug!(\"unsafe borrowed sched\");\n+\n+        if opts.linked {\n+            do Local::borrow::<Task, ~Task>() |running_task| {\n+                ~running_task.new_child(&mut (*sched).stack_pool, f.take())\n+            }\n+        } else {\n+            // An unlinked task is a new root in the task tree\n+            ~Task::new_root(&mut (*sched).stack_pool, f.take())\n+        }\n+    };\n+\n+    if opts.notify_chan.is_some() {\n+        let notify_chan = opts.notify_chan.swap_unwrap();\n+        let notify_chan = Cell::new(notify_chan);\n+        let on_exit: ~fn(bool) = |success| {\n+            notify_chan.take().send(\n+                if success { Success } else { Failure }\n+            )\n+        };\n+        task.on_exit = Some(on_exit);\n+    }\n+\n+    rtdebug!(\"spawn about to take scheduler\");\n+\n+    let sched = Local::take::<Scheduler>();\n+    rtdebug!(\"took sched in spawn\");\n+    sched.schedule_task(task);\n }\n \n fn spawn_raw_oldsched(mut opts: TaskOpts, f: ~fn()) {"}, {"sha": "66bb46b8991a5516aa3a3703a2016db66d208b31", "filename": "src/libstd/unstable/lang.rs", "status": "modified", "additions": 19, "deletions": 248, "changes": 267, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Funstable%2Flang.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Funstable%2Flang.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Flang.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -10,29 +10,21 @@\n \n //! Runtime calls emitted by the compiler.\n \n-use iterator::IteratorUtil;\n-use uint;\n use cast::transmute;\n-use libc::{c_char, c_uchar, c_void, size_t, uintptr_t, c_int, STDERR_FILENO};\n-use managed::raw::BoxRepr;\n+use libc::{c_char, c_uchar, c_void, size_t, uintptr_t, c_int};\n use str;\n use sys;\n use rt::{context, OldTaskContext};\n use rt::task::Task;\n use rt::local::Local;\n-use option::{Option, Some, None};\n-use io;\n+use rt::borrowck;\n \n #[allow(non_camel_case_types)]\n pub type rust_task = c_void;\n \n-pub static FROZEN_BIT: uint = 1 << (uint::bits - 1);\n-pub static MUT_BIT: uint = 1 << (uint::bits - 2);\n-static ALL_BITS: uint = FROZEN_BIT | MUT_BIT;\n-\n pub mod rustrt {\n     use unstable::lang::rust_task;\n-    use libc::{c_void, c_char, uintptr_t};\n+    use libc::{c_char, uintptr_t};\n \n     pub extern {\n         #[rust_stack]\n@@ -46,15 +38,6 @@ pub mod rustrt {\n                                               size: uintptr_t)\n                                            -> *c_char;\n \n-        #[fast_ffi]\n-        unsafe fn rust_upcall_free_noswitch(ptr: *c_char);\n-\n-        #[rust_stack]\n-        fn rust_take_task_borrow_list(task: *rust_task) -> *c_void;\n-\n-        #[rust_stack]\n-        fn rust_set_task_borrow_list(task: *rust_task, map: *c_void);\n-\n         #[rust_stack]\n         fn rust_try_get_task() -> *rust_task;\n \n@@ -77,149 +60,6 @@ pub fn fail_bounds_check(file: *c_char, line: size_t,\n     }\n }\n \n-#[deriving(Eq)]\n-struct BorrowRecord {\n-    box: *mut BoxRepr,\n-    file: *c_char,\n-    line: size_t\n-}\n-\n-fn try_take_task_borrow_list() -> Option<~[BorrowRecord]> {\n-    unsafe {\n-        let cur_task: *rust_task = rustrt::rust_try_get_task();\n-        if cur_task.is_not_null() {\n-            let ptr = rustrt::rust_take_task_borrow_list(cur_task);\n-            if ptr.is_null() {\n-                None\n-            } else {\n-                let v: ~[BorrowRecord] = transmute(ptr);\n-                Some(v)\n-            }\n-        } else {\n-            None\n-        }\n-    }\n-}\n-\n-fn swap_task_borrow_list(f: &fn(~[BorrowRecord]) -> ~[BorrowRecord]) {\n-    unsafe {\n-        let cur_task: *rust_task = rustrt::rust_try_get_task();\n-        if cur_task.is_not_null() {\n-            let mut borrow_list: ~[BorrowRecord] = {\n-                let ptr = rustrt::rust_take_task_borrow_list(cur_task);\n-                if ptr.is_null() { ~[] } else { transmute(ptr) }\n-            };\n-            borrow_list = f(borrow_list);\n-            rustrt::rust_set_task_borrow_list(cur_task, transmute(borrow_list));\n-        }\n-    }\n-}\n-\n-pub unsafe fn clear_task_borrow_list() {\n-    // pub because it is used by the box annihilator.\n-    let _ = try_take_task_borrow_list();\n-}\n-\n-unsafe fn fail_borrowed(box: *mut BoxRepr, file: *c_char, line: size_t) {\n-    debug_borrow(\"fail_borrowed: \", box, 0, 0, file, line);\n-\n-    match try_take_task_borrow_list() {\n-        None => { // not recording borrows\n-            let msg = \"borrowed\";\n-            do str::as_buf(msg) |msg_p, _| {\n-                fail_(msg_p as *c_char, file, line);\n-            }\n-        }\n-        Some(borrow_list) => { // recording borrows\n-            let mut msg = ~\"borrowed\";\n-            let mut sep = \" at \";\n-            for borrow_list.rev_iter().advance |entry| {\n-                if entry.box == box {\n-                    msg.push_str(sep);\n-                    let filename = str::raw::from_c_str(entry.file);\n-                    msg.push_str(filename);\n-                    msg.push_str(fmt!(\":%u\", entry.line as uint));\n-                    sep = \" and at \";\n-                }\n-            }\n-            do str::as_buf(msg) |msg_p, _| {\n-                fail_(msg_p as *c_char, file, line)\n-            }\n-        }\n-    }\n-}\n-\n-/// Because this code is so perf. sensitive, use a static constant so that\n-/// debug printouts are compiled out most of the time.\n-static ENABLE_DEBUG: bool = false;\n-\n-#[inline]\n-unsafe fn debug_borrow<T>(tag: &'static str,\n-                          p: *const T,\n-                          old_bits: uint,\n-                          new_bits: uint,\n-                          filename: *c_char,\n-                          line: size_t) {\n-    //! A useful debugging function that prints a pointer + tag + newline\n-    //! without allocating memory.\n-\n-    if ENABLE_DEBUG && ::rt::env::get().debug_borrow {\n-        debug_borrow_slow(tag, p, old_bits, new_bits, filename, line);\n-    }\n-\n-    unsafe fn debug_borrow_slow<T>(tag: &'static str,\n-                                   p: *const T,\n-                                   old_bits: uint,\n-                                   new_bits: uint,\n-                                   filename: *c_char,\n-                                   line: size_t) {\n-        let dbg = STDERR_FILENO as io::fd_t;\n-        dbg.write_str(tag);\n-        dbg.write_hex(p as uint);\n-        dbg.write_str(\" \");\n-        dbg.write_hex(old_bits);\n-        dbg.write_str(\" \");\n-        dbg.write_hex(new_bits);\n-        dbg.write_str(\" \");\n-        dbg.write_cstr(filename);\n-        dbg.write_str(\":\");\n-        dbg.write_hex(line as uint);\n-        dbg.write_str(\"\\n\");\n-    }\n-}\n-\n-trait DebugPrints {\n-    fn write_hex(&self, val: uint);\n-    unsafe fn write_cstr(&self, str: *c_char);\n-}\n-\n-impl DebugPrints for io::fd_t {\n-    fn write_hex(&self, mut i: uint) {\n-        let letters = ['0', '1', '2', '3', '4', '5', '6', '7', '8',\n-                       '9', 'a', 'b', 'c', 'd', 'e', 'f'];\n-        static UINT_NIBBLES: uint = ::uint::bytes << 1;\n-        let mut buffer = [0_u8, ..UINT_NIBBLES+1];\n-        let mut c = UINT_NIBBLES;\n-        while c > 0 {\n-            c -= 1;\n-            buffer[c] = letters[i & 0xF] as u8;\n-            i >>= 4;\n-        }\n-        self.write(buffer.slice(0, UINT_NIBBLES));\n-    }\n-\n-    unsafe fn write_cstr(&self, p: *c_char) {\n-        use libc::strlen;\n-        use vec;\n-\n-        let len = strlen(p);\n-        let p: *u8 = transmute(p);\n-        do vec::raw::buf_as_slice(p, len as uint) |s| {\n-            self.write(s);\n-        }\n-    }\n-}\n-\n #[lang=\"malloc\"]\n pub unsafe fn local_malloc(td: *c_char, size: uintptr_t) -> *c_char {\n     match context() {\n@@ -228,7 +68,10 @@ pub unsafe fn local_malloc(td: *c_char, size: uintptr_t) -> *c_char {\n         }\n         _ => {\n             let mut alloc = ::ptr::null();\n-            do Local::borrow::<Task> |task| {\n+            do Local::borrow::<Task,()> |task| {\n+                rtdebug!(\"task pointer: %x, heap pointer: %x\",\n+                         to_uint(task),\n+                         to_uint(&task.heap));\n                 alloc = task.heap.alloc(td as *c_void, size as uint) as *c_char;\n             }\n             return alloc;\n@@ -241,123 +84,46 @@ pub unsafe fn local_malloc(td: *c_char, size: uintptr_t) -> *c_char {\n // problem occurs, call exit instead.\n #[lang=\"free\"]\n pub unsafe fn local_free(ptr: *c_char) {\n-    match context() {\n-        OldTaskContext => {\n-            rustrt::rust_upcall_free_noswitch(ptr);\n-        }\n-        _ => {\n-            do Local::borrow::<Task> |task| {\n-                task.heap.free(ptr as *c_void);\n-            }\n-        }\n-    }\n+    ::rt::local_heap::local_free(ptr);\n }\n \n #[lang=\"borrow_as_imm\"]\n #[inline]\n pub unsafe fn borrow_as_imm(a: *u8, file: *c_char, line: size_t) -> uint {\n-    let a: *mut BoxRepr = transmute(a);\n-    let old_ref_count = (*a).header.ref_count;\n-    let new_ref_count = old_ref_count | FROZEN_BIT;\n-\n-    debug_borrow(\"borrow_as_imm:\", a, old_ref_count, new_ref_count, file, line);\n-\n-    if (old_ref_count & MUT_BIT) != 0 {\n-        fail_borrowed(a, file, line);\n-    }\n-\n-    (*a).header.ref_count = new_ref_count;\n-\n-    old_ref_count\n+    borrowck::borrow_as_imm(a, file, line)\n }\n \n #[lang=\"borrow_as_mut\"]\n #[inline]\n pub unsafe fn borrow_as_mut(a: *u8, file: *c_char, line: size_t) -> uint {\n-    let a: *mut BoxRepr = transmute(a);\n-    let old_ref_count = (*a).header.ref_count;\n-    let new_ref_count = old_ref_count | MUT_BIT | FROZEN_BIT;\n-\n-    debug_borrow(\"borrow_as_mut:\", a, old_ref_count, new_ref_count, file, line);\n-\n-    if (old_ref_count & (MUT_BIT|FROZEN_BIT)) != 0 {\n-        fail_borrowed(a, file, line);\n-    }\n-\n-    (*a).header.ref_count = new_ref_count;\n-\n-    old_ref_count\n+    borrowck::borrow_as_mut(a, file, line)\n }\n \n-\n #[lang=\"record_borrow\"]\n pub unsafe fn record_borrow(a: *u8, old_ref_count: uint,\n                             file: *c_char, line: size_t) {\n-    if (old_ref_count & ALL_BITS) == 0 {\n-        // was not borrowed before\n-        let a: *mut BoxRepr = transmute(a);\n-        debug_borrow(\"record_borrow:\", a, old_ref_count, 0, file, line);\n-        do swap_task_borrow_list |borrow_list| {\n-            let mut borrow_list = borrow_list;\n-            borrow_list.push(BorrowRecord {box: a, file: file, line: line});\n-            borrow_list\n-        }\n-    }\n+    borrowck::record_borrow(a, old_ref_count, file, line)\n }\n \n #[lang=\"unrecord_borrow\"]\n pub unsafe fn unrecord_borrow(a: *u8, old_ref_count: uint,\n                               file: *c_char, line: size_t) {\n-    if (old_ref_count & ALL_BITS) == 0 {\n-        // was not borrowed before, so we should find the record at\n-        // the end of the list\n-        let a: *mut BoxRepr = transmute(a);\n-        debug_borrow(\"unrecord_borrow:\", a, old_ref_count, 0, file, line);\n-        do swap_task_borrow_list |borrow_list| {\n-            let mut borrow_list = borrow_list;\n-            assert!(!borrow_list.is_empty());\n-            let br = borrow_list.pop();\n-            if br.box != a || br.file != file || br.line != line {\n-                let err = fmt!(\"wrong borrow found, br=%?\", br);\n-                do str::as_buf(err) |msg_p, _| {\n-                    fail_(msg_p as *c_char, file, line)\n-                }\n-            }\n-            borrow_list\n-        }\n-    }\n+    borrowck::unrecord_borrow(a, old_ref_count, file, line)\n }\n \n #[lang=\"return_to_mut\"]\n #[inline]\n pub unsafe fn return_to_mut(a: *u8, orig_ref_count: uint,\n                             file: *c_char, line: size_t) {\n-    // Sometimes the box is null, if it is conditionally frozen.\n-    // See e.g. #4904.\n-    if !a.is_null() {\n-        let a: *mut BoxRepr = transmute(a);\n-        let old_ref_count = (*a).header.ref_count;\n-        let new_ref_count =\n-            (old_ref_count & !ALL_BITS) | (orig_ref_count & ALL_BITS);\n-\n-        debug_borrow(\"return_to_mut:\",\n-                     a, old_ref_count, new_ref_count, file, line);\n-\n-        (*a).header.ref_count = new_ref_count;\n-    }\n+    borrowck::return_to_mut(a, orig_ref_count, file, line)\n }\n \n #[lang=\"check_not_borrowed\"]\n #[inline]\n pub unsafe fn check_not_borrowed(a: *u8,\n                                  file: *c_char,\n                                  line: size_t) {\n-    let a: *mut BoxRepr = transmute(a);\n-    let ref_count = (*a).header.ref_count;\n-    debug_borrow(\"check_not_borrowed:\", a, ref_count, 0, file, line);\n-    if (ref_count & FROZEN_BIT) != 0 {\n-        fail_borrowed(a, file, line);\n-    }\n+    borrowck::check_not_borrowed(a, file, line)\n }\n \n #[lang=\"strdup_uniq\"]\n@@ -366,6 +132,11 @@ pub unsafe fn strdup_uniq(ptr: *c_uchar, len: uint) -> ~str {\n     str::raw::from_buf_len(ptr, len)\n }\n \n+#[lang=\"annihilate\"]\n+pub unsafe fn annihilate() {\n+    ::cleanup::annihilate()\n+}\n+\n #[lang=\"start\"]\n pub fn start(main: *u8, argc: int, argv: **c_char,\n              crate_map: *u8) -> int {"}, {"sha": "0da05dd167d2d279c79bb426e0b74ef8020ca31f", "filename": "src/libstd/unstable/sync.rs", "status": "modified", "additions": 69, "deletions": 0, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Funstable%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Funstable%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Fsync.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -205,8 +205,53 @@ extern {\n     fn rust_unlock_little_lock(lock: rust_little_lock);\n }\n \n+/* *********************************************************************/\n+\n+//FIXME: #5042 This should be replaced by proper atomic type\n+pub struct AtomicUint {\n+    priv inner: uint\n+}\n+\n+impl AtomicUint {\n+    pub fn new(val: uint) -> AtomicUint { AtomicUint { inner: val } }\n+    pub fn load(&self) -> uint {\n+        unsafe { intrinsics::atomic_load(cast::transmute(self)) as uint }\n+    }\n+    pub fn store(&mut self, val: uint) {\n+        unsafe { intrinsics::atomic_store(cast::transmute(self), val as int); }\n+    }\n+    pub fn add(&mut self, val: int) -> uint {\n+        unsafe { intrinsics::atomic_xadd(cast::transmute(self), val as int) as uint }\n+    }\n+    pub fn cas(&mut self, old:uint, new: uint) -> uint {\n+        unsafe { intrinsics::atomic_cxchg(cast::transmute(self), old as int, new as int) as uint }\n+    }\n+}\n+\n+pub struct AtomicInt {\n+    priv inner: int\n+}\n+\n+impl AtomicInt {\n+    pub fn new(val: int) -> AtomicInt { AtomicInt { inner: val } }\n+    pub fn load(&self) -> int {\n+        unsafe { intrinsics::atomic_load(&self.inner) }\n+    }\n+    pub fn store(&mut self, val: int) {\n+        unsafe { intrinsics::atomic_store(&mut self.inner, val); }\n+    }\n+    pub fn add(&mut self, val: int) -> int {\n+        unsafe { intrinsics::atomic_xadd(&mut self.inner, val) }\n+    }\n+    pub fn cas(&mut self, old: int, new: int) -> int {\n+        unsafe { intrinsics::atomic_cxchg(&mut self.inner, old, new) }\n+    }\n+}\n+\n+\n #[cfg(test)]\n mod tests {\n+    use super::*;\n     use comm;\n     use super::exclusive;\n     use task;\n@@ -262,4 +307,28 @@ mod tests {\n             }\n         }\n     }\n+\n+    #[test]\n+    fn atomic_int_smoke_test() {\n+        let mut i = AtomicInt::new(0);\n+        i.store(10);\n+        assert!(i.load() == 10);\n+        assert!(i.add(1) == 10);\n+        assert!(i.load() == 11);\n+        assert!(i.cas(11, 12) == 11);\n+        assert!(i.cas(11, 13) == 12);\n+        assert!(i.load() == 12);\n+    }\n+\n+    #[test]\n+    fn atomic_uint_smoke_test() {\n+        let mut i = AtomicUint::new(0);\n+        i.store(10);\n+        assert!(i.load() == 10);\n+        assert!(i.add(1) == 10);\n+        assert!(i.load() == 11);\n+        assert!(i.cas(11, 12) == 11);\n+        assert!(i.cas(11, 13) == 12);\n+        assert!(i.load() == 12);\n+    }\n }"}, {"sha": "4b719080f8436a3a7366e124bc870f50925fe0a8", "filename": "src/libstd/vec.rs", "status": "modified", "additions": 6, "deletions": 10, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Flibstd%2Fvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fvec.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -20,7 +20,6 @@ use cmp::{Eq, TotalEq, TotalOrd, Ordering, Less, Equal, Greater};\n use clone::Clone;\n use iterator::{FromIterator, Iterator, IteratorUtil};\n use kinds::Copy;\n-use libc;\n use libc::c_void;\n use num::Zero;\n use option::{None, Option, Some};\n@@ -33,17 +32,12 @@ use sys::size_of;\n use uint;\n use unstable::intrinsics;\n #[cfg(stage0)]\n-use intrinsic::{get_tydesc, TyDesc};\n+use intrinsic::{get_tydesc};\n #[cfg(not(stage0))]\n-use unstable::intrinsics::{get_tydesc, contains_managed, TyDesc};\n+use unstable::intrinsics::{get_tydesc, contains_managed};\n use vec;\n use util;\n \n-extern {\n-    #[fast_ffi]\n-    unsafe fn vec_reserve_shared_actual(t: *TyDesc, v: **raw::VecRepr, n: libc::size_t);\n-}\n-\n /// Returns true if two vectors have the same length\n pub fn same_length<T, U>(xs: &[T], ys: &[U]) -> bool {\n     xs.len() == ys.len()\n@@ -1139,7 +1133,9 @@ impl<T> OwnedVector<T> for ~[T] {\n                 let td = get_tydesc::<T>();\n                 if ((**ptr).box_header.ref_count ==\n                     managed::raw::RC_MANAGED_UNIQUE) {\n-                    vec_reserve_shared_actual(td, ptr as **raw::VecRepr, n as libc::size_t);\n+                    // XXX transmute shouldn't be necessary\n+                    let td = cast::transmute(td);\n+                    ::at_vec::raw::reserve_raw(td, ptr, n);\n                 } else {\n                     let alloc = n * sys::nonzero_size_of::<T>();\n                     *ptr = realloc_raw(*ptr as *mut c_void, alloc + size_of::<raw::VecRepr>())\n@@ -1169,7 +1165,7 @@ impl<T> OwnedVector<T> for ~[T] {\n                 let ptr: *mut *mut raw::VecRepr = cast::transmute(self);\n                 let td = get_tydesc::<T>();\n                 if contains_managed::<T>() {\n-                    vec_reserve_shared_actual(td, ptr as **raw::VecRepr, n as libc::size_t);\n+                    ::at_vec::raw::reserve_raw(td, ptr, n);\n                 } else {\n                     let alloc = n * sys::nonzero_size_of::<T>();\n                     let size = alloc + size_of::<raw::VecRepr>();"}, {"sha": "4a5fcf3c60432aec90e9360fff779f32277baa03", "filename": "src/rt/rust_builtin.cpp", "status": "modified", "additions": 68, "deletions": 18, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_builtin.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_builtin.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_builtin.cpp?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -68,11 +68,10 @@ rust_env_pairs() {\n }\n #endif\n \n-extern \"C\" CDECL void\n-vec_reserve_shared_actual(type_desc* ty, rust_vec_box** vp,\n-                          size_t n_elts) {\n+extern \"C\" CDECL void *\n+rust_local_realloc(rust_opaque_box *ptr, size_t size) {\n     rust_task *task = rust_get_current_task();\n-    reserve_vec_exact_shared(task, vp, n_elts * ty->size);\n+    return task->boxed.realloc(ptr, size);\n }\n \n extern \"C\" CDECL size_t\n@@ -87,15 +86,10 @@ rand_gen_seed(uint8_t* dest, size_t size) {\n \n extern \"C\" CDECL void *\n rand_new_seeded(uint8_t* seed, size_t seed_size) {\n-    rust_task *task = rust_get_current_task();\n-    rust_rng *rng = (rust_rng *) task->malloc(sizeof(rust_rng),\n-                                              \"rand_new_seeded\");\n-    if (!rng) {\n-        task->fail();\n-        return NULL;\n-    }\n-    char *env_seed = task->kernel->env->rust_seed;\n-    rng_init(rng, env_seed, seed, seed_size);\n+    assert(seed != NULL);\n+    rust_rng *rng = (rust_rng *) malloc(sizeof(rust_rng));\n+    assert(rng != NULL && \"rng alloc failed\");\n+    rng_init(rng, NULL, seed, seed_size);\n     return rng;\n }\n \n@@ -106,8 +100,7 @@ rand_next(rust_rng *rng) {\n \n extern \"C\" CDECL void\n rand_free(rust_rng *rng) {\n-    rust_task *task = rust_get_current_task();\n-    task->free(rng);\n+    free(rng);\n }\n \n \n@@ -594,12 +587,18 @@ rust_log_console_on() {\n     log_console_on();\n }\n \n-extern void log_console_off(rust_env *env);\n+extern void log_console_off();\n \n extern \"C\" CDECL void\n rust_log_console_off() {\n-    rust_task *task = rust_get_current_task();\n-    log_console_off(task->kernel->env);\n+    log_console_off();\n+}\n+\n+extern bool should_log_console();\n+\n+extern \"C\" CDECL uintptr_t\n+rust_should_log_console() {\n+    return (uintptr_t)should_log_console();\n }\n \n extern \"C\" CDECL void\n@@ -871,6 +870,12 @@ rust_delete_memory_region(memory_region *region) {\n     delete region;\n }\n \n+extern \"C\" CDECL boxed_region*\n+rust_current_boxed_region() {\n+    rust_task *task = rust_get_current_task();\n+    return &task->boxed;\n+}\n+\n extern \"C\" CDECL boxed_region*\n rust_new_boxed_region(memory_region *region,\n                       uintptr_t poison_on_free) {\n@@ -887,6 +892,11 @@ rust_boxed_region_malloc(boxed_region *region, type_desc *td, size_t size) {\n     return region->malloc(td, size);\n }\n \n+extern \"C\" CDECL rust_opaque_box*\n+rust_boxed_region_realloc(boxed_region *region, rust_opaque_box *ptr, size_t size) {\n+    return region->realloc(ptr, size);\n+}\n+\n extern \"C\" CDECL void\n rust_boxed_region_free(boxed_region *region, rust_opaque_box *box) {\n     region->free(box);\n@@ -919,6 +929,46 @@ rust_running_on_valgrind() {\n     return RUNNING_ON_VALGRIND;\n }\n \n+extern int get_num_cpus();\n+\n+extern \"C\" CDECL uintptr_t\n+rust_get_num_cpus() {\n+    return get_num_cpus();\n+}\n+\n+static lock_and_signal global_args_lock;\n+static uintptr_t global_args_ptr = 0;\n+\n+extern \"C\" CDECL void\n+rust_take_global_args_lock() {\n+    global_args_lock.lock();\n+}\n+\n+extern \"C\" CDECL void\n+rust_drop_global_args_lock() {\n+    global_args_lock.unlock();\n+}\n+\n+extern \"C\" CDECL uintptr_t*\n+rust_get_global_args_ptr() {\n+    return &global_args_ptr;\n+}\n+\n+static lock_and_signal exit_status_lock;\n+static uintptr_t exit_status = 0;\n+\n+extern \"C\" CDECL void\n+rust_set_exit_status_newrt(uintptr_t code) {\n+    scoped_lock with(exit_status_lock);\n+    exit_status = code;\n+}\n+\n+extern \"C\" CDECL uintptr_t\n+rust_get_exit_status_newrt() {\n+    scoped_lock with(exit_status_lock);\n+    return exit_status;\n+}\n+\n //\n // Local Variables:\n // mode: C++"}, {"sha": "ff03ea817b868cc1c2ed0e06a1143b70b98ce116", "filename": "src/rt/rust_env.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_env.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_env.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_env.cpp?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -40,15 +40,15 @@ rust_drop_env_lock() {\n }\n \n #if defined(__WIN32__)\n-static int\n+int\n get_num_cpus() {\n     SYSTEM_INFO sysinfo;\n     GetSystemInfo(&sysinfo);\n \n     return (int) sysinfo.dwNumberOfProcessors;\n }\n #elif defined(__BSD__)\n-static int\n+int\n get_num_cpus() {\n     /* swiped from http://stackoverflow.com/questions/150355/\n        programmatically-find-the-number-of-cores-on-a-machine */\n@@ -75,7 +75,7 @@ get_num_cpus() {\n     return numCPU;\n }\n #elif defined(__GNUC__)\n-static int\n+int\n get_num_cpus() {\n     return sysconf(_SC_NPROCESSORS_ONLN);\n }"}, {"sha": "e37856255a7d60a360873d326cb66360cecb20c8", "filename": "src/rt/rust_gc_metadata.cpp", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_gc_metadata.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_gc_metadata.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_gc_metadata.cpp?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -79,6 +79,11 @@ rust_gc_metadata() {\n     return (void *)global_safe_points;\n }\n \n+extern \"C\" CDECL void\n+rust_update_gc_metadata(const void* map) {\n+    update_gc_metadata(map);\n+}\n+\n //\n // Local Variables:\n // mode: C++"}, {"sha": "8179c53e96d5e6e4aac7e699785b159d88b5d2c1", "filename": "src/rt/rust_log.cpp", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_log.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_log.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_log.cpp?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -43,11 +43,15 @@ log_console_on() {\n  * overridden by the environment.\n  */\n void\n-log_console_off(rust_env *env) {\n+log_console_off() {\n     scoped_lock with(_log_lock);\n-    if (env->logspec == NULL) {\n-        _log_to_console = false;\n-    }\n+    _log_to_console = false;\n+}\n+\n+bool\n+should_log_console() {\n+    scoped_lock with(_log_lock);\n+    return _log_to_console;\n }\n \n rust_log::rust_log(rust_sched_loop *sched_loop) :"}, {"sha": "2cfd5cf1eb63c0653165323ef675fb1f0dd1c27f", "filename": "src/rt/rust_test_helpers.cpp", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_test_helpers.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_test_helpers.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_test_helpers.cpp?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -168,11 +168,11 @@ rust_dbg_extern_identity_TwoDoubles(TwoDoubles u) {\n \n // Generates increasing port numbers for network testing\n extern \"C\" CDECL uintptr_t\n-rust_dbg_next_port() {\n+rust_dbg_next_port(uintptr_t base_port) {\n   static lock_and_signal dbg_port_lock;\n-  static uintptr_t next_port = 9600;\n+  static uintptr_t next_offset = 0;\n   scoped_lock with(dbg_port_lock);\n-  uintptr_t this_port = next_port;\n-  next_port += 1;\n+  uintptr_t this_port = base_port + next_offset;\n+  next_offset += 1;\n   return this_port;\n }"}, {"sha": "242c2ef0a81adedcaf554307223f74d1b79a43ca", "filename": "src/rt/rust_util.h", "status": "modified", "additions": 0, "deletions": 10, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_util.h", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_util.h", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_util.h?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -57,16 +57,6 @@ vec_data(rust_vec *v) {\n     return reinterpret_cast<T*>(v->data);\n }\n \n-inline void reserve_vec_exact_shared(rust_task* task, rust_vec_box** vpp,\n-                                     size_t size) {\n-    rust_opaque_box** ovpp = (rust_opaque_box**)vpp;\n-    if (size > (*vpp)->body.alloc) {\n-        *vpp = (rust_vec_box*)task->boxed.realloc(\n-            *ovpp, size + sizeof(rust_vec));\n-        (*vpp)->body.alloc = size;\n-    }\n-}\n-\n inline void reserve_vec_exact(rust_vec_box** vpp,\n                               size_t size) {\n     if (size > (*vpp)->body.alloc) {"}, {"sha": "95e38a9903c4bd39913921a00949a9fd9491d3dc", "filename": "src/rt/rust_uv.cpp", "status": "modified", "additions": 136, "deletions": 0, "changes": 136, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_uv.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frust_uv.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frust_uv.cpp?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -294,6 +294,118 @@ rust_uv_tcp_getpeername6\n     return uv_tcp_getpeername(handle, (sockaddr*)name, &namelen);\n }\n \n+extern \"C\" int\n+rust_uv_tcp_getsockname\n+(uv_tcp_t* handle, sockaddr_in* name) {\n+    int namelen = sizeof(sockaddr_in);\n+    return uv_tcp_getsockname(handle, (sockaddr*)name, &namelen);\n+}\n+\n+extern \"C\" int\n+rust_uv_tcp_getsockname6\n+(uv_tcp_t* handle, sockaddr_in6* name) {\n+    int namelen = sizeof(sockaddr_in6);\n+    return uv_tcp_getsockname(handle, (sockaddr*)name, &namelen);\n+}\n+\n+extern \"C\" int\n+rust_uv_tcp_nodelay\n+(uv_tcp_t* handle, int enable) {\n+    return uv_tcp_nodelay(handle, enable);\n+}\n+\n+extern \"C\" int\n+rust_uv_tcp_keepalive\n+(uv_tcp_t* handle, int enable, unsigned int delay) {\n+    return uv_tcp_keepalive(handle, enable, delay);\n+}\n+\n+extern \"C\" int\n+rust_uv_tcp_simultaneous_accepts\n+(uv_tcp_t* handle, int enable) {\n+    return uv_tcp_simultaneous_accepts(handle, enable);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_init(uv_loop_t* loop, uv_udp_t* handle) {\n+    return uv_udp_init(loop, handle);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_bind(uv_udp_t* server, sockaddr_in* addr_ptr, unsigned flags) {\n+    return uv_udp_bind(server, *addr_ptr, flags);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_bind6(uv_udp_t* server, sockaddr_in6* addr_ptr, unsigned flags) {\n+    return uv_udp_bind6(server, *addr_ptr, flags);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_send(uv_udp_send_t* req, uv_udp_t* handle, uv_buf_t* buf_in,\n+                 int buf_cnt, sockaddr_in* addr_ptr, uv_udp_send_cb cb) {\n+    return uv_udp_send(req, handle, buf_in, buf_cnt, *addr_ptr, cb);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_send6(uv_udp_send_t* req, uv_udp_t* handle, uv_buf_t* buf_in,\n+                  int buf_cnt, sockaddr_in6* addr_ptr, uv_udp_send_cb cb) {\n+    return uv_udp_send6(req, handle, buf_in, buf_cnt, *addr_ptr, cb);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_recv_start(uv_udp_t* server, uv_alloc_cb on_alloc, uv_udp_recv_cb on_read) {\n+    return uv_udp_recv_start(server, on_alloc, on_read);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_recv_stop(uv_udp_t* server) {\n+    return uv_udp_recv_stop(server);\n+}\n+\n+extern \"C\" uv_udp_t*\n+rust_uv_get_udp_handle_from_send_req(uv_udp_send_t* send_req) {\n+    return send_req->handle;\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_getsockname\n+(uv_udp_t* handle, sockaddr_in* name) {\n+    int namelen = sizeof(sockaddr_in);\n+    return uv_udp_getsockname(handle, (sockaddr*)name, &namelen);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_getsockname6\n+(uv_udp_t* handle, sockaddr_in6* name) {\n+    int namelen = sizeof(sockaddr_in6);\n+    return uv_udp_getsockname(handle, (sockaddr*)name, &namelen);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_set_membership\n+(uv_udp_t* handle, const char* m_addr, const char* i_addr, uv_membership membership) {\n+    return uv_udp_set_membership(handle, m_addr, i_addr, membership);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_set_multicast_loop\n+(uv_udp_t* handle, int on) {\n+    return uv_udp_set_multicast_loop(handle, on);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_set_multicast_ttl\n+(uv_udp_t* handle, int ttl) {\n+    return uv_udp_set_multicast_ttl(handle, ttl);\n+}\n+\n+extern \"C\" int\n+rust_uv_udp_set_broadcast\n+(uv_udp_t* handle, int on) {\n+    return uv_udp_set_broadcast(handle, on);\n+}\n+\n extern \"C\" int\n rust_uv_listen(uv_stream_t* stream, int backlog,\n         uv_connection_cb cb) {\n@@ -546,10 +658,34 @@ extern \"C\" void\n rust_uv_freeaddrinfo(addrinfo* res) {\n     uv_freeaddrinfo(res);\n }\n+\n+extern \"C\" int\n+rust_uv_is_ipv4_sockaddr(sockaddr* addr) {\n+    return addr->sa_family == AF_INET;\n+}\n+\n+extern \"C\" int\n+rust_uv_is_ipv6_sockaddr(sockaddr* addr) {\n+    return addr->sa_family == AF_INET6;\n+}\n+\n+extern \"C\" sockaddr_in*\n+rust_uv_sockaddr_as_sockaddr_in(sockaddr* addr) {\n+//    return (sockaddr_in*)addr->sa_data;\n+    return (sockaddr_in*)addr;\n+}\n+\n+extern \"C\" sockaddr_in6*\n+rust_uv_sockaddr_as_sockaddr_in6(sockaddr* addr) {\n+    //return (sockaddr_in6*)addr->sa_data;\n+    return (sockaddr_in6*)addr;\n+}\n+\n extern \"C\" bool\n rust_uv_is_ipv4_addrinfo(addrinfo* input) {\n     return input->ai_family == AF_INET;\n }\n+\n extern \"C\" bool\n rust_uv_is_ipv6_addrinfo(addrinfo* input) {\n     return input->ai_family == AF_INET6;"}, {"sha": "ea614330866fe5358de7bcbc868153dd7c42334e", "filename": "src/rt/rustrt.def.in", "status": "modified", "additions": 34, "deletions": 1, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frustrt.def.in", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Frt%2Frustrt.def.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frt%2Frustrt.def.in?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -39,6 +39,7 @@ rust_list_dir_wfd_size\n rust_list_dir_wfd_fp_buf\n rust_log_console_on\n rust_log_console_off\n+rust_should_log_console\n rust_set_environ\n rust_unset_sigprocmask\n rust_sched_current_nonlazy_threads\n@@ -54,7 +55,7 @@ rust_get_stack_segment\n rust_get_c_stack\n rust_log_str\n start_task\n-vec_reserve_shared_actual\n+rust_local_realloc\n task_clear_event_reject\n task_wait_event\n task_signal_event\n@@ -105,6 +106,29 @@ rust_uv_tcp_connect\n rust_uv_tcp_bind\n rust_uv_tcp_connect6\n rust_uv_tcp_bind6\n+rust_uv_tcp_getsockname\n+rust_uv_tcp_getsockname6\n+rust_uv_tcp_nodelay\n+rust_uv_tcp_keepalive\n+rust_uv_tcp_simultaneous_accepts\n+rust_uv_udp_init\n+rust_uv_udp_bind\n+rust_uv_udp_bind6\n+rust_uv_udp_send\n+rust_uv_udp_send6\n+rust_uv_udp_recv_start\n+rust_uv_udp_recv_stop\n+rust_uv_get_udp_handle_from_send_req\n+rust_uv_udp_getsockname\n+rust_uv_udp_getsockname6\n+rust_uv_udp_set_membership\n+rust_uv_udp_set_multicast_loop\n+rust_uv_udp_set_multicast_ttl\n+rust_uv_udp_set_broadcast\n+rust_uv_is_ipv4_sockaddr\n+rust_uv_is_ipv6_sockaddr\n+rust_uv_sockaddr_as_sockaddr_in\n+rust_uv_sockaddr_as_sockaddr_in6\n rust_uv_listen\n rust_uv_accept\n rust_uv_write\n@@ -178,6 +202,7 @@ rust_task_deref\n tdefl_compress_mem_to_heap\n tinfl_decompress_mem_to_heap\n rust_gc_metadata\n+rust_update_gc_metadata\n rust_uv_ip4_port\n rust_uv_ip6_port\n rust_uv_tcp_getpeername\n@@ -228,6 +253,7 @@ rust_delete_memory_region\n rust_new_boxed_region\n rust_delete_boxed_region\n rust_boxed_region_malloc\n+rust_boxed_region_realloc\n rust_boxed_region_free\n rust_try\n rust_begin_unwind\n@@ -239,3 +265,10 @@ rust_take_env_lock\n rust_drop_env_lock\n rust_update_log_settings\n rust_running_on_valgrind\n+rust_get_num_cpus\n+rust_get_global_args_ptr\n+rust_current_boxed_region\n+rust_take_global_args_lock\n+rust_drop_global_args_lock\n+rust_set_exit_status_newrt\n+rust_get_exit_status_newrt\n\\ No newline at end of file"}, {"sha": "a46b7a3dfcff649906877fe1f2a306709577651e", "filename": "src/test/run-pass/morestack6.rs", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Ftest%2Frun-pass%2Fmorestack6.rs", "raw_url": "https://github.com/rust-lang/rust/raw/41dcec2fe16e272016ae77d10a6a5ff3a737f192/src%2Ftest%2Frun-pass%2Fmorestack6.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fmorestack6.rs?ref=41dcec2fe16e272016ae77d10a6a5ff3a737f192", "patch": "@@ -23,15 +23,13 @@ mod rustrt {\n         pub fn rust_get_sched_id() -> libc::intptr_t;\n         pub fn rust_get_argc() -> libc::c_int;\n         pub fn get_task_id() -> libc::intptr_t;\n-        pub fn rust_sched_threads();\n         pub fn rust_get_task();\n     }\n }\n \n fn calllink01() { unsafe { rustrt::rust_get_sched_id(); } }\n fn calllink02() { unsafe { rustrt::rust_get_argc(); } }\n fn calllink08() { unsafe { rustrt::get_task_id(); } }\n-fn calllink09() { unsafe { rustrt::rust_sched_threads(); } }\n fn calllink10() { unsafe { rustrt::rust_get_task(); } }\n \n fn runtest(f: extern fn(), frame_backoff: u32) {\n@@ -64,7 +62,6 @@ pub fn main() {\n         calllink01,\n         calllink02,\n         calllink08,\n-        calllink09,\n         calllink10\n     ];\n     let mut rng = rand::rng();"}]}