{"sha": "75660ff94fd54a921d411a75789a994111184257", "node_id": "C_kwDOAAsO6NoAKDc1NjYwZmY5NGZkNTRhOTIxZDQxMWE3NTc4OWE5OTQxMTExODQyNTc", "commit": {"author": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2021-09-27T16:44:40Z"}, "committer": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2021-09-27T16:44:40Z"}, "message": "Cleanup descend_into_macros_impl", "tree": {"sha": "88d0cf42d484ba1c8a4c8469038be4e5b5cc1c6f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/88d0cf42d484ba1c8a4c8469038be4e5b5cc1c6f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/75660ff94fd54a921d411a75789a994111184257", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/75660ff94fd54a921d411a75789a994111184257", "html_url": "https://github.com/rust-lang/rust/commit/75660ff94fd54a921d411a75789a994111184257", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/75660ff94fd54a921d411a75789a994111184257/comments", "author": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c4251319fd3acf7b7781275ec77b53cc0efe6140", "url": "https://api.github.com/repos/rust-lang/rust/commits/c4251319fd3acf7b7781275ec77b53cc0efe6140", "html_url": "https://github.com/rust-lang/rust/commit/c4251319fd3acf7b7781275ec77b53cc0efe6140"}], "stats": {"total": 79, "additions": 43, "deletions": 36}, "files": [{"sha": "38c24d53db5fa3067f004bd4c5da079f1357bb24", "filename": "crates/hir/src/semantics.rs", "status": "modified", "additions": 43, "deletions": 36, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/75660ff94fd54a921d411a75789a994111184257/crates%2Fhir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/75660ff94fd54a921d411a75789a994111184257/crates%2Fhir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir%2Fsrc%2Fsemantics.rs?ref=75660ff94fd54a921d411a75789a994111184257", "patch": "@@ -544,38 +544,54 @@ impl<'db> SemanticsImpl<'db> {\n         let sa = self.analyze(&parent);\n         let mut queue = vec![InFile::new(sa.file_id, token)];\n         let mut cache = self.expansion_info_cache.borrow_mut();\n+\n+        let mut process_expansion_for_token =\n+            |queue: &mut Vec<_>, file_id, item, token: InFile<&_>| {\n+                let mapped_tokens = cache\n+                    .entry(file_id)\n+                    .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n+                    .as_ref()?\n+                    .map_token_down(self.db.upcast(), item, token)?;\n+\n+                let len = queue.len();\n+                // requeue the tokens we got from mapping our current token down\n+                queue.extend(mapped_tokens.inspect(|token| {\n+                    if let Some(parent) = token.value.parent() {\n+                        self.cache(find_root(&parent), token.file_id);\n+                    }\n+                }));\n+                // if the length changed we have found a mapping for the token\n+                (queue.len() != len).then(|| ())\n+            };\n+\n         // Remap the next token in the queue into a macro call its in, if it is not being remapped\n         // either due to not being in a macro-call or because its unused push it into the result vec,\n         // otherwise push the remapped tokens back into the queue as they can potentially be remapped again.\n         while let Some(token) = queue.pop() {\n             self.db.unwind_if_cancelled();\n             let was_not_remapped = (|| {\n-                if let Some((call_id, item)) = token\n-                    .value\n-                    .ancestors()\n-                    .filter_map(ast::Item::cast)\n-                    .filter_map(|item| {\n-                        self.with_ctx(|ctx| ctx.item_to_macro_call(token.with_value(item.clone())))\n-                            .zip(Some(item))\n-                    })\n-                    .last()\n-                {\n+                // are we inside an attribute macro call\n+                let containing_attribute_macro_call = self.with_ctx(|ctx| {\n+                    token\n+                        .value\n+                        .ancestors()\n+                        .filter_map(ast::Item::cast)\n+                        .filter_map(|item| {\n+                            Some((ctx.item_to_macro_call(token.with_value(item.clone()))?, item))\n+                        })\n+                        .last()\n+                });\n+                if let Some((call_id, item)) = containing_attribute_macro_call {\n                     let file_id = call_id.as_file();\n-                    let tokens = cache\n-                        .entry(file_id)\n-                        .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                        .as_ref()?\n-                        .map_token_down(self.db.upcast(), Some(item), token.as_ref())?;\n-\n-                    let len = queue.len();\n-                    queue.extend(tokens.inspect(|token| {\n-                        if let Some(parent) = token.value.parent() {\n-                            self.cache(find_root(&parent), token.file_id);\n-                        }\n-                    }));\n-                    return (queue.len() != len).then(|| ());\n+                    return process_expansion_for_token(\n+                        &mut queue,\n+                        file_id,\n+                        Some(item),\n+                        token.as_ref(),\n+                    );\n                 }\n \n+                // or are we inside a function-like macro call\n                 if let Some(macro_call) = token.value.ancestors().find_map(ast::MacroCall::cast) {\n                     let tt = macro_call.token_tree()?;\n                     let l_delim = match tt.left_delimiter_token() {\n@@ -589,21 +605,12 @@ impl<'db> SemanticsImpl<'db> {\n                     if !TextRange::new(l_delim, r_delim).contains_range(token.value.text_range()) {\n                         return None;\n                     }\n+\n                     let file_id = sa.expand(self.db, token.with_value(&macro_call))?;\n-                    let tokens = cache\n-                        .entry(file_id)\n-                        .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                        .as_ref()?\n-                        .map_token_down(self.db.upcast(), None, token.as_ref())?;\n-\n-                    let len = queue.len();\n-                    queue.extend(tokens.inspect(|token| {\n-                        if let Some(parent) = token.value.parent() {\n-                            self.cache(find_root(&parent), token.file_id);\n-                        }\n-                    }));\n-                    return (queue.len() != len).then(|| ());\n+                    return process_expansion_for_token(&mut queue, file_id, None, token.as_ref());\n                 }\n+\n+                // outside of a macro invocation so this is a \"final\" token\n                 None\n             })()\n             .is_none();"}]}