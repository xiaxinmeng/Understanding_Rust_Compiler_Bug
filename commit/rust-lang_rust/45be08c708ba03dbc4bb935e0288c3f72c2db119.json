{"sha": "45be08c708ba03dbc4bb935e0288c3f72c2db119", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQ1YmUwOGM3MDhiYTAzZGJjNGJiOTM1ZTAyODhjM2Y3MmMyZGIxMTk=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2020-07-11T10:34:14Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-07-11T10:34:14Z"}, "message": "Merge #5310\n\n5310: Reduce visibility r=matklad a=matklad\n\n\n\nbors r+\n\ud83e\udd16\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>", "tree": {"sha": "52252c8467225c2dd453976f28eb0365b17e167a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/52252c8467225c2dd453976f28eb0365b17e167a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/45be08c708ba03dbc4bb935e0288c3f72c2db119", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJfCZWmCRBK7hj4Ov3rIwAAdHIIAJOYNZ+bLskP2Vb46gTJWvob\nIEY7vHfP/5uAB/Vz5gScD2Mp2jKXhe1wBeotK5AtVL37pVvyt45uDVTwrO7ypI1O\njZYB+wyVsvjns2nitSURmL3im/avfJaOIt0o2yEU+jYfO9IYX9JJCoFvMy91E8il\njCGlXcD+tiE767KddGSKAqPGCNTNEnZSNLDiwRJM6u07X7K6Ort/W2Xnotg+Q0sM\nJKNiZXg2opBkRE+jMUP7Fse5/VSOPETks9k1m6HMQ3THjMhhQXX4rNm4a6fpSJNx\nmPI1aoVakSCOH6Ol258Wy/VC/ov4KKojspz6I52yK8rG9yRjVOo/H+vh2JS4A/U=\n=OB9Z\n-----END PGP SIGNATURE-----\n", "payload": "tree 52252c8467225c2dd453976f28eb0365b17e167a\nparent 33ebfa8dcc66f3b3be7da48be48257802f251088\nparent 3fc4916b53894c63320e31855e3c62b974dfcc95\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1594463654 +0000\ncommitter GitHub <noreply@github.com> 1594463654 +0000\n\nMerge #5310\n\n5310: Reduce visibility r=matklad a=matklad\n\n\n\nbors r+\n\ud83e\udd16\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/45be08c708ba03dbc4bb935e0288c3f72c2db119", "html_url": "https://github.com/rust-lang/rust/commit/45be08c708ba03dbc4bb935e0288c3f72c2db119", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/45be08c708ba03dbc4bb935e0288c3f72c2db119/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "33ebfa8dcc66f3b3be7da48be48257802f251088", "url": "https://api.github.com/repos/rust-lang/rust/commits/33ebfa8dcc66f3b3be7da48be48257802f251088", "html_url": "https://github.com/rust-lang/rust/commit/33ebfa8dcc66f3b3be7da48be48257802f251088"}, {"sha": "3fc4916b53894c63320e31855e3c62b974dfcc95", "url": "https://api.github.com/repos/rust-lang/rust/commits/3fc4916b53894c63320e31855e3c62b974dfcc95", "html_url": "https://github.com/rust-lang/rust/commit/3fc4916b53894c63320e31855e3c62b974dfcc95"}], "stats": {"total": 62, "additions": 31, "deletions": 31}, "files": [{"sha": "97125b32a3a63d74b99e444757ef0c4cfeed68ce", "filename": "crates/ra_hir/src/semantics.rs", "status": "modified", "additions": 31, "deletions": 31, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/45be08c708ba03dbc4bb935e0288c3f72c2db119/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/45be08c708ba03dbc4bb935e0288c3f72c2db119/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsemantics.rs?ref=45be08c708ba03dbc4bb935e0288c3f72c2db119", "patch": "@@ -270,17 +270,17 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n }\n \n impl<'db> SemanticsImpl<'db> {\n-    pub fn new(db: &'db dyn HirDatabase) -> Self {\n+    fn new(db: &'db dyn HirDatabase) -> Self {\n         Self { db, s2d_cache: Default::default(), cache: Default::default() }\n     }\n \n-    pub fn parse(&self, file_id: FileId) -> ast::SourceFile {\n+    fn parse(&self, file_id: FileId) -> ast::SourceFile {\n         let tree = self.db.parse(file_id).tree();\n         self.cache(tree.syntax().clone(), file_id.into());\n         tree\n     }\n \n-    pub fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n+    fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n         let macro_call = self.find_file(macro_call.syntax().clone()).with_value(macro_call);\n         let sa = self.analyze2(macro_call.map(|it| it.syntax()), None);\n         let file_id = sa.expand(self.db, macro_call)?;\n@@ -289,7 +289,7 @@ impl<'db> SemanticsImpl<'db> {\n         Some(node)\n     }\n \n-    pub fn expand_hypothetical(\n+    fn expand_hypothetical(\n         &self,\n         actual_macro_call: &ast::MacroCall,\n         hypothetical_args: &ast::TokenTree,\n@@ -310,7 +310,7 @@ impl<'db> SemanticsImpl<'db> {\n         )\n     }\n \n-    pub fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n+    fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n         let parent = token.parent();\n         let parent = self.find_file(parent);\n         let sa = self.analyze2(parent.as_ref(), None);\n@@ -334,7 +334,7 @@ impl<'db> SemanticsImpl<'db> {\n         token.value\n     }\n \n-    pub fn descend_node_at_offset(\n+    fn descend_node_at_offset(\n         &self,\n         node: &SyntaxNode,\n         offset: TextSize,\n@@ -346,24 +346,24 @@ impl<'db> SemanticsImpl<'db> {\n             .flatten()\n     }\n \n-    pub fn original_range(&self, node: &SyntaxNode) -> FileRange {\n+    fn original_range(&self, node: &SyntaxNode) -> FileRange {\n         let node = self.find_file(node.clone());\n         original_range(self.db, node.as_ref())\n     }\n \n-    pub fn diagnostics_range(&self, diagnostics: &dyn Diagnostic) -> FileRange {\n+    fn diagnostics_range(&self, diagnostics: &dyn Diagnostic) -> FileRange {\n         let src = diagnostics.source();\n         let root = self.db.parse_or_expand(src.file_id).unwrap();\n         let node = src.value.to_node(&root);\n         original_range(self.db, src.with_value(&node))\n     }\n \n-    pub fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n+    fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n         let node = self.find_file(node);\n         node.ancestors_with_macros(self.db.upcast()).map(|it| it.value)\n     }\n \n-    pub fn ancestors_at_offset_with_macros(\n+    fn ancestors_at_offset_with_macros(\n         &self,\n         node: &SyntaxNode,\n         offset: TextSize,\n@@ -373,64 +373,64 @@ impl<'db> SemanticsImpl<'db> {\n             .kmerge_by(|node1, node2| node1.text_range().len() < node2.text_range().len())\n     }\n \n-    pub fn type_of_expr(&self, expr: &ast::Expr) -> Option<Type> {\n+    fn type_of_expr(&self, expr: &ast::Expr) -> Option<Type> {\n         self.analyze(expr.syntax()).type_of_expr(self.db, &expr)\n     }\n \n-    pub fn type_of_pat(&self, pat: &ast::Pat) -> Option<Type> {\n+    fn type_of_pat(&self, pat: &ast::Pat) -> Option<Type> {\n         self.analyze(pat.syntax()).type_of_pat(self.db, &pat)\n     }\n \n-    pub fn type_of_self(&self, param: &ast::SelfParam) -> Option<Type> {\n+    fn type_of_self(&self, param: &ast::SelfParam) -> Option<Type> {\n         self.analyze(param.syntax()).type_of_self(self.db, &param)\n     }\n \n-    pub fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n+    fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n         self.analyze(call.syntax()).resolve_method_call(self.db, call)\n     }\n \n-    pub fn resolve_field(&self, field: &ast::FieldExpr) -> Option<Field> {\n+    fn resolve_field(&self, field: &ast::FieldExpr) -> Option<Field> {\n         self.analyze(field.syntax()).resolve_field(self.db, field)\n     }\n \n-    pub fn resolve_record_field(&self, field: &ast::RecordField) -> Option<(Field, Option<Local>)> {\n+    fn resolve_record_field(&self, field: &ast::RecordField) -> Option<(Field, Option<Local>)> {\n         self.analyze(field.syntax()).resolve_record_field(self.db, field)\n     }\n \n-    pub fn resolve_record_field_pat(&self, field: &ast::RecordFieldPat) -> Option<Field> {\n+    fn resolve_record_field_pat(&self, field: &ast::RecordFieldPat) -> Option<Field> {\n         self.analyze(field.syntax()).resolve_record_field_pat(self.db, field)\n     }\n \n-    pub fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<MacroDef> {\n+    fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<MacroDef> {\n         let sa = self.analyze(macro_call.syntax());\n         let macro_call = self.find_file(macro_call.syntax().clone()).with_value(macro_call);\n         sa.resolve_macro_call(self.db, macro_call)\n     }\n \n-    pub fn resolve_path(&self, path: &ast::Path) -> Option<PathResolution> {\n+    fn resolve_path(&self, path: &ast::Path) -> Option<PathResolution> {\n         self.analyze(path.syntax()).resolve_path(self.db, path)\n     }\n \n-    pub fn resolve_variant(&self, record_lit: ast::RecordLit) -> Option<VariantId> {\n+    fn resolve_variant(&self, record_lit: ast::RecordLit) -> Option<VariantId> {\n         self.analyze(record_lit.syntax()).resolve_variant(self.db, record_lit)\n     }\n \n-    pub fn lower_path(&self, path: &ast::Path) -> Option<Path> {\n+    fn lower_path(&self, path: &ast::Path) -> Option<Path> {\n         let src = self.find_file(path.syntax().clone());\n         Path::from_src(path.clone(), &Hygiene::new(self.db.upcast(), src.file_id.into()))\n     }\n \n-    pub fn resolve_bind_pat_to_const(&self, pat: &ast::BindPat) -> Option<ModuleDef> {\n+    fn resolve_bind_pat_to_const(&self, pat: &ast::BindPat) -> Option<ModuleDef> {\n         self.analyze(pat.syntax()).resolve_bind_pat_to_const(self.db, pat)\n     }\n \n-    pub fn record_literal_missing_fields(&self, literal: &ast::RecordLit) -> Vec<(Field, Type)> {\n+    fn record_literal_missing_fields(&self, literal: &ast::RecordLit) -> Vec<(Field, Type)> {\n         self.analyze(literal.syntax())\n             .record_literal_missing_fields(self.db, literal)\n             .unwrap_or_default()\n     }\n \n-    pub fn record_pattern_missing_fields(&self, pattern: &ast::RecordPat) -> Vec<(Field, Type)> {\n+    fn record_pattern_missing_fields(&self, pattern: &ast::RecordPat) -> Vec<(Field, Type)> {\n         self.analyze(pattern.syntax())\n             .record_pattern_missing_fields(self.db, pattern)\n             .unwrap_or_default()\n@@ -442,23 +442,23 @@ impl<'db> SemanticsImpl<'db> {\n         f(&mut ctx)\n     }\n \n-    pub fn to_module_def(&self, file: FileId) -> Option<Module> {\n+    fn to_module_def(&self, file: FileId) -> Option<Module> {\n         self.with_ctx(|ctx| ctx.file_to_def(file)).map(Module::from)\n     }\n \n-    pub fn scope(&self, node: &SyntaxNode) -> SemanticsScope<'db> {\n+    fn scope(&self, node: &SyntaxNode) -> SemanticsScope<'db> {\n         let node = self.find_file(node.clone());\n         let resolver = self.analyze2(node.as_ref(), None).resolver;\n         SemanticsScope { db: self.db, resolver }\n     }\n \n-    pub fn scope_at_offset(&self, node: &SyntaxNode, offset: TextSize) -> SemanticsScope<'db> {\n+    fn scope_at_offset(&self, node: &SyntaxNode, offset: TextSize) -> SemanticsScope<'db> {\n         let node = self.find_file(node.clone());\n         let resolver = self.analyze2(node.as_ref(), Some(offset)).resolver;\n         SemanticsScope { db: self.db, resolver }\n     }\n \n-    pub fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db> {\n+    fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db> {\n         let resolver = def.id.resolver(self.db.upcast());\n         SemanticsScope { db: self.db, resolver }\n     }\n@@ -490,14 +490,14 @@ impl<'db> SemanticsImpl<'db> {\n         SourceAnalyzer::new_for_resolver(resolver, src)\n     }\n \n-    pub fn cache(&self, root_node: SyntaxNode, file_id: HirFileId) {\n+    fn cache(&self, root_node: SyntaxNode, file_id: HirFileId) {\n         assert!(root_node.parent().is_none());\n         let mut cache = self.cache.borrow_mut();\n         let prev = cache.insert(root_node, file_id);\n         assert!(prev == None || prev == Some(file_id))\n     }\n \n-    pub fn assert_contains_node(&self, node: &SyntaxNode) {\n+    fn assert_contains_node(&self, node: &SyntaxNode) {\n         self.find_file(node.clone());\n     }\n \n@@ -506,7 +506,7 @@ impl<'db> SemanticsImpl<'db> {\n         cache.get(root_node).copied()\n     }\n \n-    pub fn find_file(&self, node: SyntaxNode) -> InFile<SyntaxNode> {\n+    fn find_file(&self, node: SyntaxNode) -> InFile<SyntaxNode> {\n         let root_node = find_root(&node);\n         let file_id = self.lookup(&root_node).unwrap_or_else(|| {\n             panic!("}]}