{"sha": "3bbcafe3b59ee5c4537f65e820835c526531fe59", "node_id": "C_kwDOAAsO6NoAKDNiYmNhZmUzYjU5ZWU1YzQ1MzdmNjVlODIwODM1YzUyNjUzMWZlNTk", "commit": {"author": {"name": "Ben Kimock", "email": "kimockb@gmail.com", "date": "2021-12-08T03:05:13Z"}, "committer": {"name": "Ben Kimock", "email": "kimockb@gmail.com", "date": "2022-07-01T21:51:16Z"}, "message": "Cache lookups into the borrow stack\n\nThis adds a very simple LRU-like cache which stores the locations of\noften-used tags. While the implementation is very simple, the cache hit\nrate is incredible at ~99.9% on most programs, and often the element at\nposition 0 in the cache has a hit rate of 90%. So the sub-optimality of\nthis cache basicaly vanishes into the noise in a profile.\n\nAdditionally, we keep a range which denotes where there might be an item\ngranting Unique permission in the stack, so that when we invalidate\nUniques we do not need to scan much of the stack, and often scan nothing\nat all.", "tree": {"sha": "904c242f362ebd895aa9627eb31b51f8beff8361", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/904c242f362ebd895aa9627eb31b51f8beff8361"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3bbcafe3b59ee5c4537f65e820835c526531fe59", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3bbcafe3b59ee5c4537f65e820835c526531fe59", "html_url": "https://github.com/rust-lang/rust/commit/3bbcafe3b59ee5c4537f65e820835c526531fe59", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3bbcafe3b59ee5c4537f65e820835c526531fe59/comments", "author": {"login": "saethlin", "id": 12105168, "node_id": "MDQ6VXNlcjEyMTA1MTY4", "avatar_url": "https://avatars.githubusercontent.com/u/12105168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saethlin", "html_url": "https://github.com/saethlin", "followers_url": "https://api.github.com/users/saethlin/followers", "following_url": "https://api.github.com/users/saethlin/following{/other_user}", "gists_url": "https://api.github.com/users/saethlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/saethlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saethlin/subscriptions", "organizations_url": "https://api.github.com/users/saethlin/orgs", "repos_url": "https://api.github.com/users/saethlin/repos", "events_url": "https://api.github.com/users/saethlin/events{/privacy}", "received_events_url": "https://api.github.com/users/saethlin/received_events", "type": "User", "site_admin": false}, "committer": {"login": "saethlin", "id": 12105168, "node_id": "MDQ6VXNlcjEyMTA1MTY4", "avatar_url": "https://avatars.githubusercontent.com/u/12105168?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saethlin", "html_url": "https://github.com/saethlin", "followers_url": "https://api.github.com/users/saethlin/followers", "following_url": "https://api.github.com/users/saethlin/following{/other_user}", "gists_url": "https://api.github.com/users/saethlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/saethlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saethlin/subscriptions", "organizations_url": "https://api.github.com/users/saethlin/orgs", "repos_url": "https://api.github.com/users/saethlin/repos", "events_url": "https://api.github.com/users/saethlin/events{/privacy}", "received_events_url": "https://api.github.com/users/saethlin/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "70b97a5d7b9931a731d12f427855b9090620bf69", "url": "https://api.github.com/repos/rust-lang/rust/commits/70b97a5d7b9931a731d12f427855b9090620bf69", "html_url": "https://github.com/rust-lang/rust/commit/70b97a5d7b9931a731d12f427855b9090620bf69"}], "stats": {"total": 506, "additions": 398, "deletions": 108}, "files": [{"sha": "0dead9fa28f70263fa044024fcc91151301fe4f3", "filename": "Cargo.toml", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/3bbcafe3b59ee5c4537f65e820835c526531fe59/Cargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/3bbcafe3b59ee5c4537f65e820835c526531fe59/Cargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.toml?ref=3bbcafe3b59ee5c4537f65e820835c526531fe59", "patch": "@@ -50,3 +50,8 @@ rustc_private = true\n [[test]]\n name = \"compiletest\"\n harness = false\n+\n+[features]\n+default = [\"stack-cache\"]\n+expensive-debug-assertions = []\n+stack-cache = []"}, {"sha": "a98239711ef42cdb9b9ec74138adbecb2da43804", "filename": "src/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3bbcafe3b59ee5c4537f65e820835c526531fe59/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3bbcafe3b59ee5c4537f65e820835c526531fe59/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=3bbcafe3b59ee5c4537f65e820835c526531fe59", "patch": "@@ -90,8 +90,8 @@ pub use crate::mono_hash_map::MonoHashMap;\n pub use crate::operator::EvalContextExt as OperatorEvalContextExt;\n pub use crate::range_map::RangeMap;\n pub use crate::stacked_borrows::{\n-    CallId, EvalContextExt as StackedBorEvalContextExt, Item, Permission, SbTag, SbTagExtra, Stack,\n-    Stacks,\n+    stack::Stack, CallId, EvalContextExt as StackedBorEvalContextExt, Item, Permission, PtrId,\n+    SbTag, SbTagExtra, Stacks,\n };\n pub use crate::sync::{CondvarId, EvalContextExt as SyncEvalContextExt, MutexId, RwLockId};\n pub use crate::thread::{"}, {"sha": "3a4b4ad65fa1a6f0a98f4493cce6b4fb80e649ac", "filename": "src/stacked_borrows.rs", "status": "modified", "additions": 34, "deletions": 105, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/3bbcafe3b59ee5c4537f65e820835c526531fe59/src%2Fstacked_borrows.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3bbcafe3b59ee5c4537f65e820835c526531fe59/src%2Fstacked_borrows.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fstacked_borrows.rs?ref=3bbcafe3b59ee5c4537f65e820835c526531fe59", "patch": "@@ -23,6 +23,10 @@ use crate::*;\n pub mod diagnostics;\n use diagnostics::{AllocHistory, TagHistory};\n \n+pub mod stack;\n+use stack::Stack;\n+\n+pub type PtrId = NonZeroU64;\n pub type CallId = NonZeroU64;\n \n // Even reading memory can have effects on the stack, so we need a `RefCell` here.\n@@ -111,23 +115,6 @@ impl fmt::Debug for Item {\n     }\n }\n \n-/// Extra per-location state.\n-#[derive(Clone, Debug, PartialEq, Eq)]\n-pub struct Stack {\n-    /// Used *mostly* as a stack; never empty.\n-    /// Invariants:\n-    /// * Above a `SharedReadOnly` there can only be more `SharedReadOnly`.\n-    /// * No tag occurs in the stack more than once.\n-    borrows: Vec<Item>,\n-    /// If this is `Some(id)`, then the actual current stack is unknown. This can happen when\n-    /// wildcard pointers are used to access this location. What we do know is that `borrows` are at\n-    /// the top of the stack, and below it are arbitrarily many items whose `tag` is strictly less\n-    /// than `id`.\n-    /// When the bottom is unknown, `borrows` always has a `SharedReadOnly` or `Unique` at the bottom;\n-    /// we never have the unknown-to-known boundary in an SRW group.\n-    unknown_bottom: Option<SbTag>,\n-}\n-\n /// Extra per-allocation state.\n #[derive(Clone, Debug)]\n pub struct Stacks {\n@@ -297,65 +284,10 @@ impl Permission {\n \n /// Core per-location operations: access, dealloc, reborrow.\n impl<'tcx> Stack {\n-    /// Find the item granting the given kind of access to the given tag, and return where\n-    /// it is on the stack. For wildcard tags, the given index is approximate, but if *no*\n-    /// index is given it means the match was *not* in the known part of the stack.\n-    /// `Ok(None)` indicates it matched the \"unknown\" part of the stack.\n-    /// `Err` indicates it was not found.\n-    fn find_granting(\n-        &self,\n-        access: AccessKind,\n-        tag: SbTagExtra,\n-        exposed_tags: &FxHashSet<SbTag>,\n-    ) -> Result<Option<usize>, ()> {\n-        let SbTagExtra::Concrete(tag) = tag else {\n-            // Handle the wildcard case.\n-            // Go search the stack for an exposed tag.\n-            if let Some(idx) =\n-                self.borrows\n-                    .iter()\n-                    .enumerate() // we also need to know *where* in the stack\n-                    .rev() // search top-to-bottom\n-                    .find_map(|(idx, item)| {\n-                        // If the item fits and *might* be this wildcard, use it.\n-                        if item.perm.grants(access) && exposed_tags.contains(&item.tag) {\n-                            Some(idx)\n-                        } else {\n-                            None\n-                        }\n-                    })\n-            {\n-                return Ok(Some(idx));\n-            }\n-            // If we couldn't find it in the stack, check the unknown bottom.\n-            return if self.unknown_bottom.is_some() { Ok(None) } else { Err(()) };\n-        };\n-\n-        if let Some(idx) =\n-            self.borrows\n-                .iter()\n-                .enumerate() // we also need to know *where* in the stack\n-                .rev() // search top-to-bottom\n-                // Return permission of first item that grants access.\n-                // We require a permission with the right tag, ensuring U3 and F3.\n-                .find_map(|(idx, item)| {\n-                    if tag == item.tag && item.perm.grants(access) { Some(idx) } else { None }\n-                })\n-        {\n-            return Ok(Some(idx));\n-        }\n-\n-        // Couldn't find it in the stack; but if there is an unknown bottom it might be there.\n-        let found = self.unknown_bottom.is_some_and(|&unknown_limit| {\n-            tag.0 < unknown_limit.0 // unknown_limit is an upper bound for what can be in the unknown bottom.\n-        });\n-        if found { Ok(None) } else { Err(()) }\n-    }\n-\n     /// Find the first write-incompatible item above the given one --\n     /// i.e, find the height to which the stack will be truncated when writing to `granting`.\n     fn find_first_write_incompatible(&self, granting: usize) -> usize {\n-        let perm = self.borrows[granting].perm;\n+        let perm = self.get(granting).unwrap().perm;\n         match perm {\n             Permission::SharedReadOnly => bug!(\"Cannot use SharedReadOnly for writing\"),\n             Permission::Disabled => bug!(\"Cannot use Disabled for anything\"),\n@@ -366,7 +298,7 @@ impl<'tcx> Stack {\n             Permission::SharedReadWrite => {\n                 // The SharedReadWrite *just* above us are compatible, to skip those.\n                 let mut idx = granting + 1;\n-                while let Some(item) = self.borrows.get(idx) {\n+                while let Some(item) = self.get(idx) {\n                     if item.perm == Permission::SharedReadWrite {\n                         // Go on.\n                         idx += 1;\n@@ -461,16 +393,16 @@ impl<'tcx> Stack {\n                 // There is a SRW group boundary between the unknown and the known, so everything is incompatible.\n                 0\n             };\n-            for item in self.borrows.drain(first_incompatible_idx..).rev() {\n-                trace!(\"access: popping item {:?}\", item);\n+            self.pop_items_after(first_incompatible_idx, |item| {\n                 Stack::item_popped(\n                     &item,\n                     Some((tag, alloc_range, offset, access)),\n                     global,\n                     alloc_history,\n                 )?;\n                 alloc_history.log_invalidation(item.tag, alloc_range, current_span);\n-            }\n+                Ok(())\n+            })?;\n         } else {\n             // On a read, *disable* all `Unique` above the granting item.  This ensures U2 for read accesses.\n             // The reason this is not following the stack discipline (by removing the first Unique and\n@@ -487,44 +419,39 @@ impl<'tcx> Stack {\n                 // We are reading from something in the unknown part. That means *all* `Unique` we know about are dead now.\n                 0\n             };\n-            for idx in (first_incompatible_idx..self.borrows.len()).rev() {\n-                let item = &mut self.borrows[idx];\n-\n-                if item.perm == Permission::Unique {\n-                    trace!(\"access: disabling item {:?}\", item);\n-                    Stack::item_popped(\n-                        item,\n-                        Some((tag, alloc_range, offset, access)),\n-                        global,\n-                        alloc_history,\n-                    )?;\n-                    item.perm = Permission::Disabled;\n-                    alloc_history.log_invalidation(item.tag, alloc_range, current_span);\n-                }\n-            }\n+            self.disable_uniques_starting_at(first_incompatible_idx, |item| {\n+                Stack::item_popped(\n+                    &item,\n+                    Some((tag, alloc_range, offset, access)),\n+                    global,\n+                    alloc_history,\n+                )?;\n+                alloc_history.log_invalidation(item.tag, alloc_range, current_span);\n+                Ok(())\n+            })?;\n         }\n \n         // If this was an approximate action, we now collapse everything into an unknown.\n         if granting_idx.is_none() || matches!(tag, SbTagExtra::Wildcard) {\n             // Compute the upper bound of the items that remain.\n             // (This is why we did all the work above: to reduce the items we have to consider here.)\n             let mut max = NonZeroU64::new(1).unwrap();\n-            for item in &self.borrows {\n+            for i in 0..self.len() {\n+                let item = self.get(i).unwrap();\n                 // Skip disabled items, they cannot be matched anyway.\n                 if !matches!(item.perm, Permission::Disabled) {\n                     // We are looking for a strict upper bound, so add 1 to this tag.\n                     max = cmp::max(item.tag.0.checked_add(1).unwrap(), max);\n                 }\n             }\n-            if let Some(unk) = self.unknown_bottom {\n+            if let Some(unk) = self.unknown_bottom() {\n                 max = cmp::max(unk.0, max);\n             }\n             // Use `max` as new strict upper bound for everything.\n             trace!(\n                 \"access: forgetting stack to upper bound {max} due to wildcard or unknown access\"\n             );\n-            self.borrows.clear();\n-            self.unknown_bottom = Some(SbTag(max));\n+            self.set_unknown_bottom(SbTag(max));\n         }\n \n         // Done.\n@@ -553,7 +480,8 @@ impl<'tcx> Stack {\n         })?;\n \n         // Step 2: Remove all items.  Also checks for protectors.\n-        for item in self.borrows.drain(..).rev() {\n+        for idx in (0..self.len()).rev() {\n+            let item = self.get(idx).unwrap();\n             Stack::item_popped(&item, None, global, alloc_history)?;\n         }\n         Ok(())\n@@ -601,8 +529,7 @@ impl<'tcx> Stack {\n                 // The new thing is SRW anyway, so we cannot push it \"on top of the unkown part\"\n                 // (for all we know, it might join an SRW group inside the unknown).\n                 trace!(\"reborrow: forgetting stack entirely due to SharedReadWrite reborrow from wildcard or unknown\");\n-                self.borrows.clear();\n-                self.unknown_bottom = Some(global.next_ptr_tag);\n+                self.set_unknown_bottom(global.next_ptr_tag);\n                 return Ok(());\n             };\n \n@@ -629,19 +556,18 @@ impl<'tcx> Stack {\n             // on top of `derived_from`, and we want the new item at the top so that we\n             // get the strongest possible guarantees.\n             // This ensures U1 and F1.\n-            self.borrows.len()\n+            self.len()\n         };\n \n         // Put the new item there. As an optimization, deduplicate if it is equal to one of its new neighbors.\n         // `new_idx` might be 0 if we just cleared the entire stack.\n-        if self.borrows.get(new_idx) == Some(&new)\n-            || (new_idx > 0 && self.borrows[new_idx - 1] == new)\n+        if self.get(new_idx) == Some(new) || (new_idx > 0 && self.get(new_idx - 1).unwrap() == new)\n         {\n             // Optimization applies, done.\n             trace!(\"reborrow: avoiding adding redundant item {:?}\", new);\n         } else {\n             trace!(\"reborrow: adding item {:?}\", new);\n-            self.borrows.insert(new_idx, new);\n+            self.insert(new_idx, new);\n         }\n         Ok(())\n     }\n@@ -653,8 +579,8 @@ impl<'tcx> Stacks {\n     /// Creates new stack with initial tag.\n     fn new(size: Size, perm: Permission, tag: SbTag) -> Self {\n         let item = Item { perm, tag, protector: None };\n-        let stack = Stack { borrows: vec![item], unknown_bottom: None };\n \n+        let stack = Stack::new(item);\n         Stacks {\n             stacks: RangeMap::new(size, stack),\n             history: AllocHistory::new(),\n@@ -900,11 +826,14 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 // We have to use shared references to alloc/memory_extra here since\n                 // `visit_freeze_sensitive` needs to access the global state.\n                 let extra = this.get_alloc_extra(alloc_id)?;\n+\n                 let mut stacked_borrows = extra\n                     .stacked_borrows\n                     .as_ref()\n                     .expect(\"we should have Stacked Borrows data\")\n                     .borrow_mut();\n+                let mut current_span = this.machine.current_span();\n+\n                 this.visit_freeze_sensitive(place, size, |mut range, frozen| {\n                     // Adjust range.\n                     range.start += base_offset;\n@@ -929,7 +858,7 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                             item,\n                             (alloc_id, range, offset),\n                             &mut global,\n-                            current_span,\n+                            &mut current_span,\n                             history,\n                             exposed_tags,\n                         )"}, {"sha": "a7b8e5f13cea4162b429c1ce486078adf21f3e8d", "filename": "src/stacked_borrows/diagnostics.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/3bbcafe3b59ee5c4537f65e820835c526531fe59/src%2Fstacked_borrows%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3bbcafe3b59ee5c4537f65e820835c526531fe59/src%2Fstacked_borrows%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fstacked_borrows%2Fdiagnostics.rs?ref=3bbcafe3b59ee5c4537f65e820835c526531fe59", "patch": "@@ -185,7 +185,10 @@ fn operation_summary(\n \n fn error_cause(stack: &Stack, tag: SbTagExtra) -> &'static str {\n     if let SbTagExtra::Concrete(tag) = tag {\n-        if stack.borrows.iter().any(|item| item.tag == tag && item.perm != Permission::Disabled) {\n+        if (0..stack.len())\n+            .map(|i| stack.get(i).unwrap())\n+            .any(|item| item.tag == tag && item.perm != Permission::Disabled)\n+        {\n             \", but that tag only grants SharedReadOnly permission for this location\"\n         } else {\n             \", but that tag does not exist in the borrow stack for this location\""}, {"sha": "e6dc507802fd0313d43aa2aa1d8f722c9bae1c8d", "filename": "src/stacked_borrows/stack.rs", "status": "added", "additions": 349, "deletions": 0, "changes": 349, "blob_url": "https://github.com/rust-lang/rust/blob/3bbcafe3b59ee5c4537f65e820835c526531fe59/src%2Fstacked_borrows%2Fstack.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3bbcafe3b59ee5c4537f65e820835c526531fe59/src%2Fstacked_borrows%2Fstack.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fstacked_borrows%2Fstack.rs?ref=3bbcafe3b59ee5c4537f65e820835c526531fe59", "patch": "@@ -0,0 +1,349 @@\n+use crate::stacked_borrows::{AccessKind, Item, Permission, SbTag, SbTagExtra};\n+use rustc_data_structures::fx::FxHashSet;\n+#[cfg(feature = \"stack-cache\")]\n+use std::ops::Range;\n+\n+/// Exactly what cache size we should use is a difficult tradeoff. There will always be some\n+/// workload which has a `SbTag` working set which exceeds the size of the cache, and ends up\n+/// falling back to linear searches of the borrow stack very often.\n+/// The cost of making this value too large is that the loop in `Stack::insert` which ensures the\n+/// entries in the cache stay correct after an insert becomes expensive.\n+#[cfg(feature = \"stack-cache\")]\n+const CACHE_LEN: usize = 32;\n+\n+/// Extra per-location state.\n+#[derive(Clone, Debug)]\n+pub struct Stack {\n+    /// Used *mostly* as a stack; never empty.\n+    /// Invariants:\n+    /// * Above a `SharedReadOnly` there can only be more `SharedReadOnly`.\n+    /// * Except for `Untagged`, no tag occurs in the stack more than once.\n+    borrows: Vec<Item>,\n+    /// If this is `Some(id)`, then the actual current stack is unknown. This can happen when\n+    /// wildcard pointers are used to access this location. What we do know is that `borrows` are at\n+    /// the top of the stack, and below it are arbitrarily many items whose `tag` is strictly less\n+    /// than `id`.\n+    /// When the bottom is unknown, `borrows` always has a `SharedReadOnly` or `Unique` at the bottom;\n+    /// we never have the unknown-to-known boundary in an SRW group.\n+    unknown_bottom: Option<SbTag>,\n+\n+    /// A small LRU cache of searches of the borrow stack. This only caches accesses of `Tagged`,\n+    /// because those are unique in the stack.\n+    #[cfg(feature = \"stack-cache\")]\n+    cache: StackCache,\n+    /// On a read, we need to disable all `Unique` above the granting item. We can avoid most of\n+    /// this scan by keeping track of the region of the borrow stack that may contain `Unique`s.\n+    #[cfg(feature = \"stack-cache\")]\n+    unique_range: Range<usize>,\n+}\n+\n+/// A very small cache of searches of the borrow stack\n+/// This maps tags to locations in the borrow stack. Any use of this still needs to do a\n+/// probably-cold random access into the borrow stack to figure out what `Permission` an\n+/// `SbTag` grants. We could avoid this by also storing the `Permission` in the cache, but\n+/// most lookups into the cache are immediately followed by access of the full borrow stack anyway.\n+#[cfg(feature = \"stack-cache\")]\n+#[derive(Clone, Debug)]\n+struct StackCache {\n+    tags: [SbTag; CACHE_LEN], // Hot in find_granting\n+    idx: [usize; CACHE_LEN],  // Hot in grant\n+}\n+\n+#[cfg(feature = \"stack-cache\")]\n+impl StackCache {\n+    fn add(&mut self, idx: usize, tag: SbTag) {\n+        self.tags.copy_within(0..CACHE_LEN - 1, 1);\n+        self.tags[0] = tag;\n+        self.idx.copy_within(0..CACHE_LEN - 1, 1);\n+        self.idx[0] = idx;\n+    }\n+}\n+\n+impl PartialEq for Stack {\n+    fn eq(&self, other: &Self) -> bool {\n+        // All the semantics of Stack are in self.borrows, everything else is caching\n+        self.borrows == other.borrows\n+    }\n+}\n+\n+impl Eq for Stack {}\n+\n+impl<'tcx> Stack {\n+    /// Panics if any of the caching mechanisms have broken,\n+    /// - The StackCache indices don't refer to the parallel tags,\n+    /// - There are no Unique tags outside of first_unique..last_unique\n+    #[cfg(feature = \"expensive-debug-assertions\")]\n+    fn verify_cache_consistency(&self) {\n+        if self.borrows.len() > CACHE_LEN {\n+            for (tag, stack_idx) in self.cache.tags.iter().zip(self.cache.idx.iter()) {\n+                assert_eq!(self.borrows[*stack_idx].tag, *tag);\n+            }\n+        }\n+\n+        for (idx, item) in self.borrows.iter().enumerate() {\n+            if item.perm == Permission::Unique {\n+                assert!(\n+                    self.unique_range.contains(&idx),\n+                    \"{:?} {:?}\",\n+                    self.unique_range,\n+                    self.borrows\n+                );\n+            }\n+        }\n+    }\n+\n+    /// Find the item granting the given kind of access to the given tag, and return where\n+    /// it is on the stack. For wildcard tags, the given index is approximate, but if *no*\n+    /// index is given it means the match was *not* in the known part of the stack.\n+    /// `Ok(None)` indicates it matched the \"unknown\" part of the stack.\n+    /// `Err` indicates it was not found.\n+    pub fn find_granting(\n+        &mut self,\n+        access: AccessKind,\n+        tag: SbTagExtra,\n+        exposed_tags: &FxHashSet<SbTag>,\n+    ) -> Result<Option<usize>, ()> {\n+        #[cfg(feature = \"expensive-debug-assertions\")]\n+        self.verify_cache_consistency();\n+\n+        let SbTagExtra::Concrete(tag) = tag else {\n+            // Handle the wildcard case.\n+            // Go search the stack for an exposed tag.\n+            if let Some(idx) =\n+                self.borrows\n+                    .iter()\n+                    .enumerate() // we also need to know *where* in the stack\n+                    .rev() // search top-to-bottom\n+                    .find_map(|(idx, item)| {\n+                        // If the item fits and *might* be this wildcard, use it.\n+                        if item.perm.grants(access) && exposed_tags.contains(&item.tag) {\n+                            Some(idx)\n+                        } else {\n+                            None\n+                        }\n+                    })\n+            {\n+                return Ok(Some(idx));\n+            }\n+            // If we couldn't find it in the stack, check the unknown bottom.\n+            return if self.unknown_bottom.is_some() { Ok(None) } else { Err(()) };\n+        };\n+\n+        if let Some(idx) = self.find_granting_tagged(access, tag) {\n+            return Ok(Some(idx));\n+        }\n+\n+        // Couldn't find it in the stack; but if there is an unknown bottom it might be there.\n+        let found = self.unknown_bottom.is_some_and(|&unknown_limit| {\n+            tag.0 < unknown_limit.0 // unknown_limit is an upper bound for what can be in the unknown bottom.\n+        });\n+        if found { Ok(None) } else { Err(()) }\n+    }\n+\n+    fn find_granting_tagged(&mut self, access: AccessKind, tag: SbTag) -> Option<usize> {\n+        #[cfg(feature = \"stack-cache\")]\n+        if let Some(idx) = self.find_granting_cache(access, tag) {\n+            return Some(idx);\n+        }\n+\n+        // If we didn't find the tag in the cache, fall back to a linear search of the\n+        // whole stack, and add the tag to the stack.\n+        for (stack_idx, item) in self.borrows.iter().enumerate().rev() {\n+            if tag == item.tag && item.perm.grants(access) {\n+                #[cfg(feature = \"stack-cache\")]\n+                self.cache.add(stack_idx, tag);\n+                return Some(stack_idx);\n+            }\n+        }\n+        None\n+    }\n+\n+    #[cfg(feature = \"stack-cache\")]\n+    fn find_granting_cache(&mut self, access: AccessKind, tag: SbTag) -> Option<usize> {\n+        // When the borrow stack is empty, there are no tags we could put into the cache that would\n+        // be valid. Additionally, since lookups into the cache are a linear search it doesn't make\n+        // sense to use the cache when it is no smaller than a search of the borrow stack itself.\n+        if self.borrows.len() <= CACHE_LEN {\n+            return None;\n+        }\n+        // Search the cache for the tag we're looking up\n+        let cache_idx = self.cache.tags.iter().position(|t| *t == tag)?;\n+        let stack_idx = self.cache.idx[cache_idx];\n+        // If we found the tag, look up its position in the stack to see if it grants\n+        // the required permission\n+        if self.borrows[stack_idx].perm.grants(access) {\n+            // If it does, and it's already in the most-recently-used position, move it\n+            // there.\n+            if cache_idx != 0 {\n+                self.cache.add(stack_idx, tag);\n+            }\n+            Some(stack_idx)\n+        } else {\n+            // Tag is in the cache, but it doesn't grant the required permission\n+            None\n+        }\n+    }\n+\n+    pub fn insert(&mut self, new_idx: usize, new: Item) {\n+        self.borrows.insert(new_idx, new);\n+\n+        #[cfg(feature = \"stack-cache\")]\n+        self.insert_cache(new_idx, new);\n+    }\n+\n+    #[cfg(feature = \"stack-cache\")]\n+    fn insert_cache(&mut self, new_idx: usize, new: Item) {\n+        // Adjust the possibly-unique range if an insert occurs before or within it\n+        if self.unique_range.start >= new_idx {\n+            self.unique_range.start += 1;\n+        }\n+        if self.unique_range.end >= new_idx {\n+            self.unique_range.end += 1;\n+        }\n+        if new.perm == Permission::Unique {\n+            // Make sure the possibly-unique range contains the new borrow\n+            self.unique_range.start = self.unique_range.start.min(new_idx);\n+            self.unique_range.end = self.unique_range.end.max(new_idx + 1);\n+        }\n+\n+        // The above insert changes the meaning of every index in the cache >= new_idx, so now\n+        // we need to find every one of those indexes and increment it.\n+        for idx in &mut self.cache.idx {\n+            if *idx >= new_idx {\n+                *idx += 1;\n+            }\n+        }\n+\n+        // This primes the cache for the next access, which is almost always the just-added tag.\n+        self.cache.add(new_idx, new.tag);\n+\n+        #[cfg(feature = \"expensive-debug-assertions\")]\n+        self.verify_cache_consistency();\n+    }\n+\n+    /// Construct a new `Stack` using the passed `Item` as the base tag.\n+    pub fn new(item: Item) -> Self {\n+        Stack {\n+            borrows: vec![item],\n+            unknown_bottom: None,\n+            #[cfg(feature = \"stack-cache\")]\n+            cache: StackCache { idx: [0; CACHE_LEN], tags: [item.tag; CACHE_LEN] },\n+            #[cfg(feature = \"stack-cache\")]\n+            unique_range: if item.perm == Permission::Unique { 0..1 } else { 0..0 },\n+        }\n+    }\n+\n+    pub fn get(&self, idx: usize) -> Option<Item> {\n+        self.borrows.get(idx).cloned()\n+    }\n+\n+    #[allow(clippy::len_without_is_empty)] // Stacks are never empty\n+    pub fn len(&self) -> usize {\n+        self.borrows.len()\n+    }\n+\n+    pub fn unknown_bottom(&self) -> Option<SbTag> {\n+        self.unknown_bottom\n+    }\n+\n+    pub fn set_unknown_bottom(&mut self, tag: SbTag) {\n+        self.borrows.clear();\n+        self.unknown_bottom = Some(tag);\n+    }\n+\n+    /// Find all `Unique` elements in this borrow stack above `granting_idx`, pass a copy of them\n+    /// to the `visitor`, then set their `Permission` to `Disabled`.\n+    pub fn disable_uniques_starting_at<V: FnMut(Item) -> crate::InterpResult<'tcx>>(\n+        &mut self,\n+        disable_start: usize,\n+        mut visitor: V,\n+    ) -> crate::InterpResult<'tcx> {\n+        #[cfg(feature = \"stack-cache\")]\n+        let unique_range = self.unique_range.clone();\n+        #[cfg(not(feature = \"stack-cache\"))]\n+        let unique_range = 0..self.len();\n+\n+        if disable_start <= unique_range.end {\n+            // add 1 so we don't disable the granting item\n+            let lower = unique_range.start.max(disable_start);\n+            let upper = (unique_range.end + 1).min(self.borrows.len());\n+            for item in &mut self.borrows[lower..upper] {\n+                if item.perm == Permission::Unique {\n+                    log::trace!(\"access: disabling item {:?}\", item);\n+                    visitor(*item)?;\n+                    item.perm = Permission::Disabled;\n+                }\n+            }\n+        }\n+\n+        #[cfg(feature = \"stack-cache\")]\n+        if disable_start < self.unique_range.start {\n+            // We disabled all Unique items\n+            self.unique_range.start = 0;\n+            self.unique_range.end = 0;\n+        } else {\n+            // Truncate the range to disable_start. This is + 2 because we are only removing\n+            // elements after disable_start, and this range does not include the end.\n+            self.unique_range.end = self.unique_range.end.min(disable_start + 1);\n+        }\n+\n+        #[cfg(feature = \"expensive-debug-assertions\")]\n+        self.verify_cache_consistency();\n+\n+        Ok(())\n+    }\n+\n+    /// Produces an iterator which iterates over `range` in reverse, and when dropped removes that\n+    /// range of `Item`s from this `Stack`.\n+    pub fn pop_items_after<V: FnMut(Item) -> crate::InterpResult<'tcx>>(\n+        &mut self,\n+        start: usize,\n+        mut visitor: V,\n+    ) -> crate::InterpResult<'tcx> {\n+        while self.borrows.len() > start {\n+            let item = self.borrows.pop().unwrap();\n+            visitor(item)?;\n+        }\n+\n+        #[cfg(feature = \"stack-cache\")]\n+        if !self.borrows.is_empty() {\n+            // After we remove from the borrow stack, every aspect of our caching may be invalid, but it is\n+            // also possible that the whole cache is still valid. So we call this method to repair what\n+            // aspects of the cache are now invalid, instead of resetting the whole thing to a trivially\n+            // valid default state.\n+            let base_tag = self.borrows[0].tag;\n+            let mut removed = 0;\n+            let mut cursor = 0;\n+            // Remove invalid entries from the cache by rotating them to the end of the cache, then\n+            // keep track of how many invalid elements there are and overwrite them with the base tag.\n+            // The base tag here serves as a harmless default value.\n+            for _ in 0..CACHE_LEN - 1 {\n+                if self.cache.idx[cursor] >= start {\n+                    self.cache.idx[cursor..CACHE_LEN - removed].rotate_left(1);\n+                    self.cache.tags[cursor..CACHE_LEN - removed].rotate_left(1);\n+                    removed += 1;\n+                } else {\n+                    cursor += 1;\n+                }\n+            }\n+            for i in CACHE_LEN - removed - 1..CACHE_LEN {\n+                self.cache.idx[i] = 0;\n+                self.cache.tags[i] = base_tag;\n+            }\n+\n+            if start < self.unique_range.start.saturating_sub(1) {\n+                // We removed all the Unique items\n+                self.unique_range = 0..0;\n+            } else {\n+                // Ensure the range doesn't extend past the new top of the stack\n+                self.unique_range.end = self.unique_range.end.min(start + 1);\n+            }\n+        } else {\n+            self.unique_range = 0..0;\n+        }\n+\n+        #[cfg(feature = \"expensive-debug-assertions\")]\n+        self.verify_cache_consistency();\n+        Ok(())\n+    }\n+}"}, {"sha": "0838733db2de32bd9080a87eba74b0fa8d1a82e8", "filename": "ui_test/Cargo.toml", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3bbcafe3b59ee5c4537f65e820835c526531fe59/ui_test%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/3bbcafe3b59ee5c4537f65e820835c526531fe59/ui_test%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/ui_test%2FCargo.toml?ref=3bbcafe3b59ee5c4537f65e820835c526531fe59", "patch": "@@ -14,3 +14,7 @@ crossbeam = \"0.8.1\"\n lazy_static = \"1.4.0\"\n serde = { version = \"1.0\", features = [\"derive\"] }\n serde_json = \"1.0\"\n+\n+[features]\n+# Doesn't do anything, but the miri script wants to pass the same flags to ui_test and miri itself\n+expensive-debug-assertions = []"}]}