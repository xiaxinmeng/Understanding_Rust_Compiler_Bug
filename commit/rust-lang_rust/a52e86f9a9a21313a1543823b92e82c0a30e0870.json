{"sha": "a52e86f9a9a21313a1543823b92e82c0a30e0870", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE1MmU4NmY5YTlhMjEzMTNhMTU0MzgyM2I5MmU4MmMwYTMwZTA4NzA=", "commit": {"author": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2019-04-05T14:17:07Z"}, "committer": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2019-04-05T14:17:07Z"}, "message": "Merge #1112\n\n1112: Fix literal support in token tree to ast item list r=matklad a=edwin0cheng\n\nThis PR implements following things :\r\n\r\n1. Expose `next_token` from `ra_parse`\r\n2. Fix the literal conversion in `token_tree_to_ast_item_list`\r\n3. Add test for the conversion\n\nCo-authored-by: Edwin Cheng <edwin0cheng@gmail.com>", "tree": {"sha": "35d8b8b04a8e17a162fd6b95105db34919d59507", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/35d8b8b04a8e17a162fd6b95105db34919d59507"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a52e86f9a9a21313a1543823b92e82c0a30e0870", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a52e86f9a9a21313a1543823b92e82c0a30e0870", "html_url": "https://github.com/rust-lang/rust/commit/a52e86f9a9a21313a1543823b92e82c0a30e0870", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a52e86f9a9a21313a1543823b92e82c0a30e0870/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "parents": [{"sha": "be9a44e9bad262ac5e615730e540fd434f846a0e", "url": "https://api.github.com/repos/rust-lang/rust/commits/be9a44e9bad262ac5e615730e540fd434f846a0e", "html_url": "https://github.com/rust-lang/rust/commit/be9a44e9bad262ac5e615730e540fd434f846a0e"}, {"sha": "7abc06bd576264cb6b7c8becdbd1a8c0e914463d", "url": "https://api.github.com/repos/rust-lang/rust/commits/7abc06bd576264cb6b7c8becdbd1a8c0e914463d", "html_url": "https://github.com/rust-lang/rust/commit/7abc06bd576264cb6b7c8becdbd1a8c0e914463d"}], "stats": {"total": 108, "additions": 101, "deletions": 7}, "files": [{"sha": "4203929d4f4eaa205311976cf6605af2f6519e7e", "filename": "crates/ra_mbe/src/lib.rs", "status": "modified", "additions": 45, "deletions": 3, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_mbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_mbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Flib.rs?ref=a52e86f9a9a21313a1543823b92e82c0a30e0870", "patch": "@@ -167,7 +167,7 @@ impl_froms!(TokenTree: Leaf, Subtree);\n     )\n     }\n \n-    fn create_rules(macro_definition: &str) -> MacroRules {\n+    pub(crate) fn create_rules(macro_definition: &str) -> MacroRules {\n         let source_file = ast::SourceFile::parse(macro_definition);\n         let macro_definition =\n             source_file.syntax().descendants().find_map(ast::MacroCall::cast).unwrap();\n@@ -176,7 +176,7 @@ impl_froms!(TokenTree: Leaf, Subtree);\n         crate::MacroRules::parse(&definition_tt).unwrap()\n     }\n \n-    fn expand(rules: &MacroRules, invocation: &str) -> tt::Subtree {\n+    pub(crate) fn expand(rules: &MacroRules, invocation: &str) -> tt::Subtree {\n         let source_file = ast::SourceFile::parse(invocation);\n         let macro_invocation =\n             source_file.syntax().descendants().find_map(ast::MacroCall::cast).unwrap();\n@@ -186,7 +186,7 @@ impl_froms!(TokenTree: Leaf, Subtree);\n         rules.expand(&invocation_tt).unwrap()\n     }\n \n-    fn assert_expansion(rules: &MacroRules, invocation: &str, expansion: &str) {\n+    pub(crate) fn assert_expansion(rules: &MacroRules, invocation: &str, expansion: &str) {\n         let expanded = expand(rules, invocation);\n         assert_eq!(expanded.to_string(), expansion);\n     }\n@@ -337,4 +337,46 @@ SOURCE_FILE@[0; 40)\n         );\n     }\n \n+    #[test]\n+    fn expand_literals_to_token_tree() {\n+        fn to_subtree(tt: &tt::TokenTree) -> &tt::Subtree {\n+            if let tt::TokenTree::Subtree(subtree) = tt {\n+                return &subtree;\n+            }\n+            unreachable!(\"It is not a subtree\");\n+        }\n+\n+        fn to_literal(tt: &tt::TokenTree) -> &tt::Literal {\n+            if let tt::TokenTree::Leaf(tt::Leaf::Literal(lit)) = tt {\n+                return lit;\n+            }\n+            unreachable!(\"It is not a literal\");\n+        }\n+\n+        let rules = create_rules(\n+            r#\"\n+            macro_rules! literals {\n+                ($i:ident) => {\n+                    {\n+                        let a = 'c';\n+                        let c = 1000;\n+                        let f = 12E+99_f64;\n+                        let s = \"rust1\";\n+                    }\n+                }\n+            }\n+            \"#,\n+        );\n+        let expansion = expand(&rules, \"literals!(foo)\");\n+        let stm_tokens = &to_subtree(&expansion.token_trees[0]).token_trees;\n+\n+        // [let] [a] [=] ['c'] [;]\n+        assert_eq!(to_literal(&stm_tokens[3]).text, \"'c'\");\n+        // [let] [c] [=] [1000] [;]\n+        assert_eq!(to_literal(&stm_tokens[5 + 3]).text, \"1000\");\n+        // [let] [f] [=] [12E+99_f64] [;]\n+        assert_eq!(to_literal(&stm_tokens[10 + 3]).text, \"12E+99_f64\");\n+        // [let] [s] [=] [\"rust1\"] [;]\n+        assert_eq!(to_literal(&stm_tokens[15 + 3]).text, \"\\\"rust1\\\"\");\n+    }\n }"}, {"sha": "139a0fd3379aa7230d0f9607e3d7ab7fa376129f", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 45, "deletions": 2, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=a52e86f9a9a21313a1543823b92e82c0a30e0870", "patch": "@@ -1,7 +1,7 @@\n use ra_parser::{TokenSource, TreeSink, ParseError};\n use ra_syntax::{\n     AstNode, SyntaxNode, TextRange, SyntaxKind, SmolStr, SyntaxTreeBuilder, TreeArc, SyntaxElement,\n-    ast, SyntaxKind::*, TextUnit\n+    ast, SyntaxKind::*, TextUnit, classify_literal\n };\n \n /// Maps `tt::TokenId` to the relative range of the original token.\n@@ -103,10 +103,12 @@ fn convert_tt(\n     Some(res)\n }\n \n+#[derive(Debug)]\n struct TtTokenSource {\n     tokens: Vec<TtToken>,\n }\n \n+#[derive(Debug)]\n struct TtToken {\n     kind: SyntaxKind,\n     is_joint_to_next: bool,\n@@ -189,7 +191,7 @@ impl TtTokenSource {\n     {\n         let tok = match token {\n             tt::Leaf::Literal(l) => TtToken {\n-                kind: SyntaxKind::INT_NUMBER, // FIXME\n+                kind: classify_literal(&l.text).unwrap().kind,\n                 is_joint_to_next: false,\n                 text: l.text.clone(),\n             },\n@@ -355,3 +357,44 @@ impl<'a> TreeSink for TtTreeSink<'a> {\n         self.inner.error(error, self.text_pos)\n     }\n }\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+    use crate::tests::{expand, create_rules};\n+\n+    #[test]\n+    fn convert_tt_token_source() {\n+        let rules = create_rules(\n+            r#\"\n+            macro_rules! literals {\n+                ($i:ident) => {\n+                    {\n+                        let a = 'c';\n+                        let c = 1000;\n+                        let f = 12E+99_f64;\n+                        let s = \"rust1\";\n+                    }\n+                }\n+            }\n+            \"#,\n+        );\n+        let expansion = expand(&rules, \"literals!(foo)\");\n+        let tt_src = TtTokenSource::new(&expansion);\n+\n+        // [{]\n+        // [let] [a] [=] ['c'] [;]\n+        assert_eq!(tt_src.tokens[1 + 3].text, \"'c'\");\n+        assert_eq!(tt_src.tokens[1 + 3].kind, CHAR);\n+        // [let] [c] [=] [1000] [;]\n+        assert_eq!(tt_src.tokens[1 + 5 + 3].text, \"1000\");\n+        assert_eq!(tt_src.tokens[1 + 5 + 3].kind, INT_NUMBER);\n+        // [let] [f] [=] [12E+99_f64] [;]\n+        assert_eq!(tt_src.tokens[1 + 10 + 3].text, \"12E+99_f64\");\n+        assert_eq!(tt_src.tokens[1 + 10 + 3].kind, FLOAT_NUMBER);\n+\n+        // [let] [s] [=] [\"rust1\"] [;]\n+        assert_eq!(tt_src.tokens[1 + 15 + 3].text, \"\\\"rust1\\\"\");\n+        assert_eq!(tt_src.tokens[1 + 15 + 3].kind, STRING);\n+    }\n+}"}, {"sha": "c56bc9f16828ed5e363421dbaff17cfb04ca57ee", "filename": "crates/ra_syntax/src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_syntax%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_syntax%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Flib.rs?ref=a52e86f9a9a21313a1543823b92e82c0a30e0870", "patch": "@@ -40,7 +40,7 @@ pub use crate::{\n     syntax_text::SyntaxText,\n     syntax_node::{Direction,  SyntaxNode, WalkEvent, TreeArc, SyntaxTreeBuilder, SyntaxElement, SyntaxToken},\n     ptr::{SyntaxNodePtr, AstPtr},\n-    parsing::{tokenize, Token},\n+    parsing::{tokenize, classify_literal, Token},\n };\n \n use ra_text_edit::AtomTextEdit;"}, {"sha": "15d69c5ab03c41740d9e4ed19e1d3382fd677361", "filename": "crates/ra_syntax/src/parsing.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_syntax%2Fsrc%2Fparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_syntax%2Fsrc%2Fparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing.rs?ref=a52e86f9a9a21313a1543823b92e82c0a30e0870", "patch": "@@ -11,7 +11,7 @@ use crate::{\n     syntax_node::GreenNode,\n };\n \n-pub use self::lexer::{tokenize, Token};\n+pub use self::lexer::{tokenize, classify_literal, Token};\n \n pub(crate) use self::reparsing::incremental_reparse;\n "}, {"sha": "3ae42912c5284c9ba2335d01dea695c296f954df", "filename": "crates/ra_syntax/src/parsing/lexer.rs", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_syntax%2Fsrc%2Fparsing%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a52e86f9a9a21313a1543823b92e82c0a30e0870/crates%2Fra_syntax%2Fsrc%2Fparsing%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Flexer.rs?ref=a52e86f9a9a21313a1543823b92e82c0a30e0870", "patch": "@@ -214,3 +214,12 @@ fn scan_literal_suffix(ptr: &mut Ptr) {\n     }\n     ptr.bump_while(is_ident_continue);\n }\n+\n+pub fn classify_literal(text: &str) -> Option<Token> {\n+    let tkn = next_token(text);\n+    if !tkn.kind.is_literal() || tkn.len.to_usize() != text.len() {\n+        return None;\n+    }\n+\n+    Some(tkn)\n+}"}]}