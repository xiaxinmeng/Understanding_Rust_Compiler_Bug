{"sha": "fa6fff585f5c23146e6d8db7899f4bb1d71399b4", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZhNmZmZjU4NWY1YzIzMTQ2ZTZkOGRiNzg5OWY0YmIxZDcxMzk5YjQ=", "commit": {"author": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-06-24T23:21:17Z"}, "committer": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-06-24T23:21:17Z"}, "message": "vec 1.0", "tree": {"sha": "c296916a88f0cb73ce939a47a0901641ca544632", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c296916a88f0cb73ce939a47a0901641ca544632"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fa6fff585f5c23146e6d8db7899f4bb1d71399b4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fa6fff585f5c23146e6d8db7899f4bb1d71399b4", "html_url": "https://github.com/rust-lang/rust/commit/fa6fff585f5c23146e6d8db7899f4bb1d71399b4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fa6fff585f5c23146e6d8db7899f4bb1d71399b4/comments", "author": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "af2fd1d53ee2013a8febcef0b064739d1ed7d76e", "url": "https://api.github.com/repos/rust-lang/rust/commits/af2fd1d53ee2013a8febcef0b064739d1ed7d76e", "html_url": "https://github.com/rust-lang/rust/commit/af2fd1d53ee2013a8febcef0b064739d1ed7d76e"}], "stats": {"total": 520, "additions": 509, "deletions": 11}, "files": [{"sha": "a2fecf8238251b6caecb559300261b888aca03e7", "filename": "vec.md", "status": "modified", "additions": 509, "deletions": 11, "changes": 520, "blob_url": "https://github.com/rust-lang/rust/blob/fa6fff585f5c23146e6d8db7899f4bb1d71399b4/vec.md", "raw_url": "https://github.com/rust-lang/rust/raw/fa6fff585f5c23146e6d8db7899f4bb1d71399b4/vec.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/vec.md?ref=fa6fff585f5c23146e6d8db7899f4bb1d71399b4", "patch": "@@ -1,11 +1,11 @@\n % Example: Implementing Vec\n \n-TODO: audit for non-ZST offsets from heap::empty\n-\n To bring everything together, we're going to write `std::Vec` from scratch.\n Because the all the best tools for writing unsafe code are unstable, this\n project will only work on nightly (as of Rust 1.2.0).\n \n+\n+\n # Layout\n \n First off, we need to come up with the struct layout. Naively we want this\n@@ -63,16 +63,19 @@ as `std::rt::heap::EMPTY`. There are quite a few places where we'll want to use\n `heap::EMPTY` because there's no real allocation to talk about but `null` would\n make the compiler angry.\n \n-All of the `heap` API is totally unstable under the `alloc` feature, though.\n+All of the `heap` API is totally unstable under the `heap_api` feature, though.\n We could trivially define `heap::EMPTY` ourselves, but we'll want the rest of\n the `heap` API anyway, so let's just get that dependency over with.\n \n+\n+\n+\n # Allocating Memory\n \n So:\n \n ```rust\n-#![feature(alloc)]\n+#![feature(heap_api)]\n \n use std::rt::heap::EMPTY;\n use std::mem;\n@@ -184,6 +187,10 @@ fn grow(&mut self) {\n Nothing particularly tricky here. Just computing sizes and alignments and doing\n some careful multiplication checks.\n \n+\n+\n+\n+\n # Push and Pop\n \n Alright. We can initialize. We can allocate. Let's actually implement some\n@@ -240,6 +247,10 @@ pub fn pop(&mut self) -> Option<T> {\n }\n ```\n \n+\n+\n+\n+\n # Deallocating\n \n Next we should implement Drop so that we don't massively leaks tons of resources.\n@@ -270,6 +281,10 @@ impl<T> Drop for Vec<T> {\n }\n ```\n \n+\n+\n+\n+\n # Deref\n \n Alright! We've got a decent minimal ArrayStack implemented. We can push, we can\n@@ -311,6 +326,10 @@ impl<T> DerefMut for Vec<T> {\n Now we have `len`, `first`, `last`, indexing, slicing, sorting, `iter`, `iter_mut`,\n and all other sorts of bells and whistles provided by slice. Sweet!\n \n+\n+\n+\n+\n # Insert and Remove\n \n Something *not* provided but slice is `insert` and `remove`, so let's do those next.\n@@ -362,6 +381,10 @@ pub fn remove(&mut self, index: usize) -> T {\n }\n ```\n \n+\n+\n+\n+\n # IntoIter\n \n Let's move on to writing iterators. `iter` and `iter_mut` have already been\n@@ -410,7 +433,22 @@ struct IntoIter<T> {\n }\n ```\n \n-And initialize it like this:\n+One last subtle detail: if our Vec is empty, we want to produce an empty iterator.\n+This will actually technically fall out doing the naive thing of:\n+\n+```text\n+start = ptr\n+end = ptr.offset(len)\n+```\n+\n+However because `offset` is marked as a GEP inbounds instruction, this will tell\n+llVM that ptr is allocated and won't alias other allocated memory. This is fine\n+for zero-sized types, as they can't alias anything. However if we're using\n+heap::EMPTY as a sentinel for a non-allocation for a *non-zero-sized* type,\n+this can cause undefined behaviour. Alas, we must therefore special case either\n+cap or len being 0 to not do the offset.\n+\n+So this is what we end up with for initialization:\n \n ```rust\n impl<T> Vec<T> {\n@@ -428,7 +466,12 @@ impl<T> Vec<T> {\n                 buf: ptr,\n                 cap: cap,\n                 start: *ptr,\n-                end: ptr.offset(len as isize),\n+                end: if cap == 0 {\n+                    // can't offset off this pointer, it's not allocated!\n+                    *ptr\n+                } else {\n+                    ptr.offset(len as isize)\n+                }\n             }\n         }\n     }\n@@ -635,6 +678,10 @@ impl<T> Vec<T> {\n \n Much better.\n \n+\n+\n+\n+\n # Drain\n \n Let's move on to Drain. Drain is largely the same as IntoIter, except that\n@@ -674,7 +721,11 @@ impl<T> RawValIter<T> {\n     unsafe fn new(slice: &[T]) -> Self {\n         RawValIter {\n             start: slice.as_ptr(),\n-            end: slice.as_ptr().offset(slice.len() as isize),\n+            end: if slice.len() == 0 {\n+                slice.as_ptr()\n+            } else {\n+                slice.as_ptr().offset(slice.len() as isize)\n+            }\n         }\n     }\n }\n@@ -771,6 +822,8 @@ impl<T> Vec<T> {\n ```\n \n \n+\n+\n # Handling Zero-Sized Types\n \n It's time. We're going to fight the spectre that is zero-sized types. Safe Rust\n@@ -781,13 +834,14 @@ zero-sized types. We need to be careful of two things:\n * The raw allocator API has undefined behaviour if you pass in 0 for an\n   allocation size.\n * raw pointer offsets are no-ops for zero-sized types, which will break our\n-  C-style pointer iterator\n+  C-style pointer iterator.\n \n Thankfully we abstracted out pointer-iterators and allocating handling into\n RawValIter and RawVec respectively. How mysteriously convenient.\n \n \n \n+\n ## Allocating Zero-Sized Types\n \n So if the allocator API doesn't support zero-sized allocations, what on earth\n@@ -797,13 +851,457 @@ to be considered to store or load them. This actually extends to `ptr::read` and\n `ptr::write`: they won't actually look at the pointer at all. As such we *never* need\n to change the pointer.\n \n-TODO\n+Note however that our previous reliance on running out of memory before overflow is\n+no longer valid with zero-sized types. We must explicitly guard against capacity\n+overflow for zero-sized types.\n+\n+Due to our current architecture, all this means is writing 3 guards, one in each\n+method of RawVec.\n+\n+```rust\n+impl<T> RawVec<T> {\n+    fn new() -> Self {\n+        unsafe {\n+            // -1 is usize::MAX. This branch should be stripped at compile time.\n+            let cap = if mem::size_of::<T>() == 0 { -1 } else { 0 };\n+\n+            // heap::EMPTY doubles as \"unallocated\" and \"zero-sized allocation\"\n+            RawVec { ptr: Unique::new(heap::EMPTY as *mut T), cap: cap }\n+        }\n+    }\n+\n+    fn grow(&mut self) {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+\n+            // since we set the capacity to usize::MAX when elem_size is\n+            // 0, getting to here necessarily means the Vec is overfull.\n+            assert!(elem_size != 0, \"capacity overflow\");\n+\n+            let align = mem::min_align_of::<T>();\n+\n+            let (new_cap, ptr) = if self.cap == 0 {\n+                let ptr = heap::allocate(elem_size, align);\n+                (1, ptr)\n+            } else {\n+                let new_cap = 2 * self.cap;\n+                let ptr = heap::reallocate(*self.ptr as *mut _,\n+                                            self.cap * elem_size,\n+                                            new_cap * elem_size,\n+                                            align);\n+                (new_cap, ptr)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+}\n+\n+impl<T> Drop for RawVec<T> {\n+    fn drop(&mut self) {\n+        let elem_size = mem::size_of::<T>();\n+\n+        // don't free zero-sized allocations, as they were never allocated.\n+        if self.cap != 0 && elem_size != 0 {\n+            let align = mem::min_align_of::<T>();\n+\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+```\n+\n+That's it. We support pushing and popping zero-sized types now. Our iterators\n+(that aren't provided by slice Deref) are still busted, though.\n+\n+\n+\n \n ## Iterating Zero-Sized Types\n \n-TODO\n+Zero-sized offsets are no-ops. This means that our current design will always\n+initialize `start` and `end` as the same value, and our iterators will yield\n+nothing. The current solution to this is to cast the pointers to integers,\n+increment, and then cast them back:\n \n-## Advanced Drain\n+```\n+impl<T> RawValIter<T> {\n+    unsafe fn new(slice: &[T]) -> Self {\n+        RawValIter {\n+            start: slice.as_ptr(),\n+            end: if mem::size_of::<T>() == 0 {\n+                ((slice.as_ptr() as usize) + slice.len()) as *const _\n+            } else if slice.len() == 0 {\n+                slice.as_ptr()\n+            } else {\n+                slice.as_ptr().offset(slice.len() as isize)\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Now we have a different bug. Instead of our iterators not running at all, our\n+iterators now run *forever*. We need to do the same trick in our iterator impls:\n+\n+```\n+impl<T> Iterator for RawValIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                let result = ptr::read(self.start);\n+                self.start = if mem::size_of::<T>() == 0 {\n+                    (self.start as usize + 1) as *const _\n+                } else {\n+                    self.start.offset(1);\n+                }\n+                Some(result)\n+            }\n+        }\n+    }\n+\n+    fn size_hint(&self) -> (usize, Option<usize>) {\n+        let len = self.end as usize - self.start as usize;\n+        (len, Some(len))\n+    }\n+}\n+\n+impl<T> DoubleEndedIterator for RawValIter<T> {\n+    fn next_back(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                self.end = if mem::size_of::<T>() == 0 {\n+                    (self.end as usize - 1) as *const _\n+                } else {\n+                    self.end.offset(-1);\n+                }\n+                Some(ptr::read(self.end))\n+            }\n+        }\n+    }\n+}\n+```\n+\n+And that's it. Iteration works!\n+\n+\n+\n+# Advanced Drain\n \n TODO? Not clear if informative\n \n+\n+\n+\n+\n+# The Final Code\n+\n+```rust\n+#![feature(unique)]\n+#![feature(heap_api)]\n+\n+use std::ptr::{Unique, self};\n+use std::rt::heap;\n+use std::mem;\n+use std::ops::{Deref, DerefMut};\n+use std::marker::PhantomData;\n+\n+struct RawVec<T> {\n+    ptr: Unique<T>,\n+    cap: usize,\n+}\n+\n+impl<T> RawVec<T> {\n+    fn new() -> Self {\n+        unsafe {\n+            // -1 is usize::MAX. This branch should be stripped at compile time.\n+            let cap = if mem::size_of::<T>() == 0 { -1 } else { 0 };\n+\n+            // heap::EMPTY doubles as \"unallocated\" and \"zero-sized allocation\"\n+            RawVec { ptr: Unique::new(heap::EMPTY as *mut T), cap: cap }\n+        }\n+    }\n+\n+    fn grow(&mut self) {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+\n+            // since we set the capacity to usize::MAX when elem_size is\n+            // 0, getting to here necessarily means the Vec is overfull.\n+            assert!(elem_size != 0, \"capacity overflow\");\n+\n+            let align = mem::min_align_of::<T>();\n+\n+            let (new_cap, ptr) = if self.cap == 0 {\n+                let ptr = heap::allocate(elem_size, align);\n+                (1, ptr)\n+            } else {\n+                let new_cap = 2 * self.cap;\n+                let ptr = heap::reallocate(*self.ptr as *mut _,\n+                                            self.cap * elem_size,\n+                                            new_cap * elem_size,\n+                                            align);\n+                (new_cap, ptr)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+}\n+\n+impl<T> Drop for RawVec<T> {\n+    fn drop(&mut self) {\n+        let elem_size = mem::size_of::<T>();\n+        if self.cap != 0 && elem_size != 0 {\n+            let align = mem::min_align_of::<T>();\n+\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+\n+pub struct Vec<T> {\n+    buf: RawVec<T>,\n+    len: usize,\n+}\n+\n+impl<T> Vec<T> {\n+    fn ptr(&self) -> *mut T { *self.buf.ptr }\n+\n+    fn cap(&self) -> usize { self.buf.cap }\n+\n+    pub fn new() -> Self {\n+        Vec { buf: RawVec::new(), len: 0 }\n+    }\n+    pub fn push(&mut self, elem: T) {\n+        if self.len == self.cap() { self.buf.grow(); }\n+\n+        unsafe {\n+            ptr::write(self.ptr().offset(self.len as isize), elem);\n+        }\n+\n+        // Can't fail, we'll OOM first.\n+        self.len += 1;\n+    }\n+\n+    pub fn pop(&mut self) -> Option<T> {\n+        if self.len == 0 {\n+            None\n+        } else {\n+            self.len -= 1;\n+            unsafe {\n+                Some(ptr::read(self.ptr().offset(self.len as isize)))\n+            }\n+        }\n+    }\n+\n+    pub fn insert(&mut self, index: usize, elem: T) {\n+        assert!(index <= self.len, \"index out of bounds\");\n+        if self.cap() == self.len { self.buf.grow(); }\n+\n+        unsafe {\n+            if index < self.len {\n+                ptr::copy(self.ptr().offset(index as isize),\n+                          self.ptr().offset(index as isize + 1),\n+                          self.len - index);\n+            }\n+            ptr::write(self.ptr().offset(index as isize), elem);\n+            self.len += 1;\n+        }\n+    }\n+\n+    pub fn remove(&mut self, index: usize) -> T {\n+        assert!(index < self.len, \"index out of bounds\");\n+        unsafe {\n+            self.len -= 1;\n+            let result = ptr::read(self.ptr().offset(index as isize));\n+            ptr::copy(self.ptr().offset(index as isize + 1),\n+                      self.ptr().offset(index as isize),\n+                      self.len - index);\n+            result\n+        }\n+    }\n+\n+    pub fn into_iter(self) -> IntoIter<T> {\n+        unsafe {\n+            let iter = RawValIter::new(&self);\n+            let buf = ptr::read(&self.buf);\n+            mem::forget(self);\n+\n+            IntoIter {\n+                iter: iter,\n+                _buf: buf,\n+            }\n+        }\n+    }\n+\n+    pub fn drain(&mut self) -> Drain<T> {\n+        // this is a mem::forget safety thing. If this is forgotten, we just\n+        // leak the whole Vec's contents. Also we need to do this *eventually*\n+        // anyway, so why not do it now?\n+        self.len = 0;\n+        unsafe {\n+            Drain {\n+                iter: RawValIter::new(&self),\n+                vec: PhantomData,\n+            }\n+        }\n+    }\n+}\n+\n+impl<T> Drop for Vec<T> {\n+    fn drop(&mut self) {\n+        while let Some(_) = self.pop() {}\n+        // allocation is handled by RawVec\n+    }\n+}\n+\n+impl<T> Deref for Vec<T> {\n+    type Target = [T];\n+    fn deref(&self) -> &[T] {\n+        unsafe {\n+            ::std::slice::from_raw_parts(self.ptr(), self.len)\n+        }\n+    }\n+}\n+\n+impl<T> DerefMut for Vec<T> {\n+    fn deref_mut(&mut self) -> &mut [T] {\n+        unsafe {\n+            ::std::slice::from_raw_parts_mut(self.ptr(), self.len)\n+        }\n+    }\n+}\n+\n+\n+\n+\n+\n+struct RawValIter<T> {\n+    start: *const T,\n+    end: *const T,\n+}\n+\n+impl<T> RawValIter<T> {\n+    unsafe fn new(slice: &[T]) -> Self {\n+        RawValIter {\n+            start: slice.as_ptr(),\n+            end: if mem::size_of::<T>() == 0 {\n+                ((slice.as_ptr() as usize) + slice.len()) as *const _\n+            } else if slice.len() == 0 {\n+                slice.as_ptr()\n+            } else {\n+                slice.as_ptr().offset(slice.len() as isize)\n+            }\n+        }\n+    }\n+}\n+\n+impl<T> Iterator for RawValIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                let result = ptr::read(self.start);\n+                self.start = self.start.offset(1);\n+                Some(result)\n+            }\n+        }\n+    }\n+\n+    fn size_hint(&self) -> (usize, Option<usize>) {\n+        let len = self.end as usize - self.start as usize;\n+        (len, Some(len))\n+    }\n+}\n+\n+impl<T> DoubleEndedIterator for RawValIter<T> {\n+    fn next_back(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                self.end = self.end.offset(-1);\n+                Some(ptr::read(self.end))\n+            }\n+        }\n+    }\n+}\n+\n+\n+\n+\n+pub struct IntoIter<T> {\n+    _buf: RawVec<T>, // we don't actually care about this. Just need it to live.\n+    iter: RawValIter<T>,\n+}\n+\n+impl<T> Iterator for IntoIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> { self.iter.next() }\n+    fn size_hint(&self) -> (usize, Option<usize>) { self.iter.size_hint() }\n+}\n+\n+impl<T> DoubleEndedIterator for IntoIter<T> {\n+    fn next_back(&mut self) -> Option<T> { self.iter.next_back() }\n+}\n+\n+impl<T> Drop for IntoIter<T> {\n+    fn drop(&mut self) {\n+        for _ in &mut *self {}\n+    }\n+}\n+\n+\n+\n+\n+pub struct Drain<'a, T: 'a> {\n+    vec: PhantomData<&'a mut Vec<T>>,\n+    iter: RawValIter<T>,\n+}\n+\n+impl<'a, T> Iterator for Drain<'a, T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> { self.iter.next_back() }\n+    fn size_hint(&self) -> (usize, Option<usize>) { self.iter.size_hint() }\n+}\n+\n+impl<'a, T> DoubleEndedIterator for Drain<'a, T> {\n+    fn next_back(&mut self) -> Option<T> { self.iter.next_back() }\n+}\n+\n+impl<'a, T> Drop for Drain<'a, T> {\n+    fn drop(&mut self) {\n+        // pre-drain the iter\n+        for _ in &mut self.iter {}\n+    }\n+}\n+\n+/// Abort the process, we're out of memory!\n+///\n+/// In practice this is probably dead code on most OSes\n+fn oom() {\n+    ::std::process::exit(-1);\n+}\n+```"}]}