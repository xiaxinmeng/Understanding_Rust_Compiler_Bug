{"sha": "02a845a8268e6c6ed45f8bf2e7748ec8208af650", "node_id": "C_kwDOAAsO6NoAKDAyYTg0NWE4MjY4ZTZjNmVkNDVmOGJmMmU3NzQ4ZWM4MjA4YWY2NTA", "commit": {"author": {"name": "Guillaume Gomez", "email": "guillaume.gomez@huawei.com", "date": "2023-02-14T17:29:56Z"}, "committer": {"name": "Guillaume Gomez", "email": "guillaume.gomez@huawei.com", "date": "2023-02-14T22:23:59Z"}, "message": "Correctly handle reexport traversal by fixing multiple bugs, especially for items with a path of 1 element", "tree": {"sha": "22caa1700441d1d60a9440b472af5e9fe7c845e8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/22caa1700441d1d60a9440b472af5e9fe7c845e8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/02a845a8268e6c6ed45f8bf2e7748ec8208af650", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/02a845a8268e6c6ed45f8bf2e7748ec8208af650", "html_url": "https://github.com/rust-lang/rust/commit/02a845a8268e6c6ed45f8bf2e7748ec8208af650", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/02a845a8268e6c6ed45f8bf2e7748ec8208af650/comments", "author": {"login": "GuillaumeGomez", "id": 3050060, "node_id": "MDQ6VXNlcjMwNTAwNjA=", "avatar_url": "https://avatars.githubusercontent.com/u/3050060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GuillaumeGomez", "html_url": "https://github.com/GuillaumeGomez", "followers_url": "https://api.github.com/users/GuillaumeGomez/followers", "following_url": "https://api.github.com/users/GuillaumeGomez/following{/other_user}", "gists_url": "https://api.github.com/users/GuillaumeGomez/gists{/gist_id}", "starred_url": "https://api.github.com/users/GuillaumeGomez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GuillaumeGomez/subscriptions", "organizations_url": "https://api.github.com/users/GuillaumeGomez/orgs", "repos_url": "https://api.github.com/users/GuillaumeGomez/repos", "events_url": "https://api.github.com/users/GuillaumeGomez/events{/privacy}", "received_events_url": "https://api.github.com/users/GuillaumeGomez/received_events", "type": "User", "site_admin": false}, "committer": {"login": "GuillaumeGomez", "id": 3050060, "node_id": "MDQ6VXNlcjMwNTAwNjA=", "avatar_url": "https://avatars.githubusercontent.com/u/3050060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GuillaumeGomez", "html_url": "https://github.com/GuillaumeGomez", "followers_url": "https://api.github.com/users/GuillaumeGomez/followers", "following_url": "https://api.github.com/users/GuillaumeGomez/following{/other_user}", "gists_url": "https://api.github.com/users/GuillaumeGomez/gists{/gist_id}", "starred_url": "https://api.github.com/users/GuillaumeGomez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GuillaumeGomez/subscriptions", "organizations_url": "https://api.github.com/users/GuillaumeGomez/orgs", "repos_url": "https://api.github.com/users/GuillaumeGomez/repos", "events_url": "https://api.github.com/users/GuillaumeGomez/events{/privacy}", "received_events_url": "https://api.github.com/users/GuillaumeGomez/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5f93edd4b8b03a4b16e0efa6868166a6bc7ed645", "url": "https://api.github.com/repos/rust-lang/rust/commits/5f93edd4b8b03a4b16e0efa6868166a6bc7ed645", "html_url": "https://github.com/rust-lang/rust/commit/5f93edd4b8b03a4b16e0efa6868166a6bc7ed645"}], "stats": {"total": 144, "additions": 85, "deletions": 59}, "files": [{"sha": "a46e6a2ca6c150533c12d51343064d910192fa38", "filename": "src/librustdoc/clean/mod.rs", "status": "modified", "additions": 85, "deletions": 59, "changes": 144, "blob_url": "https://github.com/rust-lang/rust/blob/02a845a8268e6c6ed45f8bf2e7748ec8208af650/src%2Flibrustdoc%2Fclean%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a845a8268e6c6ed45f8bf2e7748ec8208af650/src%2Flibrustdoc%2Fclean%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Fmod.rs?ref=02a845a8268e6c6ed45f8bf2e7748ec8208af650", "patch": "@@ -11,6 +11,8 @@ pub(crate) mod types;\n pub(crate) mod utils;\n \n use rustc_ast as ast;\n+use rustc_ast::token::{Token, TokenKind};\n+use rustc_ast::tokenstream::{TokenStream, TokenTree};\n use rustc_attr as attr;\n use rustc_data_structures::fx::{FxHashMap, FxHashSet, FxIndexMap, FxIndexSet, IndexEntry};\n use rustc_hir as hir;\n@@ -2081,8 +2083,8 @@ impl<'hir> hir::intravisit::Visitor<'hir> for OneLevelVisitor<'hir> {\n     fn visit_item(&mut self, item: &'hir hir::Item<'hir>) {\n         if self.item.is_none()\n             && item.ident == self.looking_for\n-            && matches!(item.kind, hir::ItemKind::Use(_, _))\n-            || item.owner_id.def_id == self.target_def_id\n+            && (matches!(item.kind, hir::ItemKind::Use(_, _))\n+                || item.owner_id.def_id == self.target_def_id)\n         {\n             self.item = Some(item);\n         }\n@@ -2103,33 +2105,74 @@ fn get_all_import_attributes<'hir>(\n     let mut visitor = OneLevelVisitor::new(hir_map, target_def_id);\n     let mut visited = FxHashSet::default();\n     // If the item is an import and has at least a path with two parts, we go into it.\n-    while let hir::ItemKind::Use(path, _) = item.kind &&\n-        path.segments.len() > 1 &&\n-        let hir::def::Res::Def(_, def_id) = path.segments[path.segments.len() - 2].res &&\n-        visited.insert(def_id)\n-    {\n-        if let Some(hir::Node::Item(parent_item)) = hir_map.get_if_local(def_id) {\n-            // We add the attributes from this import into the list.\n-            attributes.extend_from_slice(hir_map.attrs(item.hir_id()));\n-            // We get the `Ident` we will be looking for into `item`.\n-            let looking_for = path.segments[path.segments.len() - 1].ident;\n-            visitor.reset(looking_for);\n-            hir::intravisit::walk_item(&mut visitor, parent_item);\n-            if let Some(i) = visitor.item {\n-                item = i;\n-            } else {\n-                break;\n+    while let hir::ItemKind::Use(path, _) = item.kind && visited.insert(item.hir_id()) {\n+        // We add the attributes from this import into the list.\n+        add_without_unwanted_attributes(attributes, hir_map.attrs(item.hir_id()));\n+\n+        let def_id = if path.segments.len() > 1 {\n+            match path.segments[path.segments.len() - 2].res {\n+                hir::def::Res::Def(_, def_id) => def_id,\n+                _ => break,\n+            }\n+        } else {\n+            // If the path doesn't have a parent, then the parent is the current module.\n+            tcx.parent(item.owner_id.def_id.to_def_id())\n+        };\n+\n+        let Some(parent) = hir_map.get_if_local(def_id) else { break };\n+\n+        // We get the `Ident` we will be looking for into `item`.\n+        let looking_for = path.segments[path.segments.len() - 1].ident;\n+        visitor.reset(looking_for);\n+\n+        match parent {\n+            hir::Node::Item(parent_item) => {\n+                hir::intravisit::walk_item(&mut visitor, parent_item);\n+            }\n+            hir::Node::Crate(m) => {\n+                hir::intravisit::walk_mod(\n+                    &mut visitor,\n+                    m,\n+                    tcx.local_def_id_to_hir_id(def_id.as_local().unwrap()),\n+                );\n             }\n+            _ => break,\n+        }\n+        if let Some(i) = visitor.item {\n+            item = i;\n         } else {\n             break;\n         }\n     }\n }\n \n+fn filter_tokens_from_list(\n+    args_tokens: TokenStream,\n+    should_retain: impl Fn(&TokenTree) -> bool,\n+) -> Vec<TokenTree> {\n+    let mut tokens = Vec::with_capacity(args_tokens.len());\n+    let mut skip_next_comma = false;\n+    for token in args_tokens.into_trees() {\n+        match token {\n+            TokenTree::Token(Token { kind: TokenKind::Comma, .. }, _) if skip_next_comma => {\n+                skip_next_comma = false;\n+            }\n+            token if should_retain(&token) => {\n+                skip_next_comma = false;\n+                tokens.push(token);\n+            }\n+            _ => {\n+                skip_next_comma = true;\n+            }\n+        }\n+    }\n+    tokens\n+}\n+\n /// When inlining items, we merge its attributes (and all the reexports attributes too) with the\n /// final reexport. For example:\n ///\n-/// ```\n+/// ```ignore (just an example)\n /// #[doc(hidden, cfg(feature = \"foo\"))]\n /// pub struct Foo;\n ///\n@@ -2147,55 +2190,38 @@ fn get_all_import_attributes<'hir>(\n /// * `doc(no_inline)`\n /// * `doc(hidden)`\n fn add_without_unwanted_attributes(attrs: &mut Vec<ast::Attribute>, new_attrs: &[ast::Attribute]) {\n-    use rustc_ast::token::{Token, TokenKind};\n-    use rustc_ast::tokenstream::{TokenStream, TokenTree};\n-\n     for attr in new_attrs {\n         let mut attr = attr.clone();\n         match attr.kind {\n             ast::AttrKind::Normal(ref mut normal) => {\n-                if let [ident] = &*normal.item.path.segments {\n-                    let ident = ident.ident.name;\n-                    if ident == sym::doc {\n-                        match normal.item.args {\n-                            ast::AttrArgs::Delimited(ref mut args) => {\n-                                let mut tokens = Vec::with_capacity(args.tokens.len());\n-                                let mut skip_next_comma = false;\n-                                for token in args.tokens.clone().into_trees() {\n-                                    match token {\n+                if let [ident] = &*normal.item.path.segments &&\n+                    let ident = ident.ident.name &&\n+                    ident == sym::doc\n+                {\n+                    match normal.item.args {\n+                        ast::AttrArgs::Delimited(ref mut args) => {\n+                            let tokens =\n+                                filter_tokens_from_list(args.tokens.clone(), |token| {\n+                                    !matches!(\n+                                        token,\n                                         TokenTree::Token(\n                                             Token {\n-                                                kind:\n-                                                    TokenKind::Ident(\n-                                                        sym::hidden | sym::inline | sym::no_inline,\n-                                                        _,\n-                                                    ),\n+                                                kind: TokenKind::Ident(\n+                                                    sym::hidden | sym::inline | sym::no_inline,\n+                                                    _,\n+                                                ),\n                                                 ..\n                                             },\n                                             _,\n-                                        ) => {\n-                                            skip_next_comma = true;\n-                                            continue;\n-                                        }\n-                                        TokenTree::Token(\n-                                            Token { kind: TokenKind::Comma, .. },\n-                                            _,\n-                                        ) if skip_next_comma => {\n-                                            skip_next_comma = false;\n-                                            continue;\n-                                        }\n-                                        _ => {}\n-                                    }\n-                                    skip_next_comma = false;\n-                                    tokens.push(token);\n-                                }\n-                                args.tokens = TokenStream::new(tokens);\n-                                attrs.push(attr);\n-                            }\n-                            ast::AttrArgs::Empty | ast::AttrArgs::Eq(..) => {\n-                                attrs.push(attr);\n-                                continue;\n-                            }\n+                                        ),\n+                                    )\n+                                });\n+                            args.tokens = TokenStream::new(tokens);\n+                            attrs.push(attr);\n+                        }\n+                        ast::AttrArgs::Empty | ast::AttrArgs::Eq(..) => {\n+                            attrs.push(attr);\n+                            continue;\n                         }\n                     }\n                 }"}]}