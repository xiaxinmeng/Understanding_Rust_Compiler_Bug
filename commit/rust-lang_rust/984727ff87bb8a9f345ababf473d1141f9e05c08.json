{"sha": "984727ff87bb8a9f345ababf473d1141f9e05c08", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk4NDcyN2ZmODdiYjhhOWYzNDVhYmFiZjQ3M2QxMTQxZjllMDVjMDg=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-01-28T06:41:10Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-02-03T20:05:16Z"}, "message": "extra: Introduce a mutex type for native/green threads", "tree": {"sha": "0d74ace2b51ff7d9593040082f5337a94a2fa57f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0d74ace2b51ff7d9593040082f5337a94a2fa57f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/984727ff87bb8a9f345ababf473d1141f9e05c08", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/984727ff87bb8a9f345ababf473d1141f9e05c08", "html_url": "https://github.com/rust-lang/rust/commit/984727ff87bb8a9f345ababf473d1141f9e05c08", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/984727ff87bb8a9f345ababf473d1141f9e05c08/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b49771e392983b8aeed5bed9f510b72656544544", "url": "https://api.github.com/repos/rust-lang/rust/commits/b49771e392983b8aeed5bed9f510b72656544544", "html_url": "https://github.com/rust-lang/rust/commit/b49771e392983b8aeed5bed9f510b72656544544"}], "stats": {"total": 564, "additions": 564, "deletions": 0}, "files": [{"sha": "6fb436d35281f7b8200e97ae41f9551ee23d01bb", "filename": "src/libextra/sync/mutex.rs", "status": "added", "additions": 564, "deletions": 0, "changes": 564, "blob_url": "https://github.com/rust-lang/rust/blob/984727ff87bb8a9f345ababf473d1141f9e05c08/src%2Flibextra%2Fsync%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/984727ff87bb8a9f345ababf473d1141f9e05c08/src%2Flibextra%2Fsync%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fsync%2Fmutex.rs?ref=984727ff87bb8a9f345ababf473d1141f9e05c08", "patch": "@@ -0,0 +1,564 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! A proper mutex implementation regardless of the \"flavor of task\" which is\n+//! acquiring the lock.\n+\n+// # Implementation of Rust mutexes\n+//\n+// Most answers to the question of \"how do I use a mutex\" are \"use pthreads\",\n+// but for Rust this isn't quite sufficient. Green threads cannot acquire an OS\n+// mutex because they can context switch among many OS threads, leading to\n+// deadlocks with other green threads.\n+//\n+// Another problem for green threads grabbing an OS mutex is that POSIX dictates\n+// that unlocking a mutex on a different thread from where it was locked is\n+// undefined behavior. Remember that green threads can migrate among OS threads,\n+// so this would mean that we would have to pin green threads to OS threads,\n+// which is less than ideal.\n+//\n+// ## Using deschedule/reawaken\n+//\n+// We already have primitives for descheduling/reawakening tasks, so they're the\n+// first obvious choice when implementing a mutex. The idea would be to have a\n+// concurrent queue that everyone is pushed on to, and then the owner of the\n+// mutex is the one popping from the queue.\n+//\n+// Unfortunately, this is not very performant for native tasks. The suspected\n+// reason for this is that each native thread is suspended on its own condition\n+// variable, unique from all the other threads. In this situation, the kernel\n+// has no idea what the scheduling semantics are of the user program, so all of\n+// the threads are distributed among all cores on the system. This ends up\n+// having very expensive wakeups of remote cores high up in the profile when\n+// handing off the mutex among native tasks. On the other hand, when using an OS\n+// mutex, the kernel knows that all native threads are contended on the same\n+// mutex, so they're in theory all migrated to a single core (fast context\n+// switching).\n+//\n+// ## Mixing implementations\n+//\n+// From that above information, we have two constraints. The first is that\n+// green threads can't touch os mutexes, and the second is that native tasks\n+// pretty much *must* touch an os mutex.\n+//\n+// As a compromise, the queueing implementation is used for green threads and\n+// the os mutex is used for native threads (why not have both?). This ends up\n+// leading to fairly decent performance for both native threads and green\n+// threads on various workloads (uncontended and contended).\n+//\n+// The crux of this implementation is an atomic work which is CAS'd on many many\n+// times in order to manage a few flags about who's blocking where and whether\n+// it's locked or not.\n+\n+use std::rt::local::Local;\n+use std::rt::task::{BlockedTask, Task};\n+use std::rt::thread::Thread;\n+use std::sync::atomics;\n+use std::unstable::mutex;\n+\n+use q = sync::mpsc_intrusive;\n+\n+pub static LOCKED: uint = 1 << 0;\n+pub static GREEN_BLOCKED: uint = 1 << 1;\n+pub static NATIVE_BLOCKED: uint = 1 << 2;\n+\n+/// A mutual exclusion primitive useful for protecting shared data\n+///\n+/// This mutex is an implementation of a lock for all flavors of tasks which may\n+/// be grabbing. A common problem with green threads is that they cannot grab\n+/// locks (if they reschedule during the lock a contender could deadlock the\n+/// system), but this mutex does *not* suffer this problem.\n+///\n+/// This mutex will properly block tasks waiting for the lock to become\n+/// available. The mutex can also be statically initialized or created via a\n+/// `new` constructor.\n+///\n+/// # Example\n+///\n+/// ```rust\n+/// use extra::sync::mutex::Mutex;\n+///\n+/// let mut m = Mutex::new();\n+/// let guard = m.lock();\n+/// // do some work\n+/// drop(guard); // unlock the lock\n+///\n+/// {\n+///     let _g = m.lock();\n+///     // do some work in a scope\n+/// }\n+///\n+/// // now the mutex is unlocked\n+/// ```\n+pub struct Mutex {\n+    priv lock: StaticMutex,\n+}\n+\n+#[deriving(Eq)]\n+enum Flavor {\n+    Unlocked,\n+    TryLockAcquisition,\n+    GreenAcquisition,\n+    NativeAcquisition,\n+}\n+\n+/// The static mutex type is provided to allow for static allocation of mutexes.\n+///\n+/// Note that this is a separate type because using a Mutex correctly means that\n+/// it needs to have a destructor run. In Rust, statics are not allowed to have\n+/// destructors. As a result, a `StaticMutex` has one extra method when compared\n+/// to a `Mutex`, a `destroy` method. This method is unsafe to call, and\n+/// documentation can be found directly on the method.\n+///\n+/// # Example\n+///\n+/// ```rust\n+/// use extra::sync::mutex::{StaticMutex, MUTEX_INIT};\n+///\n+/// static mut LOCK: StaticMutex = MUTEX_INIT;\n+///\n+/// unsafe {\n+///     let _g = LOCK.lock();\n+///     // do some productive work\n+/// }\n+/// // lock is unlocked here.\n+/// ```\n+pub struct StaticMutex {\n+    /// Current set of flags on this mutex\n+    priv state: atomics::AtomicUint,\n+    /// Type of locking operation currently on this mutex\n+    priv flavor: Flavor,\n+    /// uint-cast of the green thread waiting for this mutex\n+    priv green_blocker: uint,\n+    /// uint-cast of the native thread waiting for this mutex\n+    priv native_blocker: uint,\n+    /// an OS mutex used by native threads\n+    priv lock: mutex::Mutex,\n+\n+    /// A concurrent mpsc queue used by green threads, along with a count used\n+    /// to figure out when to dequeue and enqueue.\n+    priv q: q::Queue<uint>,\n+    priv green_cnt: atomics::AtomicUint,\n+}\n+\n+/// An RAII implementation of a \"scoped lock\" of a mutex. When this structure is\n+/// dropped (falls out of scope), the lock will be unlocked.\n+pub struct Guard<'a> {\n+    priv lock: &'a mut StaticMutex,\n+}\n+\n+/// Static initialization of a mutex. This constant can be used to initialize\n+/// other mutex constants.\n+pub static MUTEX_INIT: StaticMutex = StaticMutex {\n+    lock: mutex::MUTEX_INIT,\n+    state: atomics::INIT_ATOMIC_UINT,\n+    flavor: Unlocked,\n+    green_blocker: 0,\n+    native_blocker: 0,\n+    green_cnt: atomics::INIT_ATOMIC_UINT,\n+    q: q::Queue {\n+        head: atomics::INIT_ATOMIC_UINT,\n+        tail: 0 as *mut q::Node<uint>,\n+        stub: q::DummyNode {\n+            next: atomics::INIT_ATOMIC_UINT,\n+        }\n+    }\n+};\n+\n+impl StaticMutex {\n+    /// Attempts to grab this lock, see `Mutex::try_lock`\n+    pub fn try_lock<'a>(&'a mut self) -> Option<Guard<'a>> {\n+        // Attempt to steal the mutex from an unlocked state.\n+        //\n+        // FIXME: this can mess up the fairness of the mutex, seems bad\n+        match self.state.compare_and_swap(0, LOCKED, atomics::SeqCst) {\n+            0 => {\n+                assert!(self.flavor == Unlocked);\n+                self.flavor = TryLockAcquisition;\n+                Some(Guard::new(self))\n+            }\n+            _ => None\n+        }\n+    }\n+\n+    /// Acquires this lock, see `Mutex::lock`\n+    pub fn lock<'a>(&'a mut self) -> Guard<'a> {\n+        // First, attempt to steal the mutex from an unlocked state. The \"fast\n+        // path\" needs to have as few atomic instructions as possible, and this\n+        // one cmpxchg is already pretty expensive.\n+        //\n+        // FIXME: this can mess up the fairness of the mutex, seems bad\n+        match self.state.compare_and_swap(0, LOCKED, atomics::SeqCst) {\n+            0 => {\n+                assert!(self.flavor == Unlocked);\n+                self.flavor = TryLockAcquisition;\n+                return Guard::new(self)\n+            }\n+            _ => {}\n+        }\n+\n+        // After we've failed the fast path, then we delegate to the differnet\n+        // locking protocols for green/native tasks. This will select two tasks\n+        // to continue further (one native, one green).\n+        let t: ~Task = Local::take();\n+        let can_block = t.can_block();\n+        let native_bit;\n+        if can_block {\n+            self.native_lock(t);\n+            native_bit = NATIVE_BLOCKED;\n+        } else {\n+            self.green_lock(t);\n+            native_bit = GREEN_BLOCKED;\n+        }\n+\n+        // After we've arbitrated among task types, attempt to re-acquire the\n+        // lock (avoids a deschedule). This is very important to do in order to\n+        // allow threads coming out of the native_lock function to try their\n+        // best to not hit a cvar in deschedule.\n+        let mut old = match self.state.compare_and_swap(0, LOCKED,\n+                                                        atomics::SeqCst) {\n+            0 => {\n+                self.flavor = if can_block {\n+                    NativeAcquisition\n+                } else {\n+                    GreenAcquisition\n+                };\n+                return Guard::new(self)\n+            }\n+            old => old,\n+        };\n+\n+        // Alright, everything else failed. We need to deschedule ourselves and\n+        // flag ourselves as waiting. Note that this case should only happen\n+        // regularly in native/green contention. Due to try_lock and the header\n+        // of lock stealing the lock, it's also possible for native/native\n+        // contention to hit this location, but as less common.\n+        let t: ~Task = Local::take();\n+        t.deschedule(1, |task| {\n+            let task = unsafe { task.cast_to_uint() };\n+            if can_block {\n+                assert_eq!(self.native_blocker, 0);\n+                self.native_blocker = task;\n+            } else {\n+                assert_eq!(self.green_blocker, 0);\n+                self.green_blocker = task;\n+            }\n+\n+            loop {\n+                assert_eq!(old & native_bit, 0);\n+                // If the old state was locked, then we need to flag ourselves\n+                // as blocking in the state. If the old state was unlocked, then\n+                // we attempt to acquire the mutex. Everything here is a CAS\n+                // loop that'll eventually make progress.\n+                if old & LOCKED != 0 {\n+                    old = match self.state.compare_and_swap(old,\n+                                                            old | native_bit,\n+                                                            atomics::SeqCst) {\n+                        n if n == old => return Ok(()),\n+                        n => n\n+                    };\n+                } else {\n+                    assert_eq!(old, 0);\n+                    old = match self.state.compare_and_swap(old,\n+                                                            old | LOCKED,\n+                                                            atomics::SeqCst) {\n+                        n if n == old => {\n+                            assert_eq!(self.flavor, Unlocked);\n+                            if can_block {\n+                                self.native_blocker = 0;\n+                                self.flavor = NativeAcquisition;\n+                            } else {\n+                                self.green_blocker = 0;\n+                                self.flavor = GreenAcquisition;\n+                            }\n+                            return Err(unsafe {\n+                                BlockedTask::cast_from_uint(task)\n+                            })\n+                        }\n+                        n => n,\n+                    };\n+                }\n+            }\n+        });\n+\n+        Guard::new(self)\n+    }\n+\n+    // Tasks which can block are super easy. These tasks just call the blocking\n+    // `lock()` function on an OS mutex\n+    fn native_lock(&mut self, t: ~Task) {\n+        Local::put(t);\n+        unsafe { self.lock.lock(); }\n+    }\n+\n+    fn native_unlock(&mut self) {\n+        unsafe { self.lock.unlock(); }\n+    }\n+\n+    fn green_lock(&mut self, t: ~Task) {\n+        // Green threads flag their presence with an atomic counter, and if they\n+        // fail to be the first to the mutex, they enqueue themselves on a\n+        // concurrent internal queue with a stack-allocated node.\n+        //\n+        // FIXME: There isn't a cancellation currently of an enqueue, forcing\n+        //        the unlocker to spin for a bit.\n+        if self.green_cnt.fetch_add(1, atomics::SeqCst) == 0 {\n+            Local::put(t);\n+            return\n+        }\n+\n+        let mut node = q::Node::new(0);\n+        t.deschedule(1, |task| {\n+            unsafe {\n+                node.data = task.cast_to_uint();\n+                self.q.push(&mut node);\n+            }\n+            Ok(())\n+        });\n+    }\n+\n+    fn green_unlock(&mut self) {\n+        // If we're the only green thread, then no need to check the queue,\n+        // otherwise the fixme above forces us to spin for a bit.\n+        if self.green_cnt.fetch_sub(1, atomics::SeqCst) == 1 { return }\n+        let node;\n+        loop {\n+            match unsafe { self.q.pop() } {\n+                Some(t) => { node = t; break; }\n+                None => Thread::yield_now(),\n+            }\n+        }\n+        let task = unsafe { BlockedTask::cast_from_uint((*node).data) };\n+        task.wake().map(|t| t.reawaken());\n+    }\n+\n+    fn unlock(&mut self) {\n+        // Unlocking this mutex is a little tricky. We favor any task that is\n+        // manually blocked (not in each of the separate locks) in order to help\n+        // provide a little fairness (green threads will wake up the pending\n+        // native thread and native threads will wake up the pending green\n+        // thread).\n+        //\n+        // There's also the question of when we unlock the actual green/native\n+        // locking halves as well. If we're waking up someone, then we can wait\n+        // to unlock until we've acquired the task to wake up (we're guaranteed\n+        // the mutex memory is still valid when there's contenders), but as soon\n+        // as we don't find any contenders we must unlock the mutex, and *then*\n+        // flag the mutex as unlocked.\n+        //\n+        // This flagging can fail, leading to another round of figuring out if a\n+        // task needs to be woken, and in this case it's ok that the \"mutex\n+        // halves\" are unlocked, we're just mainly dealing with the atomic state\n+        // of the outer mutex.\n+        let flavor = self.flavor;\n+        self.flavor = Unlocked;\n+\n+        let mut state = self.state.load(atomics::SeqCst);\n+        let mut unlocked = false;\n+        let task;\n+        loop {\n+            assert!(state & LOCKED != 0);\n+            if state & GREEN_BLOCKED != 0 {\n+                self.unset(state, GREEN_BLOCKED);\n+                task = unsafe {\n+                    BlockedTask::cast_from_uint(self.green_blocker)\n+                };\n+                self.green_blocker = 0;\n+                self.flavor = GreenAcquisition;\n+                break;\n+            } else if state & NATIVE_BLOCKED != 0 {\n+                self.unset(state, NATIVE_BLOCKED);\n+                task = unsafe {\n+                    BlockedTask::cast_from_uint(self.native_blocker)\n+                };\n+                self.native_blocker = 0;\n+                self.flavor = NativeAcquisition;\n+                break;\n+            } else {\n+                assert_eq!(state, LOCKED);\n+                if !unlocked {\n+                    match flavor {\n+                        GreenAcquisition => { self.green_unlock(); }\n+                        NativeAcquisition => { self.native_unlock(); }\n+                        TryLockAcquisition => {}\n+                        Unlocked => unreachable!()\n+                    }\n+                    unlocked = true;\n+                }\n+                match self.state.compare_and_swap(LOCKED, 0, atomics::SeqCst) {\n+                    LOCKED => return,\n+                    n => { state = n; }\n+                }\n+            }\n+        }\n+        if !unlocked {\n+            match flavor {\n+                GreenAcquisition => { self.green_unlock(); }\n+                NativeAcquisition => { self.native_unlock(); }\n+                TryLockAcquisition => {}\n+                Unlocked => unreachable!()\n+            }\n+        }\n+\n+        task.wake().map(|t| t.reawaken());\n+    }\n+\n+    /// Loops around a CAS to unset the `bit` in `state`\n+    fn unset(&mut self, mut state: uint, bit: uint) {\n+        loop {\n+            assert!(state & bit != 0);\n+            let new = state ^ bit;\n+            match self.state.compare_and_swap(state, new, atomics::SeqCst) {\n+                n if n == state => break,\n+                n => { state = n; }\n+            }\n+        }\n+    }\n+\n+    /// Deallocates resources associated with this static mutex.\n+    ///\n+    /// This method is unsafe because it provides no guarantees that there are\n+    /// no active users of this mutex, and safety is not guaranteed if there are\n+    /// active users of this mutex.\n+    ///\n+    /// This method is required to ensure that there are no memory leaks on\n+    /// *all* platforms. It may be the case that some platforms do not leak\n+    /// memory if this method is not called, but this is not guaranteed to be\n+    /// true on all platforms.\n+    pub unsafe fn destroy(&mut self) {\n+        self.lock.destroy()\n+    }\n+}\n+\n+impl Mutex {\n+    /// Creates a new mutex in an unlocked state ready for use.\n+    pub fn new() -> Mutex {\n+        Mutex {\n+            lock: StaticMutex {\n+                state: atomics::AtomicUint::new(0),\n+                flavor: Unlocked,\n+                green_blocker: 0,\n+                native_blocker: 0,\n+                green_cnt: atomics::AtomicUint::new(0),\n+                q: q::Queue::new(),\n+                lock: unsafe { mutex::Mutex::new() },\n+            }\n+        }\n+    }\n+\n+    /// Attempts to acquire this lock.\n+    ///\n+    /// If the lock could not be acquired at this time, then `None` is returned.\n+    /// Otherwise, an RAII guard is returned. The lock will be unlocked when the\n+    /// guard is dropped.\n+    ///\n+    /// This function does not block.\n+    pub fn try_lock<'a>(&'a mut self) -> Option<Guard<'a>> {\n+        self.lock.try_lock()\n+    }\n+\n+    /// Acquires a mutex, blocking the current task until it is able to do so.\n+    ///\n+    /// This function will block the local task until it is availble to acquire\n+    /// the mutex. Upon returning, the task is the only task with the mutex\n+    /// held. An RAII guard is returned to allow scoped unlock of the lock. When\n+    /// the guard goes out of scope, the mutex will be unlocked.\n+    pub fn lock<'a>(&'a mut self) -> Guard<'a> { self.lock.lock() }\n+}\n+\n+impl<'a> Guard<'a> {\n+    fn new<'b>(lock: &'b mut StaticMutex) -> Guard<'b> {\n+        if cfg!(debug) {\n+            assert!(lock.flavor != Unlocked);\n+            assert!(lock.state.load(atomics::SeqCst) & LOCKED != 0);\n+        }\n+        Guard { lock: lock }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl<'a> Drop for Guard<'a> {\n+    #[inline]\n+    fn drop(&mut self) {\n+        self.lock.unlock();\n+    }\n+}\n+\n+impl Drop for Mutex {\n+    fn drop(&mut self) {\n+        // This is actually safe b/c we know that there is no further usage of\n+        // this mutex (it's up to the user to arrange for a mutex to get\n+        // dropped, that's not our job)\n+        unsafe { self.lock.destroy() }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+    extern mod native;\n+    use super::{Mutex, StaticMutex, MUTEX_INIT};\n+\n+    #[test]\n+    fn smoke() {\n+        let mut m = Mutex::new();\n+        drop(m.lock());\n+        drop(m.lock());\n+    }\n+\n+    #[test]\n+    fn smoke_static() {\n+        static mut m: StaticMutex = MUTEX_INIT;\n+        unsafe {\n+            drop(m.lock());\n+            drop(m.lock());\n+            m.destroy();\n+        }\n+    }\n+\n+    #[test]\n+    fn lots_and_lots() {\n+        static mut m: StaticMutex = MUTEX_INIT;\n+        static mut CNT: uint = 0;\n+        static M: uint = 1000;\n+        static N: uint = 3;\n+\n+        fn inc() {\n+            for _ in range(0, M) {\n+                unsafe {\n+                    let _g = m.lock();\n+                    CNT += 1;\n+                }\n+            }\n+        }\n+\n+        let (p, c) = SharedChan::new();\n+        for _ in range(0, N) {\n+            let c2 = c.clone();\n+            do native::task::spawn { inc(); c2.send(()); }\n+            let c2 = c.clone();\n+            do spawn { inc(); c2.send(()); }\n+        }\n+\n+        drop(c);\n+        for _ in range(0, 2 * N) {\n+            p.recv();\n+        }\n+        assert_eq!(unsafe {CNT}, M * N * 2);\n+        unsafe {\n+            m.destroy();\n+        }\n+    }\n+\n+    #[test]\n+    fn trylock() {\n+        let mut m = Mutex::new();\n+        assert!(m.try_lock().is_some());\n+    }\n+}"}]}