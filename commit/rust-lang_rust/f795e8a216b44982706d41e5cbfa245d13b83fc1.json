{"sha": "f795e8a216b44982706d41e5cbfa245d13b83fc1", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY3OTVlOGEyMTZiNDQ5ODI3MDZkNDFlNWNiZmEyNDVkMTNiODNmYzE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-01-10T12:18:46Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-01-10T12:18:46Z"}, "message": "Auto merge of #67397 - michaelwoerister:query-keys-in-self-profiling, r=wesleywiser\n\nself-profiling: Support recording query keys\n\nThis PR makes self-profiling able to record query keys. The implementation is not as efficient as it could be yet (all query keys except for `DefId`s cause string data to be duplicated) and the rendered strings could be nicer too. But the implementation is functional and introduces the basic framework for emitting per-query-invocation event data.\n\nI tried to add proper documentation on how everything works. Let me know if more documentation is needed.\n\nr? @wesleywiser\n\n@Mark-Simulacrum, heads up: This updates `measureme` to 0.7.0 which means that `summarize` on perf.rlo needs to be update accordingly once this is merged.", "tree": {"sha": "54b00a0ff92055a4ec8c3fa0135f0585594f05c8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/54b00a0ff92055a4ec8c3fa0135f0585594f05c8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f795e8a216b44982706d41e5cbfa245d13b83fc1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f795e8a216b44982706d41e5cbfa245d13b83fc1", "html_url": "https://github.com/rust-lang/rust/commit/f795e8a216b44982706d41e5cbfa245d13b83fc1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f795e8a216b44982706d41e5cbfa245d13b83fc1/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2d8d559bbecf6272eb41f8a800e319238aa9d621", "url": "https://api.github.com/repos/rust-lang/rust/commits/2d8d559bbecf6272eb41f8a800e319238aa9d621", "html_url": "https://github.com/rust-lang/rust/commit/2d8d559bbecf6272eb41f8a800e319238aa9d621"}, {"sha": "ad65e3e6bc8ded92db38507b84ec4a2bf2677d62", "url": "https://api.github.com/repos/rust-lang/rust/commits/ad65e3e6bc8ded92db38507b84ec4a2bf2677d62", "html_url": "https://github.com/rust-lang/rust/commit/ad65e3e6bc8ded92db38507b84ec4a2bf2677d62"}], "stats": {"total": 675, "additions": 550, "deletions": 125}, "files": [{"sha": "bbe014baa498b39019ce05d94fbcd5705df3e0f0", "filename": "Cargo.lock", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -1995,9 +1995,9 @@ dependencies = [\n \n [[package]]\n name = \"measureme\"\n-version = \"0.5.0\"\n+version = \"0.7.1\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"c420bbc064623934620b5ab2dc0cf96451b34163329e82f95e7fa1b7b99a6ac8\"\n+checksum = \"fef709d3257013bba7cff14fc504e07e80631d3fe0f6d38ce63b8f6510ccb932\"\n dependencies = [\n  \"byteorder\",\n  \"memmap\",\n@@ -3079,6 +3079,7 @@ dependencies = [\n  \"graphviz\",\n  \"jobserver\",\n  \"log\",\n+ \"measureme\",\n  \"parking_lot\",\n  \"polonius-engine\",\n  \"rustc-rayon\","}, {"sha": "bca960202316cbe36bc77f37ff88751ad4e48940", "filename": "src/librustc/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2FCargo.toml?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -36,5 +36,6 @@ parking_lot = \"0.9\"\n byteorder = { version = \"1.3\" }\n chalk-engine = { version = \"0.9.0\", default-features=false }\n smallvec = { version = \"1.0\", features = [\"union\", \"may_dangle\"] }\n+measureme = \"0.7.1\"\n rustc_error_codes = { path = \"../librustc_error_codes\" }\n rustc_session = { path = \"../librustc_session\" }"}, {"sha": "625aa25978e6eb265afdd588be4bb649d9363a7a", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 28, "deletions": 8, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -2,6 +2,7 @@ use crate::ty::{self, TyCtxt};\n use errors::Diagnostic;\n use parking_lot::{Condvar, Mutex};\n use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n+use rustc_data_structures::profiling::QueryInvocationId;\n use rustc_data_structures::sharded::{self, Sharded};\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n use rustc_data_structures::sync::{AtomicU32, AtomicU64, Lock, Lrc, Ordering};\n@@ -11,7 +12,7 @@ use std::collections::hash_map::Entry;\n use std::env;\n use std::hash::Hash;\n use std::mem;\n-use std::sync::atomic::Ordering::SeqCst;\n+use std::sync::atomic::Ordering::Relaxed;\n \n use crate::ich::{Fingerprint, StableHashingContext, StableHashingContextProvider};\n \n@@ -25,6 +26,12 @@ use super::serialized::{SerializedDepGraph, SerializedDepNodeIndex};\n #[derive(Clone)]\n pub struct DepGraph {\n     data: Option<Lrc<DepGraphData>>,\n+\n+    /// This field is used for assigning DepNodeIndices when running in\n+    /// non-incremental mode. Even in non-incremental mode we make sure that\n+    /// each task has a `DepNodeIndex` that uniquely identifies it. This unique\n+    /// ID is used for self-profiling.\n+    virtual_dep_node_index: Lrc<AtomicU32>,\n }\n \n rustc_index::newtype_index! {\n@@ -35,6 +42,13 @@ impl DepNodeIndex {\n     pub const INVALID: DepNodeIndex = DepNodeIndex::MAX;\n }\n \n+impl std::convert::From<DepNodeIndex> for QueryInvocationId {\n+    #[inline]\n+    fn from(dep_node_index: DepNodeIndex) -> Self {\n+        QueryInvocationId(dep_node_index.as_u32())\n+    }\n+}\n+\n #[derive(PartialEq)]\n pub enum DepNodeColor {\n     Red,\n@@ -105,11 +119,12 @@ impl DepGraph {\n                 previous: prev_graph,\n                 colors: DepNodeColorMap::new(prev_graph_node_count),\n             })),\n+            virtual_dep_node_index: Lrc::new(AtomicU32::new(0)),\n         }\n     }\n \n     pub fn new_disabled() -> DepGraph {\n-        DepGraph { data: None }\n+        DepGraph { data: None, virtual_dep_node_index: Lrc::new(AtomicU32::new(0)) }\n     }\n \n     /// Returns `true` if we are actually building the full dep-graph, and `false` otherwise.\n@@ -322,7 +337,7 @@ impl DepGraph {\n \n             (result, dep_node_index)\n         } else {\n-            (task(cx, arg), DepNodeIndex::INVALID)\n+            (task(cx, arg), self.next_virtual_depnode_index())\n         }\n     }\n \n@@ -352,7 +367,7 @@ impl DepGraph {\n             let dep_node_index = data.current.complete_anon_task(dep_kind, task_deps);\n             (result, dep_node_index)\n         } else {\n-            (op(), DepNodeIndex::INVALID)\n+            (op(), self.next_virtual_depnode_index())\n         }\n     }\n \n@@ -478,8 +493,8 @@ impl DepGraph {\n             let current_dep_graph = &self.data.as_ref().unwrap().current;\n \n             Some((\n-                current_dep_graph.total_read_count.load(SeqCst),\n-                current_dep_graph.total_duplicate_read_count.load(SeqCst),\n+                current_dep_graph.total_read_count.load(Relaxed),\n+                current_dep_graph.total_duplicate_read_count.load(Relaxed),\n             ))\n         } else {\n             None\n@@ -877,6 +892,11 @@ impl DepGraph {\n             }\n         }\n     }\n+\n+    fn next_virtual_depnode_index(&self) -> DepNodeIndex {\n+        let index = self.virtual_dep_node_index.fetch_add(1, Relaxed);\n+        DepNodeIndex::from_u32(index)\n+    }\n }\n \n /// A \"work product\" is an intermediate result that we save into the\n@@ -1087,7 +1107,7 @@ impl DepGraphData {\n             if let Some(task_deps) = icx.task_deps {\n                 let mut task_deps = task_deps.lock();\n                 if cfg!(debug_assertions) {\n-                    self.current.total_read_count.fetch_add(1, SeqCst);\n+                    self.current.total_read_count.fetch_add(1, Relaxed);\n                 }\n                 if task_deps.read_set.insert(source) {\n                     task_deps.reads.push(source);\n@@ -1105,7 +1125,7 @@ impl DepGraphData {\n                         }\n                     }\n                 } else if cfg!(debug_assertions) {\n-                    self.current.total_duplicate_read_count.fetch_add(1, SeqCst);\n+                    self.current.total_duplicate_read_count.fetch_add(1, Relaxed);\n                 }\n             }\n         })"}, {"sha": "dbb6a1080e6d46f6a305ea5ab0a8dd186d718226", "filename": "src/librustc/ty/query/config.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -2,8 +2,7 @@ use crate::dep_graph::SerializedDepNodeIndex;\n use crate::dep_graph::{DepKind, DepNode};\n use crate::ty::query::plumbing::CycleError;\n use crate::ty::query::queries;\n-use crate::ty::query::QueryCache;\n-use crate::ty::query::{Query, QueryName};\n+use crate::ty::query::{Query, QueryCache};\n use crate::ty::TyCtxt;\n use rustc_data_structures::profiling::ProfileCategory;\n use rustc_hir::def_id::{CrateNum, DefId};\n@@ -20,7 +19,7 @@ use std::hash::Hash;\n // FIXME(eddyb) false positive, the lifetime parameter is used for `Key`/`Value`.\n #[allow(unused_lifetimes)]\n pub trait QueryConfig<'tcx> {\n-    const NAME: QueryName;\n+    const NAME: &'static str;\n     const CATEGORY: ProfileCategory;\n \n     type Key: Eq + Hash + Clone + Debug;"}, {"sha": "6b272ab3d4a9bfd1a7feaad08d3a0252e6a7f5e3", "filename": "src/librustc/ty/query/mod.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -81,6 +81,9 @@ pub(crate) use self::config::QueryDescription;\n mod on_disk_cache;\n pub use self::on_disk_cache::OnDiskCache;\n \n+mod profiling_support;\n+pub use self::profiling_support::{IntoSelfProfilingString, QueryKeyStringBuilder};\n+\n // Each of these queries corresponds to a function pointer field in the\n // `Providers` struct for requesting a value of that type, and a method\n // on `tcx: TyCtxt` (and `tcx.at(span)`) for doing that request in a way"}, {"sha": "33f2a5e3ffa75364151787c4ca507684553b81a1", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 80, "deletions": 65, "changes": 145, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -13,6 +13,8 @@ use errors::{struct_span_err, Diagnostic, DiagnosticBuilder, FatalError, Handler\n #[cfg(not(parallel_compiler))]\n use rustc_data_structures::cold_path;\n use rustc_data_structures::fx::{FxHashMap, FxHasher};\n+#[cfg(parallel_compiler)]\n+use rustc_data_structures::profiling::TimingGuard;\n use rustc_data_structures::sharded::Sharded;\n use rustc_data_structures::sync::{Lock, Lrc};\n use rustc_data_structures::thin_vec::ThinVec;\n@@ -82,6 +84,19 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n     /// for some compile-time benchmarks.\n     #[inline(always)]\n     pub(super) fn try_get(tcx: TyCtxt<'tcx>, span: Span, key: &Q::Key) -> TryGetJob<'a, 'tcx, Q> {\n+        // Handling the `query_blocked_prof_timer` is a bit weird because of the\n+        // control flow in this function: Blocking is implemented by\n+        // awaiting a running job and, once that is done, entering the loop below\n+        // again from the top. In that second iteration we will hit the\n+        // cache which provides us with the information we need for\n+        // finishing the \"query-blocked\" event.\n+        //\n+        // We thus allocate `query_blocked_prof_timer` outside the loop,\n+        // initialize it during the first iteration and finish it during the\n+        // second iteration.\n+        #[cfg(parallel_compiler)]\n+        let mut query_blocked_prof_timer: Option<TimingGuard<'_>> = None;\n+\n         let cache = Q::query_cache(tcx);\n         loop {\n             // We compute the key's hash once and then use it for both the\n@@ -95,7 +110,17 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n             if let Some((_, value)) =\n                 lock.results.raw_entry().from_key_hashed_nocheck(key_hash, key)\n             {\n-                tcx.prof.query_cache_hit(Q::NAME);\n+                if unlikely!(tcx.prof.enabled()) {\n+                    tcx.prof.query_cache_hit(value.index.into());\n+\n+                    #[cfg(parallel_compiler)]\n+                    {\n+                        if let Some(prof_timer) = query_blocked_prof_timer.take() {\n+                            prof_timer.finish_with_query_invocation_id(value.index.into());\n+                        }\n+                    }\n+                }\n+\n                 let result = (value.value.clone(), value.index);\n                 #[cfg(debug_assertions)]\n                 {\n@@ -104,9 +129,6 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n                 return TryGetJob::JobCompleted(result);\n             }\n \n-            #[cfg(parallel_compiler)]\n-            let query_blocked_prof_timer;\n-\n             let job = match lock.active.entry((*key).clone()) {\n                 Entry::Occupied(entry) => {\n                     match *entry.get() {\n@@ -116,7 +138,7 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n                             // self-profiler.\n                             #[cfg(parallel_compiler)]\n                             {\n-                                query_blocked_prof_timer = tcx.prof.query_blocked(Q::NAME);\n+                                query_blocked_prof_timer = Some(tcx.prof.query_blocked());\n                             }\n \n                             job.clone()\n@@ -153,11 +175,6 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n             {\n                 let result = job.r#await(tcx, span);\n \n-                // This `drop()` is not strictly necessary as the binding\n-                // would go out of scope anyway. But it's good to have an\n-                // explicit marker of how far the measurement goes.\n-                drop(query_blocked_prof_timer);\n-\n                 if let Err(cycle) = result {\n                     return TryGetJob::Cycle(Q::handle_cycle_error(tcx, cycle));\n                 }\n@@ -347,7 +364,7 @@ impl<'tcx> TyCtxt<'tcx> {\n \n     #[inline(never)]\n     pub(super) fn get_query<Q: QueryDescription<'tcx>>(self, span: Span, key: Q::Key) -> Q::Value {\n-        debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME.as_str(), key, span);\n+        debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n \n         let job = match JobOwner::try_get(self, span, &key) {\n             TryGetJob::NotYetStarted(job) => job,\n@@ -366,15 +383,15 @@ impl<'tcx> TyCtxt<'tcx> {\n         }\n \n         if Q::ANON {\n-            let prof_timer = self.prof.query_provider(Q::NAME);\n+            let prof_timer = self.prof.query_provider();\n \n             let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n                 self.start_query(job.job.clone(), diagnostics, |tcx| {\n                     tcx.dep_graph.with_anon_task(Q::dep_kind(), || Q::compute(tcx, key))\n                 })\n             });\n \n-            drop(prof_timer);\n+            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n             self.dep_graph.read_index(dep_node_index);\n \n@@ -436,8 +453,9 @@ impl<'tcx> TyCtxt<'tcx> {\n         let result = if Q::cache_on_disk(self, key.clone(), None)\n             && self.sess.opts.debugging_opts.incremental_queries\n         {\n-            let _prof_timer = self.prof.incr_cache_loading(Q::NAME);\n+            let prof_timer = self.prof.incr_cache_loading();\n             let result = Q::try_load_from_disk(self, prev_dep_node_index);\n+            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n             // We always expect to find a cached result for things that\n             // can be forced from `DepNode`.\n@@ -457,11 +475,13 @@ impl<'tcx> TyCtxt<'tcx> {\n         } else {\n             // We could not load a result from the on-disk cache, so\n             // recompute.\n-            let _prof_timer = self.prof.query_provider(Q::NAME);\n+            let prof_timer = self.prof.query_provider();\n \n             // The dep-graph for this computation is already in-place.\n             let result = self.dep_graph.with_ignore(|| Q::compute(self, key));\n \n+            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+\n             result\n         };\n \n@@ -523,7 +543,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             dep_node\n         );\n \n-        let prof_timer = self.prof.query_provider(Q::NAME);\n+        let prof_timer = self.prof.query_provider();\n \n         let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n             self.start_query(job.job.clone(), diagnostics, |tcx| {\n@@ -541,7 +561,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             })\n         });\n \n-        drop(prof_timer);\n+        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n         if unlikely!(!diagnostics.is_empty()) {\n             if dep_node.kind != crate::dep_graph::DepKind::Null {\n@@ -572,17 +592,19 @@ impl<'tcx> TyCtxt<'tcx> {\n \n         let dep_node = Q::to_dep_node(self, &key);\n \n-        if self.dep_graph.try_mark_green_and_read(self, &dep_node).is_none() {\n-            // A None return from `try_mark_green_and_read` means that this is either\n-            // a new dep node or that the dep node has already been marked red.\n-            // Either way, we can't call `dep_graph.read()` as we don't have the\n-            // DepNodeIndex. We must invoke the query itself. The performance cost\n-            // this introduces should be negligible as we'll immediately hit the\n-            // in-memory cache, or another query down the line will.\n-\n-            let _ = self.get_query::<Q>(DUMMY_SP, key);\n-        } else {\n-            self.prof.query_cache_hit(Q::NAME);\n+        match self.dep_graph.try_mark_green_and_read(self, &dep_node) {\n+            None => {\n+                // A None return from `try_mark_green_and_read` means that this is either\n+                // a new dep node or that the dep node has already been marked red.\n+                // Either way, we can't call `dep_graph.read()` as we don't have the\n+                // DepNodeIndex. We must invoke the query itself. The performance cost\n+                // this introduces should be negligible as we'll immediately hit the\n+                // in-memory cache, or another query down the line will.\n+                let _ = self.get_query::<Q>(DUMMY_SP, key);\n+            }\n+            Some((_, dep_node_index)) => {\n+                self.prof.query_cache_hit(dep_node_index.into());\n+            }\n         }\n     }\n \n@@ -813,36 +835,6 @@ macro_rules! define_queries_inner {\n             }\n         }\n \n-        #[allow(nonstandard_style)]\n-        #[derive(Clone, Copy)]\n-        pub enum QueryName {\n-            $($name),*\n-        }\n-\n-        impl rustc_data_structures::profiling::QueryName for QueryName {\n-            fn discriminant(self) -> std::mem::Discriminant<QueryName> {\n-                std::mem::discriminant(&self)\n-            }\n-\n-            fn as_str(self) -> &'static str {\n-                QueryName::as_str(&self)\n-            }\n-        }\n-\n-        impl QueryName {\n-            pub fn register_with_profiler(\n-                profiler: &rustc_data_structures::profiling::SelfProfiler,\n-            ) {\n-                $(profiler.register_query_name(QueryName::$name);)*\n-            }\n-\n-            pub fn as_str(&self) -> &'static str {\n-                match self {\n-                    $(QueryName::$name => stringify!($name),)*\n-                }\n-            }\n-        }\n-\n         #[allow(nonstandard_style)]\n         #[derive(Clone, Debug)]\n         pub enum Query<$tcx> {\n@@ -883,12 +875,6 @@ macro_rules! define_queries_inner {\n                     $(Query::$name(key) => key.default_span(tcx),)*\n                 }\n             }\n-\n-            pub fn query_name(&self) -> QueryName {\n-                match self {\n-                    $(Query::$name(_) => QueryName::$name,)*\n-                }\n-            }\n         }\n \n         impl<'a, $tcx> HashStable<StableHashingContext<'a>> for Query<$tcx> {\n@@ -923,7 +909,7 @@ macro_rules! define_queries_inner {\n             type Key = $K;\n             type Value = $V;\n \n-            const NAME: QueryName = QueryName::$name;\n+            const NAME: &'static str = stringify!($name);\n             const CATEGORY: ProfileCategory = $category;\n         }\n \n@@ -1035,6 +1021,35 @@ macro_rules! define_queries_inner {\n             pub fn $name(self, key: $K) -> $V {\n                 self.at(DUMMY_SP).$name(key)\n             })*\n+\n+            /// All self-profiling events generated by the query engine use\n+            /// virtual `StringId`s for their `event_id`. This method makes all\n+            /// those virtual `StringId`s point to actual strings.\n+            ///\n+            /// If we are recording only summary data, the ids will point to\n+            /// just the query names. If we are recording query keys too, we\n+            /// allocate the corresponding strings here.\n+            pub fn alloc_self_profile_query_strings(self) {\n+                use crate::ty::query::profiling_support::{\n+                    alloc_self_profile_query_strings_for_query_cache,\n+                    QueryKeyStringCache,\n+                };\n+\n+                if !self.prof.enabled() {\n+                    return;\n+                }\n+\n+                let mut string_cache = QueryKeyStringCache::new();\n+\n+                $({\n+                    alloc_self_profile_query_strings_for_query_cache(\n+                        self,\n+                        stringify!($name),\n+                        &self.queries.$name,\n+                        &mut string_cache,\n+                    );\n+                })*\n+            }\n         }\n \n         impl TyCtxtAt<$tcx> {"}, {"sha": "79b32ba83aea0100bf80e6d4a4e2127fe88f17fe", "filename": "src/librustc/ty/query/profiling_support.rs", "status": "added", "additions": 235, "deletions": 0, "changes": 235, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fprofiling_support.rs?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -0,0 +1,235 @@\n+use crate::hir::map::definitions::DefPathData;\n+use crate::ty::context::TyCtxt;\n+use crate::ty::query::config::QueryConfig;\n+use crate::ty::query::plumbing::QueryCache;\n+use measureme::{StringComponent, StringId};\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::profiling::SelfProfiler;\n+use rustc_data_structures::sharded::Sharded;\n+use rustc_hir::def_id::{CrateNum, DefId, DefIndex, CRATE_DEF_INDEX, LOCAL_CRATE};\n+use std::fmt::Debug;\n+use std::io::Write;\n+\n+pub struct QueryKeyStringCache {\n+    def_id_cache: FxHashMap<DefId, StringId>,\n+}\n+\n+impl QueryKeyStringCache {\n+    pub fn new() -> QueryKeyStringCache {\n+        QueryKeyStringCache { def_id_cache: Default::default() }\n+    }\n+}\n+\n+pub struct QueryKeyStringBuilder<'p, 'c, 'tcx> {\n+    profiler: &'p SelfProfiler,\n+    tcx: TyCtxt<'tcx>,\n+    string_cache: &'c mut QueryKeyStringCache,\n+}\n+\n+impl<'p, 'c, 'tcx> QueryKeyStringBuilder<'p, 'c, 'tcx> {\n+    pub fn new(\n+        profiler: &'p SelfProfiler,\n+        tcx: TyCtxt<'tcx>,\n+        string_cache: &'c mut QueryKeyStringCache,\n+    ) -> QueryKeyStringBuilder<'p, 'c, 'tcx> {\n+        QueryKeyStringBuilder { profiler, tcx, string_cache }\n+    }\n+\n+    // The current implementation is rather crude. In the future it might be a\n+    // good idea to base this on `ty::print` in order to get nicer and more\n+    // efficient query keys.\n+    fn def_id_to_string_id(&mut self, def_id: DefId) -> StringId {\n+        if let Some(&string_id) = self.string_cache.def_id_cache.get(&def_id) {\n+            return string_id;\n+        }\n+\n+        let def_key = self.tcx.def_key(def_id);\n+\n+        let (parent_string_id, start_index) = match def_key.parent {\n+            Some(parent_index) => {\n+                let parent_def_id = DefId { index: parent_index, krate: def_id.krate };\n+\n+                (self.def_id_to_string_id(parent_def_id), 0)\n+            }\n+            None => (StringId::INVALID, 2),\n+        };\n+\n+        let dis_buffer = &mut [0u8; 16];\n+        let name;\n+        let dis;\n+        let end_index;\n+\n+        match def_key.disambiguated_data.data {\n+            DefPathData::CrateRoot => {\n+                name = self.tcx.original_crate_name(def_id.krate).as_str();\n+                dis = \"\";\n+                end_index = 3;\n+            }\n+            other => {\n+                name = other.as_symbol().as_str();\n+                if def_key.disambiguated_data.disambiguator == 0 {\n+                    dis = \"\";\n+                    end_index = 3;\n+                } else {\n+                    write!(&mut dis_buffer[..], \"[{}]\", def_key.disambiguated_data.disambiguator)\n+                        .unwrap();\n+                    let end_of_dis = dis_buffer.iter().position(|&c| c == b']').unwrap();\n+                    dis = std::str::from_utf8(&dis_buffer[..end_of_dis + 1]).unwrap();\n+                    end_index = 4;\n+                }\n+            }\n+        }\n+\n+        let components = [\n+            StringComponent::Ref(parent_string_id),\n+            StringComponent::Value(\"::\"),\n+            StringComponent::Value(&name[..]),\n+            StringComponent::Value(dis),\n+        ];\n+\n+        let string_id = self.profiler.alloc_string(&components[start_index..end_index]);\n+\n+        self.string_cache.def_id_cache.insert(def_id, string_id);\n+\n+        string_id\n+    }\n+}\n+\n+pub trait IntoSelfProfilingString {\n+    fn to_self_profile_string(&self, builder: &mut QueryKeyStringBuilder<'_, '_, '_>) -> StringId;\n+}\n+\n+// The default implementation of `IntoSelfProfilingString` just uses `Debug`\n+// which is slow and causes lots of duplication of string data.\n+// The specialized impls below take care of making the `DefId` case more\n+// efficient.\n+impl<T: Debug> IntoSelfProfilingString for T {\n+    default fn to_self_profile_string(\n+        &self,\n+        builder: &mut QueryKeyStringBuilder<'_, '_, '_>,\n+    ) -> StringId {\n+        let s = format!(\"{:?}\", self);\n+        builder.profiler.alloc_string(&s[..])\n+    }\n+}\n+\n+impl IntoSelfProfilingString for DefId {\n+    fn to_self_profile_string(&self, builder: &mut QueryKeyStringBuilder<'_, '_, '_>) -> StringId {\n+        builder.def_id_to_string_id(*self)\n+    }\n+}\n+\n+impl IntoSelfProfilingString for CrateNum {\n+    fn to_self_profile_string(&self, builder: &mut QueryKeyStringBuilder<'_, '_, '_>) -> StringId {\n+        builder.def_id_to_string_id(DefId { krate: *self, index: CRATE_DEF_INDEX })\n+    }\n+}\n+\n+impl IntoSelfProfilingString for DefIndex {\n+    fn to_self_profile_string(&self, builder: &mut QueryKeyStringBuilder<'_, '_, '_>) -> StringId {\n+        builder.def_id_to_string_id(DefId { krate: LOCAL_CRATE, index: *self })\n+    }\n+}\n+\n+impl<T0, T1> IntoSelfProfilingString for (T0, T1)\n+where\n+    T0: IntoSelfProfilingString + Debug,\n+    T1: IntoSelfProfilingString + Debug,\n+{\n+    default fn to_self_profile_string(\n+        &self,\n+        builder: &mut QueryKeyStringBuilder<'_, '_, '_>,\n+    ) -> StringId {\n+        let val0 = self.0.to_self_profile_string(builder);\n+        let val1 = self.1.to_self_profile_string(builder);\n+\n+        let components = &[\n+            StringComponent::Value(\"(\"),\n+            StringComponent::Ref(val0),\n+            StringComponent::Value(\",\"),\n+            StringComponent::Ref(val1),\n+            StringComponent::Value(\")\"),\n+        ];\n+\n+        builder.profiler.alloc_string(components)\n+    }\n+}\n+\n+/// Allocate the self-profiling query strings for a single query cache. This\n+/// method is called from `alloc_self_profile_query_strings` which knows all\n+/// the queries via macro magic.\n+pub(super) fn alloc_self_profile_query_strings_for_query_cache<'tcx, Q>(\n+    tcx: TyCtxt<'tcx>,\n+    query_name: &'static str,\n+    query_cache: &Sharded<QueryCache<'tcx, Q>>,\n+    string_cache: &mut QueryKeyStringCache,\n+) where\n+    Q: QueryConfig<'tcx>,\n+{\n+    tcx.prof.with_profiler(|profiler| {\n+        let event_id_builder = profiler.event_id_builder();\n+\n+        // Walk the entire query cache and allocate the appropriate\n+        // string representations. Each cache entry is uniquely\n+        // identified by its dep_node_index.\n+        if profiler.query_key_recording_enabled() {\n+            let mut query_string_builder = QueryKeyStringBuilder::new(profiler, tcx, string_cache);\n+\n+            let query_name = profiler.get_or_alloc_cached_string(query_name);\n+\n+            // Since building the string representation of query keys might\n+            // need to invoke queries itself, we cannot keep the query caches\n+            // locked while doing so. Instead we copy out the\n+            // `(query_key, dep_node_index)` pairs and release the lock again.\n+            let query_keys_and_indices = {\n+                let shards = query_cache.lock_shards();\n+                let len = shards.iter().map(|shard| shard.results.len()).sum();\n+\n+                let mut query_keys_and_indices = Vec::with_capacity(len);\n+\n+                for shard in &shards {\n+                    query_keys_and_indices.extend(\n+                        shard.results.iter().map(|(q_key, q_val)| (q_key.clone(), q_val.index)),\n+                    );\n+                }\n+\n+                query_keys_and_indices\n+            };\n+\n+            // Now actually allocate the strings. If allocating the strings\n+            // generates new entries in the query cache, we'll miss them but\n+            // we don't actually care.\n+            for (query_key, dep_node_index) in query_keys_and_indices {\n+                // Translate the DepNodeIndex into a QueryInvocationId\n+                let query_invocation_id = dep_node_index.into();\n+\n+                // Create the string version of the query-key\n+                let query_key = query_key.to_self_profile_string(&mut query_string_builder);\n+                let event_id = event_id_builder.from_label_and_arg(query_name, query_key);\n+\n+                // Doing this in bulk might be a good idea:\n+                profiler.map_query_invocation_id_to_string(\n+                    query_invocation_id,\n+                    event_id.to_string_id(),\n+                );\n+            }\n+        } else {\n+            // In this branch we don't allocate query keys\n+            let query_name = profiler.get_or_alloc_cached_string(query_name);\n+            let event_id = event_id_builder.from_label(query_name).to_string_id();\n+\n+            let shards = query_cache.lock_shards();\n+\n+            for shard in shards.iter() {\n+                let query_invocation_ids = shard\n+                    .results\n+                    .values()\n+                    .map(|v| v.index)\n+                    .map(|dep_node_index| dep_node_index.into());\n+\n+                profiler\n+                    .bulk_map_query_invocation_id_to_single_string(query_invocation_ids, event_id);\n+            }\n+        }\n+    });\n+}"}, {"sha": "9b9434539a8e50a53e6a07ecd75dbd5dc2c351dc", "filename": "src/librustc_codegen_ssa/base.rs", "status": "modified", "additions": 13, "deletions": 6, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc_codegen_ssa%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc_codegen_ssa%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fbase.rs?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -85,7 +85,7 @@ pub fn bin_op_to_icmp_predicate(op: hir::BinOpKind, signed: bool) -> IntPredicat\n         }\n         op => bug!(\n             \"comparison_op_to_icmp_predicate: expected comparison operator, \\\n-                  found {:?}\",\n+             found {:?}\",\n             op\n         ),\n     }\n@@ -102,7 +102,7 @@ pub fn bin_op_to_fcmp_predicate(op: hir::BinOpKind) -> RealPredicate {\n         op => {\n             bug!(\n                 \"comparison_op_to_fcmp_predicate: expected comparison operator, \\\n-                  found {:?}\",\n+                 found {:?}\",\n                 op\n             );\n         }\n@@ -519,7 +519,7 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n \n         ongoing_codegen.codegen_finished(tcx);\n \n-        assert_and_save_dep_graph(tcx);\n+        finalize_tcx(tcx);\n \n         ongoing_codegen.check_for_errors(tcx.sess);\n \n@@ -660,7 +660,8 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n \n     ongoing_codegen.check_for_errors(tcx.sess);\n \n-    assert_and_save_dep_graph(tcx);\n+    finalize_tcx(tcx);\n+\n     ongoing_codegen.into_inner()\n }\n \n@@ -711,10 +712,16 @@ impl<B: ExtraBackendMethods> Drop for AbortCodegenOnDrop<B> {\n     }\n }\n \n-fn assert_and_save_dep_graph(tcx: TyCtxt<'_>) {\n+fn finalize_tcx(tcx: TyCtxt<'_>) {\n     tcx.sess.time(\"assert_dep_graph\", || ::rustc_incremental::assert_dep_graph(tcx));\n-\n     tcx.sess.time(\"serialize_dep_graph\", || ::rustc_incremental::save_dep_graph(tcx));\n+\n+    // We assume that no queries are run past here. If there are new queries\n+    // after this point, they'll show up as \"<unknown>\" in self-profiling data.\n+    {\n+        let _prof_timer = tcx.prof.generic_activity(\"self_profile_alloc_query_strings\");\n+        tcx.alloc_self_profile_query_strings();\n+    }\n }\n \n impl CrateInfo {"}, {"sha": "19db9834fd48e69921715c8aca5ef56c77155a07", "filename": "src/librustc_data_structures/Cargo.toml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc_data_structures%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc_data_structures%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2FCargo.toml?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -26,7 +26,7 @@ rustc-hash = \"1.0.1\"\n smallvec = { version = \"1.0\", features = [\"union\", \"may_dangle\"] }\n rustc_index = { path = \"../librustc_index\", package = \"rustc_index\" }\n bitflags = \"1.2.1\"\n-measureme = \"0.5\"\n+measureme = \"0.7.1\"\n \n [dependencies.parking_lot]\n version = \"0.9\""}, {"sha": "e8a70d58f0cff4aec871a9642c9104c7cafadf3c", "filename": "src/librustc_data_structures/profiling.rs", "status": "modified", "additions": 184, "deletions": 36, "changes": 220, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc_data_structures%2Fprofiling.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc_data_structures%2Fprofiling.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fprofiling.rs?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -1,14 +1,99 @@\n+//! # Rust Compiler Self-Profiling\n+//!\n+//! This module implements the basic framework for the compiler's self-\n+//! profiling support. It provides the `SelfProfiler` type which enables\n+//! recording \"events\". An event is something that starts and ends at a given\n+//! point in time and has an ID and a kind attached to it. This allows for\n+//! tracing the compiler's activity.\n+//!\n+//! Internally this module uses the custom tailored [measureme][mm] crate for\n+//! efficiently recording events to disk in a compact format that can be\n+//! post-processed and analyzed by the suite of tools in the `measureme`\n+//! project. The highest priority for the tracing framework is on incurring as\n+//! little overhead as possible.\n+//!\n+//!\n+//! ## Event Overview\n+//!\n+//! Events have a few properties:\n+//!\n+//! - The `event_kind` designates the broad category of an event (e.g. does it\n+//!   correspond to the execution of a query provider or to loading something\n+//!   from the incr. comp. on-disk cache, etc).\n+//! - The `event_id` designates the query invocation or function call it\n+//!   corresponds to, possibly including the query key or function arguments.\n+//! - Each event stores the ID of the thread it was recorded on.\n+//! - The timestamp stores beginning and end of the event, or the single point\n+//!   in time it occurred at for \"instant\" events.\n+//!\n+//!\n+//! ## Event Filtering\n+//!\n+//! Event generation can be filtered by event kind. Recording all possible\n+//! events generates a lot of data, much of which is not needed for most kinds\n+//! of analysis. So, in order to keep overhead as low as possible for a given\n+//! use case, the `SelfProfiler` will only record the kinds of events that\n+//! pass the filter specified as a command line argument to the compiler.\n+//!\n+//!\n+//! ## `event_id` Assignment\n+//!\n+//! As far as `measureme` is concerned, `event_id`s are just strings. However,\n+//! it would incur too much overhead to generate and persist each `event_id`\n+//! string at the point where the event is recorded. In order to make this more\n+//! efficient `measureme` has two features:\n+//!\n+//! - Strings can share their content, so that re-occurring parts don't have to\n+//!   be copied over and over again. One allocates a string in `measureme` and\n+//!   gets back a `StringId`. This `StringId` is then used to refer to that\n+//!   string. `measureme` strings are actually DAGs of string components so that\n+//!   arbitrary sharing of substrings can be done efficiently. This is useful\n+//!   because `event_id`s contain lots of redundant text like query names or\n+//!   def-path components.\n+//!\n+//! - `StringId`s can be \"virtual\" which means that the client picks a numeric\n+//!   ID according to some application-specific scheme and can later make that\n+//!   ID be mapped to an actual string. This is used to cheaply generate\n+//!   `event_id`s while the events actually occur, causing little timing\n+//!   distortion, and then later map those `StringId`s, in bulk, to actual\n+//!   `event_id` strings. This way the largest part of the tracing overhead is\n+//!   localized to one contiguous chunk of time.\n+//!\n+//! How are these `event_id`s generated in the compiler? For things that occur\n+//! infrequently (e.g. \"generic activities\"), we just allocate the string the\n+//! first time it is used and then keep the `StringId` in a hash table. This\n+//! is implemented in `SelfProfiler::get_or_alloc_cached_string()`.\n+//!\n+//! For queries it gets more interesting: First we need a unique numeric ID for\n+//! each query invocation (the `QueryInvocationId`). This ID is used as the\n+//! virtual `StringId` we use as `event_id` for a given event. This ID has to\n+//! be available both when the query is executed and later, together with the\n+//! query key, when we allocate the actual `event_id` strings in bulk.\n+//!\n+//! We could make the compiler generate and keep track of such an ID for each\n+//! query invocation but luckily we already have something that fits all the\n+//! the requirements: the query's `DepNodeIndex`. So we use the numeric value\n+//! of the `DepNodeIndex` as `event_id` when recording the event and then,\n+//! just before the query context is dropped, we walk the entire query cache\n+//! (which stores the `DepNodeIndex` along with the query key for each\n+//! invocation) and allocate the corresponding strings together with a mapping\n+//! for `DepNodeIndex as StringId`.\n+//!\n+//! [mm]: https://github.com/rust-lang/measureme/\n+\n+use crate::fx::FxHashMap;\n+\n use std::error::Error;\n use std::fs;\n-use std::mem::{self, Discriminant};\n use std::path::Path;\n use std::process;\n use std::sync::Arc;\n use std::thread::ThreadId;\n use std::time::{Duration, Instant};\n use std::u32;\n \n-use measureme::StringId;\n+use measureme::{EventId, EventIdBuilder, SerializableString, StringId};\n+use parking_lot::RwLock;\n \n /// MmapSerializatioSink is faster on macOS and Linux\n /// but FileSerializationSink is faster on Windows\n@@ -19,11 +104,6 @@ type SerializationSink = measureme::FileSerializationSink;\n \n type Profiler = measureme::Profiler<SerializationSink>;\n \n-pub trait QueryName: Sized + Copy {\n-    fn discriminant(self) -> Discriminant<Self>;\n-    fn as_str(self) -> &'static str;\n-}\n-\n #[derive(Clone, Copy, Debug, PartialEq, Eq, Ord, PartialOrd)]\n pub enum ProfileCategory {\n     Parsing,\n@@ -43,6 +123,8 @@ bitflags::bitflags! {\n         const QUERY_BLOCKED      = 1 << 3;\n         const INCR_CACHE_LOADS   = 1 << 4;\n \n+        const QUERY_KEYS         = 1 << 5;\n+\n         const DEFAULT = Self::GENERIC_ACTIVITIES.bits |\n                         Self::QUERY_PROVIDERS.bits |\n                         Self::QUERY_BLOCKED.bits |\n@@ -62,12 +144,16 @@ const EVENT_FILTERS_BY_NAME: &[(&str, EventFilter)] = &[\n     (\"query-cache-hit\", EventFilter::QUERY_CACHE_HITS),\n     (\"query-blocked\", EventFilter::QUERY_BLOCKED),\n     (\"incr-cache-load\", EventFilter::INCR_CACHE_LOADS),\n+    (\"query-keys\", EventFilter::QUERY_KEYS),\n ];\n \n fn thread_id_to_u32(tid: ThreadId) -> u32 {\n-    unsafe { mem::transmute::<ThreadId, u64>(tid) as u32 }\n+    unsafe { std::mem::transmute::<ThreadId, u64>(tid) as u32 }\n }\n \n+/// Something that uniquely identifies a query invocation.\n+pub struct QueryInvocationId(pub u32);\n+\n /// A reference to the SelfProfiler. It can be cloned and sent across thread\n /// boundaries at will.\n #[derive(Clone)]\n@@ -138,7 +224,10 @@ impl SelfProfilerRef {\n     /// a measureme event, \"verbose\" generic activities also print a timing entry to\n     /// stdout if the compiler is invoked with -Ztime or -Ztime-passes.\n     #[inline(always)]\n-    pub fn verbose_generic_activity<'a>(&'a self, event_id: &'a str) -> VerboseTimingGuard<'a> {\n+    pub fn verbose_generic_activity<'a>(\n+        &'a self,\n+        event_id: &'static str,\n+    ) -> VerboseTimingGuard<'a> {\n         VerboseTimingGuard::start(\n             event_id,\n             self.print_verbose_generic_activities,\n@@ -167,29 +256,29 @@ impl SelfProfilerRef {\n     /// Start profiling a generic activity. Profiling continues until the\n     /// TimingGuard returned from this call is dropped.\n     #[inline(always)]\n-    pub fn generic_activity(&self, event_id: &str) -> TimingGuard<'_> {\n+    pub fn generic_activity(&self, event_id: &'static str) -> TimingGuard<'_> {\n         self.exec(EventFilter::GENERIC_ACTIVITIES, |profiler| {\n-            let event_id = profiler.profiler.alloc_string(event_id);\n+            let event_id = profiler.get_or_alloc_cached_string(event_id);\n+            let event_id = EventId::from_label(event_id);\n             TimingGuard::start(profiler, profiler.generic_activity_event_kind, event_id)\n         })\n     }\n \n     /// Start profiling a query provider. Profiling continues until the\n     /// TimingGuard returned from this call is dropped.\n     #[inline(always)]\n-    pub fn query_provider(&self, query_name: impl QueryName) -> TimingGuard<'_> {\n+    pub fn query_provider(&self) -> TimingGuard<'_> {\n         self.exec(EventFilter::QUERY_PROVIDERS, |profiler| {\n-            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n-            TimingGuard::start(profiler, profiler.query_event_kind, event_id)\n+            TimingGuard::start(profiler, profiler.query_event_kind, EventId::INVALID)\n         })\n     }\n \n     /// Record a query in-memory cache hit.\n     #[inline(always)]\n-    pub fn query_cache_hit(&self, query_name: impl QueryName) {\n+    pub fn query_cache_hit(&self, query_invocation_id: QueryInvocationId) {\n         self.instant_query_event(\n             |profiler| profiler.query_cache_hit_event_kind,\n-            query_name,\n+            query_invocation_id,\n             EventFilter::QUERY_CACHE_HITS,\n         );\n     }\n@@ -198,51 +287,65 @@ impl SelfProfilerRef {\n     /// Profiling continues until the TimingGuard returned from this call is\n     /// dropped.\n     #[inline(always)]\n-    pub fn query_blocked(&self, query_name: impl QueryName) -> TimingGuard<'_> {\n+    pub fn query_blocked(&self) -> TimingGuard<'_> {\n         self.exec(EventFilter::QUERY_BLOCKED, |profiler| {\n-            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n-            TimingGuard::start(profiler, profiler.query_blocked_event_kind, event_id)\n+            TimingGuard::start(profiler, profiler.query_blocked_event_kind, EventId::INVALID)\n         })\n     }\n \n     /// Start profiling how long it takes to load a query result from the\n     /// incremental compilation on-disk cache. Profiling continues until the\n     /// TimingGuard returned from this call is dropped.\n     #[inline(always)]\n-    pub fn incr_cache_loading(&self, query_name: impl QueryName) -> TimingGuard<'_> {\n+    pub fn incr_cache_loading(&self) -> TimingGuard<'_> {\n         self.exec(EventFilter::INCR_CACHE_LOADS, |profiler| {\n-            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n-            TimingGuard::start(profiler, profiler.incremental_load_result_event_kind, event_id)\n+            TimingGuard::start(\n+                profiler,\n+                profiler.incremental_load_result_event_kind,\n+                EventId::INVALID,\n+            )\n         })\n     }\n \n     #[inline(always)]\n     fn instant_query_event(\n         &self,\n         event_kind: fn(&SelfProfiler) -> StringId,\n-        query_name: impl QueryName,\n+        query_invocation_id: QueryInvocationId,\n         event_filter: EventFilter,\n     ) {\n         drop(self.exec(event_filter, |profiler| {\n-            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n+            let event_id = StringId::new_virtual(query_invocation_id.0);\n             let thread_id = thread_id_to_u32(std::thread::current().id());\n \n-            profiler.profiler.record_instant_event(event_kind(profiler), event_id, thread_id);\n+            profiler.profiler.record_instant_event(\n+                event_kind(profiler),\n+                EventId::from_virtual(event_id),\n+                thread_id,\n+            );\n \n             TimingGuard::none()\n         }));\n     }\n \n-    pub fn register_queries(&self, f: impl FnOnce(&SelfProfiler)) {\n+    pub fn with_profiler(&self, f: impl FnOnce(&SelfProfiler)) {\n         if let Some(profiler) = &self.profiler {\n             f(&profiler)\n         }\n     }\n+\n+    #[inline]\n+    pub fn enabled(&self) -> bool {\n+        self.profiler.is_some()\n+    }\n }\n \n pub struct SelfProfiler {\n     profiler: Profiler,\n     event_filter_mask: EventFilter,\n+\n+    string_cache: RwLock<FxHashMap<&'static str, StringId>>,\n+\n     query_event_kind: StringId,\n     generic_activity_event_kind: StringId,\n     incremental_load_result_event_kind: StringId,\n@@ -305,6 +408,7 @@ impl SelfProfiler {\n         Ok(SelfProfiler {\n             profiler,\n             event_filter_mask,\n+            string_cache: RwLock::new(FxHashMap::default()),\n             query_event_kind,\n             generic_activity_event_kind,\n             incremental_load_result_event_kind,\n@@ -313,16 +417,51 @@ impl SelfProfiler {\n         })\n     }\n \n-    fn get_query_name_string_id(query_name: impl QueryName) -> StringId {\n-        let discriminant =\n-            unsafe { mem::transmute::<Discriminant<_>, u64>(query_name.discriminant()) };\n+    /// Allocates a new string in the profiling data. Does not do any caching\n+    /// or deduplication.\n+    pub fn alloc_string<STR: SerializableString + ?Sized>(&self, s: &STR) -> StringId {\n+        self.profiler.alloc_string(s)\n+    }\n+\n+    /// Gets a `StringId` for the given string. This method makes sure that\n+    /// any strings going through it will only be allocated once in the\n+    /// profiling data.\n+    pub fn get_or_alloc_cached_string(&self, s: &'static str) -> StringId {\n+        // Only acquire a read-lock first since we assume that the string is\n+        // already present in the common case.\n+        {\n+            let string_cache = self.string_cache.read();\n+\n+            if let Some(&id) = string_cache.get(s) {\n+                return id;\n+            }\n+        }\n+\n+        let mut string_cache = self.string_cache.write();\n+        // Check if the string has already been added in the small time window\n+        // between dropping the read lock and acquiring the write lock.\n+        *string_cache.entry(s).or_insert_with(|| self.profiler.alloc_string(s))\n+    }\n+\n+    pub fn map_query_invocation_id_to_string(&self, from: QueryInvocationId, to: StringId) {\n+        let from = StringId::new_virtual(from.0);\n+        self.profiler.map_virtual_to_concrete_string(from, to);\n+    }\n \n-        StringId::reserved(discriminant as u32)\n+    pub fn bulk_map_query_invocation_id_to_single_string<I>(&self, from: I, to: StringId)\n+    where\n+        I: Iterator<Item = QueryInvocationId> + ExactSizeIterator,\n+    {\n+        let from = from.map(|qid| StringId::new_virtual(qid.0));\n+        self.profiler.bulk_map_virtual_to_single_concrete_string(from, to);\n+    }\n+\n+    pub fn query_key_recording_enabled(&self) -> bool {\n+        self.event_filter_mask.contains(EventFilter::QUERY_KEYS)\n     }\n \n-    pub fn register_query_name(&self, query_name: impl QueryName) {\n-        let id = SelfProfiler::get_query_name_string_id(query_name);\n-        self.profiler.alloc_string_with_reserved_id(id, query_name.as_str());\n+    pub fn event_id_builder(&self) -> EventIdBuilder<'_, SerializationSink> {\n+        EventIdBuilder::new(&self.profiler)\n     }\n }\n \n@@ -334,7 +473,7 @@ impl<'a> TimingGuard<'a> {\n     pub fn start(\n         profiler: &'a SelfProfiler,\n         event_kind: StringId,\n-        event_id: StringId,\n+        event_id: EventId,\n     ) -> TimingGuard<'a> {\n         let thread_id = thread_id_to_u32(std::thread::current().id());\n         let raw_profiler = &profiler.profiler;\n@@ -343,6 +482,15 @@ impl<'a> TimingGuard<'a> {\n         TimingGuard(Some(timing_guard))\n     }\n \n+    #[inline]\n+    pub fn finish_with_query_invocation_id(self, query_invocation_id: QueryInvocationId) {\n+        if let Some(guard) = self.0 {\n+            let event_id = StringId::new_virtual(query_invocation_id.0);\n+            let event_id = EventId::from_virtual(event_id);\n+            guard.finish_with_override_event_id(event_id);\n+        }\n+    }\n+\n     #[inline]\n     pub fn none() -> TimingGuard<'a> {\n         TimingGuard(None)\n@@ -444,8 +592,8 @@ fn get_resident() -> Option<usize> {\n             cb: DWORD,\n         ) -> BOOL;\n     }\n-    let mut pmc: PROCESS_MEMORY_COUNTERS = unsafe { mem::zeroed() };\n-    pmc.cb = mem::size_of_val(&pmc) as DWORD;\n+    let mut pmc: PROCESS_MEMORY_COUNTERS = unsafe { std::mem::zeroed() };\n+    pmc.cb = std::mem::size_of_val(&pmc) as DWORD;\n     match unsafe { GetProcessMemoryInfo(GetCurrentProcess(), &mut pmc, pmc.cb) } {\n         0 => None,\n         _ => Some(pmc.WorkingSetSize as usize),"}, {"sha": "8e381a27b414f335da858c0da5f651f037c23088", "filename": "src/librustc_interface/util.rs", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc_interface%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f795e8a216b44982706d41e5cbfa245d13b83fc1/src%2Flibrustc_interface%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Futil.rs?ref=f795e8a216b44982706d41e5cbfa245d13b83fc1", "patch": "@@ -71,10 +71,6 @@ pub fn create_session(\n         lint_caps,\n     );\n \n-    sess.prof.register_queries(|profiler| {\n-        rustc::ty::query::QueryName::register_with_profiler(&profiler);\n-    });\n-\n     let codegen_backend = get_codegen_backend(&sess);\n \n     let mut cfg = config::build_configuration(&sess, config::to_crate_config(cfg));"}]}