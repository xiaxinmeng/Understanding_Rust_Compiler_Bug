{"sha": "830ff4a592cf6a5adc0e5482d4294779d7a91177", "node_id": "MDY6Q29tbWl0NzI0NzEyOjgzMGZmNGE1OTJjZjZhNWFkYzBlNTQ4MmQ0Mjk0Nzc5ZDdhOTExNzc=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-07-02T10:44:38Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-07-04T06:01:37Z"}, "message": "remove StringReader::peek\n\nThe reader itself doesn't need ability to peek tokens, so it's better\nif clients implement this functionality.\n\nThis hopefully becomes especially easy once we use iterator interface\nfor lexer, but this is not too easy at the moment, because of buffered\nerrors.", "tree": {"sha": "02a63590fed1084da3fefbc87764f03d592c1bf0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/02a63590fed1084da3fefbc87764f03d592c1bf0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/830ff4a592cf6a5adc0e5482d4294779d7a91177", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/830ff4a592cf6a5adc0e5482d4294779d7a91177", "html_url": "https://github.com/rust-lang/rust/commit/830ff4a592cf6a5adc0e5482d4294779d7a91177", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/830ff4a592cf6a5adc0e5482d4294779d7a91177/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b43eb4235ac43c822d903ad26ed806f34cc1a14a", "url": "https://api.github.com/repos/rust-lang/rust/commits/b43eb4235ac43c822d903ad26ed806f34cc1a14a", "html_url": "https://github.com/rust-lang/rust/commit/b43eb4235ac43c822d903ad26ed806f34cc1a14a"}], "stats": {"total": 33, "additions": 20, "deletions": 13}, "files": [{"sha": "852c1e031de4a238a528392318d46a601100ae02", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 20, "deletions": 9, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/830ff4a592cf6a5adc0e5482d4294779d7a91177/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/830ff4a592cf6a5adc0e5482d4294779d7a91177/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=830ff4a592cf6a5adc0e5482d4294779d7a91177", "patch": "@@ -79,6 +79,7 @@ pub fn render_with_highlighting(\n /// each span of text in sequence.\n struct Classifier<'a> {\n     lexer: lexer::StringReader<'a>,\n+    peek_token: Option<Token>,\n     source_map: &'a SourceMap,\n \n     // State of the classifier.\n@@ -178,6 +179,7 @@ impl<'a> Classifier<'a> {\n     fn new(lexer: lexer::StringReader<'a>, source_map: &'a SourceMap) -> Classifier<'a> {\n         Classifier {\n             lexer,\n+            peek_token: None,\n             source_map,\n             in_attribute: false,\n             in_macro: false,\n@@ -187,10 +189,19 @@ impl<'a> Classifier<'a> {\n \n     /// Gets the next token out of the lexer.\n     fn try_next_token(&mut self) -> Result<Token, HighlightError> {\n-        match self.lexer.try_next_token() {\n-            Ok(token) => Ok(token),\n-            Err(_) => Err(HighlightError::LexError),\n+        if let Some(token) = self.peek_token.take() {\n+            return Ok(token);\n         }\n+        self.lexer.try_next_token().map_err(|()| HighlightError::LexError)\n+    }\n+\n+    fn peek(&mut self) -> Result<&Token, HighlightError> {\n+        if self.peek_token.is_none() {\n+            self.peek_token = Some(\n+                self.lexer.try_next_token().map_err(|()| HighlightError::LexError)?\n+            );\n+        }\n+        Ok(self.peek_token.as_ref().unwrap())\n     }\n \n     /// Exhausts the `lexer` writing the output into `out`.\n@@ -234,7 +245,7 @@ impl<'a> Classifier<'a> {\n             // reference or dereference operator or a reference or pointer type, instead of the\n             // bit-and or multiplication operator.\n             token::BinOp(token::And) | token::BinOp(token::Star)\n-                if self.lexer.peek() != &token::Whitespace => Class::RefKeyWord,\n+                if self.peek()? != &token::Whitespace => Class::RefKeyWord,\n \n             // Consider this as part of a macro invocation if there was a\n             // leading identifier.\n@@ -257,7 +268,7 @@ impl<'a> Classifier<'a> {\n             token::Question => Class::QuestionMark,\n \n             token::Dollar => {\n-                if self.lexer.peek().is_ident() {\n+                if self.peek()?.is_ident() {\n                     self.in_macro_nonterminal = true;\n                     Class::MacroNonTerminal\n                 } else {\n@@ -280,9 +291,9 @@ impl<'a> Classifier<'a> {\n                 // as an attribute.\n \n                 // Case 1: #![inner_attribute]\n-                if self.lexer.peek() == &token::Not {\n+                if self.peek()? == &token::Not {\n                     self.try_next_token()?; // NOTE: consumes `!` token!\n-                    if self.lexer.peek() == &token::OpenDelim(token::Bracket) {\n+                    if self.peek()? == &token::OpenDelim(token::Bracket) {\n                         self.in_attribute = true;\n                         out.enter_span(Class::Attribute)?;\n                     }\n@@ -292,7 +303,7 @@ impl<'a> Classifier<'a> {\n                 }\n \n                 // Case 2: #[outer_attribute]\n-                if self.lexer.peek() == &token::OpenDelim(token::Bracket) {\n+                if self.peek()? == &token::OpenDelim(token::Bracket) {\n                     self.in_attribute = true;\n                     out.enter_span(Class::Attribute)?;\n                 }\n@@ -341,7 +352,7 @@ impl<'a> Classifier<'a> {\n                         if self.in_macro_nonterminal {\n                             self.in_macro_nonterminal = false;\n                             Class::MacroNonTerminal\n-                        } else if self.lexer.peek() == &token::Not {\n+                        } else if self.peek()? == &token::Not {\n                             self.in_macro = true;\n                             Class::Macro\n                         } else {"}, {"sha": "021b623d509c72606983dce0e66a63b77c2ded06", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/830ff4a592cf6a5adc0e5482d4294779d7a91177/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/830ff4a592cf6a5adc0e5482d4294779d7a91177/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=830ff4a592cf6a5adc0e5482d4294779d7a91177", "patch": "@@ -142,10 +142,6 @@ impl<'a> StringReader<'a> {\n         buffer\n     }\n \n-    pub fn peek(&self) -> &Token {\n-        &self.peek_token\n-    }\n-\n     /// For comments.rs, which hackily pokes into next_pos and ch\n     fn new_raw(sess: &'a ParseSess,\n                source_file: Lrc<syntax_pos::SourceFile>,"}]}