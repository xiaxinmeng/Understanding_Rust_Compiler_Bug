{"sha": "43a5ff4222e1f217ac14331afd59f82ec4204d12", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQzYTVmZjQyMjJlMWYyMTdhYzE0MzMxYWZkNTlmODJlYzQyMDRkMTI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-09-07T18:02:22Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-09-07T18:02:22Z"}, "message": "Auto merge of #64264 - Centril:rollup-w1khzun, r=Centril\n\nRollup of 7 pull requests\n\nSuccessful merges:\n\n - #64023 (libstd fuchsia fixes)\n - #64098 (Ensure edition lints and internal lints are enabled with deny-warnings=false)\n - #64139 (Migrate internal diagnostic registration to macro_rules)\n - #64226 (Aggregation of cosmetic changes made during work on REPL PRs: libsyntax)\n - #64227 (Aggregation of cosmetic changes made during work on REPL PRs: librustc)\n - #64235 (Upgrade env_logger to 0.6)\n - #64258 (compiletest: Match suffixed environments)\n\nFailed merges:\n\nr? @ghost", "tree": {"sha": "77d362c6a5a0a963f321158252b7b224ea7acc70", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/77d362c6a5a0a963f321158252b7b224ea7acc70"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/43a5ff4222e1f217ac14331afd59f82ec4204d12", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/43a5ff4222e1f217ac14331afd59f82ec4204d12", "html_url": "https://github.com/rust-lang/rust/commit/43a5ff4222e1f217ac14331afd59f82ec4204d12", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/43a5ff4222e1f217ac14331afd59f82ec4204d12/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ef54f57c5b9d894a38179d09b00610c1b337b086", "url": "https://api.github.com/repos/rust-lang/rust/commits/ef54f57c5b9d894a38179d09b00610c1b337b086", "html_url": "https://github.com/rust-lang/rust/commit/ef54f57c5b9d894a38179d09b00610c1b337b086"}, {"sha": "635c3bcc3cd9fcd80380572de0efb905224a8fa0", "url": "https://api.github.com/repos/rust-lang/rust/commits/635c3bcc3cd9fcd80380572de0efb905224a8fa0", "html_url": "https://github.com/rust-lang/rust/commit/635c3bcc3cd9fcd80380572de0efb905224a8fa0"}], "stats": {"total": 3841, "additions": 1805, "deletions": 2036}, "files": [{"sha": "108c2fbd8f503fea2decf83cba36ceb4e604bba9", "filename": "Cargo.lock", "status": "modified", "additions": 12, "deletions": 28, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -277,7 +277,7 @@ dependencies = [\n  \"crypto-hash\",\n  \"curl\",\n  \"curl-sys\",\n- \"env_logger 0.6.0\",\n+ \"env_logger\",\n  \"failure\",\n  \"filetime\",\n  \"flate2\",\n@@ -507,7 +507,7 @@ name = \"compiletest\"\n version = \"0.0.0\"\n dependencies = [\n  \"diff\",\n- \"env_logger 0.5.13\",\n+ \"env_logger\",\n  \"getopts\",\n  \"lazy_static 1.3.0\",\n  \"libc\",\n@@ -909,21 +909,9 @@ dependencies = [\n \n [[package]]\n name = \"env_logger\"\n-version = \"0.5.13\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"15b0a4d2e39f8420210be8b27eeda28029729e2fd4291019455016c348240c38\"\n-dependencies = [\n- \"atty\",\n- \"humantime\",\n- \"log\",\n- \"termcolor\",\n-]\n-\n-[[package]]\n-name = \"env_logger\"\n-version = \"0.6.0\"\n+version = \"0.6.2\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"afb070faf94c85d17d50ca44f6ad076bce18ae92f0037d350947240a36e9d42e\"\n+checksum = \"aafcde04e90a5226a6443b7aabdb016ba2f8307c847d524724bd9b346dd1a2d3\"\n dependencies = [\n  \"atty\",\n  \"humantime\",\n@@ -1774,7 +1762,7 @@ dependencies = [\n  \"chrono\",\n  \"clap\",\n  \"elasticlunr-rs\",\n- \"env_logger 0.6.0\",\n+ \"env_logger\",\n  \"error-chain\",\n  \"handlebars\",\n  \"itertools 0.8.0\",\n@@ -1799,7 +1787,7 @@ version = \"0.3.0\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n checksum = \"77d1f0ba4d1e6b86fa18e8853d026d7d76a97eb7eb5eb052ed80901e43b7fc10\"\n dependencies = [\n- \"env_logger 0.6.0\",\n+ \"env_logger\",\n  \"failure\",\n  \"log\",\n  \"mdbook\",\n@@ -1992,7 +1980,7 @@ dependencies = [\n  \"colored\",\n  \"compiletest_rs\",\n  \"directories\",\n- \"env_logger 0.6.0\",\n+ \"env_logger\",\n  \"getrandom\",\n  \"hex\",\n  \"log\",\n@@ -2363,7 +2351,7 @@ source = \"registry+https://github.com/rust-lang/crates.io-index\"\n checksum = \"df8b3f4e0475def7d9c2e5de8e5a1306949849761e107b360d03e98eafaffd61\"\n dependencies = [\n  \"chrono\",\n- \"env_logger 0.6.0\",\n+ \"env_logger\",\n  \"log\",\n ]\n \n@@ -2440,7 +2428,7 @@ dependencies = [\n  \"bitflags\",\n  \"clap\",\n  \"derive_more\",\n- \"env_logger 0.6.0\",\n+ \"env_logger\",\n  \"humantime\",\n  \"lazy_static 1.3.0\",\n  \"log\",\n@@ -2734,7 +2722,7 @@ dependencies = [\n  \"clippy_lints\",\n  \"crossbeam-channel\",\n  \"difference\",\n- \"env_logger 0.6.0\",\n+ \"env_logger\",\n  \"failure\",\n  \"futures\",\n  \"heck\",\n@@ -3129,11 +3117,7 @@ dependencies = [\n name = \"rustc_codegen_llvm\"\n version = \"0.0.0\"\n dependencies = [\n- \"cc\",\n- \"memmap\",\n- \"num_cpus\",\n  \"rustc_llvm\",\n- \"tempfile\",\n ]\n \n [[package]]\n@@ -3203,7 +3187,7 @@ dependencies = [\n name = \"rustc_driver\"\n version = \"0.0.0\"\n dependencies = [\n- \"env_logger 0.5.13\",\n+ \"env_logger\",\n  \"graphviz\",\n  \"log\",\n  \"rustc\",\n@@ -3590,7 +3574,7 @@ dependencies = [\n  \"derive-new\",\n  \"diff\",\n  \"dirs\",\n- \"env_logger 0.6.0\",\n+ \"env_logger\",\n  \"failure\",\n  \"getopts\",\n  \"ignore\","}, {"sha": "84415baa3a14085a63b572e0e4d625c18d077a42", "filename": "src/bootstrap/bin/rustc.rs", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Fbootstrap%2Fbin%2Frustc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Fbootstrap%2Fbin%2Frustc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fbin%2Frustc.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -119,17 +119,18 @@ fn main() {\n         cmd.arg(format!(\"-Cdebuginfo={}\", debuginfo_level));\n     }\n \n-    if env::var_os(\"RUSTC_DENY_WARNINGS\").is_some() &&\n-       env::var_os(\"RUSTC_EXTERNAL_TOOL\").is_none() {\n+    if env::var_os(\"RUSTC_EXTERNAL_TOOL\").is_none() {\n         // When extending this list, add the new lints to the RUSTFLAGS of the\n         // build_bootstrap function of src/bootstrap/bootstrap.py as well as\n         // some code doesn't go through this `rustc` wrapper.\n-        cmd.arg(\"-Dwarnings\");\n-        cmd.arg(\"-Drust_2018_idioms\");\n-        cmd.arg(\"-Dunused_lifetimes\");\n+        cmd.arg(\"-Wrust_2018_idioms\");\n+        cmd.arg(\"-Wunused_lifetimes\");\n         if use_internal_lints(crate_name) {\n             cmd.arg(\"-Zunstable-options\");\n-            cmd.arg(\"-Drustc::internal\");\n+            cmd.arg(\"-Wrustc::internal\");\n+        }\n+        if env::var_os(\"RUSTC_DENY_WARNINGS\").is_some() {\n+            cmd.arg(\"-Dwarnings\");\n         }\n     }\n "}, {"sha": "e0e4c076071b65b3c71150359c5ffe38d4896c65", "filename": "src/bootstrap/bootstrap.py", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Fbootstrap%2Fbootstrap.py", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Fbootstrap%2Fbootstrap.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fbootstrap.py?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -631,8 +631,9 @@ def build_bootstrap(self):\n         target_linker = self.get_toml(\"linker\", build_section)\n         if target_linker is not None:\n             env[\"RUSTFLAGS\"] += \"-C linker=\" + target_linker + \" \"\n+        env[\"RUSTFLAGS\"] += \" -Wrust_2018_idioms -Wunused_lifetimes \"\n         if self.get_toml(\"deny-warnings\", \"rust\") != \"false\":\n-            env[\"RUSTFLAGS\"] += \"-Dwarnings -Drust_2018_idioms -Dunused_lifetimes \"\n+            env[\"RUSTFLAGS\"] += \"-Dwarnings \"\n \n         env[\"PATH\"] = os.path.join(self.bin_root(), \"bin\") + \\\n             os.pathsep + env[\"PATH\"]"}, {"sha": "d9580b598155edc946002b2a77efa6ad0d73ad7f", "filename": "src/bootstrap/flags.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Fbootstrap%2Fflags.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Fbootstrap%2Fflags.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fflags.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -36,7 +36,7 @@ pub struct Flags {\n     // This overrides the deny-warnings configuation option,\n     // which passes -Dwarnings to the compiler invocations.\n     //\n-    // true => deny, false => allow\n+    // true => deny, false => warn\n     pub deny_warnings: Option<bool>,\n }\n \n@@ -556,10 +556,10 @@ fn split(s: &[String]) -> Vec<String> {\n fn parse_deny_warnings(matches: &getopts::Matches) -> Option<bool> {\n     match matches.opt_str(\"warnings\").as_ref().map(|v| v.as_str()) {\n         Some(\"deny\") => Some(true),\n-        Some(\"allow\") => Some(false),\n+        Some(\"warn\") => Some(false),\n         Some(value) => {\n             eprintln!(\n-                r#\"invalid value for --warnings: {:?}, expected \"allow\" or \"deny\"\"#,\n+                r#\"invalid value for --warnings: {:?}, expected \"warn\" or \"deny\"\"#,\n                 value,\n                 );\n             process::exit(1);"}, {"sha": "00d87f3841cfffd04af86c5c3139f36591aa3565", "filename": "src/bootstrap/test.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Fbootstrap%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Fbootstrap%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Ftest.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1327,7 +1327,10 @@ impl Step for Compiletest {\n             cmd.env(\"RUSTC_PROFILER_SUPPORT\", \"1\");\n         }\n \n-        cmd.env(\"RUST_TEST_TMPDIR\", builder.out.join(\"tmp\"));\n+        let tmp = builder.out.join(\"tmp\");\n+        std::fs::create_dir_all(&tmp).unwrap();\n+        cmd.env(\"RUST_TEST_TMPDIR\", tmp);\n+\n \n         cmd.arg(\"--adb-path\").arg(\"adb\");\n         cmd.arg(\"--adb-test-dir\").arg(ADB_TEST_DIR);"}, {"sha": "d4fc1b12830a12eeb4af48f5a5306f0841da4252", "filename": "src/librustc/arena.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Farena.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Farena.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Farena.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -187,7 +187,7 @@ impl<T: Copy> ArenaAllocatable for T {}\n \n unsafe trait ArenaField<'tcx>: Sized {\n     /// Returns a specific arena to allocate from.\n-    /// If None is returned, the DropArena will be used.\n+    /// If `None` is returned, the `DropArena` will be used.\n     fn arena<'a>(arena: &'a Arena<'tcx>) -> Option<&'a TypedArena<Self>>;\n }\n "}, {"sha": "eee33846139e673dcdea38ac9a8977807ae573af", "filename": "src/librustc/error_codes.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,7 +1,8 @@\n // Error messages for EXXXX errors.\n-// Each message should start and end with a new line, and be wrapped to 80 characters.\n-// In vim you can `:set tw=80` and use `gq` to wrap paragraphs. Use `:set tw=0` to disable.\n-register_long_diagnostics! {\n+// Each message should start and end with a new line, and be wrapped to 80\n+// characters.  In vim you can `:set tw=80` and use `gq` to wrap paragraphs. Use\n+// `:set tw=0` to disable.\n+syntax::register_diagnostics! {\n E0038: r##\"\n Trait objects like `Box<Trait>` can only be constructed when certain\n requirements are satisfied by the trait in question.\n@@ -2183,11 +2184,7 @@ Examples of erroneous code:\n static X: u32 = 42;\n ```\n \"##,\n-\n-}\n-\n-\n-register_diagnostics! {\n+;\n //  E0006, // merged with E0005\n //  E0101, // replaced with E0282\n //  E0102, // replaced with E0282\n@@ -2206,7 +2203,8 @@ register_diagnostics! {\n //  E0305, // expected constant\n     E0311, // thing may not live long enough\n     E0312, // lifetime of reference outlives lifetime of borrowed content\n-    E0313, // lifetime of borrowed pointer outlives lifetime of captured variable\n+    E0313, // lifetime of borrowed pointer outlives lifetime of captured\n+           // variable\n     E0314, // closure outlives stack frame\n     E0315, // cannot invoke closure outside of its lifetime\n     E0316, // nested quantification of lifetimes\n@@ -2223,12 +2221,13 @@ register_diagnostics! {\n     E0483, // lifetime of operand does not outlive the operation\n     E0484, // reference is not valid at the time of borrow\n     E0485, // automatically reference is not valid at the time of borrow\n-    E0486, // type of expression contains references that are not valid during...\n+    E0486, // type of expression contains references that are not valid during..\n     E0487, // unsafe use of destructor: destructor might be called while...\n     E0488, // lifetime of variable does not enclose its declaration\n     E0489, // type/lifetime parameter not in scope here\n     E0490, // a value of type `..` is borrowed for too long\n-    E0495, // cannot infer an appropriate lifetime due to conflicting requirements\n+    E0495, // cannot infer an appropriate lifetime due to conflicting\n+           // requirements\n     E0566, // conflicting representation hints\n     E0623, // lifetime mismatch where both parameters are anonymous regions\n     E0628, // generators cannot have explicit parameters\n@@ -2239,7 +2238,8 @@ register_diagnostics! {\n     E0688, // in-band lifetimes cannot be mixed with explicit lifetime binders\n     E0697, // closures cannot be static\n     E0707, // multiple elided lifetimes used in arguments of `async fn`\n-    E0708, // `async` non-`move` closures with parameters are not currently supported\n+    E0708, // `async` non-`move` closures with parameters are not currently\n+           // supported\n     E0709, // multiple different lifetimes used in arguments of `async fn`\n     E0710, // an unknown tool name found in scoped lint\n     E0711, // a feature has been declared with conflicting stability attributes"}, {"sha": "1df09429e519f835948af6007239498a3beefe14", "filename": "src/librustc/hir/check_attr.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fcheck_attr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fcheck_attr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fcheck_attr.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -4,13 +4,12 @@\n //! conflicts between multiple such attributes attached to the same\n //! item.\n \n-\n-use crate::ty::TyCtxt;\n-use crate::ty::query::Providers;\n-\n use crate::hir;\n use crate::hir::def_id::DefId;\n use crate::hir::intravisit::{self, Visitor, NestedVisitorMap};\n+use crate::ty::TyCtxt;\n+use crate::ty::query::Providers;\n+\n use std::fmt::{self, Display};\n use syntax::symbol::sym;\n use syntax_pos::Span;"}, {"sha": "f7d31ca06ee56e173dc8d900632d980de17d8206", "filename": "src/librustc/hir/def.rs", "status": "modified", "additions": 14, "deletions": 8, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fdef.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fdef.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fdef.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,15 +1,17 @@\n+use self::Namespace::*;\n+\n use crate::hir::def_id::{DefId, CRATE_DEF_INDEX, LOCAL_CRATE};\n+use crate::hir;\n+use crate::ty;\n use crate::util::nodemap::DefIdMap;\n+\n use syntax::ast;\n use syntax::ext::base::MacroKind;\n use syntax::ast::NodeId;\n use syntax_pos::Span;\n use rustc_macros::HashStable;\n-use crate::hir;\n-use crate::ty;\n-use std::fmt::Debug;\n \n-use self::Namespace::*;\n+use std::fmt::Debug;\n \n /// Encodes if a `DefKind::Ctor` is the constructor of an enum variant or a struct.\n #[derive(Clone, Copy, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug, HashStable)]\n@@ -115,7 +117,7 @@ impl DefKind {\n         }\n     }\n \n-    /// An English article for the def.\n+    /// Gets an English article for the definition.\n     pub fn article(&self) -> &'static str {\n         match *self {\n             DefKind::AssocTy\n@@ -134,18 +136,22 @@ pub enum Res<Id = hir::HirId> {\n     Def(DefKind, DefId),\n \n     // Type namespace\n+\n     PrimTy(hir::PrimTy),\n     SelfTy(Option<DefId> /* trait */, Option<DefId> /* impl */),\n     ToolMod, // e.g., `rustfmt` in `#[rustfmt::skip]`\n \n     // Value namespace\n+\n     SelfCtor(DefId /* impl */),  // `DefId` refers to the impl\n     Local(Id),\n \n     // Macro namespace\n+\n     NonMacroAttr(NonMacroAttrKind), // e.g., `#[inline]` or `#[rustfmt::skip]`\n \n     // All namespaces\n+\n     Err,\n }\n \n@@ -330,7 +336,7 @@ impl NonMacroAttrKind {\n }\n \n impl<Id> Res<Id> {\n-    /// Return the `DefId` of this `Def` if it has an id, else panic.\n+    /// Return the `DefId` of this `Def` if it has an ID, else panic.\n     pub fn def_id(&self) -> DefId\n     where\n         Id: Debug,\n@@ -340,7 +346,7 @@ impl<Id> Res<Id> {\n         })\n     }\n \n-    /// Return `Some(..)` with the `DefId` of this `Res` if it has a id, else `None`.\n+    /// Return `Some(..)` with the `DefId` of this `Res` if it has a ID, else `None`.\n     pub fn opt_def_id(&self) -> Option<DefId> {\n         match *self {\n             Res::Def(_, id) => Some(id),\n@@ -379,7 +385,7 @@ impl<Id> Res<Id> {\n         }\n     }\n \n-    /// An English article for the res.\n+    /// Gets an English article for the `Res`.\n     pub fn article(&self) -> &'static str {\n         match *self {\n             Res::Def(kind, _) => kind.article(),"}, {"sha": "d0bdc149131835c8bc62d9c300d18e37c1c2669d", "filename": "src/librustc/hir/def_id.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fdef_id.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fdef_id.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fdef_id.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -11,7 +11,7 @@ newtype_index! {\n \n #[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n pub enum CrateNum {\n-    /// A special CrateNum that we use for the tcx.rcache when decoding from\n+    /// A special `CrateNum` that we use for the `tcx.rcache` when decoding from\n     /// the incr. comp. cache.\n     ReservedForIncrCompCache,\n     Index(CrateId),\n@@ -26,11 +26,10 @@ impl ::std::fmt::Debug for CrateNum {\n     }\n }\n \n-/// Item definitions in the currently-compiled crate would have the CrateNum\n-/// LOCAL_CRATE in their DefId.\n+/// Item definitions in the currently-compiled crate would have the `CrateNum`\n+/// `LOCAL_CRATE` in their `DefId`.\n pub const LOCAL_CRATE: CrateNum = CrateNum::Index(CrateId::from_u32_const(0));\n \n-\n impl Idx for CrateNum {\n     #[inline]\n     fn new(value: usize) -> Self {"}, {"sha": "1f125de9672168d6e599aeef32378264ad20dbc7", "filename": "src/librustc/hir/intravisit.rs", "status": "modified", "additions": 11, "deletions": 9, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fintravisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fintravisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fintravisit.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -31,11 +31,13 @@\n //! This order consistency is required in a few places in rustc, for\n //! example generator inference, and possibly also HIR borrowck.\n \n-use syntax::ast::{Ident, Name, Attribute};\n-use syntax_pos::Span;\n+use super::itemlikevisit::DeepVisitor;\n+\n use crate::hir::*;\n use crate::hir::map::Map;\n-use super::itemlikevisit::DeepVisitor;\n+\n+use syntax::ast::{Ident, Name, Attribute};\n+use syntax_pos::Span;\n \n #[derive(Copy, Clone)]\n pub enum FnKind<'a> {\n@@ -139,7 +141,7 @@ impl<'this, 'tcx> NestedVisitorMap<'this, 'tcx> {\n /// explicitly, you need to override each method. (And you also need\n /// to monitor future changes to `Visitor` in case a new method with a\n /// new default implementation gets introduced.)\n-pub trait Visitor<'v> : Sized {\n+pub trait Visitor<'v>: Sized {\n     ///////////////////////////////////////////////////////////////////////////\n     // Nested items.\n \n@@ -162,8 +164,8 @@ pub trait Visitor<'v> : Sized {\n     fn nested_visit_map<'this>(&'this mut self) -> NestedVisitorMap<'this, 'v>;\n \n     /// Invoked when a nested item is encountered. By default does\n-    /// nothing unless you override `nested_visit_map` to return\n-    /// `Some(_)`, in which case it will walk the item. **You probably\n+    /// nothing unless you override `nested_visit_map` to return other than\n+    /// `None`, in which case it will walk the item. **You probably\n     /// don't want to override this method** -- instead, override\n     /// `nested_visit_map` or use the \"shallow\" or \"deep\" visit\n     /// patterns described on `itemlikevisit::ItemLikeVisitor`. The only\n@@ -201,8 +203,8 @@ pub trait Visitor<'v> : Sized {\n \n     /// Invoked to visit the body of a function, method or closure. Like\n     /// visit_nested_item, does nothing by default unless you override\n-    /// `nested_visit_map` to return `Some(_)`, in which case it will walk the\n-    /// body.\n+    /// `nested_visit_map` to return other htan `None`, in which case it will walk\n+    /// the body.\n     fn visit_nested_body(&mut self, id: BodyId) {\n         let opt_body = self.nested_visit_map().intra().map(|map| map.body(id));\n         if let Some(body) = opt_body {\n@@ -603,7 +605,7 @@ pub fn walk_ty<'v, V: Visitor<'v>>(visitor: &mut V, typ: &'v Ty) {\n             visitor.visit_lifetime(lifetime);\n             visitor.visit_ty(&mutable_type.ty)\n         }\n-        TyKind::Never => {},\n+        TyKind::Never => {}\n         TyKind::Tup(ref tuple_element_types) => {\n             walk_list!(visitor, visit_ty, tuple_element_types);\n         }"}, {"sha": "39dd46c2d2903473e35e8b26a88e3163d24add3d", "filename": "src/librustc/hir/itemlikevisit.rs", "status": "modified", "additions": 10, "deletions": 11, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fitemlikevisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fitemlikevisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fitemlikevisit.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,7 +1,7 @@\n use super::{Item, ImplItem, TraitItem};\n use super::intravisit::Visitor;\n \n-/// The \"item-like visitor\" visitor defines only the top-level methods\n+/// The \"item-like visitor\" defines only the top-level methods\n /// that can be invoked by `Crate::visit_all_item_likes()`. Whether\n /// this trait is the right one to implement will depend on the\n /// overall pattern you need. Here are the three available patterns,\n@@ -18,22 +18,21 @@ use super::intravisit::Visitor;\n ///    an item, but don't care about how item-like things are nested\n ///    within one another.\n ///    - Example: Examine each expression to look for its type and do some check or other.\n-///    - How: Implement `intravisit::Visitor` and use\n-///      `tcx.hir().krate().visit_all_item_likes(visitor.as_deep_visitor())`. Within\n-///      your `intravisit::Visitor` impl, implement methods like\n-///      `visit_expr()`; don't forget to invoke\n-///      `intravisit::walk_visit_expr()` to keep walking the subparts.\n+///    - How: Implement `intravisit::Visitor` and override the `nested_visit_map()` method\n+///      to return `NestedVisitorMap::OnlyBodies` and use\n+///      `tcx.hir().krate().visit_all_item_likes(&mut visitor.as_deep_visitor())`. Within\n+///      your `intravisit::Visitor` impl, implement methods like `visit_expr()` (don't forget\n+///      to invoke `intravisit::walk_expr()` to keep walking the subparts).\n ///    - Pro: Visitor methods for any kind of HIR node, not just item-like things.\n ///    - Pro: Integrates well into dependency tracking.\n ///    - Con: Don't get information about nesting between items\n /// 3. **Nested visit**: Want to visit the whole HIR and you care about the nesting between\n ///    item-like things.\n ///    - Example: Lifetime resolution, which wants to bring lifetimes declared on the\n ///      impl into scope while visiting the impl-items, and then back out again.\n-///    - How: Implement `intravisit::Visitor` and override the\n-///      `nested_visit_map()` methods to return\n-///      `NestedVisitorMap::All`. Walk your crate with\n-///      `intravisit::walk_crate()` invoked on `tcx.hir().krate()`.\n+///    - How: Implement `intravisit::Visitor` and override the `nested_visit_map()` method\n+///      to return `NestedVisitorMap::All`. Walk your crate with `intravisit::walk_crate()`\n+///      invoked on `tcx.hir().krate()`.\n ///    - Pro: Visitor methods for any kind of HIR node, not just item-like things.\n ///    - Pro: Preserves nesting information\n ///    - Con: Does not integrate well into dependency tracking.\n@@ -79,7 +78,7 @@ impl<'v, 'hir, V> ItemLikeVisitor<'hir> for DeepVisitor<'v, V>\n     }\n }\n \n-/// A parallel variant of ItemLikeVisitor\n+/// A parallel variant of `ItemLikeVisitor`.\n pub trait ParItemLikeVisitor<'hir> {\n     fn visit_item(&self, item: &'hir Item);\n     fn visit_trait_item(&self, trait_item: &'hir TraitItem);"}, {"sha": "b50cfa00f09ef63e433b29102fe273dfb0f1caa2", "filename": "src/librustc/hir/lowering.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Flowering.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Flowering.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Flowering.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -79,7 +79,7 @@ const HIR_ID_COUNTER_LOCKED: u32 = 0xFFFFFFFF;\n pub struct LoweringContext<'a> {\n     crate_root: Option<Symbol>,\n \n-    /// Used to assign ids to HIR nodes that do not directly correspond to an AST node.\n+    /// Used to assign IDs to HIR nodes that do not directly correspond to AST nodes.\n     sess: &'a Session,\n \n     cstore: &'a dyn CrateStore,\n@@ -126,7 +126,7 @@ pub struct LoweringContext<'a> {\n     /// lifetime definitions in the corresponding impl or function generics.\n     lifetimes_to_define: Vec<(Span, ParamName)>,\n \n-    /// Whether or not in-band lifetimes are being collected. This is used to\n+    /// `true` if in-band lifetimes are being collected. This is used to\n     /// indicate whether or not we're in a place where new lifetimes will result\n     /// in in-band lifetime definitions, such a function or an impl header,\n     /// including implicit lifetimes from `impl_header_lifetime_elision`.\n@@ -154,13 +154,13 @@ pub struct LoweringContext<'a> {\n }\n \n pub trait Resolver {\n-    /// Obtain resolution for a `NodeId` with a single resolution.\n+    /// Obtains resolution for a `NodeId` with a single resolution.\n     fn get_partial_res(&mut self, id: NodeId) -> Option<PartialRes>;\n \n-    /// Obtain per-namespace resolutions for `use` statement with the given `NoedId`.\n+    /// Obtains per-namespace resolutions for `use` statement with the given `NodeId`.\n     fn get_import_res(&mut self, id: NodeId) -> PerNS<Option<Res<NodeId>>>;\n \n-    /// Obtain resolution for a label with the given `NodeId`.\n+    /// Obtains resolution for a label with the given `NodeId`.\n     fn get_label_res(&mut self, id: NodeId) -> Option<NodeId>;\n \n     /// We must keep the set of definitions up to date as we add nodes that weren't in the AST.\n@@ -699,7 +699,7 @@ impl<'a> LoweringContext<'a> {\n     fn lower_res(&mut self, res: Res<NodeId>) -> Res {\n         res.map_id(|id| {\n             self.lower_node_id_generic(id, |_| {\n-                panic!(\"expected node_id to be lowered already for res {:#?}\", res)\n+                panic!(\"expected `NodeId` to be lowered already for res {:#?}\", res);\n             })\n         })\n     }\n@@ -1364,7 +1364,7 @@ impl<'a> LoweringContext<'a> {\n                     }\n                 }\n             }\n-            TyKind::Mac(_) => bug!(\"`TyMac` should have been expanded by now.\"),\n+            TyKind::Mac(_) => bug!(\"`TyMac` should have been expanded by now\"),\n             TyKind::CVarArgs => {\n                 // Create the implicit lifetime of the \"spoofed\" `VaListImpl`.\n                 let span = self.sess.source_map().next_point(t.span.shrink_to_lo());\n@@ -2999,7 +2999,7 @@ impl<'a> LoweringContext<'a> {\n             }\n             StmtKind::Expr(ref e) => hir::StmtKind::Expr(P(self.lower_expr(e))),\n             StmtKind::Semi(ref e) => hir::StmtKind::Semi(P(self.lower_expr(e))),\n-            StmtKind::Mac(..) => panic!(\"Shouldn't exist here\"),\n+            StmtKind::Mac(..) => panic!(\"shouldn't exist here\"),\n         };\n         smallvec![hir::Stmt {\n             hir_id: self.lower_node_id(s.id),\n@@ -3187,7 +3187,7 @@ impl<'a> LoweringContext<'a> {\n \n         hir::Path {\n             span,\n-            res: res.map_id(|_| panic!(\"unexpected node_id\")),\n+            res: res.map_id(|_| panic!(\"unexpected `NodeId`\")),\n             segments: segments.into(),\n         }\n     }"}, {"sha": "5f82e42abb308ccc32efd82bcc56cf9f15774cd9", "filename": "src/librustc/hir/lowering/item.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Flowering%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Flowering%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Flowering%2Fitem.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -718,7 +718,7 @@ impl LoweringContext<'_> {\n                         AnonymousLifetimeMode::PassThrough,\n                         |this, _| {\n                             (\n-                                // Disallow impl Trait in foreign items\n+                                // Disallow `impl Trait` in foreign items.\n                                 this.lower_fn_decl(fdec, None, false, None),\n                                 this.lower_fn_params_to_names(fdec),\n                             )\n@@ -732,7 +732,7 @@ impl LoweringContext<'_> {\n                         self.lower_ty(t, ImplTraitContext::disallowed()), self.lower_mutability(m))\n                 }\n                 ForeignItemKind::Ty => hir::ForeignItemKind::Type,\n-                ForeignItemKind::Macro(_) => panic!(\"shouldn't exist here\"),\n+                ForeignItemKind::Macro(_) => panic!(\"macro shouldn't exist here\"),\n             },\n             vis: self.lower_visibility(&i.vis, None),\n             span: i.span,"}, {"sha": "4179cf2ff807fd0d169900eef3e3c8bbec10afcf", "filename": "src/librustc/hir/map/collector.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fmap%2Fcollector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fmap%2Fcollector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmap%2Fcollector.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -340,7 +340,7 @@ impl<'a, 'hir> Visitor<'hir> for NodeCollector<'a, 'hir> {\n     /// their outer items.\n \n     fn nested_visit_map<'this>(&'this mut self) -> NestedVisitorMap<'this, 'hir> {\n-        panic!(\"visit_nested_xxx must be manually implemented in this visitor\")\n+        panic!(\"`visit_nested_xxx` must be manually implemented in this visitor\");\n     }\n \n     fn visit_nested_item(&mut self, item: ItemId) {"}, {"sha": "651fe8449ac935cd8c4957b68f947b8fb3bd67d4", "filename": "src/librustc/hir/map/definitions.rs", "status": "modified", "additions": 41, "deletions": 36, "changes": 77, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fmap%2Fdefinitions.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fmap%2Fdefinitions.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmap%2Fdefinitions.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -7,23 +7,24 @@\n use crate::hir;\n use crate::hir::def_id::{CrateNum, DefId, DefIndex, LOCAL_CRATE, CRATE_DEF_INDEX};\n use crate::ich::Fingerprint;\n+use crate::session::CrateDisambiguator;\n+use crate::util::nodemap::NodeMap;\n+\n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::indexed_vec::{IndexVec};\n use rustc_data_structures::stable_hasher::StableHasher;\n-use crate::session::CrateDisambiguator;\n use std::borrow::Borrow;\n use std::fmt::Write;\n use std::hash::Hash;\n use syntax::ast;\n use syntax::ext::hygiene::ExpnId;\n use syntax::symbol::{Symbol, sym, InternedString};\n use syntax_pos::{Span, DUMMY_SP};\n-use crate::util::nodemap::NodeMap;\n \n-/// The DefPathTable maps DefIndexes to DefKeys and vice versa.\n-/// Internally the DefPathTable holds a tree of DefKeys, where each DefKey\n-/// stores the DefIndex of its parent.\n-/// There is one DefPathTable for each crate.\n+/// The `DefPathTable` maps `DefIndex`es to `DefKey`s and vice versa.\n+/// Internally the `DefPathTable` holds a tree of `DefKey`s, where each `DefKey`\n+/// stores the `DefIndex` of its parent.\n+/// There is one `DefPathTable` for each crate.\n #[derive(Clone, Default, RustcDecodable, RustcEncodable)]\n pub struct DefPathTable {\n     index_to_key: Vec<DefKey>,\n@@ -121,7 +122,7 @@ impl DefKey {\n     fn compute_stable_hash(&self, parent_hash: DefPathHash) -> DefPathHash {\n         let mut hasher = StableHasher::new();\n \n-        // We hash a 0u8 here to disambiguate between regular DefPath hashes,\n+        // We hash a `0u8` here to disambiguate between regular `DefPath` hashes,\n         // and the special \"root_parent\" below.\n         0u8.hash(&mut hasher);\n         parent_hash.hash(&mut hasher);\n@@ -145,8 +146,7 @@ impl DefKey {\n                                crate_disambiguator: CrateDisambiguator)\n                                -> DefPathHash {\n         let mut hasher = StableHasher::new();\n-        // Disambiguate this from a regular DefPath hash,\n-        // see compute_stable_hash() above.\n+        // Disambiguate this from a regular `DefPath` hash; see `compute_stable_hash()` above.\n         1u8.hash(&mut hasher);\n         crate_name.hash(&mut hasher);\n         crate_disambiguator.hash(&mut hasher);\n@@ -155,10 +155,10 @@ impl DefKey {\n }\n \n /// A pair of `DefPathData` and an integer disambiguator. The integer is\n-/// normally 0, but in the event that there are multiple defs with the\n+/// normally `0`, but in the event that there are multiple defs with the\n /// same `parent` and `data`, we use this field to disambiguate\n /// between them. This introduces some artificial ordering dependency\n-/// but means that if you have (e.g.) two impls for the same type in\n+/// but means that if you have, e.g., two impls for the same type in\n /// the same module, they do get distinct `DefId`s.\n #[derive(Clone, PartialEq, Debug, Hash, RustcEncodable, RustcDecodable)]\n pub struct DisambiguatedDefPathData {\n@@ -277,29 +277,34 @@ impl DefPath {\n pub enum DefPathData {\n     // Root: these should only be used for the root nodes, because\n     // they are treated specially by the `def_path` function.\n-    /// The crate root (marker)\n+\n+    /// The crate root (marker).\n     CrateRoot,\n-    // Catch-all for random DefId things like `DUMMY_NODE_ID`\n+    // Catch-all for random `DefId` things like `DUMMY_NODE_ID`.\n     Misc,\n+\n     // Different kinds of items and item-like things:\n-    /// An impl\n+\n+    /// An impl.\n     Impl,\n-    /// Something in the type NS\n+    /// Something in the type namespace.\n     TypeNs(InternedString),\n-    /// Something in the value NS\n+    /// Something in the value namespace.\n     ValueNs(InternedString),\n-    /// Something in the macro NS\n+    /// Something in the macro namespace.\n     MacroNs(InternedString),\n-    /// Something in the lifetime NS\n+    /// Something in the lifetime namespace.\n     LifetimeNs(InternedString),\n-    /// A closure expression\n+    /// A closure expression.\n     ClosureExpr,\n-    // Subportions of items\n-    /// Implicit ctor for a unit or tuple-like struct or enum variant.\n+\n+    // Subportions of items:\n+\n+    /// Implicit constructor for a unit or tuple-like struct or enum variant.\n     Ctor,\n-    /// A constant expression (see {ast,hir}::AnonConst).\n+    /// A constant expression (see `{ast,hir}::AnonConst`).\n     AnonConst,\n-    /// An `impl Trait` type node\n+    /// An `impl Trait` type node.\n     ImplTrait,\n     /// Identifies a piece of crate metadata that is global to a whole crate\n     /// (as opposed to just one item). `GlobalMetaData` components are only\n@@ -435,7 +440,7 @@ impl Definitions {\n         self.node_to_def_index.insert(ast::CRATE_NODE_ID, root_index);\n         self.set_invocation_parent(ExpnId::root(), root_index);\n \n-        // Allocate some other DefIndices that always must exist.\n+        // Allocate some other `DefIndex`es that always must exist.\n         GlobalMetaDataKind::allocate_def_indices(self);\n \n         root_index\n@@ -458,7 +463,7 @@ impl Definitions {\n                 data,\n                 self.table.def_key(self.node_to_def_index[&node_id]));\n \n-        // The root node must be created with create_root_def()\n+        // The root node must be created with `create_root_def()`.\n         assert!(data != DefPathData::CrateRoot);\n \n         // Find the next free disambiguator for this key.\n@@ -486,9 +491,9 @@ impl Definitions {\n         assert_eq!(index.index(), self.def_index_to_node.len());\n         self.def_index_to_node.push(node_id);\n \n-        // Some things for which we allocate DefIndices don't correspond to\n-        // anything in the AST, so they don't have a NodeId. For these cases\n-        // we don't need a mapping from NodeId to DefIndex.\n+        // Some things for which we allocate `DefIndex`es don't correspond to\n+        // anything in the AST, so they don't have a `NodeId`. For these cases\n+        // we don't need a mapping from `NodeId` to `DefIndex`.\n         if node_id != ast::DUMMY_NODE_ID {\n             debug!(\"create_def_with_parent: def_index_to_node[{:?} <-> {:?}\", index, node_id);\n             self.node_to_def_index.insert(node_id, index);\n@@ -498,20 +503,20 @@ impl Definitions {\n             self.expansions_that_defined.insert(index, expn_id);\n         }\n \n-        // The span is added if it isn't dummy\n+        // The span is added if it isn't dummy.\n         if !span.is_dummy() {\n             self.def_index_to_span.insert(index, span);\n         }\n \n         index\n     }\n \n-    /// Initialize the `ast::NodeId` to `HirId` mapping once it has been generated during\n+    /// Initializes the `ast::NodeId` to `HirId` mapping once it has been generated during\n     /// AST to HIR lowering.\n     pub fn init_node_id_to_hir_id_mapping(&mut self,\n                                           mapping: IndexVec<ast::NodeId, hir::HirId>) {\n         assert!(self.node_to_hir_id.is_empty(),\n-                \"Trying initialize NodeId -> HirId mapping twice\");\n+                \"trying to initialize `NodeId` -> `HirId` mapping twice\");\n         self.node_to_hir_id = mapping;\n     }\n \n@@ -533,7 +538,7 @@ impl Definitions {\n \n     pub fn set_invocation_parent(&mut self, invoc_id: ExpnId, parent: DefIndex) {\n         let old_parent = self.invocation_parents.insert(invoc_id, parent);\n-        assert!(old_parent.is_none(), \"parent def-index is reset for an invocation\");\n+        assert!(old_parent.is_none(), \"parent `DefIndex` is reset for an invocation\");\n     }\n }\n \n@@ -585,9 +590,9 @@ impl DefPathData {\n     }\n }\n \n-// We define the GlobalMetaDataKind enum with this macro because we want to\n+// We define the `GlobalMetaDataKind` enum with this macro because we want to\n // make sure that we exhaustively iterate over all variants when registering\n-// the corresponding DefIndices in the DefTable.\n+// the corresponding `DefIndex`es in the `DefTable`.\n macro_rules! define_global_metadata_kind {\n     (pub enum GlobalMetaDataKind {\n         $($variant:ident),*\n@@ -609,7 +614,7 @@ macro_rules! define_global_metadata_kind {\n                         DUMMY_SP\n                     );\n \n-                    // Make sure calling def_index does not crash.\n+                    // Make sure calling `def_index` does not crash.\n                     instance.def_index(&definitions.table);\n                 })*\n             }\n@@ -623,7 +628,7 @@ macro_rules! define_global_metadata_kind {\n                     }\n                 };\n \n-                // These DefKeys are all right after the root,\n+                // These `DefKey`s are all right after the root,\n                 // so a linear search is fine.\n                 let index = def_path_table.index_to_key\n                                           .iter()"}, {"sha": "5cec8a593f12af42337d18b12bf41164b2a516f1", "filename": "src/librustc/hir/map/mod.rs", "status": "modified", "additions": 19, "deletions": 22, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fmap%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fmap%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmap%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -5,10 +5,15 @@ pub use self::definitions::{\n };\n \n use crate::dep_graph::{DepGraph, DepNode, DepKind, DepNodeIndex};\n-\n+use crate::hir::*;\n+use crate::hir::DefKind;\n use crate::hir::def_id::{CRATE_DEF_INDEX, DefId, LocalDefId};\n-\n+use crate::hir::itemlikevisit::ItemLikeVisitor;\n+use crate::hir::print::Nested;\n use crate::middle::cstore::CrateStoreDyn;\n+use crate::ty::query::Providers;\n+use crate::util::nodemap::FxHashMap;\n+use crate::util::common::time;\n \n use rustc_target::spec::abi::Abi;\n use rustc_data_structures::svh::Svh;\n@@ -18,15 +23,7 @@ use syntax::source_map::Spanned;\n use syntax::ext::base::MacroKind;\n use syntax_pos::{Span, DUMMY_SP};\n \n-use crate::hir::*;\n-use crate::hir::DefKind;\n-use crate::hir::itemlikevisit::ItemLikeVisitor;\n-use crate::hir::print::Nested;\n-use crate::util::nodemap::FxHashMap;\n-use crate::util::common::time;\n-\n use std::result::Result::Err;\n-use crate::ty::query::Providers;\n \n pub mod blocks;\n mod collector;\n@@ -627,7 +624,7 @@ impl<'hir> Map<'hir> {\n             .unwrap_or(hir_id)\n     }\n \n-    /// Check if the node is an argument. An argument is a local variable whose\n+    /// Checks if the node is an argument. An argument is a local variable whose\n     /// immediate parent is an item or a closure.\n     pub fn is_argument(&self, id: HirId) -> bool {\n         match self.find(id) {\n@@ -733,7 +730,7 @@ impl<'hir> Map<'hir> {\n     /// ```\n     /// fn foo(x: usize) -> bool {\n     ///     if x == 1 {\n-    ///         true  // `get_return_block` gets passed the `id` corresponding\n+    ///         true  // If `get_return_block` gets passed the `id` corresponding\n     ///     } else {  // to this, it will return `foo`'s `HirId`.\n     ///         false\n     ///     }\n@@ -743,7 +740,7 @@ impl<'hir> Map<'hir> {\n     /// ```\n     /// fn foo(x: usize) -> bool {\n     ///     loop {\n-    ///         true  // `get_return_block` gets passed the `id` corresponding\n+    ///         true  // If `get_return_block` gets passed the `id` corresponding\n     ///     }         // to this, it will return `None`.\n     ///     false\n     /// }\n@@ -994,9 +991,9 @@ impl<'hir> Map<'hir> {\n         self.map.iter().enumerate().filter_map(|(i, local_map)| {\n             local_map.as_ref().map(|m| (i, m))\n         }).flat_map(move |(array_index, local_map)| {\n-            // Iterate over each valid entry in the local map\n+            // Iterate over each valid entry in the local map.\n             local_map.iter_enumerated().filter_map(move |(i, entry)| entry.map(move |_| {\n-                // Reconstruct the HirId based on the 3 indices we used to find it\n+                // Reconstruct the `HirId` based on the 3 indices we used to find it.\n                 HirId {\n                     owner: DefIndex::from(array_index),\n                     local_id: i,\n@@ -1207,7 +1204,7 @@ pub fn map_crate<'hir>(sess: &crate::session::Session,\n         definitions,\n     };\n \n-    time(sess, \"validate hir map\", || {\n+    time(sess, \"validate HIR map\", || {\n         hir_id_validator::check_crate(&map);\n     });\n \n@@ -1247,18 +1244,18 @@ impl<'a> print::State<'a> {\n             Node::Pat(a)          => self.print_pat(&a),\n             Node::Arm(a)          => self.print_arm(&a),\n             Node::Block(a)        => {\n-                // containing cbox, will be closed by print-block at }\n+                // Containing cbox, will be closed by print-block at `}`.\n                 self.cbox(print::INDENT_UNIT);\n-                // head-ibox, will be closed by print-block after {\n+                // Head-ibox, will be closed by print-block after `{`.\n                 self.ibox(0);\n                 self.print_block(&a)\n             }\n             Node::Lifetime(a)     => self.print_lifetime(&a),\n             Node::Visibility(a)   => self.print_visibility(&a),\n             Node::GenericParam(_) => bug!(\"cannot print Node::GenericParam\"),\n             Node::Field(_)        => bug!(\"cannot print StructField\"),\n-            // these cases do not carry enough information in the\n-            // hir_map to reconstruct their full structure for pretty\n+            // These cases do not carry enough information in the\n+            // `hir_map` to reconstruct their full structure for pretty\n             // printing.\n             Node::Ctor(..)        => bug!(\"cannot print isolated Ctor\"),\n             Node::Local(a)        => self.print_local_decl(&a),\n@@ -1273,8 +1270,8 @@ fn hir_id_to_string(map: &Map<'_>, id: HirId, include_id: bool) -> String {\n     let id_str = if include_id { &id_str[..] } else { \"\" };\n \n     let path_str = || {\n-        // This functionality is used for debugging, try to use TyCtxt to get\n-        // the user-friendly path, otherwise fall back to stringifying DefPath.\n+        // This functionality is used for debugging, try to use `TyCtxt` to get\n+        // the user-friendly path, otherwise fall back to stringifying `DefPath`.\n         crate::ty::tls::with_opt(|tcx| {\n             if let Some(tcx) = tcx {\n                 let def_id = map.local_def_id(id);"}, {"sha": "f5e644625729b98f75a8ca095418be2a2f4a8fa8", "filename": "src/librustc/hir/mod.rs", "status": "modified", "additions": 26, "deletions": 27, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -13,26 +13,24 @@ pub use self::UnsafeSource::*;\n use crate::hir::def::{Res, DefKind};\n use crate::hir::def_id::{DefId, DefIndex, LocalDefId, CRATE_DEF_INDEX};\n use crate::hir::ptr::P;\n-use crate::util::nodemap::{NodeMap, FxHashSet};\n use crate::mir::mono::Linkage;\n+use crate::ty::AdtKind;\n+use crate::ty::query::Providers;\n+use crate::util::nodemap::{NodeMap, FxHashSet};\n \n use errors::FatalError;\n use syntax_pos::{Span, DUMMY_SP, symbol::InternedString, MultiSpan};\n use syntax::source_map::Spanned;\n-use rustc_target::spec::abi::Abi;\n use syntax::ast::{self, CrateSugar, Ident, Name, NodeId, AsmDialect};\n use syntax::ast::{Attribute, Label, LitKind, StrStyle, FloatTy, IntTy, UintTy};\n use syntax::attr::{InlineAttr, OptimizeAttr};\n use syntax::symbol::{Symbol, kw};\n use syntax::tokenstream::TokenStream;\n use syntax::util::parser::ExprPrecedence;\n-use crate::ty::AdtKind;\n-use crate::ty::query::Providers;\n-\n+use rustc_target::spec::abi::Abi;\n use rustc_data_structures::sync::{par_for_each_in, Send, Sync};\n use rustc_data_structures::thin_vec::ThinVec;\n use rustc_macros::HashStable;\n-\n use rustc_serialize::{self, Encoder, Encodable, Decoder, Decodable};\n use std::collections::{BTreeSet, BTreeMap};\n use std::fmt;\n@@ -99,7 +97,8 @@ impl rustc_serialize::UseSpecializedEncodable for HirId {\n         } = *self;\n \n         owner.encode(s)?;\n-        local_id.encode(s)\n+        local_id.encode(s)?;\n+        Ok(())\n     }\n }\n \n@@ -121,7 +120,7 @@ impl fmt::Display for HirId {\n     }\n }\n \n-// Hack to ensure that we don't try to access the private parts of `ItemLocalId` in this module\n+// Hack to ensure that we don't try to access the private parts of `ItemLocalId` in this module.\n mod item_local_id_inner {\n     use rustc_data_structures::indexed_vec::Idx;\n     use rustc_macros::HashStable;\n@@ -746,7 +745,7 @@ pub struct Crate {\n     // Attributes from non-exported macros, kept only for collecting the library feature list.\n     pub non_exported_macro_attrs: HirVec<Attribute>,\n \n-    // N.B., we use a BTreeMap here so that `visit_all_items` iterates\n+    // N.B., we use a `BTreeMap` here so that `visit_all_items` iterates\n     // over the ids in increasing order. In principle it should not\n     // matter what order we visit things in, but in *practice* it\n     // does, because it can affect the order in which errors are\n@@ -1403,13 +1402,13 @@ pub struct AnonConst {\n     pub body: BodyId,\n }\n \n-/// An expression\n+/// An expression.\n #[derive(RustcEncodable, RustcDecodable)]\n pub struct Expr {\n-    pub span: Span,\n+    pub hir_id: HirId,\n     pub node: ExprKind,\n     pub attrs: ThinVec<Attribute>,\n-    pub hir_id: HirId,\n+    pub span: Span,\n }\n \n // `Expr` is used a lot. Make sure it doesn't unintentionally get bigger.\n@@ -2422,37 +2421,37 @@ pub enum ItemKind {\n     ///\n     /// or just\n     ///\n-    /// `use foo::bar::baz;` (with `as baz` implicitly on the right)\n+    /// `use foo::bar::baz;` (with `as baz` implicitly on the right).\n     Use(P<Path>, UseKind),\n \n-    /// A `static` item\n+    /// A `static` item.\n     Static(P<Ty>, Mutability, BodyId),\n-    /// A `const` item\n+    /// A `const` item.\n     Const(P<Ty>, BodyId),\n-    /// A function declaration\n+    /// A function declaration.\n     Fn(P<FnDecl>, FnHeader, Generics, BodyId),\n-    /// A module\n+    /// A module.\n     Mod(Mod),\n-    /// An external module\n+    /// An external module.\n     ForeignMod(ForeignMod),\n-    /// Module-level inline assembly (from global_asm!)\n+    /// Module-level inline assembly (from `global_asm!`).\n     GlobalAsm(P<GlobalAsm>),\n-    /// A type alias, e.g., `type Foo = Bar<u8>`\n+    /// A type alias, e.g., `type Foo = Bar<u8>`.\n     TyAlias(P<Ty>, Generics),\n-    /// An opaque `impl Trait` type alias, e.g., `type Foo = impl Bar;`\n+    /// An opaque `impl Trait` type alias, e.g., `type Foo = impl Bar;`.\n     OpaqueTy(OpaqueTy),\n-    /// An enum definition, e.g., `enum Foo<A, B> {C<A>, D<B>}`\n+    /// An enum definition, e.g., `enum Foo<A, B> {C<A>, D<B>}`.\n     Enum(EnumDef, Generics),\n-    /// A struct definition, e.g., `struct Foo<A> {x: A}`\n+    /// A struct definition, e.g., `struct Foo<A> {x: A}`.\n     Struct(VariantData, Generics),\n-    /// A union definition, e.g., `union Foo<A, B> {x: A, y: B}`\n+    /// A union definition, e.g., `union Foo<A, B> {x: A, y: B}`.\n     Union(VariantData, Generics),\n-    /// A trait definition\n+    /// A trait definition.\n     Trait(IsAuto, Unsafety, Generics, GenericBounds, HirVec<TraitItemRef>),\n-    /// A trait alias\n+    /// A trait alias.\n     TraitAlias(Generics, GenericBounds),\n \n-    /// An implementation, eg `impl<A> Trait for Foo { .. }`\n+    /// An implementation, e.g., `impl<A> Trait for Foo { .. }`.\n     Impl(Unsafety,\n          ImplPolarity,\n          Defaultness,"}, {"sha": "cfbfb5eceb550f4016afe6b49f82cc29b462de5b", "filename": "src/librustc/hir/print.rs", "status": "modified", "additions": 13, "deletions": 12, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fprint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fhir%2Fprint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fprint.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1293,11 +1293,11 @@ impl<'a> State<'a> {\n                 self.print_closure_params(&decl, body);\n                 self.s.space();\n \n-                // this is a bare expression\n+                // This is a bare expression.\n                 self.ann.nested(self, Nested::Body(body));\n                 self.end(); // need to close a box\n \n-                // a box will be closed by print_expr, but we didn't want an overall\n+                // A box will be closed by `print_expr`, but we didn't want an overall\n                 // wrapper so we closed the corresponding opening. so create an\n                 // empty box to satisfy the close.\n                 self.ibox(0);\n@@ -1307,9 +1307,9 @@ impl<'a> State<'a> {\n                     self.print_ident(label.ident);\n                     self.word_space(\":\");\n                 }\n-                // containing cbox, will be closed by print-block at }\n+                // containing cbox, will be closed by print-block at `}`\n                 self.cbox(INDENT_UNIT);\n-                // head-box, will be closed by print-block after {\n+                // head-box, will be closed by print-block after `{`\n                 self.ibox(0);\n                 self.print_block(&blk);\n             }\n@@ -1759,7 +1759,7 @@ impl<'a> State<'a> {\n                         self.word_space(\",\");\n                     }\n                     if let PatKind::Wild = p.node {\n-                        // Print nothing\n+                        // Print nothing.\n                     } else {\n                         self.print_pat(&p);\n                     }\n@@ -1891,7 +1891,7 @@ impl<'a> State<'a> {\n             i += 1;\n \n             if let hir::TyKind::Infer = ty.node {\n-                // Print nothing\n+                // Print nothing.\n             } else {\n                 s.s.word(\":\");\n                 s.s.space();\n@@ -2221,14 +2221,15 @@ impl<'a> State<'a> {\n     }\n }\n \n-// Dup'ed from parse::classify, but adapted for the HIR.\n /// Does this expression require a semicolon to be treated\n /// as a statement? The negation of this: 'can this expression\n /// be used as a statement without a semicolon' -- is used\n /// as an early-bail-out in the parser so that, for instance,\n ///     if true {...} else {...}\n ///      |x| 5\n /// isn't parsed as (if true {...} else {...} | x) | 5\n+//\n+// Duplicated from `parse::classify`, but adapted for the HIR.\n fn expr_requires_semi_to_be_stmt(e: &hir::Expr) -> bool {\n     match e.node {\n         hir::ExprKind::Match(..) |\n@@ -2238,7 +2239,7 @@ fn expr_requires_semi_to_be_stmt(e: &hir::Expr) -> bool {\n     }\n }\n \n-/// this statement requires a semicolon after it.\n+/// This statement requires a semicolon after it.\n /// note that in one case (stmt_semi), we've already\n /// seen the semicolon, and thus don't need another.\n fn stmt_ends_with_semi(stmt: &hir::StmtKind) -> bool {\n@@ -2277,7 +2278,7 @@ fn bin_op_to_assoc_op(op: hir::BinOpKind) -> AssocOp {\n     }\n }\n \n-/// Expressions that syntactically contain an \"exterior\" struct literal i.e., not surrounded by any\n+/// Expressions that syntactically contain an \"exterior\" struct literal, i.e., not surrounded by any\n /// parens or other delimiters, e.g., `X { y: 1 }`, `X { y: 1 }.method()`, `foo == X { y: 1 }` and\n /// `X { y: 1 } == foo` all do, but `(X { y: 1 }) == foo` does not.\n fn contains_exterior_struct_lit(value: &hir::Expr) -> bool {\n@@ -2287,20 +2288,20 @@ fn contains_exterior_struct_lit(value: &hir::Expr) -> bool {\n         hir::ExprKind::Assign(ref lhs, ref rhs) |\n         hir::ExprKind::AssignOp(_, ref lhs, ref rhs) |\n         hir::ExprKind::Binary(_, ref lhs, ref rhs) => {\n-            // X { y: 1 } + X { y: 2 }\n+            // `X { y: 1 } + X { y: 2 }`\n             contains_exterior_struct_lit(&lhs) || contains_exterior_struct_lit(&rhs)\n         }\n         hir::ExprKind::Unary(_, ref x) |\n         hir::ExprKind::Cast(ref x, _) |\n         hir::ExprKind::Type(ref x, _) |\n         hir::ExprKind::Field(ref x, _) |\n         hir::ExprKind::Index(ref x, _) => {\n-            // &X { y: 1 }, X { y: 1 }.y\n+            // `&X { y: 1 }, X { y: 1 }.y`\n             contains_exterior_struct_lit(&x)\n         }\n \n         hir::ExprKind::MethodCall(.., ref exprs) => {\n-            // X { y: 1 }.bar(...)\n+            // `X { y: 1 }.bar(...)`\n             contains_exterior_struct_lit(&exprs[0])\n         }\n "}, {"sha": "182a9ade8c36ead44a39da901c9126bc1cf5c4b3", "filename": "src/librustc/ich/hcx.rs", "status": "modified", "additions": 25, "deletions": 29, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fich%2Fhcx.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fich%2Fhcx.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fhcx.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -12,17 +12,16 @@ use std::hash as std_hash;\n use std::cell::RefCell;\n \n use syntax::ast;\n-\n use syntax::source_map::SourceMap;\n use syntax::ext::hygiene::SyntaxContext;\n use syntax::symbol::Symbol;\n use syntax::tokenstream::DelimSpan;\n use syntax_pos::{Span, DUMMY_SP};\n use syntax_pos::hygiene;\n \n-use rustc_data_structures::stable_hasher::{HashStable,\n-                                           StableHasher, StableHasherResult,\n-                                           ToStableHashKey};\n+use rustc_data_structures::stable_hasher::{\n+    HashStable, StableHasher, StableHasherResult, ToStableHashKey,\n+};\n use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n use smallvec::SmallVec;\n \n@@ -32,9 +31,9 @@ fn compute_ignored_attr_names() -> FxHashSet<Symbol> {\n }\n \n /// This is the context state available during incr. comp. hashing. It contains\n-/// enough information to transform DefIds and HirIds into stable DefPaths (i.e.\n-/// a reference to the TyCtxt) and it holds a few caches for speeding up various\n-/// things (e.g., each DefId/DefPath is only hashed once).\n+/// enough information to transform `DefId`s and `HirId`s into stable `DefPath`s (i.e.,\n+/// a reference to the `TyCtxt`) and it holds a few caches for speeding up various\n+/// things (e.g., each `DefId`/`DefPath` is only hashed once).\n #[derive(Clone)]\n pub struct StableHashingContext<'a> {\n     sess: &'a Session,\n@@ -46,7 +45,7 @@ pub struct StableHashingContext<'a> {\n     node_id_hashing_mode: NodeIdHashingMode,\n \n     // Very often, we are hashing something that does not need the\n-    // CachingSourceMapView, so we initialize it lazily.\n+    // `CachingSourceMapView`, so we initialize it lazily.\n     raw_source_map: &'a SourceMap,\n     caching_source_map: Option<CachingSourceMapView<'a>>,\n }\n@@ -57,24 +56,24 @@ pub enum NodeIdHashingMode {\n     HashDefPath,\n }\n \n-/// The BodyResolver allows to map a BodyId to the corresponding hir::Body.\n-/// We could also just store a plain reference to the hir::Crate but we want\n+/// The `BodyResolver` allows mapping a `BodyId` to the corresponding `hir::Body`.\n+/// We could also just store a plain reference to the `hir::Crate` but we want\n /// to avoid that the crate is used to get untracked access to all of the HIR.\n #[derive(Clone, Copy)]\n struct BodyResolver<'tcx>(&'tcx hir::Crate);\n \n impl<'tcx> BodyResolver<'tcx> {\n-    // Return a reference to the hir::Body with the given BodyId.\n-    // DOES NOT DO ANY TRACKING, use carefully.\n+    /// Returns a reference to the `hir::Body` with the given `BodyId`.\n+    /// **Does not do any tracking**; use carefully.\n     fn body(self, id: hir::BodyId) -> &'tcx hir::Body {\n         self.0.body(id)\n     }\n }\n \n impl<'a> StableHashingContext<'a> {\n-    // The `krate` here is only used for mapping BodyIds to Bodies.\n-    // Don't use it for anything else or you'll run the risk of\n-    // leaking data out of the tracking system.\n+    /// The `krate` here is only used for mapping `BodyId`s to `Body`s.\n+    /// Don't use it for anything else or you'll run the risk of\n+    /// leaking data out of the tracking system.\n     #[inline]\n     pub fn new(sess: &'a Session,\n                krate: &'a hir::Crate,\n@@ -217,9 +216,7 @@ impl<'a> StableHashingContextProvider<'a> for StableHashingContext<'a> {\n     }\n }\n \n-impl<'a> crate::dep_graph::DepGraphSafe for StableHashingContext<'a> {\n-}\n-\n+impl<'a> crate::dep_graph::DepGraphSafe for StableHashingContext<'a> {}\n \n impl<'a> HashStable<StableHashingContext<'a>> for hir::BodyId {\n     fn hash_stable<W: StableHasherResult>(&self,\n@@ -292,16 +289,15 @@ impl<'a> ToStableHashKey<StableHashingContext<'a>> for ast::NodeId {\n }\n \n impl<'a> HashStable<StableHashingContext<'a>> for Span {\n-\n-    // Hash a span in a stable way. We can't directly hash the span's BytePos\n-    // fields (that would be similar to hashing pointers, since those are just\n-    // offsets into the SourceMap). Instead, we hash the (file name, line, column)\n-    // triple, which stays the same even if the containing SourceFile has moved\n-    // within the SourceMap.\n-    // Also note that we are hashing byte offsets for the column, not unicode\n-    // codepoint offsets. For the purpose of the hash that's sufficient.\n-    // Also, hashing filenames is expensive so we avoid doing it twice when the\n-    // span starts and ends in the same file, which is almost always the case.\n+    /// Hashes a span in a stable way. We can't directly hash the span's `BytePos`\n+    /// fields (that would be similar to hashing pointers, since those are just\n+    /// offsets into the `SourceMap`). Instead, we hash the (file name, line, column)\n+    /// triple, which stays the same even if the containing `SourceFile` has moved\n+    /// within the `SourceMap`.\n+    /// Also note that we are hashing byte offsets for the column, not unicode\n+    /// codepoint offsets. For the purpose of the hash that's sufficient.\n+    /// Also, hashing filenames is expensive so we avoid doing it twice when the\n+    /// span starts and ends in the same file, which is almost always the case.\n     fn hash_stable<W: StableHasherResult>(&self,\n                                           hcx: &mut StableHashingContext<'a>,\n                                           hasher: &mut StableHasher<W>) {\n@@ -340,7 +336,7 @@ impl<'a> HashStable<StableHashingContext<'a>> for Span {\n         }\n \n         std_hash::Hash::hash(&TAG_VALID_SPAN, hasher);\n-        // We truncate the stable_id hash and line and col numbers. The chances\n+        // We truncate the stable ID hash and line and column numbers. The chances\n         // of causing a collision this way should be minimal.\n         std_hash::Hash::hash(&(file_lo.name_hash as u64), hasher);\n "}, {"sha": "6e6492d0426f257c7fe9927b9361f9c9c5a3bf48", "filename": "src/librustc/ich/impls_hir.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fich%2Fimpls_hir.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fich%2Fimpls_hir.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_hir.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -5,8 +5,10 @@ use crate::hir;\n use crate::hir::map::DefPathHash;\n use crate::hir::def_id::{DefId, LocalDefId, CrateNum, CRATE_DEF_INDEX};\n use crate::ich::{StableHashingContext, NodeIdHashingMode, Fingerprint};\n-use rustc_data_structures::stable_hasher::{HashStable, ToStableHashKey,\n-                                           StableHasher, StableHasherResult};\n+\n+use rustc_data_structures::stable_hasher::{\n+    HashStable, ToStableHashKey, StableHasher, StableHasherResult,\n+};\n use smallvec::SmallVec;\n use std::mem;\n use syntax::ast;\n@@ -82,9 +84,9 @@ for hir::ItemLocalId {\n     }\n }\n \n-// The following implementations of HashStable for ItemId, TraitItemId, and\n-// ImplItemId deserve special attention. Normally we do not hash NodeIds within\n-// the HIR, since they just signify a HIR nodes own path. But ItemId et al\n+// The following implementations of HashStable for `ItemId`, `TraitItemId`, and\n+// `ImplItemId` deserve special attention. Normally we do not hash `NodeId`s within\n+// the HIR, since they just signify a HIR nodes own path. But `ItemId` et al\n // are used when another item in the HIR is *referenced* and we certainly\n // want to pick up on a reference changing its target, so we hash the NodeIds\n // in \"DefPath Mode\".\n@@ -131,7 +133,6 @@ impl<'a> HashStable<StableHashingContext<'a>> for hir::ImplItemId {\n     }\n }\n \n-\n impl_stable_hash_for!(struct ast::Label {\n     ident\n });\n@@ -241,7 +242,7 @@ impl<'a> HashStable<StableHashingContext<'a>> for hir::ImplItem {\n     }\n }\n \n-impl_stable_hash_for!(enum ::syntax::ast::CrateSugar {\n+impl_stable_hash_for!(enum ast::CrateSugar {\n     JustCrate,\n     PubCrate,\n });\n@@ -365,8 +366,7 @@ impl<'a> HashStable<StableHashingContext<'a>> for hir::def_id::DefIndex {\n     }\n }\n \n-impl<'a> ToStableHashKey<StableHashingContext<'a>>\n-for hir::def_id::DefIndex {\n+impl<'a> ToStableHashKey<StableHashingContext<'a>> for hir::def_id::DefIndex {\n     type KeyType = DefPathHash;\n \n     #[inline]"}, {"sha": "f230c53728748d4a215cc7186a98b79303977fee", "filename": "src/librustc/ich/impls_ty.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fich%2Fimpls_ty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fich%2Fimpls_ty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_ty.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -204,7 +204,7 @@ impl<'a> HashStable<StableHashingContext<'a>> for ty::TyVid {\n     fn hash_stable<W: StableHasherResult>(&self,\n                                           _hcx: &mut StableHashingContext<'a>,\n                                           _hasher: &mut StableHasher<W>) {\n-        // TyVid values are confined to an inference context and hence\n+        // `TyVid` values are confined to an inference context and hence\n         // should not be hashed.\n         bug!(\"ty::TyKind::hash_stable() - can't hash a TyVid {:?}.\", *self)\n     }\n@@ -214,7 +214,7 @@ impl<'a> HashStable<StableHashingContext<'a>> for ty::IntVid {\n     fn hash_stable<W: StableHasherResult>(&self,\n                                           _hcx: &mut StableHashingContext<'a>,\n                                           _hasher: &mut StableHasher<W>) {\n-        // IntVid values are confined to an inference context and hence\n+        // `IntVid` values are confined to an inference context and hence\n         // should not be hashed.\n         bug!(\"ty::TyKind::hash_stable() - can't hash an IntVid {:?}.\", *self)\n     }\n@@ -224,7 +224,7 @@ impl<'a> HashStable<StableHashingContext<'a>> for ty::FloatVid {\n     fn hash_stable<W: StableHasherResult>(&self,\n                                           _hcx: &mut StableHashingContext<'a>,\n                                           _hasher: &mut StableHasher<W>) {\n-        // FloatVid values are confined to an inference context and hence\n+        // `FloatVid` values are confined to an inference context and hence\n         // should not be hashed.\n         bug!(\"ty::TyKind::hash_stable() - can't hash a FloatVid {:?}.\", *self)\n     }"}, {"sha": "8638f42976f046daee626580817142e3feafda6f", "filename": "src/librustc/infer/mod.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Finfer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Finfer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Finfer%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1321,13 +1321,13 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n         T: TypeFoldable<'tcx>,\n     {\n         if !value.needs_infer() {\n-            return value.clone(); // avoid duplicated subst-folding\n+            return value.clone(); // Avoid duplicated subst-folding.\n         }\n         let mut r = resolve::OpportunisticVarResolver::new(self);\n         value.fold_with(&mut r)\n     }\n \n-    /// Returns first unresolved variable contained in `T`. In the\n+    /// Returns the first unresolved variable contained in `T`. In the\n     /// process of visiting `T`, this will resolve (where possible)\n     /// type variables in `T`, but it never constructs the final,\n     /// resolved type, so it's more efficient than\n@@ -1462,7 +1462,7 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n \n         let copy_def_id = self.tcx.require_lang_item(lang_items::CopyTraitLangItem, None);\n \n-        // this can get called from typeck (by euv), and moves_by_default\n+        // This can get called from typeck (by euv), and `moves_by_default`\n         // rightly refuses to work with inference variables, but\n         // moves_by_default has a cache, which we want to use in other\n         // cases.\n@@ -1482,7 +1482,7 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n         closure_kind_ty.to_opt_closure_kind()\n     }\n \n-    /// Obtain the signature of a closure. For closures, unlike\n+    /// Obtains the signature of a closure. For closures, unlike\n     /// `tcx.fn_sig(def_id)`, this method will work during the\n     /// type-checking of the enclosing function and return the closure\n     /// signature in its partially inferred state."}, {"sha": "63ef82a7401a3b33666adf5715d3bf96f6b7559e", "filename": "src/librustc/lib.rs", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -45,7 +45,6 @@\n #![feature(non_exhaustive)]\n #![feature(optin_builtin_traits)]\n #![feature(range_is_empty)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(slice_patterns)]\n #![feature(specialization)]\n #![feature(unboxed_closures)]\n@@ -88,8 +87,6 @@ mod tests;\n #[macro_use]\n mod macros;\n \n-// N.B., this module needs to be declared first so diagnostics are\n-// registered before they are used.\n pub mod error_codes;\n \n #[macro_use]\n@@ -142,6 +139,3 @@ pub mod util {\n \n // Allows macros to refer to this crate as `::rustc`\n extern crate self as rustc;\n-\n-// Build the diagnostics array at the end so that the metadata includes error use sites.\n-__build_diagnostic_array! { librustc, DIAGNOSTICS }"}, {"sha": "c658120b95df36a393aa7c773b9f4906cec6971d", "filename": "src/librustc/lint/context.rs", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Flint%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Flint%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flint%2Fcontext.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -16,32 +16,32 @@\n \n use self::TargetLint::*;\n \n-use std::slice;\n-use rustc_data_structures::sync::{ReadGuard, Lock, ParallelIterator, join, par_iter};\n+use crate::hir;\n+use crate::hir::def_id::{CrateNum, DefId, LOCAL_CRATE};\n+use crate::hir::intravisit as hir_visit;\n+use crate::hir::intravisit::Visitor;\n+use crate::hir::map::{definitions::DisambiguatedDefPathData, DefPathData};\n use crate::lint::{EarlyLintPass, LateLintPass, EarlyLintPassObject, LateLintPassObject};\n use crate::lint::{LintArray, Level, Lint, LintId, LintPass, LintBuffer};\n use crate::lint::builtin::BuiltinLintDiagnostics;\n use crate::lint::levels::{LintLevelSets, LintLevelsBuilder};\n use crate::middle::privacy::AccessLevels;\n-use rustc_serialize::{Decoder, Decodable, Encoder, Encodable};\n use crate::session::{config, early_error, Session};\n use crate::ty::{self, print::Printer, subst::Kind, TyCtxt, Ty};\n use crate::ty::layout::{LayoutError, LayoutOf, TyLayout};\n use crate::util::nodemap::FxHashMap;\n use crate::util::common::time;\n \n+use errors::DiagnosticBuilder;\n+use std::slice;\n use std::default::Default as StdDefault;\n+use rustc_data_structures::sync::{ReadGuard, Lock, ParallelIterator, join, par_iter};\n+use rustc_serialize::{Decoder, Decodable, Encoder, Encodable};\n use syntax::ast;\n use syntax::edition;\n-use syntax_pos::{MultiSpan, Span, symbol::Symbol};\n-use errors::DiagnosticBuilder;\n-use crate::hir;\n-use crate::hir::def_id::{CrateNum, DefId, LOCAL_CRATE};\n-use crate::hir::intravisit as hir_visit;\n-use crate::hir::intravisit::Visitor;\n-use crate::hir::map::{definitions::DisambiguatedDefPathData, DefPathData};\n use syntax::util::lev_distance::find_best_match_for_name;\n use syntax::visit as ast_visit;\n+use syntax_pos::{MultiSpan, Span, symbol::Symbol};\n \n /// Information about the registered lints.\n ///"}, {"sha": "5b490b701267deae304e620ddce0e8178eb2b305", "filename": "src/librustc/lint/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Flint%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Flint%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flint%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -875,20 +875,20 @@ pub fn in_external_macro(sess: &Session, span: Span) -> bool {\n         ExpnKind::AstPass(_) | ExpnKind::Desugaring(_) => true, // well, it's \"external\"\n         ExpnKind::Macro(MacroKind::Bang, _) => {\n             if expn_data.def_site.is_dummy() {\n-                // dummy span for the def_site means it's an external macro\n+                // Dummy span for the `def_site` means it's an external macro.\n                 return true;\n             }\n             match sess.source_map().span_to_snippet(expn_data.def_site) {\n                 Ok(code) => !code.starts_with(\"macro_rules\"),\n-                // no snippet = external macro or compiler-builtin expansion\n+                // No snippet means external macro or compiler-builtin expansion.\n                 Err(_) => true,\n             }\n         }\n         ExpnKind::Macro(..) => true, // definitely a plugin\n     }\n }\n \n-/// Returns whether `span` originates in a derive macro's expansion\n+/// Returns `true` if `span` originates in a derive-macro's expansion.\n pub fn in_derive_expansion(span: Span) -> bool {\n     if let ExpnKind::Macro(MacroKind::Derive, _) = span.ctxt().outer_expn_data().kind {\n         return true;"}, {"sha": "93bb301f0951a99eaa34e66f63acb09faad385fd", "filename": "src/librustc/middle/entry.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmiddle%2Fentry.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmiddle%2Fentry.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fentry.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -16,17 +16,17 @@ struct EntryContext<'a, 'tcx> {\n \n     map: &'a hir_map::Map<'tcx>,\n \n-    // The top-level function called 'main'\n+    /// The top-level function called 'main'.\n     main_fn: Option<(HirId, Span)>,\n \n-    // The function that has attribute named 'main'\n+    /// The function that has attribute named 'main'.\n     attr_main_fn: Option<(HirId, Span)>,\n \n-    // The function that has the attribute 'start' on it\n+    /// The function that has the attribute 'start' on it.\n     start_fn: Option<(HirId, Span)>,\n \n-    // The functions that one might think are 'main' but aren't, e.g.\n-    // main functions not defined at the top level. For diagnostics.\n+    /// The functions that one might think are 'main' but aren't, e.g.\n+    /// main functions not defined at the top level. For diagnostics.\n     non_main_fns: Vec<(HirId, Span)> ,\n }\n \n@@ -39,11 +39,11 @@ impl<'a, 'tcx> ItemLikeVisitor<'tcx> for EntryContext<'a, 'tcx> {\n     }\n \n     fn visit_trait_item(&mut self, _trait_item: &'tcx TraitItem) {\n-        // entry fn is never a trait item\n+        // Entry fn is never a trait item.\n     }\n \n     fn visit_impl_item(&mut self, _impl_item: &'tcx ImplItem) {\n-        // entry fn is never an impl item\n+        // Entry fn is never a trait item.\n     }\n }\n \n@@ -54,7 +54,7 @@ fn entry_fn(tcx: TyCtxt<'_>, cnum: CrateNum) -> Option<(DefId, EntryFnType)> {\n         *ty == config::CrateType::Executable\n     });\n     if !any_exe {\n-        // No need to find a main function\n+        // No need to find a main function.\n         return None;\n     }\n \n@@ -148,7 +148,7 @@ fn configure_main(tcx: TyCtxt<'_>, visitor: &EntryContext<'_, '_>) -> Option<(De\n     } else if let Some((hir_id, _)) = visitor.main_fn {\n         Some((tcx.hir().local_def_id(hir_id), EntryFnType::Main))\n     } else {\n-        // No main function\n+        // There is no main function.\n         let mut err = struct_err!(tcx.sess, E0601,\n             \"`main` function not found in crate `{}`\", tcx.crate_name(LOCAL_CRATE));\n         if !visitor.non_main_fns.is_empty() {"}, {"sha": "de6dadabcbf5623f846f9ecc70f8b1a17e4a1a92", "filename": "src/librustc/middle/expr_use_visitor.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmiddle%2Fexpr_use_visitor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmiddle%2Fexpr_use_visitor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fexpr_use_visitor.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -596,7 +596,7 @@ impl<'a, 'tcx> ExprUseVisitor<'a, 'tcx> {\n             }\n \n             hir::StmtKind::Item(_) => {\n-                // we don't visit nested items in this visitor,\n+                // We don't visit nested items in this visitor,\n                 // only the fn body we were given.\n             }\n "}, {"sha": "6dfd7a7f94378843e376a638d36ea5b502ff4a78", "filename": "src/librustc/middle/lang_items.rs", "status": "modified", "additions": 8, "deletions": 10, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmiddle%2Flang_items.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmiddle%2Flang_items.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Flang_items.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -3,10 +3,8 @@\n //! Language items are items that represent concepts intrinsic to the language\n //! itself. Examples are:\n //!\n-//! * Traits that specify \"kinds\"; e.g., \"Sync\", \"Send\".\n-//!\n-//! * Traits that represent operators; e.g., \"Add\", \"Sub\", \"Index\".\n-//!\n+//! * Traits that specify \"kinds\"; e.g., `Sync`, `Send`.\n+//! * Traits that represent operators; e.g., `Add`, `Sub`, `Index`.\n //! * Functions called by the compiler itself.\n \n pub use self::LangItem::*;\n@@ -151,11 +149,11 @@ impl ItemLikeVisitor<'v> for LanguageItemCollector<'tcx> {\n     }\n \n     fn visit_trait_item(&mut self, _trait_item: &hir::TraitItem) {\n-        // at present, lang items are always items, not trait items\n+        // At present, lang items are always items, not trait items.\n     }\n \n     fn visit_impl_item(&mut self, _impl_item: &hir::ImplItem) {\n-        // at present, lang items are always items, not impl items\n+        // At present, lang items are always items, not impl items.\n     }\n }\n \n@@ -204,7 +202,7 @@ impl LanguageItemCollector<'tcx> {\n     }\n }\n \n-/// Extract the first `lang = \"$name\"` out of a list of attributes.\n+/// Extracts the first `lang = \"$name\"` out of a list of attributes.\n /// The attributes `#[panic_handler]` and `#[alloc_error_handler]`\n /// are also extracted out when found.\n pub fn extract(attrs: &[ast::Attribute]) -> Option<(Symbol, Span)> {\n@@ -216,7 +214,7 @@ pub fn extract(attrs: &[ast::Attribute]) -> Option<(Symbol, Span)> {\n     }))\n }\n \n-/// Traverse and collect all the lang items in all crates.\n+/// Traverses and collects all the lang items in all crates.\n pub fn collect<'tcx>(tcx: TyCtxt<'tcx>) -> LanguageItems {\n     // Initialize the collector.\n     let mut collector = LanguageItemCollector::new(tcx);\n@@ -367,7 +365,7 @@ language_item_table! {\n \n     MaybeUninitLangItem,         \"maybe_uninit\",       maybe_uninit,            Target::Union;\n \n-    // Align offset for stride != 1, must not panic.\n+    // Align offset for stride != 1; must not panic.\n     AlignOffsetLangItem,         \"align_offset\",       align_offset_fn,         Target::Fn;\n \n     TerminationTraitLangItem,    \"termination\",        termination,             Target::Trait;\n@@ -378,7 +376,7 @@ language_item_table! {\n \n impl<'tcx> TyCtxt<'tcx> {\n     /// Returns the `DefId` for a given `LangItem`.\n-    /// If not found, fatally abort compilation.\n+    /// If not found, fatally aborts compilation.\n     pub fn require_lang_item(&self, lang_item: LangItem, span: Option<Span>) -> DefId {\n         self.lang_items().require(lang_item).unwrap_or_else(|msg| {\n             if let Some(span) = span {"}, {"sha": "b9d8a4ec68fadd2109370da0eb121034e078f3f8", "filename": "src/librustc/middle/region.rs", "status": "modified", "additions": 39, "deletions": 43, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmiddle%2Fregion.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmiddle%2Fregion.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fregion.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -6,29 +6,27 @@\n //!\n //! [rustc guide]: https://rust-lang.github.io/rustc-guide/mir/borrowck.html\n \n+use crate::hir;\n+use crate::hir::Node;\n+use crate::hir::def_id::DefId;\n+use crate::hir::intravisit::{self, Visitor, NestedVisitorMap};\n+use crate::hir::{Block, Arm, Pat, PatKind, Stmt, Expr, Local};\n use crate::ich::{StableHashingContext, NodeIdHashingMode};\n use crate::util::nodemap::{FxHashMap, FxHashSet};\n-use crate::ty;\n+use crate::ty::{self, DefIdTree, TyCtxt};\n+use crate::ty::query::Providers;\n \n-use std::mem;\n-use std::fmt;\n+use rustc_data_structures::indexed_vec::Idx;\n+use rustc_data_structures::stable_hasher::{HashStable, StableHasher, StableHasherResult};\n use rustc_macros::HashStable;\n use syntax::source_map;\n use syntax_pos::{Span, DUMMY_SP};\n-use crate::ty::{DefIdTree, TyCtxt};\n-use crate::ty::query::Providers;\n \n-use crate::hir;\n-use crate::hir::Node;\n-use crate::hir::def_id::DefId;\n-use crate::hir::intravisit::{self, Visitor, NestedVisitorMap};\n-use crate::hir::{Block, Arm, Pat, PatKind, Stmt, Expr, Local};\n-use rustc_data_structures::indexed_vec::Idx;\n-use rustc_data_structures::stable_hasher::{HashStable, StableHasher,\n-                                           StableHasherResult};\n+use std::fmt;\n+use std::mem;\n \n-/// Scope represents a statically-describable scope that can be\n-/// used to bound the lifetime/region for values.\n+/// Represents a statically-describable scope that can be used to\n+/// bound the lifetime/region for values.\n ///\n /// `Node(node_id)`: Any AST node that has any scope at all has the\n /// `Node(node_id)` scope. Other variants represent special cases not\n@@ -225,25 +223,25 @@ pub struct ScopeTree {\n     /// have lifetime parameters free in this body.\n     root_parent: Option<hir::HirId>,\n \n-    /// `parent_map` maps from a scope ID to the enclosing scope id;\n+    /// Maps from a scope ID to the enclosing scope id;\n     /// this is usually corresponding to the lexical nesting, though\n     /// in the case of closures the parent scope is the innermost\n     /// conditional expression or repeating block. (Note that the\n     /// enclosing scope ID for the block associated with a closure is\n     /// the closure itself.)\n     parent_map: FxHashMap<Scope, (Scope, ScopeDepth)>,\n \n-    /// `var_map` maps from a variable or binding ID to the block in\n-    /// which that variable is declared.\n+    /// Maps from a variable or binding ID to the block in which that\n+    /// variable is declared.\n     var_map: FxHashMap<hir::ItemLocalId, Scope>,\n \n-    /// maps from a `NodeId` to the associated destruction scope (if any)\n+    /// Maps from a `NodeId` to the associated destruction scope (if any).\n     destruction_scopes: FxHashMap<hir::ItemLocalId, Scope>,\n \n-    /// `rvalue_scopes` includes entries for those expressions whose cleanup scope is\n-    /// larger than the default. The map goes from the expression id\n-    /// to the cleanup scope id. For rvalues not present in this\n-    /// table, the appropriate cleanup scope is the innermost\n+    /// `rvalue_scopes` includes entries for those expressions whose\n+    /// cleanup scope is larger than the default. The map goes from the\n+    /// expression ID to the cleanup scope id. For rvalues not present in\n+    /// this table, the appropriate cleanup scope is the innermost\n     /// enclosing statement, conditional expression, or repeating\n     /// block (see `terminating_scopes`).\n     /// In constants, None is used to indicate that certain expressions\n@@ -318,7 +316,7 @@ pub struct ScopeTree {\n     ///     4. By `2.` and `3.`, `D` is *statically* storage-dead at `U`,\n     ///     QED.\n     ///\n-    /// I don't think this property relies on `3.` in an essential way - it\n+    /// This property ought to not on (3) in an essential way -- it\n     /// is probably still correct even if we have \"unrestricted\" terminating\n     /// scopes. However, why use the complicated proof when a simple one\n     /// works?\n@@ -341,20 +339,20 @@ pub struct ScopeTree {\n \n #[derive(Debug, Copy, Clone, RustcEncodable, RustcDecodable, HashStable)]\n pub struct YieldData {\n-    /// `Span` of the yield.\n+    /// The `Span` of the yield.\n     pub span: Span,\n-    /// The number of expressions and patterns appearing before the `yield` in the body + 1.\n+    /// The number of expressions and patterns appearing before the `yield` in the body plus one.\n     pub expr_and_pat_count: usize,\n     pub source: hir::YieldSource,\n }\n \n #[derive(Debug, Copy, Clone)]\n pub struct Context {\n-    /// the root of the current region tree. This is typically the id\n+    /// The root of the current region tree. This is typically the id\n     /// of the innermost fn body. Each fn forms its own disjoint tree\n     /// in the region hierarchy. These fn bodies are themselves\n     /// arranged into a tree. See the \"Modeling closures\" section of\n-    /// the README in infer::region_constraints for more\n+    /// the README in `infer::region_constraints` for more\n     /// details.\n     root_id: Option<hir::ItemLocalId>,\n \n@@ -369,15 +367,15 @@ pub struct Context {\n struct RegionResolutionVisitor<'tcx> {\n     tcx: TyCtxt<'tcx>,\n \n-    // The number of expressions and patterns visited in the current body\n+    // The number of expressions and patterns visited in the current body.\n     expr_and_pat_count: usize,\n     // When this is `true`, we record the `Scopes` we encounter\n     // when processing a Yield expression. This allows us to fix\n     // up their indices.\n     pessimistic_yield: bool,\n-    // Stores scopes when pessimistic_yield is true.\n+    // Stores scopes when `pessimistic_yield` is `true`.\n     fixup_scopes: Vec<Scope>,\n-    // Generated scope tree:\n+    // The generated scope tree.\n     scope_tree: ScopeTree,\n \n     cx: Context,\n@@ -411,7 +409,7 @@ struct ExprLocatorVisitor {\n     expr_and_pat_count: usize,\n }\n \n-// This visitor has to have the same visit_expr calls as RegionResolutionVisitor\n+// This visitor has to have the same `visit_expr` calls as `RegionResolutionVisitor`\n // since `expr_count` is compared against the results there.\n impl<'tcx> Visitor<'tcx> for ExprLocatorVisitor {\n     fn nested_visit_map<'this>(&'this mut self) -> NestedVisitorMap<'this, 'tcx> {\n@@ -456,7 +454,7 @@ impl<'tcx> ScopeTree {\n             assert!(prev.is_none());\n         }\n \n-        // record the destruction scopes for later so we can query them\n+        // Record the destruction scopes for later so we can query them.\n         if let ScopeData::Destruction = child.data {\n             self.destruction_scopes.insert(child.item_local_id(), child);\n         }\n@@ -478,7 +476,7 @@ impl<'tcx> ScopeTree {\n         self.destruction_scopes.get(&n).cloned()\n     }\n \n-    /// Records that `sub_closure` is defined within `sup_closure`. These ids\n+    /// Records that `sub_closure` is defined within `sup_closure`. These IDs\n     /// should be the ID of the block that is the fn body, which is\n     /// also the root of the region hierarchy for that fn.\n     fn record_closure_parent(&mut self,\n@@ -505,14 +503,14 @@ impl<'tcx> ScopeTree {\n         self.rvalue_scopes.insert(var, lifetime);\n     }\n \n+    /// Returns the narrowest scope that encloses `id`, if any.\n     pub fn opt_encl_scope(&self, id: Scope) -> Option<Scope> {\n-        //! Returns the narrowest scope that encloses `id`, if any.\n         self.parent_map.get(&id).cloned().map(|(p, _)| p)\n     }\n \n+    /// Returns the narrowest scope that encloses `id`, if any.\n     #[allow(dead_code)] // used in cfg\n     pub fn encl_scope(&self, id: Scope) -> Scope {\n-        //! Returns the narrowest scope that encloses `id`, if any.\n         self.opt_encl_scope(id).unwrap()\n     }\n \n@@ -522,16 +520,15 @@ impl<'tcx> ScopeTree {\n             bug!(\"no enclosing scope for id {:?}\", var_id))\n     }\n \n+    /// Returns the scope when the temp created by `expr_id` will be cleaned up.\n     pub fn temporary_scope(&self, expr_id: hir::ItemLocalId) -> Option<Scope> {\n-        //! Returns the scope when temp created by expr_id will be cleaned up\n-\n-        // check for a designated rvalue scope\n+        // Check for a designated rvalue scope.\n         if let Some(&s) = self.rvalue_scopes.get(&expr_id) {\n             debug!(\"temporary_scope({:?}) = {:?} [custom]\", expr_id, s);\n             return s;\n         }\n \n-        // else, locate the innermost terminating scope\n+        // Otherwise, locate the innermost terminating scope\n         // if there's one. Static items, for instance, won't\n         // have an enclosing scope, hence no scope will be\n         // returned.\n@@ -552,9 +549,8 @@ impl<'tcx> ScopeTree {\n         return None;\n     }\n \n+    /// Returns the lifetime of the variable `id`.\n     pub fn var_region(&self, id: hir::ItemLocalId) -> ty::RegionKind {\n-        //! Returns the lifetime of the variable `id`.\n-\n         let scope = ty::ReScope(self.var_scope(id));\n         debug!(\"var_region({:?}) = {:?}\", id, scope);\n         scope\n@@ -589,7 +585,7 @@ impl<'tcx> ScopeTree {\n         return true;\n     }\n \n-    /// Returns the ID of the innermost containing body\n+    /// Returns the ID of the innermost containing body.\n     pub fn containing_body(&self, mut scope: Scope) -> Option<hir::ItemLocalId> {\n         loop {\n             if let ScopeData::CallSite = scope.data {"}, {"sha": "1f604877841a730e117322eb4bced048ded902d1", "filename": "src/librustc/mir/cache.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Fcache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Fcache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Fcache.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -27,7 +27,7 @@ impl<'a> HashStable<StableHashingContext<'a>> for Cache {\n     fn hash_stable<W: StableHasherResult>(&self,\n                                           _: &mut StableHashingContext<'a>,\n                                           _: &mut StableHasher<W>) {\n-        // do nothing\n+        // Do nothing.\n     }\n }\n "}, {"sha": "755cda792ba797091591f3bb2c1d75614ea69134", "filename": "src/librustc/mir/interpret/allocation.rs", "status": "modified", "additions": 59, "deletions": 59, "changes": 118, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -4,16 +4,17 @@ use super::{\n     Pointer, InterpResult, AllocId, ScalarMaybeUndef, write_target_uint, read_target_uint, Scalar,\n };\n \n+use crate::mir;\n use crate::ty::layout::{Size, Align};\n+\n+use rustc_data_structures::sorted_map::SortedMap;\n+use rustc_target::abi::HasDataLayout;\n use syntax::ast::Mutability;\n use std::iter;\n-use crate::mir;\n use std::ops::{Range, Deref, DerefMut};\n-use rustc_data_structures::sorted_map::SortedMap;\n-use rustc_target::abi::HasDataLayout;\n use std::borrow::Cow;\n \n-// NOTE: When adding new fields, make sure to adjust the Snapshot impl in\n+// NOTE: When adding new fields, make sure to adjust the `Snapshot` impl in\n // `src/librustc_mir/interpret/snapshot.rs`.\n #[derive(\n     Clone,\n@@ -27,7 +28,7 @@ use std::borrow::Cow;\n     RustcDecodable,\n     HashStable,\n )]\n-pub struct Allocation<Tag=(),Extra=()> {\n+pub struct Allocation<Tag = (),Extra = ()> {\n     /// The actual bytes of the allocation.\n     /// Note that the bytes of a pointer represent the offset of the pointer.\n     bytes: Vec<u8>,\n@@ -42,15 +43,14 @@ pub struct Allocation<Tag=(),Extra=()> {\n     pub size: Size,\n     /// The alignment of the allocation to detect unaligned reads.\n     pub align: Align,\n-    /// Whether the allocation is mutable.\n+    /// `true` if the allocation is mutable.\n     /// Also used by codegen to determine if a static should be put into mutable memory,\n     /// which happens for `static mut` and `static` with interior mutability.\n     pub mutability: Mutability,\n     /// Extra state for the machine.\n     pub extra: Extra,\n }\n \n-\n pub trait AllocationExtra<Tag>: ::std::fmt::Debug + Clone {\n     // There is no constructor in here because the constructor's type depends\n     // on `MemoryKind`, and making things sufficiently generic leads to painful\n@@ -92,7 +92,7 @@ pub trait AllocationExtra<Tag>: ::std::fmt::Debug + Clone {\n     }\n }\n \n-// For Tag=() and no extra state, we have is a trivial implementation.\n+// For `Tag = ()` and no extra state, we have a trivial implementation.\n impl AllocationExtra<()> for () { }\n \n // The constructors are all without extra; the extra gets added by a machine hook later.\n@@ -185,7 +185,7 @@ impl<Tag, Extra> Allocation<Tag, Extra> {\n \n impl<'tcx> rustc_serialize::UseSpecializedDecodable for &'tcx Allocation {}\n \n-/// Byte accessors\n+/// Byte accessors.\n impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n     /// Just a small local helper function to avoid a bit of code repetition.\n     /// Returns the range of this allocation that was meant.\n@@ -195,7 +195,7 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         offset: Size,\n         size: Size\n     ) -> Range<usize> {\n-        let end = offset + size; // this does overflow checking\n+        let end = offset + size; // This does overflow checking.\n         assert_eq!(\n             end.bytes() as usize as u64, end.bytes(),\n             \"cannot handle this access on this host architecture\"\n@@ -232,7 +232,7 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n             self.check_defined(ptr, size)?;\n             self.check_relocations(cx, ptr, size)?;\n         } else {\n-            // We still don't want relocations on the *edges*\n+            // We still don't want relocations on the *edges*.\n             self.check_relocation_edges(cx, ptr, size)?;\n         }\n \n@@ -241,7 +241,7 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         Ok(&self.bytes[range])\n     }\n \n-    /// Check that these bytes are initialized and not pointer bytes, and then return them\n+    /// Checks that these bytes are initialized and not pointer bytes, and then return them\n     /// as a slice.\n     ///\n     /// It is the caller's responsibility to check bounds and alignment beforehand.\n@@ -293,7 +293,7 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n     }\n }\n \n-/// Reading and writing\n+/// Reading and writing.\n impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n     /// Reads bytes until a `0` is encountered. Will error if the end of the allocation is reached\n     /// before a `0` is found.\n@@ -329,9 +329,9 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         allow_ptr_and_undef: bool,\n     ) -> InterpResult<'tcx>\n     {\n-        // Check bounds and relocations on the edges\n+        // Check bounds and relocations on the edges.\n         self.get_bytes_with_undef_and_ptr(cx, ptr, size)?;\n-        // Check undef and ptr\n+        // Check undef and ptr.\n         if !allow_ptr_and_undef {\n             self.check_defined(ptr, size)?;\n             self.check_relocations(cx, ptr, size)?;\n@@ -372,12 +372,12 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         Ok(())\n     }\n \n-    /// Read a *non-ZST* scalar\n+    /// Reads a *non-ZST* scalar.\n     ///\n-    /// zsts can't be read out of two reasons:\n-    /// * byteorder cannot work with zero element buffers\n-    /// * in order to obtain a `Pointer` we need to check for ZSTness anyway due to integer pointers\n-    ///   being valid for ZSTs\n+    /// ZSTs can't be read for two reasons:\n+    /// * byte-order cannot work with zero-element buffers;\n+    /// * in order to obtain a `Pointer`, we need to check for ZSTness anyway due to integer\n+    ///   pointers being valid for ZSTs.\n     ///\n     /// It is the caller's responsibility to check bounds and alignment beforehand.\n     pub fn read_scalar(\n@@ -387,20 +387,20 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         size: Size\n     ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>>\n     {\n-        // get_bytes_unchecked tests relocation edges\n+        // `get_bytes_unchecked` tests relocation edges.\n         let bytes = self.get_bytes_with_undef_and_ptr(cx, ptr, size)?;\n         // Undef check happens *after* we established that the alignment is correct.\n-        // We must not return Ok() for unaligned pointers!\n+        // We must not return `Ok()` for unaligned pointers!\n         if self.check_defined(ptr, size).is_err() {\n-            // this inflates undefined bytes to the entire scalar, even if only a few\n-            // bytes are undefined\n+            // This inflates undefined bytes to the entire scalar, even if only a few\n+            // bytes are undefined.\n             return Ok(ScalarMaybeUndef::Undef);\n         }\n-        // Now we do the actual reading\n+        // Now we do the actual reading.\n         let bits = read_target_uint(cx.data_layout().endian, bytes).unwrap();\n-        // See if we got a pointer\n+        // See if we got a pointer.\n         if size != cx.data_layout().pointer_size {\n-            // *Now* better make sure that the inside also is free of relocations.\n+            // *Now*, we better make sure that the inside is free of relocations too.\n             self.check_relocations(cx, ptr, size)?;\n         } else {\n             match self.relocations.get(&ptr.offset) {\n@@ -415,7 +415,7 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         Ok(ScalarMaybeUndef::Scalar(Scalar::from_uint(bits, size)))\n     }\n \n-    /// Read a pointer-sized scalar.\n+    /// Reads a pointer-sized scalar.\n     ///\n     /// It is the caller's responsibility to check bounds and alignment beforehand.\n     pub fn read_ptr_sized(\n@@ -427,12 +427,12 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         self.read_scalar(cx, ptr, cx.data_layout().pointer_size)\n     }\n \n-    /// Write a *non-ZST* scalar\n+    /// Writes a *non-ZST* scalar.\n     ///\n-    /// zsts can't be read out of two reasons:\n-    /// * byteorder cannot work with zero element buffers\n-    /// * in oder to obtain a `Pointer` we need to check for ZSTness anyway due to integer pointers\n-    ///   being valid for ZSTs\n+    /// ZSTs can't be read for two reasons:\n+    /// * byte-order cannot work with zero-element buffers;\n+    /// * in order to obtain a `Pointer`, we need to check for ZSTness anyway due to integer\n+    ///   pointers being valid for ZSTs.\n     ///\n     /// It is the caller's responsibility to check bounds and alignment beforehand.\n     pub fn write_scalar(\n@@ -460,7 +460,7 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         let dst = self.get_bytes_mut(cx, ptr, type_size)?;\n         write_target_uint(endian, dst, bytes).unwrap();\n \n-        // See if we have to also write a relocation\n+        // See if we have to also write a relocation.\n         match val {\n             Scalar::Ptr(val) => {\n                 self.relocations.insert(\n@@ -474,7 +474,7 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n         Ok(())\n     }\n \n-    /// Write a pointer-sized scalar.\n+    /// Writes a pointer-sized scalar.\n     ///\n     /// It is the caller's responsibility to check bounds and alignment beforehand.\n     pub fn write_ptr_sized(\n@@ -489,9 +489,9 @@ impl<'tcx, Tag: Copy, Extra: AllocationExtra<Tag>> Allocation<Tag, Extra> {\n     }\n }\n \n-/// Relocations\n+/// Relocations.\n impl<'tcx, Tag: Copy, Extra> Allocation<Tag, Extra> {\n-    /// Returns all relocations overlapping with the given ptr-offset pair.\n+    /// Returns all relocations overlapping with the given pointer-offset pair.\n     pub fn get_relocations(\n         &self,\n         cx: &impl HasDataLayout,\n@@ -501,7 +501,7 @@ impl<'tcx, Tag: Copy, Extra> Allocation<Tag, Extra> {\n         // We have to go back `pointer_size - 1` bytes, as that one would still overlap with\n         // the beginning of this range.\n         let start = ptr.offset.bytes().saturating_sub(cx.data_layout().pointer_size.bytes() - 1);\n-        let end = ptr.offset + size; // this does overflow checking\n+        let end = ptr.offset + size; // This does overflow checking.\n         self.relocations.range(Size::from_bytes(start)..end)\n     }\n \n@@ -561,7 +561,7 @@ impl<'tcx, Tag: Copy, Extra> Allocation<Tag, Extra> {\n         Ok(())\n     }\n \n-    /// Error if there are relocations overlapping with the edges of the\n+    /// Errors if there are relocations overlapping with the edges of the\n     /// given memory range.\n     #[inline]\n     fn check_relocation_edges(\n@@ -577,7 +577,7 @@ impl<'tcx, Tag: Copy, Extra> Allocation<Tag, Extra> {\n }\n \n \n-/// Undefined bytes\n+/// Undefined bytes.\n impl<'tcx, Tag, Extra> Allocation<Tag, Extra> {\n     /// Checks that a range of bytes is defined. If not, returns the `ReadUndefBytes`\n     /// error which will report the first byte which is undefined.\n@@ -618,7 +618,7 @@ pub struct AllocationDefinedness {\n \n /// Transferring the definedness mask to other allocations.\n impl<Tag, Extra> Allocation<Tag, Extra> {\n-    /// Creates a run-length encoding of the undef_mask.\n+    /// Creates a run-length encoding of the undef mask.\n     pub fn compress_undef_range(\n         &self,\n         src: Pointer<Tag>,\n@@ -631,18 +631,18 @@ impl<Tag, Extra> Allocation<Tag, Extra> {\n         // Therefor we precompute a compressed version of the undef mask of the source value and\n         // then write it back `repeat` times without computing any more information from the source.\n \n-        // a precomputed cache for ranges of defined/undefined bits\n+        // A precomputed cache for ranges of defined/undefined bits\n         // 0000010010001110 will become\n-        // [5, 1, 2, 1, 3, 3, 1]\n-        // where each element toggles the state\n+        // `[5, 1, 2, 1, 3, 3, 1]`,\n+        // where each element toggles the state.\n \n         let mut ranges = smallvec::SmallVec::<[u64; 1]>::new();\n         let initial = self.undef_mask.get(src.offset);\n         let mut cur_len = 1;\n         let mut cur = initial;\n \n         for i in 1..size.bytes() {\n-            // FIXME: optimize to bitshift the current undef block's bits and read the top bit\n+            // FIXME: optimize to bitshift the current undef block's bits and read the top bit.\n             if self.undef_mask.get(src.offset + Size::from_bytes(i)) == cur {\n                 cur_len += 1;\n             } else {\n@@ -657,15 +657,15 @@ impl<Tag, Extra> Allocation<Tag, Extra> {\n         AllocationDefinedness { ranges, initial, }\n     }\n \n-    /// Apply multiple instances of the run-length encoding to the undef_mask.\n+    /// Applies multiple instances of the run-length encoding to the undef mask.\n     pub fn mark_compressed_undef_range(\n         &mut self,\n         defined: &AllocationDefinedness,\n         dest: Pointer<Tag>,\n         size: Size,\n         repeat: u64,\n     ) {\n-        // an optimization where we can just overwrite an entire range of definedness bits if\n+        // An optimization where we can just overwrite an entire range of definedness bits if\n         // they are going to be uniformly `1` or `0`.\n         if defined.ranges.len() <= 1 {\n             self.undef_mask.set_range_inbounds(\n@@ -694,9 +694,9 @@ impl<Tag, Extra> Allocation<Tag, Extra> {\n     }\n }\n \n-/// Relocations\n+/// Relocations.\n #[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, RustcEncodable, RustcDecodable)]\n-pub struct Relocations<Tag=(), Id=AllocId>(SortedMap<Size, (Tag, Id)>);\n+pub struct Relocations<Tag = (), Id = AllocId>(SortedMap<Size, (Tag, Id)>);\n \n impl<Tag, Id> Relocations<Tag, Id> {\n     pub fn new() -> Self {\n@@ -766,7 +766,7 @@ impl<Tag: Copy, Extra> Allocation<Tag, Extra> {\n         }\n     }\n \n-    /// Apply a relocation copy.\n+    /// Applies a relocation copy.\n     /// The affected range, as defined in the parameters to `prepare_relocation_copy` is expected\n     /// to be clear of relocations.\n     pub fn mark_relocation_range(\n@@ -838,8 +838,8 @@ impl UndefMask {\n         let (blocka, bita) = bit_index(start);\n         let (blockb, bitb) = bit_index(end);\n         if blocka == blockb {\n-            // first set all bits but the first `bita`\n-            // then unset the last `64 - bitb` bits\n+            // First set all bits except the first `bita`,\n+            // then unset the last `64 - bitb` bits.\n             let range = if bitb == 0 {\n                 u64::max_value() << bita\n             } else {\n@@ -854,24 +854,24 @@ impl UndefMask {\n         }\n         // across block boundaries\n         if new_state {\n-            // set bita..64 to 1\n+            // Set `bita..64` to `1`.\n             self.blocks[blocka] |= u64::max_value() << bita;\n-            // set 0..bitb to 1\n+            // Set `0..bitb` to `1`.\n             if bitb != 0 {\n                 self.blocks[blockb] |= u64::max_value() >> (64 - bitb);\n             }\n-            // fill in all the other blocks (much faster than one bit at a time)\n+            // Fill in all the other blocks (much faster than one bit at a time).\n             for block in (blocka + 1) .. blockb {\n                 self.blocks[block] = u64::max_value();\n             }\n         } else {\n-            // set bita..64 to 0\n+            // Set `bita..64` to `0`.\n             self.blocks[blocka] &= !(u64::max_value() << bita);\n-            // set 0..bitb to 0\n+            // Set `0..bitb` to `0`.\n             if bitb != 0 {\n                 self.blocks[blockb] &= !(u64::max_value() >> (64 - bitb));\n             }\n-            // fill in all the other blocks (much faster than one bit at a time)\n+            // Fill in all the other blocks (much faster than one bit at a time).\n             for block in (blocka + 1) .. blockb {\n                 self.blocks[block] = 0;\n             }\n@@ -908,7 +908,7 @@ impl UndefMask {\n             let additional_blocks = amount.bytes() / Self::BLOCK_SIZE + 1;\n             assert_eq!(additional_blocks as usize as u64, additional_blocks);\n             self.blocks.extend(\n-                // FIXME(oli-obk): optimize this by repeating `new_state as Block`\n+                // FIXME(oli-obk): optimize this by repeating `new_state as Block`.\n                 iter::repeat(0).take(additional_blocks as usize),\n             );\n         }"}, {"sha": "09c822f7508a02b20383f42f483f1b6dbe74da8c", "filename": "src/librustc/mir/interpret/error.rs", "status": "modified", "additions": 7, "deletions": 9, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Ferror.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Ferror.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Ferror.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,23 +1,21 @@\n-use std::{fmt, env};\n+use super::{RawConst, Pointer, CheckInAllocMsg, ScalarMaybeUndef};\n \n use crate::hir;\n use crate::hir::map::definitions::DefPathData;\n use crate::mir;\n use crate::ty::{self, Ty, layout};\n use crate::ty::layout::{Size, Align, LayoutError};\n-use rustc_target::spec::abi::Abi;\n-use rustc_macros::HashStable;\n-\n-use super::{RawConst, Pointer, CheckInAllocMsg, ScalarMaybeUndef};\n+use crate::ty::query::TyCtxtAt;\n \n use backtrace::Backtrace;\n-\n-use crate::ty::query::TyCtxtAt;\n use errors::DiagnosticBuilder;\n-\n+use rustc_macros::HashStable;\n+use rustc_target::spec::abi::Abi;\n use syntax_pos::{Pos, Span};\n use syntax::symbol::Symbol;\n \n+use std::{fmt, env};\n+\n #[derive(Debug, Copy, Clone, PartialEq, Eq, HashStable, RustcEncodable, RustcDecodable)]\n pub enum ErrorHandled {\n     /// Already reported a lint or an error for this evaluation.\n@@ -582,7 +580,7 @@ pub type InterpResult<'tcx, T = ()> = Result<T, InterpErrorInfo<'tcx>>;\n \n impl fmt::Display for InterpError<'_> {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        // Forward `Display` to `Debug`\n+        // Forward `Display` to `Debug`.\n         write!(f, \"{:?}\", self)\n     }\n }"}, {"sha": "23433c2e8834d28dc65e8b162712e62451a96db6", "filename": "src/librustc/mir/interpret/mod.rs", "status": "modified", "additions": 55, "deletions": 54, "changes": 109, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,4 +1,4 @@\n-//! An interpreter for MIR used in CTFE and by miri\n+//! An interpreter for MIR used in CTFE and by miri.\n \n #[macro_export]\n macro_rules! err_unsup {\n@@ -107,21 +107,21 @@ pub use self::allocation::{Allocation, AllocationExtra, Relocations, UndefMask};\n \n pub use self::pointer::{Pointer, PointerArithmetic, CheckInAllocMsg};\n \n-use std::fmt;\n use crate::mir;\n use crate::hir::def_id::DefId;\n use crate::ty::{self, TyCtxt, Instance, subst::UnpackedKind};\n+use crate::ty::codec::TyDecoder;\n use crate::ty::layout::{self, Size};\n use std::io;\n+use std::fmt;\n+use std::num::NonZeroU32;\n+use std::sync::atomic::{AtomicU32, Ordering};\n use rustc_serialize::{Encoder, Decodable, Encodable};\n use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::sync::{Lock as Mutex, HashMapExt};\n+use rustc_data_structures::sync::{Lock, HashMapExt};\n use rustc_data_structures::tiny_list::TinyList;\n use rustc_macros::HashStable;\n use byteorder::{WriteBytesExt, ReadBytesExt, LittleEndian, BigEndian};\n-use crate::ty::codec::TyDecoder;\n-use std::sync::atomic::{AtomicU32, Ordering};\n-use std::num::NonZeroU32;\n \n /// Uniquely identifies a specific constant or static.\n #[derive(Copy, Clone, Debug, Eq, PartialEq, Hash, RustcEncodable, RustcDecodable, HashStable)]\n@@ -152,8 +152,8 @@ pub fn specialized_encode_alloc_id<'tcx, E: Encoder>(\n     tcx: TyCtxt<'tcx>,\n     alloc_id: AllocId,\n ) -> Result<(), E::Error> {\n-    let alloc: GlobalAlloc<'tcx> =\n-        tcx.alloc_map.lock().get(alloc_id).expect(\"no value for AllocId\");\n+    let alloc: GlobalAlloc<'tcx> = tcx.alloc_map.lock().get(alloc_id)\n+        .expect(\"no value for given alloc ID\");\n     match alloc {\n         GlobalAlloc::Memory(alloc) => {\n             trace!(\"encoding {:?} with {:#?}\", alloc_id, alloc);\n@@ -166,8 +166,8 @@ pub fn specialized_encode_alloc_id<'tcx, E: Encoder>(\n             fn_instance.encode(encoder)?;\n         }\n         GlobalAlloc::Static(did) => {\n-            // referring to statics doesn't need to know about their allocations,\n-            // just about its DefId\n+            // References to statics doesn't need to know about their allocations,\n+            // just about its `DefId`.\n             AllocDiscriminant::Static.encode(encoder)?;\n             did.encode(encoder)?;\n         }\n@@ -187,19 +187,18 @@ enum State {\n }\n \n pub struct AllocDecodingState {\n-    // For each AllocId we keep track of which decoding state it's currently in.\n-    decoding_state: Vec<Mutex<State>>,\n+    // For each `AllocId`, we keep track of which decoding state it's currently in.\n+    decoding_state: Vec<Lock<State>>,\n     // The offsets of each allocation in the data stream.\n     data_offsets: Vec<u32>,\n }\n \n impl AllocDecodingState {\n-\n     pub fn new_decoding_session(&self) -> AllocDecodingSession<'_> {\n         static DECODER_SESSION_ID: AtomicU32 = AtomicU32::new(0);\n         let counter = DECODER_SESSION_ID.fetch_add(1, Ordering::SeqCst);\n \n-        // Make sure this is never zero\n+        // Make sure this is never zero.\n         let session_id = DecodingSessionId::new((counter & 0x7FFFFFFF) + 1).unwrap();\n \n         AllocDecodingSession {\n@@ -208,10 +207,10 @@ impl AllocDecodingState {\n         }\n     }\n \n-    pub fn new(data_offsets: Vec<u32>) -> AllocDecodingState {\n-        let decoding_state = vec![Mutex::new(State::Empty); data_offsets.len()];\n+    pub fn new(data_offsets: Vec<u32>) -> Self {\n+        let decoding_state = vec![Lock::new(State::Empty); data_offsets.len()];\n \n-        AllocDecodingState {\n+        Self {\n             decoding_state,\n             data_offsets,\n         }\n@@ -225,23 +224,23 @@ pub struct AllocDecodingSession<'s> {\n }\n \n impl<'s> AllocDecodingSession<'s> {\n-    // Decodes an AllocId in a thread-safe way.\n+    /// Decodes an `AllocId` in a thread-safe way.\n     pub fn decode_alloc_id<D>(&self, decoder: &mut D) -> Result<AllocId, D::Error>\n     where\n         D: TyDecoder<'tcx>,\n     {\n-        // Read the index of the allocation\n+        // Read the index of the allocation.\n         let idx = decoder.read_u32()? as usize;\n         let pos = self.state.data_offsets[idx] as usize;\n \n-        // Decode the AllocDiscriminant now so that we know if we have to reserve an\n-        // AllocId.\n+        // Decode the `AllocDiscriminant` now so that we know if we have to reserve an\n+        // `AllocId`.\n         let (alloc_kind, pos) = decoder.with_position(pos, |decoder| {\n             let alloc_kind = AllocDiscriminant::decode(decoder)?;\n             Ok((alloc_kind, decoder.position()))\n         })?;\n \n-        // Check the decoding state, see if it's already decoded or if we should\n+        // Check the decoding state to see if it's already decoded or if we should\n         // decode it here.\n         let alloc_id = {\n             let mut entry = self.state.decoding_state[idx].lock();\n@@ -251,20 +250,20 @@ impl<'s> AllocDecodingSession<'s> {\n                     return Ok(alloc_id);\n                 }\n                 ref mut entry @ State::Empty => {\n-                    // We are allowed to decode\n+                    // We are allowed to decode.\n                     match alloc_kind {\n                         AllocDiscriminant::Alloc => {\n                             // If this is an allocation, we need to reserve an\n-                            // AllocId so we can decode cyclic graphs.\n+                            // `AllocId` so we can decode cyclic graphs.\n                             let alloc_id = decoder.tcx().alloc_map.lock().reserve();\n                             *entry = State::InProgress(\n                                 TinyList::new_single(self.session_id),\n                                 alloc_id);\n                             Some(alloc_id)\n                         },\n                         AllocDiscriminant::Fn | AllocDiscriminant::Static => {\n-                            // Fns and statics cannot be cyclic and their AllocId\n-                            // is determined later by interning\n+                            // Fns and statics cannot be cyclic, and their `AllocId`\n+                            // is determined later by interning.\n                             *entry = State::InProgressNonAlloc(\n                                 TinyList::new_single(self.session_id));\n                             None\n@@ -273,9 +272,9 @@ impl<'s> AllocDecodingSession<'s> {\n                 }\n                 State::InProgressNonAlloc(ref mut sessions) => {\n                     if sessions.contains(&self.session_id) {\n-                        bug!(\"This should be unreachable\")\n+                        bug!(\"this should be unreachable\");\n                     } else {\n-                        // Start decoding concurrently\n+                        // Start decoding concurrently.\n                         sessions.insert(self.session_id);\n                         None\n                     }\n@@ -285,37 +284,38 @@ impl<'s> AllocDecodingSession<'s> {\n                         // Don't recurse.\n                         return Ok(alloc_id)\n                     } else {\n-                        // Start decoding concurrently\n+                        // Start decoding concurrently.\n                         sessions.insert(self.session_id);\n                         Some(alloc_id)\n                     }\n                 }\n             }\n         };\n \n-        // Now decode the actual data\n+        // Now decode the actual data.\n         let alloc_id = decoder.with_position(pos, |decoder| {\n             match alloc_kind {\n                 AllocDiscriminant::Alloc => {\n-                    let allocation = <&'tcx Allocation as Decodable>::decode(decoder)?;\n-                    // We already have a reserved AllocId.\n+                    let alloc = <&'tcx Allocation as Decodable>::decode(decoder)?;\n+                    // We already have a reserved `AllocId`.\n                     let alloc_id = alloc_id.unwrap();\n-                    trace!(\"decoded alloc {:?} {:#?}\", alloc_id, allocation);\n-                    decoder.tcx().alloc_map.lock().set_alloc_id_same_memory(alloc_id, allocation);\n+                    trace!(\"decoded alloc {:?}: {:#?}\", alloc_id, alloc);\n+                    decoder.tcx().alloc_map.lock().set_alloc_id_same_memory(alloc_id, alloc);\n                     Ok(alloc_id)\n                 },\n                 AllocDiscriminant::Fn => {\n                     assert!(alloc_id.is_none());\n-                    trace!(\"creating fn alloc id\");\n+                    trace!(\"creating fn alloc ID\");\n                     let instance = ty::Instance::decode(decoder)?;\n                     trace!(\"decoded fn alloc instance: {:?}\", instance);\n                     let alloc_id = decoder.tcx().alloc_map.lock().create_fn_alloc(instance);\n                     Ok(alloc_id)\n                 },\n                 AllocDiscriminant::Static => {\n                     assert!(alloc_id.is_none());\n-                    trace!(\"creating extern static alloc id at\");\n+                    trace!(\"creating extern static alloc ID\");\n                     let did = DefId::decode(decoder)?;\n+                    trace!(\"decoded static def-ID: {:?}\", did);\n                     let alloc_id = decoder.tcx().alloc_map.lock().create_static_alloc(did);\n                     Ok(alloc_id)\n                 }\n@@ -340,7 +340,7 @@ impl fmt::Display for AllocId {\n /// a static, or a \"real\" allocation with some data in it.\n #[derive(Debug, Clone, Eq, PartialEq, Hash, RustcDecodable, RustcEncodable, HashStable)]\n pub enum GlobalAlloc<'tcx> {\n-    /// The alloc ID is used as a function pointer\n+    /// The alloc ID is used as a function pointer.\n     Function(Instance<'tcx>),\n     /// The alloc ID points to a \"lazy\" static variable that did not get computed (yet).\n     /// This is also used to break the cycle in recursive statics.\n@@ -350,16 +350,17 @@ pub enum GlobalAlloc<'tcx> {\n }\n \n pub struct AllocMap<'tcx> {\n-    /// Lets you know what an `AllocId` refers to.\n+    /// Maps `AllocId`s to their corresponding allocations.\n     alloc_map: FxHashMap<AllocId, GlobalAlloc<'tcx>>,\n \n     /// Used to ensure that statics and functions only get one associated `AllocId`.\n     /// Should never contain a `GlobalAlloc::Memory`!\n-    /// FIXME: Should we just have two separate dedup maps for statics and functions each?\n+    //\n+    // FIXME: Should we just have two separate dedup maps for statics and functions each?\n     dedup: FxHashMap<GlobalAlloc<'tcx>, AllocId>,\n \n     /// The `AllocId` to assign to the next requested ID.\n-    /// Always incremented, never gets smaller.\n+    /// Always incremented; never gets smaller.\n     next_id: AllocId,\n }\n \n@@ -389,7 +390,7 @@ impl<'tcx> AllocMap<'tcx> {\n         next\n     }\n \n-    /// Reserve a new ID *if* this allocation has not been dedup-reserved before.\n+    /// Reserves a new ID *if* this allocation has not been dedup-reserved before.\n     /// Should only be used for function pointers and statics, we don't want\n     /// to dedup IDs for \"real\" memory!\n     fn reserve_and_set_dedup(&mut self, alloc: GlobalAlloc<'tcx>) -> AllocId {\n@@ -430,17 +431,17 @@ impl<'tcx> AllocMap<'tcx> {\n             }\n         });\n         if is_generic {\n-            // Get a fresh ID\n+            // Get a fresh ID.\n             let id = self.reserve();\n             self.alloc_map.insert(id, GlobalAlloc::Function(instance));\n             id\n         } else {\n-            // Deduplicate\n+            // Deduplicate.\n             self.reserve_and_set_dedup(GlobalAlloc::Function(instance))\n         }\n     }\n \n-    /// Intern the `Allocation` and return a new `AllocId`, even if there's already an identical\n+    /// Interns the `Allocation` and return a new `AllocId`, even if there's already an identical\n     /// `Allocation` with a different `AllocId`.\n     /// Statics with identical content will still point to the same `Allocation`, i.e.,\n     /// their data will be deduplicated through `Allocation` interning -- but they\n@@ -465,19 +466,19 @@ impl<'tcx> AllocMap<'tcx> {\n     pub fn unwrap_memory(&self, id: AllocId) -> &'tcx Allocation {\n         match self.get(id) {\n             Some(GlobalAlloc::Memory(mem)) => mem,\n-            _ => bug!(\"expected allocation id {} to point to memory\", id),\n+            _ => bug!(\"expected allocation ID {} to point to memory\", id),\n         }\n     }\n \n-    /// Freeze an `AllocId` created with `reserve` by pointing it at an `Allocation`. Trying to\n+    /// Freezes an `AllocId` created with `reserve` by pointing it at an `Allocation`. Trying to\n     /// call this function twice, even with the same `Allocation` will ICE the compiler.\n     pub fn set_alloc_id_memory(&mut self, id: AllocId, mem: &'tcx Allocation) {\n         if let Some(old) = self.alloc_map.insert(id, GlobalAlloc::Memory(mem)) {\n-            bug!(\"tried to set allocation id {}, but it was already existing as {:#?}\", id, old);\n+            bug!(\"tried to set allocation ID {}, but it was already existing as {:#?}\", id, old);\n         }\n     }\n \n-    /// Freeze an `AllocId` created with `reserve` by pointing it at an `Allocation`. May be called\n+    /// Freezes an `AllocId` created with `reserve` by pointing it at an `Allocation`. May be called\n     /// twice for the same `(AllocId, Allocation)` pair.\n     fn set_alloc_id_same_memory(&mut self, id: AllocId, mem: &'tcx Allocation) {\n         self.alloc_map.insert_same(id, GlobalAlloc::Memory(mem));\n@@ -513,7 +514,7 @@ pub fn read_target_uint(endianness: layout::Endian, mut source: &[u8]) -> Result\n // Methods to facilitate working with signed integers stored in a u128\n ////////////////////////////////////////////////////////////////////////////////\n \n-/// Truncate `value` to `size` bits and then sign-extend it to 128 bits\n+/// Truncates `value` to `size` bits and then sign-extend it to 128 bits\n /// (i.e., if it is negative, fill with 1's on the left).\n #[inline]\n pub fn sign_extend(value: u128, size: Size) -> u128 {\n@@ -522,14 +523,14 @@ pub fn sign_extend(value: u128, size: Size) -> u128 {\n         // Truncated until nothing is left.\n         return 0;\n     }\n-    // sign extend\n+    // Sign-extend it.\n     let shift = 128 - size;\n-    // shift the unsigned value to the left\n-    // and back to the right as signed (essentially fills with FF on the left)\n+    // Shift the unsigned value to the left, then shift back to the right as signed\n+    // (essentially fills with FF on the left).\n     (((value << shift) as i128) >> shift) as u128\n }\n \n-/// Truncate `value` to `size` bits.\n+/// Truncates `value` to `size` bits.\n #[inline]\n pub fn truncate(value: u128, size: Size) -> u128 {\n     let size = size.bits();\n@@ -538,6 +539,6 @@ pub fn truncate(value: u128, size: Size) -> u128 {\n         return 0;\n     }\n     let shift = 128 - size;\n-    // truncate (shift left to drop out leftover values, shift right to fill with zeroes)\n+    // Truncate (shift left to drop out leftover values, shift right to fill with zeroes).\n     (value << shift) >> shift\n }"}, {"sha": "1bb4d9ea4d6d92edddac3a6541ec36a84f930145", "filename": "src/librustc/mir/interpret/pointer.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Fpointer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Fpointer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fpointer.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -86,18 +86,17 @@ pub trait PointerArithmetic: layout::HasDataLayout {\n \n impl<T: layout::HasDataLayout> PointerArithmetic for T {}\n \n-\n-/// Pointer is generic over the type that represents a reference to Allocations,\n+/// `Pointer` is generic over the type that represents a reference to `Allocation`s,\n /// thus making it possible for the most convenient representation to be used in\n /// each context.\n ///\n-/// Defaults to the index based and loosely coupled AllocId.\n+/// Defaults to the index based and loosely coupled `AllocId`.\n ///\n /// Pointer is also generic over the `Tag` associated with each pointer,\n /// which is used to do provenance tracking during execution.\n #[derive(Copy, Clone, Eq, PartialEq, Ord, PartialOrd,\n          RustcEncodable, RustcDecodable, Hash, HashStable)]\n-pub struct Pointer<Tag=(),Id=AllocId> {\n+pub struct Pointer<Tag = (), Id = AllocId> {\n     pub alloc_id: Id,\n     pub offset: Size,\n     pub tag: Tag,\n@@ -117,7 +116,7 @@ impl<Id: fmt::Debug> fmt::Debug for Pointer<(), Id> {\n     }\n }\n \n-/// Produces a `Pointer` which points to the beginning of the Allocation\n+/// Produces a `Pointer` which points to the beginning of the `Allocation`.\n impl From<AllocId> for Pointer {\n     #[inline(always)]\n     fn from(alloc_id: AllocId) -> Self {"}, {"sha": "d72d879059369adb2f64d61aa2c7ae598ba564c8", "filename": "src/librustc/mir/interpret/value.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -91,7 +91,7 @@ impl<'tcx> ConstValue<'tcx> {\n /// of a simple value or a pointer into another `Allocation`\n #[derive(Clone, Copy, Eq, PartialEq, Ord, PartialOrd,\n          RustcEncodable, RustcDecodable, Hash, HashStable)]\n-pub enum Scalar<Tag=(), Id=AllocId> {\n+pub enum Scalar<Tag = (), Id = AllocId> {\n     /// The raw bytes of a simple value.\n     Raw {\n         /// The first `size` bytes of `data` are the value.\n@@ -359,7 +359,7 @@ impl<'tcx, Tag> Scalar<Tag> {\n \n     #[inline(always)]\n     pub fn assert_bits(self, target_size: Size) -> u128 {\n-        self.to_bits(target_size).expect(\"Expected Raw bits but got a Pointer\")\n+        self.to_bits(target_size).expect(\"expected Raw bits but got a Pointer\")\n     }\n \n     /// Do not call this method!  Use either `assert_ptr` or `force_ptr`.\n@@ -374,7 +374,7 @@ impl<'tcx, Tag> Scalar<Tag> {\n \n     #[inline(always)]\n     pub fn assert_ptr(self) -> Pointer<Tag> {\n-        self.to_ptr().expect(\"Expected a Pointer but got Raw bits\")\n+        self.to_ptr().expect(\"expected a Pointer but got Raw bits\")\n     }\n \n     /// Do not call this method!  Dispatch based on the type instead.\n@@ -482,8 +482,8 @@ impl<Tag> From<Pointer<Tag>> for Scalar<Tag> {\n     }\n }\n \n-#[derive(Clone, Copy, Eq, PartialEq, Ord, PartialOrd, RustcEncodable, RustcDecodable, Hash)]\n-pub enum ScalarMaybeUndef<Tag=(), Id=AllocId> {\n+#[derive(Clone, Copy, Eq, PartialEq, Ord, PartialOrd, Hash, RustcEncodable, RustcDecodable)]\n+pub enum ScalarMaybeUndef<Tag = (), Id = AllocId> {\n     Scalar(Scalar<Tag, Id>),\n     Undef,\n }"}, {"sha": "18a5142208d2d6dcb0cce0260769c79ea1f5ae04", "filename": "src/librustc/mir/mod.rs", "status": "modified", "additions": 82, "deletions": 75, "changes": 157, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fmir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -18,6 +18,7 @@ use crate::ty::{\n     self, AdtDef, CanonicalUserTypeAnnotations, ClosureSubsts, GeneratorSubsts, Region, Ty, TyCtxt,\n     UserTypeAnnotationIndex,\n };\n+\n use polonius_engine::Atom;\n use rustc_data_structures::bit_set::BitMatrix;\n use rustc_data_structures::fx::FxHashSet;\n@@ -70,7 +71,7 @@ impl<'tcx> HasLocalDecls<'tcx> for Body<'tcx> {\n \n /// The various \"big phases\" that MIR goes through.\n ///\n-/// Warning: ordering of variants is significant\n+/// Warning: ordering of variants is significant.\n #[derive(Copy, Clone, RustcEncodable, RustcDecodable, Debug, PartialEq, Eq, PartialOrd, Ord)]\n pub enum MirPhase {\n     Build = 0,\n@@ -80,16 +81,16 @@ pub enum MirPhase {\n }\n \n impl MirPhase {\n-    /// Gets the index of the current MirPhase within the set of all MirPhases.\n+    /// Gets the index of the current MirPhase within the set of all `MirPhase`s.\n     pub fn phase_index(&self) -> usize {\n         *self as usize\n     }\n }\n \n-/// Lowered representation of a single function.\n+/// The lowered representation of a single function.\n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub struct Body<'tcx> {\n-    /// List of basic blocks. References to basic block use a newtyped index type `BasicBlock`\n+    /// A list of basic blocks. References to basic block use a newtyped index type `BasicBlock`\n     /// that indexes into this vector.\n     basic_blocks: IndexVec<BasicBlock, BasicBlockData<'tcx>>,\n \n@@ -100,18 +101,18 @@ pub struct Body<'tcx> {\n     /// us to see the difference and forego optimization on the inlined promoted items.\n     pub phase: MirPhase,\n \n-    /// List of source scopes; these are referenced by statements\n+    /// A list of source scopes; these are referenced by statements\n     /// and used for debuginfo. Indexed by a `SourceScope`.\n     pub source_scopes: IndexVec<SourceScope, SourceScopeData>,\n \n     /// Crate-local information for each source scope, that can't (and\n     /// needn't) be tracked across crates.\n     pub source_scope_local_data: ClearCrossCrate<IndexVec<SourceScope, SourceScopeLocalData>>,\n \n-    /// Yields type of the function, if it is a generator.\n+    /// The yield type of the function, if it is a generator.\n     pub yield_ty: Option<Ty<'tcx>>,\n \n-    /// Generator drop glue\n+    /// Generator drop glue.\n     pub generator_drop: Option<Box<Body<'tcx>>>,\n \n     /// The layout of a generator. Produced by the state transformation.\n@@ -124,10 +125,10 @@ pub struct Body<'tcx> {\n     /// variables and temporaries.\n     pub local_decls: LocalDecls<'tcx>,\n \n-    /// User type annotations\n+    /// User type annotations.\n     pub user_type_annotations: CanonicalUserTypeAnnotations<'tcx>,\n \n-    /// Number of arguments this function takes.\n+    /// The number of arguments this function takes.\n     ///\n     /// Starting at local 1, `arg_count` locals will be provided by the caller\n     /// and can be assumed to be initialized.\n@@ -143,10 +144,11 @@ pub struct Body<'tcx> {\n \n     /// Names and capture modes of all the closure upvars, assuming\n     /// the first argument is either the closure or a reference to it.\n+    //\n     // NOTE(eddyb) This is *strictly* a temporary hack for codegen\n     // debuginfo generation, and will be removed at some point.\n-    // Do **NOT** use it for anything else, upvar information should not be\n-    // in the MIR, please rely on local crate HIR or other side-channels.\n+    // Do **NOT** use it for anything else; upvar information should not be\n+    // in the MIR, so please rely on local crate HIR or other side-channels.\n     pub __upvar_debuginfo_codegen_only_do_not_use: Vec<UpvarDebuginfo>,\n \n     /// Mark this MIR of a const context other than const functions as having converted a `&&` or\n@@ -157,10 +159,10 @@ pub struct Body<'tcx> {\n     /// List of places where control flow was destroyed. Used for error reporting.\n     pub control_flow_destroyed: Vec<(Span, String)>,\n \n-    /// A span representing this MIR, for error reporting\n+    /// A span representing this MIR, for error reporting.\n     pub span: Span,\n \n-    /// A cache for various calculations\n+    /// A cache for various calculations.\n     cache: cache::Cache,\n }\n \n@@ -177,7 +179,7 @@ impl<'tcx> Body<'tcx> {\n         span: Span,\n         control_flow_destroyed: Vec<(Span, String)>,\n     ) -> Self {\n-        // We need `arg_count` locals, and one for the return place\n+        // We need `arg_count` locals, and one for the return place.\n         assert!(\n             local_decls.len() >= arg_count + 1,\n             \"expected at least {} locals, got {}\",\n@@ -384,12 +386,12 @@ impl<'tcx> Body<'tcx> {\n         true\n     }\n \n-    /// Returns the return type, it always return first element from `local_decls` array\n+    /// Returns the return type; it always return first element from `local_decls` array.\n     pub fn return_ty(&self) -> Ty<'tcx> {\n         self.local_decls[RETURN_PLACE].ty\n     }\n \n-    /// Gets the location of the terminator for the given block\n+    /// Gets the location of the terminator for the given block.\n     pub fn terminator_loc(&self, bb: BasicBlock) -> Location {\n         Location { block: bb, statement_index: self[bb].statements.len() }\n     }\n@@ -463,7 +465,7 @@ impl<T: Decodable> rustc_serialize::UseSpecializedDecodable for ClearCrossCrate<\n /// Most passes can work with it as a whole, within a single function.\n #[derive(Copy, Clone, Debug, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, HashStable)]\n pub struct SourceInfo {\n-    /// Source span for the AST pertaining to this MIR entity.\n+    /// The source span for the AST pertaining to this MIR entity.\n     pub span: Span,\n \n     /// The source scope, keeping track of which bindings can be\n@@ -591,13 +593,13 @@ impl Atom for Local {\n /// Classifies locals into categories. See `Body::local_kind`.\n #[derive(PartialEq, Eq, Debug, HashStable)]\n pub enum LocalKind {\n-    /// User-declared variable binding\n+    /// User-declared variable binding.\n     Var,\n-    /// Compiler-introduced temporary\n+    /// Compiler-introduced temporary.\n     Temp,\n-    /// Function argument\n+    /// Function argument.\n     Arg,\n-    /// Location of function's return value\n+    /// Location of function's return value.\n     ReturnPointer,\n }\n \n@@ -619,7 +621,7 @@ pub struct VarBindingForm<'tcx> {\n     /// (b) it gives a way to separate this case from the remaining cases\n     ///     for diagnostics.\n     pub opt_match_place: Option<(Option<Place<'tcx>>, Span)>,\n-    /// Span of the pattern in which this variable was bound.\n+    /// The span of the pattern in which this variable was bound.\n     pub pat_span: Span,\n }\n \n@@ -721,12 +723,12 @@ impl_stable_hash_for!(struct BlockTailInfo { tail_result_is_ignored });\n /// argument, or the return place.\n #[derive(Clone, Debug, RustcEncodable, RustcDecodable, HashStable)]\n pub struct LocalDecl<'tcx> {\n-    /// `let mut x` vs `let x`.\n+    /// Whether this is a mutable minding (i.e., `let x` or `let mut x`).\n     ///\n     /// Temporaries and the return place are always mutable.\n     pub mutability: Mutability,\n \n-    /// Some(binding_mode) if this corresponds to a user-declared local variable.\n+    /// `Some(binding_mode)` if this corresponds to a user-declared local variable.\n     ///\n     /// This is solely used for local diagnostics when generating\n     /// warnings/errors when compiling the current crate, and\n@@ -760,7 +762,7 @@ pub struct LocalDecl<'tcx> {\n     /// intervening statement context).\n     pub is_block_tail: Option<BlockTailInfo>,\n \n-    /// Type of this local.\n+    /// The type of this local.\n     pub ty: Ty<'tcx>,\n \n     /// If the user manually ascribed a type to this variable,\n@@ -769,7 +771,7 @@ pub struct LocalDecl<'tcx> {\n     /// region inference.\n     pub user_ty: UserTypeProjections,\n \n-    /// Name of the local, used in debuginfo and pretty-printing.\n+    /// The name of the local, used in debuginfo and pretty-printing.\n     ///\n     /// Note that function arguments can also have this set to `Some(_)`\n     /// to generate better debuginfo.\n@@ -837,8 +839,8 @@ pub struct LocalDecl<'tcx> {\n     /// ROOT SCOPE\n     ///  \u2502{ argument x: &str }\n     ///  \u2502\n-    ///  \u2502 \u2502{ #[allow(unused_mut)] } // this is actually split into 2 scopes\n-    ///  \u2502 \u2502                        // in practice because I'm lazy.\n+    ///  \u2502 \u2502{ #[allow(unused_mut)] } // This is actually split into 2 scopes\n+    ///  \u2502 \u2502                         // in practice because I'm lazy.\n     ///  \u2502 \u2502\n     ///  \u2502 \u2502\u2190 x.source_info.scope\n     ///  \u2502 \u2502\u2190 `x.parse().unwrap()`\n@@ -852,7 +854,7 @@ pub struct LocalDecl<'tcx> {\n     ///  \u2502\n     ///  \u2502 \u2502{ let x: u32 }\n     ///  \u2502 \u2502\u2190 x.visibility_scope\n-    ///  \u2502 \u2502\u2190 `drop(x)` // this accesses `x: u32`\n+    ///  \u2502 \u2502\u2190 `drop(x)` // This accesses `x: u32`.\n     /// ```\n     pub source_info: SourceInfo,\n \n@@ -1038,16 +1040,16 @@ pub struct Terminator<'tcx> {\n \n #[derive(Clone, RustcEncodable, RustcDecodable, HashStable)]\n pub enum TerminatorKind<'tcx> {\n-    /// block should have one successor in the graph; we jump there\n+    /// Block should have one successor in the graph; we jump there.\n     Goto { target: BasicBlock },\n \n-    /// operand evaluates to an integer; jump depending on its value\n-    /// to one of the targets, and otherwise fallback to `otherwise`\n+    /// Operand evaluates to an integer; jump depending on its value\n+    /// to one of the targets, and otherwise fallback to `otherwise`.\n     SwitchInt {\n-        /// discriminant value being tested\n+        /// The discriminant value being tested.\n         discr: Operand<'tcx>,\n \n-        /// type of value being tested\n+        /// The type of value being tested.\n         switch_ty: Ty<'tcx>,\n \n         /// Possible values. The locations to branch to in each case\n@@ -1057,6 +1059,7 @@ pub enum TerminatorKind<'tcx> {\n         /// Possible branch sites. The last element of this vector is used\n         /// for the otherwise branch, so targets.len() == values.len() + 1\n         /// should hold.\n+        //\n         // This invariant is quite non-obvious and also could be improved.\n         // One way to make this invariant is to have something like this instead:\n         //\n@@ -1069,7 +1072,7 @@ pub enum TerminatorKind<'tcx> {\n     },\n \n     /// Indicates that the landing pad is finished and unwinding should\n-    /// continue. Emitted by build::scope::diverge_cleanup.\n+    /// continue. Emitted by `build::scope::diverge_cleanup`.\n     Resume,\n \n     /// Indicates that the landing pad is finished and that the process\n@@ -1083,10 +1086,10 @@ pub enum TerminatorKind<'tcx> {\n     /// Indicates a terminator that can never be reached.\n     Unreachable,\n \n-    /// Drop the Place\n+    /// Drop the `Place`.\n     Drop { location: Place<'tcx>, target: BasicBlock, unwind: Option<BasicBlock> },\n \n-    /// Drop the Place and assign the new value over it. This ensures\n+    /// Drop the `Place` and assign the new value over it. This ensures\n     /// that the assignment to `P` occurs *even if* the destructor for\n     /// place unwinds. Its semantics are best explained by the\n     /// elaboration:\n@@ -1119,9 +1122,9 @@ pub enum TerminatorKind<'tcx> {\n         unwind: Option<BasicBlock>,\n     },\n \n-    /// Block ends with a call of a converging function\n+    /// Block ends with a call of a converging function.\n     Call {\n-        /// The function that\u2019s being called\n+        /// The function that\u2019s being called.\n         func: Operand<'tcx>,\n         /// Arguments the function is called with.\n         /// These are owned by the callee, which is free to modify them.\n@@ -1132,7 +1135,7 @@ pub enum TerminatorKind<'tcx> {\n         destination: Option<(Place<'tcx>, BasicBlock)>,\n         /// Cleanups to be done if the call unwinds.\n         cleanup: Option<BasicBlock>,\n-        /// Whether this is from a call in HIR, rather than from an overloaded\n+        /// `true` if this is from a call in HIR rather than from an overloaded\n         /// operator. True for overloaded function call.\n         from_hir_call: bool,\n     },\n@@ -1147,40 +1150,40 @@ pub enum TerminatorKind<'tcx> {\n         cleanup: Option<BasicBlock>,\n     },\n \n-    /// A suspend point\n+    /// A suspend point.\n     Yield {\n-        /// The value to return\n+        /// The value to return.\n         value: Operand<'tcx>,\n-        /// Where to resume to\n+        /// Where to resume to.\n         resume: BasicBlock,\n-        /// Cleanup to be done if the generator is dropped at this suspend point\n+        /// Cleanup to be done if the generator is dropped at this suspend point.\n         drop: Option<BasicBlock>,\n     },\n \n-    /// Indicates the end of the dropping of a generator\n+    /// Indicates the end of the dropping of a generator.\n     GeneratorDrop,\n \n     /// A block where control flow only ever takes one real path, but borrowck\n     /// needs to be more conservative.\n     FalseEdges {\n-        /// The target normal control flow will take\n+        /// The target normal control flow will take.\n         real_target: BasicBlock,\n         /// A block control flow could conceptually jump to, but won't in\n-        /// practice\n+        /// practice.\n         imaginary_target: BasicBlock,\n     },\n     /// A terminator for blocks that only take one path in reality, but where we\n     /// reserve the right to unwind in borrowck, even if it won't happen in practice.\n     /// This can arise in infinite loops with no function calls for example.\n     FalseUnwind {\n-        /// The target normal control flow will take\n+        /// The target normal control flow will take.\n         real_target: BasicBlock,\n         /// The imaginary cleanup block link. This particular path will never be taken\n         /// in practice, but in order to avoid fragility we want to always\n         /// consider it in borrowck. We don't want to accept programs which\n-        /// pass borrowck only when panic=abort or some assertions are disabled\n-        /// due to release vs. debug mode builds. This needs to be an Option because\n-        /// of the remove_noop_landing_pads and no_landing_pads passes\n+        /// pass borrowck only when `panic=abort` or some assertions are disabled\n+        /// due to release vs. debug mode builds. This needs to be an `Option` because\n+        /// of the `remove_noop_landing_pads` and `no_landing_pads` passes.\n         unwind: Option<BasicBlock>,\n     },\n }\n@@ -1445,7 +1448,7 @@ impl<'tcx> Debug for TerminatorKind<'tcx> {\n }\n \n impl<'tcx> TerminatorKind<'tcx> {\n-    /// Write the \"head\" part of the terminator; that is, its name and the data it uses to pick the\n+    /// Writes the \"head\" part of the terminator; that is, its name and the data it uses to pick the\n     /// successor basic block, if any. The only information not included is the list of possible\n     /// successors, which may be rendered differently between the text and the graphviz format.\n     pub fn fmt_head<W: Write>(&self, fmt: &mut W) -> fmt::Result {\n@@ -1615,20 +1618,20 @@ pub enum StatementKind<'tcx> {\n     Nop,\n }\n \n-/// `RetagKind` describes what kind of retag is to be performed.\n+/// Describes what kind of retag is to be performed.\n #[derive(Copy, Clone, RustcEncodable, RustcDecodable, Debug, PartialEq, Eq, HashStable)]\n pub enum RetagKind {\n-    /// The initial retag when entering a function\n+    /// The initial retag when entering a function.\n     FnEntry,\n-    /// Retag preparing for a two-phase borrow\n+    /// Retag preparing for a two-phase borrow.\n     TwoPhase,\n-    /// Retagging raw pointers\n+    /// Retagging raw pointers.\n     Raw,\n-    /// A \"normal\" retag\n+    /// A \"normal\" retag.\n     Default,\n }\n \n-/// The `FakeReadCause` describes the type of pattern why a `FakeRead` statement exists.\n+/// The `FakeReadCause` describes the type of pattern why a FakeRead statement exists.\n #[derive(Copy, Clone, RustcEncodable, RustcDecodable, Debug, HashStable)]\n pub enum FakeReadCause {\n     /// Inject a fake read of the borrowed input at the end of each guards\n@@ -2171,7 +2174,7 @@ pub struct SourceScopeData {\n \n #[derive(Clone, Debug, RustcEncodable, RustcDecodable, HashStable)]\n pub struct SourceScopeLocalData {\n-    /// A HirId with lint levels equivalent to this scope's lint levels.\n+    /// An `HirId` with lint levels equivalent to this scope's lint levels.\n     pub lint_root: hir::HirId,\n     /// The unsafe block that contains this node.\n     pub safety: Safety,\n@@ -2760,11 +2763,12 @@ impl<'a, 'b> graph::GraphSuccessors<'b> for Body<'a> {\n \n #[derive(Copy, Clone, PartialEq, Eq, Hash, Ord, PartialOrd, HashStable)]\n pub struct Location {\n-    /// the location is within this block\n+    /// The block that the location is within.\n     pub block: BasicBlock,\n \n-    /// the location is the start of the statement; or, if `statement_index`\n-    /// == num-statements, then the start of the terminator.\n+    /// The location is the position of the start of the statement; or, if\n+    /// `statement_index` equals the number of statements, then the start of the\n+    /// terminator.\n     pub statement_index: usize,\n }\n \n@@ -2827,7 +2831,7 @@ impl Location {\n #[derive(Copy, Clone, Debug, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable, HashStable)]\n pub enum UnsafetyViolationKind {\n     General,\n-    /// Permitted in const fn and regular fns.\n+    /// Permitted both in `const fn`s and regular `fn`s.\n     GeneralAndConstFn,\n     ExternStatic(hir::HirId),\n     BorrowPacked(hir::HirId),\n@@ -2843,9 +2847,9 @@ pub struct UnsafetyViolation {\n \n #[derive(Clone, Debug, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable, HashStable)]\n pub struct UnsafetyCheckResult {\n-    /// Violations that are propagated *upwards* from this function\n+    /// Violations that are propagated *upwards* from this function.\n     pub violations: Lrc<[UnsafetyViolation]>,\n-    /// unsafe blocks in this function, along with whether they are used. This is\n+    /// `unsafe` blocks in this function, along with whether they are used. This is\n     /// used for the \"unused_unsafe\" lint.\n     pub unsafe_blocks: Lrc<[(hir::HirId, bool)]>,\n }\n@@ -2857,7 +2861,7 @@ newtype_index! {\n     }\n }\n \n-/// The layout of generator state\n+/// The layout of generator state.\n #[derive(Clone, Debug, RustcEncodable, RustcDecodable, HashStable)]\n pub struct GeneratorLayout<'tcx> {\n     /// The type of every local stored inside the generator.\n@@ -2872,11 +2876,14 @@ pub struct GeneratorLayout<'tcx> {\n     /// layout.\n     pub storage_conflicts: BitMatrix<GeneratorSavedLocal, GeneratorSavedLocal>,\n \n-    /// Names and scopes of all the stored generator locals.\n-    /// NOTE(tmandry) This is *strictly* a temporary hack for codegen\n+    /// The names and scopes of all the stored generator locals.\n+    ///\n+    /// N.B., this is *strictly* a temporary hack for codegen\n     /// debuginfo generation, and will be removed at some point.\n     /// Do **NOT** use it for anything else, local information should not be\n     /// in the MIR, please rely on local crate HIR or other side-channels.\n+    //\n+    // FIXME(tmandry): see above.\n     pub __local_debuginfo_codegen_only_do_not_use: IndexVec<GeneratorSavedLocal, LocalDecl<'tcx>>,\n }\n \n@@ -2934,7 +2941,7 @@ pub struct BorrowCheckResult<'tcx> {\n /// instances assigned one of these same indices. Those regions will\n /// be substituted away by the creator. We use `ReClosureBound` in\n /// that case because the regions must be allocated in the global\n-/// TyCtxt, and hence we cannot use `ReVar` (which is what we use\n+/// `TyCtxt`, and hence we cannot use `ReVar` (which is what we use\n /// internally within the rest of the NLL code).\n #[derive(Clone, Debug, RustcEncodable, RustcDecodable, HashStable)]\n pub struct ClosureRegionRequirements<'tcx> {\n@@ -2950,8 +2957,8 @@ pub struct ClosureRegionRequirements<'tcx> {\n     pub outlives_requirements: Vec<ClosureOutlivesRequirement<'tcx>>,\n }\n \n-/// Indicates an outlives constraint between a type or between two\n-/// free-regions declared on the closure.\n+/// Indicates an outlives-constraint between a type or between two\n+/// free regions declared on the closure.\n #[derive(Copy, Clone, Debug, RustcEncodable, RustcDecodable, HashStable)]\n pub struct ClosureOutlivesRequirement<'tcx> {\n     // This region or type ...\n@@ -2967,11 +2974,11 @@ pub struct ClosureOutlivesRequirement<'tcx> {\n     pub category: ConstraintCategory,\n }\n \n-/// Outlives constraints can be categorized to determine whether and why they\n+/// Outlives-constraints can be categorized to determine whether and why they\n /// are interesting (for error reporting). Order of variants indicates sort\n /// order of the category, thereby influencing diagnostic output.\n ///\n-/// See also [rustc_mir::borrow_check::nll::constraints]\n+/// See also [rustc_mir::borrow_check::nll::constraints].\n #[derive(\n     Copy,\n     Clone,\n@@ -3019,7 +3026,7 @@ pub enum ConstraintCategory {\n     Internal,\n }\n \n-/// The subject of a ClosureOutlivesRequirement -- that is, the thing\n+/// The subject of a `ClosureOutlivesRequirement` -- that is, the thing\n /// that must outlive some region.\n #[derive(Copy, Clone, Debug, RustcEncodable, RustcDecodable, HashStable)]\n pub enum ClosureOutlivesSubject<'tcx> {\n@@ -3037,7 +3044,7 @@ pub enum ClosureOutlivesSubject<'tcx> {\n }\n \n /*\n- * TypeFoldable implementations for MIR types\n+ * `TypeFoldable` implementations for MIR types\n */\n \n CloneTypeFoldableAndLiftImpls! {"}, {"sha": "4ebc2e72490d4565f769cfb5ac2b86f56d6ad494", "filename": "src/librustc/query/mod.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fquery%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -17,7 +17,6 @@ use crate::traits::query::{\n use std::borrow::Cow;\n use syntax_pos::symbol::InternedString;\n \n-\n // Each of these queries corresponds to a function pointer field in the\n // `Providers` struct for requesting a value of that type, and a method\n // on `tcx: TyCtxt` (and `tcx.at(span)`) for doing that request in a way\n@@ -854,7 +853,7 @@ rustc_queries! {\n             desc { \"calculating the lang items map\" }\n         }\n \n-        /// Returns all diagnostic items defined in all crates\n+        /// Returns all diagnostic items defined in all crates.\n         query all_diagnostic_items(_: CrateNum) -> &'tcx FxHashMap<Symbol, DefId> {\n             eval_always\n             desc { \"calculating the diagnostic items map\" }\n@@ -865,7 +864,7 @@ rustc_queries! {\n             desc { \"calculating the lang items defined in a crate\" }\n         }\n \n-        /// Returns the diagnostic items defined in a crate\n+        /// Returns the diagnostic items defined in a crate.\n         query diagnostic_items(_: CrateNum) -> &'tcx FxHashMap<Symbol, DefId> {\n             desc { \"calculating the diagnostic items map in a crate\" }\n         }"}, {"sha": "c74b2fee41d6c298428cd02935151e8485148706", "filename": "src/librustc/session/config.rs", "status": "modified", "additions": 68, "deletions": 69, "changes": 137, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fsession%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fsession%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fconfig.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,36 +1,36 @@\n //! Contains infrastructure for configuring the compiler, including parsing\n-//! command line options.\n-\n-use std::str::FromStr;\n+//! command-line options.\n \n+use crate::lint;\n+use crate::middle::cstore;\n use crate::session::{early_error, early_warn, Session};\n use crate::session::search_paths::SearchPath;\n \n+use rustc_data_structures::fx::FxHashSet;\n+\n use rustc_target::spec::{LinkerFlavor, MergeFunctions, PanicStrategy, RelroLevel};\n use rustc_target::spec::{Target, TargetTriple};\n-use crate::lint;\n-use crate::middle::cstore;\n \n use syntax;\n use syntax::ast::{self, IntTy, UintTy, MetaItemKind};\n use syntax::source_map::{FileName, FilePathMapping};\n use syntax::edition::{Edition, EDITION_NAME_LIST, DEFAULT_EDITION};\n+use syntax::parse::{ParseSess, new_parser_from_source_str};\n use syntax::parse::token;\n-use syntax::parse;\n use syntax::symbol::{sym, Symbol};\n use syntax::feature_gate::UnstableFeatures;\n-use errors::emitter::HumanReadableErrorType;\n \n+use errors::emitter::HumanReadableErrorType;\n use errors::{ColorConfig, FatalError, Handler};\n \n use getopts;\n-use std::collections::{BTreeMap, BTreeSet};\n-use std::collections::btree_map::Iter as BTreeMapIter;\n-use std::collections::btree_map::Keys as BTreeMapKeysIter;\n-use std::collections::btree_map::Values as BTreeMapValuesIter;\n \n-use rustc_data_structures::fx::FxHashSet;\n-use std::{fmt, str};\n+use std::collections::{BTreeMap, BTreeSet};\n+use std::collections::btree_map::{\n+    Iter as BTreeMapIter, Keys as BTreeMapKeysIter, Values as BTreeMapValuesIter,\n+};\n+use std::fmt;\n+use std::str::{self, FromStr};\n use std::hash::Hasher;\n use std::collections::hash_map::DefaultHasher;\n use std::iter::FromIterator;\n@@ -241,14 +241,14 @@ pub enum ErrorOutputType {\n }\n \n impl Default for ErrorOutputType {\n-    fn default() -> ErrorOutputType {\n-        ErrorOutputType::HumanReadable(HumanReadableErrorType::Default(ColorConfig::Auto))\n+    fn default() -> Self {\n+        Self::HumanReadable(HumanReadableErrorType::Default(ColorConfig::Auto))\n     }\n }\n \n-// Use tree-based collections to cheaply get a deterministic Hash implementation.\n-// DO NOT switch BTreeMap out for an unsorted container type! That would break\n-// dependency tracking for command-line arguments.\n+/// Use tree-based collections to cheaply get a deterministic `Hash` implementation.\n+/// *Do not* switch `BTreeMap` out for an unsorted container type! That would break\n+/// dependency tracking for command-line arguments.\n #[derive(Clone, Hash)]\n pub struct OutputTypes(BTreeMap<OutputType, Option<PathBuf>>);\n \n@@ -281,7 +281,7 @@ impl OutputTypes {\n         self.0.len()\n     }\n \n-    // True if any of the output types require codegen or linking.\n+    // Returns `true` if any of the output types require codegen or linking.\n     pub fn should_codegen(&self) -> bool {\n         self.0.keys().any(|k| match *k {\n             OutputType::Bitcode\n@@ -295,9 +295,9 @@ impl OutputTypes {\n     }\n }\n \n-// Use tree-based collections to cheaply get a deterministic Hash implementation.\n-// DO NOT switch BTreeMap or BTreeSet out for an unsorted container type! That\n-// would break dependency tracking for command-line arguments.\n+/// Use tree-based collections to cheaply get a deterministic `Hash` implementation.\n+/// *Do not* switch `BTreeMap` or `BTreeSet` out for an unsorted container type! That\n+/// would break dependency tracking for command-line arguments.\n #[derive(Clone, Hash)]\n pub struct Externs(BTreeMap<String, ExternEntry>);\n \n@@ -327,7 +327,7 @@ macro_rules! hash_option {\n     ($opt_name:ident, $opt_expr:expr, $sub_hashes:expr, [TRACKED]) => ({\n         if $sub_hashes.insert(stringify!($opt_name),\n                               $opt_expr as &dyn dep_tracking::DepTrackingHash).is_some() {\n-            bug!(\"Duplicate key in CLI DepTrackingHash: {}\", stringify!($opt_name))\n+            bug!(\"duplicate key in CLI DepTrackingHash: {}\", stringify!($opt_name))\n         }\n     });\n }\n@@ -362,7 +362,7 @@ macro_rules! top_level_options {\n     );\n }\n \n-// The top-level command-line options struct\n+// The top-level command-line options struct.\n //\n // For each option, one has to specify how it behaves with regard to the\n // dependency tracking system of incremental compilation. This is done via the\n@@ -376,16 +376,16 @@ macro_rules! top_level_options {\n // Incremental compilation is not influenced by this option.\n //\n // If you add a new option to this struct or one of the sub-structs like\n-// CodegenOptions, think about how it influences incremental compilation. If in\n+// `CodegenOptions`, think about how it influences incremental compilation. If in\n // doubt, specify [TRACKED], which is always \"correct\" but might lead to\n // unnecessary re-compilation.\n top_level_options!(\n     pub struct Options {\n         // The crate config requested for the session, which may be combined\n-        // with additional crate configurations during the compile process\n+        // with additional crate configurations during the compile process.\n         crate_types: Vec<CrateType> [TRACKED],\n         optimize: OptLevel [TRACKED],\n-        // Include the debug_assertions flag into dependency tracking, since it\n+        // Include the `debug_assertions` flag in dependency tracking, since it\n         // can influence whether overflow checks are done or not.\n         debug_assertions: bool [TRACKED],\n         debuginfo: DebugInfo [TRACKED],\n@@ -402,8 +402,8 @@ top_level_options!(\n         test: bool [TRACKED],\n         error_format: ErrorOutputType [UNTRACKED],\n \n-        // if Some, enable incremental compilation, using the given\n-        // directory to store intermediate results\n+        // If `Some`, enable incremental compilation, using the given\n+        // directory to store intermediate results.\n         incremental: Option<PathBuf> [UNTRACKED],\n \n         debugging_opts: DebuggingOptions [TRACKED],\n@@ -418,7 +418,7 @@ top_level_options!(\n         // written `extern crate name as std`. Defaults to `std`. Used by\n         // out-of-tree drivers.\n         alt_std_name: Option<String> [TRACKED],\n-        // Indicates how the compiler should treat unstable features\n+        // Indicates how the compiler should treat unstable features.\n         unstable_features: UnstableFeatures [TRACKED],\n \n         // Indicates whether this run of the compiler is actually rustdoc. This\n@@ -434,12 +434,12 @@ top_level_options!(\n         cli_forced_codegen_units: Option<usize> [UNTRACKED],\n         cli_forced_thinlto_off: bool [UNTRACKED],\n \n-        // Remap source path prefixes in all output (messages, object files, debug, etc)\n+        // Remap source path prefixes in all output (messages, object files, debug, etc.).\n         remap_path_prefix: Vec<(PathBuf, PathBuf)> [UNTRACKED],\n \n         edition: Edition [TRACKED],\n \n-        // Whether or not we're emitting JSON blobs about each artifact produced\n+        // `true` if we're emitting JSON blobs about each artifact produced\n         // by the compiler.\n         json_artifact_notifications: bool [TRACKED],\n     }\n@@ -468,7 +468,7 @@ pub enum BorrowckMode {\n }\n \n impl BorrowckMode {\n-    /// Should we run the MIR-based borrow check, but also fall back\n+    /// Returns whether we should run the MIR-based borrow check, but also fall back\n     /// on the AST borrow check if the MIR-based one errors.\n     pub fn migrate(self) -> bool {\n         match self {\n@@ -477,7 +477,7 @@ impl BorrowckMode {\n         }\n     }\n \n-    /// Should we emit the AST-based borrow checker errors?\n+    /// Returns whether we should emit the AST-based borrow checker errors.\n     pub fn use_ast(self) -> bool {\n         match self {\n             BorrowckMode::Mir => false,\n@@ -487,12 +487,13 @@ impl BorrowckMode {\n }\n \n pub enum Input {\n-    /// Loads source from file\n+    /// Load source code from a file.\n     File(PathBuf),\n+    /// Load source code from a string.\n     Str {\n-        /// String that is shown in place of a filename\n+        /// A string that is shown in place of a filename.\n         name: FileName,\n-        /// Anonymous source string\n+        /// An anonymous string containing the source code.\n         input: String,\n     },\n }\n@@ -651,7 +652,7 @@ impl Options {\n         FilePathMapping::new(self.remap_path_prefix.clone())\n     }\n \n-    /// Returns `true` if there will be an output file generated\n+    /// Returns `true` if there will be an output file generated.\n     pub fn will_create_output_file(&self) -> bool {\n         !self.debugging_opts.parse_only && // The file is just being parsed\n             !self.debugging_opts.ls // The file is just being queried\n@@ -709,16 +710,14 @@ impl Passes {\n     }\n }\n \n-/// Declare a macro that will define all CodegenOptions/DebuggingOptions fields and parsers all\n-/// at once. The goal of this macro is to define an interface that can be\n-/// programmatically used by the option parser in order to initialize the struct\n-/// without hardcoding field names all over the place.\n+/// Defines all `CodegenOptions`/`DebuggingOptions` fields and parsers all at once. The goal of this\n+/// macro is to define an interface that can be programmatically used by the option parser\n+/// to initialize the struct without hardcoding field names all over the place.\n ///\n-/// The goal is to invoke this macro once with the correct fields, and then this\n-/// macro generates all necessary code. The main gotcha of this macro is the\n-/// cgsetters module which is a bunch of generated code to parse an option into\n-/// its respective field in the struct. There are a few hand-written parsers for\n-/// parsing specific types of values in this module.\n+/// The goal is to invoke this macro once with the correct fields, and then this macro generates all\n+/// necessary code. The main gotcha of this macro is the `cgsetters` module which is a bunch of\n+/// generated code to parse an option into its respective field in the struct. There are a few\n+/// hand-written parsers for parsing specific types of values in this module.\n macro_rules! options {\n     ($struct_name:ident, $setter_name:ident, $defaultfn:ident,\n      $buildfn:ident, $prefix:expr, $outputname:expr,\n@@ -1539,7 +1538,7 @@ pub fn default_configuration(sess: &Session) -> ast::CrateConfig {\n     ret\n }\n \n-/// Converts the crate cfg! configuration from String to Symbol.\n+/// Converts the crate `cfg!` configuration from `String` to `Symbol`.\n /// `rustc_interface::interface::Config` accepts this in the compiler configuration,\n /// but the symbol interner is not yet set up then, so we must convert it later.\n pub fn to_crate_config(cfg: FxHashSet<(String, Option<String>)>) -> ast::CrateConfig {\n@@ -1550,9 +1549,9 @@ pub fn to_crate_config(cfg: FxHashSet<(String, Option<String>)>) -> ast::CrateCo\n \n pub fn build_configuration(sess: &Session, mut user_cfg: ast::CrateConfig) -> ast::CrateConfig {\n     // Combine the configuration requested by the session (command line) with\n-    // some default and generated configuration items\n+    // some default and generated configuration items.\n     let default_cfg = default_configuration(sess);\n-    // If the user wants a test runner, then add the test cfg\n+    // If the user wants a test runner, then add the test cfg.\n     if sess.opts.test {\n         user_cfg.insert((sym::test, None));\n     }\n@@ -1851,13 +1850,13 @@ pub fn rustc_optgroups() -> Vec<RustcOptGroup> {\n     opts\n }\n \n-// Convert strings provided as --cfg [cfgspec] into a crate_cfg\n+// Converts strings provided as `--cfg [cfgspec]` into a `crate_cfg`.\n pub fn parse_cfgspecs(cfgspecs: Vec<String>) -> FxHashSet<(String, Option<String>)> {\n     syntax::with_default_globals(move || {\n         let cfg = cfgspecs.into_iter().map(|s| {\n-            let sess = parse::ParseSess::new(FilePathMapping::empty());\n+            let sess = ParseSess::new(FilePathMapping::empty());\n             let filename = FileName::cfg_spec_source_code(&s);\n-            let mut parser = parse::new_parser_from_source_str(&sess, filename, s.to_string());\n+            let mut parser = new_parser_from_source_str(&sess, filename, s.to_string());\n \n             macro_rules! error {($reason: expr) => {\n                 early_error(ErrorOutputType::default(),\n@@ -1917,7 +1916,7 @@ pub fn get_cmd_lint_options(matches: &getopts::Matches,\n     (lint_opts, describe_lints, lint_cap)\n }\n \n-/// Parse the `--color` flag\n+/// Parses the `--color` flag.\n pub fn parse_color(matches: &getopts::Matches) -> ColorConfig {\n     match matches.opt_str(\"color\").as_ref().map(|s| &s[..]) {\n         Some(\"auto\") => ColorConfig::Auto,\n@@ -1929,7 +1928,7 @@ pub fn parse_color(matches: &getopts::Matches) -> ColorConfig {\n         Some(arg) => early_error(\n             ErrorOutputType::default(),\n             &format!(\n-                \"argument for --color must be auto, \\\n+                \"argument for `--color` must be auto, \\\n                  always or never (instead was `{}`)\",\n                 arg\n             ),\n@@ -1974,16 +1973,16 @@ pub fn parse_json(matches: &getopts::Matches) -> (HumanReadableErrorType, bool)\n     (json_rendered(json_color), json_artifact_notifications)\n }\n \n-/// Parse the `--error-format` flag\n+/// Parses the `--error-format` flag.\n pub fn parse_error_format(\n     matches: &getopts::Matches,\n     color: ColorConfig,\n     json_rendered: HumanReadableErrorType,\n ) -> ErrorOutputType {\n-    // We need the opts_present check because the driver will send us Matches\n+    // We need the `opts_present` check because the driver will send us Matches\n     // with only stable options if no unstable options are used. Since error-format\n-    // is unstable, it will not be present. We have to use opts_present not\n-    // opt_present because the latter will panic.\n+    // is unstable, it will not be present. We have to use `opts_present` not\n+    // `opt_present` because the latter will panic.\n     let error_format = if matches.opts_present(&[\"error-format\".to_owned()]) {\n         match matches.opt_str(\"error-format\").as_ref().map(|s| &s[..]) {\n             None |\n@@ -2116,7 +2115,7 @@ pub fn build_session_options_and_crate_config(\n     let mut codegen_units = cg.codegen_units;\n     let mut disable_thinlto = false;\n \n-    // Issue #30063: if user requests llvm-related output to one\n+    // Issue #30063: if user requests LLVM-related output to one\n     // particular path, disable codegen-units.\n     let incompatible: Vec<_> = output_types\n         .iter()\n@@ -2414,10 +2413,10 @@ pub fn build_session_options_and_crate_config(\n         )\n     }\n \n-    // We start out with a Vec<(Option<String>, bool)>>,\n-    // and later convert it into a BTreeSet<(Option<String>, bool)>\n+    // We start out with a `Vec<(Option<String>, bool)>>`,\n+    // and later convert it into a `BTreeSet<(Option<String>, bool)>`\n     // This allows to modify entries in-place to set their correct\n-    // 'public' value\n+    // 'public' value.\n     let mut externs: BTreeMap<String, ExternEntry> = BTreeMap::new();\n     for (arg, private) in matches.opt_strs(\"extern\").into_iter().map(|v| (v, false))\n         .chain(matches.opt_strs(\"extern-private\").into_iter().map(|v| (v, true))) {\n@@ -2616,15 +2615,15 @@ impl fmt::Display for CrateType {\n /// The values of all command-line arguments that are relevant for dependency\n /// tracking are hashed into a single value that determines whether the\n /// incremental compilation cache can be re-used or not. This hashing is done\n-/// via the DepTrackingHash trait defined below, since the standard Hash\n-/// implementation might not be suitable (e.g., arguments are stored in a Vec,\n+/// via the `DepTrackingHash` trait defined below, since the standard `Hash`\n+/// implementation might not be suitable (e.g., arguments are stored in a `Vec`,\n /// the hash of which is order dependent, but we might not want the order of\n /// arguments to make a difference for the hash).\n ///\n-/// However, since the value provided by Hash::hash often *is* suitable,\n+/// However, since the value provided by `Hash::hash` often *is* suitable,\n /// especially for primitive types, there is the\n-/// impl_dep_tracking_hash_via_hash!() macro that allows to simply reuse the\n-/// Hash implementation for DepTrackingHash. It's important though that\n+/// `impl_dep_tracking_hash_via_hash!()` macro that allows to simply reuse the\n+/// `Hash` implementation for `DepTrackingHash`. It's important though that\n /// we have an opt-in scheme here, so one is hopefully forced to think about\n /// how the hash should be calculated when adding a new command-line argument.\n mod dep_tracking {\n@@ -2637,9 +2636,9 @@ mod dep_tracking {\n     use super::{CrateType, DebugInfo, ErrorOutputType, OptLevel, OutputTypes,\n                 Passes, Sanitizer, LtoCli, LinkerPluginLto, SwitchWithOptPath,\n                 SymbolManglingVersion};\n-    use syntax::feature_gate::UnstableFeatures;\n     use rustc_target::spec::{MergeFunctions, PanicStrategy, RelroLevel, TargetTriple};\n     use syntax::edition::Edition;\n+    use syntax::feature_gate::UnstableFeatures;\n \n     pub trait DepTrackingHash {\n         fn hash(&self, hasher: &mut DefaultHasher, error_format: ErrorOutputType);"}, {"sha": "8656ebb2e6d72ad36190e32a6c158d39312ec46e", "filename": "src/librustc/session/mod.rs", "status": "modified", "additions": 33, "deletions": 28, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fsession%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fsession%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -79,24 +79,24 @@ pub struct Session {\n     /// if the value stored here has been affected by path remapping.\n     pub working_dir: (PathBuf, bool),\n \n-    // FIXME: lint_store and buffered_lints are not thread-safe,\n-    // but are only used in a single thread\n+    // FIXME: `lint_store` and `buffered_lints` are not thread-safe,\n+    // but are only used in a single thread.\n     pub lint_store: RwLock<lint::LintStore>,\n     pub buffered_lints: Lock<Option<lint::LintBuffer>>,\n \n-    /// Set of (DiagnosticId, Option<Span>, message) tuples tracking\n+    /// Set of `(DiagnosticId, Option<Span>, message)` tuples tracking\n     /// (sub)diagnostics that have been set once, but should not be set again,\n     /// in order to avoid redundantly verbose output (Issue #24690, #44953).\n     pub one_time_diagnostics: Lock<FxHashSet<(DiagnosticMessageId, Option<Span>, String)>>,\n     pub plugin_llvm_passes: OneThread<RefCell<Vec<String>>>,\n     pub plugin_attributes: Lock<Vec<(Symbol, AttributeType)>>,\n     pub crate_types: Once<Vec<config::CrateType>>,\n     pub dependency_formats: Once<dependency_format::Dependencies>,\n-    /// The crate_disambiguator is constructed out of all the `-C metadata`\n+    /// The `crate_disambiguator` is constructed out of all the `-C metadata`\n     /// arguments passed to the compiler. Its value together with the crate-name\n     /// forms a unique global identifier for the crate. It is used to allow\n     /// multiple crates with the same name to coexist. See the\n-    /// rustc_codegen_llvm::back::symbol_names module for more information.\n+    /// `rustc_codegen_llvm::back::symbol_names` module for more information.\n     pub crate_disambiguator: Once<CrateDisambiguator>,\n \n     features: Once<feature_gate::Features>,\n@@ -111,7 +111,7 @@ pub struct Session {\n     /// The maximum number of stackframes allowed in const eval.\n     pub const_eval_stack_frame_limit: usize,\n \n-    /// The metadata::creader module may inject an allocator/panic_runtime\n+    /// The `metadata::creader` module may inject an allocator/`panic_runtime`\n     /// dependency if it didn't already find one, and this tracks what was\n     /// injected.\n     pub allocator_kind: Once<Option<AllocatorKind>>,\n@@ -130,7 +130,7 @@ pub struct Session {\n     /// Used by `-Z profile-queries` in `util::common`.\n     pub profile_channel: Lock<Option<mpsc::Sender<ProfileQueriesMsg>>>,\n \n-    /// Used by -Z self-profile\n+    /// Used by `-Z self-profile`.\n     pub self_profiling: Option<Arc<SelfProfiler>>,\n \n     /// Some measurements that are being gathered during compilation.\n@@ -187,16 +187,16 @@ pub struct PerfStats {\n     pub normalize_projection_ty: AtomicUsize,\n }\n \n-/// Enum to support dispatch of one-time diagnostics (in Session.diag_once)\n+/// Enum to support dispatch of one-time diagnostics (in `Session.diag_once`).\n enum DiagnosticBuilderMethod {\n     Note,\n     SpanNote,\n     SpanSuggestion(String), // suggestion\n-                            // add more variants as needed to support one-time diagnostics\n+                            // Add more variants as needed to support one-time diagnostics.\n }\n \n-/// Diagnostic message ID\u2014used by `Session.one_time_diagnostics` to avoid\n-/// emitting the same message more than once\n+/// Diagnostic message ID, used by `Session.one_time_diagnostics` to avoid\n+/// emitting the same message more than once.\n #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]\n pub enum DiagnosticMessageId {\n     ErrorId(u16), // EXXXX error code as integer\n@@ -408,7 +408,7 @@ impl Session {\n             Some(next) => {\n                 self.next_node_id.set(ast::NodeId::from_usize(next));\n             }\n-            None => bug!(\"Input too large, ran out of node ids!\"),\n+            None => bug!(\"input too large; ran out of node-IDs!\"),\n         }\n \n         id\n@@ -440,11 +440,11 @@ impl Session {\n                     diag_builder.note(message);\n                 }\n                 DiagnosticBuilderMethod::SpanNote => {\n-                    let span = span_maybe.expect(\"span_note needs a span\");\n+                    let span = span_maybe.expect(\"`span_note` needs a span\");\n                     diag_builder.span_note(span, message);\n                 }\n                 DiagnosticBuilderMethod::SpanSuggestion(suggestion) => {\n-                    let span = span_maybe.expect(\"span_suggestion_* needs a span\");\n+                    let span = span_maybe.expect(\"`span_suggestion_*` needs a span\");\n                     diag_builder.span_suggestion(\n                         span,\n                         message,\n@@ -688,7 +688,7 @@ impl Session {\n \n     pub fn must_not_eliminate_frame_pointers(&self) -> bool {\n         // \"mcount\" function relies on stack pointer.\n-        // See https://sourceware.org/binutils/docs/gprof/Implementation.html\n+        // See <https://sourceware.org/binutils/docs/gprof/Implementation.html>.\n         if self.instrument_mcount() {\n             true\n         } else if let Some(x) = self.opts.cg.force_frame_pointers {\n@@ -699,7 +699,7 @@ impl Session {\n     }\n \n     /// Returns the symbol name for the registrar function,\n-    /// given the crate Svh and the function DefIndex.\n+    /// given the crate `Svh` and the function `DefIndex`.\n     pub fn generate_plugin_registrar_symbol(&self, disambiguator: CrateDisambiguator) -> String {\n         format!(\n             \"__rustc_plugin_registrar_{}__\",\n@@ -719,7 +719,7 @@ impl Session {\n             &self.sysroot,\n             self.opts.target_triple.triple(),\n             &self.opts.search_paths,\n-            // target_tlib_path==None means it's the same as host_tlib_path.\n+            // `target_tlib_path == None` means it's the same as `host_tlib_path`.\n             self.target_tlib_path.as_ref().unwrap_or(&self.host_tlib_path),\n             kind,\n         )\n@@ -779,12 +779,12 @@ impl Session {\n         if let IncrCompSession::Active { .. } = *incr_comp_session {\n         } else {\n             bug!(\n-                \"Trying to finalize IncrCompSession `{:?}`\",\n+                \"trying to finalize `IncrCompSession` `{:?}`\",\n                 *incr_comp_session\n-            )\n+            );\n         }\n \n-        // Note: This will also drop the lock file, thus unlocking the directory\n+        // Note: this will also drop the lock file, thus unlocking the directory.\n         *incr_comp_session = IncrCompSession::Finalized {\n             session_directory: new_directory_path,\n         };\n@@ -800,13 +800,15 @@ impl Session {\n             } => session_directory.clone(),\n             IncrCompSession::InvalidBecauseOfErrors { .. } => return,\n             _ => bug!(\n-                \"Trying to invalidate IncrCompSession `{:?}`\",\n+                \"trying to invalidate `IncrCompSession` `{:?}`\",\n                 *incr_comp_session\n             ),\n         };\n \n-        // Note: This will also drop the lock file, thus unlocking the directory\n-        *incr_comp_session = IncrCompSession::InvalidBecauseOfErrors { session_directory };\n+        // Note: this will also drop the lock file, thus unlocking the directory.\n+        *incr_comp_session = IncrCompSession::InvalidBecauseOfErrors {\n+            session_directory,\n+        };\n     }\n \n     pub fn incr_comp_session_dir(&self) -> cell::Ref<'_, PathBuf> {\n@@ -815,8 +817,8 @@ impl Session {\n             incr_comp_session,\n             |incr_comp_session| match *incr_comp_session {\n                 IncrCompSession::NotInitialized => bug!(\n-                    \"Trying to get session directory from IncrCompSession `{:?}`\",\n-                    *incr_comp_session\n+                    \"trying to get session directory from `IncrCompSession`: {:?}\",\n+                    *incr_comp_session,\n                 ),\n                 IncrCompSession::Active {\n                     ref session_directory,\n@@ -1185,7 +1187,10 @@ fn build_session_(\n     );\n     let target_cfg = config::build_target_config(&sopts, &span_diagnostic);\n \n-    let p_s = parse::ParseSess::with_span_handler(span_diagnostic, source_map);\n+    let parse_sess = parse::ParseSess::with_span_handler(\n+        span_diagnostic,\n+        source_map,\n+    );\n     let sysroot = match &sopts.maybe_sysroot {\n         Some(sysroot) => sysroot.clone(),\n         None => filesearch::get_or_default_sysroot(),\n@@ -1214,7 +1219,7 @@ fn build_session_(\n     let print_fuel = AtomicU64::new(0);\n \n     let working_dir = env::current_dir().unwrap_or_else(|e|\n-        p_s.span_diagnostic\n+        parse_sess.span_diagnostic\n             .fatal(&format!(\"Current directory is invalid: {}\", e))\n             .raise()\n     );\n@@ -1232,7 +1237,7 @@ fn build_session_(\n         opts: sopts,\n         host_tlib_path,\n         target_tlib_path,\n-        parse_sess: p_s,\n+        parse_sess,\n         sysroot,\n         local_crate_source_file,\n         working_dir,"}, {"sha": "a7990c4af69fd50fd0bfa7862689d4d243982b7a", "filename": "src/librustc/traits/object_safety.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ftraits%2Fobject_safety.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ftraits%2Fobject_safety.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ftraits%2Fobject_safety.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -130,13 +130,13 @@ impl<'tcx> TyCtxt<'tcx> {\n     }\n \n     /// We say a method is *vtable safe* if it can be invoked on a trait\n-    /// object.  Note that object-safe traits can have some\n-    /// non-vtable-safe methods, so long as they require `Self:Sized` or\n-    /// otherwise ensure that they cannot be used when `Self=Trait`.\n+    /// object. Note that object-safe traits can have some\n+    /// non-vtable-safe methods, so long as they require `Self: Sized` or\n+    /// otherwise ensure that they cannot be used when `Self = Trait`.\n     pub fn is_vtable_safe_method(self, trait_def_id: DefId, method: &ty::AssocItem) -> bool {\n         debug_assert!(self.generics_of(trait_def_id).has_self);\n         debug!(\"is_vtable_safe_method({:?}, {:?})\", trait_def_id, method);\n-        // Any method that has a `Self : Sized` requisite can't be called.\n+        // Any method that has a `Self: Sized` bound cannot be called.\n         if self.generics_require_sized_self(method.def_id) {\n             return false;\n         }\n@@ -350,15 +350,15 @@ impl<'tcx> TyCtxt<'tcx> {\n             &sig.map_bound(|sig| sig.inputs()[0]),\n         );\n \n-        // until `unsized_locals` is fully implemented, `self: Self` can't be dispatched on.\n+        // Until `unsized_locals` is fully implemented, `self: Self` can't be dispatched on.\n         // However, this is already considered object-safe. We allow it as a special case here.\n         // FIXME(mikeyhew) get rid of this `if` statement once `receiver_is_dispatchable` allows\n-        // `Receiver: Unsize<Receiver[Self => dyn Trait]>`\n+        // `Receiver: Unsize<Receiver[Self => dyn Trait]>`.\n         if receiver_ty != self.types.self_param {\n             if !self.receiver_is_dispatchable(method, receiver_ty) {\n                 return Some(MethodViolationCode::UndispatchableReceiver);\n             } else {\n-                // sanity check to make sure the receiver actually has the layout of a pointer\n+                // Do sanity check to make sure the receiver actually has the layout of a pointer.\n \n                 use crate::ty::layout::Abi;\n \n@@ -373,7 +373,7 @@ impl<'tcx> TyCtxt<'tcx> {\n                     }\n                 };\n \n-                // e.g., Rc<()>\n+                // e.g., `Rc<()>`\n                 let unit_receiver_ty = self.receiver_for_self_ty(\n                     receiver_ty, self.mk_unit(), method.def_id\n                 );\n@@ -395,7 +395,7 @@ impl<'tcx> TyCtxt<'tcx> {\n                     trait_def_id, self.mk_region(ty::ReStatic)\n                 );\n \n-                // e.g., Rc<dyn Trait>\n+                // e.g., `Rc<dyn Trait>`\n                 let trait_object_receiver = self.receiver_for_self_ty(\n                     receiver_ty, trait_object_ty, method.def_id\n                 );\n@@ -419,8 +419,8 @@ impl<'tcx> TyCtxt<'tcx> {\n         None\n     }\n \n-    /// Performs a type substitution to produce the version of receiver_ty when `Self = self_ty`\n-    /// e.g., for receiver_ty = `Rc<Self>` and self_ty = `Foo`, returns `Rc<Foo>`.\n+    /// Performs a type substitution to produce the version of `receiver_ty` when `Self = self_ty`.\n+    /// For example, for `receiver_ty = Rc<Self>` and `self_ty = Foo`, returns `Rc<Foo>`.\n     fn receiver_for_self_ty(\n         self,\n         receiver_ty: Ty<'tcx>,"}, {"sha": "b9557ceaa6d9f87aaf53cd7b540e3723509f69a2", "filename": "src/librustc/traits/query/evaluate_obligation.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ftraits%2Fquery%2Fevaluate_obligation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ftraits%2Fquery%2Fevaluate_obligation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ftraits%2Fquery%2Fevaluate_obligation.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,7 +1,8 @@\n use crate::infer::InferCtxt;\n use crate::infer::canonical::OriginalQueryValues;\n-use crate::traits::{EvaluationResult, PredicateObligation, SelectionContext,\n-             TraitQueryMode, OverflowError};\n+use crate::traits::{\n+    EvaluationResult, PredicateObligation, SelectionContext, TraitQueryMode, OverflowError,\n+};\n \n impl<'cx, 'tcx> InferCtxt<'cx, 'tcx> {\n     /// Evaluates whether the predicate can be satisfied (by any means)"}, {"sha": "039dea1ffcd1655d4346485a8129d9c57e0c38ad", "filename": "src/librustc/traits/query/method_autoderef.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ftraits%2Fquery%2Fmethod_autoderef.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ftraits%2Fquery%2Fmethod_autoderef.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ftraits%2Fquery%2Fmethod_autoderef.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -6,11 +6,11 @@ use crate::ty::Ty;\n pub struct CandidateStep<'tcx> {\n     pub self_ty: Canonical<'tcx, QueryResponse<'tcx, Ty<'tcx>>>,\n     pub autoderefs: usize,\n-    // true if the type results from a dereference of a raw pointer.\n-    // when assembling candidates, we include these steps, but not when\n-    // picking methods. This so that if we have `foo: *const Foo` and `Foo` has methods\n-    // `fn by_raw_ptr(self: *const Self)` and `fn by_ref(&self)`, then\n-    // `foo.by_raw_ptr()` will work and `foo.by_ref()` won't.\n+    /// `true` if the type results from a dereference of a raw pointer.\n+    /// when assembling candidates, we include these steps, but not when\n+    /// picking methods. This so that if we have `foo: *const Foo` and `Foo` has methods\n+    /// `fn by_raw_ptr(self: *const Self)` and `fn by_ref(&self)`, then\n+    /// `foo.by_raw_ptr()` will work and `foo.by_ref()` won't.\n     pub from_unsafe_deref: bool,\n     pub unsize: bool,\n }"}, {"sha": "3d36790c94b8c4bbf9ac37929f2ec0f6841c1647", "filename": "src/librustc/traits/util.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ftraits%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Ftraits%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ftraits%2Futil.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -512,7 +512,7 @@ pub fn impl_trait_ref_and_oblig<'a, 'tcx>(\n     (impl_trait_ref, impl_obligations)\n }\n \n-/// See `super::obligations_for_generics`\n+/// See [`super::obligations_for_generics`].\n pub fn predicates_for_generics<'tcx>(cause: ObligationCause<'tcx>,\n                                      recursion_depth: usize,\n                                      param_env: ty::ParamEnv<'tcx>,\n@@ -562,7 +562,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         predicate_for_trait_ref(cause, param_env, trait_ref, recursion_depth)\n     }\n \n-    /// Cast a trait reference into a reference to one of its super\n+    /// Casts a trait reference into a reference to one of its super\n     /// traits; returns `None` if `target_trait_def_id` is not a\n     /// supertrait.\n     pub fn upcast_choices(self,\n@@ -571,7 +571,7 @@ impl<'tcx> TyCtxt<'tcx> {\n                           -> Vec<ty::PolyTraitRef<'tcx>>\n     {\n         if source_trait_ref.def_id() == target_trait_def_id {\n-            return vec![source_trait_ref]; // shorcut the most common case\n+            return vec![source_trait_ref]; // Shortcut the most common case.\n         }\n \n         supertraits(self, source_trait_ref)"}, {"sha": "1aa21501129c8ab41718b6fc465f05c292ddc627", "filename": "src/librustc/ty/codec.rs", "status": "modified", "additions": 13, "deletions": 8, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fcodec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fcodec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcodec.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -284,9 +284,11 @@ where\n #[macro_export]\n macro_rules! __impl_decoder_methods {\n     ($($name:ident -> $ty:ty;)*) => {\n-        $(fn $name(&mut self) -> Result<$ty, Self::Error> {\n-            self.opaque.$name()\n-        })*\n+        $(\n+            fn $name(&mut self) -> Result<$ty, Self::Error> {\n+                self.opaque.$name()\n+            }\n+        )*\n     }\n }\n \n@@ -327,14 +329,17 @@ macro_rules! impl_arena_allocatable_decoders {\n macro_rules! implement_ty_decoder {\n     ($DecoderName:ident <$($typaram:tt),*>) => {\n         mod __ty_decoder_impl {\n-            use super::$DecoderName;\n+            use std::borrow::Cow;\n+\n+            use rustc_serialize::{Decoder, SpecializedDecoder};\n+\n             use $crate::infer::canonical::CanonicalVarInfos;\n             use $crate::ty;\n             use $crate::ty::codec::*;\n             use $crate::ty::subst::SubstsRef;\n             use $crate::hir::def_id::{CrateNum};\n-            use rustc_serialize::{Decoder, SpecializedDecoder};\n-            use std::borrow::Cow;\n+\n+            use super::$DecoderName;\n \n             impl<$($typaram ),*> Decoder for $DecoderName<$($typaram),*> {\n                 type Error = String;\n@@ -368,8 +373,8 @@ macro_rules! implement_ty_decoder {\n                 }\n             }\n \n-            // FIXME(#36588) These impls are horribly unsound as they allow\n-            // the caller to pick any lifetime for 'tcx, including 'static,\n+            // FIXME(#36588): These impls are horribly unsound as they allow\n+            // the caller to pick any lifetime for `'tcx`, including `'static`,\n             // by using the unspecialized proxies to them.\n \n             arena_types!(impl_arena_allocatable_decoders, [$DecoderName [$($typaram),*]], 'tcx);"}, {"sha": "8e8472a5aacc9b54966345befd0fc459e3455479", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 78, "deletions": 85, "changes": 163, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -7,7 +7,7 @@ use crate::session::Session;\n use crate::session::config::{BorrowckMode, OutputFilenames};\n use crate::session::config::CrateType;\n use crate::middle;\n-use crate::hir::{TraitCandidate, HirId, ItemKind, ItemLocalId, Node};\n+use crate::hir::{self, TraitCandidate, HirId, ItemKind, ItemLocalId, Node};\n use crate::hir::def::{Res, DefKind, Export};\n use crate::hir::def_id::{CrateNum, DefId, DefIndex, LOCAL_CRATE};\n use crate::hir::map as hir_map;\n@@ -45,15 +45,16 @@ use crate::ty::CanonicalPolyFnSig;\n use crate::util::common::ErrorReported;\n use crate::util::nodemap::{DefIdMap, DefIdSet, ItemLocalMap, ItemLocalSet};\n use crate::util::nodemap::{FxHashMap, FxHashSet};\n+\n use errors::DiagnosticBuilder;\n-use smallvec::SmallVec;\n-use rustc_data_structures::stable_hasher::{HashStable, hash_stable_hashmap,\n-                                           StableHasher, StableHasherResult,\n-                                           StableVec};\n use arena::SyncDroplessArena;\n+use smallvec::SmallVec;\n+use rustc_data_structures::stable_hasher::{\n+    HashStable, StableHasher, StableHasherResult, StableVec, hash_stable_hashmap,\n+};\n use rustc_data_structures::indexed_vec::{Idx, IndexVec};\n-use rustc_data_structures::sync::{Lrc, Lock, WorkerLocal};\n use rustc_data_structures::sharded::ShardedHashMap;\n+use rustc_data_structures::sync::{Lrc, Lock, WorkerLocal};\n use std::any::Any;\n use std::borrow::Borrow;\n use std::cmp::Ordering;\n@@ -74,8 +75,6 @@ use syntax::feature_gate;\n use syntax::symbol::{Symbol, InternedString, kw, sym};\n use syntax_pos::Span;\n \n-use crate::hir;\n-\n pub struct AllArenas {\n     pub interner: SyncDroplessArena,\n }\n@@ -91,10 +90,10 @@ impl AllArenas {\n type InternedSet<'tcx, T> = ShardedHashMap<Interned<'tcx, T>, ()>;\n \n pub struct CtxtInterners<'tcx> {\n-    /// The arena that types, regions, etc are allocated from\n+    /// The arena that types, regions, etc. are allocated from.\n     arena: &'tcx SyncDroplessArena,\n \n-    /// Specifically use a speedy hash algorithm for these hash sets,\n+    /// Specifically use a speedy hash algorithm for these hash sets, since\n     /// they're accessed quite often.\n     type_: InternedSet<'tcx, TyS<'tcx>>,\n     type_list: InternedSet<'tcx, List<Ty<'tcx>>>,\n@@ -129,7 +128,7 @@ impl<'tcx> CtxtInterners<'tcx> {\n         }\n     }\n \n-    /// Intern a type\n+    /// Interns a type.\n     #[allow(rustc::usage_of_ty_tykind)]\n     #[inline(never)]\n     fn intern_ty(&self,\n@@ -144,7 +143,6 @@ impl<'tcx> CtxtInterners<'tcx> {\n                 outer_exclusive_binder: flags.outer_exclusive_binder,\n             };\n \n-\n             Interned(self.arena.alloc(ty_struct))\n         }).0\n     }\n@@ -1025,7 +1023,7 @@ pub struct GlobalCtxt<'tcx> {\n \n     hir_map: hir_map::Map<'tcx>,\n \n-    /// A map from DefPathHash -> DefId. Includes DefIds from the local crate\n+    /// A map from `DefPathHash` -> `DefId`. Includes `DefId`s from the local crate\n     /// as well as all upstream crates. Only populated in incremental mode.\n     pub def_path_hash_to_def_id: Option<FxHashMap<DefPathHash, DefId>>,\n \n@@ -1124,9 +1122,9 @@ impl<'tcx> TyCtxt<'tcx> {\n         })\n     }\n \n-    /// Allocates a byte or string literal for `mir::interpret`, read-only\n+    /// Allocates a read-only byte or string literal for `mir::interpret`.\n     pub fn allocate_bytes(self, bytes: &[u8]) -> interpret::AllocId {\n-        // create an allocation that just contains these bytes\n+        // Create an allocation that just contains these bytes.\n         let alloc = interpret::Allocation::from_byte_aligned_bytes(bytes);\n         let alloc = self.intern_const_alloc(alloc);\n         self.alloc_map.lock().create_memory_alloc(alloc)\n@@ -1346,7 +1344,7 @@ impl<'tcx> TyCtxt<'tcx> {\n     }\n \n     /// Converts a `DefId` into its fully expanded `DefPath` (every\n-    /// `DefId` is really just an interned def-path).\n+    /// `DefId` is really just an interned `DefPath`).\n     ///\n     /// Note that if `id` is not local to this crate, the result will\n     ///  be a non-local `DefPath`.\n@@ -1402,6 +1400,10 @@ impl<'tcx> TyCtxt<'tcx> {\n         self.cstore.metadata_encoding_version().to_vec()\n     }\n \n+    pub fn encode_metadata(self)-> EncodedMetadata {\n+        self.cstore.encode_metadata(self)\n+    }\n+\n     // Note that this is *untracked* and should only be used within the query\n     // system if the result is otherwise tracked through queries\n     pub fn crate_data_as_rc_any(self, cnum: CrateNum) -> Lrc<dyn Any> {\n@@ -1446,25 +1448,25 @@ impl<'tcx> TyCtxt<'tcx> {\n         self.queries.on_disk_cache.serialize(self.global_tcx(), encoder)\n     }\n \n-    /// If true, we should use the AST-based borrowck (we may *also* use\n+    /// If `true`, we should use the AST-based borrowck (we may *also* use\n     /// the MIR-based borrowck).\n     pub fn use_ast_borrowck(self) -> bool {\n         self.borrowck_mode().use_ast()\n     }\n \n-    /// If true, we should use the MIR-based borrow check, but also\n-    /// fall back on the AST borrow check if the MIR-based one errors.\n+    /// If `true`, we should use the MIR-based borrowck, but also\n+    /// fall back on the AST borrowck if the MIR-based one errors.\n     pub fn migrate_borrowck(self) -> bool {\n         self.borrowck_mode().migrate()\n     }\n \n-    /// If true, make MIR codegen for `match` emit a temp that holds a\n+    /// If `true`, make MIR codegen for `match` emit a temp that holds a\n     /// borrow of the input to the match expression.\n     pub fn generate_borrow_of_any_match_input(&self) -> bool {\n         self.emit_read_for_match()\n     }\n \n-    /// If true, make MIR codegen for `match` emit FakeRead\n+    /// If `true`, make MIR codegen for `match` emit FakeRead\n     /// statements (which simulate the maximal effect of executing the\n     /// patterns in a match arm).\n     pub fn emit_read_for_match(&self) -> bool {\n@@ -1517,7 +1519,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         })\n     }\n \n-    // This method returns the DefId and the BoundRegion corresponding to the given region.\n+    // Returns the `DefId` and the `BoundRegion` corresponding to the given region.\n     pub fn is_suitable_region(&self, region: Region<'tcx>) -> Option<FreeRegionInfo> {\n         let (suitable_region_binding_scope, bound_region) = match *region {\n             ty::ReFree(ref free_region) => (free_region.scope, free_region.bound_region),\n@@ -1550,18 +1552,18 @@ impl<'tcx> TyCtxt<'tcx> {\n         &self,\n         scope_def_id: DefId,\n     ) -> Option<Ty<'tcx>> {\n-        // HACK: `type_of_def_id()` will fail on these (#55796), so return None\n+        // HACK: `type_of_def_id()` will fail on these (#55796), so return `None`.\n         let hir_id = self.hir().as_local_hir_id(scope_def_id).unwrap();\n         match self.hir().get(hir_id) {\n             Node::Item(item) => {\n                 match item.node {\n-                    ItemKind::Fn(..) => { /* type_of_def_id() will work */ }\n+                    ItemKind::Fn(..) => { /* `type_of_def_id()` will work */ }\n                     _ => {\n                         return None;\n                     }\n                 }\n             }\n-            _ => { /* type_of_def_id() will work or panic */ }\n+            _ => { /* `type_of_def_id()` will work or panic */ }\n         }\n \n         let ret_ty = self.type_of(scope_def_id);\n@@ -1579,7 +1581,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         }\n     }\n \n-    // Here we check if the bound region is in Impl Item.\n+    // Checks if the bound region is in Impl Item.\n     pub fn is_bound_region_in_impl_item(\n         &self,\n         suitable_region_binding_scope: DefId,\n@@ -1599,23 +1601,15 @@ impl<'tcx> TyCtxt<'tcx> {\n         false\n     }\n \n-    /// Determine whether identifiers in the assembly have strict naming rules.\n+    /// Determines whether identifiers in the assembly have strict naming rules.\n     /// Currently, only NVPTX* targets need it.\n     pub fn has_strict_asm_symbol_naming(&self) -> bool {\n-        self.gcx.sess.target.target.arch.contains(\"nvptx\")\n-    }\n-}\n-\n-impl<'tcx> TyCtxt<'tcx> {\n-    pub fn encode_metadata(self)\n-        -> EncodedMetadata\n-    {\n-        self.cstore.encode_metadata(self)\n+        self.sess.target.target.arch.contains(\"nvptx\")\n     }\n }\n \n impl<'tcx> GlobalCtxt<'tcx> {\n-    /// Call the closure with a local `TyCtxt` using the given arena.\n+    /// Calls the closure with a local `TyCtxt` using the given arena.\n     /// `interners` is a slot passed so we can create a CtxtInterners\n     /// with the same lifetime as `arena`.\n     pub fn enter_local<F, R>(&'tcx self, f: F) -> R\n@@ -1651,7 +1645,7 @@ impl<'tcx> GlobalCtxt<'tcx> {\n /// It would be more efficient if `TypedArena` provided a way to\n /// determine whether the address is in the allocated range.\n ///\n-/// None is returned if the value or one of the components is not part\n+/// `None` is returned if the value or one of the components is not part\n /// of the provided context.\n /// For `Ty`, `None` can be returned if either the type interner doesn't\n /// contain the `TyKind` key or if the address of the interned\n@@ -1662,7 +1656,6 @@ pub trait Lift<'tcx>: fmt::Debug {\n     fn lift_to_tcx(&self, tcx: TyCtxt<'tcx>) -> Option<Self::Lifted>;\n }\n \n-\n macro_rules! nop_lift {\n     ($ty:ty => $lifted:ty) => {\n         impl<'a, 'tcx> Lift<'tcx> for $ty {\n@@ -1709,7 +1702,7 @@ nop_list_lift!{Predicate<'a> => Predicate<'tcx>}\n nop_list_lift!{CanonicalVarInfo => CanonicalVarInfo}\n nop_list_lift!{ProjectionKind => ProjectionKind}\n \n-// this is the impl for `&'a InternalSubsts<'a>`\n+// This is the impl for `&'a InternalSubsts<'a>`.\n nop_list_lift!{Kind<'a> => Kind<'tcx>}\n \n pub mod tls {\n@@ -1732,43 +1725,43 @@ pub mod tls {\n     use rustc_rayon_core as rayon_core;\n \n     /// This is the implicit state of rustc. It contains the current\n-    /// TyCtxt and query. It is updated when creating a local interner or\n-    /// executing a new query. Whenever there's a TyCtxt value available\n-    /// you should also have access to an ImplicitCtxt through the functions\n+    /// `TyCtxt` and query. It is updated when creating a local interner or\n+    /// executing a new query. Whenever there's a `TyCtxt` value available\n+    /// you should also have access to an `ImplicitCtxt` through the functions\n     /// in this module.\n     #[derive(Clone)]\n     pub struct ImplicitCtxt<'a, 'tcx> {\n-        /// The current TyCtxt. Initially created by `enter_global` and updated\n-        /// by `enter_local` with a new local interner\n+        /// The current `TyCtxt`. Initially created by `enter_global` and updated\n+        /// by `enter_local` with a new local interner.\n         pub tcx: TyCtxt<'tcx>,\n \n-        /// The current query job, if any. This is updated by JobOwner::start in\n-        /// ty::query::plumbing when executing a query\n+        /// The current query job, if any. This is updated by `JobOwner::start` in\n+        /// `ty::query::plumbing` when executing a query.\n         pub query: Option<Lrc<query::QueryJob<'tcx>>>,\n \n         /// Where to store diagnostics for the current query job, if any.\n-        /// This is updated by JobOwner::start in ty::query::plumbing when executing a query\n+        /// This is updated by `JobOwner::start` in `ty::query::plumbing` when executing a query.\n         pub diagnostics: Option<&'a Lock<ThinVec<Diagnostic>>>,\n \n         /// Used to prevent layout from recursing too deeply.\n         pub layout_depth: usize,\n \n         /// The current dep graph task. This is used to add dependencies to queries\n-        /// when executing them\n+        /// when executing them.\n         pub task_deps: Option<&'a Lock<TaskDeps>>,\n     }\n \n-    /// Sets Rayon's thread local variable which is preserved for Rayon jobs\n+    /// Sets Rayon's thread-local variable, which is preserved for Rayon jobs\n     /// to `value` during the call to `f`. It is restored to its previous value after.\n-    /// This is used to set the pointer to the new ImplicitCtxt.\n+    /// This is used to set the pointer to the new `ImplicitCtxt`.\n     #[cfg(parallel_compiler)]\n     #[inline]\n     fn set_tlv<F: FnOnce() -> R, R>(value: usize, f: F) -> R {\n         rayon_core::tlv::with(value, f)\n     }\n \n-    /// Gets Rayon's thread local variable which is preserved for Rayon jobs.\n-    /// This is used to get the pointer to the current ImplicitCtxt.\n+    /// Gets Rayon's thread-local variable, which is preserved for Rayon jobs.\n+    /// This is used to get the pointer to the current `ImplicitCtxt`.\n     #[cfg(parallel_compiler)]\n     #[inline]\n     fn get_tlv() -> usize {\n@@ -1777,13 +1770,13 @@ pub mod tls {\n \n     #[cfg(not(parallel_compiler))]\n     thread_local! {\n-        /// A thread local variable which stores a pointer to the current ImplicitCtxt.\n+        /// A thread local variable that stores a pointer to the current `ImplicitCtxt`.\n         static TLV: Cell<usize> = Cell::new(0);\n     }\n \n     /// Sets TLV to `value` during the call to `f`.\n     /// It is restored to its previous value after.\n-    /// This is used to set the pointer to the new ImplicitCtxt.\n+    /// This is used to set the pointer to the new `ImplicitCtxt`.\n     #[cfg(not(parallel_compiler))]\n     #[inline]\n     fn set_tlv<F: FnOnce() -> R, R>(value: usize, f: F) -> R {\n@@ -1793,14 +1786,14 @@ pub mod tls {\n         f()\n     }\n \n-    /// This is used to get the pointer to the current ImplicitCtxt.\n+    /// Gets the pointer to the current `ImplicitCtxt`.\n     #[cfg(not(parallel_compiler))]\n     fn get_tlv() -> usize {\n         TLV.with(|tlv| tlv.get())\n     }\n \n     /// This is a callback from libsyntax as it cannot access the implicit state\n-    /// in librustc otherwise\n+    /// in librustc otherwise.\n     fn span_debug(span: syntax_pos::Span, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         with_opt(|tcx| {\n             if let Some(tcx) = tcx {\n@@ -1825,7 +1818,7 @@ pub mod tls {\n         })\n     }\n \n-    /// Sets up the callbacks from libsyntax on the current thread\n+    /// Sets up the callbacks from libsyntax on the current thread.\n     pub fn with_thread_locals<F, R>(f: F) -> R\n         where F: FnOnce() -> R\n     {\n@@ -1850,7 +1843,7 @@ pub mod tls {\n         })\n     }\n \n-    /// Sets `context` as the new current ImplicitCtxt for the duration of the function `f`\n+    /// Sets `context` as the new current `ImplicitCtxt` for the duration of the function `f`.\n     #[inline]\n     pub fn enter_context<'a, 'tcx, F, R>(context: &ImplicitCtxt<'a, 'tcx>, f: F) -> R\n     where\n@@ -1861,19 +1854,19 @@ pub mod tls {\n         })\n     }\n \n-    /// Enters GlobalCtxt by setting up libsyntax callbacks and\n-    /// creating a initial TyCtxt and ImplicitCtxt.\n-    /// This happens once per rustc session and TyCtxts only exists\n+    /// Enters `GlobalCtxt` by setting up libsyntax callbacks and\n+    /// creating a initial `TyCtxt` and `ImplicitCtxt`.\n+    /// This happens once per rustc session and `TyCtxt`s only exists\n     /// inside the `f` function.\n     pub fn enter_global<'tcx, F, R>(gcx: &'tcx GlobalCtxt<'tcx>, f: F) -> R\n     where\n         F: FnOnce(TyCtxt<'tcx>) -> R,\n     {\n-        // Update GCX_PTR to indicate there's a GlobalCtxt available\n+        // Update `GCX_PTR` to indicate there's a `GlobalCtxt` available.\n         GCX_PTR.with(|lock| {\n             *lock.lock() = gcx as *const _ as usize;\n         });\n-        // Set GCX_PTR back to 0 when we exit\n+        // Set `GCX_PTR` back to 0 when we exit.\n         let _on_drop = OnDrop(move || {\n             GCX_PTR.with(|lock| *lock.lock() = 0);\n         });\n@@ -1894,12 +1887,12 @@ pub mod tls {\n     }\n \n     scoped_thread_local! {\n-        /// Stores a pointer to the GlobalCtxt if one is available.\n-        /// This is used to access the GlobalCtxt in the deadlock handler given to Rayon.\n+        /// Stores a pointer to the `GlobalCtxt` if one is available.\n+        /// This is used to access the `GlobalCtxt` in the deadlock handler given to Rayon.\n         pub static GCX_PTR: Lock<usize>\n     }\n \n-    /// Creates a TyCtxt and ImplicitCtxt based on the GCX_PTR thread local.\n+    /// Creates a `TyCtxt` and `ImplicitCtxt` based on the `GCX_PTR` thread local.\n     /// This is used in the deadlock handler.\n     pub unsafe fn with_global<F, R>(f: F) -> R\n     where\n@@ -1921,7 +1914,7 @@ pub mod tls {\n         enter_context(&icx, |_| f(tcx))\n     }\n \n-    /// Allows access to the current ImplicitCtxt in a closure if one is available\n+    /// Allows access to the current `ImplicitCtxt` in a closure if one is available.\n     #[inline]\n     pub fn with_context_opt<F, R>(f: F) -> R\n     where\n@@ -1931,16 +1924,16 @@ pub mod tls {\n         if context == 0 {\n             f(None)\n         } else {\n-            // We could get a ImplicitCtxt pointer from another thread.\n-            // Ensure that ImplicitCtxt is Sync\n+            // We could get a `ImplicitCtxt` pointer from another thread.\n+            // Ensure that `ImplicitCtxt` is `Sync`.\n             sync::assert_sync::<ImplicitCtxt<'_, '_>>();\n \n             unsafe { f(Some(&*(context as *const ImplicitCtxt<'_, '_>))) }\n         }\n     }\n \n-    /// Allows access to the current ImplicitCtxt.\n-    /// Panics if there is no ImplicitCtxt available\n+    /// Allows access to the current `ImplicitCtxt`.\n+    /// Panics if there is no `ImplicitCtxt` available.\n     #[inline]\n     pub fn with_context<F, R>(f: F) -> R\n     where\n@@ -1949,11 +1942,11 @@ pub mod tls {\n         with_context_opt(|opt_context| f(opt_context.expect(\"no ImplicitCtxt stored in tls\")))\n     }\n \n-    /// Allows access to the current ImplicitCtxt whose tcx field has the same global\n-    /// interner as the tcx argument passed in. This means the closure is given an ImplicitCtxt\n-    /// with the same 'tcx lifetime as the TyCtxt passed in.\n-    /// This will panic if you pass it a TyCtxt which has a different global interner from\n-    /// the current ImplicitCtxt's tcx field.\n+    /// Allows access to the current `ImplicitCtxt` whose tcx field has the same global\n+    /// interner as the tcx argument passed in. This means the closure is given an `ImplicitCtxt`\n+    /// with the same `'tcx` lifetime as the `TyCtxt` passed in.\n+    /// This will panic if you pass it a `TyCtxt` which has a different global interner from\n+    /// the current `ImplicitCtxt`'s `tcx` field.\n     #[inline]\n     pub fn with_related_context<'tcx, F, R>(tcx: TyCtxt<'tcx>, f: F) -> R\n     where\n@@ -1968,8 +1961,8 @@ pub mod tls {\n         })\n     }\n \n-    /// Allows access to the TyCtxt in the current ImplicitCtxt.\n-    /// Panics if there is no ImplicitCtxt available\n+    /// Allows access to the `TyCtxt` in the current `ImplicitCtxt`.\n+    /// Panics if there is no `ImplicitCtxt` available.\n     #[inline]\n     pub fn with<F, R>(f: F) -> R\n     where\n@@ -1978,8 +1971,8 @@ pub mod tls {\n         with_context(|context| f(context.tcx))\n     }\n \n-    /// Allows access to the TyCtxt in the current ImplicitCtxt.\n-    /// The closure is passed None if there is no ImplicitCtxt available\n+    /// Allows access to the `TyCtxt` in the current `ImplicitCtxt`.\n+    /// The closure is passed None if there is no `ImplicitCtxt` available.\n     #[inline]\n     pub fn with_opt<F, R>(f: F) -> R\n     where\n@@ -1991,7 +1984,7 @@ pub mod tls {\n \n macro_rules! sty_debug_print {\n     ($ctxt: expr, $($variant: ident),*) => {{\n-        // curious inner module to allow variant names to be used as\n+        // Curious inner module to allow variant names to be used as\n         // variable names.\n         #[allow(non_snake_case)]\n         mod inner {\n@@ -2265,9 +2258,9 @@ slice_interners!(\n     projs: _intern_projs(ProjectionKind)\n );\n \n-// This isn't a perfect fit: CanonicalVarInfo slices are always\n+// This isn't a perfect fit: `CanonicalVarInfo` slices are always\n // allocated in the global arena, so this `intern_method!` macro is\n-// overly general.  But we just return false for the code that checks\n+// overly general. However, we just return `false` for the code that checks\n // whether they belong in the thread-local arena, so no harm done, and\n // seems better than open-coding the rest.\n intern_method! {\n@@ -2366,7 +2359,7 @@ impl<'tcx> TyCtxt<'tcx> {\n \n     #[inline]\n     pub fn mk_adt(self, def: &'tcx AdtDef, substs: SubstsRef<'tcx>) -> Ty<'tcx> {\n-        // take a copy of substs so that we own the vectors inside\n+        // Take a copy of substs so that we own the vectors inside.\n         self.mk_ty(Adt(def, substs))\n     }\n "}, {"sha": "1e08ae45951d1e4db2b17a19b36af95c1009954b", "filename": "src/librustc/ty/fold.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Ffold.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -39,8 +39,8 @@ use std::collections::BTreeMap;\n use std::fmt;\n use crate::util::nodemap::FxHashSet;\n \n-/// The TypeFoldable trait is implemented for every type that can be folded.\n-/// Basically, every type that has a corresponding method in TypeFolder.\n+/// This trait is implemented for every type that can be folded.\n+/// Basically, every type that has a corresponding method in `TypeFolder`.\n ///\n /// To implement this conveniently, use the\n /// `BraceStructTypeFoldableImpl` etc macros found in `macros.rs`."}, {"sha": "63cc60d80aada4e682db73528e837dacac1d313d", "filename": "src/librustc/ty/inhabitedness/def_id_forest.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Finhabitedness%2Fdef_id_forest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Finhabitedness%2Fdef_id_forest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Finhabitedness%2Fdef_id_forest.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -4,20 +4,20 @@ use rustc::hir::CRATE_HIR_ID;\n use crate::ty::context::TyCtxt;\n use crate::ty::{DefId, DefIdTree};\n \n-/// Represents a forest of DefIds closed under the ancestor relation. That is,\n-/// if a DefId representing a module is contained in the forest then all\n-/// DefIds defined in that module or submodules are also implicitly contained\n+/// Represents a forest of `DefId`s closed under the ancestor relation. That is,\n+/// if a `DefId` representing a module is contained in the forest then all\n+/// `DefId`s defined in that module or submodules are also implicitly contained\n /// in the forest.\n ///\n /// This is used to represent a set of modules in which a type is visibly\n /// uninhabited.\n #[derive(Clone)]\n pub struct DefIdForest {\n-    /// The minimal set of DefIds required to represent the whole set.\n-    /// If A and B are DefIds in the DefIdForest, and A is a descendant\n-    /// of B, then only B will be in root_ids.\n-    /// We use a SmallVec here because (for its use for caching inhabitedness)\n-    /// its rare that this will contain even two ids.\n+    /// The minimal set of `DefId`s required to represent the whole set.\n+    /// If A and B are DefIds in the `DefIdForest`, and A is a descendant\n+    /// of B, then only B will be in `root_ids`.\n+    /// We use a `SmallVec` here because (for its use for caching inhabitedness)\n+    /// its rare that this will contain even two IDs.\n     root_ids: SmallVec<[DefId; 1]>,\n }\n \n@@ -37,7 +37,7 @@ impl<'tcx> DefIdForest {\n         DefIdForest::from_id(crate_id)\n     }\n \n-    /// Creates a forest containing a DefId and all its descendants.\n+    /// Creates a forest containing a `DefId` and all its descendants.\n     pub fn from_id(id: DefId) -> DefIdForest {\n         let mut root_ids = SmallVec::new();\n         root_ids.push(id);"}, {"sha": "1a0e3517338773209352e43f4f282800ebc41c2b", "filename": "src/librustc/ty/inhabitedness/mod.rs", "status": "modified", "additions": 18, "deletions": 17, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Finhabitedness%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Finhabitedness%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Finhabitedness%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,16 +1,16 @@\n+pub use self::def_id_forest::DefIdForest;\n+\n use crate::ty::context::TyCtxt;\n use crate::ty::{AdtDef, VariantDef, FieldDef, Ty, TyS};\n use crate::ty::{DefId, SubstsRef};\n use crate::ty::{AdtKind, Visibility};\n use crate::ty::TyKind::*;\n use crate::ty;\n \n-pub use self::def_id_forest::DefIdForest;\n-\n mod def_id_forest;\n \n-// The methods in this module calculate DefIdForests of modules in which a\n-// AdtDef/VariantDef/FieldDef is visibly uninhabited.\n+// The methods in this module calculate `DefIdForest`s of modules in which a\n+// `AdtDef`/`VariantDef`/`FieldDef` is visibly uninhabited.\n //\n // # Example\n // ```rust\n@@ -36,24 +36,25 @@ mod def_id_forest;\n //     y: c::AlsoSecretlyUninhabited,\n // }\n // ```\n-// In this code, the type Foo will only be visibly uninhabited inside the\n-// modules b, c and d. Calling uninhabited_from on Foo or its AdtDef will\n-// return the forest of modules {b, c->d} (represented in a DefIdForest by the\n-// set {b, c})\n+// In this code, the type `Foo` will only be visibly uninhabited inside the\n+// modules `b`, `c` and `d`. Calling `uninhabited_from` on `Foo` or its `AdtDef` will\n+// return the forest of modules {`b`, `c`->`d`} (represented in a `DefIdForest` by the\n+// set {`b`, `c`}).\n //\n-// We need this information for pattern-matching on Foo or types that contain\n-// Foo.\n+// We need this information for pattern-matching on `Foo` or types that contain\n+// `Foo`.\n //\n // # Example\n // ```rust\n // let foo_result: Result<T, Foo> = ... ;\n // let Ok(t) = foo_result;\n // ```\n-// This code should only compile in modules where the uninhabitedness of Foo is\n+// This code should only compile in modules where the uninhabitedness of `Foo` is\n // visible.\n \n impl<'tcx> TyCtxt<'tcx> {\n     /// Checks whether a type is visibly uninhabited from a particular module.\n+    ///\n     /// # Example\n     /// ```rust\n     /// enum Void {}\n@@ -91,7 +92,7 @@ impl<'tcx> TyCtxt<'tcx> {\n     /// visible.\n     pub fn is_ty_uninhabited_from(self, module: DefId, ty: Ty<'tcx>) -> bool {\n         // To check whether this type is uninhabited at all (not just from the\n-        // given node) you could check whether the forest is empty.\n+        // given node), you could check whether the forest is empty.\n         // ```\n         // forest.is_empty()\n         // ```\n@@ -108,7 +109,7 @@ impl<'tcx> TyCtxt<'tcx> {\n }\n \n impl<'tcx> AdtDef {\n-    /// Calculate the forest of DefIds from which this adt is visibly uninhabited.\n+    /// Calculates the forest of `DefId`s from which this ADT is visibly uninhabited.\n     fn uninhabited_from(&self, tcx: TyCtxt<'tcx>, substs: SubstsRef<'tcx>) -> DefIdForest {\n         // Non-exhaustive ADTs from other crates are always considered inhabited.\n         if self.is_variant_list_non_exhaustive() && !self.did.is_local() {\n@@ -122,7 +123,7 @@ impl<'tcx> AdtDef {\n }\n \n impl<'tcx> VariantDef {\n-    /// Calculate the forest of DefIds from which this variant is visibly uninhabited.\n+    /// Calculates the forest of `DefId`s from which this variant is visibly uninhabited.\n     pub fn uninhabited_from(\n         &self,\n         tcx: TyCtxt<'tcx>,\n@@ -148,7 +149,7 @@ impl<'tcx> VariantDef {\n }\n \n impl<'tcx> FieldDef {\n-    /// Calculate the forest of DefIds from which this field is visibly uninhabited.\n+    /// Calculates the forest of `DefId`s from which this field is visibly uninhabited.\n     fn uninhabited_from(\n         &self,\n         tcx: TyCtxt<'tcx>,\n@@ -159,7 +160,7 @@ impl<'tcx> FieldDef {\n             self.ty(tcx, substs).uninhabited_from(tcx)\n         };\n         // FIXME(canndrew): Currently enum fields are (incorrectly) stored with\n-        // Visibility::Invisible so we need to override self.vis if we're\n+        // `Visibility::Invisible` so we need to override `self.vis` if we're\n         // dealing with an enum.\n         if is_enum {\n             data_uninhabitedness()\n@@ -178,7 +179,7 @@ impl<'tcx> FieldDef {\n }\n \n impl<'tcx> TyS<'tcx> {\n-    /// Calculate the forest of DefIds from which this type is visibly uninhabited.\n+    /// Calculates the forest of `DefId`s from which this type is visibly uninhabited.\n     fn uninhabited_from(&self, tcx: TyCtxt<'tcx>) -> DefIdForest {\n         match self.sty {\n             Adt(def, substs) => def.uninhabited_from(tcx, substs),"}, {"sha": "41e4295caeccec00257e5f326c253acc9a6e3904", "filename": "src/librustc/ty/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -590,7 +590,7 @@ impl<'tcx> rustc_serialize::UseSpecializedDecodable for Ty<'tcx> {}\n pub type CanonicalTy<'tcx> = Canonical<'tcx, Ty<'tcx>>;\n \n extern {\n-    /// A dummy type used to force List to by unsized without requiring fat pointers\n+    /// A dummy type used to force `List` to by unsized without requiring fat pointers.\n     type OpaqueListContents;\n }\n "}, {"sha": "50789bf6213b6ffd23d1e8a93e18b0a93e89d46e", "filename": "src/librustc/ty/print/mod.rs", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fprint%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fprint%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fprint%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -27,7 +27,8 @@ pub trait Print<'tcx, P> {\n /// which the associated types allow passing through the methods.\n ///\n /// For pretty-printing/formatting in particular, see `PrettyPrinter`.\n-// FIXME(eddyb) find a better name, this is more general than \"printing\".\n+//\n+// FIXME(eddyb) find a better name; this is more general than \"printing\".\n pub trait Printer<'tcx>: Sized {\n     type Error;\n \n@@ -46,6 +47,7 @@ pub trait Printer<'tcx>: Sized {\n     ) -> Result<Self::Path, Self::Error> {\n         self.default_print_def_path(def_id, substs)\n     }\n+\n     fn print_impl_path(\n         self,\n         impl_def_id: DefId,\n@@ -80,6 +82,7 @@ pub trait Printer<'tcx>: Sized {\n         self,\n         cnum: CrateNum,\n     ) -> Result<Self::Path, Self::Error>;\n+\n     fn path_qualified(\n         self,\n         self_ty: Ty<'tcx>,\n@@ -93,11 +96,13 @@ pub trait Printer<'tcx>: Sized {\n         self_ty: Ty<'tcx>,\n         trait_ref: Option<ty::TraitRef<'tcx>>,\n     ) -> Result<Self::Path, Self::Error>;\n+\n     fn path_append(\n         self,\n         print_prefix: impl FnOnce(Self) -> Result<Self::Path, Self::Error>,\n         disambiguated_data: &DisambiguatedDefPathData,\n     ) -> Result<Self::Path, Self::Error>;\n+\n     fn path_generic_args(\n         self,\n         print_prefix: impl FnOnce(Self) -> Result<Self::Path, Self::Error>,"}, {"sha": "d99580116e4ae30fe0394c12a012a0566c581d39", "filename": "src/librustc/ty/print/pretty.rs", "status": "modified", "additions": 16, "deletions": 12, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fprint%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fprint%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fprint%2Fpretty.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -8,10 +8,11 @@ use crate::ty::{self, DefIdTree, ParamConst, Ty, TyCtxt, TypeFoldable};\n use crate::ty::subst::{Kind, Subst, UnpackedKind};\n use crate::ty::layout::{Integer, IntegerExt, Size};\n use crate::mir::interpret::{ConstValue, sign_extend, Scalar, truncate};\n-use syntax::ast;\n+\n use rustc_apfloat::ieee::{Double, Single};\n use rustc_apfloat::Float;\n use rustc_target::spec::abi::Abi;\n+use syntax::ast;\n use syntax::attr::{SignedInt, UnsignedInt};\n use syntax::symbol::{kw, InternedString};\n \n@@ -194,7 +195,7 @@ pub trait PrettyPrinter<'tcx>:\n         value.skip_binder().print(self)\n     }\n \n-    /// Print comma-separated elements.\n+    /// Prints comma-separated elements.\n     fn comma_sep<T>(mut self, mut elems: impl Iterator<Item = T>) -> Result<Self, Self::Error>\n     where\n         T: Print<'tcx, Self, Output = Self, Error = Self::Error>,\n@@ -209,14 +210,14 @@ pub trait PrettyPrinter<'tcx>:\n         Ok(self)\n     }\n \n-    /// Print `<...>` around what `f` prints.\n+    /// Prints `<...>` around what `f` prints.\n     fn generic_delimiters(\n         self,\n         f: impl FnOnce(Self) -> Result<Self, Self::Error>,\n     ) -> Result<Self, Self::Error>;\n \n-    /// Return `true` if the region should be printed in\n-    /// optional positions, e.g. `&'a T` or `dyn Tr + 'b`.\n+    /// Returns `true` if the region should be printed in\n+    /// optional positions, e.g., `&'a T` or `dyn Tr + 'b`.\n     /// This is typically the case for all non-`'_` regions.\n     fn region_should_not_be_omitted(\n         &self,\n@@ -226,7 +227,7 @@ pub trait PrettyPrinter<'tcx>:\n     // Defaults (should not be overriden):\n \n     /// If possible, this returns a global path resolving to `def_id` that is visible\n-    /// from at least one local module and returns true. If the crate defining `def_id` is\n+    /// from at least one local module, and returns `true`. If the crate defining `def_id` is\n     /// declared with an `extern crate`, the path is guaranteed to use the `extern crate`.\n     fn try_print_visible_def_path(\n         self,\n@@ -267,11 +268,11 @@ pub trait PrettyPrinter<'tcx>:\n             // In local mode, when we encounter a crate other than\n             // LOCAL_CRATE, execution proceeds in one of two ways:\n             //\n-            // 1. for a direct dependency, where user added an\n+            // 1. For a direct dependency, where user added an\n             //    `extern crate` manually, we put the `extern\n             //    crate` as the parent. So you wind up with\n             //    something relative to the current crate.\n-            // 2. for an extern inferred from a path or an indirect crate,\n+            // 2. For an extern inferred from a path or an indirect crate,\n             //    where there is no explicit `extern crate`, we just prepend\n             //    the crate name.\n             match self.tcx().extern_crate(def_id) {\n@@ -304,13 +305,13 @@ pub trait PrettyPrinter<'tcx>:\n         let mut cur_def_key = self.tcx().def_key(def_id);\n         debug!(\"try_print_visible_def_path: cur_def_key={:?}\", cur_def_key);\n \n-        // For a constructor we want the name of its parent rather than <unnamed>.\n+        // For a constructor, we want the name of its parent rather than <unnamed>.\n         match cur_def_key.disambiguated_data.data {\n             DefPathData::Ctor => {\n                 let parent = DefId {\n                     krate: def_id.krate,\n                     index: cur_def_key.parent\n-                        .expect(\"DefPathData::Ctor/VariantData missing a parent\"),\n+                        .expect(\"`DefPathData::Ctor` / `VariantData` missing a parent\"),\n                 };\n \n                 cur_def_key = self.tcx().def_key(parent);\n@@ -630,7 +631,7 @@ pub trait PrettyPrinter<'tcx>:\n                         sep = \", \";\n                     }\n                 } else {\n-                    // cross-crate closure types should only be\n+                    // Cross-crate closure types should only be\n                     // visible in codegen bug reports, I imagine.\n                     p!(write(\"@{:?}\", did));\n                     let mut sep = \" \";\n@@ -673,7 +674,7 @@ pub trait PrettyPrinter<'tcx>:\n                         sep = \", \";\n                     }\n                 } else {\n-                    // cross-crate closure types should only be\n+                    // Cross-crate closure types should only be\n                     // visible in codegen bug reports, I imagine.\n                     p!(write(\"@{:?}\", did));\n                     let mut sep = \" \";\n@@ -1173,6 +1174,7 @@ impl<F: fmt::Write> Printer<'tcx> for FmtPrinter<'_, 'tcx, F> {\n         }\n         Ok(self)\n     }\n+\n     fn path_qualified(\n         mut self,\n         self_ty: Ty<'tcx>,\n@@ -1201,6 +1203,7 @@ impl<F: fmt::Write> Printer<'tcx> for FmtPrinter<'_, 'tcx, F> {\n         self.empty_path = false;\n         Ok(self)\n     }\n+\n     fn path_append(\n         mut self,\n         print_prefix: impl FnOnce(Self) -> Result<Self::Path, Self::Error>,\n@@ -1238,6 +1241,7 @@ impl<F: fmt::Write> Printer<'tcx> for FmtPrinter<'_, 'tcx, F> {\n \n         Ok(self)\n     }\n+\n     fn path_generic_args(\n         mut self,\n         print_prefix: impl FnOnce(Self) -> Result<Self::Path, Self::Error>,"}, {"sha": "4cef6a09925addb6b3365440cd48e59245c6595f", "filename": "src/librustc/ty/query/on_disk_cache.rs", "status": "modified", "additions": 104, "deletions": 107, "changes": 211, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -5,9 +5,6 @@ use crate::hir::map::definitions::DefPathHash;\n use crate::ich::{CachingSourceMapView, Fingerprint};\n use crate::mir::{self, interpret};\n use crate::mir::interpret::{AllocDecodingSession, AllocDecodingState};\n-use rustc_serialize::{Decodable, Decoder, Encodable, Encoder, opaque,\n-                      SpecializedDecoder, SpecializedEncoder,\n-                      UseSpecializedDecodable, UseSpecializedEncodable};\n use crate::session::{CrateDisambiguator, Session};\n use crate::ty::{self, Ty};\n use crate::ty::codec::{self as ty_codec, TyDecoder, TyEncoder};\n@@ -19,6 +16,10 @@ use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::thin_vec::ThinVec;\n use rustc_data_structures::sync::{Lrc, Lock, HashMapExt, Once};\n use rustc_data_structures::indexed_vec::{IndexVec, Idx};\n+use rustc_serialize::{\n+    Decodable, Decoder, Encodable, Encoder, SpecializedDecoder, SpecializedEncoder,\n+    UseSpecializedDecodable, UseSpecializedEncodable, opaque,\n+};\n use std::mem;\n use syntax::ast::{Ident, NodeId};\n use syntax::source_map::{SourceMap, StableSourceFileId};\n@@ -37,17 +38,16 @@ const TAG_EXPN_DATA_INLINE: u8 = 2;\n const TAG_VALID_SPAN: u8 = 0;\n const TAG_INVALID_SPAN: u8 = 1;\n \n-/// `OnDiskCache` provides an interface to incr. comp. data cached from the\n+/// Provides an interface to incremental compilation data cached from the\n /// previous compilation session. This data will eventually include the results\n /// of a few selected queries (like `typeck_tables_of` and `mir_optimized`) and\n /// any diagnostics that have been emitted during a query.\n pub struct OnDiskCache<'sess> {\n-\n     // The complete cache data in serialized form.\n     serialized_data: Vec<u8>,\n \n-    // This field collects all Diagnostics emitted during the current\n-    // compilation session.\n+    // Collects all `Diagnostic`s emitted during the current compilation\n+    // session.\n     current_diagnostics: Lock<FxHashMap<DepNodeIndex, Vec<Diagnostic>>>,\n \n     prev_cnums: Vec<(u32, String, CrateDisambiguator)>,\n@@ -56,7 +56,7 @@ pub struct OnDiskCache<'sess> {\n     source_map: &'sess SourceMap,\n     file_index_to_stable_id: FxHashMap<SourceFileIndex, StableSourceFileId>,\n \n-    // These two fields caches that are populated lazily during decoding.\n+    // Caches that are populated lazily during decoding.\n     file_index_to_file: Lock<FxHashMap<SourceFileIndex, Lrc<SourceFile>>>,\n     synthetic_syntax_contexts: Lock<FxHashMap<AbsoluteBytePos, SyntaxContext>>,\n \n@@ -78,7 +78,7 @@ struct Footer {\n     prev_cnums: Vec<(u32, String, CrateDisambiguator)>,\n     query_result_index: EncodedQueryResultIndex,\n     diagnostics_index: EncodedQueryResultIndex,\n-    // the location of all allocations\n+    // The location of all allocations.\n     interpret_alloc_index: Vec<u32>,\n }\n \n@@ -104,28 +104,28 @@ impl AbsoluteBytePos {\n }\n \n impl<'sess> OnDiskCache<'sess> {\n-    /// Creates a new OnDiskCache instance from the serialized data in `data`.\n-    pub fn new(sess: &'sess Session, data: Vec<u8>, start_pos: usize) -> OnDiskCache<'sess> {\n+    /// Creates a new `OnDiskCache` instance from the serialized data in `data`.\n+    pub fn new(sess: &'sess Session, data: Vec<u8>, start_pos: usize) -> Self {\n         debug_assert!(sess.opts.incremental.is_some());\n \n-        // Wrapping in a scope so we can borrow `data`\n+        // Wrap in a scope so we can borrow `data`.\n         let footer: Footer = {\n             let mut decoder = opaque::Decoder::new(&data[..], start_pos);\n \n-            // Decode the *position* of the footer which can be found in the\n+            // Decode the *position* of the footer, which can be found in the\n             // last 8 bytes of the file.\n             decoder.set_position(data.len() - IntEncodedWithFixedSize::ENCODED_SIZE);\n-            let query_result_index_pos = IntEncodedWithFixedSize::decode(&mut decoder)\n-                .expect(\"Error while trying to decode query result index position.\")\n+            let footer_pos = IntEncodedWithFixedSize::decode(&mut decoder)\n+                .expect(\"error while trying to decode footer position\")\n                 .0 as usize;\n \n-            // Decoder the file footer which contains all the lookup tables, etc.\n-            decoder.set_position(query_result_index_pos);\n+            // Decode the file footer, which contains all the lookup tables, etc.\n+            decoder.set_position(footer_pos);\n             decode_tagged(&mut decoder, TAG_FILE_FOOTER)\n-                .expect(\"Error while trying to decode query result index position.\")\n+                .expect(\"error while trying to decode footer position\")\n         };\n \n-        OnDiskCache {\n+        Self {\n             serialized_data: data,\n             file_index_to_stable_id: footer.file_index_to_stable_id,\n             file_index_to_file: Default::default(),\n@@ -140,8 +140,8 @@ impl<'sess> OnDiskCache<'sess> {\n         }\n     }\n \n-    pub fn new_empty(source_map: &'sess SourceMap) -> OnDiskCache<'sess> {\n-        OnDiskCache {\n+    pub fn new_empty(source_map: &'sess SourceMap) -> Self {\n+        Self {\n             serialized_data: Vec::new(),\n             file_index_to_stable_id: Default::default(),\n             file_index_to_file: Default::default(),\n@@ -158,11 +158,11 @@ impl<'sess> OnDiskCache<'sess> {\n \n     pub fn serialize<'tcx, E>(&self, tcx: TyCtxt<'tcx>, encoder: &mut E) -> Result<(), E::Error>\n     where\n-        E: ty_codec::TyEncoder,\n+        E: TyEncoder,\n     {\n-        // Serializing the DepGraph should not modify it:\n+        // Serializing the `DepGraph` should not modify it.\n         tcx.dep_graph.with_ignore(|| {\n-            // Allocate SourceFileIndices\n+            // Allocate `SourceFileIndex`es.\n             let (file_to_file_index, file_index_to_stable_id) = {\n                 let files = tcx.sess.source_map().files();\n                 let mut file_to_file_index = FxHashMap::with_capacity_and_hasher(\n@@ -197,7 +197,7 @@ impl<'sess> OnDiskCache<'sess> {\n             // be in memory, so this should be a cheap operation.\n             tcx.dep_graph.exec_cache_promotions(tcx);\n \n-            // Encode query results\n+            // Encode query results.\n             let mut query_result_index = EncodedQueryResultIndex::new();\n \n             time(tcx.sess, \"encode query results\", || {\n@@ -221,29 +221,28 @@ impl<'sess> OnDiskCache<'sess> {\n                 Ok(())\n             })?;\n \n-            // Encode diagnostics\n+            // Encode diagnostics.\n             let diagnostics_index: EncodedDiagnosticsIndex = self.current_diagnostics.borrow()\n                 .iter()\n-                .map(|(dep_node_index, diagnostics)|\n-            {\n-                let pos = AbsoluteBytePos::new(encoder.position());\n-                // Let's make sure we get the expected type here:\n-                let diagnostics: &EncodedDiagnostics = diagnostics;\n-                let dep_node_index = SerializedDepNodeIndex::new(dep_node_index.index());\n-                encoder.encode_tagged(dep_node_index, diagnostics)?;\n-\n-                Ok((dep_node_index, pos))\n-            })\n-            .collect::<Result<_, _>>()?;\n+                .map(|(dep_node_index, diagnostics)| {\n+                    let pos = AbsoluteBytePos::new(encoder.position());\n+                    // Let's make sure we get the expected type here.\n+                    let diagnostics: &EncodedDiagnostics = diagnostics;\n+                    let dep_node_index = SerializedDepNodeIndex::new(dep_node_index.index());\n+                    encoder.encode_tagged(dep_node_index, diagnostics)?;\n+\n+                    Ok((dep_node_index, pos))\n+                })\n+                .collect::<Result<_, _>>()?;\n \n             let interpret_alloc_index = {\n                 let mut interpret_alloc_index = Vec::new();\n                 let mut n = 0;\n                 loop {\n                     let new_n = encoder.interpret_allocs_inverse.len();\n-                    // if we have found new ids, serialize those, too\n+                    // If we have found new IDs, serialize those too.\n                     if n == new_n {\n-                        // otherwise, abort\n+                        // Otherwise, abort.\n                         break;\n                     }\n                     interpret_alloc_index.reserve(new_n - n);\n@@ -263,13 +262,15 @@ impl<'sess> OnDiskCache<'sess> {\n             };\n \n             let sorted_cnums = sorted_cnums_including_local_crate(tcx);\n-            let prev_cnums: Vec<_> = sorted_cnums.iter().map(|&cnum| {\n-                let crate_name = tcx.original_crate_name(cnum).as_str().to_string();\n-                let crate_disambiguator = tcx.crate_disambiguator(cnum);\n-                (cnum.as_u32(), crate_name, crate_disambiguator)\n-            }).collect();\n-\n-            // Encode the file footer\n+            let prev_cnums: Vec<_> = sorted_cnums.iter()\n+                .map(|&cnum| {\n+                    let crate_name = tcx.original_crate_name(cnum).as_str().to_string();\n+                    let crate_disambiguator = tcx.crate_disambiguator(cnum);\n+                    (cnum.as_u32(), crate_name, crate_disambiguator)\n+                })\n+                .collect();\n+\n+            // Encode the file footer.\n             let footer_pos = encoder.position() as u64;\n             encoder.encode_tagged(TAG_FILE_FOOTER, &Footer {\n                 file_index_to_stable_id,\n@@ -371,7 +372,7 @@ impl<'sess> OnDiskCache<'sess> {\n     {\n         let pos = index.get(&dep_node_index).cloned()?;\n \n-        // Initialize the cnum_map using the value from the thread which finishes the closure first\n+        // Initialize `cnum_map` using the value from the thread that finishes the closure first.\n         self.cnum_map.init_nonlocking_same(|| {\n             Self::compute_cnum_map(tcx, &self.prev_cnums[..])\n         });\n@@ -381,25 +382,21 @@ impl<'sess> OnDiskCache<'sess> {\n             opaque: opaque::Decoder::new(&self.serialized_data[..], pos.to_usize()),\n             source_map: self.source_map,\n             cnum_map: self.cnum_map.get(),\n+            synthetic_syntax_contexts: &self.synthetic_syntax_contexts,\n             file_index_to_file: &self.file_index_to_file,\n             file_index_to_stable_id: &self.file_index_to_stable_id,\n-            synthetic_syntax_contexts: &self.synthetic_syntax_contexts,\n             alloc_decoding_session: self.alloc_decoding_state.new_decoding_session(),\n         };\n \n         match decode_tagged(&mut decoder, dep_node_index) {\n-            Ok(value) => {\n-                Some(value)\n-            }\n-            Err(e) => {\n-                bug!(\"Could not decode cached {}: {}\", debug_tag, e)\n-            }\n+            Ok(v) => Some(v),\n+            Err(e) => bug!(\"could not decode cached {}: {}\", debug_tag, e),\n         }\n     }\n \n-    // This function builds mapping from previous-session-CrateNum to\n-    // current-session-CrateNum. There might be CrateNums from the previous\n-    // Session that don't occur in the current one. For these, the mapping\n+    // This function builds mapping from previous-session-`CrateNum` to\n+    // current-session-`CrateNum`. There might be `CrateNum`s from the previous\n+    // `Session` that don't occur in the current one. For these, the mapping\n     // maps to None.\n     fn compute_cnum_map(\n         tcx: TyCtxt<'_>,\n@@ -432,9 +429,9 @@ impl<'sess> OnDiskCache<'sess> {\n \n //- DECODING -------------------------------------------------------------------\n \n-/// A decoder that can read the incr. comp. cache. It is similar to the one\n-/// we use for crate metadata decoding in that it can rebase spans and\n-/// eventually will also handle things that contain `Ty` instances.\n+/// A decoder that can read fro the incr. comp. cache. It is similar to the one\n+/// we use for crate metadata decoding in that it can rebase spans and eventually\n+/// will also handle things that contain `Ty` instances.\n struct CacheDecoder<'a, 'tcx> {\n     tcx: TyCtxt<'tcx>,\n     opaque: opaque::Decoder<'a>,\n@@ -458,7 +455,7 @@ impl<'a, 'tcx> CacheDecoder<'a, 'tcx> {\n         file_index_to_file.borrow_mut().entry(index).or_insert_with(|| {\n             let stable_id = file_index_to_stable_id[&index];\n             source_map.source_file_by_stable_id(stable_id)\n-                .expect(\"Failed to lookup SourceFile in new context.\")\n+                .expect(\"failed to lookup `SourceFile` in new context\")\n         }).clone()\n     }\n }\n@@ -479,7 +476,7 @@ impl<'a, 'tcx> DecoderWithPosition for CacheDecoder<'a, 'tcx> {\n     }\n }\n \n-// Decode something that was encoded with encode_tagged() and verify that the\n+// Decodes something that was encoded with `encode_tagged()` and verify that the\n // tag matches and the correct amount of bytes was read.\n fn decode_tagged<D, T, V>(decoder: &mut D, expected_tag: T) -> Result<V, D::Error>\n where\n@@ -500,7 +497,7 @@ where\n     Ok(value)\n }\n \n-impl<'a, 'tcx> ty_codec::TyDecoder<'tcx> for CacheDecoder<'a, 'tcx> {\n+impl<'a, 'tcx> TyDecoder<'tcx> for CacheDecoder<'a, 'tcx> {\n     #[inline]\n     fn tcx(&self) -> TyCtxt<'tcx> {\n         self.tcx\n@@ -534,7 +531,7 @@ impl<'a, 'tcx> ty_codec::TyDecoder<'tcx> for CacheDecoder<'a, 'tcx> {\n         }\n \n         let ty = or_insert_with(self)?;\n-        // This may overwrite the entry, but it should overwrite with the same value\n+        // This may overwrite the entry, but it should overwrite with the same value.\n         tcx.rcache.borrow_mut().insert_same(cache_key, ty);\n         Ok(ty)\n     }\n@@ -553,7 +550,7 @@ impl<'a, 'tcx> ty_codec::TyDecoder<'tcx> for CacheDecoder<'a, 'tcx> {\n \n     fn map_encoded_cnum_to_current(&self, cnum: CrateNum) -> CrateNum {\n         self.cnum_map[cnum].unwrap_or_else(|| {\n-            bug!(\"Could not find new CrateNum for {:?}\", cnum)\n+            bug!(\"could not find new `CrateNum` for {:?}\", cnum)\n         })\n     }\n }\n@@ -635,25 +632,25 @@ impl<'a, 'tcx> SpecializedDecoder<Ident> for CacheDecoder<'a, 'tcx> {\n }\n \n // This impl makes sure that we get a runtime error when we try decode a\n-// DefIndex that is not contained in a DefId. Such a case would be problematic\n-// because we would not know how to transform the DefIndex to the current\n+// `DefIndex` that is not contained in a `DefId`. Such a case would be problematic\n+// because we would not know how to transform the `DefIndex` to the current\n // context.\n impl<'a, 'tcx> SpecializedDecoder<DefIndex> for CacheDecoder<'a, 'tcx> {\n     fn specialized_decode(&mut self) -> Result<DefIndex, Self::Error> {\n-        bug!(\"Trying to decode DefIndex outside the context of a DefId\")\n+        bug!(\"trying to decode `DefIndex` outside the context of a `DefId`\")\n     }\n }\n \n-// Both the CrateNum and the DefIndex of a DefId can change in between two\n-// compilation sessions. We use the DefPathHash, which is stable across\n-// sessions, to map the old DefId to the new one.\n+// Both the `CrateNum` and the `DefIndex` of a `DefId` can change in between two\n+// compilation sessions. We use the `DefPathHash`, which is stable across\n+// sessions, to map the old DefId`` to the new one.\n impl<'a, 'tcx> SpecializedDecoder<DefId> for CacheDecoder<'a, 'tcx> {\n     #[inline]\n     fn specialized_decode(&mut self) -> Result<DefId, Self::Error> {\n-        // Load the DefPathHash which is was we encoded the DefId as.\n+        // Load the `DefPathHash` which is was we encoded the `DefId` as.\n         let def_path_hash = DefPathHash::decode(self)?;\n \n-        // Using the DefPathHash, we can lookup the new DefId\n+        // Using the `DefPathHash`, we can lookup the new `DefId`.\n         Ok(self.tcx().def_path_hash_to_def_id.as_ref().unwrap()[&def_path_hash])\n     }\n }\n@@ -667,21 +664,21 @@ impl<'a, 'tcx> SpecializedDecoder<LocalDefId> for CacheDecoder<'a, 'tcx> {\n \n impl<'a, 'tcx> SpecializedDecoder<hir::HirId> for CacheDecoder<'a, 'tcx> {\n     fn specialized_decode(&mut self) -> Result<hir::HirId, Self::Error> {\n-        // Load the DefPathHash which is was we encoded the DefIndex as.\n+        // Load the `DefPathHash` which is what we encoded the `DefIndex` as.\n         let def_path_hash = DefPathHash::decode(self)?;\n \n-        // Use the DefPathHash to map to the current DefId.\n+        // Use the `DefPathHash` to map to the current `DefId`.\n         let def_id = self.tcx()\n                          .def_path_hash_to_def_id\n                          .as_ref()\n                          .unwrap()[&def_path_hash];\n \n         debug_assert!(def_id.is_local());\n \n-        // The ItemLocalId needs no remapping.\n+        // The `ItemLocalId` needs no remapping.\n         let local_id = hir::ItemLocalId::decode(self)?;\n \n-        // Reconstruct the HirId and look up the corresponding NodeId in the\n+        // Reconstruct the `HirId` and look up the corresponding `NodeId` in the\n         // context of the current session.\n         Ok(hir::HirId {\n             owner: def_id.index,\n@@ -690,8 +687,8 @@ impl<'a, 'tcx> SpecializedDecoder<hir::HirId> for CacheDecoder<'a, 'tcx> {\n     }\n }\n \n-// NodeIds are not stable across compilation sessions, so we store them in their\n-// HirId representation. This allows use to map them to the current NodeId.\n+// `NodeId`s are not stable across compilation sessions, so we store them in their\n+// `HirId` representation. This allows use to map them to the current `NodeId`.\n impl<'a, 'tcx> SpecializedDecoder<NodeId> for CacheDecoder<'a, 'tcx> {\n     #[inline]\n     fn specialized_decode(&mut self) -> Result<NodeId, Self::Error> {\n@@ -728,6 +725,7 @@ impl<'a, 'tcx, T: Decodable> SpecializedDecoder<mir::ClearCrossCrate<T>>\n \n //- ENCODING -------------------------------------------------------------------\n \n+/// An encoder that can write the incr. comp. cache.\n struct CacheEncoder<'a, 'tcx, E: ty_codec::TyEncoder> {\n     tcx: TyCtxt<'tcx>,\n     encoder: &'a mut E,\n@@ -742,7 +740,7 @@ struct CacheEncoder<'a, 'tcx, E: ty_codec::TyEncoder> {\n \n impl<'a, 'tcx, E> CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     fn source_file_index(&mut self, source_file: Lrc<SourceFile>) -> SourceFileIndex {\n         self.file_to_file_index[&(&*source_file as *const SourceFile)]\n@@ -753,11 +751,11 @@ where\n     /// encode the specified tag, then the given value, then the number of\n     /// bytes taken up by tag and value. On decoding, we can then verify that\n     /// we get the expected tag and read the expected number of bytes.\n-    fn encode_tagged<T: Encodable, V: Encodable>(&mut self,\n-                                                 tag: T,\n-                                                 value: &V)\n-                                                 -> Result<(), E::Error>\n-    {\n+    fn encode_tagged<T: Encodable, V: Encodable>(\n+        &mut self,\n+        tag: T,\n+        value: &V\n+    ) -> Result<(), E::Error> {\n         let start_pos = self.position();\n \n         tag.encode(self)?;\n@@ -770,7 +768,7 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<interpret::AllocId> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     fn specialized_encode(&mut self, alloc_id: &interpret::AllocId) -> Result<(), Self::Error> {\n         use std::collections::hash_map::Entry;\n@@ -790,10 +788,9 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<Span> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     fn specialized_encode(&mut self, span: &Span) -> Result<(), Self::Error> {\n-\n         if *span == DUMMY_SP {\n             return TAG_INVALID_SPAN.encode(self);\n         }\n@@ -849,14 +846,14 @@ where\n         // We don't currently encode enough information to ensure hygiene works\n         // with incremental, so panic rather than risk incremental bugs.\n \n-        // FIXME: Handle hygiene in incremental\n-        bug!(\"Trying to encode Ident for incremental\")\n+        // FIXME: handle hygiene in incremental.\n+        bug!(\"trying to encode `Ident` for incremental\");\n     }\n }\n \n impl<'a, 'tcx, E> ty_codec::TyEncoder for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     #[inline]\n     fn position(&self) -> usize {\n@@ -866,7 +863,7 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<CrateNum> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     #[inline]\n     fn specialized_encode(&mut self, cnum: &CrateNum) -> Result<(), Self::Error> {\n@@ -876,7 +873,7 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<Ty<'tcx>> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     #[inline]\n     fn specialized_encode(&mut self, ty: &Ty<'tcx>) -> Result<(), Self::Error> {\n@@ -887,7 +884,7 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<ty::GenericPredicates<'tcx>> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     #[inline]\n     fn specialized_encode(&mut self,\n@@ -900,7 +897,7 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<hir::HirId> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     #[inline]\n     fn specialized_encode(&mut self, id: &hir::HirId) -> Result<(), Self::Error> {\n@@ -918,7 +915,7 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<DefId> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     #[inline]\n     fn specialized_encode(&mut self, id: &DefId) -> Result<(), Self::Error> {\n@@ -929,7 +926,7 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<LocalDefId> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     #[inline]\n     fn specialized_encode(&mut self, id: &LocalDefId) -> Result<(), Self::Error> {\n@@ -939,18 +936,18 @@ where\n \n impl<'a, 'tcx, E> SpecializedEncoder<DefIndex> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     fn specialized_encode(&mut self, _: &DefIndex) -> Result<(), Self::Error> {\n-        bug!(\"Encoding DefIndex without context.\")\n+        bug!(\"encoding `DefIndex` without context\");\n     }\n }\n \n-// NodeIds are not stable across compilation sessions, so we store them in their\n-// HirId representation. This allows use to map them to the current NodeId.\n+// `NodeId`s are not stable across compilation sessions, so we store them in their\n+// `HirId` representation. This allows use to map them to the current `NodeId`.\n impl<'a, 'tcx, E> SpecializedEncoder<NodeId> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     #[inline]\n     fn specialized_encode(&mut self, node_id: &NodeId) -> Result<(), Self::Error> {\n@@ -967,7 +964,7 @@ impl<'a, 'tcx> SpecializedEncoder<Fingerprint> for CacheEncoder<'a, 'tcx, opaque\n \n impl<'a, 'tcx, E, T> SpecializedEncoder<mir::ClearCrossCrate<T>> for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n     T: Encodable,\n {\n     #[inline]\n@@ -996,7 +993,7 @@ macro_rules! encoder_methods {\n \n impl<'a, 'tcx, E> Encoder for CacheEncoder<'a, 'tcx, E>\n where\n-    E: 'a + ty_codec::TyEncoder,\n+    E: 'a + TyEncoder,\n {\n     type Error = E::Error;\n \n@@ -1040,7 +1037,7 @@ impl UseSpecializedDecodable for IntEncodedWithFixedSize {}\n impl SpecializedEncoder<IntEncodedWithFixedSize> for opaque::Encoder {\n     fn specialized_encode(&mut self, x: &IntEncodedWithFixedSize) -> Result<(), Self::Error> {\n         let start_pos = self.position();\n-        for i in 0 .. IntEncodedWithFixedSize::ENCODED_SIZE {\n+        for i in 0..IntEncodedWithFixedSize::ENCODED_SIZE {\n             ((x.0 >> i * 8) as u8).encode(self)?;\n         }\n         let end_pos = self.position();\n@@ -1085,10 +1082,10 @@ where\n             if Q::cache_on_disk(tcx, key.clone(), Some(&entry.value)) {\n                 let dep_node = SerializedDepNodeIndex::new(entry.index.index());\n \n-                // Record position of the cache entry\n+                // Record position of the cache entry.\n                 query_result_index.push((dep_node, AbsoluteBytePos::new(encoder.position())));\n \n-                // Encode the type check tables with the SerializedDepNodeIndex\n+                // Encode the type check tables with the `SerializedDepNodeIndex`\n                 // as tag.\n                 encoder.encode_tagged(dep_node, &entry.value)?;\n             }"}, {"sha": "d199a26475be706b891010fe7100d95ae0aeae40", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 55, "deletions": 51, "changes": 106, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -61,7 +61,7 @@ impl<'tcx, M: QueryConfig<'tcx>> Default for QueryCache<'tcx, M> {\n     }\n }\n \n-// If enabled, send a message to the profile-queries thread\n+// If enabled, sends a message to the profile-queries thread.\n macro_rules! profq_msg {\n     ($tcx:expr, $msg:expr) => {\n         if cfg!(debug_assertions) {\n@@ -72,7 +72,7 @@ macro_rules! profq_msg {\n     }\n }\n \n-// If enabled, format a key using its debug string, which can be\n+// If enabled, formats a key using its debug string, which can be\n // expensive to compute (in terms of time).\n macro_rules! profq_query_msg {\n     ($query:expr, $tcx:expr, $key:expr) => {{\n@@ -98,7 +98,7 @@ pub(super) struct JobOwner<'a, 'tcx, Q: QueryDescription<'tcx>> {\n \n impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n     /// Either gets a `JobOwner` corresponding the query, allowing us to\n-    /// start executing the query, or it returns with the result of the query.\n+    /// start executing the query, or returns with the result of the query.\n     /// If the query is executing elsewhere, this will wait for it.\n     /// If the query panicked, this will silently panic.\n     ///\n@@ -215,38 +215,38 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> Drop for JobOwner<'a, 'tcx, Q> {\n     #[inline(never)]\n     #[cold]\n     fn drop(&mut self) {\n-        // Poison the query so jobs waiting on it panic\n+        // Poison the query so jobs waiting on it panic.\n         let shard = self.cache.get_shard_by_value(&self.key);\n         shard.lock().active.insert(self.key.clone(), QueryResult::Poisoned);\n         // Also signal the completion of the job, so waiters\n-        // will continue execution\n+        // will continue execution.\n         self.job.signal_complete();\n     }\n }\n \n #[derive(Clone)]\n pub struct CycleError<'tcx> {\n-    /// The query and related span which uses the cycle\n+    /// The query and related span that uses the cycle.\n     pub(super) usage: Option<(Span, Query<'tcx>)>,\n     pub(super) cycle: Vec<QueryInfo<'tcx>>,\n }\n \n-/// The result of `try_get_lock`\n+/// The result of `try_get_lock`.\n pub(super) enum TryGetJob<'a, 'tcx, D: QueryDescription<'tcx>> {\n     /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n     NotYetStarted(JobOwner<'a, 'tcx, D>),\n \n     /// The query was already completed.\n-    /// Returns the result of the query and its dep node index\n-    /// if it succeeded or a cycle error if it failed\n+    /// Returns the result of the query and its dep-node index\n+    /// if it succeeded or a cycle error if it failed.\n     JobCompleted((D::Value, DepNodeIndex)),\n \n     /// Trying to execute the query resulted in a cycle.\n     Cycle(D::Value),\n }\n \n impl<'tcx> TyCtxt<'tcx> {\n-    /// Executes a job by changing the ImplicitCtxt to point to the\n+    /// Executes a job by changing the `ImplicitCtxt` to point to the\n     /// new query job while it executes. It returns the diagnostics\n     /// captured during execution and the actual result.\n     #[inline(always)]\n@@ -259,11 +259,11 @@ impl<'tcx> TyCtxt<'tcx> {\n     where\n         F: FnOnce(TyCtxt<'tcx>) -> R,\n     {\n-        // The TyCtxt stored in TLS has the same global interner lifetime\n+        // The `TyCtxt` stored in TLS has the same global interner lifetime\n         // as `self`, so we use `with_related_context` to relate the 'tcx lifetimes\n-        // when accessing the ImplicitCtxt\n+        // when accessing the `ImplicitCtxt`.\n         tls::with_related_context(self, move |current_icx| {\n-            // Update the ImplicitCtxt to point to our new query job\n+            // Update the `ImplicitCtxt` to point to our new query job.\n             let new_icx = tls::ImplicitCtxt {\n                 tcx: self.global_tcx(),\n                 query: Some(job),\n@@ -272,7 +272,7 @@ impl<'tcx> TyCtxt<'tcx> {\n                 task_deps: current_icx.task_deps,\n             };\n \n-            // Use the ImplicitCtxt while we execute the query\n+            // Use the `ImplicitCtxt` while we execute the query.\n             tls::enter_context(&new_icx, |_| {\n                 compute(self.global_tcx())\n             })\n@@ -372,7 +372,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         };\n \n         // Fast path for when incr. comp. is off. `to_dep_node` is\n-        // expensive for some DepKinds.\n+        // expensive for some `DepKind`s.\n         if !self.dep_graph.is_fully_enabled() {\n             let null_dep_node = DepNode::new_no_params(crate::dep_graph::DepKind::Null);\n             return self.force_query_with_job::<Q>(key, job, null_dep_node).0;\n@@ -410,7 +410,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         if !Q::EVAL_ALWAYS {\n             // The diagnostics for this query will be\n             // promoted to the current session during\n-            // try_mark_green(), so we can ignore them here.\n+            // `try_mark_green()`, so we can ignore them here.\n             let loaded = self.start_query(job.job.clone(), None, |tcx| {\n                 let marked = tcx.dep_graph.try_mark_green_and_read(tcx, &dep_node);\n                 marked.map(|(prev_dep_node_index, dep_node_index)| {\n@@ -441,22 +441,22 @@ impl<'tcx> TyCtxt<'tcx> {\n         dep_node: &DepNode,\n     ) -> Q::Value {\n         // Note this function can be called concurrently from the same query\n-        // We must ensure that this is handled correctly\n+        // We must ensure that this is handled correctly.\n \n         debug_assert!(self.dep_graph.is_green(dep_node));\n \n-        // First we try to load the result from the on-disk cache\n+        // First we try to load the result from the on-disk cache.\n         let result = if Q::cache_on_disk(self.global_tcx(), key.clone(), None) &&\n                         self.sess.opts.debugging_opts.incremental_queries {\n             self.sess.profiler(|p| p.incremental_load_result_start(Q::NAME));\n             let result = Q::try_load_from_disk(self.global_tcx(), prev_dep_node_index);\n             self.sess.profiler(|p| p.incremental_load_result_end(Q::NAME));\n \n             // We always expect to find a cached result for things that\n-            // can be forced from DepNode.\n+            // can be forced from `DepNode`.\n             debug_assert!(!dep_node.kind.can_reconstruct_query_key() ||\n                           result.is_some(),\n-                          \"Missing on-disk cache entry for {:?}\",\n+                          \"missing on-disk cache entry for {:?}\",\n                           dep_node);\n             result\n         } else {\n@@ -475,8 +475,7 @@ impl<'tcx> TyCtxt<'tcx> {\n \n             self.sess.profiler(|p| p.start_query(Q::NAME));\n \n-            // The dep-graph for this computation is already in\n-            // place\n+            // The dep-graph for this computation is already in-place.\n             let result = self.dep_graph.with_ignore(|| {\n                 Q::compute(self, key)\n             });\n@@ -485,7 +484,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             result\n         };\n \n-        // If -Zincremental-verify-ich is specified, re-hash results from\n+        // If `-Zincremental-verify-ich` is specified, re-hash results from\n         // the cache and make sure that they have the expected fingerprint.\n         if unlikely!(self.sess.opts.debugging_opts.incremental_verify_ich) {\n             self.incremental_verify_ich::<Q>(&result, dep_node, dep_node_index);\n@@ -508,10 +507,12 @@ impl<'tcx> TyCtxt<'tcx> {\n     ) {\n         use crate::ich::Fingerprint;\n \n-        assert!(Some(self.dep_graph.fingerprint_of(dep_node_index)) ==\n+        assert!(\n+            Some(self.dep_graph.fingerprint_of(dep_node_index)) ==\n                 self.dep_graph.prev_fingerprint_of(dep_node),\n-                \"Fingerprint for green query instance not loaded \\\n-                    from cache: {:?}\", dep_node);\n+            \"fingerprint for green query instance not loaded from cache: {:?}\",\n+            dep_node,\n+        );\n \n         debug!(\"BEGIN verify_ich({:?})\", dep_node);\n         let mut hcx = self.create_stable_hashing_context();\n@@ -521,8 +522,11 @@ impl<'tcx> TyCtxt<'tcx> {\n \n         let old_hash = self.dep_graph.fingerprint_of(dep_node_index);\n \n-        assert!(new_hash == old_hash, \"Found unstable fingerprints \\\n-            for {:?}\", dep_node);\n+        assert!(\n+            new_hash == old_hash,\n+            \"found unstable fingerprints for {:?}\",\n+            dep_node,\n+        );\n     }\n \n     #[inline(always)]\n@@ -534,11 +538,11 @@ impl<'tcx> TyCtxt<'tcx> {\n     ) -> (Q::Value, DepNodeIndex) {\n         // If the following assertion triggers, it can have two reasons:\n         // 1. Something is wrong with DepNode creation, either here or\n-        //    in DepGraph::try_mark_green()\n-        // 2. Two distinct query keys get mapped to the same DepNode\n-        //    (see for example #48923)\n+        //    in `DepGraph::try_mark_green()`.\n+        // 2. Two distinct query keys get mapped to the same `DepNode`\n+        //    (see for example #48923).\n         assert!(!self.dep_graph.dep_node_exists(&dep_node),\n-                \"Forcing query with already existing DepNode.\\n\\\n+                \"forcing query with already existing `DepNode`\\n\\\n                  - query-key: {:?}\\n\\\n                  - dep-node: {:?}\",\n                 key, dep_node);\n@@ -584,7 +588,7 @@ impl<'tcx> TyCtxt<'tcx> {\n     }\n \n     /// Ensure that either this query has all green inputs or been executed.\n-    /// Executing query::ensure(D) is considered a read of the dep-node D.\n+    /// Executing `query::ensure(D)` is considered a read of the dep-node `D`.\n     ///\n     /// This function is particularly useful when executing passes for their\n     /// side-effects -- e.g., in order to report errors for erroneous programs.\n@@ -899,13 +903,13 @@ macro_rules! define_queries_inner {\n                 }\n             }\n \n-            // FIXME(eddyb) Get more valid Span's on queries.\n+            // FIXME(eddyb) Get more valid `Span`s on queries.\n             pub fn default_span(&self, tcx: TyCtxt<$tcx>, span: Span) -> Span {\n                 if !span.is_dummy() {\n                     return span;\n                 }\n-                // The def_span query is used to calculate default_span,\n-                // so exit to avoid infinite recursion\n+                // The `def_span` query is used to calculate `default_span`,\n+                // so exit to avoid infinite recursion.\n                 if let Query::def_span(..) = *self {\n                     return span\n                 }\n@@ -1116,7 +1120,7 @@ macro_rules! define_provider_struct {\n         impl<$tcx> Default for Providers<$tcx> {\n             fn default() -> Self {\n                 $(fn $name<$tcx>(_: TyCtxt<$tcx>, key: $K) -> $R {\n-                    bug!(\"tcx.{}({:?}) unsupported by its crate\",\n+                    bug!(\"`tcx.{}({:?})` unsupported by its crate\",\n                          stringify!($name), key);\n                 })*\n                 Providers { $($name),* }\n@@ -1128,26 +1132,26 @@ macro_rules! define_provider_struct {\n \n /// The red/green evaluation system will try to mark a specific DepNode in the\n /// dependency graph as green by recursively trying to mark the dependencies of\n-/// that DepNode as green. While doing so, it will sometimes encounter a DepNode\n+/// that `DepNode` as green. While doing so, it will sometimes encounter a `DepNode`\n /// where we don't know if it is red or green and we therefore actually have\n /// to recompute its value in order to find out. Since the only piece of\n-/// information that we have at that point is the DepNode we are trying to\n+/// information that we have at that point is the `DepNode` we are trying to\n /// re-evaluate, we need some way to re-run a query from just that. This is what\n /// `force_from_dep_node()` implements.\n ///\n-/// In the general case, a DepNode consists of a DepKind and an opaque\n+/// In the general case, a `DepNode` consists of a `DepKind` and an opaque\n /// GUID/fingerprint that will uniquely identify the node. This GUID/fingerprint\n /// is usually constructed by computing a stable hash of the query-key that the\n-/// DepNode corresponds to. Consequently, it is not in general possible to go\n+/// `DepNode` corresponds to. Consequently, it is not in general possible to go\n /// back from hash to query-key (since hash functions are not reversible). For\n /// this reason `force_from_dep_node()` is expected to fail from time to time\n-/// because we just cannot find out, from the DepNode alone, what the\n+/// because we just cannot find out, from the `DepNode` alone, what the\n /// corresponding query-key is and therefore cannot re-run the query.\n ///\n /// The system deals with this case letting `try_mark_green` fail which forces\n /// the root query to be re-evaluated.\n ///\n-/// Now, if force_from_dep_node() would always fail, it would be pretty useless.\n+/// Now, if `force_from_dep_node()` would always fail, it would be pretty useless.\n /// Fortunately, we can use some contextual information that will allow us to\n /// reconstruct query-keys for certain kinds of `DepNode`s. In particular, we\n /// enforce by construction that the GUID/fingerprint of certain `DepNode`s is a\n@@ -1171,9 +1175,9 @@ macro_rules! define_provider_struct {\n pub fn force_from_dep_node(tcx: TyCtxt<'_>, dep_node: &DepNode) -> bool {\n     use crate::dep_graph::RecoverKey;\n \n-    // We must avoid ever having to call force_from_dep_node() for a\n-    // DepNode::codegen_unit:\n-    // Since we cannot reconstruct the query key of a DepNode::codegen_unit, we\n+    // We must avoid ever having to call `force_from_dep_node()` for a\n+    // `DepNode::codegen_unit`:\n+    // Since we cannot reconstruct the query key of a `DepNode::codegen_unit`, we\n     // would always end up having to evaluate the first caller of the\n     // `codegen_unit` query that *is* reconstructible. This might very well be\n     // the `compile_codegen_unit` query, thus re-codegenning the whole CGU just\n@@ -1196,7 +1200,7 @@ pub fn force_from_dep_node(tcx: TyCtxt<'_>, dep_node: &DepNode) -> bool {\n             if let Some(def_id) = dep_node.extract_def_id(tcx) {\n                 def_id\n             } else {\n-                // return from the whole function\n+                // Return from the whole function.\n                 return false\n             }\n         }\n@@ -1224,20 +1228,20 @@ pub fn force_from_dep_node(tcx: TyCtxt<'_>, dep_node: &DepNode) -> bool {\n \n     rustc_dep_node_force!([dep_node, tcx]\n         // These are inputs that are expected to be pre-allocated and that\n-        // should therefore always be red or green already\n+        // should therefore always be red or green already.\n         DepKind::AllLocalTraitImpls |\n         DepKind::Krate |\n         DepKind::CrateMetadata |\n         DepKind::HirBody |\n         DepKind::Hir |\n \n-        // This are anonymous nodes\n+        // These are anonymous nodes.\n         DepKind::TraitSelect |\n \n         // We don't have enough information to reconstruct the query key of\n-        // these\n+        // these.\n         DepKind::CompileCodegenUnit => {\n-            bug!(\"force_from_dep_node() - Encountered {:?}\", dep_node)\n+            bug!(\"force_from_dep_node: encountered {:?}\", dep_node)\n         }\n \n         DepKind::Analysis => { force!(analysis, krate!()); }"}, {"sha": "e73a51e6f78e5272eee86659d566340f87a7567d", "filename": "src/librustc/ty/sty.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fsty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc%2Fty%2Fsty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fsty.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -644,7 +644,7 @@ impl<'tcx> Binder<ExistentialPredicate<'tcx>> {\n impl<'tcx> rustc_serialize::UseSpecializedDecodable for &'tcx List<ExistentialPredicate<'tcx>> {}\n \n impl<'tcx> List<ExistentialPredicate<'tcx>> {\n-    /// Returns the \"principal def id\" of this set of existential predicates.\n+    /// Returns the \"principal `DefId`\" of this set of existential predicates.\n     ///\n     /// A Rust trait object type consists (in addition to a lifetime bound)\n     /// of a set of trait bounds, which are separated into any number\n@@ -1052,7 +1052,7 @@ impl<'tcx> PolyGenSig<'tcx> {\n     }\n }\n \n-/// Signature of a function type, which I have arbitrarily\n+/// Signature of a function type, which we have arbitrarily\n /// decided to use to refer to the input/output types.\n ///\n /// - `inputs`: is the list of arguments and their modes.\n@@ -1076,7 +1076,8 @@ impl<'tcx> FnSig<'tcx> {\n         self.inputs_and_output[self.inputs_and_output.len() - 1]\n     }\n \n-    // Create a minimal `FnSig` to be used when encountering a `TyKind::Error` in a fallible method\n+    // Creates a minimal `FnSig` to be used when encountering a `TyKind::Error` in a fallible\n+    // method.\n     fn fake() -> FnSig<'tcx> {\n         FnSig {\n             inputs_and_output: List::empty(),\n@@ -1118,7 +1119,6 @@ impl<'tcx> PolyFnSig<'tcx> {\n \n pub type CanonicalPolyFnSig<'tcx> = Canonical<'tcx, Binder<FnSig<'tcx>>>;\n \n-\n #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord,\n          Hash, RustcEncodable, RustcDecodable, HashStable)]\n pub struct ParamTy {"}, {"sha": "0dc999083a91a93c88ffcf3f0419657ad0ddc408", "filename": "src/librustc_ast_borrowck/cfg/construct.rs", "status": "modified", "additions": 79, "deletions": 67, "changes": 146, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_ast_borrowck%2Fcfg%2Fconstruct.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_ast_borrowck%2Fcfg%2Fconstruct.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast_borrowck%2Fcfg%2Fconstruct.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,11 +1,12 @@\n use crate::cfg::*;\n-use rustc_data_structures::graph::implementation as graph;\n-use rustc::middle::region;\n-use rustc::ty::{self, TyCtxt};\n \n use rustc::hir::{self, PatKind};\n use rustc::hir::def_id::DefId;\n use rustc::hir::ptr::P;\n+use rustc::middle::region;\n+use rustc::ty::{self, TyCtxt};\n+\n+use rustc_data_structures::graph::implementation as graph;\n \n struct CFGBuilder<'a, 'tcx> {\n     tcx: TyCtxt<'tcx>,\n@@ -19,15 +20,15 @@ struct CFGBuilder<'a, 'tcx> {\n \n #[derive(Copy, Clone)]\n struct BlockScope {\n-    block_expr_id: hir::ItemLocalId, // id of breakable block expr node\n+    block_expr_id: hir::ItemLocalId, // ID of breakable block expr node\n     break_index: CFGIndex, // where to go on `break`\n }\n \n #[derive(Copy, Clone)]\n struct LoopScope {\n-    loop_id: hir::ItemLocalId,     // id of loop/while node\n+    loop_id: hir::ItemLocalId, // ID of `loop`/`while` node\n     continue_index: CFGIndex, // where to go on a `loop`\n-    break_index: CFGIndex,    // where to go on a `break`\n+    break_index: CFGIndex, // where to go on a `break`\n }\n \n pub(super) fn construct(tcx: TyCtxt<'_>, body: &hir::Body) -> CFG {\n@@ -103,9 +104,7 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n                 let init_exit = self.opt_expr(&local.init, pred);\n                 self.pat(&local.pat, init_exit)\n             }\n-            hir::StmtKind::Item(_) => {\n-                pred\n-            }\n+            hir::StmtKind::Item(_) => pred,\n             hir::StmtKind::Expr(ref expr) |\n             hir::StmtKind::Semi(ref expr) => {\n                 self.expr(&expr, pred)\n@@ -154,12 +153,12 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n         }\n     }\n \n-    fn pats_all<'b, I: Iterator<Item=&'b P<hir::Pat>>>(\n+    /// Handles case where all of the patterns must match.\n+    fn pats_all<'b, I: Iterator<Item = &'b P<hir::Pat>>>(\n         &mut self,\n         pats: I,\n-        pred: CFGIndex\n+        pred: CFGIndex,\n     ) -> CFGIndex {\n-        //! Handles case where all of the patterns must match.\n         pats.fold(pred, |pred, pat| self.pat(&pat, pred))\n     }\n \n@@ -185,15 +184,15 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n                 // Note that `break` and `loop` statements\n                 // may cause additional edges.\n \n-                let loopback = self.add_dummy_node(&[pred]);              // 1\n-                let expr_exit = self.add_ast_node(expr.hir_id.local_id, &[]);          // 2\n+                let loopback = self.add_dummy_node(&[pred]); // 1\n+                let expr_exit = self.add_ast_node(expr.hir_id.local_id, &[]); // 2\n                 self.loop_scopes.push(LoopScope {\n                     loop_id: expr.hir_id.local_id,\n                     continue_index: loopback,\n                     break_index: expr_exit,\n                 });\n-                let body_exit = self.block(&body, loopback);           // 3\n-                self.add_contained_edge(body_exit, loopback);            // 4\n+                let body_exit = self.block(&body, loopback); // 3\n+                self.add_contained_edge(body_exit, loopback); // 4\n                 self.loop_scopes.pop();\n                 expr_exit\n             }\n@@ -217,9 +216,9 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n                 //    v 3  v 4\n                 //   [..exit..]\n                 //\n-                let l_exit = self.expr(&l, pred);                      // 1\n-                let r_exit = self.expr(&r, l_exit);                    // 2\n-                self.add_ast_node(expr.hir_id.local_id, &[l_exit, r_exit])            // 3,4\n+                let l_exit = self.expr(&l, pred); // 1\n+                let r_exit = self.expr(&r, l_exit); // 2\n+                self.add_ast_node(expr.hir_id.local_id, &[l_exit, r_exit]) // 3,4\n             }\n \n             hir::ExprKind::Ret(ref v) => {\n@@ -313,11 +312,13 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n         }\n     }\n \n-    fn call<'b, I: Iterator<Item=&'b hir::Expr>>(&mut self,\n-            call_expr: &hir::Expr,\n-            pred: CFGIndex,\n-            func_or_rcvr: &hir::Expr,\n-            args: I) -> CFGIndex {\n+    fn call<'b, I: Iterator<Item = &'b hir::Expr>>(\n+        &mut self,\n+        call_expr: &hir::Expr,\n+        pred: CFGIndex,\n+        func_or_rcvr: &hir::Expr,\n+        args: I,\n+    ) -> CFGIndex {\n         let func_or_rcvr_exit = self.expr(func_or_rcvr, pred);\n         let ret = self.straightline(call_expr, func_or_rcvr_exit, args);\n         let m = self.tcx.hir().get_module_parent(call_expr.hir_id);\n@@ -328,33 +329,38 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n         }\n     }\n \n-    fn exprs<'b, I: Iterator<Item=&'b hir::Expr>>(&mut self,\n-                                             exprs: I,\n-                                             pred: CFGIndex) -> CFGIndex {\n-        //! Constructs graph for `exprs` evaluated in order\n+    /// Constructs graph for `exprs` evaluated in order.\n+    fn exprs<'b, I: Iterator<Item = &'b hir::Expr>>(\n+        &mut self,\n+        exprs: I,\n+        pred: CFGIndex,\n+    ) -> CFGIndex {\n         exprs.fold(pred, |p, e| self.expr(e, p))\n     }\n \n-    fn opt_expr(&mut self,\n-                opt_expr: &Option<P<hir::Expr>>,\n-                pred: CFGIndex) -> CFGIndex {\n-        //! Constructs graph for `opt_expr` evaluated, if Some\n+    /// Constructs graph for `opt_expr` evaluated, if `Some`.\n+    fn opt_expr(\n+        &mut self,\n+        opt_expr: &Option<P<hir::Expr>>,\n+        pred: CFGIndex,\n+    ) -> CFGIndex {\n         opt_expr.iter().fold(pred, |p, e| self.expr(&e, p))\n     }\n \n-    fn straightline<'b, I: Iterator<Item=&'b hir::Expr>>(&mut self,\n-                    expr: &hir::Expr,\n-                    pred: CFGIndex,\n-                    subexprs: I) -> CFGIndex {\n-        //! Handles case of an expression that evaluates `subexprs` in order\n-\n+    /// Handles case of an expression that evaluates `subexprs` in order.\n+    fn straightline<'b, I: Iterator<Item = &'b hir::Expr>>(\n+        &mut self,\n+        expr: &hir::Expr,\n+        pred: CFGIndex,\n+        subexprs: I,\n+    ) -> CFGIndex {\n         let subexprs_exit = self.exprs(subexprs, pred);\n         self.add_ast_node(expr.hir_id.local_id, &[subexprs_exit])\n     }\n \n     fn match_(&mut self, id: hir::ItemLocalId, discr: &hir::Expr,\n               arms: &[hir::Arm], pred: CFGIndex) -> CFGIndex {\n-        // The CFG for match expression is quite complex, so no ASCII\n+        // The CFG for match expressions is quite complex, so no ASCII\n         // art for it (yet).\n         //\n         // The CFG generated below matches roughly what MIR contains.\n@@ -369,13 +375,13 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n         //\n         // What is going on is explained in further comments.\n \n-        // Visit the discriminant expression\n+        // Visit the discriminant expression.\n         let discr_exit = self.expr(discr, pred);\n \n         // Add a node for the exit of the match expression as a whole.\n         let expr_exit = self.add_ast_node(id, &[]);\n \n-        // Keep track of the previous guard expressions\n+        // Keep track of the previous guard expressions.\n         let mut prev_guard = None;\n         let match_scope = region::Scope { id, data: region::ScopeData::Node };\n \n@@ -388,12 +394,12 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n                 // Visit the pattern, coming from the discriminant exit\n                 let mut pat_exit = self.pat(&pat, discr_exit);\n \n-                // If there is a guard expression, handle it here\n+                // If there is a guard expression, handle it here.\n                 if let Some(ref guard) = arm.guard {\n                     // Add a dummy node for the previous guard\n-                    // expression to target\n+                    // expression to target.\n                     let guard_start = self.add_dummy_node(&[pat_exit]);\n-                    // Visit the guard expression\n+                    // Visit the guard expression.\n                     let guard_exit = match guard {\n                         hir::Guard::If(ref e) => (&**e, self.expr(e, guard_start)),\n                     };\n@@ -407,24 +413,23 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n                         self.add_exiting_edge(prev_guard, prev_index, match_scope, guard_start);\n                     }\n \n-                    // Push the guard onto the list of previous guards\n+                    // Push the guard onto the list of previous guards.\n                     prev_guard = Some(guard_exit);\n \n-                    // Update the exit node for the pattern\n+                    // Update the exit node for the pattern.\n                     pat_exit = guard_exit.1;\n                 }\n \n-                // Add an edge from the exit of this pattern to the\n-                // exit of the arm\n+                // Add an edge from the exit of this pattern to the exit of the arm.\n                 self.add_contained_edge(pat_exit, bindings_exit);\n             }\n \n-            // Visit the body of this arm\n+            // Visit the body of this arm.\n             let body_exit = self.expr(&arm.body, bindings_exit);\n \n             let arm_exit = self.add_ast_node(arm.hir_id.local_id, &[body_exit]);\n \n-            // Link the body to the exit of the expression\n+            // Link the body to the exit of the expression.\n             self.add_contained_edge(arm_exit, expr_exit);\n         }\n \n@@ -451,18 +456,22 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n         node\n     }\n \n-    fn add_contained_edge(&mut self,\n-                          source: CFGIndex,\n-                          target: CFGIndex) {\n+    fn add_contained_edge(\n+        &mut self,\n+        source: CFGIndex,\n+        target: CFGIndex,\n+    ) {\n         let data = CFGEdgeData {exiting_scopes: vec![] };\n         self.graph.add_edge(source, target, data);\n     }\n \n-    fn add_exiting_edge(&mut self,\n-                        from_expr: &hir::Expr,\n-                        from_index: CFGIndex,\n-                        target_scope: region::Scope,\n-                        to_index: CFGIndex) {\n+    fn add_exiting_edge(\n+        &mut self,\n+        from_expr: &hir::Expr,\n+        from_index: CFGIndex,\n+        target_scope: region::Scope,\n+        to_index: CFGIndex,\n+    ) {\n         let mut data = CFGEdgeData { exiting_scopes: vec![] };\n         let mut scope = region::Scope {\n             id: from_expr.hir_id.local_id,\n@@ -476,9 +485,11 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n         self.graph.add_edge(from_index, to_index, data);\n     }\n \n-    fn add_returning_edge(&mut self,\n-                          _from_expr: &hir::Expr,\n-                          from_index: CFGIndex) {\n+    fn add_returning_edge(\n+        &mut self,\n+        _from_expr: &hir::Expr,\n+        from_index: CFGIndex,\n+    ) {\n         let data = CFGEdgeData {\n             exiting_scopes: self.loop_scopes.iter()\n                                             .rev()\n@@ -488,11 +499,12 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n         self.graph.add_edge(from_index, self.fn_exit, data);\n     }\n \n-    fn find_scope_edge(&self,\n-                  expr: &hir::Expr,\n-                  destination: hir::Destination,\n-                  scope_cf_kind: ScopeCfKind) -> (region::Scope, CFGIndex) {\n-\n+    fn find_scope_edge(\n+        &self,\n+        expr: &hir::Expr,\n+        destination: hir::Destination,\n+        scope_cf_kind: ScopeCfKind,\n+    ) -> (region::Scope, CFGIndex) {\n         match destination.target_id {\n             Ok(loop_id) => {\n                 for b in &self.breakable_block_scopes {\n@@ -519,7 +531,7 @@ impl<'a, 'tcx> CFGBuilder<'a, 'tcx> {\n                         });\n                     }\n                 }\n-                span_bug!(expr.span, \"no scope for id {}\", loop_id);\n+                span_bug!(expr.span, \"no scope for ID {}\", loop_id);\n             }\n             Err(err) => span_bug!(expr.span, \"scope error: {}\",  err),\n         }"}, {"sha": "99c6b49cad5d908f9529d0a5737016a9b8e3a23f", "filename": "src/librustc_ast_borrowck/cfg/graphviz.rs", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_ast_borrowck%2Fcfg%2Fgraphviz.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_ast_borrowck%2Fcfg%2Fgraphviz.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast_borrowck%2Fcfg%2Fgraphviz.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,4 +1,4 @@\n-/// This module provides linkage between rustc::middle::graph and\n+/// This module provides linkage between `rustc::middle::graph` and\n /// libgraphviz traits.\n \n use crate::cfg;\n@@ -12,7 +12,7 @@ pub struct LabelledCFG<'a, 'tcx> {\n     pub tcx: TyCtxt<'tcx>,\n     pub cfg: &'a cfg::CFG,\n     pub name: String,\n-    /// `labelled_edges` controls whether we emit labels on the edges\n+    /// `labelled_edges` controls whether we emit labels on the edges.\n     pub labelled_edges: bool,\n }\n \n@@ -25,12 +25,12 @@ impl<'a, 'tcx> LabelledCFG<'a, 'tcx> {\n         };\n         let s = self.tcx.hir().node_to_string(hir_id);\n \n-        // Replacing newlines with \\\\l causes each line to be left-aligned,\n+        // Replacing newlines with `\\\\l` causes each line to be left-aligned,\n         // improving presentation of (long) pretty-printed expressions.\n         if s.contains(\"\\n\") {\n             let mut s = s.replace(\"\\n\", \"\\\\l\");\n             // Apparently left-alignment applies to the line that precedes\n-            // \\l, not the line that follows; so, add \\l at end of string\n+            // `\\l`, not the line that follows; so, add `\\l` at end of string\n             // if not already present, ensuring last line gets left-aligned\n             // as well.\n             let mut last_two: Vec<_> =\n@@ -109,8 +109,7 @@ impl<'a> dot::GraphWalk<'a> for &'a cfg::CFG {\n     }\n }\n \n-impl<'a, 'hir> dot::GraphWalk<'a> for LabelledCFG<'a, 'hir>\n-{\n+impl<'a, 'hir> dot::GraphWalk<'a> for LabelledCFG<'a, 'hir> {\n     type Node = Node<'a>;\n     type Edge = Edge<'a>;\n     fn nodes(&'a self) -> dot::Nodes<'a, Node<'a>> { self.cfg.nodes() }"}, {"sha": "98efa6a5804bd352d4617912ecdaaf58f099df4a", "filename": "src/librustc_codegen_llvm/Cargo.toml", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_llvm%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_llvm%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2FCargo.toml?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -11,11 +11,7 @@ crate-type = [\"dylib\"]\n test = false\n \n [dependencies]\n-cc = \"1.0.1\" # Used to locate MSVC\n-num_cpus = \"1.0\"\n-tempfile = \"3.0\"\n rustc_llvm = { path = \"../librustc_llvm\" }\n-memmap = \"0.6\"\n \n [features]\n # This is used to convince Cargo to separately cache builds of `rustc_codegen_llvm`"}, {"sha": "042e51ed2ba7a4e95e0f4bacd7e16142947df71c", "filename": "src/librustc_codegen_llvm/error_codes.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_llvm%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_llvm%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,4 +1,4 @@\n-register_long_diagnostics! {\n+register_diagnostics! {\n \n E0511: r##\"\n Invalid monomorphization of an intrinsic function was used. Erroneous code"}, {"sha": "9f2c303145dc8e28eba27d63b60ad603d2fc6cf1", "filename": "src/librustc_codegen_llvm/lib.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_llvm%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_llvm%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -14,7 +14,6 @@\n #![feature(in_band_lifetimes)]\n #![feature(libc)]\n #![feature(nll)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(optin_builtin_traits)]\n #![feature(concat_idents)]\n #![feature(link_args)]\n@@ -256,7 +255,7 @@ impl CodegenBackend for LlvmCodegenBackend {\n     }\n \n     fn diagnostics(&self) -> &[(&'static str, &'static str)] {\n-        &DIAGNOSTICS\n+        &error_codes::DIAGNOSTICS\n     }\n \n     fn target_features(&self, sess: &Session) -> Vec<Symbol> {\n@@ -425,5 +424,3 @@ impl Drop for ModuleLlvm {\n         }\n     }\n }\n-\n-__build_diagnostic_array! { librustc_codegen_llvm, DIAGNOSTICS }"}, {"sha": "8ff41c275a8f45283e387847e7d5861dd3abd94b", "filename": "src/librustc_codegen_ssa/error_codes.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_ssa%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_ssa%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,4 +1,4 @@\n-register_long_diagnostics! {\n+syntax::register_diagnostics! {\n \n E0668: r##\"\n Malformed inline assembly rejected by LLVM."}, {"sha": "90bf964ceaa1302e3494894f0cf3373227fd033d", "filename": "src/librustc_codegen_ssa/lib.rs", "status": "modified", "additions": 0, "deletions": 5, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_ssa%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_ssa%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -4,7 +4,6 @@\n #![feature(box_syntax)]\n #![feature(core_intrinsics)]\n #![feature(libc)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(stmt_expr_attributes)]\n #![feature(try_blocks)]\n #![feature(in_band_lifetimes)]\n@@ -35,8 +34,6 @@ use rustc_data_structures::svh::Svh;\n use rustc::middle::cstore::{LibSource, CrateSource, NativeLibrary};\n use syntax_pos::symbol::Symbol;\n \n-// N.B., this module needs to be declared first so diagnostics are\n-// registered before they are used.\n mod error_codes;\n \n pub mod common;\n@@ -158,5 +155,3 @@ pub struct CodegenResults {\n     pub linker_info: back::linker::LinkerInfo,\n     pub crate_info: CrateInfo,\n }\n-\n-__build_diagnostic_array! { librustc_codegen_ssa, DIAGNOSTICS }"}, {"sha": "1201446afb53128dddbd1b0a52134801ae72d6ff", "filename": "src/librustc_codegen_utils/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_utils%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_codegen_utils%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_utils%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -10,7 +10,6 @@\n #![feature(core_intrinsics)]\n #![feature(never_type)]\n #![feature(nll)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(in_band_lifetimes)]\n \n #![recursion_limit=\"256\"]"}, {"sha": "a839ee56b2b6e9a3cda5ff776d66556abf92dc0a", "filename": "src/librustc_driver/Cargo.toml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_driver%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_driver%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2FCargo.toml?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -12,7 +12,7 @@ crate-type = [\"dylib\"]\n [dependencies]\n graphviz = { path = \"../libgraphviz\" }\n log = \"0.4\"\n-env_logger = { version = \"0.5\", default-features = false }\n+env_logger = { version = \"0.6\", default-features = false }\n rustc = { path = \"../librustc\" }\n rustc_target = { path = \"../librustc_target\" }\n rustc_ast_borrowck = { path = \"../librustc_ast_borrowck\" }"}, {"sha": "a912ea3c358215cae6f9f49788b6bf535579a71b", "filename": "src/librustc_driver/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_driver%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_driver%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -9,7 +9,6 @@\n #![feature(box_syntax)]\n #![cfg_attr(unix, feature(libc))]\n #![feature(nll)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(set_stdio)]\n #![feature(no_debug)]\n #![feature(integer_atomics)]"}, {"sha": "3cfae1686dfdf911761869c25c49b0f7646bacf8", "filename": "src/librustc_interface/passes.rs", "status": "modified", "additions": 1, "deletions": 16, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_interface%2Fpasses.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_interface%2Fpasses.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Fpasses.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -34,7 +34,7 @@ use rustc_privacy;\n use rustc_resolve::{Resolver, ResolverArenas};\n use rustc_traits;\n use rustc_typeck as typeck;\n-use syntax::{self, ast, diagnostics, visit};\n+use syntax::{self, ast, visit};\n use syntax::early_buffered_lints::BufferedEarlyLint;\n use syntax::ext::base::{NamedSyntaxExtension, ExtCtxt};\n use syntax::mut_visit::MutVisitor;\n@@ -283,21 +283,6 @@ pub fn register_plugins<'a>(\n     let mut registry = Registry::new(sess, krate.span);\n \n     time(sess, \"plugin registration\", || {\n-        if sess.features_untracked().rustc_diagnostic_macros {\n-            registry.register_macro(\n-                \"__diagnostic_used\",\n-                diagnostics::plugin::expand_diagnostic_used,\n-            );\n-            registry.register_macro(\n-                \"__register_diagnostic\",\n-                diagnostics::plugin::expand_register_diagnostic,\n-            );\n-            registry.register_macro(\n-                \"__build_diagnostic_array\",\n-                diagnostics::plugin::expand_build_diagnostic_array,\n-            );\n-        }\n-\n         for registrar in registrars {\n             registry.args_hidden = Some(registrar.args);\n             (registrar.fun)(&mut registry);"}, {"sha": "9eaf7b77716f3f0d62c25d3d4e2f6c54839de019", "filename": "src/librustc_interface/util.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_interface%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_interface%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Futil.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -43,17 +43,17 @@ use std::{thread, panic};\n \n pub fn diagnostics_registry() -> Registry {\n     let mut all_errors = Vec::new();\n-    all_errors.extend_from_slice(&rustc::DIAGNOSTICS);\n-    all_errors.extend_from_slice(&rustc_typeck::DIAGNOSTICS);\n-    all_errors.extend_from_slice(&rustc_resolve::DIAGNOSTICS);\n-    all_errors.extend_from_slice(&rustc_privacy::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&rustc::error_codes::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&rustc_typeck::error_codes::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&rustc_resolve::error_codes::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&rustc_privacy::error_codes::DIAGNOSTICS);\n     // FIXME: need to figure out a way to get these back in here\n     // all_errors.extend_from_slice(get_codegen_backend(sess).diagnostics());\n-    all_errors.extend_from_slice(&rustc_metadata::DIAGNOSTICS);\n-    all_errors.extend_from_slice(&rustc_passes::DIAGNOSTICS);\n-    all_errors.extend_from_slice(&rustc_plugin::DIAGNOSTICS);\n-    all_errors.extend_from_slice(&rustc_mir::DIAGNOSTICS);\n-    all_errors.extend_from_slice(&syntax::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&rustc_metadata::error_codes::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&rustc_passes::error_codes::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&rustc_plugin::error_codes::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&rustc_mir::error_codes::DIAGNOSTICS);\n+    all_errors.extend_from_slice(&syntax::error_codes::DIAGNOSTICS);\n \n     Registry::new(&all_errors)\n }"}, {"sha": "ea2e1d9ecc53f46553207c643ec5eed7c560de96", "filename": "src/librustc_lint/error_codes.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_lint%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_lint%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lint%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,5 +1,4 @@\n-use syntax::register_diagnostics;\n-\n-register_diagnostics! {\n+syntax::register_diagnostics! {\n+;\n     E0721, // `await` keyword\n }"}, {"sha": "4ee6551f787818c3dba16abe60de8f368b3b9dbe", "filename": "src/librustc_lint/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_lint%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_lint%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lint%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -15,7 +15,6 @@\n #![feature(box_patterns)]\n #![feature(box_syntax)]\n #![feature(nll)]\n-#![feature(rustc_diagnostic_macros)]\n \n #![recursion_limit=\"256\"]\n "}, {"sha": "cd8e95e6c3a1101786cd08bc55fba6b8bc0c7a37", "filename": "src/librustc_metadata/error_codes.rs", "status": "modified", "additions": 4, "deletions": 8, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_metadata%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_metadata%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,6 +1,4 @@\n-use syntax::{register_diagnostics, register_long_diagnostics};\n-\n-register_long_diagnostics! {\n+syntax::register_diagnostics! {\n E0454: r##\"\n A link name was given with an empty name. Erroneous code example:\n \n@@ -84,10 +82,7 @@ You need to link your code to the relevant crate in order to be able to use it\n (through Cargo or the `-L` option of rustc example). Plugins are crates as\n well, and you link to them the same way.\n \"##,\n-\n-}\n-\n-register_diagnostics! {\n+;\n     E0456, // plugin `..` is not available for triple `..`\n     E0457, // plugin `..` only found in rlib format, but must be available...\n     E0514, // metadata version mismatch\n@@ -97,5 +92,6 @@ register_diagnostics! {\n     E0464, // multiple matching crates for `..`\n     E0465, // multiple .. candidates for `..` found\n     E0519, // local crate and dependency have same (crate-name, disambiguator)\n-    E0523, // two dependencies have same (crate-name, disambiguator) but different SVH\n+    // two dependencies have same (crate-name, disambiguator) but different SVH\n+    E0523,\n }"}, {"sha": "e6104e629e9fbfefbec87db6c2dc3a602e2137e9", "filename": "src/librustc_metadata/lib.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_metadata%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_metadata%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -8,7 +8,6 @@\n #![feature(nll)]\n #![feature(proc_macro_internals)]\n #![feature(proc_macro_quote)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(rustc_private)]\n #![feature(slice_patterns)]\n #![feature(specialization)]\n@@ -23,7 +22,7 @@ extern crate rustc;\n #[macro_use]\n extern crate rustc_data_structures;\n \n-mod error_codes;\n+pub mod error_codes;\n \n mod index;\n mod encoder;\n@@ -68,5 +67,3 @@ pub fn validate_crate_name(\n         sess.unwrap().abort_if_errors();\n     }\n }\n-\n-__build_diagnostic_array! { librustc_metadata, DIAGNOSTICS }"}, {"sha": "d80449ac2372476c8af7bc9137c2592506a8ae72", "filename": "src/librustc_mir/error_codes.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_mir%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_mir%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,4 +1,4 @@\n-register_long_diagnostics! {\n+syntax::register_diagnostics! {\n \n \n E0001: r##\"\n@@ -2448,9 +2448,9 @@ information.\n \n There are some known bugs that trigger this message.\n \"##,\n-}\n \n-register_diagnostics! {\n+;\n+\n //  E0298, // cannot compare constants\n //  E0299, // mismatched types between arms\n //  E0471, // constant evaluation error (in pattern)"}, {"sha": "f27db351b74dbbf124eba38a733e2ec85f00e9b8", "filename": "src/librustc_mir/lib.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_mir%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_mir%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -14,7 +14,6 @@ Rust MIR: a lowered representation of Rust. Also: an experiment!\n #![feature(const_fn)]\n #![feature(decl_macro)]\n #![feature(exhaustive_patterns)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(never_type)]\n #![feature(specialization)]\n #![feature(try_trait)]\n@@ -32,7 +31,7 @@ Rust MIR: a lowered representation of Rust. Also: an experiment!\n #[macro_use] extern crate rustc_data_structures;\n #[macro_use] extern crate syntax;\n \n-mod error_codes;\n+pub mod error_codes;\n \n mod borrow_check;\n mod build;\n@@ -62,5 +61,3 @@ pub fn provide(providers: &mut Providers<'_>) {\n     };\n     providers.type_name = interpret::type_name;\n }\n-\n-__build_diagnostic_array! { librustc_mir, DIAGNOSTICS }"}, {"sha": "af07c790e2a8799a35e82878719ab7d1af97d0f4", "filename": "src/librustc_passes/error_codes.rs", "status": "modified", "additions": 3, "deletions": 7, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_passes%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_passes%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_passes%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,6 +1,4 @@\n-use syntax::{register_diagnostics, register_long_diagnostics};\n-\n-register_long_diagnostics! {\n+syntax::register_diagnostics! {\n /*\n E0014: r##\"\n Constants can only be initialized by a constant value or, in a future\n@@ -320,10 +318,8 @@ async fn foo() {}\n ```\n \n Switch to the Rust 2018 edition to use `async fn`.\n-\"##\n-}\n-\n-register_diagnostics! {\n+\"##,\n+;\n     E0226, // only a single explicit lifetime bound is permitted\n     E0472, // asm! is unsupported on this target\n     E0561, // patterns aren't allowed in function pointer types"}, {"sha": "cf2da4ffa2af08989dced816605512e411a951f6", "filename": "src/librustc_passes/lib.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_passes%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_passes%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_passes%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -9,7 +9,6 @@\n #![feature(in_band_lifetimes)]\n #![feature(nll)]\n #![feature(bind_by_move_pattern_guards)]\n-#![feature(rustc_diagnostic_macros)]\n \n #![recursion_limit=\"256\"]\n \n@@ -18,16 +17,14 @@ extern crate rustc;\n \n use rustc::ty::query::Providers;\n \n-mod error_codes;\n+pub mod error_codes;\n \n pub mod ast_validation;\n pub mod rvalue_promotion;\n pub mod hir_stats;\n pub mod layout_test;\n pub mod loops;\n \n-__build_diagnostic_array! { librustc_passes, DIAGNOSTICS }\n-\n pub fn provide(providers: &mut Providers<'_>) {\n     rvalue_promotion::provide(providers);\n     loops::provide(providers);"}, {"sha": "7b3f01c0ee11144b6cea496836470e049e398462", "filename": "src/librustc_plugin/error_codes.rs", "status": "modified", "additions": 3, "deletions": 8, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_plugin%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_plugin%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_plugin%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,9 +1,4 @@\n-use syntax::{register_diagnostics, register_long_diagnostics};\n-\n-register_long_diagnostics! {\n-\n-}\n-\n-register_diagnostics! {\n-    E0498  // malformed plugin attribute\n+syntax::register_diagnostics! {\n+;\n+    E0498,  // malformed plugin attribute\n }"}, {"sha": "4e1a47c503e59fd3675e8f576714dbbf74b8a3e2", "filename": "src/librustc_plugin/lib.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_plugin%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_plugin%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_plugin%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -54,15 +54,12 @@\n #![doc(html_root_url = \"https://doc.rust-lang.org/nightly/\")]\n \n #![feature(nll)]\n-#![feature(rustc_diagnostic_macros)]\n \n #![recursion_limit=\"256\"]\n \n pub use registry::Registry;\n \n-mod error_codes;\n+pub mod error_codes;\n pub mod registry;\n pub mod load;\n pub mod build;\n-\n-__build_diagnostic_array! { librustc_plugin, DIAGNOSTICS }"}, {"sha": "67066466f1d222d0d0af63a786a193a46f45f137", "filename": "src/librustc_privacy/error_codes.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_privacy%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_privacy%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_privacy%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,4 +1,4 @@\n-register_long_diagnostics! {\n+syntax::register_diagnostics! {\n \n E0445: r##\"\n A private trait was used on a public type parameter bound. Erroneous code\n@@ -154,8 +154,5 @@ let f = Bar::Foo::new(); // ok!\n ```\n \"##,\n \n-}\n-\n-register_diagnostics! {\n //  E0450, moved into resolve\n }"}, {"sha": "1e61f78c357dfa5d3260c4c5cbf7f31cb750608c", "filename": "src/librustc_privacy/lib.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_privacy%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_privacy%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_privacy%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -2,7 +2,6 @@\n \n #![feature(in_band_lifetimes)]\n #![feature(nll)]\n-#![feature(rustc_diagnostic_macros)]\n \n #![recursion_limit=\"256\"]\n \n@@ -31,7 +30,7 @@ use syntax_pos::Span;\n use std::{cmp, fmt, mem};\n use std::marker::PhantomData;\n \n-mod error_codes;\n+pub mod error_codes;\n \n ////////////////////////////////////////////////////////////////////////////////\n /// Generic infrastructure used to implement specific visitors below.\n@@ -2035,5 +2034,3 @@ fn check_private_in_public(tcx: TyCtxt<'_>, krate: CrateNum) {\n     };\n     krate.visit_all_item_likes(&mut DeepVisitor::new(&mut visitor));\n }\n-\n-__build_diagnostic_array! { librustc_privacy, DIAGNOSTICS }"}, {"sha": "adbff67cc8dac2942728becb3c9039b9533023a2", "filename": "src/librustc_resolve/error_codes.rs", "status": "modified", "additions": 2, "deletions": 7, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_resolve%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_resolve%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,9 +1,7 @@\n-use syntax::{register_diagnostics, register_long_diagnostics};\n-\n // Error messages for EXXXX errors.  Each message should start and end with a\n // new line, and be wrapped to 80 characters.  In vim you can `:set tw=80` and\n // use `gq` to wrap paragraphs. Use `:set tw=0` to disable.\n-register_long_diagnostics! {\n+syntax::register_diagnostics! {\n \n E0128: r##\"\n Type parameter defaults can only use parameters that occur before them.\n@@ -1662,10 +1660,7 @@ fn const_id<T, const N: T>() -> T { // error: const parameter\n }\n ```\n \"##,\n-\n-}\n-\n-register_diagnostics! {\n+;\n //  E0153, unused error code\n //  E0157, unused error code\n //  E0257,"}, {"sha": "aae283b74523650aebf14d07eed96a9040273bd2", "filename": "src/librustc_resolve/late.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_resolve%2Flate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_resolve%2Flate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Flate.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -298,18 +298,18 @@ impl<'a> PathSource<'a> {\n     }\n \n     fn error_code(self, has_unexpected_resolution: bool) -> &'static str {\n-        __diagnostic_used!(E0404);\n-        __diagnostic_used!(E0405);\n-        __diagnostic_used!(E0412);\n-        __diagnostic_used!(E0422);\n-        __diagnostic_used!(E0423);\n-        __diagnostic_used!(E0425);\n-        __diagnostic_used!(E0531);\n-        __diagnostic_used!(E0532);\n-        __diagnostic_used!(E0573);\n-        __diagnostic_used!(E0574);\n-        __diagnostic_used!(E0575);\n-        __diagnostic_used!(E0576);\n+        syntax::diagnostic_used!(E0404);\n+        syntax::diagnostic_used!(E0405);\n+        syntax::diagnostic_used!(E0412);\n+        syntax::diagnostic_used!(E0422);\n+        syntax::diagnostic_used!(E0423);\n+        syntax::diagnostic_used!(E0425);\n+        syntax::diagnostic_used!(E0531);\n+        syntax::diagnostic_used!(E0532);\n+        syntax::diagnostic_used!(E0573);\n+        syntax::diagnostic_used!(E0574);\n+        syntax::diagnostic_used!(E0575);\n+        syntax::diagnostic_used!(E0576);\n         match (self, has_unexpected_resolution) {\n             (PathSource::Trait(_), true) => \"E0404\",\n             (PathSource::Trait(_), false) => \"E0405\","}, {"sha": "0c86d8494fde833afcf0f92760d8b8821a14c219", "filename": "src/librustc_resolve/late/diagnostics.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_resolve%2Flate%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_resolve%2Flate%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Flate%2Fdiagnostics.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -113,7 +113,7 @@ impl<'a> LateResolutionVisitor<'a, '_> {\n \n         // Emit special messages for unresolved `Self` and `self`.\n         if is_self_type(path, ns) {\n-            __diagnostic_used!(E0411);\n+            syntax::diagnostic_used!(E0411);\n             err.code(DiagnosticId::Error(\"E0411\".into()));\n             err.span_label(span, format!(\"`Self` is only available in impls, traits, \\\n                                           and type definitions\"));\n@@ -122,7 +122,7 @@ impl<'a> LateResolutionVisitor<'a, '_> {\n         if is_self_value(path, ns) {\n             debug!(\"smart_resolve_path_fragment: E0424, source={:?}\", source);\n \n-            __diagnostic_used!(E0424);\n+            syntax::diagnostic_used!(E0424);\n             err.code(DiagnosticId::Error(\"E0424\".into()));\n             err.span_label(span, match source {\n                 PathSource::Pat => {"}, {"sha": "e980b8d01f7a8f34c217b2bd286532ab4aba44c5", "filename": "src/librustc_resolve/lib.rs", "status": "modified", "additions": 1, "deletions": 6, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_resolve%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_resolve%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -14,7 +14,6 @@\n #![feature(label_break_value)]\n #![feature(mem_take)]\n #![feature(nll)]\n-#![feature(rustc_diagnostic_macros)]\n \n #![recursion_limit=\"256\"]\n \n@@ -68,9 +67,7 @@ use macros::{LegacyBinding, LegacyScope};\n \n type Res = def::Res<NodeId>;\n \n-// N.B., this module needs to be declared first so diagnostics are\n-// registered before they are used.\n-mod error_codes;\n+pub mod error_codes;\n mod diagnostics;\n mod late;\n mod macros;\n@@ -2840,5 +2837,3 @@ impl CrateLint {\n         }\n     }\n }\n-\n-__build_diagnostic_array! { librustc_resolve, DIAGNOSTICS }"}, {"sha": "e11dcfafb8f8b1f10b31972b543b838fd716e0f2", "filename": "src/librustc_typeck/error_codes.rs", "status": "modified", "additions": 7, "deletions": 9, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_typeck%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_typeck%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,6 +1,6 @@\n // ignore-tidy-filelength\n \n-register_long_diagnostics! {\n+syntax::register_diagnostics! {\n \n E0023: r##\"\n A pattern used to match against an enum variant must provide a sub-pattern for\n@@ -4870,10 +4870,7 @@ fn foo_recursive(n: usize) -> Pin<Box<dyn Future<Output = ()>>> {\n The `Box<...>` ensures that the result is of known size,\n and the pin is required to keep it in the same place in memory.\n \"##,\n-\n-}  // (end of detailed error messages)\n-\n-register_diagnostics! {\n+;\n //  E0035, merged into E0087/E0089\n //  E0036, merged into E0087/E0089\n //  E0068,\n@@ -4930,15 +4927,16 @@ register_diagnostics! {\n //  E0245, // not a trait\n //  E0246, // invalid recursive type\n //  E0247,\n-//  E0248, // value used as a type, now reported earlier during resolution as E0412\n+//  E0248, // value used as a type, now reported earlier during resolution\n+           // as E0412\n //  E0249,\n //  E0319, // trait impls for defaulted traits allowed just for structs/enums\n //  E0372, // coherence not object safe\n     E0377, // the trait `CoerceUnsized` may only be implemented for a coercion\n            // between structures with the same definition\n //  E0558, // replaced with a generic attribute input check\n     E0533, // `{}` does not name a unit variant, unit struct or a constant\n-//  E0563, // cannot determine a type for this `impl Trait`: {} // removed in 6383de15\n+//  E0563, // cannot determine a type for this `impl Trait` removed in 6383de15\n     E0564, // only named lifetimes are allowed in `impl Trait`,\n            // but `{}` was found in the type `{}`\n     E0587, // type has conflicting packed and align representation hints\n@@ -4947,8 +4945,8 @@ register_diagnostics! {\n //  E0612, // merged into E0609\n //  E0613, // Removed (merged with E0609)\n     E0627, // yield statement outside of generator literal\n-    E0632, // cannot provide explicit type parameters when `impl Trait` is used in\n-           // argument position.\n+    E0632, // cannot provide explicit type parameters when `impl Trait` is used\n+           // in argument position.\n     E0634, // type has conflicting packed representaton hints\n     E0640, // infer outlives requirements\n     E0641, // cannot cast to/from a pointer with an unknown kind"}, {"sha": "959483e4439ff1a68f36a640f4f7889e6302e139", "filename": "src/librustc_typeck/lib.rs", "status": "modified", "additions": 1, "deletions": 6, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_typeck%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_typeck%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -65,7 +65,6 @@ This API is completely unstable and subject to change.\n #![feature(exhaustive_patterns)]\n #![feature(in_band_lifetimes)]\n #![feature(nll)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(slice_patterns)]\n #![feature(never_type)]\n #![feature(inner_deref)]\n@@ -78,9 +77,7 @@ This API is completely unstable and subject to change.\n \n #[macro_use] extern crate rustc;\n \n-// N.B., this module needs to be declared first so diagnostics are\n-// registered before they are used.\n-mod error_codes;\n+pub mod error_codes;\n \n mod astconv;\n mod check;\n@@ -389,5 +386,3 @@ pub fn hir_trait_to_predicates<'tcx>(\n \n     bounds\n }\n-\n-__build_diagnostic_array! { librustc_typeck, DIAGNOSTICS }"}, {"sha": "273a36edc56ff47068cd4b38518e7c12a189cdd1", "filename": "src/librustc_typeck/structured_errors.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_typeck%2Fstructured_errors.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibrustc_typeck%2Fstructured_errors.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fstructured_errors.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -48,7 +48,7 @@ impl<'tcx> StructuredDiagnostic<'tcx> for VariadicError<'tcx> {\n     fn session(&self) -> &Session { self.sess }\n \n     fn code(&self) -> DiagnosticId {\n-        __diagnostic_used!(E0617);\n+        syntax::diagnostic_used!(E0617);\n         DiagnosticId::Error(\"E0617\".to_owned())\n     }\n \n@@ -104,7 +104,7 @@ impl<'tcx> StructuredDiagnostic<'tcx> for SizedUnsizedCastError<'tcx> {\n     fn session(&self) -> &Session { self.sess }\n \n     fn code(&self) -> DiagnosticId {\n-        __diagnostic_used!(E0607);\n+        syntax::diagnostic_used!(E0607);\n         DiagnosticId::Error(\"E0607\".to_owned())\n     }\n "}, {"sha": "713d30855595682dc95f150e1f83d5df8776b606", "filename": "src/libstd/sys/unix/process/process_common.rs", "status": "modified", "additions": 25, "deletions": 3, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fprocess_common.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fprocess_common.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fprocess_common.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,19 +1,27 @@\n use crate::os::unix::prelude::*;\n \n-use crate::ffi::{OsString, OsStr, CString, CStr};\n+use crate::ffi::{OsString, OsStr, CString};\n use crate::fmt;\n use crate::io;\n use crate::ptr;\n use crate::sys::fd::FileDesc;\n-use crate::sys::fs::{File, OpenOptions};\n+use crate::sys::fs::File;\n use crate::sys::pipe::{self, AnonPipe};\n use crate::sys_common::process::CommandEnv;\n use crate::collections::BTreeMap;\n \n+#[cfg(not(target_os = \"fuchsia\"))]\n+use {\n+    crate::ffi::CStr,\n+    crate::sys::fs::OpenOptions,\n+};\n+\n use libc::{c_int, gid_t, uid_t, c_char, EXIT_SUCCESS, EXIT_FAILURE};\n \n cfg_if::cfg_if! {\n-    if #[cfg(target_os = \"redox\")] {\n+    if #[cfg(target_os = \"fuchsia\")] {\n+        // fuchsia doesn't have /dev/null\n+    } else if #[cfg(target_os = \"redox\")] {\n         const DEV_NULL: &'static str = \"null:\\0\";\n     } else {\n         const DEV_NULL: &'static str = \"/dev/null\\0\";\n@@ -107,6 +115,11 @@ pub enum ChildStdio {\n     Inherit,\n     Explicit(c_int),\n     Owned(FileDesc),\n+\n+    // On Fuchsia, null stdio is the default, so we simply don't specify\n+    // any actions at the time of spawning.\n+    #[cfg(target_os = \"fuchsia\")]\n+    Null,\n }\n \n pub enum Stdio {\n@@ -325,6 +338,7 @@ impl Stdio {\n                 Ok((ChildStdio::Owned(theirs.into_fd()), Some(ours)))\n             }\n \n+            #[cfg(not(target_os = \"fuchsia\"))]\n             Stdio::Null => {\n                 let mut opts = OpenOptions::new();\n                 opts.read(readable);\n@@ -335,6 +349,11 @@ impl Stdio {\n                 let fd = File::open_c(&path, &opts)?;\n                 Ok((ChildStdio::Owned(fd.into_fd()), None))\n             }\n+\n+            #[cfg(target_os = \"fuchsia\")]\n+            Stdio::Null => {\n+                Ok((ChildStdio::Null, None))\n+            }\n         }\n     }\n }\n@@ -357,6 +376,9 @@ impl ChildStdio {\n             ChildStdio::Inherit => None,\n             ChildStdio::Explicit(fd) => Some(fd),\n             ChildStdio::Owned(ref fd) => Some(fd.raw()),\n+\n+            #[cfg(target_os = \"fuchsia\")]\n+            ChildStdio::Null => None,\n         }\n     }\n }"}, {"sha": "fff9fc6b3bbc8b4e137a1318ddc1c96c535916be", "filename": "src/libstd/sys/unix/process/process_fuchsia.rs", "status": "modified", "additions": 43, "deletions": 20, "changes": 63, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fprocess_fuchsia.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fprocess_fuchsia.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fprocess_fuchsia.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -48,30 +48,51 @@ impl Command {\n         use crate::sys::process::zircon::*;\n \n         let envp = match maybe_envp {\n-            Some(envp) => envp.as_ptr(),\n+            // None means to clone the current environment, which is done in the\n+            // flags below.\n             None => ptr::null(),\n+            Some(envp) => envp.as_ptr(),\n         };\n \n-        let transfer_or_clone = |opt_fd, target_fd| if let Some(local_fd) = opt_fd {\n-            fdio_spawn_action_t {\n-                action: FDIO_SPAWN_ACTION_TRANSFER_FD,\n-                local_fd,\n-                target_fd,\n-                ..Default::default()\n-            }\n-        } else {\n-            fdio_spawn_action_t {\n-                action: FDIO_SPAWN_ACTION_CLONE_FD,\n-                local_fd: target_fd,\n-                target_fd,\n-                ..Default::default()\n+        let make_action = |local_io: &ChildStdio, target_fd| -> io::Result<fdio_spawn_action_t> {\n+            if let Some(local_fd) = local_io.fd() {\n+                Ok(fdio_spawn_action_t {\n+                    action: FDIO_SPAWN_ACTION_TRANSFER_FD,\n+                    local_fd,\n+                    target_fd,\n+                    ..Default::default()\n+                })\n+            } else {\n+                if let ChildStdio::Null = local_io {\n+                    // acts as no-op\n+                    return Ok(Default::default());\n+                }\n+\n+                let mut handle = ZX_HANDLE_INVALID;\n+                let status = fdio_fd_clone(target_fd, &mut handle);\n+                if status == ERR_INVALID_ARGS || status == ERR_NOT_SUPPORTED {\n+                    // This descriptor is closed; skip it rather than generating an\n+                    // error.\n+                    return Ok(Default::default());\n+                }\n+                zx_cvt(status)?;\n+\n+                let mut cloned_fd = 0;\n+                zx_cvt(fdio_fd_create(handle, &mut cloned_fd))?;\n+\n+                Ok(fdio_spawn_action_t {\n+                    action: FDIO_SPAWN_ACTION_TRANSFER_FD,\n+                    local_fd: cloned_fd as i32,\n+                    target_fd,\n+                    ..Default::default()\n+                })\n             }\n         };\n \n         // Clone stdin, stdout, and stderr\n-        let action1 = transfer_or_clone(stdio.stdin.fd(), 0);\n-        let action2 = transfer_or_clone(stdio.stdout.fd(), 1);\n-        let action3 = transfer_or_clone(stdio.stderr.fd(), 2);\n+        let action1 = make_action(&stdio.stdin, 0)?;\n+        let action2 = make_action(&stdio.stdout, 1)?;\n+        let action3 = make_action(&stdio.stderr, 2)?;\n         let actions = [action1, action2, action3];\n \n         // We don't want FileDesc::drop to be called on any stdio. fdio_spawn_etc\n@@ -84,9 +105,11 @@ impl Command {\n \n         let mut process_handle: zx_handle_t = 0;\n         zx_cvt(fdio_spawn_etc(\n-            0,\n-            FDIO_SPAWN_CLONE_JOB | FDIO_SPAWN_CLONE_LDSVC | FDIO_SPAWN_CLONE_NAMESPACE,\n-            self.get_argv()[0], self.get_argv().as_ptr(), envp, 3, actions.as_ptr(),\n+            ZX_HANDLE_INVALID,\n+            FDIO_SPAWN_CLONE_JOB | FDIO_SPAWN_CLONE_LDSVC | FDIO_SPAWN_CLONE_NAMESPACE\n+            | FDIO_SPAWN_CLONE_ENVIRON,  // this is ignored when envp is non-null\n+            self.get_argv()[0], self.get_argv().as_ptr(), envp,\n+            actions.len() as size_t, actions.as_ptr(),\n             &mut process_handle,\n             ptr::null_mut(),\n         ))?;"}, {"sha": "1ba48de3c07855badc5bc34778ee960c9c29231f", "filename": "src/libstd/sys/unix/process/zircon.rs", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fzircon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fzircon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fprocess%2Fzircon.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -2,8 +2,9 @@\n \n use crate::convert::TryInto;\n use crate::io;\n+use crate::i64;\n+use crate::mem::MaybeUninit;\n use crate::os::raw::c_char;\n-use crate::u64;\n \n use libc::{c_int, c_void, size_t};\n \n@@ -14,8 +15,8 @@ pub type zx_status_t = i32;\n \n pub const ZX_HANDLE_INVALID: zx_handle_t = 0;\n \n-pub type zx_time_t = u64;\n-pub const ZX_TIME_INFINITE : zx_time_t = u64::MAX;\n+pub type zx_time_t = i64;\n+pub const ZX_TIME_INFINITE : zx_time_t = i64::MAX;\n \n pub type zx_signals_t = u32;\n \n@@ -120,8 +121,11 @@ pub struct fdio_spawn_action_t {\n extern {\n     pub fn fdio_spawn_etc(job: zx_handle_t, flags: u32, path: *const c_char,\n                           argv: *const *const c_char, envp: *const *const c_char,\n-                          action_count: u64, actions: *const fdio_spawn_action_t,\n+                          action_count: size_t, actions: *const fdio_spawn_action_t,\n                           process: *mut zx_handle_t, err_msg: *mut c_char) -> zx_status_t;\n+\n+    pub fn fdio_fd_clone(fd: c_int, out_handle: *mut zx_handle_t) -> zx_status_t;\n+    pub fn fdio_fd_create(handle: zx_handle_t, fd: *mut c_int) -> zx_status_t;\n }\n \n // fdio_spawn_etc flags"}, {"sha": "bfb2db959636390e21257d2dee2b98a65ae0fb12", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 26, "deletions": 26, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -413,11 +413,11 @@ impl WherePredicate {\n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub struct WhereBoundPredicate {\n     pub span: Span,\n-    /// Any generics from a `for` binding\n+    /// Any generics from a `for` binding.\n     pub bound_generic_params: Vec<GenericParam>,\n-    /// The type being bounded\n+    /// The type being bounded.\n     pub bounded_ty: P<Ty>,\n-    /// Trait and lifetime bounds (`Clone+Send+'static`)\n+    /// Trait and lifetime bounds (`Clone + Send + 'static`).\n     pub bounds: GenericBounds,\n }\n \n@@ -495,15 +495,15 @@ pub enum MetaItemKind {\n     NameValue(Lit),\n }\n \n-/// A Block (`{ .. }`).\n+/// A block (`{ .. }`).\n ///\n /// E.g., `{ .. }` as in `fn foo() { .. }`.\n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub struct Block {\n-    /// Statements in a block\n+    /// The statements in the block.\n     pub stmts: Vec<Stmt>,\n     pub id: NodeId,\n-    /// Distinguishes between `unsafe { ... }` and `{ ... }`\n+    /// Distinguishes between `unsafe { ... }` and `{ ... }`.\n     pub rules: BlockCheckMode,\n     pub span: Span,\n }\n@@ -908,11 +908,11 @@ pub enum MacStmtStyle {\n /// Local represents a `let` statement, e.g., `let <pat>:<ty> = <expr>;`.\n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub struct Local {\n+    pub id: NodeId,\n     pub pat: P<Pat>,\n     pub ty: Option<P<Ty>>,\n     /// Initializer expression to set the value, if any.\n     pub init: Option<P<Expr>>,\n-    pub id: NodeId,\n     pub span: Span,\n     pub attrs: ThinVec<Attribute>,\n }\n@@ -970,7 +970,7 @@ pub struct AnonConst {\n     pub value: P<Expr>,\n }\n \n-/// An expression\n+/// An expression.\n #[derive(Clone, RustcEncodable, RustcDecodable)]\n pub struct Expr {\n     pub id: NodeId,\n@@ -984,26 +984,26 @@ pub struct Expr {\n static_assert_size!(Expr, 96);\n \n impl Expr {\n-    /// Whether this expression would be valid somewhere that expects a value; for example, an `if`\n-    /// condition.\n+    /// Returns `true` if this expression would be valid somewhere that expects a value;\n+    /// for example, an `if` condition.\n     pub fn returns(&self) -> bool {\n         if let ExprKind::Block(ref block, _) = self.node {\n             match block.stmts.last().map(|last_stmt| &last_stmt.node) {\n-                // implicit return\n+                // Implicit return\n                 Some(&StmtKind::Expr(_)) => true,\n                 Some(&StmtKind::Semi(ref expr)) => {\n                     if let ExprKind::Ret(_) = expr.node {\n-                        // last statement is explicit return\n+                        // Last statement is explicit return.\n                         true\n                     } else {\n                         false\n                     }\n                 }\n-                // This is a block that doesn't end in either an implicit or explicit return\n+                // This is a block that doesn't end in either an implicit or explicit return.\n                 _ => false,\n             }\n         } else {\n-            // This is not a block, it is a value\n+            // This is not a block, it is a value.\n             true\n         }\n     }\n@@ -2307,57 +2307,57 @@ impl Default for FnHeader {\n \n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub enum ItemKind {\n-    /// An `extern crate` item, with optional *original* crate name if the crate was renamed.\n+    /// An `extern crate` item, with the optional *original* crate name if the crate was renamed.\n     ///\n     /// E.g., `extern crate foo` or `extern crate foo_bar as foo`.\n     ExternCrate(Option<Name>),\n-    /// A use declaration (`use` or `pub use`) item.\n+    /// A use declaration item (`use`).\n     ///\n     /// E.g., `use foo;`, `use foo::bar;` or `use foo::bar as FooBar;`.\n     Use(P<UseTree>),\n-    /// A static item (`static` or `pub static`).\n+    /// A static item (`static`).\n     ///\n     /// E.g., `static FOO: i32 = 42;` or `static FOO: &'static str = \"bar\";`.\n     Static(P<Ty>, Mutability, P<Expr>),\n-    /// A constant item (`const` or `pub const`).\n+    /// A constant item (`const`).\n     ///\n     /// E.g., `const FOO: i32 = 42;`.\n     Const(P<Ty>, P<Expr>),\n-    /// A function declaration (`fn` or `pub fn`).\n+    /// A function declaration (`fn`).\n     ///\n     /// E.g., `fn foo(bar: usize) -> usize { .. }`.\n     Fn(P<FnDecl>, FnHeader, Generics, P<Block>),\n-    /// A module declaration (`mod` or `pub mod`).\n+    /// A module declaration (`mod`).\n     ///\n     /// E.g., `mod foo;` or `mod foo { .. }`.\n     Mod(Mod),\n-    /// An external module (`extern` or `pub extern`).\n+    /// An external module (`extern`).\n     ///\n     /// E.g., `extern {}` or `extern \"C\" {}`.\n     ForeignMod(ForeignMod),\n     /// Module-level inline assembly (from `global_asm!()`).\n     GlobalAsm(P<GlobalAsm>),\n-    /// A type alias (`type` or `pub type`).\n+    /// A type alias (`type`).\n     ///\n     /// E.g., `type Foo = Bar<u8>;`.\n     TyAlias(P<Ty>, Generics),\n     /// An opaque `impl Trait` type alias.\n     ///\n     /// E.g., `type Foo = impl Bar + Boo;`.\n     OpaqueTy(GenericBounds, Generics),\n-    /// An enum definition (`enum` or `pub enum`).\n+    /// An enum definition (`enum`).\n     ///\n     /// E.g., `enum Foo<A, B> { C<A>, D<B> }`.\n     Enum(EnumDef, Generics),\n-    /// A struct definition (`struct` or `pub struct`).\n+    /// A struct definition (`struct`).\n     ///\n     /// E.g., `struct Foo<A> { x: A }`.\n     Struct(VariantData, Generics),\n-    /// A union definition (`union` or `pub union`).\n+    /// A union definition (`union`).\n     ///\n     /// E.g., `union Foo<A, B> { x: A, y: B }`.\n     Union(VariantData, Generics),\n-    /// A Trait declaration (`trait` or `pub trait`).\n+    /// A trait declaration (`trait`).\n     ///\n     /// E.g., `trait Foo { .. }`, `trait Foo<T> { .. }` or `auto trait Foo {}`.\n     Trait(IsAuto, Unsafety, Generics, GenericBounds, Vec<TraitItem>),"}, {"sha": "1f954064944dc1f5df3c3b27d04fc34a2e62fe4e", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 22, "deletions": 21, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,4 +1,4 @@\n-//! Functions dealing with attributes and meta items\n+//! Functions dealing with attributes and meta items.\n \n mod builtin;\n \n@@ -61,15 +61,15 @@ pub fn is_known_lint_tool(m_item: Ident) -> bool {\n }\n \n impl NestedMetaItem {\n-    /// Returns the MetaItem if self is a NestedMetaItem::MetaItem.\n+    /// Returns the `MetaItem` if `self` is a `NestedMetaItem::MetaItem`.\n     pub fn meta_item(&self) -> Option<&MetaItem> {\n         match *self {\n             NestedMetaItem::MetaItem(ref item) => Some(item),\n             _ => None\n         }\n     }\n \n-    /// Returns the Lit if self is a NestedMetaItem::Literal.\n+    /// Returns the `Lit` if `self` is a `NestedMetaItem::Literal`s.\n     pub fn literal(&self) -> Option<&Lit> {\n         match *self {\n             NestedMetaItem::Literal(ref lit) => Some(lit),\n@@ -82,21 +82,21 @@ impl NestedMetaItem {\n         self.meta_item().map_or(false, |meta_item| meta_item.check_name(name))\n     }\n \n-    /// For a single-segment meta-item returns its name, otherwise returns `None`.\n+    /// For a single-segment meta item, returns its name; otherwise, returns `None`.\n     pub fn ident(&self) -> Option<Ident> {\n         self.meta_item().and_then(|meta_item| meta_item.ident())\n     }\n     pub fn name_or_empty(&self) -> Symbol {\n         self.ident().unwrap_or(Ident::invalid()).name\n     }\n \n-    /// Gets the string value if self is a MetaItem and the MetaItem is a\n-    /// MetaItemKind::NameValue variant containing a string, otherwise None.\n+    /// Gets the string value if `self` is a `MetaItem` and the `MetaItem` is a\n+    /// `MetaItemKind::NameValue` variant containing a string, otherwise `None`.\n     pub fn value_str(&self) -> Option<Symbol> {\n         self.meta_item().and_then(|meta_item| meta_item.value_str())\n     }\n \n-    /// Returns a name and single literal value tuple of the MetaItem.\n+    /// Returns a name and single literal value tuple of the `MetaItem`.\n     pub fn name_value_literal(&self) -> Option<(Name, &Lit)> {\n         self.meta_item().and_then(\n             |meta_item| meta_item.meta_item_list().and_then(\n@@ -112,32 +112,32 @@ impl NestedMetaItem {\n                 }))\n     }\n \n-    /// Gets a list of inner meta items from a list MetaItem type.\n+    /// Gets a list of inner meta items from a list `MetaItem` type.\n     pub fn meta_item_list(&self) -> Option<&[NestedMetaItem]> {\n         self.meta_item().and_then(|meta_item| meta_item.meta_item_list())\n     }\n \n-    /// Returns `true` if the variant is MetaItem.\n+    /// Returns `true` if the variant is `MetaItem`.\n     pub fn is_meta_item(&self) -> bool {\n         self.meta_item().is_some()\n     }\n \n-    /// Returns `true` if the variant is Literal.\n+    /// Returns `true` if the variant is `Literal`.\n     pub fn is_literal(&self) -> bool {\n         self.literal().is_some()\n     }\n \n-    /// Returns `true` if self is a MetaItem and the meta item is a word.\n+    /// Returns `true` if `self` is a `MetaItem` and the meta item is a word.\n     pub fn is_word(&self) -> bool {\n         self.meta_item().map_or(false, |meta_item| meta_item.is_word())\n     }\n \n-    /// Returns `true` if self is a MetaItem and the meta item is a ValueString.\n+    /// Returns `true` if `self` is a `MetaItem` and the meta item is a `ValueString`.\n     pub fn is_value_str(&self) -> bool {\n         self.value_str().is_some()\n     }\n \n-    /// Returns `true` if self is a MetaItem and the meta item is a list.\n+    /// Returns `true` if `self` is a `MetaItem` and the meta item is a list.\n     pub fn is_meta_item_list(&self) -> bool {\n         self.meta_item_list().is_some()\n     }\n@@ -156,7 +156,7 @@ impl Attribute {\n         matches\n     }\n \n-    /// For a single-segment attribute returns its name, otherwise returns `None`.\n+    /// For a single-segment attribute, returns its name; otherwise, returns `None`.\n     pub fn ident(&self) -> Option<Ident> {\n         if self.path.segments.len() == 1 {\n             Some(self.path.segments[0].ident)\n@@ -187,14 +187,14 @@ impl Attribute {\n         self.meta_item_list().is_some()\n     }\n \n-    /// Indicates if the attribute is a Value String.\n+    /// Indicates if the attribute is a `ValueString`.\n     pub fn is_value_str(&self) -> bool {\n         self.value_str().is_some()\n     }\n }\n \n impl MetaItem {\n-    /// For a single-segment meta-item returns its name, otherwise returns `None`.\n+    /// For a single-segment meta item, returns its name; otherwise, returns `None`.\n     pub fn ident(&self) -> Option<Ident> {\n         if self.path.segments.len() == 1 {\n             Some(self.path.segments[0].ident)\n@@ -206,8 +206,9 @@ impl MetaItem {\n         self.ident().unwrap_or(Ident::invalid()).name\n     }\n \n-    // #[attribute(name = \"value\")]\n-    //             ^^^^^^^^^^^^^^\n+    // Example:\n+    //     #[attribute(name = \"value\")]\n+    //                 ^^^^^^^^^^^^^^\n     pub fn name_value_literal(&self) -> Option<&Lit> {\n         match &self.node {\n             MetaItemKind::NameValue(v) => Some(v),\n@@ -255,7 +256,7 @@ impl MetaItem {\n }\n \n impl Attribute {\n-    /// Extracts the MetaItem from inside this Attribute.\n+    /// Extracts the `MetaItem` from inside this `Attribute`.\n     pub fn meta(&self) -> Option<MetaItem> {\n         let mut tokens = self.tokens.trees().peekable();\n         Some(MetaItem {\n@@ -318,8 +319,8 @@ impl Attribute {\n         })\n     }\n \n-    /// Converts self to a normal #[doc=\"foo\"] comment, if it is a\n-    /// comment like `///` or `/** */`. (Returns self unchanged for\n+    /// Converts `self` to a normal `#[doc=\"foo\"]` comment, if it is a\n+    /// comment like `///` or `/** */`. (Returns `self` unchanged for\n     /// non-sugared doc attributes.)\n     pub fn with_desugared_doc<T, F>(&self, f: F) -> T where\n         F: FnOnce(&Attribute) -> T,"}, {"sha": "c95c5bd5d02d4d20479a9b6ec806985c19dd2989", "filename": "src/libsyntax/diagnostics/macros.rs", "status": "modified", "additions": 29, "deletions": 26, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fdiagnostics%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fdiagnostics%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fmacros.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,13 +1,14 @@\n #[macro_export]\n-macro_rules! register_diagnostic {\n-    ($code:tt, $description:tt) => (__register_diagnostic! { $code, $description });\n-    ($code:tt) => (__register_diagnostic! { $code })\n+macro_rules! diagnostic_used {\n+    ($code:ident) => (\n+        let _ = crate::error_codes::$code;\n+    )\n }\n \n #[macro_export]\n macro_rules! span_fatal {\n     ($session:expr, $span:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         $session.span_fatal_with_code(\n             $span,\n             &format!($($message)*),\n@@ -19,7 +20,7 @@ macro_rules! span_fatal {\n #[macro_export]\n macro_rules! span_err {\n     ($session:expr, $span:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         $session.span_err_with_code(\n             $span,\n             &format!($($message)*),\n@@ -31,7 +32,7 @@ macro_rules! span_err {\n #[macro_export]\n macro_rules! span_warn {\n     ($session:expr, $span:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         $session.span_warn_with_code(\n             $span,\n             &format!($($message)*),\n@@ -43,7 +44,7 @@ macro_rules! span_warn {\n #[macro_export]\n macro_rules! struct_err {\n     ($session:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         $session.struct_err_with_code(\n             &format!($($message)*),\n             $crate::errors::DiagnosticId::Error(stringify!($code).to_owned()),\n@@ -54,7 +55,7 @@ macro_rules! struct_err {\n #[macro_export]\n macro_rules! span_err_or_warn {\n     ($is_warning:expr, $session:expr, $span:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         if $is_warning {\n             $session.span_warn_with_code(\n                 $span,\n@@ -74,7 +75,7 @@ macro_rules! span_err_or_warn {\n #[macro_export]\n macro_rules! struct_span_fatal {\n     ($session:expr, $span:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         $session.struct_span_fatal_with_code(\n             $span,\n             &format!($($message)*),\n@@ -86,7 +87,7 @@ macro_rules! struct_span_fatal {\n #[macro_export]\n macro_rules! struct_span_err {\n     ($session:expr, $span:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         $session.struct_span_err_with_code(\n             $span,\n             &format!($($message)*),\n@@ -98,7 +99,7 @@ macro_rules! struct_span_err {\n #[macro_export]\n macro_rules! stringify_error_code {\n     ($code:ident) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         $crate::errors::DiagnosticId::Error(stringify!($code).to_owned())\n     })\n }\n@@ -117,7 +118,7 @@ macro_rules! type_error_struct {\n #[macro_export]\n macro_rules! struct_span_warn {\n     ($session:expr, $span:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         $session.struct_span_warn_with_code(\n             $span,\n             &format!($($message)*),\n@@ -129,7 +130,7 @@ macro_rules! struct_span_warn {\n #[macro_export]\n macro_rules! struct_span_err_or_warn {\n     ($is_warning:expr, $session:expr, $span:expr, $code:ident, $($message:tt)*) => ({\n-        __diagnostic_used!($code);\n+        $crate::diagnostic_used!($code);\n         if $is_warning {\n             $session.struct_span_warn_with_code(\n                 $span,\n@@ -169,20 +170,22 @@ macro_rules! help {\n \n #[macro_export]\n macro_rules! register_diagnostics {\n-    ($($code:tt),*) => (\n-        $($crate::register_diagnostic! { $code })*\n+    ($($ecode:ident: $message:expr,)*) => (\n+        $crate::register_diagnostics!{$($ecode:$message,)* ;}\n     );\n-    ($($code:tt),*,) => (\n-        $($crate::register_diagnostic! { $code })*\n-    )\n-}\n \n-#[macro_export]\n-macro_rules! register_long_diagnostics {\n-    ($($code:tt: $description:tt),*) => (\n-        $($crate::register_diagnostic! { $code, $description })*\n-    );\n-    ($($code:tt: $description:tt),*,) => (\n-        $($crate::register_diagnostic! { $code, $description })*\n+    ($($ecode:ident: $message:expr,)* ; $($code:ident,)*) => (\n+        pub static DIAGNOSTICS: &[(&str, &str)] = &[\n+            $( (stringify!($ecode), $message), )*\n+        ];\n+\n+        $(\n+            #[deny(unused)]\n+            pub(crate) const $ecode: &str = $message;\n+        )*\n+        $(\n+            #[deny(unused)]\n+            pub(crate) const $code: () = ();\n+        )*\n     )\n }"}, {"sha": "5de39c8d14d17d2af304947be1489049c0914f49", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "removed", "additions": 0, "deletions": 185, "changes": 185, "blob_url": "https://github.com/rust-lang/rust/blob/ef54f57c5b9d894a38179d09b00610c1b337b086/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ef54f57c5b9d894a38179d09b00610c1b337b086/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=ef54f57c5b9d894a38179d09b00610c1b337b086", "patch": "@@ -1,185 +0,0 @@\n-use std::collections::BTreeMap;\n-\n-use crate::ast::{self, Ident, Name};\n-use crate::source_map;\n-use crate::ext::base::{ExtCtxt, MacEager, MacResult};\n-use crate::parse::token::{self, Token};\n-use crate::ptr::P;\n-use crate::symbol::kw;\n-use crate::tokenstream::{TokenTree, TokenStream};\n-\n-use smallvec::smallvec;\n-use syntax_pos::Span;\n-\n-pub use errors::*;\n-\n-// Maximum width of any line in an extended error description (inclusive).\n-const MAX_DESCRIPTION_WIDTH: usize = 80;\n-\n-/// Error information type.\n-pub struct ErrorInfo {\n-    pub description: Option<Name>,\n-    pub use_site: Option<Span>\n-}\n-\n-/// Mapping from error codes to metadata.\n-pub type ErrorMap = BTreeMap<Name, ErrorInfo>;\n-\n-pub fn expand_diagnostic_used<'cx>(ecx: &'cx mut ExtCtxt<'_>,\n-                                   span: Span,\n-                                   tts: TokenStream)\n-                                   -> Box<dyn MacResult+'cx> {\n-    assert_eq!(tts.len(), 1);\n-    let code = match tts.into_trees().next() {\n-        Some(TokenTree::Token(Token { kind: token::Ident(code, _), .. })) => code,\n-        _ => unreachable!()\n-    };\n-\n-    ecx.parse_sess.registered_diagnostics.with_lock(|diagnostics| {\n-        match diagnostics.get_mut(&code) {\n-            // Previously used errors.\n-            Some(&mut ErrorInfo { description: _, use_site: Some(previous_span) }) => {\n-                ecx.struct_span_warn(span, &format!(\n-                    \"diagnostic code {} already used\", code\n-                )).span_note(previous_span, \"previous invocation\")\n-                  .emit();\n-            }\n-            // Newly used errors.\n-            Some(ref mut info) => {\n-                info.use_site = Some(span);\n-            }\n-            // Unregistered errors.\n-            None => {\n-                ecx.span_err(span, &format!(\n-                    \"used diagnostic code {} not registered\", code\n-                ));\n-            }\n-        }\n-    });\n-    MacEager::expr(ecx.expr_tuple(span, Vec::new()))\n-}\n-\n-pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt<'_>,\n-                                       span: Span,\n-                                       tts: TokenStream)\n-                                       -> Box<dyn MacResult+'cx> {\n-    assert!(tts.len() == 1 || tts.len() == 3);\n-    let mut cursor = tts.into_trees();\n-    let code = match cursor.next() {\n-        Some(TokenTree::Token(Token { kind: token::Ident(code, _), .. })) => code,\n-        _ => unreachable!()\n-    };\n-    let description = match  (cursor.next(), cursor.next()) {\n-        (None, None) => None,\n-        (\n-            Some(TokenTree::Token(Token { kind: token::Comma, .. })),\n-            Some(TokenTree::Token(Token { kind: token::Literal(token::Lit { symbol, .. }), ..}))\n-        ) => {\n-            Some(symbol)\n-        },\n-        _ => unreachable!()\n-    };\n-\n-    // Check that the description starts and ends with a newline and doesn't\n-    // overflow the maximum line width.\n-    description.map(|raw_msg| {\n-        let msg = raw_msg.as_str();\n-        if !msg.starts_with(\"\\n\") || !msg.ends_with(\"\\n\") {\n-            ecx.span_err(span, &format!(\n-                \"description for error code {} doesn't start and end with a newline\",\n-                code\n-            ));\n-        }\n-\n-        // URLs can be unavoidably longer than the line limit, so we allow them.\n-        // Allowed format is: `[name]: https://www.rust-lang.org/`\n-        let is_url = |l: &str| l.starts_with(\"[\") && l.contains(\"]:\") && l.contains(\"http\");\n-\n-        if msg.lines().any(|line| line.len() > MAX_DESCRIPTION_WIDTH && !is_url(line)) {\n-            ecx.span_err(span, &format!(\n-                \"description for error code {} contains a line longer than {} characters.\\n\\\n-                 if you're inserting a long URL use the footnote style to bypass this check.\",\n-                code, MAX_DESCRIPTION_WIDTH\n-            ));\n-        }\n-    });\n-    // Add the error to the map.\n-    ecx.parse_sess.registered_diagnostics.with_lock(|diagnostics| {\n-        let info = ErrorInfo {\n-            description,\n-            use_site: None\n-        };\n-        if diagnostics.insert(code, info).is_some() {\n-            ecx.span_err(span, &format!(\n-                \"diagnostic code {} already registered\", code\n-            ));\n-        }\n-    });\n-\n-    MacEager::items(smallvec![])\n-}\n-\n-pub fn expand_build_diagnostic_array<'cx>(ecx: &'cx mut ExtCtxt<'_>,\n-                                          span: Span,\n-                                          tts: TokenStream)\n-                                          -> Box<dyn MacResult+'cx> {\n-    assert_eq!(tts.len(), 3);\n-    let ident = match tts.into_trees().nth(2) {\n-        // DIAGNOSTICS ident.\n-        Some(TokenTree::Token(Token { kind: token::Ident(name, _), span }))\n-        => Ident::new(name, span),\n-        _ => unreachable!()\n-    };\n-\n-    // Construct the output expression.\n-    let (count, expr) =\n-        ecx.parse_sess.registered_diagnostics.with_lock(|diagnostics| {\n-            let descriptions: Vec<P<ast::Expr>> =\n-                diagnostics.iter().filter_map(|(&code, info)| {\n-                    info.description.map(|description| {\n-                        ecx.expr_tuple(span, vec![\n-                            ecx.expr_str(span, code),\n-                            ecx.expr_str(span, description)\n-                        ])\n-                    })\n-                }).collect();\n-            (descriptions.len(), ecx.expr_vec(span, descriptions))\n-        });\n-\n-    let static_ = ecx.lifetime(span, Ident::with_dummy_span(kw::StaticLifetime));\n-    let ty_str = ecx.ty_rptr(\n-        span,\n-        ecx.ty_ident(span, ecx.ident_of(\"str\")),\n-        Some(static_),\n-        ast::Mutability::Immutable,\n-    );\n-\n-    let ty = ecx.ty(\n-        span,\n-        ast::TyKind::Array(\n-            ecx.ty(\n-                span,\n-                ast::TyKind::Tup(vec![ty_str.clone(), ty_str])\n-            ),\n-            ast::AnonConst {\n-                id: ast::DUMMY_NODE_ID,\n-                value: ecx.expr_usize(span, count),\n-            },\n-        ),\n-    );\n-\n-    MacEager::items(smallvec![\n-        P(ast::Item {\n-            ident,\n-            attrs: Vec::new(),\n-            id: ast::DUMMY_NODE_ID,\n-            node: ast::ItemKind::Const(\n-                ty,\n-                expr,\n-            ),\n-            vis: source_map::respan(span.shrink_to_lo(), ast::VisibilityKind::Public),\n-            span,\n-            tokens: None,\n-        })\n-    ])\n-}"}, {"sha": "9925dd8ada0d51520cf413608243e35a690784dc", "filename": "src/libsyntax/error_codes.rs", "status": "modified", "additions": 12, "deletions": 8, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,7 +1,8 @@\n // Error messages for EXXXX errors.\n-// Each message should start and end with a new line, and be wrapped to 80 characters.\n-// In vim you can `:set tw=80` and use `gq` to wrap paragraphs. Use `:set tw=0` to disable.\n-register_long_diagnostics! {\n+// Each message should start and end with a new line, and be wrapped to 80\n+// characters.  In vim you can `:set tw=80` and use `gq` to wrap paragraphs. Use\n+// `:set tw=0` to disable.\n+register_diagnostics! {\n \n E0178: r##\"\n In types, the `+` type operator has low precedence, so it is often necessary\n@@ -420,9 +421,8 @@ Delete the offending feature attribute, or add it to the list of allowed\n features in the `-Z allow_features` flag.\n \"##,\n \n-}\n+;\n \n-register_diagnostics! {\n     E0539, // incorrect meta item\n     E0540, // multiple rustc_deprecated attributes\n     E0542, // missing 'since'\n@@ -432,17 +432,21 @@ register_diagnostics! {\n     E0546, // missing 'feature'\n     E0547, // missing 'issue'\n //  E0548, // replaced with a generic attribute input check\n-    E0549, // rustc_deprecated attribute must be paired with either stable or unstable attribute\n+    // rustc_deprecated attribute must be paired with either stable or unstable\n+    // attribute\n+    E0549,\n     E0550, // multiple deprecated attributes\n     E0551, // incorrect meta item\n     E0553, // multiple rustc_const_unstable attributes\n //  E0555, // replaced with a generic attribute input check\n     E0556, // malformed feature, expected just one word\n     E0584, // file for module `..` found at both .. and ..\n     E0629, // missing 'feature' (rustc_const_unstable)\n-    E0630, // rustc_const_unstable attribute must be paired with stable/unstable attribute\n+    // rustc_const_unstable attribute must be paired with stable/unstable\n+    // attribute\n+    E0630,\n     E0693, // incorrect `repr(align)` attribute format\n-    E0694, // an unknown tool name found in scoped attributes\n+//  E0694, // an unknown tool name found in scoped attributes\n     E0703, // invalid ABI\n     E0717, // rustc_promotable without stability attribute\n }"}, {"sha": "c4569b3fba1be0d52f744ada8a32b0118741821e", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -958,7 +958,7 @@ impl<'a> ExtCtxt<'a> {\n         self.resolver.check_unused_macros();\n     }\n \n-    /// Resolve a path mentioned inside Rust code.\n+    /// Resolves a path mentioned inside Rust code.\n     ///\n     /// This unifies the logic used for resolving `include_X!`, and `#[doc(include)]` file paths.\n     ///"}, {"sha": "5a248df6af25225620165bb82e43438fd025e991", "filename": "src/libsyntax/feature_gate/active.rs", "status": "modified", "additions": 10, "deletions": 14, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ffeature_gate%2Factive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ffeature_gate%2Factive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate%2Factive.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,9 +1,11 @@\n //! List of the active feature gates.\n \n+use super::{State, Feature};\n+\n use crate::edition::Edition;\n use crate::symbol::{Symbol, sym};\n+\n use syntax_pos::Span;\n-use super::{State, Feature};\n \n macro_rules! set {\n     ($field: ident) => {{\n@@ -37,9 +39,9 @@ macro_rules! declare_features {\n         /// A set of features to be used by later passes.\n         #[derive(Clone)]\n         pub struct Features {\n-            /// `#![feature]` attrs for language features, for error reporting\n+            /// `#![feature]` attrs for language features, for error reporting.\n             pub declared_lang_features: Vec<(Symbol, Span, Option<Symbol>)>,\n-            /// `#![feature]` attrs for non-language (library) features\n+            /// `#![feature]` attrs for non-language (library) features.\n             pub declared_lib_features: Vec<(Symbol, Span)>,\n             $(\n                 $(#[doc = $doc])*\n@@ -66,11 +68,11 @@ macro_rules! declare_features {\n }\n \n impl Feature {\n-    /// Set this feature in `Features`. Panics if called on a non-active feature.\n+    /// Sets this feature in `Features`. Panics if called on a non-active feature.\n     pub fn set(&self, features: &mut Features, span: Span) {\n         match self.state {\n             State::Active { set } => set(features, span),\n-            _ => panic!(\"Called `set` on feature `{}` which is not `active`\", self.name)\n+            _ => panic!(\"called `set` on feature `{}` which is not `active`\", self.name)\n         }\n     }\n }\n@@ -120,12 +122,6 @@ declare_features! (\n     /// macros disappear).\n     (active, allow_internal_unsafe, \"1.0.0\", None, None),\n \n-    /// Allows using the macros:\n-    /// + `__diagnostic_used`\n-    /// + `__register_diagnostic`\n-    /// +`__build_diagnostic_array`\n-    (active, rustc_diagnostic_macros, \"1.0.0\", None, None),\n-\n     /// Allows using `#[rustc_const_unstable(feature = \"foo\", ..)]` which\n     /// lets a function to be `const` when opted into with `#![feature(foo)]`.\n     (active, rustc_const_unstable, \"1.0.0\", None, None),\n@@ -478,7 +474,7 @@ declare_features! (\n     (active, precise_pointer_size_matching, \"1.32.0\", Some(56354), None),\n \n     /// Allows relaxing the coherence rules such that\n-    /// `impl<T> ForeignTrait<LocalType> for ForeignType<T> is permitted.\n+    /// `impl<T> ForeignTrait<LocalType> for ForeignType<T>` is permitted.\n     (active, re_rebalance_coherence, \"1.32.0\", Some(55437), None),\n \n     /// Allows using `#[ffi_returns_twice]` on foreign functions.\n@@ -520,7 +516,7 @@ declare_features! (\n     /// Allows `async || body` closures.\n     (active, async_closure, \"1.37.0\", Some(62290), None),\n \n-    /// Allows the use of `#[cfg(doctest)]`, set when rustdoc is collecting doctests\n+    /// Allows the use of `#[cfg(doctest)]`; set when rustdoc is collecting doctests.\n     (active, cfg_doctest, \"1.37.0\", Some(62210), None),\n \n     /// Allows `[x; N]` where `x` is a constant (RFC 2203).\n@@ -529,7 +525,7 @@ declare_features! (\n     /// Allows `impl Trait` to be used inside type aliases (RFC 2515).\n     (active, type_alias_impl_trait, \"1.38.0\", Some(63063), None),\n \n-    /// Allows the use of or-patterns, e.g. `0 | 1`.\n+    /// Allows the use of or-patterns (e.g., `0 | 1`).\n     (active, or_patterns, \"1.38.0\", Some(54883), None),\n \n     // -------------------------------------------------------------------------"}, {"sha": "763c3ffd782df949415a53886d27d23d959722fd", "filename": "src/libsyntax/feature_gate/builtin_attrs.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ffeature_gate%2Fbuiltin_attrs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ffeature_gate%2Fbuiltin_attrs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate%2Fbuiltin_attrs.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -169,7 +169,7 @@ const INTERAL_UNSTABLE: &str = \"this is an internal attribute that will never be\n \n pub type BuiltinAttribute = (Symbol, AttributeType, AttributeTemplate, AttributeGate);\n \n-/// Attributes that have a special meaning to rustc or rustdoc\n+/// Attributes that have a special meaning to rustc or rustdoc.\n pub const BUILTIN_ATTRIBUTES: &[BuiltinAttribute] = &[\n     // ==========================================================================\n     // Stable attributes:"}, {"sha": "5711b269ff092fe12982df3401eae7e690cb7419", "filename": "src/libsyntax/feature_gate/check.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ffeature_gate%2Fcheck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ffeature_gate%2Fcheck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate%2Fcheck.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -920,9 +920,9 @@ pub enum UnstableFeatures {\n \n impl UnstableFeatures {\n     pub fn from_environment() -> UnstableFeatures {\n-        // Whether this is a feature-staged build, i.e., on the beta or stable channel\n+        // `true` if this is a feature-staged build, i.e., on the beta or stable channel.\n         let disable_unstable_features = option_env!(\"CFG_DISABLE_UNSTABLE_FEATURES\").is_some();\n-        // Whether we should enable unstable features for bootstrapping\n+        // `true` if we should enable unstable features for bootstrapping.\n         let bootstrap = env::var(\"RUSTC_BOOTSTRAP\").is_ok();\n         match (disable_unstable_features, bootstrap) {\n             (_, true) => UnstableFeatures::Cheat,"}, {"sha": "2c29e1ebf1493c4089fab7adaea5a7df4fcfa542", "filename": "src/libsyntax/feature_gate/removed.rs", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ffeature_gate%2Fremoved.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ffeature_gate%2Fremoved.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate%2Fremoved.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -94,6 +94,11 @@ declare_features! (\n     /// Allows defining `existential type`s.\n     (removed, existential_type, \"1.38.0\", Some(63063), None,\n      Some(\"removed in favor of `#![feature(type_alias_impl_trait)]`\")),\n+    /// Allows using the macros:\n+    /// + `__diagnostic_used`\n+    /// + `__register_diagnostic`\n+    /// +`__build_diagnostic_array`\n+    (removed, rustc_diagnostic_macros, \"1.38.0\", None, None, None),\n \n     // -------------------------------------------------------------------------\n     // feature-group-end: removed features"}, {"sha": "49efbce482fa36e29850d035b32d19fea0f6aef8", "filename": "src/libsyntax/lib.rs", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -18,7 +18,6 @@\n #![feature(proc_macro_diagnostic)]\n #![feature(proc_macro_internals)]\n #![feature(proc_macro_span)]\n-#![feature(rustc_diagnostic_macros)]\n #![feature(try_trait)]\n #![feature(unicode_internals)]\n \n@@ -123,11 +122,8 @@ scoped_tls::scoped_thread_local!(pub static GLOBALS: Globals);\n pub mod diagnostics {\n     #[macro_use]\n     pub mod macros;\n-    pub mod plugin;\n }\n \n-// N.B., this module needs to be declared first so diagnostics are\n-// registered before they are used.\n pub mod error_codes;\n \n pub mod util {\n@@ -182,5 +178,3 @@ pub mod ext {\n }\n \n pub mod early_buffered_lints;\n-\n-__build_diagnostic_array! { libsyntax, DIAGNOSTICS }"}, {"sha": "1c35688666836350d9dcc8afb7d30a70d3cfedf3", "filename": "src/libsyntax/mut_visit.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fmut_visit.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,10 +1,10 @@\n-//! A MutVisitor represents an AST modification; it accepts an AST piece and\n-//! and mutates it in place. So, for instance, macro expansion is a MutVisitor\n+//! A `MutVisitor` represents an AST modification; it accepts an AST piece and\n+//! and mutates it in place. So, for instance, macro expansion is a `MutVisitor`\n //! that walks over an AST and modifies it.\n //!\n-//! Note: using a MutVisitor (other than the MacroExpander MutVisitor) on\n+//! Note: using a `MutVisitor` (other than the `MacroExpander` `MutVisitor`) on\n //! an AST before macro expansion is probably a bad idea. For instance,\n-//! a MutVisitor renaming item names in a module will miss all of those\n+//! a `MutVisitor` renaming item names in a module will miss all of those\n //! that are created by the expansion of a macro.\n \n use crate::ast::*;\n@@ -614,7 +614,7 @@ pub fn noop_visit_tts<T: MutVisitor>(TokenStream(tts): &mut TokenStream, vis: &m\n     })\n }\n \n-// Apply ident visitor if it's an ident, apply other visits to interpolated nodes.\n+// Applies ident visitor if it's an ident; applies other visits to interpolated nodes.\n // In practice the ident part is not actually used by specific visitors right now,\n // but there's a test below checking that it works.\n pub fn noop_visit_token<T: MutVisitor>(t: &mut Token, vis: &mut T) {\n@@ -625,7 +625,7 @@ pub fn noop_visit_token<T: MutVisitor>(t: &mut Token, vis: &mut T) {\n             vis.visit_ident(&mut ident);\n             *name = ident.name;\n             *span = ident.span;\n-            return; // avoid visiting the span for the second time\n+            return; // Avoid visiting the span for the second time.\n         }\n         token::Interpolated(nt) => {\n             let mut nt = Lrc::make_mut(nt);\n@@ -636,28 +636,28 @@ pub fn noop_visit_token<T: MutVisitor>(t: &mut Token, vis: &mut T) {\n     vis.visit_span(span);\n }\n \n-/// Apply visitor to elements of interpolated nodes.\n+/// Applies the visitor to elements of interpolated nodes.\n //\n // N.B., this can occur only when applying a visitor to partially expanded\n // code, where parsed pieces have gotten implanted ito *other* macro\n // invocations. This is relevant for macro hygiene, but possibly not elsewhere.\n //\n // One problem here occurs because the types for flat_map_item, flat_map_stmt,\n-// etc. allow the visitor to return *multiple* items; this is a problem for the\n+// etc., allow the visitor to return *multiple* items; this is a problem for the\n // nodes here, because they insist on having exactly one piece. One solution\n // would be to mangle the MutVisitor trait to include one-to-many and\n // one-to-one versions of these entry points, but that would probably confuse a\n // lot of people and help very few. Instead, I'm just going to put in dynamic\n // checks. I think the performance impact of this will be pretty much\n-// nonexistent. The danger is that someone will apply a MutVisitor to a\n+// nonexistent. The danger is that someone will apply a `MutVisitor` to a\n // partially expanded node, and will be confused by the fact that their\n-// \"flat_map_item\" or \"flat_map_stmt\" isn't getting called on NtItem or NtStmt\n+// `flat_map_item` or `flat_map_stmt` isn't getting called on `NtItem` or `NtStmt`\n // nodes. Hopefully they'll wind up reading this comment, and doing something\n // appropriate.\n //\n-// BTW, design choice: I considered just changing the type of, e.g., NtItem to\n+// BTW, design choice: I considered just changing the type of, e.g., `NtItem` to\n // contain multiple items, but decided against it when I looked at\n-// parse_item_or_view_item and tried to figure out what I would do with\n+// `parse_item_or_view_item` and tried to figure out what I would do with\n // multiple items there....\n pub fn noop_visit_interpolated<T: MutVisitor>(nt: &mut token::Nonterminal, vis: &mut T) {\n     match nt {\n@@ -1014,7 +1014,7 @@ pub fn noop_visit_crate<T: MutVisitor>(krate: &mut Crate, vis: &mut T) {\n     });\n }\n \n-// Mutate one item into possibly many items.\n+// Mutates one item into possibly many items.\n pub fn noop_flat_map_item<T: MutVisitor>(mut item: P<Item>, visitor: &mut T)\n                                          -> SmallVec<[P<Item>; 1]> {\n     let Item { ident, attrs, id, node, vis, span, tokens: _ } = item.deref_mut();\n@@ -1224,7 +1224,7 @@ pub fn noop_visit_expr<T: MutVisitor>(Expr { node, id, span, attrs }: &mut Expr,\n         ExprKind::Paren(expr) => {\n             vis.visit_expr(expr);\n \n-            // Nodes that are equal modulo `Paren` sugar no-ops should have the same ids.\n+            // Nodes that are equal modulo `Paren` sugar no-ops should have the same IDs.\n             *id = expr.id;\n             vis.visit_span(span);\n             visit_thin_attrs(attrs, vis);"}, {"sha": "f779e0d0a601471d4064570c9fc25d1824c62129", "filename": "src/libsyntax/mut_visit/tests.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fmut_visit%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fmut_visit%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fmut_visit%2Ftests.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -6,13 +6,13 @@ use crate::print::pprust;\n use crate::mut_visit;\n use crate::with_default_globals;\n \n-// this version doesn't care about getting comments or docstrings in.\n+// This version doesn't care about getting comments or doc-strings in.\n fn fake_print_crate(s: &mut pprust::State<'_>,\n                     krate: &ast::Crate) {\n     s.print_mod(&krate.module, &krate.attrs)\n }\n \n-// change every identifier to \"zz\"\n+// Change every identifier to \"zz\".\n struct ToZzIdentMutVisitor;\n \n impl MutVisitor for ToZzIdentMutVisitor {\n@@ -24,7 +24,7 @@ impl MutVisitor for ToZzIdentMutVisitor {\n     }\n }\n \n-// maybe add to expand.rs...\n+// Maybe add to `expand.rs`.\n macro_rules! assert_pred {\n     ($pred:expr, $predname:expr, $a:expr , $b:expr) => (\n         {\n@@ -39,7 +39,7 @@ macro_rules! assert_pred {\n     )\n }\n \n-// make sure idents get transformed everywhere\n+// Make sure idents get transformed everywhere.\n #[test] fn ident_transformation () {\n     with_default_globals(|| {\n         let mut zz_visitor = ToZzIdentMutVisitor;\n@@ -54,7 +54,7 @@ macro_rules! assert_pred {\n     })\n }\n \n-// even inside macro defs....\n+// Make sure idents get transformed even inside macro defs.\n #[test] fn ident_transformation_in_defs () {\n     with_default_globals(|| {\n         let mut zz_visitor = ToZzIdentMutVisitor;"}, {"sha": "9aa1ec0b14fe962f5388c90590b6392b081f866c", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -26,7 +26,7 @@ impl<'a> Parser<'a> {\n         Ok(attrs)\n     }\n \n-    /// Parse attributes that appear before an item\n+    /// Parses attributes that appear before an item.\n     crate fn parse_outer_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n         let mut attrs: Vec<ast::Attribute> = Vec::new();\n         let mut just_parsed_doc_comment = false;\n@@ -69,10 +69,10 @@ impl<'a> Parser<'a> {\n         Ok(attrs)\n     }\n \n-    /// Matches `attribute = # ! [ meta_item ]`\n+    /// Matches `attribute = # ! [ meta_item ]`.\n     ///\n-    /// If permit_inner is true, then a leading `!` indicates an inner\n-    /// attribute\n+    /// If `permit_inner` is `true`, then a leading `!` indicates an inner\n+    /// attribute.\n     pub fn parse_attribute(&mut self, permit_inner: bool) -> PResult<'a, ast::Attribute> {\n         debug!(\"parse_attribute: permit_inner={:?} self.token={:?}\",\n                permit_inner,\n@@ -167,14 +167,14 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    /// Parse an inner part of attribute - path and following tokens.\n+    /// Parses an inner part of an attribute (the path and following tokens).\n     /// The tokens must be either a delimited token stream, or empty token stream,\n     /// or the \"legacy\" key-value form.\n-    /// PATH `(` TOKEN_STREAM `)`\n-    /// PATH `[` TOKEN_STREAM `]`\n-    /// PATH `{` TOKEN_STREAM `}`\n-    /// PATH\n-    /// PATH `=` TOKEN_TREE\n+    ///     PATH `(` TOKEN_STREAM `)`\n+    ///     PATH `[` TOKEN_STREAM `]`\n+    ///     PATH `{` TOKEN_STREAM `}`\n+    ///     PATH\n+    ///     PATH `=` TOKEN_TREE\n     /// The delimiters or `=` are still put into the resulting token stream.\n     pub fn parse_meta_item_unrestricted(&mut self) -> PResult<'a, (ast::Path, TokenStream)> {\n         let meta = match self.token.kind {\n@@ -217,11 +217,11 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    /// Parse attributes that appear after the opening of an item. These should\n+    /// Parses attributes that appear after the opening of an item. These should\n     /// be preceded by an exclamation mark, but we accept and warn about one\n     /// terminated by a semicolon.\n-\n-    /// matches inner_attrs*\n+    ///\n+    /// Matches `inner_attrs*`.\n     crate fn parse_inner_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n         let mut attrs: Vec<ast::Attribute> = vec![];\n         loop {\n@@ -237,7 +237,7 @@ impl<'a> Parser<'a> {\n                     attrs.push(attr);\n                 }\n                 token::DocComment(s) => {\n-                    // we need to get the position of this token before we bump.\n+                    // We need to get the position of this token before we bump.\n                     let attr = attr::mk_sugared_doc_attr(s, self.token.span);\n                     if attr.style == ast::AttrStyle::Inner {\n                         attrs.push(attr);\n@@ -268,10 +268,10 @@ impl<'a> Parser<'a> {\n         Ok(lit)\n     }\n \n-    /// Per RFC#1559, matches the following grammar:\n+    /// Matches the following grammar (per RFC 1559).\n     ///\n-    /// meta_item : IDENT ( '=' UNSUFFIXED_LIT | '(' meta_item_inner? ')' )? ;\n-    /// meta_item_inner : (meta_item | UNSUFFIXED_LIT) (',' meta_item_inner)? ;\n+    ///     meta_item : IDENT ( '=' UNSUFFIXED_LIT | '(' meta_item_inner? ')' )? ;\n+    ///     meta_item_inner : (meta_item | UNSUFFIXED_LIT) (',' meta_item_inner)? ;\n     pub fn parse_meta_item(&mut self) -> PResult<'a, ast::MetaItem> {\n         let nt_meta = match self.token.kind {\n             token::Interpolated(ref nt) => match **nt {\n@@ -303,7 +303,7 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    /// matches meta_item_inner : (meta_item | UNSUFFIXED_LIT) ;\n+    /// Matches `meta_item_inner : (meta_item | UNSUFFIXED_LIT) ;`.\n     fn parse_meta_item_inner(&mut self) -> PResult<'a, ast::NestedMetaItem> {\n         match self.parse_unsuffixed_lit() {\n             Ok(lit) => {\n@@ -324,7 +324,7 @@ impl<'a> Parser<'a> {\n         Err(self.diagnostic().struct_span_err(self.token.span, &msg))\n     }\n \n-    /// matches meta_seq = ( COMMASEP(meta_item_inner) )\n+    /// Matches `meta_seq = ( COMMASEP(meta_item_inner) )`.\n     fn parse_meta_seq(&mut self) -> PResult<'a, Vec<ast::NestedMetaItem>> {\n         self.parse_seq_to_end(&token::CloseDelim(token::Paren),\n                               SeqSep::trailing_allowed(token::Comma),"}, {"sha": "3120d0e35173ddfe440e567bf554d3352db1b5b5", "filename": "src/libsyntax/parse/diagnostics.rs", "status": "modified", "additions": 37, "deletions": 37, "changes": 74, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -240,7 +240,7 @@ impl<'a> Parser<'a> {\n     ) -> PResult<'a, bool /* recovered */> {\n         fn tokens_to_string(tokens: &[TokenType]) -> String {\n             let mut i = tokens.iter();\n-            // This might be a sign we need a connect method on Iterator.\n+            // This might be a sign we need a connect method on `Iterator`.\n             let b = i.next()\n                      .map_or(String::new(), |t| t.to_string());\n             i.enumerate().fold(b, |mut b, (i, a)| {\n@@ -301,7 +301,7 @@ impl<'a> Parser<'a> {\n             );\n         }\n         let sp = if self.token == token::Eof {\n-            // This is EOF, don't want to point at the following char, but rather the last token\n+            // This is EOF; don't want to point at the following char, but rather the last token.\n             self.prev_span\n         } else {\n             label_sp\n@@ -317,9 +317,9 @@ impl<'a> Parser<'a> {\n         }\n \n         let is_semi_suggestable = expected.iter().any(|t| match t {\n-            TokenType::Token(token::Semi) => true, // we expect a `;` here\n+            TokenType::Token(token::Semi) => true, // We expect a `;` here.\n             _ => false,\n-        }) && ( // a `;` would be expected before the current keyword\n+        }) && ( // A `;` would be expected before the current keyword.\n             self.token.is_keyword(kw::Break) ||\n             self.token.is_keyword(kw::Continue) ||\n             self.token.is_keyword(kw::For) ||\n@@ -541,16 +541,16 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Produce an error if comparison operators are chained (RFC #558).\n-    /// We only need to check lhs, not rhs, because all comparison ops\n-    /// have same precedence and are left-associative\n+    /// Produces an error if comparison operators are chained (RFC #558).\n+    /// We only need to check the LHS, not the RHS, because all comparison ops\n+    /// have same precedence and are left-associative.\n     crate fn check_no_chained_comparison(&self, lhs: &Expr, outer_op: &AssocOp) -> PResult<'a, ()> {\n         debug_assert!(outer_op.is_comparison(),\n                       \"check_no_chained_comparison: {:?} is not comparison\",\n                       outer_op);\n         match lhs.node {\n             ExprKind::Binary(op, _, _) if op.node.is_comparison() => {\n-                // respan to include both operators\n+                // Respan to include both operators.\n                 let op_span = op.span.to(self.token.span);\n                 let mut err = self.struct_span_err(\n                     op_span,\n@@ -691,9 +691,9 @@ impl<'a> Parser<'a> {\n         Ok(())\n     }\n \n-    /// Try to recover from associated item paths like `[T]::AssocItem`/`(T, U)::AssocItem`.\n-    /// Attempt to convert the base expression/pattern/type into a type, parse the `::AssocItem`\n-    /// tail, and combine them into a `<Ty>::AssocItem` expression/pattern/type.\n+    /// Tries to recover from associated item paths like `[T]::AssocItem` / `(T, U)::AssocItem`.\n+    /// Attempts to convert the base expression/pattern/type into a type, parses the `::AssocItem`\n+    /// tail, and combines them into a `<Ty>::AssocItem` expression/pattern/type.\n     crate fn maybe_recover_from_bad_qpath<T: RecoverQPath>(\n         &mut self,\n         base: P<T>,\n@@ -708,8 +708,8 @@ impl<'a> Parser<'a> {\n         Ok(base)\n     }\n \n-    /// Given an already parsed `Ty` parse the `::AssocItem` tail and\n-    /// combine them into a `<Ty>::AssocItem` expression/pattern/type.\n+    /// Given an already parsed `Ty`, parses the `::AssocItem` tail and\n+    /// combines them into a `<Ty>::AssocItem` expression/pattern/type.\n     crate fn maybe_recover_from_bad_qpath_stage_2<T: RecoverQPath>(\n         &mut self,\n         ty_span: Span,\n@@ -730,15 +730,15 @@ impl<'a> Parser<'a> {\n         self.diagnostic()\n             .struct_span_err(path.span, \"missing angle brackets in associated item path\")\n             .span_suggestion(\n-                // this is a best-effort recovery\n+                // This is a best-effort recovery.\n                 path.span,\n                 \"try\",\n                 format!(\"<{}>::{}\", ty_str, path),\n                 Applicability::MaybeIncorrect,\n             )\n             .emit();\n \n-        let path_span = ty_span.shrink_to_hi(); // use an empty path since `position` == 0\n+        let path_span = ty_span.shrink_to_hi(); // Use an empty path since `position == 0`.\n         Ok(P(T::recovered(\n             Some(QSelf {\n                 ty,\n@@ -761,8 +761,8 @@ impl<'a> Parser<'a> {\n             if !items.is_empty() {\n                 let previous_item = &items[items.len() - 1];\n                 let previous_item_kind_name = match previous_item.node {\n-                    // say \"braced struct\" because tuple-structs and\n-                    // braceless-empty-struct declarations do take a semicolon\n+                    // Say \"braced struct\" because tuple-structs and\n+                    // braceless-empty-struct declarations do take a semicolon.\n                     ItemKind::Struct(..) => Some(\"braced struct\"),\n                     ItemKind::Enum(..) => Some(\"enum\"),\n                     ItemKind::Trait(..) => Some(\"trait\"),\n@@ -783,7 +783,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Create a `DiagnosticBuilder` for an unexpected token `t` and try to recover if it is a\n+    /// Creates a `DiagnosticBuilder` for an unexpected token `t` and tries to recover if it is a\n     /// closing delimiter.\n     pub fn unexpected_try_recover(\n         &mut self,\n@@ -841,7 +841,7 @@ impl<'a> Parser<'a> {\n         extern_sp: Span,\n     ) -> PResult<'a, ()> {\n         if self.token != token::Semi {\n-            // this might be an incorrect fn definition (#62109)\n+            // This might be an incorrect fn definition (#62109).\n             let parser_snapshot = self.clone();\n             match self.parse_inner_attrs_and_block() {\n                 Ok((_, body)) => {\n@@ -871,7 +871,7 @@ impl<'a> Parser<'a> {\n         Ok(())\n     }\n \n-    /// Consume alternative await syntaxes like `await!(<expr>)`, `await <expr>`,\n+    /// Consumes alternative await syntaxes like `await!(<expr>)`, `await <expr>`,\n     /// `await? <expr>`, `await(<expr>)`, and `await { <expr> }`.\n     crate fn parse_incorrect_await_syntax(\n         &mut self,\n@@ -924,7 +924,7 @@ impl<'a> Parser<'a> {\n         sp\n     }\n \n-    /// If encountering `future.await()`, consume and emit error.\n+    /// If encountering `future.await()`, consumes and emits an error.\n     crate fn recover_from_await_method_call(&mut self) {\n         if self.token == token::OpenDelim(token::Paren) &&\n             self.look_ahead(1, |t| t == &token::CloseDelim(token::Paren))\n@@ -944,7 +944,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Recover a situation like `for ( $pat in $expr )`\n+    /// Recovers a situation like `for ( $pat in $expr )`\n     /// and suggest writing `for $pat in $expr` instead.\n     ///\n     /// This should be called before parsing the `$block`.\n@@ -1010,7 +1010,7 @@ impl<'a> Parser<'a> {\n             Ok(x) => x,\n             Err(mut err) => {\n                 err.emit();\n-                // recover from parse error\n+                // Recover from parse error.\n                 self.consume_block(delim);\n                 self.mk_expr(lo.to(self.prev_span), ExprKind::Err, ThinVec::new())\n             }\n@@ -1023,7 +1023,7 @@ impl<'a> Parser<'a> {\n         mut err: DiagnosticBuilder<'a>,\n     ) -> PResult<'a, bool> {\n         let mut pos = None;\n-        // we want to use the last closing delim that would apply\n+        // We want to use the last closing delim that would apply.\n         for (i, unmatched) in self.unclosed_delims.iter().enumerate().rev() {\n             if tokens.contains(&token::CloseDelim(unmatched.expected_delim))\n                 && Some(self.token.span) > unmatched.unclosed_span\n@@ -1041,7 +1041,7 @@ impl<'a> Parser<'a> {\n                 let unmatched = self.unclosed_delims.remove(pos);\n                 let delim = TokenType::Token(token::CloseDelim(unmatched.expected_delim));\n \n-                 // We want to suggest the inclusion of the closing delimiter where it makes\n+                // We want to suggest the inclusion of the closing delimiter where it makes\n                 // the most sense, which is immediately after the last token:\n                 //\n                 //  {foo(bar {}}\n@@ -1067,7 +1067,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Recover from `pub` keyword in places where it seems _reasonable_ but isn't valid.\n+    /// Recovers from `pub` keyword in places where it seems _reasonable_ but isn't valid.\n     crate fn eat_bad_pub(&mut self) {\n         if self.token.is_keyword(kw::Pub) {\n             match self.parse_visibility(false) {\n@@ -1082,21 +1082,21 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    // Eat tokens until we can be relatively sure we reached the end of the\n-    // statement. This is something of a best-effort heuristic.\n-    //\n-    // We terminate when we find an unmatched `}` (without consuming it).\n+    /// Eats tokens until we can be relatively sure we reached the end of the\n+    /// statement. This is something of a best-effort heuristic.\n+    ///\n+    /// We terminate when we find an unmatched `}` (without consuming it).\n     crate fn recover_stmt(&mut self) {\n         self.recover_stmt_(SemiColonMode::Ignore, BlockMode::Ignore)\n     }\n \n-    // If `break_on_semi` is `Break`, then we will stop consuming tokens after\n-    // finding (and consuming) a `;` outside of `{}` or `[]` (note that this is\n-    // approximate - it can mean we break too early due to macros, but that\n-    // should only lead to sub-optimal recovery, not inaccurate parsing).\n-    //\n-    // If `break_on_block` is `Break`, then we will stop consuming tokens\n-    // after finding (and consuming) a brace-delimited block.\n+    /// If `break_on_semi` is `Break`, then we will stop consuming tokens after\n+    /// finding (and consuming) a `;` outside of `{}` or `[]` (note that this is\n+    /// approximate -- it can mean we break too early due to macros, but that\n+    /// should only lead to sub-optimal recovery, not inaccurate parsing).\n+    ///\n+    /// If `break_on_block` is `Break`, then we will stop consuming tokens\n+    /// after finding (and consuming) a brace-delimited block.\n     crate fn recover_stmt_(&mut self, break_on_semi: SemiColonMode, break_on_block: BlockMode) {\n         let mut brace_depth = 0;\n         let mut bracket_depth = 0;"}, {"sha": "c1ec41902e2bea58032c415ea1a10557fdfdbfb0", "filename": "src/libsyntax/parse/lexer/tests.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -4,9 +4,10 @@ use crate::symbol::Symbol;\n use crate::source_map::{SourceMap, FilePathMapping};\n use crate::parse::token;\n use crate::with_default_globals;\n+\n+use errors::{Handler, emitter::EmitterWriter};\n use std::io;\n use std::path::PathBuf;\n-use errors::{Handler, emitter::EmitterWriter};\n use syntax_pos::{BytePos, Span};\n \n fn mk_sess(sm: Lrc<SourceMap>) -> ParseSess {\n@@ -21,7 +22,7 @@ fn mk_sess(sm: Lrc<SourceMap>) -> ParseSess {\n     ParseSess::with_span_handler(Handler::with_emitter(true, None, Box::new(emitter)), sm)\n }\n \n-// open a string reader for the given string\n+// Creates a string reader for the given string.\n fn setup<'a>(sm: &SourceMap,\n                 sess: &'a ParseSess,\n                 teststr: String)\n@@ -50,7 +51,7 @@ fn t1() {\n         assert_eq!(tok1.kind, tok2.kind);\n         assert_eq!(tok1.span, tok2.span);\n         assert_eq!(string_reader.next_token(), token::Whitespace);\n-        // read another token:\n+        // Read another token.\n         let tok3 = string_reader.next_token();\n         assert_eq!(string_reader.pos.clone(), BytePos(28));\n         let tok4 = Token::new(\n@@ -65,15 +66,15 @@ fn t1() {\n     })\n }\n \n-// check that the given reader produces the desired stream\n-// of tokens (stop checking after exhausting the expected vec)\n+// Checks that the given reader produces the desired stream\n+// of tokens (stop checking after exhausting `expected`).\n fn check_tokenization(mut string_reader: StringReader<'_>, expected: Vec<TokenKind>) {\n     for expected_tok in &expected {\n         assert_eq!(&string_reader.next_token(), expected_tok);\n     }\n }\n \n-// make the identifier by looking up the string in the interner\n+// Makes the identifier by looking up the string in the interner.\n fn mk_ident(id: &str) -> TokenKind {\n     token::Ident(Symbol::intern(id), false)\n }\n@@ -201,7 +202,7 @@ fn literal_suffixes() {\n                     setup(&sm, &sh, format!(\"{}suffix\", $input)).next_token(),\n                     mk_lit(token::$tok_type, $tok_contents, Some(\"suffix\")),\n                 );\n-                // with a whitespace separator:\n+                // with a whitespace separator\n                 assert_eq!(\n                     setup(&sm, &sh, format!(\"{} suffix\", $input)).next_token(),\n                     mk_lit(token::$tok_type, $tok_contents, None),"}, {"sha": "bc1bc00ac84054ac0f359bec86e52aafd66ba259", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 27, "deletions": 30, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -8,17 +8,16 @@ use crate::parse::parser::Parser;\n use crate::parse::parser::emit_unclosed_delims;\n use crate::parse::token::TokenKind;\n use crate::tokenstream::{TokenStream, TokenTree};\n-use crate::diagnostics::plugin::ErrorMap;\n use crate::print::pprust;\n use crate::symbol::Symbol;\n \n use errors::{Applicability, FatalError, Level, Handler, ColorConfig, Diagnostic, DiagnosticBuilder};\n+use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n use rustc_data_structures::sync::{Lrc, Lock, Once};\n use syntax_pos::{Span, SourceFile, FileName, MultiSpan};\n use syntax_pos::edition::Edition;\n use syntax_pos::hygiene::ExpnId;\n \n-use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n use std::borrow::Cow;\n use std::path::{Path, PathBuf};\n use std::str;\n@@ -64,8 +63,6 @@ pub struct ParseSess {\n     pub missing_fragment_specifiers: Lock<FxHashSet<Span>>,\n     /// Places where raw identifiers were used. This is used for feature-gating raw identifiers.\n     pub raw_identifier_spans: Lock<Vec<Span>>,\n-    /// The registered diagnostics codes.\n-    crate registered_diagnostics: Lock<ErrorMap>,\n     /// Used to determine and report recursive module inclusions.\n     included_mod_stack: Lock<Vec<PathBuf>>,\n     source_map: Lrc<SourceMap>,\n@@ -81,25 +78,26 @@ pub struct ParseSess {\n impl ParseSess {\n     pub fn new(file_path_mapping: FilePathMapping) -> Self {\n         let cm = Lrc::new(SourceMap::new(file_path_mapping));\n-        let handler = Handler::with_tty_emitter(ColorConfig::Auto,\n-                                                true,\n-                                                None,\n-                                                Some(cm.clone()));\n+        let handler = Handler::with_tty_emitter(\n+            ColorConfig::Auto,\n+            true,\n+            None,\n+            Some(cm.clone()),\n+        );\n         ParseSess::with_span_handler(handler, cm)\n     }\n \n-    pub fn with_span_handler(handler: Handler, source_map: Lrc<SourceMap>) -> ParseSess {\n-        ParseSess {\n+    pub fn with_span_handler(handler: Handler, source_map: Lrc<SourceMap>) -> Self {\n+        Self {\n             span_diagnostic: handler,\n             unstable_features: UnstableFeatures::from_environment(),\n             config: FxHashSet::default(),\n+            edition: ExpnId::root().expn_data().edition,\n             missing_fragment_specifiers: Lock::new(FxHashSet::default()),\n             raw_identifier_spans: Lock::new(Vec::new()),\n-            registered_diagnostics: Lock::new(ErrorMap::new()),\n             included_mod_stack: Lock::new(vec![]),\n             source_map,\n             buffered_lints: Lock::new(vec![]),\n-            edition: ExpnId::root().expn_data().edition,\n             ambiguous_block_expr_parse: Lock::new(FxHashMap::default()),\n             injected_crate_name: Once::new(),\n             gated_spans: GatedSpans::default(),\n@@ -155,17 +153,17 @@ pub struct Directory<'a> {\n #[derive(Copy, Clone)]\n pub enum DirectoryOwnership {\n     Owned {\n-        // None if `mod.rs`, `Some(\"foo\")` if we're in `foo.rs`\n+        // None if `mod.rs`, `Some(\"foo\")` if we're in `foo.rs`.\n         relative: Option<ast::Ident>,\n     },\n     UnownedViaBlock,\n     UnownedViaMod(bool /* legacy warnings? */),\n }\n \n-// a bunch of utility functions of the form parse_<thing>_from_<source>\n+// A bunch of utility functions of the form `parse_<thing>_from_<source>`\n // where <thing> includes crate, expr, item, stmt, tts, and one that\n // uses a HOF to parse anything, and <source> includes file and\n-// source_str.\n+// `source_str`.\n \n pub fn parse_crate_from_file<'a>(input: &Path, sess: &'a ParseSess) -> PResult<'a, ast::Crate> {\n     let mut parser = new_parser_from_file(sess, input);\n@@ -219,23 +217,22 @@ pub fn maybe_new_parser_from_source_str(sess: &ParseSess, name: FileName, source\n     Ok(parser)\n }\n \n-/// Creates a new parser, handling errors as appropriate\n-/// if the file doesn't exist\n+/// Creates a new parser, handling errors as appropriate if the file doesn't exist.\n pub fn new_parser_from_file<'a>(sess: &'a ParseSess, path: &Path) -> Parser<'a> {\n     source_file_to_parser(sess, file_to_source_file(sess, path, None))\n }\n \n-/// Creates a new parser, returning buffered diagnostics if the file doesn't\n-/// exist or from lexing the initial token stream.\n+/// Creates a new parser, returning buffered diagnostics if the file doesn't exist,\n+/// or from lexing the initial token stream.\n pub fn maybe_new_parser_from_file<'a>(sess: &'a ParseSess, path: &Path)\n     -> Result<Parser<'a>, Vec<Diagnostic>> {\n     let file = try_file_to_source_file(sess, path, None).map_err(|db| vec![db])?;\n     maybe_source_file_to_parser(sess, file)\n }\n \n /// Given a session, a crate config, a path, and a span, add\n-/// the file at the given path to the source_map, and return a parser.\n-/// On an error, use the given span as the source of the problem.\n+/// the file at the given path to the `source_map`, and returns a parser.\n+/// On an error, uses the given span as the source of the problem.\n pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n                                     path: &Path,\n                                     directory_ownership: DirectoryOwnership,\n@@ -247,13 +244,13 @@ pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n     p\n }\n \n-/// Given a source_file and config, return a parser\n+/// Given a `source_file` and config, returns a parser.\n fn source_file_to_parser(sess: &ParseSess, source_file: Lrc<SourceFile>) -> Parser<'_> {\n     panictry_buffer!(&sess.span_diagnostic,\n                      maybe_source_file_to_parser(sess, source_file))\n }\n \n-/// Given a source_file and config, return a parser. Returns any buffered errors from lexing the\n+/// Given a `source_file` and config, return a parser. Returns any buffered errors from lexing the\n /// initial token stream.\n fn maybe_source_file_to_parser(\n     sess: &ParseSess,\n@@ -270,14 +267,14 @@ fn maybe_source_file_to_parser(\n     Ok(parser)\n }\n \n-// must preserve old name for now, because quote! from the *existing*\n-// compiler expands into it\n+// Must preserve old name for now, because `quote!` from the *existing*\n+// compiler expands into it.\n pub fn new_parser_from_tts(sess: &ParseSess, tts: Vec<TokenTree>) -> Parser<'_> {\n     stream_to_parser(sess, tts.into_iter().collect(), crate::MACRO_ARGUMENTS)\n }\n \n \n-// base abstractions\n+// Base abstractions\n \n /// Given a session and a path and an optional span (for error reporting),\n /// add the path to the session's source_map and return the new source_file or\n@@ -296,7 +293,7 @@ fn try_file_to_source_file(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n }\n \n /// Given a session and a path and an optional span (for error reporting),\n-/// add the path to the session's `source_map` and return the new `source_file`.\n+/// adds the path to the session's `source_map` and returns the new `source_file`.\n fn file_to_source_file(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n                    -> Lrc<SourceFile> {\n     match try_file_to_source_file(sess, path, spanopt) {\n@@ -308,7 +305,7 @@ fn file_to_source_file(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n     }\n }\n \n-/// Given a source_file, produces a sequence of token trees.\n+/// Given a `source_file`, produces a sequence of token trees.\n pub fn source_file_to_stream(\n     sess: &ParseSess,\n     source_file: Lrc<SourceFile>,\n@@ -352,7 +349,7 @@ pub fn maybe_file_to_stream(\n     }\n }\n \n-/// Given stream and the `ParseSess`, produces a parser.\n+/// Given a stream and the `ParseSess`, produces a parser.\n pub fn stream_to_parser<'a>(\n     sess: &'a ParseSess,\n     stream: TokenStream,\n@@ -361,7 +358,7 @@ pub fn stream_to_parser<'a>(\n     Parser::new(sess, stream, None, true, false, subparser_name)\n }\n \n-/// Given stream, the `ParseSess` and the base directory, produces a parser.\n+/// Given a stream, the `ParseSess` and the base directory, produces a parser.\n ///\n /// Use this function when you are creating a parser from the token stream\n /// and also care about the current working directory of the parser (e.g.,"}, {"sha": "fcaf5065dac78b8d4b6d7090da344dc1369b5fa6", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -10,22 +10,22 @@ pub use path::PathStyle;\n mod stmt;\n mod generics;\n \n-use crate::ast::{self, AttrStyle, Attribute, Param, BindingMode, StrStyle, SelfKind};\n-use crate::ast::{FnDecl, Ident, IsAsync, MacDelimiter, Mutability, TyKind};\n-use crate::ast::{Visibility, VisibilityKind, Unsafety, CrateSugar};\n-use crate::source_map::{self, respan};\n-use crate::parse::{SeqSep, literal, token};\n+use crate::ast::{\n+    self, DUMMY_NODE_ID, AttrStyle, Attribute, BindingMode, CrateSugar, FnDecl, Ident,\n+    IsAsync, MacDelimiter, Mutability, Param, StrStyle, SelfKind, TyKind, Visibility,\n+    VisibilityKind, Unsafety,\n+};\n+use crate::parse::{ParseSess, PResult, Directory, DirectoryOwnership, SeqSep, literal, token};\n+use crate::parse::diagnostics::{Error, dummy_arg};\n use crate::parse::lexer::UnmatchedBrace;\n use crate::parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use crate::parse::token::{Token, TokenKind, DelimToken};\n-use crate::parse::{ParseSess, Directory, DirectoryOwnership};\n use crate::print::pprust;\n use crate::ptr::P;\n-use crate::parse::PResult;\n-use crate::ThinVec;\n-use crate::tokenstream::{self, DelimSpan, TokenTree, TokenStream, TreeAndJoint};\n+use crate::source_map::{self, respan};\n use crate::symbol::{kw, sym, Symbol};\n-use crate::parse::diagnostics::{Error, dummy_arg};\n+use crate::tokenstream::{self, DelimSpan, TokenTree, TokenStream, TreeAndJoint};\n+use crate::ThinVec;\n \n use errors::{Applicability, DiagnosticId, FatalError};\n use rustc_target::spec::abi::{self, Abi};\n@@ -56,7 +56,7 @@ crate enum BlockMode {\n     Ignore,\n }\n \n-/// As maybe_whole_expr, but for things other than expressions\n+/// Like `maybe_whole_expr`, but for things other than expressions.\n #[macro_export]\n macro_rules! maybe_whole {\n     ($p:expr, $constructor:ident, |$x:ident| $e:expr) => {\n@@ -116,11 +116,11 @@ pub struct Parser<'a> {\n     /// with non-interpolated identifier and lifetime tokens they refer to.\n     /// Perhaps the normalized / non-normalized setup can be simplified somehow.\n     pub token: Token,\n-    /// Span of the current non-normalized token.\n+    /// The span of the current non-normalized token.\n     meta_var_span: Option<Span>,\n-    /// Span of the previous non-normalized token.\n+    /// The span of the previous non-normalized token.\n     pub prev_span: Span,\n-    /// Kind of the previous normalized token (in simplified form).\n+    /// The kind of the previous normalized token (in simplified form).\n     prev_token_kind: PrevTokenKind,\n     restrictions: Restrictions,\n     /// Used to determine the path to externally loaded source files.\n@@ -143,7 +143,7 @@ pub struct Parser<'a> {\n     /// See the comments in the `parse_path_segment` function for more details.\n     crate unmatched_angle_bracket_count: u32,\n     crate max_angle_bracket_count: u32,\n-    /// List of all unclosed delimiters found by the lexer. If an entry is used for error recovery\n+    /// A list of all unclosed delimiters found by the lexer. If an entry is used for error recovery\n     /// it gets removed from here. Every entry left at the end gets emitted as an independent\n     /// error.\n     crate unclosed_delims: Vec<UnmatchedBrace>,\n@@ -799,14 +799,14 @@ impl<'a> Parser<'a> {\n                             break;\n                         }\n                         Err(mut e) => {\n-                            // Attempt to keep parsing if it was a similar separator\n+                            // Attempt to keep parsing if it was a similar separator.\n                             if let Some(ref tokens) = t.similar_tokens() {\n                                 if tokens.contains(&self.token.kind) {\n                                     self.bump();\n                                 }\n                             }\n                             e.emit();\n-                            // Attempt to keep parsing if it was an omitted separator\n+                            // Attempt to keep parsing if it was an omitted separator.\n                             match f(self) {\n                                 Ok(t) => {\n                                     v.push(t);\n@@ -871,7 +871,7 @@ impl<'a> Parser<'a> {\n         self.parse_delim_comma_seq(token::Paren, f)\n     }\n \n-    /// Advance the parser by one token\n+    /// Advance the parser by one token.\n     pub fn bump(&mut self) {\n         if self.prev_token_kind == PrevTokenKind::Eof {\n             // Bumping after EOF is a bad sign, usually an infinite loop.\n@@ -894,17 +894,17 @@ impl<'a> Parser<'a> {\n \n         self.token = self.next_tok();\n         self.expected_tokens.clear();\n-        // check after each token\n+        // Check after each token.\n         self.process_potential_macro_variable();\n     }\n \n-    /// Advance the parser using provided token as a next one. Use this when\n+    /// Advances the parser using provided token as a next one. Use this when\n     /// consuming a part of a token. For example a single `<` from `<<`.\n     fn bump_with(&mut self, next: TokenKind, span: Span) {\n         self.prev_span = self.token.span.with_hi(span.lo());\n         // It would be incorrect to record the kind of the current token, but\n         // fortunately for tokens currently using `bump_with`, the\n-        // prev_token_kind will be of no use anyway.\n+        // `prev_token_kind` will be of no use anyway.\n         self.prev_token_kind = PrevTokenKind::Other;\n         self.token = Token::new(next, span);\n         self.expected_tokens.clear();\n@@ -937,8 +937,8 @@ impl<'a> Parser<'a> {\n     fn parse_asyncness(&mut self) -> IsAsync {\n         if self.eat_keyword(kw::Async) {\n             IsAsync::Async {\n-                closure_id: ast::DUMMY_NODE_ID,\n-                return_impl_trait_id: ast::DUMMY_NODE_ID,\n+                closure_id: DUMMY_NODE_ID,\n+                return_impl_trait_id: DUMMY_NODE_ID,\n             }\n         } else {\n             IsAsync::NotAsync\n@@ -1040,7 +1040,7 @@ impl<'a> Parser<'a> {\n \n         let span = lo.to(self.token.span);\n \n-        Ok(Param { attrs: attrs.into(), id: ast::DUMMY_NODE_ID, pat, span, ty })\n+        Ok(Param { attrs: attrs.into(), id: DUMMY_NODE_ID, pat, span, ty })\n     }\n \n     /// Parses mutability (`mut` or nothing).\n@@ -1497,7 +1497,7 @@ impl<'a> Parser<'a> {\n                         format!(\"in {}\", path),\n                         Applicability::MachineApplicable,\n                     )\n-                    .emit();  // emit diagnostic, but continue with public visibility\n+                    .emit(); // Emit diagnostic, but continue with public visibility.\n             }\n         }\n "}, {"sha": "4dbb5ff75eb216225a8015a7c68593eee8d129b5", "filename": "src/libsyntax/parse/parser/expr.rs", "status": "modified", "additions": 69, "deletions": 72, "changes": 141, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fexpr.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,26 +1,26 @@\n-use super::{Parser, PResult, Restrictions, PrevTokenKind, TokenType, PathStyle};\n-use super::{BlockMode, SemiColonMode};\n-use super::{SeqSep, TokenExpectType};\n+use super::{\n+    Parser, PResult, Restrictions, PrevTokenKind, TokenType, PathStyle, BlockMode, SemiColonMode,\n+    SeqSep, TokenExpectType,\n+};\n use super::pat::{GateOr, PARAM_EXPECTED};\n \n+use crate::ast::{\n+    self, DUMMY_NODE_ID, Attribute, AttrStyle, Ident, CaptureBy, BlockCheckMode,\n+    Expr, ExprKind, RangeLimits, Label, Movability, IsAsync, Arm, Ty, TyKind,\n+    FunctionRetTy, Param, FnDecl, BinOpKind, BinOp, UnOp, Mac, AnonConst, Field,\n+};\n use crate::maybe_recover_from_interpolated_ty_qpath;\n-use crate::ptr::P;\n-use crate::ast::{self, Attribute, AttrStyle, Ident, CaptureBy, BlockCheckMode};\n-use crate::ast::{Expr, ExprKind, RangeLimits, Label, Movability, IsAsync, Arm};\n-use crate::ast::{Ty, TyKind, FunctionRetTy, Param, FnDecl};\n-use crate::ast::{BinOpKind, BinOp, UnOp};\n-use crate::ast::{Mac, AnonConst, Field};\n-\n use crate::parse::classify;\n use crate::parse::token::{self, Token};\n-use crate::parse::diagnostics::{Error};\n+use crate::parse::diagnostics::Error;\n use crate::print::pprust;\n+use crate::ptr::P;\n use crate::source_map::{self, Span};\n use crate::symbol::{kw, sym};\n use crate::util::parser::{AssocOp, Fixity, prec_let_scrutinee_needs_par};\n \n-use std::mem;\n use errors::Applicability;\n+use std::mem;\n use rustc_data_structures::thin_vec::ThinVec;\n \n /// Possibly accepts an `token::Interpolated` expression (a pre-parsed expression\n@@ -51,7 +51,7 @@ macro_rules! maybe_whole_expr {\n                         $p.token.span, ExprKind::Block(block, None), ThinVec::new()\n                     ));\n                 }\n-                // N.B: `NtIdent(ident)` is normalized to `Ident` in `fn bump`.\n+                // N.B., `NtIdent(ident)` is normalized to `Ident` in `fn bump`.\n                 _ => {},\n             };\n         }\n@@ -340,7 +340,7 @@ impl<'a> Parser<'a> {\n \n     fn is_at_start_of_range_notation_rhs(&self) -> bool {\n         if self.token.can_begin_expr() {\n-            // parse `for i in 1.. { }` as infinite loop, not as `for i in (1..{})`.\n+            // Parse `for i in 1.. { }` as infinite loop, not as `for i in (1..{})`.\n             if self.token == token::OpenDelim(token::Brace) {\n                 return !self.restrictions.contains(Restrictions::NO_STRUCT_LITERAL);\n             }\n@@ -350,12 +350,12 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Parse prefix-forms of range notation: `..expr`, `..`, `..=expr`\n+    /// Parses prefix-forms of range notation: `..expr`, `..`, `..=expr`.\n     fn parse_prefix_range_expr(\n         &mut self,\n         already_parsed_attrs: Option<ThinVec<Attribute>>\n     ) -> PResult<'a, P<Expr>> {\n-        // Check for deprecated `...` syntax\n+        // Check for deprecated `...` syntax.\n         if self.token == token::DotDotDot {\n             self.err_dotdotdot_syntax(self.token.span);\n         }\n@@ -389,7 +389,7 @@ impl<'a> Parser<'a> {\n         Ok(self.mk_expr(lo.to(hi), r, attrs))\n     }\n \n-    /// Parse a prefix-unary-operator expr\n+    /// Parses a prefix-unary-operator expr.\n     fn parse_prefix_expr(\n         &mut self,\n         already_parsed_attrs: Option<ThinVec<Attribute>>\n@@ -549,7 +549,7 @@ impl<'a> Parser<'a> {\n                         let expr = mk_expr(self, P(Ty {\n                             span: path.span,\n                             node: TyKind::Path(None, path),\n-                            id: ast::DUMMY_NODE_ID\n+                            id: DUMMY_NODE_ID,\n                         }));\n \n                         let expr_str = self.span_to_snippet(expr.span)\n@@ -565,7 +565,7 @@ impl<'a> Parser<'a> {\n                                 expr.span,\n                                 &format!(\"try {} the cast value\", op_verb),\n                                 format!(\"({})\", expr_str),\n-                                Applicability::MachineApplicable\n+                                Applicability::MachineApplicable,\n                             )\n                             .emit();\n \n@@ -741,7 +741,6 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-\n     /// At the bottom (top?) of the precedence hierarchy,\n     /// Parses things like parenthesized exprs, macros, `return`, etc.\n     ///\n@@ -755,7 +754,7 @@ impl<'a> Parser<'a> {\n         // added to the return value after the fact.\n         //\n         // Therefore, prevent sub-parser from parsing\n-        // attributes by giving them a empty \"already parsed\" list.\n+        // attributes by giving them a empty \"already-parsed\" list.\n         let mut attrs = ThinVec::new();\n \n         let lo = self.token.span;\n@@ -778,7 +777,7 @@ impl<'a> Parser<'a> {\n             }\n         }\n \n-        // Note: when adding new syntax here, don't forget to adjust TokenKind::can_begin_expr().\n+        // Note: when adding new syntax here, don't forget to adjust `TokenKind::can_begin_expr()`.\n         match self.token.kind {\n             // This match arm is a special-case of the `_` match arm below and\n             // could be removed without changing functionality, but it's faster\n@@ -791,16 +790,16 @@ impl<'a> Parser<'a> {\n \n                 attrs.extend(self.parse_inner_attributes()?);\n \n-                // (e) is parenthesized e\n-                // (e,) is a tuple with only one field, e\n+                // `(e)` is parenthesized `e`.\n+                // `(e,)` is a tuple with only one field, `e`.\n                 let mut es = vec![];\n                 let mut trailing_comma = false;\n                 let mut recovered = false;\n                 while self.token != token::CloseDelim(token::Paren) {\n                     es.push(match self.parse_expr() {\n                         Ok(es) => es,\n                         Err(mut err) => {\n-                            // recover from parse error in tuple list\n+                            // Recover from parse error in tuple list.\n                             match self.token.kind {\n                                 token::Ident(name, false)\n                                 if name == kw::Underscore && self.look_ahead(1, |t| {\n@@ -844,29 +843,29 @@ impl<'a> Parser<'a> {\n                 return self.parse_block_expr(None, lo, BlockCheckMode::Default, attrs);\n             }\n             token::BinOp(token::Or) | token::OrOr => {\n-                return self.parse_lambda_expr(attrs);\n+                return self.parse_closure_expr(attrs);\n             }\n             token::OpenDelim(token::Bracket) => {\n                 self.bump();\n \n                 attrs.extend(self.parse_inner_attributes()?);\n \n                 if self.eat(&token::CloseDelim(token::Bracket)) {\n-                    // Empty vector.\n+                    // Empty vector\n                     ex = ExprKind::Array(Vec::new());\n                 } else {\n-                    // Nonempty vector.\n+                    // Non-empty vector\n                     let first_expr = self.parse_expr()?;\n                     if self.eat(&token::Semi) {\n-                        // Repeating array syntax: [ 0; 512 ]\n+                        // Repeating array syntax: `[ 0; 512 ]`\n                         let count = AnonConst {\n-                            id: ast::DUMMY_NODE_ID,\n+                            id: DUMMY_NODE_ID,\n                             value: self.parse_expr()?,\n                         };\n                         self.expect(&token::CloseDelim(token::Bracket))?;\n                         ex = ExprKind::Repeat(first_expr, count);\n                     } else if self.eat(&token::Comma) {\n-                        // Vector with two or more elements.\n+                        // Vector with two or more elements\n                         let remaining_exprs = self.parse_seq_to_end(\n                             &token::CloseDelim(token::Bracket),\n                             SeqSep::trailing_allowed(token::Comma),\n@@ -876,7 +875,7 @@ impl<'a> Parser<'a> {\n                         exprs.extend(remaining_exprs);\n                         ex = ExprKind::Array(exprs);\n                     } else {\n-                        // Vector with one element.\n+                        // Vector with one element\n                         self.expect(&token::CloseDelim(token::Bracket))?;\n                         ex = ExprKind::Array(vec![first_expr]);\n                     }\n@@ -892,7 +891,7 @@ impl<'a> Parser<'a> {\n                 if self.token.is_path_start() {\n                     let path = self.parse_path(PathStyle::Expr)?;\n \n-                    // `!`, as an operator, is prefix, so we know this isn't that\n+                    // `!`, as an operator, is prefix, so we know this isn't that.\n                     if self.eat(&token::Not) {\n                         // MACRO INVOCATION expression\n                         let (delim, tts) = self.expect_delimited_token_tree()?;\n@@ -920,7 +919,7 @@ impl<'a> Parser<'a> {\n                     return self.maybe_recover_from_bad_qpath(expr, true);\n                 }\n                 if self.check_keyword(kw::Move) || self.check_keyword(kw::Static) {\n-                    return self.parse_lambda_expr(attrs);\n+                    return self.parse_closure_expr(attrs);\n                 }\n                 if self.eat_keyword(kw::If) {\n                     return self.parse_if_expr(attrs);\n@@ -991,13 +990,13 @@ impl<'a> Parser<'a> {\n                     return self.parse_try_block(lo, attrs);\n                 }\n \n-                // Span::rust_2018() is somewhat expensive; don't get it repeatedly.\n+                // `Span::rust_2018()` is somewhat expensive; don't get it repeatedly.\n                 let is_span_rust_2018 = self.token.span.rust_2018();\n                 if is_span_rust_2018 && self.check_keyword(kw::Async) {\n-                    return if self.is_async_block() { // check for `async {` and `async move {`\n+                    return if self.is_async_block() { // Check for `async {` and `async move {`.\n                         self.parse_async_block(attrs)\n                     } else {\n-                        self.parse_lambda_expr(attrs)\n+                        self.parse_closure_expr(attrs)\n                     };\n                 }\n                 if self.eat_keyword(kw::Return) {\n@@ -1043,13 +1042,12 @@ impl<'a> Parser<'a> {\n                         // recovery in order to keep the error count down. Fixing the\n                         // delimiters will possibly also fix the bare semicolon found in\n                         // expression context. For example, silence the following error:\n-                        // ```\n-                        // error: expected expression, found `;`\n-                        //  --> file.rs:2:13\n-                        //   |\n-                        // 2 |     foo(bar(;\n-                        //   |             ^ expected expression\n-                        // ```\n+                        //\n+                        //     error: expected expression, found `;`\n+                        //      --> file.rs:2:13\n+                        //       |\n+                        //     2 |     foo(bar(;\n+                        //       |             ^ expected expression\n                         self.bump();\n                         return Ok(self.mk_expr(self.token.span, ExprKind::Err, ThinVec::new()));\n                     }\n@@ -1096,11 +1094,11 @@ impl<'a> Parser<'a> {\n         attrs.extend(self.parse_inner_attributes()?);\n \n         let blk = self.parse_block_tail(lo, blk_mode)?;\n-        return Ok(self.mk_expr(blk.span, ExprKind::Block(blk, opt_label), attrs));\n+        Ok(self.mk_expr(blk.span, ExprKind::Block(blk, opt_label), attrs))\n     }\n \n-    /// Parses `move |args| expr`.\n-    fn parse_lambda_expr(&mut self, attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n+    /// Parses a closure expression (e.g., `move |args| expr`).\n+    fn parse_closure_expr(&mut self, attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         let lo = self.token.span;\n \n         let movability = if self.eat_keyword(kw::Static) {\n@@ -1115,7 +1113,7 @@ impl<'a> Parser<'a> {\n             IsAsync::NotAsync\n         };\n         if asyncness.is_async() {\n-            // Feature gate `async ||` closures.\n+            // Feature-gate `async ||` closures.\n             self.sess.gated_spans.async_closure.borrow_mut().push(self.prev_span);\n         }\n \n@@ -1128,8 +1126,7 @@ impl<'a> Parser<'a> {\n                 self.parse_expr_res(restrictions, None)?\n             },\n             _ => {\n-                // If an explicit return type is given, require a\n-                // block to appear (RFC 968).\n+                // If an explicit return type is given, require a block to appear (RFC 968).\n                 let body_lo = self.token.span;\n                 self.parse_block_expr(None, body_lo, BlockCheckMode::Default, ThinVec::new())?\n             }\n@@ -1141,7 +1138,7 @@ impl<'a> Parser<'a> {\n             attrs))\n     }\n \n-    /// Parse an optional `move` prefix to a closure lke construct.\n+    /// Parses an optional `move` prefix to a closure lke construct.\n     fn parse_capture_clause(&mut self) -> CaptureBy {\n         if self.eat_keyword(kw::Move) {\n             CaptureBy::Value\n@@ -1176,7 +1173,7 @@ impl<'a> Parser<'a> {\n         }))\n     }\n \n-    /// Parses a parameter in a lambda header (e.g., `|arg, arg|`).\n+    /// Parses a parameter in a closure header (e.g., `|arg, arg|`).\n     fn parse_fn_block_param(&mut self) -> PResult<'a, Param> {\n         let lo = self.token.span;\n         let attrs = self.parse_param_attributes()?;\n@@ -1185,7 +1182,7 @@ impl<'a> Parser<'a> {\n             self.parse_ty()?\n         } else {\n             P(Ty {\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 node: TyKind::Infer,\n                 span: self.prev_span,\n             })\n@@ -1196,7 +1193,7 @@ impl<'a> Parser<'a> {\n             ty: t,\n             pat,\n             span,\n-            id: ast::DUMMY_NODE_ID\n+            id: DUMMY_NODE_ID\n         })\n     }\n \n@@ -1233,7 +1230,7 @@ impl<'a> Parser<'a> {\n         Ok(self.mk_expr(lo.to(hi), ExprKind::If(cond, thn, els), attrs))\n     }\n \n-    /// Parse the condition of a `if`- or `while`-expression\n+    /// Parses the condition of a `if` or `while` expression.\n     fn parse_cond_expr(&mut self) -> PResult<'a, P<Expr>> {\n         let cond = self.parse_expr_res(Restrictions::NO_STRUCT_LITERAL, None)?;\n \n@@ -1261,7 +1258,7 @@ impl<'a> Parser<'a> {\n         Ok(self.mk_expr(span, ExprKind::Let(pat, expr), attrs))\n     }\n \n-    /// `else` token already eaten\n+    /// Parses an `else { ... }` expression (`else` token already eaten).\n     fn parse_else_expr(&mut self) -> PResult<'a, P<Expr>> {\n         if self.eat_keyword(kw::If) {\n             return self.parse_if_expr(ThinVec::new());\n@@ -1271,7 +1268,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Parse a 'for' .. 'in' expression ('for' token already eaten)\n+    /// Parses a `for ... in` expression (`for` token already eaten).\n     fn parse_for_expr(\n         &mut self,\n         opt_label: Option<Label>,\n@@ -1327,7 +1324,7 @@ impl<'a> Parser<'a> {\n         Ok(self.mk_expr(span, ExprKind::While(cond, body, opt_label), attrs))\n     }\n \n-    /// Parse `loop {...}`, `loop` token already eaten.\n+    /// Parses `loop { ... }` (`loop` token already eaten).\n     fn parse_loop_expr(\n         &mut self,\n         opt_label: Option<Label>,\n@@ -1350,7 +1347,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    // `match` token already eaten\n+    /// Parses a `match ... { ... }` expression (`match` token already eaten).\n     fn parse_match_expr(&mut self, mut attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         let match_span = self.prev_span;\n         let lo = self.prev_span;\n@@ -1457,7 +1454,7 @@ impl<'a> Parser<'a> {\n             guard,\n             body: expr,\n             span: lo.to(hi),\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n         })\n     }\n \n@@ -1491,7 +1488,7 @@ impl<'a> Parser<'a> {\n         self.token.is_keyword(kw::Try) &&\n         self.look_ahead(1, |t| *t == token::OpenDelim(token::Brace)) &&\n         self.token.span.rust_2018() &&\n-        // prevent `while try {} {}`, `if try {} {} else {}`, etc.\n+        // Prevent `while try {} {}`, `if try {} {} else {}`, etc.\n         !self.restrictions.contains(Restrictions::NO_STRUCT_LITERAL)\n     }\n \n@@ -1504,7 +1501,7 @@ impl<'a> Parser<'a> {\n         attrs.extend(iattrs);\n         Ok(self.mk_expr(\n             span_lo.to(body.span),\n-            ExprKind::Async(capture_clause, ast::DUMMY_NODE_ID, body), attrs))\n+            ExprKind::Async(capture_clause, DUMMY_NODE_ID, body), attrs))\n     }\n \n     fn is_async_block(&self) -> bool {\n@@ -1527,18 +1524,18 @@ impl<'a> Parser<'a> {\n     ) -> Option<PResult<'a, P<Expr>>> {\n         let struct_allowed = !self.restrictions.contains(Restrictions::NO_STRUCT_LITERAL);\n         let certainly_not_a_block = || self.look_ahead(1, |t| t.is_ident()) && (\n-            // `{ ident, ` cannot start a block\n+            // `{ ident, ` cannot start a block.\n             self.look_ahead(2, |t| t == &token::Comma) ||\n             self.look_ahead(2, |t| t == &token::Colon) && (\n-                // `{ ident: token, ` cannot start a block\n+                // `{ ident: token, ` cannot start a block.\n                 self.look_ahead(4, |t| t == &token::Comma) ||\n-                // `{ ident: ` cannot start a block unless it's a type ascription `ident: Type`\n+                // `{ ident: ` cannot start a block unless it's a type ascription `ident: Type`.\n                 self.look_ahead(3, |t| !t.can_begin_type())\n             )\n         );\n \n         if struct_allowed || certainly_not_a_block() {\n-            // This is a struct literal, but we don't can't accept them here\n+            // This is a struct literal, but we don't can't accept them here.\n             let expr = self.parse_struct_expr(lo, path.clone(), attrs.clone());\n             if let (Ok(expr), false) = (&expr, struct_allowed) {\n                 self.struct_span_err(\n@@ -1606,14 +1603,14 @@ impl<'a> Parser<'a> {\n             let mut recovery_field = None;\n             if let token::Ident(name, _) = self.token.kind {\n                 if !self.token.is_reserved_ident() && self.look_ahead(1, |t| *t == token::Colon) {\n-                    // Use in case of error after field-looking code: `S { foo: () with a }`\n+                    // Use in case of error after field-looking code: `S { foo: () with a }`.\n                     recovery_field = Some(ast::Field {\n                         ident: Ident::new(name, self.token.span),\n                         span: self.token.span,\n                         expr: self.mk_expr(self.token.span, ExprKind::Err, ThinVec::new()),\n                         is_shorthand: false,\n                         attrs: ThinVec::new(),\n-                        id: ast::DUMMY_NODE_ID,\n+                        id: DUMMY_NODE_ID,\n                     });\n                 }\n             }\n@@ -1639,7 +1636,7 @@ impl<'a> Parser<'a> {\n             match self.expect_one_of(&[token::Comma],\n                                      &[token::CloseDelim(token::Brace)]) {\n                 Ok(_) => if let Some(f) = parsed_field.or(recovery_field) {\n-                    // only include the field if there's no parse error for the field name\n+                    // Only include the field if there's no parse error for the field name.\n                     fields.push(f);\n                 }\n                 Err(mut e) => {\n@@ -1659,7 +1656,7 @@ impl<'a> Parser<'a> {\n         return Ok(self.mk_expr(span, ExprKind::Struct(pth, fields, base), attrs));\n     }\n \n-    /// Parse ident (COLON expr)?\n+    /// Parses `ident (COLON expr)?`.\n     fn parse_field(&mut self) -> PResult<'a, Field> {\n         let attrs = self.parse_outer_attributes()?;\n         let lo = self.token.span;\n@@ -1699,7 +1696,7 @@ impl<'a> Parser<'a> {\n             expr,\n             is_shorthand,\n             attrs: attrs.into(),\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n         })\n     }\n \n@@ -1772,6 +1769,6 @@ impl<'a> Parser<'a> {\n     }\n \n     crate fn mk_expr(&self, span: Span, node: ExprKind, attrs: ThinVec<Attribute>) -> P<Expr> {\n-        P(Expr { node, span, attrs, id: ast::DUMMY_NODE_ID })\n+        P(Expr { node, span, attrs, id: DUMMY_NODE_ID })\n     }\n }"}, {"sha": "be7fc48fdaf66e639756cbe746522beffc0e5c3b", "filename": "src/libsyntax/parse/parser/item.rs", "status": "modified", "additions": 58, "deletions": 57, "changes": 115, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fitem.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -2,34 +2,36 @@ use super::{Parser, PResult, PathStyle, SemiColonMode, BlockMode};\n \n use crate::maybe_whole;\n use crate::ptr::P;\n-use crate::ast::{self, Ident, Attribute, AttrStyle};\n-use crate::ast::{Item, ItemKind, ImplItem, TraitItem, TraitItemKind};\n-use crate::ast::{UseTree, UseTreeKind, PathSegment};\n-use crate::ast::{IsAuto, Constness, IsAsync, Unsafety, Defaultness};\n-use crate::ast::{Visibility, VisibilityKind, Mutability, FnDecl, FnHeader};\n-use crate::ast::{ForeignItem, ForeignItemKind};\n-use crate::ast::{Ty, TyKind, GenericBounds, TraitRef};\n-use crate::ast::{EnumDef, VariantData, StructField, AnonConst};\n-use crate::ast::{Mac, MacDelimiter};\n+use crate::ast::{\n+    self, DUMMY_NODE_ID, Ident, Attribute, AttrStyle,\n+    Item, ItemKind, ImplItem, TraitItem, TraitItemKind,\n+    UseTree, UseTreeKind, PathSegment,\n+    IsAuto, Constness, IsAsync, Unsafety, Defaultness,\n+    Visibility, VisibilityKind, Mutability, FnDecl, FnHeader,\n+    ForeignItem, ForeignItemKind,\n+    Ty, TyKind, Generics, GenericBounds, TraitRef,\n+    EnumDef, VariantData, StructField, AnonConst,\n+    Mac, MacDelimiter,\n+};\n use crate::ext::base::DummyResult;\n use crate::parse::token;\n use crate::parse::parser::maybe_append;\n-use crate::parse::diagnostics::{Error};\n+use crate::parse::diagnostics::Error;\n use crate::tokenstream::{TokenTree, TokenStream};\n use crate::source_map::{respan, Span, Spanned};\n use crate::symbol::{kw, sym};\n \n use std::mem;\n use log::debug;\n-use rustc_target::spec::abi::{Abi};\n+use rustc_target::spec::abi::Abi;\n use errors::{Applicability, DiagnosticBuilder, DiagnosticId};\n \n-/// Whether the type alias or associated type is a concrete type or an opaque type\n+/// Whether the type alias or associated type is a concrete type or an opaque type.\n #[derive(Debug)]\n pub enum AliasKind {\n-    /// Just a new name for the same type\n+    /// Just a new name for the same type.\n     Weak(P<Ty>),\n-    /// Only trait impls of the type will be usable, not the actual type itself\n+    /// Only trait impls of the type will be usable, not the actual type itself.\n     OpaqueTy(GenericBounds),\n }\n \n@@ -200,7 +202,7 @@ impl<'a> Parser<'a> {\n             return Ok(Some(item));\n         }\n \n-        // Parse `async unsafe? fn`.\n+        // Parses `async unsafe? fn`.\n         if self.check_keyword(kw::Async) {\n             let async_span = self.token.span;\n             if self.is_keyword_ahead(1, &[kw::Fn])\n@@ -214,8 +216,8 @@ impl<'a> Parser<'a> {\n                 let (ident, item_, extra_attrs) =\n                     self.parse_item_fn(unsafety,\n                                     respan(async_span, IsAsync::Async {\n-                                        closure_id: ast::DUMMY_NODE_ID,\n-                                        return_impl_trait_id: ast::DUMMY_NODE_ID,\n+                                        closure_id: DUMMY_NODE_ID,\n+                                        return_impl_trait_id: DUMMY_NODE_ID,\n                                     }),\n                                     respan(fn_span, Constness::NotConst),\n                                     Abi::Rust)?;\n@@ -286,7 +288,7 @@ impl<'a> Parser<'a> {\n             && self.look_ahead(1, |t| *t != token::OpenDelim(token::Brace)) {\n             // UNSAFE FUNCTION ITEM\n             self.bump(); // `unsafe`\n-            // `{` is also expected after `unsafe`, in case of error, include it in the diagnostic\n+            // `{` is also expected after `unsafe`; in case of error, include it in the diagnostic.\n             self.check(&token::OpenDelim(token::Brace));\n             let abi = if self.eat_keyword(kw::Extern) {\n                 self.parse_opt_abi()?.unwrap_or(Abi::C)\n@@ -521,7 +523,7 @@ impl<'a> Parser<'a> {\n \n             let mac_lo = self.token.span;\n \n-            // item macro.\n+            // Item macro\n             let path = self.parse_path(PathStyle::Mod)?;\n             self.expect(&token::Not)?;\n             let (delim, tts) = self.expect_delimited_token_tree()?;\n@@ -659,7 +661,7 @@ impl<'a> Parser<'a> {\n         let mut generics = if self.choose_generics_over_qpath() {\n             self.parse_generics()?\n         } else {\n-            ast::Generics::default()\n+            Generics::default()\n         };\n \n         // Disambiguate `impl !Trait for Type { ... }` and `impl ! { ... }` for the never type.\n@@ -676,7 +678,7 @@ impl<'a> Parser<'a> {\n                           self.look_ahead(1, |t| t != &token::Lt) {\n             let span = self.prev_span.between(self.token.span);\n             self.struct_span_err(span, \"missing trait in a trait impl\").emit();\n-            P(Ty { node: TyKind::Path(None, err_path(span)), span, id: ast::DUMMY_NODE_ID })\n+            P(Ty { node: TyKind::Path(None, err_path(span)), span, id: DUMMY_NODE_ID })\n         } else {\n             self.parse_ty()?\n         };\n@@ -798,15 +800,15 @@ impl<'a> Parser<'a> {\n             self.expect(&token::Eq)?;\n             let expr = self.parse_expr()?;\n             self.expect(&token::Semi)?;\n-            (name, ast::ImplItemKind::Const(typ, expr), ast::Generics::default())\n+            (name, ast::ImplItemKind::Const(typ, expr), Generics::default())\n         } else {\n             let (name, inner_attrs, generics, node) = self.parse_impl_method(&vis, at_end)?;\n             attrs.extend(inner_attrs);\n             (name, node, generics)\n         };\n \n         Ok(ImplItem {\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(self.prev_span),\n             ident: name,\n             vis,\n@@ -847,14 +849,13 @@ impl<'a> Parser<'a> {\n             !self.is_keyword_ahead(1, &[kw::Fn, kw::Unsafe])\n     }\n \n-    /// Parse a method or a macro invocation in a trait impl.\n+    /// Parses a method or a macro invocation in a trait impl.\n     fn parse_impl_method(&mut self, vis: &Visibility, at_end: &mut bool)\n-                         -> PResult<'a, (Ident, Vec<Attribute>, ast::Generics,\n-                             ast::ImplItemKind)> {\n-        // code copied from parse_macro_use_or_failure... abstraction!\n+                         -> PResult<'a, (Ident, Vec<Attribute>, Generics, ast::ImplItemKind)> {\n+        // FIXME: code copied from `parse_macro_use_or_failure` -- use abstraction!\n         if let Some(mac) = self.parse_assoc_macro_invoc(\"impl\", Some(vis), at_end)? {\n             // method macro\n-            Ok((Ident::invalid(), vec![], ast::Generics::default(),\n+            Ok((Ident::invalid(), vec![], Generics::default(),\n                 ast::ImplItemKind::Macro(mac)))\n         } else {\n             let (constness, unsafety, asyncness, abi) = self.parse_fn_front_matter()?;\n@@ -930,7 +931,7 @@ impl<'a> Parser<'a> {\n         };\n \n         if self.eat(&token::Eq) {\n-            // it's a trait alias\n+            // It's a trait alias.\n             let bounds = self.parse_generic_bounds(None)?;\n             tps.where_clause = self.parse_where_clause()?;\n             self.expect(&token::Semi)?;\n@@ -948,7 +949,7 @@ impl<'a> Parser<'a> {\n             }\n             Ok((ident, ItemKind::TraitAlias(tps, bounds), None))\n         } else {\n-            // it's a normal trait\n+            // It's a normal trait.\n             tps.where_clause = self.parse_where_clause()?;\n             self.expect(&token::OpenDelim(token::Brace))?;\n             let mut trait_items = vec![];\n@@ -1023,10 +1024,10 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::Semi)?;\n                 None\n             };\n-            (ident, TraitItemKind::Const(ty, default), ast::Generics::default())\n+            (ident, TraitItemKind::Const(ty, default), Generics::default())\n         } else if let Some(mac) = self.parse_assoc_macro_invoc(\"trait\", None, &mut false)? {\n             // trait item macro.\n-            (Ident::invalid(), ast::TraitItemKind::Macro(mac), ast::Generics::default())\n+            (Ident::invalid(), ast::TraitItemKind::Macro(mac), Generics::default())\n         } else {\n             let (constness, unsafety, asyncness, abi) = self.parse_fn_front_matter()?;\n \n@@ -1089,7 +1090,7 @@ impl<'a> Parser<'a> {\n         };\n \n         Ok(TraitItem {\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             ident: name,\n             attrs,\n             generics,\n@@ -1103,7 +1104,7 @@ impl<'a> Parser<'a> {\n     ///\n     ///     TraitItemAssocTy = Ident [\"<\"...\">\"] [\":\" [GenericBounds]] [\"where\" ...] [\"=\" Ty]\n     fn parse_trait_item_assoc_ty(&mut self)\n-        -> PResult<'a, (Ident, TraitItemKind, ast::Generics)> {\n+        -> PResult<'a, (Ident, TraitItemKind, Generics)> {\n         let ident = self.parse_ident()?;\n         let mut generics = self.parse_generics()?;\n \n@@ -1165,7 +1166,7 @@ impl<'a> Parser<'a> {\n                     UseTreeKind::Nested(self.parse_use_tree_list()?)\n                 }\n             } else {\n-                UseTreeKind::Simple(self.parse_rename()?, ast::DUMMY_NODE_ID, ast::DUMMY_NODE_ID)\n+                UseTreeKind::Simple(self.parse_rename()?, DUMMY_NODE_ID, DUMMY_NODE_ID)\n             }\n         };\n \n@@ -1178,7 +1179,7 @@ impl<'a> Parser<'a> {\n     /// USE_TREE_LIST = \u00d8 | (USE_TREE `,`)* USE_TREE [`,`]\n     /// ```\n     fn parse_use_tree_list(&mut self) -> PResult<'a, Vec<(UseTree, ast::NodeId)>> {\n-        self.parse_delim_comma_seq(token::Brace, |p| Ok((p.parse_use_tree()?, ast::DUMMY_NODE_ID)))\n+        self.parse_delim_comma_seq(token::Brace, |p| Ok((p.parse_use_tree()?, DUMMY_NODE_ID)))\n             .map(|(r, _)| r)\n     }\n \n@@ -1240,9 +1241,9 @@ impl<'a> Parser<'a> {\n         let mut idents = vec![];\n         let mut replacement = vec![];\n         let mut fixed_crate_name = false;\n-        // Accept `extern crate name-like-this` for better diagnostics\n+        // Accept `extern crate name-like-this` for better diagnostics.\n         let dash = token::BinOp(token::BinOpToken::Minus);\n-        if self.token == dash {  // Do not include `-` as part of the expected tokens list\n+        if self.token == dash {  // Do not include `-` as part of the expected tokens list.\n             while self.eat(&dash) {\n                 fixed_crate_name = true;\n                 replacement.push((self.prev_span, \"_\".to_string()));\n@@ -1283,7 +1284,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parses the name and optional generic types of a function header.\n-    fn parse_fn_header(&mut self) -> PResult<'a, (Ident, ast::Generics)> {\n+    fn parse_fn_header(&mut self) -> PResult<'a, (Ident, Generics)> {\n         let id = self.parse_ident()?;\n         let generics = self.parse_generics()?;\n         Ok((id, generics))\n@@ -1379,7 +1380,7 @@ impl<'a> Parser<'a> {\n                     ForeignItem {\n                         ident: Ident::invalid(),\n                         span: lo.to(self.prev_span),\n-                        id: ast::DUMMY_NODE_ID,\n+                        id: DUMMY_NODE_ID,\n                         attrs,\n                         vis: visibility,\n                         node: ForeignItemKind::Macro(mac),\n@@ -1415,7 +1416,7 @@ impl<'a> Parser<'a> {\n             ident,\n             attrs,\n             node: ForeignItemKind::Fn(decl, generics),\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(hi),\n             vis,\n         })\n@@ -1435,7 +1436,7 @@ impl<'a> Parser<'a> {\n             ident,\n             attrs,\n             node: ForeignItemKind::Static(ty, mutbl),\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(hi),\n             vis,\n         })\n@@ -1453,15 +1454,15 @@ impl<'a> Parser<'a> {\n             ident,\n             attrs,\n             node: ForeignItemKind::Ty,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(hi),\n             vis\n         })\n     }\n \n     fn is_static_global(&mut self) -> bool {\n         if self.check_keyword(kw::Static) {\n-            // Check if this could be a closure\n+            // Check if this could be a closure.\n             !self.look_ahead(1, |token| {\n                 if token.is_keyword(kw::Move) {\n                     return true;\n@@ -1492,7 +1493,7 @@ impl<'a> Parser<'a> {\n \n     /// Parses `type Foo = Bar;` or returns `None`\n     /// without modifying the parser state.\n-    fn eat_type(&mut self) -> Option<PResult<'a, (Ident, AliasKind, ast::Generics)>> {\n+    fn eat_type(&mut self) -> Option<PResult<'a, (Ident, AliasKind, Generics)>> {\n         // This parses the grammar:\n         //     Ident [\"<\"...\">\"] [\"where\" ...] (\"=\" | \":\") Ty \";\"\n         if self.eat_keyword(kw::Type) {\n@@ -1503,7 +1504,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parses a type alias or opaque type.\n-    fn parse_type_alias(&mut self) -> PResult<'a, (Ident, AliasKind, ast::Generics)> {\n+    fn parse_type_alias(&mut self) -> PResult<'a, (Ident, AliasKind, Generics)> {\n         let ident = self.parse_ident()?;\n         let mut tps = self.parse_generics()?;\n         tps.where_clause = self.parse_where_clause()?;\n@@ -1536,7 +1537,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parses the part of an enum declaration following the `{`.\n-    fn parse_enum_def(&mut self, _generics: &ast::Generics) -> PResult<'a, EnumDef> {\n+    fn parse_enum_def(&mut self, _generics: &Generics) -> PResult<'a, EnumDef> {\n         let mut variants = Vec::new();\n         while self.token != token::CloseDelim(token::Brace) {\n             let variant_attrs = self.parse_outer_attributes()?;\n@@ -1552,15 +1553,15 @@ impl<'a> Parser<'a> {\n             } else if self.check(&token::OpenDelim(token::Paren)) {\n                 VariantData::Tuple(\n                     self.parse_tuple_struct_body()?,\n-                    ast::DUMMY_NODE_ID,\n+                    DUMMY_NODE_ID,\n                 )\n             } else {\n-                VariantData::Unit(ast::DUMMY_NODE_ID)\n+                VariantData::Unit(DUMMY_NODE_ID)\n             };\n \n             let disr_expr = if self.eat(&token::Eq) {\n                 Some(AnonConst {\n-                    id: ast::DUMMY_NODE_ID,\n+                    id: DUMMY_NODE_ID,\n                     value: self.parse_expr()?,\n                 })\n             } else {\n@@ -1569,7 +1570,7 @@ impl<'a> Parser<'a> {\n \n             let vr = ast::Variant {\n                 ident,\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 attrs: variant_attrs,\n                 data: struct_def,\n                 disr_expr,\n@@ -1622,22 +1623,22 @@ impl<'a> Parser<'a> {\n             generics.where_clause = self.parse_where_clause()?;\n             if self.eat(&token::Semi) {\n                 // If we see a: `struct Foo<T> where T: Copy;` style decl.\n-                VariantData::Unit(ast::DUMMY_NODE_ID)\n+                VariantData::Unit(DUMMY_NODE_ID)\n             } else {\n                 // If we see: `struct Foo<T> where T: Copy { ... }`\n                 let (fields, recovered) = self.parse_record_struct_body()?;\n                 VariantData::Struct(fields, recovered)\n             }\n         // No `where` so: `struct Foo<T>;`\n         } else if self.eat(&token::Semi) {\n-            VariantData::Unit(ast::DUMMY_NODE_ID)\n+            VariantData::Unit(DUMMY_NODE_ID)\n         // Record-style struct definition\n         } else if self.token == token::OpenDelim(token::Brace) {\n             let (fields, recovered) = self.parse_record_struct_body()?;\n             VariantData::Struct(fields, recovered)\n         // Tuple-style struct definition with optional where-clause.\n         } else if self.token == token::OpenDelim(token::Paren) {\n-            let body = VariantData::Tuple(self.parse_tuple_struct_body()?, ast::DUMMY_NODE_ID);\n+            let body = VariantData::Tuple(self.parse_tuple_struct_body()?, DUMMY_NODE_ID);\n             generics.where_clause = self.parse_where_clause()?;\n             self.expect(&token::Semi)?;\n             body\n@@ -1726,7 +1727,7 @@ impl<'a> Parser<'a> {\n                 span: lo.to(ty.span),\n                 vis,\n                 ident: None,\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 ty,\n                 attrs,\n             })\n@@ -1817,7 +1818,7 @@ impl<'a> Parser<'a> {\n             span: lo.to(self.prev_span),\n             ident: Some(name),\n             vis,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             ty,\n             attrs,\n         })\n@@ -1909,7 +1910,7 @@ impl<'a> Parser<'a> {\n         P(Item {\n             ident,\n             attrs,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             node,\n             vis,\n             span,"}, {"sha": "2d2fb487d7df21c2b787ce7237fc0e76d2bc0929", "filename": "src/libsyntax/parse/parser/module.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fmodule.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fmodule.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fmodule.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -36,12 +36,12 @@ impl<'a> Parser<'a> {\n         krate\n     }\n \n-    /// Parse a `mod <foo> { ... }` or `mod <foo>;` item\n+    /// Parses a `mod <foo> { ... }` or `mod <foo>;` item.\n     pub(super) fn parse_item_mod(&mut self, outer_attrs: &[Attribute]) -> PResult<'a, ItemInfo> {\n         let (in_cfg, outer_attrs) = {\n             let mut strip_unconfigured = crate::config::StripUnconfigured {\n                 sess: self.sess,\n-                features: None, // don't perform gated feature checking\n+                features: None, // Don't perform gated feature checking.\n             };\n             let mut outer_attrs = outer_attrs.to_owned();\n             strip_unconfigured.process_cfg_attrs(&mut outer_attrs);\n@@ -57,7 +57,7 @@ impl<'a> Parser<'a> {\n                     self.submod_path(id, &outer_attrs, id_span)?;\n                 let (module, mut attrs) =\n                     self.eval_src_mod(path, directory_ownership, id.to_string(), id_span)?;\n-                // Record that we fetched the mod from an external file\n+                // Record that we fetched the mod from an external file.\n                 if warn {\n                     let attr = attr::mk_attr_outer(\n                         attr::mk_word_item(Ident::with_dummy_span(sym::warn_directory_ownership)));"}, {"sha": "49f8d58c6a762bc43a43885d5d0df4521f3ecf03", "filename": "src/libsyntax/parse/parser/pat.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fpat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fpat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fpat.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -844,14 +844,14 @@ impl<'a> Parser<'a> {\n         // Check if a colon exists one ahead. This means we're parsing a fieldname.\n         let hi;\n         let (subpat, fieldname, is_shorthand) = if self.look_ahead(1, |t| t == &token::Colon) {\n-            // Parsing a pattern of the form \"fieldname: pat\"\n+            // Parsing a pattern of the form `fieldname: pat`.\n             let fieldname = self.parse_field_name()?;\n             self.bump();\n             let pat = self.parse_pat_with_or_inner()?;\n             hi = pat.span;\n             (pat, fieldname, false)\n         } else {\n-            // Parsing a pattern of the form \"(box) (ref) (mut) fieldname\"\n+            // Parsing a pattern of the form `(box) (ref) (mut) fieldname`.\n             let is_box = self.eat_keyword(kw::Box);\n             let boxed_span = self.token.span;\n             let is_ref = self.eat_keyword(kw::Ref);"}, {"sha": "04bd61a4cfb5b3f47a2ae7743c39550fac9baae3", "filename": "src/libsyntax/parse/parser/stmt.rs", "status": "modified", "additions": 31, "deletions": 31, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fstmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Fparser%2Fstmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fstmt.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -5,20 +5,20 @@ use super::pat::GateOr;\n \n use crate::ptr::P;\n use crate::{maybe_whole, ThinVec};\n-use crate::ast::{self, Stmt, StmtKind, Local, Block, BlockCheckMode, Expr, ExprKind};\n+use crate::ast::{self, DUMMY_NODE_ID, Stmt, StmtKind, Local, Block, BlockCheckMode, Expr, ExprKind};\n use crate::ast::{Attribute, AttrStyle, VisibilityKind, MacStmtStyle, Mac, MacDelimiter};\n use crate::ext::base::DummyResult;\n use crate::parse::{classify, DirectoryOwnership};\n use crate::parse::diagnostics::Error;\n-use crate::parse::token::{self};\n+use crate::parse::token;\n use crate::source_map::{respan, Span};\n use crate::symbol::{kw, sym};\n \n use std::mem;\n use errors::Applicability;\n \n impl<'a> Parser<'a> {\n-    /// Parse a statement. This stops just before trailing semicolons on everything but items.\n+    /// Parses a statement. This stops just before trailing semicolons on everything but items.\n     /// e.g., a `StmtKind::Semi` parses to a `StmtKind::Expr`, leaving the trailing `;` unconsumed.\n     pub fn parse_stmt(&mut self) -> PResult<'a, Option<Stmt>> {\n         Ok(self.parse_stmt_(true))\n@@ -43,7 +43,7 @@ impl<'a> Parser<'a> {\n \n         Ok(Some(if self.eat_keyword(kw::Let) {\n             Stmt {\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 node: StmtKind::Local(self.parse_local(attrs.into())?),\n                 span: lo.to(self.prev_span),\n             }\n@@ -53,7 +53,7 @@ impl<'a> Parser<'a> {\n             lo,\n         )? {\n             Stmt {\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 node: StmtKind::Item(macro_def),\n                 span: lo.to(self.prev_span),\n             }\n@@ -85,7 +85,7 @@ impl<'a> Parser<'a> {\n                 })?;\n \n                 return Ok(Some(Stmt {\n-                    id: ast::DUMMY_NODE_ID,\n+                    id: DUMMY_NODE_ID,\n                     node: StmtKind::Expr(expr),\n                     span: lo.to(self.prev_span),\n                 }));\n@@ -114,17 +114,17 @@ impl<'a> Parser<'a> {\n             // We used to incorrectly stop parsing macro-expanded statements here.\n             // If the next token will be an error anyway but could have parsed with the\n             // earlier behavior, stop parsing here and emit a warning to avoid breakage.\n-            else if macro_legacy_warnings &&\n-                    self.token.can_begin_expr() &&\n-                    match self.token.kind {\n-                // These can continue an expression, so we can't stop parsing and warn.\n-                token::OpenDelim(token::Paren) | token::OpenDelim(token::Bracket) |\n-                token::BinOp(token::Minus) | token::BinOp(token::Star) |\n-                token::BinOp(token::And) | token::BinOp(token::Or) |\n-                token::AndAnd | token::OrOr |\n-                token::DotDot | token::DotDotDot | token::DotDotEq => false,\n-                _ => true,\n-            } {\n+            else if macro_legacy_warnings && self.token.can_begin_expr() &&\n+                match self.token.kind {\n+                    // These can continue an expression, so we can't stop parsing and warn.\n+                    token::OpenDelim(token::Paren) | token::OpenDelim(token::Bracket) |\n+                    token::BinOp(token::Minus) | token::BinOp(token::Star) |\n+                    token::BinOp(token::And) | token::BinOp(token::Or) |\n+                    token::AndAnd | token::OrOr |\n+                    token::DotDot | token::DotDotDot | token::DotDotEq => false,\n+                    _ => true,\n+                }\n+            {\n                 self.warn_missing_semicolon();\n                 StmtKind::Mac(P((mac, style, attrs.into())))\n             } else {\n@@ -135,7 +135,7 @@ impl<'a> Parser<'a> {\n                 StmtKind::Expr(e)\n             };\n             Stmt {\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 span: lo.to(hi),\n                 node,\n             }\n@@ -148,7 +148,7 @@ impl<'a> Parser<'a> {\n \n             match item {\n                 Some(i) => Stmt {\n-                    id: ast::DUMMY_NODE_ID,\n+                    id: DUMMY_NODE_ID,\n                     span: lo.to(i.span),\n                     node: StmtKind::Item(i),\n                 },\n@@ -178,7 +178,7 @@ impl<'a> Parser<'a> {\n                         // an empty tuple that spans the excess semicolons\n                         // to preserve this info until the lint stage\n                         return Ok(Some(Stmt {\n-                            id: ast::DUMMY_NODE_ID,\n+                            id: DUMMY_NODE_ID,\n                             span: lo.to(last_semi),\n                             node: StmtKind::Semi(self.mk_expr(lo.to(last_semi),\n                                 ExprKind::Tup(Vec::new()),\n@@ -196,7 +196,7 @@ impl<'a> Parser<'a> {\n                     let e = self.parse_expr_res(\n                         Restrictions::STMT_EXPR, Some(attrs.into()))?;\n                     Stmt {\n-                        id: ast::DUMMY_NODE_ID,\n+                        id: DUMMY_NODE_ID,\n                         span: lo.to(e.span),\n                         node: StmtKind::Expr(e),\n                     }\n@@ -218,7 +218,7 @@ impl<'a> Parser<'a> {\n             match self.parse_ty() {\n                 Ok(ty) => (None, Some(ty)),\n                 Err(mut err) => {\n-                    // Rewind to before attempting to parse the type and continue parsing\n+                    // Rewind to before attempting to parse the type and continue parsing.\n                     let parser_snapshot_after_type = self.clone();\n                     mem::replace(self, parser_snapshot_before_type);\n \n@@ -272,7 +272,7 @@ impl<'a> Parser<'a> {\n             ty,\n             pat,\n             init,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(hi),\n             attrs,\n         }))\n@@ -334,18 +334,18 @@ impl<'a> Parser<'a> {\n             //    if (cond)\n             //      bar;\n             //\n-            // Which is valid in other languages, but not Rust.\n+            // which is valid in other languages, but not Rust.\n             match self.parse_stmt_without_recovery(false) {\n                 Ok(Some(stmt)) => {\n                     if self.look_ahead(1, |t| t == &token::OpenDelim(token::Brace))\n                         || do_not_suggest_help {\n-                        // if the next token is an open brace (e.g., `if a b {`), the place-\n-                        // inside-a-block suggestion would be more likely wrong than right\n+                        // If the next token is an open brace (e.g., `if a b {`), the place-\n+                        // inside-a-block suggestion would be more likely wrong than right.\n                         e.span_label(sp, \"expected `{`\");\n                         return Err(e);\n                     }\n                     let mut stmt_span = stmt.span;\n-                    // expand the span to include the semicolon, if it exists\n+                    // Expand the span to include the semicolon, if it exists.\n                     if self.eat(&token::Semi) {\n                         stmt_span = stmt_span.with_hi(self.prev_span.hi());\n                     }\n@@ -354,7 +354,7 @@ impl<'a> Parser<'a> {\n                             stmt_span,\n                             \"try placing this code inside a block\",\n                             format!(\"{{ {} }}\", snippet),\n-                            // speculative, has been misleading in the past (#46836)\n+                            // Speculative; has been misleading in the past (#46836).\n                             Applicability::MaybeIncorrect,\n                         );\n                     }\n@@ -399,7 +399,7 @@ impl<'a> Parser<'a> {\n                     err.emit();\n                     self.recover_stmt_(SemiColonMode::Ignore, BlockMode::Ignore);\n                     Some(Stmt {\n-                        id: ast::DUMMY_NODE_ID,\n+                        id: DUMMY_NODE_ID,\n                         node: StmtKind::Expr(DummyResult::raw_expr(self.token.span, true)),\n                         span: self.token.span,\n                     })\n@@ -415,15 +415,15 @@ impl<'a> Parser<'a> {\n         }\n         Ok(P(ast::Block {\n             stmts,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             rules: s,\n             span: lo.to(self.prev_span),\n         }))\n     }\n \n     /// Parses a statement, including the trailing semicolon.\n     crate fn parse_full_stmt(&mut self, macro_legacy_warnings: bool) -> PResult<'a, Option<Stmt>> {\n-        // skip looking for a trailing semicolon when we have an interpolated statement\n+        // Skip looking for a trailing semicolon when we have an interpolated statement.\n         maybe_whole!(self, NtStmt, |x| Some(x));\n \n         let mut stmt = match self.parse_stmt_without_recovery(macro_legacy_warnings)? {"}, {"sha": "5cb59b3f82790a0d9236927671632a80579cb28b", "filename": "src/libsyntax/parse/tests.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fparse%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftests.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -25,20 +25,20 @@ fn parse_item_from_source_str(name: FileName, source: String, sess: &ParseSess)\n     new_parser_from_source_str(sess, name, source).parse_item()\n }\n \n-// produce a syntax_pos::span\n+// Produces a `syntax_pos::span`.\n fn sp(a: u32, b: u32) -> Span {\n     Span::with_root_ctxt(BytePos(a), BytePos(b))\n }\n \n-/// Parse a string, return an expr\n+/// Parses a string, return an expression.\n fn string_to_expr(source_str : String) -> P<ast::Expr> {\n     let ps = ParseSess::new(FilePathMapping::empty());\n     with_error_checking_parse(source_str, &ps, |p| {\n         p.parse_expr()\n     })\n }\n \n-/// Parse a string, return an item\n+/// Parses a string, returns an item.\n fn string_to_item(source_str : String) -> Option<P<ast::Item>> {\n     let ps = ParseSess::new(FilePathMapping::empty());\n     with_error_checking_parse(source_str, &ps, |p| {\n@@ -53,7 +53,7 @@ fn string_to_item(source_str : String) -> Option<P<ast::Item>> {\n     })\n }\n \n-// check the token-tree-ization of macros\n+// Checks the token-tree-ization of macros.\n #[test]\n fn string_to_tts_macro () {\n     with_default_globals(|| {"}, {"sha": "5d8498f8b5d260278c6f48f480b5d056dfc99ff4", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 25, "deletions": 27, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -119,19 +119,19 @@ pub fn print_crate<'a>(cm: &'a SourceMap,\n     if is_expanded && sess.injected_crate_name.try_get().is_some() {\n         // We need to print `#![no_std]` (and its feature gate) so that\n         // compiling pretty-printed source won't inject libstd again.\n-        // However we don't want these attributes in the AST because\n+        // However, we don't want these attributes in the AST because\n         // of the feature gate, so we fake them up here.\n \n-        // #![feature(prelude_import)]\n+        // `#![feature(prelude_import)]`\n         let pi_nested = attr::mk_nested_word_item(ast::Ident::with_dummy_span(sym::prelude_import));\n         let list = attr::mk_list_item(ast::Ident::with_dummy_span(sym::feature), vec![pi_nested]);\n         let fake_attr = attr::mk_attr_inner(list);\n         s.print_attribute(&fake_attr);\n \n-        // Currently on Rust 2018 we don't have `extern crate std;` at the crate\n+        // Currently, in Rust 2018 we don't have `extern crate std;` at the crate\n         // root, so this is not needed, and actually breaks things.\n         if sess.edition == syntax_pos::edition::Edition::Edition2015 {\n-            // #![no_std]\n+            // `#![no_std]`\n             let no_std_meta = attr::mk_word_item(ast::Ident::with_dummy_span(sym::no_std));\n             let fake_attr = attr::mk_attr_inner(no_std_meta);\n             s.print_attribute(&fake_attr);\n@@ -398,9 +398,9 @@ pub fn vis_to_string(v: &ast::Visibility) -> String {\n \n fn block_to_string(blk: &ast::Block) -> String {\n     to_string(|s| {\n-        // containing cbox, will be closed by print-block at }\n+        // Containing cbox, will be closed by `print_block` at `}`.\n         s.cbox(INDENT_UNIT);\n-        // head-ibox, will be closed by print-block after {\n+        // Head-ibox, will be closed by `print_block` after `{`.\n         s.ibox(0);\n         s.print_block(blk)\n     })\n@@ -443,7 +443,7 @@ impl std::ops::DerefMut for State<'_> {\n     }\n }\n \n-pub trait PrintState<'a>: std::ops::Deref<Target=pp::Printer> + std::ops::DerefMut {\n+pub trait PrintState<'a>: std::ops::Deref<Target = pp::Printer> + std::ops::DerefMut {\n     fn comments(&mut self) -> &mut Option<Comments<'a>>;\n     fn print_ident(&mut self, ident: ast::Ident);\n     fn print_generic_args(&mut self, args: &ast::GenericArgs, colons_before_params: bool);\n@@ -495,7 +495,7 @@ pub trait PrintState<'a>: std::ops::Deref<Target=pp::Printer> + std::ops::DerefM\n                 self.hardbreak_if_not_bol();\n                 for line in &cmnt.lines {\n                     // Don't print empty lines because they will end up as trailing\n-                    // whitespace\n+                    // whitespace.\n                     if !line.is_empty() {\n                         self.word(line.clone());\n                     }\n@@ -783,27 +783,27 @@ pub trait PrintState<'a>: std::ops::Deref<Target=pp::Printer> + std::ops::DerefM\n \n     fn head<S: Into<Cow<'static, str>>>(&mut self, w: S) {\n         let w = w.into();\n-        // outer-box is consistent\n+        // Outer-box is consistent.\n         self.cbox(INDENT_UNIT);\n-        // head-box is inconsistent\n+        // Head-box is inconsistent.\n         self.ibox(w.len() + 1);\n-        // keyword that starts the head\n+        // Keyword that starts the head.\n         if !w.is_empty() {\n             self.word_nbsp(w);\n         }\n     }\n \n     fn bopen(&mut self) {\n         self.word(\"{\");\n-        self.end(); // close the head-box\n+        self.end(); // Close the head-box.\n     }\n \n     fn bclose_maybe_open(&mut self, span: syntax_pos::Span, close_box: bool) {\n         self.maybe_print_comment(span.hi());\n         self.break_offset_if_not_bol(1, -(INDENT_UNIT as isize));\n         self.word(\"}\");\n         if close_box {\n-            self.end(); // close the outer-box\n+            self.end(); // Close the outer-box.\n         }\n     }\n \n@@ -900,8 +900,6 @@ impl<'a> State<'a> {\n         self.s.word(\"*/\")\n     }\n \n-\n-\n     crate fn commasep_cmnt<T, F, G>(&mut self,\n                                   b: Breaks,\n                                   elts: &[T],\n@@ -928,20 +926,20 @@ impl<'a> State<'a> {\n     }\n \n     crate fn commasep_exprs(&mut self, b: Breaks,\n-                          exprs: &[P<ast::Expr>]) {\n+                            exprs: &[P<ast::Expr>]) {\n         self.commasep_cmnt(b, exprs, |s, e| s.print_expr(e), |e| e.span)\n     }\n \n     crate fn print_mod(&mut self, _mod: &ast::Mod,\n-                     attrs: &[ast::Attribute]) {\n+                       attrs: &[ast::Attribute]) {\n         self.print_inner_attributes(attrs);\n         for item in &_mod.items {\n             self.print_item(item);\n         }\n     }\n \n     crate fn print_foreign_mod(&mut self, nmod: &ast::ForeignMod,\n-                             attrs: &[ast::Attribute]) {\n+                               attrs: &[ast::Attribute]) {\n         self.print_inner_attributes(attrs);\n         for item in &nmod.items {\n             self.print_foreign_item(item);\n@@ -1136,7 +1134,7 @@ impl<'a> State<'a> {\n         self.s.word(\";\")\n     }\n \n-    /// Pretty-print an item\n+    /// Pretty-prints an item.\n     crate fn print_item(&mut self, item: &ast::Item) {\n         self.hardbreak_if_not_bol();\n         self.maybe_print_comment(item.span.lo());\n@@ -1489,7 +1487,7 @@ impl<'a> State<'a> {\n                     self.s.word(\";\");\n                 }\n                 self.end();\n-                self.end(); // close the outer-box\n+                self.end(); // Close the outer-box.\n             }\n             ast::VariantData::Struct(..) => {\n                 self.print_where_clause(&generics.where_clause);\n@@ -1793,7 +1791,7 @@ impl<'a> State<'a> {\n         self.print_expr_cond_paren(expr, expr.precedence().order() < prec)\n     }\n \n-    /// Print an expr using syntax that's acceptable in a condition position, such as the `cond` in\n+    /// Prints an expr using syntax that's acceptable in a condition position, such as the `cond` in\n     /// `if cond { ... }`.\n     crate fn print_expr_as_cond(&mut self, expr: &ast::Expr) {\n         self.print_expr_cond_paren(expr, Self::cond_needs_par(expr))\n@@ -1812,7 +1810,7 @@ impl<'a> State<'a> {\n         }\n     }\n \n-    /// Print `expr` or `(expr)` when `needs_par` holds.\n+    /// Prints `expr` or `(expr)` when `needs_par` holds.\n     fn print_expr_cond_paren(&mut self, expr: &ast::Expr, needs_par: bool) {\n         if needs_par {\n             self.popen();\n@@ -2456,7 +2454,7 @@ impl<'a> State<'a> {\n     }\n \n     fn print_arm(&mut self, arm: &ast::Arm) {\n-        // I have no idea why this check is necessary, but here it is :(\n+        // Note, I have no idea why this check is necessary, but here it is.\n         if arm.attrs.is_empty() {\n             self.s.space();\n         }\n@@ -2480,21 +2478,21 @@ impl<'a> State<'a> {\n                     self.word_space(\":\");\n                 }\n \n-                // the block will close the pattern's ibox\n+                // The block will close the pattern's ibox.\n                 self.print_block_unclosed_indent(blk);\n \n-                // If it is a user-provided unsafe block, print a comma after it\n+                // If it is a user-provided unsafe block, print a comma after it.\n                 if let BlockCheckMode::Unsafe(ast::UserProvided) = blk.rules {\n                     self.s.word(\",\");\n                 }\n             }\n             _ => {\n-                self.end(); // close the ibox for the pattern\n+                self.end(); // Close the ibox for the pattern.\n                 self.print_expr(&arm.body);\n                 self.s.word(\",\");\n             }\n         }\n-        self.end(); // close enclosing cbox\n+        self.end(); // Close enclosing cbox.\n     }\n \n     fn print_explicit_self(&mut self, explicit_self: &ast::ExplicitSelf) {"}, {"sha": "afd1726adf36b2731d7a7efff848b71c55d772c5", "filename": "src/libsyntax/print/pprust/tests.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fprint%2Fpprust%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fprint%2Fpprust%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust%2Ftests.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -12,8 +12,8 @@ fn fun_to_string(\n         s.head(\"\");\n         s.print_fn(decl, header, Some(name),\n                    generics, &source_map::dummy_spanned(ast::VisibilityKind::Inherited));\n-        s.end(); // Close the head box\n-        s.end(); // Close the outer box\n+        s.end(); // Close the head box.\n+        s.end(); // Close the outer box.\n     })\n }\n \n@@ -58,7 +58,6 @@ fn test_variant_to_string() {\n             ident,\n             attrs: Vec::new(),\n             id: ast::DUMMY_NODE_ID,\n-            // making this up as I go.... ?\n             data: ast::VariantData::Unit(ast::DUMMY_NODE_ID),\n             disr_expr: None,\n             span: syntax_pos::DUMMY_SP,"}, {"sha": "d7ea799e00459029495c3b13c755ea5746a57a03", "filename": "src/libsyntax/source_map.rs", "status": "modified", "additions": 64, "deletions": 62, "changes": 126, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fsource_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fsource_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fsource_map.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,10 +1,10 @@\n-//! The SourceMap tracks all the source code used within a single crate, mapping\n+//! The `SourceMap` tracks all the source code used within a single crate, mapping\n //! from integer byte positions to the original source code location. Each bit\n //! of source parsed during crate parsing (typically files, in-memory strings,\n //! or various bits of macro expansion) cover a continuous range of bytes in the\n-//! SourceMap and are represented by SourceFiles. Byte positions are stored in\n-//! `spans` and used pervasively in the compiler. They are absolute positions\n-//! within the SourceMap, which upon request can be converted to line and column\n+//! `SourceMap` and are represented by `SourceFile`s. Byte positions are stored in\n+//! `Span`` and used pervasively in the compiler. They are absolute positions\n+//! within the `SourceMap`, which upon request can be converted to line and column\n //! information, source code snippets, etc.\n \n pub use syntax_pos::*;\n@@ -94,7 +94,7 @@ impl FileLoader for RealFileLoader {\n     }\n }\n \n-// This is a SourceFile identifier that is used to correlate SourceFiles between\n+// This is a `SourceFile` identifier that is used to correlate `SourceFile`s between\n // subsequent compilation sessions (which is something we need to do during\n // incremental compilation).\n #[derive(Copy, Clone, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable, Debug)]\n@@ -103,8 +103,8 @@ pub struct StableSourceFileId(u128);\n impl StableSourceFileId {\n     pub fn new(source_file: &SourceFile) -> StableSourceFileId {\n         StableSourceFileId::new_from_pieces(&source_file.name,\n-                                         source_file.name_was_remapped,\n-                                         source_file.unmapped_path.as_ref())\n+                                            source_file.name_was_remapped,\n+                                            source_file.unmapped_path.as_ref())\n     }\n \n     pub fn new_from_pieces(name: &FileName,\n@@ -134,7 +134,7 @@ pub struct SourceMap {\n     files: Lock<SourceMapFiles>,\n     file_loader: Box<dyn FileLoader + Sync + Send>,\n     // This is used to apply the file path remapping as specified via\n-    // --remap-path-prefix to all SourceFiles allocated within this SourceMap.\n+    // `--remap-path-prefix` to all `SourceFile`s allocated within this `SourceMap`.\n     path_mapping: FilePathMapping,\n }\n \n@@ -204,14 +204,14 @@ impl SourceMap {\n         match self.files.borrow().source_files.last() {\n             None => 0,\n             // Add one so there is some space between files. This lets us distinguish\n-            // positions in the source_map, even in the presence of zero-length files.\n+            // positions in the `SourceMap`, even in the presence of zero-length files.\n             Some(last) => last.end_pos.to_usize() + 1,\n         }\n     }\n \n-    /// Creates a new source_file.\n-    /// If a file already exists in the source_map with the same id, that file is returned\n-    /// unmodified\n+    /// Creates a new `SourceFile`.\n+    /// If a file already exists in the `SourceMap` with the same ID, that file is returned\n+    /// unmodified.\n     pub fn new_source_file(&self, filename: FileName, src: String) -> Lrc<SourceFile> {\n         self.try_new_source_file(filename, src)\n             .unwrap_or_else(|OffsetOverflowError| {\n@@ -268,8 +268,8 @@ impl SourceMap {\n         Ok(lrc_sf)\n     }\n \n-    /// Allocates a new SourceFile representing a source file from an external\n-    /// crate. The source code of such an \"imported source_file\" is not available,\n+    /// Allocates a new `SourceFile` representing a source file from an external\n+    /// crate. The source code of such an \"imported `SourceFile`\" is not available,\n     /// but we still know enough to generate accurate debuginfo location\n     /// information for things inlined from other crates.\n     pub fn new_imported_source_file(\n@@ -334,7 +334,7 @@ impl SourceMap {\n                  pos.col.to_usize() + 1)\n     }\n \n-    // If there is a doctest_offset, apply it to the line\n+    // If there is a doctest offset, applies it to the line.\n     pub fn doctest_offset_line(&self, file: &FileName, orig: usize) -> usize {\n         return match file {\n             FileName::DocTest(_, offset) => {\n@@ -348,7 +348,7 @@ impl SourceMap {\n         }\n     }\n \n-    /// Lookup source information about a BytePos\n+    /// Looks up source information about a `BytePos`.\n     pub fn lookup_char_pos(&self, pos: BytePos) -> Loc {\n         let chpos = self.bytepos_to_file_charpos(pos);\n         match self.lookup_line(pos) {\n@@ -411,7 +411,7 @@ impl SourceMap {\n         }\n     }\n \n-    // If the relevant source_file is empty, we don't return a line number.\n+    // If the corresponding `SourceFile` is empty, does not return a line number.\n     pub fn lookup_line(&self, pos: BytePos) -> Result<SourceFileAndLine, Lrc<SourceFile>> {\n         let idx = self.lookup_source_file_idx(pos);\n \n@@ -423,15 +423,15 @@ impl SourceMap {\n         }\n     }\n \n-    /// Returns `Some(span)`, a union of the lhs and rhs span. The lhs must precede the rhs. If\n-    /// there are gaps between lhs and rhs, the resulting union will cross these gaps.\n-    /// For this to work, the spans have to be:\n+    /// Returns `Some(span)`, a union of the LHS and RHS span. The LHS must precede the RHS. If\n+    /// there are gaps between LHS and RHS, the resulting union will cross these gaps.\n+    /// For this to work,\n     ///\n-    ///    * the ctxt of both spans much match\n-    ///    * the lhs span needs to end on the same line the rhs span begins\n-    ///    * the lhs span must start at or before the rhs span\n+    ///    * the syntax contexts of both spans much match,\n+    ///    * the LHS span needs to end on the same line the RHS span begins,\n+    ///    * the LHS span must start at or before the RHS span.\n     pub fn merge_spans(&self, sp_lhs: Span, sp_rhs: Span) -> Option<Span> {\n-        // make sure we're at the same expansion id\n+        // Ensure we're at the same expansion ID.\n         if sp_lhs.ctxt() != sp_rhs.ctxt() {\n             return None;\n         }\n@@ -445,12 +445,12 @@ impl SourceMap {\n             Err(_) => return None\n         };\n \n-        // if we must cross lines to merge, don't merge\n+        // If we must cross lines to merge, don't merge.\n         if lhs_end.line != rhs_begin.line {\n             return None;\n         }\n \n-        // ensure these follow the expected order and we don't overlap\n+        // Ensure these follow the expected order and that we don't overlap.\n         if (sp_lhs.lo() <= sp_rhs.lo()) && (sp_lhs.hi() <= sp_rhs.lo()) {\n             Some(sp_lhs.to(sp_rhs))\n         } else {\n@@ -466,11 +466,12 @@ impl SourceMap {\n         let lo = self.lookup_char_pos(sp.lo());\n         let hi = self.lookup_char_pos(sp.hi());\n         format!(\"{}:{}:{}: {}:{}\",\n-                        lo.file.name,\n-                        lo.line,\n-                        lo.col.to_usize() + 1,\n-                        hi.line,\n-                        hi.col.to_usize() + 1)\n+            lo.file.name,\n+            lo.line,\n+            lo.col.to_usize() + 1,\n+            hi.line,\n+            hi.col.to_usize() + 1,\n+        )\n     }\n \n     pub fn span_to_filename(&self, sp: Span) -> FileName {\n@@ -479,7 +480,7 @@ impl SourceMap {\n \n     pub fn span_to_unmapped_path(&self, sp: Span) -> FileName {\n         self.lookup_char_pos(sp.lo()).file.unmapped_path.clone()\n-            .expect(\"SourceMap::span_to_unmapped_path called for imported SourceFile?\")\n+            .expect(\"`SourceMap::span_to_unmapped_path` called for imported `SourceFile`?\")\n     }\n \n     pub fn is_multiline(&self, sp: Span) -> bool {\n@@ -586,7 +587,7 @@ impl SourceMap {\n         }\n     }\n \n-    /// Returns the source snippet as `String` corresponding to the given `Span`\n+    /// Returns the source snippet as `String` corresponding to the given `Span`.\n     pub fn span_to_snippet(&self, sp: Span) -> Result<String, SpanSnippetError> {\n         self.span_to_source(sp, |src, start_index, end_index| src.get(start_index..end_index)\n             .map(|s| s.to_string())\n@@ -602,14 +603,14 @@ impl SourceMap {\n         }\n     }\n \n-    /// Returns the source snippet as `String` before the given `Span`\n+    /// Returns the source snippet as `String` before the given `Span`.\n     pub fn span_to_prev_source(&self, sp: Span) -> Result<String, SpanSnippetError> {\n         self.span_to_source(sp, |src, start_index, _| src.get(..start_index)\n             .map(|s| s.to_string())\n             .ok_or_else(|| SpanSnippetError::IllFormedSpan(sp)))\n     }\n \n-    /// Extend the given `Span` to just after the previous occurrence of `c`. Return the same span\n+    /// Extends the given `Span` to just after the previous occurrence of `c`. Return the same span\n     /// if no character could be found or if an error occurred while retrieving the code snippet.\n     pub fn span_extend_to_prev_char(&self, sp: Span, c: char) -> Span {\n         if let Ok(prev_source) = self.span_to_prev_source(sp) {\n@@ -622,8 +623,8 @@ impl SourceMap {\n         sp\n     }\n \n-    /// Extend the given `Span` to just after the previous occurrence of `pat` when surrounded by\n-    /// whitespace. Return the same span if no character could be found or if an error occurred\n+    /// Extends the given `Span` to just after the previous occurrence of `pat` when surrounded by\n+    /// whitespace. Returns the same span if no character could be found or if an error occurred\n     /// while retrieving the code snippet.\n     pub fn span_extend_to_prev_str(&self, sp: Span, pat: &str, accept_newlines: bool) -> Span {\n         // assure that the pattern is delimited, to avoid the following\n@@ -643,7 +644,8 @@ impl SourceMap {\n         sp\n     }\n \n-    /// Given a `Span`, try to get a shorter span ending before the first occurrence of `c` `char`\n+    /// Given a `Span`, tries to get a shorter span ending before the first occurrence of `char`\n+    /// ``c`.\n     pub fn span_until_char(&self, sp: Span, c: char) -> Span {\n         match self.span_to_snippet(sp) {\n             Ok(snippet) => {\n@@ -658,7 +660,7 @@ impl SourceMap {\n         }\n     }\n \n-    /// Given a `Span`, try to get a shorter span ending just after the first occurrence of `char`\n+    /// Given a `Span`, tries to get a shorter span ending just after the first occurrence of `char`\n     /// `c`.\n     pub fn span_through_char(&self, sp: Span, c: char) -> Span {\n         if let Ok(snippet) = self.span_to_snippet(sp) {\n@@ -669,8 +671,8 @@ impl SourceMap {\n         sp\n     }\n \n-    /// Given a `Span`, get a new `Span` covering the first token and all its trailing whitespace or\n-    /// the original `Span`.\n+    /// Given a `Span`, gets a new `Span` covering the first token and all its trailing whitespace\n+    /// or the original `Span`.\n     ///\n     /// If `sp` points to `\"let mut x\"`, then a span pointing at `\"let \"` will be returned.\n     pub fn span_until_non_whitespace(&self, sp: Span) -> Span {\n@@ -689,15 +691,15 @@ impl SourceMap {\n         })\n     }\n \n-    /// Given a `Span`, get a new `Span` covering the first token without its trailing whitespace or\n-    /// the original `Span` in case of error.\n+    /// Given a `Span`, gets a new `Span` covering the first token without its trailing whitespace\n+    /// or the original `Span` in case of error.\n     ///\n     /// If `sp` points to `\"let mut x\"`, then a span pointing at `\"let\"` will be returned.\n     pub fn span_until_whitespace(&self, sp: Span) -> Span {\n         self.span_take_while(sp, |c| !c.is_whitespace())\n     }\n \n-    /// Given a `Span`, get a shorter one until `predicate` yields false.\n+    /// Given a `Span`, gets a shorter one until `predicate` yields `false`.\n     pub fn span_take_while<P>(&self, sp: Span, predicate: P) -> Span\n         where P: for <'r> FnMut(&'r char) -> bool\n     {\n@@ -717,7 +719,7 @@ impl SourceMap {\n         self.span_until_char(sp, '{')\n     }\n \n-    /// Returns a new span representing just the start-point of this span\n+    /// Returns a new span representing just the start point of this span.\n     pub fn start_point(&self, sp: Span) -> Span {\n         let pos = sp.lo().0;\n         let width = self.find_width_of_character_at_span(sp, false);\n@@ -726,7 +728,7 @@ impl SourceMap {\n         sp.with_hi(end_point)\n     }\n \n-    /// Returns a new span representing just the end-point of this span\n+    /// Returns a new span representing just the end point of this span.\n     pub fn end_point(&self, sp: Span) -> Span {\n         let pos = sp.hi().0;\n \n@@ -737,7 +739,7 @@ impl SourceMap {\n         sp.with_lo(end_point)\n     }\n \n-    /// Returns a new span representing the next character after the end-point of this span\n+    /// Returns a new span representing the next character after the end-point of this span.\n     pub fn next_point(&self, sp: Span) -> Span {\n         let start_of_next_point = sp.hi().0;\n \n@@ -840,30 +842,30 @@ impl SourceMap {\n         None\n     }\n \n-    /// For a global BytePos compute the local offset within the containing SourceFile\n+    /// For a global `BytePos`, computes the local offset within the containing `SourceFile`.\n     pub fn lookup_byte_offset(&self, bpos: BytePos) -> SourceFileAndBytePos {\n         let idx = self.lookup_source_file_idx(bpos);\n         let sf = (*self.files.borrow().source_files)[idx].clone();\n         let offset = bpos - sf.start_pos;\n         SourceFileAndBytePos {sf, pos: offset}\n     }\n \n-    /// Converts an absolute BytePos to a CharPos relative to the source_file.\n+    /// Converts an absolute `BytePos` to a `CharPos` relative to the `SourceFile`.\n     pub fn bytepos_to_file_charpos(&self, bpos: BytePos) -> CharPos {\n         let idx = self.lookup_source_file_idx(bpos);\n         let map = &(*self.files.borrow().source_files)[idx];\n \n-        // The number of extra bytes due to multibyte chars in the SourceFile\n+        // The number of extra bytes due to multibyte chars in the `SourceFile`.\n         let mut total_extra_bytes = 0;\n \n         for mbc in map.multibyte_chars.iter() {\n             debug!(\"{}-byte char at {:?}\", mbc.bytes, mbc.pos);\n             if mbc.pos < bpos {\n-                // every character is at least one byte, so we only\n+                // Every character is at least one byte, so we only\n                 // count the actual extra bytes.\n                 total_extra_bytes += mbc.bytes as u32 - 1;\n                 // We should never see a byte position in the middle of a\n-                // character\n+                // character.\n                 assert!(bpos.to_u32() >= mbc.pos.to_u32() + mbc.bytes as u32);\n             } else {\n                 break;\n@@ -874,13 +876,13 @@ impl SourceMap {\n         CharPos(bpos.to_usize() - map.start_pos.to_usize() - total_extra_bytes as usize)\n     }\n \n-    // Return the index of the source_file (in self.files) which contains pos.\n+    // Returns the index of the `SourceFile` (in `self.files`) that contains `pos`.\n     pub fn lookup_source_file_idx(&self, pos: BytePos) -> usize {\n         let files = self.files.borrow();\n         let files = &files.source_files;\n         let count = files.len();\n \n-        // Binary search for the source_file.\n+        // Binary search for the `SourceFile`.\n         let mut a = 0;\n         let mut b = count;\n         while b - a > 1 {\n@@ -911,8 +913,8 @@ impl SourceMap {\n         }).ok()\n     }\n \n-    /// Take the span of a type parameter in a function signature and try to generate a span for the\n-    /// function name (with generics) and a new snippet for this span with the pointed type\n+    /// Takes the span of a type parameter in a function signature and try to generate a span for\n+    /// the function name (with generics) and a new snippet for this span with the pointed type\n     /// parameter as a new local type parameter.\n     ///\n     /// For instance:\n@@ -928,18 +930,18 @@ impl SourceMap {\n     ///\n     /// Attention: The method used is very fragile since it essentially duplicates the work of the\n     /// parser. If you need to use this function or something similar, please consider updating the\n-    /// source_map functions and this function to something more robust.\n+    /// `SourceMap` functions and this function to something more robust.\n     pub fn generate_local_type_param_snippet(&self, span: Span) -> Option<(Span, String)> {\n         // Try to extend the span to the previous \"fn\" keyword to retrieve the function\n-        // signature\n+        // signature.\n         let sugg_span = self.span_extend_to_prev_str(span, \"fn\", false);\n         if sugg_span != span {\n             if let Ok(snippet) = self.span_to_snippet(sugg_span) {\n-                // Consume the function name\n+                // Consume the function name.\n                 let mut offset = snippet.find(|c: char| !c.is_alphanumeric() && c != '_')\n                     .expect(\"no label after fn\");\n \n-                // Consume the generics part of the function signature\n+                // Consume the generics part of the function signature.\n                 let mut bracket_counter = 0;\n                 let mut last_char = None;\n                 for c in snippet[offset..].chars() {\n@@ -953,11 +955,11 @@ impl SourceMap {\n                     last_char = Some(c);\n                 }\n \n-                // Adjust the suggestion span to encompass the function name with its generics\n+                // Adjust the suggestion span to encompass the function name with its generics.\n                 let sugg_span = sugg_span.with_hi(BytePos(sugg_span.lo().0 + offset as u32));\n \n                 // Prepare the new suggested snippet to append the type parameter that triggered\n-                // the error in the generics of the function signature\n+                // the error in the generics of the function signature.\n                 let mut new_snippet = if last_char == Some('>') {\n                     format!(\"{}, \", &snippet[..(offset - '>'.len_utf8())])\n                 } else {"}, {"sha": "15254336bbfa5dd8049113c24f230d165f16a02e", "filename": "src/libsyntax/source_map/tests.rs", "status": "modified", "additions": 48, "deletions": 39, "changes": 87, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fsource_map%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fsource_map%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fsource_map%2Ftests.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -4,18 +4,24 @@ use rustc_data_structures::sync::Lrc;\n \n fn init_source_map() -> SourceMap {\n     let sm = SourceMap::new(FilePathMapping::empty());\n-    sm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n-                    \"first line.\\nsecond line\".to_string());\n-    sm.new_source_file(PathBuf::from(\"empty.rs\").into(),\n-                    String::new());\n-    sm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n-                    \"first line.\\nsecond line\".to_string());\n+    sm.new_source_file(\n+        PathBuf::from(\"blork.rs\").into(),\n+        \"first line.\\nsecond line\".to_string(),\n+    );\n+    sm.new_source_file(\n+        PathBuf::from(\"empty.rs\").into(),\n+        String::new(),\n+    );\n+    sm.new_source_file(\n+        PathBuf::from(\"blork2.rs\").into(),\n+        \"first line.\\nsecond line\".to_string(),\n+    );\n     sm\n }\n \n+/// Tests `lookup_byte_offset`.\n #[test]\n fn t3() {\n-    // Test lookup_byte_offset\n     let sm = init_source_map();\n \n     let srcfbp1 = sm.lookup_byte_offset(BytePos(23));\n@@ -31,9 +37,9 @@ fn t3() {\n     assert_eq!(srcfbp2.pos, BytePos(0));\n }\n \n+/// Tests `bytepos_to_file_charpos`.\n #[test]\n fn t4() {\n-    // Test bytepos_to_file_charpos\n     let sm = init_source_map();\n \n     let cp1 = sm.bytepos_to_file_charpos(BytePos(22));\n@@ -43,9 +49,9 @@ fn t4() {\n     assert_eq!(cp2, CharPos(0));\n }\n \n+/// Tests zero-length `SourceFile`s.\n #[test]\n fn t5() {\n-    // Test zero-length source_files.\n     let sm = init_source_map();\n \n     let loc1 = sm.lookup_char_pos(BytePos(22));\n@@ -61,17 +67,17 @@ fn t5() {\n \n fn init_source_map_mbc() -> SourceMap {\n     let sm = SourceMap::new(FilePathMapping::empty());\n-    // \u20ac is a three byte utf8 char.\n+    // \"\u20ac\" is a three-byte UTF8 char.\n     sm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n                     \"fir\u20acst \u20ac\u20ac\u20ac\u20ac line.\\nsecond line\".to_string());\n     sm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n                     \"first line\u20ac\u20ac.\\n\u20ac second line\".to_string());\n     sm\n }\n \n+/// Tests `bytepos_to_file_charpos` in the presence of multi-byte chars.\n #[test]\n fn t6() {\n-    // Test bytepos_to_file_charpos in the presence of multi-byte chars\n     let sm = init_source_map_mbc();\n \n     let cp1 = sm.bytepos_to_file_charpos(BytePos(3));\n@@ -87,9 +93,9 @@ fn t6() {\n     assert_eq!(cp4, CharPos(15));\n }\n \n+/// Test `span_to_lines` for a span ending at the end of a `SourceFile`.\n #[test]\n fn t7() {\n-    // Test span_to_lines for a span ending at the end of source_file\n     let sm = init_source_map();\n     let span = Span::with_root_ctxt(BytePos(12), BytePos(23));\n     let file_lines = sm.span_to_lines(span).unwrap();\n@@ -110,7 +116,7 @@ fn span_from_selection(input: &str, selection: &str) -> Span {\n     Span::with_root_ctxt(BytePos(left_index), BytePos(right_index + 1))\n }\n \n-/// Tests span_to_snippet and span_to_lines for a span converting 3\n+/// Tests `span_to_snippet` and `span_to_lines` for a span converting 3\n /// lines in the middle of a file.\n #[test]\n fn span_to_snippet_and_lines_spanning_multiple_lines() {\n@@ -120,10 +126,10 @@ fn span_to_snippet_and_lines_spanning_multiple_lines() {\n     sm.new_source_file(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_string());\n     let span = span_from_selection(inputtext, selection);\n \n-    // check that we are extracting the text we thought we were extracting\n+    // Check that we are extracting the text we thought we were extracting.\n     assert_eq!(&sm.span_to_snippet(span).unwrap(), \"BB\\nCCC\\nDDDDD\");\n \n-    // check that span_to_lines gives us the complete result with the lines/cols we expected\n+    // Check that span_to_lines gives us the complete result with the lines/cols we expected.\n     let lines = sm.span_to_lines(span).unwrap();\n     let expected = vec![\n         LineInfo { line_index: 1, start_col: CharPos(4), end_col: CharPos(6) },\n@@ -133,27 +139,27 @@ fn span_to_snippet_and_lines_spanning_multiple_lines() {\n     assert_eq!(lines.lines, expected);\n }\n \n+/// Test span_to_snippet for a span ending at the end of a `SourceFile`.\n #[test]\n fn t8() {\n-    // Test span_to_snippet for a span ending at the end of source_file\n     let sm = init_source_map();\n     let span = Span::with_root_ctxt(BytePos(12), BytePos(23));\n     let snippet = sm.span_to_snippet(span);\n \n     assert_eq!(snippet, Ok(\"second line\".to_string()));\n }\n \n+/// Test `span_to_str` for a span ending at the end of a `SourceFile`.\n #[test]\n fn t9() {\n-    // Test span_to_str for a span ending at the end of source_file\n     let sm = init_source_map();\n     let span = Span::with_root_ctxt(BytePos(12), BytePos(23));\n     let sstr =  sm.span_to_string(span);\n \n     assert_eq!(sstr, \"blork.rs:2:1: 2:12\");\n }\n \n-/// Tests failing to merge two spans on different lines\n+/// Tests failing to merge two spans on different lines.\n #[test]\n fn span_merging_fail() {\n     let sm = SourceMap::new(FilePathMapping::empty());\n@@ -167,33 +173,37 @@ fn span_merging_fail() {\n     assert!(sm.merge_spans(span1, span2).is_none());\n }\n \n-/// Returns the span corresponding to the `n`th occurrence of\n-/// `substring` in `source_text`.\n+/// Returns the span corresponding to the `n`th occurrence of `substring` in `source_text`.\n trait SourceMapExtension {\n-    fn span_substr(&self,\n-                file: &Lrc<SourceFile>,\n-                source_text: &str,\n-                substring: &str,\n-                n: usize)\n-                -> Span;\n+    fn span_substr(\n+        &self,\n+        file: &Lrc<SourceFile>,\n+        source_text: &str,\n+        substring: &str,\n+        n: usize,\n+    ) -> Span;\n }\n \n impl SourceMapExtension for SourceMap {\n-    fn span_substr(&self,\n-                file: &Lrc<SourceFile>,\n-                source_text: &str,\n-                substring: &str,\n-                n: usize)\n-                -> Span\n-    {\n-        println!(\"span_substr(file={:?}/{:?}, substring={:?}, n={})\",\n-                file.name, file.start_pos, substring, n);\n+    fn span_substr(\n+        &self,\n+        file: &Lrc<SourceFile>,\n+        source_text: &str,\n+        substring: &str,\n+        n: usize,\n+    ) -> Span {\n+        println!(\n+            \"span_substr(file={:?}/{:?}, substring={:?}, n={})\",\n+            file.name, file.start_pos, substring, n\n+        );\n         let mut i = 0;\n         let mut hi = 0;\n         loop {\n             let offset = source_text[hi..].find(substring).unwrap_or_else(|| {\n-                panic!(\"source_text `{}` does not have {} occurrences of `{}`, only {}\",\n-                    source_text, n, substring, i);\n+                panic!(\n+                    \"source_text `{}` does not have {} occurrences of `{}`, only {}\",\n+                    source_text, n, substring, i\n+                );\n             });\n             let lo = hi + offset;\n             hi = lo + substring.len();\n@@ -202,8 +212,7 @@ impl SourceMapExtension for SourceMap {\n                     BytePos(lo as u32 + file.start_pos.0),\n                     BytePos(hi as u32 + file.start_pos.0),\n                 );\n-                assert_eq!(&self.span_to_snippet(span).unwrap()[..],\n-                        substring);\n+                assert_eq!(&self.span_to_snippet(span).unwrap()[..], substring);\n                 return span;\n             }\n             i += 1;"}, {"sha": "540881b0a54965b8ec15f2582887fd640313378e", "filename": "src/libsyntax/tests.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftests.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -18,7 +18,7 @@ use std::path::{Path, PathBuf};\n use std::str;\n use std::sync::{Arc, Mutex};\n \n-/// Map string to parser (via tts)\n+/// Map string to parser (via tts).\n fn string_to_parser(ps: &ParseSess, source_str: String) -> Parser<'_> {\n     new_parser_from_source_str(ps, PathBuf::from(\"bogofile\").into(), source_str)\n }\n@@ -32,7 +32,7 @@ crate fn with_error_checking_parse<'a, T, F>(s: String, ps: &'a ParseSess, f: F)\n     x\n }\n \n-/// Map a string to tts, using a made-up filename:\n+/// Maps a string to tts, using a made-up filename.\n crate fn string_to_stream(source_str: String) -> TokenStream {\n     let ps = ParseSess::new(FilePathMapping::empty());\n     source_file_to_stream(\n@@ -42,7 +42,7 @@ crate fn string_to_stream(source_str: String) -> TokenStream {\n     ), None).0\n }\n \n-/// Parse a string, return a crate.\n+/// Parses a string, returns a crate.\n crate fn string_to_crate(source_str : String) -> ast::Crate {\n     let ps = ParseSess::new(FilePathMapping::empty());\n     with_error_checking_parse(source_str, &ps, |p| {\n@@ -64,7 +64,7 @@ crate fn matches_codepattern(a : &str, b : &str) -> bool {\n             (None, _) => return false,\n             (Some(&a), None) => {\n                 if rustc_lexer::is_whitespace(a) {\n-                    break // trailing whitespace check is out of loop for borrowck\n+                    break // Trailing whitespace check is out of loop for borrowck.\n                 } else {\n                     return false\n                 }\n@@ -73,11 +73,11 @@ crate fn matches_codepattern(a : &str, b : &str) -> bool {\n         };\n \n         if rustc_lexer::is_whitespace(a) && rustc_lexer::is_whitespace(b) {\n-            // skip whitespace for a and b\n+            // Skip whitespace for `a` and `b`.\n             scan_for_non_ws_or_end(&mut a_iter);\n             scan_for_non_ws_or_end(&mut b_iter);\n         } else if rustc_lexer::is_whitespace(a) {\n-            // skip whitespace for a\n+            // Skip whitespace for `a`.\n             scan_for_non_ws_or_end(&mut a_iter);\n         } else if a == b {\n             a_iter.next();\n@@ -87,18 +87,18 @@ crate fn matches_codepattern(a : &str, b : &str) -> bool {\n         }\n     }\n \n-    // check if a has *only* trailing whitespace\n+    // Check if a has *only* trailing whitespace.\n     a_iter.all(rustc_lexer::is_whitespace)\n }\n \n-/// Advances the given peekable `Iterator` until it reaches a non-whitespace character\n+/// Advances the given peekable `Iterator` until it reaches a non-whitespace character.\n fn scan_for_non_ws_or_end<I: Iterator<Item = char>>(iter: &mut Peekable<I>) {\n     while iter.peek().copied().map(|c| rustc_lexer::is_whitespace(c)) == Some(true) {\n         iter.next();\n     }\n }\n \n-/// Identify a position in the text by the Nth occurrence of a string.\n+/// Identifies a position in the text by the n'th occurrence of a string.\n struct Position {\n     string: &'static str,\n     count: usize,"}, {"sha": "d702038f54ec3ef9727a35062d81f60cd9a1c560", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -6,7 +6,7 @@\n //!\n //! ## Ownership\n //!\n-//! `TokenStreams` are persistent data structures constructed as ropes with reference\n+//! `TokenStream`s are persistent data structures constructed as ropes with reference\n //! counted-children. In general, this means that calling an operation on a `TokenStream`\n //! (such as `slice`) produces an entirely new `TokenStream` from the borrowed reference to\n //! the original. This essentially coerces `TokenStream`s into 'views' of their subparts,\n@@ -147,9 +147,8 @@ impl TokenTree {\n     }\n }\n \n-/// # Token Streams\n-///\n /// A `TokenStream` is an abstract sequence of tokens, organized into `TokenTree`s.\n+///\n /// The goal is for procedural macros to work with `TokenStream`s and `TokenTree`s\n /// instead of a representation of the abstract syntax tree.\n /// Today's `TokenTree`s can still contain AST via `token::Interpolated` for back-compat.\n@@ -304,7 +303,7 @@ impl TokenStream {\n         Cursor::new(self)\n     }\n \n-    /// Compares two TokenStreams, checking equality without regarding span information.\n+    /// Compares two `TokenStream`s, checking equality without regarding span information.\n     pub fn eq_unspanned(&self, other: &TokenStream) -> bool {\n         let mut t1 = self.trees();\n         let mut t2 = other.trees();"}, {"sha": "d7c537be89668814707e1b873bd2a4d2a6ba622a", "filename": "src/libsyntax/visit.rs", "status": "modified", "additions": 13, "deletions": 10, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fvisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax%2Fvisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fvisit.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -21,13 +21,13 @@ use syntax_pos::Span;\n \n #[derive(Copy, Clone)]\n pub enum FnKind<'a> {\n-    /// fn foo() or extern \"Abi\" fn foo()\n+    /// E.g., `fn foo()` or `extern \"Abi\" fn foo()`.\n     ItemFn(Ident, &'a FnHeader, &'a Visibility, &'a Block),\n \n-    /// fn foo(&self)\n+    /// E.g., `fn foo(&self)`.\n     Method(Ident, &'a MethodSig, Option<&'a Visibility>, &'a Block),\n \n-    /// |x, y| body\n+    /// E.g., `|x, y| body`.\n     Closure(&'a Expr),\n }\n \n@@ -41,7 +41,7 @@ impl<'a> FnKind<'a> {\n     }\n }\n \n-/// Each method of the Visitor trait is a hook to be potentially\n+/// Each method of the `Visitor` trait is a hook to be potentially\n /// overridden. Each method's default implementation recursively visits\n /// the substructure of the input via the corresponding `walk` method;\n /// e.g., the `visit_mod` method by default calls `visit::walk_mod`.\n@@ -302,10 +302,12 @@ pub fn walk_item<'a, V: Visitor<'a>>(visitor: &mut V, item: &'a Item) {\n     walk_list!(visitor, visit_attribute, &item.attrs);\n }\n \n-pub fn walk_enum_def<'a, V: Visitor<'a>>(visitor: &mut V,\n-                                 enum_definition: &'a EnumDef,\n-                                 _: &'a Generics,\n-                                 _: NodeId) {\n+pub fn walk_enum_def<'a, V: Visitor<'a>>(\n+    visitor: &mut V,\n+    enum_definition: &'a EnumDef,\n+    _: &'a Generics,\n+    _: NodeId,\n+) {\n     walk_list!(visitor, visit_variant, &enum_definition.variants);\n }\n \n@@ -342,7 +344,6 @@ pub fn walk_ty<'a, V: Visitor<'a>>(visitor: &mut V, typ: &'a Ty) {\n             walk_list!(visitor, visit_lifetime, opt_lifetime);\n             visitor.visit_ty(&mutable_type.ty)\n         }\n-        TyKind::Never | TyKind::CVarArgs => {}\n         TyKind::Tup(ref tuple_element_types) => {\n             walk_list!(visitor, visit_ty, tuple_element_types);\n         }\n@@ -371,6 +372,8 @@ pub fn walk_ty<'a, V: Visitor<'a>>(visitor: &mut V, typ: &'a Ty) {\n         TyKind::Mac(ref mac) => {\n             visitor.visit_mac(mac)\n         }\n+        TyKind::Never |\n+        TyKind::CVarArgs => {}\n     }\n }\n \n@@ -386,7 +389,7 @@ pub fn walk_use_tree<'a, V: Visitor<'a>>(\n     visitor.visit_path(&use_tree.prefix, id);\n     match use_tree.kind {\n         UseTreeKind::Simple(rename, ..) => {\n-            // the extra IDs are handled during HIR lowering\n+            // The extra IDs are handled during HIR lowering.\n             if let Some(rename) = rename {\n                 visitor.visit_ident(rename);\n             }"}, {"sha": "2bc990574f7a878a838bec630a98415978506f96", "filename": "src/libsyntax_ext/error_codes.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax_ext%2Ferror_codes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax_ext%2Ferror_codes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Ferror_codes.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,9 +1,8 @@\n-use syntax::register_long_diagnostics;\n-\n // Error messages for EXXXX errors.\n-// Each message should start and end with a new line, and be wrapped to 80 characters.\n-// In vim you can `:set tw=80` and use `gq` to wrap paragraphs. Use `:set tw=0` to disable.\n-register_long_diagnostics! {\n+// Each message should start and end with a new line, and be wrapped to 80\n+// characters.  In vim you can `:set tw=80` and use `gq` to wrap paragraphs. Use\n+// `:set tw=0` to disable.\n+syntax::register_diagnostics! {\n E0660: r##\"\n The argument to the `asm` macro is not well-formed.\n "}, {"sha": "631ab7a33106f2aa63ab765d78ab286ecab7545f", "filename": "src/libsyntax_ext/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax_ext%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Flibsyntax_ext%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Flib.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -9,7 +9,6 @@\n #![feature(nll)]\n #![feature(proc_macro_internals)]\n #![feature(proc_macro_quote)]\n-#![feature(rustc_diagnostic_macros)]\n \n extern crate proc_macro;\n "}, {"sha": "641e4b852e79f8441372d920b5c67088e325474a", "filename": "src/test/ui/feature-gate/allow-features-empty.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features-empty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features-empty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features-empty.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,8 +1,6 @@\n // compile-flags: -Z allow_features=\n // Note: This test uses rustc internal flags because they will never stabilize.\n \n-#![feature(rustc_diagnostic_macros)] //~ ERROR\n-\n #![feature(rustc_const_unstable)] //~ ERROR\n \n #![feature(lang_items)] //~ ERROR"}, {"sha": "a87d105850327c911357c074af0e8b78fe908bbb", "filename": "src/test/ui/feature-gate/allow-features-empty.stderr", "status": "modified", "additions": 4, "deletions": 10, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features-empty.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features-empty.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features-empty.stderr?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,27 +1,21 @@\n-error[E0725]: the feature `rustc_diagnostic_macros` is not in the list of allowed features\n-  --> $DIR/allow-features-empty.rs:4:12\n-   |\n-LL | #![feature(rustc_diagnostic_macros)]\n-   |            ^^^^^^^^^^^^^^^^^^^^^^^\n-\n error[E0725]: the feature `rustc_const_unstable` is not in the list of allowed features\n-  --> $DIR/allow-features-empty.rs:6:12\n+  --> $DIR/allow-features-empty.rs:4:12\n    |\n LL | #![feature(rustc_const_unstable)]\n    |            ^^^^^^^^^^^^^^^^^^^^\n \n error[E0725]: the feature `lang_items` is not in the list of allowed features\n-  --> $DIR/allow-features-empty.rs:8:12\n+  --> $DIR/allow-features-empty.rs:6:12\n    |\n LL | #![feature(lang_items)]\n    |            ^^^^^^^^^^\n \n error[E0725]: the feature `unknown_stdlib_feature` is not in the list of allowed features\n-  --> $DIR/allow-features-empty.rs:10:12\n+  --> $DIR/allow-features-empty.rs:8:12\n    |\n LL | #![feature(unknown_stdlib_feature)]\n    |            ^^^^^^^^^^^^^^^^^^^^^^\n \n-error: aborting due to 4 previous errors\n+error: aborting due to 3 previous errors\n \n For more information about this error, try `rustc --explain E0725`."}, {"sha": "de69e48a65fdfab5a04259db7d97f1de194c5ed1", "filename": "src/test/ui/feature-gate/allow-features.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,8 +1,6 @@\n-// compile-flags: -Z allow_features=rustc_diagnostic_macros,lang_items\n+// compile-flags: -Z allow_features=lang_items\n // Note: This test uses rustc internal flags because they will never stabilize.\n \n-#![feature(rustc_diagnostic_macros)]\n-\n #![feature(rustc_const_unstable)] //~ ERROR\n \n #![feature(lang_items)]"}, {"sha": "157dddf06ad1d6dbf28ebc214b1b16c0f4cbd9ee", "filename": "src/test/ui/feature-gate/allow-features.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ffeature-gate%2Fallow-features.stderr?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -1,11 +1,11 @@\n error[E0725]: the feature `rustc_const_unstable` is not in the list of allowed features\n-  --> $DIR/allow-features.rs:6:12\n+  --> $DIR/allow-features.rs:4:12\n    |\n LL | #![feature(rustc_const_unstable)]\n    |            ^^^^^^^^^^^^^^^^^^^^\n \n error[E0725]: the feature `unknown_stdlib_feature` is not in the list of allowed features\n-  --> $DIR/allow-features.rs:10:12\n+  --> $DIR/allow-features.rs:8:12\n    |\n LL | #![feature(unknown_stdlib_feature)]\n    |            ^^^^^^^^^^^^^^^^^^^^^^"}, {"sha": "63c2c31fd30e625cc2368cc9074a2995cc4aeafb", "filename": "src/test/ui/feature-gates/feature-gate-rustc-diagnostic-macros.rs", "status": "removed", "additions": 0, "deletions": 13, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/ef54f57c5b9d894a38179d09b00610c1b337b086/src%2Ftest%2Fui%2Ffeature-gates%2Ffeature-gate-rustc-diagnostic-macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ef54f57c5b9d894a38179d09b00610c1b337b086/src%2Ftest%2Fui%2Ffeature-gates%2Ffeature-gate-rustc-diagnostic-macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ffeature-gates%2Ffeature-gate-rustc-diagnostic-macros.rs?ref=ef54f57c5b9d894a38179d09b00610c1b337b086", "patch": "@@ -1,13 +0,0 @@\n-// Test that diagnostic macros are gated by `rustc_diagnostic_macros` feature\n-// gate\n-\n-__register_diagnostic!(E0001);\n-//~^ ERROR cannot find macro `__register_diagnostic!` in this scope\n-\n-fn main() {\n-    __diagnostic_used!(E0001);\n-    //~^ ERROR cannot find macro `__diagnostic_used!` in this scope\n-}\n-\n-__build_diagnostic_array!(DIAGNOSTICS);\n-//~^ ERROR cannot find macro `__build_diagnostic_array!` in this scope"}, {"sha": "676b8b9f056c1288c79909c5340a26eedffa3711", "filename": "src/test/ui/feature-gates/feature-gate-rustc-diagnostic-macros.stderr", "status": "removed", "additions": 0, "deletions": 20, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/ef54f57c5b9d894a38179d09b00610c1b337b086/src%2Ftest%2Fui%2Ffeature-gates%2Ffeature-gate-rustc-diagnostic-macros.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/ef54f57c5b9d894a38179d09b00610c1b337b086/src%2Ftest%2Fui%2Ffeature-gates%2Ffeature-gate-rustc-diagnostic-macros.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ffeature-gates%2Ffeature-gate-rustc-diagnostic-macros.stderr?ref=ef54f57c5b9d894a38179d09b00610c1b337b086", "patch": "@@ -1,20 +0,0 @@\n-error: cannot find macro `__build_diagnostic_array!` in this scope\n-  --> $DIR/feature-gate-rustc-diagnostic-macros.rs:12:1\n-   |\n-LL | __build_diagnostic_array!(DIAGNOSTICS);\n-   | ^^^^^^^^^^^^^^^^^^^^^^^^\n-\n-error: cannot find macro `__diagnostic_used!` in this scope\n-  --> $DIR/feature-gate-rustc-diagnostic-macros.rs:8:5\n-   |\n-LL |     __diagnostic_used!(E0001);\n-   |     ^^^^^^^^^^^^^^^^^\n-\n-error: cannot find macro `__register_diagnostic!` in this scope\n-  --> $DIR/feature-gate-rustc-diagnostic-macros.rs:4:1\n-   |\n-LL | __register_diagnostic!(E0001);\n-   | ^^^^^^^^^^^^^^^^^^^^^\n-\n-error: aborting due to 3 previous errors\n-"}, {"sha": "745233c151cd6fec6de13e7e868a6cec862af8d5", "filename": "src/tools/compiletest/Cargo.toml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Fcompiletest%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Fcompiletest%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fcompiletest%2FCargo.toml?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -6,7 +6,7 @@ edition = \"2018\"\n \n [dependencies]\n diff = \"0.1.10\"\n-env_logger = { version = \"0.5\", default-features = false }\n+env_logger = { version = \"0.6\", default-features = false }\n getopts = \"0.2\"\n log = \"0.4\"\n regex = \"1.0\""}, {"sha": "819d399f34a41ef055b9a3a55ebe0acf85245e54", "filename": "src/tools/compiletest/src/header.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Fcompiletest%2Fsrc%2Fheader.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Fcompiletest%2Fsrc%2Fheader.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fcompiletest%2Fsrc%2Fheader.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -835,10 +835,10 @@ impl Config {\n \n             if name == \"test\" ||\n                 util::matches_os(&self.target, name) ||             // target\n+                util::matches_env(&self.target, name) ||            // env\n                 name == util::get_arch(&self.target) ||             // architecture\n                 name == util::get_pointer_width(&self.target) ||    // pointer width\n                 name == self.stage_id.split('-').next().unwrap() || // stage\n-                Some(name) == util::get_env(&self.target) ||        // env\n                 (self.target != self.host && name == \"cross-compile\") ||\n                 match self.compare_mode {\n                     Some(CompareMode::Nll) => name == \"compare-mode-nll\","}, {"sha": "3a2ee445087d5f2e95e6cbae87699b9c6889ecaf", "filename": "src/tools/compiletest/src/util.rs", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Fcompiletest%2Fsrc%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Fcompiletest%2Fsrc%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fcompiletest%2Fsrc%2Futil.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -105,8 +105,12 @@ pub fn get_arch(triple: &str) -> &'static str {\n     panic!(\"Cannot determine Architecture from triple\");\n }\n \n-pub fn get_env(triple: &str) -> Option<&str> {\n-    triple.split('-').nth(3)\n+pub fn matches_env(triple: &str, name: &str) -> bool {\n+    if let Some(env) = triple.split('-').nth(3) {\n+        env.starts_with(name)\n+    } else {\n+        false\n+    }\n }\n \n pub fn get_pointer_width(triple: &str) -> &'static str {"}, {"sha": "832aa3b1c8dfd3378d4b30ef74593f52fe733153", "filename": "src/tools/error_index_generator/build.rs", "status": "modified", "additions": 22, "deletions": 29, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Ferror_index_generator%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Ferror_index_generator%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ferror_index_generator%2Fbuild.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -14,9 +14,7 @@ fn main() {\n         if entry.file_name() == \"error_codes.rs\" {\n             println!(\"cargo:rerun-if-changed={}\", entry.path().to_str().unwrap());\n             let file = fs::read_to_string(entry.path()).unwrap()\n-                .replace(\"use syntax::{register_diagnostics, register_long_diagnostics};\", \"\")\n-                .replace(\"use syntax::register_diagnostics;\", \"\")\n-                .replace(\"use syntax::register_long_diagnostics;\", \"\");\n+                .replace(\"syntax::register_diagnostics!\", \"register_diagnostics!\");\n             let contents = format!(\"(|| {{\\n{}\\n}})();\", file);\n \n             fs::write(&out_dir.join(&format!(\"error_{}.rs\", idx)), &contents).unwrap();\n@@ -26,36 +24,31 @@ fn main() {\n     }\n \n     let mut all = String::new();\n-    all.push_str(\"fn register_all() -> Vec<(&'static str, Option<&'static str>)> {\\n\");\n-    all.push_str(\"let mut long_codes: Vec<(&'static str, Option<&'static str>)> = Vec::new();\\n\");\n-    all.push_str(r#\"\n-macro_rules! register_diagnostics {\n-    ($($code:tt),*) => {{\n-        long_codes.extend([$(\n-            stringify!($code),\n-        )*].iter().cloned().map(|s| (s, None)).collect::<Vec<_>>());\n-    }};\n-    ($($code:tt),*,) => {{\n-        long_codes.extend([$(\n-            stringify!($code),\n-        )*].iter().cloned().map(|s| (s, None)));\n-    }}\n-}\n+    all.push_str(r###\"\n+fn register_all() -> Vec<(&'static str, Option<&'static str>)> {\n+    let mut long_codes: Vec<(&'static str, Option<&'static str>)> = Vec::new();\n+    macro_rules! register_diagnostics {\n+        ($($ecode:ident: $message:expr,)*) => (\n+            register_diagnostics!{$($ecode:$message,)* ;}\n+        );\n \n-macro_rules! register_long_diagnostics {\n-    ($($code:tt: $description:tt),*) => {\n-        {long_codes.extend([$(\n-            (stringify!($code), Some(stringify!($description))),\n-        )*].iter());}\n-    };\n-    ($($code:tt: $description:tt),*,) => {\n-        {long_codes.extend([$(\n-            (stringify!($code), Some(stringify!($description))),\n-        )*].iter());}\n+        ($($ecode:ident: $message:expr,)* ; $($code:ident,)*) => (\n+            $(\n+                {long_codes.extend([\n+                    (stringify!($ecode), Some(stringify!($message))),\n+                ].iter());}\n+            )*\n+            $(\n+                {long_codes.extend([\n+                    stringify!($code),\n+                ].iter().cloned().map(|s| (s, None)).collect::<Vec<_>>());}\n+            )*\n+        )\n     }\n-}\"#);\n+\"###);\n     for idx in 0..idx {\n         all.push_str(&format!(r#\"include!(concat!(env!(\"OUT_DIR\"), \"/error_{}.rs\"));\"#, idx));\n+        all.push_str(\"\\n\");\n     }\n     all.push_str(\"\\nlong_codes\\n\");\n     all.push_str(\"}\\n\");"}, {"sha": "930290996861515c7317184a87b1a5bd39ba94ba", "filename": "src/tools/tidy/src/style.rs", "status": "modified", "additions": 20, "deletions": 6, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Ftidy%2Fsrc%2Fstyle.rs", "raw_url": "https://github.com/rust-lang/rust/raw/43a5ff4222e1f217ac14331afd59f82ec4204d12/src%2Ftools%2Ftidy%2Fsrc%2Fstyle.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ftidy%2Fsrc%2Fstyle.rs?ref=43a5ff4222e1f217ac14331afd59f82ec4204d12", "patch": "@@ -15,6 +15,7 @@\n \n use std::path::Path;\n \n+const ERROR_CODE_COLS: usize = 80;\n const COLS: usize = 100;\n \n const LINES: usize = 3000;\n@@ -51,7 +52,13 @@ enum LIUState {\n /// Lines of this form are allowed to be overlength, because Markdown\n /// offers no way to split a line in the middle of a URL, and the lengths\n /// of URLs to external references are beyond our control.\n-fn line_is_url(line: &str) -> bool {\n+fn line_is_url(columns: usize, line: &str) -> bool {\n+    // more basic check for error_codes.rs, to avoid complexity in implementing two state machines\n+    if columns == ERROR_CODE_COLS {\n+        return line.starts_with(\"[\") &&\n+            line.contains(\"]:\") && line.contains(\"http\");\n+    }\n+\n     use self::LIUState::*;\n     let mut state: LIUState = EXP_COMMENT_START;\n     let is_url = |w: &str| w.starts_with(\"http://\") || w.starts_with(\"https://\");\n@@ -75,7 +82,7 @@ fn line_is_url(line: &str) -> bool {\n                 => state = EXP_END,\n \n             (_, w)\n-                if w.len() > COLS && is_url(w)\n+                if w.len() > columns && is_url(w)\n                 => state = EXP_END,\n \n             (_, _) => {}\n@@ -88,8 +95,8 @@ fn line_is_url(line: &str) -> bool {\n /// Returns `true` if `line` is allowed to be longer than the normal limit.\n /// Currently there is only one exception, for long URLs, but more\n /// may be added in the future.\n-fn long_line_is_ok(line: &str) -> bool {\n-    if line_is_url(line) {\n+fn long_line_is_ok(max_columns: usize, line: &str) -> bool {\n+    if line_is_url(max_columns, line) {\n         return true;\n     }\n \n@@ -144,6 +151,12 @@ pub fn check(path: &Path, bad: &mut bool) {\n             tidy_error!(bad, \"{}: empty file\", file.display());\n         }\n \n+        let max_columns = if filename == \"error_codes.rs\" {\n+            ERROR_CODE_COLS\n+        } else {\n+            COLS\n+        };\n+\n         let can_contain = contents.contains(\"// ignore-tidy-\") ||\n             contents.contains(\"# ignore-tidy-\");\n         let mut skip_cr = contains_ignore_directive(can_contain, &contents, \"cr\");\n@@ -162,11 +175,12 @@ pub fn check(path: &Path, bad: &mut bool) {\n             let mut err = |msg: &str| {\n                 tidy_error!(bad, \"{}:{}: {}\", file.display(), i + 1, msg);\n             };\n-            if line.chars().count() > COLS && !long_line_is_ok(line) {\n+            if line.chars().count() > max_columns &&\n+                !long_line_is_ok(max_columns, line) {\n                 suppressible_tidy_err!(\n                     err,\n                     skip_line_length,\n-                    &format!(\"line longer than {} chars\", COLS)\n+                    &format!(\"line longer than {} chars\", max_columns)\n                 );\n             }\n             if line.contains('\\t') {"}]}