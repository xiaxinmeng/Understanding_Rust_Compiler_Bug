{"sha": "4bfab89aa258f25ceb8cc4973127fceaa5367ec3", "node_id": "MDY6Q29tbWl0NzI0NzEyOjRiZmFiODlhYTI1OGYyNWNlYjhjYzQ5NzMxMjdmY2VhYTUzNjdlYzM=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2017-11-14T15:15:45Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2017-11-14T15:15:45Z"}, "message": "incr.comp.: Store the query result index which records where query results can be found in the cached.", "tree": {"sha": "c0523cdbe6494a7bcc7e1fc9ab6dc5d55273b915", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c0523cdbe6494a7bcc7e1fc9ab6dc5d55273b915"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4bfab89aa258f25ceb8cc4973127fceaa5367ec3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4bfab89aa258f25ceb8cc4973127fceaa5367ec3", "html_url": "https://github.com/rust-lang/rust/commit/4bfab89aa258f25ceb8cc4973127fceaa5367ec3", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4bfab89aa258f25ceb8cc4973127fceaa5367ec3/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2087d5ebfa06a32b4142f3cebbe4add0e62a9588", "url": "https://api.github.com/repos/rust-lang/rust/commits/2087d5ebfa06a32b4142f3cebbe4add0e62a9588", "html_url": "https://github.com/rust-lang/rust/commit/2087d5ebfa06a32b4142f3cebbe4add0e62a9588"}], "stats": {"total": 154, "additions": 134, "deletions": 20}, "files": [{"sha": "6b0cc426b52aac6b6251277771cdc93edae6a430", "filename": "src/librustc/ty/maps/on_disk_cache.rs", "status": "modified", "additions": 133, "deletions": 19, "changes": 152, "blob_url": "https://github.com/rust-lang/rust/blob/4bfab89aa258f25ceb8cc4973127fceaa5367ec3/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bfab89aa258f25ceb8cc4973127fceaa5367ec3/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs?ref=4bfab89aa258f25ceb8cc4973127fceaa5367ec3", "patch": "@@ -20,7 +20,7 @@ use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::indexed_vec::{IndexVec, Idx};\n use rustc_serialize::{Decodable, Decoder, Encodable, Encoder, opaque,\n                       SpecializedDecoder, SpecializedEncoder,\n-                      UseSpecializedDecodable};\n+                      UseSpecializedDecodable, UseSpecializedEncodable};\n use session::{CrateDisambiguator, Session};\n use std::borrow::Cow;\n use std::cell::RefCell;\n@@ -30,20 +30,25 @@ use syntax::ast::NodeId;\n use syntax::codemap::{CodeMap, StableFilemapId};\n use syntax_pos::{BytePos, Span, NO_EXPANSION, DUMMY_SP};\n use ty;\n-use ty::codec::{self as ty_codec, TyDecoder};\n+use ty::codec::{self as ty_codec, TyDecoder, TyEncoder};\n use ty::context::TyCtxt;\n use ty::subst::Substs;\n \n // Some magic values used for verifying that encoding and decoding. These are\n // basically random numbers.\n const PREV_DIAGNOSTICS_TAG: u64 = 0x1234_5678_A1A1_A1A1;\n const DEF_PATH_TABLE_TAG: u64 = 0x1234_5678_B2B2_B2B2;\n+const QUERY_RESULT_INDEX_TAG: u64 = 0x1234_5678_C3C3_C3C3;\n \n /// `OnDiskCache` provides an interface to incr. comp. data cached from the\n /// previous compilation session. This data will eventually include the results\n /// of a few selected queries (like `typeck_tables_of` and `mir_optimized`) and\n /// any diagnostics that have been emitted during a query.\n pub struct OnDiskCache<'sess> {\n+\n+    // The complete cache data in serialized form.\n+    serialized_data: Vec<u8>,\n+\n     // The diagnostics emitted during the previous compilation session.\n     prev_diagnostics: FxHashMap<SerializedDepNodeIndex, Vec<Diagnostic>>,\n \n@@ -56,8 +61,12 @@ pub struct OnDiskCache<'sess> {\n     cnum_map: RefCell<Option<IndexVec<CrateNum, Option<CrateNum>>>>,\n     prev_def_path_tables: Vec<DefPathTable>,\n \n-    _prev_filemap_starts: BTreeMap<BytePos, StableFilemapId>,\n+    prev_filemap_starts: BTreeMap<BytePos, StableFilemapId>,\n     codemap: &'sess CodeMap,\n+\n+    // A map from dep-node to the position of the cached query result in\n+    // `serialized_data`.\n+    query_result_index: FxHashMap<SerializedDepNodeIndex, usize>,\n }\n \n // This type is used only for (de-)serialization.\n@@ -68,26 +77,25 @@ struct Header {\n }\n \n type EncodedPrevDiagnostics = Vec<(SerializedDepNodeIndex, Vec<Diagnostic>)>;\n+type EncodedQueryResultIndex = Vec<(SerializedDepNodeIndex, usize)>;\n \n impl<'sess> OnDiskCache<'sess> {\n     /// Create a new OnDiskCache instance from the serialized data in `data`.\n-    /// Note that the current implementation (which only deals with diagnostics\n-    /// so far) will eagerly deserialize the complete cache. Once we are\n-    /// dealing with larger amounts of data (i.e. cached query results),\n-    /// deserialization will need to happen lazily.\n-    pub fn new(sess: &'sess Session, data: &[u8], start_pos: usize) -> OnDiskCache<'sess> {\n+    pub fn new(sess: &'sess Session, data: Vec<u8>, start_pos: usize) -> OnDiskCache<'sess> {\n         debug_assert!(sess.opts.incremental.is_some());\n \n-        let mut decoder = opaque::Decoder::new(&data[..], start_pos);\n-\n-\n         // Decode the header\n-        let header = Header::decode(&mut decoder).unwrap();\n+        let (header, post_header_pos) = {\n+            let mut decoder = opaque::Decoder::new(&data[..], start_pos);\n+            let header = Header::decode(&mut decoder)\n+                .expect(\"Error while trying to decode incr. comp. cache header.\");\n+            (header, decoder.position())\n+        };\n \n-        let (prev_diagnostics, prev_def_path_tables) = {\n+        let (prev_diagnostics, prev_def_path_tables, query_result_index) = {\n             let mut decoder = CacheDecoder {\n                 tcx: None,\n-                opaque: decoder,\n+                opaque: opaque::Decoder::new(&data[..], post_header_pos),\n                 codemap: sess.codemap(),\n                 prev_filemap_starts: &header.prev_filemap_starts,\n                 cnum_map: &IndexVec::new(),\n@@ -100,38 +108,56 @@ impl<'sess> OnDiskCache<'sess> {\n                     decode_tagged(&mut decoder, PREV_DIAGNOSTICS_TAG)\n                         .expect(\"Error while trying to decode previous session \\\n                                  diagnostics from incr. comp. cache.\");\n-\n                 diagnostics.into_iter().collect()\n             };\n \n             // Decode DefPathTables\n             let prev_def_path_tables: Vec<DefPathTable> =\n                 decode_tagged(&mut decoder, DEF_PATH_TABLE_TAG)\n-                    .expect(\"Error while trying to decode cached DefPathTables\");\n+                    .expect(\"Error while trying to decode cached DefPathTables.\");\n+\n+            // Decode the *position* of the query result index\n+            let query_result_index_pos = {\n+                let pos_pos = data.len() - IntEncodedWithFixedSize::ENCODED_SIZE;\n+                decoder.with_position(pos_pos, |decoder| {\n+                    IntEncodedWithFixedSize::decode(decoder)\n+                }).expect(\"Error while trying to decode query result index position.\")\n+                .0 as usize\n+            };\n \n-            (prev_diagnostics, prev_def_path_tables)\n+            // Decode the query result index itself\n+            let query_result_index: EncodedQueryResultIndex =\n+                decoder.with_position(query_result_index_pos, |decoder| {\n+                    decode_tagged(decoder, QUERY_RESULT_INDEX_TAG)\n+                }).expect(\"Error while trying to decode query result index.\");\n+\n+            (prev_diagnostics, prev_def_path_tables, query_result_index)\n         };\n \n         OnDiskCache {\n+            serialized_data: data,\n             prev_diagnostics,\n-            _prev_filemap_starts: header.prev_filemap_starts,\n+            prev_filemap_starts: header.prev_filemap_starts,\n             prev_cnums: header.prev_cnums,\n             cnum_map: RefCell::new(None),\n             prev_def_path_tables,\n             codemap: sess.codemap(),\n             current_diagnostics: RefCell::new(FxHashMap()),\n+            query_result_index: query_result_index.into_iter().collect(),\n         }\n     }\n \n     pub fn new_empty(codemap: &'sess CodeMap) -> OnDiskCache<'sess> {\n         OnDiskCache {\n+            serialized_data: Vec::new(),\n             prev_diagnostics: FxHashMap(),\n-            _prev_filemap_starts: BTreeMap::new(),\n+            prev_filemap_starts: BTreeMap::new(),\n             prev_cnums: vec![],\n             cnum_map: RefCell::new(None),\n             prev_def_path_tables: Vec::new(),\n             codemap,\n             current_diagnostics: RefCell::new(FxHashMap()),\n+            query_result_index: FxHashMap(),\n         }\n     }\n \n@@ -201,6 +227,20 @@ impl<'sess> OnDiskCache<'sess> {\n \n         encoder.encode_tagged(DEF_PATH_TABLE_TAG, &def_path_tables)?;\n \n+\n+        // Encode query results\n+        let query_result_index = EncodedQueryResultIndex::new();\n+        // ... we don't encode anything yet, actually\n+\n+\n+        // Encode query result index\n+        let query_result_index_pos = encoder.position() as u64;\n+        encoder.encode_tagged(QUERY_RESULT_INDEX_TAG, &query_result_index)?;\n+\n+        // Encode the position of the query result index as the last 8 bytes of\n+        // file so we know where to look for it.\n+        IntEncodedWithFixedSize(query_result_index_pos).encode(&mut encoder)?;\n+\n         return Ok(());\n \n         fn sorted_cnums_including_local_crate(cstore: &CrateStore) -> Vec<CrateNum> {\n@@ -231,6 +271,38 @@ impl<'sess> OnDiskCache<'sess> {\n         debug_assert!(prev.is_none());\n     }\n \n+    pub fn load_query_result<'a, 'tcx, T>(&self,\n+                                          tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                                          dep_node_index: SerializedDepNodeIndex)\n+                                          -> T\n+        where T: Decodable\n+    {\n+        let pos = self.query_result_index[&dep_node_index];\n+\n+        let mut cnum_map = self.cnum_map.borrow_mut();\n+        if cnum_map.is_none() {\n+            *cnum_map = Some(Self::compute_cnum_map(tcx, &self.prev_cnums[..]));\n+        }\n+\n+        let mut decoder = CacheDecoder {\n+            tcx: Some(tcx),\n+            opaque: opaque::Decoder::new(&self.serialized_data[..], pos),\n+            codemap: self.codemap,\n+            prev_filemap_starts: &self.prev_filemap_starts,\n+            cnum_map: cnum_map.as_ref().unwrap(),\n+            prev_def_path_tables: &self.prev_def_path_tables,\n+        };\n+\n+        match decode_tagged(&mut decoder, dep_node_index) {\n+            Ok(value) => {\n+                value\n+            }\n+            Err(e) => {\n+                bug!(\"Could not decode cached query result: {}\", e)\n+            }\n+        }\n+    }\n+\n     /// Store a diagnostic emitted during computation of an anonymous query.\n     /// Since many anonymous queries can share the same `DepNode`, we aggregate\n     /// them -- as opposed to regular queries where we assume that there is a\n@@ -700,3 +772,45 @@ impl<'enc, 'tcx, E> Encoder for CacheEncoder<'enc, 'tcx, E>\n     }\n }\n \n+// An integer that will always encode to 8 bytes.\n+struct IntEncodedWithFixedSize(u64);\n+\n+impl IntEncodedWithFixedSize {\n+    pub const ENCODED_SIZE: usize = 8;\n+}\n+\n+impl UseSpecializedEncodable for IntEncodedWithFixedSize {}\n+impl UseSpecializedDecodable for IntEncodedWithFixedSize {}\n+\n+impl<'enc, 'tcx, E> SpecializedEncoder<IntEncodedWithFixedSize>\n+for CacheEncoder<'enc, 'tcx, E>\n+    where E: 'enc + ty_codec::TyEncoder\n+{\n+    fn specialized_encode(&mut self, x: &IntEncodedWithFixedSize) -> Result<(), Self::Error> {\n+        let start_pos = self.position();\n+        for i in 0 .. IntEncodedWithFixedSize::ENCODED_SIZE {\n+            ((x.0 >> i * 8) as u8).encode(self)?;\n+        }\n+        let end_pos = self.position();\n+        assert_eq!((end_pos - start_pos), IntEncodedWithFixedSize::ENCODED_SIZE);\n+        Ok(())\n+    }\n+}\n+\n+impl<'a, 'tcx, 'x> SpecializedDecoder<IntEncodedWithFixedSize>\n+for CacheDecoder<'a, 'tcx, 'x> {\n+    fn specialized_decode(&mut self) -> Result<IntEncodedWithFixedSize, Self::Error> {\n+        let mut value: u64 = 0;\n+        let start_pos = self.position();\n+\n+        for i in 0 .. IntEncodedWithFixedSize::ENCODED_SIZE {\n+            let byte: u8 = Decodable::decode(self)?;\n+            value |= (byte as u64) << (i * 8);\n+        }\n+\n+        let end_pos = self.position();\n+        assert_eq!((end_pos - start_pos), IntEncodedWithFixedSize::ENCODED_SIZE);\n+\n+        Ok(IntEncodedWithFixedSize(value))\n+    }\n+}"}, {"sha": "44111e8af0945e70b9ca20ad1e9a412579cee480", "filename": "src/librustc_incremental/persist/load.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4bfab89aa258f25ceb8cc4973127fceaa5367ec3/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bfab89aa258f25ceb8cc4973127fceaa5367ec3/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fload.rs?ref=4bfab89aa258f25ceb8cc4973127fceaa5367ec3", "patch": "@@ -207,7 +207,7 @@ pub fn load_query_result_cache<'sess>(sess: &'sess Session) -> OnDiskCache<'sess\n     }\n \n     if let Some((bytes, start_pos)) = load_data(sess, &query_cache_path(sess)) {\n-        OnDiskCache::new(sess, &bytes[..], start_pos)\n+        OnDiskCache::new(sess, bytes, start_pos)\n     } else {\n         OnDiskCache::new_empty(sess.codemap())\n     }"}]}