{"sha": "fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZlZmRiNjNjNGMyYjA3OGM0MzgzNmUyYWU5ZDdmZmNhZWVjMzI4OTA=", "commit": {"author": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2012-01-13T03:10:30Z"}, "committer": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2012-01-13T03:10:30Z"}, "message": "Begin shift over to using pandoc, markdown and llnextgen for reference manual. Fix man page URL while at it.", "tree": {"sha": "1ce371a50ece05cec0d1b9755fadaed376b7723e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1ce371a50ece05cec0d1b9755fadaed376b7723e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "html_url": "https://github.com/rust-lang/rust/commit/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/comments", "author": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "committer": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "565ea068ca6deb50c5866475508c538dc7e3acee", "url": "https://api.github.com/repos/rust-lang/rust/commits/565ea068ca6deb50c5866475508c538dc7e3acee", "html_url": "https://github.com/rust-lang/rust/commit/565ea068ca6deb50c5866475508c538dc7e3acee"}], "stats": {"total": 876, "additions": 846, "deletions": 30}, "files": [{"sha": "b62f6abe86c7d34a50275d0aa052b8413741ce4a", "filename": "Makefile.in", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/Makefile.in", "raw_url": "https://github.com/rust-lang/rust/raw/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/Makefile.in", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Makefile.in?ref=fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "patch": "@@ -132,17 +132,17 @@ ifdef CFG_BAD_VALGRIND\n endif\n \n DOCS :=\n-ifeq ($(CFG_MAKEINFO),)\n-  $(info cfg: no makeinfo found, omitting doc/rust.html)\n+ifeq ($(CFG_PANDOC),)\n+  $(info cfg: no pandoc found, omitting doc/rust.html)\n else\n   DOCS += doc/rust.html\n endif\n \n-ifeq ($(CFG_TEXI2PDF),)\n-  $(info cfg: no texi2pdf found, omitting doc/rust.pdf)\n+ifeq ($(CFG_PANDOC),)\n+  $(info cfg: no pandoc found, omitting doc/rust.pdf)\n else\n-  ifeq ($(CFG_TEX),)\n-    $(info cfg: no tex found, omitting doc/rust.pdf)\n+  ifeq ($(CFG_PDFLATEX),)\n+    $(info cfg: no pdflatex found, omitting doc/rust.pdf)\n   else\n     DOCS += doc/rust.pdf\n   endif"}, {"sha": "71dac58feeabf1b65456d901dbb92b1dd2791763", "filename": "configure", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/configure", "raw_url": "https://github.com/rust-lang/rust/raw/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/configure", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/configure?ref=fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "patch": "@@ -284,11 +284,11 @@ probe CFG_GCC              gcc\n probe CFG_LLVM_CONFIG      llvm-config\n probe CFG_VALGRIND         valgrind\n probe CFG_PERF             perf\n-probe CFG_MAKEINFO         makeinfo\n-probe CFG_TEXI2PDF         texi2pdf\n-probe CFG_TEX              tex\n probe CFG_MAKENSIS         makensis\n probe CFG_NATURALDOCS      naturaldocs\n+probe CFG_LLNEXTGEN        LLnextgen\n+probe CFG_PANDOC           pandoc\n+probe CFG_PDFLATEX         pdflatex\n \n if [ -z \"$CFG_ENABLE_CLANG\" -a -z \"$CFG_GCC\" ]\n then"}, {"sha": "e026b2ef860ed98867ed6755fa03655000b3fd5b", "filename": "doc/rust.md", "status": "added", "additions": 645, "deletions": 0, "changes": 645, "blob_url": "https://github.com/rust-lang/rust/blob/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/doc%2Frust.md", "raw_url": "https://github.com/rust-lang/rust/raw/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/doc%2Frust.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/doc%2Frust.md?ref=fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "patch": "@@ -0,0 +1,645 @@\n+% Rust Reference Manual\n+% January 2012\n+\n+# Introduction\n+\n+This document is the reference manual for the Rust programming language. It\n+provides three kinds of material:\n+\n+  - Chapters that formally define the language grammar and, for each\n+    construct, informally describe its semantics and give examples of its\n+    use.\n+  - Chapters that informally describe the memory model, concurrency model,\n+    runtime services, linkage model and debugging facilities.\n+  - Appendix chapters providing rationale and references to languages that\n+    influenced the design.\n+\n+This document does not serve as a tutorial introduction to the\n+language. Background familiarity with the language is assumed. A separate\n+tutorial document is available at <http://www.rust-lang.org/doc/tutorial>\n+to help acquire such background familiarity.\n+\n+This document also does not serve as a reference to the core or standard\n+libraries included in the language distribution. Those libraries are\n+documented separately by extracting documentation attributes from their\n+source code. Formatted documentation can be found at the following\n+locations:\n+\n+  - Core library: <http://doc.rust-lang.org/doc/core>\n+  - Standard library: <http://doc.rust-lang.org/doc/std>\n+\n+## Disclaimer\n+\n+Rust is a work in progress. The language continues to evolve as the design\n+shifts and is fleshed out in working code. Certain parts work, certain parts\n+do not, certain parts will be removed or changed.\n+\n+This manual is a snapshot written in the present tense. All features\n+described exist in working code, but some are quite primitive or remain to\n+be further modified by planned work. Some may be temporary. It is a\n+*draft*, and we ask that you not take anything you read here as final.\n+\n+If you have suggestions to make, please try to focus them on *reductions* to\n+the language: possible features that can be combined or omitted. We aim to\n+keep the size and complexity of the language under control.\n+\n+# Notation\n+\n+Rust's grammar is defined over Unicode codepoints, each conventionally\n+denoted `U+XXXX`, for 4 or more hexadecimal digits `X`. _Most_ of Rust's\n+grammar is confined to the ASCII range of Unicode, and is described in this\n+document by a dialect of Extended Backus-Naur Form (EBNF), specifically a\n+dialect of EBNF supported by common automated LL(k) parsing tools such as\n+`llgen`, rather than the dialect given in ISO 14977. The dialect can be\n+defined self-referentially as follows:\n+\n+~~~~~~~~ {.ebnf .notation}\n+\n+grammar : rule + ;\n+rule    : nonterminal ':' productionrule ';' ;\n+productionrule : production [ '|' production ] * ;\n+production : term * ;\n+term : element repeats ;\n+element : LITERAL | IDENTIFIER | '[' productionrule ']' ;\n+repeats : [ '*' | '+' ] NUMBER ? | NUMBER ? | '?' ;\n+\n+~~~~~~~~\n+\n+Where:\n+\n+  - Whitespace in the grammar is ignored.\n+  - Square brackets are used to group rules.\n+  - `LITERAL` is a single printable ASCII character, or an escaped hexadecimal\n+     ASCII code of the form `\\xQQ`, in single quotes, denoting the corresponding\n+     Unicode codepoint `U+00QQ`.\n+  - `IDENTIFIER` is a nonempty string of ASCII letters and underscores.\n+  - The `repeat` forms apply to the adjacent `element`, and are as follows:\n+    - `'?'` means zero or one repetition\n+    - `'*'` means zero or more repetitions\n+    - `'+'` means one or more repetitions\n+    - NUMBER trailing a repeat symbol gives a maximum repetition count\n+    - NUMBER on its own gives an exact repetition count\n+\n+This EBNF dialect should hopefully be familiar to many readers.\n+\n+The grammar for Rust given in this document is extracted and verified as\n+LL(1) by an automated grammar-analysis tool, and further tested against the\n+Rust sources. The generated parser is currently *not* the one used by the\n+Rust compiler itself, but in the future we hope to relate the two together\n+more precisely. As of this writing they are only related by testing against\n+existing source code.\n+\n+## Unicode productions\n+\n+A small number of productions in Rust's grammar permit Unicode codepoints\n+ouside the ASCII range; these productions are defined in terms of character\n+properties given by the Unicode standard, rather than ASCII-range\n+codepoints. These are given in the section [Special Unicode\n+Productions](#special-unicode-productions).\n+\n+## String table productions\n+\n+Some rules in the grammar -- notably [operators](#operators),\n+[keywords](#keywords) and [reserved words](#reserved-words) -- are given in a\n+simplified form: as a listing of a table of unquoted, printable\n+whitespace-separated strings. These cases form a subset of the rules regarding\n+the [token](#tokens) rule, and are assumed to be the result of a\n+lexical-analysis phase feeding the parser, driven by a DFA, operating over the\n+disjunction of all such string table entries.\n+\n+When such a string enclosed in double-quotes (`'\"'`) occurs inside the\n+grammar, it is an implicit reference to a single member of such a string table\n+production. See [tokens](#tokens) for more information.\n+\n+\n+# Lexical structure\n+\n+## Input format\n+\n+Rust input is interpreted in as a sequence of Unicode codepoints encoded in\n+UTF-8. No normalization is performed during input processing. Most Rust\n+grammar rules are defined in terms of printable ASCII-range codepoints, but\n+a small number are defined in terms of Unicode properties or explicit\n+codepoint lists. ^[Surrogate definitions for the special Unicode productions\n+are provided to the grammar verifier, restricted to ASCII range, when\n+verifying the grammar in this document.]\n+\n+## Special Unicode Productions\n+\n+The following productions in the Rust grammar are defined in terms of\n+Unicode properties: `ident`, `non_null`, `non_star`, `non_eol`, `non_slash`,\n+`non_single_quote` and `non_double_quote`.\n+\n+### Identifier\n+\n+The `ident` production is any nonempty Unicode string of the following form:\n+\n+   - The first character has property `XID_start`\n+   - The remaining characters have property `XID_continue`\n+\n+that does _not_ occur in the set of [keywords](#keywords) or [reserved\n+words](#reserved-words).\n+\n+Note: `XID_start` and `XID_continue` as character properties cover the\n+character ranges used to form the more familiar C and Java language-family\n+identifiers.\n+\n+### Delimiter-restricted productions\n+\n+Some productions are defined by exclusion of particular Unicode characters:\n+\n+  - `non_null` is any single Unicode character aside from `U+0000` (null)\n+  - `non_eol` is `non_null` restricted to exclude `U+000A` (`'\\n'`)\n+  - `non_star` is `non_null` restricted to exclude `U+002A` (`'*'`)\n+  - `non_slash` is `non_null` restricted to exclude `U+002F` (`'/'`)\n+  - `non_single_quote` is `non_null` restricted to exclude `U+0027`  (`'\\''`)\n+  - `non_double_quote` is `non_null` restricted to exclude `U+0022` (`'\\\"'`)\n+\n+## Comments\n+\n+~~~~~~~~ {.ebnf .gram}\n+comment : block_comment | line_comment ;\n+block_comment : \"/*\" block_comment_body * \"*/\" ;\n+block_comment_body : block_comment | non_star * | '*' non_slash ;\n+line_comment : \"//\" non_eol * ;\n+~~~~~~~~\n+\n+Comments in Rust code follow the general C++ style of line and block-comment\n+forms, with proper nesting of block-comment delimeters. Comments are\n+interpreted as a form of whitespace.\n+\n+## Whitespace\n+\n+~~~~~~~~ {.ebnf .gram}\n+whitespace_char : '\\x20' | '\\x09' | '\\x0a' | '\\x0d' ;\n+whitespace : [ whitespace_char | comment ] + ;\n+~~~~~~~~\n+\n+The `whitespace_char` production is any nonempty Unicode string consisting of any\n+of the following Unicode characters: `U+0020` (space, `' '`), `U+0009` (tab,\n+`'\\t'`), `U+000A` (LF, `'\\n'`), `U+000D` (CR, `'\\r'`).\n+\n+Rust is a \"free-form\" language, meaning that all forms of whitespace serve\n+only to separate _tokens_ in the grammar, and have no semantic meaning.\n+\n+A Rust program has identical meaning if each whitespace element is replaced\n+with any other legal whitespace element, such as a single space character.\n+\n+## Tokens\n+\n+~~~~~~~~ {.ebnf .gram}\n+simple_token : keyword | reserved | unop | binop ; \n+token : simple_token | ident | immediate | symbol | whitespace token ;\n+~~~~~~~~\n+\n+Tokens are primitive productions in the grammar defined by regular\n+(non-recursive) languages. \"Simple\" tokens are given in [string table\n+production](#string-table-productions) form, and occur in the rest of the\n+grammar as double-quoted strings. Other tokens have exact rules given.\n+\n+### Keywords\n+\n+The keywords in [crate files](#crate-files) are the following strings:\n+\n+~~~~~~~~ {.keyword}\n+import export use mod dir\n+~~~~~~~~\n+\n+The keywords in [source files](#source-files) are the following strings:\n+\n+~~~~~~~~ {.keyword}\n+alt any as assert\n+be bind block bool break\n+char check claim const cont\n+do\n+else export\n+f32 f64 fail false float fn for\n+i16 i32 i64 i8 if import in int\n+let log\n+mod mutable\n+native note\n+obj  \n+prove pure\n+resource ret\n+self str syntax\n+tag true type\n+u16 u32 u64 u8 uint unchecked unsafe use\n+vec\n+while with\n+~~~~~~~~\n+\n+Any of these have special meaning in their respective grammars, and are\n+excluded from the `ident` rule.\n+\n+### Reserved words\n+\n+The reserved words are the following strings:\n+\n+~~~~~~~~ {.reserved}\n+m32 m64 m128\n+f80 f16 f128\n+class trait\n+~~~~~~~~\n+\n+Any of these may have special meaning in future versions of the language, do\n+are excluded from the `ident` rule.\n+\n+### Immediates\n+\n+Immediates are a subset of all possible literals: those that are defined as\n+single tokens, rather than sequences of tokens.\n+\n+An immediate is a form of [constant expression](#constant-expression), so is\n+evaluated (primarily) at compile time.\n+\n+~~~~~~~~ {.ebnf .gram}\n+immediate : string_lit | char_lit | num_lit ;\n+~~~~~~~~\n+\n+#### Character and string literals\n+\n+~~~~~~~~ {.ebnf .gram}\n+char_lit : '\\x27' char_body '\\x27' ;\n+string_lit : '\"' string_body * '\"' ;\n+\n+char_body : non_single_quote\n+          | '\\x5c' [ '\\x27' | common_escape ] ;\n+\n+string_body : non_double_quote\n+            | '\\x5c' [ '\\x22' | common_escape ] ;\n+\n+common_escape : '\\x5c'\n+              | 'n' | 'r' | 't'\n+              | 'x' hex_digit 2\n+              | 'u' hex_digit 4\n+              | 'U' hex_digit 8 ;\n+\n+hex_digit : 'a' | 'b' | 'c' | 'd' | 'e' | 'f'\n+          | 'A' | 'B' | 'C' | 'D' | 'E' | 'F'\n+          | dec_digit ;\n+dec_digit : '0' | nonzero_dec ;\n+nonzero_dec: '1' | '2' | '3' | '4'\n+           | '5' | '6' | '7' | '8' | '9' ;\n+~~~~~~~~\n+\n+A _character literal_ is a single Unicode character enclosed within two\n+`U+0027` (single-quote) characters, with the exception of `U+0027` itself,\n+which must be _escaped_ by a preceding U+005C character (`'\\'`).\n+\n+A _string literal_ is a sequence of any Unicode characters enclosed within\n+two `U+0022` (double-quote) characters, with the exception of `U+0022`\n+itself, which must be _escaped_ by a preceding `U+005C` character (`'\\'`).\n+\n+Some additional _escapes_ are available in either character or string\n+literals. An escape starts with a `U+005C` (`'\\'`) and continues with one of\n+the following forms:\n+\n+  * An _8-bit codepoint escape_ escape starts with `U+0078` (`'x'`) and is\n+    followed by exactly two _hex digits_. It denotes the Unicode codepoint\n+    equal to the provided hex value.\n+  * A _16-bit codepoint escape_ starts with `U+0075` (`'u'`) and is followed\n+    by exactly four _hex digits_. It denotes the Unicode codepoint equal to\n+    the provided hex value.\n+  * A _32-bit codepoint escape_ starts with `U+0055` (`'U'`) and is followed\n+    by exactly eight _hex digits_. It denotes the Unicode codepoint equal to\n+    the provided hex value.\n+  * A _whitespace escape_ is one of the characters `U+006E` (`'n'`), `U+0072`\n+    (`'r'`), or `U+0074` (`'t'`), denoting the unicode values `U+000A` (LF),\n+    `U+000D` (CR) or `U+0009` (HT) respectively.\n+  * The _backslash escape_ is the character U+005C (`'\\'`) which must be\n+    escaped in order to denote *itself*.\n+\n+#### Number literals\n+\n+~~~~~~~~ {.ebnf .gram}\n+\n+num_lit : nonzero_dec [ dec_digit | '_' ] * num_suffix ?\n+        | '0' [       [ dec_digit | '_' ] + num_suffix ?\n+              | 'b'   [ '1' | '0' | '_' ] + int_suffix ?\n+              | 'x'   [ hex_digit | '-' ] + int_suffix ? ] ;\n+\n+num_suffix : int_suffix | float_suffix ;\n+\n+int_suffix : 'u' int_suffix_size ?\n+           | 'i' int_suffix_size ;\n+int_suffix_size : [ '8' | '1' '6' | '3' '2' | '6' '4' ] ;\n+\n+float_suffix : [ exponent | '.' dec_lit exponent ? ] float_suffix_ty ? ;\n+float_suffix_ty : 'f' [ '3' '2' | '6' '4' ] ;\n+exponent : ['E' | 'e'] ['-' | '+' ] ? dec_lit ;\n+dec_lit : [ dec_digit | '_' ] + ;\n+~~~~~~~~\n+\n+A _number literal_ is either an _integer literal_ or a _floating-point\n+literal_. The grammar for recognizing the two kinds of literals is mixed\n+as they are differentiated by suffixes.\n+\n+##### Integer literals\n+\n+An _integer literal_ has one of three forms:\n+\n+  * A _decimal literal_ starts with a *decimal digit* and continues with any\n+    mixture of *decimal digits* and _underscores_.\n+  * A _hex literal_ starts with the character sequence `U+0030` `U+0078`\n+    (`\"0x\"`) and continues as any mixture hex digits and underscores.\n+  * A _binary literal_ starts with the character sequence `U+0030` `U+0062`\n+    (`\"0b\"`) and continues as any mixture binary digits and underscores.\n+\n+By default, an integer literal is of type `int`. An integer literal may be\n+followed (immediately, without any spaces) by an _integer suffix_, which\n+changes the type of the literal. There are two kinds of integer literal\n+suffix:\n+\n+  * The `u` suffix gives the literal type `uint`.\n+  * Each of the signed and unsigned machine types `u8`, `i8`,\n+    `u16`, `i16`, `u32`, `i32`, `u64` and `i64`\n+    give the literal the corresponding machine type.\n+\n+\n+Examples of integer literals of various forms:\n+\n+~~~~\n+123;                               // type int\n+123u;                              // type uint\n+123_u;                             // type uint\n+0xff00;                            // type int\n+0xff_u8;                           // type u8\n+0b1111_1111_1001_0000_i32;         // type i32\n+~~~~\n+\n+##### Floating-point literals\n+\n+A _floating-point literal_ has one of two forms:\n+\n+* Two _decimal literals_ separated by a period\n+  character `U+002E` (`'.'`), with an optional _exponent_ trailing after the\n+  second decimal literal.\n+* A single _decimal literal_ followed by an _exponent_.\n+\n+By default, a floating-point literal is of type `float`. A floating-point\n+literal may be followed (immediately, without any spaces) by a\n+_floating-point suffix_, which changes the type of the literal. There are\n+only two floating-point suffixes: `f32` and `f64`. Each of these gives the\n+floating point literal the associated type, rather than `float`.\n+\n+A set of suffixes are also reserved to accommodate literal support for\n+types corresponding to reserved tokens. The reserved suffixes are `f16`,\n+`f80`, `f128`, `m`, `m32`, `m64` and `m128`.\n+\n+Examples of floating-point literals of various forms:\n+\n+~~~~\n+123.0;                             // type float\n+0.1;                               // type float\n+0.1f32;                            // type f32\n+12E+99_f64;                        // type f64\n+~~~~\n+\n+### Symbols\n+\n+~~~~~~~~ {.ebnf .gram}\n+symbol : \"::\" \"->\"\n+       | '#' | '[' | ']' | '(' | ')' | '{' | '}'\n+       | ',' | ';' ;\n+~~~~~~~~\n+\n+Symbols are a general class of printable [token](#tokens) that play structural\n+roles in a variety of grammar productions. They are catalogued here for\n+completeness as the set of remaining miscellaneous printable token that do not\n+otherwise appear as [operators](#operators), [keywords](#keywords) or [reserved\n+words](#reserved-words).\n+\n+\n+## Paths\n+\n+~~~~~~~~ {.ebnf .gram}\n+\n+expr_path : ident [ \"::\" expr_path_tail ] + ;\n+expr_path_tail : '<' type_expr [ ',' type_expr ] + '>'\n+               | expr_path ;\n+\n+type_path : ident [ type_path_tail ] + ;\n+type_path_tail : '<' type_expr [ ',' type_expr ] + '>'\n+               | \"::\" type_path ;\n+\n+~~~~~~~~\n+\n+A _path_ is a sequence of one or more path components _logically_ separated by\n+a namespace qualifier (`\"::\"`). If a path consists of only one component, it\n+may refer to either an [item](#items) or a (variable)[#variables) in a local\n+control scope. If a path has multiple components, it refers to an item.\n+\n+Every item has a _canonical path_ within its [crate](#crates), but the path\n+naming an item is only meaningful within a given crate. There is no global\n+namespace across crates; an item's canonical path merely identifies it within\n+the crate.\n+\n+Two examples of simple paths consisting of only identifier components:\n+\n+~~~~\n+x;\n+x::y::z;\n+~~~~\n+\n+Path components are usually [identifiers](#identifiers), but the trailing\n+component of a path may be an angle-bracket enclosed list of [type\n+arguments](type-arguments). In [expression](#expressions) context, the type\n+argument list is given after a final (`\"::\"`) namespace qualifier in order to\n+disambiguate it from a relational expression involving the less-than symbol\n+(`'<'`). In [type expression](#type-expressions) context, the final namespace\n+qualifier is omitted.\n+\n+Two examples of paths with type arguments:\n+\n+~~~~\n+type t = map::hashtbl<int,str>;  // Type arguments used in a type expression\n+let x = id::<int>(10);           // Type arguments used in a call expression\n+~~~~\n+\n+\n+# Crates and source files\n+\n+Rust is a *compiled* language. Its semantics are divided along a\n+*phase distinction* between compile-time and run-time. Those semantic\n+rules that have a *static interpretation* govern the success or failure\n+of compilation. A program that fails to compile due to violation of a\n+compile-time rule has no defined semantics at run-time; the compiler should\n+halt with an error report, and produce no executable artifact.\n+\n+The compilation model centres on artifacts called _crates_. Each compilation\n+is directed towards a single crate in source form, and if successful\n+produces a single crate in binary form, either an executable or a library.\n+\n+A _crate_ is a unit of compilation and linking, as well as versioning,\n+distribution and runtime loading.\n+\n+Crates are provided to the Rust compiler through two kinds of file:\n+\n+  - _crate files_, that end in `.rc` and each define a `crate`.\n+  - _source files_, that end in `.rs` and each define a `module`.\n+\n+The Rust compiler is always invoked with a single input file, and always\n+produces a single output crate.\n+\n+When the Rust compiler is invoked with a crate file, it reads the _explicit_\n+definition of the crate it's compiling from that file, and populates the\n+crate with modules derived from all the source files referenced by the\n+crate, reading and processing all the referenced modules at once.\n+\n+When the Rust compiler is invoked with a source file, it creates an\n+_implicit_ crate and treats the source file and though it was referenced as\n+the sole module populating this implicit crate. The module name is derived\n+from the source file name, with the `.rs` extension removed.\n+\n+## Crate files\n+\n+~~~~~~~~ {.ebnf .gram}\n+crate : [ attribute * directive ] * ;\n+directive : view_directive | dir_directive | source_directive ;\n+~~~~~~~~\n+\n+A crate file contains a crate definition, for which the production above\n+defines the grammar. It is a declarative grammar that guides the compiler in\n+assembling a crate from component source files.^[A crate is somewhat\n+analogous to an *assembly* in the ECMA-335 CLI model, a *library* in the\n+SML/NJ Compilation Manager, a *unit* in the Owens and Flatt module system,\n+or a *configuration* in Mesa.] A crate file describes:\n+\n+* Metadata about the crate, such as author, name, version, and copyright.\n+* The source file and directory modules that make up the crate.\n+* Any external crates or native modules that the crate imports to its top level.\n+* The organization of the crate's internal namespace.\n+* The set of names exported from the crate.\n+\n+### View directives\n+\n+A `view_directive` contains a single `view_item` and arranges the top-level\n+namespace of the crate, the same way a `view_item` would in a module. See\n+[view items](#view-items).\n+\n+### Dir directives\n+\n+A `dir_directive` forms a module in the module tree making up the crate, as\n+well as implicitly relating that module to a directory in the filesystem\n+containing source files and/or further subdirectories. The filesystem\n+directory associated with a `dir_directive` module can either be explicit,\n+or if omitted, is implicitly the same name as the module.\n+\n+A `source_directive` references a source file, either explicitly or\n+implicitly by combining the module name with the file extension `.rs`.  The\n+module contained in that source file is bound to the module path formed by\n+the `dir_directive` modules containing the `source_directive`.\n+\n+## Source file\n+\n+A source file contains a `module`, that is, a sequence of zero-or-more\n+`item` definitions. Each source file is an implicit module, the name and\n+location of which -- in the module tree of the current crate -- is defined\n+from outside the source file: either by an explicit `source_directive` in\n+a referencing crate file, or by the filename of the source file itself.\n+\n+\n+# Items and attributes\n+\n+# Statements and expressions\n+\n+## Operators\n+\n+### Unary operators\n+\n+~~~~~~~~ {.unop}\n++ - * ! @ ~\n+~~~~~~~~\n+\n+### Binary operators\n+\n+~~~~~~~~ {.binop}\n+.\n++ - * / %\n+& | ^\n+|| &&\n+< <= == >= >\n+<< >> >>>\n+<- <-> = += -= *= /= %= &= |= ^= <<= >>= >>>=\n+~~~~~~~~\n+\n+# Memory and concurrency model\n+\n+# Runtime services, linkage and debugging\n+\n+# Appendix: Rationales and design tradeoffs\n+\n+_TBD_.\n+\n+# Appendix: Influences and further references\n+\n+## Influences\n+\n+\n+>  The essential problem that must be solved in making a fault-tolerant\n+>  software system is therefore that of fault-isolation. Different programmers\n+>  will write different modules, some modules will be correct, others will have\n+>  errors. We do not want the errors in one module to adversely affect the\n+>  behaviour of a module which does not have any errors.\n+>\n+>  &mdash; Joe Armstrong\n+\n+\n+>  In our approach, all data is private to some process, and processes can\n+>  only communicate through communications channels. *Security*, as used\n+>  in this paper, is the property which guarantees that processes in a system\n+>  cannot affect each other except by explicit communication.\n+>\n+>  When security is absent, nothing which can be proven about a single module\n+>  in isolation can be guaranteed to hold when that module is embedded in a\n+>  system [...]\n+>\n+>  &mdash;  Robert Strom and Shaula Yemini\n+\n+\n+>  Concurrent and applicative programming complement each other. The\n+>  ability to send messages on channels provides I/O without side effects,\n+>  while the avoidance of shared data helps keep concurrent processes from\n+>  colliding.\n+>\n+>  &mdash; Rob Pike\n+\n+\n+Rust is not a particularly original language. It may however appear unusual\n+by contemporary standards, as its design elements are drawn from a number of\n+\"historical\" languages that have, with a few exceptions, fallen out of\n+favour. Five prominent lineages contribute the most, though their influences\n+have come and gone during the course of Rust's development:\n+\n+* The NIL (1981) and Hermes (1990) family. These languages were developed by\n+  Robert Strom, Shaula Yemini, David Bacon and others in their group at IBM\n+  Watson Research Center (Yorktown Heights, NY, USA).\n+\n+* The Erlang (1987) language, developed by Joe Armstrong, Robert Virding, Claes\n+  Wikstr&ouml;m, Mike Williams and others in their group at the Ericsson Computer\n+  Science Laboratory (&Auml;lvsj&ouml;, Stockholm, Sweden) .\n+\n+* The Sather (1990) language, developed by Stephen Omohundro, Chu-Cheow Lim,\n+  Heinz Schmidt and others in their group at The International Computer\n+  Science Institute of the University of California, Berkeley (Berkeley, CA,\n+  USA).\n+\n+* The Newsqueak (1988), Alef (1995), and Limbo (1996) family. These\n+  languages were developed by Rob Pike, Phil Winterbottom, Sean Dorward and\n+  others in their group at Bell labs Computing Sciences Reserch Center\n+  (Murray Hill, NJ, USA).\n+\n+* The Napier (1985) and Napier88 (1988) family. These languages were\n+  developed by Malcolm Atkinson, Ron Morrison and others in their group at\n+  the University of St. Andrews (St. Andrews, Fife, UK).\n+\n+Additional specific influences can be seen from the following languages:\n+\n+* The stack-growth implementation of Go.\n+* The structural algebraic types and compilation manager of SML.\n+* The attribute and assembly systems of C#.\n+* The deterministic destructor system of C++.\n+* The typeclass system of Haskell.\n+* The lexical identifier rule of Python.\n+* The block syntax of Ruby.\n+"}, {"sha": "2e05974451df2db38162112c035293c3d64530ba", "filename": "man/rustc.1", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/man%2Frustc.1", "raw_url": "https://github.com/rust-lang/rust/raw/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/man%2Frustc.1", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/man%2Frustc.1?ref=fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "patch": "@@ -10,7 +10,7 @@ Only the most commonly-used options are listed here. All options are listed and\n described below.\n .SH DESCRIPTION\n This program is a compiler for the Rust language, available at\n-<\\fBhttps://github.com/graydon/rust\\fR>.\n+<\\fBhttps://www.rust-lang.org\\fR>.\n .SH OPTIONS\n .TP\n \\fB-h, --help\\fR:\n@@ -124,7 +124,7 @@ Build a test harness.\n \\fB--warn-unused-imports\\fR:\n Warn about unnecessary imports.\n .SH \"BUGS\"\n-See \\fBhttps://github.com/graydon/rust/issues\\fR for a list of known bugs.\n+See \\fBhttps://github.com/mozilla/rust/issues\\fR for a list of known bugs.\n .SH \"AUTHOR\"\n See \\fBAUTHORS.txt\\fR in the rust source distribution. Graydon Hoare\n <\\fIgraydon@mozilla.com\\fR> is the project leader."}, {"sha": "bc8964ab7504eded07c01bd3da4306e89cb4f0ef", "filename": "mk/clean.mk", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/mk%2Fclean.mk", "raw_url": "https://github.com/rust-lang/rust/raw/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/mk%2Fclean.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fclean.mk?ref=fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "patch": "@@ -52,8 +52,8 @@ clean-misc:\n                  $(wildcard doc/*.$(ext) \\\n                             doc/*/*.$(ext) \\\n                             doc/*/*/*.$(ext)))\n-\t$(Q)rm -Rf doc/keywords.texi\n-\t$(Q)rm -Rf doc/version.texi\n+\t$(Q)rm -Rf doc/keywords.md\n+\t$(Q)rm -Rf doc/version.md\n \t$(Q)rm -Rf $(foreach sub, index styles files search javascript, \\\n                  $(wildcard doc/*/$(sub)))\n \t$(Q)rm -rf libuv"}, {"sha": "866d5f20a1931d0c0cd58f40b7eeb48ebad9c267", "filename": "mk/docs.mk", "status": "modified", "additions": 50, "deletions": 17, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/mk%2Fdocs.mk", "raw_url": "https://github.com/rust-lang/rust/raw/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/mk%2Fdocs.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fdocs.mk?ref=fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "patch": "@@ -2,28 +2,61 @@\n # Doc variables and rules\n ######################################################################\n \n-doc/keywords.texi: $(S)doc/keywords.txt $(S)src/etc/gen-keywords-table.py\n-\t@$(call E, gen-keywords-table: $@)\n-\t$(Q)$(S)src/etc/gen-keywords-table.py\n-\n-doc/version.texi: $(MKFILE_DEPS) rust.texi\n+doc/version.md: $(MKFILE_DEPS) rust.md\n \t@$(call E, version-stamp: $@)\n-\t$(Q)echo \"@macro gitversion\" >$@\n \t$(Q)echo \"$(CFG_VERSION)\" >>$@\n-\t$(Q)echo \"@end macro\" >>$@\n \n-GENERATED += doc/keywords.texi doc/version.texi\n+doc/keywords.md: $(MKFILE_DEPS) rust.md\n+\t@$(call E, grep -v: $$@)\n+\t$(Q)grep -v '^#' $< >$@\n+\n+ifdef CFG_PANDOC\n+\n+doc/rust.html: rust.md doc/version.md doc/keywords.md\n+\t@$(call E, pandoc: $@)\n+\t$(Q)$(CFG_PANDOC) \\\n+         --standalone --toc \\\n+         --section-divs \\\n+         --number-sections \\\n+         --from=markdown --to=html \\\n+         --output=$@ \\\n+         $<\n+\n+ifdef CFG_PDFLATEX\n+\n+doc/rust.tex: rust.md doc/version.md doc/keywords.md\n+\t@$(call E, pandoc: $@)\n+\t$(Q)$(CFG_PANDOC) \\\n+         --standalone --toc \\\n+         --number-sections \\\n+         --from=markdown --to=latex \\\n+         --output=$@ \\\n+         $<\n+\n+doc/rust.pdf: doc/rust.tex\n+\t@$(call E, pdflatex: $@)\n+\t$(Q)$(CFG_PDFLATEX) \\\n+        -interaction=batchmode \\\n+        -output-directory=doc \\\n+        $<\n+\n+endif\n+\n+endif\n+\n+ifdef CFG_LLNEXTGEN\n+doc/rust.g: rust.md $(S)src/etc/extract_grammar.py\n+\t@$(call E, extract_grammar: $@)\n+\t$(Q)$(S)src/etc/extract_grammar.py $< >$@\n+\n+verify-grammar: doc/rust.g\n+\t@$(call E, LLnextgen: $<)\n+\t$(Q)$(CFG_LLNEXTGEN) --generate-lexer-wrapper=no $< >$@\n+\t$(Q)rm -f doc/rust.c doc/rust.h\n+endif\n \n-doc/%.pdf: %.texi doc/version.texi doc/keywords.texi\n-\t@$(call E, texi2pdf: $@)\n-\t@# LC_COLLATE=C works around a bug in texi2dvi; see\n-\t@# https://bugzilla.redhat.com/show_bug.cgi?id=583011 and\n-\t@# https://github.com/graydon/rust/issues/1134\n-\t$(Q)LC_COLLATE=C texi2pdf --silent --batch -I doc -o $@ --clean $<\n \n-doc/%.html: %.texi doc/version.texi doc/keywords.texi\n-\t@$(call E, makeinfo: $@)\n-\t$(Q)makeinfo -I doc --html --ifhtml --force --no-split --output=$@ $<\n+GENERATED += doc/keywords.md doc/version.md\n \n docsnap: doc/rust.pdf\n \t@$(call E, snap: doc/rust-$(shell date +\"%Y-%m-%d\")-snap.pdf)"}, {"sha": "6066a1ebc9c52263fdcb14558e51df2cd67f9314", "filename": "src/etc/extract_grammar.py", "status": "added", "additions": 138, "deletions": 0, "changes": 138, "blob_url": "https://github.com/rust-lang/rust/blob/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/src%2Fetc%2Fextract_grammar.py", "raw_url": "https://github.com/rust-lang/rust/raw/fefdb63c4c2b078c43836e2ae9d7ffcaeec32890/src%2Fetc%2Fextract_grammar.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fextract_grammar.py?ref=fefdb63c4c2b078c43836e2ae9d7ffcaeec32890", "patch": "@@ -0,0 +1,138 @@\n+#!/usr/bin/env python\n+\n+# This script is for extracting the grammar from the rust docs.\n+\n+import fileinput\n+\n+collections = { \"gram\": [],\n+                \"keyword\": [],\n+                \"reserved\": [],\n+                \"binop\": [],\n+                \"unop\": [] }\n+\n+\n+in_coll = False\n+coll = \"\"\n+\n+for line in fileinput.input(openhook=fileinput.hook_encoded(\"utf-8\")):\n+    if in_coll:\n+        if line.startswith(\"~~~~\"):\n+            in_coll = False\n+        else:\n+            if coll in [\"keyword\", \"reserved\", \"binop\", \"unop\"]:\n+                for word in line.split():\n+                    if word not in collections[coll]:\n+                        collections[coll].append(word)\n+            else:\n+                collections[coll].append(line)\n+\n+    else:\n+        if line.startswith(\"~~~~\"):\n+            for cname in collections:\n+                if (\".\" + cname) in line:\n+                    coll = cname\n+                    in_coll = True\n+                    break\n+\n+# Define operator symbol-names here\n+\n+tokens = [\"non_star\", \"non_slash\", \"non_eol\",\n+          \"non_single_quote\", \"non_double_quote\", \"ident\" ]\n+\n+symnames = {\n+\".\": \"dot\",\n+\"+\": \"plus\",\n+\"-\": \"minus\",\n+\"/\": \"slash\",\n+\"*\": \"star\",\n+\"%\": \"percent\",\n+\n+\"~\": \"tilde\",\n+\"@\": \"at\",\n+\n+\"!\": \"not\",\n+\"&\": \"and\",\n+\"|\": \"or\",\n+\"^\": \"xor\",\n+\n+\"<<\": \"lsl\",\n+\">>\": \"lsr\",\n+\">>>\": \"asr\",\n+\n+\"&&\": \"andand\",\n+\"||\": \"oror\",\n+\n+\"<\" : \"lt\",\n+\"<=\" : \"le\",\n+\"==\" : \"eqeq\",\n+\">=\" : \"ge\",\n+\">\" : \"gt\",\n+\n+\"=\": \"eq\",\n+\n+\"+=\": \"plusequal\",\n+\"-=\": \"minusequal\",\n+\"/=\": \"divequal\",\n+\"*=\": \"starequal\",\n+\"%=\": \"percentequal\",\n+\n+\"&=\": \"andequal\",\n+\"|=\": \"orequal\",\n+\"^=\": \"xorequal\",\n+\n+\">>=\": \"lsrequal\",\n+\">>>=\": \"asrequal\",\n+\"<<=\": \"lslequal\",\n+\n+\"::\": \"coloncolon\",\n+\n+\"//\": \"linecomment\",\n+\"/*\": \"openblockcomment\",\n+\"*/\": \"closeblockcomment\"\n+}\n+\n+lines = []\n+\n+for line in collections[\"gram\"]:\n+    line2 = \"\"\n+    for word in line.split():\n+        # replace strings with keyword-names or symbol-names from table\n+        if word.startswith(\"\\\"\"):\n+            word = word[1:-1]\n+            if word in symnames:\n+                word = symnames[word]\n+            else:\n+                for ch in word:\n+                    if not ch.isalpha():\n+                        raise Exception(\"non-alpha apparent keyword: \"\n+                                        + word)\n+                if word not in tokens:\n+                    if (word in collections[\"keyword\"] or\n+                        word in collections[\"reserved\"]):\n+                       tokens.append(word)\n+                    else:\n+                        raise Exception(\"unknown keyword/reserved word: \"\n+                                        + word)\n+\n+        line2 += \" \" + word\n+    lines.append(line2)\n+\n+\n+for word in collections[\"keyword\"] + collections[\"reserved\"]:\n+    if word not in tokens:\n+        tokens.append(word)\n+\n+for sym in collections[\"unop\"] + collections[\"binop\"] + symnames.keys():\n+    word = symnames[sym]\n+    if word not in tokens:\n+        tokens.append(word)\n+\n+\n+print(\"%start parser, token;\")\n+print(\"%%token %s ;\" % (\"\\n\\t, \".join(tokens)))\n+for coll in [\"keyword\", \"reserved\"]:\n+    print(\"%s: %s ; \" % (coll, \"\\n\\t| \".join(collections[coll])));\n+for coll in [\"binop\", \"unop\"]:\n+    print(\"%s: %s ; \" % (coll, \"\\n\\t| \".join([symnames[x]\n+                                              for x in collections[coll]])));\n+print(\"\\n\".join(lines));"}]}