{"sha": "9aa9a846b6e131f9a2b1f477ecc19c2024609847", "node_id": "C_kwDOAAsO6NoAKDlhYTlhODQ2YjZlMTMxZjlhMmIxZjQ3N2VjYzE5YzIwMjQ2MDk4NDc", "commit": {"author": {"name": "Scott McMurray", "email": "scottmcm@users.noreply.github.com", "date": "2023-04-01T08:46:36Z"}, "committer": {"name": "Scott McMurray", "email": "scottmcm@users.noreply.github.com", "date": "2023-04-05T01:44:29Z"}, "message": "Allow `transmute`s to produce `OperandValue`s instead of always using `alloca`s\n\nLLVM can usually optimize these away, but especially for things like transmutes of newtypes it's silly to generate the `alloc`+`store`+`load` at all when it's actually a nop at LLVM level.", "tree": {"sha": "5740ac69dfb4f290a90850c7c41b1d1d2ef2cdd9", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/5740ac69dfb4f290a90850c7c41b1d1d2ef2cdd9"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/9aa9a846b6e131f9a2b1f477ecc19c2024609847", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/9aa9a846b6e131f9a2b1f477ecc19c2024609847", "html_url": "https://github.com/rust-lang/rust/commit/9aa9a846b6e131f9a2b1f477ecc19c2024609847", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/9aa9a846b6e131f9a2b1f477ecc19c2024609847/comments", "author": {"login": "scottmcm", "id": 18526288, "node_id": "MDQ6VXNlcjE4NTI2Mjg4", "avatar_url": "https://avatars.githubusercontent.com/u/18526288?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scottmcm", "html_url": "https://github.com/scottmcm", "followers_url": "https://api.github.com/users/scottmcm/followers", "following_url": "https://api.github.com/users/scottmcm/following{/other_user}", "gists_url": "https://api.github.com/users/scottmcm/gists{/gist_id}", "starred_url": "https://api.github.com/users/scottmcm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scottmcm/subscriptions", "organizations_url": "https://api.github.com/users/scottmcm/orgs", "repos_url": "https://api.github.com/users/scottmcm/repos", "events_url": "https://api.github.com/users/scottmcm/events{/privacy}", "received_events_url": "https://api.github.com/users/scottmcm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "scottmcm", "id": 18526288, "node_id": "MDQ6VXNlcjE4NTI2Mjg4", "avatar_url": "https://avatars.githubusercontent.com/u/18526288?v=4", "gravatar_id": "", "url": "https://api.github.com/users/scottmcm", "html_url": "https://github.com/scottmcm", "followers_url": "https://api.github.com/users/scottmcm/followers", "following_url": "https://api.github.com/users/scottmcm/following{/other_user}", "gists_url": "https://api.github.com/users/scottmcm/gists{/gist_id}", "starred_url": "https://api.github.com/users/scottmcm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/scottmcm/subscriptions", "organizations_url": "https://api.github.com/users/scottmcm/orgs", "repos_url": "https://api.github.com/users/scottmcm/repos", "events_url": "https://api.github.com/users/scottmcm/events{/privacy}", "received_events_url": "https://api.github.com/users/scottmcm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "480068c2359ea65df4481788b5ce717a548ce171", "url": "https://api.github.com/repos/rust-lang/rust/commits/480068c2359ea65df4481788b5ce717a548ce171", "html_url": "https://github.com/rust-lang/rust/commit/480068c2359ea65df4481788b5ce717a548ce171"}], "stats": {"total": 455, "additions": 381, "deletions": 74}, "files": [{"sha": "ddef4aaee3babc47288aab10c9f6302de0485318", "filename": "compiler/rustc_codegen_ssa/src/mir/operand.rs", "status": "modified", "additions": 17, "deletions": 1, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/9aa9a846b6e131f9a2b1f477ecc19c2024609847/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Foperand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9aa9a846b6e131f9a2b1f477ecc19c2024609847/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Foperand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Foperand.rs?ref=9aa9a846b6e131f9a2b1f477ecc19c2024609847", "patch": "@@ -23,10 +23,26 @@ pub enum OperandValue<V> {\n     /// to be valid for the operand's lifetime.\n     /// The second value, if any, is the extra data (vtable or length)\n     /// which indicates that it refers to an unsized rvalue.\n+    ///\n+    /// An `OperandValue` has this variant for types which are neither\n+    /// `Immediate` nor `Pair`s. The backend value in this variant must be a\n+    /// pointer to the *non*-immediate backend type. That pointee type is the\n+    /// one returned by [`LayoutTypeMethods::backend_type`].\n     Ref(V, Option<V>, Align),\n-    /// A single LLVM value.\n+    /// A single LLVM immediate value.\n+    ///\n+    /// An `OperandValue` *must* be this variant for any type for which\n+    /// [`LayoutTypeMethods::is_backend_immediate`] returns `true`.\n+    /// The backend value in this variant must be the *immediate* backend type,\n+    /// as returned by [`LayoutTypeMethods::immediate_backend_type`].\n     Immediate(V),\n     /// A pair of immediate LLVM values. Used by fat pointers too.\n+    ///\n+    /// An `OperandValue` *must* be this variant for any type for which\n+    /// [`LayoutTypeMethods::is_backend_scalar_pair`] returns `true`.\n+    /// The backend values in this variant must be the *immediate* backend types,\n+    /// as returned by [`LayoutTypeMethods::scalar_pair_element_backend_type`]\n+    /// with `immediate: true`.\n     Pair(V, V),\n }\n "}, {"sha": "3b4522a99dd518872564b826298dbab7458de746", "filename": "compiler/rustc_codegen_ssa/src/mir/rvalue.rs", "status": "modified", "additions": 159, "deletions": 19, "changes": 178, "blob_url": "https://github.com/rust-lang/rust/blob/9aa9a846b6e131f9a2b1f477ecc19c2024609847/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Frvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9aa9a846b6e131f9a2b1f477ecc19c2024609847/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Frvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Frvalue.rs?ref=9aa9a846b6e131f9a2b1f477ecc19c2024609847", "patch": "@@ -10,7 +10,7 @@ use crate::MemFlags;\n use rustc_middle::mir;\n use rustc_middle::mir::Operand;\n use rustc_middle::ty::cast::{CastTy, IntTy};\n-use rustc_middle::ty::layout::{HasTyCtxt, LayoutOf};\n+use rustc_middle::ty::layout::{HasTyCtxt, LayoutOf, TyAndLayout};\n use rustc_middle::ty::{self, adjustment::PointerCast, Instance, Ty, TyCtxt};\n use rustc_span::source_map::{Span, DUMMY_SP};\n use rustc_target::abi::{self, FIRST_VARIANT};\n@@ -159,8 +159,8 @@ impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n         debug_assert!(dst.layout.is_sized());\n \n         if src.layout.size != dst.layout.size\n-            || src.layout.abi == abi::Abi::Uninhabited\n-            || dst.layout.abi == abi::Abi::Uninhabited\n+            || src.layout.abi.is_uninhabited()\n+            || dst.layout.abi.is_uninhabited()\n         {\n             // In all of these cases it's UB to run this transmute, but that's\n             // known statically so might as well trap for it, rather than just\n@@ -169,22 +169,20 @@ impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n             return;\n         }\n \n-        let size_in_bytes = src.layout.size.bytes();\n-        if size_in_bytes == 0 {\n-            // Nothing to write\n+        if let Some(val) = self.codegen_transmute_operand(bx, src, dst.layout) {\n+            val.store(bx, dst);\n             return;\n         }\n \n         match src.val {\n-            OperandValue::Ref(src_llval, meta, src_align) => {\n-                debug_assert_eq!(meta, None);\n-                // For a place-to-place transmute, call `memcpy` directly so that\n-                // both arguments get the best-available alignment information.\n-                let bytes = bx.cx().const_usize(size_in_bytes);\n-                let flags = MemFlags::empty();\n-                bx.memcpy(dst.llval, dst.align, src_llval, src_align, bytes, flags);\n+            OperandValue::Ref(..) => {\n+                span_bug!(\n+                    self.mir.span,\n+                    \"Operand path should have handled transmute \\\n+                    from `Ref` {src:?} to place {dst:?}\"\n+                );\n             }\n-            OperandValue::Immediate(_) | OperandValue::Pair(_, _) => {\n+            OperandValue::Immediate(..) | OperandValue::Pair(..) => {\n                 // When we have immediate(s), the alignment of the source is irrelevant,\n                 // so we can store them using the destination's alignment.\n                 let llty = bx.backend_type(src.layout);\n@@ -194,6 +192,94 @@ impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n         }\n     }\n \n+    /// Attempts to transmute an `OperandValue` to another `OperandValue`.\n+    ///\n+    /// Returns `None` for cases that can't work in that framework, such as for\n+    /// `Immediate`->`Ref` that needs an `alloc` to get the location.\n+    fn codegen_transmute_operand(\n+        &mut self,\n+        bx: &mut Bx,\n+        operand: OperandRef<'tcx, Bx::Value>,\n+        cast: TyAndLayout<'tcx>,\n+    ) -> Option<OperandValue<Bx::Value>> {\n+        // Callers already checked that the layout sizes match\n+        debug_assert_eq!(operand.layout.size, cast.size);\n+\n+        let operand_kind = self.value_kind(operand.layout);\n+        let cast_kind = self.value_kind(cast);\n+\n+        match operand.val {\n+            OperandValue::Ref(ptr, meta, align) => {\n+                debug_assert_eq!(meta, None);\n+                debug_assert!(matches!(operand_kind, OperandValueKind::Ref));\n+                let cast_bty = bx.backend_type(cast);\n+                let cast_ptr = bx.pointercast(ptr, bx.type_ptr_to(cast_bty));\n+                let fake_place = PlaceRef::new_sized_aligned(cast_ptr, cast, align);\n+                Some(bx.load_operand(fake_place).val)\n+            }\n+            OperandValue::Immediate(imm) => {\n+                let OperandValueKind::Immediate(in_scalar) = operand_kind else {\n+                    bug!(\"Found {operand_kind:?} for operand {operand:?}\");\n+                };\n+                if let OperandValueKind::Immediate(out_scalar) = cast_kind {\n+                    let cast_bty = bx.backend_type(cast);\n+                    Some(OperandValue::Immediate(Self::transmute_immediate(\n+                        bx, imm, in_scalar, out_scalar, cast_bty,\n+                    )))\n+                } else {\n+                    None\n+                }\n+            }\n+            OperandValue::Pair(imm_a, imm_b) => {\n+                let OperandValueKind::Pair(in_a, in_b) = operand_kind else {\n+                    bug!(\"Found {operand_kind:?} for operand {operand:?}\");\n+                };\n+                if let OperandValueKind::Pair(out_a, out_b) = cast_kind {\n+                    let out_a_ibty = bx.scalar_pair_element_backend_type(cast, 0, false);\n+                    let out_b_ibty = bx.scalar_pair_element_backend_type(cast, 1, false);\n+                    Some(OperandValue::Pair(\n+                        Self::transmute_immediate(bx, imm_a, in_a, out_a, out_a_ibty),\n+                        Self::transmute_immediate(bx, imm_b, in_b, out_b, out_b_ibty),\n+                    ))\n+                } else {\n+                    None\n+                }\n+            }\n+        }\n+    }\n+\n+    /// Transmutes one of the immediates from an [`OperandValue::Immediate`]\n+    /// or an [`OperandValue::Pair`] to an immediate of the target type.\n+    ///\n+    /// `to_backend_ty` must be the *non*-immediate backend type (so it will be\n+    /// `i8`, not `i1`, for `bool`-like types.)\n+    fn transmute_immediate(\n+        bx: &mut Bx,\n+        mut imm: Bx::Value,\n+        from_scalar: abi::Scalar,\n+        to_scalar: abi::Scalar,\n+        to_backend_ty: Bx::Type,\n+    ) -> Bx::Value {\n+        use abi::Primitive::*;\n+        imm = bx.from_immediate(imm);\n+        imm = match (from_scalar.primitive(), to_scalar.primitive()) {\n+            (Int(..) | F32 | F64, Int(..) | F32 | F64) => bx.bitcast(imm, to_backend_ty),\n+            (Pointer(..), Pointer(..)) => bx.pointercast(imm, to_backend_ty),\n+            (Int(..), Pointer(..)) => bx.inttoptr(imm, to_backend_ty),\n+            (Pointer(..), Int(..)) => bx.ptrtoint(imm, to_backend_ty),\n+            (F32 | F64, Pointer(..)) => {\n+                let int_imm = bx.bitcast(imm, bx.cx().type_isize());\n+                bx.inttoptr(int_imm, to_backend_ty)\n+            }\n+            (Pointer(..), F32 | F64) => {\n+                let int_imm = bx.ptrtoint(imm, bx.cx().type_isize());\n+                bx.bitcast(int_imm, to_backend_ty)\n+            }\n+        };\n+        imm = bx.to_immediate_scalar(imm, to_scalar);\n+        imm\n+    }\n+\n     pub fn codegen_rvalue_unsized(\n         &mut self,\n         bx: &mut Bx,\n@@ -396,7 +482,9 @@ impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n                         OperandValue::Immediate(newval)\n                     }\n                     mir::CastKind::Transmute => {\n-                        bug!(\"Transmute operand {:?} in `codegen_rvalue_operand`\", operand);\n+                        self.codegen_transmute_operand(bx, operand, cast).unwrap_or_else(|| {\n+                            bug!(\"Unsupported transmute-as-operand of {operand:?} to {cast:?}\");\n+                        })\n                     }\n                 };\n                 OperandRef { val, layout: cast }\n@@ -739,10 +827,36 @@ impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n     pub fn rvalue_creates_operand(&self, rvalue: &mir::Rvalue<'tcx>, span: Span) -> bool {\n         match *rvalue {\n-            mir::Rvalue::Cast(mir::CastKind::Transmute, ..) =>\n-                // FIXME: Now that transmute is an Rvalue, it would be nice if\n-                // it could create `Immediate`s for scalars, where possible.\n-                false,\n+            mir::Rvalue::Cast(mir::CastKind::Transmute, ref operand, cast_ty) => {\n+                let operand_ty = operand.ty(self.mir, self.cx.tcx());\n+                let cast_layout = self.cx.layout_of(self.monomorphize(cast_ty));\n+                let operand_layout = self.cx.layout_of(self.monomorphize(operand_ty));\n+                if operand_layout.size != cast_layout.size\n+                    || operand_layout.abi.is_uninhabited()\n+                    || cast_layout.abi.is_uninhabited()\n+                {\n+                    // Send UB cases to the full form so the operand version can\n+                    // `bitcast` without worrying about malformed IR.\n+                    return false;\n+                }\n+\n+                match (self.value_kind(operand_layout), self.value_kind(cast_layout)) {\n+                    // Can always load from a pointer as needed\n+                    (OperandValueKind::Ref, _) => true,\n+\n+                    // Need to generate an `alloc` to get a pointer from an immediate\n+                    (OperandValueKind::Immediate(..) | OperandValueKind::Pair(..), OperandValueKind::Ref) => false,\n+\n+                    // When we have scalar immediates, we can convert them as needed\n+                    (OperandValueKind::Immediate(..), OperandValueKind::Immediate(..)) |\n+                    (OperandValueKind::Pair(..), OperandValueKind::Pair(..)) => true,\n+\n+                    // Send mixings between scalars and pairs through the memory route\n+                    // FIXME: Maybe this could use insertvalue/extractvalue instead?\n+                    (OperandValueKind::Immediate(..), OperandValueKind::Pair(..)) |\n+                    (OperandValueKind::Pair(..), OperandValueKind::Immediate(..)) => false,\n+                }\n+            }\n             mir::Rvalue::Ref(..) |\n             mir::Rvalue::CopyForDeref(..) |\n             mir::Rvalue::AddressOf(..) |\n@@ -767,4 +881,30 @@ impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n \n         // (*) this is only true if the type is suitable\n     }\n+\n+    /// Gets which variant of [`OperandValue`] is expected for a particular type.\n+    fn value_kind(&self, layout: TyAndLayout<'tcx>) -> OperandValueKind {\n+        if self.cx.is_backend_immediate(layout) {\n+            debug_assert!(!self.cx.is_backend_scalar_pair(layout));\n+            OperandValueKind::Immediate(match layout.abi {\n+                abi::Abi::Scalar(s) => s,\n+                abi::Abi::Vector { element, .. } => element,\n+                x => bug!(\"Couldn't translate {x:?} as backend immediate\"),\n+            })\n+        } else if self.cx.is_backend_scalar_pair(layout) {\n+            let abi::Abi::ScalarPair(s1, s2) = layout.abi else {\n+                bug!(\"Couldn't translate {:?} as backend scalar pair\", layout.abi)\n+            };\n+            OperandValueKind::Pair(s1, s2)\n+        } else {\n+            OperandValueKind::Ref\n+        }\n+    }\n+}\n+\n+#[derive(Debug, Copy, Clone)]\n+enum OperandValueKind {\n+    Ref,\n+    Immediate(abi::Scalar),\n+    Pair(abi::Scalar, abi::Scalar),\n }"}, {"sha": "32905b079d365a72a4a97a7018949084fb6ec124", "filename": "compiler/rustc_codegen_ssa/src/traits/type_.rs", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/9aa9a846b6e131f9a2b1f477ecc19c2024609847/compiler%2Frustc_codegen_ssa%2Fsrc%2Ftraits%2Ftype_.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9aa9a846b6e131f9a2b1f477ecc19c2024609847/compiler%2Frustc_codegen_ssa%2Fsrc%2Ftraits%2Ftype_.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_ssa%2Fsrc%2Ftraits%2Ftype_.rs?ref=9aa9a846b6e131f9a2b1f477ecc19c2024609847", "patch": "@@ -100,11 +100,22 @@ pub trait DerivedTypeMethods<'tcx>: BaseTypeMethods<'tcx> + MiscMethods<'tcx> {\n impl<'tcx, T> DerivedTypeMethods<'tcx> for T where Self: BaseTypeMethods<'tcx> + MiscMethods<'tcx> {}\n \n pub trait LayoutTypeMethods<'tcx>: Backend<'tcx> {\n+    /// The backend type used for a rust type when it's in memory,\n+    /// such as when it's stack-allocated or when it's being loaded or stored.\n     fn backend_type(&self, layout: TyAndLayout<'tcx>) -> Self::Type;\n     fn cast_backend_type(&self, ty: &CastTarget) -> Self::Type;\n     fn fn_decl_backend_type(&self, fn_abi: &FnAbi<'tcx, Ty<'tcx>>) -> Self::Type;\n     fn fn_ptr_backend_type(&self, fn_abi: &FnAbi<'tcx, Ty<'tcx>>) -> Self::Type;\n     fn reg_backend_type(&self, ty: &Reg) -> Self::Type;\n+    /// The backend type used for a rust type when it's in an SSA register.\n+    ///\n+    /// For nearly all types this is the same as the [`Self::backend_type`], however\n+    /// `bool` (and other `0`-or-`1` values) are kept as [`BaseTypeMethods::type_i1`]\n+    /// in registers but as [`BaseTypeMethods::type_i8`] in memory.\n+    ///\n+    /// Converting values between the two different backend types is done using\n+    /// [`from_immediate`](super::BuilderMethods::from_immediate) and\n+    /// [`to_immediate_scalar`](super::BuilderMethods::to_immediate_scalar).\n     fn immediate_backend_type(&self, layout: TyAndLayout<'tcx>) -> Self::Type;\n     fn is_backend_immediate(&self, layout: TyAndLayout<'tcx>) -> bool;\n     fn is_backend_scalar_pair(&self, layout: TyAndLayout<'tcx>) -> bool;"}, {"sha": "7ad0e62213cb238481e3aeb9d48492ab5f05e2e5", "filename": "tests/codegen/intrinsics/transmute.rs", "status": "modified", "additions": 130, "deletions": 23, "changes": 153, "blob_url": "https://github.com/rust-lang/rust/blob/9aa9a846b6e131f9a2b1f477ecc19c2024609847/tests%2Fcodegen%2Fintrinsics%2Ftransmute.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9aa9a846b6e131f9a2b1f477ecc19c2024609847/tests%2Fcodegen%2Fintrinsics%2Ftransmute.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcodegen%2Fintrinsics%2Ftransmute.rs?ref=9aa9a846b6e131f9a2b1f477ecc19c2024609847", "patch": "@@ -6,6 +6,7 @@\n #![feature(core_intrinsics)]\n #![feature(custom_mir)]\n #![feature(inline_const)]\n+#![allow(unreachable_code)]\n \n use std::mem::transmute;\n \n@@ -24,6 +25,9 @@ pub struct Scalar64(i64);\n #[repr(C, align(4))]\n pub struct Aggregate64(u16, u8, i8, f32);\n \n+#[repr(C)]\n+pub struct Aggregate8(u8);\n+\n // CHECK-LABEL: @check_bigger_size(\n #[no_mangle]\n #[custom_mir(dialect = \"runtime\", phase = \"initial\")]\n@@ -76,23 +80,80 @@ pub unsafe fn check_from_uninhabited(x: BigNever) -> u16 {\n     }\n }\n \n+// CHECK-LABEL: @check_intermediate_passthrough(\n+#[no_mangle]\n+pub unsafe fn check_intermediate_passthrough(x: u32) -> i32 {\n+    // CHECK: start\n+    // CHECK: %[[TMP:.+]] = add i32 1, %x\n+    // CHECK: %[[RET:.+]] = add i32 %[[TMP]], 1\n+    // CHECK: ret i32 %[[RET]]\n+    unsafe {\n+        transmute::<u32, i32>(1 + x) + 1\n+    }\n+}\n+\n+// CHECK-LABEL: @check_nop_pair(\n+#[no_mangle]\n+pub unsafe fn check_nop_pair(x: (u8, i8)) -> (i8, u8) {\n+    // CHECK-NOT: alloca\n+    // CHECK: %0 = insertvalue { i8, i8 } poison, i8 %x.0, 0\n+    // CHECK: %1 = insertvalue { i8, i8 } %0, i8 %x.1, 1\n+    // CHECK: ret { i8, i8 } %1\n+    unsafe {\n+        transmute(x)\n+    }\n+}\n+\n // CHECK-LABEL: @check_to_newtype(\n #[no_mangle]\n pub unsafe fn check_to_newtype(x: u64) -> Scalar64 {\n-    // CHECK: %0 = alloca i64\n-    // CHECK: store i64 %x, ptr %0\n-    // CHECK: %1 = load i64, ptr %0\n-    // CHECK: ret i64 %1\n+    // CHECK-NOT: alloca\n+    // CHECK: ret i64 %x\n     transmute(x)\n }\n \n // CHECK-LABEL: @check_from_newtype(\n #[no_mangle]\n pub unsafe fn check_from_newtype(x: Scalar64) -> u64 {\n-    // CHECK: %0 = alloca i64\n-    // CHECK: store i64 %x, ptr %0\n-    // CHECK: %1 = load i64, ptr %0\n-    // CHECK: ret i64 %1\n+    // CHECK-NOT: alloca\n+    // CHECK: ret i64 %x\n+    transmute(x)\n+}\n+\n+// CHECK-LABEL: @check_aggregate_to_bool(\n+#[no_mangle]\n+pub unsafe fn check_aggregate_to_bool(x: Aggregate8) -> bool {\n+    // CHECK: %x = alloca %Aggregate8, align 1\n+    // CHECK: %[[BYTE:.+]] = load i8, ptr %x, align 1\n+    // CHECK: %[[BOOL:.+]] = trunc i8 %[[BYTE]] to i1\n+    // CHECK: ret i1 %[[BOOL]]\n+    transmute(x)\n+}\n+\n+// CHECK-LABEL: @check_aggregate_from_bool(\n+#[no_mangle]\n+pub unsafe fn check_aggregate_from_bool(x: bool) -> Aggregate8 {\n+    // CHECK: %0 = alloca %Aggregate8, align 1\n+    // CHECK: %[[BYTE:.+]] = zext i1 %x to i8\n+    // CHECK: store i8 %[[BYTE]], ptr %0, align 1\n+    transmute(x)\n+}\n+\n+// CHECK-LABEL: @check_byte_to_bool(\n+#[no_mangle]\n+pub unsafe fn check_byte_to_bool(x: u8) -> bool {\n+    // CHECK-NOT: alloca\n+    // CHECK: %0 = trunc i8 %x to i1\n+    // CHECK: ret i1 %0\n+    transmute(x)\n+}\n+\n+// CHECK-LABEL: @check_byte_from_bool(\n+#[no_mangle]\n+pub unsafe fn check_byte_from_bool(x: bool) -> u8 {\n+    // CHECK-NOT: alloca\n+    // CHECK: %0 = zext i1 %x to i8\n+    // CHECK: ret i8 %0\n     transmute(x)\n }\n \n@@ -122,20 +183,18 @@ pub unsafe fn check_from_pair(x: Option<i32>) -> u64 {\n // CHECK-LABEL: @check_to_float(\n #[no_mangle]\n pub unsafe fn check_to_float(x: u32) -> f32 {\n-    // CHECK: %0 = alloca float\n-    // CHECK: store i32 %x, ptr %0\n-    // CHECK: %1 = load float, ptr %0\n-    // CHECK: ret float %1\n+    // CHECK-NOT: alloca\n+    // CHECK: %0 = bitcast i32 %x to float\n+    // CHECK: ret float %0\n     transmute(x)\n }\n \n // CHECK-LABEL: @check_from_float(\n #[no_mangle]\n pub unsafe fn check_from_float(x: f32) -> u32 {\n-    // CHECK: %0 = alloca i32\n-    // CHECK: store float %x, ptr %0\n-    // CHECK: %1 = load i32, ptr %0\n-    // CHECK: ret i32 %1\n+    // CHECK-NOT: alloca\n+    // CHECK: %0 = bitcast float %x to i32\n+    // CHECK: ret i32 %0\n     transmute(x)\n }\n \n@@ -144,19 +203,15 @@ pub unsafe fn check_from_float(x: f32) -> u32 {\n pub unsafe fn check_to_bytes(x: u32) -> [u8; 4] {\n     // CHECK: %0 = alloca [4 x i8], align 1\n     // CHECK: store i32 %x, ptr %0, align 1\n-    // CHECK: %1 = load i32, ptr %0, align 1\n-    // CHECK: ret i32 %1\n     transmute(x)\n }\n \n // CHECK-LABEL: @check_from_bytes(\n #[no_mangle]\n pub unsafe fn check_from_bytes(x: [u8; 4]) -> u32 {\n-    // CHECK: %1 = alloca i32, align 4\n     // CHECK: %x = alloca [4 x i8], align 1\n-    // CHECK: call void @llvm.memcpy.p0.p0.i64(ptr align 4 %1, ptr align 1 %x, i64 4, i1 false)\n-    // CHECK: %3 = load i32, ptr %1, align 4\n-    // CHECK: ret i32 %3\n+    // CHECK: %[[VAL:.+]] = load i32, ptr %x, align 1\n+    // CHECK: ret i32 %[[VAL]]\n     transmute(x)\n }\n \n@@ -173,7 +228,9 @@ pub unsafe fn check_to_aggregate(x: u64) -> Aggregate64 {\n // CHECK-LABEL: @check_from_aggregate(\n #[no_mangle]\n pub unsafe fn check_from_aggregate(x: Aggregate64) -> u64 {\n-    // CHECK: call void @llvm.memcpy.p0.p0.i64(ptr align 8 %{{[0-9]+}}, ptr align 4 %x, i64 8, i1 false)\n+    // CHECK: %x = alloca %Aggregate64, align 4\n+    // CHECK: %[[VAL:.+]] = load i64, ptr %x, align 4\n+    // CHECK: ret i64 %[[VAL]]\n     transmute(x)\n }\n \n@@ -194,3 +251,53 @@ pub unsafe fn check_long_array_more_aligned(x: [u8; 100]) -> [u32; 25] {\n     // CHECK-NEXT: ret void\n     transmute(x)\n }\n+\n+// CHECK-LABEL: @check_pair_with_bool(\n+#[no_mangle]\n+pub unsafe fn check_pair_with_bool(x: (u8, bool)) -> (bool, i8) {\n+    // CHECK-NOT: alloca\n+    // CHECK: trunc i8 %x.0 to i1\n+    // CHECK: zext i1 %x.1 to i8\n+    transmute(x)\n+}\n+\n+// CHECK-LABEL: @check_float_to_pointer(\n+#[no_mangle]\n+pub unsafe fn check_float_to_pointer(x: f64) -> *const () {\n+    // CHECK-NOT: alloca\n+    // CHECK: %0 = bitcast double %x to i64\n+    // CHECK: %1 = inttoptr i64 %0 to ptr\n+    // CHECK: ret ptr %1\n+    transmute(x)\n+}\n+\n+// CHECK-LABEL: @check_float_from_pointer(\n+#[no_mangle]\n+pub unsafe fn check_float_from_pointer(x: *const ()) -> f64 {\n+    // CHECK-NOT: alloca\n+    // CHECK: %0 = ptrtoint ptr %x to i64\n+    // CHECK: %1 = bitcast i64 %0 to double\n+    // CHECK: ret double %1\n+    transmute(x)\n+}\n+\n+// CHECK-LABEL: @check_array_to_pair(\n+#[no_mangle]\n+pub unsafe fn check_array_to_pair(x: [u8; 16]) -> (i64, u64) {\n+    // CHECK-NOT: alloca\n+    // CHECK: %[[FST:.+]] = load i64, ptr %{{.+}}, align 1, !noundef !\n+    // CHECK: %[[SND:.+]] = load i64, ptr %{{.+}}, align 1, !noundef !\n+    // CHECK: %[[PAIR0:.+]] = insertvalue { i64, i64 } poison, i64 %[[FST]], 0\n+    // CHECK: %[[PAIR01:.+]] = insertvalue { i64, i64 } %[[PAIR0]], i64 %[[SND]], 1\n+    // CHECK: ret { i64, i64 } %[[PAIR01]]\n+    transmute(x)\n+}\n+\n+// CHECK-LABEL: @check_pair_to_array(\n+#[no_mangle]\n+pub unsafe fn check_pair_to_array(x: (i64, u64)) -> [u8; 16] {\n+    // CHECK-NOT: alloca\n+    // CHECK: store i64 %x.0, ptr %{{.+}}, align 1\n+    // CHECK: store i64 %x.1, ptr %{{.+}}, align 1\n+    transmute(x)\n+}"}, {"sha": "fd488a14bd37071555d3003a8d8c8fdff783316a", "filename": "tests/codegen/simd-intrinsic/simd-intrinsic-transmute-array.rs", "status": "modified", "additions": 47, "deletions": 4, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/9aa9a846b6e131f9a2b1f477ecc19c2024609847/tests%2Fcodegen%2Fsimd-intrinsic%2Fsimd-intrinsic-transmute-array.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9aa9a846b6e131f9a2b1f477ecc19c2024609847/tests%2Fcodegen%2Fsimd-intrinsic%2Fsimd-intrinsic-transmute-array.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcodegen%2Fsimd-intrinsic%2Fsimd-intrinsic-transmute-array.rs?ref=9aa9a846b6e131f9a2b1f477ecc19c2024609847", "patch": "@@ -4,7 +4,8 @@\n #![crate_type = \"lib\"]\n \n #![allow(non_camel_case_types)]\n-#![feature(repr_simd, platform_intrinsics, min_const_generics)]\n+#![feature(repr_simd, platform_intrinsics)]\n+#![feature(inline_const)]\n \n #[repr(simd)]\n #[derive(Copy, Clone)]\n@@ -18,23 +19,65 @@ pub struct T([f32; 4]);\n #[derive(Copy, Clone)]\n pub struct U(f32, f32, f32, f32);\n \n+// CHECK-LABEL: @array_align(\n+#[no_mangle]\n+pub fn array_align() -> usize {\n+    // CHECK: ret [[USIZE:i[0-9]+]] [[ARRAY_ALIGN:[0-9]+]]\n+    const { std::mem::align_of::<f32>() }\n+}\n+\n+// CHECK-LABEL: @vector_align(\n+#[no_mangle]\n+pub fn vector_align() -> usize {\n+    // CHECK: ret [[USIZE]] [[VECTOR_ALIGN:[0-9]+]]\n+    const { std::mem::align_of::<U>() }\n+}\n+\n // CHECK-LABEL: @build_array_s\n #[no_mangle]\n pub fn build_array_s(x: [f32; 4]) -> S<4> {\n-    // CHECK: call void @llvm.memcpy.{{.+}}({{.*}}, i{{[0-9]+}} 16, i1 false)\n+    // CHECK: call void @llvm.memcpy.{{.+}}({{.*}} align [[VECTOR_ALIGN]] {{.*}} align [[ARRAY_ALIGN]] {{.*}}, [[USIZE]] 16, i1 false)\n     S::<4>(x)\n }\n \n+// CHECK-LABEL: @build_array_transmute_s\n+#[no_mangle]\n+pub fn build_array_transmute_s(x: [f32; 4]) -> S<4> {\n+    // CHECK: %[[VAL:.+]] = load <4 x float>, {{ptr %x|.+>\\* %.+}}, align [[ARRAY_ALIGN]]\n+    // CHECK: store <4 x float> %[[VAL:.+]], {{ptr %0|.+>\\* %.+}}, align [[VECTOR_ALIGN]]\n+    unsafe { std::mem::transmute(x) }\n+}\n+\n // CHECK-LABEL: @build_array_t\n #[no_mangle]\n pub fn build_array_t(x: [f32; 4]) -> T {\n-    // CHECK: call void @llvm.memcpy.{{.+}}({{.*}}, i{{[0-9]+}} 16, i1 false)\n+    // CHECK: call void @llvm.memcpy.{{.+}}({{.*}} align [[VECTOR_ALIGN]] {{.*}} align [[ARRAY_ALIGN]] {{.*}}, [[USIZE]] 16, i1 false)\n     T(x)\n }\n \n+// CHECK-LABEL: @build_array_transmute_t\n+#[no_mangle]\n+pub fn build_array_transmute_t(x: [f32; 4]) -> T {\n+    // CHECK: %[[VAL:.+]] = load <4 x float>, {{ptr %x|.+>\\* %.+}}, align [[ARRAY_ALIGN]]\n+    // CHECK: store <4 x float> %[[VAL:.+]], {{ptr %0|.+>\\* %.+}}, align [[VECTOR_ALIGN]]\n+    unsafe { std::mem::transmute(x) }\n+}\n+\n // CHECK-LABEL: @build_array_u\n #[no_mangle]\n pub fn build_array_u(x: [f32; 4]) -> U {\n-    // CHECK: call void @llvm.memcpy.{{.+}}({{.*}}, i{{[0-9]+}} 16, i1 false)\n+    // CHECK: store float %a, {{.+}}, align [[VECTOR_ALIGN]]\n+    // CHECK: store float %b, {{.+}}, align [[ARRAY_ALIGN]]\n+    // CHECK: store float %c, {{.+}}, align\n+    // CHECK: store float %d, {{.+}}, align [[ARRAY_ALIGN]]\n+    let [a, b, c, d] = x;\n+    U(a, b, c, d)\n+}\n+\n+// CHECK-LABEL: @build_array_transmute_u\n+#[no_mangle]\n+pub fn build_array_transmute_u(x: [f32; 4]) -> U {\n+    // CHECK: %[[VAL:.+]] = load <4 x float>, {{ptr %x|.+>\\* %.+}}, align [[ARRAY_ALIGN]]\n+    // CHECK: store <4 x float> %[[VAL:.+]], {{ptr %0|.+>\\* %.+}}, align [[VECTOR_ALIGN]]\n     unsafe { std::mem::transmute(x) }\n }"}, {"sha": "af2cef472ec6a098f85dbb943a26a0bee13e3d1a", "filename": "tests/codegen/transmute-scalar.rs", "status": "modified", "additions": 17, "deletions": 27, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/9aa9a846b6e131f9a2b1f477ecc19c2024609847/tests%2Fcodegen%2Ftransmute-scalar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9aa9a846b6e131f9a2b1f477ecc19c2024609847/tests%2Fcodegen%2Ftransmute-scalar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcodegen%2Ftransmute-scalar.rs?ref=9aa9a846b6e131f9a2b1f477ecc19c2024609847", "patch": "@@ -5,63 +5,53 @@\n \n // With opaque ptrs in LLVM, `transmute` can load/store any `alloca` as any type,\n // without needing to pointercast, and SRoA will turn that into a `bitcast`.\n-// As such, there's no longer special-casing in `transmute` to attempt to\n-// generate `bitcast` ourselves, as that just made the IR longer.\n+// Thus memory-to-memory transmutes don't need to generate them ourselves.\n \n-// FIXME: That said, `bitcast`s could still be a valuable addition if they could\n-// be done in `rvalue_creates_operand`, and thus avoid the `alloca`s entirely.\n+// However, `bitcast`s and `ptrtoint`s and `inttoptr`s are still worth doing when\n+// that allows us to avoid the `alloca`s entirely; see `rvalue_creates_operand`.\n \n // CHECK-LABEL: define{{.*}}i32 @f32_to_bits(float noundef %x)\n-// CHECK: store float %{{.*}}, ptr %0\n-// CHECK-NEXT: %[[RES:.*]] = load i32, ptr %0\n-// CHECK: ret i32 %[[RES]]\n+// CHECK: %0 = bitcast float %x to i32\n+// CHECK-NEXT: ret i32 %0\n #[no_mangle]\n pub fn f32_to_bits(x: f32) -> u32 {\n     unsafe { std::mem::transmute(x) }\n }\n \n // CHECK-LABEL: define{{.*}}i8 @bool_to_byte(i1 noundef zeroext %b)\n-// CHECK: %1 = zext i1 %b to i8\n-// CHECK-NEXT: store i8 %1, {{.*}} %0\n-// CHECK-NEXT: %2 = load i8, {{.*}} %0\n-// CHECK: ret i8 %2\n+// CHECK: %0 = zext i1 %b to i8\n+// CHECK-NEXT: ret i8 %0\n #[no_mangle]\n pub fn bool_to_byte(b: bool) -> u8 {\n     unsafe { std::mem::transmute(b) }\n }\n \n // CHECK-LABEL: define{{.*}}noundef zeroext i1 @byte_to_bool(i8 noundef %byte)\n-// CHECK: store i8 %byte, ptr %0\n-// CHECK-NEXT: %1 = load i8, {{.*}} %0\n-// CHECK-NEXT: %2 = trunc i8 %1 to i1\n-// CHECK: ret i1 %2\n+// CHECK: %0 = trunc i8 %byte to i1\n+// CHECK-NEXT: ret i1 %0\n #[no_mangle]\n pub unsafe fn byte_to_bool(byte: u8) -> bool {\n     std::mem::transmute(byte)\n }\n \n-// CHECK-LABEL: define{{.*}}{{i8\\*|ptr}} @ptr_to_ptr({{i16\\*|ptr}} noundef %p)\n-// CHECK: store {{i8\\*|ptr}} %{{.*}}, {{.*}} %0\n-// CHECK-NEXT: %[[RES:.*]] = load {{i8\\*|ptr}}, {{.*}} %0\n-// CHECK: ret {{i8\\*|ptr}} %[[RES]]\n+// CHECK-LABEL: define{{.*}}ptr @ptr_to_ptr(ptr noundef %p)\n+// CHECK: ret ptr %p\n #[no_mangle]\n pub fn ptr_to_ptr(p: *mut u16) -> *mut u8 {\n     unsafe { std::mem::transmute(p) }\n }\n \n-// CHECK: define{{.*}}[[USIZE:i[0-9]+]] @ptr_to_int({{i16\\*|ptr}} noundef %p)\n-// CHECK: store {{i16\\*|ptr}} %p, {{.*}}\n-// CHECK-NEXT: %[[RES:.*]] = load [[USIZE]], {{.*}} %0\n-// CHECK: ret [[USIZE]] %[[RES]]\n+// CHECK: define{{.*}}[[USIZE:i[0-9]+]] @ptr_to_int(ptr noundef %p)\n+// CHECK: %0 = ptrtoint ptr %p to [[USIZE]]\n+// CHECK-NEXT: ret [[USIZE]] %0\n #[no_mangle]\n pub fn ptr_to_int(p: *mut u16) -> usize {\n     unsafe { std::mem::transmute(p) }\n }\n \n-// CHECK: define{{.*}}{{i16\\*|ptr}} @int_to_ptr([[USIZE]] noundef %i)\n-// CHECK: store [[USIZE]] %i, {{.*}}\n-// CHECK-NEXT: %[[RES:.*]] = load {{i16\\*|ptr}}, {{.*}} %0\n-// CHECK: ret {{i16\\*|ptr}} %[[RES]]\n+// CHECK: define{{.*}}ptr @int_to_ptr([[USIZE]] noundef %i)\n+// CHECK: %0 = inttoptr [[USIZE]] %i to ptr\n+// CHECK-NEXT: ret ptr %0\n #[no_mangle]\n pub fn int_to_ptr(i: usize) -> *mut u16 {\n     unsafe { std::mem::transmute(i) }"}]}