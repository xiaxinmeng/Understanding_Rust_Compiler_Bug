{"sha": "d630671a33942988391a6a5b52ae0346057e2cf7", "node_id": "C_kwDOAAsO6NoAKGQ2MzA2NzFhMzM5NDI5ODgzOTFhNmE1YjUyYWUwMzQ2MDU3ZTJjZjc", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-08-05T20:27:44Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2022-08-09T17:59:34Z"}, "message": "move atomic access alginment check to helper function and inside atomic access lib", "tree": {"sha": "8374181cacc3e2ac2bed3f6f766c3eafdabad587", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8374181cacc3e2ac2bed3f6f766c3eafdabad587"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d630671a33942988391a6a5b52ae0346057e2cf7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d630671a33942988391a6a5b52ae0346057e2cf7", "html_url": "https://github.com/rust-lang/rust/commit/d630671a33942988391a6a5b52ae0346057e2cf7", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d630671a33942988391a6a5b52ae0346057e2cf7/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "df3c141762b4082ef405bf092b385ca859f1dc8b", "url": "https://api.github.com/repos/rust-lang/rust/commits/df3c141762b4082ef405bf092b385ca859f1dc8b", "html_url": "https://github.com/rust-lang/rust/commit/df3c141762b4082ef405bf092b385ca859f1dc8b"}], "stats": {"total": 90, "additions": 30, "deletions": 60}, "files": [{"sha": "65f198f3c9dd7adc35f82f1dfb842e1dd6b6723b", "filename": "src/concurrency/data_race.rs", "status": "modified", "additions": 26, "deletions": 1, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/d630671a33942988391a6a5b52ae0346057e2cf7/src%2Fconcurrency%2Fdata_race.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d630671a33942988391a6a5b52ae0346057e2cf7/src%2Fconcurrency%2Fdata_race.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fconcurrency%2Fdata_race.rs?ref=d630671a33942988391a6a5b52ae0346057e2cf7", "patch": "@@ -49,7 +49,7 @@ use std::{\n use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n use rustc_index::vec::{Idx, IndexVec};\n use rustc_middle::{mir, ty::layout::TyAndLayout};\n-use rustc_target::abi::Size;\n+use rustc_target::abi::{Align, Size};\n \n use crate::*;\n \n@@ -463,13 +463,30 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         this.write_scalar_atomic(value.into(), &value_place, atomic)\n     }\n \n+    /// Checks that an atomic access is legal at the given place.\n+    fn atomic_access_check(&self, place: &MPlaceTy<'tcx, Provenance>) -> InterpResult<'tcx> {\n+        let this = self.eval_context_ref();\n+        // Check alignment requirements. Atomics must always be aligned to their size,\n+        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n+        // be 8-aligned).\n+        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n+        this.check_ptr_access_align(\n+            place.ptr,\n+            place.layout.size,\n+            align,\n+            CheckInAllocMsg::MemoryAccessTest,\n+        )?;\n+        Ok(())\n+    }\n+\n     /// Perform an atomic read operation at the memory location.\n     fn read_scalar_atomic(\n         &self,\n         place: &MPlaceTy<'tcx, Provenance>,\n         atomic: AtomicReadOrd,\n     ) -> InterpResult<'tcx, ScalarMaybeUninit<Provenance>> {\n         let this = self.eval_context_ref();\n+        this.atomic_access_check(place)?;\n         // This will read from the last store in the modification order of this location. In case\n         // weak memory emulation is enabled, this may not be the store we will pick to actually read from and return.\n         // This is fine with StackedBorrow and race checks because they don't concern metadata on\n@@ -490,6 +507,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         atomic: AtomicWriteOrd,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n+        this.atomic_access_check(dest)?;\n+\n         this.validate_overlapping_atomic(dest)?;\n         this.allow_data_races_mut(move |this| this.write_scalar(val, &dest.into()))?;\n         this.validate_atomic_store(dest, atomic)?;\n@@ -511,6 +530,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         atomic: AtomicRwOrd,\n     ) -> InterpResult<'tcx, ImmTy<'tcx, Provenance>> {\n         let this = self.eval_context_mut();\n+        this.atomic_access_check(place)?;\n \n         this.validate_overlapping_atomic(place)?;\n         let old = this.allow_data_races_mut(|this| this.read_immediate(&place.into()))?;\n@@ -540,6 +560,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         atomic: AtomicRwOrd,\n     ) -> InterpResult<'tcx, ScalarMaybeUninit<Provenance>> {\n         let this = self.eval_context_mut();\n+        this.atomic_access_check(place)?;\n \n         this.validate_overlapping_atomic(place)?;\n         let old = this.allow_data_races_mut(|this| this.read_scalar(&place.into()))?;\n@@ -561,6 +582,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         atomic: AtomicRwOrd,\n     ) -> InterpResult<'tcx, ImmTy<'tcx, Provenance>> {\n         let this = self.eval_context_mut();\n+        this.atomic_access_check(place)?;\n \n         this.validate_overlapping_atomic(place)?;\n         let old = this.allow_data_races_mut(|this| this.read_immediate(&place.into()))?;\n@@ -604,6 +626,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     ) -> InterpResult<'tcx, Immediate<Provenance>> {\n         use rand::Rng as _;\n         let this = self.eval_context_mut();\n+        this.atomic_access_check(place)?;\n \n         this.validate_overlapping_atomic(place)?;\n         // Failure ordering cannot be stronger than success ordering, therefore first attempt\n@@ -1016,6 +1039,7 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     fn allow_data_races_ref<R>(&self, op: impl FnOnce(&MiriEvalContext<'mir, 'tcx>) -> R) -> R {\n         let this = self.eval_context_ref();\n         if let Some(data_race) = &this.machine.data_race {\n+            assert!(!data_race.ongoing_action_data_race_free.get(), \"cannot nest allow_data_races\");\n             data_race.ongoing_action_data_race_free.set(true);\n         }\n         let result = op(this);\n@@ -1035,6 +1059,7 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n     ) -> R {\n         let this = self.eval_context_mut();\n         if let Some(data_race) = &this.machine.data_race {\n+            assert!(!data_race.ongoing_action_data_race_free.get(), \"cannot nest allow_data_races\");\n             data_race.ongoing_action_data_race_free.set(true);\n         }\n         let result = op(this);"}, {"sha": "752bc0e302e74d013d4877b19145fc4b2f0f4016", "filename": "src/shims/intrinsics/atomic.rs", "status": "modified", "additions": 4, "deletions": 59, "changes": 63, "blob_url": "https://github.com/rust-lang/rust/blob/d630671a33942988391a6a5b52ae0346057e2cf7/src%2Fshims%2Fintrinsics%2Fatomic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d630671a33942988391a6a5b52ae0346057e2cf7/src%2Fshims%2Fintrinsics%2Fatomic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fintrinsics%2Fatomic.rs?ref=d630671a33942988391a6a5b52ae0346057e2cf7", "patch": "@@ -1,5 +1,4 @@\n use rustc_middle::{mir, mir::BinOp, ty};\n-use rustc_target::abi::Align;\n \n use crate::*;\n use helpers::check_arg_count;\n@@ -130,20 +129,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         let [place] = check_arg_count(args)?;\n         let place = this.deref_operand(place)?;\n \n-        // make sure it fits into a scalar; otherwise it cannot be atomic\n+        // Perform atomic load.\n         let val = this.read_scalar_atomic(&place, atomic)?;\n-\n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-        // Perform regular access.\n+        // Perform regular store.\n         this.write_scalar(val, dest)?;\n         Ok(())\n     }\n@@ -157,19 +145,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n         let [place, val] = check_arg_count(args)?;\n         let place = this.deref_operand(place)?;\n-        let val = this.read_scalar(val)?; // make sure it fits into a scalar; otherwise it cannot be atomic\n-\n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n \n+        // Perform regular load.\n+        let val = this.read_scalar(val)?;\n         // Perform atomic store\n         this.write_scalar_atomic(val, &place, atomic)?;\n         Ok(())\n@@ -220,17 +198,6 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             span_bug!(this.cur_span(), \"atomic arithmetic operation type mismatch\");\n         }\n \n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-\n         match atomic_op {\n             AtomicOp::Min => {\n                 let old = this.atomic_min_max_scalar(&place, rhs, true, atomic)?;\n@@ -262,17 +229,6 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         let place = this.deref_operand(place)?;\n         let new = this.read_scalar(new)?;\n \n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-\n         let old = this.atomic_exchange_scalar(&place, new, atomic)?;\n         this.write_scalar(old, dest)?; // old value is returned\n         Ok(())\n@@ -293,17 +249,6 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         let expect_old = this.read_immediate(expect_old)?; // read as immediate for the sake of `binary_op()`\n         let new = this.read_scalar(new)?;\n \n-        // Check alignment requirements. Atomics must always be aligned to their size,\n-        // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n-        // be 8-aligned).\n-        let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n-        this.check_ptr_access_align(\n-            place.ptr,\n-            place.layout.size,\n-            align,\n-            CheckInAllocMsg::MemoryAccessTest,\n-        )?;\n-\n         let old = this.atomic_compare_exchange_scalar(\n             &place,\n             &expect_old,"}]}