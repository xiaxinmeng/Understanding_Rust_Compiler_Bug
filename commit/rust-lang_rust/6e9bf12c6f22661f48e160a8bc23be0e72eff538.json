{"sha": "6e9bf12c6f22661f48e160a8bc23be0e72eff538", "node_id": "MDY6Q29tbWl0NzI0NzEyOjZlOWJmMTJjNmYyMjY2MWY0OGUxNjBhOGJjMjNiZTBlNzJlZmY1Mzg=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2016-11-03T07:43:29Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2016-11-03T23:48:24Z"}, "message": "Reimplement \"macros: Improve `tt` fragments\" with better performance.", "tree": {"sha": "40f2e1bcdbd410f6775b3a97a3921821ee846287", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/40f2e1bcdbd410f6775b3a97a3921821ee846287"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6e9bf12c6f22661f48e160a8bc23be0e72eff538", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6e9bf12c6f22661f48e160a8bc23be0e72eff538", "html_url": "https://github.com/rust-lang/rust/commit/6e9bf12c6f22661f48e160a8bc23be0e72eff538", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6e9bf12c6f22661f48e160a8bc23be0e72eff538/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3b71646a600b44868ed6cd7e69d66617a24e41e2", "url": "https://api.github.com/repos/rust-lang/rust/commits/3b71646a600b44868ed6cd7e69d66617a24e41e2", "html_url": "https://github.com/rust-lang/rust/commit/3b71646a600b44868ed6cd7e69d66617a24e41e2"}], "stats": {"total": 79, "additions": 61, "deletions": 18}, "files": [{"sha": "93ab09c89ab96fbd91c3e210fbd63ba8732b634b", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 61, "deletions": 18, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/6e9bf12c6f22661f48e160a8bc23be0e72eff538/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6e9bf12c6f22661f48e160a8bc23be0e72eff538/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=6e9bf12c6f22661f48e160a8bc23be0e72eff538", "patch": "@@ -210,6 +210,7 @@ pub struct Parser<'a> {\n     /// into modules, and sub-parsers have new values for this name.\n     pub root_module_name: Option<String>,\n     pub expected_tokens: Vec<TokenType>,\n+    pub tts: Vec<(TokenTree, usize)>,\n }\n \n #[derive(PartialEq, Eq, Clone)]\n@@ -273,33 +274,71 @@ impl From<P<Expr>> for LhsExpr {\n }\n \n impl<'a> Parser<'a> {\n-    pub fn new(sess: &'a ParseSess, mut rdr: Box<Reader+'a>) -> Self {\n-        let tok0 = rdr.real_token();\n-        let span = tok0.sp;\n-        let mut directory = match span {\n-            syntax_pos::DUMMY_SP => PathBuf::new(),\n-            _ => PathBuf::from(sess.codemap().span_to_filename(span)),\n-        };\n-        directory.pop();\n-\n-        Parser {\n+    pub fn new(sess: &'a ParseSess, rdr: Box<Reader+'a>) -> Self {\n+        let mut parser = Parser {\n             reader: rdr,\n             sess: sess,\n-            token: tok0.tok,\n-            span: span,\n-            prev_span: span,\n+            token: token::Underscore,\n+            span: syntax_pos::DUMMY_SP,\n+            prev_span: syntax_pos::DUMMY_SP,\n             prev_token_kind: PrevTokenKind::Other,\n             lookahead_buffer: Default::default(),\n             tokens_consumed: 0,\n             restrictions: Restrictions::empty(),\n             quote_depth: 0,\n             parsing_token_tree: false,\n             obsolete_set: HashSet::new(),\n-            directory: directory,\n+            directory: PathBuf::new(),\n             open_braces: Vec::new(),\n             owns_directory: true,\n             root_module_name: None,\n             expected_tokens: Vec::new(),\n+            tts: Vec::new(),\n+        };\n+\n+        let tok = parser.next_tok();\n+        parser.token = tok.tok;\n+        parser.span = tok.sp;\n+        if parser.span != syntax_pos::DUMMY_SP {\n+            parser.directory = PathBuf::from(sess.codemap().span_to_filename(parser.span));\n+            parser.directory.pop();\n+        }\n+        parser\n+    }\n+\n+    fn next_tok(&mut self) -> TokenAndSpan {\n+        'outer: loop {\n+            let mut tok = if let Some((tts, i)) = self.tts.pop() {\n+                let tt = tts.get_tt(i);\n+                if i + 1 < tts.len() {\n+                    self.tts.push((tts, i + 1));\n+                }\n+                if let TokenTree::Token(sp, tok) = tt {\n+                    TokenAndSpan { tok: tok, sp: sp }\n+                } else {\n+                    self.tts.push((tt, 0));\n+                    continue\n+                }\n+            } else {\n+                self.reader.real_token()\n+            };\n+\n+            loop {\n+                let nt = match tok.tok {\n+                    token::Interpolated(ref nt) => nt.clone(),\n+                    _ => return tok,\n+                };\n+                match *nt {\n+                    token::NtTT(TokenTree::Token(sp, ref t)) => {\n+                        tok = TokenAndSpan { tok: t.clone(), sp: sp };\n+                    }\n+                    token::NtTT(ref tt) => {\n+                        self.tts.push((tt.clone(), 0));\n+                        continue 'outer\n+                    }\n+                    _ => return tok,\n+                }\n+            }\n         }\n     }\n \n@@ -848,7 +887,7 @@ impl<'a> Parser<'a> {\n         };\n \n         let next = if self.lookahead_buffer.start == self.lookahead_buffer.end {\n-            self.reader.real_token()\n+            self.next_tok()\n         } else {\n             // Avoid token copies with `replace`.\n             let old_start = self.lookahead_buffer.start;\n@@ -893,7 +932,7 @@ impl<'a> Parser<'a> {\n             f(&self.token)\n         } else if dist < LOOKAHEAD_BUFFER_CAPACITY {\n             while self.lookahead_buffer.len() < dist {\n-                self.lookahead_buffer.buffer[self.lookahead_buffer.end] = self.reader.real_token();\n+                self.lookahead_buffer.buffer[self.lookahead_buffer.end] = self.next_tok();\n                 self.lookahead_buffer.end =\n                     (self.lookahead_buffer.end + 1) % LOOKAHEAD_BUFFER_CAPACITY;\n             }\n@@ -2653,8 +2692,6 @@ impl<'a> Parser<'a> {\n         // and token::SubstNt's; it's too early to know yet\n         // whether something will be a nonterminal or a seq\n         // yet.\n-        maybe_whole!(self, NtTT, |x| x);\n-\n         match self.token {\n             token::Eof => {\n                 let mut err: DiagnosticBuilder<'a> =\n@@ -2667,6 +2704,12 @@ impl<'a> Parser<'a> {\n                 Err(err)\n             },\n             token::OpenDelim(delim) => {\n+                if self.tts.last().map(|&(_, i)| i == 1).unwrap_or(false) {\n+                    let tt = self.tts.pop().unwrap().0;\n+                    self.bump();\n+                    return Ok(tt);\n+                }\n+\n                 let parsing_token_tree = ::std::mem::replace(&mut self.parsing_token_tree, true);\n                 // The span for beginning of the delimited section\n                 let pre_span = self.span;"}]}