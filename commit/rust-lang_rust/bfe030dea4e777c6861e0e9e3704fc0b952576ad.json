{"sha": "bfe030dea4e777c6861e0e9e3704fc0b952576ad", "node_id": "MDY6Q29tbWl0NzI0NzEyOmJmZTAzMGRlYTRlNzc3YzY4NjFlMGU5ZTM3MDRmYzBiOTUyNTc2YWQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-05-25T07:02:53Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-05-25T07:02:53Z"}, "message": "Auto merge of #1362 - vakaras:add-sync-primitives-cr1, r=RalfJung\n\nAdd sync primitives\n\nThis is a follow up PR for https://github.com/rust-lang/miri/pull/1284 that adds support for the missing synchronization primitives.\n\nSorry for flooding with PRs, but my internship is coming to an end and I need to get things out.\n\nFixes https://github.com/rust-lang/miri/issues/1419", "tree": {"sha": "a22bbbc430262c98be8fb1a1f7371b93095f7e1b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a22bbbc430262c98be8fb1a1f7371b93095f7e1b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bfe030dea4e777c6861e0e9e3704fc0b952576ad", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bfe030dea4e777c6861e0e9e3704fc0b952576ad", "html_url": "https://github.com/rust-lang/rust/commit/bfe030dea4e777c6861e0e9e3704fc0b952576ad", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bfe030dea4e777c6861e0e9e3704fc0b952576ad/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "726373fcaa8a94c1dea242992a19bb7d58f94df4", "url": "https://api.github.com/repos/rust-lang/rust/commits/726373fcaa8a94c1dea242992a19bb7d58f94df4", "html_url": "https://github.com/rust-lang/rust/commit/726373fcaa8a94c1dea242992a19bb7d58f94df4"}, {"sha": "34ddd775e8352c4905b56f183421902cdda9d100", "url": "https://api.github.com/repos/rust-lang/rust/commits/34ddd775e8352c4905b56f183421902cdda9d100", "html_url": "https://github.com/rust-lang/rust/commit/34ddd775e8352c4905b56f183421902cdda9d100"}], "stats": {"total": 1875, "additions": 1505, "deletions": 370}, "files": [{"sha": "7a6c562e7ca07b76a9a0a6d362a14917afd62f40", "filename": "src/eval.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Feval.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -210,6 +210,12 @@ pub fn eval_main<'tcx>(tcx: TyCtxt<'tcx>, main_id: DefId, config: MiriConfig) ->\n                 SchedulingAction::ExecuteStep => {\n                     assert!(ecx.step()?, \"a terminated thread was scheduled for execution\");\n                 }\n+                SchedulingAction::ExecuteTimeoutCallback => {\n+                    assert!(ecx.machine.communicate,\n+                        \"scheduler callbacks require disabled isolation, but the code \\\n+                        that created the callback did not check it\");\n+                    ecx.run_timeout_callback()?;\n+                }\n                 SchedulingAction::ExecuteDtors => {\n                     // This will either enable the thread again (so we go back\n                     // to `ExecuteStep`), or determine that this thread is done"}, {"sha": "e79fc2add39e1e2152957ad203f2eb0ec71a5e0f", "filename": "src/lib.rs", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -31,6 +31,7 @@ mod operator;\n mod range_map;\n mod shims;\n mod stacked_borrows;\n+mod sync;\n mod thread;\n \n // Make all those symbols available in the same place as our own.\n@@ -45,7 +46,7 @@ pub use crate::shims::fs::{DirHandler, EvalContextExt as FileEvalContextExt, Fil\n pub use crate::shims::intrinsics::EvalContextExt as IntrinsicsEvalContextExt;\n pub use crate::shims::os_str::EvalContextExt as OsStrEvalContextExt;\n pub use crate::shims::panic::{CatchUnwindData, EvalContextExt as PanicEvalContextExt};\n-pub use crate::shims::sync::{EvalContextExt as SyncEvalContextExt};\n+pub use crate::shims::sync::{EvalContextExt as SyncShimsEvalContextExt};\n pub use crate::shims::thread::EvalContextExt as ThreadShimsEvalContextExt;\n pub use crate::shims::time::EvalContextExt as TimeEvalContextExt;\n pub use crate::shims::tls::{EvalContextExt as TlsEvalContextExt, TlsData};\n@@ -70,6 +71,9 @@ pub use crate::stacked_borrows::{\n pub use crate::thread::{\n     EvalContextExt as ThreadsEvalContextExt, SchedulingAction, ThreadId, ThreadManager, ThreadState,\n };\n+pub use crate::sync::{\n+    EvalContextExt as SyncEvalContextExt, CondvarId, MutexId, RwLockId\n+};\n \n /// Insert rustc arguments at the beginning of the argument list that Miri wants to be\n /// set per default, for maximal validation power."}, {"sha": "db2fab526c1f7fe4e6f3ee15404889b8a944038d", "filename": "src/shims/foreign_items/posix.rs", "status": "modified", "additions": 49, "deletions": 5, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Fshims%2Fforeign_items%2Fposix.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Fshims%2Fforeign_items%2Fposix.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fforeign_items%2Fposix.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -330,6 +330,55 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 let result = this.pthread_rwlock_destroy(rwlock)?;\n                 this.write_scalar(Scalar::from_i32(result), dest)?;\n             }\n+            \"pthread_condattr_init\" => {\n+                let &[attr] = check_arg_count(args)?;\n+                let result = this.pthread_condattr_init(attr)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_condattr_setclock\" => {\n+                let &[attr, clock_id] = check_arg_count(args)?;\n+                let result = this.pthread_condattr_setclock(attr, clock_id)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_condattr_getclock\" => {\n+                let &[attr, clock_id] = check_arg_count(args)?;\n+                let result = this.pthread_condattr_getclock(attr, clock_id)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_condattr_destroy\" => {\n+                let &[attr] = check_arg_count(args)?;\n+                let result = this.pthread_condattr_destroy(attr)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_cond_init\" => {\n+                let &[cond, attr] = check_arg_count(args)?;\n+                let result = this.pthread_cond_init(cond, attr)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_cond_signal\" => {\n+                let &[cond] = check_arg_count(args)?;\n+                let result = this.pthread_cond_signal(cond)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_cond_broadcast\" => {\n+                let &[cond] = check_arg_count(args)?;\n+                let result = this.pthread_cond_broadcast(cond)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_cond_wait\" => {\n+                let &[cond, mutex] = check_arg_count(args)?;\n+                let result = this.pthread_cond_wait(cond, mutex)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n+            \"pthread_cond_timedwait\" => {\n+                let &[cond, mutex, abstime] = check_arg_count(args)?;\n+                this.pthread_cond_timedwait(cond, mutex, abstime, dest)?;\n+            }\n+            \"pthread_cond_destroy\" => {\n+                let &[cond] = check_arg_count(args)?;\n+                let result = this.pthread_cond_destroy(cond)?;\n+                this.write_scalar(Scalar::from_i32(result), dest)?;\n+            }\n \n             // Threading\n             \"pthread_create\" => {\n@@ -391,16 +440,11 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n             | \"pthread_attr_init\"\n             | \"pthread_attr_destroy\"\n-            | \"pthread_condattr_init\"\n-            | \"pthread_condattr_destroy\"\n-            | \"pthread_cond_destroy\"\n             if this.frame().instance.to_string().starts_with(\"std::sys::unix::\") => {\n                 let &[_] = check_arg_count(args)?;\n                 this.write_null(dest)?;\n             }\n-            | \"pthread_cond_init\"\n             | \"pthread_attr_setstacksize\"\n-            | \"pthread_condattr_setclock\"\n             if this.frame().instance.to_string().starts_with(\"std::sys::unix::\") => {\n                 let &[_, _] = check_arg_count(args)?;\n                 this.write_null(dest)?;"}, {"sha": "5b0de43e5466996c5974a3a2c4c6dc13fcb73710", "filename": "src/shims/sync.rs", "status": "modified", "additions": 490, "deletions": 236, "changes": 726, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Fshims%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Fshims%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fsync.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -1,8 +1,12 @@\n+use std::convert::TryInto;\n+use std::time::{Duration, SystemTime};\n+\n use rustc_middle::ty::{layout::TyAndLayout, TyKind, TypeAndMut};\n use rustc_target::abi::{LayoutOf, Size};\n \n use crate::stacked_borrows::Tag;\n-use crate::thread::BlockSetId;\n+use crate::thread::Time;\n+\n use crate::*;\n \n fn assert_ptr_target_min_size<'mir, 'tcx: 'mir>(\n@@ -54,8 +58,31 @@ fn set_at_offset<'mir, 'tcx: 'mir>(\n // store an i32 in the first four bytes equal to the corresponding libc mutex kind constant\n // (e.g. PTHREAD_MUTEX_NORMAL).\n \n+/// A flag that allows to distinguish `PTHREAD_MUTEX_NORMAL` from\n+/// `PTHREAD_MUTEX_DEFAULT`. Since in `glibc` they have the same numeric values,\n+/// but different behaviour, we need a way to distinguish them. We do this by\n+/// setting this bit flag to the `PTHREAD_MUTEX_NORMAL` mutexes. See the comment\n+/// in `pthread_mutexattr_settype` function.\n+const PTHREAD_MUTEX_NORMAL_FLAG: i32 = 0x8000000;\n+\n const PTHREAD_MUTEXATTR_T_MIN_SIZE: u64 = 4;\n \n+fn is_mutex_kind_default<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    kind: Scalar<Tag>,\n+) -> InterpResult<'tcx, bool> {\n+    Ok(kind == ecx.eval_libc(\"PTHREAD_MUTEX_DEFAULT\")?)\n+}\n+\n+fn is_mutex_kind_normal<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    kind: Scalar<Tag>,\n+) -> InterpResult<'tcx, bool> {\n+    let kind = kind.to_i32()?;\n+    let mutex_normal_kind = ecx.eval_libc(\"PTHREAD_MUTEX_NORMAL\")?.to_i32()?;\n+    Ok(kind == (mutex_normal_kind | PTHREAD_MUTEX_NORMAL_FLAG))\n+}\n+\n fn mutexattr_get_kind<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     attr_op: OpTy<'tcx, Tag>,\n@@ -76,45 +103,12 @@ fn mutexattr_set_kind<'mir, 'tcx: 'mir>(\n // Our chosen memory layout for the emulated mutex (does not have to match the platform layout!):\n // bytes 0-3: reserved for signature on macOS\n // (need to avoid this because it is set by static initializer macros)\n-// bytes 4-7: count of how many times this mutex has been locked, as a u32\n-// bytes 8-11: when count > 0, id of the owner thread as a u32\n+// bytes 4-7: mutex id as u32 or 0 if id is not assigned yet.\n // bytes 12-15 or 16-19 (depending on platform): mutex kind, as an i32\n // (the kind has to be at its offset for compatibility with static initializer macros)\n-// bytes 20-23: when count > 0, id of the blockset in which the blocked threads\n-// are waiting or 0 if blockset is not yet assigned.\n \n const PTHREAD_MUTEX_T_MIN_SIZE: u64 = 24;\n \n-fn mutex_get_locked_count<'mir, 'tcx: 'mir>(\n-    ecx: &MiriEvalContext<'mir, 'tcx>,\n-    mutex_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n-    get_at_offset(ecx, mutex_op, 4, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n-}\n-\n-fn mutex_set_locked_count<'mir, 'tcx: 'mir>(\n-    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    mutex_op: OpTy<'tcx, Tag>,\n-    locked_count: impl Into<ScalarMaybeUninit<Tag>>,\n-) -> InterpResult<'tcx, ()> {\n-    set_at_offset(ecx, mutex_op, 4, locked_count, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n-}\n-\n-fn mutex_get_owner<'mir, 'tcx: 'mir>(\n-    ecx: &MiriEvalContext<'mir, 'tcx>,\n-    mutex_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n-    get_at_offset(ecx, mutex_op, 8, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n-}\n-\n-fn mutex_set_owner<'mir, 'tcx: 'mir>(\n-    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    mutex_op: OpTy<'tcx, Tag>,\n-    owner: impl Into<ScalarMaybeUninit<Tag>>,\n-) -> InterpResult<'tcx, ()> {\n-    set_at_offset(ecx, mutex_op, 8, owner, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n-}\n-\n fn mutex_get_kind<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n@@ -132,34 +126,34 @@ fn mutex_set_kind<'mir, 'tcx: 'mir>(\n     set_at_offset(ecx, mutex_op, offset, kind, ecx.machine.layouts.i32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n-fn mutex_get_blockset<'mir, 'tcx: 'mir>(\n+fn mutex_get_id<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n-    get_at_offset(ecx, mutex_op, 20, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n+    get_at_offset(ecx, mutex_op, 4, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n-fn mutex_set_blockset<'mir, 'tcx: 'mir>(\n+fn mutex_set_id<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n-    blockset: impl Into<ScalarMaybeUninit<Tag>>,\n+    id: impl Into<ScalarMaybeUninit<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    set_at_offset(ecx, mutex_op, 20, blockset, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n+    set_at_offset(ecx, mutex_op, 4, id, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n-fn mutex_get_or_create_blockset<'mir, 'tcx: 'mir>(\n+fn mutex_get_or_create_id<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, BlockSetId> {\n-    let blockset = mutex_get_blockset(ecx, mutex_op)?.to_u32()?;\n-    if blockset == 0 {\n-        // 0 is a default value and also not a valid blockset id. Need to\n-        // allocate a new blockset.\n-        let blockset = ecx.create_blockset()?;\n-        mutex_set_blockset(ecx, mutex_op, blockset.to_u32_scalar())?;\n-        Ok(blockset)\n+) -> InterpResult<'tcx, MutexId> {\n+    let id = mutex_get_id(ecx, mutex_op)?.to_u32()?;\n+    if id == 0 {\n+        // 0 is a default value and also not a valid mutex id. Need to allocate\n+        // a new mutex.\n+        let id = ecx.mutex_create();\n+        mutex_set_id(ecx, mutex_op, id.to_u32_scalar())?;\n+        Ok(id)\n     } else {\n-        Ok(BlockSetId::new(blockset))\n+        Ok(MutexId::from_u32(id))\n     }\n }\n \n@@ -168,105 +162,166 @@ fn mutex_get_or_create_blockset<'mir, 'tcx: 'mir>(\n // Our chosen memory layout for the emulated rwlock (does not have to match the platform layout!):\n // bytes 0-3: reserved for signature on macOS\n // (need to avoid this because it is set by static initializer macros)\n-// bytes 4-7: reader count, as a u32\n-// bytes 8-11: writer count, as a u32\n-// bytes 12-15: when writer or reader count > 0, id of the blockset in which the\n-// blocked writers are waiting or 0 if blockset is not yet assigned.\n-// bytes 16-20: when writer count > 0, id of the blockset in which the blocked\n-// readers are waiting or 0 if blockset is not yet assigned.\n+// bytes 4-7: rwlock id as u32 or 0 if id is not assigned yet.\n \n-const PTHREAD_RWLOCK_T_MIN_SIZE: u64 = 20;\n+const PTHREAD_RWLOCK_T_MIN_SIZE: u64 = 32;\n \n-fn rwlock_get_readers<'mir, 'tcx: 'mir>(\n+fn rwlock_get_id<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n     get_at_offset(ecx, rwlock_op, 4, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n-fn rwlock_set_readers<'mir, 'tcx: 'mir>(\n+fn rwlock_set_id<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n-    readers: impl Into<ScalarMaybeUninit<Tag>>,\n+    id: impl Into<ScalarMaybeUninit<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    set_at_offset(ecx, rwlock_op, 4, readers, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+    set_at_offset(ecx, rwlock_op, 4, id, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n-fn rwlock_get_writers<'mir, 'tcx: 'mir>(\n-    ecx: &MiriEvalContext<'mir, 'tcx>,\n+fn rwlock_get_or_create_id<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, RwLockId> {\n+    let id = rwlock_get_id(ecx, rwlock_op)?.to_u32()?;\n+    if id == 0 {\n+        // 0 is a default value and also not a valid rwlock id. Need to allocate\n+        // a new read-write lock.\n+        let id = ecx.rwlock_create();\n+        rwlock_set_id(ecx, rwlock_op, id.to_u32_scalar())?;\n+        Ok(id)\n+    } else {\n+        Ok(RwLockId::from_u32(id))\n+    }\n+}\n+\n+// pthread_condattr_t\n+\n+// Our chosen memory layout for emulation (does not have to match the platform layout!):\n+// store an i32 in the first four bytes equal to the corresponding libc clock id constant\n+// (e.g. CLOCK_REALTIME).\n+\n+const PTHREAD_CONDATTR_T_MIN_SIZE: u64 = 4;\n+\n+fn condattr_get_clock_id<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    attr_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n-    get_at_offset(ecx, rwlock_op, 8, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+    get_at_offset(ecx, attr_op, 0, ecx.machine.layouts.i32, PTHREAD_CONDATTR_T_MIN_SIZE)\n }\n \n-fn rwlock_set_writers<'mir, 'tcx: 'mir>(\n+fn condattr_set_clock_id<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-    writers: impl Into<ScalarMaybeUninit<Tag>>,\n+    attr_op: OpTy<'tcx, Tag>,\n+    clock_id: impl Into<ScalarMaybeUninit<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    set_at_offset(ecx, rwlock_op, 8, writers, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+    set_at_offset(ecx, attr_op, 0, clock_id, ecx.machine.layouts.i32, PTHREAD_CONDATTR_T_MIN_SIZE)\n }\n \n-fn rwlock_get_writer_blockset<'mir, 'tcx: 'mir>(\n+// pthread_cond_t\n+\n+// Our chosen memory layout for the emulated conditional variable (does not have\n+// to match the platform layout!):\n+\n+// bytes 0-3: reserved for signature on macOS\n+// bytes 4-7: the conditional variable id as u32 or 0 if id is not assigned yet.\n+// bytes 8-11: the clock id constant as i32\n+\n+const PTHREAD_COND_T_MIN_SIZE: u64 = 12;\n+\n+fn cond_get_id<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n+    cond_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n-    get_at_offset(ecx, rwlock_op, 12, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+    get_at_offset(ecx, cond_op, 4, ecx.machine.layouts.u32, PTHREAD_COND_T_MIN_SIZE)\n }\n \n-fn rwlock_set_writer_blockset<'mir, 'tcx: 'mir>(\n+fn cond_set_id<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-    blockset: impl Into<ScalarMaybeUninit<Tag>>,\n+    cond_op: OpTy<'tcx, Tag>,\n+    id: impl Into<ScalarMaybeUninit<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    set_at_offset(ecx, rwlock_op, 12, blockset, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+    set_at_offset(ecx, cond_op, 4, id, ecx.machine.layouts.u32, PTHREAD_COND_T_MIN_SIZE)\n }\n \n-fn rwlock_get_or_create_writer_blockset<'mir, 'tcx: 'mir>(\n+fn cond_get_or_create_id<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, BlockSetId> {\n-    let blockset = rwlock_get_writer_blockset(ecx, rwlock_op)?.to_u32()?;\n-    if blockset == 0 {\n-        // 0 is a default value and also not a valid blockset id. Need to\n-        // allocate a new blockset.\n-        let blockset = ecx.create_blockset()?;\n-        rwlock_set_writer_blockset(ecx, rwlock_op, blockset.to_u32_scalar())?;\n-        Ok(blockset)\n+    cond_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, CondvarId> {\n+    let id = cond_get_id(ecx, cond_op)?.to_u32()?;\n+    if id == 0 {\n+        // 0 is a default value and also not a valid conditional variable id.\n+        // Need to allocate a new id.\n+        let id = ecx.condvar_create();\n+        cond_set_id(ecx, cond_op, id.to_u32_scalar())?;\n+        Ok(id)\n     } else {\n-        Ok(BlockSetId::new(blockset))\n+        Ok(CondvarId::from_u32(id))\n     }\n }\n \n-fn rwlock_get_reader_blockset<'mir, 'tcx: 'mir>(\n+fn cond_get_clock_id<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n+    cond_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUninit<Tag>> {\n-    get_at_offset(ecx, rwlock_op, 16, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+    get_at_offset(ecx, cond_op, 8, ecx.machine.layouts.i32, PTHREAD_COND_T_MIN_SIZE)\n }\n \n-fn rwlock_set_reader_blockset<'mir, 'tcx: 'mir>(\n+fn cond_set_clock_id<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-    blockset: impl Into<ScalarMaybeUninit<Tag>>,\n+    cond_op: OpTy<'tcx, Tag>,\n+    clock_id: impl Into<ScalarMaybeUninit<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    set_at_offset(ecx, rwlock_op, 16, blockset, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n+    set_at_offset(ecx, cond_op, 8, clock_id, ecx.machine.layouts.i32, PTHREAD_COND_T_MIN_SIZE)\n }\n \n-fn rwlock_get_or_create_reader_blockset<'mir, 'tcx: 'mir>(\n+/// Try to reacquire the mutex associated with the condition variable after we\n+/// were signaled.\n+fn reacquire_cond_mutex<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, BlockSetId> {\n-    let blockset = rwlock_get_reader_blockset(ecx, rwlock_op)?.to_u32()?;\n-    if blockset == 0 {\n-        // 0 is a default value and also not a valid blockset id. Need to\n-        // allocate a new blockset.\n-        let blockset = ecx.create_blockset()?;\n-        rwlock_set_reader_blockset(ecx, rwlock_op, blockset.to_u32_scalar())?;\n-        Ok(blockset)\n+    thread: ThreadId,\n+    mutex: MutexId,\n+) -> InterpResult<'tcx> {\n+    if ecx.mutex_is_locked(mutex) {\n+        ecx.mutex_enqueue(mutex, thread);\n+    } else {\n+        ecx.mutex_lock(mutex, thread);\n+        ecx.unblock_thread(thread)?;\n+    }\n+    Ok(())\n+}\n+\n+/// Reacquire the conditional variable and remove the timeout callback if any\n+/// was registered.\n+fn post_cond_signal<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    thread: ThreadId,\n+    mutex: MutexId,\n+) -> InterpResult<'tcx> {\n+    reacquire_cond_mutex(ecx, thread, mutex)?;\n+    // Waiting for the mutex is not included in the waiting time because we need\n+    // to acquire the mutex always even if we get a timeout.\n+    ecx.unregister_timeout_callback_if_exists(thread)\n+}\n+\n+/// Release the mutex associated with the condition variable because we are\n+/// entering the waiting state.\n+fn release_cond_mutex<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    active_thread: ThreadId,\n+    mutex: MutexId,\n+) -> InterpResult<'tcx> {\n+    if let Some(old_locked_count) = ecx.mutex_unlock(mutex, active_thread)? {\n+        if old_locked_count != 1 {\n+            throw_unsup_format!(\"awaiting on a lock acquired multiple times is not supported\");\n+        }\n     } else {\n-        Ok(BlockSetId::new(blockset))\n+        throw_ub_format!(\"awaiting on unlocked or owned by a different thread mutex\");\n     }\n+    ecx.block_thread(active_thread)?;\n+    Ok(())\n }\n \n impl<'mir, 'tcx> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n@@ -288,7 +343,27 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         let this = self.eval_context_mut();\n \n         let kind = this.read_scalar(kind_op)?.not_undef()?;\n-        if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")?\n+        if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n+            // In `glibc` implementation, the numeric values of\n+            // `PTHREAD_MUTEX_NORMAL` and `PTHREAD_MUTEX_DEFAULT` are equal.\n+            // However, a mutex created by explicitly passing\n+            // `PTHREAD_MUTEX_NORMAL` type has in some cases different behaviour\n+            // from the default mutex for which the type was not explicitly\n+            // specified. For a more detailed discussion, please see\n+            // https://github.com/rust-lang/miri/issues/1419.\n+            //\n+            // To distinguish these two cases in already constructed mutexes, we\n+            // use the same trick as glibc: for the case when\n+            // `pthread_mutexattr_settype` is caled explicitly, we set the\n+            // `PTHREAD_MUTEX_NORMAL_FLAG` flag.\n+            let normal_kind = kind.to_i32()? | PTHREAD_MUTEX_NORMAL_FLAG;\n+            // Check that after setting the flag, the kind is distinguishable\n+            // from all other kinds.\n+            assert_ne!(normal_kind, this.eval_libc(\"PTHREAD_MUTEX_DEFAULT\")?.to_i32()?);\n+            assert_ne!(normal_kind, this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")?.to_i32()?);\n+            assert_ne!(normal_kind, this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")?.to_i32()?);\n+            mutexattr_set_kind(this, attr_op, Scalar::from_i32(normal_kind))?;\n+        } else if kind == this.eval_libc(\"PTHREAD_MUTEX_DEFAULT\")?\n             || kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")?\n             || kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")?\n         {\n@@ -323,7 +398,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             mutexattr_get_kind(this, attr_op)?.not_undef()?\n         };\n \n-        mutex_set_locked_count(this, mutex_op, Scalar::from_u32(0))?;\n+        // Write 0 to use the same code path as the static initializers.\n+        mutex_set_id(this, mutex_op, Scalar::from_i32(0))?;\n+\n         mutex_set_kind(this, mutex_op, kind)?;\n \n         Ok(0)\n@@ -333,256 +410,433 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         let this = self.eval_context_mut();\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n-        let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n+        let id = mutex_get_or_create_id(this, mutex_op)?;\n         let active_thread = this.get_active_thread()?;\n \n-        if locked_count == 0 {\n-            // The mutex is unlocked. Let's lock it.\n-            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n-            mutex_set_owner(this, mutex_op, active_thread.to_u32_scalar())?;\n-            Ok(0)\n-        } else {\n-            // The mutex is locked. Let's check by whom.\n-            let owner_thread: ThreadId = mutex_get_owner(this, mutex_op)?.to_u32()?.into();\n+        if this.mutex_is_locked(id) {\n+            let owner_thread = this.mutex_get_owner(id);\n             if owner_thread != active_thread {\n                 // Block the active thread.\n-                let blockset = mutex_get_or_create_blockset(this, mutex_op)?;\n-                this.block_active_thread(blockset)?;\n+                this.block_thread(active_thread)?;\n+                this.mutex_enqueue(id, active_thread);\n                 Ok(0)\n             } else {\n                 // Trying to acquire the same mutex again.\n-                if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n+                if is_mutex_kind_default(this, kind)? {\n+                    throw_ub_format!(\"trying to acquire already locked default mutex\");\n+                } else if is_mutex_kind_normal(this, kind)? {\n                     throw_machine_stop!(TerminationInfo::Deadlock);\n                 } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n                     this.eval_libc_i32(\"EDEADLK\")\n                 } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-                    match locked_count.checked_add(1) {\n-                        Some(new_count) => {\n-                            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                            Ok(0)\n-                        }\n-                        None => this.eval_libc_i32(\"EAGAIN\"),\n-                    }\n+                    this.mutex_lock(id, active_thread);\n+                    Ok(0)\n                 } else {\n-                    throw_ub_format!(\"called pthread_mutex_lock on an unsupported type of mutex\");\n+                    throw_unsup_format!(\n+                        \"called pthread_mutex_lock on an unsupported type of mutex\"\n+                    );\n                 }\n             }\n+        } else {\n+            // The mutex is unlocked. Let's lock it.\n+            this.mutex_lock(id, active_thread);\n+            Ok(0)\n         }\n     }\n \n     fn pthread_mutex_trylock(&mut self, mutex_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n-        let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n+        let id = mutex_get_or_create_id(this, mutex_op)?;\n         let active_thread = this.get_active_thread()?;\n \n-        if locked_count == 0 {\n-            // The mutex is unlocked. Let's lock it.\n-            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(1))?;\n-            mutex_set_owner(this, mutex_op, active_thread.to_u32_scalar())?;\n-            Ok(0)\n-        } else {\n-            let owner_thread: ThreadId = mutex_get_owner(this, mutex_op)?.to_u32()?.into();\n+        if this.mutex_is_locked(id) {\n+            let owner_thread = this.mutex_get_owner(id);\n             if owner_thread != active_thread {\n                 this.eval_libc_i32(\"EBUSY\")\n             } else {\n-                if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")?\n+                if is_mutex_kind_default(this, kind)?\n+                    || is_mutex_kind_normal(this, kind)?\n                     || kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")?\n                 {\n                     this.eval_libc_i32(\"EBUSY\")\n                 } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-                    match locked_count.checked_add(1) {\n-                        Some(new_count) => {\n-                            mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                            Ok(0)\n-                        }\n-                        None => this.eval_libc_i32(\"EAGAIN\"),\n-                    }\n+                    this.mutex_lock(id, active_thread);\n+                    Ok(0)\n                 } else {\n-                    throw_ub_format!(\n+                    throw_unsup_format!(\n                         \"called pthread_mutex_trylock on an unsupported type of mutex\"\n                     );\n                 }\n             }\n+        } else {\n+            // The mutex is unlocked. Let's lock it.\n+            this.mutex_lock(id, active_thread);\n+            Ok(0)\n         }\n     }\n \n     fn pthread_mutex_unlock(&mut self, mutex_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n         let kind = mutex_get_kind(this, mutex_op)?.not_undef()?;\n-        let locked_count = mutex_get_locked_count(this, mutex_op)?.to_u32()?;\n-        let owner_thread: ThreadId = mutex_get_owner(this, mutex_op)?.to_u32()?.into();\n-\n-        if owner_thread != this.get_active_thread()? {\n-            throw_ub_format!(\"called pthread_mutex_unlock on a mutex owned by another thread\");\n-        } else if locked_count == 1 {\n-            let blockset = mutex_get_or_create_blockset(this, mutex_op)?;\n-            if let Some(new_owner) = this.unblock_some_thread(blockset)? {\n-                // We have at least one thread waiting on this mutex. Transfer\n-                // ownership to it.\n-                mutex_set_owner(this, mutex_op, new_owner.to_u32_scalar())?;\n-            } else {\n-                // No thread is waiting on this mutex.\n-                mutex_set_owner(this, mutex_op, Scalar::from_u32(0))?;\n-                mutex_set_locked_count(this, mutex_op, Scalar::from_u32(0))?;\n-            }\n+        let id = mutex_get_or_create_id(this, mutex_op)?;\n+        let active_thread = this.get_active_thread()?;\n+\n+        if let Some(_old_locked_count) = this.mutex_unlock(id, active_thread)? {\n+            // The mutex was locked by the current thread.\n             Ok(0)\n         } else {\n-            if kind == this.eval_libc(\"PTHREAD_MUTEX_NORMAL\")? {\n-                throw_ub_format!(\"unlocked a PTHREAD_MUTEX_NORMAL mutex that was not locked\");\n+            // The mutex was locked by another thread or not locked at all. See\n+            // the \u201cUnlock When Not Owner\u201d column in\n+            // https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_mutex_unlock.html.\n+            if is_mutex_kind_default(this, kind)? {\n+                throw_ub_format!(\n+                    \"unlocked a default mutex that was not locked by the current thread\"\n+                );\n+            } else if is_mutex_kind_normal(this, kind)? {\n+                throw_ub_format!(\n+                    \"unlocked a PTHREAD_MUTEX_NORMAL mutex that was not locked by the current thread\"\n+                );\n             } else if kind == this.eval_libc(\"PTHREAD_MUTEX_ERRORCHECK\")? {\n                 this.eval_libc_i32(\"EPERM\")\n             } else if kind == this.eval_libc(\"PTHREAD_MUTEX_RECURSIVE\")? {\n-                match locked_count.checked_sub(1) {\n-                    Some(new_count) => {\n-                        mutex_set_locked_count(this, mutex_op, Scalar::from_u32(new_count))?;\n-                        Ok(0)\n-                    }\n-                    None => {\n-                        // locked_count was already zero\n-                        this.eval_libc_i32(\"EPERM\")\n-                    }\n-                }\n+                this.eval_libc_i32(\"EPERM\")\n             } else {\n-                throw_ub_format!(\"called pthread_mutex_unlock on an unsupported type of mutex\");\n+                throw_unsup_format!(\"called pthread_mutex_unlock on an unsupported type of mutex\");\n             }\n         }\n     }\n \n     fn pthread_mutex_destroy(&mut self, mutex_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n-        if mutex_get_locked_count(this, mutex_op)?.to_u32()? != 0 {\n+        let id = mutex_get_or_create_id(this, mutex_op)?;\n+\n+        if this.mutex_is_locked(id) {\n             throw_ub_format!(\"destroyed a locked mutex\");\n         }\n \n         mutex_set_kind(this, mutex_op, ScalarMaybeUninit::Uninit)?;\n-        mutex_set_locked_count(this, mutex_op, ScalarMaybeUninit::Uninit)?;\n-        mutex_set_blockset(this, mutex_op, ScalarMaybeUninit::Uninit)?;\n+        mutex_set_id(this, mutex_op, ScalarMaybeUninit::Uninit)?;\n \n         Ok(0)\n     }\n \n     fn pthread_rwlock_rdlock(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n-        let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n-        let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n+        let id = rwlock_get_or_create_id(this, rwlock_op)?;\n+        let active_thread = this.get_active_thread()?;\n \n-        if writers != 0 {\n-            // The lock is locked by a writer.\n-            assert_eq!(writers, 1);\n-            let reader_blockset = rwlock_get_or_create_reader_blockset(this, rwlock_op)?;\n-            this.block_active_thread(reader_blockset)?;\n+        if this.rwlock_is_write_locked(id) {\n+            this.rwlock_enqueue_and_block_reader(id, active_thread)?;\n             Ok(0)\n         } else {\n-            match readers.checked_add(1) {\n-                Some(new_readers) => {\n-                    rwlock_set_readers(this, rwlock_op, Scalar::from_u32(new_readers))?;\n-                    Ok(0)\n-                }\n-                None => this.eval_libc_i32(\"EAGAIN\"),\n-            }\n+            this.rwlock_reader_lock(id, active_thread);\n+            Ok(0)\n         }\n     }\n \n     fn pthread_rwlock_tryrdlock(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n-        let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n-        let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n-        if writers != 0 {\n+        let id = rwlock_get_or_create_id(this, rwlock_op)?;\n+        let active_thread = this.get_active_thread()?;\n+\n+        if this.rwlock_is_write_locked(id) {\n             this.eval_libc_i32(\"EBUSY\")\n         } else {\n-            match readers.checked_add(1) {\n-                Some(new_readers) => {\n-                    rwlock_set_readers(this, rwlock_op, Scalar::from_u32(new_readers))?;\n-                    Ok(0)\n-                }\n-                None => this.eval_libc_i32(\"EAGAIN\"),\n-            }\n+            this.rwlock_reader_lock(id, active_thread);\n+            Ok(0)\n         }\n     }\n \n     fn pthread_rwlock_wrlock(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n-        let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n-        let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n-        let writer_blockset = rwlock_get_or_create_writer_blockset(this, rwlock_op)?;\n-        if readers != 0 || writers != 0 {\n-            this.block_active_thread(writer_blockset)?;\n+        let id = rwlock_get_or_create_id(this, rwlock_op)?;\n+        let active_thread = this.get_active_thread()?;\n+\n+        if this.rwlock_is_locked(id) {\n+            // Note: this will deadlock if the lock is already locked by this\n+            // thread in any way.\n+            //\n+            // Relevant documentation:\n+            // https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_rwlock_wrlock.html\n+            // An in depth discussion on this topic:\n+            // https://github.com/rust-lang/rust/issues/53127\n+            //\n+            // FIXME: Detect and report the deadlock proactively. (We currently\n+            // report the deadlock only when no thread can continue execution,\n+            // but we could detect that this lock is already locked and report\n+            // an error.)\n+            this.rwlock_enqueue_and_block_writer(id, active_thread)?;\n         } else {\n-            rwlock_set_writers(this, rwlock_op, Scalar::from_u32(1))?;\n+            this.rwlock_writer_lock(id, active_thread);\n         }\n+\n         Ok(0)\n     }\n \n     fn pthread_rwlock_trywrlock(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n-        let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n-        let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n-        if readers != 0 || writers != 0 {\n+        let id = rwlock_get_or_create_id(this, rwlock_op)?;\n+        let active_thread = this.get_active_thread()?;\n+\n+        if this.rwlock_is_locked(id) {\n             this.eval_libc_i32(\"EBUSY\")\n         } else {\n-            rwlock_set_writers(this, rwlock_op, Scalar::from_u32(1))?;\n+            this.rwlock_writer_lock(id, active_thread);\n             Ok(0)\n         }\n     }\n \n-    // FIXME: We should check that this lock was locked by the active thread.\n     fn pthread_rwlock_unlock(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n-        let readers = rwlock_get_readers(this, rwlock_op)?.to_u32()?;\n-        let writers = rwlock_get_writers(this, rwlock_op)?.to_u32()?;\n-        let writer_blockset = rwlock_get_or_create_writer_blockset(this, rwlock_op)?;\n-        if let Some(new_readers) = readers.checked_sub(1) {\n-            assert_eq!(writers, 0);\n-            rwlock_set_readers(this, rwlock_op, Scalar::from_u32(new_readers))?;\n-            if new_readers == 0 {\n-                if let Some(_writer) = this.unblock_some_thread(writer_blockset)? {\n-                    rwlock_set_writers(this, rwlock_op, Scalar::from_u32(1))?;\n+        let id = rwlock_get_or_create_id(this, rwlock_op)?;\n+        let active_thread = this.get_active_thread()?;\n+\n+        if this.rwlock_reader_unlock(id, active_thread) {\n+            // The thread was a reader.\n+            if this.rwlock_is_locked(id) {\n+                // No more readers owning the lock. Give it to a writer if there\n+                // is any.\n+                if let Some(writer) = this.rwlock_dequeue_writer(id) {\n+                    this.unblock_thread(writer)?;\n+                    this.rwlock_writer_lock(id, writer);\n                 }\n             }\n             Ok(0)\n-        } else if writers != 0 {\n-            let reader_blockset = rwlock_get_or_create_reader_blockset(this, rwlock_op)?;\n+        } else if Some(active_thread) == this.rwlock_writer_unlock(id) {\n+            // The thread was a writer.\n+            //\n             // We are prioritizing writers here against the readers. As a\n             // result, not only readers can starve writers, but also writers can\n             // starve readers.\n-            if let Some(_writer) = this.unblock_some_thread(writer_blockset)? {\n-                assert_eq!(writers, 1);\n+            if let Some(writer) = this.rwlock_dequeue_writer(id) {\n+                // Give the lock to another writer.\n+                this.unblock_thread(writer)?;\n+                this.rwlock_writer_lock(id, writer);\n             } else {\n-                rwlock_set_writers(this, rwlock_op, Scalar::from_u32(0))?;\n-                let mut readers = 0;\n-                while let Some(_reader) = this.unblock_some_thread(reader_blockset)? {\n-                    readers += 1;\n+                // Give the lock to all readers.\n+                while let Some(reader) = this.rwlock_dequeue_reader(id) {\n+                    this.unblock_thread(reader)?;\n+                    this.rwlock_reader_lock(id, reader);\n                 }\n-                rwlock_set_readers(this, rwlock_op, Scalar::from_u32(readers))?\n             }\n             Ok(0)\n         } else {\n-            throw_ub_format!(\"unlocked an rwlock that was not locked\");\n+            throw_ub_format!(\"unlocked an rwlock that was not locked by the active thread\");\n         }\n     }\n \n     fn pthread_rwlock_destroy(&mut self, rwlock_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n         let this = self.eval_context_mut();\n \n-        if rwlock_get_readers(this, rwlock_op)?.to_u32()? != 0\n-            || rwlock_get_writers(this, rwlock_op)?.to_u32()? != 0\n-        {\n+        let id = rwlock_get_or_create_id(this, rwlock_op)?;\n+\n+        if this.rwlock_is_locked(id) {\n             throw_ub_format!(\"destroyed a locked rwlock\");\n         }\n \n-        rwlock_set_readers(this, rwlock_op, ScalarMaybeUninit::Uninit)?;\n-        rwlock_set_writers(this, rwlock_op, ScalarMaybeUninit::Uninit)?;\n-        rwlock_set_reader_blockset(this, rwlock_op, ScalarMaybeUninit::Uninit)?;\n-        rwlock_set_writer_blockset(this, rwlock_op, ScalarMaybeUninit::Uninit)?;\n+        rwlock_set_id(this, rwlock_op, ScalarMaybeUninit::Uninit)?;\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_condattr_init(&mut self, attr_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        // The default value of the clock attribute shall refer to the system\n+        // clock.\n+        // https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_condattr_setclock.html\n+        let default_clock_id = this.eval_libc(\"CLOCK_REALTIME\")?;\n+        condattr_set_clock_id(this, attr_op, default_clock_id)?;\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_condattr_setclock(\n+        &mut self,\n+        attr_op: OpTy<'tcx, Tag>,\n+        clock_id_op: OpTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        let clock_id = this.read_scalar(clock_id_op)?.not_undef()?;\n+        if clock_id == this.eval_libc(\"CLOCK_REALTIME\")?\n+            || clock_id == this.eval_libc(\"CLOCK_MONOTONIC\")?\n+        {\n+            condattr_set_clock_id(this, attr_op, clock_id)?;\n+        } else {\n+            let einval = this.eval_libc_i32(\"EINVAL\")?;\n+            return Ok(einval);\n+        }\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_condattr_getclock(\n+        &mut self,\n+        attr_op: OpTy<'tcx, Tag>,\n+        clk_id_op: OpTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        let clock_id = condattr_get_clock_id(this, attr_op)?;\n+        this.write_scalar(clock_id, this.deref_operand(clk_id_op)?.into())?;\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_condattr_destroy(&mut self, attr_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        condattr_set_clock_id(this, attr_op, ScalarMaybeUninit::Uninit)?;\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_cond_init(\n+        &mut self,\n+        cond_op: OpTy<'tcx, Tag>,\n+        attr_op: OpTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        let attr = this.read_scalar(attr_op)?.not_undef()?;\n+        let clock_id = if this.is_null(attr)? {\n+            this.eval_libc(\"CLOCK_REALTIME\")?\n+        } else {\n+            condattr_get_clock_id(this, attr_op)?.not_undef()?\n+        };\n+\n+        // Write 0 to use the same code path as the static initializers.\n+        cond_set_id(this, cond_op, Scalar::from_i32(0))?;\n+\n+        cond_set_clock_id(this, cond_op, clock_id)?;\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_cond_signal(&mut self, cond_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+        let id = cond_get_or_create_id(this, cond_op)?;\n+        if let Some((thread, mutex)) = this.condvar_signal(id) {\n+            post_cond_signal(this, thread, mutex)?;\n+        }\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_cond_broadcast(&mut self, cond_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+        let id = cond_get_or_create_id(this, cond_op)?;\n+\n+        while let Some((thread, mutex)) = this.condvar_signal(id) {\n+            post_cond_signal(this, thread, mutex)?;\n+        }\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_cond_wait(\n+        &mut self,\n+        cond_op: OpTy<'tcx, Tag>,\n+        mutex_op: OpTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        let id = cond_get_or_create_id(this, cond_op)?;\n+        let mutex_id = mutex_get_or_create_id(this, mutex_op)?;\n+        let active_thread = this.get_active_thread()?;\n+\n+        release_cond_mutex(this, active_thread, mutex_id)?;\n+        this.condvar_wait(id, active_thread, mutex_id);\n+\n+        Ok(0)\n+    }\n+\n+    fn pthread_cond_timedwait(\n+        &mut self,\n+        cond_op: OpTy<'tcx, Tag>,\n+        mutex_op: OpTy<'tcx, Tag>,\n+        abstime_op: OpTy<'tcx, Tag>,\n+        dest: PlaceTy<'tcx, Tag>,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+\n+        this.check_no_isolation(\"pthread_cond_timedwait\")?;\n+\n+        let id = cond_get_or_create_id(this, cond_op)?;\n+        let mutex_id = mutex_get_or_create_id(this, mutex_op)?;\n+        let active_thread = this.get_active_thread()?;\n+\n+        release_cond_mutex(this, active_thread, mutex_id)?;\n+        this.condvar_wait(id, active_thread, mutex_id);\n+\n+        // We return success for now and override it in the timeout callback.\n+        this.write_scalar(Scalar::from_i32(0), dest)?;\n+\n+        // Extract the timeout.\n+        let clock_id = cond_get_clock_id(this, cond_op)?.to_i32()?;\n+        let duration = {\n+            let tp = this.deref_operand(abstime_op)?;\n+            let seconds_place = this.mplace_field(tp, 0)?;\n+            let seconds = this.read_scalar(seconds_place.into())?;\n+            let nanoseconds_place = this.mplace_field(tp, 1)?;\n+            let nanoseconds = this.read_scalar(nanoseconds_place.into())?;\n+            let (seconds, nanoseconds) = (\n+                seconds.to_machine_usize(this)?,\n+                nanoseconds.to_machine_usize(this)?.try_into().unwrap(),\n+            );\n+            Duration::new(seconds, nanoseconds)\n+        };\n+\n+        let timeout_time = if clock_id == this.eval_libc_i32(\"CLOCK_REALTIME\")? {\n+            Time::RealTime(SystemTime::UNIX_EPOCH.checked_add(duration).unwrap())\n+        } else if clock_id == this.eval_libc_i32(\"CLOCK_MONOTONIC\")? {\n+            Time::Monotonic(this.machine.time_anchor.checked_add(duration).unwrap())\n+        } else {\n+            throw_unsup_format!(\"unsupported clock id: {}\", clock_id);\n+        };\n+\n+        // Register the timeout callback.\n+        this.register_timeout_callback(\n+            active_thread,\n+            timeout_time,\n+            Box::new(move |ecx| {\n+                // We are not waiting for the condvar any more, wait for the\n+                // mutex instead.\n+                reacquire_cond_mutex(ecx, active_thread, mutex_id)?;\n+\n+                // Remove the thread from the conditional variable.\n+                ecx.condvar_remove_waiter(id, active_thread);\n+\n+                // Set the return value: we timed out.\n+                let timeout = ecx.eval_libc_i32(\"ETIMEDOUT\")?;\n+                ecx.write_scalar(Scalar::from_i32(timeout), dest)?;\n+\n+                Ok(())\n+            }),\n+        )?;\n+\n+        Ok(())\n+    }\n+\n+    fn pthread_cond_destroy(&mut self, cond_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n+        let this = self.eval_context_mut();\n+\n+        let id = cond_get_or_create_id(this, cond_op)?;\n+        if this.condvar_is_awaited(id) {\n+            throw_ub_format!(\"destroyed an awaited conditional variable\");\n+        }\n+        cond_set_id(this, cond_op, ScalarMaybeUninit::Uninit)?;\n+        cond_set_clock_id(this, cond_op, ScalarMaybeUninit::Uninit)?;\n \n         Ok(0)\n     }"}, {"sha": "026542926ed841f559911e8402057aea95fd62c9", "filename": "src/sync.rs", "status": "added", "additions": 344, "deletions": 0, "changes": 344, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fsync.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -0,0 +1,344 @@\n+use std::collections::{hash_map::Entry, HashMap, VecDeque};\n+use std::convert::TryFrom;\n+use std::num::NonZeroU32;\n+use std::ops::Not;\n+\n+use rustc_index::vec::{Idx, IndexVec};\n+\n+use crate::*;\n+\n+/// We cannot use the `newtype_index!` macro because we have to use 0 as a\n+/// sentinel value meaning that the identifier is not assigned. This is because\n+/// the pthreads static initializers initialize memory with zeros (see the\n+/// `src/shims/sync.rs` file).\n+macro_rules! declare_id {\n+    ($name: ident) => {\n+        /// 0 is used to indicate that the id was not yet assigned and,\n+        /// therefore, is not a valid identifier.\n+        #[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n+        pub struct $name(NonZeroU32);\n+\n+        impl $name {\n+            // Panics if `id == 0`.\n+            pub fn from_u32(id: u32) -> Self {\n+                Self(NonZeroU32::new(id).unwrap())\n+            }\n+        }\n+\n+        impl Idx for $name {\n+            fn new(idx: usize) -> Self {\n+                // We use 0 as a sentinel value (see the comment above) and,\n+                // therefore, need to shift by one when converting from an index\n+                // into a vector.\n+                let shifted_idx = u32::try_from(idx).unwrap().checked_add(1).unwrap();\n+                $name(NonZeroU32::new(shifted_idx).unwrap())\n+            }\n+            fn index(self) -> usize {\n+                // See the comment in `Self::new`.\n+                // (This cannot underflow because self is NonZeroU32.)\n+                usize::try_from(self.0.get() - 1).unwrap()\n+            }\n+        }\n+\n+        impl $name {\n+            pub fn to_u32_scalar<'tcx>(&self) -> Scalar<Tag> {\n+                Scalar::from_u32(self.0.get())\n+            }\n+        }\n+    };\n+}\n+\n+declare_id!(MutexId);\n+\n+/// The mutex state.\n+#[derive(Default, Debug)]\n+struct Mutex {\n+    /// The thread that currently owns the lock.\n+    owner: Option<ThreadId>,\n+    /// How many times the mutex was locked by the owner.\n+    lock_count: usize,\n+    /// The queue of threads waiting for this mutex.\n+    queue: VecDeque<ThreadId>,\n+}\n+\n+declare_id!(RwLockId);\n+\n+/// The read-write lock state.\n+#[derive(Default, Debug)]\n+struct RwLock {\n+    /// The writer thread that currently owns the lock.\n+    writer: Option<ThreadId>,\n+    /// The readers that currently own the lock and how many times they acquired\n+    /// the lock.\n+    readers: HashMap<ThreadId, usize>,\n+    /// The queue of writer threads waiting for this lock.\n+    writer_queue: VecDeque<ThreadId>,\n+    /// The queue of reader threads waiting for this lock.\n+    reader_queue: VecDeque<ThreadId>,\n+}\n+\n+declare_id!(CondvarId);\n+\n+/// A thread waiting on a conditional variable.\n+#[derive(Debug)]\n+struct CondvarWaiter {\n+    /// The thread that is waiting on this variable.\n+    thread: ThreadId,\n+    /// The mutex on which the thread is waiting.\n+    mutex: MutexId,\n+}\n+\n+/// The conditional variable state.\n+#[derive(Default, Debug)]\n+struct Condvar {\n+    waiters: VecDeque<CondvarWaiter>,\n+}\n+\n+/// The state of all synchronization variables.\n+#[derive(Default, Debug)]\n+pub(super) struct SynchronizationState {\n+    mutexes: IndexVec<MutexId, Mutex>,\n+    rwlocks: IndexVec<RwLockId, RwLock>,\n+    condvars: IndexVec<CondvarId, Condvar>,\n+}\n+\n+// Public interface to synchronization primitives. Please note that in most\n+// cases, the function calls are infallible and it is the client's (shim\n+// implementation's) responsibility to detect and deal with erroneous\n+// situations.\n+impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n+pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n+    #[inline]\n+    /// Create state for a new mutex.\n+    fn mutex_create(&mut self) -> MutexId {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.mutexes.push(Default::default())\n+    }\n+\n+    #[inline]\n+    /// Get the id of the thread that currently owns this lock.\n+    fn mutex_get_owner(&mut self, id: MutexId) -> ThreadId {\n+        let this = self.eval_context_ref();\n+        this.machine.threads.sync.mutexes[id].owner.unwrap()\n+    }\n+\n+    #[inline]\n+    /// Check if locked.\n+    fn mutex_is_locked(&mut self, id: MutexId) -> bool {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.mutexes[id].owner.is_some()\n+    }\n+\n+    /// Lock by setting the mutex owner and increasing the lock count.\n+    fn mutex_lock(&mut self, id: MutexId, thread: ThreadId) {\n+        let this = self.eval_context_mut();\n+        let mutex = &mut this.machine.threads.sync.mutexes[id];\n+        if let Some(current_owner) = mutex.owner {\n+            assert_eq!(thread, current_owner, \"mutex already locked by another thread\");\n+            assert!(\n+                mutex.lock_count > 0,\n+                \"invariant violation: lock_count == 0 iff the thread is unlocked\"\n+            );\n+        } else {\n+            mutex.owner = Some(thread);\n+        }\n+        mutex.lock_count = mutex.lock_count.checked_add(1).unwrap();\n+    }\n+\n+    /// Try unlocking by decreasing the lock count and returning the old owner\n+    /// and the old lock count. If the lock count reaches 0, release the lock\n+    /// and potentially give to a new owner. If the lock was not locked, return\n+    /// `None`.\n+    ///\n+    /// Note: It is the caller's responsibility to check that the thread that\n+    /// unlocked the lock actually is the same one, which owned it.\n+    fn mutex_unlock(\n+        &mut self,\n+        id: MutexId,\n+        expected_owner: ThreadId,\n+    ) -> InterpResult<'tcx, Option<usize>> {\n+        let this = self.eval_context_mut();\n+        let mutex = &mut this.machine.threads.sync.mutexes[id];\n+        if let Some(current_owner) = mutex.owner {\n+            // Mutex is locked.\n+            if current_owner != expected_owner {\n+                // Only the owner can unlock the mutex.\n+                return Ok(None);\n+            }\n+            let old_lock_count = mutex.lock_count;\n+            mutex.lock_count = old_lock_count\n+                .checked_sub(1)\n+                .expect(\"invariant violation: lock_count == 0 iff the thread is unlocked\");\n+            if mutex.lock_count == 0 {\n+                mutex.owner = None;\n+                // The mutex is completely unlocked. Try transfering ownership\n+                // to another thread.\n+                if let Some(new_owner) = this.mutex_dequeue(id) {\n+                    this.mutex_lock(id, new_owner);\n+                    this.unblock_thread(new_owner)?;\n+                }\n+            }\n+            Ok(Some(old_lock_count))\n+        } else {\n+            // Mutex is unlocked.\n+            Ok(None)\n+        }\n+    }\n+\n+    #[inline]\n+    /// Put the thread into the queue waiting for the lock.\n+    fn mutex_enqueue(&mut self, id: MutexId, thread: ThreadId) {\n+        let this = self.eval_context_mut();\n+        assert!(this.mutex_is_locked(id), \"queing on unlocked mutex\");\n+        this.machine.threads.sync.mutexes[id].queue.push_back(thread);\n+    }\n+\n+    #[inline]\n+    /// Take a thread out of the queue waiting for the lock.\n+    fn mutex_dequeue(&mut self, id: MutexId) -> Option<ThreadId> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.mutexes[id].queue.pop_front()\n+    }\n+\n+    #[inline]\n+    /// Create state for a new read write lock.\n+    fn rwlock_create(&mut self) -> RwLockId {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.rwlocks.push(Default::default())\n+    }\n+\n+    #[inline]\n+    /// Check if locked.\n+    fn rwlock_is_locked(&mut self, id: RwLockId) -> bool {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.rwlocks[id].writer.is_some()\n+            || this.machine.threads.sync.rwlocks[id].readers.is_empty().not()\n+    }\n+\n+    #[inline]\n+    /// Check if write locked.\n+    fn rwlock_is_write_locked(&mut self, id: RwLockId) -> bool {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.rwlocks[id].writer.is_some()\n+    }\n+\n+    /// Read-lock the lock by adding the `reader` the list of threads that own\n+    /// this lock.\n+    fn rwlock_reader_lock(&mut self, id: RwLockId, reader: ThreadId) {\n+        let this = self.eval_context_mut();\n+        assert!(!this.rwlock_is_write_locked(id), \"the lock is write locked\");\n+        let count = this.machine.threads.sync.rwlocks[id].readers.entry(reader).or_insert(0);\n+        *count = count.checked_add(1).expect(\"the reader counter overflowed\");\n+    }\n+\n+    /// Try read-unlock the lock for `reader`. Returns `true` if succeeded,\n+    /// `false` if this `reader` did not hold the lock.\n+    fn rwlock_reader_unlock(&mut self, id: RwLockId, reader: ThreadId) -> bool {\n+        let this = self.eval_context_mut();\n+        match this.machine.threads.sync.rwlocks[id].readers.entry(reader) {\n+            Entry::Occupied(mut entry) => {\n+                let count = entry.get_mut();\n+                *count -= 1;\n+                if *count == 0 {\n+                    entry.remove();\n+                }\n+                true\n+            }\n+            Entry::Vacant(_) => false,\n+        }\n+    }\n+\n+    #[inline]\n+    /// Put the reader in the queue waiting for the lock and block it.\n+    fn rwlock_enqueue_and_block_reader(\n+        &mut self,\n+        id: RwLockId,\n+        reader: ThreadId,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        assert!(this.rwlock_is_write_locked(id), \"queueing on not write locked lock\");\n+        this.machine.threads.sync.rwlocks[id].reader_queue.push_back(reader);\n+        this.block_thread(reader)\n+    }\n+\n+    #[inline]\n+    /// Take a reader out the queue waiting for the lock.\n+    fn rwlock_dequeue_reader(&mut self, id: RwLockId) -> Option<ThreadId> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.rwlocks[id].reader_queue.pop_front()\n+    }\n+\n+    #[inline]\n+    /// Lock by setting the writer that owns the lock.\n+    fn rwlock_writer_lock(&mut self, id: RwLockId, writer: ThreadId) {\n+        let this = self.eval_context_mut();\n+        assert!(!this.rwlock_is_locked(id), \"the lock is already locked\");\n+        this.machine.threads.sync.rwlocks[id].writer = Some(writer);\n+    }\n+\n+    #[inline]\n+    /// Try to unlock by removing the writer.\n+    fn rwlock_writer_unlock(&mut self, id: RwLockId) -> Option<ThreadId> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.rwlocks[id].writer.take()\n+    }\n+\n+    #[inline]\n+    /// Put the writer in the queue waiting for the lock.\n+    fn rwlock_enqueue_and_block_writer(\n+        &mut self,\n+        id: RwLockId,\n+        writer: ThreadId,\n+    ) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        assert!(this.rwlock_is_locked(id), \"queueing on unlocked lock\");\n+        this.machine.threads.sync.rwlocks[id].writer_queue.push_back(writer);\n+        this.block_thread(writer)\n+    }\n+\n+    #[inline]\n+    /// Take the writer out the queue waiting for the lock.\n+    fn rwlock_dequeue_writer(&mut self, id: RwLockId) -> Option<ThreadId> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.rwlocks[id].writer_queue.pop_front()\n+    }\n+\n+    #[inline]\n+    /// Create state for a new conditional variable.\n+    fn condvar_create(&mut self) -> CondvarId {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.condvars.push(Default::default())\n+    }\n+\n+    #[inline]\n+    /// Is the conditional variable awaited?\n+    fn condvar_is_awaited(&mut self, id: CondvarId) -> bool {\n+        let this = self.eval_context_mut();\n+        !this.machine.threads.sync.condvars[id].waiters.is_empty()\n+    }\n+\n+    /// Mark that the thread is waiting on the conditional variable.\n+    fn condvar_wait(&mut self, id: CondvarId, thread: ThreadId, mutex: MutexId) {\n+        let this = self.eval_context_mut();\n+        let waiters = &mut this.machine.threads.sync.condvars[id].waiters;\n+        assert!(waiters.iter().all(|waiter| waiter.thread != thread), \"thread is already waiting\");\n+        waiters.push_back(CondvarWaiter { thread, mutex });\n+    }\n+\n+    /// Wake up some thread (if there is any) sleeping on the conditional\n+    /// variable.\n+    fn condvar_signal(&mut self, id: CondvarId) -> Option<(ThreadId, MutexId)> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.condvars[id]\n+            .waiters\n+            .pop_front()\n+            .map(|waiter| (waiter.thread, waiter.mutex))\n+    }\n+\n+    #[inline]\n+    /// Remove the thread from the queue of threads waiting on this conditional variable.\n+    fn condvar_remove_waiter(&mut self, id: CondvarId, thread: ThreadId) {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.sync.condvars[id].waiters.retain(|waiter| waiter.thread != thread);\n+    }\n+}"}, {"sha": "59f08eec1649b18d998dc28846640dcb4f02809b", "filename": "src/thread.rs", "status": "modified", "additions": 162, "deletions": 51, "changes": 213, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/src%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fthread.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -1,8 +1,10 @@\n //! Implements threads.\n \n use std::cell::RefCell;\n+use std::collections::hash_map::Entry;\n use std::convert::TryFrom;\n-use std::num::{NonZeroU32, TryFromIntError};\n+use std::num::TryFromIntError;\n+use std::time::{Duration, Instant, SystemTime};\n \n use log::trace;\n \n@@ -15,18 +17,26 @@ use rustc_middle::{\n     ty::{self, Instance},\n };\n \n+use crate::sync::SynchronizationState;\n use crate::*;\n \n #[derive(Clone, Copy, Debug, PartialEq, Eq)]\n pub enum SchedulingAction {\n     /// Execute step on the active thread.\n     ExecuteStep,\n+    /// Execute a timeout callback.\n+    ExecuteTimeoutCallback,\n     /// Execute destructors of the active thread.\n     ExecuteDtors,\n     /// Stop the program.\n     Stop,\n }\n \n+/// Timeout callbacks can be created by synchronization primitives to tell the\n+/// scheduler that they should be called once some period of time passes.\n+type TimeoutCallback<'mir, 'tcx> =\n+    Box<dyn FnOnce(&mut InterpCx<'mir, 'tcx, Evaluator<'mir, 'tcx>>) -> InterpResult<'tcx> + 'tcx>;\n+\n /// A thread identifier.\n #[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n pub struct ThreadId(u32);\n@@ -69,21 +79,6 @@ impl ThreadId {\n     }\n }\n \n-/// An identifier of a set of blocked threads. 0 is used to indicate the absence\n-/// of a blockset identifier and, therefore, is not a valid identifier.\n-#[derive(Clone, Copy, Debug, PartialOrd, Ord, PartialEq, Eq, Hash)]\n-pub struct BlockSetId(NonZeroU32);\n-\n-impl BlockSetId {\n-    /// Panics if `id` is 0.\n-    pub fn new(id: u32) -> Self {\n-        Self(NonZeroU32::new(id).expect(\"0 is not a valid blockset id\"))\n-    }\n-    pub fn to_u32_scalar<'tcx>(&self) -> Scalar<Tag> {\n-        Scalar::from_u32(self.0.get())\n-    }\n-}\n-\n /// The state of a thread.\n #[derive(Debug, Copy, Clone, PartialEq, Eq)]\n pub enum ThreadState {\n@@ -92,8 +87,10 @@ pub enum ThreadState {\n     /// The thread tried to join the specified thread and is blocked until that\n     /// thread terminates.\n     BlockedOnJoin(ThreadId),\n-    /// The thread is blocked and belongs to the given blockset.\n-    Blocked(BlockSetId),\n+    /// The thread is blocked on some synchronization primitive. It is the\n+    /// responsibility of the synchronization primitives to track threads that\n+    /// are blocked by them.\n+    BlockedOnSync,\n     /// The thread has terminated its execution (we do not delete terminated\n     /// threads).\n     Terminated,\n@@ -162,6 +159,41 @@ impl<'mir, 'tcx> Default for Thread<'mir, 'tcx> {\n     }\n }\n \n+/// A specific moment in time.\n+#[derive(Debug)]\n+pub enum Time {\n+    Monotonic(Instant),\n+    RealTime(SystemTime),\n+}\n+\n+impl Time {\n+    /// How long do we have to wait from now until the specified time?\n+    fn get_wait_time(&self) -> Duration {\n+        match self {\n+            Time::Monotonic(instant) => instant.saturating_duration_since(Instant::now()),\n+            Time::RealTime(time) =>\n+                time.duration_since(SystemTime::now()).unwrap_or(Duration::new(0, 0)),\n+        }\n+    }\n+}\n+\n+/// Callbacks are used to implement timeouts. For example, waiting on a\n+/// conditional variable with a timeout creates a callback that is called after\n+/// the specified time and unblocks the thread. If another thread signals on the\n+/// conditional variable, the signal handler deletes the callback.\n+struct TimeoutCallbackInfo<'mir, 'tcx> {\n+    /// The callback should be called no earlier than this time.\n+    call_time: Time,\n+    /// The called function.\n+    callback: TimeoutCallback<'mir, 'tcx>,\n+}\n+\n+impl<'mir, 'tcx> std::fmt::Debug for TimeoutCallbackInfo<'mir, 'tcx> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        write!(f, \"TimeoutCallback({:?})\", self.call_time)\n+    }\n+}\n+\n /// A set of threads.\n #[derive(Debug)]\n pub struct ThreadManager<'mir, 'tcx> {\n@@ -171,13 +203,16 @@ pub struct ThreadManager<'mir, 'tcx> {\n     ///\n     /// Note that this vector also contains terminated threads.\n     threads: IndexVec<ThreadId, Thread<'mir, 'tcx>>,\n-    /// A counter used to generate unique identifiers for blocksets.\n-    blockset_counter: u32,\n+    /// This field is pub(crate) because the synchronization primitives\n+    /// (`crate::sync`) need a way to access it.\n+    pub(crate) sync: SynchronizationState,\n     /// A mapping from a thread-local static to an allocation id of a thread\n     /// specific allocation.\n     thread_local_alloc_ids: RefCell<FxHashMap<(DefId, ThreadId), AllocId>>,\n     /// A flag that indicates that we should change the active thread.\n     yield_active_thread: bool,\n+    /// Callbacks that are called once the specified time passes.\n+    timeout_callbacks: FxHashMap<ThreadId, TimeoutCallbackInfo<'mir, 'tcx>>,\n }\n \n impl<'mir, 'tcx> Default for ThreadManager<'mir, 'tcx> {\n@@ -191,9 +226,10 @@ impl<'mir, 'tcx> Default for ThreadManager<'mir, 'tcx> {\n         Self {\n             active_thread: ThreadId::new(0),\n             threads: threads,\n-            blockset_counter: 0,\n+            sync: SynchronizationState::default(),\n             thread_local_alloc_ids: Default::default(),\n             yield_active_thread: false,\n+            timeout_callbacks: FxHashMap::default(),\n         }\n     }\n }\n@@ -321,37 +357,61 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n         self.active_thread_ref().thread_name()\n     }\n \n-    /// Allocate a new blockset id.\n-    fn create_blockset(&mut self) -> BlockSetId {\n-        self.blockset_counter = self.blockset_counter.checked_add(1).unwrap();\n-        BlockSetId::new(self.blockset_counter)\n-    }\n-\n-    /// Block the currently active thread and put it into the given blockset.\n-    fn block_active_thread(&mut self, set: BlockSetId) {\n-        let state = &mut self.active_thread_mut().state;\n+    /// Put the thread into the blocked state.\n+    fn block_thread(&mut self, thread: ThreadId) {\n+        let state = &mut self.threads[thread].state;\n         assert_eq!(*state, ThreadState::Enabled);\n-        *state = ThreadState::Blocked(set);\n+        *state = ThreadState::BlockedOnSync;\n     }\n \n-    /// Unblock any one thread from the given blockset if it contains at least\n-    /// one. Return the id of the unblocked thread.\n-    fn unblock_some_thread(&mut self, set: BlockSetId) -> Option<ThreadId> {\n-        for (id, thread) in self.threads.iter_enumerated_mut() {\n-            if thread.state == ThreadState::Blocked(set) {\n-                trace!(\"unblocking {:?} in blockset {:?}\", id, set);\n-                thread.state = ThreadState::Enabled;\n-                return Some(id);\n-            }\n-        }\n-        None\n+    /// Put the blocked thread into the enabled state.\n+    fn unblock_thread(&mut self, thread: ThreadId) {\n+        let state = &mut self.threads[thread].state;\n+        assert_eq!(*state, ThreadState::BlockedOnSync);\n+        *state = ThreadState::Enabled;\n     }\n \n     /// Change the active thread to some enabled thread.\n     fn yield_active_thread(&mut self) {\n         self.yield_active_thread = true;\n     }\n \n+    /// Register the given `callback` to be called once the `call_time` passes.\n+    ///\n+    /// The callback will be called with `thread` being the active thread, and\n+    /// the callback may not change the active thread.\n+    fn register_timeout_callback(\n+        &mut self,\n+        thread: ThreadId,\n+        call_time: Time,\n+        callback: TimeoutCallback<'mir, 'tcx>,\n+    ) {\n+        self.timeout_callbacks\n+            .insert(thread, TimeoutCallbackInfo { call_time, callback })\n+            .unwrap_none();\n+    }\n+\n+    /// Unregister the callback for the `thread`.\n+    fn unregister_timeout_callback_if_exists(&mut self, thread: ThreadId) {\n+        self.timeout_callbacks.remove(&thread);\n+    }\n+\n+    /// Get a callback that is ready to be called.\n+    fn get_ready_callback(&mut self) -> Option<(ThreadId, TimeoutCallback<'mir, 'tcx>)> {\n+        // We iterate over all threads in the order of their indices because\n+        // this allows us to have a deterministic scheduler.\n+        for thread in self.threads.indices() {\n+            match self.timeout_callbacks.entry(thread) {\n+                Entry::Occupied(entry) =>\n+                    if entry.get().call_time.get_wait_time() == Duration::new(0, 0) {\n+                        return Some((thread, entry.remove().callback));\n+                    },\n+                Entry::Vacant(_) => {}\n+            }\n+        }\n+        None\n+    }\n+\n     /// Decide which action to take next and on which thread.\n     ///\n     /// The currently implemented scheduling policy is the one that is commonly\n@@ -385,6 +445,20 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n             }\n             return Ok(SchedulingAction::Stop);\n         }\n+        // At least for `pthread_cond_timedwait` we need to report timeout when\n+        // the function is called already after the specified time even if a\n+        // signal is received before the thread gets scheduled. Therefore, we\n+        // need to schedule all timeout callbacks before we continue regular\n+        // execution.\n+        //\n+        // Documentation:\n+        // https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_cond_timedwait.html#\n+        let potential_sleep_time =\n+            self.timeout_callbacks.values().map(|info| info.call_time.get_wait_time()).min();\n+        if potential_sleep_time == Some(Duration::new(0, 0)) {\n+            return Ok(SchedulingAction::ExecuteTimeoutCallback);\n+        }\n+        // No callbacks scheduled, pick a regular thread to execute.\n         if self.threads[self.active_thread].state == ThreadState::Enabled\n             && !self.yield_active_thread\n         {\n@@ -406,7 +480,13 @@ impl<'mir, 'tcx: 'mir> ThreadManager<'mir, 'tcx> {\n         }\n         // We have not found a thread to execute.\n         if self.threads.iter().all(|thread| thread.state == ThreadState::Terminated) {\n-            unreachable!();\n+            unreachable!(\"all threads terminated without the main thread terminating?!\");\n+        } else if let Some(sleep_time) = potential_sleep_time {\n+            // All threads are currently blocked, but we have unexecuted\n+            // timeout_callbacks, which may unblock some of the threads. Hence,\n+            // sleep until the first callback.\n+            std::thread::sleep(sleep_time);\n+            Ok(SchedulingAction::ExecuteTimeoutCallback)\n         } else {\n             throw_machine_stop!(TerminationInfo::Deadlock);\n         }\n@@ -577,27 +657,58 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n     }\n \n     #[inline]\n-    fn create_blockset(&mut self) -> InterpResult<'tcx, BlockSetId> {\n+    fn block_thread(&mut self, thread: ThreadId) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n-        Ok(this.machine.threads.create_blockset())\n+        Ok(this.machine.threads.block_thread(thread))\n     }\n \n     #[inline]\n-    fn block_active_thread(&mut self, set: BlockSetId) -> InterpResult<'tcx> {\n+    fn unblock_thread(&mut self, thread: ThreadId) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n-        Ok(this.machine.threads.block_active_thread(set))\n+        Ok(this.machine.threads.unblock_thread(thread))\n     }\n \n     #[inline]\n-    fn unblock_some_thread(&mut self, set: BlockSetId) -> InterpResult<'tcx, Option<ThreadId>> {\n+    fn yield_active_thread(&mut self) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n-        Ok(this.machine.threads.unblock_some_thread(set))\n+        this.machine.threads.yield_active_thread();\n+        Ok(())\n     }\n \n     #[inline]\n-    fn yield_active_thread(&mut self) -> InterpResult<'tcx> {\n+    fn register_timeout_callback(\n+        &mut self,\n+        thread: ThreadId,\n+        call_time: Time,\n+        callback: TimeoutCallback<'mir, 'tcx>,\n+    ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n-        this.machine.threads.yield_active_thread();\n+        this.machine.threads.register_timeout_callback(thread, call_time, callback);\n+        Ok(())\n+    }\n+\n+    #[inline]\n+    fn unregister_timeout_callback_if_exists(&mut self, thread: ThreadId) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        this.machine.threads.unregister_timeout_callback_if_exists(thread);\n+        Ok(())\n+    }\n+\n+    /// Execute a timeout callback on the callback's thread.\n+    #[inline]\n+    fn run_timeout_callback(&mut self) -> InterpResult<'tcx> {\n+        let this = self.eval_context_mut();\n+        let (thread, callback) =\n+            this.machine.threads.get_ready_callback().expect(\"no callback found\");\n+        // This back-and-forth with `set_active_thread` is here because of two\n+        // design decisions:\n+        // 1. Make the caller and not the callback responsible for changing\n+        //    thread.\n+        // 2. Make the scheduler the only place that can change the active\n+        //    thread.\n+        let old_thread = this.set_active_thread(thread)?;\n+        callback(this)?;\n+        this.set_active_thread(old_thread)?;\n         Ok(())\n     }\n "}, {"sha": "3a737b2e3e155786f60a891da2cc6a1089383508", "filename": "tests/compile-fail/sync/libc_pthread_mutex_NULL_deadlock.rs", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_NULL_deadlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_NULL_deadlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_NULL_deadlock.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -0,0 +1,16 @@\n+// ignore-windows: No libc on Windows\n+//\n+// Check that if we pass NULL attribute, then we get the default mutex type.\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+fn main() {\n+    unsafe {\n+        let mut mutex: libc::pthread_mutex_t = std::mem::zeroed();\n+        assert_eq!(libc::pthread_mutex_init(&mut mutex as *mut _, std::ptr::null() as *const _), 0);\n+        assert_eq!(libc::pthread_mutex_lock(&mut mutex as *mut _), 0);\n+        libc::pthread_mutex_lock(&mut mutex as *mut _); //~ ERROR Undefined Behavior: trying to acquire already locked default mutex\n+    }\n+}"}, {"sha": "0f6f570d70b0241520c9f9d4d5fbfb290a68b3bc", "filename": "tests/compile-fail/sync/libc_pthread_mutex_default_deadlock.rs", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_default_deadlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_default_deadlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_default_deadlock.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -0,0 +1,17 @@\n+// ignore-windows: No libc on Windows\n+//\n+// Check that if we do not set the mutex type, it is the default.\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+fn main() {\n+    unsafe {\n+        let mutexattr: libc::pthread_mutexattr_t = std::mem::zeroed();\n+        let mut mutex: libc::pthread_mutex_t = std::mem::zeroed();\n+        assert_eq!(libc::pthread_mutex_init(&mut mutex as *mut _, &mutexattr as *const _), 0);\n+        assert_eq!(libc::pthread_mutex_lock(&mut mutex as *mut _), 0);\n+        libc::pthread_mutex_lock(&mut mutex as *mut _); //~ ERROR Undefined Behavior: trying to acquire already locked default mutex\n+    }\n+}"}, {"sha": "96e0ff3bfff7211f2ca4f5922cf6fad81463a980", "filename": "tests/compile-fail/sync/libc_pthread_mutex_normal_deadlock.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_normal_deadlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_normal_deadlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_normal_deadlock.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -11,6 +11,6 @@ fn main() {\n         let mut mutex: libc::pthread_mutex_t = std::mem::zeroed();\n         assert_eq!(libc::pthread_mutex_init(&mut mutex as *mut _, &mutexattr as *const _), 0);\n         assert_eq!(libc::pthread_mutex_lock(&mut mutex as *mut _), 0);\n-        libc::pthread_mutex_lock(&mut mutex as *mut _); //~ ERROR deadlock\n+        libc::pthread_mutex_lock(&mut mutex as *mut _); //~ ERROR deadlock: the evaluated program deadlocked\n     }\n }"}, {"sha": "d69929d4ed465a7d3ca28ad7d863a9775d152588", "filename": "tests/compile-fail/sync/libc_pthread_mutex_wrong_owner.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_wrong_owner.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_wrong_owner.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_mutex_wrong_owner.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -24,7 +24,7 @@ fn main() {\n \n         let lock_copy = lock.clone();\n         thread::spawn(move || {\n-            assert_eq!(libc::pthread_mutex_unlock(lock_copy.0.get() as *mut _), 0); //~ ERROR: Undefined Behavior: called pthread_mutex_unlock on a mutex owned by another thread\n+            assert_eq!(libc::pthread_mutex_unlock(lock_copy.0.get() as *mut _), 0); //~ ERROR: Undefined Behavior: unlocked a default mutex that was not locked by the current thread\n         })\n         .join()\n         .unwrap();"}, {"sha": "a73a8496a3296c5b6ce1a70fe2775ff2eba31dcc", "filename": "tests/compile-fail/sync/libc_pthread_rwlock_read_wrong_owner.rs", "status": "added", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_read_wrong_owner.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_read_wrong_owner.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_read_wrong_owner.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -0,0 +1,32 @@\n+// ignore-windows: No libc on Windows\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::cell::UnsafeCell;\n+use std::sync::Arc;\n+use std::thread;\n+\n+struct RwLock(UnsafeCell<libc::pthread_rwlock_t>);\n+\n+unsafe impl Send for RwLock {}\n+unsafe impl Sync for RwLock {}\n+\n+fn new_lock() -> Arc<RwLock> {\n+    Arc::new(RwLock(UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER)))\n+}\n+\n+fn main() {\n+    unsafe {\n+        let lock = new_lock();\n+        assert_eq!(libc::pthread_rwlock_rdlock(lock.0.get() as *mut _), 0);\n+\n+        let lock_copy = lock.clone();\n+        thread::spawn(move || {\n+            assert_eq!(libc::pthread_rwlock_unlock(lock_copy.0.get() as *mut _), 0); //~ ERROR: Undefined Behavior: unlocked an rwlock that was not locked by the active thread\n+        })\n+        .join()\n+        .unwrap();\n+    }\n+}"}, {"sha": "663dedb6f6fca643f6b2a4c6bc83bc765e2df0f5", "filename": "tests/compile-fail/sync/libc_pthread_rwlock_write_wrong_owner.rs", "status": "added", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_wrong_owner.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_wrong_owner.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fsync%2Flibc_pthread_rwlock_write_wrong_owner.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -0,0 +1,32 @@\n+// ignore-windows: No libc on Windows\n+\n+#![feature(rustc_private)]\n+\n+extern crate libc;\n+\n+use std::cell::UnsafeCell;\n+use std::sync::Arc;\n+use std::thread;\n+\n+struct RwLock(UnsafeCell<libc::pthread_rwlock_t>);\n+\n+unsafe impl Send for RwLock {}\n+unsafe impl Sync for RwLock {}\n+\n+fn new_lock() -> Arc<RwLock> {\n+    Arc::new(RwLock(UnsafeCell::new(libc::PTHREAD_RWLOCK_INITIALIZER)))\n+}\n+\n+fn main() {\n+    unsafe {\n+        let lock = new_lock();\n+        assert_eq!(libc::pthread_rwlock_wrlock(lock.0.get() as *mut _), 0);\n+\n+        let lock_copy = lock.clone();\n+        thread::spawn(move || {\n+            assert_eq!(libc::pthread_rwlock_unlock(lock_copy.0.get() as *mut _), 0); //~ ERROR: Undefined Behavior: unlocked an rwlock that was not locked by the active thread\n+        })\n+        .join()\n+        .unwrap();\n+    }\n+}"}, {"sha": "27f5ead450fab10f3cdbd029f3a90cfe557ee481", "filename": "tests/run-pass/concurrency/libc_pthread_cond.rs", "status": "added", "additions": 47, "deletions": 0, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Frun-pass%2Fconcurrency%2Flibc_pthread_cond.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Frun-pass%2Fconcurrency%2Flibc_pthread_cond.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Flibc_pthread_cond.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -0,0 +1,47 @@\n+// ignore-windows: No libc on Windows\n+// ignore-macos: pthread_condattr_setclock is not supported on MacOS.\n+// compile-flags: -Zmiri-disable-isolation\n+\n+#![feature(rustc_private)]\n+\n+/// Test that conditional variable timeouts are working properly with both\n+/// monotonic and system clocks.\n+extern crate libc;\n+\n+use std::mem;\n+use std::time::Instant;\n+\n+fn test_timed_wait_timeout(clock_id: i32) {\n+    unsafe {\n+        let mut attr: libc::pthread_condattr_t = mem::zeroed();\n+        assert_eq!(libc::pthread_condattr_init(&mut attr as *mut _), 0);\n+        assert_eq!(libc::pthread_condattr_setclock(&mut attr as *mut _, clock_id), 0);\n+\n+        let mut cond: libc::pthread_cond_t = mem::zeroed();\n+        assert_eq!(libc::pthread_cond_init(&mut cond as *mut _, &attr as *const _), 0);\n+        assert_eq!(libc::pthread_condattr_destroy(&mut attr as *mut _), 0);\n+\n+        let mut mutex: libc::pthread_mutex_t = mem::zeroed();\n+\n+        let mut now: libc::timespec = mem::zeroed();\n+        assert_eq!(libc::clock_gettime(clock_id, &mut now), 0);\n+        let timeout = libc::timespec { tv_sec: now.tv_sec + 1, tv_nsec: now.tv_nsec };\n+\n+        assert_eq!(libc::pthread_mutex_lock(&mut mutex as *mut _), 0);\n+        let current_time = Instant::now();\n+        assert_eq!(\n+            libc::pthread_cond_timedwait(&mut cond as *mut _, &mut mutex as *mut _, &timeout),\n+            libc::ETIMEDOUT\n+        );\n+        let elapsed_time = current_time.elapsed().as_millis();\n+        assert!(900 <= elapsed_time && elapsed_time <= 1300);\n+        assert_eq!(libc::pthread_mutex_unlock(&mut mutex as *mut _), 0);\n+        assert_eq!(libc::pthread_mutex_destroy(&mut mutex as *mut _), 0);\n+        assert_eq!(libc::pthread_cond_destroy(&mut cond as *mut _), 0);\n+    }\n+}\n+\n+fn main() {\n+    test_timed_wait_timeout(libc::CLOCK_MONOTONIC);\n+    test_timed_wait_timeout(libc::CLOCK_REALTIME);\n+}"}, {"sha": "f5469712c5f55fe318b1ff1e6294b801f1d08e5d", "filename": "tests/run-pass/concurrency/locks.rs", "status": "removed", "additions": 0, "deletions": 75, "changes": 75, "blob_url": "https://github.com/rust-lang/rust/blob/726373fcaa8a94c1dea242992a19bb7d58f94df4/tests%2Frun-pass%2Fconcurrency%2Flocks.rs", "raw_url": "https://github.com/rust-lang/rust/raw/726373fcaa8a94c1dea242992a19bb7d58f94df4/tests%2Frun-pass%2Fconcurrency%2Flocks.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Flocks.rs?ref=726373fcaa8a94c1dea242992a19bb7d58f94df4", "patch": "@@ -1,75 +0,0 @@\n-// ignore-windows: Concurrency on Windows is not supported yet.\n-\n-use std::sync::{Arc, Mutex, RwLock};\n-use std::thread;\n-\n-fn check_mutex() {\n-    let data = Arc::new(Mutex::new(0));\n-    let mut threads = Vec::new();\n-\n-    for _ in 0..3 {\n-        let data = Arc::clone(&data);\n-        let thread = thread::spawn(move || {\n-            let mut data = data.lock().unwrap();\n-            thread::yield_now();\n-            *data += 1;\n-        });\n-        threads.push(thread);\n-    }\n-\n-    for thread in threads {\n-        thread.join().unwrap();\n-    }\n-\n-    assert!(data.try_lock().is_ok());\n-\n-    let data = Arc::try_unwrap(data).unwrap().into_inner().unwrap();\n-    assert_eq!(data, 3);\n-}\n-\n-fn check_rwlock_write() {\n-    let data = Arc::new(RwLock::new(0));\n-    let mut threads = Vec::new();\n-\n-    for _ in 0..3 {\n-        let data = Arc::clone(&data);\n-        let thread = thread::spawn(move || {\n-            let mut data = data.write().unwrap();\n-            thread::yield_now();\n-            *data += 1;\n-        });\n-        threads.push(thread);\n-    }\n-\n-    for thread in threads {\n-        thread.join().unwrap();\n-    }\n-\n-    assert!(data.try_write().is_ok());\n-\n-    let data = Arc::try_unwrap(data).unwrap().into_inner().unwrap();\n-    assert_eq!(data, 3);\n-}\n-\n-fn check_rwlock_read_no_deadlock() {\n-    let l1 = Arc::new(RwLock::new(0));\n-    let l2 = Arc::new(RwLock::new(0));\n-\n-    let l1_copy = Arc::clone(&l1);\n-    let l2_copy = Arc::clone(&l2);\n-    let _guard1 = l1.read().unwrap();\n-    let handle = thread::spawn(move || {\n-        let _guard2 = l2_copy.read().unwrap();\n-        thread::yield_now();\n-        let _guard1 = l1_copy.read().unwrap();\n-    });\n-    thread::yield_now();\n-    let _guard2 = l2.read().unwrap();\n-    handle.join().unwrap();\n-}\n-\n-fn main() {\n-    check_mutex();\n-    check_rwlock_write();\n-    check_rwlock_read_no_deadlock();\n-}"}, {"sha": "2009c01ce9f952e33ec6c41d2cf70b89c944bffe", "filename": "tests/run-pass/concurrency/sync.rs", "status": "added", "additions": 283, "deletions": 0, "changes": 283, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Frun-pass%2Fconcurrency%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Frun-pass%2Fconcurrency%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Fsync.rs?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -0,0 +1,283 @@\n+// ignore-windows: Concurrency on Windows is not supported yet.\n+// compile-flags: -Zmiri-disable-isolation\n+\n+use std::sync::mpsc::{channel, sync_channel};\n+use std::sync::{Arc, Barrier, Condvar, Mutex, Once, RwLock};\n+use std::thread;\n+use std::time::{Duration, Instant};\n+\n+// Check if Rust barriers are working.\n+\n+/// This test is taken from the Rust documentation.\n+fn check_barriers() {\n+    let mut handles = Vec::with_capacity(10);\n+    let barrier = Arc::new(Barrier::new(10));\n+    for _ in 0..10 {\n+        let c = barrier.clone();\n+        // The same messages will be printed together.\n+        // You will NOT see any interleaving.\n+        handles.push(thread::spawn(move || {\n+            println!(\"before wait\");\n+            c.wait();\n+            println!(\"after wait\");\n+        }));\n+    }\n+    // Wait for other threads to finish.\n+    for handle in handles {\n+        handle.join().unwrap();\n+    }\n+}\n+\n+// Check if Rust conditional variables are working.\n+\n+/// The test taken from the Rust documentation.\n+fn check_conditional_variables_notify_one() {\n+    let pair = Arc::new((Mutex::new(false), Condvar::new()));\n+    let pair2 = pair.clone();\n+\n+    // Spawn a new thread.\n+    thread::spawn(move || {\n+        thread::yield_now();\n+        let (lock, cvar) = &*pair2;\n+        let mut started = lock.lock().unwrap();\n+        *started = true;\n+        // We notify the condvar that the value has changed.\n+        cvar.notify_one();\n+    });\n+\n+    // Wait for the thread to fully start up.\n+    let (lock, cvar) = &*pair;\n+    let mut started = lock.lock().unwrap();\n+    while !*started {\n+        started = cvar.wait(started).unwrap();\n+    }\n+}\n+\n+fn check_conditional_variables_notify_all() {\n+    let pair = Arc::new(((Mutex::new(())), Condvar::new()));\n+\n+    // Spawn threads and block them on the conditional variable.\n+    let handles: Vec<_> = (0..5)\n+        .map(|_| {\n+            let pair2 = pair.clone();\n+            thread::spawn(move || {\n+                let (lock, cvar) = &*pair2;\n+                let guard = lock.lock().unwrap();\n+                // Block waiting on the conditional variable.\n+                let _ = cvar.wait(guard).unwrap();\n+            })\n+        })\n+        .inspect(|_| {\n+            thread::yield_now();\n+            thread::yield_now();\n+        })\n+        .collect();\n+\n+    let (_, cvar) = &*pair;\n+    // Unblock all threads.\n+    cvar.notify_all();\n+\n+    for handle in handles {\n+        handle.join().unwrap();\n+    }\n+}\n+\n+/// Test that waiting on a conditional variable with a timeout does not\n+/// deadlock.\n+fn check_conditional_variables_timed_wait_timeout() {\n+    let lock = Mutex::new(());\n+    let cvar = Condvar::new();\n+    let guard = lock.lock().unwrap();\n+    let now = Instant::now();\n+    let (_guard, timeout) = cvar.wait_timeout(guard, Duration::from_millis(100)).unwrap();\n+    assert!(timeout.timed_out());\n+    let elapsed_time = now.elapsed().as_millis();\n+    assert!(100 <= elapsed_time && elapsed_time <= 300);\n+}\n+\n+/// Test that signaling a conditional variable when waiting with a timeout works\n+/// as expected.\n+fn check_conditional_variables_timed_wait_notimeout() {\n+    let pair = Arc::new((Mutex::new(()), Condvar::new()));\n+    let pair2 = pair.clone();\n+\n+    let (lock, cvar) = &*pair;\n+    let guard = lock.lock().unwrap();\n+\n+    let handle = thread::spawn(move || {\n+        let (_lock, cvar) = &*pair2;\n+        cvar.notify_one();\n+    });\n+\n+    let (_guard, timeout) = cvar.wait_timeout(guard, Duration::from_millis(100)).unwrap();\n+    assert!(!timeout.timed_out());\n+    handle.join().unwrap();\n+}\n+\n+// Check if locks are working.\n+\n+fn check_mutex() {\n+    let data = Arc::new(Mutex::new(0));\n+    let mut threads = Vec::new();\n+\n+    for _ in 0..3 {\n+        let data = Arc::clone(&data);\n+        let thread = thread::spawn(move || {\n+            let mut data = data.lock().unwrap();\n+            thread::yield_now();\n+            *data += 1;\n+        });\n+        threads.push(thread);\n+    }\n+\n+    for thread in threads {\n+        thread.join().unwrap();\n+    }\n+\n+    assert!(data.try_lock().is_ok());\n+\n+    let data = Arc::try_unwrap(data).unwrap().into_inner().unwrap();\n+    assert_eq!(data, 3);\n+}\n+\n+fn check_rwlock_write() {\n+    let data = Arc::new(RwLock::new(0));\n+    let mut threads = Vec::new();\n+\n+    for _ in 0..3 {\n+        let data = Arc::clone(&data);\n+        let thread = thread::spawn(move || {\n+            let mut data = data.write().unwrap();\n+            thread::yield_now();\n+            *data += 1;\n+        });\n+        threads.push(thread);\n+    }\n+\n+    for thread in threads {\n+        thread.join().unwrap();\n+    }\n+\n+    assert!(data.try_write().is_ok());\n+\n+    let data = Arc::try_unwrap(data).unwrap().into_inner().unwrap();\n+    assert_eq!(data, 3);\n+}\n+\n+fn check_rwlock_read_no_deadlock() {\n+    let l1 = Arc::new(RwLock::new(0));\n+    let l2 = Arc::new(RwLock::new(0));\n+\n+    let l1_copy = Arc::clone(&l1);\n+    let l2_copy = Arc::clone(&l2);\n+    let _guard1 = l1.read().unwrap();\n+    let handle = thread::spawn(move || {\n+        let _guard2 = l2_copy.read().unwrap();\n+        thread::yield_now();\n+        let _guard1 = l1_copy.read().unwrap();\n+    });\n+    thread::yield_now();\n+    let _guard2 = l2.read().unwrap();\n+    handle.join().unwrap();\n+}\n+\n+// Check if channels are working.\n+\n+/// The test taken from the Rust documentation.\n+fn simple_send() {\n+    let (tx, rx) = channel();\n+    thread::spawn(move || {\n+        tx.send(10).unwrap();\n+    });\n+    assert_eq!(rx.recv().unwrap(), 10);\n+}\n+\n+/// The test taken from the Rust documentation.\n+fn multiple_send() {\n+    let (tx, rx) = channel();\n+    for i in 0..10 {\n+        let tx = tx.clone();\n+        thread::spawn(move || {\n+            tx.send(i).unwrap();\n+        });\n+    }\n+\n+    let mut sum = 0;\n+    for _ in 0..10 {\n+        let j = rx.recv().unwrap();\n+        assert!(0 <= j && j < 10);\n+        sum += j;\n+    }\n+    assert_eq!(sum, 45);\n+}\n+\n+/// The test taken from the Rust documentation.\n+fn send_on_sync() {\n+    let (sender, receiver) = sync_channel(1);\n+\n+    // this returns immediately\n+    sender.send(1).unwrap();\n+\n+    thread::spawn(move || {\n+        // this will block until the previous message has been received\n+        sender.send(2).unwrap();\n+    });\n+\n+    assert_eq!(receiver.recv().unwrap(), 1);\n+    assert_eq!(receiver.recv().unwrap(), 2);\n+}\n+\n+// Check if Rust once statics are working.\n+\n+static mut VAL: usize = 0;\n+static INIT: Once = Once::new();\n+\n+fn get_cached_val() -> usize {\n+    unsafe {\n+        INIT.call_once(|| {\n+            VAL = expensive_computation();\n+        });\n+        VAL\n+    }\n+}\n+\n+fn expensive_computation() -> usize {\n+    let mut i = 1;\n+    let mut c = 1;\n+    while i < 1000 {\n+        i *= c;\n+        c += 1;\n+    }\n+    i\n+}\n+\n+/// The test taken from the Rust documentation.\n+fn check_once() {\n+    let handles: Vec<_> = (0..10)\n+        .map(|_| {\n+            thread::spawn(|| {\n+                thread::yield_now();\n+                let val = get_cached_val();\n+                assert_eq!(val, 5040);\n+            })\n+        })\n+        .collect();\n+    for handle in handles {\n+        handle.join().unwrap();\n+    }\n+}\n+\n+fn main() {\n+    check_barriers();\n+    check_conditional_variables_notify_one();\n+    check_conditional_variables_notify_all();\n+    check_conditional_variables_timed_wait_timeout();\n+    check_conditional_variables_timed_wait_notimeout();\n+    check_mutex();\n+    check_rwlock_write();\n+    check_rwlock_read_no_deadlock();\n+    simple_send();\n+    multiple_send();\n+    send_on_sync();\n+    check_once();\n+}"}, {"sha": "2dbfb7721d3683fb4d82c2ce771e3784be86fdc9", "filename": "tests/run-pass/concurrency/sync.stderr", "status": "renamed", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Frun-pass%2Fconcurrency%2Fsync.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Frun-pass%2Fconcurrency%2Fsync.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Fsync.stderr?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "previous_filename": "tests/run-pass/concurrency/locks.stderr"}, {"sha": "f2c036a1735eda7186df3a4b5249b8fc8abe5896", "filename": "tests/run-pass/concurrency/sync.stdout", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Frun-pass%2Fconcurrency%2Fsync.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/bfe030dea4e777c6861e0e9e3704fc0b952576ad/tests%2Frun-pass%2Fconcurrency%2Fsync.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fconcurrency%2Fsync.stdout?ref=bfe030dea4e777c6861e0e9e3704fc0b952576ad", "patch": "@@ -0,0 +1,20 @@\n+before wait\n+before wait\n+before wait\n+before wait\n+before wait\n+before wait\n+before wait\n+before wait\n+before wait\n+before wait\n+after wait\n+after wait\n+after wait\n+after wait\n+after wait\n+after wait\n+after wait\n+after wait\n+after wait\n+after wait"}]}