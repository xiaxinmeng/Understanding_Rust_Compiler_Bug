{"sha": "49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQ5ZDJmZDE3MjU1MTBmZDNiZjZmMjkzN2UxNzhiMWFhMDU1ZGRiMDI=", "commit": {"author": {"name": "Alexander Regueiro", "email": "alexreg@me.com", "date": "2019-09-06T02:56:45Z"}, "committer": {"name": "Alexander Regueiro", "email": "alexreg@me.com", "date": "2019-09-07T15:29:04Z"}, "message": "Aggregation of cosmetic changes made during work on REPL PRs: libsyntax", "tree": {"sha": "a04455dea49b29d2c981573bd920116f0418024b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a04455dea49b29d2c981573bd920116f0418024b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "html_url": "https://github.com/rust-lang/rust/commit/49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/comments", "author": {"login": "alexreg", "id": 67036, "node_id": "MDQ6VXNlcjY3MDM2", "avatar_url": "https://avatars.githubusercontent.com/u/67036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexreg", "html_url": "https://github.com/alexreg", "followers_url": "https://api.github.com/users/alexreg/followers", "following_url": "https://api.github.com/users/alexreg/following{/other_user}", "gists_url": "https://api.github.com/users/alexreg/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexreg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexreg/subscriptions", "organizations_url": "https://api.github.com/users/alexreg/orgs", "repos_url": "https://api.github.com/users/alexreg/repos", "events_url": "https://api.github.com/users/alexreg/events{/privacy}", "received_events_url": "https://api.github.com/users/alexreg/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexreg", "id": 67036, "node_id": "MDQ6VXNlcjY3MDM2", "avatar_url": "https://avatars.githubusercontent.com/u/67036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexreg", "html_url": "https://github.com/alexreg", "followers_url": "https://api.github.com/users/alexreg/followers", "following_url": "https://api.github.com/users/alexreg/following{/other_user}", "gists_url": "https://api.github.com/users/alexreg/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexreg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexreg/subscriptions", "organizations_url": "https://api.github.com/users/alexreg/orgs", "repos_url": "https://api.github.com/users/alexreg/repos", "events_url": "https://api.github.com/users/alexreg/events{/privacy}", "received_events_url": "https://api.github.com/users/alexreg/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ef54f57c5b9d894a38179d09b00610c1b337b086", "url": "https://api.github.com/repos/rust-lang/rust/commits/ef54f57c5b9d894a38179d09b00610c1b337b086", "html_url": "https://github.com/rust-lang/rust/commit/ef54f57c5b9d894a38179d09b00610c1b337b086"}], "stats": {"total": 1062, "additions": 538, "deletions": 524}, "files": [{"sha": "bfb2db959636390e21257d2dee2b98a65ae0fb12", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 26, "deletions": 26, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -413,11 +413,11 @@ impl WherePredicate {\n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub struct WhereBoundPredicate {\n     pub span: Span,\n-    /// Any generics from a `for` binding\n+    /// Any generics from a `for` binding.\n     pub bound_generic_params: Vec<GenericParam>,\n-    /// The type being bounded\n+    /// The type being bounded.\n     pub bounded_ty: P<Ty>,\n-    /// Trait and lifetime bounds (`Clone+Send+'static`)\n+    /// Trait and lifetime bounds (`Clone + Send + 'static`).\n     pub bounds: GenericBounds,\n }\n \n@@ -495,15 +495,15 @@ pub enum MetaItemKind {\n     NameValue(Lit),\n }\n \n-/// A Block (`{ .. }`).\n+/// A block (`{ .. }`).\n ///\n /// E.g., `{ .. }` as in `fn foo() { .. }`.\n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub struct Block {\n-    /// Statements in a block\n+    /// The statements in the block.\n     pub stmts: Vec<Stmt>,\n     pub id: NodeId,\n-    /// Distinguishes between `unsafe { ... }` and `{ ... }`\n+    /// Distinguishes between `unsafe { ... }` and `{ ... }`.\n     pub rules: BlockCheckMode,\n     pub span: Span,\n }\n@@ -908,11 +908,11 @@ pub enum MacStmtStyle {\n /// Local represents a `let` statement, e.g., `let <pat>:<ty> = <expr>;`.\n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub struct Local {\n+    pub id: NodeId,\n     pub pat: P<Pat>,\n     pub ty: Option<P<Ty>>,\n     /// Initializer expression to set the value, if any.\n     pub init: Option<P<Expr>>,\n-    pub id: NodeId,\n     pub span: Span,\n     pub attrs: ThinVec<Attribute>,\n }\n@@ -970,7 +970,7 @@ pub struct AnonConst {\n     pub value: P<Expr>,\n }\n \n-/// An expression\n+/// An expression.\n #[derive(Clone, RustcEncodable, RustcDecodable)]\n pub struct Expr {\n     pub id: NodeId,\n@@ -984,26 +984,26 @@ pub struct Expr {\n static_assert_size!(Expr, 96);\n \n impl Expr {\n-    /// Whether this expression would be valid somewhere that expects a value; for example, an `if`\n-    /// condition.\n+    /// Returns `true` if this expression would be valid somewhere that expects a value;\n+    /// for example, an `if` condition.\n     pub fn returns(&self) -> bool {\n         if let ExprKind::Block(ref block, _) = self.node {\n             match block.stmts.last().map(|last_stmt| &last_stmt.node) {\n-                // implicit return\n+                // Implicit return\n                 Some(&StmtKind::Expr(_)) => true,\n                 Some(&StmtKind::Semi(ref expr)) => {\n                     if let ExprKind::Ret(_) = expr.node {\n-                        // last statement is explicit return\n+                        // Last statement is explicit return.\n                         true\n                     } else {\n                         false\n                     }\n                 }\n-                // This is a block that doesn't end in either an implicit or explicit return\n+                // This is a block that doesn't end in either an implicit or explicit return.\n                 _ => false,\n             }\n         } else {\n-            // This is not a block, it is a value\n+            // This is not a block, it is a value.\n             true\n         }\n     }\n@@ -2307,57 +2307,57 @@ impl Default for FnHeader {\n \n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub enum ItemKind {\n-    /// An `extern crate` item, with optional *original* crate name if the crate was renamed.\n+    /// An `extern crate` item, with the optional *original* crate name if the crate was renamed.\n     ///\n     /// E.g., `extern crate foo` or `extern crate foo_bar as foo`.\n     ExternCrate(Option<Name>),\n-    /// A use declaration (`use` or `pub use`) item.\n+    /// A use declaration item (`use`).\n     ///\n     /// E.g., `use foo;`, `use foo::bar;` or `use foo::bar as FooBar;`.\n     Use(P<UseTree>),\n-    /// A static item (`static` or `pub static`).\n+    /// A static item (`static`).\n     ///\n     /// E.g., `static FOO: i32 = 42;` or `static FOO: &'static str = \"bar\";`.\n     Static(P<Ty>, Mutability, P<Expr>),\n-    /// A constant item (`const` or `pub const`).\n+    /// A constant item (`const`).\n     ///\n     /// E.g., `const FOO: i32 = 42;`.\n     Const(P<Ty>, P<Expr>),\n-    /// A function declaration (`fn` or `pub fn`).\n+    /// A function declaration (`fn`).\n     ///\n     /// E.g., `fn foo(bar: usize) -> usize { .. }`.\n     Fn(P<FnDecl>, FnHeader, Generics, P<Block>),\n-    /// A module declaration (`mod` or `pub mod`).\n+    /// A module declaration (`mod`).\n     ///\n     /// E.g., `mod foo;` or `mod foo { .. }`.\n     Mod(Mod),\n-    /// An external module (`extern` or `pub extern`).\n+    /// An external module (`extern`).\n     ///\n     /// E.g., `extern {}` or `extern \"C\" {}`.\n     ForeignMod(ForeignMod),\n     /// Module-level inline assembly (from `global_asm!()`).\n     GlobalAsm(P<GlobalAsm>),\n-    /// A type alias (`type` or `pub type`).\n+    /// A type alias (`type`).\n     ///\n     /// E.g., `type Foo = Bar<u8>;`.\n     TyAlias(P<Ty>, Generics),\n     /// An opaque `impl Trait` type alias.\n     ///\n     /// E.g., `type Foo = impl Bar + Boo;`.\n     OpaqueTy(GenericBounds, Generics),\n-    /// An enum definition (`enum` or `pub enum`).\n+    /// An enum definition (`enum`).\n     ///\n     /// E.g., `enum Foo<A, B> { C<A>, D<B> }`.\n     Enum(EnumDef, Generics),\n-    /// A struct definition (`struct` or `pub struct`).\n+    /// A struct definition (`struct`).\n     ///\n     /// E.g., `struct Foo<A> { x: A }`.\n     Struct(VariantData, Generics),\n-    /// A union definition (`union` or `pub union`).\n+    /// A union definition (`union`).\n     ///\n     /// E.g., `union Foo<A, B> { x: A, y: B }`.\n     Union(VariantData, Generics),\n-    /// A Trait declaration (`trait` or `pub trait`).\n+    /// A trait declaration (`trait`).\n     ///\n     /// E.g., `trait Foo { .. }`, `trait Foo<T> { .. }` or `auto trait Foo {}`.\n     Trait(IsAuto, Unsafety, Generics, GenericBounds, Vec<TraitItem>),"}, {"sha": "1f954064944dc1f5df3c3b27d04fc34a2e62fe4e", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 22, "deletions": 21, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -1,4 +1,4 @@\n-//! Functions dealing with attributes and meta items\n+//! Functions dealing with attributes and meta items.\n \n mod builtin;\n \n@@ -61,15 +61,15 @@ pub fn is_known_lint_tool(m_item: Ident) -> bool {\n }\n \n impl NestedMetaItem {\n-    /// Returns the MetaItem if self is a NestedMetaItem::MetaItem.\n+    /// Returns the `MetaItem` if `self` is a `NestedMetaItem::MetaItem`.\n     pub fn meta_item(&self) -> Option<&MetaItem> {\n         match *self {\n             NestedMetaItem::MetaItem(ref item) => Some(item),\n             _ => None\n         }\n     }\n \n-    /// Returns the Lit if self is a NestedMetaItem::Literal.\n+    /// Returns the `Lit` if `self` is a `NestedMetaItem::Literal`s.\n     pub fn literal(&self) -> Option<&Lit> {\n         match *self {\n             NestedMetaItem::Literal(ref lit) => Some(lit),\n@@ -82,21 +82,21 @@ impl NestedMetaItem {\n         self.meta_item().map_or(false, |meta_item| meta_item.check_name(name))\n     }\n \n-    /// For a single-segment meta-item returns its name, otherwise returns `None`.\n+    /// For a single-segment meta item, returns its name; otherwise, returns `None`.\n     pub fn ident(&self) -> Option<Ident> {\n         self.meta_item().and_then(|meta_item| meta_item.ident())\n     }\n     pub fn name_or_empty(&self) -> Symbol {\n         self.ident().unwrap_or(Ident::invalid()).name\n     }\n \n-    /// Gets the string value if self is a MetaItem and the MetaItem is a\n-    /// MetaItemKind::NameValue variant containing a string, otherwise None.\n+    /// Gets the string value if `self` is a `MetaItem` and the `MetaItem` is a\n+    /// `MetaItemKind::NameValue` variant containing a string, otherwise `None`.\n     pub fn value_str(&self) -> Option<Symbol> {\n         self.meta_item().and_then(|meta_item| meta_item.value_str())\n     }\n \n-    /// Returns a name and single literal value tuple of the MetaItem.\n+    /// Returns a name and single literal value tuple of the `MetaItem`.\n     pub fn name_value_literal(&self) -> Option<(Name, &Lit)> {\n         self.meta_item().and_then(\n             |meta_item| meta_item.meta_item_list().and_then(\n@@ -112,32 +112,32 @@ impl NestedMetaItem {\n                 }))\n     }\n \n-    /// Gets a list of inner meta items from a list MetaItem type.\n+    /// Gets a list of inner meta items from a list `MetaItem` type.\n     pub fn meta_item_list(&self) -> Option<&[NestedMetaItem]> {\n         self.meta_item().and_then(|meta_item| meta_item.meta_item_list())\n     }\n \n-    /// Returns `true` if the variant is MetaItem.\n+    /// Returns `true` if the variant is `MetaItem`.\n     pub fn is_meta_item(&self) -> bool {\n         self.meta_item().is_some()\n     }\n \n-    /// Returns `true` if the variant is Literal.\n+    /// Returns `true` if the variant is `Literal`.\n     pub fn is_literal(&self) -> bool {\n         self.literal().is_some()\n     }\n \n-    /// Returns `true` if self is a MetaItem and the meta item is a word.\n+    /// Returns `true` if `self` is a `MetaItem` and the meta item is a word.\n     pub fn is_word(&self) -> bool {\n         self.meta_item().map_or(false, |meta_item| meta_item.is_word())\n     }\n \n-    /// Returns `true` if self is a MetaItem and the meta item is a ValueString.\n+    /// Returns `true` if `self` is a `MetaItem` and the meta item is a `ValueString`.\n     pub fn is_value_str(&self) -> bool {\n         self.value_str().is_some()\n     }\n \n-    /// Returns `true` if self is a MetaItem and the meta item is a list.\n+    /// Returns `true` if `self` is a `MetaItem` and the meta item is a list.\n     pub fn is_meta_item_list(&self) -> bool {\n         self.meta_item_list().is_some()\n     }\n@@ -156,7 +156,7 @@ impl Attribute {\n         matches\n     }\n \n-    /// For a single-segment attribute returns its name, otherwise returns `None`.\n+    /// For a single-segment attribute, returns its name; otherwise, returns `None`.\n     pub fn ident(&self) -> Option<Ident> {\n         if self.path.segments.len() == 1 {\n             Some(self.path.segments[0].ident)\n@@ -187,14 +187,14 @@ impl Attribute {\n         self.meta_item_list().is_some()\n     }\n \n-    /// Indicates if the attribute is a Value String.\n+    /// Indicates if the attribute is a `ValueString`.\n     pub fn is_value_str(&self) -> bool {\n         self.value_str().is_some()\n     }\n }\n \n impl MetaItem {\n-    /// For a single-segment meta-item returns its name, otherwise returns `None`.\n+    /// For a single-segment meta item, returns its name; otherwise, returns `None`.\n     pub fn ident(&self) -> Option<Ident> {\n         if self.path.segments.len() == 1 {\n             Some(self.path.segments[0].ident)\n@@ -206,8 +206,9 @@ impl MetaItem {\n         self.ident().unwrap_or(Ident::invalid()).name\n     }\n \n-    // #[attribute(name = \"value\")]\n-    //             ^^^^^^^^^^^^^^\n+    // Example:\n+    //     #[attribute(name = \"value\")]\n+    //                 ^^^^^^^^^^^^^^\n     pub fn name_value_literal(&self) -> Option<&Lit> {\n         match &self.node {\n             MetaItemKind::NameValue(v) => Some(v),\n@@ -255,7 +256,7 @@ impl MetaItem {\n }\n \n impl Attribute {\n-    /// Extracts the MetaItem from inside this Attribute.\n+    /// Extracts the `MetaItem` from inside this `Attribute`.\n     pub fn meta(&self) -> Option<MetaItem> {\n         let mut tokens = self.tokens.trees().peekable();\n         Some(MetaItem {\n@@ -318,8 +319,8 @@ impl Attribute {\n         })\n     }\n \n-    /// Converts self to a normal #[doc=\"foo\"] comment, if it is a\n-    /// comment like `///` or `/** */`. (Returns self unchanged for\n+    /// Converts `self` to a normal `#[doc=\"foo\"]` comment, if it is a\n+    /// comment like `///` or `/** */`. (Returns `self` unchanged for\n     /// non-sugared doc attributes.)\n     pub fn with_desugared_doc<T, F>(&self, f: F) -> T where\n         F: FnOnce(&Attribute) -> T,"}, {"sha": "c4569b3fba1be0d52f744ada8a32b0118741821e", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -958,7 +958,7 @@ impl<'a> ExtCtxt<'a> {\n         self.resolver.check_unused_macros();\n     }\n \n-    /// Resolve a path mentioned inside Rust code.\n+    /// Resolves a path mentioned inside Rust code.\n     ///\n     /// This unifies the logic used for resolving `include_X!`, and `#[doc(include)]` file paths.\n     ///"}, {"sha": "a15fc050141a339e02d86af5304e444e158fc20b", "filename": "src/libsyntax/feature_gate/active.rs", "status": "modified", "additions": 10, "deletions": 8, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ffeature_gate%2Factive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ffeature_gate%2Factive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate%2Factive.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -1,9 +1,11 @@\n //! List of the active feature gates.\n \n+use super::{State, Feature};\n+\n use crate::edition::Edition;\n use crate::symbol::{Symbol, sym};\n+\n use syntax_pos::Span;\n-use super::{State, Feature};\n \n macro_rules! set {\n     ($field: ident) => {{\n@@ -37,9 +39,9 @@ macro_rules! declare_features {\n         /// A set of features to be used by later passes.\n         #[derive(Clone)]\n         pub struct Features {\n-            /// `#![feature]` attrs for language features, for error reporting\n+            /// `#![feature]` attrs for language features, for error reporting.\n             pub declared_lang_features: Vec<(Symbol, Span, Option<Symbol>)>,\n-            /// `#![feature]` attrs for non-language (library) features\n+            /// `#![feature]` attrs for non-language (library) features.\n             pub declared_lib_features: Vec<(Symbol, Span)>,\n             $(\n                 $(#[doc = $doc])*\n@@ -66,11 +68,11 @@ macro_rules! declare_features {\n }\n \n impl Feature {\n-    /// Set this feature in `Features`. Panics if called on a non-active feature.\n+    /// Sets this feature in `Features`. Panics if called on a non-active feature.\n     pub fn set(&self, features: &mut Features, span: Span) {\n         match self.state {\n             State::Active { set } => set(features, span),\n-            _ => panic!(\"Called `set` on feature `{}` which is not `active`\", self.name)\n+            _ => panic!(\"called `set` on feature `{}` which is not `active`\", self.name)\n         }\n     }\n }\n@@ -478,7 +480,7 @@ declare_features! (\n     (active, precise_pointer_size_matching, \"1.32.0\", Some(56354), None),\n \n     /// Allows relaxing the coherence rules such that\n-    /// `impl<T> ForeignTrait<LocalType> for ForeignType<T> is permitted.\n+    /// `impl<T> ForeignTrait<LocalType> for ForeignType<T>` is permitted.\n     (active, re_rebalance_coherence, \"1.32.0\", Some(55437), None),\n \n     /// Allows using `#[ffi_returns_twice]` on foreign functions.\n@@ -520,7 +522,7 @@ declare_features! (\n     /// Allows `async || body` closures.\n     (active, async_closure, \"1.37.0\", Some(62290), None),\n \n-    /// Allows the use of `#[cfg(doctest)]`, set when rustdoc is collecting doctests\n+    /// Allows the use of `#[cfg(doctest)]`; set when rustdoc is collecting doctests.\n     (active, cfg_doctest, \"1.37.0\", Some(62210), None),\n \n     /// Allows `[x; N]` where `x` is a constant (RFC 2203).\n@@ -529,7 +531,7 @@ declare_features! (\n     /// Allows `impl Trait` to be used inside type aliases (RFC 2515).\n     (active, type_alias_impl_trait, \"1.38.0\", Some(63063), None),\n \n-    /// Allows the use of or-patterns, e.g. `0 | 1`.\n+    /// Allows the use of or-patterns (e.g., `0 | 1`).\n     (active, or_patterns, \"1.38.0\", Some(54883), None),\n \n     // -------------------------------------------------------------------------"}, {"sha": "763c3ffd782df949415a53886d27d23d959722fd", "filename": "src/libsyntax/feature_gate/builtin_attrs.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ffeature_gate%2Fbuiltin_attrs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ffeature_gate%2Fbuiltin_attrs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate%2Fbuiltin_attrs.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -169,7 +169,7 @@ const INTERAL_UNSTABLE: &str = \"this is an internal attribute that will never be\n \n pub type BuiltinAttribute = (Symbol, AttributeType, AttributeTemplate, AttributeGate);\n \n-/// Attributes that have a special meaning to rustc or rustdoc\n+/// Attributes that have a special meaning to rustc or rustdoc.\n pub const BUILTIN_ATTRIBUTES: &[BuiltinAttribute] = &[\n     // ==========================================================================\n     // Stable attributes:"}, {"sha": "5711b269ff092fe12982df3401eae7e690cb7419", "filename": "src/libsyntax/feature_gate/check.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ffeature_gate%2Fcheck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ffeature_gate%2Fcheck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate%2Fcheck.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -920,9 +920,9 @@ pub enum UnstableFeatures {\n \n impl UnstableFeatures {\n     pub fn from_environment() -> UnstableFeatures {\n-        // Whether this is a feature-staged build, i.e., on the beta or stable channel\n+        // `true` if this is a feature-staged build, i.e., on the beta or stable channel.\n         let disable_unstable_features = option_env!(\"CFG_DISABLE_UNSTABLE_FEATURES\").is_some();\n-        // Whether we should enable unstable features for bootstrapping\n+        // `true` if we should enable unstable features for bootstrapping.\n         let bootstrap = env::var(\"RUSTC_BOOTSTRAP\").is_ok();\n         match (disable_unstable_features, bootstrap) {\n             (_, true) => UnstableFeatures::Cheat,"}, {"sha": "1c35688666836350d9dcc8afb7d30a70d3cfedf3", "filename": "src/libsyntax/mut_visit.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fmut_visit.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -1,10 +1,10 @@\n-//! A MutVisitor represents an AST modification; it accepts an AST piece and\n-//! and mutates it in place. So, for instance, macro expansion is a MutVisitor\n+//! A `MutVisitor` represents an AST modification; it accepts an AST piece and\n+//! and mutates it in place. So, for instance, macro expansion is a `MutVisitor`\n //! that walks over an AST and modifies it.\n //!\n-//! Note: using a MutVisitor (other than the MacroExpander MutVisitor) on\n+//! Note: using a `MutVisitor` (other than the `MacroExpander` `MutVisitor`) on\n //! an AST before macro expansion is probably a bad idea. For instance,\n-//! a MutVisitor renaming item names in a module will miss all of those\n+//! a `MutVisitor` renaming item names in a module will miss all of those\n //! that are created by the expansion of a macro.\n \n use crate::ast::*;\n@@ -614,7 +614,7 @@ pub fn noop_visit_tts<T: MutVisitor>(TokenStream(tts): &mut TokenStream, vis: &m\n     })\n }\n \n-// Apply ident visitor if it's an ident, apply other visits to interpolated nodes.\n+// Applies ident visitor if it's an ident; applies other visits to interpolated nodes.\n // In practice the ident part is not actually used by specific visitors right now,\n // but there's a test below checking that it works.\n pub fn noop_visit_token<T: MutVisitor>(t: &mut Token, vis: &mut T) {\n@@ -625,7 +625,7 @@ pub fn noop_visit_token<T: MutVisitor>(t: &mut Token, vis: &mut T) {\n             vis.visit_ident(&mut ident);\n             *name = ident.name;\n             *span = ident.span;\n-            return; // avoid visiting the span for the second time\n+            return; // Avoid visiting the span for the second time.\n         }\n         token::Interpolated(nt) => {\n             let mut nt = Lrc::make_mut(nt);\n@@ -636,28 +636,28 @@ pub fn noop_visit_token<T: MutVisitor>(t: &mut Token, vis: &mut T) {\n     vis.visit_span(span);\n }\n \n-/// Apply visitor to elements of interpolated nodes.\n+/// Applies the visitor to elements of interpolated nodes.\n //\n // N.B., this can occur only when applying a visitor to partially expanded\n // code, where parsed pieces have gotten implanted ito *other* macro\n // invocations. This is relevant for macro hygiene, but possibly not elsewhere.\n //\n // One problem here occurs because the types for flat_map_item, flat_map_stmt,\n-// etc. allow the visitor to return *multiple* items; this is a problem for the\n+// etc., allow the visitor to return *multiple* items; this is a problem for the\n // nodes here, because they insist on having exactly one piece. One solution\n // would be to mangle the MutVisitor trait to include one-to-many and\n // one-to-one versions of these entry points, but that would probably confuse a\n // lot of people and help very few. Instead, I'm just going to put in dynamic\n // checks. I think the performance impact of this will be pretty much\n-// nonexistent. The danger is that someone will apply a MutVisitor to a\n+// nonexistent. The danger is that someone will apply a `MutVisitor` to a\n // partially expanded node, and will be confused by the fact that their\n-// \"flat_map_item\" or \"flat_map_stmt\" isn't getting called on NtItem or NtStmt\n+// `flat_map_item` or `flat_map_stmt` isn't getting called on `NtItem` or `NtStmt`\n // nodes. Hopefully they'll wind up reading this comment, and doing something\n // appropriate.\n //\n-// BTW, design choice: I considered just changing the type of, e.g., NtItem to\n+// BTW, design choice: I considered just changing the type of, e.g., `NtItem` to\n // contain multiple items, but decided against it when I looked at\n-// parse_item_or_view_item and tried to figure out what I would do with\n+// `parse_item_or_view_item` and tried to figure out what I would do with\n // multiple items there....\n pub fn noop_visit_interpolated<T: MutVisitor>(nt: &mut token::Nonterminal, vis: &mut T) {\n     match nt {\n@@ -1014,7 +1014,7 @@ pub fn noop_visit_crate<T: MutVisitor>(krate: &mut Crate, vis: &mut T) {\n     });\n }\n \n-// Mutate one item into possibly many items.\n+// Mutates one item into possibly many items.\n pub fn noop_flat_map_item<T: MutVisitor>(mut item: P<Item>, visitor: &mut T)\n                                          -> SmallVec<[P<Item>; 1]> {\n     let Item { ident, attrs, id, node, vis, span, tokens: _ } = item.deref_mut();\n@@ -1224,7 +1224,7 @@ pub fn noop_visit_expr<T: MutVisitor>(Expr { node, id, span, attrs }: &mut Expr,\n         ExprKind::Paren(expr) => {\n             vis.visit_expr(expr);\n \n-            // Nodes that are equal modulo `Paren` sugar no-ops should have the same ids.\n+            // Nodes that are equal modulo `Paren` sugar no-ops should have the same IDs.\n             *id = expr.id;\n             vis.visit_span(span);\n             visit_thin_attrs(attrs, vis);"}, {"sha": "f779e0d0a601471d4064570c9fc25d1824c62129", "filename": "src/libsyntax/mut_visit/tests.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fmut_visit%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fmut_visit%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fmut_visit%2Ftests.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -6,13 +6,13 @@ use crate::print::pprust;\n use crate::mut_visit;\n use crate::with_default_globals;\n \n-// this version doesn't care about getting comments or docstrings in.\n+// This version doesn't care about getting comments or doc-strings in.\n fn fake_print_crate(s: &mut pprust::State<'_>,\n                     krate: &ast::Crate) {\n     s.print_mod(&krate.module, &krate.attrs)\n }\n \n-// change every identifier to \"zz\"\n+// Change every identifier to \"zz\".\n struct ToZzIdentMutVisitor;\n \n impl MutVisitor for ToZzIdentMutVisitor {\n@@ -24,7 +24,7 @@ impl MutVisitor for ToZzIdentMutVisitor {\n     }\n }\n \n-// maybe add to expand.rs...\n+// Maybe add to `expand.rs`.\n macro_rules! assert_pred {\n     ($pred:expr, $predname:expr, $a:expr , $b:expr) => (\n         {\n@@ -39,7 +39,7 @@ macro_rules! assert_pred {\n     )\n }\n \n-// make sure idents get transformed everywhere\n+// Make sure idents get transformed everywhere.\n #[test] fn ident_transformation () {\n     with_default_globals(|| {\n         let mut zz_visitor = ToZzIdentMutVisitor;\n@@ -54,7 +54,7 @@ macro_rules! assert_pred {\n     })\n }\n \n-// even inside macro defs....\n+// Make sure idents get transformed even inside macro defs.\n #[test] fn ident_transformation_in_defs () {\n     with_default_globals(|| {\n         let mut zz_visitor = ToZzIdentMutVisitor;"}, {"sha": "9aa1ec0b14fe962f5388c90590b6392b081f866c", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -26,7 +26,7 @@ impl<'a> Parser<'a> {\n         Ok(attrs)\n     }\n \n-    /// Parse attributes that appear before an item\n+    /// Parses attributes that appear before an item.\n     crate fn parse_outer_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n         let mut attrs: Vec<ast::Attribute> = Vec::new();\n         let mut just_parsed_doc_comment = false;\n@@ -69,10 +69,10 @@ impl<'a> Parser<'a> {\n         Ok(attrs)\n     }\n \n-    /// Matches `attribute = # ! [ meta_item ]`\n+    /// Matches `attribute = # ! [ meta_item ]`.\n     ///\n-    /// If permit_inner is true, then a leading `!` indicates an inner\n-    /// attribute\n+    /// If `permit_inner` is `true`, then a leading `!` indicates an inner\n+    /// attribute.\n     pub fn parse_attribute(&mut self, permit_inner: bool) -> PResult<'a, ast::Attribute> {\n         debug!(\"parse_attribute: permit_inner={:?} self.token={:?}\",\n                permit_inner,\n@@ -167,14 +167,14 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    /// Parse an inner part of attribute - path and following tokens.\n+    /// Parses an inner part of an attribute (the path and following tokens).\n     /// The tokens must be either a delimited token stream, or empty token stream,\n     /// or the \"legacy\" key-value form.\n-    /// PATH `(` TOKEN_STREAM `)`\n-    /// PATH `[` TOKEN_STREAM `]`\n-    /// PATH `{` TOKEN_STREAM `}`\n-    /// PATH\n-    /// PATH `=` TOKEN_TREE\n+    ///     PATH `(` TOKEN_STREAM `)`\n+    ///     PATH `[` TOKEN_STREAM `]`\n+    ///     PATH `{` TOKEN_STREAM `}`\n+    ///     PATH\n+    ///     PATH `=` TOKEN_TREE\n     /// The delimiters or `=` are still put into the resulting token stream.\n     pub fn parse_meta_item_unrestricted(&mut self) -> PResult<'a, (ast::Path, TokenStream)> {\n         let meta = match self.token.kind {\n@@ -217,11 +217,11 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    /// Parse attributes that appear after the opening of an item. These should\n+    /// Parses attributes that appear after the opening of an item. These should\n     /// be preceded by an exclamation mark, but we accept and warn about one\n     /// terminated by a semicolon.\n-\n-    /// matches inner_attrs*\n+    ///\n+    /// Matches `inner_attrs*`.\n     crate fn parse_inner_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n         let mut attrs: Vec<ast::Attribute> = vec![];\n         loop {\n@@ -237,7 +237,7 @@ impl<'a> Parser<'a> {\n                     attrs.push(attr);\n                 }\n                 token::DocComment(s) => {\n-                    // we need to get the position of this token before we bump.\n+                    // We need to get the position of this token before we bump.\n                     let attr = attr::mk_sugared_doc_attr(s, self.token.span);\n                     if attr.style == ast::AttrStyle::Inner {\n                         attrs.push(attr);\n@@ -268,10 +268,10 @@ impl<'a> Parser<'a> {\n         Ok(lit)\n     }\n \n-    /// Per RFC#1559, matches the following grammar:\n+    /// Matches the following grammar (per RFC 1559).\n     ///\n-    /// meta_item : IDENT ( '=' UNSUFFIXED_LIT | '(' meta_item_inner? ')' )? ;\n-    /// meta_item_inner : (meta_item | UNSUFFIXED_LIT) (',' meta_item_inner)? ;\n+    ///     meta_item : IDENT ( '=' UNSUFFIXED_LIT | '(' meta_item_inner? ')' )? ;\n+    ///     meta_item_inner : (meta_item | UNSUFFIXED_LIT) (',' meta_item_inner)? ;\n     pub fn parse_meta_item(&mut self) -> PResult<'a, ast::MetaItem> {\n         let nt_meta = match self.token.kind {\n             token::Interpolated(ref nt) => match **nt {\n@@ -303,7 +303,7 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    /// matches meta_item_inner : (meta_item | UNSUFFIXED_LIT) ;\n+    /// Matches `meta_item_inner : (meta_item | UNSUFFIXED_LIT) ;`.\n     fn parse_meta_item_inner(&mut self) -> PResult<'a, ast::NestedMetaItem> {\n         match self.parse_unsuffixed_lit() {\n             Ok(lit) => {\n@@ -324,7 +324,7 @@ impl<'a> Parser<'a> {\n         Err(self.diagnostic().struct_span_err(self.token.span, &msg))\n     }\n \n-    /// matches meta_seq = ( COMMASEP(meta_item_inner) )\n+    /// Matches `meta_seq = ( COMMASEP(meta_item_inner) )`.\n     fn parse_meta_seq(&mut self) -> PResult<'a, Vec<ast::NestedMetaItem>> {\n         self.parse_seq_to_end(&token::CloseDelim(token::Paren),\n                               SeqSep::trailing_allowed(token::Comma),"}, {"sha": "2890a8e721e656cd77a0f6289a0c9c367fba4153", "filename": "src/libsyntax/parse/diagnostics.rs", "status": "modified", "additions": 38, "deletions": 38, "changes": 76, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -240,7 +240,7 @@ impl<'a> Parser<'a> {\n     ) -> PResult<'a, bool /* recovered */> {\n         fn tokens_to_string(tokens: &[TokenType]) -> String {\n             let mut i = tokens.iter();\n-            // This might be a sign we need a connect method on Iterator.\n+            // This might be a sign we need a connect method on `Iterator`.\n             let b = i.next()\n                      .map_or(String::new(), |t| t.to_string());\n             i.enumerate().fold(b, |mut b, (i, a)| {\n@@ -301,7 +301,7 @@ impl<'a> Parser<'a> {\n             );\n         }\n         let sp = if self.token == token::Eof {\n-            // This is EOF, don't want to point at the following char, but rather the last token\n+            // This is EOF; don't want to point at the following char, but rather the last token.\n             self.prev_span\n         } else {\n             label_sp\n@@ -317,9 +317,9 @@ impl<'a> Parser<'a> {\n         }\n \n         let is_semi_suggestable = expected.iter().any(|t| match t {\n-            TokenType::Token(token::Semi) => true, // we expect a `;` here\n+            TokenType::Token(token::Semi) => true, // We expect a `;` here.\n             _ => false,\n-        }) && ( // a `;` would be expected before the current keyword\n+        }) && ( // A `;` would be expected before the current keyword.\n             self.token.is_keyword(kw::Break) ||\n             self.token.is_keyword(kw::Continue) ||\n             self.token.is_keyword(kw::For) ||\n@@ -541,16 +541,16 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Produce an error if comparison operators are chained (RFC #558).\n-    /// We only need to check lhs, not rhs, because all comparison ops\n-    /// have same precedence and are left-associative\n+    /// Produces an error if comparison operators are chained (RFC #558).\n+    /// We only need to check the LHS, not the RHS, because all comparison ops\n+    /// have same precedence and are left-associative.\n     crate fn check_no_chained_comparison(&self, lhs: &Expr, outer_op: &AssocOp) -> PResult<'a, ()> {\n         debug_assert!(outer_op.is_comparison(),\n                       \"check_no_chained_comparison: {:?} is not comparison\",\n                       outer_op);\n         match lhs.node {\n             ExprKind::Binary(op, _, _) if op.node.is_comparison() => {\n-                // respan to include both operators\n+                // Respan to include both operators.\n                 let op_span = op.span.to(self.token.span);\n                 let mut err = self.struct_span_err(\n                     op_span,\n@@ -691,9 +691,9 @@ impl<'a> Parser<'a> {\n         Ok(())\n     }\n \n-    /// Try to recover from associated item paths like `[T]::AssocItem`/`(T, U)::AssocItem`.\n-    /// Attempt to convert the base expression/pattern/type into a type, parse the `::AssocItem`\n-    /// tail, and combine them into a `<Ty>::AssocItem` expression/pattern/type.\n+    /// Tries to recover from associated item paths like `[T]::AssocItem` / `(T, U)::AssocItem`.\n+    /// Attempts to convert the base expression/pattern/type into a type, parses the `::AssocItem`\n+    /// tail, and combines them into a `<Ty>::AssocItem` expression/pattern/type.\n     crate fn maybe_recover_from_bad_qpath<T: RecoverQPath>(\n         &mut self,\n         base: P<T>,\n@@ -708,8 +708,8 @@ impl<'a> Parser<'a> {\n         Ok(base)\n     }\n \n-    /// Given an already parsed `Ty` parse the `::AssocItem` tail and\n-    /// combine them into a `<Ty>::AssocItem` expression/pattern/type.\n+    /// Given an already parsed `Ty`, parses the `::AssocItem` tail and\n+    /// combines them into a `<Ty>::AssocItem` expression/pattern/type.\n     crate fn maybe_recover_from_bad_qpath_stage_2<T: RecoverQPath>(\n         &mut self,\n         ty_span: Span,\n@@ -730,15 +730,15 @@ impl<'a> Parser<'a> {\n         self.diagnostic()\n             .struct_span_err(path.span, \"missing angle brackets in associated item path\")\n             .span_suggestion(\n-                // this is a best-effort recovery\n+                // This is a best-effort recovery.\n                 path.span,\n                 \"try\",\n                 format!(\"<{}>::{}\", ty_str, path),\n                 Applicability::MaybeIncorrect,\n             )\n             .emit();\n \n-        let path_span = ty_span.shrink_to_hi(); // use an empty path since `position` == 0\n+        let path_span = ty_span.shrink_to_hi(); // Use an empty path since `position == 0`.\n         Ok(P(T::recovered(\n             Some(QSelf {\n                 ty,\n@@ -761,8 +761,8 @@ impl<'a> Parser<'a> {\n             if !items.is_empty() {\n                 let previous_item = &items[items.len() - 1];\n                 let previous_item_kind_name = match previous_item.node {\n-                    // say \"braced struct\" because tuple-structs and\n-                    // braceless-empty-struct declarations do take a semicolon\n+                    // Say \"braced struct\" because tuple-structs and\n+                    // braceless-empty-struct declarations do take a semicolon.\n                     ItemKind::Struct(..) => Some(\"braced struct\"),\n                     ItemKind::Enum(..) => Some(\"enum\"),\n                     ItemKind::Trait(..) => Some(\"trait\"),\n@@ -783,7 +783,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Create a `DiagnosticBuilder` for an unexpected token `t` and try to recover if it is a\n+    /// Creates a `DiagnosticBuilder` for an unexpected token `t` and tries to recover if it is a\n     /// closing delimiter.\n     pub fn unexpected_try_recover(\n         &mut self,\n@@ -841,7 +841,7 @@ impl<'a> Parser<'a> {\n         extern_sp: Span,\n     ) -> PResult<'a, ()> {\n         if self.token != token::Semi {\n-            // this might be an incorrect fn definition (#62109)\n+            // This might be an incorrect fn definition (#62109).\n             let parser_snapshot = self.clone();\n             match self.parse_inner_attrs_and_block() {\n                 Ok((_, body)) => {\n@@ -871,7 +871,7 @@ impl<'a> Parser<'a> {\n         Ok(())\n     }\n \n-    /// Consume alternative await syntaxes like `await!(<expr>)`, `await <expr>`,\n+    /// Consumes alternative await syntaxes like `await!(<expr>)`, `await <expr>`,\n     /// `await? <expr>`, `await(<expr>)`, and `await { <expr> }`.\n     crate fn parse_incorrect_await_syntax(\n         &mut self,\n@@ -924,7 +924,7 @@ impl<'a> Parser<'a> {\n         sp\n     }\n \n-    /// If encountering `future.await()`, consume and emit error.\n+    /// If encountering `future.await()`, consumes and emits an error.\n     crate fn recover_from_await_method_call(&mut self) {\n         if self.token == token::OpenDelim(token::Paren) &&\n             self.look_ahead(1, |t| t == &token::CloseDelim(token::Paren))\n@@ -944,7 +944,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Recover a situation like `for ( $pat in $expr )`\n+    /// Recovers a situation like `for ( $pat in $expr )`\n     /// and suggest writing `for $pat in $expr` instead.\n     ///\n     /// This should be called before parsing the `$block`.\n@@ -1010,7 +1010,7 @@ impl<'a> Parser<'a> {\n             Ok(x) => x,\n             Err(mut err) => {\n                 err.emit();\n-                // recover from parse error\n+                // Recover from parse error.\n                 self.consume_block(delim);\n                 self.mk_expr(lo.to(self.prev_span), ExprKind::Err, ThinVec::new())\n             }\n@@ -1023,7 +1023,7 @@ impl<'a> Parser<'a> {\n         mut err: DiagnosticBuilder<'a>,\n     ) -> PResult<'a, bool> {\n         let mut pos = None;\n-        // we want to use the last closing delim that would apply\n+        // We want to use the last closing delim that would apply.\n         for (i, unmatched) in self.unclosed_delims.iter().enumerate().rev() {\n             if tokens.contains(&token::CloseDelim(unmatched.expected_delim))\n                 && Some(self.token.span) > unmatched.unclosed_span\n@@ -1041,7 +1041,7 @@ impl<'a> Parser<'a> {\n                 let unmatched = self.unclosed_delims.remove(pos);\n                 let delim = TokenType::Token(token::CloseDelim(unmatched.expected_delim));\n \n-                 // We want to suggest the inclusion of the closing delimiter where it makes\n+                // We want to suggest the inclusion of the closing delimiter where it makes\n                 // the most sense, which is immediately after the last token:\n                 //\n                 //  {foo(bar {}}\n@@ -1067,7 +1067,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Recover from `pub` keyword in places where it seems _reasonable_ but isn't valid.\n+    /// Recovers from `pub` keyword in places where it seems _reasonable_ but isn't valid.\n     crate fn eat_bad_pub(&mut self) {\n         if self.token.is_keyword(kw::Pub) {\n             match self.parse_visibility(false) {\n@@ -1082,21 +1082,21 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    // Eat tokens until we can be relatively sure we reached the end of the\n-    // statement. This is something of a best-effort heuristic.\n-    //\n-    // We terminate when we find an unmatched `}` (without consuming it).\n-    crate fn recover_stmt(&mut self) {\n+    /// Eats tokens until we can be relatively sure we reached the end of the\n+    /// statement. This is something of a best-effort heuristic.\n+    ///\n+    /// We terminate when we find an unmatched `}` (without consuming it).\n+    pub fn recover_stmt(&mut self) {\n         self.recover_stmt_(SemiColonMode::Ignore, BlockMode::Ignore)\n     }\n \n-    // If `break_on_semi` is `Break`, then we will stop consuming tokens after\n-    // finding (and consuming) a `;` outside of `{}` or `[]` (note that this is\n-    // approximate - it can mean we break too early due to macros, but that\n-    // should only lead to sub-optimal recovery, not inaccurate parsing).\n-    //\n-    // If `break_on_block` is `Break`, then we will stop consuming tokens\n-    // after finding (and consuming) a brace-delimited block.\n+    /// If `break_on_semi` is `Break`, then we will stop consuming tokens after\n+    /// finding (and consuming) a `;` outside of `{}` or `[]` (note that this is\n+    /// approximate -- it can mean we break too early due to macros, but that\n+    /// should only lead to sub-optimal recovery, not inaccurate parsing).\n+    ///\n+    /// If `break_on_block` is `Break`, then we will stop consuming tokens\n+    /// after finding (and consuming) a brace-delimited block.\n     crate fn recover_stmt_(&mut self, break_on_semi: SemiColonMode, break_on_block: BlockMode) {\n         let mut brace_depth = 0;\n         let mut bracket_depth = 0;"}, {"sha": "d965bf28ee7df3ebf46c173aa5043e35e9f8a1f5", "filename": "src/libsyntax/parse/lexer/tests.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftests.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -4,9 +4,10 @@ use crate::symbol::Symbol;\n use crate::source_map::{SourceMap, FilePathMapping};\n use crate::parse::token;\n use crate::with_default_globals;\n+\n+use errors::{Handler, emitter::EmitterWriter};\n use std::io;\n use std::path::PathBuf;\n-use errors::{Handler, emitter::EmitterWriter};\n use syntax_pos::{BytePos, Span};\n \n fn mk_sess(sm: Lrc<SourceMap>) -> ParseSess {\n@@ -21,7 +22,7 @@ fn mk_sess(sm: Lrc<SourceMap>) -> ParseSess {\n     ParseSess::with_span_handler(Handler::with_emitter(true, None, Box::new(emitter)), sm)\n }\n \n-// open a string reader for the given string\n+// Creates a string reader for the given string.\n fn setup<'a>(sm: &SourceMap,\n                 sess: &'a ParseSess,\n                 teststr: String)\n@@ -38,7 +39,7 @@ fn t1() {\n         let mut string_reader = setup(\n             &sm,\n             &sh,\n-            \"/* my source file */ fn main() { println!(\\\"zebra\\\"); }\\n\".to_string(),\n+            \"/* my source file */ fn main() { println!(\\\"zebra\\\"); }\\n\".to_owned(),\n         );\n         assert_eq!(string_reader.next_token(), token::Comment);\n         assert_eq!(string_reader.next_token(), token::Whitespace);\n@@ -50,7 +51,7 @@ fn t1() {\n         assert_eq!(tok1.kind, tok2.kind);\n         assert_eq!(tok1.span, tok2.span);\n         assert_eq!(string_reader.next_token(), token::Whitespace);\n-        // read another token:\n+        // Read another token.\n         let tok3 = string_reader.next_token();\n         assert_eq!(string_reader.pos.clone(), BytePos(28));\n         let tok4 = Token::new(\n@@ -65,15 +66,15 @@ fn t1() {\n     })\n }\n \n-// check that the given reader produces the desired stream\n-// of tokens (stop checking after exhausting the expected vec)\n+// Checks that the given reader produces the desired stream\n+// of tokens (stop checking after exhausting `expected`).\n fn check_tokenization(mut string_reader: StringReader<'_>, expected: Vec<TokenKind>) {\n     for expected_tok in &expected {\n         assert_eq!(&string_reader.next_token(), expected_tok);\n     }\n }\n \n-// make the identifier by looking up the string in the interner\n+// Makes the identifier by looking up the string in the interner.\n fn mk_ident(id: &str) -> TokenKind {\n     token::Ident(Symbol::intern(id), false)\n }\n@@ -201,7 +202,7 @@ fn literal_suffixes() {\n                     setup(&sm, &sh, format!(\"{}suffix\", $input)).next_token(),\n                     mk_lit(token::$tok_type, $tok_contents, Some(\"suffix\")),\n                 );\n-                // with a whitespace separator:\n+                // with a whitespace separator\n                 assert_eq!(\n                     setup(&sm, &sh, format!(\"{} suffix\", $input)).next_token(),\n                     mk_lit(token::$tok_type, $tok_contents, None),"}, {"sha": "aa57c3954e352f66656efb73375440b6eede0b1a", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 27, "deletions": 26, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -13,12 +13,12 @@ use crate::print::pprust;\n use crate::symbol::Symbol;\n \n use errors::{Applicability, FatalError, Level, Handler, ColorConfig, Diagnostic, DiagnosticBuilder};\n+use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n use rustc_data_structures::sync::{Lrc, Lock, Once};\n use syntax_pos::{Span, SourceFile, FileName, MultiSpan};\n use syntax_pos::edition::Edition;\n use syntax_pos::hygiene::ExpnId;\n \n-use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n use std::borrow::Cow;\n use std::path::{Path, PathBuf};\n use std::str;\n@@ -81,25 +81,27 @@ pub struct ParseSess {\n impl ParseSess {\n     pub fn new(file_path_mapping: FilePathMapping) -> Self {\n         let cm = Lrc::new(SourceMap::new(file_path_mapping));\n-        let handler = Handler::with_tty_emitter(ColorConfig::Auto,\n-                                                true,\n-                                                None,\n-                                                Some(cm.clone()));\n+        let handler = Handler::with_tty_emitter(\n+            ColorConfig::Auto,\n+            true,\n+            None,\n+            Some(cm.clone()),\n+        );\n         ParseSess::with_span_handler(handler, cm)\n     }\n \n-    pub fn with_span_handler(handler: Handler, source_map: Lrc<SourceMap>) -> ParseSess {\n-        ParseSess {\n+    pub fn with_span_handler(handler: Handler, source_map: Lrc<SourceMap>) -> Self {\n+        Self {\n             span_diagnostic: handler,\n             unstable_features: UnstableFeatures::from_environment(),\n             config: FxHashSet::default(),\n+            edition: ExpnId::root().expn_data().edition,\n             missing_fragment_specifiers: Lock::new(FxHashSet::default()),\n             raw_identifier_spans: Lock::new(Vec::new()),\n             registered_diagnostics: Lock::new(ErrorMap::new()),\n             included_mod_stack: Lock::new(vec![]),\n             source_map,\n             buffered_lints: Lock::new(vec![]),\n-            edition: ExpnId::root().expn_data().edition,\n             ambiguous_block_expr_parse: Lock::new(FxHashMap::default()),\n             injected_crate_name: Once::new(),\n             gated_spans: GatedSpans::default(),\n@@ -155,17 +157,17 @@ pub struct Directory<'a> {\n #[derive(Copy, Clone)]\n pub enum DirectoryOwnership {\n     Owned {\n-        // None if `mod.rs`, `Some(\"foo\")` if we're in `foo.rs`\n+        // None if `mod.rs`, `Some(\"foo\")` if we're in `foo.rs`.\n         relative: Option<ast::Ident>,\n     },\n     UnownedViaBlock,\n     UnownedViaMod(bool /* legacy warnings? */),\n }\n \n-// a bunch of utility functions of the form parse_<thing>_from_<source>\n+// A bunch of utility functions of the form `parse_<thing>_from_<source>`\n // where <thing> includes crate, expr, item, stmt, tts, and one that\n // uses a HOF to parse anything, and <source> includes file and\n-// source_str.\n+// `source_str`.\n \n pub fn parse_crate_from_file<'a>(input: &Path, sess: &'a ParseSess) -> PResult<'a, ast::Crate> {\n     let mut parser = new_parser_from_file(sess, input);\n@@ -219,23 +221,22 @@ pub fn maybe_new_parser_from_source_str(sess: &ParseSess, name: FileName, source\n     Ok(parser)\n }\n \n-/// Creates a new parser, handling errors as appropriate\n-/// if the file doesn't exist\n+/// Creates a new parser, handling errors as appropriate if the file doesn't exist.\n pub fn new_parser_from_file<'a>(sess: &'a ParseSess, path: &Path) -> Parser<'a> {\n     source_file_to_parser(sess, file_to_source_file(sess, path, None))\n }\n \n-/// Creates a new parser, returning buffered diagnostics if the file doesn't\n-/// exist or from lexing the initial token stream.\n+/// Creates a new parser, returning buffered diagnostics if the file doesn't exist,\n+/// or from lexing the initial token stream.\n pub fn maybe_new_parser_from_file<'a>(sess: &'a ParseSess, path: &Path)\n     -> Result<Parser<'a>, Vec<Diagnostic>> {\n     let file = try_file_to_source_file(sess, path, None).map_err(|db| vec![db])?;\n     maybe_source_file_to_parser(sess, file)\n }\n \n /// Given a session, a crate config, a path, and a span, add\n-/// the file at the given path to the source_map, and return a parser.\n-/// On an error, use the given span as the source of the problem.\n+/// the file at the given path to the `source_map`, and returns a parser.\n+/// On an error, uses the given span as the source of the problem.\n pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n                                     path: &Path,\n                                     directory_ownership: DirectoryOwnership,\n@@ -247,13 +248,13 @@ pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n     p\n }\n \n-/// Given a source_file and config, return a parser\n+/// Given a `source_file` and config, returns a parser.\n fn source_file_to_parser(sess: &ParseSess, source_file: Lrc<SourceFile>) -> Parser<'_> {\n     panictry_buffer!(&sess.span_diagnostic,\n                      maybe_source_file_to_parser(sess, source_file))\n }\n \n-/// Given a source_file and config, return a parser. Returns any buffered errors from lexing the\n+/// Given a `source_file` and config, return a parser. Returns any buffered errors from lexing the\n /// initial token stream.\n fn maybe_source_file_to_parser(\n     sess: &ParseSess,\n@@ -270,14 +271,14 @@ fn maybe_source_file_to_parser(\n     Ok(parser)\n }\n \n-// must preserve old name for now, because quote! from the *existing*\n-// compiler expands into it\n+// Must preserve old name for now, because `quote!` from the *existing*\n+// compiler expands into it.\n pub fn new_parser_from_tts(sess: &ParseSess, tts: Vec<TokenTree>) -> Parser<'_> {\n     stream_to_parser(sess, tts.into_iter().collect(), crate::MACRO_ARGUMENTS)\n }\n \n \n-// base abstractions\n+// Base abstractions\n \n /// Given a session and a path and an optional span (for error reporting),\n /// add the path to the session's source_map and return the new source_file or\n@@ -296,7 +297,7 @@ fn try_file_to_source_file(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n }\n \n /// Given a session and a path and an optional span (for error reporting),\n-/// add the path to the session's `source_map` and return the new `source_file`.\n+/// adds the path to the session's `source_map` and returns the new `source_file`.\n fn file_to_source_file(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n                    -> Lrc<SourceFile> {\n     match try_file_to_source_file(sess, path, spanopt) {\n@@ -308,7 +309,7 @@ fn file_to_source_file(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n     }\n }\n \n-/// Given a source_file, produces a sequence of token trees.\n+/// Given a `source_file`, produces a sequence of token trees.\n pub fn source_file_to_stream(\n     sess: &ParseSess,\n     source_file: Lrc<SourceFile>,\n@@ -352,7 +353,7 @@ pub fn maybe_file_to_stream(\n     }\n }\n \n-/// Given stream and the `ParseSess`, produces a parser.\n+/// Given a stream and the `ParseSess`, produces a parser.\n pub fn stream_to_parser<'a>(\n     sess: &'a ParseSess,\n     stream: TokenStream,\n@@ -361,7 +362,7 @@ pub fn stream_to_parser<'a>(\n     Parser::new(sess, stream, None, true, false, subparser_name)\n }\n \n-/// Given stream, the `ParseSess` and the base directory, produces a parser.\n+/// Given a stream, the `ParseSess` and the base directory, produces a parser.\n ///\n /// Use this function when you are creating a parser from the token stream\n /// and also care about the current working directory of the parser (e.g.,"}, {"sha": "fcaf5065dac78b8d4b6d7090da344dc1369b5fa6", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -10,22 +10,22 @@ pub use path::PathStyle;\n mod stmt;\n mod generics;\n \n-use crate::ast::{self, AttrStyle, Attribute, Param, BindingMode, StrStyle, SelfKind};\n-use crate::ast::{FnDecl, Ident, IsAsync, MacDelimiter, Mutability, TyKind};\n-use crate::ast::{Visibility, VisibilityKind, Unsafety, CrateSugar};\n-use crate::source_map::{self, respan};\n-use crate::parse::{SeqSep, literal, token};\n+use crate::ast::{\n+    self, DUMMY_NODE_ID, AttrStyle, Attribute, BindingMode, CrateSugar, FnDecl, Ident,\n+    IsAsync, MacDelimiter, Mutability, Param, StrStyle, SelfKind, TyKind, Visibility,\n+    VisibilityKind, Unsafety,\n+};\n+use crate::parse::{ParseSess, PResult, Directory, DirectoryOwnership, SeqSep, literal, token};\n+use crate::parse::diagnostics::{Error, dummy_arg};\n use crate::parse::lexer::UnmatchedBrace;\n use crate::parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use crate::parse::token::{Token, TokenKind, DelimToken};\n-use crate::parse::{ParseSess, Directory, DirectoryOwnership};\n use crate::print::pprust;\n use crate::ptr::P;\n-use crate::parse::PResult;\n-use crate::ThinVec;\n-use crate::tokenstream::{self, DelimSpan, TokenTree, TokenStream, TreeAndJoint};\n+use crate::source_map::{self, respan};\n use crate::symbol::{kw, sym, Symbol};\n-use crate::parse::diagnostics::{Error, dummy_arg};\n+use crate::tokenstream::{self, DelimSpan, TokenTree, TokenStream, TreeAndJoint};\n+use crate::ThinVec;\n \n use errors::{Applicability, DiagnosticId, FatalError};\n use rustc_target::spec::abi::{self, Abi};\n@@ -56,7 +56,7 @@ crate enum BlockMode {\n     Ignore,\n }\n \n-/// As maybe_whole_expr, but for things other than expressions\n+/// Like `maybe_whole_expr`, but for things other than expressions.\n #[macro_export]\n macro_rules! maybe_whole {\n     ($p:expr, $constructor:ident, |$x:ident| $e:expr) => {\n@@ -116,11 +116,11 @@ pub struct Parser<'a> {\n     /// with non-interpolated identifier and lifetime tokens they refer to.\n     /// Perhaps the normalized / non-normalized setup can be simplified somehow.\n     pub token: Token,\n-    /// Span of the current non-normalized token.\n+    /// The span of the current non-normalized token.\n     meta_var_span: Option<Span>,\n-    /// Span of the previous non-normalized token.\n+    /// The span of the previous non-normalized token.\n     pub prev_span: Span,\n-    /// Kind of the previous normalized token (in simplified form).\n+    /// The kind of the previous normalized token (in simplified form).\n     prev_token_kind: PrevTokenKind,\n     restrictions: Restrictions,\n     /// Used to determine the path to externally loaded source files.\n@@ -143,7 +143,7 @@ pub struct Parser<'a> {\n     /// See the comments in the `parse_path_segment` function for more details.\n     crate unmatched_angle_bracket_count: u32,\n     crate max_angle_bracket_count: u32,\n-    /// List of all unclosed delimiters found by the lexer. If an entry is used for error recovery\n+    /// A list of all unclosed delimiters found by the lexer. If an entry is used for error recovery\n     /// it gets removed from here. Every entry left at the end gets emitted as an independent\n     /// error.\n     crate unclosed_delims: Vec<UnmatchedBrace>,\n@@ -799,14 +799,14 @@ impl<'a> Parser<'a> {\n                             break;\n                         }\n                         Err(mut e) => {\n-                            // Attempt to keep parsing if it was a similar separator\n+                            // Attempt to keep parsing if it was a similar separator.\n                             if let Some(ref tokens) = t.similar_tokens() {\n                                 if tokens.contains(&self.token.kind) {\n                                     self.bump();\n                                 }\n                             }\n                             e.emit();\n-                            // Attempt to keep parsing if it was an omitted separator\n+                            // Attempt to keep parsing if it was an omitted separator.\n                             match f(self) {\n                                 Ok(t) => {\n                                     v.push(t);\n@@ -871,7 +871,7 @@ impl<'a> Parser<'a> {\n         self.parse_delim_comma_seq(token::Paren, f)\n     }\n \n-    /// Advance the parser by one token\n+    /// Advance the parser by one token.\n     pub fn bump(&mut self) {\n         if self.prev_token_kind == PrevTokenKind::Eof {\n             // Bumping after EOF is a bad sign, usually an infinite loop.\n@@ -894,17 +894,17 @@ impl<'a> Parser<'a> {\n \n         self.token = self.next_tok();\n         self.expected_tokens.clear();\n-        // check after each token\n+        // Check after each token.\n         self.process_potential_macro_variable();\n     }\n \n-    /// Advance the parser using provided token as a next one. Use this when\n+    /// Advances the parser using provided token as a next one. Use this when\n     /// consuming a part of a token. For example a single `<` from `<<`.\n     fn bump_with(&mut self, next: TokenKind, span: Span) {\n         self.prev_span = self.token.span.with_hi(span.lo());\n         // It would be incorrect to record the kind of the current token, but\n         // fortunately for tokens currently using `bump_with`, the\n-        // prev_token_kind will be of no use anyway.\n+        // `prev_token_kind` will be of no use anyway.\n         self.prev_token_kind = PrevTokenKind::Other;\n         self.token = Token::new(next, span);\n         self.expected_tokens.clear();\n@@ -937,8 +937,8 @@ impl<'a> Parser<'a> {\n     fn parse_asyncness(&mut self) -> IsAsync {\n         if self.eat_keyword(kw::Async) {\n             IsAsync::Async {\n-                closure_id: ast::DUMMY_NODE_ID,\n-                return_impl_trait_id: ast::DUMMY_NODE_ID,\n+                closure_id: DUMMY_NODE_ID,\n+                return_impl_trait_id: DUMMY_NODE_ID,\n             }\n         } else {\n             IsAsync::NotAsync\n@@ -1040,7 +1040,7 @@ impl<'a> Parser<'a> {\n \n         let span = lo.to(self.token.span);\n \n-        Ok(Param { attrs: attrs.into(), id: ast::DUMMY_NODE_ID, pat, span, ty })\n+        Ok(Param { attrs: attrs.into(), id: DUMMY_NODE_ID, pat, span, ty })\n     }\n \n     /// Parses mutability (`mut` or nothing).\n@@ -1497,7 +1497,7 @@ impl<'a> Parser<'a> {\n                         format!(\"in {}\", path),\n                         Applicability::MachineApplicable,\n                     )\n-                    .emit();  // emit diagnostic, but continue with public visibility\n+                    .emit(); // Emit diagnostic, but continue with public visibility.\n             }\n         }\n "}, {"sha": "f70c607198fa98787938593e24cdacaa20d7ed4d", "filename": "src/libsyntax/parse/parser/expr.rs", "status": "modified", "additions": 69, "deletions": 72, "changes": 141, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fexpr.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -1,26 +1,26 @@\n-use super::{Parser, PResult, Restrictions, PrevTokenKind, TokenType, PathStyle};\n-use super::{BlockMode, SemiColonMode};\n-use super::{SeqSep, TokenExpectType};\n+use super::{\n+    Parser, PResult, Restrictions, PrevTokenKind, TokenType, PathStyle, BlockMode, SemiColonMode,\n+    SeqSep, TokenExpectType,\n+};\n use super::pat::{GateOr, PARAM_EXPECTED};\n \n+use crate::ast::{\n+    self, DUMMY_NODE_ID, Attribute, AttrStyle, Ident, CaptureBy, BlockCheckMode,\n+    Expr, ExprKind, RangeLimits, Label, Movability, IsAsync, Arm, Ty, TyKind,\n+    FunctionRetTy, Param, FnDecl, BinOpKind, BinOp, UnOp, Mac, AnonConst, Field,\n+};\n use crate::maybe_recover_from_interpolated_ty_qpath;\n-use crate::ptr::P;\n-use crate::ast::{self, Attribute, AttrStyle, Ident, CaptureBy, BlockCheckMode};\n-use crate::ast::{Expr, ExprKind, RangeLimits, Label, Movability, IsAsync, Arm};\n-use crate::ast::{Ty, TyKind, FunctionRetTy, Param, FnDecl};\n-use crate::ast::{BinOpKind, BinOp, UnOp};\n-use crate::ast::{Mac, AnonConst, Field};\n-\n use crate::parse::classify;\n use crate::parse::token::{self, Token};\n-use crate::parse::diagnostics::{Error};\n+use crate::parse::diagnostics::Error;\n use crate::print::pprust;\n+use crate::ptr::P;\n use crate::source_map::{self, Span};\n use crate::symbol::{kw, sym};\n use crate::util::parser::{AssocOp, Fixity, prec_let_scrutinee_needs_par};\n \n-use std::mem;\n use errors::Applicability;\n+use std::mem;\n use rustc_data_structures::thin_vec::ThinVec;\n \n /// Possibly accepts an `token::Interpolated` expression (a pre-parsed expression\n@@ -51,7 +51,7 @@ macro_rules! maybe_whole_expr {\n                         $p.token.span, ExprKind::Block(block, None), ThinVec::new()\n                     ));\n                 }\n-                // N.B: `NtIdent(ident)` is normalized to `Ident` in `fn bump`.\n+                // N.B., `NtIdent(ident)` is normalized to `Ident` in `fn bump`.\n                 _ => {},\n             };\n         }\n@@ -340,7 +340,7 @@ impl<'a> Parser<'a> {\n \n     fn is_at_start_of_range_notation_rhs(&self) -> bool {\n         if self.token.can_begin_expr() {\n-            // parse `for i in 1.. { }` as infinite loop, not as `for i in (1..{})`.\n+            // Parse `for i in 1.. { }` as infinite loop, not as `for i in (1..{})`.\n             if self.token == token::OpenDelim(token::Brace) {\n                 return !self.restrictions.contains(Restrictions::NO_STRUCT_LITERAL);\n             }\n@@ -350,12 +350,12 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Parse prefix-forms of range notation: `..expr`, `..`, `..=expr`\n+    /// Parses prefix-forms of range notation: `..expr`, `..`, `..=expr`.\n     fn parse_prefix_range_expr(\n         &mut self,\n         already_parsed_attrs: Option<ThinVec<Attribute>>\n     ) -> PResult<'a, P<Expr>> {\n-        // Check for deprecated `...` syntax\n+        // Check for deprecated `...` syntax.\n         if self.token == token::DotDotDot {\n             self.err_dotdotdot_syntax(self.token.span);\n         }\n@@ -389,7 +389,7 @@ impl<'a> Parser<'a> {\n         Ok(self.mk_expr(lo.to(hi), r, attrs))\n     }\n \n-    /// Parse a prefix-unary-operator expr\n+    /// Parses a prefix-unary-operator expr.\n     fn parse_prefix_expr(\n         &mut self,\n         already_parsed_attrs: Option<ThinVec<Attribute>>\n@@ -549,7 +549,7 @@ impl<'a> Parser<'a> {\n                         let expr = mk_expr(self, P(Ty {\n                             span: path.span,\n                             node: TyKind::Path(None, path),\n-                            id: ast::DUMMY_NODE_ID\n+                            id: DUMMY_NODE_ID,\n                         }));\n \n                         let expr_str = self.span_to_snippet(expr.span)\n@@ -565,7 +565,7 @@ impl<'a> Parser<'a> {\n                                 expr.span,\n                                 &format!(\"try {} the cast value\", op_verb),\n                                 format!(\"({})\", expr_str),\n-                                Applicability::MachineApplicable\n+                                Applicability::MachineApplicable,\n                             )\n                             .emit();\n \n@@ -741,7 +741,6 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-\n     /// At the bottom (top?) of the precedence hierarchy,\n     /// Parses things like parenthesized exprs, macros, `return`, etc.\n     ///\n@@ -755,7 +754,7 @@ impl<'a> Parser<'a> {\n         // added to the return value after the fact.\n         //\n         // Therefore, prevent sub-parser from parsing\n-        // attributes by giving them a empty \"already parsed\" list.\n+        // attributes by giving them a empty \"already-parsed\" list.\n         let mut attrs = ThinVec::new();\n \n         let lo = self.token.span;\n@@ -778,7 +777,7 @@ impl<'a> Parser<'a> {\n             }\n         }\n \n-        // Note: when adding new syntax here, don't forget to adjust TokenKind::can_begin_expr().\n+        // Note: when adding new syntax here, don't forget to adjust `TokenKind::can_begin_expr()`.\n         match self.token.kind {\n             // This match arm is a special-case of the `_` match arm below and\n             // could be removed without changing functionality, but it's faster\n@@ -791,16 +790,16 @@ impl<'a> Parser<'a> {\n \n                 attrs.extend(self.parse_inner_attributes()?);\n \n-                // (e) is parenthesized e\n-                // (e,) is a tuple with only one field, e\n+                // `(e)` is parenthesized `e`.\n+                // `(e,)` is a tuple with only one field, `e`.\n                 let mut es = vec![];\n                 let mut trailing_comma = false;\n                 let mut recovered = false;\n                 while self.token != token::CloseDelim(token::Paren) {\n                     es.push(match self.parse_expr() {\n                         Ok(es) => es,\n                         Err(mut err) => {\n-                            // recover from parse error in tuple list\n+                            // Recover from parse error in tuple list.\n                             match self.token.kind {\n                                 token::Ident(name, false)\n                                 if name == kw::Underscore && self.look_ahead(1, |t| {\n@@ -844,29 +843,29 @@ impl<'a> Parser<'a> {\n                 return self.parse_block_expr(None, lo, BlockCheckMode::Default, attrs);\n             }\n             token::BinOp(token::Or) | token::OrOr => {\n-                return self.parse_lambda_expr(attrs);\n+                return self.parse_closure(attrs);\n             }\n             token::OpenDelim(token::Bracket) => {\n                 self.bump();\n \n                 attrs.extend(self.parse_inner_attributes()?);\n \n                 if self.eat(&token::CloseDelim(token::Bracket)) {\n-                    // Empty vector.\n+                    // Empty vector\n                     ex = ExprKind::Array(Vec::new());\n                 } else {\n-                    // Nonempty vector.\n+                    // Non-empty vector\n                     let first_expr = self.parse_expr()?;\n                     if self.eat(&token::Semi) {\n-                        // Repeating array syntax: [ 0; 512 ]\n+                        // Repeating array syntax: `[ 0; 512 ]`\n                         let count = AnonConst {\n-                            id: ast::DUMMY_NODE_ID,\n+                            id: DUMMY_NODE_ID,\n                             value: self.parse_expr()?,\n                         };\n                         self.expect(&token::CloseDelim(token::Bracket))?;\n                         ex = ExprKind::Repeat(first_expr, count);\n                     } else if self.eat(&token::Comma) {\n-                        // Vector with two or more elements.\n+                        // Vector with two or more elements\n                         let remaining_exprs = self.parse_seq_to_end(\n                             &token::CloseDelim(token::Bracket),\n                             SeqSep::trailing_allowed(token::Comma),\n@@ -876,7 +875,7 @@ impl<'a> Parser<'a> {\n                         exprs.extend(remaining_exprs);\n                         ex = ExprKind::Array(exprs);\n                     } else {\n-                        // Vector with one element.\n+                        // Vector with one element\n                         self.expect(&token::CloseDelim(token::Bracket))?;\n                         ex = ExprKind::Array(vec![first_expr]);\n                     }\n@@ -892,7 +891,7 @@ impl<'a> Parser<'a> {\n                 if self.token.is_path_start() {\n                     let path = self.parse_path(PathStyle::Expr)?;\n \n-                    // `!`, as an operator, is prefix, so we know this isn't that\n+                    // `!`, as an operator, is prefix, so we know this isn't that.\n                     if self.eat(&token::Not) {\n                         // MACRO INVOCATION expression\n                         let (delim, tts) = self.expect_delimited_token_tree()?;\n@@ -920,7 +919,7 @@ impl<'a> Parser<'a> {\n                     return self.maybe_recover_from_bad_qpath(expr, true);\n                 }\n                 if self.check_keyword(kw::Move) || self.check_keyword(kw::Static) {\n-                    return self.parse_lambda_expr(attrs);\n+                    return self.parse_closure(attrs);\n                 }\n                 if self.eat_keyword(kw::If) {\n                     return self.parse_if_expr(attrs);\n@@ -991,13 +990,13 @@ impl<'a> Parser<'a> {\n                     return self.parse_try_block(lo, attrs);\n                 }\n \n-                // Span::rust_2018() is somewhat expensive; don't get it repeatedly.\n+                // `Span::rust_2018()` is somewhat expensive; don't get it repeatedly.\n                 let is_span_rust_2018 = self.token.span.rust_2018();\n                 if is_span_rust_2018 && self.check_keyword(kw::Async) {\n-                    return if self.is_async_block() { // check for `async {` and `async move {`\n+                    return if self.is_async_block() { // Check for `async {` and `async move {`.\n                         self.parse_async_block(attrs)\n                     } else {\n-                        self.parse_lambda_expr(attrs)\n+                        self.parse_closure(attrs)\n                     };\n                 }\n                 if self.eat_keyword(kw::Return) {\n@@ -1043,13 +1042,12 @@ impl<'a> Parser<'a> {\n                         // recovery in order to keep the error count down. Fixing the\n                         // delimiters will possibly also fix the bare semicolon found in\n                         // expression context. For example, silence the following error:\n-                        // ```\n-                        // error: expected expression, found `;`\n-                        //  --> file.rs:2:13\n-                        //   |\n-                        // 2 |     foo(bar(;\n-                        //   |             ^ expected expression\n-                        // ```\n+                        //\n+                        //     error: expected expression, found `;`\n+                        //      --> file.rs:2:13\n+                        //       |\n+                        //     2 |     foo(bar(;\n+                        //       |             ^ expected expression\n                         self.bump();\n                         return Ok(self.mk_expr(self.token.span, ExprKind::Err, ThinVec::new()));\n                     }\n@@ -1096,11 +1094,11 @@ impl<'a> Parser<'a> {\n         attrs.extend(self.parse_inner_attributes()?);\n \n         let blk = self.parse_block_tail(lo, blk_mode)?;\n-        return Ok(self.mk_expr(blk.span, ExprKind::Block(blk, opt_label), attrs));\n+        Ok(self.mk_expr(blk.span, ExprKind::Block(blk, opt_label), attrs))\n     }\n \n-    /// Parses `move |args| expr`.\n-    fn parse_lambda_expr(&mut self, attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n+    /// Parses a closure (e.g., `move |args| expr`).\n+    fn parse_closure(&mut self, attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         let lo = self.token.span;\n \n         let movability = if self.eat_keyword(kw::Static) {\n@@ -1115,7 +1113,7 @@ impl<'a> Parser<'a> {\n             IsAsync::NotAsync\n         };\n         if asyncness.is_async() {\n-            // Feature gate `async ||` closures.\n+            // Feature-gate `async ||` closures.\n             self.sess.gated_spans.async_closure.borrow_mut().push(self.prev_span);\n         }\n \n@@ -1128,8 +1126,7 @@ impl<'a> Parser<'a> {\n                 self.parse_expr_res(restrictions, None)?\n             },\n             _ => {\n-                // If an explicit return type is given, require a\n-                // block to appear (RFC 968).\n+                // If an explicit return type is given, require a block to appear (RFC 968).\n                 let body_lo = self.token.span;\n                 self.parse_block_expr(None, body_lo, BlockCheckMode::Default, ThinVec::new())?\n             }\n@@ -1141,7 +1138,7 @@ impl<'a> Parser<'a> {\n             attrs))\n     }\n \n-    /// Parse an optional `move` prefix to a closure lke construct.\n+    /// Parses an optional `move` prefix to a closure lke construct.\n     fn parse_capture_clause(&mut self) -> CaptureBy {\n         if self.eat_keyword(kw::Move) {\n             CaptureBy::Value\n@@ -1176,7 +1173,7 @@ impl<'a> Parser<'a> {\n         }))\n     }\n \n-    /// Parses a parameter in a lambda header (e.g., `|arg, arg|`).\n+    /// Parses a parameter in a closure header (e.g., `|arg, arg|`).\n     fn parse_fn_block_param(&mut self) -> PResult<'a, Param> {\n         let lo = self.token.span;\n         let attrs = self.parse_param_attributes()?;\n@@ -1185,7 +1182,7 @@ impl<'a> Parser<'a> {\n             self.parse_ty()?\n         } else {\n             P(Ty {\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 node: TyKind::Infer,\n                 span: self.prev_span,\n             })\n@@ -1196,7 +1193,7 @@ impl<'a> Parser<'a> {\n             ty: t,\n             pat,\n             span,\n-            id: ast::DUMMY_NODE_ID\n+            id: DUMMY_NODE_ID\n         })\n     }\n \n@@ -1233,7 +1230,7 @@ impl<'a> Parser<'a> {\n         Ok(self.mk_expr(lo.to(hi), ExprKind::If(cond, thn, els), attrs))\n     }\n \n-    /// Parse the condition of a `if`- or `while`-expression\n+    /// Parses the condition of a `if` or `while` expression.\n     fn parse_cond_expr(&mut self) -> PResult<'a, P<Expr>> {\n         let cond = self.parse_expr_res(Restrictions::NO_STRUCT_LITERAL, None)?;\n \n@@ -1261,7 +1258,7 @@ impl<'a> Parser<'a> {\n         Ok(self.mk_expr(span, ExprKind::Let(pat, expr), attrs))\n     }\n \n-    /// `else` token already eaten\n+    /// Parses an `else { ... }` expression (`else` token already eaten).\n     fn parse_else_expr(&mut self) -> PResult<'a, P<Expr>> {\n         if self.eat_keyword(kw::If) {\n             return self.parse_if_expr(ThinVec::new());\n@@ -1271,7 +1268,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Parse a 'for' .. 'in' expression ('for' token already eaten)\n+    /// Parses a `for ... in` expression (`for` token already eaten).\n     fn parse_for_expr(\n         &mut self,\n         opt_label: Option<Label>,\n@@ -1327,7 +1324,7 @@ impl<'a> Parser<'a> {\n         Ok(self.mk_expr(span, ExprKind::While(cond, body, opt_label), attrs))\n     }\n \n-    /// Parse `loop {...}`, `loop` token already eaten.\n+    /// Parses `loop { ... }` (`loop` token already eaten).\n     fn parse_loop_expr(\n         &mut self,\n         opt_label: Option<Label>,\n@@ -1350,7 +1347,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    // `match` token already eaten\n+    /// Parses a `match ... { ... }` expression (`match` token already eaten).\n     fn parse_match_expr(&mut self, mut attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         let match_span = self.prev_span;\n         let lo = self.prev_span;\n@@ -1457,7 +1454,7 @@ impl<'a> Parser<'a> {\n             guard,\n             body: expr,\n             span: lo.to(hi),\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n         })\n     }\n \n@@ -1491,7 +1488,7 @@ impl<'a> Parser<'a> {\n         self.token.is_keyword(kw::Try) &&\n         self.look_ahead(1, |t| *t == token::OpenDelim(token::Brace)) &&\n         self.token.span.rust_2018() &&\n-        // prevent `while try {} {}`, `if try {} {} else {}`, etc.\n+        // Prevent `while try {} {}`, `if try {} {} else {}`, etc.\n         !self.restrictions.contains(Restrictions::NO_STRUCT_LITERAL)\n     }\n \n@@ -1504,7 +1501,7 @@ impl<'a> Parser<'a> {\n         attrs.extend(iattrs);\n         Ok(self.mk_expr(\n             span_lo.to(body.span),\n-            ExprKind::Async(capture_clause, ast::DUMMY_NODE_ID, body), attrs))\n+            ExprKind::Async(capture_clause, DUMMY_NODE_ID, body), attrs))\n     }\n \n     fn is_async_block(&self) -> bool {\n@@ -1527,18 +1524,18 @@ impl<'a> Parser<'a> {\n     ) -> Option<PResult<'a, P<Expr>>> {\n         let struct_allowed = !self.restrictions.contains(Restrictions::NO_STRUCT_LITERAL);\n         let certainly_not_a_block = || self.look_ahead(1, |t| t.is_ident()) && (\n-            // `{ ident, ` cannot start a block\n+            // `{ ident, ` cannot start a block.\n             self.look_ahead(2, |t| t == &token::Comma) ||\n             self.look_ahead(2, |t| t == &token::Colon) && (\n-                // `{ ident: token, ` cannot start a block\n+                // `{ ident: token, ` cannot start a block.\n                 self.look_ahead(4, |t| t == &token::Comma) ||\n-                // `{ ident: ` cannot start a block unless it's a type ascription `ident: Type`\n+                // `{ ident: ` cannot start a block unless it's a type ascription `ident: Type`.\n                 self.look_ahead(3, |t| !t.can_begin_type())\n             )\n         );\n \n         if struct_allowed || certainly_not_a_block() {\n-            // This is a struct literal, but we don't can't accept them here\n+            // This is a struct literal, but we don't can't accept them here.\n             let expr = self.parse_struct_expr(lo, path.clone(), attrs.clone());\n             if let (Ok(expr), false) = (&expr, struct_allowed) {\n                 self.struct_span_err(\n@@ -1606,14 +1603,14 @@ impl<'a> Parser<'a> {\n             let mut recovery_field = None;\n             if let token::Ident(name, _) = self.token.kind {\n                 if !self.token.is_reserved_ident() && self.look_ahead(1, |t| *t == token::Colon) {\n-                    // Use in case of error after field-looking code: `S { foo: () with a }`\n+                    // Use in case of error after field-looking code: `S { foo: () with a }`.\n                     recovery_field = Some(ast::Field {\n                         ident: Ident::new(name, self.token.span),\n                         span: self.token.span,\n                         expr: self.mk_expr(self.token.span, ExprKind::Err, ThinVec::new()),\n                         is_shorthand: false,\n                         attrs: ThinVec::new(),\n-                        id: ast::DUMMY_NODE_ID,\n+                        id: DUMMY_NODE_ID,\n                     });\n                 }\n             }\n@@ -1639,7 +1636,7 @@ impl<'a> Parser<'a> {\n             match self.expect_one_of(&[token::Comma],\n                                      &[token::CloseDelim(token::Brace)]) {\n                 Ok(_) => if let Some(f) = parsed_field.or(recovery_field) {\n-                    // only include the field if there's no parse error for the field name\n+                    // Only include the field if there's no parse error for the field name.\n                     fields.push(f);\n                 }\n                 Err(mut e) => {\n@@ -1659,7 +1656,7 @@ impl<'a> Parser<'a> {\n         return Ok(self.mk_expr(span, ExprKind::Struct(pth, fields, base), attrs));\n     }\n \n-    /// Parse ident (COLON expr)?\n+    /// Parses `ident (COLON expr)?`.\n     fn parse_field(&mut self) -> PResult<'a, Field> {\n         let attrs = self.parse_outer_attributes()?;\n         let lo = self.token.span;\n@@ -1699,7 +1696,7 @@ impl<'a> Parser<'a> {\n             expr,\n             is_shorthand,\n             attrs: attrs.into(),\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n         })\n     }\n \n@@ -1772,6 +1769,6 @@ impl<'a> Parser<'a> {\n     }\n \n     crate fn mk_expr(&self, span: Span, node: ExprKind, attrs: ThinVec<Attribute>) -> P<Expr> {\n-        P(Expr { node, span, attrs, id: ast::DUMMY_NODE_ID })\n+        P(Expr { node, span, attrs, id: DUMMY_NODE_ID })\n     }\n }"}, {"sha": "be7fc48fdaf66e639756cbe746522beffc0e5c3b", "filename": "src/libsyntax/parse/parser/item.rs", "status": "modified", "additions": 58, "deletions": 57, "changes": 115, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fitem.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -2,34 +2,36 @@ use super::{Parser, PResult, PathStyle, SemiColonMode, BlockMode};\n \n use crate::maybe_whole;\n use crate::ptr::P;\n-use crate::ast::{self, Ident, Attribute, AttrStyle};\n-use crate::ast::{Item, ItemKind, ImplItem, TraitItem, TraitItemKind};\n-use crate::ast::{UseTree, UseTreeKind, PathSegment};\n-use crate::ast::{IsAuto, Constness, IsAsync, Unsafety, Defaultness};\n-use crate::ast::{Visibility, VisibilityKind, Mutability, FnDecl, FnHeader};\n-use crate::ast::{ForeignItem, ForeignItemKind};\n-use crate::ast::{Ty, TyKind, GenericBounds, TraitRef};\n-use crate::ast::{EnumDef, VariantData, StructField, AnonConst};\n-use crate::ast::{Mac, MacDelimiter};\n+use crate::ast::{\n+    self, DUMMY_NODE_ID, Ident, Attribute, AttrStyle,\n+    Item, ItemKind, ImplItem, TraitItem, TraitItemKind,\n+    UseTree, UseTreeKind, PathSegment,\n+    IsAuto, Constness, IsAsync, Unsafety, Defaultness,\n+    Visibility, VisibilityKind, Mutability, FnDecl, FnHeader,\n+    ForeignItem, ForeignItemKind,\n+    Ty, TyKind, Generics, GenericBounds, TraitRef,\n+    EnumDef, VariantData, StructField, AnonConst,\n+    Mac, MacDelimiter,\n+};\n use crate::ext::base::DummyResult;\n use crate::parse::token;\n use crate::parse::parser::maybe_append;\n-use crate::parse::diagnostics::{Error};\n+use crate::parse::diagnostics::Error;\n use crate::tokenstream::{TokenTree, TokenStream};\n use crate::source_map::{respan, Span, Spanned};\n use crate::symbol::{kw, sym};\n \n use std::mem;\n use log::debug;\n-use rustc_target::spec::abi::{Abi};\n+use rustc_target::spec::abi::Abi;\n use errors::{Applicability, DiagnosticBuilder, DiagnosticId};\n \n-/// Whether the type alias or associated type is a concrete type or an opaque type\n+/// Whether the type alias or associated type is a concrete type or an opaque type.\n #[derive(Debug)]\n pub enum AliasKind {\n-    /// Just a new name for the same type\n+    /// Just a new name for the same type.\n     Weak(P<Ty>),\n-    /// Only trait impls of the type will be usable, not the actual type itself\n+    /// Only trait impls of the type will be usable, not the actual type itself.\n     OpaqueTy(GenericBounds),\n }\n \n@@ -200,7 +202,7 @@ impl<'a> Parser<'a> {\n             return Ok(Some(item));\n         }\n \n-        // Parse `async unsafe? fn`.\n+        // Parses `async unsafe? fn`.\n         if self.check_keyword(kw::Async) {\n             let async_span = self.token.span;\n             if self.is_keyword_ahead(1, &[kw::Fn])\n@@ -214,8 +216,8 @@ impl<'a> Parser<'a> {\n                 let (ident, item_, extra_attrs) =\n                     self.parse_item_fn(unsafety,\n                                     respan(async_span, IsAsync::Async {\n-                                        closure_id: ast::DUMMY_NODE_ID,\n-                                        return_impl_trait_id: ast::DUMMY_NODE_ID,\n+                                        closure_id: DUMMY_NODE_ID,\n+                                        return_impl_trait_id: DUMMY_NODE_ID,\n                                     }),\n                                     respan(fn_span, Constness::NotConst),\n                                     Abi::Rust)?;\n@@ -286,7 +288,7 @@ impl<'a> Parser<'a> {\n             && self.look_ahead(1, |t| *t != token::OpenDelim(token::Brace)) {\n             // UNSAFE FUNCTION ITEM\n             self.bump(); // `unsafe`\n-            // `{` is also expected after `unsafe`, in case of error, include it in the diagnostic\n+            // `{` is also expected after `unsafe`; in case of error, include it in the diagnostic.\n             self.check(&token::OpenDelim(token::Brace));\n             let abi = if self.eat_keyword(kw::Extern) {\n                 self.parse_opt_abi()?.unwrap_or(Abi::C)\n@@ -521,7 +523,7 @@ impl<'a> Parser<'a> {\n \n             let mac_lo = self.token.span;\n \n-            // item macro.\n+            // Item macro\n             let path = self.parse_path(PathStyle::Mod)?;\n             self.expect(&token::Not)?;\n             let (delim, tts) = self.expect_delimited_token_tree()?;\n@@ -659,7 +661,7 @@ impl<'a> Parser<'a> {\n         let mut generics = if self.choose_generics_over_qpath() {\n             self.parse_generics()?\n         } else {\n-            ast::Generics::default()\n+            Generics::default()\n         };\n \n         // Disambiguate `impl !Trait for Type { ... }` and `impl ! { ... }` for the never type.\n@@ -676,7 +678,7 @@ impl<'a> Parser<'a> {\n                           self.look_ahead(1, |t| t != &token::Lt) {\n             let span = self.prev_span.between(self.token.span);\n             self.struct_span_err(span, \"missing trait in a trait impl\").emit();\n-            P(Ty { node: TyKind::Path(None, err_path(span)), span, id: ast::DUMMY_NODE_ID })\n+            P(Ty { node: TyKind::Path(None, err_path(span)), span, id: DUMMY_NODE_ID })\n         } else {\n             self.parse_ty()?\n         };\n@@ -798,15 +800,15 @@ impl<'a> Parser<'a> {\n             self.expect(&token::Eq)?;\n             let expr = self.parse_expr()?;\n             self.expect(&token::Semi)?;\n-            (name, ast::ImplItemKind::Const(typ, expr), ast::Generics::default())\n+            (name, ast::ImplItemKind::Const(typ, expr), Generics::default())\n         } else {\n             let (name, inner_attrs, generics, node) = self.parse_impl_method(&vis, at_end)?;\n             attrs.extend(inner_attrs);\n             (name, node, generics)\n         };\n \n         Ok(ImplItem {\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(self.prev_span),\n             ident: name,\n             vis,\n@@ -847,14 +849,13 @@ impl<'a> Parser<'a> {\n             !self.is_keyword_ahead(1, &[kw::Fn, kw::Unsafe])\n     }\n \n-    /// Parse a method or a macro invocation in a trait impl.\n+    /// Parses a method or a macro invocation in a trait impl.\n     fn parse_impl_method(&mut self, vis: &Visibility, at_end: &mut bool)\n-                         -> PResult<'a, (Ident, Vec<Attribute>, ast::Generics,\n-                             ast::ImplItemKind)> {\n-        // code copied from parse_macro_use_or_failure... abstraction!\n+                         -> PResult<'a, (Ident, Vec<Attribute>, Generics, ast::ImplItemKind)> {\n+        // FIXME: code copied from `parse_macro_use_or_failure` -- use abstraction!\n         if let Some(mac) = self.parse_assoc_macro_invoc(\"impl\", Some(vis), at_end)? {\n             // method macro\n-            Ok((Ident::invalid(), vec![], ast::Generics::default(),\n+            Ok((Ident::invalid(), vec![], Generics::default(),\n                 ast::ImplItemKind::Macro(mac)))\n         } else {\n             let (constness, unsafety, asyncness, abi) = self.parse_fn_front_matter()?;\n@@ -930,7 +931,7 @@ impl<'a> Parser<'a> {\n         };\n \n         if self.eat(&token::Eq) {\n-            // it's a trait alias\n+            // It's a trait alias.\n             let bounds = self.parse_generic_bounds(None)?;\n             tps.where_clause = self.parse_where_clause()?;\n             self.expect(&token::Semi)?;\n@@ -948,7 +949,7 @@ impl<'a> Parser<'a> {\n             }\n             Ok((ident, ItemKind::TraitAlias(tps, bounds), None))\n         } else {\n-            // it's a normal trait\n+            // It's a normal trait.\n             tps.where_clause = self.parse_where_clause()?;\n             self.expect(&token::OpenDelim(token::Brace))?;\n             let mut trait_items = vec![];\n@@ -1023,10 +1024,10 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::Semi)?;\n                 None\n             };\n-            (ident, TraitItemKind::Const(ty, default), ast::Generics::default())\n+            (ident, TraitItemKind::Const(ty, default), Generics::default())\n         } else if let Some(mac) = self.parse_assoc_macro_invoc(\"trait\", None, &mut false)? {\n             // trait item macro.\n-            (Ident::invalid(), ast::TraitItemKind::Macro(mac), ast::Generics::default())\n+            (Ident::invalid(), ast::TraitItemKind::Macro(mac), Generics::default())\n         } else {\n             let (constness, unsafety, asyncness, abi) = self.parse_fn_front_matter()?;\n \n@@ -1089,7 +1090,7 @@ impl<'a> Parser<'a> {\n         };\n \n         Ok(TraitItem {\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             ident: name,\n             attrs,\n             generics,\n@@ -1103,7 +1104,7 @@ impl<'a> Parser<'a> {\n     ///\n     ///     TraitItemAssocTy = Ident [\"<\"...\">\"] [\":\" [GenericBounds]] [\"where\" ...] [\"=\" Ty]\n     fn parse_trait_item_assoc_ty(&mut self)\n-        -> PResult<'a, (Ident, TraitItemKind, ast::Generics)> {\n+        -> PResult<'a, (Ident, TraitItemKind, Generics)> {\n         let ident = self.parse_ident()?;\n         let mut generics = self.parse_generics()?;\n \n@@ -1165,7 +1166,7 @@ impl<'a> Parser<'a> {\n                     UseTreeKind::Nested(self.parse_use_tree_list()?)\n                 }\n             } else {\n-                UseTreeKind::Simple(self.parse_rename()?, ast::DUMMY_NODE_ID, ast::DUMMY_NODE_ID)\n+                UseTreeKind::Simple(self.parse_rename()?, DUMMY_NODE_ID, DUMMY_NODE_ID)\n             }\n         };\n \n@@ -1178,7 +1179,7 @@ impl<'a> Parser<'a> {\n     /// USE_TREE_LIST = \u00d8 | (USE_TREE `,`)* USE_TREE [`,`]\n     /// ```\n     fn parse_use_tree_list(&mut self) -> PResult<'a, Vec<(UseTree, ast::NodeId)>> {\n-        self.parse_delim_comma_seq(token::Brace, |p| Ok((p.parse_use_tree()?, ast::DUMMY_NODE_ID)))\n+        self.parse_delim_comma_seq(token::Brace, |p| Ok((p.parse_use_tree()?, DUMMY_NODE_ID)))\n             .map(|(r, _)| r)\n     }\n \n@@ -1240,9 +1241,9 @@ impl<'a> Parser<'a> {\n         let mut idents = vec![];\n         let mut replacement = vec![];\n         let mut fixed_crate_name = false;\n-        // Accept `extern crate name-like-this` for better diagnostics\n+        // Accept `extern crate name-like-this` for better diagnostics.\n         let dash = token::BinOp(token::BinOpToken::Minus);\n-        if self.token == dash {  // Do not include `-` as part of the expected tokens list\n+        if self.token == dash {  // Do not include `-` as part of the expected tokens list.\n             while self.eat(&dash) {\n                 fixed_crate_name = true;\n                 replacement.push((self.prev_span, \"_\".to_string()));\n@@ -1283,7 +1284,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parses the name and optional generic types of a function header.\n-    fn parse_fn_header(&mut self) -> PResult<'a, (Ident, ast::Generics)> {\n+    fn parse_fn_header(&mut self) -> PResult<'a, (Ident, Generics)> {\n         let id = self.parse_ident()?;\n         let generics = self.parse_generics()?;\n         Ok((id, generics))\n@@ -1379,7 +1380,7 @@ impl<'a> Parser<'a> {\n                     ForeignItem {\n                         ident: Ident::invalid(),\n                         span: lo.to(self.prev_span),\n-                        id: ast::DUMMY_NODE_ID,\n+                        id: DUMMY_NODE_ID,\n                         attrs,\n                         vis: visibility,\n                         node: ForeignItemKind::Macro(mac),\n@@ -1415,7 +1416,7 @@ impl<'a> Parser<'a> {\n             ident,\n             attrs,\n             node: ForeignItemKind::Fn(decl, generics),\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(hi),\n             vis,\n         })\n@@ -1435,7 +1436,7 @@ impl<'a> Parser<'a> {\n             ident,\n             attrs,\n             node: ForeignItemKind::Static(ty, mutbl),\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(hi),\n             vis,\n         })\n@@ -1453,15 +1454,15 @@ impl<'a> Parser<'a> {\n             ident,\n             attrs,\n             node: ForeignItemKind::Ty,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(hi),\n             vis\n         })\n     }\n \n     fn is_static_global(&mut self) -> bool {\n         if self.check_keyword(kw::Static) {\n-            // Check if this could be a closure\n+            // Check if this could be a closure.\n             !self.look_ahead(1, |token| {\n                 if token.is_keyword(kw::Move) {\n                     return true;\n@@ -1492,7 +1493,7 @@ impl<'a> Parser<'a> {\n \n     /// Parses `type Foo = Bar;` or returns `None`\n     /// without modifying the parser state.\n-    fn eat_type(&mut self) -> Option<PResult<'a, (Ident, AliasKind, ast::Generics)>> {\n+    fn eat_type(&mut self) -> Option<PResult<'a, (Ident, AliasKind, Generics)>> {\n         // This parses the grammar:\n         //     Ident [\"<\"...\">\"] [\"where\" ...] (\"=\" | \":\") Ty \";\"\n         if self.eat_keyword(kw::Type) {\n@@ -1503,7 +1504,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parses a type alias or opaque type.\n-    fn parse_type_alias(&mut self) -> PResult<'a, (Ident, AliasKind, ast::Generics)> {\n+    fn parse_type_alias(&mut self) -> PResult<'a, (Ident, AliasKind, Generics)> {\n         let ident = self.parse_ident()?;\n         let mut tps = self.parse_generics()?;\n         tps.where_clause = self.parse_where_clause()?;\n@@ -1536,7 +1537,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parses the part of an enum declaration following the `{`.\n-    fn parse_enum_def(&mut self, _generics: &ast::Generics) -> PResult<'a, EnumDef> {\n+    fn parse_enum_def(&mut self, _generics: &Generics) -> PResult<'a, EnumDef> {\n         let mut variants = Vec::new();\n         while self.token != token::CloseDelim(token::Brace) {\n             let variant_attrs = self.parse_outer_attributes()?;\n@@ -1552,15 +1553,15 @@ impl<'a> Parser<'a> {\n             } else if self.check(&token::OpenDelim(token::Paren)) {\n                 VariantData::Tuple(\n                     self.parse_tuple_struct_body()?,\n-                    ast::DUMMY_NODE_ID,\n+                    DUMMY_NODE_ID,\n                 )\n             } else {\n-                VariantData::Unit(ast::DUMMY_NODE_ID)\n+                VariantData::Unit(DUMMY_NODE_ID)\n             };\n \n             let disr_expr = if self.eat(&token::Eq) {\n                 Some(AnonConst {\n-                    id: ast::DUMMY_NODE_ID,\n+                    id: DUMMY_NODE_ID,\n                     value: self.parse_expr()?,\n                 })\n             } else {\n@@ -1569,7 +1570,7 @@ impl<'a> Parser<'a> {\n \n             let vr = ast::Variant {\n                 ident,\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 attrs: variant_attrs,\n                 data: struct_def,\n                 disr_expr,\n@@ -1622,22 +1623,22 @@ impl<'a> Parser<'a> {\n             generics.where_clause = self.parse_where_clause()?;\n             if self.eat(&token::Semi) {\n                 // If we see a: `struct Foo<T> where T: Copy;` style decl.\n-                VariantData::Unit(ast::DUMMY_NODE_ID)\n+                VariantData::Unit(DUMMY_NODE_ID)\n             } else {\n                 // If we see: `struct Foo<T> where T: Copy { ... }`\n                 let (fields, recovered) = self.parse_record_struct_body()?;\n                 VariantData::Struct(fields, recovered)\n             }\n         // No `where` so: `struct Foo<T>;`\n         } else if self.eat(&token::Semi) {\n-            VariantData::Unit(ast::DUMMY_NODE_ID)\n+            VariantData::Unit(DUMMY_NODE_ID)\n         // Record-style struct definition\n         } else if self.token == token::OpenDelim(token::Brace) {\n             let (fields, recovered) = self.parse_record_struct_body()?;\n             VariantData::Struct(fields, recovered)\n         // Tuple-style struct definition with optional where-clause.\n         } else if self.token == token::OpenDelim(token::Paren) {\n-            let body = VariantData::Tuple(self.parse_tuple_struct_body()?, ast::DUMMY_NODE_ID);\n+            let body = VariantData::Tuple(self.parse_tuple_struct_body()?, DUMMY_NODE_ID);\n             generics.where_clause = self.parse_where_clause()?;\n             self.expect(&token::Semi)?;\n             body\n@@ -1726,7 +1727,7 @@ impl<'a> Parser<'a> {\n                 span: lo.to(ty.span),\n                 vis,\n                 ident: None,\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 ty,\n                 attrs,\n             })\n@@ -1817,7 +1818,7 @@ impl<'a> Parser<'a> {\n             span: lo.to(self.prev_span),\n             ident: Some(name),\n             vis,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             ty,\n             attrs,\n         })\n@@ -1909,7 +1910,7 @@ impl<'a> Parser<'a> {\n         P(Item {\n             ident,\n             attrs,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             node,\n             vis,\n             span,"}, {"sha": "2d2fb487d7df21c2b787ce7237fc0e76d2bc0929", "filename": "src/libsyntax/parse/parser/module.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fmodule.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fmodule.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fmodule.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -36,12 +36,12 @@ impl<'a> Parser<'a> {\n         krate\n     }\n \n-    /// Parse a `mod <foo> { ... }` or `mod <foo>;` item\n+    /// Parses a `mod <foo> { ... }` or `mod <foo>;` item.\n     pub(super) fn parse_item_mod(&mut self, outer_attrs: &[Attribute]) -> PResult<'a, ItemInfo> {\n         let (in_cfg, outer_attrs) = {\n             let mut strip_unconfigured = crate::config::StripUnconfigured {\n                 sess: self.sess,\n-                features: None, // don't perform gated feature checking\n+                features: None, // Don't perform gated feature checking.\n             };\n             let mut outer_attrs = outer_attrs.to_owned();\n             strip_unconfigured.process_cfg_attrs(&mut outer_attrs);\n@@ -57,7 +57,7 @@ impl<'a> Parser<'a> {\n                     self.submod_path(id, &outer_attrs, id_span)?;\n                 let (module, mut attrs) =\n                     self.eval_src_mod(path, directory_ownership, id.to_string(), id_span)?;\n-                // Record that we fetched the mod from an external file\n+                // Record that we fetched the mod from an external file.\n                 if warn {\n                     let attr = attr::mk_attr_outer(\n                         attr::mk_word_item(Ident::with_dummy_span(sym::warn_directory_ownership)));"}, {"sha": "49f8d58c6a762bc43a43885d5d0df4521f3ecf03", "filename": "src/libsyntax/parse/parser/pat.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fpat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fpat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fpat.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -844,14 +844,14 @@ impl<'a> Parser<'a> {\n         // Check if a colon exists one ahead. This means we're parsing a fieldname.\n         let hi;\n         let (subpat, fieldname, is_shorthand) = if self.look_ahead(1, |t| t == &token::Colon) {\n-            // Parsing a pattern of the form \"fieldname: pat\"\n+            // Parsing a pattern of the form `fieldname: pat`.\n             let fieldname = self.parse_field_name()?;\n             self.bump();\n             let pat = self.parse_pat_with_or_inner()?;\n             hi = pat.span;\n             (pat, fieldname, false)\n         } else {\n-            // Parsing a pattern of the form \"(box) (ref) (mut) fieldname\"\n+            // Parsing a pattern of the form `(box) (ref) (mut) fieldname`.\n             let is_box = self.eat_keyword(kw::Box);\n             let boxed_span = self.token.span;\n             let is_ref = self.eat_keyword(kw::Ref);"}, {"sha": "6a3ac2d73f8b2a5a99d7eb4a1a5e73e26396a03b", "filename": "src/libsyntax/parse/parser/stmt.rs", "status": "modified", "additions": 32, "deletions": 32, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fstmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Fparser%2Fstmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fstmt.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -5,20 +5,20 @@ use super::pat::GateOr;\n \n use crate::ptr::P;\n use crate::{maybe_whole, ThinVec};\n-use crate::ast::{self, Stmt, StmtKind, Local, Block, BlockCheckMode, Expr, ExprKind};\n+use crate::ast::{self, DUMMY_NODE_ID, Stmt, StmtKind, Local, Block, BlockCheckMode, Expr, ExprKind};\n use crate::ast::{Attribute, AttrStyle, VisibilityKind, MacStmtStyle, Mac, MacDelimiter};\n use crate::ext::base::DummyResult;\n use crate::parse::{classify, DirectoryOwnership};\n use crate::parse::diagnostics::Error;\n-use crate::parse::token::{self};\n+use crate::parse::token;\n use crate::source_map::{respan, Span};\n use crate::symbol::{kw, sym};\n \n use std::mem;\n use errors::Applicability;\n \n impl<'a> Parser<'a> {\n-    /// Parse a statement. This stops just before trailing semicolons on everything but items.\n+    /// Parses a statement. This stops just before trailing semicolons on everything but items.\n     /// e.g., a `StmtKind::Semi` parses to a `StmtKind::Expr`, leaving the trailing `;` unconsumed.\n     pub fn parse_stmt(&mut self) -> PResult<'a, Option<Stmt>> {\n         Ok(self.parse_stmt_(true))\n@@ -43,7 +43,7 @@ impl<'a> Parser<'a> {\n \n         Ok(Some(if self.eat_keyword(kw::Let) {\n             Stmt {\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 node: StmtKind::Local(self.parse_local(attrs.into())?),\n                 span: lo.to(self.prev_span),\n             }\n@@ -53,7 +53,7 @@ impl<'a> Parser<'a> {\n             lo,\n         )? {\n             Stmt {\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 node: StmtKind::Item(macro_def),\n                 span: lo.to(self.prev_span),\n             }\n@@ -85,7 +85,7 @@ impl<'a> Parser<'a> {\n                 })?;\n \n                 return Ok(Some(Stmt {\n-                    id: ast::DUMMY_NODE_ID,\n+                    id: DUMMY_NODE_ID,\n                     node: StmtKind::Expr(expr),\n                     span: lo.to(self.prev_span),\n                 }));\n@@ -114,17 +114,17 @@ impl<'a> Parser<'a> {\n             // We used to incorrectly stop parsing macro-expanded statements here.\n             // If the next token will be an error anyway but could have parsed with the\n             // earlier behavior, stop parsing here and emit a warning to avoid breakage.\n-            else if macro_legacy_warnings &&\n-                    self.token.can_begin_expr() &&\n-                    match self.token.kind {\n-                // These can continue an expression, so we can't stop parsing and warn.\n-                token::OpenDelim(token::Paren) | token::OpenDelim(token::Bracket) |\n-                token::BinOp(token::Minus) | token::BinOp(token::Star) |\n-                token::BinOp(token::And) | token::BinOp(token::Or) |\n-                token::AndAnd | token::OrOr |\n-                token::DotDot | token::DotDotDot | token::DotDotEq => false,\n-                _ => true,\n-            } {\n+            else if macro_legacy_warnings && self.token.can_begin_expr() &&\n+                match self.token.kind {\n+                    // These can continue an expression, so we can't stop parsing and warn.\n+                    token::OpenDelim(token::Paren) | token::OpenDelim(token::Bracket) |\n+                    token::BinOp(token::Minus) | token::BinOp(token::Star) |\n+                    token::BinOp(token::And) | token::BinOp(token::Or) |\n+                    token::AndAnd | token::OrOr |\n+                    token::DotDot | token::DotDotDot | token::DotDotEq => false,\n+                    _ => true,\n+                }\n+            {\n                 self.warn_missing_semicolon();\n                 StmtKind::Mac(P((mac, style, attrs.into())))\n             } else {\n@@ -135,7 +135,7 @@ impl<'a> Parser<'a> {\n                 StmtKind::Expr(e)\n             };\n             Stmt {\n-                id: ast::DUMMY_NODE_ID,\n+                id: DUMMY_NODE_ID,\n                 span: lo.to(hi),\n                 node,\n             }\n@@ -148,7 +148,7 @@ impl<'a> Parser<'a> {\n \n             match item {\n                 Some(i) => Stmt {\n-                    id: ast::DUMMY_NODE_ID,\n+                    id: DUMMY_NODE_ID,\n                     span: lo.to(i.span),\n                     node: StmtKind::Item(i),\n                 },\n@@ -178,7 +178,7 @@ impl<'a> Parser<'a> {\n                         // an empty tuple that spans the excess semicolons\n                         // to preserve this info until the lint stage\n                         return Ok(Some(Stmt {\n-                            id: ast::DUMMY_NODE_ID,\n+                            id: DUMMY_NODE_ID,\n                             span: lo.to(last_semi),\n                             node: StmtKind::Semi(self.mk_expr(lo.to(last_semi),\n                                 ExprKind::Tup(Vec::new()),\n@@ -196,7 +196,7 @@ impl<'a> Parser<'a> {\n                     let e = self.parse_expr_res(\n                         Restrictions::STMT_EXPR, Some(attrs.into()))?;\n                     Stmt {\n-                        id: ast::DUMMY_NODE_ID,\n+                        id: DUMMY_NODE_ID,\n                         span: lo.to(e.span),\n                         node: StmtKind::Expr(e),\n                     }\n@@ -218,7 +218,7 @@ impl<'a> Parser<'a> {\n             match self.parse_ty() {\n                 Ok(ty) => (None, Some(ty)),\n                 Err(mut err) => {\n-                    // Rewind to before attempting to parse the type and continue parsing\n+                    // Rewind to before attempting to parse the type and continue parsing.\n                     let parser_snapshot_after_type = self.clone();\n                     mem::replace(self, parser_snapshot_before_type);\n \n@@ -272,7 +272,7 @@ impl<'a> Parser<'a> {\n             ty,\n             pat,\n             init,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             span: lo.to(hi),\n             attrs,\n         }))\n@@ -334,18 +334,18 @@ impl<'a> Parser<'a> {\n             //    if (cond)\n             //      bar;\n             //\n-            // Which is valid in other languages, but not Rust.\n+            // which is valid in other languages, but not Rust.\n             match self.parse_stmt_without_recovery(false) {\n                 Ok(Some(stmt)) => {\n                     if self.look_ahead(1, |t| t == &token::OpenDelim(token::Brace))\n                         || do_not_suggest_help {\n-                        // if the next token is an open brace (e.g., `if a b {`), the place-\n-                        // inside-a-block suggestion would be more likely wrong than right\n+                        // If the next token is an open brace (e.g., `if a b {`), the place-\n+                        // inside-a-block suggestion would be more likely wrong than right.\n                         e.span_label(sp, \"expected `{`\");\n                         return Err(e);\n                     }\n                     let mut stmt_span = stmt.span;\n-                    // expand the span to include the semicolon, if it exists\n+                    // Expand the span to include the semicolon, if it exists.\n                     if self.eat(&token::Semi) {\n                         stmt_span = stmt_span.with_hi(self.prev_span.hi());\n                     }\n@@ -354,7 +354,7 @@ impl<'a> Parser<'a> {\n                             stmt_span,\n                             \"try placing this code inside a block\",\n                             format!(\"{{ {} }}\", snippet),\n-                            // speculative, has been misleading in the past (#46836)\n+                            // Speculative; has been misleading in the past (#46836).\n                             Applicability::MaybeIncorrect,\n                         );\n                     }\n@@ -399,7 +399,7 @@ impl<'a> Parser<'a> {\n                     err.emit();\n                     self.recover_stmt_(SemiColonMode::Ignore, BlockMode::Ignore);\n                     Some(Stmt {\n-                        id: ast::DUMMY_NODE_ID,\n+                        id: DUMMY_NODE_ID,\n                         node: StmtKind::Expr(DummyResult::raw_expr(self.token.span, true)),\n                         span: self.token.span,\n                     })\n@@ -415,15 +415,15 @@ impl<'a> Parser<'a> {\n         }\n         Ok(P(ast::Block {\n             stmts,\n-            id: ast::DUMMY_NODE_ID,\n+            id: DUMMY_NODE_ID,\n             rules: s,\n             span: lo.to(self.prev_span),\n         }))\n     }\n \n     /// Parses a statement, including the trailing semicolon.\n-    crate fn parse_full_stmt(&mut self, macro_legacy_warnings: bool) -> PResult<'a, Option<Stmt>> {\n-        // skip looking for a trailing semicolon when we have an interpolated statement\n+    pub fn parse_full_stmt(&mut self, macro_legacy_warnings: bool) -> PResult<'a, Option<Stmt>> {\n+        // Skip looking for a trailing semicolon when we have an interpolated statement.\n         maybe_whole!(self, NtStmt, |x| Some(x));\n \n         let mut stmt = match self.parse_stmt_without_recovery(macro_legacy_warnings)? {"}, {"sha": "5cb59b3f82790a0d9236927671632a80579cb28b", "filename": "src/libsyntax/parse/tests.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fparse%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftests.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -25,20 +25,20 @@ fn parse_item_from_source_str(name: FileName, source: String, sess: &ParseSess)\n     new_parser_from_source_str(sess, name, source).parse_item()\n }\n \n-// produce a syntax_pos::span\n+// Produces a `syntax_pos::span`.\n fn sp(a: u32, b: u32) -> Span {\n     Span::with_root_ctxt(BytePos(a), BytePos(b))\n }\n \n-/// Parse a string, return an expr\n+/// Parses a string, return an expression.\n fn string_to_expr(source_str : String) -> P<ast::Expr> {\n     let ps = ParseSess::new(FilePathMapping::empty());\n     with_error_checking_parse(source_str, &ps, |p| {\n         p.parse_expr()\n     })\n }\n \n-/// Parse a string, return an item\n+/// Parses a string, returns an item.\n fn string_to_item(source_str : String) -> Option<P<ast::Item>> {\n     let ps = ParseSess::new(FilePathMapping::empty());\n     with_error_checking_parse(source_str, &ps, |p| {\n@@ -53,7 +53,7 @@ fn string_to_item(source_str : String) -> Option<P<ast::Item>> {\n     })\n }\n \n-// check the token-tree-ization of macros\n+// Checks the token-tree-ization of macros.\n #[test]\n fn string_to_tts_macro () {\n     with_default_globals(|| {"}, {"sha": "5d8498f8b5d260278c6f48f480b5d056dfc99ff4", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 25, "deletions": 27, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -119,19 +119,19 @@ pub fn print_crate<'a>(cm: &'a SourceMap,\n     if is_expanded && sess.injected_crate_name.try_get().is_some() {\n         // We need to print `#![no_std]` (and its feature gate) so that\n         // compiling pretty-printed source won't inject libstd again.\n-        // However we don't want these attributes in the AST because\n+        // However, we don't want these attributes in the AST because\n         // of the feature gate, so we fake them up here.\n \n-        // #![feature(prelude_import)]\n+        // `#![feature(prelude_import)]`\n         let pi_nested = attr::mk_nested_word_item(ast::Ident::with_dummy_span(sym::prelude_import));\n         let list = attr::mk_list_item(ast::Ident::with_dummy_span(sym::feature), vec![pi_nested]);\n         let fake_attr = attr::mk_attr_inner(list);\n         s.print_attribute(&fake_attr);\n \n-        // Currently on Rust 2018 we don't have `extern crate std;` at the crate\n+        // Currently, in Rust 2018 we don't have `extern crate std;` at the crate\n         // root, so this is not needed, and actually breaks things.\n         if sess.edition == syntax_pos::edition::Edition::Edition2015 {\n-            // #![no_std]\n+            // `#![no_std]`\n             let no_std_meta = attr::mk_word_item(ast::Ident::with_dummy_span(sym::no_std));\n             let fake_attr = attr::mk_attr_inner(no_std_meta);\n             s.print_attribute(&fake_attr);\n@@ -398,9 +398,9 @@ pub fn vis_to_string(v: &ast::Visibility) -> String {\n \n fn block_to_string(blk: &ast::Block) -> String {\n     to_string(|s| {\n-        // containing cbox, will be closed by print-block at }\n+        // Containing cbox, will be closed by `print_block` at `}`.\n         s.cbox(INDENT_UNIT);\n-        // head-ibox, will be closed by print-block after {\n+        // Head-ibox, will be closed by `print_block` after `{`.\n         s.ibox(0);\n         s.print_block(blk)\n     })\n@@ -443,7 +443,7 @@ impl std::ops::DerefMut for State<'_> {\n     }\n }\n \n-pub trait PrintState<'a>: std::ops::Deref<Target=pp::Printer> + std::ops::DerefMut {\n+pub trait PrintState<'a>: std::ops::Deref<Target = pp::Printer> + std::ops::DerefMut {\n     fn comments(&mut self) -> &mut Option<Comments<'a>>;\n     fn print_ident(&mut self, ident: ast::Ident);\n     fn print_generic_args(&mut self, args: &ast::GenericArgs, colons_before_params: bool);\n@@ -495,7 +495,7 @@ pub trait PrintState<'a>: std::ops::Deref<Target=pp::Printer> + std::ops::DerefM\n                 self.hardbreak_if_not_bol();\n                 for line in &cmnt.lines {\n                     // Don't print empty lines because they will end up as trailing\n-                    // whitespace\n+                    // whitespace.\n                     if !line.is_empty() {\n                         self.word(line.clone());\n                     }\n@@ -783,27 +783,27 @@ pub trait PrintState<'a>: std::ops::Deref<Target=pp::Printer> + std::ops::DerefM\n \n     fn head<S: Into<Cow<'static, str>>>(&mut self, w: S) {\n         let w = w.into();\n-        // outer-box is consistent\n+        // Outer-box is consistent.\n         self.cbox(INDENT_UNIT);\n-        // head-box is inconsistent\n+        // Head-box is inconsistent.\n         self.ibox(w.len() + 1);\n-        // keyword that starts the head\n+        // Keyword that starts the head.\n         if !w.is_empty() {\n             self.word_nbsp(w);\n         }\n     }\n \n     fn bopen(&mut self) {\n         self.word(\"{\");\n-        self.end(); // close the head-box\n+        self.end(); // Close the head-box.\n     }\n \n     fn bclose_maybe_open(&mut self, span: syntax_pos::Span, close_box: bool) {\n         self.maybe_print_comment(span.hi());\n         self.break_offset_if_not_bol(1, -(INDENT_UNIT as isize));\n         self.word(\"}\");\n         if close_box {\n-            self.end(); // close the outer-box\n+            self.end(); // Close the outer-box.\n         }\n     }\n \n@@ -900,8 +900,6 @@ impl<'a> State<'a> {\n         self.s.word(\"*/\")\n     }\n \n-\n-\n     crate fn commasep_cmnt<T, F, G>(&mut self,\n                                   b: Breaks,\n                                   elts: &[T],\n@@ -928,20 +926,20 @@ impl<'a> State<'a> {\n     }\n \n     crate fn commasep_exprs(&mut self, b: Breaks,\n-                          exprs: &[P<ast::Expr>]) {\n+                            exprs: &[P<ast::Expr>]) {\n         self.commasep_cmnt(b, exprs, |s, e| s.print_expr(e), |e| e.span)\n     }\n \n     crate fn print_mod(&mut self, _mod: &ast::Mod,\n-                     attrs: &[ast::Attribute]) {\n+                       attrs: &[ast::Attribute]) {\n         self.print_inner_attributes(attrs);\n         for item in &_mod.items {\n             self.print_item(item);\n         }\n     }\n \n     crate fn print_foreign_mod(&mut self, nmod: &ast::ForeignMod,\n-                             attrs: &[ast::Attribute]) {\n+                               attrs: &[ast::Attribute]) {\n         self.print_inner_attributes(attrs);\n         for item in &nmod.items {\n             self.print_foreign_item(item);\n@@ -1136,7 +1134,7 @@ impl<'a> State<'a> {\n         self.s.word(\";\")\n     }\n \n-    /// Pretty-print an item\n+    /// Pretty-prints an item.\n     crate fn print_item(&mut self, item: &ast::Item) {\n         self.hardbreak_if_not_bol();\n         self.maybe_print_comment(item.span.lo());\n@@ -1489,7 +1487,7 @@ impl<'a> State<'a> {\n                     self.s.word(\";\");\n                 }\n                 self.end();\n-                self.end(); // close the outer-box\n+                self.end(); // Close the outer-box.\n             }\n             ast::VariantData::Struct(..) => {\n                 self.print_where_clause(&generics.where_clause);\n@@ -1793,7 +1791,7 @@ impl<'a> State<'a> {\n         self.print_expr_cond_paren(expr, expr.precedence().order() < prec)\n     }\n \n-    /// Print an expr using syntax that's acceptable in a condition position, such as the `cond` in\n+    /// Prints an expr using syntax that's acceptable in a condition position, such as the `cond` in\n     /// `if cond { ... }`.\n     crate fn print_expr_as_cond(&mut self, expr: &ast::Expr) {\n         self.print_expr_cond_paren(expr, Self::cond_needs_par(expr))\n@@ -1812,7 +1810,7 @@ impl<'a> State<'a> {\n         }\n     }\n \n-    /// Print `expr` or `(expr)` when `needs_par` holds.\n+    /// Prints `expr` or `(expr)` when `needs_par` holds.\n     fn print_expr_cond_paren(&mut self, expr: &ast::Expr, needs_par: bool) {\n         if needs_par {\n             self.popen();\n@@ -2456,7 +2454,7 @@ impl<'a> State<'a> {\n     }\n \n     fn print_arm(&mut self, arm: &ast::Arm) {\n-        // I have no idea why this check is necessary, but here it is :(\n+        // Note, I have no idea why this check is necessary, but here it is.\n         if arm.attrs.is_empty() {\n             self.s.space();\n         }\n@@ -2480,21 +2478,21 @@ impl<'a> State<'a> {\n                     self.word_space(\":\");\n                 }\n \n-                // the block will close the pattern's ibox\n+                // The block will close the pattern's ibox.\n                 self.print_block_unclosed_indent(blk);\n \n-                // If it is a user-provided unsafe block, print a comma after it\n+                // If it is a user-provided unsafe block, print a comma after it.\n                 if let BlockCheckMode::Unsafe(ast::UserProvided) = blk.rules {\n                     self.s.word(\",\");\n                 }\n             }\n             _ => {\n-                self.end(); // close the ibox for the pattern\n+                self.end(); // Close the ibox for the pattern.\n                 self.print_expr(&arm.body);\n                 self.s.word(\",\");\n             }\n         }\n-        self.end(); // close enclosing cbox\n+        self.end(); // Close enclosing cbox.\n     }\n \n     fn print_explicit_self(&mut self, explicit_self: &ast::ExplicitSelf) {"}, {"sha": "afd1726adf36b2731d7a7efff848b71c55d772c5", "filename": "src/libsyntax/print/pprust/tests.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fprint%2Fpprust%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fprint%2Fpprust%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust%2Ftests.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -12,8 +12,8 @@ fn fun_to_string(\n         s.head(\"\");\n         s.print_fn(decl, header, Some(name),\n                    generics, &source_map::dummy_spanned(ast::VisibilityKind::Inherited));\n-        s.end(); // Close the head box\n-        s.end(); // Close the outer box\n+        s.end(); // Close the head box.\n+        s.end(); // Close the outer box.\n     })\n }\n \n@@ -58,7 +58,6 @@ fn test_variant_to_string() {\n             ident,\n             attrs: Vec::new(),\n             id: ast::DUMMY_NODE_ID,\n-            // making this up as I go.... ?\n             data: ast::VariantData::Unit(ast::DUMMY_NODE_ID),\n             disr_expr: None,\n             span: syntax_pos::DUMMY_SP,"}, {"sha": "393723b02b2d3572a3c8e535b36eedd121ba980c", "filename": "src/libsyntax/source_map.rs", "status": "modified", "additions": 65, "deletions": 63, "changes": 128, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fsource_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fsource_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fsource_map.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -1,10 +1,10 @@\n-//! The SourceMap tracks all the source code used within a single crate, mapping\n+//! The `SourceMap` tracks all the source code used within a single crate, mapping\n //! from integer byte positions to the original source code location. Each bit\n //! of source parsed during crate parsing (typically files, in-memory strings,\n //! or various bits of macro expansion) cover a continuous range of bytes in the\n-//! SourceMap and are represented by SourceFiles. Byte positions are stored in\n-//! `spans` and used pervasively in the compiler. They are absolute positions\n-//! within the SourceMap, which upon request can be converted to line and column\n+//! `SourceMap` and are represented by `SourceFile`s. Byte positions are stored in\n+//! `Span`` and used pervasively in the compiler. They are absolute positions\n+//! within the `SourceMap`, which upon request can be converted to line and column\n //! information, source code snippets, etc.\n \n pub use syntax_pos::*;\n@@ -94,7 +94,7 @@ impl FileLoader for RealFileLoader {\n     }\n }\n \n-// This is a SourceFile identifier that is used to correlate SourceFiles between\n+// This is a `SourceFile` identifier that is used to correlate `SourceFile`s between\n // subsequent compilation sessions (which is something we need to do during\n // incremental compilation).\n #[derive(Copy, Clone, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable, Debug)]\n@@ -103,8 +103,8 @@ pub struct StableSourceFileId(u128);\n impl StableSourceFileId {\n     pub fn new(source_file: &SourceFile) -> StableSourceFileId {\n         StableSourceFileId::new_from_pieces(&source_file.name,\n-                                         source_file.name_was_remapped,\n-                                         source_file.unmapped_path.as_ref())\n+                                            source_file.name_was_remapped,\n+                                            source_file.unmapped_path.as_ref())\n     }\n \n     pub fn new_from_pieces(name: &FileName,\n@@ -134,7 +134,7 @@ pub struct SourceMap {\n     files: Lock<SourceMapFiles>,\n     file_loader: Box<dyn FileLoader + Sync + Send>,\n     // This is used to apply the file path remapping as specified via\n-    // --remap-path-prefix to all SourceFiles allocated within this SourceMap.\n+    // `--remap-path-prefix` to all `SourceFile`s allocated within this `SourceMap`.\n     path_mapping: FilePathMapping,\n }\n \n@@ -204,14 +204,14 @@ impl SourceMap {\n         match self.files.borrow().source_files.last() {\n             None => 0,\n             // Add one so there is some space between files. This lets us distinguish\n-            // positions in the source_map, even in the presence of zero-length files.\n+            // positions in the `SourceMap`, even in the presence of zero-length files.\n             Some(last) => last.end_pos.to_usize() + 1,\n         }\n     }\n \n-    /// Creates a new source_file.\n-    /// If a file already exists in the source_map with the same id, that file is returned\n-    /// unmodified\n+    /// Creates a new `SourceFile`.\n+    /// If a file already exists in the `SourceMap` with the same ID, that file is returned\n+    /// unmodified.\n     pub fn new_source_file(&self, filename: FileName, src: String) -> Lrc<SourceFile> {\n         self.try_new_source_file(filename, src)\n             .unwrap_or_else(|OffsetOverflowError| {\n@@ -268,8 +268,8 @@ impl SourceMap {\n         Ok(lrc_sf)\n     }\n \n-    /// Allocates a new SourceFile representing a source file from an external\n-    /// crate. The source code of such an \"imported source_file\" is not available,\n+    /// Allocates a new `SourceFile` representing a source file from an external\n+    /// crate. The source code of such an \"imported `SourceFile`\" is not available,\n     /// but we still know enough to generate accurate debuginfo location\n     /// information for things inlined from other crates.\n     pub fn new_imported_source_file(\n@@ -334,7 +334,7 @@ impl SourceMap {\n                  pos.col.to_usize() + 1)\n     }\n \n-    // If there is a doctest_offset, apply it to the line\n+    // If there is a doctest offset, applies it to the line.\n     pub fn doctest_offset_line(&self, file: &FileName, orig: usize) -> usize {\n         return match file {\n             FileName::DocTest(_, offset) => {\n@@ -348,7 +348,7 @@ impl SourceMap {\n         }\n     }\n \n-    /// Lookup source information about a BytePos\n+    /// Looks up source information about a `BytePos`.\n     pub fn lookup_char_pos(&self, pos: BytePos) -> Loc {\n         let chpos = self.bytepos_to_file_charpos(pos);\n         match self.lookup_line(pos) {\n@@ -411,7 +411,7 @@ impl SourceMap {\n         }\n     }\n \n-    // If the relevant source_file is empty, we don't return a line number.\n+    // If the corresponding `SourceFile` is empty, does not return a line number.\n     pub fn lookup_line(&self, pos: BytePos) -> Result<SourceFileAndLine, Lrc<SourceFile>> {\n         let idx = self.lookup_source_file_idx(pos);\n \n@@ -423,15 +423,15 @@ impl SourceMap {\n         }\n     }\n \n-    /// Returns `Some(span)`, a union of the lhs and rhs span. The lhs must precede the rhs. If\n-    /// there are gaps between lhs and rhs, the resulting union will cross these gaps.\n-    /// For this to work, the spans have to be:\n+    /// Returns `Some(span)`, a union of the LHS and RHS span. The LHS must precede the RHS. If\n+    /// there are gaps between LHS and RHS, the resulting union will cross these gaps.\n+    /// For this to work,\n     ///\n-    ///    * the ctxt of both spans much match\n-    ///    * the lhs span needs to end on the same line the rhs span begins\n-    ///    * the lhs span must start at or before the rhs span\n+    ///    * the syntax contexts of both spans much match,\n+    ///    * the LHS span needs to end on the same line the RHS span begins,\n+    ///    * the LHS span must start at or before the RHS span.\n     pub fn merge_spans(&self, sp_lhs: Span, sp_rhs: Span) -> Option<Span> {\n-        // make sure we're at the same expansion id\n+        // Ensure we're at the same expansion ID.\n         if sp_lhs.ctxt() != sp_rhs.ctxt() {\n             return None;\n         }\n@@ -445,12 +445,12 @@ impl SourceMap {\n             Err(_) => return None\n         };\n \n-        // if we must cross lines to merge, don't merge\n+        // If we must cross lines to merge, don't merge.\n         if lhs_end.line != rhs_begin.line {\n             return None;\n         }\n \n-        // ensure these follow the expected order and we don't overlap\n+        // Ensure these follow the expected order and that we don't overlap.\n         if (sp_lhs.lo() <= sp_rhs.lo()) && (sp_lhs.hi() <= sp_rhs.lo()) {\n             Some(sp_lhs.to(sp_rhs))\n         } else {\n@@ -466,20 +466,21 @@ impl SourceMap {\n         let lo = self.lookup_char_pos(sp.lo());\n         let hi = self.lookup_char_pos(sp.hi());\n         format!(\"{}:{}:{}: {}:{}\",\n-                        lo.file.name,\n-                        lo.line,\n-                        lo.col.to_usize() + 1,\n-                        hi.line,\n-                        hi.col.to_usize() + 1)\n+            lo.file.name,\n+            lo.line,\n+            lo.col.to_usize() + 1,\n+            hi.line,\n+            hi.col.to_usize() + 1,\n+        )\n     }\n \n     pub fn span_to_filename(&self, sp: Span) -> FileName {\n         self.lookup_char_pos(sp.lo()).file.name.clone()\n     }\n \n     pub fn span_to_unmapped_path(&self, sp: Span) -> FileName {\n-        self.lookup_char_pos(sp.lo()).file.unmapped_path.clone()\n-            .expect(\"SourceMap::span_to_unmapped_path called for imported SourceFile?\")\n+        let source_file = self.lookup_char_pos(sp.lo()).file;\n+        source_file.unmapped_path.clone().unwrap_or(source_file.name.clone())\n     }\n \n     pub fn is_multiline(&self, sp: Span) -> bool {\n@@ -586,7 +587,7 @@ impl SourceMap {\n         }\n     }\n \n-    /// Returns the source snippet as `String` corresponding to the given `Span`\n+    /// Returns the source snippet as `String` corresponding to the given `Span`.\n     pub fn span_to_snippet(&self, sp: Span) -> Result<String, SpanSnippetError> {\n         self.span_to_source(sp, |src, start_index, end_index| src.get(start_index..end_index)\n             .map(|s| s.to_string())\n@@ -602,14 +603,14 @@ impl SourceMap {\n         }\n     }\n \n-    /// Returns the source snippet as `String` before the given `Span`\n+    /// Returns the source snippet as `String` before the given `Span`.\n     pub fn span_to_prev_source(&self, sp: Span) -> Result<String, SpanSnippetError> {\n         self.span_to_source(sp, |src, start_index, _| src.get(..start_index)\n             .map(|s| s.to_string())\n             .ok_or_else(|| SpanSnippetError::IllFormedSpan(sp)))\n     }\n \n-    /// Extend the given `Span` to just after the previous occurrence of `c`. Return the same span\n+    /// Extends the given `Span` to just after the previous occurrence of `c`. Return the same span\n     /// if no character could be found or if an error occurred while retrieving the code snippet.\n     pub fn span_extend_to_prev_char(&self, sp: Span, c: char) -> Span {\n         if let Ok(prev_source) = self.span_to_prev_source(sp) {\n@@ -622,8 +623,8 @@ impl SourceMap {\n         sp\n     }\n \n-    /// Extend the given `Span` to just after the previous occurrence of `pat` when surrounded by\n-    /// whitespace. Return the same span if no character could be found or if an error occurred\n+    /// Extends the given `Span` to just after the previous occurrence of `pat` when surrounded by\n+    /// whitespace. Returns the same span if no character could be found or if an error occurred\n     /// while retrieving the code snippet.\n     pub fn span_extend_to_prev_str(&self, sp: Span, pat: &str, accept_newlines: bool) -> Span {\n         // assure that the pattern is delimited, to avoid the following\n@@ -643,7 +644,8 @@ impl SourceMap {\n         sp\n     }\n \n-    /// Given a `Span`, try to get a shorter span ending before the first occurrence of `c` `char`\n+    /// Given a `Span`, tries to get a shorter span ending before the first occurrence of `char`\n+    /// ``c`.\n     pub fn span_until_char(&self, sp: Span, c: char) -> Span {\n         match self.span_to_snippet(sp) {\n             Ok(snippet) => {\n@@ -658,7 +660,7 @@ impl SourceMap {\n         }\n     }\n \n-    /// Given a `Span`, try to get a shorter span ending just after the first occurrence of `char`\n+    /// Given a `Span`, tries to get a shorter span ending just after the first occurrence of `char`\n     /// `c`.\n     pub fn span_through_char(&self, sp: Span, c: char) -> Span {\n         if let Ok(snippet) = self.span_to_snippet(sp) {\n@@ -669,8 +671,8 @@ impl SourceMap {\n         sp\n     }\n \n-    /// Given a `Span`, get a new `Span` covering the first token and all its trailing whitespace or\n-    /// the original `Span`.\n+    /// Given a `Span`, gets a new `Span` covering the first token and all its trailing whitespace\n+    /// or the original `Span`.\n     ///\n     /// If `sp` points to `\"let mut x\"`, then a span pointing at `\"let \"` will be returned.\n     pub fn span_until_non_whitespace(&self, sp: Span) -> Span {\n@@ -689,15 +691,15 @@ impl SourceMap {\n         })\n     }\n \n-    /// Given a `Span`, get a new `Span` covering the first token without its trailing whitespace or\n-    /// the original `Span` in case of error.\n+    /// Given a `Span`, gets a new `Span` covering the first token without its trailing whitespace\n+    /// or the original `Span` in case of error.\n     ///\n     /// If `sp` points to `\"let mut x\"`, then a span pointing at `\"let\"` will be returned.\n     pub fn span_until_whitespace(&self, sp: Span) -> Span {\n         self.span_take_while(sp, |c| !c.is_whitespace())\n     }\n \n-    /// Given a `Span`, get a shorter one until `predicate` yields false.\n+    /// Given a `Span`, gets a shorter one until `predicate` yields `false`.\n     pub fn span_take_while<P>(&self, sp: Span, predicate: P) -> Span\n         where P: for <'r> FnMut(&'r char) -> bool\n     {\n@@ -717,7 +719,7 @@ impl SourceMap {\n         self.span_until_char(sp, '{')\n     }\n \n-    /// Returns a new span representing just the start-point of this span\n+    /// Returns a new span representing just the start point of this span.\n     pub fn start_point(&self, sp: Span) -> Span {\n         let pos = sp.lo().0;\n         let width = self.find_width_of_character_at_span(sp, false);\n@@ -726,7 +728,7 @@ impl SourceMap {\n         sp.with_hi(end_point)\n     }\n \n-    /// Returns a new span representing just the end-point of this span\n+    /// Returns a new span representing just the end point of this span.\n     pub fn end_point(&self, sp: Span) -> Span {\n         let pos = sp.hi().0;\n \n@@ -737,7 +739,7 @@ impl SourceMap {\n         sp.with_lo(end_point)\n     }\n \n-    /// Returns a new span representing the next character after the end-point of this span\n+    /// Returns a new span representing the next character after the end-point of this span.\n     pub fn next_point(&self, sp: Span) -> Span {\n         let start_of_next_point = sp.hi().0;\n \n@@ -840,30 +842,30 @@ impl SourceMap {\n         None\n     }\n \n-    /// For a global BytePos compute the local offset within the containing SourceFile\n+    /// For a global `BytePos`, computes the local offset within the containing `SourceFile`.\n     pub fn lookup_byte_offset(&self, bpos: BytePos) -> SourceFileAndBytePos {\n         let idx = self.lookup_source_file_idx(bpos);\n         let sf = (*self.files.borrow().source_files)[idx].clone();\n         let offset = bpos - sf.start_pos;\n         SourceFileAndBytePos {sf, pos: offset}\n     }\n \n-    /// Converts an absolute BytePos to a CharPos relative to the source_file.\n+    /// Converts an absolute `BytePos` to a `CharPos` relative to the `SourceFile`.\n     pub fn bytepos_to_file_charpos(&self, bpos: BytePos) -> CharPos {\n         let idx = self.lookup_source_file_idx(bpos);\n         let map = &(*self.files.borrow().source_files)[idx];\n \n-        // The number of extra bytes due to multibyte chars in the SourceFile\n+        // The number of extra bytes due to multibyte chars in the `SourceFile`.\n         let mut total_extra_bytes = 0;\n \n         for mbc in map.multibyte_chars.iter() {\n             debug!(\"{}-byte char at {:?}\", mbc.bytes, mbc.pos);\n             if mbc.pos < bpos {\n-                // every character is at least one byte, so we only\n+                // Every character is at least one byte, so we only\n                 // count the actual extra bytes.\n                 total_extra_bytes += mbc.bytes as u32 - 1;\n                 // We should never see a byte position in the middle of a\n-                // character\n+                // character.\n                 assert!(bpos.to_u32() >= mbc.pos.to_u32() + mbc.bytes as u32);\n             } else {\n                 break;\n@@ -874,13 +876,13 @@ impl SourceMap {\n         CharPos(bpos.to_usize() - map.start_pos.to_usize() - total_extra_bytes as usize)\n     }\n \n-    // Return the index of the source_file (in self.files) which contains pos.\n+    // Returns the index of the `SourceFile` (in `self.files`) that contains `pos`.\n     pub fn lookup_source_file_idx(&self, pos: BytePos) -> usize {\n         let files = self.files.borrow();\n         let files = &files.source_files;\n         let count = files.len();\n \n-        // Binary search for the source_file.\n+        // Binary search for the `SourceFile`.\n         let mut a = 0;\n         let mut b = count;\n         while b - a > 1 {\n@@ -911,8 +913,8 @@ impl SourceMap {\n         }).ok()\n     }\n \n-    /// Take the span of a type parameter in a function signature and try to generate a span for the\n-    /// function name (with generics) and a new snippet for this span with the pointed type\n+    /// Takes the span of a type parameter in a function signature and try to generate a span for\n+    /// the function name (with generics) and a new snippet for this span with the pointed type\n     /// parameter as a new local type parameter.\n     ///\n     /// For instance:\n@@ -928,18 +930,18 @@ impl SourceMap {\n     ///\n     /// Attention: The method used is very fragile since it essentially duplicates the work of the\n     /// parser. If you need to use this function or something similar, please consider updating the\n-    /// source_map functions and this function to something more robust.\n+    /// `SourceMap` functions and this function to something more robust.\n     pub fn generate_local_type_param_snippet(&self, span: Span) -> Option<(Span, String)> {\n         // Try to extend the span to the previous \"fn\" keyword to retrieve the function\n-        // signature\n+        // signature.\n         let sugg_span = self.span_extend_to_prev_str(span, \"fn\", false);\n         if sugg_span != span {\n             if let Ok(snippet) = self.span_to_snippet(sugg_span) {\n-                // Consume the function name\n+                // Consume the function name.\n                 let mut offset = snippet.find(|c: char| !c.is_alphanumeric() && c != '_')\n                     .expect(\"no label after fn\");\n \n-                // Consume the generics part of the function signature\n+                // Consume the generics part of the function signature.\n                 let mut bracket_counter = 0;\n                 let mut last_char = None;\n                 for c in snippet[offset..].chars() {\n@@ -953,11 +955,11 @@ impl SourceMap {\n                     last_char = Some(c);\n                 }\n \n-                // Adjust the suggestion span to encompass the function name with its generics\n+                // Adjust the suggestion span to encompass the function name with its generics.\n                 let sugg_span = sugg_span.with_hi(BytePos(sugg_span.lo().0 + offset as u32));\n \n                 // Prepare the new suggested snippet to append the type parameter that triggered\n-                // the error in the generics of the function signature\n+                // the error in the generics of the function signature.\n                 let mut new_snippet = if last_char == Some('>') {\n                     format!(\"{}, \", &snippet[..(offset - '>'.len_utf8())])\n                 } else {"}, {"sha": "28fc19093242a95a6d417f28b83be043dde6bc97", "filename": "src/libsyntax/source_map/tests.rs", "status": "modified", "additions": 54, "deletions": 44, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fsource_map%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fsource_map%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fsource_map%2Ftests.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -4,18 +4,24 @@ use rustc_data_structures::sync::Lrc;\n \n fn init_source_map() -> SourceMap {\n     let sm = SourceMap::new(FilePathMapping::empty());\n-    sm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n-                    \"first line.\\nsecond line\".to_string());\n-    sm.new_source_file(PathBuf::from(\"empty.rs\").into(),\n-                    String::new());\n-    sm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n-                    \"first line.\\nsecond line\".to_string());\n+    sm.new_source_file(\n+        PathBuf::from(\"blork.rs\").into(),\n+        \"first line.\\nsecond line\".to_string(),\n+    );\n+    sm.new_source_file(\n+        PathBuf::from(\"empty.rs\").into(),\n+        String::new(),\n+    );\n+    sm.new_source_file(\n+        PathBuf::from(\"blork2.rs\").into(),\n+        \"first line.\\nsecond line\".to_string(),\n+    );\n     sm\n }\n \n+/// Tests `lookup_byte_offset`.\n #[test]\n fn t3() {\n-    // Test lookup_byte_offset\n     let sm = init_source_map();\n \n     let srcfbp1 = sm.lookup_byte_offset(BytePos(23));\n@@ -31,9 +37,9 @@ fn t3() {\n     assert_eq!(srcfbp2.pos, BytePos(0));\n }\n \n+/// Tests `bytepos_to_file_charpos`.\n #[test]\n fn t4() {\n-    // Test bytepos_to_file_charpos\n     let sm = init_source_map();\n \n     let cp1 = sm.bytepos_to_file_charpos(BytePos(22));\n@@ -43,9 +49,9 @@ fn t4() {\n     assert_eq!(cp2, CharPos(0));\n }\n \n+/// Tests zero-length `SourceFile`s.\n #[test]\n fn t5() {\n-    // Test zero-length source_files.\n     let sm = init_source_map();\n \n     let loc1 = sm.lookup_char_pos(BytePos(22));\n@@ -61,17 +67,17 @@ fn t5() {\n \n fn init_source_map_mbc() -> SourceMap {\n     let sm = SourceMap::new(FilePathMapping::empty());\n-    // \u20ac is a three byte utf8 char.\n+    // \"\u20ac\" is a three-byte UTF8 char.\n     sm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n                     \"fir\u20acst \u20ac\u20ac\u20ac\u20ac line.\\nsecond line\".to_string());\n     sm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n                     \"first line\u20ac\u20ac.\\n\u20ac second line\".to_string());\n     sm\n }\n \n+/// Tests `bytepos_to_file_charpos` in the presence of multi-byte chars.\n #[test]\n fn t6() {\n-    // Test bytepos_to_file_charpos in the presence of multi-byte chars\n     let sm = init_source_map_mbc();\n \n     let cp1 = sm.bytepos_to_file_charpos(BytePos(3));\n@@ -87,11 +93,11 @@ fn t6() {\n     assert_eq!(cp4, CharPos(15));\n }\n \n+/// Test `span_to_lines` for a span ending at the end of a `SourceFile`.\n #[test]\n fn t7() {\n-    // Test span_to_lines for a span ending at the end of source_file\n     let sm = init_source_map();\n-    let span = Span::with_root_ctxt(BytePos(12), BytePos(23));\n+    let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n     let file_lines = sm.span_to_lines(span).unwrap();\n \n     assert_eq!(file_lines.file.name, PathBuf::from(\"blork.rs\").into());\n@@ -107,10 +113,10 @@ fn span_from_selection(input: &str, selection: &str) -> Span {\n     assert_eq!(input.len(), selection.len());\n     let left_index = selection.find('~').unwrap() as u32;\n     let right_index = selection.rfind('~').map(|x|x as u32).unwrap_or(left_index);\n-    Span::with_root_ctxt(BytePos(left_index), BytePos(right_index + 1))\n+    Span::new(BytePos(left_index), BytePos(right_index + 1), NO_EXPANSION)\n }\n \n-/// Tests span_to_snippet and span_to_lines for a span converting 3\n+/// Tests `span_to_snippet` and `span_to_lines` for a span converting 3\n /// lines in the middle of a file.\n #[test]\n fn span_to_snippet_and_lines_spanning_multiple_lines() {\n@@ -120,10 +126,10 @@ fn span_to_snippet_and_lines_spanning_multiple_lines() {\n     sm.new_source_file(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_string());\n     let span = span_from_selection(inputtext, selection);\n \n-    // check that we are extracting the text we thought we were extracting\n+    // Check that we are extracting the text we thought we were extracting.\n     assert_eq!(&sm.span_to_snippet(span).unwrap(), \"BB\\nCCC\\nDDDDD\");\n \n-    // check that span_to_lines gives us the complete result with the lines/cols we expected\n+    // Check that span_to_lines gives us the complete result with the lines/cols we expected.\n     let lines = sm.span_to_lines(span).unwrap();\n     let expected = vec![\n         LineInfo { line_index: 1, start_col: CharPos(4), end_col: CharPos(6) },\n@@ -133,27 +139,27 @@ fn span_to_snippet_and_lines_spanning_multiple_lines() {\n     assert_eq!(lines.lines, expected);\n }\n \n+/// Test span_to_snippet for a span ending at the end of a `SourceFile`.\n #[test]\n fn t8() {\n-    // Test span_to_snippet for a span ending at the end of source_file\n     let sm = init_source_map();\n-    let span = Span::with_root_ctxt(BytePos(12), BytePos(23));\n+    let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n     let snippet = sm.span_to_snippet(span);\n \n     assert_eq!(snippet, Ok(\"second line\".to_string()));\n }\n \n+/// Test `span_to_str` for a span ending at the end of a `SourceFile`.\n #[test]\n fn t9() {\n-    // Test span_to_str for a span ending at the end of source_file\n     let sm = init_source_map();\n-    let span = Span::with_root_ctxt(BytePos(12), BytePos(23));\n+    let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n     let sstr =  sm.span_to_string(span);\n \n     assert_eq!(sstr, \"blork.rs:2:1: 2:12\");\n }\n \n-/// Tests failing to merge two spans on different lines\n+/// Tests failing to merge two spans on different lines.\n #[test]\n fn span_merging_fail() {\n     let sm = SourceMap::new(FilePathMapping::empty());\n@@ -167,43 +173,47 @@ fn span_merging_fail() {\n     assert!(sm.merge_spans(span1, span2).is_none());\n }\n \n-/// Returns the span corresponding to the `n`th occurrence of\n-/// `substring` in `source_text`.\n+/// Returns the span corresponding to the `n`th occurrence of `substring` in `source_text`.\n trait SourceMapExtension {\n-    fn span_substr(&self,\n-                file: &Lrc<SourceFile>,\n-                source_text: &str,\n-                substring: &str,\n-                n: usize)\n-                -> Span;\n+    fn span_substr(\n+        self,\n+        file: &Lrc<SourceFile>,\n+        source_text: &str,\n+        substring: &str,\n+        n: usize,\n+    ) -> Span;\n }\n \n impl SourceMapExtension for SourceMap {\n-    fn span_substr(&self,\n-                file: &Lrc<SourceFile>,\n-                source_text: &str,\n-                substring: &str,\n-                n: usize)\n-                -> Span\n-    {\n-        println!(\"span_substr(file={:?}/{:?}, substring={:?}, n={})\",\n-                file.name, file.start_pos, substring, n);\n+    fn span_substr(\n+        &self,\n+        file: &Lrc<SourceFile>,\n+        source_text: &str,\n+        substring: &str,\n+        n: usize,\n+    ) -> Span {\n+        println!(\n+            \"span_substr(file={:?}/{:?}, substring={:?}, n={})\",\n+            file.name, file.start_pos, substring, n\n+        );\n         let mut i = 0;\n         let mut hi = 0;\n         loop {\n             let offset = source_text[hi..].find(substring).unwrap_or_else(|| {\n-                panic!(\"source_text `{}` does not have {} occurrences of `{}`, only {}\",\n-                    source_text, n, substring, i);\n+                panic!(\n+                    \"source_text `{}` does not have {} occurrences of `{}`, only {}\",\n+                    source_text, n, substring, i\n+                );\n             });\n             let lo = hi + offset;\n             hi = lo + substring.len();\n             if i == n {\n-                let span = Span::with_root_ctxt(\n+                let span = Span::new(\n                     BytePos(lo as u32 + file.start_pos.0),\n                     BytePos(hi as u32 + file.start_pos.0),\n+                    NO_EXPANSION,\n                 );\n-                assert_eq!(&self.span_to_snippet(span).unwrap()[..],\n-                        substring);\n+                assert_eq!(&self.span_to_snippet(span).unwrap()[..], substring);\n                 return span;\n             }\n             i += 1;"}, {"sha": "540881b0a54965b8ec15f2582887fd640313378e", "filename": "src/libsyntax/tests.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftests.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -18,7 +18,7 @@ use std::path::{Path, PathBuf};\n use std::str;\n use std::sync::{Arc, Mutex};\n \n-/// Map string to parser (via tts)\n+/// Map string to parser (via tts).\n fn string_to_parser(ps: &ParseSess, source_str: String) -> Parser<'_> {\n     new_parser_from_source_str(ps, PathBuf::from(\"bogofile\").into(), source_str)\n }\n@@ -32,7 +32,7 @@ crate fn with_error_checking_parse<'a, T, F>(s: String, ps: &'a ParseSess, f: F)\n     x\n }\n \n-/// Map a string to tts, using a made-up filename:\n+/// Maps a string to tts, using a made-up filename.\n crate fn string_to_stream(source_str: String) -> TokenStream {\n     let ps = ParseSess::new(FilePathMapping::empty());\n     source_file_to_stream(\n@@ -42,7 +42,7 @@ crate fn string_to_stream(source_str: String) -> TokenStream {\n     ), None).0\n }\n \n-/// Parse a string, return a crate.\n+/// Parses a string, returns a crate.\n crate fn string_to_crate(source_str : String) -> ast::Crate {\n     let ps = ParseSess::new(FilePathMapping::empty());\n     with_error_checking_parse(source_str, &ps, |p| {\n@@ -64,7 +64,7 @@ crate fn matches_codepattern(a : &str, b : &str) -> bool {\n             (None, _) => return false,\n             (Some(&a), None) => {\n                 if rustc_lexer::is_whitespace(a) {\n-                    break // trailing whitespace check is out of loop for borrowck\n+                    break // Trailing whitespace check is out of loop for borrowck.\n                 } else {\n                     return false\n                 }\n@@ -73,11 +73,11 @@ crate fn matches_codepattern(a : &str, b : &str) -> bool {\n         };\n \n         if rustc_lexer::is_whitespace(a) && rustc_lexer::is_whitespace(b) {\n-            // skip whitespace for a and b\n+            // Skip whitespace for `a` and `b`.\n             scan_for_non_ws_or_end(&mut a_iter);\n             scan_for_non_ws_or_end(&mut b_iter);\n         } else if rustc_lexer::is_whitespace(a) {\n-            // skip whitespace for a\n+            // Skip whitespace for `a`.\n             scan_for_non_ws_or_end(&mut a_iter);\n         } else if a == b {\n             a_iter.next();\n@@ -87,18 +87,18 @@ crate fn matches_codepattern(a : &str, b : &str) -> bool {\n         }\n     }\n \n-    // check if a has *only* trailing whitespace\n+    // Check if a has *only* trailing whitespace.\n     a_iter.all(rustc_lexer::is_whitespace)\n }\n \n-/// Advances the given peekable `Iterator` until it reaches a non-whitespace character\n+/// Advances the given peekable `Iterator` until it reaches a non-whitespace character.\n fn scan_for_non_ws_or_end<I: Iterator<Item = char>>(iter: &mut Peekable<I>) {\n     while iter.peek().copied().map(|c| rustc_lexer::is_whitespace(c)) == Some(true) {\n         iter.next();\n     }\n }\n \n-/// Identify a position in the text by the Nth occurrence of a string.\n+/// Identifies a position in the text by the n'th occurrence of a string.\n struct Position {\n     string: &'static str,\n     count: usize,"}, {"sha": "d702038f54ec3ef9727a35062d81f60cd9a1c560", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -6,7 +6,7 @@\n //!\n //! ## Ownership\n //!\n-//! `TokenStreams` are persistent data structures constructed as ropes with reference\n+//! `TokenStream`s are persistent data structures constructed as ropes with reference\n //! counted-children. In general, this means that calling an operation on a `TokenStream`\n //! (such as `slice`) produces an entirely new `TokenStream` from the borrowed reference to\n //! the original. This essentially coerces `TokenStream`s into 'views' of their subparts,\n@@ -147,9 +147,8 @@ impl TokenTree {\n     }\n }\n \n-/// # Token Streams\n-///\n /// A `TokenStream` is an abstract sequence of tokens, organized into `TokenTree`s.\n+///\n /// The goal is for procedural macros to work with `TokenStream`s and `TokenTree`s\n /// instead of a representation of the abstract syntax tree.\n /// Today's `TokenTree`s can still contain AST via `token::Interpolated` for back-compat.\n@@ -304,7 +303,7 @@ impl TokenStream {\n         Cursor::new(self)\n     }\n \n-    /// Compares two TokenStreams, checking equality without regarding span information.\n+    /// Compares two `TokenStream`s, checking equality without regarding span information.\n     pub fn eq_unspanned(&self, other: &TokenStream) -> bool {\n         let mut t1 = self.trees();\n         let mut t2 = other.trees();"}, {"sha": "1cff834b7ad5c0784a59536ea2004ff602e92935", "filename": "src/libsyntax/visit.rs", "status": "modified", "additions": 13, "deletions": 10, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fvisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/49d2fd1725510fd3bf6f2937e178b1aa055ddb02/src%2Flibsyntax%2Fvisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fvisit.rs?ref=49d2fd1725510fd3bf6f2937e178b1aa055ddb02", "patch": "@@ -21,13 +21,13 @@ use syntax_pos::Span;\n \n #[derive(Copy, Clone)]\n pub enum FnKind<'a> {\n-    /// fn foo() or extern \"Abi\" fn foo()\n+    /// E.g., `fn foo()` or `extern \"Abi\" fn foo()`.\n     ItemFn(Ident, &'a FnHeader, &'a Visibility, &'a Block),\n \n-    /// fn foo(&self)\n+    /// E.g., `fn foo(&self)`.\n     Method(Ident, &'a MethodSig, Option<&'a Visibility>, &'a Block),\n \n-    /// |x, y| body\n+    /// E.g., `|x, y| body`.\n     Closure(&'a Expr),\n }\n \n@@ -41,7 +41,7 @@ impl<'a> FnKind<'a> {\n     }\n }\n \n-/// Each method of the Visitor trait is a hook to be potentially\n+/// Each method of the `Visitor` trait is a hook to be potentially\n /// overridden. Each method's default implementation recursively visits\n /// the substructure of the input via the corresponding `walk` method;\n /// e.g., the `visit_mod` method by default calls `visit::walk_mod`.\n@@ -302,10 +302,12 @@ pub fn walk_item<'a, V: Visitor<'a>>(visitor: &mut V, item: &'a Item) {\n     walk_list!(visitor, visit_attribute, &item.attrs);\n }\n \n-pub fn walk_enum_def<'a, V: Visitor<'a>>(visitor: &mut V,\n-                                 enum_definition: &'a EnumDef,\n-                                 _: &'a Generics,\n-                                 _: NodeId) {\n+pub fn walk_enum_def<'a, V: Visitor<'a>>(\n+    visitor: &mut V,\n+    enum_definition: &'a EnumDef,\n+    _: &'a Generics,\n+    _: NodeId,\n+) {\n     walk_list!(visitor, visit_variant, &enum_definition.variants);\n }\n \n@@ -342,7 +344,7 @@ pub fn walk_ty<'a, V: Visitor<'a>>(visitor: &mut V, typ: &'a Ty) {\n             walk_list!(visitor, visit_lifetime, opt_lifetime);\n             visitor.visit_ty(&mutable_type.ty)\n         }\n-        TyKind::Never | TyKind::CVarArgs => {}\n+        TyKind::Never => {}\n         TyKind::Tup(ref tuple_element_types) => {\n             walk_list!(visitor, visit_ty, tuple_element_types);\n         }\n@@ -371,6 +373,7 @@ pub fn walk_ty<'a, V: Visitor<'a>>(visitor: &mut V, typ: &'a Ty) {\n         TyKind::Mac(ref mac) => {\n             visitor.visit_mac(mac)\n         }\n+        TyKind::CVarArgs => {}\n     }\n }\n \n@@ -386,7 +389,7 @@ pub fn walk_use_tree<'a, V: Visitor<'a>>(\n     visitor.visit_path(&use_tree.prefix, id);\n     match use_tree.kind {\n         UseTreeKind::Simple(rename, ..) => {\n-            // the extra IDs are handled during HIR lowering\n+            // The extra IDs are handled during HIR lowering.\n             if let Some(rename) = rename {\n                 visitor.visit_ident(rename);\n             }"}]}