{"sha": "427140f771828d5a2fce7a21d97359d2967c3239", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQyNzE0MGY3NzE4MjhkNWEyZmNlN2EyMWQ5NzM1OWQyOTY3YzMyMzk=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-10-29T11:14:27Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-10-29T11:14:27Z"}, "message": "Auto merge of #29188 - nikomatsakis:remove-contraction, r=pnkfelix\n\nThis fixes #29048 (though I think adding better transactional support would be a better fix for that issue, but that is more difficult). It also simplifies region inference and changes the model to a pure data flow one, as discussed in [this internals thread](https://internals.rust-lang.org/t/rough-thoughts-on-the-impl-of-region-inference-mir-etc/2800). I am not 100% sure though if this PR is the right thing to do -- or at least maybe not at this moment, so thoughts on that would be appreciated.\r\n\r\nr? @pnkfelix \r\ncc @arielb1", "tree": {"sha": "cc505b85f1cfb66200317633899045eb8d7bb6f6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/cc505b85f1cfb66200317633899045eb8d7bb6f6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/427140f771828d5a2fce7a21d97359d2967c3239", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/427140f771828d5a2fce7a21d97359d2967c3239", "html_url": "https://github.com/rust-lang/rust/commit/427140f771828d5a2fce7a21d97359d2967c3239", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/427140f771828d5a2fce7a21d97359d2967c3239/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "696cd7cf86c176af4b8ff77b9bd00855a71648d2", "url": "https://api.github.com/repos/rust-lang/rust/commits/696cd7cf86c176af4b8ff77b9bd00855a71648d2", "html_url": "https://github.com/rust-lang/rust/commit/696cd7cf86c176af4b8ff77b9bd00855a71648d2"}, {"sha": "c2277de6737059c984248e20a5435a3dea7f823b", "url": "https://api.github.com/repos/rust-lang/rust/commits/c2277de6737059c984248e20a5435a3dea7f823b", "html_url": "https://github.com/rust-lang/rust/commit/c2277de6737059c984248e20a5435a3dea7f823b"}], "stats": {"total": 638, "additions": 182, "deletions": 456}, "files": [{"sha": "288eb01ebb4705d8aa58f2b66a66fb976312bb68", "filename": "src/librustc/middle/def_id.rs", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc%2Fmiddle%2Fdef_id.rs", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc%2Fmiddle%2Fdef_id.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fdef_id.rs?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -61,12 +61,16 @@ impl fmt::Debug for DefId {\n         // Unfortunately, there seems to be no way to attempt to print\n         // a path for a def-id, so I'll just make a best effort for now\n         // and otherwise fallback to just printing the crate/node pair\n-        try!(ty::tls::with_opt(|opt_tcx| {\n-            if let Some(tcx) = opt_tcx {\n-                try!(write!(f, \" => {}\", tcx.item_path_str(*self)));\n-            }\n-            Ok(())\n-        }));\n+        if self.is_local() { // (1)\n+            // (1) side-step fact that not all external things have paths at\n+            // the moment, such as type parameters\n+            try!(ty::tls::with_opt(|opt_tcx| {\n+                if let Some(tcx) = opt_tcx {\n+                    try!(write!(f, \" => {}\", tcx.item_path_str(*self)));\n+                }\n+                Ok(())\n+            }));\n+        }\n \n         write!(f, \" }}\")\n     }"}, {"sha": "0ab572c543b29e202f1854e3752c3818ab04afbb", "filename": "src/librustc/middle/infer/error_reporting.rs", "status": "modified", "additions": 0, "deletions": 40, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc%2Fmiddle%2Finfer%2Ferror_reporting.rs", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc%2Fmiddle%2Finfer%2Ferror_reporting.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Ferror_reporting.rs?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -65,7 +65,6 @@ use super::ValuePairs;\n use super::region_inference::RegionResolutionError;\n use super::region_inference::ConcreteFailure;\n use super::region_inference::SubSupConflict;\n-use super::region_inference::SupSupConflict;\n use super::region_inference::GenericBoundFailure;\n use super::region_inference::GenericKind;\n use super::region_inference::ProcessedErrors;\n@@ -258,13 +257,6 @@ pub trait ErrorReporting<'tcx> {\n                                sup_origin: SubregionOrigin<'tcx>,\n                                sup_region: Region);\n \n-    fn report_sup_sup_conflict(&self,\n-                               var_origin: RegionVariableOrigin,\n-                               origin1: SubregionOrigin<'tcx>,\n-                               region1: Region,\n-                               origin2: SubregionOrigin<'tcx>,\n-                               region2: Region);\n-\n     fn report_processed_errors(&self,\n                                var_origin: &[RegionVariableOrigin],\n                                trace_origin: &[(TypeTrace<'tcx>, TypeError<'tcx>)],\n@@ -313,14 +305,6 @@ impl<'a, 'tcx> ErrorReporting<'tcx> for InferCtxt<'a, 'tcx> {\n                                                  sup_origin, sup_r);\n                 }\n \n-                SupSupConflict(var_origin,\n-                               origin1, r1,\n-                               origin2, r2) => {\n-                    self.report_sup_sup_conflict(var_origin,\n-                                                 origin1, r1,\n-                                                 origin2, r2);\n-                }\n-\n                 ProcessedErrors(ref var_origins,\n                                 ref trace_origins,\n                                 ref same_regions) => {\n@@ -376,7 +360,6 @@ impl<'a, 'tcx> ErrorReporting<'tcx> for InferCtxt<'a, 'tcx> {\n                         None => processed_errors.push((*error).clone()),\n                     }\n                 }\n-                SupSupConflict(..) => processed_errors.push((*error).clone()),\n                 _ => ()  // This shouldn't happen\n             }\n         }\n@@ -933,29 +916,6 @@ impl<'a, 'tcx> ErrorReporting<'tcx> for InferCtxt<'a, 'tcx> {\n         self.note_region_origin(&sub_origin);\n     }\n \n-    fn report_sup_sup_conflict(&self,\n-                               var_origin: RegionVariableOrigin,\n-                               origin1: SubregionOrigin<'tcx>,\n-                               region1: Region,\n-                               origin2: SubregionOrigin<'tcx>,\n-                               region2: Region) {\n-        self.report_inference_failure(var_origin);\n-\n-        self.tcx.note_and_explain_region(\n-            \"first, the lifetime must be contained by \",\n-            region1,\n-            \"...\");\n-\n-        self.note_region_origin(&origin1);\n-\n-        self.tcx.note_and_explain_region(\n-            \"but, the lifetime must also be contained by \",\n-            region2,\n-            \"...\");\n-\n-        self.note_region_origin(&origin2);\n-    }\n-\n     fn report_processed_errors(&self,\n                                var_origins: &[RegionVariableOrigin],\n                                trace_origins: &[(TypeTrace<'tcx>, TypeError<'tcx>)],"}, {"sha": "80da861139b42fd9acc50f686746219a5f091c4a", "filename": "src/librustc/middle/infer/region_inference/README.md", "status": "modified", "additions": 46, "deletions": 46, "changes": 92, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2FREADME.md?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -2,13 +2,12 @@ Region inference\n \n # Terminology\n \n-Note that we use the terms region and lifetime interchangeably,\n-though the term `lifetime` is preferred.\n+Note that we use the terms region and lifetime interchangeably.\n \n # Introduction\n \n Region inference uses a somewhat more involved algorithm than type\n-inference.  It is not the most efficient thing ever written though it\n+inference. It is not the most efficient thing ever written though it\n seems to work well enough in practice (famous last words).  The reason\n that we use a different algorithm is because, unlike with types, it is\n impractical to hand-annotate with regions (in some cases, there aren't\n@@ -25,22 +24,42 @@ once.\n \n The constraints are always of one of three possible forms:\n \n-- ConstrainVarSubVar(R_i, R_j) states that region variable R_i\n-  must be a subregion of R_j\n-- ConstrainRegSubVar(R, R_i) states that the concrete region R\n-  (which must not be a variable) must be a subregion of the variable R_i\n-- ConstrainVarSubReg(R_i, R) is the inverse\n+- `ConstrainVarSubVar(Ri, Rj)` states that region variable Ri must be\n+  a subregion of Rj\n+- `ConstrainRegSubVar(R, Ri)` states that the concrete region R (which\n+  must not be a variable) must be a subregion of the variable Ri\n+- `ConstrainVarSubReg(Ri, R)` states the variable Ri shoudl be less\n+  than the concrete region R. This is kind of deprecated and ought to\n+  be replaced with a verify (they essentially play the same role).\n+\n+In addition to constraints, we also gather up a set of \"verifys\"\n+(what, you don't think Verify is a noun? Get used to it my\n+friend!). These represent relations that must hold but which don't\n+influence inference proper. These take the form of:\n+\n+- `VerifyRegSubReg(Ri, Rj)` indicates that Ri <= Rj must hold,\n+  where Rj is not an inference variable (and Ri may or may not contain\n+  one). This doesn't influence inference because we will already have\n+  inferred Ri to be as small as possible, so then we just test whether\n+  that result was less than Rj or not.\n+- `VerifyGenericBound(R, Vb)` is a more complex expression which tests\n+  that the region R must satisfy the bound `Vb`. The bounds themselves\n+  may have structure like \"must outlive one of the following regions\"\n+  or \"must outlive ALL of the following regions. These bounds arise\n+  from constraints like `T: 'a` -- if we know that `T: 'b` and `T: 'c`\n+  (say, from where clauses), then we can conclude that `T: 'a` if `'b:\n+  'a` *or* `'c: 'a`.\n \n # Building up the constraints\n \n Variables and constraints are created using the following methods:\n \n - `new_region_var()` creates a new, unconstrained region variable;\n-- `make_subregion(R_i, R_j)` states that R_i is a subregion of R_j\n-- `lub_regions(R_i, R_j) -> R_k` returns a region R_k which is\n-  the smallest region that is greater than both R_i and R_j\n-- `glb_regions(R_i, R_j) -> R_k` returns a region R_k which is\n-  the greatest region that is smaller than both R_i and R_j\n+- `make_subregion(Ri, Rj)` states that Ri is a subregion of Rj\n+- `lub_regions(Ri, Rj) -> Rk` returns a region Rk which is\n+  the smallest region that is greater than both Ri and Rj\n+- `glb_regions(Ri, Rj) -> Rk` returns a region Rk which is\n+  the greatest region that is smaller than both Ri and Rj\n \n The actual region resolution algorithm is not entirely\n obvious, though it is also not overly complex.\n@@ -54,14 +73,6 @@ Alternatively, you can call `commit()` which ends all snapshots.\n Snapshots can be recursive---so you can start a snapshot when another\n is in progress, but only the root snapshot can \"commit\".\n \n-# Resolving constraints\n-\n-The constraint resolution algorithm is not super complex but also not\n-entirely obvious.  Here I describe the problem somewhat abstractly,\n-then describe how the current code works.  There may be other, smarter\n-ways of doing this with which I am unfamiliar and can't be bothered to\n-research at the moment. - NDM\n-\n ## The problem\n \n Basically our input is a directed graph where nodes can be divided\n@@ -83,31 +94,20 @@ Before resolution begins, we build up the constraints in a hashmap\n that maps `Constraint` keys to spans.  During resolution, we construct\n the actual `Graph` structure that we describe here.\n \n-## Our current algorithm\n-\n-We divide region variables into two groups: Expanding and Contracting.\n-Expanding region variables are those that have a concrete region\n-predecessor (direct or indirect).  Contracting region variables are\n-all others.\n-\n-We first resolve the values of Expanding region variables and then\n-process Contracting ones.  We currently use an iterative, fixed-point\n-procedure (but read on, I believe this could be replaced with a linear\n-walk).  Basically we iterate over the edges in the graph, ensuring\n-that, if the source of the edge has a value, then this value is a\n-subregion of the target value.  If the target does not yet have a\n-value, it takes the value from the source.  If the target already had\n-a value, then the resulting value is Least Upper Bound of the old and\n-new values. When we are done, each Expanding node will have the\n-smallest region that it could possibly have and still satisfy the\n-constraints.\n-\n-We next process the Contracting nodes.  Here we again iterate over the\n-edges, only this time we move values from target to source (if the\n-source is a Contracting node).  For each contracting node, we compute\n-its value as the GLB of all its successors.  Basically contracting\n-nodes ensure that there is overlap between their successors; we will\n-ultimately infer the largest overlap possible.\n+## Computing the values for region variables\n+\n+The algorithm is a simple dataflow algorithm. Each region variable\n+begins as empty. We iterate over the constraints, and for each constraint\n+we grow the relevant region variable to be as big as it must be to meet all the\n+constraints. This means the region variables can grow to be `'static` if\n+necessary.\n+\n+## Verification\n+\n+After all constraints are fully propoagated, we do a \"verification\"\n+step where we walk over the verify bounds and check that they are\n+satisfied. These bounds represent the \"maximal\" values that a region\n+variable can take on, basically.\n \n # The Region Hierarchy\n "}, {"sha": "279ab9d5f30b2ff3765dc984449def282afed985", "filename": "src/librustc/middle/infer/region_inference/mod.rs", "status": "modified", "additions": 37, "deletions": 343, "changes": 380, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Finfer%2Fregion_inference%2Fmod.rs?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -16,19 +16,16 @@ pub use self::UndoLogEntry::*;\n pub use self::CombineMapType::*;\n pub use self::RegionResolutionError::*;\n pub use self::VarValue::*;\n-use self::Classification::*;\n \n use super::{RegionVariableOrigin, SubregionOrigin, TypeTrace, MiscVariable};\n \n use rustc_data_structures::graph::{self, Direction, NodeIndex};\n use middle::free_region::FreeRegionMap;\n-use middle::region;\n use middle::ty::{self, Ty};\n use middle::ty::{BoundRegion, FreeRegion, Region, RegionVid};\n use middle::ty::{ReEmpty, ReStatic, ReFree, ReEarlyBound};\n use middle::ty::{ReLateBound, ReScope, ReVar, ReSkolemized, BrFresh};\n use middle::ty::error::TypeError;\n-use middle::ty::relate::RelateResult;\n use util::common::indenter;\n use util::nodemap::{FnvHashMap, FnvHashSet};\n \n@@ -50,6 +47,8 @@ pub enum Constraint {\n     ConstrainRegSubVar(Region, RegionVid),\n \n     // Region variable is subregion of concrete region\n+    //\n+    // FIXME(#29436) -- should be remove in favor of a Verify\n     ConstrainVarSubReg(RegionVid, Region),\n }\n \n@@ -144,15 +143,6 @@ pub enum RegionResolutionError<'tcx> {\n                    SubregionOrigin<'tcx>, Region,\n                    SubregionOrigin<'tcx>, Region),\n \n-    /// `SupSupConflict(v, origin1, r1, origin2, r2)`:\n-    ///\n-    /// Could not infer a value for `v` because `v <= r1` (due to\n-    /// `origin1`) and `v <= r2` (due to `origin2`) and\n-    /// `r1` and `r2` have no intersection.\n-    SupSupConflict(RegionVariableOrigin,\n-                   SubregionOrigin<'tcx>, Region,\n-                   SubregionOrigin<'tcx>, Region),\n-\n     /// For subsets of `ConcreteFailure` and `SubSupConflict`, we can derive\n     /// more specific errors message by suggesting to the user where they\n     /// should put a lifetime. In those cases we process and put those errors\n@@ -824,147 +814,14 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n           }\n         }\n     }\n-\n-    fn glb_concrete_regions(&self,\n-                            free_regions: &FreeRegionMap,\n-                            a: Region,\n-                            b: Region)\n-                            -> RelateResult<'tcx, Region>\n-    {\n-        debug!(\"glb_concrete_regions({:?}, {:?})\", a, b);\n-        match (a, b) {\n-            (ReLateBound(..), _) |\n-            (_, ReLateBound(..)) |\n-            (ReEarlyBound(..), _) |\n-            (_, ReEarlyBound(..)) => {\n-              self.tcx.sess.bug(\n-                  &format!(\"cannot relate bound region: GLB({:?}, {:?})\",\n-                          a,\n-                          b));\n-            }\n-\n-            (ReStatic, r) | (r, ReStatic) => {\n-                // static lives longer than everything else\n-                Ok(r)\n-            }\n-\n-            (ReEmpty, _) | (_, ReEmpty) => {\n-                // nothing lives shorter than everything else\n-                Ok(ReEmpty)\n-            }\n-\n-            (ReVar(v_id), _) |\n-            (_, ReVar(v_id)) => {\n-                self.tcx.sess.span_bug(\n-                    (*self.var_origins.borrow())[v_id.index as usize].span(),\n-                    &format!(\"glb_concrete_regions invoked with \\\n-                             non-concrete regions: {:?}, {:?}\",\n-                            a,\n-                            b));\n-            }\n-\n-            (ReFree(fr), ReScope(s_id)) |\n-            (ReScope(s_id), ReFree(fr)) => {\n-                let s = ReScope(s_id);\n-                // Free region is something \"at least as big as\n-                // `fr.scope_id`.\"  If we find that the scope `fr.scope_id` is bigger\n-                // than the scope `s_id`, then we can say that the GLB\n-                // is the scope `s_id`.  Otherwise, as we do not know\n-                // big the free region is precisely, the GLB is undefined.\n-                if self.tcx.region_maps.nearest_common_ancestor(fr.scope, s_id) == fr.scope ||\n-                        free_regions.is_static(fr) {\n-                    Ok(s)\n-                } else {\n-                    Err(TypeError::RegionsNoOverlap(b, a))\n-                }\n-            }\n-\n-            (ReScope(a_id), ReScope(b_id)) => {\n-                self.intersect_scopes(a, b, a_id, b_id)\n-            }\n-\n-            (ReFree(ref a_fr), ReFree(ref b_fr)) => {\n-                self.glb_free_regions(free_regions, a_fr, b_fr)\n-            }\n-\n-            // For these types, we cannot define any additional\n-            // relationship:\n-            (ReSkolemized(..), _) |\n-            (_, ReSkolemized(..)) => {\n-                if a == b {\n-                    Ok(a)\n-                } else {\n-                    Err(TypeError::RegionsNoOverlap(b, a))\n-                }\n-            }\n-        }\n-    }\n-\n-    /// Computes a region that is enclosed by both free region arguments, if any. Guarantees that\n-    /// if the same two regions are given as argument, in any order, a consistent result is\n-    /// returned.\n-    fn glb_free_regions(&self,\n-                        free_regions: &FreeRegionMap,\n-                        a: &FreeRegion,\n-                        b: &FreeRegion)\n-                        -> RelateResult<'tcx, ty::Region>\n-    {\n-        return match a.cmp(b) {\n-            Less => helper(self, free_regions, a, b),\n-            Greater => helper(self, free_regions, b, a),\n-            Equal => Ok(ty::ReFree(*a))\n-        };\n-\n-        fn helper<'a, 'tcx>(this: &RegionVarBindings<'a, 'tcx>,\n-                            free_regions: &FreeRegionMap,\n-                            a: &FreeRegion,\n-                            b: &FreeRegion) -> RelateResult<'tcx, ty::Region>\n-        {\n-            if free_regions.sub_free_region(*a, *b) {\n-                Ok(ty::ReFree(*a))\n-            } else if free_regions.sub_free_region(*b, *a) {\n-                Ok(ty::ReFree(*b))\n-            } else {\n-                this.intersect_scopes(ty::ReFree(*a), ty::ReFree(*b),\n-                                      a.scope, b.scope)\n-            }\n-        }\n-    }\n-\n-    fn intersect_scopes(&self,\n-                        region_a: ty::Region,\n-                        region_b: ty::Region,\n-                        scope_a: region::CodeExtent,\n-                        scope_b: region::CodeExtent)\n-                        -> RelateResult<'tcx, Region>\n-    {\n-        // We want to generate the intersection of two\n-        // scopes or two free regions.  So, if one of\n-        // these scopes is a subscope of the other, return\n-        // it. Otherwise fail.\n-        debug!(\"intersect_scopes(scope_a={:?}, scope_b={:?}, region_a={:?}, region_b={:?})\",\n-               scope_a, scope_b, region_a, region_b);\n-        let r_id = self.tcx.region_maps.nearest_common_ancestor(scope_a, scope_b);\n-        if r_id == scope_a {\n-            Ok(ReScope(scope_b))\n-        } else if r_id == scope_b {\n-            Ok(ReScope(scope_a))\n-        } else {\n-            Err(TypeError::RegionsNoOverlap(region_a, region_b))\n-        }\n-    }\n }\n \n // ______________________________________________________________________\n \n-#[derive(Copy, Clone, PartialEq, Debug)]\n-enum Classification { Expanding, Contracting }\n-\n #[derive(Copy, Clone, Debug)]\n-pub enum VarValue { NoValue, Value(Region), ErrorValue }\n+pub enum VarValue { Value(Region), ErrorValue }\n \n struct VarData {\n-    classification: Classification,\n     value: VarValue,\n }\n \n@@ -1005,12 +862,7 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n     fn construct_var_data(&self) -> Vec<VarData> {\n         (0..self.num_vars() as usize).map(|_| {\n             VarData {\n-                // All nodes are initially classified as contracting; during\n-                // the expansion phase, we will shift the classification for\n-                // those nodes that have a concrete region predecessor to\n-                // Expanding.\n-                classification: Contracting,\n-                value: NoValue,\n+                value: Value(ty::ReEmpty),\n             }\n         }).collect()\n     }\n@@ -1062,11 +914,11 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n               }\n               ConstrainVarSubVar(a_vid, b_vid) => {\n                 match var_data[a_vid.index as usize].value {\n-                  NoValue | ErrorValue => false,\n-                  Value(a_region) => {\n-                    let b_node = &mut var_data[b_vid.index as usize];\n-                    self.expand_node(free_regions, a_region, b_vid, b_node)\n-                  }\n+                    ErrorValue => false,\n+                    Value(a_region) => {\n+                        let b_node = &mut var_data[b_vid.index as usize];\n+                        self.expand_node(free_regions, a_region, b_vid, b_node)\n+                    }\n                 }\n               }\n               ConstrainVarSubReg(..) => {\n@@ -1100,16 +952,7 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n             _ => { }\n         }\n \n-        b_data.classification = Expanding;\n         match b_data.value {\n-          NoValue => {\n-            debug!(\"Setting initial value of {:?} to {:?}\",\n-                   b_vid, a_region);\n-\n-            b_data.value = Value(a_region);\n-            return true;\n-          }\n-\n           Value(cur_region) => {\n             let lub = self.lub_concrete_regions(free_regions, a_region, cur_region);\n             if lub == cur_region {\n@@ -1131,6 +974,7 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n         }\n     }\n \n+    // FIXME(#29436) -- this fn would just go away if we removed ConstrainVarSubReg\n     fn contraction(&self,\n                    free_regions: &FreeRegionMap,\n                    var_data: &mut [VarData]) {\n@@ -1142,104 +986,31 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n                                    .unwrap()\n                                    );\n             match *constraint {\n-              ConstrainRegSubVar(..) => {\n-                // This is an expansion constraint.  Ignore.\n-                false\n-              }\n-              ConstrainVarSubVar(a_vid, b_vid) => {\n-                match var_data[b_vid.index as usize].value {\n-                  NoValue | ErrorValue => false,\n-                  Value(b_region) => {\n-                    let a_data = &mut var_data[a_vid.index as usize];\n-                    self.contract_node(free_regions, a_vid, a_data, b_region)\n-                  }\n+                ConstrainRegSubVar(..) |\n+                ConstrainVarSubVar(..) => {\n+                    // Expansion will ensure that these constraints hold. Ignore.\n                 }\n-              }\n-              ConstrainVarSubReg(a_vid, b_region) => {\n-                let a_data = &mut var_data[a_vid.index as usize];\n-                self.contract_node(free_regions, a_vid, a_data, b_region)\n-              }\n-            }\n-        })\n-    }\n-\n-    fn contract_node(&self,\n-                     free_regions: &FreeRegionMap,\n-                     a_vid: RegionVid,\n-                     a_data: &mut VarData,\n-                     b_region: Region)\n-                     -> bool {\n-        debug!(\"contract_node({:?} == {:?}/{:?}, {:?})\",\n-               a_vid, a_data.value,\n-               a_data.classification, b_region);\n-\n-        return match a_data.value {\n-            NoValue => {\n-                assert_eq!(a_data.classification, Contracting);\n-                a_data.value = Value(b_region);\n-                true // changed\n-            }\n-\n-            ErrorValue => false, // no change\n-\n-            Value(a_region) => {\n-                match a_data.classification {\n-                    Expanding =>\n-                        check_node(self, free_regions, a_vid, a_data, a_region, b_region),\n-                    Contracting =>\n-                        adjust_node(self, free_regions, a_vid, a_data, a_region, b_region),\n+                ConstrainVarSubReg(a_vid, b_region) => {\n+                    let a_data = &mut var_data[a_vid.index as usize];\n+                    debug!(\"contraction: {:?} == {:?}, {:?}\", a_vid, a_data.value, b_region);\n+\n+                    let a_region = match a_data.value {\n+                        ErrorValue => return false,\n+                        Value(a_region) => a_region,\n+                    };\n+\n+                    if !free_regions.is_subregion_of(self.tcx, a_region, b_region) {\n+                        debug!(\"Setting {:?} to ErrorValue: {:?} not subregion of {:?}\",\n+                            a_vid,\n+                            a_region,\n+                            b_region);\n+                        a_data.value = ErrorValue;\n+                    }\n                 }\n             }\n-        };\n \n-        fn check_node(this: &RegionVarBindings,\n-                      free_regions: &FreeRegionMap,\n-                      a_vid: RegionVid,\n-                      a_data: &mut VarData,\n-                      a_region: Region,\n-                      b_region: Region)\n-                      -> bool\n-        {\n-            if !free_regions.is_subregion_of(this.tcx, a_region, b_region) {\n-                debug!(\"Setting {:?} to ErrorValue: {:?} not subregion of {:?}\",\n-                       a_vid,\n-                       a_region,\n-                       b_region);\n-                a_data.value = ErrorValue;\n-            }\n             false\n-        }\n-\n-        fn adjust_node(this: &RegionVarBindings,\n-                       free_regions: &FreeRegionMap,\n-                       a_vid: RegionVid,\n-                       a_data: &mut VarData,\n-                       a_region: Region,\n-                       b_region: Region)\n-                       -> bool {\n-            match this.glb_concrete_regions(free_regions, a_region, b_region) {\n-                Ok(glb) => {\n-                    if glb == a_region {\n-                        false\n-                    } else {\n-                        debug!(\"Contracting value of {:?} from {:?} to {:?}\",\n-                               a_vid,\n-                               a_region,\n-                               glb);\n-                        a_data.value = Value(glb);\n-                        true\n-                    }\n-                }\n-                Err(_) => {\n-                    debug!(\"Setting {:?} to ErrorValue: no glb of {:?}, {:?}\",\n-                           a_vid,\n-                           a_region,\n-                           b_region);\n-                    a_data.value = ErrorValue;\n-                    false\n-                }\n-            }\n-        }\n+        })\n     }\n \n     fn collect_concrete_region_errors(&self,\n@@ -1308,12 +1079,6 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n                 Value(_) => {\n                     /* Inference successful */\n                 }\n-                NoValue => {\n-                    /* Unconstrained inference: do not report an error\n-                       until the value of this variable is requested.\n-                       After all, sometimes we make region variables but never\n-                       really use their values. */\n-                }\n                 ErrorValue => {\n                     /* Inference impossible, this value contains\n                        inconsistent constraints.\n@@ -1339,18 +1104,8 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n                        this portion of the code and think hard about it. =) */\n \n                     let node_vid = RegionVid { index: idx as u32 };\n-                    match var_data[idx].classification {\n-                        Expanding => {\n-                            self.collect_error_for_expanding_node(\n-                                free_regions, graph, var_data, &mut dup_vec,\n-                                node_vid, errors);\n-                        }\n-                        Contracting => {\n-                            self.collect_error_for_contracting_node(\n-                                free_regions, graph, var_data, &mut dup_vec,\n-                                node_vid, errors);\n-                        }\n-                    }\n+                    self.collect_error_for_expanding_node(\n+                        free_regions, graph, &mut dup_vec, node_vid, errors);\n                 }\n             }\n         }\n@@ -1396,19 +1151,16 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n     fn collect_error_for_expanding_node(&self,\n                                         free_regions: &FreeRegionMap,\n                                         graph: &RegionGraph,\n-                                        var_data: &[VarData],\n                                         dup_vec: &mut [u32],\n                                         node_idx: RegionVid,\n                                         errors: &mut Vec<RegionResolutionError<'tcx>>)\n     {\n         // Errors in expanding nodes result from a lower-bound that is\n         // not contained by an upper-bound.\n         let (mut lower_bounds, lower_dup) =\n-            self.collect_concrete_regions(graph, var_data, node_idx,\n-                                          graph::INCOMING, dup_vec);\n+            self.collect_concrete_regions(graph, node_idx, graph::INCOMING, dup_vec);\n         let (mut upper_bounds, upper_dup) =\n-            self.collect_concrete_regions(graph, var_data, node_idx,\n-                                          graph::OUTGOING, dup_vec);\n+            self.collect_concrete_regions(graph, node_idx, graph::OUTGOING, dup_vec);\n \n         if lower_dup || upper_dup {\n             return;\n@@ -1459,59 +1211,8 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n                     upper_bounds));\n     }\n \n-    fn collect_error_for_contracting_node(\n-        &self,\n-        free_regions: &FreeRegionMap,\n-        graph: &RegionGraph,\n-        var_data: &[VarData],\n-        dup_vec: &mut [u32],\n-        node_idx: RegionVid,\n-        errors: &mut Vec<RegionResolutionError<'tcx>>)\n-    {\n-        // Errors in contracting nodes result from two upper-bounds\n-        // that have no intersection.\n-        let (upper_bounds, dup_found) =\n-            self.collect_concrete_regions(graph, var_data, node_idx,\n-                                          graph::OUTGOING, dup_vec);\n-\n-        if dup_found {\n-            return;\n-        }\n-\n-        for upper_bound_1 in &upper_bounds {\n-            for upper_bound_2 in &upper_bounds {\n-                match self.glb_concrete_regions(free_regions,\n-                                                upper_bound_1.region,\n-                                                upper_bound_2.region) {\n-                    Ok(_) => {}\n-                    Err(_) => {\n-                        let origin = (*self.var_origins.borrow())[node_idx.index as usize].clone();\n-                        debug!(\"region inference error at {:?} for {:?}: \\\n-                                SupSupConflict sub: {:?} sup: {:?}\",\n-                               origin, node_idx, upper_bound_1.region, upper_bound_2.region);\n-                        errors.push(SupSupConflict(\n-                            origin,\n-                            upper_bound_1.origin.clone(),\n-                            upper_bound_1.region,\n-                            upper_bound_2.origin.clone(),\n-                            upper_bound_2.region));\n-                        return;\n-                    }\n-                }\n-            }\n-        }\n-\n-        self.tcx.sess.span_bug(\n-            (*self.var_origins.borrow())[node_idx.index as usize].span(),\n-            &format!(\"collect_error_for_contracting_node() could not find error \\\n-                     for var {:?}, upper_bounds={:?}\",\n-                    node_idx,\n-                    upper_bounds));\n-    }\n-\n     fn collect_concrete_regions(&self,\n                                 graph: &RegionGraph,\n-                                var_data: &[VarData],\n                                 orig_node_idx: RegionVid,\n                                 dir: Direction,\n                                 dup_vec: &mut [u32])\n@@ -1536,7 +1237,6 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n \n         while !state.stack.is_empty() {\n             let node_idx = state.stack.pop().unwrap();\n-            let classification = var_data[node_idx.index as usize].classification;\n \n             // check whether we've visited this node on some previous walk\n             if dup_vec[node_idx.index as usize] == u32::MAX {\n@@ -1545,17 +1245,12 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n                 state.dup_found = true;\n             }\n \n-            debug!(\"collect_concrete_regions(orig_node_idx={:?}, node_idx={:?}, \\\n-                    classification={:?})\",\n-                   orig_node_idx, node_idx, classification);\n+            debug!(\"collect_concrete_regions(orig_node_idx={:?}, node_idx={:?})\",\n+                   orig_node_idx, node_idx);\n \n             // figure out the direction from which this node takes its\n             // values, and search for concrete regions etc in that direction\n-            let dir = match classification {\n-                Expanding => graph::INCOMING,\n-                Contracting => graph::OUTGOING,\n-            };\n-\n+            let dir = graph::INCOMING;\n             process_edges(self, &mut state, graph, node_idx, dir);\n         }\n \n@@ -1638,7 +1333,6 @@ fn normalize(values: &Vec<VarValue>, r: ty::Region) -> ty::Region {\n fn lookup(values: &Vec<VarValue>, rid: ty::RegionVid) -> ty::Region {\n     match values[rid.index as usize] {\n         Value(r) => r,\n-        NoValue => ReEmpty, // No constraints, return ty::ReEmpty\n         ErrorValue => ReStatic, // Previously reported error.\n     }\n }"}, {"sha": "4bbc22ef1a273d87bcaf3bfa55ab082ebd24b74b", "filename": "src/librustc_driver/test.rs", "status": "modified", "additions": 14, "deletions": 10, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc_driver%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc_driver%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Ftest.rs?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -351,6 +351,11 @@ impl<'a, 'tcx> Env<'a, 'tcx> {\n                                    self.tcx().types.isize)\n     }\n \n+    pub fn t_rptr_empty(&self) -> Ty<'tcx> {\n+        self.infcx.tcx.mk_imm_ref(self.infcx.tcx.mk_region(ty::ReEmpty),\n+                                   self.tcx().types.isize)\n+    }\n+\n     pub fn dummy_type_trace(&self) -> infer::TypeTrace<'tcx> {\n         infer::TypeTrace::dummy(self.tcx())\n     }\n@@ -593,16 +598,15 @@ fn lub_free_free() {\n \n #[test]\n fn lub_returning_scope() {\n-    test_env(EMPTY_SOURCE_STR,\n-             errors(&[\"cannot infer an appropriate lifetime\"]), |env| {\n-                 env.create_simple_region_hierarchy();\n-                 let t_rptr_scope10 = env.t_rptr_scope(10);\n-                 let t_rptr_scope11 = env.t_rptr_scope(11);\n-\n-                 // this should generate an error when regions are resolved\n-                 env.make_lub_ty(env.t_fn(&[], t_rptr_scope10),\n-                                 env.t_fn(&[], t_rptr_scope11));\n-             })\n+    test_env(EMPTY_SOURCE_STR, errors(&[]), |env| {\n+        env.create_simple_region_hierarchy();\n+        let t_rptr_scope10 = env.t_rptr_scope(10);\n+        let t_rptr_scope11 = env.t_rptr_scope(11);\n+        let t_rptr_empty = env.t_rptr_empty();\n+        env.check_lub(env.t_fn(&[t_rptr_scope10], env.tcx().types.isize),\n+                      env.t_fn(&[t_rptr_scope11], env.tcx().types.isize),\n+                      env.t_fn(&[t_rptr_empty], env.tcx().types.isize));\n+    });\n }\n \n #[test]"}, {"sha": "ef1bb9cee174ddab6bc3716180383a11c7279b83", "filename": "src/librustc_typeck/check/_match.rs", "status": "modified", "additions": 20, "deletions": 7, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc_typeck%2Fcheck%2F_match.rs", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc_typeck%2Fcheck%2F_match.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2F_match.rs?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -259,17 +259,30 @@ pub fn check_pat<'a, 'tcx>(pcx: &pat_ctxt<'a, 'tcx>,\n             }\n         }\n         hir::PatRegion(ref inner, mutbl) => {\n-            let inner_ty = fcx.infcx().next_ty_var();\n-\n-            let mt = ty::TypeAndMut { ty: inner_ty, mutbl: mutbl };\n-            let region = fcx.infcx().next_region_var(infer::PatternRegion(pat.span));\n-            let rptr_ty = tcx.mk_ref(tcx.mk_region(region), mt);\n-\n+            let expected = fcx.infcx().shallow_resolve(expected);\n             if check_dereferencable(pcx, pat.span, expected, &**inner) {\n                 // `demand::subtype` would be good enough, but using\n                 // `eqtype` turns out to be equally general. See (*)\n                 // below for details.\n-                demand::eqtype(fcx, pat.span, expected, rptr_ty);\n+\n+                // Take region, inner-type from expected type if we\n+                // can, to avoid creating needless variables.  This\n+                // also helps with the bad interactions of the given\n+                // hack detailed in (*) below.\n+                let (rptr_ty, inner_ty) = match expected.sty {\n+                    ty::TyRef(_, mt) if mt.mutbl == mutbl => {\n+                        (expected, mt.ty)\n+                    }\n+                    _ => {\n+                        let inner_ty = fcx.infcx().next_ty_var();\n+                        let mt = ty::TypeAndMut { ty: inner_ty, mutbl: mutbl };\n+                        let region = fcx.infcx().next_region_var(infer::PatternRegion(pat.span));\n+                        let rptr_ty = tcx.mk_ref(tcx.mk_region(region), mt);\n+                        demand::eqtype(fcx, pat.span, expected, rptr_ty);\n+                        (rptr_ty, inner_ty)\n+                    }\n+                };\n+\n                 fcx.write_ty(pat.id, rptr_ty);\n                 check_pat(pcx, &**inner, inner_ty);\n             } else {"}, {"sha": "7c6417e61d464de18791032f8d885a9f5b503855", "filename": "src/librustc_typeck/check/regionck.rs", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc_typeck%2Fcheck%2Fregionck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Flibrustc_typeck%2Fcheck%2Fregionck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fregionck.rs?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -1182,9 +1182,10 @@ fn link_fn_args(rcx: &Rcx, body_scope: CodeExtent, args: &[hir::Arg]) {\n         let arg_ty = rcx.fcx.node_ty(arg.id);\n         let re_scope = ty::ReScope(body_scope);\n         let arg_cmt = mc.cat_rvalue(arg.id, arg.ty.span, re_scope, arg_ty);\n-        debug!(\"arg_ty={:?} arg_cmt={:?}\",\n+        debug!(\"arg_ty={:?} arg_cmt={:?} arg={:?}\",\n                arg_ty,\n-               arg_cmt);\n+               arg_cmt,\n+               arg);\n         link_pattern(rcx, mc, arg_cmt, &*arg.pat);\n     }\n }\n@@ -1527,9 +1528,10 @@ pub fn type_must_outlive<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n {\n     let ty = rcx.resolve_type(ty);\n \n-    debug!(\"type_must_outlive(ty={:?}, region={:?})\",\n+    debug!(\"type_must_outlive(ty={:?}, region={:?}, origin={:?})\",\n            ty,\n-           region);\n+           region,\n+           origin);\n \n     assert!(!ty.has_escaping_regions());\n "}, {"sha": "2f437c7a814793f91dc7410aa7f949e26c26ce16", "filename": "src/test/run-fail/issue-28934.rs", "status": "added", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Ftest%2Frun-fail%2Fissue-28934.rs", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Ftest%2Frun-fail%2Fissue-28934.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-fail%2Fissue-28934.rs?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -0,0 +1,28 @@\n+// Copyright 2015 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// Regression test: issue had to do with \"givens\" in region inference,\n+// which were not being considered during the contraction phase.\n+\n+// error-pattern:explicit panic\n+\n+struct Parser<'i: 't, 't>(&'i u8, &'t u8);\n+\n+impl<'i, 't> Parser<'i, 't> {\n+    fn parse_nested_block<F, T>(&mut self, parse: F) -> Result<T, ()>\n+        where for<'tt> F: FnOnce(&mut Parser<'i, 'tt>) -> T { panic!() }\n+\n+    fn expect_exhausted(&mut self) -> Result<(), ()> { Ok(()) }\n+}\n+\n+fn main() {\n+    let x = 0u8;\n+    Parser(&x, &x).parse_nested_block(|input| input.expect_exhausted()).unwrap();\n+}"}, {"sha": "48f4327d3e99a89da31095fd2f0c6da74690eadf", "filename": "src/test/run-pass/issue-29048.rs", "status": "added", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/427140f771828d5a2fce7a21d97359d2967c3239/src%2Ftest%2Frun-pass%2Fissue-29048.rs", "raw_url": "https://github.com/rust-lang/rust/raw/427140f771828d5a2fce7a21d97359d2967c3239/src%2Ftest%2Frun-pass%2Fissue-29048.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-29048.rs?ref=427140f771828d5a2fce7a21d97359d2967c3239", "patch": "@@ -0,0 +1,21 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+pub struct Chan;\n+pub struct ChanSelect<'c, T> {\n+    chans: Vec<(&'c Chan, T)>,\n+}\n+impl<'c, T> ChanSelect<'c, T> {\n+    pub fn add_recv_ret(&mut self, chan: &'c Chan, ret: T)\n+    {\n+        self.chans.push((chan, ret));\n+    }\n+}\n+fn main() {}"}]}