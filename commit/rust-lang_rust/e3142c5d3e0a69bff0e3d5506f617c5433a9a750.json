{"sha": "e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "node_id": "MDY6Q29tbWl0NzI0NzEyOmUzMTQyYzVkM2UwYTY5YmZmMGUzZDU1MDZmNjE3YzU0MzNhOWE3NTA=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-07-20T10:55:39Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-07-20T10:55:39Z"}, "message": "auto merge of #7858 : bblum/rust/kill, r=brson\n\nSome notes about the commits.\r\n\r\nExit code propagation commits:\r\n* ```Reimplement unwrap()``` has the same old code from ```arc::unwrap``` ported to use modern atomic types and finally (it's considerably nicer this way)\r\n* ```Add try_unwrap()``` has some new slightly-tricky (but pretty simple) concurrency primitive code\r\n* ```Add KillHandle``` and ```Add kill::Death``` are the bulk of the logic.\r\n\r\nTask killing commits:\r\n* ```Implement KillHandle::kill() and friends```, ```Do a task-killed check```, and ```Add BlockedTask``` implement the killing logic;\r\n* ```Change the HOF context switchers``` turns said logic on\r\n\r\nLinked failure commits:\r\n* ```Replace *rust_task ptrs``` adapts the taskgroup code to work for both runtimes\r\n* ```Enable taskgroup code``` does what it says on the tin.\r\n\r\nr? @brson", "tree": {"sha": "ac663b8946ea8d8f18f0c3c58cef11235b173ab0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ac663b8946ea8d8f18f0c3c58cef11235b173ab0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "html_url": "https://github.com/rust-lang/rust/commit/e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fdbd56ca38c4a58377056c63e0b03b0d4e131f2c", "url": "https://api.github.com/repos/rust-lang/rust/commits/fdbd56ca38c4a58377056c63e0b03b0d4e131f2c", "html_url": "https://github.com/rust-lang/rust/commit/fdbd56ca38c4a58377056c63e0b03b0d4e131f2c"}, {"sha": "980646a4501a9622db40d3519a8f6db98f4359a1", "url": "https://api.github.com/repos/rust-lang/rust/commits/980646a4501a9622db40d3519a8f6db98f4359a1", "html_url": "https://github.com/rust-lang/rust/commit/980646a4501a9622db40d3519a8f6db98f4359a1"}], "stats": {"total": 3233, "additions": 1979, "deletions": 1254}, "files": [{"sha": "404d5bfde58761f86193062f49452bb3918c47e1", "filename": "src/libextra/arc.rs", "status": "modified", "additions": 72, "deletions": 8, "changes": 80, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Farc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Farc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Farc.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -50,9 +50,9 @@ use std::borrow;\n \n /// As sync::condvar, a mechanism for unlock-and-descheduling and signaling.\n pub struct Condvar<'self> {\n-    is_mutex: bool,\n-    failed: &'self mut bool,\n-    cond: &'self sync::Condvar<'self>\n+    priv is_mutex: bool,\n+    priv failed: &'self mut bool,\n+    priv cond: &'self sync::Condvar<'self>\n }\n \n impl<'self> Condvar<'self> {\n@@ -108,7 +108,7 @@ impl<'self> Condvar<'self> {\n  ****************************************************************************/\n \n /// An atomically reference counted wrapper for shared immutable state.\n-pub struct ARC<T> { x: UnsafeAtomicRcBox<T> }\n+pub struct ARC<T> { priv x: UnsafeAtomicRcBox<T> }\n \n /// Create an atomically reference counted wrapper.\n pub fn ARC<T:Freeze + Send>(data: T) -> ARC<T> {\n@@ -123,6 +123,20 @@ impl<T:Freeze+Send> ARC<T> {\n     pub fn get<'a>(&'a self) -> &'a T {\n         unsafe { &*self.x.get_immut() }\n     }\n+\n+    /**\n+     * Retrieve the data back out of the ARC. This function blocks until the\n+     * reference given to it is the last existing one, and then unwrap the data\n+     * instead of destroying it.\n+     *\n+     * If multiple tasks call unwrap, all but the first will fail. Do not call\n+     * unwrap from a task that holds another reference to the same ARC; it is\n+     * guaranteed to deadlock.\n+     */\n+    pub fn unwrap(self) -> T {\n+        let ARC { x: x } = self;\n+        unsafe { x.unwrap() }\n+    }\n }\n \n /**\n@@ -143,9 +157,9 @@ impl<T:Freeze + Send> Clone for ARC<T> {\n  ****************************************************************************/\n \n #[doc(hidden)]\n-struct MutexARCInner<T> { lock: Mutex, failed: bool, data: T }\n+struct MutexARCInner<T> { priv lock: Mutex, priv failed: bool, priv data: T }\n /// An ARC with mutable data protected by a blocking mutex.\n-struct MutexARC<T> { x: UnsafeAtomicRcBox<MutexARCInner<T>> }\n+struct MutexARC<T> { priv x: UnsafeAtomicRcBox<MutexARCInner<T>> }\n \n /// Create a mutex-protected ARC with the supplied data.\n pub fn MutexARC<T:Send>(user_data: T) -> MutexARC<T> {\n@@ -225,6 +239,22 @@ impl<T:Send> MutexARC<T> {\n                           cond: cond })\n         }\n     }\n+\n+    /**\n+     * Retrieves the data, blocking until all other references are dropped,\n+     * exactly as arc::unwrap.\n+     *\n+     * Will additionally fail if another task has failed while accessing the arc.\n+     */\n+    pub fn unwrap(self) -> T {\n+        let MutexARC { x: x } = self;\n+        let inner = unsafe { x.unwrap() };\n+        let MutexARCInner { failed: failed, data: data, _ } = inner;\n+        if failed {\n+            fail!(~\"Can't unwrap poisoned MutexARC - another task failed inside!\");\n+        }\n+        data\n+    }\n }\n \n // Common code for {mutex.access,rwlock.write}{,_cond}.\n@@ -268,7 +298,7 @@ fn PoisonOnFail<'r>(failed: &'r mut bool) -> PoisonOnFail {\n  ****************************************************************************/\n \n #[doc(hidden)]\n-struct RWARCInner<T> { lock: RWlock, failed: bool, data: T }\n+struct RWARCInner<T> { priv lock: RWlock, priv failed: bool, priv data: T }\n /**\n  * A dual-mode ARC protected by a reader-writer lock. The data can be accessed\n  * mutably or immutably, and immutably-accessing tasks may run concurrently.\n@@ -278,7 +308,7 @@ struct RWARCInner<T> { lock: RWlock, failed: bool, data: T }\n #[mutable] // XXX remove after snap\n #[no_freeze]\n struct RWARC<T> {\n-    x: UnsafeAtomicRcBox<RWARCInner<T>>,\n+    priv x: UnsafeAtomicRcBox<RWARCInner<T>>,\n }\n \n /// Create a reader/writer ARC with the supplied data.\n@@ -429,6 +459,23 @@ impl<T:Freeze + Send> RWARC<T> {\n             }\n         }\n     }\n+\n+    /**\n+     * Retrieves the data, blocking until all other references are dropped,\n+     * exactly as arc::unwrap.\n+     *\n+     * Will additionally fail if another task has failed while accessing the arc\n+     * in write mode.\n+     */\n+    pub fn unwrap(self) -> T {\n+        let RWARC { x: x, _ } = self;\n+        let inner = unsafe { x.unwrap() };\n+        let RWARCInner { failed: failed, data: data, _ } = inner;\n+        if failed {\n+            fail!(~\"Can't unwrap poisoned RWARC - another task failed inside!\")\n+        }\n+        data\n+    }\n }\n \n // Borrowck rightly complains about immutably aliasing the rwlock in order to\n@@ -611,6 +658,23 @@ mod tests {\n         }\n     }\n     #[test] #[should_fail] #[ignore(cfg(windows))]\n+    pub fn test_mutex_arc_unwrap_poison() {\n+        let arc = MutexARC(1);\n+        let arc2 = ~(&arc).clone();\n+        let (p, c) = comm::stream();\n+        do task::spawn {\n+            unsafe {\n+                do arc2.access |one| {\n+                    c.send(());\n+                    assert!(*one == 2);\n+                }\n+            }\n+        }\n+        let _ = p.recv();\n+        let one = arc.unwrap();\n+        assert!(one == 1);\n+    }\n+    #[test] #[should_fail] #[ignore(cfg(windows))]\n     fn test_rw_arc_poison_wr() {\n         let arc = ~RWARC(1);\n         let arc2 = (*arc).clone();"}, {"sha": "c42eba1ffa29cd1aab52b5b47188150007c02605", "filename": "src/libextra/dlist.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fdlist.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fdlist.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fdlist.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -208,7 +208,7 @@ impl<T> Deque<T> for DList<T> {\n     ///\n     /// O(1)\n     fn pop_front(&mut self) -> Option<T> {\n-        match util::replace(&mut self.list_head, None) {\n+        match self.list_head.take() {\n             None => None,\n             Some(old_head) => {\n                 self.length -= 1;"}, {"sha": "f46af664b189f630508677050fababf46915a9d5", "filename": "src/libextra/ringbuf.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fringbuf.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fringbuf.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fringbuf.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -14,7 +14,6 @@\n //! extra::container::Deque`.\n \n use std::num;\n-use std::util;\n use std::uint;\n use std::vec;\n use std::iterator::{FromIterator, InvertIterator};\n@@ -72,7 +71,7 @@ impl<T> Deque<T> for RingBuf<T> {\n \n     /// Remove and return the first element in the RingBuf, or None if it is empty\n     fn pop_front(&mut self) -> Option<T> {\n-        let result = util::replace(&mut self.elts[self.lo], None);\n+        let result = self.elts[self.lo].take();\n         if result.is_some() {\n             self.lo = (self.lo + 1u) % self.elts.len();\n             self.nelts -= 1u;\n@@ -85,7 +84,7 @@ impl<T> Deque<T> for RingBuf<T> {\n         if self.nelts > 0 {\n             self.nelts -= 1;\n             let hi = self.raw_index(self.nelts);\n-            util::replace(&mut self.elts[hi], None)\n+            self.elts[hi].take()\n         } else {\n             None\n         }"}, {"sha": "6ff219a4f8f7b2d61c2d96e059a4b888df905e35", "filename": "src/libextra/smallintmap.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fsmallintmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fsmallintmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fsmallintmap.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -118,7 +118,7 @@ impl<V> MutableMap<uint, V> for SmallIntMap<V> {\n         if *key >= self.v.len() {\n             return None;\n         }\n-        replace(&mut self.v[*key], None)\n+        self.v[*key].take()\n     }\n }\n "}, {"sha": "57d8563861e353dd9cded407f8b8154938853ee5", "filename": "src/libextra/sort.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fsort.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fsort.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fsort.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -1020,8 +1020,6 @@ mod big_tests {\n \n     use sort::*;\n \n-    use std::cast::unsafe_copy;\n-    use std::local_data;\n     use std::rand::RngUtil;\n     use std::rand;\n     use std::uint;"}, {"sha": "7e0cb76b5156157e0278416398ccbf5eb5751bb8", "filename": "src/libextra/treemap.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Ftreemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Ftreemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Ftreemap.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -697,7 +697,7 @@ fn remove<K: TotalOrd, V>(node: &mut Option<~TreeNode<K, V>>,\n         }\n       }\n     }\n-    return match replace(node, None) {\n+    return match node.take() {\n         Some(~TreeNode{value, _}) => Some(value), None => fail!()\n     };\n }"}, {"sha": "ea13f33199912183d7ea39a31ac2257a76c765d8", "filename": "src/libextra/workcache.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fworkcache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibextra%2Fworkcache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fworkcache.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -27,7 +27,6 @@ use std::result;\n use std::run;\n use std::task;\n use std::to_bytes;\n-use std::util::replace;\n \n /**\n *\n@@ -353,7 +352,7 @@ impl TPrep for Prep {\n \n             _ => {\n                 let (port, chan) = oneshot();\n-                let blk = replace(&mut bo, None).unwrap();\n+                let blk = bo.take_unwrap();\n                 let chan = Cell::new(chan);\n \n                 do task::spawn {\n@@ -385,7 +384,7 @@ fn unwrap<T:Send +\n             Decodable<json::Decoder>>( // FIXME(#5121)\n         w: Work<T>) -> T {\n     let mut ww = w;\n-    let s = replace(&mut ww.res, None);\n+    let s = ww.res.take();\n \n     match s {\n         None => fail!(),"}, {"sha": "695ed0749dde0216bb1e860e38644b402b5e7313", "filename": "src/libstd/cell.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fcell.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fcell.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcell.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -14,7 +14,6 @@\n \n use cast::transmute_mut;\n use prelude::*;\n-use util::replace;\n \n /*\n A dynamic, mutable location.\n@@ -48,7 +47,7 @@ impl<T> Cell<T> {\n             fail!(\"attempt to take an empty cell\");\n         }\n \n-        replace(&mut this.value, None).unwrap()\n+        this.value.take_unwrap()\n     }\n \n     /// Returns the value, failing if the cell is full."}, {"sha": "b9dacc142cebc24e7d7ee9c2d1feb752e923aa7e", "filename": "src/libstd/comm.rs", "status": "modified", "additions": 7, "deletions": 12, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fcomm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fcomm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -242,8 +242,7 @@ impl<T: Send> GenericChan<T> for SharedChan<T> {\n                 unsafe {\n                     let mut xx = Some(x);\n                     do chan.with_imm |chan| {\n-                        let x = replace(&mut xx, None);\n-                        chan.send(x.unwrap())\n+                        chan.send(xx.take_unwrap())\n                     }\n                 }\n             }\n@@ -259,8 +258,7 @@ impl<T: Send> GenericSmartChan<T> for SharedChan<T> {\n                 unsafe {\n                     let mut xx = Some(x);\n                     do chan.with_imm |chan| {\n-                        let x = replace(&mut xx, None);\n-                        chan.try_send(x.unwrap())\n+                        chan.try_send(xx.take_unwrap())\n                     }\n                 }\n             }\n@@ -372,7 +370,6 @@ mod pipesy {\n     use pipes::{recv, try_recv, peek, PacketHeader};\n     use super::{GenericChan, GenericSmartChan, GenericPort, Peekable, Selectable};\n     use cast::transmute_mut;\n-    use util::replace;\n \n     /*proto! oneshot (\n         Oneshot:send<T:Send> {\n@@ -638,8 +635,7 @@ mod pipesy {\n         fn send(&self, x: T) {\n             unsafe {\n                 let self_endp = transmute_mut(&self.endp);\n-                let endp = replace(self_endp, None);\n-                *self_endp = Some(streamp::client::data(endp.unwrap(), x))\n+                *self_endp = Some(streamp::client::data(self_endp.take_unwrap(), x))\n             }\n         }\n     }\n@@ -649,8 +645,7 @@ mod pipesy {\n         fn try_send(&self, x: T) -> bool {\n             unsafe {\n                 let self_endp = transmute_mut(&self.endp);\n-                let endp = replace(self_endp, None);\n-                match streamp::client::try_data(endp.unwrap(), x) {\n+                match streamp::client::try_data(self_endp.take_unwrap(), x) {\n                     Some(next) => {\n                         *self_endp = Some(next);\n                         true\n@@ -666,7 +661,7 @@ mod pipesy {\n         fn recv(&self) -> T {\n             unsafe {\n                 let self_endp = transmute_mut(&self.endp);\n-                let endp = replace(self_endp, None);\n+                let endp = self_endp.take();\n                 let streamp::data(x, endp) = recv(endp.unwrap());\n                 *self_endp = Some(endp);\n                 x\n@@ -677,7 +672,7 @@ mod pipesy {\n         fn try_recv(&self) -> Option<T> {\n             unsafe {\n                 let self_endp = transmute_mut(&self.endp);\n-                let endp = replace(self_endp, None);\n+                let endp = self_endp.take();\n                 match try_recv(endp.unwrap()) {\n                     Some(streamp::data(x, endp)) => {\n                         *self_endp = Some(endp);\n@@ -694,7 +689,7 @@ mod pipesy {\n         fn peek(&self) -> bool {\n             unsafe {\n                 let self_endp = transmute_mut(&self.endp);\n-                let mut endp = replace(self_endp, None);\n+                let mut endp = self_endp.take();\n                 let peek = match endp {\n                     Some(ref mut endp) => peek(endp),\n                     None => fail!(\"peeking empty stream\")"}, {"sha": "4fb43e5157b433acc03a52ec25ef9c24591dfdaf", "filename": "src/libstd/either.rs", "status": "modified", "additions": 26, "deletions": 6, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Feither.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Feither.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Feither.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -18,6 +18,7 @@ use cmp::Eq;\n use iterator::IteratorUtil;\n use result::Result;\n use result;\n+use str::StrSlice;\n use vec;\n use vec::{OwnedVector, ImmutableVector};\n \n@@ -121,24 +122,37 @@ pub fn is_right<T, U>(eith: &Either<T, U>) -> bool {\n     }\n }\n \n-/// Retrieves the value in the left branch. Fails if the either is Right.\n+/// Retrieves the value in the left branch.\n+/// Fails with a specified reason if the either is Right.\n #[inline]\n-pub fn unwrap_left<T,U>(eith: Either<T,U>) -> T {\n+pub fn expect_left<T,U>(eith: Either<T,U>, reason: &str) -> T {\n     match eith {\n         Left(x) => x,\n-        Right(_) => fail!(\"either::unwrap_left Right\")\n+        Right(_) => fail!(reason.to_owned())\n     }\n }\n \n-/// Retrieves the value in the right branch. Fails if the either is Left.\n+/// Retrieves the value in the left branch. Fails if the either is Right.\n #[inline]\n-pub fn unwrap_right<T,U>(eith: Either<T,U>) -> U {\n+pub fn unwrap_left<T,U>(eith: Either<T,U>) -> T {\n+    expect_left(eith, \"either::unwrap_left Right\")\n+}\n+\n+/// Retrieves the value in the right branch.\n+/// Fails with a specified reason if the either is Left.\n+#[inline]\n+pub fn expect_right<T,U>(eith: Either<T,U>, reason: &str) -> U {\n     match eith {\n         Right(x) => x,\n-        Left(_) => fail!(\"either::unwrap_right Left\")\n+        Left(_) => fail!(reason.to_owned())\n     }\n }\n \n+/// Retrieves the value in the right branch. Fails if the either is Left.\n+pub fn unwrap_right<T,U>(eith: Either<T,U>) -> U {\n+    expect_right(eith, \"either::unwrap_right Left\")\n+}\n+\n impl<T, U> Either<T, U> {\n     #[inline]\n     pub fn either<V>(&self, f_left: &fn(&T) -> V, f_right: &fn(&U) -> V) -> V {\n@@ -157,9 +171,15 @@ impl<T, U> Either<T, U> {\n     #[inline]\n     pub fn is_right(&self) -> bool { is_right(self) }\n \n+    #[inline]\n+    pub fn expect_left(self, reason: &str) -> T { expect_left(self, reason) }\n+\n     #[inline]\n     pub fn unwrap_left(self) -> T { unwrap_left(self) }\n \n+    #[inline]\n+    pub fn expect_right(self, reason: &str) -> U { expect_right(self, reason) }\n+\n     #[inline]\n     pub fn unwrap_right(self) -> U { unwrap_right(self) }\n }"}, {"sha": "182ee37202a658f48c56b8caf7f39f087bed33fc", "filename": "src/libstd/hashmap.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fhashmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fhashmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fhashmap.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -253,7 +253,7 @@ impl<K:Hash + Eq,V> HashMap<K, V> {\n         };\n \n         let len_buckets = self.buckets.len();\n-        let bucket = replace(&mut self.buckets[idx], None);\n+        let bucket = self.buckets[idx].take();\n \n         let value = match bucket {\n             None => None,\n@@ -267,7 +267,7 @@ impl<K:Hash + Eq,V> HashMap<K, V> {\n         let size = self.size - 1;\n         idx = self.next_bucket(idx, len_buckets);\n         while self.buckets[idx].is_some() {\n-            let bucket = replace(&mut self.buckets[idx], None);\n+            let bucket = self.buckets[idx].take();\n             self.insert_opt_bucket(bucket);\n             idx = self.next_bucket(idx, len_buckets);\n         }"}, {"sha": "f5e5dbb3dbf7ff5db30dddd4fa8d9b62799b9274", "filename": "src/libstd/option.rs", "status": "modified", "additions": 28, "deletions": 1, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Foption.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Foption.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Foption.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -180,6 +180,13 @@ impl<T> Option<T> {\n         match *self { Some(ref mut x) => Some(f(x)), None => None }\n     }\n \n+    /// Maps a `some` value from one type to another by a mutable reference,\n+    /// or returns a default value.\n+    #[inline]\n+    pub fn map_mut_default<'a, U>(&'a mut self, def: U, f: &fn(&'a mut T) -> U) -> U {\n+        match *self { Some(ref mut x) => f(x), None => def }\n+    }\n+\n     /// As `map`, but consumes the option and gives `f` ownership to avoid\n     /// copying.\n     #[inline]\n@@ -200,6 +207,26 @@ impl<T> Option<T> {\n         match self { None => def, Some(v) => f(v) }\n     }\n \n+    /// Take the value out of the option, leaving a `None` in its place.\n+    #[inline]\n+    pub fn take(&mut self) -> Option<T> {\n+        util::replace(self, None)\n+    }\n+\n+    /// As `map_consume`, but swaps a None into the original option rather\n+    /// than consuming it by-value.\n+    #[inline]\n+    pub fn take_map<U>(&mut self, blk: &fn(T) -> U) -> Option<U> {\n+        self.take().map_consume(blk)\n+    }\n+\n+    /// As `map_consume_default`, but swaps a None into the original option\n+    /// rather than consuming it by-value.\n+    #[inline]\n+    pub fn take_map_default<U> (&mut self, def: U, blk: &fn(T) -> U) -> U {\n+        self.take().map_consume_default(def, blk)\n+    }\n+\n     /// Apply a function to the contained value or do nothing\n     pub fn mutate(&mut self, f: &fn(T) -> T) {\n         if self.is_some() {\n@@ -295,7 +322,7 @@ impl<T> Option<T> {\n     #[inline]\n     pub fn take_unwrap(&mut self) -> T {\n         if self.is_none() { fail!(\"option::take_unwrap none\") }\n-        util::replace(self, None).unwrap()\n+        self.take().unwrap()\n     }\n \n     /**"}, {"sha": "a861c3c5f0fd6d23169b21760e0ce5e891e58b98", "filename": "src/libstd/pipes.rs", "status": "modified", "additions": 8, "deletions": 10, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fpipes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fpipes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fpipes.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -431,7 +431,7 @@ fn try_recv_<T:Send>(p: &mut Packet<T>) -> Option<T> {\n     // optimistic path\n     match p.header.state {\n       Full => {\n-        let payload = replace(&mut p.payload, None);\n+        let payload = p.payload.take();\n         p.header.state = Empty;\n         return Some(payload.unwrap())\n       },\n@@ -482,7 +482,7 @@ fn try_recv_<T:Send>(p: &mut Packet<T>) -> Option<T> {\n             fail!(\"blocking on already blocked packet\")\n           },\n           Full => {\n-            let payload = replace(&mut p.payload, None);\n+            let payload = p.payload.take();\n             let old_task = swap_task(&mut p.header.blocked_task, ptr::null());\n             if !old_task.is_null() {\n                 unsafe {\n@@ -676,8 +676,7 @@ impl<T:Send,Tbuffer:Send> Drop for SendPacketBuffered<T,Tbuffer> {\n         unsafe {\n             let this: &mut SendPacketBuffered<T,Tbuffer> = transmute(self);\n             if this.p != None {\n-                let p = replace(&mut this.p, None);\n-                sender_terminate(p.unwrap())\n+                sender_terminate(this.p.take_unwrap());\n             }\n         }\n     }\n@@ -695,7 +694,7 @@ pub fn SendPacketBuffered<T,Tbuffer>(p: *mut Packet<T>)\n \n impl<T,Tbuffer> SendPacketBuffered<T,Tbuffer> {\n     pub fn unwrap(&mut self) -> *mut Packet<T> {\n-        replace(&mut self.p, None).unwrap()\n+        self.p.take_unwrap()\n     }\n \n     pub fn header(&mut self) -> *mut PacketHeader {\n@@ -711,7 +710,7 @@ impl<T,Tbuffer> SendPacketBuffered<T,Tbuffer> {\n \n     pub fn reuse_buffer(&mut self) -> BufferResource<Tbuffer> {\n         //error!(\"send reuse_buffer\");\n-        replace(&mut self.buffer, None).unwrap()\n+        self.buffer.take_unwrap()\n     }\n }\n \n@@ -734,20 +733,19 @@ impl<T:Send,Tbuffer:Send> Drop for RecvPacketBuffered<T,Tbuffer> {\n         unsafe {\n             let this: &mut RecvPacketBuffered<T,Tbuffer> = transmute(self);\n             if this.p != None {\n-                let p = replace(&mut this.p, None);\n-                receiver_terminate(p.unwrap())\n+                receiver_terminate(this.p.take_unwrap())\n             }\n         }\n     }\n }\n \n impl<T:Send,Tbuffer:Send> RecvPacketBuffered<T, Tbuffer> {\n     pub fn unwrap(&mut self) -> *mut Packet<T> {\n-        replace(&mut self.p, None).unwrap()\n+        self.p.take_unwrap()\n     }\n \n     pub fn reuse_buffer(&mut self) -> BufferResource<Tbuffer> {\n-        replace(&mut self.buffer, None).unwrap()\n+        self.buffer.take_unwrap()\n     }\n }\n "}, {"sha": "f098f8b2767cedbf04d66e37fd98566c8908bfb0", "filename": "src/libstd/rt/comm.rs", "status": "modified", "additions": 26, "deletions": 16, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fcomm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fcomm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fcomm.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -19,7 +19,7 @@ use option::*;\n use cast;\n use util;\n use ops::Drop;\n-use rt::task::Task;\n+use rt::kill::BlockedTask;\n use kinds::Send;\n use rt::sched::Scheduler;\n use rt::local::Local;\n@@ -30,13 +30,13 @@ use comm::{GenericChan, GenericSmartChan, GenericPort, Peekable};\n use cell::Cell;\n use clone::Clone;\n \n-/// A combined refcount / ~Task pointer.\n+/// A combined refcount / BlockedTask-as-uint pointer.\n ///\n /// Can be equal to the following values:\n ///\n /// * 2 - both endpoints are alive\n /// * 1 - either the sender or the receiver is dead, determined by context\n-/// * <ptr> - A pointer to a blocked Task that can be transmuted to ~Task\n+/// * <ptr> - A pointer to a blocked Task (see BlockedTask::cast_{to,from}_uint)\n type State = uint;\n \n static STATE_BOTH: State = 2;\n@@ -137,11 +137,13 @@ impl<T> ChanOne<T> {\n                 }\n                 task_as_state => {\n                     // Port is blocked. Wake it up.\n-                    let recvr: ~Task = cast::transmute(task_as_state);\n-                    let mut sched = Local::take::<Scheduler>();\n-                    rtdebug!(\"rendezvous send\");\n-                    sched.metrics.rendezvous_sends += 1;\n-                    sched.schedule_task(recvr);\n+                    let recvr = BlockedTask::cast_from_uint(task_as_state);\n+                    do recvr.wake().map_consume |woken_task| {\n+                        let mut sched = Local::take::<Scheduler>();\n+                        rtdebug!(\"rendezvous send\");\n+                        sched.metrics.rendezvous_sends += 1;\n+                        sched.schedule_task(woken_task);\n+                    };\n                 }\n             }\n         }\n@@ -177,7 +179,7 @@ impl<T> PortOne<T> {\n                 // an acquire barrier to prevent reordering of the subsequent read\n                 // of the payload. Also issues a release barrier to prevent reordering\n                 // of any previous writes to the task structure.\n-                let task_as_state: State = cast::transmute(task);\n+                let task_as_state = task.cast_to_uint();\n                 let oldstate = (*packet).state.swap(task_as_state, SeqCst);\n                 match oldstate {\n                     STATE_BOTH => {\n@@ -193,8 +195,8 @@ impl<T> PortOne<T> {\n                         // NB: We have to drop back into the scheduler event loop here\n                         // instead of switching immediately back or we could end up\n                         // triggering infinite recursion on the scheduler's stack.\n-                        let task: ~Task = cast::transmute(task_as_state);\n-                        sched.enqueue_task(task);\n+                        let recvr = BlockedTask::cast_from_uint(task_as_state);\n+                        sched.enqueue_blocked_task(recvr);\n                     }\n                     _ => util::unreachable()\n                 }\n@@ -258,9 +260,11 @@ impl<T> Drop for ChanOneHack<T> {\n                 task_as_state => {\n                     // The port is blocked waiting for a message we will never send. Wake it.\n                     assert!((*this.packet()).payload.is_none());\n-                    let recvr: ~Task = cast::transmute(task_as_state);\n-                    let sched = Local::take::<Scheduler>();\n-                    sched.schedule_task(recvr);\n+                    let recvr = BlockedTask::cast_from_uint(task_as_state);\n+                    do recvr.wake().map_consume |woken_task| {\n+                        let sched = Local::take::<Scheduler>();\n+                        sched.schedule_task(woken_task);\n+                    };\n                 }\n             }\n         }\n@@ -282,8 +286,14 @@ impl<T> Drop for PortOneHack<T> {\n                 STATE_ONE => {\n                     let _packet: ~Packet<T> = cast::transmute(this.void_packet);\n                 }\n-                _ => {\n-                    util::unreachable()\n+                task_as_state => {\n+                    // This case occurs during unwinding, when the blocked\n+                    // receiver was killed awake. The task can't still be\n+                    // blocked (we are it), but we need to free the handle.\n+                    let recvr = BlockedTask::cast_from_uint(task_as_state);\n+                    // FIXME(#7554)(bblum): Make this cfg(test) dependent.\n+                    // in a later commit.\n+                    assert!(recvr.wake().is_none());\n                 }\n             }\n         }"}, {"sha": "924db1a21b729774ad1d9ba06db52be254555961", "filename": "src/libstd/rt/join_latch.rs", "status": "removed", "additions": 0, "deletions": 647, "changes": 647, "blob_url": "https://github.com/rust-lang/rust/blob/fdbd56ca38c4a58377056c63e0b03b0d4e131f2c/src%2Flibstd%2Frt%2Fjoin_latch.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fdbd56ca38c4a58377056c63e0b03b0d4e131f2c/src%2Flibstd%2Frt%2Fjoin_latch.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fjoin_latch.rs?ref=fdbd56ca38c4a58377056c63e0b03b0d4e131f2c", "patch": "@@ -1,647 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! The JoinLatch is a concurrent type that establishes the task\n-//! tree and propagates failure.\n-//!\n-//! Each task gets a JoinLatch that is derived from the JoinLatch\n-//! of its parent task. Every latch must be released by either calling\n-//! the non-blocking `release` method or the task-blocking `wait` method.\n-//! Releasing a latch does not complete until all of its child latches\n-//! complete.\n-//!\n-//! Latches carry a `success` flag that is set to `false` during task\n-//! failure and is propagated both from children to parents and parents\n-//! to children. The status af this flag may be queried for the purposes\n-//! of linked failure.\n-//!\n-//! In addition to failure propagation the task tree serves to keep the\n-//! default task schedulers alive. The runtime only sends the shutdown\n-//! message to schedulers once the root task exits.\n-//!\n-//! Under this scheme tasks that terminate before their children become\n-//! 'zombies' since they may not exit until their children do. Zombie\n-//! tasks are 'tombstoned' as `Tombstone(~JoinLatch)` and the tasks\n-//! themselves allowed to terminate.\n-//!\n-//! XXX: Propagate flag from parents to children.\n-//! XXX: Tombstoning actually doesn't work.\n-//! XXX: This could probably be done in a way that doesn't leak tombstones\n-//!      longer than the life of the child tasks.\n-\n-use comm::{GenericPort, Peekable, GenericSmartChan};\n-use clone::Clone;\n-use container::Container;\n-use option::{Option, Some, None};\n-use ops::Drop;\n-use rt::comm::{SharedChan, Port, stream};\n-use rt::local::Local;\n-use rt::sched::Scheduler;\n-use unstable::atomics::{AtomicUint, SeqCst};\n-use util;\n-use vec::OwnedVector;\n-\n-// FIXME #7026: Would prefer this to be an enum\n-pub struct JoinLatch {\n-    priv parent: Option<ParentLink>,\n-    priv child: Option<ChildLink>,\n-    closed: bool,\n-}\n-\n-// Shared between parents and all their children.\n-struct SharedState {\n-    /// Reference count, held by a parent and all children.\n-    count: AtomicUint,\n-    success: bool\n-}\n-\n-struct ParentLink {\n-    shared: *mut SharedState,\n-    // For communicating with the parent.\n-    chan: SharedChan<Message>\n-}\n-\n-struct ChildLink {\n-    shared: ~SharedState,\n-    // For receiving from children.\n-    port: Port<Message>,\n-    chan: SharedChan<Message>,\n-    // Prevents dropping the child SharedState reference counts multiple times.\n-    dropped_child: bool\n-}\n-\n-// Messages from child latches to parent.\n-enum Message {\n-    Tombstone(~JoinLatch),\n-    ChildrenTerminated\n-}\n-\n-impl JoinLatch {\n-    pub fn new_root() -> ~JoinLatch {\n-        let this = ~JoinLatch {\n-            parent: None,\n-            child: None,\n-            closed: false\n-        };\n-        rtdebug!(\"new root latch %x\", this.id());\n-        return this;\n-    }\n-\n-    fn id(&self) -> uint {\n-        unsafe { ::cast::transmute(&*self) }\n-    }\n-\n-    pub fn new_child(&mut self) -> ~JoinLatch {\n-        rtassert!(!self.closed);\n-\n-        if self.child.is_none() {\n-            // This is the first time spawning a child\n-            let shared = ~SharedState {\n-                count: AtomicUint::new(1),\n-                success: true\n-            };\n-            let (port, chan) = stream();\n-            let chan = SharedChan::new(chan);\n-            let child = ChildLink {\n-                shared: shared,\n-                port: port,\n-                chan: chan,\n-                dropped_child: false\n-            };\n-            self.child = Some(child);\n-        }\n-\n-        let child_link: &mut ChildLink = self.child.get_mut_ref();\n-        let shared_state: *mut SharedState = &mut *child_link.shared;\n-\n-        child_link.shared.count.fetch_add(1, SeqCst);\n-\n-        let child = ~JoinLatch {\n-            parent: Some(ParentLink {\n-                shared: shared_state,\n-                chan: child_link.chan.clone()\n-            }),\n-            child: None,\n-            closed: false\n-        };\n-        rtdebug!(\"NEW child latch %x\", child.id());\n-        return child;\n-    }\n-\n-    pub fn release(~self, local_success: bool) {\n-        // XXX: This should not block, but there's a bug in the below\n-        // code that I can't figure out.\n-        self.wait(local_success);\n-    }\n-\n-    // XXX: Should not require ~self\n-    fn release_broken(~self, local_success: bool) {\n-        rtassert!(!self.closed);\n-\n-        rtdebug!(\"releasing %x\", self.id());\n-\n-        let id = self.id();\n-        let _ = id; // XXX: `id` is only used in debug statements so appears unused\n-        let mut this = self;\n-        let mut child_success = true;\n-        let mut children_done = false;\n-\n-        if this.child.is_some() {\n-            rtdebug!(\"releasing children\");\n-            let child_link: &mut ChildLink = this.child.get_mut_ref();\n-            let shared: &mut SharedState = &mut *child_link.shared;\n-\n-            if !child_link.dropped_child {\n-                let last_count = shared.count.fetch_sub(1, SeqCst);\n-                rtdebug!(\"child count before sub %u %x\", last_count, id);\n-                if last_count == 1 {\n-                    assert!(child_link.chan.try_send(ChildrenTerminated));\n-                }\n-                child_link.dropped_child = true;\n-            }\n-\n-            // Wait for messages from children\n-            let mut tombstones = ~[];\n-            loop {\n-                if child_link.port.peek() {\n-                    match child_link.port.recv() {\n-                        Tombstone(t) => {\n-                            tombstones.push(t);\n-                        },\n-                        ChildrenTerminated => {\n-                            children_done = true;\n-                            break;\n-                        }\n-                    }\n-                } else {\n-                    break\n-                }\n-            }\n-\n-            rtdebug!(\"releasing %u tombstones %x\", tombstones.len(), id);\n-\n-            // Try to release the tombstones. Those that still have\n-            // outstanding will be re-enqueued.  When this task's\n-            // parents release their latch we'll end up back here\n-            // trying them again.\n-            while !tombstones.is_empty() {\n-                tombstones.pop().release(true);\n-            }\n-\n-            if children_done {\n-                let count = shared.count.load(SeqCst);\n-                assert!(count == 0);\n-                // self_count is the acquire-read barrier\n-                child_success = shared.success;\n-            }\n-        } else {\n-            children_done = true;\n-        }\n-\n-        let total_success = local_success && child_success;\n-\n-        rtassert!(this.parent.is_some());\n-\n-        unsafe {\n-            {\n-                let parent_link: &mut ParentLink = this.parent.get_mut_ref();\n-                let shared: *mut SharedState = parent_link.shared;\n-\n-                if !total_success {\n-                    // parent_count is the write-wait barrier\n-                    (*shared).success = false;\n-                }\n-            }\n-\n-            if children_done {\n-                rtdebug!(\"children done\");\n-                do Local::borrow::<Scheduler, ()> |sched| {\n-                    sched.metrics.release_tombstone += 1;\n-                }\n-                {\n-                    rtdebug!(\"RELEASING parent %x\", id);\n-                    let parent_link: &mut ParentLink = this.parent.get_mut_ref();\n-                    let shared: *mut SharedState = parent_link.shared;\n-                    let last_count = (*shared).count.fetch_sub(1, SeqCst);\n-                    rtdebug!(\"count before parent sub %u %x\", last_count, id);\n-                    if last_count == 1 {\n-                        assert!(parent_link.chan.try_send(ChildrenTerminated));\n-                    }\n-                }\n-                this.closed = true;\n-                util::ignore(this);\n-            } else {\n-                rtdebug!(\"children not done\");\n-                rtdebug!(\"TOMBSTONING %x\", id);\n-                do Local::borrow::<Scheduler, ()> |sched| {\n-                    sched.metrics.release_no_tombstone += 1;\n-                }\n-                let chan = {\n-                    let parent_link: &mut ParentLink = this.parent.get_mut_ref();\n-                    parent_link.chan.clone()\n-                };\n-                assert!(chan.try_send(Tombstone(this)));\n-            }\n-        }\n-    }\n-\n-    // XXX: Should not require ~self\n-    pub fn wait(~self, local_success: bool) -> bool {\n-        rtassert!(!self.closed);\n-\n-        rtdebug!(\"WAITING %x\", self.id());\n-\n-        let mut this = self;\n-        let mut child_success = true;\n-\n-        if this.child.is_some() {\n-            rtdebug!(\"waiting for children\");\n-            let child_link: &mut ChildLink = this.child.get_mut_ref();\n-            let shared: &mut SharedState = &mut *child_link.shared;\n-\n-            if !child_link.dropped_child {\n-                let last_count = shared.count.fetch_sub(1, SeqCst);\n-                rtdebug!(\"child count before sub %u\", last_count);\n-                if last_count == 1 {\n-                    assert!(child_link.chan.try_send(ChildrenTerminated));\n-                }\n-                child_link.dropped_child = true;\n-            }\n-\n-            // Wait for messages from children\n-            loop {\n-                match child_link.port.recv() {\n-                    Tombstone(t) => {\n-                        t.wait(true);\n-                    }\n-                    ChildrenTerminated => break\n-                }\n-            }\n-\n-            let count = shared.count.load(SeqCst);\n-            if count != 0 { ::io::println(fmt!(\"%u\", count)); }\n-            assert!(count == 0);\n-            // self_count is the acquire-read barrier\n-            child_success = shared.success;\n-        }\n-\n-        let total_success = local_success && child_success;\n-\n-        if this.parent.is_some() {\n-            rtdebug!(\"releasing parent\");\n-            unsafe {\n-                let parent_link: &mut ParentLink = this.parent.get_mut_ref();\n-                let shared: *mut SharedState = parent_link.shared;\n-\n-                if !total_success {\n-                    // parent_count is the write-wait barrier\n-                    (*shared).success = false;\n-                }\n-\n-                let last_count = (*shared).count.fetch_sub(1, SeqCst);\n-                rtdebug!(\"count before parent sub %u\", last_count);\n-                if last_count == 1 {\n-                    assert!(parent_link.chan.try_send(ChildrenTerminated));\n-                }\n-            }\n-        }\n-\n-        this.closed = true;\n-        util::ignore(this);\n-\n-        return total_success;\n-    }\n-}\n-\n-impl Drop for JoinLatch {\n-    fn drop(&self) {\n-        rtdebug!(\"DESTROYING %x\", self.id());\n-        rtassert!(self.closed);\n-    }\n-}\n-\n-#[cfg(test)]\n-mod test {\n-    use super::*;\n-    use cell::Cell;\n-    use container::Container;\n-    use iter::Times;\n-    use rt::test::*;\n-    use rand;\n-    use rand::RngUtil;\n-    use vec::{CopyableVector, ImmutableVector};\n-\n-    #[test]\n-    fn success_immediately() {\n-        do run_in_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-\n-            let child_latch = latch.new_child();\n-            let child_latch = Cell::new(child_latch);\n-            do spawntask_immediately {\n-                let child_latch = child_latch.take();\n-                assert!(child_latch.wait(true));\n-            }\n-\n-            assert!(latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn success_later() {\n-        do run_in_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-\n-            let child_latch = latch.new_child();\n-            let child_latch = Cell::new(child_latch);\n-            do spawntask_later {\n-                let child_latch = child_latch.take();\n-                assert!(child_latch.wait(true));\n-            }\n-\n-            assert!(latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn mt_success() {\n-        do run_in_mt_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-\n-            for 10.times {\n-                let child_latch = latch.new_child();\n-                let child_latch = Cell::new(child_latch);\n-                do spawntask_random {\n-                    let child_latch = child_latch.take();\n-                    assert!(child_latch.wait(true));\n-                }\n-            }\n-\n-            assert!(latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn mt_failure() {\n-        do run_in_mt_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-\n-            let spawn = |status| {\n-                let child_latch = latch.new_child();\n-                let child_latch = Cell::new(child_latch);\n-                do spawntask_random {\n-                    let child_latch = child_latch.take();\n-                    child_latch.wait(status);\n-                }\n-            };\n-\n-            for 10.times { spawn(true) }\n-            spawn(false);\n-            for 10.times { spawn(true) }\n-\n-            assert!(!latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn mt_multi_level_success() {\n-        do run_in_mt_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-\n-            fn child(latch: &mut JoinLatch, i: int) {\n-                let child_latch = latch.new_child();\n-                let child_latch = Cell::new(child_latch);\n-                do spawntask_random {\n-                    let mut child_latch = child_latch.take();\n-                    if i != 0 {\n-                        child(&mut *child_latch, i - 1);\n-                        child_latch.wait(true);\n-                    } else {\n-                        child_latch.wait(true);\n-                    }\n-                }\n-            }\n-\n-            child(&mut *latch, 10);\n-\n-            assert!(latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn mt_multi_level_failure() {\n-        do run_in_mt_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-\n-            fn child(latch: &mut JoinLatch, i: int) {\n-                let child_latch = latch.new_child();\n-                let child_latch = Cell::new(child_latch);\n-                do spawntask_random {\n-                    let mut child_latch = child_latch.take();\n-                    if i != 0 {\n-                        child(&mut *child_latch, i - 1);\n-                        child_latch.wait(false);\n-                    } else {\n-                        child_latch.wait(true);\n-                    }\n-                }\n-            }\n-\n-            child(&mut *latch, 10);\n-\n-            assert!(!latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn release_child() {\n-        do run_in_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-            let child_latch = latch.new_child();\n-            let child_latch = Cell::new(child_latch);\n-\n-            do spawntask_immediately {\n-                let latch = child_latch.take();\n-                latch.release(false);\n-            }\n-\n-            assert!(!latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn release_child_tombstone() {\n-        do run_in_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-            let child_latch = latch.new_child();\n-            let child_latch = Cell::new(child_latch);\n-\n-            do spawntask_immediately {\n-                let mut latch = child_latch.take();\n-                let child_latch = latch.new_child();\n-                let child_latch = Cell::new(child_latch);\n-                do spawntask_later {\n-                    let latch = child_latch.take();\n-                    latch.release(false);\n-                }\n-                latch.release(true);\n-            }\n-\n-            assert!(!latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn release_child_no_tombstone() {\n-        do run_in_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-            let child_latch = latch.new_child();\n-            let child_latch = Cell::new(child_latch);\n-\n-            do spawntask_later {\n-                let mut latch = child_latch.take();\n-                let child_latch = latch.new_child();\n-                let child_latch = Cell::new(child_latch);\n-                do spawntask_immediately {\n-                    let latch = child_latch.take();\n-                    latch.release(false);\n-                }\n-                latch.release(true);\n-            }\n-\n-            assert!(!latch.wait(true));\n-        }\n-    }\n-\n-    #[test]\n-    fn release_child_tombstone_stress() {\n-        fn rand_orders() -> ~[bool] {\n-            let mut v = ~[false,.. 5];\n-            v[0] = true;\n-            let mut rng = rand::rng();\n-            return rng.shuffle(v);\n-        }\n-\n-        fn split_orders(orders: &[bool]) -> (~[bool], ~[bool]) {\n-            if orders.is_empty() {\n-                return (~[], ~[]);\n-            } else if orders.len() <= 2 {\n-                return (orders.to_owned(), ~[]);\n-            }\n-            let mut rng = rand::rng();\n-            let n = rng.gen_uint_range(1, orders.len());\n-            let first = orders.slice(0, n).to_owned();\n-            let last = orders.slice(n, orders.len()).to_owned();\n-            assert!(first.len() + last.len() == orders.len());\n-            return (first, last);\n-        }\n-\n-        for stress_factor().times {\n-            do run_in_newsched_task {\n-                fn doit(latch: &mut JoinLatch, orders: ~[bool], depth: uint) {\n-                    let (my_orders, remaining_orders) = split_orders(orders);\n-                    rtdebug!(\"(my_orders, remaining): %?\", (&my_orders, &remaining_orders));\n-                    rtdebug!(\"depth: %u\", depth);\n-                    let mut remaining_orders = remaining_orders;\n-                    let mut num = 0;\n-                    for my_orders.iter().advance |&order| {\n-                        let child_latch = latch.new_child();\n-                        let child_latch = Cell::new(child_latch);\n-                        let (child_orders, remaining) = split_orders(remaining_orders);\n-                        rtdebug!(\"(child_orders, remaining): %?\", (&child_orders, &remaining));\n-                        remaining_orders = remaining;\n-                        let child_orders = Cell::new(child_orders);\n-                        let child_num = num;\n-                        let _ = child_num; // XXX unused except in rtdebug!\n-                        do spawntask_random {\n-                            rtdebug!(\"depth %u num %u\", depth, child_num);\n-                            let mut child_latch = child_latch.take();\n-                            let child_orders = child_orders.take();\n-                            doit(&mut *child_latch, child_orders, depth + 1);\n-                            child_latch.release(order);\n-                        }\n-\n-                        num += 1;\n-                    }\n-                }\n-\n-                let mut latch = JoinLatch::new_root();\n-                let orders = rand_orders();\n-                rtdebug!(\"orders: %?\", orders);\n-\n-                doit(&mut *latch, orders, 0);\n-\n-                assert!(!latch.wait(true));\n-            }\n-        }\n-    }\n-\n-    #[deriving(Clone)]\n-    struct Order {\n-        immediate: bool,\n-        succeed: bool,\n-        orders: ~[Order]\n-    }\n-\n-    #[test]\n-    fn whateverman() {\n-        fn next(latch: &mut JoinLatch, orders: ~[Order]) {\n-            for orders.iter().advance |order| {\n-                let suborders = order.orders.clone();\n-                let child_latch = Cell::new(latch.new_child());\n-                let succeed = order.succeed;\n-                if order.immediate {\n-                    do spawntask_immediately {\n-                        let mut child_latch = child_latch.take();\n-                        next(&mut *child_latch, suborders.clone());\n-                        rtdebug!(\"immediate releasing\");\n-                        child_latch.release(succeed);\n-                    }\n-                } else {\n-                    do spawntask_later {\n-                        let mut child_latch = child_latch.take();\n-                        next(&mut *child_latch, suborders.clone());\n-                        rtdebug!(\"later releasing\");\n-                        child_latch.release(succeed);\n-                    }\n-                }\n-            }\n-        }\n-\n-        do run_in_newsched_task {\n-            let mut latch = JoinLatch::new_root();\n-            let orders = ~[ Order { // 0 0\n-                immediate: true,\n-                succeed: true,\n-                orders: ~[ Order { // 1 0\n-                    immediate: true,\n-                    succeed: false,\n-                    orders: ~[ Order { // 2 0\n-                        immediate: false,\n-                        succeed: false,\n-                        orders: ~[ Order { // 3 0\n-                            immediate: true,\n-                            succeed: false,\n-                            orders: ~[]\n-                        }, Order { // 3 1\n-                            immediate: false,\n-                            succeed: false,\n-                            orders: ~[]\n-                        }]\n-                    }]\n-                }]\n-            }];\n-\n-            next(&mut *latch, orders);\n-            assert!(!latch.wait(true));\n-        }\n-    }\n-}\n-"}, {"sha": "cfd8e46dfdb75f721d3a95f9f2a6ea348345a360", "filename": "src/libstd/rt/kill.rs", "status": "added", "additions": 792, "deletions": 0, "changes": 792, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fkill.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fkill.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fkill.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -0,0 +1,792 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! Task death: asynchronous killing, linked failure, exit code propagation.\n+\n+use cast;\n+use cell::Cell;\n+use either::{Either, Left, Right};\n+use option::{Option, Some, None};\n+use prelude::*;\n+use rt::task::Task;\n+use to_bytes::IterBytes;\n+use unstable::atomics::{AtomicUint, Acquire, SeqCst};\n+use unstable::sync::{UnsafeAtomicRcBox, LittleLock};\n+use util;\n+\n+static KILLED_MSG: &'static str = \"killed by linked failure\";\n+\n+// State values for the 'killed' and 'unkillable' atomic flags below.\n+static KILL_RUNNING:    uint = 0;\n+static KILL_KILLED:     uint = 1;\n+static KILL_UNKILLABLE: uint = 2;\n+\n+struct KillFlag(AtomicUint);\n+type KillFlagHandle = UnsafeAtomicRcBox<KillFlag>;\n+\n+/// A handle to a blocked task. Usually this means having the ~Task pointer by\n+/// ownership, but if the task is killable, a killer can steal it at any time.\n+pub enum BlockedTask {\n+    Unkillable(~Task),\n+    Killable(KillFlagHandle),\n+}\n+\n+// FIXME(#7544)(bblum): think about the cache efficiency of this\n+struct KillHandleInner {\n+    // Is the task running, blocked, or killed? Possible values:\n+    // * KILL_RUNNING    - Not unkillable, no kill pending.\n+    // * KILL_KILLED     - Kill pending.\n+    // * <ptr>           - A transmuted blocked ~Task pointer.\n+    // This flag is refcounted because it may also be referenced by a blocking\n+    // concurrency primitive, used to wake the task normally, whose reference\n+    // may outlive the handle's if the task is killed.\n+    killed: KillFlagHandle,\n+    // Has the task deferred kill signals? This flag guards the above one.\n+    // Possible values:\n+    // * KILL_RUNNING    - Not unkillable, no kill pending.\n+    // * KILL_KILLED     - Kill pending.\n+    // * KILL_UNKILLABLE - Kill signals deferred.\n+    unkillable: AtomicUint,\n+\n+    // Shared state between task and children for exit code propagation. These\n+    // are here so we can re-use the kill handle to implement watched children\n+    // tasks. Using a separate ARClike would introduce extra atomic adds/subs\n+    // into common spawn paths, so this is just for speed.\n+\n+    // Locklessly accessed; protected by the enclosing refcount's barriers.\n+    any_child_failed: bool,\n+    // A lazy list, consuming which may unwrap() many child tombstones.\n+    child_tombstones: Option<~fn() -> bool>,\n+    // Protects multiple children simultaneously creating tombstones.\n+    graveyard_lock: LittleLock,\n+}\n+\n+/// State shared between tasks used for task killing during linked failure.\n+#[deriving(Clone)]\n+pub struct KillHandle(UnsafeAtomicRcBox<KillHandleInner>);\n+\n+/// Per-task state related to task death, killing, failure, etc.\n+pub struct Death {\n+    // Shared among this task, its watched children, and any linked tasks who\n+    // might kill it. This is optional so we can take it by-value at exit time.\n+    kill_handle:     Option<KillHandle>,\n+    // Handle to a watching parent, if we have one, for exit code propagation.\n+    watching_parent: Option<KillHandle>,\n+    // Action to be done with the exit code. If set, also makes the task wait\n+    // until all its watched children exit before collecting the status.\n+    on_exit:         Option<~fn(bool)>,\n+    // nesting level counter for task::unkillable calls (0 == killable).\n+    unkillable:      int,\n+    // nesting level counter for task::atomically calls (0 == can yield).\n+    wont_sleep:      int,\n+    // A \"spare\" handle to the kill flag inside the kill handle. Used during\n+    // blocking/waking as an optimization to avoid two xadds on the refcount.\n+    spare_kill_flag: Option<KillFlagHandle>,\n+}\n+\n+impl Drop for KillFlag {\n+    // Letting a KillFlag with a task inside get dropped would leak the task.\n+    // We could free it here, but the task should get awoken by hand somehow.\n+    fn drop(&self) {\n+        match self.load(Acquire) {\n+            KILL_RUNNING | KILL_KILLED => { },\n+            _ => rtabort!(\"can't drop kill flag with a blocked task inside!\"),\n+        }\n+    }\n+}\n+\n+// Whenever a task blocks, it swaps out its spare kill flag to use as the\n+// blocked task handle. So unblocking a task must restore that spare.\n+unsafe fn revive_task_ptr(task_ptr: uint, spare_flag: Option<KillFlagHandle>) -> ~Task {\n+    let mut task: ~Task = cast::transmute(task_ptr);\n+    rtassert!(task.death.spare_kill_flag.is_none());\n+    task.death.spare_kill_flag = spare_flag;\n+    task\n+}\n+\n+impl BlockedTask {\n+    /// Returns Some if the task was successfully woken; None if already killed.\n+    pub fn wake(self) -> Option<~Task> {\n+        match self {\n+            Unkillable(task) => Some(task),\n+            Killable(flag_arc) => {\n+                let flag = unsafe { &mut **flag_arc.get() };\n+                match flag.swap(KILL_RUNNING, SeqCst) {\n+                    KILL_RUNNING => rtabort!(\"tried to wake an already-running task\"),\n+                    KILL_KILLED  => None, // a killer stole it already\n+                    task_ptr     =>\n+                        Some(unsafe { revive_task_ptr(task_ptr, Some(flag_arc)) })\n+                }\n+            }\n+        }\n+    }\n+\n+    /// Create a blocked task, unless the task was already killed.\n+    pub fn try_block(mut task: ~Task) -> Either<~Task, BlockedTask> {\n+        if task.death.unkillable > 0 {\n+            Right(Unkillable(task))\n+        } else {\n+            rtassert!(task.death.kill_handle.is_some());\n+            unsafe {\n+                // The inverse of 'revive', above, occurs here.\n+                // The spare kill flag will usually be Some, unless the task was\n+                // already killed, in which case the killer will have deferred\n+                // creating a new one until whenever it blocks during unwinding.\n+                let flag_arc = match task.death.spare_kill_flag.take() {\n+                    Some(spare_flag) => spare_flag,\n+                    None => {\n+                        // FIXME(#7544): Uncomment this when terminate_current_task\n+                        // stops being *terrible*. That's the only place that violates\n+                        // the assumption of \"becoming unkillable will fail if the\n+                        // task was killed\".\n+                        // rtassert!(task.unwinder.unwinding);\n+                        (*task.death.kill_handle.get_ref().get()).killed.clone()\n+                    }\n+                };\n+                let flag     = &mut **flag_arc.get();\n+                let task_ptr = cast::transmute(task);\n+                // Expect flag to contain RUNNING. If KILLED, it should stay KILLED.\n+                match flag.compare_and_swap(KILL_RUNNING, task_ptr, SeqCst) {\n+                    KILL_RUNNING => Right(Killable(flag_arc)),\n+                    KILL_KILLED  => Left(revive_task_ptr(task_ptr, Some(flag_arc))),\n+                    x            => rtabort!(\"can't block task! kill flag = %?\", x),\n+                }\n+            }\n+        }\n+    }\n+\n+    /// Convert to an unsafe uint value. Useful for storing in a pipe's state flag.\n+    #[inline]\n+    pub unsafe fn cast_to_uint(self) -> uint {\n+        // Use the low bit to distinguish the enum variants, to save a second\n+        // allocation in the indestructible case.\n+        match self {\n+            Unkillable(task) => {\n+                let blocked_task_ptr: uint = cast::transmute(task);\n+                rtassert!(blocked_task_ptr & 0x1 == 0);\n+                blocked_task_ptr\n+            },\n+            Killable(flag_arc) => {\n+                let blocked_task_ptr: uint = cast::transmute(~flag_arc);\n+                rtassert!(blocked_task_ptr & 0x1 == 0);\n+                blocked_task_ptr | 0x1\n+            }\n+        }\n+    }\n+\n+    /// Convert from an unsafe uint value. Useful for retrieving a pipe's state flag.\n+    #[inline]\n+    pub unsafe fn cast_from_uint(blocked_task_ptr: uint) -> BlockedTask {\n+        if blocked_task_ptr & 0x1 == 0 {\n+            Unkillable(cast::transmute(blocked_task_ptr))\n+        } else {\n+            let ptr: ~KillFlagHandle = cast::transmute(blocked_task_ptr & !0x1);\n+            match ptr {\n+                ~flag_arc => Killable(flag_arc)\n+            }\n+        }\n+    }\n+}\n+\n+// So that KillHandle can be hashed in the taskgroup bookkeeping code.\n+impl IterBytes for KillHandle {\n+    fn iter_bytes(&self, lsb0: bool, f: &fn(buf: &[u8]) -> bool) -> bool {\n+        self.data.iter_bytes(lsb0, f)\n+    }\n+}\n+impl Eq for KillHandle {\n+    #[inline] fn eq(&self, other: &KillHandle) -> bool { self.data.eq(&other.data) }\n+    #[inline] fn ne(&self, other: &KillHandle) -> bool { self.data.ne(&other.data) }\n+}\n+\n+impl KillHandle {\n+    pub fn new() -> (KillHandle, KillFlagHandle) {\n+        let (flag, flag_clone) =\n+            UnsafeAtomicRcBox::new2(KillFlag(AtomicUint::new(KILL_RUNNING)));\n+        let handle = KillHandle(UnsafeAtomicRcBox::new(KillHandleInner {\n+            // Linked failure fields\n+            killed:     flag,\n+            unkillable: AtomicUint::new(KILL_RUNNING),\n+            // Exit code propagation fields\n+            any_child_failed: false,\n+            child_tombstones: None,\n+            graveyard_lock:   LittleLock(),\n+        }));\n+        (handle, flag_clone)\n+    }\n+\n+    // Will begin unwinding if a kill signal was received, unless already_failing.\n+    // This can't be used recursively, because a task which sees a KILLED\n+    // signal must fail immediately, which an already-unkillable task can't do.\n+    #[inline]\n+    pub fn inhibit_kill(&mut self, already_failing: bool) {\n+        let inner = unsafe { &mut *self.get() };\n+        // Expect flag to contain RUNNING. If KILLED, it should stay KILLED.\n+        // FIXME(#7544)(bblum): is it really necessary to prohibit double kill?\n+        match inner.unkillable.compare_and_swap(KILL_RUNNING, KILL_UNKILLABLE, SeqCst) {\n+            KILL_RUNNING    => { }, // normal case\n+            KILL_KILLED     => if !already_failing { fail!(KILLED_MSG) },\n+            _               => rtabort!(\"inhibit_kill: task already unkillable\"),\n+        }\n+    }\n+\n+    // Will begin unwinding if a kill signal was received, unless already_failing.\n+    #[inline]\n+    pub fn allow_kill(&mut self, already_failing: bool) {\n+        let inner = unsafe { &mut *self.get() };\n+        // Expect flag to contain UNKILLABLE. If KILLED, it should stay KILLED.\n+        // FIXME(#7544)(bblum): is it really necessary to prohibit double kill?\n+        match inner.unkillable.compare_and_swap(KILL_UNKILLABLE, KILL_RUNNING, SeqCst) {\n+            KILL_UNKILLABLE => { }, // normal case\n+            KILL_KILLED     => if !already_failing { fail!(KILLED_MSG) },\n+            _               => rtabort!(\"allow_kill: task already killable\"),\n+        }\n+    }\n+\n+    // Send a kill signal to the handle's owning task. Returns the task itself\n+    // if it was blocked and needs punted awake. To be called by other tasks.\n+    pub fn kill(&mut self) -> Option<~Task> {\n+        let inner = unsafe { &mut *self.get() };\n+        if inner.unkillable.swap(KILL_KILLED, SeqCst) == KILL_RUNNING {\n+            // Got in. Allowed to try to punt the task awake.\n+            let flag = unsafe { &mut *inner.killed.get() };\n+            match flag.swap(KILL_KILLED, SeqCst) {\n+                // Task either not blocked or already taken care of.\n+                KILL_RUNNING | KILL_KILLED => None,\n+                // Got ownership of the blocked task.\n+                // While the usual 'wake' path can just pass back the flag\n+                // handle, we (the slower kill path) haven't an extra one lying\n+                // around. The task will wake up without a spare.\n+                task_ptr => Some(unsafe { revive_task_ptr(task_ptr, None) }),\n+            }\n+        } else {\n+            // Otherwise it was either unkillable or already killed. Somebody\n+            // else was here first who will deal with the kill signal.\n+            None\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn killed(&self) -> bool {\n+        // Called every context switch, so shouldn't report true if the task\n+        // is unkillable with a kill signal pending.\n+        let inner = unsafe { &*self.get() };\n+        let flag  = unsafe { &*inner.killed.get() };\n+        // FIXME(#6598): can use relaxed ordering (i think)\n+        flag.load(Acquire) == KILL_KILLED\n+    }\n+\n+    pub fn notify_immediate_failure(&mut self) {\n+        // A benign data race may happen here if there are failing sibling\n+        // tasks that were also spawned-watched. The refcount's write barriers\n+        // in UnsafeAtomicRcBox ensure that this write will be seen by the\n+        // unwrapper/destructor, whichever task may unwrap it.\n+        unsafe { (*self.get()).any_child_failed = true; }\n+    }\n+\n+    // For use when a task does not need to collect its children's exit\n+    // statuses, but the task has a parent which might want them.\n+    pub fn reparent_children_to(self, parent: &mut KillHandle) {\n+        // Optimistic path: If another child of the parent's already failed,\n+        // we don't need to worry about any of this.\n+        if unsafe { (*parent.get()).any_child_failed } {\n+            return;\n+        }\n+\n+        // Try to see if all our children are gone already.\n+        match unsafe { self.try_unwrap() } {\n+            // Couldn't unwrap; children still alive. Reparent entire handle as\n+            // our own tombstone, to be unwrapped later.\n+            Left(this) => {\n+                let this = Cell::new(this); // :(\n+                do add_lazy_tombstone(parent) |other_tombstones| {\n+                    let this = Cell::new(this.take()); // :(\n+                    let others = Cell::new(other_tombstones); // :(\n+                    || {\n+                        // Prefer to check tombstones that were there first,\n+                        // being \"more fair\" at the expense of tail-recursion.\n+                        others.take().map_consume_default(true, |f| f()) && {\n+                            let mut inner = unsafe { this.take().unwrap() };\n+                            (!inner.any_child_failed) &&\n+                                inner.child_tombstones.take_map_default(true, |f| f())\n+                        }\n+                    }\n+                }\n+            }\n+            // Whether or not all children exited, one or more already failed.\n+            Right(KillHandleInner { any_child_failed: true, _ }) => {\n+                parent.notify_immediate_failure();\n+            }\n+            // All children exited, but some left behind tombstones that we\n+            // don't want to wait on now. Give them to our parent.\n+            Right(KillHandleInner { any_child_failed: false,\n+                                    child_tombstones: Some(f), _ }) => {\n+                let f = Cell::new(f); // :(\n+                do add_lazy_tombstone(parent) |other_tombstones| {\n+                    let f = Cell::new(f.take()); // :(\n+                    let others = Cell::new(other_tombstones); // :(\n+                    || {\n+                        // Prefer fairness to tail-recursion, as in above case.\n+                        others.take().map_consume_default(true, |f| f()) &&\n+                            f.take()()\n+                    }\n+                }\n+            }\n+            // All children exited, none failed. Nothing to do!\n+            Right(KillHandleInner { any_child_failed: false,\n+                                    child_tombstones: None, _ }) => { }\n+        }\n+\n+        // NB: Takes a pthread mutex -- 'blk' not allowed to reschedule.\n+        #[inline]\n+        fn add_lazy_tombstone(parent: &mut KillHandle,\n+                              blk: &fn(Option<~fn() -> bool>) -> ~fn() -> bool) {\n+\n+            let inner: &mut KillHandleInner = unsafe { &mut *parent.get() };\n+            unsafe {\n+                do inner.graveyard_lock.lock {\n+                    // Update the current \"head node\" of the lazy list.\n+                    inner.child_tombstones =\n+                        Some(blk(util::replace(&mut inner.child_tombstones, None)));\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+impl Death {\n+    pub fn new() -> Death {\n+        let (handle, spare) = KillHandle::new();\n+        Death {\n+            kill_handle:     Some(handle),\n+            watching_parent: None,\n+            on_exit:         None,\n+            unkillable:      0,\n+            wont_sleep:      0,\n+            spare_kill_flag: Some(spare),\n+        }\n+    }\n+\n+    pub fn new_child(&self) -> Death {\n+        // FIXME(#7327)\n+        let (handle, spare) = KillHandle::new();\n+        Death {\n+            kill_handle:     Some(handle),\n+            watching_parent: self.kill_handle.clone(),\n+            on_exit:         None,\n+            unkillable:      0,\n+            wont_sleep:      0,\n+            spare_kill_flag: Some(spare),\n+        }\n+    }\n+\n+    /// Collect failure exit codes from children and propagate them to a parent.\n+    pub fn collect_failure(&mut self, mut success: bool) {\n+        // This may run after the task has already failed, so even though the\n+        // task appears to need to be killed, the scheduler should not fail us\n+        // when we block to unwrap.\n+        // (XXX: Another less-elegant reason for doing this is so that the use\n+        // of the LittleLock in reparent_children_to doesn't need to access the\n+        // unkillable flag in the kill_handle, since we'll have removed it.)\n+        rtassert!(self.unkillable == 0);\n+        self.unkillable = 1;\n+\n+        // Step 1. Decide if we need to collect child failures synchronously.\n+        do self.on_exit.take_map |on_exit| {\n+            if success {\n+                // We succeeded, but our children might not. Need to wait for them.\n+                let mut inner = unsafe { self.kill_handle.take_unwrap().unwrap() };\n+                if inner.any_child_failed {\n+                    success = false;\n+                } else {\n+                    // Lockless access to tombstones protected by unwrap barrier.\n+                    success = inner.child_tombstones.take_map_default(true, |f| f());\n+                }\n+            }\n+            on_exit(success);\n+        };\n+\n+        // Step 2. Possibly alert possibly-watching parent to failure status.\n+        // Note that as soon as parent_handle goes out of scope, the parent\n+        // can successfully unwrap its handle and collect our reported status.\n+        do self.watching_parent.take_map |mut parent_handle| {\n+            if success {\n+                // Our handle might be None if we had an exit callback, and\n+                // already unwrapped it. But 'success' being true means no\n+                // child failed, so there's nothing to do (see below case).\n+                do self.kill_handle.take_map |own_handle| {\n+                    own_handle.reparent_children_to(&mut parent_handle);\n+                };\n+            } else {\n+                // Can inform watching parent immediately that we failed.\n+                // (Note the importance of non-failing tasks NOT writing\n+                // 'false', which could obscure another task's failure.)\n+                parent_handle.notify_immediate_failure();\n+            }\n+        };\n+\n+        // Can't use allow_kill directly; that would require the kill handle.\n+        rtassert!(self.unkillable == 1);\n+        self.unkillable = 0;\n+    }\n+\n+    /// Fails if a kill signal was received.\n+    #[inline]\n+    pub fn check_killed(&self) {\n+        match self.kill_handle {\n+            Some(ref kill_handle) =>\n+                // The task may be both unkillable and killed if it does some\n+                // synchronization during unwinding or cleanup (for example,\n+                // sending on a notify port). In that case failing won't help.\n+                if self.unkillable == 0 && kill_handle.killed() {\n+                    fail!(KILLED_MSG);\n+                },\n+            // This may happen during task death (see comments in collect_failure).\n+            None => rtassert!(self.unkillable > 0),\n+        }\n+    }\n+\n+    /// Enter a possibly-nested unkillable section of code.\n+    /// All calls must be paired with a subsequent call to allow_kill.\n+    #[inline]\n+    pub fn inhibit_kill(&mut self, already_failing: bool) {\n+        if self.unkillable == 0 {\n+            rtassert!(self.kill_handle.is_some());\n+            self.kill_handle.get_mut_ref().inhibit_kill(already_failing);\n+        }\n+        self.unkillable += 1;\n+    }\n+\n+    /// Exit a possibly-nested unkillable section of code.\n+    /// All calls must be paired with a preceding call to inhibit_kill.\n+    #[inline]\n+    pub fn allow_kill(&mut self, already_failing: bool) {\n+        rtassert!(self.unkillable != 0);\n+        self.unkillable -= 1;\n+        if self.unkillable == 0 {\n+            rtassert!(self.kill_handle.is_some());\n+            self.kill_handle.get_mut_ref().allow_kill(already_failing);\n+        }\n+    }\n+\n+    /// Enter a possibly-nested \"atomic\" section of code. Just for assertions.\n+    /// All calls must be paired with a subsequent call to allow_yield.\n+    #[inline]\n+    pub fn inhibit_yield(&mut self) {\n+        self.wont_sleep += 1;\n+    }\n+\n+    /// Exit a possibly-nested \"atomic\" section of code. Just for assertions.\n+    /// All calls must be paired with a preceding call to inhibit_yield.\n+    #[inline]\n+    pub fn allow_yield(&mut self) {\n+        rtassert!(self.wont_sleep != 0);\n+        self.wont_sleep -= 1;\n+    }\n+\n+    /// Ensure that the task is allowed to become descheduled.\n+    #[inline]\n+    pub fn assert_may_sleep(&self) {\n+        if self.wont_sleep != 0 {\n+            rtabort!(\"illegal atomic-sleep: can't deschedule inside atomically()\");\n+        }\n+    }\n+}\n+\n+impl Drop for Death {\n+    fn drop(&self) {\n+        // Mustn't be in an atomic or unkillable section at task death.\n+        rtassert!(self.unkillable == 0);\n+        rtassert!(self.wont_sleep == 0);\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+    #[allow(unused_mut)];\n+    use cell::Cell;\n+    use rt::test::*;\n+    use super::*;\n+    use util;\n+\n+    // Test cases don't care about the spare killed flag.\n+    fn make_kill_handle() -> KillHandle { let (h,_) = KillHandle::new(); h }\n+\n+    #[test]\n+    fn no_tombstone_success() {\n+        do run_in_newsched_task {\n+            // Tests case 4 of the 4-way match in reparent_children.\n+            let mut parent = make_kill_handle();\n+            let mut child  = make_kill_handle();\n+\n+            // Without another handle to child, the try unwrap should succeed.\n+            child.reparent_children_to(&mut parent);\n+            let mut parent_inner = unsafe { parent.unwrap() };\n+            assert!(parent_inner.child_tombstones.is_none());\n+            assert!(parent_inner.any_child_failed == false);\n+        }\n+    }\n+    #[test]\n+    fn no_tombstone_failure() {\n+        do run_in_newsched_task {\n+            // Tests case 2 of the 4-way match in reparent_children.\n+            let mut parent = make_kill_handle();\n+            let mut child  = make_kill_handle();\n+\n+            child.notify_immediate_failure();\n+            // Without another handle to child, the try unwrap should succeed.\n+            child.reparent_children_to(&mut parent);\n+            let mut parent_inner = unsafe { parent.unwrap() };\n+            assert!(parent_inner.child_tombstones.is_none());\n+            // Immediate failure should have been propagated.\n+            assert!(parent_inner.any_child_failed);\n+        }\n+    }\n+    #[test]\n+    fn no_tombstone_because_sibling_already_failed() {\n+        do run_in_newsched_task {\n+            // Tests \"case 0, the optimistic path in reparent_children.\n+            let mut parent = make_kill_handle();\n+            let mut child1 = make_kill_handle();\n+            let mut child2 = make_kill_handle();\n+            let mut link   = child2.clone();\n+\n+            // Should set parent's child_failed flag\n+            child1.notify_immediate_failure();\n+            child1.reparent_children_to(&mut parent);\n+            // Should bypass trying to unwrap child2 entirely.\n+            // Otherwise, due to 'link', it would try to tombstone.\n+            child2.reparent_children_to(&mut parent);\n+            // Should successfully unwrap even though 'link' is still alive.\n+            let mut parent_inner = unsafe { parent.unwrap() };\n+            assert!(parent_inner.child_tombstones.is_none());\n+            // Immediate failure should have been propagated by first child.\n+            assert!(parent_inner.any_child_failed);\n+            util::ignore(link);\n+        }\n+    }\n+    #[test]\n+    fn one_tombstone_success() {\n+        do run_in_newsched_task {\n+            let mut parent = make_kill_handle();\n+            let mut child  = make_kill_handle();\n+            let mut link   = child.clone();\n+\n+            // Creates 1 tombstone. Existence of 'link' makes try-unwrap fail.\n+            child.reparent_children_to(&mut parent);\n+            // Let parent collect tombstones.\n+            util::ignore(link);\n+            // Must have created a tombstone\n+            let mut parent_inner = unsafe { parent.unwrap() };\n+            assert!(parent_inner.child_tombstones.take_unwrap()());\n+            assert!(parent_inner.any_child_failed == false);\n+        }\n+    }\n+    #[test]\n+    fn one_tombstone_failure() {\n+        do run_in_newsched_task {\n+            let mut parent = make_kill_handle();\n+            let mut child  = make_kill_handle();\n+            let mut link   = child.clone();\n+\n+            // Creates 1 tombstone. Existence of 'link' makes try-unwrap fail.\n+            child.reparent_children_to(&mut parent);\n+            // Must happen after tombstone to not be immediately propagated.\n+            link.notify_immediate_failure();\n+            // Let parent collect tombstones.\n+            util::ignore(link);\n+            // Must have created a tombstone\n+            let mut parent_inner = unsafe { parent.unwrap() };\n+            // Failure must be seen in the tombstone.\n+            assert!(parent_inner.child_tombstones.take_unwrap()() == false);\n+            assert!(parent_inner.any_child_failed == false);\n+        }\n+    }\n+    #[test]\n+    fn two_tombstones_success() {\n+        do run_in_newsched_task {\n+            let mut parent = make_kill_handle();\n+            let mut middle = make_kill_handle();\n+            let mut child  = make_kill_handle();\n+            let mut link   = child.clone();\n+\n+            child.reparent_children_to(&mut middle); // case 1 tombstone\n+            // 'middle' should try-unwrap okay, but still have to reparent.\n+            middle.reparent_children_to(&mut parent); // case 3 tombston\n+            // Let parent collect tombstones.\n+            util::ignore(link);\n+            // Must have created a tombstone\n+            let mut parent_inner = unsafe { parent.unwrap() };\n+            assert!(parent_inner.child_tombstones.take_unwrap()());\n+            assert!(parent_inner.any_child_failed == false);\n+        }\n+    }\n+    #[test]\n+    fn two_tombstones_failure() {\n+        do run_in_newsched_task {\n+            let mut parent = make_kill_handle();\n+            let mut middle = make_kill_handle();\n+            let mut child  = make_kill_handle();\n+            let mut link   = child.clone();\n+\n+            child.reparent_children_to(&mut middle); // case 1 tombstone\n+            // Must happen after tombstone to not be immediately propagated.\n+            link.notify_immediate_failure();\n+            // 'middle' should try-unwrap okay, but still have to reparent.\n+            middle.reparent_children_to(&mut parent); // case 3 tombstone\n+            // Let parent collect tombstones.\n+            util::ignore(link);\n+            // Must have created a tombstone\n+            let mut parent_inner = unsafe { parent.unwrap() };\n+            // Failure must be seen in the tombstone.\n+            assert!(parent_inner.child_tombstones.take_unwrap()() == false);\n+            assert!(parent_inner.any_child_failed == false);\n+        }\n+    }\n+\n+    // Task killing tests\n+\n+    #[test]\n+    fn kill_basic() {\n+        do run_in_newsched_task {\n+            let mut handle = make_kill_handle();\n+            assert!(!handle.killed());\n+            assert!(handle.kill().is_none());\n+            assert!(handle.killed());\n+        }\n+    }\n+\n+    #[test]\n+    fn double_kill() {\n+        do run_in_newsched_task {\n+            let mut handle = make_kill_handle();\n+            assert!(!handle.killed());\n+            assert!(handle.kill().is_none());\n+            assert!(handle.killed());\n+            assert!(handle.kill().is_none());\n+            assert!(handle.killed());\n+        }\n+    }\n+\n+    #[test]\n+    fn unkillable_after_kill() {\n+        do run_in_newsched_task {\n+            let mut handle = make_kill_handle();\n+            assert!(handle.kill().is_none());\n+            assert!(handle.killed());\n+            let handle_cell = Cell::new(handle);\n+            let result = do spawntask_try {\n+                handle_cell.take().inhibit_kill(false);\n+            };\n+            assert!(result.is_err());\n+        }\n+    }\n+\n+    #[test]\n+    fn unkillable_during_kill() {\n+        do run_in_newsched_task {\n+            let mut handle = make_kill_handle();\n+            handle.inhibit_kill(false);\n+            assert!(handle.kill().is_none());\n+            assert!(!handle.killed());\n+            let handle_cell = Cell::new(handle);\n+            let result = do spawntask_try {\n+                handle_cell.take().allow_kill(false);\n+            };\n+            assert!(result.is_err());\n+        }\n+    }\n+\n+    #[test]\n+    fn unkillable_before_kill() {\n+        do run_in_newsched_task {\n+            let mut handle = make_kill_handle();\n+            handle.inhibit_kill(false);\n+            handle.allow_kill(false);\n+            assert!(handle.kill().is_none());\n+            assert!(handle.killed());\n+        }\n+    }\n+\n+    // Task blocking tests\n+\n+    #[test]\n+    fn block_and_wake() {\n+        do with_test_task |mut task| {\n+            BlockedTask::try_block(task).unwrap_right().wake().unwrap()\n+        }\n+    }\n+\n+    #[test]\n+    fn block_and_get_killed() {\n+        do with_test_task |mut task| {\n+            let mut handle = task.death.kill_handle.get_ref().clone();\n+            let result = BlockedTask::try_block(task).unwrap_right();\n+            let task = handle.kill().unwrap();\n+            assert!(result.wake().is_none());\n+            task\n+        }\n+    }\n+\n+    #[test]\n+    fn block_already_killed() {\n+        do with_test_task |mut task| {\n+            let mut handle = task.death.kill_handle.get_ref().clone();\n+            assert!(handle.kill().is_none());\n+            BlockedTask::try_block(task).unwrap_left()\n+        }\n+    }\n+\n+    #[test]\n+    fn block_unkillably_and_get_killed() {\n+        do with_test_task |mut task| {\n+            let mut handle = task.death.kill_handle.get_ref().clone();\n+            task.death.inhibit_kill(false);\n+            let result = BlockedTask::try_block(task).unwrap_right();\n+            assert!(handle.kill().is_none());\n+            let mut task = result.wake().unwrap();\n+            // This call wants to fail, but we can't have that happen since\n+            // we're not running in a newsched task, so we can't even use\n+            // spawntask_try. But the failing behaviour is already tested\n+            // above, in unkillable_during_kill(), so we punt on it here.\n+            task.death.allow_kill(true);\n+            task\n+        }\n+    }\n+\n+    #[test]\n+    fn block_on_pipe() {\n+        // Tests the \"killable\" path of casting to/from uint.\n+        do run_in_newsched_task {\n+            do with_test_task |mut task| {\n+                let result = BlockedTask::try_block(task).unwrap_right();\n+                let result = unsafe { result.cast_to_uint() };\n+                let result = unsafe { BlockedTask::cast_from_uint(result) };\n+                result.wake().unwrap()\n+            }\n+        }\n+    }\n+\n+    #[test]\n+    fn block_unkillably_on_pipe() {\n+        // Tests the \"indestructible\" path of casting to/from uint.\n+        do run_in_newsched_task {\n+            do with_test_task |mut task| {\n+                task.death.inhibit_kill(false);\n+                let result = BlockedTask::try_block(task).unwrap_right();\n+                let result = unsafe { result.cast_to_uint() };\n+                let result = unsafe { BlockedTask::cast_from_uint(result) };\n+                let mut task = result.wake().unwrap();\n+                task.death.allow_kill(false);\n+                task\n+            }\n+        }\n+    }\n+}"}, {"sha": "85537f476d4a10fc7af2c8d31494dac9709b22db", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -83,6 +83,9 @@ pub mod global_heap;\n /// Implementations of language-critical runtime features like @.\n pub mod task;\n \n+/// Facilities related to task failure, killing, and death.\n+mod kill;\n+\n /// The coroutine task scheduler, built on the `io` event loop.\n mod sched;\n \n@@ -149,9 +152,6 @@ pub mod local_ptr;\n /// Bindings to pthread/windows thread-local storage.\n pub mod thread_local_storage;\n \n-/// For waiting on child tasks.\n-pub mod join_latch;\n-\n pub mod metrics;\n \n // FIXME #5248 shouldn't be pub\n@@ -277,7 +277,7 @@ pub fn run(main: ~fn()) -> int {\n     let main_cell = Cell::new(main);\n     let mut main_task = ~Task::new_root(&mut scheds[0].stack_pool,\n                                     main_cell.take());\n-    main_task.on_exit = Some(on_exit);\n+    main_task.death.on_exit = Some(on_exit);\n     scheds[0].enqueue_task(main_task);\n \n     // Run each scheduler in a thread.\n@@ -367,7 +367,7 @@ fn test_context() {\n             let sched = Local::take::<Scheduler>();\n             do sched.deschedule_running_task_and_then() |sched, task| {\n                 assert_eq!(context(), SchedulerContext);\n-                sched.enqueue_task(task);\n+                sched.enqueue_blocked_task(task);\n             }\n         };\n         sched.enqueue_task(task);"}, {"sha": "d8d61806a5bba88501aff2c0df2add4543b435e5", "filename": "src/libstd/rt/sched.rs", "status": "modified", "additions": 71, "deletions": 23, "changes": 94, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fsched.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -8,7 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use option::*;\n+use either::{Left, Right};\n+use option::{Option, Some, None};\n use sys;\n use cast::transmute;\n use clone::Clone;\n@@ -20,6 +21,7 @@ use super::rtio::{EventLoop, EventLoopObject, RemoteCallbackObject};\n use super::context::Context;\n use super::task::{Task, AnySched, Sched};\n use super::message_queue::MessageQueue;\n+use rt::kill::BlockedTask;\n use rt::local_ptr;\n use rt::local::Local;\n use rt::rtio::RemoteCallback;\n@@ -271,6 +273,14 @@ impl Scheduler {\n         };\n     }\n \n+    /// As enqueue_task, but with the possibility for the blocked task to\n+    /// already have been killed.\n+    pub fn enqueue_blocked_task(&mut self, blocked_task: BlockedTask) {\n+        do blocked_task.wake().map_consume |task| {\n+            self.enqueue_task(task);\n+        };\n+    }\n+\n     // * Scheduler-context operations\n \n     fn interpret_message_queue(~self) -> bool {\n@@ -412,14 +422,26 @@ impl Scheduler {\n     /// Called by a running task to end execution, after which it will\n     /// be recycled by the scheduler for reuse in a new task.\n     pub fn terminate_current_task(~self) {\n-        assert!(self.in_task_context());\n+        let mut this = self;\n+        assert!(this.in_task_context());\n \n         rtdebug!(\"ending running task\");\n \n-        do self.deschedule_running_task_and_then |sched, dead_task| {\n-            let mut dead_task = dead_task;\n-            let coroutine = dead_task.coroutine.take_unwrap();\n-            coroutine.recycle(&mut sched.stack_pool);\n+        // This task is post-cleanup, so it must be unkillable. This sequence\n+        // of descheduling and recycling must not get interrupted by a kill.\n+        // FIXME(#7544): Make this use an inner descheduler, like yield should.\n+        this.current_task.get_mut_ref().death.unkillable += 1;\n+\n+        do this.deschedule_running_task_and_then |sched, dead_task| {\n+            match dead_task.wake() {\n+                Some(dead_task) => {\n+                    let mut dead_task = dead_task;\n+                    dead_task.death.unkillable -= 1; // FIXME(#7544) ugh\n+                    let coroutine = dead_task.coroutine.take_unwrap();\n+                    coroutine.recycle(&mut sched.stack_pool);\n+                }\n+                None => rtabort!(\"dead task killed before recycle\"),\n+            }\n         }\n \n         rtabort!(\"control reached end of task\");\n@@ -440,7 +462,7 @@ impl Scheduler {\n             // here we know we are home, execute now OR we know we\n             // aren't homed, and that this sched doesn't care\n             do this.switch_running_tasks_and_then(task) |sched, last_task| {\n-                sched.enqueue_task(last_task);\n+                sched.enqueue_blocked_task(last_task);\n             }\n         } else if !homed && !this.run_anything {\n             // the task isn't homed, but it can't be run here\n@@ -483,9 +505,21 @@ impl Scheduler {\n \n             // Running tasks may have asked us to do some cleanup\n             (*sched).run_cleanup_job();\n+\n+            // Must happen after running the cleanup job (of course).\n+            // Might not be running in task context; if not, a later call to\n+            // resume_task_immediately will take care of this.\n+            (*sched).current_task.map(|t| t.death.check_killed());\n         }\n     }\n \n+    pub fn resume_blocked_task_immediately(~self, blocked_task: BlockedTask) {\n+        match blocked_task.wake() {\n+            Some(task) => self.resume_task_immediately(task),\n+            None => Local::put(self),\n+        };\n+    }\n+\n     /// Block a running task, context switch to the scheduler, then pass the\n     /// blocked task to a closure.\n     ///\n@@ -498,7 +532,7 @@ impl Scheduler {\n     /// This passes a Scheduler pointer to the fn after the context switch\n     /// in order to prevent that fn from performing further scheduling operations.\n     /// Doing further scheduling could easily result in infinite recursion.\n-    pub fn deschedule_running_task_and_then(~self, f: &fn(&mut Scheduler, ~Task)) {\n+    pub fn deschedule_running_task_and_then(~self, f: &fn(&mut Scheduler, BlockedTask)) {\n         let mut this = self;\n         assert!(this.in_task_context());\n \n@@ -507,8 +541,8 @@ impl Scheduler {\n \n         unsafe {\n             let blocked_task = this.current_task.take_unwrap();\n-            let f_fake_region = transmute::<&fn(&mut Scheduler, ~Task),\n-                                            &fn(&mut Scheduler, ~Task)>(f);\n+            let f_fake_region = transmute::<&fn(&mut Scheduler, BlockedTask),\n+                                            &fn(&mut Scheduler, BlockedTask)>(f);\n             let f_opaque = ClosureConverter::from_fn(f_fake_region);\n             this.enqueue_cleanup_job(GiveTask(blocked_task, f_opaque));\n         }\n@@ -524,14 +558,17 @@ impl Scheduler {\n             // We could be executing in a different thread now\n             let sched = Local::unsafe_borrow::<Scheduler>();\n             (*sched).run_cleanup_job();\n+\n+            // As above, must happen after running the cleanup job.\n+            (*sched).current_task.map(|t| t.death.check_killed());\n         }\n     }\n \n     /// Switch directly to another task, without going through the scheduler.\n     /// You would want to think hard about doing this, e.g. if there are\n     /// pending I/O events it would be a bad idea.\n     pub fn switch_running_tasks_and_then(~self, next_task: ~Task,\n-                                         f: &fn(&mut Scheduler, ~Task)) {\n+                                         f: &fn(&mut Scheduler, BlockedTask)) {\n         let mut this = self;\n         assert!(this.in_task_context());\n \n@@ -540,8 +577,8 @@ impl Scheduler {\n \n         let old_running_task = this.current_task.take_unwrap();\n         let f_fake_region = unsafe {\n-            transmute::<&fn(&mut Scheduler, ~Task),\n-                        &fn(&mut Scheduler, ~Task)>(f)\n+            transmute::<&fn(&mut Scheduler, BlockedTask),\n+                        &fn(&mut Scheduler, BlockedTask)>(f)\n         };\n         let f_opaque = ClosureConverter::from_fn(f_fake_region);\n         this.enqueue_cleanup_job(GiveTask(old_running_task, f_opaque));\n@@ -559,6 +596,9 @@ impl Scheduler {\n             // We could be executing in a different thread now\n             let sched = Local::unsafe_borrow::<Scheduler>();\n             (*sched).run_cleanup_job();\n+\n+            // As above, must happen after running the cleanup job.\n+            (*sched).current_task.map(|t| t.death.check_killed());\n         }\n     }\n \n@@ -579,7 +619,15 @@ impl Scheduler {\n         let cleanup_job = self.cleanup_job.take_unwrap();\n         match cleanup_job {\n             DoNothing => { }\n-            GiveTask(task, f) => (f.to_fn())(self, task)\n+            GiveTask(task, f) => {\n+                let f = f.to_fn();\n+                // Task might need to receive a kill signal instead of blocking.\n+                // We can call the \"and_then\" only if it blocks successfully.\n+                match BlockedTask::try_block(task) {\n+                    Left(killed_task) => self.enqueue_task(killed_task),\n+                    Right(blocked_task) => f(self, blocked_task),\n+                }\n+            }\n         }\n     }\n \n@@ -652,12 +700,14 @@ impl SchedHandle {\n // complaining\n type UnsafeTaskReceiver = sys::Closure;\n trait ClosureConverter {\n-    fn from_fn(&fn(&mut Scheduler, ~Task)) -> Self;\n-    fn to_fn(self) -> &fn(&mut Scheduler, ~Task);\n+    fn from_fn(&fn(&mut Scheduler, BlockedTask)) -> Self;\n+    fn to_fn(self) -> &fn(&mut Scheduler, BlockedTask);\n }\n impl ClosureConverter for UnsafeTaskReceiver {\n-    fn from_fn(f: &fn(&mut Scheduler, ~Task)) -> UnsafeTaskReceiver { unsafe { transmute(f) } }\n-    fn to_fn(self) -> &fn(&mut Scheduler, ~Task) { unsafe { transmute(self) } }\n+    fn from_fn(f: &fn(&mut Scheduler, BlockedTask)) -> UnsafeTaskReceiver {\n+        unsafe { transmute(f) }\n+    }\n+    fn to_fn(self) -> &fn(&mut Scheduler, BlockedTask) { unsafe { transmute(self) } }\n }\n \n \n@@ -917,8 +967,7 @@ mod test {\n                 };\n                 // Context switch directly to the new task\n                 do sched.switch_running_tasks_and_then(task2) |sched, task1| {\n-                    let task1 = Cell::new(task1);\n-                    sched.enqueue_task(task1.take());\n+                    sched.enqueue_blocked_task(task1);\n                 }\n                 unsafe { *count_ptr = *count_ptr + 1; }\n             };\n@@ -969,9 +1018,8 @@ mod test {\n                 let sched = Local::take::<Scheduler>();\n                 assert!(sched.in_task_context());\n                 do sched.deschedule_running_task_and_then() |sched, task| {\n-                    let task = Cell::new(task);\n                     assert!(!sched.in_task_context());\n-                    sched.enqueue_task(task.take());\n+                    sched.enqueue_blocked_task(task);\n                 }\n             };\n             sched.enqueue_task(task);\n@@ -993,7 +1041,7 @@ mod test {\n                     do sched.event_loop.callback_ms(10) {\n                         rtdebug!(\"in callback\");\n                         let mut sched = Local::take::<Scheduler>();\n-                        sched.enqueue_task(task.take());\n+                        sched.enqueue_blocked_task(task.take());\n                         Local::put(sched);\n                     }\n                 }"}, {"sha": "d2975148350852aa2c46594651fb82120ea0c2bf", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 11, "deletions": 20, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -20,13 +20,14 @@ use libc::{c_void, uintptr_t};\n use ptr;\n use prelude::*;\n use option::{Option, Some, None};\n+use rt::kill::Death;\n use rt::local::Local;\n use rt::logging::StdErrLogger;\n use super::local_heap::LocalHeap;\n use rt::sched::{Scheduler, SchedHandle};\n-use rt::join_latch::JoinLatch;\n use rt::stack::{StackSegment, StackPool};\n use rt::context::Context;\n+use task::spawn::Taskgroup;\n use cell::Cell;\n \n pub struct Task {\n@@ -36,8 +37,8 @@ pub struct Task {\n     logger: StdErrLogger,\n     unwinder: Unwinder,\n     home: Option<SchedHome>,\n-    join_latch: Option<~JoinLatch>,\n-    on_exit: Option<~fn(bool)>,\n+    taskgroup: Option<Taskgroup>,\n+    death: Death,\n     destroyed: bool,\n     coroutine: Option<~Coroutine>\n }\n@@ -86,8 +87,8 @@ impl Task {\n             logger: StdErrLogger,\n             unwinder: Unwinder { unwinding: false },\n             home: Some(home),\n-            join_latch: Some(JoinLatch::new_root()),\n-            on_exit: None,\n+            taskgroup: None,\n+            death: Death::new(),\n             destroyed: false,\n             coroutine: Some(~Coroutine::new(stack_pool, start))\n         }\n@@ -104,8 +105,9 @@ impl Task {\n             logger: StdErrLogger,\n             home: Some(home),\n             unwinder: Unwinder { unwinding: false },\n-            join_latch: Some(self.join_latch.get_mut_ref().new_child()),\n-            on_exit: None,\n+            taskgroup: None,\n+            // FIXME(#7544) make watching optional\n+            death: self.death.new_child(),\n             destroyed: false,\n             coroutine: Some(~Coroutine::new(stack_pool, start))\n         }\n@@ -123,20 +125,9 @@ impl Task {\n         }\n \n         self.unwinder.try(f);\n+        { let _ = self.taskgroup.take(); }\n+        self.death.collect_failure(!self.unwinder.unwinding);\n         self.destroy();\n-\n-        // Wait for children. Possibly report the exit status.\n-        let local_success = !self.unwinder.unwinding;\n-        let join_latch = self.join_latch.take_unwrap();\n-        match self.on_exit {\n-            Some(ref on_exit) => {\n-                let success = join_latch.wait(local_success);\n-                (*on_exit)(success);\n-            }\n-            None => {\n-                join_latch.release(local_success);\n-            }\n-        }\n     }\n \n     /// must be called manually before finalization to clean up"}, {"sha": "a9cbc6dae316c4430aeb9fc68c93750b9d24e8ff", "filename": "src/libstd/rt/test.rs", "status": "modified", "additions": 17, "deletions": 7, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftest.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -51,7 +51,7 @@ pub fn run_in_newsched_task(f: ~fn()) {\n         let mut task = ~Task::new_root(&mut sched.stack_pool,\n                                        f.take());\n         rtdebug!(\"newsched_task: %x\", to_uint(task));\n-        task.on_exit = Some(on_exit);\n+        task.death.on_exit = Some(on_exit);\n         sched.enqueue_task(task);\n         sched.run();\n     }\n@@ -108,7 +108,7 @@ pub fn run_in_mt_newsched_task(f: ~fn()) {\n         };\n         let mut main_task = ~Task::new_root(&mut scheds[0].stack_pool,\n                                         f_cell.take());\n-        main_task.on_exit = Some(on_exit);\n+        main_task.death.on_exit = Some(on_exit);\n         scheds[0].enqueue_task(main_task);\n \n         let mut threads = ~[];\n@@ -169,7 +169,7 @@ pub fn spawntask_immediately(f: ~fn()) {\n \n     let sched = Local::take::<Scheduler>();\n     do sched.switch_running_tasks_and_then(task) |sched, task| {\n-        sched.enqueue_task(task);\n+        sched.enqueue_blocked_task(task);\n     }\n }\n \n@@ -213,7 +213,7 @@ pub fn spawntask_random(f: ~fn()) {\n \n     if run_now {\n         do sched.switch_running_tasks_and_then(task) |sched, task| {\n-            sched.enqueue_task(task);\n+            sched.enqueue_blocked_task(task);\n         }\n     } else {\n         sched.enqueue_task(task);\n@@ -279,11 +279,11 @@ pub fn spawntask_try(f: ~fn()) -> Result<(), ()> {\n                            f.take())\n         }\n     };\n-    new_task.on_exit = Some(on_exit);\n+    new_task.death.on_exit = Some(on_exit);\n \n     let sched = Local::take::<Scheduler>();\n     do sched.switch_running_tasks_and_then(new_task) |sched, old_task| {\n-        sched.enqueue_task(old_task);\n+        sched.enqueue_blocked_task(old_task);\n     }\n \n     rtdebug!(\"enqueued the new task, now waiting on exit_status\");\n@@ -292,7 +292,7 @@ pub fn spawntask_try(f: ~fn()) -> Result<(), ()> {\n     if exit_status { Ok(()) } else { Err(()) }\n }\n \n-// Spawn a new task in a new scheduler and return a thread handle.\n+/// Spawn a new task in a new scheduler and return a thread handle.\n pub fn spawntask_thread(f: ~fn()) -> Thread {\n     use rt::sched::*;\n \n@@ -316,6 +316,16 @@ pub fn spawntask_thread(f: ~fn()) -> Thread {\n     return thread;\n }\n \n+/// Get a ~Task for testing purposes other than actually scheduling it.\n+pub fn with_test_task(blk: ~fn(~Task) -> ~Task) {\n+    do run_in_bare_thread {\n+        let mut sched = ~new_test_uv_sched();\n+        let task = blk(~Task::new_root(&mut sched.stack_pool, ||{}));\n+        sched.enqueue_task(task);\n+        sched.run();\n+    }\n+}\n+\n \n /// Get a port number, starting at 9600, for use in tests\n pub fn next_test_port() -> u16 {"}, {"sha": "bc223d8f3f70d4bcdf4ac54e14353b45b648fc53", "filename": "src/libstd/rt/tube.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Ftube.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Ftube.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftube.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -18,13 +18,13 @@ use clone::Clone;\n use super::rc::RC;\n use rt::sched::Scheduler;\n use rt::{context, TaskContext, SchedulerContext};\n+use rt::kill::BlockedTask;\n use rt::local::Local;\n-use rt::task::Task;\n use vec::OwnedVector;\n use container::Container;\n \n struct TubeState<T> {\n-    blocked_task: Option<~Task>,\n+    blocked_task: Option<BlockedTask>,\n     buf: ~[T]\n }\n \n@@ -55,7 +55,7 @@ impl<T> Tube<T> {\n                 rtdebug!(\"waking blocked tube\");\n                 let task = (*state).blocked_task.take_unwrap();\n                 let sched = Local::take::<Scheduler>();\n-                sched.resume_task_immediately(task);\n+                sched.resume_blocked_task_immediately(task);\n             }\n         }\n     }\n@@ -111,7 +111,7 @@ mod test {\n             do sched.deschedule_running_task_and_then |sched, task| {\n                 let mut tube_clone = tube_clone_cell.take();\n                 tube_clone.send(1);\n-                sched.enqueue_task(task);\n+                sched.enqueue_blocked_task(task);\n             }\n \n             assert!(tube.recv() == 1);\n@@ -133,7 +133,7 @@ mod test {\n                     // sending will wake it up.\n                     tube_clone.send(1);\n                 }\n-                sched.enqueue_task(task);\n+                sched.enqueue_blocked_task(task);\n             }\n \n             assert!(tube.recv() == 1);\n@@ -168,7 +168,7 @@ mod test {\n                     }\n                 }\n \n-                sched.enqueue_task(task);\n+                sched.enqueue_blocked_task(task);\n             }\n \n             for int::range(0, MAX) |i| {"}, {"sha": "7046afe855133a53850772bd3da836546a39a166", "filename": "src/libstd/rt/uv/uvio.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -227,15 +227,15 @@ impl IoFactory for UvIoFactory {\n \n                     // Context switch\n                     let scheduler = Local::take::<Scheduler>();\n-                    scheduler.resume_task_immediately(task_cell.take());\n+                    scheduler.resume_blocked_task_immediately(task_cell.take());\n                 } else {\n                     rtdebug!(\"status is some\");\n                     let task_cell = Cell::new(task_cell.take());\n                     do stream_watcher.close {\n                         let res = Err(uv_error_to_io_error(status.get()));\n                         unsafe { (*result_cell_ptr).put_back(res); }\n                         let scheduler = Local::take::<Scheduler>();\n-                        scheduler.resume_task_immediately(task_cell.take());\n+                        scheduler.resume_blocked_task_immediately(task_cell.take());\n                     }\n                 };\n             }\n@@ -255,7 +255,7 @@ impl IoFactory for UvIoFactory {\n                     let task_cell = Cell::new(task);\n                     do watcher.as_stream().close {\n                         let scheduler = Local::take::<Scheduler>();\n-                        scheduler.resume_task_immediately(task_cell.take());\n+                        scheduler.resume_blocked_task_immediately(task_cell.take());\n                     }\n                 }\n                 Err(uv_error_to_io_error(uverr))\n@@ -273,7 +273,7 @@ impl IoFactory for UvIoFactory {\n                     let task_cell = Cell::new(task);\n                     do watcher.close {\n                         let scheduler = Local::take::<Scheduler>();\n-                        scheduler.resume_task_immediately(task_cell.take());\n+                        scheduler.resume_blocked_task_immediately(task_cell.take());\n                     }\n                 }\n                 Err(uv_error_to_io_error(uverr))\n@@ -309,7 +309,7 @@ impl Drop for UvTcpListener {\n             let task_cell = Cell::new(task);\n             do watcher.as_stream().close {\n                 let scheduler = Local::take::<Scheduler>();\n-                scheduler.resume_task_immediately(task_cell.take());\n+                scheduler.resume_blocked_task_immediately(task_cell.take());\n             }\n         }\n     }\n@@ -372,7 +372,7 @@ impl Drop for UvTcpStream {\n             let task_cell = Cell::new(task);\n             do self.close {\n                 let scheduler = Local::take::<Scheduler>();\n-                scheduler.resume_task_immediately(task_cell.take());\n+                scheduler.resume_blocked_task_immediately(task_cell.take());\n             }\n         }\n     }\n@@ -419,7 +419,7 @@ impl RtioTcpStream for UvTcpStream {\n                 unsafe { (*result_cell_ptr).put_back(result); }\n \n                 let scheduler = Local::take::<Scheduler>();\n-                scheduler.resume_task_immediately(task_cell.take());\n+                scheduler.resume_blocked_task_immediately(task_cell.take());\n             }\n         }\n \n@@ -447,7 +447,7 @@ impl RtioTcpStream for UvTcpStream {\n                 unsafe { (*result_cell_ptr).put_back(result); }\n \n                 let scheduler = Local::take::<Scheduler>();\n-                scheduler.resume_task_immediately(task_cell.take());\n+                scheduler.resume_blocked_task_immediately(task_cell.take());\n             }\n         }\n \n@@ -473,7 +473,7 @@ impl Drop for UvUdpSocket {\n             let task_cell = Cell::new(task);\n             do self.close {\n                 let scheduler = Local::take::<Scheduler>();\n-                scheduler.resume_task_immediately(task_cell.take());\n+                scheduler.resume_blocked_task_immediately(task_cell.take());\n             }\n         }\n     }\n@@ -513,7 +513,7 @@ impl RtioUdpSocket for UvUdpSocket {\n                 unsafe { (*result_cell_ptr).put_back(result); }\n \n                 let scheduler = Local::take::<Scheduler>();\n-                scheduler.resume_task_immediately(task_cell.take());\n+                scheduler.resume_blocked_task_immediately(task_cell.take());\n             }\n         }\n \n@@ -540,7 +540,7 @@ impl RtioUdpSocket for UvUdpSocket {\n                 unsafe { (*result_cell_ptr).put_back(result); }\n \n                 let scheduler = Local::take::<Scheduler>();\n-                scheduler.resume_task_immediately(task_cell.take());\n+                scheduler.resume_blocked_task_immediately(task_cell.take());\n             }\n         }\n \n@@ -678,7 +678,7 @@ fn test_read_and_block() {\n                 // not ready for it\n                 do scheduler.deschedule_running_task_and_then |sched, task| {\n                     let task = Cell::new(task);\n-                    sched.enqueue_task(task.take());\n+                    sched.enqueue_blocked_task(task.take());\n                 }\n             }\n "}, {"sha": "de6410aa82f91d70bfba72942968f4cc686a28cb", "filename": "src/libstd/task/mod.rs", "status": "modified", "additions": 207, "deletions": 71, "changes": 278, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Ftask%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Ftask%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fmod.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -42,10 +42,10 @@ use cmp::Eq;\n use comm::{stream, Chan, GenericChan, GenericPort, Port};\n use result::Result;\n use result;\n-use rt::{context, OldTaskContext};\n+use rt::{context, OldTaskContext, TaskContext};\n+use rt::local::Local;\n use task::rt::{task_id, sched_id};\n use unstable::finally::Finally;\n-use util::replace;\n use util;\n \n #[cfg(test)] use cast;\n@@ -147,6 +147,17 @@ pub struct SchedOpts {\n  * * supervised - Propagate failure unidirectionally from parent to child,\n  *                but not from child to parent. False by default.\n  *\n+ * * watched - Make parent task collect exit status notifications from child\n+ *             before reporting its own exit status. (This delays the parent\n+ *             task's death and cleanup until after all transitively watched\n+ *             children also exit.) True by default.\n+ *\n+ * * indestructible - Configures the task to ignore kill signals received from\n+ *                    linked failure. This may cause process hangs during\n+ *                    failure if not used carefully, but causes task blocking\n+ *                    code paths (e.g. port recv() calls) to be faster by 2\n+ *                    atomic operations. False by default.\n+ *\n  * * notify_chan - Enable lifecycle notifications on the given channel\n  *\n  * * sched - Specify the configuration of a new scheduler to create the task\n@@ -165,6 +176,8 @@ pub struct SchedOpts {\n pub struct TaskOpts {\n     linked: bool,\n     supervised: bool,\n+    watched: bool,\n+    indestructible: bool,\n     notify_chan: Option<Chan<TaskResult>>,\n     sched: SchedOpts\n }\n@@ -210,12 +223,14 @@ impl TaskBuilder {\n             fail!(\"Cannot copy a task_builder\"); // Fake move mode on self\n         }\n         self.consumed = true;\n-        let gen_body = replace(&mut self.gen_body, None);\n-        let notify_chan = replace(&mut self.opts.notify_chan, None);\n+        let gen_body = self.gen_body.take();\n+        let notify_chan = self.opts.notify_chan.take();\n         TaskBuilder {\n             opts: TaskOpts {\n                 linked: self.opts.linked,\n                 supervised: self.opts.supervised,\n+                watched: self.opts.watched,\n+                indestructible: self.opts.indestructible,\n                 notify_chan: notify_chan,\n                 sched: self.opts.sched\n             },\n@@ -231,6 +246,7 @@ impl TaskBuilder {\n     /// the other will not be killed.\n     pub fn unlinked(&mut self) {\n         self.opts.linked = false;\n+        self.opts.watched = false;\n     }\n \n     /// Unidirectionally link the child task's failure with the parent's. The\n@@ -239,13 +255,34 @@ impl TaskBuilder {\n     pub fn supervised(&mut self) {\n         self.opts.supervised = true;\n         self.opts.linked = false;\n+        self.opts.watched = false;\n     }\n \n     /// Link the child task's and parent task's failures. If either fails, the\n     /// other will be killed.\n     pub fn linked(&mut self) {\n         self.opts.linked = true;\n         self.opts.supervised = false;\n+        self.opts.watched = true;\n+    }\n+\n+    /// Cause the parent task to collect the child's exit status (and that of\n+    /// all transitively-watched grandchildren) before reporting its own.\n+    pub fn watched(&mut self) {\n+        self.opts.watched = true;\n+    }\n+\n+    /// Allow the child task to outlive the parent task, at the possible cost\n+    /// of the parent reporting success even if the child task fails later.\n+    pub fn unwatched(&mut self) {\n+        self.opts.watched = false;\n+    }\n+\n+    /// Cause the child task to ignore any kill signals received from linked\n+    /// failure. This optimizes context switching, at the possible expense of\n+    /// process hangs in the case of unexpected failure.\n+    pub fn indestructible(&mut self) {\n+        self.opts.indestructible = true;\n     }\n \n     /**\n@@ -302,7 +339,7 @@ impl TaskBuilder {\n      * existing body generator to the new body generator.\n      */\n     pub fn add_wrapper(&mut self, wrapper: ~fn(v: ~fn()) -> ~fn()) {\n-        let prev_gen_body = replace(&mut self.gen_body, None);\n+        let prev_gen_body = self.gen_body.take();\n         let prev_gen_body = match prev_gen_body {\n             Some(gen) => gen,\n             None => {\n@@ -334,12 +371,14 @@ impl TaskBuilder {\n      * must be greater than zero.\n      */\n     pub fn spawn(&mut self, f: ~fn()) {\n-        let gen_body = replace(&mut self.gen_body, None);\n-        let notify_chan = replace(&mut self.opts.notify_chan, None);\n+        let gen_body = self.gen_body.take();\n+        let notify_chan = self.opts.notify_chan.take();\n         let x = self.consume();\n         let opts = TaskOpts {\n             linked: x.opts.linked,\n             supervised: x.opts.supervised,\n+            watched: x.opts.watched,\n+            indestructible: x.opts.indestructible,\n             notify_chan: notify_chan,\n             sched: x.opts.sched\n         };\n@@ -406,6 +445,8 @@ pub fn default_task_opts() -> TaskOpts {\n     TaskOpts {\n         linked: true,\n         supervised: false,\n+        watched: true,\n+        indestructible: false,\n         notify_chan: None,\n         sched: SchedOpts {\n             mode: DefaultScheduler,\n@@ -447,6 +488,17 @@ pub fn spawn_supervised(f: ~fn()) {\n     task.spawn(f)\n }\n \n+/// Creates a child task that cannot be killed by linked failure. This causes\n+/// its context-switch path to be faster by 2 atomic swap operations.\n+/// (Note that this convenience wrapper still uses linked-failure, so the\n+/// child's children will still be killable by the parent. For the fastest\n+/// possible spawn mode, use task::task().unlinked().indestructible().spawn.)\n+pub fn spawn_indestructible(f: ~fn()) {\n+    let mut task = task();\n+    task.indestructible();\n+    task.spawn(f)\n+}\n+\n pub fn spawn_with<A:Send>(arg: A, f: ~fn(v: A)) {\n     /*!\n      * Runs a task, while transfering ownership of one argument to the\n@@ -514,9 +566,10 @@ pub fn yield() {\n             }\n             _ => {\n                 // XXX: What does yield really mean in newsched?\n+                // FIXME(#7544): Optimize this, since we know we won't block.\n                 let sched = Local::take::<Scheduler>();\n                 do sched.deschedule_running_task_and_then |sched, task| {\n-                    sched.enqueue_task(task);\n+                    sched.enqueue_blocked_task(task);\n                 }\n             }\n         }\n@@ -526,8 +579,6 @@ pub fn yield() {\n pub fn failing() -> bool {\n     //! True if the running task has failed\n \n-    use rt::{context, OldTaskContext};\n-    use rt::local::Local;\n     use rt::task::Task;\n \n     match context() {\n@@ -572,33 +623,59 @@ pub fn get_scheduler() -> Scheduler {\n  * ~~~\n  */\n pub unsafe fn unkillable<U>(f: &fn() -> U) -> U {\n-    if context() == OldTaskContext {\n-        let t = rt::rust_get_task();\n-        do (|| {\n-            rt::rust_task_inhibit_kill(t);\n-            f()\n-        }).finally {\n-            rt::rust_task_allow_kill(t);\n+    use rt::task::Task;\n+\n+    match context() {\n+        OldTaskContext => {\n+            let t = rt::rust_get_task();\n+            do (|| {\n+                rt::rust_task_inhibit_kill(t);\n+                f()\n+            }).finally {\n+                rt::rust_task_allow_kill(t);\n+            }\n+        }\n+        TaskContext => {\n+            // The inhibits/allows might fail and need to borrow the task.\n+            let t = Local::unsafe_borrow::<Task>();\n+            do (|| {\n+                (*t).death.inhibit_kill((*t).unwinder.unwinding);\n+                f()\n+            }).finally {\n+                (*t).death.allow_kill((*t).unwinder.unwinding);\n+            }\n         }\n-    } else {\n-        // FIXME #6377\n-        f()\n+        // FIXME(#3095): This should be an rtabort as soon as the scheduler\n+        // no longer uses a workqueue implemented with an Exclusive.\n+        _ => f()\n     }\n }\n \n /// The inverse of unkillable. Only ever to be used nested in unkillable().\n pub unsafe fn rekillable<U>(f: &fn() -> U) -> U {\n-    if context() == OldTaskContext {\n-        let t = rt::rust_get_task();\n-        do (|| {\n-            rt::rust_task_allow_kill(t);\n-            f()\n-        }).finally {\n-            rt::rust_task_inhibit_kill(t);\n+    use rt::task::Task;\n+\n+    match context() {\n+        OldTaskContext => {\n+            let t = rt::rust_get_task();\n+            do (|| {\n+                rt::rust_task_allow_kill(t);\n+                f()\n+            }).finally {\n+                rt::rust_task_inhibit_kill(t);\n+            }\n+        }\n+        TaskContext => {\n+            let t = Local::unsafe_borrow::<Task>();\n+            do (|| {\n+                (*t).death.allow_kill((*t).unwinder.unwinding);\n+                f()\n+            }).finally {\n+                (*t).death.inhibit_kill((*t).unwinder.unwinding);\n+            }\n         }\n-    } else {\n-        // FIXME #6377\n-        f()\n+        // FIXME(#3095): As in unkillable().\n+        _ => f()\n     }\n }\n \n@@ -607,19 +684,36 @@ pub unsafe fn rekillable<U>(f: &fn() -> U) -> U {\n  * For use with exclusive ARCs, which use pthread mutexes directly.\n  */\n pub unsafe fn atomically<U>(f: &fn() -> U) -> U {\n-    if context() == OldTaskContext {\n-        let t = rt::rust_get_task();\n-        do (|| {\n-            rt::rust_task_inhibit_kill(t);\n-            rt::rust_task_inhibit_yield(t);\n-            f()\n-        }).finally {\n-            rt::rust_task_allow_yield(t);\n-            rt::rust_task_allow_kill(t);\n+    use rt::task::Task;\n+\n+    match context() {\n+        OldTaskContext => {\n+            let t = rt::rust_get_task();\n+            do (|| {\n+                rt::rust_task_inhibit_kill(t);\n+                rt::rust_task_inhibit_yield(t);\n+                f()\n+            }).finally {\n+                rt::rust_task_allow_yield(t);\n+                rt::rust_task_allow_kill(t);\n+            }\n         }\n-    } else {\n-        // FIXME #6377\n-        f()\n+        TaskContext => {\n+            let t = Local::unsafe_borrow::<Task>();\n+            do (|| {\n+                // It's important to inhibit kill after inhibiting yield, because\n+                // inhibit-kill might fail if we were already killed, and the\n+                // inhibit-yield must happen to match the finally's allow-yield.\n+                (*t).death.inhibit_yield();\n+                (*t).death.inhibit_kill((*t).unwinder.unwinding);\n+                f()\n+            }).finally {\n+                (*t).death.allow_kill((*t).unwinder.unwinding);\n+                (*t).death.allow_yield();\n+            }\n+        }\n+        // FIXME(#3095): As in unkillable().\n+        _ => f()\n     }\n }\n \n@@ -640,6 +734,9 @@ fn test_cant_dup_task_builder() {\n // !!! These tests are dangerous. If Something is buggy, they will hang, !!!\n // !!! instead of exiting cleanly. This might wedge the buildbots.       !!!\n \n+#[cfg(test)]\n+fn block_forever() { let (po, _ch) = stream::<()>(); po.recv(); }\n+\n #[test] #[ignore(cfg(windows))]\n fn test_spawn_unlinked_unsup_no_fail_down() { // grandchild sends on a port\n     let (po, ch) = stream();\n@@ -667,14 +764,12 @@ fn test_spawn_unlinked_sup_no_fail_up() { // child unlinked fails\n }\n #[test] #[should_fail] #[ignore(cfg(windows))]\n fn test_spawn_unlinked_sup_fail_down() {\n-    do spawn_supervised { loop { task::yield(); } }\n+    do spawn_supervised { block_forever(); }\n     fail!(); // Shouldn't leave a child hanging around.\n }\n \n #[test] #[should_fail] #[ignore(cfg(windows))]\n fn test_spawn_linked_sup_fail_up() { // child fails; parent fails\n-    let (po, _ch) = stream::<()>();\n-\n     // Unidirectional \"parenting\" shouldn't override bidirectional linked.\n     // We have to cheat with opts - the interface doesn't support them because\n     // they don't make sense (redundant with task().supervised()).\n@@ -685,7 +780,7 @@ fn test_spawn_linked_sup_fail_up() { // child fails; parent fails\n     do b0.spawn {\n         fail!();\n     }\n-    po.recv(); // We should get punted awake\n+    block_forever(); // We should get punted awake\n }\n #[test] #[should_fail] #[ignore(cfg(windows))]\n fn test_spawn_linked_sup_fail_down() { // parent fails; child fails\n@@ -694,36 +789,27 @@ fn test_spawn_linked_sup_fail_down() { // parent fails; child fails\n     let mut b0 = task();\n     b0.opts.linked = true;\n     b0.opts.supervised = true;\n-    do b0.spawn {\n-        loop {\n-            task::yield();\n-        }\n-    }\n+    do b0.spawn { block_forever(); }\n     fail!(); // *both* mechanisms would be wrong if this didn't kill the child\n }\n #[test] #[should_fail] #[ignore(cfg(windows))]\n fn test_spawn_linked_unsup_fail_up() { // child fails; parent fails\n-    let (po, _ch) = stream::<()>();\n     // Default options are to spawn linked & unsupervised.\n     do spawn { fail!(); }\n-    po.recv(); // We should get punted awake\n+    block_forever(); // We should get punted awake\n }\n #[test] #[should_fail] #[ignore(cfg(windows))]\n fn test_spawn_linked_unsup_fail_down() { // parent fails; child fails\n     // Default options are to spawn linked & unsupervised.\n-    do spawn { loop { task::yield(); } }\n+    do spawn { block_forever(); }\n     fail!();\n }\n #[test] #[should_fail] #[ignore(cfg(windows))]\n fn test_spawn_linked_unsup_default_opts() { // parent fails; child fails\n     // Make sure the above test is the same as this one.\n     let mut builder = task();\n     builder.linked();\n-    do builder.spawn {\n-        loop {\n-            task::yield();\n-        }\n-    }\n+    do builder.spawn { block_forever(); }\n     fail!();\n }\n \n@@ -734,9 +820,7 @@ fn test_spawn_linked_unsup_default_opts() { // parent fails; child fails\n fn test_spawn_failure_propagate_grandchild() {\n     // Middle task exits; does grandparent's failure propagate across the gap?\n     do spawn_supervised {\n-        do spawn_supervised {\n-            loop { task::yield(); }\n-        }\n+        do spawn_supervised { block_forever(); }\n     }\n     for 16.times { task::yield(); }\n     fail!();\n@@ -746,9 +830,7 @@ fn test_spawn_failure_propagate_grandchild() {\n fn test_spawn_failure_propagate_secondborn() {\n     // First-born child exits; does parent's failure propagate to sibling?\n     do spawn_supervised {\n-        do spawn { // linked\n-            loop { task::yield(); }\n-        }\n+        do spawn { block_forever(); } // linked\n     }\n     for 16.times { task::yield(); }\n     fail!();\n@@ -758,9 +840,7 @@ fn test_spawn_failure_propagate_secondborn() {\n fn test_spawn_failure_propagate_nephew_or_niece() {\n     // Our sibling exits; does our failure propagate to sibling's child?\n     do spawn { // linked\n-        do spawn_supervised {\n-            loop { task::yield(); }\n-        }\n+        do spawn_supervised { block_forever(); }\n     }\n     for 16.times { task::yield(); }\n     fail!();\n@@ -770,9 +850,7 @@ fn test_spawn_failure_propagate_nephew_or_niece() {\n fn test_spawn_linked_sup_propagate_sibling() {\n     // Middle sibling exits - does eldest's failure propagate to youngest?\n     do spawn { // linked\n-        do spawn { // linked\n-            loop { task::yield(); }\n-        }\n+        do spawn { block_forever(); } // linked\n     }\n     for 16.times { task::yield(); }\n     fail!();\n@@ -1182,3 +1260,61 @@ fn test_simple_newsched_spawn() {\n     }\n }\n \n+#[test] #[ignore(cfg(windows))]\n+fn test_spawn_watched() {\n+    use rt::test::{run_in_newsched_task, spawntask_try};\n+    do run_in_newsched_task {\n+        let result = do spawntask_try {\n+            let mut t = task();\n+            t.unlinked();\n+            t.watched();\n+            do t.spawn {\n+                let mut t = task();\n+                t.unlinked();\n+                t.watched();\n+                do t.spawn {\n+                    task::yield();\n+                    fail!();\n+                }\n+            }\n+        };\n+        assert!(result.is_err());\n+    }\n+}\n+\n+#[test] #[ignore(cfg(windows))]\n+fn test_indestructible() {\n+    use rt::test::{run_in_newsched_task, spawntask_try};\n+    do run_in_newsched_task {\n+        let result = do spawntask_try {\n+            let mut t = task();\n+            t.watched();\n+            t.supervised();\n+            t.indestructible();\n+            do t.spawn {\n+                let (p1, _c1) = stream::<()>();\n+                let (p2, c2) = stream::<()>();\n+                let (p3, c3) = stream::<()>();\n+                let mut t = task();\n+                t.unwatched();\n+                do t.spawn {\n+                    do (|| {\n+                        p1.recv(); // would deadlock if not killed\n+                    }).finally {\n+                        c2.send(());\n+                    };\n+                }\n+                let mut t = task();\n+                t.unwatched();\n+                do t.spawn {\n+                    p3.recv();\n+                    task::yield();\n+                    fail!();\n+                }\n+                c3.send(());\n+                p2.recv();\n+            }\n+        };\n+        assert!(result.is_ok());\n+    }\n+}"}, {"sha": "2150c0c5ac28dc39e39c2e6af2918ce9215df96d", "filename": "src/libstd/task/spawn.rs", "status": "modified", "additions": 294, "deletions": 228, "changes": 522, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Ftask%2Fspawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Ftask%2Fspawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fspawn.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -79,7 +79,7 @@ use cast;\n use cell::Cell;\n use container::MutableMap;\n use comm::{Chan, GenericChan};\n-use hashmap::HashSet;\n+use hashmap::{HashSet, HashSetConsumeIterator};\n use local_data;\n use task::local_data_priv::{local_get, local_set, OldHandle};\n use task::rt::rust_task;\n@@ -88,32 +88,67 @@ use task::{Failure, ManualThreads, PlatformThread, SchedOpts, SingleThreaded};\n use task::{Success, TaskOpts, TaskResult, ThreadPerTask};\n use task::{ExistingScheduler, SchedulerHandle};\n use task::unkillable;\n+use to_bytes::IterBytes;\n use uint;\n use util;\n use unstable::sync::{Exclusive, exclusive};\n+use rt::{OldTaskContext, TaskContext, SchedulerContext, GlobalContext, context};\n use rt::local::Local;\n use rt::task::Task;\n+use rt::kill::KillHandle;\n+use rt::sched::Scheduler;\n use iterator::IteratorUtil;\n \n #[cfg(test)] use task::default_task_opts;\n #[cfg(test)] use comm;\n #[cfg(test)] use task;\n \n-type TaskSet = HashSet<*rust_task>;\n-\n-fn new_taskset() -> TaskSet {\n-    HashSet::new()\n+// Transitionary.\n+#[deriving(Eq)]\n+enum TaskHandle {\n+    OldTask(*rust_task),\n+    NewTask(KillHandle),\n }\n-fn taskset_insert(tasks: &mut TaskSet, task: *rust_task) {\n-    let didnt_overwrite = tasks.insert(task);\n-    assert!(didnt_overwrite);\n+\n+impl Clone for TaskHandle {\n+    fn clone(&self) -> TaskHandle {\n+        match *self {\n+            OldTask(x) => OldTask(x),\n+            NewTask(ref x) => NewTask(x.clone()),\n+        }\n+    }\n }\n-fn taskset_remove(tasks: &mut TaskSet, task: *rust_task) {\n-    let was_present = tasks.remove(&task);\n-    assert!(was_present);\n+\n+impl IterBytes for TaskHandle {\n+    fn iter_bytes(&self, lsb0: bool, f: &fn(buf: &[u8]) -> bool) -> bool {\n+        match *self {\n+            OldTask(ref x) => x.iter_bytes(lsb0, f),\n+            NewTask(ref x) => x.iter_bytes(lsb0, f),\n+        }\n+    }\n }\n-pub fn taskset_each(tasks: &TaskSet, blk: &fn(v: *rust_task) -> bool) -> bool {\n-    tasks.iter().advance(|k| blk(*k))\n+\n+struct TaskSet(HashSet<TaskHandle>);\n+\n+impl TaskSet {\n+    #[inline]\n+    fn new() -> TaskSet {\n+        TaskSet(HashSet::new())\n+    }\n+    #[inline]\n+    fn insert(&mut self, task: TaskHandle) {\n+        let didnt_overwrite = (**self).insert(task);\n+        assert!(didnt_overwrite);\n+    }\n+    #[inline]\n+    fn remove(&mut self, task: &TaskHandle) {\n+        let was_present = (**self).remove(task);\n+        assert!(was_present);\n+    }\n+    #[inline]\n+    fn consume(self) -> HashSetConsumeIterator<TaskHandle> {\n+        (*self).consume()\n+    }\n }\n \n // One of these per group of linked-failure tasks.\n@@ -147,10 +182,9 @@ struct AncestorNode {\n     // circular references arise, deadlock and memory leaks are imminent).\n     // Hence we assert that this counter monotonically decreases as we\n     // approach the tail of the list.\n-    // FIXME(#3068): Make the generation counter togglable with #[cfg(debug)].\n     generation:     uint,\n-    // Should really be a non-option. This way appeases borrowck.\n-    parent_group:   Option<TaskGroupArc>,\n+    // Handle to the tasks in the group of the current generation.\n+    parent_group:   TaskGroupArc,\n     // Recursive rest of the list.\n     ancestors:      AncestorList,\n }\n@@ -173,39 +207,44 @@ fn access_ancestors<U>(x: &Exclusive<AncestorNode>,\n     }\n }\n \n+#[inline] #[cfg(test)]\n+fn check_generation(younger: uint, older: uint) { assert!(younger > older); }\n+#[inline] #[cfg(not(test))]\n+fn check_generation(_younger: uint, _older: uint) { }\n+\n+#[inline] #[cfg(test)]\n+fn incr_generation(ancestors: &AncestorList) -> uint {\n+    ancestors.map_default(0, |arc| access_ancestors(arc, |a| a.generation+1))\n+}\n+#[inline] #[cfg(not(test))]\n+fn incr_generation(_ancestors: &AncestorList) -> uint { 0 }\n+\n // Iterates over an ancestor list.\n // (1) Runs forward_blk on each ancestral taskgroup in the list\n // (2) If forward_blk \"break\"s, runs optional bail_blk on all ancestral\n //     taskgroups that forward_blk already ran on successfully (Note: bail_blk\n //     is NOT called on the block that forward_blk broke on!).\n // (3) As a bonus, coalesces away all 'dead' taskgroup nodes in the list.\n-// FIXME(#2190): Change Option<@fn(...)> to Option<&fn(...)>, to save on\n-// allocations. Once that bug is fixed, changing the sigil should suffice.\n fn each_ancestor(list:        &mut AncestorList,\n-                 bail_opt:    Option<@fn(TaskGroupInner)>,\n+                 bail_blk:    &fn(TaskGroupInner),\n                  forward_blk: &fn(TaskGroupInner) -> bool)\n               -> bool {\n     // \"Kickoff\" call - there was no last generation.\n-    return !coalesce(list, bail_opt, forward_blk, uint::max_value);\n+    return !coalesce(list, bail_blk, forward_blk, uint::max_value);\n \n     // Recursively iterates, and coalesces afterwards if needed. Returns\n     // whether or not unwinding is needed (i.e., !successful iteration).\n     fn coalesce(list:            &mut AncestorList,\n-                bail_opt:        Option<@fn(TaskGroupInner)>,\n+                bail_blk:        &fn(TaskGroupInner),\n                 forward_blk:     &fn(TaskGroupInner) -> bool,\n                 last_generation: uint) -> bool {\n-        // Need to swap the list out to use it, to appease borrowck.\n-        let tmp_list = util::replace(&mut *list, AncestorList(None));\n         let (coalesce_this, early_break) =\n-            iterate(&tmp_list, bail_opt, forward_blk, last_generation);\n+            iterate(list, bail_blk, forward_blk, last_generation);\n         // What should our next ancestor end up being?\n         if coalesce_this.is_some() {\n             // Needed coalesce. Our next ancestor becomes our old\n             // ancestor's next ancestor. (\"next = old_next->next;\")\n             *list = coalesce_this.unwrap();\n-        } else {\n-            // No coalesce; restore from tmp. (\"next = old_next;\")\n-            *list = tmp_list;\n         }\n         return early_break;\n     }\n@@ -218,8 +257,8 @@ fn each_ancestor(list:        &mut AncestorList,\n     // bool:\n     //     True if the supplied block did 'break', here or in any recursive\n     //     calls. If so, must call the unwinder on all previous nodes.\n-    fn iterate(ancestors:       &AncestorList,\n-               bail_opt:        Option<@fn(TaskGroupInner)>,\n+    fn iterate(ancestors:       &mut AncestorList,\n+               bail_blk:        &fn(TaskGroupInner),\n                forward_blk:     &fn(TaskGroupInner) -> bool,\n                last_generation: uint)\n             -> (Option<AncestorList>, bool) {\n@@ -236,28 +275,28 @@ fn each_ancestor(list:        &mut AncestorList,\n \n         // The map defaults to None, because if ancestors is None, we're at\n         // the end of the list, which doesn't make sense to coalesce.\n-        return do (**ancestors).map_default((None,false)) |ancestor_arc| {\n+        do ancestors.map_default((None,false)) |ancestor_arc| {\n             // NB: Takes a lock! (this ancestor node)\n             do access_ancestors(ancestor_arc) |nobe| {\n                 // Argh, but we couldn't give it to coalesce() otherwise.\n                 let forward_blk = forward_blk.take();\n                 // Check monotonicity\n-                assert!(last_generation > nobe.generation);\n+                check_generation(last_generation, nobe.generation);\n                 /*##########################################################*\n                  * Step 1: Look at this ancestor group (call iterator block).\n                  *##########################################################*/\n                 let mut nobe_is_dead = false;\n                 let do_continue =\n                     // NB: Takes a lock! (this ancestor node's parent group)\n-                    do with_parent_tg(&mut nobe.parent_group) |tg_opt| {\n+                    do access_group(&nobe.parent_group) |tg_opt| {\n                         // Decide whether this group is dead. Note that the\n                         // group being *dead* is disjoint from it *failing*.\n                         nobe_is_dead = match *tg_opt {\n                             Some(ref tg) => taskgroup_is_dead(tg),\n                             None => nobe_is_dead\n                         };\n                         // Call iterator block. (If the group is dead, it's\n-                        // safe to skip it. This will leave our *rust_task\n+                        // safe to skip it. This will leave our TaskHandle\n                         // hanging around in the group even after it's freed,\n                         // but that's ok because, by virtue of the group being\n                         // dead, nobody will ever kill-all (foreach) over it.)\n@@ -271,17 +310,15 @@ fn each_ancestor(list:        &mut AncestorList,\n                 let mut need_unwind = false;\n                 if do_continue {\n                     // NB: Takes many locks! (ancestor nodes & parent groups)\n-                    need_unwind = coalesce(&mut nobe.ancestors, bail_opt,\n+                    need_unwind = coalesce(&mut nobe.ancestors, |tg| bail_blk(tg),\n                                            forward_blk, nobe.generation);\n                 }\n                 /*##########################################################*\n                  * Step 3: Maybe unwind; compute return info for our caller.\n                  *##########################################################*/\n                 if need_unwind && !nobe_is_dead {\n-                    for bail_opt.iter().advance |bail_blk| {\n-                        do with_parent_tg(&mut nobe.parent_group) |tg_opt| {\n-                            (*bail_blk)(tg_opt)\n-                        }\n+                    do access_group(&nobe.parent_group) |tg_opt| {\n+                        bail_blk(tg_opt)\n                     }\n                 }\n                 // Decide whether our caller should unwind.\n@@ -296,23 +333,12 @@ fn each_ancestor(list:        &mut AncestorList,\n                     (None, need_unwind)\n                 }\n             }\n-        };\n-\n-        // Wrapper around exclusive::with that appeases borrowck.\n-        fn with_parent_tg<U>(parent_group: &mut Option<TaskGroupArc>,\n-                             blk: &fn(TaskGroupInner) -> U) -> U {\n-            // If this trips, more likely the problem is 'blk' failed inside.\n-            let tmp_arc = parent_group.take_unwrap();\n-            let result = do access_group(&tmp_arc) |tg_opt| { blk(tg_opt) };\n-            *parent_group = Some(tmp_arc);\n-            result\n         }\n     }\n }\n \n // One of these per task.\n-struct TCB {\n-    me:         *rust_task,\n+pub struct Taskgroup {\n     // List of tasks with whose fates this one's is intertwined.\n     tasks:      TaskGroupArc, // 'none' means the group has failed.\n     // Lists of tasks who will kill us if they fail, but whom we won't kill.\n@@ -321,50 +347,50 @@ struct TCB {\n     notifier:   Option<AutoNotify>,\n }\n \n-impl Drop for TCB {\n+impl Drop for Taskgroup {\n     // Runs on task exit.\n     fn drop(&self) {\n         unsafe {\n             // FIXME(#4330) Need self by value to get mutability.\n-            let this: &mut TCB = transmute(self);\n+            let this: &mut Taskgroup = transmute(self);\n \n             // If we are failing, the whole taskgroup needs to die.\n-            if rt::rust_task_is_unwinding(self.me) {\n-                for this.notifier.mut_iter().advance |x| {\n-                    x.failed = true;\n-                }\n-                // Take everybody down with us.\n-                do access_group(&self.tasks) |tg| {\n-                    kill_taskgroup(tg, self.me, self.is_main);\n-                }\n-            } else {\n-                // Remove ourselves from the group(s).\n-                do access_group(&self.tasks) |tg| {\n-                    leave_taskgroup(tg, self.me, true);\n+            do RuntimeGlue::with_task_handle_and_failing |me, failing| {\n+                if failing {\n+                    for this.notifier.mut_iter().advance |x| {\n+                        x.failed = true;\n+                    }\n+                    // Take everybody down with us.\n+                    do access_group(&self.tasks) |tg| {\n+                        kill_taskgroup(tg, &me, self.is_main);\n+                    }\n+                } else {\n+                    // Remove ourselves from the group(s).\n+                    do access_group(&self.tasks) |tg| {\n+                        leave_taskgroup(tg, &me, true);\n+                    }\n                 }\n+                // It doesn't matter whether this happens before or after dealing\n+                // with our own taskgroup, so long as both happen before we die.\n+                // We remove ourself from every ancestor we can, so no cleanup; no\n+                // break.\n+                for each_ancestor(&mut this.ancestors, |_| {}) |ancestor_group| {\n+                    leave_taskgroup(ancestor_group, &me, false);\n+                };\n             }\n-            // It doesn't matter whether this happens before or after dealing\n-            // with our own taskgroup, so long as both happen before we die.\n-            // We remove ourself from every ancestor we can, so no cleanup; no\n-            // break.\n-            for each_ancestor(&mut this.ancestors, None) |ancestor_group| {\n-                leave_taskgroup(ancestor_group, self.me, false);\n-            };\n         }\n     }\n }\n \n-fn TCB(me: *rust_task,\n-       tasks: TaskGroupArc,\n+pub fn Taskgroup(tasks: TaskGroupArc,\n        ancestors: AncestorList,\n        is_main: bool,\n-       mut notifier: Option<AutoNotify>) -> TCB {\n+       mut notifier: Option<AutoNotify>) -> Taskgroup {\n     for notifier.mut_iter().advance |x| {\n         x.failed = false;\n     }\n \n-    TCB {\n-        me: me,\n+    Taskgroup {\n         tasks: tasks,\n         ancestors: ancestors,\n         is_main: is_main,\n@@ -391,42 +417,36 @@ fn AutoNotify(chan: Chan<TaskResult>) -> AutoNotify {\n     }\n }\n \n-fn enlist_in_taskgroup(state: TaskGroupInner, me: *rust_task,\n+fn enlist_in_taskgroup(state: TaskGroupInner, me: TaskHandle,\n                            is_member: bool) -> bool {\n-    let newstate = util::replace(&mut *state, None);\n+    let me = Cell::new(me); // :(\n     // If 'None', the group was failing. Can't enlist.\n-    if newstate.is_some() {\n-        let mut group = newstate.unwrap();\n-        taskset_insert(if is_member {\n+    do state.map_mut_default(false) |group| {\n+        (if is_member {\n             &mut group.members\n         } else {\n             &mut group.descendants\n-        }, me);\n-        *state = Some(group);\n+        }).insert(me.take());\n         true\n-    } else {\n-        false\n     }\n }\n \n // NB: Runs in destructor/post-exit context. Can't 'fail'.\n-fn leave_taskgroup(state: TaskGroupInner, me: *rust_task,\n+fn leave_taskgroup(state: TaskGroupInner, me: &TaskHandle,\n                        is_member: bool) {\n-    let newstate = util::replace(&mut *state, None);\n+    let me = Cell::new(me); // :(\n     // If 'None', already failing and we've already gotten a kill signal.\n-    if newstate.is_some() {\n-        let mut group = newstate.unwrap();\n-        taskset_remove(if is_member {\n+    do state.map_mut |group| {\n+        (if is_member {\n             &mut group.members\n         } else {\n             &mut group.descendants\n-        }, me);\n-        *state = Some(group);\n-    }\n+        }).remove(me.take());\n+    };\n }\n \n // NB: Runs in destructor/post-exit context. Can't 'fail'.\n-fn kill_taskgroup(state: TaskGroupInner, me: *rust_task, is_main: bool) {\n+fn kill_taskgroup(state: TaskGroupInner, me: &TaskHandle, is_main: bool) {\n     unsafe {\n         // NB: We could do the killing iteration outside of the group arc, by\n         // having \"let mut newstate\" here, swapping inside, and iterating\n@@ -442,20 +462,21 @@ fn kill_taskgroup(state: TaskGroupInner, me: *rust_task, is_main: bool) {\n         // That's ok; only one task needs to do the dirty work. (Might also\n         // see 'None' if Somebody already failed and we got a kill signal.)\n         if newstate.is_some() {\n-            let group = newstate.unwrap();\n-            for taskset_each(&group.members) |sibling| {\n+            let TaskGroupData { members: members, descendants: descendants } =\n+                newstate.unwrap();\n+            for members.consume().advance |sibling| {\n                 // Skip self - killing ourself won't do much good.\n-                if sibling != me {\n-                    rt::rust_task_kill_other(sibling);\n+                if &sibling != me {\n+                    RuntimeGlue::kill_task(sibling);\n                 }\n             }\n-            for taskset_each(&group.descendants) |child| {\n-                assert!(child != me);\n-                rt::rust_task_kill_other(child);\n+            for descendants.consume().advance |child| {\n+                assert!(&child != me);\n+                RuntimeGlue::kill_task(child);\n             }\n             // Only one task should ever do this.\n             if is_main {\n-                rt::rust_task_kill_all(me);\n+                RuntimeGlue::kill_all_tasks(me);\n             }\n             // Do NOT restore state to Some(..)! It stays None to indicate\n             // that the whole taskgroup is failing, to forbid new spawns.\n@@ -467,112 +488,171 @@ fn kill_taskgroup(state: TaskGroupInner, me: *rust_task, is_main: bool) {\n // FIXME (#2912): Work around core-vs-coretest function duplication. Can't use\n // a proper closure because the #[test]s won't understand. Have to fake it.\n #[cfg(not(stage0))]\n-fn taskgroup_key() -> local_data::Key<@@mut TCB> {\n+fn taskgroup_key() -> local_data::Key<@@mut Taskgroup> {\n     unsafe { cast::transmute(-2) }\n }\n #[cfg(stage0)]\n-fn taskgroup_key() -> local_data::Key<@@mut TCB> {\n+fn taskgroup_key() -> local_data::Key<@@mut Taskgroup> {\n     unsafe { cast::transmute((-2, 0)) }\n }\n \n-fn gen_child_taskgroup(linked: bool, supervised: bool)\n-    -> (TaskGroupArc, AncestorList, bool) {\n-    unsafe {\n-        let spawner = rt::rust_get_task();\n-        /*##################################################################*\n-         * Step 1. Get spawner's taskgroup info.\n-         *##################################################################*/\n-        let spawner_group: @@mut TCB =\n-            do local_get(OldHandle(spawner), taskgroup_key()) |group| {\n-                match group {\n+// Transitionary.\n+struct RuntimeGlue;\n+impl RuntimeGlue {\n+    unsafe fn kill_task(task: TaskHandle) {\n+        match task {\n+            OldTask(ptr) => rt::rust_task_kill_other(ptr),\n+            NewTask(handle) => {\n+                let mut handle = handle;\n+                do handle.kill().map_consume |killed_task| {\n+                    let killed_task = Cell::new(killed_task);\n+                    do Local::borrow::<Scheduler, ()> |sched| {\n+                        sched.enqueue_task(killed_task.take());\n+                    }\n+                };\n+            }\n+        }\n+    }\n+\n+    unsafe fn kill_all_tasks(task: &TaskHandle) {\n+        match *task {\n+            OldTask(ptr) => rt::rust_task_kill_all(ptr),\n+            NewTask(ref _handle) => rtabort!(\"unimplemented\"), // FIXME(#7544)\n+        }\n+    }\n+\n+    fn with_task_handle_and_failing(blk: &fn(TaskHandle, bool)) {\n+        match context() {\n+            OldTaskContext => unsafe {\n+                let me = rt::rust_get_task();\n+                blk(OldTask(me), rt::rust_task_is_unwinding(me))\n+            },\n+            TaskContext => unsafe {\n+                // Can't use safe borrow, because the taskgroup destructor needs to\n+                // access the scheduler again to send kill signals to other tasks.\n+                let me = Local::unsafe_borrow::<Task>();\n+                // FIXME(#7544): Get rid of this clone by passing by-ref.\n+                // Will probably have to wait until the old rt is gone.\n+                blk(NewTask((*me).death.kill_handle.get_ref().clone()),\n+                    (*me).unwinder.unwinding)\n+            },\n+            SchedulerContext | GlobalContext => rtabort!(\"task dying in bad context\"),\n+        }\n+    }\n+\n+    fn with_my_taskgroup<U>(blk: &fn(&Taskgroup) -> U) -> U {\n+        match context() {\n+            OldTaskContext => unsafe {\n+                let me = rt::rust_get_task();\n+                do local_get(OldHandle(me), taskgroup_key()) |g| {\n+                    match g {\n+                        None => {\n+                            // Main task, doing first spawn ever. Lazily initialise here.\n+                            let mut members = TaskSet::new();\n+                            members.insert(OldTask(me));\n+                            let tasks = exclusive(Some(TaskGroupData {\n+                                members: members,\n+                                descendants: TaskSet::new(),\n+                            }));\n+                            // Main task/group has no ancestors, no notifier, etc.\n+                            let group = @@mut Taskgroup(tasks, AncestorList(None),\n+                                                        true, None);\n+                            local_set(OldHandle(me), taskgroup_key(), group);\n+                            blk(&**group)\n+                        }\n+                        Some(&group) => blk(&**group)\n+                    }\n+                }\n+            },\n+            TaskContext => unsafe {\n+                // Can't use safe borrow, because creating new hashmaps for the\n+                // tasksets requires an rng, which needs to borrow the sched.\n+                let me = Local::unsafe_borrow::<Task>();\n+                blk(match (*me).taskgroup {\n                     None => {\n-                        // Main task, doing first spawn ever. Lazily initialise\n-                        // here.\n-                        let mut members = new_taskset();\n-                        taskset_insert(&mut members, spawner);\n+                        // Main task, doing first spawn ever. Lazily initialize.\n+                        let mut members = TaskSet::new();\n+                        let my_handle = (*me).death.kill_handle.get_ref().clone();\n+                        members.insert(NewTask(my_handle));\n                         let tasks = exclusive(Some(TaskGroupData {\n                             members: members,\n-                            descendants: new_taskset(),\n+                            descendants: TaskSet::new(),\n                         }));\n-                        // Main task/group has no ancestors, no notifier, etc.\n-                        let group = @@mut TCB(spawner,\n-                                              tasks,\n-                                              AncestorList(None),\n-                                              true,\n-                                              None);\n-                        local_set(OldHandle(spawner), taskgroup_key(), group);\n-                        group\n+                        let group = Taskgroup(tasks, AncestorList(None), true, None);\n+                        (*me).taskgroup = Some(group);\n+                        (*me).taskgroup.get_ref()\n                     }\n-                    Some(&group) => group\n-                }\n-            };\n-        let spawner_group: &mut TCB = *spawner_group;\n+                    Some(ref group) => group,\n+                })\n+            },\n+            SchedulerContext | GlobalContext => rtabort!(\"spawning in bad context\"),\n+        }\n+    }\n+}\n \n-        /*##################################################################*\n-         * Step 2. Process spawn options for child.\n-         *##################################################################*/\n-        return if linked {\n+fn gen_child_taskgroup(linked: bool, supervised: bool)\n+    -> (TaskGroupArc, AncestorList, bool) {\n+    do RuntimeGlue::with_my_taskgroup |spawner_group| {\n+        let ancestors = AncestorList(spawner_group.ancestors.map(|x| x.clone()));\n+        if linked {\n             // Child is in the same group as spawner.\n-            let g = spawner_group.tasks.clone();\n             // Child's ancestors are spawner's ancestors.\n-            let a = share_ancestors(&mut spawner_group.ancestors);\n             // Propagate main-ness.\n-            (g, a, spawner_group.is_main)\n+            (spawner_group.tasks.clone(), ancestors, spawner_group.is_main)\n         } else {\n             // Child is in a separate group from spawner.\n             let g = exclusive(Some(TaskGroupData {\n-                members:     new_taskset(),\n-                descendants: new_taskset(),\n+                members:     TaskSet::new(),\n+                descendants: TaskSet::new(),\n             }));\n             let a = if supervised {\n-                // Child's ancestors start with the spawner.\n-                let old_ancestors =\n-                    share_ancestors(&mut spawner_group.ancestors);\n-                // FIXME(#3068) - The generation counter is only used for a\n-                // debug assertion, but initialising it requires locking a\n-                // mutex. Hence it should be enabled only in debug builds.\n-                let new_generation =\n-                    match *old_ancestors {\n-                        Some(ref arc) => {\n-                            access_ancestors(arc, |a| a.generation+1)\n-                        }\n-                        None => 0 // the actual value doesn't really matter.\n-                    };\n+                let new_generation = incr_generation(&ancestors);\n                 assert!(new_generation < uint::max_value);\n+                // Child's ancestors start with the spawner.\n                 // Build a new node in the ancestor list.\n                 AncestorList(Some(exclusive(AncestorNode {\n                     generation: new_generation,\n-                    parent_group: Some(spawner_group.tasks.clone()),\n-                    ancestors: old_ancestors,\n+                    parent_group: spawner_group.tasks.clone(),\n+                    ancestors: ancestors,\n                 })))\n             } else {\n                 // Child has no ancestors.\n                 AncestorList(None)\n             };\n             (g, a, false)\n-        };\n+        }\n     }\n+}\n \n-    fn share_ancestors(ancestors: &mut AncestorList) -> AncestorList {\n-        // Appease the borrow-checker. Really this wants to be written as:\n-        // match ancestors\n-        //    Some(ancestor_arc) { ancestor_list(Some(ancestor_arc.clone())) }\n-        //    None               { ancestor_list(None) }\n-        let tmp = util::replace(&mut **ancestors, None);\n-        if tmp.is_some() {\n-            let ancestor_arc = tmp.unwrap();\n-            let result = ancestor_arc.clone();\n-            **ancestors = Some(ancestor_arc);\n-            AncestorList(Some(result))\n-        } else {\n-            AncestorList(None)\n+// Set up membership in taskgroup and descendantship in all ancestor\n+// groups. If any enlistment fails, Some task was already failing, so\n+// don't let the child task run, and undo every successful enlistment.\n+fn enlist_many(child: TaskHandle, child_arc: &TaskGroupArc,\n+               ancestors: &mut AncestorList) -> bool {\n+    // Join this taskgroup.\n+    let mut result = do access_group(child_arc) |child_tg| {\n+        enlist_in_taskgroup(child_tg, child.clone(), true) // member\n+    };\n+    if result {\n+        // Unwinding function in case any ancestral enlisting fails\n+        let bail: &fn(TaskGroupInner) = |tg| { leave_taskgroup(tg, &child, false) };\n+        // Attempt to join every ancestor group.\n+        result = do each_ancestor(ancestors, bail) |ancestor_tg| {\n+            // Enlist as a descendant, not as an actual member.\n+            // Descendants don't kill ancestor groups on failure.\n+            enlist_in_taskgroup(ancestor_tg, child.clone(), false)\n+        };\n+        // If any ancestor group fails, need to exit this group too.\n+        if !result {\n+            do access_group(child_arc) |child_tg| {\n+                leave_taskgroup(child_tg, &child, true); // member\n+            }\n         }\n     }\n+    result\n }\n \n pub fn spawn_raw(opts: TaskOpts, f: ~fn()) {\n-    use rt::*;\n-\n     match context() {\n         OldTaskContext => {\n             spawn_raw_oldsched(opts, f)\n@@ -590,21 +670,49 @@ pub fn spawn_raw(opts: TaskOpts, f: ~fn()) {\n }\n \n fn spawn_raw_newsched(mut opts: TaskOpts, f: ~fn()) {\n-    use rt::sched::*;\n-\n-    let f = Cell::new(f);\n+    let child_data = Cell::new(gen_child_taskgroup(opts.linked, opts.supervised));\n+    let indestructible = opts.indestructible;\n+\n+    let child_wrapper: ~fn() = || {\n+        // Child task runs this code.\n+        let child_data = Cell::new(child_data.take()); // :(\n+        let enlist_success = do Local::borrow::<Task, bool> |me| {\n+            let (child_tg, ancestors, is_main) = child_data.take();\n+            let mut ancestors = ancestors;\n+            // FIXME(#7544): Optimize out the xadd in this clone, somehow.\n+            let handle = me.death.kill_handle.get_ref().clone();\n+            // Atomically try to get into all of our taskgroups.\n+            if enlist_many(NewTask(handle), &child_tg, &mut ancestors) {\n+                // Got in. We can run the provided child body, and can also run\n+                // the taskgroup's exit-time-destructor afterward.\n+                me.taskgroup = Some(Taskgroup(child_tg, ancestors, is_main, None));\n+                true\n+            } else {\n+                false\n+            }\n+        };\n+        // Should be run after the local-borrowed task is returned.\n+        if enlist_success {\n+            if indestructible {\n+                unsafe { do unkillable { f() } }\n+            } else {\n+                f()\n+            }\n+        }\n+    };\n \n     let mut task = unsafe {\n         let sched = Local::unsafe_borrow::<Scheduler>();\n         rtdebug!(\"unsafe borrowed sched\");\n \n-        if opts.linked {\n+        if opts.watched {\n+            let child_wrapper = Cell::new(child_wrapper);\n             do Local::borrow::<Task, ~Task>() |running_task| {\n-                ~running_task.new_child(&mut (*sched).stack_pool, f.take())\n+                ~running_task.new_child(&mut (*sched).stack_pool, child_wrapper.take())\n             }\n         } else {\n-            // An unlinked task is a new root in the task tree\n-            ~Task::new_root(&mut (*sched).stack_pool, f.take())\n+            // An unwatched task is a new root in the exit-code propagation tree\n+            ~Task::new_root(&mut (*sched).stack_pool, child_wrapper)\n         }\n     };\n \n@@ -616,7 +724,7 @@ fn spawn_raw_newsched(mut opts: TaskOpts, f: ~fn()) {\n                 if success { Success } else { Failure }\n             )\n         };\n-        task.on_exit = Some(on_exit);\n+        task.death.on_exit = Some(on_exit);\n     }\n \n     rtdebug!(\"spawn about to take scheduler\");\n@@ -635,23 +743,16 @@ fn spawn_raw_oldsched(mut opts: TaskOpts, f: ~fn()) {\n         let child_data = Cell::new((child_tg, ancestors, f));\n         // Being killed with the unsafe task/closure pointers would leak them.\n         do unkillable {\n-            // Agh. Get move-mode items into the closure. FIXME (#2829)\n-            let (child_tg, ancestors, f) = child_data.take();\n+            let (child_tg, ancestors, f) = child_data.take(); // :(\n             // Create child task.\n             let new_task = match opts.sched.mode {\n                 DefaultScheduler => rt::new_task(),\n                 _ => new_task_in_sched(opts.sched)\n             };\n             assert!(!new_task.is_null());\n             // Getting killed after here would leak the task.\n-            let notify_chan = if opts.notify_chan.is_none() {\n-                None\n-            } else {\n-                Some(opts.notify_chan.take_unwrap())\n-            };\n-\n             let child_wrapper = make_child_wrapper(new_task, child_tg,\n-                  ancestors, is_main, notify_chan, f);\n+                  ancestors, is_main, opts.notify_chan.take(), f);\n \n             let closure = cast::transmute(&child_wrapper);\n \n@@ -676,8 +777,7 @@ fn spawn_raw_oldsched(mut opts: TaskOpts, f: ~fn()) {\n                        -> ~fn() {\n         let child_data = Cell::new((notify_chan, child_arc, ancestors));\n         let result: ~fn() = || {\n-            // Agh. Get move-mode items into the closure. FIXME (#2829)\n-            let (notify_chan, child_arc, ancestors) = child_data.take();\n+            let (notify_chan, child_arc, ancestors) = child_data.take(); // :(\n             let mut ancestors = ancestors;\n             // Child task runs this code.\n \n@@ -686,12 +786,8 @@ fn spawn_raw_oldsched(mut opts: TaskOpts, f: ~fn()) {\n \n             let notifier = notify_chan.map_consume(|c| AutoNotify(c));\n \n-            if enlist_many(child, &child_arc, &mut ancestors) {\n-                let group = @@mut TCB(child,\n-                                      child_arc,\n-                                      ancestors,\n-                                      is_main,\n-                                      notifier);\n+            if enlist_many(OldTask(child), &child_arc, &mut ancestors) {\n+                let group = @@mut Taskgroup(child_arc, ancestors, is_main, notifier);\n                 unsafe {\n                     local_set(OldHandle(child), taskgroup_key(), group);\n                 }\n@@ -707,38 +803,6 @@ fn spawn_raw_oldsched(mut opts: TaskOpts, f: ~fn()) {\n             // unsafe { cleanup::annihilate(); }\n         };\n         return result;\n-\n-        // Set up membership in taskgroup and descendantship in all ancestor\n-        // groups. If any enlistment fails, Some task was already failing, so\n-        // don't let the child task run, and undo every successful enlistment.\n-        fn enlist_many(child: *rust_task, child_arc: &TaskGroupArc,\n-                       ancestors: &mut AncestorList) -> bool {\n-            // Join this taskgroup.\n-            let mut result =\n-                do access_group(child_arc) |child_tg| {\n-                    enlist_in_taskgroup(child_tg, child, true) // member\n-                };\n-            if result {\n-                // Unwinding function in case any ancestral enlisting fails\n-                let bail: @fn(TaskGroupInner) = |tg| {\n-                    leave_taskgroup(tg, child, false)\n-                };\n-                // Attempt to join every ancestor group.\n-                result =\n-                    each_ancestor(ancestors, Some(bail), |ancestor_tg| {\n-                        // Enlist as a descendant, not as an actual member.\n-                        // Descendants don't kill ancestor groups on failure.\n-                        enlist_in_taskgroup(ancestor_tg, child, false)\n-                    });\n-                // If any ancestor group fails, need to exit this group too.\n-                if !result {\n-                    do access_group(child_arc) |child_tg| {\n-                        leave_taskgroup(child_tg, child, true); // member\n-                    }\n-                }\n-            }\n-            result\n-        }\n     }\n \n     fn new_task_in_sched(opts: SchedOpts) -> *rust_task {\n@@ -789,6 +853,7 @@ fn test_spawn_raw_simple() {\n fn test_spawn_raw_unsupervise() {\n     let opts = task::TaskOpts {\n         linked: false,\n+        watched: false,\n         notify_chan: None,\n         .. default_task_opts()\n     };\n@@ -819,6 +884,7 @@ fn test_spawn_raw_notify_failure() {\n \n     let opts = task::TaskOpts {\n         linked: false,\n+        watched: false,\n         notify_chan: Some(notify_ch),\n         .. default_task_opts()\n     };"}, {"sha": "dbb9c83ea39546b01d293e819c8af2102150c9df", "filename": "src/libstd/unstable/atomics.rs", "status": "modified", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Funstable%2Fatomics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Funstable%2Fatomics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Fatomics.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -272,6 +272,30 @@ impl<T> AtomicOption<T> {\n             self.swap(cast::transmute(0), order)\n         }\n     }\n+\n+    /// A compare-and-swap. Succeeds if the option is 'None' and returns 'None'\n+    /// if so. If the option was already 'Some', returns 'Some' of the rejected\n+    /// value.\n+    #[inline]\n+    pub fn fill(&mut self, val: ~T, order: Ordering) -> Option<~T> {\n+        unsafe {\n+            let val = cast::transmute(val);\n+            let expected = cast::transmute(0);\n+            let oldval = atomic_compare_and_swap(&mut self.p, expected, val, order);\n+            if oldval == expected {\n+                None\n+            } else {\n+                Some(cast::transmute(val))\n+            }\n+        }\n+    }\n+\n+    /// Be careful: The caller must have some external method of ensuring the\n+    /// result does not get invalidated by another task after this returns.\n+    #[inline]\n+    pub fn is_empty(&mut self, order: Ordering) -> bool {\n+        unsafe { atomic_load(&self.p, order) == cast::transmute(0) }\n+    }\n }\n \n #[unsafe_destructor]\n@@ -374,6 +398,11 @@ mod test {\n         assert!(!flg.test_and_set(SeqCst));\n     }\n \n+    #[test]\n+    fn option_empty() {\n+        assert!(AtomicOption::empty::<()>().is_empty(SeqCst));\n+    }\n+\n     #[test]\n     fn option_swap() {\n         let mut p = AtomicOption::new(~1);\n@@ -398,4 +427,13 @@ mod test {\n         assert_eq!(p.take(SeqCst), Some(~2));\n     }\n \n+    #[test]\n+    fn option_fill() {\n+        let mut p = AtomicOption::new(~1);\n+        assert!(p.fill(~2, SeqCst).is_some()); // should fail; shouldn't leak!\n+        assert_eq!(p.take(SeqCst), Some(~1));\n+\n+        assert!(p.fill(~2, SeqCst).is_none()); // shouldn't fail\n+        assert_eq!(p.take(SeqCst), Some(~2));\n+    }\n }"}, {"sha": "d4de402a33e52f3775654ebfa1d6b98d8dd2f594", "filename": "src/libstd/unstable/sync.rs", "status": "modified", "additions": 287, "deletions": 85, "changes": 372, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Funstable%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Funstable%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Fsync.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -9,12 +9,16 @@\n // except according to those terms.\n \n use cast;\n+use cell::Cell;\n+use comm;\n use libc;\n+use ptr;\n use option::*;\n+use either::{Either, Left, Right};\n use task;\n use task::atomically;\n+use unstable::atomics::{AtomicOption,AtomicUint,Acquire,Release,SeqCst};\n use unstable::finally::Finally;\n-use unstable::intrinsics;\n use ops::Drop;\n use clone::Clone;\n use kinds::Send;\n@@ -27,24 +31,44 @@ pub struct UnsafeAtomicRcBox<T> {\n }\n \n struct AtomicRcBoxData<T> {\n-    count: int,\n+    count: AtomicUint,\n+    // An unwrapper uses this protocol to communicate with the \"other\" task that\n+    // drops the last refcount on an arc. Unfortunately this can't be a proper\n+    // pipe protocol because the unwrapper has to access both stages at once.\n+    // FIXME(#7544): Maybe use AtomicPtr instead (to avoid xchg in take() later)?\n+    unwrapper: AtomicOption<(comm::ChanOne<()>, comm::PortOne<bool>)>,\n+    // FIXME(#3224) should be able to make this non-option to save memory\n     data: Option<T>,\n }\n \n impl<T: Send> UnsafeAtomicRcBox<T> {\n     pub fn new(data: T) -> UnsafeAtomicRcBox<T> {\n         unsafe {\n-            let data = ~AtomicRcBoxData { count: 1, data: Some(data) };\n+            let data = ~AtomicRcBoxData { count: AtomicUint::new(1),\n+                                          unwrapper: AtomicOption::empty(),\n+                                          data: Some(data) };\n             let ptr = cast::transmute(data);\n             return UnsafeAtomicRcBox { data: ptr };\n         }\n     }\n \n+    /// As new(), but returns an extra pre-cloned handle.\n+    pub fn new2(data: T) -> (UnsafeAtomicRcBox<T>, UnsafeAtomicRcBox<T>) {\n+        unsafe {\n+            let data = ~AtomicRcBoxData { count: AtomicUint::new(2),\n+                                          unwrapper: AtomicOption::empty(),\n+                                          data: Some(data) };\n+            let ptr = cast::transmute(data);\n+            return (UnsafeAtomicRcBox { data: ptr },\n+                    UnsafeAtomicRcBox { data: ptr });\n+        }\n+    }\n+\n     #[inline]\n     pub unsafe fn get(&self) -> *mut T\n     {\n         let mut data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n-        assert!(data.count > 0);\n+        assert!(data.count.load(Acquire) > 0); // no barrier is really needed\n         let r: *mut T = data.data.get_mut_ref();\n         cast::forget(data);\n         return r;\n@@ -53,20 +77,113 @@ impl<T: Send> UnsafeAtomicRcBox<T> {\n     #[inline]\n     pub unsafe fn get_immut(&self) -> *T\n     {\n-        let mut data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n-        assert!(data.count > 0);\n-        let r: *T = cast::transmute_immut(data.data.get_mut_ref());\n+        let data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n+        assert!(data.count.load(Acquire) > 0); // no barrier is really needed\n+        let r: *T = data.data.get_ref();\n         cast::forget(data);\n         return r;\n     }\n+\n+    /// Wait until all other handles are dropped, then retrieve the enclosed\n+    /// data. See extra::arc::ARC for specific semantics documentation.\n+    /// If called when the task is already unkillable, unwrap will unkillably\n+    /// block; otherwise, an unwrapping task can be killed by linked failure.\n+    pub unsafe fn unwrap(self) -> T {\n+        let this = Cell::new(self); // argh\n+        do task::unkillable {\n+            let mut this = this.take();\n+            let mut data: ~AtomicRcBoxData<T> = cast::transmute(this.data);\n+            // Set up the unwrap protocol.\n+            let (p1,c1) = comm::oneshot(); // ()\n+            let (p2,c2) = comm::oneshot(); // bool\n+            // Try to put our server end in the unwrapper slot.\n+            // This needs no barrier -- it's protected by the release barrier on\n+            // the xadd, and the acquire+release barrier in the destructor's xadd.\n+            // FIXME(#6598) Change Acquire to Relaxed.\n+            if data.unwrapper.fill(~(c1,p2), Acquire).is_none() {\n+                // Got in. Tell this handle's destructor not to run (we are now it).\n+                this.data = ptr::mut_null();\n+                // Drop our own reference.\n+                let old_count = data.count.fetch_sub(1, Release);\n+                assert!(old_count >= 1);\n+                if old_count == 1 {\n+                    // We were the last owner. Can unwrap immediately.\n+                    // AtomicOption's destructor will free the server endpoint.\n+                    // FIXME(#3224): it should be like this\n+                    // let ~AtomicRcBoxData { data: user_data, _ } = data;\n+                    // user_data\n+                    data.data.take_unwrap()\n+                } else {\n+                    // The *next* person who sees the refcount hit 0 will wake us.\n+                    let p1 = Cell::new(p1); // argh\n+                    // Unlike the above one, this cell is necessary. It will get\n+                    // taken either in the do block or in the finally block.\n+                    let c2_and_data = Cell::new((c2,data));\n+                    do (|| {\n+                        do task::rekillable { p1.take().recv(); }\n+                        // Got here. Back in the 'unkillable' without getting killed.\n+                        let (c2, data) = c2_and_data.take();\n+                        c2.send(true);\n+                        // FIXME(#3224): it should be like this\n+                        // let ~AtomicRcBoxData { data: user_data, _ } = data;\n+                        // user_data\n+                        let mut data = data;\n+                        data.data.take_unwrap()\n+                    }).finally {\n+                        if task::failing() {\n+                            // Killed during wait. Because this might happen while\n+                            // someone else still holds a reference, we can't free\n+                            // the data now; the \"other\" last refcount will free it.\n+                            let (c2, data) = c2_and_data.take();\n+                            c2.send(false);\n+                            cast::forget(data);\n+                        } else {\n+                            assert!(c2_and_data.is_empty());\n+                        }\n+                    }\n+                }\n+            } else {\n+                // If 'put' returns the server end back to us, we were rejected;\n+                // someone else was trying to unwrap. Avoid guaranteed deadlock.\n+                cast::forget(data);\n+                fail!(\"Another task is already unwrapping this ARC!\");\n+            }\n+        }\n+    }\n+\n+    /// As unwrap above, but without blocking. Returns 'Left(self)' if this is\n+    /// not the last reference; 'Right(unwrapped_data)' if so.\n+    pub unsafe fn try_unwrap(self) -> Either<UnsafeAtomicRcBox<T>, T> {\n+        let mut this = self; // FIXME(#4330) mutable self\n+        let mut data: ~AtomicRcBoxData<T> = cast::transmute(this.data);\n+        // This can of course race with anybody else who has a handle, but in\n+        // such a case, the returned count will always be at least 2. If we\n+        // see 1, no race was possible. All that matters is 1 or not-1.\n+        let count = data.count.load(Acquire);\n+        assert!(count >= 1);\n+        // The more interesting race is one with an unwrapper. They may have\n+        // already dropped their count -- but if so, the unwrapper pointer\n+        // will have been set first, which the barriers ensure we will see.\n+        // (Note: using is_empty(), not take(), to not free the unwrapper.)\n+        if count == 1 && data.unwrapper.is_empty(Acquire) {\n+            // Tell this handle's destructor not to run (we are now it).\n+            this.data = ptr::mut_null();\n+            // FIXME(#3224) as above\n+            Right(data.data.take_unwrap())\n+        } else {\n+            cast::forget(data);\n+            Left(this)\n+        }\n+    }\n }\n \n impl<T: Send> Clone for UnsafeAtomicRcBox<T> {\n     fn clone(&self) -> UnsafeAtomicRcBox<T> {\n         unsafe {\n             let mut data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n-            let new_count = intrinsics::atomic_xadd(&mut data.count, 1) + 1;\n-            assert!(new_count >= 2);\n+            // This barrier might be unnecessary, but I'm not sure...\n+            let old_count = data.count.fetch_add(1, Acquire);\n+            assert!(old_count >= 1);\n             cast::forget(data);\n             return UnsafeAtomicRcBox { data: self.data };\n         }\n@@ -77,12 +194,37 @@ impl<T: Send> Clone for UnsafeAtomicRcBox<T> {\n impl<T> Drop for UnsafeAtomicRcBox<T>{\n     fn drop(&self) {\n         unsafe {\n+            if self.data.is_null() {\n+                return; // Happens when destructing an unwrapper's handle.\n+            }\n             do task::unkillable {\n                 let mut data: ~AtomicRcBoxData<T> = cast::transmute(self.data);\n-                let new_count = intrinsics::atomic_xsub(&mut data.count, 1) - 1;\n-                assert!(new_count >= 0);\n-                if new_count == 0 {\n-                    // drop glue takes over.\n+                // Must be acquire+release, not just release, to make sure this\n+                // doesn't get reordered to after the unwrapper pointer load.\n+                let old_count = data.count.fetch_sub(1, SeqCst);\n+                assert!(old_count >= 1);\n+                if old_count == 1 {\n+                    // Were we really last, or should we hand off to an\n+                    // unwrapper? It's safe to not xchg because the unwrapper\n+                    // will set the unwrap lock *before* dropping his/her\n+                    // reference. In effect, being here means we're the only\n+                    // *awake* task with the data.\n+                    match data.unwrapper.take(Acquire) {\n+                        Some(~(message,response)) => {\n+                            // Send 'ready' and wait for a response.\n+                            message.send(());\n+                            // Unkillable wait. Message guaranteed to come.\n+                            if response.recv() {\n+                                // Other task got the data.\n+                                cast::forget(data);\n+                            } else {\n+                                // Other task was killed. drop glue takes over.\n+                            }\n+                        }\n+                        None => {\n+                            // drop glue takes over.\n+                        }\n+                    }\n                 } else {\n                     cast::forget(data);\n                 }\n@@ -95,9 +237,9 @@ impl<T> Drop for UnsafeAtomicRcBox<T>{\n /****************************************************************************/\n \n #[allow(non_camel_case_types)] // runtime type\n-pub type rust_little_lock = *libc::c_void;\n+type rust_little_lock = *libc::c_void;\n \n-struct LittleLock {\n+pub struct LittleLock {\n     l: rust_little_lock,\n }\n \n@@ -109,7 +251,7 @@ impl Drop for LittleLock {\n     }\n }\n \n-fn LittleLock() -> LittleLock {\n+pub fn LittleLock() -> LittleLock {\n     unsafe {\n         LittleLock {\n             l: rust_create_little_lock()\n@@ -139,6 +281,13 @@ struct ExData<T> {\n \n /**\n  * An arc over mutable data that is protected by a lock. For library use only.\n+ *\n+ * # Safety note\n+ *\n+ * This uses a pthread mutex, not one that's aware of the userspace scheduler.\n+ * The user of an exclusive must be careful not to invoke any functions that may\n+ * reschedule the task while holding the lock, or deadlock may result. If you\n+ * need to block or yield while accessing shared state, use extra::sync::RWARC.\n  */\n pub struct Exclusive<T> {\n     x: UnsafeAtomicRcBox<ExData<T>>\n@@ -189,12 +338,13 @@ impl<T:Send> Exclusive<T> {\n             f(cast::transmute_immut(x))\n         }\n     }\n-}\n \n-fn compare_and_swap(address: &mut int, oldval: int, newval: int) -> bool {\n-    unsafe {\n-        let old = intrinsics::atomic_cxchg(address, oldval, newval);\n-        old == oldval\n+    pub fn unwrap(self) -> T {\n+        let Exclusive { x: x } = self;\n+        // Someday we might need to unkillably unwrap an exclusive, but not today.\n+        let inner = unsafe { x.unwrap() };\n+        let ExData { data: user_data, _ } = inner; // will destroy the LittleLock\n+        user_data\n     }\n }\n \n@@ -205,57 +355,15 @@ extern {\n     fn rust_unlock_little_lock(lock: rust_little_lock);\n }\n \n-/* *********************************************************************/\n-\n-//FIXME: #5042 This should be replaced by proper atomic type\n-pub struct AtomicUint {\n-    priv inner: uint\n-}\n-\n-impl AtomicUint {\n-    pub fn new(val: uint) -> AtomicUint { AtomicUint { inner: val } }\n-    pub fn load(&self) -> uint {\n-        unsafe { intrinsics::atomic_load(cast::transmute(self)) as uint }\n-    }\n-    pub fn store(&mut self, val: uint) {\n-        unsafe { intrinsics::atomic_store(cast::transmute(self), val as int); }\n-    }\n-    pub fn add(&mut self, val: int) -> uint {\n-        unsafe { intrinsics::atomic_xadd(cast::transmute(self), val as int) as uint }\n-    }\n-    pub fn cas(&mut self, old:uint, new: uint) -> uint {\n-        unsafe { intrinsics::atomic_cxchg(cast::transmute(self), old as int, new as int) as uint }\n-    }\n-}\n-\n-pub struct AtomicInt {\n-    priv inner: int\n-}\n-\n-impl AtomicInt {\n-    pub fn new(val: int) -> AtomicInt { AtomicInt { inner: val } }\n-    pub fn load(&self) -> int {\n-        unsafe { intrinsics::atomic_load(&self.inner) }\n-    }\n-    pub fn store(&mut self, val: int) {\n-        unsafe { intrinsics::atomic_store(&mut self.inner, val); }\n-    }\n-    pub fn add(&mut self, val: int) -> int {\n-        unsafe { intrinsics::atomic_xadd(&mut self.inner, val) }\n-    }\n-    pub fn cas(&mut self, old: int, new: int) -> int {\n-        unsafe { intrinsics::atomic_cxchg(&mut self.inner, old, new) }\n-    }\n-}\n-\n-\n #[cfg(test)]\n mod tests {\n-    use super::*;\n+    use cell::Cell;\n     use comm;\n-    use super::exclusive;\n+    use option::*;\n+    use super::{exclusive, UnsafeAtomicRcBox};\n     use task;\n     use uint;\n+    use util;\n \n     #[test]\n     fn exclusive_arc() {\n@@ -309,26 +417,120 @@ mod tests {\n     }\n \n     #[test]\n-    fn atomic_int_smoke_test() {\n-        let mut i = AtomicInt::new(0);\n-        i.store(10);\n-        assert!(i.load() == 10);\n-        assert!(i.add(1) == 10);\n-        assert!(i.load() == 11);\n-        assert!(i.cas(11, 12) == 11);\n-        assert!(i.cas(11, 13) == 12);\n-        assert!(i.load() == 12);\n+    fn arclike_unwrap_basic() {\n+        unsafe {\n+            let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+            assert!(x.unwrap() == ~~\"hello\");\n+        }\n     }\n \n     #[test]\n-    fn atomic_uint_smoke_test() {\n-        let mut i = AtomicUint::new(0);\n-        i.store(10);\n-        assert!(i.load() == 10);\n-        assert!(i.add(1) == 10);\n-        assert!(i.load() == 11);\n-        assert!(i.cas(11, 12) == 11);\n-        assert!(i.cas(11, 13) == 12);\n-        assert!(i.load() == 12);\n+    fn arclike_try_unwrap() {\n+        unsafe {\n+            let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+            assert!(x.try_unwrap().expect_right(\"try_unwrap failed\") == ~~\"hello\");\n+        }\n+    }\n+\n+    #[test]\n+    fn arclike_try_unwrap_fail() {\n+        unsafe {\n+            let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+            let x2 = x.clone();\n+            let left_x = x.try_unwrap();\n+            assert!(left_x.is_left());\n+            util::ignore(left_x);\n+            assert!(x2.try_unwrap().expect_right(\"try_unwrap none\") == ~~\"hello\");\n+        }\n+    }\n+\n+    #[test]\n+    fn arclike_try_unwrap_unwrap_race() {\n+        // When an unwrap and a try_unwrap race, the unwrapper should always win.\n+        unsafe {\n+            let x = UnsafeAtomicRcBox::new(~~\"hello\");\n+            let x2 = Cell::new(x.clone());\n+            let (p,c) = comm::stream();\n+            do task::spawn {\n+                c.send(());\n+                assert!(x2.take().unwrap() == ~~\"hello\");\n+                c.send(());\n+            }\n+            p.recv();\n+            task::yield(); // Try to make the unwrapper get blocked first.\n+            let left_x = x.try_unwrap();\n+            assert!(left_x.is_left());\n+            util::ignore(left_x);\n+            p.recv();\n+        }\n+    }\n+\n+    #[test]\n+    fn exclusive_unwrap_basic() {\n+        // Unlike the above, also tests no double-freeing of the LittleLock.\n+        let x = exclusive(~~\"hello\");\n+        assert!(x.unwrap() == ~~\"hello\");\n+    }\n+\n+    #[test]\n+    fn exclusive_unwrap_contended() {\n+        let x = exclusive(~~\"hello\");\n+        let x2 = Cell::new(x.clone());\n+        do task::spawn {\n+            let x2 = x2.take();\n+            unsafe { do x2.with |_hello| { } }\n+            task::yield();\n+        }\n+        assert!(x.unwrap() == ~~\"hello\");\n+\n+        // Now try the same thing, but with the child task blocking.\n+        let x = exclusive(~~\"hello\");\n+        let x2 = Cell::new(x.clone());\n+        let mut res = None;\n+        let mut builder = task::task();\n+        builder.future_result(|r| res = Some(r));\n+        do builder.spawn {\n+            let x2 = x2.take();\n+            assert!(x2.unwrap() == ~~\"hello\");\n+        }\n+        // Have to get rid of our reference before blocking.\n+        util::ignore(x);\n+        res.unwrap().recv();\n+    }\n+\n+    #[test] #[should_fail] #[ignore(cfg(windows))]\n+    fn exclusive_unwrap_conflict() {\n+        let x = exclusive(~~\"hello\");\n+        let x2 = Cell::new(x.clone());\n+        let mut res = None;\n+        let mut builder = task::task();\n+        builder.future_result(|r| res = Some(r));\n+        do builder.spawn {\n+            let x2 = x2.take();\n+            assert!(x2.unwrap() == ~~\"hello\");\n+        }\n+        assert!(x.unwrap() == ~~\"hello\");\n+        // See #4689 for why this can't be just \"res.recv()\".\n+        assert!(res.unwrap().recv() == task::Success);\n+    }\n+\n+    #[test] #[ignore(cfg(windows))]\n+    fn exclusive_unwrap_deadlock() {\n+        // This is not guaranteed to get to the deadlock before being killed,\n+        // but it will show up sometimes, and if the deadlock were not there,\n+        // the test would nondeterministically fail.\n+        let result = do task::try {\n+            // a task that has two references to the same exclusive will\n+            // deadlock when it unwraps. nothing to be done about that.\n+            let x = exclusive(~~\"hello\");\n+            let x2 = x.clone();\n+            do task::spawn {\n+                for 10.times { task::yield(); } // try to let the unwrapper go\n+                fail!(); // punt it awake from its deadlock\n+            }\n+            let _z = x.unwrap();\n+            unsafe { do x2.with |_hello| { } }\n+        };\n+        assert!(result.is_err());\n     }\n }"}, {"sha": "03e94a902c1a1b495b4237ab7dd46e634a389a9c", "filename": "src/libstd/vec.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Flibstd%2Fvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fvec.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -1896,12 +1896,11 @@ pub mod raw {\n     use cast::transmute;\n     use clone::Clone;\n     use managed;\n-    use option::{None, Some};\n+    use option::Some;\n     use ptr;\n     use sys;\n     use unstable::intrinsics;\n     use vec::{UnboxedVecRepr, with_capacity, ImmutableVector, MutableVector};\n-    use util;\n     #[cfg(not(stage0))]\n     use unstable::intrinsics::contains_managed;\n \n@@ -2022,9 +2021,8 @@ pub mod raw {\n     pub unsafe fn init_elem<T>(v: &mut [T], i: uint, val: T) {\n         let mut box = Some(val);\n         do v.as_mut_buf |p, _len| {\n-            let box2 = util::replace(&mut box, None);\n             intrinsics::move_val_init(&mut(*ptr::mut_offset(p, i)),\n-                                      box2.unwrap());\n+                                      box.take_unwrap());\n         }\n     }\n "}, {"sha": "ea5aa309dc6c916bf898bc41b3386fd4d2a97413", "filename": "src/test/bench/core-std.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fcore-std.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fcore-std.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fcore-std.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -30,7 +30,7 @@ macro_rules! bench (\n \n fn main() {\n     let argv = os::args();\n-    let tests = argv.slice(1, argv.len());\n+    let _tests = argv.slice(1, argv.len());\n \n     bench!(shift_push);\n     bench!(read_line);\n@@ -44,7 +44,7 @@ fn main() {\n fn maybe_run_test(argv: &[~str], name: ~str, test: &fn()) {\n     let mut run_test = false;\n \n-    if os::getenv(~\"RUST_BENCH\").is_some() {\n+    if os::getenv(\"RUST_BENCH\").is_some() {\n         run_test = true\n     } else if argv.len() > 0 {\n         run_test = argv.iter().any(|x| x == &~\"all\") || argv.iter().any(|x| x == &name)"}, {"sha": "2c5cb5d1347727c4bbb1359da71d64855f25a361", "filename": "src/test/bench/core-uint-to-str.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fcore-uint-to-str.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fcore-uint-to-str.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fcore-uint-to-str.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -13,7 +13,7 @@ use std::uint;\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"10000000\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"100000\"]"}, {"sha": "f17b6658f9dcd8b5b3a2251c96012822fdefcf72", "filename": "src/test/bench/graph500-bfs.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fgraph500-bfs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fgraph500-bfs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fgraph500-bfs.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -410,7 +410,7 @@ fn validate(edges: ~[(node_id, node_id)],\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"15\", ~\"48\"]\n     } else if args.len() <= 1 {\n         ~[~\"\", ~\"10\", ~\"16\"]\n@@ -447,7 +447,7 @@ fn main() {\n     let graph_arc = arc::ARC(graph.clone());\n \n     do gen_search_keys(graph, num_keys).map() |root| {\n-        io::stdout().write_line(~\"\");\n+        io::stdout().write_line(\"\");\n         io::stdout().write_line(fmt!(\"Search key: %?\", root));\n \n         if do_sequential {\n@@ -511,7 +511,7 @@ fn main() {\n         }\n     };\n \n-    io::stdout().write_line(~\"\");\n+    io::stdout().write_line(\"\");\n     io::stdout().write_line(\n         fmt!(\"Total sequential: %? \\t Total Parallel: %? \\t Speedup: %?x\",\n              total_seq, total_par, total_seq / total_par));"}, {"sha": "9b0fd23d9cb420a2b59d0662ed1ada3c074af8d0", "filename": "src/test/bench/msgsend-pipes-shared.rs", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-pipes-shared.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-pipes-shared.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-pipes-shared.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -22,23 +22,20 @@ extern mod extra;\n \n use std::comm::{Port, Chan, SharedChan};\n use std::comm;\n-use std::io::{Writer, WriterUtil};\n use std::io;\n use std::os;\n use std::task;\n-use std::ptr;\n use std::uint;\n-use std::vec;\n \n-fn move_out<T>(x: T) {}\n+fn move_out<T>(_x: T) {}\n \n enum request {\n     get_count,\n     bytes(uint),\n     stop\n }\n \n-fn server(requests: &Port<request>, responses: &comm::Chan<uint>) {\n+fn server(requests: &Port<request>, responses: &Chan<uint>) {\n     let mut count = 0u;\n     let mut done = false;\n     while !done {\n@@ -102,7 +99,7 @@ fn run(args: &[~str]) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"1000000\", ~\"10000\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"10000\", ~\"4\"]"}, {"sha": "5ce5e902ed1ef309d28b99c14f9b7db87c1a9a3d", "filename": "src/test/bench/msgsend-pipes.rs", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-pipes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-pipes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-pipes.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -16,16 +16,13 @@\n \n extern mod extra;\n \n-use std::comm::{Port, PortSet, Chan, stream};\n-use std::io::{Writer, WriterUtil};\n+use std::comm::{PortSet, Chan, stream};\n use std::io;\n use std::os;\n-use std::ptr;\n use std::task;\n use std::uint;\n-use std::vec;\n \n-fn move_out<T>(x: T) {}\n+fn move_out<T>(_x: T) {}\n \n enum request {\n     get_count,\n@@ -98,7 +95,7 @@ fn run(args: &[~str]) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"1000000\", ~\"8\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"10000\", ~\"4\"]"}, {"sha": "86784c0b7d3bc2714f1add8dbd9f003ca2055ff6", "filename": "src/test/bench/msgsend-ring-mutex-arcs.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-ring-mutex-arcs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-ring-mutex-arcs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-ring-mutex-arcs.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -24,7 +24,6 @@ use std::cell::Cell;\n use std::io;\n use std::os;\n use std::uint;\n-use std::vec;\n \n // A poor man's pipe.\n type pipe = arc::MutexARC<~[uint]>;\n@@ -60,8 +59,8 @@ fn thread_ring(i: uint, count: uint, num_chan: pipe, num_port: pipe) {\n     // Send/Receive lots of messages.\n     for uint::range(0u, count) |j| {\n         //error!(\"task %?, iter %?\", i, j);\n-        let mut num_chan2 = num_chan.take_unwrap();\n-        let mut num_port2 = num_port.take_unwrap();\n+        let num_chan2 = num_chan.take_unwrap();\n+        let num_port2 = num_port.take_unwrap();\n         send(&num_chan2, i * j);\n         num_chan = Some(num_chan2);\n         let _n = recv(&num_port2);\n@@ -72,7 +71,7 @@ fn thread_ring(i: uint, count: uint, num_chan: pipe, num_port: pipe) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"100\", ~\"10000\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"10\", ~\"100\"]\n@@ -84,7 +83,7 @@ fn main() {\n     let msg_per_task = uint::from_str(args[2]).get();\n \n     let (num_chan, num_port) = init();\n-    let mut num_chan = Cell::new(num_chan);\n+    let num_chan = Cell::new(num_chan);\n \n     let start = time::precise_time_s();\n "}, {"sha": "b79f171147aa04225315f0f601960b5dbad6ef4d", "filename": "src/test/bench/msgsend-ring-pipes.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-ring-pipes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-ring-pipes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-ring-pipes.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -24,7 +24,6 @@ use std::cell::Cell;\n use std::io;\n use std::os;\n use std::pipes::recv;\n-use std::ptr;\n use std::uint;\n use std::util;\n \n@@ -58,7 +57,7 @@ fn thread_ring(i: uint,\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"100\", ~\"10000\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"100\", ~\"1000\"]\n@@ -70,7 +69,7 @@ fn main() {\n     let msg_per_task = uint::from_str(args[2]).get();\n \n     let (num_port, num_chan) = ring::init();\n-    let mut num_chan = Cell::new(num_chan);\n+    let num_chan = Cell::new(num_chan);\n \n     let start = time::precise_time_s();\n "}, {"sha": "b4037d866a010e32f2bc2f5c7ba259cdadd11630", "filename": "src/test/bench/msgsend-ring-rw-arcs.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-ring-rw-arcs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fmsgsend-ring-rw-arcs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-ring-rw-arcs.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -24,7 +24,6 @@ use std::cell::Cell;\n use std::io;\n use std::os;\n use std::uint;\n-use std::vec;\n \n // A poor man's pipe.\n type pipe = arc::RWARC<~[uint]>;\n@@ -56,8 +55,8 @@ fn thread_ring(i: uint, count: uint, num_chan: pipe, num_port: pipe) {\n     // Send/Receive lots of messages.\n     for uint::range(0u, count) |j| {\n         //error!(\"task %?, iter %?\", i, j);\n-        let mut num_chan2 = num_chan.take_unwrap();\n-        let mut num_port2 = num_port.take_unwrap();\n+        let num_chan2 = num_chan.take_unwrap();\n+        let num_port2 = num_port.take_unwrap();\n         send(&num_chan2, i * j);\n         num_chan = Some(num_chan2);\n         let _n = recv(&num_port2);\n@@ -68,7 +67,7 @@ fn thread_ring(i: uint, count: uint, num_chan: pipe, num_port: pipe) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"100\", ~\"10000\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"10\", ~\"100\"]\n@@ -80,7 +79,7 @@ fn main() {\n     let msg_per_task = uint::from_str(args[2]).get();\n \n     let (num_chan, num_port) = init();\n-    let mut num_chan = Cell::new(num_chan);\n+    let num_chan = Cell::new(num_chan);\n \n     let start = time::precise_time_s();\n "}, {"sha": "2eb274378900a3ca95f0cfcfc6199c236ff4336e", "filename": "src/test/bench/pingpong.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fpingpong.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fpingpong.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fpingpong.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -190,7 +190,7 @@ fn timeit(f: &fn()) -> float {\n }\n \n fn main() {\n-    let count = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let count = if os::getenv(\"RUST_BENCH\").is_some() {\n         250000\n     } else {\n         100"}, {"sha": "ff806c8b5d44d6aa7003358ab38f1721d7304ab2", "filename": "src/test/bench/shootout-ackermann.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-ackermann.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-ackermann.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-ackermann.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -28,7 +28,7 @@ fn ack(m: int, n: int) -> int {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"12\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"8\"]"}, {"sha": "d88843e11804537ffc5e2ce6115e09404f5a4fdc", "filename": "src/test/bench/shootout-binarytrees.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-binarytrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-binarytrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-binarytrees.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -40,7 +40,7 @@ fn main() {\n     use std::os;\n     use std::int;\n     let args = std::os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"17\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"8\"]"}, {"sha": "f218b963aaa31e3461dcf15b844a0d37c7d59176", "filename": "src/test/bench/shootout-chameneos-redux.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-chameneos-redux.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-chameneos-redux.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-chameneos-redux.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -12,15 +12,13 @@\n \n extern mod extra;\n \n-use extra::sort;\n use std::cell::Cell;\n use std::comm::*;\n use std::io;\n use std::option;\n use std::os;\n use std::task;\n use std::uint;\n-use std::vec;\n \n fn print_complements() {\n     let all = [Blue, Red, Yellow];\n@@ -206,7 +204,7 @@ fn rendezvous(nn: uint, set: ~[color]) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"200000\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"600\"]\n@@ -217,10 +215,10 @@ fn main() {\n     let nn = uint::from_str(args[1]).get();\n \n     print_complements();\n-    io::println(~\"\");\n+    io::println(\"\");\n \n     rendezvous(nn, ~[Blue, Red, Yellow]);\n-    io::println(~\"\");\n+    io::println(\"\");\n \n     rendezvous(nn,\n         ~[Blue, Red, Yellow, Red, Yellow, Blue, Red, Yellow, Red, Blue]);"}, {"sha": "cc23c0018331596924e414306a541853e86d1128", "filename": "src/test/bench/shootout-fasta-redux.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-fasta-redux.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-fasta-redux.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-fasta-redux.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -2,7 +2,6 @@ use std::cast::transmute;\n use std::from_str::FromStr;\n use std::libc::{FILE, STDOUT_FILENO, c_int, fdopen, fputc, fputs, fwrite, size_t};\n use std::os;\n-use std::str;\n use std::uint::{min, range};\n use std::vec::bytes::copy_memory;\n use std::vec;"}, {"sha": "de36a59dd6507d59fd1582defc39efd65a7747db", "filename": "src/test/bench/shootout-fibo.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-fibo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-fibo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-fibo.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -24,7 +24,7 @@ fn fib(n: int) -> int {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"40\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"30\"]"}, {"sha": "46b882f7b82534873d0c07b1df05c62f4a00a510", "filename": "src/test/bench/shootout-k-nucleotide-pipes.rs", "status": "modified", "additions": 10, "deletions": 11, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-k-nucleotide-pipes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-k-nucleotide-pipes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-k-nucleotide-pipes.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -121,8 +121,8 @@ fn windows_with_carry(bb: &[u8], nn: uint,\n }\n \n fn make_sequence_processor(sz: uint,\n-                           from_parent: &comm::Port<~[u8]>,\n-                           to_parent: &comm::Chan<~str>) {\n+                           from_parent: &Port<~[u8]>,\n+                           to_parent: &Chan<~str>) {\n    let mut freqs: HashMap<~[u8], uint> = HashMap::new();\n    let mut carry: ~[u8] = ~[];\n    let mut total: uint = 0u;\n@@ -143,11 +143,11 @@ fn make_sequence_processor(sz: uint,\n    let buffer = match sz {\n        1u => { sort_and_fmt(&freqs, total) }\n        2u => { sort_and_fmt(&freqs, total) }\n-       3u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGT\"), ~\"GGT\") }\n-       4u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGTA\"), ~\"GGTA\") }\n-       6u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGTATT\"), ~\"GGTATT\") }\n-      12u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGTATTTTAATT\"), ~\"GGTATTTTAATT\") }\n-      18u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGTATTTTAATTTATAGT\"), ~\"GGTATTTTAATTTATAGT\") }\n+       3u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGT\"), \"GGT\") }\n+       4u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGTA\"), \"GGTA\") }\n+       6u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGTATT\"), \"GGTATT\") }\n+      12u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGTATTTTAATT\"), \"GGTATTTTAATT\") }\n+      18u => { fmt!(\"%u\\t%s\", find(&freqs, ~\"GGTATTTTAATTTATAGT\"), \"GGTATTTTAATTTATAGT\") }\n         _ => { ~\"\" }\n    };\n \n@@ -156,8 +156,7 @@ fn make_sequence_processor(sz: uint,\n \n // given a FASTA file on stdin, process sequence THREE\n fn main() {\n-    let args = os::args();\n-    let rdr = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let rdr = if os::getenv(\"RUST_BENCH\").is_some() {\n        // FIXME: Using this compile-time env variable is a crummy way to\n        // get to this massive data set, but include_bin! chokes on it (#2598)\n        let path = Path(env!(\"CFG_SRC_DIR\"))\n@@ -203,7 +202,7 @@ fn main() {\n \n          // start processing if this is the one\n          ('>', false) => {\n-            match line.slice_from(1).find_str(~\"THREE\") {\n+            match line.slice_from(1).find_str(\"THREE\") {\n                option::Some(_) => { proc_mode = true; }\n                option::None    => { }\n             }\n@@ -217,7 +216,7 @@ fn main() {\n             let line_bytes = line.as_bytes();\n \n            for sizes.iter().enumerate().advance |(ii, _sz)| {\n-               let mut lb = line_bytes.to_owned();\n+               let lb = line_bytes.to_owned();\n                to_child[ii].send(lb);\n             }\n          }"}, {"sha": "1fab646fb37a7c9caf98d8cd3d3b1e92331ce847", "filename": "src/test/bench/shootout-nbody.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-nbody.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-nbody.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-nbody.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -1,7 +1,6 @@\n use std::from_str::FromStr;\n use std::os;\n use std::uint::range;\n-use std::vec;\n \n static PI: f64 = 3.141592653589793;\n static SOLAR_MASS: f64 = 4.0 * PI * PI;"}, {"sha": "6ea22715750c5f1aba4b1cdd05e8b60f6db3f308", "filename": "src/test/bench/shootout-pfib.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-pfib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-pfib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-pfib.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -28,7 +28,6 @@ use std::io::WriterUtil;\n use std::io;\n use std::os;\n use std::result::{Ok, Err};\n-use std::str;\n use std::task;\n use std::u64;\n use std::uint;\n@@ -59,13 +58,13 @@ struct Config {\n }\n \n fn parse_opts(argv: ~[~str]) -> Config {\n-    let opts = ~[getopts::optflag(~\"stress\")];\n+    let opts = ~[getopts::optflag(\"stress\")];\n \n     let opt_args = argv.slice(1, argv.len());\n \n     match getopts::getopts(opt_args, opts) {\n       Ok(ref m) => {\n-          return Config {stress: getopts::opt_present(m, ~\"stress\")}\n+          return Config {stress: getopts::opt_present(m, \"stress\")}\n       }\n       Err(_) => { fail!(); }\n     }\n@@ -97,7 +96,7 @@ fn stress(num_tasks: int) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"20\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"8\"]"}, {"sha": "6ce62ccd1271453e82faaf46031b172321db38c3", "filename": "src/test/bench/shootout-reverse-complement.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-reverse-complement.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-reverse-complement.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-reverse-complement.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -5,7 +5,6 @@ use std::cast::transmute;\n use std::libc::{STDOUT_FILENO, c_int, fdopen, fgets, fopen, fputc, fwrite};\n use std::libc::{size_t};\n use std::ptr::null;\n-use std::vec::raw::set_len;\n \n static LINE_LEN: u32 = 80;\n "}, {"sha": "7e75ac858485574ee87400d0a6aeddc6544af323", "filename": "src/test/bench/shootout-threadring.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-threadring.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fshootout-threadring.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-threadring.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -15,7 +15,7 @@ use std::os;\n fn start(n_tasks: int, token: int) {\n     let (p, ch1) = stream();\n     let mut p = p;\n-    let mut ch1 = ch1;\n+    let ch1 = ch1;\n     ch1.send(token);\n     //  XXX could not get this to work with a range closure\n     let mut i = 2;\n@@ -55,7 +55,7 @@ fn roundtrip(id: int, n_tasks: int, p: &Port<int>, ch: &Chan<int>) {\n }\n \n fn main() {\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"2000000\", ~\"503\"]\n     }\n     else {"}, {"sha": "7f2accb6f0ea911fb6a54f39cd356d3a5ebebe64", "filename": "src/test/bench/std-smallintmap.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fstd-smallintmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fstd-smallintmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fstd-smallintmap.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -32,7 +32,7 @@ fn check_sequential(min: uint, max: uint, map: &SmallIntMap<uint>) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"100000\", ~\"100\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"10000\", ~\"50\"]"}, {"sha": "f4ddc090c21609a9ecfa3e05cb6dd4ad095be8de", "filename": "src/test/bench/sudoku.rs", "status": "modified", "additions": 10, "deletions": 11, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fsudoku.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Fsudoku.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fsudoku.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -15,7 +15,6 @@ extern mod extra;\n use std::io::{ReaderUtil, WriterUtil};\n use std::io;\n use std::os;\n-use std::str;\n use std::u8;\n use std::uint;\n use std::unstable::intrinsics::cttz16;\n@@ -50,7 +49,7 @@ impl Sudoku {\n     }\n \n     pub fn from_vec(vec: &[[u8, ..9], ..9]) -> Sudoku {\n-        let mut g = do vec::from_fn(9u) |i| {\n+        let g = do vec::from_fn(9u) |i| {\n             do vec::from_fn(9u) |j| { vec[i][j] }\n         };\n         return Sudoku::new(g)\n@@ -161,17 +160,17 @@ impl Sudoku {\n // Stores available colors as simple bitfield, bit 0 is always unset\n struct Colors(u16);\n \n-static heads: u16 = (1u16 << 10) - 1; /* bits 9..0 */\n+static HEADS: u16 = (1u16 << 10) - 1; /* bits 9..0 */\n \n impl Colors {\n     fn new(start_color: u8) -> Colors {\n         // Sets bits 9..start_color\n         let tails = !0u16 << start_color;\n-        return Colors(heads & tails);\n+        return Colors(HEADS & tails);\n     }\n \n     fn next(&self) -> u8 {\n-        let val = **self & heads;\n+        let val = **self & HEADS;\n         if (0u16 == val) {\n             return 0u8;\n         } else {\n@@ -190,7 +189,7 @@ impl Colors {\n     }\n }\n \n-static default_sudoku: [[u8, ..9], ..9] = [\n+static DEFAULT_SUDOKU: [[u8, ..9], ..9] = [\n          /* 0    1    2    3    4    5    6    7    8    */\n   /* 0 */  [0u8, 4u8, 0u8, 6u8, 0u8, 0u8, 0u8, 3u8, 2u8],\n   /* 1 */  [0u8, 0u8, 8u8, 0u8, 2u8, 0u8, 0u8, 0u8, 0u8],\n@@ -204,7 +203,7 @@ static default_sudoku: [[u8, ..9], ..9] = [\n ];\n \n #[cfg(test)]\n-static default_solution: [[u8, ..9], ..9] = [\n+static DEFAULT_SOLUTION: [[u8, ..9], ..9] = [\n          /* 0    1    2    3    4    5    6    7    8    */\n   /* 0 */  [1u8, 4u8, 9u8, 6u8, 7u8, 5u8, 8u8, 3u8, 2u8],\n   /* 1 */  [5u8, 3u8, 8u8, 1u8, 2u8, 9u8, 7u8, 4u8, 6u8],\n@@ -258,10 +257,10 @@ fn colors_remove_works() {\n }\n \n #[test]\n-fn check_default_sudoku_solution() {\n+fn check_DEFAULT_SUDOKU_solution() {\n     // GIVEN\n-    let mut sudoku = Sudoku::from_vec(&default_sudoku);\n-    let solution   = Sudoku::from_vec(&default_solution);\n+    let mut sudoku = Sudoku::from_vec(&DEFAULT_SUDOKU);\n+    let solution   = Sudoku::from_vec(&DEFAULT_SOLUTION);\n \n     // WHEN\n     sudoku.solve();\n@@ -274,7 +273,7 @@ fn main() {\n     let args        = os::args();\n     let use_default = args.len() == 1u;\n     let mut sudoku = if use_default {\n-        Sudoku::from_vec(&default_sudoku)\n+        Sudoku::from_vec(&DEFAULT_SUDOKU)\n     } else {\n         Sudoku::read(io::stdin())\n     };"}, {"sha": "3470cc9274578e806ead9aaf2f58843651735b46", "filename": "src/test/bench/task-perf-alloc-unwind.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-alloc-unwind.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-alloc-unwind.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Ftask-perf-alloc-unwind.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -22,7 +22,7 @@ enum UniqueList {\n }\n \n fn main() {\n-    let (repeat, depth) = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let (repeat, depth) = if os::getenv(\"RUST_BENCH\").is_some() {\n         (50, 1000)\n     } else {\n         (10, 10)"}, {"sha": "4e27841a748505b9ca0b58c0a8c470cf9aa23748", "filename": "src/test/bench/task-perf-jargon-metal-smoke.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-jargon-metal-smoke.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-jargon-metal-smoke.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Ftask-perf-jargon-metal-smoke.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -43,7 +43,7 @@ fn child_generation(gens_left: uint, c: comm::Chan<()>) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"100000\"]\n     } else if args.len() <= 1 {\n         ~[~\"\", ~\"100\"]"}, {"sha": "7eb138e99a0865fb98362f45c698849e301f114a", "filename": "src/test/bench/task-perf-linked-failure.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-linked-failure.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-linked-failure.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Ftask-perf-linked-failure.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -63,7 +63,7 @@ fn spawn_supervised_blocking(myname: &str, f: ~fn()) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"100000\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"100\"]"}, {"sha": "7f986eab7893880e5da06bcca47a0245d1caaf11", "filename": "src/test/bench/task-perf-one-million.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-one-million.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-one-million.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Ftask-perf-one-million.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -12,7 +12,6 @@\n \n // xfail-test OOM on linux-32 without opts\n \n-use std::comm::*;\n use std::os;\n use std::task;\n use std::uint;\n@@ -49,7 +48,7 @@ fn calc(children: uint, parent_wait_chan: &Chan<Chan<Chan<int>>>) {\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"30\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"10\"]"}, {"sha": "a152c3021331841ab19f83fa8760e5f2a1c7f914", "filename": "src/test/bench/task-perf-spawnalot.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-spawnalot.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e3142c5d3e0a69bff0e3d5506f617c5433a9a750/src%2Ftest%2Fbench%2Ftask-perf-spawnalot.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Ftask-perf-spawnalot.rs?ref=e3142c5d3e0a69bff0e3d5506f617c5433a9a750", "patch": "@@ -24,7 +24,7 @@ fn g() { }\n \n fn main() {\n     let args = os::args();\n-    let args = if os::getenv(~\"RUST_BENCH\").is_some() {\n+    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n         ~[~\"\", ~\"400\"]\n     } else if args.len() <= 1u {\n         ~[~\"\", ~\"10\"]"}]}