{"sha": "8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "node_id": "C_kwDOAAsO6NoAKDhlOGZiNGY0OWU3MjcyYjhkY2JkMjU4MDdhM2FlODQwOGFjNDFjZTg", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2022-05-21T12:50:39Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2022-05-22T09:01:07Z"}, "message": "rustc_parse: Move AST -> TokenStream conversion logic to `rustc_ast`", "tree": {"sha": "b1fb402921ac606206de326f438054f601d4a9fe", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b1fb402921ac606206de326f438054f601d4a9fe"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "html_url": "https://github.com/rust-lang/rust/commit/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "acfd327fd4e3a302ebb0a077f422a527a7935333", "url": "https://api.github.com/repos/rust-lang/rust/commits/acfd327fd4e3a302ebb0a077f422a527a7935333", "html_url": "https://github.com/rust-lang/rust/commit/acfd327fd4e3a302ebb0a077f422a527a7935333"}], "stats": {"total": 408, "additions": 124, "deletions": 284}, "files": [{"sha": "07b8a98e47f41b65b7c27fe650f9ab703b1abdb5", "filename": "compiler/rustc_ast/src/ast.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -444,8 +444,7 @@ impl Default for Generics {\n pub struct WhereClause {\n     /// `true` if we ate a `where` token: this can happen\n     /// if we parsed no predicates (e.g. `struct Foo where {}`).\n-    /// This allows us to accurately pretty-print\n-    /// in `nt_to_tokenstream`\n+    /// This allows us to pretty-print accurately.\n     pub has_where_token: bool,\n     pub predicates: Vec<WherePredicate>,\n     pub span: Span,"}, {"sha": "5c30a75a140a441ef2e5d1aecc0810530f6f6ac1", "filename": "compiler/rustc_ast/src/ast_traits.rs", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -108,14 +108,20 @@ macro_rules! impl_has_span {\n     };\n }\n \n-impl_has_span!(AssocItem, Expr, ForeignItem, Item, Stmt);\n+impl_has_span!(AssocItem, Block, Expr, ForeignItem, Item, Pat, Path, Stmt, Ty, Visibility);\n \n impl<T: AstDeref<Target: HasSpan>> HasSpan for T {\n     fn span(&self) -> Span {\n         self.ast_deref().span()\n     }\n }\n \n+impl HasSpan for AttrItem {\n+    fn span(&self) -> Span {\n+        self.span()\n+    }\n+}\n+\n /// A trait for AST nodes having (or not having) collected tokens.\n pub trait HasTokens {\n     fn tokens(&self) -> Option<&LazyTokenStream>;"}, {"sha": "c58fe7287bf79bb1367851f7f501c277164d3a28", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 86, "deletions": 7, "changes": 93, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -13,7 +13,9 @@\n //! and a borrowed `TokenStream` is sufficient to build an owned `TokenStream` without taking\n //! ownership of the original.\n \n-use crate::token::{self, Delimiter, Token, TokenKind};\n+use crate::ast::StmtKind;\n+use crate::ast_traits::{HasAttrs, HasSpan, HasTokens};\n+use crate::token::{self, Delimiter, Nonterminal, Token, TokenKind};\n use crate::AttrVec;\n \n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n@@ -45,12 +47,6 @@ pub enum TokenTree {\n     Delimited(DelimSpan, Delimiter, TokenStream),\n }\n \n-#[derive(Copy, Clone)]\n-pub enum CanSynthesizeMissingTokens {\n-    Yes,\n-    No,\n-}\n-\n // Ensure all fields of `TokenTree` is `Send` and `Sync`.\n #[cfg(parallel_compiler)]\n fn _dummy()\n@@ -471,6 +467,89 @@ impl TokenStream {\n                 .collect(),\n         ))\n     }\n+\n+    fn opt_from_ast(node: &(impl HasAttrs + HasTokens)) -> Option<TokenStream> {\n+        let tokens = node.tokens()?;\n+        let attrs = node.attrs();\n+        let attr_annotated = if attrs.is_empty() {\n+            tokens.create_token_stream()\n+        } else {\n+            let attr_data = AttributesData { attrs: attrs.to_vec().into(), tokens: tokens.clone() };\n+            AttrAnnotatedTokenStream::new(vec![(\n+                AttrAnnotatedTokenTree::Attributes(attr_data),\n+                Spacing::Alone,\n+            )])\n+        };\n+        Some(attr_annotated.to_tokenstream())\n+    }\n+\n+    pub fn from_ast(node: &(impl HasAttrs + HasSpan + HasTokens + fmt::Debug)) -> TokenStream {\n+        TokenStream::opt_from_ast(node)\n+            .unwrap_or_else(|| panic!(\"missing tokens for node at {:?}: {:?}\", node.span(), node))\n+    }\n+\n+    pub fn from_nonterminal_ast(nt: &Nonterminal) -> TokenStream {\n+        match nt {\n+            Nonterminal::NtIdent(ident, is_raw) => {\n+                TokenTree::token(token::Ident(ident.name, *is_raw), ident.span).into()\n+            }\n+            Nonterminal::NtLifetime(ident) => {\n+                TokenTree::token(token::Lifetime(ident.name), ident.span).into()\n+            }\n+            Nonterminal::NtItem(item) => TokenStream::from_ast(item),\n+            Nonterminal::NtBlock(block) => TokenStream::from_ast(block),\n+            Nonterminal::NtStmt(stmt) if let StmtKind::Empty = stmt.kind => {\n+                // FIXME: Properly collect tokens for empty statements.\n+                TokenTree::token(token::Semi, stmt.span).into()\n+            }\n+            Nonterminal::NtStmt(stmt) => TokenStream::from_ast(stmt),\n+            Nonterminal::NtPat(pat) => TokenStream::from_ast(pat),\n+            Nonterminal::NtTy(ty) => TokenStream::from_ast(ty),\n+            Nonterminal::NtMeta(attr) => TokenStream::from_ast(attr),\n+            Nonterminal::NtPath(path) => TokenStream::from_ast(path),\n+            Nonterminal::NtVis(vis) => TokenStream::from_ast(vis),\n+            Nonterminal::NtExpr(expr) | Nonterminal::NtLiteral(expr) => TokenStream::from_ast(expr),\n+        }\n+    }\n+\n+    fn flatten_token(token: &Token) -> TokenTree {\n+        match &token.kind {\n+            token::Interpolated(nt) if let token::NtIdent(ident, is_raw) = **nt => {\n+                TokenTree::token(token::Ident(ident.name, is_raw), ident.span)\n+            }\n+            token::Interpolated(nt) => TokenTree::Delimited(\n+                DelimSpan::from_single(token.span),\n+                Delimiter::Invisible,\n+                TokenStream::from_nonterminal_ast(&nt).flattened(),\n+            ),\n+            _ => TokenTree::Token(token.clone()),\n+        }\n+    }\n+\n+    fn flatten_token_tree(tree: &TokenTree) -> TokenTree {\n+        match tree {\n+            TokenTree::Token(token) => TokenStream::flatten_token(token),\n+            TokenTree::Delimited(span, delim, tts) => {\n+                TokenTree::Delimited(*span, *delim, tts.flattened())\n+            }\n+        }\n+    }\n+\n+    #[must_use]\n+    pub fn flattened(&self) -> TokenStream {\n+        fn can_skip(stream: &TokenStream) -> bool {\n+            stream.trees().all(|tree| match tree {\n+                TokenTree::Token(token) => !matches!(token.kind, token::Interpolated(_)),\n+                TokenTree::Delimited(_, _, inner) => can_skip(inner),\n+            })\n+        }\n+\n+        if can_skip(self) {\n+            return self.clone();\n+        }\n+\n+        self.trees().map(|tree| TokenStream::flatten_token_tree(tree)).collect()\n+    }\n }\n \n // 99.5%+ of the time we have 1 or 2 elements in this vector."}, {"sha": "12d1b8404eb8b9f17e4c287de56d3eaae30449f4", "filename": "compiler/rustc_ast_lowering/src/item.rs", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast_lowering%2Fsrc%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast_lowering%2Fsrc%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast_lowering%2Fsrc%2Fitem.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -13,7 +13,6 @@ use rustc_hir::def::{DefKind, Res};\n use rustc_hir::def_id::{LocalDefId, CRATE_DEF_ID};\n use rustc_hir::PredicateOrigin;\n use rustc_index::vec::{Idx, IndexVec};\n-use rustc_session::utils::NtToTokenstream;\n use rustc_session::Session;\n use rustc_span::source_map::DesugaringKind;\n use rustc_span::symbol::{kw, sym, Ident};\n@@ -27,7 +26,6 @@ use std::iter;\n pub(super) struct ItemLowerer<'a, 'hir> {\n     pub(super) sess: &'a Session,\n     pub(super) resolver: &'a mut dyn ResolverAstLowering,\n-    pub(super) nt_to_tokenstream: NtToTokenstream,\n     pub(super) arena: &'hir Arena<'hir>,\n     pub(super) ast_index: &'a IndexVec<LocalDefId, AstOwner<'a>>,\n     pub(super) owners: &'a mut IndexVec<LocalDefId, hir::MaybeOwner<&'hir hir::OwnerInfo<'hir>>>,\n@@ -63,7 +61,6 @@ impl<'a, 'hir> ItemLowerer<'a, 'hir> {\n             // Pseudo-globals.\n             sess: &self.sess,\n             resolver: self.resolver,\n-            nt_to_tokenstream: self.nt_to_tokenstream,\n             arena: self.arena,\n \n             // HirId handling."}, {"sha": "e59bc9aa6b399af4626379c82741939a75976390", "filename": "compiler/rustc_ast_lowering/src/lib.rs", "status": "modified", "additions": 3, "deletions": 35, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -37,7 +37,6 @@\n #![recursion_limit = \"256\"]\n #![allow(rustc::potential_query_instability)]\n \n-use rustc_ast::tokenstream::{CanSynthesizeMissingTokens, TokenStream};\n use rustc_ast::visit;\n use rustc_ast::{self as ast, *};\n use rustc_ast_pretty::pprust;\n@@ -56,7 +55,6 @@ use rustc_hir::{ConstArg, GenericArg, ItemLocalId, ParamName, TraitCandidate};\n use rustc_index::vec::{Idx, IndexVec};\n use rustc_query_system::ich::StableHashingContext;\n use rustc_session::parse::feature_err;\n-use rustc_session::utils::{FlattenNonterminals, NtToTokenstream};\n use rustc_session::Session;\n use rustc_span::hygiene::{ExpnId, MacroKind};\n use rustc_span::source_map::DesugaringKind;\n@@ -89,11 +87,6 @@ struct LoweringContext<'a, 'hir: 'a> {\n \n     resolver: &'a mut dyn ResolverAstLowering,\n \n-    /// HACK(Centril): there is a cyclic dependency between the parser and lowering\n-    /// if we don't have this function pointer. To avoid that dependency so that\n-    /// `rustc_middle` is independent of the parser, we use dynamic dispatch here.\n-    nt_to_tokenstream: NtToTokenstream,\n-\n     /// Used to allocate HIR nodes.\n     arena: &'hir Arena<'hir>,\n \n@@ -436,7 +429,6 @@ pub fn lower_crate<'a, 'hir>(\n     sess: &'a Session,\n     krate: &'a Crate,\n     resolver: &'a mut dyn ResolverAstLowering,\n-    nt_to_tokenstream: NtToTokenstream,\n     arena: &'hir Arena<'hir>,\n ) -> &'hir hir::Crate<'hir> {\n     let _prof_timer = sess.prof.verbose_generic_activity(\"hir_lowering\");\n@@ -447,15 +439,8 @@ pub fn lower_crate<'a, 'hir>(\n         IndexVec::from_fn_n(|_| hir::MaybeOwner::Phantom, resolver.definitions().def_index_count());\n \n     for def_id in ast_index.indices() {\n-        item::ItemLowerer {\n-            sess,\n-            resolver,\n-            nt_to_tokenstream,\n-            arena,\n-            ast_index: &ast_index,\n-            owners: &mut owners,\n-        }\n-        .lower_node(def_id);\n+        item::ItemLowerer { sess, resolver, arena, ast_index: &ast_index, owners: &mut owners }\n+            .lower_node(def_id);\n     }\n \n     let hir_hash = compute_hir_hash(resolver, &owners);\n@@ -875,11 +860,7 @@ impl<'a, 'hir> LoweringContext<'a, 'hir> {\n                 // ```\n                 //\n                 // In both cases, we don't want to synthesize any tokens\n-                MacArgs::Delimited(\n-                    dspan,\n-                    delim,\n-                    self.lower_token_stream(tokens.clone(), CanSynthesizeMissingTokens::No),\n-                )\n+                MacArgs::Delimited(dspan, delim, tokens.flattened())\n             }\n             // This is an inert key-value attribute - it will never be visible to macros\n             // after it gets lowered to HIR. Therefore, we can extract literals to handle\n@@ -904,19 +885,6 @@ impl<'a, 'hir> LoweringContext<'a, 'hir> {\n         }\n     }\n \n-    fn lower_token_stream(\n-        &self,\n-        tokens: TokenStream,\n-        synthesize_tokens: CanSynthesizeMissingTokens,\n-    ) -> TokenStream {\n-        FlattenNonterminals {\n-            parse_sess: &self.sess.parse_sess,\n-            synthesize_tokens,\n-            nt_to_tokenstream: self.nt_to_tokenstream,\n-        }\n-        .process_token_stream(tokens)\n-    }\n-\n     /// Given an associated type constraint like one of these:\n     ///\n     /// ```ignore (illustrative)"}, {"sha": "ac9e7d06c4e4006fb9563cd55fe0af516869272b", "filename": "compiler/rustc_ast_pretty/src/pprust/mod.rs", "status": "modified", "additions": 1, "deletions": 31, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast_pretty%2Fsrc%2Fpprust%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_ast_pretty%2Fsrc%2Fpprust%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast_pretty%2Fsrc%2Fpprust%2Fmod.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -4,42 +4,12 @@ mod tests;\n pub mod state;\n pub use state::{print_crate, AnnNode, Comments, PpAnn, PrintState, State};\n \n+use rustc_ast as ast;\n use rustc_ast::token::{Nonterminal, Token, TokenKind};\n use rustc_ast::tokenstream::{TokenStream, TokenTree};\n-use rustc_ast::{self as ast, AstDeref};\n \n use std::borrow::Cow;\n \n-pub trait AstPrettyPrint {\n-    fn pretty_print(&self) -> String;\n-}\n-\n-impl<T: AstDeref<Target: AstPrettyPrint>> AstPrettyPrint for T {\n-    fn pretty_print(&self) -> String {\n-        self.ast_deref().pretty_print()\n-    }\n-}\n-\n-macro_rules! impl_ast_pretty_print {\n-    ($($T:ty => $method:ident),+ $(,)?) => {\n-        $(\n-            impl AstPrettyPrint for $T {\n-                fn pretty_print(&self) -> String {\n-                    State::new().$method(self)\n-                }\n-            }\n-        )+\n-    };\n-}\n-\n-impl_ast_pretty_print! {\n-    ast::Item => item_to_string,\n-    ast::AssocItem => assoc_item_to_string,\n-    ast::ForeignItem => foreign_item_to_string,\n-    ast::Expr => expr_to_string,\n-    ast::Stmt => stmt_to_string,\n-}\n-\n pub fn nonterminal_to_string(nt: &Nonterminal) -> String {\n     State::new().nonterminal_to_string(nt)\n }"}, {"sha": "89b2c329236d4749951fb8111046b0878fbee21f", "filename": "compiler/rustc_builtin_macros/src/cfg_eval.rs", "status": "modified", "additions": 1, "deletions": 10, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -3,7 +3,6 @@ use crate::util::{check_builtin_macro_attribute, warn_on_duplicate_attribute};\n use rustc_ast as ast;\n use rustc_ast::mut_visit::MutVisitor;\n use rustc_ast::ptr::P;\n-use rustc_ast::tokenstream::CanSynthesizeMissingTokens;\n use rustc_ast::visit::Visitor;\n use rustc_ast::NodeId;\n use rustc_ast::{mut_visit, visit};\n@@ -13,7 +12,6 @@ use rustc_expand::config::StripUnconfigured;\n use rustc_expand::configure;\n use rustc_feature::Features;\n use rustc_parse::parser::{ForceCollect, Parser};\n-use rustc_session::utils::FlattenNonterminals;\n use rustc_session::Session;\n use rustc_span::symbol::sym;\n use rustc_span::Span;\n@@ -174,8 +172,6 @@ impl CfgEval<'_, '_> {\n             _ => unreachable!(),\n         };\n \n-        let mut orig_tokens = annotatable.to_tokens(&self.cfg.sess.parse_sess);\n-\n         // 'Flatten' all nonterminals (i.e. `TokenKind::Interpolated`)\n         // to `None`-delimited groups containing the corresponding tokens. This\n         // is normally delayed until the proc-macro server actually needs to\n@@ -189,12 +185,7 @@ impl CfgEval<'_, '_> {\n         // where `$item` is `#[cfg_attr] struct Foo {}`. We want to make\n         // sure to evaluate *all* `#[cfg]` and `#[cfg_attr]` attributes - the simplest\n         // way to do this is to do a single parse of a stream without any nonterminals.\n-        let mut flatten = FlattenNonterminals {\n-            nt_to_tokenstream: rustc_parse::nt_to_tokenstream,\n-            parse_sess: &self.cfg.sess.parse_sess,\n-            synthesize_tokens: CanSynthesizeMissingTokens::No,\n-        };\n-        orig_tokens = flatten.process_token_stream(orig_tokens);\n+        let orig_tokens = annotatable.to_tokens().flattened();\n \n         // Re-parse the tokens, setting the `capture_cfg` flag to save extra information\n         // to the captured `AttrAnnotatedTokenStream` (specifically, we capture"}, {"sha": "e48ce60218525aff6e0ba978f5b74acf7d4582ae", "filename": "compiler/rustc_expand/src/base.rs", "status": "modified", "additions": 8, "deletions": 10, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_expand%2Fsrc%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_expand%2Fsrc%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fbase.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -4,7 +4,7 @@ use crate::module::DirOwnership;\n use rustc_ast::attr::MarkedAttrs;\n use rustc_ast::ptr::P;\n use rustc_ast::token::{self, Nonterminal};\n-use rustc_ast::tokenstream::{CanSynthesizeMissingTokens, TokenStream};\n+use rustc_ast::tokenstream::TokenStream;\n use rustc_ast::visit::{AssocCtxt, Visitor};\n use rustc_ast::{self as ast, Attribute, HasAttrs, Item, NodeId, PatKind};\n use rustc_attr::{self as attr, Deprecation, Stability};\n@@ -13,7 +13,7 @@ use rustc_data_structures::sync::{self, Lrc};\n use rustc_errors::{Applicability, DiagnosticBuilder, ErrorGuaranteed, MultiSpan, PResult};\n use rustc_lint_defs::builtin::PROC_MACRO_BACK_COMPAT;\n use rustc_lint_defs::BuiltinLintDiagnostics;\n-use rustc_parse::{self, parser, to_token_stream, MACRO_ARGUMENTS};\n+use rustc_parse::{self, parser, MACRO_ARGUMENTS};\n use rustc_session::{parse::ParseSess, Limit, Session};\n use rustc_span::def_id::{CrateNum, DefId, LocalDefId};\n use rustc_span::edition::Edition;\n@@ -109,20 +109,18 @@ impl Annotatable {\n         }\n     }\n \n-    pub fn to_tokens(&self, sess: &ParseSess) -> TokenStream {\n+    pub fn to_tokens(&self) -> TokenStream {\n         match self {\n-            Annotatable::Item(node) => to_token_stream(node, sess, CanSynthesizeMissingTokens::No),\n+            Annotatable::Item(node) => TokenStream::from_ast(node),\n             Annotatable::TraitItem(node) | Annotatable::ImplItem(node) => {\n-                to_token_stream(node, sess, CanSynthesizeMissingTokens::No)\n-            }\n-            Annotatable::ForeignItem(node) => {\n-                to_token_stream(node, sess, CanSynthesizeMissingTokens::No)\n+                TokenStream::from_ast(node)\n             }\n+            Annotatable::ForeignItem(node) => TokenStream::from_ast(node),\n             Annotatable::Stmt(node) => {\n                 assert!(!matches!(node.kind, ast::StmtKind::Empty));\n-                to_token_stream(node, sess, CanSynthesizeMissingTokens::No)\n+                TokenStream::from_ast(node)\n             }\n-            Annotatable::Expr(node) => to_token_stream(node, sess, CanSynthesizeMissingTokens::No),\n+            Annotatable::Expr(node) => TokenStream::from_ast(node),\n             Annotatable::Arm(..)\n             | Annotatable::ExprField(..)\n             | Annotatable::PatField(..)"}, {"sha": "5af6b777abee1c3fa6f757cf904386f27423f430", "filename": "compiler/rustc_expand/src/expand.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -679,9 +679,12 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n                                     )\n                                 ) =>\n                         {\n-                            rustc_parse::fake_token_stream(&self.cx.sess.parse_sess, item_inner)\n+                            rustc_parse::fake_token_stream_for_item(\n+                                &self.cx.sess.parse_sess,\n+                                item_inner,\n+                            )\n                         }\n-                        _ => item.to_tokens(&self.cx.sess.parse_sess),\n+                        _ => item.to_tokens(),\n                     };\n                     let attr_item = attr.unwrap_normal_item();\n                     if let MacArgs::Eq(..) = attr_item.args {"}, {"sha": "b3679b31c6c1f209915728432d91a3c18f1d6bbe", "filename": "compiler/rustc_expand/src/proc_macro.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -96,7 +96,7 @@ impl MultiItemModifier for ProcMacroDerive {\n             };\n             TokenTree::token(token::Interpolated(Lrc::new(nt)), DUMMY_SP).into()\n         } else {\n-            item.to_tokens(&ecx.sess.parse_sess)\n+            item.to_tokens()\n         };\n \n         let stream = {"}, {"sha": "d4407c03d03f53fa820a3890c1bf4be690724f1e", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -2,14 +2,13 @@ use crate::base::ExtCtxt;\n \n use rustc_ast as ast;\n use rustc_ast::token;\n-use rustc_ast::tokenstream::{self, CanSynthesizeMissingTokens};\n-use rustc_ast::tokenstream::{DelimSpan, Spacing::*, TokenStream, TreeAndSpacing};\n+use rustc_ast::tokenstream::{self, DelimSpan, Spacing::*, TokenStream, TreeAndSpacing};\n use rustc_ast_pretty::pprust;\n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::{Diagnostic, MultiSpan, PResult};\n use rustc_parse::lexer::nfc_normalize;\n-use rustc_parse::{nt_to_tokenstream, parse_stream_from_source_str};\n+use rustc_parse::parse_stream_from_source_str;\n use rustc_session::parse::ParseSess;\n use rustc_span::def_id::CrateNum;\n use rustc_span::symbol::{self, kw, sym, Symbol};\n@@ -179,10 +178,9 @@ impl FromInternal<(TreeAndSpacing, &'_ mut Vec<Self>, &mut Rustc<'_, '_>)>\n                 TokenTree::Ident(Ident::new(rustc.sess(), ident.name, is_raw, ident.span))\n             }\n             Interpolated(nt) => {\n-                let stream = nt_to_tokenstream(&nt, rustc.sess(), CanSynthesizeMissingTokens::No);\n                 TokenTree::Group(Group {\n                     delimiter: pm::Delimiter::None,\n-                    stream,\n+                    stream: TokenStream::from_nonterminal_ast(&nt),\n                     span: DelimSpan::from_single(span),\n                     flatten: crate::base::nt_pretty_printing_compatibility_hack(&nt, rustc.sess()),\n                 })\n@@ -454,7 +452,7 @@ impl server::TokenStream for Rustc<'_, '_> {\n \n         // NOTE: For now, limit `expand_expr` to exclusively expand to literals.\n         // This may be relaxed in the future.\n-        // We don't use `nt_to_tokenstream` as the tokenstream currently cannot\n+        // We don't use `TokenStream::from_ast` as the tokenstream currently cannot\n         // be recovered in the general case.\n         match &expr.kind {\n             ast::ExprKind::Lit(l) => {"}, {"sha": "afbf48fceb51035c6367f05b896f0a3aae38c9ff", "filename": "compiler/rustc_interface/src/passes.rs", "status": "modified", "additions": 1, "deletions": 7, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_interface%2Fsrc%2Fpasses.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_interface%2Fsrc%2Fpasses.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_interface%2Fsrc%2Fpasses.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -494,13 +494,7 @@ pub fn lower_to_hir<'res, 'tcx>(\n     arena: &'tcx rustc_ast_lowering::Arena<'tcx>,\n ) -> &'tcx Crate<'tcx> {\n     // Lower AST to HIR.\n-    let hir_crate = rustc_ast_lowering::lower_crate(\n-        sess,\n-        &*krate,\n-        resolver,\n-        rustc_parse::nt_to_tokenstream,\n-        arena,\n-    );\n+    let hir_crate = rustc_ast_lowering::lower_crate(sess, &*krate, resolver, arena);\n \n     // Drop AST to free memory\n     sess.time(\"drop_ast\", || std::mem::drop(krate));"}, {"sha": "df1765952ceac61e1d3e40497c9c9327b349b103", "filename": "compiler/rustc_parse/src/lib.rs", "status": "modified", "additions": 6, "deletions": 111, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flib.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -12,20 +12,16 @@\n extern crate tracing;\n \n use rustc_ast as ast;\n-use rustc_ast::token::{self, Nonterminal, Token, TokenKind};\n-use rustc_ast::tokenstream::{self, AttributesData, CanSynthesizeMissingTokens, LazyTokenStream};\n-use rustc_ast::tokenstream::{AttrAnnotatedTokenStream, AttrAnnotatedTokenTree};\n-use rustc_ast::tokenstream::{Spacing, TokenStream};\n+use rustc_ast::token;\n+use rustc_ast::tokenstream::TokenStream;\n use rustc_ast::Attribute;\n use rustc_ast::{AttrItem, MetaItem};\n-use rustc_ast::{HasAttrs, HasSpan, HasTokens};\n-use rustc_ast_pretty::pprust::{self, AstPrettyPrint};\n+use rustc_ast_pretty::pprust;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::{Applicability, Diagnostic, FatalError, Level, PResult};\n use rustc_session::parse::ParseSess;\n use rustc_span::{FileName, SourceFile, Span};\n \n-use std::fmt;\n use std::path::Path;\n \n pub const MACRO_ARGUMENTS: Option<&str> = Some(\"macro arguments\");\n@@ -240,111 +236,10 @@ pub fn parse_in<'a, T>(\n     Ok(result)\n }\n \n-// NOTE(Centril): The following probably shouldn't be here but it acknowledges the\n-// fact that architecturally, we are using parsing (read on below to understand why).\n-\n-pub fn to_token_stream(\n-    node: &(impl HasAttrs + HasSpan + HasTokens + AstPrettyPrint + fmt::Debug),\n-    sess: &ParseSess,\n-    synthesize_tokens: CanSynthesizeMissingTokens,\n-) -> TokenStream {\n-    if let Some(tokens) = prepend_attrs(&node.attrs(), node.tokens()) {\n-        return tokens;\n-    } else if matches!(synthesize_tokens, CanSynthesizeMissingTokens::Yes) {\n-        return fake_token_stream(sess, node);\n-    } else {\n-        panic!(\"Missing tokens for nt {:?} at {:?}: {:?}\", node, node.span(), node.pretty_print());\n-    }\n-}\n-\n-pub fn nt_to_tokenstream(\n-    nt: &Nonterminal,\n-    sess: &ParseSess,\n-    synthesize_tokens: CanSynthesizeMissingTokens,\n-) -> TokenStream {\n-    // A `Nonterminal` is often a parsed AST item. At this point we now\n-    // need to convert the parsed AST to an actual token stream, e.g.\n-    // un-parse it basically.\n-    //\n-    // Unfortunately there's not really a great way to do that in a\n-    // guaranteed lossless fashion right now. The fallback here is to just\n-    // stringify the AST node and reparse it, but this loses all span\n-    // information.\n-    //\n-    // As a result, some AST nodes are annotated with the token stream they\n-    // came from. Here we attempt to extract these lossless token streams\n-    // before we fall back to the stringification.\n-\n-    let convert_tokens =\n-        |tokens: Option<&LazyTokenStream>| Some(tokens?.create_token_stream().to_tokenstream());\n-\n-    let tokens = match *nt {\n-        Nonterminal::NtItem(ref item) => prepend_attrs(&item.attrs, item.tokens.as_ref()),\n-        Nonterminal::NtBlock(ref block) => convert_tokens(block.tokens.as_ref()),\n-        Nonterminal::NtStmt(ref stmt) if let ast::StmtKind::Empty = stmt.kind => {\n-            let tokens = AttrAnnotatedTokenStream::new(vec![(\n-                tokenstream::AttrAnnotatedTokenTree::Token(Token::new(\n-                    TokenKind::Semi,\n-                    stmt.span,\n-                )),\n-                Spacing::Alone,\n-            )]);\n-            prepend_attrs(&stmt.attrs(), Some(&LazyTokenStream::new(tokens)))\n-        }\n-        Nonterminal::NtStmt(ref stmt) => prepend_attrs(&stmt.attrs(), stmt.tokens()),\n-        Nonterminal::NtPat(ref pat) => convert_tokens(pat.tokens.as_ref()),\n-        Nonterminal::NtTy(ref ty) => convert_tokens(ty.tokens.as_ref()),\n-        Nonterminal::NtIdent(ident, is_raw) => {\n-            Some(tokenstream::TokenTree::token(token::Ident(ident.name, is_raw), ident.span).into())\n-        }\n-        Nonterminal::NtLifetime(ident) => {\n-            Some(tokenstream::TokenTree::token(token::Lifetime(ident.name), ident.span).into())\n-        }\n-        Nonterminal::NtMeta(ref attr) => convert_tokens(attr.tokens.as_ref()),\n-        Nonterminal::NtPath(ref path) => convert_tokens(path.tokens.as_ref()),\n-        Nonterminal::NtVis(ref vis) => convert_tokens(vis.tokens.as_ref()),\n-        Nonterminal::NtExpr(ref expr) | Nonterminal::NtLiteral(ref expr) => {\n-            prepend_attrs(&expr.attrs, expr.tokens.as_ref())\n-        }\n-    };\n-\n-    if let Some(tokens) = tokens {\n-        return tokens;\n-    } else if matches!(synthesize_tokens, CanSynthesizeMissingTokens::Yes) {\n-        return nt_fake_token_stream(sess, nt);\n-    } else {\n-        panic!(\n-            \"Missing tokens for nt {:?} at {:?}: {:?}\",\n-            nt,\n-            nt.span(),\n-            pprust::nonterminal_to_string(nt)\n-        );\n-    }\n-}\n-\n-fn prepend_attrs(attrs: &[Attribute], tokens: Option<&LazyTokenStream>) -> Option<TokenStream> {\n-    let tokens = tokens?;\n-    if attrs.is_empty() {\n-        return Some(tokens.create_token_stream().to_tokenstream());\n-    }\n-    let attr_data = AttributesData { attrs: attrs.to_vec().into(), tokens: tokens.clone() };\n-    let wrapped = AttrAnnotatedTokenStream::new(vec![(\n-        AttrAnnotatedTokenTree::Attributes(attr_data),\n-        Spacing::Alone,\n-    )]);\n-    Some(wrapped.to_tokenstream())\n-}\n-\n-pub fn fake_token_stream(sess: &ParseSess, node: &(impl AstPrettyPrint + HasSpan)) -> TokenStream {\n-    let source = node.pretty_print();\n-    let filename = FileName::macro_expansion_source_code(&source);\n-    parse_stream_from_source_str(filename, source, sess, Some(node.span()))\n-}\n-\n-fn nt_fake_token_stream(sess: &ParseSess, nt: &Nonterminal) -> TokenStream {\n-    let source = pprust::nonterminal_to_string(nt);\n+pub fn fake_token_stream_for_item(sess: &ParseSess, item: &ast::Item) -> TokenStream {\n+    let source = pprust::item_to_string(item);\n     let filename = FileName::macro_expansion_source_code(&source);\n-    parse_stream_from_source_str(filename, source, sess, Some(nt.span()))\n+    parse_stream_from_source_str(filename, source, sess, Some(item.span))\n }\n \n pub fn fake_token_stream_for_crate(sess: &ParseSess, krate: &ast::Crate) -> TokenStream {"}, {"sha": "bda7b314308a5ec1f993b9c879c6f92134363261", "filename": "compiler/rustc_session/src/utils.rs", "status": "modified", "additions": 0, "deletions": 58, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_session%2Fsrc%2Futils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8/compiler%2Frustc_session%2Fsrc%2Futils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_session%2Fsrc%2Futils.rs?ref=8e8fb4f49e7272b8dcbd25807a3ae8408ac41ce8", "patch": "@@ -1,13 +1,7 @@\n-use crate::parse::ParseSess;\n use crate::session::Session;\n-use rustc_ast::token::{self, Delimiter, Nonterminal, Token};\n-use rustc_ast::tokenstream::CanSynthesizeMissingTokens;\n-use rustc_ast::tokenstream::{DelimSpan, TokenStream, TokenTree};\n use rustc_data_structures::profiling::VerboseTimingGuard;\n use std::path::{Path, PathBuf};\n \n-pub type NtToTokenstream = fn(&Nonterminal, &ParseSess, CanSynthesizeMissingTokens) -> TokenStream;\n-\n impl Session {\n     pub fn timer<'a>(&'a self, what: &'static str) -> VerboseTimingGuard<'a> {\n         self.prof.verbose_generic_activity(what)\n@@ -94,55 +88,3 @@ impl CanonicalizedPath {\n         &self.original\n     }\n }\n-\n-// FIXME: Find a better spot for this - it needs to be accessible from `rustc_ast_lowering`,\n-// and needs to access `ParseSess\n-pub struct FlattenNonterminals<'a> {\n-    pub parse_sess: &'a ParseSess,\n-    pub synthesize_tokens: CanSynthesizeMissingTokens,\n-    pub nt_to_tokenstream: NtToTokenstream,\n-}\n-\n-impl<'a> FlattenNonterminals<'a> {\n-    pub fn process_token_stream(&mut self, tokens: TokenStream) -> TokenStream {\n-        fn can_skip(stream: &TokenStream) -> bool {\n-            stream.trees().all(|tree| match tree {\n-                TokenTree::Token(token) => !matches!(token.kind, token::Interpolated(_)),\n-                TokenTree::Delimited(_, _, inner) => can_skip(inner),\n-            })\n-        }\n-\n-        if can_skip(&tokens) {\n-            return tokens;\n-        }\n-\n-        tokens.into_trees().flat_map(|tree| self.process_token_tree(tree).into_trees()).collect()\n-    }\n-\n-    pub fn process_token_tree(&mut self, tree: TokenTree) -> TokenStream {\n-        match tree {\n-            TokenTree::Token(token) => self.process_token(token),\n-            TokenTree::Delimited(span, delim, tts) => {\n-                TokenTree::Delimited(span, delim, self.process_token_stream(tts)).into()\n-            }\n-        }\n-    }\n-\n-    pub fn process_token(&mut self, token: Token) -> TokenStream {\n-        match token.kind {\n-            token::Interpolated(nt) if let token::NtIdent(ident, is_raw) = *nt => {\n-                TokenTree::Token(Token::new(token::Ident(ident.name, is_raw), ident.span)).into()\n-            }\n-            token::Interpolated(nt) => {\n-                let tts = (self.nt_to_tokenstream)(&nt, self.parse_sess, self.synthesize_tokens);\n-                TokenTree::Delimited(\n-                    DelimSpan::from_single(token.span),\n-                    Delimiter::Invisible,\n-                    self.process_token_stream(tts),\n-                )\n-                .into()\n-            }\n-            _ => TokenTree::Token(token).into(),\n-        }\n-    }\n-}"}]}