{"sha": "8f24c2ec9d43d3c616652a4040b8c6a1672b18d8", "node_id": "MDY6Q29tbWl0NzI0NzEyOjhmMjRjMmVjOWQ0M2QzYzYxNjY1MmE0MDQwYjhjNmExNjcyYjE4ZDg=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-08-31T17:00:49Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-09-01T09:39:11Z"}, "message": "Don't emit trivia tokens", "tree": {"sha": "dfaa3548267b4db12b09b4ef1c94f5e0e1c9bcbc", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/dfaa3548267b4db12b09b4ef1c94f5e0e1c9bcbc"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8f24c2ec9d43d3c616652a4040b8c6a1672b18d8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8f24c2ec9d43d3c616652a4040b8c6a1672b18d8", "html_url": "https://github.com/rust-lang/rust/commit/8f24c2ec9d43d3c616652a4040b8c6a1672b18d8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8f24c2ec9d43d3c616652a4040b8c6a1672b18d8/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "445f34bb144c5b163163d8243e9845c644d3662d", "url": "https://api.github.com/repos/rust-lang/rust/commits/445f34bb144c5b163163d8243e9845c644d3662d", "html_url": "https://github.com/rust-lang/rust/commit/445f34bb144c5b163163d8243e9845c644d3662d"}], "stats": {"total": 129, "additions": 56, "deletions": 73}, "files": [{"sha": "034442b798b29b193264469a66c2477fd326026e", "filename": "compiler/rustc_parse/src/lexer/mod.rs", "status": "modified", "additions": 53, "deletions": 60, "changes": 113, "blob_url": "https://github.com/rust-lang/rust/blob/8f24c2ec9d43d3c616652a4040b8c6a1672b18d8/compiler%2Frustc_parse%2Fsrc%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8f24c2ec9d43d3c616652a4040b8c6a1672b18d8/compiler%2Frustc_parse%2Fsrc%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flexer%2Fmod.rs?ref=8f24c2ec9d43d3c616652a4040b8c6a1672b18d8", "patch": "@@ -1,5 +1,6 @@\n use rustc_ast::ast::AttrStyle;\n use rustc_ast::token::{self, CommentKind, Token, TokenKind};\n+use rustc_ast::tokenstream::IsJoint;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::{error_code, Applicability, DiagnosticBuilder, FatalError};\n use rustc_lexer::Base;\n@@ -65,42 +66,46 @@ impl<'a> StringReader<'a> {\n         self.override_span.unwrap_or_else(|| Span::with_root_ctxt(lo, hi))\n     }\n \n-    /// Returns the next token, including trivia like whitespace or comments.\n-    fn next_token(&mut self) -> Token {\n+    /// Returns the next token, and info about preceding whitespace, if any.\n+    fn next_token(&mut self) -> (IsJoint, Token) {\n+        let mut is_joint = IsJoint::Joint;\n+\n+        // Skip `#!` at the start of the file\n         let start_src_index = self.src_index(self.pos);\n         let text: &str = &self.src[start_src_index..self.end_src_index];\n-\n-        if text.is_empty() {\n-            let span = self.mk_sp(self.pos, self.pos);\n-            return Token::new(token::Eof, span);\n+        let is_beginning_of_file = self.pos == self.start_pos;\n+        if is_beginning_of_file {\n+            if let Some(shebang_len) = rustc_lexer::strip_shebang(text) {\n+                self.pos = self.pos + BytePos::from_usize(shebang_len);\n+                is_joint = IsJoint::NonJoint;\n+            }\n         }\n \n-        {\n-            let is_beginning_of_file = self.pos == self.start_pos;\n-            if is_beginning_of_file {\n-                if let Some(shebang_len) = rustc_lexer::strip_shebang(text) {\n-                    let start = self.pos;\n-                    self.pos = self.pos + BytePos::from_usize(shebang_len);\n+        // Skip trivial (whitespace & comments) tokens\n+        loop {\n+            let start_src_index = self.src_index(self.pos);\n+            let text: &str = &self.src[start_src_index..self.end_src_index];\n \n-                    let sym = self.symbol_from(start + BytePos::from_usize(\"#!\".len()));\n-                    let kind = token::Shebang(sym);\n-\n-                    let span = self.mk_sp(start, self.pos);\n-                    return Token::new(kind, span);\n-                }\n+            if text.is_empty() {\n+                let span = self.mk_sp(self.pos, self.pos);\n+                return (is_joint, Token::new(token::Eof, span));\n             }\n-        }\n \n-        let token = rustc_lexer::first_token(text);\n+            let token = rustc_lexer::first_token(text);\n \n-        let start = self.pos;\n-        self.pos = self.pos + BytePos::from_usize(token.len);\n+            let start = self.pos;\n+            self.pos = self.pos + BytePos::from_usize(token.len);\n \n-        debug!(\"try_next_token: {:?}({:?})\", token.kind, self.str_from(start));\n+            debug!(\"next_token: {:?}({:?})\", token.kind, self.str_from(start));\n \n-        let kind = self.cook_lexer_token(token.kind, start);\n-        let span = self.mk_sp(start, self.pos);\n-        Token::new(kind, span)\n+            match self.cook_lexer_token(token.kind, start) {\n+                Some(kind) => {\n+                    let span = self.mk_sp(start, self.pos);\n+                    return (is_joint, Token::new(kind, span));\n+                }\n+                None => is_joint = IsJoint::NonJoint,\n+            }\n+        }\n     }\n \n     /// Report a fatal lexical error with a given span.\n@@ -140,19 +145,16 @@ impl<'a> StringReader<'a> {\n     /// Turns simple `rustc_lexer::TokenKind` enum into a rich\n     /// `librustc_ast::TokenKind`. This turns strings into interned\n     /// symbols and runs additional validation.\n-    fn cook_lexer_token(&self, token: rustc_lexer::TokenKind, start: BytePos) -> TokenKind {\n-        match token {\n+    fn cook_lexer_token(&self, token: rustc_lexer::TokenKind, start: BytePos) -> Option<TokenKind> {\n+        Some(match token {\n             rustc_lexer::TokenKind::LineComment { doc_style } => {\n-                match doc_style {\n-                    Some(doc_style) => {\n-                        // Opening delimiter of the length 3 is not included into the symbol.\n-                        let content_start = start + BytePos(3);\n-                        let content = self.str_from(content_start);\n+                // Skip non-doc comments\n+                let doc_style = doc_style?;\n \n-                        self.cook_doc_comment(content_start, content, CommentKind::Line, doc_style)\n-                    }\n-                    None => token::Comment,\n-                }\n+                // Opening delimiter of the length 3 is not included into the symbol.\n+                let content_start = start + BytePos(3);\n+                let content = self.str_from(content_start);\n+                self.cook_doc_comment(content_start, content, CommentKind::Line, doc_style)\n             }\n             rustc_lexer::TokenKind::BlockComment { doc_style, terminated } => {\n                 if !terminated {\n@@ -171,20 +173,18 @@ impl<'a> StringReader<'a> {\n                         .emit();\n                     FatalError.raise();\n                 }\n-                match doc_style {\n-                    Some(doc_style) => {\n-                        // Opening delimiter of the length 3 and closing delimiter of the length 2\n-                        // are not included into the symbol.\n-                        let content_start = start + BytePos(3);\n-                        let content_end = self.pos - BytePos(if terminated { 2 } else { 0 });\n-                        let content = self.str_from_to(content_start, content_end);\n-\n-                        self.cook_doc_comment(content_start, content, CommentKind::Block, doc_style)\n-                    }\n-                    None => token::Comment,\n-                }\n+\n+                // Skip non-doc comments\n+                let doc_style = doc_style?;\n+\n+                // Opening delimiter of the length 3 and closing delimiter of the length 2\n+                // are not included into the symbol.\n+                let content_start = start + BytePos(3);\n+                let content_end = self.pos - BytePos(if terminated { 2 } else { 0 });\n+                let content = self.str_from_to(content_start, content_end);\n+                self.cook_doc_comment(content_start, content, CommentKind::Block, doc_style)\n             }\n-            rustc_lexer::TokenKind::Whitespace => token::Whitespace,\n+            rustc_lexer::TokenKind::Whitespace => return None,\n             rustc_lexer::TokenKind::Ident | rustc_lexer::TokenKind::RawIdent => {\n                 let is_raw_ident = token == rustc_lexer::TokenKind::RawIdent;\n                 let mut ident_start = start;\n@@ -282,12 +282,11 @@ impl<'a> StringReader<'a> {\n                 // this should be inside `rustc_lexer`. However, we should first remove compound\n                 // tokens like `<<` from `rustc_lexer`, and then add fancier error recovery to it,\n                 // as there will be less overall work to do this way.\n-                let token = unicode_chars::check_for_substitution(self, start, c, &mut err)\n-                    .unwrap_or_else(|| token::Unknown(self.symbol_from(start)));\n+                let token = unicode_chars::check_for_substitution(self, start, c, &mut err);\n                 err.emit();\n-                token\n+                token?\n             }\n-        }\n+        })\n     }\n \n     fn cook_doc_comment(\n@@ -450,12 +449,6 @@ impl<'a> StringReader<'a> {\n         self.str_from_to(start, self.pos)\n     }\n \n-    /// Creates a Symbol from a given offset to the current offset.\n-    fn symbol_from(&self, start: BytePos) -> Symbol {\n-        debug!(\"taking an ident from {:?} to {:?}\", start, self.pos);\n-        Symbol::intern(self.str_from(start))\n-    }\n-\n     /// As symbol_from, with an explicit endpoint.\n     fn symbol_from_to(&self, start: BytePos, end: BytePos) -> Symbol {\n         debug!(\"taking an ident from {:?} to {:?}\", start, end);"}, {"sha": "6e13bfb9c9d37a7be26592121c832c4003983553", "filename": "compiler/rustc_parse/src/lexer/tokentrees.rs", "status": "modified", "additions": 3, "deletions": 13, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/8f24c2ec9d43d3c616652a4040b8c6a1672b18d8/compiler%2Frustc_parse%2Fsrc%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8f24c2ec9d43d3c616652a4040b8c6a1672b18d8/compiler%2Frustc_parse%2Fsrc%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flexer%2Ftokentrees.rs?ref=8f24c2ec9d43d3c616652a4040b8c6a1672b18d8", "patch": "@@ -272,19 +272,9 @@ impl<'a> TokenTreesReader<'a> {\n     }\n \n     fn real_token(&mut self) {\n-        self.joint_to_prev = Joint;\n-        loop {\n-            let token = self.string_reader.next_token();\n-            match token.kind {\n-                token::Whitespace | token::Comment | token::Shebang(_) | token::Unknown(_) => {\n-                    self.joint_to_prev = NonJoint;\n-                }\n-                _ => {\n-                    self.token = token;\n-                    return;\n-                }\n-            }\n-        }\n+        let (joint_to_prev, token) = self.string_reader.next_token();\n+        self.joint_to_prev = joint_to_prev;\n+        self.token = token;\n     }\n }\n "}]}