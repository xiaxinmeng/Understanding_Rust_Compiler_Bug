{"sha": "1e848a564b12e3e1dff2da48e1762c983b9bda3e", "node_id": "C_kwDOAAsO6NoAKDFlODQ4YTU2NGIxMmUzZTFkZmYyZGE0OGUxNzYyYzk4M2I5YmRhM2U", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-10-04T23:38:15Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-10-05T01:42:54Z"}, "message": "Remove `TokenStreamBuilder`.\n\n`TokenStreamBuilder` exists to concatenate multiple `TokenStream`s\ntogether. This commit removes it, and moves the concatenation\nfunctionality directly into `TokenStream`, via two new methods\n`push_tree` and `push_stream`. This makes things both simpler and\nfaster.\n\n`push_tree` is particularly important. `TokenStreamBuilder` only had a\nsingle `push` method, which pushed a stream. But in practice most of the\ntime we push a single token tree rather than a stream, and `push_tree`\navoids the need to build a token stream with a single entry (which\nrequires two allocations, one for the `Lrc` and one for the `Vec`).\n\nThe main `push_tree` use arises from a change to one of the `ToInternal`\nimpls in `proc_macro_server.rs`. It now returns a `SmallVec` instead of\na `TokenStream`. This return value is then iterated over by\n`concat_trees`, which does `push_tree` on each element. Furthermore, the\nuse of `SmallVec` avoids more allocations, because there is always only\none or two token trees.\n\nNote: the removed `TokenStreamBuilder::push` method had some code to\ndeal with a quadratic blowup case from #57735. This commit removes the\ncode. I tried and failed to reproduce the blowup from that PR, before\nand after this change. Various other changes have happened to\n`TokenStreamBuilder` in the meantime, so I suspect the original problem\nis no longer relevant, though I don't have proof of this. Generally\nspeaking, repeatedly extending a `Vec` without pre-determining its\ncapacity is *not* quadratic. It's also incredibly common, within rustc\nand many other Rust programs, so if there were performance problems\nthere you'd think it would show up in other places, too.", "tree": {"sha": "c05a70faf5844508ef80919561d9f060d1bd24cf", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c05a70faf5844508ef80919561d9f060d1bd24cf"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1e848a564b12e3e1dff2da48e1762c983b9bda3e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1e848a564b12e3e1dff2da48e1762c983b9bda3e", "html_url": "https://github.com/rust-lang/rust/commit/1e848a564b12e3e1dff2da48e1762c983b9bda3e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1e848a564b12e3e1dff2da48e1762c983b9bda3e/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1e8dc45fb502c39a81ddda532d35a4c3dbd6b4ad", "url": "https://api.github.com/repos/rust-lang/rust/commits/1e8dc45fb502c39a81ddda532d35a4c3dbd6b4ad", "html_url": "https://github.com/rust-lang/rust/commit/1e8dc45fb502c39a81ddda532d35a4c3dbd6b4ad"}], "stats": {"total": 202, "additions": 87, "deletions": 115}, "files": [{"sha": "1d3c4fcca0a44e9c10a647481d2b54ba3eee11d5", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 45, "deletions": 72, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/1e848a564b12e3e1dff2da48e1762c983b9bda3e/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1e848a564b12e3e1dff2da48e1762c983b9bda3e/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=1e848a564b12e3e1dff2da48e1762c983b9bda3e", "patch": "@@ -245,12 +245,12 @@ impl AttrTokenStream {\n                                 // properly implemented - we always synthesize fake tokens,\n                                 // so we never reach this code.\n \n-                                let mut builder = TokenStreamBuilder::new();\n+                                let mut stream = TokenStream::default();\n                                 for inner_attr in inner_attrs {\n-                                    builder.push(inner_attr.tokens());\n+                                    stream.push_stream(inner_attr.tokens());\n                                 }\n-                                builder.push(delim_tokens.clone());\n-                                *tree = TokenTree::Delimited(*span, *delim, builder.build());\n+                                stream.push_stream(delim_tokens.clone());\n+                                *tree = TokenTree::Delimited(*span, *delim, stream);\n                                 found = true;\n                                 break;\n                             }\n@@ -505,76 +505,49 @@ impl TokenStream {\n \n         self.trees().map(|tree| TokenStream::flatten_token_tree(tree)).collect()\n     }\n-}\n \n-// 99.5%+ of the time we have 1 or 2 elements in this vector.\n-#[derive(Clone)]\n-pub struct TokenStreamBuilder(SmallVec<[TokenStream; 2]>);\n-\n-impl TokenStreamBuilder {\n-    pub fn new() -> TokenStreamBuilder {\n-        TokenStreamBuilder(SmallVec::new())\n-    }\n-\n-    pub fn push(&mut self, stream: TokenStream) {\n-        self.0.push(stream);\n-    }\n-\n-    pub fn build(self) -> TokenStream {\n-        let mut streams = self.0;\n-        match streams.len() {\n-            0 => TokenStream::default(),\n-            1 => streams.pop().unwrap(),\n-            _ => {\n-                // We will extend the first stream in `streams` with the\n-                // elements from the subsequent streams. This requires using\n-                // `make_mut()` on the first stream, and in practice this\n-                // doesn't cause cloning 99.9% of the time.\n-                //\n-                // One very common use case is when `streams` has two elements,\n-                // where the first stream has any number of elements within\n-                // (often 1, but sometimes many more) and the second stream has\n-                // a single element within.\n-\n-                // Determine how much the first stream will be extended.\n-                // Needed to avoid quadratic blow up from on-the-fly\n-                // reallocations (#57735).\n-                let num_appends = streams.iter().skip(1).map(|ts| ts.len()).sum();\n-\n-                // Get the first stream, which will become the result stream.\n-                // If it's `None`, create an empty stream.\n-                let mut iter = streams.into_iter();\n-                let mut res_stream_lrc = iter.next().unwrap().0;\n-\n-                // Append the subsequent elements to the result stream, after\n-                // reserving space for them.\n-                let res_vec_mut = Lrc::make_mut(&mut res_stream_lrc);\n-                res_vec_mut.reserve(num_appends);\n-                for stream in iter {\n-                    let stream_iter = stream.0.iter().cloned();\n-\n-                    // If (a) `res_mut_vec` is not empty and the last tree\n-                    // within it is a token tree marked with `Joint`, and (b)\n-                    // `stream` is not empty and the first tree within it is a\n-                    // token tree, and (c) the two tokens can be glued\n-                    // together...\n-                    if let Some(TokenTree::Token(last_tok, Spacing::Joint)) = res_vec_mut.last()\n-                        && let Some(TokenTree::Token(tok, spacing)) = stream.0.first()\n-                        && let Some(glued_tok) = last_tok.glue(&tok)\n-                    {\n-                        // ...then overwrite the last token tree in\n-                        // `res_vec_mut` with the glued token, and skip the\n-                        // first token tree from `stream`.\n-                        *res_vec_mut.last_mut().unwrap() = TokenTree::Token(glued_tok, *spacing);\n-                        res_vec_mut.extend(stream_iter.skip(1));\n-                    } else {\n-                        // Append all of `stream`.\n-                        res_vec_mut.extend(stream_iter);\n-                    }\n-                }\n+    // If `vec` is not empty, try to glue `tt` onto its last token. The return\n+    // value indicates if gluing took place.\n+    fn try_glue_to_last(vec: &mut Vec<TokenTree>, tt: &TokenTree) -> bool {\n+        if let Some(TokenTree::Token(last_tok, Spacing::Joint)) = vec.last()\n+            && let TokenTree::Token(tok, spacing) = tt\n+            && let Some(glued_tok) = last_tok.glue(&tok)\n+        {\n+            // ...then overwrite the last token tree in `vec` with the\n+            // glued token, and skip the first token tree from `stream`.\n+            *vec.last_mut().unwrap() = TokenTree::Token(glued_tok, *spacing);\n+            true\n+        } else {\n+            false\n+        }\n+    }\n \n-                TokenStream(res_stream_lrc)\n-            }\n+    // Push `tt` onto the end of the stream, possibly gluing it to the last\n+    // token. Uses `make_mut` to maximize efficiency.\n+    pub fn push_tree(&mut self, tt: TokenTree) {\n+        let vec_mut = Lrc::make_mut(&mut self.0);\n+\n+        if Self::try_glue_to_last(vec_mut, &tt) {\n+            // nothing else to do\n+        } else {\n+            vec_mut.push(tt);\n+        }\n+    }\n+\n+    // Push `stream` onto the end of the stream, possibly gluing the first\n+    // token tree to the last token. (No other token trees will be glued.)\n+    // Uses `make_mut` to maximize efficiency.\n+    pub fn push_stream(&mut self, stream: TokenStream) {\n+        let vec_mut = Lrc::make_mut(&mut self.0);\n+\n+        let stream_iter = stream.0.iter().cloned();\n+\n+        if let Some(first) = stream.0.first() && Self::try_glue_to_last(vec_mut, first) {\n+            // Now skip the first token tree from `stream`.\n+            vec_mut.extend(stream_iter.skip(1));\n+        } else {\n+            // Append all of `stream`.\n+            vec_mut.extend(stream_iter);\n         }\n     }\n }"}, {"sha": "24762b8346b12077a95b2a11e3bb900151436674", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 34, "deletions": 33, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/1e848a564b12e3e1dff2da48e1762c983b9bda3e/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1e848a564b12e3e1dff2da48e1762c983b9bda3e/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=1e848a564b12e3e1dff2da48e1762c983b9bda3e", "patch": "@@ -1,5 +1,8 @@\n use crate::base::ExtCtxt;\n-\n+use pm::bridge::{\n+    server, DelimSpan, Diagnostic, ExpnGlobals, Group, Ident, LitKind, Literal, Punct, TokenTree,\n+};\n+use pm::{Delimiter, Level, LineColumn};\n use rustc_ast as ast;\n use rustc_ast::token;\n use rustc_ast::tokenstream::{self, Spacing::*, TokenStream};\n@@ -13,11 +16,7 @@ use rustc_session::parse::ParseSess;\n use rustc_span::def_id::CrateNum;\n use rustc_span::symbol::{self, sym, Symbol};\n use rustc_span::{BytePos, FileName, Pos, SourceFile, Span};\n-\n-use pm::bridge::{\n-    server, DelimSpan, Diagnostic, ExpnGlobals, Group, Ident, LitKind, Literal, Punct, TokenTree,\n-};\n-use pm::{Delimiter, Level, LineColumn};\n+use smallvec::{smallvec, SmallVec};\n use std::ops::Bound;\n \n trait FromInternal<T> {\n@@ -241,8 +240,11 @@ impl FromInternal<(TokenStream, &mut Rustc<'_, '_>)> for Vec<TokenTree<TokenStre\n     }\n }\n \n-impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rustc<'_, '_>) {\n-    fn to_internal(self) -> TokenStream {\n+// We use a `SmallVec` because the output size is always one or two `TokenTree`s.\n+impl ToInternal<SmallVec<[tokenstream::TokenTree; 2]>>\n+    for (TokenTree<TokenStream, Span, Symbol>, &mut Rustc<'_, '_>)\n+{\n+    fn to_internal(self) -> SmallVec<[tokenstream::TokenTree; 2]> {\n         use rustc_ast::token::*;\n \n         let (tree, rustc) = self;\n@@ -273,22 +275,22 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n                     b'\\'' => SingleQuote,\n                     _ => unreachable!(),\n                 };\n-                if joint {\n-                    tokenstream::TokenStream::token_joint(kind, span)\n+                smallvec![if joint {\n+                    tokenstream::TokenTree::token_joint(kind, span)\n                 } else {\n-                    tokenstream::TokenStream::token_alone(kind, span)\n-                }\n+                    tokenstream::TokenTree::token_alone(kind, span)\n+                }]\n             }\n             TokenTree::Group(Group { delimiter, stream, span: DelimSpan { open, close, .. } }) => {\n-                tokenstream::TokenStream::delimited(\n+                smallvec![tokenstream::TokenTree::Delimited(\n                     tokenstream::DelimSpan { open, close },\n                     delimiter.to_internal(),\n                     stream.unwrap_or_default(),\n-                )\n+                )]\n             }\n             TokenTree::Ident(self::Ident { sym, is_raw, span }) => {\n                 rustc.sess().symbol_gallery.insert(sym, span);\n-                tokenstream::TokenStream::token_alone(Ident(sym, is_raw), span)\n+                smallvec![tokenstream::TokenTree::token_alone(Ident(sym, is_raw), span)]\n             }\n             TokenTree::Literal(self::Literal {\n                 kind: self::LitKind::Integer,\n@@ -301,7 +303,7 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n                 let integer = TokenKind::lit(token::Integer, symbol, suffix);\n                 let a = tokenstream::TokenTree::token_alone(minus, span);\n                 let b = tokenstream::TokenTree::token_alone(integer, span);\n-                [a, b].into_iter().collect()\n+                smallvec![a, b]\n             }\n             TokenTree::Literal(self::Literal {\n                 kind: self::LitKind::Float,\n@@ -314,13 +316,13 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n                 let float = TokenKind::lit(token::Float, symbol, suffix);\n                 let a = tokenstream::TokenTree::token_alone(minus, span);\n                 let b = tokenstream::TokenTree::token_alone(float, span);\n-                [a, b].into_iter().collect()\n+                smallvec![a, b]\n             }\n             TokenTree::Literal(self::Literal { kind, symbol, suffix, span }) => {\n-                tokenstream::TokenStream::token_alone(\n+                smallvec![tokenstream::TokenTree::token_alone(\n                     TokenKind::lit(kind.to_internal(), symbol, suffix),\n                     span,\n-                )\n+                )]\n             }\n         }\n     }\n@@ -536,37 +538,35 @@ impl server::TokenStream for Rustc<'_, '_> {\n         &mut self,\n         tree: TokenTree<Self::TokenStream, Self::Span, Self::Symbol>,\n     ) -> Self::TokenStream {\n-        (tree, &mut *self).to_internal()\n+        Self::TokenStream::new((tree, &mut *self).to_internal().into_iter().collect::<Vec<_>>())\n     }\n \n     fn concat_trees(\n         &mut self,\n         base: Option<Self::TokenStream>,\n         trees: Vec<TokenTree<Self::TokenStream, Self::Span, Self::Symbol>>,\n     ) -> Self::TokenStream {\n-        let mut builder = tokenstream::TokenStreamBuilder::new();\n-        if let Some(base) = base {\n-            builder.push(base);\n-        }\n+        let mut stream =\n+            if let Some(base) = base { base } else { tokenstream::TokenStream::default() };\n         for tree in trees {\n-            builder.push((tree, &mut *self).to_internal());\n+            for tt in (tree, &mut *self).to_internal() {\n+                stream.push_tree(tt);\n+            }\n         }\n-        builder.build()\n+        stream\n     }\n \n     fn concat_streams(\n         &mut self,\n         base: Option<Self::TokenStream>,\n         streams: Vec<Self::TokenStream>,\n     ) -> Self::TokenStream {\n-        let mut builder = tokenstream::TokenStreamBuilder::new();\n-        if let Some(base) = base {\n-            builder.push(base);\n-        }\n-        for stream in streams {\n-            builder.push(stream);\n+        let mut stream =\n+            if let Some(base) = base { base } else { tokenstream::TokenStream::default() };\n+        for s in streams {\n+            stream.push_stream(s);\n         }\n-        builder.build()\n+        stream\n     }\n \n     fn into_trees(\n@@ -692,6 +692,7 @@ impl server::Span for Rustc<'_, '_> {\n     fn source_text(&mut self, span: Self::Span) -> Option<String> {\n         self.sess().source_map().span_to_snippet(span).ok()\n     }\n+\n     /// Saves the provided span into the metadata of\n     /// *the crate we are currently compiling*, which must\n     /// be a proc-macro crate. This id can be passed to"}, {"sha": "91c4dd732e3a5108b932988d8da821bdfafa8b58", "filename": "compiler/rustc_expand/src/tokenstream/tests.rs", "status": "modified", "additions": 8, "deletions": 10, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/1e848a564b12e3e1dff2da48e1762c983b9bda3e/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1e848a564b12e3e1dff2da48e1762c983b9bda3e/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs?ref=1e848a564b12e3e1dff2da48e1762c983b9bda3e", "patch": "@@ -1,7 +1,7 @@\n use crate::tests::string_to_stream;\n \n use rustc_ast::token;\n-use rustc_ast::tokenstream::{TokenStream, TokenStreamBuilder};\n+use rustc_ast::tokenstream::{TokenStream, TokenTree};\n use rustc_span::create_default_session_globals_then;\n use rustc_span::{BytePos, Span, Symbol};\n \n@@ -19,10 +19,9 @@ fn test_concat() {\n         let test_res = string_to_ts(\"foo::bar::baz\");\n         let test_fst = string_to_ts(\"foo::bar\");\n         let test_snd = string_to_ts(\"::baz\");\n-        let mut builder = TokenStreamBuilder::new();\n-        builder.push(test_fst);\n-        builder.push(test_snd);\n-        let eq_res = builder.build();\n+        let mut eq_res = TokenStream::default();\n+        eq_res.push_stream(test_fst);\n+        eq_res.push_stream(test_snd);\n         assert_eq!(test_res.trees().count(), 5);\n         assert_eq!(eq_res.trees().count(), 5);\n         assert_eq!(test_res.eq_unspanned(&eq_res), true);\n@@ -99,11 +98,10 @@ fn test_is_empty() {\n #[test]\n fn test_dotdotdot() {\n     create_default_session_globals_then(|| {\n-        let mut builder = TokenStreamBuilder::new();\n-        builder.push(TokenStream::token_joint(token::Dot, sp(0, 1)));\n-        builder.push(TokenStream::token_joint(token::Dot, sp(1, 2)));\n-        builder.push(TokenStream::token_alone(token::Dot, sp(2, 3)));\n-        let stream = builder.build();\n+        let mut stream = TokenStream::default();\n+        stream.push_tree(TokenTree::token_joint(token::Dot, sp(0, 1)));\n+        stream.push_tree(TokenTree::token_joint(token::Dot, sp(1, 2)));\n+        stream.push_tree(TokenTree::token_alone(token::Dot, sp(2, 3)));\n         assert!(stream.eq_unspanned(&string_to_ts(\"...\")));\n         assert_eq!(stream.trees().count(), 1);\n     })"}]}