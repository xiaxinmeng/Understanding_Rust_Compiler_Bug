{"sha": "d6134b680230a56f8f39f31fa6578b7876eded8f", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ2MTM0YjY4MDIzMGE1NmY4ZjM5ZjMxZmE2NTc4Yjc4NzZlZGVkOGY=", "commit": {"author": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2021-08-25T16:57:24Z"}, "committer": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2021-08-25T16:57:24Z"}, "message": "Don't mutate syntax trees when preparing proc-macro input", "tree": {"sha": "4cd6f059f698600a4750ee5529b0a02d44591fd4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4cd6f059f698600a4750ee5529b0a02d44591fd4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d6134b680230a56f8f39f31fa6578b7876eded8f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d6134b680230a56f8f39f31fa6578b7876eded8f", "html_url": "https://github.com/rust-lang/rust/commit/d6134b680230a56f8f39f31fa6578b7876eded8f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d6134b680230a56f8f39f31fa6578b7876eded8f/comments", "author": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ce4670f299d72a0f23f347b5df9790aca72da617", "url": "https://api.github.com/repos/rust-lang/rust/commits/ce4670f299d72a0f23f347b5df9790aca72da617", "html_url": "https://github.com/rust-lang/rust/commit/ce4670f299d72a0f23f347b5df9790aca72da617"}], "stats": {"total": 194, "additions": 58, "deletions": 136}, "files": [{"sha": "c82dc0bc9afa953c4ab01ce5dac0098ed9400b38", "filename": "Cargo.lock", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d6134b680230a56f8f39f31fa6578b7876eded8f/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/d6134b680230a56f8f39f31fa6578b7876eded8f/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=d6134b680230a56f8f39f31fa6578b7876eded8f", "patch": "@@ -511,6 +511,7 @@ dependencies = [\n  \"cov-mark\",\n  \"either\",\n  \"expect-test\",\n+ \"itertools\",\n  \"la-arena\",\n  \"limit\",\n  \"log\","}, {"sha": "743e8079103c8984b693c7a07e581d1d29a8d182", "filename": "crates/hir_expand/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fhir_expand%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fhir_expand%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2FCargo.toml?ref=d6134b680230a56f8f39f31fa6578b7876eded8f", "patch": "@@ -14,6 +14,7 @@ log = \"0.4.8\"\n either = \"1.5.3\"\n rustc-hash = \"1.0.0\"\n la-arena = { version = \"0.2.0\", path = \"../../lib/arena\" }\n+itertools = \"0.10.0\"\n \n base_db = { path = \"../base_db\", version = \"0.0.0\" }\n cfg = { path = \"../cfg\", version = \"0.0.0\" }"}, {"sha": "964e4e96d66da149387683e467ea360e3c6d92c6", "filename": "crates/hir_expand/src/db.rs", "status": "modified", "additions": 27, "deletions": 8, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fdb.rs?ref=d6134b680230a56f8f39f31fa6578b7876eded8f", "patch": "@@ -3,19 +3,20 @@\n use std::sync::Arc;\n \n use base_db::{salsa, SourceDatabase};\n+use itertools::Itertools;\n use limit::Limit;\n use mbe::{ExpandError, ExpandResult};\n use parser::{FragmentKind, T};\n use syntax::{\n     algo::diff,\n-    ast::{self, NameOwner},\n-    AstNode, GreenNode, Parse, SyntaxNode, SyntaxToken,\n+    ast::{self, AttrsOwner, NameOwner},\n+    AstNode, GreenNode, Parse, SyntaxNode, SyntaxToken, TextRange,\n };\n \n use crate::{\n-    ast_id_map::AstIdMap, hygiene::HygieneFrame, input::process_macro_input, BuiltinAttrExpander,\n-    BuiltinDeriveExpander, BuiltinFnLikeExpander, HirFileId, HirFileIdRepr, MacroCallId,\n-    MacroCallKind, MacroCallLoc, MacroDefId, MacroDefKind, MacroFile, ProcMacroExpander,\n+    ast_id_map::AstIdMap, hygiene::HygieneFrame, BuiltinAttrExpander, BuiltinDeriveExpander,\n+    BuiltinFnLikeExpander, HirFileId, HirFileIdRepr, MacroCallId, MacroCallKind, MacroCallLoc,\n+    MacroDefId, MacroDefKind, MacroFile, ProcMacroExpander,\n };\n \n /// Total limit on the number of tokens produced by any macro invocation.\n@@ -257,9 +258,28 @@ fn parse_macro_expansion(\n \n fn macro_arg(db: &dyn AstDatabase, id: MacroCallId) -> Option<Arc<(tt::Subtree, mbe::TokenMap)>> {\n     let arg = db.macro_arg_text(id)?;\n-    let (mut tt, tmap) = mbe::syntax_node_to_token_tree(&SyntaxNode::new_root(arg));\n+    let loc = db.lookup_intern_macro(id);\n+\n+    let node = SyntaxNode::new_root(arg);\n+    let censor = match loc.kind {\n+        MacroCallKind::FnLike { .. } => None,\n+        MacroCallKind::Derive { derive_attr_index, .. } => match ast::Item::cast(node.clone()) {\n+            Some(item) => item\n+                .attrs()\n+                .map(|attr| attr.syntax().text_range())\n+                .take(derive_attr_index as usize + 1)\n+                .fold1(TextRange::cover),\n+            None => None,\n+        },\n+        MacroCallKind::Attr { invoc_attr_index, .. } => match ast::Item::cast(node.clone()) {\n+            Some(item) => {\n+                item.attrs().nth(invoc_attr_index as usize).map(|attr| attr.syntax().text_range())\n+            }\n+            None => None,\n+        },\n+    };\n+    let (mut tt, tmap) = mbe::syntax_node_to_token_tree_censored(&node, censor);\n \n-    let loc: MacroCallLoc = db.lookup_intern_macro(id);\n     if loc.def.is_proc_macro() {\n         // proc macros expect their inputs without parentheses, MBEs expect it with them included\n         tt.delimiter = None;\n@@ -271,7 +291,6 @@ fn macro_arg(db: &dyn AstDatabase, id: MacroCallId) -> Option<Arc<(tt::Subtree,\n fn macro_arg_text(db: &dyn AstDatabase, id: MacroCallId) -> Option<GreenNode> {\n     let loc = db.lookup_intern_macro(id);\n     let arg = loc.kind.arg(db)?;\n-    let arg = process_macro_input(&loc.kind, arg);\n     if matches!(loc.kind, MacroCallKind::FnLike { .. }) {\n         let first = arg.first_child_or_token().map_or(T![.], |it| it.kind());\n         let last = arg.last_child_or_token().map_or(T![.], |it| it.kind());"}, {"sha": "0ad48a470b2953c42a8aa07437ea623afce99d15", "filename": "crates/hir_expand/src/input.rs", "status": "removed", "additions": 0, "deletions": 120, "changes": 120, "blob_url": "https://github.com/rust-lang/rust/blob/ce4670f299d72a0f23f347b5df9790aca72da617/crates%2Fhir_expand%2Fsrc%2Finput.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ce4670f299d72a0f23f347b5df9790aca72da617/crates%2Fhir_expand%2Fsrc%2Finput.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Finput.rs?ref=ce4670f299d72a0f23f347b5df9790aca72da617", "patch": "@@ -1,120 +0,0 @@\n-//! Macro input conditioning.\n-\n-use syntax::{\n-    ast::{self, make, AttrsOwner},\n-    AstNode, SyntaxNode,\n-};\n-\n-use crate::{\n-    name::{name, AsName},\n-    MacroCallKind,\n-};\n-\n-pub(crate) fn process_macro_input(macro_call_kind: &MacroCallKind, node: SyntaxNode) -> SyntaxNode {\n-    match macro_call_kind {\n-        MacroCallKind::FnLike { .. } => node,\n-        MacroCallKind::Derive { derive_attr_index, .. } => {\n-            let item = match ast::Item::cast(node.clone()) {\n-                Some(item) => item,\n-                None => return node,\n-            };\n-\n-            remove_derives_up_to(item, *derive_attr_index as usize).syntax().clone()\n-        }\n-        MacroCallKind::Attr { invoc_attr_index, .. } => {\n-            let item = match ast::Item::cast(node.clone()) {\n-                Some(item) => item,\n-                None => return node,\n-            };\n-\n-            remove_attr_invoc(item, *invoc_attr_index as usize).syntax().clone()\n-        }\n-    }\n-}\n-\n-/// Removes `#[derive]` attributes from `item`, up to `attr_index`.\n-fn remove_derives_up_to(item: ast::Item, attr_index: usize) -> ast::Item {\n-    let item = item.clone_for_update();\n-    for attr in item.attrs().take(attr_index + 1) {\n-        if let Some(name) =\n-            attr.path().and_then(|path| path.as_single_segment()).and_then(|seg| seg.name_ref())\n-        {\n-            if name.as_name() == name![derive] {\n-                replace_attr(&item, &attr);\n-            }\n-        }\n-    }\n-    item\n-}\n-\n-/// Removes the attribute invoking an attribute macro from `item`.\n-fn remove_attr_invoc(item: ast::Item, attr_index: usize) -> ast::Item {\n-    let item = item.clone_for_update();\n-    let attr = item\n-        .attrs()\n-        .nth(attr_index)\n-        .unwrap_or_else(|| panic!(\"cannot find attribute #{}\", attr_index));\n-    replace_attr(&item, &attr);\n-    item\n-}\n-\n-fn replace_attr(item: &ast::Item, attr: &ast::Attr) {\n-    let syntax_index = attr.syntax().index();\n-    let ws = make::tokens::whitespace(&\" \".repeat(u32::from(attr.syntax().text().len()) as usize));\n-    item.syntax().splice_children(syntax_index..syntax_index + 1, vec![ws.into()]);\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use base_db::{fixture::WithFixture, SourceDatabase};\n-    use expect_test::{expect, Expect};\n-\n-    use crate::test_db::TestDB;\n-\n-    use super::*;\n-\n-    fn test_remove_derives_up_to(attr: usize, ra_fixture: &str, expect: Expect) {\n-        let (db, file_id) = TestDB::with_single_file(ra_fixture);\n-        let parsed = db.parse(file_id);\n-\n-        let mut items: Vec<_> =\n-            parsed.syntax_node().descendants().filter_map(ast::Item::cast).collect();\n-        assert_eq!(items.len(), 1);\n-\n-        let item = remove_derives_up_to(items.pop().unwrap(), attr);\n-        let res: String =\n-            item.syntax().children_with_tokens().map(|e| format!(\"{:?}\\n\", e)).collect();\n-        expect.assert_eq(&res);\n-    }\n-\n-    #[test]\n-    fn remove_derive() {\n-        test_remove_derives_up_to(\n-            2,\n-            r#\"\n-#[allow(unused)]\n-#[derive(Copy)]\n-#[derive(Hello)]\n-#[derive(Clone)]\n-struct A {\n-    bar: u32\n-}\n-        \"#,\n-            expect![[r#\"\n-                Node(ATTR@0..16)\n-                Token(WHITESPACE@16..17 \"\\n\")\n-                Token(WHITESPACE@17..32 \"               \")\n-                Token(WHITESPACE@32..33 \"\\n\")\n-                Token(WHITESPACE@33..49 \"                \")\n-                Token(WHITESPACE@49..50 \"\\n\")\n-                Node(ATTR@50..66)\n-                Token(WHITESPACE@66..67 \"\\n\")\n-                Token(STRUCT_KW@67..73 \"struct\")\n-                Token(WHITESPACE@73..74 \" \")\n-                Node(NAME@74..75)\n-                Token(WHITESPACE@75..76 \" \")\n-                Node(RECORD_FIELD_LIST@76..92)\n-            \"#]],\n-        );\n-    }\n-}"}, {"sha": "fd61783414ede884af9ce119b97546c112834a19", "filename": "crates/hir_expand/src/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fhir_expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fhir_expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Flib.rs?ref=d6134b680230a56f8f39f31fa6578b7876eded8f", "patch": "@@ -14,7 +14,6 @@ pub mod builtin_macro;\n pub mod proc_macro;\n pub mod quote;\n pub mod eager;\n-mod input;\n \n use base_db::ProcMacroKind;\n use either::Either;"}, {"sha": "105b8742b0c2c755983966cc2c2b7ee5974694ec", "filename": "crates/mbe/src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fmbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fmbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Flib.rs?ref=d6134b680230a56f8f39f31fa6578b7876eded8f", "patch": "@@ -67,7 +67,7 @@ impl fmt::Display for ExpandError {\n pub use crate::{\n     syntax_bridge::{\n         parse_exprs_with_sep, parse_to_token_tree, syntax_node_to_token_tree,\n-        token_tree_to_syntax_node,\n+        syntax_node_to_token_tree_censored, token_tree_to_syntax_node,\n     },\n     token_map::TokenMap,\n };"}, {"sha": "59fc8f8c771ac856cda885e8c896a2e27479ca36", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 28, "deletions": 6, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d6134b680230a56f8f39f31fa6578b7876eded8f/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=d6134b680230a56f8f39f31fa6578b7876eded8f", "patch": "@@ -1,5 +1,7 @@\n //! Conversions between [`SyntaxNode`] and [`tt::TokenTree`].\n \n+use std::iter;\n+\n use parser::{FragmentKind, ParseError, TreeSink};\n use rustc_hash::FxHashMap;\n use syntax::{\n@@ -13,11 +15,20 @@ use tt::buffer::{Cursor, TokenBuffer};\n use crate::{subtree_source::SubtreeTokenSource, tt_iter::TtIter};\n use crate::{ExpandError, TokenMap};\n \n-/// Convert the syntax node to a `TokenTree` (what macro\n+/// Convert the syntax node to a `TokenTree` with the censored nodes excluded (what macro\n /// will consume).\n pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> (tt::Subtree, TokenMap) {\n+    syntax_node_to_token_tree_censored(node, None)\n+}\n+\n+/// Convert the syntax node to a `TokenTree` with the censored nodes excluded (what macro\n+/// will consume).\n+pub fn syntax_node_to_token_tree_censored(\n+    node: &SyntaxNode,\n+    censor: Option<TextRange>,\n+) -> (tt::Subtree, TokenMap) {\n     let global_offset = node.text_range().start();\n-    let mut c = Convertor::new(node, global_offset);\n+    let mut c = Convertor::new(node, global_offset, censor);\n     let subtree = convert_tokens(&mut c);\n     c.id_alloc.map.shrink_to_fit();\n     (subtree, c.id_alloc.map)\n@@ -446,16 +457,24 @@ impl<'a> TokenConvertor for RawConvertor<'a> {\n struct Convertor {\n     id_alloc: TokenIdAlloc,\n     current: Option<SyntaxToken>,\n+    censor: Option<TextRange>,\n     range: TextRange,\n     punct_offset: Option<(SyntaxToken, TextSize)>,\n }\n \n impl Convertor {\n-    fn new(node: &SyntaxNode, global_offset: TextSize) -> Convertor {\n+    fn new(node: &SyntaxNode, global_offset: TextSize, censor: Option<TextRange>) -> Convertor {\n+        let first = node.first_token();\n+        let current = match censor {\n+            Some(censor) => iter::successors(first, |token| token.next_token())\n+                .find(|token| !censor.contains_range(token.text_range())),\n+            None => first,\n+        };\n         Convertor {\n             id_alloc: { TokenIdAlloc { map: TokenMap::default(), global_offset, next_id: 0 } },\n-            current: node.first_token(),\n+            current,\n             range: node.text_range(),\n+            censor,\n             punct_offset: None,\n         }\n     }\n@@ -512,8 +531,11 @@ impl TokenConvertor for Convertor {\n         if !&self.range.contains_range(curr.text_range()) {\n             return None;\n         }\n-        self.current = curr.next_token();\n-\n+        self.current = match self.censor {\n+            Some(censor) => iter::successors(curr.next_token(), |token| token.next_token())\n+                .find(|token| !censor.contains_range(token.text_range())),\n+            None => curr.next_token(),\n+        };\n         let token = if curr.kind().is_punct() {\n             let range = curr.text_range();\n             let range = TextRange::at(range.start(), TextSize::of('.'));"}]}