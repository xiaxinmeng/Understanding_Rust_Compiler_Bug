{"sha": "4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjRjMWY5YjhkNGU5YWI5YmEzYjE2ZDJiMDNmM2M4YmNjN2Y2MTcwNmU=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-02-20T19:58:56Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-02-20T20:02:24Z"}, "message": "remove TokenPos", "tree": {"sha": "4e9ae2abecdf31bd849f3a6d5e568a495081f9a4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4e9ae2abecdf31bd849f3a6d5e568a495081f9a4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e", "html_url": "https://github.com/rust-lang/rust/commit/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "cce23fddba4241202ebd29cce44db4ce9a08793a", "url": "https://api.github.com/repos/rust-lang/rust/commits/cce23fddba4241202ebd29cce44db4ce9a08793a", "html_url": "https://github.com/rust-lang/rust/commit/cce23fddba4241202ebd29cce44db4ce9a08793a"}], "stats": {"total": 77, "additions": 28, "deletions": 49}, "files": [{"sha": "5de6ff8c1123c3d7c81b2bdf1983d54feeeb3de2", "filename": "crates/ra_syntax/src/parsing.rs", "status": "modified", "additions": 3, "deletions": 20, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e/crates%2Fra_syntax%2Fsrc%2Fparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e/crates%2Fra_syntax%2Fsrc%2Fparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing.rs?ref=4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e", "patch": "@@ -69,24 +69,7 @@ trait TreeSink {\n ///\n /// Hopefully this will allow us to treat text and token trees in the same way!\n trait TokenSource {\n-    fn token_kind(&self, pos: TokenPos) -> SyntaxKind;\n-    fn is_token_joint_to_next(&self, pos: TokenPos) -> bool;\n-    fn is_keyword(&self, pos: TokenPos, kw: &str) -> bool;\n-}\n-\n-#[derive(Copy, Clone, Ord, PartialOrd, Eq, PartialEq, Default)]\n-pub(crate) struct TokenPos(pub u32);\n-\n-impl std::ops::Add<u32> for TokenPos {\n-    type Output = TokenPos;\n-\n-    fn add(self, rhs: u32) -> TokenPos {\n-        TokenPos(self.0 + rhs)\n-    }\n-}\n-\n-impl std::ops::AddAssign<u32> for TokenPos {\n-    fn add_assign(&mut self, rhs: u32) {\n-        self.0 += rhs\n-    }\n+    fn token_kind(&self, pos: usize) -> SyntaxKind;\n+    fn is_token_joint_to_next(&self, pos: usize) -> bool;\n+    fn is_keyword(&self, pos: usize, kw: &str) -> bool;\n }"}, {"sha": "96c03bb118506bf7b254c706a9fa636f5a84d071", "filename": "crates/ra_syntax/src/parsing/input.rs", "status": "modified", "additions": 10, "deletions": 14, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e/crates%2Fra_syntax%2Fsrc%2Fparsing%2Finput.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e/crates%2Fra_syntax%2Fsrc%2Fparsing%2Finput.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Finput.rs?ref=4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e", "patch": "@@ -1,33 +1,29 @@\n use crate::{\n     SyntaxKind, SyntaxKind::EOF, TextRange, TextUnit,\n     parsing::{\n-        TokenPos, TokenSource,\n+        TokenSource,\n         lexer::Token,\n     },\n };\n \n impl<'t> TokenSource for ParserInput<'t> {\n-    fn token_kind(&self, pos: TokenPos) -> SyntaxKind {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n+    fn token_kind(&self, pos: usize) -> SyntaxKind {\n+        if !(pos < self.tokens.len()) {\n             return EOF;\n         }\n-        self.tokens[idx].kind\n+        self.tokens[pos].kind\n     }\n-    fn is_token_joint_to_next(&self, pos: TokenPos) -> bool {\n-        let idx_curr = pos.0 as usize;\n-        let idx_next = pos.0 as usize + 1;\n-        if !(idx_next < self.tokens.len()) {\n+    fn is_token_joint_to_next(&self, pos: usize) -> bool {\n+        if !(pos + 1 < self.tokens.len()) {\n             return true;\n         }\n-        self.start_offsets[idx_curr] + self.tokens[idx_curr].len == self.start_offsets[idx_next]\n+        self.start_offsets[pos] + self.tokens[pos].len == self.start_offsets[pos + 1]\n     }\n-    fn is_keyword(&self, pos: TokenPos, kw: &str) -> bool {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n+    fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n+        if !(pos < self.tokens.len()) {\n             return false;\n         }\n-        let range = TextRange::offset_len(self.start_offsets[idx], self.tokens[idx].len);\n+        let range = TextRange::offset_len(self.start_offsets[pos], self.tokens[pos].len);\n \n         self.text[range] == *kw\n     }"}, {"sha": "988fcb518805f7ad80780f5d7b680fa54772dd1a", "filename": "crates/ra_syntax/src/parsing/parser_api.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_api.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_api.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_api.rs?ref=4c1f9b8d4e9ab9ba3b16d2b03f3c8bcc7f61706e", "patch": "@@ -6,7 +6,7 @@ use crate::{\n     syntax_error::ParseError,\n     SyntaxKind::{self, ERROR, EOF, TOMBSTONE},\n     parsing::{\n-        TokenSource, TokenPos,\n+        TokenSource,\n         token_set::TokenSet,\n         event::Event,\n     },\n@@ -23,14 +23,14 @@ use crate::{\n /// finish expression\". See `Event` docs for more.\n pub(crate) struct Parser<'t> {\n     token_source: &'t dyn TokenSource,\n-    pos: TokenPos,\n+    token_pos: usize,\n     events: Vec<Event>,\n     steps: Cell<u32>,\n }\n \n impl<'t> Parser<'t> {\n     pub(super) fn new(token_source: &'t dyn TokenSource) -> Parser<'t> {\n-        Parser { token_source, pos: TokenPos::default(), events: Vec::new(), steps: Cell::new(0) }\n+        Parser { token_source, token_pos: 0, events: Vec::new(), steps: Cell::new(0) }\n     }\n \n     pub(crate) fn finish(self) -> Vec<Event> {\n@@ -49,9 +49,9 @@ impl<'t> Parser<'t> {\n     ///\n     /// Useful for parsing things like `>>`.\n     pub(crate) fn current2(&self) -> Option<(SyntaxKind, SyntaxKind)> {\n-        let c1 = self.token_source.token_kind(self.pos);\n-        let c2 = self.token_source.token_kind(self.pos + 1);\n-        if self.token_source.is_token_joint_to_next(self.pos) {\n+        let c1 = self.token_source.token_kind(self.token_pos);\n+        let c2 = self.token_source.token_kind(self.token_pos + 1);\n+        if self.token_source.is_token_joint_to_next(self.token_pos) {\n             Some((c1, c2))\n         } else {\n             None\n@@ -63,11 +63,11 @@ impl<'t> Parser<'t> {\n     ///\n     /// Useful for parsing things like `=>>`.\n     pub(crate) fn current3(&self) -> Option<(SyntaxKind, SyntaxKind, SyntaxKind)> {\n-        let c1 = self.token_source.token_kind(self.pos);\n-        let c2 = self.token_source.token_kind(self.pos + 1);\n-        let c3 = self.token_source.token_kind(self.pos + 2);\n-        if self.token_source.is_token_joint_to_next(self.pos)\n-            && self.token_source.is_token_joint_to_next(self.pos + 1)\n+        let c1 = self.token_source.token_kind(self.token_pos);\n+        let c2 = self.token_source.token_kind(self.token_pos + 1);\n+        let c3 = self.token_source.token_kind(self.token_pos + 2);\n+        if self.token_source.is_token_joint_to_next(self.token_pos)\n+            && self.token_source.is_token_joint_to_next(self.token_pos + 1)\n         {\n             Some((c1, c2, c3))\n         } else {\n@@ -77,11 +77,11 @@ impl<'t> Parser<'t> {\n \n     /// Lookahead operation: returns the kind of the next nth\n     /// token.\n-    pub(crate) fn nth(&self, n: u32) -> SyntaxKind {\n+    pub(crate) fn nth(&self, n: usize) -> SyntaxKind {\n         let steps = self.steps.get();\n         assert!(steps <= 10_000_000, \"the parser seems stuck\");\n         self.steps.set(steps + 1);\n-        self.token_source.token_kind(self.pos + n)\n+        self.token_source.token_kind(self.token_pos + n)\n     }\n \n     /// Checks if the current token is `kind`.\n@@ -96,7 +96,7 @@ impl<'t> Parser<'t> {\n \n     /// Checks if the current token is contextual keyword with text `t`.\n     pub(crate) fn at_contextual_kw(&self, kw: &str) -> bool {\n-        self.token_source.is_keyword(self.pos, kw)\n+        self.token_source.is_keyword(self.token_pos, kw)\n     }\n \n     /// Starts a new node in the syntax tree. All nodes and tokens\n@@ -184,7 +184,7 @@ impl<'t> Parser<'t> {\n     }\n \n     fn do_bump(&mut self, kind: SyntaxKind, n_raw_tokens: u8) {\n-        self.pos += u32::from(n_raw_tokens);\n+        self.token_pos += usize::from(n_raw_tokens);\n         self.push_event(Event::Token { kind, n_raw_tokens });\n     }\n "}]}