{"sha": "eac3846b65b068a5cbdfafc786e258554b875dae", "node_id": "MDY6Q29tbWl0NzI0NzEyOmVhYzM4NDZiNjViMDY4YTVjYmRmYWZjNzg2ZTI1ODU1NGI4NzVkYWU=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-05-23T23:04:56Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-06T11:01:57Z"}, "message": "Always use token kinds through `token` module rather than `Token` type", "tree": {"sha": "7f8aeac93382bd664ac49d1791181cf6d659dcc3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7f8aeac93382bd664ac49d1791181cf6d659dcc3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/eac3846b65b068a5cbdfafc786e258554b875dae", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/eac3846b65b068a5cbdfafc786e258554b875dae", "html_url": "https://github.com/rust-lang/rust/commit/eac3846b65b068a5cbdfafc786e258554b875dae", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/eac3846b65b068a5cbdfafc786e258554b875dae/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "daf1ed0e98e75c64c3b883fd845b37bfa42358de", "url": "https://api.github.com/repos/rust-lang/rust/commits/daf1ed0e98e75c64c3b883fd845b37bfa42358de", "html_url": "https://github.com/rust-lang/rust/commit/daf1ed0e98e75c64c3b883fd845b37bfa42358de"}], "stats": {"total": 260, "additions": 130, "deletions": 130}, "files": [{"sha": "089e5de01a21f9b12794a1ade9a9888f322601cc", "filename": "src/librustc/hir/lowering.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibrustc%2Fhir%2Flowering.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibrustc%2Fhir%2Flowering.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Flowering.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -67,7 +67,7 @@ use syntax::source_map::CompilerDesugaringKind::IfTemporary;\n use syntax::std_inject;\n use syntax::symbol::{kw, sym, Symbol};\n use syntax::tokenstream::{TokenStream, TokenTree};\n-use syntax::parse::token::Token;\n+use syntax::parse::token::{self, Token};\n use syntax::visit::{self, Visitor};\n use syntax_pos::{DUMMY_SP, edition, Span};\n \n@@ -1339,7 +1339,7 @@ impl<'a> LoweringContext<'a> {\n \n     fn lower_token(&mut self, token: Token, span: Span) -> TokenStream {\n         match token {\n-            Token::Interpolated(nt) => {\n+            token::Interpolated(nt) => {\n                 let tts = nt.to_tokenstream(&self.sess.parse_sess, span);\n                 self.lower_token_stream(tts)\n             }"}, {"sha": "0fa0d1ea00c95a953a5a2a528aaf2e3ea7d04664", "filename": "src/librustc/hir/map/def_collector.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmap%2Fdef_collector.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -326,7 +326,7 @@ impl<'a> visit::Visitor<'a> for DefCollector<'a> {\n     }\n \n     fn visit_token(&mut self, t: Token) {\n-        if let Token::Interpolated(nt) = t {\n+        if let token::Interpolated(nt) = t {\n             if let token::NtExpr(ref expr) = *nt {\n                 if let ExprKind::Mac(..) = expr.node {\n                     self.visit_macro_invoc(expr.id);"}, {"sha": "6e1eba0af56f9c216519bd4d9db46c2d3fde6429", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 41, "deletions": 41, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -313,60 +313,60 @@ fn hash_token<'a, 'gcx, W: StableHasherResult>(\n ) {\n     mem::discriminant(token).hash_stable(hcx, hasher);\n     match *token {\n-        token::Token::Eq |\n-        token::Token::Lt |\n-        token::Token::Le |\n-        token::Token::EqEq |\n-        token::Token::Ne |\n-        token::Token::Ge |\n-        token::Token::Gt |\n-        token::Token::AndAnd |\n-        token::Token::OrOr |\n-        token::Token::Not |\n-        token::Token::Tilde |\n-        token::Token::At |\n-        token::Token::Dot |\n-        token::Token::DotDot |\n-        token::Token::DotDotDot |\n-        token::Token::DotDotEq |\n-        token::Token::Comma |\n-        token::Token::Semi |\n-        token::Token::Colon |\n-        token::Token::ModSep |\n-        token::Token::RArrow |\n-        token::Token::LArrow |\n-        token::Token::FatArrow |\n-        token::Token::Pound |\n-        token::Token::Dollar |\n-        token::Token::Question |\n-        token::Token::SingleQuote |\n-        token::Token::Whitespace |\n-        token::Token::Comment |\n-        token::Token::Eof => {}\n-\n-        token::Token::BinOp(bin_op_token) |\n-        token::Token::BinOpEq(bin_op_token) => {\n+        token::Eq |\n+        token::Lt |\n+        token::Le |\n+        token::EqEq |\n+        token::Ne |\n+        token::Ge |\n+        token::Gt |\n+        token::AndAnd |\n+        token::OrOr |\n+        token::Not |\n+        token::Tilde |\n+        token::At |\n+        token::Dot |\n+        token::DotDot |\n+        token::DotDotDot |\n+        token::DotDotEq |\n+        token::Comma |\n+        token::Semi |\n+        token::Colon |\n+        token::ModSep |\n+        token::RArrow |\n+        token::LArrow |\n+        token::FatArrow |\n+        token::Pound |\n+        token::Dollar |\n+        token::Question |\n+        token::SingleQuote |\n+        token::Whitespace |\n+        token::Comment |\n+        token::Eof => {}\n+\n+        token::BinOp(bin_op_token) |\n+        token::BinOpEq(bin_op_token) => {\n             std_hash::Hash::hash(&bin_op_token, hasher);\n         }\n \n-        token::Token::OpenDelim(delim_token) |\n-        token::Token::CloseDelim(delim_token) => {\n+        token::OpenDelim(delim_token) |\n+        token::CloseDelim(delim_token) => {\n             std_hash::Hash::hash(&delim_token, hasher);\n         }\n-        token::Token::Literal(lit) => lit.hash_stable(hcx, hasher),\n+        token::Literal(lit) => lit.hash_stable(hcx, hasher),\n \n-        token::Token::Ident(ident, is_raw) => {\n+        token::Ident(ident, is_raw) => {\n             ident.name.hash_stable(hcx, hasher);\n             is_raw.hash_stable(hcx, hasher);\n         }\n-        token::Token::Lifetime(ident) => ident.name.hash_stable(hcx, hasher),\n+        token::Lifetime(ident) => ident.name.hash_stable(hcx, hasher),\n \n-        token::Token::Interpolated(_) => {\n+        token::Interpolated(_) => {\n             bug!(\"interpolated tokens should not be present in the HIR\")\n         }\n \n-        token::Token::DocComment(val) |\n-        token::Token::Shebang(val) => val.hash_stable(hcx, hasher),\n+        token::DocComment(val) |\n+        token::Shebang(val) => val.hash_stable(hcx, hasher),\n     }\n }\n "}, {"sha": "76279cc0283419aa2c2eceb959d5209a9a92d050", "filename": "src/librustc_resolve/build_reduced_graph.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Fbuild_reduced_graph.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -1053,7 +1053,7 @@ impl<'a, 'b> Visitor<'a> for BuildReducedGraphVisitor<'a, 'b> {\n     }\n \n     fn visit_token(&mut self, t: Token) {\n-        if let Token::Interpolated(nt) = t {\n+        if let token::Interpolated(nt) = t {\n             if let token::NtExpr(ref expr) = *nt {\n                 if let ast::ExprKind::Mac(..) = expr.node {\n                     self.visit_invoc(expr.id);"}, {"sha": "c57510ab1a0be50550aac55a86a3c126527ae333", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -465,7 +465,7 @@ impl MetaItem {\n                 let mod_sep_span = Span::new(last_pos,\n                                              segment.ident.span.lo(),\n                                              segment.ident.span.ctxt());\n-                idents.push(TokenTree::Token(mod_sep_span, Token::ModSep).into());\n+                idents.push(TokenTree::Token(mod_sep_span, token::ModSep).into());\n             }\n             idents.push(TokenTree::Token(segment.ident.span,\n                                          Token::from_ast_ident(segment.ident)).into());\n@@ -480,10 +480,10 @@ impl MetaItem {\n     {\n         // FIXME: Share code with `parse_path`.\n         let path = match tokens.next() {\n-            Some(TokenTree::Token(span, token @ Token::Ident(..))) |\n-            Some(TokenTree::Token(span, token @ Token::ModSep)) => 'arm: {\n-                let mut segments = if let Token::Ident(ident, _) = token {\n-                    if let Some(TokenTree::Token(_, Token::ModSep)) = tokens.peek() {\n+            Some(TokenTree::Token(span, token @ token::Ident(..))) |\n+            Some(TokenTree::Token(span, token @ token::ModSep)) => 'arm: {\n+                let mut segments = if let token::Ident(ident, _) = token {\n+                    if let Some(TokenTree::Token(_, token::ModSep)) = tokens.peek() {\n                         tokens.next();\n                         vec![PathSegment::from_ident(ident.with_span_pos(span))]\n                     } else {\n@@ -494,12 +494,12 @@ impl MetaItem {\n                 };\n                 loop {\n                     if let Some(TokenTree::Token(span,\n-                                                    Token::Ident(ident, _))) = tokens.next() {\n+                                                    token::Ident(ident, _))) = tokens.next() {\n                         segments.push(PathSegment::from_ident(ident.with_span_pos(span)));\n                     } else {\n                         return None;\n                     }\n-                    if let Some(TokenTree::Token(_, Token::ModSep)) = tokens.peek() {\n+                    if let Some(TokenTree::Token(_, token::ModSep)) = tokens.peek() {\n                         tokens.next();\n                     } else {\n                         break;\n@@ -508,7 +508,7 @@ impl MetaItem {\n                 let span = span.with_hi(segments.last().unwrap().ident.span.hi());\n                 Path { span, segments }\n             }\n-            Some(TokenTree::Token(_, Token::Interpolated(nt))) => match *nt {\n+            Some(TokenTree::Token(_, token::Interpolated(nt))) => match *nt {\n                 token::Nonterminal::NtIdent(ident, _) => Path::from_ident(ident),\n                 token::Nonterminal::NtMeta(ref meta) => return Some(meta.clone()),\n                 token::Nonterminal::NtPath(ref path) => path.clone(),\n@@ -533,15 +533,15 @@ impl MetaItemKind {\n         match *self {\n             MetaItemKind::Word => TokenStream::empty(),\n             MetaItemKind::NameValue(ref lit) => {\n-                let mut vec = vec![TokenTree::Token(span, Token::Eq).into()];\n+                let mut vec = vec![TokenTree::Token(span, token::Eq).into()];\n                 lit.tokens().append_to_tree_and_joint_vec(&mut vec);\n                 TokenStream::new(vec)\n             }\n             MetaItemKind::List(ref list) => {\n                 let mut tokens = Vec::new();\n                 for (i, item) in list.iter().enumerate() {\n                     if i > 0 {\n-                        tokens.push(TokenTree::Token(span, Token::Comma).into());\n+                        tokens.push(TokenTree::Token(span, token::Comma).into());\n                     }\n                     item.tokens().append_to_tree_and_joint_vec(&mut tokens);\n                 }\n@@ -579,7 +579,7 @@ impl MetaItemKind {\n             let item = NestedMetaItem::from_tokens(&mut tokens)?;\n             result.push(item);\n             match tokens.next() {\n-                None | Some(TokenTree::Token(_, Token::Comma)) => {}\n+                None | Some(TokenTree::Token(_, token::Comma)) => {}\n                 _ => return None,\n             }\n         }"}, {"sha": "7b158b65d156233f8d50009e75648fde11d6b3c8", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -10,7 +10,7 @@ use crate::ext::placeholders::{placeholder, PlaceholderExpander};\n use crate::feature_gate::{self, Features, GateIssue, is_builtin_attr, emit_feature_err};\n use crate::mut_visit::*;\n use crate::parse::{DirectoryOwnership, PResult, ParseSess};\n-use crate::parse::token::{self, Token};\n+use crate::parse::token;\n use crate::parse::parser::Parser;\n use crate::ptr::P;\n use crate::symbol::Symbol;\n@@ -585,7 +585,7 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n             }\n             AttrProcMacro(ref mac, ..) => {\n                 self.gate_proc_macro_attr_item(attr.span, &item);\n-                let item_tok = TokenTree::Token(DUMMY_SP, Token::Interpolated(Lrc::new(match item {\n+                let item_tok = TokenTree::Token(DUMMY_SP, token::Interpolated(Lrc::new(match item {\n                     Annotatable::Item(item) => token::NtItem(item),\n                     Annotatable::TraitItem(item) => token::NtTraitItem(item.into_inner()),\n                     Annotatable::ImplItem(item) => token::NtImplItem(item.into_inner()),"}, {"sha": "473a5f414dfa8fd14a61831253bff303c955afd8", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 20, "deletions": 20, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -835,12 +835,12 @@ fn may_begin_with(name: Symbol, token: &Token) -> bool {\n         sym::literal => token.can_begin_literal_or_bool(),\n         sym::vis => match *token {\n             // The follow-set of :vis + \"priv\" keyword + interpolated\n-            Token::Comma | Token::Ident(..) | Token::Interpolated(_) => true,\n+            token::Comma | token::Ident(..) | token::Interpolated(_) => true,\n             _ => token.can_begin_type(),\n         },\n         sym::block => match *token {\n-            Token::OpenDelim(token::Brace) => true,\n-            Token::Interpolated(ref nt) => match **nt {\n+            token::OpenDelim(token::Brace) => true,\n+            token::Interpolated(ref nt) => match **nt {\n                 token::NtItem(_)\n                 | token::NtPat(_)\n                 | token::NtTy(_)\n@@ -853,32 +853,32 @@ fn may_begin_with(name: Symbol, token: &Token) -> bool {\n             _ => false,\n         },\n         sym::path | sym::meta => match *token {\n-            Token::ModSep | Token::Ident(..) => true,\n-            Token::Interpolated(ref nt) => match **nt {\n+            token::ModSep | token::Ident(..) => true,\n+            token::Interpolated(ref nt) => match **nt {\n                 token::NtPath(_) | token::NtMeta(_) => true,\n                 _ => may_be_ident(&nt),\n             },\n             _ => false,\n         },\n         sym::pat => match *token {\n-            Token::Ident(..) |               // box, ref, mut, and other identifiers (can stricten)\n-            Token::OpenDelim(token::Paren) |    // tuple pattern\n-            Token::OpenDelim(token::Bracket) |  // slice pattern\n-            Token::BinOp(token::And) |          // reference\n-            Token::BinOp(token::Minus) |        // negative literal\n-            Token::AndAnd |                     // double reference\n-            Token::Literal(..) |                // literal\n-            Token::DotDot |                     // range pattern (future compat)\n-            Token::DotDotDot |                  // range pattern (future compat)\n-            Token::ModSep |                     // path\n-            Token::Lt |                         // path (UFCS constant)\n-            Token::BinOp(token::Shl) => true,   // path (double UFCS)\n-            Token::Interpolated(ref nt) => may_be_ident(nt),\n+            token::Ident(..) |               // box, ref, mut, and other identifiers (can stricten)\n+            token::OpenDelim(token::Paren) |    // tuple pattern\n+            token::OpenDelim(token::Bracket) |  // slice pattern\n+            token::BinOp(token::And) |          // reference\n+            token::BinOp(token::Minus) |        // negative literal\n+            token::AndAnd |                     // double reference\n+            token::Literal(..) |                // literal\n+            token::DotDot |                     // range pattern (future compat)\n+            token::DotDotDot |                  // range pattern (future compat)\n+            token::ModSep |                     // path\n+            token::Lt |                         // path (UFCS constant)\n+            token::BinOp(token::Shl) => true,   // path (double UFCS)\n+            token::Interpolated(ref nt) => may_be_ident(nt),\n             _ => false,\n         },\n         sym::lifetime => match *token {\n-            Token::Lifetime(_) => true,\n-            Token::Interpolated(ref nt) => match **nt {\n+            token::Lifetime(_) => true,\n+            token::Interpolated(ref nt) => match **nt {\n                 token::NtLifetime(_) | token::NtTT(_) => true,\n                 _ => false,\n             },"}, {"sha": "c2a1866b03a1b90346b9398bc60b875d4e248945", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -225,7 +225,7 @@ pub fn transcribe(\n                             result.push(tt.clone().into());\n                         } else {\n                             sp = sp.apply_mark(cx.current_expansion.mark);\n-                            let token = TokenTree::Token(sp, Token::Interpolated(nt.clone()));\n+                            let token = TokenTree::Token(sp, token::Interpolated(nt.clone()));\n                             result.push(token.into());\n                         }\n                     } else {"}, {"sha": "fc09943d4f5a839e74c652c79cc4c49f78f488bb", "filename": "src/libsyntax/parse/diagnostics.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -294,7 +294,7 @@ impl<'a> Parser<'a> {\n                 Applicability::MaybeIncorrect,\n             );\n         }\n-        let sp = if self.token == token::Token::Eof {\n+        let sp = if self.token == token::Eof {\n             // This is EOF, don't want to point at the following char, but rather the last token\n             self.prev_span\n         } else {\n@@ -732,22 +732,22 @@ impl<'a> Parser<'a> {\n         let this_token_str = self.this_token_descr();\n         let (prev_sp, sp) = match (&self.token, self.subparser_name) {\n             // Point at the end of the macro call when reaching end of macro arguments.\n-            (token::Token::Eof, Some(_)) => {\n+            (token::Eof, Some(_)) => {\n                 let sp = self.sess.source_map().next_point(self.span);\n                 (sp, sp)\n             }\n             // We don't want to point at the following span after DUMMY_SP.\n             // This happens when the parser finds an empty TokenStream.\n             _ if self.prev_span == DUMMY_SP => (self.span, self.span),\n             // EOF, don't want to point at the following char, but rather the last token.\n-            (token::Token::Eof, None) => (self.prev_span, self.span),\n+            (token::Eof, None) => (self.prev_span, self.span),\n             _ => (self.sess.source_map().next_point(self.prev_span), self.span),\n         };\n         let msg = format!(\n             \"expected `{}`, found {}\",\n             token_str,\n             match (&self.token, self.subparser_name) {\n-                (token::Token::Eof, Some(origin)) => format!(\"end of {}\", origin),\n+                (token::Eof, Some(origin)) => format!(\"end of {}\", origin),\n                 _ => this_token_str,\n             },\n         );\n@@ -1215,7 +1215,7 @@ impl<'a> Parser<'a> {\n \n     crate fn expected_expression_found(&self) -> DiagnosticBuilder<'a> {\n         let (span, msg) = match (&self.token, self.subparser_name) {\n-            (&token::Token::Eof, Some(origin)) => {\n+            (&token::Eof, Some(origin)) => {\n                 let sp = self.sess.source_map().next_point(self.span);\n                 (sp, format!(\"expected expression, found end of {}\", origin))\n             }"}, {"sha": "60d04ae9d942a6c5e41262f29c1af2762514dd6e", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -311,7 +311,7 @@ pub fn maybe_file_to_stream(\n             for unmatched in unmatched_braces {\n                 let mut db = sess.span_diagnostic.struct_span_err(unmatched.found_span, &format!(\n                     \"incorrect close delimiter: `{}`\",\n-                    token_to_string(&token::Token::CloseDelim(unmatched.found_delim)),\n+                    token_to_string(&token::CloseDelim(unmatched.found_delim)),\n                 ));\n                 db.span_label(unmatched.found_span, \"incorrect close delimiter\");\n                 if let Some(sp) = unmatched.candidate_span {"}, {"sha": "8409e300fc9cd6031b018172d4a471fca0f905e7", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -3359,7 +3359,7 @@ impl<'a> Parser<'a> {\n         let discriminant = self.parse_expr_res(Restrictions::NO_STRUCT_LITERAL,\n                                                None)?;\n         if let Err(mut e) = self.expect(&token::OpenDelim(token::Brace)) {\n-            if self.token == token::Token::Semi {\n+            if self.token == token::Semi {\n                 e.span_suggestion_short(\n                     match_span,\n                     \"try removing this `match`\",\n@@ -5920,7 +5920,7 @@ impl<'a> Parser<'a> {\n             while !self.eat(&token::CloseDelim(token::Brace)) {\n                 if let token::DocComment(_) = self.token {\n                     if self.look_ahead(1,\n-                    |tok| tok == &token::Token::CloseDelim(token::Brace)) {\n+                    |tok| tok == &token::CloseDelim(token::Brace)) {\n                         let mut err = self.diagnostic().struct_span_err_with_code(\n                             self.span,\n                             \"found a documentation comment that doesn't document anything\",\n@@ -6796,7 +6796,7 @@ impl<'a> Parser<'a> {\n         let mut replacement = vec![];\n         let mut fixed_crate_name = false;\n         // Accept `extern crate name-like-this` for better diagnostics\n-        let dash = token::Token::BinOp(token::BinOpToken::Minus);\n+        let dash = token::BinOp(token::BinOpToken::Minus);\n         if self.token == dash {  // Do not include `-` as part of the expected tokens list\n             while self.eat(&dash) {\n                 fixed_crate_name = true;\n@@ -7869,7 +7869,7 @@ pub fn emit_unclosed_delims(unclosed_delims: &mut Vec<UnmatchedBrace>, handler:\n     for unmatched in unclosed_delims.iter() {\n         let mut err = handler.struct_span_err(unmatched.found_span, &format!(\n             \"incorrect close delimiter: `{}`\",\n-            pprust::token_to_string(&token::Token::CloseDelim(unmatched.found_delim)),\n+            pprust::token_to_string(&token::CloseDelim(unmatched.found_delim)),\n         ));\n         err.span_label(unmatched.found_span, \"incorrect close delimiter\");\n         if let Some(sp) = unmatched.candidate_span {"}, {"sha": "d54d12698bbb66de381b572415e92a62acd195e4", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -691,11 +691,11 @@ impl Nonterminal {\n                 prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span)\n             }\n             Nonterminal::NtIdent(ident, is_raw) => {\n-                let token = Token::Ident(ident, is_raw);\n+                let token = Ident(ident, is_raw);\n                 Some(TokenTree::Token(ident.span, token).into())\n             }\n             Nonterminal::NtLifetime(ident) => {\n-                let token = Token::Lifetime(ident);\n+                let token = Lifetime(ident);\n                 Some(TokenTree::Token(ident.span, token).into())\n             }\n             Nonterminal::NtTT(ref tt) => {"}, {"sha": "5a934cd9f08399a359cbb0208509335aea880ce0", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -167,7 +167,7 @@ impl TokenTree {\n /// A `TokenStream` is an abstract sequence of tokens, organized into `TokenTree`s.\n /// The goal is for procedural macros to work with `TokenStream`s and `TokenTree`s\n /// instead of a representation of the abstract syntax tree.\n-/// Today's `TokenTree`s can still contain AST via `Token::Interpolated` for back-compat.\n+/// Today's `TokenTree`s can still contain AST via `token::Interpolated` for back-compat.\n ///\n /// The use of `Option` is an optimization that avoids the need for an\n /// allocation when the stream is empty. However, it is not guaranteed that an\n@@ -201,7 +201,7 @@ impl TokenStream {\n             while let Some((pos, ts)) = iter.next() {\n                 if let Some((_, next)) = iter.peek() {\n                     let sp = match (&ts, &next) {\n-                        (_, (TokenTree::Token(_, token::Token::Comma), _)) => continue,\n+                        (_, (TokenTree::Token(_, token::Comma), _)) => continue,\n                         ((TokenTree::Token(sp, token_left), NonJoint),\n                          (TokenTree::Token(_, token_right), _))\n                         if ((token_left.is_ident() && !token_left.is_reserved_ident())\n@@ -352,17 +352,17 @@ impl TokenStream {\n             match tree {\n                 // The pretty printer tends to add trailing commas to\n                 // everything, and in particular, after struct fields.\n-                | TokenTree::Token(_, Token::Comma)\n+                | TokenTree::Token(_, token::Comma)\n                 // The pretty printer emits `NoDelim` as whitespace.\n-                | TokenTree::Token(_, Token::OpenDelim(DelimToken::NoDelim))\n-                | TokenTree::Token(_, Token::CloseDelim(DelimToken::NoDelim))\n+                | TokenTree::Token(_, token::OpenDelim(DelimToken::NoDelim))\n+                | TokenTree::Token(_, token::CloseDelim(DelimToken::NoDelim))\n                 // The pretty printer collapses many semicolons into one.\n-                | TokenTree::Token(_, Token::Semi)\n+                | TokenTree::Token(_, token::Semi)\n                 // The pretty printer collapses whitespace arbitrarily and can\n                 // introduce whitespace from `NoDelim`.\n-                | TokenTree::Token(_, Token::Whitespace)\n+                | TokenTree::Token(_, token::Whitespace)\n                 // The pretty printer can turn `$crate` into `::crate_name`\n-                | TokenTree::Token(_, Token::ModSep) => false,\n+                | TokenTree::Token(_, token::ModSep) => false,\n                 _ => true\n             }\n         }\n@@ -664,7 +664,7 @@ mod tests {\n         with_default_globals(|| {\n             let test0: TokenStream = Vec::<TokenTree>::new().into_iter().collect();\n             let test1: TokenStream =\n-                TokenTree::Token(sp(0, 1), Token::Ident(Ident::from_str(\"a\"), false)).into();\n+                TokenTree::Token(sp(0, 1), token::Ident(Ident::from_str(\"a\"), false)).into();\n             let test2 = string_to_ts(\"foo(bar::baz)\");\n \n             assert_eq!(test0.is_empty(), true);\n@@ -677,9 +677,9 @@ mod tests {\n     fn test_dotdotdot() {\n         with_default_globals(|| {\n             let mut builder = TokenStreamBuilder::new();\n-            builder.push(TokenTree::Token(sp(0, 1), Token::Dot).joint());\n-            builder.push(TokenTree::Token(sp(1, 2), Token::Dot).joint());\n-            builder.push(TokenTree::Token(sp(2, 3), Token::Dot));\n+            builder.push(TokenTree::Token(sp(0, 1), token::Dot).joint());\n+            builder.push(TokenTree::Token(sp(1, 2), token::Dot).joint());\n+            builder.push(TokenTree::Token(sp(2, 3), token::Dot));\n             let stream = builder.build();\n             assert!(stream.eq_unspanned(&string_to_ts(\"...\")));\n             assert_eq!(stream.trees().count(), 1);"}, {"sha": "8dc9ce39915adf31924a78daeb02f7fd284d1a29", "filename": "src/libsyntax/util/parser.rs", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Futil%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax%2Futil%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -1,4 +1,4 @@\n-use crate::parse::token::{Token, BinOpToken};\n+use crate::parse::token::{self, Token, BinOpToken};\n use crate::symbol::kw;\n use crate::ast::{self, BinOpKind};\n \n@@ -72,31 +72,31 @@ impl AssocOp {\n     pub fn from_token(t: &Token) -> Option<AssocOp> {\n         use AssocOp::*;\n         match *t {\n-            Token::BinOpEq(k) => Some(AssignOp(k)),\n-            Token::Eq => Some(Assign),\n-            Token::BinOp(BinOpToken::Star) => Some(Multiply),\n-            Token::BinOp(BinOpToken::Slash) => Some(Divide),\n-            Token::BinOp(BinOpToken::Percent) => Some(Modulus),\n-            Token::BinOp(BinOpToken::Plus) => Some(Add),\n-            Token::BinOp(BinOpToken::Minus) => Some(Subtract),\n-            Token::BinOp(BinOpToken::Shl) => Some(ShiftLeft),\n-            Token::BinOp(BinOpToken::Shr) => Some(ShiftRight),\n-            Token::BinOp(BinOpToken::And) => Some(BitAnd),\n-            Token::BinOp(BinOpToken::Caret) => Some(BitXor),\n-            Token::BinOp(BinOpToken::Or) => Some(BitOr),\n-            Token::Lt => Some(Less),\n-            Token::Le => Some(LessEqual),\n-            Token::Ge => Some(GreaterEqual),\n-            Token::Gt => Some(Greater),\n-            Token::EqEq => Some(Equal),\n-            Token::Ne => Some(NotEqual),\n-            Token::AndAnd => Some(LAnd),\n-            Token::OrOr => Some(LOr),\n-            Token::DotDot => Some(DotDot),\n-            Token::DotDotEq => Some(DotDotEq),\n+            token::BinOpEq(k) => Some(AssignOp(k)),\n+            token::Eq => Some(Assign),\n+            token::BinOp(BinOpToken::Star) => Some(Multiply),\n+            token::BinOp(BinOpToken::Slash) => Some(Divide),\n+            token::BinOp(BinOpToken::Percent) => Some(Modulus),\n+            token::BinOp(BinOpToken::Plus) => Some(Add),\n+            token::BinOp(BinOpToken::Minus) => Some(Subtract),\n+            token::BinOp(BinOpToken::Shl) => Some(ShiftLeft),\n+            token::BinOp(BinOpToken::Shr) => Some(ShiftRight),\n+            token::BinOp(BinOpToken::And) => Some(BitAnd),\n+            token::BinOp(BinOpToken::Caret) => Some(BitXor),\n+            token::BinOp(BinOpToken::Or) => Some(BitOr),\n+            token::Lt => Some(Less),\n+            token::Le => Some(LessEqual),\n+            token::Ge => Some(GreaterEqual),\n+            token::Gt => Some(Greater),\n+            token::EqEq => Some(Equal),\n+            token::Ne => Some(NotEqual),\n+            token::AndAnd => Some(LAnd),\n+            token::OrOr => Some(LOr),\n+            token::DotDot => Some(DotDot),\n+            token::DotDotEq => Some(DotDotEq),\n             // DotDotDot is no longer supported, but we need some way to display the error\n-            Token::DotDotDot => Some(DotDotEq),\n-            Token::Colon => Some(Colon),\n+            token::DotDotDot => Some(DotDotEq),\n+            token::Colon => Some(Colon),\n             _ if t.is_keyword(kw::As) => Some(As),\n             _ => None\n         }"}, {"sha": "c1d93805a5811a62d4bd04efb43eb3e5cc7663b3", "filename": "src/libsyntax_ext/deriving/custom.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eac3846b65b068a5cbdfafc786e258554b875dae/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs?ref=eac3846b65b068a5cbdfafc786e258554b875dae", "patch": "@@ -8,7 +8,7 @@ use syntax::attr::{mark_used, mark_known};\n use syntax::source_map::Span;\n use syntax::ext::base::*;\n use syntax::parse;\n-use syntax::parse::token::{self, Token};\n+use syntax::parse::token;\n use syntax::tokenstream;\n use syntax::visit::Visitor;\n use syntax_pos::DUMMY_SP;\n@@ -68,7 +68,7 @@ impl MultiItemModifier for ProcMacroDerive {\n         // Mark attributes as known, and used.\n         MarkAttrs(&self.attrs).visit_item(&item);\n \n-        let token = Token::Interpolated(Lrc::new(token::NtItem(item)));\n+        let token = token::Interpolated(Lrc::new(token::NtItem(item)));\n         let input = tokenstream::TokenTree::Token(DUMMY_SP, token).into();\n \n         let server = proc_macro_server::Rustc::new(ecx);"}]}