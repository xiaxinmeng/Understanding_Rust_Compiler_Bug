{"sha": "2184a1444cb670421bf2836cbdbb662c077bad6a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjIxODRhMTQ0NGNiNjcwNDIxYmYyODM2Y2JkYmI2NjJjMDc3YmFkNmE=", "commit": {"author": {"name": "Nadrieril", "email": "nadrieril+git@gmail.com", "date": "2020-11-21T23:13:32Z"}, "committer": {"name": "Nadrieril", "email": "nadrieril+git@gmail.com", "date": "2020-11-27T18:22:17Z"}, "message": "Extract everything related to pattern deconstruction to a new module", "tree": {"sha": "8802acf11309e87702c7513c66916d35dee3ec45", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8802acf11309e87702c7513c66916d35dee3ec45"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2184a1444cb670421bf2836cbdbb662c077bad6a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2184a1444cb670421bf2836cbdbb662c077bad6a", "html_url": "https://github.com/rust-lang/rust/commit/2184a1444cb670421bf2836cbdbb662c077bad6a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2184a1444cb670421bf2836cbdbb662c077bad6a/comments", "author": {"login": "Nadrieril", "id": 6783654, "node_id": "MDQ6VXNlcjY3ODM2NTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/6783654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nadrieril", "html_url": "https://github.com/Nadrieril", "followers_url": "https://api.github.com/users/Nadrieril/followers", "following_url": "https://api.github.com/users/Nadrieril/following{/other_user}", "gists_url": "https://api.github.com/users/Nadrieril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nadrieril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nadrieril/subscriptions", "organizations_url": "https://api.github.com/users/Nadrieril/orgs", "repos_url": "https://api.github.com/users/Nadrieril/repos", "events_url": "https://api.github.com/users/Nadrieril/events{/privacy}", "received_events_url": "https://api.github.com/users/Nadrieril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Nadrieril", "id": 6783654, "node_id": "MDQ6VXNlcjY3ODM2NTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/6783654?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Nadrieril", "html_url": "https://github.com/Nadrieril", "followers_url": "https://api.github.com/users/Nadrieril/followers", "following_url": "https://api.github.com/users/Nadrieril/following{/other_user}", "gists_url": "https://api.github.com/users/Nadrieril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Nadrieril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Nadrieril/subscriptions", "organizations_url": "https://api.github.com/users/Nadrieril/orgs", "repos_url": "https://api.github.com/users/Nadrieril/repos", "events_url": "https://api.github.com/users/Nadrieril/events{/privacy}", "received_events_url": "https://api.github.com/users/Nadrieril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3715f1ed0089a12ac7bb5dd093d3dd8bbb0833ac", "url": "https://api.github.com/repos/rust-lang/rust/commits/3715f1ed0089a12ac7bb5dd093d3dd8bbb0833ac", "html_url": "https://github.com/rust-lang/rust/commit/3715f1ed0089a12ac7bb5dd093d3dd8bbb0833ac"}], "stats": {"total": 2800, "additions": 1413, "deletions": 1387}, "files": [{"sha": "72341976c3e8ee429bbd6f7281c8fc11325e024a", "filename": "compiler/rustc_mir_build/src/thir/pattern/_match.rs", "status": "modified", "additions": 18, "deletions": 1387, "changes": 1405, "blob_url": "https://github.com/rust-lang/rust/blob/2184a1444cb670421bf2836cbdbb662c077bad6a/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2F_match.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2184a1444cb670421bf2836cbdbb662c077bad6a/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2F_match.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2F_match.rs?ref=2184a1444cb670421bf2836cbdbb662c077bad6a", "patch": "@@ -303,36 +303,26 @@\n //!       anything special (because we know none of the integers are actually wildcards: i.e., we\n //!       can't span wildcards using ranges).\n \n-use self::Constructor::*;\n-use self::SliceKind::*;\n use self::Usefulness::*;\n use self::WitnessPreference::*;\n \n+use super::deconstruct_pat::{pat_constructor, Constructor, Fields, MissingConstructors};\n+use super::{Pat, PatKind};\n+use super::{PatternFoldable, PatternFolder};\n+\n use rustc_data_structures::captures::Captures;\n use rustc_data_structures::fx::FxHashSet;\n use rustc_data_structures::sync::OnceCell;\n-use rustc_index::vec::Idx;\n-\n-use super::{compare_const_vals, PatternFoldable, PatternFolder};\n-use super::{FieldPat, Pat, PatKind, PatRange};\n \n use rustc_arena::TypedArena;\n-use rustc_attr::{SignedInt, UnsignedInt};\n use rustc_hir::def_id::DefId;\n-use rustc_hir::{HirId, RangeEnd};\n-use rustc_middle::mir::interpret::ConstValue;\n-use rustc_middle::mir::Field;\n-use rustc_middle::ty::layout::IntegerExt;\n-use rustc_middle::ty::{self, Const, Ty, TyCtxt};\n-use rustc_session::lint;\n-use rustc_span::{Span, DUMMY_SP};\n-use rustc_target::abi::{Integer, Size, VariantIdx};\n+use rustc_hir::HirId;\n+use rustc_middle::ty::{self, Ty, TyCtxt};\n+use rustc_span::Span;\n \n use smallvec::{smallvec, SmallVec};\n-use std::cmp::{self, max, min, Ordering};\n use std::fmt;\n use std::iter::{FromIterator, IntoIterator};\n-use std::ops::RangeInclusive;\n \n crate fn expand_pattern<'tcx>(pat: Pat<'tcx>) -> Pat<'tcx> {\n     LiteralExpander.fold_pattern(&pat)\n@@ -467,7 +457,7 @@ impl<'p, 'tcx> FromIterator<&'p Pat<'tcx>> for PatStack<'p, 'tcx> {\n \n /// A 2D matrix.\n #[derive(Clone, PartialEq)]\n-struct Matrix<'p, 'tcx> {\n+pub(super) struct Matrix<'p, 'tcx> {\n     patterns: Vec<PatStack<'p, 'tcx>>,\n }\n \n@@ -477,7 +467,7 @@ impl<'p, 'tcx> Matrix<'p, 'tcx> {\n     }\n \n     /// Number of columns of this matrix. `None` is the matrix is empty.\n-    fn column_count(&self) -> Option<usize> {\n+    pub(super) fn column_count(&self) -> Option<usize> {\n         self.patterns.get(0).map(|r| r.len())\n     }\n \n@@ -500,7 +490,7 @@ impl<'p, 'tcx> Matrix<'p, 'tcx> {\n     }\n \n     /// Iterate over the first constructor of each row\n-    fn head_ctors<'a>(\n+    pub(super) fn head_ctors<'a>(\n         &'a self,\n         cx: &'a MatchCheckCtxt<'p, 'tcx>,\n     ) -> impl Iterator<Item = &'a Constructor<'tcx>> + Captures<'a> + Captures<'p> {\n@@ -596,7 +586,7 @@ crate struct MatchCheckCtxt<'a, 'tcx> {\n }\n \n impl<'a, 'tcx> MatchCheckCtxt<'a, 'tcx> {\n-    fn is_uninhabited(&self, ty: Ty<'tcx>) -> bool {\n+    pub(super) fn is_uninhabited(&self, ty: Ty<'tcx>) -> bool {\n         if self.tcx.features().exhaustive_patterns {\n             self.tcx.is_ty_uninhabited_from(self.module, ty, self.param_env)\n         } else {\n@@ -605,7 +595,7 @@ impl<'a, 'tcx> MatchCheckCtxt<'a, 'tcx> {\n     }\n \n     /// Returns whether the given type is an enum from another crate declared `#[non_exhaustive]`.\n-    fn is_foreign_non_exhaustive_enum(&self, ty: Ty<'tcx>) -> bool {\n+    pub(super) fn is_foreign_non_exhaustive_enum(&self, ty: Ty<'tcx>) -> bool {\n         match ty.kind() {\n             ty::Adt(def, ..) => {\n                 def.is_enum() && def.is_variant_list_non_exhaustive() && !def.did.is_local()\n@@ -615,770 +605,6 @@ impl<'a, 'tcx> MatchCheckCtxt<'a, 'tcx> {\n     }\n }\n \n-#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n-enum SliceKind {\n-    /// Patterns of length `n` (`[x, y]`).\n-    FixedLen(u64),\n-    /// Patterns using the `..` notation (`[x, .., y]`).\n-    /// Captures any array constructor of `length >= i + j`.\n-    /// In the case where `array_len` is `Some(_)`,\n-    /// this indicates that we only care about the first `i` and the last `j` values of the array,\n-    /// and everything in between is a wildcard `_`.\n-    VarLen(u64, u64),\n-}\n-\n-impl SliceKind {\n-    fn arity(self) -> u64 {\n-        match self {\n-            FixedLen(length) => length,\n-            VarLen(prefix, suffix) => prefix + suffix,\n-        }\n-    }\n-\n-    /// Whether this pattern includes patterns of length `other_len`.\n-    fn covers_length(self, other_len: u64) -> bool {\n-        match self {\n-            FixedLen(len) => len == other_len,\n-            VarLen(prefix, suffix) => prefix + suffix <= other_len,\n-        }\n-    }\n-}\n-\n-/// A constructor for array and slice patterns.\n-#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n-struct Slice {\n-    /// `None` if the matched value is a slice, `Some(n)` if it is an array of size `n`.\n-    array_len: Option<u64>,\n-    /// The kind of pattern it is: fixed-length `[x, y]` or variable length `[x, .., y]`.\n-    kind: SliceKind,\n-}\n-\n-impl Slice {\n-    fn new(array_len: Option<u64>, kind: SliceKind) -> Self {\n-        let kind = match (array_len, kind) {\n-            // If the middle `..` is empty, we effectively have a fixed-length pattern.\n-            (Some(len), VarLen(prefix, suffix)) if prefix + suffix >= len => FixedLen(len),\n-            _ => kind,\n-        };\n-        Slice { array_len, kind }\n-    }\n-\n-    fn arity(self) -> u64 {\n-        self.kind.arity()\n-    }\n-\n-    /// The exhaustiveness-checking paper does not include any details on\n-    /// checking variable-length slice patterns. However, they may be\n-    /// matched by an infinite collection of fixed-length array patterns.\n-    ///\n-    /// Checking the infinite set directly would take an infinite amount\n-    /// of time. However, it turns out that for each finite set of\n-    /// patterns `P`, all sufficiently large array lengths are equivalent:\n-    ///\n-    /// Each slice `s` with a \"sufficiently-large\" length `l \u2265 L` that applies\n-    /// to exactly the subset `P\u209c` of `P` can be transformed to a slice\n-    /// `s\u2098` for each sufficiently-large length `m` that applies to exactly\n-    /// the same subset of `P`.\n-    ///\n-    /// Because of that, each witness for reachability-checking of one\n-    /// of the sufficiently-large lengths can be transformed to an\n-    /// equally-valid witness of any other length, so we only have\n-    /// to check slices of the \"minimal sufficiently-large length\"\n-    /// and less.\n-    ///\n-    /// Note that the fact that there is a *single* `s\u2098` for each `m`\n-    /// not depending on the specific pattern in `P` is important: if\n-    /// you look at the pair of patterns\n-    ///     `[true, ..]`\n-    ///     `[.., false]`\n-    /// Then any slice of length \u22651 that matches one of these two\n-    /// patterns can be trivially turned to a slice of any\n-    /// other length \u22651 that matches them and vice-versa,\n-    /// but the slice of length 2 `[false, true]` that matches neither\n-    /// of these patterns can't be turned to a slice from length 1 that\n-    /// matches neither of these patterns, so we have to consider\n-    /// slices from length 2 there.\n-    ///\n-    /// Now, to see that that length exists and find it, observe that slice\n-    /// patterns are either \"fixed-length\" patterns (`[_, _, _]`) or\n-    /// \"variable-length\" patterns (`[_, .., _]`).\n-    ///\n-    /// For fixed-length patterns, all slices with lengths *longer* than\n-    /// the pattern's length have the same outcome (of not matching), so\n-    /// as long as `L` is greater than the pattern's length we can pick\n-    /// any `s\u2098` from that length and get the same result.\n-    ///\n-    /// For variable-length patterns, the situation is more complicated,\n-    /// because as seen above the precise value of `s\u2098` matters.\n-    ///\n-    /// However, for each variable-length pattern `p` with a prefix of length\n-    /// `pl\u209a` and suffix of length `sl\u209a`, only the first `pl\u209a` and the last\n-    /// `sl\u209a` elements are examined.\n-    ///\n-    /// Therefore, as long as `L` is positive (to avoid concerns about empty\n-    /// types), all elements after the maximum prefix length and before\n-    /// the maximum suffix length are not examined by any variable-length\n-    /// pattern, and therefore can be added/removed without affecting\n-    /// them - creating equivalent patterns from any sufficiently-large\n-    /// length.\n-    ///\n-    /// Of course, if fixed-length patterns exist, we must be sure\n-    /// that our length is large enough to miss them all, so\n-    /// we can pick `L = max(max(FIXED_LEN)+1, max(PREFIX_LEN) + max(SUFFIX_LEN))`\n-    ///\n-    /// for example, with the above pair of patterns, all elements\n-    /// but the first and last can be added/removed, so any\n-    /// witness of length \u22652 (say, `[false, false, true]`) can be\n-    /// turned to a witness from any other length \u22652.\n-    fn split<'p, 'tcx>(self, pcx: PatCtxt<'_, 'p, 'tcx>) -> SmallVec<[Constructor<'tcx>; 1]> {\n-        let (self_prefix, self_suffix) = match self.kind {\n-            VarLen(self_prefix, self_suffix) => (self_prefix, self_suffix),\n-            _ => return smallvec![Slice(self)],\n-        };\n-\n-        let head_ctors = pcx.matrix.head_ctors(pcx.cx).filter(|c| !c.is_wildcard());\n-\n-        let mut max_prefix_len = self_prefix;\n-        let mut max_suffix_len = self_suffix;\n-        let mut max_fixed_len = 0;\n-\n-        for ctor in head_ctors {\n-            if let Slice(slice) = ctor {\n-                match slice.kind {\n-                    FixedLen(len) => {\n-                        max_fixed_len = cmp::max(max_fixed_len, len);\n-                    }\n-                    VarLen(prefix, suffix) => {\n-                        max_prefix_len = cmp::max(max_prefix_len, prefix);\n-                        max_suffix_len = cmp::max(max_suffix_len, suffix);\n-                    }\n-                }\n-            } else {\n-                bug!(\"unexpected ctor for slice type: {:?}\", ctor);\n-            }\n-        }\n-\n-        // For diagnostics, we keep the prefix and suffix lengths separate, so in the case\n-        // where `max_fixed_len + 1` is the largest, we adapt `max_prefix_len` accordingly,\n-        // so that `L = max_prefix_len + max_suffix_len`.\n-        if max_fixed_len + 1 >= max_prefix_len + max_suffix_len {\n-            // The subtraction can't overflow thanks to the above check.\n-            // The new `max_prefix_len` is also guaranteed to be larger than its previous\n-            // value.\n-            max_prefix_len = max_fixed_len + 1 - max_suffix_len;\n-        }\n-\n-        let final_slice = VarLen(max_prefix_len, max_suffix_len);\n-        let final_slice = Slice::new(self.array_len, final_slice);\n-        match self.array_len {\n-            Some(_) => smallvec![Slice(final_slice)],\n-            None => {\n-                // `self` originally covered the range `(self.arity()..infinity)`. We split that\n-                // range into two: lengths smaller than `final_slice.arity()` are treated\n-                // independently as fixed-lengths slices, and lengths above are captured by\n-                // `final_slice`.\n-                let smaller_lengths = (self.arity()..final_slice.arity()).map(FixedLen);\n-                smaller_lengths\n-                    .map(|kind| Slice::new(self.array_len, kind))\n-                    .chain(Some(final_slice))\n-                    .map(Slice)\n-                    .collect()\n-            }\n-        }\n-    }\n-\n-    /// See `Constructor::is_covered_by`\n-    fn is_covered_by(self, other: Self) -> bool {\n-        other.kind.covers_length(self.arity())\n-    }\n-}\n-\n-/// A value can be decomposed into a constructor applied to some fields. This struct represents\n-/// the constructor. See also `Fields`.\n-///\n-/// `pat_constructor` retrieves the constructor corresponding to a pattern.\n-/// `specialize_constructor` returns the list of fields corresponding to a pattern, given a\n-/// constructor. `Constructor::apply` reconstructs the pattern from a pair of `Constructor` and\n-/// `Fields`.\n-#[derive(Clone, Debug, PartialEq)]\n-enum Constructor<'tcx> {\n-    /// The constructor for patterns that have a single constructor, like tuples, struct patterns\n-    /// and fixed-length arrays.\n-    Single,\n-    /// Enum variants.\n-    Variant(DefId),\n-    /// Ranges of integer literal values (`2`, `2..=5` or `2..5`).\n-    IntRange(IntRange<'tcx>),\n-    /// Ranges of floating-point literal values (`2.0..=5.2`).\n-    FloatRange(&'tcx ty::Const<'tcx>, &'tcx ty::Const<'tcx>, RangeEnd),\n-    /// String literals. Strings are not quite the same as `&[u8]` so we treat them separately.\n-    Str(&'tcx ty::Const<'tcx>),\n-    /// Array and slice patterns.\n-    Slice(Slice),\n-    /// Constants that must not be matched structurally. They are treated as black\n-    /// boxes for the purposes of exhaustiveness: we must not inspect them, and they\n-    /// don't count towards making a match exhaustive.\n-    Opaque,\n-    /// Fake extra constructor for enums that aren't allowed to be matched exhaustively. Also used\n-    /// for those types for which we cannot list constructors explicitly, like `f64` and `str`.\n-    NonExhaustive,\n-    /// Wildcard pattern.\n-    Wildcard,\n-}\n-\n-impl<'tcx> Constructor<'tcx> {\n-    fn is_wildcard(&self) -> bool {\n-        matches!(self, Wildcard)\n-    }\n-\n-    fn as_int_range(&self) -> Option<&IntRange<'tcx>> {\n-        match self {\n-            IntRange(range) => Some(range),\n-            _ => None,\n-        }\n-    }\n-\n-    fn as_slice(&self) -> Option<Slice> {\n-        match self {\n-            Slice(slice) => Some(*slice),\n-            _ => None,\n-        }\n-    }\n-\n-    fn variant_index_for_adt(&self, adt: &'tcx ty::AdtDef) -> VariantIdx {\n-        match *self {\n-            Variant(id) => adt.variant_index_with_id(id),\n-            Single => {\n-                assert!(!adt.is_enum());\n-                VariantIdx::new(0)\n-            }\n-            _ => bug!(\"bad constructor {:?} for adt {:?}\", self, adt),\n-        }\n-    }\n-\n-    /// Some constructors (namely `Wildcard`, `IntRange` and `Slice`) actually stand for a set of actual\n-    /// constructors (like variants, integers or fixed-sized slices). When specializing for these\n-    /// constructors, we want to be specialising for the actual underlying constructors.\n-    /// Naively, we would simply return the list of constructors they correspond to. We instead are\n-    /// more clever: if there are constructors that we know will behave the same wrt the current\n-    /// matrix, we keep them grouped. For example, all slices of a sufficiently large length\n-    /// will either be all useful or all non-useful with a given matrix.\n-    ///\n-    /// See the branches for details on how the splitting is done.\n-    ///\n-    /// This function may discard some irrelevant constructors if this preserves behavior and\n-    /// diagnostics. Eg. for the `_` case, we ignore the constructors already present in the\n-    /// matrix, unless all of them are.\n-    ///\n-    /// `hir_id` is `None` when we're evaluating the wildcard pattern. In that case we do not want\n-    /// to lint for overlapping ranges.\n-    fn split<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>, hir_id: Option<HirId>) -> SmallVec<[Self; 1]> {\n-        debug!(\"Constructor::split({:#?}, {:#?})\", self, pcx.matrix);\n-\n-        match self {\n-            Wildcard => Constructor::split_wildcard(pcx),\n-            // Fast-track if the range is trivial. In particular, we don't do the overlapping\n-            // ranges check.\n-            IntRange(ctor_range)\n-                if ctor_range.treat_exhaustively(pcx.cx.tcx) && !ctor_range.is_singleton() =>\n-            {\n-                ctor_range.split(pcx, hir_id)\n-            }\n-            Slice(slice @ Slice { kind: VarLen(..), .. }) => slice.split(pcx),\n-            // Any other constructor can be used unchanged.\n-            _ => smallvec![self.clone()],\n-        }\n-    }\n-\n-    /// For wildcards, there are two groups of constructors: there are the constructors actually\n-    /// present in the matrix (`head_ctors`), and the constructors not present (`missing_ctors`).\n-    /// Two constructors that are not in the matrix will either both be caught (by a wildcard), or\n-    /// both not be caught. Therefore we can keep the missing constructors grouped together.\n-    fn split_wildcard<'p>(pcx: PatCtxt<'_, 'p, 'tcx>) -> SmallVec<[Self; 1]> {\n-        // Missing constructors are those that are not matched by any non-wildcard patterns in the\n-        // current column. We only fully construct them on-demand, because they're rarely used and\n-        // can be big.\n-        let missing_ctors = MissingConstructors::new(pcx);\n-        if missing_ctors.is_empty(pcx) {\n-            // All the constructors are present in the matrix, so we just go through them all.\n-            // We must also split them first.\n-            missing_ctors.all_ctors\n-        } else {\n-            // Some constructors are missing, thus we can specialize with the wildcard constructor,\n-            // which will stand for those constructors that are missing, and behaves like any of\n-            // them.\n-            smallvec![Wildcard]\n-        }\n-    }\n-\n-    /// Returns whether `self` is covered by `other`, i.e. whether `self` is a subset of `other`.\n-    /// For the simple cases, this is simply checking for equality. For the \"grouped\" constructors,\n-    /// this checks for inclusion.\n-    fn is_covered_by<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>, other: &Self) -> bool {\n-        // This must be kept in sync with `is_covered_by_any`.\n-        match (self, other) {\n-            // Wildcards cover anything\n-            (_, Wildcard) => true,\n-            // Wildcards are only covered by wildcards\n-            (Wildcard, _) => false,\n-\n-            (Single, Single) => true,\n-            (Variant(self_id), Variant(other_id)) => self_id == other_id,\n-\n-            (IntRange(self_range), IntRange(other_range)) => {\n-                self_range.is_covered_by(pcx, other_range)\n-            }\n-            (\n-                FloatRange(self_from, self_to, self_end),\n-                FloatRange(other_from, other_to, other_end),\n-            ) => {\n-                match (\n-                    compare_const_vals(pcx.cx.tcx, self_to, other_to, pcx.cx.param_env, pcx.ty),\n-                    compare_const_vals(pcx.cx.tcx, self_from, other_from, pcx.cx.param_env, pcx.ty),\n-                ) {\n-                    (Some(to), Some(from)) => {\n-                        (from == Ordering::Greater || from == Ordering::Equal)\n-                            && (to == Ordering::Less\n-                                || (other_end == self_end && to == Ordering::Equal))\n-                    }\n-                    _ => false,\n-                }\n-            }\n-            (Str(self_val), Str(other_val)) => {\n-                // FIXME: there's probably a more direct way of comparing for equality\n-                match compare_const_vals(pcx.cx.tcx, self_val, other_val, pcx.cx.param_env, pcx.ty)\n-                {\n-                    Some(comparison) => comparison == Ordering::Equal,\n-                    None => false,\n-                }\n-            }\n-            (Slice(self_slice), Slice(other_slice)) => self_slice.is_covered_by(*other_slice),\n-\n-            // We are trying to inspect an opaque constant. Thus we skip the row.\n-            (Opaque, _) | (_, Opaque) => false,\n-            // Only a wildcard pattern can match the special extra constructor.\n-            (NonExhaustive, _) => false,\n-\n-            _ => span_bug!(\n-                pcx.span,\n-                \"trying to compare incompatible constructors {:?} and {:?}\",\n-                self,\n-                other\n-            ),\n-        }\n-    }\n-\n-    /// Faster version of `is_covered_by` when applied to many constructors. `used_ctors` is\n-    /// assumed to be built from `matrix.head_ctors()` with wildcards filtered out, and `self` is\n-    /// assumed to have been split from a wildcard.\n-    fn is_covered_by_any<'p>(\n-        &self,\n-        pcx: PatCtxt<'_, 'p, 'tcx>,\n-        used_ctors: &[Constructor<'tcx>],\n-    ) -> bool {\n-        if used_ctors.is_empty() {\n-            return false;\n-        }\n-\n-        // This must be kept in sync with `is_covered_by`.\n-        match self {\n-            // If `self` is `Single`, `used_ctors` cannot contain anything else than `Single`s.\n-            Single => !used_ctors.is_empty(),\n-            Variant(_) => used_ctors.iter().any(|c| c == self),\n-            IntRange(range) => used_ctors\n-                .iter()\n-                .filter_map(|c| c.as_int_range())\n-                .any(|other| range.is_covered_by(pcx, other)),\n-            Slice(slice) => used_ctors\n-                .iter()\n-                .filter_map(|c| c.as_slice())\n-                .any(|other| slice.is_covered_by(other)),\n-            // This constructor is never covered by anything else\n-            NonExhaustive => false,\n-            Str(..) | FloatRange(..) | Opaque | Wildcard => {\n-                bug!(\"found unexpected ctor in all_ctors: {:?}\", self)\n-            }\n-        }\n-    }\n-}\n-\n-/// Some fields need to be explicitly hidden away in certain cases; see the comment above the\n-/// `Fields` struct. This struct represents such a potentially-hidden field. When a field is hidden\n-/// we still keep its type around.\n-#[derive(Debug, Copy, Clone)]\n-enum FilteredField<'p, 'tcx> {\n-    Kept(&'p Pat<'tcx>),\n-    Hidden(Ty<'tcx>),\n-}\n-\n-impl<'p, 'tcx> FilteredField<'p, 'tcx> {\n-    fn kept(self) -> Option<&'p Pat<'tcx>> {\n-        match self {\n-            FilteredField::Kept(p) => Some(p),\n-            FilteredField::Hidden(_) => None,\n-        }\n-    }\n-\n-    fn to_pattern(self) -> Pat<'tcx> {\n-        match self {\n-            FilteredField::Kept(p) => p.clone(),\n-            FilteredField::Hidden(ty) => Pat::wildcard_from_ty(ty),\n-        }\n-    }\n-}\n-\n-/// A value can be decomposed into a constructor applied to some fields. This struct represents\n-/// those fields, generalized to allow patterns in each field. See also `Constructor`.\n-///\n-/// If a private or `non_exhaustive` field is uninhabited, the code mustn't observe that it is\n-/// uninhabited. For that, we filter these fields out of the matrix. This is subtle because we\n-/// still need to have those fields back when going to/from a `Pat`. Most of this is handled\n-/// automatically in `Fields`, but when constructing or deconstructing `Fields` you need to be\n-/// careful. As a rule, when going to/from the matrix, use the filtered field list; when going\n-/// to/from `Pat`, use the full field list.\n-/// This filtering is uncommon in practice, because uninhabited fields are rarely used, so we avoid\n-/// it when possible to preserve performance.\n-#[derive(Debug, Clone)]\n-enum Fields<'p, 'tcx> {\n-    /// Lists of patterns that don't contain any filtered fields.\n-    /// `Slice` and `Vec` behave the same; the difference is only to avoid allocating and\n-    /// triple-dereferences when possible. Frankly this is premature optimization, I (Nadrieril)\n-    /// have not measured if it really made a difference.\n-    Slice(&'p [Pat<'tcx>]),\n-    Vec(SmallVec<[&'p Pat<'tcx>; 2]>),\n-    /// Patterns where some of the fields need to be hidden. `kept_count` caches the number of\n-    /// non-hidden fields.\n-    Filtered {\n-        fields: SmallVec<[FilteredField<'p, 'tcx>; 2]>,\n-        kept_count: usize,\n-    },\n-}\n-\n-impl<'p, 'tcx> Fields<'p, 'tcx> {\n-    fn empty() -> Self {\n-        Fields::Slice(&[])\n-    }\n-\n-    /// Construct a new `Fields` from the given pattern. Must not be used if the pattern is a field\n-    /// of a struct/tuple/variant.\n-    fn from_single_pattern(pat: &'p Pat<'tcx>) -> Self {\n-        Fields::Slice(std::slice::from_ref(pat))\n-    }\n-\n-    /// Convenience; internal use.\n-    fn wildcards_from_tys(\n-        cx: &MatchCheckCtxt<'p, 'tcx>,\n-        tys: impl IntoIterator<Item = Ty<'tcx>>,\n-    ) -> Self {\n-        let wilds = tys.into_iter().map(Pat::wildcard_from_ty);\n-        let pats = cx.pattern_arena.alloc_from_iter(wilds);\n-        Fields::Slice(pats)\n-    }\n-\n-    /// Creates a new list of wildcard fields for a given constructor.\n-    fn wildcards(pcx: PatCtxt<'_, 'p, 'tcx>, constructor: &Constructor<'tcx>) -> Self {\n-        let ty = pcx.ty;\n-        let cx = pcx.cx;\n-        let wildcard_from_ty = |ty| &*cx.pattern_arena.alloc(Pat::wildcard_from_ty(ty));\n-\n-        let ret = match constructor {\n-            Single | Variant(_) => match ty.kind() {\n-                ty::Tuple(ref fs) => {\n-                    Fields::wildcards_from_tys(cx, fs.into_iter().map(|ty| ty.expect_ty()))\n-                }\n-                ty::Ref(_, rty, _) => Fields::from_single_pattern(wildcard_from_ty(rty)),\n-                ty::Adt(adt, substs) => {\n-                    if adt.is_box() {\n-                        // Use T as the sub pattern type of Box<T>.\n-                        Fields::from_single_pattern(wildcard_from_ty(substs.type_at(0)))\n-                    } else {\n-                        let variant = &adt.variants[constructor.variant_index_for_adt(adt)];\n-                        // Whether we must not match the fields of this variant exhaustively.\n-                        let is_non_exhaustive =\n-                            variant.is_field_list_non_exhaustive() && !adt.did.is_local();\n-                        let field_tys = variant.fields.iter().map(|field| field.ty(cx.tcx, substs));\n-                        // In the following cases, we don't need to filter out any fields. This is\n-                        // the vast majority of real cases, since uninhabited fields are uncommon.\n-                        let has_no_hidden_fields = (adt.is_enum() && !is_non_exhaustive)\n-                            || !field_tys.clone().any(|ty| cx.is_uninhabited(ty));\n-\n-                        if has_no_hidden_fields {\n-                            Fields::wildcards_from_tys(cx, field_tys)\n-                        } else {\n-                            let mut kept_count = 0;\n-                            let fields = variant\n-                                .fields\n-                                .iter()\n-                                .map(|field| {\n-                                    let ty = field.ty(cx.tcx, substs);\n-                                    let is_visible = adt.is_enum()\n-                                        || field.vis.is_accessible_from(cx.module, cx.tcx);\n-                                    let is_uninhabited = cx.is_uninhabited(ty);\n-\n-                                    // In the cases of either a `#[non_exhaustive]` field list\n-                                    // or a non-public field, we hide uninhabited fields in\n-                                    // order not to reveal the uninhabitedness of the whole\n-                                    // variant.\n-                                    if is_uninhabited && (!is_visible || is_non_exhaustive) {\n-                                        FilteredField::Hidden(ty)\n-                                    } else {\n-                                        kept_count += 1;\n-                                        FilteredField::Kept(wildcard_from_ty(ty))\n-                                    }\n-                                })\n-                                .collect();\n-                            Fields::Filtered { fields, kept_count }\n-                        }\n-                    }\n-                }\n-                _ => bug!(\"Unexpected type for `Single` constructor: {:?}\", ty),\n-            },\n-            Slice(slice) => match *ty.kind() {\n-                ty::Slice(ty) | ty::Array(ty, _) => {\n-                    let arity = slice.arity();\n-                    Fields::wildcards_from_tys(cx, (0..arity).map(|_| ty))\n-                }\n-                _ => bug!(\"bad slice pattern {:?} {:?}\", constructor, ty),\n-            },\n-            Str(..) | FloatRange(..) | IntRange(..) | NonExhaustive | Opaque | Wildcard => {\n-                Fields::empty()\n-            }\n-        };\n-        debug!(\"Fields::wildcards({:?}, {:?}) = {:#?}\", constructor, ty, ret);\n-        ret\n-    }\n-\n-    /// Apply a constructor to a list of patterns, yielding a new pattern. `self`\n-    /// must have as many elements as this constructor's arity.\n-    ///\n-    /// This is roughly the inverse of `specialize_constructor`.\n-    ///\n-    /// Examples:\n-    /// `ctor`: `Constructor::Single`\n-    /// `ty`: `Foo(u32, u32, u32)`\n-    /// `self`: `[10, 20, _]`\n-    /// returns `Foo(10, 20, _)`\n-    ///\n-    /// `ctor`: `Constructor::Variant(Option::Some)`\n-    /// `ty`: `Option<bool>`\n-    /// `self`: `[false]`\n-    /// returns `Some(false)`\n-    fn apply(self, pcx: PatCtxt<'_, 'p, 'tcx>, ctor: &Constructor<'tcx>) -> Pat<'tcx> {\n-        let mut subpatterns = self.all_patterns();\n-\n-        let pat = match ctor {\n-            Single | Variant(_) => match pcx.ty.kind() {\n-                ty::Adt(..) | ty::Tuple(..) => {\n-                    let subpatterns = subpatterns\n-                        .enumerate()\n-                        .map(|(i, p)| FieldPat { field: Field::new(i), pattern: p })\n-                        .collect();\n-\n-                    if let ty::Adt(adt, substs) = pcx.ty.kind() {\n-                        if adt.is_enum() {\n-                            PatKind::Variant {\n-                                adt_def: adt,\n-                                substs,\n-                                variant_index: ctor.variant_index_for_adt(adt),\n-                                subpatterns,\n-                            }\n-                        } else {\n-                            PatKind::Leaf { subpatterns }\n-                        }\n-                    } else {\n-                        PatKind::Leaf { subpatterns }\n-                    }\n-                }\n-                // Note: given the expansion of `&str` patterns done in `expand_pattern`, we should\n-                // be careful to reconstruct the correct constant pattern here. However a string\n-                // literal pattern will never be reported as a non-exhaustiveness witness, so we\n-                // can ignore this issue.\n-                ty::Ref(..) => PatKind::Deref { subpattern: subpatterns.next().unwrap() },\n-                ty::Slice(_) | ty::Array(..) => bug!(\"bad slice pattern {:?} {:?}\", ctor, pcx.ty),\n-                _ => PatKind::Wild,\n-            },\n-            Slice(slice) => match slice.kind {\n-                FixedLen(_) => {\n-                    PatKind::Slice { prefix: subpatterns.collect(), slice: None, suffix: vec![] }\n-                }\n-                VarLen(prefix, _) => {\n-                    let mut prefix: Vec<_> = subpatterns.by_ref().take(prefix as usize).collect();\n-                    if slice.array_len.is_some() {\n-                        // Improves diagnostics a bit: if the type is a known-size array, instead\n-                        // of reporting `[x, _, .., _, y]`, we prefer to report `[x, .., y]`.\n-                        // This is incorrect if the size is not known, since `[_, ..]` captures\n-                        // arrays of lengths `>= 1` whereas `[..]` captures any length.\n-                        while !prefix.is_empty() && prefix.last().unwrap().is_wildcard() {\n-                            prefix.pop();\n-                        }\n-                    }\n-                    let suffix: Vec<_> = if slice.array_len.is_some() {\n-                        // Same as above.\n-                        subpatterns.skip_while(Pat::is_wildcard).collect()\n-                    } else {\n-                        subpatterns.collect()\n-                    };\n-                    let wild = Pat::wildcard_from_ty(pcx.ty);\n-                    PatKind::Slice { prefix, slice: Some(wild), suffix }\n-                }\n-            },\n-            &Str(value) => PatKind::Constant { value },\n-            &FloatRange(lo, hi, end) => PatKind::Range(PatRange { lo, hi, end }),\n-            IntRange(range) => return range.to_pat(pcx.cx.tcx),\n-            NonExhaustive => PatKind::Wild,\n-            Opaque => bug!(\"we should not try to apply an opaque constructor\"),\n-            Wildcard => bug!(\n-                \"trying to apply a wildcard constructor; this should have been done in `apply_constructors`\"\n-            ),\n-        };\n-\n-        Pat { ty: pcx.ty, span: DUMMY_SP, kind: Box::new(pat) }\n-    }\n-\n-    /// Returns the number of patterns from the viewpoint of match-checking, i.e. excluding hidden\n-    /// fields. This is what we want in most cases in this file, the only exception being\n-    /// conversion to/from `Pat`.\n-    fn len(&self) -> usize {\n-        match self {\n-            Fields::Slice(pats) => pats.len(),\n-            Fields::Vec(pats) => pats.len(),\n-            Fields::Filtered { kept_count, .. } => *kept_count,\n-        }\n-    }\n-\n-    /// Returns the complete list of patterns, including hidden fields.\n-    fn all_patterns(self) -> impl Iterator<Item = Pat<'tcx>> {\n-        let pats: SmallVec<[_; 2]> = match self {\n-            Fields::Slice(pats) => pats.iter().cloned().collect(),\n-            Fields::Vec(pats) => pats.into_iter().cloned().collect(),\n-            Fields::Filtered { fields, .. } => {\n-                // We don't skip any fields here.\n-                fields.into_iter().map(|p| p.to_pattern()).collect()\n-            }\n-        };\n-        pats.into_iter()\n-    }\n-\n-    /// Returns the filtered list of patterns, not including hidden fields.\n-    fn filtered_patterns(self) -> SmallVec<[&'p Pat<'tcx>; 2]> {\n-        match self {\n-            Fields::Slice(pats) => pats.iter().collect(),\n-            Fields::Vec(pats) => pats,\n-            Fields::Filtered { fields, .. } => {\n-                // We skip hidden fields here\n-                fields.into_iter().filter_map(|p| p.kept()).collect()\n-            }\n-        }\n-    }\n-\n-    /// Overrides some of the fields with the provided patterns. Exactly like\n-    /// `replace_fields_indexed`, except that it takes `FieldPat`s as input.\n-    fn replace_with_fieldpats(\n-        &self,\n-        new_pats: impl IntoIterator<Item = &'p FieldPat<'tcx>>,\n-    ) -> Self {\n-        self.replace_fields_indexed(\n-            new_pats.into_iter().map(|pat| (pat.field.index(), &pat.pattern)),\n-        )\n-    }\n-\n-    /// Overrides some of the fields with the provided patterns. This is used when a pattern\n-    /// defines some fields but not all, for example `Foo { field1: Some(_), .. }`: here we start with a\n-    /// `Fields` that is just one wildcard per field of the `Foo` struct, and override the entry\n-    /// corresponding to `field1` with the pattern `Some(_)`. This is also used for slice patterns\n-    /// for the same reason.\n-    fn replace_fields_indexed(\n-        &self,\n-        new_pats: impl IntoIterator<Item = (usize, &'p Pat<'tcx>)>,\n-    ) -> Self {\n-        let mut fields = self.clone();\n-        if let Fields::Slice(pats) = fields {\n-            fields = Fields::Vec(pats.iter().collect());\n-        }\n-\n-        match &mut fields {\n-            Fields::Vec(pats) => {\n-                for (i, pat) in new_pats {\n-                    pats[i] = pat\n-                }\n-            }\n-            Fields::Filtered { fields, .. } => {\n-                for (i, pat) in new_pats {\n-                    if let FilteredField::Kept(p) = &mut fields[i] {\n-                        *p = pat\n-                    }\n-                }\n-            }\n-            Fields::Slice(_) => unreachable!(),\n-        }\n-        fields\n-    }\n-\n-    /// Replaces contained fields with the given filtered list of patterns, e.g. taken from the\n-    /// matrix. There must be `len()` patterns in `pats`.\n-    fn replace_fields(\n-        &self,\n-        cx: &MatchCheckCtxt<'p, 'tcx>,\n-        pats: impl IntoIterator<Item = Pat<'tcx>>,\n-    ) -> Self {\n-        let pats: &[_] = cx.pattern_arena.alloc_from_iter(pats);\n-\n-        match self {\n-            Fields::Filtered { fields, kept_count } => {\n-                let mut pats = pats.iter();\n-                let mut fields = fields.clone();\n-                for f in &mut fields {\n-                    if let FilteredField::Kept(p) = f {\n-                        // We take one input pattern for each `Kept` field, in order.\n-                        *p = pats.next().unwrap();\n-                    }\n-                }\n-                Fields::Filtered { fields, kept_count: *kept_count }\n-            }\n-            _ => Fields::Slice(pats),\n-        }\n-    }\n-\n-    /// Replaces contained fields with the arguments of the given pattern. Only use on a pattern\n-    /// that is compatible with the constructor used to build `self`.\n-    /// This is meant to be used on the result of `Fields::wildcards()`. The idea is that\n-    /// `wildcards` constructs a list of fields where all entries are wildcards, and the pattern\n-    /// provided to this function fills some of the fields with non-wildcards.\n-    /// In the following example `Fields::wildcards` would return `[_, _, _, _]`. If we call\n-    /// `replace_with_pattern_arguments` on it with the pattern, the result will be `[Some(0), _,\n-    /// _, _]`.\n-    /// ```rust\n-    /// let x: [Option<u8>; 4] = foo();\n-    /// match x {\n-    ///     [Some(0), ..] => {}\n-    /// }\n-    /// ```\n-    /// This is guaranteed to preserve the number of patterns in `self`.\n-    fn replace_with_pattern_arguments(&self, pat: &'p Pat<'tcx>) -> Self {\n-        match pat.kind.as_ref() {\n-            PatKind::Deref { subpattern } => {\n-                assert_eq!(self.len(), 1);\n-                Fields::from_single_pattern(subpattern)\n-            }\n-            PatKind::Leaf { subpatterns } | PatKind::Variant { subpatterns, .. } => {\n-                self.replace_with_fieldpats(subpatterns)\n-            }\n-            PatKind::Array { prefix, suffix, .. } | PatKind::Slice { prefix, suffix, .. } => {\n-                // Number of subpatterns for the constructor\n-                let ctor_arity = self.len();\n-\n-                // Replace the prefix and the suffix with the given patterns, leaving wildcards in\n-                // the middle if there was a subslice pattern `..`.\n-                let prefix = prefix.iter().enumerate();\n-                let suffix =\n-                    suffix.iter().enumerate().map(|(i, p)| (ctor_arity - suffix.len() + i, p));\n-                self.replace_fields_indexed(prefix.chain(suffix))\n-            }\n-            _ => self.clone(),\n-        }\n-    }\n-}\n-\n #[derive(Clone, Debug)]\n crate enum Usefulness<'tcx> {\n     /// Carries, for each column in the matrix, a set of sub-branches that have been found to be\n@@ -1459,17 +685,17 @@ enum WitnessPreference {\n }\n \n #[derive(Copy, Clone)]\n-struct PatCtxt<'a, 'p, 'tcx> {\n-    cx: &'a MatchCheckCtxt<'p, 'tcx>,\n+pub(super) struct PatCtxt<'a, 'p, 'tcx> {\n+    pub(super) cx: &'a MatchCheckCtxt<'p, 'tcx>,\n     /// Current state of the matrix.\n-    matrix: &'a Matrix<'p, 'tcx>,\n+    pub(super) matrix: &'a Matrix<'p, 'tcx>,\n     /// Type of the current column under investigation.\n-    ty: Ty<'tcx>,\n+    pub(super) ty: Ty<'tcx>,\n     /// Span of the current pattern under investigation.\n-    span: Span,\n+    pub(super) span: Span,\n     /// Whether the current pattern is the whole pattern as found in a match arm, or if it's a\n     /// subpattern.\n-    is_top_level: bool,\n+    pub(super) is_top_level: bool,\n }\n \n /// A witness of non-exhaustiveness for error reporting, represented\n@@ -1547,540 +773,6 @@ impl<'tcx> Witness<'tcx> {\n     }\n }\n \n-/// This determines the set of all possible constructors of a pattern matching\n-/// values of type `left_ty`. For vectors, this would normally be an infinite set\n-/// but is instead bounded by the maximum fixed length of slice patterns in\n-/// the column of patterns being analyzed.\n-///\n-/// We make sure to omit constructors that are statically impossible. E.g., for\n-/// `Option<!>`, we do not include `Some(_)` in the returned list of constructors.\n-/// Invariant: this returns an empty `Vec` if and only if the type is uninhabited (as determined by\n-/// `cx.is_uninhabited()`).\n-fn all_constructors<'p, 'tcx>(pcx: PatCtxt<'_, 'p, 'tcx>) -> Vec<Constructor<'tcx>> {\n-    debug!(\"all_constructors({:?})\", pcx.ty);\n-    let cx = pcx.cx;\n-    let make_range = |start, end| {\n-        IntRange(\n-            // `unwrap()` is ok because we know the type is an integer.\n-            IntRange::from_range(cx.tcx, start, end, pcx.ty, &RangeEnd::Included, pcx.span)\n-                .unwrap(),\n-        )\n-    };\n-    match pcx.ty.kind() {\n-        ty::Bool => vec![make_range(0, 1)],\n-        ty::Array(sub_ty, len) if len.try_eval_usize(cx.tcx, cx.param_env).is_some() => {\n-            let len = len.eval_usize(cx.tcx, cx.param_env);\n-            if len != 0 && cx.is_uninhabited(sub_ty) {\n-                vec![]\n-            } else {\n-                vec![Slice(Slice::new(Some(len), VarLen(0, 0)))]\n-            }\n-        }\n-        // Treat arrays of a constant but unknown length like slices.\n-        ty::Array(sub_ty, _) | ty::Slice(sub_ty) => {\n-            let kind = if cx.is_uninhabited(sub_ty) { FixedLen(0) } else { VarLen(0, 0) };\n-            vec![Slice(Slice::new(None, kind))]\n-        }\n-        ty::Adt(def, substs) if def.is_enum() => {\n-            // If the enum is declared as `#[non_exhaustive]`, we treat it as if it had an\n-            // additional \"unknown\" constructor.\n-            // There is no point in enumerating all possible variants, because the user can't\n-            // actually match against them all themselves. So we always return only the fictitious\n-            // constructor.\n-            // E.g., in an example like:\n-            //\n-            // ```\n-            //     let err: io::ErrorKind = ...;\n-            //     match err {\n-            //         io::ErrorKind::NotFound => {},\n-            //     }\n-            // ```\n-            //\n-            // we don't want to show every possible IO error, but instead have only `_` as the\n-            // witness.\n-            let is_declared_nonexhaustive = cx.is_foreign_non_exhaustive_enum(pcx.ty);\n-\n-            // If `exhaustive_patterns` is disabled and our scrutinee is an empty enum, we treat it\n-            // as though it had an \"unknown\" constructor to avoid exposing its emptiness. The\n-            // exception is if the pattern is at the top level, because we want empty matches to be\n-            // considered exhaustive.\n-            let is_secretly_empty = def.variants.is_empty()\n-                && !cx.tcx.features().exhaustive_patterns\n-                && !pcx.is_top_level;\n-\n-            if is_secretly_empty || is_declared_nonexhaustive {\n-                vec![NonExhaustive]\n-            } else if cx.tcx.features().exhaustive_patterns {\n-                // If `exhaustive_patterns` is enabled, we exclude variants known to be\n-                // uninhabited.\n-                def.variants\n-                    .iter()\n-                    .filter(|v| {\n-                        !v.uninhabited_from(cx.tcx, substs, def.adt_kind(), cx.param_env)\n-                            .contains(cx.tcx, cx.module)\n-                    })\n-                    .map(|v| Variant(v.def_id))\n-                    .collect()\n-            } else {\n-                def.variants.iter().map(|v| Variant(v.def_id)).collect()\n-            }\n-        }\n-        ty::Char => {\n-            vec![\n-                // The valid Unicode Scalar Value ranges.\n-                make_range('\\u{0000}' as u128, '\\u{D7FF}' as u128),\n-                make_range('\\u{E000}' as u128, '\\u{10FFFF}' as u128),\n-            ]\n-        }\n-        ty::Int(_) | ty::Uint(_)\n-            if pcx.ty.is_ptr_sized_integral()\n-                && !cx.tcx.features().precise_pointer_size_matching =>\n-        {\n-            // `usize`/`isize` are not allowed to be matched exhaustively unless the\n-            // `precise_pointer_size_matching` feature is enabled. So we treat those types like\n-            // `#[non_exhaustive]` enums by returning a special unmatcheable constructor.\n-            vec![NonExhaustive]\n-        }\n-        &ty::Int(ity) => {\n-            let bits = Integer::from_attr(&cx.tcx, SignedInt(ity)).size().bits() as u128;\n-            let min = 1u128 << (bits - 1);\n-            let max = min - 1;\n-            vec![make_range(min, max)]\n-        }\n-        &ty::Uint(uty) => {\n-            let size = Integer::from_attr(&cx.tcx, UnsignedInt(uty)).size();\n-            let max = size.truncate(u128::MAX);\n-            vec![make_range(0, max)]\n-        }\n-        // If `exhaustive_patterns` is disabled and our scrutinee is the never type, we cannot\n-        // expose its emptiness. The exception is if the pattern is at the top level, because we\n-        // want empty matches to be considered exhaustive.\n-        ty::Never if !cx.tcx.features().exhaustive_patterns && !pcx.is_top_level => {\n-            vec![NonExhaustive]\n-        }\n-        ty::Never => vec![],\n-        _ if cx.is_uninhabited(pcx.ty) => vec![],\n-        ty::Adt(..) | ty::Tuple(..) | ty::Ref(..) => vec![Single],\n-        // This type is one for which we cannot list constructors, like `str` or `f64`.\n-        _ => vec![NonExhaustive],\n-    }\n-}\n-\n-/// An inclusive interval, used for precise integer exhaustiveness checking.\n-/// `IntRange`s always store a contiguous range. This means that values are\n-/// encoded such that `0` encodes the minimum value for the integer,\n-/// regardless of the signedness.\n-/// For example, the pattern `-128..=127i8` is encoded as `0..=255`.\n-/// This makes comparisons and arithmetic on interval endpoints much more\n-/// straightforward. See `signed_bias` for details.\n-///\n-/// `IntRange` is never used to encode an empty range or a \"range\" that wraps\n-/// around the (offset) space: i.e., `range.lo <= range.hi`.\n-#[derive(Clone, Debug)]\n-struct IntRange<'tcx> {\n-    range: RangeInclusive<u128>,\n-    ty: Ty<'tcx>,\n-    span: Span,\n-}\n-\n-impl<'tcx> IntRange<'tcx> {\n-    #[inline]\n-    fn is_integral(ty: Ty<'_>) -> bool {\n-        matches!(ty.kind(), ty::Char | ty::Int(_) | ty::Uint(_) | ty::Bool)\n-    }\n-\n-    fn is_singleton(&self) -> bool {\n-        self.range.start() == self.range.end()\n-    }\n-\n-    fn boundaries(&self) -> (u128, u128) {\n-        (*self.range.start(), *self.range.end())\n-    }\n-\n-    /// Don't treat `usize`/`isize` exhaustively unless the `precise_pointer_size_matching` feature\n-    /// is enabled.\n-    fn treat_exhaustively(&self, tcx: TyCtxt<'tcx>) -> bool {\n-        !self.ty.is_ptr_sized_integral() || tcx.features().precise_pointer_size_matching\n-    }\n-\n-    #[inline]\n-    fn integral_size_and_signed_bias(tcx: TyCtxt<'tcx>, ty: Ty<'_>) -> Option<(Size, u128)> {\n-        match *ty.kind() {\n-            ty::Bool => Some((Size::from_bytes(1), 0)),\n-            ty::Char => Some((Size::from_bytes(4), 0)),\n-            ty::Int(ity) => {\n-                let size = Integer::from_attr(&tcx, SignedInt(ity)).size();\n-                Some((size, 1u128 << (size.bits() as u128 - 1)))\n-            }\n-            ty::Uint(uty) => Some((Integer::from_attr(&tcx, UnsignedInt(uty)).size(), 0)),\n-            _ => None,\n-        }\n-    }\n-\n-    #[inline]\n-    fn from_const(\n-        tcx: TyCtxt<'tcx>,\n-        param_env: ty::ParamEnv<'tcx>,\n-        value: &Const<'tcx>,\n-        span: Span,\n-    ) -> Option<IntRange<'tcx>> {\n-        if let Some((target_size, bias)) = Self::integral_size_and_signed_bias(tcx, value.ty) {\n-            let ty = value.ty;\n-            let val = (|| {\n-                if let ty::ConstKind::Value(ConstValue::Scalar(scalar)) = value.val {\n-                    // For this specific pattern we can skip a lot of effort and go\n-                    // straight to the result, after doing a bit of checking. (We\n-                    // could remove this branch and just fall through, which\n-                    // is more general but much slower.)\n-                    if let Ok(bits) = scalar.to_bits_or_ptr(target_size, &tcx) {\n-                        return Some(bits);\n-                    }\n-                }\n-                // This is a more general form of the previous case.\n-                value.try_eval_bits(tcx, param_env, ty)\n-            })()?;\n-            let val = val ^ bias;\n-            Some(IntRange { range: val..=val, ty, span })\n-        } else {\n-            None\n-        }\n-    }\n-\n-    #[inline]\n-    fn from_range(\n-        tcx: TyCtxt<'tcx>,\n-        lo: u128,\n-        hi: u128,\n-        ty: Ty<'tcx>,\n-        end: &RangeEnd,\n-        span: Span,\n-    ) -> Option<IntRange<'tcx>> {\n-        if Self::is_integral(ty) {\n-            // Perform a shift if the underlying types are signed,\n-            // which makes the interval arithmetic simpler.\n-            let bias = IntRange::signed_bias(tcx, ty);\n-            let (lo, hi) = (lo ^ bias, hi ^ bias);\n-            let offset = (*end == RangeEnd::Excluded) as u128;\n-            if lo > hi || (lo == hi && *end == RangeEnd::Excluded) {\n-                // This should have been caught earlier by E0030.\n-                bug!(\"malformed range pattern: {}..={}\", lo, (hi - offset));\n-            }\n-            Some(IntRange { range: lo..=(hi - offset), ty, span })\n-        } else {\n-            None\n-        }\n-    }\n-\n-    // The return value of `signed_bias` should be XORed with an endpoint to encode/decode it.\n-    fn signed_bias(tcx: TyCtxt<'tcx>, ty: Ty<'tcx>) -> u128 {\n-        match *ty.kind() {\n-            ty::Int(ity) => {\n-                let bits = Integer::from_attr(&tcx, SignedInt(ity)).size().bits() as u128;\n-                1u128 << (bits - 1)\n-            }\n-            _ => 0,\n-        }\n-    }\n-\n-    fn is_subrange(&self, other: &Self) -> bool {\n-        other.range.start() <= self.range.start() && self.range.end() <= other.range.end()\n-    }\n-\n-    fn intersection(&self, tcx: TyCtxt<'tcx>, other: &Self) -> Option<Self> {\n-        let ty = self.ty;\n-        let (lo, hi) = self.boundaries();\n-        let (other_lo, other_hi) = other.boundaries();\n-        if self.treat_exhaustively(tcx) {\n-            if lo <= other_hi && other_lo <= hi {\n-                let span = other.span;\n-                Some(IntRange { range: max(lo, other_lo)..=min(hi, other_hi), ty, span })\n-            } else {\n-                None\n-            }\n-        } else {\n-            // If the range should not be treated exhaustively, fallback to checking for inclusion.\n-            if self.is_subrange(other) { Some(self.clone()) } else { None }\n-        }\n-    }\n-\n-    fn suspicious_intersection(&self, other: &Self) -> bool {\n-        // `false` in the following cases:\n-        // 1     ----      // 1  ----------   // 1 ----        // 1       ----\n-        // 2  ----------   // 2     ----      // 2       ----  // 2 ----\n-        //\n-        // The following are currently `false`, but could be `true` in the future (#64007):\n-        // 1 ---------       // 1     ---------\n-        // 2     ----------  // 2 ----------\n-        //\n-        // `true` in the following cases:\n-        // 1 -------          // 1       -------\n-        // 2       --------   // 2 -------\n-        let (lo, hi) = self.boundaries();\n-        let (other_lo, other_hi) = other.boundaries();\n-        lo == other_hi || hi == other_lo\n-    }\n-\n-    fn to_pat(&self, tcx: TyCtxt<'tcx>) -> Pat<'tcx> {\n-        let (lo, hi) = self.boundaries();\n-\n-        let bias = IntRange::signed_bias(tcx, self.ty);\n-        let (lo, hi) = (lo ^ bias, hi ^ bias);\n-\n-        let ty = ty::ParamEnv::empty().and(self.ty);\n-        let lo_const = ty::Const::from_bits(tcx, lo, ty);\n-        let hi_const = ty::Const::from_bits(tcx, hi, ty);\n-\n-        let kind = if lo == hi {\n-            PatKind::Constant { value: lo_const }\n-        } else {\n-            PatKind::Range(PatRange { lo: lo_const, hi: hi_const, end: RangeEnd::Included })\n-        };\n-\n-        // This is a brand new pattern, so we don't reuse `self.span`.\n-        Pat { ty: self.ty, span: DUMMY_SP, kind: Box::new(kind) }\n-    }\n-\n-    /// For exhaustive integer matching, some constructors are grouped within other constructors\n-    /// (namely integer typed values are grouped within ranges). However, when specialising these\n-    /// constructors, we want to be specialising for the underlying constructors (the integers), not\n-    /// the groups (the ranges). Thus we need to split the groups up. Splitting them up na\u00efvely would\n-    /// mean creating a separate constructor for every single value in the range, which is clearly\n-    /// impractical. However, observe that for some ranges of integers, the specialisation will be\n-    /// identical across all values in that range (i.e., there are equivalence classes of ranges of\n-    /// constructors based on their `U(S(c, P), S(c, p))` outcome). These classes are grouped by\n-    /// the patterns that apply to them (in the matrix `P`). We can split the range whenever the\n-    /// patterns that apply to that range (specifically: the patterns that *intersect* with that range)\n-    /// change.\n-    /// Our solution, therefore, is to split the range constructor into subranges at every single point\n-    /// the group of intersecting patterns changes (using the method described below).\n-    /// And voil\u00e0! We're testing precisely those ranges that we need to, without any exhaustive matching\n-    /// on actual integers. The nice thing about this is that the number of subranges is linear in the\n-    /// number of rows in the matrix (i.e., the number of cases in the `match` statement), so we don't\n-    /// need to be worried about matching over gargantuan ranges.\n-    ///\n-    /// Essentially, given the first column of a matrix representing ranges, looking like the following:\n-    ///\n-    /// |------|  |----------| |-------|    ||\n-    ///    |-------| |-------|            |----| ||\n-    ///       |---------|\n-    ///\n-    /// We split the ranges up into equivalence classes so the ranges are no longer overlapping:\n-    ///\n-    /// |--|--|||-||||--||---|||-------|  |-|||| ||\n-    ///\n-    /// The logic for determining how to split the ranges is fairly straightforward: we calculate\n-    /// boundaries for each interval range, sort them, then create constructors for each new interval\n-    /// between every pair of boundary points. (This essentially sums up to performing the intuitive\n-    /// merging operation depicted above.)\n-    fn split<'p>(\n-        &self,\n-        pcx: PatCtxt<'_, 'p, 'tcx>,\n-        hir_id: Option<HirId>,\n-    ) -> SmallVec<[Constructor<'tcx>; 1]> {\n-        let ty = pcx.ty;\n-\n-        /// Represents a border between 2 integers. Because the intervals spanning borders\n-        /// must be able to cover every integer, we need to be able to represent\n-        /// 2^128 + 1 such borders.\n-        #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Debug)]\n-        enum Border {\n-            JustBefore(u128),\n-            AfterMax,\n-        }\n-\n-        // A function for extracting the borders of an integer interval.\n-        fn range_borders(r: IntRange<'_>) -> impl Iterator<Item = Border> {\n-            let (lo, hi) = r.range.into_inner();\n-            let from = Border::JustBefore(lo);\n-            let to = match hi.checked_add(1) {\n-                Some(m) => Border::JustBefore(m),\n-                None => Border::AfterMax,\n-            };\n-            vec![from, to].into_iter()\n-        }\n-\n-        // Collect the span and range of all the intersecting ranges to lint on likely\n-        // incorrect range patterns. (#63987)\n-        let mut overlaps = vec![];\n-        let row_len = pcx.matrix.column_count().unwrap_or(0);\n-        // `borders` is the set of borders between equivalence classes: each equivalence\n-        // class lies between 2 borders.\n-        let row_borders = pcx\n-            .matrix\n-            .head_ctors(pcx.cx)\n-            .filter_map(|ctor| ctor.as_int_range())\n-            .filter_map(|range| {\n-                let intersection = self.intersection(pcx.cx.tcx, &range);\n-                let should_lint = self.suspicious_intersection(&range);\n-                if let (Some(range), 1, true) = (&intersection, row_len, should_lint) {\n-                    // FIXME: for now, only check for overlapping ranges on simple range\n-                    // patterns. Otherwise with the current logic the following is detected\n-                    // as overlapping:\n-                    //   match (10u8, true) {\n-                    //    (0 ..= 125, false) => {}\n-                    //    (126 ..= 255, false) => {}\n-                    //    (0 ..= 255, true) => {}\n-                    //  }\n-                    overlaps.push(range.clone());\n-                }\n-                intersection\n-            })\n-            .flat_map(range_borders);\n-        let self_borders = range_borders(self.clone());\n-        let mut borders: Vec<_> = row_borders.chain(self_borders).collect();\n-        borders.sort_unstable();\n-\n-        self.lint_overlapping_patterns(pcx.cx.tcx, hir_id, ty, overlaps);\n-\n-        // We're going to iterate through every adjacent pair of borders, making sure that\n-        // each represents an interval of nonnegative length, and convert each such\n-        // interval into a constructor.\n-        borders\n-            .array_windows()\n-            .filter_map(|&pair| match pair {\n-                [Border::JustBefore(n), Border::JustBefore(m)] => {\n-                    if n < m {\n-                        Some(n..=(m - 1))\n-                    } else {\n-                        None\n-                    }\n-                }\n-                [Border::JustBefore(n), Border::AfterMax] => Some(n..=u128::MAX),\n-                [Border::AfterMax, _] => None,\n-            })\n-            .map(|range| IntRange { range, ty, span: pcx.span })\n-            .map(IntRange)\n-            .collect()\n-    }\n-\n-    fn lint_overlapping_patterns(\n-        &self,\n-        tcx: TyCtxt<'tcx>,\n-        hir_id: Option<HirId>,\n-        ty: Ty<'tcx>,\n-        overlaps: Vec<IntRange<'tcx>>,\n-    ) {\n-        if let (true, Some(hir_id)) = (!overlaps.is_empty(), hir_id) {\n-            tcx.struct_span_lint_hir(\n-                lint::builtin::OVERLAPPING_PATTERNS,\n-                hir_id,\n-                self.span,\n-                |lint| {\n-                    let mut err = lint.build(\"multiple patterns covering the same range\");\n-                    err.span_label(self.span, \"overlapping patterns\");\n-                    for int_range in overlaps {\n-                        // Use the real type for user display of the ranges:\n-                        err.span_label(\n-                            int_range.span,\n-                            &format!(\n-                                \"this range overlaps on `{}`\",\n-                                IntRange { range: int_range.range, ty, span: DUMMY_SP }.to_pat(tcx),\n-                            ),\n-                        );\n-                    }\n-                    err.emit();\n-                },\n-            );\n-        }\n-    }\n-\n-    /// See `Constructor::is_covered_by`\n-    fn is_covered_by<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>, other: &Self) -> bool {\n-        if self.intersection(pcx.cx.tcx, other).is_some() {\n-            // Constructor splitting should ensure that all intersections we encounter are actually\n-            // inclusions.\n-            assert!(self.is_subrange(other));\n-            true\n-        } else {\n-            false\n-        }\n-    }\n-}\n-\n-/// Ignore spans when comparing, they don't carry semantic information as they are only for lints.\n-impl<'tcx> std::cmp::PartialEq for IntRange<'tcx> {\n-    fn eq(&self, other: &Self) -> bool {\n-        self.range == other.range && self.ty == other.ty\n-    }\n-}\n-\n-// A struct to compute a set of constructors equivalent to `all_ctors \\ used_ctors`.\n-#[derive(Debug)]\n-struct MissingConstructors<'tcx> {\n-    all_ctors: SmallVec<[Constructor<'tcx>; 1]>,\n-    used_ctors: Vec<Constructor<'tcx>>,\n-}\n-\n-impl<'tcx> MissingConstructors<'tcx> {\n-    fn new<'p>(pcx: PatCtxt<'_, 'p, 'tcx>) -> Self {\n-        let used_ctors: Vec<Constructor<'_>> =\n-            pcx.matrix.head_ctors(pcx.cx).cloned().filter(|c| !c.is_wildcard()).collect();\n-        // Since `all_ctors` never contains wildcards, this won't recurse further.\n-        let all_ctors =\n-            all_constructors(pcx).into_iter().flat_map(|ctor| ctor.split(pcx, None)).collect();\n-\n-        MissingConstructors { all_ctors, used_ctors }\n-    }\n-\n-    fn is_empty<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>) -> bool {\n-        self.iter(pcx).next().is_none()\n-    }\n-\n-    /// Iterate over all_ctors \\ used_ctors\n-    fn iter<'a, 'p>(\n-        &'a self,\n-        pcx: PatCtxt<'a, 'p, 'tcx>,\n-    ) -> impl Iterator<Item = &'a Constructor<'tcx>> + Captures<'p> {\n-        self.all_ctors.iter().filter(move |ctor| !ctor.is_covered_by_any(pcx, &self.used_ctors))\n-    }\n-\n-    /// List the patterns corresponding to the missing constructors. In some cases, instead of\n-    /// listing all constructors of a given type, we prefer to simply report a wildcard.\n-    fn report_patterns<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>) -> SmallVec<[Pat<'tcx>; 1]> {\n-        // There are 2 ways we can report a witness here.\n-        // Commonly, we can report all the \"free\"\n-        // constructors as witnesses, e.g., if we have:\n-        //\n-        // ```\n-        //     enum Direction { N, S, E, W }\n-        //     let Direction::N = ...;\n-        // ```\n-        //\n-        // we can report 3 witnesses: `S`, `E`, and `W`.\n-        //\n-        // However, there is a case where we don't want\n-        // to do this and instead report a single `_` witness:\n-        // if the user didn't actually specify a constructor\n-        // in this arm, e.g., in\n-        //\n-        // ```\n-        //     let x: (Direction, Direction, bool) = ...;\n-        //     let (_, _, false) = x;\n-        // ```\n-        //\n-        // we don't want to show all 16 possible witnesses\n-        // `(<direction-1>, <direction-2>, true)` - we are\n-        // satisfied with `(_, _, true)`. In this case,\n-        // `used_ctors` is empty.\n-        // The exception is: if we are at the top-level, for example in an empty match, we\n-        // sometimes prefer reporting the list of constructors instead of just `_`.\n-        let report_when_all_missing = pcx.is_top_level && !IntRange::is_integral(pcx.ty);\n-        if self.used_ctors.is_empty() && !report_when_all_missing {\n-            // All constructors are unused. Report only a wildcard\n-            // rather than each individual constructor.\n-            smallvec![Pat::wildcard_from_ty(pcx.ty)]\n-        } else {\n-            // Construct for each missing constructor a \"wild\" version of this\n-            // constructor, that matches everything that can be built with\n-            // it. For example, if `ctor` is a `Constructor::Variant` for\n-            // `Option::Some`, we get the pattern `Some(_)`.\n-            self.iter(pcx)\n-                .map(|missing_ctor| Fields::wildcards(pcx, &missing_ctor).apply(pcx, missing_ctor))\n-                .collect()\n-        }\n-    }\n-}\n-\n /// Algorithm from <http://moscova.inria.fr/~maranget/papers/warn/index.html>.\n /// The algorithm from the paper has been modified to correctly handle empty\n /// types. The changes are:\n@@ -2240,67 +932,6 @@ fn is_useful<'p, 'tcx>(\n     ret\n }\n \n-/// Determines the constructor that the given pattern can be specialized to.\n-/// Returns `None` in case of a catch-all, which can't be specialized.\n-fn pat_constructor<'p, 'tcx>(\n-    cx: &MatchCheckCtxt<'p, 'tcx>,\n-    pat: &'p Pat<'tcx>,\n-) -> Constructor<'tcx> {\n-    match pat.kind.as_ref() {\n-        PatKind::AscribeUserType { .. } => bug!(), // Handled by `expand_pattern`\n-        PatKind::Binding { .. } | PatKind::Wild => Wildcard,\n-        PatKind::Leaf { .. } | PatKind::Deref { .. } => Single,\n-        &PatKind::Variant { adt_def, variant_index, .. } => {\n-            Variant(adt_def.variants[variant_index].def_id)\n-        }\n-        PatKind::Constant { value } => {\n-            if let Some(int_range) = IntRange::from_const(cx.tcx, cx.param_env, value, pat.span) {\n-                IntRange(int_range)\n-            } else {\n-                match pat.ty.kind() {\n-                    ty::Float(_) => FloatRange(value, value, RangeEnd::Included),\n-                    // In `expand_pattern`, we convert string literals to `&CONST` patterns with\n-                    // `CONST` a pattern of type `str`. In truth this contains a constant of type\n-                    // `&str`.\n-                    ty::Str => Str(value),\n-                    // All constants that can be structurally matched have already been expanded\n-                    // into the corresponding `Pat`s by `const_to_pat`. Constants that remain are\n-                    // opaque.\n-                    _ => Opaque,\n-                }\n-            }\n-        }\n-        &PatKind::Range(PatRange { lo, hi, end }) => {\n-            let ty = lo.ty;\n-            if let Some(int_range) = IntRange::from_range(\n-                cx.tcx,\n-                lo.eval_bits(cx.tcx, cx.param_env, lo.ty),\n-                hi.eval_bits(cx.tcx, cx.param_env, hi.ty),\n-                ty,\n-                &end,\n-                pat.span,\n-            ) {\n-                IntRange(int_range)\n-            } else {\n-                FloatRange(lo, hi, end)\n-            }\n-        }\n-        PatKind::Array { prefix, slice, suffix } | PatKind::Slice { prefix, slice, suffix } => {\n-            let array_len = match pat.ty.kind() {\n-                ty::Array(_, length) => Some(length.eval_usize(cx.tcx, cx.param_env)),\n-                ty::Slice(_) => None,\n-                _ => span_bug!(pat.span, \"bad ty {:?} for slice pattern\", pat.ty),\n-            };\n-            let prefix = prefix.len() as u64;\n-            let suffix = suffix.len() as u64;\n-            let kind =\n-                if slice.is_some() { VarLen(prefix, suffix) } else { FixedLen(prefix + suffix) };\n-            Slice(Slice::new(array_len, kind))\n-        }\n-        PatKind::Or { .. } => bug!(\"Or-pattern should have been expanded earlier on.\"),\n-    }\n-}\n-\n /// The arm of a match expression.\n #[derive(Clone, Copy)]\n crate struct MatchArm<'p, 'tcx> {"}, {"sha": "932cf637c9dc752bbe3ff6f653b32e84257ec93c", "filename": "compiler/rustc_mir_build/src/thir/pattern/deconstruct_pat.rs", "status": "added", "additions": 1394, "deletions": 0, "changes": 1394, "blob_url": "https://github.com/rust-lang/rust/blob/2184a1444cb670421bf2836cbdbb662c077bad6a/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fdeconstruct_pat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2184a1444cb670421bf2836cbdbb662c077bad6a/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fdeconstruct_pat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fdeconstruct_pat.rs?ref=2184a1444cb670421bf2836cbdbb662c077bad6a", "patch": "@@ -0,0 +1,1394 @@\n+//! This module provides functions to deconstruct and reconstruct patterns into a constructor\n+//! applied to some fields. This is used by the `_match` module to compute pattern\n+//! usefulness/exhaustiveness.\n+use self::Constructor::*;\n+use self::SliceKind::*;\n+\n+use super::_match::{MatchCheckCtxt, PatCtxt};\n+use super::compare_const_vals;\n+use super::{FieldPat, Pat, PatKind, PatRange};\n+\n+use rustc_data_structures::captures::Captures;\n+use rustc_index::vec::Idx;\n+\n+use rustc_attr::{SignedInt, UnsignedInt};\n+use rustc_hir::def_id::DefId;\n+use rustc_hir::{HirId, RangeEnd};\n+use rustc_middle::mir::interpret::ConstValue;\n+use rustc_middle::mir::Field;\n+use rustc_middle::ty::layout::IntegerExt;\n+use rustc_middle::ty::{self, Const, Ty, TyCtxt};\n+use rustc_session::lint;\n+use rustc_span::{Span, DUMMY_SP};\n+use rustc_target::abi::{Integer, Size, VariantIdx};\n+\n+use smallvec::{smallvec, SmallVec};\n+use std::cmp::{self, max, min, Ordering};\n+use std::iter::IntoIterator;\n+use std::ops::RangeInclusive;\n+\n+/// An inclusive interval, used for precise integer exhaustiveness checking.\n+/// `IntRange`s always store a contiguous range. This means that values are\n+/// encoded such that `0` encodes the minimum value for the integer,\n+/// regardless of the signedness.\n+/// For example, the pattern `-128..=127i8` is encoded as `0..=255`.\n+/// This makes comparisons and arithmetic on interval endpoints much more\n+/// straightforward. See `signed_bias` for details.\n+///\n+/// `IntRange` is never used to encode an empty range or a \"range\" that wraps\n+/// around the (offset) space: i.e., `range.lo <= range.hi`.\n+#[derive(Clone, Debug)]\n+pub(super) struct IntRange<'tcx> {\n+    range: RangeInclusive<u128>,\n+    ty: Ty<'tcx>,\n+    span: Span,\n+}\n+\n+impl<'tcx> IntRange<'tcx> {\n+    #[inline]\n+    fn is_integral(ty: Ty<'_>) -> bool {\n+        matches!(ty.kind(), ty::Char | ty::Int(_) | ty::Uint(_) | ty::Bool)\n+    }\n+\n+    fn is_singleton(&self) -> bool {\n+        self.range.start() == self.range.end()\n+    }\n+\n+    fn boundaries(&self) -> (u128, u128) {\n+        (*self.range.start(), *self.range.end())\n+    }\n+\n+    /// Don't treat `usize`/`isize` exhaustively unless the `precise_pointer_size_matching` feature\n+    /// is enabled.\n+    fn treat_exhaustively(&self, tcx: TyCtxt<'tcx>) -> bool {\n+        !self.ty.is_ptr_sized_integral() || tcx.features().precise_pointer_size_matching\n+    }\n+\n+    #[inline]\n+    fn integral_size_and_signed_bias(tcx: TyCtxt<'tcx>, ty: Ty<'_>) -> Option<(Size, u128)> {\n+        match *ty.kind() {\n+            ty::Bool => Some((Size::from_bytes(1), 0)),\n+            ty::Char => Some((Size::from_bytes(4), 0)),\n+            ty::Int(ity) => {\n+                let size = Integer::from_attr(&tcx, SignedInt(ity)).size();\n+                Some((size, 1u128 << (size.bits() as u128 - 1)))\n+            }\n+            ty::Uint(uty) => Some((Integer::from_attr(&tcx, UnsignedInt(uty)).size(), 0)),\n+            _ => None,\n+        }\n+    }\n+\n+    #[inline]\n+    fn from_const(\n+        tcx: TyCtxt<'tcx>,\n+        param_env: ty::ParamEnv<'tcx>,\n+        value: &Const<'tcx>,\n+        span: Span,\n+    ) -> Option<IntRange<'tcx>> {\n+        if let Some((target_size, bias)) = Self::integral_size_and_signed_bias(tcx, value.ty) {\n+            let ty = value.ty;\n+            let val = (|| {\n+                if let ty::ConstKind::Value(ConstValue::Scalar(scalar)) = value.val {\n+                    // For this specific pattern we can skip a lot of effort and go\n+                    // straight to the result, after doing a bit of checking. (We\n+                    // could remove this branch and just fall through, which\n+                    // is more general but much slower.)\n+                    if let Ok(bits) = scalar.to_bits_or_ptr(target_size, &tcx) {\n+                        return Some(bits);\n+                    }\n+                }\n+                // This is a more general form of the previous case.\n+                value.try_eval_bits(tcx, param_env, ty)\n+            })()?;\n+            let val = val ^ bias;\n+            Some(IntRange { range: val..=val, ty, span })\n+        } else {\n+            None\n+        }\n+    }\n+\n+    #[inline]\n+    fn from_range(\n+        tcx: TyCtxt<'tcx>,\n+        lo: u128,\n+        hi: u128,\n+        ty: Ty<'tcx>,\n+        end: &RangeEnd,\n+        span: Span,\n+    ) -> Option<IntRange<'tcx>> {\n+        if Self::is_integral(ty) {\n+            // Perform a shift if the underlying types are signed,\n+            // which makes the interval arithmetic simpler.\n+            let bias = IntRange::signed_bias(tcx, ty);\n+            let (lo, hi) = (lo ^ bias, hi ^ bias);\n+            let offset = (*end == RangeEnd::Excluded) as u128;\n+            if lo > hi || (lo == hi && *end == RangeEnd::Excluded) {\n+                // This should have been caught earlier by E0030.\n+                bug!(\"malformed range pattern: {}..={}\", lo, (hi - offset));\n+            }\n+            Some(IntRange { range: lo..=(hi - offset), ty, span })\n+        } else {\n+            None\n+        }\n+    }\n+\n+    // The return value of `signed_bias` should be XORed with an endpoint to encode/decode it.\n+    fn signed_bias(tcx: TyCtxt<'tcx>, ty: Ty<'tcx>) -> u128 {\n+        match *ty.kind() {\n+            ty::Int(ity) => {\n+                let bits = Integer::from_attr(&tcx, SignedInt(ity)).size().bits() as u128;\n+                1u128 << (bits - 1)\n+            }\n+            _ => 0,\n+        }\n+    }\n+\n+    fn is_subrange(&self, other: &Self) -> bool {\n+        other.range.start() <= self.range.start() && self.range.end() <= other.range.end()\n+    }\n+\n+    fn intersection(&self, tcx: TyCtxt<'tcx>, other: &Self) -> Option<Self> {\n+        let ty = self.ty;\n+        let (lo, hi) = self.boundaries();\n+        let (other_lo, other_hi) = other.boundaries();\n+        if self.treat_exhaustively(tcx) {\n+            if lo <= other_hi && other_lo <= hi {\n+                let span = other.span;\n+                Some(IntRange { range: max(lo, other_lo)..=min(hi, other_hi), ty, span })\n+            } else {\n+                None\n+            }\n+        } else {\n+            // If the range should not be treated exhaustively, fallback to checking for inclusion.\n+            if self.is_subrange(other) { Some(self.clone()) } else { None }\n+        }\n+    }\n+\n+    fn suspicious_intersection(&self, other: &Self) -> bool {\n+        // `false` in the following cases:\n+        // 1     ----      // 1  ----------   // 1 ----        // 1       ----\n+        // 2  ----------   // 2     ----      // 2       ----  // 2 ----\n+        //\n+        // The following are currently `false`, but could be `true` in the future (#64007):\n+        // 1 ---------       // 1     ---------\n+        // 2     ----------  // 2 ----------\n+        //\n+        // `true` in the following cases:\n+        // 1 -------          // 1       -------\n+        // 2       --------   // 2 -------\n+        let (lo, hi) = self.boundaries();\n+        let (other_lo, other_hi) = other.boundaries();\n+        lo == other_hi || hi == other_lo\n+    }\n+\n+    fn to_pat(&self, tcx: TyCtxt<'tcx>) -> Pat<'tcx> {\n+        let (lo, hi) = self.boundaries();\n+\n+        let bias = IntRange::signed_bias(tcx, self.ty);\n+        let (lo, hi) = (lo ^ bias, hi ^ bias);\n+\n+        let ty = ty::ParamEnv::empty().and(self.ty);\n+        let lo_const = ty::Const::from_bits(tcx, lo, ty);\n+        let hi_const = ty::Const::from_bits(tcx, hi, ty);\n+\n+        let kind = if lo == hi {\n+            PatKind::Constant { value: lo_const }\n+        } else {\n+            PatKind::Range(PatRange { lo: lo_const, hi: hi_const, end: RangeEnd::Included })\n+        };\n+\n+        // This is a brand new pattern, so we don't reuse `self.span`.\n+        Pat { ty: self.ty, span: DUMMY_SP, kind: Box::new(kind) }\n+    }\n+\n+    /// For exhaustive integer matching, some constructors are grouped within other constructors\n+    /// (namely integer typed values are grouped within ranges). However, when specialising these\n+    /// constructors, we want to be specialising for the underlying constructors (the integers), not\n+    /// the groups (the ranges). Thus we need to split the groups up. Splitting them up na\u00efvely would\n+    /// mean creating a separate constructor for every single value in the range, which is clearly\n+    /// impractical. However, observe that for some ranges of integers, the specialisation will be\n+    /// identical across all values in that range (i.e., there are equivalence classes of ranges of\n+    /// constructors based on their `U(S(c, P), S(c, p))` outcome). These classes are grouped by\n+    /// the patterns that apply to them (in the matrix `P`). We can split the range whenever the\n+    /// patterns that apply to that range (specifically: the patterns that *intersect* with that range)\n+    /// change.\n+    /// Our solution, therefore, is to split the range constructor into subranges at every single point\n+    /// the group of intersecting patterns changes (using the method described below).\n+    /// And voil\u00e0! We're testing precisely those ranges that we need to, without any exhaustive matching\n+    /// on actual integers. The nice thing about this is that the number of subranges is linear in the\n+    /// number of rows in the matrix (i.e., the number of cases in the `match` statement), so we don't\n+    /// need to be worried about matching over gargantuan ranges.\n+    ///\n+    /// Essentially, given the first column of a matrix representing ranges, looking like the following:\n+    ///\n+    /// |------|  |----------| |-------|    ||\n+    ///    |-------| |-------|            |----| ||\n+    ///       |---------|\n+    ///\n+    /// We split the ranges up into equivalence classes so the ranges are no longer overlapping:\n+    ///\n+    /// |--|--|||-||||--||---|||-------|  |-|||| ||\n+    ///\n+    /// The logic for determining how to split the ranges is fairly straightforward: we calculate\n+    /// boundaries for each interval range, sort them, then create constructors for each new interval\n+    /// between every pair of boundary points. (This essentially sums up to performing the intuitive\n+    /// merging operation depicted above.)\n+    fn split<'p>(\n+        &self,\n+        pcx: PatCtxt<'_, 'p, 'tcx>,\n+        hir_id: Option<HirId>,\n+    ) -> SmallVec<[Constructor<'tcx>; 1]> {\n+        let ty = pcx.ty;\n+\n+        /// Represents a border between 2 integers. Because the intervals spanning borders\n+        /// must be able to cover every integer, we need to be able to represent\n+        /// 2^128 + 1 such borders.\n+        #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Debug)]\n+        enum Border {\n+            JustBefore(u128),\n+            AfterMax,\n+        }\n+\n+        // A function for extracting the borders of an integer interval.\n+        fn range_borders(r: IntRange<'_>) -> impl Iterator<Item = Border> {\n+            let (lo, hi) = r.range.into_inner();\n+            let from = Border::JustBefore(lo);\n+            let to = match hi.checked_add(1) {\n+                Some(m) => Border::JustBefore(m),\n+                None => Border::AfterMax,\n+            };\n+            vec![from, to].into_iter()\n+        }\n+\n+        // Collect the span and range of all the intersecting ranges to lint on likely\n+        // incorrect range patterns. (#63987)\n+        let mut overlaps = vec![];\n+        let row_len = pcx.matrix.column_count().unwrap_or(0);\n+        // `borders` is the set of borders between equivalence classes: each equivalence\n+        // class lies between 2 borders.\n+        let row_borders = pcx\n+            .matrix\n+            .head_ctors(pcx.cx)\n+            .filter_map(|ctor| ctor.as_int_range())\n+            .filter_map(|range| {\n+                let intersection = self.intersection(pcx.cx.tcx, &range);\n+                let should_lint = self.suspicious_intersection(&range);\n+                if let (Some(range), 1, true) = (&intersection, row_len, should_lint) {\n+                    // FIXME: for now, only check for overlapping ranges on simple range\n+                    // patterns. Otherwise with the current logic the following is detected\n+                    // as overlapping:\n+                    //   match (10u8, true) {\n+                    //    (0 ..= 125, false) => {}\n+                    //    (126 ..= 255, false) => {}\n+                    //    (0 ..= 255, true) => {}\n+                    //  }\n+                    overlaps.push(range.clone());\n+                }\n+                intersection\n+            })\n+            .flat_map(range_borders);\n+        let self_borders = range_borders(self.clone());\n+        let mut borders: Vec<_> = row_borders.chain(self_borders).collect();\n+        borders.sort_unstable();\n+\n+        self.lint_overlapping_patterns(pcx.cx.tcx, hir_id, ty, overlaps);\n+\n+        // We're going to iterate through every adjacent pair of borders, making sure that\n+        // each represents an interval of nonnegative length, and convert each such\n+        // interval into a constructor.\n+        borders\n+            .array_windows()\n+            .filter_map(|&pair| match pair {\n+                [Border::JustBefore(n), Border::JustBefore(m)] => {\n+                    if n < m {\n+                        Some(n..=(m - 1))\n+                    } else {\n+                        None\n+                    }\n+                }\n+                [Border::JustBefore(n), Border::AfterMax] => Some(n..=u128::MAX),\n+                [Border::AfterMax, _] => None,\n+            })\n+            .map(|range| IntRange { range, ty, span: pcx.span })\n+            .map(IntRange)\n+            .collect()\n+    }\n+\n+    fn lint_overlapping_patterns(\n+        &self,\n+        tcx: TyCtxt<'tcx>,\n+        hir_id: Option<HirId>,\n+        ty: Ty<'tcx>,\n+        overlaps: Vec<IntRange<'tcx>>,\n+    ) {\n+        if let (true, Some(hir_id)) = (!overlaps.is_empty(), hir_id) {\n+            tcx.struct_span_lint_hir(\n+                lint::builtin::OVERLAPPING_PATTERNS,\n+                hir_id,\n+                self.span,\n+                |lint| {\n+                    let mut err = lint.build(\"multiple patterns covering the same range\");\n+                    err.span_label(self.span, \"overlapping patterns\");\n+                    for int_range in overlaps {\n+                        // Use the real type for user display of the ranges:\n+                        err.span_label(\n+                            int_range.span,\n+                            &format!(\n+                                \"this range overlaps on `{}`\",\n+                                IntRange { range: int_range.range, ty, span: DUMMY_SP }.to_pat(tcx),\n+                            ),\n+                        );\n+                    }\n+                    err.emit();\n+                },\n+            );\n+        }\n+    }\n+\n+    /// See `Constructor::is_covered_by`\n+    fn is_covered_by<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>, other: &Self) -> bool {\n+        if self.intersection(pcx.cx.tcx, other).is_some() {\n+            // Constructor splitting should ensure that all intersections we encounter are actually\n+            // inclusions.\n+            assert!(self.is_subrange(other));\n+            true\n+        } else {\n+            false\n+        }\n+    }\n+}\n+\n+/// Ignore spans when comparing, they don't carry semantic information as they are only for lints.\n+impl<'tcx> std::cmp::PartialEq for IntRange<'tcx> {\n+    fn eq(&self, other: &Self) -> bool {\n+        self.range == other.range && self.ty == other.ty\n+    }\n+}\n+\n+#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n+enum SliceKind {\n+    /// Patterns of length `n` (`[x, y]`).\n+    FixedLen(u64),\n+    /// Patterns using the `..` notation (`[x, .., y]`).\n+    /// Captures any array constructor of `length >= i + j`.\n+    /// In the case where `array_len` is `Some(_)`,\n+    /// this indicates that we only care about the first `i` and the last `j` values of the array,\n+    /// and everything in between is a wildcard `_`.\n+    VarLen(u64, u64),\n+}\n+\n+impl SliceKind {\n+    fn arity(self) -> u64 {\n+        match self {\n+            FixedLen(length) => length,\n+            VarLen(prefix, suffix) => prefix + suffix,\n+        }\n+    }\n+\n+    /// Whether this pattern includes patterns of length `other_len`.\n+    fn covers_length(self, other_len: u64) -> bool {\n+        match self {\n+            FixedLen(len) => len == other_len,\n+            VarLen(prefix, suffix) => prefix + suffix <= other_len,\n+        }\n+    }\n+}\n+\n+/// A constructor for array and slice patterns.\n+#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n+pub(super) struct Slice {\n+    /// `None` if the matched value is a slice, `Some(n)` if it is an array of size `n`.\n+    array_len: Option<u64>,\n+    /// The kind of pattern it is: fixed-length `[x, y]` or variable length `[x, .., y]`.\n+    kind: SliceKind,\n+}\n+\n+impl Slice {\n+    fn new(array_len: Option<u64>, kind: SliceKind) -> Self {\n+        let kind = match (array_len, kind) {\n+            // If the middle `..` is empty, we effectively have a fixed-length pattern.\n+            (Some(len), VarLen(prefix, suffix)) if prefix + suffix >= len => FixedLen(len),\n+            _ => kind,\n+        };\n+        Slice { array_len, kind }\n+    }\n+\n+    fn arity(self) -> u64 {\n+        self.kind.arity()\n+    }\n+\n+    /// The exhaustiveness-checking paper does not include any details on\n+    /// checking variable-length slice patterns. However, they may be\n+    /// matched by an infinite collection of fixed-length array patterns.\n+    ///\n+    /// Checking the infinite set directly would take an infinite amount\n+    /// of time. However, it turns out that for each finite set of\n+    /// patterns `P`, all sufficiently large array lengths are equivalent:\n+    ///\n+    /// Each slice `s` with a \"sufficiently-large\" length `l \u2265 L` that applies\n+    /// to exactly the subset `P\u209c` of `P` can be transformed to a slice\n+    /// `s\u2098` for each sufficiently-large length `m` that applies to exactly\n+    /// the same subset of `P`.\n+    ///\n+    /// Because of that, each witness for reachability-checking of one\n+    /// of the sufficiently-large lengths can be transformed to an\n+    /// equally-valid witness of any other length, so we only have\n+    /// to check slices of the \"minimal sufficiently-large length\"\n+    /// and less.\n+    ///\n+    /// Note that the fact that there is a *single* `s\u2098` for each `m`\n+    /// not depending on the specific pattern in `P` is important: if\n+    /// you look at the pair of patterns\n+    ///     `[true, ..]`\n+    ///     `[.., false]`\n+    /// Then any slice of length \u22651 that matches one of these two\n+    /// patterns can be trivially turned to a slice of any\n+    /// other length \u22651 that matches them and vice-versa,\n+    /// but the slice of length 2 `[false, true]` that matches neither\n+    /// of these patterns can't be turned to a slice from length 1 that\n+    /// matches neither of these patterns, so we have to consider\n+    /// slices from length 2 there.\n+    ///\n+    /// Now, to see that that length exists and find it, observe that slice\n+    /// patterns are either \"fixed-length\" patterns (`[_, _, _]`) or\n+    /// \"variable-length\" patterns (`[_, .., _]`).\n+    ///\n+    /// For fixed-length patterns, all slices with lengths *longer* than\n+    /// the pattern's length have the same outcome (of not matching), so\n+    /// as long as `L` is greater than the pattern's length we can pick\n+    /// any `s\u2098` from that length and get the same result.\n+    ///\n+    /// For variable-length patterns, the situation is more complicated,\n+    /// because as seen above the precise value of `s\u2098` matters.\n+    ///\n+    /// However, for each variable-length pattern `p` with a prefix of length\n+    /// `pl\u209a` and suffix of length `sl\u209a`, only the first `pl\u209a` and the last\n+    /// `sl\u209a` elements are examined.\n+    ///\n+    /// Therefore, as long as `L` is positive (to avoid concerns about empty\n+    /// types), all elements after the maximum prefix length and before\n+    /// the maximum suffix length are not examined by any variable-length\n+    /// pattern, and therefore can be added/removed without affecting\n+    /// them - creating equivalent patterns from any sufficiently-large\n+    /// length.\n+    ///\n+    /// Of course, if fixed-length patterns exist, we must be sure\n+    /// that our length is large enough to miss them all, so\n+    /// we can pick `L = max(max(FIXED_LEN)+1, max(PREFIX_LEN) + max(SUFFIX_LEN))`\n+    ///\n+    /// for example, with the above pair of patterns, all elements\n+    /// but the first and last can be added/removed, so any\n+    /// witness of length \u22652 (say, `[false, false, true]`) can be\n+    /// turned to a witness from any other length \u22652.\n+    fn split<'p, 'tcx>(self, pcx: PatCtxt<'_, 'p, 'tcx>) -> SmallVec<[Constructor<'tcx>; 1]> {\n+        let (self_prefix, self_suffix) = match self.kind {\n+            VarLen(self_prefix, self_suffix) => (self_prefix, self_suffix),\n+            _ => return smallvec![Slice(self)],\n+        };\n+\n+        let head_ctors = pcx.matrix.head_ctors(pcx.cx).filter(|c| !c.is_wildcard());\n+\n+        let mut max_prefix_len = self_prefix;\n+        let mut max_suffix_len = self_suffix;\n+        let mut max_fixed_len = 0;\n+\n+        for ctor in head_ctors {\n+            if let Slice(slice) = ctor {\n+                match slice.kind {\n+                    FixedLen(len) => {\n+                        max_fixed_len = cmp::max(max_fixed_len, len);\n+                    }\n+                    VarLen(prefix, suffix) => {\n+                        max_prefix_len = cmp::max(max_prefix_len, prefix);\n+                        max_suffix_len = cmp::max(max_suffix_len, suffix);\n+                    }\n+                }\n+            } else {\n+                bug!(\"unexpected ctor for slice type: {:?}\", ctor);\n+            }\n+        }\n+\n+        // For diagnostics, we keep the prefix and suffix lengths separate, so in the case\n+        // where `max_fixed_len + 1` is the largest, we adapt `max_prefix_len` accordingly,\n+        // so that `L = max_prefix_len + max_suffix_len`.\n+        if max_fixed_len + 1 >= max_prefix_len + max_suffix_len {\n+            // The subtraction can't overflow thanks to the above check.\n+            // The new `max_prefix_len` is also guaranteed to be larger than its previous\n+            // value.\n+            max_prefix_len = max_fixed_len + 1 - max_suffix_len;\n+        }\n+\n+        let final_slice = VarLen(max_prefix_len, max_suffix_len);\n+        let final_slice = Slice::new(self.array_len, final_slice);\n+        match self.array_len {\n+            Some(_) => smallvec![Slice(final_slice)],\n+            None => {\n+                // `self` originally covered the range `(self.arity()..infinity)`. We split that\n+                // range into two: lengths smaller than `final_slice.arity()` are treated\n+                // independently as fixed-lengths slices, and lengths above are captured by\n+                // `final_slice`.\n+                let smaller_lengths = (self.arity()..final_slice.arity()).map(FixedLen);\n+                smaller_lengths\n+                    .map(|kind| Slice::new(self.array_len, kind))\n+                    .chain(Some(final_slice))\n+                    .map(Slice)\n+                    .collect()\n+            }\n+        }\n+    }\n+\n+    /// See `Constructor::is_covered_by`\n+    fn is_covered_by(self, other: Self) -> bool {\n+        other.kind.covers_length(self.arity())\n+    }\n+}\n+\n+/// A value can be decomposed into a constructor applied to some fields. This struct represents\n+/// the constructor. See also `Fields`.\n+///\n+/// `pat_constructor` retrieves the constructor corresponding to a pattern.\n+/// `specialize_constructor` returns the list of fields corresponding to a pattern, given a\n+/// constructor. `Constructor::apply` reconstructs the pattern from a pair of `Constructor` and\n+/// `Fields`.\n+#[derive(Clone, Debug, PartialEq)]\n+pub(super) enum Constructor<'tcx> {\n+    /// The constructor for patterns that have a single constructor, like tuples, struct patterns\n+    /// and fixed-length arrays.\n+    Single,\n+    /// Enum variants.\n+    Variant(DefId),\n+    /// Ranges of integer literal values (`2`, `2..=5` or `2..5`).\n+    IntRange(IntRange<'tcx>),\n+    /// Ranges of floating-point literal values (`2.0..=5.2`).\n+    FloatRange(&'tcx ty::Const<'tcx>, &'tcx ty::Const<'tcx>, RangeEnd),\n+    /// String literals. Strings are not quite the same as `&[u8]` so we treat them separately.\n+    Str(&'tcx ty::Const<'tcx>),\n+    /// Array and slice patterns.\n+    Slice(Slice),\n+    /// Constants that must not be matched structurally. They are treated as black\n+    /// boxes for the purposes of exhaustiveness: we must not inspect them, and they\n+    /// don't count towards making a match exhaustive.\n+    Opaque,\n+    /// Fake extra constructor for enums that aren't allowed to be matched exhaustively. Also used\n+    /// for those types for which we cannot list constructors explicitly, like `f64` and `str`.\n+    NonExhaustive,\n+    /// Wildcard pattern.\n+    Wildcard,\n+}\n+\n+impl<'tcx> Constructor<'tcx> {\n+    pub(super) fn is_wildcard(&self) -> bool {\n+        matches!(self, Wildcard)\n+    }\n+\n+    fn as_int_range(&self) -> Option<&IntRange<'tcx>> {\n+        match self {\n+            IntRange(range) => Some(range),\n+            _ => None,\n+        }\n+    }\n+\n+    fn as_slice(&self) -> Option<Slice> {\n+        match self {\n+            Slice(slice) => Some(*slice),\n+            _ => None,\n+        }\n+    }\n+\n+    fn variant_index_for_adt(&self, adt: &'tcx ty::AdtDef) -> VariantIdx {\n+        match *self {\n+            Variant(id) => adt.variant_index_with_id(id),\n+            Single => {\n+                assert!(!adt.is_enum());\n+                VariantIdx::new(0)\n+            }\n+            _ => bug!(\"bad constructor {:?} for adt {:?}\", self, adt),\n+        }\n+    }\n+\n+    /// Some constructors (namely `Wildcard`, `IntRange` and `Slice`) actually stand for a set of actual\n+    /// constructors (like variants, integers or fixed-sized slices). When specializing for these\n+    /// constructors, we want to be specialising for the actual underlying constructors.\n+    /// Naively, we would simply return the list of constructors they correspond to. We instead are\n+    /// more clever: if there are constructors that we know will behave the same wrt the current\n+    /// matrix, we keep them grouped. For example, all slices of a sufficiently large length\n+    /// will either be all useful or all non-useful with a given matrix.\n+    ///\n+    /// See the branches for details on how the splitting is done.\n+    ///\n+    /// This function may discard some irrelevant constructors if this preserves behavior and\n+    /// diagnostics. Eg. for the `_` case, we ignore the constructors already present in the\n+    /// matrix, unless all of them are.\n+    ///\n+    /// `hir_id` is `None` when we're evaluating the wildcard pattern. In that case we do not want\n+    /// to lint for overlapping ranges.\n+    pub(super) fn split<'p>(\n+        &self,\n+        pcx: PatCtxt<'_, 'p, 'tcx>,\n+        hir_id: Option<HirId>,\n+    ) -> SmallVec<[Self; 1]> {\n+        debug!(\"Constructor::split({:#?}, {:#?})\", self, pcx.matrix);\n+\n+        match self {\n+            Wildcard => Constructor::split_wildcard(pcx),\n+            // Fast-track if the range is trivial. In particular, we don't do the overlapping\n+            // ranges check.\n+            IntRange(ctor_range)\n+                if ctor_range.treat_exhaustively(pcx.cx.tcx) && !ctor_range.is_singleton() =>\n+            {\n+                ctor_range.split(pcx, hir_id)\n+            }\n+            Slice(slice @ Slice { kind: VarLen(..), .. }) => slice.split(pcx),\n+            // Any other constructor can be used unchanged.\n+            _ => smallvec![self.clone()],\n+        }\n+    }\n+\n+    /// For wildcards, there are two groups of constructors: there are the constructors actually\n+    /// present in the matrix (`head_ctors`), and the constructors not present (`missing_ctors`).\n+    /// Two constructors that are not in the matrix will either both be caught (by a wildcard), or\n+    /// both not be caught. Therefore we can keep the missing constructors grouped together.\n+    fn split_wildcard<'p>(pcx: PatCtxt<'_, 'p, 'tcx>) -> SmallVec<[Self; 1]> {\n+        // Missing constructors are those that are not matched by any non-wildcard patterns in the\n+        // current column. We only fully construct them on-demand, because they're rarely used and\n+        // can be big.\n+        let missing_ctors = MissingConstructors::new(pcx);\n+        if missing_ctors.is_empty(pcx) {\n+            // All the constructors are present in the matrix, so we just go through them all.\n+            // We must also split them first.\n+            missing_ctors.all_ctors\n+        } else {\n+            // Some constructors are missing, thus we can specialize with the wildcard constructor,\n+            // which will stand for those constructors that are missing, and behaves like any of\n+            // them.\n+            smallvec![Wildcard]\n+        }\n+    }\n+\n+    /// Returns whether `self` is covered by `other`, i.e. whether `self` is a subset of `other`.\n+    /// For the simple cases, this is simply checking for equality. For the \"grouped\" constructors,\n+    /// this checks for inclusion.\n+    pub(super) fn is_covered_by<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>, other: &Self) -> bool {\n+        // This must be kept in sync with `is_covered_by_any`.\n+        match (self, other) {\n+            // Wildcards cover anything\n+            (_, Wildcard) => true,\n+            // Wildcards are only covered by wildcards\n+            (Wildcard, _) => false,\n+\n+            (Single, Single) => true,\n+            (Variant(self_id), Variant(other_id)) => self_id == other_id,\n+\n+            (IntRange(self_range), IntRange(other_range)) => {\n+                self_range.is_covered_by(pcx, other_range)\n+            }\n+            (\n+                FloatRange(self_from, self_to, self_end),\n+                FloatRange(other_from, other_to, other_end),\n+            ) => {\n+                match (\n+                    compare_const_vals(pcx.cx.tcx, self_to, other_to, pcx.cx.param_env, pcx.ty),\n+                    compare_const_vals(pcx.cx.tcx, self_from, other_from, pcx.cx.param_env, pcx.ty),\n+                ) {\n+                    (Some(to), Some(from)) => {\n+                        (from == Ordering::Greater || from == Ordering::Equal)\n+                            && (to == Ordering::Less\n+                                || (other_end == self_end && to == Ordering::Equal))\n+                    }\n+                    _ => false,\n+                }\n+            }\n+            (Str(self_val), Str(other_val)) => {\n+                // FIXME: there's probably a more direct way of comparing for equality\n+                match compare_const_vals(pcx.cx.tcx, self_val, other_val, pcx.cx.param_env, pcx.ty)\n+                {\n+                    Some(comparison) => comparison == Ordering::Equal,\n+                    None => false,\n+                }\n+            }\n+            (Slice(self_slice), Slice(other_slice)) => self_slice.is_covered_by(*other_slice),\n+\n+            // We are trying to inspect an opaque constant. Thus we skip the row.\n+            (Opaque, _) | (_, Opaque) => false,\n+            // Only a wildcard pattern can match the special extra constructor.\n+            (NonExhaustive, _) => false,\n+\n+            _ => span_bug!(\n+                pcx.span,\n+                \"trying to compare incompatible constructors {:?} and {:?}\",\n+                self,\n+                other\n+            ),\n+        }\n+    }\n+\n+    /// Faster version of `is_covered_by` when applied to many constructors. `used_ctors` is\n+    /// assumed to be built from `matrix.head_ctors()` with wildcards filtered out, and `self` is\n+    /// assumed to have been split from a wildcard.\n+    fn is_covered_by_any<'p>(\n+        &self,\n+        pcx: PatCtxt<'_, 'p, 'tcx>,\n+        used_ctors: &[Constructor<'tcx>],\n+    ) -> bool {\n+        if used_ctors.is_empty() {\n+            return false;\n+        }\n+\n+        // This must be kept in sync with `is_covered_by`.\n+        match self {\n+            // If `self` is `Single`, `used_ctors` cannot contain anything else than `Single`s.\n+            Single => !used_ctors.is_empty(),\n+            Variant(_) => used_ctors.iter().any(|c| c == self),\n+            IntRange(range) => used_ctors\n+                .iter()\n+                .filter_map(|c| c.as_int_range())\n+                .any(|other| range.is_covered_by(pcx, other)),\n+            Slice(slice) => used_ctors\n+                .iter()\n+                .filter_map(|c| c.as_slice())\n+                .any(|other| slice.is_covered_by(other)),\n+            // This constructor is never covered by anything else\n+            NonExhaustive => false,\n+            Str(..) | FloatRange(..) | Opaque | Wildcard => {\n+                bug!(\"found unexpected ctor in all_ctors: {:?}\", self)\n+            }\n+        }\n+    }\n+}\n+\n+/// Determines the constructor that the given pattern can be specialized to.\n+/// Returns `None` in case of a catch-all, which can't be specialized.\n+pub(super) fn pat_constructor<'p, 'tcx>(\n+    cx: &MatchCheckCtxt<'p, 'tcx>,\n+    pat: &'p Pat<'tcx>,\n+) -> Constructor<'tcx> {\n+    match pat.kind.as_ref() {\n+        PatKind::AscribeUserType { .. } => bug!(), // Handled by `expand_pattern`\n+        PatKind::Binding { .. } | PatKind::Wild => Wildcard,\n+        PatKind::Leaf { .. } | PatKind::Deref { .. } => Single,\n+        &PatKind::Variant { adt_def, variant_index, .. } => {\n+            Variant(adt_def.variants[variant_index].def_id)\n+        }\n+        PatKind::Constant { value } => {\n+            if let Some(int_range) = IntRange::from_const(cx.tcx, cx.param_env, value, pat.span) {\n+                IntRange(int_range)\n+            } else {\n+                match pat.ty.kind() {\n+                    ty::Float(_) => FloatRange(value, value, RangeEnd::Included),\n+                    // In `expand_pattern`, we convert string literals to `&CONST` patterns with\n+                    // `CONST` a pattern of type `str`. In truth this contains a constant of type\n+                    // `&str`.\n+                    ty::Str => Str(value),\n+                    // All constants that can be structurally matched have already been expanded\n+                    // into the corresponding `Pat`s by `const_to_pat`. Constants that remain are\n+                    // opaque.\n+                    _ => Opaque,\n+                }\n+            }\n+        }\n+        &PatKind::Range(PatRange { lo, hi, end }) => {\n+            let ty = lo.ty;\n+            if let Some(int_range) = IntRange::from_range(\n+                cx.tcx,\n+                lo.eval_bits(cx.tcx, cx.param_env, lo.ty),\n+                hi.eval_bits(cx.tcx, cx.param_env, hi.ty),\n+                ty,\n+                &end,\n+                pat.span,\n+            ) {\n+                IntRange(int_range)\n+            } else {\n+                FloatRange(lo, hi, end)\n+            }\n+        }\n+        PatKind::Array { prefix, slice, suffix } | PatKind::Slice { prefix, slice, suffix } => {\n+            let array_len = match pat.ty.kind() {\n+                ty::Array(_, length) => Some(length.eval_usize(cx.tcx, cx.param_env)),\n+                ty::Slice(_) => None,\n+                _ => span_bug!(pat.span, \"bad ty {:?} for slice pattern\", pat.ty),\n+            };\n+            let prefix = prefix.len() as u64;\n+            let suffix = suffix.len() as u64;\n+            let kind =\n+                if slice.is_some() { VarLen(prefix, suffix) } else { FixedLen(prefix + suffix) };\n+            Slice(Slice::new(array_len, kind))\n+        }\n+        PatKind::Or { .. } => bug!(\"Or-pattern should have been expanded earlier on.\"),\n+    }\n+}\n+\n+/// This determines the set of all possible constructors of a pattern matching\n+/// values of type `left_ty`. For vectors, this would normally be an infinite set\n+/// but is instead bounded by the maximum fixed length of slice patterns in\n+/// the column of patterns being analyzed.\n+///\n+/// We make sure to omit constructors that are statically impossible. E.g., for\n+/// `Option<!>`, we do not include `Some(_)` in the returned list of constructors.\n+/// Invariant: this returns an empty `Vec` if and only if the type is uninhabited (as determined by\n+/// `cx.is_uninhabited()`).\n+fn all_constructors<'p, 'tcx>(pcx: PatCtxt<'_, 'p, 'tcx>) -> Vec<Constructor<'tcx>> {\n+    debug!(\"all_constructors({:?})\", pcx.ty);\n+    let cx = pcx.cx;\n+    let make_range = |start, end| {\n+        IntRange(\n+            // `unwrap()` is ok because we know the type is an integer.\n+            IntRange::from_range(cx.tcx, start, end, pcx.ty, &RangeEnd::Included, pcx.span)\n+                .unwrap(),\n+        )\n+    };\n+    match pcx.ty.kind() {\n+        ty::Bool => vec![make_range(0, 1)],\n+        ty::Array(sub_ty, len) if len.try_eval_usize(cx.tcx, cx.param_env).is_some() => {\n+            let len = len.eval_usize(cx.tcx, cx.param_env);\n+            if len != 0 && cx.is_uninhabited(sub_ty) {\n+                vec![]\n+            } else {\n+                vec![Slice(Slice::new(Some(len), VarLen(0, 0)))]\n+            }\n+        }\n+        // Treat arrays of a constant but unknown length like slices.\n+        ty::Array(sub_ty, _) | ty::Slice(sub_ty) => {\n+            let kind = if cx.is_uninhabited(sub_ty) { FixedLen(0) } else { VarLen(0, 0) };\n+            vec![Slice(Slice::new(None, kind))]\n+        }\n+        ty::Adt(def, substs) if def.is_enum() => {\n+            // If the enum is declared as `#[non_exhaustive]`, we treat it as if it had an\n+            // additional \"unknown\" constructor.\n+            // There is no point in enumerating all possible variants, because the user can't\n+            // actually match against them all themselves. So we always return only the fictitious\n+            // constructor.\n+            // E.g., in an example like:\n+            //\n+            // ```\n+            //     let err: io::ErrorKind = ...;\n+            //     match err {\n+            //         io::ErrorKind::NotFound => {},\n+            //     }\n+            // ```\n+            //\n+            // we don't want to show every possible IO error, but instead have only `_` as the\n+            // witness.\n+            let is_declared_nonexhaustive = cx.is_foreign_non_exhaustive_enum(pcx.ty);\n+\n+            // If `exhaustive_patterns` is disabled and our scrutinee is an empty enum, we treat it\n+            // as though it had an \"unknown\" constructor to avoid exposing its emptiness. The\n+            // exception is if the pattern is at the top level, because we want empty matches to be\n+            // considered exhaustive.\n+            let is_secretly_empty = def.variants.is_empty()\n+                && !cx.tcx.features().exhaustive_patterns\n+                && !pcx.is_top_level;\n+\n+            if is_secretly_empty || is_declared_nonexhaustive {\n+                vec![NonExhaustive]\n+            } else if cx.tcx.features().exhaustive_patterns {\n+                // If `exhaustive_patterns` is enabled, we exclude variants known to be\n+                // uninhabited.\n+                def.variants\n+                    .iter()\n+                    .filter(|v| {\n+                        !v.uninhabited_from(cx.tcx, substs, def.adt_kind(), cx.param_env)\n+                            .contains(cx.tcx, cx.module)\n+                    })\n+                    .map(|v| Variant(v.def_id))\n+                    .collect()\n+            } else {\n+                def.variants.iter().map(|v| Variant(v.def_id)).collect()\n+            }\n+        }\n+        ty::Char => {\n+            vec![\n+                // The valid Unicode Scalar Value ranges.\n+                make_range('\\u{0000}' as u128, '\\u{D7FF}' as u128),\n+                make_range('\\u{E000}' as u128, '\\u{10FFFF}' as u128),\n+            ]\n+        }\n+        ty::Int(_) | ty::Uint(_)\n+            if pcx.ty.is_ptr_sized_integral()\n+                && !cx.tcx.features().precise_pointer_size_matching =>\n+        {\n+            // `usize`/`isize` are not allowed to be matched exhaustively unless the\n+            // `precise_pointer_size_matching` feature is enabled. So we treat those types like\n+            // `#[non_exhaustive]` enums by returning a special unmatcheable constructor.\n+            vec![NonExhaustive]\n+        }\n+        &ty::Int(ity) => {\n+            let bits = Integer::from_attr(&cx.tcx, SignedInt(ity)).size().bits() as u128;\n+            let min = 1u128 << (bits - 1);\n+            let max = min - 1;\n+            vec![make_range(min, max)]\n+        }\n+        &ty::Uint(uty) => {\n+            let size = Integer::from_attr(&cx.tcx, UnsignedInt(uty)).size();\n+            let max = size.truncate(u128::MAX);\n+            vec![make_range(0, max)]\n+        }\n+        // If `exhaustive_patterns` is disabled and our scrutinee is the never type, we cannot\n+        // expose its emptiness. The exception is if the pattern is at the top level, because we\n+        // want empty matches to be considered exhaustive.\n+        ty::Never if !cx.tcx.features().exhaustive_patterns && !pcx.is_top_level => {\n+            vec![NonExhaustive]\n+        }\n+        ty::Never => vec![],\n+        _ if cx.is_uninhabited(pcx.ty) => vec![],\n+        ty::Adt(..) | ty::Tuple(..) | ty::Ref(..) => vec![Single],\n+        // This type is one for which we cannot list constructors, like `str` or `f64`.\n+        _ => vec![NonExhaustive],\n+    }\n+}\n+\n+// A struct to compute a set of constructors equivalent to `all_ctors \\ used_ctors`.\n+#[derive(Debug)]\n+pub(super) struct MissingConstructors<'tcx> {\n+    all_ctors: SmallVec<[Constructor<'tcx>; 1]>,\n+    used_ctors: Vec<Constructor<'tcx>>,\n+}\n+\n+impl<'tcx> MissingConstructors<'tcx> {\n+    pub(super) fn new<'p>(pcx: PatCtxt<'_, 'p, 'tcx>) -> Self {\n+        let used_ctors: Vec<Constructor<'_>> =\n+            pcx.matrix.head_ctors(pcx.cx).cloned().filter(|c| !c.is_wildcard()).collect();\n+        // Since `all_ctors` never contains wildcards, this won't recurse further.\n+        let all_ctors =\n+            all_constructors(pcx).into_iter().flat_map(|ctor| ctor.split(pcx, None)).collect();\n+\n+        MissingConstructors { all_ctors, used_ctors }\n+    }\n+\n+    fn is_empty<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>) -> bool {\n+        self.iter(pcx).next().is_none()\n+    }\n+\n+    /// Iterate over all_ctors \\ used_ctors\n+    fn iter<'a, 'p>(\n+        &'a self,\n+        pcx: PatCtxt<'a, 'p, 'tcx>,\n+    ) -> impl Iterator<Item = &'a Constructor<'tcx>> + Captures<'p> {\n+        self.all_ctors.iter().filter(move |ctor| !ctor.is_covered_by_any(pcx, &self.used_ctors))\n+    }\n+\n+    /// List the patterns corresponding to the missing constructors. In some cases, instead of\n+    /// listing all constructors of a given type, we prefer to simply report a wildcard.\n+    pub(super) fn report_patterns<'p>(\n+        &self,\n+        pcx: PatCtxt<'_, 'p, 'tcx>,\n+    ) -> SmallVec<[Pat<'tcx>; 1]> {\n+        // There are 2 ways we can report a witness here.\n+        // Commonly, we can report all the \"free\"\n+        // constructors as witnesses, e.g., if we have:\n+        //\n+        // ```\n+        //     enum Direction { N, S, E, W }\n+        //     let Direction::N = ...;\n+        // ```\n+        //\n+        // we can report 3 witnesses: `S`, `E`, and `W`.\n+        //\n+        // However, there is a case where we don't want\n+        // to do this and instead report a single `_` witness:\n+        // if the user didn't actually specify a constructor\n+        // in this arm, e.g., in\n+        //\n+        // ```\n+        //     let x: (Direction, Direction, bool) = ...;\n+        //     let (_, _, false) = x;\n+        // ```\n+        //\n+        // we don't want to show all 16 possible witnesses\n+        // `(<direction-1>, <direction-2>, true)` - we are\n+        // satisfied with `(_, _, true)`. In this case,\n+        // `used_ctors` is empty.\n+        // The exception is: if we are at the top-level, for example in an empty match, we\n+        // sometimes prefer reporting the list of constructors instead of just `_`.\n+        let report_when_all_missing = pcx.is_top_level && !IntRange::is_integral(pcx.ty);\n+        if self.used_ctors.is_empty() && !report_when_all_missing {\n+            // All constructors are unused. Report only a wildcard\n+            // rather than each individual constructor.\n+            smallvec![Pat::wildcard_from_ty(pcx.ty)]\n+        } else {\n+            // Construct for each missing constructor a \"wild\" version of this\n+            // constructor, that matches everything that can be built with\n+            // it. For example, if `ctor` is a `Constructor::Variant` for\n+            // `Option::Some`, we get the pattern `Some(_)`.\n+            self.iter(pcx)\n+                .map(|missing_ctor| Fields::wildcards(pcx, &missing_ctor).apply(pcx, missing_ctor))\n+                .collect()\n+        }\n+    }\n+}\n+\n+/// Some fields need to be explicitly hidden away in certain cases; see the comment above the\n+/// `Fields` struct. This struct represents such a potentially-hidden field. When a field is hidden\n+/// we still keep its type around.\n+#[derive(Debug, Copy, Clone)]\n+pub(super) enum FilteredField<'p, 'tcx> {\n+    Kept(&'p Pat<'tcx>),\n+    Hidden(Ty<'tcx>),\n+}\n+\n+impl<'p, 'tcx> FilteredField<'p, 'tcx> {\n+    fn kept(self) -> Option<&'p Pat<'tcx>> {\n+        match self {\n+            FilteredField::Kept(p) => Some(p),\n+            FilteredField::Hidden(_) => None,\n+        }\n+    }\n+\n+    fn to_pattern(self) -> Pat<'tcx> {\n+        match self {\n+            FilteredField::Kept(p) => p.clone(),\n+            FilteredField::Hidden(ty) => Pat::wildcard_from_ty(ty),\n+        }\n+    }\n+}\n+\n+/// A value can be decomposed into a constructor applied to some fields. This struct represents\n+/// those fields, generalized to allow patterns in each field. See also `Constructor`.\n+///\n+/// If a private or `non_exhaustive` field is uninhabited, the code mustn't observe that it is\n+/// uninhabited. For that, we filter these fields out of the matrix. This is subtle because we\n+/// still need to have those fields back when going to/from a `Pat`. Most of this is handled\n+/// automatically in `Fields`, but when constructing or deconstructing `Fields` you need to be\n+/// careful. As a rule, when going to/from the matrix, use the filtered field list; when going\n+/// to/from `Pat`, use the full field list.\n+/// This filtering is uncommon in practice, because uninhabited fields are rarely used, so we avoid\n+/// it when possible to preserve performance.\n+#[derive(Debug, Clone)]\n+pub(super) enum Fields<'p, 'tcx> {\n+    /// Lists of patterns that don't contain any filtered fields.\n+    /// `Slice` and `Vec` behave the same; the difference is only to avoid allocating and\n+    /// triple-dereferences when possible. Frankly this is premature optimization, I (Nadrieril)\n+    /// have not measured if it really made a difference.\n+    Slice(&'p [Pat<'tcx>]),\n+    Vec(SmallVec<[&'p Pat<'tcx>; 2]>),\n+    /// Patterns where some of the fields need to be hidden. `kept_count` caches the number of\n+    /// non-hidden fields.\n+    Filtered {\n+        fields: SmallVec<[FilteredField<'p, 'tcx>; 2]>,\n+        kept_count: usize,\n+    },\n+}\n+\n+impl<'p, 'tcx> Fields<'p, 'tcx> {\n+    fn empty() -> Self {\n+        Fields::Slice(&[])\n+    }\n+\n+    /// Construct a new `Fields` from the given pattern. Must not be used if the pattern is a field\n+    /// of a struct/tuple/variant.\n+    fn from_single_pattern(pat: &'p Pat<'tcx>) -> Self {\n+        Fields::Slice(std::slice::from_ref(pat))\n+    }\n+\n+    /// Convenience; internal use.\n+    fn wildcards_from_tys(\n+        cx: &MatchCheckCtxt<'p, 'tcx>,\n+        tys: impl IntoIterator<Item = Ty<'tcx>>,\n+    ) -> Self {\n+        let wilds = tys.into_iter().map(Pat::wildcard_from_ty);\n+        let pats = cx.pattern_arena.alloc_from_iter(wilds);\n+        Fields::Slice(pats)\n+    }\n+\n+    /// Creates a new list of wildcard fields for a given constructor.\n+    pub(super) fn wildcards(pcx: PatCtxt<'_, 'p, 'tcx>, constructor: &Constructor<'tcx>) -> Self {\n+        let ty = pcx.ty;\n+        let cx = pcx.cx;\n+        let wildcard_from_ty = |ty| &*cx.pattern_arena.alloc(Pat::wildcard_from_ty(ty));\n+\n+        let ret = match constructor {\n+            Single | Variant(_) => match ty.kind() {\n+                ty::Tuple(ref fs) => {\n+                    Fields::wildcards_from_tys(cx, fs.into_iter().map(|ty| ty.expect_ty()))\n+                }\n+                ty::Ref(_, rty, _) => Fields::from_single_pattern(wildcard_from_ty(rty)),\n+                ty::Adt(adt, substs) => {\n+                    if adt.is_box() {\n+                        // Use T as the sub pattern type of Box<T>.\n+                        Fields::from_single_pattern(wildcard_from_ty(substs.type_at(0)))\n+                    } else {\n+                        let variant = &adt.variants[constructor.variant_index_for_adt(adt)];\n+                        // Whether we must not match the fields of this variant exhaustively.\n+                        let is_non_exhaustive =\n+                            variant.is_field_list_non_exhaustive() && !adt.did.is_local();\n+                        let field_tys = variant.fields.iter().map(|field| field.ty(cx.tcx, substs));\n+                        // In the following cases, we don't need to filter out any fields. This is\n+                        // the vast majority of real cases, since uninhabited fields are uncommon.\n+                        let has_no_hidden_fields = (adt.is_enum() && !is_non_exhaustive)\n+                            || !field_tys.clone().any(|ty| cx.is_uninhabited(ty));\n+\n+                        if has_no_hidden_fields {\n+                            Fields::wildcards_from_tys(cx, field_tys)\n+                        } else {\n+                            let mut kept_count = 0;\n+                            let fields = variant\n+                                .fields\n+                                .iter()\n+                                .map(|field| {\n+                                    let ty = field.ty(cx.tcx, substs);\n+                                    let is_visible = adt.is_enum()\n+                                        || field.vis.is_accessible_from(cx.module, cx.tcx);\n+                                    let is_uninhabited = cx.is_uninhabited(ty);\n+\n+                                    // In the cases of either a `#[non_exhaustive]` field list\n+                                    // or a non-public field, we hide uninhabited fields in\n+                                    // order not to reveal the uninhabitedness of the whole\n+                                    // variant.\n+                                    if is_uninhabited && (!is_visible || is_non_exhaustive) {\n+                                        FilteredField::Hidden(ty)\n+                                    } else {\n+                                        kept_count += 1;\n+                                        FilteredField::Kept(wildcard_from_ty(ty))\n+                                    }\n+                                })\n+                                .collect();\n+                            Fields::Filtered { fields, kept_count }\n+                        }\n+                    }\n+                }\n+                _ => bug!(\"Unexpected type for `Single` constructor: {:?}\", ty),\n+            },\n+            Slice(slice) => match *ty.kind() {\n+                ty::Slice(ty) | ty::Array(ty, _) => {\n+                    let arity = slice.arity();\n+                    Fields::wildcards_from_tys(cx, (0..arity).map(|_| ty))\n+                }\n+                _ => bug!(\"bad slice pattern {:?} {:?}\", constructor, ty),\n+            },\n+            Str(..) | FloatRange(..) | IntRange(..) | NonExhaustive | Opaque | Wildcard => {\n+                Fields::empty()\n+            }\n+        };\n+        debug!(\"Fields::wildcards({:?}, {:?}) = {:#?}\", constructor, ty, ret);\n+        ret\n+    }\n+\n+    /// Apply a constructor to a list of patterns, yielding a new pattern. `self`\n+    /// must have as many elements as this constructor's arity.\n+    ///\n+    /// This is roughly the inverse of `specialize_constructor`.\n+    ///\n+    /// Examples:\n+    /// `ctor`: `Constructor::Single`\n+    /// `ty`: `Foo(u32, u32, u32)`\n+    /// `self`: `[10, 20, _]`\n+    /// returns `Foo(10, 20, _)`\n+    ///\n+    /// `ctor`: `Constructor::Variant(Option::Some)`\n+    /// `ty`: `Option<bool>`\n+    /// `self`: `[false]`\n+    /// returns `Some(false)`\n+    pub(super) fn apply(self, pcx: PatCtxt<'_, 'p, 'tcx>, ctor: &Constructor<'tcx>) -> Pat<'tcx> {\n+        let mut subpatterns = self.all_patterns();\n+\n+        let pat = match ctor {\n+            Single | Variant(_) => match pcx.ty.kind() {\n+                ty::Adt(..) | ty::Tuple(..) => {\n+                    let subpatterns = subpatterns\n+                        .enumerate()\n+                        .map(|(i, p)| FieldPat { field: Field::new(i), pattern: p })\n+                        .collect();\n+\n+                    if let ty::Adt(adt, substs) = pcx.ty.kind() {\n+                        if adt.is_enum() {\n+                            PatKind::Variant {\n+                                adt_def: adt,\n+                                substs,\n+                                variant_index: ctor.variant_index_for_adt(adt),\n+                                subpatterns,\n+                            }\n+                        } else {\n+                            PatKind::Leaf { subpatterns }\n+                        }\n+                    } else {\n+                        PatKind::Leaf { subpatterns }\n+                    }\n+                }\n+                // Note: given the expansion of `&str` patterns done in `expand_pattern`, we should\n+                // be careful to reconstruct the correct constant pattern here. However a string\n+                // literal pattern will never be reported as a non-exhaustiveness witness, so we\n+                // can ignore this issue.\n+                ty::Ref(..) => PatKind::Deref { subpattern: subpatterns.next().unwrap() },\n+                ty::Slice(_) | ty::Array(..) => bug!(\"bad slice pattern {:?} {:?}\", ctor, pcx.ty),\n+                _ => PatKind::Wild,\n+            },\n+            Slice(slice) => match slice.kind {\n+                FixedLen(_) => {\n+                    PatKind::Slice { prefix: subpatterns.collect(), slice: None, suffix: vec![] }\n+                }\n+                VarLen(prefix, _) => {\n+                    let mut prefix: Vec<_> = subpatterns.by_ref().take(prefix as usize).collect();\n+                    if slice.array_len.is_some() {\n+                        // Improves diagnostics a bit: if the type is a known-size array, instead\n+                        // of reporting `[x, _, .., _, y]`, we prefer to report `[x, .., y]`.\n+                        // This is incorrect if the size is not known, since `[_, ..]` captures\n+                        // arrays of lengths `>= 1` whereas `[..]` captures any length.\n+                        while !prefix.is_empty() && prefix.last().unwrap().is_wildcard() {\n+                            prefix.pop();\n+                        }\n+                    }\n+                    let suffix: Vec<_> = if slice.array_len.is_some() {\n+                        // Same as above.\n+                        subpatterns.skip_while(Pat::is_wildcard).collect()\n+                    } else {\n+                        subpatterns.collect()\n+                    };\n+                    let wild = Pat::wildcard_from_ty(pcx.ty);\n+                    PatKind::Slice { prefix, slice: Some(wild), suffix }\n+                }\n+            },\n+            &Str(value) => PatKind::Constant { value },\n+            &FloatRange(lo, hi, end) => PatKind::Range(PatRange { lo, hi, end }),\n+            IntRange(range) => return range.to_pat(pcx.cx.tcx),\n+            NonExhaustive => PatKind::Wild,\n+            Opaque => bug!(\"we should not try to apply an opaque constructor\"),\n+            Wildcard => bug!(\n+                \"trying to apply a wildcard constructor; this should have been done in `apply_constructors`\"\n+            ),\n+        };\n+\n+        Pat { ty: pcx.ty, span: DUMMY_SP, kind: Box::new(pat) }\n+    }\n+\n+    /// Returns the number of patterns from the viewpoint of match-checking, i.e. excluding hidden\n+    /// fields. This is what we want in most cases in this file, the only exception being\n+    /// conversion to/from `Pat`.\n+    pub(super) fn len(&self) -> usize {\n+        match self {\n+            Fields::Slice(pats) => pats.len(),\n+            Fields::Vec(pats) => pats.len(),\n+            Fields::Filtered { kept_count, .. } => *kept_count,\n+        }\n+    }\n+\n+    /// Returns the complete list of patterns, including hidden fields.\n+    fn all_patterns(self) -> impl Iterator<Item = Pat<'tcx>> {\n+        let pats: SmallVec<[_; 2]> = match self {\n+            Fields::Slice(pats) => pats.iter().cloned().collect(),\n+            Fields::Vec(pats) => pats.into_iter().cloned().collect(),\n+            Fields::Filtered { fields, .. } => {\n+                // We don't skip any fields here.\n+                fields.into_iter().map(|p| p.to_pattern()).collect()\n+            }\n+        };\n+        pats.into_iter()\n+    }\n+\n+    /// Returns the filtered list of patterns, not including hidden fields.\n+    pub(super) fn filtered_patterns(self) -> SmallVec<[&'p Pat<'tcx>; 2]> {\n+        match self {\n+            Fields::Slice(pats) => pats.iter().collect(),\n+            Fields::Vec(pats) => pats,\n+            Fields::Filtered { fields, .. } => {\n+                // We skip hidden fields here\n+                fields.into_iter().filter_map(|p| p.kept()).collect()\n+            }\n+        }\n+    }\n+\n+    /// Overrides some of the fields with the provided patterns. Exactly like\n+    /// `replace_fields_indexed`, except that it takes `FieldPat`s as input.\n+    fn replace_with_fieldpats(\n+        &self,\n+        new_pats: impl IntoIterator<Item = &'p FieldPat<'tcx>>,\n+    ) -> Self {\n+        self.replace_fields_indexed(\n+            new_pats.into_iter().map(|pat| (pat.field.index(), &pat.pattern)),\n+        )\n+    }\n+\n+    /// Overrides some of the fields with the provided patterns. This is used when a pattern\n+    /// defines some fields but not all, for example `Foo { field1: Some(_), .. }`: here we start with a\n+    /// `Fields` that is just one wildcard per field of the `Foo` struct, and override the entry\n+    /// corresponding to `field1` with the pattern `Some(_)`. This is also used for slice patterns\n+    /// for the same reason.\n+    fn replace_fields_indexed(\n+        &self,\n+        new_pats: impl IntoIterator<Item = (usize, &'p Pat<'tcx>)>,\n+    ) -> Self {\n+        let mut fields = self.clone();\n+        if let Fields::Slice(pats) = fields {\n+            fields = Fields::Vec(pats.iter().collect());\n+        }\n+\n+        match &mut fields {\n+            Fields::Vec(pats) => {\n+                for (i, pat) in new_pats {\n+                    pats[i] = pat\n+                }\n+            }\n+            Fields::Filtered { fields, .. } => {\n+                for (i, pat) in new_pats {\n+                    if let FilteredField::Kept(p) = &mut fields[i] {\n+                        *p = pat\n+                    }\n+                }\n+            }\n+            Fields::Slice(_) => unreachable!(),\n+        }\n+        fields\n+    }\n+\n+    /// Replaces contained fields with the given filtered list of patterns, e.g. taken from the\n+    /// matrix. There must be `len()` patterns in `pats`.\n+    pub(super) fn replace_fields(\n+        &self,\n+        cx: &MatchCheckCtxt<'p, 'tcx>,\n+        pats: impl IntoIterator<Item = Pat<'tcx>>,\n+    ) -> Self {\n+        let pats: &[_] = cx.pattern_arena.alloc_from_iter(pats);\n+\n+        match self {\n+            Fields::Filtered { fields, kept_count } => {\n+                let mut pats = pats.iter();\n+                let mut fields = fields.clone();\n+                for f in &mut fields {\n+                    if let FilteredField::Kept(p) = f {\n+                        // We take one input pattern for each `Kept` field, in order.\n+                        *p = pats.next().unwrap();\n+                    }\n+                }\n+                Fields::Filtered { fields, kept_count: *kept_count }\n+            }\n+            _ => Fields::Slice(pats),\n+        }\n+    }\n+\n+    /// Replaces contained fields with the arguments of the given pattern. Only use on a pattern\n+    /// that is compatible with the constructor used to build `self`.\n+    /// This is meant to be used on the result of `Fields::wildcards()`. The idea is that\n+    /// `wildcards` constructs a list of fields where all entries are wildcards, and the pattern\n+    /// provided to this function fills some of the fields with non-wildcards.\n+    /// In the following example `Fields::wildcards` would return `[_, _, _, _]`. If we call\n+    /// `replace_with_pattern_arguments` on it with the pattern, the result will be `[Some(0), _,\n+    /// _, _]`.\n+    /// ```rust\n+    /// let x: [Option<u8>; 4] = foo();\n+    /// match x {\n+    ///     [Some(0), ..] => {}\n+    /// }\n+    /// ```\n+    /// This is guaranteed to preserve the number of patterns in `self`.\n+    pub(super) fn replace_with_pattern_arguments(&self, pat: &'p Pat<'tcx>) -> Self {\n+        match pat.kind.as_ref() {\n+            PatKind::Deref { subpattern } => {\n+                assert_eq!(self.len(), 1);\n+                Fields::from_single_pattern(subpattern)\n+            }\n+            PatKind::Leaf { subpatterns } | PatKind::Variant { subpatterns, .. } => {\n+                self.replace_with_fieldpats(subpatterns)\n+            }\n+            PatKind::Array { prefix, suffix, .. } | PatKind::Slice { prefix, suffix, .. } => {\n+                // Number of subpatterns for the constructor\n+                let ctor_arity = self.len();\n+\n+                // Replace the prefix and the suffix with the given patterns, leaving wildcards in\n+                // the middle if there was a subslice pattern `..`.\n+                let prefix = prefix.iter().enumerate();\n+                let suffix =\n+                    suffix.iter().enumerate().map(|(i, p)| (ctor_arity - suffix.len() + i, p));\n+                self.replace_fields_indexed(prefix.chain(suffix))\n+            }\n+            _ => self.clone(),\n+        }\n+    }\n+}"}, {"sha": "d14643c44b48d95dc46e76dd456e89be261c34d7", "filename": "compiler/rustc_mir_build/src/thir/pattern/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/2184a1444cb670421bf2836cbdbb662c077bad6a/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2184a1444cb670421bf2836cbdbb662c077bad6a/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fmod.rs?ref=2184a1444cb670421bf2836cbdbb662c077bad6a", "patch": "@@ -3,6 +3,7 @@\n mod _match;\n mod check_match;\n mod const_to_pat;\n+mod deconstruct_pat;\n \n pub(crate) use self::check_match::check_match;\n "}]}