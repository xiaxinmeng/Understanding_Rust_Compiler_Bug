{"sha": "d1206f950ffb76c76e1b74a19ae33c2b7d949454", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQxMjA2Zjk1MGZmYjc2Yzc2ZTFiNzRhMTlhZTMzYzJiN2Q5NDk0NTQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-02-15T12:11:59Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-02-15T12:11:59Z"}, "message": "Auto merge of #81855 - cjgillot:ensure-cache, r=oli-obk\n\nCheck the result cache before the DepGraph when ensuring queries\n\nSplit out of https://github.com/rust-lang/rust/pull/70951\n\nCalling `ensure` on already forced queries is a common operation.\nLooking at the results cache first is faster than checking the DepGraph for a green node.", "tree": {"sha": "09a079c230c56f5ed40ebfa7b2707db4f922ccfb", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/09a079c230c56f5ed40ebfa7b2707db4f922ccfb"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d1206f950ffb76c76e1b74a19ae33c2b7d949454", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d1206f950ffb76c76e1b74a19ae33c2b7d949454", "html_url": "https://github.com/rust-lang/rust/commit/d1206f950ffb76c76e1b74a19ae33c2b7d949454", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d1206f950ffb76c76e1b74a19ae33c2b7d949454/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9503ea19edbf01b9435e80e17d60ce1b88390116", "url": "https://api.github.com/repos/rust-lang/rust/commits/9503ea19edbf01b9435e80e17d60ce1b88390116", "html_url": "https://github.com/rust-lang/rust/commit/9503ea19edbf01b9435e80e17d60ce1b88390116"}, {"sha": "3fc8ed68e99034ad5410cef47e8cd94828ef8946", "url": "https://api.github.com/repos/rust-lang/rust/commits/3fc8ed68e99034ad5410cef47e8cd94828ef8946", "html_url": "https://github.com/rust-lang/rust/commit/3fc8ed68e99034ad5410cef47e8cd94828ef8946"}], "stats": {"total": 535, "additions": 298, "deletions": 237}, "files": [{"sha": "14db71cb8f0701040da9ad286fa75c2ed6580f75", "filename": "compiler/rustc_data_structures/src/sharded.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_data_structures%2Fsrc%2Fsharded.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_data_structures%2Fsrc%2Fsharded.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Fsharded.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -63,23 +63,9 @@ impl<T> Sharded<T> {\n         if SHARDS == 1 { &self.shards[0].0 } else { self.get_shard_by_hash(make_hash(val)) }\n     }\n \n-    /// Get a shard with a pre-computed hash value. If `get_shard_by_value` is\n-    /// ever used in combination with `get_shard_by_hash` on a single `Sharded`\n-    /// instance, then `hash` must be computed with `FxHasher`. Otherwise,\n-    /// `hash` can be computed with any hasher, so long as that hasher is used\n-    /// consistently for each `Sharded` instance.\n-    #[inline]\n-    pub fn get_shard_index_by_hash(&self, hash: u64) -> usize {\n-        let hash_len = mem::size_of::<usize>();\n-        // Ignore the top 7 bits as hashbrown uses these and get the next SHARD_BITS highest bits.\n-        // hashbrown also uses the lowest bits, so we can't use those\n-        let bits = (hash >> (hash_len * 8 - 7 - SHARD_BITS)) as usize;\n-        bits % SHARDS\n-    }\n-\n     #[inline]\n     pub fn get_shard_by_hash(&self, hash: u64) -> &Lock<T> {\n-        &self.shards[self.get_shard_index_by_hash(hash)].0\n+        &self.shards[get_shard_index_by_hash(hash)].0\n     }\n \n     #[inline]\n@@ -166,3 +152,17 @@ fn make_hash<K: Hash + ?Sized>(val: &K) -> u64 {\n     val.hash(&mut state);\n     state.finish()\n }\n+\n+/// Get a shard with a pre-computed hash value. If `get_shard_by_value` is\n+/// ever used in combination with `get_shard_by_hash` on a single `Sharded`\n+/// instance, then `hash` must be computed with `FxHasher`. Otherwise,\n+/// `hash` can be computed with any hasher, so long as that hasher is used\n+/// consistently for each `Sharded` instance.\n+#[inline]\n+pub fn get_shard_index_by_hash(hash: u64) -> usize {\n+    let hash_len = mem::size_of::<usize>();\n+    // Ignore the top 7 bits as hashbrown uses these and get the next SHARD_BITS highest bits.\n+    // hashbrown also uses the lowest bits, so we can't use those\n+    let bits = (hash >> (hash_len * 8 - 7 - SHARD_BITS)) as usize;\n+    bits % SHARDS\n+}"}, {"sha": "4654a8424706d4612d0b0d1e5bc0734d63123c6d", "filename": "compiler/rustc_middle/src/ty/context.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fcontext.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -963,6 +963,7 @@ pub struct GlobalCtxt<'tcx> {\n     pub(crate) definitions: &'tcx Definitions,\n \n     pub queries: query::Queries<'tcx>,\n+    pub query_caches: query::QueryCaches<'tcx>,\n \n     maybe_unused_trait_imports: FxHashSet<LocalDefId>,\n     maybe_unused_extern_crates: Vec<(LocalDefId, Span)>,\n@@ -1154,6 +1155,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             untracked_crate: krate,\n             definitions,\n             queries: query::Queries::new(providers, extern_providers, on_disk_query_result_cache),\n+            query_caches: query::QueryCaches::default(),\n             ty_rcache: Default::default(),\n             pred_rcache: Default::default(),\n             selection_cache: Default::default(),"}, {"sha": "b41edb5deeb2cc1973454b9d0141cf8a564017d9", "filename": "compiler/rustc_middle/src/ty/query/on_disk_cache.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fon_disk_cache.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -1244,10 +1244,9 @@ where\n         .prof\n         .extra_verbose_generic_activity(\"encode_query_results_for\", std::any::type_name::<Q>());\n \n-    let state = Q::query_state(tcx);\n-    assert!(state.all_inactive());\n-\n-    state.iter_results(|results| {\n+    assert!(Q::query_state(tcx).all_inactive());\n+    let cache = Q::query_cache(tcx);\n+    cache.iter_results(|results| {\n         for (key, value, dep_node) in results {\n             if Q::cache_on_disk(tcx, &key, Some(value)) {\n                 let dep_node = SerializedDepNodeIndex::new(dep_node.index());"}, {"sha": "0961d4d0091d0a3c953091f0fc89937d91d28021", "filename": "compiler/rustc_middle/src/ty/query/plumbing.rs", "status": "modified", "additions": 53, "deletions": 16, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fplumbing.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -342,14 +342,28 @@ macro_rules! define_queries {\n \n             $(pub type $name<$tcx> = $V;)*\n         }\n+        #[allow(nonstandard_style, unused_lifetimes)]\n+        pub mod query_storage {\n+            use super::*;\n+\n+            $(pub type $name<$tcx> = query_storage!([$($modifiers)*][$($K)*, $V]);)*\n+        }\n+        #[allow(nonstandard_style, unused_lifetimes)]\n+        pub mod query_stored {\n+            use super::*;\n+\n+            $(pub type $name<$tcx> = <query_storage::$name<$tcx> as QueryStorage>::Stored;)*\n+        }\n+\n+        #[derive(Default)]\n+        pub struct QueryCaches<$tcx> {\n+            $($(#[$attr])* $name: QueryCacheStore<query_storage::$name<$tcx>>,)*\n+        }\n \n         $(impl<$tcx> QueryConfig for queries::$name<$tcx> {\n             type Key = $($K)*;\n             type Value = $V;\n-            type Stored = <\n-                query_storage!([$($modifiers)*][$($K)*, $V])\n-                as QueryStorage\n-            >::Stored;\n+            type Stored = query_stored::$name<$tcx>;\n             const NAME: &'static str = stringify!($name);\n         }\n \n@@ -358,13 +372,20 @@ macro_rules! define_queries {\n             const EVAL_ALWAYS: bool = is_eval_always!([$($modifiers)*]);\n             const DEP_KIND: dep_graph::DepKind = dep_graph::DepKind::$name;\n \n-            type Cache = query_storage!([$($modifiers)*][$($K)*, $V]);\n+            type Cache = query_storage::$name<$tcx>;\n \n             #[inline(always)]\n-            fn query_state<'a>(tcx: TyCtxt<$tcx>) -> &'a QueryState<crate::dep_graph::DepKind, <TyCtxt<$tcx> as QueryContext>::Query, Self::Cache> {\n+            fn query_state<'a>(tcx: TyCtxt<$tcx>) -> &'a QueryState<crate::dep_graph::DepKind, Query<$tcx>, Self::Key> {\n                 &tcx.queries.$name\n             }\n \n+            #[inline(always)]\n+            fn query_cache<'a>(tcx: TyCtxt<$tcx>) -> &'a QueryCacheStore<Self::Cache>\n+                where 'tcx:'a\n+            {\n+                &tcx.query_caches.$name\n+            }\n+\n             #[inline]\n             fn compute(tcx: TyCtxt<'tcx>, key: Self::Key) -> Self::Value {\n                 let provider = tcx.queries.providers.get(key.query_crate())\n@@ -401,7 +422,15 @@ macro_rules! define_queries {\n             $($(#[$attr])*\n             #[inline(always)]\n             pub fn $name(self, key: query_helper_param_ty!($($K)*)) {\n-                ensure_query::<queries::$name<'_>, _>(self.tcx, key.into_query_param())\n+                let key = key.into_query_param();\n+                let cached = try_get_cached(self.tcx, &self.tcx.query_caches.$name, &key, |_| {});\n+\n+                let lookup = match cached {\n+                    Ok(()) => return,\n+                    Err(lookup) => lookup,\n+                };\n+\n+                get_query::<queries::$name<'_>, _>(self.tcx, DUMMY_SP, key, lookup, QueryMode::Ensure);\n             })*\n         }\n \n@@ -442,10 +471,9 @@ macro_rules! define_queries {\n             $($(#[$attr])*\n             #[inline(always)]\n             #[must_use]\n-            pub fn $name(self, key: query_helper_param_ty!($($K)*))\n-                -> <queries::$name<$tcx> as QueryConfig>::Stored\n+            pub fn $name(self, key: query_helper_param_ty!($($K)*)) -> query_stored::$name<$tcx>\n             {\n-                self.at(DUMMY_SP).$name(key.into_query_param())\n+                self.at(DUMMY_SP).$name(key)\n             })*\n \n             /// All self-profiling events generated by the query engine use\n@@ -471,7 +499,7 @@ macro_rules! define_queries {\n                     alloc_self_profile_query_strings_for_query_cache(\n                         self,\n                         stringify!($name),\n-                        &self.queries.$name,\n+                        &self.query_caches.$name,\n                         &mut string_cache,\n                     );\n                 })*\n@@ -481,10 +509,19 @@ macro_rules! define_queries {\n         impl TyCtxtAt<$tcx> {\n             $($(#[$attr])*\n             #[inline(always)]\n-            pub fn $name(self, key: query_helper_param_ty!($($K)*))\n-                -> <queries::$name<$tcx> as QueryConfig>::Stored\n+            pub fn $name(self, key: query_helper_param_ty!($($K)*)) -> query_stored::$name<$tcx>\n             {\n-                get_query::<queries::$name<'_>, _>(self.tcx, self.span, key.into_query_param())\n+                let key = key.into_query_param();\n+                let cached = try_get_cached(self.tcx, &self.tcx.query_caches.$name, &key, |value| {\n+                    value.clone()\n+                });\n+\n+                let lookup = match cached {\n+                    Ok(value) => return value,\n+                    Err(lookup) => lookup,\n+                };\n+\n+                get_query::<queries::$name<'_>, _>(self.tcx, self.span, key, lookup, QueryMode::Get).unwrap()\n             })*\n         }\n \n@@ -518,8 +555,8 @@ macro_rules! define_queries_struct {\n \n             $($(#[$attr])*  $name: QueryState<\n                 crate::dep_graph::DepKind,\n-                <TyCtxt<$tcx> as QueryContext>::Query,\n-                <queries::$name<$tcx> as QueryAccessors<TyCtxt<'tcx>>>::Cache,\n+                Query<$tcx>,\n+                query_keys::$name<$tcx>,\n             >,)*\n         }\n "}, {"sha": "9976e7885090cb4e23fd66e0e2e350b036a2a6a8", "filename": "compiler/rustc_middle/src/ty/query/profiling_support.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fprofiling_support.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fprofiling_support.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fprofiling_support.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -5,7 +5,7 @@ use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::profiling::SelfProfiler;\n use rustc_hir::def_id::{CrateNum, DefId, DefIndex, LocalDefId, CRATE_DEF_INDEX, LOCAL_CRATE};\n use rustc_hir::definitions::DefPathData;\n-use rustc_query_system::query::{QueryCache, QueryContext, QueryState};\n+use rustc_query_system::query::{QueryCache, QueryCacheStore};\n use std::fmt::Debug;\n use std::io::Write;\n \n@@ -230,7 +230,7 @@ where\n pub(super) fn alloc_self_profile_query_strings_for_query_cache<'tcx, C>(\n     tcx: TyCtxt<'tcx>,\n     query_name: &'static str,\n-    query_state: &QueryState<crate::dep_graph::DepKind, <TyCtxt<'tcx> as QueryContext>::Query, C>,\n+    query_cache: &QueryCacheStore<C>,\n     string_cache: &mut QueryKeyStringCache,\n ) where\n     C: QueryCache,\n@@ -251,7 +251,7 @@ pub(super) fn alloc_self_profile_query_strings_for_query_cache<'tcx, C>(\n             // need to invoke queries itself, we cannot keep the query caches\n             // locked while doing so. Instead we copy out the\n             // `(query_key, dep_node_index)` pairs and release the lock again.\n-            let query_keys_and_indices: Vec<_> = query_state\n+            let query_keys_and_indices: Vec<_> = query_cache\n                 .iter_results(|results| results.map(|(k, _, i)| (k.clone(), i)).collect());\n \n             // Now actually allocate the strings. If allocating the strings\n@@ -276,7 +276,7 @@ pub(super) fn alloc_self_profile_query_strings_for_query_cache<'tcx, C>(\n             let query_name = profiler.get_or_alloc_cached_string(query_name);\n             let event_id = event_id_builder.from_label(query_name).to_string_id();\n \n-            query_state.iter_results(|results| {\n+            query_cache.iter_results(|results| {\n                 let query_invocation_ids: Vec<_> = results.map(|v| v.2.into()).collect();\n \n                 profiler.bulk_map_query_invocation_id_to_single_string("}, {"sha": "c885a10f8059524040b4d33a8f86c46bb37eba10", "filename": "compiler/rustc_middle/src/ty/query/stats.rs", "status": "modified", "additions": 3, "deletions": 8, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fstats.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fstats.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fquery%2Fstats.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -1,10 +1,9 @@\n use crate::ty::query::queries;\n use crate::ty::TyCtxt;\n use rustc_hir::def_id::{DefId, LOCAL_CRATE};\n-use rustc_query_system::query::{QueryAccessors, QueryCache, QueryContext, QueryState};\n+use rustc_query_system::query::{QueryAccessors, QueryCache, QueryCacheStore};\n \n use std::any::type_name;\n-use std::hash::Hash;\n use std::mem;\n #[cfg(debug_assertions)]\n use std::sync::atomic::Ordering;\n@@ -37,10 +36,8 @@ struct QueryStats {\n     local_def_id_keys: Option<usize>,\n }\n \n-fn stats<D, Q, C>(name: &'static str, map: &QueryState<D, Q, C>) -> QueryStats\n+fn stats<C>(name: &'static str, map: &QueryCacheStore<C>) -> QueryStats\n where\n-    D: Copy + Clone + Eq + Hash,\n-    Q: Clone,\n     C: QueryCache,\n {\n     let mut stats = QueryStats {\n@@ -128,12 +125,10 @@ macro_rules! print_stats {\n \n             $(\n                 queries.push(stats::<\n-                    crate::dep_graph::DepKind,\n-                    <TyCtxt<'_> as QueryContext>::Query,\n                     <queries::$name<'_> as QueryAccessors<TyCtxt<'_>>>::Cache,\n                 >(\n                     stringify!($name),\n-                    &tcx.queries.$name,\n+                    &tcx.query_caches.$name,\n                 ));\n             )*\n "}, {"sha": "ec71c8685804fb2bfd35259fe8dcf84f9ce02363", "filename": "compiler/rustc_query_system/src/query/caches.rs", "status": "modified", "additions": 27, "deletions": 31, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -1,5 +1,5 @@\n use crate::dep_graph::DepNodeIndex;\n-use crate::query::plumbing::{QueryLookup, QueryState};\n+use crate::query::plumbing::{QueryCacheStore, QueryLookup};\n \n use rustc_arena::TypedArena;\n use rustc_data_structures::fx::FxHashMap;\n@@ -31,17 +31,15 @@ pub trait QueryCache: QueryStorage {\n     /// It returns the shard index and a lock guard to the shard,\n     /// which will be used if the query is not in the cache and we need\n     /// to compute it.\n-    fn lookup<D, Q, R, OnHit, OnMiss>(\n+    fn lookup<'s, R, OnHit>(\n         &self,\n-        state: &QueryState<D, Q, Self>,\n-        key: Self::Key,\n+        state: &'s QueryCacheStore<Self>,\n+        key: &Self::Key,\n         // `on_hit` can be called while holding a lock to the query state shard.\n         on_hit: OnHit,\n-        on_miss: OnMiss,\n-    ) -> R\n+    ) -> Result<R, QueryLookup>\n     where\n-        OnHit: FnOnce(&Self::Stored, DepNodeIndex) -> R,\n-        OnMiss: FnOnce(Self::Key, QueryLookup<'_, D, Q, Self::Key, Self::Sharded>) -> R;\n+        OnHit: FnOnce(&Self::Stored, DepNodeIndex) -> R;\n \n     fn complete(\n         &self,\n@@ -95,23 +93,24 @@ where\n     type Sharded = FxHashMap<K, (V, DepNodeIndex)>;\n \n     #[inline(always)]\n-    fn lookup<D, Q, R, OnHit, OnMiss>(\n+    fn lookup<'s, R, OnHit>(\n         &self,\n-        state: &QueryState<D, Q, Self>,\n-        key: K,\n+        state: &'s QueryCacheStore<Self>,\n+        key: &K,\n         on_hit: OnHit,\n-        on_miss: OnMiss,\n-    ) -> R\n+    ) -> Result<R, QueryLookup>\n     where\n         OnHit: FnOnce(&V, DepNodeIndex) -> R,\n-        OnMiss: FnOnce(K, QueryLookup<'_, D, Q, K, Self::Sharded>) -> R,\n     {\n-        let mut lookup = state.get_lookup(&key);\n-        let lock = &mut *lookup.lock;\n+        let (lookup, lock) = state.get_lookup(key);\n+        let result = lock.raw_entry().from_key_hashed_nocheck(lookup.key_hash, key);\n \n-        let result = lock.cache.raw_entry().from_key_hashed_nocheck(lookup.key_hash, &key);\n-\n-        if let Some((_, value)) = result { on_hit(&value.0, value.1) } else { on_miss(key, lookup) }\n+        if let Some((_, value)) = result {\n+            let hit_result = on_hit(&value.0, value.1);\n+            Ok(hit_result)\n+        } else {\n+            Err(lookup)\n+        }\n     }\n \n     #[inline]\n@@ -177,26 +176,23 @@ where\n     type Sharded = FxHashMap<K, &'tcx (V, DepNodeIndex)>;\n \n     #[inline(always)]\n-    fn lookup<D, Q, R, OnHit, OnMiss>(\n+    fn lookup<'s, R, OnHit>(\n         &self,\n-        state: &QueryState<D, Q, Self>,\n-        key: K,\n+        state: &'s QueryCacheStore<Self>,\n+        key: &K,\n         on_hit: OnHit,\n-        on_miss: OnMiss,\n-    ) -> R\n+    ) -> Result<R, QueryLookup>\n     where\n         OnHit: FnOnce(&&'tcx V, DepNodeIndex) -> R,\n-        OnMiss: FnOnce(K, QueryLookup<'_, D, Q, K, Self::Sharded>) -> R,\n     {\n-        let mut lookup = state.get_lookup(&key);\n-        let lock = &mut *lookup.lock;\n-\n-        let result = lock.cache.raw_entry().from_key_hashed_nocheck(lookup.key_hash, &key);\n+        let (lookup, lock) = state.get_lookup(key);\n+        let result = lock.raw_entry().from_key_hashed_nocheck(lookup.key_hash, key);\n \n         if let Some((_, value)) = result {\n-            on_hit(&&value.0, value.1)\n+            let hit_result = on_hit(&&value.0, value.1);\n+            Ok(hit_result)\n         } else {\n-            on_miss(key, lookup)\n+            Err(lookup)\n         }\n     }\n "}, {"sha": "fecd75049fb7aa8be830e9b6160b8afd3b162137", "filename": "compiler/rustc_query_system/src/query/config.rs", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -4,7 +4,7 @@ use crate::dep_graph::DepNode;\n use crate::dep_graph::SerializedDepNodeIndex;\n use crate::query::caches::QueryCache;\n use crate::query::plumbing::CycleError;\n-use crate::query::{QueryContext, QueryState};\n+use crate::query::{QueryCacheStore, QueryContext, QueryState};\n \n use rustc_data_structures::fingerprint::Fingerprint;\n use std::fmt::Debug;\n@@ -73,7 +73,12 @@ pub trait QueryAccessors<CTX: QueryContext>: QueryConfig {\n     type Cache: QueryCache<Key = Self::Key, Stored = Self::Stored, Value = Self::Value>;\n \n     // Don't use this method to access query results, instead use the methods on TyCtxt\n-    fn query_state<'a>(tcx: CTX) -> &'a QueryState<CTX::DepKind, CTX::Query, Self::Cache>;\n+    fn query_state<'a>(tcx: CTX) -> &'a QueryState<CTX::DepKind, CTX::Query, Self::Key>;\n+\n+    // Don't use this method to access query results, instead use the methods on TyCtxt\n+    fn query_cache<'a>(tcx: CTX) -> &'a QueryCacheStore<Self::Cache>\n+    where\n+        CTX: 'a;\n \n     fn to_dep_node(tcx: CTX, key: &Self::Key) -> DepNode<CTX::DepKind>\n     where"}, {"sha": "2610ce83e4d3e7a49004a865710945fd93eab715", "filename": "compiler/rustc_query_system/src/query/plumbing.rs", "status": "modified", "additions": 184, "deletions": 157, "changes": 341, "blob_url": "https://github.com/rust-lang/rust/blob/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d1206f950ffb76c76e1b74a19ae33c2b7d949454/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs?ref=d1206f950ffb76c76e1b74a19ae33c2b7d949454", "patch": "@@ -13,11 +13,10 @@ use crate::query::{QueryContext, QueryMap};\n use rustc_data_structures::cold_path;\n use rustc_data_structures::fingerprint::Fingerprint;\n use rustc_data_structures::fx::{FxHashMap, FxHasher};\n-use rustc_data_structures::sharded::Sharded;\n+use rustc_data_structures::sharded::{get_shard_index_by_hash, Sharded};\n use rustc_data_structures::sync::{Lock, LockGuard};\n use rustc_data_structures::thin_vec::ThinVec;\n use rustc_errors::{Diagnostic, FatalError};\n-use rustc_span::source_map::DUMMY_SP;\n use rustc_span::Span;\n use std::collections::hash_map::Entry;\n use std::fmt::Debug;\n@@ -28,45 +27,77 @@ use std::ptr;\n #[cfg(debug_assertions)]\n use std::sync::atomic::{AtomicUsize, Ordering};\n \n-pub(super) struct QueryStateShard<D, Q, K, C> {\n-    pub(super) cache: C,\n-    active: FxHashMap<K, QueryResult<D, Q>>,\n-\n-    /// Used to generate unique ids for active jobs.\n-    jobs: u32,\n+pub struct QueryCacheStore<C: QueryCache> {\n+    cache: C,\n+    shards: Sharded<C::Sharded>,\n+    #[cfg(debug_assertions)]\n+    pub cache_hits: AtomicUsize,\n }\n \n-impl<D, Q, K, C: Default> Default for QueryStateShard<D, Q, K, C> {\n-    fn default() -> QueryStateShard<D, Q, K, C> {\n-        QueryStateShard { cache: Default::default(), active: Default::default(), jobs: 0 }\n+impl<C: QueryCache> Default for QueryCacheStore<C> {\n+    fn default() -> Self {\n+        Self {\n+            cache: C::default(),\n+            shards: Default::default(),\n+            #[cfg(debug_assertions)]\n+            cache_hits: AtomicUsize::new(0),\n+        }\n     }\n }\n \n-pub struct QueryState<D, Q, C: QueryCache> {\n-    cache: C,\n-    shards: Sharded<QueryStateShard<D, Q, C::Key, C::Sharded>>,\n-    #[cfg(debug_assertions)]\n-    pub cache_hits: AtomicUsize,\n+/// Values used when checking a query cache which can be reused on a cache-miss to execute the query.\n+pub struct QueryLookup {\n+    pub(super) key_hash: u64,\n+    shard: usize,\n }\n \n-impl<D, Q, C: QueryCache> QueryState<D, Q, C> {\n+// We compute the key's hash once and then use it for both the\n+// shard lookup and the hashmap lookup. This relies on the fact\n+// that both of them use `FxHasher`.\n+fn hash_for_shard<K: Hash>(key: &K) -> u64 {\n+    let mut hasher = FxHasher::default();\n+    key.hash(&mut hasher);\n+    hasher.finish()\n+}\n+\n+impl<C: QueryCache> QueryCacheStore<C> {\n     pub(super) fn get_lookup<'tcx>(\n         &'tcx self,\n         key: &C::Key,\n-    ) -> QueryLookup<'tcx, D, Q, C::Key, C::Sharded> {\n-        // We compute the key's hash once and then use it for both the\n-        // shard lookup and the hashmap lookup. This relies on the fact\n-        // that both of them use `FxHasher`.\n-        let mut hasher = FxHasher::default();\n-        key.hash(&mut hasher);\n-        let key_hash = hasher.finish();\n-\n-        let shard = self.shards.get_shard_index_by_hash(key_hash);\n+    ) -> (QueryLookup, LockGuard<'tcx, C::Sharded>) {\n+        let key_hash = hash_for_shard(key);\n+        let shard = get_shard_index_by_hash(key_hash);\n         let lock = self.shards.get_shard_by_index(shard).lock();\n-        QueryLookup { key_hash, shard, lock }\n+        (QueryLookup { key_hash, shard }, lock)\n+    }\n+\n+    pub fn iter_results<R>(\n+        &self,\n+        f: impl for<'a> FnOnce(\n+            Box<dyn Iterator<Item = (&'a C::Key, &'a C::Value, DepNodeIndex)> + 'a>,\n+        ) -> R,\n+    ) -> R {\n+        self.cache.iter(&self.shards, |shard| &mut *shard, f)\n     }\n }\n \n+struct QueryStateShard<D, Q, K> {\n+    active: FxHashMap<K, QueryResult<D, Q>>,\n+\n+    /// Used to generate unique ids for active jobs.\n+    jobs: u32,\n+}\n+\n+impl<D, Q, K> Default for QueryStateShard<D, Q, K> {\n+    fn default() -> QueryStateShard<D, Q, K> {\n+        QueryStateShard { active: Default::default(), jobs: 0 }\n+    }\n+}\n+\n+pub struct QueryState<D, Q, K> {\n+    shards: Sharded<QueryStateShard<D, Q, K>>,\n+}\n+\n /// Indicates the state of a query for a given key in a query map.\n enum QueryResult<D, Q> {\n     /// An already executing query. The query job can be used to await for its completion.\n@@ -77,21 +108,12 @@ enum QueryResult<D, Q> {\n     Poisoned,\n }\n \n-impl<D, Q, C> QueryState<D, Q, C>\n+impl<D, Q, K> QueryState<D, Q, K>\n where\n     D: Copy + Clone + Eq + Hash,\n     Q: Clone,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone + Debug,\n {\n-    pub fn iter_results<R>(\n-        &self,\n-        f: impl for<'a> FnOnce(\n-            Box<dyn Iterator<Item = (&'a C::Key, &'a C::Value, DepNodeIndex)> + 'a>,\n-        ) -> R,\n-    ) -> R {\n-        self.cache.iter(&self.shards, |shard| &mut shard.cache, f)\n-    }\n-\n     pub fn all_inactive(&self) -> bool {\n         let shards = self.shards.lock_shards();\n         shards.iter().all(|shard| shard.active.is_empty())\n@@ -100,7 +122,7 @@ where\n     pub fn try_collect_active_jobs(\n         &self,\n         kind: D,\n-        make_query: fn(C::Key) -> Q,\n+        make_query: fn(K) -> Q,\n         jobs: &mut QueryMap<D, Q>,\n     ) -> Option<()> {\n         // We use try_lock_shards here since we are called from the\n@@ -123,24 +145,12 @@ where\n     }\n }\n \n-impl<D, Q, C: QueryCache> Default for QueryState<D, Q, C> {\n-    fn default() -> QueryState<D, Q, C> {\n-        QueryState {\n-            cache: C::default(),\n-            shards: Default::default(),\n-            #[cfg(debug_assertions)]\n-            cache_hits: AtomicUsize::new(0),\n-        }\n+impl<D, Q, K> Default for QueryState<D, Q, K> {\n+    fn default() -> QueryState<D, Q, K> {\n+        QueryState { shards: Default::default() }\n     }\n }\n \n-/// Values used when checking a query cache which can be reused on a cache-miss to execute the query.\n-pub struct QueryLookup<'tcx, D, Q, K, C> {\n-    pub(super) key_hash: u64,\n-    shard: usize,\n-    pub(super) lock: LockGuard<'tcx, QueryStateShard<D, Q, K, C>>,\n-}\n-\n /// A type representing the responsibility to execute the job in the `job` field.\n /// This will poison the relevant query if dropped.\n struct JobOwner<'tcx, D, Q, C>\n@@ -149,7 +159,8 @@ where\n     Q: Clone,\n     C: QueryCache,\n {\n-    state: &'tcx QueryState<D, Q, C>,\n+    state: &'tcx QueryState<D, Q, C::Key>,\n+    cache: &'tcx QueryCacheStore<C>,\n     key: C::Key,\n     id: QueryJobId<D>,\n }\n@@ -169,18 +180,21 @@ where\n     /// This function is inlined because that results in a noticeable speed-up\n     /// for some compile-time benchmarks.\n     #[inline(always)]\n-    fn try_start<'a, 'b, CTX>(\n+    fn try_start<'b, CTX>(\n         tcx: CTX,\n-        state: &'b QueryState<CTX::DepKind, CTX::Query, C>,\n+        state: &'b QueryState<CTX::DepKind, CTX::Query, C::Key>,\n+        cache: &'b QueryCacheStore<C>,\n         span: Span,\n         key: &C::Key,\n-        mut lookup: QueryLookup<'a, CTX::DepKind, CTX::Query, C::Key, C::Sharded>,\n+        lookup: QueryLookup,\n         query: &QueryVtable<CTX, C::Key, C::Value>,\n     ) -> TryGetJob<'b, CTX::DepKind, CTX::Query, C>\n     where\n         CTX: QueryContext,\n     {\n-        let lock = &mut *lookup.lock;\n+        let shard = lookup.shard;\n+        let mut state_lock = state.shards.get_shard_by_index(shard).lock();\n+        let lock = &mut *state_lock;\n \n         let (latch, mut _query_blocked_prof_timer) = match lock.active.entry((*key).clone()) {\n             Entry::Occupied(mut entry) => {\n@@ -196,7 +210,7 @@ where\n                         };\n \n                         // Create the id of the job we're waiting for\n-                        let id = QueryJobId::new(job.id, lookup.shard, query.dep_kind);\n+                        let id = QueryJobId::new(job.id, shard, query.dep_kind);\n \n                         (job.latch(id), _query_blocked_prof_timer)\n                     }\n@@ -211,18 +225,18 @@ where\n                 lock.jobs = id;\n                 let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n \n-                let global_id = QueryJobId::new(id, lookup.shard, query.dep_kind);\n+                let global_id = QueryJobId::new(id, shard, query.dep_kind);\n \n                 let job = tcx.current_query_job();\n                 let job = QueryJob::new(id, span, job);\n \n                 entry.insert(QueryResult::Started(job));\n \n-                let owner = JobOwner { state, id: global_id, key: (*key).clone() };\n+                let owner = JobOwner { state, cache, id: global_id, key: (*key).clone() };\n                 return TryGetJob::NotYetStarted(owner);\n             }\n         };\n-        mem::drop(lookup.lock);\n+        mem::drop(state_lock);\n \n         // If we are single-threaded we know that we have cycle error,\n         // so we just return the error.\n@@ -234,7 +248,7 @@ where\n                 span,\n             );\n             let value = query.handle_cycle_error(tcx, error);\n-            state.cache.store_nocache(value)\n+            cache.cache.store_nocache(value)\n         }));\n \n         // With parallel queries we might just have to wait on some other\n@@ -245,17 +259,23 @@ where\n \n             if let Err(cycle) = result {\n                 let value = query.handle_cycle_error(tcx, cycle);\n-                let value = state.cache.store_nocache(value);\n+                let value = cache.cache.store_nocache(value);\n                 return TryGetJob::Cycle(value);\n             }\n \n-            let cached = try_get_cached(\n-                tcx,\n-                state,\n-                (*key).clone(),\n-                |value, index| (value.clone(), index),\n-                |_, _| panic!(\"value must be in cache after waiting\"),\n-            );\n+            let cached = cache\n+                .cache\n+                .lookup(cache, &key, |value, index| {\n+                    if unlikely!(tcx.profiler().enabled()) {\n+                        tcx.profiler().query_cache_hit(index.into());\n+                    }\n+                    #[cfg(debug_assertions)]\n+                    {\n+                        cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n+                    }\n+                    (value.clone(), index)\n+                })\n+                .unwrap_or_else(|_| panic!(\"value must be in cache after waiting\"));\n \n             if let Some(prof_timer) = _query_blocked_prof_timer.take() {\n                 prof_timer.finish_with_query_invocation_id(cached.1.into());\n@@ -271,17 +291,25 @@ where\n         // We can move out of `self` here because we `mem::forget` it below\n         let key = unsafe { ptr::read(&self.key) };\n         let state = self.state;\n+        let cache = self.cache;\n \n         // Forget ourself so our destructor won't poison the query\n         mem::forget(self);\n \n         let (job, result) = {\n-            let mut lock = state.shards.get_shard_by_value(&key).lock();\n-            let job = match lock.active.remove(&key).unwrap() {\n-                QueryResult::Started(job) => job,\n-                QueryResult::Poisoned => panic!(),\n+            let key_hash = hash_for_shard(&key);\n+            let shard = get_shard_index_by_hash(key_hash);\n+            let job = {\n+                let mut lock = state.shards.get_shard_by_index(shard).lock();\n+                match lock.active.remove(&key).unwrap() {\n+                    QueryResult::Started(job) => job,\n+                    QueryResult::Poisoned => panic!(),\n+                }\n+            };\n+            let result = {\n+                let mut lock = cache.shards.get_shard_by_index(shard).lock();\n+                cache.cache.complete(&mut lock, key, result, dep_node_index)\n             };\n-            let result = state.cache.complete(&mut lock.cache, key, result, dep_node_index);\n             (job, result)\n         };\n \n@@ -357,43 +385,38 @@ where\n /// It returns the shard index and a lock guard to the shard,\n /// which will be used if the query is not in the cache and we need\n /// to compute it.\n-fn try_get_cached<CTX, C, R, OnHit, OnMiss>(\n+pub fn try_get_cached<'a, CTX, C, R, OnHit>(\n     tcx: CTX,\n-    state: &QueryState<CTX::DepKind, CTX::Query, C>,\n-    key: C::Key,\n+    cache: &'a QueryCacheStore<C>,\n+    key: &C::Key,\n     // `on_hit` can be called while holding a lock to the query cache\n     on_hit: OnHit,\n-    on_miss: OnMiss,\n-) -> R\n+) -> Result<R, QueryLookup>\n where\n     C: QueryCache,\n     CTX: QueryContext,\n-    OnHit: FnOnce(&C::Stored, DepNodeIndex) -> R,\n-    OnMiss: FnOnce(C::Key, QueryLookup<'_, CTX::DepKind, CTX::Query, C::Key, C::Sharded>) -> R,\n+    OnHit: FnOnce(&C::Stored) -> R,\n {\n-    state.cache.lookup(\n-        state,\n-        key,\n-        |value, index| {\n-            if unlikely!(tcx.profiler().enabled()) {\n-                tcx.profiler().query_cache_hit(index.into());\n-            }\n-            #[cfg(debug_assertions)]\n-            {\n-                state.cache_hits.fetch_add(1, Ordering::Relaxed);\n-            }\n-            on_hit(value, index)\n-        },\n-        on_miss,\n-    )\n+    cache.cache.lookup(cache, &key, |value, index| {\n+        if unlikely!(tcx.profiler().enabled()) {\n+            tcx.profiler().query_cache_hit(index.into());\n+        }\n+        #[cfg(debug_assertions)]\n+        {\n+            cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n+        }\n+        tcx.dep_graph().read_index(index);\n+        on_hit(value)\n+    })\n }\n \n fn try_execute_query<CTX, C>(\n     tcx: CTX,\n-    state: &QueryState<CTX::DepKind, CTX::Query, C>,\n+    state: &QueryState<CTX::DepKind, CTX::Query, C::Key>,\n+    cache: &QueryCacheStore<C>,\n     span: Span,\n     key: C::Key,\n-    lookup: QueryLookup<'_, CTX::DepKind, CTX::Query, C::Key, C::Sharded>,\n+    lookup: QueryLookup,\n     query: &QueryVtable<CTX, C::Key, C::Value>,\n ) -> C::Stored\n where\n@@ -402,7 +425,7 @@ where\n     CTX: QueryContext,\n {\n     let job = match JobOwner::<'_, CTX::DepKind, CTX::Query, C>::try_start(\n-        tcx, state, span, &key, lookup, query,\n+        tcx, state, cache, span, &key, lookup, query,\n     ) {\n         TryGetJob::NotYetStarted(job) => job,\n         TryGetJob::Cycle(result) => return result,\n@@ -617,55 +640,43 @@ where\n #[inline(never)]\n fn get_query_impl<CTX, C>(\n     tcx: CTX,\n-    state: &QueryState<CTX::DepKind, CTX::Query, C>,\n+    state: &QueryState<CTX::DepKind, CTX::Query, C::Key>,\n+    cache: &QueryCacheStore<C>,\n     span: Span,\n     key: C::Key,\n+    lookup: QueryLookup,\n     query: &QueryVtable<CTX, C::Key, C::Value>,\n ) -> C::Stored\n where\n     CTX: QueryContext,\n     C: QueryCache,\n     C::Key: crate::dep_graph::DepNodeParams<CTX>,\n {\n-    try_get_cached(\n-        tcx,\n-        state,\n-        key,\n-        |value, index| {\n-            tcx.dep_graph().read_index(index);\n-            value.clone()\n-        },\n-        |key, lookup| try_execute_query(tcx, state, span, key, lookup, query),\n-    )\n+    try_execute_query(tcx, state, cache, span, key, lookup, query)\n }\n \n /// Ensure that either this query has all green inputs or been executed.\n /// Executing `query::ensure(D)` is considered a read of the dep-node `D`.\n+/// Returns true if the query should still run.\n ///\n /// This function is particularly useful when executing passes for their\n /// side-effects -- e.g., in order to report errors for erroneous programs.\n ///\n /// Note: The optimization is only available during incr. comp.\n #[inline(never)]\n-fn ensure_query_impl<CTX, C>(\n-    tcx: CTX,\n-    state: &QueryState<CTX::DepKind, CTX::Query, C>,\n-    key: C::Key,\n-    query: &QueryVtable<CTX, C::Key, C::Value>,\n-) where\n-    C: QueryCache,\n-    C::Key: crate::dep_graph::DepNodeParams<CTX>,\n+fn ensure_must_run<CTX, K, V>(tcx: CTX, key: &K, query: &QueryVtable<CTX, K, V>) -> bool\n+where\n+    K: crate::dep_graph::DepNodeParams<CTX>,\n     CTX: QueryContext,\n {\n     if query.eval_always {\n-        let _ = get_query_impl(tcx, state, DUMMY_SP, key, query);\n-        return;\n+        return true;\n     }\n \n     // Ensuring an anonymous query makes no sense\n     assert!(!query.anon);\n \n-    let dep_node = query.to_dep_node(tcx, &key);\n+    let dep_node = query.to_dep_node(tcx, key);\n \n     match tcx.dep_graph().try_mark_green_and_read(tcx, &dep_node) {\n         None => {\n@@ -675,18 +686,20 @@ fn ensure_query_impl<CTX, C>(\n             // DepNodeIndex. We must invoke the query itself. The performance cost\n             // this introduces should be negligible as we'll immediately hit the\n             // in-memory cache, or another query down the line will.\n-            let _ = get_query_impl(tcx, state, DUMMY_SP, key, query);\n+            true\n         }\n         Some((_, dep_node_index)) => {\n             tcx.profiler().query_cache_hit(dep_node_index.into());\n+            false\n         }\n     }\n }\n \n #[inline(never)]\n fn force_query_impl<CTX, C>(\n     tcx: CTX,\n-    state: &QueryState<CTX::DepKind, CTX::Query, C>,\n+    state: &QueryState<CTX::DepKind, CTX::Query, C::Key>,\n+    cache: &QueryCacheStore<C>,\n     key: C::Key,\n     span: Span,\n     dep_node: DepNode<CTX::DepKind>,\n@@ -698,46 +711,60 @@ fn force_query_impl<CTX, C>(\n {\n     // We may be concurrently trying both execute and force a query.\n     // Ensure that only one of them runs the query.\n+    let cached = cache.cache.lookup(cache, &key, |_, index| {\n+        if unlikely!(tcx.profiler().enabled()) {\n+            tcx.profiler().query_cache_hit(index.into());\n+        }\n+        #[cfg(debug_assertions)]\n+        {\n+            cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n+        }\n+    });\n \n-    try_get_cached(\n-        tcx,\n-        state,\n-        key,\n-        |_, _| {\n-            // Cache hit, do nothing\n-        },\n-        |key, lookup| {\n-            let job = match JobOwner::<'_, CTX::DepKind, CTX::Query, C>::try_start(\n-                tcx, state, span, &key, lookup, query,\n-            ) {\n-                TryGetJob::NotYetStarted(job) => job,\n-                TryGetJob::Cycle(_) => return,\n-                #[cfg(parallel_compiler)]\n-                TryGetJob::JobCompleted(_) => return,\n-            };\n-            force_query_with_job(tcx, key, job, dep_node, query);\n-        },\n-    );\n-}\n+    let lookup = match cached {\n+        Ok(()) => return,\n+        Err(lookup) => lookup,\n+    };\n \n-pub fn get_query<Q, CTX>(tcx: CTX, span: Span, key: Q::Key) -> Q::Stored\n-where\n-    Q: QueryDescription<CTX>,\n-    Q::Key: crate::dep_graph::DepNodeParams<CTX>,\n-    CTX: QueryContext,\n-{\n-    debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n+    let job = match JobOwner::<'_, CTX::DepKind, CTX::Query, C>::try_start(\n+        tcx, state, cache, span, &key, lookup, query,\n+    ) {\n+        TryGetJob::NotYetStarted(job) => job,\n+        TryGetJob::Cycle(_) => return,\n+        #[cfg(parallel_compiler)]\n+        TryGetJob::JobCompleted(_) => return,\n+    };\n+    force_query_with_job(tcx, key, job, dep_node, query);\n+}\n \n-    get_query_impl(tcx, Q::query_state(tcx), span, key, &Q::VTABLE)\n+pub enum QueryMode {\n+    Get,\n+    Ensure,\n }\n \n-pub fn ensure_query<Q, CTX>(tcx: CTX, key: Q::Key)\n+pub fn get_query<Q, CTX>(\n+    tcx: CTX,\n+    span: Span,\n+    key: Q::Key,\n+    lookup: QueryLookup,\n+    mode: QueryMode,\n+) -> Option<Q::Stored>\n where\n     Q: QueryDescription<CTX>,\n     Q::Key: crate::dep_graph::DepNodeParams<CTX>,\n     CTX: QueryContext,\n {\n-    ensure_query_impl(tcx, Q::query_state(tcx), key, &Q::VTABLE)\n+    let query = &Q::VTABLE;\n+    if let QueryMode::Ensure = mode {\n+        if !ensure_must_run(tcx, &key, query) {\n+            return None;\n+        }\n+    }\n+\n+    debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n+    let value =\n+        get_query_impl(tcx, Q::query_state(tcx), Q::query_cache(tcx), span, key, lookup, query);\n+    Some(value)\n }\n \n pub fn force_query<Q, CTX>(tcx: CTX, key: Q::Key, span: Span, dep_node: DepNode<CTX::DepKind>)\n@@ -746,5 +773,5 @@ where\n     Q::Key: crate::dep_graph::DepNodeParams<CTX>,\n     CTX: QueryContext,\n {\n-    force_query_impl(tcx, Q::query_state(tcx), key, span, dep_node, &Q::VTABLE)\n+    force_query_impl(tcx, Q::query_state(tcx), Q::query_cache(tcx), key, span, dep_node, &Q::VTABLE)\n }"}]}