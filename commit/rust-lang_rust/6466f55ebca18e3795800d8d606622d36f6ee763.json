{"sha": "6466f55ebca18e3795800d8d606622d36f6ee763", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY0NjZmNTVlYmNhMThlMzc5NTgwMGQ4ZDYwNjYyMmQzNmY2ZWU3NjM=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-17T01:14:53Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-17T08:16:47Z"}, "message": "Give the `StringReader` a `sess: &ParseSess`.", "tree": {"sha": "e362e4ac8a4b0b17dc69f90e8159991887c3b80f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e362e4ac8a4b0b17dc69f90e8159991887c3b80f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6466f55ebca18e3795800d8d606622d36f6ee763", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6466f55ebca18e3795800d8d606622d36f6ee763", "html_url": "https://github.com/rust-lang/rust/commit/6466f55ebca18e3795800d8d606622d36f6ee763", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6466f55ebca18e3795800d8d606622d36f6ee763/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f2d14077439a3037941781b7b53ea4e9ef19f52c", "url": "https://api.github.com/repos/rust-lang/rust/commits/f2d14077439a3037941781b7b53ea4e9ef19f52c", "html_url": "https://github.com/rust-lang/rust/commit/f2d14077439a3037941781b7b53ea4e9ef19f52c"}], "stats": {"total": 156, "additions": 68, "deletions": 88}, "files": [{"sha": "c0818f052866ec9264f261e5ba79d9da237d5b7a", "filename": "src/librustc/hir/print.rs", "status": "modified", "additions": 5, "deletions": 8, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibrustc%2Fhir%2Fprint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibrustc%2Fhir%2Fprint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fprint.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -13,6 +13,7 @@ pub use self::AnnNode::*;\n use syntax::abi::Abi;\n use syntax::ast;\n use syntax::codemap::{CodeMap, Spanned};\n+use syntax::parse::ParseSess;\n use syntax::parse::lexer::comments;\n use syntax::print::pp::{self, break_offset, word, space, hardbreak};\n use syntax::print::pp::{Breaks, eof};\n@@ -21,7 +22,6 @@ use syntax::print::pprust::{self as ast_pp, PrintState};\n use syntax::ptr::P;\n use syntax::symbol::keywords;\n use syntax_pos::{self, BytePos};\n-use errors;\n \n use hir;\n use hir::{PatKind, RegionTyParamBound, TraitTyParamBound, TraitBoundModifier};\n@@ -116,16 +116,15 @@ pub const default_columns: usize = 78;\n /// it can scan the input text for comments and literals to\n /// copy forward.\n pub fn print_crate<'a>(cm: &'a CodeMap,\n-                       span_diagnostic: &errors::Handler,\n+                       sess: &ParseSess,\n                        krate: &hir::Crate,\n                        filename: String,\n                        input: &mut Read,\n                        out: Box<Write + 'a>,\n                        ann: &'a PpAnn,\n                        is_expanded: bool)\n                        -> io::Result<()> {\n-    let mut s = State::new_from_input(cm, span_diagnostic, filename, input,\n-                                      out, ann, is_expanded);\n+    let mut s = State::new_from_input(cm, sess, filename, input, out, ann, is_expanded);\n \n     // When printing the AST, we sometimes need to inject `#[no_std]` here.\n     // Since you can't compile the HIR, it's not necessary.\n@@ -137,16 +136,14 @@ pub fn print_crate<'a>(cm: &'a CodeMap,\n \n impl<'a> State<'a> {\n     pub fn new_from_input(cm: &'a CodeMap,\n-                          span_diagnostic: &errors::Handler,\n+                          sess: &ParseSess,\n                           filename: String,\n                           input: &mut Read,\n                           out: Box<Write + 'a>,\n                           ann: &'a PpAnn,\n                           is_expanded: bool)\n                           -> State<'a> {\n-        let (cmnts, lits) = comments::gather_comments_and_literals(span_diagnostic,\n-                                                                   filename,\n-                                                                   input);\n+        let (cmnts, lits) = comments::gather_comments_and_literals(sess, filename, input);\n \n         State::new(cm,\n                    out,"}, {"sha": "3c8a529bdaee875b980094ca3cacb6a9b6074123", "filename": "src/librustc_driver/pretty.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibrustc_driver%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibrustc_driver%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fpretty.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -838,7 +838,7 @@ pub fn print_after_parsing(sess: &Session,\n                 debug!(\"pretty printing source code {:?}\", s);\n                 let sess = annotation.sess();\n                 pprust::print_crate(sess.codemap(),\n-                                    sess.diagnostic(),\n+                                    &sess.parse_sess,\n                                     krate,\n                                     src_name.to_string(),\n                                     &mut rdr,\n@@ -896,7 +896,7 @@ pub fn print_after_hir_lowering<'tcx, 'a: 'tcx>(sess: &'a Session,\n                     debug!(\"pretty printing source code {:?}\", s);\n                     let sess = annotation.sess();\n                     pprust::print_crate(sess.codemap(),\n-                                        sess.diagnostic(),\n+                                        &sess.parse_sess,\n                                         krate,\n                                         src_name.to_string(),\n                                         &mut rdr,\n@@ -920,7 +920,7 @@ pub fn print_after_hir_lowering<'tcx, 'a: 'tcx>(sess: &'a Session,\n                     debug!(\"pretty printing source code {:?}\", s);\n                     let sess = annotation.sess();\n                     pprust_hir::print_crate(sess.codemap(),\n-                                            sess.diagnostic(),\n+                                            &sess.parse_sess,\n                                             krate,\n                                             src_name.to_string(),\n                                             &mut rdr,\n@@ -945,7 +945,7 @@ pub fn print_after_hir_lowering<'tcx, 'a: 'tcx>(sess: &'a Session,\n                     let sess = annotation.sess();\n                     let ast_map = annotation.ast_map().expect(\"--unpretty missing HIR map\");\n                     let mut pp_state = pprust_hir::State::new_from_input(sess.codemap(),\n-                                                                         sess.diagnostic(),\n+                                                                         &sess.parse_sess,\n                                                                          src_name.to_string(),\n                                                                          &mut rdr,\n                                                                          box out,"}, {"sha": "ebfea90527cd07f76bd52e9b28f7bedfe62fed44", "filename": "src/librustc_save_analysis/span_utils.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Fspan_utils.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -85,8 +85,7 @@ impl<'a> SpanUtils<'a> {\n         let filemap = self.sess\n                           .codemap()\n                           .new_filemap(String::from(\"<anon-dxr>\"), None, self.snippet(span));\n-        let s = self.sess;\n-        lexer::StringReader::new(s.diagnostic(), filemap)\n+        lexer::StringReader::new(&self.sess.parse_sess, filemap)\n     }\n \n     fn span_to_tts(&self, span: Span) -> Vec<TokenTree> {"}, {"sha": "4b9b6518b480076a9254990b060e81fd03c0e58b", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -648,7 +648,7 @@ fn string_to_tts(text: String, parse_sess: &ParseSess) -> Vec<TokenTree> {\n     let filemap = parse_sess.codemap()\n                             .new_filemap(String::from(\"<macro expansion>\"), None, text);\n \n-    let lexer = lexer::StringReader::new(&parse_sess.span_diagnostic, filemap);\n+    let lexer = lexer::StringReader::new(parse_sess, filemap);\n     let mut parser = Parser::new(parse_sess, Box::new(lexer), None, false);\n     panictry!(parser.parse_all_token_trees())\n }"}, {"sha": "8c94cf67bf6e6202e4837f2fa9c032c9f9573b3d", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -13,11 +13,10 @@ pub use self::CommentStyle::*;\n use ast;\n use codemap::CodeMap;\n use syntax_pos::{BytePos, CharPos, Pos};\n-use errors;\n use parse::lexer::is_block_doc_comment;\n use parse::lexer::{StringReader, TokenAndSpan};\n use parse::lexer::{is_pattern_whitespace, Reader};\n-use parse::lexer;\n+use parse::{lexer, ParseSess};\n use print::pprust;\n use str::char_at;\n \n@@ -346,16 +345,14 @@ pub struct Literal {\n \n // it appears this function is called only from pprust... that's\n // probably not a good thing.\n-pub fn gather_comments_and_literals(span_diagnostic: &errors::Handler,\n-                                    path: String,\n-                                    srdr: &mut Read)\n+pub fn gather_comments_and_literals(sess: &ParseSess, path: String, srdr: &mut Read)\n                                     -> (Vec<Comment>, Vec<Literal>) {\n     let mut src = Vec::new();\n     srdr.read_to_end(&mut src).unwrap();\n     let src = String::from_utf8(src).unwrap();\n     let cm = CodeMap::new();\n     let filemap = cm.new_filemap(path, None, src);\n-    let mut rdr = lexer::StringReader::new_raw(span_diagnostic, filemap);\n+    let mut rdr = lexer::StringReader::new_raw(sess, filemap);\n \n     let mut comments: Vec<Comment> = Vec::new();\n     let mut literals: Vec<Literal> = Vec::new();"}, {"sha": "f1cb81a4c7de5c7738f82974bcd4bd21113b99b5", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 45, "deletions": 47, "changes": 92, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -11,9 +11,9 @@\n use ast::{self, Ident};\n use syntax_pos::{self, BytePos, CharPos, Pos, Span};\n use codemap::CodeMap;\n-use errors::{FatalError, Handler, DiagnosticBuilder};\n+use errors::{FatalError, DiagnosticBuilder};\n use ext::tt::transcribe::tt_next_token;\n-use parse::token;\n+use parse::{token, ParseSess};\n use str::char_at;\n use symbol::{Symbol, keywords};\n use std_unicode::property::Pattern_White_Space;\n@@ -82,7 +82,7 @@ impl Default for TokenAndSpan {\n }\n \n pub struct StringReader<'a> {\n-    pub span_diagnostic: &'a Handler,\n+    pub sess: &'a ParseSess,\n     /// The absolute offset within the codemap of the next character to read\n     pub next_pos: BytePos,\n     /// The absolute offset within the codemap of the current character\n@@ -181,27 +181,22 @@ impl<'a> Reader for TtReader<'a> {\n \n impl<'a> StringReader<'a> {\n     /// For comments.rs, which hackily pokes into next_pos and ch\n-    pub fn new_raw<'b>(span_diagnostic: &'b Handler,\n-                       filemap: Rc<syntax_pos::FileMap>)\n-                       -> StringReader<'b> {\n-        let mut sr = StringReader::new_raw_internal(span_diagnostic, filemap);\n+    pub fn new_raw<'b>(sess: &'a ParseSess, filemap: Rc<syntax_pos::FileMap>) -> Self {\n+        let mut sr = StringReader::new_raw_internal(sess, filemap);\n         sr.bump();\n         sr\n     }\n \n-    fn new_raw_internal<'b>(span_diagnostic: &'b Handler,\n-                            filemap: Rc<syntax_pos::FileMap>)\n-                            -> StringReader<'b> {\n+    fn new_raw_internal(sess: &'a ParseSess, filemap: Rc<syntax_pos::FileMap>) -> Self {\n         if filemap.src.is_none() {\n-            span_diagnostic.bug(&format!(\"Cannot lex filemap \\\n-                                          without source: {}\",\n-                                         filemap.name)[..]);\n+            sess.span_diagnostic.bug(&format!(\"Cannot lex filemap without source: {}\",\n+                                              filemap.name));\n         }\n \n         let source_text = (*filemap.src.as_ref().unwrap()).clone();\n \n         StringReader {\n-            span_diagnostic: span_diagnostic,\n+            sess: sess,\n             next_pos: filemap.start_pos,\n             pos: filemap.start_pos,\n             col: CharPos(0),\n@@ -217,10 +212,8 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    pub fn new<'b>(span_diagnostic: &'b Handler,\n-                   filemap: Rc<syntax_pos::FileMap>)\n-                   -> StringReader<'b> {\n-        let mut sr = StringReader::new_raw(span_diagnostic, filemap);\n+    pub fn new(sess: &'a ParseSess, filemap: Rc<syntax_pos::FileMap>) -> Self {\n+        let mut sr = StringReader::new_raw(sess, filemap);\n         if let Err(_) = sr.advance_token() {\n             sr.emit_fatal_errors();\n             panic!(FatalError);\n@@ -234,12 +227,12 @@ impl<'a> StringReader<'a> {\n \n     /// Report a fatal lexical error with a given span.\n     pub fn fatal_span(&self, sp: Span, m: &str) -> FatalError {\n-        self.span_diagnostic.span_fatal(sp, m)\n+        self.sess.span_diagnostic.span_fatal(sp, m)\n     }\n \n     /// Report a lexical error with a given span.\n     pub fn err_span(&self, sp: Span, m: &str) {\n-        self.span_diagnostic.span_err(sp, m)\n+        self.sess.span_diagnostic.span_err(sp, m)\n     }\n \n \n@@ -274,7 +267,7 @@ impl<'a> StringReader<'a> {\n         for c in c.escape_default() {\n             m.push(c)\n         }\n-        self.span_diagnostic.struct_span_fatal(syntax_pos::mk_sp(from_pos, to_pos), &m[..])\n+        self.sess.span_diagnostic.struct_span_fatal(syntax_pos::mk_sp(from_pos, to_pos), &m[..])\n     }\n \n     /// Report a lexical error spanning [`from_pos`, `to_pos`), appending an\n@@ -298,7 +291,7 @@ impl<'a> StringReader<'a> {\n         for c in c.escape_default() {\n             m.push(c)\n         }\n-        self.span_diagnostic.struct_span_err(syntax_pos::mk_sp(from_pos, to_pos), &m[..])\n+        self.sess.span_diagnostic.struct_span_err(syntax_pos::mk_sp(from_pos, to_pos), &m[..])\n     }\n \n     /// Report a lexical error spanning [`from_pos`, `to_pos`), appending the\n@@ -503,9 +496,8 @@ impl<'a> StringReader<'a> {\n     fn scan_comment(&mut self) -> Option<TokenAndSpan> {\n         if let Some(c) = self.ch {\n             if c.is_whitespace() {\n-                self.span_diagnostic.span_err(syntax_pos::mk_sp(self.pos, self.pos),\n-                                              \"called consume_any_line_comment, but there \\\n-                                               was whitespace\");\n+                let msg = \"called consume_any_line_comment, but there was whitespace\";\n+                self.sess.span_diagnostic.span_err(syntax_pos::mk_sp(self.pos, self.pos), msg);\n             }\n         }\n \n@@ -875,7 +867,7 @@ impl<'a> StringReader<'a> {\n                                     self.scan_unicode_escape(delim) && !ascii_only\n                                 } else {\n                                     let span = syntax_pos::mk_sp(start, self.pos);\n-                                    self.span_diagnostic\n+                                    self.sess.span_diagnostic\n                                         .struct_span_err(span, \"incorrect unicode escape sequence\")\n                                         .span_help(span,\n                                                    \"format of unicode escape sequences is \\\n@@ -1701,35 +1693,41 @@ fn ident_continue(c: Option<char>) -> bool {\n mod tests {\n     use super::*;\n \n-    use ast::Ident;\n+    use ast::{Ident, CrateConfig};\n     use symbol::Symbol;\n     use syntax_pos::{BytePos, Span, NO_EXPANSION};\n     use codemap::CodeMap;\n     use errors;\n+    use feature_gate::UnstableFeatures;\n     use parse::token;\n+    use std::cell::RefCell;\n     use std::io;\n     use std::rc::Rc;\n \n-    fn mk_sh(cm: Rc<CodeMap>) -> errors::Handler {\n-        // FIXME (#22405): Replace `Box::new` with `box` here when/if possible.\n-        let emitter = errors::emitter::EmitterWriter::new(Box::new(io::sink()),\n-                                                Some(cm));\n-        errors::Handler::with_emitter(true, false, Box::new(emitter))\n+    fn mk_sess(cm: Rc<CodeMap>) -> ParseSess {\n+        let emitter = errors::emitter::EmitterWriter::new(Box::new(io::sink()), Some(cm.clone()));\n+        ParseSess {\n+            span_diagnostic: errors::Handler::with_emitter(true, false, Box::new(emitter)),\n+            unstable_features: UnstableFeatures::from_environment(),\n+            config: CrateConfig::new(),\n+            included_mod_stack: RefCell::new(Vec::new()),\n+            code_map: cm,\n+        }\n     }\n \n     // open a string reader for the given string\n     fn setup<'a>(cm: &CodeMap,\n-                 span_handler: &'a errors::Handler,\n+                 sess: &'a ParseSess,\n                  teststr: String)\n                  -> StringReader<'a> {\n         let fm = cm.new_filemap(\"zebra.rs\".to_string(), None, teststr);\n-        StringReader::new(span_handler, fm)\n+        StringReader::new(sess, fm)\n     }\n \n     #[test]\n     fn t1() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         let mut string_reader = setup(&cm,\n                                       &sh,\n                                       \"/* my source file */ fn main() { println!(\\\"zebra\\\"); }\\n\"\n@@ -1781,71 +1779,71 @@ mod tests {\n     #[test]\n     fn doublecolonparsing() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a b\".to_string()),\n                            vec![mk_ident(\"a\"), token::Whitespace, mk_ident(\"b\")]);\n     }\n \n     #[test]\n     fn dcparsing_2() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a::b\".to_string()),\n                            vec![mk_ident(\"a\"), token::ModSep, mk_ident(\"b\")]);\n     }\n \n     #[test]\n     fn dcparsing_3() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a ::b\".to_string()),\n                            vec![mk_ident(\"a\"), token::Whitespace, token::ModSep, mk_ident(\"b\")]);\n     }\n \n     #[test]\n     fn dcparsing_4() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a:: b\".to_string()),\n                            vec![mk_ident(\"a\"), token::ModSep, token::Whitespace, mk_ident(\"b\")]);\n     }\n \n     #[test]\n     fn character_a() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"'a'\".to_string()).next_token().tok,\n                    token::Literal(token::Char(Symbol::intern(\"a\")), None));\n     }\n \n     #[test]\n     fn character_space() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"' '\".to_string()).next_token().tok,\n                    token::Literal(token::Char(Symbol::intern(\" \")), None));\n     }\n \n     #[test]\n     fn character_escaped() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"'\\\\n'\".to_string()).next_token().tok,\n                    token::Literal(token::Char(Symbol::intern(\"\\\\n\")), None));\n     }\n \n     #[test]\n     fn lifetime_name() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"'abc\".to_string()).next_token().tok,\n                    token::Lifetime(Ident::from_str(\"'abc\")));\n     }\n \n     #[test]\n     fn raw_string() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string())\n                        .next_token()\n                        .tok,\n@@ -1855,7 +1853,7 @@ mod tests {\n     #[test]\n     fn literal_suffixes() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         macro_rules! test {\n             ($input: expr, $tok_type: ident, $tok_contents: expr) => {{\n                 assert_eq!(setup(&cm, &sh, format!(\"{}suffix\", $input)).next_token().tok,\n@@ -1899,7 +1897,7 @@ mod tests {\n     #[test]\n     fn nested_block_comments() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         let mut lexer = setup(&cm, &sh, \"/* /* */ */'a'\".to_string());\n         match lexer.next_token().tok {\n             token::Comment => {}\n@@ -1912,7 +1910,7 @@ mod tests {\n     #[test]\n     fn crlf_comments() {\n         let cm = Rc::new(CodeMap::new());\n-        let sh = mk_sh(cm.clone());\n+        let sh = mk_sess(cm.clone());\n         let mut lexer = setup(&cm, &sh, \"// test\\r\\n/// test\\r\\n\".to_string());\n         let comment = lexer.next_token();\n         assert_eq!(comment.tok, token::Comment);"}, {"sha": "6da3e5de75cdc98bc6e7c697b08787ec78daef92", "filename": "src/libsyntax/parse/lexer/unicode_chars.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -243,10 +243,8 @@ pub fn check_for_substitution<'a>(reader: &StringReader<'a>,\n                 err.span_help(span, &msg);\n             },\n             None => {\n-                reader\n-                .span_diagnostic\n-                .span_bug_no_panic(span,\n-                                   &format!(\"substitution character not found for '{}'\", ch));\n+                let msg = format!(\"substitution character not found for '{}'\", ch);\n+                reader.sess.span_diagnostic.span_bug_no_panic(span, &msg);\n             }\n         }\n     });"}, {"sha": "74b313ba395a3d595b9a881e0442be278622c4a2", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -223,7 +223,7 @@ pub fn filemap_to_tts(sess: &ParseSess, filemap: Rc<FileMap>)\n     -> Vec<tokenstream::TokenTree> {\n     // it appears to me that the cfg doesn't matter here... indeed,\n     // parsing tt's probably shouldn't require a parser at all.\n-    let srdr = lexer::StringReader::new(&sess.span_diagnostic, filemap);\n+    let srdr = lexer::StringReader::new(sess, filemap);\n     let mut p1 = Parser::new(sess, Box::new(srdr), None, false);\n     panictry!(p1.parse_all_token_trees())\n }"}, {"sha": "33b4636ce0899d8c6b5ad83f65ca57f1b9b2d2fd", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 6, "deletions": 15, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6466f55ebca18e3795800d8d606622d36f6ee763/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=6466f55ebca18e3795800d8d606622d36f6ee763", "patch": "@@ -18,10 +18,9 @@ use util::parser::AssocOp;\n use attr;\n use codemap::{self, CodeMap};\n use syntax_pos::{self, BytePos};\n-use errors;\n use parse::token::{self, BinOpToken, Token};\n use parse::lexer::comments;\n-use parse;\n+use parse::{self, ParseSess};\n use print::pp::{self, break_offset, word, space, zerobreak, hardbreak};\n use print::pp::{Breaks, eof};\n use print::pp::Breaks::{Consistent, Inconsistent};\n@@ -101,20 +100,15 @@ pub const DEFAULT_COLUMNS: usize = 78;\n /// it can scan the input text for comments and literals to\n /// copy forward.\n pub fn print_crate<'a>(cm: &'a CodeMap,\n-                       span_diagnostic: &errors::Handler,\n+                       sess: &ParseSess,\n                        krate: &ast::Crate,\n                        filename: String,\n                        input: &mut Read,\n                        out: Box<Write+'a>,\n                        ann: &'a PpAnn,\n                        is_expanded: bool) -> io::Result<()> {\n-    let mut s = State::new_from_input(cm,\n-                                      span_diagnostic,\n-                                      filename,\n-                                      input,\n-                                      out,\n-                                      ann,\n-                                      is_expanded);\n+    let mut s = State::new_from_input(cm, sess, filename, input, out, ann, is_expanded);\n+\n     if is_expanded && !std_inject::injected_crate_name(krate).is_none() {\n         // We need to print `#![no_std]` (and its feature gate) so that\n         // compiling pretty-printed source won't inject libstd again.\n@@ -140,16 +134,13 @@ pub fn print_crate<'a>(cm: &'a CodeMap,\n \n impl<'a> State<'a> {\n     pub fn new_from_input(cm: &'a CodeMap,\n-                          span_diagnostic: &errors::Handler,\n+                          sess: &ParseSess,\n                           filename: String,\n                           input: &mut Read,\n                           out: Box<Write+'a>,\n                           ann: &'a PpAnn,\n                           is_expanded: bool) -> State<'a> {\n-        let (cmnts, lits) = comments::gather_comments_and_literals(\n-            span_diagnostic,\n-            filename,\n-            input);\n+        let (cmnts, lits) = comments::gather_comments_and_literals(sess, filename, input);\n \n         State::new(\n             cm,"}]}