{"sha": "f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY2NjMwMGNjZDFlNmVmMDViNjMzY2RhMDZjODdmOTEzZDFjOTFhMWU=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-12T17:50:05Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-12T17:50:05Z"}, "message": "Remove skip Delimiter::None and handle Dollars", "tree": {"sha": "bfa2e896c1da845dd04e43bb0973a156a310bcd5", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bfa2e896c1da845dd04e43bb0973a156a310bcd5"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "html_url": "https://github.com/rust-lang/rust/commit/f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "74e846b9ecffd819af3109c50e48517b560b17cf", "url": "https://api.github.com/repos/rust-lang/rust/commits/74e846b9ecffd819af3109c50e48517b560b17cf", "html_url": "https://github.com/rust-lang/rust/commit/74e846b9ecffd819af3109c50e48517b560b17cf"}], "stats": {"total": 473, "additions": 255, "deletions": 218}, "files": [{"sha": "4126854d13a8a62cccf061a2ffcab27a29548f96", "filename": "crates/ra_mbe/src/lib.rs", "status": "modified", "additions": 55, "deletions": 2, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_mbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_mbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Flib.rs?ref=f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "patch": "@@ -39,7 +39,7 @@ pub enum ExpandError {\n     BindingError(String),\n }\n \n-pub use crate::syntax_bridge::{ast_to_token_tree, token_tree_to_ast_item_list};\n+pub use crate::syntax_bridge::{ast_to_token_tree, token_tree_to_ast_item_list, syntax_node_to_token_tree};\n \n /// This struct contains AST for a single `macro_rules` definition. What might\n /// be very confusing is that AST has almost exactly the same shape as\n@@ -192,6 +192,15 @@ impl_froms!(TokenTree: Leaf, Subtree);\n     pub(crate) fn assert_expansion(rules: &MacroRules, invocation: &str, expansion: &str) {\n         let expanded = expand(rules, invocation);\n         assert_eq!(expanded.to_string(), expansion);\n+\n+        let tree = token_tree_to_ast_item_list(&expanded);\n+\n+        // Eat all white space by parse it back and forth\n+        let expansion = ast::SourceFile::parse(expansion);\n+        let expansion = syntax_node_to_token_tree(expansion.syntax()).unwrap().0;\n+        let file = token_tree_to_ast_item_list(&expansion);\n+\n+        assert_eq!(tree.syntax().debug_dump().trim(), file.syntax().debug_dump().trim());\n     }\n \n     #[test]\n@@ -287,6 +296,36 @@ impl_froms!(TokenTree: Leaf, Subtree);\n         assert_expansion(&rules, \"foo! { Foo,# Bar }\", \"struct Foo ; struct Bar ;\");\n     }\n \n+    #[test]\n+    fn test_match_group_pattern_with_multiple_defs() {\n+        let rules = create_rules(\n+            r#\"\n+        macro_rules! foo {\n+            ($ ($ i:ident),*) => ( struct Bar { $ (\n+                fn $ i {}\n+            )*} );            \n+        }\n+\"#,\n+        );\n+\n+        assert_expansion(&rules, \"foo! { foo, bar }\", \"struct Bar {fn foo {} fn bar {}}\");\n+    }\n+\n+    #[test]\n+    fn test_match_group_pattern_with_multiple_statement() {\n+        let rules = create_rules(\n+            r#\"\n+        macro_rules! foo {\n+            ($ ($ i:ident),*) => ( fn baz { $ (\n+                $ i ();\n+            )*} );            \n+        }\n+\"#,\n+        );\n+\n+        assert_expansion(&rules, \"foo! { foo, bar }\", \"fn baz {foo () ; bar () ;}\");\n+    }\n+\n     #[test]\n     fn expand_to_item_list() {\n         let rules = create_rules(\n@@ -415,7 +454,7 @@ SOURCE_FILE@[0; 40)\n         assert_expansion(\n             &rules,\n             \"foo! { bar::<u8>::baz::<u8> }\",\n-            \"fn foo () {let a = bar ::< u8 > ::baz ::< u8 > ;}\",\n+            \"fn foo () {let a = bar :: < u8 > :: baz :: < u8 > ;}\",\n         );\n     }\n \n@@ -432,4 +471,18 @@ SOURCE_FILE@[0; 40)\n         );\n         assert_expansion(&rules, \"foo! { foo, bar }\", \"fn foo () {let a = foo ; let b = bar ;}\");\n     }\n+\n+    #[test]\n+    fn test_path_with_path() {\n+        let rules = create_rules(\n+            r#\"\n+        macro_rules! foo {\n+            ($ i:path) => {\n+                fn foo() { let a = $ i :: bar; }\n+            }\n+        }\n+\"#,\n+        );\n+        assert_expansion(&rules, \"foo! { foo }\", \"fn foo () {let a = foo :: bar ;}\");\n+    }\n }"}, {"sha": "164240d9295b543cfb282b93be9266266a043d4c", "filename": "crates/ra_mbe/src/subtree_parser.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_parser.rs?ref=f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "patch": "@@ -34,8 +34,7 @@ impl<'a> Parser<'a> {\n     where\n         F: FnOnce(&dyn TokenSource, &mut dyn TreeSink),\n     {\n-        let mut src = SubtreeTokenSource::new(self.subtree);\n-        src.start_from_nth(*self.cur_pos);\n+        let mut src = SubtreeTokenSource::new(&self.subtree.token_trees[*self.cur_pos..]);\n         let mut sink = OffsetTokenSink { token_pos: 0 };\n \n         f(&src, &mut sink);"}, {"sha": "6aa20057ec6879d59e4e489b5c6ccf5ec45ebb07", "filename": "crates/ra_mbe/src/subtree_source.rs", "status": "modified", "additions": 156, "deletions": 198, "changes": 354, "blob_url": "https://github.com/rust-lang/rust/blob/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs?ref=f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "patch": "@@ -2,6 +2,64 @@ use ra_parser::{TokenSource};\n use ra_syntax::{classify_literal, SmolStr, SyntaxKind, SyntaxKind::*};\n use std::cell::{RefCell};\n \n+// A Sequece of Token,\n+#[derive(Debug, Clone, Eq, PartialEq)]\n+pub(super) enum TokenSeq<'a> {\n+    Subtree(&'a tt::Subtree),\n+    Seq(&'a [tt::TokenTree]),\n+}\n+\n+impl<'a> From<&'a tt::Subtree> for TokenSeq<'a> {\n+    fn from(s: &'a tt::Subtree) -> TokenSeq<'a> {\n+        TokenSeq::Subtree(s)\n+    }\n+}\n+\n+impl<'a> From<&'a [tt::TokenTree]> for TokenSeq<'a> {\n+    fn from(s: &'a [tt::TokenTree]) -> TokenSeq<'a> {\n+        TokenSeq::Seq(s)\n+    }\n+}\n+\n+enum DelimToken<'a> {\n+    Delim(&'a tt::Delimiter, bool),\n+    Token(&'a tt::TokenTree),\n+    End,\n+}\n+\n+impl<'a> TokenSeq<'a> {\n+    fn get(&self, pos: usize) -> DelimToken<'a> {\n+        match self {\n+            TokenSeq::Subtree(subtree) => {\n+                let len = subtree.token_trees.len() + 2;\n+                match pos {\n+                    p if p >= len => DelimToken::End,\n+                    p if p == len - 1 => DelimToken::Delim(&subtree.delimiter, true),\n+                    0 => DelimToken::Delim(&subtree.delimiter, false),\n+                    p => DelimToken::Token(&subtree.token_trees[p - 1]),\n+                }\n+            }\n+            TokenSeq::Seq(tokens) => {\n+                tokens.get(pos).map(DelimToken::Token).unwrap_or(DelimToken::End)\n+            }\n+        }\n+    }\n+\n+    fn len(&self) -> usize {\n+        match self {\n+            TokenSeq::Subtree(subtree) => subtree.token_trees.len() + 2,\n+            TokenSeq::Seq(tokens) => tokens.len(),\n+        }\n+    }\n+\n+    fn child_slice(&self) -> &[tt::TokenTree] {\n+        match self {\n+            TokenSeq::Subtree(subtree) => &subtree.token_trees,\n+            TokenSeq::Seq(tokens) => &tokens,\n+        }\n+    }\n+}\n+\n #[derive(Debug, Clone, Eq, PartialEq)]\n struct TtToken {\n     pub kind: SyntaxKind,\n@@ -12,29 +70,27 @@ struct TtToken {\n \n #[derive(Debug, Clone, Eq, PartialEq)]\n enum WalkCursor {\n-    DelimiterBegin(Option<TtToken>),\n-    Token(usize, Option<TtToken>),\n-    DelimiterEnd(Option<TtToken>),\n+    Token(usize, TtToken),\n     Eof,\n }\n \n #[derive(Debug)]\n struct SubTreeWalker<'a> {\n     pos: usize,\n-    stack: Vec<(&'a tt::Subtree, Option<usize>)>,\n+    stack: Vec<(TokenSeq<'a>, usize)>,\n     cursor: WalkCursor,\n     last_steps: Vec<usize>,\n-    subtree: &'a tt::Subtree,\n+    ts: TokenSeq<'a>,\n }\n \n impl<'a> SubTreeWalker<'a> {\n-    fn new(subtree: &tt::Subtree) -> SubTreeWalker {\n+    fn new(ts: TokenSeq<'a>) -> SubTreeWalker {\n         let mut res = SubTreeWalker {\n             pos: 0,\n             stack: vec![],\n             cursor: WalkCursor::Eof,\n             last_steps: vec![],\n-            subtree,\n+            ts,\n         };\n \n         res.reset();\n@@ -47,209 +103,106 @@ impl<'a> SubTreeWalker<'a> {\n \n     fn reset(&mut self) {\n         self.pos = 0;\n-        self.stack = vec![(self.subtree, None)];\n-        self.cursor = WalkCursor::DelimiterBegin(convert_delim(self.subtree.delimiter, false));\n+        self.stack = vec![];\n         self.last_steps = vec![];\n \n-        while self.is_empty_delimiter() {\n-            self.forward_unchecked();\n-        }\n-    }\n-\n-    // This funciton will fast forward the cursor,\n-    // Such that backward will stop at `start_pos` point\n-    fn start_from_nth(&mut self, start_pos: usize) {\n-        self.reset();\n-        self.pos = start_pos;\n-        self.cursor = self.walk_token(start_pos, 0, false);\n-\n-        while self.is_empty_delimiter() {\n-            self.forward_unchecked();\n+        self.cursor = match self.ts.get(0) {\n+            DelimToken::Token(token) => match token {\n+                tt::TokenTree::Subtree(subtree) => {\n+                    WalkCursor::Token(0, convert_delim(subtree.delimiter, false))\n+                }\n+                tt::TokenTree::Leaf(leaf) => {\n+                    let next_tokens = self.ts.child_slice();\n+                    WalkCursor::Token(0, convert_leaf(&next_tokens, leaf))\n+                }\n+            },\n+            DelimToken::Delim(delim, is_end) => {\n+                assert!(!is_end);\n+                WalkCursor::Token(0, convert_delim(*delim, false))\n+            }\n+            DelimToken::End => WalkCursor::Eof,\n         }\n     }\n \n     fn current(&self) -> Option<&TtToken> {\n         match &self.cursor {\n-            WalkCursor::DelimiterBegin(t) => t.as_ref(),\n-            WalkCursor::Token(_, t) => t.as_ref(),\n-            WalkCursor::DelimiterEnd(t) => t.as_ref(),\n+            WalkCursor::Token(_, t) => Some(t),\n             WalkCursor::Eof => None,\n         }\n     }\n \n-    fn is_empty_delimiter(&self) -> bool {\n-        match &self.cursor {\n-            WalkCursor::DelimiterBegin(None) => true,\n-            WalkCursor::DelimiterEnd(None) => true,\n-            _ => false,\n-        }\n+    fn top(&self) -> &TokenSeq {\n+        self.stack.last().map(|(t, _)| t).unwrap_or(&self.ts)\n     }\n \n-    /// Move cursor backward by 1 step with empty checking\n+    /// Move cursor backward by 1 step\n     fn backward(&mut self) {\n         if self.last_steps.is_empty() {\n             return;\n         }\n+\n         self.pos -= 1;\n-        loop {\n-            self.backward_unchecked();\n-            // Skip Empty delimiter\n-            if self.last_steps.is_empty() || !self.is_empty_delimiter() {\n-                break;\n-            }\n-        }\n+        let last_step = self.last_steps.pop().unwrap();\n \n-        // Move forward if it is empty delimiter\n-        if self.last_steps.is_empty() {\n-            while self.is_empty_delimiter() {\n-                self.forward_unchecked();\n+        self.cursor = match self.cursor {\n+            WalkCursor::Token(idx, _) => self.walk_token(idx, last_step, true),\n+            WalkCursor::Eof => {\n+                let len = self.top().len();\n+                self.walk_token(len, last_step, true)\n             }\n         }\n     }\n \n-    /// Move cursor backward by 1 step without empty check\n-    ///\n-    /// Depends on the current state of cursor:\n-    ///\n-    /// * Delimiter Begin => Pop the stack, goto last walking token  (`walk_token`)\n-    /// * Token => Goto prev token  (`walk_token`)\n-    /// * Delimiter End => Goto the last child token (`walk_token`)\n-    /// * Eof => push the root subtree, and set it as Delimiter End\n-    fn backward_unchecked(&mut self) {\n-        if self.last_steps.is_empty() {\n-            return;\n-        }\n-\n-        let last_step = self.last_steps.pop().unwrap();\n-        let do_walk_token = match self.cursor {\n-            WalkCursor::DelimiterBegin(_) => None,\n-            WalkCursor::Token(u, _) => Some(u),\n-            WalkCursor::DelimiterEnd(_) => {\n-                let (top, _) = self.stack.last().unwrap();\n-                Some(top.token_trees.len())\n-            }\n-            WalkCursor::Eof => None,\n-        };\n-\n-        self.cursor = match do_walk_token {\n-            Some(u) => self.walk_token(u, last_step, true),\n-            None => match self.cursor {\n-                WalkCursor::Eof => {\n-                    self.stack.push((self.subtree, None));\n-                    WalkCursor::DelimiterEnd(convert_delim(\n-                        self.stack.last().unwrap().0.delimiter,\n-                        true,\n-                    ))\n-                }\n-                _ => {\n-                    let (_, last_top_cursor) = self.stack.pop().unwrap();\n-                    assert!(!self.stack.is_empty());\n-\n-                    self.walk_token(last_top_cursor.unwrap(), last_step, true)\n-                }\n-            },\n-        };\n-    }\n-\n-    /// Move cursor forward by 1 step with empty checking\n+    /// Move cursor forward by 1 step        \n     fn forward(&mut self) {\n         if self.is_eof() {\n             return;\n         }\n-\n         self.pos += 1;\n-        loop {\n-            self.forward_unchecked();\n-            if !self.is_empty_delimiter() {\n-                break;\n-            }\n-        }\n-    }\n-\n-    /// Move cursor forward by 1 step without empty checking\n-    ///\n-    /// Depends on the current state of cursor:\n-    ///\n-    /// * Delimiter Begin => Goto the first child token (`walk_token`)\n-    /// * Token => Goto next token  (`walk_token`)\n-    /// * Delimiter End => Pop the stack, goto last walking token  (`walk_token`)\n-    ///   \n-    fn forward_unchecked(&mut self) {\n-        if self.is_eof() {\n-            return;\n-        }\n \n         let step = self.current().map(|x| x.n_tokens).unwrap_or(1);\n         self.last_steps.push(step);\n \n-        let do_walk_token = match self.cursor {\n-            WalkCursor::DelimiterBegin(_) => Some((0, 0)),\n-            WalkCursor::Token(u, _) => Some((u, step)),\n-            WalkCursor::DelimiterEnd(_) => None,\n-            _ => unreachable!(),\n-        };\n-\n-        self.cursor = match do_walk_token {\n-            Some((u, step)) => self.walk_token(u, step, false),\n-            None => {\n-                let (_, last_top_idx) = self.stack.pop().unwrap();\n-                match self.stack.last() {\n-                    Some(_) => self.walk_token(last_top_idx.unwrap(), 1, false),\n-                    None => WalkCursor::Eof,\n-                }\n-            }\n-        };\n+        if let WalkCursor::Token(u, _) = self.cursor {\n+            self.cursor = self.walk_token(u, step, false)\n+        }\n     }\n \n     /// Traversal child token\n-    /// Depends on the new position, it returns:\n-    ///\n-    /// * new position < 0 => DelimiterBegin\n-    /// * new position > token_tree.len() => DelimiterEnd\n-    /// * if new position is a subtree, depends on traversal direction:\n-    /// ** backward => DelimiterEnd\n-    /// ** forward => DelimiterBegin\n-    /// * if new psoition is a leaf, return walk_leaf()\n     fn walk_token(&mut self, pos: usize, offset: usize, backward: bool) -> WalkCursor {\n-        let (top, _) = self.stack.last().unwrap();\n+        let top = self.stack.last().map(|(t, _)| t).unwrap_or(&self.ts);\n \n         if backward && pos < offset {\n-            return WalkCursor::DelimiterBegin(convert_delim(\n-                self.stack.last().unwrap().0.delimiter,\n-                false,\n-            ));\n-        }\n-\n-        if !backward && pos + offset >= top.token_trees.len() {\n-            return WalkCursor::DelimiterEnd(convert_delim(\n-                self.stack.last().unwrap().0.delimiter,\n-                true,\n-            ));\n+            let (_, last_idx) = self.stack.pop().unwrap();\n+            return self.walk_token(last_idx, offset, backward);\n         }\n \n         let pos = if backward { pos - offset } else { pos + offset };\n \n-        match &top.token_trees[pos] {\n-            tt::TokenTree::Subtree(subtree) => {\n-                self.stack.push((subtree, Some(pos)));\n-                let delim = convert_delim(self.stack.last().unwrap().0.delimiter, backward);\n-                if backward {\n-                    WalkCursor::DelimiterEnd(delim)\n-                } else {\n-                    WalkCursor::DelimiterBegin(delim)\n+        match top.get(pos) {\n+            DelimToken::Token(token) => match token {\n+                tt::TokenTree::Subtree(subtree) => {\n+                    let ts = TokenSeq::from(subtree);\n+                    let new_idx = if backward { ts.len() - 1 } else { 0 };\n+                    self.stack.push((ts, pos));\n+                    WalkCursor::Token(new_idx, convert_delim(subtree.delimiter, backward))\n+                }\n+                tt::TokenTree::Leaf(leaf) => {\n+                    let next_tokens = top.child_slice();\n+                    WalkCursor::Token(pos, convert_leaf(&next_tokens[pos..], leaf))\n                 }\n+            },\n+            DelimToken::Delim(delim, is_end) => {\n+                WalkCursor::Token(pos, convert_delim(*delim, is_end))\n             }\n-            tt::TokenTree::Leaf(leaf) => WalkCursor::Token(pos, Some(self.walk_leaf(leaf, pos))),\n-        }\n-    }\n-\n-    fn walk_leaf(&mut self, leaf: &tt::Leaf, pos: usize) -> TtToken {\n-        match leaf {\n-            tt::Leaf::Literal(l) => convert_literal(l),\n-            tt::Leaf::Ident(ident) => convert_ident(ident),\n-            tt::Leaf::Punct(punct) => {\n-                let (top, _) = self.stack.last().unwrap();\n-                convert_punct(punct, top, pos)\n+            DelimToken::End => {\n+                // it is the top level\n+                if let Some((_, last_idx)) = self.stack.pop() {\n+                    assert!(!backward);\n+                    self.walk_token(last_idx, offset, backward)\n+                } else {\n+                    WalkCursor::Eof\n+                }\n             }\n         }\n     }\n@@ -263,27 +216,20 @@ pub(crate) trait Querier {\n #[derive(Debug)]\n pub(crate) struct WalkerOwner<'a> {\n     walker: RefCell<SubTreeWalker<'a>>,\n-    offset: usize,\n }\n \n impl<'a> WalkerOwner<'a> {\n-    fn new(subtree: &'a tt::Subtree) -> Self {\n-        WalkerOwner { walker: RefCell::new(SubTreeWalker::new(subtree)), offset: 0 }\n+    fn new<I: Into<TokenSeq<'a>>>(ts: I) -> Self {\n+        WalkerOwner { walker: RefCell::new(SubTreeWalker::new(ts.into())) }\n     }\n \n     fn get<'b>(&self, pos: usize) -> Option<TtToken> {\n-        self.set_walker_pos(pos);\n+        self.set_pos(pos);\n         let walker = self.walker.borrow();\n         walker.current().cloned()\n     }\n \n-    fn start_from_nth(&mut self, pos: usize) {\n-        self.offset = pos;\n-        self.walker.borrow_mut().start_from_nth(pos);\n-    }\n-\n-    fn set_walker_pos(&self, mut pos: usize) {\n-        pos += self.offset;\n+    fn set_pos(&self, pos: usize) {\n         let mut walker = self.walker.borrow_mut();\n         while pos > walker.pos && !walker.is_eof() {\n             walker.forward();\n@@ -294,19 +240,26 @@ impl<'a> WalkerOwner<'a> {\n     }\n \n     fn collect_token_trees(&mut self, n: usize) -> Vec<&tt::TokenTree> {\n-        self.start_from_nth(self.offset);\n-\n         let mut res = vec![];\n         let mut walker = self.walker.borrow_mut();\n+        walker.reset();\n \n-        while walker.pos - self.offset < n {\n+        while walker.pos < n {\n             if let WalkCursor::Token(u, tt) = &walker.cursor {\n-                if walker.stack.len() == 1 {\n-                    // We only collect the topmost child\n-                    res.push(&walker.stack[0].0.token_trees[*u]);\n-                    if let Some(tt) = tt {\n-                        for i in 0..tt.n_tokens - 1 {\n-                            res.push(&walker.stack[0].0.token_trees[u + i]);\n+                // We only collect the topmost child\n+                if walker.stack.len() == 0 {\n+                    for i in 0..tt.n_tokens {\n+                        if let DelimToken::Token(token) = walker.ts.get(u + i) {\n+                            res.push(token);\n+                        }\n+                    }\n+                } else if walker.stack.len() == 1 {\n+                    if let DelimToken::Delim(_, is_end) = walker.ts.get(*u) {\n+                        if !is_end {\n+                            let (_, last_idx) = &walker.stack[0];\n+                            if let DelimToken::Token(token) = walker.ts.get(*last_idx) {\n+                                res.push(token);\n+                            }\n                         }\n                     }\n                 }\n@@ -331,12 +284,8 @@ pub(crate) struct SubtreeTokenSource<'a> {\n }\n \n impl<'a> SubtreeTokenSource<'a> {\n-    pub fn new(subtree: &tt::Subtree) -> SubtreeTokenSource {\n-        SubtreeTokenSource { walker: WalkerOwner::new(subtree) }\n-    }\n-\n-    pub fn start_from_nth(&mut self, n: usize) {\n-        self.walker.start_from_nth(n);\n+    pub fn new<I: Into<TokenSeq<'a>>>(ts: I) -> SubtreeTokenSource<'a> {\n+        SubtreeTokenSource { walker: WalkerOwner::new(ts) }\n     }\n \n     pub fn querier<'b>(&'a self) -> &'b WalkerOwner<'a>\n@@ -467,18 +416,18 @@ where\n     None\n }\n \n-fn convert_delim(d: tt::Delimiter, closing: bool) -> Option<TtToken> {\n+fn convert_delim(d: tt::Delimiter, closing: bool) -> TtToken {\n     let (kinds, texts) = match d {\n         tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n         tt::Delimiter::Brace => ([L_CURLY, R_CURLY], \"{}\"),\n         tt::Delimiter::Bracket => ([L_BRACK, R_BRACK], \"[]\"),\n-        tt::Delimiter::None => return None,\n+        tt::Delimiter::None => ([L_DOLLAR, R_DOLLAR], \"\"),\n     };\n \n     let idx = closing as usize;\n     let kind = kinds[idx];\n-    let text = &texts[idx..texts.len() - (1 - idx)];\n-    Some(TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 })\n+    let text = if texts.len() > 0 { &texts[idx..texts.len() - (1 - idx)] } else { \"\" };\n+    TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 }\n }\n \n fn convert_literal(l: &tt::Literal) -> TtToken {\n@@ -495,8 +444,9 @@ fn convert_ident(ident: &tt::Ident) -> TtToken {\n     TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n }\n \n-fn convert_punct(p: &tt::Punct, parent: &tt::Subtree, next: usize) -> TtToken {\n-    let iter = parent.token_trees[next + 1..].iter();\n+fn convert_punct(p: &tt::Punct, next_tokens: &[tt::TokenTree]) -> TtToken {\n+    let mut iter = next_tokens.iter();\n+    iter.next();\n     let mut peek = TokenPeek::new(iter);\n \n     if let Some((kind, is_joint_to_next, text, size)) = convert_multi_char_punct(p, &mut peek) {\n@@ -519,3 +469,11 @@ fn convert_punct(p: &tt::Punct, parent: &tt::Subtree, next: usize) -> TtToken {\n         TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text, n_tokens: 1 }\n     }\n }\n+\n+fn convert_leaf(tokens: &[tt::TokenTree], leaf: &tt::Leaf) -> TtToken {\n+    match leaf {\n+        tt::Leaf::Literal(l) => convert_literal(l),\n+        tt::Leaf::Ident(ident) => convert_ident(ident),\n+        tt::Leaf::Punct(punct) => convert_punct(punct, tokens),\n+    }\n+}"}, {"sha": "28ded7870e1309c64696ac19e5c9eaa9ad829d3f", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 31, "deletions": 16, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "patch": "@@ -22,6 +22,14 @@ pub fn ast_to_token_tree(ast: &ast::TokenTree) -> Option<(tt::Subtree, TokenMap)\n     Some((tt, token_map))\n }\n \n+/// Convert the syntax node to a `TokenTree` (what macro\n+/// will consume).\n+pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> Option<(tt::Subtree, TokenMap)> {\n+    let mut token_map = TokenMap::default();\n+    let tt = convert_tt(&mut token_map, node.range().start(), node)?;\n+    Some((tt, token_map))\n+}\n+\n /// Parses the token tree (result of macro expansion) as a sequence of items\n pub fn token_tree_to_ast_item_list(tt: &tt::Subtree) -> TreeArc<ast::SourceFile> {\n     let token_source = SubtreeTokenSource::new(tt);\n@@ -51,15 +59,17 @@ fn convert_tt(\n ) -> Option<tt::Subtree> {\n     let first_child = tt.first_child_or_token()?;\n     let last_child = tt.last_child_or_token()?;\n-    let delimiter = match (first_child.kind(), last_child.kind()) {\n-        (L_PAREN, R_PAREN) => tt::Delimiter::Parenthesis,\n-        (L_CURLY, R_CURLY) => tt::Delimiter::Brace,\n-        (L_BRACK, R_BRACK) => tt::Delimiter::Bracket,\n-        _ => return None,\n+    let (delimiter, skip_first) = match (first_child.kind(), last_child.kind()) {\n+        (L_PAREN, R_PAREN) => (tt::Delimiter::Parenthesis, true),\n+        (L_CURLY, R_CURLY) => (tt::Delimiter::Brace, true),\n+        (L_BRACK, R_BRACK) => (tt::Delimiter::Bracket, true),\n+        _ => (tt::Delimiter::None, false),\n     };\n+\n     let mut token_trees = Vec::new();\n-    for child in tt.children_with_tokens().skip(1) {\n-        if child == first_child || child == last_child || child.kind().is_trivia() {\n+    for child in tt.children_with_tokens().skip(skip_first as usize) {\n+        if (skip_first && (child == first_child || child == last_child)) || child.kind().is_trivia()\n+        {\n             continue;\n         }\n         match child {\n@@ -127,6 +137,11 @@ impl<'a, Q: Querier> TtTreeSink<'a, Q> {\n \n impl<'a, Q: Querier> TreeSink for TtTreeSink<'a, Q> {\n     fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {\n+        if kind == L_DOLLAR || kind == R_DOLLAR {\n+            self.token_pos += n_tokens as usize;\n+            return;\n+        }\n+\n         for _ in 0..n_tokens {\n             self.buf += &self.src_querier.token(self.token_pos).1;\n             self.token_pos += 1;\n@@ -176,19 +191,19 @@ mod tests {\n \n         let query = tt_src.querier();\n \n-        // [{]\n+        // [${]\n         // [let] [a] [=] ['c'] [;]\n-        assert_eq!(query.token(1 + 3).1, \"'c'\");\n-        assert_eq!(query.token(1 + 3).0, CHAR);\n+        assert_eq!(query.token(2 + 3).1, \"'c'\");\n+        assert_eq!(query.token(2 + 3).0, CHAR);\n         // [let] [c] [=] [1000] [;]\n-        assert_eq!(query.token(1 + 5 + 3).1, \"1000\");\n-        assert_eq!(query.token(1 + 5 + 3).0, INT_NUMBER);\n+        assert_eq!(query.token(2 + 5 + 3).1, \"1000\");\n+        assert_eq!(query.token(2 + 5 + 3).0, INT_NUMBER);\n         // [let] [f] [=] [12E+99_f64] [;]\n-        assert_eq!(query.token(1 + 10 + 3).1, \"12E+99_f64\");\n-        assert_eq!(query.token(1 + 10 + 3).0, FLOAT_NUMBER);\n+        assert_eq!(query.token(2 + 10 + 3).1, \"12E+99_f64\");\n+        assert_eq!(query.token(2 + 10 + 3).0, FLOAT_NUMBER);\n \n         // [let] [s] [=] [\"rust1\"] [;]\n-        assert_eq!(query.token(1 + 15 + 3).1, \"\\\"rust1\\\"\");\n-        assert_eq!(query.token(1 + 15 + 3).0, STRING);\n+        assert_eq!(query.token(2 + 15 + 3).1, \"\\\"rust1\\\"\");\n+        assert_eq!(query.token(2 + 15 + 3).0, STRING);\n     }\n }"}, {"sha": "3cb57ed9ceacc05c5b22fcc405b1209e48e6a508", "filename": "crates/ra_parser/src/parser.rs", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_parser%2Fsrc%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f66300ccd1e6ef05b633cda06c87f913d1c91a1e/crates%2Fra_parser%2Fsrc%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_parser%2Fsrc%2Fparser.rs?ref=f66300ccd1e6ef05b633cda06c87f913d1c91a1e", "patch": "@@ -99,6 +99,8 @@ impl<'t> Parser<'t> {\n     /// consumed between the `start` and the corresponding `Marker::complete`\n     /// belong to the same node.\n     pub(crate) fn start(&mut self) -> Marker {\n+        self.eat_dollars();\n+\n         let pos = self.events.len() as u32;\n         self.push_event(Event::tombstone());\n         Marker::new(pos)\n@@ -180,13 +182,23 @@ impl<'t> Parser<'t> {\n     }\n \n     fn do_bump(&mut self, kind: SyntaxKind, n_raw_tokens: u8) {\n+        self.eat_dollars();\n         self.token_pos += usize::from(n_raw_tokens);\n         self.push_event(Event::Token { kind, n_raw_tokens });\n+        self.eat_dollars();\n     }\n \n     fn push_event(&mut self, event: Event) {\n         self.events.push(event)\n     }\n+\n+    fn eat_dollars(&mut self) {\n+        while self.nth(0) == SyntaxKind::L_DOLLAR || self.nth(0) == SyntaxKind::R_DOLLAR {\n+            let kind = self.nth(0);\n+            self.token_pos += 1;\n+            self.push_event(Event::Token { kind, n_raw_tokens: 1 });\n+        }\n+    }\n }\n \n /// See `Parser::start`."}]}