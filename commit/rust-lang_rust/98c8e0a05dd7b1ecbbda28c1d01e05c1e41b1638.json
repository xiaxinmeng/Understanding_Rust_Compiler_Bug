{"sha": "98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk4YzhlMGEwNWRkN2IxZWNiYmRhMjhjMWQwMWUwNWMxZTQxYjE2Mzg=", "commit": {"author": {"name": "cgswords", "email": "cameronswords@gmail.com", "date": "2016-08-04T19:20:01Z"}, "committer": {"name": "cgswords", "email": "cameronswords@gmail.com", "date": "2016-08-16T20:17:36Z"}, "message": "Proc_macro is alive", "tree": {"sha": "829168f08c68bcb796a37ef886e81a32f5c4e236", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/829168f08c68bcb796a37ef886e81a32f5c4e236"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "html_url": "https://github.com/rust-lang/rust/commit/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/comments", "author": {"login": "cgswords", "id": 1130991, "node_id": "MDQ6VXNlcjExMzA5OTE=", "avatar_url": "https://avatars.githubusercontent.com/u/1130991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgswords", "html_url": "https://github.com/cgswords", "followers_url": "https://api.github.com/users/cgswords/followers", "following_url": "https://api.github.com/users/cgswords/following{/other_user}", "gists_url": "https://api.github.com/users/cgswords/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgswords/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgswords/subscriptions", "organizations_url": "https://api.github.com/users/cgswords/orgs", "repos_url": "https://api.github.com/users/cgswords/repos", "events_url": "https://api.github.com/users/cgswords/events{/privacy}", "received_events_url": "https://api.github.com/users/cgswords/received_events", "type": "User", "site_admin": false}, "committer": {"login": "cgswords", "id": 1130991, "node_id": "MDQ6VXNlcjExMzA5OTE=", "avatar_url": "https://avatars.githubusercontent.com/u/1130991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgswords", "html_url": "https://github.com/cgswords", "followers_url": "https://api.github.com/users/cgswords/followers", "following_url": "https://api.github.com/users/cgswords/following{/other_user}", "gists_url": "https://api.github.com/users/cgswords/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgswords/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgswords/subscriptions", "organizations_url": "https://api.github.com/users/cgswords/orgs", "repos_url": "https://api.github.com/users/cgswords/repos", "events_url": "https://api.github.com/users/cgswords/events{/privacy}", "received_events_url": "https://api.github.com/users/cgswords/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "32e462ef99e2f61b75e2b0ef37048d50ad8ccf6c", "url": "https://api.github.com/repos/rust-lang/rust/commits/32e462ef99e2f61b75e2b0ef37048d50ad8ccf6c", "html_url": "https://github.com/rust-lang/rust/commit/32e462ef99e2f61b75e2b0ef37048d50ad8ccf6c"}], "stats": {"total": 1234, "additions": 1230, "deletions": 4}, "files": [{"sha": "5ff6d7a89dbe0a4bdb2e91f8aa1684c08ac8305b", "filename": "mk/crates.mk", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/mk%2Fcrates.mk", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/mk%2Fcrates.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fcrates.mk?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -60,7 +60,7 @@ RUSTC_CRATES := rustc rustc_typeck rustc_mir rustc_borrowck rustc_resolve rustc_\n                 rustc_data_structures rustc_platform_intrinsics rustc_errors \\\n                 rustc_plugin rustc_metadata rustc_passes rustc_save_analysis \\\n                 rustc_const_eval rustc_const_math rustc_incremental\n-HOST_CRATES := syntax syntax_ext syntax_pos $(RUSTC_CRATES) rustdoc fmt_macros \\\n+HOST_CRATES := syntax syntax_ext proc_macro syntax_pos $(RUSTC_CRATES) rustdoc fmt_macros \\\n \t\tflate arena graphviz rbml log serialize\n TOOLS := compiletest rustdoc rustc rustbook error_index_generator\n \n@@ -100,6 +100,7 @@ DEPS_test := std getopts term native:rust_test_helpers\n \n DEPS_syntax := std term serialize log arena libc rustc_bitflags rustc_unicode rustc_errors syntax_pos\n DEPS_syntax_ext := syntax syntax_pos rustc_errors fmt_macros\n+DEPS_proc_macro := syntax syntax_pos rustc_plugin log\n DEPS_syntax_pos := serialize\n \n DEPS_rustc_const_math := std syntax log serialize\n@@ -114,8 +115,9 @@ DEPS_rustc_borrowck := rustc log graphviz syntax syntax_pos rustc_errors rustc_m\n DEPS_rustc_data_structures := std log serialize\n DEPS_rustc_driver := arena flate getopts graphviz libc rustc rustc_back rustc_borrowck \\\n                      rustc_typeck rustc_mir rustc_resolve log syntax serialize rustc_llvm \\\n-\t             rustc_trans rustc_privacy rustc_lint rustc_plugin \\\n-                     rustc_metadata syntax_ext rustc_passes rustc_save_analysis rustc_const_eval \\\n+                     rustc_trans rustc_privacy rustc_lint rustc_plugin \\\n+                     rustc_metadata syntax_ext proc_macro \\\n+                     rustc_passes rustc_save_analysis rustc_const_eval \\\n                      rustc_incremental syntax_pos rustc_errors\n DEPS_rustc_errors := log libc serialize syntax_pos\n DEPS_rustc_lint := rustc log syntax syntax_pos rustc_const_eval"}, {"sha": "99fb1d65cda909624aadce2094c1ec7fffc78d09", "filename": "src/libproc_macro/Cargo.toml", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2FCargo.toml?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,15 @@\n+[package]\n+authors = [\"The Rust Project Developers\"]\n+name = \"proc_macro\"\n+version = \"0.0.0\"\n+\n+[lib]\n+name = \"proc_macro\"\n+path = \"lib.rs\"\n+crate-type = [\"dylib\"]\n+\n+[dependencies]\n+log = { path = \"../liblog\" }\n+rustc_plugin = { path = \"../librustc_plugin\" }\n+syntax = { path = \"../libsyntax\" }\n+syntax_pos = { path = \"../libsyntax_pos\" }"}, {"sha": "7b7590b863b71aa5e5eba1e63d13a5f707dea352", "filename": "src/libproc_macro/build.rs", "status": "added", "additions": 89, "deletions": 0, "changes": 89, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fbuild.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,89 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+extern crate syntax;\n+extern crate syntax_pos;\n+\n+use syntax::ast::Ident;\n+use syntax::codemap::DUMMY_SP;\n+use syntax::parse::token::{self, Token, keywords, str_to_ident};\n+use syntax::tokenstream::{self, TokenTree, TokenStream};\n+use std::rc::Rc;\n+\n+/// A wrapper around `TokenStream::concat` to avoid extra namespace specification and\n+/// provide TokenStream concatenation as a generic operator.\n+pub fn concat(ts1: TokenStream, ts2: TokenStream) -> TokenStream {\n+    TokenStream::concat(ts1, ts2)\n+}\n+\n+/// Checks if two identifiers have the same name, disregarding context. This allows us to\n+/// fake 'reserved' keywords.\n+// FIXME We really want `free-identifier-=?` (a la Dybvig 1993). von Tander 2007 is\n+// probably the easiest way to do that.\n+pub fn ident_eq(tident: &TokenTree, id: Ident) -> bool {\n+    let tid = match *tident {\n+        TokenTree::Token(_, Token::Ident(ref id)) => id,\n+        _ => {\n+            return false;\n+        }\n+    };\n+\n+    tid.name == id.name\n+}\n+\n+// ____________________________________________________________________________________________\n+// Conversion operators\n+\n+/// Convert a `&str` into a Token.\n+pub fn str_to_token_ident(s: &str) -> Token {\n+    Token::Ident(str_to_ident(s))\n+}\n+\n+/// Converts a keyword (from `syntax::parse::token::keywords`) into a Token that\n+/// corresponds to it.\n+pub fn keyword_to_token_ident(kw: keywords::Keyword) -> Token {\n+    Token::Ident(str_to_ident(&kw.name().as_str()[..]))\n+}\n+\n+// ____________________________________________________________________________________________\n+// Build Procedures\n+\n+/// Generically takes a `ts` and delimiter and returns `ts` delimited by the specified\n+/// delimiter.\n+pub fn build_delimited(ts: TokenStream, delim: token::DelimToken) -> TokenStream {\n+    let tts = ts.to_tts();\n+    TokenStream::from_tts(vec![TokenTree::Delimited(DUMMY_SP,\n+                                                    Rc::new(tokenstream::Delimited {\n+                                                        delim: delim,\n+                                                        open_span: DUMMY_SP,\n+                                                        tts: tts,\n+                                                        close_span: DUMMY_SP,\n+                                                    }))])\n+}\n+\n+/// Takes `ts` and returns `[ts]`.\n+pub fn build_bracket_delimited(ts: TokenStream) -> TokenStream {\n+    build_delimited(ts, token::DelimToken::Bracket)\n+}\n+\n+/// Takes `ts` and returns `{ts}`.\n+pub fn build_brace_delimited(ts: TokenStream) -> TokenStream {\n+    build_delimited(ts, token::DelimToken::Brace)\n+}\n+\n+/// Takes `ts` and returns `(ts)`.\n+pub fn build_paren_delimited(ts: TokenStream) -> TokenStream {\n+    build_delimited(ts, token::DelimToken::Paren)\n+}\n+\n+/// Constructs `()`.\n+pub fn build_empty_args() -> TokenStream {\n+    build_paren_delimited(TokenStream::mk_empty())\n+}"}, {"sha": "9e25cb88e015c8200407ed03c5e53d02566aee06", "filename": "src/libproc_macro/lib.rs", "status": "added", "additions": 137, "deletions": 0, "changes": 137, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,137 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! # Proc_Macro\n+//!\n+//! A library for procedural macro writers.\n+//!\n+//! ## Usage\n+//! This package provides the `qquote!` macro for syntax creation, and the prelude\n+//! (at libproc_macro::prelude) provides a number of operations:\n+//! - `concat`, for concatenating two TokenStreams.\n+//! - `ident_eq`, for checking if two identifiers are equal regardless of syntax context.\n+//! - `str_to_token_ident`, for converting an `&str` into a Token.\n+//! - `keyword_to_token_delim`, for converting a `parse::token::keywords::Keyword` into a\n+//!    Token.\n+//! - `build_delimited`, for creating a new TokenStream from an existing one and a delimiter\n+//!    by wrapping the TokenStream in the delimiter.\n+//! - `build_bracket_delimited`, `build_brace_delimited`, and `build_paren_delimited`, for\n+//!    easing the above.\n+//! - `build_empty_args`, which returns a TokenStream containing `()`.\n+//! - `lex`, which takes an `&str` and returns the TokenStream it represents.\n+//!\n+//! The `qquote!` macro also imports `syntax::ext::proc_macro_shim::prelude::*`, so you\n+//! will need to `extern crate syntax` for usage. (This is a temporary solution until more\n+//! of the external API in libproc_macro is stabilized to support the token construction\n+//! operations that the qausiquoter relies on.) The shim file also provides additional\n+//! operations, such as `build_block_emitter` (as used in the `cond` example below).\n+//!\n+//! ## TokenStreams\n+//!\n+//! TokenStreams serve as the basis of the macro system. They are, in essence, vectors of\n+//! TokenTrees, where indexing treats delimited values as a single term. That is, the term\n+//! `even(a+c) && even(b)` will be indexibly encoded as `even | (a+c) | even | (b)` where,\n+//! in reality, `(a+c)` is actually a decorated pointer to `a | + | c`.\n+//!\n+//! If a user has a TokenStream that is a single, delimited value, they can use\n+//! `maybe_delimited` to destruct it and receive the internal vector as a new TokenStream\n+//! as:\n+//! ```\n+//! `(a+c)`.maybe_delimited() ~> Some(a | + | c)`\n+//! ```\n+//!\n+//! Check the TokenStream documentation for more information; the structure also provides\n+//! cheap concatenation and slicing.\n+//!\n+//! ## Quasiquotation\n+//!\n+//! The quasiquoter creates output that, when run, constructs the tokenstream specified as\n+//! input. For example, `qquote!(5 + 5)` will produce a program, that, when run, will\n+//! construct the TokenStream `5 | + | 5`.\n+//!\n+//! ### Unquoting\n+//!\n+//! Unquoting is currently done as `unquote`, and works by taking the single next\n+//! TokenTree in the TokenStream as the unquoted term. Ergonomically, `unquote(foo)` works\n+//! fine, but `unquote foo` is also supported.\n+//!\n+//! A simple example might be:\n+//!\n+//!```\n+//!fn double(tmp: TokenStream) -> TokenStream {\n+//!    qquote!(unquote(tmp) * 2)\n+//!}\n+//!```\n+//!\n+//! ### Large Example: Implementing Scheme's `cond`\n+//!\n+//! Below is the full implementation of Scheme's `cond` operator.\n+//!\n+//! ```\n+//! fn cond_rec(input: TokenStream) -> TokenStream {\n+//!   if input.is_empty() { return quote!(); }\n+//!\n+//!   let next = input.slice(0..1);\n+//!   let rest = input.slice_from(1..);\n+//!\n+//!   let clause : TokenStream = match next.maybe_delimited() {\n+//!     Some(ts) => ts,\n+//!     _ => panic!(\"Invalid input\"),\n+//!   };\n+//!\n+//!   // clause is ([test]) [rhs]\n+//!   if clause.len() < 2 { panic!(\"Invalid macro usage in cond: {:?}\", clause) }\n+//!\n+//!   let test: TokenStream = clause.slice(0..1);\n+//!   let rhs: TokenStream = clause.slice_from(1..);\n+//!\n+//!   if ident_eq(&test[0], str_to_ident(\"else\")) || rest.is_empty() {\n+//!     quote!({unquote(rhs)})\n+//!   } else {\n+//!     quote!({if unquote(test) { unquote(rhs) } else { cond!(unquote(rest)) } })\n+//!   }\n+//! }\n+//! ```\n+//!\n+\n+#![crate_name = \"proc_macro\"]\n+#![unstable(feature = \"rustc_private\", issue = \"27812\")]\n+#![feature(plugin_registrar)]\n+#![crate_type = \"dylib\"]\n+#![crate_type = \"rlib\"]\n+#![doc(html_logo_url = \"https://www.rust-lang.org/logos/rust-logo-128x128-blk-v2.png\",\n+       html_favicon_url = \"https://doc.rust-lang.org/favicon.ico\",\n+       html_root_url = \"https://doc.rust-lang.org/nightly/\")]\n+#![cfg_attr(not(stage0), deny(warnings))]\n+\n+#![feature(staged_api)]\n+#![feature(rustc_diagnostic_macros)]\n+#![feature(rustc_private)]\n+\n+extern crate rustc_plugin;\n+extern crate syntax;\n+extern crate syntax_pos;\n+#[macro_use] extern crate log;\n+\n+mod qquote;\n+pub mod build;\n+pub mod parse;\n+pub mod prelude;\n+use qquote::qquote;\n+\n+use rustc_plugin::Registry;\n+\n+// ____________________________________________________________________________________________\n+// Main macro definition\n+\n+#[plugin_registrar]\n+pub fn plugin_registrar(reg: &mut Registry) {\n+    reg.register_macro(\"qquote\", qquote);\n+}"}, {"sha": "9af8a68cdcf497887b75e09a94f5917215d33bee", "filename": "src/libproc_macro/parse.rs", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Fparse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Fparse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fparse.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,26 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! Parsing utilities for writing procedural macros.\n+\n+extern crate syntax;\n+\n+use syntax::parse::{ParseSess, filemap_to_tts};\n+use syntax::tokenstream::TokenStream;\n+\n+/// Map a string to tts, using a made-up filename. For example, `lex(15)` will return a\n+/// TokenStream containing the literal 15.\n+pub fn lex(source_str: &str) -> TokenStream {\n+    let ps = ParseSess::new();\n+    TokenStream::from_tts(filemap_to_tts(&ps,\n+                                         ps.codemap().new_filemap(\"procmacro_lex\".to_string(),\n+                                                                  None,\n+                                                                  source_str.to_owned())))\n+}"}, {"sha": "4c0c8ba6c6684b1c375236a4e13fefa2a5cbcfab", "filename": "src/libproc_macro/prelude.rs", "status": "added", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Fprelude.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Fprelude.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fprelude.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,12 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+pub use build::*;\n+pub use parse::*;"}, {"sha": "67d0c77b00d83c6404df847ae57b1c6ff5b9d6c3", "filename": "src/libproc_macro/qquote.rs", "status": "added", "additions": 470, "deletions": 0, "changes": 470, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Fqquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibproc_macro%2Fqquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fqquote.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,470 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! # Quasiquoter\n+//! This file contains the implementation internals of the quasiquoter provided by `quote!`.\n+//!\n+//! ## Ouput\n+//! The quasiquoter produces output of the form:\n+//! let tmp0 = ...;\n+//! let tmp1 = ...;\n+//! ...\n+//! concat(from_tokens(...), concat(...))\n+//!\n+//! To the more explicit, the quasiquoter produces a series of bindings that each\n+//! construct TokenStreams via constructing Tokens and using `from_tokens`, ultimately\n+//! invoking `concat` on these bindings (and inlined expressions) to construct a\n+//! TokenStream that resembles the output syntax.\n+//!\n+\n+extern crate rustc_plugin;\n+extern crate syntax;\n+extern crate syntax_pos;\n+\n+use build::*;\n+use parse::lex;\n+use qquote::int_build::*;\n+\n+use syntax::ast::Ident;\n+use syntax::codemap::Span;\n+use syntax::ext::base::*;\n+use syntax::ext::base;\n+use syntax::ext::proc_macro_shim::build_block_emitter;\n+use syntax::parse::token::{self, Token, gensym_ident, str_to_ident};\n+use syntax::print::pprust;\n+use syntax::tokenstream::{TokenTree, TokenStream};\n+\n+// ____________________________________________________________________________________________\n+// Main definition\n+/// The user should use the macro, not this procedure.\n+pub fn qquote<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[TokenTree])\n+                   -> Box<base::MacResult + 'cx> {\n+\n+    debug!(\"\\nTTs in: {:?}\\n\", pprust::tts_to_string(&tts[..]));\n+    let output = qquoter(cx, TokenStream::from_tts(tts.clone().to_owned()));\n+    debug!(\"\\nQQ out: {}\\n\", pprust::tts_to_string(&output.to_tts()[..]));\n+    let imports = concat(lex(\"use syntax::ext::proc_macro_shim::prelude::*;\"),\n+                         lex(\"use proc_macro::prelude::*;\"));\n+    build_block_emitter(cx, sp, build_brace_delimited(concat(imports, output)))\n+}\n+\n+// ____________________________________________________________________________________________\n+// Datatype Definitions\n+\n+#[derive(Debug)]\n+struct QDelimited {\n+    delim: token::DelimToken,\n+    open_span: Span,\n+    tts: Vec<QTT>,\n+    close_span: Span,\n+}\n+\n+#[derive(Debug)]\n+enum QTT {\n+    TT(TokenTree),\n+    QDL(QDelimited),\n+    QIdent(TokenTree),\n+}\n+\n+type Bindings = Vec<(Ident, TokenStream)>;\n+\n+// ____________________________________________________________________________________________\n+// Quasiquoter Algorithm\n+// This algorithm works as follows:\n+// Input: TokenStream\n+// 1. Walk the TokenStream, gathering up the unquoted expressions and marking them separately.\n+// 2. Hoist any unquoted term into its own let-binding via a gensym'd identifier\n+// 3. Convert the body from a `complex expression` into a simplified one via `convert_complex_tts\n+// 4. Stitch everything together with `concat`.\n+fn qquoter<'cx>(cx: &'cx mut ExtCtxt, ts: TokenStream) -> TokenStream {\n+    if ts.is_empty() {\n+        return lex(\"TokenStream::mk_empty()\");\n+    }\n+    let qq_res = qquote_iter(cx, 0, ts);\n+    let mut bindings = qq_res.0;\n+    let body = qq_res.1;\n+    let mut cct_res = convert_complex_tts(cx, body);\n+\n+    bindings.append(&mut cct_res.0);\n+\n+    if bindings.is_empty() {\n+        cct_res.1\n+    } else {\n+        debug!(\"BINDINGS\");\n+        for b in bindings.clone() {\n+            debug!(\"{:?} = {}\", b.0, pprust::tts_to_string(&b.1.to_tts()[..]));\n+        }\n+        TokenStream::concat(unravel(bindings), cct_res.1)\n+   }\n+}\n+\n+fn qquote_iter<'cx>(cx: &'cx mut ExtCtxt, depth: i64, ts: TokenStream) -> (Bindings, Vec<QTT>) {\n+    let mut depth = depth;\n+    let mut bindings: Bindings = Vec::new();\n+    let mut output: Vec<QTT> = Vec::new();\n+\n+    let mut iter = ts.iter();\n+\n+    loop {\n+        let next = iter.next();\n+        if next.is_none() {\n+            break;\n+        }\n+        let next = next.unwrap().clone();\n+        match next {\n+            TokenTree::Token(_, Token::Ident(id)) if is_unquote(id) => {\n+                if depth == 0 {\n+                    let exp = iter.next();\n+                    if exp.is_none() {\n+                        break;\n+                    } // produce an error or something first\n+                    let exp = vec![exp.unwrap().to_owned()];\n+                    debug!(\"RHS: {:?}\", exp.clone());\n+                    let new_id = gensym_ident(\"tmp\");\n+                    debug!(\"RHS TS: {:?}\", TokenStream::from_tts(exp.clone()));\n+                    debug!(\"RHS TS TT: {:?}\", TokenStream::from_tts(exp.clone()).to_vec());\n+                    bindings.push((new_id, TokenStream::from_tts(exp)));\n+                    debug!(\"BINDINGS\");\n+                    for b in bindings.clone() {\n+                        debug!(\"{:?} = {}\", b.0, pprust::tts_to_string(&b.1.to_tts()[..]));\n+                    }\n+                    output.push(QTT::QIdent(as_tt(Token::Ident(new_id.clone()))));\n+                } else {\n+                    depth = depth - 1;\n+                    output.push(QTT::TT(next.clone()));\n+                }\n+            }\n+            TokenTree::Token(_, Token::Ident(id)) if is_qquote(id) => {\n+                depth = depth + 1;\n+            }\n+            TokenTree::Delimited(_, ref dl) => {\n+                let br = qquote_iter(cx, depth, TokenStream::from_tts(dl.tts.clone().to_owned()));\n+                let mut bind_ = br.0;\n+                let res_ = br.1;\n+                bindings.append(&mut bind_);\n+\n+                let new_dl = QDelimited {\n+                    delim: dl.delim,\n+                    open_span: dl.open_span,\n+                    tts: res_,\n+                    close_span: dl.close_span,\n+                };\n+\n+                output.push(QTT::QDL(new_dl));\n+            }\n+            t => {\n+                output.push(QTT::TT(t));\n+            }\n+        }\n+    }\n+\n+    (bindings, output)\n+}\n+\n+// ____________________________________________________________________________________________\n+// Turns QQTs into a TokenStream and some Bindings.\n+/// Construct a chain of concatenations.\n+fn unravel_concats(tss: Vec<TokenStream>) -> TokenStream {\n+    let mut pushes: Vec<TokenStream> =\n+        tss.into_iter().filter(|&ref ts| !ts.is_empty()).collect();\n+    let mut output = match pushes.pop() {\n+        Some(ts) => ts,\n+        None => {\n+            return TokenStream::mk_empty();\n+        }\n+    };\n+\n+    while let Some(ts) = pushes.pop() {\n+        output = build_fn_call(str_to_ident(\"concat\"),\n+                               concat(concat(ts,\n+                                             from_tokens(vec![Token::Comma])),\n+                                      output));\n+    }\n+    output\n+}\n+\n+/// This converts the vector of QTTs into a seet of Bindings for construction and the main\n+/// body as a TokenStream.\n+fn convert_complex_tts<'cx>(cx: &'cx mut ExtCtxt, tts: Vec<QTT>) -> (Bindings, TokenStream) {\n+    let mut pushes: Vec<TokenStream> = Vec::new();\n+    let mut bindings: Bindings = Vec::new();\n+\n+    let mut iter = tts.into_iter();\n+\n+    loop {\n+        let next = iter.next();\n+        if next.is_none() {\n+            break;\n+        }\n+        let next = next.unwrap();\n+        match next {\n+            QTT::TT(TokenTree::Token(_, t)) => {\n+                let token_out = emit_token(t);\n+                pushes.push(token_out);\n+            }\n+            // FIXME handle sequence repetition tokens\n+            QTT::QDL(qdl) => {\n+                debug!(\"  QDL: {:?} \", qdl.tts);\n+                let new_id = gensym_ident(\"qdl_tmp\");\n+                let mut cct_rec = convert_complex_tts(cx, qdl.tts);\n+                bindings.append(&mut cct_rec.0);\n+                bindings.push((new_id, cct_rec.1));\n+\n+                let sep = build_delim_tok(qdl.delim);\n+\n+                pushes.push(build_mod_call(vec![str_to_ident(\"proc_macro\"),\n+                                               str_to_ident(\"build\"),\n+                                               str_to_ident(\"build_delimited\")],\n+                                          concat(from_tokens(vec![Token::Ident(new_id)]),\n+                                                 concat(lex(\",\"), sep))));\n+            }\n+            QTT::QIdent(t) => {\n+                pushes.push(TokenStream::from_tts(vec![t]));\n+                pushes.push(TokenStream::mk_empty());\n+            }\n+            _ => panic!(\"Unhandled case!\"),\n+        }\n+\n+    }\n+\n+    (bindings, unravel_concats(pushes))\n+}\n+\n+// ____________________________________________________________________________________________\n+// Utilities\n+\n+/// Unravels Bindings into a TokenStream of `let` declarations.\n+fn unravel(binds: Bindings) -> TokenStream {\n+    let mut output = TokenStream::mk_empty();\n+\n+    for b in binds {\n+        output = concat(output, build_let(b.0, b.1));\n+    }\n+\n+    output\n+}\n+\n+/// Checks if the Ident is `unquote`.\n+fn is_unquote(id: Ident) -> bool {\n+    let qq = str_to_ident(\"unquote\");\n+    id.name == qq.name  // We disregard context; unquote is _reserved_\n+}\n+\n+/// Checks if the Ident is `quote`.\n+fn is_qquote(id: Ident) -> bool {\n+    let qq = str_to_ident(\"qquote\");\n+    id.name == qq.name  // We disregard context; qquote is _reserved_\n+}\n+\n+mod int_build {\n+    extern crate syntax;\n+    extern crate syntax_pos;\n+\n+    use parse::*;\n+    use build::*;\n+\n+    use syntax::ast::{self, Ident};\n+    use syntax::codemap::{DUMMY_SP};\n+    use syntax::parse::token::{self, Token, keywords, str_to_ident};\n+    use syntax::tokenstream::{TokenTree, TokenStream};\n+\n+    // ____________________________________________________________________________________________\n+    // Emitters\n+\n+    pub fn emit_token(t: Token) -> TokenStream {\n+        concat(lex(\"TokenStream::from_tokens\"),\n+               build_paren_delimited(build_vec(build_token_tt(t))))\n+    }\n+\n+    pub fn emit_lit(l: token::Lit, n: Option<ast::Name>) -> TokenStream {\n+        let suf = match n {\n+            Some(n) => format!(\"Some(ast::Name({}))\", n.0),\n+            None => \"None\".to_string(),\n+        };\n+\n+        let lit = match l {\n+            token::Lit::Byte(n) => format!(\"Lit::Byte(token::intern(\\\"{}\\\"))\", n.to_string()),\n+            token::Lit::Char(n) => format!(\"Lit::Char(token::intern(\\\"{}\\\"))\", n.to_string()),\n+            token::Lit::Integer(n) => format!(\"Lit::Integer(token::intern(\\\"{}\\\"))\", n.to_string()),\n+            token::Lit::Float(n) => format!(\"Lit::Float(token::intern(\\\"{}\\\"))\", n.to_string()),\n+            token::Lit::Str_(n) => format!(\"Lit::Str_(token::intern(\\\"{}\\\"))\", n.to_string()),\n+            token::Lit::ByteStr(n) => format!(\"Lit::ByteStr(token::intern(\\\"{}\\\"))\", n.to_string()),\n+            _ => panic!(\"Unsupported literal\"),\n+        };\n+\n+        let res = format!(\"Token::Literal({},{})\", lit, suf);\n+        debug!(\"{}\", res);\n+        lex(&res)\n+    }\n+\n+    // ____________________________________________________________________________________________\n+    // Token Builders\n+\n+    pub fn build_binop_tok(bot: token::BinOpToken) -> TokenStream {\n+        match bot {\n+            token::BinOpToken::Plus => lex(\"Token::BinOp(BinOpToken::Plus)\"),\n+            token::BinOpToken::Minus => lex(\"Token::BinOp(BinOpToken::Minus)\"),\n+            token::BinOpToken::Star => lex(\"Token::BinOp(BinOpToken::Star)\"),\n+            token::BinOpToken::Slash => lex(\"Token::BinOp(BinOpToken::Slash)\"),\n+            token::BinOpToken::Percent => lex(\"Token::BinOp(BinOpToken::Percent)\"),\n+            token::BinOpToken::Caret => lex(\"Token::BinOp(BinOpToken::Caret)\"),\n+            token::BinOpToken::And => lex(\"Token::BinOp(BinOpToken::And)\"),\n+            token::BinOpToken::Or => lex(\"Token::BinOp(BinOpToken::Or)\"),\n+            token::BinOpToken::Shl => lex(\"Token::BinOp(BinOpToken::Shl)\"),\n+            token::BinOpToken::Shr => lex(\"Token::BinOp(BinOpToken::Shr)\"),\n+        }\n+    }\n+\n+    pub fn build_binopeq_tok(bot: token::BinOpToken) -> TokenStream {\n+        match bot {\n+            token::BinOpToken::Plus => lex(\"Token::BinOpEq(BinOpToken::Plus)\"),\n+            token::BinOpToken::Minus => lex(\"Token::BinOpEq(BinOpToken::Minus)\"),\n+            token::BinOpToken::Star => lex(\"Token::BinOpEq(BinOpToken::Star)\"),\n+            token::BinOpToken::Slash => lex(\"Token::BinOpEq(BinOpToken::Slash)\"),\n+            token::BinOpToken::Percent => lex(\"Token::BinOpEq(BinOpToken::Percent)\"),\n+            token::BinOpToken::Caret => lex(\"Token::BinOpEq(BinOpToken::Caret)\"),\n+            token::BinOpToken::And => lex(\"Token::BinOpEq(BinOpToken::And)\"),\n+            token::BinOpToken::Or => lex(\"Token::BinOpEq(BinOpToken::Or)\"),\n+            token::BinOpToken::Shl => lex(\"Token::BinOpEq(BinOpToken::Shl)\"),\n+            token::BinOpToken::Shr => lex(\"Token::BinOpEq(BinOpToken::Shr)\"),\n+        }\n+    }\n+\n+    pub fn build_delim_tok(dt: token::DelimToken) -> TokenStream {\n+        match dt {\n+            token::DelimToken::Paren => lex(\"DelimToken::Paren\"),\n+            token::DelimToken::Bracket => lex(\"DelimToken::Bracket\"),\n+            token::DelimToken::Brace => lex(\"DelimToken::Brace\"),\n+            token::DelimToken::NoDelim => lex(\"DelimToken::NoDelim\"),\n+        }\n+    }\n+\n+    pub fn build_token_tt(t: Token) -> TokenStream {\n+        match t {\n+            Token::Eq => lex(\"Token::Eq\"),\n+            Token::Lt => lex(\"Token::Lt\"),\n+            Token::Le => lex(\"Token::Le\"),\n+            Token::EqEq => lex(\"Token::EqEq\"),\n+            Token::Ne => lex(\"Token::Ne\"),\n+            Token::Ge => lex(\"Token::Ge\"),\n+            Token::Gt => lex(\"Token::Gt\"),\n+            Token::AndAnd => lex(\"Token::AndAnd\"),\n+            Token::OrOr => lex(\"Token::OrOr\"),\n+            Token::Not => lex(\"Token::Not\"),\n+            Token::Tilde => lex(\"Token::Tilde\"),\n+            Token::BinOp(tok) => build_binop_tok(tok),\n+            Token::BinOpEq(tok) => build_binopeq_tok(tok),\n+            Token::At => lex(\"Token::At\"),\n+            Token::Dot => lex(\"Token::Dot\"),\n+            Token::DotDot => lex(\"Token::DotDot\"),\n+            Token::DotDotDot => lex(\"Token::DotDotDot\"),\n+            Token::Comma => lex(\"Token::Comma\"),\n+            Token::Semi => lex(\"Token::Semi\"),\n+            Token::Colon => lex(\"Token::Colon\"),\n+            Token::ModSep => lex(\"Token::ModSep\"),\n+            Token::RArrow => lex(\"Token::RArrow\"),\n+            Token::LArrow => lex(\"Token::LArrow\"),\n+            Token::FatArrow => lex(\"Token::FatArrow\"),\n+            Token::Pound => lex(\"Token::Pound\"),\n+            Token::Dollar => lex(\"Token::Dollar\"),\n+            Token::Question => lex(\"Token::Question\"),\n+            Token::OpenDelim(dt) => {\n+                match dt {\n+                    token::DelimToken::Paren => lex(\"Token::OpenDelim(DelimToken::Paren)\"),\n+                    token::DelimToken::Bracket => lex(\"Token::OpenDelim(DelimToken::Bracket)\"),\n+                    token::DelimToken::Brace => lex(\"Token::OpenDelim(DelimToken::Brace)\"),\n+                    token::DelimToken::NoDelim => lex(\"DelimToken::NoDelim\"),\n+                }\n+            }\n+            Token::CloseDelim(dt) => {\n+                match dt {\n+                    token::DelimToken::Paren => lex(\"Token::CloseDelim(DelimToken::Paren)\"),\n+                    token::DelimToken::Bracket => lex(\"Token::CloseDelim(DelimToken::Bracket)\"),\n+                    token::DelimToken::Brace => lex(\"Token::CloseDelim(DelimToken::Brace)\"),\n+                    token::DelimToken::NoDelim => lex(\"DelimToken::NoDelim\"),\n+                }\n+            }\n+            Token::Underscore => lex(\"_\"),\n+            Token::Literal(lit, sfx) => emit_lit(lit, sfx),\n+            // fix ident expansion information... somehow\n+            Token::Ident(ident) => lex(&format!(\"Token::Ident(str_to_ident(\\\"{}\\\"))\", ident.name)),\n+            Token::Lifetime(ident) => lex(&format!(\"Token::Ident(str_to_ident(\\\"{}\\\"))\",\n+                                                   ident.name)),\n+            _ => panic!(\"Unhandled case!\"),\n+        }\n+    }\n+\n+    // ____________________________________________________________________________________________\n+    // Conversion operators\n+\n+    pub fn as_tt(t: Token) -> TokenTree {\n+        // FIXME do something nicer with the spans\n+        TokenTree::Token(DUMMY_SP, t)\n+    }\n+\n+    // ____________________________________________________________________________________________\n+    // Build Procedures\n+\n+    /// Takes `input` and returns `vec![input]`.\n+    pub fn build_vec(ts: TokenStream) -> TokenStream {\n+        build_mac_call(str_to_ident(\"vec\"), ts)\n+        // tts.clone().to_owned()\n+    }\n+\n+    /// Takes `ident` and `rhs` and produces `let ident = rhs;`.\n+    pub fn build_let(id: Ident, tts: TokenStream) -> TokenStream {\n+        concat(from_tokens(vec![keyword_to_token_ident(keywords::Let),\n+                                Token::Ident(id),\n+                                Token::Eq]),\n+               concat(tts, from_tokens(vec![Token::Semi])))\n+    }\n+\n+    /// Takes `ident ...`, and `args ...` and produces `ident::...(args ...)`.\n+    pub fn build_mod_call(ids: Vec<Ident>, args: TokenStream) -> TokenStream {\n+        let call = from_tokens(intersperse(ids.into_iter().map(|id| Token::Ident(id)).collect(),\n+                                     Token::ModSep));\n+        concat(call, build_paren_delimited(args))\n+    }\n+\n+    /// Takes `ident` and `args ...` and produces `ident(args ...)`.\n+    pub fn build_fn_call(name: Ident, args: TokenStream) -> TokenStream {\n+        concat(from_tokens(vec![Token::Ident(name)]), build_paren_delimited(args))\n+    }\n+\n+    /// Takes `ident` and `args ...` and produces `ident!(args ...)`.\n+    pub fn build_mac_call(name: Ident, args: TokenStream) -> TokenStream {\n+        concat(from_tokens(vec![Token::Ident(name), Token::Not]),\n+               build_paren_delimited(args))\n+    }\n+\n+    // ____________________________________________________________________________________________\n+    // Utilities\n+\n+    /// A wrapper around `TokenStream::from_tokens` to avoid extra namespace specification and\n+    /// provide it as a generic operator.\n+    pub fn from_tokens(tokens: Vec<Token>) -> TokenStream {\n+        TokenStream::from_tokens(tokens)\n+    }\n+\n+    pub fn intersperse<T>(vs: Vec<T>, t: T) -> Vec<T>\n+        where T: Clone\n+    {\n+        if vs.len() < 2 {\n+            return vs;\n+        }\n+        let mut output = vec![vs.get(0).unwrap().to_owned()];\n+\n+        for v in vs.into_iter().skip(1) {\n+            output.push(t.clone());\n+            output.push(v);\n+        }\n+        output\n+    }\n+}"}, {"sha": "772d83eb2cfadd080df45a69ec493c53ac11e197", "filename": "src/librustc_driver/Cargo.toml", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibrustc_driver%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibrustc_driver%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2FCargo.toml?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -33,4 +33,5 @@ rustc_metadata = { path = \"../librustc_metadata\" }\n serialize = { path = \"../libserialize\" }\n syntax = { path = \"../libsyntax\" }\n syntax_ext = { path = \"../libsyntax_ext\" }\n-syntax_pos = { path = \"../libsyntax_pos\" }\n\\ No newline at end of file\n+syntax_pos = { path = \"../libsyntax_pos\" }\n+proc_macro = { path = \"../libproc_macro\" }"}, {"sha": "fa37e9b54e4574d04c94088680b3738269f6b72c", "filename": "src/libsyntax/ext/proc_macro_shim.rs", "status": "added", "additions": 69, "deletions": 0, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibsyntax%2Fext%2Fproc_macro_shim.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibsyntax%2Fext%2Fproc_macro_shim.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fproc_macro_shim.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,69 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! This is a shim file to ease the transition to the final procedural macro interface for\n+//! Macros 2.0. It currently exposes the `libsyntax` operations that the quasiquoter's\n+//! output needs to compile correctly, along with the following operators:\n+//!\n+//! - `build_block_emitter`, which produces a `block` output macro result from the\n+//!   provided TokenStream.\n+\n+use ast;\n+use codemap::Span;\n+use parse::parser::Parser;\n+use ptr::P;\n+use tokenstream::TokenStream;\n+use ext::base::*;\n+\n+/// Take a `ExtCtxt`, `Span`, and `TokenStream`, and produce a Macro Result that parses\n+/// the TokenStream as a block and returns it as an `Expr`.\n+pub fn build_block_emitter<'cx>(cx: &'cx mut ExtCtxt, sp: Span, output: TokenStream)\n+                                -> Box<MacResult + 'cx> {\n+    let parser = cx.new_parser_from_tts(&output.to_tts());\n+\n+    struct Result<'a> {\n+        prsr: Parser<'a>,\n+        span: Span,\n+    }; //FIXME is this the right lifetime\n+\n+    impl<'a> Result<'a> {\n+        fn block(&mut self) -> P<ast::Block> {\n+            let res = self.prsr.parse_block().unwrap();\n+            res\n+        }\n+    }\n+\n+    impl<'a> MacResult for Result<'a> {\n+        fn make_expr(self: Box<Self>) -> Option<P<ast::Expr>> {\n+            let mut me = *self;\n+            Some(P(ast::Expr {\n+                id: ast::DUMMY_NODE_ID,\n+                node: ast::ExprKind::Block(me.block()),\n+                span: me.span,\n+                attrs: ast::ThinVec::new(),\n+            }))\n+\n+        }\n+    }\n+\n+    Box::new(Result {\n+        prsr: parser,\n+        span: sp,\n+    })\n+}\n+\n+pub mod prelude {\n+    pub use ext::proc_macro_shim::build_block_emitter;\n+    pub use ast::Ident;\n+    pub use codemap::{DUMMY_SP, Span};\n+    pub use ext::base::{ExtCtxt, MacResult};\n+    pub use parse::token::{self, Token, DelimToken, keywords, str_to_ident};\n+    pub use tokenstream::{TokenTree, TokenStream};\n+}"}, {"sha": "b4311fc007d3db1b72cfbf05ddb9ca87fc922b71", "filename": "src/libsyntax/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibsyntax%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibsyntax%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Flib.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -128,6 +128,7 @@ pub mod ext {\n     pub mod build;\n     pub mod expand;\n     pub mod hygiene;\n+    pub mod proc_macro_shim;\n     pub mod quote;\n     pub mod source_util;\n "}, {"sha": "aab6f3d682e2c511da5a8537c55b20ab24ee37b1", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -548,6 +548,12 @@ impl TokenStream {\n         TokenStream::mk_leaf(Rc::new(trees), span)\n     }\n \n+    /// Convert a vector of Tokens into a TokenStream.\n+    pub fn from_tokens(tokens: Vec<Token>) -> TokenStream {\n+        // FIXME do something nicer with the spans\n+        TokenStream::from_tts(tokens.into_iter().map(|t| TokenTree::Token(DUMMY_SP, t)).collect())\n+    }\n+\n     /// Manually change a TokenStream's span.\n     pub fn respan(self, span: Span) -> TokenStream {\n         match self.ts {"}, {"sha": "4f78519e13aa860096998f43bf8c0c30a1937dc9", "filename": "src/rustc/Cargo.lock", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Frustc%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Frustc%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frustc%2FCargo.lock?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -40,6 +40,16 @@ version = \"0.0.0\"\n name = \"log\"\n version = \"0.0.0\"\n \n+[[package]]\n+name = \"proc_macro\"\n+version = \"0.0.0\"\n+dependencies = [\n+ \"log 0.0.0\",\n+ \"rustc_plugin 0.0.0\",\n+ \"syntax 0.0.0\",\n+ \"syntax_pos 0.0.0\",\n+]\n+\n [[package]]\n name = \"rbml\"\n version = \"0.0.0\"\n@@ -136,6 +146,7 @@ dependencies = [\n  \"flate 0.0.0\",\n  \"graphviz 0.0.0\",\n  \"log 0.0.0\",\n+ \"proc_macro 0.0.0\",\n  \"rustc 0.0.0\",\n  \"rustc_back 0.0.0\",\n  \"rustc_borrowck 0.0.0\","}, {"sha": "6aee63e2858e282bc1ca5890648face5cad1178d", "filename": "src/test/run-pass-fulldeps/auxiliary/cond_noprelude_plugin.rs", "status": "added", "additions": 65, "deletions": 0, "changes": 65, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_noprelude_plugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_noprelude_plugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_noprelude_plugin.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,65 @@\n+// Copyright 2015 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+#![allow(unused_parens)]\n+#![feature(plugin)]\n+#![feature(plugin_registrar)]\n+#![feature(rustc_private)]\n+#![plugin(proc_macro)]\n+\n+extern crate rustc_plugin;\n+extern crate proc_macro;\n+extern crate syntax;\n+\n+use proc_macro::build::ident_eq;\n+\n+use syntax::ext::base::{ExtCtxt, MacResult};\n+use syntax::ext::proc_macro_shim::build_block_emitter;\n+use syntax::tokenstream::{TokenTree, TokenStream};\n+use syntax::parse::token::str_to_ident;\n+use syntax::codemap::Span;\n+\n+use rustc_plugin::Registry;\n+\n+#[plugin_registrar]\n+pub fn plugin_registrar(reg: &mut Registry) {\n+    reg.register_macro(\"cond\", cond);\n+}\n+\n+fn cond<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[TokenTree]) -> Box<MacResult + 'cx> {\n+    let output = cond_rec(TokenStream::from_tts(tts.clone().to_owned()));\n+    build_block_emitter(cx, sp, output)\n+}\n+\n+fn cond_rec(input: TokenStream) -> TokenStream {\n+  if input.is_empty() {\n+      return qquote!();\n+  }\n+\n+  let next = input.slice(0..1);\n+  let rest = input.slice_from(1..);\n+\n+  let clause : TokenStream = match next.maybe_delimited() {\n+    Some(ts) => ts,\n+    _ => panic!(\"Invalid input\"),\n+  };\n+\n+  // clause is ([test]) [rhs]\n+  if clause.len() < 2 { panic!(\"Invalid macro usage in cond: {:?}\", clause) }\n+\n+  let test: TokenStream = clause.slice(0..1);\n+  let rhs: TokenStream = clause.slice_from(1..);\n+\n+  if ident_eq(&test[0], str_to_ident(\"else\")) || rest.is_empty() {\n+    qquote!({unquote(rhs)})\n+  } else {\n+    qquote!({if unquote(test) { unquote(rhs) } else { cond!(unquote(rest)) } })\n+  }\n+}"}, {"sha": "8291c8a1e41c631971142edccb8372ead0ffadcd", "filename": "src/test/run-pass-fulldeps/auxiliary/cond_plugin.rs", "status": "added", "additions": 66, "deletions": 0, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,66 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+#![allow(unused_parens)]\n+#![feature(plugin)]\n+#![feature(plugin_registrar)]\n+#![feature(rustc_private)]\n+#![plugin(proc_macro)]\n+\n+extern crate rustc_plugin;\n+extern crate proc_macro;\n+extern crate syntax;\n+\n+use proc_macro::prelude::*;\n+\n+use rustc_plugin::Registry;\n+\n+use syntax::ast::Ident;\n+use syntax::codemap::{DUMMY_SP, Span};\n+use syntax::ext::proc_macro_shim::build_block_emitter;\n+use syntax::ext::base::{ExtCtxt, MacResult};\n+use syntax::parse::token::{self, Token, DelimToken, keywords, str_to_ident};\n+use syntax::tokenstream::{TokenTree, TokenStream};\n+\n+#[plugin_registrar]\n+pub fn plugin_registrar(reg: &mut Registry) {\n+    reg.register_macro(\"cond\", cond);\n+}\n+\n+fn cond<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[TokenTree]) -> Box<MacResult + 'cx> {\n+    let output = cond_rec(TokenStream::from_tts(tts.clone().to_owned()));\n+    build_block_emitter(cx, sp, output)\n+}\n+\n+fn cond_rec(input: TokenStream) -> TokenStream {\n+  if input.is_empty() {\n+      return qquote!();\n+  }\n+\n+  let next = input.slice(0..1);\n+  let rest = input.slice_from(1..);\n+\n+  let clause : TokenStream = match next.maybe_delimited() {\n+    Some(ts) => ts,\n+    _ => panic!(\"Invalid input\"),\n+  };\n+\n+  // clause is ([test]) [rhs]\n+  if clause.len() < 2 { panic!(\"Invalid macro usage in cond: {:?}\", clause) }\n+\n+  let test: TokenStream = clause.slice(0..1);\n+  let rhs: TokenStream = clause.slice_from(1..);\n+\n+  if ident_eq(&test[0], str_to_ident(\"else\")) || rest.is_empty() {\n+    qquote!({unquote(rhs)})\n+  } else {\n+    qquote!({if unquote(test) { unquote(rhs) } else { cond!(unquote(rest)) } })\n+  }\n+}"}, {"sha": "2d92a0ef18199bac9162d96c9d7f534b248d15a7", "filename": "src/test/run-pass-fulldeps/auxiliary/cond_prelude_plugin.rs", "status": "added", "additions": 60, "deletions": 0, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_prelude_plugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_prelude_plugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_prelude_plugin.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,60 @@\n+// Copyright 2015 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+#![allow(unused_parens)]\n+#![feature(plugin)]\n+#![feature(plugin_registrar)]\n+#![feature(rustc_private)]\n+#![plugin(proc_macro)]\n+\n+extern crate rustc_plugin;\n+extern crate proc_macro;\n+extern crate syntax;\n+\n+use syntax::ext::proc_macro_shim::prelude::*;\n+use proc_macro::prelude::*;\n+\n+use rustc_plugin::Registry;\n+\n+#[plugin_registrar]\n+pub fn plugin_registrar(reg: &mut Registry) {\n+    reg.register_macro(\"cond\", cond);\n+}\n+\n+fn cond<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[TokenTree]) -> Box<MacResult + 'cx> {\n+    let output = cond_rec(TokenStream::from_tts(tts.clone().to_owned()));\n+    build_block_emitter(cx, sp, output)\n+}\n+\n+fn cond_rec(input: TokenStream) -> TokenStream {\n+  if input.is_empty() {\n+      return qquote!();\n+  }\n+\n+  let next = input.slice(0..1);\n+  let rest = input.slice_from(1..);\n+\n+  let clause : TokenStream = match next.maybe_delimited() {\n+    Some(ts) => ts,\n+    _ => panic!(\"Invalid input\"),\n+  };\n+\n+  // clause is ([test]) [rhs]\n+  if clause.len() < 2 { panic!(\"Invalid macro usage in cond: {:?}\", clause) }\n+\n+  let test: TokenStream = clause.slice(0..1);\n+  let rhs: TokenStream = clause.slice_from(1..);\n+\n+  if ident_eq(&test[0], str_to_ident(\"else\")) || rest.is_empty() {\n+    qquote!({unquote(rhs)})\n+  } else {\n+    qquote!({if unquote(test) { unquote(rhs) } else { cond!(unquote(rest)) } })\n+  }\n+}"}, {"sha": "4ee775dec0cefc39dc17021a6e41080fe309406f", "filename": "src/test/run-pass-fulldeps/macro-quote-1.rs", "status": "added", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-1.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,28 @@\n+// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// ignore-stage1\n+\n+#![feature(plugin)]\n+#![feature(rustc_private)]\n+#![plugin(proc_macro)]\n+\n+extern crate proc_macro;\n+use proc_macro::prelude::*;\n+\n+extern crate syntax;\n+use syntax::ast::Ident;\n+use syntax::codemap::DUMMY_SP;\n+use syntax::parse::token::{self, Token, keywords, str_to_ident};\n+\n+fn main() {\n+    let lex_true = lex(\"true\");\n+    assert_eq!(qquote!(true).eq_unspanned(&lex_true), true);\n+}"}, {"sha": "fa969b6a087cf1a40994a729d3c52dd1b6820d21", "filename": "src/test/run-pass-fulldeps/macro-quote-cond.rs", "status": "added", "additions": 54, "deletions": 0, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-cond.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-cond.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-cond.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,54 @@\n+// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// aux-build:cond_plugin.rs\n+// ignore-stage1\n+\n+#![feature(plugin)]\n+#![feature(rustc_private)]\n+#![plugin(cond_plugin)]\n+\n+fn fact(n : i64) -> i64 {\n+    if n == 0 {\n+        1\n+    } else {\n+        n * fact(n - 1)\n+    }\n+}\n+\n+fn fact_cond(n : i64) -> i64 {\n+  cond!(\n+    ((n == 0) 1)\n+    (else (n * fact_cond(n-1)))\n+  )\n+}\n+\n+fn fib(n : i64) -> i64 {\n+  if n == 0 || n == 1 {\n+      1\n+  } else {\n+      fib(n-1) + fib(n-2)\n+  }\n+}\n+\n+fn fib_cond(n : i64) -> i64 {\n+  cond!(\n+    ((n == 0) 1)\n+    ((n == 1) 1)\n+    (else (fib_cond(n-1) + fib_cond(n-2)))\n+  )\n+}\n+\n+fn main() {\n+    assert_eq!(fact(3), fact_cond(3));\n+    assert_eq!(fact(5), fact_cond(5));\n+    assert_eq!(fib(5), fib_cond(5));\n+    assert_eq!(fib(8), fib_cond(8));\n+}"}, {"sha": "4184ca7be372f94f59b111c82dc6347fe2b3a92d", "filename": "src/test/run-pass-fulldeps/macro-quote-noprelude.rs", "status": "added", "additions": 54, "deletions": 0, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-noprelude.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-noprelude.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-noprelude.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,54 @@\n+// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// aux-build:cond_noprelude_plugin.rs\n+// ignore-stage1\n+\n+#![feature(plugin)]\n+#![feature(rustc_private)]\n+#![plugin(cond_noprelude_plugin)]\n+\n+fn fact(n : i64) -> i64 {\n+    if n == 0 {\n+        1\n+    } else {\n+        n * fact(n - 1)\n+    }\n+}\n+\n+fn fact_cond(n : i64) -> i64 {\n+  cond!(\n+    ((n == 0) 1)\n+    (else (n * fact_cond(n-1)))\n+  )\n+}\n+\n+fn fib(n : i64) -> i64 {\n+  if n == 0 || n == 1 {\n+      1\n+  } else {\n+      fib(n-1) + fib(n-2)\n+  }\n+}\n+\n+fn fib_cond(n : i64) -> i64 {\n+  cond!(\n+    ((n == 0) 1)\n+    ((n == 1) 1)\n+    (else (fib_cond(n-1) + fib_cond(n-2)))\n+  )\n+}\n+\n+fn main() {\n+    assert_eq!(fact(3), fact_cond(3));\n+    assert_eq!(fact(5), fact_cond(5));\n+    assert_eq!(fib(5), fib_cond(5));\n+    assert_eq!(fib(8), fib_cond(8));\n+}"}, {"sha": "5b703a5bc2668a2a76c6155ce9a123bb82323179", "filename": "src/test/run-pass-fulldeps/macro-quote-prelude.rs", "status": "added", "additions": 54, "deletions": 0, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-prelude.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-prelude.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-prelude.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -0,0 +1,54 @@\n+// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// aux-build:cond_prelude_plugin.rs\n+// ignore-stage1\n+\n+#![feature(plugin)]\n+#![feature(rustc_private)]\n+#![plugin(cond_prelude_plugin)]\n+\n+fn fact(n : i64) -> i64 {\n+    if n == 0 {\n+        1\n+    } else {\n+        n * fact(n - 1)\n+    }\n+}\n+\n+fn fact_cond(n : i64) -> i64 {\n+  cond!(\n+    ((n == 0) 1)\n+    (else (n * fact_cond(n-1)))\n+  )\n+}\n+\n+fn fib(n : i64) -> i64 {\n+  if n == 0 || n == 1 {\n+      1\n+  } else {\n+      fib(n-1) + fib(n-2)\n+  }\n+}\n+\n+fn fib_cond(n : i64) -> i64 {\n+  cond!(\n+    ((n == 0) 1)\n+    ((n == 1) 1)\n+    (else (fib_cond(n-1) + fib_cond(n-2)))\n+  )\n+}\n+\n+fn main() {\n+    assert_eq!(fact(3), fact_cond(3));\n+    assert_eq!(fact(5), fact_cond(5));\n+    assert_eq!(fib(5), fib_cond(5));\n+    assert_eq!(fib(8), fib_cond(8));\n+}"}, {"sha": "4932fd5147afa8ba2a9f023cb71e6278f9509344", "filename": "src/tools/tidy/src/cargo.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftools%2Ftidy%2Fsrc%2Fcargo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638/src%2Ftools%2Ftidy%2Fsrc%2Fcargo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ftidy%2Fsrc%2Fcargo.rs?ref=98c8e0a05dd7b1ecbbda28c1d01e05c1e41b1638", "patch": "@@ -88,6 +88,12 @@ fn verify(tomlfile: &Path, libfile: &Path, bad: &mut bool) {\n             continue\n         }\n \n+        // We want the compiler to depend on the proc_macro crate so that it is built and\n+        // included in the end, but we don't want to actually use it in the compiler.\n+        if toml.contains(\"name = \\\"rustc_driver\\\"\") && krate == \"proc_macro\" {\n+            continue\n+        }\n+\n         if !librs.contains(&format!(\"extern crate {}\", krate)) {\n             println!(\"{} doesn't have `extern crate {}`, but Cargo.toml \\\n                       depends on it\", libfile.display(), krate);"}]}