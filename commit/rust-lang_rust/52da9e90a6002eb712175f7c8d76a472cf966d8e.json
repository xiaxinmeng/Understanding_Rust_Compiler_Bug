{"sha": "52da9e90a6002eb712175f7c8d76a472cf966d8e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjUyZGE5ZTkwYTYwMDJlYjcxMjE3NWY3YzhkNzZhNDcyY2Y5NjZkOGU=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-03-11T11:46:36Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-03-11T11:58:16Z"}, "message": "Move on enter to a separate module", "tree": {"sha": "f2a08835519d35693e1c8661581ce1593c3c2a91", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f2a08835519d35693e1c8661581ce1593c3c2a91"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/52da9e90a6002eb712175f7c8d76a472cf966d8e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/52da9e90a6002eb712175f7c8d76a472cf966d8e", "html_url": "https://github.com/rust-lang/rust/commit/52da9e90a6002eb712175f7c8d76a472cf966d8e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/52da9e90a6002eb712175f7c8d76a472cf966d8e/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c48dcf74118b6e0df747f036a9b66701037f3fc7", "url": "https://api.github.com/repos/rust-lang/rust/commits/c48dcf74118b6e0df747f036a9b66701037f3fc7", "html_url": "https://github.com/rust-lang/rust/commit/c48dcf74118b6e0df747f036a9b66701037f3fc7"}], "stats": {"total": 331, "additions": 177, "deletions": 154}, "files": [{"sha": "53c65f8bc3e8e928ee4b0a4760e220026477fd2c", "filename": "crates/ra_ide/src/typing.rs", "status": "modified", "additions": 6, "deletions": 154, "changes": 160, "blob_url": "https://github.com/rust-lang/rust/blob/52da9e90a6002eb712175f7c8d76a472cf966d8e/crates%2Fra_ide%2Fsrc%2Ftyping.rs", "raw_url": "https://github.com/rust-lang/rust/raw/52da9e90a6002eb712175f7c8d76a472cf966d8e/crates%2Fra_ide%2Fsrc%2Ftyping.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Ftyping.rs?ref=52da9e90a6002eb712175f7c8d76a472cf966d8e", "patch": "@@ -13,77 +13,21 @@\n //! Language server executes such typing assists synchronously. That is, they\n //! block user's typing and should be pretty fast for this reason!\n \n+mod on_enter;\n+\n use ra_db::{FilePosition, SourceDatabase};\n use ra_fmt::leading_indent;\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n     algo::find_node_at_offset,\n     ast::{self, AstToken},\n-    AstNode, SmolStr, SourceFile,\n-    SyntaxKind::*,\n-    SyntaxToken, TextRange, TextUnit, TokenAtOffset,\n+    AstNode, SourceFile, TextRange, TextUnit,\n };\n use ra_text_edit::TextEdit;\n \n-use crate::{source_change::SingleFileChange, SourceChange, SourceFileEdit};\n-\n-pub(crate) fn on_enter(db: &RootDatabase, position: FilePosition) -> Option<SourceChange> {\n-    let parse = db.parse(position.file_id);\n-    let file = parse.tree();\n-    let comment = file\n-        .syntax()\n-        .token_at_offset(position.offset)\n-        .left_biased()\n-        .and_then(ast::Comment::cast)?;\n-\n-    if comment.kind().shape.is_block() {\n-        return None;\n-    }\n-\n-    let prefix = comment.prefix();\n-    let comment_range = comment.syntax().text_range();\n-    if position.offset < comment_range.start() + TextUnit::of_str(prefix) {\n-        return None;\n-    }\n-\n-    // Continuing non-doc line comments (like this one :) ) is annoying\n-    if prefix == \"//\" && comment_range.end() == position.offset {\n-        return None;\n-    }\n-\n-    let indent = node_indent(&file, comment.syntax())?;\n-    let inserted = format!(\"\\n{}{} \", indent, prefix);\n-    let cursor_position = position.offset + TextUnit::of_str(&inserted);\n-    let edit = TextEdit::insert(position.offset, inserted);\n+use crate::{source_change::SingleFileChange, SourceChange};\n \n-    Some(\n-        SourceChange::source_file_edit(\n-            \"on enter\",\n-            SourceFileEdit { edit, file_id: position.file_id },\n-        )\n-        .with_cursor(FilePosition { offset: cursor_position, file_id: position.file_id }),\n-    )\n-}\n-\n-fn node_indent(file: &SourceFile, token: &SyntaxToken) -> Option<SmolStr> {\n-    let ws = match file.syntax().token_at_offset(token.text_range().start()) {\n-        TokenAtOffset::Between(l, r) => {\n-            assert!(r == *token);\n-            l\n-        }\n-        TokenAtOffset::Single(n) => {\n-            assert!(n == *token);\n-            return Some(\"\".into());\n-        }\n-        TokenAtOffset::None => unreachable!(),\n-    };\n-    if ws.kind() != WHITESPACE {\n-        return None;\n-    }\n-    let text = ws.text();\n-    let pos = text.rfind('\\n').map(|it| it + 1).unwrap_or(0);\n-    Some(text[pos..].into())\n-}\n+pub(crate) use on_enter::on_enter;\n \n pub(crate) const TRIGGER_CHARS: &str = \".=>\";\n \n@@ -196,102 +140,10 @@ fn on_arrow_typed(file: &SourceFile, offset: TextUnit) -> Option<SingleFileChang\n \n #[cfg(test)]\n mod tests {\n-    use test_utils::{add_cursor, assert_eq_text, extract_offset};\n-\n-    use crate::mock_analysis::single_file;\n+    use test_utils::{assert_eq_text, extract_offset};\n \n     use super::*;\n \n-    #[test]\n-    fn test_on_enter() {\n-        fn apply_on_enter(before: &str) -> Option<String> {\n-            let (offset, before) = extract_offset(before);\n-            let (analysis, file_id) = single_file(&before);\n-            let result = analysis.on_enter(FilePosition { offset, file_id }).unwrap()?;\n-\n-            assert_eq!(result.source_file_edits.len(), 1);\n-            let actual = result.source_file_edits[0].edit.apply(&before);\n-            let actual = add_cursor(&actual, result.cursor_position.unwrap().offset);\n-            Some(actual)\n-        }\n-\n-        fn do_check(before: &str, after: &str) {\n-            let actual = apply_on_enter(before).unwrap();\n-            assert_eq_text!(after, &actual);\n-        }\n-\n-        fn do_check_noop(text: &str) {\n-            assert!(apply_on_enter(text).is_none())\n-        }\n-\n-        do_check(\n-            r\"\n-/// Some docs<|>\n-fn foo() {\n-}\n-\",\n-            r\"\n-/// Some docs\n-/// <|>\n-fn foo() {\n-}\n-\",\n-        );\n-        do_check(\n-            r\"\n-impl S {\n-    /// Some<|> docs.\n-    fn foo() {}\n-}\n-\",\n-            r\"\n-impl S {\n-    /// Some\n-    /// <|> docs.\n-    fn foo() {}\n-}\n-\",\n-        );\n-        do_check(\n-            r\"\n-fn main() {\n-    // Fix<|> me\n-    let x = 1 + 1;\n-}\n-\",\n-            r\"\n-fn main() {\n-    // Fix\n-    // <|> me\n-    let x = 1 + 1;\n-}\n-\",\n-        );\n-        do_check(\n-            r\"\n-///<|> Some docs\n-fn foo() {\n-}\n-\",\n-            r\"\n-///\n-/// <|> Some docs\n-fn foo() {\n-}\n-\",\n-        );\n-        do_check_noop(\n-            r\"\n-fn main() {\n-    // Fix me<|>\n-    let x = 1 + 1;\n-}\n-\",\n-        );\n-\n-        do_check_noop(r\"<|>//! docz\");\n-    }\n-\n     fn do_type_char(char_typed: char, before: &str) -> Option<(String, SingleFileChange)> {\n         let (offset, before) = extract_offset(before);\n         let edit = TextEdit::insert(offset, char_typed.to_string());"}, {"sha": "359794f67f807a750a58781e0ec0696664b4567c", "filename": "crates/ra_ide/src/typing/on_enter.rs", "status": "added", "additions": 171, "deletions": 0, "changes": 171, "blob_url": "https://github.com/rust-lang/rust/blob/52da9e90a6002eb712175f7c8d76a472cf966d8e/crates%2Fra_ide%2Fsrc%2Ftyping%2Fon_enter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/52da9e90a6002eb712175f7c8d76a472cf966d8e/crates%2Fra_ide%2Fsrc%2Ftyping%2Fon_enter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Ftyping%2Fon_enter.rs?ref=52da9e90a6002eb712175f7c8d76a472cf966d8e", "patch": "@@ -0,0 +1,171 @@\n+//! Handles the `Enter` key press. At the momently, this only continues\n+//! comments, but should handle indent some time in the future as well.\n+\n+use ra_db::{FilePosition, SourceDatabase};\n+use ra_ide_db::RootDatabase;\n+use ra_syntax::{\n+    ast::{self, AstToken},\n+    AstNode, SmolStr, SourceFile,\n+    SyntaxKind::*,\n+    SyntaxToken, TextUnit, TokenAtOffset,\n+};\n+use ra_text_edit::TextEdit;\n+\n+use crate::{SourceChange, SourceFileEdit};\n+\n+pub(crate) fn on_enter(db: &RootDatabase, position: FilePosition) -> Option<SourceChange> {\n+    let parse = db.parse(position.file_id);\n+    let file = parse.tree();\n+    let comment = file\n+        .syntax()\n+        .token_at_offset(position.offset)\n+        .left_biased()\n+        .and_then(ast::Comment::cast)?;\n+\n+    if comment.kind().shape.is_block() {\n+        return None;\n+    }\n+\n+    let prefix = comment.prefix();\n+    let comment_range = comment.syntax().text_range();\n+    if position.offset < comment_range.start() + TextUnit::of_str(prefix) {\n+        return None;\n+    }\n+\n+    // Continuing non-doc line comments (like this one :) ) is annoying\n+    if prefix == \"//\" && comment_range.end() == position.offset {\n+        return None;\n+    }\n+\n+    let indent = node_indent(&file, comment.syntax())?;\n+    let inserted = format!(\"\\n{}{} \", indent, prefix);\n+    let cursor_position = position.offset + TextUnit::of_str(&inserted);\n+    let edit = TextEdit::insert(position.offset, inserted);\n+\n+    Some(\n+        SourceChange::source_file_edit(\n+            \"on enter\",\n+            SourceFileEdit { edit, file_id: position.file_id },\n+        )\n+        .with_cursor(FilePosition { offset: cursor_position, file_id: position.file_id }),\n+    )\n+}\n+\n+fn node_indent(file: &SourceFile, token: &SyntaxToken) -> Option<SmolStr> {\n+    let ws = match file.syntax().token_at_offset(token.text_range().start()) {\n+        TokenAtOffset::Between(l, r) => {\n+            assert!(r == *token);\n+            l\n+        }\n+        TokenAtOffset::Single(n) => {\n+            assert!(n == *token);\n+            return Some(\"\".into());\n+        }\n+        TokenAtOffset::None => unreachable!(),\n+    };\n+    if ws.kind() != WHITESPACE {\n+        return None;\n+    }\n+    let text = ws.text();\n+    let pos = text.rfind('\\n').map(|it| it + 1).unwrap_or(0);\n+    Some(text[pos..].into())\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use test_utils::{add_cursor, assert_eq_text, extract_offset};\n+\n+    use crate::mock_analysis::single_file;\n+\n+    use super::*;\n+\n+    fn apply_on_enter(before: &str) -> Option<String> {\n+        let (offset, before) = extract_offset(before);\n+        let (analysis, file_id) = single_file(&before);\n+        let result = analysis.on_enter(FilePosition { offset, file_id }).unwrap()?;\n+\n+        assert_eq!(result.source_file_edits.len(), 1);\n+        let actual = result.source_file_edits[0].edit.apply(&before);\n+        let actual = add_cursor(&actual, result.cursor_position.unwrap().offset);\n+        Some(actual)\n+    }\n+\n+    fn do_check(ra_fixture_before: &str, ra_fixture_after: &str) {\n+        let actual = apply_on_enter(ra_fixture_before).unwrap();\n+        assert_eq_text!(ra_fixture_after, &actual);\n+    }\n+\n+    fn do_check_noop(ra_fixture_text: &str) {\n+        assert!(apply_on_enter(ra_fixture_text).is_none())\n+    }\n+\n+    #[test]\n+    fn test_on_enter() {\n+        do_check(\n+            r\"\n+/// Some docs<|>\n+fn foo() {\n+}\n+\",\n+            r\"\n+/// Some docs\n+/// <|>\n+fn foo() {\n+}\n+\",\n+        );\n+        do_check(\n+            r\"\n+impl S {\n+    /// Some<|> docs.\n+    fn foo() {}\n+}\n+\",\n+            r\"\n+impl S {\n+    /// Some\n+    /// <|> docs.\n+    fn foo() {}\n+}\n+\",\n+        );\n+        do_check(\n+            r\"\n+fn main() {\n+    // Fix<|> me\n+    let x = 1 + 1;\n+}\n+\",\n+            r\"\n+fn main() {\n+    // Fix\n+    // <|> me\n+    let x = 1 + 1;\n+}\n+\",\n+        );\n+        do_check(\n+            r\"\n+///<|> Some docs\n+fn foo() {\n+}\n+\",\n+            r\"\n+///\n+/// <|> Some docs\n+fn foo() {\n+}\n+\",\n+        );\n+        do_check_noop(\n+            r\"\n+fn main() {\n+    // Fix me<|>\n+    let x = 1 + 1;\n+}\n+\",\n+        );\n+\n+        do_check_noop(r\"<|>//! docz\");\n+    }\n+}"}]}