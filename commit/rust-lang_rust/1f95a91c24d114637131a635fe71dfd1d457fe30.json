{"sha": "1f95a91c24d114637131a635fe71dfd1d457fe30", "node_id": "MDY6Q29tbWl0NzI0NzEyOjFmOTVhOTFjMjRkMTE0NjM3MTMxYTYzNWZlNzFkZmQxZDQ1N2ZlMzA=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-08-21T14:38:35Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-08-27T15:43:15Z"}, "message": "Remove dependency on StringReader from rustdoc highlighter\n\nrustc_lexer is the lossless lexer, which is a better fit for\napproximate syntax highlighting.\n\nAs a side-effect, we can now syntax-highlight even broken code.", "tree": {"sha": "ab3fbe97a67ac50e81de6fca71fd50dcaf0109fa", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ab3fbe97a67ac50e81de6fca71fd50dcaf0109fa"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1f95a91c24d114637131a635fe71dfd1d457fe30", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1f95a91c24d114637131a635fe71dfd1d457fe30", "html_url": "https://github.com/rust-lang/rust/commit/1f95a91c24d114637131a635fe71dfd1d457fe30", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1f95a91c24d114637131a635fe71dfd1d457fe30/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f7cbb7a594658099ebb9d0008779511fe2fbe9ab", "url": "https://api.github.com/repos/rust-lang/rust/commits/f7cbb7a594658099ebb9d0008779511fe2fbe9ab", "html_url": "https://github.com/rust-lang/rust/commit/f7cbb7a594658099ebb9d0008779511fe2fbe9ab"}], "stats": {"total": 590, "additions": 234, "deletions": 356}, "files": [{"sha": "26557fc1cb7ecc428da35b4d62b3d773dc1d89a4", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 224, "deletions": 330, "changes": 554, "blob_url": "https://github.com/rust-lang/rust/blob/1f95a91c24d114637131a635fe71dfd1d457fe30/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1f95a91c24d114637131a635fe71dfd1d457fe30/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=1f95a91c24d114637131a635fe71dfd1d457fe30", "patch": "@@ -7,18 +7,12 @@\n \n use crate::html::escape::Escape;\n \n-use std::fmt::Display;\n-use std::io;\n-use std::io::prelude::*;\n+use std::fmt::{Display, Write};\n+use std::iter::Peekable;\n \n-use rustc_ast::token::{self, Token};\n-use rustc_data_structures::sync::Lrc;\n-use rustc_parse::lexer;\n-use rustc_session::parse::ParseSess;\n-use rustc_span::hygiene::SyntaxContext;\n-use rustc_span::source_map::SourceMap;\n-use rustc_span::symbol::{kw, sym};\n-use rustc_span::{BytePos, FileName, SourceFile, Span};\n+use rustc_lexer::{LiteralKind, TokenKind};\n+use rustc_span::symbol::Ident;\n+use rustc_span::with_default_session_globals;\n \n /// Highlights `src`, returning the HTML output.\n pub fn render_with_highlighting(\n@@ -28,7 +22,7 @@ pub fn render_with_highlighting(\n     tooltip: Option<(&str, &str)>,\n ) -> String {\n     debug!(\"highlighting: ================\\n{}\\n==============\", src);\n-    let mut out = Vec::new();\n+    let mut out = String::with_capacity(src.len());\n     if let Some((tooltip, class)) = tooltip {\n         write!(\n             out,\n@@ -39,60 +33,30 @@ pub fn render_with_highlighting(\n         .unwrap();\n     }\n \n-    let sess = ParseSess::with_silent_emitter();\n-    let source_file = sess\n-        .source_map()\n-        .new_source_file(FileName::Custom(String::from(\"rustdoc-highlighting\")), src);\n+    write_header(&mut out, class);\n+    write_code(&mut out, &src);\n+    write_footer(&mut out, playground_button);\n \n-    let classifier_source_file = Lrc::clone(&source_file);\n-    let highlight_result = rustc_driver::catch_fatal_errors(|| {\n-        let mut classifier = Classifier::new(&sess, classifier_source_file);\n-\n-        let mut highlighted_source = vec![];\n-        if classifier.write_source(&mut highlighted_source).is_err() {\n-            Err(())\n-        } else {\n-            Ok(String::from_utf8_lossy(&highlighted_source).into_owned())\n-        }\n-    })\n-    .unwrap_or(Err(()));\n-\n-    match highlight_result {\n-        Ok(highlighted_source) => {\n-            write_header(class, &mut out).unwrap();\n-            write!(out, \"{}\", highlighted_source).unwrap();\n-            write_footer(&mut out, playground_button).unwrap();\n-        }\n-        Err(()) => {\n-            // Get the source back out of the source map to avoid a copy in the happy path.\n-            let span =\n-                Span::new(BytePos(0), BytePos(source_file.byte_length()), SyntaxContext::root());\n-            let src = sess\n-                .source_map()\n-                .span_to_snippet(span)\n-                .expect(\"could not retrieve snippet from artificial source file\");\n-\n-            // If errors are encountered while trying to highlight, just emit\n-            // the unhighlighted source.\n-            write!(out, \"<pre><code>{}</code></pre>\", Escape(&src)).unwrap();\n-        }\n-    }\n+    out\n+}\n \n-    String::from_utf8_lossy(&out[..]).into_owned()\n+fn write_header(out: &mut String, class: Option<&str>) {\n+    write!(out, \"<div class=\\\"example-wrap\\\"><pre class=\\\"rust {}\\\">\\n\", class.unwrap_or_default())\n+        .unwrap()\n }\n \n-/// Processes a program (nested in the internal `lexer`), classifying strings of\n-/// text by highlighting category (`Class`). Calls out to a `Writer` to write\n-/// each span of text in sequence.\n-struct Classifier<'sess> {\n-    lexer: lexer::StringReader<'sess>,\n-    peek_token: Option<Token>,\n-    source_map: &'sess SourceMap,\n+fn write_code(out: &mut String, src: &str) {\n+    Classifier::new(src).highlight(&mut |highlight| {\n+        match highlight {\n+            Highlight::Token { text, class } => string(out, Escape(text), class),\n+            Highlight::EnterSpan { class } => enter_span(out, class),\n+            Highlight::ExitSpan => exit_span(out),\n+        };\n+    });\n+}\n \n-    // State of the classifier.\n-    in_attribute: bool,\n-    in_macro: bool,\n-    in_macro_nonterminal: bool,\n+fn write_footer(out: &mut String, playground_button: Option<&str>) {\n+    write!(out, \"</pre>{}</div>\\n\", playground_button.unwrap_or_default()).unwrap()\n }\n \n /// How a span of text is classified. Mostly corresponds to token kinds.\n@@ -119,335 +83,265 @@ enum Class {\n     QuestionMark,\n }\n \n-/// Trait that controls writing the output of syntax highlighting. Users should\n-/// implement this trait to customize writing output.\n-///\n-/// The classifier will call into the `Writer` implementation as it finds spans\n-/// of text to highlight. Exactly how that text should be highlighted is up to\n-/// the implementation.\n-trait Writer {\n-    /// Called when we start processing a span of text that should be highlighted.\n-    /// The `Class` argument specifies how it should be highlighted.\n-    fn enter_span(&mut self, _: Class) -> io::Result<()>;\n-\n-    /// Called at the end of a span of highlighted text.\n-    fn exit_span(&mut self) -> io::Result<()>;\n-\n-    /// Called for a span of text. If the text should be highlighted differently from the\n-    /// surrounding text, then the `Class` argument will be a value other than `None`.\n-    ///\n-    /// The following sequences of callbacks are equivalent:\n-    /// ```plain\n-    ///     enter_span(Foo), string(\"text\", None), exit_span()\n-    ///     string(\"text\", Foo)\n-    /// ```\n-    /// The latter can be thought of as a shorthand for the former, which is\n-    /// more flexible.\n-    fn string<T: Display>(&mut self, text: T, klass: Class) -> io::Result<()>;\n-}\n-\n-// Implement `Writer` for anything that can be written to, this just implements\n-// the default rustdoc behaviour.\n-impl<U: Write> Writer for U {\n-    fn string<T: Display>(&mut self, text: T, klass: Class) -> io::Result<()> {\n-        match klass {\n-            Class::None => write!(self, \"{}\", text),\n-            klass => write!(self, \"<span class=\\\"{}\\\">{}</span>\", klass.rustdoc_class(), text),\n+impl Class {\n+    /// Returns the css class expected by rustdoc for each `Class`.\n+    fn as_html(self) -> &'static str {\n+        match self {\n+            Class::None => \"\",\n+            Class::Comment => \"comment\",\n+            Class::DocComment => \"doccomment\",\n+            Class::Attribute => \"attribute\",\n+            Class::KeyWord => \"kw\",\n+            Class::RefKeyWord => \"kw-2\",\n+            Class::Self_ => \"self\",\n+            Class::Op => \"op\",\n+            Class::Macro => \"macro\",\n+            Class::MacroNonTerminal => \"macro-nonterminal\",\n+            Class::String => \"string\",\n+            Class::Number => \"number\",\n+            Class::Bool => \"bool-val\",\n+            Class::Ident => \"ident\",\n+            Class::Lifetime => \"lifetime\",\n+            Class::PreludeTy => \"prelude-ty\",\n+            Class::PreludeVal => \"prelude-val\",\n+            Class::QuestionMark => \"question-mark\",\n         }\n     }\n-\n-    fn enter_span(&mut self, klass: Class) -> io::Result<()> {\n-        write!(self, \"<span class=\\\"{}\\\">\", klass.rustdoc_class())\n-    }\n-\n-    fn exit_span(&mut self) -> io::Result<()> {\n-        write!(self, \"</span>\")\n-    }\n }\n \n-#[derive(Debug)]\n-enum HighlightError {\n-    LexError,\n-    IoError(io::Error),\n+enum Highlight<'a> {\n+    Token { text: &'a str, class: Class },\n+    EnterSpan { class: Class },\n+    ExitSpan,\n }\n \n-impl From<io::Error> for HighlightError {\n-    fn from(err: io::Error) -> Self {\n-        HighlightError::IoError(err)\n-    }\n+struct TokenIter<'a> {\n+    src: &'a str,\n }\n \n-impl<'sess> Classifier<'sess> {\n-    fn new(sess: &ParseSess, source_file: Lrc<SourceFile>) -> Classifier<'_> {\n-        let lexer = lexer::StringReader::new(sess, source_file, None);\n-\n-        Classifier {\n-            lexer,\n-            peek_token: None,\n-            source_map: sess.source_map(),\n-            in_attribute: false,\n-            in_macro: false,\n-            in_macro_nonterminal: false,\n+impl Iterator for TokenIter<'a> {\n+    type Item = (TokenKind, &'a str);\n+    fn next(&mut self) -> Option<(TokenKind, &'a str)> {\n+        if self.src.is_empty() {\n+            return None;\n         }\n+        let token = rustc_lexer::first_token(self.src);\n+        let (text, rest) = self.src.split_at(token.len);\n+        self.src = rest;\n+        Some((token.kind, text))\n     }\n+}\n \n-    /// Gets the next token out of the lexer.\n-    fn try_next_token(&mut self) -> Result<Token, HighlightError> {\n-        if let Some(token) = self.peek_token.take() {\n-            return Ok(token);\n-        }\n-        let token = self.lexer.next_token();\n-        if let token::Unknown(..) = &token.kind {\n-            return Err(HighlightError::LexError);\n-        }\n-        Ok(token)\n-    }\n+/// Processes program tokens, classifying strings of text by highlighting\n+/// category (`Class`).\n+struct Classifier<'a> {\n+    tokens: Peekable<TokenIter<'a>>,\n+    in_attribute: bool,\n+    in_macro: bool,\n+    in_macro_nonterminal: bool,\n+}\n \n-    fn peek(&mut self) -> Result<&Token, HighlightError> {\n-        if self.peek_token.is_none() {\n-            let token = self.lexer.next_token();\n-            if let token::Unknown(..) = &token.kind {\n-                return Err(HighlightError::LexError);\n-            }\n-            self.peek_token = Some(token);\n-        }\n-        Ok(self.peek_token.as_ref().unwrap())\n+impl<'a> Classifier<'a> {\n+    fn new(src: &str) -> Classifier<'_> {\n+        let tokens = TokenIter { src }.peekable();\n+        Classifier { tokens, in_attribute: false, in_macro: false, in_macro_nonterminal: false }\n     }\n \n-    /// Exhausts the `lexer` writing the output into `out`.\n+    /// Exhausts the `Classifier` writing the output into `sink`.\n     ///\n     /// The general structure for this method is to iterate over each token,\n-    /// possibly giving it an HTML span with a class specifying what flavor of token\n-    /// is used. All source code emission is done as slices from the source map,\n-    /// not from the tokens themselves, in order to stay true to the original\n-    /// source.\n-    fn write_source<W: Writer>(&mut self, out: &mut W) -> Result<(), HighlightError> {\n-        loop {\n-            let mut next = self.try_next_token()?;\n-            if next == token::Eof {\n-                break;\n-            }\n-\n-            // Glue any tokens that need to be glued.\n-            if let Some(joint) = next.glue(self.peek()?) {\n-                next = joint;\n-                let _ = self.try_next_token()?;\n+    /// possibly giving it an HTML span with a class specifying what flavor of\n+    /// token is used.\n+    fn highlight(mut self, sink: &mut dyn FnMut(Highlight<'a>)) {\n+        with_default_session_globals(|| {\n+            while let Some((token, text)) = self.tokens.next() {\n+                self.advance(token, text, sink);\n             }\n-\n-            self.write_token(out, next)?;\n-        }\n-\n-        Ok(())\n+        })\n     }\n \n-    // Handles an individual token from the lexer.\n-    fn write_token<W: Writer>(&mut self, out: &mut W, token: Token) -> Result<(), HighlightError> {\n-        let klass = match token.kind {\n-            token::Shebang(s) => {\n-                out.string(Escape(&s.as_str()), Class::None)?;\n-                return Ok(());\n-            }\n-\n-            token::Whitespace | token::Unknown(..) => Class::None,\n-            token::Comment => Class::Comment,\n-            token::DocComment(..) => Class::DocComment,\n-\n-            // If this '&' or '*' token is followed by a non-whitespace token, assume that it's the\n-            // reference or dereference operator or a reference or pointer type, instead of the\n-            // bit-and or multiplication operator.\n-            token::BinOp(token::And | token::Star) if self.peek()? != &token::Whitespace => {\n-                Class::RefKeyWord\n+    /// Single step of highlighting. This will classify `token`, but maybe also\n+    /// a couple of following ones as well.\n+    fn advance(&mut self, token: TokenKind, text: &'a str, sink: &mut dyn FnMut(Highlight<'a>)) {\n+        let lookahead = self.peek();\n+        let class = match token {\n+            TokenKind::Whitespace => Class::None,\n+            TokenKind::LineComment { doc_style } | TokenKind::BlockComment { doc_style, .. } => {\n+                if doc_style.is_some() {\n+                    Class::DocComment\n+                } else {\n+                    Class::Comment\n+                }\n             }\n-\n             // Consider this as part of a macro invocation if there was a\n             // leading identifier.\n-            token::Not if self.in_macro => {\n+            TokenKind::Bang if self.in_macro => {\n                 self.in_macro = false;\n                 Class::Macro\n             }\n \n+            // Assume that '&' or '*' is the reference or dereference operator\n+            // or a reference or pointer type. Unless, of course, it looks like\n+            // a logical and or a multiplication operator: `&&` or `* `.\n+            TokenKind::Star => match lookahead {\n+                Some(TokenKind::Whitespace) => Class::Op,\n+                _ => Class::RefKeyWord,\n+            },\n+            TokenKind::And => match lookahead {\n+                Some(TokenKind::And) => {\n+                    let _and = self.tokens.next();\n+                    sink(Highlight::Token { text: \"&&\", class: Class::Op });\n+                    return;\n+                }\n+                Some(TokenKind::Eq) => {\n+                    let _eq = self.tokens.next();\n+                    sink(Highlight::Token { text: \"&=\", class: Class::Op });\n+                    return;\n+                }\n+                Some(TokenKind::Whitespace) => Class::Op,\n+                _ => Class::RefKeyWord,\n+            },\n+\n             // Operators.\n-            token::Eq\n-            | token::Lt\n-            | token::Le\n-            | token::EqEq\n-            | token::Ne\n-            | token::Ge\n-            | token::Gt\n-            | token::AndAnd\n-            | token::OrOr\n-            | token::Not\n-            | token::BinOp(..)\n-            | token::RArrow\n-            | token::BinOpEq(..)\n-            | token::FatArrow => Class::Op,\n+            TokenKind::Minus\n+            | TokenKind::Plus\n+            | TokenKind::Or\n+            | TokenKind::Slash\n+            | TokenKind::Caret\n+            | TokenKind::Percent\n+            | TokenKind::Bang\n+            | TokenKind::Eq\n+            | TokenKind::Lt\n+            | TokenKind::Gt => Class::Op,\n \n             // Miscellaneous, no highlighting.\n-            token::Dot\n-            | token::DotDot\n-            | token::DotDotDot\n-            | token::DotDotEq\n-            | token::Comma\n-            | token::Semi\n-            | token::Colon\n-            | token::ModSep\n-            | token::LArrow\n-            | token::OpenDelim(_)\n-            | token::CloseDelim(token::Brace | token::Paren | token::NoDelim) => Class::None,\n-\n-            token::Question => Class::QuestionMark,\n-\n-            token::Dollar => {\n-                if self.peek()?.is_ident() {\n+            TokenKind::Dot\n+            | TokenKind::Semi\n+            | TokenKind::Comma\n+            | TokenKind::OpenParen\n+            | TokenKind::CloseParen\n+            | TokenKind::OpenBrace\n+            | TokenKind::CloseBrace\n+            | TokenKind::OpenBracket\n+            | TokenKind::At\n+            | TokenKind::Tilde\n+            | TokenKind::Colon\n+            | TokenKind::Unknown => Class::None,\n+\n+            TokenKind::Question => Class::QuestionMark,\n+\n+            TokenKind::Dollar => match lookahead {\n+                Some(TokenKind::Ident) => {\n                     self.in_macro_nonterminal = true;\n                     Class::MacroNonTerminal\n-                } else {\n-                    Class::None\n                 }\n-            }\n+                _ => Class::None,\n+            },\n \n             // This might be the start of an attribute. We're going to want to\n             // continue highlighting it as an attribute until the ending ']' is\n             // seen, so skip out early. Down below we terminate the attribute\n             // span when we see the ']'.\n-            token::Pound => {\n-                // We can't be sure that our # begins an attribute (it could\n-                // just be appearing in a macro) until we read either `#![` or\n-                // `#[` from the input stream.\n-                //\n-                // We don't want to start highlighting as an attribute until\n-                // we're confident there is going to be a ] coming up, as\n-                // otherwise # tokens in macros highlight the rest of the input\n-                // as an attribute.\n-\n-                // Case 1: #![inner_attribute]\n-                if self.peek()? == &token::Not {\n-                    self.try_next_token()?; // NOTE: consumes `!` token!\n-                    if self.peek()? == &token::OpenDelim(token::Bracket) {\n+            TokenKind::Pound => {\n+                match lookahead {\n+                    // Case 1: #![inner_attribute]\n+                    Some(TokenKind::Bang) => {\n+                        let _not = self.tokens.next().unwrap();\n+                        if let Some(TokenKind::OpenBracket) = self.peek() {\n+                            self.in_attribute = true;\n+                            sink(Highlight::EnterSpan { class: Class::Attribute });\n+                        }\n+                        sink(Highlight::Token { text: \"#\", class: Class::None });\n+                        sink(Highlight::Token { text: \"!\", class: Class::None });\n+                        return;\n+                    }\n+                    // Case 2: #[outer_attribute]\n+                    Some(TokenKind::OpenBracket) => {\n                         self.in_attribute = true;\n-                        out.enter_span(Class::Attribute)?;\n+                        sink(Highlight::EnterSpan { class: Class::Attribute });\n                     }\n-                    out.string(\"#\", Class::None)?;\n-                    out.string(\"!\", Class::None)?;\n-                    return Ok(());\n-                }\n-\n-                // Case 2: #[outer_attribute]\n-                if self.peek()? == &token::OpenDelim(token::Bracket) {\n-                    self.in_attribute = true;\n-                    out.enter_span(Class::Attribute)?;\n+                    _ => (),\n                 }\n-                out.string(\"#\", Class::None)?;\n-                return Ok(());\n+                Class::None\n             }\n-            token::CloseDelim(token::Bracket) => {\n+            TokenKind::CloseBracket => {\n                 if self.in_attribute {\n                     self.in_attribute = false;\n-                    out.string(\"]\", Class::None)?;\n-                    out.exit_span()?;\n-                    return Ok(());\n-                } else {\n-                    Class::None\n+                    sink(Highlight::Token { text: \"]\", class: Class::None });\n+                    sink(Highlight::ExitSpan);\n+                    return;\n                 }\n+                Class::None\n             }\n-\n-            token::Literal(lit) => {\n-                match lit.kind {\n-                    // Text literals.\n-                    token::Byte\n-                    | token::Char\n-                    | token::Err\n-                    | token::ByteStr\n-                    | token::ByteStrRaw(..)\n-                    | token::Str\n-                    | token::StrRaw(..) => Class::String,\n-\n-                    // Number literals.\n-                    token::Integer | token::Float => Class::Number,\n-\n-                    token::Bool => panic!(\"literal token contains `Lit::Bool`\"),\n-                }\n+            TokenKind::Literal { kind, .. } => match kind {\n+                // Text literals.\n+                LiteralKind::Byte { .. }\n+                | LiteralKind::Char { .. }\n+                | LiteralKind::Str { .. }\n+                | LiteralKind::ByteStr { .. }\n+                | LiteralKind::RawStr { .. }\n+                | LiteralKind::RawByteStr { .. } => Class::String,\n+                // Number literals.\n+                LiteralKind::Float { .. } | LiteralKind::Int { .. } => Class::Number,\n+            },\n+            TokenKind::Ident | TokenKind::RawIdent if lookahead == Some(TokenKind::Bang) => {\n+                self.in_macro = true;\n+                Class::Macro\n             }\n-\n-            // Keywords are also included in the identifier set.\n-            token::Ident(name, is_raw) => match name {\n-                kw::Ref | kw::Mut if !is_raw => Class::RefKeyWord,\n-\n-                kw::SelfLower | kw::SelfUpper => Class::Self_,\n-                kw::False | kw::True if !is_raw => Class::Bool,\n-\n-                sym::Option | sym::Result => Class::PreludeTy,\n-                sym::Some | sym::None | sym::Ok | sym::Err => Class::PreludeVal,\n-\n-                _ if token.is_reserved_ident() => Class::KeyWord,\n-\n-                _ => {\n-                    if self.in_macro_nonterminal {\n-                        self.in_macro_nonterminal = false;\n-                        Class::MacroNonTerminal\n-                    } else if self.peek()? == &token::Not {\n-                        self.in_macro = true;\n-                        Class::Macro\n-                    } else {\n-                        Class::Ident\n-                    }\n+            TokenKind::Ident => match text {\n+                \"ref\" | \"mut\" => Class::RefKeyWord,\n+                \"self\" | \"Self\" => Class::Self_,\n+                \"false\" | \"true\" => Class::Bool,\n+                \"Option\" | \"Result\" => Class::PreludeTy,\n+                \"Some\" | \"None\" | \"Ok\" | \"Err\" => Class::PreludeVal,\n+                // Keywords are also included in the identifier set.\n+                _ if Ident::from_str(text).is_reserved() => Class::KeyWord,\n+                _ if self.in_macro_nonterminal => {\n+                    self.in_macro_nonterminal = false;\n+                    Class::MacroNonTerminal\n                 }\n+                _ => Class::Ident,\n             },\n-\n-            token::Lifetime(..) => Class::Lifetime,\n-\n-            token::Eof\n-            | token::Interpolated(..)\n-            | token::Tilde\n-            | token::At\n-            | token::SingleQuote => Class::None,\n+            TokenKind::RawIdent => Class::Ident,\n+            TokenKind::Lifetime { .. } => Class::Lifetime,\n         };\n-\n         // Anything that didn't return above is the simple case where we the\n         // class just spans a single token, so we can use the `string` method.\n-        out.string(Escape(&self.snip(token.span)), klass)?;\n-\n-        Ok(())\n+        sink(Highlight::Token { text, class });\n     }\n \n-    // Helper function to get a snippet from the source_map.\n-    fn snip(&self, sp: Span) -> String {\n-        self.source_map.span_to_snippet(sp).unwrap()\n+    fn peek(&mut self) -> Option<TokenKind> {\n+        self.tokens.peek().map(|(toke_kind, _text)| *toke_kind)\n     }\n }\n \n-impl Class {\n-    /// Returns the css class expected by rustdoc for each `Class`.\n-    fn rustdoc_class(self) -> &'static str {\n-        match self {\n-            Class::None => \"\",\n-            Class::Comment => \"comment\",\n-            Class::DocComment => \"doccomment\",\n-            Class::Attribute => \"attribute\",\n-            Class::KeyWord => \"kw\",\n-            Class::RefKeyWord => \"kw-2\",\n-            Class::Self_ => \"self\",\n-            Class::Op => \"op\",\n-            Class::Macro => \"macro\",\n-            Class::MacroNonTerminal => \"macro-nonterminal\",\n-            Class::String => \"string\",\n-            Class::Number => \"number\",\n-            Class::Bool => \"bool-val\",\n-            Class::Ident => \"ident\",\n-            Class::Lifetime => \"lifetime\",\n-            Class::PreludeTy => \"prelude-ty\",\n-            Class::PreludeVal => \"prelude-val\",\n-            Class::QuestionMark => \"question-mark\",\n-        }\n-    }\n+/// Called when we start processing a span of text that should be highlighted.\n+/// The `Class` argument specifies how it should be highlighted.\n+fn enter_span(out: &mut String, klass: Class) {\n+    write!(out, \"<span class=\\\"{}\\\">\", klass.as_html()).unwrap()\n }\n \n-fn write_header(class: Option<&str>, out: &mut dyn Write) -> io::Result<()> {\n-    write!(out, \"<div class=\\\"example-wrap\\\"><pre class=\\\"rust {}\\\">\\n\", class.unwrap_or(\"\"))\n+/// Called at the end of a span of highlighted text.\n+fn exit_span(out: &mut String) {\n+    write!(out, \"</span>\").unwrap()\n }\n \n-fn write_footer(out: &mut dyn Write, playground_button: Option<&str>) -> io::Result<()> {\n-    write!(out, \"</pre>{}</div>\\n\", if let Some(button) = playground_button { button } else { \"\" })\n+/// Called for a span of text. If the text should be highlighted differently\n+/// from the surrounding text, then the `Class` argument will be a value other\n+/// than `None`.\n+///\n+/// The following sequences of callbacks are equivalent:\n+/// ```plain\n+///     enter_span(Foo), string(\"text\", None), exit_span()\n+///     string(\"text\", Foo)\n+/// ```\n+/// The latter can be thought of as a shorthand for the former, which is more\n+/// flexible.\n+fn string<T: Display>(out: &mut String, text: T, klass: Class) {\n+    match klass {\n+        Class::None => write!(out, \"{}\", text).unwrap(),\n+        klass => write!(out, \"<span class=\\\"{}\\\">{}</span>\", klass.as_html(), text).unwrap(),\n+    }\n }\n \n #[cfg(test)]"}, {"sha": "756751e47e85d87b0dcaa6886fc08a9abe14213c", "filename": "src/librustdoc/html/highlight/tests.rs", "status": "modified", "additions": 4, "deletions": 20, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/1f95a91c24d114637131a635fe71dfd1d457fe30/src%2Flibrustdoc%2Fhtml%2Fhighlight%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1f95a91c24d114637131a635fe71dfd1d457fe30/src%2Flibrustdoc%2Fhtml%2Fhighlight%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight%2Ftests.rs?ref=1f95a91c24d114637131a635fe71dfd1d457fe30", "patch": "@@ -1,25 +1,9 @@\n-use rustc_session::parse::ParseSess;\n-use rustc_span::edition::Edition;\n-use rustc_span::with_session_globals;\n-use rustc_span::FileName;\n-\n-use super::Classifier;\n+use super::write_code;\n \n fn highlight(src: &str) -> String {\n-    let mut out = vec![];\n-\n-    with_session_globals(Edition::Edition2018, || {\n-        let sess = ParseSess::with_silent_emitter();\n-        let source_file = sess.source_map().new_source_file(\n-            FileName::Custom(String::from(\"rustdoc-highlighting\")),\n-            src.to_owned(),\n-        );\n-\n-        let mut classifier = Classifier::new(&sess, source_file);\n-        classifier.write_source(&mut out).unwrap();\n-    });\n-\n-    String::from_utf8(out).unwrap()\n+    let mut out = String::new();\n+    write_code(&mut out, src);\n+    out\n }\n \n #[test]"}, {"sha": "920877028d06a45e4dab83f755f04b00b7cd1265", "filename": "src/test/rustdoc/bad-codeblock-syntax.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/1f95a91c24d114637131a635fe71dfd1d457fe30/src%2Ftest%2Frustdoc%2Fbad-codeblock-syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1f95a91c24d114637131a635fe71dfd1d457fe30/src%2Ftest%2Frustdoc%2Fbad-codeblock-syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frustdoc%2Fbad-codeblock-syntax.rs?ref=1f95a91c24d114637131a635fe71dfd1d457fe30", "patch": "@@ -1,41 +1,41 @@\n // @has bad_codeblock_syntax/fn.foo.html\n-// @has - '//*[@class=\"docblock\"]/pre/code' '\\_'\n+// @has - '//*[@class=\"docblock\"]' '\\_'\n /// ```\n /// \\_\n /// ```\n pub fn foo() {}\n \n // @has bad_codeblock_syntax/fn.bar.html\n-// @has - '//*[@class=\"docblock\"]/pre/code' '`baz::foobar`'\n+// @has - '//*[@class=\"docblock\"]' '`baz::foobar`'\n /// ```\n /// `baz::foobar`\n /// ```\n pub fn bar() {}\n \n // @has bad_codeblock_syntax/fn.quux.html\n-// @has - '//*[@class=\"docblock\"]/pre/code' '\\_'\n+// @has - '//*[@class=\"docblock\"]' '\\_'\n /// ```rust\n /// \\_\n /// ```\n pub fn quux() {}\n \n // @has bad_codeblock_syntax/fn.ok.html\n-// @has - '//*[@class=\"docblock\"]/pre/code[@class=\"language-text\"]' '\\_'\n+// @has - '//*[@class=\"docblock\"]' '\\_'\n /// ```text\n /// \\_\n /// ```\n pub fn ok() {}\n \n // @has bad_codeblock_syntax/fn.escape.html\n-// @has - '//*[@class=\"docblock\"]/pre/code' '\\_ <script>alert(\"not valid Rust\");</script>'\n+// @has - '//*[@class=\"docblock\"]' '\\_ <script>alert(\"not valid Rust\");</script>'\n /// ```\n /// \\_\n /// <script>alert(\"not valid Rust\");</script>\n /// ```\n pub fn escape() {}\n \n // @has bad_codeblock_syntax/fn.unterminated.html\n-// @has - '//*[@class=\"docblock\"]/pre/code' '\"unterminated'\n+// @has - '//*[@class=\"docblock\"]' '\"unterminated'\n /// ```\n /// \"unterminated\n /// ```"}]}