{"sha": "db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "node_id": "C_kwDOAAsO6NoAKGRiNzVkN2UxNGI2YzUxNTdlMTJmZWE0YTExNThlOWRkNThlOTJjMzY", "commit": {"author": {"name": "Dylan DPC", "email": "99973273+Dylan-DPC@users.noreply.github.com", "date": "2022-09-13T11:21:31Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2022-09-13T11:21:31Z"}, "message": "Rollup merge of #101602 - nnethercote:AttrTokenStream, r=petrochenkov\n\nStreamline `AttrAnnotatedTokenStream`\n\nr? ```@petrochenkov```", "tree": {"sha": "fe5514f54403440f1b13ff21494af8532879f349", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/fe5514f54403440f1b13ff21494af8532879f349"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJjIGe7CRBK7hj4Ov3rIwAAw/kIAK7CJLVAMN6FET/JE2AJKoMX\n5whZZVcMtuUwZXqK8aLgFfv8IHW2cWecJyBXxVsnq1ypy3yMJTGoT8zHaYKNpLHV\nhw8bZ2jhg2DfetDjpADpOvKODslkUfEBp0Im3mCidAZIXK5hy5zeGBBOod3fZ4wm\nQbo37HjzpO+nZh9gU0FIY4Bx04Tsfok5b+2cNhjNK+DYNifoSWNiMeBoq+iJjoiJ\nUoJEsvvUPJWUCcTzxjWV2UlPC34UI/4woaq+lgC2A7X6+wFZYPHN/M4XT353lg2W\nSWGlLZNQNJjwleTb5tBfWfoZ+Jjs1ED5rhNIQVoIH7M7CfLbfHZujKOEwoM8aLQ=\n=161P\n-----END PGP SIGNATURE-----\n", "payload": "tree fe5514f54403440f1b13ff21494af8532879f349\nparent c81575657c9591d07c12778fe74c326e5ac76558\nparent d2df07c425f9b390c33e0ac31674ce4794352b3a\nauthor Dylan DPC <99973273+Dylan-DPC@users.noreply.github.com> 1663068091 +0530\ncommitter GitHub <noreply@github.com> 1663068091 +0530\n\nRollup merge of #101602 - nnethercote:AttrTokenStream, r=petrochenkov\n\nStreamline `AttrAnnotatedTokenStream`\n\nr? ```@petrochenkov```\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "html_url": "https://github.com/rust-lang/rust/commit/db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/comments", "author": {"login": "Dylan-DPC", "id": 99973273, "node_id": "U_kgDOBfV4mQ", "avatar_url": "https://avatars.githubusercontent.com/u/99973273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dylan-DPC", "html_url": "https://github.com/Dylan-DPC", "followers_url": "https://api.github.com/users/Dylan-DPC/followers", "following_url": "https://api.github.com/users/Dylan-DPC/following{/other_user}", "gists_url": "https://api.github.com/users/Dylan-DPC/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dylan-DPC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dylan-DPC/subscriptions", "organizations_url": "https://api.github.com/users/Dylan-DPC/orgs", "repos_url": "https://api.github.com/users/Dylan-DPC/repos", "events_url": "https://api.github.com/users/Dylan-DPC/events{/privacy}", "received_events_url": "https://api.github.com/users/Dylan-DPC/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c81575657c9591d07c12778fe74c326e5ac76558", "url": "https://api.github.com/repos/rust-lang/rust/commits/c81575657c9591d07c12778fe74c326e5ac76558", "html_url": "https://github.com/rust-lang/rust/commit/c81575657c9591d07c12778fe74c326e5ac76558"}, {"sha": "d2df07c425f9b390c33e0ac31674ce4794352b3a", "url": "https://api.github.com/repos/rust-lang/rust/commits/d2df07c425f9b390c33e0ac31674ce4794352b3a", "html_url": "https://github.com/rust-lang/rust/commit/d2df07c425f9b390c33e0ac31674ce4794352b3a"}], "stats": {"total": 381, "additions": 181, "deletions": 200}, "files": [{"sha": "5e4288c344be2a995168775b8f7ddc20fdc82666", "filename": "compiler/rustc_ast/src/ast.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -24,7 +24,7 @@ pub use UnsafeSource::*;\n \n use crate::ptr::P;\n use crate::token::{self, CommentKind, Delimiter};\n-use crate::tokenstream::{DelimSpan, LazyTokenStream, TokenStream};\n+use crate::tokenstream::{DelimSpan, LazyAttrTokenStream, TokenStream};\n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n use rustc_data_structures::stack::ensure_sufficient_stack;\n use rustc_data_structures::sync::Lrc;\n@@ -91,7 +91,7 @@ pub struct Path {\n     /// The segments in the path: the things separated by `::`.\n     /// Global paths begin with `kw::PathRoot`.\n     pub segments: Vec<PathSegment>,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl PartialEq<Symbol> for Path {\n@@ -534,7 +534,7 @@ pub struct Block {\n     /// Distinguishes between `unsafe { ... }` and `{ ... }`.\n     pub rules: BlockCheckMode,\n     pub span: Span,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n     /// The following *isn't* a parse error, but will cause multiple errors in following stages.\n     /// ```compile_fail\n     /// let x = {\n@@ -553,7 +553,7 @@ pub struct Pat {\n     pub id: NodeId,\n     pub kind: PatKind,\n     pub span: Span,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl Pat {\n@@ -937,8 +937,8 @@ impl Stmt {\n     /// a trailing semicolon.\n     ///\n     /// This only modifies the parsed AST struct, not the attached\n-    /// `LazyTokenStream`. The parser is responsible for calling\n-    /// `CreateTokenStream::add_trailing_semi` when there is actually\n+    /// `LazyAttrTokenStream`. The parser is responsible for calling\n+    /// `ToAttrTokenStream::add_trailing_semi` when there is actually\n     /// a semicolon in the tokenstream.\n     pub fn add_trailing_semicolon(mut self) -> Self {\n         self.kind = match self.kind {\n@@ -984,7 +984,7 @@ pub struct MacCallStmt {\n     pub mac: P<MacCall>,\n     pub style: MacStmtStyle,\n     pub attrs: AttrVec,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n #[derive(Clone, Copy, PartialEq, Encodable, Decodable, Debug)]\n@@ -1009,7 +1009,7 @@ pub struct Local {\n     pub kind: LocalKind,\n     pub span: Span,\n     pub attrs: AttrVec,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n #[derive(Clone, Encodable, Decodable, Debug)]\n@@ -1108,7 +1108,7 @@ pub struct Expr {\n     pub kind: ExprKind,\n     pub span: Span,\n     pub attrs: AttrVec,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl Expr {\n@@ -1967,7 +1967,7 @@ pub struct Ty {\n     pub id: NodeId,\n     pub kind: TyKind,\n     pub span: Span,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl Clone for Ty {\n@@ -2532,7 +2532,7 @@ impl<D: Decoder> Decodable<D> for AttrId {\n pub struct AttrItem {\n     pub path: Path,\n     pub args: MacArgs,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n /// A list of attributes.\n@@ -2552,7 +2552,7 @@ pub struct Attribute {\n #[derive(Clone, Encodable, Decodable, Debug)]\n pub struct NormalAttr {\n     pub item: AttrItem,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n #[derive(Clone, Encodable, Decodable, Debug)]\n@@ -2603,7 +2603,7 @@ impl PolyTraitRef {\n pub struct Visibility {\n     pub kind: VisibilityKind,\n     pub span: Span,\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n #[derive(Clone, Encodable, Decodable, Debug)]\n@@ -2689,7 +2689,7 @@ pub struct Item<K = ItemKind> {\n     ///\n     /// Note that the tokens here do not include the outer attributes, but will\n     /// include inner attributes.\n-    pub tokens: Option<LazyTokenStream>,\n+    pub tokens: Option<LazyAttrTokenStream>,\n }\n \n impl Item {"}, {"sha": "1b31be07f7ad1b1cc8cdb93b80fc463ab7d8e64b", "filename": "compiler/rustc_ast/src/ast_traits.rs", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast_traits.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -4,7 +4,7 @@\n \n use crate::ptr::P;\n use crate::token::Nonterminal;\n-use crate::tokenstream::LazyTokenStream;\n+use crate::tokenstream::LazyAttrTokenStream;\n use crate::{Arm, Crate, ExprField, FieldDef, GenericParam, Param, PatField, Variant};\n use crate::{AssocItem, Expr, ForeignItem, Item, NodeId};\n use crate::{AttrItem, AttrKind, Block, Pat, Path, Ty, Visibility};\n@@ -124,18 +124,18 @@ impl HasSpan for AttrItem {\n \n /// A trait for AST nodes having (or not having) collected tokens.\n pub trait HasTokens {\n-    fn tokens(&self) -> Option<&LazyTokenStream>;\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>>;\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream>;\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>>;\n }\n \n macro_rules! impl_has_tokens {\n     ($($T:ty),+ $(,)?) => {\n         $(\n             impl HasTokens for $T {\n-                fn tokens(&self) -> Option<&LazyTokenStream> {\n+                fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n                     self.tokens.as_ref()\n                 }\n-                fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+                fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n                     Some(&mut self.tokens)\n                 }\n             }\n@@ -147,10 +147,10 @@ macro_rules! impl_has_tokens_none {\n     ($($T:ty),+ $(,)?) => {\n         $(\n             impl HasTokens for $T {\n-                fn tokens(&self) -> Option<&LazyTokenStream> {\n+                fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n                     None\n                 }\n-                fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+                fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n                     None\n                 }\n             }\n@@ -162,25 +162,25 @@ impl_has_tokens!(AssocItem, AttrItem, Block, Expr, ForeignItem, Item, Pat, Path,\n impl_has_tokens_none!(Arm, ExprField, FieldDef, GenericParam, Param, PatField, Variant);\n \n impl<T: AstDeref<Target: HasTokens>> HasTokens for T {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         self.ast_deref().tokens()\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         self.ast_deref_mut().tokens_mut()\n     }\n }\n \n impl<T: HasTokens> HasTokens for Option<T> {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         self.as_ref().and_then(|inner| inner.tokens())\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         self.as_mut().and_then(|inner| inner.tokens_mut())\n     }\n }\n \n impl HasTokens for StmtKind {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         match self {\n             StmtKind::Local(local) => local.tokens.as_ref(),\n             StmtKind::Item(item) => item.tokens(),\n@@ -189,7 +189,7 @@ impl HasTokens for StmtKind {\n             StmtKind::MacCall(mac) => mac.tokens.as_ref(),\n         }\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         match self {\n             StmtKind::Local(local) => Some(&mut local.tokens),\n             StmtKind::Item(item) => item.tokens_mut(),\n@@ -201,24 +201,24 @@ impl HasTokens for StmtKind {\n }\n \n impl HasTokens for Stmt {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         self.kind.tokens()\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         self.kind.tokens_mut()\n     }\n }\n \n impl HasTokens for Attribute {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         match &self.kind {\n             AttrKind::Normal(normal) => normal.tokens.as_ref(),\n             kind @ AttrKind::DocComment(..) => {\n                 panic!(\"Called tokens on doc comment attr {:?}\", kind)\n             }\n         }\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         Some(match &mut self.kind {\n             AttrKind::Normal(normal) => &mut normal.tokens,\n             kind @ AttrKind::DocComment(..) => {\n@@ -229,7 +229,7 @@ impl HasTokens for Attribute {\n }\n \n impl HasTokens for Nonterminal {\n-    fn tokens(&self) -> Option<&LazyTokenStream> {\n+    fn tokens(&self) -> Option<&LazyAttrTokenStream> {\n         match self {\n             Nonterminal::NtItem(item) => item.tokens(),\n             Nonterminal::NtStmt(stmt) => stmt.tokens(),\n@@ -243,7 +243,7 @@ impl HasTokens for Nonterminal {\n             Nonterminal::NtIdent(..) | Nonterminal::NtLifetime(..) => None,\n         }\n     }\n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyAttrTokenStream>> {\n         match self {\n             Nonterminal::NtItem(item) => item.tokens_mut(),\n             Nonterminal::NtStmt(stmt) => stmt.tokens_mut(),"}, {"sha": "a40508494cdc1d93f349eee8420ae02ddde2f306", "filename": "compiler/rustc_ast/src/attr/mod.rs", "status": "modified", "additions": 8, "deletions": 11, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -7,9 +7,8 @@ use crate::ast::{MacArgs, MacArgsEq, MacDelimiter, MetaItem, MetaItemKind, Neste\n use crate::ast::{Path, PathSegment};\n use crate::ptr::P;\n use crate::token::{self, CommentKind, Delimiter, Token};\n-use crate::tokenstream::{AttrAnnotatedTokenStream, AttrAnnotatedTokenTree};\n use crate::tokenstream::{DelimSpan, Spacing, TokenTree};\n-use crate::tokenstream::{LazyTokenStream, TokenStream};\n+use crate::tokenstream::{LazyAttrTokenStream, TokenStream};\n use crate::util::comments;\n \n use rustc_index::bit_set::GrowableBitSet;\n@@ -296,20 +295,18 @@ impl Attribute {\n         }\n     }\n \n-    pub fn tokens(&self) -> AttrAnnotatedTokenStream {\n+    pub fn tokens(&self) -> TokenStream {\n         match self.kind {\n             AttrKind::Normal(ref normal) => normal\n                 .tokens\n                 .as_ref()\n                 .unwrap_or_else(|| panic!(\"attribute is missing tokens: {:?}\", self))\n-                .create_token_stream(),\n-            AttrKind::DocComment(comment_kind, data) => AttrAnnotatedTokenStream::from((\n-                AttrAnnotatedTokenTree::Token(Token::new(\n-                    token::DocComment(comment_kind, self.style, data),\n-                    self.span,\n-                )),\n+                .to_attr_token_stream()\n+                .to_tokenstream(),\n+            AttrKind::DocComment(comment_kind, data) => TokenStream::new(vec![TokenTree::Token(\n+                Token::new(token::DocComment(comment_kind, self.style, data), self.span),\n                 Spacing::Alone,\n-            )),\n+            )]),\n         }\n     }\n }\n@@ -356,7 +353,7 @@ pub fn mk_attr(style: AttrStyle, path: Path, args: MacArgs, span: Span) -> Attri\n \n pub fn mk_attr_from_item(\n     item: AttrItem,\n-    tokens: Option<LazyTokenStream>,\n+    tokens: Option<LazyAttrTokenStream>,\n     style: AttrStyle,\n     span: Span,\n ) -> Attribute {"}, {"sha": "4d3620ee8b0f0bfeb05dfb8f0577508ce5a20844", "filename": "compiler/rustc_ast/src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Flib.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -15,6 +15,7 @@\n #![feature(if_let_guard)]\n #![cfg_attr(bootstrap, feature(label_break_value))]\n #![feature(let_chains)]\n+#![feature(let_else)]\n #![feature(min_specialization)]\n #![feature(negative_impls)]\n #![feature(slice_internals)]"}, {"sha": "ad68d6e755e0287d5eedda3eef87d57e9e72798f", "filename": "compiler/rustc_ast/src/mut_visit.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -642,17 +642,17 @@ pub fn noop_flat_map_param<T: MutVisitor>(mut param: Param, vis: &mut T) -> Smal\n }\n \n // No `noop_` prefix because there isn't a corresponding method in `MutVisitor`.\n-pub fn visit_attr_annotated_tt<T: MutVisitor>(tt: &mut AttrAnnotatedTokenTree, vis: &mut T) {\n+pub fn visit_attr_tt<T: MutVisitor>(tt: &mut AttrTokenTree, vis: &mut T) {\n     match tt {\n-        AttrAnnotatedTokenTree::Token(token) => {\n+        AttrTokenTree::Token(token, _) => {\n             visit_token(token, vis);\n         }\n-        AttrAnnotatedTokenTree::Delimited(DelimSpan { open, close }, _delim, tts) => {\n+        AttrTokenTree::Delimited(DelimSpan { open, close }, _delim, tts) => {\n             vis.visit_span(open);\n             vis.visit_span(close);\n-            visit_attr_annotated_tts(tts, vis);\n+            visit_attr_tts(tts, vis);\n         }\n-        AttrAnnotatedTokenTree::Attributes(data) => {\n+        AttrTokenTree::Attributes(data) => {\n             for attr in &mut *data.attrs {\n                 match &mut attr.kind {\n                     AttrKind::Normal(normal) => {\n@@ -690,27 +690,27 @@ pub fn visit_tts<T: MutVisitor>(TokenStream(tts): &mut TokenStream, vis: &mut T)\n     }\n }\n \n-pub fn visit_attr_annotated_tts<T: MutVisitor>(\n-    AttrAnnotatedTokenStream(tts): &mut AttrAnnotatedTokenStream,\n-    vis: &mut T,\n-) {\n+pub fn visit_attr_tts<T: MutVisitor>(AttrTokenStream(tts): &mut AttrTokenStream, vis: &mut T) {\n     if T::VISIT_TOKENS && !tts.is_empty() {\n         let tts = Lrc::make_mut(tts);\n-        visit_vec(tts, |(tree, _is_joint)| visit_attr_annotated_tt(tree, vis));\n+        visit_vec(tts, |tree| visit_attr_tt(tree, vis));\n     }\n }\n \n-pub fn visit_lazy_tts_opt_mut<T: MutVisitor>(lazy_tts: Option<&mut LazyTokenStream>, vis: &mut T) {\n+pub fn visit_lazy_tts_opt_mut<T: MutVisitor>(\n+    lazy_tts: Option<&mut LazyAttrTokenStream>,\n+    vis: &mut T,\n+) {\n     if T::VISIT_TOKENS {\n         if let Some(lazy_tts) = lazy_tts {\n-            let mut tts = lazy_tts.create_token_stream();\n-            visit_attr_annotated_tts(&mut tts, vis);\n-            *lazy_tts = LazyTokenStream::new(tts);\n+            let mut tts = lazy_tts.to_attr_token_stream();\n+            visit_attr_tts(&mut tts, vis);\n+            *lazy_tts = LazyAttrTokenStream::new(tts);\n         }\n     }\n }\n \n-pub fn visit_lazy_tts<T: MutVisitor>(lazy_tts: &mut Option<LazyTokenStream>, vis: &mut T) {\n+pub fn visit_lazy_tts<T: MutVisitor>(lazy_tts: &mut Option<LazyAttrTokenStream>, vis: &mut T) {\n     visit_lazy_tts_opt_mut(lazy_tts.as_mut(), vis);\n }\n "}, {"sha": "875cd620dfc6ccb759f8394803651620168f382c", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 55, "deletions": 71, "changes": 126, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -121,12 +121,12 @@ where\n     }\n }\n \n-pub trait CreateTokenStream: sync::Send + sync::Sync {\n-    fn create_token_stream(&self) -> AttrAnnotatedTokenStream;\n+pub trait ToAttrTokenStream: sync::Send + sync::Sync {\n+    fn to_attr_token_stream(&self) -> AttrTokenStream;\n }\n \n-impl CreateTokenStream for AttrAnnotatedTokenStream {\n-    fn create_token_stream(&self) -> AttrAnnotatedTokenStream {\n+impl ToAttrTokenStream for AttrTokenStream {\n+    fn to_attr_token_stream(&self) -> AttrTokenStream {\n         self.clone()\n     }\n }\n@@ -135,100 +135,96 @@ impl CreateTokenStream for AttrAnnotatedTokenStream {\n /// of an actual `TokenStream` until it is needed.\n /// `Box` is here only to reduce the structure size.\n #[derive(Clone)]\n-pub struct LazyTokenStream(Lrc<Box<dyn CreateTokenStream>>);\n+pub struct LazyAttrTokenStream(Lrc<Box<dyn ToAttrTokenStream>>);\n \n-impl LazyTokenStream {\n-    pub fn new(inner: impl CreateTokenStream + 'static) -> LazyTokenStream {\n-        LazyTokenStream(Lrc::new(Box::new(inner)))\n+impl LazyAttrTokenStream {\n+    pub fn new(inner: impl ToAttrTokenStream + 'static) -> LazyAttrTokenStream {\n+        LazyAttrTokenStream(Lrc::new(Box::new(inner)))\n     }\n \n-    pub fn create_token_stream(&self) -> AttrAnnotatedTokenStream {\n-        self.0.create_token_stream()\n+    pub fn to_attr_token_stream(&self) -> AttrTokenStream {\n+        self.0.to_attr_token_stream()\n     }\n }\n \n-impl fmt::Debug for LazyTokenStream {\n+impl fmt::Debug for LazyAttrTokenStream {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        write!(f, \"LazyTokenStream({:?})\", self.create_token_stream())\n+        write!(f, \"LazyAttrTokenStream({:?})\", self.to_attr_token_stream())\n     }\n }\n \n-impl<S: Encoder> Encodable<S> for LazyTokenStream {\n+impl<S: Encoder> Encodable<S> for LazyAttrTokenStream {\n     fn encode(&self, s: &mut S) {\n         // Used by AST json printing.\n-        Encodable::encode(&self.create_token_stream(), s);\n+        Encodable::encode(&self.to_attr_token_stream(), s);\n     }\n }\n \n-impl<D: Decoder> Decodable<D> for LazyTokenStream {\n+impl<D: Decoder> Decodable<D> for LazyAttrTokenStream {\n     fn decode(_d: &mut D) -> Self {\n-        panic!(\"Attempted to decode LazyTokenStream\");\n+        panic!(\"Attempted to decode LazyAttrTokenStream\");\n     }\n }\n \n-impl<CTX> HashStable<CTX> for LazyTokenStream {\n+impl<CTX> HashStable<CTX> for LazyAttrTokenStream {\n     fn hash_stable(&self, _hcx: &mut CTX, _hasher: &mut StableHasher) {\n-        panic!(\"Attempted to compute stable hash for LazyTokenStream\");\n+        panic!(\"Attempted to compute stable hash for LazyAttrTokenStream\");\n     }\n }\n \n-/// A `AttrAnnotatedTokenStream` is similar to a `TokenStream`, but with extra\n+/// An `AttrTokenStream` is similar to a `TokenStream`, but with extra\n /// information about the tokens for attribute targets. This is used\n /// during expansion to perform early cfg-expansion, and to process attributes\n /// during proc-macro invocations.\n #[derive(Clone, Debug, Default, Encodable, Decodable)]\n-pub struct AttrAnnotatedTokenStream(pub Lrc<Vec<(AttrAnnotatedTokenTree, Spacing)>>);\n+pub struct AttrTokenStream(pub Lrc<Vec<AttrTokenTree>>);\n \n-/// Like `TokenTree`, but for `AttrAnnotatedTokenStream`\n+/// Like `TokenTree`, but for `AttrTokenStream`.\n #[derive(Clone, Debug, Encodable, Decodable)]\n-pub enum AttrAnnotatedTokenTree {\n-    Token(Token),\n-    Delimited(DelimSpan, Delimiter, AttrAnnotatedTokenStream),\n+pub enum AttrTokenTree {\n+    Token(Token, Spacing),\n+    Delimited(DelimSpan, Delimiter, AttrTokenStream),\n     /// Stores the attributes for an attribute target,\n     /// along with the tokens for that attribute target.\n     /// See `AttributesData` for more information\n     Attributes(AttributesData),\n }\n \n-impl AttrAnnotatedTokenStream {\n-    pub fn new(tokens: Vec<(AttrAnnotatedTokenTree, Spacing)>) -> AttrAnnotatedTokenStream {\n-        AttrAnnotatedTokenStream(Lrc::new(tokens))\n+impl AttrTokenStream {\n+    pub fn new(tokens: Vec<AttrTokenTree>) -> AttrTokenStream {\n+        AttrTokenStream(Lrc::new(tokens))\n     }\n \n-    /// Converts this `AttrAnnotatedTokenStream` to a plain `TokenStream\n-    /// During conversion, `AttrAnnotatedTokenTree::Attributes` get 'flattened'\n+    /// Converts this `AttrTokenStream` to a plain `TokenStream`.\n+    /// During conversion, `AttrTokenTree::Attributes` get 'flattened'\n     /// back to a `TokenStream` of the form `outer_attr attr_target`.\n     /// If there are inner attributes, they are inserted into the proper\n     /// place in the attribute target tokens.\n     pub fn to_tokenstream(&self) -> TokenStream {\n         let trees: Vec<_> = self\n             .0\n             .iter()\n-            .flat_map(|tree| match &tree.0 {\n-                AttrAnnotatedTokenTree::Token(inner) => {\n-                    smallvec![TokenTree::Token(inner.clone(), tree.1)].into_iter()\n+            .flat_map(|tree| match &tree {\n+                AttrTokenTree::Token(inner, spacing) => {\n+                    smallvec![TokenTree::Token(inner.clone(), *spacing)].into_iter()\n                 }\n-                AttrAnnotatedTokenTree::Delimited(span, delim, stream) => {\n+                AttrTokenTree::Delimited(span, delim, stream) => {\n                     smallvec![TokenTree::Delimited(*span, *delim, stream.to_tokenstream()),]\n                         .into_iter()\n                 }\n-                AttrAnnotatedTokenTree::Attributes(data) => {\n+                AttrTokenTree::Attributes(data) => {\n                     let mut outer_attrs = Vec::new();\n                     let mut inner_attrs = Vec::new();\n                     for attr in &data.attrs {\n                         match attr.style {\n-                            crate::AttrStyle::Outer => {\n-                                outer_attrs.push(attr);\n-                            }\n-                            crate::AttrStyle::Inner => {\n-                                inner_attrs.push(attr);\n-                            }\n+                            crate::AttrStyle::Outer => outer_attrs.push(attr),\n+                            crate::AttrStyle::Inner => inner_attrs.push(attr),\n                         }\n                     }\n \n                     let mut target_tokens: Vec<_> = data\n                         .tokens\n-                        .create_token_stream()\n+                        .to_attr_token_stream()\n                         .to_tokenstream()\n                         .0\n                         .iter()\n@@ -239,9 +235,9 @@ impl AttrAnnotatedTokenStream {\n                         // Check the last two trees (to account for a trailing semi)\n                         for tree in target_tokens.iter_mut().rev().take(2) {\n                             if let TokenTree::Delimited(span, delim, delim_tokens) = tree {\n-                                // Inner attributes are only supported on extern blocks, functions, impls,\n-                                // and modules. All of these have their inner attributes placed at\n-                                // the beginning of the rightmost outermost braced group:\n+                                // Inner attributes are only supported on extern blocks, functions,\n+                                // impls, and modules. All of these have their inner attributes\n+                                // placed at the beginning of the rightmost outermost braced group:\n                                 // e.g. fn foo() { #![my_attr} }\n                                 //\n                                 // Therefore, we can insert them back into the right location\n@@ -255,7 +251,7 @@ impl AttrAnnotatedTokenStream {\n \n                                 let mut builder = TokenStreamBuilder::new();\n                                 for inner_attr in inner_attrs {\n-                                    builder.push(inner_attr.tokens().to_tokenstream());\n+                                    builder.push(inner_attr.tokens());\n                                 }\n                                 builder.push(delim_tokens.clone());\n                                 *tree = TokenTree::Delimited(*span, *delim, builder.build());\n@@ -273,7 +269,7 @@ impl AttrAnnotatedTokenStream {\n                     let mut flat: SmallVec<[_; 1]> = SmallVec::new();\n                     for attr in outer_attrs {\n                         // FIXME: Make this more efficient\n-                        flat.extend(attr.tokens().to_tokenstream().0.clone().iter().cloned());\n+                        flat.extend(attr.tokens().0.clone().iter().cloned());\n                     }\n                     flat.extend(target_tokens);\n                     flat.into_iter()\n@@ -300,7 +296,7 @@ pub struct AttributesData {\n     pub attrs: AttrVec,\n     /// The underlying tokens for the attribute target that `attrs`\n     /// are applied to\n-    pub tokens: LazyTokenStream,\n+    pub tokens: LazyAttrTokenStream,\n }\n \n /// A `TokenStream` is an abstract sequence of tokens, organized into [`TokenTree`]s.\n@@ -363,12 +359,6 @@ impl TokenStream {\n     }\n }\n \n-impl From<(AttrAnnotatedTokenTree, Spacing)> for AttrAnnotatedTokenStream {\n-    fn from((tree, spacing): (AttrAnnotatedTokenTree, Spacing)) -> AttrAnnotatedTokenStream {\n-        AttrAnnotatedTokenStream::new(vec![(tree, spacing)])\n-    }\n-}\n-\n impl iter::FromIterator<TokenTree> for TokenStream {\n     fn from_iter<I: IntoIterator<Item = TokenTree>>(iter: I) -> Self {\n         TokenStream::new(iter.into_iter().collect::<Vec<TokenTree>>())\n@@ -420,22 +410,6 @@ impl TokenStream {\n         TokenStream(Lrc::new(self.0.iter().enumerate().map(|(i, tree)| f(i, tree)).collect()))\n     }\n \n-    fn opt_from_ast(node: &(impl HasAttrs + HasTokens)) -> Option<TokenStream> {\n-        let tokens = node.tokens()?;\n-        let attrs = node.attrs();\n-        let attr_annotated = if attrs.is_empty() {\n-            tokens.create_token_stream()\n-        } else {\n-            let attr_data =\n-                AttributesData { attrs: attrs.iter().cloned().collect(), tokens: tokens.clone() };\n-            AttrAnnotatedTokenStream::new(vec![(\n-                AttrAnnotatedTokenTree::Attributes(attr_data),\n-                Spacing::Alone,\n-            )])\n-        };\n-        Some(attr_annotated.to_tokenstream())\n-    }\n-\n     // Create a token stream containing a single token with alone spacing.\n     pub fn token_alone(kind: TokenKind, span: Span) -> TokenStream {\n         TokenStream::new(vec![TokenTree::token_alone(kind, span)])\n@@ -452,8 +426,18 @@ impl TokenStream {\n     }\n \n     pub fn from_ast(node: &(impl HasAttrs + HasSpan + HasTokens + fmt::Debug)) -> TokenStream {\n-        TokenStream::opt_from_ast(node)\n-            .unwrap_or_else(|| panic!(\"missing tokens for node at {:?}: {:?}\", node.span(), node))\n+        let Some(tokens) = node.tokens() else {\n+            panic!(\"missing tokens for node at {:?}: {:?}\", node.span(), node);\n+        };\n+        let attrs = node.attrs();\n+        let attr_stream = if attrs.is_empty() {\n+            tokens.to_attr_token_stream()\n+        } else {\n+            let attr_data =\n+                AttributesData { attrs: attrs.iter().cloned().collect(), tokens: tokens.clone() };\n+            AttrTokenStream::new(vec![AttrTokenTree::Attributes(attr_data)])\n+        };\n+        attr_stream.to_tokenstream()\n     }\n \n     pub fn from_nonterminal_ast(nt: &Nonterminal) -> TokenStream {"}, {"sha": "e673dff0dea8e438f33251c1b52cb6fc8f52debe", "filename": "compiler/rustc_builtin_macros/src/cfg_eval.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -188,14 +188,14 @@ impl CfgEval<'_, '_> {\n         let orig_tokens = annotatable.to_tokens().flattened();\n \n         // Re-parse the tokens, setting the `capture_cfg` flag to save extra information\n-        // to the captured `AttrAnnotatedTokenStream` (specifically, we capture\n-        // `AttrAnnotatedTokenTree::AttributesData` for all occurrences of `#[cfg]` and `#[cfg_attr]`)\n+        // to the captured `AttrTokenStream` (specifically, we capture\n+        // `AttrTokenTree::AttributesData` for all occurrences of `#[cfg]` and `#[cfg_attr]`)\n         let mut parser =\n             rustc_parse::stream_to_parser(&self.cfg.sess.parse_sess, orig_tokens, None);\n         parser.capture_cfg = true;\n         annotatable = parse_annotatable_with(&mut parser);\n \n-        // Now that we have our re-parsed `AttrAnnotatedTokenStream`, recursively configuring\n+        // Now that we have our re-parsed `AttrTokenStream`, recursively configuring\n         // our attribute target will correctly the tokens as well.\n         flat_map_annotatable(self, annotatable)\n     }"}, {"sha": "7d30596a936f9b70cf7d841ee19bd406270cecda", "filename": "compiler/rustc_expand/src/config.rs", "status": "modified", "additions": 29, "deletions": 29, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -2,9 +2,9 @@\n \n use rustc_ast::ptr::P;\n use rustc_ast::token::{Delimiter, Token, TokenKind};\n-use rustc_ast::tokenstream::{AttrAnnotatedTokenStream, AttrAnnotatedTokenTree};\n+use rustc_ast::tokenstream::{AttrTokenStream, AttrTokenTree};\n use rustc_ast::tokenstream::{DelimSpan, Spacing};\n-use rustc_ast::tokenstream::{LazyTokenStream, TokenTree};\n+use rustc_ast::tokenstream::{LazyAttrTokenStream, TokenTree};\n use rustc_ast::NodeId;\n use rustc_ast::{self as ast, AttrStyle, Attribute, HasAttrs, HasTokens, MetaItem};\n use rustc_attr as attr;\n@@ -259,8 +259,8 @@ impl<'a> StripUnconfigured<'a> {\n     fn try_configure_tokens<T: HasTokens>(&self, node: &mut T) {\n         if self.config_tokens {\n             if let Some(Some(tokens)) = node.tokens_mut() {\n-                let attr_annotated_tokens = tokens.create_token_stream();\n-                *tokens = LazyTokenStream::new(self.configure_tokens(&attr_annotated_tokens));\n+                let attr_stream = tokens.to_attr_token_stream();\n+                *tokens = LazyAttrTokenStream::new(self.configure_tokens(&attr_stream));\n             }\n         }\n     }\n@@ -270,16 +270,16 @@ impl<'a> StripUnconfigured<'a> {\n         if self.in_cfg(&attrs) { Some(attrs) } else { None }\n     }\n \n-    /// Performs cfg-expansion on `stream`, producing a new `AttrAnnotatedTokenStream`.\n+    /// Performs cfg-expansion on `stream`, producing a new `AttrTokenStream`.\n     /// This is only used during the invocation of `derive` proc-macros,\n     /// which require that we cfg-expand their entire input.\n     /// Normal cfg-expansion operates on parsed AST nodes via the `configure` method\n-    fn configure_tokens(&self, stream: &AttrAnnotatedTokenStream) -> AttrAnnotatedTokenStream {\n-        fn can_skip(stream: &AttrAnnotatedTokenStream) -> bool {\n-            stream.0.iter().all(|(tree, _spacing)| match tree {\n-                AttrAnnotatedTokenTree::Attributes(_) => false,\n-                AttrAnnotatedTokenTree::Token(_) => true,\n-                AttrAnnotatedTokenTree::Delimited(_, _, inner) => can_skip(inner),\n+    fn configure_tokens(&self, stream: &AttrTokenStream) -> AttrTokenStream {\n+        fn can_skip(stream: &AttrTokenStream) -> bool {\n+            stream.0.iter().all(|tree| match tree {\n+                AttrTokenTree::Attributes(_) => false,\n+                AttrTokenTree::Token(..) => true,\n+                AttrTokenTree::Delimited(_, _, inner) => can_skip(inner),\n             })\n         }\n \n@@ -290,36 +290,36 @@ impl<'a> StripUnconfigured<'a> {\n         let trees: Vec<_> = stream\n             .0\n             .iter()\n-            .flat_map(|(tree, spacing)| match tree.clone() {\n-                AttrAnnotatedTokenTree::Attributes(mut data) => {\n+            .flat_map(|tree| match tree.clone() {\n+                AttrTokenTree::Attributes(mut data) => {\n                     data.attrs.flat_map_in_place(|attr| self.process_cfg_attr(attr));\n \n                     if self.in_cfg(&data.attrs) {\n-                        data.tokens = LazyTokenStream::new(\n-                            self.configure_tokens(&data.tokens.create_token_stream()),\n+                        data.tokens = LazyAttrTokenStream::new(\n+                            self.configure_tokens(&data.tokens.to_attr_token_stream()),\n                         );\n-                        Some((AttrAnnotatedTokenTree::Attributes(data), *spacing)).into_iter()\n+                        Some(AttrTokenTree::Attributes(data)).into_iter()\n                     } else {\n                         None.into_iter()\n                     }\n                 }\n-                AttrAnnotatedTokenTree::Delimited(sp, delim, mut inner) => {\n+                AttrTokenTree::Delimited(sp, delim, mut inner) => {\n                     inner = self.configure_tokens(&inner);\n-                    Some((AttrAnnotatedTokenTree::Delimited(sp, delim, inner), *spacing))\n+                    Some(AttrTokenTree::Delimited(sp, delim, inner))\n                         .into_iter()\n                 }\n-                AttrAnnotatedTokenTree::Token(ref token) if let TokenKind::Interpolated(ref nt) = token.kind => {\n+                AttrTokenTree::Token(ref token, _) if let TokenKind::Interpolated(ref nt) = token.kind => {\n                     panic!(\n                         \"Nonterminal should have been flattened at {:?}: {:?}\",\n                         token.span, nt\n                     );\n                 }\n-                AttrAnnotatedTokenTree::Token(token) => {\n-                    Some((AttrAnnotatedTokenTree::Token(token), *spacing)).into_iter()\n+                AttrTokenTree::Token(token, spacing) => {\n+                    Some(AttrTokenTree::Token(token, spacing)).into_iter()\n                 }\n             })\n             .collect();\n-        AttrAnnotatedTokenStream::new(trees)\n+        AttrTokenStream::new(trees)\n     }\n \n     /// Parse and expand all `cfg_attr` attributes into a list of attributes\n@@ -388,7 +388,7 @@ impl<'a> StripUnconfigured<'a> {\n         attr: &Attribute,\n         (item, item_span): (ast::AttrItem, Span),\n     ) -> Attribute {\n-        let orig_tokens = attr.tokens().to_tokenstream();\n+        let orig_tokens = attr.tokens();\n \n         // We are taking an attribute of the form `#[cfg_attr(pred, attr)]`\n         // and producing an attribute of the form `#[attr]`. We\n@@ -404,26 +404,26 @@ impl<'a> StripUnconfigured<'a> {\n         };\n         let pound_span = pound_token.span;\n \n-        let mut trees = vec![(AttrAnnotatedTokenTree::Token(pound_token), Spacing::Alone)];\n+        let mut trees = vec![AttrTokenTree::Token(pound_token, Spacing::Alone)];\n         if attr.style == AttrStyle::Inner {\n             // For inner attributes, we do the same thing for the `!` in `#![some_attr]`\n             let TokenTree::Token(bang_token @ Token { kind: TokenKind::Not, .. }, _) = orig_trees.next().unwrap() else {\n                 panic!(\"Bad tokens for attribute {:?}\", attr);\n             };\n-            trees.push((AttrAnnotatedTokenTree::Token(bang_token), Spacing::Alone));\n+            trees.push(AttrTokenTree::Token(bang_token, Spacing::Alone));\n         }\n         // We don't really have a good span to use for the synthesized `[]`\n         // in `#[attr]`, so just use the span of the `#` token.\n-        let bracket_group = AttrAnnotatedTokenTree::Delimited(\n+        let bracket_group = AttrTokenTree::Delimited(\n             DelimSpan::from_single(pound_span),\n             Delimiter::Bracket,\n             item.tokens\n                 .as_ref()\n                 .unwrap_or_else(|| panic!(\"Missing tokens for {:?}\", item))\n-                .create_token_stream(),\n+                .to_attr_token_stream(),\n         );\n-        trees.push((bracket_group, Spacing::Alone));\n-        let tokens = Some(LazyTokenStream::new(AttrAnnotatedTokenStream::new(trees)));\n+        trees.push(bracket_group);\n+        let tokens = Some(LazyAttrTokenStream::new(AttrTokenStream::new(trees)));\n         let attr = attr::mk_attr_from_item(item, tokens, attr.style, item_span);\n         if attr.has_name(sym::crate_type) {\n             self.sess.parse_sess.buffer_lint("}, {"sha": "a37f828eafb9b4241d411fe1325b07107aa2f42e", "filename": "compiler/rustc_parse/src/parser/attr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -301,9 +301,9 @@ impl<'a> Parser<'a> {\n             if let Some(attr) = attr {\n                 let end_pos: u32 = self.token_cursor.num_next_calls.try_into().unwrap();\n                 // If we are currently capturing tokens, mark the location of this inner attribute.\n-                // If capturing ends up creating a `LazyTokenStream`, we will include\n+                // If capturing ends up creating a `LazyAttrTokenStream`, we will include\n                 // this replace range with it, removing the inner attribute from the final\n-                // `AttrAnnotatedTokenStream`. Inner attributes are stored in the parsed AST note.\n+                // `AttrTokenStream`. Inner attributes are stored in the parsed AST note.\n                 // During macro expansion, they are selectively inserted back into the\n                 // token stream (the first inner attribute is removed each time we invoke the\n                 // corresponding macro)."}, {"sha": "5fdafd187c660cab801a81ddb70768b36740d7cc", "filename": "compiler/rustc_parse/src/parser/attr_wrapper.rs", "status": "modified", "additions": 25, "deletions": 26, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -1,7 +1,7 @@\n use super::{Capturing, FlatToken, ForceCollect, Parser, ReplaceRange, TokenCursor, TrailingToken};\n use rustc_ast::token::{self, Delimiter, Token, TokenKind};\n-use rustc_ast::tokenstream::{AttrAnnotatedTokenStream, AttributesData, CreateTokenStream};\n-use rustc_ast::tokenstream::{AttrAnnotatedTokenTree, DelimSpan, LazyTokenStream, Spacing};\n+use rustc_ast::tokenstream::{AttrTokenStream, AttributesData, ToAttrTokenStream};\n+use rustc_ast::tokenstream::{AttrTokenTree, DelimSpan, LazyAttrTokenStream, Spacing};\n use rustc_ast::{self as ast};\n use rustc_ast::{AttrVec, Attribute, HasAttrs, HasTokens};\n use rustc_errors::PResult;\n@@ -88,7 +88,7 @@ fn has_cfg_or_cfg_attr(attrs: &[Attribute]) -> bool {\n // This also makes `Parser` very cheap to clone, since\n // there is no intermediate collection buffer to clone.\n #[derive(Clone)]\n-struct LazyTokenStreamImpl {\n+struct LazyAttrTokenStreamImpl {\n     start_token: (Token, Spacing),\n     cursor_snapshot: TokenCursor,\n     num_calls: usize,\n@@ -97,10 +97,10 @@ struct LazyTokenStreamImpl {\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(LazyTokenStreamImpl, 144);\n+rustc_data_structures::static_assert_size!(LazyAttrTokenStreamImpl, 144);\n \n-impl CreateTokenStream for LazyTokenStreamImpl {\n-    fn create_token_stream(&self) -> AttrAnnotatedTokenStream {\n+impl ToAttrTokenStream for LazyAttrTokenStreamImpl {\n+    fn to_attr_token_stream(&self) -> AttrTokenStream {\n         // The token produced by the final call to `{,inlined_}next` was not\n         // actually consumed by the callback. The combination of chaining the\n         // initial token and using `take` produces the desired result - we\n@@ -179,7 +179,7 @@ impl CreateTokenStream for LazyTokenStreamImpl {\n impl<'a> Parser<'a> {\n     /// Records all tokens consumed by the provided callback,\n     /// including the current token. These tokens are collected\n-    /// into a `LazyTokenStream`, and returned along with the result\n+    /// into a `LazyAttrTokenStream`, and returned along with the result\n     /// of the callback.\n     ///\n     /// Note: If your callback consumes an opening delimiter\n@@ -297,8 +297,8 @@ impl<'a> Parser<'a> {\n \n         // If we 'broke' the last token (e.g. breaking a '>>' token to two '>' tokens),\n         // then extend the range of captured tokens to include it, since the parser\n-        // was not actually bumped past it. When the `LazyTokenStream` gets converted\n-        // into an `AttrAnnotatedTokenStream`, we will create the proper token.\n+        // was not actually bumped past it. When the `LazyAttrTokenStream` gets converted\n+        // into an `AttrTokenStream`, we will create the proper token.\n         if self.token_cursor.break_last_token {\n             assert_eq!(\n                 trailing,\n@@ -316,8 +316,8 @@ impl<'a> Parser<'a> {\n             Box::new([])\n         } else {\n             // Grab any replace ranges that occur *inside* the current AST node.\n-            // We will perform the actual replacement when we convert the `LazyTokenStream`\n-            // to an `AttrAnnotatedTokenStream`\n+            // We will perform the actual replacement when we convert the `LazyAttrTokenStream`\n+            // to an `AttrTokenStream`.\n             let start_calls: u32 = cursor_snapshot_next_calls.try_into().unwrap();\n             self.capture_state.replace_ranges[replace_ranges_start..replace_ranges_end]\n                 .iter()\n@@ -329,7 +329,7 @@ impl<'a> Parser<'a> {\n                 .collect()\n         };\n \n-        let tokens = LazyTokenStream::new(LazyTokenStreamImpl {\n+        let tokens = LazyAttrTokenStream::new(LazyAttrTokenStreamImpl {\n             start_token,\n             num_calls,\n             cursor_snapshot,\n@@ -392,12 +392,12 @@ impl<'a> Parser<'a> {\n fn make_token_stream(\n     mut iter: impl Iterator<Item = (FlatToken, Spacing)>,\n     break_last_token: bool,\n-) -> AttrAnnotatedTokenStream {\n+) -> AttrTokenStream {\n     #[derive(Debug)]\n     struct FrameData {\n         // This is `None` for the first frame, `Some` for all others.\n         open_delim_sp: Option<(Delimiter, Span)>,\n-        inner: Vec<(AttrAnnotatedTokenTree, Spacing)>,\n+        inner: Vec<AttrTokenTree>,\n     }\n     let mut stack = vec![FrameData { open_delim_sp: None, inner: vec![] }];\n     let mut token_and_spacing = iter.next();\n@@ -418,48 +418,47 @@ fn make_token_stream(\n                     open_delim, span\n                 );\n                 let dspan = DelimSpan::from_pair(open_sp, span);\n-                let stream = AttrAnnotatedTokenStream::new(frame_data.inner);\n-                let delimited = AttrAnnotatedTokenTree::Delimited(dspan, delim, stream);\n+                let stream = AttrTokenStream::new(frame_data.inner);\n+                let delimited = AttrTokenTree::Delimited(dspan, delim, stream);\n                 stack\n                     .last_mut()\n                     .unwrap_or_else(|| {\n                         panic!(\"Bottom token frame is missing for token: {:?}\", token)\n                     })\n                     .inner\n-                    .push((delimited, Spacing::Alone));\n+                    .push(delimited);\n             }\n             FlatToken::Token(token) => stack\n                 .last_mut()\n                 .expect(\"Bottom token frame is missing!\")\n                 .inner\n-                .push((AttrAnnotatedTokenTree::Token(token), spacing)),\n+                .push(AttrTokenTree::Token(token, spacing)),\n             FlatToken::AttrTarget(data) => stack\n                 .last_mut()\n                 .expect(\"Bottom token frame is missing!\")\n                 .inner\n-                .push((AttrAnnotatedTokenTree::Attributes(data), spacing)),\n+                .push(AttrTokenTree::Attributes(data)),\n             FlatToken::Empty => {}\n         }\n         token_and_spacing = iter.next();\n     }\n     let mut final_buf = stack.pop().expect(\"Missing final buf!\");\n     if break_last_token {\n-        let (last_token, spacing) = final_buf.inner.pop().unwrap();\n-        if let AttrAnnotatedTokenTree::Token(last_token) = last_token {\n+        let last_token = final_buf.inner.pop().unwrap();\n+        if let AttrTokenTree::Token(last_token, spacing) = last_token {\n             let unglued_first = last_token.kind.break_two_token_op().unwrap().0;\n \n             // An 'unglued' token is always two ASCII characters\n             let mut first_span = last_token.span.shrink_to_lo();\n             first_span = first_span.with_hi(first_span.lo() + rustc_span::BytePos(1));\n \n-            final_buf.inner.push((\n-                AttrAnnotatedTokenTree::Token(Token::new(unglued_first, first_span)),\n-                spacing,\n-            ));\n+            final_buf\n+                .inner\n+                .push(AttrTokenTree::Token(Token::new(unglued_first, first_span), spacing));\n         } else {\n             panic!(\"Unexpected last token {:?}\", last_token)\n         }\n     }\n     assert!(stack.is_empty(), \"Stack should be empty: final_buf={:?} stack={:?}\", final_buf, stack);\n-    AttrAnnotatedTokenStream::new(final_buf.inner)\n+    AttrTokenStream::new(final_buf.inner)\n }"}, {"sha": "4cb198561e0adaf0c6d97d1e65ca4f096fc86d43", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/db75d7e14b6c5157e12fea4a1158e9dd58e92c36/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=db75d7e14b6c5157e12fea4a1158e9dd58e92c36", "patch": "@@ -170,7 +170,7 @@ pub struct ClosureSpans {\n /// attribute, we parse a nested AST node that has `#[cfg]` or `#[cfg_attr]`\n /// In this case, we use a `ReplaceRange` to replace the entire inner AST node\n /// with `FlatToken::AttrTarget`, allowing us to perform eager cfg-expansion\n-/// on an `AttrAnnotatedTokenStream`\n+/// on an `AttrTokenStream`.\n ///\n /// 2. When we parse an inner attribute while collecting tokens. We\n /// remove inner attributes from the token stream entirely, and\n@@ -183,7 +183,7 @@ pub type ReplaceRange = (Range<u32>, Vec<(FlatToken, Spacing)>);\n \n /// Controls how we capture tokens. Capturing can be expensive,\n /// so we try to avoid performing capturing in cases where\n-/// we will never need an `AttrAnnotatedTokenStream`\n+/// we will never need an `AttrTokenStream`.\n #[derive(Copy, Clone)]\n pub enum Capturing {\n     /// We aren't performing any capturing - this is the default mode.\n@@ -237,7 +237,7 @@ struct TokenCursor {\n     // the trailing `>>` token. The `break_last_token`\n     // field is used to track this token - it gets\n     // appended to the captured stream when\n-    // we evaluate a `LazyTokenStream`\n+    // we evaluate a `LazyAttrTokenStream`.\n     break_last_token: bool,\n }\n \n@@ -1464,23 +1464,23 @@ pub fn emit_unclosed_delims(unclosed_delims: &mut Vec<UnmatchedBrace>, sess: &Pa\n     }\n }\n \n-/// A helper struct used when building an `AttrAnnotatedTokenStream` from\n-/// a `LazyTokenStream`. Both delimiter and non-delimited tokens\n+/// A helper struct used when building an `AttrTokenStream` from\n+/// a `LazyAttrTokenStream`. Both delimiter and non-delimited tokens\n /// are stored as `FlatToken::Token`. A vector of `FlatToken`s\n-/// is then 'parsed' to build up an `AttrAnnotatedTokenStream` with nested\n-/// `AttrAnnotatedTokenTree::Delimited` tokens\n+/// is then 'parsed' to build up an `AttrTokenStream` with nested\n+/// `AttrTokenTree::Delimited` tokens.\n #[derive(Debug, Clone)]\n pub enum FlatToken {\n     /// A token - this holds both delimiter (e.g. '{' and '}')\n     /// and non-delimiter tokens\n     Token(Token),\n     /// Holds the `AttributesData` for an AST node. The\n     /// `AttributesData` is inserted directly into the\n-    /// constructed `AttrAnnotatedTokenStream` as\n-    /// an `AttrAnnotatedTokenTree::Attributes`\n+    /// constructed `AttrTokenStream` as\n+    /// an `AttrTokenTree::Attributes`.\n     AttrTarget(AttributesData),\n     /// A special 'empty' token that is ignored during the conversion\n-    /// to an `AttrAnnotatedTokenStream`. This is used to simplify the\n+    /// to an `AttrTokenStream`. This is used to simplify the\n     /// handling of replace ranges.\n     Empty,\n }"}]}