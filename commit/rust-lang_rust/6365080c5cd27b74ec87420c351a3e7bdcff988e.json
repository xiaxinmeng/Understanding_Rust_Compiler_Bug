{"sha": "6365080c5cd27b74ec87420c351a3e7bdcff988e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjYzNjUwODBjNWNkMjdiNzRlYzg3NDIwYzM1MWEzZTdiZGNmZjk4OGU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-04-26T09:52:28Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-04-26T09:52:28Z"}, "message": "Auto merge of #23085 - goffrie:interpolating-quote, r=huonw\n\nThis changes the `ToTokens` implementations for expressions, statements, etc. with almost-trivial ones that produce `Interpolated(*Nt(...))` pseudo-tokens. In this way, quasiquote now works the same way as macros do: already-parsed AST fragments are used as-is, not reparsed.\r\n\r\nThe `ToSource` trait is removed. Quasiquote no longer involves pretty-printing at all, which removes the need for the `encode_with_hygiene` hack. All associated machinery is removed.\r\n\r\nNew `Nonterminal`s are added: NtArm, NtImplItem, and NtTraitItem. These are just for quasiquote, not macros.\r\n\r\n`ToTokens` is no longer implemented for `Arg` (although this could be added again) and `Generics` (which I don't think makes sense).\r\n\r\nThis breaks any compiler extensions that relied on the ability of `ToTokens` to turn AST fragments back into inspectable token trees. For this reason, this closes #16987.\r\n\r\nAs such, this is a [breaking-change].\r\n\r\nFixes #16472.\r\nFixes #15962.\r\nFixes #17397.\r\nFixes #16617.", "tree": {"sha": "4cace13a2f04314b229a2c1860b7f672deb96ec4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4cace13a2f04314b229a2c1860b7f672deb96ec4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6365080c5cd27b74ec87420c351a3e7bdcff988e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6365080c5cd27b74ec87420c351a3e7bdcff988e", "html_url": "https://github.com/rust-lang/rust/commit/6365080c5cd27b74ec87420c351a3e7bdcff988e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6365080c5cd27b74ec87420c351a3e7bdcff988e/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b0043db4658feed7b7d17fd45285745d8af38001", "url": "https://api.github.com/repos/rust-lang/rust/commits/b0043db4658feed7b7d17fd45285745d8af38001", "html_url": "https://github.com/rust-lang/rust/commit/b0043db4658feed7b7d17fd45285745d8af38001"}, {"sha": "24ef90527351bb1a52c8b54e948cdbba8db3eef6", "url": "https://api.github.com/repos/rust-lang/rust/commits/24ef90527351bb1a52c8b54e948cdbba8db3eef6", "html_url": "https://github.com/rust-lang/rust/commit/24ef90527351bb1a52c8b54e948cdbba8db3eef6"}], "stats": {"total": 982, "additions": 257, "deletions": 725}, "files": [{"sha": "07fb6cbe5c6af4db5c7ff5aa7e2eac943969a3b5", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -89,12 +89,6 @@ impl Ident {\n     pub fn as_str<'a>(&'a self) -> &'a str {\n         self.name.as_str()\n     }\n-\n-    pub fn encode_with_hygiene(&self) -> String {\n-        format!(\"\\x00name_{},ctxt_{}\\x00\",\n-                self.name.usize(),\n-                self.ctxt)\n-    }\n }\n \n impl fmt::Debug for Ident {"}, {"sha": "e100b7705d8178ff813058b8a7aa8813f695f531", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 128, "deletions": 235, "changes": 363, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -30,16 +30,16 @@ pub mod rt {\n     use ext::base::ExtCtxt;\n     use parse::token;\n     use parse;\n-    use print::pprust;\n     use ptr::P;\n+    use std::rc::Rc;\n \n-    use ast::{TokenTree, Generics, Expr};\n+    use ast::{TokenTree, Expr};\n \n     pub use parse::new_parser_from_tts;\n-    pub use codemap::{BytePos, Span, dummy_spanned};\n+    pub use codemap::{BytePos, Span, dummy_spanned, DUMMY_SP};\n \n     pub trait ToTokens {\n-        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> ;\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree>;\n     }\n \n     impl ToTokens for TokenTree {\n@@ -70,277 +70,189 @@ pub mod rt {\n         }\n     }\n \n-    /* Should be (when bugs in default methods are fixed):\n-\n-    trait ToSource : ToTokens {\n-        // Takes a thing and generates a string containing rust code for it.\n-        pub fn to_source() -> String;\n-\n-        // If you can make source, you can definitely make tokens.\n-        pub fn to_tokens(cx: &ExtCtxt) -> ~[TokenTree] {\n-            cx.parse_tts(self.to_source())\n+    impl ToTokens for ast::Ident {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(DUMMY_SP, token::Ident(*self, token::Plain))]\n         }\n     }\n \n-    */\n-\n-    // FIXME: Move this trait to pprust and get rid of *_to_str?\n-    pub trait ToSource {\n-        // Takes a thing and generates a string containing rust code for it.\n-        fn to_source(&self) -> String;\n+    impl ToTokens for ast::Path {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(DUMMY_SP, token::Interpolated(token::NtPath(Box::new(self.clone()))))]\n+        }\n     }\n \n-    // FIXME (Issue #16472): This should go away after ToToken impls\n-    // are revised to go directly to token-trees.\n-    trait ToSourceWithHygiene : ToSource {\n-        // Takes a thing and generates a string containing rust code\n-        // for it, encoding Idents as special byte sequences to\n-        // maintain hygiene across serialization and deserialization.\n-        fn to_source_with_hygiene(&self) -> String;\n+    impl ToTokens for ast::Ty {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(self.span, token::Interpolated(token::NtTy(P(self.clone()))))]\n+        }\n     }\n \n-    macro_rules! impl_to_source {\n-        (P<$t:ty>, $pp:ident) => (\n-            impl ToSource for P<$t> {\n-                fn to_source(&self) -> String {\n-                    pprust::$pp(&**self)\n-                }\n-            }\n-            impl ToSourceWithHygiene for P<$t> {\n-                fn to_source_with_hygiene(&self) -> String {\n-                    pprust::with_hygiene::$pp(&**self)\n-                }\n-            }\n-        );\n-        ($t:ty, $pp:ident) => (\n-            impl ToSource for $t {\n-                fn to_source(&self) -> String {\n-                    pprust::$pp(self)\n-                }\n-            }\n-            impl ToSourceWithHygiene for $t {\n-                fn to_source_with_hygiene(&self) -> String {\n-                    pprust::with_hygiene::$pp(self)\n-                }\n-            }\n-        );\n+    impl ToTokens for ast::Block {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(self.span, token::Interpolated(token::NtBlock(P(self.clone()))))]\n+        }\n     }\n \n-    fn slice_to_source<'a, T: ToSource>(sep: &'static str, xs: &'a [T]) -> String {\n-        xs.iter()\n-            .map(|i| i.to_source())\n-            .collect::<Vec<String>>()\n-            .connect(sep)\n-            .to_string()\n+    impl ToTokens for P<ast::Item> {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(self.span, token::Interpolated(token::NtItem(self.clone())))]\n+        }\n     }\n \n-    fn slice_to_source_with_hygiene<'a, T: ToSourceWithHygiene>(\n-        sep: &'static str, xs: &'a [T]) -> String {\n-        xs.iter()\n-            .map(|i| i.to_source_with_hygiene())\n-            .collect::<Vec<String>>()\n-            .connect(sep)\n-            .to_string()\n+    impl ToTokens for P<ast::ImplItem> {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(self.span, token::Interpolated(token::NtImplItem(self.clone())))]\n+        }\n     }\n \n-    macro_rules! impl_to_source_slice {\n-        ($t:ty, $sep:expr) => (\n-            impl ToSource for [$t] {\n-                fn to_source(&self) -> String {\n-                    slice_to_source($sep, self)\n-                }\n-            }\n-\n-            impl ToSourceWithHygiene for [$t] {\n-                fn to_source_with_hygiene(&self) -> String {\n-                    slice_to_source_with_hygiene($sep, self)\n-                }\n-            }\n-        )\n+    impl ToTokens for P<ast::TraitItem> {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(self.span, token::Interpolated(token::NtTraitItem(self.clone())))]\n+        }\n     }\n \n-    impl ToSource for ast::Ident {\n-        fn to_source(&self) -> String {\n-            token::get_ident(*self).to_string()\n+    impl ToTokens for P<ast::Stmt> {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(self.span, token::Interpolated(token::NtStmt(self.clone())))]\n         }\n     }\n \n-    impl ToSourceWithHygiene for ast::Ident {\n-        fn to_source_with_hygiene(&self) -> String {\n-            self.encode_with_hygiene()\n+    impl ToTokens for P<ast::Expr> {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(self.span, token::Interpolated(token::NtExpr(self.clone())))]\n         }\n     }\n \n-    impl_to_source! { ast::Path, path_to_string }\n-    impl_to_source! { ast::Ty, ty_to_string }\n-    impl_to_source! { ast::Block, block_to_string }\n-    impl_to_source! { ast::Arg, arg_to_string }\n-    impl_to_source! { Generics, generics_to_string }\n-    impl_to_source! { ast::WhereClause, where_clause_to_string }\n-    impl_to_source! { P<ast::Item>, item_to_string }\n-    impl_to_source! { P<ast::ImplItem>, impl_item_to_string }\n-    impl_to_source! { P<ast::TraitItem>, trait_item_to_string }\n-    impl_to_source! { P<ast::Stmt>, stmt_to_string }\n-    impl_to_source! { P<ast::Expr>, expr_to_string }\n-    impl_to_source! { P<ast::Pat>, pat_to_string }\n-    impl_to_source! { ast::Arm, arm_to_string }\n-    impl_to_source_slice! { ast::Ty, \", \" }\n-    impl_to_source_slice! { P<ast::Item>, \"\\n\\n\" }\n-\n-    impl ToSource for ast::Attribute_ {\n-        fn to_source(&self) -> String {\n-            pprust::attribute_to_string(&dummy_spanned(self.clone()))\n+    impl ToTokens for P<ast::Pat> {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(self.span, token::Interpolated(token::NtPat(self.clone())))]\n         }\n     }\n-    impl ToSourceWithHygiene for ast::Attribute_ {\n-        fn to_source_with_hygiene(&self) -> String {\n-            self.to_source()\n+\n+    impl ToTokens for ast::Arm {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(DUMMY_SP, token::Interpolated(token::NtArm(self.clone())))]\n         }\n     }\n \n-    impl ToSource for str {\n-        fn to_source(&self) -> String {\n-            let lit = dummy_spanned(ast::LitStr(\n-                    token::intern_and_get_ident(self), ast::CookedStr));\n-            pprust::lit_to_string(&lit)\n-        }\n+    macro_rules! impl_to_tokens_slice {\n+        ($t: ty, $sep: expr) => {\n+            impl ToTokens for [$t] {\n+                fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n+                    let mut v = vec![];\n+                    for (i, x) in self.iter().enumerate() {\n+                        if i > 0 {\n+                            v.push_all(&$sep);\n+                        }\n+                        v.extend(x.to_tokens(cx));\n+                    }\n+                    v\n+                }\n+            }\n+        };\n     }\n-    impl ToSourceWithHygiene for str {\n-        fn to_source_with_hygiene(&self) -> String {\n-            self.to_source()\n+\n+    impl_to_tokens_slice! { ast::Ty, [ast::TtToken(DUMMY_SP, token::Comma)] }\n+    impl_to_tokens_slice! { P<ast::Item>, [] }\n+\n+    impl ToTokens for P<ast::MetaItem> {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtToken(DUMMY_SP, token::Interpolated(token::NtMeta(self.clone())))]\n         }\n     }\n \n-    impl ToSource for () {\n-        fn to_source(&self) -> String {\n-            \"()\".to_string()\n+    impl ToTokens for ast::Attribute {\n+        fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n+            let mut r = vec![];\n+            // FIXME: The spans could be better\n+            r.push(ast::TtToken(self.span, token::Pound));\n+            if self.node.style == ast::AttrInner {\n+                r.push(ast::TtToken(self.span, token::Not));\n+            }\n+            r.push(ast::TtDelimited(self.span, Rc::new(ast::Delimited {\n+                delim: token::Bracket,\n+                open_span: self.span,\n+                tts: self.node.value.to_tokens(cx),\n+                close_span: self.span,\n+            })));\n+            r\n         }\n     }\n-    impl ToSourceWithHygiene for () {\n-        fn to_source_with_hygiene(&self) -> String {\n-            self.to_source()\n+\n+    impl ToTokens for str {\n+        fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n+            let lit = ast::LitStr(\n+                token::intern_and_get_ident(self), ast::CookedStr);\n+            dummy_spanned(lit).to_tokens(cx)\n         }\n     }\n \n-    impl ToSource for bool {\n-        fn to_source(&self) -> String {\n-            let lit = dummy_spanned(ast::LitBool(*self));\n-            pprust::lit_to_string(&lit)\n+    impl ToTokens for () {\n+        fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n+            vec![ast::TtDelimited(DUMMY_SP, Rc::new(ast::Delimited {\n+                delim: token::Paren,\n+                open_span: DUMMY_SP,\n+                tts: vec![],\n+                close_span: DUMMY_SP,\n+            }))]\n         }\n     }\n-    impl ToSourceWithHygiene for bool {\n-        fn to_source_with_hygiene(&self) -> String {\n-            self.to_source()\n+\n+    impl ToTokens for ast::Lit {\n+        fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n+            // FIXME: This is wrong\n+            P(ast::Expr {\n+                id: ast::DUMMY_NODE_ID,\n+                node: ast::ExprLit(P(self.clone())),\n+                span: DUMMY_SP,\n+            }).to_tokens(cx)\n         }\n     }\n \n-    impl ToSource for char {\n-        fn to_source(&self) -> String {\n-            let lit = dummy_spanned(ast::LitChar(*self));\n-            pprust::lit_to_string(&lit)\n+    impl ToTokens for bool {\n+        fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n+            dummy_spanned(ast::LitBool(*self)).to_tokens(cx)\n         }\n     }\n-    impl ToSourceWithHygiene for char {\n-        fn to_source_with_hygiene(&self) -> String {\n-            self.to_source()\n+\n+    impl ToTokens for char {\n+        fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n+            dummy_spanned(ast::LitChar(*self)).to_tokens(cx)\n         }\n     }\n \n-    macro_rules! impl_to_source_int {\n+    macro_rules! impl_to_tokens_int {\n         (signed, $t:ty, $tag:expr) => (\n-            impl ToSource for $t {\n-                fn to_source(&self) -> String {\n+            impl ToTokens for $t {\n+                fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n                     let lit = ast::LitInt(*self as u64, ast::SignedIntLit($tag,\n                                                                           ast::Sign::new(*self)));\n-                    pprust::lit_to_string(&dummy_spanned(lit))\n-                }\n-            }\n-            impl ToSourceWithHygiene for $t {\n-                fn to_source_with_hygiene(&self) -> String {\n-                    self.to_source()\n+                    dummy_spanned(lit).to_tokens(cx)\n                 }\n             }\n         );\n         (unsigned, $t:ty, $tag:expr) => (\n-            impl ToSource for $t {\n-                fn to_source(&self) -> String {\n+            impl ToTokens for $t {\n+                fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n                     let lit = ast::LitInt(*self as u64, ast::UnsignedIntLit($tag));\n-                    pprust::lit_to_string(&dummy_spanned(lit))\n-                }\n-            }\n-            impl ToSourceWithHygiene for $t {\n-                fn to_source_with_hygiene(&self) -> String {\n-                    self.to_source()\n+                    dummy_spanned(lit).to_tokens(cx)\n                 }\n             }\n         );\n     }\n \n-    impl_to_source_int! { signed, isize, ast::TyIs }\n-    impl_to_source_int! { signed, i8,  ast::TyI8 }\n-    impl_to_source_int! { signed, i16, ast::TyI16 }\n-    impl_to_source_int! { signed, i32, ast::TyI32 }\n-    impl_to_source_int! { signed, i64, ast::TyI64 }\n-\n-    impl_to_source_int! { unsigned, usize, ast::TyUs }\n-    impl_to_source_int! { unsigned, u8,   ast::TyU8 }\n-    impl_to_source_int! { unsigned, u16,  ast::TyU16 }\n-    impl_to_source_int! { unsigned, u32,  ast::TyU32 }\n-    impl_to_source_int! { unsigned, u64,  ast::TyU64 }\n-\n-    // Alas ... we write these out instead. All redundant.\n-\n-    macro_rules! impl_to_tokens {\n-        ($t:ty) => (\n-            impl ToTokens for $t {\n-                fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n-                    cx.parse_tts_with_hygiene(self.to_source_with_hygiene())\n-                }\n-            }\n-        )\n-    }\n+    impl_to_tokens_int! { signed, isize, ast::TyIs }\n+    impl_to_tokens_int! { signed, i8,  ast::TyI8 }\n+    impl_to_tokens_int! { signed, i16, ast::TyI16 }\n+    impl_to_tokens_int! { signed, i32, ast::TyI32 }\n+    impl_to_tokens_int! { signed, i64, ast::TyI64 }\n \n-    macro_rules! impl_to_tokens_lifetime {\n-        ($t:ty) => (\n-            impl<'a> ToTokens for $t {\n-                fn to_tokens(&self, cx: &ExtCtxt) -> Vec<TokenTree> {\n-                    cx.parse_tts_with_hygiene(self.to_source_with_hygiene())\n-                }\n-            }\n-        )\n-    }\n-\n-    impl_to_tokens! { ast::Ident }\n-    impl_to_tokens! { ast::Path }\n-    impl_to_tokens! { P<ast::Item> }\n-    impl_to_tokens! { P<ast::ImplItem> }\n-    impl_to_tokens! { P<ast::TraitItem> }\n-    impl_to_tokens! { P<ast::Pat> }\n-    impl_to_tokens! { ast::Arm }\n-    impl_to_tokens_lifetime! { &'a [P<ast::Item>] }\n-    impl_to_tokens! { ast::Ty }\n-    impl_to_tokens_lifetime! { &'a [ast::Ty] }\n-    impl_to_tokens! { Generics }\n-    impl_to_tokens! { ast::WhereClause }\n-    impl_to_tokens! { P<ast::Stmt> }\n-    impl_to_tokens! { P<ast::Expr> }\n-    impl_to_tokens! { ast::Block }\n-    impl_to_tokens! { ast::Arg }\n-    impl_to_tokens! { ast::Attribute_ }\n-    impl_to_tokens_lifetime! { &'a str }\n-    impl_to_tokens! { () }\n-    impl_to_tokens! { char }\n-    impl_to_tokens! { bool }\n-    impl_to_tokens! { isize }\n-    impl_to_tokens! { i8 }\n-    impl_to_tokens! { i16 }\n-    impl_to_tokens! { i32 }\n-    impl_to_tokens! { i64 }\n-    impl_to_tokens! { usize }\n-    impl_to_tokens! { u8 }\n-    impl_to_tokens! { u16 }\n-    impl_to_tokens! { u32 }\n-    impl_to_tokens! { u64 }\n+    impl_to_tokens_int! { unsigned, usize, ast::TyUs }\n+    impl_to_tokens_int! { unsigned, u8,   ast::TyU8 }\n+    impl_to_tokens_int! { unsigned, u16,  ast::TyU16 }\n+    impl_to_tokens_int! { unsigned, u32,  ast::TyU32 }\n+    impl_to_tokens_int! { unsigned, u64,  ast::TyU64 }\n \n     pub trait ExtParseUtils {\n         fn parse_item(&self, s: String) -> P<ast::Item>;\n@@ -349,12 +261,6 @@ pub mod rt {\n         fn parse_tts(&self, s: String) -> Vec<ast::TokenTree>;\n     }\n \n-    trait ExtParseUtilsWithHygiene {\n-        // FIXME (Issue #16472): This should go away after ToToken impls\n-        // are revised to go directly to token-trees.\n-        fn parse_tts_with_hygiene(&self, s: String) -> Vec<ast::TokenTree>;\n-    }\n-\n     impl<'a> ExtParseUtils for ExtCtxt<'a> {\n \n         fn parse_item(&self, s: String) -> P<ast::Item> {\n@@ -386,19 +292,6 @@ pub mod rt {\n                                              self.parse_sess())\n         }\n     }\n-\n-    impl<'a> ExtParseUtilsWithHygiene for ExtCtxt<'a> {\n-\n-        fn parse_tts_with_hygiene(&self, s: String) -> Vec<ast::TokenTree> {\n-            use parse::with_hygiene::parse_tts_from_source_str;\n-            parse_tts_from_source_str(\"<quote expansion>\".to_string(),\n-                                      s,\n-                                      self.cfg(),\n-                                      self.parse_sess())\n-        }\n-\n-    }\n-\n }\n \n pub fn expand_quote_tokens<'cx>(cx: &'cx mut ExtCtxt,"}, {"sha": "5352a191b095fcb015b21c7e9ff7664b3822de6d", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -682,6 +682,13 @@ pub fn noop_fold_interpolated<T: Folder>(nt: token::Nonterminal, fld: &mut T)\n         token::NtMeta(meta_item) => token::NtMeta(fld.fold_meta_item(meta_item)),\n         token::NtPath(path) => token::NtPath(Box::new(fld.fold_path(*path))),\n         token::NtTT(tt) => token::NtTT(P(fld.fold_tt(&*tt))),\n+        token::NtArm(arm) => token::NtArm(fld.fold_arm(arm)),\n+        token::NtImplItem(arm) =>\n+            token::NtImplItem(fld.fold_impl_item(arm)\n+                              .expect_one(\"expected fold to produce exactly one item\")),\n+        token::NtTraitItem(arm) =>\n+            token::NtTraitItem(fld.fold_trait_item(arm)\n+                               .expect_one(\"expected fold to produce exactly one item\")),\n     }\n }\n "}, {"sha": "6b0674c9a41b420fe948a24a588b7bfbb4dbb3e2", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 0, "deletions": 107, "changes": 107, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -19,7 +19,6 @@ use str::char_at;\n \n use std::borrow::Cow;\n use std::char;\n-use std::fmt;\n use std::mem::replace;\n use std::rc::Rc;\n \n@@ -71,11 +70,6 @@ pub struct StringReader<'a> {\n     pub peek_tok: token::Token,\n     pub peek_span: Span,\n \n-    // FIXME (Issue #16472): This field should go away after ToToken impls\n-    // are revised to go directly to token-trees.\n-    /// Is \\x00<name>,<ctxt>\\x00 is interpreted as encoded ast::Ident?\n-    read_embedded_ident: bool,\n-\n     // cache a direct reference to the source text, so that we don't have to\n     // retrieve it via `self.filemap.src.as_ref().unwrap()` all the time.\n     source_text: Rc<String>\n@@ -130,17 +124,6 @@ impl<'a> Reader for TtReader<'a> {\n     }\n }\n \n-// FIXME (Issue #16472): This function should go away after\n-// ToToken impls are revised to go directly to token-trees.\n-pub fn make_reader_with_embedded_idents<'b>(span_diagnostic: &'b SpanHandler,\n-                                            filemap: Rc<codemap::FileMap>)\n-                                            -> StringReader<'b> {\n-    let mut sr = StringReader::new_raw(span_diagnostic, filemap);\n-    sr.read_embedded_ident = true;\n-    sr.advance_token();\n-    sr\n-}\n-\n impl<'a> StringReader<'a> {\n     /// For comments.rs, which hackily pokes into pos and curr\n     pub fn new_raw<'b>(span_diagnostic: &'b SpanHandler,\n@@ -162,7 +145,6 @@ impl<'a> StringReader<'a> {\n             /* dummy values; not read */\n             peek_tok: token::Eof,\n             peek_span: codemap::DUMMY_SP,\n-            read_embedded_ident: false,\n             source_text: source_text\n         };\n         sr.bump();\n@@ -578,81 +560,6 @@ impl<'a> StringReader<'a> {\n         })\n     }\n \n-    // FIXME (Issue #16472): The scan_embedded_hygienic_ident function\n-    // should go away after we revise the syntax::ext::quote::ToToken\n-    // impls to go directly to token-trees instead of thing -> string\n-    // -> token-trees.  (The function is currently used to resolve\n-    // Issues #15750 and #15962.)\n-    //\n-    // Since this function is only used for certain internal macros,\n-    // and the functionality it provides is not exposed to end user\n-    // programs, pnkfelix deliberately chose to write it in a way that\n-    // favors rustc debugging effectiveness over runtime efficiency.\n-\n-    /// Scan through input of form \\x00name_NNNNNN,ctxt_CCCCCCC\\x00\n-    /// whence: `NNNNNN` is a string of characters forming an integer\n-    /// (the name) and `CCCCCCC` is a string of characters forming an\n-    /// integer (the ctxt), separate by a comma and delimited by a\n-    /// `\\x00` marker.\n-    #[inline(never)]\n-    fn scan_embedded_hygienic_ident(&mut self) -> ast::Ident {\n-        fn bump_expecting_char<'a,D:fmt::Debug>(r: &mut StringReader<'a>,\n-                                                c: char,\n-                                                described_c: D,\n-                                                whence: &str) {\n-            match r.curr {\n-                Some(r_c) if r_c == c => r.bump(),\n-                Some(r_c) => panic!(\"expected {:?}, hit {:?}, {}\", described_c, r_c, whence),\n-                None      => panic!(\"expected {:?}, hit EOF, {}\", described_c, whence),\n-            }\n-        }\n-\n-        let whence = \"while scanning embedded hygienic ident\";\n-\n-        // skip over the leading `\\x00`\n-        bump_expecting_char(self, '\\x00', \"nul-byte\", whence);\n-\n-        // skip over the \"name_\"\n-        for c in \"name_\".chars() {\n-            bump_expecting_char(self, c, c, whence);\n-        }\n-\n-        let start_bpos = self.last_pos;\n-        let base = 10;\n-\n-        // find the integer representing the name\n-        self.scan_digits(base, base);\n-        let encoded_name : u32 = self.with_str_from(start_bpos, |s| {\n-            u32::from_str_radix(s, 10).unwrap_or_else(|_| {\n-                panic!(\"expected digits representing a name, got {:?}, {}, range [{:?},{:?}]\",\n-                      s, whence, start_bpos, self.last_pos);\n-            })\n-        });\n-\n-        // skip over the `,`\n-        bump_expecting_char(self, ',', \"comma\", whence);\n-\n-        // skip over the \"ctxt_\"\n-        for c in \"ctxt_\".chars() {\n-            bump_expecting_char(self, c, c, whence);\n-        }\n-\n-        // find the integer representing the ctxt\n-        let start_bpos = self.last_pos;\n-        self.scan_digits(base, base);\n-        let encoded_ctxt : ast::SyntaxContext = self.with_str_from(start_bpos, |s| {\n-            u32::from_str_radix(s, 10).unwrap_or_else(|_| {\n-                panic!(\"expected digits representing a ctxt, got {:?}, {}\", s, whence);\n-            })\n-        });\n-\n-        // skip over the `\\x00`\n-        bump_expecting_char(self, '\\x00', \"nul-byte\", whence);\n-\n-        ast::Ident { name: ast::Name(encoded_name),\n-                     ctxt: encoded_ctxt, }\n-    }\n-\n     /// Scan through any digits (base `scan_radix`) or underscores,\n     /// and return how many digits there were.\n     ///\n@@ -1020,20 +927,6 @@ impl<'a> StringReader<'a> {\n             return token::Literal(num, suffix)\n         }\n \n-        if self.read_embedded_ident {\n-            match (c.unwrap(), self.nextch(), self.nextnextch()) {\n-                ('\\x00', Some('n'), Some('a')) => {\n-                    let ast_ident = self.scan_embedded_hygienic_ident();\n-                    return if self.curr_is(':') && self.nextch_is(':') {\n-                        token::Ident(ast_ident, token::ModName)\n-                    } else {\n-                        token::Ident(ast_ident, token::Plain)\n-                    };\n-                }\n-                _ => {}\n-            }\n-        }\n-\n         match c.expect(\"next_token_inner called at EOF\") {\n           // One-byte tokens.\n           ';' => { self.bump(); return token::Semi; }"}, {"sha": "8c9ce5f78d482c4f9df632a17e2bc242a51f0f9e", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 0, "deletions": 72, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -166,9 +166,6 @@ pub fn parse_stmt_from_source_str(name: String,\n     maybe_aborted(p.parse_stmt(), p)\n }\n \n-// Note: keep in sync with `with_hygiene::parse_tts_from_source_str`\n-// until #16472 is resolved.\n-//\n // Warning: This parses with quote_depth > 0, which is not the default.\n pub fn parse_tts_from_source_str(name: String,\n                                  source: String,\n@@ -186,8 +183,6 @@ pub fn parse_tts_from_source_str(name: String,\n     maybe_aborted(panictry!(p.parse_all_token_trees()),p)\n }\n \n-// Note: keep in sync with `with_hygiene::new_parser_from_source_str`\n-// until #16472 is resolved.\n // Create a new parser from a source string\n pub fn new_parser_from_source_str<'a>(sess: &'a ParseSess,\n                                       cfg: ast::CrateConfig,\n@@ -220,8 +215,6 @@ pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n     p\n }\n \n-// Note: keep this in sync with `with_hygiene::filemap_to_parser` until\n-// #16472 is resolved.\n /// Given a filemap and config, return a parser\n pub fn filemap_to_parser<'a>(sess: &'a ParseSess,\n                              filemap: Rc<FileMap>,\n@@ -277,8 +270,6 @@ pub fn string_to_filemap(sess: &ParseSess, source: String, path: String)\n     sess.span_diagnostic.cm.new_filemap(path, source)\n }\n \n-// Note: keep this in sync with `with_hygiene::filemap_to_tts` (apart\n-// from the StringReader constructor), until #16472 is resolved.\n /// Given a filemap, produce a sequence of token-trees\n pub fn filemap_to_tts(sess: &ParseSess, filemap: Rc<FileMap>)\n     -> Vec<ast::TokenTree> {\n@@ -300,69 +291,6 @@ pub fn tts_to_parser<'a>(sess: &'a ParseSess,\n     p\n }\n \n-// FIXME (Issue #16472): The `with_hygiene` mod should go away after\n-// ToToken impls are revised to go directly to token-trees.\n-pub mod with_hygiene {\n-    use ast;\n-    use codemap::FileMap;\n-    use parse::parser::Parser;\n-    use std::rc::Rc;\n-    use super::ParseSess;\n-    use super::{maybe_aborted, string_to_filemap, tts_to_parser};\n-\n-    // Note: keep this in sync with `super::parse_tts_from_source_str` until\n-    // #16472 is resolved.\n-    //\n-    // Warning: This parses with quote_depth > 0, which is not the default.\n-    pub fn parse_tts_from_source_str(name: String,\n-                                     source: String,\n-                                     cfg: ast::CrateConfig,\n-                                     sess: &ParseSess) -> Vec<ast::TokenTree> {\n-        let mut p = new_parser_from_source_str(\n-            sess,\n-            cfg,\n-            name,\n-            source\n-        );\n-        p.quote_depth += 1;\n-        // right now this is re-creating the token trees from ... token trees.\n-        maybe_aborted(panictry!(p.parse_all_token_trees()),p)\n-    }\n-\n-    // Note: keep this in sync with `super::new_parser_from_source_str` until\n-    // #16472 is resolved.\n-    // Create a new parser from a source string\n-    fn new_parser_from_source_str<'a>(sess: &'a ParseSess,\n-                                      cfg: ast::CrateConfig,\n-                                      name: String,\n-                                      source: String) -> Parser<'a> {\n-        filemap_to_parser(sess, string_to_filemap(sess, source, name), cfg)\n-    }\n-\n-    // Note: keep this in sync with `super::filemap_to_parserr` until\n-    // #16472 is resolved.\n-    /// Given a filemap and config, return a parser\n-    fn filemap_to_parser<'a>(sess: &'a ParseSess,\n-                             filemap: Rc<FileMap>,\n-                             cfg: ast::CrateConfig) -> Parser<'a> {\n-        tts_to_parser(sess, filemap_to_tts(sess, filemap), cfg)\n-    }\n-\n-    // Note: keep this in sync with `super::filemap_to_tts` until\n-    // #16472 is resolved.\n-    /// Given a filemap, produce a sequence of token-trees\n-    fn filemap_to_tts(sess: &ParseSess, filemap: Rc<FileMap>)\n-                      -> Vec<ast::TokenTree> {\n-        // it appears to me that the cfg doesn't matter here... indeed,\n-        // parsing tt's probably shouldn't require a parser at all.\n-        use super::lexer::make_reader_with_embedded_idents as make_reader;\n-        let cfg = Vec::new();\n-        let srdr = make_reader(&sess.span_diagnostic, filemap);\n-        let mut p1 = Parser::new(sess, cfg, Box::new(srdr));\n-        panictry!(p1.parse_all_token_trees())\n-    }\n-}\n-\n /// Abort if necessary\n pub fn maybe_aborted<T>(result: T, p: Parser) -> T {\n     p.abort_if_errors();"}, {"sha": "5f097256318c0afdac6c30229ef741312888709c", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -1152,7 +1152,8 @@ impl<'a> Parser<'a> {\n             &token::OpenDelim(token::Brace),\n             &token::CloseDelim(token::Brace),\n             seq_sep_none(),\n-            |p| {\n+            |p| -> PResult<P<TraitItem>> {\n+            maybe_whole!(no_clone p, NtTraitItem);\n             let mut attrs = p.parse_outer_attributes();\n             let lo = p.span.lo;\n \n@@ -2943,6 +2944,8 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn parse_arm_nopanic(&mut self) -> PResult<Arm> {\n+        maybe_whole!(no_clone self, NtArm);\n+\n         let attrs = self.parse_outer_attributes();\n         let pats = try!(self.parse_pats());\n         let mut guard = None;\n@@ -4335,6 +4338,8 @@ impl<'a> Parser<'a> {\n \n     /// Parse an impl item.\n     pub fn parse_impl_item(&mut self) -> PResult<P<ImplItem>> {\n+        maybe_whole!(no_clone self, NtImplItem);\n+\n         let mut attrs = self.parse_outer_attributes();\n         let lo = self.span.lo;\n         let vis = try!(self.parse_visibility());"}, {"sha": "0106de913bb87de12ca60b7e925698199f110abc", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -381,6 +381,10 @@ pub enum Nonterminal {\n     NtMeta(P<ast::MetaItem>),\n     NtPath(Box<ast::Path>),\n     NtTT(P<ast::TokenTree>), // needs P'ed to break a circularity\n+    // These is not exposed to macros, but is used by quasiquote.\n+    NtArm(ast::Arm),\n+    NtImplItem(P<ast::ImplItem>),\n+    NtTraitItem(P<ast::TraitItem>),\n }\n \n impl fmt::Debug for Nonterminal {\n@@ -396,6 +400,9 @@ impl fmt::Debug for Nonterminal {\n             NtMeta(..) => f.pad(\"NtMeta(..)\"),\n             NtPath(..) => f.pad(\"NtPath(..)\"),\n             NtTT(..) => f.pad(\"NtTT(..)\"),\n+            NtArm(..) => f.pad(\"NtArm(..)\"),\n+            NtImplItem(..) => f.pad(\"NtImplItem(..)\"),\n+            NtTraitItem(..) => f.pad(\"NtTraitItem(..)\"),\n         }\n     }\n }"}, {"sha": "36364eb9bf3d5901bc9e1fc095d4d2e02d80c252", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 41, "deletions": 81, "changes": 122, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -66,7 +66,6 @@ pub struct State<'a> {\n     cur_cmnt_and_lit: CurrentCommentAndLiteral,\n     boxes: Vec<pp::Breaks>,\n     ann: &'a (PpAnn+'a),\n-    encode_idents_with_hygiene: bool,\n }\n \n pub fn rust_printer<'a>(writer: Box<Write+'a>) -> State<'a> {\n@@ -87,7 +86,6 @@ pub fn rust_printer_annotated<'a>(writer: Box<Write+'a>,\n         },\n         boxes: Vec::new(),\n         ann: ann,\n-        encode_idents_with_hygiene: false,\n     }\n }\n \n@@ -179,7 +177,6 @@ impl<'a> State<'a> {\n             },\n             boxes: Vec::new(),\n             ann: ann,\n-            encode_idents_with_hygiene: false,\n         }\n     }\n }\n@@ -290,103 +287,99 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::SpecialVarNt(var)    => format!(\"${}\", var.as_str()),\n \n         token::Interpolated(ref nt) => match *nt {\n-            token::NtExpr(ref e)  => expr_to_string(&**e),\n-            token::NtMeta(ref e)  => meta_item_to_string(&**e),\n-            token::NtTy(ref e)    => ty_to_string(&**e),\n-            token::NtPath(ref e)  => path_to_string(&**e),\n-            token::NtItem(..)     => \"an interpolated item\".to_string(),\n-            token::NtBlock(..)    => \"an interpolated block\".to_string(),\n-            token::NtStmt(..)     => \"an interpolated statement\".to_string(),\n-            token::NtPat(..)      => \"an interpolated pattern\".to_string(),\n-            token::NtIdent(..)    => \"an interpolated identifier\".to_string(),\n-            token::NtTT(..)       => \"an interpolated tt\".to_string(),\n+            token::NtExpr(ref e)   => expr_to_string(&**e),\n+            token::NtMeta(ref e)   => meta_item_to_string(&**e),\n+            token::NtTy(ref e)     => ty_to_string(&**e),\n+            token::NtPath(ref e)   => path_to_string(&**e),\n+            token::NtItem(..)      => \"an interpolated item\".to_string(),\n+            token::NtBlock(..)     => \"an interpolated block\".to_string(),\n+            token::NtStmt(..)      => \"an interpolated statement\".to_string(),\n+            token::NtPat(..)       => \"an interpolated pattern\".to_string(),\n+            token::NtIdent(..)     => \"an interpolated identifier\".to_string(),\n+            token::NtTT(..)        => \"an interpolated tt\".to_string(),\n+            token::NtArm(..)       => \"an interpolated arm\".to_string(),\n+            token::NtImplItem(..)  => \"an interpolated impl item\".to_string(),\n+            token::NtTraitItem(..) => \"an interpolated trait item\".to_string(),\n         }\n     }\n }\n \n-// FIXME (Issue #16472): the thing_to_string_impls macro should go away\n-// after we revise the syntax::ext::quote::ToToken impls to go directly\n-// to token-trees instead of thing -> string -> token-trees.\n-\n-macro_rules! thing_to_string_impls {\n-    ($to_string:ident) => {\n-\n pub fn ty_to_string(ty: &ast::Ty) -> String {\n-    $to_string(|s| s.print_type(ty))\n+    to_string(|s| s.print_type(ty))\n }\n \n pub fn bounds_to_string(bounds: &[ast::TyParamBound]) -> String {\n-    $to_string(|s| s.print_bounds(\"\", bounds))\n+    to_string(|s| s.print_bounds(\"\", bounds))\n }\n \n pub fn pat_to_string(pat: &ast::Pat) -> String {\n-    $to_string(|s| s.print_pat(pat))\n+    to_string(|s| s.print_pat(pat))\n }\n \n pub fn arm_to_string(arm: &ast::Arm) -> String {\n-    $to_string(|s| s.print_arm(arm))\n+    to_string(|s| s.print_arm(arm))\n }\n \n pub fn expr_to_string(e: &ast::Expr) -> String {\n-    $to_string(|s| s.print_expr(e))\n+    to_string(|s| s.print_expr(e))\n }\n \n pub fn lifetime_to_string(e: &ast::Lifetime) -> String {\n-    $to_string(|s| s.print_lifetime(e))\n+    to_string(|s| s.print_lifetime(e))\n }\n \n pub fn tt_to_string(tt: &ast::TokenTree) -> String {\n-    $to_string(|s| s.print_tt(tt))\n+    to_string(|s| s.print_tt(tt))\n }\n \n pub fn tts_to_string(tts: &[ast::TokenTree]) -> String {\n-    $to_string(|s| s.print_tts(tts))\n+    to_string(|s| s.print_tts(tts))\n }\n \n pub fn stmt_to_string(stmt: &ast::Stmt) -> String {\n-    $to_string(|s| s.print_stmt(stmt))\n+    to_string(|s| s.print_stmt(stmt))\n }\n \n pub fn attr_to_string(attr: &ast::Attribute) -> String {\n-    $to_string(|s| s.print_attribute(attr))\n+    to_string(|s| s.print_attribute(attr))\n }\n \n pub fn item_to_string(i: &ast::Item) -> String {\n-    $to_string(|s| s.print_item(i))\n+    to_string(|s| s.print_item(i))\n }\n \n pub fn impl_item_to_string(i: &ast::ImplItem) -> String {\n-    $to_string(|s| s.print_impl_item(i))\n+    to_string(|s| s.print_impl_item(i))\n }\n \n pub fn trait_item_to_string(i: &ast::TraitItem) -> String {\n-    $to_string(|s| s.print_trait_item(i))\n+    to_string(|s| s.print_trait_item(i))\n }\n \n pub fn generics_to_string(generics: &ast::Generics) -> String {\n-    $to_string(|s| s.print_generics(generics))\n+    to_string(|s| s.print_generics(generics))\n }\n \n pub fn where_clause_to_string(i: &ast::WhereClause) -> String {\n-    $to_string(|s| s.print_where_clause(i))\n+    to_string(|s| s.print_where_clause(i))\n }\n \n pub fn fn_block_to_string(p: &ast::FnDecl) -> String {\n-    $to_string(|s| s.print_fn_block_args(p))\n+    to_string(|s| s.print_fn_block_args(p))\n }\n \n pub fn path_to_string(p: &ast::Path) -> String {\n-    $to_string(|s| s.print_path(p, false, 0))\n+    to_string(|s| s.print_path(p, false, 0))\n }\n \n pub fn ident_to_string(id: &ast::Ident) -> String {\n-    $to_string(|s| s.print_ident(*id))\n+    to_string(|s| s.print_ident(*id))\n }\n \n pub fn fun_to_string(decl: &ast::FnDecl, unsafety: ast::Unsafety, name: ast::Ident,\n                   opt_explicit_self: Option<&ast::ExplicitSelf_>,\n                   generics: &ast::Generics) -> String {\n-    $to_string(|s| {\n+    to_string(|s| {\n         try!(s.head(\"\"));\n         try!(s.print_fn(decl, unsafety, abi::Rust, Some(name),\n                         generics, opt_explicit_self, ast::Inherited));\n@@ -396,7 +389,7 @@ pub fn fun_to_string(decl: &ast::FnDecl, unsafety: ast::Unsafety, name: ast::Ide\n }\n \n pub fn block_to_string(blk: &ast::Block) -> String {\n-    $to_string(|s| {\n+    to_string(|s| {\n         // containing cbox, will be closed by print-block at }\n         try!(s.cbox(indent_unit));\n         // head-ibox, will be closed by print-block after {\n@@ -406,59 +399,31 @@ pub fn block_to_string(blk: &ast::Block) -> String {\n }\n \n pub fn meta_item_to_string(mi: &ast::MetaItem) -> String {\n-    $to_string(|s| s.print_meta_item(mi))\n+    to_string(|s| s.print_meta_item(mi))\n }\n \n pub fn attribute_to_string(attr: &ast::Attribute) -> String {\n-    $to_string(|s| s.print_attribute(attr))\n+    to_string(|s| s.print_attribute(attr))\n }\n \n pub fn lit_to_string(l: &ast::Lit) -> String {\n-    $to_string(|s| s.print_literal(l))\n+    to_string(|s| s.print_literal(l))\n }\n \n pub fn explicit_self_to_string(explicit_self: &ast::ExplicitSelf_) -> String {\n-    $to_string(|s| s.print_explicit_self(explicit_self, ast::MutImmutable).map(|_| {}))\n+    to_string(|s| s.print_explicit_self(explicit_self, ast::MutImmutable).map(|_| {}))\n }\n \n pub fn variant_to_string(var: &ast::Variant) -> String {\n-    $to_string(|s| s.print_variant(var))\n+    to_string(|s| s.print_variant(var))\n }\n \n pub fn arg_to_string(arg: &ast::Arg) -> String {\n-    $to_string(|s| s.print_arg(arg))\n+    to_string(|s| s.print_arg(arg))\n }\n \n pub fn mac_to_string(arg: &ast::Mac) -> String {\n-    $to_string(|s| s.print_mac(arg, ::parse::token::Paren))\n-}\n-\n-} }\n-\n-thing_to_string_impls! { to_string }\n-\n-// FIXME (Issue #16472): the whole `with_hygiene` mod should go away\n-// after we revise the syntax::ext::quote::ToToken impls to go directly\n-// to token-trees instea of thing -> string -> token-trees.\n-\n-pub mod with_hygiene {\n-    use abi;\n-    use ast;\n-    use std::io;\n-    use super::indent_unit;\n-\n-    // This function is the trick that all the rest of the routines\n-    // hang on.\n-    pub fn to_string_hyg<F>(f: F) -> String where\n-        F: FnOnce(&mut super::State) -> io::Result<()>,\n-    {\n-        super::to_string(move |s| {\n-            s.encode_idents_with_hygiene = true;\n-            f(s)\n-        })\n-    }\n-\n-    thing_to_string_impls! { to_string_hyg }\n+    to_string(|s| s.print_mac(arg, ::parse::token::Paren))\n }\n \n pub fn visibility_qualified(vis: ast::Visibility, s: &str) -> String {\n@@ -2006,12 +1971,7 @@ impl<'a> State<'a> {\n     }\n \n     pub fn print_ident(&mut self, ident: ast::Ident) -> io::Result<()> {\n-        if self.encode_idents_with_hygiene {\n-            let encoded = ident.encode_with_hygiene();\n-            try!(word(&mut self.s, &encoded[..]))\n-        } else {\n-            try!(word(&mut self.s, &token::get_ident(ident)))\n-        }\n+        try!(word(&mut self.s, &token::get_ident(ident)));\n         self.ann.post(self, NodeIdent(&ident))\n     }\n "}, {"sha": "54aac5195aee3bab71ec7c0c2bc9bc9121040f5b", "filename": "src/test/auxiliary/macro_crate_test.rs", "status": "modified", "additions": 0, "deletions": 26, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Ftest%2Fauxiliary%2Fmacro_crate_test.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Ftest%2Fauxiliary%2Fmacro_crate_test.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Fmacro_crate_test.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -32,7 +32,6 @@ macro_rules! unexported_macro { () => (3) }\n #[plugin_registrar]\n pub fn plugin_registrar(reg: &mut Registry) {\n     reg.register_macro(\"make_a_1\", expand_make_a_1);\n-    reg.register_macro(\"forged_ident\", expand_forged_ident);\n     reg.register_macro(\"identity\", expand_identity);\n     reg.register_syntax_extension(\n         token::intern(\"into_foo\"),\n@@ -104,29 +103,4 @@ fn expand_into_foo_multi(cx: &mut ExtCtxt,\n     }\n }\n \n-fn expand_forged_ident(cx: &mut ExtCtxt, sp: Span, tts: &[TokenTree]) -> Box<MacResult+'static> {\n-    use syntax::ext::quote::rt::*;\n-\n-    if !tts.is_empty() {\n-        cx.span_fatal(sp, \"forged_ident takes no arguments\");\n-    }\n-\n-    // Most of this is modelled after the expansion of the `quote_expr!`\n-    // macro ...\n-    let parse_sess = cx.parse_sess();\n-    let cfg = cx.cfg();\n-\n-    // ... except this is where we inject a forged identifier,\n-    // and deliberately do not call `cx.parse_tts_with_hygiene`\n-    // (because we are testing that this will be *rejected*\n-    //  by the default parser).\n-\n-    let expr = {\n-        let tt = cx.parse_tts(\"\\x00name_2,ctxt_0\\x00\".to_string());\n-        let mut parser = new_parser_from_tts(parse_sess, cfg, tt);\n-        parser.parse_expr()\n-    };\n-    MacEager::expr(expr)\n-}\n-\n pub fn foo() {}"}, {"sha": "fd1deffb59d4da94a3f81b8253ee63752b1cb0fc", "filename": "src/test/compile-fail-fulldeps/macro-crate-cannot-read-embedded-ident.rs", "status": "removed", "additions": 0, "deletions": 28, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/b0043db4658feed7b7d17fd45285745d8af38001/src%2Ftest%2Fcompile-fail-fulldeps%2Fmacro-crate-cannot-read-embedded-ident.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b0043db4658feed7b7d17fd45285745d8af38001/src%2Ftest%2Fcompile-fail-fulldeps%2Fmacro-crate-cannot-read-embedded-ident.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail-fulldeps%2Fmacro-crate-cannot-read-embedded-ident.rs?ref=b0043db4658feed7b7d17fd45285745d8af38001", "patch": "@@ -1,28 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// aux-build:macro_crate_test.rs\n-// ignore-stage1\n-// error-pattern: unknown start of token: \\u{0}\n-\n-// Issue #15750 and #15962 : this test is checking that the standard\n-// parser rejects embedded idents.  pnkfelix did not want to attempt\n-// to make a test file that itself used the embedded ident input form,\n-// since he worried that would be difficult to work with in many text\n-// editors, so instead he made a macro that expands into the embedded\n-// ident form.\n-\n-#![feature(plugin)]\n-#![plugin(macro_crate_test)]\n-\n-fn main() {\n-    let x = 0;\n-    assert_eq!(3, forged_ident!());\n-}"}, {"sha": "cf68efe5855b754659c918c778da6e5de52be419", "filename": "src/test/compile-fail-fulldeps/qquote.rs", "status": "modified", "additions": 15, "deletions": 28, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Ftest%2Fcompile-fail-fulldeps%2Fqquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Ftest%2Fcompile-fail-fulldeps%2Fqquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail-fulldeps%2Fqquote.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -15,38 +15,25 @@\n extern crate syntax;\n \n use syntax::ast;\n-use syntax::codemap;\n+use syntax::codemap::{self, DUMMY_SP};\n use syntax::parse;\n use syntax::print::pprust;\n \n-trait FakeExtCtxt {\n-    fn call_site(&self) -> codemap::Span;\n-    fn cfg(&self) -> ast::CrateConfig;\n-    fn ident_of(&self, st: &str) -> ast::Ident;\n-    fn name_of(&self, st: &str) -> ast::Name;\n-    fn parse_sess(&self) -> &parse::ParseSess;\n-}\n-\n-impl FakeExtCtxt for parse::ParseSess {\n-    fn call_site(&self) -> codemap::Span {\n-        codemap::Span {\n-            lo: codemap::BytePos(0),\n-            hi: codemap::BytePos(0),\n-            expn_id: codemap::NO_EXPANSION,\n-        }\n-    }\n-    fn cfg(&self) -> ast::CrateConfig { Vec::new() }\n-    fn ident_of(&self, st: &str) -> ast::Ident {\n-        parse::token::str_to_ident(st)\n-    }\n-    fn name_of(&self, st: &str) -> ast::Name {\n-        parse::token::intern(st)\n-    }\n-    fn parse_sess(&self) -> &parse::ParseSess { self }\n-}\n-\n fn main() {\n-    let cx = parse::new_parse_sess();\n+    let ps = syntax::parse::new_parse_sess();\n+    let mut cx = syntax::ext::base::ExtCtxt::new(\n+        &ps, vec![],\n+        syntax::ext::expand::ExpansionConfig::default(\"qquote\".to_string()));\n+    cx.bt_push(syntax::codemap::ExpnInfo {\n+        call_site: DUMMY_SP,\n+        callee: syntax::codemap::NameAndSpan {\n+            name: \"\".to_string(),\n+            format: syntax::codemap::MacroBang,\n+            allow_internal_unstable: false,\n+            span: None,\n+        }\n+    });\n+    let cx = &mut cx;\n \n     assert_eq!(pprust::expr_to_string(&*quote_expr!(&cx, 23)), \"23\");\n "}, {"sha": "6ae22392b939eff3d10ee811caa08710edb70d96", "filename": "src/test/run-fail/qquote.rs", "status": "modified", "additions": 15, "deletions": 28, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Ftest%2Frun-fail%2Fqquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Ftest%2Frun-fail%2Fqquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-fail%2Fqquote.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -17,38 +17,25 @@\n extern crate syntax;\n \n use syntax::ast;\n-use syntax::codemap;\n+use syntax::codemap::{self, DUMMY_SP};\n use syntax::parse;\n use syntax::print::pprust;\n \n-trait FakeExtCtxt {\n-    fn call_site(&self) -> codemap::Span;\n-    fn cfg(&self) -> ast::CrateConfig;\n-    fn ident_of(&self, st: &str) -> ast::Ident;\n-    fn name_of(&self, st: &str) -> ast::Name;\n-    fn parse_sess(&self) -> &parse::ParseSess;\n-}\n-\n-impl FakeExtCtxt for parse::ParseSess {\n-    fn call_site(&self) -> codemap::Span {\n-        codemap::Span {\n-            lo: codemap::BytePos(0),\n-            hi: codemap::BytePos(0),\n-            expn_id: codemap::NO_EXPANSION,\n-        }\n-    }\n-    fn cfg(&self) -> ast::CrateConfig { Vec::new() }\n-    fn ident_of(&self, st: &str) -> ast::Ident {\n-        parse::token::str_to_ident(st)\n-    }\n-    fn name_of(&self, st: &str) -> ast::Name {\n-        parse::token::intern(st)\n-    }\n-    fn parse_sess(&self) -> &parse::ParseSess { self }\n-}\n-\n fn main() {\n-    let cx = parse::new_parse_sess();\n+    let ps = syntax::parse::new_parse_sess();\n+    let mut cx = syntax::ext::base::ExtCtxt::new(\n+        &ps, vec![],\n+        syntax::ext::expand::ExpansionConfig::default(\"qquote\".to_string()));\n+    cx.bt_push(syntax::codemap::ExpnInfo {\n+        call_site: DUMMY_SP,\n+        callee: syntax::codemap::NameAndSpan {\n+            name: \"\".to_string(),\n+            format: syntax::codemap::MacroBang,\n+            allow_internal_unstable: false,\n+            span: None,\n+        }\n+    });\n+    let cx = &mut cx;\n \n     assert_eq!(pprust::expr_to_string(&*quote_expr!(&cx, 23)), \"23\");\n "}, {"sha": "0d047be02ca1dc7c135392b8765817c8ad7e3b40", "filename": "src/test/run-make/cannot-read-embedded-idents/Makefile", "status": "removed", "additions": 0, "deletions": 28, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/b0043db4658feed7b7d17fd45285745d8af38001/src%2Ftest%2Frun-make%2Fcannot-read-embedded-idents%2FMakefile", "raw_url": "https://github.com/rust-lang/rust/raw/b0043db4658feed7b7d17fd45285745d8af38001/src%2Ftest%2Frun-make%2Fcannot-read-embedded-idents%2FMakefile", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-make%2Fcannot-read-embedded-idents%2FMakefile?ref=b0043db4658feed7b7d17fd45285745d8af38001", "patch": "@@ -1,28 +0,0 @@\n--include ../tools.mk\n-\n-# Issue #15750, #15962 : This test ensures that our special embedded\n-# ident syntax hack is not treated as legitimate input by the lexer in\n-# normal mode.\n-#\n-# It is modelled after the `unicode-input/` test, since we need to\n-# create files with syntax that can trip up normal text editting tools\n-# (namely text with embedded nul-bytes).\n-\n-# This test attempts to run rustc itself from the compiled binary; but\n-# that means that you need to set the LD_LIBRARY_PATH for rustc itself\n-# while running create_and_compile, and that won't work for stage1.\n-\n-# FIXME ignore windows\n-ifndef IS_WINDOWS\n-ifeq ($(RUST_BUILD_STAGE),1)\n-DOTEST=\n-else\n-DOTEST=dotest\n-endif\n-endif\n-\n-all: $(DOTEST)\n-\n-dotest:\n-\t$(RUSTC) create_and_compile.rs\n-\t$(call RUN,create_and_compile)  \"$(RUSTC)\" \"$(TMPDIR)\""}, {"sha": "fd69d2786b8d0800adb74bc000a7b73b638e1c0f", "filename": "src/test/run-make/cannot-read-embedded-idents/create_and_compile.rs", "status": "removed", "additions": 0, "deletions": 44, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/b0043db4658feed7b7d17fd45285745d8af38001/src%2Ftest%2Frun-make%2Fcannot-read-embedded-idents%2Fcreate_and_compile.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b0043db4658feed7b7d17fd45285745d8af38001/src%2Ftest%2Frun-make%2Fcannot-read-embedded-idents%2Fcreate_and_compile.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-make%2Fcannot-read-embedded-idents%2Fcreate_and_compile.rs?ref=b0043db4658feed7b7d17fd45285745d8af38001", "patch": "@@ -1,44 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use std::env;\n-use std::fs::File;\n-use std::process::Command;\n-use std::io::Write;\n-use std::path::Path;\n-\n-// creates broken.rs, which has the Ident \\x00name_0,ctxt_0\\x00\n-// embedded within it, and then attempts to compile broken.rs with the\n-// provided `rustc`\n-\n-fn main() {\n-    let args: Vec<String> = env::args().collect();\n-    let rustc = &args[1];\n-    let tmpdir = Path::new(&args[2]);\n-\n-    let main_file = tmpdir.join(\"broken.rs\");\n-    let _ = File::create(&main_file).unwrap()\n-        .write_all(b\"pub fn main() {\n-                   let \\x00name_0,ctxt_0\\x00 = 3;\n-                   println!(\\\"{}\\\", \\x00name_0,ctxt_0\\x00);\n-        }\").unwrap();\n-\n-    // rustc is passed to us with --out-dir and -L etc., so we\n-    // can't exec it directly\n-    let result = Command::new(\"sh\")\n-        .arg(\"-c\")\n-        .arg(&format!(\"{} {}\", rustc, main_file.display()))\n-        .output().unwrap();\n-    let err = String::from_utf8_lossy(&result.stderr);\n-\n-    // positive test so that this test will be updated when the\n-    // compiler changes.\n-    assert!(err.contains(\"unknown start of token\"))\n-}"}, {"sha": "ceface384847fe540c917a3c985776c129d88a2a", "filename": "src/test/run-pass-fulldeps/qquote.rs", "status": "modified", "additions": 38, "deletions": 41, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Ftest%2Frun-pass-fulldeps%2Fqquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6365080c5cd27b74ec87420c351a3e7bdcff988e/src%2Ftest%2Frun-pass-fulldeps%2Fqquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fqquote.rs?ref=6365080c5cd27b74ec87420c351a3e7bdcff988e", "patch": "@@ -9,59 +9,56 @@\n // except according to those terms.\n \n // ignore-cross-compile\n-// ignore-pretty\n \n #![feature(quote, rustc_private)]\n \n extern crate syntax;\n \n-use syntax::ast;\n-use syntax::codemap;\n-use syntax::parse;\n-use syntax::print::pprust;\n+use syntax::codemap::DUMMY_SP;\n+use syntax::print::pprust::*;\n \n-trait FakeExtCtxt {\n-    fn call_site(&self) -> codemap::Span;\n-    fn cfg(&self) -> ast::CrateConfig;\n-    fn ident_of(&self, st: &str) -> ast::Ident;\n-    fn name_of(&self, st: &str) -> ast::Name;\n-    fn parse_sess(&self) -> &parse::ParseSess;\n-}\n-\n-impl FakeExtCtxt for parse::ParseSess {\n-    fn call_site(&self) -> codemap::Span {\n-        codemap::Span {\n-            lo: codemap::BytePos(0),\n-            hi: codemap::BytePos(0),\n-            expn_id: codemap::NO_EXPANSION,\n+fn main() {\n+    let ps = syntax::parse::new_parse_sess();\n+    let mut cx = syntax::ext::base::ExtCtxt::new(\n+        &ps, vec![],\n+        syntax::ext::expand::ExpansionConfig::default(\"qquote\".to_string()));\n+    cx.bt_push(syntax::codemap::ExpnInfo {\n+        call_site: DUMMY_SP,\n+        callee: syntax::codemap::NameAndSpan {\n+            name: \"\".to_string(),\n+            format: syntax::codemap::MacroBang,\n+            allow_internal_unstable: false,\n+            span: None,\n         }\n+    });\n+    let cx = &mut cx;\n+\n+    macro_rules! check {\n+        ($f: ident, $($e: expr),+; $expect: expr) => ({\n+            $(assert_eq!($f(&$e), $expect);)+\n+        });\n     }\n-    fn cfg(&self) -> ast::CrateConfig { Vec::new() }\n-    fn ident_of(&self, st: &str) -> ast::Ident {\n-        parse::token::str_to_ident(st)\n-    }\n-    fn name_of(&self, st: &str) -> ast::Name {\n-        parse::token::intern(st)\n-    }\n-    fn parse_sess(&self) -> &parse::ParseSess { self }\n-}\n \n-fn main() {\n-    let cx = parse::new_parse_sess();\n+    let abc = quote_expr!(cx, 23);\n+    check!(expr_to_string, abc, *quote_expr!(cx, $abc); \"23\");\n+\n+    let ty = quote_ty!(cx, isize);\n+    check!(ty_to_string, ty, *quote_ty!(cx, $ty); \"isize\");\n \n-    assert_eq!(pprust::expr_to_string(&*quote_expr!(&cx, 23)), \"23\");\n-    assert_eq!(pprust::pat_to_string(&*quote_pat!(&cx, Some(_))), \"Some(_)\");\n-    assert_eq!(pprust::ty_to_string(&*quote_ty!(&cx, isize)), \"isize\");\n+    let item = quote_item!(cx, static x: $ty = 10;).unwrap();\n+    check!(item_to_string, item, quote_item!(cx, $item).unwrap(); \"static x: isize = 10;\");\n \n-    let arm = quote_arm!(&cx, (ref x, ref y) => (x, y),);\n-    assert_eq!(pprust::arm_to_string(&arm), \" (ref x, ref y) => (x, y),\");\n+    let twenty: u16 = 20;\n+    let stmt = quote_stmt!(cx, let x = $twenty;).unwrap();\n+    check!(stmt_to_string, stmt, *quote_stmt!(cx, $stmt).unwrap(); \"let x = 20u16;\");\n \n-    let attr = quote_attr!(&cx, #![cfg(foo = \"bar\")]);\n-    assert_eq!(pprust::attr_to_string(&attr), \"#![cfg(foo = \\\"bar\\\")]\");\n+    let pat = quote_pat!(cx, Some(_));\n+    check!(pat_to_string, pat, *quote_pat!(cx, $pat); \"Some(_)\");\n \n-    let item = quote_item!(&cx, static x : isize = 10;).unwrap();\n-    assert_eq!(pprust::item_to_string(&*item), \"static x: isize = 10;\");\n+    let expr = quote_expr!(cx, (x, y));\n+    let arm = quote_arm!(cx, (ref x, ref y) => $expr,);\n+    check!(arm_to_string, arm, quote_arm!(cx, $arm); \" (ref x, ref y) => (x, y),\");\n \n-    let stmt = quote_stmt!(&cx, let x = 20;).unwrap();\n-    assert_eq!(pprust::stmt_to_string(&*stmt), \"let x = 20;\");\n+    let attr = quote_attr!(cx, #![cfg(foo = \"bar\")]);\n+    check!(attribute_to_string, attr, quote_attr!(cx, $attr); r#\"#![cfg(foo = \"bar\")]\"#);\n }"}]}