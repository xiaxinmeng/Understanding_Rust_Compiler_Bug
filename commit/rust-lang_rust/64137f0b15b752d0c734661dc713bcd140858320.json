{"sha": "64137f0b15b752d0c734661dc713bcd140858320", "node_id": "C_kwDOAAsO6NoAKDY0MTM3ZjBiMTViNzUyZDBjNzM0NjYxZGM3MTNiY2QxNDA4NTgzMjA", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-03-22T16:24:50Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-03-22T16:24:50Z"}, "message": "Auto merge of #94693 - nnethercote:parser-inlining, r=petrochenkov\n\nInline some parser functions\n\nSome crates that do a lot of complex declarative macro expansion spend a lot of time parsing (and reparsing) tokens. These commits inline some functions for some minor speed wins.\n\nr? `@ghost`", "tree": {"sha": "72e153cb62e710ea76ee6d259141b794aa1ba897", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/72e153cb62e710ea76ee6d259141b794aa1ba897"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/64137f0b15b752d0c734661dc713bcd140858320", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/64137f0b15b752d0c734661dc713bcd140858320", "html_url": "https://github.com/rust-lang/rust/commit/64137f0b15b752d0c734661dc713bcd140858320", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/64137f0b15b752d0c734661dc713bcd140858320/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3ea44938e21f0de8ae7d4f6399a8a30f97867c70", "url": "https://api.github.com/repos/rust-lang/rust/commits/3ea44938e21f0de8ae7d4f6399a8a30f97867c70", "html_url": "https://github.com/rust-lang/rust/commit/3ea44938e21f0de8ae7d4f6399a8a30f97867c70"}, {"sha": "f8f1d3f00b9780e3053b15105f8ed0bfe57a5e9b", "url": "https://api.github.com/repos/rust-lang/rust/commits/f8f1d3f00b9780e3053b15105f8ed0bfe57a5e9b", "html_url": "https://github.com/rust-lang/rust/commit/f8f1d3f00b9780e3053b15105f8ed0bfe57a5e9b"}], "stats": {"total": 45, "additions": 33, "deletions": 12}, "files": [{"sha": "f0ec86ca64ad6cc5e31002811f6e46f2a416b1b8", "filename": "compiler/rustc_parse/src/parser/attr_wrapper.rs", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/64137f0b15b752d0c734661dc713bcd140858320/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64137f0b15b752d0c734661dc713bcd140858320/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs?ref=64137f0b15b752d0c734661dc713bcd140858320", "patch": "@@ -100,11 +100,12 @@ rustc_data_structures::static_assert_size!(LazyTokenStreamImpl, 144);\n \n impl CreateTokenStream for LazyTokenStreamImpl {\n     fn create_token_stream(&self) -> AttrAnnotatedTokenStream {\n-        // The token produced by the final call to `next` or `next_desugared`\n-        // was not actually consumed by the callback. The combination\n-        // of chaining the initial token and using `take` produces the desired\n-        // result - we produce an empty `TokenStream` if no calls were made,\n-        // and omit the final token otherwise.\n+        // The token produced by the final call to `{,inlined_}next` or\n+        // `{,inlined_}next_desugared` was not actually consumed by the\n+        // callback. The combination of chaining the initial token and using\n+        // `take` produces the desired result - we produce an empty\n+        // `TokenStream` if no calls were made, and omit the final token\n+        // otherwise.\n         let mut cursor_snapshot = self.cursor_snapshot.clone();\n         let tokens =\n             std::iter::once((FlatToken::Token(self.start_token.0.clone()), self.start_token.1))"}, {"sha": "3a2f193d31938eb3f3daff6a8e0d3c1df53c3668", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 27, "deletions": 7, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/64137f0b15b752d0c734661dc713bcd140858320/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64137f0b15b752d0c734661dc713bcd140858320/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=64137f0b15b752d0c734661dc713bcd140858320", "patch": "@@ -206,8 +206,9 @@ struct TokenCursor {\n     frame: TokenCursorFrame,\n     stack: Vec<TokenCursorFrame>,\n     desugar_doc_comments: bool,\n-    // Counts the number of calls to `next` or `next_desugared`,\n-    // depending on whether `desugar_doc_comments` is set.\n+    // Counts the number of calls to `{,inlined_}next` or\n+    // `{,inlined_}next_desugared`, depending on whether\n+    // `desugar_doc_comments` is set.\n     num_next_calls: usize,\n     // During parsing, we may sometimes need to 'unglue' a\n     // glued token into two component tokens\n@@ -256,6 +257,12 @@ impl TokenCursorFrame {\n \n impl TokenCursor {\n     fn next(&mut self) -> (Token, Spacing) {\n+        self.inlined_next()\n+    }\n+\n+    /// This always-inlined version should only be used on hot code paths.\n+    #[inline(always)]\n+    fn inlined_next(&mut self) -> (Token, Spacing) {\n         loop {\n             let (tree, spacing) = if !self.frame.open_delim {\n                 self.frame.open_delim = true;\n@@ -285,7 +292,13 @@ impl TokenCursor {\n     }\n \n     fn next_desugared(&mut self) -> (Token, Spacing) {\n-        let (data, attr_style, sp) = match self.next() {\n+        self.inlined_next_desugared()\n+    }\n+\n+    /// This always-inlined version should only be used on hot code paths.\n+    #[inline(always)]\n+    fn inlined_next_desugared(&mut self) -> (Token, Spacing) {\n+        let (data, attr_style, sp) = match self.inlined_next() {\n             (Token { kind: token::DocComment(_, attr_style, data), span }, _) => {\n                 (data, attr_style, span)\n             }\n@@ -463,12 +476,13 @@ impl<'a> Parser<'a> {\n         parser\n     }\n \n+    #[inline]\n     fn next_tok(&mut self, fallback_span: Span) -> (Token, Spacing) {\n         loop {\n             let (mut next, spacing) = if self.desugar_doc_comments {\n-                self.token_cursor.next_desugared()\n+                self.token_cursor.inlined_next_desugared()\n             } else {\n-                self.token_cursor.next()\n+                self.token_cursor.inlined_next()\n             };\n             self.token_cursor.num_next_calls += 1;\n             // We've retrieved an token from the underlying\n@@ -998,7 +1012,13 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Advance the parser by one token using provided token as the next one.\n-    fn bump_with(&mut self, (next_token, next_spacing): (Token, Spacing)) {\n+    fn bump_with(&mut self, next: (Token, Spacing)) {\n+        self.inlined_bump_with(next)\n+    }\n+\n+    /// This always-inlined version should only be used on hot code paths.\n+    #[inline(always)]\n+    fn inlined_bump_with(&mut self, (next_token, next_spacing): (Token, Spacing)) {\n         // Bumping after EOF is a bad sign, usually an infinite loop.\n         if self.prev_token.kind == TokenKind::Eof {\n             let msg = \"attempted to bump the parser past EOF (may be stuck in a loop)\";\n@@ -1016,7 +1036,7 @@ impl<'a> Parser<'a> {\n     /// Advance the parser by one token.\n     pub fn bump(&mut self) {\n         let next_token = self.next_tok(self.token.span);\n-        self.bump_with(next_token);\n+        self.inlined_bump_with(next_token);\n     }\n \n     /// Look-ahead `dist` tokens of `self.token` and get access to that token there."}]}