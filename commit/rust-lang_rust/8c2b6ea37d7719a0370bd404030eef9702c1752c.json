{"sha": "8c2b6ea37d7719a0370bd404030eef9702c1752c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjhjMmI2ZWEzN2Q3NzE5YTAzNzBiZDQwNDAzMGVlZjk3MDJjMTc1MmM=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-09-11T20:39:47Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-09-11T20:39:47Z"}, "message": "Auto merge of #78780 - cjgillot:req, r=Mark-Simulacrum\n\nRefactor query forcing\n\nThe control flow in those functions was very complex, with several layers of continuations.\n\nI tried to simplify the implementation, while keeping essentially the same logic.\nNow, all code paths go through `try_execute_query` for the actual query execution.\nCommunication with the `dep_graph` and the live caches are the only difference between query getting/ensuring/forcing.", "tree": {"sha": "0abf4ec64c0b7cee47007755372a8c0b16939439", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0abf4ec64c0b7cee47007755372a8c0b16939439"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8c2b6ea37d7719a0370bd404030eef9702c1752c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8c2b6ea37d7719a0370bd404030eef9702c1752c", "html_url": "https://github.com/rust-lang/rust/commit/8c2b6ea37d7719a0370bd404030eef9702c1752c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8c2b6ea37d7719a0370bd404030eef9702c1752c/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "43769af69e43d0fb9770f0a392671f000595df78", "url": "https://api.github.com/repos/rust-lang/rust/commits/43769af69e43d0fb9770f0a392671f000595df78", "html_url": "https://github.com/rust-lang/rust/commit/43769af69e43d0fb9770f0a392671f000595df78"}, {"sha": "31330bfce12f59b9c9a4d7b20235fdc38dcf7583", "url": "https://api.github.com/repos/rust-lang/rust/commits/31330bfce12f59b9c9a4d7b20235fdc38dcf7583", "html_url": "https://github.com/rust-lang/rust/commit/31330bfce12f59b9c9a4d7b20235fdc38dcf7583"}], "stats": {"total": 638, "additions": 266, "deletions": 372}, "files": [{"sha": "e589d16992f6c22a43dee49c24d421ae17f21c0d", "filename": "compiler/rustc_query_system/src/dep_graph/graph.rs", "status": "modified", "additions": 77, "deletions": 90, "changes": 167, "blob_url": "https://github.com/rust-lang/rust/blob/8c2b6ea37d7719a0370bd404030eef9702c1752c/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8c2b6ea37d7719a0370bd404030eef9702c1752c/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fdep_graph%2Fgraph.rs?ref=8c2b6ea37d7719a0370bd404030eef9702c1752c", "patch": "@@ -11,6 +11,7 @@ use rustc_serialize::opaque::{FileEncodeResult, FileEncoder};\n use parking_lot::Mutex;\n use smallvec::{smallvec, SmallVec};\n use std::collections::hash_map::Entry;\n+use std::fmt::Debug;\n use std::hash::Hash;\n use std::marker::PhantomData;\n use std::sync::atomic::Ordering::Relaxed;\n@@ -208,89 +209,99 @@ impl<K: DepKind> DepGraph<K> {\n     ///   `arg` parameter.\n     ///\n     /// [rustc dev guide]: https://rustc-dev-guide.rust-lang.org/incremental-compilation.html\n-    pub fn with_task<Ctxt: HasDepContext<DepKind = K>, A, R>(\n+    pub fn with_task<Ctxt: HasDepContext<DepKind = K>, A: Debug, R>(\n         &self,\n         key: DepNode<K>,\n         cx: Ctxt,\n         arg: A,\n         task: fn(Ctxt, A) -> R,\n-        hash_result: impl FnOnce(&mut Ctxt::StableHashingContext, &R) -> Option<Fingerprint>,\n+        hash_result: fn(&mut Ctxt::StableHashingContext, &R) -> Option<Fingerprint>,\n     ) -> (R, DepNodeIndex) {\n-        self.with_task_impl(\n-            key,\n-            cx,\n-            arg,\n-            task,\n-            |_key| {\n-                Some(TaskDeps {\n-                    #[cfg(debug_assertions)]\n-                    node: Some(_key),\n-                    reads: SmallVec::new(),\n-                    read_set: Default::default(),\n-                    phantom_data: PhantomData,\n-                })\n-            },\n-            hash_result,\n-        )\n+        if self.is_fully_enabled() {\n+            self.with_task_impl(key, cx, arg, task, hash_result)\n+        } else {\n+            // Incremental compilation is turned off. We just execute the task\n+            // without tracking. We still provide a dep-node index that uniquely\n+            // identifies the task so that we have a cheap way of referring to\n+            // the query for self-profiling.\n+            (task(cx, arg), self.next_virtual_depnode_index())\n+        }\n     }\n \n-    fn with_task_impl<Ctxt: HasDepContext<DepKind = K>, A, R>(\n+    fn with_task_impl<Ctxt: HasDepContext<DepKind = K>, A: Debug, R>(\n         &self,\n         key: DepNode<K>,\n         cx: Ctxt,\n         arg: A,\n         task: fn(Ctxt, A) -> R,\n-        create_task: fn(DepNode<K>) -> Option<TaskDeps<K>>,\n-        hash_result: impl FnOnce(&mut Ctxt::StableHashingContext, &R) -> Option<Fingerprint>,\n+        hash_result: fn(&mut Ctxt::StableHashingContext, &R) -> Option<Fingerprint>,\n     ) -> (R, DepNodeIndex) {\n-        if let Some(ref data) = self.data {\n-            let dcx = cx.dep_context();\n-            let task_deps = create_task(key).map(Lock::new);\n-            let result = K::with_deps(task_deps.as_ref(), || task(cx, arg));\n-            let edges = task_deps.map_or_else(|| smallvec![], |lock| lock.into_inner().reads);\n-\n-            let mut hcx = dcx.create_stable_hashing_context();\n-            let hashing_timer = dcx.profiler().incr_result_hashing();\n-            let current_fingerprint = hash_result(&mut hcx, &result);\n-\n-            let print_status = cfg!(debug_assertions) && dcx.sess().opts.debugging_opts.dep_tasks;\n-\n-            // Get timer for profiling `DepNode` interning\n-            let node_intern_timer = self\n-                .node_intern_event_id\n-                .map(|eid| dcx.profiler().generic_activity_with_event_id(eid));\n-            // Intern the new `DepNode`.\n-            let (dep_node_index, prev_and_color) = data.current.intern_node(\n-                dcx.profiler(),\n-                &data.previous,\n-                key,\n-                edges,\n-                current_fingerprint,\n-                print_status,\n-            );\n-            drop(node_intern_timer);\n+        // This function is only called when the graph is enabled.\n+        let data = self.data.as_ref().unwrap();\n \n-            hashing_timer.finish_with_query_invocation_id(dep_node_index.into());\n+        // If the following assertion triggers, it can have two reasons:\n+        // 1. Something is wrong with DepNode creation, either here or\n+        //    in `DepGraph::try_mark_green()`.\n+        // 2. Two distinct query keys get mapped to the same `DepNode`\n+        //    (see for example #48923).\n+        assert!(\n+            !self.dep_node_exists(&key),\n+            \"forcing query with already existing `DepNode`\\n\\\n+                 - query-key: {:?}\\n\\\n+                 - dep-node: {:?}\",\n+            arg,\n+            key\n+        );\n \n-            if let Some((prev_index, color)) = prev_and_color {\n-                debug_assert!(\n-                    data.colors.get(prev_index).is_none(),\n-                    \"DepGraph::with_task() - Duplicate DepNodeColor \\\n-                            insertion for {:?}\",\n-                    key\n-                );\n+        let task_deps = if key.kind.is_eval_always() {\n+            None\n+        } else {\n+            Some(Lock::new(TaskDeps {\n+                #[cfg(debug_assertions)]\n+                node: Some(key),\n+                reads: SmallVec::new(),\n+                read_set: Default::default(),\n+                phantom_data: PhantomData,\n+            }))\n+        };\n+        let result = K::with_deps(task_deps.as_ref(), || task(cx, arg));\n+        let edges = task_deps.map_or_else(|| smallvec![], |lock| lock.into_inner().reads);\n+\n+        let dcx = cx.dep_context();\n+        let mut hcx = dcx.create_stable_hashing_context();\n+        let hashing_timer = dcx.profiler().incr_result_hashing();\n+        let current_fingerprint = hash_result(&mut hcx, &result);\n+\n+        let print_status = cfg!(debug_assertions) && dcx.sess().opts.debugging_opts.dep_tasks;\n+\n+        // Get timer for profiling `DepNode` interning\n+        let node_intern_timer =\n+            self.node_intern_event_id.map(|eid| dcx.profiler().generic_activity_with_event_id(eid));\n+        // Intern the new `DepNode`.\n+        let (dep_node_index, prev_and_color) = data.current.intern_node(\n+            dcx.profiler(),\n+            &data.previous,\n+            key,\n+            edges,\n+            current_fingerprint,\n+            print_status,\n+        );\n+        drop(node_intern_timer);\n \n-                data.colors.insert(prev_index, color);\n-            }\n+        hashing_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n-            (result, dep_node_index)\n-        } else {\n-            // Incremental compilation is turned off. We just execute the task\n-            // without tracking. We still provide a dep-node index that uniquely\n-            // identifies the task so that we have a cheap way of referring to\n-            // the query for self-profiling.\n-            (task(cx, arg), self.next_virtual_depnode_index())\n+        if let Some((prev_index, color)) = prev_and_color {\n+            debug_assert!(\n+                data.colors.get(prev_index).is_none(),\n+                \"DepGraph::with_task() - Duplicate DepNodeColor \\\n+                            insertion for {:?}\",\n+                key\n+            );\n+\n+            data.colors.insert(prev_index, color);\n         }\n+\n+        (result, dep_node_index)\n     }\n \n     /// Executes something within an \"anonymous\" task, that is, a task the\n@@ -357,19 +368,6 @@ impl<K: DepKind> DepGraph<K> {\n         }\n     }\n \n-    /// Executes something within an \"eval-always\" task which is a task\n-    /// that runs whenever anything changes.\n-    pub fn with_eval_always_task<Ctxt: HasDepContext<DepKind = K>, A, R>(\n-        &self,\n-        key: DepNode<K>,\n-        cx: Ctxt,\n-        arg: A,\n-        task: fn(Ctxt, A) -> R,\n-        hash_result: impl FnOnce(&mut Ctxt::StableHashingContext, &R) -> Option<Fingerprint>,\n-    ) -> (R, DepNodeIndex) {\n-        self.with_task_impl(key, cx, arg, task, |_| None, hash_result)\n-    }\n-\n     #[inline]\n     pub fn read_index(&self, dep_node_index: DepNodeIndex) {\n         if let Some(ref data) = self.data {\n@@ -484,22 +482,11 @@ impl<K: DepKind> DepGraph<K> {\n         None\n     }\n \n-    /// Try to read a node index for the node dep_node.\n+    /// Try to mark a node index for the node dep_node.\n+    ///\n     /// A node will have an index, when it's already been marked green, or when we can mark it\n     /// green. This function will mark the current task as a reader of the specified node, when\n     /// a node index can be found for that node.\n-    pub fn try_mark_green_and_read<Ctxt: QueryContext<DepKind = K>>(\n-        &self,\n-        tcx: Ctxt,\n-        dep_node: &DepNode<K>,\n-    ) -> Option<(SerializedDepNodeIndex, DepNodeIndex)> {\n-        self.try_mark_green(tcx, dep_node).map(|(prev_index, dep_node_index)| {\n-            debug_assert!(self.is_green(&dep_node));\n-            self.read_index(dep_node_index);\n-            (prev_index, dep_node_index)\n-        })\n-    }\n-\n     pub fn try_mark_green<Ctxt: QueryContext<DepKind = K>>(\n         &self,\n         tcx: Ctxt,"}, {"sha": "98b2a450b19df73ff34e53d5e0078d580ea19b04", "filename": "compiler/rustc_query_system/src/query/job.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/8c2b6ea37d7719a0370bd404030eef9702c1752c/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8c2b6ea37d7719a0370bd404030eef9702c1752c/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs?ref=8c2b6ea37d7719a0370bd404030eef9702c1752c", "patch": "@@ -143,6 +143,8 @@ impl<D> QueryJobId<D>\n where\n     D: Copy + Clone + Eq + Hash,\n {\n+    #[cold]\n+    #[inline(never)]\n     pub(super) fn find_cycle_in_stack(\n         &self,\n         query_map: QueryMap<D>,"}, {"sha": "3534c3242959c1c4f944002e373f11910d6214ad", "filename": "compiler/rustc_query_system/src/query/plumbing.rs", "status": "modified", "additions": 187, "deletions": 282, "changes": 469, "blob_url": "https://github.com/rust-lang/rust/blob/8c2b6ea37d7719a0370bd404030eef9702c1752c/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8c2b6ea37d7719a0370bd404030eef9702c1752c/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs?ref=8c2b6ea37d7719a0370bd404030eef9702c1752c", "patch": "@@ -2,8 +2,7 @@\n //! generate the actual methods on tcx which find and execute the provider,\n //! manage the caches, and so forth.\n \n-use crate::dep_graph::{DepContext, DepKind, DepNode, DepNodeParams};\n-use crate::dep_graph::{DepNodeIndex, SerializedDepNodeIndex};\n+use crate::dep_graph::{DepContext, DepKind, DepNode, DepNodeIndex, DepNodeParams};\n use crate::query::caches::QueryCache;\n use crate::query::config::{QueryDescription, QueryVtable, QueryVtableExt};\n use crate::query::job::{\n@@ -13,12 +12,12 @@ use crate::query::{QueryContext, QueryMap, QuerySideEffects, QueryStackFrame};\n \n use rustc_data_structures::fingerprint::Fingerprint;\n use rustc_data_structures::fx::{FxHashMap, FxHasher};\n+#[cfg(parallel_compiler)]\n+use rustc_data_structures::profiling::TimingGuard;\n use rustc_data_structures::sharded::{get_shard_index_by_hash, Sharded};\n use rustc_data_structures::sync::{Lock, LockGuard};\n use rustc_data_structures::thin_vec::ThinVec;\n-#[cfg(not(parallel_compiler))]\n-use rustc_errors::DiagnosticBuilder;\n-use rustc_errors::{Diagnostic, FatalError};\n+use rustc_errors::{DiagnosticBuilder, FatalError};\n use rustc_span::{Span, DUMMY_SP};\n use std::cell::Cell;\n use std::collections::hash_map::Entry;\n@@ -148,24 +147,21 @@ impl<D, K> Default for QueryState<D, K> {\n \n /// A type representing the responsibility to execute the job in the `job` field.\n /// This will poison the relevant query if dropped.\n-struct JobOwner<'tcx, D, C>\n+struct JobOwner<'tcx, D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone,\n {\n-    state: &'tcx QueryState<D, C::Key>,\n-    cache: &'tcx QueryCacheStore<C>,\n-    key: C::Key,\n+    state: &'tcx QueryState<D, K>,\n+    key: K,\n     id: QueryJobId<D>,\n }\n \n #[cold]\n #[inline(never)]\n-#[cfg(not(parallel_compiler))]\n fn mk_cycle<CTX, V, R>(\n     tcx: CTX,\n-    root: QueryJobId<CTX::DepKind>,\n-    span: Span,\n+    error: CycleError,\n     handle_cycle_error: fn(CTX, DiagnosticBuilder<'_>) -> V,\n     cache: &dyn crate::query::QueryStorage<Value = V, Stored = R>,\n ) -> R\n@@ -174,20 +170,15 @@ where\n     V: std::fmt::Debug,\n     R: Clone,\n {\n-    let error: CycleError = root.find_cycle_in_stack(\n-        tcx.try_collect_active_jobs().unwrap(),\n-        &tcx.current_query_job(),\n-        span,\n-    );\n     let error = report_cycle(tcx.dep_context().sess(), error);\n     let value = handle_cycle_error(tcx, error);\n     cache.store_nocache(value)\n }\n \n-impl<'tcx, D, C> JobOwner<'tcx, D, C>\n+impl<'tcx, D, K> JobOwner<'tcx, D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone,\n {\n     /// Either gets a `JobOwner` corresponding the query, allowing us to\n     /// start executing the query, or returns with the result of the query.\n@@ -199,14 +190,13 @@ where\n     /// for some compile-time benchmarks.\n     #[inline(always)]\n     fn try_start<'b, CTX>(\n-        tcx: CTX,\n-        state: &'b QueryState<CTX::DepKind, C::Key>,\n-        cache: &'b QueryCacheStore<C>,\n+        tcx: &'b CTX,\n+        state: &'b QueryState<CTX::DepKind, K>,\n         span: Span,\n-        key: C::Key,\n+        key: K,\n         lookup: QueryLookup,\n-        query: &QueryVtable<CTX, C::Key, C::Value>,\n-    ) -> TryGetJob<'b, CTX::DepKind, C>\n+        dep_kind: CTX::DepKind,\n+    ) -> TryGetJob<'b, CTX::DepKind, K>\n     where\n         CTX: QueryContext,\n     {\n@@ -227,26 +217,24 @@ where\n                 let key = entry.key().clone();\n                 entry.insert(QueryResult::Started(job));\n \n-                let global_id = QueryJobId::new(id, shard, query.dep_kind);\n-                let owner = JobOwner { state, cache, id: global_id, key };\n+                let global_id = QueryJobId::new(id, shard, dep_kind);\n+                let owner = JobOwner { state, id: global_id, key };\n                 return TryGetJob::NotYetStarted(owner);\n             }\n             Entry::Occupied(mut entry) => {\n                 match entry.get_mut() {\n                     #[cfg(not(parallel_compiler))]\n                     QueryResult::Started(job) => {\n-                        let id = QueryJobId::new(job.id, shard, query.dep_kind);\n+                        let id = QueryJobId::new(job.id, shard, dep_kind);\n \n                         drop(state_lock);\n \n                         // If we are single-threaded we know that we have cycle error,\n                         // so we just return the error.\n-                        return TryGetJob::Cycle(mk_cycle(\n-                            tcx,\n-                            id,\n+                        return TryGetJob::Cycle(id.find_cycle_in_stack(\n+                            tcx.try_collect_active_jobs().unwrap(),\n+                            &tcx.current_query_job(),\n                             span,\n-                            query.handle_cycle_error,\n-                            &cache.cache,\n                         ));\n                     }\n                     #[cfg(parallel_compiler)]\n@@ -258,38 +246,17 @@ where\n \n                         // Get the latch out\n                         let latch = job.latch();\n-                        let key = entry.key().clone();\n \n                         drop(state_lock);\n \n                         // With parallel queries we might just have to wait on some other\n                         // thread.\n                         let result = latch.wait_on(tcx.current_query_job(), span);\n \n-                        if let Err(cycle) = result {\n-                            let cycle = report_cycle(tcx.dep_context().sess(), cycle);\n-                            let value = (query.handle_cycle_error)(tcx, cycle);\n-                            let value = cache.cache.store_nocache(value);\n-                            return TryGetJob::Cycle(value);\n+                        match result {\n+                            Ok(()) => TryGetJob::JobCompleted(query_blocked_prof_timer),\n+                            Err(cycle) => TryGetJob::Cycle(cycle),\n                         }\n-\n-                        let cached = cache\n-                            .cache\n-                            .lookup(cache, &key, |value, index| {\n-                                if unlikely!(tcx.dep_context().profiler().enabled()) {\n-                                    tcx.dep_context().profiler().query_cache_hit(index.into());\n-                                }\n-                                #[cfg(debug_assertions)]\n-                                {\n-                                    cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n-                                }\n-                                (value.clone(), index)\n-                            })\n-                            .unwrap_or_else(|_| panic!(\"value must be in cache after waiting\"));\n-\n-                        query_blocked_prof_timer.finish_with_query_invocation_id(cached.1.into());\n-\n-                        return TryGetJob::JobCompleted(cached);\n                     }\n                     QueryResult::Poisoned => FatalError.raise(),\n                 }\n@@ -299,11 +266,18 @@ where\n \n     /// Completes the query by updating the query cache with the `result`,\n     /// signals the waiter and forgets the JobOwner, so it won't poison the query\n-    fn complete(self, result: C::Value, dep_node_index: DepNodeIndex) -> C::Stored {\n+    fn complete<C>(\n+        self,\n+        cache: &QueryCacheStore<C>,\n+        result: C::Value,\n+        dep_node_index: DepNodeIndex,\n+    ) -> C::Stored\n+    where\n+        C: QueryCache<Key = K>,\n+    {\n         // We can move out of `self` here because we `mem::forget` it below\n         let key = unsafe { ptr::read(&self.key) };\n         let state = self.state;\n-        let cache = self.cache;\n \n         // Forget ourself so our destructor won't poison the query\n         mem::forget(self);\n@@ -330,19 +304,10 @@ where\n     }\n }\n \n-fn with_diagnostics<F, R>(f: F) -> (R, ThinVec<Diagnostic>)\n-where\n-    F: FnOnce(Option<&Lock<ThinVec<Diagnostic>>>) -> R,\n-{\n-    let diagnostics = Lock::new(ThinVec::new());\n-    let result = f(Some(&diagnostics));\n-    (result, diagnostics.into_inner())\n-}\n-\n-impl<'tcx, D, C> Drop for JobOwner<'tcx, D, C>\n+impl<'tcx, D, K> Drop for JobOwner<'tcx, D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone,\n {\n     #[inline(never)]\n     #[cold]\n@@ -373,22 +338,22 @@ pub(crate) struct CycleError {\n }\n \n /// The result of `try_start`.\n-enum TryGetJob<'tcx, D, C>\n+enum TryGetJob<'tcx, D, K>\n where\n     D: Copy + Clone + Eq + Hash,\n-    C: QueryCache,\n+    K: Eq + Hash + Clone,\n {\n     /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n-    NotYetStarted(JobOwner<'tcx, D, C>),\n+    NotYetStarted(JobOwner<'tcx, D, K>),\n \n     /// The query was already completed.\n     /// Returns the result of the query and its dep-node index\n     /// if it succeeded or a cycle error if it failed.\n     #[cfg(parallel_compiler)]\n-    JobCompleted((C::Stored, DepNodeIndex)),\n+    JobCompleted(TimingGuard<'tcx>),\n \n     /// Trying to execute the query resulted in a cycle.\n-    Cycle(C::Stored),\n+    Cycle(CycleError),\n }\n \n /// Checks if the query is already computed and in the cache.\n@@ -428,119 +393,146 @@ fn try_execute_query<CTX, C>(\n     span: Span,\n     key: C::Key,\n     lookup: QueryLookup,\n+    dep_node: Option<DepNode<CTX::DepKind>>,\n     query: &QueryVtable<CTX, C::Key, C::Value>,\n     compute: fn(CTX::DepContext, C::Key) -> C::Value,\n-) -> C::Stored\n+) -> (C::Stored, Option<DepNodeIndex>)\n where\n     C: QueryCache,\n-    C::Key: DepNodeParams<CTX::DepContext>,\n+    C::Key: Clone + DepNodeParams<CTX::DepContext>,\n     CTX: QueryContext,\n {\n-    let job = match JobOwner::<'_, CTX::DepKind, C>::try_start(\n-        tcx,\n+    match JobOwner::<'_, CTX::DepKind, C::Key>::try_start(\n+        &tcx,\n         state,\n-        cache,\n         span,\n         key.clone(),\n         lookup,\n-        query,\n+        query.dep_kind,\n     ) {\n-        TryGetJob::NotYetStarted(job) => job,\n-        TryGetJob::Cycle(result) => return result,\n+        TryGetJob::NotYetStarted(job) => {\n+            let (result, dep_node_index) = execute_job(tcx, key, dep_node, query, job.id, compute);\n+            let result = job.complete(cache, result, dep_node_index);\n+            (result, Some(dep_node_index))\n+        }\n+        TryGetJob::Cycle(error) => {\n+            let result = mk_cycle(tcx, error, query.handle_cycle_error, &cache.cache);\n+            (result, None)\n+        }\n         #[cfg(parallel_compiler)]\n-        TryGetJob::JobCompleted((v, index)) => {\n-            tcx.dep_context().dep_graph().read_index(index);\n-            return v;\n+        TryGetJob::JobCompleted(query_blocked_prof_timer) => {\n+            let (v, index) = cache\n+                .cache\n+                .lookup(cache, &key, |value, index| (value.clone(), index))\n+                .unwrap_or_else(|_| panic!(\"value must be in cache after waiting\"));\n+\n+            if unlikely!(tcx.dep_context().profiler().enabled()) {\n+                tcx.dep_context().profiler().query_cache_hit(index.into());\n+            }\n+            #[cfg(debug_assertions)]\n+            {\n+                cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n+            }\n+            query_blocked_prof_timer.finish_with_query_invocation_id(index.into());\n+\n+            (v, Some(index))\n         }\n-    };\n+    }\n+}\n \n+fn execute_job<CTX, K, V>(\n+    tcx: CTX,\n+    key: K,\n+    mut dep_node_opt: Option<DepNode<CTX::DepKind>>,\n+    query: &QueryVtable<CTX, K, V>,\n+    job_id: QueryJobId<CTX::DepKind>,\n+    compute: fn(CTX::DepContext, K) -> V,\n+) -> (V, DepNodeIndex)\n+where\n+    K: Clone + DepNodeParams<CTX::DepContext>,\n+    V: Debug,\n+    CTX: QueryContext,\n+{\n     let dep_graph = tcx.dep_context().dep_graph();\n \n     // Fast path for when incr. comp. is off.\n     if !dep_graph.is_fully_enabled() {\n         let prof_timer = tcx.dep_context().profiler().query_provider();\n-        let result = tcx.start_query(job.id, None, || compute(*tcx.dep_context(), key));\n+        let result = tcx.start_query(job_id, None, || compute(*tcx.dep_context(), key));\n         let dep_node_index = dep_graph.next_virtual_depnode_index();\n         prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-        return job.complete(result, dep_node_index);\n+        return (result, dep_node_index);\n     }\n \n-    if query.anon {\n-        let prof_timer = tcx.dep_context().profiler().query_provider();\n+    if !query.anon && !query.eval_always {\n+        // `to_dep_node` is expensive for some `DepKind`s.\n+        let dep_node =\n+            dep_node_opt.get_or_insert_with(|| query.to_dep_node(*tcx.dep_context(), &key));\n \n-        let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n-            tcx.start_query(job.id, diagnostics, || {\n-                dep_graph.with_anon_task(*tcx.dep_context(), query.dep_kind, || {\n-                    compute(*tcx.dep_context(), key)\n-                })\n-            })\n-        });\n+        // The diagnostics for this query will be promoted to the current session during\n+        // `try_mark_green()`, so we can ignore them here.\n+        if let Some(ret) = tcx.start_query(job_id, None, || {\n+            try_load_from_disk_and_cache_in_memory(tcx, &key, &dep_node, query, compute)\n+        }) {\n+            return ret;\n+        }\n+    }\n \n-        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+    let prof_timer = tcx.dep_context().profiler().query_provider();\n+    let diagnostics = Lock::new(ThinVec::new());\n \n-        dep_graph.read_index(dep_node_index);\n+    let (result, dep_node_index) = tcx.start_query(job_id, Some(&diagnostics), || {\n+        if query.anon {\n+            return dep_graph.with_anon_task(*tcx.dep_context(), query.dep_kind, || {\n+                compute(*tcx.dep_context(), key)\n+            });\n+        }\n \n-        let side_effects = QuerySideEffects { diagnostics };\n+        // `to_dep_node` is expensive for some `DepKind`s.\n+        let dep_node = dep_node_opt.unwrap_or_else(|| query.to_dep_node(*tcx.dep_context(), &key));\n \n-        if unlikely!(!side_effects.is_empty()) {\n-            tcx.store_side_effects_for_anon_node(dep_node_index, side_effects);\n-        }\n+        dep_graph.with_task(dep_node, *tcx.dep_context(), key, compute, query.hash_result)\n+    });\n \n-        return job.complete(result, dep_node_index);\n-    }\n+    prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n-    let dep_node = query.to_dep_node(*tcx.dep_context(), &key);\n+    let diagnostics = diagnostics.into_inner();\n+    let side_effects = QuerySideEffects { diagnostics };\n \n-    if !query.eval_always {\n-        // The diagnostics for this query will be\n-        // promoted to the current session during\n-        // `try_mark_green()`, so we can ignore them here.\n-        let loaded = tcx.start_query(job.id, None, || {\n-            let marked = dep_graph.try_mark_green_and_read(tcx, &dep_node);\n-            marked.map(|(prev_dep_node_index, dep_node_index)| {\n-                (\n-                    load_from_disk_and_cache_in_memory(\n-                        tcx,\n-                        key.clone(),\n-                        prev_dep_node_index,\n-                        dep_node_index,\n-                        &dep_node,\n-                        query,\n-                        compute,\n-                    ),\n-                    dep_node_index,\n-                )\n-            })\n-        });\n-        if let Some((result, dep_node_index)) = loaded {\n-            return job.complete(result, dep_node_index);\n+    if unlikely!(!side_effects.is_empty()) {\n+        if query.anon {\n+            tcx.store_side_effects_for_anon_node(dep_node_index, side_effects);\n+        } else {\n+            tcx.store_side_effects(dep_node_index, side_effects);\n         }\n     }\n \n-    let (result, dep_node_index) = force_query_with_job(tcx, key, job, dep_node, query, compute);\n-    dep_graph.read_index(dep_node_index);\n-    result\n+    (result, dep_node_index)\n }\n \n-fn load_from_disk_and_cache_in_memory<CTX, K, V: Debug>(\n+fn try_load_from_disk_and_cache_in_memory<CTX, K, V>(\n     tcx: CTX,\n-    key: K,\n-    prev_dep_node_index: SerializedDepNodeIndex,\n-    dep_node_index: DepNodeIndex,\n+    key: &K,\n     dep_node: &DepNode<CTX::DepKind>,\n     query: &QueryVtable<CTX, K, V>,\n     compute: fn(CTX::DepContext, K) -> V,\n-) -> V\n+) -> Option<(V, DepNodeIndex)>\n where\n+    K: Clone,\n     CTX: QueryContext,\n+    V: Debug,\n {\n     // Note this function can be called concurrently from the same query\n     // We must ensure that this is handled correctly.\n \n-    debug_assert!(tcx.dep_context().dep_graph().is_green(dep_node));\n+    let dep_graph = tcx.dep_context().dep_graph();\n+    let (prev_dep_node_index, dep_node_index) = dep_graph.try_mark_green(tcx, &dep_node)?;\n+\n+    debug_assert!(dep_graph.is_green(dep_node));\n \n     // First we try to load the result from the on-disk cache.\n-    let result = if query.cache_on_disk(tcx, &key, None) {\n+    // Some things are never cached on disk.\n+    if query.cache_on_disk(tcx, key, None) {\n         let prof_timer = tcx.dep_context().profiler().incr_cache_loading();\n         let result = query.try_load_from_disk(tcx, prev_dep_node_index);\n         prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n@@ -552,43 +544,39 @@ where\n             \"missing on-disk cache entry for {:?}\",\n             dep_node\n         );\n-        result\n-    } else {\n-        // Some things are never cached on disk.\n-        None\n-    };\n \n-    if let Some(result) = result {\n-        // If `-Zincremental-verify-ich` is specified, re-hash results from\n-        // the cache and make sure that they have the expected fingerprint.\n-        if unlikely!(tcx.dep_context().sess().opts.debugging_opts.incremental_verify_ich) {\n-            incremental_verify_ich(*tcx.dep_context(), &result, dep_node, query);\n+        if let Some(result) = result {\n+            // If `-Zincremental-verify-ich` is specified, re-hash results from\n+            // the cache and make sure that they have the expected fingerprint.\n+            if unlikely!(tcx.dep_context().sess().opts.debugging_opts.incremental_verify_ich) {\n+                incremental_verify_ich(*tcx.dep_context(), &result, dep_node, query);\n+            }\n+\n+            return Some((result, dep_node_index));\n         }\n+    }\n \n-        result\n-    } else {\n-        // We could not load a result from the on-disk cache, so\n-        // recompute.\n-        let prof_timer = tcx.dep_context().profiler().query_provider();\n+    // We could not load a result from the on-disk cache, so\n+    // recompute.\n+    let prof_timer = tcx.dep_context().profiler().query_provider();\n \n-        // The dep-graph for this computation is already in-place.\n-        let result = tcx.dep_context().dep_graph().with_ignore(|| compute(*tcx.dep_context(), key));\n+    // The dep-graph for this computation is already in-place.\n+    let result = dep_graph.with_ignore(|| compute(*tcx.dep_context(), key.clone()));\n \n-        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-\n-        // Verify that re-running the query produced a result with the expected hash\n-        // This catches bugs in query implementations, turning them into ICEs.\n-        // For example, a query might sort its result by `DefId` - since `DefId`s are\n-        // not stable across compilation sessions, the result could get up getting sorted\n-        // in a different order when the query is re-run, even though all of the inputs\n-        // (e.g. `DefPathHash` values) were green.\n-        //\n-        // See issue #82920 for an example of a miscompilation that would get turned into\n-        // an ICE by this check\n-        incremental_verify_ich(*tcx.dep_context(), &result, dep_node, query);\n+    prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n-        result\n-    }\n+    // Verify that re-running the query produced a result with the expected hash\n+    // This catches bugs in query implementations, turning them into ICEs.\n+    // For example, a query might sort its result by `DefId` - since `DefId`s are\n+    // not stable across compilation sessions, the result could get up getting sorted\n+    // in a different order when the query is re-run, even though all of the inputs\n+    // (e.g. `DefPathHash` values) were green.\n+    //\n+    // See issue #82920 for an example of a miscompilation that would get turned into\n+    // an ICE by this check\n+    incremental_verify_ich(*tcx.dep_context(), &result, dep_node, query);\n+\n+    Some((result, dep_node_index))\n }\n \n fn incremental_verify_ich<CTX, K, V: Debug>(\n@@ -648,88 +636,6 @@ fn incremental_verify_ich<CTX, K, V: Debug>(\n     }\n }\n \n-fn force_query_with_job<C, CTX>(\n-    tcx: CTX,\n-    key: C::Key,\n-    job: JobOwner<'_, CTX::DepKind, C>,\n-    dep_node: DepNode<CTX::DepKind>,\n-    query: &QueryVtable<CTX, C::Key, C::Value>,\n-    compute: fn(CTX::DepContext, C::Key) -> C::Value,\n-) -> (C::Stored, DepNodeIndex)\n-where\n-    C: QueryCache,\n-    CTX: QueryContext,\n-{\n-    // If the following assertion triggers, it can have two reasons:\n-    // 1. Something is wrong with DepNode creation, either here or\n-    //    in `DepGraph::try_mark_green()`.\n-    // 2. Two distinct query keys get mapped to the same `DepNode`\n-    //    (see for example #48923).\n-    assert!(\n-        !tcx.dep_context().dep_graph().dep_node_exists(&dep_node),\n-        \"forcing query with already existing `DepNode`\\n\\\n-                 - query-key: {:?}\\n\\\n-                 - dep-node: {:?}\",\n-        key,\n-        dep_node\n-    );\n-\n-    let prof_timer = tcx.dep_context().profiler().query_provider();\n-\n-    let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n-        tcx.start_query(job.id, diagnostics, || {\n-            if query.eval_always {\n-                tcx.dep_context().dep_graph().with_eval_always_task(\n-                    dep_node,\n-                    *tcx.dep_context(),\n-                    key,\n-                    compute,\n-                    query.hash_result,\n-                )\n-            } else {\n-                tcx.dep_context().dep_graph().with_task(\n-                    dep_node,\n-                    *tcx.dep_context(),\n-                    key,\n-                    compute,\n-                    query.hash_result,\n-                )\n-            }\n-        })\n-    });\n-\n-    prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-\n-    let side_effects = QuerySideEffects { diagnostics };\n-\n-    if unlikely!(!side_effects.is_empty()) && dep_node.kind != DepKind::NULL {\n-        tcx.store_side_effects(dep_node_index, side_effects);\n-    }\n-\n-    let result = job.complete(result, dep_node_index);\n-\n-    (result, dep_node_index)\n-}\n-\n-#[inline(never)]\n-fn get_query_impl<CTX, C>(\n-    tcx: CTX,\n-    state: &QueryState<CTX::DepKind, C::Key>,\n-    cache: &QueryCacheStore<C>,\n-    span: Span,\n-    key: C::Key,\n-    lookup: QueryLookup,\n-    query: &QueryVtable<CTX, C::Key, C::Value>,\n-    compute: fn(CTX::DepContext, C::Key) -> C::Value,\n-) -> C::Stored\n-where\n-    CTX: QueryContext,\n-    C: QueryCache,\n-    C::Key: DepNodeParams<CTX::DepContext>,\n-{\n-    try_execute_query(tcx, state, cache, span, key, lookup, query, compute)\n-}\n-\n /// Ensure that either this query has all green inputs or been executed.\n /// Executing `query::ensure(D)` is considered a read of the dep-node `D`.\n /// Returns true if the query should still run.\n@@ -739,33 +645,39 @@ where\n ///\n /// Note: The optimization is only available during incr. comp.\n #[inline(never)]\n-fn ensure_must_run<CTX, K, V>(tcx: CTX, key: &K, query: &QueryVtable<CTX, K, V>) -> bool\n+fn ensure_must_run<CTX, K, V>(\n+    tcx: CTX,\n+    key: &K,\n+    query: &QueryVtable<CTX, K, V>,\n+) -> (bool, Option<DepNode<CTX::DepKind>>)\n where\n     K: crate::dep_graph::DepNodeParams<CTX::DepContext>,\n     CTX: QueryContext,\n {\n     if query.eval_always {\n-        return true;\n+        return (true, None);\n     }\n \n     // Ensuring an anonymous query makes no sense\n     assert!(!query.anon);\n \n     let dep_node = query.to_dep_node(*tcx.dep_context(), key);\n \n-    match tcx.dep_context().dep_graph().try_mark_green_and_read(tcx, &dep_node) {\n+    let dep_graph = tcx.dep_context().dep_graph();\n+    match dep_graph.try_mark_green(tcx, &dep_node) {\n         None => {\n-            // A None return from `try_mark_green_and_read` means that this is either\n+            // A None return from `try_mark_green` means that this is either\n             // a new dep node or that the dep node has already been marked red.\n             // Either way, we can't call `dep_graph.read()` as we don't have the\n             // DepNodeIndex. We must invoke the query itself. The performance cost\n             // this introduces should be negligible as we'll immediately hit the\n             // in-memory cache, or another query down the line will.\n-            true\n+            (true, Some(dep_node))\n         }\n         Some((_, dep_node_index)) => {\n+            dep_graph.read_index(dep_node_index);\n             tcx.dep_context().profiler().query_cache_hit(dep_node_index.into());\n-            false\n+            (false, None)\n         }\n     }\n }\n@@ -804,23 +716,8 @@ where\n         Err(lookup) => lookup,\n     };\n \n-    let job = match JobOwner::<'_, CTX::DepKind, C>::try_start(\n-        tcx,\n-        state,\n-        cache,\n-        DUMMY_SP,\n-        key.clone(),\n-        lookup,\n-        query,\n-    ) {\n-        TryGetJob::NotYetStarted(job) => job,\n-        TryGetJob::Cycle(_) => return true,\n-        #[cfg(parallel_compiler)]\n-        TryGetJob::JobCompleted(_) => return true,\n-    };\n-\n-    force_query_with_job(tcx, key, job, dep_node, query, compute);\n-\n+    let _ =\n+        try_execute_query(tcx, state, cache, DUMMY_SP, key, lookup, Some(dep_node), query, compute);\n     true\n }\n \n@@ -842,25 +739,33 @@ where\n     CTX: QueryContext,\n {\n     let query = &Q::VTABLE;\n-    if let QueryMode::Ensure = mode {\n-        if !ensure_must_run(tcx, &key, query) {\n+    let dep_node = if let QueryMode::Ensure = mode {\n+        let (must_run, dep_node) = ensure_must_run(tcx, &key, query);\n+        if !must_run {\n             return None;\n         }\n-    }\n+        dep_node\n+    } else {\n+        None\n+    };\n \n     debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n     let compute = Q::compute_fn(tcx, &key);\n-    let value = get_query_impl(\n+    let (result, dep_node_index) = try_execute_query(\n         tcx,\n         Q::query_state(tcx),\n         Q::query_cache(tcx),\n         span,\n         key,\n         lookup,\n+        dep_node,\n         query,\n         compute,\n     );\n-    Some(value)\n+    if let Some(dep_node_index) = dep_node_index {\n+        tcx.dep_context().dep_graph().read_index(dep_node_index)\n+    }\n+    Some(result)\n }\n \n pub fn force_query<Q, CTX>(tcx: CTX, dep_node: &DepNode<CTX::DepKind>) -> bool"}]}