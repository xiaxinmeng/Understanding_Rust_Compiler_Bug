{"sha": "e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU3NzJjMjhkMmUxYTZlYjVlNGIxMzk4MDI1NTMwMGIwZWU0ZDc3NGY=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-08-01T17:21:24Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-08-01T17:21:24Z"}, "message": "Auto merge of #43506 - michaelwoerister:async-llvm, r=alexcrichton\n\nRun translation and LLVM in parallel when compiling with multiple CGUs\n\nThis is still a work in progress but the bulk of the implementation is done, so I thought it would be good to get it in front of more eyes.\n\nThis PR makes the compiler start running LLVM while translation is still in progress, effectively allowing for more parallelism towards the end of the compilation pipeline. It also allows the main thread to switch between either translation or running LLVM, which allows to reduce peak memory usage since not all LLVM module have to be kept in memory until linking. This is especially good for incr. comp. but it works just as well when running with `-Ccodegen-units=N`.\n\nIn order to help tuning and debugging the work scheduler, the PR adds the `-Ztrans-time-graph` flag which spits out html files that show how work packages where scheduled:\n![Building regex](https://user-images.githubusercontent.com/1825894/28679272-f6752bd8-72f2-11e7-8a6c-56207855ce95.png)\n(red is translation, green is llvm)\n\nOne side effect here is that `-Ztime-passes` might show something not quite correct because trans and LLVM are not strictly separated anymore. I plan to have some special handling there that will try to produce useful output.\n\nOne open question is how to determine whether the trans-thread should switch to intermediate LLVM processing.\n\nTODO:\n- [x] Restore `-Z time-passes` output for LLVM.\n- [x] Update documentation, esp. for work package scheduling.\n- [x] Tune the scheduling algorithm.\n\ncc @alexcrichton @rust-lang/compiler", "tree": {"sha": "cf8858f932dcbf15c8f0fb29b33e4bc2748e6480", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/cf8858f932dcbf15c8f0fb29b33e4bc2748e6480"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "html_url": "https://github.com/rust-lang/rust/commit/e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c2407516ff33d03d0e24c6a4268a5581e9bc8b4d", "url": "https://api.github.com/repos/rust-lang/rust/commits/c2407516ff33d03d0e24c6a4268a5581e9bc8b4d", "html_url": "https://github.com/rust-lang/rust/commit/c2407516ff33d03d0e24c6a4268a5581e9bc8b4d"}, {"sha": "6468cad977d4c81d30ba000633eaa43bc18591f9", "url": "https://api.github.com/repos/rust-lang/rust/commits/6468cad977d4c81d30ba000633eaa43bc18591f9", "html_url": "https://github.com/rust-lang/rust/commit/6468cad977d4c81d30ba000633eaa43bc18591f9"}], "stats": {"total": 2211, "additions": 1558, "deletions": 653}, "files": [{"sha": "5f363cb4c4871cee5c9485b0167ca2373e4d50ab", "filename": "src/Cargo.lock", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -1518,11 +1518,11 @@ dependencies = [\n name = \"rustc_trans\"\n version = \"0.0.0\"\n dependencies = [\n- \"crossbeam 0.2.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"flate2 0.2.19 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"gcc 0.3.51 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"jobserver 0.1.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"log 0.3.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"num_cpus 1.6.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"owning_ref 0.3.3 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc 0.0.0\",\n  \"rustc-demangle 0.1.4 (registry+https://github.com/rust-lang/crates.io-index)\","}, {"sha": "b1f4aa69adb9f50e9b949d38fa6d410286e6041d", "filename": "src/librustc/middle/cstore.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc%2Fmiddle%2Fcstore.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc%2Fmiddle%2Fcstore.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fcstore.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -50,7 +50,7 @@ pub use self::NativeLibraryKind::*;\n \n // lonely orphan structs and enums looking for a better home\n \n-#[derive(Clone, Debug)]\n+#[derive(Clone, Debug, Copy)]\n pub struct LinkMeta {\n     pub crate_hash: Svh,\n }\n@@ -161,15 +161,13 @@ pub struct ExternCrate {\n }\n \n pub struct EncodedMetadata {\n-    pub raw_data: Vec<u8>,\n-    pub hashes: EncodedMetadataHashes,\n+    pub raw_data: Vec<u8>\n }\n \n impl EncodedMetadata {\n     pub fn new() -> EncodedMetadata {\n         EncodedMetadata {\n             raw_data: Vec::new(),\n-            hashes: EncodedMetadataHashes::new(),\n         }\n     }\n }\n@@ -294,7 +292,7 @@ pub trait CrateStore {\n                                  tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                  link_meta: &LinkMeta,\n                                  reachable: &NodeSet)\n-                                 -> EncodedMetadata;\n+                                 -> (EncodedMetadata, EncodedMetadataHashes);\n     fn metadata_encoding_version(&self) -> &[u8];\n }\n \n@@ -424,7 +422,7 @@ impl CrateStore for DummyCrateStore {\n                                  tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                  link_meta: &LinkMeta,\n                                  reachable: &NodeSet)\n-                                 -> EncodedMetadata {\n+                                 -> (EncodedMetadata, EncodedMetadataHashes) {\n         bug!(\"encode_metadata\")\n     }\n     fn metadata_encoding_version(&self) -> &[u8] { bug!(\"metadata_encoding_version\") }"}, {"sha": "4a9fbbe6f157d53d72585b6b43ca9f926e4ac5c6", "filename": "src/librustc/session/config.rs", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc%2Fsession%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc%2Fsession%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fconfig.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -1059,6 +1059,8 @@ options! {DebuggingOptions, DebuggingSetter, basic_debugging_options,\n         \"choose which RELRO level to use\"),\n     nll: bool = (false, parse_bool, [UNTRACKED],\n                  \"run the non-lexical lifetimes MIR pass\"),\n+    trans_time_graph: bool = (false, parse_bool, [UNTRACKED],\n+        \"generate a graphical HTML report of time spent in trans and LLVM\"),\n }\n \n pub fn default_lib_output() -> CrateType {\n@@ -1498,6 +1500,23 @@ pub fn build_session_options_and_crate_config(matches: &getopts::Matches)\n         early_error(error_format, \"Value for codegen units must be a positive nonzero integer\");\n     }\n \n+    // It's possible that we have `codegen_units > 1` but only one item in\n+    // `trans.modules`.  We could theoretically proceed and do LTO in that\n+    // case, but it would be confusing to have the validity of\n+    // `-Z lto -C codegen-units=2` depend on details of the crate being\n+    // compiled, so we complain regardless.\n+    if cg.lto && cg.codegen_units > 1 {\n+        // This case is impossible to handle because LTO expects to be able\n+        // to combine the entire crate and all its dependencies into a\n+        // single compilation unit, but each codegen unit is in a separate\n+        // LLVM context, so they can't easily be combined.\n+        early_error(error_format, \"can't perform LTO when using multiple codegen units\");\n+    }\n+\n+    if cg.lto && debugging_opts.incremental.is_some() {\n+        early_error(error_format, \"can't perform LTO when compiling incrementally\");\n+    }\n+\n     let mut prints = Vec::<PrintRequest>::new();\n     if cg.target_cpu.as_ref().map_or(false, |s| s == \"help\") {\n         prints.push(PrintRequest::TargetCPUs);"}, {"sha": "244b7f35968894eed7177907624eb7d714f2b455", "filename": "src/librustc/util/common.rs", "status": "modified", "additions": 27, "deletions": 5, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc%2Futil%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc%2Futil%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fcommon.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -57,6 +57,32 @@ pub fn time<T, F>(do_it: bool, what: &str, f: F) -> T where\n     let rv = f();\n     let dur = start.elapsed();\n \n+    print_time_passes_entry_internal(what, dur);\n+\n+    TIME_DEPTH.with(|slot| slot.set(old));\n+\n+    rv\n+}\n+\n+pub fn print_time_passes_entry(do_it: bool, what: &str, dur: Duration) {\n+    if !do_it {\n+        return\n+    }\n+\n+    let old = TIME_DEPTH.with(|slot| {\n+        let r = slot.get();\n+        slot.set(r + 1);\n+        r\n+    });\n+\n+    print_time_passes_entry_internal(what, dur);\n+\n+    TIME_DEPTH.with(|slot| slot.set(old));\n+}\n+\n+fn print_time_passes_entry_internal(what: &str, dur: Duration) {\n+    let indentation = TIME_DEPTH.with(|slot| slot.get());\n+\n     let mem_string = match get_resident() {\n         Some(n) => {\n             let mb = n as f64 / 1_000_000.0;\n@@ -65,14 +91,10 @@ pub fn time<T, F>(do_it: bool, what: &str, f: F) -> T where\n         None => \"\".to_owned(),\n     };\n     println!(\"{}time: {}{}\\t{}\",\n-             repeat(\"  \").take(old).collect::<String>(),\n+             repeat(\"  \").take(indentation).collect::<String>(),\n              duration_to_secs_str(dur),\n              mem_string,\n              what);\n-\n-    TIME_DEPTH.with(|slot| slot.set(old));\n-\n-    rv\n }\n \n // Hack up our own formatting for the duration to make it easier for scripts"}, {"sha": "ee9d30b58fef403c9b8bc46c096f49155f92f51b", "filename": "src/librustc_driver/driver.rs", "status": "modified", "additions": 12, "deletions": 52, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_driver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_driver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fdriver.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -15,8 +15,7 @@ use rustc_data_structures::stable_hasher::StableHasher;\n use rustc_mir as mir;\n use rustc::session::{Session, CompileResult};\n use rustc::session::CompileIncomplete;\n-use rustc::session::config::{self, Input, OutputFilenames, OutputType,\n-                             OutputTypes};\n+use rustc::session::config::{self, Input, OutputFilenames, OutputType};\n use rustc::session::search_paths::PathKind;\n use rustc::lint;\n use rustc::middle::{self, dependency_format, stability, reachable};\n@@ -26,7 +25,6 @@ use rustc::ty::{self, TyCtxt, Resolutions, GlobalArenas};\n use rustc::traits;\n use rustc::util::common::{ErrorReported, time};\n use rustc::util::nodemap::NodeSet;\n-use rustc::util::fs::rename_or_copy_remove;\n use rustc_allocator as allocator;\n use rustc_borrowck as borrowck;\n use rustc_incremental::{self, IncrementalHashesMap};\n@@ -208,7 +206,7 @@ pub fn compile_input(sess: &Session,\n                 println!(\"Pre-trans\");\n                 tcx.print_debug_stats();\n             }\n-            let trans = phase_4_translate_to_llvm(tcx, analysis, &incremental_hashes_map,\n+            let trans = phase_4_translate_to_llvm(tcx, analysis, incremental_hashes_map,\n                                                   &outputs);\n \n             if log_enabled!(::log::LogLevel::Info) {\n@@ -231,16 +229,14 @@ pub fn compile_input(sess: &Session,\n         sess.code_stats.borrow().print_type_sizes();\n     }\n \n-    let phase5_result = phase_5_run_llvm_passes(sess, &trans, &outputs);\n+    let (phase5_result, trans) = phase_5_run_llvm_passes(sess, trans);\n \n     controller_entry_point!(after_llvm,\n                             sess,\n                             CompileState::state_after_llvm(input, sess, outdir, output, &trans),\n                             phase5_result);\n     phase5_result?;\n \n-    write::cleanup_llvm(&trans);\n-\n     phase_6_link_output(sess, &trans, &outputs);\n \n     // Now that we won't touch anything in the incremental compilation directory\n@@ -1055,9 +1051,9 @@ pub fn phase_3_run_analysis_passes<'tcx, F, R>(sess: &'tcx Session,\n /// be discarded.\n pub fn phase_4_translate_to_llvm<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                            analysis: ty::CrateAnalysis,\n-                                           incremental_hashes_map: &IncrementalHashesMap,\n+                                           incremental_hashes_map: IncrementalHashesMap,\n                                            output_filenames: &OutputFilenames)\n-                                           -> trans::CrateTranslation {\n+                                           -> write::OngoingCrateTranslation {\n     let time_passes = tcx.sess.time_passes();\n \n     time(time_passes,\n@@ -1067,63 +1063,27 @@ pub fn phase_4_translate_to_llvm<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     let translation =\n         time(time_passes,\n              \"translation\",\n-             move || trans::trans_crate(tcx, analysis, &incremental_hashes_map, output_filenames));\n-\n-    time(time_passes,\n-         \"assert dep graph\",\n-         || rustc_incremental::assert_dep_graph(tcx));\n+             move || trans::trans_crate(tcx, analysis, incremental_hashes_map, output_filenames));\n \n-    time(time_passes,\n-         \"serialize dep graph\",\n-         || rustc_incremental::save_dep_graph(tcx,\n-                                              &incremental_hashes_map,\n-                                              &translation.metadata.hashes,\n-                                              translation.link.crate_hash));\n     translation\n }\n \n /// Run LLVM itself, producing a bitcode file, assembly file or object file\n /// as a side effect.\n pub fn phase_5_run_llvm_passes(sess: &Session,\n-                               trans: &trans::CrateTranslation,\n-                               outputs: &OutputFilenames) -> CompileResult {\n-    if sess.opts.cg.no_integrated_as ||\n-        (sess.target.target.options.no_integrated_as &&\n-         (outputs.outputs.contains_key(&OutputType::Object) ||\n-          outputs.outputs.contains_key(&OutputType::Exe)))\n-    {\n-        let output_types = OutputTypes::new(&[(OutputType::Assembly, None)]);\n-        time(sess.time_passes(),\n-             \"LLVM passes\",\n-             || write::run_passes(sess, trans, &output_types, outputs));\n-\n-        write::run_assembler(sess, outputs);\n-\n-        // HACK the linker expects the object file to be named foo.0.o but\n-        // `run_assembler` produces an object named just foo.o. Rename it if we\n-        // are going to build an executable\n-        if sess.opts.output_types.contains_key(&OutputType::Exe) {\n-            let f = outputs.path(OutputType::Object);\n-            rename_or_copy_remove(&f,\n-                     f.with_file_name(format!(\"{}.0.o\",\n-                                              f.file_stem().unwrap().to_string_lossy()))).unwrap();\n-        }\n+                               trans: write::OngoingCrateTranslation)\n+                               -> (CompileResult, trans::CrateTranslation) {\n+    let trans = trans.join(sess);\n \n-        // Remove assembly source, unless --save-temps was specified\n-        if !sess.opts.cg.save_temps {\n-            fs::remove_file(&outputs.temp_path(OutputType::Assembly, None)).unwrap();\n-        }\n-    } else {\n-        time(sess.time_passes(),\n-             \"LLVM passes\",\n-             || write::run_passes(sess, trans, &sess.opts.output_types, outputs));\n+    if sess.opts.debugging_opts.incremental_info {\n+        write::dump_incremental_data(&trans);\n     }\n \n     time(sess.time_passes(),\n          \"serialize work products\",\n          move || rustc_incremental::save_work_products(sess));\n \n-    sess.compile_status()\n+    (sess.compile_status(), trans)\n }\n \n /// Run the linker on any artifacts that resulted from the LLVM run."}, {"sha": "339e2bdc15734960534873ae46a39402f11a37f9", "filename": "src/librustc_incremental/persist/save.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -34,7 +34,7 @@ use super::file_format;\n use super::work_product;\n \n pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                incremental_hashes_map: &IncrementalHashesMap,\n+                                incremental_hashes_map: IncrementalHashesMap,\n                                 metadata_hashes: &EncodedMetadataHashes,\n                                 svh: Svh) {\n     debug!(\"save_dep_graph()\");\n@@ -51,7 +51,7 @@ pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         eprintln!(\"incremental: {} edges in dep-graph\", query.graph.len_edges());\n     }\n \n-    let mut hcx = HashContext::new(tcx, incremental_hashes_map);\n+    let mut hcx = HashContext::new(tcx, &incremental_hashes_map);\n     let preds = Predecessors::new(&query, &mut hcx);\n     let mut current_metadata_hashes = FxHashMap();\n "}, {"sha": "e8b0dea1e8ac0285d9dc9a0e99d4baf395a9a2c2", "filename": "src/librustc_metadata/cstore_impl.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_metadata%2Fcstore_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_metadata%2Fcstore_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcstore_impl.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -15,7 +15,8 @@ use schema;\n use rustc::ty::maps::QueryConfig;\n use rustc::middle::cstore::{CrateStore, CrateSource, LibSource, DepKind,\n                             NativeLibrary, MetadataLoader, LinkMeta,\n-                            LinkagePreference, LoadedMacro, EncodedMetadata};\n+                            LinkagePreference, LoadedMacro, EncodedMetadata,\n+                            EncodedMetadataHashes};\n use rustc::hir::def;\n use rustc::middle::lang_items;\n use rustc::session::Session;\n@@ -443,7 +444,7 @@ impl CrateStore for cstore::CStore {\n                                  tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                  link_meta: &LinkMeta,\n                                  reachable: &NodeSet)\n-                                 -> EncodedMetadata\n+                                 -> (EncodedMetadata, EncodedMetadataHashes)\n     {\n         encoder::encode_metadata(tcx, link_meta, reachable)\n     }"}, {"sha": "c35d8407c9d3c4f24ee55c5da2beb13d7409bfa6", "filename": "src/librustc_metadata/encoder.rs", "status": "modified", "additions": 2, "deletions": 5, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_metadata%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_metadata%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fencoder.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -1638,7 +1638,7 @@ impl<'a, 'tcx, 'v> ItemLikeVisitor<'v> for ImplVisitor<'a, 'tcx> {\n pub fn encode_metadata<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                  link_meta: &LinkMeta,\n                                  exported_symbols: &NodeSet)\n-                                 -> EncodedMetadata\n+                                 -> (EncodedMetadata, EncodedMetadataHashes)\n {\n     let mut cursor = Cursor::new(vec![]);\n     cursor.write_all(METADATA_HEADER).unwrap();\n@@ -1681,10 +1681,7 @@ pub fn encode_metadata<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     result[header + 2] = (pos >> 8) as u8;\n     result[header + 3] = (pos >> 0) as u8;\n \n-    EncodedMetadata {\n-        raw_data: result,\n-        hashes: metadata_hashes,\n-    }\n+    (EncodedMetadata { raw_data: result }, metadata_hashes)\n }\n \n pub fn get_repr_options<'a, 'tcx, 'gcx>(tcx: &TyCtxt<'a, 'tcx, 'gcx>, did: DefId) -> ReprOptions {"}, {"sha": "ed9321cc3f3a1197dd97f45703cdfd53ebd50080", "filename": "src/librustc_trans/Cargo.toml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2FCargo.toml?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -10,7 +10,7 @@ crate-type = [\"dylib\"]\n test = false\n \n [dependencies]\n-crossbeam = \"0.2\"\n+num_cpus = \"1.0\"\n flate2 = \"0.2\"\n jobserver = \"0.1.5\"\n log = \"0.3\""}, {"sha": "6e661a5a8c6a4c278d2e15ffe44dea3bfd4ed757", "filename": "src/librustc_trans/assert_module_sources.rs", "status": "modified", "additions": 20, "deletions": 16, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Fassert_module_sources.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Fassert_module_sources.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fassert_module_sources.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -37,11 +37,22 @@ use rustc::ich::{ATTR_PARTITION_REUSED, ATTR_PARTITION_TRANSLATED};\n const MODULE: &'static str = \"module\";\n const CFG: &'static str = \"cfg\";\n \n-#[derive(Debug, PartialEq)]\n-enum Disposition { Reused, Translated }\n+#[derive(Debug, PartialEq, Clone, Copy)]\n+pub enum Disposition { Reused, Translated }\n+\n+impl ModuleTranslation {\n+    pub fn disposition(&self) -> (String, Disposition) {\n+        let disposition = match self.source {\n+            ModuleSource::Preexisting(_) => Disposition::Reused,\n+            ModuleSource::Translated(_) => Disposition::Translated,\n+        };\n+\n+        (self.name.clone(), disposition)\n+    }\n+}\n \n pub(crate) fn assert_module_sources<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                              modules: &[ModuleTranslation]) {\n+                                              modules: &[(String, Disposition)]) {\n     let _ignore = tcx.dep_graph.in_ignore();\n \n     if tcx.sess.opts.incremental.is_none() {\n@@ -56,7 +67,7 @@ pub(crate) fn assert_module_sources<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n struct AssertModuleSource<'a, 'tcx: 'a> {\n     tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-    modules: &'a [ModuleTranslation],\n+    modules: &'a [(String, Disposition)],\n }\n \n impl<'a, 'tcx> AssertModuleSource<'a, 'tcx> {\n@@ -75,15 +86,15 @@ impl<'a, 'tcx> AssertModuleSource<'a, 'tcx> {\n         }\n \n         let mname = self.field(attr, MODULE);\n-        let mtrans = self.modules.iter().find(|mtrans| *mtrans.name == *mname.as_str());\n+        let mtrans = self.modules.iter().find(|&&(ref name, _)| name == mname.as_str());\n         let mtrans = match mtrans {\n             Some(m) => m,\n             None => {\n                 debug!(\"module name `{}` not found amongst:\", mname);\n-                for mtrans in self.modules {\n+                for &(ref name, ref disposition) in self.modules {\n                     debug!(\"module named `{}` with disposition {:?}\",\n-                           mtrans.name,\n-                           self.disposition(mtrans));\n+                           name,\n+                           disposition);\n                 }\n \n                 self.tcx.sess.span_err(\n@@ -93,7 +104,7 @@ impl<'a, 'tcx> AssertModuleSource<'a, 'tcx> {\n             }\n         };\n \n-        let mtrans_disposition = self.disposition(mtrans);\n+        let mtrans_disposition = mtrans.1;\n         if disposition != mtrans_disposition {\n             self.tcx.sess.span_err(\n                 attr.span,\n@@ -104,13 +115,6 @@ impl<'a, 'tcx> AssertModuleSource<'a, 'tcx> {\n         }\n     }\n \n-    fn disposition(&self, mtrans: &ModuleTranslation) -> Disposition {\n-        match mtrans.source {\n-            ModuleSource::Preexisting(_) => Disposition::Reused,\n-            ModuleSource::Translated(_) => Disposition::Translated,\n-        }\n-    }\n-\n     fn field(&self, attr: &ast::Attribute, name: &str) -> ast::Name {\n         for item in attr.meta_item_list().unwrap_or_else(Vec::new) {\n             if item.check_name(name) {"}, {"sha": "e160d6b6c6ab32d0140416054456f826b5e6657f", "filename": "src/librustc_trans/back/lto.rs", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fback%2Flto.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -12,7 +12,7 @@ use back::link;\n use back::write;\n use back::symbol_export;\n use rustc::session::config;\n-use errors::FatalError;\n+use errors::{FatalError, Handler};\n use llvm;\n use llvm::archive_ro::ArchiveRO;\n use llvm::{ModuleRef, TargetMachineRef, True, False};\n@@ -41,24 +41,24 @@ pub fn crate_type_allows_lto(crate_type: config::CrateType) -> bool {\n }\n \n pub fn run(cgcx: &CodegenContext,\n+           diag_handler: &Handler,\n            llmod: ModuleRef,\n            tm: TargetMachineRef,\n            config: &ModuleConfig,\n            temp_no_opt_bc_filename: &Path) -> Result<(), FatalError> {\n-    let handler = cgcx.handler;\n     if cgcx.opts.cg.prefer_dynamic {\n-        handler.struct_err(\"cannot prefer dynamic linking when performing LTO\")\n-            .note(\"only 'staticlib', 'bin', and 'cdylib' outputs are \\\n-                   supported with LTO\")\n-            .emit();\n+        diag_handler.struct_err(\"cannot prefer dynamic linking when performing LTO\")\n+                    .note(\"only 'staticlib', 'bin', and 'cdylib' outputs are \\\n+                           supported with LTO\")\n+                    .emit();\n         return Err(FatalError)\n     }\n \n     // Make sure we actually can run LTO\n     for crate_type in cgcx.crate_types.iter() {\n         if !crate_type_allows_lto(*crate_type) {\n-            let e = handler.fatal(\"lto can only be run for executables, cdylibs and \\\n-                                   static library outputs\");\n+            let e = diag_handler.fatal(\"lto can only be run for executables, cdylibs and \\\n+                                        static library outputs\");\n             return Err(e)\n         }\n     }\n@@ -116,13 +116,13 @@ pub fn run(cgcx: &CodegenContext,\n                         if res.is_err() {\n                             let msg = format!(\"failed to decompress bc of `{}`\",\n                                               name);\n-                            Err(handler.fatal(&msg))\n+                            Err(diag_handler.fatal(&msg))\n                         } else {\n                             Ok(inflated)\n                         }\n                     } else {\n-                        Err(handler.fatal(&format!(\"Unsupported bytecode format version {}\",\n-                                                   version)))\n+                        Err(diag_handler.fatal(&format!(\"Unsupported bytecode format version {}\",\n+                                                        version)))\n                     }\n                 })?\n             } else {\n@@ -136,7 +136,7 @@ pub fn run(cgcx: &CodegenContext,\n                     if res.is_err() {\n                         let msg = format!(\"failed to decompress bc of `{}`\",\n                                           name);\n-                        Err(handler.fatal(&msg))\n+                        Err(diag_handler.fatal(&msg))\n                     } else {\n                         Ok(inflated)\n                     }\n@@ -152,7 +152,7 @@ pub fn run(cgcx: &CodegenContext,\n                     Ok(())\n                 } else {\n                     let msg = format!(\"failed to load bc of `{}`\", name);\n-                    Err(write::llvm_err(handler, msg))\n+                    Err(write::llvm_err(&diag_handler, msg))\n                 }\n             })?;\n         }"}, {"sha": "0d5fe6c0ae95fa3dffc45dc711098e4e490c6be7", "filename": "src/librustc_trans/back/write.rs", "status": "modified", "additions": 938, "deletions": 385, "changes": 1323, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fback%2Fwrite.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -10,36 +10,42 @@\n \n use back::lto;\n use back::link::{self, get_linker, remove};\n+use back::linker::LinkerInfo;\n use back::symbol_export::ExportedSymbols;\n use rustc_incremental::{save_trans_partition, in_incr_comp_dir};\n+use rustc::middle::cstore::{LinkMeta, EncodedMetadata};\n use rustc::session::config::{self, OutputFilenames, OutputType, OutputTypes, Passes, SomePasses,\n                              AllPasses, Sanitizer};\n use rustc::session::Session;\n+use time_graph::{self, TimeGraph};\n use llvm;\n use llvm::{ModuleRef, TargetMachineRef, PassManagerRef, DiagnosticInfoRef};\n use llvm::SMDiagnosticRef;\n-use {CrateTranslation, ModuleLlvm, ModuleSource, ModuleTranslation};\n+use {CrateTranslation, ModuleSource, ModuleTranslation, CompiledModule, ModuleKind};\n use rustc::hir::def_id::CrateNum;\n-use rustc::util::common::{time, time_depth, set_time_depth, path2cstr};\n-use rustc::util::fs::link_or_copy;\n+use rustc::util::common::{time, time_depth, set_time_depth, path2cstr, print_time_passes_entry};\n+use rustc::util::fs::{link_or_copy, rename_or_copy_remove};\n use errors::{self, Handler, Level, DiagnosticBuilder, FatalError};\n-use errors::emitter::Emitter;\n+use errors::emitter::{Emitter};\n use syntax::ext::hygiene::Mark;\n use syntax_pos::MultiSpan;\n+use syntax_pos::symbol::Symbol;\n use context::{is_pie_binary, get_reloc_model};\n use jobserver::{Client, Acquired};\n-use crossbeam::{scope, Scope};\n use rustc_demangle;\n \n-use std::cmp;\n use std::ffi::CString;\n+use std::fmt;\n use std::fs;\n use std::io;\n use std::io::Write;\n use std::path::{Path, PathBuf};\n use std::str;\n-use std::sync::mpsc::{channel, Sender};\n+use std::sync::Arc;\n+use std::sync::mpsc::{channel, Sender, Receiver};\n use std::slice;\n+use std::time::Instant;\n+use std::thread;\n use libc::{c_uint, c_void, c_char, size_t};\n \n pub const RELOC_MODEL_ARGS : [(&'static str, llvm::RelocMode); 7] = [\n@@ -190,7 +196,6 @@ pub fn create_target_machine(sess: &Session) -> TargetMachineRef {\n \n \n /// Module-specific configuration for `optimize_and_codegen`.\n-#[derive(Clone)]\n pub struct ModuleConfig {\n     /// LLVM TargetMachine to use for codegen.\n     tm: TargetMachineRef,\n@@ -229,9 +234,9 @@ pub struct ModuleConfig {\n unsafe impl Send for ModuleConfig { }\n \n impl ModuleConfig {\n-    fn new(tm: TargetMachineRef, passes: Vec<String>) -> ModuleConfig {\n+    fn new(sess: &Session, passes: Vec<String>) -> ModuleConfig {\n         ModuleConfig {\n-            tm: tm,\n+            tm: create_target_machine(sess),\n             passes: passes,\n             opt_level: None,\n             opt_size: None,\n@@ -255,10 +260,10 @@ impl ModuleConfig {\n         }\n     }\n \n-    fn set_flags(&mut self, sess: &Session, trans: &CrateTranslation) {\n+    fn set_flags(&mut self, sess: &Session, no_builtins: bool) {\n         self.no_verify = sess.no_verify();\n         self.no_prepopulate_passes = sess.opts.cg.no_prepopulate_passes;\n-        self.no_builtins = trans.no_builtins;\n+        self.no_builtins = no_builtins;\n         self.time_passes = sess.time_passes();\n         self.inline_threshold = sess.opts.cg.inline_threshold;\n         self.obj_is_bitcode = sess.target.target.options.obj_is_bitcode;\n@@ -279,20 +284,55 @@ impl ModuleConfig {\n         self.merge_functions = sess.opts.optimize == config::OptLevel::Default ||\n                                sess.opts.optimize == config::OptLevel::Aggressive;\n     }\n+\n+    fn clone(&self, sess: &Session) -> ModuleConfig {\n+        ModuleConfig {\n+            tm: create_target_machine(sess),\n+            passes: self.passes.clone(),\n+            opt_level: self.opt_level,\n+            opt_size: self.opt_size,\n+\n+            emit_no_opt_bc: self.emit_no_opt_bc,\n+            emit_bc: self.emit_bc,\n+            emit_lto_bc: self.emit_lto_bc,\n+            emit_ir: self.emit_ir,\n+            emit_asm: self.emit_asm,\n+            emit_obj: self.emit_obj,\n+            obj_is_bitcode: self.obj_is_bitcode,\n+\n+            no_verify: self.no_verify,\n+            no_prepopulate_passes: self.no_prepopulate_passes,\n+            no_builtins: self.no_builtins,\n+            time_passes: self.time_passes,\n+            vectorize_loop: self.vectorize_loop,\n+            vectorize_slp: self.vectorize_slp,\n+            merge_functions: self.merge_functions,\n+            inline_threshold: self.inline_threshold,\n+        }\n+    }\n+}\n+\n+impl Drop for ModuleConfig {\n+    fn drop(&mut self) {\n+        unsafe {\n+            llvm::LLVMRustDisposeTargetMachine(self.tm);\n+        }\n+    }\n }\n \n /// Additional resources used by optimize_and_codegen (not module specific)\n-pub struct CodegenContext<'a> {\n+#[derive(Clone)]\n+pub struct CodegenContext {\n     // Resouces needed when running LTO\n     pub time_passes: bool,\n     pub lto: bool,\n     pub no_landing_pads: bool,\n-    pub exported_symbols: &'a ExportedSymbols,\n-    pub opts: &'a config::Options,\n+    pub exported_symbols: Arc<ExportedSymbols>,\n+    pub opts: Arc<config::Options>,\n     pub crate_types: Vec<config::CrateType>,\n     pub each_linked_rlib_for_lto: Vec<(CrateNum, PathBuf)>,\n     // Handler to use for diagnostics produced during codegen.\n-    pub handler: &'a Handler,\n+    pub diag_emitter: SharedEmitter,\n     // LLVM passes added by plugins.\n     pub plugin_passes: Vec<String>,\n     // LLVM optimizations for which we want to print remarks.\n@@ -303,17 +343,27 @@ pub struct CodegenContext<'a> {\n     // compiling incrementally\n     pub incr_comp_session_dir: Option<PathBuf>,\n     // Channel back to the main control thread to send messages to\n-    pub tx: Sender<Message>,\n+    coordinator_send: Sender<Message>,\n+    // A reference to the TimeGraph so we can register timings. None means that\n+    // measuring is disabled.\n+    time_graph: Option<TimeGraph>,\n+}\n+\n+impl CodegenContext {\n+    fn create_diag_handler(&self) -> Handler {\n+        Handler::with_emitter(true, false, Box::new(self.diag_emitter.clone()))\n+    }\n }\n \n struct HandlerFreeVars<'a> {\n-    cgcx: &'a CodegenContext<'a>,\n+    cgcx: &'a CodegenContext,\n+    diag_handler: &'a Handler,\n }\n \n-unsafe extern \"C\" fn report_inline_asm<'a, 'b>(cgcx: &'a CodegenContext<'a>,\n+unsafe extern \"C\" fn report_inline_asm<'a, 'b>(cgcx: &'a CodegenContext,\n                                                msg: &'b str,\n                                                cookie: c_uint) {\n-    drop(cgcx.tx.send(Message::InlineAsmError(cookie as u32, msg.to_string())));\n+    cgcx.diag_emitter.inline_asm_error(cookie as u32, msg.to_string());\n }\n \n unsafe extern \"C\" fn inline_asm_handler(diag: SMDiagnosticRef,\n@@ -328,7 +378,7 @@ unsafe extern \"C\" fn inline_asm_handler(diag: SMDiagnosticRef,\n }\n \n unsafe extern \"C\" fn diagnostic_handler(info: DiagnosticInfoRef, user: *mut c_void) {\n-    let HandlerFreeVars { cgcx, .. } = *(user as *const HandlerFreeVars);\n+    let HandlerFreeVars { cgcx, diag_handler, .. } = *(user as *const HandlerFreeVars);\n \n     match llvm::diagnostic::Diagnostic::unpack(info) {\n         llvm::diagnostic::InlineAsm(inline) => {\n@@ -344,7 +394,7 @@ unsafe extern \"C\" fn diagnostic_handler(info: DiagnosticInfoRef, user: *mut c_vo\n             };\n \n             if enabled {\n-                cgcx.handler.note_without_error(&format!(\"optimization {} for {} at {}:{}:{}: {}\",\n+                diag_handler.note_without_error(&format!(\"optimization {} for {} at {}:{}:{}: {}\",\n                                                 opt.kind.describe(),\n                                                 opt.pass_name,\n                                                 opt.filename,\n@@ -360,25 +410,32 @@ unsafe extern \"C\" fn diagnostic_handler(info: DiagnosticInfoRef, user: *mut c_vo\n \n // Unsafe due to LLVM calls.\n unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n+                               diag_handler: &Handler,\n                                mtrans: ModuleTranslation,\n-                               mllvm: ModuleLlvm,\n                                config: ModuleConfig,\n                                output_names: OutputFilenames)\n-    -> Result<(), FatalError>\n+    -> Result<CompiledModule, FatalError>\n {\n-    let llmod = mllvm.llmod;\n-    let llcx = mllvm.llcx;\n+    let (llmod, llcx) = match mtrans.source {\n+        ModuleSource::Translated(ref llvm) => (llvm.llmod, llvm.llcx),\n+        ModuleSource::Preexisting(_) => {\n+            bug!(\"optimize_and_codegen: called with ModuleSource::Preexisting\")\n+        }\n+    };\n+\n     let tm = config.tm;\n \n     let fv = HandlerFreeVars {\n         cgcx: cgcx,\n+        diag_handler: diag_handler,\n     };\n     let fv = &fv as *const HandlerFreeVars as *mut c_void;\n \n     llvm::LLVMRustSetInlineAsmDiagnosticHandler(llcx, inline_asm_handler, fv);\n     llvm::LLVMContextSetDiagnosticHandler(llcx, diagnostic_handler, fv);\n \n-    let module_name = Some(&mtrans.name[..]);\n+    let module_name = mtrans.name.clone();\n+    let module_name = Some(&module_name[..]);\n \n     if config.emit_no_opt_bc {\n         let out = output_names.temp_path_ext(\"no-opt.bc\", module_name);\n@@ -406,7 +463,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n                 llvm::PassKind::Function => fpm,\n                 llvm::PassKind::Module => mpm,\n                 llvm::PassKind::Other => {\n-                    cgcx.handler.err(\"Encountered LLVM pass kind we can't handle\");\n+                    diag_handler.err(\"Encountered LLVM pass kind we can't handle\");\n                     return true\n                 },\n             };\n@@ -426,25 +483,25 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n \n         for pass in &config.passes {\n             if !addpass(pass) {\n-                cgcx.handler.warn(&format!(\"unknown pass `{}`, ignoring\",\n+                diag_handler.warn(&format!(\"unknown pass `{}`, ignoring\",\n                                            pass));\n             }\n         }\n \n         for pass in &cgcx.plugin_passes {\n             if !addpass(pass) {\n-                cgcx.handler.err(&format!(\"a plugin asked for LLVM pass \\\n+                diag_handler.err(&format!(\"a plugin asked for LLVM pass \\\n                                            `{}` but LLVM does not \\\n                                            recognize it\", pass));\n             }\n         }\n \n-        cgcx.handler.abort_if_errors();\n+        diag_handler.abort_if_errors();\n \n         // Finally, run the actual optimization passes\n-        time(config.time_passes, &format!(\"llvm function passes [{}]\", cgcx.worker), ||\n+        time(config.time_passes, &format!(\"llvm function passes [{}]\", module_name.unwrap()), ||\n              llvm::LLVMRustRunFunctionPassManager(fpm, llmod));\n-        time(config.time_passes, &format!(\"llvm module passes [{}]\", cgcx.worker), ||\n+        time(config.time_passes, &format!(\"llvm module passes [{}]\", module_name.unwrap()), ||\n              llvm::LLVMRunPassManager(mpm, llmod));\n \n         // Deallocate managers that we're now done with\n@@ -456,6 +513,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n                 let temp_no_opt_bc_filename =\n                     output_names.temp_path_ext(\"no-opt.lto.bc\", module_name);\n                 lto::run(cgcx,\n+                         diag_handler,\n                          llmod,\n                          tm,\n                          &config,\n@@ -506,7 +564,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n         llvm::LLVMWriteBitcodeToFile(llmod, bc_out_c.as_ptr());\n     }\n \n-    time(config.time_passes, &format!(\"codegen passes [{}]\", cgcx.worker),\n+    time(config.time_passes, &format!(\"codegen passes [{}]\", module_name.unwrap()),\n          || -> Result<(), FatalError> {\n         if config.emit_ir {\n             let out = output_names.temp_path(OutputType::LlvmAssembly, module_name);\n@@ -561,7 +619,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n                 llmod\n             };\n             with_codegen(tm, llmod, config.no_builtins, |cpm| {\n-                write_output_file(cgcx.handler, tm, cpm, llmod, &path,\n+                write_output_file(diag_handler, tm, cpm, llmod, &path,\n                                   llvm::FileType::AssemblyFile)\n             })?;\n             if config.emit_obj {\n@@ -571,7 +629,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n \n         if write_obj {\n             with_codegen(tm, llmod, config.no_builtins, |cpm| {\n-                write_output_file(cgcx.handler, tm, cpm, llmod, &obj_out,\n+                write_output_file(diag_handler, tm, cpm, llmod, &obj_out,\n                                   llvm::FileType::ObjectFile)\n             })?;\n         }\n@@ -582,67 +640,53 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n     if copy_bc_to_obj {\n         debug!(\"copying bitcode {:?} to obj {:?}\", bc_out, obj_out);\n         if let Err(e) = link_or_copy(&bc_out, &obj_out) {\n-            cgcx.handler.err(&format!(\"failed to copy bitcode to object file: {}\", e));\n+            diag_handler.err(&format!(\"failed to copy bitcode to object file: {}\", e));\n         }\n     }\n \n     if rm_bc {\n         debug!(\"removing_bitcode {:?}\", bc_out);\n         if let Err(e) = fs::remove_file(&bc_out) {\n-            cgcx.handler.err(&format!(\"failed to remove bitcode: {}\", e));\n+            diag_handler.err(&format!(\"failed to remove bitcode: {}\", e));\n         }\n     }\n \n-    llvm::LLVMRustDisposeTargetMachine(tm);\n-    Ok(())\n+    Ok(mtrans.into_compiled_module(config.emit_obj, config.emit_bc))\n }\n \n-\n-pub fn cleanup_llvm(trans: &CrateTranslation) {\n-    for module in trans.modules.iter() {\n-        unsafe {\n-            match module.source {\n-                ModuleSource::Translated(llvm) => {\n-                    llvm::LLVMDisposeModule(llvm.llmod);\n-                    llvm::LLVMContextDispose(llvm.llcx);\n-                }\n-                ModuleSource::Preexisting(_) => {\n-                }\n-            }\n-        }\n-    }\n+pub struct CompiledModules {\n+    pub modules: Vec<CompiledModule>,\n+    pub metadata_module: CompiledModule,\n+    pub allocator_module: Option<CompiledModule>,\n }\n \n-pub fn run_passes(sess: &Session,\n-                  trans: &CrateTranslation,\n-                  output_types: &OutputTypes,\n-                  crate_output: &OutputFilenames) {\n-    // It's possible that we have `codegen_units > 1` but only one item in\n-    // `trans.modules`.  We could theoretically proceed and do LTO in that\n-    // case, but it would be confusing to have the validity of\n-    // `-Z lto -C codegen-units=2` depend on details of the crate being\n-    // compiled, so we complain regardless.\n-    if sess.lto() && sess.opts.cg.codegen_units > 1 {\n-        // This case is impossible to handle because LTO expects to be able\n-        // to combine the entire crate and all its dependencies into a\n-        // single compilation unit, but each codegen unit is in a separate\n-        // LLVM context, so they can't easily be combined.\n-        sess.fatal(\"can't perform LTO when using multiple codegen units\");\n-    }\n-\n-    // Sanity check\n-    assert!(trans.modules.len() == sess.opts.cg.codegen_units ||\n-            sess.opts.debugging_opts.incremental.is_some() ||\n-            !sess.opts.output_types.should_trans() ||\n-            sess.opts.debugging_opts.no_trans);\n+fn need_crate_bitcode_for_rlib(sess: &Session) -> bool {\n+    sess.crate_types.borrow().contains(&config::CrateTypeRlib) &&\n+    sess.opts.output_types.contains_key(&OutputType::Exe)\n+}\n \n-    let tm = create_target_machine(sess);\n+pub fn start_async_translation(sess: &Session,\n+                               crate_output: &OutputFilenames,\n+                               time_graph: Option<TimeGraph>,\n+                               crate_name: Symbol,\n+                               link: LinkMeta,\n+                               metadata: EncodedMetadata,\n+                               exported_symbols: Arc<ExportedSymbols>,\n+                               no_builtins: bool,\n+                               windows_subsystem: Option<String>,\n+                               linker_info: LinkerInfo,\n+                               no_integrated_as: bool)\n+                               -> OngoingCrateTranslation {\n+    let output_types_override = if no_integrated_as {\n+        OutputTypes::new(&[(OutputType::Assembly, None)])\n+    } else {\n+        sess.opts.output_types.clone()\n+    };\n \n     // Figure out what we actually need to build.\n-\n-    let mut modules_config = ModuleConfig::new(tm, sess.opts.cg.passes.clone());\n-    let mut metadata_config = ModuleConfig::new(tm, vec![]);\n-    let mut allocator_config = ModuleConfig::new(tm, vec![]);\n+    let mut modules_config = ModuleConfig::new(sess, sess.opts.cg.passes.clone());\n+    let mut metadata_config = ModuleConfig::new(sess, vec![]);\n+    let mut allocator_config = ModuleConfig::new(sess, vec![]);\n \n     if let Some(ref sanitizer) = sess.opts.debugging_opts.sanitizer {\n         match *sanitizer {\n@@ -679,16 +723,11 @@ pub fn run_passes(sess: &Session,\n     // Emit bitcode files for the crate if we're emitting an rlib.\n     // Whenever an rlib is created, the bitcode is inserted into the\n     // archive in order to allow LTO against it.\n-    let needs_crate_bitcode =\n-            sess.crate_types.borrow().contains(&config::CrateTypeRlib) &&\n-            sess.opts.output_types.contains_key(&OutputType::Exe);\n-    let needs_crate_object =\n-            sess.opts.output_types.contains_key(&OutputType::Exe);\n-    if needs_crate_bitcode {\n+    if need_crate_bitcode_for_rlib(sess) {\n         modules_config.emit_bc = true;\n     }\n \n-    for output_type in output_types.keys() {\n+    for output_type in output_types_override.keys() {\n         match *output_type {\n             OutputType::Bitcode => { modules_config.emit_bc = true; }\n             OutputType::LlvmAssembly => { modules_config.emit_ir = true; }\n@@ -714,76 +753,86 @@ pub fn run_passes(sess: &Session,\n         }\n     }\n \n-    modules_config.set_flags(sess, trans);\n-    metadata_config.set_flags(sess, trans);\n-    allocator_config.set_flags(sess, trans);\n-\n+    modules_config.set_flags(sess, no_builtins);\n+    metadata_config.set_flags(sess, no_builtins);\n+    allocator_config.set_flags(sess, no_builtins);\n \n-    // Populate a buffer with a list of codegen threads.  Items are processed in\n-    // LIFO order, just because it's a tiny bit simpler that way.  (The order\n-    // doesn't actually matter.)\n-    let mut work_items = Vec::with_capacity(1 + trans.modules.len());\n-\n-    {\n-        let work = build_work_item(sess,\n-                                   trans.metadata_module.clone(),\n-                                   metadata_config.clone(),\n-                                   crate_output.clone());\n-        work_items.push(work);\n-    }\n-\n-    if let Some(allocator) = trans.allocator_module.clone() {\n-        let work = build_work_item(sess,\n-                                   allocator,\n-                                   allocator_config.clone(),\n-                                   crate_output.clone());\n-        work_items.push(work);\n-    }\n-\n-    for mtrans in trans.modules.iter() {\n-        let work = build_work_item(sess,\n-                                   mtrans.clone(),\n-                                   modules_config.clone(),\n-                                   crate_output.clone());\n-        work_items.push(work);\n-    }\n-\n-    if sess.opts.debugging_opts.incremental_info {\n-        dump_incremental_data(&trans);\n-    }\n+    // Exclude metadata and allocator modules from time_passes output, since\n+    // they throw off the \"LLVM passes\" measurement.\n+    metadata_config.time_passes = false;\n+    allocator_config.time_passes = false;\n \n     let client = sess.jobserver_from_env.clone().unwrap_or_else(|| {\n         // Pick a \"reasonable maximum\" if we don't otherwise have a jobserver in\n         // our environment, capping out at 32 so we don't take everything down\n         // by hogging the process run queue.\n-        let num_workers = cmp::min(work_items.len() - 1, 32);\n-        Client::new(num_workers).expect(\"failed to create jobserver\")\n-    });\n-    scope(|scope| {\n-        execute_work(sess, work_items, client, &trans.exported_symbols, scope);\n+        Client::new(32).expect(\"failed to create jobserver\")\n     });\n \n-    // If in incr. comp. mode, preserve the `.o` files for potential re-use\n-    for mtrans in trans.modules.iter() {\n+    let (shared_emitter, shared_emitter_main) = SharedEmitter::new();\n+    let (trans_worker_send, trans_worker_receive) = channel();\n+    let (coordinator_send, coordinator_receive) = channel();\n+\n+    let coordinator_thread = start_executing_work(sess,\n+                                                  shared_emitter,\n+                                                  trans_worker_send,\n+                                                  coordinator_send.clone(),\n+                                                  coordinator_receive,\n+                                                  client,\n+                                                  time_graph.clone(),\n+                                                  exported_symbols.clone());\n+    OngoingCrateTranslation {\n+        crate_name,\n+        link,\n+        metadata,\n+        exported_symbols,\n+        no_builtins,\n+        windows_subsystem,\n+        linker_info,\n+        no_integrated_as,\n+\n+        regular_module_config: modules_config,\n+        metadata_module_config: metadata_config,\n+        allocator_module_config: allocator_config,\n+\n+        time_graph,\n+        output_filenames: crate_output.clone(),\n+        coordinator_send,\n+        trans_worker_receive,\n+        shared_emitter_main,\n+        future: coordinator_thread\n+    }\n+}\n+\n+fn copy_module_artifacts_into_incr_comp_cache(sess: &Session,\n+                                              compiled_modules: &CompiledModules,\n+                                              crate_output: &OutputFilenames) {\n+    if sess.opts.incremental.is_none() {\n+        return;\n+    }\n+\n+    for module in compiled_modules.modules.iter() {\n         let mut files = vec![];\n \n-        if modules_config.emit_obj {\n-            let path = crate_output.temp_path(OutputType::Object, Some(&mtrans.name));\n+        if module.emit_obj {\n+            let path = crate_output.temp_path(OutputType::Object, Some(&module.name));\n             files.push((OutputType::Object, path));\n         }\n \n-        if modules_config.emit_bc {\n-            let path = crate_output.temp_path(OutputType::Bitcode, Some(&mtrans.name));\n+        if module.emit_bc {\n+            let path = crate_output.temp_path(OutputType::Bitcode, Some(&module.name));\n             files.push((OutputType::Bitcode, path));\n         }\n \n-        save_trans_partition(sess, &mtrans.name, mtrans.symbol_name_hash, &files);\n+        save_trans_partition(sess, &module.name, module.symbol_name_hash, &files);\n     }\n+}\n \n-    // All codegen is finished.\n-    unsafe {\n-        llvm::LLVMRustDisposeTargetMachine(tm);\n-    }\n+fn produce_final_output_artifacts(sess: &Session,\n+                                  compiled_modules: &CompiledModules,\n+                                  crate_output: &OutputFilenames) {\n+    let mut user_wants_bitcode = false;\n+    let mut user_wants_objects = false;\n \n     // Produce final compile outputs.\n     let copy_gracefully = |from: &Path, to: &Path| {\n@@ -794,10 +843,10 @@ pub fn run_passes(sess: &Session,\n \n     let copy_if_one_unit = |output_type: OutputType,\n                             keep_numbered: bool| {\n-        if trans.modules.len() == 1 {\n+        if compiled_modules.modules.len() == 1 {\n             // 1) Only one codegen unit.  In this case it's no difficulty\n             //    to copy `foo.0.x` to `foo.x`.\n-            let module_name = Some(&trans.modules[0].name[..]);\n+            let module_name = Some(&compiled_modules.modules[0].name[..]);\n             let path = crate_output.temp_path(output_type, module_name);\n             copy_gracefully(&path,\n                             &crate_output.path(output_type));\n@@ -834,9 +883,7 @@ pub fn run_passes(sess: &Session,\n     // Flag to indicate whether the user explicitly requested bitcode.\n     // Otherwise, we produced it only as a temporary output, and will need\n     // to get rid of it.\n-    let mut user_wants_bitcode = false;\n-    let mut user_wants_objects = false;\n-    for output_type in output_types.keys() {\n+    for output_type in crate_output.outputs.keys() {\n         match *output_type {\n             OutputType::Bitcode => {\n                 user_wants_bitcode = true;\n@@ -861,7 +908,6 @@ pub fn run_passes(sess: &Session,\n             OutputType::DepInfo => {}\n         }\n     }\n-    let user_wants_bitcode = user_wants_bitcode;\n \n     // Clean up unwanted temporary files.\n \n@@ -893,33 +939,39 @@ pub fn run_passes(sess: &Session,\n         // If you change how this works, also update back::link::link_rlib,\n         // where .#module-name#.bc files are (maybe) deleted after making an\n         // rlib.\n+        let needs_crate_bitcode = need_crate_bitcode_for_rlib(sess);\n+        let needs_crate_object = crate_output.outputs.contains_key(&OutputType::Exe);\n+\n         let keep_numbered_bitcode = needs_crate_bitcode ||\n                 (user_wants_bitcode && sess.opts.cg.codegen_units > 1);\n \n         let keep_numbered_objects = needs_crate_object ||\n                 (user_wants_objects && sess.opts.cg.codegen_units > 1);\n \n-        for module_name in trans.modules.iter().map(|m| Some(&m.name[..])) {\n-            if modules_config.emit_obj && !keep_numbered_objects {\n+        for module in compiled_modules.modules.iter() {\n+            let module_name = Some(&module.name[..]);\n+\n+            if module.emit_obj && !keep_numbered_objects {\n                 let path = crate_output.temp_path(OutputType::Object, module_name);\n                 remove(sess, &path);\n             }\n \n-            if modules_config.emit_bc && !keep_numbered_bitcode {\n+            if module.emit_bc && !keep_numbered_bitcode {\n                 let path = crate_output.temp_path(OutputType::Bitcode, module_name);\n                 remove(sess, &path);\n             }\n         }\n \n-        if metadata_config.emit_bc && !user_wants_bitcode {\n+        if compiled_modules.metadata_module.emit_bc && !user_wants_bitcode {\n             let path = crate_output.temp_path(OutputType::Bitcode,\n-                                              Some(&trans.metadata_module.name));\n+                                              Some(&compiled_modules.metadata_module.name));\n             remove(sess, &path);\n         }\n-        if allocator_config.emit_bc && !user_wants_bitcode {\n-            if let Some(ref module) = trans.allocator_module {\n+\n+        if let Some(ref allocator_module) = compiled_modules.allocator_module {\n+            if allocator_module.emit_bc && !user_wants_bitcode {\n                 let path = crate_output.temp_path(OutputType::Bitcode,\n-                                                  Some(&module.name));\n+                                                  Some(&allocator_module.name));\n                 remove(sess, &path);\n             }\n         }\n@@ -930,20 +982,13 @@ pub fn run_passes(sess: &Session,\n     //  - #crate#.crate.metadata.o\n     //  - #crate#.bc\n     // These are used in linking steps and will be cleaned up afterward.\n-\n-    // FIXME: time_llvm_passes support - does this use a global context or\n-    // something?\n-    if sess.opts.cg.codegen_units == 1 && sess.time_llvm_passes() {\n-        unsafe { llvm::LLVMRustPrintPassTimings(); }\n-    }\n }\n \n-fn dump_incremental_data(trans: &CrateTranslation) {\n+pub fn dump_incremental_data(trans: &CrateTranslation) {\n     let mut reuse = 0;\n     for mtrans in trans.modules.iter() {\n-        match mtrans.source {\n-            ModuleSource::Preexisting(..) => reuse += 1,\n-            ModuleSource::Translated(..) => (),\n+        if mtrans.pre_existing {\n+            reuse += 1;\n         }\n     }\n     eprintln!(\"incremental: re-using {} out of {} modules\", reuse, trans.modules.len());\n@@ -955,14 +1000,17 @@ struct WorkItem {\n     output_names: OutputFilenames\n }\n \n-fn build_work_item(sess: &Session,\n-                   mtrans: ModuleTranslation,\n+impl fmt::Debug for WorkItem {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        write!(f, \"WorkItem({})\", self.mtrans.name)\n+    }\n+}\n+\n+fn build_work_item(mtrans: ModuleTranslation,\n                    config: ModuleConfig,\n                    output_names: OutputFilenames)\n                    -> WorkItem\n {\n-    let mut config = config;\n-    config.tm = create_target_machine(sess);\n     WorkItem {\n         mtrans: mtrans,\n         config: config,\n@@ -971,70 +1019,98 @@ fn build_work_item(sess: &Session,\n }\n \n fn execute_work_item(cgcx: &CodegenContext, work_item: WorkItem)\n-    -> Result<(), FatalError>\n+    -> Result<CompiledModule, FatalError>\n {\n-    unsafe {\n-        match work_item.mtrans.source {\n-            ModuleSource::Translated(mllvm) => {\n-                debug!(\"llvm-optimizing {:?}\", work_item.mtrans.name);\n-                optimize_and_codegen(cgcx,\n-                                     work_item.mtrans,\n-                                     mllvm,\n-                                     work_item.config,\n-                                     work_item.output_names)?;\n-            }\n-            ModuleSource::Preexisting(wp) => {\n-                let incr_comp_session_dir = cgcx.incr_comp_session_dir\n-                                                .as_ref()\n-                                                .unwrap();\n-                let name = &work_item.mtrans.name;\n-                for (kind, saved_file) in wp.saved_files {\n-                    let obj_out = work_item.output_names.temp_path(kind, Some(name));\n-                    let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n-                                                       &saved_file);\n-                    debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n-                           work_item.mtrans.name,\n-                           source_file,\n-                           obj_out.display());\n-                    match link_or_copy(&source_file, &obj_out) {\n-                        Ok(_) => { }\n-                        Err(err) => {\n-                            cgcx.handler.err(&format!(\"unable to copy {} to {}: {}\",\n-                                                      source_file.display(),\n-                                                      obj_out.display(),\n-                                                      err));\n-                        }\n-                    }\n+    let diag_handler = cgcx.create_diag_handler();\n+    let module_name = work_item.mtrans.name.clone();\n+\n+    let pre_existing = match work_item.mtrans.source {\n+        ModuleSource::Translated(_) => None,\n+        ModuleSource::Preexisting(ref wp) => Some(wp.clone()),\n+    };\n+\n+    if let Some(wp) = pre_existing {\n+        let incr_comp_session_dir = cgcx.incr_comp_session_dir\n+                                        .as_ref()\n+                                        .unwrap();\n+        let name = &work_item.mtrans.name;\n+        for (kind, saved_file) in wp.saved_files {\n+            let obj_out = work_item.output_names.temp_path(kind, Some(name));\n+            let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n+                                               &saved_file);\n+            debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n+                   work_item.mtrans.name,\n+                   source_file,\n+                   obj_out.display());\n+            match link_or_copy(&source_file, &obj_out) {\n+                Ok(_) => { }\n+                Err(err) => {\n+                    diag_handler.err(&format!(\"unable to copy {} to {}: {}\",\n+                                              source_file.display(),\n+                                              obj_out.display(),\n+                                              err));\n                 }\n             }\n         }\n-    }\n \n-    Ok(())\n+        Ok(CompiledModule {\n+            name: module_name,\n+            kind: ModuleKind::Regular,\n+            pre_existing: true,\n+            symbol_name_hash: work_item.mtrans.symbol_name_hash,\n+            emit_bc: work_item.config.emit_bc,\n+            emit_obj: work_item.config.emit_obj,\n+        })\n+    } else {\n+        debug!(\"llvm-optimizing {:?}\", module_name);\n+\n+        unsafe {\n+            optimize_and_codegen(cgcx,\n+                                 &diag_handler,\n+                                 work_item.mtrans,\n+                                 work_item.config,\n+                                 work_item.output_names)\n+        }\n+    }\n }\n \n-pub enum Message {\n+#[derive(Debug)]\n+enum Message {\n     Token(io::Result<Acquired>),\n-    Diagnostic(Diagnostic),\n-    Done { success: bool },\n-    InlineAsmError(u32, String),\n-    AbortIfErrors,\n+    Done {\n+        result: Result<CompiledModule, ()>,\n+        worker_id: usize,\n+    },\n+    TranslationDone {\n+        llvm_work_item: WorkItem,\n+        cost: u64,\n+        is_last: bool,\n+    },\n+    TranslateItem,\n }\n \n-pub struct Diagnostic {\n+struct Diagnostic {\n     msg: String,\n     code: Option<String>,\n     lvl: Level,\n }\n \n-fn execute_work<'a>(sess: &'a Session,\n-                    mut work_items: Vec<WorkItem>,\n-                    jobserver: Client,\n-                    exported_symbols: &'a ExportedSymbols,\n-                    scope: &Scope<'a>) {\n-    let (tx, rx) = channel();\n-    let tx2 = tx.clone();\n+#[derive(PartialEq, Clone, Copy, Debug)]\n+enum MainThreadWorkerState {\n+    Idle,\n+    Translating,\n+    LLVMing,\n+}\n \n+fn start_executing_work(sess: &Session,\n+                        shared_emitter: SharedEmitter,\n+                        trans_worker_send: Sender<Message>,\n+                        coordinator_send: Sender<Message>,\n+                        coordinator_receive: Receiver<Message>,\n+                        jobserver: Client,\n+                        time_graph: Option<TimeGraph>,\n+                        exported_symbols: Arc<ExportedSymbols>)\n+                        -> thread::JoinHandle<CompiledModules> {\n     // First up, convert our jobserver into a helper thread so we can use normal\n     // mpsc channels to manage our messages and such. Once we've got the helper\n     // thread then request `n-1` tokens because all of our work items are ready\n@@ -1045,27 +1121,144 @@ fn execute_work<'a>(sess: &'a Session,\n     //\n     // After we've requested all these tokens then we'll, when we can, get\n     // tokens on `rx` above which will get managed in the main loop below.\n+    let coordinator_send2 = coordinator_send.clone();\n     let helper = jobserver.into_helper_thread(move |token| {\n-        drop(tx2.send(Message::Token(token)));\n+        drop(coordinator_send2.send(Message::Token(token)));\n     }).expect(\"failed to spawn helper thread\");\n-    for _ in 0..work_items.len() - 1 {\n-        helper.request_token();\n-    }\n+\n+    let mut each_linked_rlib_for_lto = Vec::new();\n+    drop(link::each_linked_rlib(sess, &mut |cnum, path| {\n+        if link::ignored_for_lto(sess, cnum) {\n+            return\n+        }\n+        each_linked_rlib_for_lto.push((cnum, path.to_path_buf()));\n+    }));\n+\n+    let cgcx = CodegenContext {\n+        crate_types: sess.crate_types.borrow().clone(),\n+        each_linked_rlib_for_lto: each_linked_rlib_for_lto,\n+        lto: sess.lto(),\n+        no_landing_pads: sess.no_landing_pads(),\n+        opts: Arc::new(sess.opts.clone()),\n+        time_passes: sess.time_passes(),\n+        exported_symbols: exported_symbols,\n+        plugin_passes: sess.plugin_llvm_passes.borrow().clone(),\n+        remark: sess.opts.cg.remark.clone(),\n+        worker: 0,\n+        incr_comp_session_dir: sess.incr_comp_session_dir_opt().map(|r| r.clone()),\n+        coordinator_send: coordinator_send,\n+        diag_emitter: shared_emitter.clone(),\n+        time_graph,\n+    };\n \n     // This is the \"main loop\" of parallel work happening for parallel codegen.\n     // It's here that we manage parallelism, schedule work, and work with\n     // messages coming from clients.\n     //\n-    // Our channel `rx` created above is a channel of messages coming from our\n-    // various worker threads. This includes the jobserver helper thread above\n-    // as well as the work we'll spawn off here. Each turn of this loop starts\n-    // off by trying to spawn as much work as possible. After we've done that we\n-    // then wait for an event and dispatch accordingly once the event is\n-    // received. We're only done once all our work items have been drained and\n-    // nothing is running, at which point we return back up the stack.\n+    // There are a few environmental pre-conditions that shape how the system\n+    // is set up:\n+    //\n+    // - Error reporting only can happen on the main thread because that's the\n+    //   only place where we have access to the compiler `Session`.\n+    // - LLVM work can be done on any thread.\n+    // - Translation can only happen on the main thread.\n+    // - Each thread doing substantial work most be in possession of a `Token`\n+    //   from the `Jobserver`.\n+    // - The compiler process always holds one `Token`. Any additional `Tokens`\n+    //   have to be requested from the `Jobserver`.\n+    //\n+    // Error Reporting\n+    // ===============\n+    // The error reporting restriction is handled separately from the rest: We\n+    // set up a `SharedEmitter` the holds an open channel to the main thread.\n+    // When an error occurs on any thread, the shared emitter will send the\n+    // error message to the receiver main thread (`SharedEmitterMain`). The\n+    // main thread will periodically query this error message queue and emit\n+    // any error messages it has received. It might even abort compilation if\n+    // has received a fatal error. In this case we rely on all other threads\n+    // being torn down automatically with the main thread.\n+    // Since the main thread will often be busy doing translation work, error\n+    // reporting will be somewhat delayed, since the message queue can only be\n+    // checked in between to work packages.\n+    //\n+    // Work Processing Infrastructure\n+    // ==============================\n+    // The work processing infrastructure knows three major actors:\n+    //\n+    // - the coordinator thread,\n+    // - the main thread, and\n+    // - LLVM worker threads\n+    //\n+    // The coordinator thread is running a message loop. It instructs the main\n+    // thread about what work to do when, and it will spawn off LLVM worker\n+    // threads as open LLVM WorkItems become available.\n+    //\n+    // The job of the main thread is to translate CGUs into LLVM work package\n+    // (since the main thread is the only thread that can do this). The main\n+    // thread will block until it receives a message from the coordinator, upon\n+    // which it will translate one CGU, send it to the coordinator and block\n+    // again. This way the coordinator can control what the main thread is\n+    // doing.\n+    //\n+    // The coordinator keeps a queue of LLVM WorkItems, and when a `Token` is\n+    // available, it will spawn off a new LLVM worker thread and let it process\n+    // that a WorkItem. When a LLVM worker thread is done with its WorkItem,\n+    // it will just shut down, which also frees all resources associated with\n+    // the given LLVM module, and sends a message to the coordinator that the\n+    // has been completed.\n+    //\n+    // Work Scheduling\n+    // ===============\n+    // The scheduler's goal is to minimize the time it takes to complete all\n+    // work there is, however, we also want to keep memory consumption low\n+    // if possible. These two goals are at odds with each other: If memory\n+    // consumption were not an issue, we could just let the main thread produce\n+    // LLVM WorkItems at full speed, assuring maximal utilization of\n+    // Tokens/LLVM worker threads. However, since translation usual is faster\n+    // than LLVM processing, the queue of LLVM WorkItems would fill up and each\n+    // WorkItem potentially holds on to a substantial amount of memory.\n+    //\n+    // So the actual goal is to always produce just enough LLVM WorkItems as\n+    // not to starve our LLVM worker threads. That means, once we have enough\n+    // WorkItems in our queue, we can block the main thread, so it does not\n+    // produce more until we need them.\n     //\n-    // ## Parallelism management\n+    // Doing LLVM Work on the Main Thread\n+    // ----------------------------------\n+    // Since the main thread owns the compiler processes implicit `Token`, it is\n+    // wasteful to keep it blocked without doing any work. Therefore, what we do\n+    // in this case is: We spawn off an additional LLVM worker thread that helps\n+    // reduce the queue. The work it is doing corresponds to the implicit\n+    // `Token`. The coordinator will mark the main thread as being busy with\n+    // LLVM work. (The actual work happens on another OS thread but we just care\n+    // about `Tokens`, not actual threads).\n     //\n+    // When any LLVM worker thread finishes while the main thread is marked as\n+    // \"busy with LLVM work\", we can do a little switcheroo: We give the Token\n+    // of the just finished thread to the LLVM worker thread that is working on\n+    // behalf of the main thread's implicit Token, thus freeing up the main\n+    // thread again. The coordinator can then again decide what the main thread\n+    // should do. This allows the coordinator to make decisions at more points\n+    // in time.\n+    //\n+    // Striking a Balance between Throughput and Memory Consumption\n+    // ------------------------------------------------------------\n+    // Since our two goals, (1) use as many Tokens as possible and (2) keep\n+    // memory consumption as low as possible, are in conflict with each other,\n+    // we have to find a trade off between them. Right now, the goal is to keep\n+    // all workers busy, which means that no worker should find the queue empty\n+    // when it is ready to start.\n+    // How do we do achieve this? Good question :) We actually never know how\n+    // many `Tokens` are potentially available so it's hard to say how much to\n+    // fill up the queue before switching the main thread to LLVM work. Also we\n+    // currently don't have a means to estimate how long a running LLVM worker\n+    // will still be busy with it's current WorkItem. However, we know the\n+    // maximal count of available Tokens that makes sense (=the number of CPU\n+    // cores), so we can take a conservative guess. The heuristic we use here\n+    // is implemented in the `queue_full_enough()` function.\n+    //\n+    // Some Background on Jobservers\n+    // -----------------------------\n     // It's worth also touching on the management of parallelism here. We don't\n     // want to just spawn a thread per work item because while that's optimal\n     // parallelism it may overload a system with too many threads or violate our\n@@ -1078,193 +1271,302 @@ fn execute_work<'a>(sess: &'a Session,\n     // and whenever we're done with that work we release the semaphore. In this\n     // manner we can ensure that the maximum number of parallel workers is\n     // capped at any one point in time.\n-    //\n-    // The jobserver protocol is a little unique, however. We, as a running\n-    // process, already have an ephemeral token assigned to us. We're not going\n-    // to be doing any productive work in this thread though so we're going to\n-    // give this token to a worker thread (there's no actual token to give, this\n-    // is just conceptually). As a result you'll see a few `+1` and `-1`\n-    // instances below, and it's about working with this ephemeral token.\n-    //\n-    // To acquire tokens we have our `helper` thread above which is just in a\n-    // loop acquiring tokens and sending them to us. We then store all tokens\n-    // locally in a `tokens` vector once they're acquired. Currently we don't\n-    // literally send a token to a worker thread to assist with management of\n-    // our \"ephemeral token\".\n-    //\n-    // As a result, our \"spawn as much work as possible\" basically means that we\n-    // fill up the `running` counter up to the limit of the `tokens` list.\n-    // Whenever we get a new token this'll mean a new unit of work is spawned,\n-    // and then whenever a unit of work finishes we relinquish a token, if we\n-    // had one, to maybe get re-acquired later.\n-    //\n-    // Note that there's a race which may mean that we acquire more tokens than\n-    // we originally anticipated. For example let's say we have 2 units of work.\n-    // First we request one token from the helper thread and then we\n-    // immediately spawn one unit of work with our ephemeral token after. We may\n-    // then finish the first piece of work before the token is acquired, but we\n-    // can continue to spawn the second piece of work with our ephemeral token.\n-    // Before that work finishes, however, we may acquire a token. In that case\n-    // we actually wastefully acquired the token, so we relinquish it back to\n-    // the jobserver.\n-    let mut tokens = Vec::new();\n-    let mut running = 0;\n-    while work_items.len() > 0 || running > 0 {\n-\n-        // Spin up what work we can, only doing this while we've got available\n-        // parallelism slots and work left to spawn.\n-        while work_items.len() > 0 && running < tokens.len() + 1 {\n-            let item = work_items.pop().unwrap();\n-            let index = work_items.len();\n-            spawn_work(sess, exported_symbols, scope, tx.clone(), item, index);\n-            running += 1;\n-        }\n-\n-        // Relinquish accidentally acquired extra tokens\n-        tokens.truncate(running.saturating_sub(1));\n-\n-        match rx.recv().unwrap() {\n-            // Save the token locally and the next turn of the loop will use\n-            // this to spawn a new unit of work, or it may get dropped\n-            // immediately if we have no more work to spawn.\n-            Message::Token(token) => {\n-                tokens.push(token.expect(\"failed to acquire jobserver token\"));\n+    return thread::spawn(move || {\n+        // We pretend to be within the top-level LLVM time-passes task here:\n+        set_time_depth(1);\n+\n+        let max_workers = ::num_cpus::get();\n+        let mut worker_id_counter = 0;\n+        let mut free_worker_ids = Vec::new();\n+        let mut get_worker_id = |free_worker_ids: &mut Vec<usize>| {\n+            if let Some(id) = free_worker_ids.pop() {\n+                id\n+            } else {\n+                let id = worker_id_counter;\n+                worker_id_counter += 1;\n+                id\n             }\n+        };\n \n-            // If a thread exits successfully then we drop a token associated\n-            // with that worker and update our `running` count. We may later\n-            // re-acquire a token to continue running more work. We may also not\n-            // actually drop a token here if the worker was running with an\n-            // \"ephemeral token\"\n-            //\n-            // Note that if the thread failed that means it panicked, so we\n-            // abort immediately.\n-            Message::Done { success: true } => {\n-                drop(tokens.pop());\n-                running -= 1;\n+        // This is where we collect codegen units that have gone all the way\n+        // through translation and LLVM.\n+        let mut compiled_modules = vec![];\n+        let mut compiled_metadata_module = None;\n+        let mut compiled_allocator_module = None;\n+\n+        // This flag tracks whether all items have gone through translations\n+        let mut translation_done = false;\n+\n+        // This is the queue of LLVM work items that still need processing.\n+        let mut work_items = Vec::new();\n+\n+        // This are the Jobserver Tokens we currently hold. Does not include\n+        // the implicit Token the compiler process owns no matter what.\n+        let mut tokens = Vec::new();\n+\n+        let mut main_thread_worker_state = MainThreadWorkerState::Idle;\n+        let mut running = 0;\n+\n+        let mut llvm_start_time = None;\n+\n+        // Run the message loop while there's still anything that needs message\n+        // processing:\n+        while !translation_done ||\n+              work_items.len() > 0 ||\n+              running > 0 ||\n+              main_thread_worker_state != MainThreadWorkerState::Idle {\n+\n+            // While there are still CGUs to be translated, the coordinator has\n+            // to decide how to utilize the compiler processes implicit Token:\n+            // For translating more CGU or for running them through LLVM.\n+            if !translation_done {\n+                if main_thread_worker_state == MainThreadWorkerState::Idle {\n+                    if !queue_full_enough(work_items.len(), running, max_workers) {\n+                        // The queue is not full enough, translate more items:\n+                        if let Err(_) = trans_worker_send.send(Message::TranslateItem) {\n+                            panic!(\"Could not send Message::TranslateItem to main thread\")\n+                        }\n+                        main_thread_worker_state = MainThreadWorkerState::Translating;\n+                    } else {\n+                        // The queue is full enough to not let the worker\n+                        // threads starve. Use the implicit Token to do some\n+                        // LLVM work too.\n+                        let (item, _) = work_items.pop()\n+                            .expect(\"queue empty - queue_full_enough() broken?\");\n+                        let cgcx = CodegenContext {\n+                            worker: get_worker_id(&mut free_worker_ids),\n+                            .. cgcx.clone()\n+                        };\n+                        maybe_start_llvm_timer(&item, &mut llvm_start_time);\n+                        main_thread_worker_state = MainThreadWorkerState::LLVMing;\n+                        spawn_work(cgcx, item);\n+                    }\n+                }\n+            } else {\n+                // In this branch, we know that everything has been translated,\n+                // so it's just a matter of determining whether the implicit\n+                // Token is free to use for LLVM work.\n+                match main_thread_worker_state {\n+                    MainThreadWorkerState::Idle => {\n+                        if let Some((item, _)) = work_items.pop() {\n+                            let cgcx = CodegenContext {\n+                                worker: get_worker_id(&mut free_worker_ids),\n+                                .. cgcx.clone()\n+                            };\n+                            maybe_start_llvm_timer(&item, &mut llvm_start_time);\n+                            main_thread_worker_state = MainThreadWorkerState::LLVMing;\n+                            spawn_work(cgcx, item);\n+                        }\n+                    }\n+                    MainThreadWorkerState::Translating => {\n+                        bug!(\"trans worker should not be translating after \\\n+                              translation was already completed\")\n+                    }\n+                    MainThreadWorkerState::LLVMing => {\n+                        // Already making good use of that token\n+                    }\n+                }\n             }\n-            Message::Done { success: false } => {\n-                sess.fatal(\"aborting due to worker thread panic\");\n+\n+            // Spin up what work we can, only doing this while we've got available\n+            // parallelism slots and work left to spawn.\n+            while work_items.len() > 0 && running < tokens.len() {\n+                let (item, _) = work_items.pop().unwrap();\n+\n+                maybe_start_llvm_timer(&item, &mut llvm_start_time);\n+\n+                let cgcx = CodegenContext {\n+                    worker: get_worker_id(&mut free_worker_ids),\n+                    .. cgcx.clone()\n+                };\n+\n+                spawn_work(cgcx, item);\n+                running += 1;\n             }\n \n-            // Our worker wants us to emit an error message, so get ahold of our\n-            // `sess` and print it out\n-            Message::Diagnostic(diag) => {\n-                let handler = sess.diagnostic();\n-                match diag.code {\n-                    Some(ref code) => {\n-                        handler.emit_with_code(&MultiSpan::new(),\n-                                               &diag.msg,\n-                                               &code,\n-                                               diag.lvl);\n+            // Relinquish accidentally acquired extra tokens\n+            tokens.truncate(running);\n+\n+            match coordinator_receive.recv().unwrap() {\n+                // Save the token locally and the next turn of the loop will use\n+                // this to spawn a new unit of work, or it may get dropped\n+                // immediately if we have no more work to spawn.\n+                Message::Token(token) => {\n+                    match token {\n+                        Ok(token) => {\n+                            tokens.push(token);\n+\n+                            if main_thread_worker_state == MainThreadWorkerState::LLVMing {\n+                                // If the main thread token is used for LLVM work\n+                                // at the moment, we turn that thread into a regular\n+                                // LLVM worker thread, so the main thread is free\n+                                // to react to translation demand.\n+                                main_thread_worker_state = MainThreadWorkerState::Idle;\n+                                running += 1;\n+                            }\n+                        }\n+                        Err(e) => {\n+                            let msg = &format!(\"failed to acquire jobserver token: {}\", e);\n+                            shared_emitter.fatal(msg);\n+                            // Exit the coordinator thread\n+                            panic!(\"{}\", msg)\n+                        }\n                     }\n-                    None => {\n-                        handler.emit(&MultiSpan::new(),\n-                                     &diag.msg,\n-                                     diag.lvl);\n+                }\n+\n+                Message::TranslationDone { llvm_work_item, cost, is_last } => {\n+                    // We keep the queue sorted by estimated processing cost,\n+                    // so that more expensive items are processed earlier. This\n+                    // is good for throughput as it gives the main thread more\n+                    // time to fill up the queue and it avoids scheduling\n+                    // expensive items to the end.\n+                    // Note, however, that this is not ideal for memory\n+                    // consumption, as LLVM module sizes are not evenly\n+                    // distributed.\n+                    let insertion_index =\n+                        work_items.binary_search_by_key(&cost, |&(_, cost)| cost);\n+                    let insertion_index = match insertion_index {\n+                        Ok(idx) | Err(idx) => idx\n+                    };\n+                    work_items.insert(insertion_index, (llvm_work_item, cost));\n+\n+                    if is_last {\n+                        // If this is the last, don't request a token because\n+                        // the trans worker thread will be free to handle this\n+                        // immediately.\n+                        translation_done = true;\n+                    } else {\n+                        helper.request_token();\n                     }\n+\n+                    assert_eq!(main_thread_worker_state,\n+                               MainThreadWorkerState::Translating);\n+                    main_thread_worker_state = MainThreadWorkerState::Idle;\n                 }\n-            }\n-            Message::InlineAsmError(cookie, msg) => {\n-                match Mark::from_u32(cookie).expn_info() {\n-                    Some(ei) => sess.span_err(ei.call_site, &msg),\n-                    None     => sess.err(&msg),\n+\n+                // If a thread exits successfully then we drop a token associated\n+                // with that worker and update our `running` count. We may later\n+                // re-acquire a token to continue running more work. We may also not\n+                // actually drop a token here if the worker was running with an\n+                // \"ephemeral token\"\n+                //\n+                // Note that if the thread failed that means it panicked, so we\n+                // abort immediately.\n+                Message::Done { result: Ok(compiled_module), worker_id } => {\n+                    if main_thread_worker_state == MainThreadWorkerState::LLVMing {\n+                        main_thread_worker_state = MainThreadWorkerState::Idle;\n+                    } else {\n+                        running -= 1;\n+                    }\n+\n+                    free_worker_ids.push(worker_id);\n+\n+                    match compiled_module.kind {\n+                        ModuleKind::Regular => {\n+                            compiled_modules.push(compiled_module);\n+                        }\n+                        ModuleKind::Metadata => {\n+                            assert!(compiled_metadata_module.is_none());\n+                            compiled_metadata_module = Some(compiled_module);\n+                        }\n+                        ModuleKind::Allocator => {\n+                            assert!(compiled_allocator_module.is_none());\n+                            compiled_allocator_module = Some(compiled_module);\n+                        }\n+                    }\n+                }\n+                Message::Done { result: Err(()), worker_id: _ } => {\n+                    shared_emitter.fatal(\"aborting due to worker thread panic\");\n+                    // Exit the coordinator thread\n+                    panic!(\"aborting due to worker thread panic\")\n+                }\n+                Message::TranslateItem => {\n+                    bug!(\"the coordinator should not receive translation requests\")\n                 }\n             }\n+        }\n \n-            // Sent to us after a worker sends us a batch of error messages, and\n-            // it's the point at which we check for errors.\n-            Message::AbortIfErrors => sess.diagnostic().abort_if_errors(),\n+        if let Some(llvm_start_time) = llvm_start_time {\n+            let total_llvm_time = Instant::now().duration_since(llvm_start_time);\n+            // This is the top-level timing for all of LLVM, set the time-depth\n+            // to zero.\n+            set_time_depth(0);\n+            print_time_passes_entry(cgcx.time_passes,\n+                                    \"LLVM passes\",\n+                                    total_llvm_time);\n         }\n-    }\n \n-    // Just in case, check this on the way out.\n-    sess.diagnostic().abort_if_errors();\n-}\n+        let compiled_metadata_module = compiled_metadata_module\n+            .expect(\"Metadata module not compiled?\");\n \n-struct SharedEmitter {\n-    tx: Sender<Message>,\n-}\n+        CompiledModules {\n+            modules: compiled_modules,\n+            metadata_module: compiled_metadata_module,\n+            allocator_module: compiled_allocator_module,\n+        }\n+    });\n \n-impl Emitter for SharedEmitter {\n-    fn emit(&mut self, db: &DiagnosticBuilder) {\n-        drop(self.tx.send(Message::Diagnostic(Diagnostic {\n-            msg: db.message(),\n-            code: db.code.clone(),\n-            lvl: db.level,\n-        })));\n-        for child in &db.children {\n-            drop(self.tx.send(Message::Diagnostic(Diagnostic {\n-                msg: child.message(),\n-                code: None,\n-                lvl: child.level,\n-            })));\n+    // A heuristic that determines if we have enough LLVM WorkItems in the\n+    // queue so that the main thread can do LLVM work instead of translation\n+    fn queue_full_enough(items_in_queue: usize,\n+                         workers_running: usize,\n+                         max_workers: usize) -> bool {\n+        // Tune me, plz.\n+        items_in_queue > 0 &&\n+        items_in_queue >= max_workers.saturating_sub(workers_running / 2)\n+    }\n+\n+    fn maybe_start_llvm_timer(work_item: &WorkItem,\n+                              llvm_start_time: &mut Option<Instant>) {\n+        // We keep track of the -Ztime-passes output manually,\n+        // since the closure-based interface does not fit well here.\n+        if work_item.config.time_passes {\n+            if llvm_start_time.is_none() {\n+                *llvm_start_time = Some(Instant::now());\n+            }\n         }\n-        drop(self.tx.send(Message::AbortIfErrors));\n     }\n }\n \n-fn spawn_work<'a>(sess: &'a Session,\n-                  exported_symbols: &'a ExportedSymbols,\n-                  scope: &Scope<'a>,\n-                  tx: Sender<Message>,\n-                  work: WorkItem,\n-                  idx: usize) {\n-    let plugin_passes = sess.plugin_llvm_passes.borrow().clone();\n-    let remark = sess.opts.cg.remark.clone();\n-    let incr_comp_session_dir = sess.incr_comp_session_dir_opt().map(|r| r.clone());\n+pub const TRANS_WORKER_ID: usize = ::std::usize::MAX;\n+pub const TRANS_WORKER_TIMELINE: time_graph::TimelineId =\n+    time_graph::TimelineId(TRANS_WORKER_ID);\n+pub const TRANS_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n+    time_graph::WorkPackageKind(&[\"#DE9597\", \"#FED1D3\", \"#FDC5C7\", \"#B46668\", \"#88494B\"]);\n+const LLVM_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n+    time_graph::WorkPackageKind(&[\"#7DB67A\", \"#C6EEC4\", \"#ACDAAA\", \"#579354\", \"#3E6F3C\"]);\n+\n+fn spawn_work(cgcx: CodegenContext, work: WorkItem) {\n     let depth = time_depth();\n-    let lto = sess.lto();\n-    let crate_types = sess.crate_types.borrow().clone();\n-    let mut each_linked_rlib_for_lto = Vec::new();\n-    drop(link::each_linked_rlib(sess, &mut |cnum, path| {\n-        if link::ignored_for_lto(sess, cnum) {\n-            return\n-        }\n-        each_linked_rlib_for_lto.push((cnum, path.to_path_buf()));\n-    }));\n-    let time_passes = sess.time_passes();\n-    let no_landing_pads = sess.no_landing_pads();\n-    let opts = &sess.opts;\n \n-    scope.spawn(move || {\n+    thread::spawn(move || {\n         set_time_depth(depth);\n \n         // Set up a destructor which will fire off a message that we're done as\n         // we exit.\n         struct Bomb {\n-            tx: Sender<Message>,\n-            success: bool,\n+            coordinator_send: Sender<Message>,\n+            result: Option<CompiledModule>,\n+            worker_id: usize,\n         }\n         impl Drop for Bomb {\n             fn drop(&mut self) {\n-                drop(self.tx.send(Message::Done { success: self.success }));\n+                let result = match self.result.take() {\n+                    Some(compiled_module) => Ok(compiled_module),\n+                    None => Err(())\n+                };\n+\n+                drop(self.coordinator_send.send(Message::Done {\n+                    result,\n+                    worker_id: self.worker_id,\n+                }));\n             }\n         }\n-        let mut bomb = Bomb {\n-            tx: tx.clone(),\n-            success: false,\n-        };\n \n-        // Set up our non-`Send` `CodegenContext` now that we're in a helper\n-        // thread and have all our info available to us.\n-        let emitter = SharedEmitter { tx: tx.clone() };\n-        let diag_handler = Handler::with_emitter(true, false, Box::new(emitter));\n-\n-        let cgcx = CodegenContext {\n-            crate_types: crate_types,\n-            each_linked_rlib_for_lto: each_linked_rlib_for_lto,\n-            lto: lto,\n-            no_landing_pads: no_landing_pads,\n-            opts: opts,\n-            time_passes: time_passes,\n-            exported_symbols: exported_symbols,\n-            handler: &diag_handler,\n-            plugin_passes: plugin_passes,\n-            remark: remark,\n-            worker: idx,\n-            incr_comp_session_dir: incr_comp_session_dir,\n-            tx: tx.clone(),\n+        let mut bomb = Bomb {\n+            coordinator_send: cgcx.coordinator_send.clone(),\n+            result: None,\n+            worker_id: cgcx.worker,\n         };\n \n         // Execute the work itself, and if it finishes successfully then flag\n@@ -1280,8 +1582,13 @@ fn spawn_work<'a>(sess: &'a Session,\n         // we just ignore the result and then send off our message saying that\n         // we're done, which if `execute_work_item` failed is unlikely to be\n         // seen by the main thread, but hey we might as well try anyway.\n-        drop(execute_work_item(&cgcx, work).is_err());\n-        bomb.success = true;\n+        bomb.result = {\n+            let _timing_guard = cgcx.time_graph\n+                                .as_ref()\n+                                .map(|tg| tg.start(time_graph::TimelineId(cgcx.worker),\n+                                                   LLVM_WORK_PACKAGE_KIND));\n+            Some(execute_work_item(&cgcx, work).unwrap())\n+        };\n     });\n }\n \n@@ -1375,3 +1682,249 @@ pub unsafe fn with_llvm_pmb(llmod: ModuleRef,\n     f(builder);\n     llvm::LLVMPassManagerBuilderDispose(builder);\n }\n+\n+\n+enum SharedEmitterMessage {\n+    Diagnostic(Diagnostic),\n+    InlineAsmError(u32, String),\n+    AbortIfErrors,\n+    Fatal(String),\n+}\n+\n+#[derive(Clone)]\n+pub struct SharedEmitter {\n+    sender: Sender<SharedEmitterMessage>,\n+}\n+\n+pub struct SharedEmitterMain {\n+    receiver: Receiver<SharedEmitterMessage>,\n+}\n+\n+impl SharedEmitter {\n+    pub fn new() -> (SharedEmitter, SharedEmitterMain) {\n+        let (sender, receiver) = channel();\n+\n+        (SharedEmitter { sender }, SharedEmitterMain { receiver })\n+    }\n+\n+    fn inline_asm_error(&self, cookie: u32, msg: String) {\n+        drop(self.sender.send(SharedEmitterMessage::InlineAsmError(cookie, msg)));\n+    }\n+\n+    fn fatal(&self, msg: &str) {\n+        drop(self.sender.send(SharedEmitterMessage::Fatal(msg.to_string())));\n+    }\n+}\n+\n+impl Emitter for SharedEmitter {\n+    fn emit(&mut self, db: &DiagnosticBuilder) {\n+        drop(self.sender.send(SharedEmitterMessage::Diagnostic(Diagnostic {\n+            msg: db.message(),\n+            code: db.code.clone(),\n+            lvl: db.level,\n+        })));\n+        for child in &db.children {\n+            drop(self.sender.send(SharedEmitterMessage::Diagnostic(Diagnostic {\n+                msg: child.message(),\n+                code: None,\n+                lvl: child.level,\n+            })));\n+        }\n+        drop(self.sender.send(SharedEmitterMessage::AbortIfErrors));\n+    }\n+}\n+\n+impl SharedEmitterMain {\n+    pub fn check(&self, sess: &Session, blocking: bool) {\n+        loop {\n+            let message = if blocking {\n+                match self.receiver.recv() {\n+                    Ok(message) => Ok(message),\n+                    Err(_) => Err(()),\n+                }\n+            } else {\n+                match self.receiver.try_recv() {\n+                    Ok(message) => Ok(message),\n+                    Err(_) => Err(()),\n+                }\n+            };\n+\n+            match message {\n+                Ok(SharedEmitterMessage::Diagnostic(diag)) => {\n+                    let handler = sess.diagnostic();\n+                    match diag.code {\n+                        Some(ref code) => {\n+                            handler.emit_with_code(&MultiSpan::new(),\n+                                                   &diag.msg,\n+                                                   &code,\n+                                                   diag.lvl);\n+                        }\n+                        None => {\n+                            handler.emit(&MultiSpan::new(),\n+                                         &diag.msg,\n+                                         diag.lvl);\n+                        }\n+                    }\n+                }\n+                Ok(SharedEmitterMessage::InlineAsmError(cookie, msg)) => {\n+                    match Mark::from_u32(cookie).expn_info() {\n+                        Some(ei) => sess.span_err(ei.call_site, &msg),\n+                        None     => sess.err(&msg),\n+                    }\n+                }\n+                Ok(SharedEmitterMessage::AbortIfErrors) => {\n+                    sess.abort_if_errors();\n+                }\n+                Ok(SharedEmitterMessage::Fatal(msg)) => {\n+                    sess.fatal(&msg);\n+                }\n+                Err(_) => {\n+                    break;\n+                }\n+            }\n+\n+        }\n+    }\n+}\n+\n+pub struct OngoingCrateTranslation {\n+    crate_name: Symbol,\n+    link: LinkMeta,\n+    metadata: EncodedMetadata,\n+    exported_symbols: Arc<ExportedSymbols>,\n+    no_builtins: bool,\n+    windows_subsystem: Option<String>,\n+    linker_info: LinkerInfo,\n+    no_integrated_as: bool,\n+\n+    output_filenames: OutputFilenames,\n+    regular_module_config: ModuleConfig,\n+    metadata_module_config: ModuleConfig,\n+    allocator_module_config: ModuleConfig,\n+\n+    time_graph: Option<TimeGraph>,\n+    coordinator_send: Sender<Message>,\n+    trans_worker_receive: Receiver<Message>,\n+    shared_emitter_main: SharedEmitterMain,\n+    future: thread::JoinHandle<CompiledModules>,\n+}\n+\n+impl OngoingCrateTranslation {\n+    pub fn join(self, sess: &Session) -> CrateTranslation {\n+        self.shared_emitter_main.check(sess, true);\n+        let compiled_modules = match self.future.join() {\n+            Ok(compiled_modules) => compiled_modules,\n+            Err(_) => {\n+                sess.fatal(\"Error during translation/LLVM phase.\");\n+            }\n+        };\n+\n+        sess.abort_if_errors();\n+\n+        if let Some(time_graph) = self.time_graph {\n+            time_graph.dump(&format!(\"{}-timings\", self.crate_name));\n+        }\n+\n+        copy_module_artifacts_into_incr_comp_cache(sess,\n+                                                   &compiled_modules,\n+                                                   &self.output_filenames);\n+        produce_final_output_artifacts(sess,\n+                                       &compiled_modules,\n+                                       &self.output_filenames);\n+\n+        // FIXME: time_llvm_passes support - does this use a global context or\n+        // something?\n+        if sess.opts.cg.codegen_units == 1 && sess.time_llvm_passes() {\n+            unsafe { llvm::LLVMRustPrintPassTimings(); }\n+        }\n+\n+        let trans = CrateTranslation {\n+            crate_name: self.crate_name,\n+            link: self.link,\n+            metadata: self.metadata,\n+            exported_symbols: self.exported_symbols,\n+            no_builtins: self.no_builtins,\n+            windows_subsystem: self.windows_subsystem,\n+            linker_info: self.linker_info,\n+\n+            modules: compiled_modules.modules,\n+            metadata_module: compiled_modules.metadata_module,\n+            allocator_module: compiled_modules.allocator_module,\n+        };\n+\n+        if self.no_integrated_as {\n+            run_assembler(sess,  &self.output_filenames);\n+\n+            // HACK the linker expects the object file to be named foo.0.o but\n+            // `run_assembler` produces an object named just foo.o. Rename it if we\n+            // are going to build an executable\n+            if sess.opts.output_types.contains_key(&OutputType::Exe) {\n+                let f =  self.output_filenames.path(OutputType::Object);\n+                rename_or_copy_remove(&f,\n+                    f.with_file_name(format!(\"{}.0.o\",\n+                                             f.file_stem().unwrap().to_string_lossy()))).unwrap();\n+            }\n+\n+            // Remove assembly source, unless --save-temps was specified\n+            if !sess.opts.cg.save_temps {\n+                fs::remove_file(&self.output_filenames\n+                                     .temp_path(OutputType::Assembly, None)).unwrap();\n+            }\n+        }\n+\n+        trans\n+    }\n+\n+    pub fn submit_translated_module_to_llvm(&self,\n+                                            sess: &Session,\n+                                            mtrans: ModuleTranslation,\n+                                            cost: u64,\n+                                            is_last: bool) {\n+        let module_config = match mtrans.kind {\n+            ModuleKind::Regular => self.regular_module_config.clone(sess),\n+            ModuleKind::Metadata => self.metadata_module_config.clone(sess),\n+            ModuleKind::Allocator => self.allocator_module_config.clone(sess),\n+        };\n+\n+        let llvm_work_item = build_work_item(mtrans,\n+                                             module_config,\n+                                             self.output_filenames.clone());\n+\n+        drop(self.coordinator_send.send(Message::TranslationDone {\n+            llvm_work_item,\n+            cost,\n+            is_last\n+        }));\n+    }\n+\n+    pub fn submit_pre_translated_module_to_llvm(&self,\n+                                                sess: &Session,\n+                                                mtrans: ModuleTranslation,\n+                                                is_last: bool) {\n+        self.wait_for_signal_to_translate_item();\n+        self.check_for_errors(sess);\n+\n+        // These are generally cheap and won't through off scheduling.\n+        let cost = 0;\n+        self.submit_translated_module_to_llvm(sess, mtrans, cost, is_last);\n+    }\n+\n+    pub fn check_for_errors(&self, sess: &Session) {\n+        self.shared_emitter_main.check(sess, false);\n+    }\n+\n+    pub fn wait_for_signal_to_translate_item(&self) {\n+        match self.trans_worker_receive.recv() {\n+            Ok(Message::TranslateItem) => {\n+                // Nothing to do\n+            }\n+            Ok(message) => {\n+                panic!(\"unexpected message: {:?}\", message)\n+            }\n+            Err(_) => {\n+                // One of the LLVM threads must have panicked, fall through so\n+                // error handling can be reached.\n+            }\n+        }\n+    }\n+}"}, {"sha": "14c73de64bc798f80e82768dac05c2f1956ea6fa", "filename": "src/librustc_trans/base.rs", "status": "modified", "additions": 274, "deletions": 153, "changes": 427, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbase.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -23,29 +23,30 @@\n //!     but one TypeRef corresponds to many `Ty`s; for instance, tup(int, int,\n //!     int) and rec(x=int, y=int, z=int) will have the same TypeRef.\n \n-use super::CrateTranslation;\n use super::ModuleLlvm;\n use super::ModuleSource;\n use super::ModuleTranslation;\n+use super::ModuleKind;\n \n use assert_module_sources;\n use back::link;\n use back::linker::LinkerInfo;\n use back::symbol_export::{self, ExportedSymbols};\n+use back::write::{self, OngoingCrateTranslation};\n use llvm::{ContextRef, Linkage, ModuleRef, ValueRef, Vector, get_param};\n use llvm;\n use metadata;\n use rustc::hir::def_id::LOCAL_CRATE;\n use rustc::middle::lang_items::StartFnLangItem;\n-use rustc::middle::cstore::EncodedMetadata;\n+use rustc::middle::cstore::{EncodedMetadata, EncodedMetadataHashes};\n use rustc::ty::{self, Ty, TyCtxt};\n use rustc::dep_graph::AssertDepGraphSafe;\n use rustc::middle::cstore::LinkMeta;\n use rustc::hir::map as hir_map;\n-use rustc::util::common::time;\n-use rustc::session::config::{self, NoDebugInfo, OutputFilenames};\n+use rustc::util::common::{time, print_time_passes_entry};\n+use rustc::session::config::{self, NoDebugInfo, OutputFilenames, OutputType};\n use rustc::session::Session;\n-use rustc_incremental::IncrementalHashesMap;\n+use rustc_incremental::{self, IncrementalHashesMap};\n use abi;\n use allocator;\n use mir::lvalue::LvalueRef;\n@@ -68,6 +69,7 @@ use mir;\n use monomorphize::{self, Instance};\n use partitioning::{self, PartitioningStrategy, CodegenUnit};\n use symbol_names_test;\n+use time_graph;\n use trans_item::{TransItem, DefPathBasedNames};\n use type_::Type;\n use type_of;\n@@ -78,6 +80,7 @@ use libc::c_uint;\n use std::ffi::{CStr, CString};\n use std::str;\n use std::sync::Arc;\n+use std::time::{Instant, Duration};\n use std::i32;\n use syntax_pos::Span;\n use syntax::attr;\n@@ -647,24 +650,30 @@ pub fn set_link_section(ccx: &CrateContext,\n     }\n }\n \n+// check for the #[rustc_error] annotation, which forces an\n+// error in trans. This is used to write compile-fail tests\n+// that actually test that compilation succeeds without\n+// reporting an error.\n+fn check_for_rustc_errors_attr(tcx: TyCtxt) {\n+    if let Some((id, span)) = *tcx.sess.entry_fn.borrow() {\n+        let main_def_id = tcx.hir.local_def_id(id);\n+\n+        if tcx.has_attr(main_def_id, \"rustc_error\") {\n+            tcx.sess.span_fatal(span, \"compilation successful\");\n+        }\n+    }\n+}\n+\n /// Create the `main` function which will initialise the rust runtime and call\n /// users main function.\n-pub fn maybe_create_entry_wrapper(ccx: &CrateContext) {\n+fn maybe_create_entry_wrapper(ccx: &CrateContext) {\n     let (main_def_id, span) = match *ccx.sess().entry_fn.borrow() {\n         Some((id, span)) => {\n             (ccx.tcx().hir.local_def_id(id), span)\n         }\n         None => return,\n     };\n \n-    // check for the #[rustc_error] annotation, which forces an\n-    // error in trans. This is used to write compile-fail tests\n-    // that actually test that compilation succeeds without\n-    // reporting an error.\n-    if ccx.tcx().has_attr(main_def_id, \"rustc_error\") {\n-        ccx.tcx().sess.span_fatal(span, \"compilation successful\");\n-    }\n-\n     let instance = Instance::mono(ccx.tcx(), main_def_id);\n \n     if !ccx.codegen_unit().contains_item(&TransItem::Fn(instance)) {\n@@ -728,7 +737,8 @@ fn contains_null(s: &str) -> bool {\n fn write_metadata<'a, 'gcx>(tcx: TyCtxt<'a, 'gcx, 'gcx>,\n                             link_meta: &LinkMeta,\n                             exported_symbols: &NodeSet)\n-                            -> (ContextRef, ModuleRef, EncodedMetadata) {\n+                            -> (ContextRef, ModuleRef,\n+                                EncodedMetadata, EncodedMetadataHashes) {\n     use std::io::Write;\n     use flate2::Compression;\n     use flate2::write::DeflateEncoder;\n@@ -758,15 +768,18 @@ fn write_metadata<'a, 'gcx>(tcx: TyCtxt<'a, 'gcx, 'gcx>,\n     }).max().unwrap();\n \n     if kind == MetadataKind::None {\n-        return (metadata_llcx, metadata_llmod, EncodedMetadata::new());\n+        return (metadata_llcx,\n+                metadata_llmod,\n+                EncodedMetadata::new(),\n+                EncodedMetadataHashes::new());\n     }\n \n     let cstore = &tcx.sess.cstore;\n-    let metadata = cstore.encode_metadata(tcx,\n-                                          &link_meta,\n-                                          exported_symbols);\n+    let (metadata, hashes) = cstore.encode_metadata(tcx,\n+                                                    &link_meta,\n+                                                    exported_symbols);\n     if kind == MetadataKind::Uncompressed {\n-        return (metadata_llcx, metadata_llmod, metadata);\n+        return (metadata_llcx, metadata_llmod, metadata, hashes);\n     }\n \n     assert!(kind == MetadataKind::Compressed);\n@@ -794,7 +807,7 @@ fn write_metadata<'a, 'gcx>(tcx: TyCtxt<'a, 'gcx, 'gcx>,\n         let directive = CString::new(directive).unwrap();\n         llvm::LLVMSetModuleInlineAsm(metadata_llmod, directive.as_ptr())\n     }\n-    return (metadata_llcx, metadata_llmod, metadata);\n+    return (metadata_llcx, metadata_llmod, metadata, hashes);\n }\n \n // Create a `__imp_<symbol> = &symbol` global for every public static `symbol`.\n@@ -803,7 +816,7 @@ fn write_metadata<'a, 'gcx>(tcx: TyCtxt<'a, 'gcx, 'gcx>,\n // code references on its own.\n // See #26591, #27438\n fn create_imps(sess: &Session,\n-               llvm_modules: &[ModuleLlvm]) {\n+               llvm_module: &ModuleLlvm) {\n     // The x86 ABI seems to require that leading underscores are added to symbol\n     // names, so we need an extra underscore on 32-bit. There's also a leading\n     // '\\x01' here which disables LLVM's symbol mangling (e.g. no extra\n@@ -814,28 +827,26 @@ fn create_imps(sess: &Session,\n         \"\\x01__imp_\"\n     };\n     unsafe {\n-        for ll in llvm_modules {\n-            let exported: Vec<_> = iter_globals(ll.llmod)\n-                                       .filter(|&val| {\n-                                           llvm::LLVMRustGetLinkage(val) ==\n-                                           llvm::Linkage::ExternalLinkage &&\n-                                           llvm::LLVMIsDeclaration(val) == 0\n-                                       })\n-                                       .collect();\n-\n-            let i8p_ty = Type::i8p_llcx(ll.llcx);\n-            for val in exported {\n-                let name = CStr::from_ptr(llvm::LLVMGetValueName(val));\n-                let mut imp_name = prefix.as_bytes().to_vec();\n-                imp_name.extend(name.to_bytes());\n-                let imp_name = CString::new(imp_name).unwrap();\n-                let imp = llvm::LLVMAddGlobal(ll.llmod,\n-                                              i8p_ty.to_ref(),\n-                                              imp_name.as_ptr() as *const _);\n-                let init = llvm::LLVMConstBitCast(val, i8p_ty.to_ref());\n-                llvm::LLVMSetInitializer(imp, init);\n-                llvm::LLVMRustSetLinkage(imp, llvm::Linkage::ExternalLinkage);\n-            }\n+        let exported: Vec<_> = iter_globals(llvm_module.llmod)\n+                                   .filter(|&val| {\n+                                       llvm::LLVMRustGetLinkage(val) ==\n+                                       llvm::Linkage::ExternalLinkage &&\n+                                       llvm::LLVMIsDeclaration(val) == 0\n+                                   })\n+                                   .collect();\n+\n+        let i8p_ty = Type::i8p_llcx(llvm_module.llcx);\n+        for val in exported {\n+            let name = CStr::from_ptr(llvm::LLVMGetValueName(val));\n+            let mut imp_name = prefix.as_bytes().to_vec();\n+            imp_name.extend(name.to_bytes());\n+            let imp_name = CString::new(imp_name).unwrap();\n+            let imp = llvm::LLVMAddGlobal(llvm_module.llmod,\n+                                          i8p_ty.to_ref(),\n+                                          imp_name.as_ptr() as *const _);\n+            let init = llvm::LLVMConstBitCast(val, i8p_ty.to_ref());\n+            llvm::LLVMSetInitializer(imp, init);\n+            llvm::LLVMRustSetLinkage(imp, llvm::Linkage::ExternalLinkage);\n         }\n     }\n }\n@@ -920,27 +931,26 @@ pub fn find_exported_symbols(tcx: TyCtxt, reachable: &NodeSet) -> NodeSet {\n \n pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                              analysis: ty::CrateAnalysis,\n-                             incremental_hashes_map: &IncrementalHashesMap,\n+                             incremental_hashes_map: IncrementalHashesMap,\n                              output_filenames: &OutputFilenames)\n-                             -> CrateTranslation {\n+                             -> OngoingCrateTranslation {\n+    check_for_rustc_errors_attr(tcx);\n+\n     // Be careful with this krate: obviously it gives access to the\n     // entire contents of the krate. So if you push any subtasks of\n     // `TransCrate`, you need to be careful to register \"reads\" of the\n     // particular items that will be processed.\n     let krate = tcx.hir.krate();\n-\n     let ty::CrateAnalysis { reachable, .. } = analysis;\n-\n     let check_overflow = tcx.sess.overflow_checks();\n-\n-    let link_meta = link::build_link_meta(incremental_hashes_map);\n-\n+    let link_meta = link::build_link_meta(&incremental_hashes_map);\n     let exported_symbol_node_ids = find_exported_symbols(tcx, &reachable);\n+\n     let shared_ccx = SharedCrateContext::new(tcx,\n                                              check_overflow,\n                                              output_filenames);\n     // Translate the metadata.\n-    let (metadata_llcx, metadata_llmod, metadata) =\n+    let (metadata_llcx, metadata_llmod, metadata, metadata_incr_hashes) =\n         time(tcx.sess.time_passes(), \"write metadata\", || {\n             write_metadata(tcx, &link_meta, &exported_symbol_node_ids)\n         });\n@@ -952,27 +962,44 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n             llcx: metadata_llcx,\n             llmod: metadata_llmod,\n         }),\n+        kind: ModuleKind::Metadata,\n     };\n \n     let no_builtins = attr::contains_name(&krate.attrs, \"no_builtins\");\n+    let time_graph = if tcx.sess.opts.debugging_opts.trans_time_graph {\n+        Some(time_graph::TimeGraph::new())\n+    } else {\n+        None\n+    };\n \n     // Skip crate items and just output metadata in -Z no-trans mode.\n     if tcx.sess.opts.debugging_opts.no_trans ||\n        !tcx.sess.opts.output_types.should_trans() {\n         let empty_exported_symbols = ExportedSymbols::empty();\n         let linker_info = LinkerInfo::new(&shared_ccx, &empty_exported_symbols);\n-        return CrateTranslation {\n-            crate_name: tcx.crate_name(LOCAL_CRATE),\n-            modules: vec![],\n-            metadata_module: metadata_module,\n-            allocator_module: None,\n-            link: link_meta,\n-            metadata: metadata,\n-            exported_symbols: empty_exported_symbols,\n-            no_builtins: no_builtins,\n-            linker_info: linker_info,\n-            windows_subsystem: None,\n-        };\n+        let ongoing_translation = write::start_async_translation(\n+            tcx.sess,\n+            output_filenames,\n+            time_graph.clone(),\n+            tcx.crate_name(LOCAL_CRATE),\n+            link_meta,\n+            metadata,\n+            Arc::new(empty_exported_symbols),\n+            no_builtins,\n+            None,\n+            linker_info,\n+            false);\n+\n+        ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess, metadata_module, true);\n+\n+        assert_and_save_dep_graph(tcx,\n+                                  incremental_hashes_map,\n+                                  metadata_incr_hashes,\n+                                  link_meta);\n+\n+        ongoing_translation.check_for_errors(tcx.sess);\n+\n+        return ongoing_translation;\n     }\n \n     let exported_symbols = Arc::new(ExportedSymbols::compute(tcx,\n@@ -983,12 +1010,110 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     let (translation_items, codegen_units) =\n         collect_and_partition_translation_items(&shared_ccx, &exported_symbols);\n \n+    assert!(codegen_units.len() <= 1 || !tcx.sess.lto());\n+\n+    let linker_info = LinkerInfo::new(&shared_ccx, &exported_symbols);\n+    let subsystem = attr::first_attr_value_str_by_name(&krate.attrs,\n+                                                       \"windows_subsystem\");\n+    let windows_subsystem = subsystem.map(|subsystem| {\n+        if subsystem != \"windows\" && subsystem != \"console\" {\n+            tcx.sess.fatal(&format!(\"invalid windows subsystem `{}`, only \\\n+                                     `windows` and `console` are allowed\",\n+                                    subsystem));\n+        }\n+        subsystem.to_string()\n+    });\n+\n+    let no_integrated_as = tcx.sess.opts.cg.no_integrated_as ||\n+        (tcx.sess.target.target.options.no_integrated_as &&\n+         (output_filenames.outputs.contains_key(&OutputType::Object) ||\n+          output_filenames.outputs.contains_key(&OutputType::Exe)));\n+\n+    let ongoing_translation = write::start_async_translation(\n+        tcx.sess,\n+        output_filenames,\n+        time_graph.clone(),\n+        tcx.crate_name(LOCAL_CRATE),\n+        link_meta,\n+        metadata,\n+        exported_symbols.clone(),\n+        no_builtins,\n+        windows_subsystem,\n+        linker_info,\n+        no_integrated_as);\n+\n+    // Translate an allocator shim, if any\n+    //\n+    // If LTO is enabled and we've got some previous LLVM module we translated\n+    // above, then we can just translate directly into that LLVM module. If not,\n+    // however, we need to create a separate module and trans into that. Note\n+    // that the separate translation is critical for the standard library where\n+    // the rlib's object file doesn't have allocator functions but the dylib\n+    // links in an object file that has allocator functions. When we're\n+    // compiling a final LTO artifact, though, there's no need to worry about\n+    // this as we're not working with this dual \"rlib/dylib\" functionality.\n+    let allocator_module = if tcx.sess.lto() {\n+        None\n+    } else if let Some(kind) = tcx.sess.allocator_kind.get() {\n+        unsafe {\n+            let (llcx, llmod) =\n+                context::create_context_and_module(tcx.sess, \"allocator\");\n+            let modules = ModuleLlvm {\n+                llmod: llmod,\n+                llcx: llcx,\n+            };\n+            time(tcx.sess.time_passes(), \"write allocator module\", || {\n+                allocator::trans(tcx, &modules, kind)\n+            });\n+\n+            Some(ModuleTranslation {\n+                name: link::ALLOCATOR_MODULE_NAME.to_string(),\n+                symbol_name_hash: 0, // we always rebuild allocator shims\n+                source: ModuleSource::Translated(modules),\n+                kind: ModuleKind::Allocator,\n+            })\n+        }\n+    } else {\n+        None\n+    };\n+\n+    if let Some(allocator_module) = allocator_module {\n+        ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess, allocator_module, false);\n+    }\n+\n+    let codegen_unit_count = codegen_units.len();\n+    ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess,\n+                                                             metadata_module,\n+                                                             codegen_unit_count == 0);\n+\n     let translation_items = Arc::new(translation_items);\n \n     let mut all_stats = Stats::default();\n-    let modules: Vec<ModuleTranslation> = codegen_units\n-        .into_iter()\n-        .map(|cgu| {\n+    let mut module_dispositions = tcx.sess.opts.incremental.as_ref().map(|_| Vec::new());\n+\n+    // We sort the codegen units by size. This way we can schedule work for LLVM\n+    // a bit more efficiently. Note that \"size\" is defined rather crudely at the\n+    // moment as it is just the number of TransItems in the CGU, not taking into\n+    // account the size of each TransItem.\n+    let codegen_units = {\n+        let mut codegen_units = codegen_units;\n+        codegen_units.sort_by_key(|cgu| -(cgu.items().len() as isize));\n+        codegen_units\n+    };\n+\n+    let mut total_trans_time = Duration::new(0, 0);\n+\n+    for (cgu_index, cgu) in codegen_units.into_iter().enumerate() {\n+        ongoing_translation.wait_for_signal_to_translate_item();\n+        ongoing_translation.check_for_errors(tcx.sess);\n+\n+        let start_time = Instant::now();\n+\n+        let module = {\n+            let _timing_guard = time_graph\n+                .as_ref()\n+                .map(|time_graph| time_graph.start(write::TRANS_WORKER_TIMELINE,\n+                                                   write::TRANS_WORK_PACKAGE_KIND));\n             let dep_node = cgu.work_product_dep_node();\n             let ((stats, module), _) =\n                 tcx.dep_graph.with_task(dep_node,\n@@ -998,9 +1123,41 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                                             exported_symbols.clone())),\n                                         module_translation);\n             all_stats.extend(stats);\n+\n+            if let Some(ref mut module_dispositions) = module_dispositions {\n+                module_dispositions.push(module.disposition());\n+            }\n+\n             module\n-        })\n-        .collect();\n+        };\n+\n+        let time_to_translate = Instant::now().duration_since(start_time);\n+\n+        // We assume that the cost to run LLVM on a CGU is proportional to\n+        // the time we needed for translating it.\n+        let cost = time_to_translate.as_secs() * 1_000_000_000 +\n+                   time_to_translate.subsec_nanos() as u64;\n+\n+        total_trans_time += time_to_translate;\n+\n+        let is_last_cgu = (cgu_index + 1) == codegen_unit_count;\n+\n+        ongoing_translation.submit_translated_module_to_llvm(tcx.sess,\n+                                                             module,\n+                                                             cost,\n+                                                             is_last_cgu);\n+        ongoing_translation.check_for_errors(tcx.sess);\n+    }\n+\n+    // Since the main thread is sometimes blocked during trans, we keep track\n+    // -Ztime-passes output manually.\n+    print_time_passes_entry(tcx.sess.time_passes(),\n+                            \"translate to LLVM IR\",\n+                            total_trans_time);\n+\n+    if let Some(module_dispositions) = module_dispositions {\n+        assert_module_sources::assert_module_sources(tcx, &module_dispositions);\n+    }\n \n     fn module_translation<'a, 'tcx>(\n         scx: AssertDepGraphSafe<&SharedCrateContext<'a, 'tcx>>,\n@@ -1044,7 +1201,8 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n             let module = ModuleTranslation {\n                 name: cgu_name,\n                 symbol_name_hash,\n-                source: ModuleSource::Preexisting(buf.clone())\n+                source: ModuleSource::Preexisting(buf.clone()),\n+                kind: ModuleKind::Regular,\n             };\n             return (Stats::default(), module);\n         }\n@@ -1099,21 +1257,40 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                 debuginfo::finalize(&ccx);\n             }\n \n+            let llvm_module = ModuleLlvm {\n+                llcx: ccx.llcx(),\n+                llmod: ccx.llmod(),\n+            };\n+\n+            // In LTO mode we inject the allocator shim into the existing\n+            // module.\n+            if ccx.sess().lto() {\n+                if let Some(kind) = ccx.sess().allocator_kind.get() {\n+                    time(ccx.sess().time_passes(), \"write allocator module\", || {\n+                        unsafe {\n+                            allocator::trans(ccx.tcx(), &llvm_module, kind);\n+                        }\n+                    });\n+                }\n+            }\n+\n+            // Adjust exported symbols for MSVC dllimport\n+            if ccx.sess().target.target.options.is_like_msvc &&\n+               ccx.sess().crate_types.borrow().iter().any(|ct| *ct == config::CrateTypeRlib) {\n+                create_imps(ccx.sess(), &llvm_module);\n+            }\n+\n             ModuleTranslation {\n                 name: cgu_name,\n                 symbol_name_hash,\n-                source: ModuleSource::Translated(ModuleLlvm {\n-                    llcx: ccx.llcx(),\n-                    llmod: ccx.llmod(),\n-                })\n+                source: ModuleSource::Translated(llvm_module),\n+                kind: ModuleKind::Regular,\n             }\n         };\n \n         (lcx.into_stats(), module)\n     }\n \n-    assert_module_sources::assert_module_sources(tcx, &modules);\n-\n     symbol_names_test::report_symbol_names(tcx);\n \n     if shared_ccx.sess().trans_stats() {\n@@ -1144,85 +1321,29 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         }\n     }\n \n-    let sess = shared_ccx.sess();\n-\n-    // Get the list of llvm modules we created. We'll do a few wacky\n-    // transforms on them now.\n-\n-    let llvm_modules: Vec<_> =\n-        modules.iter()\n-               .filter_map(|module| match module.source {\n-                   ModuleSource::Translated(llvm) => Some(llvm),\n-                   _ => None,\n-               })\n-               .collect();\n-\n-    if sess.target.target.options.is_like_msvc &&\n-       sess.crate_types.borrow().iter().any(|ct| *ct == config::CrateTypeRlib) {\n-        create_imps(sess, &llvm_modules);\n-    }\n-\n-    // Translate an allocator shim, if any\n-    //\n-    // If LTO is enabled and we've got some previous LLVM module we translated\n-    // above, then we can just translate directly into that LLVM module. If not,\n-    // however, we need to create a separate module and trans into that. Note\n-    // that the separate translation is critical for the standard library where\n-    // the rlib's object file doesn't have allocator functions but the dylib\n-    // links in an object file that has allocator functions. When we're\n-    // compiling a final LTO artifact, though, there's no need to worry about\n-    // this as we're not working with this dual \"rlib/dylib\" functionality.\n-    let allocator_module = tcx.sess.allocator_kind.get().and_then(|kind| unsafe {\n-        if sess.lto() && llvm_modules.len() > 0 {\n-            time(tcx.sess.time_passes(), \"write allocator module\", || {\n-                allocator::trans(tcx, &llvm_modules[0], kind)\n-            });\n-            None\n-        } else {\n-            let (llcx, llmod) =\n-                context::create_context_and_module(tcx.sess, \"allocator\");\n-            let modules = ModuleLlvm {\n-                llmod: llmod,\n-                llcx: llcx,\n-            };\n-            time(tcx.sess.time_passes(), \"write allocator module\", || {\n-                allocator::trans(tcx, &modules, kind)\n-            });\n-\n-            Some(ModuleTranslation {\n-                name: link::ALLOCATOR_MODULE_NAME.to_string(),\n-                symbol_name_hash: 0, // we always rebuild allocator shims\n-                source: ModuleSource::Translated(modules),\n-            })\n-        }\n-    });\n-\n-    let linker_info = LinkerInfo::new(&shared_ccx, &exported_symbols);\n+    ongoing_translation.check_for_errors(tcx.sess);\n \n-    let subsystem = attr::first_attr_value_str_by_name(&krate.attrs,\n-                                                       \"windows_subsystem\");\n-    let windows_subsystem = subsystem.map(|subsystem| {\n-        if subsystem != \"windows\" && subsystem != \"console\" {\n-            tcx.sess.fatal(&format!(\"invalid windows subsystem `{}`, only \\\n-                                     `windows` and `console` are allowed\",\n-                                    subsystem));\n-        }\n-        subsystem.to_string()\n-    });\n+    assert_and_save_dep_graph(tcx,\n+                              incremental_hashes_map,\n+                              metadata_incr_hashes,\n+                              link_meta);\n+    ongoing_translation\n+}\n \n-    CrateTranslation {\n-        crate_name: tcx.crate_name(LOCAL_CRATE),\n-        modules: modules,\n-        metadata_module: metadata_module,\n-        allocator_module: allocator_module,\n-        link: link_meta,\n-        metadata: metadata,\n-        exported_symbols: Arc::try_unwrap(exported_symbols)\n-            .expect(\"There's still a reference to exported_symbols?\"),\n-        no_builtins: no_builtins,\n-        linker_info: linker_info,\n-        windows_subsystem: windows_subsystem,\n-    }\n+fn assert_and_save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                                       incremental_hashes_map: IncrementalHashesMap,\n+                                       metadata_incr_hashes: EncodedMetadataHashes,\n+                                       link_meta: LinkMeta) {\n+    time(tcx.sess.time_passes(),\n+         \"assert dep graph\",\n+         || rustc_incremental::assert_dep_graph(tcx));\n+\n+    time(tcx.sess.time_passes(),\n+         \"serialize dep graph\",\n+         || rustc_incremental::save_dep_graph(tcx,\n+                                              incremental_hashes_map,\n+                                              &metadata_incr_hashes,\n+                                              link_meta.crate_hash));\n }\n \n #[inline(never)] // give this a place in the profiler"}, {"sha": "5a4a5b95cf90a8abbdffca2c6c35b865945ccedb", "filename": "src/librustc_trans/lib.rs", "status": "modified", "additions": 60, "deletions": 7, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Flib.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -36,9 +36,9 @@\n \n use rustc::dep_graph::WorkProduct;\n use syntax_pos::symbol::Symbol;\n+use std::sync::Arc;\n \n extern crate flate2;\n-extern crate crossbeam;\n extern crate libc;\n extern crate owning_ref;\n #[macro_use] extern crate rustc;\n@@ -54,6 +54,7 @@ extern crate rustc_const_math;\n extern crate rustc_bitflags;\n extern crate rustc_demangle;\n extern crate jobserver;\n+extern crate num_cpus;\n \n #[macro_use] extern crate log;\n #[macro_use] extern crate syntax;\n@@ -124,13 +125,13 @@ mod mir;\n mod monomorphize;\n mod partitioning;\n mod symbol_names_test;\n+mod time_graph;\n mod trans_item;\n mod tvec;\n mod type_;\n mod type_of;\n mod value;\n \n-#[derive(Clone)]\n pub struct ModuleTranslation {\n     /// The name of the module. When the crate may be saved between\n     /// compilations, incremental compilation requires that name be\n@@ -140,6 +141,58 @@ pub struct ModuleTranslation {\n     pub name: String,\n     pub symbol_name_hash: u64,\n     pub source: ModuleSource,\n+    pub kind: ModuleKind,\n+}\n+\n+#[derive(Copy, Clone, Debug)]\n+pub enum ModuleKind {\n+    Regular,\n+    Metadata,\n+    Allocator,\n+}\n+\n+impl ModuleTranslation {\n+    pub fn into_compiled_module(self, emit_obj: bool, emit_bc: bool) -> CompiledModule {\n+        let pre_existing = match self.source {\n+            ModuleSource::Preexisting(_) => true,\n+            ModuleSource::Translated(_) => false,\n+        };\n+\n+        CompiledModule {\n+            name: self.name.clone(),\n+            kind: self.kind,\n+            symbol_name_hash: self.symbol_name_hash,\n+            pre_existing,\n+            emit_obj,\n+            emit_bc,\n+        }\n+    }\n+}\n+\n+impl Drop for ModuleTranslation {\n+    fn drop(&mut self) {\n+        match self.source {\n+            ModuleSource::Preexisting(_) => {\n+                // Nothing to dispose.\n+            },\n+            ModuleSource::Translated(llvm) => {\n+                unsafe {\n+                    llvm::LLVMDisposeModule(llvm.llmod);\n+                    llvm::LLVMContextDispose(llvm.llcx);\n+                }\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Debug)]\n+pub struct CompiledModule {\n+    pub name: String,\n+    pub kind: ModuleKind,\n+    pub symbol_name_hash: u64,\n+    pub pre_existing: bool,\n+    pub emit_obj: bool,\n+    pub emit_bc: bool,\n }\n \n #[derive(Clone)]\n@@ -151,7 +204,7 @@ pub enum ModuleSource {\n     Translated(ModuleLlvm),\n }\n \n-#[derive(Copy, Clone)]\n+#[derive(Copy, Clone, Debug)]\n pub struct ModuleLlvm {\n     pub llcx: llvm::ContextRef,\n     pub llmod: llvm::ModuleRef,\n@@ -162,12 +215,12 @@ unsafe impl Sync for ModuleTranslation { }\n \n pub struct CrateTranslation {\n     pub crate_name: Symbol,\n-    pub modules: Vec<ModuleTranslation>,\n-    pub metadata_module: ModuleTranslation,\n-    pub allocator_module: Option<ModuleTranslation>,\n+    pub modules: Vec<CompiledModule>,\n+    pub metadata_module: CompiledModule,\n+    pub allocator_module: Option<CompiledModule>,\n     pub link: rustc::middle::cstore::LinkMeta,\n     pub metadata: rustc::middle::cstore::EncodedMetadata,\n-    pub exported_symbols: back::symbol_export::ExportedSymbols,\n+    pub exported_symbols: Arc<back::symbol_export::ExportedSymbols>,\n     pub no_builtins: bool,\n     pub windows_subsystem: Option<String>,\n     pub linker_info: back::linker::LinkerInfo"}, {"sha": "e0ebe8a0933f128407f5ae79c640d7beb8729a50", "filename": "src/librustc_trans/time_graph.rs", "status": "added", "additions": 181, "deletions": 0, "changes": 181, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Ftime_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Flibrustc_trans%2Ftime_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftime_graph.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -0,0 +1,181 @@\n+// Copyright 2017 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use std::collections::HashMap;\n+use std::marker::PhantomData;\n+use std::sync::{Arc, Mutex};\n+use std::time::Instant;\n+use std::io::prelude::*;\n+use std::fs::File;\n+\n+const OUTPUT_WIDTH_IN_PX: u64 = 1000;\n+const TIME_LINE_HEIGHT_IN_PX: u64 = 7;\n+const TIME_LINE_HEIGHT_STRIDE_IN_PX: usize = 10;\n+\n+#[derive(Clone)]\n+struct Timing {\n+    start: Instant,\n+    end: Instant,\n+    work_package_kind: WorkPackageKind,\n+}\n+\n+#[derive(Clone, Copy, Hash, Eq, PartialEq, Debug)]\n+pub struct TimelineId(pub usize);\n+\n+#[derive(Clone)]\n+struct PerThread {\n+    timings: Vec<Timing>,\n+    open_work_package: Option<(Instant, WorkPackageKind)>,\n+}\n+\n+#[derive(Clone)]\n+pub struct TimeGraph {\n+    data: Arc<Mutex<HashMap<TimelineId, PerThread>>>,\n+}\n+\n+#[derive(Clone, Copy)]\n+pub struct WorkPackageKind(pub &'static [&'static str]);\n+\n+pub struct RaiiToken {\n+    graph: TimeGraph,\n+    timeline: TimelineId,\n+    // The token must not be Send:\n+    _marker: PhantomData<*const ()>\n+}\n+\n+\n+impl Drop for RaiiToken {\n+    fn drop(&mut self) {\n+        self.graph.end(self.timeline);\n+    }\n+}\n+\n+impl TimeGraph {\n+    pub fn new() -> TimeGraph {\n+        TimeGraph {\n+            data: Arc::new(Mutex::new(HashMap::new()))\n+        }\n+    }\n+\n+    pub fn start(&self,\n+                 timeline: TimelineId,\n+                 work_package_kind: WorkPackageKind) -> RaiiToken {\n+        {\n+            let mut table = self.data.lock().unwrap();\n+\n+            let mut data = table.entry(timeline).or_insert(PerThread {\n+                timings: Vec::new(),\n+                open_work_package: None,\n+            });\n+\n+            assert!(data.open_work_package.is_none());\n+            data.open_work_package = Some((Instant::now(), work_package_kind));\n+        }\n+\n+        RaiiToken {\n+            graph: self.clone(),\n+            timeline,\n+            _marker: PhantomData,\n+        }\n+    }\n+\n+    fn end(&self, timeline: TimelineId) {\n+        let end = Instant::now();\n+\n+        let mut table = self.data.lock().unwrap();\n+        let mut data = table.get_mut(&timeline).unwrap();\n+\n+        if let Some((start, work_package_kind)) = data.open_work_package {\n+            data.timings.push(Timing {\n+                start,\n+                end,\n+                work_package_kind,\n+            });\n+        } else {\n+            bug!(\"end timing without start?\")\n+        }\n+\n+        data.open_work_package = None;\n+    }\n+\n+    pub fn dump(&self, output_filename: &str) {\n+        let table = self.data.lock().unwrap();\n+\n+        for data in table.values() {\n+            assert!(data.open_work_package.is_none());\n+        }\n+\n+        let mut timelines: Vec<PerThread> =\n+            table.values().map(|data| data.clone()).collect();\n+\n+        timelines.sort_by_key(|timeline| timeline.timings[0].start);\n+\n+        let earliest_instant = timelines[0].timings[0].start;\n+        let latest_instant = timelines.iter()\n+                                       .map(|timeline| timeline.timings\n+                                                               .last()\n+                                                               .unwrap()\n+                                                               .end)\n+                                       .max()\n+                                       .unwrap();\n+        let max_distance = distance(earliest_instant, latest_instant);\n+\n+        let mut file = File::create(format!(\"{}.html\", output_filename)).unwrap();\n+\n+        writeln!(file, \"<html>\").unwrap();\n+        writeln!(file, \"<head></head>\").unwrap();\n+        writeln!(file, \"<body>\").unwrap();\n+\n+        let mut color = 0;\n+\n+        for (line_index, timeline) in timelines.iter().enumerate() {\n+            let line_top = line_index * TIME_LINE_HEIGHT_STRIDE_IN_PX;\n+\n+            for span in &timeline.timings {\n+                let start = distance(earliest_instant, span.start);\n+                let end = distance(earliest_instant, span.end);\n+\n+                let start = normalize(start, max_distance, OUTPUT_WIDTH_IN_PX);\n+                let end = normalize(end, max_distance, OUTPUT_WIDTH_IN_PX);\n+\n+                let colors = span.work_package_kind.0;\n+\n+                writeln!(file, \"<div style='position:absolute; \\\n+                                            top:{}px; \\\n+                                            left:{}px; \\\n+                                            width:{}px; \\\n+                                            height:{}px; \\\n+                                            background:{};'></div>\",\n+                    line_top,\n+                    start,\n+                    end - start,\n+                    TIME_LINE_HEIGHT_IN_PX,\n+                    colors[color % colors.len()]\n+                    ).unwrap();\n+\n+                color += 1;\n+            }\n+        }\n+\n+        writeln!(file, \"</body>\").unwrap();\n+        writeln!(file, \"</html>\").unwrap();\n+    }\n+}\n+\n+fn distance(zero: Instant, x: Instant) -> u64 {\n+\n+    let duration = x.duration_since(zero);\n+    (duration.as_secs() * 1_000_000_000 + duration.subsec_nanos() as u64) // / div\n+}\n+\n+fn normalize(distance: u64, max: u64, max_pixels: u64) -> u64 {\n+    (max_pixels * distance) / max\n+}\n+"}, {"sha": "7a63871f19e3854460c22b54aac5dbf4f9b51970", "filename": "src/test/run-make/llvm-phase/test.rs", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Ftest%2Frun-make%2Fllvm-phase%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e772c28d2e1a6eb5e4b13980255300b0ee4d774f/src%2Ftest%2Frun-make%2Fllvm-phase%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-make%2Fllvm-phase%2Ftest.rs?ref=e772c28d2e1a6eb5e4b13980255300b0ee4d774f", "patch": "@@ -54,11 +54,7 @@ impl<'a> CompilerCalls<'a> for JitCalls {\n             state.session.abort_if_errors();\n             let trans = state.trans.unwrap();\n             assert_eq!(trans.modules.len(), 1);\n-            let rs_llmod = match trans.modules[0].source {\n-                ModuleSource::Preexisting(_) => unimplemented!(),\n-                ModuleSource::Translated(llvm) => llvm.llmod,\n-            };\n-            unsafe { rustc_llvm::LLVMDumpModule(rs_llmod) };\n+            println!(\"name of compiled module = {}\", trans.modules[0].name);\n         });\n         cc\n     }"}]}