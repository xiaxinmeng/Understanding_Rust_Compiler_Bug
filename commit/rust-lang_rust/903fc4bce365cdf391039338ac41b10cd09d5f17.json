{"sha": "903fc4bce365cdf391039338ac41b10cd09d5f17", "node_id": "MDY6Q29tbWl0NzI0NzEyOjkwM2ZjNGJjZTM2NWNkZjM5MTAzOTMzOGFjNDFiMTBjZDA5ZDVmMTc=", "commit": {"author": {"name": "Mazdak Farrokhzad", "email": "twingoow@gmail.com", "date": "2019-05-09T21:56:13Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-05-09T21:56:13Z"}, "message": "Rollup merge of #60618 - mark-i-m:transcribe, r=petrochenkov\n\nComment ext::tt::transcribe\n\nAlso did a bit of minor cleanup (remove unidiomatic use of `Add` and an unneeded `clone`). No functionality changes.\n\nr? @petrochenkov", "tree": {"sha": "d3bee3cba7ff4042954258e61af00a592132afb0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d3bee3cba7ff4042954258e61af00a592132afb0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/903fc4bce365cdf391039338ac41b10cd09d5f17", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJc1KH9CRBK7hj4Ov3rIwAAdHIIAA4QEq8Sj5rPw2N5Cn61XBHK\n+zuD3iq5Jep2VoCtyHNjI7vRP3RgUOKn3RN+7iFprBL6DumPzQFON+iPMZwXCpEw\nPZi9DHTavDQaw+9jglm66FNEWia8+quPUeo+I6KFNyREgDznHOWCRqELgcEVo0uH\n6lxWXkBd6COGt+ewyd6lCoj+hLZ/FuBE4UpFGByRjhnbccNb9U0kwsEnkuAoxRvR\nMnZA6jmrmCNXynF9xmFg07WLQEUdZV/zzm8nxUW83JSYs2lXTXdZSwkoIZREA1P3\nlMFrPmxFwCCK6OM6D7dreNQ9wTRbH3Y0iZhHCsifHp/gLA0cWypIZUv5NubY9j8=\n=J9td\n-----END PGP SIGNATURE-----\n", "payload": "tree d3bee3cba7ff4042954258e61af00a592132afb0\nparent bd17b5c9a2215cf8be8b2a361976730320a5f00f\nparent eb7d47cba90ac716c84fe720418e58c6eb84ac4e\nauthor Mazdak Farrokhzad <twingoow@gmail.com> 1557438973 +0200\ncommitter GitHub <noreply@github.com> 1557438973 +0200\n\nRollup merge of #60618 - mark-i-m:transcribe, r=petrochenkov\n\nComment ext::tt::transcribe\n\nAlso did a bit of minor cleanup (remove unidiomatic use of `Add` and an unneeded `clone`). No functionality changes.\n\nr? @petrochenkov\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/903fc4bce365cdf391039338ac41b10cd09d5f17", "html_url": "https://github.com/rust-lang/rust/commit/903fc4bce365cdf391039338ac41b10cd09d5f17", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/903fc4bce365cdf391039338ac41b10cd09d5f17/comments", "author": {"login": "Centril", "id": 855702, "node_id": "MDQ6VXNlcjg1NTcwMg==", "avatar_url": "https://avatars.githubusercontent.com/u/855702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Centril", "html_url": "https://github.com/Centril", "followers_url": "https://api.github.com/users/Centril/followers", "following_url": "https://api.github.com/users/Centril/following{/other_user}", "gists_url": "https://api.github.com/users/Centril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Centril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Centril/subscriptions", "organizations_url": "https://api.github.com/users/Centril/orgs", "repos_url": "https://api.github.com/users/Centril/repos", "events_url": "https://api.github.com/users/Centril/events{/privacy}", "received_events_url": "https://api.github.com/users/Centril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bd17b5c9a2215cf8be8b2a361976730320a5f00f", "url": "https://api.github.com/repos/rust-lang/rust/commits/bd17b5c9a2215cf8be8b2a361976730320a5f00f", "html_url": "https://github.com/rust-lang/rust/commit/bd17b5c9a2215cf8be8b2a361976730320a5f00f"}, {"sha": "eb7d47cba90ac716c84fe720418e58c6eb84ac4e", "url": "https://api.github.com/repos/rust-lang/rust/commits/eb7d47cba90ac716c84fe720418e58c6eb84ac4e", "html_url": "https://github.com/rust-lang/rust/commit/eb7d47cba90ac716c84fe720418e58c6eb84ac4e"}], "stats": {"total": 263, "additions": 194, "deletions": 69}, "files": [{"sha": "084a69f4cda0f97b6ec56ae08cbb6b82a348ff12", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/903fc4bce365cdf391039338ac41b10cd09d5f17/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/903fc4bce365cdf391039338ac41b10cd09d5f17/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=903fc4bce365cdf391039338ac41b10cd09d5f17", "patch": "@@ -554,7 +554,10 @@ fn inner_parse_loop<'root, 'tt>(\n             match item.top_elts.get_tt(idx) {\n                 // Need to descend into a sequence\n                 TokenTree::Sequence(sp, seq) => {\n-                    // Examine the case where there are 0 matches of this sequence\n+                    // Examine the case where there are 0 matches of this sequence. We are\n+                    // implicitly disallowing OneOrMore from having 0 matches here. Thus, that will\n+                    // result in a \"no rules expected token\" error by virtue of this matcher not\n+                    // working.\n                     if seq.op == quoted::KleeneOp::ZeroOrMore\n                         || seq.op == quoted::KleeneOp::ZeroOrOne\n                     {"}, {"sha": "a53cc2fe66173ecdce8ce9f25c3eea713f31efc5", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/903fc4bce365cdf391039338ac41b10cd09d5f17/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/903fc4bce365cdf391039338ac41b10cd09d5f17/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=903fc4bce365cdf391039338ac41b10cd09d5f17", "patch": "@@ -151,7 +151,7 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt<'_>,\n \n                 let rhs_spans = rhs.iter().map(|t| t.span()).collect::<Vec<_>>();\n                 // rhs has holes ( `$id` and `$(...)` that need filled)\n-                let mut tts = transcribe(cx, Some(named_matches), rhs);\n+                let mut tts = transcribe(cx, &named_matches, rhs);\n \n                 // Replace all the tokens for the corresponding positions in the macro, to maintain\n                 // proper positions in error reporting, while maintaining the macro_backtrace."}, {"sha": "ed8395f11ad5089c3557ea964ff748e81c280631", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/903fc4bce365cdf391039338ac41b10cd09d5f17/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/903fc4bce365cdf391039338ac41b10cd09d5f17/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=903fc4bce365cdf391039338ac41b10cd09d5f17", "patch": "@@ -73,6 +73,7 @@ pub enum KleeneOp {\n     ZeroOrMore,\n     /// Kleene plus (`+`) for one or more repetitions\n     OneOrMore,\n+    /// Kleene optional (`?`) for zero or one reptitions\n     ZeroOrOne,\n }\n "}, {"sha": "0cefcf1ce034b7603c690a43087a79d65fd49a21", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 188, "deletions": 67, "changes": 255, "blob_url": "https://github.com/rust-lang/rust/blob/903fc4bce365cdf391039338ac41b10cd09d5f17/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/903fc4bce365cdf391039338ac41b10cd09d5f17/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=903fc4bce365cdf391039338ac41b10cd09d5f17", "patch": "@@ -1,10 +1,10 @@\n use crate::ast::Ident;\n use crate::ext::base::ExtCtxt;\n use crate::ext::expand::Marker;\n-use crate::ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n+use crate::ext::tt::macro_parser::{MatchedNonterminal, MatchedSeq, NamedMatch};\n use crate::ext::tt::quoted;\n use crate::mut_visit::noop_visit_tt;\n-use crate::parse::token::{self, Token, NtTT};\n+use crate::parse::token::{self, NtTT, Token};\n use crate::tokenstream::{DelimSpan, TokenStream, TokenTree, TreeAndJoint};\n \n use smallvec::{smallvec, SmallVec};\n@@ -13,24 +13,16 @@ use syntax_pos::DUMMY_SP;\n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sync::Lrc;\n use std::mem;\n-use std::ops::Add;\n use std::rc::Rc;\n \n-// An iterator over the token trees in a delimited token tree (`{ ... }`) or a sequence (`$(...)`).\n+/// An iterator over the token trees in a delimited token tree (`{ ... }`) or a sequence (`$(...)`).\n enum Frame {\n-    Delimited {\n-        forest: Lrc<quoted::Delimited>,\n-        idx: usize,\n-        span: DelimSpan,\n-    },\n-    Sequence {\n-        forest: Lrc<quoted::SequenceRepetition>,\n-        idx: usize,\n-        sep: Option<Token>,\n-    },\n+    Delimited { forest: Lrc<quoted::Delimited>, idx: usize, span: DelimSpan },\n+    Sequence { forest: Lrc<quoted::SequenceRepetition>, idx: usize, sep: Option<Token> },\n }\n \n impl Frame {\n+    /// Construct a new frame around the delimited set of tokens.\n     fn new(tts: Vec<quoted::TokenTree>) -> Frame {\n         let forest = Lrc::new(quoted::Delimited { delim: token::NoDelim, tts: tts });\n         Frame::Delimited { forest: forest, idx: 0, span: DelimSpan::dummy() }\n@@ -54,84 +46,161 @@ impl Iterator for Frame {\n     }\n }\n \n-/// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TokenTree::{Sequence, MetaVar, MetaVarDecl}`s, `interp` can\n-/// (and should) be None.\n-pub fn transcribe(cx: &ExtCtxt<'_>,\n-                  interp: Option<FxHashMap<Ident, Rc<NamedMatch>>>,\n-                  src: Vec<quoted::TokenTree>)\n-                  -> TokenStream {\n+/// This can do Macro-By-Example transcription.\n+/// - `interp` is a map of meta-variables to the tokens (non-terminals) they matched in the\n+///   invocation. We are assuming we already know there is a match.\n+/// - `src` is the RHS of the MBE, that is, the \"example\" we are filling in.\n+///\n+/// For example,\n+///\n+/// ```rust\n+/// macro_rules! foo {\n+///     ($id:ident) => { println!(\"{}\", stringify!($id)); }\n+/// }\n+///\n+/// foo!(bar);\n+/// ```\n+///\n+/// `interp` would contain `$id => bar` and `src` would contain `println!(\"{}\", stringify!($id));`.\n+///\n+/// `transcribe` would return a `TokenStream` containing `println!(\"{}\", stringify!(bar));`.\n+///\n+/// Along the way, we do some additional error checking.\n+pub fn transcribe(\n+    cx: &ExtCtxt<'_>,\n+    interp: &FxHashMap<Ident, Rc<NamedMatch>>,\n+    src: Vec<quoted::TokenTree>,\n+) -> TokenStream {\n+    // Nothing for us to transcribe...\n+    if src.is_empty() {\n+        return TokenStream::empty();\n+    }\n+\n+    // We descend into the RHS (`src`), expanding things as we go. This stack contains the things\n+    // we have yet to expand/are still expanding. We start the stack off with the whole RHS.\n     let mut stack: SmallVec<[Frame; 1]> = smallvec![Frame::new(src)];\n-    let interpolations = interp.unwrap_or_else(FxHashMap::default); /* just a convenience */\n+\n+    // As we descend in the RHS, we will need to be able to match nested sequences of matchers.\n+    // `repeats` keeps track of where we are in matching at each level, with the last element being\n+    // the most deeply nested sequence. This is used as a stack.\n     let mut repeats = Vec::new();\n+\n+    // `result` contains resulting token stream from the TokenTree we just finished processing. At\n+    // the end, this will contain the full result of transcription, but at arbitrary points during\n+    // `transcribe`, `result` will contain subsets of the final result.\n+    //\n+    // Specifically, as we descend into each TokenTree, we will push the existing results onto the\n+    // `result_stack` and clear `results`. We will then produce the results of transcribing the\n+    // TokenTree into `results`. Then, as we unwind back out of the `TokenTree`, we will pop the\n+    // `result_stack` and append `results` too it to produce the new `results` up to that point.\n+    //\n+    // Thus, if we try to pop the `result_stack` and it is empty, we have reached the top-level\n+    // again, and we are done transcribing.\n     let mut result: Vec<TreeAndJoint> = Vec::new();\n     let mut result_stack = Vec::new();\n \n     loop {\n+        // Look at the last frame on the stack.\n         let tree = if let Some(tree) = stack.last_mut().unwrap().next() {\n+            // If it still has a TokenTree we have not looked at yet, use that tree.\n             tree\n-        } else {\n+        }\n+        // The else-case never produces a value for `tree` (it `continue`s or `return`s).\n+        else {\n+            // Otherwise, if we have just reached the end of a sequence and we can keep repeating,\n+            // go back to the beginning of the sequence.\n             if let Frame::Sequence { ref mut idx, ref sep, .. } = *stack.last_mut().unwrap() {\n                 let (ref mut repeat_idx, repeat_len) = *repeats.last_mut().unwrap();\n                 *repeat_idx += 1;\n                 if *repeat_idx < repeat_len {\n                     *idx = 0;\n                     if let Some(sep) = sep.clone() {\n-                        // repeat same span, I guess\n                         let prev_span = match result.last() {\n                             Some((tt, _)) => tt.span(),\n                             None => DUMMY_SP,\n                         };\n                         result.push(TokenTree::Token(prev_span, sep).into());\n                     }\n-                    continue\n+                    continue;\n                 }\n             }\n \n+            // We are done with the top of the stack. Pop it. Depending on what it was, we do\n+            // different things. Note that the outermost item must be the delimited, wrapped RHS\n+            // that was passed in originally to `transcribe`.\n             match stack.pop().unwrap() {\n+                // Done with a sequence. Pop from repeats.\n                 Frame::Sequence { .. } => {\n                     repeats.pop();\n                 }\n+\n+                // We are done processing a Delimited. If this is the top-level delimited, we are\n+                // done. Otherwise, we unwind the result_stack to append what we have produced to\n+                // any previous results.\n                 Frame::Delimited { forest, span, .. } => {\n                     if result_stack.is_empty() {\n+                        // No results left to compute! We are back at the top-level.\n                         return TokenStream::new(result);\n                     }\n-                    let tree = TokenTree::Delimited(\n-                        span,\n-                        forest.delim,\n-                        TokenStream::new(result).into(),\n-                    );\n+\n+                    // Step back into the parent Delimited.\n+                    let tree =\n+                        TokenTree::Delimited(span, forest.delim, TokenStream::new(result).into());\n                     result = result_stack.pop().unwrap();\n                     result.push(tree.into());\n                 }\n             }\n-            continue\n+            continue;\n         };\n \n+        // At this point, we know we are in the middle of a TokenTree (the last one on `stack`).\n+        // `tree` contains the next `TokenTree` to be processed.\n         match tree {\n-            quoted::TokenTree::Sequence(sp, seq) => {\n-                // FIXME(pcwalton): Bad copy.\n-                match lockstep_iter_size(&quoted::TokenTree::Sequence(sp, seq.clone()),\n-                                         &interpolations,\n-                                         &repeats) {\n+            // We are descending into a sequence. We first make sure that the matchers in the RHS\n+            // and the matches in `interp` have the same shape. Otherwise, either the caller or the\n+            // macro writer has made a mistake.\n+            seq @ quoted::TokenTree::Sequence(..) => {\n+                match lockstep_iter_size(&seq, interp, &repeats) {\n                     LockstepIterSize::Unconstrained => {\n-                        cx.span_fatal(sp.entire(), /* blame macro writer */\n-                            \"attempted to repeat an expression \\\n-                             containing no syntax \\\n-                             variables matched as repeating at this depth\");\n+                        cx.span_fatal(\n+                            seq.span(), /* blame macro writer */\n+                            \"attempted to repeat an expression containing no syntax variables \\\n+                             matched as repeating at this depth\",\n+                        );\n                     }\n+\n                     LockstepIterSize::Contradiction(ref msg) => {\n+                        // FIXME: this should be impossible. I (mark-i-m) believe it would\n+                        // represent a bug in the macro_parser.\n                         // FIXME #2887 blame macro invoker instead\n-                        cx.span_fatal(sp.entire(), &msg[..]);\n+                        cx.span_fatal(seq.span(), &msg[..]);\n                     }\n+\n                     LockstepIterSize::Constraint(len, _) => {\n+                        // We do this to avoid an extra clone above. We know that this is a\n+                        // sequence already.\n+                        let (sp, seq) = if let quoted::TokenTree::Sequence(sp, seq) = seq {\n+                            (sp, seq)\n+                        } else {\n+                            unreachable!()\n+                        };\n+\n+                        // Is the repetition empty?\n                         if len == 0 {\n                             if seq.op == quoted::KleeneOp::OneOrMore {\n+                                // FIXME: this should be impossible because we check for this in\n+                                // macro_parser.rs\n                                 // FIXME #2887 blame invoker\n                                 cx.span_fatal(sp.entire(), \"this must repeat at least once\");\n                             }\n                         } else {\n+                            // 0 is the initial counter (we have done 0 repretitions so far). `len`\n+                            //   is the total number of reptitions we should generate.\n                             repeats.push((0, len));\n+\n+                            // The first time we encounter the sequence we push it to the stack. It\n+                            // then gets reused (see the beginning of the loop) until we are done\n+                            // repeating.\n                             stack.push(Frame::Sequence {\n                                 idx: 0,\n                                 sep: seq.separator.clone(),\n@@ -141,10 +210,16 @@ pub fn transcribe(cx: &ExtCtxt<'_>,\n                     }\n                 }\n             }\n-            // FIXME #2887: think about span stuff here\n+\n+            // Replace the meta-var with the matched token tree from the invocation.\n             quoted::TokenTree::MetaVar(mut sp, ident) => {\n-                if let Some(cur_matched) = lookup_cur_matched(ident, &interpolations, &repeats) {\n+                // Find the matched nonterminal from the macro invocation, and use it to replace\n+                // the meta-var.\n+                if let Some(cur_matched) = lookup_cur_matched(ident, interp, &repeats) {\n                     if let MatchedNonterminal(ref nt) = *cur_matched {\n+                        // FIXME #2887: why do we apply a mark when matching a token tree meta-var\n+                        // (e.g. `$x:tt`), but not when we are matching any other type of token\n+                        // tree?\n                         if let NtTT(ref tt) = **nt {\n                             result.push(tt.clone().into());\n                         } else {\n@@ -153,37 +228,60 @@ pub fn transcribe(cx: &ExtCtxt<'_>,\n                             result.push(token.into());\n                         }\n                     } else {\n-                        cx.span_fatal(sp, /* blame the macro writer */\n-                            &format!(\"variable '{}' is still repeating at this depth\", ident));\n+                        // We were unable to descend far enough. This is an error.\n+                        cx.span_fatal(\n+                            sp, /* blame the macro writer */\n+                            &format!(\"variable '{}' is still repeating at this depth\", ident),\n+                        );\n                     }\n                 } else {\n+                    // If we aren't able to match the meta-var, we push it back into the result but\n+                    // with modified syntax context. (I believe this supports nested macros).\n                     let ident =\n                         Ident::new(ident.name, ident.span.apply_mark(cx.current_expansion.mark));\n                     sp = sp.apply_mark(cx.current_expansion.mark);\n                     result.push(TokenTree::Token(sp, token::Dollar).into());\n                     result.push(TokenTree::Token(sp, token::Token::from_ast_ident(ident)).into());\n                 }\n             }\n+\n+            // If we are entering a new delimiter, we push its contents to the `stack` to be\n+            // processed, and we push all of the currently produced results to the `result_stack`.\n+            // We will produce all of the results of the inside of the `Delimited` and then we will\n+            // jump back out of the Delimited, pop the result_stack and add the new results back to\n+            // the previous results (from outside the Delimited).\n             quoted::TokenTree::Delimited(mut span, delimited) => {\n                 span = span.apply_mark(cx.current_expansion.mark);\n                 stack.push(Frame::Delimited { forest: delimited, idx: 0, span: span });\n                 result_stack.push(mem::replace(&mut result, Vec::new()));\n             }\n+\n+            // Nothing much to do here. Just push the token to the result, being careful to\n+            // preserve syntax context.\n             quoted::TokenTree::Token(sp, tok) => {\n                 let mut marker = Marker(cx.current_expansion.mark);\n                 let mut tt = TokenTree::Token(sp, tok);\n                 noop_visit_tt(&mut tt, &mut marker);\n                 result.push(tt.into());\n             }\n+\n+            // There should be no meta-var declarations in the invocation of a macro.\n             quoted::TokenTree::MetaVarDecl(..) => panic!(\"unexpected `TokenTree::MetaVarDecl\"),\n         }\n     }\n }\n \n-fn lookup_cur_matched(ident: Ident,\n-                      interpolations: &FxHashMap<Ident, Rc<NamedMatch>>,\n-                      repeats: &[(usize, usize)])\n-                      -> Option<Rc<NamedMatch>> {\n+/// Lookup the meta-var named `ident` and return the matched token tree from the invocation using\n+/// the set of matches `interpolations`.\n+///\n+/// See the definition of `repeats` in the `transcribe` function. `repeats` is used to descend\n+/// into the right place in nested matchers. If we attempt to descend too far, the macro writer has\n+/// made a mistake, and we return `None`.\n+fn lookup_cur_matched(\n+    ident: Ident,\n+    interpolations: &FxHashMap<Ident, Rc<NamedMatch>>,\n+    repeats: &[(usize, usize)],\n+) -> Option<Rc<NamedMatch>> {\n     interpolations.get(&ident).map(|matched| {\n         let mut matched = matched.clone();\n         for &(idx, _) in repeats {\n@@ -198,17 +296,30 @@ fn lookup_cur_matched(ident: Ident,\n     })\n }\n \n+/// An accumulator over a TokenTree to be used with `fold`. During transcription, we need to make\n+/// sure that the size of each sequence and all of its nested sequences are the same as the sizes\n+/// of all the matched (nested) sequences in the macro invocation. If they don't match, somebody\n+/// has made a mistake (either the macro writer or caller).\n #[derive(Clone)]\n enum LockstepIterSize {\n+    /// No constraints on length of matcher. This is true for any TokenTree variants except a\n+    /// `MetaVar` with an actual `MatchedSeq` (as opposed to a `MatchedNonterminal`).\n     Unconstrained,\n+\n+    /// A `MetaVar` with an actual `MatchedSeq`. The length of the match and the name of the\n+    /// meta-var are returned.\n     Constraint(usize, Ident),\n+\n+    /// Two `Constraint`s on the same sequence had different lengths. This is an error.\n     Contradiction(String),\n }\n \n-impl Add for LockstepIterSize {\n-    type Output = LockstepIterSize;\n-\n-    fn add(self, other: LockstepIterSize) -> LockstepIterSize {\n+impl LockstepIterSize {\n+    /// Find incompatibilities in matcher/invocation sizes.\n+    /// - `Unconstrained` is compatible with everything.\n+    /// - `Contradiction` is incompatible with everything.\n+    /// - `Constraint(len)` is only compatible with other constraints of the same length.\n+    fn with(self, other: LockstepIterSize) -> LockstepIterSize {\n         match self {\n             LockstepIterSize::Unconstrained => other,\n             LockstepIterSize::Contradiction(_) => self,\n@@ -217,40 +328,50 @@ impl Add for LockstepIterSize {\n                 LockstepIterSize::Contradiction(_) => other,\n                 LockstepIterSize::Constraint(r_len, _) if l_len == r_len => self,\n                 LockstepIterSize::Constraint(r_len, r_id) => {\n-                    let msg = format!(\"inconsistent lockstep iteration: \\\n-                                       '{}' has {} items, but '{}' has {}\",\n-                                      l_id, l_len, r_id, r_len);\n+                    let msg = format!(\n+                        \"inconsistent lockstep iteration: \\\n+                         '{}' has {} items, but '{}' has {}\",\n+                        l_id, l_len, r_id, r_len\n+                    );\n                     LockstepIterSize::Contradiction(msg)\n                 }\n             },\n         }\n     }\n }\n \n-fn lockstep_iter_size(tree: &quoted::TokenTree,\n-                      interpolations: &FxHashMap<Ident, Rc<NamedMatch>>,\n-                      repeats: &[(usize, usize)])\n-                      -> LockstepIterSize {\n+/// Given a `tree`, make sure that all sequences have the same length as the matches for the\n+/// appropriate meta-vars in `interpolations`.\n+///\n+/// Note that if `repeats` does not match the exact correct depth of a meta-var,\n+/// `lookup_cur_matched` will return `None`, which is why this still works even in the presnece of\n+/// multiple nested matcher sequences.\n+fn lockstep_iter_size(\n+    tree: &quoted::TokenTree,\n+    interpolations: &FxHashMap<Ident, Rc<NamedMatch>>,\n+    repeats: &[(usize, usize)],\n+) -> LockstepIterSize {\n     use quoted::TokenTree;\n     match *tree {\n         TokenTree::Delimited(_, ref delimed) => {\n             delimed.tts.iter().fold(LockstepIterSize::Unconstrained, |size, tt| {\n-                size + lockstep_iter_size(tt, interpolations, repeats)\n+                size.with(lockstep_iter_size(tt, interpolations, repeats))\n             })\n-        },\n+        }\n         TokenTree::Sequence(_, ref seq) => {\n             seq.tts.iter().fold(LockstepIterSize::Unconstrained, |size, tt| {\n-                size + lockstep_iter_size(tt, interpolations, repeats)\n+                size.with(lockstep_iter_size(tt, interpolations, repeats))\n             })\n-        },\n-        TokenTree::MetaVar(_, name) | TokenTree::MetaVarDecl(_, name, _) =>\n+        }\n+        TokenTree::MetaVar(_, name) | TokenTree::MetaVarDecl(_, name, _) => {\n             match lookup_cur_matched(name, interpolations, repeats) {\n                 Some(matched) => match *matched {\n                     MatchedNonterminal(_) => LockstepIterSize::Unconstrained,\n                     MatchedSeq(ref ads, _) => LockstepIterSize::Constraint(ads.len(), name),\n                 },\n-                _ => LockstepIterSize::Unconstrained\n-            },\n+                _ => LockstepIterSize::Unconstrained,\n+            }\n+        }\n         TokenTree::Token(..) => LockstepIterSize::Unconstrained,\n     }\n }"}]}