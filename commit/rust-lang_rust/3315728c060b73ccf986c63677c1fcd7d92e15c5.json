{"sha": "3315728c060b73ccf986c63677c1fcd7d92e15c5", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMzMTU3MjhjMDYwYjczY2NmOTg2YzYzNjc3YzFmY2Q3ZDkyZTE1YzU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-02-09T20:15:57Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-02-09T20:15:57Z"}, "message": "Auto merge of #57944 - estebank:unclosed-delim-the-quickening, r=oli-obk\n\nDeduplicate mismatched delimiter errors\n\nDelay unmatched delimiter errors until after the parser has run to deduplicate them when parsing and attempt recovering intelligently.\n\nSecond attempt at #54029, follow up to #53949. Fix #31528.", "tree": {"sha": "9abeb03a99a73ce7c4029ddaa0d9696ec220dcbb", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9abeb03a99a73ce7c4029ddaa0d9696ec220dcbb"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3315728c060b73ccf986c63677c1fcd7d92e15c5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3315728c060b73ccf986c63677c1fcd7d92e15c5", "html_url": "https://github.com/rust-lang/rust/commit/3315728c060b73ccf986c63677c1fcd7d92e15c5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3315728c060b73ccf986c63677c1fcd7d92e15c5/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4c9233cdebe3d9a46c641a9c608792379490bc45", "url": "https://api.github.com/repos/rust-lang/rust/commits/4c9233cdebe3d9a46c641a9c608792379490bc45", "html_url": "https://github.com/rust-lang/rust/commit/4c9233cdebe3d9a46c641a9c608792379490bc45"}, {"sha": "fb3c4fbfc33b77b7beeeaf4a749a2081a8bfbc2f", "url": "https://api.github.com/repos/rust-lang/rust/commits/fb3c4fbfc33b77b7beeeaf4a749a2081a8bfbc2f", "html_url": "https://github.com/rust-lang/rust/commit/fb3c4fbfc33b77b7beeeaf4a749a2081a8bfbc2f"}], "stats": {"total": 489, "additions": 332, "deletions": 157}, "files": [{"sha": "2821201173ea095b22afe104ac65c0162c1912bd", "filename": "src/librustc_errors/emitter.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibrustc_errors%2Femitter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibrustc_errors%2Femitter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_errors%2Femitter.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -672,8 +672,8 @@ impl EmitterWriter {\n         //   | |  something about `foo`\n         //   | something about `fn foo()`\n         annotations_position.sort_by(|a, b| {\n-            // Decreasing order\n-            a.1.len().cmp(&b.1.len()).reverse()\n+            // Decreasing order. When `a` and `b` are the same length, prefer `Primary`.\n+            (a.1.len(), !a.1.is_primary).cmp(&(b.1.len(), !b.1.is_primary)).reverse()\n         });\n \n         // Write the underlines."}, {"sha": "b248c6bf6565a29d09d89e59a571efbbb20c03db", "filename": "src/librustc_metadata/cstore_impl.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibrustc_metadata%2Fcstore_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibrustc_metadata%2Fcstore_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcstore_impl.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -29,6 +29,7 @@ use syntax::attr;\n use syntax::source_map;\n use syntax::edition::Edition;\n use syntax::parse::source_file_to_stream;\n+use syntax::parse::parser::emit_unclosed_delims;\n use syntax::symbol::Symbol;\n use syntax_pos::{Span, NO_EXPANSION, FileName};\n use rustc_data_structures::bit_set::BitSet;\n@@ -436,7 +437,8 @@ impl cstore::CStore {\n \n         let source_file = sess.parse_sess.source_map().new_source_file(source_name, def.body);\n         let local_span = Span::new(source_file.start_pos, source_file.end_pos, NO_EXPANSION);\n-        let body = source_file_to_stream(&sess.parse_sess, source_file, None);\n+        let (body, errors) = source_file_to_stream(&sess.parse_sess, source_file, None);\n+        emit_unclosed_delims(&errors, &sess.diagnostic());\n \n         // Mark the attrs as used\n         let attrs = data.get_item_attrs(id.index, sess);"}, {"sha": "d3fc1c03634eaad45435bb63692c6bceb825e74a", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -33,6 +33,15 @@ impl Default for TokenAndSpan {\n     }\n }\n \n+#[derive(Clone, Debug)]\n+pub struct UnmatchedBrace {\n+    pub expected_delim: token::DelimToken,\n+    pub found_delim: token::DelimToken,\n+    pub found_span: Span,\n+    pub unclosed_span: Option<Span>,\n+    pub candidate_span: Option<Span>,\n+}\n+\n pub struct StringReader<'a> {\n     pub sess: &'a ParseSess,\n     /// The absolute offset within the source_map of the next character to read\n@@ -58,6 +67,7 @@ pub struct StringReader<'a> {\n     span_src_raw: Span,\n     /// Stack of open delimiters and their spans. Used for error message.\n     open_braces: Vec<(token::DelimToken, Span)>,\n+    crate unmatched_braces: Vec<UnmatchedBrace>,\n     /// The type and spans for all braces\n     ///\n     /// Used only for error recovery when arriving to EOF with mismatched braces.\n@@ -222,6 +232,7 @@ impl<'a> StringReader<'a> {\n             span: syntax_pos::DUMMY_SP,\n             span_src_raw: syntax_pos::DUMMY_SP,\n             open_braces: Vec::new(),\n+            unmatched_braces: Vec::new(),\n             matching_delim_spans: Vec::new(),\n             override_span,\n             last_unclosed_found_span: None,"}, {"sha": "0db36c84cdfeb532bfe7b3f7d0c033a4300d1c59", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -1,5 +1,5 @@\n use crate::print::pprust::token_to_string;\n-use crate::parse::lexer::StringReader;\n+use crate::parse::lexer::{StringReader, UnmatchedBrace};\n use crate::parse::{token, PResult};\n use crate::tokenstream::{DelimSpan, IsJoint::*, TokenStream, TokenTree, TreeAndJoint};\n \n@@ -101,38 +101,38 @@ impl<'a> StringReader<'a> {\n                     }\n                     // Incorrect delimiter.\n                     token::CloseDelim(other) => {\n-                        let token_str = token_to_string(&self.token);\n+                        let mut unclosed_delimiter = None;\n+                        let mut candidate = None;\n                         if self.last_unclosed_found_span != Some(self.span) {\n                             // do not complain about the same unclosed delimiter multiple times\n                             self.last_unclosed_found_span = Some(self.span);\n-                            let msg = format!(\"incorrect close delimiter: `{}`\", token_str);\n-                            let mut err = self.sess.span_diagnostic.struct_span_err(\n-                                self.span,\n-                                &msg,\n-                            );\n-                            err.span_label(self.span, \"incorrect close delimiter\");\n                             // This is a conservative error: only report the last unclosed\n                             // delimiter. The previous unclosed delimiters could actually be\n                             // closed! The parser just hasn't gotten to them yet.\n                             if let Some(&(_, sp)) = self.open_braces.last() {\n-                                err.span_label(sp, \"un-closed delimiter\");\n+                                unclosed_delimiter = Some(sp);\n                             };\n                             if let Some(current_padding) = sm.span_to_margin(self.span) {\n                                 for (brace, brace_span) in &self.open_braces {\n                                     if let Some(padding) = sm.span_to_margin(*brace_span) {\n                                         // high likelihood of these two corresponding\n                                         if current_padding == padding && brace == &other {\n-                                            err.span_label(\n-                                                *brace_span,\n-                                                \"close delimiter possibly meant for this\",\n-                                            );\n+                                            candidate = Some(*brace_span);\n                                         }\n                                     }\n                                 }\n                             }\n-                            err.emit();\n+                            let (tok, _) = self.open_braces.pop().unwrap();\n+                            self.unmatched_braces.push(UnmatchedBrace {\n+                                expected_delim: tok,\n+                                found_delim: other,\n+                                found_span: self.span,\n+                                unclosed_span: unclosed_delimiter,\n+                                candidate_span: candidate,\n+                            });\n+                        } else {\n+                            self.open_braces.pop();\n                         }\n-                        self.open_braces.pop().unwrap();\n \n                         // If the incorrect delimiter matches an earlier opening\n                         // delimiter, then don't consume it (it can be used to"}, {"sha": "317d69332078687460da9cae9243bac8eff3a954", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 41, "deletions": 17, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -9,6 +9,7 @@ use crate::parse::parser::Parser;\n use crate::symbol::Symbol;\n use crate::tokenstream::{TokenStream, TokenTree};\n use crate::diagnostics::plugin::ErrorMap;\n+use crate::print::pprust::token_to_string;\n \n use rustc_data_structures::sync::{Lrc, Lock};\n use syntax_pos::{Span, SourceFile, FileName, MultiSpan};\n@@ -136,15 +137,17 @@ pub fn parse_crate_attrs_from_source_str(name: FileName, source: String, sess: &\n     new_parser_from_source_str(sess, name, source).parse_inner_attributes()\n }\n \n-pub fn parse_stream_from_source_str(name: FileName, source: String, sess: &ParseSess,\n-                                    override_span: Option<Span>)\n-                                    -> TokenStream {\n+pub fn parse_stream_from_source_str(\n+    name: FileName,\n+    source: String,\n+    sess: &ParseSess,\n+    override_span: Option<Span>,\n+) -> (TokenStream, Vec<lexer::UnmatchedBrace>) {\n     source_file_to_stream(sess, sess.source_map().new_source_file(name, source), override_span)\n }\n \n /// Create a new parser from a source string\n-pub fn new_parser_from_source_str(sess: &ParseSess, name: FileName, source: String)\n-                                      -> Parser<'_> {\n+pub fn new_parser_from_source_str(sess: &ParseSess, name: FileName, source: String) -> Parser<'_> {\n     panictry_buffer!(&sess.span_diagnostic, maybe_new_parser_from_source_str(sess, name, source))\n }\n \n@@ -195,12 +198,14 @@ fn source_file_to_parser(sess: &ParseSess, source_file: Lrc<SourceFile>) -> Pars\n \n /// Given a source_file and config, return a parser. Returns any buffered errors from lexing the\n /// initial token stream.\n-fn maybe_source_file_to_parser(sess: &ParseSess, source_file: Lrc<SourceFile>)\n-    -> Result<Parser<'_>, Vec<Diagnostic>>\n-{\n+fn maybe_source_file_to_parser(\n+    sess: &ParseSess,\n+    source_file: Lrc<SourceFile>,\n+) -> Result<Parser<'_>, Vec<Diagnostic>> {\n     let end_pos = source_file.end_pos;\n-    let mut parser = stream_to_parser(sess, maybe_file_to_stream(sess, source_file, None)?);\n-\n+    let (stream, unclosed_delims) = maybe_file_to_stream(sess, source_file, None)?;\n+    let mut parser = stream_to_parser(sess, stream);\n+    parser.unclosed_delims = unclosed_delims;\n     if parser.token == token::Eof && parser.span.is_dummy() {\n         parser.span = Span::new(end_pos, end_pos, parser.span.ctxt());\n     }\n@@ -247,25 +252,44 @@ fn file_to_source_file(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n }\n \n /// Given a source_file, produce a sequence of token-trees\n-pub fn source_file_to_stream(sess: &ParseSess,\n-                             source_file: Lrc<SourceFile>,\n-                             override_span: Option<Span>) -> TokenStream {\n+pub fn source_file_to_stream(\n+    sess: &ParseSess,\n+    source_file: Lrc<SourceFile>,\n+    override_span: Option<Span>,\n+) -> (TokenStream, Vec<lexer::UnmatchedBrace>) {\n     panictry_buffer!(&sess.span_diagnostic, maybe_file_to_stream(sess, source_file, override_span))\n }\n \n /// Given a source file, produce a sequence of token-trees. Returns any buffered errors from\n /// parsing the token tream.\n-pub fn maybe_file_to_stream(sess: &ParseSess,\n-                            source_file: Lrc<SourceFile>,\n-                            override_span: Option<Span>) -> Result<TokenStream, Vec<Diagnostic>> {\n+pub fn maybe_file_to_stream(\n+    sess: &ParseSess,\n+    source_file: Lrc<SourceFile>,\n+    override_span: Option<Span>,\n+) -> Result<(TokenStream, Vec<lexer::UnmatchedBrace>), Vec<Diagnostic>> {\n     let mut srdr = lexer::StringReader::new_or_buffered_errs(sess, source_file, override_span)?;\n     srdr.real_token();\n \n     match srdr.parse_all_token_trees() {\n-        Ok(stream) => Ok(stream),\n+        Ok(stream) => Ok((stream, srdr.unmatched_braces)),\n         Err(err) => {\n             let mut buffer = Vec::with_capacity(1);\n             err.buffer(&mut buffer);\n+            // Not using `emit_unclosed_delims` to use `db.buffer`\n+            for unmatched in srdr.unmatched_braces {\n+                let mut db = sess.span_diagnostic.struct_span_err(unmatched.found_span, &format!(\n+                    \"incorrect close delimiter: `{}`\",\n+                    token_to_string(&token::Token::CloseDelim(unmatched.found_delim)),\n+                ));\n+                db.span_label(unmatched.found_span, \"incorrect close delimiter\");\n+                if let Some(sp) = unmatched.candidate_span {\n+                    db.span_label(sp, \"close delimiter possibly meant for this\");\n+                }\n+                if let Some(sp) = unmatched.unclosed_span {\n+                    db.span_label(sp, \"un-closed delimiter\");\n+                }\n+                db.buffer(&mut buffer);\n+            }\n             Err(buffer)\n         }\n     }"}, {"sha": "69d6407d506fb0bc17dc89851f731c4d83a613b5", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 203, "deletions": 64, "changes": 267, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -35,7 +35,7 @@ use crate::ext::base::DummyResult;\n use crate::source_map::{self, SourceMap, Spanned, respan};\n use crate::errors::{self, Applicability, DiagnosticBuilder, DiagnosticId};\n use crate::parse::{self, SeqSep, classify, token};\n-use crate::parse::lexer::TokenAndSpan;\n+use crate::parse::lexer::{TokenAndSpan, UnmatchedBrace};\n use crate::parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use crate::parse::token::DelimToken;\n use crate::parse::{new_sub_parser_from_file, ParseSess, Directory, DirectoryOwnership};\n@@ -251,6 +251,11 @@ pub struct Parser<'a> {\n     ///\n     /// See the comments in the `parse_path_segment` function for more details.\n     crate unmatched_angle_bracket_count: u32,\n+    crate max_angle_bracket_count: u32,\n+    /// List of all unclosed delimiters found by the lexer. If an entry is used for error recovery\n+    /// it gets removed from here. Every entry left at the end gets emitted as an independent\n+    /// error.\n+    crate unclosed_delims: Vec<UnmatchedBrace>,\n }\n \n \n@@ -575,6 +580,8 @@ impl<'a> Parser<'a> {\n             desugar_doc_comments,\n             cfg_mods: true,\n             unmatched_angle_bracket_count: 0,\n+            max_angle_bracket_count: 0,\n+            unclosed_delims: Vec::new(),\n         };\n \n         let tok = parser.next_tok();\n@@ -644,11 +651,11 @@ impl<'a> Parser<'a> {\n \n     /// Expect and consume the token t. Signal an error if\n     /// the next token is not t.\n-    pub fn expect(&mut self, t: &token::Token) -> PResult<'a,  ()> {\n+    pub fn expect(&mut self, t: &token::Token) -> PResult<'a,  bool /* recovered */> {\n         if self.expected_tokens.is_empty() {\n             if self.token == *t {\n                 self.bump();\n-                Ok(())\n+                Ok(false)\n             } else {\n                 let token_str = pprust::token_to_string(t);\n                 let this_token_str = self.this_token_descr();\n@@ -663,6 +670,12 @@ impl<'a> Parser<'a> {\n                     self.sess.source_map().next_point(self.prev_span)\n                 };\n                 let label_exp = format!(\"expected `{}`\", token_str);\n+                match self.recover_closing_delimiter(&[t.clone()], err) {\n+                    Err(e) => err = e,\n+                    Ok(recovered) => {\n+                        return Ok(recovered);\n+                    }\n+                }\n                 let cm = self.sess.source_map();\n                 match (cm.lookup_line(self.span.lo()), cm.lookup_line(sp.lo())) {\n                     (Ok(ref a), Ok(ref b)) if a.line == b.line => {\n@@ -682,12 +695,64 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n+    fn recover_closing_delimiter(\n+        &mut self,\n+        tokens: &[token::Token],\n+        mut err: DiagnosticBuilder<'a>,\n+    ) -> PResult<'a, bool> {\n+        let mut pos = None;\n+        // we want to use the last closing delim that would apply\n+        for (i, unmatched) in self.unclosed_delims.iter().enumerate().rev() {\n+            if tokens.contains(&token::CloseDelim(unmatched.expected_delim))\n+                && Some(self.span) > unmatched.unclosed_span\n+            {\n+                pos = Some(i);\n+            }\n+        }\n+        match pos {\n+            Some(pos) => {\n+                // Recover and assume that the detected unclosed delimiter was meant for\n+                // this location. Emit the diagnostic and act as if the delimiter was\n+                // present for the parser's sake.\n+\n+                 // Don't attempt to recover from this unclosed delimiter more than once.\n+                let unmatched = self.unclosed_delims.remove(pos);\n+                let delim = TokenType::Token(token::CloseDelim(unmatched.expected_delim));\n+\n+                 // We want to suggest the inclusion of the closing delimiter where it makes\n+                // the most sense, which is immediately after the last token:\n+                //\n+                //  {foo(bar {}}\n+                //      -      ^\n+                //      |      |\n+                //      |      help: `)` may belong here (FIXME: #58270)\n+                //      |\n+                //      unclosed delimiter\n+                if let Some(sp) = unmatched.unclosed_span {\n+                    err.span_label(sp, \"unclosed delimiter\");\n+                }\n+                err.span_suggestion_short(\n+                    self.sess.source_map().next_point(self.prev_span),\n+                    &format!(\"{} may belong here\", delim.to_string()),\n+                    delim.to_string(),\n+                    Applicability::MaybeIncorrect,\n+                );\n+                err.emit();\n+                self.expected_tokens.clear();  // reduce errors\n+                Ok(true)\n+            }\n+            _ => Err(err),\n+        }\n+    }\n+\n     /// Expect next token to be edible or inedible token.  If edible,\n     /// then consume it; if inedible, then return without consuming\n     /// anything.  Signal a fatal error if next token is unexpected.\n-    pub fn expect_one_of(&mut self,\n-                         edible: &[token::Token],\n-                         inedible: &[token::Token]) -> PResult<'a,  ()>{\n+    pub fn expect_one_of(\n+        &mut self,\n+        edible: &[token::Token],\n+        inedible: &[token::Token],\n+    ) -> PResult<'a, bool /* recovered */> {\n         fn tokens_to_string(tokens: &[TokenType]) -> String {\n             let mut i = tokens.iter();\n             // This might be a sign we need a connect method on Iterator.\n@@ -707,10 +772,10 @@ impl<'a> Parser<'a> {\n         }\n         if edible.contains(&self.token) {\n             self.bump();\n-            Ok(())\n+            Ok(false)\n         } else if inedible.contains(&self.token) {\n             // leave it in the input\n-            Ok(())\n+            Ok(false)\n         } else {\n             let mut expected = edible.iter()\n                 .map(|x| TokenType::Token(x.clone()))\n@@ -761,6 +826,15 @@ impl<'a> Parser<'a> {\n             } else {\n                 label_sp\n             };\n+            match self.recover_closing_delimiter(&expected.iter().filter_map(|tt| match tt {\n+                TokenType::Token(t) => Some(t.clone()),\n+                _ => None,\n+            }).collect::<Vec<_>>(), err) {\n+                Err(e) => err = e,\n+                Ok(recovered) => {\n+                    return Ok(recovered);\n+                }\n+            }\n \n             let cm = self.sess.source_map();\n             match (cm.lookup_line(self.span.lo()), cm.lookup_line(sp.lo())) {\n@@ -1070,6 +1144,7 @@ impl<'a> Parser<'a> {\n         if ate {\n             // See doc comment for `unmatched_angle_bracket_count`.\n             self.unmatched_angle_bracket_count += 1;\n+            self.max_angle_bracket_count += 1;\n             debug!(\"eat_lt: (increment) count={:?}\", self.unmatched_angle_bracket_count);\n         }\n \n@@ -1110,12 +1185,12 @@ impl<'a> Parser<'a> {\n         };\n \n         match ate {\n-            Some(x) => {\n+            Some(_) => {\n                 // See doc comment for `unmatched_angle_bracket_count`.\n                 self.unmatched_angle_bracket_count -= 1;\n                 debug!(\"expect_gt: (decrement) count={:?}\", self.unmatched_angle_bracket_count);\n \n-                Ok(x)\n+                Ok(())\n             },\n             None => self.unexpected(),\n         }\n@@ -1144,19 +1219,22 @@ impl<'a> Parser<'a> {\n                                   -> PResult<'a, Vec<T>> where\n         F: FnMut(&mut Parser<'a>) -> PResult<'a,  T>,\n     {\n-        let val = self.parse_seq_to_before_end(ket, sep, f)?;\n-        self.bump();\n+        let (val, recovered) = self.parse_seq_to_before_end(ket, sep, f)?;\n+        if !recovered {\n+            self.bump();\n+        }\n         Ok(val)\n     }\n \n     /// Parse a sequence, not including the closing delimiter. The function\n     /// f must consume tokens until reaching the next separator or\n     /// closing bracket.\n-    pub fn parse_seq_to_before_end<T, F>(&mut self,\n-                                         ket: &token::Token,\n-                                         sep: SeqSep,\n-                                         f: F)\n-                                         -> PResult<'a, Vec<T>>\n+    pub fn parse_seq_to_before_end<T, F>(\n+        &mut self,\n+        ket: &token::Token,\n+        sep: SeqSep,\n+        f: F,\n+    ) -> PResult<'a, (Vec<T>, bool)>\n         where F: FnMut(&mut Parser<'a>) -> PResult<'a, T>\n     {\n         self.parse_seq_to_before_tokens(&[ket], sep, TokenExpectType::Expect, f)\n@@ -1168,10 +1246,11 @@ impl<'a> Parser<'a> {\n         sep: SeqSep,\n         expect: TokenExpectType,\n         mut f: F,\n-    ) -> PResult<'a, Vec<T>>\n+    ) -> PResult<'a, (Vec<T>, bool /* recovered */)>\n         where F: FnMut(&mut Parser<'a>) -> PResult<'a, T>\n     {\n-        let mut first: bool = true;\n+        let mut first = true;\n+        let mut recovered = false;\n         let mut v = vec![];\n         while !kets.iter().any(|k| {\n                 match expect {\n@@ -1187,23 +1266,30 @@ impl<'a> Parser<'a> {\n                 if first {\n                     first = false;\n                 } else {\n-                    if let Err(mut e) = self.expect(t) {\n-                        // Attempt to keep parsing if it was a similar separator\n-                        if let Some(ref tokens) = t.similar_tokens() {\n-                            if tokens.contains(&self.token) {\n-                                self.bump();\n-                            }\n+                    match self.expect(t) {\n+                        Ok(false) => {}\n+                        Ok(true) => {\n+                            recovered = true;\n+                            break;\n                         }\n-                        e.emit();\n-                        // Attempt to keep parsing if it was an omitted separator\n-                        match f(self) {\n-                            Ok(t) => {\n-                                v.push(t);\n-                                continue;\n-                            },\n-                            Err(mut e) => {\n-                                e.cancel();\n-                                break;\n+                        Err(mut e) => {\n+                            // Attempt to keep parsing if it was a similar separator\n+                            if let Some(ref tokens) = t.similar_tokens() {\n+                                if tokens.contains(&self.token) {\n+                                    self.bump();\n+                                }\n+                            }\n+                            e.emit();\n+                            // Attempt to keep parsing if it was an omitted separator\n+                            match f(self) {\n+                                Ok(t) => {\n+                                    v.push(t);\n+                                    continue;\n+                                },\n+                                Err(mut e) => {\n+                                    e.cancel();\n+                                    break;\n+                                }\n                             }\n                         }\n                     }\n@@ -1222,23 +1308,26 @@ impl<'a> Parser<'a> {\n             v.push(t);\n         }\n \n-        Ok(v)\n+        Ok((v, recovered))\n     }\n \n     /// Parse a sequence, including the closing delimiter. The function\n     /// f must consume tokens until reaching the next separator or\n     /// closing bracket.\n-    fn parse_unspanned_seq<T, F>(&mut self,\n-                                     bra: &token::Token,\n-                                     ket: &token::Token,\n-                                     sep: SeqSep,\n-                                     f: F)\n-                                     -> PResult<'a, Vec<T>> where\n+    fn parse_unspanned_seq<T, F>(\n+        &mut self,\n+        bra: &token::Token,\n+        ket: &token::Token,\n+        sep: SeqSep,\n+        f: F,\n+    ) -> PResult<'a, Vec<T>> where\n         F: FnMut(&mut Parser<'a>) -> PResult<'a, T>,\n     {\n         self.expect(bra)?;\n-        let result = self.parse_seq_to_before_end(ket, sep, f)?;\n-        self.eat(ket);\n+        let (result, recovered) = self.parse_seq_to_before_end(ket, sep, f)?;\n+        if !recovered {\n+            self.eat(ket);\n+        }\n         Ok(result)\n     }\n \n@@ -2290,7 +2379,10 @@ impl<'a> Parser<'a> {\n             // We use `style == PathStyle::Expr` to check if this is in a recursion or not. If\n             // it isn't, then we reset the unmatched angle bracket count as we're about to start\n             // parsing a new path.\n-            if style == PathStyle::Expr { self.unmatched_angle_bracket_count = 0; }\n+            if style == PathStyle::Expr {\n+                self.unmatched_angle_bracket_count = 0;\n+                self.max_angle_bracket_count = 0;\n+            }\n \n             let args = if self.eat_lt() {\n                 // `<'a, T, A = U>`\n@@ -2302,12 +2394,14 @@ impl<'a> Parser<'a> {\n             } else {\n                 // `(T, U) -> R`\n                 self.bump(); // `(`\n-                let inputs = self.parse_seq_to_before_tokens(\n+                let (inputs, recovered) = self.parse_seq_to_before_tokens(\n                     &[&token::CloseDelim(token::Paren)],\n                     SeqSep::trailing_allowed(token::Comma),\n                     TokenExpectType::Expect,\n                     |p| p.parse_ty())?;\n-                self.bump(); // `)`\n+                if !recovered {\n+                    self.bump(); // `)`\n+                }\n                 let span = lo.to(self.prev_span);\n                 let output = if self.eat(&token::RArrow) {\n                     Some(self.parse_ty_common(false, false)?)\n@@ -2513,17 +2607,23 @@ impl<'a> Parser<'a> {\n                 // (e,) is a tuple with only one field, e\n                 let mut es = vec![];\n                 let mut trailing_comma = false;\n+                let mut recovered = false;\n                 while self.token != token::CloseDelim(token::Paren) {\n                     es.push(self.parse_expr()?);\n-                    self.expect_one_of(&[], &[token::Comma, token::CloseDelim(token::Paren)])?;\n+                    recovered = self.expect_one_of(\n+                        &[],\n+                        &[token::Comma, token::CloseDelim(token::Paren)],\n+                    )?;\n                     if self.eat(&token::Comma) {\n                         trailing_comma = true;\n                     } else {\n                         trailing_comma = false;\n                         break;\n                     }\n                 }\n-                self.bump();\n+                if !recovered {\n+                    self.bump();\n+                }\n \n                 hi = self.prev_span;\n                 ex = if es.len() == 1 && !trailing_comma {\n@@ -2720,6 +2820,21 @@ impl<'a> Parser<'a> {\n                     hi = pth.span;\n                     ex = ExprKind::Path(None, pth);\n                 } else {\n+                    if !self.unclosed_delims.is_empty() && self.check(&token::Semi) {\n+                        // Don't complain about bare semicolons after unclosed braces\n+                        // recovery in order to keep the error count down. Fixing the\n+                        // delimiters will possibly also fix the bare semicolon found in\n+                        // expression context. For example, silence the following error:\n+                        // ```\n+                        // error: expected expression, found `;`\n+                        //  --> file.rs:2:13\n+                        //   |\n+                        // 2 |     foo(bar(;\n+                        //   |             ^ expected expression\n+                        // ```\n+                        self.bump();\n+                        return Ok(self.mk_expr(self.span, ExprKind::Err, ThinVec::new()));\n+                    }\n                     match self.parse_literal_maybe_minus() {\n                         Ok(expr) => {\n                             hi = expr.span;\n@@ -2819,7 +2934,7 @@ impl<'a> Parser<'a> {\n \n             match self.expect_one_of(&[token::Comma],\n                                      &[token::CloseDelim(token::Brace)]) {\n-                Ok(()) => if let Some(f) = parsed_field.or(recovery_field) {\n+                Ok(_) => if let Some(f) = parsed_field.or(recovery_field) {\n                     // only include the field if there's no parse error for the field name\n                     fields.push(f);\n                 }\n@@ -5939,7 +6054,7 @@ impl<'a> Parser<'a> {\n \n         let sp = self.span;\n         let mut variadic = false;\n-        let args: Vec<Option<Arg>> =\n+        let (args, recovered): (Vec<Option<Arg>>, bool) =\n             self.parse_seq_to_before_end(\n                 &token::CloseDelim(token::Paren),\n                 SeqSep::trailing_allowed(token::Comma),\n@@ -5987,7 +6102,9 @@ impl<'a> Parser<'a> {\n                 }\n             )?;\n \n-        self.eat(&token::CloseDelim(token::Paren));\n+        if !recovered {\n+            self.eat(&token::CloseDelim(token::Paren));\n+        }\n \n         let args: Vec<_> = args.into_iter().filter_map(|x| x).collect();\n \n@@ -6132,24 +6249,26 @@ impl<'a> Parser<'a> {\n \n         // Parse the rest of the function parameter list.\n         let sep = SeqSep::trailing_allowed(token::Comma);\n-        let fn_inputs = if let Some(self_arg) = self_arg {\n+        let (fn_inputs, recovered) = if let Some(self_arg) = self_arg {\n             if self.check(&token::CloseDelim(token::Paren)) {\n-                vec![self_arg]\n+                (vec![self_arg], false)\n             } else if self.eat(&token::Comma) {\n                 let mut fn_inputs = vec![self_arg];\n-                fn_inputs.append(&mut self.parse_seq_to_before_end(\n-                    &token::CloseDelim(token::Paren), sep, parse_arg_fn)?\n-                );\n-                fn_inputs\n+                let (mut input, recovered) = self.parse_seq_to_before_end(\n+                    &token::CloseDelim(token::Paren), sep, parse_arg_fn)?;\n+                fn_inputs.append(&mut input);\n+                (fn_inputs, recovered)\n             } else {\n                 return self.unexpected();\n             }\n         } else {\n             self.parse_seq_to_before_end(&token::CloseDelim(token::Paren), sep, parse_arg_fn)?\n         };\n \n-        // Parse closing paren and return type.\n-        self.expect(&token::CloseDelim(token::Paren))?;\n+        if !recovered {\n+            // Parse closing paren and return type.\n+            self.expect(&token::CloseDelim(token::Paren))?;\n+        }\n         Ok(P(FnDecl {\n             inputs: fn_inputs,\n             output: self.parse_ret_ty(true)?,\n@@ -6169,7 +6288,7 @@ impl<'a> Parser<'a> {\n                     SeqSep::trailing_allowed(token::Comma),\n                     TokenExpectType::NoExpect,\n                     |p| p.parse_fn_block_arg()\n-                )?;\n+                )?.0;\n                 self.expect_or()?;\n                 args\n             }\n@@ -8168,7 +8287,7 @@ impl<'a> Parser<'a> {\n             // eat a matched-delimiter token tree:\n             let (delim, tts) = self.expect_delimited_token_tree()?;\n             if delim != MacDelimiter::Brace {\n-                self.expect(&token::Semi)?\n+                self.expect(&token::Semi)?;\n             }\n \n             Ok(Some(respan(lo.to(self.prev_span), Mac_ { path: pth, tts, delim })))\n@@ -8313,11 +8432,14 @@ impl<'a> Parser<'a> {\n     /// entry point for the parser.\n     pub fn parse_crate_mod(&mut self) -> PResult<'a, Crate> {\n         let lo = self.span;\n-        Ok(ast::Crate {\n+        let krate = Ok(ast::Crate {\n             attrs: self.parse_inner_attributes()?,\n             module: self.parse_mod_items(&token::Eof, lo)?,\n             span: lo.to(self.span),\n-        })\n+        });\n+        emit_unclosed_delims(&self.unclosed_delims, self.diagnostic());\n+        self.unclosed_delims.clear();\n+        krate\n     }\n \n     pub fn parse_optional_str(&mut self) -> Option<(Symbol, ast::StrStyle, Option<ast::Name>)> {\n@@ -8346,3 +8468,20 @@ impl<'a> Parser<'a> {\n         }\n     }\n }\n+\n+pub fn emit_unclosed_delims(unclosed_delims: &[UnmatchedBrace], handler: &errors::Handler) {\n+    for unmatched in unclosed_delims {\n+        let mut err = handler.struct_span_err(unmatched.found_span, &format!(\n+            \"incorrect close delimiter: `{}`\",\n+            pprust::token_to_string(&token::Token::CloseDelim(unmatched.found_delim)),\n+        ));\n+        err.span_label(unmatched.found_span, \"incorrect close delimiter\");\n+        if let Some(sp) = unmatched.candidate_span {\n+            err.span_label(sp, \"close delimiter possibly meant for this\");\n+        }\n+        if let Some(sp) = unmatched.unclosed_span {\n+            err.span_label(sp, \"un-closed delimiter\");\n+        }\n+        err.emit();\n+    }\n+}"}, {"sha": "09924e304cfd9c7c5317dd948caefe62b219af6d", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 11, "deletions": 5, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -10,6 +10,7 @@ use crate::print::pprust;\n use crate::ptr::P;\n use crate::symbol::keywords;\n use crate::syntax::parse::parse_stream_from_source_str;\n+use crate::syntax::parse::parser::emit_unclosed_delims;\n use crate::tokenstream::{self, DelimSpan, TokenStream, TokenTree};\n \n use serialize::{Decodable, Decoder, Encodable, Encoder};\n@@ -501,8 +502,8 @@ impl Token {\n     /// Enables better error recovery when the wrong token is found.\n     crate fn similar_tokens(&self) -> Option<Vec<Token>> {\n         match *self {\n-            Comma => Some(vec![Dot, Lt]),\n-            Semi => Some(vec![Colon]),\n+            Comma => Some(vec![Dot, Lt, Semi]),\n+            Semi => Some(vec![Colon, Comma]),\n             _ => None\n         }\n     }\n@@ -559,7 +560,10 @@ impl Token {\n             // FIXME(#43081): Avoid this pretty-print + reparse hack\n             let source = pprust::token_to_string(self);\n             let filename = FileName::macro_expansion_source_code(&source);\n-            parse_stream_from_source_str(filename, source, sess, Some(span))\n+            let (tokens, errors) = parse_stream_from_source_str(\n+                filename, source, sess, Some(span));\n+            emit_unclosed_delims(&errors, &sess.span_diagnostic);\n+            tokens\n         });\n \n         // During early phases of the compiler the AST could get modified\n@@ -800,12 +804,13 @@ fn prepend_attrs(sess: &ParseSess,\n         let source = pprust::attr_to_string(attr);\n         let macro_filename = FileName::macro_expansion_source_code(&source);\n         if attr.is_sugared_doc {\n-            let stream = parse_stream_from_source_str(\n+            let (stream, errors) = parse_stream_from_source_str(\n                 macro_filename,\n                 source,\n                 sess,\n                 Some(span),\n             );\n+            emit_unclosed_delims(&errors, &sess.span_diagnostic);\n             builder.push(stream);\n             continue\n         }\n@@ -822,12 +827,13 @@ fn prepend_attrs(sess: &ParseSess,\n         // ... and for more complicated paths, fall back to a reparse hack that\n         // should eventually be removed.\n         } else {\n-            let stream = parse_stream_from_source_str(\n+            let (stream, errors) = parse_stream_from_source_str(\n                 macro_filename,\n                 source,\n                 sess,\n                 Some(span),\n             );\n+            emit_unclosed_delims(&errors, &sess.span_diagnostic);\n             brackets.push(stream);\n         }\n "}, {"sha": "bcf1da66c04b62f5572dc12c4d0e2314f583d686", "filename": "src/libsyntax/util/parser_testing.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser_testing.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -12,8 +12,11 @@ use std::path::PathBuf;\n /// Map a string to tts, using a made-up filename:\n pub fn string_to_stream(source_str: String) -> TokenStream {\n     let ps = ParseSess::new(FilePathMapping::empty());\n-    source_file_to_stream(&ps, ps.source_map()\n-                             .new_source_file(PathBuf::from(\"bogofile\").into(), source_str), None)\n+    source_file_to_stream(\n+        &ps,\n+        ps.source_map().new_source_file(PathBuf::from(\"bogofile\").into(),\n+        source_str,\n+    ), None).0\n }\n \n /// Map string to parser (via tts)"}, {"sha": "2158cfc089bdd1cbcd9785a7b0b678581b4888a5", "filename": "src/libsyntax_ext/proc_macro_server.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fproc_macro_server.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -12,6 +12,7 @@ use syntax::ast;\n use syntax::ext::base::ExtCtxt;\n use syntax::parse::lexer::comments;\n use syntax::parse::{self, token, ParseSess};\n+use syntax::parse::parser::emit_unclosed_delims;\n use syntax::tokenstream::{self, DelimSpan, IsJoint::*, TokenStream, TreeAndJoint};\n use syntax_pos::hygiene::{SyntaxContext, Transparency};\n use syntax_pos::symbol::{keywords, Symbol};\n@@ -409,12 +410,14 @@ impl server::TokenStream for Rustc<'_> {\n         stream.is_empty()\n     }\n     fn from_str(&mut self, src: &str) -> Self::TokenStream {\n-        parse::parse_stream_from_source_str(\n+        let (tokens, errors) = parse::parse_stream_from_source_str(\n             FileName::proc_macro_source_code(src.clone()),\n             src.to_string(),\n             self.sess,\n             Some(self.call_site),\n-        )\n+        );\n+        emit_unclosed_delims(&errors, &self.sess.span_diagnostic);\n+        tokens\n     }\n     fn to_string(&mut self, stream: &Self::TokenStream) -> String {\n         stream.to_string()"}, {"sha": "33c94d6e3a59e76c267810b1323992e6c219ea04", "filename": "src/test/ui/augmented-assignments.nll.stderr", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Faugmented-assignments.nll.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Faugmented-assignments.nll.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Faugmented-assignments.nll.stderr?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -9,7 +9,7 @@ LL |       x   //~ error: use of moved value: `x`\n LL | |     //~^ value used here after move\n LL | |     +=\n LL | |     x;  //~ value moved here\n-   | |     -\n+   | |     ^\n    | |     |\n    | |_____move out of `x` occurs here\n    |       borrow later used here"}, {"sha": "65b2b9460bc9496afea3f12fe01ded404b51d6ef", "filename": "src/test/ui/issues/issue-52891.stderr", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fissues%2Fissue-52891.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fissues%2Fissue-52891.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fissues%2Fissue-52891.stderr?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -90,7 +90,7 @@ LL |   use issue_52891::a;\n LL |       m,\n    |  ______-\n LL | |     a}; //~ ERROR `a` is defined multiple times\n-   | |     -\n+   | |     ^\n    | |     |\n    | |_____`a` reimported here\n    |       help: remove unnecessary import"}, {"sha": "76f7af38e776dcd3b1ca8260669ff958795e297d", "filename": "src/test/ui/parser-recovery-2.stderr", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fparser-recovery-2.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fparser-recovery-2.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser-recovery-2.stderr?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -1,3 +1,9 @@\n+error: unexpected token: `;`\n+  --> $DIR/parser-recovery-2.rs:12:15\n+   |\n+LL |     let x = y.;  //~ ERROR unexpected token\n+   |               ^\n+\n error: incorrect close delimiter: `)`\n   --> $DIR/parser-recovery-2.rs:8:5\n    |\n@@ -7,12 +13,6 @@ LL |         let x = foo(); //~ ERROR cannot find function `foo` in this scope\n LL |     ) //~ ERROR incorrect close delimiter: `)`\n    |     ^ incorrect close delimiter\n \n-error: unexpected token: `;`\n-  --> $DIR/parser-recovery-2.rs:12:15\n-   |\n-LL |     let x = y.;  //~ ERROR unexpected token\n-   |               ^\n-\n error[E0425]: cannot find function `foo` in this scope\n   --> $DIR/parser-recovery-2.rs:7:17\n    |"}, {"sha": "6fb63639d5f6040a9e6036690f0563f04343c216", "filename": "src/test/ui/parser/issue-10636-2.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fparser%2Fissue-10636-2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fparser%2Fissue-10636-2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fissue-10636-2.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -5,7 +5,7 @@ pub fn trace_option(option: Option<isize>) {\n     option.map(|some| 42;\n                           //~^ ERROR: expected one of\n \n-} //~ ERROR: incorrect close delimiter\n+}\n //~^ ERROR: expected expression, found `)`\n \n fn main() {}"}, {"sha": "38d57ce57236556b51c54a1b974529ae6d6503c3", "filename": "src/test/ui/parser/issue-10636-2.stderr", "status": "modified", "additions": 6, "deletions": 14, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fparser%2Fissue-10636-2.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fparser%2Fissue-10636-2.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fissue-10636-2.stderr?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -1,25 +1,17 @@\n-error: incorrect close delimiter: `}`\n-  --> $DIR/issue-10636-2.rs:8:1\n-   |\n-LL | pub fn trace_option(option: Option<isize>) {\n-   |                                            - close delimiter possibly meant for this\n-LL |     option.map(|some| 42;\n-   |               - un-closed delimiter\n-...\n-LL | } //~ ERROR: incorrect close delimiter\n-   | ^ incorrect close delimiter\n-\n error: expected one of `)`, `,`, `.`, `?`, or an operator, found `;`\n   --> $DIR/issue-10636-2.rs:5:25\n    |\n LL |     option.map(|some| 42;\n-   |                         ^ expected one of `)`, `,`, `.`, `?`, or an operator here\n+   |               -         ^\n+   |               |         |\n+   |               |         help: `)` may belong here\n+   |               unclosed delimiter\n \n error: expected expression, found `)`\n   --> $DIR/issue-10636-2.rs:8:1\n    |\n-LL | } //~ ERROR: incorrect close delimiter\n+LL | }\n    | ^ expected expression\n \n-error: aborting due to 3 previous errors\n+error: aborting due to 2 previous errors\n "}, {"sha": "abb0820979532e92d3c220f4e9c3cfef2ba1749b", "filename": "src/test/ui/parser/macro-mismatched-delim-paren-brace.stderr", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fparser%2Fmacro-mismatched-delim-paren-brace.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fparser%2Fmacro-mismatched-delim-paren-brace.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fmacro-mismatched-delim-paren-brace.stderr?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -1,3 +1,9 @@\n+error: unexpected close delimiter: `}`\n+  --> $DIR/macro-mismatched-delim-paren-brace.rs:5:1\n+   |\n+LL | } //~ ERROR unexpected close delimiter: `}`\n+   | ^ unexpected close delimiter\n+\n error: incorrect close delimiter: `}`\n   --> $DIR/macro-mismatched-delim-paren-brace.rs:4:5\n    |\n@@ -7,11 +13,5 @@ LL |         bar, \"baz\", 1, 2.0\n LL |     } //~ ERROR incorrect close delimiter\n    |     ^ incorrect close delimiter\n \n-error: unexpected close delimiter: `}`\n-  --> $DIR/macro-mismatched-delim-paren-brace.rs:5:1\n-   |\n-LL | } //~ ERROR unexpected close delimiter: `}`\n-   | ^ unexpected close delimiter\n-\n error: aborting due to 2 previous errors\n "}, {"sha": "b1ca0bbfc57c10b125669ebad3718e8df0f8f0a7", "filename": "src/test/ui/resolve/token-error-correct-3.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct-3.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct-3.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct-3.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -17,7 +17,7 @@ pub mod raw {\n             //~| expected type `()`\n             //~| found type `std::result::Result<bool, std::io::Error>`\n             //~| expected one of\n-        } else { //~ ERROR: incorrect close delimiter: `}`\n+        } else {\n             //~^ ERROR: expected one of\n             //~| unexpected token\n             Ok(false);"}, {"sha": "a6bb83c71f3130a594cf54921cfab817856211a2", "filename": "src/test/ui/resolve/token-error-correct-3.stderr", "status": "modified", "additions": 6, "deletions": 14, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct-3.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct-3.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct-3.stderr?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -1,27 +1,19 @@\n-error: incorrect close delimiter: `}`\n-  --> $DIR/token-error-correct-3.rs:20:9\n-   |\n-LL |         if !is_directory(path.as_ref()) { //~ ERROR: cannot find function `is_directory`\n-   |                                         - close delimiter possibly meant for this\n-LL |             callback(path.as_ref(); //~ ERROR expected one of\n-   |                     - un-closed delimiter\n-...\n-LL |         } else { //~ ERROR: incorrect close delimiter: `}`\n-   |         ^ incorrect close delimiter\n-\n error: expected one of `)`, `,`, `.`, `?`, or an operator, found `;`\n   --> $DIR/token-error-correct-3.rs:14:35\n    |\n LL |             callback(path.as_ref(); //~ ERROR expected one of\n-   |                                   ^ expected one of `)`, `,`, `.`, `?`, or an operator here\n+   |                     -             ^\n+   |                     |             |\n+   |                     |             help: `)` may belong here\n+   |                     unclosed delimiter\n \n error: expected one of `.`, `;`, `?`, `}`, or an operator, found `)`\n   --> $DIR/token-error-correct-3.rs:20:9\n    |\n LL |             fs::create_dir_all(path.as_ref()).map(|()| true) //~ ERROR: mismatched types\n    |                                                             - expected one of `.`, `;`, `?`, `}`, or an operator here\n ...\n-LL |         } else { //~ ERROR: incorrect close delimiter: `}`\n+LL |         } else {\n    |         ^ unexpected token\n \n error[E0425]: cannot find function `is_directory` in this scope\n@@ -41,7 +33,7 @@ LL |             fs::create_dir_all(path.as_ref()).map(|()| true) //~ ERROR: mis\n    = note: expected type `()`\n               found type `std::result::Result<bool, std::io::Error>`\n \n-error: aborting due to 5 previous errors\n+error: aborting due to 4 previous errors\n \n Some errors occurred: E0308, E0425.\n For more information about an error, try `rustc --explain E0308`."}, {"sha": "d64907780efb512f838d44392b8d3783063c29cc", "filename": "src/test/ui/resolve/token-error-correct.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct.rs?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -2,6 +2,8 @@\n \n fn main() {\n     foo(bar(;\n-    //~^ ERROR: expected expression, found `;`\n+    //~^ ERROR cannot find function `bar` in this scope\n }\n //~^ ERROR: incorrect close delimiter: `}`\n+\n+fn foo(_: usize) {}"}, {"sha": "b0827ea7367c2f69910ed463ebc770a088ed13bc", "filename": "src/test/ui/resolve/token-error-correct.stderr", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/3315728c060b73ccf986c63677c1fcd7d92e15c5/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fresolve%2Ftoken-error-correct.stderr?ref=3315728c060b73ccf986c63677c1fcd7d92e15c5", "patch": "@@ -5,15 +5,16 @@ LL | fn main() {\n    |           - close delimiter possibly meant for this\n LL |     foo(bar(;\n    |            - un-closed delimiter\n-LL |     //~^ ERROR: expected expression, found `;`\n+LL |     //~^ ERROR cannot find function `bar` in this scope\n LL | }\n    | ^ incorrect close delimiter\n \n-error: expected expression, found `;`\n-  --> $DIR/token-error-correct.rs:4:13\n+error[E0425]: cannot find function `bar` in this scope\n+  --> $DIR/token-error-correct.rs:4:9\n    |\n LL |     foo(bar(;\n-   |             ^ expected expression\n+   |         ^^^ not found in this scope\n \n error: aborting due to 2 previous errors\n \n+For more information about this error, try `rustc --explain E0425`."}]}