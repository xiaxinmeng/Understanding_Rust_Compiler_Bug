{"sha": "25c4676dfa805e027564116b9c37fee7aeaf1cc4", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI1YzQ2NzZkZmE4MDVlMDI3NTY0MTE2YjljMzdmZWU3YWVhZjFjYzQ=", "commit": {"author": {"name": "John Clements", "email": "clements@racket-lang.org", "date": "2013-02-04T21:15:17Z"}, "committer": {"name": "John Clements", "email": "clements@racket-lang.org", "date": "2013-02-13T23:08:27Z"}, "message": "Commenting, test cases, cleanup", "tree": {"sha": "9f6f678010bfc527a917b552d0ebc722eb2bd41d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9f6f678010bfc527a917b552d0ebc722eb2bd41d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/25c4676dfa805e027564116b9c37fee7aeaf1cc4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/25c4676dfa805e027564116b9c37fee7aeaf1cc4", "html_url": "https://github.com/rust-lang/rust/commit/25c4676dfa805e027564116b9c37fee7aeaf1cc4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/25c4676dfa805e027564116b9c37fee7aeaf1cc4/comments", "author": {"login": "jbclements", "id": 226617, "node_id": "MDQ6VXNlcjIyNjYxNw==", "avatar_url": "https://avatars.githubusercontent.com/u/226617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbclements", "html_url": "https://github.com/jbclements", "followers_url": "https://api.github.com/users/jbclements/followers", "following_url": "https://api.github.com/users/jbclements/following{/other_user}", "gists_url": "https://api.github.com/users/jbclements/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbclements/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbclements/subscriptions", "organizations_url": "https://api.github.com/users/jbclements/orgs", "repos_url": "https://api.github.com/users/jbclements/repos", "events_url": "https://api.github.com/users/jbclements/events{/privacy}", "received_events_url": "https://api.github.com/users/jbclements/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jbclements", "id": 226617, "node_id": "MDQ6VXNlcjIyNjYxNw==", "avatar_url": "https://avatars.githubusercontent.com/u/226617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbclements", "html_url": "https://github.com/jbclements", "followers_url": "https://api.github.com/users/jbclements/followers", "following_url": "https://api.github.com/users/jbclements/following{/other_user}", "gists_url": "https://api.github.com/users/jbclements/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbclements/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbclements/subscriptions", "organizations_url": "https://api.github.com/users/jbclements/orgs", "repos_url": "https://api.github.com/users/jbclements/repos", "events_url": "https://api.github.com/users/jbclements/events{/privacy}", "received_events_url": "https://api.github.com/users/jbclements/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6d09fc2cd80231aab527a27e8112e6167a15f042", "url": "https://api.github.com/repos/rust-lang/rust/commits/6d09fc2cd80231aab527a27e8112e6167a15f042", "html_url": "https://github.com/rust-lang/rust/commit/6d09fc2cd80231aab527a27e8112e6167a15f042"}], "stats": {"total": 148, "additions": 119, "deletions": 29}, "files": [{"sha": "c7a0300a97892c19c93aca562be247a19817cacf", "filename": "src/libcore/dvec.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibcore%2Fdvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibcore%2Fdvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fdvec.rs?ref=25c4676dfa805e027564116b9c37fee7aeaf1cc4", "patch": "@@ -229,7 +229,7 @@ impl<A> DVec<A> {\n \n impl<A: Copy> DVec<A> {\n     /**\n-     * Append all elements of a vector to the end of the list\n+     * Append all elements of a vector to the end of the list.\n      *\n      * Equivalent to `append_iter()` but potentially more efficient.\n      */"}, {"sha": "b26cab7694c9165e78f9a141cecfde3a921f80b3", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=25c4676dfa805e027564116b9c37fee7aeaf1cc4", "patch": "@@ -779,10 +779,19 @@ pub enum expr_ {\n #[auto_decode]\n #[doc=\"For macro invocations; parsing is delegated to the macro\"]\n pub enum token_tree {\n+    // a single token\n     tt_tok(span, ::parse::token::Token),\n+    // a delimited sequence (the delimiters appear as the first\n+    // and last elements of the vector)\n     tt_delim(~[token_tree]),\n-    // These only make sense for right-hand-sides of MBE macros\n+    // These only make sense for right-hand-sides of MBE macros:\n+\n+    // a kleene-style repetition sequence with a span, a tt_forest,\n+    // an optional separator (?), and a boolean where true indicates\n+    // zero or more (*), and false indicates one or more (+).\n     tt_seq(span, ~[token_tree], Option<::parse::token::Token>, bool),\n+\n+    // a syntactic variable that will be filled in by macro expansion.\n     tt_nonterminal(span, ident)\n }\n "}, {"sha": "a85a7990ace9869359eb7f6973afd97e7460d16d", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=25c4676dfa805e027564116b9c37fee7aeaf1cc4", "patch": "@@ -44,8 +44,8 @@ pub struct SyntaxExpanderTT {\n     span: Option<span>\n }\n \n-pub type SyntaxExpanderTTFun = fn@(ext_ctxt, span, ~[ast::token_tree])\n-                                -> MacResult;\n+pub type SyntaxExpanderTTFun\n+    = fn@(ext_ctxt, span, ~[ast::token_tree]) -> MacResult;\n \n pub struct SyntaxExpanderTTItem {\n     expander: SyntaxExpanderTTItemFun,\n@@ -59,7 +59,7 @@ pub enum MacResult {\n     MRExpr(@ast::expr),\n     MRItem(@ast::item),\n     MRAny(fn@()-> @ast::expr, fn@()-> Option<@ast::item>, fn@()->@ast::stmt),\n-    MRDef(MacroDef)\n+    MRDef(MacroDef),\n }\n \n pub enum SyntaxExtension {\n@@ -78,9 +78,11 @@ pub enum SyntaxExtension {\n // A temporary hard-coded map of methods for expanding syntax extension\n // AST nodes into full ASTs\n pub fn syntax_expander_table() -> HashMap<~str, SyntaxExtension> {\n+    // utility function to simplify creating NormalTT syntax extensions\n     fn builtin_normal_tt(f: SyntaxExpanderTTFun) -> SyntaxExtension {\n         NormalTT(SyntaxExpanderTT{expander: f, span: None})\n     }\n+    // utility function to simplify creating ItemTT syntax extensions\n     fn builtin_item_tt(f: SyntaxExpanderTTItemFun) -> SyntaxExtension {\n         ItemTT(SyntaxExpanderTTItem{expander: f, span: None})\n     }\n@@ -112,8 +114,8 @@ pub fn syntax_expander_table() -> HashMap<~str, SyntaxExtension> {\n                                 ext::deriving::expand_deriving_iter_bytes));\n \n     // Quasi-quoting expanders\n-    syntax_expanders.insert(\n-        ~\"quote_tokens\", builtin_normal_tt(ext::quote::expand_quote_tokens));\n+    syntax_expanders.insert(~\"quote_tokens\",\n+                       builtin_normal_tt(ext::quote::expand_quote_tokens));\n     syntax_expanders.insert(~\"quote_expr\",\n                             builtin_normal_tt(ext::quote::expand_quote_expr));\n     syntax_expanders.insert(~\"quote_ty\","}, {"sha": "75120e9c0bc8cb70eff9b251be6090ea4eee5bcf", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=25c4676dfa805e027564116b9c37fee7aeaf1cc4", "patch": "@@ -121,15 +121,15 @@ pure fn lookup_cur_matched_by_matched(r: @mut TtReader,\n     vec::foldl(start, r.repeat_idx, red)\n }\n \n-fn lookup_cur_matched(r: @mut TtReader, name: ident) -> @named_match {\n+fn lookup_cur_matched(r: &TtReader, name: ident) -> @named_match {\n     lookup_cur_matched_by_matched(r, r.interpolations.get(&name))\n }\n enum lis {\n     lis_unconstrained, lis_constraint(uint, ident), lis_contradiction(~str)\n }\n \n-fn lockstep_iter_size(t: token_tree, r: @mut TtReader) -> lis {\n-    fn lis_merge(lhs: lis, rhs: lis, r: @mut TtReader) -> lis {\n+fn lockstep_iter_size(t: token_tree, r: &TtReader) -> lis {\n+    fn lis_merge(lhs: lis, rhs: lis, r: &TtReader) -> lis {\n         match lhs {\n           lis_unconstrained => rhs,\n           lis_contradiction(_) => lhs,"}, {"sha": "7e74163b6bf36c77007be9eef51a126bf0c00d6a", "filename": "src/libsyntax/parse/common.rs", "status": "modified", "additions": 23, "deletions": 3, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=25c4676dfa805e027564116b9c37fee7aeaf1cc4", "patch": "@@ -20,6 +20,8 @@ use core::option::{None, Option, Some};\n use core::option;\n use std::oldmap::HashMap;\n \n+// seq_sep : a sequence separator (token)\n+// and whether a trailing separator is allowed.\n pub type seq_sep = {\n     sep: Option<token::Token>,\n     trailing_sep_allowed: bool\n@@ -51,6 +53,8 @@ pub impl Parser {\n                    + token_to_str(self.reader, self.token) + ~\"`\");\n     }\n \n+    // expect and consume the token t. Signal an error if\n+    // the next token is not t.\n     fn expect(t: token::Token) {\n         if self.token == t {\n             self.bump();\n@@ -88,6 +92,8 @@ pub impl Parser {\n         return self.parse_ident();\n     }\n \n+    // consume token 'tok' if it exists. Returns true if the given\n+    // token was present, false otherwise.\n     fn eat(tok: token::Token) -> bool {\n         return if self.token == tok { self.bump(); true } else { false };\n     }\n@@ -185,6 +191,8 @@ pub impl Parser {\n         }\n     }\n \n+    // expect and consume a GT. if a >> is seen, replace it\n+    // with a single > and continue.\n     fn expect_gt() {\n         if self.token == token::GT {\n             self.bump();\n@@ -202,16 +210,19 @@ pub impl Parser {\n         }\n     }\n \n+    // parse a sequence bracketed by '<' and '>', stopping\n+    // before the '>'.\n     fn parse_seq_to_before_gt<T: Copy>(sep: Option<token::Token>,\n                                        f: fn(Parser) -> T) -> ~[T] {\n         let mut first = true;\n         let mut v = ~[];\n         while self.token != token::GT\n+            // wait... isn't this going to eat a whole '>>' ?\n             && self.token != token::BINOP(token::SHR) {\n             match sep {\n               Some(ref t) => {\n                 if first { first = false; }\n-                else { self.expect((*t)); }\n+                else { self.expect(*t); }\n               }\n               _ => ()\n             }\n@@ -229,6 +240,7 @@ pub impl Parser {\n         return v;\n     }\n \n+    // parse a sequence bracketed by '<' and '>'\n     fn parse_seq_lt_gt<T: Copy>(sep: Option<token::Token>,\n                                 f: fn(Parser) -> T) -> spanned<~[T]> {\n         let lo = self.span.lo;\n@@ -239,14 +251,19 @@ pub impl Parser {\n         return spanned(lo, hi, result);\n     }\n \n+    // parse a sequence, including the closing delimiter. The function\n+    // f must consume tokens until reaching the next separator or\n+    // closing bracket.\n     fn parse_seq_to_end<T: Copy>(ket: token::Token, sep: seq_sep,\n                                  f: fn(Parser) -> T) -> ~[T] {\n         let val = self.parse_seq_to_before_end(ket, sep, f);\n         self.bump();\n         return val;\n     }\n \n-\n+    // parse a sequence, not including the closing delimiter. The function\n+    // f must consume tokens until reaching the next separator or\n+    // closing bracket.\n     fn parse_seq_to_before_end<T: Copy>(ket: token::Token, sep: seq_sep,\n                                         f: fn(Parser) -> T) -> ~[T] {\n         let mut first: bool = true;\n@@ -255,7 +272,7 @@ pub impl Parser {\n             match sep.sep {\n               Some(ref t) => {\n                 if first { first = false; }\n-                else { self.expect((*t)); }\n+                else { self.expect(*t); }\n               }\n               _ => ()\n             }\n@@ -265,6 +282,9 @@ pub impl Parser {\n         return v;\n     }\n \n+    // parse a sequence, including the closing delimiter. The function\n+    // f must consume tokens until reaching the next separator or\n+    // closing bracket.\n     fn parse_unspanned_seq<T: Copy>(bra: token::Token,\n                                     ket: token::Token,\n                                     sep: seq_sep,"}, {"sha": "b863e2bd0e494b932ed8262106d9d764b7941ead", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 46, "deletions": 1, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=25c4676dfa805e027564116b9c37fee7aeaf1cc4", "patch": "@@ -183,7 +183,6 @@ pub fn new_parser_from_file(sess: parse_sess,\n           let srdr = lexer::new_string_reader(sess.span_diagnostic,\n                                               filemap,\n                                               sess.interner);\n-\n           Ok(Parser(sess, cfg, srdr as reader))\n \n       }\n@@ -222,3 +221,49 @@ pub fn new_parser_from_tts(sess: parse_sess, cfg: ast::crate_cfg,\n     return Parser(sess, cfg, trdr as reader)\n }\n \n+\n+#[cfg(test)]\n+mod test {\n+    use super::*;\n+    use std::serialize::Encodable;\n+    use std;\n+    use core::dvec;\n+    use core::str;\n+    use util::testing::*;\n+\n+    #[test] fn to_json_str (val: Encodable<std::json::Encoder>) -> ~str {\n+        let bw = @io::BytesWriter {bytes: dvec::DVec(), pos: 0};\n+        val.encode(~std::json::Encoder(bw as io::Writer));\n+        str::from_bytes(bw.bytes.data)\n+    }\n+\n+    #[test] fn alltts () {\n+        let tts = parse_tts_from_source_str(\n+            ~\"bogofile\",\n+            @~\"fn foo (x : int) { x; }\",\n+            ~[],\n+            new_parse_sess(None));\n+        check_equal(to_json_str(tts as Encodable::<std::json::Encoder>),\n+                    //[[\"tt_tok\",[\"IDENT\",\"fn\"]]]\n+                    ~\"abc\"\n+                   );\n+        let ast1 = new_parser_from_tts(new_parse_sess(None),~[],tts)\n+            .parse_item(~[]);\n+        let ast2 = parse_item_from_source_str(\n+            ~\"bogofile\",\n+            @~\"fn foo (x : int) { x; }\",\n+            ~[],~[],\n+            new_parse_sess(None));\n+        check_equal(ast1,ast2);\n+    }\n+}\n+\n+//\n+// Local Variables:\n+// mode: rust\n+// fill-column: 78;\n+// indent-tabs-mode: nil\n+// c-basic-offset: 4\n+// buffer-file-coding-system: utf-8-unix\n+// End:\n+//"}, {"sha": "3c1f306ff079e40316c673b75cd76fab69e6b76f", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 28, "deletions": 15, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=25c4676dfa805e027564116b9c37fee7aeaf1cc4", "patch": "@@ -182,7 +182,8 @@ pure fn maybe_append(+lhs: ~[attribute], rhs: Option<~[attribute]>)\n \n /* ident is handled by common.rs */\n \n-pub fn Parser(sess: parse_sess,\n+pub fn Parser(sess: parse_sess\n+              ,\n               cfg: ast::crate_cfg,\n               +rdr: reader) -> Parser {\n \n@@ -1238,6 +1239,8 @@ pub impl Parser {\n         return e;\n     }\n \n+    // parse an optional separator followed by a kleene-style\n+    // repetition token (+ or *).\n     fn parse_sep_and_zerok() -> (Option<token::Token>, bool) {\n         if self.token == token::BINOP(token::STAR)\n             || self.token == token::BINOP(token::PLUS) {\n@@ -1258,20 +1261,18 @@ pub impl Parser {\n         }\n     }\n \n+    // parse a single token tree from the input.\n     fn parse_token_tree() -> token_tree {\n         maybe_whole!(deref self, nt_tt);\n \n-        fn parse_tt_tok(p: Parser, delim_ok: bool) -> token_tree {\n+        fn parse_non_delim_tt_tok(p: Parser) -> token_tree {\n             maybe_whole!(deref p, nt_tt);\n             match p.token {\n               token::RPAREN | token::RBRACE | token::RBRACKET\n-              if !delim_ok => {\n+              => {\n                 p.fatal(~\"incorrect close delimiter: `\"\n                            + token_to_str(p.reader, p.token) + ~\"`\");\n               }\n-              token::EOF => {\n-                p.fatal(~\"file ended in the middle of a macro invocation\");\n-              }\n               /* we ought to allow different depths of unquotation */\n               token::DOLLAR if p.quote_depth > 0u => {\n                 p.bump();\n@@ -1282,32 +1283,43 @@ pub impl Parser {\n                                           seq_sep_none(),\n                                           |p| p.parse_token_tree());\n                     let (s, z) = p.parse_sep_and_zerok();\n-                    return tt_seq(mk_sp(sp.lo ,p.span.hi), seq.node, s, z);\n+                    tt_seq(mk_sp(sp.lo ,p.span.hi), seq.node, s, z)\n                 } else {\n-                    return tt_nonterminal(sp, p.parse_ident());\n+                    tt_nonterminal(sp, p.parse_ident())\n                 }\n               }\n-              _ => { /* ok */ }\n+              _ => {\n+                  parse_any_tt_tok(p)\n+              }\n             }\n+        }\n+\n+        // turn the next token into a tt_tok:\n+        fn parse_any_tt_tok(p: Parser) -> token_tree{\n             let res = tt_tok(p.span, p.token);\n             p.bump();\n-            return res;\n+            res\n         }\n \n-        return match self.token {\n+        match self.token {\n+          token::EOF => {\n+                self.fatal(~\"file ended in the middle of a macro invocation\");\n+          }\n           token::LPAREN | token::LBRACE | token::LBRACKET => {\n               // tjc: ??????\n             let ket = token::flip_delimiter(copy self.token);\n             tt_delim(vec::append(\n-                ~[parse_tt_tok(self, true)],\n+                // the open delimiter:\n+                ~[parse_any_tt_tok(self)],\n                 vec::append(\n                     self.parse_seq_to_before_end(\n                         ket, seq_sep_none(),\n                         |p| p.parse_token_tree()),\n-                    ~[parse_tt_tok(self, true)])))\n+                    // the close delimiter:\n+                    ~[parse_any_tt_tok(self)])))\n           }\n-          _ => parse_tt_tok(self, false)\n-        };\n+          _ => parse_non_delim_tt_tok(self)\n+        }\n     }\n \n     fn parse_all_token_trees() -> ~[token_tree] {\n@@ -3999,6 +4011,7 @@ pub impl Parser {\n     }\n }\n \n+\n //\n // Local Variables:\n // mode: rust"}, {"sha": "1f8b04630e2651e3f64619d0f668b08c11862964", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25c4676dfa805e027564116b9c37fee7aeaf1cc4/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=25c4676dfa805e027564116b9c37fee7aeaf1cc4", "patch": "@@ -86,6 +86,7 @@ pub enum Token {\n     LIT_STR(ast::ident),\n \n     /* Name components */\n+    // an identifier contains an \"is_mod_name\" boolean.\n     IDENT(ast::ident, bool),\n     UNDERSCORE,\n     LIFETIME(ast::ident),"}]}