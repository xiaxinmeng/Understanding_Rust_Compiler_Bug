{"sha": "ffe23475cba4b933475715ff72ca0be6aea0a398", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZmZTIzNDc1Y2JhNGI5MzM0NzU3MTVmZjcyY2EwYmU2YWVhMGEzOTg=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-08T17:20:00Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-08T17:36:20Z"}, "message": "syntax: Keep full `Token`s for `macro_rules` separators", "tree": {"sha": "8e997af213f2bd840371b705b25f0ccf6e204c44", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8e997af213f2bd840371b705b25f0ccf6e204c44"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ffe23475cba4b933475715ff72ca0be6aea0a398", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ffe23475cba4b933475715ff72ca0be6aea0a398", "html_url": "https://github.com/rust-lang/rust/commit/ffe23475cba4b933475715ff72ca0be6aea0a398", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ffe23475cba4b933475715ff72ca0be6aea0a398/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5c45343f11fbf93cf4e15568aee3ff3f2f287466", "url": "https://api.github.com/repos/rust-lang/rust/commits/5c45343f11fbf93cf4e15568aee3ff3f2f287466", "html_url": "https://github.com/rust-lang/rust/commit/5c45343f11fbf93cf4e15568aee3ff3f2f287466"}], "stats": {"total": 69, "additions": 32, "deletions": 37}, "files": [{"sha": "1c7fdf995e15a0a3abe46426d05d1447d36f3ae9", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=ffe23475cba4b933475715ff72ca0be6aea0a398", "patch": "@@ -199,7 +199,7 @@ struct MatcherPos<'root, 'tt: 'root> {\n     seq_op: Option<quoted::KleeneOp>,\n \n     /// The separator if we are in a repetition.\n-    sep: Option<TokenKind>,\n+    sep: Option<Token>,\n \n     /// The \"parent\" matcher position if we are in a repetition. That is, the matcher position just\n     /// before we enter the sequence."}, {"sha": "b7fbfd60ed740d5a895b4606f3ff583778db324f", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=ffe23475cba4b933475715ff72ca0be6aea0a398", "patch": "@@ -17,7 +17,7 @@ use crate::symbol::{Symbol, kw, sym};\n use crate::tokenstream::{DelimSpan, TokenStream, TokenTree};\n \n use errors::FatalError;\n-use syntax_pos::{Span, DUMMY_SP, symbol::Ident};\n+use syntax_pos::{Span, symbol::Ident};\n use log::debug;\n \n use rustc_data_structures::fx::{FxHashMap};\n@@ -266,17 +266,19 @@ pub fn compile(\n     let argument_gram = vec![\n         quoted::TokenTree::Sequence(DelimSpan::dummy(), Lrc::new(quoted::SequenceRepetition {\n             tts: vec![\n-                quoted::TokenTree::MetaVarDecl(DUMMY_SP, lhs_nm, ast::Ident::from_str(\"tt\")),\n-                quoted::TokenTree::token(token::FatArrow, DUMMY_SP),\n-                quoted::TokenTree::MetaVarDecl(DUMMY_SP, rhs_nm, ast::Ident::from_str(\"tt\")),\n+                quoted::TokenTree::MetaVarDecl(def.span, lhs_nm, ast::Ident::from_str(\"tt\")),\n+                quoted::TokenTree::token(token::FatArrow, def.span),\n+                quoted::TokenTree::MetaVarDecl(def.span, rhs_nm, ast::Ident::from_str(\"tt\")),\n             ],\n-            separator: Some(if body.legacy { token::Semi } else { token::Comma }),\n+            separator: Some(Token::new(\n+                if body.legacy { token::Semi } else { token::Comma }, def.span\n+            )),\n             op: quoted::KleeneOp::OneOrMore,\n             num_captures: 2,\n         })),\n         // to phase into semicolon-termination instead of semicolon-separation\n         quoted::TokenTree::Sequence(DelimSpan::dummy(), Lrc::new(quoted::SequenceRepetition {\n-            tts: vec![quoted::TokenTree::token(token::Semi, DUMMY_SP)],\n+            tts: vec![quoted::TokenTree::token(token::Semi, def.span)],\n             separator: None,\n             op: quoted::KleeneOp::ZeroOrMore,\n             num_captures: 0\n@@ -608,9 +610,8 @@ impl FirstSets {\n                         // If the sequence contents can be empty, then the first\n                         // token could be the separator token itself.\n \n-                        if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n-                                                        subfirst.maybe_empty) {\n-                            first.add_one_maybe(TokenTree::token(sep.clone(), sp.entire()));\n+                        if let (Some(sep), true) = (&seq_rep.separator, subfirst.maybe_empty) {\n+                            first.add_one_maybe(TokenTree::Token(sep.clone()));\n                         }\n \n                         // Reverse scan: Sequence comes before `first`.\n@@ -658,9 +659,8 @@ impl FirstSets {\n                             // If the sequence contents can be empty, then the first\n                             // token could be the separator token itself.\n \n-                            if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n-                                                            subfirst.maybe_empty) {\n-                                first.add_one_maybe(TokenTree::token(sep.clone(), sp.entire()));\n+                            if let (Some(sep), true) = (&seq_rep.separator, subfirst.maybe_empty) {\n+                                first.add_one_maybe(TokenTree::Token(sep.clone()));\n                             }\n \n                             assert!(first.maybe_empty);\n@@ -851,7 +851,7 @@ fn check_matcher_core(sess: &ParseSess,\n                 // against SUFFIX\n                 continue 'each_token;\n             }\n-            TokenTree::Sequence(sp, ref seq_rep) => {\n+            TokenTree::Sequence(_, ref seq_rep) => {\n                 suffix_first = build_suffix_first();\n                 // The trick here: when we check the interior, we want\n                 // to include the separator (if any) as a potential\n@@ -864,9 +864,9 @@ fn check_matcher_core(sess: &ParseSess,\n                 // work of cloning it? But then again, this way I may\n                 // get a \"tighter\" span?\n                 let mut new;\n-                let my_suffix = if let Some(ref u) = seq_rep.separator {\n+                let my_suffix = if let Some(sep) = &seq_rep.separator {\n                     new = suffix_first.clone();\n-                    new.add_one_maybe(TokenTree::token(u.clone(), sp.entire()));\n+                    new.add_one_maybe(TokenTree::Token(sep.clone()));\n                     &new\n                 } else {\n                     &suffix_first"}, {"sha": "8f8aa586070d55b14e8638472b784121005c6326", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=ffe23475cba4b933475715ff72ca0be6aea0a398", "patch": "@@ -59,7 +59,7 @@ pub struct SequenceRepetition {\n     /// The sequence of token trees\n     pub tts: Vec<TokenTree>,\n     /// The optional separator\n-    pub separator: Option<TokenKind>,\n+    pub separator: Option<Token>,\n     /// Whether the sequence can be repeated zero (*), or one or more times (+)\n     pub op: KleeneOp,\n     /// The number of `Match`s that appear in the sequence (and subsequences)\n@@ -424,7 +424,7 @@ fn parse_sep_and_kleene_op<I>(\n     attrs: &[ast::Attribute],\n     edition: Edition,\n     macro_node_id: NodeId,\n-) -> (Option<TokenKind>, KleeneOp)\n+) -> (Option<Token>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {\n@@ -449,7 +449,7 @@ fn parse_sep_and_kleene_op_2015<I>(\n     _features: &Features,\n     _attrs: &[ast::Attribute],\n     macro_node_id: NodeId,\n-) -> (Option<TokenKind>, KleeneOp)\n+) -> (Option<Token>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {\n@@ -502,7 +502,7 @@ where\n                              a hard error in an upcoming edition\",\n                         );\n \n-                        return (Some(token::Question), op);\n+                        return (Some(Token::new(token::Question, op1_span)), op);\n                     }\n \n                     // #2 is a random token (this is an error) :(\n@@ -541,7 +541,7 @@ where\n             }\n \n             // #2 is a KleeneOp :D\n-            Ok(Ok((op, _))) => return (Some(token.kind), op),\n+            Ok(Ok((op, _))) => return (Some(token), op),\n \n             // #2 is a random token :(\n             Ok(Err(token)) => token.span,\n@@ -567,7 +567,7 @@ fn parse_sep_and_kleene_op_2018<I>(\n     sess: &ParseSess,\n     _features: &Features,\n     _attrs: &[ast::Attribute],\n-) -> (Option<TokenKind>, KleeneOp)\n+) -> (Option<Token>, KleeneOp)\n where\n     I: Iterator<Item = tokenstream::TokenTree>,\n {\n@@ -596,7 +596,7 @@ where\n             }\n \n             // #2 is a KleeneOp :D\n-            Ok(Ok((op, _))) => return (Some(token.kind), op),\n+            Ok(Ok((op, _))) => return (Some(token), op),\n \n             // #2 is a random token :(\n             Ok(Err(token)) => token.span,"}, {"sha": "3408cefdf4274d81432e802a37e875ee276d9b2b", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 7, "deletions": 12, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=ffe23475cba4b933475715ff72ca0be6aea0a398", "patch": "@@ -4,11 +4,10 @@ use crate::ext::expand::Marker;\n use crate::ext::tt::macro_parser::{MatchedNonterminal, MatchedSeq, NamedMatch};\n use crate::ext::tt::quoted;\n use crate::mut_visit::noop_visit_tt;\n-use crate::parse::token::{self, NtTT, TokenKind};\n+use crate::parse::token::{self, NtTT, Token, TokenKind};\n use crate::tokenstream::{DelimSpan, TokenStream, TokenTree, TreeAndJoint};\n \n use smallvec::{smallvec, SmallVec};\n-use syntax_pos::DUMMY_SP;\n \n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sync::Lrc;\n@@ -18,7 +17,7 @@ use std::rc::Rc;\n /// An iterator over the token trees in a delimited token tree (`{ ... }`) or a sequence (`$(...)`).\n enum Frame {\n     Delimited { forest: Lrc<quoted::Delimited>, idx: usize, span: DelimSpan },\n-    Sequence { forest: Lrc<quoted::SequenceRepetition>, idx: usize, sep: Option<TokenKind> },\n+    Sequence { forest: Lrc<quoted::SequenceRepetition>, idx: usize, sep: Option<Token> },\n }\n \n impl Frame {\n@@ -109,17 +108,13 @@ pub fn transcribe(\n         else {\n             // Otherwise, if we have just reached the end of a sequence and we can keep repeating,\n             // go back to the beginning of the sequence.\n-            if let Frame::Sequence { ref mut idx, ref sep, .. } = *stack.last_mut().unwrap() {\n-                let (ref mut repeat_idx, repeat_len) = *repeats.last_mut().unwrap();\n+            if let Frame::Sequence { idx, sep, .. } = stack.last_mut().unwrap() {\n+                let (repeat_idx, repeat_len) = repeats.last_mut().unwrap();\n                 *repeat_idx += 1;\n-                if *repeat_idx < repeat_len {\n+                if repeat_idx < repeat_len {\n                     *idx = 0;\n-                    if let Some(sep) = sep.clone() {\n-                        let prev_span = match result.last() {\n-                            Some((tt, _)) => tt.span(),\n-                            None => DUMMY_SP,\n-                        };\n-                        result.push(TokenTree::token(sep, prev_span).into());\n+                    if let Some(sep) = sep {\n+                        result.push(TokenTree::Token(sep.clone()).into());\n                     }\n                     continue;\n                 }"}, {"sha": "542486927dfd115f2bb7d9b33c5369ca2a83cc3b", "filename": "src/test/ui/macros/macro-input-future-proofing.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Ftest%2Fui%2Fmacros%2Fmacro-input-future-proofing.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/ffe23475cba4b933475715ff72ca0be6aea0a398/src%2Ftest%2Fui%2Fmacros%2Fmacro-input-future-proofing.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fmacros%2Fmacro-input-future-proofing.stderr?ref=ffe23475cba4b933475715ff72ca0be6aea0a398", "patch": "@@ -55,10 +55,10 @@ LL |     ($($a:ty, $b:ty)* -) => ();\n    = note: allowed there are: `{`, `[`, `=>`, `,`, `>`, `=`, `:`, `;`, `|`, `as` or `where`\n \n error: `$ty:ty` is followed by `-`, which is not allowed for `ty` fragments\n-  --> $DIR/macro-input-future-proofing.rs:18:7\n+  --> $DIR/macro-input-future-proofing.rs:18:15\n    |\n LL |     ($($ty:ty)-+) => ();\n-   |       ^^^^^^^^ not allowed after `ty` fragments\n+   |               ^ not allowed after `ty` fragments\n    |\n    = note: allowed there are: `{`, `[`, `=>`, `,`, `>`, `=`, `:`, `;`, `|`, `as` or `where`\n "}]}