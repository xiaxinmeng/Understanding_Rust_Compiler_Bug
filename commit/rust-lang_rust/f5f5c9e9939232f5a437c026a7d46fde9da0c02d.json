{"sha": "f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY1ZjVjOWU5OTM5MjMyZjVhNDM3YzAyNmE3ZDQ2ZmRlOWRhMGMwMmQ=", "commit": {"author": {"name": "Tyler Mandry", "email": "tmandry@gmail.com", "date": "2019-10-18T20:48:18Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-10-18T20:48:18Z"}, "message": "Rollup merge of #65455 - nnethercote:avoid-unnecessary-TokenTree-to-TokenStream-conversions, r=petrochenkov\n\nAvoid unnecessary `TokenTree` to `TokenStream` conversions\n\nA `TokenStream` contains any number of `TokenTrees`. Therefore, a single `TokenTree` can be promoted to a `TokenStream`. But doing so costs two allocations: one for the single-element `Vec`, and one for the `Lrc`. (An `IsJoint` value also must be added; the default is `NonJoint`.)\n\nThe current code converts `TokenTree`s to `TokenStream`s unnecessarily in a few places. This PR removes some of these unnecessary conversions, both simplifying the code and speeding it up.\n\nr? @petrochenkov", "tree": {"sha": "265b0bfdc5a48324f4b8af70e0e32180c7c45dbc", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/265b0bfdc5a48324f4b8af70e0e32180c7c45dbc"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJdqiUTCRBK7hj4Ov3rIwAAdHIIAEh+aRDz9ADJ8/TknEYv0Vbs\n+zeqxMu/SrDgu74Xm9WJgm811oKB8Wuos8cdMfQ1GrY5KzHOQV88dNWjXEFmgEP1\np33MnGDi5wqjv7ix7JdLa9LMqli65VjdgQhNuXIYW9VqDPSN6w3eNaf7Ur21fDMr\nYBCpMEKIAyWnJY4Ih5f8ymb08OlKo2hyEVIDzop98AKN8DPN76BlZkFM04x1MTRz\n24PWYcWPTORwoqe010luOTyppL3o0AZjckAaURZEFrDtaCbfctwohGoAHeNoyQ8M\nW72N7zQFLGSf/k26Hec3diy3FwmvHA7Lkq/nqTPUzCjsJXTbseh4h9uGwUW4uBc=\n=Ryi1\n-----END PGP SIGNATURE-----\n", "payload": "tree 265b0bfdc5a48324f4b8af70e0e32180c7c45dbc\nparent 8f8a23f6422e78d1a30b40cb623e0b7b690218e9\nparent e4ec4a6da350ae2564971ae826a1bc3ec9a41988\nauthor Tyler Mandry <tmandry@gmail.com> 1571431698 -0700\ncommitter GitHub <noreply@github.com> 1571431698 -0700\n\nRollup merge of #65455 - nnethercote:avoid-unnecessary-TokenTree-to-TokenStream-conversions, r=petrochenkov\n\nAvoid unnecessary `TokenTree` to `TokenStream` conversions\n\nA `TokenStream` contains any number of `TokenTrees`. Therefore, a single `TokenTree` can be promoted to a `TokenStream`. But doing so costs two allocations: one for the single-element `Vec`, and one for the `Lrc`. (An `IsJoint` value also must be added; the default is `NonJoint`.)\n\nThe current code converts `TokenTree`s to `TokenStream`s unnecessarily in a few places. This PR removes some of these unnecessary conversions, both simplifying the code and speeding it up.\n\nr? @petrochenkov\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "html_url": "https://github.com/rust-lang/rust/commit/f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/comments", "author": {"login": "tmandry", "id": 2280544, "node_id": "MDQ6VXNlcjIyODA1NDQ=", "avatar_url": "https://avatars.githubusercontent.com/u/2280544?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmandry", "html_url": "https://github.com/tmandry", "followers_url": "https://api.github.com/users/tmandry/followers", "following_url": "https://api.github.com/users/tmandry/following{/other_user}", "gists_url": "https://api.github.com/users/tmandry/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmandry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmandry/subscriptions", "organizations_url": "https://api.github.com/users/tmandry/orgs", "repos_url": "https://api.github.com/users/tmandry/repos", "events_url": "https://api.github.com/users/tmandry/events{/privacy}", "received_events_url": "https://api.github.com/users/tmandry/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8f8a23f6422e78d1a30b40cb623e0b7b690218e9", "url": "https://api.github.com/repos/rust-lang/rust/commits/8f8a23f6422e78d1a30b40cb623e0b7b690218e9", "html_url": "https://github.com/rust-lang/rust/commit/8f8a23f6422e78d1a30b40cb623e0b7b690218e9"}, {"sha": "e4ec4a6da350ae2564971ae826a1bc3ec9a41988", "url": "https://api.github.com/repos/rust-lang/rust/commits/e4ec4a6da350ae2564971ae826a1bc3ec9a41988", "html_url": "https://github.com/rust-lang/rust/commit/e4ec4a6da350ae2564971ae826a1bc3ec9a41988"}], "stats": {"total": 77, "additions": 41, "deletions": 36}, "files": [{"sha": "4aec50408812f27a0fed880b3a095a68d8efe0ba", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 28, "deletions": 18, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "patch": "@@ -22,7 +22,7 @@ use crate::ptr::P;\n use crate::sess::ParseSess;\n use crate::symbol::{sym, Symbol};\n use crate::ThinVec;\n-use crate::tokenstream::{TokenStream, TokenTree, DelimSpan};\n+use crate::tokenstream::{DelimSpan, TokenStream, TokenTree, TreeAndJoint};\n use crate::GLOBALS;\n \n use log::debug;\n@@ -463,7 +463,7 @@ pub fn first_attr_value_str_by_name(attrs: &[Attribute], name: Symbol) -> Option\n }\n \n impl MetaItem {\n-    fn tokens(&self) -> TokenStream {\n+    fn token_trees_and_joints(&self) -> Vec<TreeAndJoint> {\n         let mut idents = vec![];\n         let mut last_pos = BytePos(0 as u32);\n         for (i, segment) in self.path.segments.iter().enumerate() {\n@@ -477,8 +477,8 @@ impl MetaItem {\n             idents.push(TokenTree::Token(Token::from_ast_ident(segment.ident)).into());\n             last_pos = segment.ident.span.hi();\n         }\n-        self.kind.tokens(self.span).append_to_tree_and_joint_vec(&mut idents);\n-        TokenStream::new(idents)\n+        idents.extend(self.kind.token_trees_and_joints(self.span));\n+        idents\n     }\n \n     fn from_tokens<I>(tokens: &mut iter::Peekable<I>) -> Option<MetaItem>\n@@ -537,31 +537,41 @@ impl MetaItem {\n }\n \n impl MetaItemKind {\n-    pub fn tokens(&self, span: Span) -> TokenStream {\n+    pub fn token_trees_and_joints(&self, span: Span) -> Vec<TreeAndJoint> {\n         match *self {\n-            MetaItemKind::Word => TokenStream::default(),\n+            MetaItemKind::Word => vec![],\n             MetaItemKind::NameValue(ref lit) => {\n-                let mut vec = vec![TokenTree::token(token::Eq, span).into()];\n-                lit.tokens().append_to_tree_and_joint_vec(&mut vec);\n-                TokenStream::new(vec)\n+                vec![\n+                    TokenTree::token(token::Eq, span).into(),\n+                    lit.token_tree().into(),\n+                ]\n             }\n             MetaItemKind::List(ref list) => {\n                 let mut tokens = Vec::new();\n                 for (i, item) in list.iter().enumerate() {\n                     if i > 0 {\n                         tokens.push(TokenTree::token(token::Comma, span).into());\n                     }\n-                    item.tokens().append_to_tree_and_joint_vec(&mut tokens);\n+                    tokens.extend(item.token_trees_and_joints())\n                 }\n-                TokenTree::Delimited(\n-                    DelimSpan::from_single(span),\n-                    token::Paren,\n-                    TokenStream::new(tokens).into(),\n-                ).into()\n+                vec![\n+                    TokenTree::Delimited(\n+                        DelimSpan::from_single(span),\n+                        token::Paren,\n+                        TokenStream::new(tokens).into(),\n+                    ).into()\n+                ]\n             }\n         }\n     }\n \n+    // Premature conversions of `TokenTree`s to `TokenStream`s can hurt\n+    // performance. Do not use this function if `token_trees_and_joints()` can\n+    // be used instead.\n+    pub fn tokens(&self, span: Span) -> TokenStream {\n+        TokenStream::new(self.token_trees_and_joints(span))\n+    }\n+\n     fn from_tokens<I>(tokens: &mut iter::Peekable<I>) -> Option<MetaItemKind>\n         where I: Iterator<Item = TokenTree>,\n     {\n@@ -603,10 +613,10 @@ impl NestedMetaItem {\n         }\n     }\n \n-    fn tokens(&self) -> TokenStream {\n+    fn token_trees_and_joints(&self) -> Vec<TreeAndJoint> {\n         match *self {\n-            NestedMetaItem::MetaItem(ref item) => item.tokens(),\n-            NestedMetaItem::Literal(ref lit) => lit.tokens(),\n+            NestedMetaItem::MetaItem(ref item) => item.token_trees_and_joints(),\n+            NestedMetaItem::Literal(ref lit) => vec![lit.token_tree().into()],\n         }\n     }\n "}, {"sha": "7952e293a532d72eef0914ddc03908ac19f328bf", "filename": "src/libsyntax/parse/literal.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Fparse%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Fparse%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fliteral.rs?ref=f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "patch": "@@ -3,7 +3,7 @@\n use crate::ast::{self, Lit, LitKind};\n use crate::parse::token::{self, Token};\n use crate::symbol::{kw, sym, Symbol};\n-use crate::tokenstream::{TokenStream, TokenTree};\n+use crate::tokenstream::TokenTree;\n \n use log::debug;\n use rustc_data_structures::sync::Lrc;\n@@ -216,13 +216,13 @@ impl Lit {\n         Lit { token: kind.to_lit_token(), kind, span }\n     }\n \n-    /// Losslessly convert an AST literal into a token stream.\n-    crate fn tokens(&self) -> TokenStream {\n+    /// Losslessly convert an AST literal into a token tree.\n+    crate fn token_tree(&self) -> TokenTree {\n         let token = match self.token.kind {\n             token::Bool => token::Ident(self.token.symbol, false),\n             _ => token::Literal(self.token),\n         };\n-        TokenTree::token(token, self.span).into()\n+        TokenTree::token(token, self.span)\n     }\n }\n "}, {"sha": "6bbd8be0cb9827d4c15c88cc77727d465ece5afa", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "patch": "@@ -285,10 +285,10 @@ impl TokenCursor {\n             token::NoDelim,\n             &if doc_comment_style(&name.as_str()) == AttrStyle::Inner {\n                 [TokenTree::token(token::Pound, sp), TokenTree::token(token::Not, sp), body]\n-                    .iter().cloned().collect::<TokenStream>().into()\n+                    .iter().cloned().collect::<TokenStream>()\n             } else {\n                 [TokenTree::token(token::Pound, sp), body]\n-                    .iter().cloned().collect::<TokenStream>().into()\n+                    .iter().cloned().collect::<TokenStream>()\n             },\n         )));\n "}, {"sha": "188a144cac9de93a6a2706e59848ad68409b30a3", "filename": "src/libsyntax/parse/parser/attr.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Fparse%2Fparser%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Fparse%2Fparser%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser%2Fattr.rs?ref=f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "patch": "@@ -6,7 +6,6 @@ use crate::tokenstream::{TokenStream, TokenTree};\n use crate::source_map::Span;\n \n use log::debug;\n-use smallvec::smallvec;\n \n #[derive(Debug)]\n enum InnerAttributeParsePolicy<'a> {\n@@ -193,15 +192,15 @@ impl<'a> Parser<'a> {\n                         is_interpolated_expr = true;\n                     }\n                 }\n-                let tokens = if is_interpolated_expr {\n+                let token_tree = if is_interpolated_expr {\n                     // We need to accept arbitrary interpolated expressions to continue\n                     // supporting things like `doc = $expr` that work on stable.\n                     // Non-literal interpolated expressions are rejected after expansion.\n-                    self.parse_token_tree().into()\n+                    self.parse_token_tree()\n                 } else {\n-                    self.parse_unsuffixed_lit()?.tokens()\n+                    self.parse_unsuffixed_lit()?.token_tree()\n                 };\n-                TokenStream::from_streams(smallvec![eq.into(), tokens])\n+                TokenStream::new(vec![eq.into(), token_tree.into()])\n             } else {\n                 TokenStream::default()\n             };"}, {"sha": "ac155556cdae25d541ca79c82b947409d0c3b58f", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 3, "deletions": 7, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f5c9e9939232f5a437c026a7d46fde9da0c02d/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=f5f5c9e9939232f5a437c026a7d46fde9da0c02d", "patch": "@@ -202,9 +202,9 @@ impl From<TokenTree> for TreeAndJoint {\n     }\n }\n \n-impl<T: Into<TokenStream>> iter::FromIterator<T> for TokenStream {\n-    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n-        TokenStream::from_streams(iter.into_iter().map(Into::into).collect::<SmallVec<_>>())\n+impl iter::FromIterator<TokenTree> for TokenStream {\n+    fn from_iter<I: IntoIterator<Item = TokenTree>>(iter: I) -> Self {\n+        TokenStream::new(iter.into_iter().map(Into::into).collect::<Vec<TreeAndJoint>>())\n     }\n }\n \n@@ -271,10 +271,6 @@ impl TokenStream {\n         }\n     }\n \n-    pub fn append_to_tree_and_joint_vec(self, vec: &mut Vec<TreeAndJoint>) {\n-        vec.extend(self.0.iter().cloned());\n-    }\n-\n     pub fn trees(&self) -> Cursor {\n         self.clone().into_trees()\n     }"}]}