{"sha": "256df83f642ff3cfff82b266edc7d9bbe3fd2ecc", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI1NmRmODNmNjQyZmYzY2ZmZjgyYjI2NmVkYzdkOWJiZTNmZDJlY2M=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-07-03T09:52:22Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-07-04T06:08:39Z"}, "message": "remove peek_span_src_raw from StringReader", "tree": {"sha": "8f21dda4685b6a9dd276035e7257634fd7a36e0a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8f21dda4685b6a9dd276035e7257634fd7a36e0a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc", "html_url": "https://github.com/rust-lang/rust/commit/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e9dc95c86ecb296e0a2067ca5813043f380b9ea6", "url": "https://api.github.com/repos/rust-lang/rust/commits/e9dc95c86ecb296e0a2067ca5813043f380b9ea6", "html_url": "https://github.com/rust-lang/rust/commit/e9dc95c86ecb296e0a2067ca5813043f380b9ea6"}], "stats": {"total": 115, "additions": 46, "deletions": 69}, "files": [{"sha": "fb9919d777db17da75d88f1f78eb2a3806291840", "filename": "src/librustc_save_analysis/span_utils.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Fspan_utils.rs?ref=256df83f642ff3cfff82b266edc7d9bbe3fd2ecc", "patch": "@@ -53,7 +53,7 @@ impl<'a> SpanUtils<'a> {\n     pub fn sub_span_of_token(&self, span: Span, tok: TokenKind) -> Option<Span> {\n         let mut toks = self.retokenise_span(span);\n         loop {\n-            let next = toks.real_token();\n+            let next = toks.next_token();\n             if next == token::Eof {\n                 return None;\n             }"}, {"sha": "8b43b88fbac9ae9de3abb8f3c6715843126f0936", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 37, "deletions": 61, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=256df83f642ff3cfff82b266edc7d9bbe3fd2ecc", "patch": "@@ -38,8 +38,6 @@ pub struct StringReader<'a> {\n     crate source_file: Lrc<syntax_pos::SourceFile>,\n     /// Stop reading src at this index.\n     crate end_src_index: usize,\n-    // cached:\n-    peek_span_src_raw: Span,\n     fatal_errs: Vec<DiagnosticBuilder<'a>>,\n     // cache a direct reference to the source text, so that we don't have to\n     // retrieve it via `self.source_file.src.as_ref().unwrap()` all the time.\n@@ -59,7 +57,7 @@ impl<'a> StringReader<'a> {\n         (real, raw)\n     }\n \n-    fn unwrap_or_abort(&mut self, res: Result<Token, ()>) -> Token {\n+    fn unwrap_or_abort<T>(&mut self, res: Result<T, ()>) -> T {\n         match res {\n             Ok(tok) => tok,\n             Err(_) => {\n@@ -69,36 +67,52 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    fn next_token(&mut self) -> Token where Self: Sized {\n-        let res = self.try_next_token();\n-        self.unwrap_or_abort(res)\n-    }\n-\n     /// Returns the next token. EFFECT: advances the string_reader.\n     pub fn try_next_token(&mut self) -> Result<Token, ()> {\n-        assert!(self.fatal_errs.is_empty());\n-        self.advance_token()\n+        let (token, _raw_span) = self.try_next_token_with_raw_span()?;\n+        Ok(token)\n     }\n \n-    fn try_real_token(&mut self) -> Result<Token, ()> {\n-        let mut t = self.try_next_token()?;\n+    pub fn next_token(&mut self) -> Token {\n+        let res = self.try_next_token();\n+        self.unwrap_or_abort(res)\n+    }\n+\n+    fn try_real_token(&mut self) -> Result<(Token, Span), ()> {\n         loop {\n-            match t.kind {\n-                token::Whitespace | token::Comment | token::Shebang(_) => {\n-                    t = self.try_next_token()?;\n-                }\n-                _ => break,\n+            let t = self.try_next_token_with_raw_span()?;\n+            match t.0.kind {\n+                token::Whitespace | token::Comment | token::Shebang(_) => continue,\n+                _ => return Ok(t),\n             }\n         }\n-\n-        Ok(t)\n     }\n \n-    pub fn real_token(&mut self) -> Token {\n+    fn real_token(&mut self) -> (Token, Span) {\n         let res = self.try_real_token();\n         self.unwrap_or_abort(res)\n     }\n \n+    fn try_next_token_with_raw_span(&mut self) -> Result<(Token, Span), ()> {\n+        assert!(self.fatal_errs.is_empty());\n+        match self.scan_whitespace_or_comment() {\n+            Some(comment) => {\n+                let raw_span = comment.span;\n+                Ok((comment, raw_span))\n+            }\n+            None => {\n+                let (kind, start_pos, end_pos) = if self.is_eof() {\n+                    (token::Eof, self.source_file.end_pos, self.source_file.end_pos)\n+                } else {\n+                    let start_pos = self.pos;\n+                    (self.next_token_inner()?, start_pos, self.pos)\n+                };\n+                let (real, raw) = self.mk_sp_and_raw(start_pos, end_pos);\n+                Ok((Token::new(kind, real), raw))\n+            }\n+        }\n+    }\n+\n     #[inline]\n     fn is_eof(&self) -> bool {\n         self.ch.is_none()\n@@ -141,7 +155,6 @@ impl<'a> StringReader<'a> {\n                override_span: Option<Span>) -> Self {\n         let mut sr = StringReader::new_raw_internal(sess, source_file, override_span);\n         sr.bump();\n-\n         sr\n     }\n \n@@ -162,7 +175,6 @@ impl<'a> StringReader<'a> {\n             ch: Some('\\n'),\n             source_file,\n             end_src_index: src.len(),\n-            peek_span_src_raw: syntax_pos::DUMMY_SP,\n             src,\n             fatal_errs: Vec::new(),\n             override_span,\n@@ -172,12 +184,8 @@ impl<'a> StringReader<'a> {\n     pub fn new_or_buffered_errs(sess: &'a ParseSess,\n                                 source_file: Lrc<syntax_pos::SourceFile>,\n                                 override_span: Option<Span>) -> Result<Self, Vec<Diagnostic>> {\n-        let mut sr = StringReader::new_raw(sess, source_file, override_span);\n-        if sr.advance_token().is_err() {\n-            Err(sr.buffer_fatal_errors())\n-        } else {\n-            Ok(sr)\n-        }\n+        let sr = StringReader::new_raw(sess, source_file, override_span);\n+        Ok(sr)\n     }\n \n     pub fn retokenize(sess: &'a ParseSess, mut span: Span) -> Self {\n@@ -197,11 +205,6 @@ impl<'a> StringReader<'a> {\n \n         sr.bump();\n \n-        if sr.advance_token().is_err() {\n-            sr.emit_fatal_errors();\n-            FatalError.raise();\n-        }\n-\n         sr\n     }\n \n@@ -257,28 +260,6 @@ impl<'a> StringReader<'a> {\n         self.sess.span_diagnostic.struct_span_fatal(self.mk_sp(from_pos, to_pos), &m[..])\n     }\n \n-    /// Advance peek_token to refer to the next token, and\n-    /// possibly update the interner.\n-    fn advance_token(&mut self) -> Result<Token, ()> {\n-        match self.scan_whitespace_or_comment() {\n-            Some(comment) => {\n-                self.peek_span_src_raw = comment.span;\n-                Ok(comment)\n-            }\n-            None => {\n-                let (kind, start_pos, end_pos) = if self.is_eof() {\n-                    (token::Eof, self.source_file.end_pos, self.source_file.end_pos)\n-                } else {\n-                    let start_pos = self.pos;\n-                    (self.next_token_inner()?, start_pos, self.pos)\n-                };\n-                let (real, raw) = self.mk_sp_and_raw(start_pos, end_pos);\n-                self.peek_span_src_raw = raw;\n-                Ok(Token::new(kind, real))\n-            }\n-        }\n-    }\n-\n     #[inline]\n     fn src_index(&self, pos: BytePos) -> usize {\n         (pos - self.source_file.start_pos).to_usize()\n@@ -1447,12 +1428,7 @@ mod tests {\n                  teststr: String)\n                  -> StringReader<'a> {\n         let sf = sm.new_source_file(PathBuf::from(teststr.clone()).into(), teststr);\n-        let mut sr = StringReader::new_raw(sess, sf, None);\n-        if sr.advance_token().is_err() {\n-            sr.emit_fatal_errors();\n-            FatalError.raise();\n-        }\n-        sr\n+        StringReader::new_raw(sess, sf, None)\n     }\n \n     #[test]"}, {"sha": "9593a50bdd2a12556c4133d6e4693fd85fa7a6b6", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/256df83f642ff3cfff82b266edc7d9bbe3fd2ecc/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=256df83f642ff3cfff82b266edc7d9bbe3fd2ecc", "patch": "@@ -1,4 +1,4 @@\n-use syntax_pos::Span;\n+use syntax_pos::{Span, DUMMY_SP};\n \n use crate::print::pprust::token_to_string;\n use crate::parse::lexer::{StringReader, UnmatchedBrace};\n@@ -11,6 +11,7 @@ impl<'a> StringReader<'a> {\n         let mut tt_reader = TokenTreesReader {\n             string_reader: self,\n             token: Token::dummy(),\n+            raw_span: DUMMY_SP,\n             open_braces: Vec::new(),\n             unmatched_braces: Vec::new(),\n             matching_delim_spans: Vec::new(),\n@@ -24,6 +25,7 @@ impl<'a> StringReader<'a> {\n struct TokenTreesReader<'a> {\n     string_reader: StringReader<'a>,\n     token: Token,\n+    raw_span: Span,\n     /// Stack of open delimiters and their spans. Used for error message.\n     open_braces: Vec<(token::DelimToken, Span)>,\n     unmatched_braces: Vec<UnmatchedBrace>,\n@@ -206,18 +208,17 @@ impl<'a> TokenTreesReader<'a> {\n                 // Note that testing for joint-ness here is done via the raw\n                 // source span as the joint-ness is a property of the raw source\n                 // rather than wanting to take `override_span` into account.\n-                // Additionally, we actually check if the *next* pair of tokens\n-                // is joint, but this is equivalent to checking the current pair.\n-                let raw = self.string_reader.peek_span_src_raw;\n+                let raw_span = self.raw_span;\n                 self.real_token();\n-                let is_joint = raw.hi() == self.string_reader.peek_span_src_raw.lo()\n-                    && self.token.is_op();\n+                let is_joint = raw_span.hi() == self.raw_span.lo() && self.token.is_op();\n                 Ok((tt, if is_joint { Joint } else { NonJoint }))\n             }\n         }\n     }\n \n     fn real_token(&mut self) {\n-        self.token = self.string_reader.real_token();\n+        let (token, raw_span) = self.string_reader.real_token();\n+        self.token = token;\n+        self.raw_span = raw_span;\n     }\n }"}]}