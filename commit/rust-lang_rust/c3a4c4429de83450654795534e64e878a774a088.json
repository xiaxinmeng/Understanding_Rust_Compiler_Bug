{"sha": "c3a4c4429de83450654795534e64e878a774a088", "node_id": "MDY6Q29tbWl0NzI0NzEyOmMzYTRjNDQyOWRlODM0NTA2NTQ3OTU1MzRlNjRlODc4YTc3NGEwODg=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-02-18T17:35:10Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-02-26T11:55:50Z"}, "message": "Refactor primary IDE API\n\nThis introduces the new type -- Semantics.\nSemantics maps SyntaxNodes to various semantic info, such as type,\nname resolution or macro expansions.\n\nTo do so, Semantics maintains a HashMap which maps every node it saw\nto the file from which the node originated. This is enough to get all\nthe necessary hir bits just from syntax.", "tree": {"sha": "12d89798f61b276f8bd640db07276a7d4e92b1c2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/12d89798f61b276f8bd640db07276a7d4e92b1c2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c3a4c4429de83450654795534e64e878a774a088", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c3a4c4429de83450654795534e64e878a774a088", "html_url": "https://github.com/rust-lang/rust/commit/c3a4c4429de83450654795534e64e878a774a088", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c3a4c4429de83450654795534e64e878a774a088/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "04deae3dba7c9b7054f7a1d64e4b93a05aecc132", "url": "https://api.github.com/repos/rust-lang/rust/commits/04deae3dba7c9b7054f7a1d64e4b93a05aecc132", "html_url": "https://github.com/rust-lang/rust/commit/04deae3dba7c9b7054f7a1d64e4b93a05aecc132"}], "stats": {"total": 2006, "additions": 1027, "deletions": 979}, "files": [{"sha": "c25d2e3239b830d01787323fea3fe9a12405bed0", "filename": "crates/ra_assists/src/assist_ctx.rs", "status": "modified", "additions": 11, "deletions": 29, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fassist_ctx.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fassist_ctx.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fassist_ctx.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,6 +1,6 @@\n //! This module defines `AssistCtx` -- the API surface that is exposed to assists.\n-use hir::{InFile, SourceAnalyzer, SourceBinder};\n-use ra_db::{FileRange, SourceDatabase};\n+use hir::Semantics;\n+use ra_db::FileRange;\n use ra_fmt::{leading_indent, reindent};\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n@@ -74,29 +74,23 @@ pub(crate) type AssistHandler = fn(AssistCtx) -> Option<Assist>;\n /// Note, however, that we don't actually use such two-phase logic at the\n /// moment, because the LSP API is pretty awkward in this place, and it's much\n /// easier to just compute the edit eagerly :-)\n-#[derive(Debug)]\n+#[derive(Clone)]\n pub(crate) struct AssistCtx<'a> {\n+    pub(crate) sema: &'a Semantics<'a, RootDatabase>,\n     pub(crate) db: &'a RootDatabase,\n     pub(crate) frange: FileRange,\n     source_file: SourceFile,\n     should_compute_edit: bool,\n }\n \n-impl Clone for AssistCtx<'_> {\n-    fn clone(&self) -> Self {\n-        AssistCtx {\n-            db: self.db,\n-            frange: self.frange,\n-            source_file: self.source_file.clone(),\n-            should_compute_edit: self.should_compute_edit,\n-        }\n-    }\n-}\n-\n impl<'a> AssistCtx<'a> {\n-    pub fn new(db: &RootDatabase, frange: FileRange, should_compute_edit: bool) -> AssistCtx {\n-        let parse = db.parse(frange.file_id);\n-        AssistCtx { db, frange, source_file: parse.tree(), should_compute_edit }\n+    pub fn new(\n+        sema: &'a Semantics<'a, RootDatabase>,\n+        frange: FileRange,\n+        should_compute_edit: bool,\n+    ) -> AssistCtx<'a> {\n+        let source_file = sema.parse(frange.file_id);\n+        AssistCtx { sema, db: sema.db, frange, source_file, should_compute_edit }\n     }\n \n     pub(crate) fn add_assist(\n@@ -138,18 +132,6 @@ impl<'a> AssistCtx<'a> {\n     pub(crate) fn covering_element(&self) -> SyntaxElement {\n         find_covering_element(self.source_file.syntax(), self.frange.range)\n     }\n-    pub(crate) fn source_binder(&self) -> SourceBinder<'a, RootDatabase> {\n-        SourceBinder::new(self.db)\n-    }\n-    pub(crate) fn source_analyzer(\n-        &self,\n-        node: &SyntaxNode,\n-        offset: Option<TextUnit>,\n-    ) -> SourceAnalyzer {\n-        let src = InFile::new(self.frange.file_id.into(), node);\n-        self.source_binder().analyze(src, offset)\n-    }\n-\n     pub(crate) fn covering_node_for_range(&self, range: TextRange) -> SyntaxElement {\n         find_covering_element(self.source_file.syntax(), range)\n     }"}, {"sha": "7846e979810078ad4b37165a9c3830dec7fcd6bb", "filename": "crates/ra_assists/src/ast_transform.rs", "status": "modified", "additions": 30, "deletions": 35, "changes": 65, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fast_transform.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fast_transform.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fast_transform.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,15 +1,12 @@\n //! `AstTransformer`s are functions that replace nodes in an AST and can be easily combined.\n use rustc_hash::FxHashMap;\n \n-use hir::{InFile, PathResolution};\n+use hir::{PathResolution, SemanticsScope};\n use ra_ide_db::RootDatabase;\n use ra_syntax::ast::{self, AstNode};\n \n pub trait AstTransform<'a> {\n-    fn get_substitution(\n-        &self,\n-        node: InFile<&ra_syntax::SyntaxNode>,\n-    ) -> Option<ra_syntax::SyntaxNode>;\n+    fn get_substitution(&self, node: &ra_syntax::SyntaxNode) -> Option<ra_syntax::SyntaxNode>;\n \n     fn chain_before(self, other: Box<dyn AstTransform<'a> + 'a>) -> Box<dyn AstTransform<'a> + 'a>;\n     fn or<T: AstTransform<'a> + 'a>(self, other: T) -> Box<dyn AstTransform<'a> + 'a>\n@@ -23,10 +20,7 @@ pub trait AstTransform<'a> {\n struct NullTransformer;\n \n impl<'a> AstTransform<'a> for NullTransformer {\n-    fn get_substitution(\n-        &self,\n-        _node: InFile<&ra_syntax::SyntaxNode>,\n-    ) -> Option<ra_syntax::SyntaxNode> {\n+    fn get_substitution(&self, _node: &ra_syntax::SyntaxNode) -> Option<ra_syntax::SyntaxNode> {\n         None\n     }\n     fn chain_before(self, other: Box<dyn AstTransform<'a> + 'a>) -> Box<dyn AstTransform<'a> + 'a> {\n@@ -35,14 +29,16 @@ impl<'a> AstTransform<'a> for NullTransformer {\n }\n \n pub struct SubstituteTypeParams<'a> {\n-    db: &'a RootDatabase,\n+    source_scope: &'a SemanticsScope<'a, RootDatabase>,\n     substs: FxHashMap<hir::TypeParam, ast::TypeRef>,\n     previous: Box<dyn AstTransform<'a> + 'a>,\n }\n \n impl<'a> SubstituteTypeParams<'a> {\n     pub fn for_trait_impl(\n+        source_scope: &'a SemanticsScope<'a, RootDatabase>,\n         db: &'a RootDatabase,\n+        // FIXME: there's implicit invariant that `trait_` and  `source_scope` match...\n         trait_: hir::Trait,\n         impl_block: ast::ImplBlock,\n     ) -> SubstituteTypeParams<'a> {\n@@ -56,7 +52,7 @@ impl<'a> SubstituteTypeParams<'a> {\n             .zip(substs.into_iter())\n             .collect();\n         return SubstituteTypeParams {\n-            db,\n+            source_scope,\n             substs: substs_by_param,\n             previous: Box::new(NullTransformer),\n         };\n@@ -80,15 +76,15 @@ impl<'a> SubstituteTypeParams<'a> {\n     }\n     fn get_substitution_inner(\n         &self,\n-        node: InFile<&ra_syntax::SyntaxNode>,\n+        node: &ra_syntax::SyntaxNode,\n     ) -> Option<ra_syntax::SyntaxNode> {\n-        let type_ref = ast::TypeRef::cast(node.value.clone())?;\n+        let type_ref = ast::TypeRef::cast(node.clone())?;\n         let path = match &type_ref {\n             ast::TypeRef::PathType(path_type) => path_type.path()?,\n             _ => return None,\n         };\n-        let analyzer = hir::SourceAnalyzer::new(self.db, node, None);\n-        let resolution = analyzer.resolve_path(self.db, &path)?;\n+        let path = hir::Path::from_ast(path)?;\n+        let resolution = self.source_scope.resolve_hir_path(&path)?;\n         match resolution {\n             hir::PathResolution::TypeParam(tp) => Some(self.substs.get(&tp)?.syntax().clone()),\n             _ => None,\n@@ -97,10 +93,7 @@ impl<'a> SubstituteTypeParams<'a> {\n }\n \n impl<'a> AstTransform<'a> for SubstituteTypeParams<'a> {\n-    fn get_substitution(\n-        &self,\n-        node: InFile<&ra_syntax::SyntaxNode>,\n-    ) -> Option<ra_syntax::SyntaxNode> {\n+    fn get_substitution(&self, node: &ra_syntax::SyntaxNode) -> Option<ra_syntax::SyntaxNode> {\n         self.get_substitution_inner(node).or_else(|| self.previous.get_substitution(node))\n     }\n     fn chain_before(self, other: Box<dyn AstTransform<'a> + 'a>) -> Box<dyn AstTransform<'a> + 'a> {\n@@ -109,29 +102,34 @@ impl<'a> AstTransform<'a> for SubstituteTypeParams<'a> {\n }\n \n pub struct QualifyPaths<'a> {\n+    target_scope: &'a SemanticsScope<'a, RootDatabase>,\n+    source_scope: &'a SemanticsScope<'a, RootDatabase>,\n     db: &'a RootDatabase,\n-    from: Option<hir::Module>,\n     previous: Box<dyn AstTransform<'a> + 'a>,\n }\n \n impl<'a> QualifyPaths<'a> {\n-    pub fn new(db: &'a RootDatabase, from: Option<hir::Module>) -> Self {\n-        Self { db, from, previous: Box::new(NullTransformer) }\n+    pub fn new(\n+        target_scope: &'a SemanticsScope<'a, RootDatabase>,\n+        source_scope: &'a SemanticsScope<'a, RootDatabase>,\n+        db: &'a RootDatabase,\n+    ) -> Self {\n+        Self { target_scope, source_scope, db, previous: Box::new(NullTransformer) }\n     }\n \n     fn get_substitution_inner(\n         &self,\n-        node: InFile<&ra_syntax::SyntaxNode>,\n+        node: &ra_syntax::SyntaxNode,\n     ) -> Option<ra_syntax::SyntaxNode> {\n         // FIXME handle value ns?\n-        let from = self.from?;\n-        let p = ast::Path::cast(node.value.clone())?;\n+        let from = self.target_scope.module()?;\n+        let p = ast::Path::cast(node.clone())?;\n         if p.segment().and_then(|s| s.param_list()).is_some() {\n             // don't try to qualify `Fn(Foo) -> Bar` paths, they are in prelude anyway\n             return None;\n         }\n-        let analyzer = hir::SourceAnalyzer::new(self.db, node, None);\n-        let resolution = analyzer.resolve_path(self.db, &p)?;\n+        let hir_path = hir::Path::from_ast(p.clone());\n+        let resolution = self.source_scope.resolve_hir_path(&hir_path?)?;\n         match resolution {\n             PathResolution::Def(def) => {\n                 let found_path = from.find_use_path(self.db, def)?;\n@@ -140,7 +138,7 @@ impl<'a> QualifyPaths<'a> {\n                 let type_args = p\n                     .segment()\n                     .and_then(|s| s.type_arg_list())\n-                    .map(|arg_list| apply(self, node.with_value(arg_list)));\n+                    .map(|arg_list| apply(self, arg_list));\n                 if let Some(type_args) = type_args {\n                     let last_segment = path.segment().unwrap();\n                     path = path.with_segment(last_segment.with_type_args(type_args))\n@@ -157,11 +155,11 @@ impl<'a> QualifyPaths<'a> {\n     }\n }\n \n-pub fn apply<'a, N: AstNode>(transformer: &dyn AstTransform<'a>, node: InFile<N>) -> N {\n-    let syntax = node.value.syntax();\n+pub fn apply<'a, N: AstNode>(transformer: &dyn AstTransform<'a>, node: N) -> N {\n+    let syntax = node.syntax();\n     let result = ra_syntax::algo::replace_descendants(syntax, &|element| match element {\n         ra_syntax::SyntaxElement::Node(n) => {\n-            let replacement = transformer.get_substitution(node.with_value(&n))?;\n+            let replacement = transformer.get_substitution(&n)?;\n             Some(replacement.into())\n         }\n         _ => None,\n@@ -170,10 +168,7 @@ pub fn apply<'a, N: AstNode>(transformer: &dyn AstTransform<'a>, node: InFile<N>\n }\n \n impl<'a> AstTransform<'a> for QualifyPaths<'a> {\n-    fn get_substitution(\n-        &self,\n-        node: InFile<&ra_syntax::SyntaxNode>,\n-    ) -> Option<ra_syntax::SyntaxNode> {\n+    fn get_substitution(&self, node: &ra_syntax::SyntaxNode) -> Option<ra_syntax::SyntaxNode> {\n         self.get_substitution_inner(node).or_else(|| self.previous.get_substitution(node))\n     }\n     fn chain_before(self, other: Box<dyn AstTransform<'a> + 'a>) -> Box<dyn AstTransform<'a> + 'a> {"}, {"sha": "a63ef48b1d060505d3782f2a2a551aa6ce2f93c0", "filename": "crates/ra_assists/src/handlers/add_explicit_type.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_explicit_type.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_explicit_type.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_explicit_type.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -51,14 +51,13 @@ pub(crate) fn add_explicit_type(ctx: AssistCtx) -> Option<Assist> {\n         }\n     }\n     // Infer type\n-    let db = ctx.db;\n-    let analyzer = ctx.source_analyzer(stmt.syntax(), None);\n-    let ty = analyzer.type_of(db, &expr)?;\n+    let ty = ctx.sema.type_of_expr(&expr)?;\n     // Assist not applicable if the type is unknown\n     if ty.contains_unknown() {\n         return None;\n     }\n \n+    let db = ctx.db;\n     ctx.add_assist(\n         AssistId(\"add_explicit_type\"),\n         format!(\"Insert explicit type '{}'\", ty.display(db)),"}, {"sha": "4005014bdf3ff4f719167fafca7215b04c4ee39b", "filename": "crates/ra_assists/src/handlers/add_missing_impl_members.rs", "status": "modified", "additions": 11, "deletions": 18, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_missing_impl_members.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_missing_impl_members.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_missing_impl_members.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,4 +1,4 @@\n-use hir::{HasSource, InFile};\n+use hir::HasSource;\n use ra_syntax::{\n     ast::{self, edit, make, AstNode, NameOwner},\n     SmolStr,\n@@ -104,9 +104,7 @@ fn add_missing_impl_members_inner(\n     let impl_node = ctx.find_node_at_offset::<ast::ImplBlock>()?;\n     let impl_item_list = impl_node.item_list()?;\n \n-    let analyzer = ctx.source_analyzer(impl_node.syntax(), None);\n-\n-    let trait_ = resolve_target_trait(ctx.db, &analyzer, &impl_node)?;\n+    let trait_ = resolve_target_trait(&ctx.sema, &impl_node)?;\n \n     let def_name = |item: &ast::ImplItem| -> Option<SmolStr> {\n         match item {\n@@ -117,7 +115,7 @@ fn add_missing_impl_members_inner(\n         .map(|it| it.text().clone())\n     };\n \n-    let missing_items = get_missing_impl_items(ctx.db, &analyzer, &impl_node)\n+    let missing_items = get_missing_impl_items(&ctx.sema, &impl_node)\n         .iter()\n         .map(|i| match i {\n             hir::AssocItem::Function(i) => ast::ImplItem::FnDef(i.source(ctx.db).value),\n@@ -138,23 +136,17 @@ fn add_missing_impl_members_inner(\n         return None;\n     }\n \n-    let db = ctx.db;\n-    let file_id = ctx.frange.file_id;\n-    let trait_file_id = trait_.source(db).file_id;\n+    let sema = ctx.sema;\n \n     ctx.add_assist(AssistId(assist_id), label, |edit| {\n         let n_existing_items = impl_item_list.impl_items().count();\n-        let module = hir::SourceAnalyzer::new(\n-            db,\n-            hir::InFile::new(file_id.into(), impl_node.syntax()),\n-            None,\n-        )\n-        .module();\n-        let ast_transform = QualifyPaths::new(db, module)\n-            .or(SubstituteTypeParams::for_trait_impl(db, trait_, impl_node));\n+        let source_scope = sema.scope_for_def(trait_);\n+        let target_scope = sema.scope(impl_item_list.syntax());\n+        let ast_transform = QualifyPaths::new(&target_scope, &source_scope, sema.db)\n+            .or(SubstituteTypeParams::for_trait_impl(&source_scope, sema.db, trait_, impl_node));\n         let items = missing_items\n             .into_iter()\n-            .map(|it| ast_transform::apply(&*ast_transform, InFile::new(trait_file_id, it)))\n+            .map(|it| ast_transform::apply(&*ast_transform, it))\n             .map(|it| match it {\n                 ast::ImplItem::FnDef(def) => ast::ImplItem::FnDef(add_body(def)),\n                 _ => it,\n@@ -181,9 +173,10 @@ fn add_body(fn_def: ast::FnDef) -> ast::FnDef {\n \n #[cfg(test)]\n mod tests {\n-    use super::*;\n     use crate::helpers::{check_assist, check_assist_not_applicable};\n \n+    use super::*;\n+\n     #[test]\n     fn test_add_missing_impl_members() {\n         check_assist("}, {"sha": "166e907fb40e0f10800b62cd3589006ef7083674", "filename": "crates/ra_assists/src/handlers/add_new.rs", "status": "modified", "additions": 3, "deletions": 8, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_new.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_new.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fadd_new.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,5 +1,5 @@\n use format_buf::format;\n-use hir::{Adt, InFile};\n+use hir::Adt;\n use join_to_string::join;\n use ra_syntax::{\n     ast::{\n@@ -133,16 +133,11 @@ fn find_struct_impl(ctx: &AssistCtx, strukt: &ast::StructDef) -> Option<Option<a\n     let module = strukt.syntax().ancestors().find(|node| {\n         ast::Module::can_cast(node.kind()) || ast::SourceFile::can_cast(node.kind())\n     })?;\n-    let mut sb = ctx.source_binder();\n \n-    let struct_def = {\n-        let src = InFile { file_id: ctx.frange.file_id.into(), value: strukt.clone() };\n-        sb.to_def(src)?\n-    };\n+    let struct_def = ctx.sema.to_def(strukt)?;\n \n     let block = module.descendants().filter_map(ast::ImplBlock::cast).find_map(|impl_blk| {\n-        let src = InFile { file_id: ctx.frange.file_id.into(), value: impl_blk.clone() };\n-        let blk = sb.to_def(src)?;\n+        let blk = ctx.sema.to_def(&impl_blk)?;\n \n         // FIXME: handle e.g. `struct S<T>; impl<U> S<U> {}`\n         // (we currently use the wrong type parameter)"}, {"sha": "edf0cf6d0e41e20e8b424f62e0ee088e37901eb2", "filename": "crates/ra_assists/src/handlers/auto_import.rs", "status": "modified", "additions": 14, "deletions": 28, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fauto_import.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fauto_import.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fhandlers%2Fauto_import.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -3,8 +3,8 @@ use crate::{\n     insert_use_statement, AssistId,\n };\n use hir::{\n-    db::HirDatabase, AsAssocItem, AssocItemContainer, ModPath, Module, ModuleDef, PathResolution,\n-    SourceAnalyzer, Trait, Type,\n+    AsAssocItem, AssocItemContainer, ModPath, Module, ModuleDef, PathResolution, Semantics, Trait,\n+    Type,\n };\n use ra_ide_db::{imports_locator::ImportsLocator, RootDatabase};\n use ra_prof::profile;\n@@ -78,14 +78,9 @@ impl AutoImportAssets {\n \n     fn for_method_call(method_call: ast::MethodCallExpr, ctx: &AssistCtx) -> Option<Self> {\n         let syntax_under_caret = method_call.syntax().to_owned();\n-        let source_analyzer = ctx.source_analyzer(&syntax_under_caret, None);\n-        let module_with_name_to_import = source_analyzer.module()?;\n+        let module_with_name_to_import = ctx.sema.scope(&syntax_under_caret).module()?;\n         Some(Self {\n-            import_candidate: ImportCandidate::for_method_call(\n-                &method_call,\n-                &source_analyzer,\n-                ctx.db,\n-            )?,\n+            import_candidate: ImportCandidate::for_method_call(&ctx.sema, &method_call)?,\n             module_with_name_to_import,\n             syntax_under_caret,\n         })\n@@ -97,14 +92,9 @@ impl AutoImportAssets {\n             return None;\n         }\n \n-        let source_analyzer = ctx.source_analyzer(&syntax_under_caret, None);\n-        let module_with_name_to_import = source_analyzer.module()?;\n+        let module_with_name_to_import = ctx.sema.scope(&syntax_under_caret).module()?;\n         Some(Self {\n-            import_candidate: ImportCandidate::for_regular_path(\n-                &path_under_caret,\n-                &source_analyzer,\n-                ctx.db,\n-            )?,\n+            import_candidate: ImportCandidate::for_regular_path(&ctx.sema, &path_under_caret)?,\n             module_with_name_to_import,\n             syntax_under_caret,\n         })\n@@ -229,25 +219,23 @@ enum ImportCandidate {\n \n impl ImportCandidate {\n     fn for_method_call(\n+        sema: &Semantics<RootDatabase>,\n         method_call: &ast::MethodCallExpr,\n-        source_analyzer: &SourceAnalyzer,\n-        db: &impl HirDatabase,\n     ) -> Option<Self> {\n-        if source_analyzer.resolve_method_call(method_call).is_some() {\n+        if sema.resolve_method_call(method_call).is_some() {\n             return None;\n         }\n         Some(Self::TraitMethod(\n-            source_analyzer.type_of(db, &method_call.expr()?)?,\n+            sema.type_of_expr(&method_call.expr()?)?,\n             method_call.name_ref()?.syntax().to_string(),\n         ))\n     }\n \n     fn for_regular_path(\n+        sema: &Semantics<RootDatabase>,\n         path_under_caret: &ast::Path,\n-        source_analyzer: &SourceAnalyzer,\n-        db: &impl HirDatabase,\n     ) -> Option<Self> {\n-        if source_analyzer.resolve_path(db, path_under_caret).is_some() {\n+        if sema.resolve_path(path_under_caret).is_some() {\n             return None;\n         }\n \n@@ -256,17 +244,15 @@ impl ImportCandidate {\n             let qualifier_start = qualifier.syntax().descendants().find_map(ast::NameRef::cast)?;\n             let qualifier_start_path =\n                 qualifier_start.syntax().ancestors().find_map(ast::Path::cast)?;\n-            if let Some(qualifier_start_resolution) =\n-                source_analyzer.resolve_path(db, &qualifier_start_path)\n-            {\n+            if let Some(qualifier_start_resolution) = sema.resolve_path(&qualifier_start_path) {\n                 let qualifier_resolution = if qualifier_start_path == qualifier {\n                     qualifier_start_resolution\n                 } else {\n-                    source_analyzer.resolve_path(db, &qualifier)?\n+                    sema.resolve_path(&qualifier)?\n                 };\n                 if let PathResolution::Def(ModuleDef::Adt(assoc_item_path)) = qualifier_resolution {\n                     Some(ImportCandidate::TraitAssocItem(\n-                        assoc_item_path.ty(db),\n+                        assoc_item_path.ty(sema.db),\n                         segment.syntax().to_string(),\n                     ))\n                 } else {"}, {"sha": "e5d8c639d121e1a23915731ae384255858f72d2a", "filename": "crates/ra_assists/src/handlers/fill_match_arms.rs", "status": "modified", "additions": 8, "deletions": 15, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Ffill_match_arms.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Ffill_match_arms.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fhandlers%2Ffill_match_arms.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -2,10 +2,11 @@\n \n use std::iter;\n \n-use hir::{db::HirDatabase, Adt, HasSource};\n+use hir::{db::HirDatabase, Adt, HasSource, Semantics};\n use ra_syntax::ast::{self, edit::IndentLevel, make, AstNode, NameOwner};\n \n use crate::{Assist, AssistCtx, AssistId};\n+use ra_ide_db::RootDatabase;\n \n // Assist: fill_match_arms\n //\n@@ -46,10 +47,9 @@ pub(crate) fn fill_match_arms(ctx: AssistCtx) -> Option<Assist> {\n     };\n \n     let expr = match_expr.expr()?;\n-    let (enum_def, module) = {\n-        let analyzer = ctx.source_analyzer(expr.syntax(), None);\n-        (resolve_enum_def(ctx.db, &analyzer, &expr)?, analyzer.module()?)\n-    };\n+    let enum_def = resolve_enum_def(&ctx.sema, &expr)?;\n+    let module = ctx.sema.scope(expr.syntax()).module()?;\n+\n     let variants = enum_def.variants(ctx.db);\n     if variants.is_empty() {\n         return None;\n@@ -81,18 +81,11 @@ fn is_trivial(arm: &ast::MatchArm) -> bool {\n     }\n }\n \n-fn resolve_enum_def(\n-    db: &impl HirDatabase,\n-    analyzer: &hir::SourceAnalyzer,\n-    expr: &ast::Expr,\n-) -> Option<hir::Enum> {\n-    let expr_ty = analyzer.type_of(db, &expr)?;\n-\n-    let result = expr_ty.autoderef(db).find_map(|ty| match ty.as_adt() {\n+fn resolve_enum_def(sema: &Semantics<RootDatabase>, expr: &ast::Expr) -> Option<hir::Enum> {\n+    sema.type_of_expr(&expr)?.autoderef(sema.db).find_map(|ty| match ty.as_adt() {\n         Some(Adt::Enum(e)) => Some(e),\n         _ => None,\n-    });\n-    result\n+    })\n }\n \n fn build_pat("}, {"sha": "53a72309b1d2a6f70f3198a05fa10195cc6536b3", "filename": "crates/ra_assists/src/handlers/inline_local_variable.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Finline_local_variable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Fhandlers%2Finline_local_variable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fhandlers%2Finline_local_variable.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -44,8 +44,7 @@ pub(crate) fn inline_local_variable(ctx: AssistCtx) -> Option<Assist> {\n     } else {\n         let_stmt.syntax().text_range()\n     };\n-    let analyzer = ctx.source_analyzer(bind_pat.syntax(), None);\n-    let refs = analyzer.find_all_refs(&bind_pat);\n+    let refs = ctx.sema.find_all_refs(&bind_pat);\n     if refs.is_empty() {\n         return None;\n     };"}, {"sha": "c28a9b92b88293f9a1627251e64bb0f9fcfda902", "filename": "crates/ra_assists/src/lib.rs", "status": "modified", "additions": 8, "deletions": 3, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Flib.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -19,6 +19,7 @@ use ra_text_edit::TextEdit;\n \n pub(crate) use crate::assist_ctx::{Assist, AssistCtx, AssistHandler};\n pub use crate::handlers::replace_qualified_name_with_use::insert_use_statement;\n+use hir::Semantics;\n \n /// Unique identifier of the assist, should not be shown to the user\n /// directly.\n@@ -63,7 +64,8 @@ pub struct ResolvedAssist {\n /// Assists are returned in the \"unresolved\" state, that is only labels are\n /// returned, without actual edits.\n pub fn unresolved_assists(db: &RootDatabase, range: FileRange) -> Vec<AssistLabel> {\n-    let ctx = AssistCtx::new(db, range, false);\n+    let sema = Semantics::new(db);\n+    let ctx = AssistCtx::new(&sema, range, false);\n     handlers::all()\n         .iter()\n         .filter_map(|f| f(ctx.clone()))\n@@ -77,7 +79,8 @@ pub fn unresolved_assists(db: &RootDatabase, range: FileRange) -> Vec<AssistLabe\n /// Assists are returned in the \"resolved\" state, that is with edit fully\n /// computed.\n pub fn resolved_assists(db: &RootDatabase, range: FileRange) -> Vec<ResolvedAssist> {\n-    let ctx = AssistCtx::new(db, range, true);\n+    let sema = Semantics::new(db);\n+    let ctx = AssistCtx::new(&sema, range, true);\n     let mut a = handlers::all()\n         .iter()\n         .filter_map(|f| f(ctx.clone()))\n@@ -165,6 +168,7 @@ mod helpers {\n     use test_utils::{add_cursor, assert_eq_text, extract_range_or_offset, RangeOrOffset};\n \n     use crate::{AssistCtx, AssistHandler};\n+    use hir::Semantics;\n \n     pub(crate) fn with_single_file(text: &str) -> (RootDatabase, FileId) {\n         let (mut db, file_id) = RootDatabase::with_single_file(text);\n@@ -202,7 +206,8 @@ mod helpers {\n \n         let (db, file_id) = with_single_file(&before);\n         let frange = FileRange { file_id, range };\n-        let assist_ctx = AssistCtx::new(&db, frange, true);\n+        let sema = Semantics::new(&db);\n+        let assist_ctx = AssistCtx::new(&sema, frange, true);\n \n         match (assist(assist_ctx), expected) {\n             (Some(assist), ExpectedResult::After(after)) => {"}, {"sha": "92d3ed47144a23b03c79fbbd1092ca6e73c364b9", "filename": "crates/ra_assists/src/utils.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Futils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_assists%2Fsrc%2Futils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Futils.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,16 +1,15 @@\n //! Assorted functions shared by several assists.\n \n+use hir::Semantics;\n+use ra_ide_db::RootDatabase;\n use ra_syntax::{\n     ast::{self, make, NameOwner},\n     AstNode, T,\n };\n-\n-use hir::db::HirDatabase;\n use rustc_hash::FxHashSet;\n \n pub fn get_missing_impl_items(\n-    db: &impl HirDatabase,\n-    analyzer: &hir::SourceAnalyzer,\n+    sema: &Semantics<RootDatabase>,\n     impl_block: &ast::ImplBlock,\n ) -> Vec<hir::AssocItem> {\n     // Names must be unique between constants and functions. However, type aliases\n@@ -42,15 +41,17 @@ pub fn get_missing_impl_items(\n         }\n     }\n \n-    resolve_target_trait(db, analyzer, impl_block).map_or(vec![], |target_trait| {\n+    resolve_target_trait(sema, impl_block).map_or(vec![], |target_trait| {\n         target_trait\n-            .items(db)\n+            .items(sema.db)\n             .iter()\n             .filter(|i| match i {\n-                hir::AssocItem::Function(f) => !impl_fns_consts.contains(&f.name(db).to_string()),\n-                hir::AssocItem::TypeAlias(t) => !impl_type.contains(&t.name(db).to_string()),\n+                hir::AssocItem::Function(f) => {\n+                    !impl_fns_consts.contains(&f.name(sema.db).to_string())\n+                }\n+                hir::AssocItem::TypeAlias(t) => !impl_type.contains(&t.name(sema.db).to_string()),\n                 hir::AssocItem::Const(c) => c\n-                    .name(db)\n+                    .name(sema.db)\n                     .map(|n| !impl_fns_consts.contains(&n.to_string()))\n                     .unwrap_or_default(),\n             })\n@@ -60,8 +61,7 @@ pub fn get_missing_impl_items(\n }\n \n pub(crate) fn resolve_target_trait(\n-    db: &impl HirDatabase,\n-    analyzer: &hir::SourceAnalyzer,\n+    sema: &Semantics<RootDatabase>,\n     impl_block: &ast::ImplBlock,\n ) -> Option<hir::Trait> {\n     let ast_path = impl_block\n@@ -70,7 +70,7 @@ pub(crate) fn resolve_target_trait(\n         .and_then(ast::PathType::cast)?\n         .path()?;\n \n-    match analyzer.resolve_path(db, &ast_path) {\n+    match sema.resolve_path(&ast_path) {\n         Some(hir::PathResolution::Def(hir::ModuleDef::Trait(def))) => Some(def),\n         _ => None,\n     }"}, {"sha": "004a2185fc3c736a33863d82c537332b84407021", "filename": "crates/ra_hir/src/lib.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_hir%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_hir%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Flib.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -26,6 +26,7 @@ macro_rules! impl_froms {\n     }\n }\n \n+mod semantics;\n pub mod db;\n pub mod source_analyzer;\n pub mod source_binder;\n@@ -45,8 +46,8 @@ pub use crate::{\n         StructField, Trait, Type, TypeAlias, TypeParam, Union, VariantDef,\n     },\n     has_source::HasSource,\n-    source_analyzer::{PathResolution, ScopeEntryWithSyntax, SourceAnalyzer},\n-    source_binder::SourceBinder,\n+    semantics::{original_range, Semantics, SemanticsScope},\n+    source_analyzer::{PathResolution, ScopeEntryWithSyntax},\n };\n \n pub use hir_def::{"}, {"sha": "22a7e7588d927627ad5c164ee65277772536c1d9", "filename": "crates/ra_hir/src/semantics.rs", "status": "added", "additions": 335, "deletions": 0, "changes": 335, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsemantics.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -0,0 +1,335 @@\n+//! See `Semantics`.\n+\n+use std::{cell::RefCell, fmt, iter::successors};\n+\n+use hir_def::{\n+    resolver::{self, HasResolver, Resolver},\n+    TraitId,\n+};\n+use ra_db::{FileId, FileRange};\n+use ra_syntax::{ast, AstNode, SyntaxNode, SyntaxToken, TextRange, TextUnit};\n+use rustc_hash::{FxHashMap, FxHashSet};\n+\n+use crate::{\n+    db::HirDatabase,\n+    source_analyzer::{resolve_hir_path, ReferenceDescriptor, SourceAnalyzer},\n+    source_binder::{ChildContainer, SourceBinder, ToDef},\n+    Function, HirFileId, InFile, Local, MacroDef, Module, Name, Origin, Path, PathResolution,\n+    ScopeDef, StructField, Trait, Type, TypeParam, VariantDef,\n+};\n+use ra_prof::profile;\n+\n+/// Primary API to get semantic information, like types, from syntax trees.\n+pub struct Semantics<'db, DB> {\n+    pub db: &'db DB,\n+    pub(crate) sb: RefCell<SourceBinder>,\n+    cache: RefCell<FxHashMap<SyntaxNode, HirFileId>>,\n+}\n+\n+impl<DB> fmt::Debug for Semantics<'_, DB> {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        write!(f, \"Semantics {{ ... }}\")\n+    }\n+}\n+\n+impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n+    pub fn new(db: &DB) -> Semantics<DB> {\n+        let sb = RefCell::new(SourceBinder::new());\n+        Semantics { db, sb, cache: RefCell::default() }\n+    }\n+\n+    pub fn parse(&self, file_id: FileId) -> ast::SourceFile {\n+        let tree = self.db.parse(file_id).tree();\n+        self.cache(tree.syntax().clone(), file_id.into());\n+        tree\n+    }\n+\n+    pub fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n+        let macro_call = self.find_file(macro_call.syntax().clone()).with_value(macro_call);\n+        let sa = self.analyze2(macro_call.map(|it| it.syntax()), None);\n+        let file_id = sa.expand(self.db, macro_call)?;\n+        let node = self.db.parse_or_expand(file_id)?;\n+        self.cache(node.clone(), file_id);\n+        Some(node)\n+    }\n+\n+    pub fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n+        let parent = token.parent();\n+        let parent = self.find_file(parent);\n+        let sa = self.analyze2(parent.as_ref(), None);\n+\n+        let token = successors(Some(parent.with_value(token)), |token| {\n+            let macro_call = token.value.ancestors().find_map(ast::MacroCall::cast)?;\n+            let tt = macro_call.token_tree()?;\n+            if !token.value.text_range().is_subrange(&tt.syntax().text_range()) {\n+                return None;\n+            }\n+            let file_id = sa.expand(self.db, token.with_value(&macro_call))?;\n+            let token = file_id.expansion_info(self.db)?.map_token_down(token.as_ref())?;\n+\n+            self.cache(find_root(&token.value.parent()), token.file_id);\n+\n+            Some(token)\n+        })\n+        .last()\n+        .unwrap();\n+\n+        token.value\n+    }\n+\n+    pub fn original_range(&self, node: &SyntaxNode) -> FileRange {\n+        let node = self.find_file(node.clone());\n+        original_range(self.db, node.as_ref())\n+    }\n+\n+    pub fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n+        let node = self.find_file(node);\n+        node.ancestors_with_macros(self.db).map(|it| it.value)\n+    }\n+\n+    pub fn type_of_expr(&self, expr: &ast::Expr) -> Option<Type> {\n+        self.analyze(expr.syntax()).type_of(self.db, &expr)\n+    }\n+\n+    pub fn type_of_pat(&self, pat: &ast::Pat) -> Option<Type> {\n+        self.analyze(pat.syntax()).type_of_pat(self.db, &pat)\n+    }\n+\n+    pub fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n+        self.analyze(call.syntax()).resolve_method_call(call)\n+    }\n+\n+    pub fn resolve_field(&self, field: &ast::FieldExpr) -> Option<StructField> {\n+        self.analyze(field.syntax()).resolve_field(field)\n+    }\n+\n+    pub fn resolve_record_field(&self, field: &ast::RecordField) -> Option<StructField> {\n+        self.analyze(field.syntax()).resolve_record_field(field)\n+    }\n+\n+    pub fn resolve_record_literal(&self, record_lit: &ast::RecordLit) -> Option<VariantDef> {\n+        self.analyze(record_lit.syntax()).resolve_record_literal(record_lit)\n+    }\n+\n+    pub fn resolve_record_pattern(&self, record_pat: &ast::RecordPat) -> Option<VariantDef> {\n+        self.analyze(record_pat.syntax()).resolve_record_pattern(record_pat)\n+    }\n+\n+    pub fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<MacroDef> {\n+        let sa = self.analyze(macro_call.syntax());\n+        let macro_call = self.find_file(macro_call.syntax().clone()).with_value(macro_call);\n+        sa.resolve_macro_call(self.db, macro_call)\n+    }\n+\n+    pub fn resolve_path(&self, path: &ast::Path) -> Option<PathResolution> {\n+        self.analyze(path.syntax()).resolve_path(self.db, path)\n+    }\n+\n+    // FIXME: use this instead?\n+    // pub fn resolve_name_ref(&self, name_ref: &ast::NameRef) -> Option<???>;\n+\n+    pub fn to_def<T: ToDef + Clone>(&self, src: &T) -> Option<T::Def> {\n+        let src = self.find_file(src.syntax().clone()).with_value(src.clone());\n+        let mut sb = self.sb.borrow_mut();\n+        T::to_def(self.db, &mut sb, src)\n+    }\n+\n+    pub fn to_module_def(&self, file: FileId) -> Option<Module> {\n+        let mut sb = self.sb.borrow_mut();\n+        sb.to_module_def(self.db, file)\n+    }\n+\n+    pub fn scope(&self, node: &SyntaxNode) -> SemanticsScope<'db, DB> {\n+        let node = self.find_file(node.clone());\n+        let resolver = self.analyze2(node.as_ref(), None).resolver;\n+        SemanticsScope { db: self.db, resolver }\n+    }\n+\n+    pub fn scope_at_offset(&self, node: &SyntaxNode, offset: TextUnit) -> SemanticsScope<'db, DB> {\n+        let node = self.find_file(node.clone());\n+        let resolver = self.analyze2(node.as_ref(), Some(offset)).resolver;\n+        SemanticsScope { db: self.db, resolver }\n+    }\n+\n+    pub fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db, DB> {\n+        let resolver = def.id.resolver(self.db);\n+        SemanticsScope { db: self.db, resolver }\n+    }\n+\n+    // FIXME: we only use this in `inline_local_variable` assist, ideally, we\n+    // should switch to general reference search infra there.\n+    pub fn find_all_refs(&self, pat: &ast::BindPat) -> Vec<ReferenceDescriptor> {\n+        self.analyze(pat.syntax()).find_all_refs(pat)\n+    }\n+\n+    fn analyze(&self, node: &SyntaxNode) -> SourceAnalyzer {\n+        let src = self.find_file(node.clone());\n+        self.analyze2(src.as_ref(), None)\n+    }\n+\n+    fn analyze2(&self, src: InFile<&SyntaxNode>, offset: Option<TextUnit>) -> SourceAnalyzer {\n+        let _p = profile(\"Semantics::analyze2\");\n+\n+        let container = match self.sb.borrow_mut().find_container(self.db, src) {\n+            Some(it) => it,\n+            None => return SourceAnalyzer::new_for_resolver(Resolver::default(), src),\n+        };\n+\n+        let resolver = match container {\n+            ChildContainer::DefWithBodyId(def) => {\n+                return SourceAnalyzer::new_for_body(self.db, def, src, offset)\n+            }\n+            ChildContainer::TraitId(it) => it.resolver(self.db),\n+            ChildContainer::ImplId(it) => it.resolver(self.db),\n+            ChildContainer::ModuleId(it) => it.resolver(self.db),\n+            ChildContainer::EnumId(it) => it.resolver(self.db),\n+            ChildContainer::VariantId(it) => it.resolver(self.db),\n+            ChildContainer::GenericDefId(it) => it.resolver(self.db),\n+        };\n+        SourceAnalyzer::new_for_resolver(resolver, src)\n+    }\n+\n+    fn cache(&self, root_node: SyntaxNode, file_id: HirFileId) {\n+        assert!(root_node.parent().is_none());\n+        let mut cache = self.cache.borrow_mut();\n+        let prev = cache.insert(root_node, file_id);\n+        assert!(prev == None || prev == Some(file_id))\n+    }\n+\n+    pub fn assert_contains_node(&self, node: &SyntaxNode) {\n+        self.find_file(node.clone());\n+    }\n+\n+    fn lookup(&self, root_node: &SyntaxNode) -> Option<HirFileId> {\n+        let cache = self.cache.borrow();\n+        cache.get(root_node).copied()\n+    }\n+\n+    fn find_file(&self, node: SyntaxNode) -> InFile<SyntaxNode> {\n+        let root_node = find_root(&node);\n+        let file_id = self.lookup(&root_node).unwrap_or_else(|| {\n+            panic!(\n+                \"\\n\\nFailed to lookup {:?} in this Semantics.\\n\\\n+                 Make sure to use only query nodes, derived from this instance of Semantics.\\n\\\n+                 root node:   {:?}\\n\\\n+                 known nodes: {}\\n\\n\",\n+                node,\n+                root_node,\n+                self.cache\n+                    .borrow()\n+                    .keys()\n+                    .map(|it| format!(\"{:?}\", it))\n+                    .collect::<Vec<_>>()\n+                    .join(\", \")\n+            )\n+        });\n+        InFile::new(file_id, node)\n+    }\n+}\n+\n+fn find_root(node: &SyntaxNode) -> SyntaxNode {\n+    node.ancestors().last().unwrap()\n+}\n+\n+pub struct SemanticsScope<'a, DB> {\n+    pub db: &'a DB,\n+    resolver: Resolver,\n+}\n+\n+impl<'a, DB: HirDatabase> SemanticsScope<'a, DB> {\n+    pub fn module(&self) -> Option<Module> {\n+        Some(Module { id: self.resolver.module()? })\n+    }\n+\n+    /// Note: `FxHashSet<TraitId>` should be treated as an opaque type, passed into `Type\n+    // FIXME: rename to visible_traits to not repeat scope?\n+    pub fn traits_in_scope(&self) -> FxHashSet<TraitId> {\n+        let resolver = &self.resolver;\n+        resolver.traits_in_scope(self.db)\n+    }\n+\n+    pub fn process_all_names(&self, f: &mut dyn FnMut(Name, ScopeDef)) {\n+        let resolver = &self.resolver;\n+\n+        resolver.process_all_names(self.db, &mut |name, def| {\n+            let def = match def {\n+                resolver::ScopeDef::PerNs(it) => it.into(),\n+                resolver::ScopeDef::ImplSelfType(it) => ScopeDef::ImplSelfType(it.into()),\n+                resolver::ScopeDef::AdtSelfType(it) => ScopeDef::AdtSelfType(it.into()),\n+                resolver::ScopeDef::GenericParam(id) => ScopeDef::GenericParam(TypeParam { id }),\n+                resolver::ScopeDef::Local(pat_id) => {\n+                    let parent = resolver.body_owner().unwrap().into();\n+                    ScopeDef::Local(Local { parent, pat_id })\n+                }\n+            };\n+            f(name, def)\n+        })\n+    }\n+\n+    pub fn resolve_hir_path(&self, path: &Path) -> Option<PathResolution> {\n+        resolve_hir_path(self.db, &self.resolver, path)\n+    }\n+}\n+\n+// FIXME: Change `HasSource` trait to work with `Semantics` and remove this?\n+pub fn original_range(db: &impl HirDatabase, node: InFile<&SyntaxNode>) -> FileRange {\n+    if let Some((range, Origin::Call)) = original_range_and_origin(db, node) {\n+        return range;\n+    }\n+\n+    if let Some(expansion) = node.file_id.expansion_info(db) {\n+        if let Some(call_node) = expansion.call_node() {\n+            return FileRange {\n+                file_id: call_node.file_id.original_file(db),\n+                range: call_node.value.text_range(),\n+            };\n+        }\n+    }\n+\n+    FileRange { file_id: node.file_id.original_file(db), range: node.value.text_range() }\n+}\n+\n+fn original_range_and_origin(\n+    db: &impl HirDatabase,\n+    node: InFile<&SyntaxNode>,\n+) -> Option<(FileRange, Origin)> {\n+    let expansion = node.file_id.expansion_info(db)?;\n+\n+    // the input node has only one token ?\n+    let single = node.value.first_token()? == node.value.last_token()?;\n+\n+    // FIXME: We should handle recurside macro expansions\n+    let (range, origin) = node.value.descendants().find_map(|it| {\n+        let first = it.first_token()?;\n+        let last = it.last_token()?;\n+\n+        if !single && first == last {\n+            return None;\n+        }\n+\n+        // Try to map first and last tokens of node, and, if success, return the union range of mapped tokens\n+        let (first, first_origin) = expansion.map_token_up(node.with_value(&first))?;\n+        let (last, last_origin) = expansion.map_token_up(node.with_value(&last))?;\n+\n+        if first.file_id != last.file_id || first_origin != last_origin {\n+            return None;\n+        }\n+\n+        // FIXME: Add union method in TextRange\n+        Some((\n+            first.with_value(union_range(first.value.text_range(), last.value.text_range())),\n+            first_origin,\n+        ))\n+    })?;\n+\n+    return Some((\n+        FileRange { file_id: range.file_id.original_file(db), range: range.value },\n+        origin,\n+    ));\n+\n+    fn union_range(a: TextRange, b: TextRange) -> TextRange {\n+        let start = a.start().min(b.start());\n+        let end = a.end().max(b.end());\n+        TextRange::from_to(start, end)\n+    }\n+}"}, {"sha": "bff1ecd14723781dfa146b21c72273fa37374e15", "filename": "crates/ra_hir/src/source_analyzer.rs", "status": "modified", "additions": 73, "deletions": 121, "changes": 194, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_hir%2Fsrc%2Fsource_analyzer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_hir%2Fsrc%2Fsource_analyzer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsource_analyzer.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -14,29 +14,27 @@ use hir_def::{\n         BodySourceMap,\n     },\n     expr::{ExprId, PatId},\n-    resolver::{self, resolver_for_scope, Resolver, TypeNs, ValueNs},\n-    AsMacroCall, DefWithBodyId, TraitId,\n+    resolver::{resolver_for_scope, Resolver, TypeNs, ValueNs},\n+    AsMacroCall, DefWithBodyId,\n };\n-use hir_expand::{hygiene::Hygiene, name::AsName, HirFileId, InFile, MacroCallId};\n+use hir_expand::{hygiene::Hygiene, name::AsName, HirFileId, InFile};\n use hir_ty::{InEnvironment, InferenceResult, TraitEnvironment};\n use ra_syntax::{\n     ast::{self, AstNode},\n-    AstPtr, SyntaxNode, SyntaxNodePtr, SyntaxToken, TextRange, TextUnit,\n+    AstPtr, SyntaxNode, SyntaxNodePtr, TextRange, TextUnit,\n };\n-use rustc_hash::FxHashSet;\n \n use crate::{\n-    db::HirDatabase, Adt, Const, DefWithBody, EnumVariant, Function, Local, MacroDef, Name, Path,\n-    ScopeDef, Static, Struct, Trait, Type, TypeAlias, TypeParam,\n+    db::HirDatabase, Adt, Const, EnumVariant, Function, Local, MacroDef, Name, Path, Static,\n+    Struct, Trait, Type, TypeAlias, TypeParam,\n };\n \n /// `SourceAnalyzer` is a convenience wrapper which exposes HIR API in terms of\n /// original source files. It should not be used inside the HIR itself.\n #[derive(Debug)]\n-pub struct SourceAnalyzer {\n+pub(crate) struct SourceAnalyzer {\n     file_id: HirFileId,\n-    resolver: Resolver,\n-    body_owner: Option<DefWithBody>,\n+    pub(crate) resolver: Resolver,\n     body_source_map: Option<Arc<BodySourceMap>>,\n     infer: Option<Arc<InferenceResult>>,\n     scopes: Option<Arc<ExprScopes>>,\n@@ -77,35 +75,7 @@ pub struct ReferenceDescriptor {\n     pub name: String,\n }\n \n-#[derive(Debug)]\n-pub struct Expansion {\n-    macro_call_id: MacroCallId,\n-}\n-\n-impl Expansion {\n-    pub fn map_token_down(\n-        &self,\n-        db: &impl HirDatabase,\n-        token: InFile<&SyntaxToken>,\n-    ) -> Option<InFile<SyntaxToken>> {\n-        let exp_info = self.file_id().expansion_info(db)?;\n-        exp_info.map_token_down(token)\n-    }\n-\n-    pub fn file_id(&self) -> HirFileId {\n-        self.macro_call_id.as_file()\n-    }\n-}\n-\n impl SourceAnalyzer {\n-    pub fn new(\n-        db: &impl HirDatabase,\n-        node: InFile<&SyntaxNode>,\n-        offset: Option<TextUnit>,\n-    ) -> SourceAnalyzer {\n-        crate::source_binder::SourceBinder::new(db).analyze(node, offset)\n-    }\n-\n     pub(crate) fn new_for_body(\n         db: &impl HirDatabase,\n         def: DefWithBodyId,\n@@ -121,7 +91,6 @@ impl SourceAnalyzer {\n         let resolver = resolver_for_scope(db, def, scope);\n         SourceAnalyzer {\n             resolver,\n-            body_owner: Some(def.into()),\n             body_source_map: Some(source_map),\n             infer: Some(db.infer(def)),\n             scopes: Some(scopes),\n@@ -135,18 +104,13 @@ impl SourceAnalyzer {\n     ) -> SourceAnalyzer {\n         SourceAnalyzer {\n             resolver,\n-            body_owner: None,\n             body_source_map: None,\n             infer: None,\n             scopes: None,\n             file_id: node.file_id,\n         }\n     }\n \n-    pub fn module(&self) -> Option<crate::code_model::Module> {\n-        Some(crate::code_model::Module { id: self.resolver.module()? })\n-    }\n-\n     fn expr_id(&self, expr: &ast::Expr) -> Option<ExprId> {\n         let src = InFile { file_id: self.file_id, value: expr };\n         self.body_source_map.as_ref()?.node_expr(src)\n@@ -180,7 +144,7 @@ impl SourceAnalyzer {\n         TraitEnvironment::lower(db, &self.resolver)\n     }\n \n-    pub fn type_of(&self, db: &impl HirDatabase, expr: &ast::Expr) -> Option<Type> {\n+    pub(crate) fn type_of(&self, db: &impl HirDatabase, expr: &ast::Expr) -> Option<Type> {\n         let expr_id = if let Some(expr) = self.expand_expr(db, InFile::new(self.file_id, expr)) {\n             self.body_source_map.as_ref()?.node_expr(expr.as_ref())?\n         } else {\n@@ -192,24 +156,27 @@ impl SourceAnalyzer {\n         Some(Type { krate: self.resolver.krate()?, ty: InEnvironment { value: ty, environment } })\n     }\n \n-    pub fn type_of_pat(&self, db: &impl HirDatabase, pat: &ast::Pat) -> Option<Type> {\n+    pub(crate) fn type_of_pat(&self, db: &impl HirDatabase, pat: &ast::Pat) -> Option<Type> {\n         let pat_id = self.pat_id(pat)?;\n         let ty = self.infer.as_ref()?[pat_id].clone();\n         let environment = self.trait_env(db);\n         Some(Type { krate: self.resolver.krate()?, ty: InEnvironment { value: ty, environment } })\n     }\n \n-    pub fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n+    pub(crate) fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n         let expr_id = self.expr_id(&call.clone().into())?;\n         self.infer.as_ref()?.method_resolution(expr_id).map(Function::from)\n     }\n \n-    pub fn resolve_field(&self, field: &ast::FieldExpr) -> Option<crate::StructField> {\n+    pub(crate) fn resolve_field(&self, field: &ast::FieldExpr) -> Option<crate::StructField> {\n         let expr_id = self.expr_id(&field.clone().into())?;\n         self.infer.as_ref()?.field_resolution(expr_id).map(|it| it.into())\n     }\n \n-    pub fn resolve_record_field(&self, field: &ast::RecordField) -> Option<crate::StructField> {\n+    pub(crate) fn resolve_record_field(\n+        &self,\n+        field: &ast::RecordField,\n+    ) -> Option<crate::StructField> {\n         let expr_id = match field.expr() {\n             Some(it) => self.expr_id(&it)?,\n             None => {\n@@ -220,17 +187,23 @@ impl SourceAnalyzer {\n         self.infer.as_ref()?.record_field_resolution(expr_id).map(|it| it.into())\n     }\n \n-    pub fn resolve_record_literal(&self, record_lit: &ast::RecordLit) -> Option<crate::VariantDef> {\n+    pub(crate) fn resolve_record_literal(\n+        &self,\n+        record_lit: &ast::RecordLit,\n+    ) -> Option<crate::VariantDef> {\n         let expr_id = self.expr_id(&record_lit.clone().into())?;\n         self.infer.as_ref()?.variant_resolution_for_expr(expr_id).map(|it| it.into())\n     }\n \n-    pub fn resolve_record_pattern(&self, record_pat: &ast::RecordPat) -> Option<crate::VariantDef> {\n+    pub(crate) fn resolve_record_pattern(\n+        &self,\n+        record_pat: &ast::RecordPat,\n+    ) -> Option<crate::VariantDef> {\n         let pat_id = self.pat_id(&record_pat.clone().into())?;\n         self.infer.as_ref()?.variant_resolution_for_pat(pat_id).map(|it| it.into())\n     }\n \n-    pub fn resolve_macro_call(\n+    pub(crate) fn resolve_macro_call(\n         &self,\n         db: &impl HirDatabase,\n         macro_call: InFile<&ast::MacroCall>,\n@@ -240,52 +213,11 @@ impl SourceAnalyzer {\n         self.resolver.resolve_path_as_macro(db, path.mod_path()).map(|it| it.into())\n     }\n \n-    pub fn resolve_hir_path(\n+    pub(crate) fn resolve_path(\n         &self,\n         db: &impl HirDatabase,\n-        path: &crate::Path,\n+        path: &ast::Path,\n     ) -> Option<PathResolution> {\n-        let types =\n-            self.resolver.resolve_path_in_type_ns_fully(db, path.mod_path()).map(|ty| match ty {\n-                TypeNs::SelfType(it) => PathResolution::SelfType(it.into()),\n-                TypeNs::GenericParam(id) => PathResolution::TypeParam(TypeParam { id }),\n-                TypeNs::AdtSelfType(it) | TypeNs::AdtId(it) => {\n-                    PathResolution::Def(Adt::from(it).into())\n-                }\n-                TypeNs::EnumVariantId(it) => PathResolution::Def(EnumVariant::from(it).into()),\n-                TypeNs::TypeAliasId(it) => PathResolution::Def(TypeAlias::from(it).into()),\n-                TypeNs::BuiltinType(it) => PathResolution::Def(it.into()),\n-                TypeNs::TraitId(it) => PathResolution::Def(Trait::from(it).into()),\n-            });\n-        let values =\n-            self.resolver.resolve_path_in_value_ns_fully(db, path.mod_path()).and_then(|val| {\n-                let res = match val {\n-                    ValueNs::LocalBinding(pat_id) => {\n-                        let var = Local { parent: self.body_owner?, pat_id };\n-                        PathResolution::Local(var)\n-                    }\n-                    ValueNs::FunctionId(it) => PathResolution::Def(Function::from(it).into()),\n-                    ValueNs::ConstId(it) => PathResolution::Def(Const::from(it).into()),\n-                    ValueNs::StaticId(it) => PathResolution::Def(Static::from(it).into()),\n-                    ValueNs::StructId(it) => PathResolution::Def(Struct::from(it).into()),\n-                    ValueNs::EnumVariantId(it) => PathResolution::Def(EnumVariant::from(it).into()),\n-                };\n-                Some(res)\n-            });\n-\n-        let items = self\n-            .resolver\n-            .resolve_module_path_in_items(db, path.mod_path())\n-            .take_types()\n-            .map(|it| PathResolution::Def(it.into()));\n-        types.or(values).or(items).or_else(|| {\n-            self.resolver\n-                .resolve_path_as_macro(db, path.mod_path())\n-                .map(|def| PathResolution::Macro(def.into()))\n-        })\n-    }\n-\n-    pub fn resolve_path(&self, db: &impl HirDatabase, path: &ast::Path) -> Option<PathResolution> {\n         if let Some(path_expr) = path.syntax().parent().and_then(ast::PathExpr::cast) {\n             let expr_id = self.expr_id(&path_expr.into())?;\n             if let Some(assoc) = self.infer.as_ref()?.assoc_resolutions_for_expr(expr_id) {\n@@ -300,7 +232,7 @@ impl SourceAnalyzer {\n         }\n         // This must be a normal source file rather than macro file.\n         let hir_path = crate::Path::from_ast(path.clone())?;\n-        self.resolve_hir_path(db, &hir_path)\n+        resolve_hir_path(db, &self.resolver, &hir_path)\n     }\n \n     fn resolve_local_name(&self, name_ref: &ast::NameRef) -> Option<ScopeEntryWithSyntax> {\n@@ -315,25 +247,9 @@ impl SourceAnalyzer {\n         })\n     }\n \n-    pub fn process_all_names(&self, db: &impl HirDatabase, f: &mut dyn FnMut(Name, ScopeDef)) {\n-        self.resolver.process_all_names(db, &mut |name, def| {\n-            let def = match def {\n-                resolver::ScopeDef::PerNs(it) => it.into(),\n-                resolver::ScopeDef::ImplSelfType(it) => ScopeDef::ImplSelfType(it.into()),\n-                resolver::ScopeDef::AdtSelfType(it) => ScopeDef::AdtSelfType(it.into()),\n-                resolver::ScopeDef::GenericParam(id) => ScopeDef::GenericParam(TypeParam { id }),\n-                resolver::ScopeDef::Local(pat_id) => {\n-                    let parent = self.resolver.body_owner().unwrap().into();\n-                    ScopeDef::Local(Local { parent, pat_id })\n-                }\n-            };\n-            f(name, def)\n-        })\n-    }\n-\n     // FIXME: we only use this in `inline_local_variable` assist, ideally, we\n     // should switch to general reference search infra there.\n-    pub fn find_all_refs(&self, pat: &ast::BindPat) -> Vec<ReferenceDescriptor> {\n+    pub(crate) fn find_all_refs(&self, pat: &ast::BindPat) -> Vec<ReferenceDescriptor> {\n         let fn_def = pat.syntax().ancestors().find_map(ast::FnDef::cast).unwrap();\n         let ptr = Either::Left(AstPtr::new(&ast::Pat::from(pat.clone())));\n         fn_def\n@@ -351,19 +267,14 @@ impl SourceAnalyzer {\n             .collect()\n     }\n \n-    /// Note: `FxHashSet<TraitId>` should be treated as an opaque type, passed into `Type\n-    pub fn traits_in_scope(&self, db: &impl HirDatabase) -> FxHashSet<TraitId> {\n-        self.resolver.traits_in_scope(db)\n-    }\n-\n-    pub fn expand(\n+    pub(crate) fn expand(\n         &self,\n         db: &impl HirDatabase,\n         macro_call: InFile<&ast::MacroCall>,\n-    ) -> Option<Expansion> {\n+    ) -> Option<HirFileId> {\n         let macro_call_id =\n             macro_call.as_call_id(db, |path| self.resolver.resolve_path_as_macro(db, &path))?;\n-        Some(Expansion { macro_call_id })\n+        Some(macro_call_id.as_file())\n     }\n }\n \n@@ -409,6 +320,47 @@ fn scope_for_offset(\n         })\n }\n \n+pub(crate) fn resolve_hir_path(\n+    db: &impl HirDatabase,\n+    resolver: &Resolver,\n+    path: &crate::Path,\n+) -> Option<PathResolution> {\n+    let types = resolver.resolve_path_in_type_ns_fully(db, path.mod_path()).map(|ty| match ty {\n+        TypeNs::SelfType(it) => PathResolution::SelfType(it.into()),\n+        TypeNs::GenericParam(id) => PathResolution::TypeParam(TypeParam { id }),\n+        TypeNs::AdtSelfType(it) | TypeNs::AdtId(it) => PathResolution::Def(Adt::from(it).into()),\n+        TypeNs::EnumVariantId(it) => PathResolution::Def(EnumVariant::from(it).into()),\n+        TypeNs::TypeAliasId(it) => PathResolution::Def(TypeAlias::from(it).into()),\n+        TypeNs::BuiltinType(it) => PathResolution::Def(it.into()),\n+        TypeNs::TraitId(it) => PathResolution::Def(Trait::from(it).into()),\n+    });\n+    let body_owner = resolver.body_owner();\n+    let values = resolver.resolve_path_in_value_ns_fully(db, path.mod_path()).and_then(|val| {\n+        let res = match val {\n+            ValueNs::LocalBinding(pat_id) => {\n+                let var = Local { parent: body_owner?.into(), pat_id };\n+                PathResolution::Local(var)\n+            }\n+            ValueNs::FunctionId(it) => PathResolution::Def(Function::from(it).into()),\n+            ValueNs::ConstId(it) => PathResolution::Def(Const::from(it).into()),\n+            ValueNs::StaticId(it) => PathResolution::Def(Static::from(it).into()),\n+            ValueNs::StructId(it) => PathResolution::Def(Struct::from(it).into()),\n+            ValueNs::EnumVariantId(it) => PathResolution::Def(EnumVariant::from(it).into()),\n+        };\n+        Some(res)\n+    });\n+\n+    let items = resolver\n+        .resolve_module_path_in_items(db, path.mod_path())\n+        .take_types()\n+        .map(|it| PathResolution::Def(it.into()));\n+    types.or(values).or(items).or_else(|| {\n+        resolver\n+            .resolve_path_as_macro(db, path.mod_path())\n+            .map(|def| PathResolution::Macro(def.into()))\n+    })\n+}\n+\n // XXX: during completion, cursor might be outside of any particular\n // expression. Try to figure out the correct scope...\n fn adjust("}, {"sha": "0b8a641f926f54e917322514c04c1ed037d9efd2", "filename": "crates/ra_hir/src/source_binder.rs", "status": "modified", "additions": 69, "deletions": 92, "changes": 161, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -5,112 +5,85 @@ use hir_def::{\n     child_by_source::ChildBySource,\n     dyn_map::DynMap,\n     keys::{self, Key},\n-    resolver::{HasResolver, Resolver},\n     ConstId, DefWithBodyId, EnumId, EnumVariantId, FunctionId, GenericDefId, ImplId, ModuleId,\n     StaticId, StructFieldId, StructId, TraitId, TypeAliasId, UnionId, VariantId,\n };\n use hir_expand::{name::AsName, AstId, InFile, MacroDefId, MacroDefKind};\n+use ra_db::FileId;\n use ra_prof::profile;\n use ra_syntax::{\n     ast::{self, NameOwner},\n-    match_ast, AstNode, SyntaxNode, TextUnit,\n+    match_ast, AstNode, SyntaxNode,\n };\n use rustc_hash::FxHashMap;\n \n-use crate::{db::HirDatabase, Local, Module, SourceAnalyzer, TypeParam};\n-use ra_db::FileId;\n+use crate::{db::HirDatabase, Local, Module, TypeParam};\n \n-pub struct SourceBinder<'a, DB> {\n-    pub db: &'a DB,\n+pub struct SourceBinder {\n     child_by_source_cache: FxHashMap<ChildContainer, DynMap>,\n }\n \n-impl<DB: HirDatabase> SourceBinder<'_, DB> {\n-    pub fn new(db: &DB) -> SourceBinder<DB> {\n-        SourceBinder { db, child_by_source_cache: FxHashMap::default() }\n-    }\n-\n-    pub fn analyze(\n-        &mut self,\n-        src: InFile<&SyntaxNode>,\n-        offset: Option<TextUnit>,\n-    ) -> SourceAnalyzer {\n-        let _p = profile(\"SourceBinder::analyzer\");\n-        let container = match self.find_container(src) {\n-            Some(it) => it,\n-            None => return SourceAnalyzer::new_for_resolver(Resolver::default(), src),\n-        };\n-\n-        let resolver = match container {\n-            ChildContainer::DefWithBodyId(def) => {\n-                return SourceAnalyzer::new_for_body(self.db, def, src, offset)\n-            }\n-            ChildContainer::TraitId(it) => it.resolver(self.db),\n-            ChildContainer::ImplId(it) => it.resolver(self.db),\n-            ChildContainer::ModuleId(it) => it.resolver(self.db),\n-            ChildContainer::EnumId(it) => it.resolver(self.db),\n-            ChildContainer::VariantId(it) => it.resolver(self.db),\n-            ChildContainer::GenericDefId(it) => it.resolver(self.db),\n-        };\n-        SourceAnalyzer::new_for_resolver(resolver, src)\n+impl SourceBinder {\n+    pub(crate) fn new() -> SourceBinder {\n+        SourceBinder { child_by_source_cache: FxHashMap::default() }\n     }\n \n-    pub fn to_def<T: ToDef>(&mut self, src: InFile<T>) -> Option<T::Def> {\n-        T::to_def(self, src)\n-    }\n-\n-    pub fn to_module_def(&mut self, file: FileId) -> Option<Module> {\n+    pub(crate) fn to_module_def(&mut self, db: &impl HirDatabase, file: FileId) -> Option<Module> {\n         let _p = profile(\"SourceBinder::to_module_def\");\n-        let (krate, local_id) = self.db.relevant_crates(file).iter().find_map(|&crate_id| {\n-            let crate_def_map = self.db.crate_def_map(crate_id);\n+        let (krate, local_id) = db.relevant_crates(file).iter().find_map(|&crate_id| {\n+            let crate_def_map = db.crate_def_map(crate_id);\n             let local_id = crate_def_map.modules_for_file(file).next()?;\n             Some((crate_id, local_id))\n         })?;\n         Some(Module { id: ModuleId { krate, local_id } })\n     }\n \n-    fn to_id<T: ToId>(&mut self, src: InFile<T>) -> Option<T::ID> {\n-        T::to_id(self, src)\n+    fn to_id<T: ToId>(&mut self, db: &impl HirDatabase, src: InFile<T>) -> Option<T::ID> {\n+        T::to_id(db, self, src)\n     }\n \n-    fn find_container(&mut self, src: InFile<&SyntaxNode>) -> Option<ChildContainer> {\n-        for container in src.cloned().ancestors_with_macros(self.db).skip(1) {\n+    pub(crate) fn find_container(\n+        &mut self,\n+        db: &impl HirDatabase,\n+        src: InFile<&SyntaxNode>,\n+    ) -> Option<ChildContainer> {\n+        for container in src.cloned().ancestors_with_macros(db).skip(1) {\n             let res: ChildContainer = match_ast! {\n                 match (container.value) {\n                     ast::TraitDef(it) => {\n-                        let def: TraitId = self.to_id(container.with_value(it))?;\n+                        let def: TraitId = self.to_id(db, container.with_value(it))?;\n                         def.into()\n                     },\n                     ast::ImplBlock(it) => {\n-                        let def: ImplId = self.to_id(container.with_value(it))?;\n+                        let def: ImplId = self.to_id(db, container.with_value(it))?;\n                         def.into()\n                     },\n                     ast::FnDef(it) => {\n-                        let def: FunctionId = self.to_id(container.with_value(it))?;\n+                        let def: FunctionId = self.to_id(db, container.with_value(it))?;\n                         DefWithBodyId::from(def).into()\n                     },\n                     ast::StaticDef(it) => {\n-                        let def: StaticId = self.to_id(container.with_value(it))?;\n+                        let def: StaticId = self.to_id(db, container.with_value(it))?;\n                         DefWithBodyId::from(def).into()\n                     },\n                     ast::ConstDef(it) => {\n-                        let def: ConstId = self.to_id(container.with_value(it))?;\n+                        let def: ConstId = self.to_id(db, container.with_value(it))?;\n                         DefWithBodyId::from(def).into()\n                     },\n                     ast::EnumDef(it) => {\n-                        let def: EnumId = self.to_id(container.with_value(it))?;\n+                        let def: EnumId = self.to_id(db, container.with_value(it))?;\n                         def.into()\n                     },\n                     ast::StructDef(it) => {\n-                        let def: StructId = self.to_id(container.with_value(it))?;\n+                        let def: StructId = self.to_id(db, container.with_value(it))?;\n                         VariantId::from(def).into()\n                     },\n                     ast::UnionDef(it) => {\n-                        let def: UnionId = self.to_id(container.with_value(it))?;\n+                        let def: UnionId = self.to_id(db, container.with_value(it))?;\n                         VariantId::from(def).into()\n                     },\n                     ast::Module(it) => {\n-                        let def: ModuleId = self.to_id(container.with_value(it))?;\n+                        let def: ModuleId = self.to_id(db, container.with_value(it))?;\n                         def.into()\n                     },\n                     _ => { continue },\n@@ -119,12 +92,11 @@ impl<DB: HirDatabase> SourceBinder<'_, DB> {\n             return Some(res);\n         }\n \n-        let c = self.to_module_def(src.file_id.original_file(self.db))?;\n+        let c = self.to_module_def(db, src.file_id.original_file(db))?;\n         Some(c.id.into())\n     }\n \n-    fn child_by_source(&mut self, container: ChildContainer) -> &DynMap {\n-        let db = self.db;\n+    fn child_by_source(&mut self, db: &impl HirDatabase, container: ChildContainer) -> &DynMap {\n         self.child_by_source_cache.entry(container).or_insert_with(|| match container {\n             ChildContainer::DefWithBodyId(it) => it.child_by_source(db),\n             ChildContainer::ModuleId(it) => it.child_by_source(db),\n@@ -137,16 +109,20 @@ impl<DB: HirDatabase> SourceBinder<'_, DB> {\n     }\n }\n \n-pub trait ToId: Sized {\n+pub(crate) trait ToId: Sized {\n     type ID: Sized + Copy + 'static;\n-    fn to_id<DB: HirDatabase>(sb: &mut SourceBinder<'_, DB>, src: InFile<Self>)\n-        -> Option<Self::ID>;\n+    fn to_id<DB: HirDatabase>(\n+        db: &DB,\n+        sb: &mut SourceBinder,\n+        src: InFile<Self>,\n+    ) -> Option<Self::ID>;\n }\n \n pub trait ToDef: Sized + AstNode + 'static {\n     type Def;\n     fn to_def<DB: HirDatabase>(\n-        sb: &mut SourceBinder<'_, DB>,\n+        db: &DB,\n+        sb: &mut SourceBinder,\n         src: InFile<Self>,\n     ) -> Option<Self::Def>;\n }\n@@ -155,9 +131,9 @@ macro_rules! to_def_impls {\n     ($(($def:path, $ast:path)),* ,) => {$(\n         impl ToDef for $ast {\n             type Def = $def;\n-            fn to_def<DB: HirDatabase>(sb: &mut SourceBinder<'_, DB>, src: InFile<Self>)\n+            fn to_def<DB: HirDatabase>(db: &DB, sb: &mut SourceBinder, src: InFile<Self>)\n                 -> Option<Self::Def>\n-            { sb.to_id(src).map(Into::into) }\n+            { sb.to_id(db, src).map(Into::into) }\n         }\n     )*}\n }\n@@ -179,7 +155,7 @@ to_def_impls![\n ];\n \n #[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]\n-enum ChildContainer {\n+pub(crate) enum ChildContainer {\n     DefWithBodyId(DefWithBodyId),\n     ModuleId(ModuleId),\n     TraitId(TraitId),\n@@ -201,19 +177,19 @@ impl_froms! {\n     GenericDefId\n }\n \n-pub trait ToIdByKey: Sized + AstNode + 'static {\n+pub(crate) trait ToIdByKey: Sized + AstNode + 'static {\n     type ID: Sized + Copy + 'static;\n     const KEY: Key<Self, Self::ID>;\n }\n \n impl<T: ToIdByKey> ToId for T {\n     type ID = <T as ToIdByKey>::ID;\n     fn to_id<DB: HirDatabase>(\n-        sb: &mut SourceBinder<'_, DB>,\n+        db: &DB,\n+        sb: &mut SourceBinder,\n         src: InFile<Self>,\n     ) -> Option<Self::ID> {\n-        let container = sb.find_container(src.as_ref().map(|it| it.syntax()))?;\n-        let db = sb.db;\n+        let container = sb.find_container(db, src.as_ref().map(|it| it.syntax()))?;\n         let dyn_map =\n             &*sb.child_by_source_cache.entry(container).or_insert_with(|| match container {\n                 ChildContainer::DefWithBodyId(it) => it.child_by_source(db),\n@@ -255,15 +231,15 @@ to_id_key_impls![\n impl ToId for ast::MacroCall {\n     type ID = MacroDefId;\n     fn to_id<DB: HirDatabase>(\n-        sb: &mut SourceBinder<'_, DB>,\n+        db: &DB,\n+        sb: &mut SourceBinder,\n         src: InFile<Self>,\n     ) -> Option<Self::ID> {\n         let kind = MacroDefKind::Declarative;\n \n-        let krate = sb.to_module_def(src.file_id.original_file(sb.db))?.id.krate;\n+        let krate = sb.to_module_def(db, src.file_id.original_file(db))?.id.krate;\n \n-        let ast_id =\n-            Some(AstId::new(src.file_id, sb.db.ast_id_map(src.file_id).ast_id(&src.value)));\n+        let ast_id = Some(AstId::new(src.file_id, db.ast_id_map(src.file_id).ast_id(&src.value)));\n \n         Some(MacroDefId { krate: Some(krate), ast_id, kind })\n     }\n@@ -272,20 +248,20 @@ impl ToId for ast::MacroCall {\n impl ToDef for ast::BindPat {\n     type Def = Local;\n \n-    fn to_def<DB: HirDatabase>(sb: &mut SourceBinder<'_, DB>, src: InFile<Self>) -> Option<Local> {\n+    fn to_def<DB: HirDatabase>(db: &DB, sb: &mut SourceBinder, src: InFile<Self>) -> Option<Local> {\n         let file_id = src.file_id;\n         let parent: DefWithBodyId = src.value.syntax().ancestors().find_map(|it| {\n             let res = match_ast! {\n                 match it {\n-                    ast::ConstDef(value) => { sb.to_id(InFile { value, file_id})?.into() },\n-                    ast::StaticDef(value) => { sb.to_id(InFile { value, file_id})?.into() },\n-                    ast::FnDef(value) => { sb.to_id(InFile { value, file_id})?.into() },\n+                    ast::ConstDef(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n+                    ast::StaticDef(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n+                    ast::FnDef(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n                     _ => return None,\n                 }\n             };\n             Some(res)\n         })?;\n-        let (_body, source_map) = sb.db.body_with_source_map(parent);\n+        let (_body, source_map) = db.body_with_source_map(parent);\n         let src = src.map(ast::Pat::from);\n         let pat_id = source_map.node_pat(src.as_ref())?;\n         Some(Local { parent: parent.into(), pat_id })\n@@ -296,26 +272,26 @@ impl ToDef for ast::TypeParam {\n     type Def = TypeParam;\n \n     fn to_def<DB: HirDatabase>(\n-        sb: &mut SourceBinder<'_, DB>,\n+        db: &DB,\n+        sb: &mut SourceBinder,\n         src: InFile<ast::TypeParam>,\n     ) -> Option<TypeParam> {\n-        let mut sb = SourceBinder::new(sb.db);\n         let file_id = src.file_id;\n         let parent: GenericDefId = src.value.syntax().ancestors().find_map(|it| {\n             let res = match_ast! {\n                 match it {\n-                    ast::FnDef(value) => { sb.to_id(InFile { value, file_id})?.into() },\n-                    ast::StructDef(value) => { sb.to_id(InFile { value, file_id})?.into() },\n-                    ast::EnumDef(value) => { sb.to_id(InFile { value, file_id})?.into() },\n-                    ast::TraitDef(value) => { sb.to_id(InFile { value, file_id})?.into() },\n-                    ast::TypeAliasDef(value) => { sb.to_id(InFile { value, file_id})?.into() },\n-                    ast::ImplBlock(value) => { sb.to_id(InFile { value, file_id})?.into() },\n+                    ast::FnDef(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n+                    ast::StructDef(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n+                    ast::EnumDef(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n+                    ast::TraitDef(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n+                    ast::TypeAliasDef(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n+                    ast::ImplBlock(value) => { sb.to_id(db, InFile { value, file_id})?.into() },\n                     _ => return None,\n                 }\n             };\n             Some(res)\n         })?;\n-        let &id = sb.child_by_source(parent.into())[keys::TYPE_PARAM].get(&src)?;\n+        let &id = sb.child_by_source(db, parent.into())[keys::TYPE_PARAM].get(&src)?;\n         Some(TypeParam { id })\n     }\n }\n@@ -324,7 +300,8 @@ impl ToId for ast::Module {\n     type ID = ModuleId;\n \n     fn to_id<DB: HirDatabase>(\n-        sb: &mut SourceBinder<'_, DB>,\n+        db: &DB,\n+        sb: &mut SourceBinder,\n         src: InFile<ast::Module>,\n     ) -> Option<ModuleId> {\n         {\n@@ -333,23 +310,23 @@ impl ToId for ast::Module {\n                 .as_ref()\n                 .map(|it| it.syntax())\n                 .cloned()\n-                .ancestors_with_macros(sb.db)\n+                .ancestors_with_macros(db)\n                 .skip(1)\n                 .find_map(|it| {\n                     let m = ast::Module::cast(it.value.clone())?;\n                     Some(it.with_value(m))\n                 });\n \n             let parent_module = match parent_declaration {\n-                Some(parent_declaration) => sb.to_id(parent_declaration)?,\n+                Some(parent_declaration) => sb.to_id(db, parent_declaration)?,\n                 None => {\n-                    let file_id = src.file_id.original_file(sb.db);\n-                    sb.to_module_def(file_id)?.id\n+                    let file_id = src.file_id.original_file(db);\n+                    sb.to_module_def(db, file_id)?.id\n                 }\n             };\n \n             let child_name = src.value.name()?.as_name();\n-            let def_map = sb.db.crate_def_map(parent_module.krate);\n+            let def_map = db.crate_def_map(parent_module.krate);\n             let child_id = *def_map[parent_module.local_id].children.get(&child_name)?;\n             Some(ModuleId { krate: parent_module.krate, local_id: child_id })\n         }"}, {"sha": "b00b6d43104ab5fbeac7c60fd4e144253dc50477", "filename": "crates/ra_ide/src/call_hierarchy.rs", "status": "modified", "additions": 21, "deletions": 21, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcall_hierarchy.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcall_hierarchy.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcall_hierarchy.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -2,13 +2,13 @@\n \n use indexmap::IndexMap;\n \n-use hir::db::AstDatabase;\n+use hir::Semantics;\n use ra_ide_db::RootDatabase;\n use ra_syntax::{ast, match_ast, AstNode, TextRange};\n \n use crate::{\n-    call_info::FnCallNode, display::ToNav, expand::descend_into_macros, goto_definition,\n-    references, FilePosition, NavigationTarget, RangeInfo,\n+    call_info::FnCallNode, display::ToNav, goto_definition, references, FilePosition,\n+    NavigationTarget, RangeInfo,\n };\n \n #[derive(Debug, Clone)]\n@@ -38,30 +38,31 @@ pub(crate) fn call_hierarchy(\n }\n \n pub(crate) fn incoming_calls(db: &RootDatabase, position: FilePosition) -> Option<Vec<CallItem>> {\n+    let sema = Semantics::new(db);\n     // 1. Find all refs\n     // 2. Loop through refs and determine unique fndef. This will become our `from: CallHierarchyItem,` in the reply.\n     // 3. Add ranges relative to the start of the fndef.\n     let refs = references::find_all_refs(db, position, None)?;\n \n     let mut calls = CallLocations::default();\n-    let mut sb = hir::SourceBinder::new(db);\n \n     for reference in refs.info.references() {\n         let file_id = reference.file_range.file_id;\n-        let file = db.parse_or_expand(file_id.into())?;\n+        let file = sema.parse(file_id);\n+        let file = file.syntax();\n         let token = file.token_at_offset(reference.file_range.range.start()).next()?;\n-        let token = descend_into_macros(db, file_id, token);\n-        let syntax = token.value.parent();\n+        let token = sema.descend_into_macros(token);\n+        let syntax = token.parent();\n \n         // This target is the containing function\n         if let Some(nav) = syntax.ancestors().find_map(|node| {\n             match_ast! {\n                 match node {\n                     ast::FnDef(it) => {\n-                        let def = sb.to_def(token.with_value(it))?;\n-                        Some(def.to_nav(sb.db))\n+                        let def = sema.to_def(&it)?;\n+                        Some(def.to_nav(sema.db))\n                     },\n-                    _ => { None },\n+                    _ => None,\n                 }\n             }\n         }) {\n@@ -74,11 +75,13 @@ pub(crate) fn incoming_calls(db: &RootDatabase, position: FilePosition) -> Optio\n }\n \n pub(crate) fn outgoing_calls(db: &RootDatabase, position: FilePosition) -> Option<Vec<CallItem>> {\n+    let sema = Semantics::new(db);\n     let file_id = position.file_id;\n-    let file = db.parse_or_expand(file_id.into())?;\n+    let file = sema.parse(file_id);\n+    let file = file.syntax();\n     let token = file.token_at_offset(position.offset).next()?;\n-    let token = descend_into_macros(db, file_id, token);\n-    let syntax = token.value.parent();\n+    let token = sema.descend_into_macros(token);\n+    let syntax = token.parent();\n \n     let mut calls = CallLocations::default();\n \n@@ -87,14 +90,11 @@ pub(crate) fn outgoing_calls(db: &RootDatabase, position: FilePosition) -> Optio\n         .filter_map(|node| FnCallNode::with_node_exact(&node))\n         .filter_map(|call_node| {\n             let name_ref = call_node.name_ref()?;\n-            let name_ref = token.with_value(name_ref.syntax());\n-\n-            let analyzer = hir::SourceAnalyzer::new(db, name_ref, None);\n \n             if let Some(func_target) = match &call_node {\n                 FnCallNode::CallExpr(expr) => {\n                     //FIXME: Type::as_callable is broken\n-                    let callable_def = analyzer.type_of(db, &expr.expr()?)?.as_callable()?;\n+                    let callable_def = sema.type_of_expr(&expr.expr()?)?.as_callable()?;\n                     match callable_def {\n                         hir::CallableDef::FunctionId(it) => {\n                             let fn_def: hir::Function = it.into();\n@@ -105,15 +105,15 @@ pub(crate) fn outgoing_calls(db: &RootDatabase, position: FilePosition) -> Optio\n                     }\n                 }\n                 FnCallNode::MethodCallExpr(expr) => {\n-                    let function = analyzer.resolve_method_call(&expr)?;\n+                    let function = sema.resolve_method_call(&expr)?;\n                     Some(function.to_nav(db))\n                 }\n-                FnCallNode::MacroCallExpr(expr) => {\n-                    let macro_def = analyzer.resolve_macro_call(db, name_ref.with_value(&expr))?;\n+                FnCallNode::MacroCallExpr(macro_call) => {\n+                    let macro_def = sema.resolve_macro_call(&macro_call)?;\n                     Some(macro_def.to_nav(db))\n                 }\n             } {\n-                Some((func_target, name_ref.value.text_range()))\n+                Some((func_target, name_ref.syntax().text_range()))\n             } else {\n                 None\n             }"}, {"sha": "9a1fc0d35b291d2465e5c33d5acb408f467e41f9", "filename": "crates/ra_ide/src/call_info.rs", "status": "modified", "additions": 13, "deletions": 14, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcall_info.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcall_info.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcall_info.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,30 +1,29 @@\n //! FIXME: write short doc here\n-use hir::db::AstDatabase;\n+use hir::Semantics;\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n     ast::{self, ArgListOwner},\n     match_ast, AstNode, SyntaxNode,\n };\n use test_utils::tested_by;\n \n-use crate::{expand::descend_into_macros, CallInfo, FilePosition, FunctionSignature};\n+use crate::{CallInfo, FilePosition, FunctionSignature};\n \n /// Computes parameter information for the given call expression.\n pub(crate) fn call_info(db: &RootDatabase, position: FilePosition) -> Option<CallInfo> {\n-    let file = db.parse_or_expand(position.file_id.into())?;\n+    let sema = Semantics::new(db);\n+    let file = sema.parse(position.file_id);\n+    let file = file.syntax();\n     let token = file.token_at_offset(position.offset).next()?;\n-    let token = descend_into_macros(db, position.file_id, token);\n+    let token = sema.descend_into_macros(token);\n \n     // Find the calling expression and it's NameRef\n-    let calling_node = FnCallNode::with_node(&token.value.parent())?;\n-    let name_ref = calling_node.name_ref()?;\n-    let name_ref = token.with_value(name_ref.syntax());\n+    let calling_node = FnCallNode::with_node(&token.parent())?;\n \n-    let analyzer = hir::SourceAnalyzer::new(db, name_ref, None);\n     let (mut call_info, has_self) = match &calling_node {\n-        FnCallNode::CallExpr(expr) => {\n+        FnCallNode::CallExpr(call) => {\n             //FIXME: Type::as_callable is broken\n-            let callable_def = analyzer.type_of(db, &expr.expr()?)?.as_callable()?;\n+            let callable_def = sema.type_of_expr(&call.expr()?)?.as_callable()?;\n             match callable_def {\n                 hir::CallableDef::FunctionId(it) => {\n                     let fn_def = it.into();\n@@ -36,12 +35,12 @@ pub(crate) fn call_info(db: &RootDatabase, position: FilePosition) -> Option<Cal\n                 }\n             }\n         }\n-        FnCallNode::MethodCallExpr(expr) => {\n-            let function = analyzer.resolve_method_call(&expr)?;\n+        FnCallNode::MethodCallExpr(method_call) => {\n+            let function = sema.resolve_method_call(&method_call)?;\n             (CallInfo::with_fn(db, function), function.has_self_param(db))\n         }\n-        FnCallNode::MacroCallExpr(expr) => {\n-            let macro_def = analyzer.resolve_macro_call(db, name_ref.with_value(&expr))?;\n+        FnCallNode::MacroCallExpr(macro_call) => {\n+            let macro_def = sema.resolve_macro_call(&macro_call)?;\n             (CallInfo::with_macro(db, macro_def)?, false)\n         }\n     };"}, {"sha": "c378c2c627f87202de69269f449195971f9e6aa3", "filename": "crates/ra_ide/src/completion.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -17,7 +17,6 @@ mod complete_postfix;\n mod complete_macro_in_item_position;\n mod complete_trait_impl;\n \n-use ra_db::SourceDatabase;\n use ra_ide_db::RootDatabase;\n \n #[cfg(test)]\n@@ -57,8 +56,7 @@ pub use crate::completion::completion_item::{\n /// identifier prefix/fuzzy match should be done higher in the stack, together\n /// with ordering of completions (currently this is done by the client).\n pub(crate) fn completions(db: &RootDatabase, position: FilePosition) -> Option<Completions> {\n-    let original_parse = db.parse(position.file_id);\n-    let ctx = CompletionContext::new(db, &original_parse, position)?;\n+    let ctx = CompletionContext::new(db, position)?;\n \n     let mut acc = Completions::default();\n "}, {"sha": "a6e0158b2a1d6d861b4cb1531b48a3b98d3ff34b", "filename": "crates/ra_ide/src/completion/complete_dot.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_dot.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_dot.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_dot.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -16,7 +16,7 @@ pub(super) fn complete_dot(acc: &mut Completions, ctx: &CompletionContext) {\n         _ => return,\n     };\n \n-    let receiver_ty = match ctx.analyzer.type_of(ctx.db, &dot_receiver) {\n+    let receiver_ty = match ctx.sema.type_of_expr(&dot_receiver) {\n         Some(ty) => ty,\n         _ => return,\n     };\n@@ -55,7 +55,7 @@ fn complete_fields(acc: &mut Completions, ctx: &CompletionContext, receiver: &Ty\n fn complete_methods(acc: &mut Completions, ctx: &CompletionContext, receiver: &Type) {\n     if let Some(krate) = ctx.module.map(|it| it.krate()) {\n         let mut seen_methods = FxHashSet::default();\n-        let traits_in_scope = ctx.analyzer.traits_in_scope(ctx.db);\n+        let traits_in_scope = ctx.scope().traits_in_scope();\n         receiver.iterate_method_candidates(ctx.db, krate, &traits_in_scope, None, |_ty, func| {\n             if func.has_self_param(ctx.db) && seen_methods.insert(func.name(ctx.db)) {\n                 acc.add_function(ctx, func);"}, {"sha": "1866d9e6c6d9b197cc235dc330416d8f1e4eeb90", "filename": "crates/ra_ide/src/completion/complete_macro_in_item_position.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_macro_in_item_position.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_macro_in_item_position.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_macro_in_item_position.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -5,7 +5,7 @@ use crate::completion::{CompletionContext, Completions};\n pub(super) fn complete_macro_in_item_position(acc: &mut Completions, ctx: &CompletionContext) {\n     // Show only macros in top level.\n     if ctx.is_new_item {\n-        ctx.analyzer.process_all_names(ctx.db, &mut |name, res| {\n+        ctx.scope().process_all_names(&mut |name, res| {\n             if let hir::ScopeDef::MacroDef(mac) = res {\n                 acc.add_macro(ctx, Some(name.to_string()), mac);\n             }"}, {"sha": "c626e90cc8bf02f4f7a9e627692ca8b892b9b8b8", "filename": "crates/ra_ide/src/completion/complete_path.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_path.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_path.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_path.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -11,7 +11,7 @@ pub(super) fn complete_path(acc: &mut Completions, ctx: &CompletionContext) {\n         Some(path) => path.clone(),\n         _ => return,\n     };\n-    let def = match ctx.analyzer.resolve_hir_path(ctx.db, &path) {\n+    let def = match ctx.scope().resolve_hir_path(&path) {\n         Some(PathResolution::Def(def)) => def,\n         _ => return,\n     };\n@@ -49,7 +49,7 @@ pub(super) fn complete_path(acc: &mut Completions, ctx: &CompletionContext) {\n             // FIXME: complete T::AssocType\n             let krate = ctx.module.map(|m| m.krate());\n             if let Some(krate) = krate {\n-                let traits_in_scope = ctx.analyzer.traits_in_scope(ctx.db);\n+                let traits_in_scope = ctx.scope().traits_in_scope();\n                 ty.iterate_path_candidates(ctx.db, krate, &traits_in_scope, None, |_ty, item| {\n                     match item {\n                         hir::AssocItem::Function(func) => {"}, {"sha": "c2c6ca002c399679a88caf4eceef7878b3d03c7c", "filename": "crates/ra_ide/src/completion/complete_pattern.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_pattern.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_pattern.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_pattern.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -9,7 +9,7 @@ pub(super) fn complete_pattern(acc: &mut Completions, ctx: &CompletionContext) {\n     }\n     // FIXME: ideally, we should look at the type we are matching against and\n     // suggest variants + auto-imports\n-    ctx.analyzer.process_all_names(ctx.db, &mut |name, res| {\n+    ctx.scope().process_all_names(&mut |name, res| {\n         let def = match &res {\n             hir::ScopeDef::ModuleDef(def) => def,\n             _ => return,"}, {"sha": "8a74f993ab62b3bc0dddeefd7afaa73d800bc138", "filename": "crates/ra_ide/src/completion/complete_postfix.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_postfix.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_postfix.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_postfix.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -29,7 +29,7 @@ pub(super) fn complete_postfix(acc: &mut Completions, ctx: &CompletionContext) {\n         dot_receiver.syntax().text().to_string()\n     };\n \n-    let receiver_ty = match ctx.analyzer.type_of(ctx.db, &dot_receiver) {\n+    let receiver_ty = match ctx.sema.type_of_expr(&dot_receiver) {\n         Some(it) => it,\n         None => return,\n     };"}, {"sha": "f98353d769cbec06b03775a300af032a3c9978bc", "filename": "crates/ra_ide/src/completion/complete_record_literal.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_record_literal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_record_literal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_record_literal.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -5,10 +5,7 @@ use crate::completion::{CompletionContext, Completions};\n /// Complete fields in fields literals.\n pub(super) fn complete_record_literal(acc: &mut Completions, ctx: &CompletionContext) {\n     let (ty, variant) = match ctx.record_lit_syntax.as_ref().and_then(|it| {\n-        Some((\n-            ctx.analyzer.type_of(ctx.db, &it.clone().into())?,\n-            ctx.analyzer.resolve_record_literal(it)?,\n-        ))\n+        Some((ctx.sema.type_of_expr(&it.clone().into())?, ctx.sema.resolve_record_literal(it)?))\n     }) {\n         Some(it) => it,\n         _ => return,"}, {"sha": "9bdeae49f98d6bb348f2dbd7514f4334b7e58e0a", "filename": "crates/ra_ide/src/completion/complete_record_pattern.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_record_pattern.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_record_pattern.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_record_pattern.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -4,10 +4,7 @@ use crate::completion::{CompletionContext, Completions};\n \n pub(super) fn complete_record_pattern(acc: &mut Completions, ctx: &CompletionContext) {\n     let (ty, variant) = match ctx.record_lit_pat.as_ref().and_then(|it| {\n-        Some((\n-            ctx.analyzer.type_of_pat(ctx.db, &it.clone().into())?,\n-            ctx.analyzer.resolve_record_pattern(it)?,\n-        ))\n+        Some((ctx.sema.type_of_pat(&it.clone().into())?, ctx.sema.resolve_record_pattern(it)?))\n     }) {\n         Some(it) => it,\n         _ => return,"}, {"sha": "aad016d4aba7a21d5eaf70fd07c5428da261e80e", "filename": "crates/ra_ide/src/completion/complete_scope.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_scope.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_scope.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_scope.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -7,9 +7,7 @@ pub(super) fn complete_scope(acc: &mut Completions, ctx: &CompletionContext) {\n         return;\n     }\n \n-    ctx.analyzer.process_all_names(ctx.db, &mut |name, res| {\n-        acc.add_resolution(ctx, name.to_string(), &res)\n-    });\n+    ctx.scope().process_all_names(&mut |name, res| acc.add_resolution(ctx, name.to_string(), &res));\n }\n \n #[cfg(test)]"}, {"sha": "9a27c164b705616e66c2792d45d1e2b4397baca1", "filename": "crates/ra_ide/src/completion/complete_trait_impl.rs", "status": "modified", "additions": 18, "deletions": 15, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_trait_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_trait_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcomplete_trait_impl.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -64,35 +64,38 @@ pub(crate) fn complete_trait_impl(acc: &mut Completions, ctx: &CompletionContext\n     if let (Some(trigger), Some(impl_block)) = (trigger, impl_block) {\n         match trigger.kind() {\n             SyntaxKind::FN_DEF => {\n-                for missing_fn in get_missing_impl_items(ctx.db, &ctx.analyzer, &impl_block)\n-                    .iter()\n-                    .filter_map(|item| match item {\n-                        hir::AssocItem::Function(fn_item) => Some(fn_item),\n-                        _ => None,\n+                for missing_fn in\n+                    get_missing_impl_items(&ctx.sema, &impl_block).iter().filter_map(|item| {\n+                        match item {\n+                            hir::AssocItem::Function(fn_item) => Some(fn_item),\n+                            _ => None,\n+                        }\n                     })\n                 {\n                     add_function_impl(&trigger, acc, ctx, &missing_fn);\n                 }\n             }\n \n             SyntaxKind::TYPE_ALIAS_DEF => {\n-                for missing_fn in get_missing_impl_items(ctx.db, &ctx.analyzer, &impl_block)\n-                    .iter()\n-                    .filter_map(|item| match item {\n-                        hir::AssocItem::TypeAlias(type_item) => Some(type_item),\n-                        _ => None,\n+                for missing_fn in\n+                    get_missing_impl_items(&ctx.sema, &impl_block).iter().filter_map(|item| {\n+                        match item {\n+                            hir::AssocItem::TypeAlias(type_item) => Some(type_item),\n+                            _ => None,\n+                        }\n                     })\n                 {\n                     add_type_alias_impl(&trigger, acc, ctx, &missing_fn);\n                 }\n             }\n \n             SyntaxKind::CONST_DEF => {\n-                for missing_fn in get_missing_impl_items(ctx.db, &ctx.analyzer, &impl_block)\n-                    .iter()\n-                    .filter_map(|item| match item {\n-                        hir::AssocItem::Const(const_item) => Some(const_item),\n-                        _ => None,\n+                for missing_fn in\n+                    get_missing_impl_items(&ctx.sema, &impl_block).iter().filter_map(|item| {\n+                        match item {\n+                            hir::AssocItem::Const(const_item) => Some(const_item),\n+                            _ => None,\n+                        }\n                     })\n                 {\n                     add_const_impl(&trigger, acc, ctx, &missing_fn);"}, {"sha": "81321a897f7c929ff111d91742f63c12843896fd", "filename": "crates/ra_ide/src/completion/completion_context.rs", "status": "modified", "additions": 38, "deletions": 27, "changes": 65, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcompletion_context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcompletion_context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fcompletion%2Fcompletion_context.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,9 +1,11 @@\n //! FIXME: write short doc here\n \n+use hir::{Semantics, SemanticsScope};\n+use ra_db::SourceDatabase;\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n     algo::{find_covering_element, find_node_at_offset},\n-    ast, AstNode, Parse, SourceFile,\n+    ast, AstNode, SourceFile,\n     SyntaxKind::*,\n     SyntaxNode, SyntaxToken, TextRange, TextUnit,\n };\n@@ -15,8 +17,8 @@ use crate::FilePosition;\n /// exactly is the cursor, syntax-wise.\n #[derive(Debug)]\n pub(crate) struct CompletionContext<'a> {\n+    pub(super) sema: Semantics<'a, RootDatabase>,\n     pub(super) db: &'a RootDatabase,\n-    pub(super) analyzer: hir::SourceAnalyzer,\n     pub(super) offset: TextUnit,\n     pub(super) token: SyntaxToken,\n     pub(super) module: Option<hir::Module>,\n@@ -51,20 +53,26 @@ pub(crate) struct CompletionContext<'a> {\n impl<'a> CompletionContext<'a> {\n     pub(super) fn new(\n         db: &'a RootDatabase,\n-        original_parse: &'a Parse<ast::SourceFile>,\n         position: FilePosition,\n     ) -> Option<CompletionContext<'a>> {\n-        let mut sb = hir::SourceBinder::new(db);\n-        let module = sb.to_module_def(position.file_id);\n-        let token =\n-            original_parse.tree().syntax().token_at_offset(position.offset).left_biased()?;\n-        let analyzer = sb.analyze(\n-            hir::InFile::new(position.file_id.into(), &token.parent()),\n-            Some(position.offset),\n-        );\n+        let sema = Semantics::new(db);\n+\n+        let original_file = sema.parse(position.file_id);\n+\n+        // Insert a fake ident to get a valid parse tree. We will use this file\n+        // to determine context, though the original_file will be used for\n+        // actual completion.\n+        let file_with_fake_ident = {\n+            let parse = db.parse(position.file_id);\n+            let edit = AtomTextEdit::insert(position.offset, \"intellijRulezz\".to_string());\n+            parse.reparse(&edit).tree()\n+        };\n+\n+        let module = sema.to_module_def(position.file_id);\n+        let token = original_file.syntax().token_at_offset(position.offset).left_biased()?;\n         let mut ctx = CompletionContext {\n+            sema,\n             db,\n-            analyzer,\n             token,\n             offset: position.offset,\n             module,\n@@ -87,7 +95,7 @@ impl<'a> CompletionContext<'a> {\n             has_type_args: false,\n             dot_receiver_is_ambiguous_float_literal: false,\n         };\n-        ctx.fill(&original_parse, position.offset);\n+        ctx.fill(&original_file, file_with_fake_ident, position.offset);\n         Some(ctx)\n     }\n \n@@ -100,29 +108,33 @@ impl<'a> CompletionContext<'a> {\n         }\n     }\n \n-    fn fill(&mut self, original_parse: &'a Parse<ast::SourceFile>, offset: TextUnit) {\n-        // Insert a fake ident to get a valid parse tree. We will use this file\n-        // to determine context, though the original_file will be used for\n-        // actual completion.\n-        let file = {\n-            let edit = AtomTextEdit::insert(offset, \"intellijRulezz\".to_string());\n-            original_parse.reparse(&edit).tree()\n-        };\n+    pub(crate) fn scope(&self) -> SemanticsScope<'_, RootDatabase> {\n+        self.sema.scope_at_offset(&self.token.parent(), self.offset)\n+    }\n \n+    fn fill(\n+        &mut self,\n+        original_file: &ast::SourceFile,\n+        file_with_fake_ident: ast::SourceFile,\n+        offset: TextUnit,\n+    ) {\n         // First, let's try to complete a reference to some declaration.\n-        if let Some(name_ref) = find_node_at_offset::<ast::NameRef>(file.syntax(), offset) {\n+        if let Some(name_ref) =\n+            find_node_at_offset::<ast::NameRef>(file_with_fake_ident.syntax(), offset)\n+        {\n             // Special case, `trait T { fn foo(i_am_a_name_ref) {} }`.\n             // See RFC#1685.\n             if is_node::<ast::Param>(name_ref.syntax()) {\n                 self.is_param = true;\n                 return;\n             }\n-            self.classify_name_ref(original_parse.tree(), name_ref);\n+            self.classify_name_ref(original_file, name_ref);\n         }\n \n         // Otherwise, see if this is a declaration. We can use heuristics to\n         // suggest declaration names, see `CompletionKind::Magic`.\n-        if let Some(name) = find_node_at_offset::<ast::Name>(file.syntax(), offset) {\n+        if let Some(name) = find_node_at_offset::<ast::Name>(file_with_fake_ident.syntax(), offset)\n+        {\n             if let Some(bind_pat) = name.syntax().ancestors().find_map(ast::BindPat::cast) {\n                 let parent = bind_pat.syntax().parent();\n                 if parent.clone().and_then(ast::MatchArm::cast).is_some()\n@@ -136,13 +148,12 @@ impl<'a> CompletionContext<'a> {\n                 return;\n             }\n             if name.syntax().ancestors().find_map(ast::RecordFieldPatList::cast).is_some() {\n-                self.record_lit_pat =\n-                    find_node_at_offset(original_parse.tree().syntax(), self.offset);\n+                self.record_lit_pat = find_node_at_offset(original_file.syntax(), self.offset);\n             }\n         }\n     }\n \n-    fn classify_name_ref(&mut self, original_file: SourceFile, name_ref: ast::NameRef) {\n+    fn classify_name_ref(&mut self, original_file: &SourceFile, name_ref: ast::NameRef) {\n         self.name_ref_syntax =\n             find_node_at_offset(original_file.syntax(), name_ref.syntax().text_range().start());\n         let name_range = name_ref.syntax().text_range();"}, {"sha": "a52f7fdd9f216bd604f553fed953a5cf76fd02ba", "filename": "crates/ra_ide/src/diagnostics.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fdiagnostics.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -2,7 +2,10 @@\n \n use std::cell::RefCell;\n \n-use hir::diagnostics::{AstDiagnostic, Diagnostic as _, DiagnosticSink};\n+use hir::{\n+    diagnostics::{AstDiagnostic, Diagnostic as _, DiagnosticSink},\n+    Semantics,\n+};\n use itertools::Itertools;\n use ra_db::{RelativePath, SourceDatabase, SourceDatabaseExt};\n use ra_ide_db::RootDatabase;\n@@ -24,7 +27,7 @@ pub enum Severity {\n \n pub(crate) fn diagnostics(db: &RootDatabase, file_id: FileId) -> Vec<Diagnostic> {\n     let _p = profile(\"diagnostics\");\n-    let mut sb = hir::SourceBinder::new(db);\n+    let sema = Semantics::new(db);\n     let parse = db.parse(file_id);\n     let mut res = Vec::new();\n \n@@ -110,7 +113,7 @@ pub(crate) fn diagnostics(db: &RootDatabase, file_id: FileId) -> Vec<Diagnostic>\n             fix: Some(fix),\n         })\n     });\n-    if let Some(m) = sb.to_module_def(file_id) {\n+    if let Some(m) = sema.to_module_def(file_id) {\n         m.diagnostics(db, &mut sink);\n     };\n     drop(sink);"}, {"sha": "5afb23764e917b556cf9f3637c588b869167488d", "filename": "crates/ra_ide/src/display/navigation_target.rs", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fdisplay%2Fnavigation_target.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fdisplay%2Fnavigation_target.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fdisplay%2Fnavigation_target.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,7 +1,7 @@\n //! FIXME: write short doc here\n \n use either::Either;\n-use hir::{AssocItem, FieldSource, HasSource, InFile, ModuleSource};\n+use hir::{original_range, AssocItem, FieldSource, HasSource, InFile, ModuleSource};\n use ra_db::{FileId, SourceDatabase};\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n@@ -11,7 +11,11 @@ use ra_syntax::{\n     TextRange,\n };\n \n-use crate::{expand::original_range, references::NameDefinition, FileSymbol};\n+use crate::{\n+    // expand::original_range,\n+    references::NameDefinition,\n+    FileSymbol,\n+};\n \n use super::short_label::ShortLabel;\n "}, {"sha": "9f3aaa3a3fcca75effa1056c944f10612a72b292", "filename": "crates/ra_ide/src/expand.rs", "status": "removed", "additions": 0, "deletions": 102, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/04deae3dba7c9b7054f7a1d64e4b93a05aecc132/crates%2Fra_ide%2Fsrc%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/04deae3dba7c9b7054f7a1d64e4b93a05aecc132/crates%2Fra_ide%2Fsrc%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fexpand.rs?ref=04deae3dba7c9b7054f7a1d64e4b93a05aecc132", "patch": "@@ -1,102 +0,0 @@\n-//! Utilities to work with files, produced by macros.\n-use std::iter::successors;\n-\n-use hir::{InFile, Origin};\n-use ra_db::FileId;\n-use ra_ide_db::RootDatabase;\n-use ra_syntax::{ast, AstNode, SyntaxNode, SyntaxToken, TextRange};\n-\n-use crate::FileRange;\n-\n-pub(crate) fn original_range(db: &RootDatabase, node: InFile<&SyntaxNode>) -> FileRange {\n-    if let Some((range, Origin::Call)) = original_range_and_origin(db, node) {\n-        return range;\n-    }\n-\n-    if let Some(expansion) = node.file_id.expansion_info(db) {\n-        if let Some(call_node) = expansion.call_node() {\n-            return FileRange {\n-                file_id: call_node.file_id.original_file(db),\n-                range: call_node.value.text_range(),\n-            };\n-        }\n-    }\n-\n-    FileRange { file_id: node.file_id.original_file(db), range: node.value.text_range() }\n-}\n-\n-fn original_range_and_origin(\n-    db: &RootDatabase,\n-    node: InFile<&SyntaxNode>,\n-) -> Option<(FileRange, Origin)> {\n-    let expansion = node.file_id.expansion_info(db)?;\n-\n-    // the input node has only one token ?\n-    let single = node.value.first_token()? == node.value.last_token()?;\n-\n-    // FIXME: We should handle recurside macro expansions\n-    let (range, origin) = node.value.descendants().find_map(|it| {\n-        let first = it.first_token()?;\n-        let last = it.last_token()?;\n-\n-        if !single && first == last {\n-            return None;\n-        }\n-\n-        // Try to map first and last tokens of node, and, if success, return the union range of mapped tokens\n-        let (first, first_origin) = expansion.map_token_up(node.with_value(&first))?;\n-        let (last, last_origin) = expansion.map_token_up(node.with_value(&last))?;\n-\n-        if first.file_id != last.file_id || first_origin != last_origin {\n-            return None;\n-        }\n-\n-        // FIXME: Add union method in TextRange\n-        Some((\n-            first.with_value(union_range(first.value.text_range(), last.value.text_range())),\n-            first_origin,\n-        ))\n-    })?;\n-\n-    return Some((\n-        FileRange { file_id: range.file_id.original_file(db), range: range.value },\n-        origin,\n-    ));\n-\n-    fn union_range(a: TextRange, b: TextRange) -> TextRange {\n-        let start = a.start().min(b.start());\n-        let end = a.end().max(b.end());\n-        TextRange::from_to(start, end)\n-    }\n-}\n-\n-pub(crate) fn descend_into_macros(\n-    db: &RootDatabase,\n-    file_id: FileId,\n-    token: SyntaxToken,\n-) -> InFile<SyntaxToken> {\n-    let src = InFile::new(file_id.into(), token);\n-\n-    let source_analyzer =\n-        hir::SourceAnalyzer::new(db, src.with_value(src.value.parent()).as_ref(), None);\n-\n-    descend_into_macros_with_analyzer(db, &source_analyzer, src)\n-}\n-\n-pub(crate) fn descend_into_macros_with_analyzer(\n-    db: &RootDatabase,\n-    source_analyzer: &hir::SourceAnalyzer,\n-    src: InFile<SyntaxToken>,\n-) -> InFile<SyntaxToken> {\n-    successors(Some(src), |token| {\n-        let macro_call = token.value.ancestors().find_map(ast::MacroCall::cast)?;\n-        let tt = macro_call.token_tree()?;\n-        if !token.value.text_range().is_subrange(&tt.syntax().text_range()) {\n-            return None;\n-        }\n-        let exp = source_analyzer.expand(db, token.with_value(&macro_call))?;\n-        exp.map_token_down(db, token.as_ref())\n-    })\n-    .last()\n-    .unwrap()\n-}"}, {"sha": "f2814e6842d626ad72422e7d14af573777f789b1", "filename": "crates/ra_ide/src/expand_macro.rs", "status": "modified", "additions": 12, "deletions": 17, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fexpand_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fexpand_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fexpand_macro.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,7 +1,6 @@\n //! This modules implements \"expand macro\" functionality in the IDE\n \n-use hir::db::AstDatabase;\n-use ra_db::SourceDatabase;\n+use hir::Semantics;\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n     algo::{find_node_at_offset, replace_descendants},\n@@ -17,13 +16,12 @@ pub struct ExpandedMacro {\n }\n \n pub(crate) fn expand_macro(db: &RootDatabase, position: FilePosition) -> Option<ExpandedMacro> {\n-    let parse = db.parse(position.file_id);\n-    let file = parse.tree();\n+    let sema = Semantics::new(db);\n+    let file = sema.parse(position.file_id);\n     let name_ref = find_node_at_offset::<ast::NameRef>(file.syntax(), position.offset)?;\n     let mac = name_ref.syntax().ancestors().find_map(ast::MacroCall::cast)?;\n \n-    let source = hir::InFile::new(position.file_id.into(), mac.syntax());\n-    let expanded = expand_macro_recur(db, source, source.with_value(&mac))?;\n+    let expanded = expand_macro_recur(&sema, &mac)?;\n \n     // FIXME:\n     // macro expansion may lose all white space information\n@@ -33,21 +31,16 @@ pub(crate) fn expand_macro(db: &RootDatabase, position: FilePosition) -> Option<\n }\n \n fn expand_macro_recur(\n-    db: &RootDatabase,\n-    source: hir::InFile<&SyntaxNode>,\n-    macro_call: hir::InFile<&ast::MacroCall>,\n+    sema: &Semantics<RootDatabase>,\n+    macro_call: &ast::MacroCall,\n ) -> Option<SyntaxNode> {\n-    let analyzer = hir::SourceAnalyzer::new(db, source, None);\n-    let expansion = analyzer.expand(db, macro_call)?;\n-    let macro_file_id = expansion.file_id();\n-    let mut expanded: SyntaxNode = db.parse_or_expand(macro_file_id)?;\n+    let mut expanded = sema.expand(macro_call)?;\n \n     let children = expanded.descendants().filter_map(ast::MacroCall::cast);\n     let mut replaces: FxHashMap<SyntaxElement, SyntaxElement> = FxHashMap::default();\n \n     for child in children.into_iter() {\n-        let node = hir::InFile::new(macro_file_id, &child);\n-        if let Some(new_node) = expand_macro_recur(db, source, node) {\n+        if let Some(new_node) = expand_macro_recur(sema, &child) {\n             // Replace the whole node if it is root\n             // `replace_descendants` will not replace the parent node\n             // but `SyntaxNode::descendants include itself\n@@ -120,10 +113,12 @@ fn insert_whitespaces(syn: SyntaxNode) -> String {\n \n #[cfg(test)]\n mod tests {\n-    use super::*;\n-    use crate::mock_analysis::analysis_and_position;\n     use insta::assert_snapshot;\n \n+    use crate::mock_analysis::analysis_and_position;\n+\n+    use super::*;\n+\n     fn check_expand_macro(fixture: &str) -> ExpandedMacro {\n         let (analysis, pos) = analysis_and_position(fixture);\n         analysis.expand_macro(pos).unwrap().unwrap()"}, {"sha": "86e6f12d7da4d55057a1e07d0ed53079a0ed3972", "filename": "crates/ra_ide/src/extend_selection.rs", "status": "modified", "additions": 23, "deletions": 28, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fextend_selection.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fextend_selection.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fextend_selection.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -2,26 +2,26 @@\n \n use std::iter::successors;\n \n-use hir::db::AstDatabase;\n-use ra_db::SourceDatabase;\n+use hir::Semantics;\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n-    algo::find_covering_element,\n+    algo::{self, find_covering_element},\n     ast::{self, AstNode, AstToken},\n-    Direction, NodeOrToken, SyntaxElement,\n+    Direction, NodeOrToken,\n     SyntaxKind::{self, *},\n     SyntaxNode, SyntaxToken, TextRange, TextUnit, TokenAtOffset, T,\n };\n \n-use crate::{expand::descend_into_macros, FileId, FileRange};\n+use crate::FileRange;\n \n pub(crate) fn extend_selection(db: &RootDatabase, frange: FileRange) -> TextRange {\n-    let src = db.parse(frange.file_id).tree();\n-    try_extend_selection(db, src.syntax(), frange).unwrap_or(frange.range)\n+    let sema = Semantics::new(db);\n+    let src = sema.parse(frange.file_id);\n+    try_extend_selection(&sema, src.syntax(), frange).unwrap_or(frange.range)\n }\n \n fn try_extend_selection(\n-    db: &RootDatabase,\n+    sema: &Semantics<RootDatabase>,\n     root: &SyntaxNode,\n     frange: FileRange,\n ) -> Option<TextRange> {\n@@ -86,7 +86,7 @@ fn try_extend_selection(\n     // if we are in single token_tree, we maybe live in macro or attr\n     if node.kind() == TOKEN_TREE {\n         if let Some(macro_call) = node.ancestors().find_map(ast::MacroCall::cast) {\n-            if let Some(range) = extend_tokens_from_range(db, frange.file_id, macro_call, range) {\n+            if let Some(range) = extend_tokens_from_range(sema, macro_call, range) {\n                 return Some(range);\n             }\n         }\n@@ -96,7 +96,7 @@ fn try_extend_selection(\n         return Some(node.text_range());\n     }\n \n-    let node = shallowest_node(&node.into()).unwrap();\n+    let node = shallowest_node(&node.into());\n \n     if node.parent().map(|n| list_kinds.contains(&n.kind())) == Some(true) {\n         if let Some(range) = extend_list_item(&node) {\n@@ -108,8 +108,7 @@ fn try_extend_selection(\n }\n \n fn extend_tokens_from_range(\n-    db: &RootDatabase,\n-    file_id: FileId,\n+    sema: &Semantics<RootDatabase>,\n     macro_call: ast::MacroCall,\n     original_range: TextRange,\n ) -> Option<TextRange> {\n@@ -130,25 +129,21 @@ fn extend_tokens_from_range(\n     }\n \n     // compute original mapped token range\n-    let expanded = {\n-        let first_node = descend_into_macros(db, file_id, first_token.clone());\n-        let first_node = first_node.map(|it| it.text_range());\n-\n-        let last_node = descend_into_macros(db, file_id, last_token.clone());\n-        if last_node.file_id == file_id.into() || first_node.file_id != last_node.file_id {\n-            return None;\n+    let extended = {\n+        let fst_expanded = sema.descend_into_macros(first_token.clone());\n+        let lst_expanded = sema.descend_into_macros(last_token.clone());\n+        let mut lca = algo::least_common_ancestor(&fst_expanded.parent(), &lst_expanded.parent())?;\n+        lca = shallowest_node(&lca);\n+        if lca.first_token() == Some(fst_expanded) && lca.last_token() == Some(lst_expanded) {\n+            lca = lca.parent()?;\n         }\n-        first_node.map(|it| union_range(it, last_node.value.text_range()))\n+        lca\n     };\n \n     // Compute parent node range\n-    let src = db.parse_or_expand(expanded.file_id)?;\n-    let parent = shallowest_node(&find_covering_element(&src, expanded.value))?.parent()?;\n-\n     let validate = |token: &SyntaxToken| {\n-        let node = descend_into_macros(db, file_id, token.clone());\n-        node.file_id == expanded.file_id\n-            && node.value.text_range().is_subrange(&parent.text_range())\n+        let expanded = sema.descend_into_macros(token.clone());\n+        algo::least_common_ancestor(&extended, &expanded.parent()).as_ref() == Some(&extended)\n     };\n \n     // Find the first and last text range under expanded parent\n@@ -191,8 +186,8 @@ fn union_range(range: TextRange, r: TextRange) -> TextRange {\n }\n \n /// Find the shallowest node with same range, which allows us to traverse siblings.\n-fn shallowest_node(node: &SyntaxElement) -> Option<SyntaxNode> {\n-    node.ancestors().take_while(|n| n.text_range() == node.text_range()).last()\n+fn shallowest_node(node: &SyntaxNode) -> SyntaxNode {\n+    node.ancestors().take_while(|n| n.text_range() == node.text_range()).last().unwrap()\n }\n \n fn extend_single_word_in_comment_or_string("}, {"sha": "6053c1bb6a97eea30ecd12a6e888d55ad5f47c17", "filename": "crates/ra_ide/src/goto_definition.rs", "status": "modified", "additions": 19, "deletions": 20, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fgoto_definition.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fgoto_definition.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fgoto_definition.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,7 +1,7 @@\n //! FIXME: write short doc here\n \n-use hir::{db::AstDatabase, InFile, SourceBinder};\n-use ra_ide_db::{symbol_index, RootDatabase};\n+use hir::Semantics;\n+use ra_ide_db::{defs::classify_name, symbol_index, RootDatabase};\n use ra_syntax::{\n     ast::{self},\n     match_ast, AstNode,\n@@ -11,27 +11,26 @@ use ra_syntax::{\n \n use crate::{\n     display::{ToNav, TryToNav},\n-    expand::descend_into_macros,\n-    references::{classify_name, classify_name_ref},\n+    references::classify_name_ref,\n     FilePosition, NavigationTarget, RangeInfo,\n };\n \n pub(crate) fn goto_definition(\n     db: &RootDatabase,\n     position: FilePosition,\n ) -> Option<RangeInfo<Vec<NavigationTarget>>> {\n-    let file = db.parse_or_expand(position.file_id.into())?;\n+    let sema = Semantics::new(db);\n+    let file = sema.parse(position.file_id).syntax().clone();\n     let original_token = pick_best(file.token_at_offset(position.offset))?;\n-    let token = descend_into_macros(db, position.file_id, original_token.clone());\n+    let token = sema.descend_into_macros(original_token.clone());\n \n-    let mut sb = SourceBinder::new(db);\n     let nav_targets = match_ast! {\n-        match (token.value.parent()) {\n+        match (token.parent()) {\n             ast::NameRef(name_ref) => {\n-                reference_definition(&mut sb, token.with_value(&name_ref)).to_vec()\n+                reference_definition(&sema, &name_ref).to_vec()\n             },\n             ast::Name(name) => {\n-                name_definition(&mut sb, token.with_value(&name))?\n+                name_definition(&sema, &name)?\n             },\n             _ => return None,\n         }\n@@ -68,33 +67,33 @@ impl ReferenceResult {\n }\n \n pub(crate) fn reference_definition(\n-    sb: &mut SourceBinder<RootDatabase>,\n-    name_ref: InFile<&ast::NameRef>,\n+    sema: &Semantics<RootDatabase>,\n+    name_ref: &ast::NameRef,\n ) -> ReferenceResult {\n     use self::ReferenceResult::*;\n \n-    let name_kind = classify_name_ref(sb, name_ref);\n+    let name_kind = classify_name_ref(sema, name_ref);\n     if let Some(def) = name_kind {\n-        return match def.try_to_nav(sb.db) {\n+        return match def.try_to_nav(sema.db) {\n             Some(nav) => ReferenceResult::Exact(nav),\n             None => ReferenceResult::Approximate(Vec::new()),\n         };\n     }\n \n     // Fallback index based approach:\n-    let navs = symbol_index::index_resolve(sb.db, name_ref.value)\n+    let navs = symbol_index::index_resolve(sema.db, name_ref)\n         .into_iter()\n-        .map(|s| s.to_nav(sb.db))\n+        .map(|s| s.to_nav(sema.db))\n         .collect();\n     Approximate(navs)\n }\n \n fn name_definition(\n-    sb: &mut SourceBinder<RootDatabase>,\n-    name: InFile<&ast::Name>,\n+    sema: &Semantics<RootDatabase>,\n+    name: &ast::Name,\n ) -> Option<Vec<NavigationTarget>> {\n-    let def = classify_name(sb, name)?;\n-    let nav = def.try_to_nav(sb.db)?;\n+    let def = classify_name(sema, name)?;\n+    let nav = def.try_to_nav(sema.db)?;\n     Some(vec![nav])\n }\n "}, {"sha": "869a4708b7d6504c13fb5fbc07bf638fb5debd76", "filename": "crates/ra_ide/src/goto_type_definition.rs", "status": "modified", "additions": 18, "deletions": 18, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fgoto_type_definition.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fgoto_type_definition.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fgoto_type_definition.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,31 +1,31 @@\n //! FIXME: write short doc here\n \n-use hir::db::AstDatabase;\n use ra_ide_db::RootDatabase;\n-use ra_syntax::{ast, AstNode, SyntaxKind::*, SyntaxToken, TokenAtOffset};\n+use ra_syntax::{ast, match_ast, AstNode, SyntaxKind::*, SyntaxToken, TokenAtOffset};\n \n-use crate::{\n-    display::ToNav, expand::descend_into_macros, FilePosition, NavigationTarget, RangeInfo,\n-};\n+use crate::{display::ToNav, FilePosition, NavigationTarget, RangeInfo};\n \n pub(crate) fn goto_type_definition(\n     db: &RootDatabase,\n     position: FilePosition,\n ) -> Option<RangeInfo<Vec<NavigationTarget>>> {\n-    let file = db.parse_or_expand(position.file_id.into())?;\n-    let token = pick_best(file.token_at_offset(position.offset))?;\n-    let token = descend_into_macros(db, position.file_id, token);\n-\n-    let node = token\n-        .value\n-        .ancestors()\n-        .find(|n| ast::Expr::cast(n.clone()).is_some() || ast::Pat::cast(n.clone()).is_some())?;\n-\n-    let analyzer = hir::SourceAnalyzer::new(db, token.with_value(&node), None);\n+    let sema = hir::Semantics::new(db);\n+\n+    let file: ast::SourceFile = sema.parse(position.file_id);\n+    let token: SyntaxToken = pick_best(file.syntax().token_at_offset(position.offset))?;\n+    let token: SyntaxToken = sema.descend_into_macros(token);\n+\n+    let (ty, node) = sema.ancestors_with_macros(token.parent()).find_map(|node| {\n+        let ty = match_ast! {\n+            match node {\n+                ast::Expr(expr) => { sema.type_of_expr(&expr)? },\n+                ast::Pat(pat) => { sema.type_of_pat(&pat)? },\n+                _ => { return None },\n+            }\n+        };\n \n-    let ty: hir::Type = ast::Expr::cast(node.clone())\n-        .and_then(|e| analyzer.type_of(db, &e))\n-        .or_else(|| ast::Pat::cast(node.clone()).and_then(|p| analyzer.type_of_pat(db, &p)))?;\n+        Some((ty, node))\n+    })?;\n \n     let adt_def = ty.autoderef(db).find_map(|ty| ty.as_adt())?;\n "}, {"sha": "ace33c0794b4622571adb5377d70e0aa1f7d485a", "filename": "crates/ra_ide/src/hover.rs", "status": "modified", "additions": 22, "deletions": 23, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fhover.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fhover.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fhover.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,8 +1,10 @@\n //! FIXME: write short doc here\n \n-use hir::{db::AstDatabase, Adt, HasSource, HirDisplay, SourceBinder};\n-use ra_db::SourceDatabase;\n-use ra_ide_db::{defs::NameDefinition, RootDatabase};\n+use hir::{Adt, HasSource, HirDisplay, Semantics};\n+use ra_ide_db::{\n+    defs::{classify_name, NameDefinition},\n+    RootDatabase,\n+};\n use ra_syntax::{\n     algo::find_covering_element,\n     ast::{self, DocCommentsOwner},\n@@ -13,8 +15,7 @@ use ra_syntax::{\n \n use crate::{\n     display::{macro_label, rust_code_markup, rust_code_markup_with_doc, ShortLabel},\n-    expand::{descend_into_macros, original_range},\n-    references::{classify_name, classify_name_ref},\n+    references::classify_name_ref,\n     FilePosition, FileRange, RangeInfo,\n };\n \n@@ -143,25 +144,25 @@ fn hover_text_from_name_kind(db: &RootDatabase, def: NameDefinition) -> Option<S\n }\n \n pub(crate) fn hover(db: &RootDatabase, position: FilePosition) -> Option<RangeInfo<HoverResult>> {\n-    let file = db.parse_or_expand(position.file_id.into())?;\n+    let sema = Semantics::new(db);\n+    let file = sema.parse(position.file_id).syntax().clone();\n     let token = pick_best(file.token_at_offset(position.offset))?;\n-    let token = descend_into_macros(db, position.file_id, token);\n+    let token = sema.descend_into_macros(token);\n \n     let mut res = HoverResult::new();\n \n-    let mut sb = SourceBinder::new(db);\n     if let Some((node, name_kind)) = match_ast! {\n-        match (token.value.parent()) {\n+        match (token.parent()) {\n             ast::NameRef(name_ref) => {\n-                classify_name_ref(&mut sb, token.with_value(&name_ref)).map(|d| (name_ref.syntax().clone(), d))\n+                classify_name_ref(&sema, &name_ref).map(|d| (name_ref.syntax().clone(), d))\n             },\n             ast::Name(name) => {\n-                classify_name(&mut sb, token.with_value(&name)).map(|d| (name.syntax().clone(), d))\n+                classify_name(&sema, &name).map(|d| (name.syntax().clone(), d))\n             },\n             _ => None,\n         }\n     } {\n-        let range = original_range(db, token.with_value(&node)).range;\n+        let range = sema.original_range(&node).range;\n         res.extend(hover_text_from_name_kind(db, name_kind));\n \n         if !res.is_empty() {\n@@ -170,11 +171,10 @@ pub(crate) fn hover(db: &RootDatabase, position: FilePosition) -> Option<RangeIn\n     }\n \n     let node = token\n-        .value\n         .ancestors()\n         .find(|n| ast::Expr::cast(n.clone()).is_some() || ast::Pat::cast(n.clone()).is_some())?;\n \n-    let frange = original_range(db, token.with_value(&node));\n+    let frange = sema.original_range(&node);\n     res.extend(type_of(db, frange).map(rust_code_markup));\n     if res.is_empty() {\n         return None;\n@@ -197,19 +197,17 @@ fn pick_best(tokens: TokenAtOffset<SyntaxToken>) -> Option<SyntaxToken> {\n }\n \n pub(crate) fn type_of(db: &RootDatabase, frange: FileRange) -> Option<String> {\n-    let parse = db.parse(frange.file_id);\n-    let leaf_node = find_covering_element(parse.tree().syntax(), frange.range);\n+    let sema = Semantics::new(db);\n+    let source_file = sema.parse(frange.file_id);\n+    let leaf_node = find_covering_element(source_file.syntax(), frange.range);\n     // if we picked identifier, expand to pattern/expression\n     let node = leaf_node\n         .ancestors()\n         .take_while(|it| it.text_range() == leaf_node.text_range())\n         .find(|it| ast::Expr::cast(it.clone()).is_some() || ast::Pat::cast(it.clone()).is_some())?;\n-    let analyzer =\n-        hir::SourceAnalyzer::new(db, hir::InFile::new(frange.file_id.into(), &node), None);\n-    let ty = if let Some(ty) = ast::Expr::cast(node.clone()).and_then(|e| analyzer.type_of(db, &e))\n-    {\n+    let ty = if let Some(ty) = ast::Expr::cast(node.clone()).and_then(|e| sema.type_of_expr(&e)) {\n         ty\n-    } else if let Some(ty) = ast::Pat::cast(node).and_then(|p| analyzer.type_of_pat(db, &p)) {\n+    } else if let Some(ty) = ast::Pat::cast(node).and_then(|p| sema.type_of_pat(&p)) {\n         ty\n     } else {\n         return None;\n@@ -219,11 +217,12 @@ pub(crate) fn type_of(db: &RootDatabase, frange: FileRange) -> Option<String> {\n \n #[cfg(test)]\n mod tests {\n+    use ra_db::FileLoader;\n+    use ra_syntax::TextRange;\n+\n     use crate::mock_analysis::{\n         analysis_and_position, single_file_with_position, single_file_with_range,\n     };\n-    use ra_db::FileLoader;\n-    use ra_syntax::TextRange;\n \n     fn trim_markup(s: &str) -> &str {\n         s.trim_start_matches(\"```rust\\n\").trim_end_matches(\"\\n```\")"}, {"sha": "bf82b2a168598c17c0b3bd90ea116a0ca7e473a3", "filename": "crates/ra_ide/src/impls.rs", "status": "modified", "additions": 18, "deletions": 31, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fimpls.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fimpls.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fimpls.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,7 +1,6 @@\n //! FIXME: write short doc here\n \n-use hir::{Crate, ImplBlock, SourceBinder};\n-use ra_db::SourceDatabase;\n+use hir::{Crate, ImplBlock, Semantics};\n use ra_ide_db::RootDatabase;\n use ra_syntax::{algo::find_node_at_offset, ast, AstNode};\n \n@@ -11,71 +10,59 @@ pub(crate) fn goto_implementation(\n     db: &RootDatabase,\n     position: FilePosition,\n ) -> Option<RangeInfo<Vec<NavigationTarget>>> {\n-    let parse = db.parse(position.file_id);\n-    let syntax = parse.tree().syntax().clone();\n-    let mut sb = SourceBinder::new(db);\n+    let sema = Semantics::new(db);\n+    let source_file = sema.parse(position.file_id);\n+    let syntax = source_file.syntax().clone();\n \n-    let krate = sb.to_module_def(position.file_id)?.krate();\n+    let krate = sema.to_module_def(position.file_id)?.krate();\n \n     if let Some(nominal_def) = find_node_at_offset::<ast::NominalDef>(&syntax, position.offset) {\n         return Some(RangeInfo::new(\n             nominal_def.syntax().text_range(),\n-            impls_for_def(&mut sb, position, &nominal_def, krate)?,\n+            impls_for_def(&sema, &nominal_def, krate)?,\n         ));\n     } else if let Some(trait_def) = find_node_at_offset::<ast::TraitDef>(&syntax, position.offset) {\n         return Some(RangeInfo::new(\n             trait_def.syntax().text_range(),\n-            impls_for_trait(&mut sb, position, &trait_def, krate)?,\n+            impls_for_trait(&sema, &trait_def, krate)?,\n         ));\n     }\n \n     None\n }\n \n fn impls_for_def(\n-    sb: &mut SourceBinder<RootDatabase>,\n-    position: FilePosition,\n+    sema: &Semantics<RootDatabase>,\n     node: &ast::NominalDef,\n     krate: Crate,\n ) -> Option<Vec<NavigationTarget>> {\n     let ty = match node {\n-        ast::NominalDef::StructDef(def) => {\n-            let src = hir::InFile { file_id: position.file_id.into(), value: def.clone() };\n-            sb.to_def(src)?.ty(sb.db)\n-        }\n-        ast::NominalDef::EnumDef(def) => {\n-            let src = hir::InFile { file_id: position.file_id.into(), value: def.clone() };\n-            sb.to_def(src)?.ty(sb.db)\n-        }\n-        ast::NominalDef::UnionDef(def) => {\n-            let src = hir::InFile { file_id: position.file_id.into(), value: def.clone() };\n-            sb.to_def(src)?.ty(sb.db)\n-        }\n+        ast::NominalDef::StructDef(def) => sema.to_def(def)?.ty(sema.db),\n+        ast::NominalDef::EnumDef(def) => sema.to_def(def)?.ty(sema.db),\n+        ast::NominalDef::UnionDef(def) => sema.to_def(def)?.ty(sema.db),\n     };\n \n-    let impls = ImplBlock::all_in_crate(sb.db, krate);\n+    let impls = ImplBlock::all_in_crate(sema.db, krate);\n \n     Some(\n         impls\n             .into_iter()\n-            .filter(|impl_block| ty.is_equal_for_find_impls(&impl_block.target_ty(sb.db)))\n-            .map(|imp| imp.to_nav(sb.db))\n+            .filter(|impl_block| ty.is_equal_for_find_impls(&impl_block.target_ty(sema.db)))\n+            .map(|imp| imp.to_nav(sema.db))\n             .collect(),\n     )\n }\n \n fn impls_for_trait(\n-    sb: &mut SourceBinder<RootDatabase>,\n-    position: FilePosition,\n+    sema: &Semantics<RootDatabase>,\n     node: &ast::TraitDef,\n     krate: Crate,\n ) -> Option<Vec<NavigationTarget>> {\n-    let src = hir::InFile { file_id: position.file_id.into(), value: node.clone() };\n-    let tr = sb.to_def(src)?;\n+    let tr = sema.to_def(node)?;\n \n-    let impls = ImplBlock::for_trait(sb.db, krate, tr);\n+    let impls = ImplBlock::for_trait(sema.db, krate, tr);\n \n-    Some(impls.into_iter().map(|imp| imp.to_nav(sb.db)).collect())\n+    Some(impls.into_iter().map(|imp| imp.to_nav(sema.db)).collect())\n }\n \n #[cfg(test)]"}, {"sha": "35e3f782d1801068790c167508e584e85c6ec4fc", "filename": "crates/ra_ide/src/inlay_hints.rs", "status": "modified", "additions": 21, "deletions": 27, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Finlay_hints.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Finlay_hints.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Finlay_hints.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,12 +1,11 @@\n //! FIXME: write short doc here\n \n-use hir::{Adt, HirDisplay, SourceAnalyzer, SourceBinder, Type};\n-use once_cell::unsync::Lazy;\n+use hir::{Adt, HirDisplay, Semantics, Type};\n use ra_ide_db::RootDatabase;\n use ra_prof::profile;\n use ra_syntax::{\n     ast::{self, ArgListOwner, AstNode, TypeAscriptionOwner},\n-    match_ast, SmolStr, SourceFile, SyntaxNode, TextRange,\n+    match_ast, SmolStr, SyntaxNode, TextRange,\n };\n \n use crate::{FileId, FunctionSignature};\n@@ -27,38 +26,36 @@ pub struct InlayHint {\n pub(crate) fn inlay_hints(\n     db: &RootDatabase,\n     file_id: FileId,\n-    file: &SourceFile,\n     max_inlay_hint_length: Option<usize>,\n ) -> Vec<InlayHint> {\n-    let mut sb = SourceBinder::new(db);\n+    let sema = Semantics::new(db);\n+    let file = sema.parse(file_id);\n     let mut res = Vec::new();\n     for node in file.syntax().descendants() {\n-        get_inlay_hints(&mut res, &mut sb, file_id, &node, max_inlay_hint_length);\n+        get_inlay_hints(&mut res, &sema, &node, max_inlay_hint_length);\n     }\n     res\n }\n \n fn get_inlay_hints(\n     acc: &mut Vec<InlayHint>,\n-    sb: &mut SourceBinder<RootDatabase>,\n-    file_id: FileId,\n+    sema: &Semantics<RootDatabase>,\n     node: &SyntaxNode,\n     max_inlay_hint_length: Option<usize>,\n ) -> Option<()> {\n     let _p = profile(\"get_inlay_hints\");\n-    let db = sb.db;\n-    let analyzer = Lazy::new(move || sb.analyze(hir::InFile::new(file_id.into(), node), None));\n+    let db = sema.db;\n     match_ast! {\n         match node {\n             ast::CallExpr(it) => {\n-                get_param_name_hints(acc, db, &analyzer, ast::Expr::from(it));\n+                get_param_name_hints(acc, sema, ast::Expr::from(it));\n             },\n             ast::MethodCallExpr(it) => {\n-                get_param_name_hints(acc, db, &analyzer, ast::Expr::from(it));\n+                get_param_name_hints(acc, sema, ast::Expr::from(it));\n             },\n             ast::BindPat(it) => {\n                 let pat = ast::Pat::from(it.clone());\n-                let ty = analyzer.type_of_pat(db, &pat)?;\n+                let ty = sema.type_of_pat(&pat)?;\n \n                 if should_not_display_type_hint(db, &it, &ty) {\n                     return None;\n@@ -125,8 +122,7 @@ fn should_not_display_type_hint(db: &RootDatabase, bind_pat: &ast::BindPat, pat_\n \n fn get_param_name_hints(\n     acc: &mut Vec<InlayHint>,\n-    db: &RootDatabase,\n-    analyzer: &SourceAnalyzer,\n+    sema: &Semantics<RootDatabase>,\n     expr: ast::Expr,\n ) -> Option<()> {\n     let args = match &expr {\n@@ -138,7 +134,7 @@ fn get_param_name_hints(\n     // we need args len to determine whether to skip or not the &self parameter\n     .collect::<Vec<_>>();\n \n-    let fn_signature = get_fn_signature(db, analyzer, &expr)?;\n+    let fn_signature = get_fn_signature(sema, &expr)?;\n     let n_params_to_skip =\n         if fn_signature.has_self_param && fn_signature.parameter_names.len() > args.len() {\n             1\n@@ -184,28 +180,26 @@ fn should_show_param_hint(\n     true\n }\n \n-fn get_fn_signature(\n-    db: &RootDatabase,\n-    analyzer: &SourceAnalyzer,\n-    expr: &ast::Expr,\n-) -> Option<FunctionSignature> {\n+fn get_fn_signature(sema: &Semantics<RootDatabase>, expr: &ast::Expr) -> Option<FunctionSignature> {\n     match expr {\n         ast::Expr::CallExpr(expr) => {\n             // FIXME: Type::as_callable is broken for closures\n-            let callable_def = analyzer.type_of(db, &expr.expr()?)?.as_callable()?;\n+            let callable_def = sema.type_of_expr(&expr.expr()?)?.as_callable()?;\n             match callable_def {\n                 hir::CallableDef::FunctionId(it) => {\n-                    Some(FunctionSignature::from_hir(db, it.into()))\n+                    Some(FunctionSignature::from_hir(sema.db, it.into()))\n+                }\n+                hir::CallableDef::StructId(it) => {\n+                    FunctionSignature::from_struct(sema.db, it.into())\n                 }\n-                hir::CallableDef::StructId(it) => FunctionSignature::from_struct(db, it.into()),\n                 hir::CallableDef::EnumVariantId(it) => {\n-                    FunctionSignature::from_enum_variant(db, it.into())\n+                    FunctionSignature::from_enum_variant(sema.db, it.into())\n                 }\n             }\n         }\n         ast::Expr::MethodCallExpr(expr) => {\n-            let fn_def = analyzer.resolve_method_call(&expr)?;\n-            Some(FunctionSignature::from_hir(db, fn_def))\n+            let fn_def = sema.resolve_method_call(&expr)?;\n+            Some(FunctionSignature::from_hir(sema.db, fn_def))\n         }\n         _ => None,\n     }"}, {"sha": "f31d3c29557091e863482c427aeb964248812ba4", "filename": "crates/ra_ide/src/lib.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Flib.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -35,7 +35,6 @@ mod typing;\n mod matching_brace;\n mod display;\n mod inlay_hints;\n-mod expand;\n mod expand_macro;\n mod ssr;\n \n@@ -319,9 +318,7 @@ impl Analysis {\n         file_id: FileId,\n         max_inlay_hint_length: Option<usize>,\n     ) -> Cancelable<Vec<InlayHint>> {\n-        self.with_db(|db| {\n-            inlay_hints::inlay_hints(db, file_id, &db.parse(file_id).tree(), max_inlay_hint_length)\n-        })\n+        self.with_db(|db| inlay_hints::inlay_hints(db, file_id, max_inlay_hint_length))\n     }\n \n     /// Returns the set of folding ranges."}, {"sha": "7b8b727b4aec8da59a646aa1fddacd42f85cf88e", "filename": "crates/ra_ide/src/marks.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fmarks.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fmarks.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fmarks.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -11,4 +11,5 @@ test_utils::marks!(\n     call_info_bad_offset\n     dont_complete_current_use\n     test_resolve_parent_module_on_module_decl\n+    search_filters_by_range\n );"}, {"sha": "2c4bdb039361594b9e28b5c1174596381a8ba8b4", "filename": "crates/ra_ide/src/parent_module.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fparent_module.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fparent_module.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fparent_module.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,6 +1,7 @@\n //! FIXME: write short doc here\n \n-use ra_db::{CrateId, FileId, FilePosition, SourceDatabase};\n+use hir::Semantics;\n+use ra_db::{CrateId, FileId, FilePosition};\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n     algo::find_node_at_offset,\n@@ -13,10 +14,10 @@ use crate::NavigationTarget;\n /// This returns `Vec` because a module may be included from several places. We\n /// don't handle this case yet though, so the Vec has length at most one.\n pub(crate) fn parent_module(db: &RootDatabase, position: FilePosition) -> Vec<NavigationTarget> {\n-    let mut sb = hir::SourceBinder::new(db);\n-    let parse = db.parse(position.file_id);\n+    let sema = Semantics::new(db);\n+    let source_file = sema.parse(position.file_id);\n \n-    let mut module = find_node_at_offset::<ast::Module>(parse.tree().syntax(), position.offset);\n+    let mut module = find_node_at_offset::<ast::Module>(source_file.syntax(), position.offset);\n \n     // If cursor is literally on `mod foo`, go to the grandpa.\n     if let Some(m) = &module {\n@@ -30,8 +31,8 @@ pub(crate) fn parent_module(db: &RootDatabase, position: FilePosition) -> Vec<Na\n     }\n \n     let module = match module {\n-        Some(module) => sb.to_def(hir::InFile::new(position.file_id.into(), module)),\n-        None => sb.to_module_def(position.file_id),\n+        Some(module) => sema.to_def(&module),\n+        None => sema.to_module_def(position.file_id),\n     };\n     let module = match module {\n         None => return Vec::new(),\n@@ -43,8 +44,8 @@ pub(crate) fn parent_module(db: &RootDatabase, position: FilePosition) -> Vec<Na\n \n /// Returns `Vec` for the same reason as `parent_module`\n pub(crate) fn crate_for(db: &RootDatabase, file_id: FileId) -> Vec<CrateId> {\n-    let mut sb = hir::SourceBinder::new(db);\n-    let module = match sb.to_module_def(file_id) {\n+    let sema = Semantics::new(db);\n+    let module = match sema.to_module_def(file_id) {\n         Some(it) => it,\n         None => return Vec::new(),\n     };"}, {"sha": "baa8a4d2910bf5167561f978d57013a70d27905b", "filename": "crates/ra_ide/src/references.rs", "status": "modified", "additions": 69, "deletions": 61, "changes": 130, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Freferences.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Freferences.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Freferences.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -13,25 +13,22 @@ mod classify;\n mod rename;\n mod search_scope;\n \n-use crate::expand::descend_into_macros_with_analyzer;\n-use hir::{InFile, SourceBinder};\n+use hir::Semantics;\n use once_cell::unsync::Lazy;\n-use ra_db::{SourceDatabase, SourceDatabaseExt};\n+use ra_db::SourceDatabaseExt;\n use ra_ide_db::RootDatabase;\n use ra_prof::profile;\n use ra_syntax::{\n     algo::find_node_at_offset,\n     ast::{self, NameOwner},\n-    match_ast, AstNode, SourceFile, SyntaxKind, SyntaxNode, TextRange, TextUnit, TokenAtOffset,\n+    match_ast, AstNode, SyntaxKind, SyntaxNode, TextRange, TextUnit, TokenAtOffset,\n };\n+use test_utils::tested_by;\n \n use crate::{display::TryToNav, FilePosition, FileRange, NavigationTarget, RangeInfo};\n \n-pub(crate) use self::{\n-    classify::{classify_name, classify_name_ref},\n-    rename::rename,\n-};\n-pub(crate) use ra_ide_db::defs::NameDefinition;\n+pub(crate) use self::{classify::classify_name_ref, rename::rename};\n+pub(crate) use ra_ide_db::defs::{classify_name, NameDefinition};\n \n pub use self::search_scope::SearchScope;\n \n@@ -114,8 +111,8 @@ pub(crate) fn find_all_refs(\n     position: FilePosition,\n     search_scope: Option<SearchScope>,\n ) -> Option<RangeInfo<ReferenceSearchResult>> {\n-    let parse = db.parse(position.file_id);\n-    let syntax = parse.tree().syntax().clone();\n+    let sema = Semantics::new(db);\n+    let syntax = sema.parse(position.file_id).syntax().clone();\n \n     let (opt_name, search_kind) =\n         if let Some(name) = get_struct_def_name_for_struc_litetal_search(&syntax, position) {\n@@ -124,7 +121,7 @@ pub(crate) fn find_all_refs(\n             (find_node_at_offset::<ast::Name>(&syntax, position.offset), ReferenceKind::Other)\n         };\n \n-    let RangeInfo { range, info: (name, def) } = find_name(db, &syntax, position, opt_name)?;\n+    let RangeInfo { range, info: (name, def) } = find_name(&sema, &syntax, position, opt_name)?;\n     let declaration = def.try_to_nav(db)?;\n \n     let search_scope = {\n@@ -152,19 +149,18 @@ pub(crate) fn find_all_refs(\n }\n \n fn find_name(\n-    db: &RootDatabase,\n+    sema: &Semantics<RootDatabase>,\n     syntax: &SyntaxNode,\n     position: FilePosition,\n     opt_name: Option<ast::Name>,\n ) -> Option<RangeInfo<(String, NameDefinition)>> {\n-    let mut sb = SourceBinder::new(db);\n     if let Some(name) = opt_name {\n-        let def = classify_name(&mut sb, InFile::new(position.file_id.into(), &name))?;\n+        let def = classify_name(sema, &name)?;\n         let range = name.syntax().text_range();\n         return Some(RangeInfo::new(range, (name.text().to_string(), def)));\n     }\n     let name_ref = find_node_at_offset::<ast::NameRef>(&syntax, position.offset)?;\n-    let def = classify_name_ref(&mut sb, InFile::new(position.file_id.into(), &name_ref))?;\n+    let def = classify_name_ref(sema, &name_ref)?;\n     let range = name_ref.syntax().text_range();\n     Some(RangeInfo::new(range, (name_ref.text().to_string(), def)))\n }\n@@ -182,64 +178,53 @@ fn process_definition(\n \n     for (file_id, search_range) in scope {\n         let text = db.file_text(file_id);\n+        let search_range =\n+            search_range.unwrap_or(TextRange::offset_len(0.into(), TextUnit::of_str(&text)));\n \n-        let parse = Lazy::new(|| SourceFile::parse(&text));\n-        let mut sb = Lazy::new(|| SourceBinder::new(db));\n-        let mut analyzer = None;\n+        let sema = Semantics::new(db);\n+        let tree = Lazy::new(|| sema.parse(file_id).syntax().clone());\n \n         for (idx, _) in text.match_indices(pat) {\n             let offset = TextUnit::from_usize(idx);\n+            if !search_range.contains_inclusive(offset) {\n+                tested_by!(search_filters_by_range);\n+                continue;\n+            }\n \n-            let (name_ref, range) = if let Some(name_ref) =\n-                find_node_at_offset::<ast::NameRef>(parse.tree().syntax(), offset)\n-            {\n-                let range = name_ref.syntax().text_range();\n-                (InFile::new(file_id.into(), name_ref), range)\n-            } else {\n-                // Handle macro token cases\n-                let t = match parse.tree().syntax().token_at_offset(offset) {\n-                    TokenAtOffset::None => continue,\n-                    TokenAtOffset::Single(t) => t,\n-                    TokenAtOffset::Between(_, t) => t,\n-                };\n-                let range = t.text_range();\n-                let analyzer = analyzer.get_or_insert_with(|| {\n-                    sb.analyze(InFile::new(file_id.into(), parse.tree().syntax()), None)\n-                });\n-                let expanded = descend_into_macros_with_analyzer(\n-                    db,\n-                    &analyzer,\n-                    InFile::new(file_id.into(), t),\n-                );\n-                if let Some(token) = ast::NameRef::cast(expanded.value.parent()) {\n-                    (expanded.with_value(token), range)\n+            let name_ref =\n+                if let Some(name_ref) = find_node_at_offset::<ast::NameRef>(&tree, offset) {\n+                    name_ref\n                 } else {\n-                    continue;\n-                }\n-            };\n+                    // Handle macro token cases\n+                    let token = match tree.token_at_offset(offset) {\n+                        TokenAtOffset::None => continue,\n+                        TokenAtOffset::Single(t) => t,\n+                        TokenAtOffset::Between(_, t) => t,\n+                    };\n+                    let expanded = sema.descend_into_macros(token);\n+                    match ast::NameRef::cast(expanded.parent()) {\n+                        Some(name_ref) => name_ref,\n+                        _ => continue,\n+                    }\n+                };\n \n-            if let Some(search_range) = search_range {\n-                if !range.is_subrange(&search_range) {\n-                    continue;\n-                }\n-            }\n             // FIXME: reuse sb\n             // See https://github.com/rust-lang/rust/pull/68198#issuecomment-574269098\n \n-            if let Some(d) = classify_name_ref(&mut sb, name_ref.as_ref()) {\n+            if let Some(d) = classify_name_ref(&sema, &name_ref) {\n                 if d == def {\n-                    let kind = if is_record_lit_name_ref(&name_ref.value)\n-                        || is_call_expr_name_ref(&name_ref.value)\n-                    {\n-                        ReferenceKind::StructLiteral\n-                    } else {\n-                        ReferenceKind::Other\n-                    };\n-\n+                    let kind =\n+                        if is_record_lit_name_ref(&name_ref) || is_call_expr_name_ref(&name_ref) {\n+                            ReferenceKind::StructLiteral\n+                        } else {\n+                            ReferenceKind::Other\n+                        };\n+\n+                    let file_range = sema.original_range(name_ref.syntax());\n                     refs.push(Reference {\n-                        file_range: FileRange { file_id, range },\n+                        file_range,\n                         kind,\n-                        access: reference_access(&d, &name_ref.value),\n+                        access: reference_access(&d, &name_ref),\n                     });\n                 }\n             }\n@@ -348,6 +333,8 @@ fn is_call_expr_name_ref(name_ref: &ast::NameRef) -> bool {\n \n #[cfg(test)]\n mod tests {\n+    use test_utils::covers;\n+\n     use crate::{\n         mock_analysis::{analysis_and_position, single_file_with_position, MockAnalysis},\n         Declaration, Reference, ReferenceSearchResult, SearchScope,\n@@ -455,6 +442,27 @@ mod tests {\n         );\n     }\n \n+    #[test]\n+    fn search_filters_by_range() {\n+        covers!(search_filters_by_range);\n+        let code = r#\"\n+            fn foo() {\n+                let spam<|> = 92;\n+                spam + spam\n+            }\n+            fn bar() {\n+                let spam = 92;\n+                spam + spam\n+            }\n+        \"#;\n+        let refs = get_all_refs(code);\n+        check_result(\n+            refs,\n+            \"spam BIND_PAT FileId(1) [44; 48) Other Write\",\n+            &[\"FileId(1) [71; 75) Other Read\", \"FileId(1) [78; 82) Other Read\"],\n+        );\n+    }\n+\n     #[test]\n     fn test_find_all_refs_for_param_inside() {\n         let code = r#\""}, {"sha": "91b21429a65b0211623a698d8a0def7d42ddaa9b", "filename": "crates/ra_ide/src/references/classify.rs", "status": "modified", "additions": 13, "deletions": 17, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Freferences%2Fclassify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Freferences%2Fclassify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Freferences%2Fclassify.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,57 +1,53 @@\n //! Functions that are used to classify an element from its definition or reference.\n \n-use hir::{InFile, PathResolution, SourceBinder};\n+use hir::{PathResolution, Semantics};\n+use ra_ide_db::defs::NameDefinition;\n+use ra_ide_db::RootDatabase;\n use ra_prof::profile;\n use ra_syntax::{ast, AstNode};\n use test_utils::tested_by;\n \n-use super::NameDefinition;\n-use ra_ide_db::RootDatabase;\n-\n-pub use ra_ide_db::defs::{classify_name, from_module_def, from_struct_field};\n+pub use ra_ide_db::defs::{from_module_def, from_struct_field};\n \n pub(crate) fn classify_name_ref(\n-    sb: &mut SourceBinder<RootDatabase>,\n-    name_ref: InFile<&ast::NameRef>,\n+    sema: &Semantics<RootDatabase>,\n+    name_ref: &ast::NameRef,\n ) -> Option<NameDefinition> {\n     let _p = profile(\"classify_name_ref\");\n \n-    let parent = name_ref.value.syntax().parent()?;\n-    let analyzer = sb.analyze(name_ref.map(|it| it.syntax()), None);\n+    let parent = name_ref.syntax().parent()?;\n \n     if let Some(method_call) = ast::MethodCallExpr::cast(parent.clone()) {\n         tested_by!(goto_def_for_methods);\n-        if let Some(func) = analyzer.resolve_method_call(&method_call) {\n+        if let Some(func) = sema.resolve_method_call(&method_call) {\n             return Some(from_module_def(func.into()));\n         }\n     }\n \n     if let Some(field_expr) = ast::FieldExpr::cast(parent.clone()) {\n         tested_by!(goto_def_for_fields);\n-        if let Some(field) = analyzer.resolve_field(&field_expr) {\n+        if let Some(field) = sema.resolve_field(&field_expr) {\n             return Some(from_struct_field(field));\n         }\n     }\n \n     if let Some(record_field) = ast::RecordField::cast(parent.clone()) {\n         tested_by!(goto_def_for_record_fields);\n         tested_by!(goto_def_for_field_init_shorthand);\n-        if let Some(field_def) = analyzer.resolve_record_field(&record_field) {\n+        if let Some(field_def) = sema.resolve_record_field(&record_field) {\n             return Some(from_struct_field(field_def));\n         }\n     }\n \n     if let Some(macro_call) = parent.ancestors().find_map(ast::MacroCall::cast) {\n         tested_by!(goto_def_for_macros);\n-        if let Some(macro_def) =\n-            analyzer.resolve_macro_call(sb.db, name_ref.with_value(&macro_call))\n-        {\n+        if let Some(macro_def) = sema.resolve_macro_call(&macro_call) {\n             return Some(NameDefinition::Macro(macro_def));\n         }\n     }\n \n-    let path = name_ref.value.syntax().ancestors().find_map(ast::Path::cast)?;\n-    let resolved = analyzer.resolve_path(sb.db, &path)?;\n+    let path = name_ref.syntax().ancestors().find_map(ast::Path::cast)?;\n+    let resolved = sema.resolve_path(&path)?;\n     let res = match resolved {\n         PathResolution::Def(def) => from_module_def(def),\n         PathResolution::AssocItem(item) => {"}, {"sha": "5b4bcf434e40bda02d6cdf01e5249abe703889e1", "filename": "crates/ra_ide/src/references/rename.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Freferences%2Frename.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Freferences%2Frename.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Freferences%2Frename.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,7 +1,7 @@\n //! FIXME: write short doc here\n \n-use hir::ModuleSource;\n-use ra_db::{RelativePath, RelativePathBuf, SourceDatabase, SourceDatabaseExt};\n+use hir::{ModuleSource, Semantics};\n+use ra_db::{RelativePath, RelativePathBuf, SourceDatabaseExt};\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n     algo::find_node_at_offset, ast, lex_single_valid_syntax_kind, AstNode, SyntaxKind, SyntaxNode,\n@@ -24,15 +24,16 @@ pub(crate) fn rename(\n         _ => return None,\n     }\n \n-    let parse = db.parse(position.file_id);\n+    let sema = Semantics::new(db);\n+    let source_file = sema.parse(position.file_id);\n     if let Some((ast_name, ast_module)) =\n-        find_name_and_module_at_offset(parse.tree().syntax(), position)\n+        find_name_and_module_at_offset(source_file.syntax(), position)\n     {\n         let range = ast_name.syntax().text_range();\n-        rename_mod(db, &ast_name, &ast_module, position, new_name)\n+        rename_mod(&sema, &ast_name, &ast_module, position, new_name)\n             .map(|info| RangeInfo::new(range, info))\n     } else {\n-        rename_reference(db, position, new_name)\n+        rename_reference(sema.db, position, new_name)\n     }\n }\n \n@@ -54,21 +55,20 @@ fn source_edit_from_file_id_range(\n }\n \n fn rename_mod(\n-    db: &RootDatabase,\n+    sema: &Semantics<RootDatabase>,\n     ast_name: &ast::Name,\n     ast_module: &ast::Module,\n     position: FilePosition,\n     new_name: &str,\n ) -> Option<SourceChange> {\n     let mut source_file_edits = Vec::new();\n     let mut file_system_edits = Vec::new();\n-    let module_src = hir::InFile { file_id: position.file_id.into(), value: ast_module.clone() };\n-    if let Some(module) = hir::SourceBinder::new(db).to_def(module_src) {\n-        let src = module.definition_source(db);\n-        let file_id = src.file_id.original_file(db);\n+    if let Some(module) = sema.to_def(ast_module) {\n+        let src = module.definition_source(sema.db);\n+        let file_id = src.file_id.original_file(sema.db);\n         match src.value {\n             ModuleSource::SourceFile(..) => {\n-                let mod_path: RelativePathBuf = db.file_relative_path(file_id);\n+                let mod_path: RelativePathBuf = sema.db.file_relative_path(file_id);\n                 // mod is defined in path/to/dir/mod.rs\n                 let dst_path = if mod_path.file_stem() == Some(\"mod\") {\n                     mod_path\n@@ -82,7 +82,7 @@ fn rename_mod(\n                 if let Some(path) = dst_path {\n                     let move_file = FileSystemEdit::MoveFile {\n                         src: file_id,\n-                        dst_source_root: db.file_source_root(position.file_id),\n+                        dst_source_root: sema.db.file_source_root(position.file_id),\n                         dst_path: path,\n                     };\n                     file_system_edits.push(move_file);\n@@ -98,7 +98,7 @@ fn rename_mod(\n     };\n     source_file_edits.push(edit);\n \n-    if let Some(RangeInfo { range: _, info: refs }) = find_all_refs(db, position, None) {\n+    if let Some(RangeInfo { range: _, info: refs }) = find_all_refs(sema.db, position, None) {\n         let ref_edits = refs.references.into_iter().map(|reference| {\n             source_edit_from_file_id_range(\n                 reference.file_range.file_id,"}, {"sha": "74877e90fec5d887fbf14cd3a59be292bc150530", "filename": "crates/ra_ide/src/runnables.rs", "status": "modified", "additions": 16, "deletions": 34, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Frunnables.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Frunnables.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Frunnables.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,8 +1,7 @@\n //! FIXME: write short doc here\n \n-use hir::{InFile, SourceBinder};\n+use hir::Semantics;\n use itertools::Itertools;\n-use ra_db::SourceDatabase;\n use ra_ide_db::RootDatabase;\n use ra_syntax::{\n     ast::{self, AstNode, AttrsOwner, ModuleItemOwner, NameOwner},\n@@ -42,46 +41,33 @@ pub enum RunnableKind {\n }\n \n pub(crate) fn runnables(db: &RootDatabase, file_id: FileId) -> Vec<Runnable> {\n-    let parse = db.parse(file_id);\n-    let mut sb = SourceBinder::new(db);\n-    parse.tree().syntax().descendants().filter_map(|i| runnable(db, &mut sb, file_id, i)).collect()\n+    let sema = Semantics::new(db);\n+    let source_file = sema.parse(file_id);\n+    source_file.syntax().descendants().filter_map(|i| runnable(&sema, i)).collect()\n }\n \n-fn runnable(\n-    db: &RootDatabase,\n-    source_binder: &mut SourceBinder<RootDatabase>,\n-    file_id: FileId,\n-    item: SyntaxNode,\n-) -> Option<Runnable> {\n+fn runnable(sema: &Semantics<RootDatabase>, item: SyntaxNode) -> Option<Runnable> {\n     match_ast! {\n         match item {\n-            ast::FnDef(it) => { runnable_fn(db, source_binder, file_id, it) },\n-            ast::Module(it) => { runnable_mod(db, source_binder, file_id, it) },\n-            _ => { None },\n+            ast::FnDef(it) => { runnable_fn(sema, it) },\n+            ast::Module(it) => { runnable_mod(sema, it) },\n+            _ => None,\n         }\n     }\n }\n \n-fn runnable_fn(\n-    db: &RootDatabase,\n-    source_binder: &mut SourceBinder<RootDatabase>,\n-    file_id: FileId,\n-    fn_def: ast::FnDef,\n-) -> Option<Runnable> {\n+fn runnable_fn(sema: &Semantics<RootDatabase>, fn_def: ast::FnDef) -> Option<Runnable> {\n     let name_string = fn_def.name()?.text().to_string();\n \n     let kind = if name_string == \"main\" {\n         RunnableKind::Bin\n     } else {\n-        let test_id = if let Some(module) = source_binder\n-            .to_def(InFile::new(file_id.into(), fn_def.clone()))\n-            .map(|def| def.module(db))\n-        {\n+        let test_id = if let Some(module) = sema.to_def(&fn_def).map(|def| def.module(sema.db)) {\n             let path = module\n-                .path_to_root(db)\n+                .path_to_root(sema.db)\n                 .into_iter()\n                 .rev()\n-                .filter_map(|it| it.name(db))\n+                .filter_map(|it| it.name(sema.db))\n                 .map(|name| name.to_string())\n                 .chain(std::iter::once(name_string))\n                 .join(\"::\");\n@@ -115,12 +101,7 @@ fn has_test_related_attribute(fn_def: &ast::FnDef) -> bool {\n         .any(|attribute_text| attribute_text.contains(\"test\"))\n }\n \n-fn runnable_mod(\n-    db: &RootDatabase,\n-    source_binder: &mut SourceBinder<RootDatabase>,\n-    file_id: FileId,\n-    module: ast::Module,\n-) -> Option<Runnable> {\n+fn runnable_mod(sema: &Semantics<RootDatabase>, module: ast::Module) -> Option<Runnable> {\n     let has_test_function = module\n         .item_list()?\n         .items()\n@@ -133,9 +114,10 @@ fn runnable_mod(\n         return None;\n     }\n     let range = module.syntax().text_range();\n-    let module = source_binder.to_def(InFile::new(file_id.into(), module))?;\n+    let module = sema.to_def(&module)?;\n \n-    let path = module.path_to_root(db).into_iter().rev().filter_map(|it| it.name(db)).join(\"::\");\n+    let path =\n+        module.path_to_root(sema.db).into_iter().rev().filter_map(|it| it.name(sema.db)).join(\"::\");\n     Some(Runnable { range, kind: RunnableKind::TestMod { path } })\n }\n "}, {"sha": "d6a7da9532a879b8a6297b7d5df52ca3144f5398", "filename": "crates/ra_ide/src/snapshots/rainbow_highlighting.html", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fsnapshots%2Frainbow_highlighting.html", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fsnapshots%2Frainbow_highlighting.html", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fsnapshots%2Frainbow_highlighting.html?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -25,14 +25,14 @@\n .keyword\\.control  { color: #F0DFAF; font-weight: bold; }\n </style>\n <pre><code><span class=\"keyword\">fn</span> <span class=\"function\">main</span>() {\n-    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"2217585909179791122\" style=\"color: hsl(280,74%,48%);\">hello</span> = <span class=\"string\">\"hello\"</span>;\n-    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"4303609361109701698\" style=\"color: hsl(242,75%,88%);\">x</span> = <span class=\"variable\" data-binding-hash=\"2217585909179791122\" style=\"color: hsl(280,74%,48%);\">hello</span>.to_string();\n-    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"13865792086344377029\" style=\"color: hsl(340,64%,86%);\">y</span> = <span class=\"variable\" data-binding-hash=\"2217585909179791122\" style=\"color: hsl(280,74%,48%);\">hello</span>.to_string();\n+    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"8121853618659664005\" style=\"color: hsl(261,57%,61%);\">hello</span> = <span class=\"string\">\"hello\"</span>;\n+    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"2705725358298919760\" style=\"color: hsl(17,51%,74%);\">x</span> = <span class=\"variable\" data-binding-hash=\"8121853618659664005\" style=\"color: hsl(261,57%,61%);\">hello</span>.to_string();\n+    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"3365759661443752373\" style=\"color: hsl(127,76%,66%);\">y</span> = <span class=\"variable\" data-binding-hash=\"8121853618659664005\" style=\"color: hsl(261,57%,61%);\">hello</span>.to_string();\n \n-    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"7011301204224269512\" style=\"color: hsl(198,45%,40%);\">x</span> = <span class=\"string\">\"other color please!\"</span>;\n-    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"12461245066629867975\" style=\"color: hsl(132,91%,68%);\">y</span> = <span class=\"variable\" data-binding-hash=\"7011301204224269512\" style=\"color: hsl(198,45%,40%);\">x</span>.to_string();\n+    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"794745962933817518\" style=\"color: hsl(19,74%,76%);\">x</span> = <span class=\"string\">\"other color please!\"</span>;\n+    <span class=\"keyword\">let</span> <span class=\"variable\" data-binding-hash=\"6717528807933952652\" style=\"color: hsl(85,49%,84%);\">y</span> = <span class=\"variable\" data-binding-hash=\"794745962933817518\" style=\"color: hsl(19,74%,76%);\">x</span>.to_string();\n }\n \n <span class=\"keyword\">fn</span> <span class=\"function\">bar</span>() {\n-    <span class=\"keyword\">let</span> <span class=\"keyword\">mut</span> <span class=\"variable.mut\" data-binding-hash=\"2217585909179791122\" style=\"color: hsl(280,74%,48%);\">hello</span> = <span class=\"string\">\"hello\"</span>;\n+    <span class=\"keyword\">let</span> <span class=\"keyword\">mut</span> <span class=\"variable.mut\" data-binding-hash=\"8121853618659664005\" style=\"color: hsl(261,57%,61%);\">hello</span> = <span class=\"string\">\"hello\"</span>;\n }</code></pre>\n\\ No newline at end of file"}, {"sha": "987476d2c97b1d1936f197a16ce40076cf1034bc", "filename": "crates/ra_ide/src/syntax_highlighting.rs", "status": "modified", "additions": 39, "deletions": 48, "changes": 87, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fsyntax_highlighting.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide%2Fsrc%2Fsyntax_highlighting.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fsyntax_highlighting.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,20 +1,19 @@\n //! FIXME: write short doc here\n \n-use hir::{HirFileId, InFile, Name, SourceAnalyzer, SourceBinder};\n+use hir::{Name, Semantics};\n use ra_db::SourceDatabase;\n-use ra_ide_db::{defs::NameDefinition, RootDatabase};\n+use ra_ide_db::{\n+    defs::{classify_name, NameDefinition},\n+    RootDatabase,\n+};\n use ra_prof::profile;\n use ra_syntax::{\n     ast, AstNode, Direction, NodeOrToken, SyntaxElement, SyntaxKind, SyntaxKind::*, SyntaxToken,\n     TextRange, WalkEvent, T,\n };\n use rustc_hash::FxHashMap;\n \n-use crate::{\n-    expand::descend_into_macros_with_analyzer,\n-    references::{classify_name, classify_name_ref},\n-    FileId,\n-};\n+use crate::{references::classify_name_ref, FileId};\n \n pub mod tags {\n     pub const FIELD: &str = \"field\";\n@@ -73,14 +72,11 @@ pub(crate) fn highlight(\n     range: Option<TextRange>,\n ) -> Vec<HighlightedRange> {\n     let _p = profile(\"highlight\");\n+    let sema = Semantics::new(db);\n+    let root = sema.parse(file_id).syntax().clone();\n \n-    let parse = db.parse(file_id);\n-    let root = parse.tree().syntax().clone();\n-\n-    let mut sb = SourceBinder::new(db);\n     let mut bindings_shadow_count: FxHashMap<Name, u32> = FxHashMap::default();\n     let mut res = Vec::new();\n-    let analyzer = sb.analyze(InFile::new(file_id.into(), &root), None);\n \n     let mut in_macro_call = None;\n \n@@ -105,7 +101,7 @@ pub(crate) fn highlight(\n                 match node.kind() {\n                     MACRO_CALL => {\n                         in_macro_call = Some(node.clone());\n-                        if let Some(range) = highlight_macro(InFile::new(file_id.into(), node)) {\n+                        if let Some(range) = highlight_macro(node) {\n                             res.push(HighlightedRange {\n                                 range,\n                                 tag: tags::MACRO,\n@@ -116,10 +112,9 @@ pub(crate) fn highlight(\n                     _ if in_macro_call.is_some() => {\n                         if let Some(token) = node.as_token() {\n                             if let Some((tag, binding_hash)) = highlight_token_tree(\n-                                &mut sb,\n-                                &analyzer,\n+                                &sema,\n                                 &mut bindings_shadow_count,\n-                                InFile::new(file_id.into(), token.clone()),\n+                                token.clone(),\n                             ) {\n                                 res.push(HighlightedRange {\n                                     range: node.text_range(),\n@@ -130,11 +125,9 @@ pub(crate) fn highlight(\n                         }\n                     }\n                     _ => {\n-                        if let Some((tag, binding_hash)) = highlight_node(\n-                            &mut sb,\n-                            &mut bindings_shadow_count,\n-                            InFile::new(file_id.into(), node.clone()),\n-                        ) {\n+                        if let Some((tag, binding_hash)) =\n+                            highlight_node(&sema, &mut bindings_shadow_count, node.clone())\n+                        {\n                             res.push(HighlightedRange {\n                                 range: node.text_range(),\n                                 tag,\n@@ -161,8 +154,8 @@ pub(crate) fn highlight(\n     res\n }\n \n-fn highlight_macro(node: InFile<SyntaxElement>) -> Option<TextRange> {\n-    let macro_call = ast::MacroCall::cast(node.value.as_node()?.clone())?;\n+fn highlight_macro(node: SyntaxElement) -> Option<TextRange> {\n+    let macro_call = ast::MacroCall::cast(node.as_node()?.clone())?;\n     let path = macro_call.path()?;\n     let name_ref = path.segment()?.name_ref()?;\n \n@@ -179,35 +172,34 @@ fn highlight_macro(node: InFile<SyntaxElement>) -> Option<TextRange> {\n }\n \n fn highlight_token_tree(\n-    sb: &mut SourceBinder<RootDatabase>,\n-    analyzer: &SourceAnalyzer,\n+    sema: &Semantics<RootDatabase>,\n     bindings_shadow_count: &mut FxHashMap<Name, u32>,\n-    token: InFile<SyntaxToken>,\n+    token: SyntaxToken,\n ) -> Option<(&'static str, Option<u64>)> {\n-    if token.value.parent().kind() != TOKEN_TREE {\n+    if token.parent().kind() != TOKEN_TREE {\n         return None;\n     }\n-    let token = descend_into_macros_with_analyzer(sb.db, analyzer, token);\n+    let token = sema.descend_into_macros(token.clone());\n     let expanded = {\n-        let parent = token.value.parent();\n+        let parent = token.parent();\n         // We only care Name and Name_ref\n-        match (token.value.kind(), parent.kind()) {\n-            (IDENT, NAME) | (IDENT, NAME_REF) => token.with_value(parent.into()),\n-            _ => token.map(|it| it.into()),\n+        match (token.kind(), parent.kind()) {\n+            (IDENT, NAME) | (IDENT, NAME_REF) => parent.into(),\n+            _ => token.into(),\n         }\n     };\n \n-    highlight_node(sb, bindings_shadow_count, expanded)\n+    highlight_node(sema, bindings_shadow_count, expanded)\n }\n \n fn highlight_node(\n-    sb: &mut SourceBinder<RootDatabase>,\n+    sema: &Semantics<RootDatabase>,\n     bindings_shadow_count: &mut FxHashMap<Name, u32>,\n-    node: InFile<SyntaxElement>,\n+    node: SyntaxElement,\n ) -> Option<(&'static str, Option<u64>)> {\n-    let db = sb.db;\n+    let db = sema.db;\n     let mut binding_hash = None;\n-    let tag = match node.value.kind() {\n+    let tag = match node.kind() {\n         FN_DEF => {\n             bindings_shadow_count.clear();\n             return None;\n@@ -216,19 +208,18 @@ fn highlight_node(\n         STRING | RAW_STRING | RAW_BYTE_STRING | BYTE_STRING => tags::LITERAL_STRING,\n         ATTR => tags::LITERAL_ATTRIBUTE,\n         // Special-case field init shorthand\n-        NAME_REF if node.value.parent().and_then(ast::RecordField::cast).is_some() => tags::FIELD,\n-        NAME_REF if node.value.ancestors().any(|it| it.kind() == ATTR) => return None,\n+        NAME_REF if node.parent().and_then(ast::RecordField::cast).is_some() => tags::FIELD,\n+        NAME_REF if node.ancestors().any(|it| it.kind() == ATTR) => return None,\n         NAME_REF => {\n-            let name_ref = node.value.as_node().cloned().and_then(ast::NameRef::cast).unwrap();\n-            let name_kind = classify_name_ref(sb, node.with_value(&name_ref));\n+            let name_ref = node.as_node().cloned().and_then(ast::NameRef::cast).unwrap();\n+            let name_kind = classify_name_ref(sema, &name_ref);\n             match name_kind {\n                 Some(name_kind) => {\n                     if let NameDefinition::Local(local) = &name_kind {\n                         if let Some(name) = local.name(db) {\n                             let shadow_count =\n                                 bindings_shadow_count.entry(name.clone()).or_default();\n-                            binding_hash =\n-                                Some(calc_binding_hash(node.file_id, &name, *shadow_count))\n+                            binding_hash = Some(calc_binding_hash(&name, *shadow_count))\n                         }\n                     };\n \n@@ -238,14 +229,14 @@ fn highlight_node(\n             }\n         }\n         NAME => {\n-            let name = node.value.as_node().cloned().and_then(ast::Name::cast).unwrap();\n-            let name_kind = classify_name(sb, node.with_value(&name));\n+            let name = node.as_node().cloned().and_then(ast::Name::cast).unwrap();\n+            let name_kind = classify_name(sema, &name);\n \n             if let Some(NameDefinition::Local(local)) = &name_kind {\n                 if let Some(name) = local.name(db) {\n                     let shadow_count = bindings_shadow_count.entry(name.clone()).or_default();\n                     *shadow_count += 1;\n-                    binding_hash = Some(calc_binding_hash(node.file_id, &name, *shadow_count))\n+                    binding_hash = Some(calc_binding_hash(&name, *shadow_count))\n                 }\n             };\n \n@@ -272,7 +263,7 @@ fn highlight_node(\n \n     return Some((tag, binding_hash));\n \n-    fn calc_binding_hash(file_id: HirFileId, name: &Name, shadow_count: u32) -> u64 {\n+    fn calc_binding_hash(name: &Name, shadow_count: u32) -> u64 {\n         fn hash<T: std::hash::Hash + std::fmt::Debug>(x: T) -> u64 {\n             use std::{collections::hash_map::DefaultHasher, hash::Hasher};\n \n@@ -281,7 +272,7 @@ fn highlight_node(\n             hasher.finish()\n         }\n \n-        hash((file_id, name, shadow_count))\n+        hash((name, shadow_count))\n     }\n }\n "}, {"sha": "e10e72f7112c80caf099b8f8f2819fb020534f54", "filename": "crates/ra_ide_db/src/defs.rs", "status": "modified", "additions": 17, "deletions": 33, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide_db%2Fsrc%2Fdefs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide_db%2Fsrc%2Fdefs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_db%2Fsrc%2Fdefs.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -6,8 +6,8 @@\n // FIXME: this badly needs rename/rewrite (matklad, 2020-02-06).\n \n use hir::{\n-    Adt, FieldSource, HasSource, ImplBlock, InFile, Local, MacroDef, Module, ModuleDef,\n-    SourceBinder, StructField, TypeParam,\n+    Adt, FieldSource, HasSource, ImplBlock, Local, MacroDef, Module, ModuleDef, Semantics,\n+    StructField, TypeParam,\n };\n use ra_prof::profile;\n use ra_syntax::{\n@@ -68,78 +68,62 @@ impl NameDefinition {\n     }\n }\n \n-pub fn classify_name(\n-    sb: &mut SourceBinder<RootDatabase>,\n-    name: InFile<&ast::Name>,\n-) -> Option<NameDefinition> {\n+pub fn classify_name(sema: &Semantics<RootDatabase>, name: &ast::Name) -> Option<NameDefinition> {\n     let _p = profile(\"classify_name\");\n-    let parent = name.value.syntax().parent()?;\n+    let parent = name.syntax().parent()?;\n \n     match_ast! {\n         match parent {\n             ast::BindPat(it) => {\n-                let src = name.with_value(it);\n-                let local = sb.to_def(src)?;\n+                let local = sema.to_def(&it)?;\n                 Some(NameDefinition::Local(local))\n             },\n             ast::RecordFieldDef(it) => {\n-                let src = name.with_value(it);\n-                let field: hir::StructField = sb.to_def(src)?;\n+                let field: hir::StructField = sema.to_def(&it)?;\n                 Some(from_struct_field(field))\n             },\n             ast::Module(it) => {\n-                let def = sb.to_def(name.with_value(it))?;\n+                let def = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::StructDef(it) => {\n-                let src = name.with_value(it);\n-                let def: hir::Struct = sb.to_def(src)?;\n+                let def: hir::Struct = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::EnumDef(it) => {\n-                let src = name.with_value(it);\n-                let def: hir::Enum = sb.to_def(src)?;\n+                let def: hir::Enum = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::TraitDef(it) => {\n-                let src = name.with_value(it);\n-                let def: hir::Trait = sb.to_def(src)?;\n+                let def: hir::Trait = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::StaticDef(it) => {\n-                let src = name.with_value(it);\n-                let def: hir::Static = sb.to_def(src)?;\n+                let def: hir::Static = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::EnumVariant(it) => {\n-                let src = name.with_value(it);\n-                let def: hir::EnumVariant = sb.to_def(src)?;\n+                let def: hir::EnumVariant = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::FnDef(it) => {\n-                let src = name.with_value(it);\n-                let def: hir::Function = sb.to_def(src)?;\n+                let def: hir::Function = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::ConstDef(it) => {\n-                let src = name.with_value(it);\n-                let def: hir::Const = sb.to_def(src)?;\n+                let def: hir::Const = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::TypeAliasDef(it) => {\n-                let src = name.with_value(it);\n-                let def: hir::TypeAlias = sb.to_def(src)?;\n+                let def: hir::TypeAlias = sema.to_def(&it)?;\n                 Some(from_module_def(def.into()))\n             },\n             ast::MacroCall(it) => {\n-                let src = name.with_value(it);\n-                let def = sb.to_def(src.clone())?;\n-\n+                let def = sema.to_def(&it)?;\n                 Some(NameDefinition::Macro(def))\n             },\n             ast::TypeParam(it) => {\n-                let src = name.with_value(it);\n-                let def = sb.to_def(src)?;\n+                let def = sema.to_def(&it)?;\n                 Some(NameDefinition::TypeParam(def))\n             },\n             _ => None,"}, {"sha": "e590d2a5c3f77e78ad287256459a50f21ce81294", "filename": "crates/ra_ide_db/src/imports_locator.rs", "status": "modified", "additions": 10, "deletions": 16, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide_db%2Fsrc%2Fimports_locator.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_ide_db%2Fsrc%2Fimports_locator.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_db%2Fsrc%2Fimports_locator.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -1,7 +1,7 @@\n //! This module contains an import search funcionality that is provided to the ra_assists module.\n //! Later, this should be moved away to a separate crate that is accessible from the ra_assists module.\n \n-use hir::{db::HirDatabase, ModuleDef, SourceBinder};\n+use hir::{ModuleDef, Semantics};\n use ra_prof::profile;\n use ra_syntax::{ast, AstNode, SyntaxKind::NAME};\n \n@@ -12,17 +12,17 @@ use crate::{\n };\n \n pub struct ImportsLocator<'a> {\n-    source_binder: SourceBinder<'a, RootDatabase>,\n+    sema: Semantics<'a, RootDatabase>,\n }\n \n impl<'a> ImportsLocator<'a> {\n     pub fn new(db: &'a RootDatabase) -> Self {\n-        Self { source_binder: SourceBinder::new(db) }\n+        Self { sema: Semantics::new(db) }\n     }\n \n     pub fn find_imports(&mut self, name_to_import: &str) -> Vec<ModuleDef> {\n         let _p = profile(\"search_for_imports\");\n-        let db = self.source_binder.db;\n+        let db = self.sema.db;\n \n         let project_results = {\n             let mut query = Query::new(name_to_import.to_string());\n@@ -41,30 +41,24 @@ impl<'a> ImportsLocator<'a> {\n         project_results\n             .into_iter()\n             .chain(lib_results.into_iter())\n-            .filter_map(|import_candidate| self.get_name_definition(db, &import_candidate))\n+            .filter_map(|import_candidate| self.get_name_definition(&import_candidate))\n             .filter_map(|name_definition_to_import| match name_definition_to_import {\n                 NameDefinition::ModuleDef(module_def) => Some(module_def),\n                 _ => None,\n             })\n             .collect()\n     }\n \n-    fn get_name_definition(\n-        &mut self,\n-        db: &impl HirDatabase,\n-        import_candidate: &FileSymbol,\n-    ) -> Option<NameDefinition> {\n+    fn get_name_definition(&mut self, import_candidate: &FileSymbol) -> Option<NameDefinition> {\n         let _p = profile(\"get_name_definition\");\n-        let file_id = import_candidate.file_id.into();\n-        let candidate_node = import_candidate.ptr.to_node(&db.parse_or_expand(file_id)?);\n+        let file_id = import_candidate.file_id;\n+\n+        let candidate_node = import_candidate.ptr.to_node(self.sema.parse(file_id).syntax());\n         let candidate_name_node = if candidate_node.kind() != NAME {\n             candidate_node.children().find(|it| it.kind() == NAME)?\n         } else {\n             candidate_node\n         };\n-        classify_name(\n-            &mut self.source_binder,\n-            hir::InFile { file_id, value: &ast::Name::cast(candidate_name_node)? },\n-        )\n+        classify_name(&self.sema, &ast::Name::cast(candidate_name_node)?)\n     }\n }"}, {"sha": "f14bcbb35053fc8671375c1f516d108f915d1220", "filename": "crates/ra_syntax/src/algo.rs", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_syntax%2Fsrc%2Falgo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3a4c4429de83450654795534e64e878a774a088/crates%2Fra_syntax%2Fsrc%2Falgo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Falgo.rs?ref=c3a4c4429de83450654795534e64e878a774a088", "patch": "@@ -4,7 +4,7 @@ use std::ops::RangeInclusive;\n \n use itertools::Itertools;\n use ra_text_edit::TextEditBuilder;\n-use rustc_hash::FxHashMap;\n+use rustc_hash::{FxHashMap, FxHashSet};\n \n use crate::{\n     AstNode, Direction, NodeOrToken, SyntaxElement, SyntaxNode, SyntaxNodePtr, TextRange, TextUnit,\n@@ -56,6 +56,11 @@ pub fn find_covering_element(root: &SyntaxNode, range: TextRange) -> SyntaxEleme\n     root.covering_element(range)\n }\n \n+pub fn least_common_ancestor(u: &SyntaxNode, v: &SyntaxNode) -> Option<SyntaxNode> {\n+    let u_ancestors = u.ancestors().collect::<FxHashSet<SyntaxNode>>();\n+    v.ancestors().find(|it| u_ancestors.contains(it))\n+}\n+\n #[derive(Debug, PartialEq, Eq, Clone, Copy)]\n pub enum InsertPosition<T> {\n     First,"}]}