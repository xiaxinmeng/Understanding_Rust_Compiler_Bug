{"sha": "10c926652515052000e44ef4ac10e6b4ebbc6e3a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjEwYzkyNjY1MjUxNTA1MjAwMGU0NGVmNGFjMTBlNmI0ZWJiYzZlM2E=", "commit": {"author": {"name": "Patrick Walton", "email": "pcwalton@mimiga.net", "date": "2011-05-11T00:27:30Z"}, "committer": {"name": "Patrick Walton", "email": "pcwalton@mimiga.net", "date": "2011-05-11T00:27:59Z"}, "message": "rustc: Number everything with an annotation", "tree": {"sha": "bce087c37ed3f7b74264c67b3b0b62757e910987", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bce087c37ed3f7b74264c67b3b0b62757e910987"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/10c926652515052000e44ef4ac10e6b4ebbc6e3a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/10c926652515052000e44ef4ac10e6b4ebbc6e3a", "html_url": "https://github.com/rust-lang/rust/commit/10c926652515052000e44ef4ac10e6b4ebbc6e3a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/10c926652515052000e44ef4ac10e6b4ebbc6e3a/comments", "author": {"login": "pcwalton", "id": 157897, "node_id": "MDQ6VXNlcjE1Nzg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/157897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcwalton", "html_url": "https://github.com/pcwalton", "followers_url": "https://api.github.com/users/pcwalton/followers", "following_url": "https://api.github.com/users/pcwalton/following{/other_user}", "gists_url": "https://api.github.com/users/pcwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcwalton/subscriptions", "organizations_url": "https://api.github.com/users/pcwalton/orgs", "repos_url": "https://api.github.com/users/pcwalton/repos", "events_url": "https://api.github.com/users/pcwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/pcwalton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pcwalton", "id": 157897, "node_id": "MDQ6VXNlcjE1Nzg5Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/157897?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pcwalton", "html_url": "https://github.com/pcwalton", "followers_url": "https://api.github.com/users/pcwalton/followers", "following_url": "https://api.github.com/users/pcwalton/following{/other_user}", "gists_url": "https://api.github.com/users/pcwalton/gists{/gist_id}", "starred_url": "https://api.github.com/users/pcwalton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pcwalton/subscriptions", "organizations_url": "https://api.github.com/users/pcwalton/orgs", "repos_url": "https://api.github.com/users/pcwalton/repos", "events_url": "https://api.github.com/users/pcwalton/events{/privacy}", "received_events_url": "https://api.github.com/users/pcwalton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4b5b96c51101a02e18eb2bb27e742ef0b3e74537", "url": "https://api.github.com/repos/rust-lang/rust/commits/4b5b96c51101a02e18eb2bb27e742ef0b3e74537", "html_url": "https://github.com/rust-lang/rust/commit/4b5b96c51101a02e18eb2bb27e742ef0b3e74537"}], "stats": {"total": 368, "additions": 193, "deletions": 175}, "files": [{"sha": "fc2c04f458cc947ec4e4e84006e2c4946625a244", "filename": "src/comp/front/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Ffront%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Ffront%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fast.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -22,7 +22,7 @@ type ty_param = ident;\n \n // Annotations added during successive passes.\n tag ann {\n-    ann_none;\n+    ann_none(uint);\n     ann_type(middle.ty.t,\n              Option.t[vec[middle.ty.t]], /* ty param substs */\n              Option.t[@ts_ann]); /* pre- and postcondition for typestate */"}, {"sha": "a7fd545d6402bc9f59917e1adeb13be6518bb8bf", "filename": "src/comp/front/extenv.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Ffront%2Fextenv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Ffront%2Fextenv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fextenv.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -29,10 +29,10 @@ fn expand_syntax_ext(parser.parser p,\n     auto var = expr_to_str(p, args.(0));\n     alt (GenericOS.getenv(var)) {\n         case (Option.none[str]) {\n-            ret make_new_str(sp, \"\");\n+            ret make_new_str(p, sp, \"\");\n         }\n         case (Option.some[str](?s)) {\n-            ret make_new_str(sp, s);\n+            ret make_new_str(p, sp, s);\n         }\n     }\n }\n@@ -54,15 +54,15 @@ fn expr_to_str(parser.parser p,\n     fail;\n }\n \n-fn make_new_lit(common.span sp, ast.lit_ lit) -> @ast.expr {\n+fn make_new_lit(parser.parser p, common.span sp, ast.lit_ lit) -> @ast.expr {\n     auto sp_lit = @rec(node=lit, span=sp);\n-    auto expr = ast.expr_lit(sp_lit, ast.ann_none);\n+    auto expr = ast.expr_lit(sp_lit, p.get_ann());\n     ret @rec(node=expr, span=sp);\n }\n \n-fn make_new_str(common.span sp, str s) -> @ast.expr {\n+fn make_new_str(parser.parser p, common.span sp, str s) -> @ast.expr {\n     auto lit = ast.lit_str(s);\n-    ret make_new_lit(sp, lit);\n+    ret make_new_lit(p, sp, lit);\n }\n \n //"}, {"sha": "49c29a1378c4b6604b719d8ab6d87f7f97cfcd2b", "filename": "src/comp/front/extfmt.rs", "status": "modified", "additions": 74, "deletions": 65, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Ffront%2Fextfmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Ffront%2Fextfmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fextfmt.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -4,6 +4,7 @@\n  * compiler syntax extension plugin interface.\n  */\n \n+import front.parser.parser;\n import util.common;\n \n import std.Str;\n@@ -45,11 +46,12 @@ import std.ExtFmt.CT.parse_fmt_string;\n \n export expand_syntax_ext;\n \n-// FIXME: Need to thread parser through here to handle errors correctly\n-fn expand_syntax_ext(vec[@ast.expr] args,\n+fn expand_syntax_ext(parser p,\n+                     vec[@ast.expr] args,\n                      Option.t[str] body) -> @ast.expr {\n \n     if (Vec.len[@ast.expr](args) == 0u) {\n+        // FIXME: Handle error correctly.\n         log_err \"malformed #fmt call\";\n         fail;\n     }\n@@ -62,7 +64,7 @@ fn expand_syntax_ext(vec[@ast.expr] args,\n     auto pieces = parse_fmt_string(fmt);\n     auto args_len = Vec.len[@ast.expr](args);\n     auto fmt_args = Vec.slice[@ast.expr](args, 1u, args_len - 1u);\n-    ret pieces_to_expr(pieces, args);\n+    ret pieces_to_expr(p, pieces, args);\n }\n \n fn expr_to_str(@ast.expr expr) -> str {\n@@ -75,6 +77,7 @@ fn expr_to_str(@ast.expr expr) -> str {\n             }\n         }\n     }\n+    // FIXME: Handle error correctly.\n     log_err \"malformed #fmt call\";\n     fail;\n }\n@@ -83,59 +86,62 @@ fn expr_to_str(@ast.expr expr) -> str {\n // be factored out in common with other code that builds expressions.\n // FIXME: Probably should be using the parser's span functions\n // FIXME: Cleanup the naming of these functions\n-fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n+fn pieces_to_expr(parser p, vec[piece] pieces, vec[@ast.expr] args)\n+        -> @ast.expr {\n \n-    fn make_new_lit(common.span sp, ast.lit_ lit) -> @ast.expr {\n+    fn make_new_lit(parser p, common.span sp, ast.lit_ lit) -> @ast.expr {\n         auto sp_lit = @rec(node=lit, span=sp);\n-        auto expr = ast.expr_lit(sp_lit, ast.ann_none);\n+        auto expr = ast.expr_lit(sp_lit, p.get_ann());\n         ret @rec(node=expr, span=sp);\n     }\n \n-    fn make_new_str(common.span sp, str s) -> @ast.expr {\n+    fn make_new_str(parser p, common.span sp, str s) -> @ast.expr {\n         auto lit = ast.lit_str(s);\n-        ret make_new_lit(sp, lit);\n+        ret make_new_lit(p, sp, lit);\n     }\n \n-    fn make_new_int(common.span sp, int i) -> @ast.expr {\n+    fn make_new_int(parser p, common.span sp, int i) -> @ast.expr {\n         auto lit = ast.lit_int(i);\n-        ret make_new_lit(sp, lit);\n+        ret make_new_lit(p, sp, lit);\n     }\n \n-    fn make_new_uint(common.span sp, uint u) -> @ast.expr {\n+    fn make_new_uint(parser p, common.span sp, uint u) -> @ast.expr {\n         auto lit = ast.lit_uint(u);\n-        ret make_new_lit(sp, lit);\n+        ret make_new_lit(p, sp, lit);\n     }\n \n-    fn make_add_expr(common.span sp,\n+    fn make_add_expr(parser p, common.span sp,\n                      @ast.expr lhs, @ast.expr rhs) -> @ast.expr {\n-        auto binexpr = ast.expr_binary(ast.add, lhs, rhs, ast.ann_none);\n+        auto binexpr = ast.expr_binary(ast.add, lhs, rhs, p.get_ann());\n         ret @rec(node=binexpr, span=sp);\n     }\n \n-    fn make_path_expr(common.span sp, vec[ast.ident] idents) -> @ast.expr {\n+    fn make_path_expr(parser p, common.span sp, vec[ast.ident] idents)\n+            -> @ast.expr {\n         let vec[@ast.ty] types = vec();\n         auto path = rec(idents=idents, types=types);\n         auto sp_path = rec(node=path, span=sp);\n-        auto pathexpr = ast.expr_path(sp_path, none[ast.def], ast.ann_none);\n+        auto pathexpr = ast.expr_path(sp_path, none[ast.def], p.get_ann());\n         auto sp_pathexpr = @rec(node=pathexpr, span=sp);\n         ret sp_pathexpr;\n     }\n \n-    fn make_vec_expr(common.span sp, vec[@ast.expr] exprs) -> @ast.expr {\n-        auto vecexpr = ast.expr_vec(exprs, ast.imm, ast.ann_none);\n+    fn make_vec_expr(parser p, common.span sp, vec[@ast.expr] exprs)\n+            -> @ast.expr {\n+        auto vecexpr = ast.expr_vec(exprs, ast.imm, p.get_ann());\n         auto sp_vecexpr = @rec(node=vecexpr, span=sp);\n         ret sp_vecexpr;\n     }\n \n-    fn make_call(common.span sp, vec[ast.ident] fn_path,\n+    fn make_call(parser p, common.span sp, vec[ast.ident] fn_path,\n                  vec[@ast.expr] args) -> @ast.expr {\n-        auto pathexpr = make_path_expr(sp, fn_path);\n-        auto callexpr = ast.expr_call(pathexpr, args, ast.ann_none);\n+        auto pathexpr = make_path_expr(p, sp, fn_path);\n+        auto callexpr = ast.expr_call(pathexpr, args, p.get_ann());\n         auto sp_callexpr = @rec(node=callexpr, span=sp);\n         ret sp_callexpr;\n     }\n \n-    fn make_rec_expr(common.span sp,\n+    fn make_rec_expr(parser p, common.span sp,\n                      vec[tup(ast.ident, @ast.expr)] fields) -> @ast.expr {\n         let vec[ast.field] astfields = vec();\n         for (tup(ast.ident, @ast.expr) field in fields) {\n@@ -149,7 +155,7 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n \n         auto recexpr = ast.expr_rec(astfields,\n                                     Option.none[@ast.expr],\n-                                    ast.ann_none);\n+                                    p.get_ann());\n         auto sp_recexpr = @rec(node=recexpr, span=sp);\n         ret sp_recexpr;\n     }\n@@ -160,16 +166,17 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n         ret vec(\"std\", \"ExtFmt\", \"RT\", ident);\n     }\n \n-    fn make_rt_path_expr(common.span sp, str ident) -> @ast.expr {\n+    fn make_rt_path_expr(parser p, common.span sp, str ident) -> @ast.expr {\n         auto path = make_path_vec(ident);\n-        ret make_path_expr(sp, path);\n+        ret make_path_expr(p, sp, path);\n     }\n \n     // Produces an AST expression that represents a RT.conv record,\n     // which tells the RT.conv* functions how to perform the conversion\n-    fn make_rt_conv_expr(common.span sp, &conv cnv) -> @ast.expr {\n+    fn make_rt_conv_expr(parser p, common.span sp, &conv cnv) -> @ast.expr {\n \n-        fn make_flags(common.span sp, vec[flag] flags) -> @ast.expr {\n+        fn make_flags(parser p, common.span sp, vec[flag] flags)\n+                -> @ast.expr {\n             let vec[@ast.expr] flagexprs = vec();\n             for (flag f in flags) {\n                 auto fstr;\n@@ -190,29 +197,29 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n                         fstr = \"flag_alternate\";\n                     }\n                 }\n-                flagexprs += vec(make_rt_path_expr(sp, fstr));\n+                flagexprs += vec(make_rt_path_expr(p, sp, fstr));\n             }\n \n             // FIXME: 0-length vectors can't have their type inferred\n             // through the rec that these flags are a member of, so\n             // this is a hack placeholder flag\n             if (Vec.len[@ast.expr](flagexprs) == 0u) {\n-                flagexprs += vec(make_rt_path_expr(sp, \"flag_none\"));\n+                flagexprs += vec(make_rt_path_expr(p, sp, \"flag_none\"));\n             }\n \n-            ret make_vec_expr(sp, flagexprs);\n+            ret make_vec_expr(p, sp, flagexprs);\n         }\n \n-        fn make_count(common.span sp, &count cnt) -> @ast.expr {\n+        fn make_count(parser p, common.span sp, &count cnt) -> @ast.expr {\n             alt (cnt) {\n                 case (count_implied) {\n-                    ret make_rt_path_expr(sp, \"count_implied\");\n+                    ret make_rt_path_expr(p, sp, \"count_implied\");\n                 }\n                 case (count_is(?c)) {\n-                    auto count_lit = make_new_int(sp, c);\n+                    auto count_lit = make_new_int(p, sp, c);\n                     auto count_is_path = make_path_vec(\"count_is\");\n                     auto count_is_args = vec(count_lit);\n-                    ret make_call(sp, count_is_path, count_is_args);\n+                    ret make_call(p, sp, count_is_path, count_is_args);\n                 }\n                 case (_) {\n                     log_err \"not implemented\";\n@@ -221,7 +228,7 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n             }\n         }\n \n-        fn make_ty(common.span sp, &ty t) -> @ast.expr {\n+        fn make_ty(parser p, common.span sp, &ty t) -> @ast.expr {\n             auto rt_type;\n             alt (t) {\n                 case (ty_hex(?c)) {\n@@ -245,41 +252,43 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n                 }\n             }\n \n-            ret make_rt_path_expr(sp, rt_type);\n+            ret make_rt_path_expr(p, sp, rt_type);\n         }\n \n-        fn make_conv_rec(common.span sp,\n+        fn make_conv_rec(parser p,\n+                         common.span sp,\n                          @ast.expr flags_expr,\n                          @ast.expr width_expr,\n                          @ast.expr precision_expr,\n                          @ast.expr ty_expr) -> @ast.expr {\n-            ret make_rec_expr(sp, vec(tup(\"flags\", flags_expr),\n-                                      tup(\"width\", width_expr),\n-                                      tup(\"precision\", precision_expr),\n-                                      tup(\"ty\", ty_expr)));\n+            ret make_rec_expr(p, sp, vec(tup(\"flags\", flags_expr),\n+                                         tup(\"width\", width_expr),\n+                                         tup(\"precision\", precision_expr),\n+                                         tup(\"ty\", ty_expr)));\n         }\n \n-        auto rt_conv_flags = make_flags(sp, cnv.flags);\n-        auto rt_conv_width = make_count(sp, cnv.width);\n-        auto rt_conv_precision = make_count(sp, cnv.precision);\n-        auto rt_conv_ty = make_ty(sp, cnv.ty);\n-        ret make_conv_rec(sp,\n+        auto rt_conv_flags = make_flags(p, sp, cnv.flags);\n+        auto rt_conv_width = make_count(p, sp, cnv.width);\n+        auto rt_conv_precision = make_count(p, sp, cnv.precision);\n+        auto rt_conv_ty = make_ty(p, sp, cnv.ty);\n+        ret make_conv_rec(p,\n+                          sp,\n                           rt_conv_flags,\n                           rt_conv_width,\n                           rt_conv_precision,\n                           rt_conv_ty);\n     }\n \n-    fn make_conv_call(common.span sp, str conv_type,\n+    fn make_conv_call(parser p, common.span sp, str conv_type,\n                       &conv cnv, @ast.expr arg) -> @ast.expr {\n         auto fname = \"conv_\" + conv_type;\n         auto path = make_path_vec(fname);\n-        auto cnv_expr = make_rt_conv_expr(sp, cnv);\n+        auto cnv_expr = make_rt_conv_expr(p, sp, cnv);\n         auto args = vec(cnv_expr, arg);\n-        ret make_call(arg.span, path, args);\n+        ret make_call(p, arg.span, path, args);\n     }\n \n-    fn make_new_conv(conv cnv, @ast.expr arg) -> @ast.expr {\n+    fn make_new_conv(parser p, conv cnv, @ast.expr arg) -> @ast.expr {\n \n         // FIXME: Extract all this validation into ExtFmt.CT\n         fn is_signed_type(conv cnv) -> bool {\n@@ -361,32 +370,32 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n \n         alt (cnv.ty) {\n             case (ty_str) {\n-                ret make_conv_call(arg.span, \"str\", cnv, arg);\n+                ret make_conv_call(p, arg.span, \"str\", cnv, arg);\n             }\n             case (ty_int(?sign)) {\n                 alt (sign) {\n                     case (signed) {\n-                        ret make_conv_call(arg.span, \"int\", cnv, arg);\n+                        ret make_conv_call(p, arg.span, \"int\", cnv, arg);\n                     }\n                     case (unsigned) {\n-                        ret make_conv_call(arg.span, \"uint\", cnv, arg);\n+                        ret make_conv_call(p, arg.span, \"uint\", cnv, arg);\n                     }\n                 }\n             }\n             case (ty_bool) {\n-                ret make_conv_call(arg.span, \"bool\", cnv, arg);\n+                ret make_conv_call(p, arg.span, \"bool\", cnv, arg);\n             }\n             case (ty_char) {\n-                ret make_conv_call(arg.span, \"char\", cnv, arg);\n+                ret make_conv_call(p, arg.span, \"char\", cnv, arg);\n             }\n             case (ty_hex(_)) {\n-                ret make_conv_call(arg.span, \"uint\", cnv, arg);\n+                ret make_conv_call(p, arg.span, \"uint\", cnv, arg);\n             }\n             case (ty_bits) {\n-                ret make_conv_call(arg.span, \"uint\", cnv, arg);\n+                ret make_conv_call(p, arg.span, \"uint\", cnv, arg);\n             }\n             case (ty_octal) {\n-                ret make_conv_call(arg.span, \"uint\", cnv, arg);\n+                ret make_conv_call(p, arg.span, \"uint\", cnv, arg);\n             }\n             case (_) {\n                 log_err unsupported;\n@@ -489,13 +498,13 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n \n     auto sp = args.(0).span;\n     auto n = 0u;\n-    auto tmp_expr = make_new_str(sp, \"\");\n+    auto tmp_expr = make_new_str(p, sp, \"\");\n \n-    for (piece p in pieces) {\n-        alt (p) {\n+    for (piece pc in pieces) {\n+        alt (pc) {\n             case (piece_string(?s)) {\n-                auto s_expr = make_new_str(sp, s);\n-                tmp_expr = make_add_expr(sp, tmp_expr, s_expr);\n+                auto s_expr = make_new_str(p, sp, s);\n+                tmp_expr = make_add_expr(p, sp, tmp_expr, s_expr);\n             }\n             case (piece_conv(?conv)) {\n                 if (n >= Vec.len[@ast.expr](args)) {\n@@ -509,8 +518,8 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n \n                 n += 1u;\n                 auto arg_expr = args.(n);\n-                auto c_expr = make_new_conv(conv, arg_expr);\n-                tmp_expr = make_add_expr(sp, tmp_expr, c_expr);\n+                auto c_expr = make_new_conv(p, conv, arg_expr);\n+                tmp_expr = make_add_expr(p, sp, tmp_expr, c_expr);\n             }\n         }\n     }"}, {"sha": "733d50503be0c1890b2b3319a94a36f0faff837b", "filename": "src/comp/front/parser.rs", "status": "modified", "additions": 85, "deletions": 76, "changes": 161, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Ffront%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Ffront%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fparser.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -42,6 +42,7 @@ state type parser =\n           fn get_reader() -> lexer.reader;\n           fn get_filemap() -> codemap.filemap;\n           fn get_chpos() -> uint;\n+          fn get_ann() -> ast.ann;\n     };\n \n fn new_parser(session.session sess,\n@@ -58,7 +59,8 @@ fn new_parser(session.session sess,\n                            mutable restriction res,\n                            ast.crate_num crate,\n                            lexer.reader rdr,\n-                           vec[op_spec] precs)\n+                           vec[op_spec] precs,\n+                           mutable uint next_ann_var)\n         {\n             fn peek() -> token.token {\n                 ret tok;\n@@ -126,6 +128,12 @@ fn new_parser(session.session sess,\n             }\n \n             fn get_chpos() -> uint {ret rdr.get_chpos();}\n+\n+            fn get_ann() -> ast.ann {\n+                auto rv = ast.ann_none(next_ann_var);\n+                next_ann_var += 1u;\n+                ret rv;\n+            }\n         }\n     auto ftype = SOURCE_FILE;\n     if (Str.ends_with(path, \".rc\")) {\n@@ -140,7 +148,7 @@ fn new_parser(session.session sess,\n     auto npos = rdr.get_chpos();\n     ret stdio_parser(sess, env, ftype, lexer.next_token(rdr),\n                      npos, npos, initial_def._1, UNRESTRICTED, initial_def._0,\n-                     rdr, prec_table());\n+                     rdr, prec_table(), 0u);\n }\n \n fn unexpected(parser p, token.token t) {\n@@ -678,14 +686,14 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n     // FIXME: can only remove this sort of thing when both typestate and\n     // alt-exhaustive-match checking are co-operating.\n     auto lit = @spanned(lo, hi, ast.lit_nil);\n-    let ast.expr_ ex = ast.expr_lit(lit, ast.ann_none);\n+    let ast.expr_ ex = ast.expr_lit(lit, p.get_ann());\n \n     alt (p.peek()) {\n \n         case (token.IDENT(_)) {\n             auto pth = parse_path(p, MINIMAL);\n             hi = pth.span.hi;\n-            ex = ast.expr_path(pth, none[ast.def], ast.ann_none);\n+            ex = ast.expr_path(pth, none[ast.def], p.get_ann());\n         }\n \n         case (token.LPAREN) {\n@@ -696,7 +704,7 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n                     p.bump();\n                     auto lit = @spanned(lo, hi, ast.lit_nil);\n                     ret @spanned(lo, hi,\n-                                 ast.expr_lit(lit, ast.ann_none));\n+                                 ast.expr_lit(lit, p.get_ann()));\n                 }\n                 case (_) { /* fall through */ }\n             }\n@@ -720,7 +728,7 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n                                    some(token.COMMA),\n                                    pf, p);\n             hi = es.span.hi;\n-            ex = ast.expr_tup(es.node, ast.ann_none);\n+            ex = ast.expr_tup(es.node, p.get_ann());\n         }\n \n         case (token.VEC) {\n@@ -733,7 +741,7 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n             auto es = parse_seq_to_end[@ast.expr](token.RPAREN,\n                                                   some(token.COMMA),\n                                                   pf, hi, p);\n-            ex = ast.expr_vec(es, mut, ast.ann_none);\n+            ex = ast.expr_vec(es, mut, p.get_ann());\n         }\n \n         case (token.REC) {\n@@ -768,7 +776,7 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n \n             }\n \n-            ex = ast.expr_rec(fields, base, ast.ann_none);\n+            ex = ast.expr_rec(fields, base, p.get_ann());\n         }\n \n         case (token.BIND) {\n@@ -792,7 +800,7 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n                                                      some(token.COMMA),\n                                                      pf, p);\n             hi = es.span.hi;\n-            ex = ast.expr_bind(e, es.node, ast.ann_none);\n+            ex = ast.expr_bind(e, es.node, p.get_ann());\n         }\n \n         case (token.POUND) {\n@@ -810,28 +818,28 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n \n         case (token.FAIL) {\n             p.bump();\n-            ex = ast.expr_fail(ast.ann_none);\n+            ex = ast.expr_fail(p.get_ann());\n         }\n \n         case (token.LOG) {\n             p.bump();\n             auto e = parse_expr(p);\n             auto hi = e.span.hi;\n-            ex = ast.expr_log(1, e, ast.ann_none);\n+            ex = ast.expr_log(1, e, p.get_ann());\n         }\n \n         case (token.LOG_ERR) {\n             p.bump();\n             auto e = parse_expr(p);\n             auto hi = e.span.hi;\n-            ex = ast.expr_log(0, e, ast.ann_none);\n+            ex = ast.expr_log(0, e, p.get_ann());\n         }\n \n         case (token.ASSERT) {\n             p.bump();\n             auto e = parse_expr(p);\n             auto hi = e.span.hi;\n-            ex = ast.expr_assert(e, ast.ann_none);\n+            ex = ast.expr_assert(e, p.get_ann());\n         }\n \n         case (token.CHECK) {\n@@ -841,43 +849,43 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n             but the typechecker enforces that. */\n             auto e = parse_expr(p);\n             auto hi = e.span.hi;\n-            ex = ast.expr_check(e, ast.ann_none);\n+            ex = ast.expr_check(e, p.get_ann());\n         } \n \n         case (token.RET) {\n             p.bump();\n             alt (p.peek()) {\n                 case (token.SEMI) {\n-                    ex = ast.expr_ret(none[@ast.expr], ast.ann_none);\n+                    ex = ast.expr_ret(none[@ast.expr], p.get_ann());\n                 }\n                 case (_) {\n                     auto e = parse_expr(p);\n                     hi = e.span.hi;\n-                    ex = ast.expr_ret(some[@ast.expr](e), ast.ann_none);\n+                    ex = ast.expr_ret(some[@ast.expr](e), p.get_ann());\n                 }\n             }\n         }\n \n         case (token.BREAK) {\n             p.bump();\n-            ex = ast.expr_break(ast.ann_none);\n+            ex = ast.expr_break(p.get_ann());\n         }\n \n         case (token.CONT) {\n             p.bump();\n-            ex = ast.expr_cont(ast.ann_none);\n+            ex = ast.expr_cont(p.get_ann());\n         }\n \n         case (token.PUT) {\n             p.bump();\n             alt (p.peek()) {\n                 case (token.SEMI) {\n-                    ex = ast.expr_put(none[@ast.expr], ast.ann_none);\n+                    ex = ast.expr_put(none[@ast.expr], p.get_ann());\n                 }\n                 case (_) {\n                     auto e = parse_expr(p);\n                     hi = e.span.hi;\n-                    ex = ast.expr_put(some[@ast.expr](e), ast.ann_none);\n+                    ex = ast.expr_put(some[@ast.expr](e), p.get_ann());\n                 }\n             }\n         }\n@@ -888,7 +896,7 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n             // FIXME: Is this the right place for this check?\n             if /*check*/ (ast.is_call_expr(e)) {\n                     hi = e.span.hi;\n-                    ex = ast.expr_be(e, ast.ann_none);\n+                    ex = ast.expr_be(e, p.get_ann());\n             }\n             else {\n                 p.err(\"Non-call expression in tail call\");\n@@ -900,7 +908,7 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n             expect(p, token.LPAREN);\n             expect(p, token.RPAREN);\n             hi = p.get_hi_pos();\n-            ex = ast.expr_port(ast.ann_none);\n+            ex = ast.expr_port(p.get_ann());\n         }\n \n         case (token.CHAN) {\n@@ -909,7 +917,7 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n             auto e = parse_expr(p);\n             hi = e.span.hi;\n             expect(p, token.RPAREN);\n-            ex = ast.expr_chan(e, ast.ann_none);\n+            ex = ast.expr_chan(e, p.get_ann());\n         }\n \n         case (token.SELF) {\n@@ -925,13 +933,13 @@ fn parse_bottom_expr(parser p) -> @ast.expr {\n                                            some(token.COMMA),\n                                            pf, p);\n             hi = es.span.hi;\n-            ex = ast.expr_call(f, es.node, ast.ann_none);\n+            ex = ast.expr_call(f, es.node, p.get_ann());\n         }\n \n         case (_) {\n             auto lit = parse_lit(p);\n             hi = lit.span.hi;\n-            ex = ast.expr_lit(@lit, ast.ann_none);\n+            ex = ast.expr_lit(@lit, p.get_ann());\n         }\n     }\n \n@@ -954,17 +962,17 @@ fn expand_syntax_ext(parser p, ast.span sp,\n     assert (Vec.len[ast.ident](path.node.idents) > 0u);\n     auto extname = path.node.idents.(0);\n     if (Str.eq(extname, \"fmt\")) {\n-        auto expanded = extfmt.expand_syntax_ext(args, body);\n+        auto expanded = extfmt.expand_syntax_ext(p, args, body);\n         auto newexpr = ast.expr_ext(path, args, body,\n                                     expanded,\n-                                    ast.ann_none);\n+                                    p.get_ann());\n \n         ret newexpr;\n     } else if (Str.eq(extname, \"env\")) {\n         auto expanded = extenv.expand_syntax_ext(p, sp, args, body);\n         auto newexpr = ast.expr_ext(path, args, body,\n                                     expanded,\n-                                    ast.ann_none);\n+                                    p.get_ann());\n \n         ret newexpr;\n     } else {\n@@ -992,7 +1000,7 @@ fn extend_expr_by_ident(parser p, uint lo, uint hi,\n             }\n         }\n         case (_) {\n-            e_ = ast.expr_field(e, i, ast.ann_none);\n+            e_ = ast.expr_field(e, i, p.get_ann());\n         }\n     }\n     ret @spanned(lo, hi, e_);\n@@ -1002,7 +1010,7 @@ fn parse_self_method(parser p) -> @ast.expr {\n     auto sp = p.get_span();\n     let ast.ident f_name = parse_ident(p);\n     auto hi = p.get_span();\n-    ret @rec(node=ast.expr_self_method(f_name, ast.ann_none), span=sp);\n+    ret @rec(node=ast.expr_self_method(f_name, p.get_ann()), span=sp);\n }\n \n fn parse_dot_or_call_expr(parser p) -> @ast.expr {\n@@ -1023,7 +1031,7 @@ fn parse_dot_or_call_expr(parser p) -> @ast.expr {\n                                                    some(token.COMMA),\n                                                    pf, p);\n                     hi = es.span.hi;\n-                    auto e_ = ast.expr_call(e, es.node, ast.ann_none);\n+                    auto e_ = ast.expr_call(e, es.node, p.get_ann());\n                     e = @spanned(lo, hi, e_);\n                 }\n             }\n@@ -1043,7 +1051,7 @@ fn parse_dot_or_call_expr(parser p) -> @ast.expr {\n                         auto ix = parse_expr(p);\n                         hi = ix.span.hi;\n                         expect(p, token.RPAREN);\n-                        auto e_ = ast.expr_index(e, ix, ast.ann_none);\n+                        auto e_ = ast.expr_index(e, ix, p.get_ann());\n                         e = @spanned(lo, hi, e_);\n                     }\n \n@@ -1074,22 +1082,22 @@ fn parse_prefix_expr(parser p) -> @ast.expr {\n     // FIXME: can only remove this sort of thing when both typestate and\n     // alt-exhaustive-match checking are co-operating.\n     auto lit = @spanned(lo, lo, ast.lit_nil);\n-    let ast.expr_ ex = ast.expr_lit(lit, ast.ann_none);\n+    let ast.expr_ ex = ast.expr_lit(lit, p.get_ann());\n \n     alt (p.peek()) {\n \n         case (token.NOT) {\n             p.bump();\n             auto e = parse_prefix_expr(p);\n             hi = e.span.hi;\n-            ex = ast.expr_unary(ast.not, e, ast.ann_none);\n+            ex = ast.expr_unary(ast.not, e, p.get_ann());\n         }\n \n         case (token.TILDE) {\n             p.bump();\n             auto e = parse_prefix_expr(p);\n             hi = e.span.hi;\n-            ex = ast.expr_unary(ast.bitnot, e, ast.ann_none);\n+            ex = ast.expr_unary(ast.bitnot, e, p.get_ann());\n         }\n \n         case (token.BINOP(?b)) {\n@@ -1098,14 +1106,14 @@ fn parse_prefix_expr(parser p) -> @ast.expr {\n                     p.bump();\n                     auto e = parse_prefix_expr(p);\n                     hi = e.span.hi;\n-                    ex = ast.expr_unary(ast.neg, e, ast.ann_none);\n+                    ex = ast.expr_unary(ast.neg, e, p.get_ann());\n                 }\n \n                 case (token.STAR) {\n                     p.bump();\n                     auto e = parse_prefix_expr(p);\n                     hi = e.span.hi;\n-                    ex = ast.expr_unary(ast.deref, e, ast.ann_none);\n+                    ex = ast.expr_unary(ast.deref, e, p.get_ann());\n                 }\n \n                 case (_) {\n@@ -1119,7 +1127,7 @@ fn parse_prefix_expr(parser p) -> @ast.expr {\n             auto m = parse_mutability(p);\n             auto e = parse_prefix_expr(p);\n             hi = e.span.hi;\n-            ex = ast.expr_unary(ast.box(m), e, ast.ann_none);\n+            ex = ast.expr_unary(ast.box(m), e, p.get_ann());\n         }\n \n         case (_) {\n@@ -1175,15 +1183,15 @@ fn parse_more_binops(parser p, @ast.expr lhs, int min_prec)\n             alt (cur.tok) {\n                 case (token.AS) {\n                     auto rhs = parse_ty(p);\n-                    auto _as = ast.expr_cast(lhs, rhs, ast.ann_none);\n+                    auto _as = ast.expr_cast(lhs, rhs, p.get_ann());\n                     auto span = @spanned(lhs.span.lo, rhs.span.hi, _as);\n                     ret parse_more_binops(p, span, min_prec);\n                 }\n                 case (_) {\n                     auto rhs = parse_more_binops(p, parse_prefix_expr(p),\n                                                  cur.prec);\n                     auto bin = ast.expr_binary(cur.op, lhs, rhs,\n-                                               ast.ann_none);\n+                                               p.get_ann());\n                     auto span = @spanned(lhs.span.lo, rhs.span.hi, bin);\n                     ret parse_more_binops(p, span, min_prec);\n                 }\n@@ -1201,7 +1209,7 @@ fn parse_assign_expr(parser p) -> @ast.expr {\n             p.bump();\n             auto rhs = parse_expr(p);\n             ret @spanned(lo, rhs.span.hi,\n-                         ast.expr_assign(lhs, rhs, ast.ann_none));\n+                         ast.expr_assign(lhs, rhs, p.get_ann()));\n         }\n         case (token.BINOPEQ(?op)) {\n             p.bump();\n@@ -1221,19 +1229,19 @@ fn parse_assign_expr(parser p) -> @ast.expr {\n                 case (token.ASR) { aop = ast.asr; }\n             }\n             ret @spanned(lo, rhs.span.hi,\n-                         ast.expr_assign_op(aop, lhs, rhs, ast.ann_none));\n+                         ast.expr_assign_op(aop, lhs, rhs, p.get_ann()));\n         }\n         case (token.SEND) {\n             p.bump();\n             auto rhs = parse_expr(p);\n             ret @spanned(lo, rhs.span.hi,\n-                         ast.expr_send(lhs, rhs, ast.ann_none));\n+                         ast.expr_send(lhs, rhs, p.get_ann()));\n         }\n         case (token.LARROW) {\n             p.bump();\n             auto rhs = parse_expr(p);\n             ret @spanned(lo, rhs.span.hi,\n-                         ast.expr_recv(lhs, rhs, ast.ann_none));\n+                         ast.expr_recv(lhs, rhs, p.get_ann()));\n         }\n         case (_) { /* fall through */ }\n     }\n@@ -1259,7 +1267,7 @@ fn parse_if_expr(parser p) -> @ast.expr {\n         case (_) { /* fall through */ }\n     }\n \n-    ret @spanned(lo, hi, ast.expr_if(cond, thn, els, ast.ann_none));\n+    ret @spanned(lo, hi, ast.expr_if(cond, thn, els, p.get_ann()));\n }\n \n fn parse_else_expr(parser p) -> @ast.expr {\n@@ -1271,7 +1279,7 @@ fn parse_else_expr(parser p) -> @ast.expr {\n         case (_) {\n             auto blk = parse_block(p);\n             ret @spanned(blk.span.lo, blk.span.hi,\n-                         ast.expr_block(blk, ast.ann_none));\n+                         ast.expr_block(blk, p.get_ann()));\n         }\n     }\n }\n@@ -1310,10 +1318,10 @@ fn parse_for_expr(parser p) -> @ast.expr {\n     auto hi = body.span.hi;\n     if (is_each) {\n         ret @spanned(lo, hi, ast.expr_for_each(decl, seq, body,\n-                                                ast.ann_none));\n+                                                p.get_ann()));\n     } else {\n         ret @spanned(lo, hi, ast.expr_for(decl, seq, body,\n-                                          ast.ann_none));\n+                                          p.get_ann()));\n     }\n }\n \n@@ -1327,7 +1335,7 @@ fn parse_while_expr(parser p) -> @ast.expr {\n     expect(p, token.RPAREN);\n     auto body = parse_block(p);\n     auto hi = body.span.hi;\n-    ret @spanned(lo, hi, ast.expr_while(cond, body, ast.ann_none));\n+    ret @spanned(lo, hi, ast.expr_while(cond, body, p.get_ann()));\n }\n \n fn parse_do_while_expr(parser p) -> @ast.expr {\n@@ -1340,7 +1348,7 @@ fn parse_do_while_expr(parser p) -> @ast.expr {\n     auto cond = parse_expr(p);\n     expect(p, token.RPAREN);\n     auto hi = cond.span.hi;\n-    ret @spanned(lo, hi, ast.expr_do_while(body, cond, ast.ann_none));\n+    ret @spanned(lo, hi, ast.expr_do_while(body, cond, p.get_ann()));\n }\n \n fn parse_alt_expr(parser p) -> @ast.expr {\n@@ -1375,7 +1383,7 @@ fn parse_alt_expr(parser p) -> @ast.expr {\n             case (token.ELSE) {\n                 p.bump();\n                 auto hi = p.get_hi_pos();\n-                auto pat = @spanned(lo, hi, ast.pat_wild(ast.ann_none));\n+                auto pat = @spanned(lo, hi, ast.pat_wild(p.get_ann()));\n                 auto index = index_arm(pat);\n                 auto block = parse_block(p);\n                 arms += vec(rec(pat=pat, block=block, index=index));\n@@ -1390,7 +1398,7 @@ fn parse_alt_expr(parser p) -> @ast.expr {\n     auto hi = p.get_hi_pos();\n     p.bump();\n \n-    auto expr = ast.expr_alt(discriminant, arms, ast.ann_none);\n+    auto expr = ast.expr_alt(discriminant, arms, p.get_ann());\n     ret @spanned(lo, hi, expr);\n }\n \n@@ -1411,7 +1419,7 @@ fn parse_spawn_expr(parser p) -> @ast.expr {\n                                      Option.none[str],\n                                      fn_expr,\n                                      es.node,\n-                                     ast.ann_none);\n+                                     p.get_ann());\n     ret @spanned(lo, hi, spawn_expr);\n }\n \n@@ -1432,7 +1440,7 @@ fn parse_expr_inner(parser p) -> @ast.expr {\n         case (token.LBRACE) {\n             auto blk = parse_block(p);\n             ret @spanned(blk.span.lo, blk.span.hi,\n-                         ast.expr_block(blk, ast.ann_none));\n+                         ast.expr_block(blk, p.get_ann()));\n         }\n         case (token.IF) {\n             ret parse_if_expr(p);\n@@ -1485,7 +1493,7 @@ fn parse_pat(parser p) -> @ast.pat {\n     alt (p.peek()) {\n         case (token.UNDERSCORE) {\n             p.bump();\n-            pat = ast.pat_wild(ast.ann_none);\n+            pat = ast.pat_wild(p.get_ann());\n         }\n         case (token.QUES) {\n             p.bump();\n@@ -1494,7 +1502,7 @@ fn parse_pat(parser p) -> @ast.pat {\n                     hi = p.get_hi_pos();\n                     p.bump();\n                     pat = ast.pat_bind(p.get_str(id), p.next_def_id(),\n-                                       ast.ann_none);\n+                                       p.get_ann());\n                 }\n                 case (?tok) {\n                     p.err(\"expected identifier after '?' in pattern but \" +\n@@ -1520,12 +1528,12 @@ fn parse_pat(parser p) -> @ast.pat {\n             }\n \n             pat = ast.pat_tag(tag_path, args, none[ast.variant_def],\n-                              ast.ann_none);\n+                              p.get_ann());\n         }\n         case (_) {\n             auto lit = parse_lit(p);\n             hi = lit.span.hi;\n-            pat = ast.pat_lit(@lit, ast.ann_none);\n+            pat = ast.pat_lit(@lit, p.get_ann());\n         }\n     }\n \n@@ -1541,7 +1549,7 @@ fn parse_local_full(&Option.t[@ast.ty] tyopt,\n              ident = ident,\n              init = init,\n              id = p.next_def_id(),\n-             ann = ast.ann_none);\n+             ann = p.get_ann());\n }\n \n fn parse_typed_local(parser p) -> @ast.local {\n@@ -1589,13 +1597,13 @@ fn parse_source_stmt(parser p) -> @ast.stmt {\n             auto decl = parse_let(p);\n             auto hi = p.get_span();\n             ret @spanned\n-                (lo, decl.span.hi, ast.stmt_decl(decl, ast.ann_none));\n+                (lo, decl.span.hi, ast.stmt_decl(decl, p.get_ann()));\n         }\n \n         case (token.AUTO) {\n             auto decl = parse_auto(p);\n             auto hi = p.get_span();\n-            ret @spanned(lo, decl.span.hi, ast.stmt_decl(decl, ast.ann_none));\n+            ret @spanned(lo, decl.span.hi, ast.stmt_decl(decl, p.get_ann()));\n         }\n \n         case (_) {\n@@ -1604,26 +1612,27 @@ fn parse_source_stmt(parser p) -> @ast.stmt {\n                 auto i = parse_item(p);\n                 auto hi = i.span.hi;\n                 auto decl = @spanned(lo, hi, ast.decl_item(i));\n-                ret @spanned(lo, hi, ast.stmt_decl(decl, ast.ann_none));\n+                ret @spanned(lo, hi, ast.stmt_decl(decl, p.get_ann()));\n \n             } else {\n                 // Remainder are line-expr stmts.\n                 auto e = parse_expr(p);\n                 auto hi = p.get_span();\n-                ret @spanned(lo, e.span.hi, ast.stmt_expr(e, ast.ann_none));\n+                ret @spanned(lo, e.span.hi, ast.stmt_expr(e, p.get_ann()));\n             }\n         }\n     }\n     p.err(\"expected statement\");\n     fail;\n }\n \n-fn index_block(vec[@ast.stmt] stmts, Option.t[@ast.expr] expr) -> ast.block_ {\n+fn index_block(parser p, vec[@ast.stmt] stmts, Option.t[@ast.expr] expr)\n+        -> ast.block_ {\n     auto index = new_str_hash[ast.block_index_entry]();\n     for (@ast.stmt s in stmts) {\n         ast.index_stmt(index, s);\n     }\n-    ret rec(stmts=stmts, expr=expr, index=index, a=ast.ann_none);\n+    ret rec(stmts=stmts, expr=expr, index=index, a=p.get_ann());\n }\n \n fn index_arm(@ast.pat pat) -> hashmap[ast.ident,ast.def_id] {\n@@ -1761,7 +1770,7 @@ fn parse_block(parser p) -> ast.block {\n     auto hi = p.get_hi_pos();\n     p.bump();\n \n-    auto bloc = index_block(stmts, expr);\n+    auto bloc = index_block(p, stmts, expr);\n     ret spanned[ast.block_](lo, hi, bloc);\n }\n \n@@ -1827,7 +1836,7 @@ fn parse_item_fn_or_iter(parser p, ast.purity purity) -> @ast.item {\n     auto t = parse_fn_header(p);\n     auto f = parse_fn(p, proto, purity);\n     auto item = ast.item_fn(t._0, f, t._1,\n-                            p.next_def_id(), ast.ann_none);\n+                            p.next_def_id(), p.get_ann());\n     ret @spanned(lo, f.body.span.hi, item);\n }\n \n@@ -1836,7 +1845,7 @@ fn parse_obj_field(parser p) -> ast.obj_field {\n     auto mut = parse_mutability(p); // TODO: store this, use it in typeck\n     auto ty = parse_ty(p);\n     auto ident = parse_ident(p);\n-    ret rec(ty=ty, ident=ident, id=p.next_def_id(), ann=ast.ann_none);\n+    ret rec(ty=ty, ident=ident, id=p.next_def_id(), ann=p.get_ann());\n }\n \n fn parse_method(parser p) -> @ast.method {\n@@ -1845,7 +1854,7 @@ fn parse_method(parser p) -> @ast.method {\n     auto ident = parse_ident(p);\n     auto f = parse_fn(p, proto, ast.impure_fn);\n     auto meth = rec(ident=ident, meth=f,\n-                    id=p.next_def_id(), ann=ast.ann_none);\n+                    id=p.next_def_id(), ann=p.get_ann());\n     ret @spanned(lo, f.body.span.hi, meth);\n }\n \n@@ -1864,7 +1873,7 @@ fn parse_dtor(parser p) -> @ast.method {\n     let ast.method_ m = rec(ident=\"drop\",\n                             meth=f,\n                             id=p.next_def_id(),\n-                            ann=ast.ann_none);\n+                            ann=p.get_ann());\n     ret @spanned(lo, f.body.span.hi, m);\n }\n \n@@ -1904,7 +1913,7 @@ fn parse_item_obj(parser p, ast.layer lyr) -> @ast.item {\n                           dtor=dtor);\n \n     auto odid = rec(ty=p.next_def_id(), ctor=p.next_def_id());\n-    auto item = ast.item_obj(ident, ob, ty_params, odid, ast.ann_none);\n+    auto item = ast.item_obj(ident, ob, ty_params, odid, p.get_ann());\n \n     ret @spanned(lo, hi, item);\n }\n@@ -1932,7 +1941,7 @@ fn parse_item_const(parser p) -> @ast.item {\n     auto e = parse_expr(p);\n     auto hi = p.get_hi_pos();\n     expect(p, token.SEMI);\n-    auto item = ast.item_const(id, ty, e, p.next_def_id(), ast.ann_none);\n+    auto item = ast.item_const(id, ty, e, p.next_def_id(), p.get_ann());\n     ret @spanned(lo, hi, item);\n }\n \n@@ -1970,7 +1979,7 @@ fn parse_item_native_fn(parser p) -> @ast.native_item {\n     expect(p, token.SEMI);\n     auto item = ast.native_item_fn(t._0, link_name, decl,\n                                    t._1, p.next_def_id(),\n-                                   ast.ann_none);\n+                                   p.get_ann());\n     ret @spanned(lo, hi, item);\n }\n \n@@ -2075,7 +2084,7 @@ fn parse_item_type(parser p) -> @ast.item {\n     auto ty = parse_ty(p);\n     auto hi = p.get_hi_pos();\n     expect(p, token.SEMI);\n-    auto item = ast.item_ty(t._1, ty, tps, p.next_def_id(), ast.ann_none);\n+    auto item = ast.item_ty(t._1, ty, tps, p.next_def_id(), p.get_ann());\n     ret @spanned(t._0, hi, item);\n }\n \n@@ -2114,7 +2123,7 @@ fn parse_item_tag(parser p) -> @ast.item {\n \n                 auto id = p.next_def_id();\n                 auto vr = rec(name=p.get_str(name), args=args,\n-                              id=id, ann=ast.ann_none);\n+                              id=id, ann=p.get_ann());\n                 variants += vec(spanned[ast.variant_](vlo, vhi, vr));\n             }\n             case (token.RBRACE) { /* empty */ }\n@@ -2128,7 +2137,7 @@ fn parse_item_tag(parser p) -> @ast.item {\n     p.bump();\n \n     auto item = ast.item_tag(id, variants, ty_params, p.next_def_id(),\n-                             ast.ann_none);\n+                             p.get_ann());\n     ret @spanned(lo, hi, item);\n }\n "}, {"sha": "98e3b14e88c6a66381b622aba3e134fb4e82cfa1", "filename": "src/comp/middle/trans.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Fmiddle%2Ftrans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Fmiddle%2Ftrans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ftrans.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -3090,7 +3090,7 @@ fn node_ann_type(@crate_ctxt cx, &ast.ann a) -> ty.t {\n \n fn node_ann_ty_params(&ast.ann a) -> vec[ty.t] {\n     alt (a) {\n-        case (ast.ann_none) {\n+        case (ast.ann_none(_)) {\n             log_err \"missing type annotation\";\n             fail;\n         }\n@@ -4106,7 +4106,7 @@ fn lval_generic_fn(@block_ctxt cx,\n     auto monoty;\n     let vec[ty.t] tys;\n     alt (ann) {\n-        case (ast.ann_none) {\n+        case (ast.ann_none(_)) {\n             cx.fcx.lcx.ccx.sess.bug(\"no type annotation for path!\");\n             fail;\n         }"}, {"sha": "5c2dc425b4953d4338852ef7ae6dda2a50385d2f", "filename": "src/comp/middle/ty.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Fmiddle%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Fmiddle%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Fty.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -1557,7 +1557,7 @@ fn eq_ty(&t a, &t b) -> bool {\n \n fn ann_to_type(&ast.ann ann) -> t {\n     alt (ann) {\n-        case (ast.ann_none) {\n+        case (ast.ann_none(_)) {\n             log_err \"ann_to_type() called on node with no type\";\n             fail;\n         }\n@@ -1569,7 +1569,7 @@ fn ann_to_type(&ast.ann ann) -> t {\n \n fn ann_to_type_params(&ast.ann ann) -> vec[t] {\n     alt (ann) {\n-        case (ast.ann_none) {\n+        case (ast.ann_none(_)) {\n             log_err \"ann_to_type_params() called on node with no type params\";\n             fail;\n         }\n@@ -1591,7 +1591,7 @@ fn ann_to_monotype(ctxt cx, ast.ann a) -> t {\n     // TODO: Refactor to use recursive pattern matching when we're more\n     // confident that it works.\n     alt (a) {\n-        case (ast.ann_none) {\n+        case (ast.ann_none(_)) {\n             log_err \"ann_to_monotype() called on expression with no type!\";\n             fail;\n         }\n@@ -1905,7 +1905,7 @@ fn expr_ty_params_and_ty(&ctxt cx, &@ast.expr expr) -> tup(vec[t], t) {\n fn expr_has_ty_params(&@ast.expr expr) -> bool {\n     // FIXME: Rewrite using complex patterns when they're trustworthy.\n     alt (expr_ann(expr)) {\n-        case (ast.ann_none) { fail; }\n+        case (ast.ann_none(_)) { fail; }\n         case (ast.ann_type(_, ?tps_opt, _)) {\n             ret !Option.is_none[vec[t]](tps_opt);\n         }"}, {"sha": "7e948376b72c62a34aef644108ba676549ecb746", "filename": "src/comp/middle/typeck.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Fmiddle%2Ftypeck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Fmiddle%2Ftypeck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ftypeck.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -1396,7 +1396,7 @@ mod Pushdown {\n                 // provided by the programmer.\n                 auto ty_params_opt;\n                 alt (ann) {\n-                    case (ast.ann_none) {\n+                    case (ast.ann_none(_)) {\n                         log_err \"pushdown_expr(): no type annotation for \" +\n                             \"path expr; did you pass it to check_expr()?\";\n                         fail;\n@@ -1558,7 +1558,7 @@ fn resolve_local_types_in_annotation(&Option.t[@fn_ctxt] env, &ast.ann ann)\n \n     auto fcx = Option.get[@fn_ctxt](env);\n     alt (ann) {\n-        case (ast.ann_none) {\n+        case (ast.ann_none(_)) {\n             log \"warning: no type for expression\";\n             ret ann;\n         }\n@@ -2506,7 +2506,7 @@ fn check_expr(&@fn_ctxt fcx, &@ast.expr expr) -> @ast.expr {\n                 Vec.push[field](fields_t, rec(ident=f.ident, mt=expr_mt));\n             }\n \n-            auto ann = ast.ann_none;\n+            auto ann;\n \n             alt (base) {\n                 case (none[@ast.expr]) {\n@@ -2717,7 +2717,7 @@ fn check_decl_local(&@fn_ctxt fcx, &@ast.decl decl) -> @ast.decl {\n \n             auto a_res = local.ann;\n             alt (a_res) {\n-                case (ann_none) {\n+                case (ann_none(_)) {\n                     a_res = triv_ann(t);\n                 }\n                 case (_) {}"}, {"sha": "4346db02444c46649c4f57e723fe83c0788837d0", "filename": "src/comp/middle/typestate_check.rs", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Fmiddle%2Ftypestate_check.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Fmiddle%2Ftypestate_check.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ftypestate_check.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -392,7 +392,7 @@ fn mk_f_to_fn_info(@ast.crate c) -> fn_info_map {\n /**** Helpers ****/\n fn ann_to_ts_ann(ann a, uint nv) -> ts_ann {\n   alt (a) {\n-    case (ann_none)         { ret empty_ann(nv); }\n+    case (ann_none(_))      { ret empty_ann(nv); }\n     case (ann_type(_,_,?t)) {\n       alt (t) {\n         /* Kind of inconsistent. empty_ann()s everywhere\n@@ -406,7 +406,7 @@ fn ann_to_ts_ann(ann a, uint nv) -> ts_ann {\n \n fn ann_to_ts_ann_fail(ann a) -> Option.t[@ts_ann] {\n   alt (a) {\n-      case (ann_none) { \n+      case (ann_none(_)) { \n           log(\"ann_to_ts_ann_fail: didn't expect ann_none here\");\n           fail;\n       }\n@@ -418,7 +418,7 @@ fn ann_to_ts_ann_fail(ann a) -> Option.t[@ts_ann] {\n \n fn ann_to_ts_ann_fail_more(ann a) -> @ts_ann {\n   alt (a) {\n-      case (ann_none) { \n+      case (ann_none(_)) { \n           log(\"ann_to_ts_ann_fail: didn't expect ann_none here\");\n           fail;\n       }\n@@ -450,7 +450,7 @@ fn stmt_to_ann(&stmt s) -> Option.t[@ts_ann] {\n /* fails if e has no annotation */\n fn expr_states(@expr e) -> pre_and_post_state {\n   alt (expr_ann(e)) {\n-    case (ann_none) {\n+    case (ann_none(_)) {\n       log_err \"expr_pp: the impossible happened (no annotation)\";\n       fail;\n     }\n@@ -471,7 +471,7 @@ fn expr_states(@expr e) -> pre_and_post_state {\n /* fails if e has no annotation */\n fn expr_pp(@expr e) -> pre_and_post {\n   alt (expr_ann(e)) {\n-    case (ann_none) {\n+    case (ann_none(_)) {\n       log_err \"expr_pp: the impossible happened (no annotation)\";\n       fail;\n     }\n@@ -505,7 +505,7 @@ fn stmt_pp(&stmt s) -> pre_and_post {\n /* FIXME: factor out code in the following two functions (block_ts_ann) */\n fn block_pp(&block b) -> pre_and_post {\n     alt (b.node.a) {\n-       case (ann_none) {\n+       case (ann_none(_)) {\n            log_err \"block_pp: the impossible happened (no ann)\";\n            fail;\n        }\n@@ -525,7 +525,7 @@ fn block_pp(&block b) -> pre_and_post {\n \n fn block_states(&block b) -> pre_and_post_state {\n     alt (b.node.a) {\n-       case (ann_none) {\n+       case (ann_none(_)) {\n            log_err \"block_pp: the impossible happened (no ann)\";\n            fail;\n        }\n@@ -605,7 +605,7 @@ fn block_poststate(&block b) -> poststate {\n /* returns a new annotation where the pre_and_post is p */\n fn with_pp(ann a, pre_and_post p) -> ann {\n   alt (a) {\n-    case (ann_none) {\n+    case (ann_none(_)) {\n       log(\"with_pp: the impossible happened\");\n       fail; /* shouldn't happen b/c code is typechecked */\n     }\n@@ -1300,7 +1300,7 @@ fn set_prestate_ann(@ann a, prestate pre) -> bool {\n       assert (! is_none[@ts_ann](ts_a));\n       ret set_prestate(get[@ts_ann](ts_a), pre);\n     }\n-    case (ann_none) {\n+    case (ann_none(_)) {\n       log(\"set_prestate_ann: expected an ann_type here\");\n       fail;\n     }\n@@ -1314,7 +1314,7 @@ fn extend_prestate_ann(ann a, prestate pre) -> bool {\n       assert (! is_none[@ts_ann](ts_a));\n       ret extend_prestate((get[@ts_ann](ts_a)).states.prestate, pre);\n     }\n-    case (ann_none) {\n+    case (ann_none(_)) {\n       log(\"set_prestate_ann: expected an ann_type here\");\n       fail;\n     }\n@@ -1327,7 +1327,7 @@ fn set_poststate_ann(ann a, poststate post) -> bool {\n       assert (! is_none[@ts_ann](ts_a));\n       ret set_poststate(get[@ts_ann](ts_a), post);\n     }\n-    case (ann_none) {\n+    case (ann_none(_)) {\n       log(\"set_poststate_ann: expected an ann_type here\");\n       fail;\n     }\n@@ -1340,7 +1340,7 @@ fn extend_poststate_ann(ann a, poststate post) -> bool {\n       assert (! is_none[@ts_ann](ts_a));\n       ret extend_poststate((*get[@ts_ann](ts_a)).states.poststate, post);\n     }\n-    case (ann_none) {\n+    case (ann_none(_)) {\n       log(\"set_poststate_ann: expected an ann_type here\");\n       fail;\n     }\n@@ -1360,7 +1360,7 @@ fn set_pre_and_post(&ann a, pre_and_post pp) -> () {\n             set_precondition(t, pp.precondition);\n             set_postcondition(t, pp.postcondition);\n         }\n-        case (ann_none) {\n+        case (ann_none(_)) {\n             log_err(\"set_pre_and_post: expected an ann_type here\");\n             fail;\n         }\n@@ -2042,7 +2042,7 @@ fn check_obj_state(&fn_info_map f_info_map, &vec[obj_field] fields,\n \n fn init_ann(&fn_info fi, &ann a) -> ann {\n     alt (a) {\n-        case (ann_none) {\n+        case (ann_none(_)) {\n             //            log(\"init_ann: shouldn't see ann_none\");\n             // fail;\n             log(\"warning: init_ann: saw ann_none\");\n@@ -2058,7 +2058,7 @@ fn init_ann(&fn_info fi, &ann a) -> ann {\n \n fn init_blank_ann(&() ignore, &ann a) -> ann {\n     alt (a) {\n-        case (ann_none) {\n+        case (ann_none(_)) {\n             //            log(\"init_blank_ann: shouldn't see ann_none\");\n             //fail;\n             log(\"warning: init_blank_ann: saw ann_none\");\n@@ -2074,7 +2074,7 @@ fn init_block(&fn_info fi, &span sp, &block_ b) -> block {\n     log(\"init_block:\");\n     log_block(respan(sp, b));\n     alt(b.a) {\n-        case (ann_none) {\n+        case (ann_none(_)) {\n             log(\"init_block: shouldn't see ann_none\");\n             fail;\n         }"}, {"sha": "5181cb45985026eafb165e1f08b4288f67471cad", "filename": "src/comp/util/common.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Futil%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/10c926652515052000e44ef4ac10e6b4ebbc6e3a/src%2Fcomp%2Futil%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Futil%2Fcommon.rs?ref=10c926652515052000e44ef4ac10e6b4ebbc6e3a", "patch": "@@ -161,7 +161,7 @@ fn log_block_err(&ast.block b) -> () {\n \n fn log_ann(&ast.ann a) -> () {\n     alt (a) {\n-        case (ast.ann_none) {\n+        case (ast.ann_none(_)) {\n             log(\"ann_none\");\n         }\n         case (ast.ann_type(_,_,_)) {"}]}