{"sha": "87b76a521d4cc281880271e4e90e8139dd5a5372", "node_id": "MDY6Q29tbWl0NzI0NzEyOjg3Yjc2YTUyMWQ0Y2MyODE4ODAyNzFlNGU5MGU4MTM5ZGQ1YTUzNzI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2016-11-14T00:23:57Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2016-11-14T00:23:57Z"}, "message": "Auto merge of #37701 - Mark-Simulacrum:macro-parser-impvement, r=jseyfried\n\nMacro parser performance improvements and refactoring\n\nThis PR locally increased performance of https://github.com/rust-lang/rust/issues/37074 by ~6.6 minutes.\n\nFollow up to https://github.com/rust-lang/rust/pull/37569, but doesn't focus explicitly on expansion performance.\n\nHistory is relatively clean, but I can/will do some more polishing if this is deemed mergeable. Partially posting this now so I can get Travis to run tests for me.\n\nr? @jseyfried", "tree": {"sha": "562db8e418062813f7dbb573cef6e84ad72e8ebd", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/562db8e418062813f7dbb573cef6e84ad72e8ebd"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/87b76a521d4cc281880271e4e90e8139dd5a5372", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/87b76a521d4cc281880271e4e90e8139dd5a5372", "html_url": "https://github.com/rust-lang/rust/commit/87b76a521d4cc281880271e4e90e8139dd5a5372", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/87b76a521d4cc281880271e4e90e8139dd5a5372/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3316ef7f3685973c930562d813f940a0b6ff30d8", "url": "https://api.github.com/repos/rust-lang/rust/commits/3316ef7f3685973c930562d813f940a0b6ff30d8", "html_url": "https://github.com/rust-lang/rust/commit/3316ef7f3685973c930562d813f940a0b6ff30d8"}, {"sha": "2189f573caf93e389a56aefe0aeaa027feafd281", "url": "https://api.github.com/repos/rust-lang/rust/commits/2189f573caf93e389a56aefe0aeaa027feafd281", "html_url": "https://github.com/rust-lang/rust/commit/2189f573caf93e389a56aefe0aeaa027feafd281"}], "stats": {"total": 413, "additions": 201, "deletions": 212}, "files": [{"sha": "39ffab4dc17a7e2fe8e9386478c3793c24bc5e50", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 201, "deletions": 212, "changes": 413, "blob_url": "https://github.com/rust-lang/rust/blob/87b76a521d4cc281880271e4e90e8139dd5a5372/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/87b76a521d4cc281880271e4e90e8139dd5a5372/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=87b76a521d4cc281880271e4e90e8139dd5a5372", "patch": "@@ -130,7 +130,7 @@ struct MatcherTtFrame {\n }\n \n #[derive(Clone)]\n-pub struct MatcherPos {\n+struct MatcherPos {\n     stack: Vec<MatcherTtFrame>,\n     top_elts: TokenTreeOrTokenTreeVec,\n     sep: Option<Token>,\n@@ -143,6 +143,8 @@ pub struct MatcherPos {\n     sp_lo: BytePos,\n }\n \n+pub type NamedParseResult = ParseResult<HashMap<Ident, Rc<NamedMatch>>>;\n+\n pub fn count_names(ms: &[TokenTree]) -> usize {\n     ms.iter().fold(0, |count, elt| {\n         count + match *elt {\n@@ -160,14 +162,13 @@ pub fn count_names(ms: &[TokenTree]) -> usize {\n     })\n }\n \n-pub fn initial_matcher_pos(ms: Vec<TokenTree>, sep: Option<Token>, lo: BytePos)\n-                           -> Box<MatcherPos> {\n+fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n     let match_idx_hi = count_names(&ms[..]);\n-    let matches: Vec<_> = (0..match_idx_hi).map(|_| Vec::new()).collect();\n+    let matches = create_matches(match_idx_hi);\n     Box::new(MatcherPos {\n         stack: vec![],\n         top_elts: TtSeq(ms),\n-        sep: sep,\n+        sep: None,\n         idx: 0,\n         up: None,\n         matches: matches,\n@@ -200,27 +201,25 @@ pub enum NamedMatch {\n     MatchedNonterminal(Rc<Nonterminal>)\n }\n \n-pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n-            -> ParseResult<HashMap<Ident, Rc<NamedMatch>>> {\n-    fn n_rec(p_s: &ParseSess, m: &TokenTree, res: &[Rc<NamedMatch>],\n-             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>, idx: &mut usize)\n+fn nameize<I: Iterator<Item=Rc<NamedMatch>>>(ms: &[TokenTree], mut res: I) -> NamedParseResult {\n+    fn n_rec<I: Iterator<Item=Rc<NamedMatch>>>(m: &TokenTree, mut res: &mut I,\n+             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>)\n              -> Result<(), (syntax_pos::Span, String)> {\n         match *m {\n             TokenTree::Sequence(_, ref seq) => {\n                 for next_m in &seq.tts {\n-                    n_rec(p_s, next_m, res, ret_val, idx)?\n+                    n_rec(next_m, res.by_ref(), ret_val)?\n                 }\n             }\n             TokenTree::Delimited(_, ref delim) => {\n                 for next_m in &delim.tts {\n-                    n_rec(p_s, next_m, res, ret_val, idx)?;\n+                    n_rec(next_m, res.by_ref(), ret_val)?;\n                 }\n             }\n             TokenTree::Token(sp, MatchNt(bind_name, _)) => {\n                 match ret_val.entry(bind_name) {\n                     Vacant(spot) => {\n-                        spot.insert(res[*idx].clone());\n-                        *idx += 1;\n+                        spot.insert(res.next().unwrap());\n                     }\n                     Occupied(..) => {\n                         return Err((sp, format!(\"duplicated bind name: {}\", bind_name)))\n@@ -237,9 +236,8 @@ pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n     }\n \n     let mut ret_val = HashMap::new();\n-    let mut idx = 0;\n     for m in ms {\n-        match n_rec(p_s, m, res, &mut ret_val, &mut idx) {\n+        match n_rec(m, res.by_ref(), &mut ret_val) {\n             Ok(_) => {},\n             Err((sp, msg)) => return Error(sp, msg),\n         }\n@@ -265,11 +263,8 @@ pub fn parse_failure_msg(tok: Token) -> String {\n     }\n }\n \n-pub type NamedParseResult = ParseResult<HashMap<Ident, Rc<NamedMatch>>>;\n-\n-/// Perform a token equality check, ignoring syntax context (that is, an\n-/// unhygienic comparison)\n-pub fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n+/// Perform a token equality check, ignoring syntax context (that is, an unhygienic comparison)\n+fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n     match (t1,t2) {\n         (&token::Ident(id1),&token::Ident(id2))\n         | (&token::Lifetime(id1),&token::Lifetime(id2)) =>\n@@ -278,234 +273,228 @@ pub fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n     }\n }\n \n-pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseResult {\n-    let mut parser = Parser::new_with_doc_flag(sess, Box::new(rdr), true);\n-    let mut cur_eis = SmallVector::one(initial_matcher_pos(ms.to_owned(), None, parser.span.lo));\n+fn create_matches(len: usize) -> Vec<Vec<Rc<NamedMatch>>> {\n+    (0..len).into_iter().map(|_| Vec::new()).collect()\n+}\n \n-    loop {\n-        let mut bb_eis = Vec::new(); // black-box parsed by parser.rs\n-        let mut next_eis = Vec::new(); // or proceed normally\n-        let mut eof_eis = Vec::new();\n-\n-        let (sp, tok) = (parser.span, parser.token.clone());\n-\n-        /* we append new items to this while we go */\n-        loop {\n-            let mut ei = match cur_eis.pop() {\n-                None => break, /* for each Earley Item */\n-                Some(ei) => ei,\n-            };\n-\n-            // When unzipped trees end, remove them\n-            while ei.idx >= ei.top_elts.len() {\n-                match ei.stack.pop() {\n-                    Some(MatcherTtFrame { elts, idx }) => {\n-                        ei.top_elts = elts;\n-                        ei.idx = idx + 1;\n-                    }\n-                    None => break\n+fn inner_parse_loop(cur_eis: &mut SmallVector<Box<MatcherPos>>,\n+                    next_eis: &mut Vec<Box<MatcherPos>>,\n+                    eof_eis: &mut SmallVector<Box<MatcherPos>>,\n+                    bb_eis: &mut SmallVector<Box<MatcherPos>>,\n+                    token: &Token, span: &syntax_pos::Span) -> ParseResult<()> {\n+    while let Some(mut ei) = cur_eis.pop() {\n+        // When unzipped trees end, remove them\n+        while ei.idx >= ei.top_elts.len() {\n+            match ei.stack.pop() {\n+                Some(MatcherTtFrame { elts, idx }) => {\n+                    ei.top_elts = elts;\n+                    ei.idx = idx + 1;\n                 }\n+                None => break\n             }\n+        }\n \n-            let idx = ei.idx;\n-            let len = ei.top_elts.len();\n-\n-            /* at end of sequence */\n-            if idx >= len {\n-                // can't move out of `match`es, so:\n-                if ei.up.is_some() {\n-                    // hack: a matcher sequence is repeating iff it has a\n-                    // parent (the top level is just a container)\n-\n-\n-                    // disregard separator, try to go up\n-                    // (remove this condition to make trailing seps ok)\n-                    if idx == len {\n-                        // pop from the matcher position\n-\n-                        let mut new_pos = ei.up.clone().unwrap();\n-\n-                        // update matches (the MBE \"parse tree\") by appending\n-                        // each tree as a subtree.\n-\n-                        // I bet this is a perf problem: we're preemptively\n-                        // doing a lot of array work that will get thrown away\n-                        // most of the time.\n-\n-                        // Only touch the binders we have actually bound\n-                        for idx in ei.match_lo..ei.match_hi {\n-                            let sub = (ei.matches[idx]).clone();\n-                            (&mut new_pos.matches[idx])\n-                                   .push(Rc::new(MatchedSeq(sub, mk_sp(ei.sp_lo,\n-                                                                       sp.hi))));\n-                        }\n-\n-                        new_pos.match_cur = ei.match_hi;\n-                        new_pos.idx += 1;\n-                        cur_eis.push(new_pos);\n+        let idx = ei.idx;\n+        let len = ei.top_elts.len();\n+\n+        // at end of sequence\n+        if idx >= len {\n+            // We are repeating iff there is a parent\n+            if ei.up.is_some() {\n+                // Disregarding the separator, add the \"up\" case to the tokens that should be\n+                // examined.\n+                // (remove this condition to make trailing seps ok)\n+                if idx == len {\n+                    let mut new_pos = ei.up.clone().unwrap();\n+\n+                    // update matches (the MBE \"parse tree\") by appending\n+                    // each tree as a subtree.\n+\n+                    // I bet this is a perf problem: we're preemptively\n+                    // doing a lot of array work that will get thrown away\n+                    // most of the time.\n+\n+                    // Only touch the binders we have actually bound\n+                    for idx in ei.match_lo..ei.match_hi {\n+                        let sub = ei.matches[idx].clone();\n+                        new_pos.matches[idx]\n+                            .push(Rc::new(MatchedSeq(sub, mk_sp(ei.sp_lo,\n+                                                                span.hi))));\n                     }\n \n-                    // can we go around again?\n-\n-                    // the *_t vars are workarounds for the lack of unary move\n-                    match ei.sep {\n-                        Some(ref t) if idx == len => { // we need a separator\n-                            // i'm conflicted about whether this should be hygienic....\n-                            // though in this case, if the separators are never legal\n-                            // idents, it shouldn't matter.\n-                            if token_name_eq(&tok, t) { //pass the separator\n-                                let mut ei_t = ei.clone();\n-                                // ei_t.match_cur = ei_t.match_lo;\n-                                ei_t.idx += 1;\n-                                next_eis.push(ei_t);\n-                            }\n-                        }\n-                        _ => { // we don't need a separator\n-                            let mut ei_t = ei;\n-                            ei_t.match_cur = ei_t.match_lo;\n-                            ei_t.idx = 0;\n-                            cur_eis.push(ei_t);\n-                        }\n-                    }\n-                } else {\n-                    eof_eis.push(ei);\n+                    new_pos.match_cur = ei.match_hi;\n+                    new_pos.idx += 1;\n+                    cur_eis.push(new_pos);\n                 }\n-            } else {\n-                match ei.top_elts.get_tt(idx) {\n-                    /* need to descend into sequence */\n-                    TokenTree::Sequence(sp, seq) => {\n-                        if seq.op == tokenstream::KleeneOp::ZeroOrMore {\n-                            let mut new_ei = ei.clone();\n-                            new_ei.match_cur += seq.num_captures;\n-                            new_ei.idx += 1;\n-                            //we specifically matched zero repeats.\n-                            for idx in ei.match_cur..ei.match_cur + seq.num_captures {\n-                                (&mut new_ei.matches[idx]).push(Rc::new(MatchedSeq(vec![], sp)));\n-                            }\n-\n-                            cur_eis.push(new_ei);\n-                        }\n \n-                        let matches: Vec<_> = (0..ei.matches.len())\n-                            .map(|_| Vec::new()).collect();\n-                        let ei_t = ei;\n-                        cur_eis.push(Box::new(MatcherPos {\n-                            stack: vec![],\n-                            sep: seq.separator.clone(),\n-                            idx: 0,\n-                            matches: matches,\n-                            match_lo: ei_t.match_cur,\n-                            match_cur: ei_t.match_cur,\n-                            match_hi: ei_t.match_cur + seq.num_captures,\n-                            up: Some(ei_t),\n-                            sp_lo: sp.lo,\n-                            top_elts: Tt(TokenTree::Sequence(sp, seq)),\n-                        }));\n+                // Check if we need a separator\n+                if idx == len && ei.sep.is_some() {\n+                    // We have a separator, and it is the current token.\n+                    if ei.sep.as_ref().map(|ref sep| token_name_eq(&token, sep)).unwrap_or(false) {\n+                        ei.idx += 1;\n+                        next_eis.push(ei);\n                     }\n-                    TokenTree::Token(_, MatchNt(..)) => {\n-                        // Built-in nonterminals never start with these tokens,\n-                        // so we can eliminate them from consideration.\n-                        match tok {\n-                            token::CloseDelim(_) => {},\n-                            _ => bb_eis.push(ei),\n+                } else { // we don't need a separator\n+                    ei.match_cur = ei.match_lo;\n+                    ei.idx = 0;\n+                    cur_eis.push(ei);\n+                }\n+            } else {\n+                // We aren't repeating, so we must be potentially at the end of the input.\n+                eof_eis.push(ei);\n+            }\n+        } else {\n+            match ei.top_elts.get_tt(idx) {\n+                /* need to descend into sequence */\n+                TokenTree::Sequence(sp, seq) => {\n+                    if seq.op == tokenstream::KleeneOp::ZeroOrMore {\n+                        // Examine the case where there are 0 matches of this sequence\n+                        let mut new_ei = ei.clone();\n+                        new_ei.match_cur += seq.num_captures;\n+                        new_ei.idx += 1;\n+                        for idx in ei.match_cur..ei.match_cur + seq.num_captures {\n+                            new_ei.matches[idx].push(Rc::new(MatchedSeq(vec![], sp)));\n                         }\n+                        cur_eis.push(new_ei);\n                     }\n-                    TokenTree::Token(sp, SubstNt(..)) => {\n-                        return Error(sp, \"missing fragment specifier\".to_string())\n-                    }\n-                    seq @ TokenTree::Delimited(..) | seq @ TokenTree::Token(_, DocComment(..)) => {\n-                        let lower_elts = mem::replace(&mut ei.top_elts, Tt(seq));\n-                        let idx = ei.idx;\n-                        ei.stack.push(MatcherTtFrame {\n-                            elts: lower_elts,\n-                            idx: idx,\n-                        });\n-                        ei.idx = 0;\n-                        cur_eis.push(ei);\n+\n+                    // Examine the case where there is at least one match of this sequence\n+                    let matches = create_matches(ei.matches.len());\n+                    cur_eis.push(Box::new(MatcherPos {\n+                        stack: vec![],\n+                        sep: seq.separator.clone(),\n+                        idx: 0,\n+                        matches: matches,\n+                        match_lo: ei.match_cur,\n+                        match_cur: ei.match_cur,\n+                        match_hi: ei.match_cur + seq.num_captures,\n+                        up: Some(ei),\n+                        sp_lo: sp.lo,\n+                        top_elts: Tt(TokenTree::Sequence(sp, seq)),\n+                    }));\n+                }\n+                TokenTree::Token(_, MatchNt(..)) => {\n+                    // Built-in nonterminals never start with these tokens,\n+                    // so we can eliminate them from consideration.\n+                    match *token {\n+                        token::CloseDelim(_) => {},\n+                        _ => bb_eis.push(ei),\n                     }\n-                    TokenTree::Token(_, ref t) => {\n-                        if token_name_eq(t,&tok) {\n-                            let mut ei_t = ei.clone();\n-                            ei_t.idx += 1;\n-                            next_eis.push(ei_t);\n-                        }\n+                }\n+                TokenTree::Token(sp, SubstNt(..)) => {\n+                    return Error(sp, \"missing fragment specifier\".to_string())\n+                }\n+                seq @ TokenTree::Delimited(..) | seq @ TokenTree::Token(_, DocComment(..)) => {\n+                    let lower_elts = mem::replace(&mut ei.top_elts, Tt(seq));\n+                    let idx = ei.idx;\n+                    ei.stack.push(MatcherTtFrame {\n+                        elts: lower_elts,\n+                        idx: idx,\n+                    });\n+                    ei.idx = 0;\n+                    cur_eis.push(ei);\n+                }\n+                TokenTree::Token(_, ref t) => {\n+                    if token_name_eq(t, &token) {\n+                        ei.idx += 1;\n+                        next_eis.push(ei);\n                     }\n                 }\n             }\n         }\n+    }\n+\n+    Success(())\n+}\n+\n+pub fn parse(sess: &ParseSess, rdr: TtReader, ms: &[TokenTree]) -> NamedParseResult {\n+    let mut parser = Parser::new_with_doc_flag(sess, Box::new(rdr), true);\n+    let mut cur_eis = SmallVector::one(initial_matcher_pos(ms.to_owned(), parser.span.lo));\n+    let mut next_eis = Vec::new(); // or proceed normally\n+\n+    loop {\n+        let mut bb_eis = SmallVector::new(); // black-box parsed by parser.rs\n+        let mut eof_eis = SmallVector::new();\n+        assert!(next_eis.is_empty());\n+\n+        match inner_parse_loop(&mut cur_eis, &mut next_eis, &mut eof_eis, &mut bb_eis,\n+                               &parser.token, &parser.span) {\n+            Success(_) => {},\n+            Failure(sp, tok) => return Failure(sp, tok),\n+            Error(sp, msg) => return Error(sp, msg),\n+        }\n+\n+        // inner parse loop handled all cur_eis, so it's empty\n+        assert!(cur_eis.is_empty());\n \n         /* error messages here could be improved with links to orig. rules */\n-        if token_name_eq(&tok, &token::Eof) {\n+        if token_name_eq(&parser.token, &token::Eof) {\n             if eof_eis.len() == 1 {\n-                let mut v = Vec::new();\n-                for dv in &mut (&mut eof_eis[0]).matches {\n-                    v.push(dv.pop().unwrap());\n-                }\n-                return nameize(sess, ms, &v[..]);\n+                return nameize(ms, eof_eis[0].matches.iter_mut().map(|mut dv| dv.pop().unwrap()));\n             } else if eof_eis.len() > 1 {\n-                return Error(sp, \"ambiguity: multiple successful parses\".to_string());\n+                return Error(parser.span, \"ambiguity: multiple successful parses\".to_string());\n             } else {\n-                return Failure(sp, token::Eof);\n+                return Failure(parser.span, token::Eof);\n             }\n-        } else {\n-            if (!bb_eis.is_empty() && !next_eis.is_empty())\n-                || bb_eis.len() > 1 {\n-                let nts = bb_eis.iter().map(|ei| match ei.top_elts.get_tt(ei.idx) {\n-                    TokenTree::Token(_, MatchNt(bind, name)) => {\n-                        format!(\"{} ('{}')\", name, bind)\n-                    }\n-                    _ => panic!()\n-                }).collect::<Vec<String>>().join(\" or \");\n-\n-                return Error(sp, format!(\n-                    \"local ambiguity: multiple parsing options: {}\",\n-                    match next_eis.len() {\n-                        0 => format!(\"built-in NTs {}.\", nts),\n-                        1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n-                        n => format!(\"built-in NTs {} or {} other options.\", nts, n),\n-                    }\n-                ))\n-            } else if bb_eis.is_empty() && next_eis.is_empty() {\n-                return Failure(sp, tok);\n-            } else if !next_eis.is_empty() {\n-                /* Now process the next token */\n-                while !next_eis.is_empty() {\n-                    cur_eis.push(next_eis.pop().unwrap());\n+        } else if (!bb_eis.is_empty() && !next_eis.is_empty()) || bb_eis.len() > 1 {\n+            let nts = bb_eis.iter().map(|ei| match ei.top_elts.get_tt(ei.idx) {\n+                TokenTree::Token(_, MatchNt(bind, name)) => {\n+                    format!(\"{} ('{}')\", name, bind)\n                 }\n-                parser.bump();\n-            } else /* bb_eis.len() == 1 */ {\n-                let mut ei = bb_eis.pop().unwrap();\n-                if let TokenTree::Token(span, MatchNt(_, ident)) = ei.top_elts.get_tt(ei.idx) {\n-                    let match_cur = ei.match_cur;\n-                    (&mut ei.matches[match_cur]).push(Rc::new(MatchedNonterminal(\n-                        Rc::new(parse_nt(&mut parser, span, &ident.name.as_str())))));\n-                    ei.idx += 1;\n-                    ei.match_cur += 1;\n-                } else {\n-                    unreachable!()\n+                _ => panic!()\n+            }).collect::<Vec<String>>().join(\" or \");\n+\n+            return Error(parser.span, format!(\n+                \"local ambiguity: multiple parsing options: {}\",\n+                match next_eis.len() {\n+                    0 => format!(\"built-in NTs {}.\", nts),\n+                    1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n+                    n => format!(\"built-in NTs {} or {} other options.\", nts, n),\n                 }\n-                cur_eis.push(ei);\n+            ));\n+        } else if bb_eis.is_empty() && next_eis.is_empty() {\n+            return Failure(parser.span, parser.token);\n+        } else if !next_eis.is_empty() {\n+            /* Now process the next token */\n+            cur_eis.extend(next_eis.drain(..));\n+            parser.bump();\n+        } else /* bb_eis.len() == 1 */ {\n+            let mut ei = bb_eis.pop().unwrap();\n+            if let TokenTree::Token(span, MatchNt(_, ident)) = ei.top_elts.get_tt(ei.idx) {\n+                let match_cur = ei.match_cur;\n+                ei.matches[match_cur].push(Rc::new(MatchedNonterminal(\n+                            Rc::new(parse_nt(&mut parser, span, &ident.name.as_str())))));\n+                ei.idx += 1;\n+                ei.match_cur += 1;\n+            } else {\n+                unreachable!()\n             }\n+            cur_eis.push(ei);\n         }\n \n         assert!(!cur_eis.is_empty());\n     }\n }\n \n-pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n+fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n     match name {\n         \"tt\" => {\n             p.quote_depth += 1; //but in theory, non-quoted tts might be useful\n             let mut tt = panictry!(p.parse_token_tree());\n             p.quote_depth -= 1;\n-            loop {\n-                let nt = match tt {\n-                    TokenTree::Token(_, token::Interpolated(ref nt)) => nt.clone(),\n-                    _ => break,\n-                };\n-                match *nt {\n-                    token::NtTT(ref sub_tt) => tt = sub_tt.clone(),\n-                    _ => break,\n+            while let TokenTree::Token(sp, token::Interpolated(nt)) = tt {\n+                if let token::NtTT(..) = *nt {\n+                    match Rc::try_unwrap(nt) {\n+                        Ok(token::NtTT(sub_tt)) => tt = sub_tt,\n+                        Ok(_) => unreachable!(),\n+                        Err(nt_rc) => match *nt_rc {\n+                            token::NtTT(ref sub_tt) => tt = sub_tt.clone(),\n+                            _ => unreachable!(),\n+                        },\n+                    }\n+                } else {\n+                    tt = TokenTree::Token(sp, token::Interpolated(nt.clone()));\n+                    break\n                 }\n             }\n             return token::NtTT(tt);"}]}