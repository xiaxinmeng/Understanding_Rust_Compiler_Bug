{"sha": "a88613c86901083dd9f87c43f41d6c0f84f88dee", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE4ODYxM2M4NjkwMTA4M2RkOWY4N2M0M2Y0MWQ2YzBmODRmODhkZWU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-11-11T14:24:39Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-11-11T14:24:39Z"}, "message": "Auto merge of #55674 - oli-obk:miri_engine_refactoring, r=RalfJung\n\nMiri engine refactoring\n\nr? @RalfJung\n\nsplit out the \"just moves stuff around\" part of https://github.com/rust-lang/rust/pull/55293", "tree": {"sha": "9c86373e6cd43d15ed39000984c524ef90d31c8c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9c86373e6cd43d15ed39000984c524ef90d31c8c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a88613c86901083dd9f87c43f41d6c0f84f88dee", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a88613c86901083dd9f87c43f41d6c0f84f88dee", "html_url": "https://github.com/rust-lang/rust/commit/a88613c86901083dd9f87c43f41d6c0f84f88dee", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a88613c86901083dd9f87c43f41d6c0f84f88dee/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b76ee83254ec0398da554f25c2168d917ba60f1c", "url": "https://api.github.com/repos/rust-lang/rust/commits/b76ee83254ec0398da554f25c2168d917ba60f1c", "html_url": "https://github.com/rust-lang/rust/commit/b76ee83254ec0398da554f25c2168d917ba60f1c"}, {"sha": "428af73e7c3b77a05a4d998e4c0fe3146b80c332", "url": "https://api.github.com/repos/rust-lang/rust/commits/428af73e7c3b77a05a4d998e4c0fe3146b80c332", "html_url": "https://github.com/rust-lang/rust/commit/428af73e7c3b77a05a4d998e4c0fe3146b80c332"}], "stats": {"total": 1026, "additions": 532, "deletions": 494}, "files": [{"sha": "e55997099c82b92c9312abd9755e84d5b1df5893", "filename": "src/librustc/mir/interpret/allocation.rs", "status": "added", "additions": 233, "deletions": 0, "changes": 233, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -0,0 +1,233 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! The virtual memory representation of the MIR interpreter\n+\n+use super::{Pointer, EvalResult, AllocId};\n+\n+use ty::layout::{Size, Align};\n+use syntax::ast::Mutability;\n+use std::iter;\n+use mir;\n+use std::ops::{Deref, DerefMut};\n+use rustc_data_structures::sorted_map::SortedMap;\n+\n+#[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n+pub struct Allocation<Tag=(),Extra=()> {\n+    /// The actual bytes of the allocation.\n+    /// Note that the bytes of a pointer represent the offset of the pointer\n+    pub bytes: Vec<u8>,\n+    /// Maps from byte addresses to extra data for each pointer.\n+    /// Only the first byte of a pointer is inserted into the map; i.e.,\n+    /// every entry in this map applies to `pointer_size` consecutive bytes starting\n+    /// at the given offset.\n+    pub relocations: Relocations<Tag>,\n+    /// Denotes undefined memory. Reading from undefined memory is forbidden in miri\n+    pub undef_mask: UndefMask,\n+    /// The alignment of the allocation to detect unaligned reads.\n+    pub align: Align,\n+    /// Whether the allocation is mutable.\n+    /// Also used by codegen to determine if a static should be put into mutable memory,\n+    /// which happens for `static mut` and `static` with interior mutability.\n+    pub mutability: Mutability,\n+    /// Extra state for the machine.\n+    pub extra: Extra,\n+}\n+\n+pub trait AllocationExtra<Tag>: ::std::fmt::Debug + Default + Clone {\n+    /// Hook for performing extra checks on a memory read access.\n+    ///\n+    /// Takes read-only access to the allocation so we can keep all the memory read\n+    /// operations take `&self`.  Use a `RefCell` in `AllocExtra` if you\n+    /// need to mutate.\n+    #[inline]\n+    fn memory_read(\n+        _alloc: &Allocation<Tag, Self>,\n+        _ptr: Pointer<Tag>,\n+        _size: Size,\n+    ) -> EvalResult<'tcx> {\n+        Ok(())\n+    }\n+\n+    /// Hook for performing extra checks on a memory write access.\n+    #[inline]\n+    fn memory_written(\n+        _alloc: &mut Allocation<Tag, Self>,\n+        _ptr: Pointer<Tag>,\n+        _size: Size,\n+    ) -> EvalResult<'tcx> {\n+        Ok(())\n+    }\n+}\n+\n+impl AllocationExtra<()> for () {}\n+\n+impl<Tag, Extra: Default> Allocation<Tag, Extra> {\n+    /// Creates a read-only allocation initialized by the given bytes\n+    pub fn from_bytes(slice: &[u8], align: Align) -> Self {\n+        let mut undef_mask = UndefMask::new(Size::ZERO);\n+        undef_mask.grow(Size::from_bytes(slice.len() as u64), true);\n+        Self {\n+            bytes: slice.to_owned(),\n+            relocations: Relocations::new(),\n+            undef_mask,\n+            align,\n+            mutability: Mutability::Immutable,\n+            extra: Extra::default(),\n+        }\n+    }\n+\n+    pub fn from_byte_aligned_bytes(slice: &[u8]) -> Self {\n+        Allocation::from_bytes(slice, Align::from_bytes(1, 1).unwrap())\n+    }\n+\n+    pub fn undef(size: Size, align: Align) -> Self {\n+        assert_eq!(size.bytes() as usize as u64, size.bytes());\n+        Allocation {\n+            bytes: vec![0; size.bytes() as usize],\n+            relocations: Relocations::new(),\n+            undef_mask: UndefMask::new(size),\n+            align,\n+            mutability: Mutability::Mutable,\n+            extra: Extra::default(),\n+        }\n+    }\n+}\n+\n+impl<'tcx> ::serialize::UseSpecializedDecodable for &'tcx Allocation {}\n+\n+#[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, RustcEncodable, RustcDecodable)]\n+pub struct Relocations<Tag=(), Id=AllocId>(SortedMap<Size, (Tag, Id)>);\n+\n+impl<Tag, Id> Relocations<Tag, Id> {\n+    pub fn new() -> Self {\n+        Relocations(SortedMap::new())\n+    }\n+\n+    // The caller must guarantee that the given relocations are already sorted\n+    // by address and contain no duplicates.\n+    pub fn from_presorted(r: Vec<(Size, (Tag, Id))>) -> Self {\n+        Relocations(SortedMap::from_presorted_elements(r))\n+    }\n+}\n+\n+impl<Tag> Deref for Relocations<Tag> {\n+    type Target = SortedMap<Size, (Tag, AllocId)>;\n+\n+    fn deref(&self) -> &Self::Target {\n+        &self.0\n+    }\n+}\n+\n+impl<Tag> DerefMut for Relocations<Tag> {\n+    fn deref_mut(&mut self) -> &mut Self::Target {\n+        &mut self.0\n+    }\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Undefined byte tracking\n+////////////////////////////////////////////////////////////////////////////////\n+\n+type Block = u64;\n+const BLOCK_SIZE: u64 = 64;\n+\n+#[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n+pub struct UndefMask {\n+    blocks: Vec<Block>,\n+    len: Size,\n+}\n+\n+impl_stable_hash_for!(struct mir::interpret::UndefMask{blocks, len});\n+\n+impl UndefMask {\n+    pub fn new(size: Size) -> Self {\n+        let mut m = UndefMask {\n+            blocks: vec![],\n+            len: Size::ZERO,\n+        };\n+        m.grow(size, false);\n+        m\n+    }\n+\n+    /// Check whether the range `start..end` (end-exclusive) is entirely defined.\n+    ///\n+    /// Returns `Ok(())` if it's defined. Otherwise returns the index of the byte\n+    /// at which the first undefined access begins.\n+    #[inline]\n+    pub fn is_range_defined(&self, start: Size, end: Size) -> Result<(), Size> {\n+        if end > self.len {\n+            return Err(self.len);\n+        }\n+\n+        let idx = (start.bytes()..end.bytes())\n+            .map(|i| Size::from_bytes(i))\n+            .find(|&i| !self.get(i));\n+\n+        match idx {\n+            Some(idx) => Err(idx),\n+            None => Ok(())\n+        }\n+    }\n+\n+    pub fn set_range(&mut self, start: Size, end: Size, new_state: bool) {\n+        let len = self.len;\n+        if end > len {\n+            self.grow(end - len, new_state);\n+        }\n+        self.set_range_inbounds(start, end, new_state);\n+    }\n+\n+    pub fn set_range_inbounds(&mut self, start: Size, end: Size, new_state: bool) {\n+        for i in start.bytes()..end.bytes() {\n+            self.set(Size::from_bytes(i), new_state);\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn get(&self, i: Size) -> bool {\n+        let (block, bit) = bit_index(i);\n+        (self.blocks[block] & 1 << bit) != 0\n+    }\n+\n+    #[inline]\n+    pub fn set(&mut self, i: Size, new_state: bool) {\n+        let (block, bit) = bit_index(i);\n+        if new_state {\n+            self.blocks[block] |= 1 << bit;\n+        } else {\n+            self.blocks[block] &= !(1 << bit);\n+        }\n+    }\n+\n+    pub fn grow(&mut self, amount: Size, new_state: bool) {\n+        let unused_trailing_bits = self.blocks.len() as u64 * BLOCK_SIZE - self.len.bytes();\n+        if amount.bytes() > unused_trailing_bits {\n+            let additional_blocks = amount.bytes() / BLOCK_SIZE + 1;\n+            assert_eq!(additional_blocks as usize as u64, additional_blocks);\n+            self.blocks.extend(\n+                iter::repeat(0).take(additional_blocks as usize),\n+            );\n+        }\n+        let start = self.len;\n+        self.len += amount;\n+        self.set_range_inbounds(start, start + amount, new_state);\n+    }\n+}\n+\n+#[inline]\n+fn bit_index(bits: Size) -> (usize, usize) {\n+    let bits = bits.bytes();\n+    let a = bits / BLOCK_SIZE;\n+    let b = bits % BLOCK_SIZE;\n+    assert_eq!(a as usize as u64, a);\n+    assert_eq!(b as usize as u64, b);\n+    (a as usize, b as usize)\n+}"}, {"sha": "40daf78f546fbf2eb7a234f96446c37f35b8586b", "filename": "src/librustc/mir/interpret/mod.rs", "status": "modified", "additions": 11, "deletions": 337, "changes": 348, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -17,27 +17,32 @@ macro_rules! err {\n \n mod error;\n mod value;\n+mod allocation;\n+mod pointer;\n \n pub use self::error::{\n     EvalError, EvalResult, EvalErrorKind, AssertMessage, ConstEvalErr, struct_error,\n     FrameInfo, ConstEvalResult, ErrorHandled,\n };\n \n-pub use self::value::{Scalar, ConstValue};\n+pub use self::value::{Scalar, ConstValue, ScalarMaybeUndef};\n+\n+pub use self::allocation::{\n+    Allocation, AllocationExtra,\n+    Relocations, UndefMask,\n+};\n+\n+pub use self::pointer::{Pointer, PointerArithmetic};\n \n use std::fmt;\n use mir;\n use hir::def_id::DefId;\n use ty::{self, TyCtxt, Instance};\n-use ty::layout::{self, Align, HasDataLayout, Size};\n+use ty::layout::{self, Size};\n use middle::region;\n-use std::iter;\n use std::io;\n-use std::ops::{Deref, DerefMut};\n use std::hash::Hash;\n-use syntax::ast::Mutability;\n use rustc_serialize::{Encoder, Decodable, Encodable};\n-use rustc_data_structures::sorted_map::SortedMap;\n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sync::{Lock as Mutex, HashMapExt};\n use rustc_data_structures::tiny_list::TinyList;\n@@ -78,152 +83,6 @@ pub struct GlobalId<'tcx> {\n     pub promoted: Option<mir::Promoted>,\n }\n \n-////////////////////////////////////////////////////////////////////////////////\n-// Pointer arithmetic\n-////////////////////////////////////////////////////////////////////////////////\n-\n-pub trait PointerArithmetic: layout::HasDataLayout {\n-    // These are not supposed to be overridden.\n-\n-    #[inline(always)]\n-    fn pointer_size(&self) -> Size {\n-        self.data_layout().pointer_size\n-    }\n-\n-    //// Trunace the given value to the pointer size; also return whether there was an overflow\n-    #[inline]\n-    fn truncate_to_ptr(&self, val: u128) -> (u64, bool) {\n-        let max_ptr_plus_1 = 1u128 << self.pointer_size().bits();\n-        ((val % max_ptr_plus_1) as u64, val >= max_ptr_plus_1)\n-    }\n-\n-    #[inline]\n-    fn offset<'tcx>(&self, val: u64, i: u64) -> EvalResult<'tcx, u64> {\n-        let (res, over) = self.overflowing_offset(val, i);\n-        if over { err!(Overflow(mir::BinOp::Add)) } else { Ok(res) }\n-    }\n-\n-    #[inline]\n-    fn overflowing_offset(&self, val: u64, i: u64) -> (u64, bool) {\n-        let (res, over1) = val.overflowing_add(i);\n-        let (res, over2) = self.truncate_to_ptr(u128::from(res));\n-        (res, over1 || over2)\n-    }\n-\n-    #[inline]\n-    fn signed_offset<'tcx>(&self, val: u64, i: i64) -> EvalResult<'tcx, u64> {\n-        let (res, over) = self.overflowing_signed_offset(val, i128::from(i));\n-        if over { err!(Overflow(mir::BinOp::Add)) } else { Ok(res) }\n-    }\n-\n-    // Overflow checking only works properly on the range from -u64 to +u64.\n-    #[inline]\n-    fn overflowing_signed_offset(&self, val: u64, i: i128) -> (u64, bool) {\n-        // FIXME: is it possible to over/underflow here?\n-        if i < 0 {\n-            // trickery to ensure that i64::min_value() works fine\n-            // this formula only works for true negative values, it panics for zero!\n-            let n = u64::max_value() - (i as u64) + 1;\n-            val.overflowing_sub(n)\n-        } else {\n-            self.overflowing_offset(val, i as u64)\n-        }\n-    }\n-}\n-\n-impl<T: layout::HasDataLayout> PointerArithmetic for T {}\n-\n-\n-/// Pointer is generic over the type that represents a reference to Allocations,\n-/// thus making it possible for the most convenient representation to be used in\n-/// each context.\n-///\n-/// Defaults to the index based and loosely coupled AllocId.\n-///\n-/// Pointer is also generic over the `Tag` associated with each pointer,\n-/// which is used to do provenance tracking during execution.\n-#[derive(Copy, Clone, Debug, Eq, PartialEq, Ord, PartialOrd, RustcEncodable, RustcDecodable, Hash)]\n-pub struct Pointer<Tag=(),Id=AllocId> {\n-    pub alloc_id: Id,\n-    pub offset: Size,\n-    pub tag: Tag,\n-}\n-\n-/// Produces a `Pointer` which points to the beginning of the Allocation\n-impl From<AllocId> for Pointer {\n-    #[inline(always)]\n-    fn from(alloc_id: AllocId) -> Self {\n-        Pointer::new(alloc_id, Size::ZERO)\n-    }\n-}\n-\n-impl<'tcx> Pointer<()> {\n-    #[inline(always)]\n-    pub fn new(alloc_id: AllocId, offset: Size) -> Self {\n-        Pointer { alloc_id, offset, tag: () }\n-    }\n-\n-    #[inline(always)]\n-    pub fn with_default_tag<Tag>(self) -> Pointer<Tag>\n-        where Tag: Default\n-    {\n-        Pointer::new_with_tag(self.alloc_id, self.offset, Default::default())\n-    }\n-}\n-\n-impl<'tcx, Tag> Pointer<Tag> {\n-    #[inline(always)]\n-    pub fn new_with_tag(alloc_id: AllocId, offset: Size, tag: Tag) -> Self {\n-        Pointer { alloc_id, offset, tag }\n-    }\n-\n-    #[inline]\n-    pub fn offset(self, i: Size, cx: &impl HasDataLayout) -> EvalResult<'tcx, Self> {\n-        Ok(Pointer::new_with_tag(\n-            self.alloc_id,\n-            Size::from_bytes(cx.data_layout().offset(self.offset.bytes(), i.bytes())?),\n-            self.tag\n-        ))\n-    }\n-\n-    #[inline]\n-    pub fn overflowing_offset(self, i: Size, cx: &impl HasDataLayout) -> (Self, bool) {\n-        let (res, over) = cx.data_layout().overflowing_offset(self.offset.bytes(), i.bytes());\n-        (Pointer::new_with_tag(self.alloc_id, Size::from_bytes(res), self.tag), over)\n-    }\n-\n-    #[inline(always)]\n-    pub fn wrapping_offset(self, i: Size, cx: &impl HasDataLayout) -> Self {\n-        self.overflowing_offset(i, cx).0\n-    }\n-\n-    #[inline]\n-    pub fn signed_offset(self, i: i64, cx: &impl HasDataLayout) -> EvalResult<'tcx, Self> {\n-        Ok(Pointer::new_with_tag(\n-            self.alloc_id,\n-            Size::from_bytes(cx.data_layout().signed_offset(self.offset.bytes(), i)?),\n-            self.tag,\n-        ))\n-    }\n-\n-    #[inline]\n-    pub fn overflowing_signed_offset(self, i: i128, cx: &impl HasDataLayout) -> (Self, bool) {\n-        let (res, over) = cx.data_layout().overflowing_signed_offset(self.offset.bytes(), i);\n-        (Pointer::new_with_tag(self.alloc_id, Size::from_bytes(res), self.tag), over)\n-    }\n-\n-    #[inline(always)]\n-    pub fn wrapping_signed_offset(self, i: i64, cx: &impl HasDataLayout) -> Self {\n-        self.overflowing_signed_offset(i128::from(i), cx).0\n-    }\n-\n-    #[inline(always)]\n-    pub fn erase_tag(self) -> Pointer {\n-        Pointer { alloc_id: self.alloc_id, offset: self.offset, tag: () }\n-    }\n-}\n-\n-\n #[derive(Copy, Clone, Eq, Hash, Ord, PartialEq, PartialOrd, Debug)]\n pub struct AllocId(pub u64);\n \n@@ -528,91 +387,6 @@ impl<'tcx, M: fmt::Debug + Eq + Hash + Clone> AllocMap<'tcx, M> {\n     }\n }\n \n-#[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n-pub struct Allocation<Tag=(),Extra=()> {\n-    /// The actual bytes of the allocation.\n-    /// Note that the bytes of a pointer represent the offset of the pointer\n-    pub bytes: Vec<u8>,\n-    /// Maps from byte addresses to extra data for each pointer.\n-    /// Only the first byte of a pointer is inserted into the map; i.e.,\n-    /// every entry in this map applies to `pointer_size` consecutive bytes starting\n-    /// at the given offset.\n-    pub relocations: Relocations<Tag>,\n-    /// Denotes undefined memory. Reading from undefined memory is forbidden in miri\n-    pub undef_mask: UndefMask,\n-    /// The alignment of the allocation to detect unaligned reads.\n-    pub align: Align,\n-    /// Whether the allocation is mutable.\n-    /// Also used by codegen to determine if a static should be put into mutable memory,\n-    /// which happens for `static mut` and `static` with interior mutability.\n-    pub mutability: Mutability,\n-    /// Extra state for the machine.\n-    pub extra: Extra,\n-}\n-\n-impl<Tag, Extra: Default> Allocation<Tag, Extra> {\n-    /// Creates a read-only allocation initialized by the given bytes\n-    pub fn from_bytes(slice: &[u8], align: Align) -> Self {\n-        let mut undef_mask = UndefMask::new(Size::ZERO);\n-        undef_mask.grow(Size::from_bytes(slice.len() as u64), true);\n-        Self {\n-            bytes: slice.to_owned(),\n-            relocations: Relocations::new(),\n-            undef_mask,\n-            align,\n-            mutability: Mutability::Immutable,\n-            extra: Extra::default(),\n-        }\n-    }\n-\n-    pub fn from_byte_aligned_bytes(slice: &[u8]) -> Self {\n-        Allocation::from_bytes(slice, Align::from_bytes(1, 1).unwrap())\n-    }\n-\n-    pub fn undef(size: Size, align: Align) -> Self {\n-        assert_eq!(size.bytes() as usize as u64, size.bytes());\n-        Allocation {\n-            bytes: vec![0; size.bytes() as usize],\n-            relocations: Relocations::new(),\n-            undef_mask: UndefMask::new(size),\n-            align,\n-            mutability: Mutability::Mutable,\n-            extra: Extra::default(),\n-        }\n-    }\n-}\n-\n-impl<'tcx> ::serialize::UseSpecializedDecodable for &'tcx Allocation {}\n-\n-#[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, RustcEncodable, RustcDecodable)]\n-pub struct Relocations<Tag=(), Id=AllocId>(SortedMap<Size, (Tag, Id)>);\n-\n-impl<Tag, Id> Relocations<Tag, Id> {\n-    pub fn new() -> Self {\n-        Relocations(SortedMap::new())\n-    }\n-\n-    // The caller must guarantee that the given relocations are already sorted\n-    // by address and contain no duplicates.\n-    pub fn from_presorted(r: Vec<(Size, (Tag, Id))>) -> Self {\n-        Relocations(SortedMap::from_presorted_elements(r))\n-    }\n-}\n-\n-impl<Tag> Deref for Relocations<Tag> {\n-    type Target = SortedMap<Size, (Tag, AllocId)>;\n-\n-    fn deref(&self) -> &Self::Target {\n-        &self.0\n-    }\n-}\n-\n-impl<Tag> DerefMut for Relocations<Tag> {\n-    fn deref_mut(&mut self) -> &mut Self::Target {\n-        &mut self.0\n-    }\n-}\n-\n ////////////////////////////////////////////////////////////////////////////////\n // Methods to access integers in the target endianness\n ////////////////////////////////////////////////////////////////////////////////\n@@ -655,103 +429,3 @@ pub fn truncate(value: u128, size: Size) -> u128 {\n     // truncate (shift left to drop out leftover values, shift right to fill with zeroes)\n     (value << shift) >> shift\n }\n-\n-////////////////////////////////////////////////////////////////////////////////\n-// Undefined byte tracking\n-////////////////////////////////////////////////////////////////////////////////\n-\n-type Block = u64;\n-const BLOCK_SIZE: u64 = 64;\n-\n-#[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n-pub struct UndefMask {\n-    blocks: Vec<Block>,\n-    len: Size,\n-}\n-\n-impl_stable_hash_for!(struct mir::interpret::UndefMask{blocks, len});\n-\n-impl UndefMask {\n-    pub fn new(size: Size) -> Self {\n-        let mut m = UndefMask {\n-            blocks: vec![],\n-            len: Size::ZERO,\n-        };\n-        m.grow(size, false);\n-        m\n-    }\n-\n-    /// Check whether the range `start..end` (end-exclusive) is entirely defined.\n-    ///\n-    /// Returns `Ok(())` if it's defined. Otherwise returns the index of the byte\n-    /// at which the first undefined access begins.\n-    #[inline]\n-    pub fn is_range_defined(&self, start: Size, end: Size) -> Result<(), Size> {\n-        if end > self.len {\n-            return Err(self.len);\n-        }\n-\n-        let idx = (start.bytes()..end.bytes())\n-            .map(|i| Size::from_bytes(i))\n-            .find(|&i| !self.get(i));\n-\n-        match idx {\n-            Some(idx) => Err(idx),\n-            None => Ok(())\n-        }\n-    }\n-\n-    pub fn set_range(&mut self, start: Size, end: Size, new_state: bool) {\n-        let len = self.len;\n-        if end > len {\n-            self.grow(end - len, new_state);\n-        }\n-        self.set_range_inbounds(start, end, new_state);\n-    }\n-\n-    pub fn set_range_inbounds(&mut self, start: Size, end: Size, new_state: bool) {\n-        for i in start.bytes()..end.bytes() {\n-            self.set(Size::from_bytes(i), new_state);\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn get(&self, i: Size) -> bool {\n-        let (block, bit) = bit_index(i);\n-        (self.blocks[block] & 1 << bit) != 0\n-    }\n-\n-    #[inline]\n-    pub fn set(&mut self, i: Size, new_state: bool) {\n-        let (block, bit) = bit_index(i);\n-        if new_state {\n-            self.blocks[block] |= 1 << bit;\n-        } else {\n-            self.blocks[block] &= !(1 << bit);\n-        }\n-    }\n-\n-    pub fn grow(&mut self, amount: Size, new_state: bool) {\n-        let unused_trailing_bits = self.blocks.len() as u64 * BLOCK_SIZE - self.len.bytes();\n-        if amount.bytes() > unused_trailing_bits {\n-            let additional_blocks = amount.bytes() / BLOCK_SIZE + 1;\n-            assert_eq!(additional_blocks as usize as u64, additional_blocks);\n-            self.blocks.extend(\n-                iter::repeat(0).take(additional_blocks as usize),\n-            );\n-        }\n-        let start = self.len;\n-        self.len += amount;\n-        self.set_range_inbounds(start, start + amount, new_state);\n-    }\n-}\n-\n-#[inline]\n-fn bit_index(bits: Size) -> (usize, usize) {\n-    let bits = bits.bytes();\n-    let a = bits / BLOCK_SIZE;\n-    let b = bits % BLOCK_SIZE;\n-    assert_eq!(a as usize as u64, a);\n-    assert_eq!(b as usize as u64, b);\n-    (a as usize, b as usize)\n-}"}, {"sha": "969f2c0e8376a959530124a0c4ee577d775f7266", "filename": "src/librustc/mir/interpret/pointer.rs", "status": "added", "additions": 151, "deletions": 0, "changes": 151, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc%2Fmir%2Finterpret%2Fpointer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc%2Fmir%2Finterpret%2Fpointer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fpointer.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -0,0 +1,151 @@\n+use mir;\n+use ty::layout::{self, HasDataLayout, Size};\n+\n+use super::{\n+    AllocId, EvalResult,\n+};\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Pointer arithmetic\n+////////////////////////////////////////////////////////////////////////////////\n+\n+pub trait PointerArithmetic: layout::HasDataLayout {\n+    // These are not supposed to be overridden.\n+\n+    #[inline(always)]\n+    fn pointer_size(&self) -> Size {\n+        self.data_layout().pointer_size\n+    }\n+\n+    //// Trunace the given value to the pointer size; also return whether there was an overflow\n+    #[inline]\n+    fn truncate_to_ptr(&self, val: u128) -> (u64, bool) {\n+        let max_ptr_plus_1 = 1u128 << self.pointer_size().bits();\n+        ((val % max_ptr_plus_1) as u64, val >= max_ptr_plus_1)\n+    }\n+\n+    #[inline]\n+    fn offset<'tcx>(&self, val: u64, i: u64) -> EvalResult<'tcx, u64> {\n+        let (res, over) = self.overflowing_offset(val, i);\n+        if over { err!(Overflow(mir::BinOp::Add)) } else { Ok(res) }\n+    }\n+\n+    #[inline]\n+    fn overflowing_offset(&self, val: u64, i: u64) -> (u64, bool) {\n+        let (res, over1) = val.overflowing_add(i);\n+        let (res, over2) = self.truncate_to_ptr(u128::from(res));\n+        (res, over1 || over2)\n+    }\n+\n+    #[inline]\n+    fn signed_offset<'tcx>(&self, val: u64, i: i64) -> EvalResult<'tcx, u64> {\n+        let (res, over) = self.overflowing_signed_offset(val, i128::from(i));\n+        if over { err!(Overflow(mir::BinOp::Add)) } else { Ok(res) }\n+    }\n+\n+    // Overflow checking only works properly on the range from -u64 to +u64.\n+    #[inline]\n+    fn overflowing_signed_offset(&self, val: u64, i: i128) -> (u64, bool) {\n+        // FIXME: is it possible to over/underflow here?\n+        if i < 0 {\n+            // trickery to ensure that i64::min_value() works fine\n+            // this formula only works for true negative values, it panics for zero!\n+            let n = u64::max_value() - (i as u64) + 1;\n+            val.overflowing_sub(n)\n+        } else {\n+            self.overflowing_offset(val, i as u64)\n+        }\n+    }\n+}\n+\n+impl<T: layout::HasDataLayout> PointerArithmetic for T {}\n+\n+\n+/// Pointer is generic over the type that represents a reference to Allocations,\n+/// thus making it possible for the most convenient representation to be used in\n+/// each context.\n+///\n+/// Defaults to the index based and loosely coupled AllocId.\n+///\n+/// Pointer is also generic over the `Tag` associated with each pointer,\n+/// which is used to do provenance tracking during execution.\n+#[derive(Copy, Clone, Debug, Eq, PartialEq, Ord, PartialOrd, RustcEncodable, RustcDecodable, Hash)]\n+pub struct Pointer<Tag=(),Id=AllocId> {\n+    pub alloc_id: Id,\n+    pub offset: Size,\n+    pub tag: Tag,\n+}\n+\n+/// Produces a `Pointer` which points to the beginning of the Allocation\n+impl From<AllocId> for Pointer {\n+    #[inline(always)]\n+    fn from(alloc_id: AllocId) -> Self {\n+        Pointer::new(alloc_id, Size::ZERO)\n+    }\n+}\n+\n+impl<'tcx> Pointer<()> {\n+    #[inline(always)]\n+    pub fn new(alloc_id: AllocId, offset: Size) -> Self {\n+        Pointer { alloc_id, offset, tag: () }\n+    }\n+\n+    #[inline(always)]\n+    pub fn with_default_tag<Tag>(self) -> Pointer<Tag>\n+        where Tag: Default\n+    {\n+        Pointer::new_with_tag(self.alloc_id, self.offset, Default::default())\n+    }\n+}\n+\n+impl<'tcx, Tag> Pointer<Tag> {\n+    #[inline(always)]\n+    pub fn new_with_tag(alloc_id: AllocId, offset: Size, tag: Tag) -> Self {\n+        Pointer { alloc_id, offset, tag }\n+    }\n+\n+    #[inline]\n+    pub fn offset(self, i: Size, cx: &impl HasDataLayout) -> EvalResult<'tcx, Self> {\n+        Ok(Pointer::new_with_tag(\n+            self.alloc_id,\n+            Size::from_bytes(cx.data_layout().offset(self.offset.bytes(), i.bytes())?),\n+            self.tag\n+        ))\n+    }\n+\n+    #[inline]\n+    pub fn overflowing_offset(self, i: Size, cx: &impl HasDataLayout) -> (Self, bool) {\n+        let (res, over) = cx.data_layout().overflowing_offset(self.offset.bytes(), i.bytes());\n+        (Pointer::new_with_tag(self.alloc_id, Size::from_bytes(res), self.tag), over)\n+    }\n+\n+    #[inline(always)]\n+    pub fn wrapping_offset(self, i: Size, cx: &impl HasDataLayout) -> Self {\n+        self.overflowing_offset(i, cx).0\n+    }\n+\n+    #[inline]\n+    pub fn signed_offset(self, i: i64, cx: &impl HasDataLayout) -> EvalResult<'tcx, Self> {\n+        Ok(Pointer::new_with_tag(\n+            self.alloc_id,\n+            Size::from_bytes(cx.data_layout().signed_offset(self.offset.bytes(), i)?),\n+            self.tag,\n+        ))\n+    }\n+\n+    #[inline]\n+    pub fn overflowing_signed_offset(self, i: i128, cx: &impl HasDataLayout) -> (Self, bool) {\n+        let (res, over) = cx.data_layout().overflowing_signed_offset(self.offset.bytes(), i);\n+        (Pointer::new_with_tag(self.alloc_id, Size::from_bytes(res), self.tag), over)\n+    }\n+\n+    #[inline(always)]\n+    pub fn wrapping_signed_offset(self, i: i64, cx: &impl HasDataLayout) -> Self {\n+        self.overflowing_signed_offset(i128::from(i), cx).0\n+    }\n+\n+    #[inline(always)]\n+    pub fn erase_tag(self) -> Pointer {\n+        Pointer { alloc_id: self.alloc_id, offset: self.offset, tag: () }\n+    }\n+}"}, {"sha": "47c42c9431a210325e7e8ab9130268c22411ca83", "filename": "src/librustc/mir/interpret/value.rs", "status": "modified", "additions": 128, "deletions": 0, "changes": 128, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -392,3 +392,131 @@ impl<Tag> From<Pointer<Tag>> for Scalar<Tag> {\n         Scalar::Ptr(ptr)\n     }\n }\n+\n+#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, RustcEncodable, RustcDecodable, Hash)]\n+pub enum ScalarMaybeUndef<Tag=(), Id=AllocId> {\n+    Scalar(Scalar<Tag, Id>),\n+    Undef,\n+}\n+\n+impl<Tag> From<Scalar<Tag>> for ScalarMaybeUndef<Tag> {\n+    #[inline(always)]\n+    fn from(s: Scalar<Tag>) -> Self {\n+        ScalarMaybeUndef::Scalar(s)\n+    }\n+}\n+\n+impl<Tag> fmt::Display for ScalarMaybeUndef<Tag> {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        match self {\n+            ScalarMaybeUndef::Undef => write!(f, \"uninitialized bytes\"),\n+            ScalarMaybeUndef::Scalar(s) => write!(f, \"{}\", s),\n+        }\n+    }\n+}\n+\n+impl<'tcx> ScalarMaybeUndef<()> {\n+    #[inline]\n+    pub fn with_default_tag<Tag>(self) -> ScalarMaybeUndef<Tag>\n+        where Tag: Default\n+    {\n+        match self {\n+            ScalarMaybeUndef::Scalar(s) => ScalarMaybeUndef::Scalar(s.with_default_tag()),\n+            ScalarMaybeUndef::Undef => ScalarMaybeUndef::Undef,\n+        }\n+    }\n+}\n+\n+impl<'tcx, Tag> ScalarMaybeUndef<Tag> {\n+    #[inline]\n+    pub fn erase_tag(self) -> ScalarMaybeUndef\n+    {\n+        match self {\n+            ScalarMaybeUndef::Scalar(s) => ScalarMaybeUndef::Scalar(s.erase_tag()),\n+            ScalarMaybeUndef::Undef => ScalarMaybeUndef::Undef,\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn not_undef(self) -> EvalResult<'static, Scalar<Tag>> {\n+        match self {\n+            ScalarMaybeUndef::Scalar(scalar) => Ok(scalar),\n+            ScalarMaybeUndef::Undef => err!(ReadUndefBytes(Size::from_bytes(0))),\n+        }\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_ptr(self) -> EvalResult<'tcx, Pointer<Tag>> {\n+        self.not_undef()?.to_ptr()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_bits(self, target_size: Size) -> EvalResult<'tcx, u128> {\n+        self.not_undef()?.to_bits(target_size)\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_bool(self) -> EvalResult<'tcx, bool> {\n+        self.not_undef()?.to_bool()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_char(self) -> EvalResult<'tcx, char> {\n+        self.not_undef()?.to_char()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_f32(self) -> EvalResult<'tcx, f32> {\n+        self.not_undef()?.to_f32()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_f64(self) -> EvalResult<'tcx, f64> {\n+        self.not_undef()?.to_f64()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_u8(self) -> EvalResult<'tcx, u8> {\n+        self.not_undef()?.to_u8()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_u32(self) -> EvalResult<'tcx, u32> {\n+        self.not_undef()?.to_u32()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_u64(self) -> EvalResult<'tcx, u64> {\n+        self.not_undef()?.to_u64()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_usize(self, cx: &impl HasDataLayout) -> EvalResult<'tcx, u64> {\n+        self.not_undef()?.to_usize(cx)\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_i8(self) -> EvalResult<'tcx, i8> {\n+        self.not_undef()?.to_i8()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_i32(self) -> EvalResult<'tcx, i32> {\n+        self.not_undef()?.to_i32()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_i64(self) -> EvalResult<'tcx, i64> {\n+        self.not_undef()?.to_i64()\n+    }\n+\n+    #[inline(always)]\n+    pub fn to_isize(self, cx: &impl HasDataLayout) -> EvalResult<'tcx, i64> {\n+        self.not_undef()?.to_isize(cx)\n+    }\n+}\n+\n+impl_stable_hash_for!(enum ::mir::interpret::ScalarMaybeUndef {\n+    Scalar(v),\n+    Undef\n+});"}, {"sha": "047996777ea968907592791c4c3701049ab8670a", "filename": "src/librustc_mir/interpret/machine.rs", "status": "modified", "additions": 2, "deletions": 22, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fmachine.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -20,7 +20,7 @@ use rustc::mir;\n use rustc::ty::{self, layout::{Size, TyLayout}, query::TyCtxtAt};\n \n use super::{\n-    Allocation, AllocId, EvalResult, Scalar,\n+    Allocation, AllocId, EvalResult, Scalar, AllocationExtra,\n     EvalContext, PlaceTy, MPlaceTy, OpTy, Pointer, MemoryKind,\n };\n \n@@ -78,7 +78,7 @@ pub trait Machine<'a, 'mir, 'tcx>: Sized {\n     type PointerTag: ::std::fmt::Debug + Default + Copy + Eq + Hash + 'static;\n \n     /// Extra data stored in every allocation.\n-    type AllocExtra: ::std::fmt::Debug + Default + Clone;\n+    type AllocExtra: AllocationExtra<Self::PointerTag>;\n \n     /// Memory's allocation map\n     type MemoryMap:\n@@ -174,26 +174,6 @@ pub trait Machine<'a, 'mir, 'tcx>: Sized {\n         dest: PlaceTy<'tcx, Self::PointerTag>,\n     ) -> EvalResult<'tcx>;\n \n-    /// Hook for performing extra checks on a memory read access.\n-    #[inline]\n-    fn memory_read(\n-        _alloc: &Allocation<Self::PointerTag, Self::AllocExtra>,\n-        _ptr: Pointer<Self::PointerTag>,\n-        _size: Size,\n-    ) -> EvalResult<'tcx> {\n-        Ok(())\n-    }\n-\n-    /// Hook for performing extra checks on a memory write access.\n-    #[inline]\n-    fn memory_written(\n-        _alloc: &mut Allocation<Self::PointerTag, Self::AllocExtra>,\n-        _ptr: Pointer<Self::PointerTag>,\n-        _size: Size,\n-    ) -> EvalResult<'tcx> {\n-        Ok(())\n-    }\n-\n     /// Hook for performing extra checks when memory gets deallocated.\n     #[inline]\n     fn memory_deallocated("}, {"sha": "10bc984a447a3c17d74a12bd7eaf4ce927625196", "filename": "src/librustc_mir/interpret/memory.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -28,7 +28,7 @@ use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n use syntax::ast::Mutability;\n \n use super::{\n-    Pointer, AllocId, Allocation, ConstValue, GlobalId,\n+    Pointer, AllocId, Allocation, ConstValue, GlobalId, AllocationExtra,\n     EvalResult, Scalar, EvalErrorKind, AllocType, PointerArithmetic,\n     Machine, AllocMap, MayLeak, ScalarMaybeUndef, ErrorHandled,\n };\n@@ -637,7 +637,7 @@ impl<'a, 'mir, 'tcx, M: Machine<'a, 'mir, 'tcx>> Memory<'a, 'mir, 'tcx, M> {\n         }\n \n         let alloc = self.get(ptr.alloc_id)?;\n-        M::memory_read(alloc, ptr, size)?;\n+        AllocationExtra::memory_read(alloc, ptr, size)?;\n \n         assert_eq!(ptr.offset.bytes() as usize as u64, ptr.offset.bytes());\n         assert_eq!(size.bytes() as usize as u64, size.bytes());\n@@ -683,7 +683,7 @@ impl<'a, 'mir, 'tcx, M: Machine<'a, 'mir, 'tcx>> Memory<'a, 'mir, 'tcx, M> {\n         self.clear_relocations(ptr, size)?;\n \n         let alloc = self.get_mut(ptr.alloc_id)?;\n-        M::memory_written(alloc, ptr, size)?;\n+        AllocationExtra::memory_written(alloc, ptr, size)?;\n \n         assert_eq!(ptr.offset.bytes() as usize as u64, ptr.offset.bytes());\n         assert_eq!(size.bytes() as usize as u64, size.bytes());"}, {"sha": "d43ec0bd349abd301dac2c96f8c4971eebc8d290", "filename": "src/librustc_mir/interpret/operand.rs", "status": "modified", "additions": 1, "deletions": 125, "changes": 126, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Foperand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Foperand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Foperand.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -12,7 +12,6 @@\n //! All high-level functions to read from memory work on operands as sources.\n \n use std::convert::TryInto;\n-use std::fmt;\n \n use rustc::{mir, ty};\n use rustc::ty::layout::{self, Size, LayoutOf, TyLayout, HasDataLayout, IntegerExt};\n@@ -23,130 +22,7 @@ use rustc::mir::interpret::{\n     EvalResult, EvalErrorKind\n };\n use super::{EvalContext, Machine, MemPlace, MPlaceTy, MemoryKind};\n-\n-#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, RustcEncodable, RustcDecodable, Hash)]\n-pub enum ScalarMaybeUndef<Tag=(), Id=AllocId> {\n-    Scalar(Scalar<Tag, Id>),\n-    Undef,\n-}\n-\n-impl<Tag> From<Scalar<Tag>> for ScalarMaybeUndef<Tag> {\n-    #[inline(always)]\n-    fn from(s: Scalar<Tag>) -> Self {\n-        ScalarMaybeUndef::Scalar(s)\n-    }\n-}\n-\n-impl<Tag> fmt::Display for ScalarMaybeUndef<Tag> {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        match self {\n-            ScalarMaybeUndef::Undef => write!(f, \"uninitialized bytes\"),\n-            ScalarMaybeUndef::Scalar(s) => write!(f, \"{}\", s),\n-        }\n-    }\n-}\n-\n-impl<'tcx> ScalarMaybeUndef<()> {\n-    #[inline]\n-    pub fn with_default_tag<Tag>(self) -> ScalarMaybeUndef<Tag>\n-        where Tag: Default\n-    {\n-        match self {\n-            ScalarMaybeUndef::Scalar(s) => ScalarMaybeUndef::Scalar(s.with_default_tag()),\n-            ScalarMaybeUndef::Undef => ScalarMaybeUndef::Undef,\n-        }\n-    }\n-}\n-\n-impl<'tcx, Tag> ScalarMaybeUndef<Tag> {\n-    #[inline]\n-    pub fn erase_tag(self) -> ScalarMaybeUndef\n-    {\n-        match self {\n-            ScalarMaybeUndef::Scalar(s) => ScalarMaybeUndef::Scalar(s.erase_tag()),\n-            ScalarMaybeUndef::Undef => ScalarMaybeUndef::Undef,\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn not_undef(self) -> EvalResult<'static, Scalar<Tag>> {\n-        match self {\n-            ScalarMaybeUndef::Scalar(scalar) => Ok(scalar),\n-            ScalarMaybeUndef::Undef => err!(ReadUndefBytes(Size::from_bytes(0))),\n-        }\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_ptr(self) -> EvalResult<'tcx, Pointer<Tag>> {\n-        self.not_undef()?.to_ptr()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_bits(self, target_size: Size) -> EvalResult<'tcx, u128> {\n-        self.not_undef()?.to_bits(target_size)\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_bool(self) -> EvalResult<'tcx, bool> {\n-        self.not_undef()?.to_bool()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_char(self) -> EvalResult<'tcx, char> {\n-        self.not_undef()?.to_char()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_f32(self) -> EvalResult<'tcx, f32> {\n-        self.not_undef()?.to_f32()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_f64(self) -> EvalResult<'tcx, f64> {\n-        self.not_undef()?.to_f64()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_u8(self) -> EvalResult<'tcx, u8> {\n-        self.not_undef()?.to_u8()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_u32(self) -> EvalResult<'tcx, u32> {\n-        self.not_undef()?.to_u32()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_u64(self) -> EvalResult<'tcx, u64> {\n-        self.not_undef()?.to_u64()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_usize(self, cx: &impl HasDataLayout) -> EvalResult<'tcx, u64> {\n-        self.not_undef()?.to_usize(cx)\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_i8(self) -> EvalResult<'tcx, i8> {\n-        self.not_undef()?.to_i8()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_i32(self) -> EvalResult<'tcx, i32> {\n-        self.not_undef()?.to_i32()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_i64(self) -> EvalResult<'tcx, i64> {\n-        self.not_undef()?.to_i64()\n-    }\n-\n-    #[inline(always)]\n-    pub fn to_isize(self, cx: &impl HasDataLayout) -> EvalResult<'tcx, i64> {\n-        self.not_undef()?.to_isize(cx)\n-    }\n-}\n-\n+pub use rustc::mir::interpret::ScalarMaybeUndef;\n \n /// A `Value` represents a single immediate self-contained Rust value.\n ///"}, {"sha": "6f8bbf3c4a97de0475f2807c7b018a4c748b468d", "filename": "src/librustc_mir/interpret/place.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fplace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fplace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fplace.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -24,7 +24,7 @@ use rustc::mir::interpret::{\n     GlobalId, AllocId, Allocation, Scalar, EvalResult, Pointer, PointerArithmetic\n };\n use super::{\n-    EvalContext, Machine, AllocMap,\n+    EvalContext, Machine, AllocMap, AllocationExtra,\n     Immediate, ImmTy, ScalarMaybeUndef, Operand, OpTy, MemoryKind\n };\n \n@@ -264,6 +264,7 @@ where\n     Tag: ::std::fmt::Debug+Default+Copy+Eq+Hash+'static,\n     M: Machine<'a, 'mir, 'tcx, PointerTag=Tag>,\n     M::MemoryMap: AllocMap<AllocId, (MemoryKind<M::MemoryKinds>, Allocation<Tag, M::AllocExtra>)>,\n+    M::AllocExtra: AllocationExtra<Tag>,\n {\n     /// Take a value, which represents a (thin or fat) reference, and make it a place.\n     /// Alignment is just based on the type.  This is the inverse of `create_ref`."}, {"sha": "4b63335ad964cba9480d1de819e583631ffa35bb", "filename": "src/librustc_mir/interpret/snapshot.rs", "status": "modified", "additions": 0, "deletions": 5, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fsnapshot.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fsnapshot.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fsnapshot.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -195,11 +195,6 @@ impl<'a, Ctx> Snapshot<'a, Ctx> for Scalar\n     }\n }\n \n-impl_stable_hash_for!(enum ::interpret::ScalarMaybeUndef {\n-    Scalar(v),\n-    Undef\n-});\n-\n impl_snapshot_for!(enum ScalarMaybeUndef {\n     Scalar(s),\n     Undef,"}, {"sha": "84aa5b6756660ceb4f224c37324e1ec6fe7d3668", "filename": "src/librustc_mir/interpret/validity.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fvalidity.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a88613c86901083dd9f87c43f41d6c0f84f88dee/src%2Flibrustc_mir%2Finterpret%2Fvalidity.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fvalidity.rs?ref=a88613c86901083dd9f87c43f41d6c0f84f88dee", "patch": "@@ -17,7 +17,7 @@ use rustc::ty::layout::{self, Size, Align, TyLayout, LayoutOf};\n use rustc::ty;\n use rustc_data_structures::fx::FxHashSet;\n use rustc::mir::interpret::{\n-    Scalar, AllocType, EvalResult, EvalErrorKind\n+    Scalar, AllocType, EvalResult, EvalErrorKind,\n };\n \n use super::{"}]}