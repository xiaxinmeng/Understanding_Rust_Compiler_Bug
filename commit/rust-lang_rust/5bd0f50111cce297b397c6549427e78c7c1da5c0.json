{"sha": "5bd0f50111cce297b397c6549427e78c7c1da5c0", "node_id": "C_kwDOAAsO6NoAKDViZDBmNTAxMTFjY2UyOTdiMzk3YzY1NDk0MjdlNzhjN2MxZGE1YzA", "commit": {"author": {"name": "hamidreza kalbasi", "email": "hamidrezakalbasi@protonmail.com", "date": "2021-09-29T12:41:58Z"}, "committer": {"name": "hamidreza kalbasi", "email": "hamidrezakalbasi@protonmail.com", "date": "2021-09-29T12:55:10Z"}, "message": "remove glob import and cancellables", "tree": {"sha": "d9a748709cda3c5243880048f17a21fdc6c581a1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d9a748709cda3c5243880048f17a21fdc6c581a1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5bd0f50111cce297b397c6549427e78c7c1da5c0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5bd0f50111cce297b397c6549427e78c7c1da5c0", "html_url": "https://github.com/rust-lang/rust/commit/5bd0f50111cce297b397c6549427e78c7c1da5c0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5bd0f50111cce297b397c6549427e78c7c1da5c0/comments", "author": {"login": "HKalbasi", "id": 45197576, "node_id": "MDQ6VXNlcjQ1MTk3NTc2", "avatar_url": "https://avatars.githubusercontent.com/u/45197576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HKalbasi", "html_url": "https://github.com/HKalbasi", "followers_url": "https://api.github.com/users/HKalbasi/followers", "following_url": "https://api.github.com/users/HKalbasi/following{/other_user}", "gists_url": "https://api.github.com/users/HKalbasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HKalbasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HKalbasi/subscriptions", "organizations_url": "https://api.github.com/users/HKalbasi/orgs", "repos_url": "https://api.github.com/users/HKalbasi/repos", "events_url": "https://api.github.com/users/HKalbasi/events{/privacy}", "received_events_url": "https://api.github.com/users/HKalbasi/received_events", "type": "User", "site_admin": false}, "committer": {"login": "HKalbasi", "id": 45197576, "node_id": "MDQ6VXNlcjQ1MTk3NTc2", "avatar_url": "https://avatars.githubusercontent.com/u/45197576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HKalbasi", "html_url": "https://github.com/HKalbasi", "followers_url": "https://api.github.com/users/HKalbasi/followers", "following_url": "https://api.github.com/users/HKalbasi/following{/other_user}", "gists_url": "https://api.github.com/users/HKalbasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HKalbasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HKalbasi/subscriptions", "organizations_url": "https://api.github.com/users/HKalbasi/orgs", "repos_url": "https://api.github.com/users/HKalbasi/repos", "events_url": "https://api.github.com/users/HKalbasi/events{/privacy}", "received_events_url": "https://api.github.com/users/HKalbasi/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7377120fee84743ad980ed87458bb08dd97f3101", "url": "https://api.github.com/repos/rust-lang/rust/commits/7377120fee84743ad980ed87458bb08dd97f3101", "html_url": "https://github.com/rust-lang/rust/commit/7377120fee84743ad980ed87458bb08dd97f3101"}], "stats": {"total": 147, "additions": 75, "deletions": 72}, "files": [{"sha": "aa62e2eae5a3e594904d1cf8f7fd3c5e159fb0ce", "filename": "crates/ide/src/static_index.rs", "status": "modified", "additions": 8, "deletions": 13, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/5bd0f50111cce297b397c6549427e78c7c1da5c0/crates%2Fide%2Fsrc%2Fstatic_index.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5bd0f50111cce297b397c6549427e78c7c1da5c0/crates%2Fide%2Fsrc%2Fstatic_index.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide%2Fsrc%2Fstatic_index.rs?ref=5bd0f50111cce297b397c6549427e78c7c1da5c0", "patch": "@@ -14,7 +14,7 @@ use syntax::{SyntaxToken, TextRange};\n \n use crate::display::TryToNav;\n use crate::hover::hover_for_definition;\n-use crate::{Analysis, Cancellable, Fold, HoverConfig, HoverDocFormat, HoverResult};\n+use crate::{Analysis, Fold, HoverConfig, HoverDocFormat, HoverResult};\n \n /// A static representation of fully analyzed source code.\n ///\n@@ -84,8 +84,8 @@ fn all_modules(db: &dyn HirDatabase) -> Vec<Module> {\n }\n \n impl StaticIndex<'_> {\n-    fn add_file(&mut self, file_id: FileId) -> Cancellable<()> {\n-        let folds = self.analysis.folding_ranges(file_id)?;\n+    fn add_file(&mut self, file_id: FileId) {\n+        let folds = self.analysis.folding_ranges(file_id).unwrap();\n         // hovers\n         let sema = hir::Semantics::new(self.db);\n         let tokens_or_nodes = sema.parse(file_id).syntax().clone();\n@@ -133,13 +133,9 @@ impl StaticIndex<'_> {\n             result.tokens.push((range, id));\n         }\n         self.files.push(result);\n-        Ok(())\n     }\n \n-    pub fn compute<'a>(\n-        db: &'a RootDatabase,\n-        analysis: &'a Analysis,\n-    ) -> Cancellable<StaticIndex<'a>> {\n+    pub fn compute<'a>(db: &'a RootDatabase, analysis: &'a Analysis) -> StaticIndex<'a> {\n         let work = all_modules(db).into_iter().filter(|module| {\n             let file_id = module.definition_source(db).file_id.original_file(db);\n             let source_root = db.file_source_root(file_id);\n@@ -159,12 +155,11 @@ impl StaticIndex<'_> {\n             if visited_files.contains(&file_id) {\n                 continue;\n             }\n-            this.add_file(file_id)?;\n+            this.add_file(file_id);\n             // mark the file\n             visited_files.insert(file_id);\n         }\n-        //eprintln!(\"{:#?}\", token_map);\n-        Ok(this)\n+        this\n     }\n }\n \n@@ -188,7 +183,7 @@ mod tests {\n \n     fn check_all_ranges(ra_fixture: &str) {\n         let (analysis, ranges) = fixture::annotations_without_marker(ra_fixture);\n-        let s = StaticIndex::compute(&*analysis.db, &analysis).unwrap();\n+        let s = StaticIndex::compute(&*analysis.db, &analysis);\n         let mut range_set: HashSet<_> = ranges.iter().map(|x| x.0).collect();\n         for f in s.files {\n             for (range, _) in f.tokens {\n@@ -206,7 +201,7 @@ mod tests {\n \n     fn check_definitions(ra_fixture: &str) {\n         let (analysis, ranges) = fixture::annotations_without_marker(ra_fixture);\n-        let s = StaticIndex::compute(&*analysis.db, &analysis).unwrap();\n+        let s = StaticIndex::compute(&*analysis.db, &analysis);\n         let mut range_set: HashSet<_> = ranges.iter().map(|x| x.0).collect();\n         for (_, t) in s.tokens.iter() {\n             if let Some(x) = t.definition {"}, {"sha": "a2354431460fb2676539de67f78c2e4d43123151", "filename": "crates/rust-analyzer/src/cli/lsif.rs", "status": "modified", "additions": 67, "deletions": 59, "changes": 126, "blob_url": "https://github.com/rust-lang/rust/blob/5bd0f50111cce297b397c6549427e78c7c1da5c0/crates%2Frust-analyzer%2Fsrc%2Fcli%2Flsif.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5bd0f50111cce297b397c6549427e78c7c1da5c0/crates%2Frust-analyzer%2Fsrc%2Fcli%2Flsif.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fcli%2Flsif.rs?ref=5bd0f50111cce297b397c6549427e78c7c1da5c0", "patch": "@@ -1,17 +1,17 @@\n-//! Lsif generator\n+//! LSIF (language server index format) generator\n \n use std::collections::HashMap;\n use std::env;\n use std::time::Instant;\n \n use ide::{\n-    Analysis, Cancellable, FileId, FileRange, RootDatabase, StaticIndex, StaticIndexedFile,\n-    TokenId, TokenStaticData,\n+    Analysis, FileId, FileRange, RootDatabase, StaticIndex, StaticIndexedFile, TokenId,\n+    TokenStaticData,\n };\n use ide_db::LineIndexDatabase;\n \n use ide_db::base_db::salsa::{self, ParallelDatabase};\n-use lsp_types::{lsif::*, Hover, HoverContents, NumberOrString};\n+use lsp_types::{self, lsif};\n use project_model::{CargoConfig, ProjectManifest, ProjectWorkspace};\n use vfs::{AbsPathBuf, Vfs};\n \n@@ -44,9 +44,9 @@ struct LsifManager<'a> {\n #[derive(Clone, Copy)]\n struct Id(i32);\n \n-impl From<Id> for NumberOrString {\n+impl From<Id> for lsp_types::NumberOrString {\n     fn from(Id(x): Id) -> Self {\n-        NumberOrString::Number(x)\n+        lsp_types::NumberOrString::Number(x)\n     }\n }\n \n@@ -63,13 +63,21 @@ impl LsifManager<'_> {\n         }\n     }\n \n-    fn add(&mut self, data: Element) -> Id {\n+    fn add(&mut self, data: lsif::Element) -> Id {\n         let id = Id(self.count);\n-        self.emit(&serde_json::to_string(&Entry { id: id.into(), data }).unwrap());\n+        self.emit(&serde_json::to_string(&lsif::Entry { id: id.into(), data }).unwrap());\n         self.count += 1;\n         id\n     }\n \n+    fn add_vertex(&mut self, vertex: lsif::Vertex) -> Id {\n+        self.add(lsif::Element::Vertex(vertex))\n+    }\n+\n+    fn add_edge(&mut self, edge: lsif::Edge) -> Id {\n+        self.add(lsif::Element::Edge(edge))\n+    }\n+\n     // FIXME: support file in addition to stdout here\n     fn emit(&self, data: &str) {\n         println!(\"{}\", data);\n@@ -79,14 +87,14 @@ impl LsifManager<'_> {\n         if let Some(x) = self.token_map.get(&id) {\n             return *x;\n         }\n-        let result_set_id = self.add(Element::Vertex(Vertex::ResultSet(ResultSet { key: None })));\n+        let result_set_id = self.add_vertex(lsif::Vertex::ResultSet(lsif::ResultSet { key: None }));\n         self.token_map.insert(id, result_set_id);\n         result_set_id\n     }\n \n-    fn get_range_id(&mut self, id: FileRange) -> Cancellable<Id> {\n+    fn get_range_id(&mut self, id: FileRange) -> Id {\n         if let Some(x) = self.range_map.get(&id) {\n-            return Ok(*x);\n+            return *x;\n         }\n         let file_id = id.file_id;\n         let doc_id = self.get_file_id(file_id);\n@@ -96,15 +104,15 @@ impl LsifManager<'_> {\n             encoding: OffsetEncoding::Utf16,\n             endings: LineEndings::Unix,\n         };\n-        let range_id = self.add(Element::Vertex(Vertex::Range {\n+        let range_id = self.add_vertex(lsif::Vertex::Range {\n             range: to_proto::range(&line_index, id.range),\n             tag: None,\n-        }));\n-        self.add(Element::Edge(Edge::Contains(EdgeDataMultiIn {\n+        });\n+        self.add_edge(lsif::Edge::Contains(lsif::EdgeDataMultiIn {\n             in_vs: vec![range_id.into()],\n             out_v: doc_id.into(),\n-        })));\n-        Ok(range_id)\n+        }));\n+        range_id\n     }\n \n     fn get_file_id(&mut self, id: FileId) -> Id {\n@@ -113,73 +121,74 @@ impl LsifManager<'_> {\n         }\n         let path = self.vfs.file_path(id);\n         let path = path.as_path().unwrap();\n-        let doc_id = self.add(Element::Vertex(Vertex::Document(Document {\n+        let doc_id = self.add_vertex(lsif::Vertex::Document(lsif::Document {\n             language_id: \"rust\".to_string(),\n             uri: lsp_types::Url::from_file_path(path).unwrap(),\n-        })));\n+        }));\n         self.file_map.insert(id, doc_id);\n         doc_id\n     }\n \n-    fn add_token(&mut self, id: TokenId, token: TokenStaticData) -> Cancellable<()> {\n+    fn add_token(&mut self, id: TokenId, token: TokenStaticData) {\n         let result_set_id = self.get_token_id(id);\n         if let Some(hover) = token.hover {\n-            let hover_id = self.add(Element::Vertex(Vertex::HoverResult {\n-                result: Hover {\n-                    contents: HoverContents::Markup(to_proto::markup_content(hover.markup)),\n+            let hover_id = self.add_vertex(lsif::Vertex::HoverResult {\n+                result: lsp_types::Hover {\n+                    contents: lsp_types::HoverContents::Markup(to_proto::markup_content(\n+                        hover.markup,\n+                    )),\n                     range: None,\n                 },\n-            }));\n-            self.add(Element::Edge(Edge::Hover(EdgeData {\n+            });\n+            self.add_edge(lsif::Edge::Hover(lsif::EdgeData {\n                 in_v: hover_id.into(),\n                 out_v: result_set_id.into(),\n-            })));\n+            }));\n         }\n         if let Some(def) = token.definition {\n-            let result_id = self.add(Element::Vertex(Vertex::DefinitionResult));\n-            let def_vertex = self.get_range_id(def)?;\n-            self.add(Element::Edge(Edge::Item(Item {\n+            let result_id = self.add_vertex(lsif::Vertex::DefinitionResult);\n+            let def_vertex = self.get_range_id(def);\n+            self.add_edge(lsif::Edge::Item(lsif::Item {\n                 document: (*self.file_map.get(&def.file_id).unwrap()).into(),\n                 property: None,\n-                edge_data: EdgeDataMultiIn {\n+                edge_data: lsif::EdgeDataMultiIn {\n                     in_vs: vec![def_vertex.into()],\n                     out_v: result_id.into(),\n                 },\n-            })));\n-            self.add(Element::Edge(Edge::Definition(EdgeData {\n+            }));\n+            self.add_edge(lsif::Edge::Definition(lsif::EdgeData {\n                 in_v: result_id.into(),\n                 out_v: result_set_id.into(),\n-            })));\n+            }));\n         }\n         if !token.references.is_empty() {\n-            let result_id = self.add(Element::Vertex(Vertex::ReferenceResult));\n-            self.add(Element::Edge(Edge::References(EdgeData {\n+            let result_id = self.add_vertex(lsif::Vertex::ReferenceResult);\n+            self.add_edge(lsif::Edge::References(lsif::EdgeData {\n                 in_v: result_id.into(),\n                 out_v: result_set_id.into(),\n-            })));\n+            }));\n             for x in token.references {\n                 let vertex = *self.range_map.get(&x.range).unwrap();\n-                self.add(Element::Edge(Edge::Item(Item {\n+                self.add_edge(lsif::Edge::Item(lsif::Item {\n                     document: (*self.file_map.get(&x.range.file_id).unwrap()).into(),\n                     property: Some(if x.is_definition {\n-                        ItemKind::Definitions\n+                        lsif::ItemKind::Definitions\n                     } else {\n-                        ItemKind::References\n+                        lsif::ItemKind::References\n                     }),\n-                    edge_data: EdgeDataMultiIn {\n+                    edge_data: lsif::EdgeDataMultiIn {\n                         in_vs: vec![vertex.into()],\n                         out_v: result_id.into(),\n                     },\n-                })));\n+                }));\n             }\n         }\n-        Ok(())\n     }\n \n-    fn add_file(&mut self, file: StaticIndexedFile) -> Cancellable<()> {\n+    fn add_file(&mut self, file: StaticIndexedFile) {\n         let StaticIndexedFile { file_id, tokens, folds } = file;\n         let doc_id = self.get_file_id(file_id);\n-        let text = self.analysis.file_text(file_id)?;\n+        let text = self.analysis.file_text(file_id).unwrap();\n         let line_index = self.db.line_index(file_id);\n         let line_index = LineIndex {\n             index: line_index.clone(),\n@@ -190,32 +199,31 @@ impl LsifManager<'_> {\n             .into_iter()\n             .map(|it| to_proto::folding_range(&*text, &line_index, false, it))\n             .collect();\n-        let folding_id = self.add(Element::Vertex(Vertex::FoldingRangeResult { result }));\n-        self.add(Element::Edge(Edge::FoldingRange(EdgeData {\n+        let folding_id = self.add_vertex(lsif::Vertex::FoldingRangeResult { result });\n+        self.add_edge(lsif::Edge::FoldingRange(lsif::EdgeData {\n             in_v: folding_id.into(),\n             out_v: doc_id.into(),\n-        })));\n+        }));\n         let tokens_id = tokens\n             .into_iter()\n             .map(|(range, id)| {\n-                let range_id = self.add(Element::Vertex(Vertex::Range {\n+                let range_id = self.add_vertex(lsif::Vertex::Range {\n                     range: to_proto::range(&line_index, range),\n                     tag: None,\n-                }));\n+                });\n                 self.range_map.insert(FileRange { file_id, range }, range_id);\n                 let result_set_id = self.get_token_id(id);\n-                self.add(Element::Edge(Edge::Next(EdgeData {\n+                self.add_edge(lsif::Edge::Next(lsif::EdgeData {\n                     in_v: result_set_id.into(),\n                     out_v: range_id.into(),\n-                })));\n+                }));\n                 range_id.into()\n             })\n             .collect();\n-        self.add(Element::Edge(Edge::Contains(EdgeDataMultiIn {\n+        self.add_edge(lsif::Edge::Contains(lsif::EdgeDataMultiIn {\n             in_vs: tokens_id,\n             out_v: doc_id.into(),\n-        })));\n-        Ok(())\n+        }));\n     }\n }\n \n@@ -239,20 +247,20 @@ impl flags::Lsif {\n         let db = host.raw_database();\n         let analysis = host.analysis();\n \n-        let si = StaticIndex::compute(db, &analysis)?;\n+        let si = StaticIndex::compute(db, &analysis);\n \n         let mut lsif = LsifManager::new(&analysis, db, &vfs);\n-        lsif.add(Element::Vertex(Vertex::MetaData(MetaData {\n+        lsif.add_vertex(lsif::Vertex::MetaData(lsif::MetaData {\n             version: String::from(\"0.5.0\"),\n             project_root: lsp_types::Url::from_file_path(path).unwrap(),\n-            position_encoding: Encoding::Utf16,\n+            position_encoding: lsif::Encoding::Utf16,\n             tool_info: None,\n-        })));\n+        }));\n         for file in si.files {\n-            lsif.add_file(file)?;\n+            lsif.add_file(file);\n         }\n         for (id, token) in si.tokens.iter() {\n-            lsif.add_token(id, token)?;\n+            lsif.add_token(id, token);\n         }\n         eprintln!(\"Generating LSIF finished in {:?}\", now.elapsed());\n         Ok(())"}]}