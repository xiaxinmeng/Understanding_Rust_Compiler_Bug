{"sha": "d7e73e4b1abe120520d1894b89c0e25469f41e69", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ3ZTczZTRiMWFiZTEyMDUyMGQxODk0Yjg5YzBlMjU0NjlmNDFlNjk=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-10-04T19:14:41Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-10-04T19:14:41Z"}, "message": "Auto merge of #44901 - michaelwoerister:on-demand-eval, r=nikomatsakis\n\nincr.comp.: Switch to red/green change tracking, remove legacy system.\n\nThis PR finally switches incremental compilation to [red/green tracking](https://github.com/rust-lang/rust/issues/42293) and completely removes the legacy dependency graph implementation -- which includes a few quite costly passes that are simply not needed with the new system anymore.\n\nThere's still some documentation to be done and there's certainly still lots of optimizing and tuning ahead -- but the foundation for red/green is in place with this PR. This has been in the making for a long time `:)`\n\nr? @nikomatsakis\ncc @alexcrichton, @rust-lang/compiler", "tree": {"sha": "c5015864e06595546fe599c5a2d0e6d1625322e3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c5015864e06595546fe599c5a2d0e6d1625322e3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d7e73e4b1abe120520d1894b89c0e25469f41e69", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d7e73e4b1abe120520d1894b89c0e25469f41e69", "html_url": "https://github.com/rust-lang/rust/commit/d7e73e4b1abe120520d1894b89c0e25469f41e69", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d7e73e4b1abe120520d1894b89c0e25469f41e69/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "417ffc98dfc770c27f7f2d7430f0edf975576591", "url": "https://api.github.com/repos/rust-lang/rust/commits/417ffc98dfc770c27f7f2d7430f0edf975576591", "html_url": "https://github.com/rust-lang/rust/commit/417ffc98dfc770c27f7f2d7430f0edf975576591"}, {"sha": "0454a41bec547b28526cdb511f05372c80cb7277", "url": "https://api.github.com/repos/rust-lang/rust/commits/0454a41bec547b28526cdb511f05372c80cb7277", "html_url": "https://github.com/rust-lang/rust/commit/0454a41bec547b28526cdb511f05372c80cb7277"}], "stats": {"total": 3459, "additions": 1088, "deletions": 2371}, "files": [{"sha": "36236ff25b0cf3eca68352f0c262baf162a01316", "filename": "src/librustc/dep_graph/dep_node.rs", "status": "modified", "additions": 15, "deletions": 64, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -65,8 +65,8 @@ use hir::map::DefPathHash;\n use hir::{HirId, ItemLocalId};\n \n use ich::Fingerprint;\n-use ty::{TyCtxt, Instance, InstanceDef};\n-use ty::fast_reject::SimplifiedType;\n+use ty::{TyCtxt, Instance, InstanceDef, ParamEnvAnd, Ty};\n+use ty::subst::Substs;\n use rustc_data_structures::stable_hasher::{StableHasher, HashStable};\n use ich::StableHashingContext;\n use std::fmt;\n@@ -347,7 +347,7 @@ impl fmt::Debug for DepNode {\n     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n         write!(f, \"{:?}\", self.kind)?;\n \n-        if !self.kind.has_params() {\n+        if !self.kind.has_params() && !self.kind.is_anon() {\n             return Ok(());\n         }\n \n@@ -356,14 +356,14 @@ impl fmt::Debug for DepNode {\n         ::ty::tls::with_opt(|opt_tcx| {\n             if let Some(tcx) = opt_tcx {\n                 if let Some(def_id) = self.extract_def_id(tcx) {\n-                    write!(f, \"{}\", tcx.item_path_str(def_id))?;\n+                    write!(f, \"{}\", tcx.def_path(def_id).to_string(tcx))?;\n                 } else if let Some(ref s) = tcx.dep_graph.dep_node_debug_str(*self) {\n                     write!(f, \"{}\", s)?;\n                 } else {\n-                    write!(f, \"{:?}\", self.hash)?;\n+                    write!(f, \"{}\", self.hash)?;\n                 }\n             } else {\n-                write!(f, \"{:?}\", self.hash)?;\n+                write!(f, \"{}\", self.hash)?;\n             }\n             Ok(())\n         })?;\n@@ -430,7 +430,6 @@ define_dep_nodes!( <'tcx>\n     [] RegionScopeTree(DefId),\n     [] Coherence,\n     [] CoherenceInherentImplOverlapCheck,\n-    [] Resolve,\n     [] CoherenceCheckTrait(DefId),\n     [] PrivacyAccessLevels(CrateNum),\n \n@@ -447,10 +446,8 @@ define_dep_nodes!( <'tcx>\n     [] MirBorrowCheck(DefId),\n     [] UnsafetyViolations(DefId),\n \n-    [] RvalueCheck(DefId),\n     [] Reachability,\n     [] MirKeys,\n-    [] TransWriteMetadata,\n     [] CrateVariances,\n \n     // Nodes representing bits of computed IR in the tcx. Each shared\n@@ -484,32 +481,23 @@ define_dep_nodes!( <'tcx>\n     [] TypeckBodiesKrate,\n     [] TypeckTables(DefId),\n     [] HasTypeckTables(DefId),\n-    [anon] ConstEval,\n+    [] ConstEval { param_env: ParamEnvAnd<'tcx, (DefId, &'tcx Substs<'tcx>)> },\n     [] SymbolName(DefId),\n     [] InstanceSymbolName { instance: Instance<'tcx> },\n     [] SpecializationGraph(DefId),\n     [] ObjectSafety(DefId),\n \n-    [anon] IsCopy,\n-    [anon] IsSized,\n-    [anon] IsFreeze,\n-    [anon] NeedsDrop,\n-    [anon] Layout,\n+    [] IsCopy { param_env: ParamEnvAnd<'tcx, Ty<'tcx>> },\n+    [] IsSized { param_env: ParamEnvAnd<'tcx, Ty<'tcx>> },\n+    [] IsFreeze { param_env: ParamEnvAnd<'tcx, Ty<'tcx>> },\n+    [] NeedsDrop { param_env: ParamEnvAnd<'tcx, Ty<'tcx>> },\n+    [] Layout { param_env: ParamEnvAnd<'tcx, Ty<'tcx>> },\n \n     // The set of impls for a given trait.\n     [] TraitImpls(DefId),\n-    [] RelevantTraitImpls(DefId, SimplifiedType),\n \n     [] AllLocalTraitImpls,\n \n-    // Nodes representing caches. To properly handle a true cache, we\n-    // don't use a DepTrackingMap, but rather we push a task node.\n-    // Otherwise the write into the map would be incorrectly\n-    // attributed to the first task that happened to fill the cache,\n-    // which would yield an overly conservative dep-graph.\n-    [] TraitItems(DefId),\n-    [] ReprHints(DefId),\n-\n     // Trait selection cache is a little funny. Given a trait\n     // reference like `Foo: SomeTrait<Bar>`, there could be\n     // arbitrarily many def-ids to map on in there (e.g., `Foo`,\n@@ -537,10 +525,6 @@ define_dep_nodes!( <'tcx>\n     // trait-select node.\n     [anon] TraitSelect,\n \n-    // For proj. cache, we just keep a list of all def-ids, since it is\n-    // not a hotspot.\n-    [] ProjectionCache { def_ids: DefIdList },\n-\n     [] ParamEnv(DefId),\n     [] DescribeDef(DefId),\n     [] DefSpan(DefId),\n@@ -598,7 +582,6 @@ define_dep_nodes!( <'tcx>\n     [] MissingLangItems(CrateNum),\n     [] ExternConstBody(DefId),\n     [] VisibleParentMap,\n-    [] IsDirectExternCrate(CrateNum),\n     [] MissingExternCrateItem(CrateNum),\n     [] UsedCrateSource(CrateNum),\n     [] PostorderCnums,\n@@ -618,6 +601,9 @@ define_dep_nodes!( <'tcx>\n     [] CodegenUnit(InternedString),\n     [] CompileCodegenUnit(InternedString),\n     [] OutputFilenames,\n+\n+    // We use this for most things when incr. comp. is turned off.\n+    [] Null,\n );\n \n trait DepNodeParams<'a, 'gcx: 'tcx + 'a, 'tcx: 'a> : fmt::Debug {\n@@ -719,40 +705,6 @@ impl<'a, 'gcx: 'tcx + 'a, 'tcx: 'a> DepNodeParams<'a, 'gcx, 'tcx> for (DefId, De\n     }\n }\n \n-\n-impl<'a, 'gcx: 'tcx + 'a, 'tcx: 'a> DepNodeParams<'a, 'gcx, 'tcx> for (DefIdList,) {\n-    const CAN_RECONSTRUCT_QUERY_KEY: bool = false;\n-\n-    // We actually would not need to specialize the implementation of this\n-    // method but it's faster to combine the hashes than to instantiate a full\n-    // hashing context and stable-hashing state.\n-    fn to_fingerprint(&self, tcx: TyCtxt) -> Fingerprint {\n-        let mut fingerprint = Fingerprint::zero();\n-\n-        for &def_id in self.0.iter() {\n-            let def_path_hash = tcx.def_path_hash(def_id);\n-            fingerprint = fingerprint.combine(def_path_hash.0);\n-        }\n-\n-        fingerprint\n-    }\n-\n-    fn to_debug_str(&self, tcx: TyCtxt<'a, 'gcx, 'tcx>) -> String {\n-        use std::fmt::Write;\n-\n-        let mut s = String::new();\n-        write!(&mut s, \"[\").unwrap();\n-\n-        for &def_id in self.0.iter() {\n-            write!(&mut s, \"{}\", tcx.def_path(def_id).to_string(tcx)).unwrap();\n-        }\n-\n-        write!(&mut s, \"]\").unwrap();\n-\n-        s\n-    }\n-}\n-\n impl<'a, 'gcx: 'tcx + 'a, 'tcx: 'a> DepNodeParams<'a, 'gcx, 'tcx> for (HirId,) {\n     const CAN_RECONSTRUCT_QUERY_KEY: bool = false;\n \n@@ -811,4 +763,3 @@ impl_stable_hash_for!(struct ::dep_graph::WorkProductId {\n     hash\n });\n \n-type DefIdList = Vec<DefId>;"}, {"sha": "b12db11cb6af692f83ba54042ffd179cfa9bc9d0", "filename": "src/librustc/dep_graph/edges.rs", "status": "removed", "additions": 0, "deletions": 266, "changes": 266, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc%2Fdep_graph%2Fedges.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc%2Fdep_graph%2Fedges.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fedges.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,266 +0,0 @@\n-// Copyright 2012-2015 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use ich::Fingerprint;\n-use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n-use rustc_data_structures::stable_hasher::StableHasher;\n-use std::env;\n-use std::hash::Hash;\n-use std::mem;\n-use super::{DepGraphQuery, DepKind, DepNode};\n-use super::debug::EdgeFilter;\n-\n-pub(super) struct DepGraphEdges {\n-    nodes: Vec<DepNode>,\n-    indices: FxHashMap<DepNode, DepNodeIndex>,\n-    edges: FxHashSet<(DepNodeIndex, DepNodeIndex)>,\n-    task_stack: Vec<OpenTask>,\n-    forbidden_edge: Option<EdgeFilter>,\n-\n-    // A set to help assert that no two tasks use the same DepNode. This is a\n-    // temporary measure. Once we load the previous dep-graph as readonly, this\n-    // check will fall out of the graph implementation naturally.\n-    opened_once: FxHashSet<DepNode>,\n-}\n-\n-#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\n-pub(super) struct DepNodeIndex {\n-    index: u32,\n-}\n-\n-impl DepNodeIndex {\n-\n-    pub const INVALID: DepNodeIndex = DepNodeIndex { index: ::std::u32::MAX };\n-\n-    fn new(v: usize) -> DepNodeIndex {\n-        assert!((v & 0xFFFF_FFFF) == v);\n-        DepNodeIndex { index: v as u32 }\n-    }\n-\n-    fn index(self) -> usize {\n-        self.index as usize\n-    }\n-}\n-\n-#[derive(Clone, Debug, PartialEq)]\n-enum OpenTask {\n-    Regular {\n-        node: DepNode,\n-        reads: Vec<DepNode>,\n-        read_set: FxHashSet<DepNode>,\n-    },\n-    Anon {\n-        reads: Vec<DepNode>,\n-        read_set: FxHashSet<DepNode>,\n-    },\n-    Ignore,\n-}\n-\n-impl DepGraphEdges {\n-    pub fn new() -> DepGraphEdges {\n-        let forbidden_edge = if cfg!(debug_assertions) {\n-            match env::var(\"RUST_FORBID_DEP_GRAPH_EDGE\") {\n-                Ok(s) => {\n-                    match EdgeFilter::new(&s) {\n-                        Ok(f) => Some(f),\n-                        Err(err) => bug!(\"RUST_FORBID_DEP_GRAPH_EDGE invalid: {}\", err),\n-                    }\n-                }\n-                Err(_) => None,\n-            }\n-        } else {\n-            None\n-        };\n-\n-        DepGraphEdges {\n-            nodes: vec![],\n-            indices: FxHashMap(),\n-            edges: FxHashSet(),\n-            task_stack: Vec::new(),\n-            forbidden_edge,\n-            opened_once: FxHashSet(),\n-        }\n-    }\n-\n-    fn id(&self, index: DepNodeIndex) -> DepNode {\n-        self.nodes[index.index()]\n-    }\n-\n-    pub fn push_ignore(&mut self) {\n-        self.task_stack.push(OpenTask::Ignore);\n-    }\n-\n-    pub fn pop_ignore(&mut self) {\n-        let popped_node = self.task_stack.pop().unwrap();\n-        debug_assert_eq!(popped_node, OpenTask::Ignore);\n-    }\n-\n-    pub fn push_task(&mut self, key: DepNode) {\n-        if !self.opened_once.insert(key) {\n-            bug!(\"Re-opened node {:?}\", key)\n-        }\n-\n-        self.task_stack.push(OpenTask::Regular {\n-            node: key,\n-            reads: Vec::new(),\n-            read_set: FxHashSet(),\n-        });\n-    }\n-\n-    pub fn pop_task(&mut self, key: DepNode) -> DepNodeIndex {\n-        let popped_node = self.task_stack.pop().unwrap();\n-\n-        if let OpenTask::Regular {\n-            node,\n-            read_set: _,\n-            reads\n-        } = popped_node {\n-            debug_assert_eq!(node, key);\n-            debug_assert!(!node.kind.is_input() || reads.is_empty());\n-\n-            let target_id = self.get_or_create_node(node);\n-\n-            for read in reads.into_iter() {\n-                let source_id = self.get_or_create_node(read);\n-                self.edges.insert((source_id, target_id));\n-            }\n-\n-            target_id\n-        } else {\n-            bug!(\"pop_task() - Expected regular task to be popped\")\n-        }\n-    }\n-\n-    pub fn push_anon_task(&mut self) {\n-        self.task_stack.push(OpenTask::Anon {\n-            reads: Vec::new(),\n-            read_set: FxHashSet(),\n-        });\n-    }\n-\n-    pub fn pop_anon_task(&mut self, kind: DepKind) -> DepNodeIndex {\n-        let popped_node = self.task_stack.pop().unwrap();\n-\n-        if let OpenTask::Anon {\n-            read_set: _,\n-            reads\n-        } = popped_node {\n-            let mut fingerprint = Fingerprint::zero();\n-            let mut hasher = StableHasher::new();\n-\n-            for read in reads.iter() {\n-                mem::discriminant(&read.kind).hash(&mut hasher);\n-\n-                // Fingerprint::combine() is faster than sending Fingerprint\n-                // through the StableHasher (at least as long as StableHasher\n-                // is so slow).\n-                fingerprint = fingerprint.combine(read.hash);\n-            }\n-\n-            fingerprint = fingerprint.combine(hasher.finish());\n-\n-            let target_dep_node = DepNode {\n-                kind,\n-                hash: fingerprint,\n-            };\n-\n-            if let Some(&index) = self.indices.get(&target_dep_node) {\n-                return index;\n-            }\n-\n-            let target_id = self.get_or_create_node(target_dep_node);\n-\n-            for read in reads.into_iter() {\n-                let source_id = self.get_or_create_node(read);\n-                self.edges.insert((source_id, target_id));\n-            }\n-\n-            target_id\n-        } else {\n-            bug!(\"pop_anon_task() - Expected anonymous task to be popped\")\n-        }\n-    }\n-\n-    /// Indicates that the current task `C` reads `v` by adding an\n-    /// edge from `v` to `C`. If there is no current task, has no\n-    /// effect. Note that *reading* from tracked state is harmless if\n-    /// you are not in a task; what is bad is *writing* to tracked\n-    /// state (and leaking data that you read into a tracked task).\n-    pub fn read(&mut self, source: DepNode) {\n-        match self.task_stack.last_mut() {\n-            Some(&mut OpenTask::Regular {\n-                node: target,\n-                ref mut reads,\n-                ref mut read_set,\n-            }) => {\n-                if read_set.insert(source) {\n-                    reads.push(source);\n-\n-                    if cfg!(debug_assertions) {\n-                        if let Some(ref forbidden_edge) = self.forbidden_edge {\n-                            if forbidden_edge.test(&source, &target) {\n-                                bug!(\"forbidden edge {:?} -> {:?} created\", source, target)\n-                            }\n-                        }\n-                    }\n-                }\n-            }\n-            Some(&mut OpenTask::Anon {\n-                ref mut reads,\n-                ref mut read_set,\n-            }) => {\n-                if read_set.insert(source) {\n-                    reads.push(source);\n-                }\n-            }\n-            Some(&mut OpenTask::Ignore) | None => {\n-                // ignore\n-            }\n-        }\n-    }\n-\n-    pub fn read_index(&mut self, source: DepNodeIndex) {\n-        let dep_node = self.nodes[source.index()];\n-        self.read(dep_node);\n-    }\n-\n-    pub fn query(&self) -> DepGraphQuery {\n-        let edges: Vec<_> = self.edges.iter()\n-                                      .map(|&(i, j)| (self.id(i), self.id(j)))\n-                                      .collect();\n-        DepGraphQuery::new(&self.nodes, &edges)\n-    }\n-\n-    #[inline]\n-    pub fn add_edge(&mut self, source: DepNode, target: DepNode) {\n-        let source = self.get_or_create_node(source);\n-        let target = self.get_or_create_node(target);\n-        self.edges.insert((source, target));\n-    }\n-\n-    pub fn add_node(&mut self, node: DepNode) -> DepNodeIndex {\n-        self.get_or_create_node(node)\n-    }\n-\n-    #[inline]\n-    fn get_or_create_node(&mut self, dep_node: DepNode) -> DepNodeIndex {\n-        let DepGraphEdges {\n-            ref mut indices,\n-            ref mut nodes,\n-            ..\n-        } = *self;\n-\n-        *indices.entry(dep_node).or_insert_with(|| {\n-            let next_id = nodes.len();\n-            nodes.push(dep_node);\n-            DepNodeIndex::new(next_id)\n-        })\n-     }\n-}"}, {"sha": "2d2558fd815c4f08f0de89503ce8f3fb7822b9c9", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 353, "deletions": 105, "changes": 458, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -14,17 +14,19 @@ use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n use rustc_data_structures::indexed_vec::{Idx, IndexVec};\n use session::config::OutputType;\n use std::cell::{Ref, RefCell};\n+use std::env;\n use std::hash::Hash;\n use std::rc::Rc;\n+use ty::TyCtxt;\n use util::common::{ProfileQueriesMsg, profq_msg};\n \n use ich::Fingerprint;\n \n+use super::debug::EdgeFilter;\n use super::dep_node::{DepNode, DepKind, WorkProductId};\n use super::query::DepGraphQuery;\n use super::raii;\n use super::safe::DepGraphSafe;\n-use super::edges::{self, DepGraphEdges};\n use super::serialized::{SerializedDepGraph, SerializedDepNodeIndex};\n use super::prev::PreviousDepGraph;\n \n@@ -42,28 +44,44 @@ pub struct DepGraph {\n     fingerprints: Rc<RefCell<FxHashMap<DepNode, Fingerprint>>>\n }\n \n-/// As a temporary measure, while transitioning to the new DepGraph\n-/// implementation, we maintain the old and the new dep-graph encoding in\n-/// parallel, so a DepNodeIndex actually contains two indices, one for each\n-/// version.\n+\n #[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\n pub struct DepNodeIndex {\n-    legacy: edges::DepNodeIndex,\n-    new: DepNodeIndexNew,\n+    index: u32,\n+}\n+\n+impl Idx for DepNodeIndex {\n+    fn new(idx: usize) -> Self {\n+        debug_assert!((idx & 0xFFFF_FFFF) == idx);\n+        DepNodeIndex { index: idx as u32 }\n+    }\n+    fn index(self) -> usize {\n+        self.index as usize\n+    }\n }\n \n impl DepNodeIndex {\n-    pub const INVALID: DepNodeIndex = DepNodeIndex {\n-        legacy: edges::DepNodeIndex::INVALID,\n-        new: DepNodeIndexNew::INVALID,\n+    const INVALID: DepNodeIndex = DepNodeIndex {\n+        index: ::std::u32::MAX,\n     };\n }\n \n-struct DepGraphData {\n-    /// The old, initial encoding of the dependency graph. This will soon go\n-    /// away.\n-    edges: RefCell<DepGraphEdges>,\n+#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\n+pub enum DepNodeColor {\n+    Red,\n+    Green(DepNodeIndex)\n+}\n \n+impl DepNodeColor {\n+    pub fn is_green(self) -> bool {\n+        match self {\n+            DepNodeColor::Red => false,\n+            DepNodeColor::Green(_) => true,\n+        }\n+    }\n+}\n+\n+struct DepGraphData {\n     /// The new encoding of the dependency graph, optimized for red/green\n     /// tracking. The `current` field is the dependency graph of only the\n     /// current compilation session: We don't merge the previous dep-graph into\n@@ -74,6 +92,8 @@ struct DepGraphData {\n     /// nodes and edges as well as all fingerprints of nodes that have them.\n     previous: PreviousDepGraph,\n \n+    colors: RefCell<FxHashMap<DepNode, DepNodeColor>>,\n+\n     /// When we load, there may be `.o` files, cached mir, or other such\n     /// things available to us. If we find that they are not dirty, we\n     /// load the path to the file storing those work-products here into\n@@ -84,6 +104,9 @@ struct DepGraphData {\n     work_products: RefCell<FxHashMap<WorkProductId, WorkProduct>>,\n \n     dep_node_debug: RefCell<FxHashMap<DepNode, String>>,\n+\n+    // Used for testing, only populated when -Zquery-dep-graph is specified.\n+    loaded_from_cache: RefCell<FxHashMap<DepNodeIndex, bool>>,\n }\n \n impl DepGraph {\n@@ -93,10 +116,11 @@ impl DepGraph {\n             data: Some(Rc::new(DepGraphData {\n                 previous_work_products: RefCell::new(FxHashMap()),\n                 work_products: RefCell::new(FxHashMap()),\n-                edges: RefCell::new(DepGraphEdges::new()),\n                 dep_node_debug: RefCell::new(FxHashMap()),\n                 current: RefCell::new(CurrentDepGraph::new()),\n                 previous: prev_graph,\n+                colors: RefCell::new(FxHashMap()),\n+                loaded_from_cache: RefCell::new(FxHashMap()),\n             })),\n             fingerprints: Rc::new(RefCell::new(FxHashMap())),\n         }\n@@ -116,12 +140,22 @@ impl DepGraph {\n     }\n \n     pub fn query(&self) -> DepGraphQuery {\n-        self.data.as_ref().unwrap().edges.borrow().query()\n+        let current_dep_graph = self.data.as_ref().unwrap().current.borrow();\n+        let nodes: Vec<_> = current_dep_graph.nodes.iter().cloned().collect();\n+        let mut edges = Vec::new();\n+        for (index, edge_targets) in current_dep_graph.edges.iter_enumerated() {\n+            let from = current_dep_graph.nodes[index];\n+            for &edge_target in edge_targets {\n+                let to = current_dep_graph.nodes[edge_target];\n+                edges.push((from, to));\n+            }\n+        }\n+\n+        DepGraphQuery::new(&nodes[..], &edges[..])\n     }\n \n     pub fn in_ignore<'graph>(&'graph self) -> Option<raii::IgnoreTask<'graph>> {\n-        self.data.as_ref().map(|data| raii::IgnoreTask::new(&data.edges,\n-                                                            &data.current))\n+        self.data.as_ref().map(|data| raii::IgnoreTask::new(&data.current))\n     }\n \n     pub fn with_ignore<OP,R>(&self, op: OP) -> R\n@@ -168,7 +202,8 @@ impl DepGraph {\n               R: HashStable<HCX>,\n     {\n         if let Some(ref data) = self.data {\n-            data.edges.borrow_mut().push_task(key);\n+            debug_assert!(!data.colors.borrow().contains_key(&key));\n+\n             data.current.borrow_mut().push_task(key);\n             if cfg!(debug_assertions) {\n                 profq_msg(ProfileQueriesMsg::TaskBegin(key.clone()))\n@@ -186,31 +221,52 @@ impl DepGraph {\n                 profq_msg(ProfileQueriesMsg::TaskEnd)\n             };\n \n-            let dep_node_index_legacy = data.edges.borrow_mut().pop_task(key);\n-            let dep_node_index_new = data.current.borrow_mut().pop_task(key);\n+            let dep_node_index = data.current.borrow_mut().pop_task(key);\n \n             let mut stable_hasher = StableHasher::new();\n             result.hash_stable(&mut hcx, &mut stable_hasher);\n \n-            assert!(self.fingerprints\n-                        .borrow_mut()\n-                        .insert(key, stable_hasher.finish())\n-                        .is_none());\n+            let current_fingerprint = stable_hasher.finish();\n \n-            (result, DepNodeIndex {\n-                legacy: dep_node_index_legacy,\n-                new: dep_node_index_new,\n-            })\n+            // Store the current fingerprint\n+            {\n+                let old_value = self.fingerprints\n+                                    .borrow_mut()\n+                                    .insert(key, current_fingerprint);\n+                debug_assert!(old_value.is_none(),\n+                              \"DepGraph::with_task() - Duplicate fingerprint \\\n+                               insertion for {:?}\", key);\n+            }\n+\n+            // Determine the color of the new DepNode.\n+            {\n+                let prev_fingerprint = data.previous.fingerprint_of(&key);\n+\n+                let color = if Some(current_fingerprint) == prev_fingerprint {\n+                    DepNodeColor::Green(dep_node_index)\n+                } else {\n+                    DepNodeColor::Red\n+                };\n+\n+                let old_value = data.colors.borrow_mut().insert(key, color);\n+                debug_assert!(old_value.is_none(),\n+                              \"DepGraph::with_task() - Duplicate DepNodeColor \\\n+                               insertion for {:?}\", key);\n+            }\n+\n+            (result, dep_node_index)\n         } else {\n             if key.kind.fingerprint_needed_for_crate_hash() {\n                 let mut hcx = cx.create_stable_hashing_context();\n                 let result = task(cx, arg);\n                 let mut stable_hasher = StableHasher::new();\n                 result.hash_stable(&mut hcx, &mut stable_hasher);\n-                assert!(self.fingerprints\n-                            .borrow_mut()\n-                            .insert(key, stable_hasher.finish())\n-                            .is_none());\n+                let old_value = self.fingerprints\n+                                    .borrow_mut()\n+                                    .insert(key, stable_hasher.finish());\n+                debug_assert!(old_value.is_none(),\n+                              \"DepGraph::with_task() - Duplicate fingerprint \\\n+                               insertion for {:?}\", key);\n                 (result, DepNodeIndex::INVALID)\n             } else {\n                 (task(cx, arg), DepNodeIndex::INVALID)\n@@ -224,15 +280,12 @@ impl DepGraph {\n         where OP: FnOnce() -> R\n     {\n         if let Some(ref data) = self.data {\n-            data.edges.borrow_mut().push_anon_task();\n             data.current.borrow_mut().push_anon_task();\n             let result = op();\n-            let dep_node_index_legacy = data.edges.borrow_mut().pop_anon_task(dep_kind);\n-            let dep_node_index_new = data.current.borrow_mut().pop_anon_task(dep_kind);\n-            (result, DepNodeIndex {\n-                legacy: dep_node_index_legacy,\n-                new: dep_node_index_new,\n-            })\n+            let dep_node_index = data.current\n+                                     .borrow_mut()\n+                                     .pop_anon_task(dep_kind);\n+            (result, dep_node_index)\n         } else {\n             (op(), DepNodeIndex::INVALID)\n         }\n@@ -241,41 +294,27 @@ impl DepGraph {\n     #[inline]\n     pub fn read(&self, v: DepNode) {\n         if let Some(ref data) = self.data {\n-            data.edges.borrow_mut().read(v);\n-\n             let mut current = data.current.borrow_mut();\n-            if let Some(&dep_node_index_new) = current.node_to_node_index.get(&v) {\n-                current.read_index(dep_node_index_new);\n+            if let Some(&dep_node_index) = current.node_to_node_index.get(&v) {\n+                current.read_index(dep_node_index);\n             } else {\n                 bug!(\"DepKind {:?} should be pre-allocated but isn't.\", v.kind)\n             }\n         }\n     }\n \n     #[inline]\n-    pub fn read_index(&self, v: DepNodeIndex) {\n+    pub fn read_index(&self, dep_node_index: DepNodeIndex) {\n         if let Some(ref data) = self.data {\n-            data.edges.borrow_mut().read_index(v.legacy);\n-            data.current.borrow_mut().read_index(v.new);\n+            data.current.borrow_mut().read_index(dep_node_index);\n         }\n     }\n \n-    /// Only to be used during graph loading\n-    #[inline]\n-    pub fn add_edge_directly(&self, source: DepNode, target: DepNode) {\n-        self.data.as_ref().unwrap().edges.borrow_mut().add_edge(source, target);\n-    }\n-\n-    /// Only to be used during graph loading\n-    pub fn add_node_directly(&self, node: DepNode) {\n-        self.data.as_ref().unwrap().edges.borrow_mut().add_node(node);\n-    }\n-\n     pub fn fingerprint_of(&self, dep_node: &DepNode) -> Fingerprint {\n         self.fingerprints.borrow()[dep_node]\n     }\n \n-    pub fn prev_fingerprint_of(&self, dep_node: &DepNode) -> Fingerprint {\n+    pub fn prev_fingerprint_of(&self, dep_node: &DepNode) -> Option<Fingerprint> {\n         self.data.as_ref().unwrap().previous.fingerprint_of(dep_node)\n     }\n \n@@ -383,6 +422,194 @@ impl DepGraph {\n             edge_list_data,\n         }\n     }\n+\n+    pub fn node_color(&self, dep_node: &DepNode) -> Option<DepNodeColor> {\n+        self.data.as_ref().and_then(|data| data.colors.borrow().get(dep_node).cloned())\n+    }\n+\n+    pub fn try_mark_green(&self,\n+                          tcx: TyCtxt,\n+                          dep_node: &DepNode)\n+                          -> Option<DepNodeIndex> {\n+        debug!(\"try_mark_green({:?}) - BEGIN\", dep_node);\n+        let data = self.data.as_ref().unwrap();\n+\n+        debug_assert!(!data.colors.borrow().contains_key(dep_node));\n+        debug_assert!(!data.current.borrow().node_to_node_index.contains_key(dep_node));\n+\n+        if dep_node.kind.is_input() {\n+            // We should only hit try_mark_green() for inputs that do not exist\n+            // anymore in the current compilation session. Existing inputs are\n+            // eagerly marked as either red/green before any queries are\n+            // executed.\n+            debug_assert!(dep_node.extract_def_id(tcx).is_none());\n+            debug!(\"try_mark_green({:?}) - END - DepNode is deleted input\", dep_node);\n+            return None;\n+        }\n+\n+        let (prev_deps, prev_dep_node_index) = match data.previous.edges_from(dep_node) {\n+            Some(prev) => {\n+                // This DepNode and the corresponding query invocation existed\n+                // in the previous compilation session too, so we can try to\n+                // mark it as green by recursively marking all of its\n+                // dependencies green.\n+                prev\n+            }\n+            None => {\n+                // This DepNode did not exist in the previous compilation session,\n+                // so we cannot mark it as green.\n+                debug!(\"try_mark_green({:?}) - END - DepNode does not exist in \\\n+                        current compilation session anymore\", dep_node);\n+                return None\n+            }\n+        };\n+\n+        let mut current_deps = Vec::new();\n+\n+        for &dep_dep_node_index in prev_deps {\n+            let dep_dep_node = &data.previous.index_to_node(dep_dep_node_index);\n+\n+            let dep_dep_node_color = data.colors.borrow().get(dep_dep_node).cloned();\n+            match dep_dep_node_color {\n+                Some(DepNodeColor::Green(node_index)) => {\n+                    // This dependency has been marked as green before, we are\n+                    // still fine and can continue with checking the other\n+                    // dependencies.\n+                    debug!(\"try_mark_green({:?}) --- found dependency {:?} to \\\n+                            be immediately green\", dep_node, dep_dep_node);\n+                    current_deps.push(node_index);\n+                }\n+                Some(DepNodeColor::Red) => {\n+                    // We found a dependency the value of which has changed\n+                    // compared to the previous compilation session. We cannot\n+                    // mark the DepNode as green and also don't need to bother\n+                    // with checking any of the other dependencies.\n+                    debug!(\"try_mark_green({:?}) - END - dependency {:?} was \\\n+                            immediately red\", dep_node, dep_dep_node);\n+                    return None\n+                }\n+                None => {\n+                    if dep_dep_node.kind.is_input() {\n+                        // This input does not exist anymore.\n+                        debug_assert!(dep_dep_node.extract_def_id(tcx).is_none(),\n+                                      \"Encountered input {:?} without color\",\n+                                      dep_dep_node);\n+                        debug!(\"try_mark_green({:?}) - END - dependency {:?} \\\n+                                was deleted input\", dep_node, dep_dep_node);\n+                        return None;\n+                    }\n+\n+                    debug!(\"try_mark_green({:?}) --- state of dependency {:?} \\\n+                            is unknown, trying to mark it green\", dep_node,\n+                            dep_dep_node);\n+\n+                    // We don't know the state of this dependency. Let's try to\n+                    // mark it green.\n+                    if let Some(node_index) = self.try_mark_green(tcx, dep_dep_node) {\n+                        debug!(\"try_mark_green({:?}) --- managed to MARK \\\n+                                dependency {:?} as green\", dep_node, dep_dep_node);\n+                        current_deps.push(node_index);\n+                    } else {\n+                        // We failed to mark it green, so we try to force the query.\n+                        debug!(\"try_mark_green({:?}) --- trying to force \\\n+                                dependency {:?}\", dep_node, dep_dep_node);\n+                        if ::ty::maps::force_from_dep_node(tcx, dep_dep_node) {\n+                            let dep_dep_node_color = data.colors\n+                                                         .borrow()\n+                                                         .get(dep_dep_node)\n+                                                         .cloned();\n+                            match dep_dep_node_color {\n+                                Some(DepNodeColor::Green(node_index)) => {\n+                                    debug!(\"try_mark_green({:?}) --- managed to \\\n+                                            FORCE dependency {:?} to green\",\n+                                            dep_node, dep_dep_node);\n+                                    current_deps.push(node_index);\n+                                }\n+                                Some(DepNodeColor::Red) => {\n+                                    debug!(\"try_mark_green({:?}) - END - \\\n+                                            dependency {:?} was red after forcing\",\n+                                           dep_node,\n+                                           dep_dep_node);\n+                                    return None\n+                                }\n+                                None => {\n+                                    bug!(\"try_mark_green() - Forcing the DepNode \\\n+                                          should have set its color\")\n+                                }\n+                            }\n+                        } else {\n+                            // The DepNode could not be forced.\n+                            debug!(\"try_mark_green({:?}) - END - dependency {:?} \\\n+                                    could not be forced\", dep_node, dep_dep_node);\n+                            return None\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+\n+\n+        // If we got here without hitting a `return` that means that all\n+        // dependencies of this DepNode could be marked as green. Therefore we\n+        // can also mark this DepNode as green. We do so by...\n+\n+        // ... allocating an entry for it in the current dependency graph and\n+        // adding all the appropriate edges imported from the previous graph ...\n+        let dep_node_index = data.current\n+                                 .borrow_mut()\n+                                 .alloc_node(*dep_node, current_deps);\n+\n+        // ... copying the fingerprint from the previous graph too, so we don't\n+        // have to recompute it ...\n+        let fingerprint = data.previous.fingerprint_by_index(prev_dep_node_index);\n+        let old_fingerprint = self.fingerprints\n+                                  .borrow_mut()\n+                                  .insert(*dep_node, fingerprint);\n+        debug_assert!(old_fingerprint.is_none(),\n+                      \"DepGraph::try_mark_green() - Duplicate fingerprint \\\n+                      insertion for {:?}\", dep_node);\n+\n+        // ... and finally storing a \"Green\" entry in the color map.\n+        let old_color = data.colors\n+                            .borrow_mut()\n+                            .insert(*dep_node, DepNodeColor::Green(dep_node_index));\n+        debug_assert!(old_color.is_none(),\n+                      \"DepGraph::try_mark_green() - Duplicate DepNodeColor \\\n+                      insertion for {:?}\", dep_node);\n+\n+        debug!(\"try_mark_green({:?}) - END - successfully marked as green\", dep_node.kind);\n+        Some(dep_node_index)\n+    }\n+\n+    // Used in various assertions\n+    pub fn is_green(&self, dep_node_index: DepNodeIndex) -> bool {\n+        let dep_node = self.data.as_ref().unwrap().current.borrow().nodes[dep_node_index];\n+        self.data.as_ref().unwrap().colors.borrow().get(&dep_node).map(|&color| {\n+            match color {\n+                DepNodeColor::Red => false,\n+                DepNodeColor::Green(_) => true,\n+            }\n+        }).unwrap_or(false)\n+    }\n+\n+    pub fn mark_loaded_from_cache(&self, dep_node_index: DepNodeIndex, state: bool) {\n+        debug!(\"mark_loaded_from_cache({:?}, {})\",\n+               self.data.as_ref().unwrap().current.borrow().nodes[dep_node_index],\n+               state);\n+\n+        self.data\n+            .as_ref()\n+            .unwrap()\n+            .loaded_from_cache\n+            .borrow_mut()\n+            .insert(dep_node_index, state);\n+    }\n+\n+    pub fn was_loaded_from_cache(&self, dep_node: &DepNode) -> Option<bool> {\n+        let data = self.data.as_ref().unwrap();\n+        let dep_node_index = data.current.borrow().node_to_node_index[dep_node];\n+        data.loaded_from_cache.borrow().get(&dep_node_index).cloned()\n+    }\n }\n \n /// A \"work product\" is an intermediate result that we save into the\n@@ -419,30 +646,62 @@ impl DepGraph {\n #[derive(Clone, Debug, RustcEncodable, RustcDecodable)]\n pub struct WorkProduct {\n     pub cgu_name: String,\n-    /// Extra hash used to decide if work-product is still suitable;\n-    /// note that this is *not* a hash of the work-product itself.\n-    /// See documentation on `WorkProduct` type for an example.\n-    pub input_hash: u64,\n-\n     /// Saved files associated with this CGU\n     pub saved_files: Vec<(OutputType, String)>,\n }\n \n pub(super) struct CurrentDepGraph {\n-    nodes: IndexVec<DepNodeIndexNew, DepNode>,\n-    edges: IndexVec<DepNodeIndexNew, Vec<DepNodeIndexNew>>,\n-    node_to_node_index: FxHashMap<DepNode, DepNodeIndexNew>,\n-\n+    nodes: IndexVec<DepNodeIndex, DepNode>,\n+    edges: IndexVec<DepNodeIndex, Vec<DepNodeIndex>>,\n+    node_to_node_index: FxHashMap<DepNode, DepNodeIndex>,\n     task_stack: Vec<OpenTask>,\n+    forbidden_edge: Option<EdgeFilter>,\n+\n+    // Anonymous DepNodes are nodes the ID of which we compute from the list of\n+    // their edges. This has the beneficial side-effect that multiple anonymous\n+    // nodes can be coalesced into one without changing the semantics of the\n+    // dependency graph. However, the merging of nodes can lead to a subtle\n+    // problem during red-green marking: The color of an anonymous node from\n+    // the current session might \"shadow\" the color of the node with the same\n+    // ID from the previous session. In order to side-step this problem, we make\n+    // sure that anon-node IDs allocated in different sessions don't overlap.\n+    // This is implemented by mixing a session-key into the ID fingerprint of\n+    // each anon node. The session-key is just a random number generated when\n+    // the DepGraph is created.\n+    anon_id_seed: Fingerprint,\n }\n \n impl CurrentDepGraph {\n     fn new() -> CurrentDepGraph {\n+        use std::time::{SystemTime, UNIX_EPOCH};\n+\n+        let duration = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();\n+        let nanos = duration.as_secs() * 1_000_000_000 +\n+                    duration.subsec_nanos() as u64;\n+        let mut stable_hasher = StableHasher::new();\n+        nanos.hash(&mut stable_hasher);\n+\n+        let forbidden_edge = if cfg!(debug_assertions) {\n+            match env::var(\"RUST_FORBID_DEP_GRAPH_EDGE\") {\n+                Ok(s) => {\n+                    match EdgeFilter::new(&s) {\n+                        Ok(f) => Some(f),\n+                        Err(err) => bug!(\"RUST_FORBID_DEP_GRAPH_EDGE invalid: {}\", err),\n+                    }\n+                }\n+                Err(_) => None,\n+            }\n+        } else {\n+            None\n+        };\n+\n         CurrentDepGraph {\n             nodes: IndexVec::new(),\n             edges: IndexVec::new(),\n             node_to_node_index: FxHashMap(),\n+            anon_id_seed: stable_hasher.finish(),\n             task_stack: Vec::new(),\n+            forbidden_edge,\n         }\n     }\n \n@@ -463,7 +722,7 @@ impl CurrentDepGraph {\n         });\n     }\n \n-    pub(super) fn pop_task(&mut self, key: DepNode) -> DepNodeIndexNew {\n+    pub(super) fn pop_task(&mut self, key: DepNode) -> DepNodeIndex {\n         let popped_node = self.task_stack.pop().unwrap();\n \n         if let OpenTask::Regular {\n@@ -485,14 +744,14 @@ impl CurrentDepGraph {\n         });\n     }\n \n-    fn pop_anon_task(&mut self, kind: DepKind) -> DepNodeIndexNew {\n+    fn pop_anon_task(&mut self, kind: DepKind) -> DepNodeIndex {\n         let popped_node = self.task_stack.pop().unwrap();\n \n         if let OpenTask::Anon {\n             read_set: _,\n             reads\n         } = popped_node {\n-            let mut fingerprint = Fingerprint::zero();\n+            let mut fingerprint = self.anon_id_seed;\n             let mut hasher = StableHasher::new();\n \n             for &read in reads.iter() {\n@@ -514,24 +773,35 @@ impl CurrentDepGraph {\n             };\n \n             if let Some(&index) = self.node_to_node_index.get(&target_dep_node) {\n-                return index;\n+                index\n+            } else {\n+                self.alloc_node(target_dep_node, reads)\n             }\n-\n-            self.alloc_node(target_dep_node, reads)\n         } else {\n             bug!(\"pop_anon_task() - Expected anonymous task to be popped\")\n         }\n     }\n \n-    fn read_index(&mut self, source: DepNodeIndexNew) {\n+    fn read_index(&mut self, source: DepNodeIndex) {\n         match self.task_stack.last_mut() {\n             Some(&mut OpenTask::Regular {\n                 ref mut reads,\n                 ref mut read_set,\n-                node: _,\n+                node: ref target,\n             }) => {\n                 if read_set.insert(source) {\n                     reads.push(source);\n+\n+                    if cfg!(debug_assertions) {\n+                        if let Some(ref forbidden_edge) = self.forbidden_edge {\n+                            let source = self.nodes[source];\n+                            if forbidden_edge.test(&source, &target) {\n+                                bug!(\"forbidden edge {:?} -> {:?} created\",\n+                                     source,\n+                                     target)\n+                            }\n+                        }\n+                    }\n                 }\n             }\n             Some(&mut OpenTask::Anon {\n@@ -550,51 +820,29 @@ impl CurrentDepGraph {\n \n     fn alloc_node(&mut self,\n                   dep_node: DepNode,\n-                  edges: Vec<DepNodeIndexNew>)\n-                  -> DepNodeIndexNew {\n+                  edges: Vec<DepNodeIndex>)\n+                  -> DepNodeIndex {\n         debug_assert_eq!(self.edges.len(), self.nodes.len());\n         debug_assert_eq!(self.node_to_node_index.len(), self.nodes.len());\n         debug_assert!(!self.node_to_node_index.contains_key(&dep_node));\n-        let dep_node_index = DepNodeIndexNew::new(self.nodes.len());\n+        let dep_node_index = DepNodeIndex::new(self.nodes.len());\n         self.nodes.push(dep_node);\n         self.node_to_node_index.insert(dep_node, dep_node_index);\n         self.edges.push(edges);\n         dep_node_index\n     }\n }\n \n-#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\n-pub(super) struct DepNodeIndexNew {\n-    index: u32,\n-}\n-\n-impl Idx for DepNodeIndexNew {\n-    fn new(v: usize) -> DepNodeIndexNew {\n-        assert!((v & 0xFFFF_FFFF) == v);\n-        DepNodeIndexNew { index: v as u32 }\n-    }\n-\n-    fn index(self) -> usize {\n-        self.index as usize\n-    }\n-}\n-\n-impl DepNodeIndexNew {\n-    const INVALID: DepNodeIndexNew = DepNodeIndexNew {\n-        index: ::std::u32::MAX,\n-    };\n-}\n-\n #[derive(Clone, Debug, PartialEq)]\n enum OpenTask {\n     Regular {\n         node: DepNode,\n-        reads: Vec<DepNodeIndexNew>,\n-        read_set: FxHashSet<DepNodeIndexNew>,\n+        reads: Vec<DepNodeIndex>,\n+        read_set: FxHashSet<DepNodeIndex>,\n     },\n     Anon {\n-        reads: Vec<DepNodeIndexNew>,\n-        read_set: FxHashSet<DepNodeIndexNew>,\n+        reads: Vec<DepNodeIndex>,\n+        read_set: FxHashSet<DepNodeIndex>,\n     },\n     Ignore,\n }"}, {"sha": "8d2cf67684923118d1523916f843d9056d646fc2", "filename": "src/librustc/dep_graph/mod.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fmod.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -11,7 +11,6 @@\n pub mod debug;\n mod dep_node;\n mod dep_tracking_map;\n-mod edges;\n mod graph;\n mod prev;\n mod query;\n@@ -21,7 +20,7 @@ mod serialized;\n \n pub use self::dep_tracking_map::{DepTrackingMap, DepTrackingMapConfig};\n pub use self::dep_node::{DepNode, DepKind, DepConstructor, WorkProductId};\n-pub use self::graph::{DepGraph, WorkProduct, DepNodeIndex};\n+pub use self::graph::{DepGraph, WorkProduct, DepNodeIndex, DepNodeColor};\n pub use self::prev::PreviousDepGraph;\n pub use self::query::DepGraphQuery;\n pub use self::safe::AssertDepGraphSafe;"}, {"sha": "17001bbb0c38a4b1362c64391e37af2134014e0b", "filename": "src/librustc/dep_graph/prev.rs", "status": "modified", "additions": 26, "deletions": 12, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fprev.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fprev.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fprev.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -28,19 +28,33 @@ impl PreviousDepGraph {\n         PreviousDepGraph { data, index }\n     }\n \n-    pub fn with_edges_from<F>(&self, dep_node: &DepNode, mut f: F)\n-    where\n-        F: FnMut(&(DepNode, Fingerprint)),\n-    {\n-        let node_index = self.index[dep_node];\n-        self.data\n-            .edge_targets_from(node_index)\n-            .into_iter()\n-            .for_each(|&index| f(&self.data.nodes[index]));\n+    #[inline]\n+    pub fn edges_from(&self,\n+                      dep_node: &DepNode)\n+                      -> Option<(&[SerializedDepNodeIndex], SerializedDepNodeIndex)> {\n+        self.index\n+            .get(dep_node)\n+            .map(|&node_index| {\n+                (self.data.edge_targets_from(node_index), node_index)\n+            })\n     }\n \n-    pub fn fingerprint_of(&self, dep_node: &DepNode) -> Fingerprint {\n-        let node_index = self.index[dep_node];\n-        self.data.nodes[node_index].1\n+    #[inline]\n+    pub fn index_to_node(&self, dep_node_index: SerializedDepNodeIndex) -> DepNode {\n+        self.data.nodes[dep_node_index].0\n+    }\n+\n+    #[inline]\n+    pub fn fingerprint_of(&self, dep_node: &DepNode) -> Option<Fingerprint> {\n+        self.index\n+            .get(dep_node)\n+            .map(|&node_index| self.data.nodes[node_index].1)\n+    }\n+\n+    #[inline]\n+    pub fn fingerprint_by_index(&self,\n+                                dep_node_index: SerializedDepNodeIndex)\n+                                -> Fingerprint {\n+        self.data.nodes[dep_node_index].1\n     }\n }"}, {"sha": "5728bcc7d27710dbccc7cfa69e32a904bc79976e", "filename": "src/librustc/dep_graph/raii.rs", "status": "modified", "additions": 5, "deletions": 12, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fraii.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fraii.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fraii.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -8,33 +8,26 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use super::edges::DepGraphEdges;\n use super::graph::CurrentDepGraph;\n \n use std::cell::RefCell;\n \n pub struct IgnoreTask<'graph> {\n-    legacy_graph: &'graph RefCell<DepGraphEdges>,\n-    new_graph: &'graph RefCell<CurrentDepGraph>,\n+    graph: &'graph RefCell<CurrentDepGraph>,\n }\n \n impl<'graph> IgnoreTask<'graph> {\n-    pub(super) fn new(legacy_graph: &'graph RefCell<DepGraphEdges>,\n-                      new_graph: &'graph RefCell<CurrentDepGraph>)\n-                      -> IgnoreTask<'graph> {\n-        legacy_graph.borrow_mut().push_ignore();\n-        new_graph.borrow_mut().push_ignore();\n+    pub(super) fn new(graph: &'graph RefCell<CurrentDepGraph>) -> IgnoreTask<'graph> {\n+        graph.borrow_mut().push_ignore();\n         IgnoreTask {\n-            legacy_graph,\n-            new_graph,\n+            graph,\n         }\n     }\n }\n \n impl<'graph> Drop for IgnoreTask<'graph> {\n     fn drop(&mut self) {\n-        self.legacy_graph.borrow_mut().pop_ignore();\n-        self.new_graph.borrow_mut().pop_ignore();\n+        self.graph.borrow_mut().pop_ignore();\n     }\n }\n "}, {"sha": "7275a740e76f8e2abcfb53f400b98fbe7bd3defb", "filename": "src/librustc/dep_graph/serialized.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fserialized.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fdep_graph%2Fserialized.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fserialized.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -56,7 +56,10 @@ impl SerializedDepGraph {\n         }\n     }\n \n-    pub fn edge_targets_from(&self, source: SerializedDepNodeIndex) -> &[SerializedDepNodeIndex] {\n+    #[inline]\n+    pub fn edge_targets_from(&self,\n+                             source: SerializedDepNodeIndex)\n+                             -> &[SerializedDepNodeIndex] {\n         let targets = self.edge_list_indices[source];\n         &self.edge_list_data[targets.0 as usize..targets.1 as usize]\n     }"}, {"sha": "3dcbeda94bc0158a8024faca7a9311fd940ab003", "filename": "src/librustc/ty/maps/mod.rs", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fty%2Fmaps%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fty%2Fmaps%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmaps%2Fmod.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -43,7 +43,6 @@ use rustc_back::PanicStrategy;\n use rustc_data_structures::indexed_vec::IndexVec;\n use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n use rustc_data_structures::stable_hasher::StableVec;\n-use std::cell::{RefCell, Cell};\n \n use std::ops::Deref;\n use std::rc::Rc;\n@@ -57,6 +56,7 @@ use syntax::symbol::Symbol;\n #[macro_use]\n mod plumbing;\n use self::plumbing::*;\n+pub use self::plumbing::force_from_dep_node;\n \n mod keys;\n pub use self::keys::Key;\n@@ -377,9 +377,9 @@ fn typeck_item_bodies_dep_node<'tcx>(_: CrateNum) -> DepConstructor<'tcx> {\n     DepConstructor::TypeckBodiesKrate\n }\n \n-fn const_eval_dep_node<'tcx>(_: ty::ParamEnvAnd<'tcx, (DefId, &'tcx Substs<'tcx>)>)\n+fn const_eval_dep_node<'tcx>(param_env: ty::ParamEnvAnd<'tcx, (DefId, &'tcx Substs<'tcx>)>)\n                              -> DepConstructor<'tcx> {\n-    DepConstructor::ConstEval\n+    DepConstructor::ConstEval { param_env }\n }\n \n fn mir_keys<'tcx>(_: CrateNum) -> DepConstructor<'tcx> {\n@@ -390,24 +390,24 @@ fn crate_variances<'tcx>(_: CrateNum) -> DepConstructor<'tcx> {\n     DepConstructor::CrateVariances\n }\n \n-fn is_copy_dep_node<'tcx>(_: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n-    DepConstructor::IsCopy\n+fn is_copy_dep_node<'tcx>(param_env: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n+    DepConstructor::IsCopy { param_env }\n }\n \n-fn is_sized_dep_node<'tcx>(_: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n-    DepConstructor::IsSized\n+fn is_sized_dep_node<'tcx>(param_env: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n+    DepConstructor::IsSized { param_env }\n }\n \n-fn is_freeze_dep_node<'tcx>(_: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n-    DepConstructor::IsFreeze\n+fn is_freeze_dep_node<'tcx>(param_env: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n+    DepConstructor::IsFreeze { param_env }\n }\n \n-fn needs_drop_dep_node<'tcx>(_: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n-    DepConstructor::NeedsDrop\n+fn needs_drop_dep_node<'tcx>(param_env: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n+    DepConstructor::NeedsDrop { param_env }\n }\n \n-fn layout_dep_node<'tcx>(_: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n-    DepConstructor::Layout\n+fn layout_dep_node<'tcx>(param_env: ty::ParamEnvAnd<'tcx, Ty<'tcx>>) -> DepConstructor<'tcx> {\n+    DepConstructor::Layout { param_env }\n }\n \n fn lint_levels_node<'tcx>(_: CrateNum) -> DepConstructor<'tcx> {"}, {"sha": "88b619558d90b8bf394e721d8ee5a07aa9768b03", "filename": "src/librustc/ty/maps/plumbing.rs", "status": "modified", "additions": 422, "deletions": 51, "changes": 473, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fty%2Fmaps%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fty%2Fmaps%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmaps%2Fplumbing.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -12,7 +12,7 @@\n //! that generate the actual methods on tcx which find and execute the\n //! provider, manage the caches, and so forth.\n \n-use dep_graph::{DepNodeIndex};\n+use dep_graph::{DepNodeIndex, DepNode, DepKind};\n use errors::{Diagnostic, DiagnosticBuilder};\n use ty::{TyCtxt};\n use ty::maps::Query; // NB: actually generated by the macros in this file\n@@ -36,6 +36,26 @@ pub(super) struct QueryValue<T> {\n     pub(super) diagnostics: Option<Box<QueryDiagnostics>>,\n }\n \n+impl<T> QueryValue<T> {\n+    pub(super) fn new(value: T,\n+                      dep_node_index: DepNodeIndex,\n+                      diagnostics: Vec<Diagnostic>)\n+                      -> QueryValue<T> {\n+        QueryValue {\n+            value,\n+            index: dep_node_index,\n+            diagnostics: if diagnostics.len() == 0 {\n+                None\n+            } else {\n+                Some(Box::new(QueryDiagnostics {\n+                    diagnostics,\n+                    emitted_diagnostics: Cell::new(true),\n+                }))\n+            },\n+        }\n+    }\n+}\n+\n pub(super) struct QueryDiagnostics {\n     pub(super) diagnostics: Vec<Diagnostic>,\n     pub(super) emitted_diagnostics: Cell<bool>,\n@@ -142,6 +162,10 @@ macro_rules! define_maps {\n     (<$tcx:tt>\n      $($(#[$attr:meta])*\n        [$($modifiers:tt)*] fn $name:ident: $node:ident($K:ty) -> $V:ty,)*) => {\n+\n+        use dep_graph::DepNodeIndex;\n+        use std::cell::RefCell;\n+\n         define_map_struct! {\n             tcx: $tcx,\n             input: ($(([$($modifiers)*] [$($attr)*] [$name]))*)\n@@ -200,19 +224,18 @@ macro_rules! define_maps {\n         }\n \n         impl<'a, $tcx, 'lcx> queries::$name<$tcx> {\n+\n             #[allow(unused)]\n             fn to_dep_node(tcx: TyCtxt<'a, $tcx, 'lcx>, key: &$K) -> DepNode {\n                 use dep_graph::DepConstructor::*;\n \n                 DepNode::new(tcx, $node(*key))\n             }\n \n-            fn try_get_with<F, R>(tcx: TyCtxt<'a, $tcx, 'lcx>,\n-                                  mut span: Span,\n-                                  key: $K,\n-                                  f: F)\n-                                  -> Result<R, CycleError<'a, $tcx>>\n-                where F: FnOnce(&$V) -> R\n+            fn try_get_with(tcx: TyCtxt<'a, $tcx, 'lcx>,\n+                            mut span: Span,\n+                            key: $K)\n+                            -> Result<$V, CycleError<'a, $tcx>>\n             {\n                 debug!(\"ty::queries::{}::try_get_with(key={:?}, span={:?})\",\n                        stringify!($name),\n@@ -239,10 +262,8 @@ macro_rules! define_maps {\n                     }\n                     profq_msg!(tcx, ProfileQueriesMsg::CacheHit);\n                     tcx.dep_graph.read_index(value.index);\n-                    return Ok(f(&value.value));\n+                    return Ok((&value.value).clone());\n                 }\n-                // else, we are going to run the provider:\n-                profq_msg!(tcx, ProfileQueriesMsg::ProviderBegin);\n \n                 // FIXME(eddyb) Get more valid Span's on queries.\n                 // def_span guard is necessary to prevent a recursive loop,\n@@ -251,70 +272,159 @@ macro_rules! define_maps {\n                     span = key.default_span(tcx)\n                 }\n \n+                // Fast path for when incr. comp. is off. `to_dep_node` is\n+                // expensive for some DepKinds.\n+                if !tcx.dep_graph.is_fully_enabled() {\n+                    let null_dep_node = DepNode::new_no_params(::dep_graph::DepKind::Null);\n+                    return Self::force(tcx, key, span, null_dep_node)\n+                                .map(|(v, _)| v);\n+                }\n+\n                 let dep_node = Self::to_dep_node(tcx, &key);\n-                let res = tcx.cycle_check(span, Query::$name(key), || {\n-                    tcx.sess.diagnostic().track_diagnostics(|| {\n-                        if dep_node.kind.is_anon() {\n+\n+                if dep_node.kind.is_anon() {\n+                    profq_msg!(tcx, ProfileQueriesMsg::ProviderBegin);\n+\n+                    let res = tcx.cycle_check(span, Query::$name(key), || {\n+                        tcx.sess.diagnostic().track_diagnostics(|| {\n                             tcx.dep_graph.with_anon_task(dep_node.kind, || {\n-                                let provider = tcx.maps.providers[key.map_crate()].$name;\n-                                provider(tcx.global_tcx(), key)\n+                                Self::compute_result(tcx.global_tcx(), key)\n                             })\n-                        } else {\n-                            fn run_provider<'a, 'tcx, 'lcx>(tcx: TyCtxt<'a, 'tcx, 'lcx>,\n-                                                            key: $K)\n-                                                            -> $V {\n-                                let provider = tcx.maps.providers[key.map_crate()].$name;\n-                                provider(tcx.global_tcx(), key)\n-                            }\n+                        })\n+                    })?;\n+\n+                    profq_msg!(tcx, ProfileQueriesMsg::ProviderEnd);\n+                    let ((result, dep_node_index), diagnostics) = res;\n+\n+                    tcx.dep_graph.read_index(dep_node_index);\n+                    let value = QueryValue::new(result, dep_node_index, diagnostics);\n+\n+                    return Ok((&tcx.maps\n+                                    .$name\n+                                    .borrow_mut()\n+                                    .map\n+                                    .entry(key)\n+                                    .or_insert(value)\n+                                    .value).clone());\n+                }\n \n-                            tcx.dep_graph.with_task(dep_node, tcx, key, run_provider)\n-                        }\n+                if !dep_node.kind.is_input() {\n+                    use dep_graph::DepNodeColor;\n+                    if let Some(DepNodeColor::Green(dep_node_index)) = tcx.dep_graph\n+                                                                          .node_color(&dep_node) {\n+                        profq_msg!(tcx, ProfileQueriesMsg::CacheHit);\n+                        tcx.dep_graph.read_index(dep_node_index);\n+                        return Self::load_from_disk_and_cache_in_memory(tcx,\n+                                                                        key,\n+                                                                        span,\n+                                                                        dep_node_index)\n+                    }\n+\n+                    debug!(\"ty::queries::{}::try_get_with(key={:?}) - running try_mark_green\",\n+                           stringify!($name),\n+                           key);\n+\n+                    if let Some(dep_node_index) = tcx.dep_graph.try_mark_green(tcx, &dep_node) {\n+                        debug_assert!(tcx.dep_graph.is_green(dep_node_index));\n+                        profq_msg!(tcx, ProfileQueriesMsg::CacheHit);\n+                        tcx.dep_graph.read_index(dep_node_index);\n+                        return Self::load_from_disk_and_cache_in_memory(tcx,\n+                                                                        key,\n+                                                                        span,\n+                                                                        dep_node_index)\n+                    }\n+                }\n+\n+                match Self::force(tcx, key, span, dep_node) {\n+                    Ok((result, dep_node_index)) => {\n+                        tcx.dep_graph.read_index(dep_node_index);\n+                        Ok(result)\n+                    }\n+                    Err(e) => Err(e)\n+                }\n+            }\n+\n+            fn compute_result(tcx: TyCtxt<'a, $tcx, 'lcx>, key: $K) -> $V {\n+                let provider = tcx.maps.providers[key.map_crate()].$name;\n+                provider(tcx.global_tcx(), key)\n+            }\n+\n+            fn load_from_disk_and_cache_in_memory(tcx: TyCtxt<'a, $tcx, 'lcx>,\n+                                                  key: $K,\n+                                                  span: Span,\n+                                                  dep_node_index: DepNodeIndex)\n+                                                  -> Result<$V, CycleError<'a, $tcx>>\n+            {\n+                debug_assert!(tcx.dep_graph.is_green(dep_node_index));\n+\n+                // We don't do any caching yet, so recompute\n+                let (result, diagnostics) = tcx.cycle_check(span, Query::$name(key), || {\n+                    tcx.sess.diagnostic().track_diagnostics(|| {\n+                        // The dep-graph for this computation is already in place\n+                        tcx.dep_graph.with_ignore(|| {\n+                            Self::compute_result(tcx, key)\n+                        })\n+                    })\n+                })?;\n+\n+                if tcx.sess.opts.debugging_opts.query_dep_graph {\n+                    tcx.dep_graph.mark_loaded_from_cache(dep_node_index, true);\n+                }\n+\n+                let value = QueryValue::new(result, dep_node_index, diagnostics);\n+\n+                Ok((&tcx.maps\n+                         .$name\n+                         .borrow_mut()\n+                         .map\n+                         .entry(key)\n+                         .or_insert(value)\n+                         .value).clone())\n+            }\n+\n+            fn force(tcx: TyCtxt<'a, $tcx, 'lcx>,\n+                     key: $K,\n+                     span: Span,\n+                     dep_node: DepNode)\n+                     -> Result<($V, DepNodeIndex), CycleError<'a, $tcx>> {\n+                debug_assert!(tcx.dep_graph.node_color(&dep_node).is_none());\n+\n+                profq_msg!(tcx, ProfileQueriesMsg::ProviderBegin);\n+                let res = tcx.cycle_check(span, Query::$name(key), || {\n+                    tcx.sess.diagnostic().track_diagnostics(|| {\n+                        tcx.dep_graph.with_task(dep_node,\n+                                                tcx,\n+                                                key,\n+                                                Self::compute_result)\n                     })\n                 })?;\n                 profq_msg!(tcx, ProfileQueriesMsg::ProviderEnd);\n+\n                 let ((result, dep_node_index), diagnostics) = res;\n \n-                tcx.dep_graph.read_index(dep_node_index);\n-\n-                let value = QueryValue {\n-                    value: result,\n-                    index: dep_node_index,\n-                    diagnostics: if diagnostics.len() == 0 {\n-                        None\n-                    } else {\n-                        Some(Box::new(QueryDiagnostics {\n-                            diagnostics,\n-                            emitted_diagnostics: Cell::new(true),\n-                        }))\n-                    },\n-                };\n+                if tcx.sess.opts.debugging_opts.query_dep_graph {\n+                    tcx.dep_graph.mark_loaded_from_cache(dep_node_index, false);\n+                }\n+\n+                let value = QueryValue::new(result, dep_node_index, diagnostics);\n \n-                Ok(f(&tcx.maps\n+                Ok(((&tcx.maps\n                          .$name\n                          .borrow_mut()\n                          .map\n                          .entry(key)\n                          .or_insert(value)\n-                         .value))\n+                         .value).clone(),\n+                   dep_node_index))\n             }\n \n             pub fn try_get(tcx: TyCtxt<'a, $tcx, 'lcx>, span: Span, key: $K)\n                            -> Result<$V, DiagnosticBuilder<'a>> {\n-                match Self::try_get_with(tcx, span, key, Clone::clone) {\n+                match Self::try_get_with(tcx, span, key) {\n                     Ok(e) => Ok(e),\n                     Err(e) => Err(tcx.report_cycle(e)),\n                 }\n             }\n-\n-            pub fn force(tcx: TyCtxt<'a, $tcx, 'lcx>, span: Span, key: $K) {\n-                // Ignore dependencies, since we not reading the computed value\n-                let _task = tcx.dep_graph.in_ignore();\n-\n-                match Self::try_get_with(tcx, span, key, |_| ()) {\n-                    Ok(()) => {}\n-                    Err(e) => tcx.report_cycle(e).emit(),\n-                }\n-            }\n         })*\n \n         #[derive(Copy, Clone)]\n@@ -492,3 +602,264 @@ macro_rules! define_provider_struct {\n         }\n     };\n }\n+\n+pub fn force_from_dep_node<'a, 'gcx, 'lcx>(tcx: TyCtxt<'a, 'gcx, 'lcx>,\n+                                           dep_node: &DepNode)\n+                                           -> bool {\n+    use ty::maps::keys::Key;\n+    use hir::def_id::LOCAL_CRATE;\n+\n+    // We must avoid ever having to call force_from_dep_node() for a\n+    // DepNode::CodegenUnit:\n+    // Since we cannot reconstruct the query key of a DepNode::CodegenUnit, we\n+    // would always end up having to evaluate the first caller of the\n+    // `codegen_unit` query that *is* reconstructible. This might very well be\n+    // the `compile_codegen_unit` query, thus re-translating the whole CGU just\n+    // to re-trigger calling the `codegen_unit` query with the right key. At\n+    // that point we would already have re-done all the work we are trying to\n+    // avoid doing in the first place.\n+    // The solution is simple: Just explicitly call the `codegen_unit` query for\n+    // each CGU, right after partitioning. This way `try_mark_green` will always\n+    // hit the cache instead of having to go through `force_from_dep_node`.\n+    // This assertion makes sure, we actually keep applying the solution above.\n+    debug_assert!(dep_node.kind != DepKind::CodegenUnit,\n+                  \"calling force_from_dep_node() on DepKind::CodegenUnit\");\n+\n+    if !dep_node.kind.can_reconstruct_query_key() {\n+        return false\n+    }\n+\n+    macro_rules! def_id {\n+        () => {\n+            if let Some(def_id) = dep_node.extract_def_id(tcx) {\n+                def_id\n+            } else {\n+                // return from the whole function\n+                return false\n+            }\n+        }\n+    };\n+\n+    macro_rules! krate {\n+        () => { (def_id!()).krate }\n+    };\n+\n+    macro_rules! force {\n+        ($query:ident, $key:expr) => {\n+            {\n+                use $crate::util::common::{ProfileQueriesMsg, profq_msg};\n+\n+                // FIXME(eddyb) Get more valid Span's on queries.\n+                // def_span guard is necessary to prevent a recursive loop,\n+                // default_span calls def_span query internally.\n+                let span = if stringify!($query) != \"def_span\" {\n+                    $key.default_span(tcx)\n+                } else {\n+                    ::syntax_pos::DUMMY_SP\n+                };\n+\n+                profq_msg!(tcx,\n+                    ProfileQueriesMsg::QueryBegin(\n+                        span.data(),\n+                        ::ty::maps::QueryMsg::$query(profq_key!(tcx, $key))\n+                    )\n+                );\n+\n+                match ::ty::maps::queries::$query::force(tcx, $key, span, *dep_node) {\n+                    Ok(_) => {},\n+                    Err(e) => {\n+                        tcx.report_cycle(e).emit();\n+                    }\n+                }\n+            }\n+        }\n+    };\n+\n+    // FIXME(#45015): We should try move this boilerplate code into a macro\n+    //                somehow.\n+    match dep_node.kind {\n+        // These are inputs that are expected to be pre-allocated and that\n+        // should therefore always be red or green already\n+        DepKind::AllLocalTraitImpls |\n+        DepKind::Krate |\n+        DepKind::CrateMetadata |\n+        DepKind::HirBody |\n+        DepKind::Hir |\n+\n+        // This are anonymous nodes\n+        DepKind::IsCopy |\n+        DepKind::IsSized |\n+        DepKind::IsFreeze |\n+        DepKind::NeedsDrop |\n+        DepKind::Layout |\n+        DepKind::TraitSelect |\n+        DepKind::ConstEval |\n+\n+        // We don't have enough information to reconstruct the query key of\n+        // these\n+        DepKind::InstanceSymbolName |\n+        DepKind::MirShim |\n+        DepKind::BorrowCheckKrate |\n+        DepKind::Specializes |\n+        DepKind::ImplementationsOfTrait |\n+        DepKind::TypeParamPredicates |\n+        DepKind::CodegenUnit |\n+        DepKind::CompileCodegenUnit |\n+\n+        // These are just odd\n+        DepKind::Null |\n+        DepKind::WorkProduct => {\n+            bug!(\"force_from_dep_node() - Encountered {:?}\", dep_node.kind)\n+        }\n+\n+        // These are not queries\n+        DepKind::CoherenceCheckTrait |\n+        DepKind::ItemVarianceConstraints => {\n+            return false\n+        }\n+\n+        DepKind::RegionScopeTree => { force!(region_scope_tree, def_id!()); }\n+\n+        DepKind::Coherence => { force!(crate_inherent_impls, LOCAL_CRATE); }\n+        DepKind::CoherenceInherentImplOverlapCheck => {\n+            force!(crate_inherent_impls_overlap_check, LOCAL_CRATE)\n+        },\n+        DepKind::PrivacyAccessLevels => { force!(privacy_access_levels, LOCAL_CRATE); }\n+        DepKind::MirConstQualif => { force!(mir_const_qualif, def_id!()); }\n+        DepKind::MirConst => { force!(mir_const, def_id!()); }\n+        DepKind::MirValidated => { force!(mir_validated, def_id!()); }\n+        DepKind::MirOptimized => { force!(optimized_mir, def_id!()); }\n+\n+        DepKind::BorrowCheck => { force!(borrowck, def_id!()); }\n+        DepKind::MirBorrowCheck => { force!(mir_borrowck, def_id!()); }\n+        DepKind::UnsafetyViolations => { force!(unsafety_violations, def_id!()); }\n+        DepKind::Reachability => { force!(reachable_set, LOCAL_CRATE); }\n+        DepKind::MirKeys => { force!(mir_keys, LOCAL_CRATE); }\n+        DepKind::CrateVariances => { force!(crate_variances, LOCAL_CRATE); }\n+        DepKind::AssociatedItems => { force!(associated_item, def_id!()); }\n+        DepKind::TypeOfItem => { force!(type_of, def_id!()); }\n+        DepKind::GenericsOfItem => { force!(generics_of, def_id!()); }\n+        DepKind::PredicatesOfItem => { force!(predicates_of, def_id!()); }\n+        DepKind::SuperPredicatesOfItem => { force!(super_predicates_of, def_id!()); }\n+        DepKind::TraitDefOfItem => { force!(trait_def, def_id!()); }\n+        DepKind::AdtDefOfItem => { force!(adt_def, def_id!()); }\n+        DepKind::IsDefaultImpl => { force!(is_default_impl, def_id!()); }\n+        DepKind::ImplTraitRef => { force!(impl_trait_ref, def_id!()); }\n+        DepKind::ImplPolarity => { force!(impl_polarity, def_id!()); }\n+        DepKind::ClosureKind => { force!(closure_kind, def_id!()); }\n+        DepKind::FnSignature => { force!(fn_sig, def_id!()); }\n+        DepKind::GenSignature => { force!(generator_sig, def_id!()); }\n+        DepKind::CoerceUnsizedInfo => { force!(coerce_unsized_info, def_id!()); }\n+        DepKind::ItemVariances => { force!(variances_of, def_id!()); }\n+        DepKind::IsConstFn => { force!(is_const_fn, def_id!()); }\n+        DepKind::IsForeignItem => { force!(is_foreign_item, def_id!()); }\n+        DepKind::SizedConstraint => { force!(adt_sized_constraint, def_id!()); }\n+        DepKind::DtorckConstraint => { force!(adt_dtorck_constraint, def_id!()); }\n+        DepKind::AdtDestructor => { force!(adt_destructor, def_id!()); }\n+        DepKind::AssociatedItemDefIds => { force!(associated_item_def_ids, def_id!()); }\n+        DepKind::InherentImpls => { force!(inherent_impls, def_id!()); }\n+        DepKind::TypeckBodiesKrate => { force!(typeck_item_bodies, LOCAL_CRATE); }\n+        DepKind::TypeckTables => { force!(typeck_tables_of, def_id!()); }\n+        DepKind::HasTypeckTables => { force!(has_typeck_tables, def_id!()); }\n+        DepKind::SymbolName => { force!(def_symbol_name, def_id!()); }\n+        DepKind::SpecializationGraph => { force!(specialization_graph_of, def_id!()); }\n+        DepKind::ObjectSafety => { force!(is_object_safe, def_id!()); }\n+        DepKind::TraitImpls => { force!(trait_impls_of, def_id!()); }\n+\n+        DepKind::ParamEnv => { force!(param_env, def_id!()); }\n+        DepKind::DescribeDef => { force!(describe_def, def_id!()); }\n+        DepKind::DefSpan => { force!(def_span, def_id!()); }\n+        DepKind::LookupStability => { force!(lookup_stability, def_id!()); }\n+        DepKind::LookupDeprecationEntry => {\n+            force!(lookup_deprecation_entry, def_id!());\n+        }\n+        DepKind::ItemBodyNestedBodies => { force!(item_body_nested_bodies, def_id!()); }\n+        DepKind::ConstIsRvaluePromotableToStatic => {\n+            force!(const_is_rvalue_promotable_to_static, def_id!());\n+        }\n+        DepKind::ImplParent => { force!(impl_parent, def_id!()); }\n+        DepKind::TraitOfItem => { force!(trait_of_item, def_id!()); }\n+        DepKind::IsExportedSymbol => { force!(is_exported_symbol, def_id!()); }\n+        DepKind::IsMirAvailable => { force!(is_mir_available, def_id!()); }\n+        DepKind::ItemAttrs => { force!(item_attrs, def_id!()); }\n+        DepKind::FnArgNames => { force!(fn_arg_names, def_id!()); }\n+        DepKind::DylibDepFormats => { force!(dylib_dependency_formats, krate!()); }\n+        DepKind::IsPanicRuntime => { force!(is_panic_runtime, krate!()); }\n+        DepKind::IsCompilerBuiltins => { force!(is_compiler_builtins, krate!()); }\n+        DepKind::HasGlobalAllocator => { force!(has_global_allocator, krate!()); }\n+        DepKind::ExternCrate => { force!(extern_crate, def_id!()); }\n+        DepKind::LintLevels => { force!(lint_levels, LOCAL_CRATE); }\n+        DepKind::InScopeTraits => { force!(in_scope_traits_map, def_id!().index); }\n+        DepKind::ModuleExports => { force!(module_exports, def_id!()); }\n+        DepKind::IsSanitizerRuntime => { force!(is_sanitizer_runtime, krate!()); }\n+        DepKind::IsProfilerRuntime => { force!(is_profiler_runtime, krate!()); }\n+        DepKind::GetPanicStrategy => { force!(panic_strategy, krate!()); }\n+        DepKind::IsNoBuiltins => { force!(is_no_builtins, krate!()); }\n+        DepKind::ImplDefaultness => { force!(impl_defaultness, def_id!()); }\n+        DepKind::ExportedSymbolIds => { force!(exported_symbol_ids, krate!()); }\n+        DepKind::NativeLibraries => { force!(native_libraries, krate!()); }\n+        DepKind::PluginRegistrarFn => { force!(plugin_registrar_fn, krate!()); }\n+        DepKind::DeriveRegistrarFn => { force!(derive_registrar_fn, krate!()); }\n+        DepKind::CrateDisambiguator => { force!(crate_disambiguator, krate!()); }\n+        DepKind::CrateHash => { force!(crate_hash, krate!()); }\n+        DepKind::OriginalCrateName => { force!(original_crate_name, krate!()); }\n+\n+        DepKind::AllTraitImplementations => {\n+            force!(all_trait_implementations, krate!());\n+        }\n+\n+        DepKind::IsDllimportForeignItem => {\n+            force!(is_dllimport_foreign_item, def_id!());\n+        }\n+        DepKind::IsStaticallyIncludedForeignItem => {\n+            force!(is_statically_included_foreign_item, def_id!());\n+        }\n+        DepKind::NativeLibraryKind => { force!(native_library_kind, def_id!()); }\n+        DepKind::LinkArgs => { force!(link_args, LOCAL_CRATE); }\n+\n+        DepKind::NamedRegion => { force!(named_region_map, def_id!().index); }\n+        DepKind::IsLateBound => { force!(is_late_bound_map, def_id!().index); }\n+        DepKind::ObjectLifetimeDefaults => {\n+            force!(object_lifetime_defaults_map, def_id!().index);\n+        }\n+\n+        DepKind::Visibility => { force!(visibility, def_id!()); }\n+        DepKind::DepKind => { force!(dep_kind, krate!()); }\n+        DepKind::CrateName => { force!(crate_name, krate!()); }\n+        DepKind::ItemChildren => { force!(item_children, def_id!()); }\n+        DepKind::ExternModStmtCnum => { force!(extern_mod_stmt_cnum, def_id!()); }\n+        DepKind::GetLangItems => { force!(get_lang_items, LOCAL_CRATE); }\n+        DepKind::DefinedLangItems => { force!(defined_lang_items, krate!()); }\n+        DepKind::MissingLangItems => { force!(missing_lang_items, krate!()); }\n+        DepKind::ExternConstBody => { force!(extern_const_body, def_id!()); }\n+        DepKind::VisibleParentMap => { force!(visible_parent_map, LOCAL_CRATE); }\n+        DepKind::MissingExternCrateItem => {\n+            force!(missing_extern_crate_item, krate!());\n+        }\n+        DepKind::UsedCrateSource => { force!(used_crate_source, krate!()); }\n+        DepKind::PostorderCnums => { force!(postorder_cnums, LOCAL_CRATE); }\n+        DepKind::HasCloneClosures => { force!(has_clone_closures, krate!()); }\n+        DepKind::HasCopyClosures => { force!(has_copy_closures, krate!()); }\n+\n+        DepKind::Freevars => { force!(freevars, def_id!()); }\n+        DepKind::MaybeUnusedTraitImport => {\n+            force!(maybe_unused_trait_import, def_id!());\n+        }\n+        DepKind::MaybeUnusedExternCrates => { force!(maybe_unused_extern_crates, LOCAL_CRATE); }\n+        DepKind::StabilityIndex => { force!(stability_index, LOCAL_CRATE); }\n+        DepKind::AllCrateNums => { force!(all_crate_nums, LOCAL_CRATE); }\n+        DepKind::ExportedSymbols => { force!(exported_symbols, krate!()); }\n+        DepKind::CollectAndPartitionTranslationItems => {\n+            force!(collect_and_partition_translation_items, LOCAL_CRATE);\n+        }\n+        DepKind::ExportName => { force!(export_name, def_id!()); }\n+        DepKind::ContainsExternIndicator => {\n+            force!(contains_extern_indicator, def_id!());\n+        }\n+        DepKind::IsTranslatedFunction => { force!(is_translated_function, def_id!()); }\n+        DepKind::OutputFilenames => { force!(output_filenames, LOCAL_CRATE); }\n+    }\n+\n+    true\n+}\n+"}, {"sha": "65e43a54833c888974eddfccf57460b580cdd6a0", "filename": "src/librustc/ty/mod.rs", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fty%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc%2Fty%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmod.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -1298,6 +1298,22 @@ impl<'tcx, T> ParamEnvAnd<'tcx, T> {\n     }\n }\n \n+impl<'gcx, T> HashStable<StableHashingContext<'gcx>> for ParamEnvAnd<'gcx, T>\n+    where T: HashStable<StableHashingContext<'gcx>>\n+{\n+    fn hash_stable<W: StableHasherResult>(&self,\n+                                          hcx: &mut StableHashingContext<'gcx>,\n+                                          hasher: &mut StableHasher<W>) {\n+        let ParamEnvAnd {\n+            ref param_env,\n+            ref value\n+        } = *self;\n+\n+        param_env.hash_stable(hcx, hasher);\n+        value.hash_stable(hcx, hasher);\n+    }\n+}\n+\n #[derive(Copy, Clone, Debug)]\n pub struct Destructor {\n     /// The def-id of the destructor method"}, {"sha": "ad6f7fbf1119bf97ca375583813afd9ba84d14e9", "filename": "src/librustc_driver/driver.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_driver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_driver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fdriver.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -642,8 +642,8 @@ pub fn phase_2_configure_and_expand<F>(sess: &Session,\n     );\n \n     let dep_graph = if sess.opts.build_dep_graph() {\n-        let prev_dep_graph = time(time_passes, \"load prev dep-graph (new)\", || {\n-            rustc_incremental::load_dep_graph_new(sess)\n+        let prev_dep_graph = time(time_passes, \"load prev dep-graph\", || {\n+            rustc_incremental::load_dep_graph(sess)\n         });\n \n         DepGraph::new(prev_dep_graph)\n@@ -1052,9 +1052,9 @@ pub fn phase_3_run_analysis_passes<'tcx, F, R>(sess: &'tcx Session,\n                              tx,\n                              output_filenames,\n                              |tcx| {\n-        time(time_passes,\n-             \"load_dep_graph\",\n-             || rustc_incremental::load_dep_graph(tcx));\n+        // Do some initialization of the DepGraph that can only be done with the\n+        // tcx available.\n+        rustc_incremental::dep_graph_tcx_init(tcx);\n \n         time(time_passes,\n              \"stability checking\","}, {"sha": "acbd3e0d63ddedf387ab9ae620739668df62f1a0", "filename": "src/librustc_incremental/assert_dep_graph.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fassert_dep_graph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fassert_dep_graph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fassert_dep_graph.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -209,7 +209,7 @@ fn check_paths<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     }\n     let query = tcx.dep_graph.query();\n     for &(_, source_def_id, ref source_dep_node) in if_this_changed {\n-        let dependents = query.transitive_successors(source_dep_node);\n+        let dependents = query.transitive_predecessors(source_dep_node);\n         for &(target_span, ref target_pass, _, ref target_dep_node) in then_this_would_need {\n             if !dependents.contains(&target_dep_node) {\n                 tcx.sess.span_err("}, {"sha": "0294adb3f5debc8efc8b95d2fa9a5513df7bdadf", "filename": "src/librustc_incremental/lib.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Flib.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -32,10 +32,11 @@ mod persist;\n \n pub use assert_dep_graph::assert_dep_graph;\n pub use persist::load_dep_graph;\n-pub use persist::load_dep_graph_new;\n+pub use persist::dep_graph_tcx_init;\n pub use persist::save_dep_graph;\n pub use persist::save_trans_partition;\n pub use persist::save_work_products;\n pub use persist::in_incr_comp_dir;\n pub use persist::prepare_session_directory;\n pub use persist::finalize_session_directory;\n+pub use persist::delete_workproduct_files;"}, {"sha": "fc417851b8897ac5f7be023411e5310f729ab482", "filename": "src/librustc_incremental/persist/data.rs", "status": "modified", "additions": 1, "deletions": 68, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -10,78 +10,11 @@\n \n //! The data that we will serialize and deserialize.\n \n-use rustc::dep_graph::{DepNode, WorkProduct, WorkProductId};\n+use rustc::dep_graph::{WorkProduct, WorkProductId};\n use rustc::hir::def_id::DefIndex;\n use rustc::hir::map::DefPathHash;\n-use rustc::ich::Fingerprint;\n use rustc::middle::cstore::EncodedMetadataHash;\n use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::indexed_vec::{IndexVec, Idx};\n-\n-/// Data for use when recompiling the **current crate**.\n-#[derive(Debug, RustcEncodable, RustcDecodable)]\n-pub struct SerializedDepGraph {\n-    /// The set of all DepNodes in the graph\n-    pub nodes: IndexVec<DepNodeIndex, DepNode>,\n-    /// For each DepNode, stores the list of edges originating from that\n-    /// DepNode. Encoded as a [start, end) pair indexing into edge_list_data,\n-    /// which holds the actual DepNodeIndices of the target nodes.\n-    pub edge_list_indices: IndexVec<DepNodeIndex, (u32, u32)>,\n-    /// A flattened list of all edge targets in the graph. Edge sources are\n-    /// implicit in edge_list_indices.\n-    pub edge_list_data: Vec<DepNodeIndex>,\n-\n-    /// These are output nodes that have no incoming edges. We track\n-    /// these separately so that when we reload all edges, we don't\n-    /// lose track of these nodes.\n-    pub bootstrap_outputs: Vec<DepNode>,\n-\n-    /// These are hashes of two things:\n-    /// - the HIR nodes in this crate\n-    /// - the metadata nodes from dependent crates we use\n-    ///\n-    /// In each case, we store a hash summarizing the contents of\n-    /// those items as they were at the time we did this compilation.\n-    /// In the case of HIR nodes, this hash is derived by walking the\n-    /// HIR itself. In the case of metadata nodes, the hash is loaded\n-    /// from saved state.\n-    ///\n-    /// When we do the next compile, we will load these back up and\n-    /// compare them against the hashes we see at that time, which\n-    /// will tell us what has changed, either in this crate or in some\n-    /// crate that we depend on.\n-    ///\n-    /// Because they will be reloaded, we don't store the DefId (which\n-    /// will be different when we next compile) related to each node,\n-    /// but rather the `DefPathIndex`. This can then be retraced\n-    /// to find the current def-id.\n-    pub hashes: Vec<(DepNodeIndex, Fingerprint)>,\n-}\n-\n-impl SerializedDepGraph {\n-    pub fn edge_targets_from(&self, source: DepNodeIndex) -> &[DepNodeIndex] {\n-        let targets = self.edge_list_indices[source];\n-        &self.edge_list_data[targets.0 as usize .. targets.1 as usize]\n-    }\n-}\n-\n-/// The index of a DepNode in the SerializedDepGraph::nodes array.\n-#[derive(Copy, Clone, Hash, Eq, PartialEq, Ord, PartialOrd, Debug,\n-         RustcEncodable, RustcDecodable)]\n-pub struct DepNodeIndex(pub u32);\n-\n-impl Idx for DepNodeIndex {\n-    #[inline]\n-    fn new(idx: usize) -> Self {\n-        assert!(idx <= ::std::u32::MAX as usize);\n-        DepNodeIndex(idx as u32)\n-    }\n-\n-    #[inline]\n-    fn index(self) -> usize {\n-        self.0 as usize\n-    }\n-}\n \n #[derive(Debug, RustcEncodable, RustcDecodable)]\n pub struct SerializedWorkProduct {"}, {"sha": "33a9cb58c517f8afcc628ee58fdedc615304e604", "filename": "src/librustc_incremental/persist/dirty_clean.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fdirty_clean.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fdirty_clean.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fdirty_clean.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -122,7 +122,7 @@ impl<'a, 'tcx> DirtyCleanVisitor<'a, 'tcx> {\n         let current_fingerprint = self.tcx.dep_graph.fingerprint_of(&dep_node);\n         let prev_fingerprint = self.tcx.dep_graph.prev_fingerprint_of(&dep_node);\n \n-        if current_fingerprint == prev_fingerprint {\n+        if Some(current_fingerprint) == prev_fingerprint {\n             let dep_node_str = self.dep_node_str(&dep_node);\n             self.tcx.sess.span_err(\n                 item_span,\n@@ -136,7 +136,7 @@ impl<'a, 'tcx> DirtyCleanVisitor<'a, 'tcx> {\n         let current_fingerprint = self.tcx.dep_graph.fingerprint_of(&dep_node);\n         let prev_fingerprint = self.tcx.dep_graph.prev_fingerprint_of(&dep_node);\n \n-        if current_fingerprint != prev_fingerprint {\n+        if Some(current_fingerprint) != prev_fingerprint {\n             let dep_node_str = self.dep_node_str(&dep_node);\n             self.tcx.sess.span_err(\n                 item_span,"}, {"sha": "9b12b755581d5f2b1de69b00fdfad710cc17f7d7", "filename": "src/librustc_incremental/persist/fs.rs", "status": "modified", "additions": 0, "deletions": 5, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Ffs.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -129,7 +129,6 @@ use std::__rand::{thread_rng, Rng};\n \n const LOCK_FILE_EXT: &'static str = \".lock\";\n const DEP_GRAPH_FILENAME: &'static str = \"dep-graph.bin\";\n-const DEP_GRAPH_NEW_FILENAME: &'static str = \"dep-graph-new.bin\";\n const WORK_PRODUCTS_FILENAME: &'static str = \"work-products.bin\";\n const METADATA_HASHES_FILENAME: &'static str = \"metadata.bin\";\n \n@@ -143,10 +142,6 @@ pub fn dep_graph_path(sess: &Session) -> PathBuf {\n     in_incr_comp_dir_sess(sess, DEP_GRAPH_FILENAME)\n }\n \n-pub fn dep_graph_path_new(sess: &Session) -> PathBuf {\n-    in_incr_comp_dir_sess(sess, DEP_GRAPH_NEW_FILENAME)\n-}\n-\n pub fn work_products_path(sess: &Session) -> PathBuf {\n     in_incr_comp_dir_sess(sess, WORK_PRODUCTS_FILENAME)\n }"}, {"sha": "cdfc9f2edc3f5aea9db688851a52f0d14fbb5c83", "filename": "src/librustc_incremental/persist/load.rs", "status": "modified", "additions": 47, "deletions": 313, "changes": 360, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fload.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -10,63 +10,68 @@\n \n //! Code to save/load the dep-graph from files.\n \n-use rustc::dep_graph::{DepNode, WorkProductId, DepKind, PreviousDepGraph};\n+use rustc::dep_graph::{PreviousDepGraph, SerializedDepGraph};\n use rustc::hir::svh::Svh;\n use rustc::ich::Fingerprint;\n use rustc::session::Session;\n use rustc::ty::TyCtxt;\n use rustc::util::nodemap::DefIdMap;\n-use rustc_data_structures::fx::{FxHashSet, FxHashMap};\n-use rustc_data_structures::indexed_vec::IndexVec;\n use rustc_serialize::Decodable as RustcDecodable;\n use rustc_serialize::opaque::Decoder;\n-use std::path::{Path};\n+use std::path::Path;\n \n use super::data::*;\n use super::fs::*;\n use super::file_format;\n use super::work_product;\n \n-// The key is a dirty node. The value is **some** base-input that we\n-// can blame it on.\n-pub type DirtyNodes = FxHashMap<DepNodeIndex, DepNodeIndex>;\n-\n-/// If we are in incremental mode, and a previous dep-graph exists,\n-/// then load up those nodes/edges that are still valid into the\n-/// dep-graph for this session. (This is assumed to be running very\n-/// early in compilation, before we've really done any work, but\n-/// actually it doesn't matter all that much.) See `README.md` for\n-/// more general overview.\n-pub fn load_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n+pub fn dep_graph_tcx_init<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n+    if !tcx.dep_graph.is_fully_enabled() {\n+        return\n+    }\n+\n     tcx.allocate_metadata_dep_nodes();\n     tcx.precompute_in_scope_traits_hashes();\n-    if tcx.sess.incr_session_load_dep_graph() {\n-        let _ignore = tcx.dep_graph.in_ignore();\n-        load_dep_graph_if_exists(tcx);\n-    }\n-}\n \n-fn load_dep_graph_if_exists<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n-    let dep_graph_path = dep_graph_path(tcx.sess);\n-    let dep_graph_data = match load_data(tcx.sess, &dep_graph_path) {\n-        Some(p) => p,\n-        None => return // no file\n-    };\n+    if tcx.sess.incr_comp_session_dir_opt().is_none() {\n+        // If we are only building with -Zquery-dep-graph but without an actual\n+        // incr. comp. session directory, we exit here. Otherwise we'd fail\n+        // when trying to load work products.\n+        return\n+    }\n \n     let work_products_path = work_products_path(tcx.sess);\n-    let work_products_data = match load_data(tcx.sess, &work_products_path) {\n-        Some(p) => p,\n-        None => return // no file\n-    };\n+    if let Some(work_products_data) = load_data(tcx.sess, &work_products_path) {\n+        // Decode the list of work_products\n+        let mut work_product_decoder = Decoder::new(&work_products_data[..], 0);\n+        let work_products: Vec<SerializedWorkProduct> =\n+            RustcDecodable::decode(&mut work_product_decoder).unwrap_or_else(|e| {\n+                let msg = format!(\"Error decoding `work-products` from incremental \\\n+                                   compilation session directory: {}\", e);\n+                tcx.sess.fatal(&msg[..])\n+            });\n \n-    match decode_dep_graph(tcx, &dep_graph_data, &work_products_data) {\n-        Ok(dirty_nodes) => dirty_nodes,\n-        Err(err) => {\n-            tcx.sess.warn(\n-                &format!(\"decoding error in dep-graph from `{}` and `{}`: {}\",\n-                         dep_graph_path.display(),\n-                         work_products_path.display(),\n-                         err));\n+        for swp in work_products {\n+            let mut all_files_exist = true;\n+            for &(_, ref file_name) in swp.work_product.saved_files.iter() {\n+                let path = in_incr_comp_dir_sess(tcx.sess, file_name);\n+                if !path.exists() {\n+                    all_files_exist = false;\n+\n+                    if tcx.sess.opts.debugging_opts.incremental_info {\n+                        eprintln!(\"incremental: could not find file for work \\\n+                                   product: {}\", path.display());\n+                    }\n+                }\n+            }\n+\n+            if all_files_exist {\n+                debug!(\"reconcile_work_products: all files for {:?} exist\", swp);\n+                tcx.dep_graph.insert_previous_work_product(&swp.id, swp.work_product);\n+            } else {\n+                debug!(\"reconcile_work_products: some file for {:?} does not exist\", swp);\n+                delete_dirty_work_product(tcx, swp);\n+            }\n         }\n     }\n }\n@@ -94,201 +99,6 @@ fn load_data(sess: &Session, path: &Path) -> Option<Vec<u8>> {\n     None\n }\n \n-/// Check if a DepNode from the previous dep-graph refers to something that\n-/// still exists in the current compilation session. Only works for DepNode\n-/// variants that represent inputs (HIR and imported Metadata).\n-fn does_still_exist(tcx: TyCtxt, dep_node: &DepNode) -> bool {\n-    match dep_node.kind {\n-        DepKind::Hir |\n-        DepKind::HirBody |\n-        DepKind::InScopeTraits |\n-        DepKind::CrateMetadata => {\n-            dep_node.extract_def_id(tcx).is_some()\n-        }\n-        _ => {\n-            bug!(\"unexpected Input DepNode: {:?}\", dep_node)\n-        }\n-    }\n-}\n-\n-/// Decode the dep graph and load the edges/nodes that are still clean\n-/// into `tcx.dep_graph`.\n-pub fn decode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                  dep_graph_data: &[u8],\n-                                  work_products_data: &[u8])\n-                                  -> Result<(), String>\n-{\n-    // Decode the list of work_products\n-    let mut work_product_decoder = Decoder::new(work_products_data, 0);\n-    let work_products = <Vec<SerializedWorkProduct>>::decode(&mut work_product_decoder)?;\n-\n-    // Deserialize the directory and dep-graph.\n-    let mut dep_graph_decoder = Decoder::new(dep_graph_data, 0);\n-    let prev_commandline_args_hash = u64::decode(&mut dep_graph_decoder)?;\n-\n-    if prev_commandline_args_hash != tcx.sess.opts.dep_tracking_hash() {\n-        if tcx.sess.opts.debugging_opts.incremental_info {\n-            eprintln!(\"incremental: completely ignoring cache because of \\\n-                       differing commandline arguments\");\n-        }\n-        // We can't reuse the cache, purge it.\n-        debug!(\"decode_dep_graph: differing commandline arg hashes\");\n-        for swp in work_products {\n-            delete_dirty_work_product(tcx, swp);\n-        }\n-\n-        // No need to do any further work\n-        return Ok(());\n-    }\n-\n-    let serialized_dep_graph = SerializedDepGraph::decode(&mut dep_graph_decoder)?;\n-\n-    // Compute the set of nodes from the old graph where some input\n-    // has changed or been removed.\n-    let dirty_raw_nodes = initial_dirty_nodes(tcx,\n-                                              &serialized_dep_graph.nodes,\n-                                              &serialized_dep_graph.hashes);\n-    let dirty_raw_nodes = transitive_dirty_nodes(&serialized_dep_graph,\n-                                                 dirty_raw_nodes);\n-\n-    // Recreate the edges in the graph that are still clean.\n-    let mut clean_work_products = FxHashSet();\n-    let mut dirty_work_products = FxHashSet(); // incomplete; just used to suppress debug output\n-    for (source, targets) in serialized_dep_graph.edge_list_indices.iter_enumerated() {\n-        let target_begin = targets.0 as usize;\n-        let target_end = targets.1 as usize;\n-\n-        for &target in &serialized_dep_graph.edge_list_data[target_begin .. target_end] {\n-            process_edge(tcx,\n-                         source,\n-                         target,\n-                         &serialized_dep_graph.nodes,\n-                         &dirty_raw_nodes,\n-                         &mut clean_work_products,\n-                         &mut dirty_work_products,\n-                         &work_products);\n-        }\n-    }\n-\n-    // Recreate bootstrap outputs, which are outputs that have no incoming edges\n-    // (and hence cannot be dirty).\n-    for bootstrap_output in &serialized_dep_graph.bootstrap_outputs {\n-        if let DepKind::WorkProduct = bootstrap_output.kind {\n-            let wp_id = WorkProductId::from_fingerprint(bootstrap_output.hash);\n-            clean_work_products.insert(wp_id);\n-        }\n-\n-        tcx.dep_graph.add_node_directly(*bootstrap_output);\n-    }\n-\n-    // Add in work-products that are still clean, and delete those that are\n-    // dirty.\n-    reconcile_work_products(tcx, work_products, &clean_work_products);\n-\n-    Ok(())\n-}\n-\n-/// Computes which of the original set of def-ids are dirty. Stored in\n-/// a bit vector where the index is the DefPathIndex.\n-fn initial_dirty_nodes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                 nodes: &IndexVec<DepNodeIndex, DepNode>,\n-                                 serialized_hashes: &[(DepNodeIndex, Fingerprint)])\n-                                 -> DirtyNodes {\n-    let mut dirty_nodes = FxHashMap();\n-\n-    for &(dep_node_index, prev_hash) in serialized_hashes {\n-        let dep_node = nodes[dep_node_index];\n-        if does_still_exist(tcx, &dep_node) {\n-            let current_hash = tcx.dep_graph.fingerprint_of(&dep_node);\n-\n-            if current_hash == prev_hash {\n-                debug!(\"initial_dirty_nodes: {:?} is clean (hash={:?})\",\n-                       dep_node,\n-                       current_hash);\n-                continue;\n-            }\n-\n-            if tcx.sess.opts.debugging_opts.incremental_dump_hash {\n-                println!(\"node {:?} is dirty as hash is {:?}, was {:?}\",\n-                         dep_node,\n-                         current_hash,\n-                         prev_hash);\n-            }\n-\n-            debug!(\"initial_dirty_nodes: {:?} is dirty as hash is {:?}, was {:?}\",\n-                   dep_node,\n-                   current_hash,\n-                   prev_hash);\n-        } else {\n-            if tcx.sess.opts.debugging_opts.incremental_dump_hash {\n-                println!(\"node {:?} is dirty as it was removed\", dep_node);\n-            }\n-\n-            debug!(\"initial_dirty_nodes: {:?} is dirty as it was removed\", dep_node);\n-        }\n-        dirty_nodes.insert(dep_node_index, dep_node_index);\n-    }\n-\n-    dirty_nodes\n-}\n-\n-fn transitive_dirty_nodes(serialized_dep_graph: &SerializedDepGraph,\n-                          mut dirty_nodes: DirtyNodes)\n-                          -> DirtyNodes\n-{\n-    let mut stack: Vec<(DepNodeIndex, DepNodeIndex)> = vec![];\n-    stack.extend(dirty_nodes.iter().map(|(&s, &b)| (s, b)));\n-    while let Some((source, blame)) = stack.pop() {\n-        // we know the source is dirty (because of the node `blame`)...\n-        debug_assert!(dirty_nodes.contains_key(&source));\n-\n-        // ...so we dirty all the targets (with the same blame)\n-        for &target in serialized_dep_graph.edge_targets_from(source) {\n-            if !dirty_nodes.contains_key(&target) {\n-                dirty_nodes.insert(target, blame);\n-                stack.push((target, blame));\n-            }\n-        }\n-    }\n-    dirty_nodes\n-}\n-\n-/// Go through the list of work-products produced in the previous run.\n-/// Delete any whose nodes have been found to be dirty or which are\n-/// otherwise no longer applicable.\n-fn reconcile_work_products<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                     work_products: Vec<SerializedWorkProduct>,\n-                                     clean_work_products: &FxHashSet<WorkProductId>) {\n-    debug!(\"reconcile_work_products({:?})\", work_products);\n-    for swp in work_products {\n-        if !clean_work_products.contains(&swp.id) {\n-            debug!(\"reconcile_work_products: dep-node for {:?} is dirty\", swp);\n-            delete_dirty_work_product(tcx, swp);\n-        } else {\n-            let mut all_files_exist = true;\n-            for &(_, ref file_name) in swp.work_product.saved_files.iter() {\n-                let path = in_incr_comp_dir_sess(tcx.sess, file_name);\n-                if !path.exists() {\n-                    all_files_exist = false;\n-\n-                    if tcx.sess.opts.debugging_opts.incremental_info {\n-                        eprintln!(\"incremental: could not find file for \\\n-                                   up-to-date work product: {}\", path.display());\n-                    }\n-                }\n-            }\n-\n-            if all_files_exist {\n-                debug!(\"reconcile_work_products: all files for {:?} exist\", swp);\n-                tcx.dep_graph.insert_previous_work_product(&swp.id, swp.work_product);\n-            } else {\n-                debug!(\"reconcile_work_products: some file for {:?} does not exist\", swp);\n-                delete_dirty_work_product(tcx, swp);\n-            }\n-        }\n-    }\n-}\n-\n fn delete_dirty_work_product(tcx: TyCtxt,\n                              swp: SerializedWorkProduct) {\n     debug!(\"delete_dirty_work_product({:?})\", swp);\n@@ -353,90 +163,14 @@ pub fn load_prev_metadata_hashes(tcx: TyCtxt) -> DefIdMap<Fingerprint> {\n     output\n }\n \n-fn process_edge<'a, 'tcx, 'edges>(\n-    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-    source: DepNodeIndex,\n-    target: DepNodeIndex,\n-    nodes: &IndexVec<DepNodeIndex, DepNode>,\n-    dirty_raw_nodes: &DirtyNodes,\n-    clean_work_products: &mut FxHashSet<WorkProductId>,\n-    dirty_work_products: &mut FxHashSet<WorkProductId>,\n-    work_products: &[SerializedWorkProduct])\n-{\n-    // If the target is dirty, skip the edge. If this is an edge\n-    // that targets a work-product, we can print the blame\n-    // information now.\n-    if let Some(&blame) = dirty_raw_nodes.get(&target) {\n-        let target = nodes[target];\n-        if let DepKind::WorkProduct = target.kind {\n-            if tcx.sess.opts.debugging_opts.incremental_info {\n-                let wp_id = WorkProductId::from_fingerprint(target.hash);\n-\n-                if dirty_work_products.insert(wp_id) {\n-                    // Try to reconstruct the human-readable version of the\n-                    // DepNode. This cannot be done for things that where\n-                    // removed.\n-                    let blame = nodes[blame];\n-                    let blame_str = if let Some(def_id) = blame.extract_def_id(tcx) {\n-                        format!(\"{:?}({})\",\n-                                blame.kind,\n-                                tcx.def_path(def_id).to_string(tcx))\n-                    } else {\n-                        format!(\"{:?}\", blame)\n-                    };\n-\n-                    let wp = work_products.iter().find(|swp| swp.id == wp_id).unwrap();\n-\n-                    eprintln!(\"incremental: module {:?} is dirty because \\\n-                              {:?} changed or was removed\",\n-                              wp.work_product.cgu_name,\n-                              blame_str);\n-                }\n-            }\n-        }\n-        return;\n-    }\n-\n-    // At this point we have asserted that the target is clean -- otherwise, we\n-    // would have hit the return above. We can do some further consistency\n-    // checks based on this fact:\n-\n-    // We should never have an edge where the target is clean but the source\n-    // was dirty. Otherwise something was wrong with the dirtying pass above:\n-    debug_assert!(!dirty_raw_nodes.contains_key(&source));\n-\n-    // We also never should encounter an edge going from a removed input to a\n-    // clean target because removing the input would have dirtied the input\n-    // node and transitively dirtied the target.\n-    debug_assert!(match nodes[source].kind {\n-        DepKind::Hir | DepKind::HirBody | DepKind::CrateMetadata => {\n-            does_still_exist(tcx, &nodes[source])\n-        }\n-        _ => true,\n-    });\n-\n-    if !dirty_raw_nodes.contains_key(&target) {\n-        let target = nodes[target];\n-        let source = nodes[source];\n-        tcx.dep_graph.add_edge_directly(source, target);\n-\n-        if let DepKind::WorkProduct = target.kind {\n-            let wp_id = WorkProductId::from_fingerprint(target.hash);\n-            clean_work_products.insert(wp_id);\n-        }\n-    }\n-}\n-\n-pub fn load_dep_graph_new(sess: &Session) -> PreviousDepGraph {\n-    use rustc::dep_graph::SerializedDepGraph as SerializedDepGraphNew;\n-\n-    let empty = PreviousDepGraph::new(SerializedDepGraphNew::new());\n+pub fn load_dep_graph(sess: &Session) -> PreviousDepGraph {\n+    let empty = PreviousDepGraph::new(SerializedDepGraph::new());\n \n     if sess.opts.incremental.is_none() {\n         return empty\n     }\n \n-    if let Some(bytes) = load_data(sess, &dep_graph_path_new(sess)) {\n+    if let Some(bytes) = load_data(sess, &dep_graph_path(sess)) {\n         let mut decoder = Decoder::new(&bytes, 0);\n         let prev_commandline_args_hash = u64::decode(&mut decoder)\n             .expect(\"Error reading commandline arg hash from cached dep-graph\");\n@@ -453,7 +187,7 @@ pub fn load_dep_graph_new(sess: &Session) -> PreviousDepGraph {\n             return empty\n         }\n \n-        let dep_graph = SerializedDepGraphNew::decode(&mut decoder)\n+        let dep_graph = SerializedDepGraph::decode(&mut decoder)\n             .expect(\"Error reading cached dep-graph\");\n \n         PreviousDepGraph::new(dep_graph)"}, {"sha": "88d49e7aedca7d03a781c638fda565fd9e216a1f", "filename": "src/librustc_incremental/persist/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -16,7 +16,6 @@ mod data;\n mod dirty_clean;\n mod fs;\n mod load;\n-mod preds;\n mod save;\n mod work_product;\n mod file_format;\n@@ -25,7 +24,8 @@ pub use self::fs::prepare_session_directory;\n pub use self::fs::finalize_session_directory;\n pub use self::fs::in_incr_comp_dir;\n pub use self::load::load_dep_graph;\n-pub use self::load::load_dep_graph_new;\n+pub use self::load::dep_graph_tcx_init;\n pub use self::save::save_dep_graph;\n pub use self::save::save_work_products;\n pub use self::work_product::save_trans_partition;\n+pub use self::work_product::delete_workproduct_files;"}, {"sha": "d2aa245c7c9424633718f3eadfe052b8accc5083", "filename": "src/librustc_incremental/persist/preds/compress/README.md", "status": "removed", "additions": 0, "deletions": 48, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2FREADME.md?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,48 +0,0 @@\n-Graph compression\n-\n-The graph compression algorithm is intended to remove and minimize the\n-size of the dependency graph so it can be saved, while preserving\n-everything we care about. In particular, given a set of input/output\n-nodes in the graph (which must be disjoint), we ensure that the set of\n-input nodes that can reach a given output node does not change,\n-although the intermediate nodes may change in various ways. In short,\n-the output nodes are intended to be the ones whose existence we care\n-about when we start up, because they have some associated data that we\n-will try to re-use (and hence if they are dirty, we have to throw that\n-data away). The other intermediate nodes don't really matter so much.\n-\n-### Overview\n-\n-The algorithm works as follows:\n-\n-1. Do a single walk of the graph to construct a DAG\n-    - in this walk, we identify and unify all cycles, electing a representative \"head\" node\n-    - this is done using the union-find implementation\n-    - this code is found in the `classify` module\n-2. The result from this walk is a `Dag`: \n-   - the set of SCCs, represented by the union-find table\n-   - a set of edges in the new DAG, represented by:\n-     - a vector of parent nodes for each child node\n-     - a vector of cross-edges\n-     - once these are canonicalized, some of these edges may turn out to be cyclic edges\n-       (i.e., an edge A -> A where A is the head of some SCC)\n-3. We pass this `Dag` into the construct code, which then creates a\n-   new graph.  This graph has a smaller set of indices which includes\n-   *at least* the inputs/outputs from the original graph, but may have\n-   other nodes as well, if keeping them reduces the overall size of\n-   the graph.\n-   - This code is found in the `construct` module.\n-   \n-### Some notes\n-\n-The input graph is assumed to have *read-by* edges. i.e., `A -> B`\n-means that the task B reads data from A. But the DAG defined by\n-classify is expressed in terms of *reads-from* edges, which are the\n-inverse. So `A -> B` is the same as `B -rf-> A`. *reads-from* edges\n-are more natural since we want to walk from the outputs to the inputs,\n-effectively. When we construct the final graph, we reverse these edges\n-back into the *read-by* edges common elsewhere.\n-\n-   \n-   \n-   "}, {"sha": "aa29afd543c77f8f400ff256d3bf276f07334e53", "filename": "src/librustc_incremental/persist/preds/compress/classify/mod.rs", "status": "removed", "additions": 0, "deletions": 151, "changes": 151, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fclassify%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fclassify%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fclassify%2Fmod.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,151 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! First phase. Detect cycles and cross-edges.\n-\n-use super::*;\n-\n-#[cfg(test)]\n-mod test;\n-\n-pub struct Classify<'a, 'g: 'a, N: 'g, I: 'a, O: 'a>\n-    where N: Debug + Clone + 'g,\n-          I: Fn(&N) -> bool,\n-          O: Fn(&N) -> bool,\n-{\n-    r: &'a mut GraphReduce<'g, N, I, O>,\n-    stack: Vec<NodeIndex>,\n-    colors: Vec<Color>,\n-    dag: Dag,\n-}\n-\n-#[derive(Copy, Clone, Debug, PartialEq)]\n-enum Color {\n-    // not yet visited\n-    White,\n-\n-    // visiting; usize is index on stack\n-    Grey(usize),\n-\n-    // finished visiting\n-    Black,\n-}\n-\n-impl<'a, 'g, N, I, O> Classify<'a, 'g, N, I, O>\n-    where N: Debug + Clone + 'g,\n-          I: Fn(&N) -> bool,\n-          O: Fn(&N) -> bool,\n-{\n-    pub(super) fn new(r: &'a mut GraphReduce<'g, N, I, O>) -> Self {\n-        Classify {\n-            r,\n-            colors: vec![Color::White; r.in_graph.len_nodes()],\n-            stack: vec![],\n-            dag: Dag {\n-                parents: (0..r.in_graph.len_nodes()).map(|i| NodeIndex(i)).collect(),\n-                cross_edges: vec![],\n-                input_nodes: vec![],\n-                output_nodes: vec![],\n-            },\n-        }\n-    }\n-\n-    pub(super) fn walk(mut self) -> Dag {\n-        for (index, node) in self.r.in_graph.all_nodes().iter().enumerate() {\n-            if (self.r.is_output)(&node.data) {\n-                let index = NodeIndex(index);\n-                self.dag.output_nodes.push(index);\n-                match self.colors[index.0] {\n-                    Color::White => self.open(index),\n-                    Color::Grey(_) => panic!(\"grey node but have not yet started a walk\"),\n-                    Color::Black => (), // already visited, skip\n-                }\n-            }\n-        }\n-\n-        // At this point we've identifed all the cycles, and we've\n-        // constructed a spanning tree over the original graph\n-        // (encoded in `self.parents`) as well as a list of\n-        // cross-edges that reflect additional edges from the DAG.\n-        //\n-        // If we converted each node to its `cycle-head` (a\n-        // representative choice from each SCC, basically) and then\n-        // take the union of `self.parents` and `self.cross_edges`\n-        // (after canonicalization), that is basically our DAG.\n-        //\n-        // Note that both of those may well contain trivial `X -rf-> X`\n-        // cycle edges after canonicalization, though. e.g., if you\n-        // have a graph `{A -rf-> B, B -rf-> A}`, we will have unioned A and\n-        // B, but A will also be B's parent (or vice versa), and hence\n-        // when we canonicalize the parent edge it would become `A -rf->\n-        // A` (or `B -rf-> B`).\n-        self.dag\n-    }\n-\n-    fn open(&mut self, node: NodeIndex) {\n-        let index = self.stack.len();\n-        self.stack.push(node);\n-        self.colors[node.0] = Color::Grey(index);\n-        for child in self.r.inputs(node) {\n-            self.walk_edge(node, child);\n-        }\n-        self.stack.pop().unwrap();\n-        self.colors[node.0] = Color::Black;\n-\n-        if (self.r.is_input)(&self.r.in_graph.node_data(node)) {\n-            // base inputs should have no inputs\n-            assert!(self.r.inputs(node).next().is_none());\n-            debug!(\"input: `{:?}`\", self.r.in_graph.node_data(node));\n-            self.dag.input_nodes.push(node);\n-        }\n-    }\n-\n-    fn walk_edge(&mut self, parent: NodeIndex, child: NodeIndex) {\n-        debug!(\"walk_edge: {:?} -rf-> {:?}, {:?}\",\n-               self.r.in_graph.node_data(parent),\n-               self.r.in_graph.node_data(child),\n-               self.colors[child.0]);\n-\n-        // Ignore self-edges, just in case they exist.\n-        if child == parent {\n-            return;\n-        }\n-\n-        match self.colors[child.0] {\n-            Color::White => {\n-                // Not yet visited this node; start walking it.\n-                assert_eq!(self.dag.parents[child.0], child);\n-                self.dag.parents[child.0] = parent;\n-                self.open(child);\n-            }\n-\n-            Color::Grey(stack_index) => {\n-                // Back-edge; unify everything on stack between here and `stack_index`\n-                // since we are all participating in a cycle\n-                assert!(self.stack[stack_index] == child);\n-\n-                for &n in &self.stack[stack_index..] {\n-                    debug!(\"cycle `{:?}` and `{:?}`\",\n-                           self.r.in_graph.node_data(n),\n-                           self.r.in_graph.node_data(parent));\n-                    self.r.mark_cycle(n, parent);\n-                }\n-            }\n-\n-            Color::Black => {\n-                // Cross-edge, record and ignore\n-                self.dag.cross_edges.push((parent, child));\n-                debug!(\"cross-edge `{:?} -rf-> {:?}`\",\n-                       self.r.in_graph.node_data(parent),\n-                       self.r.in_graph.node_data(child));\n-            }\n-        }\n-    }\n-}"}, {"sha": "ca26f714a2a747aa978df35c5401d1dfdd46b9f8", "filename": "src/librustc_incremental/persist/preds/compress/classify/test.rs", "status": "removed", "additions": 0, "deletions": 94, "changes": 94, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fclassify%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fclassify%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fclassify%2Ftest.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,94 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use super::*;\n-\n-#[test]\n-fn detect_cycles() {\n-    let (graph, nodes) = graph! {\n-        A -> C0,\n-        A -> C1,\n-        B -> C1,\n-        C0 -> C1,\n-        C1 -> C0,\n-        C0 -> D,\n-        C1 -> E,\n-    };\n-    let inputs = [\"A\", \"B\"];\n-    let outputs = [\"D\", \"E\"];\n-    let mut reduce = GraphReduce::new(&graph, |n| inputs.contains(n), |n| outputs.contains(n));\n-    Classify::new(&mut reduce).walk();\n-\n-    assert!(!reduce.in_cycle(nodes(\"A\"), nodes(\"C0\")));\n-    assert!(!reduce.in_cycle(nodes(\"B\"), nodes(\"C0\")));\n-    assert!(reduce.in_cycle(nodes(\"C0\"), nodes(\"C1\")));\n-    assert!(!reduce.in_cycle(nodes(\"D\"), nodes(\"C0\")));\n-    assert!(!reduce.in_cycle(nodes(\"E\"), nodes(\"C0\")));\n-    assert!(!reduce.in_cycle(nodes(\"E\"), nodes(\"A\")));\n-}\n-\n-/// Regr test for a bug where we forgot to pop nodes off of the stack\n-/// as we were walking. In this case, because edges are pushed to the front\n-/// of the list, we would visit OUT, then A, then IN, and then close IN (but forget\n-/// to POP. Then visit B, C, and then A, which would mark everything from A to C as\n-/// cycle. But since we failed to pop IN, the stack was `OUT, A, IN, B, C` so that\n-/// marked C and IN as being in a cycle.\n-#[test]\n-fn edge_order1() {\n-    let (graph, nodes) = graph! {\n-        A -> C,\n-        C -> B,\n-        B -> A,\n-        IN -> B,\n-        IN -> A,\n-        A -> OUT,\n-    };\n-    let inputs = [\"IN\"];\n-    let outputs = [\"OUT\"];\n-    let mut reduce = GraphReduce::new(&graph, |n| inputs.contains(n), |n| outputs.contains(n));\n-    Classify::new(&mut reduce).walk();\n-\n-    // A, B, and C are mutually in a cycle, but IN/OUT are not participating.\n-    let names = [\"A\", \"B\", \"C\", \"IN\", \"OUT\"];\n-    let cycle_names = [\"A\", \"B\", \"C\"];\n-    for &i in &names {\n-        for &j in names.iter().filter(|&&j| j != i) {\n-            let in_cycle = cycle_names.contains(&i) && cycle_names.contains(&j);\n-            assert_eq!(reduce.in_cycle(nodes(i), nodes(j)), in_cycle,\n-                       \"cycle status for nodes {} and {} is incorrect\",\n-                       i, j);\n-        }\n-    }\n-}\n-\n-/// Same as `edge_order1` but in reverse order so as to detect a failure\n-/// if we were to enqueue edges onto end of list instead.\n-#[test]\n-fn edge_order2() {\n-    let (graph, nodes) = graph! {\n-        A -> OUT,\n-        IN -> A,\n-        IN -> B,\n-        B -> A,\n-        C -> B,\n-        A -> C,\n-    };\n-    let inputs = [\"IN\"];\n-    let outputs = [\"OUT\"];\n-    let mut reduce = GraphReduce::new(&graph, |n| inputs.contains(n), |n| outputs.contains(n));\n-    Classify::new(&mut reduce).walk();\n-\n-    assert!(reduce.in_cycle(nodes(\"B\"), nodes(\"C\")));\n-\n-    assert!(!reduce.in_cycle(nodes(\"IN\"), nodes(\"A\")));\n-    assert!(!reduce.in_cycle(nodes(\"IN\"), nodes(\"B\")));\n-    assert!(!reduce.in_cycle(nodes(\"IN\"), nodes(\"C\")));\n-    assert!(!reduce.in_cycle(nodes(\"IN\"), nodes(\"OUT\")));\n-}"}, {"sha": "0ad8d1789167df38a7cb9e0a882a64b42d7a2c65", "filename": "src/librustc_incremental/persist/preds/compress/construct.rs", "status": "removed", "additions": 0, "deletions": 223, "changes": 223, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fconstruct.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fconstruct.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fconstruct.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,223 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Second phase. Construct new graph. The previous phase has\n-//! converted the input graph into a DAG by detecting and unifying\n-//! cycles. It provides us with the following (which is a\n-//! representation of the DAG):\n-//!\n-//! - SCCs, in the form of a union-find repr that can convert each node to\n-//!   its *cycle head* (an arbitrarily chosen representative from the cycle)\n-//! - a vector of *leaf nodes*, just a convenience\n-//! - a vector of *parents* for each node (in some cases, nodes have no parents,\n-//!   or their parent is another member of same cycle; in that case, the vector\n-//!   will be stored `v[i] == i`, after canonicalization)\n-//! - a vector of *cross edges*, meaning add'l edges between graphs nodes beyond\n-//!   the parents.\n-\n-use rustc_data_structures::fx::FxHashMap;\n-\n-use super::*;\n-\n-pub(super) fn construct_graph<'g, N, I, O>(r: &mut GraphReduce<'g, N, I, O>, dag: Dag)\n-                                           -> Reduction<'g, N>\n-    where N: Debug + Clone, I: Fn(&N) -> bool, O: Fn(&N) -> bool,\n-{\n-    let Dag { parents: old_parents, input_nodes, output_nodes, cross_edges } = dag;\n-    let in_graph = r.in_graph;\n-\n-    debug!(\"construct_graph\");\n-\n-    // Create a canonical list of edges; this includes both parent and\n-    // cross-edges. We store this in `(target -> Vec<source>)` form.\n-    // We call the first edge to any given target its \"parent\".\n-    let mut edges = FxHashMap();\n-    let old_parent_edges = old_parents.iter().cloned().zip((0..).map(NodeIndex));\n-    for (source, target) in old_parent_edges.chain(cross_edges) {\n-        debug!(\"original edge `{:?} -rf-> {:?}`\",\n-               in_graph.node_data(source),\n-               in_graph.node_data(target));\n-        let source = r.cycle_head(source);\n-        let target = r.cycle_head(target);\n-        if source != target {\n-            let v = edges.entry(target).or_insert(vec![]);\n-            if !v.contains(&source) {\n-                debug!(\"edge `{:?} -rf-> {:?}` is edge #{} with that target\",\n-                       in_graph.node_data(source),\n-                       in_graph.node_data(target),\n-                       v.len());\n-                v.push(source);\n-            }\n-        }\n-    }\n-    let parent = |ni: NodeIndex| -> NodeIndex {\n-        edges[&ni][0]\n-    };\n-\n-    // `retain_map`: a map of those nodes that we will want to\n-    // *retain* in the ultimate graph; the key is the node index in\n-    // the old graph, the value is the node index in the new\n-    // graph. These are nodes in the following categories:\n-    //\n-    // - inputs\n-    // - work-products\n-    // - targets of a cross-edge\n-    //\n-    // The first two categories hopefully make sense. We want the\n-    // inputs so we can compare hashes later. We want the\n-    // work-products so we can tell precisely when a given\n-    // work-product is invalidated. But the last one isn't strictly\n-    // needed; we keep cross-target edges so as to minimize the total\n-    // graph size.\n-    //\n-    // Consider a graph like:\n-    //\n-    //     WP0 -rf-> Y\n-    //     WP1 -rf-> Y\n-    //     Y -rf-> INPUT0\n-    //     Y -rf-> INPUT1\n-    //     Y -rf-> INPUT2\n-    //     Y -rf-> INPUT3\n-    //\n-    // Now if we were to remove Y, we would have a total of 8 edges: both WP0 and WP1\n-    // depend on INPUT0...INPUT3. As it is, we have 6 edges.\n-    //\n-    // NB: The current rules are not optimal. For example, given this\n-    // input graph:\n-    //\n-    //     OUT0 -rf-> X\n-    //     OUT1 -rf-> X\n-    //     X -rf -> INPUT0\n-    //\n-    // we will preserve X because it has two \"consumers\" (OUT0 and\n-    // OUT1).  We could as easily skip it, but we'd have to tally up\n-    // the number of input nodes that it (transitively) reaches, and I\n-    // was too lazy to do so. This is the unit test `suboptimal`.\n-\n-    let mut retain_map = FxHashMap();\n-    let mut new_graph = Graph::new();\n-\n-    {\n-        // Start by adding start-nodes and inputs.\n-        let retained_nodes = output_nodes.iter().chain(&input_nodes).map(|&n| r.cycle_head(n));\n-\n-        // Next add in targets of cross-edges. Due to the canonicalization,\n-        // some of these may be self-edges or may may duplicate the parent\n-        // edges, so ignore those.\n-        let retained_nodes = retained_nodes.chain(\n-            edges.iter()\n-                 .filter(|&(_, ref sources)| sources.len() > 1)\n-                 .map(|(&target, _)| target));\n-\n-        // Now create the new graph, adding in the entries from the map.\n-        for n in retained_nodes {\n-            retain_map.entry(n)\n-                      .or_insert_with(|| {\n-                          let data = in_graph.node_data(n);\n-                          debug!(\"retaining node `{:?}`\", data);\n-                          new_graph.add_node(data)\n-                      });\n-        }\n-    }\n-\n-    // Given a cycle-head `ni`, converts it to the closest parent that has\n-    // been retained in the output graph.\n-    let retained_parent = |mut ni: NodeIndex| -> NodeIndex {\n-        loop {\n-            debug!(\"retained_parent({:?})\", in_graph.node_data(ni));\n-            match retain_map.get(&ni) {\n-                Some(&v) => return v,\n-                None => ni = parent(ni),\n-            }\n-        }\n-    };\n-\n-    // Now add in the edges into the graph.\n-    for (&target, sources) in &edges {\n-        if let Some(&r_target) = retain_map.get(&target) {\n-            debug!(\"adding edges that target `{:?}`\", in_graph.node_data(target));\n-            for &source in sources {\n-                debug!(\"new edge `{:?} -rf-> {:?}`\",\n-                       in_graph.node_data(source),\n-                       in_graph.node_data(target));\n-                let r_source = retained_parent(source);\n-\n-                // NB. In the input graph, we have `a -> b` if b\n-                // **reads from** a. But in the terminology of this\n-                // code, we would describe that edge as `b -> a`,\n-                // because we have edges *from* outputs *to* inputs.\n-                // Therefore, when we create our new graph, we have to\n-                // reverse the edge.\n-                new_graph.add_edge(r_target, r_source, ());\n-            }\n-        } else {\n-            assert_eq!(sources.len(), 1);\n-        }\n-    }\n-\n-    // One complication. In some cases, output nodes *may* participate in\n-    // cycles. An example:\n-    //\n-    //             [HIR0]                    [HIR1]\n-    //               |                         |\n-    //               v                         v\n-    //      TypeckClosureBody(X) -> ItemSignature(X::SomeClosureInX)\n-    //            |  ^                         | |\n-    //            |  +-------------------------+ |\n-    //            |                              |\n-    //            v                              v\n-    //           Foo                            Bar\n-    //\n-    // In these cases, the output node may not wind up as the head\n-    // of the cycle, in which case it would be absent from the\n-    // final graph. We don't wish this to happen, therefore we go\n-    // over the list of output nodes again and check for any that\n-    // are not their own cycle-head. If we find such a node, we\n-    // add it to the graph now with an edge from the cycle head.\n-    // So the graph above could get transformed into this:\n-    //\n-    //                                    [HIR0, HIR1]\n-    //                                         |\n-    //                                         v\n-    //      TypeckClosureBody(X)    ItemSignature(X::SomeClosureInX)\n-    //               ^                         | |\n-    //               +-------------------------+ |\n-    //                                           v\n-    //                                       [Foo, Bar]\n-    //\n-    // (Note that all the edges here are \"read-by\" edges, not\n-    // \"reads-from\" edges.)\n-    for &output_node in &output_nodes {\n-        let head = r.cycle_head(output_node);\n-        if output_node == head {\n-            assert!(retain_map.contains_key(&output_node));\n-        } else {\n-            assert!(!retain_map.contains_key(&output_node));\n-            let output_data = in_graph.node_data(output_node);\n-            let new_node = new_graph.add_node(output_data);\n-            let new_head_node = retain_map[&head];\n-            new_graph.add_edge(new_head_node, new_node, ());\n-        }\n-    }\n-\n-    // Finally, prepare a list of the input node indices as found in\n-    // the new graph. Note that since all input nodes are leaves in\n-    // the graph, they should never participate in a cycle.\n-    let input_nodes =\n-        input_nodes.iter()\n-                   .map(|&n| {\n-                       assert_eq!(r.cycle_head(n), n, \"input node participating in a cycle\");\n-                       retain_map[&n]\n-                   })\n-                   .collect();\n-\n-    Reduction { graph: new_graph, input_nodes: input_nodes }\n-}\n-"}, {"sha": "a286862e9551f9d9a468e9c6f26d12157173c939", "filename": "src/librustc_incremental/persist/preds/compress/dag_id.rs", "status": "removed", "additions": 0, "deletions": 43, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fdag_id.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fdag_id.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fdag_id.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,43 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use rustc_data_structures::graph::NodeIndex;\n-use rustc_data_structures::unify::UnifyKey;\n-\n-#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\n-pub struct DagId {\n-    index: u32,\n-}\n-\n-impl DagId {\n-    pub fn from_input_index(n: NodeIndex) -> Self {\n-        DagId { index: n.0 as u32 }\n-    }\n-\n-    pub fn as_input_index(&self) -> NodeIndex {\n-        NodeIndex(self.index as usize)\n-    }\n-}\n-\n-impl UnifyKey for DagId {\n-    type Value = ();\n-\n-    fn index(&self) -> u32 {\n-        self.index\n-    }\n-\n-    fn from_index(u: u32) -> Self {\n-        DagId { index: u }\n-    }\n-\n-    fn tag(_: Option<Self>) -> &'static str {\n-        \"DagId\"\n-    }\n-}"}, {"sha": "974a2221a4575bf6f35107c044a81c03492b97dc", "filename": "src/librustc_incremental/persist/preds/compress/mod.rs", "status": "removed", "additions": 0, "deletions": 125, "changes": 125, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Fmod.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,125 +0,0 @@\n-// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Graph compression. See `README.md`.\n-\n-use rustc_data_structures::graph::{Graph, NodeIndex};\n-use rustc_data_structures::unify::UnificationTable;\n-use std::fmt::Debug;\n-\n-#[cfg(test)]\n-#[macro_use]\n-mod test_macro;\n-\n-mod construct;\n-\n-mod classify;\n-use self::classify::Classify;\n-\n-mod dag_id;\n-use self::dag_id::DagId;\n-\n-#[cfg(test)]\n-mod test;\n-\n-pub fn reduce_graph<N, I, O>(graph: &Graph<N, ()>,\n-                             is_input: I,\n-                             is_output: O) -> Reduction<N>\n-    where N: Debug + Clone,\n-          I: Fn(&N) -> bool,\n-          O: Fn(&N) -> bool,\n-{\n-    GraphReduce::new(graph, is_input, is_output).compute()\n-}\n-\n-pub struct Reduction<'q, N> where N: 'q + Debug + Clone {\n-    pub graph: Graph<&'q N, ()>,\n-    pub input_nodes: Vec<NodeIndex>,\n-}\n-\n-struct GraphReduce<'q, N, I, O>\n-    where N: 'q + Debug + Clone,\n-          I: Fn(&N) -> bool,\n-          O: Fn(&N) -> bool,\n-{\n-    in_graph: &'q Graph<N, ()>,\n-    unify: UnificationTable<DagId>,\n-    is_input: I,\n-    is_output: O,\n-}\n-\n-struct Dag {\n-    // The \"parent\" of a node is the node which reached it during the\n-    // initial DFS. To encode the case of \"no parent\" (i.e., for the\n-    // roots of the walk), we make `parents[i] == i` to start, which\n-    // turns out be convenient.\n-    parents: Vec<NodeIndex>,\n-\n-    // Additional edges beyond the parents.\n-    cross_edges: Vec<(NodeIndex, NodeIndex)>,\n-\n-    // Nodes which we found that are considered \"outputs\"\n-    output_nodes: Vec<NodeIndex>,\n-\n-    // Nodes which we found that are considered \"inputs\"\n-    input_nodes: Vec<NodeIndex>,\n-}\n-\n-#[derive(Copy, Clone, PartialEq, Eq, Hash)]\n-struct DagNode {\n-    in_index: NodeIndex\n-}\n-\n-impl<'q, N, I, O> GraphReduce<'q, N, I, O>\n-    where N: Debug + Clone,\n-          I: Fn(&N) -> bool,\n-          O: Fn(&N) -> bool,\n-{\n-    fn new(in_graph: &'q Graph<N, ()>, is_input: I, is_output: O) -> Self {\n-        let mut unify = UnificationTable::new();\n-\n-        // create a set of unification keys whose indices\n-        // correspond to the indices from the input graph\n-        for i in 0..in_graph.len_nodes() {\n-            let k = unify.new_key(());\n-            assert!(k == DagId::from_input_index(NodeIndex(i)));\n-        }\n-\n-        GraphReduce { in_graph, unify, is_input, is_output }\n-    }\n-\n-    fn compute(mut self) -> Reduction<'q, N> {\n-        let dag = Classify::new(&mut self).walk();\n-        construct::construct_graph(&mut self, dag)\n-    }\n-\n-    fn inputs(&self, in_node: NodeIndex) -> impl Iterator<Item = NodeIndex> + 'q {\n-        self.in_graph.predecessor_nodes(in_node)\n-    }\n-\n-    fn mark_cycle(&mut self, in_node1: NodeIndex, in_node2: NodeIndex) {\n-        let dag_id1 = DagId::from_input_index(in_node1);\n-        let dag_id2 = DagId::from_input_index(in_node2);\n-        self.unify.union(dag_id1, dag_id2);\n-    }\n-\n-    /// Convert a dag-id into its cycle head representative. This will\n-    /// be a no-op unless `in_node` participates in a cycle, in which\n-    /// case a distinct node *may* be returned.\n-    fn cycle_head(&mut self, in_node: NodeIndex) -> NodeIndex {\n-        let i = DagId::from_input_index(in_node);\n-        self.unify.find(i).as_input_index()\n-    }\n-\n-    #[cfg(test)]\n-    fn in_cycle(&mut self, ni1: NodeIndex, ni2: NodeIndex) -> bool {\n-        self.cycle_head(ni1) == self.cycle_head(ni2)\n-    }\n-}"}, {"sha": "1c5130845a855ed9c75d313e707a6d8f912b0c11", "filename": "src/librustc_incremental/persist/preds/compress/test.rs", "status": "removed", "additions": 0, "deletions": 259, "changes": 259, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Ftest.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,259 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use super::*;\n-\n-fn reduce(graph: &Graph<&'static str, ()>,\n-          inputs: &[&'static str],\n-          outputs: &[&'static str],\n-          expected: &[&'static str])\n-{\n-    let reduce = GraphReduce::new(&graph,\n-                                  |n| inputs.contains(n),\n-                                  |n| outputs.contains(n));\n-    let result = reduce.compute();\n-    let mut edges: Vec<String> =\n-        result.graph\n-              .all_edges()\n-              .iter()\n-              .map(|edge| format!(\"{} -> {}\",\n-                                  result.graph.node_data(edge.source()),\n-                                  result.graph.node_data(edge.target())))\n-              .collect();\n-    edges.sort();\n-    println!(\"{:#?}\", edges);\n-    assert_eq!(edges.len(), expected.len());\n-    for (expected, actual) in expected.iter().zip(&edges) {\n-        assert_eq!(expected, actual);\n-    }\n-}\n-\n-#[test]\n-fn test1() {\n-    //  +---------------+\n-    //  |               |\n-    //  |      +--------|------+\n-    //  |      |        v      v\n-    // [A] -> [C0] -> [C1]    [D]\n-    //        [  ] <- [  ] -> [E]\n-    //                  ^\n-    // [B] -------------+\n-    let (graph, _nodes) = graph! {\n-        A -> C0,\n-        A -> C1,\n-        B -> C1,\n-        C0 -> C1,\n-        C1 -> C0,\n-        C0 -> D,\n-        C1 -> E,\n-    };\n-\n-    // [A] -> [C1] -> [D]\n-    // [B] -> [  ] -> [E]\n-    reduce(&graph, &[\"A\", \"B\"], &[\"D\", \"E\"], &[\n-        \"A -> C1\",\n-        \"B -> C1\",\n-        \"C1 -> D\",\n-        \"C1 -> E\",\n-    ]);\n-}\n-\n-#[test]\n-fn test2() {\n-    //  +---------------+\n-    //  |               |\n-    //  |      +--------|------+\n-    //  |      |        v      v\n-    // [A] -> [C0] -> [C1]    [D] -> [E]\n-    //        [  ] <- [  ]\n-    //                  ^\n-    // [B] -------------+\n-    let (graph, _nodes) = graph! {\n-        A -> C0,\n-        A -> C1,\n-        B -> C1,\n-        C0 -> C1,\n-        C1 -> C0,\n-        C0 -> D,\n-        D -> E,\n-    };\n-\n-    // [A] -> [D] -> [E]\n-    // [B] -> [ ]\n-    reduce(&graph, &[\"A\", \"B\"], &[\"D\", \"E\"], &[\n-        \"A -> D\",\n-        \"B -> D\",\n-        \"D -> E\",\n-    ]);\n-}\n-\n-#[test]\n-fn test2b() {\n-    // Variant on test2 in which [B] is not\n-    // considered an input.\n-    let (graph, _nodes) = graph! {\n-        A -> C0,\n-        A -> C1,\n-        B -> C1,\n-        C0 -> C1,\n-        C1 -> C0,\n-        C0 -> D,\n-        D -> E,\n-    };\n-\n-    // [A] -> [D] -> [E]\n-    reduce(&graph, &[\"A\"], &[\"D\", \"E\"], &[\n-        \"A -> D\",\n-        \"D -> E\",\n-    ]);\n-}\n-\n-#[test]\n-fn test3() {\n-\n-    // Edges going *downwards*, so 0, 1 and 2 are inputs,\n-    // while 7, 8, and 9 are outputs.\n-    //\n-    //     0     1   2\n-    //     |      \\ /\n-    //     3---+   |\n-    //     |   |   |\n-    //     |   |   |\n-    //     4   5   6\n-    //      \\ / \\ / \\\n-    //       |   |   |\n-    //       7   8   9\n-    //\n-    // Here the end result removes node 4, instead encoding an edge\n-    // from n3 -> n7, but keeps nodes 5 and 6, as they are common\n-    // inputs to nodes 8/9.\n-\n-    let (graph, _nodes) = graph! {\n-        n0 -> n3,\n-        n3 -> n4,\n-        n3 -> n5,\n-        n4 -> n7,\n-        n5 -> n7,\n-        n5 -> n8,\n-        n1 -> n6,\n-        n2 -> n6,\n-        n6 -> n8,\n-        n6 -> n9,\n-    };\n-\n-    reduce(&graph, &[\"n0\", \"n1\", \"n2\"], &[\"n7\", \"n8\", \"n9\"], &[\n-        \"n0 -> n3\",\n-        \"n1 -> n6\",\n-        \"n2 -> n6\",\n-        \"n3 -> n5\",\n-        \"n3 -> n7\",\n-        \"n5 -> n7\",\n-        \"n5 -> n8\",\n-        \"n6 -> n8\",\n-        \"n6 -> n9\"\n-    ]);\n-}\n-\n-#[test]\n-fn test_cached_dfs_cyclic() {\n-\n-    //    0       1 <---- 2       3\n-    //    ^       |       ^       ^\n-    //    |       v       |       |\n-    //    4 ----> 5 ----> 6 ----> 7\n-    //    ^       ^       ^       ^\n-    //    |       |       |       |\n-    //    8       9      10      11\n-\n-    let (graph, _nodes) = graph! {\n-        // edges from above diagram, in columns, top-to-bottom:\n-        n4 -> n0,\n-        n8 -> n4,\n-        n4 -> n5,\n-        n1 -> n5,\n-        n9 -> n5,\n-        n2 -> n1,\n-        n5 -> n6,\n-        n6 -> n2,\n-        n10 -> n6,\n-        n6 -> n7,\n-        n7 -> n3,\n-        n11 -> n7,\n-    };\n-\n-    //    0       1  2            3\n-    //    ^       ^ /             ^\n-    //    |       |/              |\n-    //    4 ----> 5 --------------+\n-    //    ^       ^ \\             |\n-    //    |       |  \\            |\n-    //    8       9   10         11\n-\n-    reduce(&graph, &[\"n8\", \"n9\", \"n10\", \"n11\"], &[\"n0\", \"n1\", \"n2\", \"n3\"], &[\n-        \"n10 -> n5\",\n-        \"n11 -> n3\",\n-        \"n4 -> n0\",\n-        \"n4 -> n5\",\n-        \"n5 -> n1\",\n-        \"n5 -> n2\",\n-        \"n5 -> n3\",\n-        \"n8 -> n4\",\n-        \"n9 -> n5\"\n-    ]);\n-}\n-\n-/// Demonstrates the case where we don't reduce as much as we could.\n-#[test]\n-fn suboptimal() {\n-    let (graph, _nodes) = graph! {\n-        INPUT0 -> X,\n-        X -> OUTPUT0,\n-        X -> OUTPUT1,\n-    };\n-\n-    reduce(&graph, &[\"INPUT0\"], &[\"OUTPUT0\", \"OUTPUT1\"], &[\n-        \"INPUT0 -> X\",\n-        \"X -> OUTPUT0\",\n-        \"X -> OUTPUT1\"\n-    ]);\n-}\n-\n-#[test]\n-fn test_cycle_output() {\n-    //  +---------------+\n-    //  |               |\n-    //  |      +--------|------+\n-    //  |      |        v      v\n-    // [A] -> [C0] <-> [C1] <- [D]\n-    //                  +----> [E]\n-    //                          ^\n-    // [B] ----------------- ---+\n-    let (graph, _nodes) = graph! {\n-        A -> C0,\n-        A -> C1,\n-        B -> E,\n-        C0 -> C1,\n-        C1 -> C0,\n-        C0 -> D,\n-        C1 -> E,\n-        D -> C1,\n-    };\n-\n-    // [A] -> [C0] --> [D]\n-    //          +----> [E]\n-    //                  ^\n-    // [B] -------------+\n-    reduce(&graph, &[\"A\", \"B\"], &[\"D\", \"E\"], &[\n-        \"A -> C0\",\n-        \"B -> E\",\n-        \"C0 -> D\",\n-        \"C0 -> E\",\n-    ]);\n-}"}, {"sha": "044b143e306250944542e6b7fb12b3c73a090a21", "filename": "src/librustc_incremental/persist/preds/compress/test_macro.rs", "status": "removed", "additions": 0, "deletions": 39, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Ftest_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Ftest_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fcompress%2Ftest_macro.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,39 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-macro_rules! graph {\n-    ($( $source:ident -> $target:ident, )*) => {\n-        {\n-            use $crate::rustc_data_structures::graph::{Graph, NodeIndex};\n-            use $crate::rustc_data_structures::fx::FxHashMap;\n-\n-            let mut graph = Graph::new();\n-            let mut nodes: FxHashMap<&'static str, NodeIndex> = FxHashMap();\n-\n-            for &name in &[ $(stringify!($source), stringify!($target)),* ] {\n-                let name: &'static str = name;\n-                nodes.entry(name)\n-                     .or_insert_with(|| graph.add_node(name));\n-            }\n-\n-            $(\n-                {\n-                    let source = nodes[&stringify!($source)];\n-                    let target = nodes[&stringify!($target)];\n-                    graph.add_edge(source, target, ());\n-                }\n-            )*\n-\n-            let f = move |name: &'static str| -> NodeIndex { nodes[&name] };\n-\n-            (graph, f)\n-        }\n-    }\n-}"}, {"sha": "a552a27c62af0f9eec9356a9a3e1ed88393d4fbf", "filename": "src/librustc_incremental/persist/preds/mod.rs", "status": "removed", "additions": 0, "deletions": 108, "changes": 108, "blob_url": "https://github.com/rust-lang/rust/blob/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/417ffc98dfc770c27f7f2d7430f0edf975576591/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fpreds%2Fmod.rs?ref=417ffc98dfc770c27f7f2d7430f0edf975576591", "patch": "@@ -1,108 +0,0 @@\n-// Copyright 2012-2015 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use rustc::dep_graph::{DepGraphQuery, DepNode, DepKind};\n-use rustc::ich::Fingerprint;\n-use rustc::ty::TyCtxt;\n-use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::graph::{Graph, NodeIndex};\n-\n-\n-mod compress;\n-\n-/// A data-structure that makes it easy to enumerate the hashable\n-/// predecessors of any given dep-node.\n-pub struct Predecessors<'query> {\n-    // A reduced version of the input graph that contains fewer nodes.\n-    // This is intended to keep all of the base inputs (i.e., HIR\n-    // nodes) and all of the \"work-products\" we may care about\n-    // later. Other nodes may be retained if it keeps the overall size\n-    // of the graph down.\n-    pub reduced_graph: Graph<&'query DepNode, ()>,\n-\n-    // These are output nodes that have no incoming edges. We have to\n-    // track these specially because, when we load the data back up\n-    // again, we want to make sure and recreate these nodes (we want\n-    // to recreate the nodes where all incoming edges are clean; but\n-    // since we ordinarily just serialize edges, we wind up just\n-    // forgetting that bootstrap outputs even exist in that case.)\n-    pub bootstrap_outputs: Vec<&'query DepNode>,\n-\n-    // For the inputs (hir/foreign-metadata), we include hashes.\n-    pub hashes: FxHashMap<&'query DepNode, Fingerprint>,\n-}\n-\n-impl<'q> Predecessors<'q> {\n-    pub fn new(tcx: TyCtxt, query: &'q DepGraphQuery) -> Self {\n-        // Find the set of \"start nodes\". These are nodes that we will\n-        // possibly query later.\n-        let is_output = |node: &DepNode| -> bool {\n-            match node.kind {\n-                DepKind::WorkProduct => true,\n-                DepKind::CrateMetadata => {\n-                    // We do *not* create dep-nodes for the current crate's\n-                    // metadata anymore, just for metadata that we import/read\n-                    // from other crates.\n-                    debug_assert!(!node.extract_def_id(tcx).unwrap().is_local());\n-                    false\n-                }\n-                // if -Z query-dep-graph is passed, save more extended data\n-                // to enable better unit testing\n-                DepKind::TypeckTables => tcx.sess.opts.debugging_opts.query_dep_graph,\n-\n-                _ => false,\n-            }\n-        };\n-\n-        // Reduce the graph to the most important nodes.\n-        let compress::Reduction { graph, input_nodes } =\n-            compress::reduce_graph(&query.graph,\n-                                   |n| n.kind.is_input(),\n-                                   |n| is_output(n));\n-\n-        let mut hashes = FxHashMap();\n-        for input_index in input_nodes {\n-            let input = *graph.node_data(input_index);\n-            debug!(\"computing hash for input node `{:?}`\", input);\n-            hashes.entry(input)\n-                  .or_insert_with(|| tcx.dep_graph.fingerprint_of(&input));\n-        }\n-\n-        if tcx.sess.opts.debugging_opts.query_dep_graph {\n-            // Not all inputs might have been reachable from an output node,\n-            // but we still want their hash for our unit tests.\n-            let hir_nodes = query.graph.all_nodes().iter().filter_map(|node| {\n-                match node.data.kind {\n-                    DepKind::Hir => Some(&node.data),\n-                    _ => None,\n-                }\n-            });\n-\n-            for node in hir_nodes {\n-                hashes.entry(node)\n-                      .or_insert_with(|| tcx.dep_graph.fingerprint_of(&node));\n-            }\n-        }\n-\n-        let bootstrap_outputs: Vec<&'q DepNode> =\n-            (0 .. graph.len_nodes())\n-            .map(NodeIndex)\n-            .filter(|&n| graph.incoming_edges(n).next().is_none())\n-            .map(|n| *graph.node_data(n))\n-            .filter(|n| is_output(n))\n-            .collect();\n-\n-        Predecessors {\n-            reduced_graph: graph,\n-            bootstrap_outputs,\n-            hashes,\n-        }\n-    }\n-}"}, {"sha": "4919870fcd5198ee62c5664111fa94bf3dbfb191", "filename": "src/librustc_incremental/persist/save.rs", "status": "modified", "additions": 14, "deletions": 140, "changes": 154, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use rustc::dep_graph::{DepGraph, DepNode};\n+use rustc::dep_graph::DepGraph;\n use rustc::hir::def_id::DefId;\n use rustc::hir::svh::Svh;\n use rustc::ich::Fingerprint;\n@@ -18,16 +18,13 @@ use rustc::ty::TyCtxt;\n use rustc::util::common::time;\n use rustc::util::nodemap::DefIdMap;\n use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::graph;\n-use rustc_data_structures::indexed_vec::{IndexVec, Idx};\n use rustc_serialize::Encodable as RustcEncodable;\n use rustc_serialize::opaque::Encoder;\n use std::io::{self, Cursor, Write};\n use std::fs::{self, File};\n use std::path::PathBuf;\n \n use super::data::*;\n-use super::preds::*;\n use super::fs::*;\n use super::dirty_clean;\n use super::file_format;\n@@ -55,9 +52,6 @@ pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n     let mut current_metadata_hashes = FxHashMap();\n \n-    // IMPORTANT: We are saving the metadata hashes *before* the dep-graph,\n-    //            since metadata-encoding might add new entries to the\n-    //            DefIdDirectory (which is saved in the dep-graph file).\n     if sess.opts.debugging_opts.incremental_cc ||\n        sess.opts.debugging_opts.query_dep_graph {\n         save_in(sess,\n@@ -69,24 +63,10 @@ pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                            e));\n     }\n \n-    time(sess.time_passes(), \"persist dep-graph (old)\", || {\n-        let query = tcx.dep_graph.query();\n-\n-        if tcx.sess.opts.debugging_opts.incremental_info {\n-            eprintln!(\"incremental: {} nodes in dep-graph\", query.graph.len_nodes());\n-            eprintln!(\"incremental: {} edges in dep-graph\", query.graph.len_edges());\n-        }\n-\n-        let preds = Predecessors::new(tcx, &query);\n+    time(sess.time_passes(), \"persist dep-graph\", || {\n         save_in(sess,\n                 dep_graph_path(sess),\n-                |e| encode_dep_graph(tcx, &preds, e));\n-    });\n-\n-    time(sess.time_passes(), \"persist dep-graph (new)\", || {\n-        save_in(sess,\n-                dep_graph_path_new(sess),\n-                |e| encode_dep_graph_new(tcx, e));\n+                |e| encode_dep_graph(tcx, e));\n     });\n \n     dirty_clean::check_dirty_clean_annotations(tcx);\n@@ -182,9 +162,9 @@ fn save_in<F>(sess: &Session, path_buf: PathBuf, encode: F)\n     }\n }\n \n-fn encode_dep_graph_new(tcx: TyCtxt,\n-                        encoder: &mut Encoder)\n-                        -> io::Result<()> {\n+fn encode_dep_graph(tcx: TyCtxt,\n+                    encoder: &mut Encoder)\n+                    -> io::Result<()> {\n     // First encode the commandline arguments hash\n     tcx.sess.opts.dep_tracking_hash().encode(encoder)?;\n \n@@ -195,118 +175,12 @@ fn encode_dep_graph_new(tcx: TyCtxt,\n     Ok(())\n }\n \n-pub fn encode_dep_graph(tcx: TyCtxt,\n-                        preds: &Predecessors,\n-                        encoder: &mut Encoder)\n-                        -> io::Result<()> {\n-    // First encode the commandline arguments hash\n-    tcx.sess.opts.dep_tracking_hash().encode(encoder)?;\n-\n-    // NB: We rely on this Vec being indexable by reduced_graph's NodeIndex.\n-    let mut nodes: IndexVec<DepNodeIndex, DepNode> = preds\n-        .reduced_graph\n-        .all_nodes()\n-        .iter()\n-        .map(|node| node.data.clone())\n-        .collect();\n-\n-    let mut edge_list_indices = IndexVec::with_capacity(nodes.len());\n-    let mut edge_list_data = Vec::with_capacity(preds.reduced_graph.len_edges());\n-\n-    for node_index in 0 .. nodes.len() {\n-        let start = edge_list_data.len() as u32;\n-\n-        for target in preds.reduced_graph.successor_nodes(graph::NodeIndex(node_index)) {\n-            edge_list_data.push(DepNodeIndex::new(target.node_id()));\n-        }\n-\n-        let end = edge_list_data.len() as u32;\n-        debug_assert_eq!(node_index, edge_list_indices.len());\n-        edge_list_indices.push((start, end));\n-    }\n-\n-    // Let's make sure we had no overflow there.\n-    assert!(edge_list_data.len() <= ::std::u32::MAX as usize);\n-    // Check that we have a consistent number of edges.\n-    assert_eq!(edge_list_data.len(), preds.reduced_graph.len_edges());\n-\n-    let bootstrap_outputs = preds.bootstrap_outputs\n-                                 .iter()\n-                                 .map(|dep_node| (**dep_node).clone())\n-                                 .collect();\n-\n-    // Next, build the map of content hashes. To this end, we need to transform\n-    // the (DepNode -> Fingerprint) map that we have into a\n-    // (DepNodeIndex -> Fingerprint) map. This may necessitate adding nodes back\n-    // to the dep-graph that have been filtered out during reduction.\n-    let content_hashes = {\n-        // We have to build a (DepNode -> DepNodeIndex) map. We over-allocate a\n-        // little because we expect some more nodes to be added.\n-        let capacity = (nodes.len() * 120) / 100;\n-        let mut node_to_index = FxHashMap::with_capacity_and_hasher(capacity,\n-                                                                    Default::default());\n-        // Add the nodes we already have in the graph.\n-        node_to_index.extend(nodes.iter_enumerated()\n-                                  .map(|(index, &node)| (node, index)));\n-\n-        let mut content_hashes = Vec::with_capacity(preds.hashes.len());\n-\n-        for (&&dep_node, &hash) in preds.hashes.iter() {\n-            let dep_node_index = *node_to_index\n-                .entry(dep_node)\n-                .or_insert_with(|| {\n-                    // There is no DepNodeIndex for this DepNode yet. This\n-                    // happens when the DepNode got filtered out during graph\n-                    // reduction. Since we have a content hash for the DepNode,\n-                    // we add it back to the graph.\n-                    let next_index = nodes.len();\n-                    nodes.push(dep_node);\n-\n-                    debug_assert_eq!(next_index, edge_list_indices.len());\n-                    // Push an empty list of edges\n-                    edge_list_indices.push((0,0));\n-\n-                    DepNodeIndex::new(next_index)\n-                });\n-\n-            content_hashes.push((dep_node_index, hash));\n-        }\n-\n-        content_hashes\n-    };\n-\n-    let graph = SerializedDepGraph {\n-        nodes,\n-        edge_list_indices,\n-        edge_list_data,\n-        bootstrap_outputs,\n-        hashes: content_hashes,\n-    };\n-\n-    // Encode the graph data.\n-    graph.encode(encoder)?;\n-\n-    if tcx.sess.opts.debugging_opts.incremental_info {\n-        eprintln!(\"incremental: {} nodes in reduced dep-graph\", graph.nodes.len());\n-        eprintln!(\"incremental: {} edges in serialized dep-graph\", graph.edge_list_data.len());\n-        eprintln!(\"incremental: {} hashes in serialized dep-graph\", graph.hashes.len());\n-    }\n-\n-    if tcx.sess.opts.debugging_opts.incremental_dump_hash {\n-        for (dep_node, hash) in &preds.hashes {\n-            println!(\"ICH for {:?} is {}\", dep_node, hash);\n-        }\n-    }\n-\n-    Ok(())\n-}\n-\n-pub fn encode_metadata_hashes(tcx: TyCtxt,\n-                              svh: Svh,\n-                              metadata_hashes: &EncodedMetadataHashes,\n-                              current_metadata_hashes: &mut FxHashMap<DefId, Fingerprint>,\n-                              encoder: &mut Encoder)\n-                              -> io::Result<()> {\n+fn encode_metadata_hashes(tcx: TyCtxt,\n+                          svh: Svh,\n+                          metadata_hashes: &EncodedMetadataHashes,\n+                          current_metadata_hashes: &mut FxHashMap<DefId, Fingerprint>,\n+                          encoder: &mut Encoder)\n+                          -> io::Result<()> {\n     assert_eq!(metadata_hashes.hashes.len(),\n         metadata_hashes.hashes.iter().map(|x| (x.def_index, ())).collect::<FxHashMap<_,_>>().len());\n \n@@ -338,8 +212,8 @@ pub fn encode_metadata_hashes(tcx: TyCtxt,\n     Ok(())\n }\n \n-pub fn encode_work_products(dep_graph: &DepGraph,\n-                            encoder: &mut Encoder) -> io::Result<()> {\n+fn encode_work_products(dep_graph: &DepGraph,\n+                        encoder: &mut Encoder) -> io::Result<()> {\n     let work_products: Vec<_> = dep_graph\n         .work_products()\n         .iter()"}, {"sha": "9865e8fb1734a08bd1ce14731709af9e987642bf", "filename": "src/librustc_incremental/persist/work_product.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -21,11 +21,9 @@ use std::fs as std_fs;\n pub fn save_trans_partition(sess: &Session,\n                             dep_graph: &DepGraph,\n                             cgu_name: &str,\n-                            partition_hash: u64,\n                             files: &[(OutputType, PathBuf)]) {\n-    debug!(\"save_trans_partition({:?},{},{:?})\",\n+    debug!(\"save_trans_partition({:?},{:?})\",\n            cgu_name,\n-           partition_hash,\n            files);\n     if sess.opts.incremental.is_none() {\n         return;\n@@ -57,7 +55,6 @@ pub fn save_trans_partition(sess: &Session,\n \n     let work_product = WorkProduct {\n         cgu_name: cgu_name.to_string(),\n-        input_hash: partition_hash,\n         saved_files,\n     };\n "}, {"sha": "322f46cf02b6332b6877c29617eae386875fd858", "filename": "src/librustc_mir/transform/mod.rs", "status": "modified", "additions": 7, "deletions": 8, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_mir%2Ftransform%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_mir%2Ftransform%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Ftransform%2Fmod.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -13,15 +13,15 @@ use rustc::hir::def_id::{CrateNum, DefId, LOCAL_CRATE};\n use rustc::mir::Mir;\n use rustc::mir::transform::{MirPassIndex, MirSuite, MirSource,\n                             MIR_CONST, MIR_VALIDATED, MIR_OPTIMIZED};\n-use rustc::ty::{self, TyCtxt};\n+use rustc::ty::TyCtxt;\n use rustc::ty::maps::Providers;\n use rustc::ty::steal::Steal;\n use rustc::hir;\n use rustc::hir::intravisit::{self, Visitor, NestedVisitorMap};\n use rustc::util::nodemap::DefIdSet;\n use std::rc::Rc;\n use syntax::ast;\n-use syntax_pos::{DUMMY_SP, Span};\n+use syntax_pos::Span;\n use transform;\n \n pub mod add_validation;\n@@ -114,11 +114,10 @@ fn mir_validated<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>, def_id: DefId) -> &'tcx\n     let source = MirSource::from_local_def_id(tcx, def_id);\n     if let MirSource::Const(_) = source {\n         // Ensure that we compute the `mir_const_qualif` for constants at\n-        // this point, before we steal the mir-const result. We don't\n-        // directly need the result or `mir_const_qualif`, so we can just force it.\n-        ty::queries::mir_const_qualif::force(tcx, DUMMY_SP, def_id);\n+        // this point, before we steal the mir-const result.\n+        let _ = tcx.mir_const_qualif(def_id);\n     }\n-    ty::queries::unsafety_violations::force(tcx, DUMMY_SP, def_id);\n+    let _ = tcx.unsafety_violations(def_id);\n \n     let mut mir = tcx.mir_const(def_id).steal();\n     transform::run_suite(tcx, source, MIR_VALIDATED, &mut mir);\n@@ -128,8 +127,8 @@ fn mir_validated<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>, def_id: DefId) -> &'tcx\n fn optimized_mir<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>, def_id: DefId) -> &'tcx Mir<'tcx> {\n     // (Mir-)Borrowck uses `mir_validated`, so we have to force it to\n     // execute before we can steal.\n-    ty::queries::mir_borrowck::force(tcx, DUMMY_SP, def_id);\n-    ty::queries::borrowck::force(tcx, DUMMY_SP, def_id);\n+    let _ = tcx.mir_borrowck(def_id);\n+    let _ = tcx.borrowck(def_id);\n \n     let mut mir = tcx.mir_validated(def_id).steal();\n     let source = MirSource::from_local_def_id(tcx, def_id);"}, {"sha": "c891bd8aaf44f06d499dc68bbe2c51e769ad37fd", "filename": "src/librustc_trans/assert_module_sources.rs", "status": "modified", "additions": 28, "deletions": 44, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fassert_module_sources.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fassert_module_sources.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fassert_module_sources.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -27,47 +27,32 @@\n //! the HIR doesn't change as a result of the annotations, which might\n //! perturb the reuse results.\n \n+use rustc::dep_graph::{DepNode, DepConstructor};\n use rustc::ty::TyCtxt;\n use syntax::ast;\n-\n-use {ModuleSource, ModuleTranslation};\n-\n use rustc::ich::{ATTR_PARTITION_REUSED, ATTR_PARTITION_TRANSLATED};\n \n const MODULE: &'static str = \"module\";\n const CFG: &'static str = \"cfg\";\n \n #[derive(Debug, PartialEq, Clone, Copy)]\n-pub enum Disposition { Reused, Translated }\n-\n-impl ModuleTranslation {\n-    pub fn disposition(&self) -> (String, Disposition) {\n-        let disposition = match self.source {\n-            ModuleSource::Preexisting(_) => Disposition::Reused,\n-            ModuleSource::Translated(_) => Disposition::Translated,\n-        };\n+enum Disposition { Reused, Translated }\n \n-        (self.name.clone(), disposition)\n-    }\n-}\n-\n-pub(crate) fn assert_module_sources<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                              modules: &[(String, Disposition)]) {\n+pub(crate) fn assert_module_sources<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n     let _ignore = tcx.dep_graph.in_ignore();\n \n     if tcx.sess.opts.incremental.is_none() {\n         return;\n     }\n \n-    let ams = AssertModuleSource { tcx: tcx, modules: modules };\n+    let ams = AssertModuleSource { tcx };\n     for attr in &tcx.hir.krate().attrs {\n         ams.check_attr(attr);\n     }\n }\n \n struct AssertModuleSource<'a, 'tcx: 'a> {\n-    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-    modules: &'a [(String, Disposition)],\n+    tcx: TyCtxt<'a, 'tcx, 'tcx>\n }\n \n impl<'a, 'tcx> AssertModuleSource<'a, 'tcx> {\n@@ -86,32 +71,31 @@ impl<'a, 'tcx> AssertModuleSource<'a, 'tcx> {\n         }\n \n         let mname = self.field(attr, MODULE);\n-        let mtrans = self.modules.iter().find(|&&(ref name, _)| name == mname.as_str());\n-        let mtrans = match mtrans {\n-            Some(m) => m,\n-            None => {\n-                debug!(\"module name `{}` not found amongst:\", mname);\n-                for &(ref name, ref disposition) in self.modules {\n-                    debug!(\"module named `{}` with disposition {:?}\",\n-                           name,\n-                           disposition);\n-                }\n \n-                self.tcx.sess.span_err(\n-                    attr.span,\n-                    &format!(\"no module named `{}`\", mname));\n-                return;\n-            }\n-        };\n+        let dep_node = DepNode::new(self.tcx,\n+                                    DepConstructor::CompileCodegenUnit(mname.as_str()));\n \n-        let mtrans_disposition = mtrans.1;\n-        if disposition != mtrans_disposition {\n-            self.tcx.sess.span_err(\n-                attr.span,\n-                &format!(\"expected module named `{}` to be {:?} but is {:?}\",\n-                         mname,\n-                         disposition,\n-                         mtrans_disposition));\n+        if let Some(loaded_from_cache) = self.tcx.dep_graph.was_loaded_from_cache(&dep_node) {\n+            match (disposition, loaded_from_cache) {\n+                (Disposition::Reused, false) => {\n+                    self.tcx.sess.span_err(\n+                        attr.span,\n+                        &format!(\"expected module named `{}` to be Reused but is Translated\",\n+                                 mname));\n+                }\n+                (Disposition::Translated, true) => {\n+                    self.tcx.sess.span_err(\n+                        attr.span,\n+                        &format!(\"expected module named `{}` to be Translated but is Reused\",\n+                                 mname));\n+                }\n+                (Disposition::Reused, true) |\n+                (Disposition::Translated, false) => {\n+                    // These are what we would expect.\n+                }\n+            }\n+        } else {\n+            self.tcx.sess.span_err(attr.span, &format!(\"no module named `{}`\", mname));\n         }\n     }\n "}, {"sha": "4996972a64586c1af584b1981e5c49b91ee68c84", "filename": "src/librustc_trans/back/symbol_export.rs", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fback%2Fsymbol_export.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fback%2Fsymbol_export.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fback%2Fsymbol_export.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -77,11 +77,7 @@ pub fn provide_local(providers: &mut Providers) {\n     };\n \n     providers.is_exported_symbol = |tcx, id| {\n-        // FIXME(#42293) needs red/green to not break a bunch of incremental\n-        // tests\n-        tcx.dep_graph.with_ignore(|| {\n-            tcx.exported_symbol_ids(id.krate).contains(&id)\n-        })\n+        tcx.exported_symbol_ids(id.krate).contains(&id)\n     };\n \n     providers.exported_symbols = |tcx, cnum| {"}, {"sha": "c238c68c4718da604816c152dddf02879fbaca0e", "filename": "src/librustc_trans/back/write.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fback%2Fwrite.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -884,7 +884,6 @@ fn copy_module_artifacts_into_incr_comp_cache(sess: &Session,\n         save_trans_partition(sess,\n                              dep_graph,\n                              &module.name,\n-                             module.symbol_name_hash,\n                              &files);\n     }\n }\n@@ -1134,7 +1133,6 @@ fn execute_work_item(cgcx: &CodegenContext, work_item: WorkItem)\n             name: module_name,\n             kind: ModuleKind::Regular,\n             pre_existing: true,\n-            symbol_name_hash: mtrans.symbol_name_hash,\n             emit_bc: config.emit_bc,\n             emit_obj: config.emit_obj,\n         }))"}, {"sha": "8c39f579b3ea6003b4a98132ee9c9095189f499a", "filename": "src/librustc_trans/base.rs", "status": "modified", "additions": 63, "deletions": 73, "changes": 136, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbase.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -28,7 +28,7 @@ use super::ModuleSource;\n use super::ModuleTranslation;\n use super::ModuleKind;\n \n-use assert_module_sources::{self, Disposition};\n+use assert_module_sources;\n use back::link;\n use back::symbol_export;\n use back::write::{self, OngoingCrateTranslation, create_target_machine};\n@@ -41,7 +41,7 @@ use rustc::middle::trans::{Linkage, Visibility, Stats};\n use rustc::middle::cstore::{EncodedMetadata, EncodedMetadataHashes};\n use rustc::ty::{self, Ty, TyCtxt};\n use rustc::ty::maps::Providers;\n-use rustc::dep_graph::{DepNode, DepKind};\n+use rustc::dep_graph::{DepNode, DepKind, DepConstructor};\n use rustc::middle::cstore::{self, LinkMeta, LinkagePreference};\n use rustc::util::common::{time, print_time_passes_entry};\n use rustc::session::config::{self, NoDebugInfo};\n@@ -78,7 +78,6 @@ use rustc::util::nodemap::{NodeSet, FxHashMap, FxHashSet, DefIdSet};\n use CrateInfo;\n \n use std::any::Any;\n-use std::cell::RefCell;\n use std::ffi::{CStr, CString};\n use std::str;\n use std::sync::Arc;\n@@ -904,7 +903,6 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     let metadata_module = ModuleTranslation {\n         name: link::METADATA_MODULE_NAME.to_string(),\n         llmod_id: llmod_id.to_string(),\n-        symbol_name_hash: 0, // we always rebuild metadata, at least for now\n         source: ModuleSource::Translated(ModuleLlvm {\n             llcx: metadata_llcx,\n             llmod: metadata_llmod,\n@@ -947,6 +945,17 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         shared_ccx.tcx().collect_and_partition_translation_items(LOCAL_CRATE).1;\n     let codegen_units = (*codegen_units).clone();\n \n+    // Force all codegen_unit queries so they are already either red or green\n+    // when compile_codegen_unit accesses them. We are not able to re-execute\n+    // the codegen_unit query from just the DepNode, so an unknown color would\n+    // lead to having to re-execute compile_codegen_unit, possibly\n+    // unnecessarily.\n+    if tcx.dep_graph.is_fully_enabled() {\n+        for cgu in &codegen_units {\n+            tcx.codegen_unit(cgu.name().clone());\n+        }\n+    }\n+\n     let ongoing_translation = write::start_async_translation(\n         tcx,\n         time_graph.clone(),\n@@ -972,7 +981,6 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n             Some(ModuleTranslation {\n                 name: link::ALLOCATOR_MODULE_NAME.to_string(),\n                 llmod_id: llmod_id.to_string(),\n-                symbol_name_hash: 0, // we always rebuild allocator shims\n                 source: ModuleSource::Translated(modules),\n                 kind: ModuleKind::Allocator,\n             })\n@@ -1004,6 +1012,50 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         ongoing_translation.wait_for_signal_to_translate_item();\n         ongoing_translation.check_for_errors(tcx.sess);\n \n+        // First, if incremental compilation is enabled, we try to re-use the\n+        // codegen unit from the cache.\n+        if tcx.dep_graph.is_fully_enabled() {\n+            let cgu_id = cgu.work_product_id();\n+\n+            // Check whether there is a previous work-product we can\n+            // re-use.  Not only must the file exist, and the inputs not\n+            // be dirty, but the hash of the symbols we will generate must\n+            // be the same.\n+            if let Some(buf) = tcx.dep_graph.previous_work_product(&cgu_id) {\n+                let dep_node = &DepNode::new(tcx,\n+                    DepConstructor::CompileCodegenUnit(cgu.name().clone()));\n+\n+                // We try to mark the DepNode::CompileCodegenUnit green. If we\n+                // succeed it means that none of the dependencies has changed\n+                // and we can safely re-use.\n+                if let Some(dep_node_index) = tcx.dep_graph.try_mark_green(tcx, dep_node) {\n+                    // Append \".rs\" to LLVM module identifier.\n+                    //\n+                    // LLVM code generator emits a \".file filename\" directive\n+                    // for ELF backends. Value of the \"filename\" is set as the\n+                    // LLVM module identifier.  Due to a LLVM MC bug[1], LLVM\n+                    // crashes if the module identifier is same as other symbols\n+                    // such as a function name in the module.\n+                    // 1. http://llvm.org/bugs/show_bug.cgi?id=11479\n+                    let llmod_id = format!(\"{}.rs\", cgu.name());\n+\n+                    let module = ModuleTranslation {\n+                        name: cgu.name().to_string(),\n+                        source: ModuleSource::Preexisting(buf),\n+                        kind: ModuleKind::Regular,\n+                        llmod_id,\n+                    };\n+                    tcx.dep_graph.mark_loaded_from_cache(dep_node_index, true);\n+                    write::submit_translated_module_to_llvm(tcx, module, 0);\n+                    // Continue to next cgu, this one is done.\n+                    continue\n+                }\n+            } else {\n+                // This can happen if files were  deleted from the cache\n+                // directory for some reason. We just re-compile then.\n+            }\n+        }\n+\n         let _timing_guard = time_graph.as_ref().map(|time_graph| {\n             time_graph.start(write::TRANS_WORKER_TIMELINE,\n                              write::TRANS_WORK_PACKAGE_KIND,\n@@ -1024,9 +1076,7 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                             total_trans_time);\n \n     if tcx.sess.opts.incremental.is_some() {\n-        DISPOSITIONS.with(|d| {\n-            assert_module_sources::assert_module_sources(tcx, &d.borrow());\n-        });\n+        assert_module_sources::assert_module_sources(tcx);\n     }\n \n     symbol_names_test::report_symbol_names(tcx);\n@@ -1061,10 +1111,6 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     ongoing_translation\n }\n \n-// FIXME(#42293) hopefully once red/green is enabled we're testing everything\n-// via a method that doesn't require this!\n-thread_local!(static DISPOSITIONS: RefCell<Vec<(String, Disposition)>> = Default::default());\n-\n fn assert_and_save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                        metadata_incr_hashes: EncodedMetadataHashes,\n                                        link_meta: LinkMeta) {\n@@ -1288,38 +1334,19 @@ impl CrateInfo {\n }\n \n fn is_translated_function(tcx: TyCtxt, id: DefId) -> bool {\n-    // FIXME(#42293) needs red/green tracking to avoid failing a bunch of\n-    // existing tests\n-    tcx.dep_graph.with_ignore(|| {\n-        let (all_trans_items, _) =\n-            tcx.collect_and_partition_translation_items(LOCAL_CRATE);\n-        all_trans_items.contains(&id)\n-    })\n+    let (all_trans_items, _) =\n+        tcx.collect_and_partition_translation_items(LOCAL_CRATE);\n+    all_trans_items.contains(&id)\n }\n \n fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                   cgu: InternedString) -> Stats {\n-    // FIXME(#42293) needs red/green tracking to avoid failing a bunch of\n-    // existing tests\n-    let cgu = tcx.dep_graph.with_ignore(|| {\n-        tcx.codegen_unit(cgu)\n-    });\n+    let cgu = tcx.codegen_unit(cgu);\n \n     let start_time = Instant::now();\n-    let dep_node = cgu.work_product_dep_node();\n-    let ((stats, module), _) =\n-        tcx.dep_graph.with_task(dep_node,\n-                                tcx,\n-                                cgu,\n-                                module_translation);\n+    let (stats, module) = module_translation(tcx, cgu);\n     let time_to_translate = start_time.elapsed();\n \n-    if tcx.sess.opts.incremental.is_some() {\n-        DISPOSITIONS.with(|d| {\n-            d.borrow_mut().push(module.disposition());\n-        });\n-    }\n-\n     // We assume that the cost to run LLVM on a CGU is proportional to\n     // the time we needed for translating it.\n     let cost = time_to_translate.as_secs() * 1_000_000_000 +\n@@ -1336,8 +1363,6 @@ fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         -> (Stats, ModuleTranslation)\n     {\n         let cgu_name = cgu.name().to_string();\n-        let cgu_id = cgu.work_product_id();\n-        let symbol_name_hash = cgu.compute_symbol_name_hash(tcx);\n \n         // Append \".rs\" to LLVM module identifier.\n         //\n@@ -1349,40 +1374,6 @@ fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         // 1. http://llvm.org/bugs/show_bug.cgi?id=11479\n         let llmod_id = format!(\"{}.rs\", cgu.name());\n \n-        // Check whether there is a previous work-product we can\n-        // re-use.  Not only must the file exist, and the inputs not\n-        // be dirty, but the hash of the symbols we will generate must\n-        // be the same.\n-        let previous_work_product =\n-            tcx.dep_graph.previous_work_product(&cgu_id).and_then(|work_product| {\n-                if work_product.input_hash == symbol_name_hash {\n-                    debug!(\"trans_reuse_previous_work_products: reusing {:?}\", work_product);\n-                    Some(work_product)\n-                } else {\n-                    if tcx.sess.opts.debugging_opts.incremental_info {\n-                        eprintln!(\"incremental: CGU `{}` invalidated because of \\\n-                                   changed partitioning hash.\",\n-                                   cgu.name());\n-                    }\n-                    debug!(\"trans_reuse_previous_work_products: \\\n-                            not reusing {:?} because hash changed to {:?}\",\n-                           work_product, symbol_name_hash);\n-                    None\n-                }\n-            });\n-\n-        if let Some(buf) = previous_work_product {\n-            // Don't need to translate this module.\n-            let module = ModuleTranslation {\n-                llmod_id: llmod_id,\n-                name: cgu_name,\n-                symbol_name_hash,\n-                source: ModuleSource::Preexisting(buf.clone()),\n-                kind: ModuleKind::Regular,\n-            };\n-            return (Stats::default(), module);\n-        }\n-\n         // Instantiate translation items without filling out definitions yet...\n         let scx = SharedCrateContext::new(tcx);\n         let lcx = LocalCrateContext::new(&scx, cgu, &llmod_id);\n@@ -1448,7 +1439,6 @@ fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n             ModuleTranslation {\n                 name: cgu_name,\n-                symbol_name_hash,\n                 source: ModuleSource::Translated(llvm_module),\n                 kind: ModuleKind::Regular,\n                 llmod_id,"}, {"sha": "18b91b18d8e54af05a2d4127342461641e657749", "filename": "src/librustc_trans/callee.rs", "status": "modified", "additions": 7, "deletions": 10, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fcallee.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fcallee.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fcallee.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -156,17 +156,14 @@ pub fn get_fn<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n             }\n         }\n \n-        // FIXME(#42293) we should actually track this, but fails too many tests\n-        // today.\n-        tcx.dep_graph.with_ignore(|| {\n-            if ccx.use_dll_storage_attrs() &&\n-                tcx.is_dllimport_foreign_item(instance_def_id)\n-            {\n-                unsafe {\n-                    llvm::LLVMSetDLLStorageClass(llfn, llvm::DLLStorageClass::DllImport);\n-                }\n+        if ccx.use_dll_storage_attrs() &&\n+            tcx.is_dllimport_foreign_item(instance_def_id)\n+        {\n+            unsafe {\n+                llvm::LLVMSetDLLStorageClass(llfn, llvm::DLLStorageClass::DllImport);\n             }\n-        });\n+        }\n+\n         llfn\n     };\n "}, {"sha": "73df1b45c59827f44064bbeb18a6d407cd318e71", "filename": "src/librustc_trans/collector.rs", "status": "modified", "additions": 15, "deletions": 19, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fcollector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fcollector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fcollector.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -296,26 +296,22 @@ pub fn collect_crate_translation_items<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                                  mode: TransItemCollectionMode)\n                                                  -> (FxHashSet<TransItem<'tcx>>,\n                                                      InliningMap<'tcx>) {\n-    // We are not tracking dependencies of this pass as it has to be re-executed\n-    // every time no matter what.\n-    tcx.dep_graph.with_ignore(|| {\n-        let roots = collect_roots(tcx, mode);\n-\n-        debug!(\"Building translation item graph, beginning at roots\");\n-        let mut visited = FxHashSet();\n-        let mut recursion_depths = DefIdMap();\n-        let mut inlining_map = InliningMap::new();\n-\n-        for root in roots {\n-            collect_items_rec(tcx,\n-                              root,\n-                              &mut visited,\n-                              &mut recursion_depths,\n-                              &mut inlining_map);\n-        }\n+    let roots = collect_roots(tcx, mode);\n+\n+    debug!(\"Building translation item graph, beginning at roots\");\n+    let mut visited = FxHashSet();\n+    let mut recursion_depths = DefIdMap();\n+    let mut inlining_map = InliningMap::new();\n+\n+    for root in roots {\n+        collect_items_rec(tcx,\n+                          root,\n+                          &mut visited,\n+                          &mut recursion_depths,\n+                          &mut inlining_map);\n+    }\n \n-        (visited, inlining_map)\n-    })\n+    (visited, inlining_map)\n }\n \n // Find all non-generic items by walking the HIR. These items serve as roots to"}, {"sha": "eaf7392aab5b4f6d95a2ca635c4fb0bd8db8b3e6", "filename": "src/librustc_trans/consts.rs", "status": "modified", "additions": 6, "deletions": 10, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fconsts.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fconsts.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fconsts.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -231,17 +231,13 @@ pub fn get_static(ccx: &CrateContext, def_id: DefId) -> ValueRef {\n         g\n     };\n \n-\n-    // FIXME(#42293) we should actually track this, but fails too many tests\n-    // today.\n-    ccx.tcx().dep_graph.with_ignore(|| {\n-        if ccx.use_dll_storage_attrs() && ccx.tcx().is_dllimport_foreign_item(def_id) {\n-            // For foreign (native) libs we know the exact storage type to use.\n-            unsafe {\n-                llvm::LLVMSetDLLStorageClass(g, llvm::DLLStorageClass::DllImport);\n-            }\n+    if ccx.use_dll_storage_attrs() && ccx.tcx().is_dllimport_foreign_item(def_id) {\n+        // For foreign (native) libs we know the exact storage type to use.\n+        unsafe {\n+            llvm::LLVMSetDLLStorageClass(g, llvm::DLLStorageClass::DllImport);\n         }\n-    });\n+    }\n+\n     ccx.instances().borrow_mut().insert(instance, g);\n     ccx.statics().borrow_mut().insert(g, def_id);\n     g"}, {"sha": "2b1c62c7f1c768cded788224bb50c96c233cac48", "filename": "src/librustc_trans/lib.rs", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Flib.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -204,7 +204,6 @@ pub struct ModuleTranslation {\n     /// as the crate name and disambiguator.\n     name: String,\n     llmod_id: String,\n-    symbol_name_hash: u64,\n     pub source: ModuleSource,\n     pub kind: ModuleKind,\n }\n@@ -238,7 +237,6 @@ impl ModuleTranslation {\n             llmod_id: self.llmod_id,\n             name: self.name.clone(),\n             kind: self.kind,\n-            symbol_name_hash: self.symbol_name_hash,\n             pre_existing,\n             emit_obj,\n             emit_bc,\n@@ -253,7 +251,6 @@ pub struct CompiledModule {\n     pub llmod_id: String,\n     pub object: PathBuf,\n     pub kind: ModuleKind,\n-    pub symbol_name_hash: u64,\n     pub pre_existing: bool,\n     pub emit_obj: bool,\n     pub emit_bc: bool,"}, {"sha": "7b6daa7d13328c9c2f312fdca294674ea9109cae", "filename": "src/librustc_trans/partitioning.rs", "status": "modified", "additions": 0, "deletions": 16, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fpartitioning.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_trans%2Fpartitioning.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fpartitioning.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -108,14 +108,11 @@ use rustc::dep_graph::{DepNode, WorkProductId};\n use rustc::hir::def_id::DefId;\n use rustc::hir::map::DefPathData;\n use rustc::middle::trans::{Linkage, Visibility};\n-use rustc::ich::Fingerprint;\n use rustc::session::config::NUMBERED_CODEGEN_UNIT_MARKER;\n use rustc::ty::{self, TyCtxt, InstanceDef};\n use rustc::ty::item_path::characteristic_def_id_of_type;\n use rustc::util::nodemap::{FxHashMap, FxHashSet};\n-use rustc_data_structures::stable_hasher::StableHasher;\n use std::collections::hash_map::Entry;\n-use std::hash::Hash;\n use syntax::ast::NodeId;\n use syntax::symbol::{Symbol, InternedString};\n use trans_item::{TransItem, TransItemExt, InstantiationMode};\n@@ -155,19 +152,6 @@ pub trait CodegenUnitExt<'tcx> {\n         self.work_product_id().to_dep_node()\n     }\n \n-    fn compute_symbol_name_hash<'a>(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>) -> u64 {\n-        let mut state: StableHasher<Fingerprint> = StableHasher::new();\n-        let all_items = self.items_in_deterministic_order(tcx);\n-        for (item, (linkage, visibility)) in all_items {\n-            let symbol_name = item.symbol_name(tcx);\n-            symbol_name.len().hash(&mut state);\n-            symbol_name.hash(&mut state);\n-            linkage.hash(&mut state);\n-            visibility.hash(&mut state);\n-        }\n-        state.finish().to_smaller_hash()\n-    }\n-\n     fn items_in_deterministic_order<'a>(&self,\n                                         tcx: TyCtxt<'a, 'tcx, 'tcx>)\n                                         -> Vec<(TransItem<'tcx>,"}, {"sha": "c1653cfb43bc8f1f33bf618f03efe8e8d0b8dd93", "filename": "src/librustc_typeck/variance/constraints.rs", "status": "modified", "additions": 17, "deletions": 5, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_typeck%2Fvariance%2Fconstraints.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Flibrustc_typeck%2Fvariance%2Fconstraints.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fvariance%2Fconstraints.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -14,7 +14,7 @@\n //! We walk the set of items and, for each member, generate new constraints.\n \n use hir::def_id::DefId;\n-use rustc::dep_graph::{DepGraphSafe, DepKind};\n+use rustc::dep_graph::{DepGraphSafe, DepKind, DepNodeColor};\n use rustc::ich::StableHashingContext;\n use rustc::ty::subst::Substs;\n use rustc::ty::{self, Ty, TyCtxt};\n@@ -162,10 +162,22 @@ impl<'a, 'tcx> ConstraintContext<'a, 'tcx> {\n         // See README.md for a detailed discussion\n         // on dep-graph management.\n         let dep_node = def_id.to_dep_node(tcx, DepKind::ItemVarianceConstraints);\n-        tcx.dep_graph.with_task(dep_node,\n-                                self,\n-                                def_id,\n-                                visit_item_task);\n+\n+        if let Some(DepNodeColor::Green(_)) = tcx.dep_graph.node_color(&dep_node) {\n+            // If the corresponding node has already been marked as green, the\n+            // appropriate portion of the DepGraph has already been loaded from\n+            // the previous graph, so we don't do any dep-tracking. Since we\n+            // don't cache any values though, we still have to re-run the\n+            // computation.\n+            tcx.dep_graph.with_ignore(|| {\n+                self.build_constraints_for_item(def_id);\n+            });\n+        } else {\n+            tcx.dep_graph.with_task(dep_node,\n+                                    self,\n+                                    def_id,\n+                                    visit_item_task);\n+        }\n \n         fn visit_item_task<'a, 'tcx>(ccx: &mut ConstraintContext<'a, 'tcx>,\n                                      def_id: DefId)"}, {"sha": "40067efd57595973a13dc00676ee0347c5681eeb", "filename": "src/test/incremental/add_private_fn_at_krate_root_cc/struct_point.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fadd_private_fn_at_krate_root_cc%2Fstruct_point.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fadd_private_fn_at_krate_root_cc%2Fstruct_point.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fadd_private_fn_at_krate_root_cc%2Fstruct_point.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -15,7 +15,6 @@\n // revisions:rpass1 rpass2\n // compile-flags: -Z query-dep-graph\n // aux-build:point.rs\n-// ignore-test FIXME(#42293) this regressed in #44142 but should get fixed with red/green\n \n #![feature(rustc_attrs)]\n #![feature(stmt_expr_attributes)]"}, {"sha": "feecfecd0b85368a137ffb543cd6ccf1a09bf6ab", "filename": "src/test/incremental/cache_file_headers.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fcache_file_headers.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fcache_file_headers.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fcache_file_headers.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -20,6 +20,7 @@\n //[rpass1] rustc-env:RUSTC_FORCE_INCR_COMP_ARTIFACT_HEADER=\"l33t haxx0r rustc 2.1 LTS\"\n \n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n #![rustc_partition_translated(module=\"cache_file_headers\", cfg=\"rpass2\")]"}, {"sha": "9e56d34636ff0083b4dc53a91809aef0a13c8eb0", "filename": "src/test/incremental/callee_caller_cross_crate/b.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fcallee_caller_cross_crate%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fcallee_caller_cross_crate%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fcallee_caller_cross_crate%2Fb.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -12,8 +12,6 @@\n // revisions:rpass1 rpass2\n // compile-flags:-Z query-dep-graph\n \n-// ignore-test -- ignored until red/green restores cross-crate tracking fidelity\n-\n #![feature(rustc_attrs)]\n \n extern crate a;"}, {"sha": "a6d029515d74263d23cbeb295eb101fb68618967", "filename": "src/test/incremental/change_private_fn_cc/struct_point.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fchange_private_fn_cc%2Fstruct_point.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fchange_private_fn_cc%2Fstruct_point.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fchange_private_fn_cc%2Fstruct_point.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -15,8 +15,6 @@\n // compile-flags: -Z query-dep-graph\n // aux-build:point.rs\n \n-// ignore-test -- ignored until red/green restores cross-crate tracking fidelity\n-\n #![feature(rustc_attrs)]\n #![feature(stmt_expr_attributes)]\n #![allow(dead_code)]"}, {"sha": "05c076b9f4bc3b47dd286d658a3221024fef4ef3", "filename": "src/test/incremental/change_private_impl_method_cc/struct_point.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fchange_private_impl_method_cc%2Fstruct_point.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fchange_private_impl_method_cc%2Fstruct_point.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fchange_private_impl_method_cc%2Fstruct_point.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -15,8 +15,6 @@\n // compile-flags: -Z query-dep-graph\n // aux-build:point.rs\n \n-// ignore-test -- ignored until red/green restores cross-crate tracking fidelity\n-\n #![feature(rustc_attrs)]\n #![feature(stmt_expr_attributes)]\n #![allow(dead_code)]"}, {"sha": "ab91a941a1663aa62006a6aefbea4556d60e517f", "filename": "src/test/incremental/change_symbol_export_status.rs", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fchange_symbol_export_status.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fchange_symbol_export_status.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fchange_symbol_export_status.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -9,13 +9,13 @@\n // except according to those terms.\n \n // revisions: rpass1 rpass2\n+// compile-flags: -Zquery-dep-graph\n \n #![feature(rustc_attrs)]\n #![allow(private_no_mangle_fns)]\n \n-#![rustc_partition_reused(module=\"change_symbol_export_status\", cfg=\"rpass2\")]\n #![rustc_partition_translated(module=\"change_symbol_export_status-mod1\", cfg=\"rpass2\")]\n-\n+#![rustc_partition_reused(module=\"change_symbol_export_status-mod2\", cfg=\"rpass2\")]\n \n // This test case makes sure that a change in symbol visibility is detected by\n // our dependency tracking. We do this by changing a module's visibility to\n@@ -37,6 +37,11 @@ mod mod1 {\n     pub fn foo() {}\n }\n \n+pub mod mod2 {\n+    #[no_mangle]\n+    pub fn bar() {}\n+}\n+\n fn main() {\n     mod1::foo();\n }"}, {"sha": "e29f2ec2a1345682a33d3604984c91187c4fff54", "filename": "src/test/incremental/commandline-args.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fcommandline-args.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fcommandline-args.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fcommandline-args.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -12,6 +12,7 @@\n // the cache while changing an untracked one doesn't.\n \n // revisions:rpass1 rpass2 rpass3\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "52a601ac1e87bd447afa3cc6745b931437201757", "filename": "src/test/incremental/issue-35593.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fissue-35593.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fissue-35593.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fissue-35593.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -12,6 +12,7 @@\n // equal example.\n \n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n #![rustc_partition_reused(module=\"issue_35593\", cfg=\"rpass2\")]"}, {"sha": "410ff69bf69c5391169c13de2c775d876d2847f8", "filename": "src/test/incremental/issue-38222.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fissue-38222.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fissue-38222.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fissue-38222.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -12,6 +12,8 @@\n // dep-node.\n \n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n+\n \n #![feature(rustc_attrs)]\n "}, {"sha": "432d8a1b444f3eb1708b050e7d304c306a4e8c81", "filename": "src/test/incremental/remapped_paths_cc/main.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fremapped_paths_cc%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fremapped_paths_cc%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fremapped_paths_cc%2Fmain.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -11,8 +11,6 @@\n // revisions:rpass1 rpass2 rpass3\n // compile-flags: -Z query-dep-graph -g -Zincremental-cc\n // aux-build:extern_crate.rs\n-// ignore-test FIXME(#42293) this regressed in #44142 but should get fixed with red/green\n-\n \n // This test case makes sure that we detect if paths emitted into debuginfo\n // are changed, even when the change happens in an external crate."}, {"sha": "d94cb403da8a5209c02ad382d0f55f61d882f296", "filename": "src/test/incremental/remove-private-item-cross-crate/main.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fremove-private-item-cross-crate%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fremove-private-item-cross-crate%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fremove-private-item-cross-crate%2Fmain.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -17,8 +17,7 @@\n #![feature(rustc_attrs)]\n #![crate_type = \"bin\"]\n \n-// FIXME(#42293) this regressed in #44142 but should get fixed with red/green\n-// #![rustc_partition_reused(module=\"main\", cfg=\"rpass2\")]\n+#![rustc_partition_reused(module=\"main\", cfg=\"rpass2\")]\n \n extern crate a;\n "}, {"sha": "9849e93d3ff9ef4e0de1eb6aea01f9bd5c9d89a1", "filename": "src/test/incremental/rlib_cross_crate/b.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Frlib_cross_crate%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Frlib_cross_crate%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Frlib_cross_crate%2Fb.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -18,8 +18,6 @@\n // no-prefer-dynamic\n // compile-flags: -Z query-dep-graph\n \n-// ignore-test -- ignored until red/green restores cross-crate tracking fidelity\n-\n #![feature(rustc_attrs)]\n \n extern crate a;"}, {"sha": "a820471b7d55baf1dfea4d1a54278cbeb9cf5851", "filename": "src/test/incremental/spike.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fspike.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fspike.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fspike.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -13,6 +13,7 @@\n // `y` module entirely (but not the `x` module).\n \n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "9660f47da35c1ef6de5ad5a6b3dac243cd563000", "filename": "src/test/incremental/struct_change_field_type_cross_crate/b.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fstruct_change_field_type_cross_crate%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Fstruct_change_field_type_cross_crate%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstruct_change_field_type_cross_crate%2Fb.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -12,8 +12,6 @@\n // revisions:rpass1 rpass2\n // compile-flags: -Z query-dep-graph\n \n-// ignore-test -- ignored until red/green restores cross-crate tracking fidelity\n-\n #![feature(rustc_attrs)]\n \n extern crate a;"}, {"sha": "ee35a4d9b9c6e9f0c96af2a5ba000fb32168da90", "filename": "src/test/incremental/type_alias_cross_crate/b.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Ftype_alias_cross_crate%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d7e73e4b1abe120520d1894b89c0e25469f41e69/src%2Ftest%2Fincremental%2Ftype_alias_cross_crate%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Ftype_alias_cross_crate%2Fb.rs?ref=d7e73e4b1abe120520d1894b89c0e25469f41e69", "patch": "@@ -12,8 +12,6 @@\n // revisions:rpass1 rpass2 rpass3\n // compile-flags: -Z query-dep-graph\n \n-// ignore-test -- ignored until red/green restores cross-crate tracking fidelity\n-\n #![feature(rustc_attrs)]\n \n extern crate a;"}]}