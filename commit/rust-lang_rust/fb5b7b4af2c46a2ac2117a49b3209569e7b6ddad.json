{"sha": "fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad", "node_id": "C_kwDOAAsO6NoAKGZiNWI3YjRhZjJjNDZhMmFjMjExN2E0OWIzMjA5NTY5ZTdiNmRkYWQ", "commit": {"author": {"name": "Nika Layzell", "email": "nika@thelayzells.com", "date": "2022-06-19T17:56:04Z"}, "committer": {"name": "Nika Layzell", "email": "nika@thelayzells.com", "date": "2022-06-24T17:43:26Z"}, "message": "proc_macro: Fix expand_expr expansion of bool literals\n\nPreviously, the expand_expr method would expand bool literals as a\n`Literal` token containing a `LitKind::Bool`, rather than as an `Ident`.\nThis is not a valid token, and the `LitKind::Bool` case needs to be\nhandled seperately.\n\nTests were added to more deeply compare the streams in the expand-expr\ntest suite to catch mistakes like this in the future.", "tree": {"sha": "b97d509837020fc4a21babfd82f6ad72baf5c714", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b97d509837020fc4a21babfd82f6ad72baf5c714"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad", "html_url": "https://github.com/rust-lang/rust/commit/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad/comments", "author": {"login": "mystor", "id": 1261662, "node_id": "MDQ6VXNlcjEyNjE2NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/1261662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mystor", "html_url": "https://github.com/mystor", "followers_url": "https://api.github.com/users/mystor/followers", "following_url": "https://api.github.com/users/mystor/following{/other_user}", "gists_url": "https://api.github.com/users/mystor/gists{/gist_id}", "starred_url": "https://api.github.com/users/mystor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mystor/subscriptions", "organizations_url": "https://api.github.com/users/mystor/orgs", "repos_url": "https://api.github.com/users/mystor/repos", "events_url": "https://api.github.com/users/mystor/events{/privacy}", "received_events_url": "https://api.github.com/users/mystor/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mystor", "id": 1261662, "node_id": "MDQ6VXNlcjEyNjE2NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/1261662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mystor", "html_url": "https://github.com/mystor", "followers_url": "https://api.github.com/users/mystor/followers", "following_url": "https://api.github.com/users/mystor/following{/other_user}", "gists_url": "https://api.github.com/users/mystor/gists{/gist_id}", "starred_url": "https://api.github.com/users/mystor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mystor/subscriptions", "organizations_url": "https://api.github.com/users/mystor/orgs", "repos_url": "https://api.github.com/users/mystor/repos", "events_url": "https://api.github.com/users/mystor/events{/privacy}", "received_events_url": "https://api.github.com/users/mystor/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7036449c774860a5b348dbbe01c20704c557382e", "url": "https://api.github.com/repos/rust-lang/rust/commits/7036449c774860a5b348dbbe01c20704c557382e", "html_url": "https://github.com/rust-lang/rust/commit/7036449c774860a5b348dbbe01c20704c557382e"}], "stats": {"total": 75, "additions": 74, "deletions": 1}, "files": [{"sha": "e5c8f1c4d9ae02e2f089060630a87da8a50c75d3", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad", "patch": "@@ -448,6 +448,10 @@ impl server::TokenStream for Rustc<'_, '_> {\n         // We don't use `TokenStream::from_ast` as the tokenstream currently cannot\n         // be recovered in the general case.\n         match &expr.kind {\n+            ast::ExprKind::Lit(l) if l.token.kind == token::Bool => {\n+                Ok(tokenstream::TokenTree::token(token::Ident(l.token.symbol, false), l.span)\n+                    .into())\n+            }\n             ast::ExprKind::Lit(l) => {\n                 Ok(tokenstream::TokenTree::token(token::Literal(l.token), l.span).into())\n             }"}, {"sha": "5463e79d74e0a262eefcbcc5bfca58d53f702f4f", "filename": "src/test/ui/proc-macro/auxiliary/expand-expr.rs", "status": "modified", "additions": 70, "deletions": 1, "changes": 71, "blob_url": "https://github.com/rust-lang/rust/blob/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fexpand-expr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fexpand-expr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fauxiliary%2Fexpand-expr.rs?ref=fb5b7b4af2c46a2ac2117a49b3209569e7b6ddad", "patch": "@@ -10,6 +10,72 @@ extern crate proc_macro;\n use proc_macro::*;\n use std::str::FromStr;\n \n+// Flatten the TokenStream, removing any toplevel `Delimiter::None`s for\n+// comparison.\n+fn flatten(ts: TokenStream) -> Vec<TokenTree> {\n+    ts.into_iter()\n+        .flat_map(|tt| match &tt {\n+            TokenTree::Group(group) if group.delimiter() == Delimiter::None => {\n+                flatten(group.stream())\n+            }\n+            _ => vec![tt],\n+        })\n+        .collect()\n+}\n+\n+// Assert that two TokenStream values are roughly equal to one-another.\n+fn assert_ts_eq(lhs: &TokenStream, rhs: &TokenStream) {\n+    let ltts = flatten(lhs.clone());\n+    let rtts = flatten(rhs.clone());\n+\n+    if ltts.len() != rtts.len() {\n+        panic!(\n+            \"expected the same number of tts ({} == {})\\nlhs:\\n{:#?}\\nrhs:\\n{:#?}\",\n+            ltts.len(),\n+            rtts.len(),\n+            lhs,\n+            rhs\n+        )\n+    }\n+\n+    for (ltt, rtt) in ltts.iter().zip(&rtts) {\n+        match (ltt, rtt) {\n+            (TokenTree::Group(l), TokenTree::Group(r)) => {\n+                assert_eq!(\n+                    l.delimiter(),\n+                    r.delimiter(),\n+                    \"expected delimiters to match for {:?} and {:?}\",\n+                    l,\n+                    r\n+                );\n+                assert_ts_eq(&l.stream(), &r.stream());\n+            }\n+            (TokenTree::Punct(l), TokenTree::Punct(r)) => assert_eq!(\n+                (l.as_char(), l.spacing()),\n+                (r.as_char(), r.spacing()),\n+                \"expected punct to match for {:?} and {:?}\",\n+                l,\n+                r\n+            ),\n+            (TokenTree::Ident(l), TokenTree::Ident(r)) => assert_eq!(\n+                l.to_string(),\n+                r.to_string(),\n+                \"expected ident to match for {:?} and {:?}\",\n+                l,\n+                r\n+            ),\n+            (TokenTree::Literal(l), TokenTree::Literal(r)) => assert_eq!(\n+                l.to_string(),\n+                r.to_string(),\n+                \"expected literal to match for {:?} and {:?}\",\n+                l,\n+                r\n+            ),\n+            (l, r) => panic!(\"expected type to match for {:?} and {:?}\", l, r),\n+        }\n+    }\n+}\n+\n #[proc_macro]\n pub fn expand_expr_is(input: TokenStream) -> TokenStream {\n     let mut iter = input.into_iter();\n@@ -31,6 +97,9 @@ pub fn expand_expr_is(input: TokenStream) -> TokenStream {\n         expanded.to_string()\n     );\n \n+    // Also compare the raw tts to make sure they line up.\n+    assert_ts_eq(&expected, &expanded);\n+\n     TokenStream::new()\n }\n \n@@ -48,7 +117,7 @@ pub fn check_expand_expr_file(ts: TokenStream) -> TokenStream {\n     // invocation expand to the same literal.\n     let input_t = ts.expand_expr().expect(\"expand_expr failed on macro input\").to_string();\n     let parse_t = TokenStream::from_str(\"file!{}\")\n-    .unwrap()\n+        .unwrap()\n         .expand_expr()\n         .expect(\"expand_expr failed on internal macro\")\n         .to_string();"}]}