{"sha": "838cc9d3cc4de0abb52263a1fa2e9a6f0191a151", "node_id": "C_kwDOAAsO6NoAKDgzOGNjOWQzY2M0ZGUwYWJiNTIyNjNhMWZhMmU5YTZmMDE5MWExNTE", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-04-18T14:55:31Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-04-18T14:55:31Z"}, "message": "Auto merge of #12025 - Veykril:completion-ctx, r=Veykril\n\nminor: Document completion context some more", "tree": {"sha": "dc474dca1cef270bda1b967824d25c308e277bb9", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/dc474dca1cef270bda1b967824d25c308e277bb9"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/838cc9d3cc4de0abb52263a1fa2e9a6f0191a151", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/838cc9d3cc4de0abb52263a1fa2e9a6f0191a151", "html_url": "https://github.com/rust-lang/rust/commit/838cc9d3cc4de0abb52263a1fa2e9a6f0191a151", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/838cc9d3cc4de0abb52263a1fa2e9a6f0191a151/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e0d41bc2a171e0ce80cb16da72d8f045ef9b365b", "url": "https://api.github.com/repos/rust-lang/rust/commits/e0d41bc2a171e0ce80cb16da72d8f045ef9b365b", "html_url": "https://github.com/rust-lang/rust/commit/e0d41bc2a171e0ce80cb16da72d8f045ef9b365b"}, {"sha": "f8c32df7cda4cf6aad20dd1e2b01a6dc8659b98a", "url": "https://api.github.com/repos/rust-lang/rust/commits/f8c32df7cda4cf6aad20dd1e2b01a6dc8659b98a", "html_url": "https://github.com/rust-lang/rust/commit/f8c32df7cda4cf6aad20dd1e2b01a6dc8659b98a"}], "stats": {"total": 75, "additions": 49, "deletions": 26}, "files": [{"sha": "3ba02d78b5c0b34253bb65d471ecaf6ae7d9c67e", "filename": "crates/ide_completion/src/context.rs", "status": "modified", "additions": 49, "deletions": 26, "changes": 75, "blob_url": "https://github.com/rust-lang/rust/blob/838cc9d3cc4de0abb52263a1fa2e9a6f0191a151/crates%2Fide_completion%2Fsrc%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/838cc9d3cc4de0abb52263a1fa2e9a6f0191a151/crates%2Fide_completion%2Fsrc%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Fcontext.rs?ref=838cc9d3cc4de0abb52263a1fa2e9a6f0191a151", "patch": "@@ -148,7 +148,11 @@ pub(crate) struct CompletionContext<'a> {\n     pub(super) krate: hir::Crate,\n     /// The module of the `scope`.\n     pub(super) module: hir::Module,\n+\n+    /// The expected name of what we are completing.\n+    /// This is usually the parameter name of the function argument we are completing.\n     pub(super) expected_name: Option<NameOrNameRef>,\n+    /// The expected type of what we are completing.\n     pub(super) expected_type: Option<Type>,\n \n     /// The parent function of the cursor position if it exists.\n@@ -157,6 +161,7 @@ pub(crate) struct CompletionContext<'a> {\n     pub(super) impl_def: Option<ast::Impl>,\n     /// The NameLike under the cursor in the original file if it exists.\n     pub(super) name_syntax: Option<ast::NameLike>,\n+    /// Are we completing inside a let statement with a missing semicolon?\n     pub(super) incomplete_let: bool,\n \n     pub(super) completion_location: Option<ImmediateLocation>,\n@@ -424,6 +429,7 @@ impl<'a> CompletionContext<'a> {\n         let scope = sema.scope_at_offset(&token.parent()?, offset)?;\n         let krate = scope.krate();\n         let module = scope.module();\n+\n         let mut locals = FxHashMap::default();\n         scope.process_all_names(&mut |name, scope| {\n             if let ScopeDef::Local(local) = scope {\n@@ -467,8 +473,9 @@ impl<'a> CompletionContext<'a> {\n         Some(ctx)\n     }\n \n-    /// Do the attribute expansion at the current cursor position for both original file and fake file\n-    /// as long as possible. As soon as one of the two expansions fail we stop to stay in sync.\n+    /// Expand attributes and macro calls at the current cursor position for both the original file\n+    /// and fake file repeatedly. As soon as one of the two expansions fail we stop so the original\n+    /// and speculative states stay in sync.\n     fn expand_and_fill(\n         &mut self,\n         mut original_file: SyntaxNode,\n@@ -489,7 +496,9 @@ impl<'a> CompletionContext<'a> {\n                 ),\n                 |(a, b)| parent_item(a).zip(parent_item(b)),\n             );\n-            for (actual_item, item_with_fake_ident) in ancestor_items {\n+\n+            // first try to expand attributes as these are always the outermost macro calls\n+            'ancestors: for (actual_item, item_with_fake_ident) in ancestor_items {\n                 match (\n                     self.sema.expand_attr_macro(&actual_item),\n                     self.sema.speculative_expand_attr_macro(\n@@ -498,12 +507,14 @@ impl<'a> CompletionContext<'a> {\n                         fake_ident_token.clone(),\n                     ),\n                 ) {\n-                    // maybe parent items have attributes\n-                    (None, None) => (),\n+                    // maybe parent items have attributes, so continue walking the ancestors\n+                    (None, None) => continue 'ancestors,\n                     // successful expansions\n                     (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n                         let new_offset = fake_mapped_token.text_range().start();\n                         if new_offset > actual_expansion.text_range().end() {\n+                            // offset outside of bounds from the original expansion,\n+                            // stop here to prevent problems from happening\n                             break 'expansion;\n                         }\n                         original_file = actual_expansion;\n@@ -516,40 +527,39 @@ impl<'a> CompletionContext<'a> {\n                     _ => break 'expansion,\n                 }\n             }\n+\n+            // No attributes have been expanded, so look for macro_call! token trees or derive token trees\n             let orig_tt = match find_node_at_offset::<ast::TokenTree>(&original_file, offset) {\n                 Some(it) => it,\n-                None => break,\n+                None => break 'expansion,\n             };\n             let spec_tt = match find_node_at_offset::<ast::TokenTree>(&speculative_file, offset) {\n                 Some(it) => it,\n-                None => break,\n+                None => break 'expansion,\n             };\n \n             // Expand pseudo-derive expansion\n             if let (Some(orig_attr), Some(spec_attr)) = (\n                 orig_tt.syntax().parent().and_then(ast::Meta::cast).and_then(|it| it.parent_attr()),\n                 spec_tt.syntax().parent().and_then(ast::Meta::cast).and_then(|it| it.parent_attr()),\n             ) {\n-                match (\n+                if let (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) = (\n                     self.sema.expand_derive_as_pseudo_attr_macro(&orig_attr),\n                     self.sema.speculative_expand_derive_as_pseudo_attr_macro(\n                         &orig_attr,\n                         &spec_attr,\n                         fake_ident_token.clone(),\n                     ),\n                 ) {\n-                    // Clearly not a derive macro\n-                    (None, None) => (),\n-                    // successful expansions\n-                    (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n-                        let new_offset = fake_mapped_token.text_range().start();\n-                        derive_ctx =\n-                            Some((actual_expansion, fake_expansion, new_offset, orig_attr));\n-                        break 'expansion;\n-                    }\n-                    // exactly one expansion failed, inconsistent state so stop expanding completely\n-                    _ => break 'expansion,\n+                    derive_ctx = Some((\n+                        actual_expansion,\n+                        fake_expansion,\n+                        fake_mapped_token.text_range().start(),\n+                        orig_attr,\n+                    ));\n                 }\n+                // at this point we won't have any more successful expansions, so stop\n+                break 'expansion;\n             }\n \n             // Expand fn-like macro calls\n@@ -560,12 +570,14 @@ impl<'a> CompletionContext<'a> {\n                 let mac_call_path0 = actual_macro_call.path().as_ref().map(|s| s.syntax().text());\n                 let mac_call_path1 =\n                     macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());\n+\n+                // inconsistent state, stop expanding\n                 if mac_call_path0 != mac_call_path1 {\n-                    break;\n+                    break 'expansion;\n                 }\n                 let speculative_args = match macro_call_with_fake_ident.token_tree() {\n                     Some(tt) => tt,\n-                    None => break,\n+                    None => break 'expansion,\n                 };\n \n                 match (\n@@ -580,24 +592,30 @@ impl<'a> CompletionContext<'a> {\n                     (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n                         let new_offset = fake_mapped_token.text_range().start();\n                         if new_offset > actual_expansion.text_range().end() {\n-                            break;\n+                            // offset outside of bounds from the original expansion,\n+                            // stop here to prevent problems from happening\n+                            break 'expansion;\n                         }\n                         original_file = actual_expansion;\n                         speculative_file = fake_expansion;\n                         fake_ident_token = fake_mapped_token;\n                         offset = new_offset;\n-                        continue;\n+                        continue 'expansion;\n                     }\n-                    _ => break,\n+                    // at least on expansion failed, we won't have anything to expand from this point\n+                    // onwards so break out\n+                    _ => break 'expansion,\n                 }\n             }\n \n-            break;\n+            // none of our states have changed so stop the loop\n+            break 'expansion;\n         }\n \n         self.fill(&original_file, speculative_file, offset, derive_ctx);\n     }\n \n+    /// Calculate the expected type and name of the cursor position.\n     fn expected_type_and_name(&self) -> (Option<Type>, Option<NameOrNameRef>) {\n         let mut node = match self.token.parent() {\n             Some(it) => it,\n@@ -734,6 +752,8 @@ impl<'a> CompletionContext<'a> {\n         }\n     }\n \n+    /// Fill the completion context, this is what does semantic reasoning about the surrounding context\n+    /// of the completion location.\n     fn fill(\n         &mut self,\n         original_file: &SyntaxNode,\n@@ -1067,14 +1087,16 @@ fn pattern_context_for(original_file: &SyntaxNode, pat: ast::Pat) -> PatternCont\n     }\n }\n \n+/// Attempts to find `node` inside `syntax` via `node`'s text range.\n fn find_node_in_file<N: AstNode>(syntax: &SyntaxNode, node: &N) -> Option<N> {\n     let syntax_range = syntax.text_range();\n     let range = node.syntax().text_range();\n     let intersection = range.intersect(syntax_range)?;\n     syntax.covering_element(intersection).ancestors().find_map(N::cast)\n }\n \n-/// Compensates for the offset introduced by the fake ident\n+/// Attempts to find `node` inside `syntax` via `node`'s text range while compensating\n+/// for the offset introduced by the fake ident.\n /// This is wrong if `node` comes before the insertion point! Use `find_node_in_file` instead.\n fn find_node_in_file_compensated<N: AstNode>(syntax: &SyntaxNode, node: &N) -> Option<N> {\n     let syntax_range = syntax.text_range();\n@@ -1143,6 +1165,7 @@ const OP_TRAIT_LANG_NAMES: &[&str] = &[\n     \"shr\",\n     \"sub\",\n ];\n+\n #[cfg(test)]\n mod tests {\n     use expect_test::{expect, Expect};"}]}