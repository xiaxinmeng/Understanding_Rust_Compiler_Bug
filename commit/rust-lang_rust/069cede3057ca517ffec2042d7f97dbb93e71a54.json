{"sha": "069cede3057ca517ffec2042d7f97dbb93e71a54", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA2OWNlZGUzMDU3Y2E1MTdmZmVjMjA0MmQ3Zjk3ZGJiOTNlNzFhNTQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-03-22T04:31:42Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-03-22T04:31:42Z"}, "message": "auto merge of #13036 : alexcrichton/rust/atomics, r=alexcrichton\n\nCloses #11583, rebasing of #12430 now that we've got `Share` and better analysis with statics.", "tree": {"sha": "f7ec231b3a3b53e87fb277d7a3a623e8cb05f5e2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f7ec231b3a3b53e87fb277d7a3a623e8cb05f5e2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/069cede3057ca517ffec2042d7f97dbb93e71a54", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/069cede3057ca517ffec2042d7f97dbb93e71a54", "html_url": "https://github.com/rust-lang/rust/commit/069cede3057ca517ffec2042d7f97dbb93e71a54", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/069cede3057ca517ffec2042d7f97dbb93e71a54/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f5357cf3cee42d12249006a42dfa835f96ab5422", "url": "https://api.github.com/repos/rust-lang/rust/commits/f5357cf3cee42d12249006a42dfa835f96ab5422", "html_url": "https://github.com/rust-lang/rust/commit/f5357cf3cee42d12249006a42dfa835f96ab5422"}, {"sha": "9e66f2c6b4d102a47aa596e0dda7ba64f28bac6a", "url": "https://api.github.com/repos/rust-lang/rust/commits/9e66f2c6b4d102a47aa596e0dda7ba64f28bac6a", "html_url": "https://github.com/rust-lang/rust/commit/9e66f2c6b4d102a47aa596e0dda7ba64f28bac6a"}], "stats": {"total": 1359, "additions": 1153, "deletions": 206}, "files": [{"sha": "b4b19d88fda8461c82a7da24f7d93a5fd28dfe33", "filename": "src/librustc/middle/typeck/check/mod.rs", "status": "modified", "additions": 9, "deletions": 21, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmod.rs?ref=069cede3057ca517ffec2042d7f97dbb93e71a54", "patch": "@@ -4011,30 +4011,18 @@ pub fn check_intrinsic_type(ccx: &CrateCtxt, it: &ast::ForeignItem) {\n \n         //We only care about the operation here\n         match *split.get(1) {\n-            \"cxchg\" => (1, vec!(ty::mk_mut_rptr(tcx,\n-                                             ty::ReLateBound(it.id, ty::BrAnon(0)),\n-                                             param(ccx, 0)),\n-                        param(ccx, 0),\n-                        param(ccx, 0)), param(ccx, 0)),\n-            \"load\" => (1,\n-               vec!(\n-                  ty::mk_imm_rptr(tcx, ty::ReLateBound(it.id, ty::BrAnon(0)),\n-                                  param(ccx, 0))\n-               ),\n-              param(ccx, 0)),\n-            \"store\" => (1,\n-               vec!(\n-                  ty::mk_mut_rptr(tcx, ty::ReLateBound(it.id, ty::BrAnon(0)),\n-                                  param(ccx, 0)),\n-                  param(ccx, 0)\n-               ),\n-               ty::mk_nil()),\n+            \"cxchg\" => (1, vec!(ty::mk_mut_ptr(tcx, param(ccx, 0)),\n+                                param(ccx, 0),\n+                                param(ccx, 0)),\n+                        param(ccx, 0)),\n+            \"load\" => (1, vec!(ty::mk_imm_ptr(tcx, param(ccx, 0))),\n+                       param(ccx, 0)),\n+            \"store\" => (1, vec!(ty::mk_mut_ptr(tcx, param(ccx, 0)), param(ccx, 0)),\n+                        ty::mk_nil()),\n \n             \"xchg\" | \"xadd\" | \"xsub\" | \"and\"  | \"nand\" | \"or\" | \"xor\" | \"max\" |\n             \"min\"  | \"umax\" | \"umin\" => {\n-                (1, vec!(ty::mk_mut_rptr(tcx,\n-                                      ty::ReLateBound(it.id, ty::BrAnon(0)),\n-                                      param(ccx, 0)), param(ccx, 0) ),\n+                (1, vec!(ty::mk_mut_ptr(tcx, param(ccx, 0)), param(ccx, 0)),\n                  param(ccx, 0))\n             }\n             \"fence\" => {"}, {"sha": "95607bd8f79bdbfdadb3eb74126f48404e4d1c36", "filename": "src/libstd/intrinsics.rs", "status": "modified", "additions": 91, "deletions": 0, "changes": 91, "blob_url": "https://github.com/rust-lang/rust/blob/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibstd%2Fintrinsics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibstd%2Fintrinsics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fintrinsics.rs?ref=069cede3057ca517ffec2042d7f97dbb93e71a54", "patch": "@@ -164,6 +164,7 @@ pub trait TyVisitor {\n     fn visit_self(&mut self) -> bool;\n }\n \n+#[cfg(stage0)]\n extern \"rust-intrinsic\" {\n     pub fn atomic_cxchg<T>(dst: &mut T, old: T, src: T) -> T;\n     pub fn atomic_cxchg_acq<T>(dst: &mut T, old: T, src: T) -> T;\n@@ -244,6 +245,96 @@ extern \"rust-intrinsic\" {\n     pub fn atomic_umax_rel<T>(dst: &mut T, src: T) -> T;\n     pub fn atomic_umax_acqrel<T>(dst: &mut T, src: T) -> T;\n     pub fn atomic_umax_relaxed<T>(dst: &mut T, src: T) -> T;\n+}\n+\n+#[cfg(not(stage0))]\n+extern \"rust-intrinsic\" {\n+\n+    // NB: These intrinsics take unsafe pointers because they mutate aliased\n+    // memory, which is not valid for either `&` or `&mut`.\n+\n+    pub fn atomic_cxchg<T>(dst: *mut T, old: T, src: T) -> T;\n+    pub fn atomic_cxchg_acq<T>(dst: *mut T, old: T, src: T) -> T;\n+    pub fn atomic_cxchg_rel<T>(dst: *mut T, old: T, src: T) -> T;\n+    pub fn atomic_cxchg_acqrel<T>(dst: *mut T, old: T, src: T) -> T;\n+    pub fn atomic_cxchg_relaxed<T>(dst: *mut T, old: T, src: T) -> T;\n+\n+    pub fn atomic_load<T>(src: *T) -> T;\n+    pub fn atomic_load_acq<T>(src: *T) -> T;\n+    pub fn atomic_load_relaxed<T>(src: *T) -> T;\n+\n+    pub fn atomic_store<T>(dst: *mut T, val: T);\n+    pub fn atomic_store_rel<T>(dst: *mut T, val: T);\n+    pub fn atomic_store_relaxed<T>(dst: *mut T, val: T);\n+\n+    pub fn atomic_xchg<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xchg_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xchg_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xchg_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xchg_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_xadd<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xadd_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xadd_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xadd_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xadd_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_xsub<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xsub_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xsub_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xsub_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xsub_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_and<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_and_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_and_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_and_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_and_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_nand<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_nand_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_nand_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_nand_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_nand_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_or<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_or_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_or_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_or_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_or_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_xor<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xor_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xor_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xor_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_xor_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_max<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_max_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_max_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_max_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_max_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_min<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_min_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_min_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_min_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_min_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_umin<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_umin_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_umin_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_umin_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_umin_relaxed<T>(dst: *mut T, src: T) -> T;\n+\n+    pub fn atomic_umax<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_umax_acq<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_umax_rel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_umax_acqrel<T>(dst: *mut T, src: T) -> T;\n+    pub fn atomic_umax_relaxed<T>(dst: *mut T, src: T) -> T;\n+}\n+\n+extern \"rust-intrinsic\" {\n \n     pub fn atomic_fence();\n     pub fn atomic_fence_acq();"}, {"sha": "32e0ec3ad9d6f324bc16d671da2d937fce1d97ef", "filename": "src/libstd/sync/atomics.rs", "status": "modified", "additions": 85, "deletions": 137, "changes": 222, "blob_url": "https://github.com/rust-lang/rust/blob/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibstd%2Fsync%2Fatomics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibstd%2Fsync%2Fatomics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fatomics.rs?ref=069cede3057ca517ffec2042d7f97dbb93e71a54", "patch": "@@ -134,13 +134,6 @@ pub struct AtomicUint {\n     priv nopod: marker::NoPod\n }\n \n-/// An unsigned atomic integer type that is forced to be 64-bits. This does not\n-/// support all operations.\n-pub struct AtomicU64 {\n-    priv v: Unsafe<u64>,\n-    priv nopod: marker::NoPod\n-}\n-\n /// An unsafe atomic pointer. Only supports basic atomic operations\n pub struct AtomicPtr<T> {\n     priv p: Unsafe<uint>,\n@@ -198,11 +191,6 @@ pub static INIT_ATOMIC_INT  : AtomicInt  = AtomicInt  { v: Unsafe{value: 0,\n pub static INIT_ATOMIC_UINT : AtomicUint = AtomicUint { v: Unsafe{value: 0,\n                                                                   marker1: marker::InvariantType},\n                                                         nopod: marker::NoPod };\n-/// An `AtomicU64` initialized to `0`\n-pub static INIT_ATOMIC_U64 : AtomicU64 = AtomicU64 { v: Unsafe{value: 0,\n-                                                               marker1: marker::InvariantType},\n-                                                     nopod: marker::NoPod };\n-\n \n // NB: Needs to be -1 (0b11111111...) to make fetch_nand work correctly\n static UINT_TRUE: uint = -1;\n@@ -217,23 +205,23 @@ impl AtomicBool {\n     /// Load the value\n     #[inline]\n     pub fn load(&self, order: Ordering) -> bool {\n-        unsafe { atomic_load(&*self.v.get(), order) > 0 }\n+        unsafe { atomic_load(self.v.get() as *uint, order) > 0 }\n     }\n \n     /// Store the value\n     #[inline]\n-    pub fn store(&mut self, val: bool, order: Ordering) {\n+    pub fn store(&self, val: bool, order: Ordering) {\n         let val = if val { UINT_TRUE } else { 0 };\n \n-        unsafe { atomic_store(&mut *self.v.get(), val, order); }\n+        unsafe { atomic_store(self.v.get(), val, order); }\n     }\n \n     /// Store a value, returning the old value\n     #[inline]\n-    pub fn swap(&mut self, val: bool, order: Ordering) -> bool {\n+    pub fn swap(&self, val: bool, order: Ordering) -> bool {\n         let val = if val { UINT_TRUE } else { 0 };\n \n-        unsafe { atomic_swap(&mut *self.v.get(), val, order) > 0 }\n+        unsafe { atomic_swap(self.v.get(), val, order) > 0 }\n     }\n \n     /// If the current value is the same as expected, store a new value\n@@ -282,11 +270,11 @@ impl AtomicBool {\n     /// }\n     /// ```\n     #[inline]\n-    pub fn compare_and_swap(&mut self, old: bool, new: bool, order: Ordering) -> bool {\n+    pub fn compare_and_swap(&self, old: bool, new: bool, order: Ordering) -> bool {\n         let old = if old { UINT_TRUE } else { 0 };\n         let new = if new { UINT_TRUE } else { 0 };\n \n-        unsafe { atomic_compare_and_swap(&mut *self.v.get(), old, new, order) > 0 }\n+        unsafe { atomic_compare_and_swap(self.v.get(), old, new, order) > 0 }\n     }\n \n     /// A logical \"and\" operation\n@@ -300,23 +288,23 @@ impl AtomicBool {\n     /// ```\n     /// use std::sync::atomics::{AtomicBool, SeqCst};\n     ///\n-    /// let mut foo = AtomicBool::new(true);\n+    /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_and(false, SeqCst));\n     /// assert_eq!(false, foo.load(SeqCst));\n     ///\n-    /// let mut foo = AtomicBool::new(true);\n+    /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_and(true, SeqCst));\n     /// assert_eq!(true, foo.load(SeqCst));\n     ///\n-    /// let mut foo = AtomicBool::new(false);\n+    /// let foo = AtomicBool::new(false);\n     /// assert_eq!(false, foo.fetch_and(false, SeqCst));\n     /// assert_eq!(false, foo.load(SeqCst));\n     /// ```\n     #[inline]\n-    pub fn fetch_and(&mut self, val: bool, order: Ordering) -> bool {\n+    pub fn fetch_and(&self, val: bool, order: Ordering) -> bool {\n         let val = if val { UINT_TRUE } else { 0 };\n \n-        unsafe { atomic_and(&mut *self.v.get(), val, order) > 0 }\n+        unsafe { atomic_and(self.v.get(), val, order) > 0 }\n     }\n \n     /// A logical \"nand\" operation\n@@ -330,24 +318,24 @@ impl AtomicBool {\n     /// ```\n     /// use std::sync::atomics::{AtomicBool, SeqCst};\n     ///\n-    /// let mut foo = AtomicBool::new(true);\n+    /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_nand(false, SeqCst));\n     /// assert_eq!(true, foo.load(SeqCst));\n     ///\n-    /// let mut foo = AtomicBool::new(true);\n+    /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_nand(true, SeqCst));\n     /// assert_eq!(0, foo.load(SeqCst) as int);\n     /// assert_eq!(false, foo.load(SeqCst));\n     ///\n-    /// let mut foo = AtomicBool::new(false);\n+    /// let foo = AtomicBool::new(false);\n     /// assert_eq!(false, foo.fetch_nand(false, SeqCst));\n     /// assert_eq!(true, foo.load(SeqCst));\n     /// ```\n     #[inline]\n-    pub fn fetch_nand(&mut self, val: bool, order: Ordering) -> bool {\n+    pub fn fetch_nand(&self, val: bool, order: Ordering) -> bool {\n         let val = if val { UINT_TRUE } else { 0 };\n \n-        unsafe { atomic_nand(&mut *self.v.get(), val, order) > 0 }\n+        unsafe { atomic_nand(self.v.get(), val, order) > 0 }\n     }\n \n     /// A logical \"or\" operation\n@@ -361,23 +349,23 @@ impl AtomicBool {\n     /// ```\n     /// use std::sync::atomics::{AtomicBool, SeqCst};\n     ///\n-    /// let mut foo = AtomicBool::new(true);\n+    /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_or(false, SeqCst));\n     /// assert_eq!(true, foo.load(SeqCst));\n     ///\n-    /// let mut foo = AtomicBool::new(true);\n+    /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_or(true, SeqCst));\n     /// assert_eq!(true, foo.load(SeqCst));\n     ///\n-    /// let mut foo = AtomicBool::new(false);\n+    /// let foo = AtomicBool::new(false);\n     /// assert_eq!(false, foo.fetch_or(false, SeqCst));\n     /// assert_eq!(false, foo.load(SeqCst));\n     /// ```\n     #[inline]\n-    pub fn fetch_or(&mut self, val: bool, order: Ordering) -> bool {\n+    pub fn fetch_or(&self, val: bool, order: Ordering) -> bool {\n         let val = if val { UINT_TRUE } else { 0 };\n \n-        unsafe { atomic_or(&mut *self.v.get(), val, order) > 0 }\n+        unsafe { atomic_or(self.v.get(), val, order) > 0 }\n     }\n \n     /// A logical \"xor\" operation\n@@ -391,23 +379,23 @@ impl AtomicBool {\n     /// ```\n     /// use std::sync::atomics::{AtomicBool, SeqCst};\n     ///\n-    /// let mut foo = AtomicBool::new(true);\n+    /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_xor(false, SeqCst));\n     /// assert_eq!(true, foo.load(SeqCst));\n     ///\n-    /// let mut foo = AtomicBool::new(true);\n+    /// let foo = AtomicBool::new(true);\n     /// assert_eq!(true, foo.fetch_xor(true, SeqCst));\n     /// assert_eq!(false, foo.load(SeqCst));\n     ///\n-    /// let mut foo = AtomicBool::new(false);\n+    /// let foo = AtomicBool::new(false);\n     /// assert_eq!(false, foo.fetch_xor(false, SeqCst));\n     /// assert_eq!(false, foo.load(SeqCst));\n     /// ```\n     #[inline]\n-    pub fn fetch_xor(&mut self, val: bool, order: Ordering) -> bool {\n+    pub fn fetch_xor(&self, val: bool, order: Ordering) -> bool {\n         let val = if val { UINT_TRUE } else { 0 };\n \n-        unsafe { atomic_xor(&mut *self.v.get(), val, order) > 0 }\n+        unsafe { atomic_xor(self.v.get(), val, order) > 0 }\n     }\n }\n \n@@ -420,19 +408,19 @@ impl AtomicInt {\n     /// Load the value\n     #[inline]\n     pub fn load(&self, order: Ordering) -> int {\n-        unsafe { atomic_load(&*self.v.get(), order) }\n+        unsafe { atomic_load(self.v.get() as *int, order) }\n     }\n \n     /// Store the value\n     #[inline]\n-    pub fn store(&mut self, val: int, order: Ordering) {\n-        unsafe { atomic_store(&mut *self.v.get(), val, order); }\n+    pub fn store(&self, val: int, order: Ordering) {\n+        unsafe { atomic_store(self.v.get(), val, order); }\n     }\n \n     /// Store a value, returning the old value\n     #[inline]\n-    pub fn swap(&mut self, val: int, order: Ordering) -> int {\n-        unsafe { atomic_swap(&mut *self.v.get(), val, order) }\n+    pub fn swap(&self, val: int, order: Ordering) -> int {\n+        unsafe { atomic_swap(self.v.get(), val, order) }\n     }\n \n     /// If the current value is the same as expected, store a new value\n@@ -441,8 +429,8 @@ impl AtomicInt {\n     /// replace the current value with `new`. Return the previous value.\n     /// If the return value is equal to `old` then the value was updated.\n     #[inline]\n-    pub fn compare_and_swap(&mut self, old: int, new: int, order: Ordering) -> int {\n-        unsafe { atomic_compare_and_swap(&mut *self.v.get(), old, new, order) }\n+    pub fn compare_and_swap(&self, old: int, new: int, order: Ordering) -> int {\n+        unsafe { atomic_compare_and_swap(self.v.get(), old, new, order) }\n     }\n \n     /// Add to the current value, returning the previous\n@@ -452,13 +440,13 @@ impl AtomicInt {\n     /// ```\n     /// use std::sync::atomics::{AtomicInt, SeqCst};\n     ///\n-    /// let mut foo = AtomicInt::new(0);\n+    /// let foo = AtomicInt::new(0);\n     /// assert_eq!(0, foo.fetch_add(10, SeqCst));\n     /// assert_eq!(10, foo.load(SeqCst));\n     /// ```\n     #[inline]\n-    pub fn fetch_add(&mut self, val: int, order: Ordering) -> int {\n-        unsafe { atomic_add(&mut *self.v.get(), val, order) }\n+    pub fn fetch_add(&self, val: int, order: Ordering) -> int {\n+        unsafe { atomic_add(self.v.get(), val, order) }\n     }\n \n     /// Subtract from the current value, returning the previous\n@@ -468,53 +456,13 @@ impl AtomicInt {\n     /// ```\n     /// use std::sync::atomics::{AtomicInt, SeqCst};\n     ///\n-    /// let mut foo = AtomicInt::new(0);\n+    /// let foo = AtomicInt::new(0);\n     /// assert_eq!(0, foo.fetch_sub(10, SeqCst));\n     /// assert_eq!(-10, foo.load(SeqCst));\n     /// ```\n     #[inline]\n-    pub fn fetch_sub(&mut self, val: int, order: Ordering) -> int {\n-        unsafe { atomic_sub(&mut *self.v.get(), val, order) }\n-    }\n-}\n-\n-// temporary workaround\n-// it causes link failure on MIPS target\n-// libgcc doesn't implement 64-bit atomic operations for MIPS32\n-#[cfg(not(target_arch = \"mips\"))]\n-impl AtomicU64 {\n-    pub fn new(v: u64) -> AtomicU64 {\n-        AtomicU64 { v: Unsafe::new(v), nopod: marker::NoPod }\n-    }\n-\n-    #[inline]\n-    pub fn load(&self, order: Ordering) -> u64 {\n-        unsafe { atomic_load(&*self.v.get(), order) }\n-    }\n-\n-    #[inline]\n-    pub fn store(&mut self, val: u64, order: Ordering) {\n-        unsafe { atomic_store(&mut *self.v.get(), val, order); }\n-    }\n-\n-    #[inline]\n-    pub fn swap(&mut self, val: u64, order: Ordering) -> u64 {\n-        unsafe { atomic_swap(&mut *self.v.get(), val, order) }\n-    }\n-\n-    #[inline]\n-    pub fn compare_and_swap(&mut self, old: u64, new: u64, order: Ordering) -> u64 {\n-        unsafe { atomic_compare_and_swap(&mut *self.v.get(), old, new, order) }\n-    }\n-\n-    #[inline]\n-    pub fn fetch_add(&mut self, val: u64, order: Ordering) -> u64 {\n-        unsafe { atomic_add(&mut *self.v.get(), val, order) }\n-    }\n-\n-    #[inline]\n-    pub fn fetch_sub(&mut self, val: u64, order: Ordering) -> u64 {\n-        unsafe { atomic_sub(&mut *self.v.get(), val, order) }\n+    pub fn fetch_sub(&self, val: int, order: Ordering) -> int {\n+        unsafe { atomic_sub(self.v.get(), val, order) }\n     }\n }\n \n@@ -527,19 +475,19 @@ impl AtomicUint {\n     /// Load the value\n     #[inline]\n     pub fn load(&self, order: Ordering) -> uint {\n-        unsafe { atomic_load(&*self.v.get(), order) }\n+        unsafe { atomic_load(self.v.get() as *uint, order) }\n     }\n \n     /// Store the value\n     #[inline]\n-    pub fn store(&mut self, val: uint, order: Ordering) {\n-        unsafe { atomic_store(&mut *self.v.get(), val, order); }\n+    pub fn store(&self, val: uint, order: Ordering) {\n+        unsafe { atomic_store(self.v.get(), val, order); }\n     }\n \n     /// Store a value, returning the old value\n     #[inline]\n-    pub fn swap(&mut self, val: uint, order: Ordering) -> uint {\n-        unsafe { atomic_swap(&mut *self.v.get(), val, order) }\n+    pub fn swap(&self, val: uint, order: Ordering) -> uint {\n+        unsafe { atomic_swap(self.v.get(), val, order) }\n     }\n \n     /// If the current value is the same as expected, store a new value\n@@ -548,8 +496,8 @@ impl AtomicUint {\n     /// replace the current value with `new`. Return the previous value.\n     /// If the return value is equal to `old` then the value was updated.\n     #[inline]\n-    pub fn compare_and_swap(&mut self, old: uint, new: uint, order: Ordering) -> uint {\n-        unsafe { atomic_compare_and_swap(&mut *self.v.get(), old, new, order) }\n+    pub fn compare_and_swap(&self, old: uint, new: uint, order: Ordering) -> uint {\n+        unsafe { atomic_compare_and_swap(self.v.get(), old, new, order) }\n     }\n \n     /// Add to the current value, returning the previous\n@@ -559,13 +507,13 @@ impl AtomicUint {\n     /// ```\n     /// use std::sync::atomics::{AtomicUint, SeqCst};\n     ///\n-    /// let mut foo = AtomicUint::new(0);\n+    /// let foo = AtomicUint::new(0);\n     /// assert_eq!(0, foo.fetch_add(10, SeqCst));\n     /// assert_eq!(10, foo.load(SeqCst));\n     /// ```\n     #[inline]\n-    pub fn fetch_add(&mut self, val: uint, order: Ordering) -> uint {\n-        unsafe { atomic_add(&mut *self.v.get(), val, order) }\n+    pub fn fetch_add(&self, val: uint, order: Ordering) -> uint {\n+        unsafe { atomic_add(self.v.get(), val, order) }\n     }\n \n     /// Subtract from the current value, returning the previous\n@@ -575,13 +523,13 @@ impl AtomicUint {\n     /// ```\n     /// use std::sync::atomics::{AtomicUint, SeqCst};\n     ///\n-    /// let mut foo = AtomicUint::new(10);\n+    /// let foo = AtomicUint::new(10);\n     /// assert_eq!(10, foo.fetch_sub(10, SeqCst));\n     /// assert_eq!(0, foo.load(SeqCst));\n     /// ```\n     #[inline]\n-    pub fn fetch_sub(&mut self, val: uint, order: Ordering) -> uint {\n-        unsafe { atomic_sub(&mut *self.v.get(), val, order) }\n+    pub fn fetch_sub(&self, val: uint, order: Ordering) -> uint {\n+        unsafe { atomic_sub(self.v.get(), val, order) }\n     }\n }\n \n@@ -595,20 +543,20 @@ impl<T> AtomicPtr<T> {\n     #[inline]\n     pub fn load(&self, order: Ordering) -> *mut T {\n         unsafe {\n-            atomic_load(&*self.p.get(), order) as *mut T\n+            atomic_load(self.p.get() as **mut T, order) as *mut T\n         }\n     }\n \n     /// Store the value\n     #[inline]\n-    pub fn store(&mut self, ptr: *mut T, order: Ordering) {\n-        unsafe { atomic_store(&mut *self.p.get(), ptr as uint, order); }\n+    pub fn store(&self, ptr: *mut T, order: Ordering) {\n+        unsafe { atomic_store(self.p.get(), ptr as uint, order); }\n     }\n \n     /// Store a value, returning the old value\n     #[inline]\n-    pub fn swap(&mut self, ptr: *mut T, order: Ordering) -> *mut T {\n-        unsafe { atomic_swap(&mut *self.p.get(), ptr as uint, order) as *mut T }\n+    pub fn swap(&self, ptr: *mut T, order: Ordering) -> *mut T {\n+        unsafe { atomic_swap(self.p.get(), ptr as uint, order) as *mut T }\n     }\n \n     /// If the current value is the same as expected, store a new value\n@@ -617,9 +565,9 @@ impl<T> AtomicPtr<T> {\n     /// replace the current value with `new`. Return the previous value.\n     /// If the return value is equal to `old` then the value was updated.\n     #[inline]\n-    pub fn compare_and_swap(&mut self, old: *mut T, new: *mut T, order: Ordering) -> *mut T {\n+    pub fn compare_and_swap(&self, old: *mut T, new: *mut T, order: Ordering) -> *mut T {\n         unsafe {\n-            atomic_compare_and_swap(&mut *self.p.get(), old as uint,\n+            atomic_compare_and_swap(self.p.get(), old as uint,\n                                     new as uint, order) as *mut T\n         }\n     }\n@@ -636,11 +584,11 @@ impl<T> AtomicOption<T> {\n \n     /// Store a value, returning the old value\n     #[inline]\n-    pub fn swap(&mut self, val: ~T, order: Ordering) -> Option<~T> {\n+    pub fn swap(&self, val: ~T, order: Ordering) -> Option<~T> {\n         unsafe {\n             let val = cast::transmute(val);\n \n-            let p = atomic_swap(&mut *self.p.get(), val, order);\n+            let p = atomic_swap(self.p.get(), val, order);\n             if p as uint == 0 {\n                 None\n             } else {\n@@ -651,7 +599,7 @@ impl<T> AtomicOption<T> {\n \n     /// Remove the value, leaving the `AtomicOption` empty.\n     #[inline]\n-    pub fn take(&mut self, order: Ordering) -> Option<~T> {\n+    pub fn take(&self, order: Ordering) -> Option<~T> {\n         unsafe { self.swap(cast::transmute(0), order) }\n     }\n \n@@ -661,11 +609,11 @@ impl<T> AtomicOption<T> {\n     /// the option was already `Some`, returns `Some` of the rejected\n     /// value.\n     #[inline]\n-    pub fn fill(&mut self, val: ~T, order: Ordering) -> Option<~T> {\n+    pub fn fill(&self, val: ~T, order: Ordering) -> Option<~T> {\n         unsafe {\n             let val = cast::transmute(val);\n             let expected = cast::transmute(0);\n-            let oldval = atomic_compare_and_swap(&mut *self.p.get(), expected, val, order);\n+            let oldval = atomic_compare_and_swap(self.p.get(), expected, val, order);\n             if oldval == expected {\n                 None\n             } else {\n@@ -679,8 +627,8 @@ impl<T> AtomicOption<T> {\n     /// Be careful: The caller must have some external method of ensuring the\n     /// result does not get invalidated by another task after this returns.\n     #[inline]\n-    pub fn is_empty(&mut self, order: Ordering) -> bool {\n-        unsafe { atomic_load(&*self.p.get(), order) as uint == 0 }\n+    pub fn is_empty(&self, order: Ordering) -> bool {\n+        unsafe { atomic_load(self.p.get() as *uint, order) as uint == 0 }\n     }\n }\n \n@@ -692,7 +640,7 @@ impl<T> Drop for AtomicOption<T> {\n }\n \n #[inline]\n-pub unsafe fn atomic_store<T>(dst: &mut T, val: T, order:Ordering) {\n+unsafe fn atomic_store<T>(dst: *mut T, val: T, order:Ordering) {\n     match order {\n         Release => intrinsics::atomic_store_rel(dst, val),\n         Relaxed => intrinsics::atomic_store_relaxed(dst, val),\n@@ -701,7 +649,7 @@ pub unsafe fn atomic_store<T>(dst: &mut T, val: T, order:Ordering) {\n }\n \n #[inline]\n-pub unsafe fn atomic_load<T>(dst: &T, order:Ordering) -> T {\n+unsafe fn atomic_load<T>(dst: *T, order:Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_load_acq(dst),\n         Relaxed => intrinsics::atomic_load_relaxed(dst),\n@@ -710,7 +658,7 @@ pub unsafe fn atomic_load<T>(dst: &T, order:Ordering) -> T {\n }\n \n #[inline]\n-pub unsafe fn atomic_swap<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+unsafe fn atomic_swap<T>(dst: *mut T, val: T, order: Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_xchg_acq(dst, val),\n         Release => intrinsics::atomic_xchg_rel(dst, val),\n@@ -722,7 +670,7 @@ pub unsafe fn atomic_swap<T>(dst: &mut T, val: T, order: Ordering) -> T {\n \n /// Returns the old value (like __sync_fetch_and_add).\n #[inline]\n-pub unsafe fn atomic_add<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+unsafe fn atomic_add<T>(dst: *mut T, val: T, order: Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_xadd_acq(dst, val),\n         Release => intrinsics::atomic_xadd_rel(dst, val),\n@@ -734,7 +682,7 @@ pub unsafe fn atomic_add<T>(dst: &mut T, val: T, order: Ordering) -> T {\n \n /// Returns the old value (like __sync_fetch_and_sub).\n #[inline]\n-pub unsafe fn atomic_sub<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+unsafe fn atomic_sub<T>(dst: *mut T, val: T, order: Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_xsub_acq(dst, val),\n         Release => intrinsics::atomic_xsub_rel(dst, val),\n@@ -745,7 +693,7 @@ pub unsafe fn atomic_sub<T>(dst: &mut T, val: T, order: Ordering) -> T {\n }\n \n #[inline]\n-pub unsafe fn atomic_compare_and_swap<T>(dst:&mut T, old:T, new:T, order: Ordering) -> T {\n+unsafe fn atomic_compare_and_swap<T>(dst: *mut T, old:T, new:T, order: Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_cxchg_acq(dst, old, new),\n         Release => intrinsics::atomic_cxchg_rel(dst, old, new),\n@@ -756,7 +704,7 @@ pub unsafe fn atomic_compare_and_swap<T>(dst:&mut T, old:T, new:T, order: Orderi\n }\n \n #[inline]\n-pub unsafe fn atomic_and<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+unsafe fn atomic_and<T>(dst: *mut T, val: T, order: Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_and_acq(dst, val),\n         Release => intrinsics::atomic_and_rel(dst, val),\n@@ -767,7 +715,7 @@ pub unsafe fn atomic_and<T>(dst: &mut T, val: T, order: Ordering) -> T {\n }\n \n #[inline]\n-pub unsafe fn atomic_nand<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+unsafe fn atomic_nand<T>(dst: *mut T, val: T, order: Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_nand_acq(dst, val),\n         Release => intrinsics::atomic_nand_rel(dst, val),\n@@ -779,7 +727,7 @@ pub unsafe fn atomic_nand<T>(dst: &mut T, val: T, order: Ordering) -> T {\n \n \n #[inline]\n-pub unsafe fn atomic_or<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+unsafe fn atomic_or<T>(dst: *mut T, val: T, order: Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_or_acq(dst, val),\n         Release => intrinsics::atomic_or_rel(dst, val),\n@@ -791,7 +739,7 @@ pub unsafe fn atomic_or<T>(dst: &mut T, val: T, order: Ordering) -> T {\n \n \n #[inline]\n-pub unsafe fn atomic_xor<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+unsafe fn atomic_xor<T>(dst: *mut T, val: T, order: Ordering) -> T {\n     match order {\n         Acquire => intrinsics::atomic_xor_acq(dst, val),\n         Release => intrinsics::atomic_xor_rel(dst, val),\n@@ -842,7 +790,7 @@ mod test {\n \n     #[test]\n     fn bool_() {\n-        let mut a = AtomicBool::new(false);\n+        let a = AtomicBool::new(false);\n         assert_eq!(a.compare_and_swap(false, true, SeqCst), false);\n         assert_eq!(a.compare_and_swap(false, true, SeqCst), true);\n \n@@ -852,13 +800,13 @@ mod test {\n \n     #[test]\n     fn option_empty() {\n-        let mut option: AtomicOption<()> = AtomicOption::empty();\n+        let option: AtomicOption<()> = AtomicOption::empty();\n         assert!(option.is_empty(SeqCst));\n     }\n \n     #[test]\n     fn option_swap() {\n-        let mut p = AtomicOption::new(~1);\n+        let p = AtomicOption::new(~1);\n         let a = ~2;\n \n         let b = p.swap(a, SeqCst);\n@@ -869,7 +817,7 @@ mod test {\n \n     #[test]\n     fn option_take() {\n-        let mut p = AtomicOption::new(~1);\n+        let p = AtomicOption::new(~1);\n \n         assert_eq!(p.take(SeqCst), Some(~1));\n         assert_eq!(p.take(SeqCst), None);\n@@ -882,7 +830,7 @@ mod test {\n \n     #[test]\n     fn option_fill() {\n-        let mut p = AtomicOption::new(~1);\n+        let p = AtomicOption::new(~1);\n         assert!(p.fill(~2, SeqCst).is_some()); // should fail; shouldn't leak!\n         assert_eq!(p.take(SeqCst), Some(~1));\n \n@@ -892,7 +840,7 @@ mod test {\n \n     #[test]\n     fn bool_and() {\n-        let mut a = AtomicBool::new(true);\n+        let a = AtomicBool::new(true);\n         assert_eq!(a.fetch_and(false, SeqCst),true);\n         assert_eq!(a.load(SeqCst),false);\n     }\n@@ -919,8 +867,8 @@ mod test {\n             let mut slot = 0u8;\n             assert_eq!(super::atomic_compare_and_swap(&mut slot, 1, 2, SeqCst), 0);\n \n-            let mut slot = 0u32;\n-            assert_eq!(super::atomic_load(&mut slot, SeqCst), 0);\n+            let slot = 0u32;\n+            assert_eq!(super::atomic_load(&slot, SeqCst), 0);\n \n             let mut slot = 0u64;\n             super::atomic_store(&mut slot, 2, SeqCst);"}, {"sha": "b501972532d62daf791ac9f0890e9d818ae57f27", "filename": "src/libstd/sync/atomics_stage0.rs", "status": "added", "additions": 930, "deletions": 0, "changes": 930, "blob_url": "https://github.com/rust-lang/rust/blob/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibstd%2Fsync%2Fatomics_stage0.rs", "raw_url": "https://github.com/rust-lang/rust/raw/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibstd%2Fsync%2Fatomics_stage0.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fatomics_stage0.rs?ref=069cede3057ca517ffec2042d7f97dbb93e71a54", "patch": "@@ -0,0 +1,930 @@\n+// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! Atomic types\n+//!\n+//! Atomic types provide primitive shared-memory communication between\n+//! threads, and are the building blocks of other concurrent\n+//! types.\n+//!\n+//! This module defines atomic versions of a select number of primitive\n+//! types, including `AtomicBool`, `AtomicInt`, `AtomicUint`, and `AtomicOption`.\n+//! Atomic types present operations that, when used correctly, synchronize\n+//! updates between threads.\n+//!\n+//! Each method takes an `Ordering` which represents the strength of\n+//! the memory barrier for that operation. These orderings are the\n+//! same as [C++11 atomic orderings][1].\n+//!\n+//! [1]: http://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync\n+//!\n+//! Atomic variables are safe to share between threads (they implement `Share`)\n+//! but they do not themselves provide the mechanism for sharing. The most\n+//! common way to share an atomic variable is to put it into an `Arc` (an\n+//! atomically-reference-counted shared pointer).\n+//!\n+//! Most atomic types may be stored in static variables, initialized using\n+//! the provided static initializers like `INIT_ATOMIC_BOOL`. Atomic statics\n+//! are often used for lazy global initialization.\n+//!\n+//!\n+//! # Examples\n+//!\n+//! A simple spinlock:\n+//!\n+//! ```ignore\n+//! # // FIXME: Needs PR #12430\n+//! extern crate sync;\n+//!\n+//! use sync::Arc;\n+//! use std::sync::atomics::{AtomicUint, SeqCst};\n+//! use std::task::deschedule;\n+//!\n+//! fn main() {\n+//!     let spinlock = Arc::new(AtomicUint::new(1));\n+//!\n+//!     let spinlock_clone = spinlock.clone();\n+//!     spawn(proc() {\n+//!         spinlock_clone.store(0, SeqCst);\n+//!     });\n+//!\n+//!     // Wait for the other task to release the lock\n+//!     while spinlock.load(SeqCst) != 0 {\n+//!         // Since tasks may not be preemptive (if they are green threads)\n+//!         // yield to the scheduler to let the other task run. Low level\n+//!         // concurrent code needs to take into account Rust's two threading\n+//!         // models.\n+//!         deschedule();\n+//!     }\n+//! }\n+//! ```\n+//!\n+//! Transferring a heap object with `AtomicOption`:\n+//!\n+//! ```ignore\n+//! # // FIXME: Needs PR #12430\n+//! extern crate sync;\n+//!\n+//! use sync::Arc;\n+//! use std::sync::atomics::{AtomicOption, SeqCst};\n+//!\n+//! fn main() {\n+//!     struct BigObject;\n+//!\n+//!     let shared_big_object = Arc::new(AtomicOption::empty());\n+//!\n+//!     let shared_big_object_clone = shared_big_object.clone();\n+//!     spawn(proc() {\n+//!         let unwrapped_big_object = shared_big_object_clone.take(SeqCst);\n+//!         if unwrapped_big_object.is_some() {\n+//!             println!(\"got a big object from another task\");\n+//!         } else {\n+//!             println!(\"other task hasn't sent big object yet\");\n+//!         }\n+//!     });\n+//!\n+//!     shared_big_object.swap(~BigObject, SeqCst);\n+//! }\n+//! ```\n+//!\n+//! Keep a global count of live tasks:\n+//!\n+//! ```\n+//! use std::sync::atomics::{AtomicUint, SeqCst, INIT_ATOMIC_UINT};\n+//!\n+//! static mut GLOBAL_TASK_COUNT: AtomicUint = INIT_ATOMIC_UINT;\n+//!\n+//! unsafe {\n+//!     let old_task_count = GLOBAL_TASK_COUNT.fetch_add(1, SeqCst);\n+//!     println!(\"live tasks: {}\", old_task_count + 1);\n+//! }\n+//! ```\n+\n+#[allow(missing_doc)];\n+\n+use intrinsics;\n+use cast;\n+use std::kinds::marker;\n+use option::{Option,Some,None};\n+use ops::Drop;\n+use ty::Unsafe;\n+\n+/// An atomic boolean type.\n+pub struct AtomicBool {\n+    priv v: Unsafe<uint>,\n+    priv nopod: marker::NoPod\n+}\n+\n+/// A signed atomic integer type, supporting basic atomic arithmetic operations\n+pub struct AtomicInt {\n+    priv v: Unsafe<int>,\n+    priv nopod: marker::NoPod\n+}\n+\n+/// An unsigned atomic integer type, supporting basic atomic arithmetic operations\n+pub struct AtomicUint {\n+    priv v: Unsafe<uint>,\n+    priv nopod: marker::NoPod\n+}\n+\n+/// An unsigned atomic integer type that is forced to be 64-bits. This does not\n+/// support all operations.\n+pub struct AtomicU64 {\n+    priv v: Unsafe<u64>,\n+    priv nopod: marker::NoPod\n+}\n+\n+/// An unsafe atomic pointer. Only supports basic atomic operations\n+pub struct AtomicPtr<T> {\n+    priv p: Unsafe<uint>,\n+    priv nopod: marker::NoPod\n+}\n+\n+/// An atomic, nullable unique pointer\n+///\n+/// This can be used as the concurrency primitive for operations that transfer\n+/// owned heap objects across tasks.\n+#[unsafe_no_drop_flag]\n+pub struct AtomicOption<T> {\n+    priv p: Unsafe<uint>,\n+}\n+\n+/// Atomic memory orderings\n+///\n+/// Memory orderings limit the ways that both the compiler and CPU may reorder\n+/// instructions around atomic operations. At its most restrictive,\n+/// \"sequentially consistent\" atomics allow neither reads nor writes\n+/// to be moved either before or after the atomic operation; on the other end\n+/// \"relaxed\" atomics allow all reorderings.\n+///\n+/// Rust's memory orderings are the same as in C++[1].\n+///\n+/// [1]: http://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync\n+pub enum Ordering {\n+    /// No ordering constraints, only atomic operations\n+    Relaxed,\n+    /// When coupled with a store, all previous writes become visible\n+    /// to another thread that performs a load with `Acquire` ordering\n+    /// on the same value\n+    Release,\n+    /// When coupled with a load, all subsequent loads will see data\n+    /// written before a store with `Release` ordering on the same value\n+    /// in another thread\n+    Acquire,\n+    /// When coupled with a load, uses `Acquire` ordering, and with a store\n+    /// `Release` ordering\n+    AcqRel,\n+    /// Like `AcqRel` with the additional guarantee that all threads see all\n+    /// sequentially consistent operations in the same order.\n+    SeqCst\n+}\n+\n+/// An `AtomicBool` initialized to `false`\n+pub static INIT_ATOMIC_BOOL : AtomicBool = AtomicBool { v: Unsafe{value: 0,\n+                                                                  marker1: marker::InvariantType},\n+                                                        nopod: marker::NoPod };\n+/// An `AtomicInt` initialized to `0`\n+pub static INIT_ATOMIC_INT  : AtomicInt  = AtomicInt  { v: Unsafe{value: 0,\n+                                                                  marker1: marker::InvariantType},\n+                                                        nopod: marker::NoPod };\n+/// An `AtomicUint` initialized to `0`\n+pub static INIT_ATOMIC_UINT : AtomicUint = AtomicUint { v: Unsafe{value: 0,\n+                                                                  marker1: marker::InvariantType},\n+                                                        nopod: marker::NoPod };\n+/// An `AtomicU64` initialized to `0`\n+pub static INIT_ATOMIC_U64 : AtomicU64 = AtomicU64 { v: Unsafe{value: 0,\n+                                                               marker1: marker::InvariantType},\n+                                                     nopod: marker::NoPod };\n+\n+\n+// NB: Needs to be -1 (0b11111111...) to make fetch_nand work correctly\n+static UINT_TRUE: uint = -1;\n+\n+impl AtomicBool {\n+    /// Create a new `AtomicBool`\n+    pub fn new(v: bool) -> AtomicBool {\n+        let val = if v { UINT_TRUE } else { 0 };\n+        AtomicBool { v: Unsafe::new(val), nopod: marker::NoPod }\n+    }\n+\n+    /// Load the value\n+    #[inline]\n+    pub fn load(&self, order: Ordering) -> bool {\n+        unsafe { atomic_load(&*self.v.get(), order) > 0 }\n+    }\n+\n+    /// Store the value\n+    #[inline]\n+    pub fn store(&mut self, val: bool, order: Ordering) {\n+        let val = if val { UINT_TRUE } else { 0 };\n+\n+        unsafe { atomic_store(&mut *self.v.get(), val, order); }\n+    }\n+\n+    /// Store a value, returning the old value\n+    #[inline]\n+    pub fn swap(&mut self, val: bool, order: Ordering) -> bool {\n+        let val = if val { UINT_TRUE } else { 0 };\n+\n+        unsafe { atomic_swap(&mut *self.v.get(), val, order) > 0 }\n+    }\n+\n+    /// If the current value is the same as expected, store a new value\n+    ///\n+    /// Compare the current value with `old`; if they are the same then\n+    /// replace the current value with `new`. Return the previous value.\n+    /// If the return value is equal to `old` then the value was updated.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```ignore\n+    /// # // FIXME: Needs PR #12430\n+    /// extern crate sync;\n+    ///\n+    /// use sync::Arc;\n+    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    ///\n+    /// fn main() {\n+    ///     let spinlock = Arc::new(AtomicBool::new(false));\n+    ///     let spinlock_clone = spin_lock.clone();\n+    ///\n+    ///     spawn(proc() {\n+    ///         with_lock(&spinlock, || println!(\"task 1 in lock\"));\n+    ///     });\n+    ///\n+    ///     spawn(proc() {\n+    ///         with_lock(&spinlock_clone, || println!(\"task 2 in lock\"));\n+    ///     });\n+    /// }\n+    ///\n+    /// fn with_lock(spinlock: &Arc<AtomicBool>, f: || -> ()) {\n+    ///     // CAS loop until we are able to replace `false` with `true`\n+    ///     while spinlock.compare_and_swap(false, true, SeqCst) == false {\n+    ///         // Since tasks may not be preemptive (if they are green threads)\n+    ///         // yield to the scheduler to let the other task run. Low level\n+    ///         // concurrent code needs to take into account Rust's two threading\n+    ///         // models.\n+    ///         deschedule();\n+    ///     }\n+    ///\n+    ///     // Now we have the spinlock\n+    ///     f();\n+    ///\n+    ///     // Release the lock\n+    ///     spinlock.store(false);\n+    /// }\n+    /// ```\n+    #[inline]\n+    pub fn compare_and_swap(&mut self, old: bool, new: bool, order: Ordering) -> bool {\n+        let old = if old { UINT_TRUE } else { 0 };\n+        let new = if new { UINT_TRUE } else { 0 };\n+\n+        unsafe { atomic_compare_and_swap(&mut *self.v.get(), old, new, order) > 0 }\n+    }\n+\n+    /// A logical \"and\" operation\n+    ///\n+    /// Performs a logical \"and\" operation on the current value and the\n+    /// argument `val`, and sets the new value to the result.\n+    /// Returns the previous value.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    ///\n+    /// let mut foo = AtomicBool::new(true);\n+    /// assert_eq!(true, foo.fetch_and(false, SeqCst));\n+    /// assert_eq!(false, foo.load(SeqCst));\n+    ///\n+    /// let mut foo = AtomicBool::new(true);\n+    /// assert_eq!(true, foo.fetch_and(true, SeqCst));\n+    /// assert_eq!(true, foo.load(SeqCst));\n+    ///\n+    /// let mut foo = AtomicBool::new(false);\n+    /// assert_eq!(false, foo.fetch_and(false, SeqCst));\n+    /// assert_eq!(false, foo.load(SeqCst));\n+    /// ```\n+    #[inline]\n+    pub fn fetch_and(&mut self, val: bool, order: Ordering) -> bool {\n+        let val = if val { UINT_TRUE } else { 0 };\n+\n+        unsafe { atomic_and(&mut *self.v.get(), val, order) > 0 }\n+    }\n+\n+    /// A logical \"nand\" operation\n+    ///\n+    /// Performs a logical \"nand\" operation on the current value and the\n+    /// argument `val`, and sets the new value to the result.\n+    /// Returns the previous value.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    ///\n+    /// let mut foo = AtomicBool::new(true);\n+    /// assert_eq!(true, foo.fetch_nand(false, SeqCst));\n+    /// assert_eq!(true, foo.load(SeqCst));\n+    ///\n+    /// let mut foo = AtomicBool::new(true);\n+    /// assert_eq!(true, foo.fetch_nand(true, SeqCst));\n+    /// assert_eq!(0, foo.load(SeqCst) as int);\n+    /// assert_eq!(false, foo.load(SeqCst));\n+    ///\n+    /// let mut foo = AtomicBool::new(false);\n+    /// assert_eq!(false, foo.fetch_nand(false, SeqCst));\n+    /// assert_eq!(true, foo.load(SeqCst));\n+    /// ```\n+    #[inline]\n+    pub fn fetch_nand(&mut self, val: bool, order: Ordering) -> bool {\n+        let val = if val { UINT_TRUE } else { 0 };\n+\n+        unsafe { atomic_nand(&mut *self.v.get(), val, order) > 0 }\n+    }\n+\n+    /// A logical \"or\" operation\n+    ///\n+    /// Performs a logical \"or\" operation on the current value and the\n+    /// argument `val`, and sets the new value to the result.\n+    /// Returns the previous value.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    ///\n+    /// let mut foo = AtomicBool::new(true);\n+    /// assert_eq!(true, foo.fetch_or(false, SeqCst));\n+    /// assert_eq!(true, foo.load(SeqCst));\n+    ///\n+    /// let mut foo = AtomicBool::new(true);\n+    /// assert_eq!(true, foo.fetch_or(true, SeqCst));\n+    /// assert_eq!(true, foo.load(SeqCst));\n+    ///\n+    /// let mut foo = AtomicBool::new(false);\n+    /// assert_eq!(false, foo.fetch_or(false, SeqCst));\n+    /// assert_eq!(false, foo.load(SeqCst));\n+    /// ```\n+    #[inline]\n+    pub fn fetch_or(&mut self, val: bool, order: Ordering) -> bool {\n+        let val = if val { UINT_TRUE } else { 0 };\n+\n+        unsafe { atomic_or(&mut *self.v.get(), val, order) > 0 }\n+    }\n+\n+    /// A logical \"xor\" operation\n+    ///\n+    /// Performs a logical \"xor\" operation on the current value and the\n+    /// argument `val`, and sets the new value to the result.\n+    /// Returns the previous value.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::atomics::{AtomicBool, SeqCst};\n+    ///\n+    /// let mut foo = AtomicBool::new(true);\n+    /// assert_eq!(true, foo.fetch_xor(false, SeqCst));\n+    /// assert_eq!(true, foo.load(SeqCst));\n+    ///\n+    /// let mut foo = AtomicBool::new(true);\n+    /// assert_eq!(true, foo.fetch_xor(true, SeqCst));\n+    /// assert_eq!(false, foo.load(SeqCst));\n+    ///\n+    /// let mut foo = AtomicBool::new(false);\n+    /// assert_eq!(false, foo.fetch_xor(false, SeqCst));\n+    /// assert_eq!(false, foo.load(SeqCst));\n+    /// ```\n+    #[inline]\n+    pub fn fetch_xor(&mut self, val: bool, order: Ordering) -> bool {\n+        let val = if val { UINT_TRUE } else { 0 };\n+\n+        unsafe { atomic_xor(&mut *self.v.get(), val, order) > 0 }\n+    }\n+}\n+\n+impl AtomicInt {\n+    /// Create a new `AtomicInt`\n+    pub fn new(v: int) -> AtomicInt {\n+        AtomicInt {v: Unsafe::new(v), nopod: marker::NoPod}\n+    }\n+\n+    /// Load the value\n+    #[inline]\n+    pub fn load(&self, order: Ordering) -> int {\n+        unsafe { atomic_load(&*self.v.get(), order) }\n+    }\n+\n+    /// Store the value\n+    #[inline]\n+    pub fn store(&mut self, val: int, order: Ordering) {\n+        unsafe { atomic_store(&mut *self.v.get(), val, order); }\n+    }\n+\n+    /// Store a value, returning the old value\n+    #[inline]\n+    pub fn swap(&mut self, val: int, order: Ordering) -> int {\n+        unsafe { atomic_swap(&mut *self.v.get(), val, order) }\n+    }\n+\n+    /// If the current value is the same as expected, store a new value\n+    ///\n+    /// Compare the current value with `old`; if they are the same then\n+    /// replace the current value with `new`. Return the previous value.\n+    /// If the return value is equal to `old` then the value was updated.\n+    #[inline]\n+    pub fn compare_and_swap(&mut self, old: int, new: int, order: Ordering) -> int {\n+        unsafe { atomic_compare_and_swap(&mut *self.v.get(), old, new, order) }\n+    }\n+\n+    /// Add to the current value, returning the previous\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::atomics::{AtomicInt, SeqCst};\n+    ///\n+    /// let mut foo = AtomicInt::new(0);\n+    /// assert_eq!(0, foo.fetch_add(10, SeqCst));\n+    /// assert_eq!(10, foo.load(SeqCst));\n+    /// ```\n+    #[inline]\n+    pub fn fetch_add(&mut self, val: int, order: Ordering) -> int {\n+        unsafe { atomic_add(&mut *self.v.get(), val, order) }\n+    }\n+\n+    /// Subtract from the current value, returning the previous\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::atomics::{AtomicInt, SeqCst};\n+    ///\n+    /// let mut foo = AtomicInt::new(0);\n+    /// assert_eq!(0, foo.fetch_sub(10, SeqCst));\n+    /// assert_eq!(-10, foo.load(SeqCst));\n+    /// ```\n+    #[inline]\n+    pub fn fetch_sub(&mut self, val: int, order: Ordering) -> int {\n+        unsafe { atomic_sub(&mut *self.v.get(), val, order) }\n+    }\n+}\n+\n+// temporary workaround\n+// it causes link failure on MIPS target\n+// libgcc doesn't implement 64-bit atomic operations for MIPS32\n+#[cfg(not(target_arch = \"mips\"))]\n+impl AtomicU64 {\n+    pub fn new(v: u64) -> AtomicU64 {\n+        AtomicU64 { v: Unsafe::new(v), nopod: marker::NoPod }\n+    }\n+\n+    #[inline]\n+    pub fn load(&self, order: Ordering) -> u64 {\n+        unsafe { atomic_load(&*self.v.get(), order) }\n+    }\n+\n+    #[inline]\n+    pub fn store(&mut self, val: u64, order: Ordering) {\n+        unsafe { atomic_store(&mut *self.v.get(), val, order); }\n+    }\n+\n+    #[inline]\n+    pub fn swap(&mut self, val: u64, order: Ordering) -> u64 {\n+        unsafe { atomic_swap(&mut *self.v.get(), val, order) }\n+    }\n+\n+    #[inline]\n+    pub fn compare_and_swap(&mut self, old: u64, new: u64, order: Ordering) -> u64 {\n+        unsafe { atomic_compare_and_swap(&mut *self.v.get(), old, new, order) }\n+    }\n+\n+    #[inline]\n+    pub fn fetch_add(&mut self, val: u64, order: Ordering) -> u64 {\n+        unsafe { atomic_add(&mut *self.v.get(), val, order) }\n+    }\n+\n+    #[inline]\n+    pub fn fetch_sub(&mut self, val: u64, order: Ordering) -> u64 {\n+        unsafe { atomic_sub(&mut *self.v.get(), val, order) }\n+    }\n+}\n+\n+impl AtomicUint {\n+    /// Create a new `AtomicUint`\n+    pub fn new(v: uint) -> AtomicUint {\n+        AtomicUint { v: Unsafe::new(v), nopod: marker::NoPod }\n+    }\n+\n+    /// Load the value\n+    #[inline]\n+    pub fn load(&self, order: Ordering) -> uint {\n+        unsafe { atomic_load(&*self.v.get(), order) }\n+    }\n+\n+    /// Store the value\n+    #[inline]\n+    pub fn store(&mut self, val: uint, order: Ordering) {\n+        unsafe { atomic_store(&mut *self.v.get(), val, order); }\n+    }\n+\n+    /// Store a value, returning the old value\n+    #[inline]\n+    pub fn swap(&mut self, val: uint, order: Ordering) -> uint {\n+        unsafe { atomic_swap(&mut *self.v.get(), val, order) }\n+    }\n+\n+    /// If the current value is the same as expected, store a new value\n+    ///\n+    /// Compare the current value with `old`; if they are the same then\n+    /// replace the current value with `new`. Return the previous value.\n+    /// If the return value is equal to `old` then the value was updated.\n+    #[inline]\n+    pub fn compare_and_swap(&mut self, old: uint, new: uint, order: Ordering) -> uint {\n+        unsafe { atomic_compare_and_swap(&mut *self.v.get(), old, new, order) }\n+    }\n+\n+    /// Add to the current value, returning the previous\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    ///\n+    /// let mut foo = AtomicUint::new(0);\n+    /// assert_eq!(0, foo.fetch_add(10, SeqCst));\n+    /// assert_eq!(10, foo.load(SeqCst));\n+    /// ```\n+    #[inline]\n+    pub fn fetch_add(&mut self, val: uint, order: Ordering) -> uint {\n+        unsafe { atomic_add(&mut *self.v.get(), val, order) }\n+    }\n+\n+    /// Subtract from the current value, returning the previous\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use std::sync::atomics::{AtomicUint, SeqCst};\n+    ///\n+    /// let mut foo = AtomicUint::new(10);\n+    /// assert_eq!(10, foo.fetch_sub(10, SeqCst));\n+    /// assert_eq!(0, foo.load(SeqCst));\n+    /// ```\n+    #[inline]\n+    pub fn fetch_sub(&mut self, val: uint, order: Ordering) -> uint {\n+        unsafe { atomic_sub(&mut *self.v.get(), val, order) }\n+    }\n+}\n+\n+impl<T> AtomicPtr<T> {\n+    /// Create a new `AtomicPtr`\n+    pub fn new(p: *mut T) -> AtomicPtr<T> {\n+        AtomicPtr { p: Unsafe::new(p as uint), nopod: marker::NoPod }\n+    }\n+\n+    /// Load the value\n+    #[inline]\n+    pub fn load(&self, order: Ordering) -> *mut T {\n+        unsafe {\n+            atomic_load(&*self.p.get(), order) as *mut T\n+        }\n+    }\n+\n+    /// Store the value\n+    #[inline]\n+    pub fn store(&mut self, ptr: *mut T, order: Ordering) {\n+        unsafe { atomic_store(&mut *self.p.get(), ptr as uint, order); }\n+    }\n+\n+    /// Store a value, returning the old value\n+    #[inline]\n+    pub fn swap(&mut self, ptr: *mut T, order: Ordering) -> *mut T {\n+        unsafe { atomic_swap(&mut *self.p.get(), ptr as uint, order) as *mut T }\n+    }\n+\n+    /// If the current value is the same as expected, store a new value\n+    ///\n+    /// Compare the current value with `old`; if they are the same then\n+    /// replace the current value with `new`. Return the previous value.\n+    /// If the return value is equal to `old` then the value was updated.\n+    #[inline]\n+    pub fn compare_and_swap(&mut self, old: *mut T, new: *mut T, order: Ordering) -> *mut T {\n+        unsafe {\n+            atomic_compare_and_swap(&mut *self.p.get(), old as uint,\n+                                    new as uint, order) as *mut T\n+        }\n+    }\n+}\n+\n+impl<T> AtomicOption<T> {\n+    /// Create a new `AtomicOption`\n+    pub fn new(p: ~T) -> AtomicOption<T> {\n+        unsafe { AtomicOption { p: Unsafe::new(cast::transmute(p)) } }\n+    }\n+\n+    /// Create a new `AtomicOption` that doesn't contain a value\n+    pub fn empty() -> AtomicOption<T> { AtomicOption { p: Unsafe::new(0) } }\n+\n+    /// Store a value, returning the old value\n+    #[inline]\n+    pub fn swap(&mut self, val: ~T, order: Ordering) -> Option<~T> {\n+        unsafe {\n+            let val = cast::transmute(val);\n+\n+            let p = atomic_swap(&mut *self.p.get(), val, order);\n+            if p as uint == 0 {\n+                None\n+            } else {\n+                Some(cast::transmute(p))\n+            }\n+        }\n+    }\n+\n+    /// Remove the value, leaving the `AtomicOption` empty.\n+    #[inline]\n+    pub fn take(&mut self, order: Ordering) -> Option<~T> {\n+        unsafe { self.swap(cast::transmute(0), order) }\n+    }\n+\n+    /// Replace an empty value with a non-empty value.\n+    ///\n+    /// Succeeds if the option is `None` and returns `None` if so. If\n+    /// the option was already `Some`, returns `Some` of the rejected\n+    /// value.\n+    #[inline]\n+    pub fn fill(&mut self, val: ~T, order: Ordering) -> Option<~T> {\n+        unsafe {\n+            let val = cast::transmute(val);\n+            let expected = cast::transmute(0);\n+            let oldval = atomic_compare_and_swap(&mut *self.p.get(), expected, val, order);\n+            if oldval == expected {\n+                None\n+            } else {\n+                Some(cast::transmute(val))\n+            }\n+        }\n+    }\n+\n+    /// Returns `true` if the `AtomicOption` is empty.\n+    ///\n+    /// Be careful: The caller must have some external method of ensuring the\n+    /// result does not get invalidated by another task after this returns.\n+    #[inline]\n+    pub fn is_empty(&mut self, order: Ordering) -> bool {\n+        unsafe { atomic_load(&*self.p.get(), order) as uint == 0 }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl<T> Drop for AtomicOption<T> {\n+    fn drop(&mut self) {\n+        let _ = self.take(SeqCst);\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn atomic_store<T>(dst: &mut T, val: T, order:Ordering) {\n+    match order {\n+        Release => intrinsics::atomic_store_rel(dst, val),\n+        Relaxed => intrinsics::atomic_store_relaxed(dst, val),\n+        _       => intrinsics::atomic_store(dst, val)\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn atomic_load<T>(dst: &T, order:Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_load_acq(dst),\n+        Relaxed => intrinsics::atomic_load_relaxed(dst),\n+        _       => intrinsics::atomic_load(dst)\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn atomic_swap<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_xchg_acq(dst, val),\n+        Release => intrinsics::atomic_xchg_rel(dst, val),\n+        AcqRel  => intrinsics::atomic_xchg_acqrel(dst, val),\n+        Relaxed => intrinsics::atomic_xchg_relaxed(dst, val),\n+        _       => intrinsics::atomic_xchg(dst, val)\n+    }\n+}\n+\n+/// Returns the old value (like __sync_fetch_and_add).\n+#[inline]\n+pub unsafe fn atomic_add<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_xadd_acq(dst, val),\n+        Release => intrinsics::atomic_xadd_rel(dst, val),\n+        AcqRel  => intrinsics::atomic_xadd_acqrel(dst, val),\n+        Relaxed => intrinsics::atomic_xadd_relaxed(dst, val),\n+        _       => intrinsics::atomic_xadd(dst, val)\n+    }\n+}\n+\n+/// Returns the old value (like __sync_fetch_and_sub).\n+#[inline]\n+pub unsafe fn atomic_sub<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_xsub_acq(dst, val),\n+        Release => intrinsics::atomic_xsub_rel(dst, val),\n+        AcqRel  => intrinsics::atomic_xsub_acqrel(dst, val),\n+        Relaxed => intrinsics::atomic_xsub_relaxed(dst, val),\n+        _       => intrinsics::atomic_xsub(dst, val)\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn atomic_compare_and_swap<T>(dst:&mut T, old:T, new:T, order: Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_cxchg_acq(dst, old, new),\n+        Release => intrinsics::atomic_cxchg_rel(dst, old, new),\n+        AcqRel  => intrinsics::atomic_cxchg_acqrel(dst, old, new),\n+        Relaxed => intrinsics::atomic_cxchg_relaxed(dst, old, new),\n+        _       => intrinsics::atomic_cxchg(dst, old, new),\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn atomic_and<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_and_acq(dst, val),\n+        Release => intrinsics::atomic_and_rel(dst, val),\n+        AcqRel  => intrinsics::atomic_and_acqrel(dst, val),\n+        Relaxed => intrinsics::atomic_and_relaxed(dst, val),\n+        _       => intrinsics::atomic_and(dst, val)\n+    }\n+}\n+\n+#[inline]\n+pub unsafe fn atomic_nand<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_nand_acq(dst, val),\n+        Release => intrinsics::atomic_nand_rel(dst, val),\n+        AcqRel  => intrinsics::atomic_nand_acqrel(dst, val),\n+        Relaxed => intrinsics::atomic_nand_relaxed(dst, val),\n+        _       => intrinsics::atomic_nand(dst, val)\n+    }\n+}\n+\n+\n+#[inline]\n+pub unsafe fn atomic_or<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_or_acq(dst, val),\n+        Release => intrinsics::atomic_or_rel(dst, val),\n+        AcqRel  => intrinsics::atomic_or_acqrel(dst, val),\n+        Relaxed => intrinsics::atomic_or_relaxed(dst, val),\n+        _       => intrinsics::atomic_or(dst, val)\n+    }\n+}\n+\n+\n+#[inline]\n+pub unsafe fn atomic_xor<T>(dst: &mut T, val: T, order: Ordering) -> T {\n+    match order {\n+        Acquire => intrinsics::atomic_xor_acq(dst, val),\n+        Release => intrinsics::atomic_xor_rel(dst, val),\n+        AcqRel  => intrinsics::atomic_xor_acqrel(dst, val),\n+        Relaxed => intrinsics::atomic_xor_relaxed(dst, val),\n+        _       => intrinsics::atomic_xor(dst, val)\n+    }\n+}\n+\n+\n+/// An atomic fence.\n+///\n+/// A fence 'A' which has `Release` ordering semantics, synchronizes with a\n+/// fence 'B' with (at least) `Acquire` semantics, if and only if there exists\n+/// atomic operations X and Y, both operating on some atomic object 'M' such\n+/// that A is sequenced before X, Y is synchronized before B and Y observers\n+/// the change to M. This provides a happens-before dependence between A and B.\n+///\n+/// Atomic operations with `Release` or `Acquire` semantics can also synchronize\n+/// with a fence.\n+///\n+/// A fence with has `SeqCst` ordering, in addition to having both `Acquire` and\n+/// `Release` semantics, participates in the global program order of the other\n+/// `SeqCst` operations and/or fences.\n+///\n+/// Accepts `Acquire`, `Release`, `AcqRel` and `SeqCst` orderings.\n+///\n+/// # Failure\n+///\n+/// Fails if `order` is `Relaxed`\n+#[inline]\n+pub fn fence(order: Ordering) {\n+    unsafe {\n+        match order {\n+            Acquire => intrinsics::atomic_fence_acq(),\n+            Release => intrinsics::atomic_fence_rel(),\n+            AcqRel  => intrinsics::atomic_fence_acqrel(),\n+            SeqCst  => intrinsics::atomic_fence(),\n+            Relaxed => fail!(\"there is no such thing as a relaxed fence\")\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+    use option::*;\n+    use super::*;\n+\n+    #[test]\n+    fn bool_() {\n+        let mut a = AtomicBool::new(false);\n+        assert_eq!(a.compare_and_swap(false, true, SeqCst), false);\n+        assert_eq!(a.compare_and_swap(false, true, SeqCst), true);\n+\n+        a.store(false, SeqCst);\n+        assert_eq!(a.compare_and_swap(false, true, SeqCst), false);\n+    }\n+\n+    #[test]\n+    fn option_empty() {\n+        let mut option: AtomicOption<()> = AtomicOption::empty();\n+        assert!(option.is_empty(SeqCst));\n+    }\n+\n+    #[test]\n+    fn option_swap() {\n+        let mut p = AtomicOption::new(~1);\n+        let a = ~2;\n+\n+        let b = p.swap(a, SeqCst);\n+\n+        assert_eq!(b, Some(~1));\n+        assert_eq!(p.take(SeqCst), Some(~2));\n+    }\n+\n+    #[test]\n+    fn option_take() {\n+        let mut p = AtomicOption::new(~1);\n+\n+        assert_eq!(p.take(SeqCst), Some(~1));\n+        assert_eq!(p.take(SeqCst), None);\n+\n+        let p2 = ~2;\n+        p.swap(p2, SeqCst);\n+\n+        assert_eq!(p.take(SeqCst), Some(~2));\n+    }\n+\n+    #[test]\n+    fn option_fill() {\n+        let mut p = AtomicOption::new(~1);\n+        assert!(p.fill(~2, SeqCst).is_some()); // should fail; shouldn't leak!\n+        assert_eq!(p.take(SeqCst), Some(~1));\n+\n+        assert!(p.fill(~2, SeqCst).is_none()); // shouldn't fail\n+        assert_eq!(p.take(SeqCst), Some(~2));\n+    }\n+\n+    #[test]\n+    fn bool_and() {\n+        let mut a = AtomicBool::new(true);\n+        assert_eq!(a.fetch_and(false, SeqCst),true);\n+        assert_eq!(a.load(SeqCst),false);\n+    }\n+\n+    static mut S_BOOL : AtomicBool = INIT_ATOMIC_BOOL;\n+    static mut S_INT  : AtomicInt  = INIT_ATOMIC_INT;\n+    static mut S_UINT : AtomicUint = INIT_ATOMIC_UINT;\n+\n+    #[test]\n+    fn static_init() {\n+        unsafe {\n+            assert!(!S_BOOL.load(SeqCst));\n+            assert!(S_INT.load(SeqCst) == 0);\n+            assert!(S_UINT.load(SeqCst) == 0);\n+        }\n+    }\n+\n+    #[test]\n+    fn different_sizes() {\n+        unsafe {\n+            let mut slot = 0u16;\n+            assert_eq!(super::atomic_swap(&mut slot, 1, SeqCst), 0);\n+\n+            let mut slot = 0u8;\n+            assert_eq!(super::atomic_compare_and_swap(&mut slot, 1, 2, SeqCst), 0);\n+\n+            let mut slot = 0u32;\n+            assert_eq!(super::atomic_load(&mut slot, SeqCst), 0);\n+\n+            let mut slot = 0u64;\n+            super::atomic_store(&mut slot, 2, SeqCst);\n+        }\n+    }\n+}\n+"}, {"sha": "994d12b34e5aa845533c8ad3c62def38ce06e6d6", "filename": "src/libstd/sync/mod.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibstd%2Fsync%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Flibstd%2Fsync%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmod.rs?ref=069cede3057ca517ffec2042d7f97dbb93e71a54", "patch": "@@ -16,6 +16,10 @@\n //! other types of concurrent primitives.\n \n pub mod arc;\n+#[cfg(stage0)]\n+#[path = \"atomics_stage0.rs\"]\n+pub mod atomics;\n+#[cfg(not(stage0))]\n pub mod atomics;\n pub mod deque;\n pub mod mpmc_bounded_queue;"}, {"sha": "35d987480c0786be72ce1ae6884012c07ac58be4", "filename": "src/test/auxiliary/cci_intrinsic.rs", "status": "modified", "additions": 2, "deletions": 16, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Ftest%2Fauxiliary%2Fcci_intrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Ftest%2Fauxiliary%2Fcci_intrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Fcci_intrinsic.rs?ref=069cede3057ca517ffec2042d7f97dbb93e71a54", "patch": "@@ -10,26 +10,12 @@\n \n pub mod rusti {\n     extern \"rust-intrinsic\" {\n-        pub fn atomic_cxchg<T>(dst: &mut T, old: T, src: T) -> T;\n-        pub fn atomic_cxchg_acq<T>(dst: &mut T, old: T, src: T) -> T;\n-        pub fn atomic_cxchg_rel<T>(dst: &mut T, old: T, src: T) -> T;\n-\n-        pub fn atomic_xchg<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xchg_acq<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xchg_rel<T>(dst: &mut T, src: T) -> T;\n-\n-        pub fn atomic_xadd<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xadd_acq<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xadd_rel<T>(dst: &mut T, src: T) -> T;\n-\n-        pub fn atomic_xsub<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xsub_acq<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xsub_rel<T>(dst: &mut T, src: T) -> T;\n+        pub fn atomic_xchg<T>(dst: *mut T, src: T) -> T;\n     }\n }\n \n #[inline(always)]\n-pub fn atomic_xchg(dst: &mut int, src: int) -> int {\n+pub fn atomic_xchg(dst: *mut int, src: int) -> int {\n     unsafe {\n         rusti::atomic_xchg(dst, src)\n     }"}, {"sha": "b663cbfa50974e43088ced20806ca9027bf853d3", "filename": "src/test/run-pass/intrinsic-atomics.rs", "status": "modified", "additions": 32, "deletions": 32, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Ftest%2Frun-pass%2Fintrinsic-atomics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/069cede3057ca517ffec2042d7f97dbb93e71a54/src%2Ftest%2Frun-pass%2Fintrinsic-atomics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fintrinsic-atomics.rs?ref=069cede3057ca517ffec2042d7f97dbb93e71a54", "patch": "@@ -10,69 +10,69 @@\n \n mod rusti {\n     extern \"rust-intrinsic\" {\n-        pub fn atomic_cxchg<T>(dst: &mut T, old: T, src: T) -> T;\n-        pub fn atomic_cxchg_acq<T>(dst: &mut T, old: T, src: T) -> T;\n-        pub fn atomic_cxchg_rel<T>(dst: &mut T, old: T, src: T) -> T;\n+        pub fn atomic_cxchg<T>(dst: *mut T, old: T, src: T) -> T;\n+        pub fn atomic_cxchg_acq<T>(dst: *mut T, old: T, src: T) -> T;\n+        pub fn atomic_cxchg_rel<T>(dst: *mut T, old: T, src: T) -> T;\n \n-        pub fn atomic_load<T>(src: &T) -> T;\n-        pub fn atomic_load_acq<T>(src: &T) -> T;\n+        pub fn atomic_load<T>(src: *T) -> T;\n+        pub fn atomic_load_acq<T>(src: *T) -> T;\n \n-        pub fn atomic_store<T>(dst: &mut T, val: T);\n-        pub fn atomic_store_rel<T>(dst: &mut T, val: T);\n+        pub fn atomic_store<T>(dst: *mut T, val: T);\n+        pub fn atomic_store_rel<T>(dst: *mut T, val: T);\n \n-        pub fn atomic_xchg<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xchg_acq<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xchg_rel<T>(dst: &mut T, src: T) -> T;\n+        pub fn atomic_xchg<T>(dst: *mut T, src: T) -> T;\n+        pub fn atomic_xchg_acq<T>(dst: *mut T, src: T) -> T;\n+        pub fn atomic_xchg_rel<T>(dst: *mut T, src: T) -> T;\n \n-        pub fn atomic_xadd<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xadd_acq<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xadd_rel<T>(dst: &mut T, src: T) -> T;\n+        pub fn atomic_xadd<T>(dst: *mut T, src: T) -> T;\n+        pub fn atomic_xadd_acq<T>(dst: *mut T, src: T) -> T;\n+        pub fn atomic_xadd_rel<T>(dst: *mut T, src: T) -> T;\n \n-        pub fn atomic_xsub<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xsub_acq<T>(dst: &mut T, src: T) -> T;\n-        pub fn atomic_xsub_rel<T>(dst: &mut T, src: T) -> T;\n+        pub fn atomic_xsub<T>(dst: *mut T, src: T) -> T;\n+        pub fn atomic_xsub_acq<T>(dst: *mut T, src: T) -> T;\n+        pub fn atomic_xsub_rel<T>(dst: *mut T, src: T) -> T;\n     }\n }\n \n pub fn main() {\n     unsafe {\n         let mut x = ~1;\n \n-        assert_eq!(rusti::atomic_load(x), 1);\n+        assert_eq!(rusti::atomic_load(&*x), 1);\n         *x = 5;\n-        assert_eq!(rusti::atomic_load_acq(x), 5);\n+        assert_eq!(rusti::atomic_load_acq(&*x), 5);\n \n-        rusti::atomic_store(x,3);\n+        rusti::atomic_store(&mut *x,3);\n         assert_eq!(*x, 3);\n-        rusti::atomic_store_rel(x,1);\n+        rusti::atomic_store_rel(&mut *x,1);\n         assert_eq!(*x, 1);\n \n-        assert_eq!(rusti::atomic_cxchg(x, 1, 2), 1);\n+        assert_eq!(rusti::atomic_cxchg(&mut *x, 1, 2), 1);\n         assert_eq!(*x, 2);\n \n-        assert_eq!(rusti::atomic_cxchg_acq(x, 1, 3), 2);\n+        assert_eq!(rusti::atomic_cxchg_acq(&mut *x, 1, 3), 2);\n         assert_eq!(*x, 2);\n \n-        assert_eq!(rusti::atomic_cxchg_rel(x, 2, 1), 2);\n+        assert_eq!(rusti::atomic_cxchg_rel(&mut *x, 2, 1), 2);\n         assert_eq!(*x, 1);\n \n-        assert_eq!(rusti::atomic_xchg(x, 0), 1);\n+        assert_eq!(rusti::atomic_xchg(&mut *x, 0), 1);\n         assert_eq!(*x, 0);\n \n-        assert_eq!(rusti::atomic_xchg_acq(x, 1), 0);\n+        assert_eq!(rusti::atomic_xchg_acq(&mut *x, 1), 0);\n         assert_eq!(*x, 1);\n \n-        assert_eq!(rusti::atomic_xchg_rel(x, 0), 1);\n+        assert_eq!(rusti::atomic_xchg_rel(&mut *x, 0), 1);\n         assert_eq!(*x, 0);\n \n-        assert_eq!(rusti::atomic_xadd(x, 1), 0);\n-        assert_eq!(rusti::atomic_xadd_acq(x, 1), 1);\n-        assert_eq!(rusti::atomic_xadd_rel(x, 1), 2);\n+        assert_eq!(rusti::atomic_xadd(&mut *x, 1), 0);\n+        assert_eq!(rusti::atomic_xadd_acq(&mut *x, 1), 1);\n+        assert_eq!(rusti::atomic_xadd_rel(&mut *x, 1), 2);\n         assert_eq!(*x, 3);\n \n-        assert_eq!(rusti::atomic_xsub(x, 1), 3);\n-        assert_eq!(rusti::atomic_xsub_acq(x, 1), 2);\n-        assert_eq!(rusti::atomic_xsub_rel(x, 1), 1);\n+        assert_eq!(rusti::atomic_xsub(&mut *x, 1), 3);\n+        assert_eq!(rusti::atomic_xsub_acq(&mut *x, 1), 2);\n+        assert_eq!(rusti::atomic_xsub_rel(&mut *x, 1), 1);\n         assert_eq!(*x, 0);\n     }\n }"}]}