{"sha": "675073c26615896350034c1e07fa39b6b99cf58d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY3NTA3M2MyNjYxNTg5NjM1MDAzNGMxZTA3ZmEzOWI2Yjk5Y2Y1OGQ=", "commit": {"author": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2011-08-27T07:43:22Z"}, "committer": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2011-08-27T22:54:46Z"}, "message": "Convert parser to istrs. Issue #855", "tree": {"sha": "04b83c11d6bf5be4f522686c50ba0ece39ed67c3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/04b83c11d6bf5be4f522686c50ba0ece39ed67c3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/675073c26615896350034c1e07fa39b6b99cf58d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/675073c26615896350034c1e07fa39b6b99cf58d", "html_url": "https://github.com/rust-lang/rust/commit/675073c26615896350034c1e07fa39b6b99cf58d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/675073c26615896350034c1e07fa39b6b99cf58d/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "427d42228f89b52c761d91834754382637d79925", "url": "https://api.github.com/repos/rust-lang/rust/commits/427d42228f89b52c761d91834754382637d79925", "html_url": "https://github.com/rust-lang/rust/commit/427d42228f89b52c761d91834754382637d79925"}], "stats": {"total": 448, "additions": 231, "deletions": 217}, "files": [{"sha": "c607f216dcacf610d26db60b8d223c82bd35982e", "filename": "src/comp/driver/rustc.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fdriver%2Frustc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fdriver%2Frustc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fdriver%2Frustc.rs?ref=675073c26615896350034c1e07fa39b6b99cf58d", "patch": "@@ -95,7 +95,8 @@ fn input_is_stdin(filename: str) -> bool { filename == \"-\" }\n fn parse_input(sess: session::session, cfg: &ast::crate_cfg, input: str) ->\n    @ast::crate {\n     if !input_is_stdin(input) {\n-        parser::parse_crate_from_file(input, cfg, sess.get_parse_sess())\n+        parser::parse_crate_from_file(\n+            istr::from_estr(input), cfg, sess.get_parse_sess())\n     } else { parse_input_src(sess, cfg, input).crate }\n }\n \n@@ -107,8 +108,10 @@ fn parse_input_src(sess: session::session, cfg: &ast::crate_cfg, infile: str)\n         } else { io::stdin() }.read_whole_stream();\n     let src = str::unsafe_from_bytes(srcbytes);\n     let crate =\n-        parser::parse_crate_from_source_str(infile, src, cfg,\n-                                            sess.get_parse_sess());\n+        parser::parse_crate_from_source_str(\n+            istr::from_estr(infile),\n+            istr::from_estr(src), cfg,\n+            sess.get_parse_sess());\n     ret {crate: crate, src: src};\n }\n "}, {"sha": "28d8e18c0091ecf69dd826982d4c4f3cc320513b", "filename": "src/comp/middle/trans.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fmiddle%2Ftrans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fmiddle%2Ftrans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ftrans.rs?ref=675073c26615896350034c1e07fa39b6b99cf58d", "patch": "@@ -4649,7 +4649,7 @@ fn trans_fail_value(cx: &@block_ctxt, sp_opt: &option::t<span>,\n     alt sp_opt {\n       some(sp) {\n         let loc = bcx_ccx(cx).sess.lookup_pos(sp.lo);\n-        V_filename = C_cstr(bcx_ccx(cx), istr::from_estr(loc.filename));\n+        V_filename = C_cstr(bcx_ccx(cx), loc.filename);\n         V_line = loc.line as int;\n       }\n       none. { V_filename = C_cstr(bcx_ccx(cx), ~\"<runtime>\"); V_line = 0; }"}, {"sha": "2ef4e3b2caa35568fe86f57cf622213d5f05f91b", "filename": "src/comp/syntax/codemap.rs", "status": "modified", "additions": 13, "deletions": 7, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fcodemap.rs?ref=675073c26615896350034c1e07fa39b6b99cf58d", "patch": "@@ -8,7 +8,7 @@ import std::option;\n import std::option::some;\n import std::option::none;\n \n-type filename = str;\n+type filename = istr;\n \n type file_pos = {ch: uint, byte: uint};\n \n@@ -84,7 +84,9 @@ fn span_to_str(sp: &span, cm: &codemap) -> str {\n             #fmt[\"%s:%u:%u: %u:%u\",\n                  if some(lo.filename) == prev_file {\n                      \"-\"\n-                 } else { lo.filename }, lo.line, lo.col, hi.line, hi.col];\n+                 } else {\n+                     istr::to_estr(lo.filename)\n+                 }, lo.line, lo.col, hi.line, hi.col];\n         alt cur.expanded_from {\n           os_none. { break; }\n           os_some(new_sp) {\n@@ -146,14 +148,16 @@ fn maybe_highlight_lines(sp: &option::t<span>, cm: &codemap,\n         // Print the offending lines\n         for line: uint in display_lines {\n             io::stdout().write_str(\n-                istr::from_estr(#fmt[\"%s:%u \", fm.name, line + 1u]));\n+                istr::from_estr(#fmt[\"%s:%u \",\n+                                     istr::to_estr(fm.name), line + 1u]));\n             let s = get_line(fm, line as int, file);\n             if !str::ends_with(s, \"\\n\") { s += \"\\n\"; }\n             io::stdout().write_str(istr::from_estr(s));\n         }\n         if elided {\n             let last_line = display_lines[vec::len(display_lines) - 1u];\n-            let s = #fmt[\"%s:%u \", fm.name, last_line + 1u];\n+            let s = #fmt[\"%s:%u \",\n+                         istr::to_estr(fm.name), last_line + 1u];\n             let indent = str::char_len(s);\n             let out = ~\"\";\n             while indent > 0u { out += ~\" \"; indent -= 1u; }\n@@ -172,7 +176,7 @@ fn maybe_highlight_lines(sp: &option::t<span>, cm: &codemap,\n             while num > 0u { num /= 10u; digits += 1u; }\n \n             // indent past |name:## | and the 0-offset column location\n-            let left = str::char_len(fm.name) + digits + lo.col + 3u;\n+            let left = istr::char_len(fm.name) + digits + lo.col + 3u;\n             let s = \"\";\n             while left > 0u { str::push_char(s, ' '); left -= 1u; }\n \n@@ -209,7 +213,7 @@ fn span_to_lines(sp: span, cm: codemap::codemap) -> @file_lines {\n     for each i: uint in uint::range(lo.line - 1u, hi.line as uint) {\n         lines += [i];\n     }\n-    ret @{name: lo.filename, lines: lines};\n+    ret @{name: istr::to_estr(lo.filename), lines: lines};\n }\n \n fn get_line(fm: filemap, line: int, file: &str) -> str {\n@@ -230,7 +234,9 @@ fn get_line(fm: filemap, line: int, file: &str) -> str {\n }\n \n fn get_filemap(cm: codemap, filename: str) -> filemap {\n-    for fm: filemap in cm.files { if fm.name == filename { ret fm; } }\n+    for fm: filemap in cm.files {\n+        if fm.name == istr::from_estr(filename) { ret fm; }\n+    }\n     //XXjdm the following triggers a mismatched type bug\n     //      (or expected function, found _|_)\n     fail; // (\"asking for \" + filename + \" which we don't know about\");"}, {"sha": "15c5de6ab4c70cb900d4dcf1936b75b5a282d0c1", "filename": "src/comp/syntax/ext/base.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fext%2Fbase.rs?ref=675073c26615896350034c1e07fa39b6b99cf58d", "patch": "@@ -93,7 +93,8 @@ fn mk_ctxt(sess: &session) -> ext_ctxt {\n     // super-ugly and needs a better solution.\n     let crate_file_name_hack = sess.get_codemap().files[0].name;\n \n-    ret ext_ctxt(@sess, crate_file_name_hack, codemap::os_none);\n+    ret ext_ctxt(@sess, istr::to_estr(crate_file_name_hack),\n+                 codemap::os_none);\n }\n \n fn expr_to_str(cx: &ext_ctxt, expr: @ast::expr, error: str) -> str {"}, {"sha": "1a4b3c9c29f9ae41cf97c5b52a40b0313e18de36", "filename": "src/comp/syntax/parse/eval.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fparse%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fparse%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fparse%2Feval.rs?ref=675073c26615896350034c1e07fa39b6b99cf58d", "patch": "@@ -51,7 +51,7 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: &istr,\n         let file_path = id + ~\".rs\";\n         alt file_opt {\n           some(f) {\n-            file_path = istr::from_estr(f);\n+            file_path = f;\n           }\n           none. { }\n         }\n@@ -63,7 +63,7 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: &istr,\n         if cx.mode == mode_depend { cx.deps += [full_path]; ret; }\n         let p0 =\n             new_parser_from_file(cx.sess, cx.cfg,\n-                                 istr::to_estr(full_path), cx.chpos,\n+                                 full_path, cx.chpos,\n                                  cx.byte_pos, SOURCE_FILE);\n         let inner_attrs = parse_inner_attrs_and_next(p0);\n         let mod_attrs = attrs + inner_attrs.inner;\n@@ -82,7 +82,7 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: &istr,\n         let path = id;\n         alt dir_opt {\n           some(d) {\n-            path = istr::from_estr(d);\n+            path = d;\n           }\n           none. { }\n         }"}, {"sha": "d1cec447d9f6edf1f2731c12a135ee67b1d9e23f", "filename": "src/comp/syntax/parse/lexer.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fparse%2Flexer.rs?ref=675073c26615896350034c1e07fa39b6b99cf58d", "patch": "@@ -728,7 +728,7 @@ fn gather_comments_and_literals(cm: &codemap::codemap, path: &istr,\n     let itr = @interner::mk::<istr>(istr::hash, istr::eq);\n     let rdr = new_reader(cm, src,\n                          codemap::new_filemap(\n-                             istr::to_estr(path), 0u, 0u), itr);\n+                             path, 0u, 0u), itr);\n     let comments: [cmnt] = [];\n     let literals: [lit] = [];\n     let first_read: bool = true;"}, {"sha": "288f11ad797c973feab4cd417134f631f807622c", "filename": "src/comp/syntax/parse/parser.rs", "status": "modified", "additions": 200, "deletions": 199, "changes": 399, "blob_url": "https://github.com/rust-lang/rust/blob/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/675073c26615896350034c1e07fa39b6b99cf58d/src%2Fcomp%2Fsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fparse%2Fparser.rs?ref=675073c26615896350034c1e07fa39b6b99cf58d", "patch": "@@ -38,8 +38,8 @@ type parser =\n         fn bump();\n         fn swap(token::token, uint, uint);\n         fn look_ahead(uint) -> token::token;\n-        fn fatal(str) -> ! ;\n-        fn warn(str);\n+        fn fatal(&istr) -> ! ;\n+        fn warn(&istr);\n         fn restrict(restriction);\n         fn get_restriction() -> restriction;\n         fn get_file_type() -> file_type;\n@@ -50,7 +50,7 @@ type parser =\n         fn get_last_lo_pos() -> uint;\n         fn get_last_hi_pos() -> uint;\n         fn get_prec_table() -> @[op_spec];\n-        fn get_str(token::str_num) -> str;\n+        fn get_str(token::str_num) -> istr;\n         fn get_reader() -> lexer::reader;\n         fn get_filemap() -> codemap::filemap;\n         fn get_bad_expr_words() -> hashmap<istr, ()>;\n@@ -60,11 +60,12 @@ type parser =\n         fn get_sess() -> parse_sess;\n     };\n \n-fn new_parser_from_file(sess: parse_sess, cfg: ast::crate_cfg, path: str,\n+fn new_parser_from_file(sess: parse_sess, cfg: ast::crate_cfg, path: &istr,\n                         chpos: uint, byte_pos: uint, ftype: file_type) ->\n    parser {\n-    let src = io::read_whole_file_str(istr::from_estr(path));\n-    let filemap = codemap::new_filemap(path, chpos, byte_pos);\n+    let src = io::read_whole_file_str(path);\n+    let filemap = codemap::new_filemap(\n+        path, chpos, byte_pos);\n     sess.cm.files += [filemap];\n     let itr = @interner::mk(istr::hash, istr::eq);\n     let rdr = lexer::new_reader(sess.cm, src, filemap, itr);\n@@ -110,12 +111,14 @@ fn new_parser(sess: parse_sess, cfg: ast::crate_cfg, rdr: lexer::reader,\n             }\n             ret buffer[distance - 1u].tok;\n         }\n-        fn fatal(m: str) -> ! {\n-            codemap::emit_error(some(self.get_span()), m, sess.cm);\n+        fn fatal(m: &istr) -> ! {\n+            codemap::emit_error(some(self.get_span()),\n+                                istr::to_estr(m), sess.cm);\n             fail;\n         }\n-        fn warn(m: str) {\n-            codemap::emit_warning(some(self.get_span()), m, sess.cm);\n+        fn warn(m: &istr) {\n+            codemap::emit_warning(some(self.get_span()),\n+                                  istr::to_estr(m), sess.cm);\n         }\n         fn restrict(r: restriction) { restr = r; }\n         fn get_restriction() -> restriction { ret restr; }\n@@ -127,8 +130,8 @@ fn new_parser(sess: parse_sess, cfg: ast::crate_cfg, rdr: lexer::reader,\n         fn get_file_type() -> file_type { ret ftype; }\n         fn get_cfg() -> ast::crate_cfg { ret cfg; }\n         fn get_prec_table() -> @[op_spec] { ret precs; }\n-        fn get_str(i: token::str_num) -> str {\n-            ret istr::to_estr(interner::get(*rdr.get_interner(), i));\n+        fn get_str(i: token::str_num) -> istr {\n+            ret interner::get(*rdr.get_interner(), i);\n         }\n         fn get_reader() -> lexer::reader { ret rdr; }\n         fn get_filemap() -> codemap::filemap { ret rdr.get_filemap(); }\n@@ -190,19 +193,19 @@ fn bad_expr_word_table() -> hashmap<istr, ()> {\n }\n \n fn unexpected(p: &parser, t: token::token) -> ! {\n-    let s: str = \"unexpected token: \";\n-    s += istr::to_estr(token::to_str(p.get_reader(), t));\n+    let s: istr = ~\"unexpected token: \";\n+    s += token::to_str(p.get_reader(), t);\n     p.fatal(s);\n }\n \n fn expect(p: &parser, t: token::token) {\n     if p.peek() == t {\n         p.bump();\n     } else {\n-        let s: str = \"expecting \";\n-        s += istr::to_estr(token::to_str(p.get_reader(), t));\n-        s += \", found \";\n-        s += istr::to_estr(token::to_str(p.get_reader(), p.peek()));\n+        let s: istr = ~\"expecting \";\n+        s += token::to_str(p.get_reader(), t);\n+        s += ~\", found \";\n+        s += token::to_str(p.get_reader(), p.peek());\n         p.fatal(s);\n     }\n }\n@@ -215,10 +218,10 @@ fn expect_gt(p: &parser) {\n     } else if p.peek() == token::BINOP(token::ASR) {\n         p.swap(token::BINOP(token::LSR), p.get_lo_pos() + 1u, p.get_hi_pos());\n     } else {\n-        let s: str = \"expecting \";\n-        s += istr::to_estr(token::to_str(p.get_reader(), token::GT));\n-        s += \", found \";\n-        s += istr::to_estr(token::to_str(p.get_reader(), p.peek()));\n+        let s: istr = ~\"expecting \";\n+        s += token::to_str(p.get_reader(), token::GT);\n+        s += ~\", found \";\n+        s += token::to_str(p.get_reader(), p.peek());\n         p.fatal(s);\n     }\n }\n@@ -231,9 +234,9 @@ fn parse_ident(p: &parser) -> ast::ident {\n     alt p.peek() {\n       token::IDENT(i, _) {\n         p.bump();\n-        ret istr::from_estr(p.get_str(i));\n+        ret p.get_str(i);\n       }\n-      _ { p.fatal(\"expecting ident\"); }\n+      _ { p.fatal(~\"expecting ident\"); }\n     }\n }\n \n@@ -246,17 +249,17 @@ fn eat(p: &parser, tok: &token::token) -> bool {\n     ret if p.peek() == tok { p.bump(); true } else { false };\n }\n \n-fn is_word(p: &parser, word: &str) -> bool {\n+fn is_word(p: &parser, word: &istr) -> bool {\n     ret alt p.peek() {\n-          token::IDENT(sid, false) { str::eq(word, p.get_str(sid)) }\n+          token::IDENT(sid, false) { istr::eq(word, p.get_str(sid)) }\n           _ { false }\n         };\n }\n \n-fn eat_word(p: &parser, word: &str) -> bool {\n+fn eat_word(p: &parser, word: &istr) -> bool {\n     alt p.peek() {\n       token::IDENT(sid, false) {\n-        if str::eq(word, p.get_str(sid)) {\n+        if istr::eq(word, p.get_str(sid)) {\n             p.bump();\n             ret true;\n         } else { ret false; }\n@@ -265,19 +268,19 @@ fn eat_word(p: &parser, word: &str) -> bool {\n     }\n }\n \n-fn expect_word(p: &parser, word: &str) {\n+fn expect_word(p: &parser, word: &istr) {\n     if !eat_word(p, word) {\n-        p.fatal(\"expecting \" + word + \", found \" +\n-                istr::to_estr(token::to_str(p.get_reader(), p.peek())));\n+        p.fatal(~\"expecting \" + word + ~\", found \" +\n+                token::to_str(p.get_reader(), p.peek()));\n     }\n }\n \n fn check_bad_word(p: &parser) {\n     alt p.peek() {\n       token::IDENT(sid, false) {\n         let w = p.get_str(sid);\n-        if p.get_bad_expr_words().contains_key(istr::from_estr(w)) {\n-            p.fatal(\"found \" + w + \" in expression position\");\n+        if p.get_bad_expr_words().contains_key(w) {\n+            p.fatal(~\"found \" + w + ~\" in expression position\");\n         }\n       }\n       _ { }\n@@ -295,7 +298,7 @@ fn parse_ty_fn(proto: ast::proto, p: &parser) -> ast::ty_ {\n         let mode = ast::val;\n         if p.peek() == token::BINOP(token::AND) {\n             p.bump();\n-            mode = ast::alias(eat_word(p, \"mutable\"));\n+            mode = ast::alias(eat_word(p, ~\"mutable\"));\n         }\n         let t = parse_ty(p, false);\n         ret spanned(lo, t.span.hi, {mode: mode, ty: t});\n@@ -324,11 +327,11 @@ fn parse_ty_fn(proto: ast::proto, p: &parser) -> ast::ty_ {\n }\n \n fn parse_proto(p: &parser) -> ast::proto {\n-    if eat_word(p, \"iter\") {\n+    if eat_word(p, ~\"iter\") {\n         ret ast::proto_iter;\n-    } else if eat_word(p, \"fn\") {\n+    } else if eat_word(p, ~\"fn\") {\n         ret ast::proto_fn;\n-    } else if eat_word(p, \"block\") {\n+    } else if eat_word(p, ~\"block\") {\n         ret ast::proto_block;\n     } else { unexpected(p, p.peek()); }\n }\n@@ -378,8 +381,8 @@ fn parse_ty_field(p: &parser) -> ast::ty_field {\n fn ident_index(p: &parser, args: &[ast::arg], i: &ast::ident) -> uint {\n     let j = 0u;\n     for a: ast::arg in args { if a.ident == i { ret j; } j += 1u; }\n-    p.fatal(\"Unbound variable \" +\n-            istr::to_estr(i) + \" in constraint arg\");\n+    p.fatal(~\"Unbound variable \" +\n+            i + ~\" in constraint arg\");\n }\n \n fn parse_type_constr_arg(p: &parser) -> @ast::ty_constr_arg {\n@@ -468,7 +471,7 @@ fn parse_ty_postfix(orig_t: ast::ty_, p: &parser, colons_before_params: bool)\n                                            idents: pth.node.idents,\n                                            types: seq}), ann));\n       }\n-      _ { p.fatal(\"type parameter instantiation only allowed for paths\"); }\n+      _ { p.fatal(~\"type parameter instantiation only allowed for paths\"); }\n     }\n }\n \n@@ -485,43 +488,43 @@ fn parse_ty(p: &parser, colons_before_params: bool) -> @ast::ty {\n     let t: ast::ty_;\n     // FIXME: do something with this\n \n-    if eat_word(p, \"bool\") {\n+    if eat_word(p, ~\"bool\") {\n         t = ast::ty_bool;\n-    } else if eat_word(p, \"int\") {\n+    } else if eat_word(p, ~\"int\") {\n         t = ast::ty_int;\n-    } else if eat_word(p, \"uint\") {\n+    } else if eat_word(p, ~\"uint\") {\n         t = ast::ty_uint;\n-    } else if eat_word(p, \"float\") {\n+    } else if eat_word(p, ~\"float\") {\n         t = ast::ty_float;\n-    } else if eat_word(p, \"str\") {\n+    } else if eat_word(p, ~\"str\") {\n         t = ast::ty_str;\n-    } else if eat_word(p, \"istr\") {\n+    } else if eat_word(p, ~\"istr\") {\n         t = ast::ty_istr;\n-    } else if eat_word(p, \"char\") {\n+    } else if eat_word(p, ~\"char\") {\n         t = ast::ty_char;\n         /*\n             } else if (eat_word(p, \"task\")) {\n                 t = ast::ty_task;\n         */\n-    } else if eat_word(p, \"i8\") {\n+    } else if eat_word(p, ~\"i8\") {\n         t = ast::ty_machine(ast::ty_i8);\n-    } else if eat_word(p, \"i16\") {\n+    } else if eat_word(p, ~\"i16\") {\n         t = ast::ty_machine(ast::ty_i16);\n-    } else if eat_word(p, \"i32\") {\n+    } else if eat_word(p, ~\"i32\") {\n         t = ast::ty_machine(ast::ty_i32);\n-    } else if eat_word(p, \"i64\") {\n+    } else if eat_word(p, ~\"i64\") {\n         t = ast::ty_machine(ast::ty_i64);\n-    } else if eat_word(p, \"u8\") {\n+    } else if eat_word(p, ~\"u8\") {\n         t = ast::ty_machine(ast::ty_u8);\n-    } else if eat_word(p, \"u16\") {\n+    } else if eat_word(p, ~\"u16\") {\n         t = ast::ty_machine(ast::ty_u16);\n-    } else if eat_word(p, \"u32\") {\n+    } else if eat_word(p, ~\"u32\") {\n         t = ast::ty_machine(ast::ty_u32);\n-    } else if eat_word(p, \"u64\") {\n+    } else if eat_word(p, ~\"u64\") {\n         t = ast::ty_machine(ast::ty_u64);\n-    } else if eat_word(p, \"f32\") {\n+    } else if eat_word(p, ~\"f32\") {\n         t = ast::ty_machine(ast::ty_f32);\n-    } else if eat_word(p, \"f64\") {\n+    } else if eat_word(p, ~\"f64\") {\n         t = ast::ty_machine(ast::ty_f64);\n     } else if p.peek() == token::LPAREN {\n         p.bump();\n@@ -568,33 +571,33 @@ fn parse_ty(p: &parser, colons_before_params: bool) -> @ast::ty {\n         t = ast::ty_vec(parse_mt(p));\n         hi = p.get_hi_pos();\n         expect(p, token::RBRACKET);\n-    } else if eat_word(p, \"fn\") {\n+    } else if eat_word(p, ~\"fn\") {\n         t = parse_ty_fn(ast::proto_fn, p);\n         alt t { ast::ty_fn(_, _, out, _, _) { hi = out.span.hi; } }\n-    } else if eat_word(p, \"block\") {\n+    } else if eat_word(p, ~\"block\") {\n         t = parse_ty_fn(ast::proto_block, p);\n         alt t { ast::ty_fn(_, _, out, _, _) { hi = out.span.hi; } }\n-    } else if eat_word(p, \"iter\") {\n+    } else if eat_word(p, ~\"iter\") {\n         t = parse_ty_fn(ast::proto_iter, p);\n         alt t { ast::ty_fn(_, _, out, _, _) { hi = out.span.hi; } }\n-    } else if eat_word(p, \"obj\") {\n+    } else if eat_word(p, ~\"obj\") {\n         t = parse_ty_obj(p, hi);\n-    } else if eat_word(p, \"mutable\") {\n-        p.warn(\"ignoring deprecated 'mutable' type constructor\");\n+    } else if eat_word(p, ~\"mutable\") {\n+        p.warn(~\"ignoring deprecated 'mutable' type constructor\");\n         let typ = parse_ty(p, false);\n         t = typ.node;\n         hi = typ.span.hi;\n     } else if p.peek() == token::MOD_SEP || is_ident(p.peek()) {\n         let path = parse_path(p);\n         t = ast::ty_path(path, p.get_id());\n         hi = path.span.hi;\n-    } else { p.fatal(\"expecting type\"); }\n+    } else { p.fatal(~\"expecting type\"); }\n     ret parse_ty_postfix(t, p, colons_before_params);\n }\n \n fn parse_arg_mode(p: &parser) -> ast::mode {\n     if eat(p, token::BINOP(token::AND)) {\n-        ast::alias(eat_word(p, \"mutable\"))\n+        ast::alias(eat_word(p, ~\"mutable\"))\n     } else if eat(p, token::BINOP(token::MINUS)) {\n         ast::move\n     } else { ast::val }\n@@ -686,30 +689,30 @@ fn parse_seq<T>(bra: token::token, ket: token::token,\n fn parse_lit(p: &parser) -> ast::lit {\n     let sp = p.get_span();\n     let lit: ast::lit_ = ast::lit_nil;\n-    if eat_word(p, \"true\") {\n+    if eat_word(p, ~\"true\") {\n         lit = ast::lit_bool(true);\n-    } else if eat_word(p, \"false\") {\n+    } else if eat_word(p, ~\"false\") {\n         lit = ast::lit_bool(false);\n     } else {\n         alt p.peek() {\n           token::LIT_INT(i) { p.bump(); lit = ast::lit_int(i); }\n           token::LIT_UINT(u) { p.bump(); lit = ast::lit_uint(u); }\n           token::LIT_FLOAT(s) {\n             p.bump();\n-            lit = ast::lit_float(istr::from_estr(p.get_str(s)));\n+            lit = ast::lit_float(p.get_str(s));\n           }\n           token::LIT_MACH_INT(tm, i) {\n             p.bump();\n             lit = ast::lit_mach_int(tm, i);\n           }\n           token::LIT_MACH_FLOAT(tm, s) {\n             p.bump();\n-            lit = ast::lit_mach_float(tm, istr::from_estr(p.get_str(s)));\n+            lit = ast::lit_mach_float(tm, p.get_str(s));\n           }\n           token::LIT_CHAR(c) { p.bump(); lit = ast::lit_char(c); }\n           token::LIT_STR(s) {\n             p.bump();\n-            lit = ast::lit_str(istr::from_estr(p.get_str(s)), ast::sk_rc);\n+            lit = ast::lit_str(p.get_str(s), ast::sk_rc);\n           }\n           token::LPAREN. {\n             p.bump();\n@@ -746,7 +749,7 @@ fn parse_path(p: &parser) -> ast::path {\n         alt p.peek() {\n           token::IDENT(i, _) {\n             hi = p.get_hi_pos();\n-            ids += [istr::from_estr(p.get_str(i))];\n+            ids += [p.get_str(i)];\n             hi = p.get_hi_pos();\n             p.bump();\n             if p.peek() == token::MOD_SEP && p.look_ahead(1u) != token::LT {\n@@ -778,7 +781,7 @@ fn parse_path_and_ty_param_substs(p: &parser) -> ast::path {\n }\n \n fn parse_mutability(p: &parser) -> ast::mutability {\n-    if eat_word(p, \"mutable\") {\n+    if eat_word(p, ~\"mutable\") {\n         if p.peek() == token::QUES { p.bump(); ret ast::maybe_mut; }\n         ret ast::mut;\n     }\n@@ -826,12 +829,12 @@ fn parse_bottom_expr(p: &parser) -> @ast::expr {\n         } else { ret mk_expr(p, lo, hi, ast::expr_tup(es)); }\n     } else if p.peek() == token::LBRACE {\n         p.bump();\n-        if is_word(p, \"mutable\") ||\n+        if is_word(p, ~\"mutable\") ||\n                is_plain_ident(p) && p.look_ahead(1u) == token::COLON {\n             let fields = [parse_field(p, token::COLON)];\n             let base = none;\n             while p.peek() != token::RBRACE {\n-                if eat_word(p, \"with\") { base = some(parse_expr(p)); break; }\n+                if eat_word(p, ~\"with\") { base = some(parse_expr(p)); break; }\n                 expect(p, token::COMMA);\n                 fields += [parse_field(p, token::COLON)];\n             }\n@@ -844,27 +847,27 @@ fn parse_bottom_expr(p: &parser) -> @ast::expr {\n             let blk = parse_block_tail(p, lo, ast::checked);\n             ret mk_expr(p, blk.span.lo, blk.span.hi, ast::expr_block(blk));\n         }\n-    } else if eat_word(p, \"if\") {\n+    } else if eat_word(p, ~\"if\") {\n         ret parse_if_expr(p);\n-    } else if eat_word(p, \"for\") {\n+    } else if eat_word(p, ~\"for\") {\n         ret parse_for_expr(p);\n-    } else if eat_word(p, \"while\") {\n+    } else if eat_word(p, ~\"while\") {\n         ret parse_while_expr(p);\n-    } else if eat_word(p, \"do\") {\n+    } else if eat_word(p, ~\"do\") {\n         ret parse_do_while_expr(p);\n-    } else if eat_word(p, \"alt\") {\n+    } else if eat_word(p, ~\"alt\") {\n         ret parse_alt_expr(p);\n         /*\n             } else if (eat_word(p, \"spawn\")) {\n                 ret parse_spawn_expr(p);\n         */\n-    } else if eat_word(p, \"fn\") {\n+    } else if eat_word(p, ~\"fn\") {\n         ret parse_fn_expr(p, ast::proto_fn);\n-    } else if eat_word(p, \"block\") {\n+    } else if eat_word(p, ~\"block\") {\n         ret parse_fn_expr(p, ast::proto_block);\n-    } else if eat_word(p, \"lambda\") {\n+    } else if eat_word(p, ~\"lambda\") {\n         ret parse_fn_expr(p, ast::proto_closure);\n-    } else if eat_word(p, \"unchecked\") {\n+    } else if eat_word(p, ~\"unchecked\") {\n         expect(p, token::LBRACE);\n         let blk = parse_block_tail(p, lo, ast::unchecked);\n         ret mk_expr(p, blk.span.lo, blk.span.hi, ast::expr_block(blk));\n@@ -896,14 +899,14 @@ fn parse_bottom_expr(p: &parser) -> @ast::expr {\n             let sp = p.get_span();\n             p.bump();\n             let lit =\n-                @{node: ast::lit_str(istr::from_estr(p.get_str(s)),\n+                @{node: ast::lit_str(p.get_str(s),\n                                      ast::sk_unique),\n                   span: sp};\n             ex = ast::expr_lit(lit);\n           }\n           _ { ex = ast::expr_uniq(parse_expr(p)); }\n         }\n-    } else if eat_word(p, \"obj\") {\n+    } else if eat_word(p, ~\"obj\") {\n         // Anonymous object\n \n         // Only make people type () if they're actually adding new fields\n@@ -918,7 +921,7 @@ fn parse_bottom_expr(p: &parser) -> @ast::expr {\n         let inner_obj: option::t<@ast::expr> = none;\n         expect(p, token::LBRACE);\n         while p.peek() != token::RBRACE {\n-            if eat_word(p, \"with\") {\n+            if eat_word(p, ~\"with\") {\n                 inner_obj = some(parse_expr(p));\n             } else { meths += [parse_method(p)]; }\n         }\n@@ -932,7 +935,7 @@ fn parse_bottom_expr(p: &parser) -> @ast::expr {\n         // \"spanned\".\n         let ob = {fields: fields, methods: meths, inner_obj: inner_obj};\n         ex = ast::expr_anon_obj(ob);\n-    } else if eat_word(p, \"bind\") {\n+    } else if eat_word(p, ~\"bind\") {\n         let e = parse_expr_res(p, RESTRICT_NO_CALL_EXPRS);\n         fn parse_expr_opt(p: &parser) -> option::t<@ast::expr> {\n             alt p.peek() {\n@@ -949,53 +952,53 @@ fn parse_bottom_expr(p: &parser) -> @ast::expr {\n         let ex_ext = parse_syntax_ext(p);\n         hi = ex_ext.span.hi;\n         ex = ex_ext.node;\n-    } else if eat_word(p, \"fail\") {\n+    } else if eat_word(p, ~\"fail\") {\n         if can_begin_expr(p.peek()) {\n             let e = parse_expr(p);\n             hi = e.span.hi;\n             ex = ast::expr_fail(some(e));\n         } else { ex = ast::expr_fail(none); }\n-    } else if eat_word(p, \"log\") {\n+    } else if eat_word(p, ~\"log\") {\n         let e = parse_expr(p);\n         ex = ast::expr_log(1, e);\n         hi = e.span.hi;\n-    } else if eat_word(p, \"log_err\") {\n+    } else if eat_word(p, ~\"log_err\") {\n         let e = parse_expr(p);\n         ex = ast::expr_log(0, e);\n         hi = e.span.hi;\n-    } else if eat_word(p, \"assert\") {\n+    } else if eat_word(p, ~\"assert\") {\n         let e = parse_expr(p);\n         ex = ast::expr_assert(e);\n         hi = e.span.hi;\n-    } else if eat_word(p, \"check\") {\n+    } else if eat_word(p, ~\"check\") {\n         /* Should be a predicate (pure boolean function) applied to\n            arguments that are all either slot variables or literals.\n            but the typechecker enforces that. */\n \n         let e = parse_expr(p);\n         hi = e.span.hi;\n         ex = ast::expr_check(ast::checked, e);\n-    } else if eat_word(p, \"claim\") {\n+    } else if eat_word(p, ~\"claim\") {\n         /* Same rules as check, except that if check-claims\n          is enabled (a command-line flag), then the parser turns\n         claims into check */\n \n         let e = parse_expr(p);\n         hi = e.span.hi;\n         ex = ast::expr_check(ast::unchecked, e);\n-    } else if eat_word(p, \"ret\") {\n+    } else if eat_word(p, ~\"ret\") {\n         if can_begin_expr(p.peek()) {\n             let e = parse_expr(p);\n             hi = e.span.hi;\n             ex = ast::expr_ret(some(e));\n         } else { ex = ast::expr_ret(none); }\n-    } else if eat_word(p, \"break\") {\n+    } else if eat_word(p, ~\"break\") {\n         ex = ast::expr_break;\n         hi = p.get_hi_pos();\n-    } else if eat_word(p, \"cont\") {\n+    } else if eat_word(p, ~\"cont\") {\n         ex = ast::expr_cont;\n         hi = p.get_hi_pos();\n-    } else if eat_word(p, \"put\") {\n+    } else if eat_word(p, ~\"put\") {\n         alt p.peek() {\n           token::SEMI. { ex = ast::expr_put(none); }\n           _ {\n@@ -1004,19 +1007,19 @@ fn parse_bottom_expr(p: &parser) -> @ast::expr {\n             ex = ast::expr_put(some(e));\n           }\n         }\n-    } else if eat_word(p, \"be\") {\n+    } else if eat_word(p, ~\"be\") {\n         let e = parse_expr(p);\n \n         // FIXME: Is this the right place for this check?\n         if /*check*/ast_util::is_call_expr(e) {\n             hi = e.span.hi;\n             ex = ast::expr_be(e);\n-        } else { p.fatal(\"Non-call expression in tail call\"); }\n-    } else if eat_word(p, \"copy\") {\n+        } else { p.fatal(~\"Non-call expression in tail call\"); }\n+    } else if eat_word(p, ~\"copy\") {\n         let e = parse_expr(p);\n         ex = ast::expr_copy(e);\n         hi = e.span.hi;\n-    } else if eat_word(p, \"self\") {\n+    } else if eat_word(p, ~\"self\") {\n         expect(p, token::DOT);\n         // The rest is a call expression.\n         let f: @ast::expr = parse_self_method(p);\n@@ -1026,8 +1029,8 @@ fn parse_bottom_expr(p: &parser) -> @ast::expr {\n         hi = es.span.hi;\n         ex = ast::expr_call(f, es.node);\n     } else if p.peek() == token::MOD_SEP ||\n-                  is_ident(p.peek()) && !is_word(p, \"true\") &&\n-                      !is_word(p, \"false\") {\n+                  is_ident(p.peek()) && !is_word(p, ~\"true\") &&\n+                      !is_word(p, ~\"false\") {\n         check_bad_word(p);\n         let pth = parse_path_and_ty_param_substs(p);\n         hi = pth.span.hi;\n@@ -1049,7 +1052,7 @@ fn parse_syntax_ext(p: &parser) -> @ast::expr {\n fn parse_syntax_ext_naked(p: &parser, lo: uint) -> @ast::expr {\n     let pth = parse_path(p);\n     if vec::len(pth.node.idents) == 0u {\n-        p.fatal(\"expected a syntax expander name\");\n+        p.fatal(~\"expected a syntax expander name\");\n     }\n     //temporary for a backwards-compatible cycle:\n     let es =\n@@ -1109,7 +1112,7 @@ fn parse_dot_or_call_expr_with(p: &parser, e: @ast::expr) -> @ast::expr {\n                 p.bump();\n                 e = mk_expr(p, lo, hi,\n                             ast::expr_field(\n-                                e, istr::from_estr(p.get_str(i))));\n+                                e, p.get_str(i)));\n               }\n               t { unexpected(p, t); }\n             }\n@@ -1121,8 +1124,8 @@ fn parse_dot_or_call_expr_with(p: &parser, e: @ast::expr) -> @ast::expr {\n }\n \n fn parse_prefix_expr(p: &parser) -> @ast::expr {\n-    if eat_word(p, \"mutable\") {\n-        p.warn(\"ignoring deprecated 'mutable' prefix operator\");\n+    if eat_word(p, ~\"mutable\") {\n+        p.warn(~\"ignoring deprecated 'mutable' prefix operator\");\n     }\n     let lo = p.get_lo_pos();\n     let hi = p.get_hi_pos();\n@@ -1225,7 +1228,7 @@ fn parse_more_binops(p: &parser, lhs: @ast::expr, min_prec: int) ->\n             ret parse_more_binops(p, bin, min_prec);\n         }\n     }\n-    if as_prec > min_prec && eat_word(p, \"as\") {\n+    if as_prec > min_prec && eat_word(p, ~\"as\") {\n         let rhs = parse_ty(p, true);\n         let _as =\n             mk_expr(p, lhs.span.lo, rhs.span.hi, ast::expr_cast(lhs, rhs));\n@@ -1288,7 +1291,7 @@ fn parse_if_expr_1(p: &parser) ->\n     let thn = parse_block(p);\n     let els: option::t<@ast::expr> = none;\n     let hi = thn.span.hi;\n-    if eat_word(p, \"else\") {\n+    if eat_word(p, ~\"else\") {\n         let elexpr = parse_else_expr(p);\n         els = some(elexpr);\n         hi = elexpr.span.hi;\n@@ -1297,7 +1300,7 @@ fn parse_if_expr_1(p: &parser) ->\n }\n \n fn parse_if_expr(p: &parser) -> @ast::expr {\n-    if eat_word(p, \"check\") {\n+    if eat_word(p, ~\"check\") {\n         let q = parse_if_expr_1(p);\n         ret mk_expr(p, q.lo, q.hi, ast::expr_if_check(q.cond, q.then, q.els));\n     } else {\n@@ -1323,7 +1326,7 @@ fn parse_fn_block_expr(p: &parser) -> @ast::expr {\n }\n \n fn parse_else_expr(p: &parser) -> @ast::expr {\n-    if eat_word(p, \"if\") {\n+    if eat_word(p, ~\"if\") {\n         ret parse_if_expr(p);\n     } else {\n         let blk = parse_block(p);\n@@ -1333,9 +1336,9 @@ fn parse_else_expr(p: &parser) -> @ast::expr {\n \n fn parse_for_expr(p: &parser) -> @ast::expr {\n     let lo = p.get_last_lo_pos();\n-    let is_each = eat_word(p, \"each\");\n+    let is_each = eat_word(p, ~\"each\");\n     let decl = parse_local(p, false);\n-    expect_word(p, \"in\");\n+    expect_word(p, ~\"in\");\n     let seq = parse_expr(p);\n     let body = parse_block(p);\n     let hi = body.span.hi;\n@@ -1355,7 +1358,7 @@ fn parse_while_expr(p: &parser) -> @ast::expr {\n fn parse_do_while_expr(p: &parser) -> @ast::expr {\n     let lo = p.get_last_lo_pos();\n     let body = parse_block(p);\n-    expect_word(p, \"while\");\n+    expect_word(p, ~\"while\");\n     let cond = parse_expr(p);\n     let hi = cond.span.hi;\n     ret mk_expr(p, lo, hi, ast::expr_do_while(body, cond));\n@@ -1369,7 +1372,7 @@ fn parse_alt_expr(p: &parser) -> @ast::expr {\n     while p.peek() != token::RBRACE {\n         let pats = parse_pats(p);\n         let guard = none;\n-        if eat_word(p, \"when\") {\n+        if eat_word(p, ~\"when\") {\n             guard = some(parse_expr(p));\n         }\n         let blk = parse_block(p);\n@@ -1449,9 +1452,8 @@ fn parse_pat(p: &parser) -> @ast::pat {\n             if p.peek() == token::UNDERSCORE {\n                 p.bump();\n                 if p.peek() != token::RBRACE {\n-                    p.fatal(\"expecting }, found \" +\n-                            istr::to_estr(\n-                                token::to_str(p.get_reader(), p.peek())));\n+                    p.fatal(~\"expecting }, found \" +\n+                            token::to_str(p.get_reader(), p.peek()));\n                 }\n                 etc = true;\n                 break;\n@@ -1464,8 +1466,8 @@ fn parse_pat(p: &parser) -> @ast::pat {\n                 subpat = parse_pat(p);\n             } else {\n                 if p.get_bad_expr_words().contains_key(fieldname) {\n-                    p.fatal(\"found \" + istr::to_estr(fieldname)\n-                            + \" in binding position\");\n+                    p.fatal(~\"found \" + fieldname\n+                            + ~\" in binding position\");\n                 }\n                 subpat =\n                     @{id: p.get_id(),\n@@ -1499,7 +1501,7 @@ fn parse_pat(p: &parser) -> @ast::pat {\n         }\n       }\n       tok {\n-        if !is_ident(tok) || is_word(p, \"true\") || is_word(p, \"false\") {\n+        if !is_ident(tok) || is_word(p, ~\"true\") || is_word(p, ~\"false\") {\n             let lit = parse_lit(p);\n             hi = lit.span.hi;\n             pat = ast::pat_lit(@lit);\n@@ -1568,7 +1570,7 @@ fn parse_crate_stmt(p: &parser) -> @ast::stmt {\n \n fn parse_source_stmt(p: &parser) -> @ast::stmt {\n     let lo = p.get_lo_pos();\n-    if eat_word(p, \"let\") {\n+    if eat_word(p, ~\"let\") {\n         let decl = parse_let(p);\n         ret @spanned(lo, decl.span.hi, ast::stmt_decl(decl, p.get_id()));\n     } else {\n@@ -1588,7 +1590,7 @@ fn parse_source_stmt(p: &parser) -> @ast::stmt {\n         if vec::len(item_attrs) > 0u {\n             alt maybe_item {\n               some(_) {/* fallthrough */ }\n-              _ { ret p.fatal(\"expected item\"); }\n+              _ { ret p.fatal(~\"expected item\"); }\n             }\n         }\n \n@@ -1604,7 +1606,7 @@ fn parse_source_stmt(p: &parser) -> @ast::stmt {\n             let e = parse_expr(p);\n             ret @spanned(lo, e.span.hi, ast::stmt_expr(e, p.get_id()));\n           }\n-          _ { p.fatal(\"expected statement\"); }\n+          _ { p.fatal(~\"expected statement\"); }\n         }\n     }\n }\n@@ -1674,7 +1676,7 @@ fn stmt_ends_with_semi(stmt: &ast::stmt) -> bool {\n \n fn parse_block(p: &parser) -> ast::blk {\n     let lo = p.get_lo_pos();\n-    if eat_word(p, \"unchecked\") {\n+    if eat_word(p, ~\"unchecked\") {\n         be parse_block_tail(p, lo, ast::unchecked);\n     }\n     else {\n@@ -1704,10 +1706,9 @@ fn parse_block_tail(p: &parser, lo: uint, s: ast::check_mode) -> ast::blk {\n                   token::RBRACE. { expr = some(e); }\n                   t {\n                     if stmt_ends_with_semi(*stmt) {\n-                        p.fatal(\"expected ';' or '}' after \" +\n-                                    \"expression but found \" +\n-                                istr::to_estr(\n-                                    token::to_str(p.get_reader(), t)));\n+                        p.fatal(~\"expected ';' or '}' after \" +\n+                                    ~\"expression but found \" +\n+                                    token::to_str(p.get_reader(), t));\n                     }\n                     stmts += [stmt];\n                   }\n@@ -1924,9 +1925,8 @@ fn parse_mod_items(p: &parser, term: token::token,\n         alt parse_item(p, attrs) {\n           some(i) { items += [i]; }\n           _ {\n-            p.fatal(\"expected item but found \" +\n-                    istr::to_estr(\n-                        token::to_str(p.get_reader(), p.peek())));\n+            p.fatal(~\"expected item but found \" +\n+                        token::to_str(p.get_reader(), p.peek()));\n           }\n         }\n     }\n@@ -1977,7 +1977,7 @@ fn parse_item_native_fn(p: &parser, attrs: &[ast::attribute]) ->\n     let link_name = none;\n     if p.peek() == token::EQ {\n         p.bump();\n-        link_name = some(istr::from_estr(parse_str(p)));\n+        link_name = some(parse_str(p));\n     }\n     let hi = p.get_hi_pos();\n     expect(p, token::SEMI);\n@@ -1990,14 +1990,14 @@ fn parse_item_native_fn(p: &parser, attrs: &[ast::attribute]) ->\n \n fn parse_native_item(p: &parser, attrs: &[ast::attribute]) ->\n    @ast::native_item {\n-    if eat_word(p, \"type\") {\n+    if eat_word(p, ~\"type\") {\n         ret parse_item_native_type(p, attrs);\n-    } else if eat_word(p, \"fn\") {\n+    } else if eat_word(p, ~\"fn\") {\n         ret parse_item_native_fn(p, attrs);\n     } else { unexpected(p, p.peek()); }\n }\n \n-fn parse_native_mod_items(p: &parser, native_name: &str,\n+fn parse_native_mod_items(p: &parser, native_name: &istr,\n                           abi: ast::native_abi,\n                           first_item_attrs: &[ast::attribute]) ->\n    ast::native_mod {\n@@ -2013,7 +2013,7 @@ fn parse_native_mod_items(p: &parser, native_name: &str,\n         initial_attrs = [];\n         items += [parse_native_item(p, attrs)];\n     }\n-    ret {native_name: istr::from_estr(native_name),\n+    ret {native_name: native_name,\n          abi: abi,\n          view_items: view_items,\n          items: items};\n@@ -2022,26 +2022,26 @@ fn parse_native_mod_items(p: &parser, native_name: &str,\n fn parse_item_native_mod(p: &parser, attrs: &[ast::attribute]) -> @ast::item {\n     let lo = p.get_last_lo_pos();\n     let abi = ast::native_abi_cdecl;\n-    if !is_word(p, \"mod\") {\n+    if !is_word(p, ~\"mod\") {\n         let t = parse_str(p);\n-        if str::eq(t, \"cdecl\") {\n-        } else if str::eq(t, \"rust\") {\n+        if istr::eq(t, ~\"cdecl\") {\n+        } else if istr::eq(t, ~\"rust\") {\n             abi = ast::native_abi_rust;\n-        } else if str::eq(t, \"llvm\") {\n+        } else if istr::eq(t, ~\"llvm\") {\n             abi = ast::native_abi_llvm;\n-        } else if str::eq(t, \"rust-intrinsic\") {\n+        } else if istr::eq(t, ~\"rust-intrinsic\") {\n             abi = ast::native_abi_rust_intrinsic;\n-        } else if str::eq(t, \"x86stdcall\") {\n+        } else if istr::eq(t, ~\"x86stdcall\") {\n             abi = ast::native_abi_x86stdcall;\n-        } else { p.fatal(\"unsupported abi: \" + t); }\n+        } else { p.fatal(~\"unsupported abi: \" + t); }\n     }\n-    expect_word(p, \"mod\");\n+    expect_word(p, ~\"mod\");\n     let id = parse_ident(p);\n     let native_name;\n     if p.peek() == token::EQ {\n         expect(p, token::EQ);\n         native_name = parse_str(p);\n-    } else { native_name = istr::to_estr(id); }\n+    } else { native_name = id; }\n     expect(p, token::LBRACE);\n     let more_attrs = parse_inner_attrs_and_next(p);\n     let inner_attrs = more_attrs.inner;\n@@ -2077,8 +2077,8 @@ fn parse_item_tag(p: &parser, attrs: &[ast::attribute]) -> @ast::item {\n     // Newtype syntax\n     if p.peek() == token::EQ {\n         if p.get_bad_expr_words().contains_key(id) {\n-            p.fatal(\"found \" + istr::to_estr(id)\n-                    + \" in tag constructor position\");\n+            p.fatal(~\"found \" + id\n+                    + ~\" in tag constructor position\");\n         }\n         p.bump();\n         let ty = parse_ty(p, false);\n@@ -2115,15 +2115,14 @@ fn parse_item_tag(p: &parser, attrs: &[ast::attribute]) -> @ast::item {\n             }\n             expect(p, token::SEMI);\n             p.get_id();\n-            let vr = {name: istr::from_estr(p.get_str(name)),\n+            let vr = {name: p.get_str(name),\n                       args: args, id: p.get_id()};\n             variants += [spanned(vlo, vhi, vr)];\n           }\n           token::RBRACE. {/* empty */ }\n           _ {\n-            p.fatal(\"expected name of variant or '}' but found \" +\n-                    istr::to_estr(\n-                        token::to_str(p.get_reader(), tok)));\n+            p.fatal(~\"expected name of variant or '}' but found \" +\n+                        token::to_str(p.get_reader(), tok));\n           }\n         }\n     }\n@@ -2133,42 +2132,42 @@ fn parse_item_tag(p: &parser, attrs: &[ast::attribute]) -> @ast::item {\n }\n \n fn parse_auth(p: &parser) -> ast::_auth {\n-    if eat_word(p, \"unsafe\") {\n+    if eat_word(p, ~\"unsafe\") {\n         ret ast::auth_unsafe;\n     } else { unexpected(p, p.peek()); }\n }\n \n fn parse_item(p: &parser, attrs: &[ast::attribute]) -> option::t<@ast::item> {\n-    if eat_word(p, \"const\") {\n+    if eat_word(p, ~\"const\") {\n         ret some(parse_item_const(p, attrs));\n-    } else if eat_word(p, \"inline\") {\n-        expect_word(p, \"fn\");\n+    } else if eat_word(p, ~\"inline\") {\n+        expect_word(p, ~\"fn\");\n         ret some(parse_item_fn_or_iter(p, ast::impure_fn, ast::proto_fn,\n                                        attrs, ast::il_inline));\n-    } else if is_word(p, \"fn\") && p.look_ahead(1u) != token::LPAREN {\n+    } else if is_word(p, ~\"fn\") && p.look_ahead(1u) != token::LPAREN {\n         p.bump();\n         ret some(parse_item_fn_or_iter(p, ast::impure_fn, ast::proto_fn,\n                                        attrs, ast::il_normal));\n-    } else if eat_word(p, \"pure\") {\n-        expect_word(p, \"fn\");\n+    } else if eat_word(p, ~\"pure\") {\n+        expect_word(p, ~\"fn\");\n         ret some(parse_item_fn_or_iter(p, ast::pure_fn, ast::proto_fn, attrs,\n                                        ast::il_normal));\n-    } else if eat_word(p, \"iter\") {\n+    } else if eat_word(p, ~\"iter\") {\n         ret some(parse_item_fn_or_iter(p, ast::impure_fn, ast::proto_iter,\n                                        attrs, ast::il_normal));\n-    } else if eat_word(p, \"mod\") {\n+    } else if eat_word(p, ~\"mod\") {\n         ret some(parse_item_mod(p, attrs));\n-    } else if eat_word(p, \"native\") {\n+    } else if eat_word(p, ~\"native\") {\n         ret some(parse_item_native_mod(p, attrs));\n     }\n-    if eat_word(p, \"type\") {\n+    if eat_word(p, ~\"type\") {\n         ret some(parse_item_type(p, attrs));\n-    } else if eat_word(p, \"tag\") {\n+    } else if eat_word(p, ~\"tag\") {\n         ret some(parse_item_tag(p, attrs));\n-    } else if is_word(p, \"obj\") && p.look_ahead(1u) != token::LPAREN {\n+    } else if is_word(p, ~\"obj\") && p.look_ahead(1u) != token::LPAREN {\n         p.bump();\n         ret some(parse_item_obj(p, attrs));\n-    } else if eat_word(p, \"resource\") {\n+    } else if eat_word(p, ~\"resource\") {\n         ret some(parse_item_res(p, attrs));\n     } else { ret none; }\n }\n@@ -2288,13 +2287,13 @@ fn parse_rest_import_name(p: &parser, first: &ast::ident,\n         alt p.peek() {\n           token::SEMI. { break; }\n           token::MOD_SEP. {\n-            if glob { p.fatal(\"cannot path into a glob\"); }\n+            if glob { p.fatal(~\"cannot path into a glob\"); }\n             if option::is_some(from_idents) {\n-                p.fatal(\"cannot path into import list\");\n+                p.fatal(~\"cannot path into import list\");\n             }\n             p.bump();\n           }\n-          _ { p.fatal(\"expecting '::' or ';'\"); }\n+          _ { p.fatal(~\"expecting '::' or ';'\"); }\n         }\n         alt p.peek() {\n           token::IDENT(_, _) { identifiers += [parse_ident(p)]; }\n@@ -2318,22 +2317,22 @@ fn parse_rest_import_name(p: &parser, first: &ast::ident,\n                 parse_seq(token::LBRACE, token::RBRACE, some(token::COMMA),\n                           parse_import_ident, p).node;\n             if vec::is_empty(from_idents_) {\n-                p.fatal(\"at least one import is required\");\n+                p.fatal(~\"at least one import is required\");\n             }\n             from_idents = some(from_idents_);\n           }\n \n \n           _ {\n-            p.fatal(\"expecting an identifier, or '*'\");\n+            p.fatal(~\"expecting an identifier, or '*'\");\n           }\n         }\n     }\n     alt def_ident {\n       some(i) {\n-        if glob { p.fatal(\"globbed imports can't be renamed\"); }\n+        if glob { p.fatal(~\"globbed imports can't be renamed\"); }\n         if option::is_some(from_idents) {\n-            p.fatal(\"can't rename import list\");\n+            p.fatal(~\"can't rename import list\");\n         }\n         ret ast::view_item_import(i, identifiers, p.get_id());\n       }\n@@ -2359,9 +2358,9 @@ fn parse_full_import_name(p: &parser, def_ident: &ast::ident) ->\n       token::IDENT(i, _) {\n         p.bump();\n         ret parse_rest_import_name(\n-            p, istr::from_estr(p.get_str(i)), some(def_ident));\n+            p, p.get_str(i), some(def_ident));\n       }\n-      _ { p.fatal(\"expecting an identifier\"); }\n+      _ { p.fatal(~\"expecting an identifier\"); }\n     }\n }\n \n@@ -2372,15 +2371,15 @@ fn parse_import(p: &parser) -> ast::view_item_ {\n         alt p.peek() {\n           token::EQ. {\n             p.bump();\n-            ret parse_full_import_name(p, istr::from_estr(p.get_str(i)));\n+            ret parse_full_import_name(p, p.get_str(i));\n           }\n           _ {\n             ret parse_rest_import_name(\n-                p, istr::from_estr(p.get_str(i)), none);\n+                p, p.get_str(i), none);\n           }\n         }\n       }\n-      _ { p.fatal(\"expecting an identifier\"); }\n+      _ { p.fatal(~\"expecting an identifier\"); }\n     }\n }\n \n@@ -2394,11 +2393,11 @@ fn parse_export(p: &parser) -> ast::view_item_ {\n fn parse_view_item(p: &parser) -> @ast::view_item {\n     let lo = p.get_lo_pos();\n     let the_item =\n-        if eat_word(p, \"use\") {\n+        if eat_word(p, ~\"use\") {\n             parse_use(p)\n-        } else if eat_word(p, \"import\") {\n+        } else if eat_word(p, ~\"import\") {\n             parse_import(p)\n-        } else if eat_word(p, \"export\") { parse_export(p) } else { fail };\n+        } else if eat_word(p, ~\"export\") { parse_export(p) } else { fail };\n     let hi = p.get_lo_pos();\n     expect(p, token::SEMI);\n     ret @spanned(lo, hi, the_item);\n@@ -2408,8 +2407,8 @@ fn is_view_item(p: &parser) -> bool {\n     alt p.peek() {\n       token::IDENT(sid, false) {\n         let st = p.get_str(sid);\n-        ret str::eq(st, \"use\") || str::eq(st, \"import\") ||\n-                str::eq(st, \"export\");\n+        ret istr::eq(st, ~\"use\") || istr::eq(st, ~\"import\") ||\n+                istr::eq(st, ~\"export\");\n       }\n       _ { ret false; }\n     }\n@@ -2427,19 +2426,20 @@ fn parse_native_view(p: &parser) -> [@ast::view_item] {\n     ret items;\n }\n \n-fn parse_crate_from_source_file(input: &str, cfg: &ast::crate_cfg,\n+fn parse_crate_from_source_file(input: &istr, cfg: &ast::crate_cfg,\n                                 sess: &parse_sess) -> @ast::crate {\n     let p = new_parser_from_file(sess, cfg, input, 0u, 0u, SOURCE_FILE);\n     ret parse_crate_mod(p, cfg);\n }\n \n-fn parse_crate_from_source_str(name: &str, source: &str, cfg: &ast::crate_cfg,\n+fn parse_crate_from_source_str(name: &istr, source: &istr,\n+                               cfg: &ast::crate_cfg,\n                                sess: &parse_sess) -> @ast::crate {\n     let ftype = SOURCE_FILE;\n     let filemap = codemap::new_filemap(name, 0u, 0u);\n     sess.cm.files += [filemap];\n     let itr = @interner::mk(istr::hash, istr::eq);\n-    let rdr = lexer::new_reader(sess.cm, istr::from_estr(source),\n+    let rdr = lexer::new_reader(sess.cm, source,\n                                 filemap, itr);\n     let p = new_parser(sess, cfg, rdr, ftype);\n     ret parse_crate_mod(p, cfg);\n@@ -2458,7 +2458,7 @@ fn parse_crate_mod(p: &parser, _cfg: &ast::crate_cfg) -> @ast::crate {\n                   config: p.get_cfg()});\n }\n \n-fn parse_str(p: &parser) -> str {\n+fn parse_str(p: &parser) -> istr {\n     alt p.peek() {\n       token::LIT_STR(s) { p.bump(); ret p.get_str(s); }\n       _ { fail; }\n@@ -2479,8 +2479,8 @@ fn parse_crate_directive(p: &parser, first_outer_attr: &[ast::attribute]) ->\n     let expect_mod = vec::len(outer_attrs) > 0u;\n \n     let lo = p.get_lo_pos();\n-    if expect_mod || is_word(p, \"mod\") {\n-        expect_word(p, \"mod\");\n+    if expect_mod || is_word(p, ~\"mod\") {\n+        expect_word(p, ~\"mod\");\n         let id = parse_ident(p);\n         let file_opt =\n             alt p.peek() {\n@@ -2513,7 +2513,7 @@ fn parse_crate_directive(p: &parser, first_outer_attr: &[ast::attribute]) ->\n           }\n           t { unexpected(p, t); }\n         }\n-    } else if eat_word(p, \"auth\") {\n+    } else if eat_word(p, ~\"auth\") {\n         let n = parse_path(p);\n         expect(p, token::EQ);\n         let a = parse_auth(p);\n@@ -2523,7 +2523,7 @@ fn parse_crate_directive(p: &parser, first_outer_attr: &[ast::attribute]) ->\n     } else if is_view_item(p) {\n         let vi = parse_view_item(p);\n         ret spanned(lo, vi.span.hi, ast::cdir_view_item(vi));\n-    } else { ret p.fatal(\"expected crate directive\"); }\n+    } else { ret p.fatal(~\"expected crate directive\"); }\n }\n \n fn parse_crate_directives(p: &parser, term: token::token,\n@@ -2534,7 +2534,7 @@ fn parse_crate_directives(p: &parser, term: token::token,\n     // seeing the terminator next, so if we do see it then fail the same way\n     // parse_crate_directive would\n     if vec::len(first_outer_attr) > 0u && p.peek() == term {\n-        expect_word(p, \"mod\");\n+        expect_word(p, ~\"mod\");\n     }\n \n     let cdirs: [@ast::crate_directive] = [];\n@@ -2545,12 +2545,12 @@ fn parse_crate_directives(p: &parser, term: token::token,\n     ret cdirs;\n }\n \n-fn parse_crate_from_crate_file(input: &str, cfg: &ast::crate_cfg,\n+fn parse_crate_from_crate_file(input: &istr, cfg: &ast::crate_cfg,\n                                sess: &parse_sess) -> @ast::crate {\n     let p = new_parser_from_file(sess, cfg, input, 0u, 0u, CRATE_FILE);\n     let lo = p.get_lo_pos();\n     let prefix =\n-        std::fs::dirname(istr::from_estr(p.get_filemap().name));\n+        std::fs::dirname(p.get_filemap().name);\n     let leading_attrs = parse_inner_attrs_and_next(p);\n     let crate_attrs = leading_attrs.inner;\n     let first_cdir_attr = leading_attrs.next;\n@@ -2574,14 +2574,15 @@ fn parse_crate_from_crate_file(input: &str, cfg: &ast::crate_cfg,\n                   config: p.get_cfg()});\n }\n \n-fn parse_crate_from_file(input: &str, cfg: &ast::crate_cfg, sess: &parse_sess)\n-   -> @ast::crate {\n-    if str::ends_with(input, \".rc\") {\n+fn parse_crate_from_file(input: &istr, cfg: &ast::crate_cfg,\n+                         sess: &parse_sess) -> @ast::crate {\n+    if istr::ends_with(input, ~\".rc\") {\n         parse_crate_from_crate_file(input, cfg, sess)\n-    } else if str::ends_with(input, \".rs\") {\n+    } else if istr::ends_with(input, ~\".rs\") {\n         parse_crate_from_source_file(input, cfg, sess)\n     } else {\n-        codemap::emit_error(none, \"unknown input file type: \" + input,\n+        codemap::emit_error(none, \"unknown input file type: \"\n+                            + istr::to_estr(input),\n                             sess.cm);\n         fail\n     }"}, {"sha": "54a551f33c4d86f27f86800b2b1331f52b71babd", "filename": "src/fuzzer/fuzzer.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/675073c26615896350034c1e07fa39b6b99cf58d/src%2Ffuzzer%2Ffuzzer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/675073c26615896350034c1e07fa39b6b99cf58d/src%2Ffuzzer%2Ffuzzer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ffuzzer%2Ffuzzer.rs?ref=675073c26615896350034c1e07fa39b6b99cf58d", "patch": "@@ -252,7 +252,8 @@ fn parse_and_print(code: &str) -> str {\n     let filename = \"tmp.rs\";\n     let sess = @{cm: codemap::new_codemap(), mutable next_id: 0};\n     //write_file(filename, code);\n-    let crate = parser::parse_crate_from_source_str(filename, code, [], sess);\n+    let crate = parser::parse_crate_from_source_str(\n+        istr::from_estr(filename), istr::from_estr(code), [], sess);\n     ret as_str(bind pprust::print_crate(sess.cm, crate, filename,\n                                         io::string_reader(istr::from_estr(code)), _,\n                                         pprust::no_ann()));\n@@ -360,7 +361,9 @@ fn check_variants(files: &[str]) {\n             log_err \"check_variants: \" + file;\n             let sess = @{cm: codemap::new_codemap(), mutable next_id: 0};\n             let crate =\n-                parser::parse_crate_from_source_str(file, s, [], sess);\n+                parser::parse_crate_from_source_str(\n+                    istr::from_estr(file),\n+                    istr::from_estr(s), [], sess);\n             log_err as_str(bind pprust::print_crate(sess.cm, crate, file,\n                                                     io::string_reader(istr::from_estr(s)), _,\n                                                     pprust::no_ann()));"}]}