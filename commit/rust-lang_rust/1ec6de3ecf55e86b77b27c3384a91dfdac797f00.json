{"sha": "1ec6de3ecf55e86b77b27c3384a91dfdac797f00", "node_id": "MDY6Q29tbWl0NzI0NzEyOjFlYzZkZTNlY2Y1NWU4NmI3N2IyN2MzMzg0YTkxZGZkYWM3OTdmMDA=", "commit": {"author": {"name": "klutzy", "email": "klutzytheklutzy@gmail.com", "date": "2014-06-03T16:42:11Z"}, "committer": {"name": "klutzy", "email": "klutzytheklutzy@gmail.com", "date": "2014-06-03T17:00:03Z"}, "message": "syntax: Make quasiquoter use absolute paths\n\nAs part of removing `pub use` glob, two extra import globs were\ninjected to make `quote_expr!` work. However the globs caused\n`unused_import` warning in some places.\n\nQuasiquoter needed the globs since it generated idents (e.g. `TyU`)\nrather than absolute paths (`::syntax::ast::TyU`).\nThis patch removes the extra globs and makes quasiquoter use absolute\npaths.\n\nFixes #14618", "tree": {"sha": "2714a9b338d0e5e63aa62514c2083a831de375d4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2714a9b338d0e5e63aa62514c2083a831de375d4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1ec6de3ecf55e86b77b27c3384a91dfdac797f00", "comment_count": 5, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1ec6de3ecf55e86b77b27c3384a91dfdac797f00", "html_url": "https://github.com/rust-lang/rust/commit/1ec6de3ecf55e86b77b27c3384a91dfdac797f00", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1ec6de3ecf55e86b77b27c3384a91dfdac797f00/comments", "author": {"login": "klutzy", "id": 1589355, "node_id": "MDQ6VXNlcjE1ODkzNTU=", "avatar_url": "https://avatars.githubusercontent.com/u/1589355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/klutzy", "html_url": "https://github.com/klutzy", "followers_url": "https://api.github.com/users/klutzy/followers", "following_url": "https://api.github.com/users/klutzy/following{/other_user}", "gists_url": "https://api.github.com/users/klutzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/klutzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/klutzy/subscriptions", "organizations_url": "https://api.github.com/users/klutzy/orgs", "repos_url": "https://api.github.com/users/klutzy/repos", "events_url": "https://api.github.com/users/klutzy/events{/privacy}", "received_events_url": "https://api.github.com/users/klutzy/received_events", "type": "User", "site_admin": false}, "committer": {"login": "klutzy", "id": 1589355, "node_id": "MDQ6VXNlcjE1ODkzNTU=", "avatar_url": "https://avatars.githubusercontent.com/u/1589355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/klutzy", "html_url": "https://github.com/klutzy", "followers_url": "https://api.github.com/users/klutzy/followers", "following_url": "https://api.github.com/users/klutzy/following{/other_user}", "gists_url": "https://api.github.com/users/klutzy/gists{/gist_id}", "starred_url": "https://api.github.com/users/klutzy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/klutzy/subscriptions", "organizations_url": "https://api.github.com/users/klutzy/orgs", "repos_url": "https://api.github.com/users/klutzy/repos", "events_url": "https://api.github.com/users/klutzy/events{/privacy}", "received_events_url": "https://api.github.com/users/klutzy/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "918dbfea60e84868537a1951ad38a782502d39c2", "url": "https://api.github.com/repos/rust-lang/rust/commits/918dbfea60e84868537a1951ad38a782502d39c2", "html_url": "https://github.com/rust-lang/rust/commit/918dbfea60e84868537a1951ad38a782502d39c2"}], "stats": {"total": 124, "additions": 54, "deletions": 70}, "files": [{"sha": "71e3d06cf967c9e72c3a27085a4d7518eb30ccc0", "filename": "src/libregex_macros/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/1ec6de3ecf55e86b77b27c3384a91dfdac797f00/src%2Flibregex_macros%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1ec6de3ecf55e86b77b27c3384a91dfdac797f00/src%2Flibregex_macros%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex_macros%2Flib.rs?ref=1ec6de3ecf55e86b77b27c3384a91dfdac797f00", "patch": "@@ -20,7 +20,6 @@\n        html_root_url = \"http://doc.rust-lang.org/\")]\n \n #![feature(macro_registrar, managed_boxes, quote)]\n-#![allow(unused_imports)] // `quote_expr!` adds some `use` globs which may be unused\n \n extern crate regex;\n extern crate syntax;"}, {"sha": "d7bab3e2ffaa057784cb4969255acb59dae6fe86", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 54, "deletions": 69, "changes": 123, "blob_url": "https://github.com/rust-lang/rust/blob/1ec6de3ecf55e86b77b27c3384a91dfdac797f00/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1ec6de3ecf55e86b77b27c3384a91dfdac797f00/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=1ec6de3ecf55e86b77b27c3384a91dfdac797f00", "patch": "@@ -401,6 +401,16 @@ fn mk_ident(cx: &ExtCtxt, sp: Span, ident: ast::Ident) -> @ast::Expr {\n                         vec!(e_str))\n }\n \n+fn mk_ast_path(cx: &ExtCtxt, sp: Span, name: &str) -> @ast::Expr {\n+    let idents = vec!(id_ext(\"syntax\"), id_ext(\"ast\"), id_ext(name));\n+    cx.expr_path(cx.path_global(sp, idents))\n+}\n+\n+fn mk_token_path(cx: &ExtCtxt, sp: Span, name: &str) -> @ast::Expr {\n+    let idents = vec!(id_ext(\"syntax\"), id_ext(\"parse\"), id_ext(\"token\"), id_ext(name));\n+    cx.expr_path(cx.path_global(sp, idents))\n+}\n+\n fn mk_binop(cx: &ExtCtxt, sp: Span, bop: token::BinOp) -> @ast::Expr {\n     let name = match bop {\n         PLUS => \"PLUS\",\n@@ -414,116 +424,96 @@ fn mk_binop(cx: &ExtCtxt, sp: Span, bop: token::BinOp) -> @ast::Expr {\n         SHL => \"SHL\",\n         SHR => \"SHR\"\n     };\n-    cx.expr_ident(sp, id_ext(name))\n+    mk_token_path(cx, sp, name)\n }\n \n fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> @ast::Expr {\n \n     match *tok {\n         BINOP(binop) => {\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"BINOP\"),\n-                                      vec!(mk_binop(cx, sp, binop)));\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"BINOP\"), vec!(mk_binop(cx, sp, binop)));\n         }\n         BINOPEQ(binop) => {\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"BINOPEQ\"),\n-                                      vec!(mk_binop(cx, sp, binop)));\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"BINOPEQ\"),\n+                                vec!(mk_binop(cx, sp, binop)));\n         }\n \n         LIT_CHAR(i) => {\n             let e_char = cx.expr_lit(sp, ast::LitChar(i));\n \n-            return cx.expr_call_ident(sp, id_ext(\"LIT_CHAR\"), vec!(e_char));\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"LIT_CHAR\"), vec!(e_char));\n         }\n \n         LIT_INT(i, ity) => {\n             let s_ity = match ity {\n-                ast::TyI => \"TyI\".to_string(),\n-                ast::TyI8 => \"TyI8\".to_string(),\n-                ast::TyI16 => \"TyI16\".to_string(),\n-                ast::TyI32 => \"TyI32\".to_string(),\n-                ast::TyI64 => \"TyI64\".to_string()\n+                ast::TyI => \"TyI\",\n+                ast::TyI8 => \"TyI8\",\n+                ast::TyI16 => \"TyI16\",\n+                ast::TyI32 => \"TyI32\",\n+                ast::TyI64 => \"TyI64\"\n             };\n-            let e_ity = cx.expr_ident(sp, id_ext(s_ity.as_slice()));\n-\n+            let e_ity = mk_ast_path(cx, sp, s_ity);\n             let e_i64 = cx.expr_lit(sp, ast::LitInt(i, ast::TyI64));\n-\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"LIT_INT\"),\n-                                      vec!(e_i64, e_ity));\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"LIT_INT\"), vec!(e_i64, e_ity));\n         }\n \n         LIT_UINT(u, uty) => {\n             let s_uty = match uty {\n-                ast::TyU => \"TyU\".to_string(),\n-                ast::TyU8 => \"TyU8\".to_string(),\n-                ast::TyU16 => \"TyU16\".to_string(),\n-                ast::TyU32 => \"TyU32\".to_string(),\n-                ast::TyU64 => \"TyU64\".to_string()\n+                ast::TyU => \"TyU\",\n+                ast::TyU8 => \"TyU8\",\n+                ast::TyU16 => \"TyU16\",\n+                ast::TyU32 => \"TyU32\",\n+                ast::TyU64 => \"TyU64\"\n             };\n-            let e_uty = cx.expr_ident(sp, id_ext(s_uty.as_slice()));\n-\n+            let e_uty = mk_ast_path(cx, sp, s_uty);\n             let e_u64 = cx.expr_lit(sp, ast::LitUint(u, ast::TyU64));\n-\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"LIT_UINT\"),\n-                                      vec!(e_u64, e_uty));\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"LIT_UINT\"), vec!(e_u64, e_uty));\n         }\n \n         LIT_INT_UNSUFFIXED(i) => {\n             let e_i64 = cx.expr_lit(sp, ast::LitInt(i, ast::TyI64));\n-\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"LIT_INT_UNSUFFIXED\"),\n-                                      vec!(e_i64));\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"LIT_INT_UNSUFFIXED\"), vec!(e_i64));\n         }\n \n         LIT_FLOAT(fident, fty) => {\n             let s_fty = match fty {\n-                ast::TyF32 => \"TyF32\".to_string(),\n-                ast::TyF64 => \"TyF64\".to_string(),\n-                ast::TyF128 => \"TyF128\".to_string()\n+                ast::TyF32 => \"TyF32\",\n+                ast::TyF64 => \"TyF64\",\n+                ast::TyF128 => \"TyF128\"\n             };\n-            let e_fty = cx.expr_ident(sp, id_ext(s_fty.as_slice()));\n-\n+            let e_fty = mk_ast_path(cx, sp, s_fty);\n             let e_fident = mk_ident(cx, sp, fident);\n-\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"LIT_FLOAT\"),\n-                                      vec!(e_fident, e_fty));\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"LIT_FLOAT\"), vec!(e_fident, e_fty));\n         }\n \n         LIT_STR(ident) => {\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"LIT_STR\"),\n-                                      vec!(mk_ident(cx, sp, ident)));\n+            return cx.expr_call(sp,\n+                                mk_token_path(cx, sp, \"LIT_STR\"),\n+                                vec!(mk_ident(cx, sp, ident)));\n         }\n \n         LIT_STR_RAW(ident, n) => {\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"LIT_STR_RAW\"),\n-                                      vec!(mk_ident(cx, sp, ident),\n-                                        cx.expr_uint(sp, n)));\n+            return cx.expr_call(sp,\n+                                mk_token_path(cx, sp, \"LIT_STR_RAW\"),\n+                                vec!(mk_ident(cx, sp, ident), cx.expr_uint(sp, n)));\n         }\n \n         IDENT(ident, b) => {\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"IDENT\"),\n-                                      vec!(mk_ident(cx, sp, ident),\n-                                        cx.expr_bool(sp, b)));\n+            return cx.expr_call(sp,\n+                                mk_token_path(cx, sp, \"IDENT\"),\n+                                vec!(mk_ident(cx, sp, ident), cx.expr_bool(sp, b)));\n         }\n \n         LIFETIME(ident) => {\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"LIFETIME\"),\n-                                      vec!(mk_ident(cx, sp, ident)));\n+            return cx.expr_call(sp,\n+                                mk_token_path(cx, sp, \"LIFETIME\"),\n+                                vec!(mk_ident(cx, sp, ident)));\n         }\n \n         DOC_COMMENT(ident) => {\n-            return cx.expr_call_ident(sp,\n-                                      id_ext(\"DOC_COMMENT\"),\n-                                      vec!(mk_ident(cx, sp, ident)));\n+            return cx.expr_call(sp,\n+                                mk_token_path(cx, sp, \"DOC_COMMENT\"),\n+                                vec!(mk_ident(cx, sp, ident)));\n         }\n \n         INTERPOLATED(_) => fail!(\"quote! with interpolated token\"),\n@@ -565,19 +555,16 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> @ast::Expr {\n         EOF => \"EOF\",\n         _ => fail!()\n     };\n-    cx.expr_ident(sp, id_ext(name))\n+    mk_token_path(cx, sp, name)\n }\n \n-\n fn mk_tt(cx: &ExtCtxt, sp: Span, tt: &ast::TokenTree) -> Vec<@ast::Stmt> {\n-\n     match *tt {\n-\n         ast::TTTok(sp, ref tok) => {\n             let e_sp = cx.expr_ident(sp, id_ext(\"_sp\"));\n-            let e_tok = cx.expr_call_ident(sp,\n-                                           id_ext(\"TTTok\"),\n-                                           vec!(e_sp, mk_token(cx, sp, tok)));\n+            let e_tok = cx.expr_call(sp,\n+                                     mk_ast_path(cx, sp, \"TTTok\"),\n+                                     vec!(e_sp, mk_token(cx, sp, tok)));\n             let e_push =\n                 cx.expr_method_call(sp,\n                                     cx.expr_ident(sp, id_ext(\"tt\")),\n@@ -695,8 +682,6 @@ fn expand_wrapper(cx: &ExtCtxt,\n                   cx_expr: @ast::Expr,\n                   expr: @ast::Expr) -> @ast::Expr {\n     let uses = [\n-        &[\"syntax\", \"ast\"],\n-        &[\"syntax\", \"parse\", \"token\"],\n         &[\"syntax\", \"ext\", \"quote\", \"rt\"],\n     ].iter().map(|path| {\n         let path = path.iter().map(|s| s.to_string()).collect();"}]}