{"sha": "b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a", "node_id": "C_kwDOAAsO6NoAKGIxZDJlNWMwY2MxYTlkNTVjNWYwNDgxMTFlOTczNzhjMzIwYzVmNGE", "commit": {"author": {"name": "Yuki Okushi", "email": "jtitor@2k36.org", "date": "2022-06-21T11:08:12Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2022-06-21T11:08:12Z"}, "message": "Rollup merge of #98278 - nnethercote:some-token-stream-cleanups, r=petrochenkov\n\nSome token stream cleanups\n\nBest reviewed one commit at a time.\n\nr? ```@petrochenkov```", "tree": {"sha": "29a02857b9ea8755694d298b8ecb1a16e55c8041", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/29a02857b9ea8755694d298b8ecb1a16e55c8041"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJisaacCRBK7hj4Ov3rIwAAPloIABrlgjbPIO3gXQ4SlawdDIP3\nMLZbKJtVUyDSpYNpcQBqr/OFOgDvYUTiPTNJ2RAy6aLR/dEZ13xexk85f95JwbUK\nYyrgvGBz47cUb3fpl8lO+VTCW0MgInRjlZtl1M6qBYzGU1mAYjWmmUF1pStMB746\ntNxgD4qCuK9NTx8331kAy8IHlt19co1wg424eTy4IC3ePHEkkagpVYpOCzVW/VB3\nk1eQ+jmrLccC9YZwU5aB4DzCfd7AMRsW6yO7fmadiZLjTBPfEhp1MkilbarPPUKC\nuW44KY/OQxtky9bGWry3dtzYKvAVvLErcMaF+f3IZVD83puUPtjOwxZfTkrtC9I=\n=BPOH\n-----END PGP SIGNATURE-----\n", "payload": "tree 29a02857b9ea8755694d298b8ecb1a16e55c8041\nparent 75f17ed9099a510bb3833a387bb4ffbf7ab564b1\nparent 69f45b78608c1ddef9994b013461dcb7584d7072\nauthor Yuki Okushi <jtitor@2k36.org> 1655809692 +0900\ncommitter GitHub <noreply@github.com> 1655809692 +0900\n\nRollup merge of #98278 - nnethercote:some-token-stream-cleanups, r=petrochenkov\n\nSome token stream cleanups\n\nBest reviewed one commit at a time.\n\nr? ```@petrochenkov```\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a", "html_url": "https://github.com/rust-lang/rust/commit/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a/comments", "author": {"login": "JohnTitor", "id": 25030997, "node_id": "MDQ6VXNlcjI1MDMwOTk3", "avatar_url": "https://avatars.githubusercontent.com/u/25030997?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JohnTitor", "html_url": "https://github.com/JohnTitor", "followers_url": "https://api.github.com/users/JohnTitor/followers", "following_url": "https://api.github.com/users/JohnTitor/following{/other_user}", "gists_url": "https://api.github.com/users/JohnTitor/gists{/gist_id}", "starred_url": "https://api.github.com/users/JohnTitor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JohnTitor/subscriptions", "organizations_url": "https://api.github.com/users/JohnTitor/orgs", "repos_url": "https://api.github.com/users/JohnTitor/repos", "events_url": "https://api.github.com/users/JohnTitor/events{/privacy}", "received_events_url": "https://api.github.com/users/JohnTitor/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "75f17ed9099a510bb3833a387bb4ffbf7ab564b1", "url": "https://api.github.com/repos/rust-lang/rust/commits/75f17ed9099a510bb3833a387bb4ffbf7ab564b1", "html_url": "https://github.com/rust-lang/rust/commit/75f17ed9099a510bb3833a387bb4ffbf7ab564b1"}, {"sha": "69f45b78608c1ddef9994b013461dcb7584d7072", "url": "https://api.github.com/repos/rust-lang/rust/commits/69f45b78608c1ddef9994b013461dcb7584d7072", "html_url": "https://github.com/rust-lang/rust/commit/69f45b78608c1ddef9994b013461dcb7584d7072"}], "stats": {"total": 218, "additions": 118, "deletions": 100}, "files": [{"sha": "37de90d64c774409d4ecdb353fdfb1f7d5e052e3", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 57, "deletions": 95, "changes": 152, "blob_url": "https://github.com/rust-lang/rust/blob/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a", "patch": "@@ -25,7 +25,7 @@ use rustc_serialize::{Decodable, Decoder, Encodable, Encoder};\n use rustc_span::{Span, DUMMY_SP};\n use smallvec::{smallvec, SmallVec};\n \n-use std::{fmt, iter, mem};\n+use std::{fmt, iter};\n \n /// When the main Rust parser encounters a syntax-extension invocation, it\n /// parses the arguments to the invocation as a token tree. This is a very\n@@ -399,45 +399,6 @@ impl TokenStream {\n         self.0.len()\n     }\n \n-    pub fn from_streams(mut streams: SmallVec<[TokenStream; 2]>) -> TokenStream {\n-        match streams.len() {\n-            0 => TokenStream::default(),\n-            1 => streams.pop().unwrap(),\n-            _ => {\n-                // We are going to extend the first stream in `streams` with\n-                // the elements from the subsequent streams. This requires\n-                // using `make_mut()` on the first stream, and in practice this\n-                // doesn't cause cloning 99.9% of the time.\n-                //\n-                // One very common use case is when `streams` has two elements,\n-                // where the first stream has any number of elements within\n-                // (often 1, but sometimes many more) and the second stream has\n-                // a single element within.\n-\n-                // Determine how much the first stream will be extended.\n-                // Needed to avoid quadratic blow up from on-the-fly\n-                // reallocations (#57735).\n-                let num_appends = streams.iter().skip(1).map(|ts| ts.len()).sum();\n-\n-                // Get the first stream. If it's `None`, create an empty\n-                // stream.\n-                let mut iter = streams.drain(..);\n-                let mut first_stream_lrc = iter.next().unwrap().0;\n-\n-                // Append the elements to the first stream, after reserving\n-                // space for them.\n-                let first_vec_mut = Lrc::make_mut(&mut first_stream_lrc);\n-                first_vec_mut.reserve(num_appends);\n-                for stream in iter {\n-                    first_vec_mut.extend(stream.0.iter().cloned());\n-                }\n-\n-                // Create the final `TokenStream`.\n-                TokenStream(first_stream_lrc)\n-            }\n-        }\n-    }\n-\n     pub fn trees(&self) -> CursorRef<'_> {\n         CursorRef::new(self)\n     }\n@@ -562,50 +523,65 @@ impl TokenStreamBuilder {\n     }\n \n     pub fn push<T: Into<TokenStream>>(&mut self, stream: T) {\n-        let mut stream = stream.into();\n-\n-        // If `self` is not empty and the last tree within the last stream is a\n-        // token tree marked with `Joint`...\n-        if let Some(TokenStream(ref mut last_stream_lrc)) = self.0.last_mut()\n-            && let Some((TokenTree::Token(last_token), Spacing::Joint)) = last_stream_lrc.last()\n-            // ...and `stream` is not empty and the first tree within it is\n-            // a token tree...\n-            && let TokenStream(ref mut stream_lrc) = stream\n-            && let Some((TokenTree::Token(token), spacing)) = stream_lrc.first()\n-            // ...and the two tokens can be glued together...\n-            && let Some(glued_tok) = last_token.glue(&token)\n-        {\n-            // ...then do so, by overwriting the last token\n-            // tree in `self` and removing the first token tree\n-            // from `stream`. This requires using `make_mut()`\n-            // on the last stream in `self` and on `stream`,\n-            // and in practice this doesn't cause cloning 99.9%\n-            // of the time.\n-\n-            // Overwrite the last token tree with the merged\n-            // token.\n-            let last_vec_mut = Lrc::make_mut(last_stream_lrc);\n-            *last_vec_mut.last_mut().unwrap() = (TokenTree::Token(glued_tok), *spacing);\n-\n-            // Remove the first token tree from `stream`. (This\n-            // is almost always the only tree in `stream`.)\n-            let stream_vec_mut = Lrc::make_mut(stream_lrc);\n-            stream_vec_mut.remove(0);\n-\n-            // Don't push `stream` if it's empty -- that could\n-            // block subsequent token gluing, by getting\n-            // between two token trees that should be glued\n-            // together.\n-            if !stream.is_empty() {\n-                self.0.push(stream);\n-            }\n-            return;\n-        }\n-        self.0.push(stream);\n+        self.0.push(stream.into());\n     }\n \n     pub fn build(self) -> TokenStream {\n-        TokenStream::from_streams(self.0)\n+        let mut streams = self.0;\n+        match streams.len() {\n+            0 => TokenStream::default(),\n+            1 => streams.pop().unwrap(),\n+            _ => {\n+                // We will extend the first stream in `streams` with the\n+                // elements from the subsequent streams. This requires using\n+                // `make_mut()` on the first stream, and in practice this\n+                // doesn't cause cloning 99.9% of the time.\n+                //\n+                // One very common use case is when `streams` has two elements,\n+                // where the first stream has any number of elements within\n+                // (often 1, but sometimes many more) and the second stream has\n+                // a single element within.\n+\n+                // Determine how much the first stream will be extended.\n+                // Needed to avoid quadratic blow up from on-the-fly\n+                // reallocations (#57735).\n+                let num_appends = streams.iter().skip(1).map(|ts| ts.len()).sum();\n+\n+                // Get the first stream, which will become the result stream.\n+                // If it's `None`, create an empty stream.\n+                let mut iter = streams.drain(..);\n+                let mut res_stream_lrc = iter.next().unwrap().0;\n+\n+                // Append the subsequent elements to the result stream, after\n+                // reserving space for them.\n+                let res_vec_mut = Lrc::make_mut(&mut res_stream_lrc);\n+                res_vec_mut.reserve(num_appends);\n+                for stream in iter {\n+                    let stream_iter = stream.0.iter().cloned();\n+\n+                    // If (a) `res_mut_vec` is not empty and the last tree\n+                    // within it is a token tree marked with `Joint`, and (b)\n+                    // `stream` is not empty and the first tree within it is a\n+                    // token tree, and (c) the two tokens can be glued\n+                    // together...\n+                    if let Some((TokenTree::Token(last_tok), Spacing::Joint)) = res_vec_mut.last()\n+                        && let Some((TokenTree::Token(tok), spacing)) = stream.0.first()\n+                        && let Some(glued_tok) = last_tok.glue(&tok)\n+                    {\n+                        // ...then overwrite the last token tree in\n+                        // `res_vec_mut` with the glued token, and skip the\n+                        // first token tree from `stream`.\n+                        *res_vec_mut.last_mut().unwrap() = (TokenTree::Token(glued_tok), *spacing);\n+                        res_vec_mut.extend(stream_iter.skip(1));\n+                    } else {\n+                        // Append all of `stream`.\n+                        res_vec_mut.extend(stream_iter);\n+                    }\n+                }\n+\n+                TokenStream(res_stream_lrc)\n+            }\n+        }\n     }\n }\n \n@@ -679,20 +655,6 @@ impl Cursor {\n         })\n     }\n \n-    pub fn index(&self) -> usize {\n-        self.index\n-    }\n-\n-    pub fn append(&mut self, new_stream: TokenStream) {\n-        if new_stream.is_empty() {\n-            return;\n-        }\n-        let index = self.index;\n-        let stream = mem::take(&mut self.stream);\n-        *self = TokenStream::from_streams(smallvec![stream, new_stream]).into_trees();\n-        self.index = index;\n-    }\n-\n     pub fn look_ahead(&self, n: usize) -> Option<&TokenTree> {\n         self.stream.0[self.index..].get(n).map(|(tree, _)| tree)\n     }"}, {"sha": "1e4193a5a16cc6cc7f360cb09ef4a91277e2bbbd", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 57, "deletions": 3, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a", "patch": "@@ -329,6 +329,7 @@ impl Ident {\n         sess.symbol_gallery.insert(sym, span);\n         Ident { sym, is_raw, span }\n     }\n+\n     fn dollar_crate(span: Span) -> Ident {\n         // `$crate` is accepted as an ident only if it comes from the compiler.\n         Ident { sym: kw::DollarCrate, is_raw: false, span }\n@@ -403,6 +404,7 @@ impl server::TokenStream for Rustc<'_, '_> {\n     fn is_empty(&mut self, stream: &Self::TokenStream) -> bool {\n         stream.is_empty()\n     }\n+\n     fn from_str(&mut self, src: &str) -> Self::TokenStream {\n         parse_stream_from_source_str(\n             FileName::proc_macro_source_code(src),\n@@ -411,9 +413,11 @@ impl server::TokenStream for Rustc<'_, '_> {\n             Some(self.call_site),\n         )\n     }\n+\n     fn to_string(&mut self, stream: &Self::TokenStream) -> String {\n         pprust::tts_to_string(stream)\n     }\n+\n     fn expand_expr(&mut self, stream: &Self::TokenStream) -> Result<Self::TokenStream, ()> {\n         // Parse the expression from our tokenstream.\n         let expr: PResult<'_, _> = try {\n@@ -464,12 +468,14 @@ impl server::TokenStream for Rustc<'_, '_> {\n             _ => Err(()),\n         }\n     }\n+\n     fn from_token_tree(\n         &mut self,\n         tree: TokenTree<Self::Group, Self::Punct, Self::Ident, Self::Literal>,\n     ) -> Self::TokenStream {\n         tree.to_internal()\n     }\n+\n     fn concat_trees(\n         &mut self,\n         base: Option<Self::TokenStream>,\n@@ -484,6 +490,7 @@ impl server::TokenStream for Rustc<'_, '_> {\n         }\n         builder.build()\n     }\n+\n     fn concat_streams(\n         &mut self,\n         base: Option<Self::TokenStream>,\n@@ -498,6 +505,7 @@ impl server::TokenStream for Rustc<'_, '_> {\n         }\n         builder.build()\n     }\n+\n     fn into_trees(\n         &mut self,\n         stream: Self::TokenStream,\n@@ -522,10 +530,10 @@ impl server::TokenStream for Rustc<'_, '_> {\n                     // FIXME: It needs to be removed, but there are some\n                     // compatibility issues (see #73345).\n                     if group.flatten {\n-                        cursor.append(group.stream);\n-                        continue;\n+                        tts.append(&mut self.into_trees(group.stream));\n+                    } else {\n+                        tts.push(TokenTree::Group(group));\n                     }\n-                    tts.push(TokenTree::Group(group));\n                 }\n                 Some(tt) => tts.push(tt),\n                 None => return tts,\n@@ -543,21 +551,27 @@ impl server::Group for Rustc<'_, '_> {\n             flatten: false,\n         }\n     }\n+\n     fn delimiter(&mut self, group: &Self::Group) -> Delimiter {\n         group.delimiter\n     }\n+\n     fn stream(&mut self, group: &Self::Group) -> Self::TokenStream {\n         group.stream.clone()\n     }\n+\n     fn span(&mut self, group: &Self::Group) -> Self::Span {\n         group.span.entire()\n     }\n+\n     fn span_open(&mut self, group: &Self::Group) -> Self::Span {\n         group.span.open\n     }\n+\n     fn span_close(&mut self, group: &Self::Group) -> Self::Span {\n         group.span.close\n     }\n+\n     fn set_span(&mut self, group: &mut Self::Group, span: Self::Span) {\n         group.span = DelimSpan::from_single(span);\n     }\n@@ -567,15 +581,19 @@ impl server::Punct for Rustc<'_, '_> {\n     fn new(&mut self, ch: char, spacing: Spacing) -> Self::Punct {\n         Punct::new(ch, spacing == Spacing::Joint, server::Span::call_site(self))\n     }\n+\n     fn as_char(&mut self, punct: Self::Punct) -> char {\n         punct.ch\n     }\n+\n     fn spacing(&mut self, punct: Self::Punct) -> Spacing {\n         if punct.joint { Spacing::Joint } else { Spacing::Alone }\n     }\n+\n     fn span(&mut self, punct: Self::Punct) -> Self::Span {\n         punct.span\n     }\n+\n     fn with_span(&mut self, punct: Self::Punct, span: Self::Span) -> Self::Punct {\n         Punct { span, ..punct }\n     }\n@@ -585,9 +603,11 @@ impl server::Ident for Rustc<'_, '_> {\n     fn new(&mut self, string: &str, span: Self::Span, is_raw: bool) -> Self::Ident {\n         Ident::new(self.sess(), Symbol::intern(string), is_raw, span)\n     }\n+\n     fn span(&mut self, ident: Self::Ident) -> Self::Span {\n         ident.span\n     }\n+\n     fn with_span(&mut self, ident: Self::Ident, span: Self::Span) -> Self::Ident {\n         Ident { span, ..ident }\n     }\n@@ -639,45 +659,57 @@ impl server::Literal for Rustc<'_, '_> {\n \n         Ok(Literal { lit, span: self.call_site })\n     }\n+\n     fn to_string(&mut self, literal: &Self::Literal) -> String {\n         literal.lit.to_string()\n     }\n+\n     fn debug_kind(&mut self, literal: &Self::Literal) -> String {\n         format!(\"{:?}\", literal.lit.kind)\n     }\n+\n     fn symbol(&mut self, literal: &Self::Literal) -> String {\n         literal.lit.symbol.to_string()\n     }\n+\n     fn suffix(&mut self, literal: &Self::Literal) -> Option<String> {\n         literal.lit.suffix.as_ref().map(Symbol::to_string)\n     }\n+\n     fn integer(&mut self, n: &str) -> Self::Literal {\n         self.lit(token::Integer, Symbol::intern(n), None)\n     }\n+\n     fn typed_integer(&mut self, n: &str, kind: &str) -> Self::Literal {\n         self.lit(token::Integer, Symbol::intern(n), Some(Symbol::intern(kind)))\n     }\n+\n     fn float(&mut self, n: &str) -> Self::Literal {\n         self.lit(token::Float, Symbol::intern(n), None)\n     }\n+\n     fn f32(&mut self, n: &str) -> Self::Literal {\n         self.lit(token::Float, Symbol::intern(n), Some(sym::f32))\n     }\n+\n     fn f64(&mut self, n: &str) -> Self::Literal {\n         self.lit(token::Float, Symbol::intern(n), Some(sym::f64))\n     }\n+\n     fn string(&mut self, string: &str) -> Self::Literal {\n         let quoted = format!(\"{:?}\", string);\n         assert!(quoted.starts_with('\"') && quoted.ends_with('\"'));\n         let symbol = &quoted[1..quoted.len() - 1];\n         self.lit(token::Str, Symbol::intern(symbol), None)\n     }\n+\n     fn character(&mut self, ch: char) -> Self::Literal {\n         let quoted = format!(\"{:?}\", ch);\n         assert!(quoted.starts_with('\\'') && quoted.ends_with('\\''));\n         let symbol = &quoted[1..quoted.len() - 1];\n         self.lit(token::Char, Symbol::intern(symbol), None)\n     }\n+\n     fn byte_string(&mut self, bytes: &[u8]) -> Self::Literal {\n         let string = bytes\n             .iter()\n@@ -687,12 +719,15 @@ impl server::Literal for Rustc<'_, '_> {\n             .collect::<String>();\n         self.lit(token::ByteStr, Symbol::intern(&string), None)\n     }\n+\n     fn span(&mut self, literal: &Self::Literal) -> Self::Span {\n         literal.span\n     }\n+\n     fn set_span(&mut self, literal: &mut Self::Literal, span: Self::Span) {\n         literal.span = span;\n     }\n+\n     fn subspan(\n         &mut self,\n         literal: &Self::Literal,\n@@ -735,6 +770,7 @@ impl server::SourceFile for Rustc<'_, '_> {\n     fn eq(&mut self, file1: &Self::SourceFile, file2: &Self::SourceFile) -> bool {\n         Lrc::ptr_eq(file1, file2)\n     }\n+\n     fn path(&mut self, file: &Self::SourceFile) -> String {\n         match file.name {\n             FileName::Real(ref name) => name\n@@ -746,6 +782,7 @@ impl server::SourceFile for Rustc<'_, '_> {\n             _ => file.name.prefer_local().to_string(),\n         }\n     }\n+\n     fn is_real(&mut self, file: &Self::SourceFile) -> bool {\n         file.is_real_file()\n     }\n@@ -755,6 +792,7 @@ impl server::MultiSpan for Rustc<'_, '_> {\n     fn new(&mut self) -> Self::MultiSpan {\n         vec![]\n     }\n+\n     fn push(&mut self, spans: &mut Self::MultiSpan, span: Self::Span) {\n         spans.push(span)\n     }\n@@ -766,6 +804,7 @@ impl server::Diagnostic for Rustc<'_, '_> {\n         diag.set_span(MultiSpan::from_spans(spans));\n         diag\n     }\n+\n     fn sub(\n         &mut self,\n         diag: &mut Self::Diagnostic,\n@@ -775,6 +814,7 @@ impl server::Diagnostic for Rustc<'_, '_> {\n     ) {\n         diag.sub(level.to_internal(), msg, MultiSpan::from_spans(spans), None);\n     }\n+\n     fn emit(&mut self, mut diag: Self::Diagnostic) {\n         self.sess().span_diagnostic.emit_diagnostic(&mut diag);\n     }\n@@ -788,38 +828,49 @@ impl server::Span for Rustc<'_, '_> {\n             format!(\"{:?} bytes({}..{})\", span.ctxt(), span.lo().0, span.hi().0)\n         }\n     }\n+\n     fn def_site(&mut self) -> Self::Span {\n         self.def_site\n     }\n+\n     fn call_site(&mut self) -> Self::Span {\n         self.call_site\n     }\n+\n     fn mixed_site(&mut self) -> Self::Span {\n         self.mixed_site\n     }\n+\n     fn source_file(&mut self, span: Self::Span) -> Self::SourceFile {\n         self.sess().source_map().lookup_char_pos(span.lo()).file\n     }\n+\n     fn parent(&mut self, span: Self::Span) -> Option<Self::Span> {\n         span.parent_callsite()\n     }\n+\n     fn source(&mut self, span: Self::Span) -> Self::Span {\n         span.source_callsite()\n     }\n+\n     fn start(&mut self, span: Self::Span) -> LineColumn {\n         let loc = self.sess().source_map().lookup_char_pos(span.lo());\n         LineColumn { line: loc.line, column: loc.col.to_usize() }\n     }\n+\n     fn end(&mut self, span: Self::Span) -> LineColumn {\n         let loc = self.sess().source_map().lookup_char_pos(span.hi());\n         LineColumn { line: loc.line, column: loc.col.to_usize() }\n     }\n+\n     fn before(&mut self, span: Self::Span) -> Self::Span {\n         span.shrink_to_lo()\n     }\n+\n     fn after(&mut self, span: Self::Span) -> Self::Span {\n         span.shrink_to_hi()\n     }\n+\n     fn join(&mut self, first: Self::Span, second: Self::Span) -> Option<Self::Span> {\n         let self_loc = self.sess().source_map().lookup_char_pos(first.lo());\n         let other_loc = self.sess().source_map().lookup_char_pos(second.lo());\n@@ -830,9 +881,11 @@ impl server::Span for Rustc<'_, '_> {\n \n         Some(first.to(second))\n     }\n+\n     fn resolved_at(&mut self, span: Self::Span, at: Self::Span) -> Self::Span {\n         span.with_ctxt(at.ctxt())\n     }\n+\n     fn source_text(&mut self, span: Self::Span) -> Option<String> {\n         self.sess().source_map().span_to_snippet(span).ok()\n     }\n@@ -863,6 +916,7 @@ impl server::Span for Rustc<'_, '_> {\n     fn save_span(&mut self, span: Self::Span) -> usize {\n         self.sess().save_proc_macro_span(span)\n     }\n+\n     fn recover_proc_macro_span(&mut self, id: usize) -> Self::Span {\n         let (resolver, krate, def_site) = (&*self.ecx.resolver, self.krate, self.def_site);\n         *self.rebased_spans.entry(id).or_insert_with(|| {"}, {"sha": "e4a4db204d922e32099c9a0a87f901655935c373", "filename": "compiler/rustc_expand/src/tokenstream/tests.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs?ref=b1d2e5c0cc1a9d55c5f048111e97378c320c5f4a", "patch": "@@ -4,7 +4,6 @@ use rustc_ast::token;\n use rustc_ast::tokenstream::{Spacing, TokenStream, TokenStreamBuilder, TokenTree};\n use rustc_span::create_default_session_globals_then;\n use rustc_span::{BytePos, Span, Symbol};\n-use smallvec::smallvec;\n \n fn string_to_ts(string: &str) -> TokenStream {\n     string_to_stream(string.to_owned())\n@@ -24,7 +23,10 @@ fn test_concat() {\n         let test_res = string_to_ts(\"foo::bar::baz\");\n         let test_fst = string_to_ts(\"foo::bar\");\n         let test_snd = string_to_ts(\"::baz\");\n-        let eq_res = TokenStream::from_streams(smallvec![test_fst, test_snd]);\n+        let mut builder = TokenStreamBuilder::new();\n+        builder.push(test_fst);\n+        builder.push(test_snd);\n+        let eq_res = builder.build();\n         assert_eq!(test_res.trees().count(), 5);\n         assert_eq!(eq_res.trees().count(), 5);\n         assert_eq!(test_res.eq_unspanned(&eq_res), true);"}]}