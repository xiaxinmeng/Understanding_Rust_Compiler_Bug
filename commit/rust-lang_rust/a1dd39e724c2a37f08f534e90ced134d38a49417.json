{"sha": "a1dd39e724c2a37f08f534e90ced134d38a49417", "node_id": "MDY6Q29tbWl0NzI0NzEyOmExZGQzOWU3MjRjMmEzN2YwOGY1MzRlOTBjZWQxMzRkMzhhNDk0MTc=", "commit": {"author": {"name": "David Tolnay", "email": "dtolnay@gmail.com", "date": "2018-09-09T01:07:02Z"}, "committer": {"name": "David Tolnay", "email": "dtolnay@gmail.com", "date": "2018-09-09T02:01:48Z"}, "message": "Track distinct spans for open and close delimiter", "tree": {"sha": "63a5dcdd4f9249bac10b208ffd78e53441696d8b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/63a5dcdd4f9249bac10b208ffd78e53441696d8b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a1dd39e724c2a37f08f534e90ced134d38a49417", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1\n\niQIcBAABAgAGBQJblH8MAAoJEPm6FDuV/22CloEQAMFYjyC5HgDn+Smnnw+1kCdw\nOCxembuKFEdwTCMb10fiBESWf+lusKGR+gc4xz+0Qn6aUw7FbrHawlfTzlos77T1\n7TflbjYrnQVu7StMQZySAgZEJ+9HuRVkH0pDdDHS9UjcQZCerk1Ioach8eQCnaI2\n4Sd4C07/AjNCwNXfhPhzcYj7LcWfIf7BLsH0+mLqpEkvGO5IBlpy1HKdDByTnQL7\n91iwMXWsRZWd3mc73ujZ+FwhnMpP+M3JrVzmN8750RWYH71zNFAwSH70UioIlyjK\nGMi72FAakxOekgktFFxRn5Wx/eHnoDEqVXK495gB2JRVBF5H7+9NaE3O8h9qmB/K\nxiuYZB8pVoN4NM8BgmotYb/GWQfPjTGbAYzroDcLuC+EYz4VJUoTcgwKnNLnaa5W\nDyArsEW0cauYx2V1PrgQ0WQMYtfPTqFYFC+HGnQ9S0tR7+av5glGyfwV7Fb3KTIH\naJMuTvvytVldxFSw5LgaTOdwaQYrQi8fUYYLqcdx93P/UP0FJLN2NdyoCMCfpvfY\nP7d8tB1iRXt82UIU6pNrqYbGI+VQPlrBEJtC3pEVpatwhDpP0FLMf/NvMjrePntP\n5vPnoShFbOw63ZW/ah/MNhreLFV/Qj9cWXR7aNcO26yFoh/+C5TgZAc6+NgNAWaf\nU/M6S1atCdNAPhhreVxn\n=qHEN\n-----END PGP SIGNATURE-----", "payload": "tree 63a5dcdd4f9249bac10b208ffd78e53441696d8b\nparent c5a561c0abe432006063408dc3371891585319a6\nauthor David Tolnay <dtolnay@gmail.com> 1536455222 -0700\ncommitter David Tolnay <dtolnay@gmail.com> 1536458508 -0700\n\nTrack distinct spans for open and close delimiter\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a1dd39e724c2a37f08f534e90ced134d38a49417", "html_url": "https://github.com/rust-lang/rust/commit/a1dd39e724c2a37f08f534e90ced134d38a49417", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a1dd39e724c2a37f08f534e90ced134d38a49417/comments", "author": {"login": "dtolnay", "id": 1940490, "node_id": "MDQ6VXNlcjE5NDA0OTA=", "avatar_url": "https://avatars.githubusercontent.com/u/1940490?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dtolnay", "html_url": "https://github.com/dtolnay", "followers_url": "https://api.github.com/users/dtolnay/followers", "following_url": "https://api.github.com/users/dtolnay/following{/other_user}", "gists_url": "https://api.github.com/users/dtolnay/gists{/gist_id}", "starred_url": "https://api.github.com/users/dtolnay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dtolnay/subscriptions", "organizations_url": "https://api.github.com/users/dtolnay/orgs", "repos_url": "https://api.github.com/users/dtolnay/repos", "events_url": "https://api.github.com/users/dtolnay/events{/privacy}", "received_events_url": "https://api.github.com/users/dtolnay/received_events", "type": "User", "site_admin": false}, "committer": {"login": "dtolnay", "id": 1940490, "node_id": "MDQ6VXNlcjE5NDA0OTA=", "avatar_url": "https://avatars.githubusercontent.com/u/1940490?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dtolnay", "html_url": "https://github.com/dtolnay", "followers_url": "https://api.github.com/users/dtolnay/followers", "following_url": "https://api.github.com/users/dtolnay/following{/other_user}", "gists_url": "https://api.github.com/users/dtolnay/gists{/gist_id}", "starred_url": "https://api.github.com/users/dtolnay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dtolnay/subscriptions", "organizations_url": "https://api.github.com/users/dtolnay/orgs", "repos_url": "https://api.github.com/users/dtolnay/repos", "events_url": "https://api.github.com/users/dtolnay/events{/privacy}", "received_events_url": "https://api.github.com/users/dtolnay/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c5a561c0abe432006063408dc3371891585319a6", "url": "https://api.github.com/repos/rust-lang/rust/commits/c5a561c0abe432006063408dc3371891585319a6", "html_url": "https://github.com/rust-lang/rust/commit/c5a561c0abe432006063408dc3371891585319a6"}], "stats": {"total": 289, "additions": 163, "deletions": 126}, "files": [{"sha": "d4737052875b6f75840743be10d44e93c1943b3e", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 10, "deletions": 24, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -63,8 +63,8 @@ use std::str::FromStr;\n use syntax::errors::DiagnosticBuilder;\n use syntax::parse::{self, token};\n use syntax::symbol::Symbol;\n-use syntax::tokenstream;\n-use syntax_pos::{BytePos, Pos, FileName};\n+use syntax::tokenstream::{self, DelimSpan};\n+use syntax_pos::{Pos, FileName};\n \n /// The main type provided by this crate, representing an abstract stream of\n /// tokens, or, more specifically, a sequence of token trees.\n@@ -609,7 +609,7 @@ impl fmt::Display for TokenTree {\n pub struct Group {\n     delimiter: Delimiter,\n     stream: TokenStream,\n-    span: Span,\n+    span: DelimSpan,\n }\n \n #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n@@ -650,7 +650,7 @@ impl Group {\n         Group {\n             delimiter: delimiter,\n             stream: stream,\n-            span: Span::call_site(),\n+            span: DelimSpan::from_single(Span::call_site().0),\n         }\n     }\n \n@@ -678,43 +678,29 @@ impl Group {\n     /// ```\n     #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n     pub fn span(&self) -> Span {\n-        self.span\n+        Span(self.span.entire())\n     }\n \n-    /// Returns the span pointing to the opening delimiter of this group, or the\n-    /// span of the entire group if this is a None-delimited group.\n+    /// Returns the span pointing to the opening delimiter of this group.\n     ///\n     /// ```text\n     /// pub fn span_open(&self) -> Span {\n     ///                 ^\n     /// ```\n     #[unstable(feature = \"proc_macro_span\", issue = \"38356\")]\n     pub fn span_open(&self) -> Span {\n-        if self.delimiter == Delimiter::None {\n-            self.span\n-        } else {\n-            let lo = self.span.0.lo();\n-            let new_hi = BytePos::from_usize(lo.to_usize() + 1);\n-            Span(self.span.0.with_hi(new_hi))\n-        }\n+        Span(self.span.open)\n     }\n \n-    /// Returns the span pointing to the closing delimiter of this group, or the\n-    /// span of the entire group if this is a None-delimited group.\n+    /// Returns the span pointing to the closing delimiter of this group.\n     ///\n     /// ```text\n     /// pub fn span_close(&self) -> Span {\n     ///                        ^\n     /// ```\n     #[unstable(feature = \"proc_macro_span\", issue = \"38356\")]\n     pub fn span_close(&self) -> Span {\n-        let hi = self.span.0.hi();\n-        if self.delimiter == Delimiter::None || hi.to_usize() == 0 {\n-            self.span\n-        } else {\n-            let new_lo = BytePos::from_usize(hi.to_usize() - 1);\n-            Span(self.span.0.with_lo(new_lo))\n-        }\n+        Span(self.span.close)\n     }\n \n     /// Configures the span for this `Group`'s delimiters, but not its internal\n@@ -725,7 +711,7 @@ impl Group {\n     /// tokens at the level of the `Group`.\n     #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n     pub fn set_span(&mut self, span: Span) {\n-        self.span = span;\n+        self.span = DelimSpan::from_single(span.0);\n     }\n }\n "}, {"sha": "3ce02d1afb10bf60089a65413463d4ac69930304", "filename": "src/libproc_macro/rustc.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibproc_macro%2Frustc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibproc_macro%2Frustc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Frustc.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -64,7 +64,7 @@ impl TokenTree {\n             tokenstream::TokenTree::Delimited(span, delimed) => {\n                 let delimiter = Delimiter::from_internal(delimed.delim);\n                 let mut g = Group::new(delimiter, ::TokenStream(delimed.tts.into()));\n-                g.set_span(Span(span));\n+                g.span = span;\n                 return g.into();\n             }\n         };\n@@ -192,7 +192,7 @@ impl TokenTree {\n             self::TokenTree::Punct(tt) => (tt.as_char(), tt.spacing(), tt.span()),\n             self::TokenTree::Group(tt) => {\n                 return TokenTree::Delimited(\n-                    tt.span.0,\n+                    tt.span,\n                     Delimited {\n                         delim: tt.delimiter.to_internal(),\n                         tts: tt.stream.0.into(),"}, {"sha": "ed4a1e3d72f441eadae187912087882bb1a2a5ed", "filename": "src/librustc/ich/hcx.rs", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibrustc%2Fich%2Fhcx.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibrustc%2Fich%2Fhcx.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fhcx.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -28,6 +28,7 @@ use syntax::ast;\n use syntax::source_map::SourceMap;\n use syntax::ext::hygiene::SyntaxContext;\n use syntax::symbol::Symbol;\n+use syntax::tokenstream::DelimSpan;\n use syntax_pos::{Span, DUMMY_SP};\n use syntax_pos::hygiene;\n \n@@ -396,6 +397,17 @@ impl<'a> HashStable<StableHashingContext<'a>> for Span {\n     }\n }\n \n+impl<'a> HashStable<StableHashingContext<'a>> for DelimSpan {\n+    fn hash_stable<W: StableHasherResult>(\n+        &self,\n+        hcx: &mut StableHashingContext<'a>,\n+        hasher: &mut StableHasher<W>,\n+    ) {\n+        self.open.hash_stable(hcx, hasher);\n+        self.close.hash_stable(hcx, hasher);\n+    }\n+}\n+\n pub fn hash_stable_trait_impls<'a, 'gcx, W, R>(\n     hcx: &mut StableHashingContext<'a>,\n     hasher: &mut StableHasher<W>,"}, {"sha": "032ec8de2b791ed46161c846b93fa6e8c712042a", "filename": "src/librustc_resolve/macros.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibrustc_resolve%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibrustc_resolve%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_resolve%2Fmacros.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -35,7 +35,7 @@ use syntax::parse::parser::PathStyle;\n use syntax::parse::token::{self, Token};\n use syntax::ptr::P;\n use syntax::symbol::{Symbol, keywords};\n-use syntax::tokenstream::{TokenStream, TokenTree, Delimited};\n+use syntax::tokenstream::{TokenStream, TokenTree, Delimited, DelimSpan};\n use syntax::util::lev_distance::find_best_match_for_name;\n use syntax_pos::{Span, DUMMY_SP};\n use errors::Applicability;\n@@ -279,7 +279,8 @@ impl<'a, 'crateloader: 'a> base::Resolver for Resolver<'a, 'crateloader> {\n                                 tokens.push(TokenTree::Token(path.span, tok).into());\n                             }\n                         }\n-                        attrs[i].tokens = TokenTree::Delimited(attrs[i].span, Delimited {\n+                        let delim_span = DelimSpan::from_single(attrs[i].span);\n+                        attrs[i].tokens = TokenTree::Delimited(delim_span, Delimited {\n                             delim: token::Paren,\n                             tts: TokenStream::concat(tokens).into(),\n                         }).into();"}, {"sha": "a980f3ab51584d78f35ada6e74061b0ff850dc01", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -34,7 +34,7 @@ use parse::token::{self, Token};\n use ptr::P;\n use symbol::Symbol;\n use ThinVec;\n-use tokenstream::{TokenStream, TokenTree, Delimited};\n+use tokenstream::{TokenStream, TokenTree, Delimited, DelimSpan};\n use GLOBALS;\n \n use std::iter;\n@@ -535,7 +535,7 @@ impl MetaItemKind {\n                     }\n                     tokens.push(item.node.tokens());\n                 }\n-                TokenTree::Delimited(span, Delimited {\n+                TokenTree::Delimited(DelimSpan::from_single(span), Delimited {\n                     delim: token::Paren,\n                     tts: TokenStream::concat(tokens).into(),\n                 }).into()"}, {"sha": "62bc9fae3b59af13855894295903953da83f643c", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 13, "deletions": 9, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -10,14 +10,14 @@\n \n use ast::{self, Arg, Arm, Block, Expr, Item, Pat, Stmt, Ty};\n use source_map::respan;\n-use syntax_pos::Span;\n+use syntax_pos::{Span, DUMMY_SP};\n use ext::base::ExtCtxt;\n use ext::base;\n use ext::build::AstBuilder;\n use parse::parser::{Parser, PathStyle};\n use parse::token;\n use ptr::P;\n-use tokenstream::{TokenStream, TokenTree};\n+use tokenstream::{DelimSpan, TokenStream, TokenTree};\n \n /// Quasiquoting works via token trees.\n ///\n@@ -36,7 +36,7 @@ pub mod rt {\n     use symbol::Symbol;\n     use ThinVec;\n \n-    use tokenstream::{self, TokenTree, TokenStream};\n+    use tokenstream::{self, DelimSpan, TokenTree, TokenStream};\n \n     pub use parse::new_parser_from_tts;\n     pub use syntax_pos::{BytePos, Span, DUMMY_SP, FileName};\n@@ -245,7 +245,8 @@ pub mod rt {\n             }\n             inner.push(self.tokens.clone());\n \n-            r.push(TokenTree::Delimited(self.span, tokenstream::Delimited {\n+            let delim_span = DelimSpan::from_single(self.span);\n+            r.push(TokenTree::Delimited(delim_span, tokenstream::Delimited {\n                 delim: token::Bracket, tts: TokenStream::concat(inner).into()\n             }));\n             r\n@@ -261,7 +262,7 @@ pub mod rt {\n \n     impl ToTokens for () {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Delimited(DUMMY_SP, tokenstream::Delimited {\n+            vec![TokenTree::Delimited(DelimSpan::dummy(), tokenstream::Delimited {\n                 delim: token::Paren,\n                 tts: TokenStream::empty().into(),\n             })]\n@@ -385,13 +386,16 @@ pub fn unflatten(tts: Vec<TokenTree>) -> Vec<TokenTree> {\n \n     let mut results = Vec::new();\n     let mut result = Vec::new();\n+    let mut open_span = DUMMY_SP;\n     for tree in tts {\n         match tree {\n-            TokenTree::Token(_, token::OpenDelim(..)) => {\n+            TokenTree::Token(span, token::OpenDelim(..)) => {\n+                open_span = span;\n                 results.push(::std::mem::replace(&mut result, Vec::new()));\n             }\n             TokenTree::Token(span, token::CloseDelim(delim)) => {\n-                let tree = TokenTree::Delimited(span, Delimited {\n+                let delim_span = DelimSpan::from_pair(open_span, span);\n+                let tree = TokenTree::Delimited(delim_span, Delimited {\n                     delim,\n                     tts: result.into_iter().map(TokenStream::from).collect::<TokenStream>().into(),\n                 });\n@@ -756,9 +760,9 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &TokenTree, quoted: bool) -> Vec<ast::Stmt\n             vec![cx.stmt_expr(e_push)]\n         },\n         TokenTree::Delimited(span, ref delimed) => {\n-            let mut stmts = statements_mk_tt(cx, &delimed.open_tt(span), false);\n+            let mut stmts = statements_mk_tt(cx, &delimed.open_tt(span.open), false);\n             stmts.extend(statements_mk_tts(cx, delimed.stream()));\n-            stmts.extend(statements_mk_tt(cx, &delimed.close_tt(span), false));\n+            stmts.extend(statements_mk_tt(cx, &delimed.close_tt(span.close), false));\n             stmts\n         }\n     }"}, {"sha": "2ef8da3f6d80c3b55bf307d4bb1f11885cccac3d", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -85,7 +85,7 @@ pub use self::ParseResult::*;\n use self::TokenTreeOrTokenTreeSlice::*;\n \n use ast::Ident;\n-use syntax_pos::{self, BytePos, Span};\n+use syntax_pos::{self, Span};\n use errors::FatalError;\n use ext::tt::quoted::{self, TokenTree};\n use parse::{Directory, ParseSess};\n@@ -94,7 +94,7 @@ use parse::token::{self, DocComment, Nonterminal, Token};\n use print::pprust;\n use OneVector;\n use symbol::keywords;\n-use tokenstream::TokenStream;\n+use tokenstream::{DelimSpan, TokenStream};\n \n use rustc_data_structures::fx::FxHashMap;\n use std::collections::hash_map::Entry::{Occupied, Vacant};\n@@ -154,7 +154,7 @@ struct MatcherPos<'a> {\n     /// The beginning position in the source that the beginning of this matcher corresponds to. In\n     /// other words, the token in the source at `sp_lo` is matched against the first token of the\n     /// matcher.\n-    sp_lo: BytePos,\n+    sp_lo: Span,\n \n     /// For each named metavar in the matcher, we keep track of token trees matched against the\n     /// metavar by the black box parser. In particular, there may be more than one match per\n@@ -285,7 +285,7 @@ fn create_matches(len: usize) -> Vec<Rc<Vec<NamedMatch>>> {\n \n /// Generate the top-level matcher position in which the \"dot\" is before the first token of the\n /// matcher `ms` and we are going to start matching at position `lo` in the source.\n-fn initial_matcher_pos(ms: &[TokenTree], lo: BytePos) -> MatcherPos {\n+fn initial_matcher_pos(ms: &[TokenTree], lo: Span) -> MatcherPos {\n     let match_idx_hi = count_names(ms);\n     let matches = create_matches(match_idx_hi);\n     MatcherPos {\n@@ -332,7 +332,7 @@ fn initial_matcher_pos(ms: &[TokenTree], lo: BytePos) -> MatcherPos {\n /// token tree it was derived from.\n #[derive(Debug, Clone)]\n pub enum NamedMatch {\n-    MatchedSeq(Rc<Vec<NamedMatch>>, syntax_pos::Span),\n+    MatchedSeq(Rc<Vec<NamedMatch>>, DelimSpan),\n     MatchedNonterminal(Rc<Nonterminal>),\n }\n \n@@ -488,7 +488,7 @@ fn inner_parse_loop<'a>(\n                     // Add matches from this repetition to the `matches` of `up`\n                     for idx in item.match_lo..item.match_hi {\n                         let sub = item.matches[idx].clone();\n-                        let span = span.with_lo(item.sp_lo);\n+                        let span = DelimSpan::from_pair(item.sp_lo, span);\n                         new_pos.push_match(idx, MatchedSeq(sub, span));\n                     }\n \n@@ -556,7 +556,7 @@ fn inner_parse_loop<'a>(\n                         match_cur: item.match_cur,\n                         match_hi: item.match_cur + seq.num_captures,\n                         up: Some(item),\n-                        sp_lo: sp.lo(),\n+                        sp_lo: sp.open,\n                         top_elts: Tt(TokenTree::Sequence(sp, seq)),\n                     })));\n                 }\n@@ -643,7 +643,7 @@ pub fn parse(\n     //\n     // This MatcherPos instance is allocated on the stack. All others -- and\n     // there are frequently *no* others! -- are allocated on the heap.\n-    let mut initial = initial_matcher_pos(ms, parser.span.lo());\n+    let mut initial = initial_matcher_pos(ms, parser.span);\n     let mut cur_items = smallvec![MatcherPosHandle::Ref(&mut initial)];\n     let mut next_items = Vec::new();\n "}, {"sha": "86247745c4116b6eedb3d1cdda9f38aadf05fca0", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 13, "deletions": 12, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -25,7 +25,7 @@ use parse::parser::Parser;\n use parse::token::{self, NtTT};\n use parse::token::Token::*;\n use symbol::Symbol;\n-use tokenstream::{TokenStream, TokenTree};\n+use tokenstream::{DelimSpan, TokenStream, TokenTree};\n \n use rustc_data_structures::fx::FxHashMap;\n use std::borrow::Cow;\n@@ -226,7 +226,7 @@ pub fn compile(sess: &ParseSess, features: &Features, def: &ast::Item, edition:\n     // ...quasiquoting this would be nice.\n     // These spans won't matter, anyways\n     let argument_gram = vec![\n-        quoted::TokenTree::Sequence(DUMMY_SP, Lrc::new(quoted::SequenceRepetition {\n+        quoted::TokenTree::Sequence(DelimSpan::dummy(), Lrc::new(quoted::SequenceRepetition {\n             tts: vec![\n                 quoted::TokenTree::MetaVarDecl(DUMMY_SP, lhs_nm, ast::Ident::from_str(\"tt\")),\n                 quoted::TokenTree::Token(DUMMY_SP, token::FatArrow),\n@@ -237,7 +237,7 @@ pub fn compile(sess: &ParseSess, features: &Features, def: &ast::Item, edition:\n             num_captures: 2,\n         })),\n         // to phase into semicolon-termination instead of semicolon-separation\n-        quoted::TokenTree::Sequence(DUMMY_SP, Lrc::new(quoted::SequenceRepetition {\n+        quoted::TokenTree::Sequence(DelimSpan::dummy(), Lrc::new(quoted::SequenceRepetition {\n             tts: vec![quoted::TokenTree::Token(DUMMY_SP, token::Semi)],\n             separator: None,\n             op: quoted::KleeneOp::ZeroOrMore,\n@@ -400,7 +400,8 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n                         _ => false,\n                     }\n                 }) {\n-                    sess.span_diagnostic.span_err(span, \"repetition matches empty token tree\");\n+                    let sp = span.entire();\n+                    sess.span_diagnostic.span_err(sp, \"repetition matches empty token tree\");\n                     return false;\n                 }\n                 if !check_lhs_no_empty_seq(sess, &seq.tts) {\n@@ -474,12 +475,12 @@ impl FirstSets {\n                     }\n                     TokenTree::Delimited(span, ref delimited) => {\n                         build_recur(sets, &delimited.tts[..]);\n-                        first.replace_with(delimited.open_tt(span));\n+                        first.replace_with(delimited.open_tt(span.open));\n                     }\n                     TokenTree::Sequence(sp, ref seq_rep) => {\n                         let subfirst = build_recur(sets, &seq_rep.tts[..]);\n \n-                        match sets.first.entry(sp) {\n+                        match sets.first.entry(sp.entire()) {\n                             Entry::Vacant(vac) => {\n                                 vac.insert(Some(subfirst.clone()));\n                             }\n@@ -499,7 +500,7 @@ impl FirstSets {\n \n                         if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n                                                         subfirst.maybe_empty) {\n-                            first.add_one_maybe(TokenTree::Token(sp, sep.clone()));\n+                            first.add_one_maybe(TokenTree::Token(sp.entire(), sep.clone()));\n                         }\n \n                         // Reverse scan: Sequence comes before `first`.\n@@ -534,19 +535,19 @@ impl FirstSets {\n                     return first;\n                 }\n                 TokenTree::Delimited(span, ref delimited) => {\n-                    first.add_one(delimited.open_tt(span));\n+                    first.add_one(delimited.open_tt(span.open));\n                     return first;\n                 }\n                 TokenTree::Sequence(sp, ref seq_rep) => {\n-                    match self.first.get(&sp) {\n+                    match self.first.get(&sp.entire()) {\n                         Some(&Some(ref subfirst)) => {\n \n                             // If the sequence contents can be empty, then the first\n                             // token could be the separator token itself.\n \n                             if let (Some(ref sep), true) = (seq_rep.separator.clone(),\n                                                             subfirst.maybe_empty) {\n-                                first.add_one_maybe(TokenTree::Token(sp, sep.clone()));\n+                                first.add_one_maybe(TokenTree::Token(sp.entire(), sep.clone()));\n                             }\n \n                             assert!(first.maybe_empty);\n@@ -727,7 +728,7 @@ fn check_matcher_core(sess: &ParseSess,\n                 }\n             }\n             TokenTree::Delimited(span, ref d) => {\n-                let my_suffix = TokenSet::singleton(d.close_tt(span));\n+                let my_suffix = TokenSet::singleton(d.close_tt(span.close));\n                 check_matcher_core(sess, features, attrs, first_sets, &d.tts, &my_suffix);\n                 // don't track non NT tokens\n                 last.replace_with_irrelevant();\n@@ -751,7 +752,7 @@ fn check_matcher_core(sess: &ParseSess,\n                 let mut new;\n                 let my_suffix = if let Some(ref u) = seq_rep.separator {\n                     new = suffix_first.clone();\n-                    new.add_one_maybe(TokenTree::Token(sp, u.clone()));\n+                    new.add_one_maybe(TokenTree::Token(sp.entire(), u.clone()));\n                     &new\n                 } else {\n                     &suffix_first"}, {"sha": "74363f3e5f7d968931a36fccfcd8489fa1dd8c6c", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -16,7 +16,7 @@ use parse::{token, ParseSess};\n use print::pprust;\n use symbol::keywords;\n use syntax_pos::{edition::Edition, BytePos, Span};\n-use tokenstream;\n+use tokenstream::{self, DelimSpan};\n use {ast, attr};\n \n use rustc_data_structures::sync::Lrc;\n@@ -90,9 +90,9 @@ pub enum KleeneOp {\n #[derive(Debug, Clone, PartialEq, RustcEncodable, RustcDecodable)]\n pub enum TokenTree {\n     Token(Span, token::Token),\n-    Delimited(Span, Lrc<Delimited>),\n+    Delimited(DelimSpan, Lrc<Delimited>),\n     /// A kleene-style repetition sequence\n-    Sequence(Span, Lrc<SequenceRepetition>),\n+    Sequence(DelimSpan, Lrc<SequenceRepetition>),\n     /// E.g. `$var`\n     MetaVar(Span, ast::Ident),\n     /// E.g. `$var:expr`. This is only used in the left hand side of MBE macros.\n@@ -137,10 +137,10 @@ impl TokenTree {\n             }\n             (&TokenTree::Delimited(span, ref delimed), _) => {\n                 if index == 0 {\n-                    return delimed.open_tt(span);\n+                    return delimed.open_tt(span.open);\n                 }\n                 if index == delimed.tts.len() + 1 {\n-                    return delimed.close_tt(span);\n+                    return delimed.close_tt(span.close);\n                 }\n                 delimed.tts[index - 1].clone()\n             }\n@@ -154,9 +154,9 @@ impl TokenTree {\n         match *self {\n             TokenTree::Token(sp, _)\n             | TokenTree::MetaVar(sp, _)\n-            | TokenTree::MetaVarDecl(sp, _, _)\n-            | TokenTree::Delimited(sp, _)\n-            | TokenTree::Sequence(sp, _) => sp,\n+            | TokenTree::MetaVarDecl(sp, _, _) => sp,\n+            TokenTree::Delimited(sp, _)\n+            | TokenTree::Sequence(sp, _) => sp.entire(),\n         }\n     }\n }\n@@ -286,7 +286,7 @@ where\n                 if delimited.delim != token::Paren {\n                     let tok = pprust::token_to_string(&token::OpenDelim(delimited.delim));\n                     let msg = format!(\"expected `(`, found `{}`\", tok);\n-                    sess.span_diagnostic.span_err(span, &msg);\n+                    sess.span_diagnostic.span_err(span.entire(), &msg);\n                 }\n                 // Parse the contents of the sequence itself\n                 let sequence = parse(\n@@ -302,7 +302,7 @@ where\n                 let (separator, op) =\n                     parse_sep_and_kleene_op(\n                         trees,\n-                        span,\n+                        span.entire(),\n                         sess,\n                         features,\n                         attrs,"}, {"sha": "2ed469e8e77f855ce868b12a92786b0f67b09e54", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -16,8 +16,8 @@ use ext::tt::quoted;\n use fold::noop_fold_tt;\n use parse::token::{self, Token, NtTT};\n use OneVector;\n-use syntax_pos::{Span, DUMMY_SP};\n-use tokenstream::{TokenStream, TokenTree, Delimited};\n+use syntax_pos::DUMMY_SP;\n+use tokenstream::{TokenStream, TokenTree, Delimited, DelimSpan};\n \n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sync::Lrc;\n@@ -30,7 +30,7 @@ enum Frame {\n     Delimited {\n         forest: Lrc<quoted::Delimited>,\n         idx: usize,\n-        span: Span,\n+        span: DelimSpan,\n     },\n     Sequence {\n         forest: Lrc<quoted::SequenceRepetition>,\n@@ -42,7 +42,7 @@ enum Frame {\n impl Frame {\n     fn new(tts: Vec<quoted::TokenTree>) -> Frame {\n         let forest = Lrc::new(quoted::Delimited { delim: token::NoDelim, tts: tts });\n-        Frame::Delimited { forest: forest, idx: 0, span: DUMMY_SP }\n+        Frame::Delimited { forest: forest, idx: 0, span: DelimSpan::dummy() }\n     }\n }\n \n@@ -123,20 +123,20 @@ pub fn transcribe(cx: &ExtCtxt,\n                                          &interpolations,\n                                          &repeats) {\n                     LockstepIterSize::Unconstrained => {\n-                        cx.span_fatal(sp, /* blame macro writer */\n+                        cx.span_fatal(sp.entire(), /* blame macro writer */\n                             \"attempted to repeat an expression \\\n                              containing no syntax \\\n                              variables matched as repeating at this depth\");\n                     }\n                     LockstepIterSize::Contradiction(ref msg) => {\n                         // FIXME #2887 blame macro invoker instead\n-                        cx.span_fatal(sp, &msg[..]);\n+                        cx.span_fatal(sp.entire(), &msg[..]);\n                     }\n                     LockstepIterSize::Constraint(len, _) => {\n                         if len == 0 {\n                             if seq.op == quoted::KleeneOp::OneOrMore {\n                                 // FIXME #2887 blame invoker\n-                                cx.span_fatal(sp, \"this must repeat at least once\");\n+                                cx.span_fatal(sp.entire(), \"this must repeat at least once\");\n                             }\n                         } else {\n                             repeats.push((0, len));"}, {"sha": "032393b4f12534e3727808531de87e5bfd9a8999", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 7, "deletions": 4, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -594,10 +594,13 @@ pub fn noop_fold_tt<T: Folder>(tt: TokenTree, fld: &mut T) -> TokenTree {\n     match tt {\n         TokenTree::Token(span, tok) =>\n             TokenTree::Token(fld.new_span(span), fld.fold_token(tok)),\n-        TokenTree::Delimited(span, delimed) => TokenTree::Delimited(fld.new_span(span), Delimited {\n-            tts: fld.fold_tts(delimed.stream()).into(),\n-            delim: delimed.delim,\n-        }),\n+        TokenTree::Delimited(span, delimed) => TokenTree::Delimited(\n+            DelimSpan::from_pair(fld.new_span(span.open), fld.new_span(span.close)),\n+            Delimited {\n+                tts: fld.fold_tts(delimed.stream()).into(),\n+                delim: delimed.delim,\n+            }\n+        ),\n     }\n }\n "}, {"sha": "d19748937e108fc5ce4635098efd0e17b65234fa", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -11,7 +11,7 @@\n use print::pprust::token_to_string;\n use parse::lexer::StringReader;\n use parse::{token, PResult};\n-use tokenstream::{Delimited, TokenStream, TokenTree};\n+use tokenstream::{Delimited, DelimSpan, TokenStream, TokenTree};\n \n impl<'a> StringReader<'a> {\n     // Parse a stream of tokens into a list of `TokenTree`s, up to an `Eof`.\n@@ -68,7 +68,7 @@ impl<'a> StringReader<'a> {\n                 let tts = self.parse_token_trees_until_close_delim();\n \n                 // Expand to cover the entire delimited token tree\n-                let span = pre_span.with_hi(self.span.hi());\n+                let delim_span = DelimSpan::from_pair(pre_span, self.span);\n \n                 match self.token {\n                     // Correct delimiter.\n@@ -119,7 +119,7 @@ impl<'a> StringReader<'a> {\n                     _ => {}\n                 }\n \n-                Ok(TokenTree::Delimited(span, Delimited {\n+                Ok(TokenTree::Delimited(delim_span, Delimited {\n                     delim,\n                     tts: tts.into(),\n                 }).into())"}, {"sha": "5c6d5816a472b045acbdedef6395fbd5e94f065f", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -722,7 +722,7 @@ mod tests {\n     use attr::first_attr_value_str_by_name;\n     use parse;\n     use print::pprust::item_to_string;\n-    use tokenstream::{self, TokenTree};\n+    use tokenstream::{self, DelimSpan, TokenTree};\n     use util::parser_testing::string_to_stream;\n     use util::parser_testing::{string_to_expr, string_to_item};\n     use with_globals;\n@@ -805,7 +805,7 @@ mod tests {\n                 TokenTree::Token(sp(0, 2), token::Ident(Ident::from_str(\"fn\"), false)).into(),\n                 TokenTree::Token(sp(3, 4), token::Ident(Ident::from_str(\"a\"), false)).into(),\n                 TokenTree::Delimited(\n-                    sp(5, 14),\n+                    DelimSpan::from_pair(sp(5, 6), sp(13, 14)),\n                     tokenstream::Delimited {\n                         delim: token::DelimToken::Paren,\n                         tts: TokenStream::concat(vec![\n@@ -817,7 +817,7 @@ mod tests {\n                         ]).into(),\n                     }).into(),\n                 TokenTree::Delimited(\n-                    sp(15, 21),\n+                    DelimSpan::from_pair(sp(15, 16), sp(20, 21)),\n                     tokenstream::Delimited {\n                         delim: token::DelimToken::Brace,\n                         tts: TokenStream::concat(vec!["}, {"sha": "b9d4e9fc268d849e4a8f3316cdd0bf2be80e1f9d", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 12, "deletions": 10, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -54,7 +54,7 @@ use print::pprust;\n use ptr::P;\n use parse::PResult;\n use ThinVec;\n-use tokenstream::{self, Delimited, ThinTokenStream, TokenTree, TokenStream};\n+use tokenstream::{self, Delimited, DelimSpan, ThinTokenStream, TokenTree, TokenStream};\n use symbol::{Symbol, keywords};\n \n use std::borrow::Cow;\n@@ -262,7 +262,7 @@ struct TokenCursor {\n #[derive(Clone)]\n struct TokenCursorFrame {\n     delim: token::DelimToken,\n-    span: Span,\n+    span: DelimSpan,\n     open_delim: bool,\n     tree_cursor: tokenstream::Cursor,\n     close_delim: bool,\n@@ -293,7 +293,7 @@ enum LastToken {\n }\n \n impl TokenCursorFrame {\n-    fn new(sp: Span, delimited: &Delimited) -> Self {\n+    fn new(sp: DelimSpan, delimited: &Delimited) -> Self {\n         TokenCursorFrame {\n             delim: delimited.delim,\n             span: sp,\n@@ -311,13 +311,13 @@ impl TokenCursor {\n             let tree = if !self.frame.open_delim {\n                 self.frame.open_delim = true;\n                 Delimited { delim: self.frame.delim, tts: TokenStream::empty().into() }\n-                    .open_tt(self.frame.span)\n+                    .open_tt(self.frame.span.open)\n             } else if let Some(tree) = self.frame.tree_cursor.next() {\n                 tree\n             } else if !self.frame.close_delim {\n                 self.frame.close_delim = true;\n                 Delimited { delim: self.frame.delim, tts: TokenStream::empty().into() }\n-                    .close_tt(self.frame.span)\n+                    .close_tt(self.frame.span.close)\n             } else if let Some(frame) = self.stack.pop() {\n                 self.frame = frame;\n                 continue\n@@ -361,7 +361,8 @@ impl TokenCursor {\n             num_of_hashes = cmp::max(num_of_hashes, count);\n         }\n \n-        let body = TokenTree::Delimited(sp, Delimited {\n+        let delim_span = DelimSpan::from_single(sp);\n+        let body = TokenTree::Delimited(delim_span, Delimited {\n             delim: token::Bracket,\n             tts: [TokenTree::Token(sp, token::Ident(ast::Ident::from_str(\"doc\"), false)),\n                   TokenTree::Token(sp, token::Eq),\n@@ -370,7 +371,7 @@ impl TokenCursor {\n                 .iter().cloned().collect::<TokenStream>().into(),\n         });\n \n-        self.stack.push(mem::replace(&mut self.frame, TokenCursorFrame::new(sp, &Delimited {\n+        self.stack.push(mem::replace(&mut self.frame, TokenCursorFrame::new(delim_span, &Delimited {\n             delim: token::NoDelim,\n             tts: if doc_comment_style(&name.as_str()) == AttrStyle::Inner {\n                 [TokenTree::Token(sp, token::Pound), TokenTree::Token(sp, token::Not), body]\n@@ -560,7 +561,7 @@ impl<'a> Parser<'a> {\n             root_module_name: None,\n             expected_tokens: Vec::new(),\n             token_cursor: TokenCursor {\n-                frame: TokenCursorFrame::new(syntax_pos::DUMMY_SP, &Delimited {\n+                frame: TokenCursorFrame::new(DelimSpan::dummy(), &Delimited {\n                     delim: token::NoDelim,\n                     tts: tokens.into(),\n                 }),\n@@ -1229,7 +1230,8 @@ impl<'a> Parser<'a> {\n         }\n \n         match self.token_cursor.frame.tree_cursor.look_ahead(dist - 1) {\n-            Some(TokenTree::Token(span, _)) | Some(TokenTree::Delimited(span, _)) => span,\n+            Some(TokenTree::Token(span, _)) => span,\n+            Some(TokenTree::Delimited(span, _)) => span.entire(),\n             None => self.look_ahead_span(dist - 1),\n         }\n     }\n@@ -2796,7 +2798,7 @@ impl<'a> Parser<'a> {\n             token::OpenDelim(..) => {\n                 let frame = mem::replace(&mut self.token_cursor.frame,\n                                          self.token_cursor.stack.pop().unwrap());\n-                self.span = frame.span;\n+                self.span = frame.span.entire();\n                 self.bump();\n                 TokenTree::Delimited(frame.span, Delimited {\n                     delim: frame.delim,"}, {"sha": "6e8014284ec401c2d2ec93a9650a8cae331cd6aa", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -23,8 +23,7 @@ use symbol::keywords;\n use syntax::parse::parse_stream_from_source_str;\n use syntax_pos::{self, Span, FileName};\n use syntax_pos::symbol::{self, Symbol};\n-use tokenstream::{TokenStream, TokenTree};\n-use tokenstream;\n+use tokenstream::{self, DelimSpan, TokenStream, TokenTree};\n \n use std::{cmp, fmt};\n use std::mem;\n@@ -825,7 +824,8 @@ fn prepend_attrs(sess: &ParseSess,\n         // that it encompasses more than each token, but it hopefully is \"good\n         // enough\" for now at least.\n         builder.push(tokenstream::TokenTree::Token(attr.span, Pound));\n-        builder.push(tokenstream::TokenTree::Delimited(attr.span, tokens));\n+        let delim_span = DelimSpan::from_single(attr.span);\n+        builder.push(tokenstream::TokenTree::Delimited(delim_span, tokens));\n     }\n     builder.push(tokens.clone());\n     Some(builder.build())"}, {"sha": "70867f9e42ff5f3cc9c9644f771397d2980559ac", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 53, "deletions": 26, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -22,7 +22,7 @@\n //! and a borrowed `TokenStream` is sufficient to build an owned `TokenStream` without taking\n //! ownership of the original.\n \n-use syntax_pos::{BytePos, Span, DUMMY_SP};\n+use syntax_pos::{BytePos, Mark, Span, DUMMY_SP};\n use ext::base;\n use ext::tt::{macro_parser, quoted};\n use parse::Directory;\n@@ -97,7 +97,7 @@ pub enum TokenTree {\n     /// A single token\n     Token(Span, token::Token),\n     /// A delimited sequence of token trees\n-    Delimited(Span, Delimited),\n+    Delimited(DelimSpan, Delimited),\n }\n \n impl TokenTree {\n@@ -145,16 +145,16 @@ impl TokenTree {\n     /// Retrieve the TokenTree's span.\n     pub fn span(&self) -> Span {\n         match *self {\n-            TokenTree::Token(sp, _) | TokenTree::Delimited(sp, _) => sp,\n+            TokenTree::Token(sp, _) => sp,\n+            TokenTree::Delimited(sp, _) => sp.entire(),\n         }\n     }\n \n     /// Modify the `TokenTree`'s span inplace.\n     pub fn set_span(&mut self, span: Span) {\n         match *self {\n-            TokenTree::Token(ref mut sp, _) | TokenTree::Delimited(ref mut sp, _) => {\n-                *sp = span;\n-            }\n+            TokenTree::Token(ref mut sp, _) => *sp = span,\n+            TokenTree::Delimited(ref mut sp, _) => *sp = DelimSpan::from_single(span),\n         }\n     }\n \n@@ -192,27 +192,20 @@ impl TokenStream {\n             let mut iter = slice.iter().enumerate().peekable();\n             while let Some((pos, ts)) = iter.next() {\n                 if let Some((_, next)) = iter.peek() {\n-                    match (ts, next) {\n-                        (TokenStream {\n-                            kind: TokenStreamKind::Tree(TokenTree::Token(_, token::Token::Comma))\n-                        }, _) |\n-                        (_, TokenStream {\n-                            kind: TokenStreamKind::Tree(TokenTree::Token(_, token::Token::Comma))\n-                        }) => {}\n-                        (TokenStream {\n-                            kind: TokenStreamKind::Tree(TokenTree::Token(sp, _))\n-                        }, _) |\n-                        (TokenStream {\n-                            kind: TokenStreamKind::Tree(TokenTree::Delimited(sp, _))\n-                        }, _) => {\n-                            let sp = sp.shrink_to_hi();\n-                            let comma = TokenStream {\n-                                kind: TokenStreamKind::Tree(TokenTree::Token(sp, token::Comma)),\n-                            };\n-                            suggestion = Some((pos, comma, sp));\n+                    let sp = match (&ts.kind, &next.kind) {\n+                        (TokenStreamKind::Tree(TokenTree::Token(_, token::Token::Comma)), _) |\n+                        (_, TokenStreamKind::Tree(TokenTree::Token(_, token::Token::Comma))) => {\n+                            continue;\n                         }\n-                        _ => {}\n-                    }\n+                        (TokenStreamKind::Tree(TokenTree::Token(sp, _)), _) => *sp,\n+                        (TokenStreamKind::Tree(TokenTree::Delimited(sp, _)), _) => sp.entire(),\n+                        _ => continue,\n+                    };\n+                    let sp = sp.shrink_to_hi();\n+                    let comma = TokenStream {\n+                        kind: TokenStreamKind::Tree(TokenTree::Token(sp, token::Comma)),\n+                    };\n+                    suggestion = Some((pos, comma, sp));\n                 }\n             }\n             if let Some((pos, comma, sp)) = suggestion {\n@@ -718,6 +711,40 @@ impl Decodable for ThinTokenStream {\n     }\n }\n \n+#[derive(Debug, Copy, Clone, PartialEq, RustcEncodable, RustcDecodable)]\n+pub struct DelimSpan {\n+    pub open: Span,\n+    pub close: Span,\n+}\n+\n+impl DelimSpan {\n+    pub fn from_single(sp: Span) -> Self {\n+        DelimSpan {\n+            open: sp,\n+            close: sp,\n+        }\n+    }\n+\n+    pub fn from_pair(open: Span, close: Span) -> Self {\n+        DelimSpan { open, close }\n+    }\n+\n+    pub fn dummy() -> Self {\n+        Self::from_single(DUMMY_SP)\n+    }\n+\n+    pub fn entire(self) -> Span {\n+        self.open.with_hi(self.close.hi())\n+    }\n+\n+    pub fn apply_mark(self, mark: Mark) -> Self {\n+        DelimSpan {\n+            open: self.open.apply_mark(mark),\n+            close: self.close.apply_mark(mark),\n+        }\n+    }\n+}\n+\n #[cfg(test)]\n mod tests {\n     use super::*;"}, {"sha": "f2f14f84923c0c2aacb5600ef18c89a316724e0e", "filename": "src/test/run-pass-fulldeps/auxiliary/procedural_mbe_matching.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1dd39e724c2a37f08f534e90ced134d38a49417/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fprocedural_mbe_matching.rs?ref=a1dd39e724c2a37f08f534e90ced134d38a49417", "patch": "@@ -70,7 +70,8 @@ fn expand_mbe_matches(cx: &mut ExtCtxt, _: Span, args: &[TokenTree])\n                     _ => unreachable!(),\n                 }\n             }).collect();\n-            let arm = cx.arm(seq_sp, pats, cx.expr_bool(seq_sp, true));\n+            let span = seq_sp.entire();\n+            let arm = cx.arm(span, pats, cx.expr_bool(span, true));\n \n             quote_expr!(cx,\n                 match $matched_expr {"}]}