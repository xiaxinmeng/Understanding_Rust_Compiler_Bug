{"sha": "ee73f80dc963707df3b3da82976556d64cac5752", "node_id": "MDY6Q29tbWl0NzI0NzEyOmVlNzNmODBkYzk2MzcwN2RmM2IzZGE4Mjk3NjU1NmQ2NGNhYzU3NTI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-09-03T13:59:57Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-09-03T13:59:57Z"}, "message": "Auto merge of #53673 - michaelwoerister:incr-thinlto-2000, r=alexcrichton\n\nEnable ThinLTO with incremental compilation.\n\nThis is an updated version of #52309. This PR allows `rustc` to use (local) ThinLTO and incremental compilation at the same time. In theory this should allow for getting compile-time improvements for small changes while keeping the runtime performance of the generated code roughly the same as when compiling non-incrementally.\n\nThe difference to #52309 is that this version also caches the pre-LTO version of LLVM bitcode. This allows for another layer of caching:\n1. if the module itself has changed, we have to re-codegen and re-optimize.\n2. if the module itself has not changed, but a module it imported from during ThinLTO has, we don't need to re-codegen and don't need to re-run the first optimization phase. Only the second (i.e. ThinLTO-) optimization phase is re-run.\n3. if neither the module itself nor any of its imports have changed then we can re-use the final, post-ThinLTO version of the module. (We might have to load its pre-ThinLTO version though so it's available for other modules to import from)", "tree": {"sha": "95b4ebd6c5b993d4c4c4ab8d3ce4b2c3913fad84", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/95b4ebd6c5b993d4c4c4ab8d3ce4b2c3913fad84"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ee73f80dc963707df3b3da82976556d64cac5752", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ee73f80dc963707df3b3da82976556d64cac5752", "html_url": "https://github.com/rust-lang/rust/commit/ee73f80dc963707df3b3da82976556d64cac5752", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ee73f80dc963707df3b3da82976556d64cac5752/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "591a17d3d90d6cab51200a0e696f0d8ca63c2f87", "url": "https://api.github.com/repos/rust-lang/rust/commits/591a17d3d90d6cab51200a0e696f0d8ca63c2f87", "html_url": "https://github.com/rust-lang/rust/commit/591a17d3d90d6cab51200a0e696f0d8ca63c2f87"}, {"sha": "21d05f64aa10fd15208bd6d96599275b044a0636", "url": "https://api.github.com/repos/rust-lang/rust/commits/21d05f64aa10fd15208bd6d96599275b044a0636", "html_url": "https://github.com/rust-lang/rust/commit/21d05f64aa10fd15208bd6d96599275b044a0636"}], "stats": {"total": 944, "additions": 647, "deletions": 297}, "files": [{"sha": "defb5b9869d822f9d37e73775daa80738bf41b6d", "filename": "src/Cargo.lock", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -1198,6 +1198,15 @@ dependencies = [\n  \"libc 0.2.43 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]\n \n+[[package]]\n+name = \"memmap\"\n+version = \"0.6.2\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+dependencies = [\n+ \"libc 0.2.43 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"winapi 0.3.5 (registry+https://github.com/rust-lang/crates.io-index)\",\n+]\n+\n [[package]]\n name = \"memoffset\"\n version = \"0.2.1\"\n@@ -2029,6 +2038,7 @@ name = \"rustc_codegen_llvm\"\n version = \"0.0.0\"\n dependencies = [\n  \"cc 1.0.22 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"memmap 0.6.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"num_cpus 1.8.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc-demangle 0.1.9 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc_llvm 0.0.0\",\n@@ -3151,6 +3161,7 @@ source = \"registry+https://github.com/rust-lang/crates.io-index\"\n \"checksum matches 0.1.8 (registry+https://github.com/rust-lang/crates.io-index)\" = \"7ffc5c5338469d4d3ea17d269fa8ea3512ad247247c30bd2df69e68309ed0a08\"\n \"checksum mdbook 0.1.7 (registry+https://github.com/rust-lang/crates.io-index)\" = \"90b5a8d7e341ceee5db3882a06078d42661ddcfa2b3687319cc5da76ec4e782f\"\n \"checksum memchr 2.0.2 (registry+https://github.com/rust-lang/crates.io-index)\" = \"a3b4142ab8738a78c51896f704f83c11df047ff1bda9a92a661aa6361552d93d\"\n+\"checksum memmap 0.6.2 (registry+https://github.com/rust-lang/crates.io-index)\" = \"e2ffa2c986de11a9df78620c01eeaaf27d94d3ff02bf81bfcca953102dd0c6ff\"\n \"checksum memoffset 0.2.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"0f9dc261e2b62d7a622bf416ea3c5245cdd5d9a7fcc428c0d06804dfce1775b3\"\n \"checksum minifier 0.0.19 (registry+https://github.com/rust-lang/crates.io-index)\" = \"9908ed7c62f990c21ab41fdca53a864a3ada0da69d8729c4de727b397e27bc11\"\n \"checksum miniz-sys 0.1.10 (registry+https://github.com/rust-lang/crates.io-index)\" = \"609ce024854aeb19a0ef7567d348aaa5a746b32fb72e336df7fcc16869d7e2b4\""}, {"sha": "4df0fc443a27c6ed2fcc246cc607fad247f12adb", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -878,7 +878,7 @@ pub struct WorkProduct {\n     pub saved_files: Vec<(WorkProductFileKind, String)>,\n }\n \n-#[derive(Clone, Copy, Debug, RustcEncodable, RustcDecodable)]\n+#[derive(Clone, Copy, Debug, RustcEncodable, RustcDecodable, PartialEq)]\n pub enum WorkProductFileKind {\n     Object,\n     Bytecode,"}, {"sha": "ee3fabc58d53f6edc6e6b150a1b652727991587b", "filename": "src/librustc/session/config.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fsession%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fsession%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fconfig.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -68,7 +68,7 @@ pub enum OptLevel {\n     SizeMin,    // -Oz\n }\n \n-#[derive(Clone, Copy, PartialEq, Hash)]\n+#[derive(Clone, Copy, PartialEq, Hash, Debug)]\n pub enum Lto {\n     /// Don't do any LTO whatsoever\n     No,"}, {"sha": "778c388c7dec71181c88bdb7da7b009c6f8a1c46", "filename": "src/librustc/session/mod.rs", "status": "modified", "additions": 12, "deletions": 7, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fsession%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fsession%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fmod.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -580,11 +580,6 @@ impl Session {\n             return config::Lto::No;\n         }\n \n-        // Right now ThinLTO isn't compatible with incremental compilation.\n-        if self.opts.incremental.is_some() {\n-            return config::Lto::No;\n-        }\n-\n         // Now we're in \"defaults\" territory. By default we enable ThinLTO for\n         // optimized compiles (anything greater than O0).\n         match self.opts.optimize {\n@@ -1177,8 +1172,18 @@ pub fn build_session_(\n // commandline argument, you can do so here.\n fn validate_commandline_args_with_session_available(sess: &Session) {\n \n-    if sess.lto() != Lto::No && sess.opts.incremental.is_some() {\n-        sess.err(\"can't perform LTO when compiling incrementally\");\n+    if sess.opts.incremental.is_some() {\n+        match sess.lto() {\n+            Lto::Yes |\n+            Lto::Thin |\n+            Lto::Fat => {\n+                sess.err(\"can't perform LTO when compiling incrementally\");\n+            }\n+            Lto::ThinLocal |\n+            Lto::No => {\n+                // This is fine\n+            }\n+        }\n     }\n \n     // Since we don't know if code in an rlib will be linked to statically or"}, {"sha": "837354bfcaf360246acac0c7717df5a2bb3708e3", "filename": "src/librustc/ty/query/config.rs", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -716,12 +716,6 @@ impl<'tcx> QueryDescription<'tcx> for queries::codegen_unit<'tcx> {\n     }\n }\n \n-impl<'tcx> QueryDescription<'tcx> for queries::compile_codegen_unit<'tcx> {\n-    fn describe(_tcx: TyCtxt, _: InternedString) -> String {\n-        \"compile_codegen_unit\".to_string()\n-    }\n-}\n-\n impl<'tcx> QueryDescription<'tcx> for queries::output_filenames<'tcx> {\n     fn describe(_tcx: TyCtxt, _: CrateNum) -> String {\n         \"output_filenames\".to_string()"}, {"sha": "993ba2fd13d0d7d05bda5003b97fe950d9cc92ea", "filename": "src/librustc/ty/query/mod.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -28,7 +28,7 @@ use middle::lib_features::LibFeatures;\n use middle::lang_items::{LanguageItems, LangItem};\n use middle::exported_symbols::{SymbolExportLevel, ExportedSymbol};\n use mir::interpret::ConstEvalResult;\n-use mir::mono::{CodegenUnit, Stats};\n+use mir::mono::CodegenUnit;\n use mir;\n use mir::interpret::GlobalId;\n use session::{CompileResult, CrateDisambiguator};\n@@ -525,7 +525,6 @@ define_queries! { <'tcx>\n             -> (Arc<DefIdSet>, Arc<Vec<Arc<CodegenUnit<'tcx>>>>),\n         [] fn is_codegened_item: IsCodegenedItem(DefId) -> bool,\n         [] fn codegen_unit: CodegenUnit(InternedString) -> Arc<CodegenUnit<'tcx>>,\n-        [] fn compile_codegen_unit: CompileCodegenUnit(InternedString) -> Stats,\n     },\n \n     Other {"}, {"sha": "b711502b14b7fb1af4222d0859fbf82a03e75d06", "filename": "src/librustc_codegen_llvm/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2FCargo.toml?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -14,6 +14,7 @@ cc = \"1.0.1\"\n num_cpus = \"1.0\"\n rustc-demangle = \"0.1.4\"\n rustc_llvm = { path = \"../librustc_llvm\" }\n+memmap = \"0.6\"\n \n [features]\n # This is used to convince Cargo to separately cache builds of `rustc_codegen_llvm`"}, {"sha": "c1dda02264ed16749ce002324fa8b1ca8f1cec70", "filename": "src/librustc_codegen_llvm/back/lto.rs", "status": "modified", "additions": 181, "deletions": 29, "changes": 210, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -11,21 +11,25 @@\n use back::bytecode::{DecodedBytecode, RLIB_BYTECODE_EXTENSION};\n use back::symbol_export;\n use back::write::{ModuleConfig, with_llvm_pmb, CodegenContext};\n-use back::write::{self, DiagnosticHandlers};\n+use back::write::{self, DiagnosticHandlers, pre_lto_bitcode_filename};\n use errors::{FatalError, Handler};\n use llvm::archive_ro::ArchiveRO;\n use llvm::{True, False};\n use llvm;\n+use memmap;\n+use rustc::dep_graph::WorkProduct;\n use rustc::hir::def_id::LOCAL_CRATE;\n use rustc::middle::exported_symbols::SymbolExportLevel;\n use rustc::session::config::{self, Lto};\n use rustc::util::common::time_ext;\n+use rustc_data_structures::fx::FxHashMap;\n use time_graph::Timeline;\n-use {ModuleCodegen, ModuleLlvm, ModuleKind, ModuleSource};\n+use {ModuleCodegen, ModuleLlvm, ModuleKind};\n \n use libc;\n \n-use std::ffi::CString;\n+use std::ffi::{CStr, CString};\n+use std::fs::{self, File};\n use std::ptr;\n use std::slice;\n use std::sync::Arc;\n@@ -75,8 +79,8 @@ impl LtoModuleCodegen {\n                 let module = module.take().unwrap();\n                 {\n                     let config = cgcx.config(module.kind);\n-                    let llmod = module.llvm().unwrap().llmod();\n-                    let tm = &*module.llvm().unwrap().tm;\n+                    let llmod = module.module_llvm.llmod();\n+                    let tm = &*module.module_llvm.tm;\n                     run_pass_manager(cgcx, tm, llmod, config, false);\n                     timeline.record(\"fat-done\");\n                 }\n@@ -97,10 +101,16 @@ impl LtoModuleCodegen {\n     }\n }\n \n+/// Performs LTO, which in the case of full LTO means merging all modules into\n+/// a single one and returning it for further optimizing. For ThinLTO, it will\n+/// do the global analysis necessary and return two lists, one of the modules\n+/// the need optimization and another for modules that can simply be copied over\n+/// from the incr. comp. cache.\n pub(crate) fn run(cgcx: &CodegenContext,\n                   modules: Vec<ModuleCodegen>,\n+                  cached_modules: Vec<(SerializedModule, WorkProduct)>,\n                   timeline: &mut Timeline)\n-    -> Result<Vec<LtoModuleCodegen>, FatalError>\n+    -> Result<(Vec<LtoModuleCodegen>, Vec<WorkProduct>), FatalError>\n {\n     let diag_handler = cgcx.create_diag_handler();\n     let export_threshold = match cgcx.lto {\n@@ -187,19 +197,34 @@ pub(crate) fn run(cgcx: &CodegenContext,\n         }\n     }\n \n-    let arr = symbol_white_list.iter().map(|c| c.as_ptr()).collect::<Vec<_>>();\n+    let symbol_white_list = symbol_white_list.iter()\n+                                             .map(|c| c.as_ptr())\n+                                             .collect::<Vec<_>>();\n     match cgcx.lto {\n         Lto::Yes | // `-C lto` == fat LTO by default\n         Lto::Fat => {\n-            fat_lto(cgcx, &diag_handler, modules, upstream_modules, &arr, timeline)\n+            assert!(cached_modules.is_empty());\n+            let opt_jobs = fat_lto(cgcx,\n+                                  &diag_handler,\n+                                  modules,\n+                                  upstream_modules,\n+                                  &symbol_white_list,\n+                                  timeline);\n+            opt_jobs.map(|opt_jobs| (opt_jobs, vec![]))\n         }\n         Lto::Thin |\n         Lto::ThinLocal => {\n             if cgcx.opts.debugging_opts.cross_lang_lto.enabled() {\n                 unreachable!(\"We should never reach this case if the LTO step \\\n                               is deferred to the linker\");\n             }\n-            thin_lto(&diag_handler, modules, upstream_modules, &arr, timeline)\n+            thin_lto(cgcx,\n+                     &diag_handler,\n+                     modules,\n+                     upstream_modules,\n+                     cached_modules,\n+                     &symbol_white_list,\n+                     timeline)\n         }\n         Lto::No => unreachable!(),\n     }\n@@ -229,7 +254,7 @@ fn fat_lto(cgcx: &CodegenContext,\n         .filter(|&(_, module)| module.kind == ModuleKind::Regular)\n         .map(|(i, module)| {\n             let cost = unsafe {\n-                llvm::LLVMRustModuleCost(module.llvm().unwrap().llmod())\n+                llvm::LLVMRustModuleCost(module.module_llvm.llmod())\n             };\n             (cost, i)\n         })\n@@ -239,7 +264,7 @@ fn fat_lto(cgcx: &CodegenContext,\n     let mut serialized_bitcode = Vec::new();\n     {\n         let (llcx, llmod) = {\n-            let llvm = module.llvm().expect(\"can't lto pre-codegened modules\");\n+            let llvm = &module.module_llvm;\n             (&llvm.llcx, llvm.llmod())\n         };\n         info!(\"using {:?} as a base module\", module.name);\n@@ -255,8 +280,7 @@ fn fat_lto(cgcx: &CodegenContext,\n         // way we know of to do that is to serialize them to a string and them parse\n         // them later. Not great but hey, that's why it's \"fat\" LTO, right?\n         for module in modules {\n-            let llvm = module.llvm().expect(\"can't lto pre-codegened modules\");\n-            let buffer = ModuleBuffer::new(llvm.llmod());\n+            let buffer = ModuleBuffer::new(module.module_llvm.llmod());\n             let llmod_id = CString::new(&module.name[..]).unwrap();\n             serialized_modules.push((SerializedModule::Local(buffer), llmod_id));\n         }\n@@ -362,16 +386,23 @@ impl Drop for Linker<'a> {\n /// calculating the *index* for ThinLTO. This index will then be shared amongst\n /// all of the `LtoModuleCodegen` units returned below and destroyed once\n /// they all go out of scope.\n-fn thin_lto(diag_handler: &Handler,\n+fn thin_lto(cgcx: &CodegenContext,\n+            diag_handler: &Handler,\n             modules: Vec<ModuleCodegen>,\n             serialized_modules: Vec<(SerializedModule, CString)>,\n+            cached_modules: Vec<(SerializedModule, WorkProduct)>,\n             symbol_white_list: &[*const libc::c_char],\n             timeline: &mut Timeline)\n-    -> Result<Vec<LtoModuleCodegen>, FatalError>\n+    -> Result<(Vec<LtoModuleCodegen>, Vec<WorkProduct>), FatalError>\n {\n     unsafe {\n         info!(\"going for that thin, thin LTO\");\n \n+        let green_modules: FxHashMap<_, _> = cached_modules\n+            .iter()\n+            .map(|&(_, ref wp)| (wp.cgu_name.clone(), wp.clone()))\n+            .collect();\n+\n         let mut thin_buffers = Vec::new();\n         let mut module_names = Vec::new();\n         let mut thin_modules = Vec::new();\n@@ -385,9 +416,24 @@ fn thin_lto(diag_handler: &Handler,\n         //        analysis!\n         for (i, module) in modules.iter().enumerate() {\n             info!(\"local module: {} - {}\", i, module.name);\n-            let llvm = module.llvm().expect(\"can't lto precodegened module\");\n             let name = CString::new(module.name.clone()).unwrap();\n-            let buffer = ThinBuffer::new(llvm.llmod());\n+            let buffer = ThinBuffer::new(module.module_llvm.llmod());\n+\n+            // We emit the module after having serialized it into a ThinBuffer\n+            // because only then it will contain the ThinLTO module summary.\n+            if let Some(ref incr_comp_session_dir) = cgcx.incr_comp_session_dir {\n+                if cgcx.config(module.kind).emit_pre_thin_lto_bc {\n+                    let path = incr_comp_session_dir\n+                        .join(pre_lto_bitcode_filename(&module.name));\n+\n+                    fs::write(&path, buffer.data()).unwrap_or_else(|e| {\n+                        panic!(\"Error writing pre-lto-bitcode file `{}`: {}\",\n+                               path.display(),\n+                               e);\n+                    });\n+                }\n+            }\n+\n             thin_modules.push(llvm::ThinLTOModule {\n                 identifier: name.as_ptr(),\n                 data: buffer.data().as_ptr(),\n@@ -415,8 +461,13 @@ fn thin_lto(diag_handler: &Handler,\n         //        looking at upstream modules entirely sometimes (the contents,\n         //        we must always unconditionally look at the index).\n         let mut serialized = Vec::new();\n-        for (module, name) in serialized_modules {\n-            info!(\"foreign module {:?}\", name);\n+\n+        let cached_modules = cached_modules.into_iter().map(|(sm, wp)| {\n+            (sm, CString::new(wp.cgu_name).unwrap())\n+        });\n+\n+        for (module, name) in serialized_modules.into_iter().chain(cached_modules) {\n+            info!(\"upstream or cached module {:?}\", name);\n             thin_modules.push(llvm::ThinLTOModule {\n                 identifier: name.as_ptr(),\n                 data: module.data().as_ptr(),\n@@ -426,6 +477,9 @@ fn thin_lto(diag_handler: &Handler,\n             module_names.push(name);\n         }\n \n+        // Sanity check\n+        assert_eq!(thin_modules.len(), module_names.len());\n+\n         // Delegate to the C++ bindings to create some data here. Once this is a\n         // tried-and-true interface we may wish to try to upstream some of this\n         // to LLVM itself, right now we reimplement a lot of what they do\n@@ -439,10 +493,22 @@ fn thin_lto(diag_handler: &Handler,\n             write::llvm_err(&diag_handler, \"failed to prepare thin LTO context\".to_string())\n         })?;\n \n-        let data = ThinData(data);\n         info!(\"thin LTO data created\");\n         timeline.record(\"data\");\n \n+        let import_map = if cgcx.incr_comp_session_dir.is_some() {\n+            ThinLTOImports::from_thin_lto_data(data)\n+        } else {\n+            // If we don't compile incrementally, we don't need to load the\n+            // import data from LLVM.\n+            assert!(green_modules.is_empty());\n+            ThinLTOImports::new()\n+        };\n+        info!(\"thin LTO import map loaded\");\n+        timeline.record(\"import-map-loaded\");\n+\n+        let data = ThinData(data);\n+\n         // Throw our data in an `Arc` as we'll be sharing it across threads. We\n         // also put all memory referenced by the C++ data (buffers, ids, etc)\n         // into the arc as well. After this we'll create a thin module\n@@ -453,12 +519,38 @@ fn thin_lto(diag_handler: &Handler,\n             serialized_modules: serialized,\n             module_names,\n         });\n-        Ok((0..shared.module_names.len()).map(|i| {\n-            LtoModuleCodegen::Thin(ThinModule {\n+\n+        let mut copy_jobs = vec![];\n+        let mut opt_jobs = vec![];\n+\n+        info!(\"checking which modules can be-reused and which have to be re-optimized.\");\n+        for (module_index, module_name) in shared.module_names.iter().enumerate() {\n+            let module_name = module_name_to_str(module_name);\n+\n+            // If the module hasn't changed and none of the modules it imports\n+            // from has changed, we can re-use the post-ThinLTO version of the\n+            // module.\n+            if green_modules.contains_key(module_name) {\n+                let imports_all_green = import_map.modules_imported_by(module_name)\n+                    .iter()\n+                    .all(|imported_module| green_modules.contains_key(imported_module));\n+\n+                if imports_all_green {\n+                    let work_product = green_modules[module_name].clone();\n+                    copy_jobs.push(work_product);\n+                    info!(\" - {}: re-used\", module_name);\n+                    continue\n+                }\n+            }\n+\n+            info!(\" - {}: re-compiled\", module_name);\n+            opt_jobs.push(LtoModuleCodegen::Thin(ThinModule {\n                 shared: shared.clone(),\n-                idx: i,\n-            })\n-        }).collect())\n+                idx: module_index,\n+            }));\n+        }\n+\n+        Ok((opt_jobs, copy_jobs))\n     }\n }\n \n@@ -527,13 +619,15 @@ fn run_pass_manager(cgcx: &CodegenContext,\n pub enum SerializedModule {\n     Local(ModuleBuffer),\n     FromRlib(Vec<u8>),\n+    FromUncompressedFile(memmap::Mmap, File),\n }\n \n impl SerializedModule {\n     fn data(&self) -> &[u8] {\n         match *self {\n             SerializedModule::Local(ref m) => m.data(),\n             SerializedModule::FromRlib(ref m) => m,\n+            SerializedModule::FromUncompressedFile(ref m, _) => m,\n         }\n     }\n }\n@@ -663,16 +757,16 @@ impl ThinModule {\n             write::llvm_err(&diag_handler, msg)\n         })? as *const _;\n         let module = ModuleCodegen {\n-            source: ModuleSource::Codegened(ModuleLlvm {\n+            module_llvm: ModuleLlvm {\n                 llmod_raw,\n                 llcx,\n                 tm,\n-            }),\n+            },\n             name: self.name().to_string(),\n             kind: ModuleKind::Regular,\n         };\n         {\n-            let llmod = module.llvm().unwrap().llmod();\n+            let llmod = module.module_llvm.llmod();\n             cgcx.save_temp_bitcode(&module, \"thin-lto-input\");\n \n             // Before we do much else find the \"main\" `DICompileUnit` that we'll be\n@@ -768,11 +862,69 @@ impl ThinModule {\n             // little differently.\n             info!(\"running thin lto passes over {}\", module.name);\n             let config = cgcx.config(module.kind);\n-            run_pass_manager(cgcx, module.llvm().unwrap().tm, llmod, config, true);\n+            run_pass_manager(cgcx, module.module_llvm.tm, llmod, config, true);\n             cgcx.save_temp_bitcode(&module, \"thin-lto-after-pm\");\n             timeline.record(\"thin-done\");\n         }\n \n         Ok(module)\n     }\n }\n+\n+#[derive(Debug)]\n+pub struct ThinLTOImports {\n+    // key = llvm name of importing module, value = list of modules it imports from\n+    imports: FxHashMap<String, Vec<String>>,\n+}\n+\n+impl ThinLTOImports {\n+    fn new() -> ThinLTOImports {\n+        ThinLTOImports {\n+            imports: FxHashMap(),\n+        }\n+    }\n+\n+    fn modules_imported_by(&self, llvm_module_name: &str) -> &[String] {\n+        self.imports.get(llvm_module_name).map(|v| &v[..]).unwrap_or(&[])\n+    }\n+\n+    /// Load the ThinLTO import map from ThinLTOData.\n+    unsafe fn from_thin_lto_data(data: *const llvm::ThinLTOData) -> ThinLTOImports {\n+        unsafe extern \"C\" fn imported_module_callback(payload: *mut libc::c_void,\n+                                                      importing_module_name: *const libc::c_char,\n+                                                      imported_module_name: *const libc::c_char) {\n+            let map = &mut* (payload as *mut ThinLTOImports);\n+            let importing_module_name = CStr::from_ptr(importing_module_name);\n+            let importing_module_name = module_name_to_str(&importing_module_name);\n+            let imported_module_name = CStr::from_ptr(imported_module_name);\n+            let imported_module_name = module_name_to_str(&imported_module_name);\n+\n+            if !map.imports.contains_key(importing_module_name) {\n+                map.imports.insert(importing_module_name.to_owned(), vec![]);\n+            }\n+\n+            map.imports\n+               .get_mut(importing_module_name)\n+               .unwrap()\n+               .push(imported_module_name.to_owned());\n+        }\n+        let mut map = ThinLTOImports {\n+            imports: FxHashMap(),\n+        };\n+        llvm::LLVMRustGetThinLTOModuleImports(data,\n+                                              imported_module_callback,\n+                                              &mut map as *mut _ as *mut libc::c_void);\n+        map\n+    }\n+}\n+\n+fn module_name_to_str(c_str: &CStr) -> &str {\n+    match c_str.to_str() {\n+        Ok(s) => s,\n+        Err(e) => {\n+            bug!(\"Encountered non-utf8 LLVM module name `{}`: {}\",\n+                c_str.to_string_lossy(),\n+                e)\n+        }\n+    }\n+}"}, {"sha": "1c0f89193b20909e8773c6e52d37c732c7c14d9a", "filename": "src/librustc_codegen_llvm/back/write.rs", "status": "modified", "additions": 277, "deletions": 163, "changes": 440, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -10,14 +10,16 @@\n \n use attributes;\n use back::bytecode::{self, RLIB_BYTECODE_EXTENSION};\n-use back::lto::{self, ModuleBuffer, ThinBuffer};\n+use back::lto::{self, ModuleBuffer, ThinBuffer, SerializedModule};\n use back::link::{self, get_linker, remove};\n use back::command::Command;\n use back::linker::LinkerInfo;\n use back::symbol_export::ExportedSymbols;\n use base;\n use consts;\n-use rustc_incremental::{copy_cgu_workproducts_to_incr_comp_cache_dir, in_incr_comp_dir};\n+use memmap;\n+use rustc_incremental::{copy_cgu_workproducts_to_incr_comp_cache_dir,\n+                        in_incr_comp_dir, in_incr_comp_dir_sess};\n use rustc::dep_graph::{WorkProduct, WorkProductId, WorkProductFileKind};\n use rustc::middle::cstore::EncodedMetadata;\n use rustc::session::config::{self, OutputFilenames, OutputType, Passes, Sanitizer, Lto};\n@@ -26,7 +28,8 @@ use rustc::util::nodemap::FxHashMap;\n use time_graph::{self, TimeGraph, Timeline};\n use llvm::{self, DiagnosticInfo, PassManager, SMDiagnostic};\n use llvm_util;\n-use {CodegenResults, ModuleSource, ModuleCodegen, CompiledModule, ModuleKind};\n+use {CodegenResults, ModuleCodegen, CompiledModule, ModuleKind, // ModuleLlvm,\n+     CachedModuleCodegen};\n use CrateInfo;\n use rustc::hir::def_id::{CrateNum, LOCAL_CRATE};\n use rustc::ty::TyCtxt;\n@@ -84,6 +87,8 @@ pub const TLS_MODEL_ARGS : [(&'static str, llvm::ThreadLocalMode); 4] = [\n     (\"local-exec\", llvm::ThreadLocalMode::LocalExec),\n ];\n \n+const PRE_THIN_LTO_BC_EXT: &str = \"pre-thin-lto.bc\";\n+\n pub fn llvm_err(handler: &errors::Handler, msg: String) -> FatalError {\n     match llvm::last_error() {\n         Some(err) => handler.fatal(&format!(\"{}: {}\", msg, err)),\n@@ -223,6 +228,7 @@ pub struct ModuleConfig {\n     pgo_use: String,\n \n     // Flags indicating which outputs to produce.\n+    pub emit_pre_thin_lto_bc: bool,\n     emit_no_opt_bc: bool,\n     emit_bc: bool,\n     emit_bc_compressed: bool,\n@@ -260,6 +266,7 @@ impl ModuleConfig {\n             pgo_use: String::new(),\n \n             emit_no_opt_bc: false,\n+            emit_pre_thin_lto_bc: false,\n             emit_bc: false,\n             emit_bc_compressed: false,\n             emit_lto_bc: false,\n@@ -392,7 +399,7 @@ impl CodegenContext {\n             let cgu = Some(&module.name[..]);\n             let path = self.output_filenames.temp_path_ext(&ext, cgu);\n             let cstr = path2cstr(&path);\n-            let llmod = module.llvm().unwrap().llmod();\n+            let llmod = module.module_llvm.llmod();\n             llvm::LLVMWriteBitcodeToFile(llmod, cstr.as_ptr());\n         }\n     }\n@@ -495,13 +502,9 @@ unsafe fn optimize(cgcx: &CodegenContext,\n                    timeline: &mut Timeline)\n     -> Result<(), FatalError>\n {\n-    let (llmod, llcx, tm) = match module.source {\n-        ModuleSource::Codegened(ref llvm) => (llvm.llmod(), &*llvm.llcx, &*llvm.tm),\n-        ModuleSource::Preexisting(_) => {\n-            bug!(\"optimize_and_codegen: called with ModuleSource::Preexisting\")\n-        }\n-    };\n-\n+    let llmod = module.module_llvm.llmod();\n+    let llcx = &*module.module_llvm.llcx;\n+    let tm = &*module.module_llvm.tm;\n     let _handlers = DiagnosticHandlers::new(cgcx, diag_handler, llcx);\n \n     let module_name = module.name.clone();\n@@ -627,21 +630,31 @@ unsafe fn optimize(cgcx: &CodegenContext,\n }\n \n fn generate_lto_work(cgcx: &CodegenContext,\n-                     modules: Vec<ModuleCodegen>)\n+                     modules: Vec<ModuleCodegen>,\n+                     import_only_modules: Vec<(SerializedModule, WorkProduct)>)\n     -> Vec<(WorkItem, u64)>\n {\n     let mut timeline = cgcx.time_graph.as_ref().map(|tg| {\n         tg.start(CODEGEN_WORKER_TIMELINE,\n                  CODEGEN_WORK_PACKAGE_KIND,\n                  \"generate lto\")\n     }).unwrap_or(Timeline::noop());\n-    let lto_modules = lto::run(cgcx, modules, &mut timeline)\n+    let (lto_modules, copy_jobs) = lto::run(cgcx, modules, import_only_modules, &mut timeline)\n         .unwrap_or_else(|e| e.raise());\n \n-    lto_modules.into_iter().map(|module| {\n+    let lto_modules = lto_modules.into_iter().map(|module| {\n         let cost = module.cost();\n         (WorkItem::LTO(module), cost)\n-    }).collect()\n+    });\n+\n+    let copy_jobs = copy_jobs.into_iter().map(|wp| {\n+        (WorkItem::CopyPostLtoArtifacts(CachedModuleCodegen {\n+            name: wp.cgu_name.clone(),\n+            source: wp,\n+        }), 0)\n+    });\n+\n+    lto_modules.chain(copy_jobs).collect()\n }\n \n unsafe fn codegen(cgcx: &CodegenContext,\n@@ -653,12 +666,9 @@ unsafe fn codegen(cgcx: &CodegenContext,\n {\n     timeline.record(\"codegen\");\n     {\n-        let (llmod, llcx, tm) = match module.source {\n-            ModuleSource::Codegened(ref llvm) => (llvm.llmod(), &*llvm.llcx, &*llvm.tm),\n-            ModuleSource::Preexisting(_) => {\n-                bug!(\"codegen: called with ModuleSource::Preexisting\")\n-            }\n-        };\n+        let llmod = module.module_llvm.llmod();\n+        let llcx = &*module.module_llvm.llcx;\n+        let tm = &*module.module_llvm.tm;\n         let module_name = module.name.clone();\n         let module_name = Some(&module_name[..]);\n         let handlers = DiagnosticHandlers::new(cgcx, diag_handler, llcx);\n@@ -912,6 +922,20 @@ fn need_crate_bitcode_for_rlib(sess: &Session) -> bool {\n     sess.opts.output_types.contains_key(&OutputType::Exe)\n }\n \n+fn need_pre_thin_lto_bitcode_for_incr_comp(sess: &Session) -> bool {\n+    if sess.opts.incremental.is_none() {\n+        return false\n+    }\n+\n+    match sess.lto() {\n+        Lto::Yes |\n+        Lto::Fat |\n+        Lto::No => false,\n+        Lto::Thin |\n+        Lto::ThinLocal => true,\n+    }\n+}\n+\n pub fn start_async_codegen(tcx: TyCtxt,\n                                time_graph: Option<TimeGraph>,\n                                metadata: EncodedMetadata,\n@@ -970,6 +994,7 @@ pub fn start_async_codegen(tcx: TyCtxt,\n     // Save all versions of the bytecode if we're saving our temporaries.\n     if sess.opts.cg.save_temps {\n         modules_config.emit_no_opt_bc = true;\n+        modules_config.emit_pre_thin_lto_bc = true;\n         modules_config.emit_bc = true;\n         modules_config.emit_lto_bc = true;\n         metadata_config.emit_bc = true;\n@@ -984,6 +1009,9 @@ pub fn start_async_codegen(tcx: TyCtxt,\n         allocator_config.emit_bc_compressed = true;\n     }\n \n+    modules_config.emit_pre_thin_lto_bc =\n+        need_pre_thin_lto_bitcode_for_incr_comp(sess);\n+\n     modules_config.no_integrated_as = tcx.sess.opts.cg.no_integrated_as ||\n         tcx.sess.target.target.options.no_integrated_as;\n \n@@ -1056,15 +1084,15 @@ pub fn start_async_codegen(tcx: TyCtxt,\n \n fn copy_all_cgu_workproducts_to_incr_comp_cache_dir(\n     sess: &Session,\n-    compiled_modules: &CompiledModules\n+    compiled_modules: &CompiledModules,\n ) -> FxHashMap<WorkProductId, WorkProduct> {\n     let mut work_products = FxHashMap::default();\n \n     if sess.opts.incremental.is_none() {\n         return work_products;\n     }\n \n-    for module in compiled_modules.modules.iter() {\n+    for module in compiled_modules.modules.iter().filter(|m| m.kind == ModuleKind::Regular) {\n         let mut files = vec![];\n \n         if let Some(ref path) = module.object {\n@@ -1236,28 +1264,38 @@ fn produce_final_output_artifacts(sess: &Session,\n     // These are used in linking steps and will be cleaned up afterward.\n }\n \n-pub(crate) fn dump_incremental_data(codegen_results: &CodegenResults) {\n-    println!(\"[incremental] Re-using {} out of {} modules\",\n-              codegen_results.modules.iter().filter(|m| m.pre_existing).count(),\n-              codegen_results.modules.len());\n+pub(crate) fn dump_incremental_data(_codegen_results: &CodegenResults) {\n+    // FIXME(mw): This does not work at the moment because the situation has\n+    //            become more complicated due to incremental LTO. Now a CGU\n+    //            can have more than two caching states.\n+    // println!(\"[incremental] Re-using {} out of {} modules\",\n+    //           codegen_results.modules.iter().filter(|m| m.pre_existing).count(),\n+    //           codegen_results.modules.len());\n }\n \n enum WorkItem {\n+    /// Optimize a newly codegened, totally unoptimized module.\n     Optimize(ModuleCodegen),\n+    /// Copy the post-LTO artifacts from the incremental cache to the output\n+    /// directory.\n+    CopyPostLtoArtifacts(CachedModuleCodegen),\n+    /// Perform (Thin)LTO on the given module.\n     LTO(lto::LtoModuleCodegen),\n }\n \n impl WorkItem {\n-    fn kind(&self) -> ModuleKind {\n+    fn module_kind(&self) -> ModuleKind {\n         match *self {\n             WorkItem::Optimize(ref m) => m.kind,\n+            WorkItem::CopyPostLtoArtifacts(_) |\n             WorkItem::LTO(_) => ModuleKind::Regular,\n         }\n     }\n \n     fn name(&self) -> String {\n         match *self {\n             WorkItem::Optimize(ref m) => format!(\"optimize: {}\", m.name),\n+            WorkItem::CopyPostLtoArtifacts(ref m) => format!(\"copy post LTO artifacts: {}\", m.name),\n             WorkItem::LTO(ref m) => format!(\"lto: {}\", m.name()),\n         }\n     }\n@@ -1273,141 +1311,168 @@ fn execute_work_item(cgcx: &CodegenContext,\n                      timeline: &mut Timeline)\n     -> Result<WorkItemResult, FatalError>\n {\n-    let diag_handler = cgcx.create_diag_handler();\n-    let config = cgcx.config(work_item.kind());\n-    let module = match work_item {\n-        WorkItem::Optimize(module) => module,\n-        WorkItem::LTO(mut lto) => {\n-            unsafe {\n-                let module = lto.optimize(cgcx, timeline)?;\n-                let module = codegen(cgcx, &diag_handler, module, config, timeline)?;\n-                return Ok(WorkItemResult::Compiled(module))\n-            }\n+    let module_config = cgcx.config(work_item.module_kind());\n+\n+    match work_item {\n+        WorkItem::Optimize(module) => {\n+            execute_optimize_work_item(cgcx, module, module_config, timeline)\n         }\n-    };\n-    let module_name = module.name.clone();\n+        WorkItem::CopyPostLtoArtifacts(module) => {\n+            execute_copy_from_cache_work_item(cgcx, module, module_config, timeline)\n+        }\n+        WorkItem::LTO(module) => {\n+            execute_lto_work_item(cgcx, module, module_config, timeline)\n+        }\n+    }\n+}\n \n-    let pre_existing = match module.source {\n-        ModuleSource::Codegened(_) => None,\n-        ModuleSource::Preexisting(ref wp) => Some(wp.clone()),\n-    };\n+fn execute_optimize_work_item(cgcx: &CodegenContext,\n+                              module: ModuleCodegen,\n+                              module_config: &ModuleConfig,\n+                              timeline: &mut Timeline)\n+    -> Result<WorkItemResult, FatalError>\n+{\n+    let diag_handler = cgcx.create_diag_handler();\n \n-    if let Some(wp) = pre_existing {\n-        let incr_comp_session_dir = cgcx.incr_comp_session_dir\n-                                        .as_ref()\n-                                        .unwrap();\n-        let name = &module.name;\n-        let mut object = None;\n-        let mut bytecode = None;\n-        let mut bytecode_compressed = None;\n-        for (kind, saved_file) in wp.saved_files {\n-            let obj_out = match kind {\n-                WorkProductFileKind::Object => {\n-                    let path = cgcx.output_filenames.temp_path(OutputType::Object, Some(name));\n-                    object = Some(path.clone());\n-                    path\n-                }\n-                WorkProductFileKind::Bytecode => {\n-                    let path = cgcx.output_filenames.temp_path(OutputType::Bitcode, Some(name));\n-                    bytecode = Some(path.clone());\n-                    path\n-                }\n-                WorkProductFileKind::BytecodeCompressed => {\n-                    let path = cgcx.output_filenames.temp_path(OutputType::Bitcode, Some(name))\n-                        .with_extension(RLIB_BYTECODE_EXTENSION);\n-                    bytecode_compressed = Some(path.clone());\n-                    path\n-                }\n-            };\n-            let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n-                                               &saved_file);\n-            debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n-                   module.name,\n-                   source_file,\n-                   obj_out.display());\n-            match link_or_copy(&source_file, &obj_out) {\n-                Ok(_) => { }\n-                Err(err) => {\n-                    diag_handler.err(&format!(\"unable to copy {} to {}: {}\",\n-                                              source_file.display(),\n-                                              obj_out.display(),\n-                                              err));\n-                }\n-            }\n+    unsafe {\n+        optimize(cgcx, &diag_handler, &module, module_config, timeline)?;\n+    }\n+\n+    let linker_does_lto = cgcx.opts.debugging_opts.cross_lang_lto.enabled();\n+\n+    // After we've done the initial round of optimizations we need to\n+    // decide whether to synchronously codegen this module or ship it\n+    // back to the coordinator thread for further LTO processing (which\n+    // has to wait for all the initial modules to be optimized).\n+    //\n+    // Here we dispatch based on the `cgcx.lto` and kind of module we're\n+    // codegenning...\n+    let needs_lto = match cgcx.lto {\n+        Lto::No => false,\n+\n+        // If the linker does LTO, we don't have to do it. Note that we\n+        // keep doing full LTO, if it is requested, as not to break the\n+        // assumption that the output will be a single module.\n+        Lto::Thin | Lto::ThinLocal if linker_does_lto => false,\n+\n+        // Here we've got a full crate graph LTO requested. We ignore\n+        // this, however, if the crate type is only an rlib as there's\n+        // no full crate graph to process, that'll happen later.\n+        //\n+        // This use case currently comes up primarily for targets that\n+        // require LTO so the request for LTO is always unconditionally\n+        // passed down to the backend, but we don't actually want to do\n+        // anything about it yet until we've got a final product.\n+        Lto::Yes | Lto::Fat | Lto::Thin => {\n+            cgcx.crate_types.len() != 1 ||\n+                cgcx.crate_types[0] != config::CrateType::Rlib\n         }\n-        assert_eq!(object.is_some(), config.emit_obj);\n-        assert_eq!(bytecode.is_some(), config.emit_bc);\n-        assert_eq!(bytecode_compressed.is_some(), config.emit_bc_compressed);\n-\n-        Ok(WorkItemResult::Compiled(CompiledModule {\n-            name: module_name,\n-            kind: ModuleKind::Regular,\n-            pre_existing: true,\n-            object,\n-            bytecode,\n-            bytecode_compressed,\n-        }))\n-    } else {\n-        debug!(\"llvm-optimizing {:?}\", module_name);\n \n-        unsafe {\n-            optimize(cgcx, &diag_handler, &module, config, timeline)?;\n-\n-            let linker_does_lto = cgcx.opts.debugging_opts.cross_lang_lto.enabled();\n-\n-            // After we've done the initial round of optimizations we need to\n-            // decide whether to synchronously codegen this module or ship it\n-            // back to the coordinator thread for further LTO processing (which\n-            // has to wait for all the initial modules to be optimized).\n-            //\n-            // Here we dispatch based on the `cgcx.lto` and kind of module we're\n-            // codegenning...\n-            let needs_lto = match cgcx.lto {\n-                Lto::No => false,\n-\n-                // If the linker does LTO, we don't have to do it. Note that we\n-                // keep doing full LTO, if it is requested, as not to break the\n-                // assumption that the output will be a single module.\n-                Lto::Thin | Lto::ThinLocal if linker_does_lto => false,\n-\n-                // Here we've got a full crate graph LTO requested. We ignore\n-                // this, however, if the crate type is only an rlib as there's\n-                // no full crate graph to process, that'll happen later.\n-                //\n-                // This use case currently comes up primarily for targets that\n-                // require LTO so the request for LTO is always unconditionally\n-                // passed down to the backend, but we don't actually want to do\n-                // anything about it yet until we've got a final product.\n-                Lto::Yes | Lto::Fat | Lto::Thin => {\n-                    cgcx.crate_types.len() != 1 ||\n-                        cgcx.crate_types[0] != config::CrateType::Rlib\n-                }\n+        // When we're automatically doing ThinLTO for multi-codegen-unit\n+        // builds we don't actually want to LTO the allocator modules if\n+        // it shows up. This is due to various linker shenanigans that\n+        // we'll encounter later.\n+        //\n+        // Additionally here's where we also factor in the current LLVM\n+        // version. If it doesn't support ThinLTO we skip this.\n+        Lto::ThinLocal => {\n+            module.kind != ModuleKind::Allocator &&\n+                unsafe { llvm::LLVMRustThinLTOAvailable() }\n+        }\n+    };\n \n-                // When we're automatically doing ThinLTO for multi-codegen-unit\n-                // builds we don't actually want to LTO the allocator modules if\n-                // it shows up. This is due to various linker shenanigans that\n-                // we'll encounter later.\n-                //\n-                // Additionally here's where we also factor in the current LLVM\n-                // version. If it doesn't support ThinLTO we skip this.\n-                Lto::ThinLocal => {\n-                    module.kind != ModuleKind::Allocator &&\n-                        llvm::LLVMRustThinLTOAvailable()\n-                }\n-            };\n+    // Metadata modules never participate in LTO regardless of the lto\n+    // settings.\n+    let needs_lto = needs_lto && module.kind != ModuleKind::Metadata;\n \n-            // Metadata modules never participate in LTO regardless of the lto\n-            // settings.\n-            let needs_lto = needs_lto && module.kind != ModuleKind::Metadata;\n+    if needs_lto {\n+        Ok(WorkItemResult::NeedsLTO(module))\n+    } else {\n+        let module = unsafe {\n+            codegen(cgcx, &diag_handler, module, module_config, timeline)?\n+        };\n+        Ok(WorkItemResult::Compiled(module))\n+    }\n+}\n \n-            if needs_lto {\n-                Ok(WorkItemResult::NeedsLTO(module))\n-            } else {\n-                let module = codegen(cgcx, &diag_handler, module, config, timeline)?;\n-                Ok(WorkItemResult::Compiled(module))\n+fn execute_copy_from_cache_work_item(cgcx: &CodegenContext,\n+                                     module: CachedModuleCodegen,\n+                                     module_config: &ModuleConfig,\n+                                     _: &mut Timeline)\n+    -> Result<WorkItemResult, FatalError>\n+{\n+    let incr_comp_session_dir = cgcx.incr_comp_session_dir\n+                                    .as_ref()\n+                                    .unwrap();\n+    let mut object = None;\n+    let mut bytecode = None;\n+    let mut bytecode_compressed = None;\n+    for (kind, saved_file) in &module.source.saved_files {\n+        let obj_out = match kind {\n+            WorkProductFileKind::Object => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Object,\n+                                                           Some(&module.name));\n+                object = Some(path.clone());\n+                path\n+            }\n+            WorkProductFileKind::Bytecode => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Bitcode,\n+                                                           Some(&module.name));\n+                bytecode = Some(path.clone());\n+                path\n+            }\n+            WorkProductFileKind::BytecodeCompressed => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Bitcode,\n+                                                           Some(&module.name))\n+                    .with_extension(RLIB_BYTECODE_EXTENSION);\n+                bytecode_compressed = Some(path.clone());\n+                path\n+            }\n+        };\n+        let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n+                                           &saved_file);\n+        debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n+               module.name,\n+               source_file,\n+               obj_out.display());\n+        match link_or_copy(&source_file, &obj_out) {\n+            Ok(_) => { }\n+            Err(err) => {\n+                let diag_handler = cgcx.create_diag_handler();\n+                diag_handler.err(&format!(\"unable to copy {} to {}: {}\",\n+                                          source_file.display(),\n+                                          obj_out.display(),\n+                                          err));\n             }\n         }\n     }\n+\n+    assert_eq!(object.is_some(), module_config.emit_obj);\n+    assert_eq!(bytecode.is_some(), module_config.emit_bc);\n+    assert_eq!(bytecode_compressed.is_some(), module_config.emit_bc_compressed);\n+\n+    Ok(WorkItemResult::Compiled(CompiledModule {\n+        name: module.name,\n+        kind: ModuleKind::Regular,\n+        object,\n+        bytecode,\n+        bytecode_compressed,\n+    }))\n+}\n+\n+fn execute_lto_work_item(cgcx: &CodegenContext,\n+                         mut module: lto::LtoModuleCodegen,\n+                         module_config: &ModuleConfig,\n+                         timeline: &mut Timeline)\n+    -> Result<WorkItemResult, FatalError>\n+{\n+    let diag_handler = cgcx.create_diag_handler();\n+\n+    unsafe {\n+        let module = module.optimize(cgcx, timeline)?;\n+        let module = codegen(cgcx, &diag_handler, module, module_config, timeline)?;\n+        Ok(WorkItemResult::Compiled(module))\n+    }\n }\n \n enum Message {\n@@ -1424,6 +1489,10 @@ enum Message {\n         llvm_work_item: WorkItem,\n         cost: u64,\n     },\n+    AddImportOnlyModule {\n+        module_data: SerializedModule,\n+        work_product: WorkProduct,\n+    },\n     CodegenComplete,\n     CodegenItem,\n }\n@@ -1703,6 +1772,7 @@ fn start_executing_work(tcx: TyCtxt,\n         let mut compiled_metadata_module = None;\n         let mut compiled_allocator_module = None;\n         let mut needs_lto = Vec::new();\n+        let mut lto_import_only_modules = Vec::new();\n         let mut started_lto = false;\n \n         // This flag tracks whether all items have gone through codegens\n@@ -1726,6 +1796,7 @@ fn start_executing_work(tcx: TyCtxt,\n               work_items.len() > 0 ||\n               running > 0 ||\n               needs_lto.len() > 0 ||\n+              lto_import_only_modules.len() > 0 ||\n               main_thread_worker_state != MainThreadWorkerState::Idle {\n \n             // While there are still CGUs to be codegened, the coordinator has\n@@ -1749,7 +1820,7 @@ fn start_executing_work(tcx: TyCtxt,\n                             worker: get_worker_id(&mut free_worker_ids),\n                             .. cgcx.clone()\n                         };\n-                        maybe_start_llvm_timer(cgcx.config(item.kind()),\n+                        maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n                                                &mut llvm_start_time);\n                         main_thread_worker_state = MainThreadWorkerState::LLVMing;\n                         spawn_work(cgcx, item);\n@@ -1765,10 +1836,12 @@ fn start_executing_work(tcx: TyCtxt,\n                    running == 0 &&\n                    main_thread_worker_state == MainThreadWorkerState::Idle {\n                     assert!(!started_lto);\n-                    assert!(needs_lto.len() > 0);\n+                    assert!(needs_lto.len() + lto_import_only_modules.len() > 0);\n                     started_lto = true;\n                     let modules = mem::replace(&mut needs_lto, Vec::new());\n-                    for (work, cost) in generate_lto_work(&cgcx, modules) {\n+                    let import_only_modules =\n+                        mem::replace(&mut lto_import_only_modules, Vec::new());\n+                    for (work, cost) in generate_lto_work(&cgcx, modules, import_only_modules) {\n                         let insertion_index = work_items\n                             .binary_search_by_key(&cost, |&(_, cost)| cost)\n                             .unwrap_or_else(|e| e);\n@@ -1789,7 +1862,7 @@ fn start_executing_work(tcx: TyCtxt,\n                                 worker: get_worker_id(&mut free_worker_ids),\n                                 .. cgcx.clone()\n                             };\n-                            maybe_start_llvm_timer(cgcx.config(item.kind()),\n+                            maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n                                                    &mut llvm_start_time);\n                             main_thread_worker_state = MainThreadWorkerState::LLVMing;\n                             spawn_work(cgcx, item);\n@@ -1820,7 +1893,7 @@ fn start_executing_work(tcx: TyCtxt,\n             while work_items.len() > 0 && running < tokens.len() {\n                 let (item, _) = work_items.pop().unwrap();\n \n-                maybe_start_llvm_timer(cgcx.config(item.kind()),\n+                maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n                                        &mut llvm_start_time);\n \n                 let cgcx = CodegenContext {\n@@ -1932,10 +2005,17 @@ fn start_executing_work(tcx: TyCtxt,\n                     } else {\n                         running -= 1;\n                     }\n-\n                     free_worker_ids.push(worker_id);\n                     needs_lto.push(result);\n                 }\n+                Message::AddImportOnlyModule { module_data, work_product } => {\n+                    assert!(!started_lto);\n+                    assert!(!codegen_done);\n+                    assert_eq!(main_thread_worker_state,\n+                               MainThreadWorkerState::Codegenning);\n+                    lto_import_only_modules.push((module_data, work_product));\n+                    main_thread_worker_state = MainThreadWorkerState::Idle;\n+                }\n                 Message::Done { result: Err(()), worker_id: _ } => {\n                     shared_emitter.fatal(\"aborting due to worker thread failure\");\n                     // Exit the coordinator thread\n@@ -2308,9 +2388,9 @@ impl OngoingCodegen {\n             time_graph.dump(&format!(\"{}-timings\", self.crate_name));\n         }\n \n-        let work_products = copy_all_cgu_workproducts_to_incr_comp_cache_dir(sess,\n-                                                                             &compiled_modules);\n-\n+        let work_products =\n+            copy_all_cgu_workproducts_to_incr_comp_cache_dir(sess,\n+                                                             &compiled_modules);\n         produce_final_output_artifacts(sess,\n                                        &compiled_modules,\n                                        &self.output_filenames);\n@@ -2371,15 +2451,49 @@ impl OngoingCodegen {\n }\n \n pub(crate) fn submit_codegened_module_to_llvm(tcx: TyCtxt,\n-                                               module: ModuleCodegen,\n-                                               cost: u64) {\n+                                              module: ModuleCodegen,\n+                                              cost: u64) {\n     let llvm_work_item = WorkItem::Optimize(module);\n     drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone {\n         llvm_work_item,\n         cost,\n     })));\n }\n \n+pub(crate) fn submit_post_lto_module_to_llvm(tcx: TyCtxt,\n+                                             module: CachedModuleCodegen) {\n+    let llvm_work_item = WorkItem::CopyPostLtoArtifacts(module);\n+    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone {\n+        llvm_work_item,\n+        cost: 0,\n+    })));\n+}\n+\n+pub(crate) fn submit_pre_lto_module_to_llvm(tcx: TyCtxt,\n+                                            module: CachedModuleCodegen) {\n+    let filename = pre_lto_bitcode_filename(&module.name);\n+    let bc_path = in_incr_comp_dir_sess(tcx.sess, &filename);\n+    let file = fs::File::open(&bc_path).unwrap_or_else(|e| {\n+        panic!(\"failed to open bitcode file `{}`: {}\", bc_path.display(), e)\n+    });\n+\n+    let mmap = unsafe {\n+        memmap::Mmap::map(&file).unwrap_or_else(|e| {\n+            panic!(\"failed to mmap bitcode file `{}`: {}\", bc_path.display(), e)\n+        })\n+    };\n+\n+    // Schedule the module to be loaded\n+    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::AddImportOnlyModule {\n+        module_data: SerializedModule::FromUncompressedFile(mmap, file),\n+        work_product: module.source,\n+    })));\n+}\n+\n+pub(super) fn pre_lto_bitcode_filename(module_name: &str) -> String {\n+    format!(\"{}.{}\", module_name, PRE_THIN_LTO_BC_EXT)\n+}\n+\n fn msvc_imps_needed(tcx: TyCtxt) -> bool {\n     // This should never be true (because it's not supported). If it is true,\n     // something is wrong with commandline arg validation."}, {"sha": "c1f6006e684be595bdcaabae0eb29f22c5209f40", "filename": "src/librustc_codegen_llvm/base.rs", "status": "modified", "additions": 96, "deletions": 58, "changes": 154, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fbase.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -24,9 +24,9 @@\n //!     int) and rec(x=int, y=int, z=int) will have the same llvm::Type.\n \n use super::ModuleLlvm;\n-use super::ModuleSource;\n use super::ModuleCodegen;\n use super::ModuleKind;\n+use super::CachedModuleCodegen;\n \n use abi;\n use back::write::{self, OngoingCodegen};\n@@ -40,12 +40,11 @@ use rustc::middle::cstore::{EncodedMetadata};\n use rustc::ty::{self, Ty, TyCtxt};\n use rustc::ty::layout::{self, Align, TyLayout, LayoutOf};\n use rustc::ty::query::Providers;\n-use rustc::dep_graph::{DepNode, DepConstructor};\n use rustc::middle::cstore::{self, LinkagePreference};\n use rustc::middle::exported_symbols;\n use rustc::util::common::{time, print_time_passes_entry};\n use rustc::util::profiling::ProfileCategory;\n-use rustc::session::config::{self, DebugInfo, EntryFnType};\n+use rustc::session::config::{self, DebugInfo, EntryFnType, Lto};\n use rustc::session::Session;\n use rustc_incremental;\n use allocator;\n@@ -698,6 +697,50 @@ pub fn iter_globals(llmod: &'ll llvm::Module) -> ValueIter<'ll> {\n     }\n }\n \n+#[derive(Debug)]\n+enum CguReUsable {\n+    PreLto,\n+    PostLto,\n+    No\n+}\n+\n+fn determine_cgu_reuse<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                                 cgu: &CodegenUnit<'tcx>)\n+                                 -> CguReUsable {\n+    if !tcx.dep_graph.is_fully_enabled() {\n+        return CguReUsable::No\n+    }\n+\n+    let work_product_id = &cgu.work_product_id();\n+    if tcx.dep_graph.previous_work_product(work_product_id).is_none() {\n+        // We don't have anything cached for this CGU. This can happen\n+        // if the CGU did not exist in the previous session.\n+        return CguReUsable::No\n+    }\n+\n+    // Try to mark the CGU as green. If it we can do so, it means that nothing\n+    // affecting the LLVM module has changed and we can re-use a cached version.\n+    // If we compile with any kind of LTO, this means we can re-use the bitcode\n+    // of the Pre-LTO stage (possibly also the Post-LTO version but we'll only\n+    // know that later). If we are not doing LTO, there is only one optimized\n+    // version of each module, so we re-use that.\n+    let dep_node = cgu.codegen_dep_node(tcx);\n+    assert!(!tcx.dep_graph.dep_node_exists(&dep_node),\n+        \"CompileCodegenUnit dep-node for CGU `{}` already exists before marking.\",\n+        cgu.name());\n+\n+    if tcx.dep_graph.try_mark_green(tcx, &dep_node).is_some() {\n+        // We can re-use either the pre- or the post-thinlto state\n+        if tcx.sess.lto() != Lto::No {\n+            CguReUsable::PreLto\n+        } else {\n+            CguReUsable::PostLto\n+        }\n+    } else {\n+        CguReUsable::No\n+    }\n+}\n+\n pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                              rx: mpsc::Receiver<Box<dyn Any + Send>>)\n                              -> OngoingCodegen {\n@@ -734,7 +777,7 @@ pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n     let metadata_module = ModuleCodegen {\n         name: metadata_cgu_name,\n-        source: ModuleSource::Codegened(metadata_llvm_module),\n+        module_llvm: metadata_llvm_module,\n         kind: ModuleKind::Metadata,\n     };\n \n@@ -823,7 +866,7 @@ pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n         Some(ModuleCodegen {\n             name: llmod_id,\n-            source: ModuleSource::Codegened(modules),\n+            module_llvm: modules,\n             kind: ModuleKind::Allocator,\n         })\n     } else {\n@@ -851,48 +894,40 @@ pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         ongoing_codegen.wait_for_signal_to_codegen_item();\n         ongoing_codegen.check_for_errors(tcx.sess);\n \n-        // First, if incremental compilation is enabled, we try to re-use the\n-        // codegen unit from the cache.\n-        if tcx.dep_graph.is_fully_enabled() {\n-            let cgu_id = cgu.work_product_id();\n-\n-            // Check whether there is a previous work-product we can\n-            // re-use.  Not only must the file exist, and the inputs not\n-            // be dirty, but the hash of the symbols we will generate must\n-            // be the same.\n-            if let Some(buf) = tcx.dep_graph.previous_work_product(&cgu_id) {\n-                let dep_node = &DepNode::new(tcx,\n-                    DepConstructor::CompileCodegenUnit(cgu.name().clone()));\n-\n-                // We try to mark the DepNode::CompileCodegenUnit green. If we\n-                // succeed it means that none of the dependencies has changed\n-                // and we can safely re-use.\n-                if let Some(dep_node_index) = tcx.dep_graph.try_mark_green(tcx, dep_node) {\n-                    let module = ModuleCodegen {\n-                        name: cgu.name().to_string(),\n-                        source: ModuleSource::Preexisting(buf),\n-                        kind: ModuleKind::Regular,\n-                    };\n-                    tcx.dep_graph.mark_loaded_from_cache(dep_node_index, true);\n-                    write::submit_codegened_module_to_llvm(tcx, module, 0);\n-                    // Continue to next cgu, this one is done.\n-                    continue\n-                }\n-            } else {\n-                // This can happen if files were  deleted from the cache\n-                // directory for some reason. We just re-compile then.\n+        let loaded_from_cache = match determine_cgu_reuse(tcx, &cgu) {\n+            CguReUsable::No => {\n+                let _timing_guard = time_graph.as_ref().map(|time_graph| {\n+                    time_graph.start(write::CODEGEN_WORKER_TIMELINE,\n+                                     write::CODEGEN_WORK_PACKAGE_KIND,\n+                                     &format!(\"codegen {}\", cgu.name()))\n+                });\n+                let start_time = Instant::now();\n+                let stats = compile_codegen_unit(tcx, *cgu.name());\n+                all_stats.extend(stats);\n+                total_codegen_time += start_time.elapsed();\n+                false\n             }\n-        }\n+            CguReUsable::PreLto => {\n+                write::submit_pre_lto_module_to_llvm(tcx, CachedModuleCodegen {\n+                    name: cgu.name().to_string(),\n+                    source: cgu.work_product(tcx),\n+                });\n+                true\n+            }\n+            CguReUsable::PostLto => {\n+                write::submit_post_lto_module_to_llvm(tcx, CachedModuleCodegen {\n+                    name: cgu.name().to_string(),\n+                    source: cgu.work_product(tcx),\n+                });\n+                true\n+            }\n+        };\n \n-        let _timing_guard = time_graph.as_ref().map(|time_graph| {\n-            time_graph.start(write::CODEGEN_WORKER_TIMELINE,\n-                             write::CODEGEN_WORK_PACKAGE_KIND,\n-                             &format!(\"codegen {}\", cgu.name()))\n-        });\n-        let start_time = Instant::now();\n-        all_stats.extend(tcx.compile_codegen_unit(*cgu.name()));\n-        total_codegen_time += start_time.elapsed();\n-        ongoing_codegen.check_for_errors(tcx.sess);\n+        if tcx.dep_graph.is_fully_enabled() {\n+            let dep_node = cgu.codegen_dep_node(tcx);\n+            let dep_node_index = tcx.dep_graph.dep_node_index_of(&dep_node);\n+            tcx.dep_graph.mark_loaded_from_cache(dep_node_index, loaded_from_cache);\n+        }\n     }\n \n     ongoing_codegen.codegen_finished(tcx);\n@@ -1156,11 +1191,15 @@ fn is_codegened_item(tcx: TyCtxt, id: DefId) -> bool {\n }\n \n fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                  cgu: InternedString) -> Stats {\n-    let cgu = tcx.codegen_unit(cgu);\n-\n+                                  cgu_name: InternedString)\n+                                  -> Stats {\n     let start_time = Instant::now();\n-    let (stats, module) = module_codegen(tcx, cgu);\n+\n+    let dep_node = tcx.codegen_unit(cgu_name).codegen_dep_node(tcx);\n+    let ((stats, module), _) = tcx.dep_graph.with_task(dep_node,\n+                                                       tcx,\n+                                                       cgu_name,\n+                                                       module_codegen);\n     let time_to_codegen = start_time.elapsed();\n \n     // We assume that the cost to run LLVM on a CGU is proportional to\n@@ -1169,23 +1208,23 @@ fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                time_to_codegen.subsec_nanos() as u64;\n \n     write::submit_codegened_module_to_llvm(tcx,\n-                                            module,\n-                                            cost);\n+                                           module,\n+                                           cost);\n     return stats;\n \n     fn module_codegen<'a, 'tcx>(\n         tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-        cgu: Arc<CodegenUnit<'tcx>>)\n+        cgu_name: InternedString)\n         -> (Stats, ModuleCodegen)\n     {\n-        let cgu_name = cgu.name().to_string();\n+        let cgu = tcx.codegen_unit(cgu_name);\n \n         // Instantiate monomorphizations without filling out definitions yet...\n-        let llvm_module = ModuleLlvm::new(tcx.sess, &cgu_name);\n+        let llvm_module = ModuleLlvm::new(tcx.sess, &cgu_name.as_str());\n         let stats = {\n             let cx = CodegenCx::new(tcx, cgu, &llvm_module);\n             let mono_items = cx.codegen_unit\n-                                 .items_in_deterministic_order(cx.tcx);\n+                               .items_in_deterministic_order(cx.tcx);\n             for &(mono_item, (linkage, visibility)) in &mono_items {\n                 mono_item.predefine(&cx, linkage, visibility);\n             }\n@@ -1234,8 +1273,8 @@ fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         };\n \n         (stats, ModuleCodegen {\n-            name: cgu_name,\n-            source: ModuleSource::Codegened(llvm_module),\n+            name: cgu_name.to_string(),\n+            module_llvm: llvm_module,\n             kind: ModuleKind::Regular,\n         })\n     }\n@@ -1254,7 +1293,6 @@ pub fn provide(providers: &mut Providers) {\n             .cloned()\n             .unwrap_or_else(|| panic!(\"failed to find cgu with name {:?}\", name))\n     };\n-    providers.compile_codegen_unit = compile_codegen_unit;\n \n     provide_extern(providers);\n }"}, {"sha": "dcdd8c1f6e9f99a5c2848af27fba61feaaaa8789", "filename": "src/librustc_codegen_llvm/lib.rs", "status": "modified", "additions": 13, "deletions": 29, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Flib.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -66,13 +66,13 @@ extern crate rustc_errors as errors;\n extern crate serialize;\n extern crate cc; // Used to locate MSVC\n extern crate tempfile;\n+extern crate memmap;\n \n use back::bytecode::RLIB_BYTECODE_EXTENSION;\n \n pub use llvm_util::target_features;\n-\n use std::any::Any;\n-use std::path::PathBuf;\n+use std::path::{PathBuf};\n use std::sync::mpsc;\n use rustc_data_structures::sync::Lrc;\n \n@@ -100,7 +100,7 @@ mod back {\n     mod command;\n     pub mod linker;\n     pub mod link;\n-    mod lto;\n+    pub mod lto;\n     pub mod symbol_export;\n     pub mod write;\n     mod rpath;\n@@ -273,10 +273,15 @@ struct ModuleCodegen {\n     /// as the crate name and disambiguator.\n     /// We currently generate these names via CodegenUnit::build_cgu_name().\n     name: String,\n-    source: ModuleSource,\n+    module_llvm: ModuleLlvm,\n     kind: ModuleKind,\n }\n \n+struct CachedModuleCodegen {\n+    name: String,\n+    source: WorkProduct,\n+}\n+\n #[derive(Copy, Clone, Debug, PartialEq)]\n enum ModuleKind {\n     Regular,\n@@ -285,22 +290,11 @@ enum ModuleKind {\n }\n \n impl ModuleCodegen {\n-    fn llvm(&self) -> Option<&ModuleLlvm> {\n-        match self.source {\n-            ModuleSource::Codegened(ref llvm) => Some(llvm),\n-            ModuleSource::Preexisting(_) => None,\n-        }\n-    }\n-\n     fn into_compiled_module(self,\n-                                emit_obj: bool,\n-                                emit_bc: bool,\n-                                emit_bc_compressed: bool,\n-                                outputs: &OutputFilenames) -> CompiledModule {\n-        let pre_existing = match self.source {\n-            ModuleSource::Preexisting(_) => true,\n-            ModuleSource::Codegened(_) => false,\n-        };\n+                            emit_obj: bool,\n+                            emit_bc: bool,\n+                            emit_bc_compressed: bool,\n+                            outputs: &OutputFilenames) -> CompiledModule {\n         let object = if emit_obj {\n             Some(outputs.temp_path(OutputType::Object, Some(&self.name)))\n         } else {\n@@ -321,7 +315,6 @@ impl ModuleCodegen {\n         CompiledModule {\n             name: self.name.clone(),\n             kind: self.kind,\n-            pre_existing,\n             object,\n             bytecode,\n             bytecode_compressed,\n@@ -333,20 +326,11 @@ impl ModuleCodegen {\n struct CompiledModule {\n     name: String,\n     kind: ModuleKind,\n-    pre_existing: bool,\n     object: Option<PathBuf>,\n     bytecode: Option<PathBuf>,\n     bytecode_compressed: Option<PathBuf>,\n }\n \n-enum ModuleSource {\n-    /// Copy the `.o` files or whatever from the incr. comp. directory.\n-    Preexisting(WorkProduct),\n-\n-    /// Rebuild from this LLVM module.\n-    Codegened(ModuleLlvm),\n-}\n-\n struct ModuleLlvm {\n     llcx: &'static mut llvm::Context,\n     llmod_raw: *const llvm::Module,"}, {"sha": "6c2601bf1ef1255ec229b6533da9b8290bbd55dc", "filename": "src/librustc_codegen_llvm/llvm/ffi.rs", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Fllvm%2Fffi.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_codegen_llvm%2Fllvm%2Fffi.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fllvm%2Fffi.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -363,6 +363,10 @@ extern { pub type ThinLTOData; }\n /// LLVMRustThinLTOBuffer\n extern { pub type ThinLTOBuffer; }\n \n+// LLVMRustModuleNameCallback\n+pub type ThinLTOModuleNameCallback =\n+    unsafe extern \"C\" fn(*mut c_void, *const c_char, *const c_char);\n+\n /// LLVMRustThinLTOModule\n #[repr(C)]\n pub struct ThinLTOModule {\n@@ -1622,6 +1626,11 @@ extern \"C\" {\n         Data: &ThinLTOData,\n         Module: &Module,\n     ) -> bool;\n+    pub fn LLVMRustGetThinLTOModuleImports(\n+        Data: *const ThinLTOData,\n+        ModuleNameCallback: ThinLTOModuleNameCallback,\n+        CallbackPayload: *mut c_void,\n+    );\n     pub fn LLVMRustFreeThinLTOData(Data: &'static mut ThinLTOData);\n     pub fn LLVMRustParseBitcodeForThinLTO(\n         Context: &Context,"}, {"sha": "4ffd726c1d47ce2b5aba82c21f2e403fdcc28992", "filename": "src/librustc_incremental/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_incremental%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_incremental%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Flib.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -44,6 +44,7 @@ pub use persist::copy_cgu_workproducts_to_incr_comp_cache_dir;\n pub use persist::save_dep_graph;\n pub use persist::save_work_product_index;\n pub use persist::in_incr_comp_dir;\n+pub use persist::in_incr_comp_dir_sess;\n pub use persist::prepare_session_directory;\n pub use persist::finalize_session_directory;\n pub use persist::delete_workproduct_files;"}, {"sha": "17d36ba3fa7f4bbbd2051ae78b26fcce1e62df99", "filename": "src/librustc_incremental/persist/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -23,6 +23,7 @@ mod file_format;\n pub use self::fs::finalize_session_directory;\n pub use self::fs::garbage_collect_session_directories;\n pub use self::fs::in_incr_comp_dir;\n+pub use self::fs::in_incr_comp_dir_sess;\n pub use self::fs::prepare_session_directory;\n pub use self::load::dep_graph_tcx_init;\n pub use self::load::load_dep_graph;"}, {"sha": "fd094ffc1cf4f7fd02d09f4bff3cde03224a44ab", "filename": "src/librustc_mir/monomorphize/partitioning.rs", "status": "modified", "additions": 14, "deletions": 1, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_mir%2Fmonomorphize%2Fpartitioning.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Flibrustc_mir%2Fmonomorphize%2Fpartitioning.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fmonomorphize%2Fpartitioning.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -103,7 +103,7 @@\n //! inlining, even when they are not marked #[inline].\n \n use monomorphize::collector::InliningMap;\n-use rustc::dep_graph::WorkProductId;\n+use rustc::dep_graph::{WorkProductId, WorkProduct, DepNode, DepConstructor};\n use rustc::hir::CodegenFnAttrFlags;\n use rustc::hir::def_id::{DefId, LOCAL_CRATE, CRATE_DEF_INDEX};\n use rustc::hir::map::DefPathData;\n@@ -150,6 +150,15 @@ pub trait CodegenUnitExt<'tcx> {\n         WorkProductId::from_cgu_name(&self.name().as_str())\n     }\n \n+    fn work_product(&self, tcx: TyCtxt) -> WorkProduct {\n+        let work_product_id = self.work_product_id();\n+        tcx.dep_graph\n+           .previous_work_product(&work_product_id)\n+           .unwrap_or_else(|| {\n+                panic!(\"Could not find work-product for CGU `{}`\", self.name())\n+            })\n+    }\n+\n     fn items_in_deterministic_order<'a>(&self,\n                                         tcx: TyCtxt<'a, 'tcx, 'tcx>)\n                                         -> Vec<(MonoItem<'tcx>,\n@@ -194,6 +203,10 @@ pub trait CodegenUnitExt<'tcx> {\n         items.sort_by_cached_key(|&(i, _)| item_sort_key(tcx, i));\n         items\n     }\n+\n+    fn codegen_dep_node(&self, tcx: TyCtxt<'_, 'tcx, 'tcx>) -> DepNode {\n+        DepNode::new(tcx, DepConstructor::CompileCodegenUnit(self.name().clone()))\n+    }\n }\n \n impl<'tcx> CodegenUnitExt<'tcx> for CodegenUnit<'tcx> {"}, {"sha": "5c4bb61781ed1367b99cdb91ba42275336a01dd5", "filename": "src/rustllvm/PassWrapper.cpp", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Frustllvm%2FPassWrapper.cpp", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Frustllvm%2FPassWrapper.cpp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frustllvm%2FPassWrapper.cpp?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -1123,6 +1123,28 @@ LLVMRustPrepareThinLTOImport(const LLVMRustThinLTOData *Data, LLVMModuleRef M) {\n   return true;\n }\n \n+extern \"C\" typedef void (*LLVMRustModuleNameCallback)(void*, // payload\n+                                                      const char*, // importing module name\n+                                                      const char*); // imported module name\n+\n+// Calls `module_name_callback` for each module import done by ThinLTO.\n+// The callback is provided with regular null-terminated C strings.\n+extern \"C\" void\n+LLVMRustGetThinLTOModuleImports(const LLVMRustThinLTOData *data,\n+                                LLVMRustModuleNameCallback module_name_callback,\n+                                void* callback_payload) {\n+  for (const auto& importing_module : data->ImportLists) {\n+    const std::string importing_module_id = importing_module.getKey().str();\n+    const auto& imports = importing_module.getValue();\n+    for (const auto& imported_module : imports) {\n+      const std::string imported_module_id = imported_module.getKey().str();\n+      module_name_callback(callback_payload,\n+                           importing_module_id.c_str(),\n+                           imported_module_id.c_str());\n+    }\n+  }\n+}\n+\n // This struct and various functions are sort of a hack right now, but the\n // problem is that we've got in-memory LLVM modules after we generate and\n // optimize all codegen-units for one compilation in rustc. To be compatible\n@@ -1288,6 +1310,11 @@ LLVMRustPrepareThinLTOImport(const LLVMRustThinLTOData *Data, LLVMModuleRef M) {\n   report_fatal_error(\"ThinLTO not available\");\n }\n \n+extern \"C\" LLVMRustThinLTOModuleImports\n+LLVMRustGetLLVMRustThinLTOModuleImports(const LLVMRustThinLTOData *Data) {\n+  report_fatal_error(\"ThinLTO not available\");\n+}\n+\n extern \"C\" void\n LLVMRustFreeThinLTOData(LLVMRustThinLTOData *Data) {\n   report_fatal_error(\"ThinLTO not available\");"}, {"sha": "b9549968db4ba22ae8176a03f2c9e29efc76ca73", "filename": "src/tools/tidy/src/deps.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/ee73f80dc963707df3b3da82976556d64cac5752/src%2Ftools%2Ftidy%2Fsrc%2Fdeps.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ee73f80dc963707df3b3da82976556d64cac5752/src%2Ftools%2Ftidy%2Fsrc%2Fdeps.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ftidy%2Fsrc%2Fdeps.rs?ref=ee73f80dc963707df3b3da82976556d64cac5752", "patch": "@@ -94,6 +94,7 @@ static WHITELIST: &'static [Crate] = &[\n     Crate(\"log\"),\n     Crate(\"log_settings\"),\n     Crate(\"memchr\"),\n+    Crate(\"memmap\"),\n     Crate(\"memoffset\"),\n     Crate(\"miniz-sys\"),\n     Crate(\"nodrop\"),"}]}