{"sha": "4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "node_id": "MDY6Q29tbWl0NzI0NzEyOjRjMjZlMmUzZmJhNjFmMThjYWNhOGJkNDNjNTdlMWYxZDc5OWYwN2I=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-05-20T08:55:50Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-05-20T08:55:50Z"}, "message": "Auto merge of #50855 - nnethercote:fewer-macro_parser-allocs, r=petrochenkov\n\nSpeed up the macro parser\n\nThese three commits reduce the number of allocations done by the macro parser, in some cases dramatically. For example, for a clean check builds of html5ever, the number of allocations is reduced by 40%.\n\nHere are the rustc-benchmarks that are sped up by at least 1%.\n```\nhtml5ever-check\n        avg: -6.6%      min: -10.3%     max: -4.1%\nhtml5ever\n        avg: -5.2%      min: -9.5%      max: -2.8%\nhtml5ever-opt\n        avg: -4.3%      min: -9.3%      max: -1.6%\ncrates.io-check\n        avg: -1.8%      min: -2.9%      max: -0.6%\ncrates.io-opt\n        avg: -1.0%      min: -2.2%      max: -0.1%\ncrates.io\n        avg: -1.1%      min: -2.2%      max: -0.2%\n```", "tree": {"sha": "d6c8437e0fd5aff8c306a193338b1fd25f4ef140", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d6c8437e0fd5aff8c306a193338b1fd25f4ef140"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "html_url": "https://github.com/rust-lang/rust/commit/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ccb5e973f7546cef6c389a5378cdfbf2fcb595f1", "url": "https://api.github.com/repos/rust-lang/rust/commits/ccb5e973f7546cef6c389a5378cdfbf2fcb595f1", "html_url": "https://github.com/rust-lang/rust/commit/ccb5e973f7546cef6c389a5378cdfbf2fcb595f1"}, {"sha": "ad471452ba6fbbf91ad566dc4bdf1033a7281811", "url": "https://api.github.com/repos/rust-lang/rust/commits/ad471452ba6fbbf91ad566dc4bdf1033a7281811", "html_url": "https://github.com/rust-lang/rust/commit/ad471452ba6fbbf91ad566dc4bdf1033a7281811"}], "stats": {"total": 122, "additions": 87, "deletions": 35}, "files": [{"sha": "faf7e06c9f38f5eed691675f20fe8864d36e3d53", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 71, "deletions": 23, "changes": 94, "blob_url": "https://github.com/rust-lang/rust/blob/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "patch": "@@ -82,7 +82,7 @@\n \n pub use self::NamedMatch::*;\n pub use self::ParseResult::*;\n-use self::TokenTreeOrTokenTreeVec::*;\n+use self::TokenTreeOrTokenTreeSlice::*;\n \n use ast::Ident;\n use syntax_pos::{self, BytePos, Span};\n@@ -97,6 +97,7 @@ use tokenstream::TokenStream;\n use util::small_vector::SmallVector;\n \n use std::mem;\n+use std::ops::{Deref, DerefMut};\n use std::rc::Rc;\n use std::collections::HashMap;\n use std::collections::hash_map::Entry::{Occupied, Vacant};\n@@ -106,12 +107,12 @@ use std::collections::hash_map::Entry::{Occupied, Vacant};\n /// Either a sequence of token trees or a single one. This is used as the representation of the\n /// sequence of tokens that make up a matcher.\n #[derive(Clone)]\n-enum TokenTreeOrTokenTreeVec {\n+enum TokenTreeOrTokenTreeSlice<'a> {\n     Tt(TokenTree),\n-    TtSeq(Vec<TokenTree>),\n+    TtSeq(&'a [TokenTree]),\n }\n \n-impl TokenTreeOrTokenTreeVec {\n+impl<'a> TokenTreeOrTokenTreeSlice<'a> {\n     /// Returns the number of constituent top-level token trees of `self` (top-level in that it\n     /// will not recursively descend into subtrees).\n     fn len(&self) -> usize {\n@@ -135,19 +136,19 @@ impl TokenTreeOrTokenTreeVec {\n /// This is used by `inner_parse_loop` to keep track of delimited submatchers that we have\n /// descended into.\n #[derive(Clone)]\n-struct MatcherTtFrame {\n+struct MatcherTtFrame<'a> {\n     /// The \"parent\" matcher that we are descending into.\n-    elts: TokenTreeOrTokenTreeVec,\n+    elts: TokenTreeOrTokenTreeSlice<'a>,\n     /// The position of the \"dot\" in `elts` at the time we descended.\n     idx: usize,\n }\n \n /// Represents a single \"position\" (aka \"matcher position\", aka \"item\"), as described in the module\n /// documentation.\n #[derive(Clone)]\n-struct MatcherPos {\n+struct MatcherPos<'a> {\n     /// The token or sequence of tokens that make up the matcher\n-    top_elts: TokenTreeOrTokenTreeVec,\n+    top_elts: TokenTreeOrTokenTreeSlice<'a>,\n     /// The position of the \"dot\" in this matcher\n     idx: usize,\n     /// The beginning position in the source that the beginning of this matcher corresponds to. In\n@@ -186,7 +187,7 @@ struct MatcherPos {\n     sep: Option<Token>,\n     /// The \"parent\" matcher position if we are in a repetition. That is, the matcher position just\n     /// before we enter the sequence.\n-    up: Option<Box<MatcherPos>>,\n+    up: Option<MatcherPosHandle<'a>>,\n \n     // Specifically used to \"unzip\" token trees. By \"unzip\", we mean to unwrap the delimiters from\n     // a delimited token tree (e.g. something wrapped in `(` `)`) or to get the contents of a doc\n@@ -195,17 +196,60 @@ struct MatcherPos {\n     /// pat ) pat`), we need to keep track of the matchers we are descending into. This stack does\n     /// that where the bottom of the stack is the outermost matcher.\n     // Also, throughout the comments, this \"descent\" is often referred to as \"unzipping\"...\n-    stack: Vec<MatcherTtFrame>,\n+    stack: Vec<MatcherTtFrame<'a>>,\n }\n \n-impl MatcherPos {\n+impl<'a> MatcherPos<'a> {\n     /// Add `m` as a named match for the `idx`-th metavar.\n     fn push_match(&mut self, idx: usize, m: NamedMatch) {\n         let matches = Rc::make_mut(&mut self.matches[idx]);\n         matches.push(m);\n     }\n }\n \n+// Lots of MatcherPos instances are created at runtime. Allocating them on the\n+// heap is slow. Furthermore, using SmallVec<MatcherPos> to allocate them all\n+// on the stack is also slow, because MatcherPos is quite a large type and\n+// instances get moved around a lot between vectors, which requires lots of\n+// slow memcpy calls.\n+//\n+// Therefore, the initial MatcherPos is always allocated on the stack,\n+// subsequent ones (of which there aren't that many) are allocated on the heap,\n+// and this type is used to encapsulate both cases.\n+enum MatcherPosHandle<'a> {\n+    Ref(&'a mut MatcherPos<'a>),\n+    Box(Box<MatcherPos<'a>>),\n+}\n+\n+impl<'a> Clone for MatcherPosHandle<'a> {\n+    // This always produces a new Box.\n+    fn clone(&self) -> Self {\n+        MatcherPosHandle::Box(match *self {\n+            MatcherPosHandle::Ref(ref r) => Box::new((**r).clone()),\n+            MatcherPosHandle::Box(ref b) => b.clone(),\n+        })\n+    }\n+}\n+\n+impl<'a> Deref for MatcherPosHandle<'a> {\n+    type Target = MatcherPos<'a>;\n+    fn deref(&self) -> &Self::Target {\n+        match *self {\n+            MatcherPosHandle::Ref(ref r) => r,\n+            MatcherPosHandle::Box(ref b) => b,\n+        }\n+    }\n+}\n+\n+impl<'a> DerefMut for MatcherPosHandle<'a> {\n+    fn deref_mut(&mut self) -> &mut MatcherPos<'a> {\n+        match *self {\n+            MatcherPosHandle::Ref(ref mut r) => r,\n+            MatcherPosHandle::Box(ref mut b) => b,\n+        }\n+    }\n+}\n+\n /// Represents the possible results of an attempted parse.\n pub enum ParseResult<T> {\n     /// Parsed successfully.\n@@ -241,10 +285,10 @@ fn create_matches(len: usize) -> Vec<Rc<Vec<NamedMatch>>> {\n \n /// Generate the top-level matcher position in which the \"dot\" is before the first token of the\n /// matcher `ms` and we are going to start matching at position `lo` in the source.\n-fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n-    let match_idx_hi = count_names(&ms[..]);\n+fn initial_matcher_pos(ms: &[TokenTree], lo: BytePos) -> MatcherPos {\n+    let match_idx_hi = count_names(ms);\n     let matches = create_matches(match_idx_hi);\n-    Box::new(MatcherPos {\n+    MatcherPos {\n         // Start with the top level matcher given to us\n         top_elts: TtSeq(ms), // \"elts\" is an abbr. for \"elements\"\n         // The \"dot\" is before the first token of the matcher\n@@ -267,7 +311,7 @@ fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n         seq_op: None,\n         sep: None,\n         up: None,\n-    })\n+    }\n }\n \n /// `NamedMatch` is a pattern-match result for a single `token::MATCH_NONTERMINAL`:\n@@ -394,12 +438,12 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n /// # Returns\n ///\n /// A `ParseResult`. Note that matches are kept track of through the items generated.\n-fn inner_parse_loop(\n+fn inner_parse_loop<'a>(\n     sess: &ParseSess,\n-    cur_items: &mut SmallVector<Box<MatcherPos>>,\n-    next_items: &mut Vec<Box<MatcherPos>>,\n-    eof_items: &mut SmallVector<Box<MatcherPos>>,\n-    bb_items: &mut SmallVector<Box<MatcherPos>>,\n+    cur_items: &mut SmallVector<MatcherPosHandle<'a>>,\n+    next_items: &mut Vec<MatcherPosHandle<'a>>,\n+    eof_items: &mut SmallVector<MatcherPosHandle<'a>>,\n+    bb_items: &mut SmallVector<MatcherPosHandle<'a>>,\n     token: &Token,\n     span: syntax_pos::Span,\n ) -> ParseResult<()> {\n@@ -502,7 +546,7 @@ fn inner_parse_loop(\n                     }\n \n                     let matches = create_matches(item.matches.len());\n-                    cur_items.push(Box::new(MatcherPos {\n+                    cur_items.push(MatcherPosHandle::Box(Box::new(MatcherPos {\n                         stack: vec![],\n                         sep: seq.separator.clone(),\n                         seq_op: Some(seq.op),\n@@ -514,7 +558,7 @@ fn inner_parse_loop(\n                         up: Some(item),\n                         sp_lo: sp.lo(),\n                         top_elts: Tt(TokenTree::Sequence(sp, seq)),\n-                    }));\n+                    })));\n                 }\n \n                 // We need to match a metavar (but the identifier is invalid)... this is an error\n@@ -596,7 +640,11 @@ pub fn parse(\n     // processes all of these possible matcher positions and produces posible next positions into\n     // `next_items`. After some post-processing, the contents of `next_items` replenish `cur_items`\n     // and we start over again.\n-    let mut cur_items = SmallVector::one(initial_matcher_pos(ms.to_owned(), parser.span.lo()));\n+    //\n+    // This MatcherPos instance is allocated on the stack. All others -- and\n+    // there are frequently *no* others! -- are allocated on the heap.\n+    let mut initial = initial_matcher_pos(ms, parser.span.lo());\n+    let mut cur_items = SmallVector::one(MatcherPosHandle::Ref(&mut initial));\n     let mut next_items = Vec::new();\n \n     loop {"}, {"sha": "8fc1d363914104cedf85f1ae1532e313f2157997", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "patch": "@@ -27,6 +27,7 @@ use parse::token::Token::*;\n use symbol::Symbol;\n use tokenstream::{TokenStream, TokenTree};\n \n+use std::borrow::Cow;\n use std::collections::HashMap;\n use std::collections::hash_map::Entry;\n \n@@ -142,7 +143,7 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt,\n                 }\n \n                 let directory = Directory {\n-                    path: cx.current_expansion.module.directory.clone(),\n+                    path: Cow::from(cx.current_expansion.module.directory.as_path()),\n                     ownership: cx.current_expansion.directory_ownership,\n                 };\n                 let mut p = Parser::new(cx.parse_sess(), tts, Some(directory), true, false);"}, {"sha": "0abedb99bd0376564ac2daac7f27c2253616167e", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "patch": "@@ -23,6 +23,7 @@ use symbol::Symbol;\n use tokenstream::{TokenStream, TokenTree};\n use diagnostics::plugin::ErrorMap;\n \n+use std::borrow::Cow;\n use std::collections::HashSet;\n use std::iter;\n use std::path::{Path, PathBuf};\n@@ -89,8 +90,8 @@ impl ParseSess {\n }\n \n #[derive(Clone)]\n-pub struct Directory {\n-    pub path: PathBuf,\n+pub struct Directory<'a> {\n+    pub path: Cow<'a, Path>,\n     pub ownership: DirectoryOwnership,\n }\n "}, {"sha": "3e9869494f93449beae7f57f654c4d2e394dfff3", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 9, "deletions": 8, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "patch": "@@ -57,6 +57,7 @@ use tokenstream::{self, Delimited, ThinTokenStream, TokenTree, TokenStream};\n use symbol::{Symbol, keywords};\n use util::ThinVec;\n \n+use std::borrow::Cow;\n use std::cmp;\n use std::mem;\n use std::path::{self, Path, PathBuf};\n@@ -228,7 +229,7 @@ pub struct Parser<'a> {\n     prev_token_kind: PrevTokenKind,\n     pub restrictions: Restrictions,\n     /// Used to determine the path to externally loaded source files\n-    pub directory: Directory,\n+    pub directory: Directory<'a>,\n     /// Whether to parse sub-modules in other files.\n     pub recurse_into_file_modules: bool,\n     /// Name of the root module this parser originated from. If `None`, then the\n@@ -535,7 +536,7 @@ enum TokenExpectType {\n impl<'a> Parser<'a> {\n     pub fn new(sess: &'a ParseSess,\n                tokens: TokenStream,\n-               directory: Option<Directory>,\n+               directory: Option<Directory<'a>>,\n                recurse_into_file_modules: bool,\n                desugar_doc_comments: bool)\n                -> Self {\n@@ -549,7 +550,7 @@ impl<'a> Parser<'a> {\n             restrictions: Restrictions::empty(),\n             recurse_into_file_modules,\n             directory: Directory {\n-                path: PathBuf::new(),\n+                path: Cow::from(PathBuf::new()),\n                 ownership: DirectoryOwnership::Owned { relative: None }\n             },\n             root_module_name: None,\n@@ -572,9 +573,9 @@ impl<'a> Parser<'a> {\n         if let Some(directory) = directory {\n             parser.directory = directory;\n         } else if !parser.span.source_equal(&DUMMY_SP) {\n-            if let FileName::Real(path) = sess.codemap().span_to_unmapped_path(parser.span) {\n-                parser.directory.path = path;\n-                parser.directory.path.pop();\n+            if let FileName::Real(mut path) = sess.codemap().span_to_unmapped_path(parser.span) {\n+                path.pop();\n+                parser.directory.path = Cow::from(path);\n             }\n         }\n \n@@ -6008,10 +6009,10 @@ impl<'a> Parser<'a> {\n \n     fn push_directory(&mut self, id: Ident, attrs: &[Attribute]) {\n         if let Some(path) = attr::first_attr_value_str_by_name(attrs, \"path\") {\n-            self.directory.path.push(&path.as_str());\n+            self.directory.path.to_mut().push(&path.as_str());\n             self.directory.ownership = DirectoryOwnership::Owned { relative: None };\n         } else {\n-            self.directory.path.push(&id.name.as_str());\n+            self.directory.path.to_mut().push(&id.name.as_str());\n         }\n     }\n "}, {"sha": "455cc4391dd3b535877d8b79d03a926859833a95", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4c26e2e3fba61f18caca8bd43c57e1f1d799f07b/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=4c26e2e3fba61f18caca8bd43c57e1f1d799f07b", "patch": "@@ -31,6 +31,7 @@ use print::pprust;\n use serialize::{Decoder, Decodable, Encoder, Encodable};\n use util::RcSlice;\n \n+use std::borrow::Cow;\n use std::{fmt, iter, mem};\n use std::hash::{self, Hash};\n \n@@ -106,7 +107,7 @@ impl TokenTree {\n                  -> macro_parser::NamedParseResult {\n         // `None` is because we're not interpolating\n         let directory = Directory {\n-            path: cx.current_expansion.module.directory.clone(),\n+            path: Cow::from(cx.current_expansion.module.directory.as_path()),\n             ownership: cx.current_expansion.directory_ownership,\n         };\n         macro_parser::parse(cx.parse_sess(), tts, mtch, Some(directory), true)"}]}