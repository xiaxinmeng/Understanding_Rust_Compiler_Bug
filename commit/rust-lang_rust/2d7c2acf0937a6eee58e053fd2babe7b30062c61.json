{"sha": "2d7c2acf0937a6eee58e053fd2babe7b30062c61", "node_id": "MDY6Q29tbWl0NzI0NzEyOjJkN2MyYWNmMDkzN2E2ZWVlNThlMDUzZmQyYmFiZTdiMzAwNjJjNjE=", "commit": {"author": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2011-01-24T23:26:10Z"}, "committer": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2011-01-24T23:26:10Z"}, "message": "Switch from booleans to symbolic tags in a few places.", "tree": {"sha": "f8c3e311fbd89c80c84d1f0c2de0639c479f63c9", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f8c3e311fbd89c80c84d1f0c2de0639c479f63c9"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2d7c2acf0937a6eee58e053fd2babe7b30062c61", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2d7c2acf0937a6eee58e053fd2babe7b30062c61", "html_url": "https://github.com/rust-lang/rust/commit/2d7c2acf0937a6eee58e053fd2babe7b30062c61", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2d7c2acf0937a6eee58e053fd2babe7b30062c61/comments", "author": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "committer": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "65da18faf8eb17cd258d373c316f048d5ca8ee56", "url": "https://api.github.com/repos/rust-lang/rust/commits/65da18faf8eb17cd258d373c316f048d5ca8ee56", "html_url": "https://github.com/rust-lang/rust/commit/65da18faf8eb17cd258d373c316f048d5ca8ee56"}], "stats": {"total": 110, "additions": 64, "deletions": 46}, "files": [{"sha": "a7a4881bb0d71c87e526c29798a1d1a4b6b75bde", "filename": "src/comp/front/parser.rs", "status": "modified", "additions": 28, "deletions": 23, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/2d7c2acf0937a6eee58e053fd2babe7b30062c61/src%2Fcomp%2Ffront%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d7c2acf0937a6eee58e053fd2babe7b30062c61/src%2Fcomp%2Ffront%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fparser.rs?ref=2d7c2acf0937a6eee58e053fd2babe7b30062c61", "patch": "@@ -12,13 +12,18 @@ import util.common.append;\n import util.common.span;\n import util.common.new_str_hash;\n \n+tag restriction {\n+    UNRESTRICTED;\n+    RESTRICT_NO_CALL_EXPRS;\n+}\n+\n state type parser =\n     state obj {\n           fn peek() -> token.token;\n           impure fn bump();\n           impure fn err(str s);\n-          impure fn restrict(bool r);\n-          fn is_restricted() -> bool;\n+          impure fn restrict(restriction r);\n+          fn get_restriction() -> restriction;\n           fn get_session() -> session.session;\n           fn get_span() -> common.span;\n           fn next_def_id() -> ast.def_id;\n@@ -31,7 +36,7 @@ impure fn new_parser(session.session sess,\n                            mutable common.pos lo,\n                            mutable common.pos hi,\n                            mutable ast.def_num def,\n-                           mutable bool restricted,\n+                           mutable restriction res,\n                            ast.crate_num crate,\n                            lexer.reader rdr)\n         {\n@@ -52,12 +57,12 @@ impure fn new_parser(session.session sess,\n                 sess.span_err(span, m);\n             }\n \n-            impure fn restrict(bool r) {\n-                restricted = r;\n+            impure fn restrict(restriction r) {\n+                res = r;\n             }\n \n-            fn is_restricted() -> bool {\n-                ret restricted;\n+            fn get_restriction() -> restriction {\n+                ret res;\n             }\n \n             fn get_session() -> session.session {\n@@ -78,7 +83,7 @@ impure fn new_parser(session.session sess,\n     auto rdr = lexer.new_reader(srdr, path);\n     auto npos = rdr.get_curr_pos();\n     ret stdio_parser(sess, lexer.next_token(rdr),\n-                     npos, npos, 0, false, crate, rdr);\n+                     npos, npos, 0, UNRESTRICTED, crate, rdr);\n }\n \n impure fn unexpected(parser p, token.token t) {\n@@ -283,7 +288,7 @@ impure fn parse_ty(parser p) -> @ast.ty {\n         }\n \n         case (token.IDENT(_)) {\n-            t = ast.ty_path(parse_path(p, true), none[ast.def]);\n+            t = ast.ty_path(parse_path(p, GREEDY), none[ast.def]);\n         }\n \n         case (_) {\n@@ -380,7 +385,12 @@ fn is_ident(token.token t) -> bool {\n     ret false;\n }\n \n-impure fn parse_path(parser p, bool greedy) -> ast.path {\n+tag greed {\n+    GREEDY;\n+    MINIMAL;\n+}\n+\n+impure fn parse_path(parser p, greed g) -> ast.path {\n \n     auto lo = p.get_span();\n     auto hi = lo;\n@@ -394,7 +404,7 @@ impure fn parse_path(parser p, bool greedy) -> ast.path {\n                 ids += i;\n                 p.bump();\n                 if (p.peek() == token.DOT) {\n-                    if (greedy) {\n+                    if (g == GREEDY) {\n                         p.bump();\n                         check (is_ident(p.peek()));\n                     } else {\n@@ -456,7 +466,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n     alt (p.peek()) {\n \n         case (token.IDENT(_)) {\n-            auto pth = parse_path(p, false);\n+            auto pth = parse_path(p, MINIMAL);\n             hi = pth.span;\n             ex = ast.expr_path(pth, none[ast.def], ast.ann_none);\n         }\n@@ -521,7 +531,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n \n         case (token.BIND) {\n             p.bump();\n-            auto e = parse_restricted_expr(p);\n+            auto e = parse_expr_res(p, RESTRICT_NO_CALL_EXPRS);\n             impure fn parse_expr_opt(parser p) -> option.t[@ast.expr] {\n                 alt (p.peek()) {\n                     case (token.UNDERSCORE) {\n@@ -589,7 +599,7 @@ impure fn parse_dot_or_call_expr(parser p) -> @ast.expr {\n         alt (p.peek()) {\n \n             case (token.LPAREN) {\n-                if (p.is_restricted()) {\n+                if (p.get_restriction() == RESTRICT_NO_CALL_EXPRS) {\n                     ret e;\n                 } else {\n                     // Call expr.\n@@ -983,18 +993,13 @@ impure fn parse_alt_expr(parser p) -> @ast.expr {\n     ret @spanned(lo, hi, expr);\n }\n \n-\n-impure fn parse_restricted_expr(parser p) -> @ast.expr {\n-    ret parse_expr_res(p, true);\n-}\n-\n impure fn parse_expr(parser p) -> @ast.expr {\n-    ret parse_expr_res(p, false);\n+    ret parse_expr_res(p, UNRESTRICTED);\n }\n \n-impure fn parse_expr_res(parser p, bool restrict) -> @ast.expr {\n-    auto old = p.is_restricted();\n-    p.restrict(restrict);\n+impure fn parse_expr_res(parser p, restriction r) -> @ast.expr {\n+    auto old = p.get_restriction();\n+    p.restrict(r);\n     auto e = parse_expr_inner(p);\n     p.restrict(old);\n     ret e;"}, {"sha": "4f333348ca59ee6ae1a25de3bdb7f785e57f229e", "filename": "src/comp/middle/trans.rs", "status": "modified", "additions": 36, "deletions": 23, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/2d7c2acf0937a6eee58e053fd2babe7b30062c61/src%2Fcomp%2Fmiddle%2Ftrans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d7c2acf0937a6eee58e053fd2babe7b30062c61/src%2Fcomp%2Fmiddle%2Ftrans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ftrans.rs?ref=2d7c2acf0937a6eee58e053fd2babe7b30062c61", "patch": "@@ -93,10 +93,16 @@ tag cleanup {\n     clean(fn(@block_ctxt cx) -> result);\n }\n \n+\n+tag block_kind {\n+    SCOPE_BLOCK;\n+    NON_SCOPE_BLOCK;\n+}\n+\n state type block_ctxt = rec(BasicBlockRef llbb,\n                             builder build,\n                             block_parent parent,\n-                            bool is_scope,\n+                            block_kind kind,\n                             mutable vec[cleanup] cleanups,\n                             @fn_ctxt fcx);\n \n@@ -640,7 +646,7 @@ fn trans_non_gc_free(@block_ctxt cx, ValueRef v) -> result {\n }\n \n fn find_scope_cx(@block_ctxt cx) -> @block_ctxt {\n-    if (cx.is_scope) {\n+    if (cx.kind == SCOPE_BLOCK) {\n         ret cx;\n     }\n     alt (cx.parent) {\n@@ -1492,8 +1498,13 @@ fn memcpy_ty(@block_ctxt cx,\n     }\n }\n \n+tag copy_action {\n+    INIT;\n+    DROP_EXISTING;\n+}\n+\n fn copy_ty(@block_ctxt cx,\n-           bool is_init,\n+           copy_action action,\n            ValueRef dst,\n            ValueRef src,\n            @ty.t t) -> result {\n@@ -1505,15 +1516,15 @@ fn copy_ty(@block_ctxt cx,\n \n     } else if (ty.type_is_boxed(t)) {\n         auto r = incr_all_refcnts(cx, src, t);\n-        if (! is_init) {\n+        if (action == DROP_EXISTING) {\n             r = drop_ty(r.bcx, r.bcx.build.Load(dst), t);\n         }\n         ret res(r.bcx, r.bcx.build.Store(src, dst));\n \n     } else if (ty.type_is_structural(t) ||\n                ty.type_has_dynamic_size(t)) {\n         auto r = incr_all_refcnts(cx, src, t);\n-        if (! is_init) {\n+        if (action == DROP_EXISTING) {\n             r = drop_ty(r.bcx, dst, t);\n         }\n         ret memcpy_ty(r.bcx, dst, src, t);\n@@ -1623,7 +1634,7 @@ fn trans_unary(@block_ctxt cx, ast.unop op,\n                                           vec(C_int(0),\n                                               C_int(abi.box_rc_field_body)));\n             sub.bcx.build.Store(C_int(1), rc);\n-            sub = copy_ty(sub.bcx, true, body, e_val, e_ty);\n+            sub = copy_ty(sub.bcx, INIT, body, e_val, e_ty);\n             ret res(sub.bcx, box);\n         }\n         case (ast.deref) {\n@@ -1815,7 +1826,7 @@ fn trans_for(@block_ctxt cx,\n \n         cx.build.Br(scope_cx.llbb);\n         auto local_res = alloc_local(scope_cx, local);\n-        auto bcx = copy_ty(local_res.bcx, true, local_res.val, curr, t).bcx;\n+        auto bcx = copy_ty(local_res.bcx, INIT, local_res.val, curr, t).bcx;\n         bcx = trans_block(bcx, body).bcx;\n         bcx.build.Br(next_cx.llbb);\n         ret res(next_cx, C_nil());\n@@ -1955,7 +1966,7 @@ fn trans_pat_binding(@block_ctxt cx, @ast.pat pat, ValueRef llval)\n             cx.fcx.lllocals.insert(def_id, dst);\n             cx.cleanups += clean(bind drop_slot(_, dst, ty));\n \n-            ret copy_ty(cx, true, dst, llval, ty);\n+            ret copy_ty(cx, INIT, dst, llval, ty);\n         }\n         case (ast.pat_tag(_, ?subpats, _, _)) {\n             if (_vec.len[@ast.pat](subpats) == 0u) { ret res(cx, llval); }\n@@ -2496,7 +2507,7 @@ fn trans_bind(@block_ctxt cx, @ast.expr f,\n             for (ValueRef v in bound_vals) {\n                 auto bound = bcx.build.GEP(bindings,\n                                            vec(C_int(0),C_int(i)));\n-                bcx = copy_ty(r.bcx, true, bound, v, bound_tys.(i)).bcx;\n+                bcx = copy_ty(r.bcx, INIT, bound, v, bound_tys.(i)).bcx;\n                 i += 1;\n             }\n \n@@ -2608,7 +2619,7 @@ fn trans_tup(@block_ctxt cx, vec[ast.elt] elts,\n         auto t = ty.expr_ty(e.expr);\n         auto src_res = trans_expr(r.bcx, e.expr);\n         auto dst_elt = r.bcx.build.GEP(tup_val, vec(C_int(0), C_int(i)));\n-        r = copy_ty(src_res.bcx, true, dst_elt, src_res.val, t);\n+        r = copy_ty(src_res.bcx, INIT, dst_elt, src_res.val, t);\n         i += 1;\n     }\n     ret res(r.bcx, tup_val);\n@@ -2645,7 +2656,7 @@ fn trans_vec(@block_ctxt cx, vec[@ast.expr] args,\n     for (@ast.expr e in args) {\n         auto src_res = trans_expr(sub.bcx, e);\n         auto dst_elt = sub.bcx.build.GEP(body, vec(C_int(0), C_int(i)));\n-        sub = copy_ty(src_res.bcx, true, dst_elt, src_res.val, unit_ty);\n+        sub = copy_ty(src_res.bcx, INIT, dst_elt, src_res.val, unit_ty);\n         i += 1;\n     }\n     auto fill = sub.bcx.build.GEP(vec_val,\n@@ -2668,7 +2679,7 @@ fn trans_rec(@block_ctxt cx, vec[ast.field] fields,\n         auto src_res = trans_expr(r.bcx, f.expr);\n         auto dst_elt = r.bcx.build.GEP(rec_val, vec(C_int(0), C_int(i)));\n         // FIXME: calculate copy init-ness in typestate.\n-        r = copy_ty(src_res.bcx, true, dst_elt, src_res.val, t);\n+        r = copy_ty(src_res.bcx, INIT, dst_elt, src_res.val, t);\n         i += 1;\n     }\n     ret res(r.bcx, rec_val);\n@@ -2727,7 +2738,8 @@ fn trans_expr(@block_ctxt cx, @ast.expr e) -> result {\n             auto rhs_res = trans_expr(lhs_res.res.bcx, src);\n             auto t = node_ann_type(cx.fcx.ccx, ann);\n             // FIXME: calculate copy init-ness in typestate.\n-            ret copy_ty(rhs_res.bcx, false, lhs_res.res.val, rhs_res.val, t);\n+            ret copy_ty(rhs_res.bcx, DROP_EXISTING,\n+                        lhs_res.res.val, rhs_res.val, t);\n         }\n \n         case (ast.expr_assign_op(?op, ?dst, ?src, ?ann)) {\n@@ -2739,7 +2751,8 @@ fn trans_expr(@block_ctxt cx, @ast.expr e) -> result {\n             auto rhs_res = trans_expr(lhs_res.res.bcx, src);\n             auto v = trans_eager_binop(rhs_res.bcx, op, lhs_val, rhs_res.val);\n             // FIXME: calculate copy init-ness in typestate.\n-            ret copy_ty(rhs_res.bcx, false, lhs_res.res.val, v, t);\n+            ret copy_ty(rhs_res.bcx, DROP_EXISTING,\n+                        lhs_res.res.val, v, t);\n         }\n \n         case (ast.expr_bind(?f, ?args, ?ann)) {\n@@ -2889,7 +2902,7 @@ fn trans_ret(@block_ctxt cx, &option.t[@ast.expr] e) -> result {\n             alt (cx.fcx.llretptr) {\n                 case (some[ValueRef](?llptr)) {\n                     // Generic return via tydesc + retptr.\n-                    bcx = copy_ty(bcx, true, llptr, val, t).bcx;\n+                    bcx = copy_ty(bcx, INIT, llptr, val, t).bcx;\n                     bcx.build.RetVoid();\n                 }\n                 case (none[ValueRef]) {\n@@ -2921,7 +2934,7 @@ fn init_local(@block_ctxt cx, @ast.local local) -> result {\n     alt (local.init) {\n         case (some[@ast.expr](?e)) {\n             auto sub = trans_expr(bcx, e);\n-            bcx = copy_ty(sub.bcx, true, llptr, sub.val, ty).bcx;\n+            bcx = copy_ty(sub.bcx, INIT, llptr, sub.val, ty).bcx;\n         }\n         case (_) {\n             if (middle.ty.type_has_dynamic_size(ty)) {\n@@ -2983,7 +2996,7 @@ fn new_builder(BasicBlockRef llbb) -> builder {\n // You probably don't want to use this one. See the\n // next three functions instead.\n fn new_block_ctxt(@fn_ctxt cx, block_parent parent,\n-                  bool is_scope,\n+                  block_kind kind,\n                   str name) -> @block_ctxt {\n     let vec[cleanup] cleanups = vec();\n     let BasicBlockRef llbb =\n@@ -2993,32 +3006,32 @@ fn new_block_ctxt(@fn_ctxt cx, block_parent parent,\n     ret @rec(llbb=llbb,\n              build=new_builder(llbb),\n              parent=parent,\n-             is_scope=is_scope,\n+             kind=kind,\n              mutable cleanups=cleanups,\n              fcx=cx);\n }\n \n // Use this when you're at the top block of a function or the like.\n fn new_top_block_ctxt(@fn_ctxt fcx) -> @block_ctxt {\n-    ret new_block_ctxt(fcx, parent_none, true, \"function top level\");\n+    ret new_block_ctxt(fcx, parent_none, SCOPE_BLOCK, \"function top level\");\n }\n \n // Use this when you're at a curly-brace or similar lexical scope.\n fn new_scope_block_ctxt(@block_ctxt bcx, str n) -> @block_ctxt {\n-    ret new_block_ctxt(bcx.fcx, parent_some(bcx), true, n);\n+    ret new_block_ctxt(bcx.fcx, parent_some(bcx), SCOPE_BLOCK, n);\n }\n \n // Use this when you're making a general CFG BB within a scope.\n fn new_sub_block_ctxt(@block_ctxt bcx, str n) -> @block_ctxt {\n-    ret new_block_ctxt(bcx.fcx, parent_some(bcx), false, n);\n+    ret new_block_ctxt(bcx.fcx, parent_some(bcx), NON_SCOPE_BLOCK, n);\n }\n \n \n fn trans_block_cleanups(@block_ctxt cx,\n                         @block_ctxt cleanup_cx) -> @block_ctxt {\n     auto bcx = cx;\n \n-    if (!cleanup_cx.is_scope) {\n+    if (cleanup_cx.kind != SCOPE_BLOCK) {\n         check (_vec.len[cleanup](cleanup_cx.cleanups) == 0u);\n     }\n \n@@ -3430,7 +3443,7 @@ fn trans_obj(@crate_ctxt cx, &ast._obj ob, ast.def_id oid,\n             arg = load_scalar_or_boxed(r.bcx, arg, arg_tys.(i).ty);\n             auto field = r.bcx.build.GEP(body_fields,\n                                          vec(C_int(0),C_int(i)));\n-            r = copy_ty(r.bcx, true, field, arg, arg_tys.(i).ty);\n+            r = copy_ty(r.bcx, INIT, field, arg, arg_tys.(i).ty);\n             i += 1;\n         }\n "}]}