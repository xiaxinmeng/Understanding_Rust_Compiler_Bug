{"sha": "d6414f5f8c30593cd250fddf315e6f0098c3239a", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ2NDE0ZjVmOGMzMDU5M2NkMjUwZmRkZjMxNWU2ZjAwOThjMzIzOWE=", "commit": {"author": {"name": "Dylan DPC", "email": "dylan.dpc@gmail.com", "date": "2020-02-23T08:57:45Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-02-23T08:57:45Z"}, "message": "Rollup merge of #69376 - petrochenkov:bumpwith, r=Centril\n\nparser: Cleanup `Parser::bump_with` and its uses\n\nFollow-up to https://github.com/rust-lang/rust/pull/69006.\nr? @Centril", "tree": {"sha": "91c7ad89aa389500bcfb3d9e322beb3b9fbcb83f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/91c7ad89aa389500bcfb3d9e322beb3b9fbcb83f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d6414f5f8c30593cd250fddf315e6f0098c3239a", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJeUj6KCRBK7hj4Ov3rIwAAdHIIAAftL4wKAalITPet8F2vCiy7\n/psvgxzczDNAsiyvR8VXVxmBWGb9TZ4UWqRleAwrMbtmK4HXECrAQlI320eWMDNf\nRU596O+4E+xFGTVmdPzGazAVJhWYyyXDro/c4KAXLjipyzsXG+wtDqnd8j0S7Xh+\nMDKDmWejWK/SMFa/98ezpu4VVDPrgsfqSD5QRgzz3tejtpZoqhbrARCD/cJRNF3m\nRQxYlNfXHuPrrb80fQ+P1MJNahqngXloRQDwKaKkfZThrGorfXqFtJ1a82Tqv5Zg\nmUc3QgpP7SWAI91TMsKFDi0+1SwUE6dPuOsGn/XEMC7+Gj5ciWR1rvRGPx06cl8=\n=WrPg\n-----END PGP SIGNATURE-----\n", "payload": "tree 91c7ad89aa389500bcfb3d9e322beb3b9fbcb83f\nparent bdd275de2affa203d5ef4185d32b9b68109e38ca\nparent 4356d18e4ab262a6703fa3a901c7cf00e9d27cc7\nauthor Dylan DPC <dylan.dpc@gmail.com> 1582448265 +0100\ncommitter GitHub <noreply@github.com> 1582448265 +0100\n\nRollup merge of #69376 - petrochenkov:bumpwith, r=Centril\n\nparser: Cleanup `Parser::bump_with` and its uses\n\nFollow-up to https://github.com/rust-lang/rust/pull/69006.\nr? @Centril\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d6414f5f8c30593cd250fddf315e6f0098c3239a", "html_url": "https://github.com/rust-lang/rust/commit/d6414f5f8c30593cd250fddf315e6f0098c3239a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d6414f5f8c30593cd250fddf315e6f0098c3239a/comments", "author": {"login": "Dylan-DPC", "id": 99973273, "node_id": "U_kgDOBfV4mQ", "avatar_url": "https://avatars.githubusercontent.com/u/99973273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dylan-DPC", "html_url": "https://github.com/Dylan-DPC", "followers_url": "https://api.github.com/users/Dylan-DPC/followers", "following_url": "https://api.github.com/users/Dylan-DPC/following{/other_user}", "gists_url": "https://api.github.com/users/Dylan-DPC/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dylan-DPC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dylan-DPC/subscriptions", "organizations_url": "https://api.github.com/users/Dylan-DPC/orgs", "repos_url": "https://api.github.com/users/Dylan-DPC/repos", "events_url": "https://api.github.com/users/Dylan-DPC/events{/privacy}", "received_events_url": "https://api.github.com/users/Dylan-DPC/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bdd275de2affa203d5ef4185d32b9b68109e38ca", "url": "https://api.github.com/repos/rust-lang/rust/commits/bdd275de2affa203d5ef4185d32b9b68109e38ca", "html_url": "https://github.com/rust-lang/rust/commit/bdd275de2affa203d5ef4185d32b9b68109e38ca"}, {"sha": "4356d18e4ab262a6703fa3a901c7cf00e9d27cc7", "url": "https://api.github.com/repos/rust-lang/rust/commits/4356d18e4ab262a6703fa3a901c7cf00e9d27cc7", "html_url": "https://github.com/rust-lang/rust/commit/4356d18e4ab262a6703fa3a901c7cf00e9d27cc7"}], "stats": {"total": 211, "additions": 84, "deletions": 127}, "files": [{"sha": "75d4b3750f164ff53a344ac96237a092345a3c88", "filename": "src/librustc_parse/parser/mod.rs", "status": "modified", "additions": 51, "deletions": 127, "changes": 178, "blob_url": "https://github.com/rust-lang/rust/blob/d6414f5f8c30593cd250fddf315e6f0098c3239a/src%2Flibrustc_parse%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d6414f5f8c30593cd250fddf315e6f0098c3239a/src%2Flibrustc_parse%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fmod.rs?ref=d6414f5f8c30593cd250fddf315e6f0098c3239a", "patch": "@@ -601,141 +601,76 @@ impl<'a> Parser<'a> {\n         )\n     }\n \n-    /// Expects and consumes a `+`. if `+=` is seen, replaces it with a `=`\n-    /// and continues. If a `+` is not seen, returns `false`.\n-    ///\n-    /// This is used when token-splitting `+=` into `+`.\n-    /// See issue #47856 for an example of when this may occur.\n-    fn eat_plus(&mut self) -> bool {\n-        self.expected_tokens.push(TokenType::Token(token::BinOp(token::Plus)));\n-        match self.token.kind {\n-            token::BinOp(token::Plus) => {\n-                self.bump();\n+    /// Eats the expected token if it's present possibly breaking\n+    /// compound tokens like multi-character operators in process.\n+    /// Returns `true` if the token was eaten.\n+    fn break_and_eat(&mut self, expected: TokenKind) -> bool {\n+        if self.token.kind == expected {\n+            self.bump();\n+            return true;\n+        }\n+        match self.token.kind.break_two_token_op() {\n+            Some((first, second)) if first == expected => {\n+                let first_span = self.sess.source_map().start_point(self.token.span);\n+                let second_span = self.token.span.with_lo(first_span.hi());\n+                self.set_token(Token::new(first, first_span));\n+                self.bump_with(Token::new(second, second_span));\n                 true\n             }\n-            token::BinOpEq(token::Plus) => {\n-                let start_point = self.sess.source_map().start_point(self.token.span);\n-                self.bump_with(token::Eq, self.token.span.with_lo(start_point.hi()));\n-                true\n+            _ => {\n+                self.expected_tokens.push(TokenType::Token(expected));\n+                false\n             }\n-            _ => false,\n         }\n     }\n \n-    /// Expects and consumes an `&`. If `&&` is seen, replaces it with a single\n-    /// `&` and continues. If an `&` is not seen, signals an error.\n+    /// Eats `+` possibly breaking tokens like `+=` in process.\n+    fn eat_plus(&mut self) -> bool {\n+        self.break_and_eat(token::BinOp(token::Plus))\n+    }\n+\n+    /// Eats `&` possibly breaking tokens like `&&` in process.\n+    /// Signals an error if `&` is not eaten.\n     fn expect_and(&mut self) -> PResult<'a, ()> {\n-        self.expected_tokens.push(TokenType::Token(token::BinOp(token::And)));\n-        match self.token.kind {\n-            token::BinOp(token::And) => {\n-                self.bump();\n-                Ok(())\n-            }\n-            token::AndAnd => {\n-                let start_point = self.sess.source_map().start_point(self.token.span);\n-                Ok(self\n-                    .bump_with(token::BinOp(token::And), self.token.span.with_lo(start_point.hi())))\n-            }\n-            _ => self.unexpected(),\n-        }\n+        if self.break_and_eat(token::BinOp(token::And)) { Ok(()) } else { self.unexpected() }\n     }\n \n-    /// Expects and consumes an `|`. If `||` is seen, replaces it with a single\n-    /// `|` and continues. If an `|` is not seen, signals an error.\n+    /// Eats `|` possibly breaking tokens like `||` in process.\n+    /// Signals an error if `|` was not eaten.\n     fn expect_or(&mut self) -> PResult<'a, ()> {\n-        self.expected_tokens.push(TokenType::Token(token::BinOp(token::Or)));\n-        match self.token.kind {\n-            token::BinOp(token::Or) => {\n-                self.bump();\n-                Ok(())\n-            }\n-            token::OrOr => {\n-                let start_point = self.sess.source_map().start_point(self.token.span);\n-                Ok(self\n-                    .bump_with(token::BinOp(token::Or), self.token.span.with_lo(start_point.hi())))\n-            }\n-            _ => self.unexpected(),\n-        }\n+        if self.break_and_eat(token::BinOp(token::Or)) { Ok(()) } else { self.unexpected() }\n     }\n \n-    /// Attempts to consume a `<`. If `<<` is seen, replaces it with a single\n-    /// `<` and continue. If `<-` is seen, replaces it with a single `<`\n-    /// and continue. If a `<` is not seen, returns false.\n-    ///\n-    /// This is meant to be used when parsing generics on a path to get the\n-    /// starting token.\n+    /// Eats `<` possibly breaking tokens like `<<` in process.\n     fn eat_lt(&mut self) -> bool {\n-        self.expected_tokens.push(TokenType::Token(token::Lt));\n-        let ate = match self.token.kind {\n-            token::Lt => {\n-                self.bump();\n-                true\n-            }\n-            token::BinOp(token::Shl) => {\n-                let start_point = self.sess.source_map().start_point(self.token.span);\n-                self.bump_with(token::Lt, self.token.span.with_lo(start_point.hi()));\n-                true\n-            }\n-            token::LArrow => {\n-                let start_point = self.sess.source_map().start_point(self.token.span);\n-                self.bump_with(\n-                    token::BinOp(token::Minus),\n-                    self.token.span.with_lo(start_point.hi()),\n-                );\n-                true\n-            }\n-            _ => false,\n-        };\n-\n+        let ate = self.break_and_eat(token::Lt);\n         if ate {\n             // See doc comment for `unmatched_angle_bracket_count`.\n             self.unmatched_angle_bracket_count += 1;\n             self.max_angle_bracket_count += 1;\n             debug!(\"eat_lt: (increment) count={:?}\", self.unmatched_angle_bracket_count);\n         }\n-\n         ate\n     }\n \n+    /// Eats `<` possibly breaking tokens like `<<` in process.\n+    /// Signals an error if `<` was not eaten.\n     fn expect_lt(&mut self) -> PResult<'a, ()> {\n-        if !self.eat_lt() { self.unexpected() } else { Ok(()) }\n+        if self.eat_lt() { Ok(()) } else { self.unexpected() }\n     }\n \n-    /// Expects and consumes a single `>` token. if a `>>` is seen, replaces it\n-    /// with a single `>` and continues. If a `>` is not seen, signals an error.\n+    /// Eats `>` possibly breaking tokens like `>>` in process.\n+    /// Signals an error if `>` was not eaten.\n     fn expect_gt(&mut self) -> PResult<'a, ()> {\n-        self.expected_tokens.push(TokenType::Token(token::Gt));\n-        let ate = match self.token.kind {\n-            token::Gt => {\n-                self.bump();\n-                Some(())\n-            }\n-            token::BinOp(token::Shr) => {\n-                let start_point = self.sess.source_map().start_point(self.token.span);\n-                Some(self.bump_with(token::Gt, self.token.span.with_lo(start_point.hi())))\n-            }\n-            token::BinOpEq(token::Shr) => {\n-                let start_point = self.sess.source_map().start_point(self.token.span);\n-                Some(self.bump_with(token::Ge, self.token.span.with_lo(start_point.hi())))\n-            }\n-            token::Ge => {\n-                let start_point = self.sess.source_map().start_point(self.token.span);\n-                Some(self.bump_with(token::Eq, self.token.span.with_lo(start_point.hi())))\n-            }\n-            _ => None,\n-        };\n-\n-        match ate {\n-            Some(_) => {\n-                // See doc comment for `unmatched_angle_bracket_count`.\n-                if self.unmatched_angle_bracket_count > 0 {\n-                    self.unmatched_angle_bracket_count -= 1;\n-                    debug!(\"expect_gt: (decrement) count={:?}\", self.unmatched_angle_bracket_count);\n-                }\n-\n-                Ok(())\n+        if self.break_and_eat(token::Gt) {\n+            // See doc comment for `unmatched_angle_bracket_count`.\n+            if self.unmatched_angle_bracket_count > 0 {\n+                self.unmatched_angle_bracket_count -= 1;\n+                debug!(\"expect_gt: (decrement) count={:?}\", self.unmatched_angle_bracket_count);\n             }\n-            None => self.unexpected(),\n+            Ok(())\n+        } else {\n+            self.unexpected()\n         }\n     }\n \n@@ -903,41 +838,30 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Advance the parser by one token.\n-    pub fn bump(&mut self) {\n+    /// Advance the parser by one token using provided token as the next one.\n+    fn bump_with(&mut self, next_token: Token) {\n+        // Bumping after EOF is a bad sign, usually an infinite loop.\n         if self.prev_token.kind == TokenKind::Eof {\n-            // Bumping after EOF is a bad sign, usually an infinite loop.\n             let msg = \"attempted to bump the parser past EOF (may be stuck in a loop)\";\n             self.span_bug(self.token.span, msg);\n         }\n \n         // Update the current and previous tokens.\n         self.prev_token = self.token.take();\n         self.unnormalized_prev_token = self.unnormalized_token.take();\n-        let next_token = self.next_tok(self.unnormalized_prev_token.span);\n         self.set_token(next_token);\n \n         // Update fields derived from the previous token.\n         self.prev_span = self.unnormalized_prev_token.span;\n \n+        // Diagnostics.\n         self.expected_tokens.clear();\n     }\n \n-    /// Advances the parser using provided token as a next one. Use this when\n-    /// consuming a part of a token. For example a single `<` from `<<`.\n-    /// FIXME: this function sets the previous token data to some semi-nonsensical values\n-    /// which kind of work because they are currently used in very limited ways in practice.\n-    /// Correct token kinds and spans need to be calculated instead.\n-    fn bump_with(&mut self, next: TokenKind, span: Span) {\n-        // Update the current and previous tokens.\n-        self.prev_token = self.token.take();\n-        self.unnormalized_prev_token = self.unnormalized_token.take();\n-        self.set_token(Token::new(next, span));\n-\n-        // Update fields derived from the previous token.\n-        self.prev_span = self.unnormalized_prev_token.span.with_hi(span.lo());\n-\n-        self.expected_tokens.clear();\n+    /// Advance the parser by one token.\n+    pub fn bump(&mut self) {\n+        let next_token = self.next_tok(self.unnormalized_token.span);\n+        self.bump_with(next_token);\n     }\n \n     /// Look-ahead `dist` tokens of `self.token` and get access to that token there."}, {"sha": "6eeee49881579606ab27497d798620cea6ba5296", "filename": "src/libsyntax/token.rs", "status": "modified", "additions": 33, "deletions": 0, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/d6414f5f8c30593cd250fddf315e6f0098c3239a/src%2Flibsyntax%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d6414f5f8c30593cd250fddf315e6f0098c3239a/src%2Flibsyntax%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftoken.rs?ref=d6414f5f8c30593cd250fddf315e6f0098c3239a", "patch": "@@ -270,6 +270,39 @@ impl TokenKind {\n         Literal(Lit::new(kind, symbol, suffix))\n     }\n \n+    // An approximation to proc-macro-style single-character operators used by rustc parser.\n+    // If the operator token can be broken into two tokens, the first of which is single-character,\n+    // then this function performs that operation, otherwise it returns `None`.\n+    pub fn break_two_token_op(&self) -> Option<(TokenKind, TokenKind)> {\n+        Some(match *self {\n+            Le => (Lt, Eq),\n+            EqEq => (Eq, Eq),\n+            Ne => (Not, Eq),\n+            Ge => (Gt, Eq),\n+            AndAnd => (BinOp(And), BinOp(And)),\n+            OrOr => (BinOp(Or), BinOp(Or)),\n+            BinOp(Shl) => (Lt, Lt),\n+            BinOp(Shr) => (Gt, Gt),\n+            BinOpEq(Plus) => (BinOp(Plus), Eq),\n+            BinOpEq(Minus) => (BinOp(Minus), Eq),\n+            BinOpEq(Star) => (BinOp(Star), Eq),\n+            BinOpEq(Slash) => (BinOp(Slash), Eq),\n+            BinOpEq(Percent) => (BinOp(Percent), Eq),\n+            BinOpEq(Caret) => (BinOp(Caret), Eq),\n+            BinOpEq(And) => (BinOp(And), Eq),\n+            BinOpEq(Or) => (BinOp(Or), Eq),\n+            BinOpEq(Shl) => (Lt, Le),\n+            BinOpEq(Shr) => (Gt, Ge),\n+            DotDot => (Dot, Dot),\n+            DotDotDot => (Dot, DotDot),\n+            ModSep => (Colon, Colon),\n+            RArrow => (BinOp(Minus), Gt),\n+            LArrow => (Lt, BinOp(Minus)),\n+            FatArrow => (Eq, Gt),\n+            _ => return None,\n+        })\n+    }\n+\n     /// Returns tokens that are likely to be typed accidentally instead of the current token.\n     /// Enables better error recovery when the wrong token is found.\n     pub fn similar_tokens(&self) -> Option<Vec<TokenKind>> {"}]}