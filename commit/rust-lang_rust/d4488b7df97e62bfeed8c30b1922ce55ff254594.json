{"sha": "d4488b7df97e62bfeed8c30b1922ce55ff254594", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ0NDg4YjdkZjk3ZTYyYmZlZWQ4YzMwYjE5MjJjZTU1ZmYyNTQ1OTQ=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-03-28T05:32:43Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-06-26T02:05:45Z"}, "message": "Simplify `hygiene::Mark` application, and\nremove variant `Token::SubstNt` in favor of `quoted::TokenTree::MetaVar`.", "tree": {"sha": "3e65f4bf53f191bba6ec937843a8a73e019686d6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3e65f4bf53f191bba6ec937843a8a73e019686d6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d4488b7df97e62bfeed8c30b1922ce55ff254594", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d4488b7df97e62bfeed8c30b1922ce55ff254594", "html_url": "https://github.com/rust-lang/rust/commit/d4488b7df97e62bfeed8c30b1922ce55ff254594", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d4488b7df97e62bfeed8c30b1922ce55ff254594/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fc9ccfdbe02f4cf3e3ea60ee4412f00d29ef7f53", "url": "https://api.github.com/repos/rust-lang/rust/commits/fc9ccfdbe02f4cf3e3ea60ee4412f00d29ef7f53", "html_url": "https://github.com/rust-lang/rust/commit/fc9ccfdbe02f4cf3e3ea60ee4412f00d29ef7f53"}], "stats": {"total": 332, "additions": 160, "deletions": 172}, "files": [{"sha": "4744baf1b42feb1da217212e17146b80440c5091", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 16, "deletions": 12, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -87,6 +87,8 @@ pub mod __internal {\n     use std::rc::Rc;\n \n     use syntax::ast;\n+    use syntax::ext::base::ExtCtxt;\n+    use syntax::ext::hygiene::Mark;\n     use syntax::ptr::P;\n     use syntax::parse::{self, token, ParseSess};\n     use syntax::tokenstream::{TokenTree, TokenStream as TokenStream_};\n@@ -107,7 +109,7 @@ pub mod __internal {\n     }\n \n     pub fn token_stream_parse_items(stream: TokenStream) -> Result<Vec<P<ast::Item>>, LexError> {\n-        with_parse_sess(move |sess| {\n+        with_sess(move |(sess, _)| {\n             let mut parser = parse::stream_to_parser(sess, stream.inner);\n             let mut items = Vec::new();\n \n@@ -140,13 +142,14 @@ pub mod __internal {\n \n     // Emulate scoped_thread_local!() here essentially\n     thread_local! {\n-        static CURRENT_SESS: Cell<*const ParseSess> = Cell::new(0 as *const _);\n+        static CURRENT_SESS: Cell<(*const ParseSess, Mark)> =\n+            Cell::new((0 as *const _, Mark::root()));\n     }\n \n-    pub fn set_parse_sess<F, R>(sess: &ParseSess, f: F) -> R\n+    pub fn set_sess<F, R>(cx: &ExtCtxt, f: F) -> R\n         where F: FnOnce() -> R\n     {\n-        struct Reset { prev: *const ParseSess }\n+        struct Reset { prev: (*const ParseSess, Mark) }\n \n         impl Drop for Reset {\n             fn drop(&mut self) {\n@@ -156,18 +159,18 @@ pub mod __internal {\n \n         CURRENT_SESS.with(|p| {\n             let _reset = Reset { prev: p.get() };\n-            p.set(sess);\n+            p.set((cx.parse_sess, cx.current_expansion.mark));\n             f()\n         })\n     }\n \n-    pub fn with_parse_sess<F, R>(f: F) -> R\n-        where F: FnOnce(&ParseSess) -> R\n+    pub fn with_sess<F, R>(f: F) -> R\n+        where F: FnOnce((&ParseSess, Mark)) -> R\n     {\n         let p = CURRENT_SESS.with(|p| p.get());\n-        assert!(!p.is_null(), \"proc_macro::__internal::with_parse_sess() called \\\n-                               before set_parse_sess()!\");\n-        f(unsafe { &*p })\n+        assert!(!p.0.is_null(), \"proc_macro::__internal::with_sess() called \\\n+                                 before set_parse_sess()!\");\n+        f(unsafe { (&*p.0, p.1) })\n     }\n }\n \n@@ -181,10 +184,11 @@ impl FromStr for TokenStream {\n     type Err = LexError;\n \n     fn from_str(src: &str) -> Result<TokenStream, LexError> {\n-        __internal::with_parse_sess(|sess| {\n+        __internal::with_sess(|(sess, mark)| {\n             let src = src.to_string();\n             let name = \"<proc-macro source code>\".to_string();\n-            let stream = parse::parse_stream_from_source_str(name, src, sess);\n+            let call_site = mark.expn_info().unwrap().call_site;\n+            let stream = parse::parse_stream_from_source_str(name, src, sess, Some(call_site));\n             Ok(__internal::token_stream_wrap(stream))\n         })\n     }"}, {"sha": "b827284271ed2235925313eadd31a1b662332fd8", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -283,8 +283,7 @@ fn hash_token<'a, 'gcx, 'tcx, W: StableHasherResult>(token: &token::Token,\n         }\n \n         token::Token::Ident(ident) |\n-        token::Token::Lifetime(ident) |\n-        token::Token::SubstNt(ident) => ident.name.hash_stable(hcx, hasher),\n+        token::Token::Lifetime(ident) => ident.name.hash_stable(hcx, hasher),\n \n         token::Token::Interpolated(ref non_terminal) => {\n             // FIXME(mw): This could be implemented properly. It's just a"}, {"sha": "0649553e382e344621cc699773634ff111a98aac", "filename": "src/librustc_metadata/cstore_impl.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibrustc_metadata%2Fcstore_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibrustc_metadata%2Fcstore_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcstore_impl.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -372,7 +372,7 @@ impl CrateStore for cstore::CStore {\n \n         let filemap = sess.parse_sess.codemap().new_filemap(source_name, def.body);\n         let local_span = Span { lo: filemap.start_pos, hi: filemap.end_pos, ctxt: NO_EXPANSION };\n-        let body = filemap_to_stream(&sess.parse_sess, filemap);\n+        let body = filemap_to_stream(&sess.parse_sess, filemap, None);\n \n         // Mark the attrs as used\n         let attrs = data.get_item_attrs(id.index, &self.dep_graph);"}, {"sha": "1f8c88d8ecf96d972623bcc721e533e59ceadada", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -319,7 +319,7 @@ impl<'a> Classifier<'a> {\n             token::Lifetime(..) => Class::Lifetime,\n \n             token::Underscore | token::Eof | token::Interpolated(..) |\n-            token::SubstNt(..) | token::Tilde | token::At => Class::None,\n+            token::Tilde | token::At => Class::None,\n         };\n \n         // Anything that didn't return above is the simple case where we the"}, {"sha": "af5eabf06f87b99211b5f1d63a16d5ef5c08c3d3", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 0, "deletions": 14, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -903,17 +903,3 @@ pub fn get_exprs_from_tts(cx: &mut ExtCtxt,\n     }\n     Some(es)\n }\n-\n-pub struct ChangeSpan {\n-    pub span: Span\n-}\n-\n-impl Folder for ChangeSpan {\n-    fn new_span(&mut self, _sp: Span) -> Span {\n-        self.span\n-    }\n-\n-    fn fold_mac(&mut self, mac: ast::Mac) -> ast::Mac {\n-        fold::noop_fold_mac(mac, self)\n-    }\n-}"}, {"sha": "11efef45499766d4c4262f9cc7f44326218244d4", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 16, "deletions": 20, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -16,7 +16,7 @@ use config::{is_test_or_bench, StripUnconfigured};\n use errors::FatalError;\n use ext::base::*;\n use ext::derive::{add_derived_markers, collect_derives};\n-use ext::hygiene::Mark;\n+use ext::hygiene::{Mark, SyntaxContext};\n use ext::placeholders::{placeholder, PlaceholderExpander};\n use feature_gate::{self, Features, is_builtin_attr};\n use fold;\n@@ -470,15 +470,14 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n             Ok(())\n         };\n \n-        let marked_tts = noop_fold_tts(mac.node.stream(), &mut Marker(mark));\n         let opt_expanded = match *ext {\n             SyntaxExtension::DeclMacro(ref expand, def_span) => {\n                 if let Err(msg) = validate_and_set_expn_info(def_span.map(|(_, s)| s),\n                                                              false) {\n                     self.cx.span_err(path.span, &msg);\n                     return kind.dummy(span);\n                 }\n-                kind.make_from(expand.expand(self.cx, span, marked_tts))\n+                kind.make_from(expand.expand(self.cx, span, mac.node.stream()))\n             }\n \n             NormalTT(ref expandfun, def_info, allow_internal_unstable) => {\n@@ -487,7 +486,7 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n                     self.cx.span_err(path.span, &msg);\n                     return kind.dummy(span);\n                 }\n-                kind.make_from(expandfun.expand(self.cx, span, marked_tts))\n+                kind.make_from(expandfun.expand(self.cx, span, mac.node.stream()))\n             }\n \n             IdentTT(ref expander, tt_span, allow_internal_unstable) => {\n@@ -506,7 +505,7 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n                     }\n                 });\n \n-                let input: Vec<_> = marked_tts.into_trees().collect();\n+                let input: Vec<_> = mac.node.stream().into_trees().collect();\n                 kind.make_from(expander.expand(self.cx, span, ident, input))\n             }\n \n@@ -541,21 +540,17 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n                     },\n                 });\n \n-                let tok_result = expandfun.expand(self.cx, span, marked_tts);\n+                let tok_result = expandfun.expand(self.cx, span, mac.node.stream());\n                 Some(self.parse_expansion(tok_result, kind, path, span))\n             }\n         };\n \n-        let expanded = if let Some(expanded) = opt_expanded {\n-            expanded\n-        } else {\n+        unwrap_or!(opt_expanded, {\n             let msg = format!(\"non-{kind} macro in {kind} position: {name}\",\n                               name = path.segments[0].identifier.name, kind = kind.name());\n             self.cx.span_err(path.span, &msg);\n-            return kind.dummy(span);\n-        };\n-\n-        expanded.fold_with(&mut Marker(mark))\n+            kind.dummy(span)\n+        })\n     }\n \n     /// Expand a derive invocation. Returns the result of expansion.\n@@ -621,8 +616,7 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n             }\n         };\n         parser.ensure_complete_parse(path, kind.name(), span);\n-        // FIXME better span info\n-        expansion.fold_with(&mut ChangeSpan { span: span })\n+        expansion\n     }\n }\n \n@@ -673,7 +667,9 @@ impl<'a> Parser<'a> {\n         if self.token != token::Eof {\n             let msg = format!(\"macro expansion ignores token `{}` and any following\",\n                               self.this_token_to_string());\n-            let mut err = self.diagnostic().struct_span_err(self.span, &msg);\n+            let mut def_site_span = self.span;\n+            def_site_span.ctxt = SyntaxContext::empty(); // Avoid emitting backtrace info twice.\n+            let mut err = self.diagnostic().struct_span_err(def_site_span, &msg);\n             let msg = format!(\"caused by the macro expansion here; the usage \\\n                                of `{}!` is likely invalid in {} context\",\n                                macro_path, kind_name);\n@@ -787,12 +783,12 @@ fn stream_for_item(item: &Annotatable, parse_sess: &ParseSess) -> TokenStream {\n         Annotatable::TraitItem(ref ti) => pprust::trait_item_to_string(ti),\n         Annotatable::ImplItem(ref ii) => pprust::impl_item_to_string(ii),\n     };\n-    string_to_stream(text, parse_sess)\n+    string_to_stream(text, parse_sess, item.span())\n }\n \n-fn string_to_stream(text: String, parse_sess: &ParseSess) -> TokenStream {\n+fn string_to_stream(text: String, parse_sess: &ParseSess, span: Span) -> TokenStream {\n     let filename = String::from(\"<macro expansion>\");\n-    filemap_to_stream(parse_sess, parse_sess.codemap().new_filemap(filename, text))\n+    filemap_to_stream(parse_sess, parse_sess.codemap().new_filemap(filename, text), Some(span))\n }\n \n impl<'a, 'b> Folder for InvocationCollector<'a, 'b> {\n@@ -1070,7 +1066,7 @@ impl<'feat> ExpansionConfig<'feat> {\n }\n \n // A Marker adds the given mark to the syntax context.\n-struct Marker(Mark);\n+pub struct Marker(pub Mark);\n \n impl Folder for Marker {\n     fn fold_ident(&mut self, mut ident: Ident) -> Ident {"}, {"sha": "314a97496f8cc1a327e829f055630db0f5a71a61", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -364,7 +364,7 @@ pub mod rt {\n \n         fn parse_tts(&self, s: String) -> Vec<TokenTree> {\n             let source_name = \"<quote expansion>\".to_owned();\n-            parse::parse_stream_from_source_str(source_name, s, self.parse_sess())\n+            parse::parse_stream_from_source_str(source_name, s, self.parse_sess(), None)\n                 .into_trees().collect()\n         }\n     }\n@@ -700,7 +700,7 @@ fn expr_mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n         token::Underscore   => \"Underscore\",\n         token::Eof          => \"Eof\",\n \n-        token::Whitespace | token::SubstNt(_) | token::Comment | token::Shebang(_) => {\n+        token::Whitespace | token::Comment | token::Shebang(_) => {\n             panic!(\"unhandled token in quote!\");\n         }\n     };"}, {"sha": "e877f1fedd40980c08f1f921cc78e95d80fe7a31", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 9, "deletions": 15, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -158,15 +158,10 @@ pub type NamedParseResult = ParseResult<HashMap<Ident, Rc<NamedMatch>>>;\n pub fn count_names(ms: &[TokenTree]) -> usize {\n     ms.iter().fold(0, |count, elt| {\n         count + match *elt {\n-            TokenTree::Sequence(_, ref seq) => {\n-                seq.num_captures\n-            }\n-            TokenTree::Delimited(_, ref delim) => {\n-                count_names(&delim.tts)\n-            }\n-            TokenTree::MetaVarDecl(..) => {\n-                1\n-            }\n+            TokenTree::Sequence(_, ref seq) => seq.num_captures,\n+            TokenTree::Delimited(_, ref delim) => count_names(&delim.tts),\n+            TokenTree::MetaVar(..) => 0,\n+            TokenTree::MetaVarDecl(..) => 1,\n             TokenTree::Token(..) => 0,\n         }\n     })\n@@ -244,7 +239,7 @@ fn nameize<I: Iterator<Item=NamedMatch>>(sess: &ParseSess, ms: &[TokenTree], mut\n                     }\n                 }\n             }\n-            TokenTree::Token(..) => (),\n+            TokenTree::MetaVar(..) | TokenTree::Token(..) => (),\n         }\n \n         Ok(())\n@@ -409,12 +404,11 @@ fn inner_parse_loop(sess: &ParseSess,\n                     ei.idx = 0;\n                     cur_eis.push(ei);\n                 }\n-                TokenTree::Token(_, ref t) => {\n-                    if token_name_eq(t, token) {\n-                        ei.idx += 1;\n-                        next_eis.push(ei);\n-                    }\n+                TokenTree::Token(_, ref t) if token_name_eq(t, token) => {\n+                    ei.idx += 1;\n+                    next_eis.push(ei);\n                 }\n+                TokenTree::Token(..) | TokenTree::MetaVar(..) => {}\n             }\n         }\n     }"}, {"sha": "b732f47ce6a93da34d7fdbb87e2169e5d9a376fc", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -120,7 +120,7 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt,\n                     _ => cx.span_bug(sp, \"malformed macro rhs\"),\n                 };\n                 // rhs has holes ( `$id` and `$(...)` that need filled)\n-                let tts = transcribe(&cx.parse_sess.span_diagnostic, Some(named_matches), rhs);\n+                let tts = transcribe(cx, Some(named_matches), rhs);\n \n                 if cx.trace_macros() {\n                     trace_macros_note(cx, sp, format!(\"to `{}`\", tts));\n@@ -292,7 +292,7 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n     use self::quoted::TokenTree;\n     for tt in tts {\n         match *tt {\n-            TokenTree::Token(..) | TokenTree::MetaVarDecl(..) => (),\n+            TokenTree::Token(..) | TokenTree::MetaVar(..) | TokenTree::MetaVarDecl(..) => (),\n             TokenTree::Delimited(_, ref del) => if !check_lhs_no_empty_seq(sess, &del.tts) {\n                 return false;\n             },\n@@ -372,7 +372,7 @@ impl FirstSets {\n             let mut first = TokenSet::empty();\n             for tt in tts.iter().rev() {\n                 match *tt {\n-                    TokenTree::Token(..) | TokenTree::MetaVarDecl(..) => {\n+                    TokenTree::Token(..) | TokenTree::MetaVar(..) | TokenTree::MetaVarDecl(..) => {\n                         first.replace_with(tt.clone());\n                     }\n                     TokenTree::Delimited(span, ref delimited) => {\n@@ -432,7 +432,7 @@ impl FirstSets {\n         for tt in tts.iter() {\n             assert!(first.maybe_empty);\n             match *tt {\n-                TokenTree::Token(..) | TokenTree::MetaVarDecl(..) => {\n+                TokenTree::Token(..) | TokenTree::MetaVar(..) | TokenTree::MetaVarDecl(..) => {\n                     first.add_one(tt.clone());\n                     return first;\n                 }\n@@ -602,7 +602,7 @@ fn check_matcher_core(sess: &ParseSess,\n         // First, update `last` so that it corresponds to the set\n         // of NT tokens that might end the sequence `... token`.\n         match *token {\n-            TokenTree::Token(..) | TokenTree::MetaVarDecl(..) => {\n+            TokenTree::Token(..) | TokenTree::MetaVar(..) | TokenTree::MetaVarDecl(..) => {\n                 let can_be_followed_by_any;\n                 if let Err(bad_frag) = has_legal_fragment_specifier(sess, features, token) {\n                     let msg = format!(\"invalid fragment specifier `{}`\", bad_frag);\n@@ -872,6 +872,7 @@ fn is_legal_fragment_specifier(sess: &ParseSess,\n fn quoted_tt_to_string(tt: &quoted::TokenTree) -> String {\n     match *tt {\n         quoted::TokenTree::Token(_, ref tok) => ::print::pprust::token_to_string(tok),\n+        quoted::TokenTree::MetaVar(_, name) => format!(\"${}\", name),\n         quoted::TokenTree::MetaVarDecl(_, name, kind) => format!(\"${}:{}\", name, kind),\n         _ => panic!(\"unexpected quoted::TokenTree::{{Sequence or Delimited}} \\\n                      in follow set checker\"),"}, {"sha": "18056f6028745ba7783e8e62c4ba78d11d89d9f6", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -78,9 +78,11 @@ pub enum KleeneOp {\n pub enum TokenTree {\n     Token(Span, token::Token),\n     Delimited(Span, Rc<Delimited>),\n-    /// A kleene-style repetition sequence with a span\n+    /// A kleene-style repetition sequence\n     Sequence(Span, Rc<SequenceRepetition>),\n-    /// Matches a nonterminal. This is only used in the left hand side of MBE macros.\n+    /// E.g. `$var`\n+    MetaVar(Span, ast::Ident),\n+    /// E.g. `$var:expr`. This is only used in the left hand side of MBE macros.\n     MetaVarDecl(Span, ast::Ident /* name to bind */, ast::Ident /* kind of nonterminal */),\n }\n \n@@ -130,6 +132,7 @@ impl TokenTree {\n     pub fn span(&self) -> Span {\n         match *self {\n             TokenTree::Token(sp, _) |\n+            TokenTree::MetaVar(sp, _) |\n             TokenTree::MetaVarDecl(sp, _, _) |\n             TokenTree::Delimited(sp, _) |\n             TokenTree::Sequence(sp, _) => sp,\n@@ -144,7 +147,7 @@ pub fn parse(input: tokenstream::TokenStream, expect_matchers: bool, sess: &Pars\n     while let Some(tree) = trees.next() {\n         let tree = parse_tree(tree, &mut trees, expect_matchers, sess);\n         match tree {\n-            TokenTree::Token(start_sp, token::SubstNt(ident)) if expect_matchers => {\n+            TokenTree::MetaVar(start_sp, ident) if expect_matchers => {\n                 let span = match trees.next() {\n                     Some(tokenstream::TokenTree::Token(span, token::Colon)) => match trees.next() {\n                         Some(tokenstream::TokenTree::Token(end_sp, ref tok)) => match tok.ident() {\n@@ -199,13 +202,13 @@ fn parse_tree<I>(tree: tokenstream::TokenTree,\n                     let ident = ast::Ident { name: Symbol::intern(\"$crate\"), ..ident };\n                     TokenTree::Token(span, token::Ident(ident))\n                 } else {\n-                    TokenTree::Token(span, token::SubstNt(ident))\n+                    TokenTree::MetaVar(span, ident)\n                 }\n             }\n             Some(tokenstream::TokenTree::Token(span, tok)) => {\n                 let msg = format!(\"expected identifier, found `{}`\", pprust::token_to_string(&tok));\n                 sess.span_diagnostic.span_err(span, &msg);\n-                TokenTree::Token(span, token::SubstNt(keywords::Invalid.ident()))\n+                TokenTree::MetaVar(span, keywords::Invalid.ident())\n             }\n             None => TokenTree::Token(span, token::Dollar),\n         },"}, {"sha": "9438e2fb0e5bffa44466c59ac2bc9e88b215c338", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 34, "deletions": 26, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -9,10 +9,12 @@\n // except according to those terms.\n \n use ast::Ident;\n-use errors::Handler;\n+use ext::base::ExtCtxt;\n+use ext::expand::Marker;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n use ext::tt::quoted;\n-use parse::token::{self, SubstNt, Token, NtTT};\n+use fold::noop_fold_tt;\n+use parse::token::{self, Token, NtTT};\n use syntax_pos::{Span, DUMMY_SP};\n use tokenstream::{TokenStream, TokenTree, Delimited};\n use util::small_vector::SmallVector;\n@@ -61,9 +63,9 @@ impl Iterator for Frame {\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TokenTree::{Sequence, Match}`s, or `SubstNt`s, `interp` can\n+/// `src` contains no `TokenTree::{Sequence, MetaVar, MetaVarDecl}`s, `interp` can\n /// (and should) be None.\n-pub fn transcribe(sp_diag: &Handler,\n+pub fn transcribe(cx: &ExtCtxt,\n                   interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n                   src: Vec<quoted::TokenTree>)\n                   -> TokenStream {\n@@ -120,22 +122,20 @@ pub fn transcribe(sp_diag: &Handler,\n                                          &interpolations,\n                                          &repeats) {\n                     LockstepIterSize::Unconstrained => {\n-                        panic!(sp_diag.span_fatal(\n-                            sp, /* blame macro writer */\n+                        cx.span_fatal(sp, /* blame macro writer */\n                             \"attempted to repeat an expression \\\n                              containing no syntax \\\n-                             variables matched as repeating at this depth\"));\n+                             variables matched as repeating at this depth\");\n                     }\n                     LockstepIterSize::Contradiction(ref msg) => {\n                         // FIXME #2887 blame macro invoker instead\n-                        panic!(sp_diag.span_fatal(sp, &msg[..]));\n+                        cx.span_fatal(sp, &msg[..]);\n                     }\n                     LockstepIterSize::Constraint(len, _) => {\n                         if len == 0 {\n                             if seq.op == quoted::KleeneOp::OneOrMore {\n                                 // FIXME #2887 blame invoker\n-                                panic!(sp_diag.span_fatal(sp,\n-                                                          \"this must repeat at least once\"));\n+                                cx.span_fatal(sp, \"this must repeat at least once\");\n                             }\n                         } else {\n                             repeats.push((0, len));\n@@ -149,29 +149,37 @@ pub fn transcribe(sp_diag: &Handler,\n                 }\n             }\n             // FIXME #2887: think about span stuff here\n-            quoted::TokenTree::Token(sp, SubstNt(ident)) => {\n-                match lookup_cur_matched(ident, &interpolations, &repeats) {\n-                    None => result.push(TokenTree::Token(sp, SubstNt(ident)).into()),\n-                    Some(cur_matched) => if let MatchedNonterminal(ref nt) = *cur_matched {\n-                        match **nt {\n-                            NtTT(ref tt) => result.push(tt.clone().into()),\n-                            _ => {\n-                                let token = TokenTree::Token(sp, token::Interpolated(nt.clone()));\n-                                result.push(token.into());\n-                            }\n+            quoted::TokenTree::MetaVar(mut sp, ident) => {\n+                if let Some(cur_matched) = lookup_cur_matched(ident, &interpolations, &repeats) {\n+                    if let MatchedNonterminal(ref nt) = *cur_matched {\n+                        if let NtTT(ref tt) = **nt {\n+                            result.push(tt.clone().into());\n+                        } else {\n+                            sp.ctxt = sp.ctxt.apply_mark(cx.current_expansion.mark);\n+                            let token = TokenTree::Token(sp, token::Interpolated(nt.clone()));\n+                            result.push(token.into());\n                         }\n                     } else {\n-                        panic!(sp_diag.span_fatal(\n-                            sp, /* blame the macro writer */\n-                            &format!(\"variable '{}' is still repeating at this depth\", ident)));\n+                        cx.span_fatal(sp, /* blame the macro writer */\n+                            &format!(\"variable '{}' is still repeating at this depth\", ident));\n                     }\n+                } else {\n+                    let ident =\n+                        Ident { ctxt: ident.ctxt.apply_mark(cx.current_expansion.mark), ..ident };\n+                    sp.ctxt = sp.ctxt.apply_mark(cx.current_expansion.mark);\n+                    result.push(TokenTree::Token(sp, token::Dollar).into());\n+                    result.push(TokenTree::Token(sp, token::Ident(ident)).into());\n                 }\n             }\n-            quoted::TokenTree::Delimited(span, delimited) => {\n+            quoted::TokenTree::Delimited(mut span, delimited) => {\n+                span.ctxt = span.ctxt.apply_mark(cx.current_expansion.mark);\n                 stack.push(Frame::Delimited { forest: delimited, idx: 0, span: span });\n                 result_stack.push(mem::replace(&mut result, Vec::new()));\n             }\n-            quoted::TokenTree::Token(span, tok) => result.push(TokenTree::Token(span, tok).into()),\n+            quoted::TokenTree::Token(sp, tok) => {\n+                let mut marker = Marker(cx.current_expansion.mark);\n+                result.push(noop_fold_tt(TokenTree::Token(sp, tok), &mut marker).into())\n+            }\n             quoted::TokenTree::MetaVarDecl(..) => panic!(\"unexpected `TokenTree::MetaVarDecl\"),\n         }\n     }\n@@ -240,7 +248,7 @@ fn lockstep_iter_size(tree: &quoted::TokenTree,\n                 size + lockstep_iter_size(tt, interpolations, repeats)\n             })\n         },\n-        TokenTree::Token(_, SubstNt(name)) | TokenTree::MetaVarDecl(_, name, _) =>\n+        TokenTree::MetaVar(_, name) | TokenTree::MetaVarDecl(_, name, _) =>\n             match lookup_cur_matched(name, interpolations, repeats) {\n                 Some(matched) => match *matched {\n                     MatchedNonterminal(_) => LockstepIterSize::Unconstrained,"}, {"sha": "2032aecacbb9102a67d2a46a480c47479c47abb9", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -588,7 +588,6 @@ pub fn noop_fold_token<T: Folder>(t: token::Token, fld: &mut T) -> token::Token\n             };\n             token::Interpolated(Rc::new(fld.fold_interpolated(nt)))\n         }\n-        token::SubstNt(ident) => token::SubstNt(fld.fold_ident(ident)),\n         _ => t\n     }\n }"}, {"sha": "afc1e583d69bb7a0928f1488ee40f3858b55f03b", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 22, "deletions": 20, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -66,14 +66,15 @@ pub struct StringReader<'a> {\n     token: token::Token,\n     span: Span,\n     open_braces: Vec<(token::DelimToken, Span)>,\n-}\n-\n-fn mk_sp(lo: BytePos, hi: BytePos) -> Span {\n-    Span { lo: lo, hi: hi, ctxt: NO_EXPANSION }\n+    pub override_span: Option<Span>,\n }\n \n impl<'a> StringReader<'a> {\n-    fn next_token(&mut self) -> TokenAndSpan {\n+    fn mk_sp(&self, lo: BytePos, hi: BytePos) -> Span {\n+        unwrap_or!(self.override_span, Span { lo: lo, hi: hi, ctxt: NO_EXPANSION})\n+    }\n+\n+    fn next_token(&mut self) -> TokenAndSpan where Self: Sized {\n         let res = self.try_next_token();\n         self.unwrap_or_abort(res)\n     }\n@@ -175,6 +176,7 @@ impl<'a> StringReader<'a> {\n             token: token::Eof,\n             span: syntax_pos::DUMMY_SP,\n             open_braces: Vec::new(),\n+            override_span: None,\n         }\n     }\n \n@@ -229,12 +231,12 @@ impl<'a> StringReader<'a> {\n \n     /// Report a fatal error spanning [`from_pos`, `to_pos`).\n     fn fatal_span_(&self, from_pos: BytePos, to_pos: BytePos, m: &str) -> FatalError {\n-        self.fatal_span(mk_sp(from_pos, to_pos), m)\n+        self.fatal_span(self.mk_sp(from_pos, to_pos), m)\n     }\n \n     /// Report a lexical error spanning [`from_pos`, `to_pos`).\n     fn err_span_(&self, from_pos: BytePos, to_pos: BytePos, m: &str) {\n-        self.err_span(mk_sp(from_pos, to_pos), m)\n+        self.err_span(self.mk_sp(from_pos, to_pos), m)\n     }\n \n     /// Report a lexical error spanning [`from_pos`, `to_pos`), appending an\n@@ -258,7 +260,7 @@ impl<'a> StringReader<'a> {\n         for c in c.escape_default() {\n             m.push(c)\n         }\n-        self.sess.span_diagnostic.struct_span_fatal(mk_sp(from_pos, to_pos), &m[..])\n+        self.sess.span_diagnostic.struct_span_fatal(self.mk_sp(from_pos, to_pos), &m[..])\n     }\n \n     /// Report a lexical error spanning [`from_pos`, `to_pos`), appending an\n@@ -282,7 +284,7 @@ impl<'a> StringReader<'a> {\n         for c in c.escape_default() {\n             m.push(c)\n         }\n-        self.sess.span_diagnostic.struct_span_err(mk_sp(from_pos, to_pos), &m[..])\n+        self.sess.span_diagnostic.struct_span_err(self.mk_sp(from_pos, to_pos), &m[..])\n     }\n \n     /// Report a lexical error spanning [`from_pos`, `to_pos`), appending the\n@@ -306,11 +308,11 @@ impl<'a> StringReader<'a> {\n             None => {\n                 if self.is_eof() {\n                     self.peek_tok = token::Eof;\n-                    self.peek_span = mk_sp(self.filemap.end_pos, self.filemap.end_pos);\n+                    self.peek_span = self.mk_sp(self.filemap.end_pos, self.filemap.end_pos);\n                 } else {\n                     let start_bytepos = self.pos;\n                     self.peek_tok = self.next_token_inner()?;\n-                    self.peek_span = mk_sp(start_bytepos, self.pos);\n+                    self.peek_span = self.mk_sp(start_bytepos, self.pos);\n                 };\n             }\n         }\n@@ -502,7 +504,7 @@ impl<'a> StringReader<'a> {\n         if let Some(c) = self.ch {\n             if c.is_whitespace() {\n                 let msg = \"called consume_any_line_comment, but there was whitespace\";\n-                self.sess.span_diagnostic.span_err(mk_sp(self.pos, self.pos), msg);\n+                self.sess.span_diagnostic.span_err(self.mk_sp(self.pos, self.pos), msg);\n             }\n         }\n \n@@ -545,13 +547,13 @@ impl<'a> StringReader<'a> {\n \n                             Some(TokenAndSpan {\n                                 tok: tok,\n-                                sp: mk_sp(start_bpos, self.pos),\n+                                sp: self.mk_sp(start_bpos, self.pos),\n                             })\n                         })\n                     } else {\n                         Some(TokenAndSpan {\n                             tok: token::Comment,\n-                            sp: mk_sp(start_bpos, self.pos),\n+                            sp: self.mk_sp(start_bpos, self.pos),\n                         })\n                     }\n                 }\n@@ -584,7 +586,7 @@ impl<'a> StringReader<'a> {\n                     }\n                     return Some(TokenAndSpan {\n                         tok: token::Shebang(self.name_from(start)),\n-                        sp: mk_sp(start, self.pos),\n+                        sp: self.mk_sp(start, self.pos),\n                     });\n                 }\n             }\n@@ -612,7 +614,7 @@ impl<'a> StringReader<'a> {\n                 }\n                 let c = Some(TokenAndSpan {\n                     tok: token::Whitespace,\n-                    sp: mk_sp(start_bpos, self.pos),\n+                    sp: self.mk_sp(start_bpos, self.pos),\n                 });\n                 debug!(\"scanning whitespace: {:?}\", c);\n                 c\n@@ -674,7 +676,7 @@ impl<'a> StringReader<'a> {\n \n             Some(TokenAndSpan {\n                 tok: tok,\n-                sp: mk_sp(start_bpos, self.pos),\n+                sp: self.mk_sp(start_bpos, self.pos),\n             })\n         })\n     }\n@@ -869,7 +871,7 @@ impl<'a> StringReader<'a> {\n                                 let valid = if self.ch_is('{') {\n                                     self.scan_unicode_escape(delim) && !ascii_only\n                                 } else {\n-                                    let span = mk_sp(start, self.pos);\n+                                    let span = self.mk_sp(start, self.pos);\n                                     self.sess.span_diagnostic\n                                         .struct_span_err(span, \"incorrect unicode escape sequence\")\n                                         .span_help(span,\n@@ -907,13 +909,13 @@ impl<'a> StringReader<'a> {\n                                                                         },\n                                                                         c);\n                                 if e == '\\r' {\n-                                    err.span_help(mk_sp(escaped_pos, pos),\n+                                    err.span_help(self.mk_sp(escaped_pos, pos),\n                                                   \"this is an isolated carriage return; consider \\\n                                                    checking your editor and version control \\\n                                                    settings\");\n                                 }\n                                 if (e == '{' || e == '}') && !ascii_only {\n-                                    err.span_help(mk_sp(escaped_pos, pos),\n+                                    err.span_help(self.mk_sp(escaped_pos, pos),\n                                                   \"if used in a formatting string, curly braces \\\n                                                    are escaped with `{{` and `}}`\");\n                                 }"}, {"sha": "f917eec2cd0b13ec7f85f856c83c740ce6fe7699", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -141,9 +141,10 @@ pub fn parse_stmt_from_source_str(name: String, source: String, sess: &ParseSess\n     new_parser_from_source_str(sess, name, source).parse_stmt()\n }\n \n-pub fn parse_stream_from_source_str(name: String, source: String, sess: &ParseSess)\n-                                        -> TokenStream {\n-    filemap_to_stream(sess, sess.codemap().new_filemap(name, source))\n+pub fn parse_stream_from_source_str(name: String, source: String, sess: &ParseSess,\n+                                    override_span: Option<Span>)\n+                                    -> TokenStream {\n+    filemap_to_stream(sess, sess.codemap().new_filemap(name, source), override_span)\n }\n \n // Create a new parser from a source string\n@@ -177,7 +178,7 @@ pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n /// Given a filemap and config, return a parser\n pub fn filemap_to_parser(sess: & ParseSess, filemap: Rc<FileMap>, ) -> Parser {\n     let end_pos = filemap.end_pos;\n-    let mut parser = stream_to_parser(sess, filemap_to_stream(sess, filemap));\n+    let mut parser = stream_to_parser(sess, filemap_to_stream(sess, filemap, None));\n \n     if parser.token == token::Eof && parser.span == syntax_pos::DUMMY_SP {\n         parser.span = Span { lo: end_pos, hi: end_pos, ctxt: NO_EXPANSION };\n@@ -212,8 +213,10 @@ fn file_to_filemap(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n }\n \n /// Given a filemap, produce a sequence of token-trees\n-pub fn filemap_to_stream(sess: &ParseSess, filemap: Rc<FileMap>) -> TokenStream {\n+pub fn filemap_to_stream(sess: &ParseSess, filemap: Rc<FileMap>, override_span: Option<Span>)\n+                         -> TokenStream {\n     let mut srdr = lexer::StringReader::new(sess, filemap);\n+    srdr.override_span = override_span;\n     srdr.real_token();\n     panictry!(srdr.parse_all_token_trees())\n }"}, {"sha": "25ab46f6f9e2bad1067f0cf5d16c60a1aefb2ed7", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -2626,7 +2626,10 @@ impl<'a> Parser<'a> {\n \n     pub fn process_potential_macro_variable(&mut self) {\n         let ident = match self.token {\n-            token::SubstNt(name) => {\n+            token::Dollar if self.span.ctxt != syntax_pos::hygiene::SyntaxContext::empty() &&\n+                             self.look_ahead(1, |t| t.is_ident()) => {\n+                self.bump();\n+                let name = match self.token { token::Ident(ident) => ident, _ => unreachable!() };\n                 self.fatal(&format!(\"unknown macro variable `{}`\", name)).emit();\n                 return\n             }"}, {"sha": "f208b0f56f81ec66a81ec7120ce5b6b08432d299", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -172,9 +172,6 @@ pub enum Token {\n     // Can be expanded into several tokens.\n     /// Doc comment\n     DocComment(ast::Name),\n-    // In right-hand-sides of MBE macros:\n-    /// A syntactic variable that will be filled in by macro expansion.\n-    SubstNt(ast::Ident),\n \n     // Junk. These carry no data because we don't really care about the data\n     // they *would* carry, and don't really want to allocate a new ident for"}, {"sha": "6c6ca556e35ed91ac4712626d14e2e6b4ed39a89", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -270,7 +270,6 @@ pub fn token_to_string(tok: &Token) -> String {\n \n         /* Other */\n         token::DocComment(s)        => s.to_string(),\n-        token::SubstNt(s)           => format!(\"${}\", s),\n         token::Eof                  => \"<eof>\".to_string(),\n         token::Whitespace           => \" \".to_string(),\n         token::Comment              => \"/* */\".to_string(),"}, {"sha": "6f4c112acb6c6430eadb8b34608e2c08bdb5ae8c", "filename": "src/libsyntax_ext/concat_idents.rs", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_ext%2Fconcat_idents.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_ext%2Fconcat_idents.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fconcat_idents.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -15,6 +15,8 @@ use syntax::feature_gate;\n use syntax::parse::token;\n use syntax::ptr::P;\n use syntax_pos::Span;\n+use syntax_pos::symbol::Symbol;\n+use syntax_pos::hygiene::SyntaxContext;\n use syntax::tokenstream::TokenTree;\n \n pub fn expand_syntax_ext<'cx>(cx: &'cx mut ExtCtxt,\n@@ -50,7 +52,10 @@ pub fn expand_syntax_ext<'cx>(cx: &'cx mut ExtCtxt,\n             }\n         }\n     }\n-    let res = ast::Ident::from_str(&res_str);\n+    let res = ast::Ident {\n+        name: Symbol::intern(&res_str),\n+        ctxt: SyntaxContext::empty().apply_mark(cx.current_expansion.mark),\n+    };\n \n     struct Result {\n         ident: ast::Ident,"}, {"sha": "fa5537b5d8fe3e93f18da7581c992891d8e64f12", "filename": "src/libsyntax_ext/deriving/custom.rs", "status": "modified", "additions": 4, "deletions": 11, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fderiving%2Fcustom.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -16,7 +16,6 @@ use syntax::ast::{self, ItemKind, Attribute, Mac};\n use syntax::attr::{mark_used, mark_known};\n use syntax::codemap::Span;\n use syntax::ext::base::*;\n-use syntax::fold::Folder;\n use syntax::visit::Visitor;\n \n struct MarkAttrs<'a>(&'a [ast::Name]);\n@@ -75,7 +74,7 @@ impl MultiItemModifier for ProcMacroDerive {\n         MarkAttrs(&self.attrs).visit_item(&item);\n \n         let input = __internal::new_token_stream(ecx.resolver.eliminate_crate_var(item.clone()));\n-        let res = __internal::set_parse_sess(&ecx.parse_sess, || {\n+        let res = __internal::set_sess(ecx, || {\n             let inner = self.inner;\n             panic::catch_unwind(panic::AssertUnwindSafe(|| inner(input)))\n         });\n@@ -97,22 +96,16 @@ impl MultiItemModifier for ProcMacroDerive {\n             }\n         };\n \n-        let new_items = __internal::set_parse_sess(&ecx.parse_sess, || {\n+        __internal::set_sess(ecx, || {\n             match __internal::token_stream_parse_items(stream) {\n-                Ok(new_items) => new_items,\n+                Ok(new_items) => new_items.into_iter().map(Annotatable::Item).collect(),\n                 Err(_) => {\n                     // FIXME: handle this better\n                     let msg = \"proc-macro derive produced unparseable tokens\";\n                     ecx.struct_span_fatal(span, msg).emit();\n                     panic!(FatalError);\n                 }\n             }\n-        });\n-\n-        // Reassign spans of all expanded items to the input `item`\n-        // for better errors here.\n-        new_items.into_iter().map(|item| {\n-            Annotatable::Item(ChangeSpan { span: span }.fold_item(item).expect_one(\"\"))\n-        }).collect()\n+        })\n     }\n }"}, {"sha": "144d1930df90b54d3b99f77118fe477ec85eb469", "filename": "src/libsyntax_ext/format.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_ext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_ext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fformat.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -20,7 +20,7 @@ use syntax::ext::build::AstBuilder;\n use syntax::parse::token;\n use syntax::ptr::P;\n use syntax::symbol::{Symbol, keywords};\n-use syntax_pos::{Span, DUMMY_SP};\n+use syntax_pos::Span;\n use syntax::tokenstream;\n \n use std::collections::{HashMap, HashSet};\n@@ -558,7 +558,9 @@ impl<'a, 'b> Context<'a, 'b> {\n         // passed to this function.\n         for (i, e) in self.args.into_iter().enumerate() {\n             let name = self.ecx.ident_of(&format!(\"__arg{}\", i));\n-            pats.push(self.ecx.pat_ident(DUMMY_SP, name));\n+            let span =\n+                Span { ctxt: e.span.ctxt.apply_mark(self.ecx.current_expansion.mark), ..e.span };\n+            pats.push(self.ecx.pat_ident(span, name));\n             for ref arg_ty in self.arg_unique_types[i].iter() {\n                 locals.push(Context::format_arg(self.ecx, self.macsp, e.span, arg_ty, name));\n             }\n@@ -672,10 +674,10 @@ impl<'a, 'b> Context<'a, 'b> {\n }\n \n pub fn expand_format_args<'cx>(ecx: &'cx mut ExtCtxt,\n-                               sp: Span,\n+                               mut sp: Span,\n                                tts: &[tokenstream::TokenTree])\n                                -> Box<base::MacResult + 'cx> {\n-\n+    sp.ctxt = sp.ctxt.apply_mark(ecx.current_expansion.mark);\n     match parse_args(ecx, sp, tts) {\n         Some((efmt, args, names)) => {\n             MacEager::expr(expand_preparsed_format_args(ecx, sp, efmt, args, names))\n@@ -696,7 +698,8 @@ pub fn expand_preparsed_format_args(ecx: &mut ExtCtxt,\n     // `ArgumentType` does not derive `Clone`.\n     let arg_types: Vec<_> = (0..args.len()).map(|_| Vec::new()).collect();\n     let arg_unique_types: Vec<_> = (0..args.len()).map(|_| Vec::new()).collect();\n-    let macsp = ecx.call_site();\n+    let mut macsp = ecx.call_site();\n+    macsp.ctxt = macsp.ctxt.apply_mark(ecx.current_expansion.mark);\n     let msg = \"format argument must be a string literal.\";\n     let fmt = match expr_to_spanned_string(ecx, efmt, msg) {\n         Some(fmt) => fmt,"}, {"sha": "5fcedbf50c60f71caeba36d8c8811acab084f204", "filename": "src/libsyntax_ext/proc_macro_impl.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_ext%2Fproc_macro_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_ext%2Fproc_macro_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fproc_macro_impl.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -34,7 +34,7 @@ impl base::AttrProcMacro for AttrProcMacro {\n         let annotation = __internal::token_stream_wrap(annotation);\n         let annotated = __internal::token_stream_wrap(annotated);\n \n-        let res = __internal::set_parse_sess(&ecx.parse_sess, || {\n+        let res = __internal::set_sess(ecx, || {\n             panic::catch_unwind(panic::AssertUnwindSafe(|| (self.inner)(annotation, annotated)))\n         });\n \n@@ -69,7 +69,7 @@ impl base::ProcMacro for BangProcMacro {\n                    -> TokenStream {\n         let input = __internal::token_stream_wrap(input);\n \n-        let res = __internal::set_parse_sess(&ecx.parse_sess, || {\n+        let res = __internal::set_sess(ecx, || {\n             panic::catch_unwind(panic::AssertUnwindSafe(|| (self.inner)(input)))\n         });\n "}, {"sha": "804b91ab09e3c333363305262763886f8de88cbd", "filename": "src/libsyntax_pos/hygiene.rs", "status": "modified", "additions": 9, "deletions": 15, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_pos%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_pos%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fhygiene.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -144,24 +144,18 @@ impl SyntaxContext {\n     pub fn apply_mark(self, mark: Mark) -> SyntaxContext {\n         HygieneData::with(|data| {\n             let syntax_contexts = &mut data.syntax_contexts;\n-            let ctxt_data = syntax_contexts[self.0 as usize];\n-            if mark == ctxt_data.outer_mark {\n-                return ctxt_data.prev_ctxt;\n-            }\n-\n-            let modern = if data.marks[mark.0 as usize].modern {\n-                *data.markings.entry((ctxt_data.modern, mark)).or_insert_with(|| {\n-                    let modern = SyntaxContext(syntax_contexts.len() as u32);\n+            let mut modern = syntax_contexts[self.0 as usize].modern;\n+            if data.marks[mark.0 as usize].modern {\n+                modern = *data.markings.entry((modern, mark)).or_insert_with(|| {\n+                    let len = syntax_contexts.len() as u32;\n                     syntax_contexts.push(SyntaxContextData {\n                         outer_mark: mark,\n-                        prev_ctxt: ctxt_data.modern,\n-                        modern: modern,\n+                        prev_ctxt: modern,\n+                        modern: SyntaxContext(len),\n                     });\n-                    modern\n-                })\n-            } else {\n-                ctxt_data.modern\n-            };\n+                    SyntaxContext(len)\n+                });\n+            }\n \n             *data.markings.entry((self, mark)).or_insert_with(|| {\n                 syntax_contexts.push(SyntaxContextData {"}, {"sha": "a7c247689cce88b08cbef538fde74eb6cff8e17b", "filename": "src/libsyntax_pos/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_pos%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Flibsyntax_pos%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Flib.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -186,7 +186,7 @@ impl Span {\n \n     pub fn to(self, end: Span) -> Span {\n         // FIXME(jseyfried): self.ctxt should always equal end.ctxt here (c.f. issue #23480)\n-        if end.ctxt == SyntaxContext::empty() {\n+        if self.ctxt == SyntaxContext::empty() {\n             Span { lo: self.lo, ..end }\n         } else {\n             Span { hi: end.hi, ..self }"}, {"sha": "f95e4410381d96d1df37e111d080b6fc9f692c97", "filename": "src/test/compile-fail/asm-out-assign-imm.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Ftest%2Fcompile-fail%2Fasm-out-assign-imm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Ftest%2Fcompile-fail%2Fasm-out-assign-imm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fasm-out-assign-imm.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -28,7 +28,6 @@ pub fn main() {\n         asm!(\"mov $1, $0\" : \"=r\"(x) : \"r\"(5));\n         //~^ ERROR re-assignment of immutable variable `x`\n         //~| NOTE re-assignment of immutable\n-        //~| NOTE in this expansion of asm!\n     }\n     foo(x);\n }"}, {"sha": "cc714a6e43141744d3beeb394e59fdab3694c2fd", "filename": "src/test/compile-fail/macro-context.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Ftest%2Fcompile-fail%2Fmacro-context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Ftest%2Fcompile-fail%2Fmacro-context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fmacro-context.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -23,5 +23,5 @@ fn main() {\n         m!() => {}  //~ NOTE the usage of `m!` is likely invalid in pattern context\n     }\n \n-    m!();\n+    m!(); //~ NOTE in this expansion\n }"}, {"sha": "08749373432f567761c01f2e208497baa93f86fd", "filename": "src/test/ui/token/macro-incomplete-parse.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Ftest%2Fui%2Ftoken%2Fmacro-incomplete-parse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4488b7df97e62bfeed8c30b1922ce55ff254594/src%2Ftest%2Fui%2Ftoken%2Fmacro-incomplete-parse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Ftoken%2Fmacro-incomplete-parse.rs?ref=d4488b7df97e62bfeed8c30b1922ce55ff254594", "patch": "@@ -32,7 +32,7 @@ macro_rules! ignored_pat {\n ignored_item!(); //~ NOTE caused by the macro expansion here\n \n fn main() {\n-    ignored_expr!();\n+    ignored_expr!(); //~ NOTE in this expansion\n     match 1 {\n         ignored_pat!() => (), //~ NOTE caused by the macro expansion here\n         _ => (),"}]}