{"sha": "3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a", "node_id": "C_kwDOAAsO6NoAKDNkN2U5YzRiN2ZkY2UwNjJiMmIzMzdmNzA4OTgwZWNiM2U5ZjRjOWE", "commit": {"author": {"name": "Lukas Markeffsky", "email": "@", "date": "2022-11-16T10:41:18Z"}, "committer": {"name": "Lukas Markeffsky", "email": "@", "date": "2022-11-19T15:58:02Z"}, "message": "Revert \"don't call `align_offset` during const eval, ever\"\n\nThis reverts commit f3a577bfae376c0222e934911865ed14cddd1539.", "tree": {"sha": "21b05b07859bc4c2061bb5ada982564be9c34456", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/21b05b07859bc4c2061bb5ada982564be9c34456"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a", "html_url": "https://github.com/rust-lang/rust/commit/3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a/comments", "author": null, "committer": null, "parents": [{"sha": "9e5d497b67c7566001bdcfc8a2767f26a23afc5b", "url": "https://api.github.com/repos/rust-lang/rust/commits/9e5d497b67c7566001bdcfc8a2767f26a23afc5b", "html_url": "https://github.com/rust-lang/rust/commit/9e5d497b67c7566001bdcfc8a2767f26a23afc5b"}], "stats": {"total": 141, "additions": 49, "deletions": 92}, "files": [{"sha": "04e68b96455251c2eeaa8651be41b7c88685b78f", "filename": "compiler/rustc_const_eval/src/const_eval/machine.rs", "status": "modified", "additions": 44, "deletions": 90, "changes": 134, "blob_url": "https://github.com/rust-lang/rust/blob/3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a/compiler%2Frustc_const_eval%2Fsrc%2Fconst_eval%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a/compiler%2Frustc_const_eval%2Fsrc%2Fconst_eval%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_const_eval%2Fsrc%2Fconst_eval%2Fmachine.rs?ref=3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a", "patch": "@@ -2,10 +2,11 @@ use rustc_hir::def::DefKind;\n use rustc_hir::LangItem;\n use rustc_middle::mir;\n use rustc_middle::mir::interpret::PointerArithmetic;\n-use rustc_middle::ty::layout::LayoutOf;\n+use rustc_middle::ty::layout::FnAbiOf;\n use rustc_middle::ty::{self, Ty, TyCtxt};\n use std::borrow::Borrow;\n use std::hash::Hash;\n+use std::ops::ControlFlow;\n \n use rustc_data_structures::fx::FxIndexMap;\n use rustc_data_structures::fx::IndexEntry;\n@@ -20,8 +21,8 @@ use rustc_target::abi::{Align, Size};\n use rustc_target::spec::abi::Abi as CallAbi;\n \n use crate::interpret::{\n-    self, compile_time_machine, AllocId, ConstAllocation, Frame, ImmTy, InterpCx, InterpResult,\n-    OpTy, PlaceTy, Pointer, Scalar, StackPopUnwind,\n+    self, compile_time_machine, AllocId, ConstAllocation, FnVal, Frame, ImmTy, InterpCx,\n+    InterpResult, OpTy, PlaceTy, Pointer, Scalar, StackPopUnwind,\n };\n \n use super::error::*;\n@@ -191,21 +192,24 @@ impl<'mir, 'tcx: 'mir> CompileTimeEvalContext<'mir, 'tcx> {\n \n             return Ok(Some(new_instance));\n         } else if Some(def_id) == self.tcx.lang_items().align_offset_fn() {\n-            // For align_offset, we replace the function call entirely.\n-            self.align_offset(instance, args, dest, ret)?;\n-            return Ok(None);\n+            // For align_offset, we replace the function call if the pointer has no address.\n+            match self.align_offset(instance, args, dest, ret)? {\n+                ControlFlow::Continue(()) => return Ok(Some(instance)),\n+                ControlFlow::Break(()) => return Ok(None),\n+            }\n         }\n         Ok(Some(instance))\n     }\n \n-    /// This function replaces `align_offset(ptr, target_align)` in const eval, because the\n-    /// pointer may not have an address.\n+    /// `align_offset(ptr, target_align)` needs special handling in const eval, because the pointer\n+    /// may not have an address.\n     ///\n-    /// If `ptr` does have a known address, we forward it to [`Self::align_offset_impl`].\n+    /// If `ptr` does have a known address, then we return `CONTINUE` and the function call should\n+    /// proceed as normal.\n     ///\n     /// If `ptr` doesn't have an address, but its underlying allocation's alignment is at most\n-    /// `target_align`, then we call [`Self::align_offset_impl`] with an dummy address relative\n-    /// to the allocation.\n+    /// `target_align`, then we call the function again with an dummy address relative to the\n+    /// allocation.\n     ///\n     /// If `ptr` doesn't have an address and `target_align` is stricter than the underlying\n     /// allocation's alignment, then we return `usize::MAX` immediately.\n@@ -215,103 +219,53 @@ impl<'mir, 'tcx: 'mir> CompileTimeEvalContext<'mir, 'tcx> {\n         args: &[OpTy<'tcx>],\n         dest: &PlaceTy<'tcx>,\n         ret: Option<mir::BasicBlock>,\n-    ) -> InterpResult<'tcx> {\n+    ) -> InterpResult<'tcx, ControlFlow<()>> {\n         assert_eq!(args.len(), 2);\n \n         let ptr = self.read_pointer(&args[0])?;\n         let target_align = self.read_scalar(&args[1])?.to_machine_usize(self)?;\n \n-        let pointee_ty = instance.substs.type_at(0);\n-        let stride = self.layout_of(pointee_ty)?.size.bytes();\n-\n         if !target_align.is_power_of_two() {\n             throw_ub_format!(\"`align_offset` called with non-power-of-two align: {}\", target_align);\n         }\n \n-        let mut align_offset = match self.ptr_try_get_alloc_id(ptr) {\n+        match self.ptr_try_get_alloc_id(ptr) {\n             Ok((alloc_id, offset, _extra)) => {\n-                // Extract the address relative to a base that is definitely sufficiently aligned.\n                 let (_size, alloc_align, _kind) = self.get_alloc_info(alloc_id);\n \n                 if target_align <= alloc_align.bytes() {\n-                    // The pointer *is* alignable in const. We use an address relative to the\n-                    // allocation base that is definitely sufficiently aligned.\n-                    let addr = offset.bytes();\n-                    Self::align_offset_impl(addr, stride, target_align)\n+                    // Extract the address relative to the allocation base that is definitely\n+                    // sufficiently aligned and call `align_offset` again.\n+                    let addr = ImmTy::from_uint(offset.bytes(), args[0].layout).into();\n+                    let align = ImmTy::from_uint(target_align, args[1].layout).into();\n+                    let fn_abi = self.fn_abi_of_instance(instance, ty::List::empty())?;\n+\n+                    // We replace the entire entire function call with a \"tail call\".\n+                    // Note that this happens before the frame of the original function\n+                    // is pushed on the stack.\n+                    self.eval_fn_call(\n+                        FnVal::Instance(instance),\n+                        (CallAbi::Rust, fn_abi),\n+                        &[addr, align],\n+                        /* with_caller_location = */ false,\n+                        dest,\n+                        ret,\n+                        StackPopUnwind::NotAllowed,\n+                    )?;\n+                    Ok(ControlFlow::BREAK)\n                 } else {\n-                    // The pointer *is not* alignable in const, return `usize::MAX`.\n-                    // (We clamp this to machine `usize` below.)\n-                    u64::MAX\n+                    // Not alignable in const, return `usize::MAX`.\n+                    let usize_max = Scalar::from_machine_usize(self.machine_usize_max(), self);\n+                    self.write_scalar(usize_max, dest)?;\n+                    self.return_to_block(ret)?;\n+                    Ok(ControlFlow::BREAK)\n                 }\n             }\n-            Err(addr) => {\n-                // The pointer has a known address.\n-                Self::align_offset_impl(addr, stride, target_align)\n-            }\n-        };\n-\n-        let usize_max = self.machine_usize_max();\n-        if align_offset > usize_max {\n-            align_offset = usize_max;\n-        }\n-\n-        self.write_scalar(Scalar::from_machine_usize(align_offset, self), dest)?;\n-        self.return_to_block(ret)?;\n-\n-        Ok(())\n-    }\n-\n-    /// Const eval implementation of `#[lang = \"align_offset\"]`.\n-    /// See the runtime version for a detailed explanation how this works.\n-    fn align_offset_impl(addr: u64, stride: u64, align: u64) -> u64 {\n-        assert!(align.is_power_of_two());\n-\n-        let addr_mod_align = addr % align;\n-\n-        if addr_mod_align == 0 {\n-            // The address is already sufficiently aligned.\n-            return 0;\n-        }\n-\n-        if stride == 0 {\n-            // The address cannot be aligned.\n-            return u64::MAX;\n-        }\n-\n-        if align % stride == 0 {\n-            let byte_offset = align - addr_mod_align;\n-            if byte_offset % stride == 0 {\n-                return byte_offset / stride;\n-            } else {\n-                return u64::MAX;\n+            Err(_addr) => {\n+                // The pointer has an address, continue with function call.\n+                Ok(ControlFlow::CONTINUE)\n             }\n         }\n-\n-        // This only works, because `align` is a power of two.\n-        let gcd = 1u64 << (stride | align).trailing_zeros();\n-\n-        if addr % gcd != 0 {\n-            // The address cannot be aligned.\n-            return u64::MAX;\n-        }\n-\n-        // Instead of `(addr + offset * stride) % align == 0`, we solve\n-        // `((addr + offset * stride) / gcd) % (align / gcd) == 0`.\n-        let addr2 = addr / gcd;\n-        let align2 = align / gcd;\n-        let stride2 = stride / gcd;\n-\n-        let mut stride_inv = 1u64;\n-        let mut mod_gate = 2u64;\n-        let mut overflow = false;\n-        while !overflow && mod_gate < align2 {\n-            stride_inv =\n-                stride_inv.wrapping_mul(2u64.wrapping_sub(stride2.wrapping_mul(stride_inv)));\n-            (mod_gate, overflow) = mod_gate.overflowing_mul(mod_gate);\n-        }\n-\n-        let byte_offset = align2 - addr2 % align2;\n-        byte_offset.wrapping_mul(stride_inv) % align2\n     }\n \n     /// See documentation on the `ptr_guaranteed_cmp` intrinsic."}, {"sha": "9283b81a84e2b621e25794685a42ea8bdffa877b", "filename": "library/core/src/ptr/mod.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a/library%2Fcore%2Fsrc%2Fptr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a/library%2Fcore%2Fsrc%2Fptr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fcore%2Fsrc%2Fptr%2Fmod.rs?ref=3d7e9c4b7fdce062b2b337f708980ecb3e9f4c9a", "patch": "@@ -1591,7 +1591,6 @@ pub unsafe fn write_volatile<T>(dst: *mut T, src: T) {\n ///\n /// Any questions go to @nagisa.\n #[lang = \"align_offset\"]\n-#[rustc_do_not_const_check] // hooked by const-eval\n pub(crate) const unsafe fn align_offset<T: Sized>(p: *const T, a: usize) -> usize {\n     // FIXME(#75598): Direct use of these intrinsics improves codegen significantly at opt-level <=\n     // 1, where the method versions of these operations are not inlined.\n@@ -1651,9 +1650,13 @@ pub(crate) const unsafe fn align_offset<T: Sized>(p: *const T, a: usize) -> usiz\n         inverse & m_minus_one\n     }\n \n-    let addr = p.addr();\n     let stride = mem::size_of::<T>();\n \n+    // SAFETY: At runtime, transmuting a pointer to `usize` is always safe, because they have the\n+    // same layout. During const eval, we hook this function to ensure that the pointer always has\n+    // an address (only the standard library can do this).\n+    let addr: usize = unsafe { mem::transmute(p) };\n+\n     // SAFETY: `a` is a power-of-two, therefore non-zero.\n     let a_minus_one = unsafe { unchecked_sub(a, 1) };\n "}]}