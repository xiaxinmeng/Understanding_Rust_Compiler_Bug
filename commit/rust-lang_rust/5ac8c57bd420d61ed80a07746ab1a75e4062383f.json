{"sha": "5ac8c57bd420d61ed80a07746ab1a75e4062383f", "node_id": "MDY6Q29tbWl0NzI0NzEyOjVhYzhjNTdiZDQyMGQ2MWVkODBhMDc3NDZhYjFhNzVlNDA2MjM4M2Y=", "commit": {"author": {"name": "Ben Blum", "email": "bblum@andrew.cmu.edu", "date": "2013-08-12T18:54:09Z"}, "committer": {"name": "Ben Blum", "email": "bblum@andrew.cmu.edu", "date": "2013-08-12T19:20:02Z"}, "message": "Clean up transitionary glue in task/spawn.rs. Don't hold kill-little-lock for O(n) time, cf #3100, and optimize out several unneeded clone()s.", "tree": {"sha": "d568cc4d7c6f5401a9e4712c1f77f0eb29622ed9", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d568cc4d7c6f5401a9e4712c1f77f0eb29622ed9"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5ac8c57bd420d61ed80a07746ab1a75e4062383f", "comment_count": 5, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5ac8c57bd420d61ed80a07746ab1a75e4062383f", "html_url": "https://github.com/rust-lang/rust/commit/5ac8c57bd420d61ed80a07746ab1a75e4062383f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5ac8c57bd420d61ed80a07746ab1a75e4062383f/comments", "author": {"login": "bblum", "id": 1820515, "node_id": "MDQ6VXNlcjE4MjA1MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/1820515?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bblum", "html_url": "https://github.com/bblum", "followers_url": "https://api.github.com/users/bblum/followers", "following_url": "https://api.github.com/users/bblum/following{/other_user}", "gists_url": "https://api.github.com/users/bblum/gists{/gist_id}", "starred_url": "https://api.github.com/users/bblum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bblum/subscriptions", "organizations_url": "https://api.github.com/users/bblum/orgs", "repos_url": "https://api.github.com/users/bblum/repos", "events_url": "https://api.github.com/users/bblum/events{/privacy}", "received_events_url": "https://api.github.com/users/bblum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bblum", "id": 1820515, "node_id": "MDQ6VXNlcjE4MjA1MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/1820515?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bblum", "html_url": "https://github.com/bblum", "followers_url": "https://api.github.com/users/bblum/followers", "following_url": "https://api.github.com/users/bblum/following{/other_user}", "gists_url": "https://api.github.com/users/bblum/gists{/gist_id}", "starred_url": "https://api.github.com/users/bblum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bblum/subscriptions", "organizations_url": "https://api.github.com/users/bblum/orgs", "repos_url": "https://api.github.com/users/bblum/repos", "events_url": "https://api.github.com/users/bblum/events{/privacy}", "received_events_url": "https://api.github.com/users/bblum/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ce48e71d28a69151a9f1fb7a620dcbad2834cef3", "url": "https://api.github.com/repos/rust-lang/rust/commits/ce48e71d28a69151a9f1fb7a620dcbad2834cef3", "html_url": "https://github.com/rust-lang/rust/commit/ce48e71d28a69151a9f1fb7a620dcbad2834cef3"}], "stats": {"total": 207, "additions": 69, "deletions": 138}, "files": [{"sha": "83bf34941dc705688f39f5ddaa3629fcf21107cd", "filename": "src/libstd/rt/kill.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/5ac8c57bd420d61ed80a07746ab1a75e4062383f/src%2Flibstd%2Frt%2Fkill.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5ac8c57bd420d61ed80a07746ab1a75e4062383f/src%2Flibstd%2Frt%2Fkill.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fkill.rs?ref=5ac8c57bd420d61ed80a07746ab1a75e4062383f", "patch": "@@ -488,8 +488,8 @@ impl Death {\n         rtassert!(self.unkillable == 0);\n         self.unkillable = 1;\n \n-        // FIXME(#7544): See corresponding fixme at the callsite in task.rs.\n-        // NB(#8192): Doesn't work with \"let _ = ...\"\n+        // NB. See corresponding comment at the callsite in task.rs.\n+        // FIXME(#8192): Doesn't work with \"let _ = ...\"\n         { use util; util::ignore(group); }\n \n         // Step 1. Decide if we need to collect child failures synchronously."}, {"sha": "c669f25d8b738033b78c7ab4188cd1be0579bcaa", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/5ac8c57bd420d61ed80a07746ab1a75e4062383f/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5ac8c57bd420d61ed80a07746ab1a75e4062383f/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=5ac8c57bd420d61ed80a07746ab1a75e4062383f", "patch": "@@ -253,12 +253,10 @@ impl Task {\n             }\n         }\n \n-        // FIXME(#7544): We pass the taskgroup into death so that it can be\n-        // dropped while the unkillable counter is set. This should not be\n-        // necessary except for an extraneous clone() in task/spawn.rs that\n-        // causes a killhandle to get dropped, which mustn't receive a kill\n-        // signal since we're outside of the unwinder's try() scope.\n-        // { let _ = self.taskgroup.take(); }\n+        // NB. We pass the taskgroup into death so that it can be dropped while\n+        // the unkillable counter is set. This is necessary for when the\n+        // taskgroup destruction code drops references on KillHandles, which\n+        // might require using unkillable (to synchronize with an unwrapper).\n         self.death.collect_failure(!self.unwinder.unwinding, self.taskgroup.take());\n         self.destroyed = true;\n     }"}, {"sha": "c38e6f233130b57cd6f0cfd9a28a28520c8b459a", "filename": "src/libstd/task/mod.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/5ac8c57bd420d61ed80a07746ab1a75e4062383f/src%2Flibstd%2Ftask%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5ac8c57bd420d61ed80a07746ab1a75e4062383f/src%2Flibstd%2Ftask%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fmod.rs?ref=5ac8c57bd420d61ed80a07746ab1a75e4062383f", "patch": "@@ -38,7 +38,6 @@\n use prelude::*;\n \n use cell::Cell;\n-use cmp::Eq;\n use comm::{stream, Chan, GenericChan, GenericPort, Port};\n use result::Result;\n use result;"}, {"sha": "e0efc14a8871fbe5970127b985119fdb42b1401f", "filename": "src/libstd/task/spawn.rs", "status": "modified", "additions": 63, "deletions": 129, "changes": 192, "blob_url": "https://github.com/rust-lang/rust/blob/5ac8c57bd420d61ed80a07746ab1a75e4062383f/src%2Flibstd%2Ftask%2Fspawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5ac8c57bd420d61ed80a07746ab1a75e4062383f/src%2Flibstd%2Ftask%2Fspawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fspawn.rs?ref=5ac8c57bd420d61ed80a07746ab1a75e4062383f", "patch": "@@ -22,10 +22,9 @@\n  *\n  *     A new one of these is created each spawn_linked or spawn_supervised.\n  *\n- * (2) The \"tcb\" is a per-task control structure that tracks a task's spawn\n- *     configuration. It contains a reference to its taskgroup_arc, a\n- *     reference to its node in the ancestor list (below), a flag for\n- *     whether it's part of the 'main'/'root' taskgroup, and an optionally\n+ * (2) The \"taskgroup\" is a per-task control structure that tracks a task's\n+ *     spawn configuration. It contains a reference to its taskgroup_arc, a\n+ *     reference to its node in the ancestor list (below), and an optionally\n  *     configured notification port. These are stored in TLS.\n  *\n  * (3) The \"ancestor_list\" is a cons-style list of unsafe::exclusives which\n@@ -84,7 +83,6 @@ use local_data;\n use task::{Failure, SingleThreaded};\n use task::{Success, TaskOpts, TaskResult};\n use task::unkillable;\n-use to_bytes::IterBytes;\n use uint;\n use util;\n use unstable::sync::Exclusive;\n@@ -101,47 +99,25 @@ use rt::work_queue::WorkQueue;\n #[cfg(test)] use comm;\n #[cfg(test)] use task;\n \n-// Transitionary.\n-#[deriving(Eq)]\n-enum TaskHandle {\n-    NewTask(KillHandle),\n-}\n-\n-impl Clone for TaskHandle {\n-    fn clone(&self) -> TaskHandle {\n-        match *self {\n-            NewTask(ref x) => NewTask(x.clone()),\n-        }\n-    }\n-}\n-\n-impl IterBytes for TaskHandle {\n-    fn iter_bytes(&self, lsb0: bool, f: &fn(buf: &[u8]) -> bool) -> bool {\n-        match *self {\n-            NewTask(ref x) => x.iter_bytes(lsb0, f),\n-        }\n-    }\n-}\n-\n-struct TaskSet(HashSet<TaskHandle>);\n+struct TaskSet(HashSet<KillHandle>);\n \n impl TaskSet {\n     #[inline]\n     fn new() -> TaskSet {\n         TaskSet(HashSet::new())\n     }\n     #[inline]\n-    fn insert(&mut self, task: TaskHandle) {\n+    fn insert(&mut self, task: KillHandle) {\n         let didnt_overwrite = (**self).insert(task);\n         assert!(didnt_overwrite);\n     }\n     #[inline]\n-    fn remove(&mut self, task: &TaskHandle) {\n+    fn remove(&mut self, task: &KillHandle) {\n         let was_present = (**self).remove(task);\n         assert!(was_present);\n     }\n     #[inline]\n-    fn move_iter(self) -> HashSetMoveIterator<TaskHandle> {\n+    fn move_iter(self) -> HashSetMoveIterator<KillHandle> {\n         (*self).move_iter()\n     }\n }\n@@ -291,7 +267,7 @@ fn each_ancestor(list:        &mut AncestorList,\n                             None => nobe_is_dead\n                         };\n                         // Call iterator block. (If the group is dead, it's\n-                        // safe to skip it. This will leave our TaskHandle\n+                        // safe to skip it. This will leave our KillHandle\n                         // hanging around in the group even after it's freed,\n                         // but that's ok because, by virtue of the group being\n                         // dead, nobody will ever kill-all (for) over it.)\n@@ -338,7 +314,6 @@ pub struct Taskgroup {\n     tasks:      TaskGroupArc, // 'none' means the group has failed.\n     // Lists of tasks who will kill us if they fail, but whom we won't kill.\n     ancestors:  AncestorList,\n-    is_main:    bool,\n     notifier:   Option<AutoNotify>,\n }\n \n@@ -355,22 +330,26 @@ impl Drop for Taskgroup {\n                     for x in this.notifier.mut_iter() {\n                         x.failed = true;\n                     }\n-                    // Take everybody down with us.\n-                    do access_group(&self.tasks) |tg| {\n-                        kill_taskgroup(tg, &me, self.is_main);\n-                    }\n+                    // Take everybody down with us. After this point, every\n+                    // other task in the group will see 'tg' as none, which\n+                    // indicates the whole taskgroup is failing (and forbids\n+                    // new spawns from succeeding).\n+                    let tg = do access_group(&self.tasks) |tg| { tg.take() };\n+                    // It's safe to send kill signals outside the lock, because\n+                    // we have a refcount on all kill-handles in the group.\n+                    kill_taskgroup(tg, me);\n                 } else {\n                     // Remove ourselves from the group(s).\n                     do access_group(&self.tasks) |tg| {\n-                        leave_taskgroup(tg, &me, true);\n+                        leave_taskgroup(tg, me, true);\n                     }\n                 }\n                 // It doesn't matter whether this happens before or after dealing\n                 // with our own taskgroup, so long as both happen before we die.\n                 // We remove ourself from every ancestor we can, so no cleanup; no\n                 // break.\n                 do each_ancestor(&mut this.ancestors, |_| {}) |ancestor_group| {\n-                    leave_taskgroup(ancestor_group, &me, false);\n+                    leave_taskgroup(ancestor_group, me, false);\n                     true\n                 };\n             }\n@@ -380,7 +359,6 @@ impl Drop for Taskgroup {\n \n pub fn Taskgroup(tasks: TaskGroupArc,\n        ancestors: AncestorList,\n-       is_main: bool,\n        mut notifier: Option<AutoNotify>) -> Taskgroup {\n     for x in notifier.mut_iter() {\n         x.failed = false;\n@@ -389,7 +367,6 @@ pub fn Taskgroup(tasks: TaskGroupArc,\n     Taskgroup {\n         tasks: tasks,\n         ancestors: ancestors,\n-        is_main: is_main,\n         notifier: notifier\n     }\n }\n@@ -413,7 +390,7 @@ fn AutoNotify(chan: Chan<TaskResult>) -> AutoNotify {\n     }\n }\n \n-fn enlist_in_taskgroup(state: TaskGroupInner, me: TaskHandle,\n+fn enlist_in_taskgroup(state: TaskGroupInner, me: KillHandle,\n                            is_member: bool) -> bool {\n     let me = Cell::new(me); // :(\n     // If 'None', the group was failing. Can't enlist.\n@@ -428,8 +405,7 @@ fn enlist_in_taskgroup(state: TaskGroupInner, me: TaskHandle,\n }\n \n // NB: Runs in destructor/post-exit context. Can't 'fail'.\n-fn leave_taskgroup(state: TaskGroupInner, me: &TaskHandle,\n-                       is_member: bool) {\n+fn leave_taskgroup(state: TaskGroupInner, me: &KillHandle, is_member: bool) {\n     let me = Cell::new(me); // :(\n     // If 'None', already failing and we've already gotten a kill signal.\n     do state.map_mut |group| {\n@@ -442,43 +418,23 @@ fn leave_taskgroup(state: TaskGroupInner, me: &TaskHandle,\n }\n \n // NB: Runs in destructor/post-exit context. Can't 'fail'.\n-fn kill_taskgroup(state: TaskGroupInner, me: &TaskHandle, is_main: bool) {\n-    unsafe {\n-        // NB: We could do the killing iteration outside of the group arc, by\n-        // having \"let mut newstate\" here, swapping inside, and iterating\n-        // after. But that would let other exiting tasks fall-through and exit\n-        // while we were trying to kill them, causing potential\n-        // use-after-free. A task's presence in the arc guarantees it's alive\n-        // only while we hold the lock, so if we're failing, all concurrently\n-        // exiting tasks must wait for us. To do it differently, we'd have to\n-        // use the runtime's task refcounting, but that could leave task\n-        // structs around long after their task exited.\n-        let newstate = util::replace(state, None);\n-        // Might already be None, if Somebody is failing simultaneously.\n-        // That's ok; only one task needs to do the dirty work. (Might also\n-        // see 'None' if Somebody already failed and we got a kill signal.)\n-        if newstate.is_some() {\n-            let TaskGroupData { members: members, descendants: descendants } =\n-                newstate.unwrap();\n-            for sibling in members.move_iter() {\n-                // Skip self - killing ourself won't do much good.\n-                if &sibling != me {\n-                    RuntimeGlue::kill_task(sibling);\n-                }\n-            }\n-            for child in descendants.move_iter() {\n-                assert!(&child != me);\n-                RuntimeGlue::kill_task(child);\n+fn kill_taskgroup(state: Option<TaskGroupData>, me: &KillHandle) {\n+    // Might already be None, if somebody is failing simultaneously.\n+    // That's ok; only one task needs to do the dirty work. (Might also\n+    // see 'None' if somebody already failed and we got a kill signal.)\n+    do state.map_move |TaskGroupData { members: members, descendants: descendants }| {\n+        for sibling in members.move_iter() {\n+            // Skip self - killing ourself won't do much good.\n+            if &sibling != me {\n+                RuntimeGlue::kill_task(sibling);\n             }\n-            // Only one task should ever do this.\n-            if is_main {\n-                RuntimeGlue::kill_all_tasks(me);\n-            }\n-            // Do NOT restore state to Some(..)! It stays None to indicate\n-            // that the whole taskgroup is failing, to forbid new spawns.\n         }\n-        // (note: multiple tasks may reach this point)\n-    }\n+        for child in descendants.move_iter() {\n+            assert!(&child != me);\n+            RuntimeGlue::kill_task(child);\n+        }\n+    };\n+    // (note: multiple tasks may reach this point)\n }\n \n // FIXME (#2912): Work around core-vs-coretest function duplication. Can't use\n@@ -490,38 +446,23 @@ fn taskgroup_key() -> local_data::Key<@@mut Taskgroup> {\n // Transitionary.\n struct RuntimeGlue;\n impl RuntimeGlue {\n-    unsafe fn kill_task(task: TaskHandle) {\n-        match task {\n-            NewTask(handle) => {\n-                let mut handle = handle;\n-                do handle.kill().map_move |killed_task| {\n-                    let killed_task = Cell::new(killed_task);\n-                    do Local::borrow::<Scheduler, ()> |sched| {\n-                        sched.enqueue_task(killed_task.take());\n-                    }\n-                };\n+    fn kill_task(handle: KillHandle) {\n+        let mut handle = handle;\n+        do handle.kill().map_move |killed_task| {\n+            let killed_task = Cell::new(killed_task);\n+            do Local::borrow::<Scheduler, ()> |sched| {\n+                sched.enqueue_task(killed_task.take());\n             }\n-        }\n-    }\n-\n-    unsafe fn kill_all_tasks(task: &TaskHandle) {\n-        match *task {\n-            // FIXME(#7544): Remove the kill_all feature entirely once the\n-            // oldsched goes away.\n-            NewTask(ref _handle) => rtabort!(\"can't kill_all in newsched\"),\n-        }\n+        };\n     }\n \n-    fn with_task_handle_and_failing(blk: &fn(TaskHandle, bool)) {\n+    fn with_task_handle_and_failing(blk: &fn(&KillHandle, bool)) {\n         if in_green_task_context() {\n             unsafe {\n                 // Can't use safe borrow, because the taskgroup destructor needs to\n                 // access the scheduler again to send kill signals to other tasks.\n                 let me = Local::unsafe_borrow::<Task>();\n-                // FIXME(#7544): Get rid of this clone by passing by-ref.\n-                // Will probably have to wait until the old rt is gone.\n-                blk(NewTask((*me).death.kill_handle.get_ref().clone()),\n-                    (*me).unwinder.unwinding)\n+                blk((*me).death.kill_handle.get_ref(), (*me).unwinder.unwinding)\n             }\n         } else {\n             rtabort!(\"task dying in bad context\")\n@@ -540,15 +481,12 @@ impl RuntimeGlue {\n                         // Lazily initialize.\n                         let mut members = TaskSet::new();\n                         let my_handle = (*me).death.kill_handle.get_ref().clone();\n-                        members.insert(NewTask(my_handle));\n+                        members.insert(my_handle);\n                         let tasks = Exclusive::new(Some(TaskGroupData {\n                             members: members,\n                             descendants: TaskSet::new(),\n                         }));\n-                        // FIXME(#7544): Remove the is_main flag entirely once\n-                        // the newsched goes away. The main taskgroup has no special\n-                        // behaviour.\n-                        let group = Taskgroup(tasks, AncestorList(None), false, None);\n+                        let group = Taskgroup(tasks, AncestorList(None), None);\n                         (*me).taskgroup = Some(group);\n                         (*me).taskgroup.get_ref()\n                     }\n@@ -563,9 +501,7 @@ impl RuntimeGlue {\n \n // Returns 'None' in the case where the child's TG should be lazily initialized.\n fn gen_child_taskgroup(linked: bool, supervised: bool)\n-    -> Option<(TaskGroupArc, AncestorList, bool)> {\n-    // FIXME(#7544): Not safe to lazily initialize in the old runtime. Remove\n-    // this context check once 'spawn_raw_oldsched' is gone.\n+    -> Option<(TaskGroupArc, AncestorList)> {\n     if linked || supervised {\n         // with_my_taskgroup will lazily initialize the parent's taskgroup if\n         // it doesn't yet exist. We don't want to call it in the unlinked case.\n@@ -574,8 +510,7 @@ fn gen_child_taskgroup(linked: bool, supervised: bool)\n             if linked {\n                 // Child is in the same group as spawner.\n                 // Child's ancestors are spawner's ancestors.\n-                // Propagate main-ness.\n-                Some((spawner_group.tasks.clone(), ancestors, spawner_group.is_main))\n+                Some((spawner_group.tasks.clone(), ancestors))\n             } else {\n                 // Child is in a separate group from spawner.\n                 let g = Exclusive::new(Some(TaskGroupData {\n@@ -596,7 +531,7 @@ fn gen_child_taskgroup(linked: bool, supervised: bool)\n                     // Child has no ancestors.\n                     AncestorList(None)\n                 };\n-                Some((g, a, false))\n+                Some((g, a))\n             }\n         }\n     } else {\n@@ -607,15 +542,15 @@ fn gen_child_taskgroup(linked: bool, supervised: bool)\n // Set up membership in taskgroup and descendantship in all ancestor\n // groups. If any enlistment fails, Some task was already failing, so\n // don't let the child task run, and undo every successful enlistment.\n-fn enlist_many(child: TaskHandle, child_arc: &TaskGroupArc,\n+fn enlist_many(child: &KillHandle, child_arc: &TaskGroupArc,\n                ancestors: &mut AncestorList) -> bool {\n     // Join this taskgroup.\n     let mut result = do access_group(child_arc) |child_tg| {\n         enlist_in_taskgroup(child_tg, child.clone(), true) // member\n     };\n     if result {\n         // Unwinding function in case any ancestral enlisting fails\n-        let bail: &fn(TaskGroupInner) = |tg| { leave_taskgroup(tg, &child, false) };\n+        let bail: &fn(TaskGroupInner) = |tg| { leave_taskgroup(tg, child, false) };\n         // Attempt to join every ancestor group.\n         result = do each_ancestor(ancestors, bail) |ancestor_tg| {\n             // Enlist as a descendant, not as an actual member.\n@@ -625,7 +560,7 @@ fn enlist_many(child: TaskHandle, child_arc: &TaskGroupArc,\n         // If any ancestor group fails, need to exit this group too.\n         if !result {\n             do access_group(child_arc) |child_tg| {\n-                leave_taskgroup(child_tg, &child, true); // member\n+                leave_taskgroup(child_tg, child, true); // member\n             }\n         }\n     }\n@@ -653,15 +588,14 @@ fn spawn_raw_newsched(mut opts: TaskOpts, f: ~fn()) {\n         let enlist_success = do child_data.take().map_move_default(true) |child_data| {\n             let child_data = Cell::new(child_data); // :(\n             do Local::borrow::<Task, bool> |me| {\n-                let (child_tg, ancestors, is_main) = child_data.take();\n+                let (child_tg, ancestors) = child_data.take();\n                 let mut ancestors = ancestors;\n-                // FIXME(#7544): Optimize out the xadd in this clone, somehow.\n-                let handle = me.death.kill_handle.get_ref().clone();\n+                let handle = me.death.kill_handle.get_ref();\n                 // Atomically try to get into all of our taskgroups.\n-                if enlist_many(NewTask(handle), &child_tg, &mut ancestors) {\n+                if enlist_many(handle, &child_tg, &mut ancestors) {\n                     // Got in. We can run the provided child body, and can also run\n                     // the taskgroup's exit-time-destructor afterward.\n-                    me.taskgroup = Some(Taskgroup(child_tg, ancestors, is_main, None));\n+                    me.taskgroup = Some(Taskgroup(child_tg, ancestors, None));\n                     true\n                 } else {\n                     false\n@@ -678,14 +612,14 @@ fn spawn_raw_newsched(mut opts: TaskOpts, f: ~fn()) {\n         }\n     };\n \n-    let mut task = unsafe {\n-        if opts.sched.mode != SingleThreaded {\n-            if opts.watched {\n-                Task::build_child(opts.stack_size, child_wrapper)\n-            } else {\n-                Task::build_root(opts.stack_size, child_wrapper)\n-            }\n+    let mut task = if opts.sched.mode != SingleThreaded {\n+        if opts.watched {\n+            Task::build_child(opts.stack_size, child_wrapper)\n         } else {\n+            Task::build_root(opts.stack_size, child_wrapper)\n+        }\n+    } else {\n+        unsafe {\n             // Creating a 1:1 task:thread ...\n             let sched = Local::unsafe_borrow::<Scheduler>();\n             let sched_handle = (*sched).make_handle();"}]}