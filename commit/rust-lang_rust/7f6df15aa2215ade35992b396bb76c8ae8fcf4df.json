{"sha": "7f6df15aa2215ade35992b396bb76c8ae8fcf4df", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdmNmRmMTVhYTIyMTVhZGUzNTk5MmIzOTZiYjc2YzhhZThmY2Y0ZGY=", "commit": {"author": {"name": "David Cook", "email": "divergentdave@gmail.com", "date": "2020-03-28T14:25:02Z"}, "committer": {"name": "David Cook", "email": "divergentdave@gmail.com", "date": "2020-04-05T15:32:06Z"}, "message": "Rearrange functions", "tree": {"sha": "8ff36a70c95370f3859efc29de62373223d59f6a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8ff36a70c95370f3859efc29de62373223d59f6a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7f6df15aa2215ade35992b396bb76c8ae8fcf4df", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7f6df15aa2215ade35992b396bb76c8ae8fcf4df", "html_url": "https://github.com/rust-lang/rust/commit/7f6df15aa2215ade35992b396bb76c8ae8fcf4df", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7f6df15aa2215ade35992b396bb76c8ae8fcf4df/comments", "author": {"login": "divergentdave", "id": 181772, "node_id": "MDQ6VXNlcjE4MTc3Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/181772?v=4", "gravatar_id": "", "url": "https://api.github.com/users/divergentdave", "html_url": "https://github.com/divergentdave", "followers_url": "https://api.github.com/users/divergentdave/followers", "following_url": "https://api.github.com/users/divergentdave/following{/other_user}", "gists_url": "https://api.github.com/users/divergentdave/gists{/gist_id}", "starred_url": "https://api.github.com/users/divergentdave/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/divergentdave/subscriptions", "organizations_url": "https://api.github.com/users/divergentdave/orgs", "repos_url": "https://api.github.com/users/divergentdave/repos", "events_url": "https://api.github.com/users/divergentdave/events{/privacy}", "received_events_url": "https://api.github.com/users/divergentdave/received_events", "type": "User", "site_admin": false}, "committer": {"login": "divergentdave", "id": 181772, "node_id": "MDQ6VXNlcjE4MTc3Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/181772?v=4", "gravatar_id": "", "url": "https://api.github.com/users/divergentdave", "html_url": "https://github.com/divergentdave", "followers_url": "https://api.github.com/users/divergentdave/followers", "following_url": "https://api.github.com/users/divergentdave/following{/other_user}", "gists_url": "https://api.github.com/users/divergentdave/gists{/gist_id}", "starred_url": "https://api.github.com/users/divergentdave/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/divergentdave/subscriptions", "organizations_url": "https://api.github.com/users/divergentdave/orgs", "repos_url": "https://api.github.com/users/divergentdave/repos", "events_url": "https://api.github.com/users/divergentdave/events{/privacy}", "received_events_url": "https://api.github.com/users/divergentdave/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c7466c9531c1a282380183c78001014c35dc9fac", "url": "https://api.github.com/repos/rust-lang/rust/commits/c7466c9531c1a282380183c78001014c35dc9fac", "html_url": "https://github.com/rust-lang/rust/commit/c7466c9531c1a282380183c78001014c35dc9fac"}], "stats": {"total": 342, "additions": 171, "deletions": 171}, "files": [{"sha": "4e4f8c112e533b71d3dca50e7f2d168ab2a02b05", "filename": "src/shims/sync.rs", "status": "modified", "additions": 171, "deletions": 171, "changes": 342, "blob_url": "https://github.com/rust-lang/rust/blob/7f6df15aa2215ade35992b396bb76c8ae8fcf4df/src%2Fshims%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f6df15aa2215ade35992b396bb76c8ae8fcf4df/src%2Fshims%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fsync.rs?ref=7f6df15aa2215ade35992b396bb76c8ae8fcf4df", "patch": "@@ -4,6 +4,177 @@ use rustc_target::abi::{LayoutOf, Size};\n use crate::stacked_borrows::Tag;\n use crate::*;\n \n+fn assert_ptr_target_min_size<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    operand: OpTy<'tcx, Tag>,\n+    min_size: u64,\n+) -> InterpResult<'tcx, ()> {\n+    let target_ty = match operand.layout.ty.kind {\n+        TyKind::RawPtr(TypeAndMut { ty, mutbl: _ }) => ty,\n+        _ => panic!(\"Argument to pthread function was not a raw pointer\"),\n+    };\n+    let target_layout = ecx.layout_of(target_ty)?;\n+    assert!(target_layout.size.bytes() >= min_size);\n+    Ok(())\n+}\n+\n+// pthread_mutexattr_t is either 4 or 8 bytes, depending on the platform.\n+\n+// Our chosen memory layout: store an i32 in the first four bytes equal to the\n+// corresponding libc mutex kind constant (i.e. PTHREAD_MUTEX_NORMAL)\n+\n+fn mutexattr_get_kind<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    attr_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the attr pointer is within bounds\n+    assert_ptr_target_min_size(ecx, attr_op, 4)?;\n+    let attr_place = ecx.deref_operand(attr_op)?;\n+    let i32_layout = ecx.layout_of(ecx.tcx.types.i32)?;\n+    let kind_place = attr_place.offset(Size::ZERO, MemPlaceMeta::None, i32_layout, ecx)?;\n+    ecx.read_scalar(kind_place.into())\n+}\n+\n+fn mutexattr_set_kind<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    attr_op: OpTy<'tcx, Tag>,\n+    kind: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the attr pointer is within bounds\n+    assert_ptr_target_min_size(ecx, attr_op, 4)?;\n+    let attr_place = ecx.deref_operand(attr_op)?;\n+    let i32_layout = ecx.layout_of(ecx.tcx.types.i32)?;\n+    let kind_place = attr_place.offset(Size::ZERO, MemPlaceMeta::None, i32_layout, ecx)?;\n+    ecx.write_scalar(kind.into(), kind_place.into())\n+}\n+\n+// pthread_mutex_t is between 24 and 48 bytes, depending on the platform.\n+\n+// Our chosen memory layout:\n+// bytes 0-3: reserved for signature on macOS\n+// (need to avoid this because it is set by static initializer macros)\n+// bytes 4-7: count of how many times this mutex has been locked, as a u32\n+// bytes 12-15 or 16-19 (depending on platform): mutex kind, as an i32\n+// (the kind has to be at its offset for compatibility with static initializer macros)\n+\n+fn mutex_get_locked_count<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the mutex pointer is within bounds\n+    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n+    let mutex_place = ecx.deref_operand(mutex_op)?;\n+    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n+    let locked_count_place =\n+        mutex_place.offset(Size::from_bytes(4), MemPlaceMeta::None, u32_layout, ecx)?;\n+    ecx.read_scalar(locked_count_place.into())\n+}\n+\n+fn mutex_set_locked_count<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+    locked_count: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the mutex pointer is within bounds\n+    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n+    let mutex_place = ecx.deref_operand(mutex_op)?;\n+    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n+    let locked_count_place =\n+        mutex_place.offset(Size::from_bytes(4), MemPlaceMeta::None, u32_layout, ecx)?;\n+    ecx.write_scalar(locked_count.into(), locked_count_place.into())\n+}\n+\n+fn mutex_get_kind<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the mutex pointer is within bounds\n+    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n+    let mutex_place = ecx.deref_operand(mutex_op)?;\n+    let i32_layout = ecx.layout_of(ecx.tcx.types.i32)?;\n+    let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n+    let kind_place =\n+        mutex_place.offset(Size::from_bytes(kind_offset), MemPlaceMeta::None, i32_layout, ecx)?;\n+    ecx.read_scalar(kind_place.into())\n+}\n+\n+fn mutex_set_kind<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    mutex_op: OpTy<'tcx, Tag>,\n+    kind: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the mutex pointer is within bounds\n+    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n+    let mutex_place = ecx.deref_operand(mutex_op)?;\n+    let i32_layout = ecx.layout_of(ecx.tcx.types.i32)?;\n+    let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n+    let kind_place =\n+        mutex_place.offset(Size::from_bytes(kind_offset), MemPlaceMeta::None, i32_layout, ecx)?;\n+    ecx.write_scalar(kind.into(), kind_place.into())\n+}\n+\n+// pthread_rwlock_t is between 32 and 56 bytes, depending on the platform.\n+\n+// Our chosen memory layout:\n+// bytes 0-3: reserved for signature on macOS\n+// (need to avoid this because it is set by static initializer macros)\n+// bytes 4-7: reader count, as a u32\n+// bytes 8-11: writer count, as a u32\n+\n+fn rwlock_get_readers<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n+    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n+    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n+    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n+    let readers_place =\n+        rwlock_place.offset(Size::from_bytes(4), MemPlaceMeta::None, u32_layout, ecx)?;\n+    ecx.read_scalar(readers_place.into())\n+}\n+\n+fn rwlock_set_readers<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+    readers: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n+    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n+    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n+    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n+    let readers_place =\n+        rwlock_place.offset(Size::from_bytes(4), MemPlaceMeta::None, u32_layout, ecx)?;\n+    ecx.write_scalar(readers.into(), readers_place.into())\n+}\n+\n+fn rwlock_get_writers<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n+    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n+    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n+    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n+    let writers_place =\n+        rwlock_place.offset(Size::from_bytes(8), MemPlaceMeta::None, u32_layout, ecx)?;\n+    ecx.read_scalar(writers_place.into())\n+}\n+\n+fn rwlock_set_writers<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    rwlock_op: OpTy<'tcx, Tag>,\n+    writers: impl Into<ScalarMaybeUndef<Tag>>,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n+    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n+    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n+    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n+    let writers_place =\n+        rwlock_place.offset(Size::from_bytes(8), MemPlaceMeta::None, u32_layout, ecx)?;\n+    ecx.write_scalar(writers.into(), writers_place.into())\n+}\n+\n impl<'mir, 'tcx> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n     fn pthread_mutexattr_init(&mut self, attr_op: OpTy<'tcx, Tag>) -> InterpResult<'tcx, i32> {\n@@ -348,174 +519,3 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         Ok(0)\n     }\n }\n-\n-fn assert_ptr_target_min_size<'mir, 'tcx: 'mir>(\n-    ecx: &MiriEvalContext<'mir, 'tcx>,\n-    operand: OpTy<'tcx, Tag>,\n-    min_size: u64,\n-) -> InterpResult<'tcx, ()> {\n-    let target_ty = match operand.layout.ty.kind {\n-        TyKind::RawPtr(TypeAndMut { ty, mutbl: _ }) => ty,\n-        _ => panic!(\"Argument to pthread function was not a raw pointer\"),\n-    };\n-    let target_layout = ecx.layout_of(target_ty)?;\n-    assert!(target_layout.size.bytes() >= min_size);\n-    Ok(())\n-}\n-\n-// pthread_mutexattr_t is either 4 or 8 bytes, depending on the platform.\n-\n-// Our chosen memory layout: store an i32 in the first four bytes equal to the\n-// corresponding libc mutex kind constant (i.e. PTHREAD_MUTEX_NORMAL)\n-\n-fn mutexattr_get_kind<'mir, 'tcx: 'mir>(\n-    ecx: &MiriEvalContext<'mir, 'tcx>,\n-    attr_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the attr pointer is within bounds\n-    assert_ptr_target_min_size(ecx, attr_op, 4)?;\n-    let attr_place = ecx.deref_operand(attr_op)?;\n-    let i32_layout = ecx.layout_of(ecx.tcx.types.i32)?;\n-    let kind_place = attr_place.offset(Size::ZERO, MemPlaceMeta::None, i32_layout, ecx)?;\n-    ecx.read_scalar(kind_place.into())\n-}\n-\n-fn mutexattr_set_kind<'mir, 'tcx: 'mir>(\n-    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    attr_op: OpTy<'tcx, Tag>,\n-    kind: impl Into<ScalarMaybeUndef<Tag>>,\n-) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the attr pointer is within bounds\n-    assert_ptr_target_min_size(ecx, attr_op, 4)?;\n-    let attr_place = ecx.deref_operand(attr_op)?;\n-    let i32_layout = ecx.layout_of(ecx.tcx.types.i32)?;\n-    let kind_place = attr_place.offset(Size::ZERO, MemPlaceMeta::None, i32_layout, ecx)?;\n-    ecx.write_scalar(kind.into(), kind_place.into())\n-}\n-\n-// pthread_mutex_t is between 24 and 48 bytes, depending on the platform.\n-\n-// Our chosen memory layout:\n-// bytes 0-3: reserved for signature on macOS\n-// (need to avoid this because it is set by static initializer macros)\n-// bytes 4-7: count of how many times this mutex has been locked, as a u32\n-// bytes 12-15 or 16-19 (depending on platform): mutex kind, as an i32\n-// (the kind has to be at its offset for compatibility with static initializer macros)\n-\n-fn mutex_get_locked_count<'mir, 'tcx: 'mir>(\n-    ecx: &MiriEvalContext<'mir, 'tcx>,\n-    mutex_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n-    let locked_count_place =\n-        mutex_place.offset(Size::from_bytes(4), MemPlaceMeta::None, u32_layout, ecx)?;\n-    ecx.read_scalar(locked_count_place.into())\n-}\n-\n-fn mutex_set_locked_count<'mir, 'tcx: 'mir>(\n-    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    mutex_op: OpTy<'tcx, Tag>,\n-    locked_count: impl Into<ScalarMaybeUndef<Tag>>,\n-) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n-    let locked_count_place =\n-        mutex_place.offset(Size::from_bytes(4), MemPlaceMeta::None, u32_layout, ecx)?;\n-    ecx.write_scalar(locked_count.into(), locked_count_place.into())\n-}\n-\n-fn mutex_get_kind<'mir, 'tcx: 'mir>(\n-    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    mutex_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let i32_layout = ecx.layout_of(ecx.tcx.types.i32)?;\n-    let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n-    let kind_place =\n-        mutex_place.offset(Size::from_bytes(kind_offset), MemPlaceMeta::None, i32_layout, ecx)?;\n-    ecx.read_scalar(kind_place.into())\n-}\n-\n-fn mutex_set_kind<'mir, 'tcx: 'mir>(\n-    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    mutex_op: OpTy<'tcx, Tag>,\n-    kind: impl Into<ScalarMaybeUndef<Tag>>,\n-) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 20)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let i32_layout = ecx.layout_of(ecx.tcx.types.i32)?;\n-    let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n-    let kind_place =\n-        mutex_place.offset(Size::from_bytes(kind_offset), MemPlaceMeta::None, i32_layout, ecx)?;\n-    ecx.write_scalar(kind.into(), kind_place.into())\n-}\n-\n-// pthread_rwlock_t is between 32 and 56 bytes, depending on the platform.\n-\n-// Our chosen memory layout:\n-// bytes 0-3: reserved for signature on macOS\n-// (need to avoid this because it is set by static initializer macros)\n-// bytes 4-7: reader count, as a u32\n-// bytes 8-11: writer count, as a u32\n-\n-fn rwlock_get_readers<'mir, 'tcx: 'mir>(\n-    ecx: &MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n-    let readers_place =\n-        rwlock_place.offset(Size::from_bytes(4), MemPlaceMeta::None, u32_layout, ecx)?;\n-    ecx.read_scalar(readers_place.into())\n-}\n-\n-fn rwlock_set_readers<'mir, 'tcx: 'mir>(\n-    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-    readers: impl Into<ScalarMaybeUndef<Tag>>,\n-) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n-    let readers_place =\n-        rwlock_place.offset(Size::from_bytes(4), MemPlaceMeta::None, u32_layout, ecx)?;\n-    ecx.write_scalar(readers.into(), readers_place.into())\n-}\n-\n-fn rwlock_get_writers<'mir, 'tcx: 'mir>(\n-    ecx: &MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n-    let writers_place =\n-        rwlock_place.offset(Size::from_bytes(8), MemPlaceMeta::None, u32_layout, ecx)?;\n-    ecx.read_scalar(writers_place.into())\n-}\n-\n-fn rwlock_set_writers<'mir, 'tcx: 'mir>(\n-    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n-    rwlock_op: OpTy<'tcx, Tag>,\n-    writers: impl Into<ScalarMaybeUndef<Tag>>,\n-) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 12)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let u32_layout = ecx.layout_of(ecx.tcx.types.u32)?;\n-    let writers_place =\n-        rwlock_place.offset(Size::from_bytes(8), MemPlaceMeta::None, u32_layout, ecx)?;\n-    ecx.write_scalar(writers.into(), writers_place.into())\n-}"}]}