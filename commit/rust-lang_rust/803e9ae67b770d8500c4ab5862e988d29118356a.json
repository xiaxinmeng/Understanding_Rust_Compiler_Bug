{"sha": "803e9ae67b770d8500c4ab5862e988d29118356a", "node_id": "MDY6Q29tbWl0NzI0NzEyOjgwM2U5YWU2N2I3NzBkODUwMGM0YWI1ODYyZTk4OGQyOTExODM1NmE=", "commit": {"author": {"name": "Piotr Czarnecki", "email": "pioczarn@gmail.com", "date": "2015-08-12T03:52:37Z"}, "committer": {"name": "Piotr Czarnecki", "email": "pioczarn@gmail.com", "date": "2016-01-05T10:02:43Z"}, "message": "Improve TypedArena's chunk allocation scheme\n\nCloses #17931\nFixes #18037", "tree": {"sha": "aac3e81ccfbbe382d551c2ea7682730dba738c56", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/aac3e81ccfbbe382d551c2ea7682730dba738c56"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/803e9ae67b770d8500c4ab5862e988d29118356a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/803e9ae67b770d8500c4ab5862e988d29118356a", "html_url": "https://github.com/rust-lang/rust/commit/803e9ae67b770d8500c4ab5862e988d29118356a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/803e9ae67b770d8500c4ab5862e988d29118356a/comments", "author": {"login": "pczarn", "id": 3356767, "node_id": "MDQ6VXNlcjMzNTY3Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/3356767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pczarn", "html_url": "https://github.com/pczarn", "followers_url": "https://api.github.com/users/pczarn/followers", "following_url": "https://api.github.com/users/pczarn/following{/other_user}", "gists_url": "https://api.github.com/users/pczarn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pczarn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pczarn/subscriptions", "organizations_url": "https://api.github.com/users/pczarn/orgs", "repos_url": "https://api.github.com/users/pczarn/repos", "events_url": "https://api.github.com/users/pczarn/events{/privacy}", "received_events_url": "https://api.github.com/users/pczarn/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pczarn", "id": 3356767, "node_id": "MDQ6VXNlcjMzNTY3Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/3356767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pczarn", "html_url": "https://github.com/pczarn", "followers_url": "https://api.github.com/users/pczarn/followers", "following_url": "https://api.github.com/users/pczarn/following{/other_user}", "gists_url": "https://api.github.com/users/pczarn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pczarn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pczarn/subscriptions", "organizations_url": "https://api.github.com/users/pczarn/orgs", "repos_url": "https://api.github.com/users/pczarn/repos", "events_url": "https://api.github.com/users/pczarn/events{/privacy}", "received_events_url": "https://api.github.com/users/pczarn/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2674b2ca985f73ce389e2550f8df69927aeabc00", "url": "https://api.github.com/repos/rust-lang/rust/commits/2674b2ca985f73ce389e2550f8df69927aeabc00", "html_url": "https://github.com/rust-lang/rust/commit/2674b2ca985f73ce389e2550f8df69927aeabc00"}], "stats": {"total": 165, "additions": 90, "deletions": 75}, "files": [{"sha": "bb6521254a3ba47be196fbfd1e1646176ad14e07", "filename": "src/libarena/lib.rs", "status": "modified", "additions": 90, "deletions": 75, "changes": 165, "blob_url": "https://github.com/rust-lang/rust/blob/803e9ae67b770d8500c4ab5862e988d29118356a/src%2Flibarena%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/803e9ae67b770d8500c4ab5862e988d29118356a/src%2Flibarena%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibarena%2Flib.rs?ref=803e9ae67b770d8500c4ab5862e988d29118356a", "patch": "@@ -31,9 +31,10 @@\n #![feature(alloc)]\n #![feature(box_syntax)]\n #![feature(core_intrinsics)]\n+#![feature(drop_in_place)]\n+#![feature(raw)]\n #![feature(heap_api)]\n #![feature(oom)]\n-#![feature(ptr_as_ref)]\n #![feature(raw)]\n #![feature(staged_api)]\n #![feature(dropck_parametricity)]\n@@ -47,9 +48,13 @@ use std::intrinsics;\n use std::marker;\n use std::mem;\n use std::ptr;\n+use std::raw;\n+use std::raw::Repr;\n use std::rc::Rc;\n+use std::slice;\n \n-use alloc::heap::{allocate, deallocate};\n+use alloc::heap;\n+use alloc::raw_vec::RawVec;\n \n // The way arena uses arrays is really deeply awful. The arrays are\n // allocated, and have capacities reserved, but the fill for the array\n@@ -366,115 +371,87 @@ fn test_arena_destructors_fail() {\n /// A faster arena that can hold objects of only one type.\n pub struct TypedArena<T> {\n     /// A pointer to the next object to be allocated.\n-    ptr: Cell<*const T>,\n+    ptr: Cell<*mut T>,\n \n     /// A pointer to the end of the allocated area. When this pointer is\n     /// reached, a new chunk is allocated.\n-    end: Cell<*const T>,\n+    end: Cell<*mut T>,\n \n-    /// A pointer to the first arena segment.\n-    first: RefCell<*mut TypedArenaChunk<T>>,\n+    /// A vector arena segments.\n+    chunks: RefCell<Vec<TypedArenaChunk<T>>>,\n \n     /// Marker indicating that dropping the arena causes its owned\n     /// instances of `T` to be dropped.\n     _own: marker::PhantomData<T>,\n }\n \n struct TypedArenaChunk<T> {\n-    marker: marker::PhantomData<T>,\n-\n     /// Pointer to the next arena segment.\n-    next: *mut TypedArenaChunk<T>,\n-\n-    /// The number of elements that this chunk can hold.\n-    capacity: usize,\n-\n-    // Objects follow here, suitably aligned.\n-}\n-\n-fn calculate_size<T>(capacity: usize) -> usize {\n-    let mut size = mem::size_of::<TypedArenaChunk<T>>();\n-    size = round_up(size, mem::align_of::<T>());\n-    let elem_size = mem::size_of::<T>();\n-    let elems_size = elem_size.checked_mul(capacity).unwrap();\n-    size = size.checked_add(elems_size).unwrap();\n-    size\n+    storage: RawVec<T>,\n }\n \n impl<T> TypedArenaChunk<T> {\n     #[inline]\n-    unsafe fn new(next: *mut TypedArenaChunk<T>, capacity: usize) -> *mut TypedArenaChunk<T> {\n-        let size = calculate_size::<T>(capacity);\n-        let chunk =\n-            allocate(size, mem::align_of::<TypedArenaChunk<T>>()) as *mut TypedArenaChunk<T>;\n-        if chunk.is_null() {\n-            alloc::oom()\n-        }\n-        (*chunk).next = next;\n-        (*chunk).capacity = capacity;\n-        chunk\n+    unsafe fn new(capacity: usize) -> TypedArenaChunk<T> {\n+        TypedArenaChunk { storage: RawVec::with_capacity(capacity) }\n     }\n \n-    /// Destroys this arena chunk. If the type descriptor is supplied, the\n-    /// drop glue is called; otherwise, drop glue is not called.\n+    /// Destroys this arena chunk.\n     #[inline]\n     unsafe fn destroy(&mut self, len: usize) {\n-        // Destroy all the allocated objects.\n+        // The branch on needs_drop() is an -O1 performance optimization.\n+        // Without the branch, dropping TypedArena<u8> takes linear time.\n         if intrinsics::needs_drop::<T>() {\n             let mut start = self.start();\n+            // Destroy all allocated objects.\n             for _ in 0..len {\n-                ptr::read(start as *const T); // run the destructor on the pointer\n-                start = start.offset(mem::size_of::<T>() as isize)\n+                ptr::drop_in_place(start);\n+                start = start.offset(1);\n             }\n         }\n-\n-        // Destroy the next chunk.\n-        let next = self.next;\n-        let size = calculate_size::<T>(self.capacity);\n-        let self_ptr: *mut TypedArenaChunk<T> = self;\n-        deallocate(self_ptr as *mut u8,\n-                   size,\n-                   mem::align_of::<TypedArenaChunk<T>>());\n-        if !next.is_null() {\n-            let capacity = (*next).capacity;\n-            (*next).destroy(capacity);\n-        }\n     }\n \n     // Returns a pointer to the first allocated object.\n     #[inline]\n-    fn start(&self) -> *const u8 {\n-        let this: *const TypedArenaChunk<T> = self;\n-        unsafe { round_up(this.offset(1) as usize, mem::align_of::<T>()) as *const u8 }\n+    fn start(&self) -> *mut T {\n+        self.storage.ptr()\n     }\n \n     // Returns a pointer to the end of the allocated space.\n     #[inline]\n-    fn end(&self) -> *const u8 {\n+    fn end(&self) -> *mut T {\n         unsafe {\n-            let size = mem::size_of::<T>().checked_mul(self.capacity).unwrap();\n-            self.start().offset(size as isize)\n+            if mem::size_of::<T>() == 0 {\n+                // A pointer as large as possible for zero-sized elements.\n+                !0 as *mut T\n+            } else {\n+                self.start().offset(self.storage.cap() as isize)\n+            }\n         }\n     }\n }\n \n+const PAGE: usize = 4096;\n+\n impl<T> TypedArena<T> {\n-    /// Creates a new `TypedArena` with preallocated space for eight objects.\n+    /// Creates a new `TypedArena` with preallocated space for many objects.\n     #[inline]\n     pub fn new() -> TypedArena<T> {\n-        TypedArena::with_capacity(8)\n+        // Reserve at least one page.\n+        let elem_size = cmp::max(1, mem::size_of::<T>());\n+        TypedArena::with_capacity(PAGE / elem_size)\n     }\n \n     /// Creates a new `TypedArena` with preallocated space for the given number of\n     /// objects.\n     #[inline]\n     pub fn with_capacity(capacity: usize) -> TypedArena<T> {\n         unsafe {\n-            let chunk = TypedArenaChunk::<T>::new(ptr::null_mut(), capacity);\n+            let chunk = TypedArenaChunk::<T>::new(cmp::max(1, capacity));\n             TypedArena {\n-                ptr: Cell::new((*chunk).start() as *const T),\n-                end: Cell::new((*chunk).end() as *const T),\n-                first: RefCell::new(chunk),\n+                ptr: Cell::new(chunk.start()),\n+                end: Cell::new(chunk.end()),\n+                chunks: RefCell::new(vec![chunk]),\n                 _own: marker::PhantomData,\n             }\n         }\n@@ -488,23 +465,39 @@ impl<T> TypedArena<T> {\n         }\n \n         unsafe {\n-            let ptr: &mut T = &mut *(self.ptr.get() as *mut T);\n-            ptr::write(ptr, object);\n-            self.ptr.set(self.ptr.get().offset(1));\n-            ptr\n+            if mem::size_of::<T>() == 0 {\n+                self.ptr.set(intrinsics::arith_offset(self.ptr.get() as *mut u8, 1) as *mut T);\n+                let ptr = heap::EMPTY as *mut T;\n+                // Don't drop the object. This `write` is equivalent to `forget`.\n+                ptr::write(ptr, object);\n+                &mut *ptr\n+            } else {\n+                let ptr = self.ptr.get();\n+                // Advance the pointer.\n+                self.ptr.set(self.ptr.get().offset(1));\n+                // Write into uninitialized memory.\n+                ptr::write(ptr, object);\n+                &mut *ptr\n+            }\n         }\n     }\n \n     /// Grows the arena.\n     #[inline(never)]\n+    #[cold]\n     fn grow(&self) {\n         unsafe {\n-            let chunk = *self.first.borrow_mut();\n-            let new_capacity = (*chunk).capacity.checked_mul(2).unwrap();\n-            let chunk = TypedArenaChunk::<T>::new(chunk, new_capacity);\n-            self.ptr.set((*chunk).start() as *const T);\n-            self.end.set((*chunk).end() as *const T);\n-            *self.first.borrow_mut() = chunk\n+            let mut chunks = self.chunks.borrow_mut();\n+            let prev_capacity = chunks.last().unwrap().storage.cap();\n+            let new_capacity = prev_capacity.checked_mul(2).unwrap();\n+            if chunks.last_mut().unwrap().storage.double_in_place() {\n+                self.end.set(chunks.last().unwrap().end());\n+            } else {\n+                let chunk = TypedArenaChunk::<T>::new(new_capacity);\n+                self.ptr.set(chunk.start());\n+                self.end.set(chunk.end());\n+                chunks.push(chunk);\n+            }\n         }\n     }\n }\n@@ -514,12 +507,26 @@ impl<T> Drop for TypedArena<T> {\n     fn drop(&mut self) {\n         unsafe {\n             // Determine how much was filled.\n-            let start = self.first.borrow().as_ref().unwrap().start() as usize;\n+            let mut chunks_borrow = self.chunks.borrow_mut();\n+            let mut last_chunk = chunks_borrow.pop().unwrap();\n+            let start = last_chunk.start() as usize;\n             let end = self.ptr.get() as usize;\n-            let diff = (end - start) / mem::size_of::<T>();\n+            let diff = if mem::size_of::<T>() == 0 {\n+                // Avoid division by zero.\n+                end - start\n+            } else {\n+                (end - start) / mem::size_of::<T>()\n+            };\n \n             // Pass that to the `destroy` method.\n-            (**self.first.borrow_mut()).destroy(diff)\n+            last_chunk.destroy(diff);\n+            // Destroy this chunk.\n+            let _: RawVec<T> = mem::transmute(last_chunk);\n+\n+            for chunk in chunks_borrow.iter_mut() {\n+                let cap = chunk.storage.cap();\n+                chunk.destroy(cap);\n+            }\n         }\n     }\n }\n@@ -657,4 +664,12 @@ mod tests {\n             })\n         })\n     }\n+\n+    #[test]\n+    pub fn test_zero_sized() {\n+        let arena = TypedArena::new();\n+        for _ in 0..100000 {\n+            arena.alloc(());\n+        }\n+    }\n }"}]}