{"sha": "000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731", "node_id": "MDY6Q29tbWl0NzI0NzEyOjAwMGQzYzk3ZWViMjg2YTFhMWU5YzJmYTJhMWZjODg3NGVkOTM3MzE=", "commit": {"author": {"name": "Wesley Wiser", "email": "wwiser@gmail.com", "date": "2018-05-08T02:30:44Z"}, "committer": {"name": "Wesley Wiser", "email": "wwiser@gmail.com", "date": "2018-05-08T03:17:16Z"}, "message": "Make DepGraph::previous_work_products immutable\n\nFixes #50501", "tree": {"sha": "939d64a2ac96cedece97a3ee497a3256db4095ed", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/939d64a2ac96cedece97a3ee497a3256db4095ed"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731", "html_url": "https://github.com/rust-lang/rust/commit/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731/comments", "author": {"login": "wesleywiser", "id": 831192, "node_id": "MDQ6VXNlcjgzMTE5Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/831192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wesleywiser", "html_url": "https://github.com/wesleywiser", "followers_url": "https://api.github.com/users/wesleywiser/followers", "following_url": "https://api.github.com/users/wesleywiser/following{/other_user}", "gists_url": "https://api.github.com/users/wesleywiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/wesleywiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wesleywiser/subscriptions", "organizations_url": "https://api.github.com/users/wesleywiser/orgs", "repos_url": "https://api.github.com/users/wesleywiser/repos", "events_url": "https://api.github.com/users/wesleywiser/events{/privacy}", "received_events_url": "https://api.github.com/users/wesleywiser/received_events", "type": "User", "site_admin": false}, "committer": {"login": "wesleywiser", "id": 831192, "node_id": "MDQ6VXNlcjgzMTE5Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/831192?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wesleywiser", "html_url": "https://github.com/wesleywiser", "followers_url": "https://api.github.com/users/wesleywiser/followers", "following_url": "https://api.github.com/users/wesleywiser/following{/other_user}", "gists_url": "https://api.github.com/users/wesleywiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/wesleywiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wesleywiser/subscriptions", "organizations_url": "https://api.github.com/users/wesleywiser/orgs", "repos_url": "https://api.github.com/users/wesleywiser/repos", "events_url": "https://api.github.com/users/wesleywiser/events{/privacy}", "received_events_url": "https://api.github.com/users/wesleywiser/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "565235ee7e2d978e98b84450e15f673c84123a8a", "url": "https://api.github.com/repos/rust-lang/rust/commits/565235ee7e2d978e98b84450e15f673c84123a8a", "html_url": "https://github.com/rust-lang/rust/commit/565235ee7e2d978e98b84450e15f673c84123a8a"}], "stats": {"total": 157, "additions": 74, "deletions": 83}, "files": [{"sha": "61a7404b08526545885cf054442e697c645bd9b4", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 7, "deletions": 19, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731", "patch": "@@ -77,7 +77,7 @@ struct DepGraphData {\n     /// things available to us. If we find that they are not dirty, we\n     /// load the path to the file storing those work-products here into\n     /// this map. We can later look for and extract that data.\n-    previous_work_products: RwLock<FxHashMap<WorkProductId, WorkProduct>>,\n+    previous_work_products: FxHashMap<WorkProductId, WorkProduct>,\n \n     /// Work-products that we generate in this run.\n     work_products: RwLock<FxHashMap<WorkProductId, WorkProduct>>,\n@@ -90,7 +90,8 @@ struct DepGraphData {\n \n impl DepGraph {\n \n-    pub fn new(prev_graph: PreviousDepGraph) -> DepGraph {\n+    pub fn new(prev_graph: PreviousDepGraph,\n+               prev_work_products: FxHashMap<WorkProductId, WorkProduct>) -> DepGraph {\n         // Pre-allocate the fingerprints array. We over-allocate a little so\n         // that we hopefully don't have to re-allocate during this compilation\n         // session.\n@@ -100,7 +101,7 @@ impl DepGraph {\n                                                  (prev_graph_node_count * 115) / 100);\n         DepGraph {\n             data: Some(Lrc::new(DepGraphData {\n-                previous_work_products: RwLock::new(FxHashMap()),\n+                previous_work_products: prev_work_products,\n                 work_products: RwLock::new(FxHashMap()),\n                 dep_node_debug: Lock::new(FxHashMap()),\n                 current: Lock::new(CurrentDepGraph::new()),\n@@ -460,19 +461,6 @@ impl DepGraph {\n         self.data.as_ref().unwrap().previous.node_to_index(dep_node)\n     }\n \n-    /// Indicates that a previous work product exists for `v`. This is\n-    /// invoked during initial start-up based on what nodes are clean\n-    /// (and what files exist in the incr. directory).\n-    pub fn insert_previous_work_product(&self, v: &WorkProductId, data: WorkProduct) {\n-        debug!(\"insert_previous_work_product({:?}, {:?})\", v, data);\n-        self.data\n-            .as_ref()\n-            .unwrap()\n-            .previous_work_products\n-            .borrow_mut()\n-            .insert(v.clone(), data);\n-    }\n-\n     /// Indicates that we created the given work-product in this run\n     /// for `v`. This record will be preserved and loaded in the next\n     /// run.\n@@ -492,7 +480,7 @@ impl DepGraph {\n         self.data\n             .as_ref()\n             .and_then(|data| {\n-                data.previous_work_products.borrow().get(v).cloned()\n+                data.previous_work_products.get(v).cloned()\n             })\n     }\n \n@@ -504,8 +492,8 @@ impl DepGraph {\n \n     /// Access the map of work-products created during the cached run. Only\n     /// used during saving of the dep-graph.\n-    pub fn previous_work_products(&self) -> ReadGuard<FxHashMap<WorkProductId, WorkProduct>> {\n-        self.data.as_ref().unwrap().previous_work_products.borrow()\n+    pub fn previous_work_products(&self) -> &FxHashMap<WorkProductId, WorkProduct> {\n+        &self.data.as_ref().unwrap().previous_work_products\n     }\n \n     #[inline(always)]"}, {"sha": "1e74039503d51c5760498d1fd3f8de3f75e7b5d5", "filename": "src/librustc_driver/driver.rs", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731/src%2Flibrustc_driver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731/src%2Flibrustc_driver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fdriver.rs?ref=000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731", "patch": "@@ -980,15 +980,16 @@ where\n     let dep_graph = match future_dep_graph {\n         None => DepGraph::new_disabled(),\n         Some(future) => {\n-            let prev_graph = time(sess, \"blocked while dep-graph loading finishes\", || {\n-                future\n-                    .open()\n-                    .unwrap_or_else(|e| rustc_incremental::LoadResult::Error {\n-                        message: format!(\"could not decode incremental cache: {:?}\", e),\n-                    })\n-                    .open(sess)\n-            });\n-            DepGraph::new(prev_graph)\n+            let (prev_graph, prev_work_products) =\n+                time(sess, \"blocked while dep-graph loading finishes\", || {\n+                    future\n+                        .open()\n+                        .unwrap_or_else(|e| rustc_incremental::LoadResult::Error {\n+                            message: format!(\"could not decode incremental cache: {:?}\", e),\n+                        })\n+                        .open(sess)\n+                });\n+            DepGraph::new(prev_graph, prev_work_products)\n         }\n     };\n     let hir_forest = time(sess, \"lowering ast -> hir\", || {"}, {"sha": "01186483a6839619c3c72f51b13c2c7925216eef", "filename": "src/librustc_incremental/persist/load.rs", "status": "modified", "additions": 57, "deletions": 55, "changes": 112, "blob_url": "https://github.com/rust-lang/rust/blob/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fload.rs?ref=000d3c97eeb286a1a1e9c2fa2a1fc8874ed93731", "patch": "@@ -10,7 +10,8 @@\n \n //! Code to save/load the dep-graph from files.\n \n-use rustc::dep_graph::{PreviousDepGraph, SerializedDepGraph};\n+use rustc_data_structures::fx::FxHashMap;\n+use rustc::dep_graph::{PreviousDepGraph, SerializedDepGraph, WorkProduct, WorkProductId};\n use rustc::session::Session;\n use rustc::ty::TyCtxt;\n use rustc::ty::maps::OnDiskCache;\n@@ -32,73 +33,30 @@ pub fn dep_graph_tcx_init<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n \n     tcx.allocate_metadata_dep_nodes();\n     tcx.precompute_in_scope_traits_hashes();\n-\n-    if tcx.sess.incr_comp_session_dir_opt().is_none() {\n-        // If we are only building with -Zquery-dep-graph but without an actual\n-        // incr. comp. session directory, we exit here. Otherwise we'd fail\n-        // when trying to load work products.\n-        return\n-    }\n-\n-    let work_products_path = work_products_path(tcx.sess);\n-    let load_result = load_data(tcx.sess.opts.debugging_opts.incremental_info, &work_products_path);\n-\n-    if let LoadResult::Ok { data: (work_products_data, start_pos) } = load_result {\n-        // Decode the list of work_products\n-        let mut work_product_decoder = Decoder::new(&work_products_data[..], start_pos);\n-        let work_products: Vec<SerializedWorkProduct> =\n-            RustcDecodable::decode(&mut work_product_decoder).unwrap_or_else(|e| {\n-                let msg = format!(\"Error decoding `work-products` from incremental \\\n-                                   compilation session directory: {}\", e);\n-                tcx.sess.fatal(&msg[..])\n-            });\n-\n-        for swp in work_products {\n-            let mut all_files_exist = true;\n-            for &(_, ref file_name) in swp.work_product.saved_files.iter() {\n-                let path = in_incr_comp_dir_sess(tcx.sess, file_name);\n-                if !path.exists() {\n-                    all_files_exist = false;\n-\n-                    if tcx.sess.opts.debugging_opts.incremental_info {\n-                        eprintln!(\"incremental: could not find file for work \\\n-                                   product: {}\", path.display());\n-                    }\n-                }\n-            }\n-\n-            if all_files_exist {\n-                debug!(\"reconcile_work_products: all files for {:?} exist\", swp);\n-                tcx.dep_graph.insert_previous_work_product(&swp.id, swp.work_product);\n-            } else {\n-                debug!(\"reconcile_work_products: some file for {:?} does not exist\", swp);\n-                delete_dirty_work_product(tcx, swp);\n-            }\n-        }\n-    }\n }\n \n+type WorkProductMap = FxHashMap<WorkProductId, WorkProduct>;\n+\n pub enum LoadResult<T> {\n     Ok { data: T },\n     DataOutOfDate,\n     Error { message: String },\n }\n \n-\n-impl LoadResult<PreviousDepGraph> {\n-    pub fn open(self, sess: &Session) -> PreviousDepGraph {\n+impl LoadResult<(PreviousDepGraph, WorkProductMap)> {\n+    pub fn open(self, sess: &Session) -> (PreviousDepGraph, WorkProductMap) {\n         match self {\n             LoadResult::Error { message } => {\n                 sess.warn(&message);\n-                PreviousDepGraph::new(SerializedDepGraph::new())\n+                (PreviousDepGraph::new(SerializedDepGraph::new()), FxHashMap())\n             },\n             LoadResult::DataOutOfDate => {\n                 if let Err(err) = delete_all_session_dir_contents(sess) {\n                     sess.err(&format!(\"Failed to delete invalidated or incompatible \\\n                                       incremental compilation session directory contents `{}`: {}.\",\n                                       dep_graph_path(sess).display(), err));\n                 }\n-                PreviousDepGraph::new(SerializedDepGraph::new())\n+                (PreviousDepGraph::new(SerializedDepGraph::new()), FxHashMap())\n             }\n             LoadResult::Ok { data } => data\n         }\n@@ -125,10 +83,10 @@ fn load_data(report_incremental_info: bool, path: &Path) -> LoadResult<(Vec<u8>,\n     }\n }\n \n-fn delete_dirty_work_product(tcx: TyCtxt,\n+fn delete_dirty_work_product(sess: &Session,\n                              swp: SerializedWorkProduct) {\n     debug!(\"delete_dirty_work_product({:?})\", swp);\n-    work_product::delete_workproduct_files(tcx.sess, &swp.work_product);\n+    work_product::delete_workproduct_files(sess, &swp.work_product);\n }\n \n /// Either a result that has already be computed or a\n@@ -149,7 +107,7 @@ impl<T> MaybeAsync<T> {\n \n /// Launch a thread and load the dependency graph in the background.\n pub fn load_dep_graph(sess: &Session) ->\n-    MaybeAsync<LoadResult<PreviousDepGraph>>\n+    MaybeAsync<LoadResult<(PreviousDepGraph, WorkProductMap)>>\n {\n     // Since `sess` isn't `Sync`, we perform all accesses to `sess`\n     // before we fire the background thread.\n@@ -159,7 +117,7 @@ pub fn load_dep_graph(sess: &Session) ->\n     if sess.opts.incremental.is_none() {\n         // No incremental compilation.\n         return MaybeAsync::Sync(LoadResult::Ok {\n-            data: PreviousDepGraph::new(SerializedDepGraph::new())\n+            data: (PreviousDepGraph::new(SerializedDepGraph::new()), FxHashMap())\n         });\n     }\n \n@@ -169,6 +127,50 @@ pub fn load_dep_graph(sess: &Session) ->\n     let report_incremental_info = sess.opts.debugging_opts.incremental_info;\n     let expected_hash = sess.opts.dep_tracking_hash();\n \n+    let mut prev_work_products = FxHashMap();\n+\n+    // If we are only building with -Zquery-dep-graph but without an actual\n+    // incr. comp. session directory, we exit here. Otherwise we'd fail\n+    // when trying to load work products.\n+    if sess.incr_comp_session_dir_opt().is_some() {\n+        let work_products_path = work_products_path(sess);\n+        let load_result = load_data(report_incremental_info, &work_products_path);\n+\n+        if let LoadResult::Ok { data: (work_products_data, start_pos) } = load_result {\n+            // Decode the list of work_products\n+            let mut work_product_decoder = Decoder::new(&work_products_data[..], start_pos);\n+            let work_products: Vec<SerializedWorkProduct> =\n+                RustcDecodable::decode(&mut work_product_decoder).unwrap_or_else(|e| {\n+                    let msg = format!(\"Error decoding `work-products` from incremental \\\n+                                    compilation session directory: {}\", e);\n+                    sess.fatal(&msg[..])\n+                });\n+\n+            for swp in work_products {\n+                let mut all_files_exist = true;\n+                for &(_, ref file_name) in swp.work_product.saved_files.iter() {\n+                    let path = in_incr_comp_dir_sess(sess, file_name);\n+                    if !path.exists() {\n+                        all_files_exist = false;\n+\n+                        if sess.opts.debugging_opts.incremental_info {\n+                            eprintln!(\"incremental: could not find file for work \\\n+                                    product: {}\", path.display());\n+                        }\n+                    }\n+                }\n+\n+                if all_files_exist {\n+                    debug!(\"reconcile_work_products: all files for {:?} exist\", swp);\n+                    prev_work_products.insert(swp.id, swp.work_product);\n+                } else {\n+                    debug!(\"reconcile_work_products: some file for {:?} does not exist\", swp);\n+                    delete_dirty_work_product(sess, swp);\n+                }\n+            }\n+        }\n+    }\n+\n     MaybeAsync::Async(std::thread::spawn(move || {\n         time_ext(time_passes, None, \"background load prev dep-graph\", move || {\n             match load_data(report_incremental_info, &path) {\n@@ -195,7 +197,7 @@ pub fn load_dep_graph(sess: &Session) ->\n                     let dep_graph = SerializedDepGraph::decode(&mut decoder)\n                         .expect(\"Error reading cached dep-graph\");\n \n-                    LoadResult::Ok { data: PreviousDepGraph::new(dep_graph) }\n+                    LoadResult::Ok { data: (PreviousDepGraph::new(dep_graph), prev_work_products) }\n                 }\n             }\n         })"}]}