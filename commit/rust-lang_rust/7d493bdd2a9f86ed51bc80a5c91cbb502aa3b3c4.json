{"sha": "7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdkNDkzYmRkMmE5Zjg2ZWQ1MWJjODBhNWM5MWNiYjUwMmFhM2IzYzQ=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-03-29T01:55:01Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-06-26T02:06:31Z"}, "message": "Add `LazyTokenStream`.", "tree": {"sha": "1bc25f9a4588f4e41aa43a1e61d0d20350c11a20", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1bc25f9a4588f4e41aa43a1e61d0d20350c11a20"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "html_url": "https://github.com/rust-lang/rust/commit/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e42836b2085233323339bacb636ecf9c28e8422e", "url": "https://api.github.com/repos/rust-lang/rust/commits/e42836b2085233323339bacb636ecf9c28e8422e", "html_url": "https://github.com/rust-lang/rust/commit/e42836b2085233323339bacb636ecf9c28e8422e"}], "stats": {"total": 240, "additions": 151, "deletions": 89}, "files": [{"sha": "8a345e67c57b32188d9ed0787998bb7a85ddbbde", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 28, "deletions": 8, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -42,6 +42,7 @@\n #![feature(staged_api)]\n #![feature(lang_items)]\n \n+#[macro_use]\n extern crate syntax;\n extern crate syntax_pos;\n \n@@ -50,7 +51,8 @@ use std::str::FromStr;\n \n use syntax::ast;\n use syntax::errors::DiagnosticBuilder;\n-use syntax::parse::{self, token};\n+use syntax::parse::{self, token, parse_stream_from_source_str};\n+use syntax::print::pprust;\n use syntax::symbol;\n use syntax::tokenstream;\n use syntax_pos::DUMMY_SP;\n@@ -337,8 +339,18 @@ impl Iterator for TokenIter {\n     type Item = TokenTree;\n \n     fn next(&mut self) -> Option<TokenTree> {\n-        self.next.take().or_else(|| self.cursor.next_as_stream())\n-            .map(|next| TokenTree::from_raw(next, &mut self.next))\n+        loop {\n+            let next =\n+                unwrap_or!(self.next.take().or_else(|| self.cursor.next_as_stream()), return None);\n+            let tree = TokenTree::from_raw(next, &mut self.next);\n+            if tree.span.0 == DUMMY_SP {\n+                if let TokenKind::Sequence(Delimiter::None, stream) = tree.kind {\n+                    self.cursor.insert(stream.0);\n+                    continue\n+                }\n+            }\n+            return Some(tree);\n+        }\n     }\n }\n \n@@ -449,7 +461,14 @@ impl TokenTree {\n             Ident(ident) | Lifetime(ident) => TokenKind::Word(Symbol(ident.name)),\n             Literal(..) | DocComment(..) => TokenKind::Literal(self::Literal(token)),\n \n-            Interpolated(..) => unimplemented!(),\n+            Interpolated(ref nt) => __internal::with_sess(|(sess, _)| {\n+                TokenKind::Sequence(Delimiter::None, TokenStream(nt.1.force(|| {\n+                    // FIXME(jseyfried): Avoid this pretty-print + reparse hack\n+                    let name = \"<macro expansion>\".to_owned();\n+                    let source = pprust::token_to_string(&token);\n+                    parse_stream_from_source_str(name, source, sess, Some(span))\n+                })))\n+            }),\n \n             OpenDelim(..) | CloseDelim(..) => unreachable!(),\n             Whitespace | Comment | Shebang(..) | Eof => unreachable!(),\n@@ -530,20 +549,21 @@ pub mod __internal {\n     pub use self::quote::{Quoter, __rt};\n \n     use std::cell::Cell;\n-    use std::rc::Rc;\n \n     use syntax::ast;\n     use syntax::ext::base::ExtCtxt;\n     use syntax::ext::hygiene::Mark;\n     use syntax::ptr::P;\n-    use syntax::parse::{self, token, ParseSess};\n+    use syntax::parse::{self, ParseSess};\n+    use syntax::parse::token::{self, Token};\n     use syntax::tokenstream;\n+    use syntax_pos::DUMMY_SP;\n \n     use super::{TokenStream, LexError};\n \n     pub fn new_token_stream(item: P<ast::Item>) -> TokenStream {\n-        let (span, token) = (item.span, token::Interpolated(Rc::new(token::NtItem(item))));\n-        TokenStream(tokenstream::TokenTree::Token(span, token).into())\n+        let token = Token::interpolated(token::NtItem(item));\n+        TokenStream(tokenstream::TokenTree::Token(DUMMY_SP, token).into())\n     }\n \n     pub fn token_stream_wrap(inner: tokenstream::TokenStream) -> TokenStream {"}, {"sha": "f0fc849c0c596a67f4ad0935ab920f33cfa209f6", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -1057,7 +1057,7 @@ impl MetaItem {\n     {\n         let (mut span, name) = match tokens.next() {\n             Some(TokenTree::Token(span, Token::Ident(ident))) => (span, ident.name),\n-            Some(TokenTree::Token(_, Token::Interpolated(ref nt))) => match **nt {\n+            Some(TokenTree::Token(_, Token::Interpolated(ref nt))) => match nt.0 {\n                 token::Nonterminal::NtIdent(ident) => (ident.span, ident.node.name),\n                 token::Nonterminal::NtMeta(ref meta) => return Some(meta.clone()),\n                 _ => return None,\n@@ -1229,7 +1229,7 @@ impl LitKind {\n         match token {\n             Token::Ident(ident) if ident.name == \"true\" => Some(LitKind::Bool(true)),\n             Token::Ident(ident) if ident.name == \"false\" => Some(LitKind::Bool(false)),\n-            Token::Interpolated(ref nt) => match **nt {\n+            Token::Interpolated(ref nt) => match nt.0 {\n                 token::NtExpr(ref v) => match v.node {\n                     ExprKind::Lit(ref lit) => Some(lit.node.clone()),\n                     _ => None,"}, {"sha": "4881170c1d13af7aa8c9cf3d43ed93faff6c8b21", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -215,7 +215,7 @@ impl<F> TTMacroExpander for F\n         impl Folder for AvoidInterpolatedIdents {\n             fn fold_tt(&mut self, tt: tokenstream::TokenTree) -> tokenstream::TokenTree {\n                 if let tokenstream::TokenTree::Token(_, token::Interpolated(ref nt)) = tt {\n-                    if let token::NtIdent(ident) = **nt {\n+                    if let token::NtIdent(ident) = nt.0 {\n                         return tokenstream::TokenTree::Token(ident.span, token::Ident(ident.node));\n                     }\n                 }"}, {"sha": "d2e51c9cb4868df9be0c10938d4063b44569dde3", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 10, "deletions": 30, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -21,15 +21,15 @@ use ext::placeholders::{placeholder, PlaceholderExpander};\n use feature_gate::{self, Features, is_builtin_attr};\n use fold;\n use fold::*;\n-use parse::{filemap_to_stream, ParseSess, DirectoryOwnership, PResult, token};\n+use parse::{DirectoryOwnership, PResult};\n+use parse::token::{self, Token};\n use parse::parser::Parser;\n-use print::pprust;\n use ptr::P;\n use std_inject;\n use symbol::Symbol;\n use symbol::keywords;\n use syntax_pos::{Span, DUMMY_SP};\n-use tokenstream::TokenStream;\n+use tokenstream::{TokenStream, TokenTree};\n use util::small_vector::SmallVector;\n use visit::Visitor;\n \n@@ -427,11 +427,13 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n                 kind.expect_from_annotatables(items)\n             }\n             SyntaxExtension::AttrProcMacro(ref mac) => {\n-                let item_toks = stream_for_item(&item, self.cx.parse_sess);\n-\n-                let span = Span { ctxt: self.cx.backtrace(), ..attr.span };\n-                let tok_result = mac.expand(self.cx, attr.span, attr.tokens, item_toks);\n-                self.parse_expansion(tok_result, kind, &attr.path, span)\n+                let item_tok = TokenTree::Token(DUMMY_SP, Token::interpolated(match item {\n+                    Annotatable::Item(item) => token::NtItem(item),\n+                    Annotatable::TraitItem(item) => token::NtTraitItem(item.unwrap()),\n+                    Annotatable::ImplItem(item) => token::NtImplItem(item.unwrap()),\n+                })).into();\n+                let tok_result = mac.expand(self.cx, attr.span, attr.tokens, item_tok);\n+                self.parse_expansion(tok_result, kind, &attr.path, attr.span)\n             }\n             SyntaxExtension::ProcMacroDerive(..) | SyntaxExtension::BuiltinDerive(..) => {\n                 self.cx.span_err(attr.span, &format!(\"`{}` is a derive mode\", attr.path));\n@@ -769,28 +771,6 @@ pub fn find_attr_invoc(attrs: &mut Vec<ast::Attribute>) -> Option<ast::Attribute\n          .map(|i| attrs.remove(i))\n }\n \n-// These are pretty nasty. Ideally, we would keep the tokens around, linked from\n-// the AST. However, we don't so we need to create new ones. Since the item might\n-// have come from a macro expansion (possibly only in part), we can't use the\n-// existing codemap.\n-//\n-// Therefore, we must use the pretty printer (yuck) to turn the AST node into a\n-// string, which we then re-tokenise (double yuck), but first we have to patch\n-// the pretty-printed string on to the end of the existing codemap (infinity-yuck).\n-fn stream_for_item(item: &Annotatable, parse_sess: &ParseSess) -> TokenStream {\n-    let text = match *item {\n-        Annotatable::Item(ref i) => pprust::item_to_string(i),\n-        Annotatable::TraitItem(ref ti) => pprust::trait_item_to_string(ti),\n-        Annotatable::ImplItem(ref ii) => pprust::impl_item_to_string(ii),\n-    };\n-    string_to_stream(text, parse_sess, item.span())\n-}\n-\n-fn string_to_stream(text: String, parse_sess: &ParseSess, span: Span) -> TokenStream {\n-    let filename = String::from(\"<macro expansion>\");\n-    filemap_to_stream(parse_sess, parse_sess.codemap().new_filemap(filename, text), Some(span))\n-}\n-\n impl<'a, 'b> Folder for InvocationCollector<'a, 'b> {\n     fn fold_expr(&mut self, expr: P<ast::Expr>) -> P<ast::Expr> {\n         let mut expr = self.cfg.configure_expr(expr).unwrap();"}, {"sha": "9907dfe341e75d4465789a2a1ef6316f992a3b9e", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 18, "deletions": 18, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -30,9 +30,9 @@ pub mod rt {\n     use ast;\n     use codemap::Spanned;\n     use ext::base::ExtCtxt;\n-    use parse::{self, token, classify};\n+    use parse::{self, classify};\n+    use parse::token::{self, Token};\n     use ptr::P;\n-    use std::rc::Rc;\n     use symbol::Symbol;\n \n     use tokenstream::{self, TokenTree, TokenStream};\n@@ -82,70 +82,70 @@ pub mod rt {\n     impl ToTokens for ast::Path {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtPath(self.clone());\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(DUMMY_SP, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::Ty {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtTy(P(self.clone()));\n-            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(self.span, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::Block {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtBlock(P(self.clone()));\n-            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(self.span, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::Generics {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtGenerics(self.clone());\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(DUMMY_SP, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::WhereClause {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtWhereClause(self.clone());\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(DUMMY_SP, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for P<ast::Item> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtItem(self.clone());\n-            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(self.span, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::ImplItem {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtImplItem(self.clone());\n-            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(self.span, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for P<ast::ImplItem> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtImplItem((**self).clone());\n-            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(self.span, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::TraitItem {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtTraitItem(self.clone());\n-            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(self.span, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::Stmt {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtStmt(self.clone());\n-            let mut tts = vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))];\n+            let mut tts = vec![TokenTree::Token(self.span, Token::interpolated(nt))];\n \n             // Some statements require a trailing semicolon.\n             if classify::stmt_ends_with_semi(&self.node) {\n@@ -159,35 +159,35 @@ pub mod rt {\n     impl ToTokens for P<ast::Expr> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtExpr(self.clone());\n-            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(self.span, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for P<ast::Pat> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtPat(self.clone());\n-            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(self.span, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::Arm {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtArm(self.clone());\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(DUMMY_SP, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for ast::Arg {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtArg(self.clone());\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(DUMMY_SP, Token::interpolated(nt))]\n         }\n     }\n \n     impl ToTokens for P<ast::Block> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtBlock(self.clone());\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(DUMMY_SP, Token::interpolated(nt))]\n         }\n     }\n \n@@ -215,7 +215,7 @@ pub mod rt {\n     impl ToTokens for ast::MetaItem {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n             let nt = token::NtMeta(self.clone());\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n+            vec![TokenTree::Token(DUMMY_SP, Token::interpolated(nt))]\n         }\n     }\n "}, {"sha": "fe3dd83f9d5c0e60af278b297feba77380eb4608", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -156,7 +156,7 @@ pub fn transcribe(cx: &ExtCtxt,\n                             result.push(tt.clone().into());\n                         } else {\n                             sp.ctxt = sp.ctxt.apply_mark(cx.current_expansion.mark);\n-                            let token = TokenTree::Token(sp, token::Interpolated(nt.clone()));\n+                            let token = TokenTree::Token(sp, Token::interpolated((**nt).clone()));\n                             result.push(token.into());\n                         }\n                     } else {"}, {"sha": "1fc670ec9f7fb26dad735284192e131eb3d27d24", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -22,7 +22,7 @@ use ast::*;\n use ast;\n use syntax_pos::Span;\n use codemap::{Spanned, respan};\n-use parse::token;\n+use parse::token::{self, Token};\n use ptr::P;\n use symbol::keywords;\n use tokenstream::*;\n@@ -586,7 +586,7 @@ pub fn noop_fold_token<T: Folder>(t: token::Token, fld: &mut T) -> token::Token\n                 Ok(nt) => nt,\n                 Err(nt) => (*nt).clone(),\n             };\n-            token::Interpolated(Rc::new(fld.fold_interpolated(nt)))\n+            Token::interpolated(fld.fold_interpolated(nt.0))\n         }\n         _ => t\n     }"}, {"sha": "c99a09ab24e6b076ff12d4e9dc3312829c5c4bdc", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -151,7 +151,7 @@ impl<'a> Parser<'a> {\n \n     pub fn parse_path_and_tokens(&mut self) -> PResult<'a, (ast::Path, TokenStream)> {\n         let meta = match self.token {\n-            token::Interpolated(ref nt) => match **nt {\n+            token::Interpolated(ref nt) => match nt.0 {\n                 Nonterminal::NtMeta(ref meta) => Some(meta.clone()),\n                 _ => None,\n             },\n@@ -223,7 +223,7 @@ impl<'a> Parser<'a> {\n     /// meta_item_inner : (meta_item | UNSUFFIXED_LIT) (',' meta_item_inner)? ;\n     pub fn parse_meta_item(&mut self) -> PResult<'a, ast::MetaItem> {\n         let nt_meta = match self.token {\n-            token::Interpolated(ref nt) => match **nt {\n+            token::Interpolated(ref nt) => match nt.0 {\n                 token::NtMeta(ref e) => Some(e.clone()),\n                 _ => None,\n             },"}, {"sha": "2858d49d63db7fe8b9a3287ab9bf2741b8ac847b", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -107,7 +107,7 @@ pub enum BlockMode {\n macro_rules! maybe_whole_expr {\n     ($p:expr) => {\n         if let token::Interpolated(nt) = $p.token.clone() {\n-            match *nt {\n+            match nt.0 {\n                 token::NtExpr(ref e) => {\n                     $p.bump();\n                     return Ok((*e).clone());\n@@ -134,7 +134,7 @@ macro_rules! maybe_whole_expr {\n macro_rules! maybe_whole {\n     ($p:expr, $constructor:ident, |$x:ident| $e:expr) => {\n         if let token::Interpolated(nt) = $p.token.clone() {\n-            if let token::$constructor($x) = (*nt).clone() {\n+            if let token::$constructor($x) = nt.0.clone() {\n                 $p.bump();\n                 return Ok($e);\n             }\n@@ -1620,7 +1620,7 @@ impl<'a> Parser<'a> {\n     /// Matches token_lit = LIT_INTEGER | ...\n     pub fn parse_lit_token(&mut self) -> PResult<'a, LitKind> {\n         let out = match self.token {\n-            token::Interpolated(ref nt) => match **nt {\n+            token::Interpolated(ref nt) => match nt.0 {\n                 token::NtExpr(ref v) => match v.node {\n                     ExprKind::Lit(ref lit) => { lit.node.clone() }\n                     _ => { return self.unexpected_last(&self.token); }\n@@ -1791,7 +1791,7 @@ impl<'a> Parser<'a> {\n     /// This is used when parsing derive macro paths in `#[derive]` attributes.\n     pub fn parse_path_allowing_meta(&mut self, mode: PathStyle) -> PResult<'a, ast::Path> {\n         let meta_ident = match self.token {\n-            token::Interpolated(ref nt) => match **nt {\n+            token::Interpolated(ref nt) => match nt.0 {\n                 token::NtMeta(ref meta) => match meta.node {\n                     ast::MetaItemKind::Word => Some(ast::Ident::with_empty_ctxt(meta.name)),\n                     _ => None,\n@@ -2635,7 +2635,7 @@ impl<'a> Parser<'a> {\n             }\n             token::Interpolated(ref nt) => {\n                 self.meta_var_span = Some(self.span);\n-                match **nt {\n+                match nt.0 {\n                     token::NtIdent(ident) => ident,\n                     _ => return,\n                 }"}, {"sha": "189a18f44203346ebdb9bba842d3c1953dd8f560", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 47, "deletions": 6, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -16,9 +16,11 @@ pub use self::Token::*;\n \n use ast::{self};\n use ptr::P;\n+use serialize::{Decodable, Decoder, Encodable, Encoder};\n use symbol::keywords;\n-use tokenstream::TokenTree;\n+use tokenstream::{TokenStream, TokenTree};\n \n+use std::cell::RefCell;\n use std::fmt;\n use std::rc::Rc;\n \n@@ -168,7 +170,7 @@ pub enum Token {\n     Lifetime(ast::Ident),\n \n     /* For interpolation */\n-    Interpolated(Rc<Nonterminal>),\n+    Interpolated(Rc<(Nonterminal, LazyTokenStream)>),\n     // Can be expanded into several tokens.\n     /// Doc comment\n     DocComment(ast::Name),\n@@ -187,6 +189,10 @@ pub enum Token {\n }\n \n impl Token {\n+    pub fn interpolated(nt: Nonterminal) -> Token {\n+        Token::Interpolated(Rc::new((nt, LazyTokenStream::new())))\n+    }\n+\n     /// Returns `true` if the token starts with '>'.\n     pub fn is_like_gt(&self) -> bool {\n         match *self {\n@@ -211,7 +217,7 @@ impl Token {\n             Lt | BinOp(Shl)             | // associated path\n             ModSep                      | // global path\n             Pound                       => true, // expression attributes\n-            Interpolated(ref nt) => match **nt {\n+            Interpolated(ref nt) => match nt.0 {\n                 NtIdent(..) | NtExpr(..) | NtBlock(..) | NtPath(..) => true,\n                 _ => false,\n             },\n@@ -234,7 +240,7 @@ impl Token {\n             Lifetime(..)                | // lifetime bound in trait object\n             Lt | BinOp(Shl)             | // associated path\n             ModSep                      => true, // global path\n-            Interpolated(ref nt) => match **nt {\n+            Interpolated(ref nt) => match nt.0 {\n                 NtIdent(..) | NtTy(..) | NtPath(..) => true,\n                 _ => false,\n             },\n@@ -253,7 +259,7 @@ impl Token {\n     pub fn ident(&self) -> Option<ast::Ident> {\n         match *self {\n             Ident(ident) => Some(ident),\n-            Interpolated(ref nt) => match **nt {\n+            Interpolated(ref nt) => match nt.0 {\n                 NtIdent(ident) => Some(ident.node),\n                 _ => None,\n             },\n@@ -285,7 +291,7 @@ impl Token {\n     /// Returns `true` if the token is an interpolated path.\n     pub fn is_path(&self) -> bool {\n         if let Interpolated(ref nt) = *self {\n-            if let NtPath(..) = **nt {\n+            if let NtPath(..) = nt.0 {\n                 return true;\n             }\n         }\n@@ -461,3 +467,38 @@ pub fn is_op(tok: &Token) -> bool {\n         _ => true,\n     }\n }\n+\n+#[derive(Clone, Eq, PartialEq, Debug)]\n+pub struct LazyTokenStream(RefCell<Option<TokenStream>>);\n+\n+impl LazyTokenStream {\n+    pub fn new() -> Self {\n+        LazyTokenStream(RefCell::new(None))\n+    }\n+\n+    pub fn force<F: FnOnce() -> TokenStream>(&self, f: F) -> TokenStream {\n+        let mut opt_stream = self.0.borrow_mut();\n+        if opt_stream.is_none() {\n+            *opt_stream = Some(f());\n+        };\n+        opt_stream.clone().unwrap()\n+    }\n+}\n+\n+impl Encodable for LazyTokenStream {\n+    fn encode<S: Encoder>(&self, _: &mut S) -> Result<(), S::Error> {\n+        Ok(())\n+    }\n+}\n+\n+impl Decodable for LazyTokenStream {\n+    fn decode<D: Decoder>(_: &mut D) -> Result<LazyTokenStream, D::Error> {\n+        Ok(LazyTokenStream::new())\n+    }\n+}\n+\n+impl ::std::hash::Hash for LazyTokenStream {\n+    fn hash<H: ::std::hash::Hasher>(&self, hasher: &mut H) {\n+        self.0.borrow().hash(hasher);\n+    }\n+}"}, {"sha": "ac5b32c828ae2fc24e3d771fa654600840147e7e", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -275,7 +275,7 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::Comment              => \"/* */\".to_string(),\n         token::Shebang(s)           => format!(\"/* shebang: {}*/\", s),\n \n-        token::Interpolated(ref nt) => match **nt {\n+        token::Interpolated(ref nt) => match nt.0 {\n             token::NtExpr(ref e)        => expr_to_string(e),\n             token::NtMeta(ref e)        => meta_item_to_string(e),\n             token::NtTy(ref e)          => ty_to_string(e),"}, {"sha": "a3c3fa3a52ee7311686cbba664ff636acb5e6a8e", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 33, "deletions": 12, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -348,17 +348,18 @@ struct StreamCursor {\n }\n \n impl StreamCursor {\n+    fn new(stream: RcSlice<TokenStream>) -> Self {\n+        StreamCursor { stream: stream, index: 0, stack: Vec::new() }\n+    }\n+\n     fn next_as_stream(&mut self) -> Option<TokenStream> {\n         loop {\n             if self.index < self.stream.len() {\n                 self.index += 1;\n                 let next = self.stream[self.index - 1].clone();\n                 match next.kind {\n                     TokenStreamKind::Tree(..) | TokenStreamKind::JointTree(..) => return Some(next),\n-                    TokenStreamKind::Stream(stream) => {\n-                        self.stack.push((mem::replace(&mut self.stream, stream),\n-                                         mem::replace(&mut self.index, 0)));\n-                    }\n+                    TokenStreamKind::Stream(stream) => self.insert(stream),\n                     TokenStreamKind::Empty => {}\n                 }\n             } else if let Some((stream, index)) = self.stack.pop() {\n@@ -369,6 +370,11 @@ impl StreamCursor {\n             }\n         }\n     }\n+\n+    fn insert(&mut self, stream: RcSlice<TokenStream>) {\n+        self.stack.push((mem::replace(&mut self.stream, stream),\n+                         mem::replace(&mut self.index, 0)));\n+    }\n }\n \n impl Iterator for Cursor {\n@@ -388,9 +394,7 @@ impl Cursor {\n             TokenStreamKind::Empty => CursorKind::Empty,\n             TokenStreamKind::Tree(tree) => CursorKind::Tree(tree, false),\n             TokenStreamKind::JointTree(tree) => CursorKind::JointTree(tree, false),\n-            TokenStreamKind::Stream(stream) => {\n-                CursorKind::Stream(StreamCursor { stream: stream, index: 0, stack: Vec::new() })\n-            }\n+            TokenStreamKind::Stream(stream) => CursorKind::Stream(StreamCursor::new(stream)),\n         })\n     }\n \n@@ -408,13 +412,30 @@ impl Cursor {\n         Some(stream)\n     }\n \n-    pub fn original_stream(self) -> TokenStream {\n+    pub fn insert(&mut self, stream: TokenStream) {\n+        match self.0 {\n+            _ if stream.is_empty() => return,\n+            CursorKind::Empty => *self = stream.trees(),\n+            CursorKind::Tree(_, consumed) | CursorKind::JointTree(_, consumed) => {\n+                *self = TokenStream::concat(vec![self.original_stream(), stream]).trees();\n+                if consumed {\n+                    self.next();\n+                }\n+            }\n+            CursorKind::Stream(ref mut cursor) => {\n+                cursor.insert(ThinTokenStream::from(stream).0.unwrap());\n+            }\n+        }\n+    }\n+\n+    pub fn original_stream(&self) -> TokenStream {\n         match self.0 {\n             CursorKind::Empty => TokenStream::empty(),\n-            CursorKind::Tree(tree, _) => tree.into(),\n-            CursorKind::JointTree(tree, _) => tree.joint(),\n-            CursorKind::Stream(cursor) => TokenStream::concat_rc_slice({\n-                cursor.stack.get(0).cloned().map(|(stream, _)| stream).unwrap_or(cursor.stream)\n+            CursorKind::Tree(ref tree, _) => tree.clone().into(),\n+            CursorKind::JointTree(ref tree, _) => tree.clone().joint(),\n+            CursorKind::Stream(ref cursor) => TokenStream::concat_rc_slice({\n+                cursor.stack.get(0).cloned().map(|(stream, _)| stream)\n+                    .unwrap_or(cursor.stream.clone())\n             }),\n         }\n     }"}, {"sha": "93815d16837d30fa40cda8ae9ee2f387ed41e44a", "filename": "src/test/run-pass-fulldeps/proc-macro/auxiliary/attr-args.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fattr-args.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fattr-args.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc-macro%2Fauxiliary%2Fattr-args.rs?ref=7d493bdd2a9f86ed51bc80a5c91cbb502aa3b3c4", "patch": "@@ -24,7 +24,7 @@ pub fn attr_with_args(args: TokenStream, input: TokenStream) -> TokenStream {\n \n     let input = input.to_string();\n \n-    assert_eq!(input, \"fn foo (  ) {  }\");\n+    assert_eq!(input, \"fn foo() { }\");\n \n     r#\"\n         fn foo() -> &'static str { \"Hello, world!\" }"}]}