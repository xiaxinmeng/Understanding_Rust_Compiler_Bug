{"sha": "7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdkYjA0ODM1ZjlhYjNhYjNkNGI2ZjhhOTE1NDdhMmM3YTRmNjYwOTE=", "commit": {"author": {"name": "Oliver Scherer", "email": "github35764891676564198441@oli-obk.de", "date": "2018-10-23T16:05:32Z"}, "committer": {"name": "Oliver Scherer", "email": "github35764891676564198441@oli-obk.de", "date": "2018-11-08T13:52:02Z"}, "message": "Move `Allocation` into its own module", "tree": {"sha": "9952a247745b597f85eb533ca43cf986e7434773", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9952a247745b597f85eb533ca43cf986e7434773"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091", "html_url": "https://github.com/rust-lang/rust/commit/7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091/comments", "author": {"login": "oli-obk", "id": 332036, "node_id": "MDQ6VXNlcjMzMjAzNg==", "avatar_url": "https://avatars.githubusercontent.com/u/332036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oli-obk", "html_url": "https://github.com/oli-obk", "followers_url": "https://api.github.com/users/oli-obk/followers", "following_url": "https://api.github.com/users/oli-obk/following{/other_user}", "gists_url": "https://api.github.com/users/oli-obk/gists{/gist_id}", "starred_url": "https://api.github.com/users/oli-obk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oli-obk/subscriptions", "organizations_url": "https://api.github.com/users/oli-obk/orgs", "repos_url": "https://api.github.com/users/oli-obk/repos", "events_url": "https://api.github.com/users/oli-obk/events{/privacy}", "received_events_url": "https://api.github.com/users/oli-obk/received_events", "type": "User", "site_admin": false}, "committer": {"login": "oli-obk", "id": 332036, "node_id": "MDQ6VXNlcjMzMjAzNg==", "avatar_url": "https://avatars.githubusercontent.com/u/332036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oli-obk", "html_url": "https://github.com/oli-obk", "followers_url": "https://api.github.com/users/oli-obk/followers", "following_url": "https://api.github.com/users/oli-obk/following{/other_user}", "gists_url": "https://api.github.com/users/oli-obk/gists{/gist_id}", "starred_url": "https://api.github.com/users/oli-obk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oli-obk/subscriptions", "organizations_url": "https://api.github.com/users/oli-obk/orgs", "repos_url": "https://api.github.com/users/oli-obk/repos", "events_url": "https://api.github.com/users/oli-obk/events{/privacy}", "received_events_url": "https://api.github.com/users/oli-obk/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c6404f56e786255592d655d9af9742004037a75a", "url": "https://api.github.com/repos/rust-lang/rust/commits/c6404f56e786255592d655d9af9742004037a75a", "html_url": "https://github.com/rust-lang/rust/commit/c6404f56e786255592d655d9af9742004037a75a"}], "stats": {"total": 749, "additions": 9, "deletions": 740}, "files": [{"sha": "8444cf5726f84002435ed14585ddc4a02c51baee", "filename": "src/librustc/mir/interpret/allocation.rs", "status": "modified", "additions": 5, "deletions": 682, "changes": 687, "blob_url": "https://github.com/rust-lang/rust/blob/7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs?ref=7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091", "patch": "@@ -8,520 +8,15 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! An interpreter for MIR used in CTFE and by miri\n+//! The virtual memory representation of the MIR interpreter\n \n-#[macro_export]\n-macro_rules! err {\n-    ($($tt:tt)*) => { Err($crate::mir::interpret::EvalErrorKind::$($tt)*.into()) };\n-}\n-\n-mod error;\n-mod value;\n-\n-pub use self::error::{\n-    EvalError, EvalResult, EvalErrorKind, AssertMessage, ConstEvalErr, struct_error,\n-    FrameInfo, ConstEvalResult,\n+use super::{\n+    UndefMask,\n+    Relocations,\n };\n \n-pub use self::value::{Scalar, ConstValue};\n-\n-use std::fmt;\n-use mir;\n-use hir::def_id::DefId;\n-use ty::{self, TyCtxt, Instance};\n-use ty::layout::{self, Align, HasDataLayout, Size};\n-use middle::region;\n-use std::iter;\n-use std::io;\n-use std::ops::{Deref, DerefMut};\n-use std::hash::Hash;\n+use ty::layout::{Size, Align};\n use syntax::ast::Mutability;\n-use rustc_serialize::{Encoder, Decodable, Encodable};\n-use rustc_data_structures::sorted_map::SortedMap;\n-use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::sync::{Lock as Mutex, HashMapExt};\n-use rustc_data_structures::tiny_list::TinyList;\n-use byteorder::{WriteBytesExt, ReadBytesExt, LittleEndian, BigEndian};\n-use ty::codec::TyDecoder;\n-use std::sync::atomic::{AtomicU32, Ordering};\n-use std::num::NonZeroU32;\n-\n-#[derive(Clone, Debug, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable)]\n-pub enum Lock {\n-    NoLock,\n-    WriteLock(DynamicLifetime),\n-    /// This should never be empty -- that would be a read lock held and nobody\n-    /// there to release it...\n-    ReadLock(Vec<DynamicLifetime>),\n-}\n-\n-#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable)]\n-pub struct DynamicLifetime {\n-    pub frame: usize,\n-    pub region: Option<region::Scope>, // \"None\" indicates \"until the function ends\"\n-}\n-\n-#[derive(Copy, Clone, Debug, PartialEq, Eq, RustcEncodable, RustcDecodable)]\n-pub enum AccessKind {\n-    Read,\n-    Write,\n-}\n-\n-/// Uniquely identifies a specific constant or static.\n-#[derive(Copy, Clone, Debug, Eq, PartialEq, Hash, RustcEncodable, RustcDecodable)]\n-pub struct GlobalId<'tcx> {\n-    /// For a constant or static, the `Instance` of the item itself.\n-    /// For a promoted global, the `Instance` of the function they belong to.\n-    pub instance: ty::Instance<'tcx>,\n-\n-    /// The index for promoted globals within their function's `Mir`.\n-    pub promoted: Option<mir::Promoted>,\n-}\n-\n-////////////////////////////////////////////////////////////////////////////////\n-// Pointer arithmetic\n-////////////////////////////////////////////////////////////////////////////////\n-\n-pub trait PointerArithmetic: layout::HasDataLayout {\n-    // These are not supposed to be overridden.\n-\n-    #[inline(always)]\n-    fn pointer_size(self) -> Size {\n-        self.data_layout().pointer_size\n-    }\n-\n-    //// Trunace the given value to the pointer size; also return whether there was an overflow\n-    fn truncate_to_ptr(self, val: u128) -> (u64, bool) {\n-        let max_ptr_plus_1 = 1u128 << self.pointer_size().bits();\n-        ((val % max_ptr_plus_1) as u64, val >= max_ptr_plus_1)\n-    }\n-\n-    // Overflow checking only works properly on the range from -u64 to +u64.\n-    fn overflowing_signed_offset(self, val: u64, i: i128) -> (u64, bool) {\n-        // FIXME: is it possible to over/underflow here?\n-        if i < 0 {\n-            // trickery to ensure that i64::min_value() works fine\n-            // this formula only works for true negative values, it panics for zero!\n-            let n = u64::max_value() - (i as u64) + 1;\n-            val.overflowing_sub(n)\n-        } else {\n-            self.overflowing_offset(val, i as u64)\n-        }\n-    }\n-\n-    fn overflowing_offset(self, val: u64, i: u64) -> (u64, bool) {\n-        let (res, over1) = val.overflowing_add(i);\n-        let (res, over2) = self.truncate_to_ptr(res as u128);\n-        (res, over1 || over2)\n-    }\n-\n-    fn signed_offset<'tcx>(self, val: u64, i: i64) -> EvalResult<'tcx, u64> {\n-        let (res, over) = self.overflowing_signed_offset(val, i as i128);\n-        if over { err!(Overflow(mir::BinOp::Add)) } else { Ok(res) }\n-    }\n-\n-    fn offset<'tcx>(self, val: u64, i: u64) -> EvalResult<'tcx, u64> {\n-        let (res, over) = self.overflowing_offset(val, i);\n-        if over { err!(Overflow(mir::BinOp::Add)) } else { Ok(res) }\n-    }\n-\n-    fn wrapping_signed_offset(self, val: u64, i: i64) -> u64 {\n-        self.overflowing_signed_offset(val, i as i128).0\n-    }\n-}\n-\n-impl<T: layout::HasDataLayout> PointerArithmetic for T {}\n-\n-\n-/// Pointer is generic over the type that represents a reference to Allocations,\n-/// thus making it possible for the most convenient representation to be used in\n-/// each context.\n-///\n-/// Defaults to the index based and loosely coupled AllocId.\n-///\n-/// Pointer is also generic over the `Tag` associated with each pointer,\n-/// which is used to do provenance tracking during execution.\n-#[derive(Copy, Clone, Debug, Eq, PartialEq, Ord, PartialOrd, RustcEncodable, RustcDecodable, Hash)]\n-pub struct Pointer<Tag=(),Id=AllocId> {\n-    pub alloc_id: Id,\n-    pub offset: Size,\n-    pub tag: Tag,\n-}\n-\n-/// Produces a `Pointer` which points to the beginning of the Allocation\n-impl From<AllocId> for Pointer {\n-    #[inline(always)]\n-    fn from(alloc_id: AllocId) -> Self {\n-        Pointer::new(alloc_id, Size::ZERO)\n-    }\n-}\n-\n-impl<'tcx> Pointer<()> {\n-    #[inline(always)]\n-    pub fn new(alloc_id: AllocId, offset: Size) -> Self {\n-        Pointer { alloc_id, offset, tag: () }\n-    }\n-\n-    #[inline(always)]\n-    pub fn with_default_tag<Tag>(self) -> Pointer<Tag>\n-        where Tag: Default\n-    {\n-        Pointer::new_with_tag(self.alloc_id, self.offset, Default::default())\n-    }\n-}\n-\n-impl<'tcx, Tag> Pointer<Tag> {\n-    #[inline(always)]\n-    pub fn new_with_tag(alloc_id: AllocId, offset: Size, tag: Tag) -> Self {\n-        Pointer { alloc_id, offset, tag }\n-    }\n-\n-    pub fn wrapping_signed_offset<C: HasDataLayout>(self, i: i64, cx: C) -> Self {\n-        Pointer::new_with_tag(\n-            self.alloc_id,\n-            Size::from_bytes(cx.data_layout().wrapping_signed_offset(self.offset.bytes(), i)),\n-            self.tag,\n-        )\n-    }\n-\n-    pub fn overflowing_signed_offset<C: HasDataLayout>(self, i: i128, cx: C) -> (Self, bool) {\n-        let (res, over) = cx.data_layout().overflowing_signed_offset(self.offset.bytes(), i);\n-        (Pointer::new_with_tag(self.alloc_id, Size::from_bytes(res), self.tag), over)\n-    }\n-\n-    pub fn signed_offset<C: HasDataLayout>(self, i: i64, cx: C) -> EvalResult<'tcx, Self> {\n-        Ok(Pointer::new_with_tag(\n-            self.alloc_id,\n-            Size::from_bytes(cx.data_layout().signed_offset(self.offset.bytes(), i)?),\n-            self.tag,\n-        ))\n-    }\n-\n-    pub fn overflowing_offset<C: HasDataLayout>(self, i: Size, cx: C) -> (Self, bool) {\n-        let (res, over) = cx.data_layout().overflowing_offset(self.offset.bytes(), i.bytes());\n-        (Pointer::new_with_tag(self.alloc_id, Size::from_bytes(res), self.tag), over)\n-    }\n-\n-    pub fn offset<C: HasDataLayout>(self, i: Size, cx: C) -> EvalResult<'tcx, Self> {\n-        Ok(Pointer::new_with_tag(\n-            self.alloc_id,\n-            Size::from_bytes(cx.data_layout().offset(self.offset.bytes(), i.bytes())?),\n-            self.tag\n-        ))\n-    }\n-\n-    #[inline]\n-    pub fn erase_tag(self) -> Pointer {\n-        Pointer { alloc_id: self.alloc_id, offset: self.offset, tag: () }\n-    }\n-}\n-\n-\n-#[derive(Copy, Clone, Eq, Hash, Ord, PartialEq, PartialOrd, Debug)]\n-pub struct AllocId(pub u64);\n-\n-impl ::rustc_serialize::UseSpecializedEncodable for AllocId {}\n-impl ::rustc_serialize::UseSpecializedDecodable for AllocId {}\n-\n-#[derive(RustcDecodable, RustcEncodable)]\n-enum AllocKind {\n-    Alloc,\n-    Fn,\n-    Static,\n-}\n-\n-pub fn specialized_encode_alloc_id<\n-    'a, 'tcx,\n-    E: Encoder,\n->(\n-    encoder: &mut E,\n-    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-    alloc_id: AllocId,\n-) -> Result<(), E::Error> {\n-    let alloc_type: AllocType<'tcx, &'tcx Allocation> =\n-        tcx.alloc_map.lock().get(alloc_id).expect(\"no value for AllocId\");\n-    match alloc_type {\n-        AllocType::Memory(alloc) => {\n-            trace!(\"encoding {:?} with {:#?}\", alloc_id, alloc);\n-            AllocKind::Alloc.encode(encoder)?;\n-            alloc.encode(encoder)?;\n-        }\n-        AllocType::Function(fn_instance) => {\n-            trace!(\"encoding {:?} with {:#?}\", alloc_id, fn_instance);\n-            AllocKind::Fn.encode(encoder)?;\n-            fn_instance.encode(encoder)?;\n-        }\n-        AllocType::Static(did) => {\n-            // referring to statics doesn't need to know about their allocations,\n-            // just about its DefId\n-            AllocKind::Static.encode(encoder)?;\n-            did.encode(encoder)?;\n-        }\n-    }\n-    Ok(())\n-}\n-\n-// Used to avoid infinite recursion when decoding cyclic allocations.\n-type DecodingSessionId = NonZeroU32;\n-\n-#[derive(Clone)]\n-enum State {\n-    Empty,\n-    InProgressNonAlloc(TinyList<DecodingSessionId>),\n-    InProgress(TinyList<DecodingSessionId>, AllocId),\n-    Done(AllocId),\n-}\n-\n-pub struct AllocDecodingState {\n-    // For each AllocId we keep track of which decoding state it's currently in.\n-    decoding_state: Vec<Mutex<State>>,\n-    // The offsets of each allocation in the data stream.\n-    data_offsets: Vec<u32>,\n-}\n-\n-impl AllocDecodingState {\n-\n-    pub fn new_decoding_session(&self) -> AllocDecodingSession<'_> {\n-        static DECODER_SESSION_ID: AtomicU32 = AtomicU32::new(0);\n-        let counter = DECODER_SESSION_ID.fetch_add(1, Ordering::SeqCst);\n-\n-        // Make sure this is never zero\n-        let session_id = DecodingSessionId::new((counter & 0x7FFFFFFF) + 1).unwrap();\n-\n-        AllocDecodingSession {\n-            state: self,\n-            session_id,\n-        }\n-    }\n-\n-    pub fn new(data_offsets: Vec<u32>) -> AllocDecodingState {\n-        let decoding_state: Vec<_> = ::std::iter::repeat(Mutex::new(State::Empty))\n-            .take(data_offsets.len())\n-            .collect();\n-\n-        AllocDecodingState {\n-            decoding_state: decoding_state,\n-            data_offsets,\n-        }\n-    }\n-}\n-\n-#[derive(Copy, Clone)]\n-pub struct AllocDecodingSession<'s> {\n-    state: &'s AllocDecodingState,\n-    session_id: DecodingSessionId,\n-}\n-\n-impl<'s> AllocDecodingSession<'s> {\n-\n-    // Decodes an AllocId in a thread-safe way.\n-    pub fn decode_alloc_id<'a, 'tcx, D>(&self,\n-                                        decoder: &mut D)\n-                                        -> Result<AllocId, D::Error>\n-        where D: TyDecoder<'a, 'tcx>,\n-              'tcx: 'a,\n-    {\n-        // Read the index of the allocation\n-        let idx = decoder.read_u32()? as usize;\n-        let pos = self.state.data_offsets[idx] as usize;\n-\n-        // Decode the AllocKind now so that we know if we have to reserve an\n-        // AllocId.\n-        let (alloc_kind, pos) = decoder.with_position(pos, |decoder| {\n-            let alloc_kind = AllocKind::decode(decoder)?;\n-            Ok((alloc_kind, decoder.position()))\n-        })?;\n-\n-        // Check the decoding state, see if it's already decoded or if we should\n-        // decode it here.\n-        let alloc_id = {\n-            let mut entry = self.state.decoding_state[idx].lock();\n-\n-            match *entry {\n-                State::Done(alloc_id) => {\n-                    return Ok(alloc_id);\n-                }\n-                ref mut entry @ State::Empty => {\n-                    // We are allowed to decode\n-                    match alloc_kind {\n-                        AllocKind::Alloc => {\n-                            // If this is an allocation, we need to reserve an\n-                            // AllocId so we can decode cyclic graphs.\n-                            let alloc_id = decoder.tcx().alloc_map.lock().reserve();\n-                            *entry = State::InProgress(\n-                                TinyList::new_single(self.session_id),\n-                                alloc_id);\n-                            Some(alloc_id)\n-                        },\n-                        AllocKind::Fn | AllocKind::Static => {\n-                            // Fns and statics cannot be cyclic and their AllocId\n-                            // is determined later by interning\n-                            *entry = State::InProgressNonAlloc(\n-                                TinyList::new_single(self.session_id));\n-                            None\n-                        }\n-                    }\n-                }\n-                State::InProgressNonAlloc(ref mut sessions) => {\n-                    if sessions.contains(&self.session_id) {\n-                        bug!(\"This should be unreachable\")\n-                    } else {\n-                        // Start decoding concurrently\n-                        sessions.insert(self.session_id);\n-                        None\n-                    }\n-                }\n-                State::InProgress(ref mut sessions, alloc_id) => {\n-                    if sessions.contains(&self.session_id) {\n-                        // Don't recurse.\n-                        return Ok(alloc_id)\n-                    } else {\n-                        // Start decoding concurrently\n-                        sessions.insert(self.session_id);\n-                        Some(alloc_id)\n-                    }\n-                }\n-            }\n-        };\n-\n-        // Now decode the actual data\n-        let alloc_id = decoder.with_position(pos, |decoder| {\n-            match alloc_kind {\n-                AllocKind::Alloc => {\n-                    let allocation = <&'tcx Allocation as Decodable>::decode(decoder)?;\n-                    // We already have a reserved AllocId.\n-                    let alloc_id = alloc_id.unwrap();\n-                    trace!(\"decoded alloc {:?} {:#?}\", alloc_id, allocation);\n-                    decoder.tcx().alloc_map.lock().set_id_same_memory(alloc_id, allocation);\n-                    Ok(alloc_id)\n-                },\n-                AllocKind::Fn => {\n-                    assert!(alloc_id.is_none());\n-                    trace!(\"creating fn alloc id\");\n-                    let instance = ty::Instance::decode(decoder)?;\n-                    trace!(\"decoded fn alloc instance: {:?}\", instance);\n-                    let alloc_id = decoder.tcx().alloc_map.lock().create_fn_alloc(instance);\n-                    Ok(alloc_id)\n-                },\n-                AllocKind::Static => {\n-                    assert!(alloc_id.is_none());\n-                    trace!(\"creating extern static alloc id at\");\n-                    let did = DefId::decode(decoder)?;\n-                    let alloc_id = decoder.tcx().alloc_map.lock().intern_static(did);\n-                    Ok(alloc_id)\n-                }\n-            }\n-        })?;\n-\n-        self.state.decoding_state[idx].with_lock(|entry| {\n-            *entry = State::Done(alloc_id);\n-        });\n-\n-        Ok(alloc_id)\n-    }\n-}\n-\n-impl fmt::Display for AllocId {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        write!(f, \"{}\", self.0)\n-    }\n-}\n-\n-#[derive(Debug, Clone, Eq, PartialEq, Hash, RustcDecodable, RustcEncodable)]\n-pub enum AllocType<'tcx, M> {\n-    /// The alloc id is used as a function pointer\n-    Function(Instance<'tcx>),\n-    /// The alloc id points to a \"lazy\" static variable that did not get computed (yet).\n-    /// This is also used to break the cycle in recursive statics.\n-    Static(DefId),\n-    /// The alloc id points to memory\n-    Memory(M)\n-}\n-\n-pub struct AllocMap<'tcx, M> {\n-    /// Lets you know what an AllocId refers to\n-    id_to_type: FxHashMap<AllocId, AllocType<'tcx, M>>,\n-\n-    /// Used to ensure that functions and statics only get one associated AllocId\n-    type_interner: FxHashMap<AllocType<'tcx, M>, AllocId>,\n-\n-    /// The AllocId to assign to the next requested id.\n-    /// Always incremented, never gets smaller.\n-    next_id: AllocId,\n-}\n-\n-impl<'tcx, M: fmt::Debug + Eq + Hash + Clone> AllocMap<'tcx, M> {\n-    pub fn new() -> Self {\n-        AllocMap {\n-            id_to_type: Default::default(),\n-            type_interner: Default::default(),\n-            next_id: AllocId(0),\n-        }\n-    }\n-\n-    /// obtains a new allocation ID that can be referenced but does not\n-    /// yet have an allocation backing it.\n-    pub fn reserve(\n-        &mut self,\n-    ) -> AllocId {\n-        let next = self.next_id;\n-        self.next_id.0 = self.next_id.0\n-            .checked_add(1)\n-            .expect(\"You overflowed a u64 by incrementing by 1... \\\n-                     You've just earned yourself a free drink if we ever meet. \\\n-                     Seriously, how did you do that?!\");\n-        next\n-    }\n-\n-    fn intern(&mut self, alloc_type: AllocType<'tcx, M>) -> AllocId {\n-        if let Some(&alloc_id) = self.type_interner.get(&alloc_type) {\n-            return alloc_id;\n-        }\n-        let id = self.reserve();\n-        debug!(\"creating alloc_type {:?} with id {}\", alloc_type, id);\n-        self.id_to_type.insert(id, alloc_type.clone());\n-        self.type_interner.insert(alloc_type, id);\n-        id\n-    }\n-\n-    // FIXME: Check if functions have identity. If not, we should not intern these,\n-    // but instead create a new id per use.\n-    // Alternatively we could just make comparing function pointers an error.\n-    pub fn create_fn_alloc(&mut self, instance: Instance<'tcx>) -> AllocId {\n-        self.intern(AllocType::Function(instance))\n-    }\n-\n-    pub fn get(&self, id: AllocId) -> Option<AllocType<'tcx, M>> {\n-        self.id_to_type.get(&id).cloned()\n-    }\n-\n-    pub fn unwrap_memory(&self, id: AllocId) -> M {\n-        match self.get(id) {\n-            Some(AllocType::Memory(mem)) => mem,\n-            _ => bug!(\"expected allocation id {} to point to memory\", id),\n-        }\n-    }\n-\n-    pub fn intern_static(&mut self, static_id: DefId) -> AllocId {\n-        self.intern(AllocType::Static(static_id))\n-    }\n-\n-    pub fn allocate(&mut self, mem: M) -> AllocId {\n-        let id = self.reserve();\n-        self.set_id_memory(id, mem);\n-        id\n-    }\n-\n-    pub fn set_id_memory(&mut self, id: AllocId, mem: M) {\n-        if let Some(old) = self.id_to_type.insert(id, AllocType::Memory(mem)) {\n-            bug!(\"tried to set allocation id {}, but it was already existing as {:#?}\", id, old);\n-        }\n-    }\n-\n-    pub fn set_id_same_memory(&mut self, id: AllocId, mem: M) {\n-       self.id_to_type.insert_same(id, AllocType::Memory(mem));\n-    }\n-}\n \n #[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n pub struct Allocation<Tag=(),Extra=()> {\n@@ -578,175 +73,3 @@ impl<Tag, Extra: Default> Allocation<Tag, Extra> {\n }\n \n impl<'tcx> ::serialize::UseSpecializedDecodable for &'tcx Allocation {}\n-\n-#[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, RustcEncodable, RustcDecodable)]\n-pub struct Relocations<Tag=(), Id=AllocId>(SortedMap<Size, (Tag, Id)>);\n-\n-impl<Tag, Id> Relocations<Tag, Id> {\n-    pub fn new() -> Self {\n-        Relocations(SortedMap::new())\n-    }\n-\n-    // The caller must guarantee that the given relocations are already sorted\n-    // by address and contain no duplicates.\n-    pub fn from_presorted(r: Vec<(Size, (Tag, Id))>) -> Self {\n-        Relocations(SortedMap::from_presorted_elements(r))\n-    }\n-}\n-\n-impl<Tag> Deref for Relocations<Tag> {\n-    type Target = SortedMap<Size, (Tag, AllocId)>;\n-\n-    fn deref(&self) -> &Self::Target {\n-        &self.0\n-    }\n-}\n-\n-impl<Tag> DerefMut for Relocations<Tag> {\n-    fn deref_mut(&mut self) -> &mut Self::Target {\n-        &mut self.0\n-    }\n-}\n-\n-////////////////////////////////////////////////////////////////////////////////\n-// Methods to access integers in the target endianness\n-////////////////////////////////////////////////////////////////////////////////\n-\n-pub fn write_target_uint(\n-    endianness: layout::Endian,\n-    mut target: &mut [u8],\n-    data: u128,\n-) -> Result<(), io::Error> {\n-    let len = target.len();\n-    match endianness {\n-        layout::Endian::Little => target.write_uint128::<LittleEndian>(data, len),\n-        layout::Endian::Big => target.write_uint128::<BigEndian>(data, len),\n-    }\n-}\n-\n-pub fn read_target_uint(endianness: layout::Endian, mut source: &[u8]) -> Result<u128, io::Error> {\n-    match endianness {\n-        layout::Endian::Little => source.read_uint128::<LittleEndian>(source.len()),\n-        layout::Endian::Big => source.read_uint128::<BigEndian>(source.len()),\n-    }\n-}\n-\n-////////////////////////////////////////////////////////////////////////////////\n-// Methods to faciliate working with signed integers stored in a u128\n-////////////////////////////////////////////////////////////////////////////////\n-\n-pub fn sign_extend(value: u128, size: Size) -> u128 {\n-    let size = size.bits();\n-    // sign extend\n-    let shift = 128 - size;\n-    // shift the unsigned value to the left\n-    // and back to the right as signed (essentially fills with FF on the left)\n-    (((value << shift) as i128) >> shift) as u128\n-}\n-\n-pub fn truncate(value: u128, size: Size) -> u128 {\n-    let size = size.bits();\n-    let shift = 128 - size;\n-    // truncate (shift left to drop out leftover values, shift right to fill with zeroes)\n-    (value << shift) >> shift\n-}\n-\n-////////////////////////////////////////////////////////////////////////////////\n-// Undefined byte tracking\n-////////////////////////////////////////////////////////////////////////////////\n-\n-type Block = u64;\n-const BLOCK_SIZE: u64 = 64;\n-\n-#[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n-pub struct UndefMask {\n-    blocks: Vec<Block>,\n-    len: Size,\n-}\n-\n-impl_stable_hash_for!(struct mir::interpret::UndefMask{blocks, len});\n-\n-impl UndefMask {\n-    pub fn new(size: Size) -> Self {\n-        let mut m = UndefMask {\n-            blocks: vec![],\n-            len: Size::ZERO,\n-        };\n-        m.grow(size, false);\n-        m\n-    }\n-\n-    /// Check whether the range `start..end` (end-exclusive) is entirely defined.\n-    ///\n-    /// Returns `Ok(())` if it's defined. Otherwise returns the index of the byte\n-    /// at which the first undefined access begins.\n-    #[inline]\n-    pub fn is_range_defined(&self, start: Size, end: Size) -> Result<(), Size> {\n-        if end > self.len {\n-            return Err(self.len);\n-        }\n-\n-        let idx = (start.bytes()..end.bytes())\n-            .map(|i| Size::from_bytes(i))\n-            .find(|&i| !self.get(i));\n-\n-        match idx {\n-            Some(idx) => Err(idx),\n-            None => Ok(())\n-        }\n-    }\n-\n-    pub fn set_range(&mut self, start: Size, end: Size, new_state: bool) {\n-        let len = self.len;\n-        if end > len {\n-            self.grow(end - len, new_state);\n-        }\n-        self.set_range_inbounds(start, end, new_state);\n-    }\n-\n-    pub fn set_range_inbounds(&mut self, start: Size, end: Size, new_state: bool) {\n-        for i in start.bytes()..end.bytes() {\n-            self.set(Size::from_bytes(i), new_state);\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn get(&self, i: Size) -> bool {\n-        let (block, bit) = bit_index(i);\n-        (self.blocks[block] & 1 << bit) != 0\n-    }\n-\n-    #[inline]\n-    pub fn set(&mut self, i: Size, new_state: bool) {\n-        let (block, bit) = bit_index(i);\n-        if new_state {\n-            self.blocks[block] |= 1 << bit;\n-        } else {\n-            self.blocks[block] &= !(1 << bit);\n-        }\n-    }\n-\n-    pub fn grow(&mut self, amount: Size, new_state: bool) {\n-        let unused_trailing_bits = self.blocks.len() as u64 * BLOCK_SIZE - self.len.bytes();\n-        if amount.bytes() > unused_trailing_bits {\n-            let additional_blocks = amount.bytes() / BLOCK_SIZE + 1;\n-            assert_eq!(additional_blocks as usize as u64, additional_blocks);\n-            self.blocks.extend(\n-                iter::repeat(0).take(additional_blocks as usize),\n-            );\n-        }\n-        let start = self.len;\n-        self.len += amount;\n-        self.set_range_inbounds(start, start + amount, new_state);\n-    }\n-}\n-\n-#[inline]\n-fn bit_index(bits: Size) -> (usize, usize) {\n-    let bits = bits.bytes();\n-    let a = bits / BLOCK_SIZE;\n-    let b = bits % BLOCK_SIZE;\n-    assert_eq!(a as usize as u64, a);\n-    assert_eq!(b as usize as u64, b);\n-    (a as usize, b as usize)\n-}"}, {"sha": "238ffad0ae24ca55aad78cb8ab9b776de4a6bb73", "filename": "src/librustc/mir/interpret/mod.rs", "status": "modified", "additions": 4, "deletions": 58, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs?ref=7db04835f9ab3ab3d4b6f8a91547a2c7a4f66091", "patch": "@@ -17,6 +17,7 @@ macro_rules! err {\n \n mod error;\n mod value;\n+mod allocation;\n \n pub use self::error::{\n     EvalError, EvalResult, EvalErrorKind, AssertMessage, ConstEvalErr, struct_error,\n@@ -25,17 +26,18 @@ pub use self::error::{\n \n pub use self::value::{Scalar, ConstValue};\n \n+pub use self::allocation::Allocation;\n+\n use std::fmt;\n use mir;\n use hir::def_id::DefId;\n use ty::{self, TyCtxt, Instance};\n-use ty::layout::{self, Align, HasDataLayout, Size};\n+use ty::layout::{self, HasDataLayout, Size};\n use middle::region;\n use std::iter;\n use std::io;\n use std::ops::{Deref, DerefMut};\n use std::hash::Hash;\n-use syntax::ast::Mutability;\n use rustc_serialize::{Encoder, Decodable, Encodable};\n use rustc_data_structures::sorted_map::SortedMap;\n use rustc_data_structures::fx::FxHashMap;\n@@ -528,62 +530,6 @@ impl<'tcx, M: fmt::Debug + Eq + Hash + Clone> AllocMap<'tcx, M> {\n     }\n }\n \n-#[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n-pub struct Allocation<Tag=(),Extra=()> {\n-    /// The actual bytes of the allocation.\n-    /// Note that the bytes of a pointer represent the offset of the pointer\n-    pub bytes: Vec<u8>,\n-    /// Maps from byte addresses to extra data for each pointer.\n-    /// Only the first byte of a pointer is inserted into the map; i.e.,\n-    /// every entry in this map applies to `pointer_size` consecutive bytes starting\n-    /// at the given offset.\n-    pub relocations: Relocations<Tag>,\n-    /// Denotes undefined memory. Reading from undefined memory is forbidden in miri\n-    pub undef_mask: UndefMask,\n-    /// The alignment of the allocation to detect unaligned reads.\n-    pub align: Align,\n-    /// Whether the allocation is mutable.\n-    /// Also used by codegen to determine if a static should be put into mutable memory,\n-    /// which happens for `static mut` and `static` with interior mutability.\n-    pub mutability: Mutability,\n-    /// Extra state for the machine.\n-    pub extra: Extra,\n-}\n-\n-impl<Tag, Extra: Default> Allocation<Tag, Extra> {\n-    /// Creates a read-only allocation initialized by the given bytes\n-    pub fn from_bytes(slice: &[u8], align: Align) -> Self {\n-        let mut undef_mask = UndefMask::new(Size::ZERO);\n-        undef_mask.grow(Size::from_bytes(slice.len() as u64), true);\n-        Self {\n-            bytes: slice.to_owned(),\n-            relocations: Relocations::new(),\n-            undef_mask,\n-            align,\n-            mutability: Mutability::Immutable,\n-            extra: Extra::default(),\n-        }\n-    }\n-\n-    pub fn from_byte_aligned_bytes(slice: &[u8]) -> Self {\n-        Allocation::from_bytes(slice, Align::from_bytes(1, 1).unwrap())\n-    }\n-\n-    pub fn undef(size: Size, align: Align) -> Self {\n-        assert_eq!(size.bytes() as usize as u64, size.bytes());\n-        Allocation {\n-            bytes: vec![0; size.bytes() as usize],\n-            relocations: Relocations::new(),\n-            undef_mask: UndefMask::new(size),\n-            align,\n-            mutability: Mutability::Mutable,\n-            extra: Extra::default(),\n-        }\n-    }\n-}\n-\n-impl<'tcx> ::serialize::UseSpecializedDecodable for &'tcx Allocation {}\n-\n #[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, RustcEncodable, RustcDecodable)]\n pub struct Relocations<Tag=(), Id=AllocId>(SortedMap<Size, (Tag, Id)>);\n "}]}