{"sha": "f955c8ef2a703de41c347b86b4f828c76f76dede", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY5NTVjOGVmMmE3MDNkZTQxYzM0N2I4NmI0ZjgyOGM3NmY3NmRlZGU=", "commit": {"author": {"name": "bjorn3", "email": "bjorn3@users.noreply.github.com", "date": "2018-11-11T10:36:11Z"}, "committer": {"name": "bjorn3", "email": "bjorn3@users.noreply.github.com", "date": "2018-11-11T10:40:41Z"}, "message": "Move all functions in link.rs copied from cg_llvm to link_copied.rs", "tree": {"sha": "227b95de22af14029dc7b7df7610f9464bd69482", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/227b95de22af14029dc7b7df7610f9464bd69482"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f955c8ef2a703de41c347b86b4f828c76f76dede", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f955c8ef2a703de41c347b86b4f828c76f76dede", "html_url": "https://github.com/rust-lang/rust/commit/f955c8ef2a703de41c347b86b4f828c76f76dede", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f955c8ef2a703de41c347b86b4f828c76f76dede/comments", "author": {"login": "bjorn3", "id": 17426603, "node_id": "MDQ6VXNlcjE3NDI2NjAz", "avatar_url": "https://avatars.githubusercontent.com/u/17426603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjorn3", "html_url": "https://github.com/bjorn3", "followers_url": "https://api.github.com/users/bjorn3/followers", "following_url": "https://api.github.com/users/bjorn3/following{/other_user}", "gists_url": "https://api.github.com/users/bjorn3/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjorn3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjorn3/subscriptions", "organizations_url": "https://api.github.com/users/bjorn3/orgs", "repos_url": "https://api.github.com/users/bjorn3/repos", "events_url": "https://api.github.com/users/bjorn3/events{/privacy}", "received_events_url": "https://api.github.com/users/bjorn3/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bjorn3", "id": 17426603, "node_id": "MDQ6VXNlcjE3NDI2NjAz", "avatar_url": "https://avatars.githubusercontent.com/u/17426603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjorn3", "html_url": "https://github.com/bjorn3", "followers_url": "https://api.github.com/users/bjorn3/followers", "following_url": "https://api.github.com/users/bjorn3/following{/other_user}", "gists_url": "https://api.github.com/users/bjorn3/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjorn3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjorn3/subscriptions", "organizations_url": "https://api.github.com/users/bjorn3/orgs", "repos_url": "https://api.github.com/users/bjorn3/repos", "events_url": "https://api.github.com/users/bjorn3/events{/privacy}", "received_events_url": "https://api.github.com/users/bjorn3/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7ef83ec641cff0d2c50d6253588cc86e788254bc", "url": "https://api.github.com/repos/rust-lang/rust/commits/7ef83ec641cff0d2c50d6253588cc86e788254bc", "html_url": "https://github.com/rust-lang/rust/commit/7ef83ec641cff0d2c50d6253588cc86e788254bc"}], "stats": {"total": 1547, "additions": 782, "deletions": 765}, "files": [{"sha": "fdfa0d1d78707735f0853e892e29b387caaa5c28", "filename": "src/lib.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f955c8ef2a703de41c347b86b4f828c76f76dede/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f955c8ef2a703de41c347b86b4f828c76f76dede/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=f955c8ef2a703de41c347b86b4f828c76f76dede", "patch": "@@ -77,6 +77,7 @@ mod common;\n mod constant;\n mod intrinsics;\n mod link;\n+mod link_copied;\n mod main_shim;\n mod metadata;\n mod pretty_clif;\n@@ -404,7 +405,7 @@ impl CodegenBackend for CraneliftCodegenBackend {\n             std::fs::write(&tmp_file, obj).unwrap();\n \n             /*use rustc_mir::monomorphize::partitioning::CodegenUnitExt;\n-            \n+\n             let dep_node = tcx.codegen_unit(cgu_name).codegen_dep_node(tcx);\n             let ((stats, module), _) = tcx.dep_graph.with_task(\n                 dep_node,"}, {"sha": "1335b209f8c589dee270e62e665323ae9187255c", "filename": "src/link.rs", "status": "modified", "additions": 3, "deletions": 764, "changes": 767, "blob_url": "https://github.com/rust-lang/rust/blob/f955c8ef2a703de41c347b86b4f828c76f76dede/src%2Flink.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f955c8ef2a703de41c347b86b4f828c76f76dede/src%2Flink.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flink.rs?ref=f955c8ef2a703de41c347b86b4f828c76f76dede", "patch": "@@ -1,34 +1,21 @@\n use std::env;\n-use std::fmt;\n-use std::fs::{self, File};\n+use std::fs::File;\n use std::io;\n-use std::iter;\n use std::path::{Path, PathBuf};\n-use std::process::{Output, Stdio};\n \n-use cc::windows_registry;\n use tempfile::Builder as TempFileBuilder;\n \n-use rustc::middle::cstore::{NativeLibrary, NativeLibraryKind};\n-use rustc::middle::dependency_format::Linkage;\n-use rustc::session::config::{self, CrateType, DebugInfo, OutputType, RUST_CGU_EXT};\n+use rustc::session::config::{self, CrateType, DebugInfo, RUST_CGU_EXT};\n use rustc::session::search_paths::PathKind;\n use rustc::session::Session;\n-use rustc::util::common::time;\n use rustc_codegen_utils::command::Command;\n use rustc_codegen_utils::linker::*;\n-use rustc_data_structures::fx::FxHashSet;\n use rustc_fs_util::fix_windows_verbatim_for_gcc;\n use rustc_target::spec::{LinkerFlavor, PanicStrategy, RelroLevel};\n-use syntax::attr;\n \n use crate::prelude::*;\n \n-use crate::archive::{ArchiveBuilder, ArchiveConfig};\n-use crate::metadata::METADATA_FILENAME;\n-\n-// cg_clif doesn't have bytecode, so this is just a dummy\n-const RLIB_BYTECODE_EXTENSION: &str = \".cg_clif_bytecode_dummy\";\n+use crate::link_copied::*;\n \n pub(crate) fn link_rlib(sess: &Session, res: &CodegenResults, output_name: PathBuf) {\n     let file = File::create(&output_name).unwrap();\n@@ -441,751 +428,3 @@ fn link_args(cmd: &mut dyn Linker,\n     cmd.args(&sess.opts.cg.link_arg);\n     cmd.args(&used_link_args);\n }\n-\n-// ===========================\n-// Copied from https://github.com/rust-lang/rust/blob/942864a000efd74b73e36bda5606b2cdb55ecf39/src/librustc_codegen_llvm/back/link.rs\n-// ===========================\n-\n-fn archive_search_paths(sess: &Session) -> Vec<PathBuf> {\n-    let mut search = Vec::new();\n-    sess.target_filesearch(PathKind::Native).for_each_lib_search_path(|path, _| {\n-        search.push(path.to_path_buf());\n-    });\n-    return search;\n-}\n-\n-fn archive_config<'a>(sess: &'a Session,\n-                      output: &Path,\n-                      input: Option<&Path>) -> ArchiveConfig<'a> {\n-    ArchiveConfig {\n-        sess,\n-        dst: output.to_path_buf(),\n-        src: input.map(|p| p.to_path_buf()),\n-        lib_search_paths: archive_search_paths(sess),\n-    }\n-}\n-\n-// The third parameter is for env vars, used on windows to set up the\n-// path for MSVC to find its DLLs, and gcc to find its bundled\n-// toolchain\n-fn get_linker(sess: &Session, linker: &Path, flavor: LinkerFlavor) -> (PathBuf, Command) {\n-    let msvc_tool = windows_registry::find_tool(&sess.opts.target_triple.triple(), \"link.exe\");\n-\n-    // If our linker looks like a batch script on Windows then to execute this\n-    // we'll need to spawn `cmd` explicitly. This is primarily done to handle\n-    // emscripten where the linker is `emcc.bat` and needs to be spawned as\n-    // `cmd /c emcc.bat ...`.\n-    //\n-    // This worked historically but is needed manually since #42436 (regression\n-    // was tagged as #42791) and some more info can be found on #44443 for\n-    // emscripten itself.\n-    let mut cmd = match linker.to_str() {\n-        Some(linker) if cfg!(windows) && linker.ends_with(\".bat\") => Command::bat_script(linker),\n-        _ => match flavor {\n-            LinkerFlavor::Lld(f) => Command::lld(linker, f),\n-            LinkerFlavor::Msvc\n-                if sess.opts.cg.linker.is_none() && sess.target.target.options.linker.is_none() =>\n-            {\n-                Command::new(msvc_tool.as_ref().map(|t| t.path()).unwrap_or(linker))\n-            },\n-            _ => Command::new(linker),\n-        }\n-    };\n-\n-    // The compiler's sysroot often has some bundled tools, so add it to the\n-    // PATH for the child.\n-    let mut new_path = sess.host_filesearch(PathKind::All)\n-                           .get_tools_search_paths();\n-    let mut msvc_changed_path = false;\n-    if sess.target.target.options.is_like_msvc {\n-        if let Some(ref tool) = msvc_tool {\n-            cmd.args(tool.args());\n-            for &(ref k, ref v) in tool.env() {\n-                if k == \"PATH\" {\n-                    new_path.extend(env::split_paths(v));\n-                    msvc_changed_path = true;\n-                } else {\n-                    cmd.env(k, v);\n-                }\n-            }\n-        }\n-    }\n-\n-    if !msvc_changed_path {\n-        if let Some(path) = env::var_os(\"PATH\") {\n-            new_path.extend(env::split_paths(&path));\n-        }\n-    }\n-    cmd.env(\"PATH\", env::join_paths(new_path).unwrap());\n-\n-    (linker.to_path_buf(), cmd)\n-}\n-\n-fn linker_and_flavor(sess: &Session) -> (PathBuf, LinkerFlavor) {\n-    fn infer_from(\n-        sess: &Session,\n-        linker: Option<PathBuf>,\n-        flavor: Option<LinkerFlavor>,\n-    ) -> Option<(PathBuf, LinkerFlavor)> {\n-        match (linker, flavor) {\n-            (Some(linker), Some(flavor)) => Some((linker, flavor)),\n-            // only the linker flavor is known; use the default linker for the selected flavor\n-            (None, Some(flavor)) => Some((PathBuf::from(match flavor {\n-                LinkerFlavor::Em  => if cfg!(windows) { \"emcc.bat\" } else { \"emcc\" },\n-                LinkerFlavor::Gcc => \"cc\",\n-                LinkerFlavor::Ld => \"ld\",\n-                LinkerFlavor::Msvc => \"link.exe\",\n-                LinkerFlavor::Lld(_) => \"lld\",\n-            }), flavor)),\n-            (Some(linker), None) => {\n-                let stem = linker.file_stem().and_then(|stem| stem.to_str()).unwrap_or_else(|| {\n-                    sess.fatal(\"couldn't extract file stem from specified linker\");\n-                }).to_owned();\n-\n-                let flavor = if stem == \"emcc\" {\n-                    LinkerFlavor::Em\n-                } else if stem == \"gcc\" || stem.ends_with(\"-gcc\") {\n-                    LinkerFlavor::Gcc\n-                } else if stem == \"ld\" || stem == \"ld.lld\" || stem.ends_with(\"-ld\") {\n-                    LinkerFlavor::Ld\n-                } else if stem == \"link\" || stem == \"lld-link\" {\n-                    LinkerFlavor::Msvc\n-                } else if stem == \"lld\" || stem == \"rust-lld\" {\n-                    LinkerFlavor::Lld(sess.target.target.options.lld_flavor)\n-                } else {\n-                    // fall back to the value in the target spec\n-                    sess.target.target.linker_flavor\n-                };\n-\n-                Some((linker, flavor))\n-            },\n-            (None, None) => None,\n-        }\n-    }\n-\n-    // linker and linker flavor specified via command line have precedence over what the target\n-    // specification specifies\n-    if let Some(ret) = infer_from(\n-        sess,\n-        sess.opts.cg.linker.clone(),\n-        sess.opts.debugging_opts.linker_flavor,\n-    ) {\n-        return ret;\n-    }\n-\n-    if let Some(ret) = infer_from(\n-        sess,\n-        sess.target.target.options.linker.clone().map(PathBuf::from),\n-        Some(sess.target.target.linker_flavor),\n-    ) {\n-        return ret;\n-    }\n-\n-    bug!(\"Not enough information provided to determine how to invoke the linker\");\n-}\n-\n-fn exec_linker(sess: &Session, cmd: &mut Command, out_filename: &Path, tmpdir: &Path)\n-    -> io::Result<Output>\n-{\n-    // When attempting to spawn the linker we run a risk of blowing out the\n-    // size limits for spawning a new process with respect to the arguments\n-    // we pass on the command line.\n-    //\n-    // Here we attempt to handle errors from the OS saying \"your list of\n-    // arguments is too big\" by reinvoking the linker again with an `@`-file\n-    // that contains all the arguments. The theory is that this is then\n-    // accepted on all linkers and the linker will read all its options out of\n-    // there instead of looking at the command line.\n-    if !cmd.very_likely_to_exceed_some_spawn_limit() {\n-        match cmd.command().stdout(Stdio::piped()).stderr(Stdio::piped()).spawn() {\n-            Ok(child) => {\n-                let output = child.wait_with_output();\n-                flush_linked_file(&output, out_filename)?;\n-                return output;\n-            }\n-            Err(ref e) if command_line_too_big(e) => {\n-                info!(\"command line to linker was too big: {}\", e);\n-            }\n-            Err(e) => return Err(e)\n-        }\n-    }\n-\n-    info!(\"falling back to passing arguments to linker via an @-file\");\n-    let mut cmd2 = cmd.clone();\n-    let mut args = String::new();\n-    for arg in cmd2.take_args() {\n-        args.push_str(&Escape {\n-            arg: arg.to_str().unwrap(),\n-            is_like_msvc: sess.target.target.options.is_like_msvc,\n-        }.to_string());\n-        args.push_str(\"\\n\");\n-    }\n-    let file = tmpdir.join(\"linker-arguments\");\n-    let bytes = if sess.target.target.options.is_like_msvc {\n-        let mut out = Vec::with_capacity((1 + args.len()) * 2);\n-        // start the stream with a UTF-16 BOM\n-        for c in iter::once(0xFEFF).chain(args.encode_utf16()) {\n-            // encode in little endian\n-            out.push(c as u8);\n-            out.push((c >> 8) as u8);\n-        }\n-        out\n-    } else {\n-        args.into_bytes()\n-    };\n-    fs::write(&file, &bytes)?;\n-    cmd2.arg(format!(\"@{}\", file.display()));\n-    info!(\"invoking linker {:?}\", cmd2);\n-    let output = cmd2.output();\n-    flush_linked_file(&output, out_filename)?;\n-    return output;\n-\n-    #[cfg(unix)]\n-    fn flush_linked_file(_: &io::Result<Output>, _: &Path) -> io::Result<()> {\n-        Ok(())\n-    }\n-\n-    #[cfg(windows)]\n-    fn flush_linked_file(command_output: &io::Result<Output>, out_filename: &Path)\n-        -> io::Result<()>\n-    {\n-        // On Windows, under high I/O load, output buffers are sometimes not flushed,\n-        // even long after process exit, causing nasty, non-reproducible output bugs.\n-        //\n-        // File::sync_all() calls FlushFileBuffers() down the line, which solves the problem.\n-        //\n-        // \u0410 full writeup of the original Chrome bug can be found at\n-        // randomascii.wordpress.com/2018/02/25/compiler-bug-linker-bug-windows-kernel-bug/amp\n-\n-        if let &Ok(ref out) = command_output {\n-            if out.status.success() {\n-                if let Ok(of) = fs::OpenOptions::new().write(true).open(out_filename) {\n-                    of.sync_all()?;\n-                }\n-            }\n-        }\n-\n-        Ok(())\n-    }\n-\n-    #[cfg(unix)]\n-    fn command_line_too_big(err: &io::Error) -> bool {\n-        err.raw_os_error() == Some(::libc::E2BIG)\n-    }\n-\n-    #[cfg(windows)]\n-    fn command_line_too_big(err: &io::Error) -> bool {\n-        const ERROR_FILENAME_EXCED_RANGE: i32 = 206;\n-        err.raw_os_error() == Some(ERROR_FILENAME_EXCED_RANGE)\n-    }\n-\n-    struct Escape<'a> {\n-        arg: &'a str,\n-        is_like_msvc: bool,\n-    }\n-\n-    impl<'a> fmt::Display for Escape<'a> {\n-        fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-            if self.is_like_msvc {\n-                // This is \"documented\" at\n-                // https://msdn.microsoft.com/en-us/library/4xdcbak7.aspx\n-                //\n-                // Unfortunately there's not a great specification of the\n-                // syntax I could find online (at least) but some local\n-                // testing showed that this seemed sufficient-ish to catch\n-                // at least a few edge cases.\n-                write!(f, \"\\\"\")?;\n-                for c in self.arg.chars() {\n-                    match c {\n-                        '\"' => write!(f, \"\\\\{}\", c)?,\n-                        c => write!(f, \"{}\", c)?,\n-                    }\n-                }\n-                write!(f, \"\\\"\")?;\n-            } else {\n-                // This is documented at https://linux.die.net/man/1/ld, namely:\n-                //\n-                // > Options in file are separated by whitespace. A whitespace\n-                // > character may be included in an option by surrounding the\n-                // > entire option in either single or double quotes. Any\n-                // > character (including a backslash) may be included by\n-                // > prefixing the character to be included with a backslash.\n-                //\n-                // We put an argument on each line, so all we need to do is\n-                // ensure the line is interpreted as one whole argument.\n-                for c in self.arg.chars() {\n-                    match c {\n-                        '\\\\' |\n-                        ' ' => write!(f, \"\\\\{}\", c)?,\n-                        c => write!(f, \"{}\", c)?,\n-                    }\n-                }\n-            }\n-            Ok(())\n-        }\n-    }\n-}\n-\n-// # Rust Crate linking\n-//\n-// Rust crates are not considered at all when creating an rlib output. All\n-// dependencies will be linked when producing the final output (instead of\n-// the intermediate rlib version)\n-fn add_upstream_rust_crates(cmd: &mut dyn Linker,\n-                            sess: &Session,\n-                            codegen_results: &CodegenResults,\n-                            crate_type: config::CrateType,\n-                            tmpdir: &Path) {\n-    // All of the heavy lifting has previously been accomplished by the\n-    // dependency_format module of the compiler. This is just crawling the\n-    // output of that module, adding crates as necessary.\n-    //\n-    // Linking to a rlib involves just passing it to the linker (the linker\n-    // will slurp up the object files inside), and linking to a dynamic library\n-    // involves just passing the right -l flag.\n-\n-    let formats = sess.dependency_formats.borrow();\n-    let data = formats.get(&crate_type).unwrap();\n-\n-    // Invoke get_used_crates to ensure that we get a topological sorting of\n-    // crates.\n-    let deps = &codegen_results.crate_info.used_crates_dynamic;\n-\n-    // There's a few internal crates in the standard library (aka libcore and\n-    // libstd) which actually have a circular dependence upon one another. This\n-    // currently arises through \"weak lang items\" where libcore requires things\n-    // like `rust_begin_unwind` but libstd ends up defining it. To get this\n-    // circular dependence to work correctly in all situations we'll need to be\n-    // sure to correctly apply the `--start-group` and `--end-group` options to\n-    // GNU linkers, otherwise if we don't use any other symbol from the standard\n-    // library it'll get discarded and the whole application won't link.\n-    //\n-    // In this loop we're calculating the `group_end`, after which crate to\n-    // pass `--end-group` and `group_start`, before which crate to pass\n-    // `--start-group`. We currently do this by passing `--end-group` after\n-    // the first crate (when iterating backwards) that requires a lang item\n-    // defined somewhere else. Once that's set then when we've defined all the\n-    // necessary lang items we'll pass `--start-group`.\n-    //\n-    // Note that this isn't amazing logic for now but it should do the trick\n-    // for the current implementation of the standard library.\n-    let mut group_end = None;\n-    let mut group_start = None;\n-    let mut end_with = FxHashSet::default();\n-    let info = &codegen_results.crate_info;\n-    for &(cnum, _) in deps.iter().rev() {\n-        if let Some(missing) = info.missing_lang_items.get(&cnum) {\n-            end_with.extend(missing.iter().cloned());\n-            if end_with.len() > 0 && group_end.is_none() {\n-                group_end = Some(cnum);\n-            }\n-        }\n-        end_with.retain(|item| info.lang_item_to_crate.get(item) != Some(&cnum));\n-        if end_with.len() == 0 && group_end.is_some() {\n-            group_start = Some(cnum);\n-            break\n-        }\n-    }\n-\n-    // If we didn't end up filling in all lang items from upstream crates then\n-    // we'll be filling it in with our crate. This probably means we're the\n-    // standard library itself, so skip this for now.\n-    if group_end.is_some() && group_start.is_none() {\n-        group_end = None;\n-    }\n-\n-    let mut compiler_builtins = None;\n-\n-    for &(cnum, _) in deps.iter() {\n-        if group_start == Some(cnum) {\n-            cmd.group_start();\n-        }\n-\n-        // We may not pass all crates through to the linker. Some crates may\n-        // appear statically in an existing dylib, meaning we'll pick up all the\n-        // symbols from the dylib.\n-        let src = &codegen_results.crate_info.used_crate_source[&cnum];\n-        match data[cnum.as_usize() - 1] {\n-            _ if codegen_results.crate_info.profiler_runtime == Some(cnum) => {\n-                add_static_crate(cmd, sess, codegen_results, tmpdir, crate_type, cnum);\n-            }\n-            _ if codegen_results.crate_info.sanitizer_runtime == Some(cnum) => {\n-                link_sanitizer_runtime(cmd, sess, codegen_results, tmpdir, cnum);\n-            }\n-            // compiler-builtins are always placed last to ensure that they're\n-            // linked correctly.\n-            _ if codegen_results.crate_info.compiler_builtins == Some(cnum) => {\n-                assert!(compiler_builtins.is_none());\n-                compiler_builtins = Some(cnum);\n-            }\n-            Linkage::NotLinked |\n-            Linkage::IncludedFromDylib => {}\n-            Linkage::Static => {\n-                add_static_crate(cmd, sess, codegen_results, tmpdir, crate_type, cnum);\n-            }\n-            Linkage::Dynamic => {\n-                add_dynamic_crate(cmd, sess, &src.dylib.as_ref().unwrap().0)\n-            }\n-        }\n-\n-        if group_end == Some(cnum) {\n-            cmd.group_end();\n-        }\n-    }\n-\n-    // compiler-builtins are always placed last to ensure that they're\n-    // linked correctly.\n-    // We must always link the `compiler_builtins` crate statically. Even if it\n-    // was already \"included\" in a dylib (e.g. `libstd` when `-C prefer-dynamic`\n-    // is used)\n-    if let Some(cnum) = compiler_builtins {\n-        add_static_crate(cmd, sess, codegen_results, tmpdir, crate_type, cnum);\n-    }\n-\n-    // Converts a library file-stem into a cc -l argument\n-    fn unlib<'a>(config: &config::Config, stem: &'a str) -> &'a str {\n-        if stem.starts_with(\"lib\") && !config.target.options.is_like_windows {\n-            &stem[3..]\n-        } else {\n-            stem\n-        }\n-    }\n-\n-    // We must link the sanitizer runtime using -Wl,--whole-archive but since\n-    // it's packed in a .rlib, it contains stuff that are not objects that will\n-    // make the linker error. So we must remove those bits from the .rlib before\n-    // linking it.\n-    fn link_sanitizer_runtime(cmd: &mut dyn Linker,\n-                              sess: &Session,\n-                              codegen_results: &CodegenResults,\n-                              tmpdir: &Path,\n-                              cnum: CrateNum) {\n-        let src = &codegen_results.crate_info.used_crate_source[&cnum];\n-        let cratepath = &src.rlib.as_ref().unwrap().0;\n-\n-        if sess.target.target.options.is_like_osx {\n-            // On Apple platforms, the sanitizer is always built as a dylib, and\n-            // LLVM will link to `@rpath/*.dylib`, so we need to specify an\n-            // rpath to the library as well (the rpath should be absolute, see\n-            // PR #41352 for details).\n-            //\n-            // FIXME: Remove this logic into librustc_*san once Cargo supports it\n-            let rpath = cratepath.parent().unwrap();\n-            let rpath = rpath.to_str().expect(\"non-utf8 component in path\");\n-            cmd.args(&[\"-Wl,-rpath\".into(), \"-Xlinker\".into(), rpath.into()]);\n-        }\n-\n-        let dst = tmpdir.join(cratepath.file_name().unwrap());\n-        let cfg = archive_config(sess, &dst, Some(cratepath));\n-        let mut archive = ArchiveBuilder::new(cfg);\n-        archive.update_symbols();\n-\n-        for f in archive.src_files() {\n-            if f.ends_with(RLIB_BYTECODE_EXTENSION) || f == METADATA_FILENAME {\n-                archive.remove_file(&f);\n-                continue\n-            }\n-        }\n-\n-        archive.build();\n-\n-        cmd.link_whole_rlib(&dst);\n-    }\n-\n-    // Adds the static \"rlib\" versions of all crates to the command line.\n-    // There's a bit of magic which happens here specifically related to LTO and\n-    // dynamic libraries. Specifically:\n-    //\n-    // * For LTO, we remove upstream object files.\n-    // * For dylibs we remove metadata and bytecode from upstream rlibs\n-    //\n-    // When performing LTO, almost(*) all of the bytecode from the upstream\n-    // libraries has already been included in our object file output. As a\n-    // result we need to remove the object files in the upstream libraries so\n-    // the linker doesn't try to include them twice (or whine about duplicate\n-    // symbols). We must continue to include the rest of the rlib, however, as\n-    // it may contain static native libraries which must be linked in.\n-    //\n-    // (*) Crates marked with `#![no_builtins]` don't participate in LTO and\n-    // their bytecode wasn't included. The object files in those libraries must\n-    // still be passed to the linker.\n-    //\n-    // When making a dynamic library, linkers by default don't include any\n-    // object files in an archive if they're not necessary to resolve the link.\n-    // We basically want to convert the archive (rlib) to a dylib, though, so we\n-    // *do* want everything included in the output, regardless of whether the\n-    // linker thinks it's needed or not. As a result we must use the\n-    // --whole-archive option (or the platform equivalent). When using this\n-    // option the linker will fail if there are non-objects in the archive (such\n-    // as our own metadata and/or bytecode). All in all, for rlibs to be\n-    // entirely included in dylibs, we need to remove all non-object files.\n-    //\n-    // Note, however, that if we're not doing LTO or we're not producing a dylib\n-    // (aka we're making an executable), we can just pass the rlib blindly to\n-    // the linker (fast) because it's fine if it's not actually included as\n-    // we're at the end of the dependency chain.\n-    fn add_static_crate(cmd: &mut dyn Linker,\n-                        sess: &Session,\n-                        codegen_results: &CodegenResults,\n-                        tmpdir: &Path,\n-                        crate_type: config::CrateType,\n-                        cnum: CrateNum) {\n-        let src = &codegen_results.crate_info.used_crate_source[&cnum];\n-        let cratepath = &src.rlib.as_ref().unwrap().0;\n-\n-        // See the comment above in `link_staticlib` and `link_rlib` for why if\n-        // there's a static library that's not relevant we skip all object\n-        // files.\n-        let native_libs = &codegen_results.crate_info.native_libraries[&cnum];\n-        let skip_native = native_libs.iter().any(|lib| {\n-            lib.kind == NativeLibraryKind::NativeStatic && !relevant_lib(sess, lib)\n-        });\n-\n-        if (!are_upstream_rust_objects_already_included(sess) ||\n-            ignored_for_lto(sess, &codegen_results.crate_info, cnum)) &&\n-           crate_type != config::CrateType::Dylib &&\n-           !skip_native {\n-            cmd.link_rlib(&fix_windows_verbatim_for_gcc(cratepath));\n-            return\n-        }\n-\n-        let dst = tmpdir.join(cratepath.file_name().unwrap());\n-        let name = cratepath.file_name().unwrap().to_str().unwrap();\n-        let name = &name[3..name.len() - 5]; // chop off lib/.rlib\n-\n-        time(sess, &format!(\"altering {}.rlib\", name), || {\n-            let cfg = archive_config(sess, &dst, Some(cratepath));\n-            let mut archive = ArchiveBuilder::new(cfg);\n-            archive.update_symbols();\n-\n-            let mut any_objects = false;\n-            for f in archive.src_files() {\n-                if f.ends_with(RLIB_BYTECODE_EXTENSION) || f == METADATA_FILENAME {\n-                    archive.remove_file(&f);\n-                    continue\n-                }\n-\n-                let canonical = f.replace(\"-\", \"_\");\n-                let canonical_name = name.replace(\"-\", \"_\");\n-\n-                // Look for `.rcgu.o` at the end of the filename to conclude\n-                // that this is a Rust-related object file.\n-                fn looks_like_rust(s: &str) -> bool {\n-                    let path = Path::new(s);\n-                    let ext = path.extension().and_then(|s| s.to_str());\n-                    if ext != Some(OutputType::Object.extension()) {\n-                        return false\n-                    }\n-                    let ext2 = path.file_stem()\n-                        .and_then(|s| Path::new(s).extension())\n-                        .and_then(|s| s.to_str());\n-                    ext2 == Some(RUST_CGU_EXT)\n-                }\n-\n-                let is_rust_object =\n-                    canonical.starts_with(&canonical_name) &&\n-                    looks_like_rust(&f);\n-\n-                // If we've been requested to skip all native object files\n-                // (those not generated by the rust compiler) then we can skip\n-                // this file. See above for why we may want to do this.\n-                let skip_because_cfg_say_so = skip_native && !is_rust_object;\n-\n-                // If we're performing LTO and this is a rust-generated object\n-                // file, then we don't need the object file as it's part of the\n-                // LTO module. Note that `#![no_builtins]` is excluded from LTO,\n-                // though, so we let that object file slide.\n-                let skip_because_lto = are_upstream_rust_objects_already_included(sess) &&\n-                    is_rust_object &&\n-                    (sess.target.target.options.no_builtins ||\n-                     !codegen_results.crate_info.is_no_builtins.contains(&cnum));\n-\n-                if skip_because_cfg_say_so || skip_because_lto {\n-                    archive.remove_file(&f);\n-                } else {\n-                    any_objects = true;\n-                }\n-            }\n-\n-            if !any_objects {\n-                return\n-            }\n-            archive.build();\n-\n-            // If we're creating a dylib, then we need to include the\n-            // whole of each object in our archive into that artifact. This is\n-            // because a `dylib` can be reused as an intermediate artifact.\n-            //\n-            // Note, though, that we don't want to include the whole of a\n-            // compiler-builtins crate (e.g. compiler-rt) because it'll get\n-            // repeatedly linked anyway.\n-            if crate_type == config::CrateType::Dylib &&\n-                codegen_results.crate_info.compiler_builtins != Some(cnum) {\n-                cmd.link_whole_rlib(&fix_windows_verbatim_for_gcc(&dst));\n-            } else {\n-                cmd.link_rlib(&fix_windows_verbatim_for_gcc(&dst));\n-            }\n-        });\n-    }\n-\n-    // Same thing as above, but for dynamic crates instead of static crates.\n-    fn add_dynamic_crate(cmd: &mut dyn Linker, sess: &Session, cratepath: &Path) {\n-        // If we're performing LTO, then it should have been previously required\n-        // that all upstream rust dependencies were available in an rlib format.\n-        assert!(!are_upstream_rust_objects_already_included(sess));\n-\n-        // Just need to tell the linker about where the library lives and\n-        // what its name is\n-        let parent = cratepath.parent();\n-        if let Some(dir) = parent {\n-            cmd.include_path(&fix_windows_verbatim_for_gcc(dir));\n-        }\n-        let filestem = cratepath.file_stem().unwrap().to_str().unwrap();\n-        cmd.link_rust_dylib(&unlib(&sess.target, filestem),\n-                            parent.unwrap_or(Path::new(\"\")));\n-    }\n-}\n-\n-// # Native library linking\n-//\n-// User-supplied library search paths (-L on the command line). These are\n-// the same paths used to find Rust crates, so some of them may have been\n-// added already by the previous crate linking code. This only allows them\n-// to be found at compile time so it is still entirely up to outside\n-// forces to make sure that library can be found at runtime.\n-//\n-// Also note that the native libraries linked here are only the ones located\n-// in the current crate. Upstream crates with native library dependencies\n-// may have their native library pulled in above.\n-fn add_local_native_libraries(cmd: &mut dyn Linker,\n-                              sess: &Session,\n-                              codegen_results: &CodegenResults) {\n-    sess.target_filesearch(PathKind::All).for_each_lib_search_path(|path, k| {\n-        match k {\n-            PathKind::Framework => { cmd.framework_path(path); }\n-            _ => { cmd.include_path(&fix_windows_verbatim_for_gcc(path)); }\n-        }\n-    });\n-\n-    let relevant_libs = codegen_results.crate_info.used_libraries.iter().filter(|l| {\n-        relevant_lib(sess, l)\n-    });\n-\n-    let search_path = archive_search_paths(sess);\n-    for lib in relevant_libs {\n-        let name = match lib.name {\n-            Some(ref l) => l,\n-            None => continue,\n-        };\n-        match lib.kind {\n-            NativeLibraryKind::NativeUnknown => cmd.link_dylib(&name.as_str()),\n-            NativeLibraryKind::NativeFramework => cmd.link_framework(&name.as_str()),\n-            NativeLibraryKind::NativeStaticNobundle => cmd.link_staticlib(&name.as_str()),\n-            NativeLibraryKind::NativeStatic => cmd.link_whole_staticlib(&name.as_str(),\n-                                                                        &search_path)\n-        }\n-    }\n-}\n-\n-// Link in all of our upstream crates' native dependencies. Remember that\n-// all of these upstream native dependencies are all non-static\n-// dependencies. We've got two cases then:\n-//\n-// 1. The upstream crate is an rlib. In this case we *must* link in the\n-// native dependency because the rlib is just an archive.\n-//\n-// 2. The upstream crate is a dylib. In order to use the dylib, we have to\n-// have the dependency present on the system somewhere. Thus, we don't\n-// gain a whole lot from not linking in the dynamic dependency to this\n-// crate as well.\n-//\n-// The use case for this is a little subtle. In theory the native\n-// dependencies of a crate are purely an implementation detail of the crate\n-// itself, but the problem arises with generic and inlined functions. If a\n-// generic function calls a native function, then the generic function must\n-// be instantiated in the target crate, meaning that the native symbol must\n-// also be resolved in the target crate.\n-fn add_upstream_native_libraries(cmd: &mut dyn Linker,\n-                                 sess: &Session,\n-                                 codegen_results: &CodegenResults,\n-                                 crate_type: config::CrateType) {\n-    // Be sure to use a topological sorting of crates because there may be\n-    // interdependencies between native libraries. When passing -nodefaultlibs,\n-    // for example, almost all native libraries depend on libc, so we have to\n-    // make sure that's all the way at the right (liblibc is near the base of\n-    // the dependency chain).\n-    //\n-    // This passes RequireStatic, but the actual requirement doesn't matter,\n-    // we're just getting an ordering of crate numbers, we're not worried about\n-    // the paths.\n-    let formats = sess.dependency_formats.borrow();\n-    let data = formats.get(&crate_type).unwrap();\n-\n-    let crates = &codegen_results.crate_info.used_crates_static;\n-    for &(cnum, _) in crates {\n-        for lib in codegen_results.crate_info.native_libraries[&cnum].iter() {\n-            let name = match lib.name {\n-                Some(ref l) => l,\n-                None => continue,\n-            };\n-            if !relevant_lib(sess, &lib) {\n-                continue\n-            }\n-            match lib.kind {\n-                NativeLibraryKind::NativeUnknown => cmd.link_dylib(&name.as_str()),\n-                NativeLibraryKind::NativeFramework => cmd.link_framework(&name.as_str()),\n-                NativeLibraryKind::NativeStaticNobundle => {\n-                    // Link \"static-nobundle\" native libs only if the crate they originate from\n-                    // is being linked statically to the current crate.  If it's linked dynamically\n-                    // or is an rlib already included via some other dylib crate, the symbols from\n-                    // native libs will have already been included in that dylib.\n-                    if data[cnum.as_usize() - 1] == Linkage::Static {\n-                        cmd.link_staticlib(&name.as_str())\n-                    }\n-                },\n-                // ignore statically included native libraries here as we've\n-                // already included them when we included the rust library\n-                // previously\n-                NativeLibraryKind::NativeStatic => {}\n-            }\n-        }\n-    }\n-}\n-\n-/// Returns a boolean indicating whether the specified crate should be ignored\n-/// during LTO.\n-///\n-/// Crates ignored during LTO are not lumped together in the \"massive object\n-/// file\" that we create and are linked in their normal rlib states. See\n-/// comments below for what crates do not participate in LTO.\n-///\n-/// It's unusual for a crate to not participate in LTO. Typically only\n-/// compiler-specific and unstable crates have a reason to not participate in\n-/// LTO.\n-fn ignored_for_lto(sess: &Session, info: &CrateInfo, cnum: CrateNum) -> bool {\n-    // If our target enables builtin function lowering in LLVM then the\n-    // crates providing these functions don't participate in LTO (e.g.\n-    // no_builtins or compiler builtins crates).\n-    !sess.target.target.options.no_builtins &&\n-        (info.is_no_builtins.contains(&cnum) || info.compiler_builtins == Some(cnum))\n-}\n-\n-fn relevant_lib(sess: &Session, lib: &NativeLibrary) -> bool {\n-    match lib.cfg {\n-        Some(ref cfg) => attr::cfg_matches(cfg, &sess.parse_sess, None),\n-        None => true,\n-    }\n-}\n-\n-fn are_upstream_rust_objects_already_included(sess: &Session) -> bool {\n-    match sess.lto() {\n-        Lto::Fat => true,\n-        Lto::Thin => {\n-            // If we defer LTO to the linker, we haven't run LTO ourselves, so\n-            // any upstream object files have not been copied yet.\n-            !sess.opts.debugging_opts.cross_lang_lto.enabled()\n-        }\n-        Lto::No |\n-        Lto::ThinLocal => false,\n-    }\n-}"}, {"sha": "986fe71e906b32898b1e716f6ab2fb314a002fff", "filename": "src/link_copied.rs", "status": "added", "additions": 777, "deletions": 0, "changes": 777, "blob_url": "https://github.com/rust-lang/rust/blob/f955c8ef2a703de41c347b86b4f828c76f76dede/src%2Flink_copied.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f955c8ef2a703de41c347b86b4f828c76f76dede/src%2Flink_copied.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flink_copied.rs?ref=f955c8ef2a703de41c347b86b4f828c76f76dede", "patch": "@@ -0,0 +1,777 @@\n+//! All functions here are copied from https://github.com/rust-lang/rust/blob/942864a000efd74b73e36bda5606b2cdb55ecf39/src/librustc_codegen_llvm/back/link.rs\n+\n+use std::env;\n+use std::fmt;\n+use std::fs;\n+use std::io;\n+use std::iter;\n+use std::path::{Path, PathBuf};\n+use std::process::{Output, Stdio};\n+\n+use cc::windows_registry;\n+\n+use rustc::middle::cstore::{NativeLibrary, NativeLibraryKind};\n+use rustc::middle::dependency_format::Linkage;\n+use rustc::session::config::{self, OutputType, RUST_CGU_EXT};\n+use rustc::session::search_paths::PathKind;\n+use rustc::session::Session;\n+use rustc::util::common::time;\n+use rustc_codegen_utils::command::Command;\n+use rustc_codegen_utils::linker::*;\n+use rustc_data_structures::fx::FxHashSet;\n+use rustc_fs_util::fix_windows_verbatim_for_gcc;\n+use rustc_target::spec::LinkerFlavor;\n+use syntax::attr;\n+\n+use crate::prelude::*;\n+\n+use crate::archive::{ArchiveBuilder, ArchiveConfig};\n+use crate::metadata::METADATA_FILENAME;\n+\n+\n+// cg_clif doesn't have bytecode, so this is just a dummy\n+const RLIB_BYTECODE_EXTENSION: &str = \".cg_clif_bytecode_dummy\";\n+\n+fn archive_search_paths(sess: &Session) -> Vec<PathBuf> {\n+    let mut search = Vec::new();\n+    sess.target_filesearch(PathKind::Native).for_each_lib_search_path(|path, _| {\n+        search.push(path.to_path_buf());\n+    });\n+    return search;\n+}\n+\n+fn archive_config<'a>(sess: &'a Session,\n+                      output: &Path,\n+                      input: Option<&Path>) -> ArchiveConfig<'a> {\n+    ArchiveConfig {\n+        sess,\n+        dst: output.to_path_buf(),\n+        src: input.map(|p| p.to_path_buf()),\n+        lib_search_paths: archive_search_paths(sess),\n+    }\n+}\n+\n+// The third parameter is for env vars, used on windows to set up the\n+// path for MSVC to find its DLLs, and gcc to find its bundled\n+// toolchain\n+pub fn get_linker(sess: &Session, linker: &Path, flavor: LinkerFlavor) -> (PathBuf, Command) {\n+    let msvc_tool = windows_registry::find_tool(&sess.opts.target_triple.triple(), \"link.exe\");\n+\n+    // If our linker looks like a batch script on Windows then to execute this\n+    // we'll need to spawn `cmd` explicitly. This is primarily done to handle\n+    // emscripten where the linker is `emcc.bat` and needs to be spawned as\n+    // `cmd /c emcc.bat ...`.\n+    //\n+    // This worked historically but is needed manually since #42436 (regression\n+    // was tagged as #42791) and some more info can be found on #44443 for\n+    // emscripten itself.\n+    let mut cmd = match linker.to_str() {\n+        Some(linker) if cfg!(windows) && linker.ends_with(\".bat\") => Command::bat_script(linker),\n+        _ => match flavor {\n+            LinkerFlavor::Lld(f) => Command::lld(linker, f),\n+            LinkerFlavor::Msvc\n+                if sess.opts.cg.linker.is_none() && sess.target.target.options.linker.is_none() =>\n+            {\n+                Command::new(msvc_tool.as_ref().map(|t| t.path()).unwrap_or(linker))\n+            },\n+            _ => Command::new(linker),\n+        }\n+    };\n+\n+    // The compiler's sysroot often has some bundled tools, so add it to the\n+    // PATH for the child.\n+    let mut new_path = sess.host_filesearch(PathKind::All)\n+                           .get_tools_search_paths();\n+    let mut msvc_changed_path = false;\n+    if sess.target.target.options.is_like_msvc {\n+        if let Some(ref tool) = msvc_tool {\n+            cmd.args(tool.args());\n+            for &(ref k, ref v) in tool.env() {\n+                if k == \"PATH\" {\n+                    new_path.extend(env::split_paths(v));\n+                    msvc_changed_path = true;\n+                } else {\n+                    cmd.env(k, v);\n+                }\n+            }\n+        }\n+    }\n+\n+    if !msvc_changed_path {\n+        if let Some(path) = env::var_os(\"PATH\") {\n+            new_path.extend(env::split_paths(&path));\n+        }\n+    }\n+    cmd.env(\"PATH\", env::join_paths(new_path).unwrap());\n+\n+    (linker.to_path_buf(), cmd)\n+}\n+\n+pub fn linker_and_flavor(sess: &Session) -> (PathBuf, LinkerFlavor) {\n+    fn infer_from(\n+        sess: &Session,\n+        linker: Option<PathBuf>,\n+        flavor: Option<LinkerFlavor>,\n+    ) -> Option<(PathBuf, LinkerFlavor)> {\n+        match (linker, flavor) {\n+            (Some(linker), Some(flavor)) => Some((linker, flavor)),\n+            // only the linker flavor is known; use the default linker for the selected flavor\n+            (None, Some(flavor)) => Some((PathBuf::from(match flavor {\n+                LinkerFlavor::Em  => if cfg!(windows) { \"emcc.bat\" } else { \"emcc\" },\n+                LinkerFlavor::Gcc => \"cc\",\n+                LinkerFlavor::Ld => \"ld\",\n+                LinkerFlavor::Msvc => \"link.exe\",\n+                LinkerFlavor::Lld(_) => \"lld\",\n+            }), flavor)),\n+            (Some(linker), None) => {\n+                let stem = linker.file_stem().and_then(|stem| stem.to_str()).unwrap_or_else(|| {\n+                    sess.fatal(\"couldn't extract file stem from specified linker\");\n+                }).to_owned();\n+\n+                let flavor = if stem == \"emcc\" {\n+                    LinkerFlavor::Em\n+                } else if stem == \"gcc\" || stem.ends_with(\"-gcc\") {\n+                    LinkerFlavor::Gcc\n+                } else if stem == \"ld\" || stem == \"ld.lld\" || stem.ends_with(\"-ld\") {\n+                    LinkerFlavor::Ld\n+                } else if stem == \"link\" || stem == \"lld-link\" {\n+                    LinkerFlavor::Msvc\n+                } else if stem == \"lld\" || stem == \"rust-lld\" {\n+                    LinkerFlavor::Lld(sess.target.target.options.lld_flavor)\n+                } else {\n+                    // fall back to the value in the target spec\n+                    sess.target.target.linker_flavor\n+                };\n+\n+                Some((linker, flavor))\n+            },\n+            (None, None) => None,\n+        }\n+    }\n+\n+    // linker and linker flavor specified via command line have precedence over what the target\n+    // specification specifies\n+    if let Some(ret) = infer_from(\n+        sess,\n+        sess.opts.cg.linker.clone(),\n+        sess.opts.debugging_opts.linker_flavor,\n+    ) {\n+        return ret;\n+    }\n+\n+    if let Some(ret) = infer_from(\n+        sess,\n+        sess.target.target.options.linker.clone().map(PathBuf::from),\n+        Some(sess.target.target.linker_flavor),\n+    ) {\n+        return ret;\n+    }\n+\n+    bug!(\"Not enough information provided to determine how to invoke the linker\");\n+}\n+\n+pub fn exec_linker(sess: &Session, cmd: &mut Command, out_filename: &Path, tmpdir: &Path)\n+    -> io::Result<Output>\n+{\n+    // When attempting to spawn the linker we run a risk of blowing out the\n+    // size limits for spawning a new process with respect to the arguments\n+    // we pass on the command line.\n+    //\n+    // Here we attempt to handle errors from the OS saying \"your list of\n+    // arguments is too big\" by reinvoking the linker again with an `@`-file\n+    // that contains all the arguments. The theory is that this is then\n+    // accepted on all linkers and the linker will read all its options out of\n+    // there instead of looking at the command line.\n+    if !cmd.very_likely_to_exceed_some_spawn_limit() {\n+        match cmd.command().stdout(Stdio::piped()).stderr(Stdio::piped()).spawn() {\n+            Ok(child) => {\n+                let output = child.wait_with_output();\n+                flush_linked_file(&output, out_filename)?;\n+                return output;\n+            }\n+            Err(ref e) if command_line_too_big(e) => {\n+                info!(\"command line to linker was too big: {}\", e);\n+            }\n+            Err(e) => return Err(e)\n+        }\n+    }\n+\n+    info!(\"falling back to passing arguments to linker via an @-file\");\n+    let mut cmd2 = cmd.clone();\n+    let mut args = String::new();\n+    for arg in cmd2.take_args() {\n+        args.push_str(&Escape {\n+            arg: arg.to_str().unwrap(),\n+            is_like_msvc: sess.target.target.options.is_like_msvc,\n+        }.to_string());\n+        args.push_str(\"\\n\");\n+    }\n+    let file = tmpdir.join(\"linker-arguments\");\n+    let bytes = if sess.target.target.options.is_like_msvc {\n+        let mut out = Vec::with_capacity((1 + args.len()) * 2);\n+        // start the stream with a UTF-16 BOM\n+        for c in iter::once(0xFEFF).chain(args.encode_utf16()) {\n+            // encode in little endian\n+            out.push(c as u8);\n+            out.push((c >> 8) as u8);\n+        }\n+        out\n+    } else {\n+        args.into_bytes()\n+    };\n+    fs::write(&file, &bytes)?;\n+    cmd2.arg(format!(\"@{}\", file.display()));\n+    info!(\"invoking linker {:?}\", cmd2);\n+    let output = cmd2.output();\n+    flush_linked_file(&output, out_filename)?;\n+    return output;\n+\n+    #[cfg(unix)]\n+    fn flush_linked_file(_: &io::Result<Output>, _: &Path) -> io::Result<()> {\n+        Ok(())\n+    }\n+\n+    #[cfg(windows)]\n+    fn flush_linked_file(command_output: &io::Result<Output>, out_filename: &Path)\n+        -> io::Result<()>\n+    {\n+        // On Windows, under high I/O load, output buffers are sometimes not flushed,\n+        // even long after process exit, causing nasty, non-reproducible output bugs.\n+        //\n+        // File::sync_all() calls FlushFileBuffers() down the line, which solves the problem.\n+        //\n+        // \u0410 full writeup of the original Chrome bug can be found at\n+        // randomascii.wordpress.com/2018/02/25/compiler-bug-linker-bug-windows-kernel-bug/amp\n+\n+        if let &Ok(ref out) = command_output {\n+            if out.status.success() {\n+                if let Ok(of) = fs::OpenOptions::new().write(true).open(out_filename) {\n+                    of.sync_all()?;\n+                }\n+            }\n+        }\n+\n+        Ok(())\n+    }\n+\n+    #[cfg(unix)]\n+    fn command_line_too_big(err: &io::Error) -> bool {\n+        err.raw_os_error() == Some(::libc::E2BIG)\n+    }\n+\n+    #[cfg(windows)]\n+    fn command_line_too_big(err: &io::Error) -> bool {\n+        const ERROR_FILENAME_EXCED_RANGE: i32 = 206;\n+        err.raw_os_error() == Some(ERROR_FILENAME_EXCED_RANGE)\n+    }\n+\n+    struct Escape<'a> {\n+        arg: &'a str,\n+        is_like_msvc: bool,\n+    }\n+\n+    impl<'a> fmt::Display for Escape<'a> {\n+        fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+            if self.is_like_msvc {\n+                // This is \"documented\" at\n+                // https://msdn.microsoft.com/en-us/library/4xdcbak7.aspx\n+                //\n+                // Unfortunately there's not a great specification of the\n+                // syntax I could find online (at least) but some local\n+                // testing showed that this seemed sufficient-ish to catch\n+                // at least a few edge cases.\n+                write!(f, \"\\\"\")?;\n+                for c in self.arg.chars() {\n+                    match c {\n+                        '\"' => write!(f, \"\\\\{}\", c)?,\n+                        c => write!(f, \"{}\", c)?,\n+                    }\n+                }\n+                write!(f, \"\\\"\")?;\n+            } else {\n+                // This is documented at https://linux.die.net/man/1/ld, namely:\n+                //\n+                // > Options in file are separated by whitespace. A whitespace\n+                // > character may be included in an option by surrounding the\n+                // > entire option in either single or double quotes. Any\n+                // > character (including a backslash) may be included by\n+                // > prefixing the character to be included with a backslash.\n+                //\n+                // We put an argument on each line, so all we need to do is\n+                // ensure the line is interpreted as one whole argument.\n+                for c in self.arg.chars() {\n+                    match c {\n+                        '\\\\' |\n+                        ' ' => write!(f, \"\\\\{}\", c)?,\n+                        c => write!(f, \"{}\", c)?,\n+                    }\n+                }\n+            }\n+            Ok(())\n+        }\n+    }\n+}\n+\n+// # Rust Crate linking\n+//\n+// Rust crates are not considered at all when creating an rlib output. All\n+// dependencies will be linked when producing the final output (instead of\n+// the intermediate rlib version)\n+pub fn add_upstream_rust_crates(cmd: &mut dyn Linker,\n+                            sess: &Session,\n+                            codegen_results: &CodegenResults,\n+                            crate_type: config::CrateType,\n+                            tmpdir: &Path) {\n+    // All of the heavy lifting has previously been accomplished by the\n+    // dependency_format module of the compiler. This is just crawling the\n+    // output of that module, adding crates as necessary.\n+    //\n+    // Linking to a rlib involves just passing it to the linker (the linker\n+    // will slurp up the object files inside), and linking to a dynamic library\n+    // involves just passing the right -l flag.\n+\n+    let formats = sess.dependency_formats.borrow();\n+    let data = formats.get(&crate_type).unwrap();\n+\n+    // Invoke get_used_crates to ensure that we get a topological sorting of\n+    // crates.\n+    let deps = &codegen_results.crate_info.used_crates_dynamic;\n+\n+    // There's a few internal crates in the standard library (aka libcore and\n+    // libstd) which actually have a circular dependence upon one another. This\n+    // currently arises through \"weak lang items\" where libcore requires things\n+    // like `rust_begin_unwind` but libstd ends up defining it. To get this\n+    // circular dependence to work correctly in all situations we'll need to be\n+    // sure to correctly apply the `--start-group` and `--end-group` options to\n+    // GNU linkers, otherwise if we don't use any other symbol from the standard\n+    // library it'll get discarded and the whole application won't link.\n+    //\n+    // In this loop we're calculating the `group_end`, after which crate to\n+    // pass `--end-group` and `group_start`, before which crate to pass\n+    // `--start-group`. We currently do this by passing `--end-group` after\n+    // the first crate (when iterating backwards) that requires a lang item\n+    // defined somewhere else. Once that's set then when we've defined all the\n+    // necessary lang items we'll pass `--start-group`.\n+    //\n+    // Note that this isn't amazing logic for now but it should do the trick\n+    // for the current implementation of the standard library.\n+    let mut group_end = None;\n+    let mut group_start = None;\n+    let mut end_with = FxHashSet::default();\n+    let info = &codegen_results.crate_info;\n+    for &(cnum, _) in deps.iter().rev() {\n+        if let Some(missing) = info.missing_lang_items.get(&cnum) {\n+            end_with.extend(missing.iter().cloned());\n+            if end_with.len() > 0 && group_end.is_none() {\n+                group_end = Some(cnum);\n+            }\n+        }\n+        end_with.retain(|item| info.lang_item_to_crate.get(item) != Some(&cnum));\n+        if end_with.len() == 0 && group_end.is_some() {\n+            group_start = Some(cnum);\n+            break\n+        }\n+    }\n+\n+    // If we didn't end up filling in all lang items from upstream crates then\n+    // we'll be filling it in with our crate. This probably means we're the\n+    // standard library itself, so skip this for now.\n+    if group_end.is_some() && group_start.is_none() {\n+        group_end = None;\n+    }\n+\n+    let mut compiler_builtins = None;\n+\n+    for &(cnum, _) in deps.iter() {\n+        if group_start == Some(cnum) {\n+            cmd.group_start();\n+        }\n+\n+        // We may not pass all crates through to the linker. Some crates may\n+        // appear statically in an existing dylib, meaning we'll pick up all the\n+        // symbols from the dylib.\n+        let src = &codegen_results.crate_info.used_crate_source[&cnum];\n+        match data[cnum.as_usize() - 1] {\n+            _ if codegen_results.crate_info.profiler_runtime == Some(cnum) => {\n+                add_static_crate(cmd, sess, codegen_results, tmpdir, crate_type, cnum);\n+            }\n+            _ if codegen_results.crate_info.sanitizer_runtime == Some(cnum) => {\n+                link_sanitizer_runtime(cmd, sess, codegen_results, tmpdir, cnum);\n+            }\n+            // compiler-builtins are always placed last to ensure that they're\n+            // linked correctly.\n+            _ if codegen_results.crate_info.compiler_builtins == Some(cnum) => {\n+                assert!(compiler_builtins.is_none());\n+                compiler_builtins = Some(cnum);\n+            }\n+            Linkage::NotLinked |\n+            Linkage::IncludedFromDylib => {}\n+            Linkage::Static => {\n+                add_static_crate(cmd, sess, codegen_results, tmpdir, crate_type, cnum);\n+            }\n+            Linkage::Dynamic => {\n+                add_dynamic_crate(cmd, sess, &src.dylib.as_ref().unwrap().0)\n+            }\n+        }\n+\n+        if group_end == Some(cnum) {\n+            cmd.group_end();\n+        }\n+    }\n+\n+    // compiler-builtins are always placed last to ensure that they're\n+    // linked correctly.\n+    // We must always link the `compiler_builtins` crate statically. Even if it\n+    // was already \"included\" in a dylib (e.g. `libstd` when `-C prefer-dynamic`\n+    // is used)\n+    if let Some(cnum) = compiler_builtins {\n+        add_static_crate(cmd, sess, codegen_results, tmpdir, crate_type, cnum);\n+    }\n+\n+    // Converts a library file-stem into a cc -l argument\n+    fn unlib<'a>(config: &config::Config, stem: &'a str) -> &'a str {\n+        if stem.starts_with(\"lib\") && !config.target.options.is_like_windows {\n+            &stem[3..]\n+        } else {\n+            stem\n+        }\n+    }\n+\n+    // We must link the sanitizer runtime using -Wl,--whole-archive but since\n+    // it's packed in a .rlib, it contains stuff that are not objects that will\n+    // make the linker error. So we must remove those bits from the .rlib before\n+    // linking it.\n+    fn link_sanitizer_runtime(cmd: &mut dyn Linker,\n+                              sess: &Session,\n+                              codegen_results: &CodegenResults,\n+                              tmpdir: &Path,\n+                              cnum: CrateNum) {\n+        let src = &codegen_results.crate_info.used_crate_source[&cnum];\n+        let cratepath = &src.rlib.as_ref().unwrap().0;\n+\n+        if sess.target.target.options.is_like_osx {\n+            // On Apple platforms, the sanitizer is always built as a dylib, and\n+            // LLVM will link to `@rpath/*.dylib`, so we need to specify an\n+            // rpath to the library as well (the rpath should be absolute, see\n+            // PR #41352 for details).\n+            //\n+            // FIXME: Remove this logic into librustc_*san once Cargo supports it\n+            let rpath = cratepath.parent().unwrap();\n+            let rpath = rpath.to_str().expect(\"non-utf8 component in path\");\n+            cmd.args(&[\"-Wl,-rpath\".into(), \"-Xlinker\".into(), rpath.into()]);\n+        }\n+\n+        let dst = tmpdir.join(cratepath.file_name().unwrap());\n+        let cfg = archive_config(sess, &dst, Some(cratepath));\n+        let mut archive = ArchiveBuilder::new(cfg);\n+        archive.update_symbols();\n+\n+        for f in archive.src_files() {\n+            if f.ends_with(RLIB_BYTECODE_EXTENSION) || f == METADATA_FILENAME {\n+                archive.remove_file(&f);\n+                continue\n+            }\n+        }\n+\n+        archive.build();\n+\n+        cmd.link_whole_rlib(&dst);\n+    }\n+\n+    // Adds the static \"rlib\" versions of all crates to the command line.\n+    // There's a bit of magic which happens here specifically related to LTO and\n+    // dynamic libraries. Specifically:\n+    //\n+    // * For LTO, we remove upstream object files.\n+    // * For dylibs we remove metadata and bytecode from upstream rlibs\n+    //\n+    // When performing LTO, almost(*) all of the bytecode from the upstream\n+    // libraries has already been included in our object file output. As a\n+    // result we need to remove the object files in the upstream libraries so\n+    // the linker doesn't try to include them twice (or whine about duplicate\n+    // symbols). We must continue to include the rest of the rlib, however, as\n+    // it may contain static native libraries which must be linked in.\n+    //\n+    // (*) Crates marked with `#![no_builtins]` don't participate in LTO and\n+    // their bytecode wasn't included. The object files in those libraries must\n+    // still be passed to the linker.\n+    //\n+    // When making a dynamic library, linkers by default don't include any\n+    // object files in an archive if they're not necessary to resolve the link.\n+    // We basically want to convert the archive (rlib) to a dylib, though, so we\n+    // *do* want everything included in the output, regardless of whether the\n+    // linker thinks it's needed or not. As a result we must use the\n+    // --whole-archive option (or the platform equivalent). When using this\n+    // option the linker will fail if there are non-objects in the archive (such\n+    // as our own metadata and/or bytecode). All in all, for rlibs to be\n+    // entirely included in dylibs, we need to remove all non-object files.\n+    //\n+    // Note, however, that if we're not doing LTO or we're not producing a dylib\n+    // (aka we're making an executable), we can just pass the rlib blindly to\n+    // the linker (fast) because it's fine if it's not actually included as\n+    // we're at the end of the dependency chain.\n+    fn add_static_crate(cmd: &mut dyn Linker,\n+                        sess: &Session,\n+                        codegen_results: &CodegenResults,\n+                        tmpdir: &Path,\n+                        crate_type: config::CrateType,\n+                        cnum: CrateNum) {\n+        let src = &codegen_results.crate_info.used_crate_source[&cnum];\n+        let cratepath = &src.rlib.as_ref().unwrap().0;\n+\n+        // See the comment above in `link_staticlib` and `link_rlib` for why if\n+        // there's a static library that's not relevant we skip all object\n+        // files.\n+        let native_libs = &codegen_results.crate_info.native_libraries[&cnum];\n+        let skip_native = native_libs.iter().any(|lib| {\n+            lib.kind == NativeLibraryKind::NativeStatic && !relevant_lib(sess, lib)\n+        });\n+\n+        if (!are_upstream_rust_objects_already_included(sess) ||\n+            ignored_for_lto(sess, &codegen_results.crate_info, cnum)) &&\n+           crate_type != config::CrateType::Dylib &&\n+           !skip_native {\n+            cmd.link_rlib(&fix_windows_verbatim_for_gcc(cratepath));\n+            return\n+        }\n+\n+        let dst = tmpdir.join(cratepath.file_name().unwrap());\n+        let name = cratepath.file_name().unwrap().to_str().unwrap();\n+        let name = &name[3..name.len() - 5]; // chop off lib/.rlib\n+\n+        time(sess, &format!(\"altering {}.rlib\", name), || {\n+            let cfg = archive_config(sess, &dst, Some(cratepath));\n+            let mut archive = ArchiveBuilder::new(cfg);\n+            archive.update_symbols();\n+\n+            let mut any_objects = false;\n+            for f in archive.src_files() {\n+                if f.ends_with(RLIB_BYTECODE_EXTENSION) || f == METADATA_FILENAME {\n+                    archive.remove_file(&f);\n+                    continue\n+                }\n+\n+                let canonical = f.replace(\"-\", \"_\");\n+                let canonical_name = name.replace(\"-\", \"_\");\n+\n+                // Look for `.rcgu.o` at the end of the filename to conclude\n+                // that this is a Rust-related object file.\n+                fn looks_like_rust(s: &str) -> bool {\n+                    let path = Path::new(s);\n+                    let ext = path.extension().and_then(|s| s.to_str());\n+                    if ext != Some(OutputType::Object.extension()) {\n+                        return false\n+                    }\n+                    let ext2 = path.file_stem()\n+                        .and_then(|s| Path::new(s).extension())\n+                        .and_then(|s| s.to_str());\n+                    ext2 == Some(RUST_CGU_EXT)\n+                }\n+\n+                let is_rust_object =\n+                    canonical.starts_with(&canonical_name) &&\n+                    looks_like_rust(&f);\n+\n+                // If we've been requested to skip all native object files\n+                // (those not generated by the rust compiler) then we can skip\n+                // this file. See above for why we may want to do this.\n+                let skip_because_cfg_say_so = skip_native && !is_rust_object;\n+\n+                // If we're performing LTO and this is a rust-generated object\n+                // file, then we don't need the object file as it's part of the\n+                // LTO module. Note that `#![no_builtins]` is excluded from LTO,\n+                // though, so we let that object file slide.\n+                let skip_because_lto = are_upstream_rust_objects_already_included(sess) &&\n+                    is_rust_object &&\n+                    (sess.target.target.options.no_builtins ||\n+                     !codegen_results.crate_info.is_no_builtins.contains(&cnum));\n+\n+                if skip_because_cfg_say_so || skip_because_lto {\n+                    archive.remove_file(&f);\n+                } else {\n+                    any_objects = true;\n+                }\n+            }\n+\n+            if !any_objects {\n+                return\n+            }\n+            archive.build();\n+\n+            // If we're creating a dylib, then we need to include the\n+            // whole of each object in our archive into that artifact. This is\n+            // because a `dylib` can be reused as an intermediate artifact.\n+            //\n+            // Note, though, that we don't want to include the whole of a\n+            // compiler-builtins crate (e.g. compiler-rt) because it'll get\n+            // repeatedly linked anyway.\n+            if crate_type == config::CrateType::Dylib &&\n+                codegen_results.crate_info.compiler_builtins != Some(cnum) {\n+                cmd.link_whole_rlib(&fix_windows_verbatim_for_gcc(&dst));\n+            } else {\n+                cmd.link_rlib(&fix_windows_verbatim_for_gcc(&dst));\n+            }\n+        });\n+    }\n+\n+    // Same thing as above, but for dynamic crates instead of static crates.\n+    fn add_dynamic_crate(cmd: &mut dyn Linker, sess: &Session, cratepath: &Path) {\n+        // If we're performing LTO, then it should have been previously required\n+        // that all upstream rust dependencies were available in an rlib format.\n+        assert!(!are_upstream_rust_objects_already_included(sess));\n+\n+        // Just need to tell the linker about where the library lives and\n+        // what its name is\n+        let parent = cratepath.parent();\n+        if let Some(dir) = parent {\n+            cmd.include_path(&fix_windows_verbatim_for_gcc(dir));\n+        }\n+        let filestem = cratepath.file_stem().unwrap().to_str().unwrap();\n+        cmd.link_rust_dylib(&unlib(&sess.target, filestem),\n+                            parent.unwrap_or(Path::new(\"\")));\n+    }\n+}\n+\n+// # Native library linking\n+//\n+// User-supplied library search paths (-L on the command line). These are\n+// the same paths used to find Rust crates, so some of them may have been\n+// added already by the previous crate linking code. This only allows them\n+// to be found at compile time so it is still entirely up to outside\n+// forces to make sure that library can be found at runtime.\n+//\n+// Also note that the native libraries linked here are only the ones located\n+// in the current crate. Upstream crates with native library dependencies\n+// may have their native library pulled in above.\n+pub fn add_local_native_libraries(cmd: &mut dyn Linker,\n+                              sess: &Session,\n+                              codegen_results: &CodegenResults) {\n+    sess.target_filesearch(PathKind::All).for_each_lib_search_path(|path, k| {\n+        match k {\n+            PathKind::Framework => { cmd.framework_path(path); }\n+            _ => { cmd.include_path(&fix_windows_verbatim_for_gcc(path)); }\n+        }\n+    });\n+\n+    let relevant_libs = codegen_results.crate_info.used_libraries.iter().filter(|l| {\n+        relevant_lib(sess, l)\n+    });\n+\n+    let search_path = archive_search_paths(sess);\n+    for lib in relevant_libs {\n+        let name = match lib.name {\n+            Some(ref l) => l,\n+            None => continue,\n+        };\n+        match lib.kind {\n+            NativeLibraryKind::NativeUnknown => cmd.link_dylib(&name.as_str()),\n+            NativeLibraryKind::NativeFramework => cmd.link_framework(&name.as_str()),\n+            NativeLibraryKind::NativeStaticNobundle => cmd.link_staticlib(&name.as_str()),\n+            NativeLibraryKind::NativeStatic => cmd.link_whole_staticlib(&name.as_str(),\n+                                                                        &search_path)\n+        }\n+    }\n+}\n+\n+// Link in all of our upstream crates' native dependencies. Remember that\n+// all of these upstream native dependencies are all non-static\n+// dependencies. We've got two cases then:\n+//\n+// 1. The upstream crate is an rlib. In this case we *must* link in the\n+// native dependency because the rlib is just an archive.\n+//\n+// 2. The upstream crate is a dylib. In order to use the dylib, we have to\n+// have the dependency present on the system somewhere. Thus, we don't\n+// gain a whole lot from not linking in the dynamic dependency to this\n+// crate as well.\n+//\n+// The use case for this is a little subtle. In theory the native\n+// dependencies of a crate are purely an implementation detail of the crate\n+// itself, but the problem arises with generic and inlined functions. If a\n+// generic function calls a native function, then the generic function must\n+// be instantiated in the target crate, meaning that the native symbol must\n+// also be resolved in the target crate.\n+pub fn add_upstream_native_libraries(cmd: &mut dyn Linker,\n+                                 sess: &Session,\n+                                 codegen_results: &CodegenResults,\n+                                 crate_type: config::CrateType) {\n+    // Be sure to use a topological sorting of crates because there may be\n+    // interdependencies between native libraries. When passing -nodefaultlibs,\n+    // for example, almost all native libraries depend on libc, so we have to\n+    // make sure that's all the way at the right (liblibc is near the base of\n+    // the dependency chain).\n+    //\n+    // This passes RequireStatic, but the actual requirement doesn't matter,\n+    // we're just getting an ordering of crate numbers, we're not worried about\n+    // the paths.\n+    let formats = sess.dependency_formats.borrow();\n+    let data = formats.get(&crate_type).unwrap();\n+\n+    let crates = &codegen_results.crate_info.used_crates_static;\n+    for &(cnum, _) in crates {\n+        for lib in codegen_results.crate_info.native_libraries[&cnum].iter() {\n+            let name = match lib.name {\n+                Some(ref l) => l,\n+                None => continue,\n+            };\n+            if !relevant_lib(sess, &lib) {\n+                continue\n+            }\n+            match lib.kind {\n+                NativeLibraryKind::NativeUnknown => cmd.link_dylib(&name.as_str()),\n+                NativeLibraryKind::NativeFramework => cmd.link_framework(&name.as_str()),\n+                NativeLibraryKind::NativeStaticNobundle => {\n+                    // Link \"static-nobundle\" native libs only if the crate they originate from\n+                    // is being linked statically to the current crate.  If it's linked dynamically\n+                    // or is an rlib already included via some other dylib crate, the symbols from\n+                    // native libs will have already been included in that dylib.\n+                    if data[cnum.as_usize() - 1] == Linkage::Static {\n+                        cmd.link_staticlib(&name.as_str())\n+                    }\n+                },\n+                // ignore statically included native libraries here as we've\n+                // already included them when we included the rust library\n+                // previously\n+                NativeLibraryKind::NativeStatic => {}\n+            }\n+        }\n+    }\n+}\n+\n+/// Returns a boolean indicating whether the specified crate should be ignored\n+/// during LTO.\n+///\n+/// Crates ignored during LTO are not lumped together in the \"massive object\n+/// file\" that we create and are linked in their normal rlib states. See\n+/// comments below for what crates do not participate in LTO.\n+///\n+/// It's unusual for a crate to not participate in LTO. Typically only\n+/// compiler-specific and unstable crates have a reason to not participate in\n+/// LTO.\n+fn ignored_for_lto(sess: &Session, info: &CrateInfo, cnum: CrateNum) -> bool {\n+    // If our target enables builtin function lowering in LLVM then the\n+    // crates providing these functions don't participate in LTO (e.g.\n+    // no_builtins or compiler builtins crates).\n+    !sess.target.target.options.no_builtins &&\n+        (info.is_no_builtins.contains(&cnum) || info.compiler_builtins == Some(cnum))\n+}\n+\n+fn relevant_lib(sess: &Session, lib: &NativeLibrary) -> bool {\n+    match lib.cfg {\n+        Some(ref cfg) => attr::cfg_matches(cfg, &sess.parse_sess, None),\n+        None => true,\n+    }\n+}\n+\n+fn are_upstream_rust_objects_already_included(sess: &Session) -> bool {\n+    match sess.lto() {\n+        Lto::Fat => true,\n+        Lto::Thin => {\n+            // If we defer LTO to the linker, we haven't run LTO ourselves, so\n+            // any upstream object files have not been copied yet.\n+            !sess.opts.debugging_opts.cross_lang_lto.enabled()\n+        }\n+        Lto::No |\n+        Lto::ThinLocal => false,\n+    }\n+}"}]}