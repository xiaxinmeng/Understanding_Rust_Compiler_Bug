{"sha": "bb30f047f6dbb5c8a73d105b25c2dc23d814b9ba", "node_id": "MDY6Q29tbWl0NzI0NzEyOmJiMzBmMDQ3ZjZkYmI1YzhhNzNkMTA1YjI1YzJkYzIzZDgxNGI5YmE=", "commit": {"author": {"name": "Tim Chevalier", "email": "chevalier@alum.wellesley.edu", "date": "2013-09-07T01:59:29Z"}, "committer": {"name": "Tim Chevalier", "email": "chevalier@alum.wellesley.edu", "date": "2013-09-09T03:05:11Z"}, "message": "workcache: Add the ability to save and load the database...\n\n...as well as the ability to discover inputs and outputs.", "tree": {"sha": "24d41880e17b6fcb9943a94f59bee681df20c036", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/24d41880e17b6fcb9943a94f59bee681df20c036"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bb30f047f6dbb5c8a73d105b25c2dc23d814b9ba", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bb30f047f6dbb5c8a73d105b25c2dc23d814b9ba", "html_url": "https://github.com/rust-lang/rust/commit/bb30f047f6dbb5c8a73d105b25c2dc23d814b9ba", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bb30f047f6dbb5c8a73d105b25c2dc23d814b9ba/comments", "author": {"login": "catamorphism", "id": 427212, "node_id": "MDQ6VXNlcjQyNzIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/427212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/catamorphism", "html_url": "https://github.com/catamorphism", "followers_url": "https://api.github.com/users/catamorphism/followers", "following_url": "https://api.github.com/users/catamorphism/following{/other_user}", "gists_url": "https://api.github.com/users/catamorphism/gists{/gist_id}", "starred_url": "https://api.github.com/users/catamorphism/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/catamorphism/subscriptions", "organizations_url": "https://api.github.com/users/catamorphism/orgs", "repos_url": "https://api.github.com/users/catamorphism/repos", "events_url": "https://api.github.com/users/catamorphism/events{/privacy}", "received_events_url": "https://api.github.com/users/catamorphism/received_events", "type": "User", "site_admin": false}, "committer": {"login": "catamorphism", "id": 427212, "node_id": "MDQ6VXNlcjQyNzIxMg==", "avatar_url": "https://avatars.githubusercontent.com/u/427212?v=4", "gravatar_id": "", "url": "https://api.github.com/users/catamorphism", "html_url": "https://github.com/catamorphism", "followers_url": "https://api.github.com/users/catamorphism/followers", "following_url": "https://api.github.com/users/catamorphism/following{/other_user}", "gists_url": "https://api.github.com/users/catamorphism/gists{/gist_id}", "starred_url": "https://api.github.com/users/catamorphism/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/catamorphism/subscriptions", "organizations_url": "https://api.github.com/users/catamorphism/orgs", "repos_url": "https://api.github.com/users/catamorphism/repos", "events_url": "https://api.github.com/users/catamorphism/events{/privacy}", "received_events_url": "https://api.github.com/users/catamorphism/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "dd5c7379e9b8f3fe6df95f3ff43ca955b6bba485", "url": "https://api.github.com/repos/rust-lang/rust/commits/dd5c7379e9b8f3fe6df95f3ff43ca955b6bba485", "html_url": "https://github.com/rust-lang/rust/commit/dd5c7379e9b8f3fe6df95f3ff43ca955b6bba485"}], "stats": {"total": 158, "additions": 139, "deletions": 19}, "files": [{"sha": "bf897e938810ef9711cf6bd6fba10c75549a0309", "filename": "src/libextra/workcache.rs", "status": "modified", "additions": 139, "deletions": 19, "changes": 158, "blob_url": "https://github.com/rust-lang/rust/blob/bb30f047f6dbb5c8a73d105b25c2dc23d814b9ba/src%2Flibextra%2Fworkcache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bb30f047f6dbb5c8a73d105b25c2dc23d814b9ba/src%2Flibextra%2Fworkcache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fworkcache.rs?ref=bb30f047f6dbb5c8a73d105b25c2dc23d814b9ba", "patch": "@@ -12,17 +12,15 @@\n \n use digest::Digest;\n use json;\n+use json::ToJson;\n use sha1::Sha1;\n use serialize::{Encoder, Encodable, Decoder, Decodable};\n use arc::{Arc,RWArc};\n use treemap::TreeMap;\n-\n use std::cell::Cell;\n use std::comm::{PortOne, oneshot};\n use std::either::{Either, Left, Right};\n-use std::io;\n-use std::run;\n-use std::task;\n+use std::{io, os, task};\n \n /**\n *\n@@ -107,11 +105,27 @@ impl WorkKey {\n     }\n }\n \n+// FIXME #8883: The key should be a WorkKey and not a ~str.\n+// This is working around some JSON weirdness.\n+#[deriving(Clone, Eq, Encodable, Decodable)]\n+struct WorkMap(TreeMap<~str, KindMap>);\n+\n #[deriving(Clone, Eq, Encodable, Decodable)]\n-struct WorkMap(TreeMap<WorkKey, ~str>);\n+struct KindMap(TreeMap<~str, ~str>);\n \n impl WorkMap {\n     fn new() -> WorkMap { WorkMap(TreeMap::new()) }\n+\n+    fn insert_work_key(&mut self, k: WorkKey, val: ~str) {\n+        let WorkKey { kind, name } = k;\n+        match self.find_mut(&name) {\n+            Some(&KindMap(ref mut m)) => { m.insert(kind, val); return; }\n+            None => ()\n+        }\n+        let mut new_map = TreeMap::new();\n+        new_map.insert(kind, val);\n+        self.insert(name, KindMap(new_map));\n+    }\n }\n \n struct Database {\n@@ -123,11 +137,15 @@ struct Database {\n impl Database {\n \n     pub fn new(p: Path) -> Database {\n-        Database {\n+        let mut rslt = Database {\n             db_filename: p,\n             db_cache: TreeMap::new(),\n             db_dirty: false\n+        };\n+        if os::path_exists(&rslt.db_filename) {\n+            rslt.load();\n         }\n+        rslt\n     }\n \n     pub fn prepare(&self,\n@@ -154,6 +172,41 @@ impl Database {\n         self.db_cache.insert(k,v);\n         self.db_dirty = true\n     }\n+\n+    // FIXME #4330: This should have &mut self and should set self.db_dirty to false.\n+    fn save(&self) {\n+        let f = io::file_writer(&self.db_filename, [io::Create, io::Truncate]).unwrap();\n+        self.db_cache.to_json().to_pretty_writer(f);\n+    }\n+\n+    fn load(&mut self) {\n+        assert!(!self.db_dirty);\n+        assert!(os::path_exists(&self.db_filename));\n+        let f = io::file_reader(&self.db_filename);\n+        match f {\n+            Err(e) => fail!(\"Couldn't load workcache database %s: %s\",\n+                            self.db_filename.to_str(), e.to_str()),\n+            Ok(r) =>\n+                match json::from_reader(r) {\n+                    Err(e) => fail!(\"Couldn't parse workcache database (from file %s): %s\",\n+                                    self.db_filename.to_str(), e.to_str()),\n+                    Ok(r) => {\n+                        let mut decoder = json::Decoder(r);\n+                        self.db_cache = Decodable::decode(&mut decoder);\n+                    }\n+            }\n+        }\n+    }\n+}\n+\n+// FIXME #4330: use &mut self here\n+#[unsafe_destructor]\n+impl Drop for Database {\n+    fn drop(&self) {\n+        if self.db_dirty {\n+            self.save();\n+        }\n+    }\n }\n \n struct Logger {\n@@ -172,12 +225,20 @@ impl Logger {\n     }\n }\n \n+type FreshnessMap = TreeMap<~str,extern fn(&str,&str)->bool>;\n+\n #[deriving(Clone)]\n struct Context {\n     db: RWArc<Database>,\n     logger: RWArc<Logger>,\n     cfg: Arc<json::Object>,\n-    freshness: Arc<TreeMap<~str,extern fn(&str,&str)->bool>>\n+    /// Map from kinds (source, exe, url, etc.) to a freshness function.\n+    /// The freshness function takes a name (e.g. file path) and value\n+    /// (e.g. hash of file contents) and determines whether it's up-to-date.\n+    /// For example, in the file case, this would read the file off disk,\n+    /// hash it, and return the result of comparing the given hash and the\n+    /// read hash for equality.\n+    freshness: Arc<FreshnessMap>\n }\n \n struct Prep<'self> {\n@@ -205,6 +266,7 @@ fn json_encode<T:Encodable<json::Encoder>>(t: &T) -> ~str {\n \n // FIXME(#5121)\n fn json_decode<T:Decodable<json::Decoder>>(s: &str) -> T {\n+    debug!(\"json decoding: %s\", s);\n     do io::with_str_reader(s) |rdr| {\n         let j = json::from_reader(rdr).unwrap();\n         let mut decoder = json::Decoder(j);\n@@ -230,11 +292,18 @@ impl Context {\n     pub fn new(db: RWArc<Database>,\n                lg: RWArc<Logger>,\n                cfg: Arc<json::Object>) -> Context {\n+        Context::new_with_freshness(db, lg, cfg, Arc::new(TreeMap::new()))\n+    }\n+\n+    pub fn new_with_freshness(db: RWArc<Database>,\n+               lg: RWArc<Logger>,\n+               cfg: Arc<json::Object>,\n+               freshness: Arc<FreshnessMap>) -> Context {\n         Context {\n             db: db,\n             logger: lg,\n             cfg: cfg,\n-            freshness: Arc::new(TreeMap::new())\n+            freshness: freshness\n         }\n     }\n \n@@ -249,6 +318,35 @@ impl Context {\n \n }\n \n+impl Exec {\n+    pub fn discover_input(&mut self, dependency_kind:&str,\n+       // Discovered input\n+       dependency_name: &str, dependency_val: &str) {\n+        debug!(\"Discovering input %s %s %s\", dependency_kind, dependency_name, dependency_val);\n+        self.discovered_inputs.insert_work_key(WorkKey::new(dependency_kind, dependency_name),\n+                                 dependency_val.to_owned());\n+    }\n+    pub fn discover_output(&mut self, dependency_kind:&str,\n+       // Discovered output\n+       dependency_name: &str, dependency_val: &str) {\n+        debug!(\"Discovering output %s %s %s\", dependency_kind, dependency_name, dependency_val);\n+        self.discovered_outputs.insert_work_key(WorkKey::new(dependency_kind, dependency_name),\n+                                 dependency_val.to_owned());\n+    }\n+\n+    // returns pairs of (kind, name)\n+    pub fn lookup_discovered_inputs(&self) -> ~[(~str, ~str)] {\n+        let mut rs = ~[];\n+        for (k, v) in self.discovered_inputs.iter() {\n+            for (k1, _) in v.iter() {\n+                rs.push((k1.clone(), k.clone()));\n+                }\n+        }\n+        rs\n+    }\n+\n+}\n+\n impl<'self> Prep<'self> {\n     fn new(ctxt: &'self Context, fn_name: &'self str) -> Prep<'self> {\n         Prep {\n@@ -257,18 +355,30 @@ impl<'self> Prep<'self> {\n             declared_inputs: WorkMap::new()\n         }\n     }\n+\n+    pub fn lookup_declared_inputs(&self) -> ~[~str] {\n+        let mut rs = ~[];\n+        for (_, v) in self.declared_inputs.iter() {\n+            for (inp, _) in v.iter() {\n+                rs.push(inp.clone());\n+            }\n+        }\n+        rs\n+    }\n }\n \n impl<'self> Prep<'self> {\n-    fn declare_input(&mut self, kind:&str, name:&str, val:&str) {\n-        self.declared_inputs.insert(WorkKey::new(kind, name),\n+    pub fn declare_input(&mut self, kind:&str, name:&str, val:&str) {\n+        debug!(\"Declaring input %s %s %s\", kind, name, val);\n+        self.declared_inputs.insert_work_key(WorkKey::new(kind, name),\n                                  val.to_owned());\n     }\n \n     fn is_fresh(&self, cat: &str, kind: &str,\n                 name: &str, val: &str) -> bool {\n         let k = kind.to_owned();\n         let f = self.ctxt.freshness.get().find(&k);\n+        debug!(\"freshness for: %s/%s/%s/%s\", cat, kind, name, val)\n         let fresh = match f {\n             None => fail!(\"missing freshness-function for '%s'\", kind),\n             Some(f) => (*f)(name, val)\n@@ -286,27 +396,31 @@ impl<'self> Prep<'self> {\n     }\n \n     fn all_fresh(&self, cat: &str, map: &WorkMap) -> bool {\n-        for (k, v) in map.iter() {\n-            if ! self.is_fresh(cat, k.kind, k.name, *v) {\n-                return false;\n+        for (k_name, kindmap) in map.iter() {\n+            for (k_kind, v) in kindmap.iter() {\n+               if ! self.is_fresh(cat, *k_kind, *k_name, *v) {\n+                  return false;\n             }\n+          }\n         }\n         return true;\n     }\n \n-    fn exec<T:Send +\n+    pub fn exec<T:Send +\n         Encodable<json::Encoder> +\n         Decodable<json::Decoder>>(\n-            &'self self, blk: ~fn(&Exec) -> T) -> T {\n+            &'self self, blk: ~fn(&mut Exec) -> T) -> T {\n         self.exec_work(blk).unwrap()\n     }\n \n     fn exec_work<T:Send +\n         Encodable<json::Encoder> +\n         Decodable<json::Decoder>>( // FIXME(#5121)\n-            &'self self, blk: ~fn(&Exec) -> T) -> Work<'self, T> {\n+            &'self self, blk: ~fn(&mut Exec) -> T) -> Work<'self, T> {\n         let mut bo = Some(blk);\n \n+        debug!(\"exec_work: looking up %s and %?\", self.fn_name,\n+               self.declared_inputs);\n         let cached = do self.ctxt.db.read |db| {\n             db.prepare(self.fn_name, &self.declared_inputs)\n         };\n@@ -316,21 +430,26 @@ impl<'self> Prep<'self> {\n             if self.all_fresh(\"declared input\",&self.declared_inputs) &&\n                self.all_fresh(\"discovered input\", disc_in) &&\n                self.all_fresh(\"discovered output\", disc_out) => {\n+                debug!(\"Cache hit!\");\n+                debug!(\"Trying to decode: %? / %? / %?\",\n+                       disc_in, disc_out, *res);\n                 Left(json_decode(*res))\n             }\n \n             _ => {\n+                debug!(\"Cache miss!\");\n                 let (port, chan) = oneshot();\n                 let blk = bo.take_unwrap();\n                 let chan = Cell::new(chan);\n \n+// What happens if the task fails?\n                 do task::spawn {\n-                    let exe = Exec {\n+                    let mut exe = Exec {\n                         discovered_inputs: WorkMap::new(),\n                         discovered_outputs: WorkMap::new(),\n                     };\n                     let chan = chan.take();\n-                    let v = blk(&exe);\n+                    let v = blk(&mut exe);\n                     chan.send((exe, v));\n                 }\n                 Right(port)\n@@ -371,9 +490,10 @@ impl<'self, T:Send +\n }\n \n \n-//#[test]\n+#[test]\n fn test() {\n     use std::io::WriterUtil;\n+    use std::run;\n \n     let pth = Path(\"foo.c\");\n     {"}]}