{"sha": "32167f52b018e319ac1e62a9713b771566bebe8e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMyMTY3ZjUyYjAxOGUzMTlhYzFlNjJhOTcxM2I3NzE1NjZiZWJlOGU=", "commit": {"author": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-05-30T18:36:30Z"}, "committer": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-06-15T19:41:41Z"}, "message": "Pull out an interface for the lexer.", "tree": {"sha": "91b684e00cdbd312cfa8be8d967fa572dd955969", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/91b684e00cdbd312cfa8be8d967fa572dd955969"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/32167f52b018e319ac1e62a9713b771566bebe8e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/32167f52b018e319ac1e62a9713b771566bebe8e", "html_url": "https://github.com/rust-lang/rust/commit/32167f52b018e319ac1e62a9713b771566bebe8e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/32167f52b018e319ac1e62a9713b771566bebe8e/comments", "author": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "committer": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "473b1ec0a09db8aee9fde61a55cbe5074422c91f", "url": "https://api.github.com/repos/rust-lang/rust/commits/473b1ec0a09db8aee9fde61a55cbe5074422c91f", "html_url": "https://github.com/rust-lang/rust/commit/473b1ec0a09db8aee9fde61a55cbe5074422c91f"}], "stats": {"total": 532, "additions": 285, "deletions": 247}, "files": [{"sha": "ce674f53662b3b8ddefb64d0e38536c22f529c1a", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=32167f52b018e319ac1e62a9713b771566bebe8e", "patch": "@@ -374,13 +374,10 @@ enum blk_sort {\n */\n \n #[auto_serialize]\n-type token_tree = spanned<token_tree_>;\n-\n-#[auto_serialize]\n-enum token_tree_ {\n+enum token_tree {\n     /* for macro invocations; parsing is the macro's job */\n-    tt_delim(token::token, [token_tree]),\n-    tt_flat(token::token)\n+    tt_delim([token_tree]),\n+    tt_flat(uint, token::token)\n }\n \n #[auto_serialize]"}, {"sha": "c08ad9927ad44d9ef0b16e35b4a667fc930913a9", "filename": "src/libsyntax/parse.rs", "status": "modified", "additions": 51, "deletions": 34, "changes": 85, "blob_url": "https://github.com/rust-lang/rust/blob/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse.rs?ref=32167f52b018e319ac1e62a9713b771566bebe8e", "patch": "@@ -4,6 +4,7 @@ import dvec::extensions;\n export parse_sess;\n export next_node_id;\n export new_parser_from_file;\n+export new_parser_etc_from_file;\n export new_parser_from_source_str;\n export parse_crate_from_file;\n export parse_crate_from_crate_file;\n@@ -17,7 +18,7 @@ import attr::parser_attr;\n import common::parser_common;\n import ast::node_id;\n import util::interner;\n-import lexer::reader;\n+import lexer::{string_reader_as_reader, reader, string_reader};\n \n type parse_sess = @{\n     cm: codemap::codemap,\n@@ -42,14 +43,15 @@ fn parse_crate_from_file(input: str, cfg: ast::crate_cfg, sess: parse_sess) ->\n \n fn parse_crate_from_crate_file(input: str, cfg: ast::crate_cfg,\n                                sess: parse_sess) -> @ast::crate {\n-    let p = new_parser_from_file(sess, cfg, input, parser::CRATE_FILE);\n+    let (p, rdr) = new_parser_etc_from_file(sess, cfg, input,\n+                                            parser::CRATE_FILE);\n     let lo = p.span.lo;\n-    let prefix = path::dirname(p.reader.filemap.name);\n+    let prefix = path::dirname(input);\n     let leading_attrs = p.parse_inner_attrs_and_next();\n     let { inner: crate_attrs, next: first_cdir_attr } = leading_attrs;\n     let cdirs = p.parse_crate_directives(token::EOF, first_cdir_attr);\n-    sess.chpos = p.reader.chpos;\n-    sess.byte_pos = sess.byte_pos + p.reader.pos;\n+    sess.chpos = rdr.chpos;\n+    sess.byte_pos = sess.byte_pos + rdr.pos;\n     let cx = @{sess: sess, cfg: /* FIXME: bad */ copy p.cfg};\n     let (companionmod, _) = path::splitext(path::basename(input));\n     let (m, attrs) = eval::eval_crate_directives_to_mod(\n@@ -65,41 +67,42 @@ fn parse_crate_from_crate_file(input: str, cfg: ast::crate_cfg,\n \n fn parse_crate_from_source_file(input: str, cfg: ast::crate_cfg,\n                                 sess: parse_sess) -> @ast::crate {\n-    let p = new_parser_from_file(sess, cfg, input, parser::SOURCE_FILE);\n+    let (p, rdr) = new_parser_etc_from_file(sess, cfg, input,\n+                                            parser::SOURCE_FILE);\n     let r = p.parse_crate_mod(cfg);\n-    sess.chpos = p.reader.chpos;\n-    sess.byte_pos = sess.byte_pos + p.reader.pos;\n+    sess.chpos = rdr.chpos;\n+    sess.byte_pos = sess.byte_pos + rdr.pos;\n     ret r;\n }\n \n fn parse_crate_from_source_str(name: str, source: @str, cfg: ast::crate_cfg,\n                                sess: parse_sess) -> @ast::crate {\n-    let p = new_parser_from_source_str(\n-        sess, cfg, name, codemap::fss_none, source);\n+    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name,\n+                                                  codemap::fss_none, source);\n     let r = p.parse_crate_mod(cfg);\n-    sess.chpos = p.reader.chpos;\n-    sess.byte_pos = sess.byte_pos + p.reader.pos;\n+    sess.chpos = rdr.chpos;\n+    sess.byte_pos = sess.byte_pos + rdr.pos;\n     ret r;\n }\n \n fn parse_expr_from_source_str(name: str, source: @str, cfg: ast::crate_cfg,\n                               sess: parse_sess) -> @ast::expr {\n-    let p = new_parser_from_source_str(\n-        sess, cfg, name, codemap::fss_none, source);\n+    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name,\n+                                                  codemap::fss_none, source);\n     let r = p.parse_expr();\n-    sess.chpos = p.reader.chpos;\n-    sess.byte_pos = sess.byte_pos + p.reader.pos;\n+    sess.chpos = rdr.chpos;\n+    sess.byte_pos = sess.byte_pos + rdr.pos;\n     ret r;\n }\n \n fn parse_item_from_source_str(name: str, source: @str, cfg: ast::crate_cfg,\n                               +attrs: [ast::attribute], vis: ast::visibility,\n                               sess: parse_sess) -> option<@ast::item> {\n-    let p = new_parser_from_source_str(\n-        sess, cfg, name, codemap::fss_none, source);\n+    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name,\n+                                                  codemap::fss_none, source);\n     let r = p.parse_item(attrs, vis);\n-    sess.chpos = p.reader.chpos;\n-    sess.byte_pos = sess.byte_pos + p.reader.pos;\n+    sess.chpos = rdr.chpos;\n+    sess.byte_pos = sess.byte_pos + rdr.pos;\n     ret r;\n }\n \n@@ -109,13 +112,14 @@ fn parse_from_source_str<T>(f: fn (p: parser) -> T,\n                             sess: parse_sess)\n     -> T\n {\n-    let p = new_parser_from_source_str(sess, cfg, name, ss, source);\n+    let (p, rdr) = new_parser_etc_from_source_str(sess, cfg, name, ss,\n+                                                  source);\n     let r = f(p);\n     if !p.reader.is_eof() {\n         p.reader.fatal(\"expected end-of-string\");\n     }\n-    sess.chpos = p.reader.chpos;\n-    sess.byte_pos = sess.byte_pos + p.reader.pos;\n+    sess.chpos = rdr.chpos;\n+    sess.byte_pos = sess.byte_pos + rdr.pos;\n     ret r;\n }\n \n@@ -127,9 +131,9 @@ fn next_node_id(sess: parse_sess) -> node_id {\n     ret rv;\n }\n \n-fn new_parser_from_source_str(sess: parse_sess, cfg: ast::crate_cfg,\n-                              +name: str, +ss: codemap::file_substr,\n-                              source: @str) -> parser {\n+fn new_parser_etc_from_source_str(sess: parse_sess, cfg: ast::crate_cfg,\n+                                  +name: str, +ss: codemap::file_substr,\n+                                  source: @str) -> (parser, string_reader) {\n     let ftype = parser::SOURCE_FILE;\n     let filemap = codemap::new_filemap_w_substr\n         (name, ss, source, sess.chpos, sess.byte_pos);\n@@ -138,14 +142,21 @@ fn new_parser_from_source_str(sess: parse_sess, cfg: ast::crate_cfg,\n         {|x|str::hash(*x)},\n         {|x,y|str::eq(*x, *y)}\n     );\n-    let rdr = lexer::new_reader(sess.span_diagnostic,\n-                                filemap, itr);\n-    ret parser(sess, cfg, rdr, ftype);\n+    let srdr = lexer::new_string_reader(sess.span_diagnostic, filemap, itr);\n+    ret (parser(sess, cfg, srdr as reader, ftype), srdr);\n }\n \n-fn new_parser_from_file(sess: parse_sess, cfg: ast::crate_cfg, +path: str,\n-                        ftype: parser::file_type) ->\n-   parser {\n+fn new_parser_from_source_str(sess: parse_sess, cfg: ast::crate_cfg,\n+                              +name: str, +ss: codemap::file_substr,\n+                              source: @str) -> parser {\n+    let (p, _) = new_parser_etc_from_source_str(sess, cfg, name, ss, source);\n+    ret p;\n+}\n+\n+\n+fn new_parser_etc_from_file(sess: parse_sess, cfg: ast::crate_cfg, +path: str,\n+                            ftype: parser::file_type) ->\n+   (parser, string_reader) {\n     let res = io::read_whole_file_str(path);\n     alt res {\n       result::ok(_) { /* Continue. */ }\n@@ -158,6 +169,12 @@ fn new_parser_from_file(sess: parse_sess, cfg: ast::crate_cfg, +path: str,\n         {|x|str::hash(*x)},\n         {|x,y|str::eq(*x, *y)}\n     );\n-    let rdr = lexer::new_reader(sess.span_diagnostic, filemap, itr);\n-    ret parser(sess, cfg, rdr, ftype);\n+    let srdr = lexer::new_string_reader(sess.span_diagnostic, filemap, itr);\n+    ret (parser(sess, cfg, srdr as reader, ftype), srdr);\n+}\n+\n+fn new_parser_from_file(sess: parse_sess, cfg: ast::crate_cfg, +path: str,\n+                        ftype: parser::file_type) -> parser {\n+    let (p, _) = new_parser_etc_from_file(sess, cfg, path, ftype);\n+    ret p;\n }"}, {"sha": "53a6238d57f022ead428b11d3545716d691d6f09", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 46, "deletions": 42, "changes": 88, "blob_url": "https://github.com/rust-lang/rust/blob/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=32167f52b018e319ac1e62a9713b771566bebe8e", "patch": "@@ -1,7 +1,8 @@\n import io::reader_util;\n import io::println;//XXXXXXXXxxx\n import util::interner;\n-import lexer::{ reader, new_reader, next_token, is_whitespace };\n+import lexer::{ string_reader, bump, is_eof, nextch, new_string_reader,\n+               is_whitespace, get_str_from, string_reader_as_reader };\n \n export cmnt;\n export lit;\n@@ -17,45 +18,46 @@ enum cmnt_style {\n \n type cmnt = {style: cmnt_style, lines: [str], pos: uint};\n \n-fn read_to_eol(rdr: reader) -> str {\n+fn read_to_eol(rdr: string_reader) -> str {\n     let mut val = \"\";\n-    while rdr.curr != '\\n' && !rdr.is_eof() {\n+    while rdr.curr != '\\n' && !is_eof(rdr) {\n         str::push_char(val, rdr.curr);\n-        rdr.bump();\n+        bump(rdr);\n     }\n-    if rdr.curr == '\\n' { rdr.bump(); }\n+    if rdr.curr == '\\n' { bump(rdr); }\n     ret val;\n }\n \n-fn read_one_line_comment(rdr: reader) -> str {\n+fn read_one_line_comment(rdr: string_reader) -> str {\n     let val = read_to_eol(rdr);\n     assert ((val[0] == '/' as u8 && val[1] == '/' as u8) ||\n             (val[0] == '#' as u8 && val[1] == '!' as u8));\n     ret val;\n }\n \n-fn consume_non_eol_whitespace(rdr: reader) {\n-    while is_whitespace(rdr.curr) && rdr.curr != '\\n' && !rdr.is_eof() {\n-        rdr.bump();\n+fn consume_non_eol_whitespace(rdr: string_reader) {\n+    while is_whitespace(rdr.curr) && rdr.curr != '\\n' && !is_eof(rdr) {\n+        bump(rdr);\n     }\n }\n \n-fn push_blank_line_comment(rdr: reader, &comments: [cmnt]) {\n+fn push_blank_line_comment(rdr: string_reader, &comments: [cmnt]) {\n     #debug(\">>> blank-line comment\");\n     let v: [str] = [];\n     comments += [{style: blank_line, lines: v, pos: rdr.chpos}];\n }\n \n-fn consume_whitespace_counting_blank_lines(rdr: reader, &comments: [cmnt]) {\n-    while is_whitespace(rdr.curr) && !rdr.is_eof() {\n+fn consume_whitespace_counting_blank_lines(rdr: string_reader,\n+                                           &comments: [cmnt]) {\n+    while is_whitespace(rdr.curr) && !is_eof(rdr) {\n         if rdr.col == 0u && rdr.curr == '\\n' {\n             push_blank_line_comment(rdr, comments);\n         }\n-        rdr.bump();\n+        bump(rdr);\n     }\n }\n \n-fn read_shebang_comment(rdr: reader, code_to_the_left: bool) -> cmnt {\n+fn read_shebang_comment(rdr: string_reader, code_to_the_left: bool) -> cmnt {\n     #debug(\">>> shebang comment\");\n     let p = rdr.chpos;\n     #debug(\"<<< shebang comment\");\n@@ -64,11 +66,11 @@ fn read_shebang_comment(rdr: reader, code_to_the_left: bool) -> cmnt {\n          pos: p};\n }\n \n-fn read_line_comments(rdr: reader, code_to_the_left: bool) -> cmnt {\n+fn read_line_comments(rdr: string_reader, code_to_the_left: bool) -> cmnt {\n     #debug(\">>> line comments\");\n     let p = rdr.chpos;\n     let mut lines: [str] = [];\n-    while rdr.curr == '/' && rdr.next() == '/' {\n+    while rdr.curr == '/' && nextch(rdr) == '/' {\n         let line = read_one_line_comment(rdr);\n         log(debug, line);\n         lines += [line];\n@@ -99,36 +101,36 @@ fn trim_whitespace_prefix_and_push_line(&lines: [str],\n     lines += [s1];\n }\n \n-fn read_block_comment(rdr: reader, code_to_the_left: bool) -> cmnt {\n+fn read_block_comment(rdr: string_reader, code_to_the_left: bool) -> cmnt {\n     #debug(\">>> block comment\");\n     let p = rdr.chpos;\n     let mut lines: [str] = [];\n     let mut col: uint = rdr.col;\n-    rdr.bump();\n-    rdr.bump();\n+    bump(rdr);\n+    bump(rdr);\n     let mut curr_line = \"/*\";\n     let mut level: int = 1;\n     while level > 0 {\n         #debug(\"=== block comment level %d\", level);\n-        if rdr.is_eof() { rdr.fatal(\"unterminated block comment\"); }\n+        if is_eof(rdr) {(rdr as reader).fatal(\"unterminated block comment\");}\n         if rdr.curr == '\\n' {\n             trim_whitespace_prefix_and_push_line(lines, curr_line, col);\n             curr_line = \"\";\n-            rdr.bump();\n+            bump(rdr);\n         } else {\n             str::push_char(curr_line, rdr.curr);\n-            if rdr.curr == '/' && rdr.next() == '*' {\n-                rdr.bump();\n-                rdr.bump();\n+            if rdr.curr == '/' && nextch(rdr) == '*' {\n+                bump(rdr);\n+                bump(rdr);\n                 curr_line += \"*\";\n                 level += 1;\n             } else {\n-                if rdr.curr == '*' && rdr.next() == '/' {\n-                    rdr.bump();\n-                    rdr.bump();\n+                if rdr.curr == '*' && nextch(rdr) == '/' {\n+                    bump(rdr);\n+                    bump(rdr);\n                     curr_line += \"/\";\n                     level -= 1;\n-                } else { rdr.bump(); }\n+                } else { bump(rdr); }\n             }\n         }\n     }\n@@ -137,26 +139,27 @@ fn read_block_comment(rdr: reader, code_to_the_left: bool) -> cmnt {\n     }\n     let mut style = if code_to_the_left { trailing } else { isolated };\n     consume_non_eol_whitespace(rdr);\n-    if !rdr.is_eof() && rdr.curr != '\\n' && vec::len(lines) == 1u {\n+    if !is_eof(rdr) && rdr.curr != '\\n' && vec::len(lines) == 1u {\n         style = mixed;\n     }\n     #debug(\"<<< block comment\");\n     ret {style: style, lines: lines, pos: p};\n }\n \n-fn peeking_at_comment(rdr: reader) -> bool {\n-    ret ((rdr.curr == '/' && rdr.next() == '/') ||\n-         (rdr.curr == '/' && rdr.next() == '*')) ||\n-        (rdr.curr == '#' && rdr.next() == '!');\n+fn peeking_at_comment(rdr: string_reader) -> bool {\n+    ret ((rdr.curr == '/' && nextch(rdr) == '/') ||\n+         (rdr.curr == '/' && nextch(rdr) == '*')) ||\n+         (rdr.curr == '#' && nextch(rdr) == '!');\n }\n \n-fn consume_comment(rdr: reader, code_to_the_left: bool, &comments: [cmnt]) {\n+fn consume_comment(rdr: string_reader, code_to_the_left: bool,\n+                   &comments: [cmnt]) {\n     #debug(\">>> consume comment\");\n-    if rdr.curr == '/' && rdr.next() == '/' {\n+    if rdr.curr == '/' && nextch(rdr) == '/' {\n         comments += [read_line_comments(rdr, code_to_the_left)];\n-    } else if rdr.curr == '/' && rdr.next() == '*' {\n+    } else if rdr.curr == '/' && nextch(rdr) == '*' {\n         comments += [read_block_comment(rdr, code_to_the_left)];\n-    } else if rdr.curr == '#' && rdr.next() == '!' {\n+    } else if rdr.curr == '#' && nextch(rdr) == '!' {\n         comments += [read_shebang_comment(rdr, code_to_the_left)];\n     } else { fail; }\n     #debug(\"<<< consume comment\");\n@@ -173,12 +176,12 @@ fn gather_comments_and_literals(span_diagnostic: diagnostic::span_handler,\n         {|x|str::hash(*x)},\n         {|x,y|str::eq(*x, *y)}\n     );\n-    let rdr = new_reader(span_diagnostic,\n-                         codemap::new_filemap(path, src, 0u, 0u), itr);\n+    let rdr = new_string_reader(span_diagnostic,\n+                                codemap::new_filemap(path, src, 0u, 0u), itr);\n     let mut comments: [cmnt] = [];\n     let mut literals: [lit] = [];\n     let mut first_read: bool = true;\n-    while !rdr.is_eof() {\n+    while !is_eof(rdr) {\n         loop {\n             let mut code_to_the_left = !first_read;\n             consume_non_eol_whitespace(rdr);\n@@ -192,9 +195,10 @@ fn gather_comments_and_literals(span_diagnostic: diagnostic::span_handler,\n             }\n             break;\n         }\n-        let tok = next_token(rdr);\n+        let bpos = rdr.pos;\n+        let tok = rdr.next_token();\n         if token::is_lit(tok.tok) {\n-            let s = rdr.get_str_from(tok.bpos);\n+            let s = get_str_from(rdr, bpos);\n             literals += [{lit: s, pos: tok.chpos}];\n             log(debug, \"tok lit: \" + s);\n         } else {"}, {"sha": "f8292be51fee5982bebc07bc58c709bda1e9c493", "filename": "src/libsyntax/parse/common.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=32167f52b018e319ac1e62a9713b771566bebe8e", "patch": "@@ -18,7 +18,7 @@ fn seq_sep_none() -> seq_sep {\n }\n \n fn token_to_str(reader: reader, ++token: token::token) -> str {\n-    token::to_str(*reader.interner, token)\n+    token::to_str(*reader.interner(), token)\n }\n \n // This should be done with traits, once traits work"}, {"sha": "5ca9b22524b19fa66008e803f3e75842eb8edcf1", "filename": "src/libsyntax/parse/eval.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Feval.rs?ref=32167f52b018e319ac1e62a9713b771566bebe8e", "patch": "@@ -64,11 +64,12 @@ fn parse_companion_mod(cx: ctx, prefix: str, suffix: option<str>)\n     #debug(\"looking for companion mod %s\", modpath);\n     if file_exists(modpath) {\n         #debug(\"found companion mod\");\n-        let p0 = new_parser_from_file(cx.sess, cx.cfg, modpath, SOURCE_FILE);\n+        let (p0, r0) = new_parser_etc_from_file(cx.sess, cx.cfg,\n+                                                modpath, SOURCE_FILE);\n         let inner_attrs = p0.parse_inner_attrs_and_next();\n         let m0 = p0.parse_mod_items(token::EOF, inner_attrs.next);\n-        cx.sess.chpos = p0.reader.chpos;\n-        cx.sess.byte_pos = cx.sess.byte_pos + p0.reader.pos;\n+        cx.sess.chpos = p0.reader.chpos();\n+        cx.sess.byte_pos = cx.sess.byte_pos + r0.pos;\n         ret (m0.view_items, m0.items, inner_attrs.inner);\n     } else {\n         ret ([], [], []);\n@@ -94,8 +95,8 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: str,\n             if path::path_is_absolute(*file_path) {\n                 *file_path\n             } else { prefix + path::path_sep() + *file_path };\n-        let p0 =\n-            new_parser_from_file(cx.sess, cx.cfg, full_path, SOURCE_FILE);\n+        let (p0, r0) =\n+            new_parser_etc_from_file(cx.sess, cx.cfg, full_path, SOURCE_FILE);\n         let inner_attrs = p0.parse_inner_attrs_and_next();\n         let mod_attrs = attrs + inner_attrs.inner;\n         let first_item_outer_attrs = inner_attrs.next;\n@@ -105,8 +106,8 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: str,\n                            /* FIXME: bad */ copy id,\n                            ast::item_mod(m0), ast::public, mod_attrs);\n         // Thread defids, chpos and byte_pos through the parsers\n-        cx.sess.chpos = p0.reader.chpos;\n-        cx.sess.byte_pos = cx.sess.byte_pos + p0.reader.pos;\n+        cx.sess.chpos = p0.reader.chpos();\n+        cx.sess.byte_pos = cx.sess.byte_pos + r0.pos;\n         items += [i];\n       }\n       ast::cdir_dir_mod(id, cdirs, attrs) {"}, {"sha": "e5be37dc4f0f84c53b7e74ddfa8539ae5651dabc", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 165, "deletions": 146, "changes": 311, "blob_url": "https://github.com/rust-lang/rust/blob/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=32167f52b018e319ac1e62a9713b771566bebe8e", "patch": "@@ -2,9 +2,19 @@ import util::interner;\n import util::interner::intern;\n import diagnostic;\n \n-export reader, new_reader, next_token, is_whitespace;\n+export reader, string_reader, new_string_reader, is_whitespace;\n+export nextch, is_eof, bump, get_str_from;\n+export string_reader_as_reader;\n+\n+iface reader {\n+    fn is_eof() -> bool;\n+    fn next_token() -> {tok: token::token, chpos: uint};\n+    fn fatal(str) -> !;\n+    fn chpos() -> uint;\n+    fn interner() -> @interner::interner<@str>;\n+}\n \n-type reader = @{\n+type string_reader = @{\n     span_diagnostic: diagnostic::span_handler,\n     src: @str,\n     mut col: uint,\n@@ -15,47 +25,64 @@ type reader = @{\n     interner: @interner::interner<@str>\n };\n \n-impl reader for reader {\n-    fn is_eof() -> bool { self.curr == -1 as char }\n-    fn get_str_from(start: uint) -> str unsafe {\n-        // I'm pretty skeptical about this subtraction. What if there's a\n-        // multi-byte character before the mark?\n-        ret str::slice(*self.src, start - 1u, self.pos - 1u);\n-    }\n-    fn next() -> char {\n-        if self.pos < (*self.src).len() {\n-            ret str::char_at(*self.src, self.pos);\n-        } else { ret -1 as char; }\n-    }\n-    fn bump() {\n-        if self.pos < (*self.src).len() {\n-            self.col += 1u;\n-            self.chpos += 1u;\n-            if self.curr == '\\n' {\n-                codemap::next_line(self.filemap, self.chpos, self.pos);\n-                self.col = 0u;\n-            }\n-            let next = str::char_range_at(*self.src, self.pos);\n-            self.pos = next.next;\n-            self.curr = next.ch;\n+impl string_reader_as_reader of reader for string_reader {\n+    fn is_eof() -> bool { is_eof(self) }\n+    fn next_token() -> {tok: token::token, chpos: uint} {\n+        consume_whitespace_and_comments(self);\n+        let start_chpos = self.chpos;\n+        let tok = if is_eof(self) {\n+            token::EOF\n         } else {\n-            if (self.curr != -1 as char) {\n-                self.col += 1u;\n-                self.chpos += 1u;\n-                self.curr = -1 as char;\n-            }\n-        }\n+            next_token_inner(self)\n+        };\n+        ret {tok: tok, chpos: start_chpos};\n     }\n     fn fatal(m: str) -> ! {\n         self.span_diagnostic.span_fatal(\n             ast_util::mk_sp(self.chpos, self.chpos),\n             m)\n     }\n+    fn chpos() -> uint { self.chpos }\n+    fn interner() -> @interner::interner<@str> { self.interner }\n }\n \n-fn new_reader(span_diagnostic: diagnostic::span_handler,\n-              filemap: codemap::filemap,\n-              itr: @interner::interner<@str>) -> reader {\n+fn get_str_from(rdr: string_reader, start: uint) -> str unsafe {\n+    // I'm pretty skeptical about this subtraction. What if there's a\n+    // multi-byte character before the mark?\n+    ret str::slice(*rdr.src, start - 1u, rdr.pos - 1u);\n+}\n+\n+fn bump(rdr: string_reader) {\n+    if rdr.pos < (*rdr.src).len() {\n+        rdr.col += 1u;\n+        rdr.chpos += 1u;\n+        if rdr.curr == '\\n' {\n+            codemap::next_line(rdr.filemap, rdr.chpos, rdr.pos);\n+            rdr.col = 0u;\n+        }\n+        let next = str::char_range_at(*rdr.src, rdr.pos);\n+        rdr.pos = next.next;\n+        rdr.curr = next.ch;\n+    } else {\n+        if (rdr.curr != -1 as char) {\n+            rdr.col += 1u;\n+            rdr.chpos += 1u;\n+            rdr.curr = -1 as char;\n+        }\n+    }\n+}\n+fn is_eof(rdr: string_reader) -> bool {\n+    rdr.curr == -1 as char\n+}\n+fn nextch(rdr: string_reader) -> char {\n+    if rdr.pos < (*rdr.src).len() {\n+        ret str::char_at(*rdr.src, rdr.pos);\n+    } else { ret -1 as char; }\n+}\n+\n+fn new_string_reader(span_diagnostic: diagnostic::span_handler,\n+                     filemap: codemap::filemap,\n+                     itr: @interner::interner<@str>) -> string_reader {\n     let r = @{span_diagnostic: span_diagnostic, src: filemap.src,\n               mut col: 0u, mut pos: 0u, mut curr: -1 as char,\n               mut chpos: filemap.start_pos.ch,\n@@ -102,67 +129,67 @@ fn is_hex_digit(c: char) -> bool {\n \n fn is_bin_digit(c: char) -> bool { ret c == '0' || c == '1'; }\n \n-fn consume_whitespace_and_comments(rdr: reader) {\n-    while is_whitespace(rdr.curr) { rdr.bump(); }\n+fn consume_whitespace_and_comments(rdr: string_reader) {\n+    while is_whitespace(rdr.curr) { bump(rdr); }\n     ret consume_any_line_comment(rdr);\n }\n \n-fn consume_any_line_comment(rdr: reader) {\n+fn consume_any_line_comment(rdr: string_reader) {\n     if rdr.curr == '/' {\n-        alt rdr.next() {\n+        alt nextch(rdr) {\n           '/' {\n-            while rdr.curr != '\\n' && !rdr.is_eof() { rdr.bump(); }\n+            while rdr.curr != '\\n' && !is_eof(rdr) { bump(rdr); }\n             // Restart whitespace munch.\n \n             ret consume_whitespace_and_comments(rdr);\n           }\n-          '*' { rdr.bump(); rdr.bump(); ret consume_block_comment(rdr); }\n+          '*' { bump(rdr); bump(rdr); ret consume_block_comment(rdr); }\n           _ { ret; }\n         }\n     } else if rdr.curr == '#' {\n-        if rdr.next() == '!' {\n+        if nextch(rdr) == '!' {\n             let cmap = codemap::new_codemap();\n             (*cmap).files.push(rdr.filemap);\n             let loc = codemap::lookup_char_pos_adj(cmap, rdr.chpos);\n             if loc.line == 1u && loc.col == 0u {\n-                while rdr.curr != '\\n' && !rdr.is_eof() { rdr.bump(); }\n+                while rdr.curr != '\\n' && !is_eof(rdr) { bump(rdr); }\n                 ret consume_whitespace_and_comments(rdr);\n             }\n         }\n     }\n }\n \n-fn consume_block_comment(rdr: reader) {\n+fn consume_block_comment(rdr: string_reader) {\n     let mut level: int = 1;\n     while level > 0 {\n-        if rdr.is_eof() { rdr.fatal(\"unterminated block comment\"); }\n-        if rdr.curr == '/' && rdr.next() == '*' {\n-            rdr.bump();\n-            rdr.bump();\n+        if is_eof(rdr) { rdr.fatal(\"unterminated block comment\"); }\n+        if rdr.curr == '/' && nextch(rdr) == '*' {\n+            bump(rdr);\n+            bump(rdr);\n             level += 1;\n         } else {\n-            if rdr.curr == '*' && rdr.next() == '/' {\n-                rdr.bump();\n-                rdr.bump();\n+            if rdr.curr == '*' && nextch(rdr) == '/' {\n+                bump(rdr);\n+                bump(rdr);\n                 level -= 1;\n-            } else { rdr.bump(); }\n+            } else { bump(rdr); }\n         }\n     }\n     // restart whitespace munch.\n \n     ret consume_whitespace_and_comments(rdr);\n }\n \n-fn scan_exponent(rdr: reader) -> option<str> {\n+fn scan_exponent(rdr: string_reader) -> option<str> {\n     let mut c = rdr.curr;\n     let mut rslt = \"\";\n     if c == 'e' || c == 'E' {\n         str::push_char(rslt, c);\n-        rdr.bump();\n+        bump(rdr);\n         c = rdr.curr;\n         if c == '-' || c == '+' {\n             str::push_char(rslt, c);\n-            rdr.bump();\n+            bump(rdr);\n         }\n         let exponent = scan_digits(rdr, 10u);\n         if str::len(exponent) > 0u {\n@@ -171,62 +198,62 @@ fn scan_exponent(rdr: reader) -> option<str> {\n     } else { ret none::<str>; }\n }\n \n-fn scan_digits(rdr: reader, radix: uint) -> str {\n+fn scan_digits(rdr: string_reader, radix: uint) -> str {\n     let mut rslt = \"\";\n     loop {\n         let c = rdr.curr;\n-        if c == '_' { rdr.bump(); cont; }\n+        if c == '_' { bump(rdr); cont; }\n         alt char::to_digit(c, radix) {\n           some(d) {\n             str::push_char(rslt, c);\n-            rdr.bump();\n+            bump(rdr);\n           }\n           _ { ret rslt; }\n         }\n     };\n }\n \n-fn scan_number(c: char, rdr: reader) -> token::token {\n-    let mut num_str, base = 10u, c = c, n = rdr.next();\n+fn scan_number(c: char, rdr: string_reader) -> token::token {\n+    let mut num_str, base = 10u, c = c, n = nextch(rdr);\n     if c == '0' && n == 'x' {\n-        rdr.bump();\n-        rdr.bump();\n+        bump(rdr);\n+        bump(rdr);\n         base = 16u;\n     } else if c == '0' && n == 'b' {\n-        rdr.bump();\n-        rdr.bump();\n+        bump(rdr);\n+        bump(rdr);\n         base = 2u;\n     }\n     num_str = scan_digits(rdr, base);\n     c = rdr.curr;\n-    rdr.next();\n+    nextch(rdr);\n     if c == 'u' || c == 'i' {\n         let signed = c == 'i';\n         let mut tp = {\n             if signed { either::left(ast::ty_i) }\n             else { either::right(ast::ty_u) }\n         };\n-        rdr.bump();\n+        bump(rdr);\n         c = rdr.curr;\n         if c == '8' {\n-            rdr.bump();\n+            bump(rdr);\n             tp = if signed { either::left(ast::ty_i8) }\n                       else { either::right(ast::ty_u8) };\n         }\n-        n = rdr.next();\n+        n = nextch(rdr);\n         if c == '1' && n == '6' {\n-            rdr.bump();\n-            rdr.bump();\n+            bump(rdr);\n+            bump(rdr);\n             tp = if signed { either::left(ast::ty_i16) }\n                       else { either::right(ast::ty_u16) };\n         } else if c == '3' && n == '2' {\n-            rdr.bump();\n-            rdr.bump();\n+            bump(rdr);\n+            bump(rdr);\n             tp = if signed { either::left(ast::ty_i32) }\n                       else { either::right(ast::ty_u32) };\n         } else if c == '6' && n == '4' {\n-            rdr.bump();\n-            rdr.bump();\n+            bump(rdr);\n+            bump(rdr);\n             tp = if signed { either::left(ast::ty_i64) }\n                       else { either::right(ast::ty_u64) };\n         }\n@@ -240,9 +267,9 @@ fn scan_number(c: char, rdr: reader) -> token::token {\n         }\n     }\n     let mut is_float = false;\n-    if rdr.curr == '.' && !(is_alpha(rdr.next()) || rdr.next() == '_') {\n+    if rdr.curr == '.' && !(is_alpha(nextch(rdr)) || nextch(rdr) == '_') {\n         is_float = true;\n-        rdr.bump();\n+        bump(rdr);\n         let dec_part = scan_digits(rdr, 10u);\n         num_str += \".\" + dec_part;\n     }\n@@ -254,17 +281,17 @@ fn scan_number(c: char, rdr: reader) -> token::token {\n       none {}\n     }\n     if rdr.curr == 'f' {\n-        rdr.bump();\n+        bump(rdr);\n         c = rdr.curr;\n-        n = rdr.next();\n+        n = nextch(rdr);\n         if c == '3' && n == '2' {\n-            rdr.bump();\n-            rdr.bump();\n+            bump(rdr);\n+            bump(rdr);\n             ret token::LIT_FLOAT(intern(*rdr.interner, @num_str),\n                                  ast::ty_f32);\n         } else if c == '6' && n == '4' {\n-            rdr.bump();\n-            rdr.bump();\n+            bump(rdr);\n+            bump(rdr);\n             ret token::LIT_FLOAT(intern(*rdr.interner, @num_str),\n                                  ast::ty_f64);\n             /* FIXME: if this is out of range for either a 32-bit or\n@@ -289,11 +316,11 @@ fn scan_number(c: char, rdr: reader) -> token::token {\n     }\n }\n \n-fn scan_numeric_escape(rdr: reader, n_hex_digits: uint) -> char {\n+fn scan_numeric_escape(rdr: string_reader, n_hex_digits: uint) -> char {\n     let mut accum_int = 0, i = n_hex_digits;\n     while i != 0u {\n         let n = rdr.curr;\n-        rdr.bump();\n+        bump(rdr);\n         if !is_hex_digit(n) {\n             rdr.fatal(#fmt[\"illegal numeric character escape: %d\", n as int]);\n         }\n@@ -304,15 +331,7 @@ fn scan_numeric_escape(rdr: reader, n_hex_digits: uint) -> char {\n     ret accum_int as char;\n }\n \n-fn next_token(rdr: reader) -> {tok: token::token, chpos: uint, bpos: uint} {\n-    consume_whitespace_and_comments(rdr);\n-    let start_chpos = rdr.chpos;\n-    let start_bpos = rdr.pos;\n-    let tok = if rdr.is_eof() { token::EOF } else { next_token_inner(rdr) };\n-    ret {tok: tok, chpos: start_chpos, bpos: start_bpos};\n-}\n-\n-fn next_token_inner(rdr: reader) -> token::token {\n+fn next_token_inner(rdr: string_reader) -> token::token {\n     let mut accum_str = \"\";\n     let mut c = rdr.curr;\n     if (c >= 'a' && c <= 'z')\n@@ -325,11 +344,11 @@ fn next_token_inner(rdr: reader) -> token::token {\n             || c == '_'\n             || (c > 'z' && char::is_XID_continue(c)) {\n             str::push_char(accum_str, c);\n-            rdr.bump();\n+            bump(rdr);\n             c = rdr.curr;\n         }\n         if str::eq(accum_str, \"_\") { ret token::UNDERSCORE; }\n-        let is_mod_name = c == ':' && rdr.next() == ':';\n+        let is_mod_name = c == ':' && nextch(rdr) == ':';\n \n         // FIXME: perform NFKC normalization here. (Issue #2253)\n         ret token::IDENT(interner::intern(*rdr.interner,\n@@ -338,10 +357,10 @@ fn next_token_inner(rdr: reader) -> token::token {\n     if is_dec_digit(c) {\n         ret scan_number(c, rdr);\n     }\n-    fn binop(rdr: reader, op: token::binop) -> token::token {\n-        rdr.bump();\n+    fn binop(rdr: string_reader, op: token::binop) -> token::token {\n+        bump(rdr);\n         if rdr.curr == '=' {\n-            rdr.bump();\n+            bump(rdr);\n             ret token::BINOPEQ(op);\n         } else { ret token::BINOP(op); }\n     }\n@@ -352,90 +371,90 @@ fn next_token_inner(rdr: reader) -> token::token {\n \n \n       // One-byte tokens.\n-      ';' { rdr.bump(); ret token::SEMI; }\n-      ',' { rdr.bump(); ret token::COMMA; }\n+      ';' { bump(rdr); ret token::SEMI; }\n+      ',' { bump(rdr); ret token::COMMA; }\n       '.' {\n-        rdr.bump();\n-        if rdr.curr == '.' && rdr.next() == '.' {\n-            rdr.bump();\n-            rdr.bump();\n+        bump(rdr);\n+        if rdr.curr == '.' && nextch(rdr) == '.' {\n+            bump(rdr);\n+            bump(rdr);\n             ret token::ELLIPSIS;\n         }\n         ret token::DOT;\n       }\n-      '(' { rdr.bump(); ret token::LPAREN; }\n-      ')' { rdr.bump(); ret token::RPAREN; }\n-      '{' { rdr.bump(); ret token::LBRACE; }\n-      '}' { rdr.bump(); ret token::RBRACE; }\n-      '[' { rdr.bump(); ret token::LBRACKET; }\n-      ']' { rdr.bump(); ret token::RBRACKET; }\n-      '@' { rdr.bump(); ret token::AT; }\n-      '#' { rdr.bump(); ret token::POUND; }\n-      '~' { rdr.bump(); ret token::TILDE; }\n+      '(' { bump(rdr); ret token::LPAREN; }\n+      ')' { bump(rdr); ret token::RPAREN; }\n+      '{' { bump(rdr); ret token::LBRACE; }\n+      '}' { bump(rdr); ret token::RBRACE; }\n+      '[' { bump(rdr); ret token::LBRACKET; }\n+      ']' { bump(rdr); ret token::RBRACKET; }\n+      '@' { bump(rdr); ret token::AT; }\n+      '#' { bump(rdr); ret token::POUND; }\n+      '~' { bump(rdr); ret token::TILDE; }\n       ':' {\n-        rdr.bump();\n+        bump(rdr);\n         if rdr.curr == ':' {\n-            rdr.bump();\n+            bump(rdr);\n             ret token::MOD_SEP;\n         } else { ret token::COLON; }\n       }\n \n-      '$' { rdr.bump(); ret token::DOLLAR; }\n+      '$' { bump(rdr); ret token::DOLLAR; }\n \n \n \n \n \n       // Multi-byte tokens.\n       '=' {\n-        rdr.bump();\n+        bump(rdr);\n         if rdr.curr == '=' {\n-            rdr.bump();\n+            bump(rdr);\n             ret token::EQEQ;\n         } else if rdr.curr == '>' {\n-            rdr.bump();\n+            bump(rdr);\n             ret token::FAT_ARROW;\n         } else {\n             ret token::EQ;\n         }\n       }\n       '!' {\n-        rdr.bump();\n+        bump(rdr);\n         if rdr.curr == '=' {\n-            rdr.bump();\n+            bump(rdr);\n             ret token::NE;\n         } else { ret token::NOT; }\n       }\n       '<' {\n-        rdr.bump();\n+        bump(rdr);\n         alt rdr.curr {\n-          '=' { rdr.bump(); ret token::LE; }\n+          '=' { bump(rdr); ret token::LE; }\n           '<' { ret binop(rdr, token::SHL); }\n           '-' {\n-            rdr.bump();\n+            bump(rdr);\n             alt rdr.curr {\n-              '>' { rdr.bump(); ret token::DARROW; }\n+              '>' { bump(rdr); ret token::DARROW; }\n               _ { ret token::LARROW; }\n             }\n           }\n           _ { ret token::LT; }\n         }\n       }\n       '>' {\n-        rdr.bump();\n+        bump(rdr);\n         alt rdr.curr {\n-          '=' { rdr.bump(); ret token::GE; }\n+          '=' { bump(rdr); ret token::GE; }\n           '>' { ret binop(rdr, token::SHR); }\n           _ { ret token::GT; }\n         }\n       }\n       '\\'' {\n-        rdr.bump();\n+        bump(rdr);\n         let mut c2 = rdr.curr;\n-        rdr.bump();\n+        bump(rdr);\n         if c2 == '\\\\' {\n             let escaped = rdr.curr;\n-            rdr.bump();\n+            bump(rdr);\n             alt escaped {\n               'n' { c2 = '\\n'; }\n               'r' { c2 = '\\r'; }\n@@ -454,24 +473,24 @@ fn next_token_inner(rdr: reader) -> token::token {\n         if rdr.curr != '\\'' {\n             rdr.fatal(\"unterminated character constant\");\n         }\n-        rdr.bump(); // advance curr past token\n+        bump(rdr); // advance curr past token\n         ret token::LIT_INT(c2 as i64, ast::ty_char);\n       }\n       '\"' {\n         let n = rdr.chpos;\n-        rdr.bump();\n+        bump(rdr);\n         while rdr.curr != '\"' {\n-            if rdr.is_eof() {\n+            if is_eof(rdr) {\n                 rdr.fatal(#fmt[\"unterminated double quote string: %s\",\n-                             rdr.get_str_from(n)]);\n+                               get_str_from(rdr, n)]);\n             }\n \n             let ch = rdr.curr;\n-            rdr.bump();\n+            bump(rdr);\n             alt ch {\n               '\\\\' {\n                 let escaped = rdr.curr;\n-                rdr.bump();\n+                bump(rdr);\n                 alt escaped {\n                   'n' { str::push_char(accum_str, '\\n'); }\n                   'r' { str::push_char(accum_str, '\\r'); }\n@@ -496,27 +515,27 @@ fn next_token_inner(rdr: reader) -> token::token {\n               _ { str::push_char(accum_str, ch); }\n             }\n         }\n-        rdr.bump();\n+        bump(rdr);\n         ret token::LIT_STR(interner::intern(*rdr.interner,\n                                             @accum_str));\n       }\n       '-' {\n-        if rdr.next() == '>' {\n-            rdr.bump();\n-            rdr.bump();\n+        if nextch(rdr) == '>' {\n+            bump(rdr);\n+            bump(rdr);\n             ret token::RARROW;\n         } else { ret binop(rdr, token::MINUS); }\n       }\n       '&' {\n-        if rdr.next() == '&' {\n-            rdr.bump();\n-            rdr.bump();\n+        if nextch(rdr) == '&' {\n+            bump(rdr);\n+            bump(rdr);\n             ret token::ANDAND;\n         } else { ret binop(rdr, token::AND); }\n       }\n       '|' {\n-        alt rdr.next() {\n-          '|' { rdr.bump(); rdr.bump(); ret token::OROR; }\n+        alt nextch(rdr) {\n+          '|' { bump(rdr); bump(rdr); ret token::OROR; }\n           _ { ret binop(rdr, token::OR); }\n         }\n       }\n@@ -529,8 +548,8 @@ fn next_token_inner(rdr: reader) -> token::token {\n     }\n }\n \n-fn consume_whitespace(rdr: reader) {\n-    while is_whitespace(rdr.curr) && !rdr.is_eof() { rdr.bump(); }\n+fn consume_whitespace(rdr: string_reader) {\n+    while is_whitespace(rdr.curr) && !is_eof(rdr) { bump(rdr); }\n }\n \n "}, {"sha": "1bf407f31c0949892239e0f9bd2841cac2073a3d", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/32167f52b018e319ac1e62a9713b771566bebe8e/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=32167f52b018e319ac1e62a9713b771566bebe8e", "patch": "@@ -71,10 +71,11 @@ class parser {\n     let keywords: hashmap<str, ()>;\n     let restricted_keywords: hashmap<str, ()>;\n \n-    new(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader,\n-        ftype: file_type) {\n-        let tok0 = lexer::next_token(rdr);\n-        let span0 = ast_util::mk_sp(tok0.chpos, rdr.chpos);\n+    new(sess: parse_sess, cfg: ast::crate_cfg, +rdr: reader, ftype: file_type)\n+    {\n+        self.reader <- rdr;\n+        let tok0 = self.reader.next_token();\n+        let span0 = ast_util::mk_sp(tok0.chpos, self.reader.chpos());\n         self.sess = sess;\n         self.cfg = cfg;\n         self.file_type = ftype;\n@@ -90,7 +91,6 @@ class parser {\n         self.buffer_start = 0;\n         self.buffer_end = 0;\n         self.restriction = UNRESTRICTED;\n-        self.reader = rdr;\n         self.keywords = token::keyword_table();\n         self.restricted_keywords = token::restricted_keyword_table();\n     }\n@@ -101,9 +101,9 @@ class parser {\n     fn bump() {\n         self.last_span = self.span;\n         if self.buffer_start == self.buffer_end {\n-            let next = lexer::next_token(self.reader);\n+            let next = self.reader.next_token();\n             self.token = next.tok;\n-            self.span = mk_sp(next.chpos, self.reader.chpos);\n+            self.span = mk_sp(next.chpos, self.reader.chpos());\n         } else {\n             let next = self.buffer[self.buffer_start];\n             self.buffer_start = (self.buffer_start + 1) & 3;\n@@ -124,8 +124,8 @@ class parser {\n     fn look_ahead(distance: uint) -> token::token {\n         let dist = distance as int;\n         while self.buffer_length() < dist {\n-            let next = lexer::next_token(self.reader);\n-            let sp = mk_sp(next.chpos, self.reader.chpos);\n+            let next = self.reader.next_token();\n+            let sp = mk_sp(next.chpos, self.reader.chpos());\n             self.buffer[self.buffer_end] = {tok: next.tok, span: sp};\n             self.buffer_end = (self.buffer_end + 1) & 3;\n         }\n@@ -144,7 +144,7 @@ class parser {\n         self.sess.span_diagnostic.span_warn(copy self.span, m)\n     }\n     fn get_str(i: token::str_num) -> @str {\n-        interner::get(*self.reader.interner, i)\n+        interner::get(*self.reader.interner(), i)\n     }\n     fn get_id() -> node_id { next_node_id(self.sess) }\n \n@@ -1060,7 +1060,7 @@ class parser {\n \n     fn parse_token_tree() -> token_tree {\n         #[doc=\"what's the opposite delimiter?\"]\n-        fn flip(t: token::token) -> token::token {\n+        fn flip(&t: token::token) -> token::token {\n             alt t {\n               token::LPAREN { token::RPAREN }\n               token::LBRACE { token::RBRACE }"}]}