{"sha": "de13b20b2706607c9c130e16d5fb2b83241a94c1", "node_id": "MDY6Q29tbWl0NzI0NzEyOmRlMTNiMjBiMjcwNjYwN2M5YzEzMGUxNmQ1ZmIyYjgzMjQxYTk0YzE=", "commit": {"author": {"name": "Caleb Zulawski", "email": "caleb.zulawski@gmail.com", "date": "2021-08-07T04:30:24Z"}, "committer": {"name": "Caleb Zulawski", "email": "caleb.zulawski@gmail.com", "date": "2021-08-07T04:30:24Z"}, "message": "Convert all masks to a single type", "tree": {"sha": "596fd3a9906a26c103c6b4bf304844ba6909009b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/596fd3a9906a26c103c6b4bf304844ba6909009b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/de13b20b2706607c9c130e16d5fb2b83241a94c1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/de13b20b2706607c9c130e16d5fb2b83241a94c1", "html_url": "https://github.com/rust-lang/rust/commit/de13b20b2706607c9c130e16d5fb2b83241a94c1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/de13b20b2706607c9c130e16d5fb2b83241a94c1/comments", "author": {"login": "calebzulawski", "id": 563826, "node_id": "MDQ6VXNlcjU2MzgyNg==", "avatar_url": "https://avatars.githubusercontent.com/u/563826?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calebzulawski", "html_url": "https://github.com/calebzulawski", "followers_url": "https://api.github.com/users/calebzulawski/followers", "following_url": "https://api.github.com/users/calebzulawski/following{/other_user}", "gists_url": "https://api.github.com/users/calebzulawski/gists{/gist_id}", "starred_url": "https://api.github.com/users/calebzulawski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calebzulawski/subscriptions", "organizations_url": "https://api.github.com/users/calebzulawski/orgs", "repos_url": "https://api.github.com/users/calebzulawski/repos", "events_url": "https://api.github.com/users/calebzulawski/events{/privacy}", "received_events_url": "https://api.github.com/users/calebzulawski/received_events", "type": "User", "site_admin": false}, "committer": {"login": "calebzulawski", "id": 563826, "node_id": "MDQ6VXNlcjU2MzgyNg==", "avatar_url": "https://avatars.githubusercontent.com/u/563826?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calebzulawski", "html_url": "https://github.com/calebzulawski", "followers_url": "https://api.github.com/users/calebzulawski/followers", "following_url": "https://api.github.com/users/calebzulawski/following{/other_user}", "gists_url": "https://api.github.com/users/calebzulawski/gists{/gist_id}", "starred_url": "https://api.github.com/users/calebzulawski/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calebzulawski/subscriptions", "organizations_url": "https://api.github.com/users/calebzulawski/orgs", "repos_url": "https://api.github.com/users/calebzulawski/repos", "events_url": "https://api.github.com/users/calebzulawski/events{/privacy}", "received_events_url": "https://api.github.com/users/calebzulawski/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ddc67e3bf22fe1e79604e5fa0ee2836c87e20b20", "url": "https://api.github.com/repos/rust-lang/rust/commits/ddc67e3bf22fe1e79604e5fa0ee2836c87e20b20", "html_url": "https://github.com/rust-lang/rust/commit/ddc67e3bf22fe1e79604e5fa0ee2836c87e20b20"}], "stats": {"total": 1382, "additions": 677, "deletions": 705}, "files": [{"sha": "d4a0cff4e2380a7f4b3c11ba7edcd99788be7bcb", "filename": "crates/core_simd/src/masks.rs", "status": "modified", "additions": 405, "deletions": 364, "changes": 769, "blob_url": "https://github.com/rust-lang/rust/blob/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Fmasks.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Fmasks.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fsrc%2Fmasks.rs?ref=de13b20b2706607c9c130e16d5fb2b83241a94c1", "patch": "@@ -12,420 +12,461 @@\n )]\n mod mask_impl;\n \n-use crate::{SimdI16, SimdI32, SimdI64, SimdI8, SimdIsize};\n-\n-macro_rules! define_opaque_mask {\n-    {\n-        $(#[$attr:meta])*\n-        struct $name:ident<const $lanes:ident: usize>($inner_ty:ty);\n-        @bits $bits_ty:ident\n-    } => {\n-        $(#[$attr])*\n-        #[allow(non_camel_case_types)]\n-        pub struct $name<const LANES: usize>($inner_ty)\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount;\n-\n-        impl_opaque_mask_reductions! { $name, $bits_ty }\n-\n-        impl<const LANES: usize> $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            /// Construct a mask by setting all lanes to the given value.\n-            pub fn splat(value: bool) -> Self {\n-                Self(<$inner_ty>::splat(value))\n-            }\n+use crate::{LaneCount, Simd, SimdElement, SupportedLaneCount};\n \n-            /// Converts an array to a SIMD vector.\n-            pub fn from_array(array: [bool; LANES]) -> Self {\n-                let mut vector = Self::splat(false);\n-                let mut i = 0;\n-                while i < $lanes {\n-                    vector.set(i, array[i]);\n-                    i += 1;\n-                }\n-                vector\n-            }\n+/// Marker trait for types that may be used as SIMD mask elements.\n+pub unsafe trait MaskElement: SimdElement {\n+    #[doc(hidden)]\n+    fn valid<const LANES: usize>(values: Simd<Self, LANES>) -> bool\n+    where\n+        LaneCount<LANES>: SupportedLaneCount;\n \n-            /// Converts a SIMD vector to an array.\n-            pub fn to_array(self) -> [bool; LANES] {\n-                let mut array = [false; LANES];\n-                let mut i = 0;\n-                while i < $lanes {\n-                    array[i] = self.test(i);\n-                    i += 1;\n-                }\n-                array\n-            }\n+    #[doc(hidden)]\n+    fn eq(self, other: Self) -> bool;\n \n-            /// Converts a vector of integers to a mask, where 0 represents `false` and -1\n-            /// represents `true`.\n-            ///\n-            /// # Safety\n-            /// All lanes must be either 0 or -1.\n-            #[inline]\n-            pub unsafe fn from_int_unchecked(value: $bits_ty<LANES>) -> Self {\n-                Self(<$inner_ty>::from_int_unchecked(value))\n-            }\n+    #[doc(hidden)]\n+    const TRUE: Self;\n \n-            /// Converts a vector of integers to a mask, where 0 represents `false` and -1\n-            /// represents `true`.\n-            ///\n-            /// # Panics\n-            /// Panics if any lane is not 0 or -1.\n-            #[inline]\n-            pub fn from_int(value: $bits_ty<LANES>) -> Self {\n-                assert!(\n-                    (value.lanes_eq($bits_ty::splat(0)) | value.lanes_eq($bits_ty::splat(-1))).all(),\n-                    \"all values must be either 0 or -1\",\n-                );\n-                unsafe { Self::from_int_unchecked(value) }\n-            }\n+    #[doc(hidden)]\n+    const FALSE: Self;\n+}\n \n-            /// Converts the mask to a vector of integers, where 0 represents `false` and -1\n-            /// represents `true`.\n-            #[inline]\n-            pub fn to_int(self) -> $bits_ty<LANES> {\n-                self.0.to_int()\n+macro_rules! impl_element {\n+    { $ty:ty } => {\n+        unsafe impl MaskElement for $ty {\n+            fn valid<const LANES: usize>(value: Simd<Self, LANES>) -> bool\n+            where\n+                LaneCount<LANES>: SupportedLaneCount,\n+            {\n+                (value.lanes_eq(Simd::splat(0)) | value.lanes_eq(Simd::splat(-1))).all()\n             }\n \n-            /// Tests the value of the specified lane.\n-            ///\n-            /// # Safety\n-            /// `lane` must be less than `LANES`.\n-            #[inline]\n-            pub unsafe fn test_unchecked(&self, lane: usize) -> bool {\n-                self.0.test_unchecked(lane)\n-            }\n+            fn eq(self, other: Self) -> bool { self == other }\n \n-            /// Tests the value of the specified lane.\n-            ///\n-            /// # Panics\n-            /// Panics if `lane` is greater than or equal to the number of lanes in the vector.\n-            #[inline]\n-            pub fn test(&self, lane: usize) -> bool {\n-                assert!(lane < LANES, \"lane index out of range\");\n-                unsafe { self.test_unchecked(lane) }\n-            }\n+            const TRUE: Self = -1;\n+            const FALSE: Self = 0;\n+        }\n+    }\n+}\n \n-            /// Sets the value of the specified lane.\n-            ///\n-            /// # Safety\n-            /// `lane` must be less than `LANES`.\n-            #[inline]\n-            pub unsafe fn set_unchecked(&mut self, lane: usize, value: bool) {\n-                self.0.set_unchecked(lane, value);\n-            }\n+impl_element! { i8 }\n+impl_element! { i16 }\n+impl_element! { i32 }\n+impl_element! { i64 }\n+impl_element! { isize }\n+\n+/// A SIMD vector mask for `LANES` elements of width specified by `Element`.\n+///\n+/// The layout of this type is unspecified.\n+#[repr(transparent)]\n+pub struct Mask<Element, const LANES: usize>(mask_impl::Mask<Element, LANES>)\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount;\n+\n+impl<Element, const LANES: usize> Copy for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+}\n \n-            /// Sets the value of the specified lane.\n-            ///\n-            /// # Panics\n-            /// Panics if `lane` is greater than or equal to the number of lanes in the vector.\n-            #[inline]\n-            pub fn set(&mut self, lane: usize, value: bool) {\n-                assert!(lane < LANES, \"lane index out of range\");\n-                unsafe { self.set_unchecked(lane, value); }\n-            }\n+impl<Element, const LANES: usize> Clone for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    fn clone(&self) -> Self {\n+        *self\n+    }\n+}\n \n-            /// Convert this mask to a bitmask, with one bit set per lane.\n-            pub fn to_bitmask(self) -> [u8; crate::LaneCount::<LANES>::BITMASK_LEN] {\n-                self.0.to_bitmask()\n-            }\n+impl<Element, const LANES: usize> Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    /// Construct a mask by setting all lanes to the given value.\n+    pub fn splat(value: bool) -> Self {\n+        Self(mask_impl::Mask::splat(value))\n+    }\n \n-            /// Convert a bitmask to a mask.\n-            pub fn from_bitmask(bitmask: [u8; crate::LaneCount::<LANES>::BITMASK_LEN]) -> Self {\n-                Self(<$inner_ty>::from_bitmask(bitmask))\n-            }\n+    /// Converts an array to a SIMD vector.\n+    pub fn from_array(array: [bool; LANES]) -> Self {\n+        let mut vector = Self::splat(false);\n+        for (i, v) in array.iter().enumerate() {\n+            vector.set(i, *v);\n         }\n+        vector\n+    }\n \n-        // vector/array conversion\n-        impl<const LANES: usize> From<[bool; LANES]> for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            fn from(array: [bool; LANES]) -> Self {\n-                Self::from_array(array)\n-            }\n+    /// Converts a SIMD vector to an array.\n+    pub fn to_array(self) -> [bool; LANES] {\n+        let mut array = [false; LANES];\n+        for (i, v) in array.iter_mut().enumerate() {\n+            *v = self.test(i);\n         }\n+        array\n+    }\n \n-        impl <const LANES: usize> From<$name<LANES>> for [bool; LANES]\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            fn from(vector: $name<LANES>) -> Self {\n-                vector.to_array()\n-            }\n-        }\n+    /// Converts a vector of integers to a mask, where 0 represents `false` and -1\n+    /// represents `true`.\n+    ///\n+    /// # Safety\n+    /// All lanes must be either 0 or -1.\n+    #[inline]\n+    pub unsafe fn from_int_unchecked(value: Simd<Element, LANES>) -> Self {\n+        Self(mask_impl::Mask::from_int_unchecked(value))\n+    }\n \n-        impl<const LANES: usize> Copy for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {}\n+    /// Converts a vector of integers to a mask, where 0 represents `false` and -1\n+    /// represents `true`.\n+    ///\n+    /// # Panics\n+    /// Panics if any lane is not 0 or -1.\n+    #[inline]\n+    pub fn from_int(value: Simd<Element, LANES>) -> Self {\n+        assert!(Element::valid(value), \"all values must be either 0 or -1\",);\n+        unsafe { Self::from_int_unchecked(value) }\n+    }\n \n-        impl<const LANES: usize> Clone for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn clone(&self) -> Self {\n-                *self\n-            }\n-        }\n+    /// Converts the mask to a vector of integers, where 0 represents `false` and -1\n+    /// represents `true`.\n+    #[inline]\n+    pub fn to_int(self) -> Simd<Element, LANES> {\n+        self.0.to_int()\n+    }\n \n-        impl<const LANES: usize> Default for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn default() -> Self {\n-                Self::splat(false)\n-            }\n-        }\n+    /// Tests the value of the specified lane.\n+    ///\n+    /// # Safety\n+    /// `lane` must be less than `LANES`.\n+    #[inline]\n+    pub unsafe fn test_unchecked(&self, lane: usize) -> bool {\n+        self.0.test_unchecked(lane)\n+    }\n \n-        impl<const LANES: usize> PartialEq for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn eq(&self, other: &Self) -> bool {\n-                self.0 == other.0\n-            }\n-        }\n+    /// Tests the value of the specified lane.\n+    ///\n+    /// # Panics\n+    /// Panics if `lane` is greater than or equal to the number of lanes in the vector.\n+    #[inline]\n+    pub fn test(&self, lane: usize) -> bool {\n+        assert!(lane < LANES, \"lane index out of range\");\n+        unsafe { self.test_unchecked(lane) }\n+    }\n \n-        impl<const LANES: usize> PartialOrd for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {\n-                self.0.partial_cmp(&other.0)\n-            }\n-        }\n+    /// Sets the value of the specified lane.\n+    ///\n+    /// # Safety\n+    /// `lane` must be less than `LANES`.\n+    #[inline]\n+    pub unsafe fn set_unchecked(&mut self, lane: usize, value: bool) {\n+        self.0.set_unchecked(lane, value);\n+    }\n \n-        impl<const LANES: usize> core::fmt::Debug for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {\n-                f.debug_list()\n-                    .entries((0..LANES).map(|lane| self.test(lane)))\n-                    .finish()\n-            }\n+    /// Sets the value of the specified lane.\n+    ///\n+    /// # Panics\n+    /// Panics if `lane` is greater than or equal to the number of lanes in the vector.\n+    #[inline]\n+    pub fn set(&mut self, lane: usize, value: bool) {\n+        assert!(lane < LANES, \"lane index out of range\");\n+        unsafe {\n+            self.set_unchecked(lane, value);\n         }\n+    }\n \n-        impl<const LANES: usize> core::ops::BitAnd for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitand(self, rhs: Self) -> Self {\n-                Self(self.0 & rhs.0)\n-            }\n-        }\n+    /// Convert this mask to a bitmask, with one bit set per lane.\n+    pub fn to_bitmask(self) -> [u8; LaneCount::<LANES>::BITMASK_LEN] {\n+        self.0.to_bitmask()\n+    }\n \n-        impl<const LANES: usize> core::ops::BitAnd<bool> for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitand(self, rhs: bool) -> Self {\n-                self & Self::splat(rhs)\n-            }\n-        }\n+    /// Convert a bitmask to a mask.\n+    pub fn from_bitmask(bitmask: [u8; LaneCount::<LANES>::BITMASK_LEN]) -> Self {\n+        Self(mask_impl::Mask::from_bitmask(bitmask))\n+    }\n \n-        impl<const LANES: usize> core::ops::BitAnd<$name<LANES>> for bool\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = $name<LANES>;\n-            #[inline]\n-            fn bitand(self, rhs: $name<LANES>) -> $name<LANES> {\n-                $name::<LANES>::splat(self) & rhs\n-            }\n-        }\n+    /// Returns true if any lane is set, or false otherwise.\n+    #[inline]\n+    pub fn any(self) -> bool {\n+        self.0.any()\n+    }\n \n-        impl<const LANES: usize> core::ops::BitOr for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitor(self, rhs: Self) -> Self {\n-                Self(self.0 | rhs.0)\n-            }\n-        }\n+    /// Returns true if all lanes are set, or false otherwise.\n+    #[inline]\n+    pub fn all(self) -> bool {\n+        self.0.all()\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitOr<bool> for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitor(self, rhs: bool) -> Self {\n-                self | Self::splat(rhs)\n-            }\n-        }\n+// vector/array conversion\n+impl<Element, const LANES: usize> From<[bool; LANES]> for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    fn from(array: [bool; LANES]) -> Self {\n+        Self::from_array(array)\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitOr<$name<LANES>> for bool\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = $name<LANES>;\n-            #[inline]\n-            fn bitor(self, rhs: $name<LANES>) -> $name<LANES> {\n-                $name::<LANES>::splat(self) | rhs\n-            }\n-        }\n+impl<Element, const LANES: usize> From<Mask<Element, LANES>> for [bool; LANES]\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    fn from(vector: Mask<Element, LANES>) -> Self {\n+        vector.to_array()\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitXor for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitxor(self, rhs: Self) -> Self::Output {\n-                Self(self.0 ^ rhs.0)\n-            }\n-        }\n+impl<Element, const LANES: usize> Default for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn default() -> Self {\n+        Self::splat(false)\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitXor<bool> for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitxor(self, rhs: bool) -> Self::Output {\n-                self ^ Self::splat(rhs)\n-            }\n-        }\n+impl<Element, const LANES: usize> PartialEq for Mask<Element, LANES>\n+where\n+    Element: MaskElement + PartialEq,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn eq(&self, other: &Self) -> bool {\n+        self.0 == other.0\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitXor<$name<LANES>> for bool\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = $name<LANES>;\n-            #[inline]\n-            fn bitxor(self, rhs: $name<LANES>) -> Self::Output {\n-                $name::<LANES>::splat(self) ^ rhs\n-            }\n-        }\n+impl<Element, const LANES: usize> PartialOrd for Mask<Element, LANES>\n+where\n+    Element: MaskElement + PartialOrd,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {\n+        self.0.partial_cmp(&other.0)\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::Not for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = $name<LANES>;\n-            #[inline]\n-            fn not(self) -> Self::Output {\n-                Self(!self.0)\n-            }\n-        }\n+impl<Element, const LANES: usize> core::fmt::Debug for Mask<Element, LANES>\n+where\n+    Element: MaskElement + core::fmt::Debug,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    fn fmt(&self, f: &mut core::fmt::Formatter) -> core::fmt::Result {\n+        f.debug_list()\n+            .entries((0..LANES).map(|lane| self.test(lane)))\n+            .finish()\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitAndAssign for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn bitand_assign(&mut self, rhs: Self) {\n-                self.0 = self.0 & rhs.0;\n-            }\n-        }\n+impl<Element, const LANES: usize> core::ops::BitAnd for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitand(self, rhs: Self) -> Self {\n+        Self(self.0 & rhs.0)\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitAndAssign<bool> for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn bitand_assign(&mut self, rhs: bool) {\n-                *self &= Self::splat(rhs);\n-            }\n-        }\n+impl<Element, const LANES: usize> core::ops::BitAnd<bool> for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitand(self, rhs: bool) -> Self {\n+        self & Self::splat(rhs)\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitOrAssign for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn bitor_assign(&mut self, rhs: Self) {\n-                self.0 = self.0 | rhs.0;\n-            }\n-        }\n+impl<Element, const LANES: usize> core::ops::BitAnd<Mask<Element, LANES>> for bool\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Mask<Element, LANES>;\n+    #[inline]\n+    fn bitand(self, rhs: Mask<Element, LANES>) -> Mask<Element, LANES> {\n+        Mask::splat(self) & rhs\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitOrAssign<bool> for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn bitor_assign(&mut self, rhs: bool) {\n-                *self |= Self::splat(rhs);\n-            }\n-        }\n+impl<Element, const LANES: usize> core::ops::BitOr for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitor(self, rhs: Self) -> Self {\n+        Self(self.0 | rhs.0)\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitXorAssign for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn bitxor_assign(&mut self, rhs: Self) {\n-                self.0 = self.0 ^ rhs.0;\n-            }\n-        }\n+impl<Element, const LANES: usize> core::ops::BitOr<bool> for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitor(self, rhs: bool) -> Self {\n+        self | Self::splat(rhs)\n+    }\n+}\n \n-        impl<const LANES: usize> core::ops::BitXorAssign<bool> for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn bitxor_assign(&mut self, rhs: bool) {\n-                *self ^= Self::splat(rhs);\n-            }\n-        }\n-    };\n+impl<Element, const LANES: usize> core::ops::BitOr<Mask<Element, LANES>> for bool\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Mask<Element, LANES>;\n+    #[inline]\n+    fn bitor(self, rhs: Mask<Element, LANES>) -> Mask<Element, LANES> {\n+        Mask::splat(self) | rhs\n+    }\n }\n \n-define_opaque_mask! {\n-    /// Mask for vectors with `LANES` 8-bit elements.\n-    ///\n-    /// The layout of this type is unspecified.\n-    struct Mask8<const LANES: usize>(mask_impl::Mask8<LANES>);\n-    @bits SimdI8\n+impl<Element, const LANES: usize> core::ops::BitXor for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitxor(self, rhs: Self) -> Self::Output {\n+        Self(self.0 ^ rhs.0)\n+    }\n }\n \n-define_opaque_mask! {\n-    /// Mask for vectors with `LANES` 16-bit elements.\n-    ///\n-    /// The layout of this type is unspecified.\n-    struct Mask16<const LANES: usize>(mask_impl::Mask16<LANES>);\n-    @bits SimdI16\n+impl<Element, const LANES: usize> core::ops::BitXor<bool> for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitxor(self, rhs: bool) -> Self::Output {\n+        self ^ Self::splat(rhs)\n+    }\n }\n \n-define_opaque_mask! {\n-    /// Mask for vectors with `LANES` 32-bit elements.\n-    ///\n-    /// The layout of this type is unspecified.\n-    struct Mask32<const LANES: usize>(mask_impl::Mask32<LANES>);\n-    @bits SimdI32\n+impl<Element, const LANES: usize> core::ops::BitXor<Mask<Element, LANES>> for bool\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Mask<Element, LANES>;\n+    #[inline]\n+    fn bitxor(self, rhs: Mask<Element, LANES>) -> Self::Output {\n+        Mask::splat(self) ^ rhs\n+    }\n }\n \n-define_opaque_mask! {\n-    /// Mask for vectors with `LANES` 64-bit elements.\n-    ///\n-    /// The layout of this type is unspecified.\n-    struct Mask64<const LANES: usize>(mask_impl::Mask64<LANES>);\n-    @bits SimdI64\n+impl<Element, const LANES: usize> core::ops::Not for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Mask<Element, LANES>;\n+    #[inline]\n+    fn not(self) -> Self::Output {\n+        Self(!self.0)\n+    }\n }\n \n-define_opaque_mask! {\n-    /// Mask for vectors with `LANES` pointer-width elements.\n-    ///\n-    /// The layout of this type is unspecified.\n-    struct MaskSize<const LANES: usize>(mask_impl::MaskSize<LANES>);\n-    @bits SimdIsize\n+impl<Element, const LANES: usize> core::ops::BitAndAssign for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn bitand_assign(&mut self, rhs: Self) {\n+        self.0 = self.0 & rhs.0;\n+    }\n+}\n+\n+impl<Element, const LANES: usize> core::ops::BitAndAssign<bool> for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn bitand_assign(&mut self, rhs: bool) {\n+        *self &= Self::splat(rhs);\n+    }\n+}\n+\n+impl<Element, const LANES: usize> core::ops::BitOrAssign for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn bitor_assign(&mut self, rhs: Self) {\n+        self.0 = self.0 | rhs.0;\n+    }\n+}\n+\n+impl<Element, const LANES: usize> core::ops::BitOrAssign<bool> for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn bitor_assign(&mut self, rhs: bool) {\n+        *self |= Self::splat(rhs);\n+    }\n }\n \n+impl<Element, const LANES: usize> core::ops::BitXorAssign for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn bitxor_assign(&mut self, rhs: Self) {\n+        self.0 = self.0 ^ rhs.0;\n+    }\n+}\n+\n+impl<Element, const LANES: usize> core::ops::BitXorAssign<bool> for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn bitxor_assign(&mut self, rhs: bool) {\n+        *self ^= Self::splat(rhs);\n+    }\n+}\n+\n+/// A SIMD mask of `LANES` 8-bit values.\n+pub type Mask8<const LANES: usize> = Mask<i8, LANES>;\n+\n+/// A SIMD mask of `LANES` 16-bit values.\n+pub type Mask16<const LANES: usize> = Mask<i16, LANES>;\n+\n+/// A SIMD mask of `LANES` 32-bit values.\n+pub type Mask32<const LANES: usize> = Mask<i32, LANES>;\n+\n+/// A SIMD mask of `LANES` 64-bit values.\n+pub type Mask64<const LANES: usize> = Mask<i64, LANES>;\n+\n+/// A SIMD mask of `LANES` pointer-width values.\n+pub type MaskSize<const LANES: usize> = Mask<isize, LANES>;\n+\n /// Vector of eight 8-bit masks\n pub type mask8x8 = Mask8<8>;\n \n@@ -488,7 +529,7 @@ macro_rules! impl_from {\n             crate::LaneCount<LANES>: crate::SupportedLaneCount,\n         {\n             fn from(value: $from<LANES>) -> Self {\n-                Self(value.0.into())\n+                Self(value.0.convert())\n             }\n         }\n         )*"}, {"sha": "2b830949451051bd5d89c975e3183c9719070354", "filename": "crates/core_simd/src/masks/bitmask.rs", "status": "modified", "additions": 59, "deletions": 61, "changes": 120, "blob_url": "https://github.com/rust-lang/rust/blob/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Fmasks%2Fbitmask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Fmasks%2Fbitmask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fsrc%2Fmasks%2Fbitmask.rs?ref=de13b20b2706607c9c130e16d5fb2b83241a94c1", "patch": "@@ -1,76 +1,73 @@\n-use crate::{LaneCount, SupportedLaneCount};\n-\n-/// Helper trait for limiting int conversion types\n-pub trait ConvertToInt {}\n-impl<const LANES: usize> ConvertToInt for crate::SimdI8<LANES> where\n-    LaneCount<LANES>: SupportedLaneCount\n-{\n-}\n-impl<const LANES: usize> ConvertToInt for crate::SimdI16<LANES> where\n-    LaneCount<LANES>: SupportedLaneCount\n-{\n-}\n-impl<const LANES: usize> ConvertToInt for crate::SimdI32<LANES> where\n-    LaneCount<LANES>: SupportedLaneCount\n-{\n-}\n-impl<const LANES: usize> ConvertToInt for crate::SimdI64<LANES> where\n-    LaneCount<LANES>: SupportedLaneCount\n-{\n-}\n-impl<const LANES: usize> ConvertToInt for crate::SimdIsize<LANES> where\n-    LaneCount<LANES>: SupportedLaneCount\n-{\n-}\n+use crate::{LaneCount, MaskElement, Simd, SupportedLaneCount};\n+use core::marker::PhantomData;\n \n /// A mask where each lane is represented by a single bit.\n #[repr(transparent)]\n-pub struct BitMask<const LANES: usize>(<LaneCount<LANES> as SupportedLaneCount>::BitMask)\n+pub struct Mask<Element, const LANES: usize>(\n+    <LaneCount<LANES> as SupportedLaneCount>::BitMask,\n+    PhantomData<Element>,\n+)\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount;\n \n-impl<const LANES: usize> Copy for BitMask<LANES> where LaneCount<LANES>: SupportedLaneCount {}\n+impl<Element, const LANES: usize> Copy for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+}\n \n-impl<const LANES: usize> Clone for BitMask<LANES>\n+impl<Element, const LANES: usize> Clone for Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n {\n     fn clone(&self) -> Self {\n         *self\n     }\n }\n \n-impl<const LANES: usize> PartialEq for BitMask<LANES>\n+impl<Element, const LANES: usize> PartialEq for Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n {\n     fn eq(&self, other: &Self) -> bool {\n         self.0.as_ref() == other.0.as_ref()\n     }\n }\n \n-impl<const LANES: usize> PartialOrd for BitMask<LANES>\n+impl<Element, const LANES: usize> PartialOrd for Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n {\n     fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {\n         self.0.as_ref().partial_cmp(other.0.as_ref())\n     }\n }\n \n-impl<const LANES: usize> Eq for BitMask<LANES> where LaneCount<LANES>: SupportedLaneCount {}\n+impl<Element, const LANES: usize> Eq for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+}\n \n-impl<const LANES: usize> Ord for BitMask<LANES>\n+impl<Element, const LANES: usize> Ord for Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n {\n     fn cmp(&self, other: &Self) -> core::cmp::Ordering {\n         self.0.as_ref().cmp(other.0.as_ref())\n     }\n }\n \n-impl<const LANES: usize> BitMask<LANES>\n+impl<Element, const LANES: usize> Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n {\n     #[inline]\n@@ -84,7 +81,7 @@ where\n         if LANES % 8 > 0 {\n             *mask.as_mut().last_mut().unwrap() &= u8::MAX >> (8 - LANES % 8);\n         }\n-        Self(mask)\n+        Self(mask, PhantomData)\n     }\n \n     #[inline]\n@@ -98,33 +95,28 @@ where\n     }\n \n     #[inline]\n-    pub fn to_int<V>(self) -> V\n-    where\n-        V: ConvertToInt + Default + core::ops::Not<Output = V>,\n-    {\n+    pub fn to_int(self) -> Simd<Element, LANES> {\n         unsafe {\n             let mask: <LaneCount<LANES> as SupportedLaneCount>::IntBitMask =\n                 core::mem::transmute_copy(&self);\n-            crate::intrinsics::simd_select_bitmask(mask, !V::default(), V::default())\n+            crate::intrinsics::simd_select_bitmask(\n+                mask,\n+                Simd::splat(Element::TRUE),\n+                Simd::splat(Element::FALSE),\n+            )\n         }\n     }\n \n     #[inline]\n-    pub unsafe fn from_int_unchecked<V>(value: V) -> Self\n-    where\n-        V: crate::Vector,\n-    {\n+    pub unsafe fn from_int_unchecked(value: Simd<Element, LANES>) -> Self {\n         // TODO remove the transmute when rustc is more flexible\n         assert_eq!(\n-            core::mem::size_of::<<crate::LaneCount::<LANES> as crate::SupportedLaneCount>::BitMask>(\n-            ),\n-            core::mem::size_of::<\n-                <crate::LaneCount::<LANES> as crate::SupportedLaneCount>::IntBitMask,\n-            >(),\n+            core::mem::size_of::<<LaneCount::<LANES> as SupportedLaneCount>::BitMask>(),\n+            core::mem::size_of::<<LaneCount::<LANES> as SupportedLaneCount>::IntBitMask>(),\n         );\n         let mask: <LaneCount<LANES> as SupportedLaneCount>::IntBitMask =\n             crate::intrinsics::simd_bitmask(value);\n-        Self(core::mem::transmute_copy(&mask))\n+        Self(core::mem::transmute_copy(&mask), PhantomData)\n     }\n \n     #[inline]\n@@ -136,7 +128,15 @@ where\n     #[inline]\n     pub fn from_bitmask(bitmask: [u8; LaneCount::<LANES>::BITMASK_LEN]) -> Self {\n         // Safety: these are the same type and we are laundering the generic\n-        Self(unsafe { core::mem::transmute_copy(&bitmask) })\n+        Self(unsafe { core::mem::transmute_copy(&bitmask) }, PhantomData)\n+    }\n+\n+    #[inline]\n+    pub fn convert<T>(self) -> Mask<T, LANES>\n+    where\n+        T: MaskElement,\n+    {\n+        unsafe { core::mem::transmute_copy(&self) }\n     }\n \n     #[inline]\n@@ -150,10 +150,11 @@ where\n     }\n }\n \n-impl<const LANES: usize> core::ops::BitAnd for BitMask<LANES>\n+impl<Element, const LANES: usize> core::ops::BitAnd for Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n-    <LaneCount<LANES> as SupportedLaneCount>::BitMask: Default + AsRef<[u8]> + AsMut<[u8]>,\n+    <LaneCount<LANES> as SupportedLaneCount>::BitMask: AsRef<[u8]> + AsMut<[u8]>,\n {\n     type Output = Self;\n     #[inline]\n@@ -165,10 +166,11 @@ where\n     }\n }\n \n-impl<const LANES: usize> core::ops::BitOr for BitMask<LANES>\n+impl<Element, const LANES: usize> core::ops::BitOr for Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n-    <LaneCount<LANES> as SupportedLaneCount>::BitMask: Default + AsRef<[u8]> + AsMut<[u8]>,\n+    <LaneCount<LANES> as SupportedLaneCount>::BitMask: AsRef<[u8]> + AsMut<[u8]>,\n {\n     type Output = Self;\n     #[inline]\n@@ -180,8 +182,9 @@ where\n     }\n }\n \n-impl<const LANES: usize> core::ops::BitXor for BitMask<LANES>\n+impl<Element, const LANES: usize> core::ops::BitXor for Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n {\n     type Output = Self;\n@@ -194,8 +197,9 @@ where\n     }\n }\n \n-impl<const LANES: usize> core::ops::Not for BitMask<LANES>\n+impl<Element, const LANES: usize> core::ops::Not for Mask<Element, LANES>\n where\n+    Element: MaskElement,\n     LaneCount<LANES>: SupportedLaneCount,\n {\n     type Output = Self;\n@@ -210,9 +214,3 @@ where\n         self\n     }\n }\n-\n-pub type Mask8<const LANES: usize> = BitMask<LANES>;\n-pub type Mask16<const LANES: usize> = BitMask<LANES>;\n-pub type Mask32<const LANES: usize> = BitMask<LANES>;\n-pub type Mask64<const LANES: usize> = BitMask<LANES>;\n-pub type MaskSize<const LANES: usize> = BitMask<LANES>;"}, {"sha": "858c99032a3195b8add359aa221355afdde56ac8", "filename": "crates/core_simd/src/masks/full_masks.rs", "status": "modified", "additions": 185, "deletions": 228, "changes": 413, "blob_url": "https://github.com/rust-lang/rust/blob/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Fmasks%2Ffull_masks.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Fmasks%2Ffull_masks.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fsrc%2Fmasks%2Ffull_masks.rs?ref=de13b20b2706607c9c130e16d5fb2b83241a94c1", "patch": "@@ -1,264 +1,221 @@\n //! Masks that take up full SIMD vector registers.\n \n-macro_rules! define_mask {\n-    {\n-        $(#[$attr:meta])*\n-        struct $name:ident<const $lanes:ident: usize>(\n-            crate::$type:ident<$lanes2:ident>\n-        );\n-    } => {\n-        $(#[$attr])*\n-        #[repr(transparent)]\n-        pub struct $name<const $lanes: usize>(crate::$type<$lanes>)\n-        where\n-            crate::LaneCount<$lanes>: crate::SupportedLaneCount;\n-\n-        impl_full_mask_reductions! { $name, $type }\n-\n-        impl<const LANES: usize> Copy for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {}\n-\n-        impl<const LANES: usize> Clone for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            #[inline]\n-            fn clone(&self) -> Self {\n-                *self\n-            }\n-        }\n-\n-        impl<const LANES: usize> PartialEq for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            fn eq(&self, other: &Self) -> bool {\n-                self.0 == other.0\n-            }\n-        }\n-\n-        impl<const LANES: usize> PartialOrd for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {\n-                self.0.partial_cmp(&other.0)\n-            }\n-        }\n-\n-        impl<const LANES: usize> Eq for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {}\n+use super::MaskElement;\n+use crate::{LaneCount, Simd, SupportedLaneCount};\n+\n+#[repr(transparent)]\n+pub struct Mask<Element, const LANES: usize>(Simd<Element, LANES>)\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount;\n+\n+impl<Element, const LANES: usize> Copy for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+}\n \n-        impl<const LANES: usize> Ord for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            fn cmp(&self, other: &Self) -> core::cmp::Ordering {\n-                self.0.cmp(&other.0)\n-            }\n-        }\n+impl<Element, const LANES: usize> Clone for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    #[inline]\n+    fn clone(&self) -> Self {\n+        *self\n+    }\n+}\n \n-        impl<const LANES: usize> $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            pub fn splat(value: bool) -> Self {\n-                Self(\n-                    <crate::$type<LANES>>::splat(\n-                        if value {\n-                            -1\n-                        } else {\n-                            0\n-                        }\n-                    ),\n-                )\n-            }\n+impl<Element, const LANES: usize> PartialEq for Mask<Element, LANES>\n+where\n+    Element: MaskElement + PartialEq,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    fn eq(&self, other: &Self) -> bool {\n+        self.0.eq(&other.0)\n+    }\n+}\n \n-            #[inline]\n-            pub unsafe fn test_unchecked(&self, lane: usize) -> bool {\n-                self.0[lane] == -1\n-            }\n+impl<Element, const LANES: usize> PartialOrd for Mask<Element, LANES>\n+where\n+    Element: MaskElement + PartialOrd,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {\n+        self.0.partial_cmp(&other.0)\n+    }\n+}\n \n-            #[inline]\n-            pub unsafe fn set_unchecked(&mut self, lane: usize, value: bool) {\n-                self.0[lane] = if value {\n-                    -1\n-                } else {\n-                    0\n-                }\n-            }\n+impl<Element, const LANES: usize> Eq for Mask<Element, LANES>\n+where\n+    Element: MaskElement + Eq,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+}\n \n-            #[inline]\n-            pub fn to_int(self) -> crate::$type<LANES> {\n-                self.0\n-            }\n+impl<Element, const LANES: usize> Ord for Mask<Element, LANES>\n+where\n+    Element: MaskElement + Ord,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    fn cmp(&self, other: &Self) -> core::cmp::Ordering {\n+        self.0.cmp(&other.0)\n+    }\n+}\n \n-            #[inline]\n-            pub unsafe fn from_int_unchecked(value: crate::$type<LANES>) -> Self {\n-                Self(value)\n-            }\n+impl<Element, const LANES: usize> Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    pub fn splat(value: bool) -> Self {\n+        Self(Simd::splat(if value {\n+            Element::TRUE\n+        } else {\n+            Element::FALSE\n+        }))\n+    }\n \n-            #[inline]\n-            pub fn to_bitmask(self) -> [u8; crate::LaneCount::<LANES>::BITMASK_LEN] {\n-                unsafe {\n-                    // TODO remove the transmute when rustc can use arrays of u8 as bitmasks\n-                    assert_eq!(\n-                        core::mem::size_of::<<crate::LaneCount::<LANES> as crate::SupportedLaneCount>::IntBitMask>(),\n-                        crate::LaneCount::<LANES>::BITMASK_LEN,\n-                    );\n-                    let bitmask: <crate::LaneCount::<LANES> as crate::SupportedLaneCount>::IntBitMask = crate::intrinsics::simd_bitmask(self.0);\n-                    let mut bitmask: [u8; crate::LaneCount::<LANES>::BITMASK_LEN] = core::mem::transmute_copy(&bitmask);\n+    #[inline]\n+    pub unsafe fn test_unchecked(&self, lane: usize) -> bool {\n+        Element::eq(self.0[lane], Element::TRUE)\n+    }\n \n-                    // There is a bug where LLVM appears to implement this operation with the wrong\n-                    // bit order.\n-                    // TODO fix this in a better way\n-                    if cfg!(any(target_arch = \"mips\", target_arch = \"mips64\")) {\n-                        for x in bitmask.as_mut() {\n-                            *x = x.reverse_bits();\n-                        }\n-                    }\n+    #[inline]\n+    pub unsafe fn set_unchecked(&mut self, lane: usize, value: bool) {\n+        self.0[lane] = if value { Element::TRUE } else { Element::FALSE }\n+    }\n \n-                    bitmask\n-                }\n-            }\n+    #[inline]\n+    pub fn to_int(self) -> Simd<Element, LANES> {\n+        self.0\n+    }\n \n-            #[inline]\n-            pub fn from_bitmask(mut bitmask: [u8; crate::LaneCount::<LANES>::BITMASK_LEN]) -> Self {\n-                unsafe {\n-                    // There is a bug where LLVM appears to implement this operation with the wrong\n-                    // bit order.\n-                    // TODO fix this in a better way\n-                    if cfg!(any(target_arch = \"mips\", target_arch = \"mips64\")) {\n-                        for x in bitmask.as_mut() {\n-                            *x = x.reverse_bits();\n-                        }\n-                    }\n+    #[inline]\n+    pub unsafe fn from_int_unchecked(value: Simd<Element, LANES>) -> Self {\n+        Self(value)\n+    }\n \n-                    // TODO remove the transmute when rustc can use arrays of u8 as bitmasks\n-                    assert_eq!(\n-                        core::mem::size_of::<<crate::LaneCount::<LANES> as crate::SupportedLaneCount>::IntBitMask>(),\n-                        crate::LaneCount::<LANES>::BITMASK_LEN,\n-                    );\n-                    let bitmask: <crate::LaneCount::<LANES> as crate::SupportedLaneCount>::IntBitMask = core::mem::transmute_copy(&bitmask);\n+    #[inline]\n+    pub fn convert<T>(self) -> Mask<T, LANES>\n+    where\n+        T: MaskElement,\n+    {\n+        unsafe { Mask(crate::intrinsics::simd_cast(self.0)) }\n+    }\n \n-                    Self::from_int_unchecked(crate::intrinsics::simd_select_bitmask(\n-                        bitmask,\n-                        Self::splat(true).to_int(),\n-                        Self::splat(false).to_int(),\n-                    ))\n+    #[inline]\n+    pub fn to_bitmask(self) -> [u8; LaneCount::<LANES>::BITMASK_LEN] {\n+        unsafe {\n+            // TODO remove the transmute when rustc can use arrays of u8 as bitmasks\n+            assert_eq!(\n+                core::mem::size_of::<<LaneCount::<LANES> as SupportedLaneCount>::IntBitMask>(),\n+                LaneCount::<LANES>::BITMASK_LEN,\n+            );\n+            let bitmask: <LaneCount<LANES> as SupportedLaneCount>::IntBitMask =\n+                crate::intrinsics::simd_bitmask(self.0);\n+            let mut bitmask: [u8; LaneCount::<LANES>::BITMASK_LEN] =\n+                core::mem::transmute_copy(&bitmask);\n+\n+            // There is a bug where LLVM appears to implement this operation with the wrong\n+            // bit order.\n+            // TODO fix this in a better way\n+            if cfg!(any(target_arch = \"mips\", target_arch = \"mips64\")) {\n+                for x in bitmask.as_mut() {\n+                    *x = x.reverse_bits();\n                 }\n             }\n-        }\n \n-        impl<const LANES: usize> core::convert::From<$name<LANES>> for crate::$type<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            fn from(value: $name<LANES>) -> Self {\n-                value.0\n-            }\n-        }\n-\n-        impl<const LANES: usize> core::ops::BitAnd for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitand(self, rhs: Self) -> Self {\n-                Self(self.0 & rhs.0)\n-            }\n+            bitmask\n         }\n+    }\n \n-        impl<const LANES: usize> core::ops::BitOr for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitor(self, rhs: Self) -> Self {\n-                Self(self.0 | rhs.0)\n+    #[inline]\n+    pub fn from_bitmask(mut bitmask: [u8; LaneCount::<LANES>::BITMASK_LEN]) -> Self {\n+        unsafe {\n+            // There is a bug where LLVM appears to implement this operation with the wrong\n+            // bit order.\n+            // TODO fix this in a better way\n+            if cfg!(any(target_arch = \"mips\", target_arch = \"mips64\")) {\n+                for x in bitmask.as_mut() {\n+                    *x = x.reverse_bits();\n+                }\n             }\n-        }\n \n-        impl<const LANES: usize> core::ops::BitXor for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn bitxor(self, rhs: Self) -> Self::Output {\n-                Self(self.0 ^ rhs.0)\n-            }\n-        }\n+            // TODO remove the transmute when rustc can use arrays of u8 as bitmasks\n+            assert_eq!(\n+                core::mem::size_of::<<LaneCount::<LANES> as SupportedLaneCount>::IntBitMask>(),\n+                LaneCount::<LANES>::BITMASK_LEN,\n+            );\n+            let bitmask: <LaneCount<LANES> as SupportedLaneCount>::IntBitMask =\n+                core::mem::transmute_copy(&bitmask);\n \n-        impl<const LANES: usize> core::ops::Not for $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            type Output = Self;\n-            #[inline]\n-            fn not(self) -> Self::Output {\n-                Self(!self.0)\n-            }\n+            Self::from_int_unchecked(crate::intrinsics::simd_select_bitmask(\n+                bitmask,\n+                Self::splat(true).to_int(),\n+                Self::splat(false).to_int(),\n+            ))\n         }\n     }\n }\n \n-define_mask! {\n-    /// A mask equivalent to [SimdI8](crate::SimdI8), where all bits in the lane must be either set\n-    /// or unset.\n-    struct Mask8<const LANES: usize>(crate::SimdI8<LANES>);\n-}\n-\n-define_mask! {\n-    /// A mask equivalent to [SimdI16](crate::SimdI16), where all bits in the lane must be either set\n-    /// or unset.\n-    struct Mask16<const LANES: usize>(crate::SimdI16<LANES>);\n+impl<Element, const LANES: usize> core::convert::From<Mask<Element, LANES>> for Simd<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    fn from(value: Mask<Element, LANES>) -> Self {\n+        value.0\n+    }\n }\n \n-define_mask! {\n-    /// A mask equivalent to [SimdI32](crate::SimdI32), where all bits in the lane must be either set\n-    /// or unset.\n-    struct Mask32<const LANES: usize>(crate::SimdI32<LANES>);\n+impl<Element, const LANES: usize> core::ops::BitAnd for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitand(self, rhs: Self) -> Self {\n+        unsafe { Self(crate::intrinsics::simd_and(self.0, rhs.0)) }\n+    }\n }\n \n-define_mask! {\n-    /// A mask equivalent to [SimdI64](crate::SimdI64), where all bits in the lane must be either set\n-    /// or unset.\n-    struct Mask64<const LANES: usize>(crate::SimdI64<LANES>);\n+impl<Element, const LANES: usize> core::ops::BitOr for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitor(self, rhs: Self) -> Self {\n+        unsafe { Self(crate::intrinsics::simd_or(self.0, rhs.0)) }\n+    }\n }\n \n-define_mask! {\n-    /// A mask equivalent to [SimdIsize](crate::SimdIsize), where all bits in the lane must be either set\n-    /// or unset.\n-    struct MaskSize<const LANES: usize>(crate::SimdIsize<LANES>);\n+impl<Element, const LANES: usize> core::ops::BitXor for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn bitxor(self, rhs: Self) -> Self {\n+        unsafe { Self(crate::intrinsics::simd_xor(self.0, rhs.0)) }\n+    }\n }\n \n-macro_rules! impl_from {\n-    { $from:ident ($from_inner:ident) => $($to:ident ($to_inner:ident)),* } => {\n-        $(\n-        impl<const LANES: usize> From<$from<LANES>> for $to<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            fn from(value: $from<LANES>) -> Self {\n-                let mut new = Self::splat(false);\n-                for i in 0..LANES {\n-                    unsafe { new.set_unchecked(i, value.test_unchecked(i)) }\n-                }\n-                new\n-            }\n-        }\n-        )*\n+impl<Element, const LANES: usize> core::ops::Not for Mask<Element, LANES>\n+where\n+    Element: MaskElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+{\n+    type Output = Self;\n+    #[inline]\n+    fn not(self) -> Self::Output {\n+        Self::splat(true) ^ self\n     }\n }\n-impl_from! { Mask8 (SimdI8) => Mask16 (SimdI16), Mask32 (SimdI32), Mask64 (SimdI64), MaskSize (SimdIsize) }\n-impl_from! { Mask16 (SimdI16) => Mask32 (SimdI32), Mask64 (SimdI64), MaskSize (SimdIsize), Mask8 (SimdI8) }\n-impl_from! { Mask32 (SimdI32) => Mask64 (SimdI64), MaskSize (SimdIsize), Mask8 (SimdI8), Mask16 (SimdI16) }\n-impl_from! { Mask64 (SimdI64) => MaskSize (SimdIsize), Mask8 (SimdI8), Mask16 (SimdI16), Mask32 (SimdI32) }\n-impl_from! { MaskSize (SimdIsize) => Mask8 (SimdI8), Mask16 (SimdI16), Mask32 (SimdI32), Mask64 (SimdI64) }\n+\n+impl_full_mask_reductions! {}"}, {"sha": "67bafd73b144a2b0078d0469c0f7d51c36d8da27", "filename": "crates/core_simd/src/ops.rs", "status": "modified", "additions": 24, "deletions": 28, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Fops.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Fops.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fsrc%2Fops.rs?ref=de13b20b2706607c9c130e16d5fb2b83241a94c1", "patch": "@@ -1,4 +1,27 @@\n-use crate::{LaneCount, SupportedLaneCount};\n+use crate::{LaneCount, Simd, SimdElement, SupportedLaneCount};\n+\n+impl<I, Element, const LANES: usize> core::ops::Index<I> for Simd<Element, LANES>\n+where\n+    Element: SimdElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+    I: core::slice::SliceIndex<[Element]>,\n+{\n+    type Output = I::Output;\n+    fn index(&self, index: I) -> &Self::Output {\n+        &self.as_array()[index]\n+    }\n+}\n+\n+impl<I, Element, const LANES: usize> core::ops::IndexMut<I> for Simd<Element, LANES>\n+where\n+    Element: SimdElement,\n+    LaneCount<LANES>: SupportedLaneCount,\n+    I: core::slice::SliceIndex<[Element]>,\n+{\n+    fn index_mut(&mut self, index: I) -> &mut Self::Output {\n+        &mut self.as_mut_array()[index]\n+    }\n+}\n \n /// Checks if the right-hand side argument of a left- or right-shift would cause overflow.\n fn invalid_shift_rhs<T>(rhs: T) -> bool\n@@ -191,31 +214,6 @@ macro_rules! impl_op {\n         }\n     };\n \n-    { impl Index for $type:ident, $scalar:ty } => {\n-        impl<I, const LANES: usize> core::ops::Index<I> for crate::$type<LANES>\n-        where\n-            LaneCount<LANES>: SupportedLaneCount,\n-            I: core::slice::SliceIndex<[$scalar]>,\n-        {\n-            type Output = I::Output;\n-            fn index(&self, index: I) -> &Self::Output {\n-                let slice: &[_] = self.as_ref();\n-                &slice[index]\n-            }\n-        }\n-\n-        impl<I, const LANES: usize> core::ops::IndexMut<I> for crate::$type<LANES>\n-        where\n-            LaneCount<LANES>: SupportedLaneCount,\n-            I: core::slice::SliceIndex<[$scalar]>,\n-        {\n-            fn index_mut(&mut self, index: I) -> &mut Self::Output {\n-                let slice: &mut [_] = self.as_mut();\n-                &mut slice[index]\n-            }\n-        }\n-    };\n-\n     // generic binary op with assignment when output is `Self`\n     { @binary $type:ident, $scalar:ty, $trait:ident :: $trait_fn:ident, $assign_trait:ident :: $assign_trait_fn:ident, $intrinsic:ident } => {\n         impl_ref_ops! {\n@@ -301,7 +299,6 @@ macro_rules! impl_float_ops {\n                 impl_op! { impl Div for $vector, $scalar }\n                 impl_op! { impl Rem for $vector, $scalar }\n                 impl_op! { impl Neg for $vector, $scalar }\n-                impl_op! { impl Index for $vector, $scalar }\n             )*\n         )*\n     };\n@@ -319,7 +316,6 @@ macro_rules! impl_unsigned_int_ops {\n                 impl_op! { impl BitOr  for $vector, $scalar }\n                 impl_op! { impl BitXor for $vector, $scalar }\n                 impl_op! { impl Not for $vector, $scalar }\n-                impl_op! { impl Index for $vector, $scalar }\n \n                 // Integers panic on divide by 0\n                 impl_ref_ops! {"}, {"sha": "b9c24d027b62db199e070cf47b77b508a1812b6e", "filename": "crates/core_simd/src/reduction.rs", "status": "modified", "additions": 4, "deletions": 24, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Freduction.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de13b20b2706607c9c130e16d5fb2b83241a94c1/crates%2Fcore_simd%2Fsrc%2Freduction.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fcore_simd%2Fsrc%2Freduction.rs?ref=de13b20b2706607c9c130e16d5fb2b83241a94c1", "patch": "@@ -103,10 +103,11 @@ macro_rules! impl_float_reductions {\n }\n \n macro_rules! impl_full_mask_reductions {\n-    { $name:ident, $bits_ty:ident } => {\n-        impl<const LANES: usize> $name<LANES>\n+    {} => {\n+        impl<Element, const LANES: usize> Mask<Element, LANES>\n         where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n+            Element: MaskElement,\n+            LaneCount<LANES>: SupportedLaneCount,\n         {\n             #[inline]\n             pub fn any(self) -> bool {\n@@ -120,24 +121,3 @@ macro_rules! impl_full_mask_reductions {\n         }\n     }\n }\n-\n-macro_rules! impl_opaque_mask_reductions {\n-    { $name:ident, $bits_ty:ident } => {\n-        impl<const LANES: usize> $name<LANES>\n-        where\n-            crate::LaneCount<LANES>: crate::SupportedLaneCount,\n-        {\n-            /// Returns true if any lane is set, or false otherwise.\n-            #[inline]\n-            pub fn any(self) -> bool {\n-                self.0.any()\n-            }\n-\n-            /// Returns true if all lanes are set, or false otherwise.\n-            #[inline]\n-            pub fn all(self) -> bool {\n-                self.0.all()\n-            }\n-        }\n-    }\n-}"}]}