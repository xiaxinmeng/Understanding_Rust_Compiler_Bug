{"sha": "2b91cbe2d4ce90d30520674876e9d700cf7a561b", "node_id": "C_kwDOAAsO6NoAKDJiOTFjYmUyZDRjZTkwZDMwNTIwNjc0ODc2ZTlkNzAwY2Y3YTU2MWI", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-10-12T03:46:16Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-10-12T03:46:16Z"}, "message": "Auto merge of #102692 - nnethercote:TokenStreamBuilder, r=Aaron1011\n\nRemove `TokenStreamBuilder`\n\n`TokenStreamBuilder` is used to combine multiple token streams. It can be removed, leaving the code a little simpler and a little faster.\n\nr? `@Aaron1011`", "tree": {"sha": "6d98e289f792fa00bc4fafa82b66b340473ce5c4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6d98e289f792fa00bc4fafa82b66b340473ce5c4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2b91cbe2d4ce90d30520674876e9d700cf7a561b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2b91cbe2d4ce90d30520674876e9d700cf7a561b", "html_url": "https://github.com/rust-lang/rust/commit/2b91cbe2d4ce90d30520674876e9d700cf7a561b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2b91cbe2d4ce90d30520674876e9d700cf7a561b/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7e8d64e792543fedb8574ac0a27522dbab66aa52", "url": "https://api.github.com/repos/rust-lang/rust/commits/7e8d64e792543fedb8574ac0a27522dbab66aa52", "html_url": "https://github.com/rust-lang/rust/commit/7e8d64e792543fedb8574ac0a27522dbab66aa52"}, {"sha": "ed6f4813bb5838e472e1e59d0454b75f777d1b9d", "url": "https://api.github.com/repos/rust-lang/rust/commits/ed6f4813bb5838e472e1e59d0454b75f777d1b9d", "html_url": "https://github.com/rust-lang/rust/commit/ed6f4813bb5838e472e1e59d0454b75f777d1b9d"}], "stats": {"total": 265, "additions": 118, "deletions": 147}, "files": [{"sha": "1d3c4fcca0a44e9c10a647481d2b54ba3eee11d5", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 45, "deletions": 72, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/2b91cbe2d4ce90d30520674876e9d700cf7a561b/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2b91cbe2d4ce90d30520674876e9d700cf7a561b/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=2b91cbe2d4ce90d30520674876e9d700cf7a561b", "patch": "@@ -245,12 +245,12 @@ impl AttrTokenStream {\n                                 // properly implemented - we always synthesize fake tokens,\n                                 // so we never reach this code.\n \n-                                let mut builder = TokenStreamBuilder::new();\n+                                let mut stream = TokenStream::default();\n                                 for inner_attr in inner_attrs {\n-                                    builder.push(inner_attr.tokens());\n+                                    stream.push_stream(inner_attr.tokens());\n                                 }\n-                                builder.push(delim_tokens.clone());\n-                                *tree = TokenTree::Delimited(*span, *delim, builder.build());\n+                                stream.push_stream(delim_tokens.clone());\n+                                *tree = TokenTree::Delimited(*span, *delim, stream);\n                                 found = true;\n                                 break;\n                             }\n@@ -505,76 +505,49 @@ impl TokenStream {\n \n         self.trees().map(|tree| TokenStream::flatten_token_tree(tree)).collect()\n     }\n-}\n \n-// 99.5%+ of the time we have 1 or 2 elements in this vector.\n-#[derive(Clone)]\n-pub struct TokenStreamBuilder(SmallVec<[TokenStream; 2]>);\n-\n-impl TokenStreamBuilder {\n-    pub fn new() -> TokenStreamBuilder {\n-        TokenStreamBuilder(SmallVec::new())\n-    }\n-\n-    pub fn push(&mut self, stream: TokenStream) {\n-        self.0.push(stream);\n-    }\n-\n-    pub fn build(self) -> TokenStream {\n-        let mut streams = self.0;\n-        match streams.len() {\n-            0 => TokenStream::default(),\n-            1 => streams.pop().unwrap(),\n-            _ => {\n-                // We will extend the first stream in `streams` with the\n-                // elements from the subsequent streams. This requires using\n-                // `make_mut()` on the first stream, and in practice this\n-                // doesn't cause cloning 99.9% of the time.\n-                //\n-                // One very common use case is when `streams` has two elements,\n-                // where the first stream has any number of elements within\n-                // (often 1, but sometimes many more) and the second stream has\n-                // a single element within.\n-\n-                // Determine how much the first stream will be extended.\n-                // Needed to avoid quadratic blow up from on-the-fly\n-                // reallocations (#57735).\n-                let num_appends = streams.iter().skip(1).map(|ts| ts.len()).sum();\n-\n-                // Get the first stream, which will become the result stream.\n-                // If it's `None`, create an empty stream.\n-                let mut iter = streams.into_iter();\n-                let mut res_stream_lrc = iter.next().unwrap().0;\n-\n-                // Append the subsequent elements to the result stream, after\n-                // reserving space for them.\n-                let res_vec_mut = Lrc::make_mut(&mut res_stream_lrc);\n-                res_vec_mut.reserve(num_appends);\n-                for stream in iter {\n-                    let stream_iter = stream.0.iter().cloned();\n-\n-                    // If (a) `res_mut_vec` is not empty and the last tree\n-                    // within it is a token tree marked with `Joint`, and (b)\n-                    // `stream` is not empty and the first tree within it is a\n-                    // token tree, and (c) the two tokens can be glued\n-                    // together...\n-                    if let Some(TokenTree::Token(last_tok, Spacing::Joint)) = res_vec_mut.last()\n-                        && let Some(TokenTree::Token(tok, spacing)) = stream.0.first()\n-                        && let Some(glued_tok) = last_tok.glue(&tok)\n-                    {\n-                        // ...then overwrite the last token tree in\n-                        // `res_vec_mut` with the glued token, and skip the\n-                        // first token tree from `stream`.\n-                        *res_vec_mut.last_mut().unwrap() = TokenTree::Token(glued_tok, *spacing);\n-                        res_vec_mut.extend(stream_iter.skip(1));\n-                    } else {\n-                        // Append all of `stream`.\n-                        res_vec_mut.extend(stream_iter);\n-                    }\n-                }\n+    // If `vec` is not empty, try to glue `tt` onto its last token. The return\n+    // value indicates if gluing took place.\n+    fn try_glue_to_last(vec: &mut Vec<TokenTree>, tt: &TokenTree) -> bool {\n+        if let Some(TokenTree::Token(last_tok, Spacing::Joint)) = vec.last()\n+            && let TokenTree::Token(tok, spacing) = tt\n+            && let Some(glued_tok) = last_tok.glue(&tok)\n+        {\n+            // ...then overwrite the last token tree in `vec` with the\n+            // glued token, and skip the first token tree from `stream`.\n+            *vec.last_mut().unwrap() = TokenTree::Token(glued_tok, *spacing);\n+            true\n+        } else {\n+            false\n+        }\n+    }\n \n-                TokenStream(res_stream_lrc)\n-            }\n+    // Push `tt` onto the end of the stream, possibly gluing it to the last\n+    // token. Uses `make_mut` to maximize efficiency.\n+    pub fn push_tree(&mut self, tt: TokenTree) {\n+        let vec_mut = Lrc::make_mut(&mut self.0);\n+\n+        if Self::try_glue_to_last(vec_mut, &tt) {\n+            // nothing else to do\n+        } else {\n+            vec_mut.push(tt);\n+        }\n+    }\n+\n+    // Push `stream` onto the end of the stream, possibly gluing the first\n+    // token tree to the last token. (No other token trees will be glued.)\n+    // Uses `make_mut` to maximize efficiency.\n+    pub fn push_stream(&mut self, stream: TokenStream) {\n+        let vec_mut = Lrc::make_mut(&mut self.0);\n+\n+        let stream_iter = stream.0.iter().cloned();\n+\n+        if let Some(first) = stream.0.first() && Self::try_glue_to_last(vec_mut, first) {\n+            // Now skip the first token tree from `stream`.\n+            vec_mut.extend(stream_iter.skip(1));\n+        } else {\n+            // Append all of `stream`.\n+            vec_mut.extend(stream_iter);\n         }\n     }\n }"}, {"sha": "cc2858d3f73a17d80a95147a4353501ca82cc5b4", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 63, "deletions": 63, "changes": 126, "blob_url": "https://github.com/rust-lang/rust/blob/2b91cbe2d4ce90d30520674876e9d700cf7a561b/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2b91cbe2d4ce90d30520674876e9d700cf7a561b/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=2b91cbe2d4ce90d30520674876e9d700cf7a561b", "patch": "@@ -1,5 +1,8 @@\n use crate::base::ExtCtxt;\n-\n+use pm::bridge::{\n+    server, DelimSpan, Diagnostic, ExpnGlobals, Group, Ident, LitKind, Literal, Punct, TokenTree,\n+};\n+use pm::{Delimiter, Level, LineColumn};\n use rustc_ast as ast;\n use rustc_ast::token;\n use rustc_ast::tokenstream::{self, Spacing::*, TokenStream};\n@@ -13,11 +16,7 @@ use rustc_session::parse::ParseSess;\n use rustc_span::def_id::CrateNum;\n use rustc_span::symbol::{self, sym, Symbol};\n use rustc_span::{BytePos, FileName, Pos, SourceFile, Span};\n-\n-use pm::bridge::{\n-    server, DelimSpan, Diagnostic, ExpnGlobals, Group, Ident, LitKind, Literal, Punct, TokenTree,\n-};\n-use pm::{Delimiter, Level, LineColumn};\n+use smallvec::{smallvec, SmallVec};\n use std::ops::Bound;\n \n trait FromInternal<T> {\n@@ -253,23 +252,57 @@ impl FromInternal<(TokenStream, &mut Rustc<'_, '_>)> for Vec<TokenTree<TokenStre\n     }\n }\n \n-impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rustc<'_, '_>) {\n-    fn to_internal(self) -> TokenStream {\n+// We use a `SmallVec` because the output size is always one or two `TokenTree`s.\n+impl ToInternal<SmallVec<[tokenstream::TokenTree; 2]>>\n+    for (TokenTree<TokenStream, Span, Symbol>, &mut Rustc<'_, '_>)\n+{\n+    fn to_internal(self) -> SmallVec<[tokenstream::TokenTree; 2]> {\n         use rustc_ast::token::*;\n \n         let (tree, rustc) = self;\n-        let (ch, joint, span) = match tree {\n-            TokenTree::Punct(Punct { ch, joint, span }) => (ch, joint, span),\n+        match tree {\n+            TokenTree::Punct(Punct { ch, joint, span }) => {\n+                let kind = match ch {\n+                    b'=' => Eq,\n+                    b'<' => Lt,\n+                    b'>' => Gt,\n+                    b'!' => Not,\n+                    b'~' => Tilde,\n+                    b'+' => BinOp(Plus),\n+                    b'-' => BinOp(Minus),\n+                    b'*' => BinOp(Star),\n+                    b'/' => BinOp(Slash),\n+                    b'%' => BinOp(Percent),\n+                    b'^' => BinOp(Caret),\n+                    b'&' => BinOp(And),\n+                    b'|' => BinOp(Or),\n+                    b'@' => At,\n+                    b'.' => Dot,\n+                    b',' => Comma,\n+                    b';' => Semi,\n+                    b':' => Colon,\n+                    b'#' => Pound,\n+                    b'$' => Dollar,\n+                    b'?' => Question,\n+                    b'\\'' => SingleQuote,\n+                    _ => unreachable!(),\n+                };\n+                smallvec![if joint {\n+                    tokenstream::TokenTree::token_joint(kind, span)\n+                } else {\n+                    tokenstream::TokenTree::token_alone(kind, span)\n+                }]\n+            }\n             TokenTree::Group(Group { delimiter, stream, span: DelimSpan { open, close, .. } }) => {\n-                return tokenstream::TokenStream::delimited(\n+                smallvec![tokenstream::TokenTree::Delimited(\n                     tokenstream::DelimSpan { open, close },\n                     delimiter.to_internal(),\n                     stream.unwrap_or_default(),\n-                );\n+                )]\n             }\n             TokenTree::Ident(self::Ident { sym, is_raw, span }) => {\n                 rustc.sess().symbol_gallery.insert(sym, span);\n-                return tokenstream::TokenStream::token_alone(Ident(sym, is_raw), span);\n+                smallvec![tokenstream::TokenTree::token_alone(Ident(sym, is_raw), span)]\n             }\n             TokenTree::Literal(self::Literal {\n                 kind: self::LitKind::Integer,\n@@ -282,7 +315,7 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n                 let integer = TokenKind::lit(token::Integer, symbol, suffix);\n                 let a = tokenstream::TokenTree::token_alone(minus, span);\n                 let b = tokenstream::TokenTree::token_alone(integer, span);\n-                return [a, b].into_iter().collect();\n+                smallvec![a, b]\n             }\n             TokenTree::Literal(self::Literal {\n                 kind: self::LitKind::Float,\n@@ -295,46 +328,14 @@ impl ToInternal<TokenStream> for (TokenTree<TokenStream, Span, Symbol>, &mut Rus\n                 let float = TokenKind::lit(token::Float, symbol, suffix);\n                 let a = tokenstream::TokenTree::token_alone(minus, span);\n                 let b = tokenstream::TokenTree::token_alone(float, span);\n-                return [a, b].into_iter().collect();\n+                smallvec![a, b]\n             }\n             TokenTree::Literal(self::Literal { kind, symbol, suffix, span }) => {\n-                return tokenstream::TokenStream::token_alone(\n+                smallvec![tokenstream::TokenTree::token_alone(\n                     TokenKind::lit(kind.to_internal(), symbol, suffix),\n                     span,\n-                );\n+                )]\n             }\n-        };\n-\n-        let kind = match ch {\n-            b'=' => Eq,\n-            b'<' => Lt,\n-            b'>' => Gt,\n-            b'!' => Not,\n-            b'~' => Tilde,\n-            b'+' => BinOp(Plus),\n-            b'-' => BinOp(Minus),\n-            b'*' => BinOp(Star),\n-            b'/' => BinOp(Slash),\n-            b'%' => BinOp(Percent),\n-            b'^' => BinOp(Caret),\n-            b'&' => BinOp(And),\n-            b'|' => BinOp(Or),\n-            b'@' => At,\n-            b'.' => Dot,\n-            b',' => Comma,\n-            b';' => Semi,\n-            b':' => Colon,\n-            b'#' => Pound,\n-            b'$' => Dollar,\n-            b'?' => Question,\n-            b'\\'' => SingleQuote,\n-            _ => unreachable!(),\n-        };\n-\n-        if joint {\n-            tokenstream::TokenStream::token_joint(kind, span)\n-        } else {\n-            tokenstream::TokenStream::token_alone(kind, span)\n         }\n     }\n }\n@@ -549,37 +550,35 @@ impl server::TokenStream for Rustc<'_, '_> {\n         &mut self,\n         tree: TokenTree<Self::TokenStream, Self::Span, Self::Symbol>,\n     ) -> Self::TokenStream {\n-        (tree, &mut *self).to_internal()\n+        Self::TokenStream::new((tree, &mut *self).to_internal().into_iter().collect::<Vec<_>>())\n     }\n \n     fn concat_trees(\n         &mut self,\n         base: Option<Self::TokenStream>,\n         trees: Vec<TokenTree<Self::TokenStream, Self::Span, Self::Symbol>>,\n     ) -> Self::TokenStream {\n-        let mut builder = tokenstream::TokenStreamBuilder::new();\n-        if let Some(base) = base {\n-            builder.push(base);\n-        }\n+        let mut stream =\n+            if let Some(base) = base { base } else { tokenstream::TokenStream::default() };\n         for tree in trees {\n-            builder.push((tree, &mut *self).to_internal());\n+            for tt in (tree, &mut *self).to_internal() {\n+                stream.push_tree(tt);\n+            }\n         }\n-        builder.build()\n+        stream\n     }\n \n     fn concat_streams(\n         &mut self,\n         base: Option<Self::TokenStream>,\n         streams: Vec<Self::TokenStream>,\n     ) -> Self::TokenStream {\n-        let mut builder = tokenstream::TokenStreamBuilder::new();\n-        if let Some(base) = base {\n-            builder.push(base);\n+        let mut stream =\n+            if let Some(base) = base { base } else { tokenstream::TokenStream::default() };\n+        for s in streams {\n+            stream.push_stream(s);\n         }\n-        for stream in streams {\n-            builder.push(stream);\n-        }\n-        builder.build()\n+        stream\n     }\n \n     fn into_trees(\n@@ -705,6 +704,7 @@ impl server::Span for Rustc<'_, '_> {\n     fn source_text(&mut self, span: Self::Span) -> Option<String> {\n         self.sess().source_map().span_to_snippet(span).ok()\n     }\n+\n     /// Saves the provided span into the metadata of\n     /// *the crate we are currently compiling*, which must\n     /// be a proc-macro crate. This id can be passed to"}, {"sha": "91c4dd732e3a5108b932988d8da821bdfafa8b58", "filename": "compiler/rustc_expand/src/tokenstream/tests.rs", "status": "modified", "additions": 8, "deletions": 10, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/2b91cbe2d4ce90d30520674876e9d700cf7a561b/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2b91cbe2d4ce90d30520674876e9d700cf7a561b/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Ftokenstream%2Ftests.rs?ref=2b91cbe2d4ce90d30520674876e9d700cf7a561b", "patch": "@@ -1,7 +1,7 @@\n use crate::tests::string_to_stream;\n \n use rustc_ast::token;\n-use rustc_ast::tokenstream::{TokenStream, TokenStreamBuilder};\n+use rustc_ast::tokenstream::{TokenStream, TokenTree};\n use rustc_span::create_default_session_globals_then;\n use rustc_span::{BytePos, Span, Symbol};\n \n@@ -19,10 +19,9 @@ fn test_concat() {\n         let test_res = string_to_ts(\"foo::bar::baz\");\n         let test_fst = string_to_ts(\"foo::bar\");\n         let test_snd = string_to_ts(\"::baz\");\n-        let mut builder = TokenStreamBuilder::new();\n-        builder.push(test_fst);\n-        builder.push(test_snd);\n-        let eq_res = builder.build();\n+        let mut eq_res = TokenStream::default();\n+        eq_res.push_stream(test_fst);\n+        eq_res.push_stream(test_snd);\n         assert_eq!(test_res.trees().count(), 5);\n         assert_eq!(eq_res.trees().count(), 5);\n         assert_eq!(test_res.eq_unspanned(&eq_res), true);\n@@ -99,11 +98,10 @@ fn test_is_empty() {\n #[test]\n fn test_dotdotdot() {\n     create_default_session_globals_then(|| {\n-        let mut builder = TokenStreamBuilder::new();\n-        builder.push(TokenStream::token_joint(token::Dot, sp(0, 1)));\n-        builder.push(TokenStream::token_joint(token::Dot, sp(1, 2)));\n-        builder.push(TokenStream::token_alone(token::Dot, sp(2, 3)));\n-        let stream = builder.build();\n+        let mut stream = TokenStream::default();\n+        stream.push_tree(TokenTree::token_joint(token::Dot, sp(0, 1)));\n+        stream.push_tree(TokenTree::token_joint(token::Dot, sp(1, 2)));\n+        stream.push_tree(TokenTree::token_alone(token::Dot, sp(2, 3)));\n         assert!(stream.eq_unspanned(&string_to_ts(\"...\")));\n         assert_eq!(stream.trees().count(), 1);\n     })"}, {"sha": "506b2a773cc49f997763493d0704d2fbed527ac1", "filename": "library/proc_macro/src/bridge/client.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/2b91cbe2d4ce90d30520674876e9d700cf7a561b/library%2Fproc_macro%2Fsrc%2Fbridge%2Fclient.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2b91cbe2d4ce90d30520674876e9d700cf7a561b/library%2Fproc_macro%2Fsrc%2Fbridge%2Fclient.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fproc_macro%2Fsrc%2Fbridge%2Fclient.rs?ref=2b91cbe2d4ce90d30520674876e9d700cf7a561b", "patch": "@@ -223,10 +223,10 @@ pub(crate) use super::symbol::Symbol;\n \n macro_rules! define_client_side {\n     ($($name:ident {\n-        $(fn $method:ident($($arg:ident: $arg_ty:ty),* $(,)?) $(-> $ret_ty:ty)*;)*\n+        $(fn $method:ident($($arg:ident: $arg_ty:ty),* $(,)?) $(-> $ret_ty:ty)?;)*\n     }),* $(,)?) => {\n         $(impl $name {\n-            $(pub(crate) fn $method($($arg: $arg_ty),*) $(-> $ret_ty)* {\n+            $(pub(crate) fn $method($($arg: $arg_ty),*) $(-> $ret_ty)? {\n                 Bridge::with(|bridge| {\n                     let mut buf = bridge.cached_buffer.take();\n "}]}