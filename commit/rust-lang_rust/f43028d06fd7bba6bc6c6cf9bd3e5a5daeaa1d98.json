{"sha": "f43028d06fd7bba6bc6c6cf9bd3e5a5daeaa1d98", "node_id": "C_kwDOAAsO6NoAKGY0MzAyOGQwNmZkN2JiYTZiYzZjNmNmOWJkM2U1YTVkYWVhYTFkOTg", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-03-18T06:13:41Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-03-18T06:22:34Z"}, "message": "Tweak a bunch of comments.\n\nI've been staring at these enough lately that they're annoying me, let's\nmake them better.", "tree": {"sha": "534fcba7fc4062736068365a61554d2a9bd54723", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/534fcba7fc4062736068365a61554d2a9bd54723"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f43028d06fd7bba6bc6c6cf9bd3e5a5daeaa1d98", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f43028d06fd7bba6bc6c6cf9bd3e5a5daeaa1d98", "html_url": "https://github.com/rust-lang/rust/commit/f43028d06fd7bba6bc6c6cf9bd3e5a5daeaa1d98", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f43028d06fd7bba6bc6c6cf9bd3e5a5daeaa1d98/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "14875a55640341b07c9f5f264ba0d5b531e80023", "url": "https://api.github.com/repos/rust-lang/rust/commits/14875a55640341b07c9f5f264ba0d5b531e80023", "html_url": "https://github.com/rust-lang/rust/commit/14875a55640341b07c9f5f264ba0d5b531e80023"}], "stats": {"total": 98, "additions": 36, "deletions": 62}, "files": [{"sha": "b45c701bbb296ca1f8fefa94e08d78a5a92846a0", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 36, "deletions": 62, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/f43028d06fd7bba6bc6c6cf9bd3e5a5daeaa1d98/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f43028d06fd7bba6bc6c6cf9bd3e5a5daeaa1d98/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=f43028d06fd7bba6bc6c6cf9bd3e5a5daeaa1d98", "patch": "@@ -490,7 +490,7 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n }\n \n /// Process the matcher positions of `cur_items` until it is empty. In the process, this will\n-/// produce more items in `next_items`, `eof_items`, and `bb_items`.\n+/// produce more items in `next_items` and `bb_items`.\n ///\n /// For more info about the how this happens, see the module-level doc comments and the inline\n /// comments of this function.\n@@ -520,11 +520,10 @@ fn parse_tt_inner<'root, 'tt>(\n     // `token == Eof`.\n     let mut eof_items = EofItems::None;\n \n-    // Pop items from `cur_items` until it is empty.\n     while let Some(mut item) = cur_items.pop() {\n         // When unzipped trees end, remove them. This corresponds to backtracking out of a\n-        // delimited submatcher into which we already descended. In backtracking out again, we need\n-        // to advance the \"dot\" past the delimiters in the outer matcher.\n+        // delimited submatcher into which we already descended. When backtracking out again, we\n+        // need to advance the \"dot\" past the delimiters in the outer matcher.\n         while item.idx >= item.top_elts.len() {\n             match item.stack.pop() {\n                 Some(MatcherTtFrame { elts, idx }) => {\n@@ -541,19 +540,12 @@ fn parse_tt_inner<'root, 'tt>(\n         let len = item.top_elts.len();\n \n         if idx < len {\n-            // We are in the middle of a matcher. Look at what token in the matcher we are trying\n-            // to match the current token (`token`) against. Depending on that, we may generate new\n-            // items.\n+            // We are in the middle of a matcher. Compare the matcher's current tt against `token`.\n             match item.top_elts.get_tt(idx) {\n-                // Need to descend into a sequence\n                 TokenTree::Sequence(sp, seq) => {\n-                    // Examine the case where there are 0 matches of this sequence. We are\n-                    // implicitly disallowing OneOrMore from having 0 matches here. Thus, that will\n-                    // result in a \"no rules expected token\" error by virtue of this matcher not\n-                    // working.\n-                    if seq.kleene.op == mbe::KleeneOp::ZeroOrMore\n-                        || seq.kleene.op == mbe::KleeneOp::ZeroOrOne\n-                    {\n+                    let op = seq.kleene.op;\n+                    if op == mbe::KleeneOp::ZeroOrMore || op == mbe::KleeneOp::ZeroOrOne {\n+                        // Allow for the possibility of zero matches of this sequence.\n                         let mut new_item = item.clone();\n                         new_item.match_cur += seq.num_captures;\n                         new_item.idx += 1;\n@@ -563,20 +555,19 @@ fn parse_tt_inner<'root, 'tt>(\n                         cur_items.push(new_item);\n                     }\n \n+                    // Allow for the possibility of one or more matches of this sequence.\n                     cur_items.push(MatcherPosHandle::Box(Box::new(MatcherPos::repetition(\n                         item, sp, seq,\n                     ))));\n                 }\n \n-                // We need to match a metavar (but the identifier is invalid)... this is an error\n                 TokenTree::MetaVarDecl(span, _, None) => {\n+                    // E.g. `$e` instead of `$e:expr`.\n                     if sess.missing_fragment_specifiers.borrow_mut().remove(&span).is_some() {\n                         return Some(Error(span, \"missing fragment specifier\".to_string()));\n                     }\n                 }\n \n-                // We need to match a metavar with a valid ident... call out to the black-box\n-                // parser by adding an item to `bb_items`.\n                 TokenTree::MetaVarDecl(_, _, Some(kind)) => {\n                     // Built-in nonterminals never start with these tokens, so we can eliminate\n                     // them from consideration.\n@@ -588,69 +579,57 @@ fn parse_tt_inner<'root, 'tt>(\n                     }\n                 }\n \n-                // We need to descend into a delimited submatcher or a doc comment. To do this, we\n-                // push the current matcher onto a stack and push a new item containing the\n-                // submatcher onto `cur_items`.\n-                //\n-                // At the beginning of the loop, if we reach the end of the delimited submatcher,\n-                // we pop the stack to backtrack out of the descent.\n                 seq @ (TokenTree::Delimited(..)\n                 | TokenTree::Token(Token { kind: DocComment(..), .. })) => {\n+                    // To descend into a delimited submatcher or a doc comment, we push the current\n+                    // matcher onto a stack and push a new item containing the submatcher onto\n+                    // `cur_items`.\n+                    //\n+                    // At the beginning of the loop, if we reach the end of the delimited\n+                    // submatcher, we pop the stack to backtrack out of the descent.\n                     let lower_elts = mem::replace(&mut item.top_elts, Tt(seq));\n                     let idx = item.idx;\n                     item.stack.push(MatcherTtFrame { elts: lower_elts, idx });\n                     item.idx = 0;\n                     cur_items.push(item);\n                 }\n \n-                // We just matched a normal token. We can just advance the parser.\n-                TokenTree::Token(t) if token_name_eq(&t, token) => {\n-                    item.idx += 1;\n-                    next_items.push(item);\n+                TokenTree::Token(t) => {\n+                    // If the token matches, we can just advance the parser. Otherwise, this match\n+                    // hash failed, there is nothing to do, and hopefully another item in\n+                    // `cur_items` will match.\n+                    if token_name_eq(&t, token) {\n+                        item.idx += 1;\n+                        next_items.push(item);\n+                    }\n                 }\n \n-                // There was another token that was not `token`... This means we can't add any\n-                // rules. NOTE that this is not necessarily an error unless _all_ items in\n-                // `cur_items` end up doing this. There may still be some other matchers that do\n-                // end up working out.\n-                TokenTree::Token(..) => {}\n-\n+                // These cannot appear in a matcher.\n                 TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n             }\n         } else if let Some(repetition) = &item.repetition {\n             // We are past the end of a repetition.\n             debug_assert!(idx <= len + 1);\n             debug_assert!(matches!(item.top_elts, Tt(TokenTree::Sequence(..))));\n \n-            // At this point, regardless of whether there is a separator, we should add all\n-            // matches from the complete repetition of the sequence to the shared, top-level\n-            // `matches` list (actually, `up.matches`, which could itself not be the top-level,\n-            // but anyway...). Moreover, we add another item to `cur_items` in which the \"dot\"\n-            // is at the end of the `up` matcher. This ensures that the \"dot\" in the `up`\n-            // matcher is also advanced sufficiently.\n-            //\n-            // NOTE: removing the condition `idx == len` allows trailing separators.\n             if idx == len {\n-                // Get the `up` matcher\n+                // Add all matches from the sequence to `up`, and move the \"dot\" past the\n+                // repetition in `up`. This allows for the case where the sequence matching is\n+                // finished.\n                 let mut new_pos = repetition.up.clone();\n-\n-                // Add matches from this repetition to the `matches` of `up`\n                 for idx in item.match_lo..item.match_hi {\n                     let sub = item.matches[idx].clone();\n                     new_pos.push_match(idx, MatchedSeq(sub));\n                 }\n-\n-                // Move the \"dot\" past the repetition in `up`\n                 new_pos.match_cur = item.match_hi;\n                 new_pos.idx += 1;\n                 cur_items.push(new_pos);\n             }\n \n-            // Check if we need a separator.\n             if idx == len && repetition.sep.is_some() {\n-                // We have a separator, and it is the current token. We can advance past the\n-                // separator token.\n                 if repetition.sep.as_ref().map_or(false, |sep| token_name_eq(token, sep)) {\n+                    // The matcher has a separator, and it matches the current token. We can\n+                    // advance past the separator token.\n                     item.idx += 1;\n                     next_items.push(item);\n                 }\n@@ -674,8 +653,8 @@ fn parse_tt_inner<'root, 'tt>(\n         }\n     }\n \n-    // If we reached the EOF, check that there is EXACTLY ONE possible matcher. Otherwise,\n-    // either the parse is ambiguous (which should never happen) or there is a syntax error.\n+    // If we reached the end of input, check that there is EXACTLY ONE possible matcher. Otherwise,\n+    // either the parse is ambiguous (which is an error) or there is a syntax error.\n     if *token == token::Eof {\n         Some(match eof_items {\n             EofItems::One(mut eof_item) => {\n@@ -712,20 +691,19 @@ pub(super) fn parse_tt(\n     // `next_items`. After some post-processing, the contents of `next_items` replenish `cur_items`\n     // and we start over again.\n     //\n-    // This MatcherPos instance is allocated on the stack. All others -- and\n-    // there are frequently *no* others! -- are allocated on the heap.\n+    // This MatcherPos instance is allocated on the stack. All others -- and there are frequently\n+    // *no* others! -- are allocated on the heap.\n     let mut initial = MatcherPos::new(ms);\n     let mut cur_items = smallvec![MatcherPosHandle::Ref(&mut initial)];\n \n     loop {\n         let mut next_items = SmallVec::new();\n \n-        // Matcher positions black-box parsed by parser.rs (`parser`)\n+        // Matcher positions black-box parsed by `Parser`.\n         let mut bb_items = SmallVec::new();\n \n         // Process `cur_items` until either we have finished the input or we need to get some\n-        // parsing from the black-box parser done. The result is that `next_items` will contain a\n-        // bunch of possible next matcher positions in `next_items`.\n+        // parsing from the black-box parser done.\n         if let Some(result) = parse_tt_inner(\n             parser.sess,\n             ms,\n@@ -740,10 +718,7 @@ pub(super) fn parse_tt(\n         // `parse_tt_inner` handled all cur_items, so it's empty.\n         assert!(cur_items.is_empty());\n \n-        // We need to do some post processing after the `parse_tt_inner`.\n-        //\n         // Error messages here could be improved with links to original rules.\n-\n         match (next_items.len(), bb_items.len()) {\n             (0, 0) => {\n                 // There are no possible next positions AND we aren't waiting for the black-box\n@@ -787,8 +762,7 @@ pub(super) fn parse_tt(\n             }\n \n             (_, _) => {\n-                // We need to call the black-box parser to get some nonterminal, but something is\n-                // wrong.\n+                // Too many possibilities!\n                 return bb_items_ambiguity_error(\n                     macro_name,\n                     next_items,"}]}