{"sha": "f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "node_id": "C_kwDOAAsO6NoAKGY0YmE2NGVlMmEwNWYzYTM4NDU4YTRhMTBkZmQ1OWVlZTlmZDJhMTY", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-10-28T10:32:13Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-10-28T10:32:13Z"}, "message": "Merge #10623\n\n10623: internal: replace L_DOLLAR/R_DOLLAR with parenthesis hack r=matklad a=matklad\n\nThe general problem we are dealing with here is this:\r\n\r\n```\r\nmacro_rules! thrice {\r\n    ($e:expr) => { $e * 3}\r\n}\r\n\r\nfn main() {\r\n    let x = thrice!(1 + 2);\r\n}\r\n```\r\n\r\nwe really want this to print 9 rather than 7.\r\n\r\nThe way rustc solves this is rather ad-hoc. In rustc, token trees are\r\nallowed to include whole AST fragments, so 1+2 is passed through macro\r\nexpansion as a single unit. This is a significant violation of token\r\ntree model.\r\n\r\nIn rust-analyzer, we intended to handle this in a more elegant way,\r\nusing token trees with \"invisible\" delimiters. The idea was is that we\r\nintroduce a new kind of parenthesis, \"left $\"/\"right $\", and let the\r\nparser intelligently handle this.\r\n\r\nThe idea was inspired by the relevant comment in the proc_macro crate:\r\n\r\nhttps://doc.rust-lang.org/stable/proc_macro/enum.Delimiter.html#variant.None\r\n\r\n> An implicit delimiter, that may, for example, appear around tokens\r\n> coming from a \u201cmacro variable\u201d $var. It is important to preserve\r\n> operator priorities in cases like $var * 3 where $var is 1 + 2.\r\n> Implicit delimiters might not survive roundtrip of a token stream\r\n> through a string.\r\n\r\nNow that we are older and wiser, we conclude that the idea doesn't work.\r\n\r\n_First_, the comment in the proc-macro crate is wishful thinking. Rustc\r\ncurrently completely ignores none delimiters. It solves the (1 + 2) * 3\r\nproblem by having magical token trees which can't be duplicated:\r\n\r\n* https://rust-lang.zulipchat.com/#narrow/stream/185405-t-compiler.2Frust-analyzer/topic/TIL.20that.20token.20streams.20are.20magic\r\n* https://rust-lang.zulipchat.com/#narrow/stream/131828-t-compiler/topic/Handling.20of.20Delimiter.3A.3ANone.20by.20the.20parser\r\n\r\n_Second_, it's not like our implementation in rust-analyzer works. We\r\nspecial-case expressions (as opposed to treating all kinds of $var\r\ncaptures the same) and we don't know how parser error recovery should\r\nwork with these dollar-parenthesis.\r\n\r\nSo, in this PR we simplify the whole thing away by not pretending that\r\nwe are doing something proper and instead just explicitly special-casing\r\nexpressions by wrapping them into real `()`.\r\n\r\nIn the future, to maintain bug-parity with `rustc` what we are going to\r\ndo is probably adding an explicit `CAPTURED_EXPR` *token* which we can\r\nexplicitly account for in the parser.\r\n\r\nIf/when rustc starts handling delimiter=none properly, we'll port that\r\nlogic as well, in addition to special handling.\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>", "tree": {"sha": "a68e10e2a38433f4a0acbed8fde467bad5f01698", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a68e10e2a38433f4a0acbed8fde467bad5f01698"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJhenwtCRBK7hj4Ov3rIwAALckIAAmBte7FkXFMpob+tXpWOttc\n0m5+s3x1t4e4g5/l3wua/8K8ZjEHRyLfJmbefXmKB/V6lYwqi2wnOmsrukltSFfr\nRDkAYGbMP50JHPJOT6b7QrTP3i3Zmp920r2AbIVGq2GzjDNKIK52LGrtrJ5iomfX\nwaIcIcVljagEVpVRRJE6wAcehxYx2D1HbYYb0Avgth3SYLobKuAEcSn4cZAInM2A\nf81smoe25dvmeH92EuXyiJDDfL83JXI4DAUBKI5MRFdVz5Wii4YYwjfU06ktiGl+\nG8BlAs4hHcg9oVG7pnP+qN7GV9vAgS3BZ7qjUQEckbewzS2W9KaVqpne573uqgc=\n=4tTT\n-----END PGP SIGNATURE-----\n", "payload": "tree a68e10e2a38433f4a0acbed8fde467bad5f01698\nparent 210a1d5ece776320ab4a36c25d0442a197939aa9\nparent 485c5e67173e444bcb8eeef14c413a7030f6b875\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1635417133 +0000\ncommitter GitHub <noreply@github.com> 1635417133 +0000\n\nMerge #10623\n\n10623: internal: replace L_DOLLAR/R_DOLLAR with parenthesis hack r=matklad a=matklad\n\nThe general problem we are dealing with here is this:\r\n\r\n```\r\nmacro_rules! thrice {\r\n    ($e:expr) => { $e * 3}\r\n}\r\n\r\nfn main() {\r\n    let x = thrice!(1 + 2);\r\n}\r\n```\r\n\r\nwe really want this to print 9 rather than 7.\r\n\r\nThe way rustc solves this is rather ad-hoc. In rustc, token trees are\r\nallowed to include whole AST fragments, so 1+2 is passed through macro\r\nexpansion as a single unit. This is a significant violation of token\r\ntree model.\r\n\r\nIn rust-analyzer, we intended to handle this in a more elegant way,\r\nusing token trees with \"invisible\" delimiters. The idea was is that we\r\nintroduce a new kind of parenthesis, \"left $\"/\"right $\", and let the\r\nparser intelligently handle this.\r\n\r\nThe idea was inspired by the relevant comment in the proc_macro crate:\r\n\r\nhttps://doc.rust-lang.org/stable/proc_macro/enum.Delimiter.html#variant.None\r\n\r\n> An implicit delimiter, that may, for example, appear around tokens\r\n> coming from a \u201cmacro variable\u201d $var. It is important to preserve\r\n> operator priorities in cases like $var * 3 where $var is 1 + 2.\r\n> Implicit delimiters might not survive roundtrip of a token stream\r\n> through a string.\r\n\r\nNow that we are older and wiser, we conclude that the idea doesn't work.\r\n\r\n_First_, the comment in the proc-macro crate is wishful thinking. Rustc\r\ncurrently completely ignores none delimiters. It solves the (1 + 2) * 3\r\nproblem by having magical token trees which can't be duplicated:\r\n\r\n* https://rust-lang.zulipchat.com/#narrow/stream/185405-t-compiler.2Frust-analyzer/topic/TIL.20that.20token.20streams.20are.20magic\r\n* https://rust-lang.zulipchat.com/#narrow/stream/131828-t-compiler/topic/Handling.20of.20Delimiter.3A.3ANone.20by.20the.20parser\r\n\r\n_Second_, it's not like our implementation in rust-analyzer works. We\r\nspecial-case expressions (as opposed to treating all kinds of $var\r\ncaptures the same) and we don't know how parser error recovery should\r\nwork with these dollar-parenthesis.\r\n\r\nSo, in this PR we simplify the whole thing away by not pretending that\r\nwe are doing something proper and instead just explicitly special-casing\r\nexpressions by wrapping them into real `()`.\r\n\r\nIn the future, to maintain bug-parity with `rustc` what we are going to\r\ndo is probably adding an explicit `CAPTURED_EXPR` *token* which we can\r\nexplicitly account for in the parser.\r\n\r\nIf/when rustc starts handling delimiter=none properly, we'll port that\r\nlogic as well, in addition to special handling.\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "html_url": "https://github.com/rust-lang/rust/commit/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "210a1d5ece776320ab4a36c25d0442a197939aa9", "url": "https://api.github.com/repos/rust-lang/rust/commits/210a1d5ece776320ab4a36c25d0442a197939aa9", "html_url": "https://github.com/rust-lang/rust/commit/210a1d5ece776320ab4a36c25d0442a197939aa9"}, {"sha": "485c5e67173e444bcb8eeef14c413a7030f6b875", "url": "https://api.github.com/repos/rust-lang/rust/commits/485c5e67173e444bcb8eeef14c413a7030f6b875", "html_url": "https://github.com/rust-lang/rust/commit/485c5e67173e444bcb8eeef14c413a7030f6b875"}], "stats": {"total": 353, "additions": 170, "deletions": 183}, "files": [{"sha": "953750d36052cf9710dda36b7ed25dc6a416c05a", "filename": "crates/hir_def/src/macro_expansion_tests/mbe.rs", "status": "modified", "additions": 51, "deletions": 42, "changes": 93, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fhir_def%2Fsrc%2Fmacro_expansion_tests%2Fmbe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fhir_def%2Fsrc%2Fmacro_expansion_tests%2Fmbe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_def%2Fsrc%2Fmacro_expansion_tests%2Fmbe.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -317,32 +317,35 @@ macro_rules! m {\n     ($ i:expr) => { fn bar() { $ i * 3; } }\n }\n fn bar() {\n-    1+2*3;\n+    (1+2)*3;\n }\n-// MACRO_ITEMS@0..15\n-//   FN@0..15\n+// MACRO_ITEMS@0..17\n+//   FN@0..17\n //     FN_KW@0..2 \"fn\"\n //     NAME@2..5\n //       IDENT@2..5 \"bar\"\n //     PARAM_LIST@5..7\n //       L_PAREN@5..6 \"(\"\n //       R_PAREN@6..7 \")\"\n-//     BLOCK_EXPR@7..15\n-//       STMT_LIST@7..15\n+//     BLOCK_EXPR@7..17\n+//       STMT_LIST@7..17\n //         L_CURLY@7..8 \"{\"\n-//         EXPR_STMT@8..14\n-//           BIN_EXPR@8..13\n-//             BIN_EXPR@8..11\n-//               LITERAL@8..9\n-//                 INT_NUMBER@8..9 \"1\"\n-//               PLUS@9..10 \"+\"\n-//               LITERAL@10..11\n-//                 INT_NUMBER@10..11 \"2\"\n-//             STAR@11..12 \"*\"\n-//             LITERAL@12..13\n-//               INT_NUMBER@12..13 \"3\"\n-//           SEMICOLON@13..14 \";\"\n-//         R_CURLY@14..15 \"}\"\n+//         EXPR_STMT@8..16\n+//           BIN_EXPR@8..15\n+//             PAREN_EXPR@8..13\n+//               L_PAREN@8..9 \"(\"\n+//               BIN_EXPR@9..12\n+//                 LITERAL@9..10\n+//                   INT_NUMBER@9..10 \"1\"\n+//                 PLUS@10..11 \"+\"\n+//                 LITERAL@11..12\n+//                   INT_NUMBER@11..12 \"2\"\n+//               R_PAREN@12..13 \")\"\n+//             STAR@13..14 \"*\"\n+//             LITERAL@14..15\n+//               INT_NUMBER@14..15 \"3\"\n+//           SEMICOLON@15..16 \";\"\n+//         R_CURLY@16..17 \"}\"\n \n \"#]],\n     )\n@@ -722,7 +725,7 @@ macro_rules! m {\n }\n \n fn bar() {\n-    2+2*baz(3).quux();\n+    (2+2*baz(3).quux());\n }\n \"#]],\n     )\n@@ -1370,42 +1373,48 @@ macro_rules! m {\n }\n /* parse error: expected identifier */\n /* parse error: expected SEMICOLON */\n+/* parse error: expected SEMICOLON */\n+/* parse error: expected expression */\n fn f() {\n-    K::C(\"0\");\n+    K::(C(\"0\"));\n }\n-// MACRO_ITEMS@0..17\n-//   FN@0..17\n+// MACRO_ITEMS@0..19\n+//   FN@0..19\n //     FN_KW@0..2 \"fn\"\n //     NAME@2..3\n //       IDENT@2..3 \"f\"\n //     PARAM_LIST@3..5\n //       L_PAREN@3..4 \"(\"\n //       R_PAREN@4..5 \")\"\n-//     BLOCK_EXPR@5..17\n-//       STMT_LIST@5..17\n+//     BLOCK_EXPR@5..19\n+//       STMT_LIST@5..19\n //         L_CURLY@5..6 \"{\"\n-//         EXPR_STMT@6..9\n-//           PATH_EXPR@6..9\n-//             PATH@6..9\n+//         EXPR_STMT@6..10\n+//           PATH_EXPR@6..10\n+//             PATH@6..10\n //               PATH@6..7\n //                 PATH_SEGMENT@6..7\n //                   NAME_REF@6..7\n //                     IDENT@6..7 \"K\"\n //               COLON2@7..9 \"::\"\n-//         EXPR_STMT@9..16\n-//           CALL_EXPR@9..15\n-//             PATH_EXPR@9..10\n-//               PATH@9..10\n-//                 PATH_SEGMENT@9..10\n-//                   NAME_REF@9..10\n-//                     IDENT@9..10 \"C\"\n-//             ARG_LIST@10..15\n-//               L_PAREN@10..11 \"(\"\n-//               LITERAL@11..14\n-//                 STRING@11..14 \"\\\"0\\\"\"\n-//               R_PAREN@14..15 \")\"\n-//           SEMICOLON@15..16 \";\"\n-//         R_CURLY@16..17 \"}\"\n+//               ERROR@9..10\n+//                 L_PAREN@9..10 \"(\"\n+//         EXPR_STMT@10..16\n+//           CALL_EXPR@10..16\n+//             PATH_EXPR@10..11\n+//               PATH@10..11\n+//                 PATH_SEGMENT@10..11\n+//                   NAME_REF@10..11\n+//                     IDENT@10..11 \"C\"\n+//             ARG_LIST@11..16\n+//               L_PAREN@11..12 \"(\"\n+//               LITERAL@12..15\n+//                 STRING@12..15 \"\\\"0\\\"\"\n+//               R_PAREN@15..16 \")\"\n+//         ERROR@16..17\n+//           R_PAREN@16..17 \")\"\n+//         SEMICOLON@17..18 \";\"\n+//         R_CURLY@18..19 \"}\"\n \n \"#]],\n     );\n@@ -1441,7 +1450,7 @@ fn f() {\n         expect![[r#\"\n macro_rules! m { ($expr:expr) => { map($expr) } }\n fn f() {\n-    let _ = map(x+foo);\n+    let _ = map((x+foo));\n }\n \"#]],\n     )"}, {"sha": "2dff4adf2ee804b538fe612a4cee8af4570705ae", "filename": "crates/hir_def/src/macro_expansion_tests/mbe/regression.rs", "status": "modified", "additions": 34, "deletions": 25, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fhir_def%2Fsrc%2Fmacro_expansion_tests%2Fmbe%2Fregression.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fhir_def%2Fsrc%2Fmacro_expansion_tests%2Fmbe%2Fregression.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_def%2Fsrc%2Fmacro_expansion_tests%2Fmbe%2Fregression.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -825,15 +825,18 @@ macro_rules! rgb_color {\n     };\n }\n /* parse error: expected type */\n+/* parse error: expected R_PAREN */\n /* parse error: expected R_ANGLE */\n /* parse error: expected COMMA */\n /* parse error: expected R_ANGLE */\n /* parse error: expected SEMICOLON */\n+/* parse error: expected SEMICOLON */\n+/* parse error: expected expression */\n pub fn new() {\n-    let _ = 0as u32<<8+8;\n+    let _ = 0as u32<<(8+8);\n }\n-// MACRO_ITEMS@0..29\n-//   FN@0..29\n+// MACRO_ITEMS@0..31\n+//   FN@0..31\n //     VISIBILITY@0..3\n //       PUB_KW@0..3 \"pub\"\n //     FN_KW@3..5 \"fn\"\n@@ -842,39 +845,45 @@ pub fn new() {\n //     PARAM_LIST@8..10\n //       L_PAREN@8..9 \"(\"\n //       R_PAREN@9..10 \")\"\n-//     BLOCK_EXPR@10..29\n-//       STMT_LIST@10..29\n+//     BLOCK_EXPR@10..31\n+//       STMT_LIST@10..31\n //         L_CURLY@10..11 \"{\"\n-//         LET_STMT@11..24\n+//         LET_STMT@11..27\n //           LET_KW@11..14 \"let\"\n //           WILDCARD_PAT@14..15\n //             UNDERSCORE@14..15 \"_\"\n //           EQ@15..16 \"=\"\n-//           CAST_EXPR@16..24\n+//           CAST_EXPR@16..27\n //             LITERAL@16..17\n //               INT_NUMBER@16..17 \"0\"\n //             AS_KW@17..19 \"as\"\n-//             PATH_TYPE@19..24\n-//               PATH@19..24\n-//                 PATH_SEGMENT@19..24\n+//             PATH_TYPE@19..27\n+//               PATH@19..27\n+//                 PATH_SEGMENT@19..27\n //                   NAME_REF@19..22\n //                     IDENT@19..22 \"u32\"\n-//                   GENERIC_ARG_LIST@22..24\n+//                   GENERIC_ARG_LIST@22..27\n //                     L_ANGLE@22..23 \"<\"\n-//                     TYPE_ARG@23..24\n-//                       PATH_TYPE@23..24\n-//                         PATH@23..24\n-//                           PATH_SEGMENT@23..24\n-//                             L_ANGLE@23..24 \"<\"\n-//         EXPR_STMT@24..28\n-//           BIN_EXPR@24..27\n-//             LITERAL@24..25\n-//               INT_NUMBER@24..25 \"8\"\n-//             PLUS@25..26 \"+\"\n-//             LITERAL@26..27\n-//               INT_NUMBER@26..27 \"8\"\n-//           SEMICOLON@27..28 \";\"\n-//         R_CURLY@28..29 \"}\"\n+//                     TYPE_ARG@23..27\n+//                       DYN_TRAIT_TYPE@23..27\n+//                         TYPE_BOUND_LIST@23..27\n+//                           TYPE_BOUND@23..26\n+//                             PATH_TYPE@23..26\n+//                               PATH@23..26\n+//                                 PATH_SEGMENT@23..26\n+//                                   L_ANGLE@23..24 \"<\"\n+//                                   PAREN_TYPE@24..26\n+//                                     L_PAREN@24..25 \"(\"\n+//                                     ERROR@25..26\n+//                                       INT_NUMBER@25..26 \"8\"\n+//                           PLUS@26..27 \"+\"\n+//         EXPR_STMT@27..28\n+//           LITERAL@27..28\n+//             INT_NUMBER@27..28 \"8\"\n+//         ERROR@28..29\n+//           R_PAREN@28..29 \")\"\n+//         SEMICOLON@29..30 \";\"\n+//         R_CURLY@30..31 \"}\"\n \n \"#]],\n     );"}, {"sha": "1e1bfa55055831a2fa2b8cb9affaa2c2f3e5a06e", "filename": "crates/mbe/src/expander.rs", "status": "modified", "additions": 8, "deletions": 3, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fexpander.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fexpander.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fexpander.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -110,7 +110,12 @@ enum Binding {\n enum Fragment {\n     /// token fragments are just copy-pasted into the output\n     Tokens(tt::TokenTree),\n-    /// Ast fragments are inserted with fake delimiters, so as to make things\n-    /// like `$i * 2` where `$i = 1 + 1` work as expectd.\n-    Ast(tt::TokenTree),\n+    /// Expr ast fragments are surrounded with `()` on insertion to preserve\n+    /// precedence. Note that this impl is different from the one currently in\n+    /// `rustc` -- `rustc` doesn't translate fragments into token trees at all.\n+    ///\n+    /// At one point in time, we tried to to use \"fake\" delimiters here a-la\n+    /// proc-macro delimiter=none. As we later discovered, \"none\" delimiters are\n+    /// tricky to handle in the parser, and rustc doesn't handle those either.\n+    Expr(tt::TokenTree),\n }"}, {"sha": "b2d3f038f544a558d04d239a88cd1a7886fac6b0", "filename": "crates/mbe/src/expander/matcher.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fexpander%2Fmatcher.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fexpander%2Fmatcher.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fexpander%2Fmatcher.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -736,7 +736,7 @@ fn match_meta_var(kind: &str, input: &mut TtIter) -> ExpandResult<Option<Fragmen\n         }\n     };\n     let result = input.expect_fragment(fragment);\n-    result.map(|tt| if kind == \"expr\" { tt.map(Fragment::Ast) } else { tt.map(Fragment::Tokens) })\n+    result.map(|tt| if kind == \"expr\" { tt.map(Fragment::Expr) } else { tt.map(Fragment::Tokens) })\n }\n \n fn collect_vars(buf: &mut Vec<SmolStr>, pattern: &MetaTemplate) {"}, {"sha": "0db17fea6e4e2d9f59b430387130b30151d50823", "filename": "crates/mbe/src/expander/transcriber.rs", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fexpander%2Ftranscriber.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fexpander%2Ftranscriber.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fexpander%2Ftranscriber.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -238,7 +238,16 @@ fn expand_repeat(\n fn push_fragment(buf: &mut Vec<tt::TokenTree>, fragment: Fragment) {\n     match fragment {\n         Fragment::Tokens(tt::TokenTree::Subtree(tt)) => push_subtree(buf, tt),\n-        Fragment::Tokens(tt) | Fragment::Ast(tt) => buf.push(tt),\n+        Fragment::Expr(tt::TokenTree::Subtree(mut tt)) => {\n+            if tt.delimiter.is_none() {\n+                tt.delimiter = Some(tt::Delimiter {\n+                    id: tt::TokenId::unspecified(),\n+                    kind: tt::DelimiterKind::Parenthesis,\n+                })\n+            }\n+            buf.push(tt.into())\n+        }\n+        Fragment::Tokens(tt) | Fragment::Expr(tt) => buf.push(tt),\n     }\n }\n "}, {"sha": "6bdd787e301adca61bf26bc0e1f3cc06f77707d2", "filename": "crates/mbe/src/subtree_source.rs", "status": "modified", "additions": 15, "deletions": 13, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsubtree_source.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -52,17 +52,20 @@ impl<'a> SubtreeTokenSource {\n                     cursor.bump()\n                 }\n                 Some(tt::buffer::TokenTreeRef::Subtree(subtree, _)) => {\n-                    cached.push(convert_delim(subtree.delimiter_kind(), false));\n+                    if let Some(d) = subtree.delimiter_kind() {\n+                        cached.push(convert_delim(d, false));\n+                    }\n                     cursor.subtree().unwrap()\n                 }\n-                None => {\n-                    if let Some(subtree) = cursor.end() {\n-                        cached.push(convert_delim(subtree.delimiter_kind(), true));\n+                None => match cursor.end() {\n+                    Some(subtree) => {\n+                        if let Some(d) = subtree.delimiter_kind() {\n+                            cached.push(convert_delim(d, true));\n+                        }\n                         cursor.bump()\n-                    } else {\n-                        continue;\n                     }\n-                }\n+                    None => continue,\n+                },\n             };\n         }\n \n@@ -109,17 +112,16 @@ impl<'a> TokenSource for SubtreeTokenSource {\n     }\n }\n \n-fn convert_delim(d: Option<tt::DelimiterKind>, closing: bool) -> TtToken {\n+fn convert_delim(d: tt::DelimiterKind, closing: bool) -> TtToken {\n     let (kinds, texts) = match d {\n-        Some(tt::DelimiterKind::Parenthesis) => ([T!['('], T![')']], \"()\"),\n-        Some(tt::DelimiterKind::Brace) => ([T!['{'], T!['}']], \"{}\"),\n-        Some(tt::DelimiterKind::Bracket) => ([T!['['], T![']']], \"[]\"),\n-        None => ([L_DOLLAR, R_DOLLAR], \"\"),\n+        tt::DelimiterKind::Parenthesis => ([T!['('], T![')']], \"()\"),\n+        tt::DelimiterKind::Brace => ([T!['{'], T!['}']], \"{}\"),\n+        tt::DelimiterKind::Bracket => ([T!['['], T![']']], \"[]\"),\n     };\n \n     let idx = closing as usize;\n     let kind = kinds[idx];\n-    let text = if !texts.is_empty() { &texts[idx..texts.len() - (1 - idx)] } else { \"\" };\n+    let text = &texts[idx..texts.len() - (1 - idx)];\n     TtToken { tt: Token { kind, is_jointed_to_next: false }, text: SmolStr::new(text) }\n }\n "}, {"sha": "0b65fa171f41137e566d6f546d193b807a34b422", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 46, "deletions": 45, "changes": 91, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -632,12 +632,11 @@ impl<'a> TtTreeSink<'a> {\n     }\n }\n \n-fn delim_to_str(d: Option<tt::DelimiterKind>, closing: bool) -> &'static str {\n+fn delim_to_str(d: tt::DelimiterKind, closing: bool) -> &'static str {\n     let texts = match d {\n-        Some(tt::DelimiterKind::Parenthesis) => \"()\",\n-        Some(tt::DelimiterKind::Brace) => \"{}\",\n-        Some(tt::DelimiterKind::Bracket) => \"[]\",\n-        None => return \"\",\n+        tt::DelimiterKind::Parenthesis => \"()\",\n+        tt::DelimiterKind::Brace => \"{}\",\n+        tt::DelimiterKind::Bracket => \"[]\",\n     };\n \n     let idx = closing as usize;\n@@ -646,10 +645,6 @@ fn delim_to_str(d: Option<tt::DelimiterKind>, closing: bool) -> &'static str {\n \n impl<'a> TreeSink for TtTreeSink<'a> {\n     fn token(&mut self, kind: SyntaxKind, mut n_tokens: u8) {\n-        if kind == L_DOLLAR || kind == R_DOLLAR {\n-            self.cursor = self.cursor.bump_subtree();\n-            return;\n-        }\n         if kind == LIFETIME_IDENT {\n             n_tokens = 2;\n         }\n@@ -661,48 +656,54 @@ impl<'a> TreeSink for TtTreeSink<'a> {\n                 break;\n             }\n             last = self.cursor;\n-            let text: &str = match self.cursor.token_tree() {\n-                Some(tt::buffer::TokenTreeRef::Leaf(leaf, _)) => {\n-                    // Mark the range if needed\n-                    let (text, id) = match leaf {\n-                        tt::Leaf::Ident(ident) => (&ident.text, ident.id),\n-                        tt::Leaf::Punct(punct) => {\n-                            assert!(punct.char.is_ascii());\n-                            let char = &(punct.char as u8);\n-                            tmp_str = SmolStr::new_inline(\n-                                std::str::from_utf8(std::slice::from_ref(char)).unwrap(),\n-                            );\n-                            (&tmp_str, punct.id)\n+            let text: &str = loop {\n+                break match self.cursor.token_tree() {\n+                    Some(tt::buffer::TokenTreeRef::Leaf(leaf, _)) => {\n+                        // Mark the range if needed\n+                        let (text, id) = match leaf {\n+                            tt::Leaf::Ident(ident) => (&ident.text, ident.id),\n+                            tt::Leaf::Punct(punct) => {\n+                                assert!(punct.char.is_ascii());\n+                                let char = &(punct.char as u8);\n+                                tmp_str = SmolStr::new_inline(\n+                                    std::str::from_utf8(std::slice::from_ref(char)).unwrap(),\n+                                );\n+                                (&tmp_str, punct.id)\n+                            }\n+                            tt::Leaf::Literal(lit) => (&lit.text, lit.id),\n+                        };\n+                        let range = TextRange::at(self.text_pos, TextSize::of(text.as_str()));\n+                        self.token_map.insert(id, range);\n+                        self.cursor = self.cursor.bump();\n+                        text\n+                    }\n+                    Some(tt::buffer::TokenTreeRef::Subtree(subtree, _)) => {\n+                        self.cursor = self.cursor.subtree().unwrap();\n+                        match subtree.delimiter {\n+                            Some(d) => {\n+                                self.open_delims.insert(d.id, self.text_pos);\n+                                delim_to_str(d.kind, false)\n+                            }\n+                            None => continue,\n                         }\n-                        tt::Leaf::Literal(lit) => (&lit.text, lit.id),\n-                    };\n-                    let range = TextRange::at(self.text_pos, TextSize::of(text.as_str()));\n-                    self.token_map.insert(id, range);\n-                    self.cursor = self.cursor.bump();\n-                    text\n-                }\n-                Some(tt::buffer::TokenTreeRef::Subtree(subtree, _)) => {\n-                    self.cursor = self.cursor.subtree().unwrap();\n-                    if let Some(id) = subtree.delimiter.map(|it| it.id) {\n-                        self.open_delims.insert(id, self.text_pos);\n                     }\n-                    delim_to_str(subtree.delimiter_kind(), false)\n-                }\n-                None => {\n-                    if let Some(parent) = self.cursor.end() {\n+                    None => {\n+                        let parent = self.cursor.end().unwrap();\n                         self.cursor = self.cursor.bump();\n-                        if let Some(id) = parent.delimiter.map(|it| it.id) {\n-                            if let Some(open_delim) = self.open_delims.get(&id) {\n-                                let open_range = TextRange::at(*open_delim, TextSize::of('('));\n-                                let close_range = TextRange::at(self.text_pos, TextSize::of('('));\n-                                self.token_map.insert_delim(id, open_range, close_range);\n+                        match parent.delimiter {\n+                            Some(d) => {\n+                                if let Some(open_delim) = self.open_delims.get(&d.id) {\n+                                    let open_range = TextRange::at(*open_delim, TextSize::of('('));\n+                                    let close_range =\n+                                        TextRange::at(self.text_pos, TextSize::of('('));\n+                                    self.token_map.insert_delim(d.id, open_range, close_range);\n+                                }\n+                                delim_to_str(d.kind, true)\n                             }\n+                            None => continue,\n                         }\n-                        delim_to_str(parent.delimiter_kind(), true)\n-                    } else {\n-                        continue;\n                     }\n-                }\n+                };\n             };\n             self.buf += text;\n             self.text_pos += TextSize::of(text);"}, {"sha": "640caa07780a94b6fdaab0768a2116078d1cdf19", "filename": "crates/parser/src/grammar/expressions/atom.rs", "status": "modified", "additions": 1, "deletions": 27, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fparser%2Fsrc%2Fgrammar%2Fexpressions%2Fatom.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fparser%2Fsrc%2Fgrammar%2Fexpressions%2Fatom.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fparser%2Fsrc%2Fgrammar%2Fexpressions%2Fatom.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -39,7 +39,6 @@ pub(super) const ATOM_EXPR_FIRST: TokenSet =\n         T!['('],\n         T!['{'],\n         T!['['],\n-        L_DOLLAR,\n         T![|],\n         T![move],\n         T![box],\n@@ -59,7 +58,7 @@ pub(super) const ATOM_EXPR_FIRST: TokenSet =\n         LIFETIME_IDENT,\n     ]));\n \n-const EXPR_RECOVERY_SET: TokenSet = TokenSet::new(&[T![let], R_DOLLAR]);\n+const EXPR_RECOVERY_SET: TokenSet = TokenSet::new(&[T![let]]);\n \n pub(super) fn atom_expr(p: &mut Parser, r: Restrictions) -> Option<(CompletedMarker, BlockLike)> {\n     if let Some(m) = literal(p) {\n@@ -72,7 +71,6 @@ pub(super) fn atom_expr(p: &mut Parser, r: Restrictions) -> Option<(CompletedMar\n     let done = match p.current() {\n         T!['('] => tuple_expr(p),\n         T!['['] => array_expr(p),\n-        L_DOLLAR => meta_var_expr(p),\n         T![|] => closure_expr(p),\n         T![move] if la == T![|] => closure_expr(p),\n         T![async] if la == T![|] || (la == T![move] && p.nth(2) == T![|]) => closure_expr(p),\n@@ -622,27 +620,3 @@ fn box_expr(p: &mut Parser, m: Option<Marker>) -> CompletedMarker {\n     }\n     m.complete(p, BOX_EXPR)\n }\n-\n-/// Expression from `$var` macro expansion, wrapped in dollars\n-fn meta_var_expr(p: &mut Parser) -> CompletedMarker {\n-    assert!(p.at(L_DOLLAR));\n-    let m = p.start();\n-    p.bump(L_DOLLAR);\n-    let expr = expr_bp(p, None, Restrictions { forbid_structs: false, prefer_stmt: false }, 1);\n-\n-    match (expr, p.current()) {\n-        (Some((cm, _)), R_DOLLAR) => {\n-            p.bump(R_DOLLAR);\n-            // FIXME: this leaves the dollar hanging in the air...\n-            m.abandon(p);\n-            cm\n-        }\n-        _ => {\n-            while !p.at(R_DOLLAR) {\n-                p.bump_any();\n-            }\n-            p.bump(R_DOLLAR);\n-            m.complete(p, ERROR)\n-        }\n-    }\n-}"}, {"sha": "05c1aea5c4b56fb775885f675a1694d2cd5aca3a", "filename": "crates/parser/src/grammar/types.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fparser%2Fsrc%2Fgrammar%2Ftypes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fparser%2Fsrc%2Fgrammar%2Ftypes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fparser%2Fsrc%2Fgrammar%2Ftypes.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -19,7 +19,6 @@ pub(super) const TYPE_FIRST: TokenSet = paths::PATH_FIRST.union(TokenSet::new(&[\n const TYPE_RECOVERY_SET: TokenSet = TokenSet::new(&[\n     T![')'],\n     T![,],\n-    L_DOLLAR,\n     // test_err struct_field_recover\n     // struct S { f pub g: () }\n     T![pub],"}, {"sha": "5820ffd77d4f5419edebc5e32c296e822b04c495", "filename": "crates/parser/src/parser.rs", "status": "modified", "additions": 3, "deletions": 13, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fparser%2Fsrc%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fparser%2Fsrc%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fparser%2Fsrc%2Fparser.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -7,7 +7,7 @@ use drop_bomb::DropBomb;\n use crate::{\n     event::Event,\n     ParseError,\n-    SyntaxKind::{self, EOF, ERROR, L_DOLLAR, R_DOLLAR, TOMBSTONE},\n+    SyntaxKind::{self, EOF, ERROR, TOMBSTONE},\n     TokenSet, TokenSource, T,\n };\n \n@@ -215,23 +215,13 @@ impl<'t> Parser<'t> {\n \n     /// Create an error node and consume the next token.\n     pub(crate) fn err_and_bump(&mut self, message: &str) {\n-        match self.current() {\n-            L_DOLLAR | R_DOLLAR => {\n-                let m = self.start();\n-                self.error(message);\n-                self.bump_any();\n-                m.complete(self, ERROR);\n-            }\n-            _ => {\n-                self.err_recover(message, TokenSet::EMPTY);\n-            }\n-        }\n+        self.err_recover(message, TokenSet::EMPTY);\n     }\n \n     /// Create an error node and consume the next token.\n     pub(crate) fn err_recover(&mut self, message: &str, recovery: TokenSet) {\n         match self.current() {\n-            T!['{'] | T!['}'] | L_DOLLAR | R_DOLLAR => {\n+            T!['{'] | T!['}'] => {\n                 self.error(message);\n                 return;\n             }"}, {"sha": "99e7651906acd85b329faac8d64743315e015249", "filename": "crates/parser/src/syntax_kind/generated.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fparser%2Fsrc%2Fsyntax_kind%2Fgenerated.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -120,8 +120,6 @@ pub enum SyntaxKind {\n     LIFETIME_IDENT,\n     COMMENT,\n     SHEBANG,\n-    L_DOLLAR,\n-    R_DOLLAR,\n     SOURCE_FILE,\n     STRUCT,\n     UNION,"}, {"sha": "c0f1d5ef565238420b750bb50911ee45b463724e", "filename": "crates/syntax/src/tests/ast_src.rs", "status": "modified", "additions": 1, "deletions": 10, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fsyntax%2Fsrc%2Ftests%2Fast_src.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16/crates%2Fsyntax%2Fsrc%2Ftests%2Fast_src.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fsyntax%2Fsrc%2Ftests%2Fast_src.rs?ref=f4ba64ee2a05f3a38458a4a10dfd59eee9fd2a16", "patch": "@@ -72,16 +72,7 @@ pub(crate) const KINDS_SRC: KindsSrc = KindsSrc {\n     ],\n     contextual_keywords: &[\"auto\", \"default\", \"existential\", \"union\", \"raw\", \"macro_rules\"],\n     literals: &[\"INT_NUMBER\", \"FLOAT_NUMBER\", \"CHAR\", \"BYTE\", \"STRING\", \"BYTE_STRING\"],\n-    tokens: &[\n-        \"ERROR\",\n-        \"IDENT\",\n-        \"WHITESPACE\",\n-        \"LIFETIME_IDENT\",\n-        \"COMMENT\",\n-        \"SHEBANG\",\n-        \"L_DOLLAR\",\n-        \"R_DOLLAR\",\n-    ],\n+    tokens: &[\"ERROR\", \"IDENT\", \"WHITESPACE\", \"LIFETIME_IDENT\", \"COMMENT\", \"SHEBANG\"],\n     nodes: &[\n         \"SOURCE_FILE\",\n         \"STRUCT\","}]}