{"sha": "fd52d721e1ed9794048d63e546f43805d24d7ab8", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZkNTJkNzIxZTFlZDk3OTQwNDhkNjNlNTQ2ZjQzODA1ZDI0ZDdhYjg=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-11-17T17:15:55Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-11-17T17:15:55Z"}, "message": "More correct expansion mapping\n\nWe can't really map arbitrary ranges, we only can map tokens", "tree": {"sha": "4a57f22e985709c4206fb95fda04367a8e90b5a3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4a57f22e985709c4206fb95fda04367a8e90b5a3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fd52d721e1ed9794048d63e546f43805d24d7ab8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fd52d721e1ed9794048d63e546f43805d24d7ab8", "html_url": "https://github.com/rust-lang/rust/commit/fd52d721e1ed9794048d63e546f43805d24d7ab8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fd52d721e1ed9794048d63e546f43805d24d7ab8/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c8f858d04323f93a4bacb143d92c976b2bc1e179", "url": "https://api.github.com/repos/rust-lang/rust/commits/c8f858d04323f93a4bacb143d92c976b2bc1e179", "html_url": "https://github.com/rust-lang/rust/commit/c8f858d04323f93a4bacb143d92c976b2bc1e179"}], "stats": {"total": 118, "additions": 74, "deletions": 44}, "files": [{"sha": "f0ed8e2b2506995edec82fc3093a425fd18159a3", "filename": "crates/ra_hir/src/source_binder.rs", "status": "modified", "additions": 9, "deletions": 4, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/fd52d721e1ed9794048d63e546f43805d24d7ab8/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd52d721e1ed9794048d63e546f43805d24d7ab8/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs?ref=fd52d721e1ed9794048d63e546f43805d24d7ab8", "patch": "@@ -16,7 +16,7 @@ use ra_syntax::{\n     ast::{self, AstNode},\n     match_ast, AstPtr,\n     SyntaxKind::*,\n-    SyntaxNode, SyntaxNodePtr, TextRange, TextUnit,\n+    SyntaxNode, SyntaxNodePtr, SyntaxToken, TextRange, TextUnit,\n };\n \n use crate::{\n@@ -131,11 +131,16 @@ pub struct Expansion {\n }\n \n impl Expansion {\n-    pub fn translate_offset(&self, db: &impl HirDatabase, offset: TextUnit) -> Option<TextUnit> {\n+    pub fn map_token_down(\n+        &self,\n+        db: &impl HirDatabase,\n+        token: Source<&SyntaxToken>,\n+    ) -> Option<Source<SyntaxToken>> {\n         let exp_info = self.file_id().expansion_info(db)?;\n-        exp_info.translate_offset(offset)\n+        exp_info.map_token_down(token)\n     }\n-    pub fn file_id(&self) -> HirFileId {\n+\n+    fn file_id(&self) -> HirFileId {\n         self.macro_call_id.as_file(MacroFileKind::Items)\n     }\n }"}, {"sha": "57e2e6cb1a4041c109dca171da7ef17bd6598761", "filename": "crates/ra_hir_expand/src/lib.rs", "status": "modified", "additions": 30, "deletions": 14, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/fd52d721e1ed9794048d63e546f43805d24d7ab8/crates%2Fra_hir_expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd52d721e1ed9794048d63e546f43805d24d7ab8/crates%2Fra_hir_expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir_expand%2Fsrc%2Flib.rs?ref=fd52d721e1ed9794048d63e546f43805d24d7ab8", "patch": "@@ -18,8 +18,9 @@ use std::sync::Arc;\n \n use ra_db::{salsa, CrateId, FileId};\n use ra_syntax::{\n+    algo,\n     ast::{self, AstNode},\n-    SyntaxNode, TextRange, TextUnit,\n+    SyntaxNode, SyntaxToken, TextRange, TextUnit,\n };\n \n use crate::ast_id_map::FileAstId;\n@@ -83,13 +84,21 @@ impl HirFileId {\n                     loc.def.ast_id.to_node(db).token_tree()?.syntax().text_range().start();\n \n                 let macro_def = db.macro_def(loc.def)?;\n-                let exp_map = db.parse_macro(macro_file)?.1;\n+                let (parse, exp_map) = db.parse_macro(macro_file)?;\n+                let expanded = Source::new(self, parse.syntax_node());\n                 let macro_arg = db.macro_arg(macro_file.macro_call_id)?;\n \n                 let arg_start = (loc.ast_id.file_id, arg_start);\n                 let def_start = (loc.def.ast_id.file_id, def_start);\n \n-                Some(ExpansionInfo { arg_start, def_start, macro_arg, macro_def, exp_map })\n+                Some(ExpansionInfo {\n+                    expanded,\n+                    arg_start,\n+                    def_start,\n+                    macro_arg,\n+                    macro_def,\n+                    exp_map,\n+                })\n             }\n         }\n     }\n@@ -146,27 +155,34 @@ impl MacroCallId {\n     }\n }\n \n-#[derive(Debug, Clone, PartialEq, Eq)]\n /// ExpansionInfo mainly describes how to map text range between src and expanded macro\n+#[derive(Debug, Clone, PartialEq, Eq)]\n pub struct ExpansionInfo {\n-    pub(crate) arg_start: (HirFileId, TextUnit),\n-    pub(crate) def_start: (HirFileId, TextUnit),\n+    expanded: Source<SyntaxNode>,\n+    arg_start: (HirFileId, TextUnit),\n+    def_start: (HirFileId, TextUnit),\n \n-    pub(crate) macro_def: Arc<(db::TokenExpander, mbe::TokenMap)>,\n-    pub(crate) macro_arg: Arc<(tt::Subtree, mbe::TokenMap)>,\n-    pub(crate) exp_map: Arc<mbe::RevTokenMap>,\n+    macro_def: Arc<(db::TokenExpander, mbe::TokenMap)>,\n+    macro_arg: Arc<(tt::Subtree, mbe::TokenMap)>,\n+    exp_map: Arc<mbe::RevTokenMap>,\n }\n \n impl ExpansionInfo {\n-    pub fn translate_offset(&self, offset: TextUnit) -> Option<TextUnit> {\n-        let offset = offset.checked_sub(self.arg_start.1)?;\n-        let token_id = self.macro_arg.1.token_by_offset(offset)?;\n+    pub fn map_token_down(&self, token: Source<&SyntaxToken>) -> Option<Source<SyntaxToken>> {\n+        assert_eq!(token.file_id, self.arg_start.0);\n+        let range = token.ast.text_range().checked_sub(self.arg_start.1)?;\n+        let token_id = self.macro_arg.1.token_by_range(range)?;\n         let token_id = self.macro_def.0.map_id_down(token_id);\n \n-        let (r, _) = self.exp_map.ranges.iter().find(|(_, tid)| *tid == token_id)?;\n-        Some(r.start())\n+        let range = self.exp_map.range_by_token(token_id)?;\n+\n+        let token = algo::find_covering_element(&self.expanded.ast, range).into_token()?;\n+\n+        Some(self.expanded.with_ast(token))\n     }\n \n+    // FIXME: a more correct signature would be\n+    // `pub fn map_token_up(&self, token: Source<&SyntaxToken>) -> Option<Source<SyntaxToken>>`\n     pub fn find_range(&self, from: TextRange) -> Option<(HirFileId, TextRange)> {\n         let token_id = look_in_rev_map(&self.exp_map, from)?;\n "}, {"sha": "b693a4c313332eec7e4bd91446918b9dea1008f3", "filename": "crates/ra_ide_api/src/goto_definition.rs", "status": "modified", "additions": 26, "deletions": 22, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/fd52d721e1ed9794048d63e546f43805d24d7ab8/crates%2Fra_ide_api%2Fsrc%2Fgoto_definition.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd52d721e1ed9794048d63e546f43805d24d7ab8/crates%2Fra_ide_api%2Fsrc%2Fgoto_definition.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fgoto_definition.rs?ref=fd52d721e1ed9794048d63e546f43805d24d7ab8", "patch": "@@ -4,9 +4,8 @@ use std::iter::successors;\n \n use hir::{db::AstDatabase, Source};\n use ra_syntax::{\n-    algo::find_node_at_offset,\n     ast::{self, DocCommentsOwner},\n-    match_ast, AstNode, SyntaxNode, TextUnit,\n+    match_ast, AstNode, SyntaxNode, SyntaxToken,\n };\n \n use crate::{\n@@ -20,37 +19,42 @@ pub(crate) fn goto_definition(\n     db: &RootDatabase,\n     position: FilePosition,\n ) -> Option<RangeInfo<Vec<NavigationTarget>>> {\n-    let offset = descend_into_macros(db, position);\n+    let token = descend_into_macros(db, position)?;\n \n-    let syntax = db.parse_or_expand(offset.file_id)?;\n+    let res = match_ast! {\n+        match (token.ast.parent()) {\n+            ast::NameRef(name_ref) => {\n+                let navs = reference_definition(db, token.with_ast(&name_ref)).to_vec();\n+                RangeInfo::new(name_ref.syntax().text_range(), navs.to_vec())\n+            },\n+            ast::Name(name) => {\n+                let navs = name_definition(db, token.with_ast(&name))?;\n+                RangeInfo::new(name.syntax().text_range(), navs)\n \n-    if let Some(name_ref) = find_node_at_offset::<ast::NameRef>(&syntax, offset.ast) {\n-        let navs = reference_definition(db, offset.with_ast(&name_ref)).to_vec();\n-        return Some(RangeInfo::new(name_ref.syntax().text_range(), navs.to_vec()));\n-    }\n-    if let Some(name) = find_node_at_offset::<ast::Name>(&syntax, offset.ast) {\n-        let navs = name_definition(db, offset.with_ast(&name))?;\n-        return Some(RangeInfo::new(name.syntax().text_range(), navs));\n-    }\n-    None\n+            },\n+            _ => return None,\n+        }\n+    };\n+\n+    Some(res)\n }\n \n-fn descend_into_macros(db: &RootDatabase, position: FilePosition) -> Source<TextUnit> {\n-    successors(Some(Source::new(position.file_id.into(), position.offset)), |offset| {\n-        let syntax = db.parse_or_expand(offset.file_id)?;\n-        let macro_call = find_node_at_offset::<ast::MacroCall>(&syntax, offset.ast)?;\n+fn descend_into_macros(db: &RootDatabase, position: FilePosition) -> Option<Source<SyntaxToken>> {\n+    let file = db.parse_or_expand(position.file_id.into())?;\n+    let token = file.token_at_offset(position.offset).filter(|it| !it.kind().is_trivia()).next()?;\n+\n+    successors(Some(Source::new(position.file_id.into(), token)), |token| {\n+        let macro_call = token.ast.ancestors().find_map(ast::MacroCall::cast)?;\n         let tt = macro_call.token_tree()?;\n-        if !tt.syntax().text_range().contains(offset.ast) {\n+        if !token.ast.text_range().is_subrange(&tt.syntax().text_range()) {\n             return None;\n         }\n         let source_analyzer =\n-            hir::SourceAnalyzer::new(db, offset.with_ast(macro_call.syntax()), None);\n+            hir::SourceAnalyzer::new(db, token.with_ast(token.ast.parent()).as_ref(), None);\n         let exp = source_analyzer.expand(db, &macro_call)?;\n-        let next_offset = exp.translate_offset(db, offset.ast)?;\n-        Some(Source::new(exp.file_id(), next_offset))\n+        exp.map_token_down(db, token.as_ref())\n     })\n     .last()\n-    .unwrap()\n }\n \n #[derive(Debug)]"}, {"sha": "8398c9ac73a4888e2f059fe5fb8456279b1f29c3", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 9, "deletions": 4, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/fd52d721e1ed9794048d63e546f43805d24d7ab8/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fd52d721e1ed9794048d63e546f43805d24d7ab8/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=fd52d721e1ed9794048d63e546f43805d24d7ab8", "patch": "@@ -77,14 +77,14 @@ pub fn token_tree_to_syntax_node(\n }\n \n impl TokenMap {\n-    pub fn token_by_offset(&self, relative_offset: TextUnit) -> Option<tt::TokenId> {\n+    pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n         let (idx, _) =\n-            self.tokens.iter().enumerate().find(|(_, range)| range.contains(relative_offset))?;\n+            self.tokens.iter().enumerate().find(|(_, range)| **range == relative_range)?;\n         Some(tt::TokenId(idx as u32))\n     }\n \n-    pub fn relative_range_of(&self, tt: tt::TokenId) -> Option<TextRange> {\n-        let idx = tt.0 as usize;\n+    pub fn relative_range_of(&self, token_id: tt::TokenId) -> Option<TextRange> {\n+        let idx = token_id.0 as usize;\n         self.tokens.get(idx).copied()\n     }\n \n@@ -96,6 +96,11 @@ impl TokenMap {\n }\n \n impl RevTokenMap {\n+    pub fn range_by_token(&self, token_id: tt::TokenId) -> Option<TextRange> {\n+        let &(r, _) = self.ranges.iter().find(|(_, tid)| *tid == token_id)?;\n+        Some(r)\n+    }\n+\n     fn add(&mut self, relative_range: TextRange, token_id: tt::TokenId) {\n         self.ranges.push((relative_range, token_id.clone()))\n     }"}]}