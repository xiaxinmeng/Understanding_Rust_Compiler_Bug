{"sha": "936d999b5270d186df28123a5dbd6d2bb848bb2c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjkzNmQ5OTliNTI3MGQxODZkZjI4MTIzYTVkYmQ2ZDJiYjg0OGJiMmM=", "commit": {"author": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-29T10:37:54Z"}, "committer": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-29T22:35:52Z"}, "message": "Use common variants for open and close delimiters\n\nThis common representation for delimeters should make pattern matching easier. Having a separate `token::DelimToken` enum also allows us to enforce the invariant that the opening and closing delimiters must be the same in `ast::TtDelimited`, removing the need to ensure matched delimiters when working with token trees.", "tree": {"sha": "53d5066fa43b14b51fa6fb326dd8a5a7ccd8295e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/53d5066fa43b14b51fa6fb326dd8a5a7ccd8295e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/936d999b5270d186df28123a5dbd6d2bb848bb2c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/936d999b5270d186df28123a5dbd6d2bb848bb2c", "html_url": "https://github.com/rust-lang/rust/commit/936d999b5270d186df28123a5dbd6d2bb848bb2c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/936d999b5270d186df28123a5dbd6d2bb848bb2c/comments", "author": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "77f44d4a7bf14805fda5fc41310a6aeffda30fd4", "url": "https://api.github.com/repos/rust-lang/rust/commits/77f44d4a7bf14805fda5fc41310a6aeffda30fd4", "html_url": "https://github.com/rust-lang/rust/commit/77f44d4a7bf14805fda5fc41310a6aeffda30fd4"}], "stats": {"total": 643, "additions": 328, "deletions": 315}, "files": [{"sha": "a4641c40165aca9ede5d17025b5b0d32d9858e0b", "filename": "src/grammar/verify.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Fgrammar%2Fverify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Fgrammar%2Fverify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fgrammar%2Fverify.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -59,20 +59,20 @@ fn parse_token_list(file: &str) -> HashMap<String, Token> {\n             \"FLOAT_SUFFIX\"      => id(),\n             \"INT_SUFFIX\"        => id(),\n             \"SHL\"               => token::BinOp(token::Shl),\n-            \"LBRACE\"            => token::LBrace,\n+            \"LBRACE\"            => token::OpenDelim(token::Brace),\n             \"RARROW\"            => token::Rarrow,\n             \"LIT_STR\"           => token::LitStr(Name(0)),\n             \"DOTDOT\"            => token::DotDot,\n             \"MOD_SEP\"           => token::ModSep,\n             \"DOTDOTDOT\"         => token::DotDotDot,\n             \"NOT\"               => token::Not,\n             \"AND\"               => token::BinOp(token::And),\n-            \"LPAREN\"            => token::LParen,\n+            \"LPAREN\"            => token::OpenDelim(token::Paren),\n             \"ANDAND\"            => token::AndAnd,\n             \"AT\"                => token::At,\n-            \"LBRACKET\"          => token::LBracket,\n+            \"LBRACKET\"          => token::OpenDelim(token::Bracket),\n             \"LIT_STR_RAW\"       => token::LitStrRaw(Name(0), 0),\n-            \"RPAREN\"            => token::RParen,\n+            \"RPAREN\"            => token::CloseDelim(token::Paren),\n             \"SLASH\"             => token::BinOp(token::Slash),\n             \"COMMA\"             => token::Comma,\n             \"LIFETIME\"          => token::Lifetime(ast::Ident { name: Name(0), ctxt: 0 }),\n@@ -83,15 +83,15 @@ fn parse_token_list(file: &str) -> HashMap<String, Token> {\n             \"LIT_CHAR\"          => token::LitChar(Name(0)),\n             \"LIT_BYTE\"          => token::LitByte(Name(0)),\n             \"EQ\"                => token::Eq,\n-            \"RBRACKET\"          => token::RBracket,\n+            \"RBRACKET\"          => token::CloseDelim(token::Bracket),\n             \"COMMENT\"           => token::Comment,\n             \"DOC_COMMENT\"       => token::DocComment(Name(0)),\n             \"DOT\"               => token::Dot,\n             \"EQEQ\"              => token::EqEq,\n             \"NE\"                => token::Ne,\n             \"GE\"                => token::Ge,\n             \"PERCENT\"           => token::BinOp(token::Percent),\n-            \"RBRACE\"            => token::RBrace,\n+            \"RBRACE\"            => token::CloseDelim(token::Brace),\n             \"BINOP\"             => token::BinOp(token::Plus),\n             \"POUND\"             => token::Pound,\n             \"OROR\"              => token::OrOr,"}, {"sha": "93ad29cff906a02184681e495e8f0276f4b193f8", "filename": "src/librustc/middle/save/span_utils.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibrustc%2Fmiddle%2Fsave%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibrustc%2Fmiddle%2Fsave%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fsave%2Fspan_utils.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -145,7 +145,7 @@ impl<'a> SpanUtils<'a> {\n             last_span = None;\n             let mut next = toks.next_token();\n \n-            if (next.tok == token::LParen ||\n+            if (next.tok == token::OpenDelim(token::Paren) ||\n                 next.tok == token::Lt) &&\n                bracket_count == 0 &&\n                prev.tok.is_ident() {\n@@ -164,8 +164,8 @@ impl<'a> SpanUtils<'a> {\n             }\n \n             bracket_count += match prev.tok {\n-                token::LParen | token::Lt => 1,\n-                token::RParen | token::Gt => -1,\n+                token::OpenDelim(token::Paren) | token::Lt => 1,\n+                token::CloseDelim(token::Paren) | token::Gt => -1,\n                 token::BinOp(token::Shr) => -2,\n                 _ => 0\n             };"}, {"sha": "4797ac7c66ac666d89f16335889e0588fa51788f", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -97,8 +97,8 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader,\n \n             // miscellaneous, no highlighting\n             token::Dot | token::DotDot | token::DotDotDot | token::Comma | token::Semi |\n-                token::Colon | token::ModSep | token::LArrow | token::LParen |\n-                token::RParen | token::LBracket | token::LBrace | token::RBrace |\n+                token::Colon | token::ModSep | token::LArrow | token::OpenDelim(_) |\n+                token::CloseDelim(token::Brace) | token::CloseDelim(token::Paren) |\n                 token::Question => \"\",\n             token::Dollar => {\n                 if lexer.peek().tok.is_ident() {\n@@ -118,7 +118,7 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader,\n                 try!(write!(out, r\"<span class='attribute'>#\"));\n                 continue\n             }\n-            token::RBracket => {\n+            token::CloseDelim(token::Bracket) => {\n                 if is_attribute {\n                     is_attribute = false;\n                     try!(write!(out, \"]</span>\"));"}, {"sha": "a2c859cf9fd3c4ae0207e9be401842d0092d6dd5", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 36, "deletions": 15, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -595,17 +595,38 @@ pub enum CaptureClause {\n     CaptureByRef,\n }\n \n-/// A token that delimits a sequence of token trees\n-#[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n-pub struct Delimiter {\n-    pub span: Span,\n-    pub token: ::parse::token::Token,\n-}\n+/// A delimited sequence of token trees\n+#[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n+pub struct Delimited {\n+    /// The type of delimiter\n+    pub delim: token::DelimToken,\n+    /// The span covering the opening delimiter\n+    pub open_span: Span,\n+    /// The delimited sequence of token trees\n+    pub tts: Vec<TokenTree>,\n+    /// The span covering the closing delimiter\n+    pub close_span: Span,\n+}\n+\n+impl Delimited {\n+    /// Returns the opening delimiter as a token.\n+    pub fn open_token(&self) -> token::Token {\n+        token::OpenDelim(self.delim)\n+    }\n+\n+    /// Returns the closing delimiter as a token.\n+    pub fn close_token(&self) -> token::Token {\n+        token::CloseDelim(self.delim)\n+    }\n+\n+    /// Returns the opening delimiter as a token tree.\n+    pub fn open_tt(&self) -> TokenTree {\n+        TtToken(self.open_span, self.open_token())\n+    }\n \n-impl Delimiter {\n-    /// Convert the delimiter to a `TtToken`\n-    pub fn to_tt(&self) -> TokenTree {\n-        TtToken(self.span, self.token.clone())\n+    /// Returns the closing delimiter as a token tree.\n+    pub fn close_tt(&self) -> TokenTree {\n+        TtToken(self.close_span, self.close_token())\n     }\n }\n \n@@ -635,15 +656,15 @@ pub enum KleeneOp {\n #[doc=\"For macro invocations; parsing is delegated to the macro\"]\n pub enum TokenTree {\n     /// A single token\n-    TtToken(Span, ::parse::token::Token),\n+    TtToken(Span, token::Token),\n     /// A delimited sequence of token trees\n-    TtDelimited(Span, Rc<(Delimiter, Vec<TokenTree>, Delimiter)>),\n+    TtDelimited(Span, Rc<Delimited>),\n \n     // These only make sense for right-hand-sides of MBE macros:\n \n     /// A Kleene-style repetition sequence with an optional separator.\n     // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TtSequence(Span, Rc<Vec<TokenTree>>, Option<::parse::token::Token>, KleeneOp),\n+    TtSequence(Span, Rc<Vec<TokenTree>>, Option<token::Token>, KleeneOp),\n     /// A syntactic variable that will be filled in by macro expansion.\n     TtNonterminal(Span, Ident)\n }\n@@ -715,10 +736,10 @@ pub type Matcher = Spanned<Matcher_>;\n #[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n pub enum Matcher_ {\n     /// Match one token\n-    MatchTok(::parse::token::Token),\n+    MatchTok(token::Token),\n     /// Match repetitions of a sequence: body, separator, Kleene operator,\n     /// lo, hi position-in-match-array used:\n-    MatchSeq(Vec<Matcher> , Option<::parse::token::Token>, KleeneOp, uint, uint),\n+    MatchSeq(Vec<Matcher>, Option<token::Token>, KleeneOp, uint, uint),\n     /// Parse a Rust NT: name to bind, name of NT, position in match array:\n     MatchNonterminal(Ident, Ident, uint)\n }"}, {"sha": "d57d6e52d7fd4ffe0dc6d09a07cabc8b1da8769d", "filename": "src/libsyntax/ext/asm.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fasm.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -84,9 +84,9 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n \n                     let span = p.last_span;\n \n-                    p.expect(&token::LParen);\n+                    p.expect(&token::OpenDelim(token::Paren));\n                     let out = p.parse_expr();\n-                    p.expect(&token::RParen);\n+                    p.expect(&token::CloseDelim(token::Paren));\n \n                     // Expands a read+write operand into two operands.\n                     //\n@@ -129,9 +129,9 @@ pub fn expand_asm<'cx>(cx: &'cx mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                         cx.span_err(p.last_span, \"input operand constraint contains '+'\");\n                     }\n \n-                    p.expect(&token::LParen);\n+                    p.expect(&token::OpenDelim(token::Paren));\n                     let input = p.parse_expr();\n-                    p.expect(&token::RParen);\n+                    p.expect(&token::CloseDelim(token::Paren));\n \n                     inputs.push((constraint, input));\n                 }"}, {"sha": "2151f79cd7b67d8ca4a4bc47773b42c5b27a8b6d", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 21, "deletions": 11, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -531,6 +531,15 @@ fn mk_binop(cx: &ExtCtxt, sp: Span, bop: token::BinOpToken) -> P<ast::Expr> {\n     mk_token_path(cx, sp, name)\n }\n \n+fn mk_delim(cx: &ExtCtxt, sp: Span, delim: token::DelimToken) -> P<ast::Expr> {\n+    let name = match delim {\n+        token::Paren     => \"Paren\",\n+        token::Bracket   => \"Bracket\",\n+        token::Brace     => \"Brace\",\n+    };\n+    mk_token_path(cx, sp, name)\n+}\n+\n #[allow(non_uppercase_statics)] // NOTE(stage0): remove this attribute after the next snapshot\n fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n     match *tok {\n@@ -542,6 +551,15 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n                                 vec!(mk_binop(cx, sp, binop)));\n         }\n \n+        token::OpenDelim(delim) => {\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"OpenDelim\"),\n+                                vec![mk_delim(cx, sp, delim)]);\n+        }\n+        token::CloseDelim(delim) => {\n+            return cx.expr_call(sp, mk_token_path(cx, sp, \"CloseDelim\"),\n+                                vec![mk_delim(cx, sp, delim)]);\n+        }\n+\n         token::LitByte(i) => {\n             let e_byte = mk_name(cx, sp, i.ident());\n \n@@ -625,12 +643,6 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n         token::RArrow       => \"RArrow\",\n         token::LArrow       => \"LArrow\",\n         token::FatArrow     => \"FatArrow\",\n-        token::LParen       => \"LParen\",\n-        token::RParen       => \"RParen\",\n-        token::LBracket     => \"LBracket\",\n-        token::RBracket     => \"RBracket\",\n-        token::LBrace       => \"LBrace\",\n-        token::RBrace       => \"RBrace\",\n         token::Pound        => \"Pound\",\n         token::Dollar       => \"Dollar\",\n         token::Underscore   => \"Underscore\",\n@@ -640,7 +652,6 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n     mk_token_path(cx, sp, name)\n }\n \n-\n fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n     match *tt {\n         ast::TtToken(sp, ref tok) => {\n@@ -656,10 +667,9 @@ fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n             vec!(cx.stmt_expr(e_push))\n         },\n         ast::TtDelimited(sp, ref delimed) => {\n-            let (ref open, ref tts, ref close) = **delimed;\n-            mk_tt(cx, sp, &open.to_tt()).into_iter()\n-                .chain(tts.iter().flat_map(|tt| mk_tt(cx, sp, tt).into_iter()))\n-                .chain(mk_tt(cx, sp, &close.to_tt()).into_iter())\n+            mk_tt(cx, sp, &delimed.open_tt()).into_iter()\n+                .chain(delimed.tts.iter().flat_map(|tt| mk_tt(cx, sp, tt).into_iter()))\n+                .chain(mk_tt(cx, sp, &delimed.close_tt()).into_iter())\n                 .collect()\n         },\n         ast::TtSequence(..) => panic!(\"TtSequence in quote!\"),"}, {"sha": "bbc2cb86d006ae618d3a3afe753a3cd0b62587d3", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -355,10 +355,8 @@ pub fn parse(sess: &ParseSess,\n                     // Built-in nonterminals never start with these tokens,\n                     // so we can eliminate them from consideration.\n                     match tok {\n-                        token::RParen |\n-                        token::RBrace |\n-                        token::RBracket => {},\n-                        _ => bb_eis.push(ei)\n+                        token::CloseDelim(_) => {},\n+                        _ => bb_eis.push(ei),\n                     }\n                   }\n                   MatchTok(ref t) => {"}, {"sha": "e50d4457af2492af1931b700ea62778fe82cba67", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -172,10 +172,7 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                     MatchedNonterminal(NtTT(ref tt)) => {\n                         match **tt {\n                             // ignore delimiters\n-                            TtDelimited(_, ref delimed) => {\n-                                let (_, ref tts, _) = **delimed;\n-                                tts.clone()\n-                            },\n+                            TtDelimited(_, ref delimed) => delimed.tts.clone(),\n                             _ => cx.span_fatal(sp, \"macro rhs must be delimited\"),\n                         }\n                     },"}, {"sha": "249a985a6488aa131cead26320825202a31c23cd", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 6, "deletions": 8, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -129,8 +129,7 @@ impl Add<LockstepIterSize, LockstepIterSize> for LockstepIterSize {\n fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n     match *t {\n         TtDelimited(_, ref delimed) => {\n-            let (_, ref tts, _) = **delimed;\n-            tts.iter().fold(LisUnconstrained, |size, tt| {\n+            delimed.tts.iter().fold(LisUnconstrained, |size, tt| {\n                 size + lockstep_iter_size(tt, r)\n             })\n         },\n@@ -207,14 +206,13 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n         };\n         match t {\n             TtDelimited(_, ref delimed) => {\n-                let (ref open, ref tts, ref close) = **delimed;\n-                let mut forest = Vec::with_capacity(1 + tts.len() + 1);\n-                forest.push(open.to_tt());\n-                forest.extend(tts.iter().map(|x| (*x).clone()));\n-                forest.push(close.to_tt());\n+                let mut tts = Vec::with_capacity(1 + delimed.tts.len() + 1);\n+                tts.push(delimed.open_tt());\n+                tts.extend(delimed.tts.iter().map(|tt| tt.clone()));\n+                tts.push(delimed.close_tt());\n \n                 r.stack.push(TtFrame {\n-                    forest: Rc::new(forest),\n+                    forest: Rc::new(tts),\n                     idx: 0,\n                     dotdotdoted: false,\n                     sep: None"}, {"sha": "9a55f07e98d798f51bf845e43aee0cfa5e5f10cb", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 8, "deletions": 12, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -572,18 +572,14 @@ pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n         TtToken(span, ref tok) =>\n             TtToken(span, fld.fold_token(tok.clone())),\n         TtDelimited(span, ref delimed) => {\n-            let (ref open, ref tts, ref close) = **delimed;\n-            TtDelimited(span, Rc::new((\n-                            Delimiter {\n-                                span: open.span,\n-                                token: fld.fold_token(open.token.clone())\n-                            },\n-                            fld.fold_tts(tts.as_slice()),\n-                            Delimiter {\n-                                span: close.span,\n-                                token: fld.fold_token(close.token.clone())\n-                            },\n-                        )))\n+            TtDelimited(span, Rc::new(\n+                            Delimited {\n+                                delim: delimed.delim,\n+                                open_span: delimed.open_span,\n+                                tts: fld.fold_tts(delimed.tts.as_slice()),\n+                                close_span: delimed.close_span,\n+                            }\n+                        ))\n         },\n         TtSequence(span, ref pattern, ref sep, is_optional) =>\n             TtSequence(span,"}, {"sha": "aefac804e4d88267e1881aad97f6f7002fec2912", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -81,10 +81,10 @@ impl<'a> ParserAttr for Parser<'a> {\n                     ast::AttrOuter\n                 };\n \n-                self.expect(&token::LBracket);\n+                self.expect(&token::OpenDelim(token::Bracket));\n                 let meta_item = self.parse_meta_item();\n                 let hi = self.span.hi;\n-                self.expect(&token::RBracket);\n+                self.expect(&token::CloseDelim(token::Bracket));\n \n                 (mk_sp(lo, hi), meta_item, style)\n             }\n@@ -194,7 +194,7 @@ impl<'a> ParserAttr for Parser<'a> {\n                 let hi = self.span.hi;\n                 P(spanned(lo, hi, ast::MetaNameValue(name, lit)))\n             }\n-            token::LParen => {\n+            token::OpenDelim(token::Paren) => {\n                 let inner_items = self.parse_meta_seq();\n                 let hi = self.span.hi;\n                 P(spanned(lo, hi, ast::MetaList(name, inner_items)))\n@@ -208,15 +208,15 @@ impl<'a> ParserAttr for Parser<'a> {\n \n     /// matches meta_seq = ( COMMASEP(meta_item) )\n     fn parse_meta_seq(&mut self) -> Vec<P<ast::MetaItem>> {\n-        self.parse_seq(&token::LParen,\n-                       &token::RParen,\n+        self.parse_seq(&token::OpenDelim(token::Paren),\n+                       &token::CloseDelim(token::Paren),\n                        seq_sep_trailing_disallowed(token::Comma),\n                        |p| p.parse_meta_item()).node\n     }\n \n     fn parse_optional_meta(&mut self) -> Vec<P<ast::MetaItem>> {\n         match self.token {\n-            token::LParen => self.parse_meta_seq(),\n+            token::OpenDelim(token::Paren) => self.parse_meta_seq(),\n             _ => Vec::new()\n         }\n     }"}, {"sha": "293b91111b5b2cce4d00df543f86da064b19ab3c", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -967,12 +967,12 @@ impl<'a> StringReader<'a> {\n                   token::Dot\n               };\n           }\n-          '(' => { self.bump(); return token::LParen; }\n-          ')' => { self.bump(); return token::RParen; }\n-          '{' => { self.bump(); return token::LBrace; }\n-          '}' => { self.bump(); return token::RBrace; }\n-          '[' => { self.bump(); return token::LBracket; }\n-          ']' => { self.bump(); return token::RBracket; }\n+          '(' => { self.bump(); return token::OpenDelim(token::Paren); }\n+          ')' => { self.bump(); return token::CloseDelim(token::Paren); }\n+          '{' => { self.bump(); return token::OpenDelim(token::Brace); }\n+          '}' => { self.bump(); return token::CloseDelim(token::Brace); }\n+          '[' => { self.bump(); return token::OpenDelim(token::Bracket); }\n+          ']' => { self.bump(); return token::CloseDelim(token::Bracket); }\n           '@' => { self.bump(); return token::At; }\n           '#' => { self.bump(); return token::Pound; }\n           '~' => { self.bump(); return token::Tilde; }"}, {"sha": "83499ec54c6766cf4e71cfa1f5c476ba86b245ea", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 27, "deletions": 43, "changes": 70, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -799,29 +799,23 @@ mod test {\n              ast::TtDelimited(_, ref macro_delimed)]\n             if name_macro_rules.as_str() == \"macro_rules\"\n             && name_zip.as_str() == \"zip\" => {\n-                let (ref macro_open, ref macro_tts, ref macro_close) = **macro_delimed;\n-                match (macro_open, macro_tts.as_slice(), macro_close) {\n-                    (&ast::Delimiter { token: token::LParen, .. },\n-                     [ast::TtDelimited(_, ref first_delimed),\n-                      ast::TtToken(_, token::FatArrow),\n-                      ast::TtDelimited(_, ref second_delimed)],\n-                     &ast::Delimiter { token: token::RParen, .. }) => {\n-                        let (ref first_open, ref first_tts, ref first_close) = **first_delimed;\n-                        match (first_open, first_tts.as_slice(), first_close) {\n-                            (&ast::Delimiter { token: token::LParen, .. },\n-                             [ast::TtToken(_, token::Dollar),\n-                              ast::TtToken(_, token::Ident(name, token::Plain))],\n-                             &ast::Delimiter { token: token::RParen, .. })\n-                            if name.as_str() == \"a\" => {},\n+                match macro_delimed.tts.as_slice() {\n+                    [ast::TtDelimited(_, ref first_delimed),\n+                     ast::TtToken(_, token::FatArrow),\n+                     ast::TtDelimited(_, ref second_delimed)]\n+                    if macro_delimed.delim == token::Paren => {\n+                        match first_delimed.tts.as_slice() {\n+                            [ast::TtToken(_, token::Dollar),\n+                             ast::TtToken(_, token::Ident(name, token::Plain))]\n+                            if first_delimed.delim == token::Paren\n+                            && name.as_str() == \"a\" => {},\n                             _ => panic!(\"value 3: {}\", **first_delimed),\n                         }\n-                        let (ref second_open, ref second_tts, ref second_close) = **second_delimed;\n-                        match (second_open, second_tts.as_slice(), second_close) {\n-                            (&ast::Delimiter { token: token::LParen, .. },\n-                             [ast::TtToken(_, token::Dollar),\n-                              ast::TtToken(_, token::Ident(name, token::Plain))],\n-                             &ast::Delimiter { token: token::RParen, .. })\n-                            if name.as_str() == \"a\" => {},\n+                        match second_delimed.tts.as_slice() {\n+                            [ast::TtToken(_, token::Dollar),\n+                             ast::TtToken(_, token::Ident(name, token::Plain))]\n+                            if second_delimed.delim == token::Paren\n+                            && name.as_str() == \"a\" => {},\n                             _ => panic!(\"value 4: {}\", **second_delimed),\n                         }\n                     },\n@@ -867,12 +861,10 @@ mod test {\n         \\\"variant\\\":\\\"TtDelimited\\\",\\\n         \\\"fields\\\":[\\\n             null,\\\n-            [\\\n-                {\\\n-                    \\\"span\\\":null,\\\n-                    \\\"token\\\":\\\"LParen\\\"\\\n-                },\\\n-                [\\\n+            {\\\n+                \\\"delim\\\":\\\"Paren\\\",\\\n+                \\\"open_span\\\":null,\\\n+                \\\"tts\\\":[\\\n                     {\\\n                         \\\"variant\\\":\\\"TtToken\\\",\\\n                         \\\"fields\\\":[\\\n@@ -907,23 +899,18 @@ mod test {\n                         ]\\\n                     }\\\n                 ],\\\n-                {\\\n-                    \\\"span\\\":null,\\\n-                    \\\"token\\\":\\\"RParen\\\"\\\n-                }\\\n-            ]\\\n+                \\\"close_span\\\":null\\\n+            }\\\n         ]\\\n     },\\\n     {\\\n         \\\"variant\\\":\\\"TtDelimited\\\",\\\n         \\\"fields\\\":[\\\n             null,\\\n-            [\\\n-                {\\\n-                    \\\"span\\\":null,\\\n-                    \\\"token\\\":\\\"LBrace\\\"\\\n-                },\\\n-                [\\\n+            {\\\n+                \\\"delim\\\":\\\"Brace\\\",\\\n+                \\\"open_span\\\":null,\\\n+                \\\"tts\\\":[\\\n                     {\\\n                         \\\"variant\\\":\\\"TtToken\\\",\\\n                         \\\"fields\\\":[\\\n@@ -945,11 +932,8 @@ mod test {\n                         ]\\\n                     }\\\n                 ],\\\n-                {\\\n-                    \\\"span\\\":null,\\\n-                    \\\"token\\\":\\\"RBrace\\\"\\\n-                }\\\n-            ]\\\n+                \\\"close_span\\\":null\\\n+            }\\\n         ]\\\n     }\\\n ]\".to_string()"}, {"sha": "3911c68fa18f8135755592faf4aab27fcbee65bf", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 163, "deletions": 160, "changes": 323, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -48,7 +48,7 @@ use ast::{StmtExpr, StmtSemi, StmtMac, StructDef, StructField};\n use ast::{StructVariantKind, BiSub};\n use ast::StrStyle;\n use ast::{SelfExplicit, SelfRegion, SelfStatic, SelfValue};\n-use ast::{Delimiter, TokenTree, TraitItem, TraitRef, TtDelimited, TtSequence, TtToken};\n+use ast::{Delimited, TokenTree, TraitItem, TraitRef, TtDelimited, TtSequence, TtToken};\n use ast::{TtNonterminal, TupleVariantKind, Ty, Ty_, TyBot};\n use ast::{TypeField, TyFixedLengthVec, TyClosure, TyProc, TyBareFn};\n use ast::{TyTypeof, TyInfer, TypeMethod};\n@@ -474,15 +474,15 @@ impl<'a> Parser<'a> {\n     /// recover (without consuming any expected input token).  Returns\n     /// true if and only if input was consumed for recovery.\n     pub fn check_for_erroneous_unit_struct_expecting(&mut self, expected: &[token::Token]) -> bool {\n-        if self.token == token::LBrace\n-            && expected.iter().all(|t| *t != token::LBrace)\n-            && self.look_ahead(1, |t| *t == token::RBrace) {\n+        if self.token == token::OpenDelim(token::Brace)\n+            && expected.iter().all(|t| *t != token::OpenDelim(token::Brace))\n+            && self.look_ahead(1, |t| *t == token::CloseDelim(token::Brace)) {\n             // matched; signal non-fatal error and recover.\n             let span = self.span;\n             self.span_err(span,\n                           \"unit-like struct construction is written with no trailing `{ }`\");\n-            self.eat(&token::LBrace);\n-            self.eat(&token::RBrace);\n+            self.eat(&token::OpenDelim(token::Brace));\n+            self.eat(&token::CloseDelim(token::Brace));\n             true\n         } else {\n             false\n@@ -1265,8 +1265,8 @@ impl<'a> Parser<'a> {\n     /// Parse the items in a trait declaration\n     pub fn parse_trait_items(&mut self) -> Vec<TraitItem> {\n         self.parse_unspanned_seq(\n-            &token::LBrace,\n-            &token::RBrace,\n+            &token::OpenDelim(token::Brace),\n+            &token::CloseDelim(token::Brace),\n             seq_sep_none(),\n             |p| {\n             let attrs = p.parse_outer_attributes();\n@@ -1319,7 +1319,7 @@ impl<'a> Parser<'a> {\n                         vis: vis,\n                     })\n                   }\n-                  token::LBrace => {\n+                  token::OpenDelim(token::Brace) => {\n                     debug!(\"parse_trait_methods(): parsing provided method\");\n                     let (inner_attrs, body) =\n                         p.parse_inner_attrs_and_block();\n@@ -1411,9 +1411,9 @@ impl<'a> Parser<'a> {\n \n         let lo = self.span.lo;\n \n-        let t = if self.token == token::LParen {\n+        let t = if self.token == token::OpenDelim(token::Paren) {\n             self.bump();\n-            if self.token == token::RParen {\n+            if self.token == token::CloseDelim(token::Paren) {\n                 self.bump();\n                 TyNil\n             } else {\n@@ -1424,7 +1424,7 @@ impl<'a> Parser<'a> {\n                 let mut one_tuple = false;\n                 while self.token == token::Comma {\n                     self.bump();\n-                    if self.token != token::RParen {\n+                    if self.token != token::CloseDelim(token::Paren) {\n                         ts.push(self.parse_ty(true));\n                     }\n                     else {\n@@ -1433,11 +1433,11 @@ impl<'a> Parser<'a> {\n                 }\n \n                 if ts.len() == 1 && !one_tuple {\n-                    self.expect(&token::RParen);\n+                    self.expect(&token::CloseDelim(token::Paren));\n                     TyParen(ts.into_iter().nth(0).unwrap())\n                 } else {\n                     let t = TyTup(ts);\n-                    self.expect(&token::RParen);\n+                    self.expect(&token::CloseDelim(token::Paren));\n                     t\n                 }\n             }\n@@ -1446,17 +1446,17 @@ impl<'a> Parser<'a> {\n             self.bump();\n             let last_span = self.last_span;\n             match self.token {\n-                token::LBracket => self.obsolete(last_span, ObsoleteOwnedVector),\n+                token::OpenDelim(token::Bracket) => self.obsolete(last_span, ObsoleteOwnedVector),\n                 _ => self.obsolete(last_span, ObsoleteOwnedType)\n             }\n             TyUniq(self.parse_ty(false))\n         } else if self.token == token::BinOp(token::Star) {\n             // STAR POINTER (bare pointer?)\n             self.bump();\n             TyPtr(self.parse_ptr())\n-        } else if self.token == token::LBracket {\n+        } else if self.token == token::OpenDelim(token::Bracket) {\n             // VECTOR\n-            self.expect(&token::LBracket);\n+            self.expect(&token::OpenDelim(token::Bracket));\n             let t = self.parse_ty(true);\n \n             // Parse the `, ..e` in `[ int, ..e ]`\n@@ -1465,7 +1465,7 @@ impl<'a> Parser<'a> {\n                 None => TyVec(t),\n                 Some(suffix) => TyFixedLengthVec(t, suffix)\n             };\n-            self.expect(&token::RBracket);\n+            self.expect(&token::CloseDelim(token::Bracket));\n             t\n         } else if self.token == token::BinOp(token::And) ||\n                 self.token == token::AndAnd {\n@@ -1490,9 +1490,9 @@ impl<'a> Parser<'a> {\n         } else if self.eat_keyword(keywords::Typeof) {\n             // TYPEOF\n             // In order to not be ambiguous, the type must be surrounded by parens.\n-            self.expect(&token::LParen);\n+            self.expect(&token::OpenDelim(token::Paren));\n             let e = self.parse_expr();\n-            self.expect(&token::RParen);\n+            self.expect(&token::CloseDelim(token::Paren));\n             TyTypeof(e)\n         } else if self.eat_keyword(keywords::Proc) {\n             self.parse_proc_type()\n@@ -1661,7 +1661,7 @@ impl<'a> Parser<'a> {\n                 LitBinary(parse::binary_lit(i.as_str())),\n             token::LitBinaryRaw(i, _) =>\n                 LitBinary(Rc::new(i.as_str().as_bytes().iter().map(|&x| x).collect())),\n-            token::LParen => { self.expect(&token::RParen); LitNil },\n+            token::OpenDelim(token::Paren) => { self.expect(&token::CloseDelim(token::Paren)); LitNil },\n             _ => { self.unexpected_last(tok); }\n         }\n     }\n@@ -2025,39 +2025,39 @@ impl<'a> Parser<'a> {\n         let ex: Expr_;\n \n         match self.token {\n-            token::LParen => {\n+            token::OpenDelim(token::Paren) => {\n                 self.bump();\n                 // (e) is parenthesized e\n                 // (e,) is a tuple with only one field, e\n                 let mut trailing_comma = false;\n-                if self.token == token::RParen {\n+                if self.token == token::CloseDelim(token::Paren) {\n                     hi = self.span.hi;\n                     self.bump();\n                     let lit = P(spanned(lo, hi, LitNil));\n                     return self.mk_expr(lo, hi, ExprLit(lit));\n                 }\n                 let mut es = vec!(self.parse_expr());\n-                self.commit_expr(&**es.last().unwrap(), &[], &[token::Comma, token::RParen]);\n+                self.commit_expr(&**es.last().unwrap(), &[], &[token::Comma, token::CloseDelim(token::Paren)]);\n                 while self.token == token::Comma {\n                     self.bump();\n-                    if self.token != token::RParen {\n+                    if self.token != token::CloseDelim(token::Paren) {\n                         es.push(self.parse_expr());\n                         self.commit_expr(&**es.last().unwrap(), &[],\n-                                         &[token::Comma, token::RParen]);\n+                                         &[token::Comma, token::CloseDelim(token::Paren)]);\n                     } else {\n                         trailing_comma = true;\n                     }\n                 }\n                 hi = self.span.hi;\n-                self.commit_expr_expecting(&**es.last().unwrap(), token::RParen);\n+                self.commit_expr_expecting(&**es.last().unwrap(), token::CloseDelim(token::Paren));\n \n                 return if es.len() == 1 && !trailing_comma {\n                    self.mk_expr(lo, hi, ExprParen(es.into_iter().nth(0).unwrap()))\n                 } else {\n                     self.mk_expr(lo, hi, ExprTup(es))\n                 }\n             },\n-            token::LBrace => {\n+            token::OpenDelim(token::Brace) => {\n                 self.bump();\n                 let blk = self.parse_block_tail(lo, DefaultBlock);\n                 return self.mk_expr(blk.span.lo, blk.span.hi,\n@@ -2077,10 +2077,10 @@ impl<'a> Parser<'a> {\n                 ex = ExprPath(path);\n                 hi = self.last_span.hi;\n             }\n-            token::LBracket => {\n+            token::OpenDelim(token::Bracket) => {\n                 self.bump();\n \n-                if self.token == token::RBracket {\n+                if self.token == token::CloseDelim(token::Bracket) {\n                     // Empty vector.\n                     self.bump();\n                     ex = ExprVec(Vec::new());\n@@ -2093,13 +2093,13 @@ impl<'a> Parser<'a> {\n                         self.bump();\n                         self.bump();\n                         let count = self.parse_expr();\n-                        self.expect(&token::RBracket);\n+                        self.expect(&token::CloseDelim(token::Bracket));\n                         ex = ExprRepeat(first_expr, count);\n                     } else if self.token == token::Comma {\n                         // Vector with two or more elements.\n                         self.bump();\n                         let remaining_exprs = self.parse_seq_to_end(\n-                            &token::RBracket,\n+                            &token::CloseDelim(token::Bracket),\n                             seq_sep_trailing_allowed(token::Comma),\n                             |p| p.parse_expr()\n                                 );\n@@ -2108,7 +2108,7 @@ impl<'a> Parser<'a> {\n                         ex = ExprVec(exprs);\n                     } else {\n                         // Vector with one element.\n-                        self.expect(&token::RBracket);\n+                        self.expect(&token::CloseDelim(token::Bracket));\n                         ex = ExprVec(vec!(first_expr));\n                     }\n                 }\n@@ -2227,7 +2227,7 @@ impl<'a> Parser<'a> {\n                                                            tts,\n                                                            EMPTY_CTXT));\n                     }\n-                    if self.token == token::LBrace {\n+                    if self.token == token::OpenDelim(token::Brace) {\n                         // This is a struct literal, unless we're prohibited\n                         // from parsing struct literals here.\n                         if !self.restrictions.contains(RESTRICTION_NO_STRUCT_LITERAL) {\n@@ -2236,7 +2236,7 @@ impl<'a> Parser<'a> {\n                             let mut fields = Vec::new();\n                             let mut base = None;\n \n-                            while self.token != token::RBrace {\n+                            while self.token != token::CloseDelim(token::Brace) {\n                                 if self.eat(&token::DotDot) {\n                                     base = Some(self.parse_expr());\n                                     break;\n@@ -2245,7 +2245,7 @@ impl<'a> Parser<'a> {\n                                 fields.push(self.parse_field());\n                                 self.commit_expr(&*fields.last().unwrap().expr,\n                                                  &[token::Comma],\n-                                                 &[token::RBrace]);\n+                                                 &[token::CloseDelim(token::Brace)]);\n                             }\n \n                             if fields.len() == 0 && base.is_none() {\n@@ -2258,7 +2258,7 @@ impl<'a> Parser<'a> {\n                             }\n \n                             hi = self.span.hi;\n-                            self.expect(&token::RBrace);\n+                            self.expect(&token::CloseDelim(token::Brace));\n                             ex = ExprStruct(pth, fields, base);\n                             return self.mk_expr(lo, hi, ex);\n                         }\n@@ -2281,7 +2281,7 @@ impl<'a> Parser<'a> {\n     /// Parse a block or unsafe block\n     pub fn parse_block_expr(&mut self, lo: BytePos, blk_mode: BlockCheckMode)\n                             -> P<Expr> {\n-        self.expect(&token::LBrace);\n+        self.expect(&token::OpenDelim(token::Brace));\n         let blk = self.parse_block_tail(lo, blk_mode);\n         return self.mk_expr(blk.span.lo, blk.span.hi, ExprBlock(blk));\n     }\n@@ -2313,10 +2313,10 @@ impl<'a> Parser<'a> {\n \n                     // expr.f() method call\n                     match self.token {\n-                        token::LParen => {\n+                        token::OpenDelim(token::Paren) => {\n                             let mut es = self.parse_unspanned_seq(\n-                                &token::LParen,\n-                                &token::RParen,\n+                                &token::OpenDelim(token::Paren),\n+                                &token::CloseDelim(token::Paren),\n                                 seq_sep_trailing_allowed(token::Comma),\n                                 |p| p.parse_expr()\n                             );\n@@ -2376,10 +2376,10 @@ impl<'a> Parser<'a> {\n             if self.expr_is_complete(&*e) { break; }\n             match self.token {\n               // expr(...)\n-              token::LParen => {\n+              token::OpenDelim(token::Paren) => {\n                 let es = self.parse_unspanned_seq(\n-                    &token::LParen,\n-                    &token::RParen,\n+                    &token::OpenDelim(token::Paren),\n+                    &token::CloseDelim(token::Paren),\n                     seq_sep_trailing_allowed(token::Comma),\n                     |p| p.parse_expr()\n                 );\n@@ -2393,7 +2393,7 @@ impl<'a> Parser<'a> {\n               // Could be either an index expression or a slicing expression.\n               // Any slicing non-terminal can have a mutable version with `mut`\n               // after the opening square bracket.\n-              token::LBracket => {\n+              token::OpenDelim(token::Bracket) => {\n                 self.bump();\n                 let mutbl = if self.eat_keyword(keywords::Mut) {\n                     MutMutable\n@@ -2402,7 +2402,7 @@ impl<'a> Parser<'a> {\n                 };\n                 match self.token {\n                     // e[]\n-                    token::RBracket => {\n+                    token::CloseDelim(token::Bracket) => {\n                         self.bump();\n                         hi = self.span.hi;\n                         let slice = self.mk_slice(e, None, None, mutbl);\n@@ -2413,7 +2413,7 @@ impl<'a> Parser<'a> {\n                         self.bump();\n                         match self.token {\n                             // e[..]\n-                            token::RBracket => {\n+                            token::CloseDelim(token::Bracket) => {\n                                 self.bump();\n                                 hi = self.span.hi;\n                                 let slice = self.mk_slice(e, None, None, mutbl);\n@@ -2427,7 +2427,7 @@ impl<'a> Parser<'a> {\n                             _ => {\n                                 hi = self.span.hi;\n                                 let e2 = self.parse_expr();\n-                                self.commit_expr_expecting(&*e2, token::RBracket);\n+                                self.commit_expr_expecting(&*e2, token::CloseDelim(token::Bracket));\n                                 let slice = self.mk_slice(e, None, Some(e2), mutbl);\n                                 e = self.mk_expr(lo, hi, slice)\n                             }\n@@ -2442,14 +2442,14 @@ impl<'a> Parser<'a> {\n                                 self.bump();\n                                 let e2 = match self.token {\n                                     // e[e..]\n-                                    token::RBracket => {\n+                                    token::CloseDelim(token::Bracket) => {\n                                         self.bump();\n                                         None\n                                     }\n                                     // e[e..e]\n                                     _ => {\n                                         let e2 = self.parse_expr();\n-                                        self.commit_expr_expecting(&*e2, token::RBracket);\n+                                        self.commit_expr_expecting(&*e2, token::CloseDelim(token::Bracket));\n                                         Some(e2)\n                                     }\n                                 };\n@@ -2464,7 +2464,7 @@ impl<'a> Parser<'a> {\n                                                   \"`mut` keyword is invalid in index expressions\");\n                                 }\n                                 hi = self.span.hi;\n-                                self.commit_expr_expecting(&*ix, token::RBracket);\n+                                self.commit_expr_expecting(&*ix, token::CloseDelim(token::Bracket));\n                                 let index = self.mk_index(e, ix);\n                                 e = self.mk_expr(lo, hi, index)\n                             }\n@@ -2525,7 +2525,7 @@ impl<'a> Parser<'a> {\n         fn parse_non_delim_tt_tok(p: &mut Parser) -> TokenTree {\n             maybe_whole!(deref p, NtTT);\n             match p.token {\n-              token::RParen | token::RBrace | token::RBracket => {\n+              token::CloseDelim(_) => {\n                   // This is a conservative error: only report the last unclosed delimiter. The\n                   // previous unclosed delimiters could actually be closed! The parser just hasn't\n                   // gotten to them yet.\n@@ -2542,10 +2542,10 @@ impl<'a> Parser<'a> {\n                 p.bump();\n                 let sp = p.span;\n \n-                if p.token == token::LParen {\n+                if p.token == token::OpenDelim(token::Paren) {\n                     let seq = p.parse_seq(\n-                        &token::LParen,\n-                        &token::RParen,\n+                        &token::OpenDelim(token::Paren),\n+                        &token::CloseDelim(token::Paren),\n                         seq_sep_none(),\n                         |p| p.parse_token_tree()\n                     );\n@@ -2564,45 +2564,48 @@ impl<'a> Parser<'a> {\n             }\n         }\n \n-        match (&self.token, self.token.get_close_delimiter()) {\n-            (&token::Eof, _) => {\n+        match self.token {\n+            token::Eof => {\n                 let open_braces = self.open_braces.clone();\n                 for sp in open_braces.iter() {\n                     self.span_note(*sp, \"Did you mean to close this delimiter?\");\n                 }\n                 // There shouldn't really be a span, but it's easier for the test runner\n                 // if we give it one\n                 self.fatal(\"this file contains an un-closed delimiter \");\n-            }\n-            (_, Some(close_delim)) => {\n+            },\n+            token::OpenDelim(delim) => {\n                 // The span for beginning of the delimited section\n                 let pre_span = self.span;\n \n                 // Parse the open delimiter.\n                 self.open_braces.push(self.span);\n-                let open = Delimiter {\n-                    span: self.span,\n-                    token: self.bump_and_get(),\n-                };\n+                let open_span = self.span;\n+                self.bump();\n \n                 // Parse the token trees within the delimeters\n                 let tts = self.parse_seq_to_before_end(\n-                    &close_delim, seq_sep_none(), |p| p.parse_token_tree()\n+                    &token::CloseDelim(delim),\n+                    seq_sep_none(),\n+                    |p| p.parse_token_tree()\n                 );\n \n                 // Parse the close delimiter.\n-                let close = Delimiter {\n-                    span: self.span,\n-                    token: self.bump_and_get(),\n-                };\n+                let close_span = self.span;\n+                self.bump();\n                 self.open_braces.pop().unwrap();\n \n                 // Expand to cover the entire delimited token tree\n                 let span = Span { hi: self.span.hi, ..pre_span };\n \n-                TtDelimited(span, Rc::new((open, tts, close)))\n-            }\n-            _ => parse_non_delim_tt_tok(self)\n+                TtDelimited(span, Rc::new(Delimited {\n+                    delim: delim,\n+                    open_span: open_span,\n+                    tts: tts,\n+                    close_span: close_span,\n+                }))\n+            },\n+            _ => parse_non_delim_tt_tok(self),\n         }\n     }\n \n@@ -2641,8 +2644,8 @@ impl<'a> Parser<'a> {\n         let mut lparens = 0u;\n \n         while self.token != *ket || lparens > 0u {\n-            if self.token == token::LParen { lparens += 1u; }\n-            if self.token == token::RParen { lparens -= 1u; }\n+            if self.token == token::OpenDelim(token::Paren) { lparens += 1u; }\n+            if self.token == token::CloseDelim(token::Paren) { lparens -= 1u; }\n             ret_val.push(self.parse_matcher(name_idx));\n         }\n \n@@ -2656,11 +2659,11 @@ impl<'a> Parser<'a> {\n \n         let m = if self.token == token::Dollar {\n             self.bump();\n-            if self.token == token::LParen {\n+            if self.token == token::OpenDelim(token::Paren) {\n                 let name_idx_lo = *name_idx;\n                 self.bump();\n                 let ms = self.parse_matcher_subseq_upto(name_idx,\n-                                                        &token::RParen);\n+                                                        &token::CloseDelim(token::Paren));\n                 if ms.len() == 0u {\n                     self.fatal(\"repetition body must be nonempty\");\n                 }\n@@ -2717,7 +2720,7 @@ impl<'a> Parser<'a> {\n             self.bump();\n             let last_span = self.last_span;\n             match self.token {\n-                token::LBracket => self.obsolete(last_span, ObsoleteOwnedVector),\n+                token::OpenDelim(token::Bracket) => self.obsolete(last_span, ObsoleteOwnedVector),\n                 _ => self.obsolete(last_span, ObsoleteOwnedExpr)\n             }\n \n@@ -2733,11 +2736,11 @@ impl<'a> Parser<'a> {\n             self.bump();\n \n             // Check for a place: `box(PLACE) EXPR`.\n-            if self.eat(&token::LParen) {\n+            if self.eat(&token::OpenDelim(token::Paren)) {\n                 // Support `box() EXPR` as the default.\n-                if !self.eat(&token::RParen) {\n+                if !self.eat(&token::CloseDelim(token::Paren)) {\n                     let place = self.parse_expr();\n-                    self.expect(&token::RParen);\n+                    self.expect(&token::CloseDelim(token::Paren));\n                     let subexpression = self.parse_prefix_expr();\n                     hi = subexpression.span.hi;\n                     ex = ExprBox(place, subexpression);\n@@ -2966,9 +2969,9 @@ impl<'a> Parser<'a> {\n     fn parse_match_expr(&mut self) -> P<Expr> {\n         let lo = self.last_span.lo;\n         let discriminant = self.parse_expr_res(RESTRICTION_NO_STRUCT_LITERAL);\n-        self.commit_expr_expecting(&*discriminant, token::LBrace);\n+        self.commit_expr_expecting(&*discriminant, token::OpenDelim(token::Brace));\n         let mut arms: Vec<Arm> = Vec::new();\n-        while self.token != token::RBrace {\n+        while self.token != token::CloseDelim(token::Brace) {\n             arms.push(self.parse_arm());\n         }\n         let hi = self.span.hi;\n@@ -2988,10 +2991,10 @@ impl<'a> Parser<'a> {\n \n         let require_comma =\n             !classify::expr_is_simple_block(&*expr)\n-            && self.token != token::RBrace;\n+            && self.token != token::CloseDelim(token::Brace);\n \n         if require_comma {\n-            self.commit_expr(&*expr, &[token::Comma], &[token::RBrace]);\n+            self.commit_expr(&*expr, &[token::Comma], &[token::CloseDelim(token::Brace)]);\n         } else {\n             self.eat(&token::Comma);\n         }\n@@ -3047,7 +3050,7 @@ impl<'a> Parser<'a> {\n         let mut first = true;\n         let mut before_slice = true;\n \n-        while self.token != token::RBracket {\n+        while self.token != token::CloseDelim(token::Bracket) {\n             if first {\n                 first = false;\n             } else {\n@@ -3059,7 +3062,7 @@ impl<'a> Parser<'a> {\n                     self.bump();\n \n                     if self.token == token::Comma ||\n-                            self.token == token::RBracket {\n+                            self.token == token::CloseDelim(token::Bracket) {\n                         slice = Some(P(ast::Pat {\n                             id: ast::DUMMY_NODE_ID,\n                             node: PatWild(PatWildMulti),\n@@ -3095,21 +3098,21 @@ impl<'a> Parser<'a> {\n         let mut fields = Vec::new();\n         let mut etc = false;\n         let mut first = true;\n-        while self.token != token::RBrace {\n+        while self.token != token::CloseDelim(token::Brace) {\n             if first {\n                 first = false;\n             } else {\n                 self.expect(&token::Comma);\n                 // accept trailing commas\n-                if self.token == token::RBrace { break }\n+                if self.token == token::CloseDelim(token::Brace) { break }\n             }\n \n             let lo = self.span.lo;\n             let hi;\n \n             if self.token == token::DotDot {\n                 self.bump();\n-                if self.token != token::RBrace {\n+                if self.token != token::CloseDelim(token::Brace) {\n                     let token_str = self.this_token_to_string();\n                     self.fatal(format!(\"expected `{}`, found `{}`\", \"}\",\n                                        token_str).as_slice())\n@@ -3205,10 +3208,10 @@ impl<'a> Parser<'a> {\n                 span: mk_sp(lo, hi)\n             })\n           }\n-          token::LParen => {\n+          token::OpenDelim(token::Paren) => {\n             // parse (pat,pat,pat,...) as tuple\n             self.bump();\n-            if self.token == token::RParen {\n+            if self.token == token::CloseDelim(token::Paren) {\n                 hi = self.span.hi;\n                 self.bump();\n                 let lit = P(codemap::Spanned {\n@@ -3218,15 +3221,15 @@ impl<'a> Parser<'a> {\n                 pat = PatLit(expr);\n             } else {\n                 let mut fields = vec!(self.parse_pat());\n-                if self.look_ahead(1, |t| *t != token::RParen) {\n+                if self.look_ahead(1, |t| *t != token::CloseDelim(token::Paren)) {\n                     while self.token == token::Comma {\n                         self.bump();\n-                        if self.token == token::RParen { break; }\n+                        if self.token == token::CloseDelim(token::Paren) { break; }\n                         fields.push(self.parse_pat());\n                     }\n                 }\n                 if fields.len() == 1 { self.expect(&token::Comma); }\n-                self.expect(&token::RParen);\n+                self.expect(&token::CloseDelim(token::Paren));\n                 pat = PatTup(fields);\n             }\n             hi = self.last_span.hi;\n@@ -3236,13 +3239,13 @@ impl<'a> Parser<'a> {\n                 span: mk_sp(lo, hi)\n             })\n           }\n-          token::LBracket => {\n+          token::OpenDelim(token::Bracket) => {\n             // parse [pat,pat,...] as vector pattern\n             self.bump();\n             let (before, slice, after) =\n                 self.parse_pat_vec_elements();\n \n-            self.expect(&token::RBracket);\n+            self.expect(&token::CloseDelim(token::Bracket));\n             pat = ast::PatVec(before, slice, after);\n             hi = self.last_span.hi;\n             return P(ast::Pat {\n@@ -3266,7 +3269,7 @@ impl<'a> Parser<'a> {\n             let val = self.parse_literal_maybe_minus();\n             if (self.token == token::DotDotDot) &&\n                     self.look_ahead(1, |t| {\n-                        *t != token::Comma && *t != token::RBracket\n+                        *t != token::Comma && *t != token::CloseDelim(token::Bracket)\n                     }) {\n                 self.bump();\n                 let end = if self.token.is_ident() || self.token.is_path() {\n@@ -3303,15 +3306,14 @@ impl<'a> Parser<'a> {\n         } else {\n             let can_be_enum_or_struct = self.look_ahead(1, |t| {\n                 match *t {\n-                    token::LParen | token::LBracket | token::Lt |\n-                    token::LBrace | token::ModSep => true,\n+                    token::OpenDelim(_) | token::Lt | token::ModSep => true,\n                     _ => false,\n                 }\n             });\n \n             if self.look_ahead(1, |t| *t == token::DotDotDot) &&\n                     self.look_ahead(2, |t| {\n-                        *t != token::Comma && *t != token::RBracket\n+                        *t != token::Comma && *t != token::CloseDelim(token::Bracket)\n                     }) {\n                 let start = self.parse_expr_res(RESTRICTION_NO_BAR_OP);\n                 self.eat(&token::DotDotDot);\n@@ -3348,7 +3350,7 @@ impl<'a> Parser<'a> {\n                 let enum_path = self.parse_path(LifetimeAndTypesWithColons)\n                                     .path;\n                 match self.token {\n-                    token::LBrace => {\n+                    token::OpenDelim(token::Brace) => {\n                         self.bump();\n                         let (fields, etc) =\n                             self.parse_pat_fields();\n@@ -3358,7 +3360,7 @@ impl<'a> Parser<'a> {\n                     _ => {\n                         let mut args: Vec<P<Pat>> = Vec::new();\n                         match self.token {\n-                          token::LParen => {\n+                          token::OpenDelim(token::Paren) => {\n                             let is_dotdot = self.look_ahead(1, |t| {\n                                 match *t {\n                                     token::DotDot => true,\n@@ -3369,12 +3371,12 @@ impl<'a> Parser<'a> {\n                                 // This is a \"top constructor only\" pat\n                                 self.bump();\n                                 self.bump();\n-                                self.expect(&token::RParen);\n+                                self.expect(&token::CloseDelim(token::Paren));\n                                 pat = PatEnum(enum_path, None);\n                             } else {\n                                 args = self.parse_enum_variant_seq(\n-                                    &token::LParen,\n-                                    &token::RParen,\n+                                    &token::OpenDelim(token::Paren),\n+                                    &token::CloseDelim(token::Paren),\n                                     seq_sep_trailing_allowed(token::Comma),\n                                     |p| p.parse_pat()\n                                 );\n@@ -3443,7 +3445,7 @@ impl<'a> Parser<'a> {\n         // leads to a parse error.  Note that if there is no explicit\n         // binding mode then we do not end up here, because the lookahead\n         // will direct us over to parse_enum_variant()\n-        if self.token == token::LParen {\n+        if self.token == token::OpenDelim(token::Paren) {\n             let last_span = self.last_span;\n             self.span_fatal(\n                 last_span,\n@@ -3632,7 +3634,7 @@ impl<'a> Parser<'a> {\n         maybe_whole!(no_clone self, NtBlock);\n \n         let lo = self.span.lo;\n-        self.expect(&token::LBrace);\n+        self.expect(&token::OpenDelim(token::Brace));\n \n         return self.parse_block_tail_(lo, DefaultBlock, Vec::new());\n     }\n@@ -3644,7 +3646,7 @@ impl<'a> Parser<'a> {\n         maybe_whole!(pair_empty self, NtBlock);\n \n         let lo = self.span.lo;\n-        self.expect(&token::LBrace);\n+        self.expect(&token::OpenDelim(token::Brace));\n         let (inner, next) = self.parse_inner_attrs_and_next();\n \n         (inner, self.parse_block_tail_(lo, DefaultBlock, next))\n@@ -3681,7 +3683,7 @@ impl<'a> Parser<'a> {\n \n         let mut attributes_box = attrs_remaining;\n \n-        while self.token != token::RBrace {\n+        while self.token != token::CloseDelim(token::Brace) {\n             // parsing items even when they're not allowed lets us give\n             // better error messages and recover more gracefully.\n             attributes_box.push_all(self.parse_outer_attributes().as_slice());\n@@ -3695,7 +3697,7 @@ impl<'a> Parser<'a> {\n                     }\n                     self.bump(); // empty\n                 }\n-                token::RBrace => {\n+                token::CloseDelim(token::Brace) => {\n                     // fall through and out.\n                 }\n                 _ => {\n@@ -3706,7 +3708,7 @@ impl<'a> Parser<'a> {\n                             // expression without semicolon\n                             if classify::expr_requires_semi_to_be_stmt(&*e) {\n                                 // Just check for errors and recover; do not eat semicolon yet.\n-                                self.commit_stmt(&[], &[token::Semi, token::RBrace]);\n+                                self.commit_stmt(&[], &[token::Semi, token::CloseDelim(token::Brace)]);\n                             }\n \n                             match self.token {\n@@ -3722,7 +3724,7 @@ impl<'a> Parser<'a> {\n                                         span: span_with_semi,\n                                     }));\n                                 }\n-                                token::RBrace => {\n+                                token::CloseDelim(token::Brace) => {\n                                     expr = Some(e);\n                                 }\n                                 _ => {\n@@ -3743,7 +3745,7 @@ impl<'a> Parser<'a> {\n                                     }));\n                                     self.bump();\n                                 }\n-                                token::RBrace => {\n+                                token::CloseDelim(token::Brace) => {\n                                     // if a block ends in `m!(arg)` without\n                                     // a `;`, it must be an expr\n                                     expr = Some(\n@@ -3838,10 +3840,10 @@ impl<'a> Parser<'a> {\n                 token::ModSep | token::Ident(..) => {\n                     let path =\n                         self.parse_path(LifetimeAndTypesWithoutColons).path;\n-                    if self.token == token::LParen {\n+                    if self.token == token::OpenDelim(token::Paren) {\n                         self.bump();\n                         let inputs = self.parse_seq_to_end(\n-                            &token::RParen,\n+                            &token::CloseDelim(token::Paren),\n                             seq_sep_trailing_allowed(token::Comma),\n                             |p| p.parse_arg_general(false));\n                         let (return_style, output) = self.parse_ret_ty();\n@@ -4035,14 +4037,14 @@ impl<'a> Parser<'a> {\n         let sp = self.span;\n         let mut args: Vec<Option<Arg>> =\n             self.parse_unspanned_seq(\n-                &token::LParen,\n-                &token::RParen,\n+                &token::OpenDelim(token::Paren),\n+                &token::CloseDelim(token::Paren),\n                 seq_sep_trailing_allowed(token::Comma),\n                 |p| {\n                     if p.token == token::DotDotDot {\n                         p.bump();\n                         if allow_variadic {\n-                            if p.token != token::RParen {\n+                            if p.token != token::CloseDelim(token::Paren) {\n                                 let span = p.span;\n                                 p.span_fatal(span,\n                                     \"`...` must be last in argument list for variadic function\");\n@@ -4154,7 +4156,7 @@ impl<'a> Parser<'a> {\n             }\n         }\n \n-        self.expect(&token::LParen);\n+        self.expect(&token::OpenDelim(token::Paren));\n \n         // A bit of complexity and lookahead is needed here in order to be\n         // backwards compatible.\n@@ -4249,14 +4251,14 @@ impl<'a> Parser<'a> {\n                     self.bump();\n                     let sep = seq_sep_trailing_allowed(token::Comma);\n                     let mut fn_inputs = self.parse_seq_to_before_end(\n-                        &token::RParen,\n+                        &token::CloseDelim(token::Paren),\n                         sep,\n                         parse_arg_fn\n                     );\n                     fn_inputs.insert(0, Arg::new_self(explicit_self_sp, mutbl_self, $self_id));\n                     fn_inputs\n                 }\n-                token::RParen => {\n+                token::CloseDelim(token::Paren) => {\n                     vec!(Arg::new_self(explicit_self_sp, mutbl_self, $self_id))\n                 }\n                 _ => {\n@@ -4271,15 +4273,15 @@ impl<'a> Parser<'a> {\n         let fn_inputs = match explicit_self {\n             SelfStatic =>  {\n                 let sep = seq_sep_trailing_allowed(token::Comma);\n-                self.parse_seq_to_before_end(&token::RParen, sep, parse_arg_fn)\n+                self.parse_seq_to_before_end(&token::CloseDelim(token::Paren), sep, parse_arg_fn)\n             }\n             SelfValue(id) => parse_remaining_arguments!(id),\n             SelfRegion(_,_,id) => parse_remaining_arguments!(id),\n             SelfExplicit(_,id) => parse_remaining_arguments!(id),\n         };\n \n \n-        self.expect(&token::RParen);\n+        self.expect(&token::CloseDelim(token::Paren));\n \n         let hi = self.span.hi;\n \n@@ -4335,8 +4337,8 @@ impl<'a> Parser<'a> {\n     /// Parses the `(arg, arg) -> return_type` header on a procedure.\n     fn parse_proc_decl(&mut self) -> P<FnDecl> {\n         let inputs =\n-            self.parse_unspanned_seq(&token::LParen,\n-                                     &token::RParen,\n+            self.parse_unspanned_seq(&token::OpenDelim(token::Paren),\n+                                     &token::CloseDelim(token::Paren),\n                                      seq_sep_trailing_allowed(token::Comma),\n                                      |p| p.parse_fn_block_arg());\n \n@@ -4405,8 +4407,8 @@ impl<'a> Parser<'a> {\n         let (method_, hi, new_attrs) = {\n             if !self.token.is_any_keyword()\n                 && self.look_ahead(1, |t| *t == token::Not)\n-                && (self.look_ahead(2, |t| *t == token::LParen)\n-                    || self.look_ahead(2, |t| *t == token::LBrace)) {\n+                && (self.look_ahead(2, |t| *t == token::OpenDelim(token::Paren))\n+                    || self.look_ahead(2, |t| *t == token::OpenDelim(token::Brace))) {\n                 // method macro.\n                 let pth = self.parse_path(NoTypesAllowed).path;\n                 self.expect(&token::Not);\n@@ -4484,10 +4486,10 @@ impl<'a> Parser<'a> {\n \n     fn parse_impl_items(&mut self) -> (Vec<ImplItem>, Vec<Attribute>) {\n         let mut impl_items = Vec::new();\n-        self.expect(&token::LBrace);\n+        self.expect(&token::OpenDelim(token::Brace));\n         let (inner_attrs, mut method_attrs) =\n             self.parse_inner_attrs_and_next();\n-        while !self.eat(&token::RBrace) {\n+        while !self.eat(&token::CloseDelim(token::Brace)) {\n             method_attrs.extend(self.parse_outer_attributes().into_iter());\n             let vis = self.parse_visibility();\n             if self.eat_keyword(keywords::Type) {\n@@ -4513,7 +4515,7 @@ impl<'a> Parser<'a> {\n \n         // Special case: if the next identifier that follows is '(', don't\n         // allow this to be parsed as a trait.\n-        let could_be_trait = self.token != token::LParen;\n+        let could_be_trait = self.token != token::OpenDelim(token::Paren);\n \n         // Parse the trait.\n         let mut ty = self.parse_ty(true);\n@@ -4571,11 +4573,11 @@ impl<'a> Parser<'a> {\n         let mut fields: Vec<StructField>;\n         let is_tuple_like;\n \n-        if self.eat(&token::LBrace) {\n+        if self.eat(&token::OpenDelim(token::Brace)) {\n             // It's a record-like struct.\n             is_tuple_like = false;\n             fields = Vec::new();\n-            while self.token != token::RBrace {\n+            while self.token != token::CloseDelim(token::Brace) {\n                 fields.push(self.parse_struct_decl_field());\n             }\n             if fields.len() == 0 {\n@@ -4584,12 +4586,12 @@ impl<'a> Parser<'a> {\n                                    token::get_ident(class_name)).as_slice());\n             }\n             self.bump();\n-        } else if self.token == token::LParen {\n+        } else if self.token == token::OpenDelim(token::Paren) {\n             // It's a tuple-like struct.\n             is_tuple_like = true;\n             fields = self.parse_unspanned_seq(\n-                &token::LParen,\n-                &token::RParen,\n+                &token::OpenDelim(token::Paren),\n+                &token::CloseDelim(token::Paren),\n                 seq_sep_trailing_allowed(token::Comma),\n                 |p| {\n                 let attrs = p.parse_outer_attributes();\n@@ -4639,7 +4641,7 @@ impl<'a> Parser<'a> {\n             token::Comma => {\n                 self.bump();\n             }\n-            token::RBrace => {}\n+            token::CloseDelim(token::Brace) => {}\n             _ => {\n                 let span = self.span;\n                 let token_str = self.this_token_to_string();\n@@ -4771,13 +4773,13 @@ impl<'a> Parser<'a> {\n             (id, m, Some(attrs))\n         } else {\n             self.push_mod_path(id, outer_attrs);\n-            self.expect(&token::LBrace);\n+            self.expect(&token::OpenDelim(token::Brace));\n             let mod_inner_lo = self.span.lo;\n             let old_owns_directory = self.owns_directory;\n             self.owns_directory = true;\n             let (inner, next) = self.parse_inner_attrs_and_next();\n-            let m = self.parse_mod_items(token::RBrace, next, mod_inner_lo);\n-            self.expect(&token::RBrace);\n+            let m = self.parse_mod_items(token::CloseDelim(token::Brace), next, mod_inner_lo);\n+            self.expect(&token::CloseDelim(token::Brace));\n             self.owns_directory = old_owns_directory;\n             self.pop_mod_path();\n             (id, ItemMod(m), Some(inner))\n@@ -4978,7 +4980,7 @@ impl<'a> Parser<'a> {\n             self.span_err(last_span,\n                           Parser::expected_item_err(attrs_remaining.as_slice()));\n         }\n-        assert!(self.token == token::RBrace);\n+        assert!(self.token == token::CloseDelim(token::Brace));\n         ast::ForeignMod {\n             abi: abi,\n             view_items: view_items,\n@@ -5065,13 +5067,13 @@ impl<'a> Parser<'a> {\n                               attrs: Vec<Attribute> )\n                               -> ItemOrViewItem {\n \n-        self.expect(&token::LBrace);\n+        self.expect(&token::OpenDelim(token::Brace));\n \n         let abi = opt_abi.unwrap_or(abi::C);\n \n         let (inner, next) = self.parse_inner_attrs_and_next();\n         let m = self.parse_foreign_mod_items(abi, next);\n-        self.expect(&token::RBrace);\n+        self.expect(&token::CloseDelim(token::Brace));\n \n         let last_span = self.last_span;\n         let item = self.mk_item(lo,\n@@ -5098,7 +5100,7 @@ impl<'a> Parser<'a> {\n     /// this should probably be renamed or refactored...\n     fn parse_struct_def(&mut self) -> P<StructDef> {\n         let mut fields: Vec<StructField> = Vec::new();\n-        while self.token != token::RBrace {\n+        while self.token != token::CloseDelim(token::Brace) {\n             fields.push(self.parse_struct_decl_field());\n         }\n         self.bump();\n@@ -5114,7 +5116,7 @@ impl<'a> Parser<'a> {\n         let mut variants = Vec::new();\n         let mut all_nullary = true;\n         let mut any_disr = None;\n-        while self.token != token::RBrace {\n+        while self.token != token::CloseDelim(token::Brace) {\n             let variant_attrs = self.parse_outer_attributes();\n             let vlo = self.span.lo;\n \n@@ -5125,15 +5127,15 @@ impl<'a> Parser<'a> {\n             let mut args = Vec::new();\n             let mut disr_expr = None;\n             ident = self.parse_ident();\n-            if self.eat(&token::LBrace) {\n+            if self.eat(&token::OpenDelim(token::Brace)) {\n                 // Parse a struct variant.\n                 all_nullary = false;\n                 kind = StructVariantKind(self.parse_struct_def());\n-            } else if self.token == token::LParen {\n+            } else if self.token == token::OpenDelim(token::Paren) {\n                 all_nullary = false;\n                 let arg_tys = self.parse_enum_variant_seq(\n-                    &token::LParen,\n-                    &token::RParen,\n+                    &token::OpenDelim(token::Paren),\n+                    &token::CloseDelim(token::Paren),\n                     seq_sep_trailing_allowed(token::Comma),\n                     |p| p.parse_ty(true)\n                 );\n@@ -5164,7 +5166,7 @@ impl<'a> Parser<'a> {\n \n             if !self.eat(&token::Comma) { break; }\n         }\n-        self.expect(&token::RBrace);\n+        self.expect(&token::CloseDelim(token::Brace));\n         match any_disr {\n             Some(disr_span) if !all_nullary =>\n                 self.span_err(disr_span,\n@@ -5180,15 +5182,15 @@ impl<'a> Parser<'a> {\n         let id = self.parse_ident();\n         let mut generics = self.parse_generics();\n         self.parse_where_clause(&mut generics);\n-        self.expect(&token::LBrace);\n+        self.expect(&token::OpenDelim(token::Brace));\n \n         let enum_definition = self.parse_enum_def(&generics);\n         (id, ItemEnum(enum_definition, generics), None)\n     }\n \n     fn fn_expr_lookahead(tok: &token::Token) -> bool {\n         match *tok {\n-          token::LParen | token::At | token::Tilde | token::BinOp(_) => true,\n+          token::OpenDelim(token::Paren) | token::At | token::Tilde | token::BinOp(_) => true,\n           _ => false\n         }\n     }\n@@ -5291,7 +5293,7 @@ impl<'a> Parser<'a> {\n                                         visibility,\n                                         maybe_append(attrs, extra_attrs));\n                 return IoviItem(item);\n-            } else if self.token == token::LBrace {\n+            } else if self.token == token::OpenDelim(token::Brace) {\n                 return self.parse_item_foreign_mod(lo, opt_abi, visibility, attrs);\n             }\n \n@@ -5356,7 +5358,7 @@ impl<'a> Parser<'a> {\n             return IoviItem(item);\n         }\n         if self.token.is_keyword(keywords::Unsafe)\n-            && self.look_ahead(1u, |t| *t != token::LBrace) {\n+            && self.look_ahead(1u, |t| *t != token::OpenDelim(token::Brace)) {\n             // UNSAFE FUNCTION ITEM\n             self.bump();\n             let abi = if self.eat_keyword(keywords::Extern) {\n@@ -5486,8 +5488,8 @@ impl<'a> Parser<'a> {\n         if macros_allowed && !self.token.is_any_keyword()\n                 && self.look_ahead(1, |t| *t == token::Not)\n                 && (self.look_ahead(2, |t| t.is_plain_ident())\n-                    || self.look_ahead(2, |t| *t == token::LParen)\n-                    || self.look_ahead(2, |t| *t == token::LBrace)) {\n+                    || self.look_ahead(2, |t| *t == token::OpenDelim(token::Paren))\n+                    || self.look_ahead(2, |t| *t == token::OpenDelim(token::Brace))) {\n             // MACRO INVOCATION ITEM\n \n             // item macro.\n@@ -5573,10 +5575,11 @@ impl<'a> Parser<'a> {\n     fn parse_view_path(&mut self) -> P<ViewPath> {\n         let lo = self.span.lo;\n \n-        if self.token == token::LBrace {\n+        if self.token == token::OpenDelim(token::Brace) {\n             // use {foo,bar}\n             let idents = self.parse_unspanned_seq(\n-                &token::LBrace, &token::RBrace,\n+                &token::OpenDelim(token::Brace),\n+                &token::CloseDelim(token::Brace),\n                 seq_sep_trailing_allowed(token::Comma),\n                 |p| p.parse_path_list_item());\n             let path = ast::Path {\n@@ -5631,10 +5634,10 @@ impl<'a> Parser<'a> {\n                   }\n \n                   // foo::bar::{a,b,c}\n-                  token::LBrace => {\n+                  token::OpenDelim(token::Brace) => {\n                     let idents = self.parse_unspanned_seq(\n-                        &token::LBrace,\n-                        &token::RBrace,\n+                        &token::OpenDelim(token::Brace),\n+                        &token::CloseDelim(token::Brace),\n                         seq_sep_trailing_allowed(token::Comma),\n                         |p| p.parse_path_list_item()\n                     );\n@@ -5793,7 +5796,7 @@ impl<'a> Parser<'a> {\n         loop {\n             match self.parse_foreign_item(attrs, macros_allowed) {\n                 IoviNone(returned_attrs) => {\n-                    if self.token == token::RBrace {\n+                    if self.token == token::CloseDelim(token::Brace) {\n                         attrs = returned_attrs;\n                         break\n                     }"}, {"sha": "cc4fdcf01b4f45635ecbbdfcdd8084afeda9cb37", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 26, "deletions": 19, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -56,12 +56,6 @@ use std::rc::Rc;\n #[cfg(stage0)] pub use self::RArrow         as RARROW;\n #[cfg(stage0)] pub use self::LArrow         as LARROW;\n #[cfg(stage0)] pub use self::FatArrow       as FAT_ARROW;\n-#[cfg(stage0)] pub use self::LParen         as LPAREN;\n-#[cfg(stage0)] pub use self::RParen         as RPAREN;\n-#[cfg(stage0)] pub use self::LBracket       as LBRACKET;\n-#[cfg(stage0)] pub use self::RBracket       as RBRACKET;\n-#[cfg(stage0)] pub use self::LBrace         as LBRACE;\n-#[cfg(stage0)] pub use self::RBrace         as RBRACE;\n #[cfg(stage0)] pub use self::Pound          as POUND;\n #[cfg(stage0)] pub use self::Dollar         as DOLLAR;\n #[cfg(stage0)] pub use self::Question       as QUESTION;\n@@ -82,6 +76,12 @@ use std::rc::Rc;\n #[cfg(stage0)] pub use self::Comment        as COMMENT;\n #[cfg(stage0)] pub use self::Shebang        as SHEBANG;\n #[cfg(stage0)] pub use self::Eof            as EOF;\n+#[cfg(stage0)] pub const LPAREN:    Token = OpenDelim(Paren);\n+#[cfg(stage0)] pub const RPAREN:    Token = CloseDelim(Paren);\n+#[cfg(stage0)] pub const LBRACKET:  Token = OpenDelim(Bracket);\n+#[cfg(stage0)] pub const RBRACKET:  Token = CloseDelim(Bracket);\n+#[cfg(stage0)] pub const LBRACE:    Token = OpenDelim(Brace);\n+#[cfg(stage0)] pub const RBRACE:    Token = CloseDelim(Brace);\n \n #[allow(non_camel_case_types)]\n #[deriving(Clone, Encodable, Decodable, PartialEq, Eq, Hash, Show)]\n@@ -98,6 +98,17 @@ pub enum BinOpToken {\n     Shr,\n }\n \n+/// A delimeter token\n+#[deriving(Clone, Encodable, Decodable, PartialEq, Eq, Hash, Show)]\n+pub enum DelimToken {\n+    /// A round parenthesis: `(` or `)`\n+    Paren,\n+    /// A square bracket: `[` or `]`\n+    Bracket,\n+    /// A curly brace: `{` or `}`\n+    Brace,\n+}\n+\n #[cfg(stage0)]\n #[allow(non_uppercase_statics)]\n pub const ModName: bool = true;\n@@ -143,15 +154,13 @@ pub enum Token {\n     RArrow,\n     LArrow,\n     FatArrow,\n-    LParen,\n-    RParen,\n-    LBracket,\n-    RBracket,\n-    LBrace,\n-    RBrace,\n     Pound,\n     Dollar,\n     Question,\n+    /// An opening delimeter, eg. `{`\n+    OpenDelim(DelimToken),\n+    /// A closing delimeter, eg. `}`\n+    CloseDelim(DelimToken),\n \n     /* Literals */\n     LitByte(ast::Name),\n@@ -192,9 +201,7 @@ impl Token {\n     /// Returns `true` if the token can appear at the start of an expression.\n     pub fn can_begin_expr(&self) -> bool {\n         match *self {\n-            LParen                      => true,\n-            LBrace                      => true,\n-            LBracket                    => true,\n+            OpenDelim(_)                => true,\n             Ident(_, _)                 => true,\n             Underscore                  => true,\n             Tilde                       => true,\n@@ -227,10 +234,10 @@ impl Token {\n     /// otherwise `None`.\n     pub fn get_close_delimiter(&self) -> Option<Token> {\n         match *self {\n-            LParen   => Some(RParen),\n-            LBrace   => Some(RBrace),\n-            LBracket => Some(RBracket),\n-            _        => None,\n+            OpenDelim(Paren)   => Some(CloseDelim(Paren)),\n+            OpenDelim(Brace)   => Some(CloseDelim(Brace)),\n+            OpenDelim(Bracket) => Some(CloseDelim(Bracket)),\n+            _                  => None,\n         }\n     }\n "}, {"sha": "6df9fff0e6bb9022d6974935b1a14eb715531bcb", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 9, "deletions": 10, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -225,12 +225,12 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::RArrow               => \"->\".into_string(),\n         token::LArrow               => \"<-\".into_string(),\n         token::FatArrow             => \"=>\".into_string(),\n-        token::LParen               => \"(\".into_string(),\n-        token::RParen               => \")\".into_string(),\n-        token::LBracket             => \"[\".into_string(),\n-        token::RBracket             => \"]\".into_string(),\n-        token::LBrace               => \"{\".into_string(),\n-        token::RBrace               => \"}\".into_string(),\n+        token::OpenDelim(token::Paren) => \"(\".into_string(),\n+        token::CloseDelim(token::Paren) => \")\".into_string(),\n+        token::OpenDelim(token::Bracket) => \"[\".into_string(),\n+        token::CloseDelim(token::Bracket) => \"]\".into_string(),\n+        token::OpenDelim(token::Brace) => \"{\".into_string(),\n+        token::CloseDelim(token::Brace) => \"}\".into_string(),\n         token::Pound                => \"#\".into_string(),\n         token::Dollar               => \"$\".into_string(),\n         token::Question             => \"?\".into_string(),\n@@ -1121,12 +1121,11 @@ impl<'a> State<'a> {\n     pub fn print_tt(&mut self, tt: &ast::TokenTree) -> IoResult<()> {\n         match *tt {\n             ast::TtDelimited(_, ref delimed) => {\n-                let (ref open, ref tts, ref close) = **delimed;\n-                try!(word(&mut self.s, token_to_string(&open.token).as_slice()));\n+                try!(word(&mut self.s, token_to_string(&delimed.open_token()).as_slice()));\n                 try!(space(&mut self.s));\n-                try!(self.print_tts(tts.as_slice()));\n+                try!(self.print_tts(delimed.tts.as_slice()));\n                 try!(space(&mut self.s));\n-                word(&mut self.s, token_to_string(&close.token).as_slice())\n+                word(&mut self.s, token_to_string(&delimed.close_token()).as_slice())\n             },\n             ast::TtToken(_, ref tk) => {\n                 try!(word(&mut self.s, token_to_string(tk).as_slice()));"}, {"sha": "b31e2538ab97bb022f989b207c6e45943c506370", "filename": "src/test/compile-fail/removed-syntax-record.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Ftest%2Fcompile-fail%2Fremoved-syntax-record.rs", "raw_url": "https://github.com/rust-lang/rust/raw/936d999b5270d186df28123a5dbd6d2bb848bb2c/src%2Ftest%2Fcompile-fail%2Fremoved-syntax-record.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fremoved-syntax-record.rs?ref=936d999b5270d186df28123a5dbd6d2bb848bb2c", "patch": "@@ -8,4 +8,4 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-type t = { f: () }; //~ ERROR expected type, found token LBrace\n+type t = { f: () }; //~ ERROR expected type, found token OpenDelim(Brace)"}]}