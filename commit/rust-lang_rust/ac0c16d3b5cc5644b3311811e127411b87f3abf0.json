{"sha": "ac0c16d3b5cc5644b3311811e127411b87f3abf0", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFjMGMxNmQzYjVjYzU2NDRiMzMxMTgxMWUxMjc0MTFiODdmM2FiZjA=", "commit": {"author": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-20T01:00:29Z"}, "committer": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-26T20:47:24Z"}, "message": "Run rustfmt on /libsyntax/ext/tt/macro_parser.rs", "tree": {"sha": "34c60519261889fe58659b722d63b17346cfc252", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/34c60519261889fe58659b722d63b17346cfc252"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ac0c16d3b5cc5644b3311811e127411b87f3abf0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ac0c16d3b5cc5644b3311811e127411b87f3abf0", "html_url": "https://github.com/rust-lang/rust/commit/ac0c16d3b5cc5644b3311811e127411b87f3abf0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ac0c16d3b5cc5644b3311811e127411b87f3abf0/comments", "author": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bacb5c58dfdde7c35e99b2b0d8171238cc33cf6c", "url": "https://api.github.com/repos/rust-lang/rust/commits/bacb5c58dfdde7c35e99b2b0d8171238cc33cf6c", "html_url": "https://github.com/rust-lang/rust/commit/bacb5c58dfdde7c35e99b2b0d8171238cc33cf6c"}], "stats": {"total": 192, "additions": 114, "deletions": 78}, "files": [{"sha": "a5b573f18db1d7e03a312b18b5ac79a2053a08da", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 114, "deletions": 78, "changes": 192, "blob_url": "https://github.com/rust-lang/rust/blob/ac0c16d3b5cc5644b3311811e127411b87f3abf0/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ac0c16d3b5cc5644b3311811e127411b87f3abf0/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=ac0c16d3b5cc5644b3311811e127411b87f3abf0", "patch": "@@ -90,8 +90,8 @@ use codemap::Spanned;\n use errors::FatalError;\n use ext::tt::quoted::{self, TokenTree};\n use parse::{Directory, ParseSess};\n-use parse::parser::{PathStyle, Parser};\n-use parse::token::{self, DocComment, Token, Nonterminal};\n+use parse::parser::{Parser, PathStyle};\n+use parse::token::{self, DocComment, Nonterminal, Token};\n use print::pprust;\n use symbol::keywords;\n use tokenstream::TokenStream;\n@@ -100,7 +100,7 @@ use util::small_vector::SmallVector;\n use std::mem;\n use std::rc::Rc;\n use std::collections::HashMap;\n-use std::collections::hash_map::Entry::{Vacant, Occupied};\n+use std::collections::hash_map::Entry::{Occupied, Vacant};\n \n // To avoid costly uniqueness checks, we require that `MatchSeq` always has\n // a nonempty body.\n@@ -182,7 +182,7 @@ fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n         match_lo: 0,\n         match_cur: 0,\n         match_hi: match_idx_hi,\n-        sp_lo: lo\n+        sp_lo: lo,\n     })\n }\n \n@@ -206,25 +206,27 @@ fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n #[derive(Debug, Clone)]\n pub enum NamedMatch {\n     MatchedSeq(Rc<Vec<NamedMatch>>, syntax_pos::Span),\n-    MatchedNonterminal(Rc<Nonterminal>)\n+    MatchedNonterminal(Rc<Nonterminal>),\n }\n \n-fn nameize<I: Iterator<Item=NamedMatch>>(sess: &ParseSess, ms: &[TokenTree], mut res: I)\n-                                             -> NamedParseResult {\n-    fn n_rec<I: Iterator<Item=NamedMatch>>(sess: &ParseSess, m: &TokenTree, res: &mut I,\n-             ret_val: &mut HashMap<Ident, Rc<NamedMatch>>)\n-             -> Result<(), (syntax_pos::Span, String)> {\n+fn nameize<I: Iterator<Item = NamedMatch>>(\n+    sess: &ParseSess,\n+    ms: &[TokenTree],\n+    mut res: I,\n+) -> NamedParseResult {\n+    fn n_rec<I: Iterator<Item = NamedMatch>>(\n+        sess: &ParseSess,\n+        m: &TokenTree,\n+        res: &mut I,\n+        ret_val: &mut HashMap<Ident, Rc<NamedMatch>>,\n+    ) -> Result<(), (syntax_pos::Span, String)> {\n         match *m {\n-            TokenTree::Sequence(_, ref seq) => {\n-                for next_m in &seq.tts {\n-                    n_rec(sess, next_m, res.by_ref(), ret_val)?\n-                }\n-            }\n-            TokenTree::Delimited(_, ref delim) => {\n-                for next_m in &delim.tts {\n-                    n_rec(sess, next_m, res.by_ref(), ret_val)?;\n-                }\n-            }\n+            TokenTree::Sequence(_, ref seq) => for next_m in &seq.tts {\n+                n_rec(sess, next_m, res.by_ref(), ret_val)?\n+            },\n+            TokenTree::Delimited(_, ref delim) => for next_m in &delim.tts {\n+                n_rec(sess, next_m, res.by_ref(), ret_val)?;\n+            },\n             TokenTree::MetaVarDecl(span, _, id) if id.name == keywords::Invalid.name() => {\n                 if sess.missing_fragment_specifiers.borrow_mut().remove(&span) {\n                     return Err((span, \"missing fragment specifier\".to_string()));\n@@ -250,7 +252,7 @@ fn nameize<I: Iterator<Item=NamedMatch>>(sess: &ParseSess, ms: &[TokenTree], mut\n     let mut ret_val = HashMap::new();\n     for m in ms {\n         match n_rec(sess, m, res.by_ref(), &mut ret_val) {\n-            Ok(_) => {},\n+            Ok(_) => {}\n             Err((sp, msg)) => return Error(sp, msg),\n         }\n     }\n@@ -265,18 +267,21 @@ pub enum ParseResult<T> {\n     /// indicates that no rules expected the given token.\n     Failure(syntax_pos::Span, Token),\n     /// Fatal error (malformed macro?). Abort compilation.\n-    Error(syntax_pos::Span, String)\n+    Error(syntax_pos::Span, String),\n }\n \n pub fn parse_failure_msg(tok: Token) -> String {\n     match tok {\n         token::Eof => \"unexpected end of macro invocation\".to_string(),\n-        _ => format!(\"no rules expected the token `{}`\", pprust::token_to_string(&tok)),\n+        _ => format!(\n+            \"no rules expected the token `{}`\",\n+            pprust::token_to_string(&tok)\n+        ),\n     }\n }\n \n /// Perform a token equality check, ignoring syntax context (that is, an unhygienic comparison)\n-fn token_name_eq(t1 : &Token, t2 : &Token) -> bool {\n+fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n     if let (Some(id1), Some(id2)) = (t1.ident(), t2.ident()) {\n         id1.name == id2.name\n     } else if let (&token::Lifetime(id1), &token::Lifetime(id2)) = (t1, t2) {\n@@ -290,14 +295,15 @@ fn create_matches(len: usize) -> Vec<Rc<Vec<NamedMatch>>> {\n     (0..len).into_iter().map(|_| Rc::new(Vec::new())).collect()\n }\n \n-fn inner_parse_loop(sess: &ParseSess,\n-                    cur_items: &mut SmallVector<Box<MatcherPos>>,\n-                    next_items: &mut Vec<Box<MatcherPos>>,\n-                    eof_items: &mut SmallVector<Box<MatcherPos>>,\n-                    bb_items: &mut SmallVector<Box<MatcherPos>>,\n-                    token: &Token,\n-                    span: syntax_pos::Span)\n-                    -> ParseResult<()> {\n+fn inner_parse_loop(\n+    sess: &ParseSess,\n+    cur_items: &mut SmallVector<Box<MatcherPos>>,\n+    next_items: &mut Vec<Box<MatcherPos>>,\n+    eof_items: &mut SmallVector<Box<MatcherPos>>,\n+    bb_items: &mut SmallVector<Box<MatcherPos>>,\n+    token: &Token,\n+    span: syntax_pos::Span,\n+) -> ParseResult<()> {\n     while let Some(mut item) = cur_items.pop() {\n         // When unzipped trees end, remove them\n         while item.idx >= item.top_elts.len() {\n@@ -306,7 +312,7 @@ fn inner_parse_loop(sess: &ParseSess,\n                     item.top_elts = elts;\n                     item.idx = idx + 1;\n                 }\n-                None => break\n+                None => break,\n             }\n         }\n \n@@ -341,11 +347,16 @@ fn inner_parse_loop(sess: &ParseSess,\n                 // Check if we need a separator\n                 if idx == len && item.sep.is_some() {\n                     // We have a separator, and it is the current token.\n-                    if item.sep.as_ref().map(|sep| token_name_eq(token, sep)).unwrap_or(false) {\n+                    if item.sep\n+                        .as_ref()\n+                        .map(|sep| token_name_eq(token, sep))\n+                        .unwrap_or(false)\n+                    {\n                         item.idx += 1;\n                         next_items.push(item);\n                     }\n-                } else { // we don't need a separator\n+                } else {\n+                    // we don't need a separator\n                     item.match_cur = item.match_lo;\n                     item.idx = 0;\n                     cur_items.push(item);\n@@ -418,12 +429,13 @@ fn inner_parse_loop(sess: &ParseSess,\n     Success(())\n }\n \n-pub fn parse(sess: &ParseSess,\n-             tts: TokenStream,\n-             ms: &[TokenTree],\n-             directory: Option<Directory>,\n-             recurse_into_modules: bool)\n-             -> NamedParseResult {\n+pub fn parse(\n+    sess: &ParseSess,\n+    tts: TokenStream,\n+    ms: &[TokenTree],\n+    directory: Option<Directory>,\n+    recurse_into_modules: bool,\n+) -> NamedParseResult {\n     let mut parser = Parser::new(sess, tts, directory, recurse_into_modules, true);\n     let mut cur_items = SmallVector::one(initial_matcher_pos(ms.to_owned(), parser.span.lo()));\n     let mut next_items = Vec::new(); // or proceed normally\n@@ -433,9 +445,16 @@ pub fn parse(sess: &ParseSess,\n         let mut eof_items = SmallVector::new();\n         assert!(next_items.is_empty());\n \n-        match inner_parse_loop(sess, &mut cur_items, &mut next_items, &mut eof_items, &mut bb_items,\n-                               &parser.token, parser.span) {\n-            Success(_) => {},\n+        match inner_parse_loop(\n+            sess,\n+            &mut cur_items,\n+            &mut next_items,\n+            &mut eof_items,\n+            &mut bb_items,\n+            &parser.token,\n+            parser.span,\n+        ) {\n+            Success(_) => {}\n             Failure(sp, tok) => return Failure(sp, tok),\n             Error(sp, msg) => return Error(sp, msg),\n         }\n@@ -446,43 +465,56 @@ pub fn parse(sess: &ParseSess,\n         /* error messages here could be improved with links to orig. rules */\n         if token_name_eq(&parser.token, &token::Eof) {\n             if eof_items.len() == 1 {\n-                let matches = eof_items[0].matches.iter_mut().map(|dv| {\n-                    Rc::make_mut(dv).pop().unwrap()\n-                });\n+                let matches = eof_items[0]\n+                    .matches\n+                    .iter_mut()\n+                    .map(|dv| Rc::make_mut(dv).pop().unwrap());\n                 return nameize(sess, ms, matches);\n             } else if eof_items.len() > 1 {\n-                return Error(parser.span, \"ambiguity: multiple successful parses\".to_string());\n+                return Error(\n+                    parser.span,\n+                    \"ambiguity: multiple successful parses\".to_string(),\n+                );\n             } else {\n                 return Failure(parser.span, token::Eof);\n             }\n         } else if (!bb_items.is_empty() && !next_items.is_empty()) || bb_items.len() > 1 {\n-            let nts = bb_items.iter().map(|item| match item.top_elts.get_tt(item.idx) {\n-                TokenTree::MetaVarDecl(_, bind, name) => {\n-                    format!(\"{} ('{}')\", name, bind)\n-                }\n-                _ => panic!()\n-            }).collect::<Vec<String>>().join(\" or \");\n-\n-            return Error(parser.span, format!(\n-                \"local ambiguity: multiple parsing options: {}\",\n-                match next_items.len() {\n-                    0 => format!(\"built-in NTs {}.\", nts),\n-                    1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n-                    n => format!(\"built-in NTs {} or {} other options.\", nts, n),\n-                }\n-            ));\n+            let nts = bb_items\n+                .iter()\n+                .map(|item| match item.top_elts.get_tt(item.idx) {\n+                    TokenTree::MetaVarDecl(_, bind, name) => format!(\"{} ('{}')\", name, bind),\n+                    _ => panic!(),\n+                })\n+                .collect::<Vec<String>>()\n+                .join(\" or \");\n+\n+            return Error(\n+                parser.span,\n+                format!(\n+                    \"local ambiguity: multiple parsing options: {}\",\n+                    match next_items.len() {\n+                        0 => format!(\"built-in NTs {}.\", nts),\n+                        1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n+                        n => format!(\"built-in NTs {} or {} other options.\", nts, n),\n+                    }\n+                ),\n+            );\n         } else if bb_items.is_empty() && next_items.is_empty() {\n             return Failure(parser.span, parser.token);\n         } else if !next_items.is_empty() {\n             /* Now process the next token */\n             cur_items.extend(next_items.drain(..));\n             parser.bump();\n-        } else /* bb_items.len() == 1 */ {\n+        } else\n+        /* bb_items.len() == 1 */\n+        {\n             let mut item = bb_items.pop().unwrap();\n             if let TokenTree::MetaVarDecl(span, _, ident) = item.top_elts.get_tt(item.idx) {\n                 let match_cur = item.match_cur;\n-                item.push_match(match_cur,\n-                    MatchedNonterminal(Rc::new(parse_nt(&mut parser, span, &ident.name.as_str()))));\n+                item.push_match(\n+                    match_cur,\n+                    MatchedNonterminal(Rc::new(parse_nt(&mut parser, span, &ident.name.as_str()))),\n+                );\n                 item.idx += 1;\n                 item.match_cur += 1;\n             } else {\n@@ -512,20 +544,21 @@ fn may_begin_with(name: &str, token: &Token) -> bool {\n         \"expr\" => token.can_begin_expr(),\n         \"ty\" => token.can_begin_type(),\n         \"ident\" => token.is_ident(),\n-        \"vis\" => match *token { // The follow-set of :vis + \"priv\" keyword + interpolated\n+        \"vis\" => match *token {\n+            // The follow-set of :vis + \"priv\" keyword + interpolated\n             Token::Comma | Token::Ident(_) | Token::Interpolated(_) => true,\n             _ => token.can_begin_type(),\n         },\n         \"block\" => match *token {\n             Token::OpenDelim(token::Brace) => true,\n             Token::Interpolated(ref nt) => match nt.0 {\n-                token::NtItem(_) |\n-                token::NtPat(_) |\n-                token::NtTy(_) |\n-                token::NtIdent(_) |\n-                token::NtMeta(_) |\n-                token::NtPath(_) |\n-                token::NtVis(_) => false, // none of these may start with '{'.\n+                token::NtItem(_)\n+                | token::NtPat(_)\n+                | token::NtTy(_)\n+                | token::NtIdent(_)\n+                | token::NtMeta(_)\n+                | token::NtPath(_)\n+                | token::NtVis(_) => false, // none of these may start with '{'.\n                 _ => true,\n             },\n             _ => false,\n@@ -591,12 +624,15 @@ fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         \"ident\" => match p.token {\n             token::Ident(sn) => {\n                 p.bump();\n-                token::NtIdent(Spanned::<Ident>{node: sn, span: p.prev_span})\n+                token::NtIdent(Spanned::<Ident> {\n+                    node: sn,\n+                    span: p.prev_span,\n+                })\n             }\n             _ => {\n                 let token_str = pprust::token_to_string(&p.token);\n-                p.fatal(&format!(\"expected ident, found {}\",\n-                                 &token_str[..])).emit();\n+                p.fatal(&format!(\"expected ident, found {}\", &token_str[..]))\n+                    .emit();\n                 FatalError.raise()\n             }\n         },\n@@ -606,6 +642,6 @@ fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         \"lifetime\" => token::NtLifetime(p.expect_lifetime()),\n         // this is not supposed to happen, since it has been checked\n         // when compiling the macro.\n-        _ => p.span_bug(sp, \"invalid fragment specifier\")\n+        _ => p.span_bug(sp, \"invalid fragment specifier\"),\n     }\n }"}]}