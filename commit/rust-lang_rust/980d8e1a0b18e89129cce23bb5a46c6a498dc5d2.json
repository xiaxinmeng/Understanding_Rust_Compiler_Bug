{"sha": "980d8e1a0b18e89129cce23bb5a46c6a498dc5d2", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk4MGQ4ZTFhMGIxOGU4OTEyOWNjZTIzYmI1YTQ2YzZhNDk4ZGM1ZDI=", "commit": {"author": {"name": "Thom Chiovoloni", "email": "tchiovoloni@mozilla.com", "date": "2020-07-05T17:09:29Z"}, "committer": {"name": "Thom Chiovoloni", "email": "tchiovoloni@mozilla.com", "date": "2020-07-05T17:23:50Z"}, "message": "Optimize is_ascii for &str and &[u8]", "tree": {"sha": "923c324ff39078a74d2f6b05599d58cefe5926dd", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/923c324ff39078a74d2f6b05599d58cefe5926dd"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2", "html_url": "https://github.com/rust-lang/rust/commit/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/comments", "author": null, "committer": null, "parents": [{"sha": "0cd7ff7ddfb75a38dca81ad3e76b1e984129e939", "url": "https://api.github.com/repos/rust-lang/rust/commits/0cd7ff7ddfb75a38dca81ad3e76b1e984129e939", "html_url": "https://github.com/rust-lang/rust/commit/0cd7ff7ddfb75a38dca81ad3e76b1e984129e939"}], "stats": {"total": 168, "additions": 166, "deletions": 2}, "files": [{"sha": "142f3950eec77e13d860aff9643266174d65e45f", "filename": "src/libcore/benches/ascii.rs", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/src%2Flibcore%2Fbenches%2Fascii.rs", "raw_url": "https://github.com/rust-lang/rust/raw/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/src%2Flibcore%2Fbenches%2Fascii.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fbenches%2Fascii.rs?ref=980d8e1a0b18e89129cce23bb5a46c6a498dc5d2", "patch": "@@ -230,6 +230,14 @@ benches! {\n         }\n     }\n \n+    fn is_ascii_slice_libcore(bytes: &mut [u8]) {\n+        bytes.is_ascii()\n+    }\n+\n+    fn is_ascii_slice_iter_all(bytes: &mut [u8]) {\n+        bytes.iter().all(|b| b.is_ascii())\n+    }\n+\n     @iter\n \n     is_ascii,"}, {"sha": "bed8495993f438f81354070f61738873e368b781", "filename": "src/libcore/slice/mod.rs", "status": "modified", "additions": 101, "deletions": 1, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/src%2Flibcore%2Fslice%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/src%2Flibcore%2Fslice%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fslice%2Fmod.rs?ref=980d8e1a0b18e89129cce23bb5a46c6a498dc5d2", "patch": "@@ -2795,7 +2795,7 @@ impl [u8] {\n     #[stable(feature = \"ascii_methods_on_intrinsics\", since = \"1.23.0\")]\n     #[inline]\n     pub fn is_ascii(&self) -> bool {\n-        self.iter().all(|b| b.is_ascii())\n+        is_ascii(self)\n     }\n \n     /// Checks that two slices are an ASCII case-insensitive match.\n@@ -2843,6 +2843,106 @@ impl [u8] {\n     }\n }\n \n+/// Returns `true` if any byte in the word `v` is nonascii (>= 128). Snarfed\n+/// from `../str/mod.rs`, which does something similar for utf8 validation.\n+#[inline]\n+fn contains_nonascii(v: usize) -> bool {\n+    const NONASCII_MASK: usize = 0x80808080_80808080u64 as usize;\n+    (NONASCII_MASK & v) != 0\n+}\n+\n+/// Optimized ASCII test that will use usize-at-a-time operations instead of\n+/// byte-at-a-time operations (when possible).\n+///\n+/// The algorithm we use here is pretty simple. If `s` is too short, we just\n+/// check each byte and be done with it. Otherwise:\n+///\n+/// - Read the first word with an unaligned load.\n+/// - Align the pointer, read subsequent words until end with aligned loads.\n+/// - If there's a tail, the last `usize` from `s` with an unaligned load.\n+///\n+/// If any of these loads produces something for which `contains_nonascii`\n+/// (above) returns true, then we know the answer is false.\n+#[inline]\n+fn is_ascii(s: &[u8]) -> bool {\n+    const USIZE_SIZE: usize = mem::size_of::<usize>();\n+\n+    let len = s.len();\n+    let align_offset = s.as_ptr().align_offset(USIZE_SIZE);\n+\n+    // If we wouldn't gain anything from the word-at-a-time implementation, fall\n+    // back to a scalar loop.\n+    //\n+    // We also do this for architectures where `size_of::<usize>()` isn't\n+    // sufficient alignment for `usize`, because it's a weird edge case.\n+    if len < USIZE_SIZE || len < align_offset || USIZE_SIZE < mem::align_of::<usize>() {\n+        return s.iter().all(|b| b.is_ascii());\n+    }\n+\n+    // We always read the first word unaligned, which means `align_offset` is\n+    // 0, we'd read the same value again for the aligned read.\n+    let offset_to_aligned = if align_offset == 0 { USIZE_SIZE } else { align_offset };\n+\n+    let start = s.as_ptr();\n+    // SAFETY: We verify `len < USIZE_SIZE` above.\n+    let first_word = unsafe { (start as *const usize).read_unaligned() };\n+\n+    if contains_nonascii(first_word) {\n+        return false;\n+    }\n+    // We checked this above, somewhat implicitly. Note that `offset_to_aligned`\n+    // is either `align_offset` or `USIZE_SIZE`, both of are explicitly checked\n+    // above.\n+    debug_assert!(offset_to_aligned <= len);\n+\n+    // word_ptr is the (properly aligned) usize ptr we use to read the middle chunk of the slice.\n+    let mut word_ptr = unsafe { start.add(offset_to_aligned) as *const usize };\n+\n+    // `byte_pos` is the byte index of `word_ptr`, used for loop end checks.\n+    let mut byte_pos = offset_to_aligned;\n+\n+    // Paranoia check about alignment, since we're about to do a bunch of\n+    // unaligned loads. In practice this should be impossible barring a bug in\n+    // `align_offset` though.\n+    debug_assert_eq!((word_ptr as usize) % mem::align_of::<usize>(), 0);\n+\n+    while byte_pos <= len - USIZE_SIZE {\n+        debug_assert!(\n+            // Sanity check that the read is in bounds\n+            (word_ptr as usize + USIZE_SIZE) <= (start.wrapping_add(len) as usize) &&\n+            // And that our assumptions about `byte_pos` hold.\n+            (word_ptr as usize) - (start as usize) == byte_pos\n+        );\n+\n+        // Safety: We know `word_ptr` is properly aligned (because of\n+        // `align_offset`), and we know that we have enough bytes between `word_ptr` and the end\n+        let word = unsafe { word_ptr.read() };\n+        if contains_nonascii(word) {\n+            return false;\n+        }\n+\n+        byte_pos += USIZE_SIZE;\n+        // SAFETY: We know that `byte_pos <= len - USIZE_SIZE`, which means that\n+        // after this `add`, `word_ptr` will be at most one-past-the-end.\n+        word_ptr = unsafe { word_ptr.add(1) };\n+    }\n+\n+    // If we have anything left over, it should be at-most 1 usize worth of bytes,\n+    // which we check with a read_unaligned.\n+    if byte_pos == len {\n+        return true;\n+    }\n+\n+    // Sanity check to ensure there really is only one `usize` left. This should\n+    // be guaranteed by our loop condition.\n+    debug_assert!(byte_pos < len && len - byte_pos < USIZE_SIZE);\n+\n+    // SAFETY: This relies on `len >= USIZE_SIZE`, which we check at the start.\n+    let last_word = unsafe { (start.add(len - USIZE_SIZE) as *const usize).read_unaligned() };\n+\n+    !contains_nonascii(last_word)\n+}\n+\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<T, I> ops::Index<I> for [T]\n where"}, {"sha": "003ed7df36e2a44d07943c718542e9c25e29eedf", "filename": "src/libcore/str/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/src%2Flibcore%2Fstr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/src%2Flibcore%2Fstr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fstr%2Fmod.rs?ref=980d8e1a0b18e89129cce23bb5a46c6a498dc5d2", "patch": "@@ -4348,7 +4348,7 @@ impl str {\n         // We can treat each byte as character here: all multibyte characters\n         // start with a byte that is not in the ascii range, so we will stop\n         // there already.\n-        self.bytes().all(|b| b.is_ascii())\n+        self.as_bytes().is_ascii()\n     }\n \n     /// Checks that two strings are an ASCII case-insensitive match."}, {"sha": "57f2de16b2b37522b78d8785b6b5fd6d5f9e7908", "filename": "src/libcore/tests/ascii.rs", "status": "modified", "additions": 56, "deletions": 0, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/src%2Flibcore%2Ftests%2Fascii.rs", "raw_url": "https://github.com/rust-lang/rust/raw/980d8e1a0b18e89129cce23bb5a46c6a498dc5d2/src%2Flibcore%2Ftests%2Fascii.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftests%2Fascii.rs?ref=980d8e1a0b18e89129cce23bb5a46c6a498dc5d2", "patch": "@@ -343,3 +343,59 @@ fn test_is_ascii_control() {\n         \" \",\n     );\n }\n+\n+// `is_ascii` does a good amount of pointer manipulation and has\n+// alignment-dependent computation. This is all sanity-checked via\n+// `debug_assert!`s, so we test various sizes/alignments thoroughly versus an\n+// \"obviously correct\" baseline function.\n+#[test]\n+fn test_is_ascii_align_size_thoroughly() {\n+    // The \"obviously-correct\" baseline mentioned above.\n+    fn is_ascii_baseline(s: &[u8]) -> bool {\n+        s.iter().all(|b| b.is_ascii())\n+    }\n+\n+    // Helper to repeat `l` copies of `b0` followed by `l` copies of `b1`.\n+    fn repeat_concat(b0: u8, b1: u8, l: usize) -> Vec<u8> {\n+        use core::iter::repeat;\n+        repeat(b0).take(l).chain(repeat(b1).take(l)).collect()\n+    }\n+\n+    // Miri is too slow for much of this, and in miri `align_offset` always\n+    // returns `usize::max_value()` anyway (at the moment), so we just test\n+    // lightly.\n+    let iter = if cfg!(miri) { 0..5 } else { 0..100 };\n+\n+    for i in iter {\n+        #[cfg(not(miri))]\n+        let cases = &[\n+            b\"a\".repeat(i),\n+            b\"\\0\".repeat(i),\n+            b\"\\x7f\".repeat(i),\n+            b\"\\x80\".repeat(i),\n+            b\"\\xff\".repeat(i),\n+            repeat_concat(b'a', 0x80u8, i),\n+            repeat_concat(0x80u8, b'a', i),\n+        ];\n+\n+        #[cfg(miri)]\n+        let cases = &[repeat_concat(b'a', 0x80u8, i)];\n+\n+        for case in cases {\n+            for pos in 0..=case.len() {\n+                // Potentially misaligned head\n+                let prefix = &case[pos..];\n+                assert_eq!(is_ascii_baseline(prefix), prefix.is_ascii(),);\n+\n+                // Potentially misaligned tail\n+                let suffix = &case[..case.len() - pos];\n+\n+                assert_eq!(is_ascii_baseline(suffix), suffix.is_ascii(),);\n+\n+                // Both head and tail are potentially misaligned\n+                let mid = &case[(pos / 2)..(case.len() - (pos / 2))];\n+                assert_eq!(is_ascii_baseline(mid), mid.is_ascii(),);\n+            }\n+        }\n+    }\n+}"}]}