{"sha": "cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "node_id": "MDY6Q29tbWl0NzI0NzEyOmNkMDQ5NTkxYTI1OTczY2Q0MWNhNWI2OWU3YTE1MWFlNWZhMGI3MWY=", "commit": {"author": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-27T15:01:44Z"}, "committer": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-28T04:55:37Z"}, "message": "Use an enum rather than a bool in token::Ident", "tree": {"sha": "e2c5dc3408d805d9bb4a2cfa0b4cdb0d64080749", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e2c5dc3408d805d9bb4a2cfa0b4cdb0d64080749"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "html_url": "https://github.com/rust-lang/rust/commit/cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/comments", "author": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "url": "https://api.github.com/repos/rust-lang/rust/commits/fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "html_url": "https://github.com/rust-lang/rust/commit/fcb78d65f2a3b553b9aaca762910daf10fbb1dce"}], "stats": {"total": 153, "additions": 96, "deletions": 57}, "files": [{"sha": "fef7d3510e7a3972e1faf764e9c5b0fe0aa8a661", "filename": "src/grammar/verify.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Fgrammar%2Fverify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Fgrammar%2Fverify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fgrammar%2Fverify.rs?ref=cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "patch": "@@ -35,7 +35,7 @@ use syntax::parse::lexer::TokenAndSpan;\n \n fn parse_token_list(file: &str) -> HashMap<String, Token> {\n     fn id() -> Token {\n-        token::Ident(ast::Ident { name: Name(0), ctxt: 0, }, false)\n+        token::Ident(ast::Ident { name: Name(0), ctxt: 0, }, token::Plain)\n     }\n \n     let mut res = HashMap::new();\n@@ -198,7 +198,8 @@ fn parse_antlr_token(s: &str, tokens: &HashMap<String, Token>) -> TokenAndSpan {\n         token::LitFloat(..)        => token::LitFloat(nm),\n         token::LitBinary(..)       => token::LitBinary(nm),\n         token::LitBinaryRaw(..)    => token::LitBinaryRaw(fix(content), count(content)),\n-        token::Ident(..)           => token::Ident(ast::Ident { name: nm, ctxt: 0 }, true),\n+        token::Ident(..)           => token::Ident(ast::Ident { name: nm, ctxt: 0 },\n+                                                   token::ModName),\n         token::Lifetime(..)        => token::Lifetime(ast::Ident { name: nm, ctxt: 0 }),\n         ref t => t.clone()\n     };"}, {"sha": "dc7a495523f22da858d9ee95c9f4aa65168f70a4", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "patch": "@@ -531,6 +531,7 @@ fn mk_binop(cx: &ExtCtxt, sp: Span, bop: token::BinOpToken) -> P<ast::Expr> {\n     mk_token_path(cx, sp, name)\n }\n \n+#[allow(non_uppercase_statics)] // NOTE(stage0): remove this attribute after the next snapshot\n fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n     match *tok {\n         token::BinOp(binop) => {\n@@ -575,10 +576,14 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n                                 vec!(mk_name(cx, sp, ident.ident()), cx.expr_uint(sp, n)));\n         }\n \n-        token::Ident(ident, b) => {\n+        token::Ident(ident, style) => {\n             return cx.expr_call(sp,\n                                 mk_token_path(cx, sp, \"Ident\"),\n-                                vec!(mk_ident(cx, sp, ident), cx.expr_bool(sp, b)));\n+                                vec![mk_ident(cx, sp, ident),\n+                                     match style {\n+                                        ModName => mk_token_path(cx, sp, \"ModName\"),\n+                                        Plain   => mk_token_path(cx, sp, \"Plain\"),\n+                                     }]);\n         }\n \n         token::Lifetime(ident) => {"}, {"sha": "b439353ad956646e712f91c5b7c279239569cf04", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 36, "deletions": 25, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "patch": "@@ -921,12 +921,14 @@ impl<'a> StringReader<'a> {\n                 if string == \"_\" {\n                     token::Underscore\n                 } else {\n-                    let is_mod_name = self.curr_is(':') && self.nextch_is(':');\n-\n                     // FIXME: perform NFKC normalization here. (Issue #2253)\n-                    token::Ident(str_to_ident(string), is_mod_name)\n+                    if self.curr_is(':') && self.nextch_is(':') {\n+                        token::Ident(str_to_ident(string), token::ModName)\n+                    } else {\n+                        token::Ident(str_to_ident(string), token::Plain)\n+                    }\n                 }\n-            })\n+            });\n         }\n \n         if is_dec_digit(c) {\n@@ -937,8 +939,11 @@ impl<'a> StringReader<'a> {\n             match (c.unwrap(), self.nextch(), self.nextnextch()) {\n                 ('\\x00', Some('n'), Some('a')) => {\n                     let ast_ident = self.scan_embedded_hygienic_ident();\n-                    let is_mod_name = self.curr_is(':') && self.nextch_is(':');\n-                    return token::Ident(ast_ident, is_mod_name);\n+                    return if self.curr_is(':') && self.nextch_is(':') {\n+                        token::Ident(ast_ident, token::ModName)\n+                    } else {\n+                        token::Ident(ast_ident, token::Plain)\n+                    };\n                 }\n                 _ => {}\n             }\n@@ -1056,7 +1061,7 @@ impl<'a> StringReader<'a> {\n                         str_to_ident(lifetime_name)\n                     });\n                 let keyword_checking_token =\n-                    &token::Ident(keyword_checking_ident, false);\n+                    &token::Ident(keyword_checking_ident, token::Plain);\n                 let last_bpos = self.last_pos;\n                 if keyword_checking_token.is_keyword(token::keywords::Self) {\n                     self.err_span_(start,\n@@ -1434,7 +1439,7 @@ mod test {\n         assert_eq!(string_reader.next_token().tok, token::Whitespace);\n         let tok1 = string_reader.next_token();\n         let tok2 = TokenAndSpan{\n-            tok:token::Ident(id, false),\n+            tok:token::Ident(id, token::Plain),\n             sp:Span {lo:BytePos(21),hi:BytePos(23),expn_id: NO_EXPANSION}};\n         assert_eq!(tok1,tok2);\n         assert_eq!(string_reader.next_token().tok, token::Whitespace);\n@@ -1443,7 +1448,7 @@ mod test {\n         // read another token:\n         let tok3 = string_reader.next_token();\n         let tok4 = TokenAndSpan{\n-            tok:token::Ident(str_to_ident(\"main\"), false),\n+            tok:token::Ident(str_to_ident(\"main\"), token::Plain),\n             sp:Span {lo:BytePos(24),hi:BytePos(28),expn_id: NO_EXPANSION}};\n         assert_eq!(tok3,tok4);\n         // the lparen is already read:\n@@ -1458,39 +1463,45 @@ mod test {\n         }\n     }\n \n-    // make the identifier by looking up the string in the interner\n+    #[cfg(stage0)]\n     fn mk_ident (id: &str, is_mod_name: bool) -> token::Token {\n-        token::Ident (str_to_ident(id),is_mod_name)\n+        token::Ident(str_to_ident(id), is_mod_name)\n+    }\n+\n+    // make the identifier by looking up the string in the interner\n+    #[cfg(not(stage0))]\n+    fn mk_ident(id: &str, style: token::IdentStyle) -> token::Token {\n+        token::Ident(str_to_ident(id), style)\n     }\n \n     #[test] fn doublecolonparsing () {\n         check_tokenization(setup(&mk_sh(), \"a b\".to_string()),\n-                           vec!(mk_ident(\"a\",false),\n-                            token::Whitespace,\n-                             mk_ident(\"b\",false)));\n+                           vec![mk_ident(\"a\", token::Plain),\n+                                token::Whitespace,\n+                                mk_ident(\"b\", token::Plain)]);\n     }\n \n     #[test] fn dcparsing_2 () {\n         check_tokenization(setup(&mk_sh(), \"a::b\".to_string()),\n-                           vec!(mk_ident(\"a\",true),\n-                             token::ModSep,\n-                             mk_ident(\"b\",false)));\n+                           vec![mk_ident(\"a\",token::ModName),\n+                                token::ModSep,\n+                                mk_ident(\"b\", token::Plain)]);\n     }\n \n     #[test] fn dcparsing_3 () {\n         check_tokenization(setup(&mk_sh(), \"a ::b\".to_string()),\n-                           vec!(mk_ident(\"a\",false),\n-                             token::Whitespace,\n-                             token::ModSep,\n-                             mk_ident(\"b\",false)));\n+                           vec![mk_ident(\"a\", token::Plain),\n+                                token::Whitespace,\n+                                token::ModSep,\n+                                mk_ident(\"b\", token::Plain)]);\n     }\n \n     #[test] fn dcparsing_4 () {\n         check_tokenization(setup(&mk_sh(), \"a:: b\".to_string()),\n-                           vec!(mk_ident(\"a\",true),\n-                             token::ModSep,\n-                             token::Whitespace,\n-                             mk_ident(\"b\",false)));\n+                           vec![mk_ident(\"a\",token::ModName),\n+                                token::ModSep,\n+                                token::Whitespace,\n+                                mk_ident(\"b\", token::Plain)]);\n     }\n \n     #[test] fn character_a() {"}, {"sha": "e60da0867f7553792f3c2f3b981ee4a98ef4e6b1", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "patch": "@@ -793,9 +793,9 @@ mod test {\n         let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_string());\n         let tts: &[ast::TokenTree] = tts.as_slice();\n         match tts {\n-            [ast::TtToken(_, token::Ident(name_macro_rules, false)),\n+            [ast::TtToken(_, token::Ident(name_macro_rules, token::Plain)),\n              ast::TtToken(_, token::Not),\n-             ast::TtToken(_, token::Ident(name_zip, false)),\n+             ast::TtToken(_, token::Ident(name_zip, token::Plain)),\n              ast::TtDelimited(_, ref macro_delimed)]\n             if name_macro_rules.as_str() == \"macro_rules\"\n             && name_zip.as_str() == \"zip\" => {\n@@ -810,7 +810,7 @@ mod test {\n                         match (first_open, first_tts.as_slice(), first_close) {\n                             (&ast::Delimiter { token: token::LParen, .. },\n                              [ast::TtToken(_, token::Dollar),\n-                              ast::TtToken(_, token::Ident(name, false))],\n+                              ast::TtToken(_, token::Ident(name, token::Plain))],\n                              &ast::Delimiter { token: token::RParen, .. })\n                             if name.as_str() == \"a\" => {},\n                             _ => fail!(\"value 3: {}\", **first_delimed),\n@@ -819,7 +819,7 @@ mod test {\n                         match (second_open, second_tts.as_slice(), second_close) {\n                             (&ast::Delimiter { token: token::LParen, .. },\n                              [ast::TtToken(_, token::Dollar),\n-                              ast::TtToken(_, token::Ident(name, false))],\n+                              ast::TtToken(_, token::Ident(name, token::Plain))],\n                              &ast::Delimiter { token: token::RParen, .. })\n                             if name.as_str() == \"a\" => {},\n                             _ => fail!(\"value 4: {}\", **second_delimed),\n@@ -845,7 +845,7 @@ mod test {\n                 \\\"variant\\\":\\\"Ident\\\",\\\n                 \\\"fields\\\":[\\\n                     \\\"fn\\\",\\\n-                    false\\\n+                    \\\"Plain\\\"\\\n                 ]\\\n             }\\\n         ]\\\n@@ -858,7 +858,7 @@ mod test {\n                 \\\"variant\\\":\\\"Ident\\\",\\\n                 \\\"fields\\\":[\\\n                     \\\"a\\\",\\\n-                    false\\\n+                    \\\"Plain\\\"\\\n                 ]\\\n             }\\\n         ]\\\n@@ -881,7 +881,7 @@ mod test {\n                                 \\\"variant\\\":\\\"Ident\\\",\\\n                                 \\\"fields\\\":[\\\n                                     \\\"b\\\",\\\n-                                    false\\\n+                                    \\\"Plain\\\"\\\n                                 ]\\\n                             }\\\n                         ]\\\n@@ -901,7 +901,7 @@ mod test {\n                                 \\\"variant\\\":\\\"Ident\\\",\\\n                                 \\\"fields\\\":[\\\n                                     \\\"int\\\",\\\n-                                    false\\\n+                                    \\\"Plain\\\"\\\n                                 ]\\\n                             }\\\n                         ]\\\n@@ -932,7 +932,7 @@ mod test {\n                                 \\\"variant\\\":\\\"Ident\\\",\\\n                                 \\\"fields\\\":[\\\n                                     \\\"b\\\",\\\n-                                    false\\\n+                                    \\\"Plain\\\"\\\n                                 ]\\\n                             }\\\n                         ]\\"}, {"sha": "54b1cc2dbad15b2d47d7a93163130256ce09eb46", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "patch": "@@ -2067,10 +2067,10 @@ impl<'a> Parser<'a> {\n             },\n             // FIXME #13626: Should be able to stick in\n             // token::SELF_KEYWORD_NAME\n-            token::Ident(id @ ast::Ident{\n-                        name: ast::Name(token::SELF_KEYWORD_NAME_NUM),\n-                        ctxt: _\n-                    } ,false) => {\n+            token::Ident(id @ ast::Ident {\n+                            name: ast::Name(token::SELF_KEYWORD_NAME_NUM),\n+                            ctxt: _\n+                         }, token::Plain) => {\n                 self.bump();\n                 let path = ast_util::ident_to_path(mk_sp(lo, hi), id);\n                 ex = ExprPath(path);\n@@ -4094,14 +4094,14 @@ impl<'a> Parser<'a> {\n \n     fn is_self_ident(&mut self) -> bool {\n         match self.token {\n-          token::Ident(id, false) => id.name == special_idents::self_.name,\n+          token::Ident(id, token::Plain) => id.name == special_idents::self_.name,\n           _ => false\n         }\n     }\n \n     fn expect_self_ident(&mut self) -> ast::Ident {\n         match self.token {\n-            token::Ident(id, false) if id.name == special_idents::self_.name => {\n+            token::Ident(id, token::Plain) if id.name == special_idents::self_.name => {\n                 self.bump();\n                 id\n             },"}, {"sha": "1a69944bffa24de0e9631d1413c299f9c42d1310", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 35, "deletions": 13, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd049591a25973cd41ca5b69e7a151ae5fa0b71f/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "patch": "@@ -98,6 +98,21 @@ pub enum BinOpToken {\n     Shr,\n }\n \n+#[cfg(stage0)]\n+#[allow(non_uppercase_statics)]\n+pub const ModName: bool = true;\n+#[cfg(stage0)]\n+#[allow(non_uppercase_statics)]\n+pub const Plain: bool = false;\n+\n+#[deriving(Clone, Encodable, Decodable, PartialEq, Eq, Hash, Show)]\n+#[cfg(not(stage0))]\n+pub enum IdentStyle {\n+    /// `::` follows the identifier with no whitespace in-between.\n+    ModName,\n+    Plain,\n+}\n+\n #[allow(non_camel_case_types)]\n #[deriving(Clone, Encodable, Decodable, PartialEq, Eq, Hash, Show)]\n pub enum Token {\n@@ -149,10 +164,10 @@ pub enum Token {\n     LitBinaryRaw(ast::Name, uint), /* raw binary str delimited by n hash symbols */\n \n     /* Name components */\n-    /// An identifier contains an \"is_mod_name\" boolean,\n-    /// indicating whether :: follows this token with no\n-    /// whitespace in between.\n+    #[cfg(stage0)]\n     Ident(ast::Ident, bool),\n+    #[cfg(not(stage0))]\n+    Ident(ast::Ident, IdentStyle),\n     Underscore,\n     Lifetime(ast::Ident),\n \n@@ -252,10 +267,11 @@ impl Token {\n \n     /// Returns `true` if the token is a path that is not followed by a `::`\n     /// token.\n+    #[allow(non_uppercase_statics)] // NOTE(stage0): remove this attribute after the next snapshot\n     pub fn is_plain_ident(&self) -> bool {\n         match *self {\n-            Ident(_, false) => true,\n-            _               => false,\n+            Ident(_, Plain) => true,\n+            _                    => false,\n         }\n     }\n \n@@ -299,18 +315,20 @@ impl Token {\n     }\n \n     /// Returns `true` if the token is a given keyword, `kw`.\n+    #[allow(non_uppercase_statics)] // NOTE(stage0): remove this attribute after the next snapshot\n     pub fn is_keyword(&self, kw: keywords::Keyword) -> bool {\n         match *self {\n-            Ident(sid, false)   => kw.to_name() == sid.name,\n-            _                   => false,\n+            Ident(sid, Plain) => kw.to_name() == sid.name,\n+            _                      => false,\n         }\n     }\n \n     /// Returns `true` if the token is either a special identifier, or a strict\n     /// or reserved keyword.\n+    #[allow(non_uppercase_statics)] // NOTE(stage0): remove this attribute after the next snapshot\n     pub fn is_any_keyword(&self) -> bool {\n         match *self {\n-            Ident(sid, false) => {\n+            Ident(sid, Plain) => {\n                 let n = sid.name;\n \n                    n == SELF_KEYWORD_NAME\n@@ -324,9 +342,10 @@ impl Token {\n     }\n \n     /// Returns `true` if the token may not appear as an identifier.\n+    #[allow(non_uppercase_statics)] // NOTE(stage0): remove this attribute after the next snapshot\n     pub fn is_strict_keyword(&self) -> bool {\n         match *self {\n-            Ident(sid, false) => {\n+            Ident(sid, Plain) => {\n                 let n = sid.name;\n \n                    n == SELF_KEYWORD_NAME\n@@ -335,7 +354,7 @@ impl Token {\n                 || STRICT_KEYWORD_START <= n\n                 && n <= STRICT_KEYWORD_FINAL\n             },\n-            Ident(sid, true) => {\n+            Ident(sid, ModName) => {\n                 let n = sid.name;\n \n                    n != SELF_KEYWORD_NAME\n@@ -349,9 +368,10 @@ impl Token {\n \n     /// Returns `true` if the token is a keyword that has been reserved for\n     /// possible future use.\n+    #[allow(non_uppercase_statics)] // NOTE(stage0): remove this attribute after the next snapshot\n     pub fn is_reserved_keyword(&self) -> bool {\n         match *self {\n-            Ident(sid, false) => {\n+            Ident(sid, Plain) => {\n                 let n = sid.name;\n \n                    RESERVED_KEYWORD_START <= n\n@@ -382,8 +402,10 @@ pub enum Nonterminal {\n     NtPat(  P<ast::Pat>),\n     NtExpr( P<ast::Expr>),\n     NtTy(   P<ast::Ty>),\n-    /// See IDENT, above, for meaning of bool in NtIdent:\n+    #[cfg(stage0)]\n     NtIdent(Box<ast::Ident>, bool),\n+    #[cfg(not(stage0))]\n+    NtIdent(Box<ast::Ident>, IdentStyle),\n     /// Stuff inside brackets for attributes\n     NtMeta( P<ast::MetaItem>),\n     NtPath(Box<ast::Path>),\n@@ -857,6 +879,6 @@ mod test {\n         assert!(Gt.mtwt_eq(&Gt));\n         let a = str_to_ident(\"bac\");\n         let a1 = mark_ident(a,92);\n-        assert!(Ident(a,true).mtwt_eq(&Ident(a1,false)));\n+        assert!(Ident(a, ModName).mtwt_eq(&Ident(a1, Plain)));\n     }\n }"}]}