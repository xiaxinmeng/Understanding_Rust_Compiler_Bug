{"sha": "c4befe1710b3c394018ca65a6e99e109d081f16e", "node_id": "MDY6Q29tbWl0NzI0NzEyOmM0YmVmZTE3MTBiM2MzOTQwMThjYTY1YTZlOTllMTA5ZDA4MWYxNmU=", "commit": {"author": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-19T21:46:15Z"}, "committer": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-19T21:46:15Z"}, "message": "Run rustfmt and add comments", "tree": {"sha": "abe04f44cfb00302a524d56f84abbbd7fd494e7d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/abe04f44cfb00302a524d56f84abbbd7fd494e7d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c4befe1710b3c394018ca65a6e99e109d081f16e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c4befe1710b3c394018ca65a6e99e109d081f16e", "html_url": "https://github.com/rust-lang/rust/commit/c4befe1710b3c394018ca65a6e99e109d081f16e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c4befe1710b3c394018ca65a6e99e109d081f16e/comments", "author": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3bd4af88bea2e6ecdd3455ed89b3ef1fc3500aa4", "url": "https://api.github.com/repos/rust-lang/rust/commits/3bd4af88bea2e6ecdd3455ed89b3ef1fc3500aa4", "html_url": "https://github.com/rust-lang/rust/commit/3bd4af88bea2e6ecdd3455ed89b3ef1fc3500aa4"}], "stats": {"total": 141, "additions": 103, "deletions": 38}, "files": [{"sha": "ee87a612345ecbc5878e2bbc215da0313682a61b", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 103, "deletions": 38, "changes": 141, "blob_url": "https://github.com/rust-lang/rust/blob/c4befe1710b3c394018ca65a6e99e109d081f16e/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c4befe1710b3c394018ca65a6e99e109d081f16e/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=c4befe1710b3c394018ca65a6e99e109d081f16e", "patch": "@@ -10,10 +10,10 @@\n \n use ast;\n use ext::tt::macro_parser;\n-use parse::{ParseSess, token};\n+use parse::{token, ParseSess};\n use print::pprust;\n use symbol::keywords;\n-use syntax_pos::{DUMMY_SP, Span, BytePos};\n+use syntax_pos::{BytePos, Span, DUMMY_SP};\n use tokenstream;\n \n use std::rc::Rc;\n@@ -68,7 +68,9 @@ pub struct SequenceRepetition {\n /// for token sequences.\n #[derive(Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n pub enum KleeneOp {\n+    /// Kleene star (`*`) for zero or more repetitions\n     ZeroOrMore,\n+    /// Kleene star (`+`) for one or more repetitions\n     OneOrMore,\n }\n \n@@ -83,7 +85,11 @@ pub enum TokenTree {\n     /// E.g. `$var`\n     MetaVar(Span, ast::Ident),\n     /// E.g. `$var:expr`. This is only used in the left hand side of MBE macros.\n-    MetaVarDecl(Span, ast::Ident /* name to bind */, ast::Ident /* kind of nonterminal */),\n+    MetaVarDecl(\n+        Span,\n+        ast::Ident, /* name to bind */\n+        ast::Ident, /* kind of nonterminal */\n+    ),\n }\n \n impl TokenTree {\n@@ -131,17 +137,20 @@ impl TokenTree {\n     /// Retrieve the `TokenTree`'s span.\n     pub fn span(&self) -> Span {\n         match *self {\n-            TokenTree::Token(sp, _) |\n-            TokenTree::MetaVar(sp, _) |\n-            TokenTree::MetaVarDecl(sp, _, _) |\n-            TokenTree::Delimited(sp, _) |\n-            TokenTree::Sequence(sp, _) => sp,\n+            TokenTree::Token(sp, _)\n+            | TokenTree::MetaVar(sp, _)\n+            | TokenTree::MetaVarDecl(sp, _, _)\n+            | TokenTree::Delimited(sp, _)\n+            | TokenTree::Sequence(sp, _) => sp,\n         }\n     }\n }\n \n-pub fn parse(input: tokenstream::TokenStream, expect_matchers: bool, sess: &ParseSess)\n-             -> Vec<TokenTree> {\n+pub fn parse(\n+    input: tokenstream::TokenStream,\n+    expect_matchers: bool,\n+    sess: &ParseSess,\n+) -> Vec<TokenTree> {\n     let mut result = Vec::new();\n     let mut trees = input.trees();\n     while let Some(tree) = trees.next() {\n@@ -154,29 +163,39 @@ pub fn parse(input: tokenstream::TokenStream, expect_matchers: bool, sess: &Pars\n                             Some(kind) => {\n                                 let span = end_sp.with_lo(start_sp.lo());\n                                 result.push(TokenTree::MetaVarDecl(span, ident, kind));\n-                                continue\n+                                continue;\n                             }\n                             _ => end_sp,\n                         },\n-                        tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n+                        tree => tree.as_ref()\n+                            .map(tokenstream::TokenTree::span)\n+                            .unwrap_or(span),\n                     },\n-                    tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(start_sp),\n+                    tree => tree.as_ref()\n+                        .map(tokenstream::TokenTree::span)\n+                        .unwrap_or(start_sp),\n                 };\n                 sess.missing_fragment_specifiers.borrow_mut().insert(span);\n-                result.push(TokenTree::MetaVarDecl(span, ident, keywords::Invalid.ident()));\n+                result.push(TokenTree::MetaVarDecl(\n+                    span,\n+                    ident,\n+                    keywords::Invalid.ident(),\n+                ));\n             }\n             _ => result.push(tree),\n         }\n     }\n     result\n }\n \n-fn parse_tree<I>(tree: tokenstream::TokenTree,\n-                 trees: &mut I,\n-                 expect_matchers: bool,\n-                 sess: &ParseSess)\n-                 -> TokenTree\n-    where I: Iterator<Item = tokenstream::TokenTree>,\n+fn parse_tree<I>(\n+    tree: tokenstream::TokenTree,\n+    trees: &mut I,\n+    expect_matchers: bool,\n+    sess: &ParseSess,\n+) -> TokenTree\n+where\n+    I: Iterator<Item = tokenstream::TokenTree>,\n {\n     match tree {\n         tokenstream::TokenTree::Token(span, token::Dollar) => match trees.next() {\n@@ -189,43 +208,69 @@ fn parse_tree<I>(tree: tokenstream::TokenTree,\n                 let sequence = parse(delimited.tts.into(), expect_matchers, sess);\n                 let (separator, op) = parse_sep_and_kleene_op(trees, span, sess);\n                 let name_captures = macro_parser::count_names(&sequence);\n-                TokenTree::Sequence(span, Rc::new(SequenceRepetition {\n-                    tts: sequence,\n-                    separator,\n-                    op,\n-                    num_captures: name_captures,\n-                }))\n+                TokenTree::Sequence(\n+                    span,\n+                    Rc::new(SequenceRepetition {\n+                        tts: sequence,\n+                        separator,\n+                        op,\n+                        num_captures: name_captures,\n+                    }),\n+                )\n             }\n             Some(tokenstream::TokenTree::Token(ident_span, ref token)) if token.is_ident() => {\n                 let ident = token.ident().unwrap();\n                 let span = ident_span.with_lo(span.lo());\n                 if ident.name == keywords::Crate.name() {\n-                    let ident = ast::Ident { name: keywords::DollarCrate.name(), ..ident };\n+                    let ident = ast::Ident {\n+                        name: keywords::DollarCrate.name(),\n+                        ..ident\n+                    };\n                     TokenTree::Token(span, token::Ident(ident))\n                 } else {\n                     TokenTree::MetaVar(span, ident)\n                 }\n             }\n             Some(tokenstream::TokenTree::Token(span, tok)) => {\n-                let msg = format!(\"expected identifier, found `{}`\", pprust::token_to_string(&tok));\n+                let msg = format!(\n+                    \"expected identifier, found `{}`\",\n+                    pprust::token_to_string(&tok)\n+                );\n                 sess.span_diagnostic.span_err(span, &msg);\n                 TokenTree::MetaVar(span, keywords::Invalid.ident())\n             }\n             None => TokenTree::Token(span, token::Dollar),\n         },\n         tokenstream::TokenTree::Token(span, tok) => TokenTree::Token(span, tok),\n-        tokenstream::TokenTree::Delimited(span, delimited) => {\n-            TokenTree::Delimited(span, Rc::new(Delimited {\n+        tokenstream::TokenTree::Delimited(span, delimited) => TokenTree::Delimited(\n+            span,\n+            Rc::new(Delimited {\n                 delim: delimited.delim,\n                 tts: parse(delimited.tts.into(), expect_matchers, sess),\n-            }))\n-        }\n+            }),\n+        ),\n     }\n }\n \n-fn parse_sep_and_kleene_op<I>(input: &mut I, span: Span, sess: &ParseSess)\n-                              -> (Option<token::Token>, KleeneOp)\n-    where I: Iterator<Item = tokenstream::TokenTree>,\n+/// Attempt to parse a single Kleene star, possibly with a separator.\n+///\n+/// For example, in a pattern such as `$(a),*`, `a` is the pattern to be repeated, `,` is the\n+/// separator, and `*` is the Kleene operator. This function is specifically concerned with parsing\n+/// the last two tokens of such a pattern: namely, the optional separator and the Kleene operator\n+/// itself. Note that here we are parsing the _pattern_ itself, rather than trying to match some\n+/// stream of tokens against the pattern.\n+///\n+/// This function will take some input iterator `input` corresponding to `span` and a parsing\n+/// session `sess`. If the next one (or possibly two) tokens in `input` correspond to a Kleene\n+/// operator and separator, then a tuple with `(separator, KleeneOp)` is returned. Otherwise, an\n+/// error with the appropriate span is emitted to `sess` and a dummy value is returned.\n+fn parse_sep_and_kleene_op<I>(\n+    input: &mut I,\n+    span: Span,\n+    sess: &ParseSess,\n+) -> (Option<token::Token>, KleeneOp)\n+where\n+    I: Iterator<Item = tokenstream::TokenTree>,\n {\n     fn kleene_op(token: &token::Token) -> Option<KleeneOp> {\n         match *token {\n@@ -235,20 +280,40 @@ fn parse_sep_and_kleene_op<I>(input: &mut I, span: Span, sess: &ParseSess)\n         }\n     }\n \n+    // We attempt to look at the next two token trees in `input`. I will call the first #1 and the\n+    // second #2. If #1 and #2 don't match a valid KleeneOp with/without separator, that is an\n+    // error, and we should emit an error on the most specific span possible.\n     let span = match input.next() {\n+        // #1 is a token\n         Some(tokenstream::TokenTree::Token(span, tok)) => match kleene_op(&tok) {\n+            // #1 is a KleeneOp with no separator\n             Some(op) => return (None, op),\n+\n+            // #1 is not a KleeneOp, but may be a separator... need to look at #2\n             None => match input.next() {\n+                // #2 is a token\n                 Some(tokenstream::TokenTree::Token(span, tok2)) => match kleene_op(&tok2) {\n+                    // #2 is a KleeneOp, so #1 must be a separator\n                     Some(op) => return (Some(tok), op),\n+\n+                    // #2 is not a KleeneOp... error\n                     None => span,\n                 },\n-                tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n-            }\n+\n+                // #2 is not a token at all... error\n+                tree => tree.as_ref()\n+                    .map(tokenstream::TokenTree::span)\n+                    .unwrap_or(span),\n+            },\n         },\n-        tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n+\n+        // #1 is not a token at all... error\n+        tree => tree.as_ref()\n+            .map(tokenstream::TokenTree::span)\n+            .unwrap_or(span),\n     };\n \n+    // Error...\n     sess.span_diagnostic.span_err(span, \"expected `*` or `+`\");\n     (None, KleeneOp::ZeroOrMore)\n }"}]}