{"sha": "abdc68973ea5961c3e942c7176c2894d00c547d7", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFiZGM2ODk3M2VhNTk2MWMzZTk0MmM3MTc2YzI4OTRkMDBjNTQ3ZDc=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-27T11:00:10Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-02-28T22:13:37Z"}, "message": "Clean up `ext::tt::transcribe::TtFrame`, rename to `Frame`.", "tree": {"sha": "076415345c5fc084c1532acef5e09ae00fb05e26", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/076415345c5fc084c1532acef5e09ae00fb05e26"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/abdc68973ea5961c3e942c7176c2894d00c547d7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/abdc68973ea5961c3e942c7176c2894d00c547d7", "html_url": "https://github.com/rust-lang/rust/commit/abdc68973ea5961c3e942c7176c2894d00c547d7", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/abdc68973ea5961c3e942c7176c2894d00c547d7/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d09e512158dcc86ad6e41231537ce960f3b2e918", "url": "https://api.github.com/repos/rust-lang/rust/commits/d09e512158dcc86ad6e41231537ce960f3b2e918", "html_url": "https://github.com/rust-lang/rust/commit/d09e512158dcc86ad6e41231537ce960f3b2e918"}], "stats": {"total": 149, "additions": 88, "deletions": 61}, "files": [{"sha": "9f3d937b056c2bbc9d7a85c9a5b7710872a9c016", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 84, "deletions": 57, "changes": 141, "blob_url": "https://github.com/rust-lang/rust/blob/abdc68973ea5961c3e942c7176c2894d00c547d7/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/abdc68973ea5961c3e942c7176c2894d00c547d7/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=abdc68973ea5961c3e942c7176c2894d00c547d7", "patch": "@@ -14,27 +14,71 @@ use errors::Handler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n use parse::token::{self, MatchNt, SubstNt, Token, NtIdent, NtTT};\n use syntax_pos::{Span, DUMMY_SP};\n-use tokenstream::{self, TokenTree};\n+use tokenstream::{self, TokenTree, Delimited, SequenceRepetition};\n use util::small_vector::SmallVector;\n \n use std::rc::Rc;\n use std::ops::Add;\n use std::collections::HashMap;\n \n-///an unzipping of `TokenTree`s\n-#[derive(Clone)]\n-struct TtFrame {\n-    forest: TokenTree,\n-    idx: usize,\n-    dotdotdoted: bool,\n-    sep: Option<Token>,\n+// An iterator over the token trees in a delimited token tree (`{ ... }`) or a sequence (`$(...)`).\n+enum Frame {\n+    Delimited {\n+        forest: Rc<Delimited>,\n+        idx: usize,\n+        span: Span,\n+    },\n+    MatchNt {\n+        name: Ident,\n+        kind: Ident,\n+        idx: usize,\n+        span: Span,\n+    },\n+    Sequence {\n+        forest: Rc<SequenceRepetition>,\n+        idx: usize,\n+        sep: Option<Token>,\n+    },\n+}\n+\n+impl Iterator for Frame {\n+    type Item = TokenTree;\n+\n+    fn next(&mut self) -> Option<TokenTree> {\n+        match *self {\n+            Frame::Delimited { ref forest, ref mut idx, span } => {\n+                *idx += 1;\n+                if *idx == forest.delim.len() {\n+                    Some(forest.open_tt(span))\n+                } else if let Some(tree) = forest.tts.get(*idx - forest.delim.len() - 1) {\n+                    Some(tree.clone())\n+                } else if *idx == forest.tts.len() + 2 * forest.delim.len() {\n+                    Some(forest.close_tt(span))\n+                } else {\n+                    None\n+                }\n+            }\n+            Frame::Sequence { ref forest, ref mut idx, .. } => {\n+                *idx += 1;\n+                forest.tts.get(*idx - 1).cloned()\n+            }\n+            Frame::MatchNt { ref mut idx, name, kind, span } => {\n+                *idx += 1;\n+                match *idx {\n+                    1 => Some(TokenTree::Token(span, token::SubstNt(name))),\n+                    2 => Some(TokenTree::Token(span, token::Colon)),\n+                    3 => Some(TokenTree::Token(span, token::Ident(kind))),\n+                    _ => None,\n+                }\n+            }\n+        }\n+    }\n }\n \n-#[derive(Clone)]\n struct TtReader<'a> {\n     sp_diag: &'a Handler,\n     /// the unzipped tree:\n-    stack: SmallVector<TtFrame>,\n+    stack: SmallVector<Frame>,\n     /* for MBE-style macro transcription */\n     interpolations: HashMap<Ident, Rc<NamedMatch>>,\n \n@@ -51,15 +95,10 @@ pub fn transcribe(sp_diag: &Handler,\n                   -> Vec<TokenTree> {\n     let mut r = TtReader {\n         sp_diag: sp_diag,\n-        stack: SmallVector::one(TtFrame {\n-            forest: TokenTree::Sequence(DUMMY_SP, Rc::new(tokenstream::SequenceRepetition {\n-                tts: src,\n-                // doesn't matter. This merely holds the root unzipping.\n-                separator: None, op: tokenstream::KleeneOp::ZeroOrMore, num_captures: 0\n-            })),\n+        stack: SmallVector::one(Frame::Delimited {\n+            forest: Rc::new(tokenstream::Delimited { delim: token::NoDelim, tts: src }),\n             idx: 0,\n-            dotdotdoted: false,\n-            sep: None,\n+            span: DUMMY_SP,\n         }),\n         interpolations: match interp { /* just a convenience */\n             None => HashMap::new(),\n@@ -151,34 +190,33 @@ fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n /// EFFECT: advances the reader's token field\n fn tt_next_token(r: &mut TtReader, prev_span: Span) -> Option<TokenTree> {\n     loop {\n-        let frame = match r.stack.last() {\n-            Some(frame) => frame.clone(),\n+        let tree = match r.stack.last_mut() {\n+            Some(frame) => frame.next(),\n             None => return None,\n         };\n \n-        if frame.idx == frame.forest.len() {\n-            if frame.dotdotdoted &&\n-               *r.repeat_idx.last().unwrap() == *r.repeat_len.last().unwrap() - 1 {\n-                *r.repeat_idx.last_mut().unwrap() += 1;\n-                r.stack.last_mut().unwrap().idx = 0;\n-                if let Some(tk) = r.stack.last().unwrap().sep.clone() {\n-                    return Some(TokenTree::Token(prev_span, tk)); // repeat same span, I guess\n-                }\n-            } else {\n-                r.stack.pop();\n-                match r.stack.last_mut() {\n-                    Some(frame) => frame.idx += 1,\n-                    None => return None,\n-                }\n-                if frame.dotdotdoted {\n-                    r.repeat_idx.pop();\n-                    r.repeat_len.pop();\n+        let tree = if let Some(tree) = tree {\n+            tree\n+        } else {\n+            if let Frame::Sequence { ref mut idx, ref sep, .. } = *r.stack.last_mut().unwrap() {\n+                if *r.repeat_idx.last().unwrap() < *r.repeat_len.last().unwrap() - 1 {\n+                    *r.repeat_idx.last_mut().unwrap() += 1;\n+                    *idx = 0;\n+                    if let Some(sep) = sep.clone() {\n+                        return Some(TokenTree::Token(prev_span, sep)); // repeat same span, I guess\n+                    }\n+                    continue\n                 }\n             }\n+\n+            if let Frame::Sequence { .. } = r.stack.pop().unwrap() {\n+                r.repeat_idx.pop();\n+                r.repeat_len.pop();\n+            }\n             continue\n-        }\n+        };\n \n-        match frame.forest.get_tt(frame.idx) {\n+        match tree {\n             TokenTree::Sequence(sp, seq) => {\n                 // FIXME(pcwalton): Bad copy.\n                 match lockstep_iter_size(&TokenTree::Sequence(sp, seq.clone()),\n@@ -202,23 +240,20 @@ fn tt_next_token(r: &mut TtReader, prev_span: Span) -> Option<TokenTree> {\n                                                      \"this must repeat at least once\"));\n                             }\n \n-                            r.stack.last_mut().unwrap().idx += 1;\n                             return tt_next_token(r, prev_span);\n                         }\n                         r.repeat_len.push(len);\n                         r.repeat_idx.push(0);\n-                        r.stack.push(TtFrame {\n+                        r.stack.push(Frame::Sequence {\n                             idx: 0,\n-                            dotdotdoted: true,\n                             sep: seq.separator.clone(),\n-                            forest: TokenTree::Sequence(sp, seq),\n+                            forest: seq,\n                         });\n                     }\n                 }\n             }\n             // FIXME #2887: think about span stuff here\n             TokenTree::Token(sp, SubstNt(ident)) => {\n-                r.stack.last_mut().unwrap().idx += 1;\n                 match lookup_cur_matched(r, ident) {\n                     None => {\n                         return Some(TokenTree::Token(sp, SubstNt(ident)));\n@@ -245,21 +280,13 @@ fn tt_next_token(r: &mut TtReader, prev_span: Span) -> Option<TokenTree> {\n                     }\n                 }\n             }\n-            // TokenTree::Delimited or any token that can be unzipped\n-            seq @ TokenTree::Delimited(..) | seq @ TokenTree::Token(_, MatchNt(..)) => {\n-                // do not advance the idx yet\n-                r.stack.push(TtFrame {\n-                   forest: seq,\n-                   idx: 0,\n-                   dotdotdoted: false,\n-                   sep: None\n-                });\n-                // if this could be 0-length, we'd need to potentially recur here\n+            TokenTree::Delimited(span, delimited) => {\n+                r.stack.push(Frame::Delimited { forest: delimited, idx: 0, span: span });\n             }\n-            tt @ TokenTree::Token(..) => {\n-                r.stack.last_mut().unwrap().idx += 1;\n-                return Some(tt);\n+            TokenTree::Token(span, MatchNt(name, kind)) => {\n+                r.stack.push(Frame::MatchNt { name: name, kind: kind, idx: 0, span: span });\n             }\n+            tt @ TokenTree::Token(..) => return Some(tt),\n         }\n     }\n }"}, {"sha": "cb052b9593dde823cd0e05f2a5b3b1f387dd5a38", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/abdc68973ea5961c3e942c7176c2894d00c547d7/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/abdc68973ea5961c3e942c7176c2894d00c547d7/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=abdc68973ea5961c3e942c7176c2894d00c547d7", "patch": "@@ -50,8 +50,8 @@ pub enum DelimToken {\n }\n \n impl DelimToken {\n-    pub fn len(&self) -> u32 {\n-        if *self == NoDelim { 0 } else { 1 }\n+    pub fn len(self) -> usize {\n+        if self == NoDelim { 0 } else { 1 }\n     }\n }\n "}, {"sha": "bd63e9f39e5622559f36245be221de39816a0883", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/abdc68973ea5961c3e942c7176c2894d00c547d7/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/abdc68973ea5961c3e942c7176c2894d00c547d7/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=abdc68973ea5961c3e942c7176c2894d00c547d7", "patch": "@@ -64,7 +64,7 @@ impl Delimited {\n     pub fn open_tt(&self, span: Span) -> TokenTree {\n         let open_span = match span {\n             DUMMY_SP => DUMMY_SP,\n-            _ => Span { hi: span.lo + BytePos(self.delim.len()), ..span },\n+            _ => Span { hi: span.lo + BytePos(self.delim.len() as u32), ..span },\n         };\n         TokenTree::Token(open_span, self.open_token())\n     }\n@@ -73,7 +73,7 @@ impl Delimited {\n     pub fn close_tt(&self, span: Span) -> TokenTree {\n         let close_span = match span {\n             DUMMY_SP => DUMMY_SP,\n-            _ => Span { lo: span.hi - BytePos(self.delim.len()), ..span },\n+            _ => Span { lo: span.hi - BytePos(self.delim.len() as u32), ..span },\n         };\n         TokenTree::Token(close_span, self.close_token())\n     }"}]}