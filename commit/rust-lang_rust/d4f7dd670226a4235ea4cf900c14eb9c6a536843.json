{"sha": "d4f7dd670226a4235ea4cf900c14eb9c6a536843", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ0ZjdkZDY3MDIyNmE0MjM1ZWE0Y2Y5MDBjMTRlYjljNmE1MzY4NDM=", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2021-07-12T16:22:15Z"}, "committer": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2021-07-14T16:17:46Z"}, "message": "CTFE/Miri engine Pointer type overhaul: make Scalar-to-Pointer conversion infallible\n\nThis resolves all the problems we had around \"normalizing\" the representation of a Scalar in case it carries a Pointer value: we can just use Pointer if we want to have a value taht we are sure is already normalized.", "tree": {"sha": "fb5b4287bd53cee0633df3b455ebffa753be6b06", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/fb5b4287bd53cee0633df3b455ebffa753be6b06"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d4f7dd670226a4235ea4cf900c14eb9c6a536843", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d4f7dd670226a4235ea4cf900c14eb9c6a536843", "html_url": "https://github.com/rust-lang/rust/commit/d4f7dd670226a4235ea4cf900c14eb9c6a536843", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d4f7dd670226a4235ea4cf900c14eb9c6a536843/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5aff6dd07a562a2cba3c57fc3460a72acb6bef46", "url": "https://api.github.com/repos/rust-lang/rust/commits/5aff6dd07a562a2cba3c57fc3460a72acb6bef46", "html_url": "https://github.com/rust-lang/rust/commit/5aff6dd07a562a2cba3c57fc3460a72acb6bef46"}], "stats": {"total": 1559, "additions": 837, "deletions": 722}, "files": [{"sha": "a73932ee1b57ff3aa75536b287bc6b721bc96867", "filename": "compiler/rustc_codegen_llvm/src/common.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_codegen_llvm%2Fsrc%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_codegen_llvm%2Fsrc%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_llvm%2Fsrc%2Fcommon.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -244,15 +244,16 @@ impl ConstMethods<'tcx> for CodegenCx<'ll, 'tcx> {\n                 }\n             }\n             Scalar::Ptr(ptr) => {\n-                let (base_addr, base_addr_space) = match self.tcx.global_alloc(ptr.alloc_id) {\n+                let (alloc_id, offset) = ptr.into_parts();\n+                let (base_addr, base_addr_space) = match self.tcx.global_alloc(alloc_id) {\n                     GlobalAlloc::Memory(alloc) => {\n                         let init = const_alloc_to_llvm(self, alloc);\n                         let value = match alloc.mutability {\n                             Mutability::Mut => self.static_addr_of_mut(init, alloc.align, None),\n                             _ => self.static_addr_of(init, alloc.align, None),\n                         };\n                         if !self.sess().fewer_names() {\n-                            llvm::set_value_name(value, format!(\"{:?}\", ptr.alloc_id).as_bytes());\n+                            llvm::set_value_name(value, format!(\"{:?}\", alloc_id).as_bytes());\n                         }\n                         (value, AddressSpace::DATA)\n                     }\n@@ -269,7 +270,7 @@ impl ConstMethods<'tcx> for CodegenCx<'ll, 'tcx> {\n                 let llval = unsafe {\n                     llvm::LLVMConstInBoundsGEP(\n                         self.const_bitcast(base_addr, self.type_i8p_ext(base_addr_space)),\n-                        &self.const_usize(ptr.offset.bytes()),\n+                        &self.const_usize(offset.bytes()),\n                         1,\n                     )\n                 };"}, {"sha": "71a387bfcacd9cab412bc44541b89c7111033890", "filename": "compiler/rustc_codegen_llvm/src/consts.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_llvm%2Fsrc%2Fconsts.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -25,7 +25,7 @@ pub fn const_alloc_to_llvm(cx: &CodegenCx<'ll, '_>, alloc: &Allocation) -> &'ll\n     let pointer_size = dl.pointer_size.bytes() as usize;\n \n     let mut next_offset = 0;\n-    for &(offset, ((), alloc_id)) in alloc.relocations().iter() {\n+    for &(offset, alloc_id) in alloc.relocations().iter() {\n         let offset = offset.bytes();\n         assert_eq!(offset as usize as u64, offset);\n         let offset = offset as usize;"}, {"sha": "f9840e35bc60d61f7631b222feed2454989581d7", "filename": "compiler/rustc_middle/src/mir/interpret/allocation.rs", "status": "modified", "additions": 25, "deletions": 34, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -25,7 +25,7 @@ use crate::ty;\n /// module provides higher-level access.\n #[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, TyEncodable, TyDecodable)]\n #[derive(HashStable)]\n-pub struct Allocation<Tag = (), Extra = ()> {\n+pub struct Allocation<Tag = AllocId, Extra = ()> {\n     /// The actual bytes of the allocation.\n     /// Note that the bytes of a pointer represent the offset of the pointer.\n     bytes: Vec<u8>,\n@@ -154,25 +154,17 @@ impl<Tag> Allocation<Tag> {\n     }\n }\n \n-impl Allocation<()> {\n-    /// Add Tag and Extra fields\n-    pub fn with_tags_and_extra<T, E>(\n+impl Allocation {\n+    /// Convert Tag and add Extra fields\n+    pub fn with_prov_and_extra<Tag, Extra>(\n         self,\n-        mut tagger: impl FnMut(AllocId) -> T,\n-        extra: E,\n-    ) -> Allocation<T, E> {\n+        mut tagger: impl FnMut(AllocId) -> Tag,\n+        extra: Extra,\n+    ) -> Allocation<Tag, Extra> {\n         Allocation {\n             bytes: self.bytes,\n             relocations: Relocations::from_presorted(\n-                self.relocations\n-                    .iter()\n-                    // The allocations in the relocations (pointers stored *inside* this allocation)\n-                    // all get the base pointer tag.\n-                    .map(|&(offset, ((), alloc))| {\n-                        let tag = tagger(alloc);\n-                        (offset, (tag, alloc))\n-                    })\n-                    .collect(),\n+                self.relocations.iter().map(|&(offset, tag)| (offset, tagger(tag))).collect(),\n             ),\n             init_mask: self.init_mask,\n             align: self.align,\n@@ -339,8 +331,8 @@ impl<Tag: Copy, Extra> Allocation<Tag, Extra> {\n             self.check_relocations(cx, range)?;\n         } else {\n             // Maybe a pointer.\n-            if let Some(&(tag, alloc_id)) = self.relocations.get(&range.start) {\n-                let ptr = Pointer::new_with_tag(alloc_id, Size::from_bytes(bits), tag);\n+            if let Some(&prov) = self.relocations.get(&range.start) {\n+                let ptr = Pointer::new(prov, Size::from_bytes(bits));\n                 return Ok(ScalarMaybeUninit::Scalar(ptr.into()));\n             }\n         }\n@@ -371,18 +363,21 @@ impl<Tag: Copy, Extra> Allocation<Tag, Extra> {\n             }\n         };\n \n-        let bytes = match val.to_bits_or_ptr(range.size, cx) {\n-            Err(val) => u128::from(val.offset.bytes()),\n-            Ok(data) => data,\n+        let (bytes, provenance) = match val.to_bits_or_ptr(range.size, cx) {\n+            Err(val) => {\n+                let (provenance, offset) = val.into_parts();\n+                (u128::from(offset.bytes()), Some(provenance))\n+            }\n+            Ok(data) => (data, None),\n         };\n \n         let endian = cx.data_layout().endian;\n         let dst = self.get_bytes_mut(cx, range);\n         write_target_uint(endian, dst, bytes).unwrap();\n \n         // See if we have to also write a relocation.\n-        if let Scalar::Ptr(val) = val {\n-            self.relocations.insert(range.start, (val.tag, val.alloc_id));\n+        if let Some(provenance) = provenance {\n+            self.relocations.insert(range.start, provenance);\n         }\n \n         Ok(())\n@@ -392,11 +387,7 @@ impl<Tag: Copy, Extra> Allocation<Tag, Extra> {\n /// Relocations.\n impl<Tag: Copy, Extra> Allocation<Tag, Extra> {\n     /// Returns all relocations overlapping with the given pointer-offset pair.\n-    pub fn get_relocations(\n-        &self,\n-        cx: &impl HasDataLayout,\n-        range: AllocRange,\n-    ) -> &[(Size, (Tag, AllocId))] {\n+    pub fn get_relocations(&self, cx: &impl HasDataLayout, range: AllocRange) -> &[(Size, Tag)] {\n         // We have to go back `pointer_size - 1` bytes, as that one would still overlap with\n         // the beginning of this range.\n         let start = range.start.bytes().saturating_sub(cx.data_layout().pointer_size.bytes() - 1);\n@@ -582,24 +573,24 @@ impl<Tag, Extra> Allocation<Tag, Extra> {\n     }\n }\n \n-/// Relocations.\n+/// \"Relocations\" stores the provenance information of pointers stored in memory.\n #[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, TyEncodable, TyDecodable)]\n-pub struct Relocations<Tag = (), Id = AllocId>(SortedMap<Size, (Tag, Id)>);\n+pub struct Relocations<Tag = AllocId>(SortedMap<Size, Tag>);\n \n-impl<Tag, Id> Relocations<Tag, Id> {\n+impl<Tag> Relocations<Tag> {\n     pub fn new() -> Self {\n         Relocations(SortedMap::new())\n     }\n \n     // The caller must guarantee that the given relocations are already sorted\n     // by address and contain no duplicates.\n-    pub fn from_presorted(r: Vec<(Size, (Tag, Id))>) -> Self {\n+    pub fn from_presorted(r: Vec<(Size, Tag)>) -> Self {\n         Relocations(SortedMap::from_presorted_elements(r))\n     }\n }\n \n impl<Tag> Deref for Relocations<Tag> {\n-    type Target = SortedMap<Size, (Tag, AllocId)>;\n+    type Target = SortedMap<Size, Tag>;\n \n     fn deref(&self) -> &Self::Target {\n         &self.0\n@@ -614,7 +605,7 @@ impl<Tag> DerefMut for Relocations<Tag> {\n \n /// A partial, owned list of relocations to transfer into another allocation.\n pub struct AllocationRelocations<Tag> {\n-    relative_relocations: Vec<(Size, (Tag, AllocId))>,\n+    relative_relocations: Vec<(Size, Tag)>,\n }\n \n impl<Tag: Copy, Extra> Allocation<Tag, Extra> {"}, {"sha": "29caf01af1f5b14bf421501d09b9ded64c81a76a", "filename": "compiler/rustc_middle/src/mir/interpret/error.rs", "status": "modified", "additions": 12, "deletions": 10, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Ferror.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Ferror.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Ferror.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -238,7 +238,9 @@ pub enum UndefinedBehaviorInfo<'tcx> {\n     PointerUseAfterFree(AllocId),\n     /// Used a pointer outside the bounds it is valid for.\n     PointerOutOfBounds {\n-        ptr: Pointer,\n+        alloc_id: AllocId,\n+        offset: Size,\n+        size: Size,\n         msg: CheckInAllocMsg,\n         allocation_size: Size,\n     },\n@@ -307,19 +309,19 @@ impl fmt::Display for UndefinedBehaviorInfo<'_> {\n             InvalidVtableAlignment(msg) => write!(f, \"invalid vtable: alignment {}\", msg),\n             UnterminatedCString(p) => write!(\n                 f,\n-                \"reading a null-terminated string starting at {} with no null found before end of allocation\",\n+                \"reading a null-terminated string starting at {:?} with no null found before end of allocation\",\n                 p,\n             ),\n             PointerUseAfterFree(a) => {\n                 write!(f, \"pointer to {} was dereferenced after this allocation got freed\", a)\n             }\n-            PointerOutOfBounds { ptr, msg, allocation_size } => write!(\n+            PointerOutOfBounds { alloc_id, offset, size, msg, allocation_size } => write!(\n                 f,\n-                \"{}pointer must be in-bounds at offset {}, \\\n-                           but is outside bounds of {} which has size {}\",\n+                \"{}pointer must be in-bounds for {} bytes at offset {}, but {} has size {}\",\n                 msg,\n-                ptr.offset.bytes(),\n-                ptr.alloc_id,\n+                size.bytes(),\n+                offset.bytes(),\n+                alloc_id,\n                 allocation_size.bytes()\n             ),\n             DanglingIntPointer(0, CheckInAllocMsg::InboundsTest) => {\n@@ -348,13 +350,13 @@ impl fmt::Display for UndefinedBehaviorInfo<'_> {\n             }\n             InvalidTag(val) => write!(f, \"enum value has invalid tag: {}\", val),\n             InvalidFunctionPointer(p) => {\n-                write!(f, \"using {} as function pointer but it does not point to a function\", p)\n+                write!(f, \"using {:?} as function pointer but it does not point to a function\", p)\n             }\n             InvalidStr(err) => write!(f, \"this string is not valid UTF-8: {}\", err),\n             InvalidUninitBytes(Some((alloc, access))) => write!(\n                 f,\n-                \"reading {} byte{} of memory starting at {}, \\\n-                 but {} byte{} {} uninitialized starting at {}, \\\n+                \"reading {} byte{} of memory starting at {:?}, \\\n+                 but {} byte{} {} uninitialized starting at {:?}, \\\n                  and this operation requires initialized memory\",\n                 access.access_size.bytes(),\n                 pluralize!(access.access_size.bytes()),"}, {"sha": "44fa94c89c5cd34e197f00ffc46aabc5cba7d075", "filename": "compiler/rustc_middle/src/mir/interpret/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fmod.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -127,7 +127,7 @@ pub use self::value::{get_slice_bytes, ConstAlloc, ConstValue, Scalar, ScalarMay\n \n pub use self::allocation::{alloc_range, AllocRange, Allocation, InitMask, Relocations};\n \n-pub use self::pointer::{Pointer, PointerArithmetic};\n+pub use self::pointer::{Pointer, PointerArithmetic, Provenance};\n \n /// Uniquely identifies one of the following:\n /// - A constant"}, {"sha": "c9dc96fc88e0290cccf2215e571401fdcaf913e5", "filename": "compiler/rustc_middle/src/mir/interpret/pointer.rs", "status": "modified", "additions": 102, "deletions": 59, "changes": 161, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fpointer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fpointer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fpointer.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -83,55 +83,74 @@ pub trait PointerArithmetic: HasDataLayout {\n \n impl<T: HasDataLayout> PointerArithmetic for T {}\n \n-/// Represents a pointer in the Miri engine.\n-///\n-/// `Pointer` is generic over the `Tag` associated with each pointer,\n-/// which is used to do provenance tracking during execution.\n-#[derive(Copy, Clone, Eq, PartialEq, Ord, PartialOrd, TyEncodable, TyDecodable, Hash)]\n-#[derive(HashStable)]\n-pub struct Pointer<Tag = ()> {\n-    pub alloc_id: AllocId,\n-    pub offset: Size,\n-    pub tag: Tag,\n+/// This trait abstracts over the kind of provenance that is associated with a `Pointer`. It is\n+/// mostly opaque; the `Machine` trait extends it with some more operations that also have access to\n+/// some global state.\n+pub trait Provenance: Copy {\n+    /// Says whether the `offset` field of `Pointer` is the actual physical address.\n+    /// If `true, ptr-to-int casts work by simply discarding the provenance.\n+    /// If `false`, ptr-to-int casts are not supported.\n+    const OFFSET_IS_ADDR: bool;\n+\n+    /// Determines how a pointer should be printed.\n+    fn fmt(ptr: &Pointer<Self>, f: &mut fmt::Formatter<'_>) -> fmt::Result\n+    where\n+        Self: Sized;\n+\n+    /// \"Erasing\" a tag converts it to the default tag type if possible. Used only for formatting purposes!\n+    fn erase_for_fmt(self) -> AllocId;\n }\n \n-static_assert_size!(Pointer, 16);\n+impl Provenance for AllocId {\n+    // With the `AllocId` as provenance, the `offset` is interpreted *relative to the allocation*,\n+    // so ptr-to-int casts are not possible (since we do not know the global physical offset).\n+    const OFFSET_IS_ADDR: bool = false;\n \n-/// Print the address of a pointer (without the tag)\n-fn print_ptr_addr<Tag>(ptr: &Pointer<Tag>, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-    // Forward `alternate` flag to `alloc_id` printing.\n-    if f.alternate() {\n-        write!(f, \"{:#?}\", ptr.alloc_id)?;\n-    } else {\n-        write!(f, \"{:?}\", ptr.alloc_id)?;\n+    fn fmt(ptr: &Pointer<Self>, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        // Forward `alternate` flag to `alloc_id` printing.\n+        if f.alternate() {\n+            write!(f, \"{:#?}\", ptr.provenance)?;\n+        } else {\n+            write!(f, \"{:?}\", ptr.provenance)?;\n+        }\n+        // Print offset only if it is non-zero.\n+        if ptr.offset.bytes() > 0 {\n+            write!(f, \"+0x{:x}\", ptr.offset.bytes())?;\n+        }\n+        Ok(())\n     }\n-    // Print offset only if it is non-zero.\n-    if ptr.offset.bytes() > 0 {\n-        write!(f, \"+0x{:x}\", ptr.offset.bytes())?;\n+\n+    fn erase_for_fmt(self) -> AllocId {\n+        self\n     }\n-    Ok(())\n }\n \n+/// Represents a pointer in the Miri engine.\n+///\n+/// Pointers are \"tagged\" with provenance information; typically the `AllocId` they belong to.\n+#[derive(Copy, Clone, Eq, PartialEq, Ord, PartialOrd, TyEncodable, TyDecodable, Hash)]\n+#[derive(HashStable)]\n+pub struct Pointer<Tag = AllocId> {\n+    pub(super) offset: Size, // kept private to avoid accidental misinterpretation (meaning depends on `Tag` type)\n+    pub provenance: Tag,\n+}\n+\n+//FIXME static_assert_size!(Pointer, 16);\n+\n // We want the `Debug` output to be readable as it is used by `derive(Debug)` for\n // all the Miri types.\n-// We have to use `Debug` output for the tag, because `()` does not implement\n-// `Display` so we cannot specialize that.\n-impl<Tag: fmt::Debug> fmt::Debug for Pointer<Tag> {\n-    default fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        print_ptr_addr(self, f)?;\n-        write!(f, \"[{:?}]\", self.tag)\n-    }\n-}\n-// Specialization for no tag\n-impl fmt::Debug for Pointer<()> {\n+impl<Tag: Provenance> fmt::Debug for Pointer<Tag> {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        print_ptr_addr(self, f)\n+        Tag::fmt(self, f)\n     }\n }\n \n-impl<Tag: fmt::Debug> fmt::Display for Pointer<Tag> {\n+impl<Tag: Provenance> fmt::Debug for Pointer<Option<Tag>> {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        fmt::Debug::fmt(self, f)\n+        match self.provenance {\n+            Some(tag) => Tag::fmt(&Pointer::new(tag, self.offset), f),\n+            None => write!(f, \"0x{:x}\", self.offset.bytes()),\n+        }\n     }\n }\n \n@@ -143,37 +162,66 @@ impl From<AllocId> for Pointer {\n     }\n }\n \n-impl Pointer<()> {\n+impl<Tag> From<Pointer<Tag>> for Pointer<Option<Tag>> {\n     #[inline(always)]\n-    pub fn new(alloc_id: AllocId, offset: Size) -> Self {\n-        Pointer { alloc_id, offset, tag: () }\n+    fn from(ptr: Pointer<Tag>) -> Self {\n+        let (tag, offset) = ptr.into_parts();\n+        Pointer::new(Some(tag), offset)\n+    }\n+}\n+\n+impl<Tag> Pointer<Option<Tag>> {\n+    pub fn into_pointer_or_offset(self) -> Result<Pointer<Tag>, Size> {\n+        match self.provenance {\n+            Some(tag) => Ok(Pointer::new(tag, self.offset)),\n+            None => Err(self.offset),\n+        }\n     }\n \n     #[inline(always)]\n-    pub fn with_tag<Tag>(self, tag: Tag) -> Pointer<Tag> {\n-        Pointer::new_with_tag(self.alloc_id, self.offset, tag)\n+    pub fn map_erase_for_fmt(self) -> Pointer<Option<AllocId>>\n+    where\n+        Tag: Provenance,\n+    {\n+        Pointer { offset: self.offset, provenance: self.provenance.map(Provenance::erase_for_fmt) }\n     }\n }\n \n impl<'tcx, Tag> Pointer<Tag> {\n     #[inline(always)]\n-    pub fn new_with_tag(alloc_id: AllocId, offset: Size, tag: Tag) -> Self {\n-        Pointer { alloc_id, offset, tag }\n+    pub fn new(provenance: Tag, offset: Size) -> Self {\n+        Pointer { provenance, offset }\n+    }\n+\n+    /// Obtain the constituents of this pointer. Not that the meaning of the offset depends on the type `Tag`!\n+    /// This function must only be used in the implementation of `Machine::ptr_get_alloc`,\n+    /// and when a `Pointer` is taken apart to be stored efficiently in an `Allocation`.\n+    #[inline(always)]\n+    pub fn into_parts(self) -> (Tag, Size) {\n+        (self.provenance, self.offset)\n+    }\n+\n+    #[inline(always)]\n+    pub fn erase_for_fmt(self) -> Pointer\n+    where\n+        Tag: Provenance,\n+    {\n+        Pointer { offset: self.offset, provenance: self.provenance.erase_for_fmt() }\n     }\n \n     #[inline]\n     pub fn offset(self, i: Size, cx: &impl HasDataLayout) -> InterpResult<'tcx, Self> {\n-        Ok(Pointer::new_with_tag(\n-            self.alloc_id,\n-            Size::from_bytes(cx.data_layout().offset(self.offset.bytes(), i.bytes())?),\n-            self.tag,\n-        ))\n+        Ok(Pointer {\n+            offset: Size::from_bytes(cx.data_layout().offset(self.offset.bytes(), i.bytes())?),\n+            ..self\n+        })\n     }\n \n     #[inline]\n     pub fn overflowing_offset(self, i: Size, cx: &impl HasDataLayout) -> (Self, bool) {\n         let (res, over) = cx.data_layout().overflowing_offset(self.offset.bytes(), i.bytes());\n-        (Pointer::new_with_tag(self.alloc_id, Size::from_bytes(res), self.tag), over)\n+        let ptr = Pointer { offset: Size::from_bytes(res), ..self };\n+        (ptr, over)\n     }\n \n     #[inline(always)]\n@@ -183,26 +231,21 @@ impl<'tcx, Tag> Pointer<Tag> {\n \n     #[inline]\n     pub fn signed_offset(self, i: i64, cx: &impl HasDataLayout) -> InterpResult<'tcx, Self> {\n-        Ok(Pointer::new_with_tag(\n-            self.alloc_id,\n-            Size::from_bytes(cx.data_layout().signed_offset(self.offset.bytes(), i)?),\n-            self.tag,\n-        ))\n+        Ok(Pointer {\n+            offset: Size::from_bytes(cx.data_layout().signed_offset(self.offset.bytes(), i)?),\n+            ..self\n+        })\n     }\n \n     #[inline]\n     pub fn overflowing_signed_offset(self, i: i64, cx: &impl HasDataLayout) -> (Self, bool) {\n         let (res, over) = cx.data_layout().overflowing_signed_offset(self.offset.bytes(), i);\n-        (Pointer::new_with_tag(self.alloc_id, Size::from_bytes(res), self.tag), over)\n+        let ptr = Pointer { offset: Size::from_bytes(res), ..self };\n+        (ptr, over)\n     }\n \n     #[inline(always)]\n     pub fn wrapping_signed_offset(self, i: i64, cx: &impl HasDataLayout) -> Self {\n         self.overflowing_signed_offset(i, cx).0\n     }\n-\n-    #[inline(always)]\n-    pub fn erase_tag(self) -> Pointer {\n-        Pointer { alloc_id: self.alloc_id, offset: self.offset, tag: () }\n-    }\n }"}, {"sha": "29692c07f031cd2442d3525868700d7c12be65ab", "filename": "compiler/rustc_middle/src/mir/interpret/value.rs", "status": "modified", "additions": 96, "deletions": 84, "changes": 180, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fvalue.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -10,7 +10,9 @@ use rustc_target::abi::{HasDataLayout, Size, TargetDataLayout};\n \n use crate::ty::{Lift, ParamEnv, ScalarInt, Ty, TyCtxt};\n \n-use super::{AllocId, AllocRange, Allocation, InterpResult, Pointer, PointerArithmetic};\n+use super::{\n+    AllocId, AllocRange, Allocation, InterpResult, Pointer, PointerArithmetic, Provenance,\n+};\n \n /// Represents the result of const evaluation via the `eval_to_allocation` query.\n #[derive(Copy, Clone, HashStable, TyEncodable, TyDecodable, Debug, Hash, Eq, PartialEq)]\n@@ -47,12 +49,6 @@ pub enum ConstValue<'tcx> {\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n static_assert_size!(ConstValue<'_>, 32);\n \n-impl From<Scalar> for ConstValue<'tcx> {\n-    fn from(s: Scalar) -> Self {\n-        Self::Scalar(s)\n-    }\n-}\n-\n impl<'a, 'tcx> Lift<'tcx> for ConstValue<'a> {\n     type Lifted = ConstValue<'tcx>;\n     fn lift_to_tcx(self, tcx: TyCtxt<'tcx>) -> Option<ConstValue<'tcx>> {\n@@ -70,7 +66,7 @@ impl<'a, 'tcx> Lift<'tcx> for ConstValue<'a> {\n \n impl<'tcx> ConstValue<'tcx> {\n     #[inline]\n-    pub fn try_to_scalar(&self) -> Option<Scalar> {\n+    pub fn try_to_scalar(&self) -> Option<Scalar<AllocId>> {\n         match *self {\n             ConstValue::ByRef { .. } | ConstValue::Slice { .. } => None,\n             ConstValue::Scalar(val) => Some(val),\n@@ -120,9 +116,12 @@ impl<'tcx> ConstValue<'tcx> {\n /// `memory::Allocation`. It is in many ways like a small chunk of a `Allocation`, up to 16 bytes in\n /// size. Like a range of bytes in an `Allocation`, a `Scalar` can either represent the raw bytes\n /// of a simple value or a pointer into another `Allocation`\n+///\n+/// These variants would be private if there was a convenient way to achieve that in Rust.\n+/// Do *not* match on a `Scalar`! Use the various `to_*` methods instead.\n #[derive(Clone, Copy, Eq, PartialEq, Ord, PartialOrd, TyEncodable, TyDecodable, Hash)]\n #[derive(HashStable)]\n-pub enum Scalar<Tag = ()> {\n+pub enum Scalar<Tag = AllocId> {\n     /// The raw bytes of a simple value.\n     Int(ScalarInt),\n \n@@ -133,11 +132,11 @@ pub enum Scalar<Tag = ()> {\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-static_assert_size!(Scalar, 24);\n+//FIXME static_assert_size!(Scalar, 24);\n \n // We want the `Debug` output to be readable as it is used by `derive(Debug)` for\n // all the Miri types.\n-impl<Tag: fmt::Debug> fmt::Debug for Scalar<Tag> {\n+impl<Tag: Provenance> fmt::Debug for Scalar<Tag> {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         match self {\n             Scalar::Ptr(ptr) => write!(f, \"{:?}\", ptr),\n@@ -146,11 +145,11 @@ impl<Tag: fmt::Debug> fmt::Debug for Scalar<Tag> {\n     }\n }\n \n-impl<Tag: fmt::Debug> fmt::Display for Scalar<Tag> {\n+impl<Tag: Provenance> fmt::Display for Scalar<Tag> {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         match self {\n-            Scalar::Ptr(ptr) => write!(f, \"pointer to {}\", ptr),\n-            Scalar::Int { .. } => fmt::Debug::fmt(self, f),\n+            Scalar::Ptr(ptr) => write!(f, \"pointer to {:?}\", ptr),\n+            Scalar::Int(int) => write!(f, \"{:?}\", int),\n         }\n     }\n }\n@@ -169,38 +168,38 @@ impl<Tag> From<Double> for Scalar<Tag> {\n     }\n }\n \n-impl Scalar<()> {\n-    /// Tag this scalar with `new_tag` if it is a pointer, leave it unchanged otherwise.\n-    ///\n-    /// Used by `MemPlace::replace_tag`.\n-    #[inline]\n-    pub fn with_tag<Tag>(self, new_tag: Tag) -> Scalar<Tag> {\n-        match self {\n-            Scalar::Ptr(ptr) => Scalar::Ptr(ptr.with_tag(new_tag)),\n-            Scalar::Int(int) => Scalar::Int(int),\n-        }\n+impl<Tag> From<Pointer<Tag>> for Scalar<Tag> {\n+    #[inline(always)]\n+    fn from(ptr: Pointer<Tag>) -> Self {\n+        Scalar::Ptr(ptr)\n+    }\n+}\n+\n+impl<Tag> From<ScalarInt> for Scalar<Tag> {\n+    #[inline(always)]\n+    fn from(ptr: ScalarInt) -> Self {\n+        Scalar::Int(ptr)\n     }\n }\n \n impl<'tcx, Tag> Scalar<Tag> {\n     pub const ZST: Self = Scalar::Int(ScalarInt::ZST);\n \n-    /// Erase the tag from the scalar, if any.\n-    ///\n-    /// Used by error reporting code to avoid having the error type depend on `Tag`.\n-    #[inline]\n-    pub fn erase_tag(self) -> Scalar {\n-        match self {\n-            Scalar::Ptr(ptr) => Scalar::Ptr(ptr.erase_tag()),\n-            Scalar::Int(int) => Scalar::Int(int),\n-        }\n-    }\n-\n     #[inline]\n     pub fn null_ptr(cx: &impl HasDataLayout) -> Self {\n         Scalar::Int(ScalarInt::null(cx.data_layout().pointer_size))\n     }\n \n+    /// Create a Scalar from a pointer with an `Option<_>` tag (where `None` represents a plain integer).\n+    pub fn from_maybe_pointer(ptr: Pointer<Option<Tag>>, cx: &impl HasDataLayout) -> Self {\n+        match ptr.into_parts() {\n+            (Some(tag), offset) => Scalar::Ptr(Pointer::new(tag, offset)),\n+            (None, offset) => {\n+                Scalar::Int(ScalarInt::try_from_uint(offset.bytes(), cx.pointer_size()).unwrap())\n+            }\n+        }\n+    }\n+\n     #[inline(always)]\n     fn ptr_op(\n         self,\n@@ -332,10 +331,11 @@ impl<'tcx, Tag> Scalar<Tag> {\n         Scalar::Int(f.into())\n     }\n \n-    /// This is very rarely the method you want!  You should dispatch on the type\n-    /// and use `force_bits`/`assert_bits`/`force_ptr`/`assert_ptr`.\n+    /// This is almost certainly not the method you want!  You should dispatch on the type\n+    /// and use `to_{u8,u16,...}`/`scalar_to_ptr` to perform ptr-to-int / int-to-ptr casts as needed.\n+    ///\n     /// This method only exists for the benefit of low-level memory operations\n-    /// as well as the implementation of the `force_*` methods.\n+    /// as well as the implementation of the above methods.\n     #[inline]\n     pub fn to_bits_or_ptr(\n         self,\n@@ -352,28 +352,13 @@ impl<'tcx, Tag> Scalar<Tag> {\n         }\n     }\n \n-    /// This method is intentionally private!\n-    /// It is just a helper for other methods in this file.\n-    #[inline]\n-    fn to_bits(self, target_size: Size) -> InterpResult<'tcx, u128> {\n-        assert_ne!(target_size.bytes(), 0, \"you should never look at the bits of a ZST\");\n-        match self {\n-            Scalar::Int(int) => int.to_bits(target_size).map_err(|size| {\n-                err_ub!(ScalarSizeMismatch {\n-                    target_size: target_size.bytes(),\n-                    data_size: size.bytes(),\n-                })\n-                .into()\n-            }),\n-            Scalar::Ptr(_) => throw_unsup!(ReadPointerAsBytes),\n-        }\n-    }\n-\n+    /// Do not call this method! It does not do ptr-to-int casts when needed.\n     #[inline(always)]\n     pub fn assert_bits(self, target_size: Size) -> u128 {\n-        self.to_bits(target_size).expect(\"expected Raw bits but got a Pointer\")\n+        self.assert_int().assert_bits(target_size)\n     }\n \n+    /// Do not call this method! It does not do ptr-to-int casts when needed.\n     #[inline]\n     pub fn assert_int(self) -> ScalarInt {\n         match self {\n@@ -382,6 +367,7 @@ impl<'tcx, Tag> Scalar<Tag> {\n         }\n     }\n \n+    /// Do not call this method! It does not do int-to-ptr casts when needed.\n     #[inline]\n     pub fn assert_ptr(self) -> Pointer<Tag> {\n         match self {\n@@ -401,6 +387,44 @@ impl<'tcx, Tag> Scalar<Tag> {\n     pub fn is_ptr(self) -> bool {\n         matches!(self, Scalar::Ptr(_))\n     }\n+}\n+\n+impl<'tcx, Tag: Provenance> Scalar<Tag> {\n+    /// Erase the tag from the scalar, if any.\n+    ///\n+    /// Used by error reporting code to avoid having the error type depend on `Tag`.\n+    #[inline]\n+    pub fn erase_for_fmt(self) -> Scalar {\n+        match self {\n+            Scalar::Ptr(ptr) => Scalar::Ptr(ptr.erase_for_fmt()),\n+            Scalar::Int(int) => Scalar::Int(int),\n+        }\n+    }\n+\n+    /// Fundamental scalar-to-int (cast) operation. Many convenience wrappers exist below, that you\n+    /// likely want to use instead.\n+    ///\n+    /// Will perform ptr-to-int casts if needed and possible.\n+    #[inline]\n+    pub fn to_bits(self, target_size: Size) -> InterpResult<'tcx, u128> {\n+        assert_ne!(target_size.bytes(), 0, \"you should never look at the bits of a ZST\");\n+        match self {\n+            Scalar::Int(int) => int.to_bits(target_size).map_err(|size| {\n+                err_ub!(ScalarSizeMismatch {\n+                    target_size: target_size.bytes(),\n+                    data_size: size.bytes(),\n+                })\n+                .into()\n+            }),\n+            Scalar::Ptr(ptr) => {\n+                if Tag::OFFSET_IS_ADDR {\n+                    Ok(ptr.offset.bytes().into())\n+                } else {\n+                    throw_unsup!(ReadPointerAsBytes)\n+                }\n+            }\n+        }\n+    }\n \n     pub fn to_bool(self) -> InterpResult<'tcx, bool> {\n         let val = self.to_u8()?;\n@@ -507,28 +531,14 @@ impl<'tcx, Tag> Scalar<Tag> {\n     }\n }\n \n-impl<Tag> From<Pointer<Tag>> for Scalar<Tag> {\n-    #[inline(always)]\n-    fn from(ptr: Pointer<Tag>) -> Self {\n-        Scalar::Ptr(ptr)\n-    }\n-}\n-\n-impl<Tag> From<ScalarInt> for Scalar<Tag> {\n-    #[inline(always)]\n-    fn from(ptr: ScalarInt) -> Self {\n-        Scalar::Int(ptr)\n-    }\n-}\n-\n #[derive(Clone, Copy, Eq, PartialEq, TyEncodable, TyDecodable, HashStable, Hash)]\n-pub enum ScalarMaybeUninit<Tag = ()> {\n+pub enum ScalarMaybeUninit<Tag = AllocId> {\n     Scalar(Scalar<Tag>),\n     Uninit,\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-static_assert_size!(ScalarMaybeUninit, 24);\n+//FIXME static_assert_size!(ScalarMaybeUninit, 24);\n \n impl<Tag> From<Scalar<Tag>> for ScalarMaybeUninit<Tag> {\n     #[inline(always)]\n@@ -546,7 +556,7 @@ impl<Tag> From<Pointer<Tag>> for ScalarMaybeUninit<Tag> {\n \n // We want the `Debug` output to be readable as it is used by `derive(Debug)` for\n // all the Miri types.\n-impl<Tag: fmt::Debug> fmt::Debug for ScalarMaybeUninit<Tag> {\n+impl<Tag: Provenance> fmt::Debug for ScalarMaybeUninit<Tag> {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         match self {\n             ScalarMaybeUninit::Uninit => write!(f, \"<uninitialized>\"),\n@@ -555,7 +565,7 @@ impl<Tag: fmt::Debug> fmt::Debug for ScalarMaybeUninit<Tag> {\n     }\n }\n \n-impl<Tag: fmt::Debug> fmt::Display for ScalarMaybeUninit<Tag> {\n+impl<Tag: Provenance> fmt::Display for ScalarMaybeUninit<Tag> {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n         match self {\n             ScalarMaybeUninit::Uninit => write!(f, \"uninitialized bytes\"),\n@@ -564,23 +574,25 @@ impl<Tag: fmt::Debug> fmt::Display for ScalarMaybeUninit<Tag> {\n     }\n }\n \n-impl<'tcx, Tag> ScalarMaybeUninit<Tag> {\n-    /// Erase the tag from the scalar, if any.\n-    ///\n-    /// Used by error reporting code to avoid having the error type depend on `Tag`.\n+impl<Tag> ScalarMaybeUninit<Tag> {\n     #[inline]\n-    pub fn erase_tag(self) -> ScalarMaybeUninit {\n+    pub fn check_init(self) -> InterpResult<'static, Scalar<Tag>> {\n         match self {\n-            ScalarMaybeUninit::Scalar(s) => ScalarMaybeUninit::Scalar(s.erase_tag()),\n-            ScalarMaybeUninit::Uninit => ScalarMaybeUninit::Uninit,\n+            ScalarMaybeUninit::Scalar(scalar) => Ok(scalar),\n+            ScalarMaybeUninit::Uninit => throw_ub!(InvalidUninitBytes(None)),\n         }\n     }\n+}\n \n+impl<'tcx, Tag: Provenance> ScalarMaybeUninit<Tag> {\n+    /// Erase the tag from the scalar, if any.\n+    ///\n+    /// Used by error reporting code to avoid having the error type depend on `Tag`.\n     #[inline]\n-    pub fn check_init(self) -> InterpResult<'static, Scalar<Tag>> {\n+    pub fn erase_for_fmt(self) -> ScalarMaybeUninit {\n         match self {\n-            ScalarMaybeUninit::Scalar(scalar) => Ok(scalar),\n-            ScalarMaybeUninit::Uninit => throw_ub!(InvalidUninitBytes(None)),\n+            ScalarMaybeUninit::Scalar(s) => ScalarMaybeUninit::Scalar(s.erase_for_fmt()),\n+            ScalarMaybeUninit::Uninit => ScalarMaybeUninit::Uninit,\n         }\n     }\n "}, {"sha": "9fc02a590c35c0b472167df18f3b3fd2a15f5149", "filename": "compiler/rustc_middle/src/mir/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmod.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -3,7 +3,7 @@\n //! [rustc dev guide]: https://rustc-dev-guide.rust-lang.org/mir/index.html\n \n use crate::mir::coverage::{CodeRegion, CoverageKind};\n-use crate::mir::interpret::{Allocation, GlobalAlloc, Scalar};\n+use crate::mir::interpret::{Allocation, ConstValue, GlobalAlloc, Scalar};\n use crate::mir::visit::MirVisitable;\n use crate::ty::adjustment::PointerCast;\n use crate::ty::codec::{TyDecoder, TyEncoder};\n@@ -2095,7 +2095,7 @@ impl<'tcx> Operand<'tcx> {\n         Operand::Constant(box Constant {\n             span,\n             user_ty: None,\n-            literal: ConstantKind::Val(val.into(), ty),\n+            literal: ConstantKind::Val(ConstValue::Scalar(val), ty),\n         })\n     }\n \n@@ -2458,7 +2458,7 @@ pub enum ConstantKind<'tcx> {\n impl Constant<'tcx> {\n     pub fn check_static_ptr(&self, tcx: TyCtxt<'_>) -> Option<DefId> {\n         match self.literal.const_for_ty()?.val.try_to_scalar() {\n-            Some(Scalar::Ptr(ptr)) => match tcx.global_alloc(ptr.alloc_id) {\n+            Some(Scalar::Ptr(ptr)) => match tcx.global_alloc(ptr.provenance) {\n                 GlobalAlloc::Static(def_id) => {\n                     assert!(!tcx.is_thread_local_static(def_id));\n                     Some(def_id)"}, {"sha": "f2db95d162b888363fc7d016fe40af5c7f261e45", "filename": "compiler/rustc_middle/src/ty/consts/kind.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fty%2Fconsts%2Fkind.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fty%2Fconsts%2Fkind.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fconsts%2Fkind.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -1,7 +1,6 @@\n use std::convert::TryInto;\n \n-use crate::mir::interpret::ConstValue;\n-use crate::mir::interpret::Scalar;\n+use crate::mir::interpret::{AllocId, ConstValue, Scalar};\n use crate::mir::Promoted;\n use crate::ty::subst::{InternalSubsts, SubstsRef};\n use crate::ty::ParamEnv;\n@@ -59,7 +58,7 @@ impl<'tcx> ConstKind<'tcx> {\n     }\n \n     #[inline]\n-    pub fn try_to_scalar(self) -> Option<Scalar> {\n+    pub fn try_to_scalar(self) -> Option<Scalar<AllocId>> {\n         self.try_to_value()?.try_to_scalar()\n     }\n "}, {"sha": "25058d2cef715054d735fa7332df9b6098055032", "filename": "compiler/rustc_middle/src/ty/print/pretty.rs", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fty%2Fprint%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fty%2Fprint%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Fprint%2Fpretty.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -987,6 +987,7 @@ pub trait PrettyPrinter<'tcx>:\n     ) -> Result<Self::Const, Self::Error> {\n         define_scoped_cx!(self);\n \n+        let (alloc_id, offset) = ptr.into_parts();\n         match ty.kind() {\n             // Byte strings (&[u8; N])\n             ty::Ref(\n@@ -1002,10 +1003,10 @@ pub trait PrettyPrinter<'tcx>:\n                     ..\n                 },\n                 _,\n-            ) => match self.tcx().get_global_alloc(ptr.alloc_id) {\n+            ) => match self.tcx().get_global_alloc(alloc_id) {\n                 Some(GlobalAlloc::Memory(alloc)) => {\n                     let len = int.assert_bits(self.tcx().data_layout.pointer_size);\n-                    let range = AllocRange { start: ptr.offset, size: Size::from_bytes(len) };\n+                    let range = AllocRange { start: offset, size: Size::from_bytes(len) };\n                     if let Ok(byte_str) = alloc.get_bytes(&self.tcx(), range) {\n                         p!(pretty_print_byte_str(byte_str))\n                     } else {\n@@ -1020,7 +1021,7 @@ pub trait PrettyPrinter<'tcx>:\n             ty::FnPtr(_) => {\n                 // FIXME: We should probably have a helper method to share code with the \"Byte strings\"\n                 // printing above (which also has to handle pointers to all sorts of things).\n-                match self.tcx().get_global_alloc(ptr.alloc_id) {\n+                match self.tcx().get_global_alloc(alloc_id) {\n                     Some(GlobalAlloc::Function(instance)) => {\n                         self = self.typed_value(\n                             |this| this.print_value_path(instance.def_id(), instance.substs),\n@@ -1068,8 +1069,8 @@ pub trait PrettyPrinter<'tcx>:\n             ty::Char if char::try_from(int).is_ok() => {\n                 p!(write(\"{:?}\", char::try_from(int).unwrap()))\n             }\n-            // Raw pointers\n-            ty::RawPtr(_) | ty::FnPtr(_) => {\n+            // Pointer types\n+            ty::Ref(..) | ty::RawPtr(_) | ty::FnPtr(_) => {\n                 let data = int.assert_bits(self.tcx().data_layout.pointer_size);\n                 self = self.typed_value(\n                     |mut this| {"}, {"sha": "5d1cc1242760c44a022c8f153489387cde42df1d", "filename": "compiler/rustc_middle/src/ty/relate.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fty%2Frelate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_middle%2Fsrc%2Fty%2Frelate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fty%2Frelate.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -597,7 +597,7 @@ fn check_const_value_eq<R: TypeRelation<'tcx>>(\n         }\n         (ConstValue::Scalar(Scalar::Ptr(a_val)), ConstValue::Scalar(Scalar::Ptr(b_val))) => {\n             a_val == b_val\n-                || match (tcx.global_alloc(a_val.alloc_id), tcx.global_alloc(b_val.alloc_id)) {\n+                || match (tcx.global_alloc(a_val.provenance), tcx.global_alloc(b_val.provenance)) {\n                     (GlobalAlloc::Function(a_instance), GlobalAlloc::Function(b_instance)) => {\n                         a_instance == b_instance\n                     }"}, {"sha": "5da1681662577648009f96b1da5b0aabfe02229d", "filename": "compiler/rustc_mir/src/const_eval/error.rs", "status": "modified", "additions": 0, "deletions": 7, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Ferror.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Ferror.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Ferror.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -16,7 +16,6 @@ use crate::interpret::{\n #[derive(Clone, Debug)]\n pub enum ConstEvalErrKind {\n     NeedsRfc(String),\n-    PtrToIntCast,\n     ConstAccessesStatic,\n     ModifiedGlobal,\n     AssertFailure(AssertKind<ConstInt>),\n@@ -49,12 +48,6 @@ impl fmt::Display for ConstEvalErrKind {\n             NeedsRfc(ref msg) => {\n                 write!(f, \"\\\"{}\\\" needs an rfc before being allowed inside constants\", msg)\n             }\n-            PtrToIntCast => {\n-                write!(\n-                    f,\n-                    \"cannot cast pointer to integer because it was not created by cast from integer\"\n-                )\n-            }\n             ConstAccessesStatic => write!(f, \"constant accesses static\"),\n             ModifiedGlobal => {\n                 write!(f, \"modifying a static's initial value from another static's initializer\")"}, {"sha": "00d73d42cfcd8c03debb166254f46b52ec060431", "filename": "compiler/rustc_mir/src/const_eval/eval_queries.rs", "status": "modified", "additions": 15, "deletions": 17, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Feval_queries.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Feval_queries.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Feval_queries.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -136,19 +136,18 @@ pub(super) fn op_to_const<'tcx>(\n         // by-val is if we are in destructure_const, i.e., if this is (a field of) something that we\n         // \"tried to make immediate\" before. We wouldn't do that for non-slice scalar pairs or\n         // structs containing such.\n-        op.try_as_mplace(ecx)\n+        op.try_as_mplace()\n     };\n \n-    let to_const_value = |mplace: &MPlaceTy<'_>| match mplace.ptr {\n-        Scalar::Ptr(ptr) => {\n-            let alloc = ecx.tcx.global_alloc(ptr.alloc_id).unwrap_memory();\n-            ConstValue::ByRef { alloc, offset: ptr.offset }\n+    let to_const_value = |mplace: &MPlaceTy<'_>| match mplace.ptr.into_parts() {\n+        (Some(alloc_id), offset) => {\n+            let alloc = ecx.tcx.global_alloc(alloc_id).unwrap_memory();\n+            ConstValue::ByRef { alloc, offset }\n         }\n-        Scalar::Int(int) => {\n+        (None, offset) => {\n             assert!(mplace.layout.is_zst());\n             assert_eq!(\n-                int.assert_bits(ecx.tcx.data_layout.pointer_size)\n-                    % u128::from(mplace.layout.align.abi.bytes()),\n+                offset.bytes() % mplace.layout.align.abi.bytes(),\n                 0,\n                 \"this MPlaceTy must come from a validated constant, thus we can assume the \\\n                 alignment is correct\",\n@@ -162,14 +161,14 @@ pub(super) fn op_to_const<'tcx>(\n         Err(imm) => match *imm {\n             Immediate::Scalar(x) => match x {\n                 ScalarMaybeUninit::Scalar(s) => ConstValue::Scalar(s),\n-                ScalarMaybeUninit::Uninit => to_const_value(&op.assert_mem_place(ecx)),\n+                ScalarMaybeUninit::Uninit => to_const_value(&op.assert_mem_place()),\n             },\n             Immediate::ScalarPair(a, b) => {\n-                let (data, start) = match a.check_init().unwrap() {\n-                    Scalar::Ptr(ptr) => {\n-                        (ecx.tcx.global_alloc(ptr.alloc_id).unwrap_memory(), ptr.offset.bytes())\n+                let (data, start) = match ecx.scalar_to_ptr(a.check_init().unwrap()).into_parts() {\n+                    (Some(alloc_id), offset) => {\n+                        (ecx.tcx.global_alloc(alloc_id).unwrap_memory(), offset.bytes())\n                     }\n-                    Scalar::Int { .. } => (\n+                    (None, _offset) => (\n                         ecx.tcx.intern_const_alloc(Allocation::from_bytes_byte_aligned_immutable(\n                             b\"\" as &[u8],\n                         )),\n@@ -369,6 +368,7 @@ pub fn eval_to_allocation_raw_provider<'tcx>(\n                     inner = true;\n                 }\n             };\n+            let alloc_id = mplace.ptr.provenance.unwrap();\n             if let Err(error) = validation {\n                 // Validation failed, report an error. This is always a hard error.\n                 let err = ConstEvalErr::new(&ecx, error, None);\n@@ -381,17 +381,15 @@ pub fn eval_to_allocation_raw_provider<'tcx>(\n                             \"the raw bytes of the constant ({}\",\n                             display_allocation(\n                                 *ecx.tcx,\n-                                ecx.tcx\n-                                    .global_alloc(mplace.ptr.assert_ptr().alloc_id)\n-                                    .unwrap_memory()\n+                                ecx.tcx.global_alloc(alloc_id).unwrap_memory()\n                             )\n                         ));\n                         diag.emit();\n                     },\n                 ))\n             } else {\n                 // Convert to raw constant\n-                Ok(ConstAlloc { alloc_id: mplace.ptr.assert_ptr().alloc_id, ty: mplace.layout.ty })\n+                Ok(ConstAlloc { alloc_id, ty: mplace.layout.ty })\n             }\n         }\n     }"}, {"sha": "dcabc91f7a8e96951cf5cebdfd7c0e04935c57b5", "filename": "compiler/rustc_mir/src/const_eval/machine.rs", "status": "modified", "additions": 4, "deletions": 8, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Fmachine.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -16,8 +16,8 @@ use rustc_target::abi::{Align, Size};\n use rustc_target::spec::abi::Abi;\n \n use crate::interpret::{\n-    self, compile_time_machine, AllocId, Allocation, Frame, ImmTy, InterpCx, InterpResult, Memory,\n-    OpTy, PlaceTy, Pointer, Scalar, StackPopUnwind,\n+    self, compile_time_machine, AllocId, Allocation, Frame, ImmTy, InterpCx, InterpResult, OpTy,\n+    PlaceTy, Scalar, StackPopUnwind,\n };\n \n use super::error::*;\n@@ -59,7 +59,7 @@ pub struct CompileTimeInterpreter<'mir, 'tcx> {\n     pub steps_remaining: usize,\n \n     /// The virtual call stack.\n-    pub(crate) stack: Vec<Frame<'mir, 'tcx, (), ()>>,\n+    pub(crate) stack: Vec<Frame<'mir, 'tcx, AllocId, ()>>,\n }\n \n #[derive(Copy, Clone, Debug)]\n@@ -184,7 +184,7 @@ impl<'mir, 'tcx: 'mir> CompileTimeEvalContext<'mir, 'tcx> {\n             // is in bounds, because if they are in bounds, the pointer can't be null.\n             // Inequality with integers other than null can never be known for sure.\n             (Scalar::Int(int), Scalar::Ptr(ptr)) | (Scalar::Ptr(ptr), Scalar::Int(int)) => {\n-                int.is_null() && !self.memory.ptr_may_be_null(ptr)\n+                int.is_null() && !self.memory.ptr_may_be_null(ptr.into())\n             }\n             // FIXME: return `true` for at least some comparisons where we can reliably\n             // determine the result of runtime inequality tests at compile-time.\n@@ -356,10 +356,6 @@ impl<'mir, 'tcx> interpret::Machine<'mir, 'tcx> for CompileTimeInterpreter<'mir,\n         Err(ConstEvalErrKind::Abort(msg).into())\n     }\n \n-    fn ptr_to_int(_mem: &Memory<'mir, 'tcx, Self>, _ptr: Pointer) -> InterpResult<'tcx, u64> {\n-        Err(ConstEvalErrKind::PtrToIntCast.into())\n-    }\n-\n     fn binary_ptr_op(\n         _ecx: &InterpCx<'mir, 'tcx, Self>,\n         _bin_op: mir::BinOp,"}, {"sha": "8254e5790013bd553d703a4add5e883c6dbf98e4", "filename": "compiler/rustc_mir/src/const_eval/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Fconst_eval%2Fmod.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -35,7 +35,7 @@ pub(crate) fn const_caller_location(\n     if intern_const_alloc_recursive(&mut ecx, InternKind::Constant, &loc_place).is_err() {\n         bug!(\"intern_const_alloc_recursive should not error in this case\")\n     }\n-    ConstValue::Scalar(loc_place.ptr)\n+    ConstValue::Scalar(Scalar::Ptr(loc_place.ptr.into_pointer_or_offset().unwrap()))\n }\n \n /// Convert an evaluated constant to a type level constant\n@@ -179,9 +179,9 @@ pub(crate) fn deref_const<'tcx>(\n     let ecx = mk_eval_cx(tcx, DUMMY_SP, param_env, false);\n     let op = ecx.const_to_op(val, None).unwrap();\n     let mplace = ecx.deref_operand(&op).unwrap();\n-    if let Scalar::Ptr(ptr) = mplace.ptr {\n+    if let Some(alloc_id) = mplace.ptr.provenance {\n         assert_eq!(\n-            tcx.get_global_alloc(ptr.alloc_id).unwrap().unwrap_memory().mutability,\n+            tcx.get_global_alloc(alloc_id).unwrap().unwrap_memory().mutability,\n             Mutability::Not,\n             \"deref_const cannot be used with mutable allocations as \\\n             that could allow pattern matching to observe mutable statics\","}, {"sha": "2821728b1d57a80b4b65bf1ebe8a0c80d90fcd11", "filename": "compiler/rustc_mir/src/interpret/cast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fcast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fcast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fcast.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -175,7 +175,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         // (a) cast a raw ptr to usize, or\n         // (b) cast from an integer-like (including bool, char, enums).\n         // In both cases we want the bits.\n-        let bits = self.force_bits(src.to_scalar()?, src.layout.size)?;\n+        let bits = src.to_scalar()?.to_bits(src.layout.size)?;\n         Ok(self.cast_from_scalar(bits, src.layout, cast_ty).into())\n     }\n "}, {"sha": "ef021435f46b54c50d7b536fc1281d6faaddbe14", "filename": "compiler/rustc_mir/src/interpret/eval_context.rs", "status": "modified", "additions": 48, "deletions": 46, "changes": 94, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Feval_context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Feval_context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Feval_context.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -8,7 +8,6 @@ use rustc_index::vec::IndexVec;\n use rustc_macros::HashStable;\n use rustc_middle::ich::StableHashingContext;\n use rustc_middle::mir;\n-use rustc_middle::mir::interpret::{GlobalId, InterpResult, Pointer, Scalar};\n use rustc_middle::ty::layout::{self, TyAndLayout};\n use rustc_middle::ty::{\n     self, query::TyCtxtAt, subst::SubstsRef, ParamEnv, Ty, TyCtxt, TypeFoldable,\n@@ -18,8 +17,9 @@ use rustc_span::{Pos, Span};\n use rustc_target::abi::{Align, HasDataLayout, LayoutOf, Size, TargetDataLayout};\n \n use super::{\n-    Immediate, MPlaceTy, Machine, MemPlace, MemPlaceMeta, Memory, MemoryKind, Operand, Place,\n-    PlaceTy, ScalarMaybeUninit, StackPopJump,\n+    AllocId, GlobalId, Immediate, InterpResult, MPlaceTy, Machine, MemPlace, MemPlaceMeta, Memory,\n+    MemoryKind, Operand, Place, PlaceTy, Pointer, Provenance, Scalar, ScalarMaybeUninit,\n+    StackPopJump,\n };\n use crate::transform::validate::equal_up_to_regions;\n use crate::util::storage::AlwaysLiveLocals;\n@@ -80,7 +80,7 @@ impl Drop for SpanGuard {\n }\n \n /// A stack frame.\n-pub struct Frame<'mir, 'tcx, Tag = (), Extra = ()> {\n+pub struct Frame<'mir, 'tcx, Tag = AllocId, Extra = ()> {\n     ////////////////////////////////////////////////////////////////////////////////\n     // Function and callsite information\n     ////////////////////////////////////////////////////////////////////////////////\n@@ -161,16 +161,16 @@ pub enum StackPopCleanup {\n \n /// State of a local variable including a memoized layout\n #[derive(Clone, PartialEq, Eq, HashStable)]\n-pub struct LocalState<'tcx, Tag = ()> {\n+pub struct LocalState<'tcx, Tag = AllocId> {\n     pub value: LocalValue<Tag>,\n     /// Don't modify if `Some`, this is only used to prevent computing the layout twice\n     #[stable_hasher(ignore)]\n     pub layout: Cell<Option<TyAndLayout<'tcx>>>,\n }\n \n /// Current value of a local variable\n-#[derive(Copy, Clone, PartialEq, Eq, Debug, HashStable)] // Miri debug-prints these\n-pub enum LocalValue<Tag = ()> {\n+#[derive(Copy, Clone, PartialEq, Eq, HashStable)]\n+pub enum LocalValue<Tag = AllocId> {\n     /// This local is not currently alive, and cannot be used at all.\n     Dead,\n     /// This local is alive but not yet initialized. It can be written to\n@@ -186,6 +186,18 @@ pub enum LocalValue<Tag = ()> {\n     Live(Operand<Tag>),\n }\n \n+impl<Tag: Provenance> std::fmt::Debug for LocalValue<Tag> {\n+    // Miri debug-prints these\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        use LocalValue::*;\n+        match self {\n+            Dead => f.debug_tuple(\"Dead\").finish(),\n+            Uninitialized => f.debug_tuple(\"Uninitialized\").finish(),\n+            Live(o) => f.debug_tuple(\"Live\").field(o).finish(),\n+        }\n+    }\n+}\n+\n impl<'tcx, Tag: Copy + 'static> LocalState<'tcx, Tag> {\n     /// Read the local's value or error if the local is not yet live or not live anymore.\n     ///\n@@ -406,20 +418,8 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n     }\n \n     #[inline(always)]\n-    pub fn force_ptr(\n-        &self,\n-        scalar: Scalar<M::PointerTag>,\n-    ) -> InterpResult<'tcx, Pointer<M::PointerTag>> {\n-        self.memory.force_ptr(scalar)\n-    }\n-\n-    #[inline(always)]\n-    pub fn force_bits(\n-        &self,\n-        scalar: Scalar<M::PointerTag>,\n-        size: Size,\n-    ) -> InterpResult<'tcx, u128> {\n-        self.memory.force_bits(scalar, size)\n+    pub fn scalar_to_ptr(&self, scalar: Scalar<M::PointerTag>) -> Pointer<Option<M::PointerTag>> {\n+        self.memory.scalar_to_ptr(scalar)\n     }\n \n     /// Call this to turn untagged \"global\" pointers (obtained via `tcx`) into\n@@ -650,7 +650,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 Ok(Some((size, align)))\n             }\n             ty::Dynamic(..) => {\n-                let vtable = metadata.unwrap_meta();\n+                let vtable = self.scalar_to_ptr(metadata.unwrap_meta());\n                 // Read size and align from vtable (already checks size).\n                 Ok(Some(self.read_size_and_align_from_vtable(vtable)?))\n             }\n@@ -898,8 +898,11 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         if let LocalValue::Live(Operand::Indirect(MemPlace { ptr, .. })) = local {\n             // All locals have a backing allocation, even if the allocation is empty\n             // due to the local having ZST type.\n-            let ptr = ptr.assert_ptr();\n-            trace!(\"deallocating local: {:?}\", self.memory.dump_alloc(ptr.alloc_id));\n+            trace!(\n+                \"deallocating local {:?}: {:?}\",\n+                local,\n+                self.memory.dump_alloc(ptr.provenance.unwrap().erase_for_fmt())\n+            );\n             self.memory.deallocate(ptr, None, MemoryKind::Stack)?;\n         };\n         Ok(())\n@@ -975,46 +978,45 @@ impl<'a, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> std::fmt::Debug\n                 match self.ecx.stack()[frame].locals[local].value {\n                     LocalValue::Dead => write!(fmt, \" is dead\")?,\n                     LocalValue::Uninitialized => write!(fmt, \" is uninitialized\")?,\n-                    LocalValue::Live(Operand::Indirect(mplace)) => match mplace.ptr {\n-                        Scalar::Ptr(ptr) => {\n-                            write!(\n-                                fmt,\n-                                \" by align({}){} ref:\",\n-                                mplace.align.bytes(),\n-                                match mplace.meta {\n-                                    MemPlaceMeta::Meta(meta) => format!(\" meta({:?})\", meta),\n-                                    MemPlaceMeta::Poison | MemPlaceMeta::None => String::new(),\n-                                }\n-                            )?;\n-                            allocs.push(ptr.alloc_id);\n-                        }\n-                        ptr => write!(fmt, \" by integral ref: {:?}\", ptr)?,\n-                    },\n+                    LocalValue::Live(Operand::Indirect(mplace)) => {\n+                        write!(\n+                            fmt,\n+                            \" by align({}){} ref {:?}:\",\n+                            mplace.align.bytes(),\n+                            match mplace.meta {\n+                                MemPlaceMeta::Meta(meta) => format!(\" meta({:?})\", meta),\n+                                MemPlaceMeta::Poison | MemPlaceMeta::None => String::new(),\n+                            },\n+                            mplace.ptr,\n+                        )?;\n+                        allocs.extend(mplace.ptr.map_erase_for_fmt().provenance);\n+                    }\n                     LocalValue::Live(Operand::Immediate(Immediate::Scalar(val))) => {\n                         write!(fmt, \" {:?}\", val)?;\n                         if let ScalarMaybeUninit::Scalar(Scalar::Ptr(ptr)) = val {\n-                            allocs.push(ptr.alloc_id);\n+                            allocs.push(ptr.provenance.erase_for_fmt());\n                         }\n                     }\n                     LocalValue::Live(Operand::Immediate(Immediate::ScalarPair(val1, val2))) => {\n                         write!(fmt, \" ({:?}, {:?})\", val1, val2)?;\n                         if let ScalarMaybeUninit::Scalar(Scalar::Ptr(ptr)) = val1 {\n-                            allocs.push(ptr.alloc_id);\n+                            allocs.push(ptr.provenance.erase_for_fmt());\n                         }\n                         if let ScalarMaybeUninit::Scalar(Scalar::Ptr(ptr)) = val2 {\n-                            allocs.push(ptr.alloc_id);\n+                            allocs.push(ptr.provenance.erase_for_fmt());\n                         }\n                     }\n                 }\n \n                 write!(fmt, \": {:?}\", self.ecx.memory.dump_allocs(allocs))\n             }\n-            Place::Ptr(mplace) => match mplace.ptr {\n-                Scalar::Ptr(ptr) => write!(\n+            Place::Ptr(mplace) => match mplace.ptr.map_erase_for_fmt().provenance {\n+                Some(alloc_id) => write!(\n                     fmt,\n-                    \"by align({}) ref: {:?}\",\n+                    \"by align({}) ref {:?}: {:?}\",\n                     mplace.align.bytes(),\n-                    self.ecx.memory.dump_alloc(ptr.alloc_id)\n+                    mplace.ptr,\n+                    self.ecx.memory.dump_alloc(alloc_id)\n                 ),\n                 ptr => write!(fmt, \" integral by ref: {:?}\", ptr),\n             },"}, {"sha": "b0606aba4164b8900c77e7b47c26f17597185509", "filename": "compiler/rustc_mir/src/interpret/intern.rs", "status": "modified", "additions": 13, "deletions": 15, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintern.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintern.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintern.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -20,18 +20,17 @@ use rustc_errors::ErrorReported;\n use rustc_hir as hir;\n use rustc_middle::mir::interpret::InterpResult;\n use rustc_middle::ty::{self, layout::TyAndLayout, Ty};\n-use rustc_target::abi::Size;\n \n use rustc_ast::Mutability;\n \n-use super::{AllocId, Allocation, InterpCx, MPlaceTy, Machine, MemoryKind, Scalar, ValueVisitor};\n+use super::{AllocId, Allocation, InterpCx, MPlaceTy, Machine, MemoryKind, ValueVisitor};\n use crate::const_eval;\n \n pub trait CompileTimeMachine<'mir, 'tcx, T> = Machine<\n     'mir,\n     'tcx,\n     MemoryKind = T,\n-    PointerTag = (),\n+    PointerTag = AllocId,\n     ExtraFnVal = !,\n     FrameExtra = (),\n     AllocExtra = (),\n@@ -136,7 +135,7 @@ fn intern_shallow<'rt, 'mir, 'tcx, M: CompileTimeMachine<'mir, 'tcx, const_eval:\n     };\n     // link the alloc id to the actual allocation\n     let alloc = tcx.intern_const_alloc(alloc);\n-    leftover_allocations.extend(alloc.relocations().iter().map(|&(_, ((), reloc))| reloc));\n+    leftover_allocations.extend(alloc.relocations().iter().map(|&(_, alloc_id)| alloc_id));\n     tcx.set_alloc_id_memory(alloc_id, alloc);\n     None\n }\n@@ -203,10 +202,11 @@ impl<'rt, 'mir, 'tcx: 'mir, M: CompileTimeMachine<'mir, 'tcx, const_eval::Memory\n             if let ty::Dynamic(..) =\n                 tcx.struct_tail_erasing_lifetimes(referenced_ty, self.ecx.param_env).kind()\n             {\n-                if let Scalar::Ptr(vtable) = mplace.meta.unwrap_meta() {\n+                let ptr = self.ecx.scalar_to_ptr(mplace.meta.unwrap_meta());\n+                if let Some(alloc_id) = ptr.provenance {\n                     // Explicitly choose const mode here, since vtables are immutable, even\n                     // if the reference of the fat pointer is mutable.\n-                    self.intern_shallow(vtable.alloc_id, InternMode::Const, None);\n+                    self.intern_shallow(alloc_id, InternMode::Const, None);\n                 } else {\n                     // Validation will error (with a better message) on an invalid vtable pointer.\n                     // Let validation show the error message, but make sure it *does* error.\n@@ -216,7 +216,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: CompileTimeMachine<'mir, 'tcx, const_eval::Memory\n             }\n             // Check if we have encountered this pointer+layout combination before.\n             // Only recurse for allocation-backed pointers.\n-            if let Scalar::Ptr(ptr) = mplace.ptr {\n+            if let Some(alloc_id) = mplace.ptr.provenance {\n                 // Compute the mode with which we intern this. Our goal here is to make as many\n                 // statics as we can immutable so they can be placed in read-only memory by LLVM.\n                 let ref_mode = match self.mode {\n@@ -259,7 +259,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: CompileTimeMachine<'mir, 'tcx, const_eval::Memory\n                         InternMode::Const\n                     }\n                 };\n-                match self.intern_shallow(ptr.alloc_id, ref_mode, Some(referenced_ty)) {\n+                match self.intern_shallow(alloc_id, ref_mode, Some(referenced_ty)) {\n                     // No need to recurse, these are interned already and statics may have\n                     // cycles, so we don't want to recurse there\n                     Some(IsStaticOrFn) => {}\n@@ -321,7 +321,7 @@ where\n         leftover_allocations,\n         // The outermost allocation must exist, because we allocated it with\n         // `Memory::allocate`.\n-        ret.ptr.assert_ptr().alloc_id,\n+        ret.ptr.provenance.unwrap(),\n         base_intern_mode,\n         Some(ret.layout.ty),\n     );\n@@ -395,9 +395,9 @@ where\n             }\n             let alloc = tcx.intern_const_alloc(alloc);\n             tcx.set_alloc_id_memory(alloc_id, alloc);\n-            for &(_, ((), reloc)) in alloc.relocations().iter() {\n-                if leftover_allocations.insert(reloc) {\n-                    todo.push(reloc);\n+            for &(_, alloc_id) in alloc.relocations().iter() {\n+                if leftover_allocations.insert(alloc_id) {\n+                    todo.push(alloc_id);\n                 }\n             }\n         } else if ecx.memory.dead_alloc_map.contains_key(&alloc_id) {\n@@ -430,9 +430,7 @@ impl<'mir, 'tcx: 'mir, M: super::intern::CompileTimeMachine<'mir, 'tcx, !>>\n     ) -> InterpResult<'tcx, &'tcx Allocation> {\n         let dest = self.allocate(layout, MemoryKind::Stack)?;\n         f(self, &dest)?;\n-        let ptr = dest.ptr.assert_ptr();\n-        assert_eq!(ptr.offset, Size::ZERO);\n-        let mut alloc = self.memory.alloc_map.remove(&ptr.alloc_id).unwrap().1;\n+        let mut alloc = self.memory.alloc_map.remove(&dest.ptr.provenance.unwrap()).unwrap().1;\n         alloc.mutability = Mutability::Not;\n         Ok(self.tcx.intern_const_alloc(alloc))\n     }"}, {"sha": "88dd94802d14f50e92581d3c72c03514f5a2e431", "filename": "compiler/rustc_mir/src/interpret/intrinsics.rs", "status": "modified", "additions": 23, "deletions": 20, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintrinsics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintrinsics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintrinsics.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -18,6 +18,7 @@ use rustc_target::abi::{Abi, Align, LayoutOf as _, Primitive, Size};\n \n use super::{\n     util::ensure_monomorphic_enough, CheckInAllocMsg, ImmTy, InterpCx, Machine, OpTy, PlaceTy,\n+    Pointer,\n };\n \n mod caller_location;\n@@ -138,7 +139,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             sym::caller_location => {\n                 let span = self.find_closest_untracked_caller_location();\n                 let location = self.alloc_caller_location_for_span(span);\n-                self.write_scalar(location.ptr, dest)?;\n+                self.write_immediate(location.to_ref(self), dest)?;\n             }\n \n             sym::min_align_of_val | sym::size_of_val => {\n@@ -190,7 +191,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 let ty = substs.type_at(0);\n                 let layout_of = self.layout_of(ty)?;\n                 let val = self.read_scalar(&args[0])?.check_init()?;\n-                let bits = self.force_bits(val, layout_of.size)?;\n+                let bits = val.to_bits(layout_of.size)?;\n                 let kind = match layout_of.abi {\n                     Abi::Scalar(ref scalar) => scalar.value,\n                     _ => span_bug!(\n@@ -238,7 +239,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                         // term since the sign of the second term can be inferred from this and\n                         // the fact that the operation has overflowed (if either is 0 no\n                         // overflow can occur)\n-                        let first_term: u128 = self.force_bits(l.to_scalar()?, l.layout.size)?;\n+                        let first_term: u128 = l.to_scalar()?.to_bits(l.layout.size)?;\n                         let first_term_positive = first_term & (1 << (num_bits - 1)) == 0;\n                         if first_term_positive {\n                             // Negative overflow not possible since the positive first term\n@@ -298,7 +299,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 let (val, overflowed, _ty) = self.overflowing_binary_op(bin_op, &l, &r)?;\n                 if overflowed {\n                     let layout = self.layout_of(substs.type_at(0))?;\n-                    let r_val = self.force_bits(r.to_scalar()?, layout.size)?;\n+                    let r_val = r.to_scalar()?.to_bits(layout.size)?;\n                     if let sym::unchecked_shl | sym::unchecked_shr = intrinsic_name {\n                         throw_ub_format!(\"overflowing shift by {} in `{}`\", r_val, intrinsic_name);\n                     } else {\n@@ -312,9 +313,9 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 // rotate_right: (X << ((BW - S) % BW)) | (X >> (S % BW))\n                 let layout = self.layout_of(substs.type_at(0))?;\n                 let val = self.read_scalar(&args[0])?.check_init()?;\n-                let val_bits = self.force_bits(val, layout.size)?;\n+                let val_bits = val.to_bits(layout.size)?;\n                 let raw_shift = self.read_scalar(&args[1])?.check_init()?;\n-                let raw_shift_bits = self.force_bits(raw_shift, layout.size)?;\n+                let raw_shift_bits = raw_shift.to_bits(layout.size)?;\n                 let width_bits = u128::from(layout.size.bits());\n                 let shift_bits = raw_shift_bits % width_bits;\n                 let inv_shift_bits = (width_bits - shift_bits) % width_bits;\n@@ -331,12 +332,12 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 self.copy_intrinsic(&args[0], &args[1], &args[2], /*nonoverlapping*/ false)?;\n             }\n             sym::offset => {\n-                let ptr = self.read_scalar(&args[0])?.check_init()?;\n+                let ptr = self.read_pointer(&args[0])?;\n                 let offset_count = self.read_scalar(&args[1])?.to_machine_isize(self)?;\n                 let pointee_ty = substs.type_at(0);\n \n                 let offset_ptr = self.ptr_offset_inbounds(ptr, pointee_ty, offset_count)?;\n-                self.write_scalar(offset_ptr, dest)?;\n+                self.write_scalar(Scalar::from_maybe_pointer(offset_ptr, self), dest)?;\n             }\n             sym::arith_offset => {\n                 let ptr = self.read_scalar(&args[0])?.check_init()?;\n@@ -376,18 +377,20 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n \n                 if !done {\n                     // General case: we need two pointers.\n-                    let a = self.force_ptr(a)?;\n-                    let b = self.force_ptr(b)?;\n-                    if a.alloc_id != b.alloc_id {\n+                    let a = self.scalar_to_ptr(a);\n+                    let b = self.scalar_to_ptr(b);\n+                    let (a_alloc_id, a_offset, _) = self.memory.ptr_force_alloc(a)?;\n+                    let (b_alloc_id, b_offset, _) = self.memory.ptr_force_alloc(b)?;\n+                    if a_alloc_id != b_alloc_id {\n                         throw_ub_format!(\n                             \"ptr_offset_from cannot compute offset of pointers into different \\\n                             allocations.\",\n                         );\n                     }\n                     let usize_layout = self.layout_of(self.tcx.types.usize)?;\n                     let isize_layout = self.layout_of(self.tcx.types.isize)?;\n-                    let a_offset = ImmTy::from_uint(a.offset.bytes(), usize_layout);\n-                    let b_offset = ImmTy::from_uint(b.offset.bytes(), usize_layout);\n+                    let a_offset = ImmTy::from_uint(a_offset.bytes(), usize_layout);\n+                    let b_offset = ImmTy::from_uint(b_offset.bytes(), usize_layout);\n                     let (val, _overflowed, _ty) =\n                         self.overflowing_binary_op(BinOp::Sub, &a_offset, &b_offset)?;\n                     let pointee_layout = self.layout_of(substs.type_at(0))?;\n@@ -513,18 +516,18 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n     /// 0, so offset-by-0 (and only 0) is okay -- except that null cannot be offset by _any_ value.\n     pub fn ptr_offset_inbounds(\n         &self,\n-        ptr: Scalar<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         pointee_ty: Ty<'tcx>,\n         offset_count: i64,\n-    ) -> InterpResult<'tcx, Scalar<M::PointerTag>> {\n+    ) -> InterpResult<'tcx, Pointer<Option<M::PointerTag>>> {\n         // We cannot overflow i64 as a type's size must be <= isize::MAX.\n         let pointee_size = i64::try_from(self.layout_of(pointee_ty)?.size.bytes()).unwrap();\n         // The computed offset, in bytes, cannot overflow an isize.\n         let offset_bytes =\n             offset_count.checked_mul(pointee_size).ok_or(err_ub!(PointerArithOverflow))?;\n         // The offset being in bounds cannot rely on \"wrapping around\" the address space.\n         // So, first rule out overflows in the pointer arithmetic.\n-        let offset_ptr = ptr.ptr_signed_offset(offset_bytes, self)?;\n+        let offset_ptr = ptr.signed_offset(offset_bytes, self)?;\n         // ptr and offset_ptr must be in bounds of the same allocated object. This means all of the\n         // memory between these pointers must be accessible. Note that we do not require the\n         // pointers to be properly aligned (unlike a read/write operation).\n@@ -558,8 +561,8 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             )\n         })?;\n \n-        let src = self.read_scalar(&src)?.check_init()?;\n-        let dst = self.read_scalar(&dst)?.check_init()?;\n+        let src = self.read_pointer(&src)?;\n+        let dst = self.read_pointer(&dst)?;\n \n         self.memory.copy(src, align, dst, align, size, nonoverlapping)\n     }\n@@ -572,8 +575,8 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         let layout = self.layout_of(lhs.layout.ty.builtin_deref(true).unwrap().ty)?;\n         assert!(!layout.is_unsized());\n \n-        let lhs = self.read_scalar(lhs)?.check_init()?;\n-        let rhs = self.read_scalar(rhs)?.check_init()?;\n+        let lhs = self.read_pointer(lhs)?;\n+        let rhs = self.read_pointer(rhs)?;\n         let lhs_bytes = self.memory.read_bytes(lhs, layout.size)?;\n         let rhs_bytes = self.memory.read_bytes(rhs, layout.size)?;\n         Ok(Scalar::from_bool(lhs_bytes == rhs_bytes))"}, {"sha": "022129b2a22046a04806c4dbb893cbd4555aa5a1", "filename": "compiler/rustc_mir/src/interpret/intrinsics/caller_location.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintrinsics%2Fcaller_location.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintrinsics%2Fcaller_location.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fintrinsics%2Fcaller_location.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -96,7 +96,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         let location = self.allocate(loc_layout, MemoryKind::CallerLocation).unwrap();\n \n         // Initialize fields.\n-        self.write_immediate(file.to_ref(), &self.mplace_field(&location, 0).unwrap().into())\n+        self.write_immediate(file.to_ref(self), &self.mplace_field(&location, 0).unwrap().into())\n             .expect(\"writing to memory we just allocated cannot fail\");\n         self.write_scalar(line, &self.mplace_field(&location, 1).unwrap().into())\n             .expect(\"writing to memory we just allocated cannot fail\");"}, {"sha": "a9e1c605a1f91e003aa263596a841cf7b04e511d", "filename": "compiler/rustc_mir/src/interpret/machine.rs", "status": "modified", "additions": 39, "deletions": 33, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fmachine.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -13,8 +13,8 @@ use rustc_target::abi::Size;\n use rustc_target::spec::abi::Abi;\n \n use super::{\n-    AllocId, Allocation, CheckInAllocMsg, Frame, ImmTy, InterpCx, InterpResult, LocalValue,\n-    MemPlace, Memory, MemoryKind, OpTy, Operand, PlaceTy, Pointer, Scalar, StackPopUnwind,\n+    AllocId, Allocation, Frame, ImmTy, InterpCx, InterpResult, LocalValue, MemPlace, Memory,\n+    MemoryKind, OpTy, Operand, PlaceTy, Pointer, Provenance, Scalar, StackPopUnwind,\n };\n \n /// Data returned by Machine::stack_pop,\n@@ -84,12 +84,8 @@ pub trait Machine<'mir, 'tcx>: Sized {\n     /// Additional memory kinds a machine wishes to distinguish from the builtin ones\n     type MemoryKind: Debug + std::fmt::Display + MayLeak + Eq + 'static;\n \n-    /// Tag tracked alongside every pointer. This is used to implement \"Stacked Borrows\"\n-    /// <https://www.ralfj.de/blog/2018/08/07/stacked-borrows.html>.\n-    /// The `default()` is used for pointers to consts, statics, vtables and functions.\n-    /// The `Debug` formatting is used for displaying pointers; we cannot use `Display`\n-    /// as `()` does not implement that, but it should be \"nice\" output.\n-    type PointerTag: Debug + Copy + Eq + Hash + 'static;\n+    /// Pointers are \"tagged\" with provenance information; typically the `AllocId` they belong to.\n+    type PointerTag: Provenance + Eq + Hash + 'static;\n \n     /// Machines can define extra (non-instance) things that represent values of function pointers.\n     /// For example, Miri uses this to return a function pointer from `dlsym`\n@@ -287,7 +283,10 @@ pub trait Machine<'mir, 'tcx>: Sized {\n     /// this will return an unusable tag (i.e., accesses will be UB)!\n     ///\n     /// Called on the id returned by `thread_local_static_alloc_id` and `extern_static_alloc_id`, if needed.\n-    fn tag_global_base_pointer(memory_extra: &Self::MemoryExtra, id: AllocId) -> Self::PointerTag;\n+    fn tag_global_base_pointer(\n+        memory_extra: &Self::MemoryExtra,\n+        ptr: Pointer,\n+    ) -> Pointer<Self::PointerTag>;\n \n     /// Called to initialize the \"extra\" state of an allocation and make the pointers\n     /// it contains (in relocations) tagged.  The way we construct allocations is\n@@ -400,31 +399,24 @@ pub trait Machine<'mir, 'tcx>: Sized {\n         Ok(StackPopJump::Normal)\n     }\n \n-    fn int_to_ptr(\n-        _mem: &Memory<'mir, 'tcx, Self>,\n-        int: u64,\n-    ) -> InterpResult<'tcx, Pointer<Self::PointerTag>> {\n-        Err((if int == 0 {\n-            // This is UB, seriously.\n-            // (`DanglingIntPointer` with these exact arguments has special printing code.)\n-            err_ub!(DanglingIntPointer(0, CheckInAllocMsg::InboundsTest))\n-        } else {\n-            // This is just something we cannot support during const-eval.\n-            err_unsup!(ReadBytesAsPointer)\n-        })\n-        .into())\n-    }\n+    /// \"Int-to-pointer cast\"\n+    fn ptr_from_addr(\n+        mem: &Memory<'mir, 'tcx, Self>,\n+        addr: u64,\n+    ) -> Pointer<Option<Self::PointerTag>>;\n \n-    fn ptr_to_int(\n-        _mem: &Memory<'mir, 'tcx, Self>,\n-        _ptr: Pointer<Self::PointerTag>,\n-    ) -> InterpResult<'tcx, u64>;\n+    /// Convert a pointer with provenance into an allocation-offset pair,\n+    /// or a `None` with an absolute address if that conversion is not possible.\n+    fn ptr_get_alloc(\n+        mem: &Memory<'mir, 'tcx, Self>,\n+        ptr: Pointer<Self::PointerTag>,\n+    ) -> (Option<AllocId>, Size);\n }\n \n // A lot of the flexibility above is just needed for `Miri`, but all \"compile-time\" machines\n // (CTFE and ConstProp) use the same instance.  Here, we share that code.\n pub macro compile_time_machine(<$mir: lifetime, $tcx: lifetime>) {\n-    type PointerTag = ();\n+    type PointerTag = AllocId;\n     type ExtraFnVal = !;\n \n     type MemoryMap =\n@@ -467,19 +459,33 @@ pub macro compile_time_machine(<$mir: lifetime, $tcx: lifetime>) {\n     #[inline(always)]\n     fn init_allocation_extra<'b>(\n         _memory_extra: &Self::MemoryExtra,\n-        _id: AllocId,\n+        id: AllocId,\n         alloc: Cow<'b, Allocation>,\n         _kind: Option<MemoryKind<Self::MemoryKind>>,\n     ) -> (Cow<'b, Allocation<Self::PointerTag>>, Self::PointerTag) {\n         // We do not use a tag so we can just cheaply forward the allocation\n-        (alloc, ())\n+        (alloc, id)\n     }\n \n     #[inline(always)]\n     fn tag_global_base_pointer(\n         _memory_extra: &Self::MemoryExtra,\n-        _id: AllocId,\n-    ) -> Self::PointerTag {\n-        ()\n+        ptr: Pointer<AllocId>,\n+    ) -> Pointer<AllocId> {\n+        ptr\n+    }\n+\n+    #[inline(always)]\n+    fn ptr_from_addr(_mem: &Memory<$mir, $tcx, Self>, addr: u64) -> Pointer<Option<AllocId>> {\n+        Pointer::new(None, Size::from_bytes(addr))\n+    }\n+\n+    #[inline(always)]\n+    fn ptr_get_alloc(\n+        _mem: &Memory<$mir, $tcx, Self>,\n+        ptr: Pointer<AllocId>,\n+    ) -> (Option<AllocId>, Size) {\n+        let (alloc_id, offset) = ptr.into_parts();\n+        (Some(alloc_id), offset)\n     }\n }"}, {"sha": "6a1d1bc3b29722a0ded47d0e22d72964803aa90d", "filename": "compiler/rustc_mir/src/interpret/memory.rs", "status": "modified", "additions": 178, "deletions": 141, "changes": 319, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fmemory.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -8,7 +8,7 @@\n \n use std::borrow::Cow;\n use std::collections::VecDeque;\n-use std::convert::{TryFrom, TryInto};\n+use std::convert::TryFrom;\n use std::fmt;\n use std::ptr;\n \n@@ -19,7 +19,8 @@ use rustc_target::abi::{Align, HasDataLayout, Size, TargetDataLayout};\n \n use super::{\n     alloc_range, AllocId, AllocMap, AllocRange, Allocation, CheckInAllocMsg, GlobalAlloc,\n-    InterpResult, Machine, MayLeak, Pointer, PointerArithmetic, Scalar, ScalarMaybeUninit,\n+    InterpResult, Machine, MayLeak, Pointer, PointerArithmetic, Provenance, Scalar,\n+    ScalarMaybeUninit,\n };\n use crate::util::pretty;\n \n@@ -162,25 +163,24 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n     #[inline]\n     pub fn global_base_pointer(\n         &self,\n-        mut ptr: Pointer,\n+        ptr: Pointer<AllocId>,\n     ) -> InterpResult<'tcx, Pointer<M::PointerTag>> {\n+        let (alloc_id, offset) = ptr.into_parts();\n         // We need to handle `extern static`.\n-        let ptr = match self.tcx.get_global_alloc(ptr.alloc_id) {\n+        let alloc_id = match self.tcx.get_global_alloc(alloc_id) {\n             Some(GlobalAlloc::Static(def_id)) if self.tcx.is_thread_local_static(def_id) => {\n                 bug!(\"global memory cannot point to thread-local static\")\n             }\n             Some(GlobalAlloc::Static(def_id)) if self.tcx.is_foreign_item(def_id) => {\n-                ptr.alloc_id = M::extern_static_alloc_id(self, def_id)?;\n-                ptr\n+                M::extern_static_alloc_id(self, def_id)?\n             }\n             _ => {\n                 // No need to change the `AllocId`.\n-                ptr\n+                alloc_id\n             }\n         };\n         // And we need to get the tag.\n-        let tag = M::tag_global_base_pointer(&self.extra, ptr.alloc_id);\n-        Ok(ptr.with_tag(tag))\n+        Ok(M::tag_global_base_pointer(&self.extra, Pointer::new(alloc_id, offset)))\n     }\n \n     pub fn create_fn_alloc(\n@@ -237,18 +237,19 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n         // This is a new allocation, not a new global one, so no `global_base_ptr`.\n         let (alloc, tag) = M::init_allocation_extra(&self.extra, id, Cow::Owned(alloc), Some(kind));\n         self.alloc_map.insert(id, (kind, alloc.into_owned()));\n-        Pointer::from(id).with_tag(tag)\n+        Pointer::new(tag, Size::ZERO)\n     }\n \n     pub fn reallocate(\n         &mut self,\n-        ptr: Pointer<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         old_size_and_align: Option<(Size, Align)>,\n         new_size: Size,\n         new_align: Align,\n         kind: MemoryKind<M::MemoryKind>,\n     ) -> InterpResult<'tcx, Pointer<M::PointerTag>> {\n-        if ptr.offset.bytes() != 0 {\n+        let (alloc_id, offset, ptr) = self.ptr_force_alloc(ptr)?;\n+        if offset.bytes() != 0 {\n             throw_ub_format!(\n                 \"reallocating {:?} which does not point to the beginning of an object\",\n                 ptr\n@@ -260,7 +261,7 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n         let new_ptr = self.allocate(new_size, new_align, kind)?;\n         let old_size = match old_size_and_align {\n             Some((size, _align)) => size,\n-            None => self.get_raw(ptr.alloc_id)?.size(),\n+            None => self.get_raw(alloc_id)?.size(),\n         };\n         // This will also call the access hooks.\n         self.copy(\n@@ -271,50 +272,51 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n             old_size.min(new_size),\n             /*nonoverlapping*/ true,\n         )?;\n-        self.deallocate(ptr, old_size_and_align, kind)?;\n+        self.deallocate(ptr.into(), old_size_and_align, kind)?;\n \n         Ok(new_ptr)\n     }\n \n     pub fn deallocate(\n         &mut self,\n-        ptr: Pointer<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         old_size_and_align: Option<(Size, Align)>,\n         kind: MemoryKind<M::MemoryKind>,\n     ) -> InterpResult<'tcx> {\n-        trace!(\"deallocating: {}\", ptr.alloc_id);\n+        let (alloc_id, offset, ptr) = self.ptr_force_alloc(ptr)?;\n+        trace!(\"deallocating: {}\", alloc_id);\n \n-        if ptr.offset.bytes() != 0 {\n+        if offset.bytes() != 0 {\n             throw_ub_format!(\n                 \"deallocating {:?} which does not point to the beginning of an object\",\n                 ptr\n             );\n         }\n \n-        let (alloc_kind, mut alloc) = match self.alloc_map.remove(&ptr.alloc_id) {\n+        let (alloc_kind, mut alloc) = match self.alloc_map.remove(&alloc_id) {\n             Some(alloc) => alloc,\n             None => {\n                 // Deallocating global memory -- always an error\n-                return Err(match self.tcx.get_global_alloc(ptr.alloc_id) {\n+                return Err(match self.tcx.get_global_alloc(alloc_id) {\n                     Some(GlobalAlloc::Function(..)) => {\n-                        err_ub_format!(\"deallocating {}, which is a function\", ptr.alloc_id)\n+                        err_ub_format!(\"deallocating {}, which is a function\", alloc_id)\n                     }\n                     Some(GlobalAlloc::Static(..) | GlobalAlloc::Memory(..)) => {\n-                        err_ub_format!(\"deallocating {}, which is static memory\", ptr.alloc_id)\n+                        err_ub_format!(\"deallocating {}, which is static memory\", alloc_id)\n                     }\n-                    None => err_ub!(PointerUseAfterFree(ptr.alloc_id)),\n+                    None => err_ub!(PointerUseAfterFree(alloc_id)),\n                 }\n                 .into());\n             }\n         };\n \n         if alloc.mutability == Mutability::Not {\n-            throw_ub_format!(\"deallocating immutable allocation {}\", ptr.alloc_id);\n+            throw_ub_format!(\"deallocating immutable allocation {}\", alloc_id);\n         }\n         if alloc_kind != kind {\n             throw_ub_format!(\n                 \"deallocating {}, which is {} memory, using {} deallocation operation\",\n-                ptr.alloc_id,\n+                alloc_id,\n                 alloc_kind,\n                 kind\n             );\n@@ -323,7 +325,7 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n             if size != alloc.size() || align != alloc.align {\n                 throw_ub_format!(\n                     \"incorrect layout on deallocation: {} has size {} and alignment {}, but gave size {} and alignment {}\",\n-                    ptr.alloc_id,\n+                    alloc_id,\n                     alloc.size().bytes(),\n                     alloc.align.bytes(),\n                     size.bytes(),\n@@ -337,60 +339,69 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n         M::memory_deallocated(&mut self.extra, &mut alloc.extra, ptr, size)?;\n \n         // Don't forget to remember size and align of this now-dead allocation\n-        let old = self.dead_alloc_map.insert(ptr.alloc_id, (size, alloc.align));\n+        let old = self.dead_alloc_map.insert(alloc_id, (size, alloc.align));\n         if old.is_some() {\n             bug!(\"Nothing can be deallocated twice\");\n         }\n \n         Ok(())\n     }\n \n-    /// Internal helper function for APIs that offer memory access based on `Scalar` pointers.\n+    /// Internal helper function to determine the allocation and offset of a pointer (if any).\n     #[inline(always)]\n-    pub(super) fn check_ptr_access(\n+    fn get_ptr_access(\n         &self,\n-        sptr: Scalar<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         size: Size,\n         align: Align,\n-    ) -> InterpResult<'tcx, Option<Pointer<M::PointerTag>>> {\n+    ) -> InterpResult<'tcx, Option<(AllocId, Size, Pointer<M::PointerTag>)>> {\n         let align = M::enforce_alignment(&self.extra).then_some(align);\n-        self.check_and_deref_ptr(sptr, size, align, CheckInAllocMsg::MemoryAccessTest, |ptr| {\n-            let (size, align) =\n-                self.get_size_and_align(ptr.alloc_id, AllocCheck::Dereferenceable)?;\n-            Ok((size, align, ptr))\n-        })\n+        self.check_and_deref_ptr(\n+            ptr,\n+            size,\n+            align,\n+            CheckInAllocMsg::MemoryAccessTest,\n+            |alloc_id, offset, ptr| {\n+                let (size, align) =\n+                    self.get_size_and_align(alloc_id, AllocCheck::Dereferenceable)?;\n+                Ok((size, align, (alloc_id, offset, ptr)))\n+            },\n+        )\n     }\n \n-    /// Check if the given scalar is allowed to do a memory access of given `size` and `align`\n+    /// Check if the given pointer is allowed to do a memory access of given `size` and `align`\n     /// (ignoring `M::enforce_alignment`). The caller can control the error message for the\n     /// out-of-bounds case.\n     #[inline(always)]\n     pub fn check_ptr_access_align(\n         &self,\n-        sptr: Scalar<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         size: Size,\n         align: Align,\n         msg: CheckInAllocMsg,\n     ) -> InterpResult<'tcx> {\n-        self.check_and_deref_ptr(sptr, size, Some(align), msg, |ptr| {\n-            let (size, align) =\n-                self.get_size_and_align(ptr.alloc_id, AllocCheck::Dereferenceable)?;\n+        self.check_and_deref_ptr(ptr, size, Some(align), msg, |alloc_id, _, _| {\n+            let (size, align) = self.get_size_and_align(alloc_id, AllocCheck::Dereferenceable)?;\n             Ok((size, align, ()))\n         })?;\n         Ok(())\n     }\n \n     /// Low-level helper function to check if a ptr is in-bounds and potentially return a reference\n-    /// to the allocation it points to. Supports both shared and mutable references, to the actual\n+    /// to the allocation it points to. Supports both shared and mutable references, as the actual\n     /// checking is offloaded to a helper closure. `align` defines whether and which alignment check\n     /// is done. Returns `None` for size 0, and otherwise `Some` of what `alloc_size` returned.\n     fn check_and_deref_ptr<T>(\n         &self,\n-        sptr: Scalar<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         size: Size,\n         align: Option<Align>,\n         msg: CheckInAllocMsg,\n-        alloc_size: impl FnOnce(Pointer<M::PointerTag>) -> InterpResult<'tcx, (Size, Align, T)>,\n+        alloc_size: impl FnOnce(\n+            AllocId,\n+            Size,\n+            Pointer<M::PointerTag>,\n+        ) -> InterpResult<'tcx, (Size, Align, T)>,\n     ) -> InterpResult<'tcx, Option<T>> {\n         fn check_offset_align(offset: u64, align: Align) -> InterpResult<'static> {\n             if offset % align.bytes() == 0 {\n@@ -405,53 +416,50 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n             }\n         }\n \n-        // Normalize to a `Pointer` if we definitely need one.\n-        let normalized = if size.bytes() == 0 {\n-            // Can be an integer, just take what we got.  We do NOT `force_bits` here;\n-            // if this is already a `Pointer` we want to do the bounds checks!\n-            sptr\n+        // Extract from the pointer an `Option<AllocId>` and an offset, which is relative to the\n+        // allocation or (if that is `None`) an absolute address.\n+        let ptr_or_addr = if size.bytes() == 0 {\n+            // Let's see what we can do, but don't throw errors if there's nothing there.\n+            self.ptr_try_get_alloc(ptr)\n         } else {\n-            // A \"real\" access, we must get a pointer to be able to check the bounds.\n-            Scalar::from(self.force_ptr(sptr)?)\n+            // A \"real\" access, we insist on getting an `AllocId`.\n+            Ok(self.ptr_force_alloc(ptr)?)\n         };\n-        Ok(match normalized.to_bits_or_ptr(self.pointer_size(), self) {\n-            Ok(bits) => {\n-                let bits = u64::try_from(bits).unwrap(); // it's ptr-sized\n-                assert!(size.bytes() == 0);\n+        Ok(match ptr_or_addr {\n+            Err(addr) => {\n+                // No memory is actually being accessed.\n+                debug_assert!(size.bytes() == 0);\n                 // Must be non-null.\n-                if bits == 0 {\n+                if addr == 0 {\n                     throw_ub!(DanglingIntPointer(0, msg))\n                 }\n                 // Must be aligned.\n                 if let Some(align) = align {\n-                    check_offset_align(bits, align)?;\n+                    check_offset_align(addr, align)?;\n                 }\n                 None\n             }\n-            Err(ptr) => {\n-                let (allocation_size, alloc_align, ret_val) = alloc_size(ptr)?;\n+            Ok((alloc_id, offset, ptr)) => {\n+                let (allocation_size, alloc_align, ret_val) = alloc_size(alloc_id, offset, ptr)?;\n                 // Test bounds. This also ensures non-null.\n-                // It is sufficient to check this for the end pointer. The addition\n-                // checks for overflow.\n-                let end_ptr = ptr.offset(size, self)?;\n-                if end_ptr.offset > allocation_size {\n-                    // equal is okay!\n-                    throw_ub!(PointerOutOfBounds { ptr: end_ptr.erase_tag(), msg, allocation_size })\n+                // It is sufficient to check this for the end pointer. Also check for overflow!\n+                if offset.checked_add(size, &self.tcx).map_or(true, |end| end > allocation_size) {\n+                    throw_ub!(PointerOutOfBounds { alloc_id, offset, size, allocation_size, msg })\n                 }\n                 // Test align. Check this last; if both bounds and alignment are violated\n                 // we want the error to be about the bounds.\n                 if let Some(align) = align {\n                     if M::force_int_for_alignment_check(&self.extra) {\n-                        let bits = self\n-                            .force_bits(ptr.into(), self.pointer_size())\n+                        let addr = Scalar::from(ptr)\n+                            .to_machine_usize(&self.tcx)\n                             .expect(\"ptr-to-int cast for align check should never fail\");\n-                        check_offset_align(bits.try_into().unwrap(), align)?;\n+                        check_offset_align(addr, align)?;\n                     } else {\n                         // Check allocation alignment and offset alignment.\n                         if alloc_align.bytes() < align.bytes() {\n                             throw_ub!(AlignmentCheckFailed { has: alloc_align, required: align });\n                         }\n-                        check_offset_align(ptr.offset.bytes(), align)?;\n+                        check_offset_align(offset.bytes(), align)?;\n                     }\n                 }\n \n@@ -463,13 +471,18 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n     }\n \n     /// Test if the pointer might be null.\n-    pub fn ptr_may_be_null(&self, ptr: Pointer<M::PointerTag>) -> bool {\n-        let (size, _align) = self\n-            .get_size_and_align(ptr.alloc_id, AllocCheck::MaybeDead)\n-            .expect(\"alloc info with MaybeDead cannot fail\");\n-        // If the pointer is out-of-bounds, it may be null.\n-        // Note that one-past-the-end (offset == size) is still inbounds, and never null.\n-        ptr.offset > size\n+    pub fn ptr_may_be_null(&self, ptr: Pointer<Option<M::PointerTag>>) -> bool {\n+        match self.ptr_try_get_alloc(ptr) {\n+            Ok((alloc_id, offset, _)) => {\n+                let (size, _align) = self\n+                    .get_size_and_align(alloc_id, AllocCheck::MaybeDead)\n+                    .expect(\"alloc info with MaybeDead cannot fail\");\n+                // If the pointer is out-of-bounds, it may be null.\n+                // Note that one-past-the-end (offset == size) is still inbounds, and never null.\n+                offset > size\n+            }\n+            Err(offset) => offset == 0,\n+        }\n     }\n }\n \n@@ -522,8 +535,8 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n             alloc,\n             M::GLOBAL_KIND.map(MemoryKind::Machine),\n         );\n-        // Sanity check that this is the same pointer we would have gotten via `global_base_pointer`.\n-        debug_assert_eq!(tag, M::tag_global_base_pointer(memory_extra, id));\n+        // Sanity check that this is the same tag we would have gotten via `global_base_pointer`.\n+        debug_assert!(tag == M::tag_global_base_pointer(memory_extra, id.into()).provenance);\n         Ok(alloc)\n     }\n \n@@ -566,30 +579,30 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n     /// \"Safe\" (bounds and align-checked) allocation access.\n     pub fn get<'a>(\n         &'a self,\n-        sptr: Scalar<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         size: Size,\n         align: Align,\n     ) -> InterpResult<'tcx, Option<AllocRef<'a, 'tcx, M::PointerTag, M::AllocExtra>>> {\n         let align = M::enforce_alignment(&self.extra).then_some(align);\n         let ptr_and_alloc = self.check_and_deref_ptr(\n-            sptr,\n+            ptr,\n             size,\n             align,\n             CheckInAllocMsg::MemoryAccessTest,\n-            |ptr| {\n-                let alloc = self.get_raw(ptr.alloc_id)?;\n-                Ok((alloc.size(), alloc.align, (ptr, alloc)))\n+            |alloc_id, offset, ptr| {\n+                let alloc = self.get_raw(alloc_id)?;\n+                Ok((alloc.size(), alloc.align, (alloc_id, offset, ptr, alloc)))\n             },\n         )?;\n-        if let Some((ptr, alloc)) = ptr_and_alloc {\n+        if let Some((alloc_id, offset, ptr, alloc)) = ptr_and_alloc {\n             M::memory_read(&self.extra, &alloc.extra, ptr, size)?;\n-            let range = alloc_range(ptr.offset, size);\n-            Ok(Some(AllocRef { alloc, range, tcx: self.tcx, alloc_id: ptr.alloc_id }))\n+            let range = alloc_range(offset, size);\n+            Ok(Some(AllocRef { alloc, range, tcx: self.tcx, alloc_id }))\n         } else {\n             // Even in this branch we have to be sure that we actually access the allocation, in\n             // order to ensure that `static FOO: Type = FOO;` causes a cycle error instead of\n             // magically pulling *any* ZST value from the ether. However, the `get_raw` above is\n-            // always called when `sptr` is truly a `Pointer`, so we are good.\n+            // always called when `ptr` has an `AllocId`.\n             Ok(None)\n         }\n     }\n@@ -638,19 +651,19 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n     /// \"Safe\" (bounds and align-checked) allocation access.\n     pub fn get_mut<'a>(\n         &'a mut self,\n-        sptr: Scalar<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         size: Size,\n         align: Align,\n     ) -> InterpResult<'tcx, Option<AllocRefMut<'a, 'tcx, M::PointerTag, M::AllocExtra>>> {\n-        let ptr = self.check_ptr_access(sptr, size, align)?;\n-        if let Some(ptr) = ptr {\n+        let parts = self.get_ptr_access(ptr, size, align)?;\n+        if let Some((alloc_id, offset, ptr)) = parts {\n             let tcx = self.tcx;\n             // FIXME: can we somehow avoid looking up the allocation twice here?\n             // We cannot call `get_raw_mut` inside `check_and_deref_ptr` as that would duplicate `&mut self`.\n-            let (alloc, extra) = self.get_raw_mut(ptr.alloc_id)?;\n+            let (alloc, extra) = self.get_raw_mut(alloc_id)?;\n             M::memory_written(extra, &mut alloc.extra, ptr, size)?;\n-            let range = alloc_range(ptr.offset, size);\n-            Ok(Some(AllocRefMut { alloc, range, tcx, alloc_id: ptr.alloc_id }))\n+            let range = alloc_range(offset, size);\n+            Ok(Some(AllocRefMut { alloc, range, tcx, alloc_id }))\n         } else {\n             Ok(None)\n         }\n@@ -740,14 +753,14 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n \n     pub fn get_fn(\n         &self,\n-        ptr: Scalar<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n     ) -> InterpResult<'tcx, FnVal<'tcx, M::ExtraFnVal>> {\n-        let ptr = self.force_ptr(ptr)?; // We definitely need a pointer value.\n-        if ptr.offset.bytes() != 0 {\n-            throw_ub!(InvalidFunctionPointer(ptr.erase_tag()))\n+        let (alloc_id, offset, ptr) = self.ptr_force_alloc(ptr)?;\n+        if offset.bytes() != 0 {\n+            throw_ub!(InvalidFunctionPointer(ptr.erase_for_fmt()))\n         }\n-        self.get_fn_alloc(ptr.alloc_id)\n-            .ok_or_else(|| err_ub!(InvalidFunctionPointer(ptr.erase_tag())).into())\n+        self.get_fn_alloc(alloc_id)\n+            .ok_or_else(|| err_ub!(InvalidFunctionPointer(ptr.erase_for_fmt())).into())\n     }\n \n     pub fn mark_immutable(&mut self, id: AllocId) -> InterpResult<'tcx> {\n@@ -786,7 +799,7 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n                 if reachable.insert(id) {\n                     // This is a new allocation, add its relocations to `todo`.\n                     if let Some((_, alloc)) = self.alloc_map.get(id) {\n-                        todo.extend(alloc.relocations().values().map(|&(_, target_id)| target_id));\n+                        todo.extend(alloc.relocations().values().map(|tag| tag.erase_for_fmt()));\n                     }\n                 }\n             }\n@@ -820,14 +833,14 @@ pub struct DumpAllocs<'a, 'mir, 'tcx, M: Machine<'mir, 'tcx>> {\n impl<'a, 'mir, 'tcx, M: Machine<'mir, 'tcx>> std::fmt::Debug for DumpAllocs<'a, 'mir, 'tcx, M> {\n     fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n         // Cannot be a closure because it is generic in `Tag`, `Extra`.\n-        fn write_allocation_track_relocs<'tcx, Tag: Copy + fmt::Debug, Extra>(\n+        fn write_allocation_track_relocs<'tcx, Tag: Provenance, Extra>(\n             fmt: &mut std::fmt::Formatter<'_>,\n             tcx: TyCtxt<'tcx>,\n             allocs_to_print: &mut VecDeque<AllocId>,\n             alloc: &Allocation<Tag, Extra>,\n         ) -> std::fmt::Result {\n-            for &(_, target_id) in alloc.relocations().values() {\n-                allocs_to_print.push_back(target_id);\n+            for alloc_id in alloc.relocations().values().map(|tag| tag.erase_for_fmt()) {\n+                allocs_to_print.push_back(alloc_id);\n             }\n             write!(fmt, \"{}\", pretty::display_allocation(tcx, alloc))\n         }\n@@ -930,8 +943,12 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n     /// Reads the given number of bytes from memory. Returns them as a slice.\n     ///\n     /// Performs appropriate bounds checks.\n-    pub fn read_bytes(&self, sptr: Scalar<M::PointerTag>, size: Size) -> InterpResult<'tcx, &[u8]> {\n-        let alloc_ref = match self.get(sptr, size, Align::ONE)? {\n+    pub fn read_bytes(\n+        &self,\n+        ptr: Pointer<Option<M::PointerTag>>,\n+        size: Size,\n+    ) -> InterpResult<'tcx, &[u8]> {\n+        let alloc_ref = match self.get(ptr, size, Align::ONE)? {\n             Some(a) => a,\n             None => return Ok(&[]), // zero-sized access\n         };\n@@ -948,7 +965,7 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n     /// Performs appropriate bounds checks.\n     pub fn write_bytes(\n         &mut self,\n-        sptr: Scalar<M::PointerTag>,\n+        ptr: Pointer<Option<M::PointerTag>>,\n         src: impl IntoIterator<Item = u8>,\n     ) -> InterpResult<'tcx> {\n         let mut src = src.into_iter();\n@@ -957,7 +974,7 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n         assert_eq!(lower, len, \"can only write iterators with a precise length\");\n \n         let size = Size::from_bytes(len);\n-        let alloc_ref = match self.get_mut(sptr, size, Align::ONE)? {\n+        let alloc_ref = match self.get_mut(ptr, size, Align::ONE)? {\n             Some(alloc_ref) => alloc_ref,\n             None => {\n                 // zero-sized access\n@@ -984,9 +1001,9 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n \n     pub fn copy(\n         &mut self,\n-        src: Scalar<M::PointerTag>,\n+        src: Pointer<Option<M::PointerTag>>,\n         src_align: Align,\n-        dest: Scalar<M::PointerTag>,\n+        dest: Pointer<Option<M::PointerTag>>,\n         dest_align: Align,\n         size: Size,\n         nonoverlapping: bool,\n@@ -996,32 +1013,32 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n \n     pub fn copy_repeatedly(\n         &mut self,\n-        src: Scalar<M::PointerTag>,\n+        src: Pointer<Option<M::PointerTag>>,\n         src_align: Align,\n-        dest: Scalar<M::PointerTag>,\n+        dest: Pointer<Option<M::PointerTag>>,\n         dest_align: Align,\n         size: Size,\n         num_copies: u64,\n         nonoverlapping: bool,\n     ) -> InterpResult<'tcx> {\n         let tcx = self.tcx;\n         // We need to do our own bounds-checks.\n-        let src = self.check_ptr_access(src, size, src_align)?;\n-        let dest = self.check_ptr_access(dest, size * num_copies, dest_align)?; // `Size` multiplication\n+        let src_parts = self.get_ptr_access(src, size, src_align)?;\n+        let dest_parts = self.get_ptr_access(dest, size * num_copies, dest_align)?; // `Size` multiplication\n \n         // FIXME: we look up both allocations twice here, once ebfore for the `check_ptr_access`\n         // and once below to get the underlying `&[mut] Allocation`.\n \n         // Source alloc preparations and access hooks.\n-        let src = match src {\n+        let (src_alloc_id, src_offset, src) = match src_parts {\n             None => return Ok(()), // Zero-sized *source*, that means dst is also zero-sized and we have nothing to do.\n             Some(src_ptr) => src_ptr,\n         };\n-        let src_alloc = self.get_raw(src.alloc_id)?;\n+        let src_alloc = self.get_raw(src_alloc_id)?;\n         M::memory_read(&self.extra, &src_alloc.extra, src, size)?;\n         // We need the `dest` ptr for the next operation, so we get it now.\n         // We already did the source checks and called the hooks so we are good to return early.\n-        let dest = match dest {\n+        let (dest_alloc_id, dest_offset, dest) = match dest_parts {\n             None => return Ok(()), // Zero-sized *destiantion*.\n             Some(dest_ptr) => dest_ptr,\n         };\n@@ -1033,23 +1050,23 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n         // relocations overlapping the edges; those would not be handled correctly).\n         let relocations = src_alloc.prepare_relocation_copy(\n             self,\n-            alloc_range(src.offset, size),\n-            dest.offset,\n+            alloc_range(src_offset, size),\n+            dest_offset,\n             num_copies,\n         );\n         // Prepare a copy of the initialization mask.\n-        let compressed = src_alloc.compress_uninit_range(alloc_range(src.offset, size));\n+        let compressed = src_alloc.compress_uninit_range(alloc_range(src_offset, size));\n         // This checks relocation edges on the src.\n         let src_bytes = src_alloc\n-            .get_bytes_with_uninit_and_ptr(&tcx, alloc_range(src.offset, size))\n-            .map_err(|e| e.to_interp_error(src.alloc_id))?\n+            .get_bytes_with_uninit_and_ptr(&tcx, alloc_range(src_offset, size))\n+            .map_err(|e| e.to_interp_error(src_alloc_id))?\n             .as_ptr(); // raw ptr, so we can also get a ptr to the destination allocation\n \n         // Destination alloc preparations and access hooks.\n-        let (dest_alloc, extra) = self.get_raw_mut(dest.alloc_id)?;\n+        let (dest_alloc, extra) = self.get_raw_mut(dest_alloc_id)?;\n         M::memory_written(extra, &mut dest_alloc.extra, dest, size * num_copies)?;\n         let dest_bytes = dest_alloc\n-            .get_bytes_mut_ptr(&tcx, alloc_range(dest.offset, size * num_copies))\n+            .get_bytes_mut_ptr(&tcx, alloc_range(dest_offset, size * num_copies))\n             .as_mut_ptr();\n \n         if compressed.no_bytes_init() {\n@@ -1059,7 +1076,7 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n             // This also avoids writing to the target bytes so that the backing allocation is never\n             // touched if the bytes stay uninitialized for the whole interpreter execution. On contemporary\n             // operating system this can avoid physically allocating the page.\n-            dest_alloc.mark_init(alloc_range(dest.offset, size * num_copies), false); // `Size` multiplication\n+            dest_alloc.mark_init(alloc_range(dest_offset, size * num_copies), false); // `Size` multiplication\n             dest_alloc.mark_relocation_range(relocations);\n             return Ok(());\n         }\n@@ -1070,11 +1087,11 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n         // The pointers above remain valid even if the `HashMap` table is moved around because they\n         // point into the `Vec` storing the bytes.\n         unsafe {\n-            if src.alloc_id == dest.alloc_id {\n+            if src_alloc_id == dest_alloc_id {\n                 if nonoverlapping {\n                     // `Size` additions\n-                    if (src.offset <= dest.offset && src.offset + size > dest.offset)\n-                        || (dest.offset <= src.offset && dest.offset + size > src.offset)\n+                    if (src_offset <= dest_offset && src_offset + size > dest_offset)\n+                        || (dest_offset <= src_offset && dest_offset + size > src_offset)\n                     {\n                         throw_ub_format!(\"copy_nonoverlapping called on overlapping ranges\")\n                     }\n@@ -1101,7 +1118,7 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n         // now fill in all the \"init\" data\n         dest_alloc.mark_compressed_init_range(\n             &compressed,\n-            alloc_range(dest.offset, size),\n+            alloc_range(dest_offset, size),\n             num_copies,\n         );\n         // copy the relocations to the destination\n@@ -1113,24 +1130,44 @@ impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n \n /// Machine pointer introspection.\n impl<'mir, 'tcx, M: Machine<'mir, 'tcx>> Memory<'mir, 'tcx, M> {\n-    pub fn force_ptr(\n-        &self,\n-        scalar: Scalar<M::PointerTag>,\n-    ) -> InterpResult<'tcx, Pointer<M::PointerTag>> {\n-        match scalar {\n-            Scalar::Ptr(ptr) => Ok(ptr),\n-            _ => M::int_to_ptr(&self, scalar.to_machine_usize(self)?),\n+    pub fn scalar_to_ptr(&self, scalar: Scalar<M::PointerTag>) -> Pointer<Option<M::PointerTag>> {\n+        match scalar.to_bits_or_ptr(self.pointer_size(), &self.tcx) {\n+            Err(ptr) => ptr.into(),\n+            Ok(bits) => {\n+                let addr = u64::try_from(bits).unwrap();\n+                M::ptr_from_addr(&self, addr)\n+            }\n         }\n     }\n \n-    pub fn force_bits(\n+    /// Internal helper for turning a \"maybe pointer\" into a proper pointer (and some information\n+    /// about where it points), or an absolute address.\n+    pub(super) fn ptr_try_get_alloc(\n         &self,\n-        scalar: Scalar<M::PointerTag>,\n-        size: Size,\n-    ) -> InterpResult<'tcx, u128> {\n-        match scalar.to_bits_or_ptr(size, self) {\n-            Ok(bits) => Ok(bits),\n-            Err(ptr) => Ok(M::ptr_to_int(&self, ptr)?.into()),\n+        ptr: Pointer<Option<M::PointerTag>>,\n+    ) -> Result<(AllocId, Size, Pointer<M::PointerTag>), u64> {\n+        match ptr.into_pointer_or_offset() {\n+            Ok(ptr) => {\n+                let (alloc_id, offset) = M::ptr_get_alloc(self, ptr);\n+                if let Some(alloc_id) = alloc_id {\n+                    Ok((alloc_id, offset, ptr))\n+                } else {\n+                    Err(offset.bytes())\n+                }\n+            }\n+            Err(offset) => Err(offset.bytes()),\n         }\n     }\n+\n+    /// Internal helper for turning a \"maybe pointer\" into a proper pointer (and some information\n+    /// about where it points).\n+    #[inline(always)]\n+    pub(super) fn ptr_force_alloc(\n+        &self,\n+        ptr: Pointer<Option<M::PointerTag>>,\n+    ) -> InterpResult<'tcx, (AllocId, Size, Pointer<M::PointerTag>)> {\n+        self.ptr_try_get_alloc(ptr).map_err(|offset| {\n+            err_ub!(DanglingIntPointer(offset, CheckInAllocMsg::InboundsTest)).into()\n+        })\n+    }\n }"}, {"sha": "db054d1f279cd0e1ece712ecc4c6a3f58eb59482", "filename": "compiler/rustc_mir/src/interpret/operand.rs", "status": "modified", "additions": 73, "deletions": 43, "changes": 116, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Foperand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Foperand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Foperand.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -15,8 +15,9 @@ use rustc_target::abi::{Abi, HasDataLayout, LayoutOf, Size, TagEncoding};\n use rustc_target::abi::{VariantIdx, Variants};\n \n use super::{\n-    alloc_range, from_known_layout, mir_assign_valid_types, ConstValue, GlobalId, InterpCx,\n-    InterpResult, MPlaceTy, Machine, MemPlace, Place, PlaceTy, Pointer, Scalar, ScalarMaybeUninit,\n+    alloc_range, from_known_layout, mir_assign_valid_types, AllocId, ConstValue, GlobalId,\n+    InterpCx, InterpResult, MPlaceTy, Machine, MemPlace, Place, PlaceTy, Pointer, Provenance,\n+    Scalar, ScalarMaybeUninit,\n };\n \n /// An `Immediate` represents a single immediate self-contained Rust value.\n@@ -26,14 +27,24 @@ use super::{\n /// operations and wide pointers. This idea was taken from rustc's codegen.\n /// In particular, thanks to `ScalarPair`, arithmetic operations and casts can be entirely\n /// defined on `Immediate`, and do not have to work with a `Place`.\n-#[derive(Copy, Clone, Debug, PartialEq, Eq, HashStable, Hash)]\n-pub enum Immediate<Tag = ()> {\n+#[derive(Copy, Clone, PartialEq, Eq, HashStable, Hash)]\n+pub enum Immediate<Tag = AllocId> {\n     Scalar(ScalarMaybeUninit<Tag>),\n     ScalarPair(ScalarMaybeUninit<Tag>, ScalarMaybeUninit<Tag>),\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(Immediate, 56);\n+//FIXME rustc_data_structures::static_assert_size!(Immediate, 56);\n+\n+impl<Tag: Provenance> std::fmt::Debug for Immediate<Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        use Immediate::*;\n+        match self {\n+            Scalar(s) => f.debug_tuple(\"Scalar\").field(s).finish(),\n+            ScalarPair(s1, s2) => f.debug_tuple(\"ScalarPair\").field(s1).field(s2).finish(),\n+        }\n+    }\n+}\n \n impl<Tag> From<ScalarMaybeUninit<Tag>> for Immediate<Tag> {\n     #[inline(always)]\n@@ -81,26 +92,33 @@ impl<'tcx, Tag> Immediate<Tag> {\n \n // ScalarPair needs a type to interpret, so we often have an immediate and a type together\n // as input for binary and cast operations.\n-#[derive(Copy, Clone, Debug)]\n-pub struct ImmTy<'tcx, Tag = ()> {\n+#[derive(Copy, Clone)]\n+pub struct ImmTy<'tcx, Tag = AllocId> {\n     imm: Immediate<Tag>,\n     pub layout: TyAndLayout<'tcx>,\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(ImmTy<'_>, 72);\n+//FIXME rustc_data_structures::static_assert_size!(ImmTy<'_>, 72);\n+\n+impl<'tcx, Tag: Provenance> std::fmt::Debug for ImmTy<'tcx, Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        let ImmTy { imm, layout } = self;\n+        f.debug_struct(\"ImmTy\").field(\"imm\", imm).field(\"layout\", layout).finish()\n+    }\n+}\n \n-impl<Tag: Copy> std::fmt::Display for ImmTy<'tcx, Tag> {\n+impl<Tag: Provenance> std::fmt::Display for ImmTy<'tcx, Tag> {\n     fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n         /// Helper function for printing a scalar to a FmtPrinter\n-        fn p<'a, 'tcx, F: std::fmt::Write, Tag>(\n+        fn p<'a, 'tcx, F: std::fmt::Write, Tag: Provenance>(\n             cx: FmtPrinter<'a, 'tcx, F>,\n             s: ScalarMaybeUninit<Tag>,\n             ty: Ty<'tcx>,\n         ) -> Result<FmtPrinter<'a, 'tcx, F>, std::fmt::Error> {\n             match s {\n                 ScalarMaybeUninit::Scalar(s) => {\n-                    cx.pretty_print_const_scalar(s.erase_tag(), ty, true)\n+                    cx.pretty_print_const_scalar(s.erase_for_fmt(), ty, true)\n                 }\n                 ScalarMaybeUninit::Uninit => cx.typed_value(\n                     |mut this| {\n@@ -120,11 +138,11 @@ impl<Tag: Copy> std::fmt::Display for ImmTy<'tcx, Tag> {\n                         p(cx, s, ty)?;\n                         return Ok(());\n                     }\n-                    write!(f, \"{}: {}\", s.erase_tag(), self.layout.ty)\n+                    write!(f, \"{}: {}\", s.erase_for_fmt(), self.layout.ty)\n                 }\n                 Immediate::ScalarPair(a, b) => {\n                     // FIXME(oli-obk): at least print tuples and slices nicely\n-                    write!(f, \"({}, {}): {}\", a.erase_tag(), b.erase_tag(), self.layout.ty,)\n+                    write!(f, \"({}, {}): {}\", a.erase_for_fmt(), b.erase_for_fmt(), self.layout.ty,)\n                 }\n             }\n         })\n@@ -142,21 +160,38 @@ impl<'tcx, Tag> std::ops::Deref for ImmTy<'tcx, Tag> {\n /// An `Operand` is the result of computing a `mir::Operand`. It can be immediate,\n /// or still in memory. The latter is an optimization, to delay reading that chunk of\n /// memory and to avoid having to store arbitrary-sized data here.\n-#[derive(Copy, Clone, Debug, PartialEq, Eq, HashStable, Hash)]\n-pub enum Operand<Tag = ()> {\n+#[derive(Copy, Clone, PartialEq, Eq, HashStable, Hash)]\n+pub enum Operand<Tag = AllocId> {\n     Immediate(Immediate<Tag>),\n     Indirect(MemPlace<Tag>),\n }\n \n-#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\n-pub struct OpTy<'tcx, Tag = ()> {\n+impl<Tag: Provenance> std::fmt::Debug for Operand<Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        use Operand::*;\n+        match self {\n+            Immediate(i) => f.debug_tuple(\"Immediate\").field(i).finish(),\n+            Indirect(p) => f.debug_tuple(\"Indirect\").field(p).finish(),\n+        }\n+    }\n+}\n+\n+#[derive(Copy, Clone, PartialEq, Eq, Hash)]\n+pub struct OpTy<'tcx, Tag = AllocId> {\n     op: Operand<Tag>, // Keep this private; it helps enforce invariants.\n     pub layout: TyAndLayout<'tcx>,\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n rustc_data_structures::static_assert_size!(OpTy<'_, ()>, 80);\n \n+impl<'tcx, Tag: Provenance> std::fmt::Debug for OpTy<'tcx, Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        let OpTy { op, layout } = self;\n+        f.debug_struct(\"OpTy\").field(\"op\", op).field(\"layout\", layout).finish()\n+    }\n+}\n+\n impl<'tcx, Tag> std::ops::Deref for OpTy<'tcx, Tag> {\n     type Target = Operand<Tag>;\n     #[inline(always)]\n@@ -225,19 +260,6 @@ impl<'tcx, Tag: Copy> ImmTy<'tcx, Tag> {\n }\n \n impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n-    /// Normalize `place.ptr` to a `Pointer` if this is a place and not a ZST.\n-    /// Can be helpful to avoid lots of `force_ptr` calls later, if this place is used a lot.\n-    #[inline]\n-    pub fn force_op_ptr(\n-        &self,\n-        op: &OpTy<'tcx, M::PointerTag>,\n-    ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n-        match op.try_as_mplace(self) {\n-            Ok(mplace) => Ok(self.force_mplace_ptr(mplace)?.into()),\n-            Err(imm) => Ok(imm.into()), // Nothing to cast/force\n-        }\n-    }\n-\n     /// Try reading an immediate in memory; this is interesting particularly for `ScalarPair`.\n     /// Returns `None` if the layout does not permit loading this as a value.\n     fn try_read_immediate_from_mplace(\n@@ -291,7 +313,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         &self,\n         src: &OpTy<'tcx, M::PointerTag>,\n     ) -> InterpResult<'tcx, Result<ImmTy<'tcx, M::PointerTag>, MPlaceTy<'tcx, M::PointerTag>>> {\n-        Ok(match src.try_as_mplace(self) {\n+        Ok(match src.try_as_mplace() {\n             Ok(ref mplace) => {\n                 if let Some(val) = self.try_read_immediate_from_mplace(mplace)? {\n                     Ok(val)\n@@ -324,6 +346,14 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         Ok(self.read_immediate(op)?.to_scalar_or_uninit())\n     }\n \n+    /// Read a pointer from a place.\n+    pub fn read_pointer(\n+        &self,\n+        op: &OpTy<'tcx, M::PointerTag>,\n+    ) -> InterpResult<'tcx, Pointer<Option<M::PointerTag>>> {\n+        Ok(self.scalar_to_ptr(self.read_scalar(op)?.check_init()?))\n+    }\n+\n     // Turn the wide MPlace into a string (must already be dereferenced!)\n     pub fn read_str(&self, mplace: &MPlaceTy<'tcx, M::PointerTag>) -> InterpResult<'tcx, &str> {\n         let len = mplace.len(self)?;\n@@ -338,7 +368,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         op: &OpTy<'tcx, M::PointerTag>,\n         field: usize,\n     ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n-        let base = match op.try_as_mplace(self) {\n+        let base = match op.try_as_mplace() {\n             Ok(ref mplace) => {\n                 // We can reuse the mplace field computation logic for indirect operands.\n                 let field = self.mplace_field(mplace, field)?;\n@@ -381,7 +411,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             self.operand_field(op, index)\n         } else {\n             // Indexing into a big array. This must be an mplace.\n-            let mplace = op.assert_mem_place(self);\n+            let mplace = op.assert_mem_place();\n             Ok(self.mplace_index(&mplace, index)?.into())\n         }\n     }\n@@ -392,7 +422,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         variant: VariantIdx,\n     ) -> InterpResult<'tcx, OpTy<'tcx, M::PointerTag>> {\n         // Downcasts only change the layout\n-        Ok(match op.try_as_mplace(self) {\n+        Ok(match op.try_as_mplace() {\n             Ok(ref mplace) => self.mplace_downcast(mplace, variant)?.into(),\n             Err(..) => {\n                 let layout = op.layout.for_variant(self, variant);\n@@ -414,7 +444,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             Subslice { .. } | ConstantIndex { .. } | Index(_) => {\n                 // The rest should only occur as mplace, we do not use Immediates for types\n                 // allowing such operations.  This matches place_projection forcing an allocation.\n-                let mplace = base.assert_mem_place(self);\n+                let mplace = base.assert_mem_place();\n                 self.mplace_projection(&mplace, proj_elem)?.into()\n             }\n         })\n@@ -580,9 +610,9 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 // We rely on mutability being set correctly in that allocation to prevent writes\n                 // where none should happen.\n                 let ptr = self.global_base_pointer(Pointer::new(id, offset))?;\n-                Operand::Indirect(MemPlace::from_ptr(ptr, layout.align.abi))\n+                Operand::Indirect(MemPlace::from_ptr(ptr.into(), layout.align.abi))\n             }\n-            ConstValue::Scalar(x) => Operand::Immediate(tag_scalar(x)?.into()),\n+            ConstValue::Scalar(x) => Operand::Immediate(tag_scalar(x.into())?.into()),\n             ConstValue::Slice { data, start, end } => {\n                 // We rely on mutability being set correctly in `data` to prevent writes\n                 // where none should happen.\n@@ -658,9 +688,9 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         // Figure out which discriminant and variant this corresponds to.\n         Ok(match *tag_encoding {\n             TagEncoding::Direct => {\n-                let tag_bits = self\n-                    .force_bits(tag_val, tag_layout.size)\n-                    .map_err(|_| err_ub!(InvalidTag(tag_val.erase_tag())))?;\n+                let tag_bits = tag_val\n+                    .to_bits(tag_layout.size)\n+                    .map_err(|_| err_ub!(InvalidTag(tag_val.erase_for_fmt())))?;\n                 // Cast bits from tag layout to discriminant layout.\n                 let discr_val = self.cast_from_scalar(tag_bits, tag_layout, discr_layout.ty);\n                 let discr_bits = discr_val.assert_bits(discr_layout.size);\n@@ -677,7 +707,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                     }\n                     _ => span_bug!(self.cur_span(), \"tagged layout for non-adt non-generator\"),\n                 }\n-                .ok_or_else(|| err_ub!(InvalidTag(tag_val.erase_tag())))?;\n+                .ok_or_else(|| err_ub!(InvalidTag(tag_val.erase_for_fmt())))?;\n                 // Return the cast value, and the index.\n                 (discr_val, index.0)\n             }\n@@ -691,9 +721,9 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                         // The niche must be just 0 (which an inbounds pointer value never is)\n                         let ptr_valid = niche_start == 0\n                             && variants_start == variants_end\n-                            && !self.memory.ptr_may_be_null(ptr);\n+                            && !self.memory.ptr_may_be_null(ptr.into());\n                         if !ptr_valid {\n-                            throw_ub!(InvalidTag(tag_val.erase_tag()))\n+                            throw_ub!(InvalidTag(tag_val.erase_for_fmt()))\n                         }\n                         dataful_variant\n                     }"}, {"sha": "79b493d74e19b47006653f8bbd6fb0ccad7012e0", "filename": "compiler/rustc_mir/src/interpret/operator.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Foperator.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Foperator.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Foperator.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -318,8 +318,8 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                     right.layout.ty\n                 );\n \n-                let l = self.force_bits(left.to_scalar()?, left.layout.size)?;\n-                let r = self.force_bits(right.to_scalar()?, right.layout.size)?;\n+                let l = left.to_scalar()?.to_bits(left.layout.size)?;\n+                let r = right.to_scalar()?.to_bits(right.layout.size)?;\n                 self.binary_int_op(bin_op, l, left.layout, r, right.layout)\n             }\n             _ if left.layout.ty.is_any_ptr() => {\n@@ -386,7 +386,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             }\n             _ => {\n                 assert!(layout.ty.is_integral());\n-                let val = self.force_bits(val, layout.size)?;\n+                let val = val.to_bits(layout.size)?;\n                 let (res, overflow) = match un_op {\n                     Not => (self.truncate(!val, layout), false), // bitwise negation, then truncate\n                     Neg => {"}, {"sha": "b5d26306d4be3d1e2db704bed72f01a7aa6736f2", "filename": "compiler/rustc_mir/src/interpret/place.rs", "status": "modified", "additions": 130, "deletions": 111, "changes": 241, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fplace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fplace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fplace.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -3,7 +3,6 @@\n //! All high-level functions to write to memory work on places as destinations.\n \n use std::convert::TryFrom;\n-use std::fmt::Debug;\n use std::hash::Hash;\n \n use rustc_ast::Mutability;\n@@ -15,14 +14,14 @@ use rustc_target::abi::{Abi, Align, FieldsShape, TagEncoding};\n use rustc_target::abi::{HasDataLayout, LayoutOf, Size, VariantIdx, Variants};\n \n use super::{\n-    alloc_range, mir_assign_valid_types, AllocRef, AllocRefMut, ConstAlloc, ImmTy, Immediate,\n-    InterpCx, InterpResult, LocalValue, Machine, MemoryKind, OpTy, Operand, Pointer,\n-    PointerArithmetic, Scalar, ScalarMaybeUninit,\n+    alloc_range, mir_assign_valid_types, AllocId, AllocRef, AllocRefMut, CheckInAllocMsg,\n+    ConstAlloc, ImmTy, Immediate, InterpCx, InterpResult, LocalValue, Machine, MemoryKind, OpTy,\n+    Operand, Pointer, PointerArithmetic, Provenance, Scalar, ScalarMaybeUninit,\n };\n \n-#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, HashStable)]\n+#[derive(Copy, Clone, Hash, PartialEq, Eq, HashStable)]\n /// Information required for the sound usage of a `MemPlace`.\n-pub enum MemPlaceMeta<Tag = ()> {\n+pub enum MemPlaceMeta<Tag = AllocId> {\n     /// The unsized payload (e.g. length for slices or vtable pointer for trait objects).\n     Meta(Scalar<Tag>),\n     /// `Sized` types or unsized `extern type`\n@@ -35,7 +34,18 @@ pub enum MemPlaceMeta<Tag = ()> {\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(MemPlaceMeta, 24);\n+//FIXME rustc_data_structures::static_assert_size!(MemPlaceMeta, 24);\n+\n+impl<Tag: Provenance> std::fmt::Debug for MemPlaceMeta<Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        use MemPlaceMeta::*;\n+        match self {\n+            Meta(s) => f.debug_tuple(\"Meta\").field(s).finish(),\n+            None => f.debug_tuple(\"None\").finish(),\n+            Poison => f.debug_tuple(\"Poison\").finish(),\n+        }\n+    }\n+}\n \n impl<Tag> MemPlaceMeta<Tag> {\n     pub fn unwrap_meta(self) -> Scalar<Tag> {\n@@ -53,21 +63,22 @@ impl<Tag> MemPlaceMeta<Tag> {\n         }\n     }\n \n-    pub fn erase_tag(self) -> MemPlaceMeta<()> {\n+    pub fn erase_for_fmt(self) -> MemPlaceMeta\n+    where\n+        Tag: Provenance,\n+    {\n         match self {\n-            Self::Meta(s) => MemPlaceMeta::Meta(s.erase_tag()),\n+            Self::Meta(s) => MemPlaceMeta::Meta(s.erase_for_fmt()),\n             Self::None => MemPlaceMeta::None,\n             Self::Poison => MemPlaceMeta::Poison,\n         }\n     }\n }\n \n-#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, HashStable)]\n-pub struct MemPlace<Tag = ()> {\n-    /// A place may have an integral pointer for ZSTs, and since it might\n-    /// be turned back into a reference before ever being dereferenced.\n-    /// However, it may never be uninit.\n-    pub ptr: Scalar<Tag>,\n+#[derive(Copy, Clone, Hash, PartialEq, Eq, HashStable)]\n+pub struct MemPlace<Tag = AllocId> {\n+    /// The pointer can be a pure integer, with the `None` tag.\n+    pub ptr: Pointer<Option<Tag>>,\n     pub align: Align,\n     /// Metadata for unsized places. Interpretation is up to the type.\n     /// Must not be present for sized types, but can be missing for unsized types\n@@ -76,10 +87,21 @@ pub struct MemPlace<Tag = ()> {\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(MemPlace, 56);\n+//FIXME rustc_data_structures::static_assert_size!(MemPlace, 56);\n+\n+impl<Tag: Provenance> std::fmt::Debug for MemPlace<Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        let MemPlace { ptr, align, meta } = self;\n+        f.debug_struct(\"MemPlace\")\n+            .field(\"ptr\", ptr)\n+            .field(\"align\", align)\n+            .field(\"meta\", meta)\n+            .finish()\n+    }\n+}\n \n-#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, HashStable)]\n-pub enum Place<Tag = ()> {\n+#[derive(Copy, Clone, Hash, PartialEq, Eq, HashStable)]\n+pub enum Place<Tag = AllocId> {\n     /// A place referring to a value allocated in the `Memory` system.\n     Ptr(MemPlace<Tag>),\n \n@@ -89,16 +111,35 @@ pub enum Place<Tag = ()> {\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(Place, 64);\n+//FIXME rustc_data_structures::static_assert_size!(Place, 64);\n+\n+impl<Tag: Provenance> std::fmt::Debug for Place<Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        use Place::*;\n+        match self {\n+            Ptr(p) => f.debug_tuple(\"Ptr\").field(p).finish(),\n+            Local { frame, local } => {\n+                f.debug_struct(\"Local\").field(\"frame\", frame).field(\"local\", local).finish()\n+            }\n+        }\n+    }\n+}\n \n-#[derive(Copy, Clone, Debug)]\n-pub struct PlaceTy<'tcx, Tag = ()> {\n+#[derive(Copy, Clone)]\n+pub struct PlaceTy<'tcx, Tag = AllocId> {\n     place: Place<Tag>, // Keep this private; it helps enforce invariants.\n     pub layout: TyAndLayout<'tcx>,\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(PlaceTy<'_>, 80);\n+//FIXME rustc_data_structures::static_assert_size!(PlaceTy<'_>, 80);\n+\n+impl<'tcx, Tag: Provenance> std::fmt::Debug for PlaceTy<'tcx, Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        let PlaceTy { place, layout } = self;\n+        f.debug_struct(\"PlaceTy\").field(\"place\", place).field(\"layout\", layout).finish()\n+    }\n+}\n \n impl<'tcx, Tag> std::ops::Deref for PlaceTy<'tcx, Tag> {\n     type Target = Place<Tag>;\n@@ -109,14 +150,21 @@ impl<'tcx, Tag> std::ops::Deref for PlaceTy<'tcx, Tag> {\n }\n \n /// A MemPlace with its layout. Constructing it is only possible in this module.\n-#[derive(Copy, Clone, Debug, Hash, Eq, PartialEq)]\n-pub struct MPlaceTy<'tcx, Tag = ()> {\n+#[derive(Copy, Clone, Hash, Eq, PartialEq)]\n+pub struct MPlaceTy<'tcx, Tag = AllocId> {\n     mplace: MemPlace<Tag>,\n     pub layout: TyAndLayout<'tcx>,\n }\n \n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(MPlaceTy<'_>, 72);\n+//FIXME rustc_data_structures::static_assert_size!(MPlaceTy<'_>, 72);\n+\n+impl<'tcx, Tag: Provenance> std::fmt::Debug for MPlaceTy<'tcx, Tag> {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        let MPlaceTy { mplace, layout } = self;\n+        f.debug_struct(\"MPlaceTy\").field(\"mplace\", mplace).field(\"layout\", layout).finish()\n+    }\n+}\n \n impl<'tcx, Tag> std::ops::Deref for MPlaceTy<'tcx, Tag> {\n     type Target = MemPlace<Tag>;\n@@ -134,34 +182,32 @@ impl<'tcx, Tag> From<MPlaceTy<'tcx, Tag>> for PlaceTy<'tcx, Tag> {\n }\n \n impl<Tag> MemPlace<Tag> {\n-    /// Replace ptr tag, maintain vtable tag (if any)\n-    #[inline]\n-    pub fn replace_tag(self, new_tag: Tag) -> Self {\n-        MemPlace { ptr: self.ptr.erase_tag().with_tag(new_tag), align: self.align, meta: self.meta }\n-    }\n-\n     #[inline]\n-    pub fn erase_tag(self) -> MemPlace {\n-        MemPlace { ptr: self.ptr.erase_tag(), align: self.align, meta: self.meta.erase_tag() }\n+    pub fn erase_for_fmt(self) -> MemPlace\n+    where\n+        Tag: Provenance,\n+    {\n+        MemPlace {\n+            ptr: self.ptr.map_erase_for_fmt(),\n+            align: self.align,\n+            meta: self.meta.erase_for_fmt(),\n+        }\n     }\n \n     #[inline(always)]\n-    fn from_scalar_ptr(ptr: Scalar<Tag>, align: Align) -> Self {\n+    pub fn from_ptr(ptr: Pointer<Option<Tag>>, align: Align) -> Self {\n         MemPlace { ptr, align, meta: MemPlaceMeta::None }\n     }\n \n-    #[inline(always)]\n-    pub fn from_ptr(ptr: Pointer<Tag>, align: Align) -> Self {\n-        Self::from_scalar_ptr(ptr.into(), align)\n-    }\n-\n     /// Turn a mplace into a (thin or wide) pointer, as a reference, pointing to the same space.\n     /// This is the inverse of `ref_to_mplace`.\n     #[inline(always)]\n-    pub fn to_ref(self) -> Immediate<Tag> {\n+    pub fn to_ref(self, cx: &impl HasDataLayout) -> Immediate<Tag> {\n         match self.meta {\n-            MemPlaceMeta::None => Immediate::Scalar(self.ptr.into()),\n-            MemPlaceMeta::Meta(meta) => Immediate::ScalarPair(self.ptr.into(), meta.into()),\n+            MemPlaceMeta::None => Immediate::from(Scalar::from_maybe_pointer(self.ptr, cx)),\n+            MemPlaceMeta::Meta(meta) => {\n+                Immediate::ScalarPair(Scalar::from_maybe_pointer(self.ptr, cx).into(), meta.into())\n+            }\n             MemPlaceMeta::Poison => bug!(\n                 \"MPlaceTy::dangling may never be used to produce a \\\n                 place that will have the address of its pointee taken\"\n@@ -177,7 +223,7 @@ impl<Tag> MemPlace<Tag> {\n         cx: &impl HasDataLayout,\n     ) -> InterpResult<'tcx, Self> {\n         Ok(MemPlace {\n-            ptr: self.ptr.ptr_offset(offset, cx)?,\n+            ptr: self.ptr.offset(offset, cx)?,\n             align: self.align.restrict_for_offset(offset),\n             meta,\n         })\n@@ -187,19 +233,13 @@ impl<Tag> MemPlace<Tag> {\n impl<'tcx, Tag: Copy> MPlaceTy<'tcx, Tag> {\n     /// Produces a MemPlace that works for ZST but nothing else\n     #[inline]\n-    pub fn dangling(layout: TyAndLayout<'tcx>, cx: &impl HasDataLayout) -> Self {\n+    pub fn dangling(layout: TyAndLayout<'tcx>) -> Self {\n         let align = layout.align.abi;\n-        let ptr = Scalar::from_machine_usize(align.bytes(), cx);\n+        let ptr = Pointer::new(None, Size::from_bytes(align.bytes())); // no provenance, absolute address\n         // `Poison` this to make sure that the pointer value `ptr` is never observable by the program.\n         MPlaceTy { mplace: MemPlace { ptr, align, meta: MemPlaceMeta::Poison }, layout }\n     }\n \n-    /// Replace ptr tag, maintain vtable tag (if any)\n-    #[inline]\n-    pub fn replace_tag(&self, new_tag: Tag) -> Self {\n-        MPlaceTy { mplace: self.mplace.replace_tag(new_tag), layout: self.layout }\n-    }\n-\n     #[inline]\n     pub fn offset(\n         &self,\n@@ -212,12 +252,15 @@ impl<'tcx, Tag: Copy> MPlaceTy<'tcx, Tag> {\n     }\n \n     #[inline]\n-    fn from_aligned_ptr(ptr: Pointer<Tag>, layout: TyAndLayout<'tcx>) -> Self {\n+    fn from_aligned_ptr(ptr: Pointer<Option<Tag>>, layout: TyAndLayout<'tcx>) -> Self {\n         MPlaceTy { mplace: MemPlace::from_ptr(ptr, layout.align.abi), layout }\n     }\n \n     #[inline]\n-    pub(super) fn len(&self, cx: &impl HasDataLayout) -> InterpResult<'tcx, u64> {\n+    pub(super) fn len(&self, cx: &impl HasDataLayout) -> InterpResult<'tcx, u64>\n+    where\n+        Tag: Provenance,\n+    {\n         if self.layout.is_unsized() {\n             // We need to consult `meta` metadata\n             match self.layout.ty.kind() {\n@@ -244,32 +287,30 @@ impl<'tcx, Tag: Copy> MPlaceTy<'tcx, Tag> {\n }\n \n // These are defined here because they produce a place.\n-impl<'tcx, Tag: Debug + Copy> OpTy<'tcx, Tag> {\n+impl<'tcx, Tag: Copy> OpTy<'tcx, Tag> {\n     #[inline(always)]\n     /// Note: do not call `as_ref` on the resulting place. This function should only be used to\n     /// read from the resulting mplace, not to get its address back.\n-    pub fn try_as_mplace(\n-        &self,\n-        cx: &impl HasDataLayout,\n-    ) -> Result<MPlaceTy<'tcx, Tag>, ImmTy<'tcx, Tag>> {\n+    pub fn try_as_mplace(&self) -> Result<MPlaceTy<'tcx, Tag>, ImmTy<'tcx, Tag>> {\n         match **self {\n             Operand::Indirect(mplace) => Ok(MPlaceTy { mplace, layout: self.layout }),\n-            Operand::Immediate(_) if self.layout.is_zst() => {\n-                Ok(MPlaceTy::dangling(self.layout, cx))\n-            }\n+            Operand::Immediate(_) if self.layout.is_zst() => Ok(MPlaceTy::dangling(self.layout)),\n             Operand::Immediate(imm) => Err(ImmTy::from_immediate(imm, self.layout)),\n         }\n     }\n \n     #[inline(always)]\n     /// Note: do not call `as_ref` on the resulting place. This function should only be used to\n     /// read from the resulting mplace, not to get its address back.\n-    pub fn assert_mem_place(&self, cx: &impl HasDataLayout) -> MPlaceTy<'tcx, Tag> {\n-        self.try_as_mplace(cx).unwrap()\n+    pub fn assert_mem_place(&self) -> MPlaceTy<'tcx, Tag>\n+    where\n+        Tag: Provenance,\n+    {\n+        self.try_as_mplace().unwrap()\n     }\n }\n \n-impl<Tag: Debug> Place<Tag> {\n+impl<Tag: Provenance> Place<Tag> {\n     #[inline]\n     pub fn assert_mem_place(self) -> MemPlace<Tag> {\n         match self {\n@@ -279,7 +320,7 @@ impl<Tag: Debug> Place<Tag> {\n     }\n }\n \n-impl<'tcx, Tag: Debug> PlaceTy<'tcx, Tag> {\n+impl<'tcx, Tag: Provenance> PlaceTy<'tcx, Tag> {\n     #[inline]\n     pub fn assert_mem_place(self) -> MPlaceTy<'tcx, Tag> {\n         MPlaceTy { mplace: self.place.assert_mem_place(), layout: self.layout }\n@@ -290,7 +331,7 @@ impl<'tcx, Tag: Debug> PlaceTy<'tcx, Tag> {\n impl<'mir, 'tcx: 'mir, Tag, M> InterpCx<'mir, 'tcx, M>\n where\n     // FIXME: Working around https://github.com/rust-lang/rust/issues/54385\n-    Tag: Debug + Copy + Eq + Hash + 'static,\n+    Tag: Provenance + Eq + Hash + 'static,\n     M: Machine<'mir, 'tcx, PointerTag = Tag>,\n {\n     /// Take a value, which represents a (thin or wide) reference, and make it a place.\n@@ -307,14 +348,12 @@ where\n             val.layout.ty.builtin_deref(true).expect(\"`ref_to_mplace` called on non-ptr type\").ty;\n         let layout = self.layout_of(pointee_type)?;\n         let (ptr, meta) = match **val {\n-            Immediate::Scalar(ptr) => (ptr.check_init()?, MemPlaceMeta::None),\n-            Immediate::ScalarPair(ptr, meta) => {\n-                (ptr.check_init()?, MemPlaceMeta::Meta(meta.check_init()?))\n-            }\n+            Immediate::Scalar(ptr) => (ptr, MemPlaceMeta::None),\n+            Immediate::ScalarPair(ptr, meta) => (ptr, MemPlaceMeta::Meta(meta.check_init()?)),\n         };\n \n         let mplace = MemPlace {\n-            ptr,\n+            ptr: self.scalar_to_ptr(ptr.check_init()?),\n             // We could use the run-time alignment here. For now, we do not, because\n             // the point of tracking the alignment here is to make sure that the *static*\n             // alignment information emitted with the loads is correct. The run-time\n@@ -333,8 +372,9 @@ where\n     ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n         let val = self.read_immediate(src)?;\n         trace!(\"deref to {} on {:?}\", val.layout.ty, *val);\n-        let place = self.ref_to_mplace(&val)?;\n-        self.mplace_access_checked(place, None)\n+        let mplace = self.ref_to_mplace(&val)?;\n+        self.check_mplace_access(mplace)?;\n+        Ok(mplace)\n     }\n \n     #[inline]\n@@ -359,38 +399,20 @@ where\n         self.memory.get_mut(place.ptr, size, place.align)\n     }\n \n-    /// Return the \"access-checked\" version of this `MPlace`, where for non-ZST\n-    /// this is definitely a `Pointer`.\n-    ///\n-    /// `force_align` must only be used when correct alignment does not matter,\n-    /// like in Stacked Borrows.\n-    pub fn mplace_access_checked(\n-        &self,\n-        mut place: MPlaceTy<'tcx, M::PointerTag>,\n-        force_align: Option<Align>,\n-    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n+    /// Check if this mplace is dereferencable and sufficiently aligned.\n+    pub fn check_mplace_access(&self, mplace: MPlaceTy<'tcx, M::PointerTag>) -> InterpResult<'tcx> {\n         let (size, align) = self\n-            .size_and_align_of_mplace(&place)?\n-            .unwrap_or((place.layout.size, place.layout.align.abi));\n-        assert!(place.mplace.align <= align, \"dynamic alignment less strict than static one?\");\n-        let align = force_align.unwrap_or(align);\n-        // Record new (stricter, unless forced) alignment requirement in place.\n-        place.mplace.align = align;\n-        // When dereferencing a pointer, it must be non-null, aligned, and live.\n-        if let Some(ptr) = self.memory.check_ptr_access(place.ptr, size, align)? {\n-            place.mplace.ptr = ptr.into();\n-        }\n-        Ok(place)\n-    }\n-\n-    /// Force `place.ptr` to a `Pointer`.\n-    /// Can be helpful to avoid lots of `force_ptr` calls later, if this place is used a lot.\n-    pub(super) fn force_mplace_ptr(\n-        &self,\n-        mut place: MPlaceTy<'tcx, M::PointerTag>,\n-    ) -> InterpResult<'tcx, MPlaceTy<'tcx, M::PointerTag>> {\n-        place.mplace.ptr = self.force_ptr(place.mplace.ptr)?.into();\n-        Ok(place)\n+            .size_and_align_of_mplace(&mplace)?\n+            .unwrap_or((mplace.layout.size, mplace.layout.align.abi));\n+        assert!(mplace.mplace.align <= align, \"dynamic alignment less strict than static one?\");\n+        let align = M::enforce_alignment(&self.memory.extra).then_some(align);\n+        self.memory.check_ptr_access_align(\n+            mplace.ptr,\n+            size,\n+            align.unwrap_or(Align::ONE),\n+            CheckInAllocMsg::MemoryAccessTest, // FIXME sth more specific?\n+        )?;\n+        Ok(())\n     }\n \n     /// Offset a pointer to project to a field of a struct/union. Unlike `place_field`, this is\n@@ -558,10 +580,7 @@ where\n                 let layout = self.layout_of(self.tcx.types.usize)?;\n                 let n = self.access_local(self.frame(), local, Some(layout))?;\n                 let n = self.read_scalar(&n)?;\n-                let n = u64::try_from(\n-                    self.force_bits(n.check_init()?, self.tcx.data_layout.pointer_size)?,\n-                )\n-                .unwrap();\n+                let n = n.to_machine_usize(self)?;\n                 self.mplace_index(base, n)?\n             }\n \n@@ -1020,7 +1039,7 @@ where\n         kind: MemoryKind<M::MemoryKind>,\n     ) -> InterpResult<'static, MPlaceTy<'tcx, M::PointerTag>> {\n         let ptr = self.memory.allocate(layout.size, layout.align.abi, kind)?;\n-        Ok(MPlaceTy::from_aligned_ptr(ptr, layout))\n+        Ok(MPlaceTy::from_aligned_ptr(ptr.into(), layout))\n     }\n \n     /// Returns a wide MPlace of type `&'static [mut] str` to a new 1-aligned allocation.\n@@ -1125,7 +1144,7 @@ where\n         let _ = self.tcx.global_alloc(raw.alloc_id);\n         let ptr = self.global_base_pointer(Pointer::from(raw.alloc_id))?;\n         let layout = self.layout_of(raw.ty)?;\n-        Ok(MPlaceTy::from_aligned_ptr(ptr, layout))\n+        Ok(MPlaceTy::from_aligned_ptr(ptr.into(), layout))\n     }\n \n     /// Turn a place with a `dyn Trait` type into a place with the actual dynamic type.\n@@ -1134,7 +1153,7 @@ where\n         &self,\n         mplace: &MPlaceTy<'tcx, M::PointerTag>,\n     ) -> InterpResult<'tcx, (ty::Instance<'tcx>, MPlaceTy<'tcx, M::PointerTag>)> {\n-        let vtable = mplace.vtable(); // also sanity checks the type\n+        let vtable = self.scalar_to_ptr(mplace.vtable()); // also sanity checks the type\n         let (instance, ty) = self.read_drop_type_from_vtable(vtable)?;\n         let layout = self.layout_of(ty)?;\n "}, {"sha": "2fbcfcfbe9087d4baed8acde7ac74daf32b86c11", "filename": "compiler/rustc_mir/src/interpret/step.rs", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fstep.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fstep.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fstep.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -240,7 +240,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                     // of the first element.\n                     let elem_size = first.layout.size;\n                     let first_ptr = first.ptr;\n-                    let rest_ptr = first_ptr.ptr_offset(elem_size, self)?;\n+                    let rest_ptr = first_ptr.offset(elem_size, self)?;\n                     self.memory.copy_repeatedly(\n                         first_ptr,\n                         first.align,\n@@ -264,11 +264,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             AddressOf(_, place) | Ref(_, _, place) => {\n                 let src = self.eval_place(place)?;\n                 let place = self.force_allocation(&src)?;\n-                if place.layout.size.bytes() > 0 {\n-                    // definitely not a ZST\n-                    assert!(place.ptr.is_ptr(), \"non-ZST places should be normalized to `Pointer`\");\n-                }\n-                self.write_immediate(place.to_ref(), &dest)?;\n+                self.write_immediate(place.to_ref(self), &dest)?;\n             }\n \n             NullaryOp(mir::NullOp::Box, _) => {"}, {"sha": "f369480d959fede95e17d9e7bc4c77271f8fb1a8", "filename": "compiler/rustc_mir/src/interpret/terminator.rs", "status": "modified", "additions": 12, "deletions": 10, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fterminator.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fterminator.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fterminator.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -12,8 +12,8 @@ use rustc_target::abi::{self, LayoutOf as _};\n use rustc_target::spec::abi::Abi;\n \n use super::{\n-    FnVal, ImmTy, InterpCx, InterpResult, MPlaceTy, Machine, OpTy, PlaceTy, StackPopCleanup,\n-    StackPopUnwind,\n+    FnVal, ImmTy, InterpCx, InterpResult, MPlaceTy, Machine, OpTy, PlaceTy, Scalar,\n+    StackPopCleanup, StackPopUnwind,\n };\n \n impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n@@ -72,8 +72,8 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 let (fn_val, abi, caller_can_unwind) = match *func.layout.ty.kind() {\n                     ty::FnPtr(sig) => {\n                         let caller_abi = sig.abi();\n-                        let fn_ptr = self.read_scalar(&func)?.check_init()?;\n-                        let fn_val = self.memory.get_fn(fn_ptr)?;\n+                        let fn_ptr = self.read_pointer(&func)?;\n+                        let fn_val = self.memory.get_fn(fn_ptr.into())?;\n                         (\n                             fn_val,\n                             caller_abi,\n@@ -454,11 +454,11 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                     }\n                     None => {\n                         // Unsized self.\n-                        args[0].assert_mem_place(self)\n+                        args[0].assert_mem_place()\n                     }\n                 };\n                 // Find and consult vtable\n-                let vtable = receiver_place.vtable();\n+                let vtable = self.scalar_to_ptr(receiver_place.vtable());\n                 let fn_val = self.get_vtable_slot(vtable, u64::try_from(idx).unwrap())?;\n \n                 // `*mut receiver_place.layout.ty` is almost the layout that we\n@@ -468,8 +468,10 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n                 let receiver_ptr_ty = self.tcx.mk_mut_ptr(receiver_place.layout.ty);\n                 let this_receiver_ptr = self.layout_of(receiver_ptr_ty)?.field(self, 0)?;\n                 // Adjust receiver argument.\n-                args[0] =\n-                    OpTy::from(ImmTy::from_immediate(receiver_place.ptr.into(), this_receiver_ptr));\n+                args[0] = OpTy::from(ImmTy::from_immediate(\n+                    Scalar::from_maybe_pointer(receiver_place.ptr, self).into(),\n+                    this_receiver_ptr,\n+                ));\n                 trace!(\"Patched self operand to {:#?}\", args[0]);\n                 // recurse with concrete function\n                 self.eval_fn_call(fn_val, caller_abi, &args, ret, unwind)\n@@ -499,12 +501,12 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         };\n \n         let arg = ImmTy::from_immediate(\n-            place.to_ref(),\n+            place.to_ref(self),\n             self.layout_of(self.tcx.mk_mut_ptr(place.layout.ty))?,\n         );\n \n         let ty = self.tcx.mk_unit(); // return type is ()\n-        let dest = MPlaceTy::dangling(self.layout_of(ty)?, self);\n+        let dest = MPlaceTy::dangling(self.layout_of(ty)?);\n \n         self.eval_fn_call(\n             FnVal::Instance(instance),"}, {"sha": "7a93fcee78e3389a60ff1b8ee360215ab8a03052", "filename": "compiler/rustc_mir/src/interpret/traits.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Ftraits.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Ftraits.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Ftraits.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -1,6 +1,6 @@\n use std::convert::TryFrom;\n \n-use rustc_middle::mir::interpret::{InterpResult, Pointer, PointerArithmetic, Scalar};\n+use rustc_middle::mir::interpret::{InterpResult, Pointer, PointerArithmetic};\n use rustc_middle::ty::{\n     self, Ty, COMMON_VTABLE_ENTRIES, COMMON_VTABLE_ENTRIES_ALIGN,\n     COMMON_VTABLE_ENTRIES_DROPINPLACE, COMMON_VTABLE_ENTRIES_SIZE,\n@@ -42,23 +42,23 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n     /// corresponds to the first method declared in the trait of the provided vtable.\n     pub fn get_vtable_slot(\n         &self,\n-        vtable: Scalar<M::PointerTag>,\n+        vtable: Pointer<Option<M::PointerTag>>,\n         idx: u64,\n     ) -> InterpResult<'tcx, FnVal<'tcx, M::ExtraFnVal>> {\n         let ptr_size = self.pointer_size();\n-        let vtable_slot = vtable.ptr_offset(ptr_size * idx, self)?;\n+        let vtable_slot = vtable.offset(ptr_size * idx, self)?;\n         let vtable_slot = self\n             .memory\n             .get(vtable_slot, ptr_size, self.tcx.data_layout.pointer_align.abi)?\n             .expect(\"cannot be a ZST\");\n-        let fn_ptr = vtable_slot.read_ptr_sized(Size::ZERO)?.check_init()?;\n+        let fn_ptr = self.scalar_to_ptr(vtable_slot.read_ptr_sized(Size::ZERO)?.check_init()?);\n         self.memory.get_fn(fn_ptr)\n     }\n \n     /// Returns the drop fn instance as well as the actual dynamic type.\n     pub fn read_drop_type_from_vtable(\n         &self,\n-        vtable: Scalar<M::PointerTag>,\n+        vtable: Pointer<Option<M::PointerTag>>,\n     ) -> InterpResult<'tcx, (ty::Instance<'tcx>, Ty<'tcx>)> {\n         let pointer_size = self.pointer_size();\n         // We don't care about the pointee type; we just want a pointer.\n@@ -77,7 +77,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n             .check_init()?;\n         // We *need* an instance here, no other kind of function value, to be able\n         // to determine the type.\n-        let drop_instance = self.memory.get_fn(drop_fn)?.as_instance()?;\n+        let drop_instance = self.memory.get_fn(self.scalar_to_ptr(drop_fn))?.as_instance()?;\n         trace!(\"Found drop fn: {:?}\", drop_instance);\n         let fn_sig = drop_instance.ty(*self.tcx, self.param_env).fn_sig(*self.tcx);\n         let fn_sig = self.tcx.normalize_erasing_late_bound_regions(self.param_env, fn_sig);\n@@ -93,7 +93,7 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n \n     pub fn read_size_and_align_from_vtable(\n         &self,\n-        vtable: Scalar<M::PointerTag>,\n+        vtable: Pointer<Option<M::PointerTag>>,\n     ) -> InterpResult<'tcx, (Size, Align)> {\n         let pointer_size = self.pointer_size();\n         // We check for `size = 3 * ptr_size`, which covers the drop fn (unused here),\n@@ -109,11 +109,11 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         let size = vtable\n             .read_ptr_sized(pointer_size * u64::try_from(COMMON_VTABLE_ENTRIES_SIZE).unwrap())?\n             .check_init()?;\n-        let size = u64::try_from(self.force_bits(size, pointer_size)?).unwrap();\n+        let size = size.to_machine_usize(self)?;\n         let align = vtable\n             .read_ptr_sized(pointer_size * u64::try_from(COMMON_VTABLE_ENTRIES_ALIGN).unwrap())?\n             .check_init()?;\n-        let align = u64::try_from(self.force_bits(align, pointer_size)?).unwrap();\n+        let align = align.to_machine_usize(self)?;\n         let align = Align::from_bytes(align).map_err(|e| err_ub!(InvalidVtableAlignment(e)))?;\n \n         if size >= self.tcx.data_layout.obj_size_bound() {"}, {"sha": "703c7480248246c810281ad671aadc04c8c483ff", "filename": "compiler/rustc_mir/src/interpret/validity.rs", "status": "modified", "additions": 8, "deletions": 18, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fvalidity.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fvalidity.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fvalidity.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -21,7 +21,7 @@ use std::hash::Hash;\n \n use super::{\n     alloc_range, CheckInAllocMsg, GlobalAlloc, InterpCx, InterpResult, MPlaceTy, Machine,\n-    MemPlaceMeta, OpTy, Scalar, ScalarMaybeUninit, ValueVisitor,\n+    MemPlaceMeta, OpTy, ScalarMaybeUninit, ValueVisitor,\n };\n \n macro_rules! throw_validation_failure {\n@@ -324,7 +324,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValidityVisitor<'rt, 'mir, '\n         let tail = self.ecx.tcx.struct_tail_erasing_lifetimes(pointee.ty, self.ecx.param_env);\n         match tail.kind() {\n             ty::Dynamic(..) => {\n-                let vtable = meta.unwrap_meta();\n+                let vtable = self.ecx.scalar_to_ptr(meta.unwrap_meta());\n                 // Direct call to `check_ptr_access_align` checks alignment even on CTFE machines.\n                 try_validation!(\n                     self.ecx.memory.check_ptr_access_align(\n@@ -448,17 +448,10 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValidityVisitor<'rt, 'mir, '\n         if let Some(ref mut ref_tracking) = self.ref_tracking {\n             // Proceed recursively even for ZST, no reason to skip them!\n             // `!` is a ZST and we want to validate it.\n-            // Normalize before handing `place` to tracking because that will\n-            // check for duplicates.\n-            let place = if size.bytes() > 0 {\n-                self.ecx.force_mplace_ptr(place).expect(\"we already bounds-checked\")\n-            } else {\n-                place\n-            };\n             // Skip validation entirely for some external statics\n-            if let Scalar::Ptr(ptr) = place.ptr {\n+            if let Ok((alloc_id, _offset, _ptr)) = self.ecx.memory.ptr_try_get_alloc(place.ptr) {\n                 // not a ZST\n-                let alloc_kind = self.ecx.tcx.get_global_alloc(ptr.alloc_id);\n+                let alloc_kind = self.ecx.tcx.get_global_alloc(alloc_id);\n                 if let Some(GlobalAlloc::Static(did)) = alloc_kind {\n                     assert!(!self.ecx.tcx.is_thread_local_static(did));\n                     assert!(self.ecx.tcx.is_static(did));\n@@ -601,7 +594,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValidityVisitor<'rt, 'mir, '\n                 // message below.\n                 let value = value.to_scalar_or_uninit();\n                 let _fn = try_validation!(\n-                    value.check_init().and_then(|ptr| self.ecx.memory.get_fn(ptr)),\n+                    value.check_init().and_then(|ptr| self.ecx.memory.get_fn(self.ecx.scalar_to_ptr(ptr))),\n                     self.path,\n                     err_ub!(DanglingIntPointer(..)) |\n                     err_ub!(InvalidFunctionPointer(..)) |\n@@ -668,7 +661,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValidityVisitor<'rt, 'mir, '\n             Err(ptr) => {\n                 if lo == 1 && hi == max_hi {\n                     // Only null is the niche.  So make sure the ptr is NOT null.\n-                    if self.ecx.memory.ptr_may_be_null(ptr) {\n+                    if self.ecx.memory.ptr_may_be_null(ptr.into()) {\n                         throw_validation_failure!(self.path,\n                             { \"a potentially null pointer\" }\n                             expected {\n@@ -832,7 +825,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValueVisitor<'mir, 'tcx, M>\n     ) -> InterpResult<'tcx> {\n         match op.layout.ty.kind() {\n             ty::Str => {\n-                let mplace = op.assert_mem_place(self.ecx); // strings are never immediate\n+                let mplace = op.assert_mem_place(); // strings are never immediate\n                 let len = mplace.len(self.ecx)?;\n                 try_validation!(\n                     self.ecx.memory.read_bytes(mplace.ptr, Size::from_bytes(len)),\n@@ -853,7 +846,7 @@ impl<'rt, 'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> ValueVisitor<'mir, 'tcx, M>\n                 // Optimized handling for arrays of integer/float type.\n \n                 // Arrays cannot be immediate, slices are never immediate.\n-                let mplace = op.assert_mem_place(self.ecx);\n+                let mplace = op.assert_mem_place();\n                 // This is the length of the array/slice.\n                 let len = mplace.len(self.ecx)?;\n                 // This is the element type size.\n@@ -940,9 +933,6 @@ impl<'mir, 'tcx: 'mir, M: Machine<'mir, 'tcx>> InterpCx<'mir, 'tcx, M> {\n         // Construct a visitor\n         let mut visitor = ValidityVisitor { path, ref_tracking, ctfe_mode, ecx: self };\n \n-        // Try to cast to ptr *once* instead of all the time.\n-        let op = self.force_op_ptr(&op).unwrap_or(*op);\n-\n         // Run it.\n         match visitor.visit_value(&op) {\n             Ok(()) => Ok(()),"}, {"sha": "679d30227f1366cb4e89b1b25ad9e923a6efc268", "filename": "compiler/rustc_mir/src/interpret/visitor.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fvisitor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fvisitor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Finterpret%2Fvisitor.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -211,7 +211,8 @@ macro_rules! make_value_visitor {\n                     // If it is a trait object, switch to the real type that was used to create it.\n                     ty::Dynamic(..) => {\n                         // immediate trait objects are not a thing\n-                        let dest = v.to_op(self.ecx())?.assert_mem_place(self.ecx());\n+                        let op = v.to_op(self.ecx())?;\n+                        let dest = op.assert_mem_place();\n                         let inner = self.ecx().unpack_dyn_trait(&dest)?.1;\n                         trace!(\"walk_value: dyn object layout: {:#?}\", inner.layout);\n                         // recurse with the inner type\n@@ -241,7 +242,8 @@ macro_rules! make_value_visitor {\n                     },\n                     FieldsShape::Array { .. } => {\n                         // Let's get an mplace first.\n-                        let mplace = v.to_op(self.ecx())?.assert_mem_place(self.ecx());\n+                        let op = v.to_op(self.ecx())?;\n+                        let mplace = op.assert_mem_place();\n                         // Now we can go over all the fields.\n                         // This uses the *run-time length*, i.e., if we are a slice,\n                         // the dynamic info from the metadata is used."}, {"sha": "548518a85e6fe2d3e8a9f66e71e5e387393d91af", "filename": "compiler/rustc_mir/src/monomorphize/collector.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fmonomorphize%2Fcollector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Fmonomorphize%2Fcollector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Fmonomorphize%2Fcollector.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -403,7 +403,7 @@ fn collect_items_rec<'tcx>(\n             recursion_depth_reset = None;\n \n             if let Ok(alloc) = tcx.eval_static_initializer(def_id) {\n-                for &((), id) in alloc.relocations().values() {\n+                for &id in alloc.relocations().values() {\n                     collect_miri(tcx, id, &mut neighbors);\n                 }\n             }\n@@ -1369,7 +1369,7 @@ fn collect_miri<'tcx>(\n         }\n         GlobalAlloc::Memory(alloc) => {\n             trace!(\"collecting {:?} with {:#?}\", alloc_id, alloc);\n-            for &((), inner) in alloc.relocations().values() {\n+            for &inner in alloc.relocations().values() {\n                 rustc_data_structures::stack::ensure_sufficient_stack(|| {\n                     collect_miri(tcx, inner, output);\n                 });\n@@ -1402,9 +1402,9 @@ fn collect_const_value<'tcx>(\n     output: &mut Vec<Spanned<MonoItem<'tcx>>>,\n ) {\n     match value {\n-        ConstValue::Scalar(Scalar::Ptr(ptr)) => collect_miri(tcx, ptr.alloc_id, output),\n+        ConstValue::Scalar(Scalar::Ptr(ptr)) => collect_miri(tcx, ptr.provenance, output),\n         ConstValue::Slice { data: alloc, start: _, end: _ } | ConstValue::ByRef { alloc, .. } => {\n-            for &((), id) in alloc.relocations().values() {\n+            for &id in alloc.relocations().values() {\n                 collect_miri(tcx, id, output);\n             }\n         }"}, {"sha": "bbf3a1c669f3ad621f4f60b70580c88bc6b6bdf0", "filename": "compiler/rustc_mir/src/transform/const_prop.rs", "status": "modified", "additions": 4, "deletions": 10, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Ftransform%2Fconst_prop.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Ftransform%2Fconst_prop.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Ftransform%2Fconst_prop.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -31,9 +31,8 @@ use rustc_trait_selection::traits;\n use crate::const_eval::ConstEvalErr;\n use crate::interpret::{\n     self, compile_time_machine, AllocId, Allocation, ConstValue, CtfeValidationMode, Frame, ImmTy,\n-    Immediate, InterpCx, InterpResult, LocalState, LocalValue, MemPlace, Memory, MemoryKind, OpTy,\n-    Operand as InterpOperand, PlaceTy, Pointer, Scalar, ScalarMaybeUninit, StackPopCleanup,\n-    StackPopUnwind,\n+    Immediate, InterpCx, InterpResult, LocalState, LocalValue, MemPlace, MemoryKind, OpTy,\n+    Operand as InterpOperand, PlaceTy, Scalar, ScalarMaybeUninit, StackPopCleanup, StackPopUnwind,\n };\n use crate::transform::MirPass;\n \n@@ -157,7 +156,7 @@ impl<'tcx> MirPass<'tcx> for ConstProp {\n \n struct ConstPropMachine<'mir, 'tcx> {\n     /// The virtual call stack.\n-    stack: Vec<Frame<'mir, 'tcx, (), ()>>,\n+    stack: Vec<Frame<'mir, 'tcx>>,\n     /// `OnlyInsideOwnBlock` locals that were written in the current block get erased at the end.\n     written_only_inside_own_block_locals: FxHashSet<Local>,\n     /// Locals that need to be cleared after every block terminates.\n@@ -223,10 +222,6 @@ impl<'mir, 'tcx> interpret::Machine<'mir, 'tcx> for ConstPropMachine<'mir, 'tcx>\n         bug!(\"panics terminators are not evaluated in ConstProp\")\n     }\n \n-    fn ptr_to_int(_mem: &Memory<'mir, 'tcx, Self>, _ptr: Pointer) -> InterpResult<'tcx, u64> {\n-        throw_unsup!(ReadPointerAsBytes)\n-    }\n-\n     fn binary_ptr_op(\n         _ecx: &InterpCx<'mir, 'tcx, Self>,\n         _bin_op: BinOp,\n@@ -759,8 +754,7 @@ impl<'mir, 'tcx> ConstPropagator<'mir, 'tcx> {\n                         }\n                     };\n \n-                    let arg_value =\n-                        this.ecx.force_bits(const_arg.to_scalar()?, const_arg.layout.size)?;\n+                    let arg_value = const_arg.to_scalar()?.to_bits(const_arg.layout.size)?;\n                     let dest = this.ecx.eval_place(place)?;\n \n                     match op {"}, {"sha": "0380218ec57f17e69ebf17f02c4e420f3beba1d3", "filename": "compiler/rustc_mir/src/transform/simplify_comparison_integral.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Ftransform%2Fsimplify_comparison_integral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Ftransform%2Fsimplify_comparison_integral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Ftransform%2Fsimplify_comparison_integral.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -211,7 +211,7 @@ fn find_branch_value_info<'tcx>(\n                 return None;\n             };\n             let branch_value_scalar = branch_value.literal.try_to_scalar()?;\n-            Some((branch_value_scalar, branch_value_ty, *to_switch_on))\n+            Some((branch_value_scalar.into(), branch_value_ty, *to_switch_on))\n         }\n         _ => None,\n     }"}, {"sha": "f31e2feac31183e0b99151b6882b6979b94afa59", "filename": "compiler/rustc_mir/src/util/pretty.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Futil%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d4f7dd670226a4235ea4cf900c14eb9c6a536843/compiler%2Frustc_mir%2Fsrc%2Futil%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir%2Fsrc%2Futil%2Fpretty.rs?ref=d4f7dd670226a4235ea4cf900c14eb9c6a536843", "patch": "@@ -1,6 +1,6 @@\n use std::collections::BTreeSet;\n+use std::fmt::Display;\n use std::fmt::Write as _;\n-use std::fmt::{Debug, Display};\n use std::fs;\n use std::io::{self, Write};\n use std::path::{Path, PathBuf};\n@@ -13,7 +13,7 @@ use rustc_data_structures::fx::FxHashMap;\n use rustc_hir::def_id::DefId;\n use rustc_index::vec::Idx;\n use rustc_middle::mir::interpret::{\n-    read_target_uint, AllocId, Allocation, ConstValue, GlobalAlloc, Pointer,\n+    read_target_uint, AllocId, Allocation, ConstValue, GlobalAlloc, Pointer, Provenance,\n };\n use rustc_middle::mir::visit::Visitor;\n use rustc_middle::mir::*;\n@@ -665,12 +665,12 @@ pub fn write_allocations<'tcx>(\n     w: &mut dyn Write,\n ) -> io::Result<()> {\n     fn alloc_ids_from_alloc(alloc: &Allocation) -> impl DoubleEndedIterator<Item = AllocId> + '_ {\n-        alloc.relocations().values().map(|(_, id)| *id)\n+        alloc.relocations().values().map(|id| *id)\n     }\n     fn alloc_ids_from_const(val: ConstValue<'_>) -> impl Iterator<Item = AllocId> + '_ {\n         match val {\n             ConstValue::Scalar(interpret::Scalar::Ptr(ptr)) => {\n-                Either::Left(Either::Left(std::iter::once(ptr.alloc_id)))\n+                Either::Left(Either::Left(std::iter::once(ptr.provenance)))\n             }\n             ConstValue::Scalar(interpret::Scalar::Int { .. }) => {\n                 Either::Left(Either::Right(std::iter::empty()))\n@@ -755,7 +755,7 @@ pub fn write_allocations<'tcx>(\n /// After the hex dump, an ascii dump follows, replacing all unprintable characters (control\n /// characters or characters whose value is larger than 127) with a `.`\n /// This also prints relocations adequately.\n-pub fn display_allocation<Tag: Copy + Debug, Extra>(\n+pub fn display_allocation<Tag, Extra>(\n     tcx: TyCtxt<'tcx>,\n     alloc: &'a Allocation<Tag, Extra>,\n ) -> RenderAllocation<'a, 'tcx, Tag, Extra> {\n@@ -768,7 +768,7 @@ pub struct RenderAllocation<'a, 'tcx, Tag, Extra> {\n     alloc: &'a Allocation<Tag, Extra>,\n }\n \n-impl<Tag: Copy + Debug, Extra> std::fmt::Display for RenderAllocation<'a, 'tcx, Tag, Extra> {\n+impl<Tag: Provenance, Extra> std::fmt::Display for RenderAllocation<'a, 'tcx, Tag, Extra> {\n     fn fmt(&self, w: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n         let RenderAllocation { tcx, alloc } = *self;\n         write!(w, \"size: {}, align: {})\", alloc.size().bytes(), alloc.align.bytes())?;\n@@ -811,7 +811,7 @@ fn write_allocation_newline(\n /// The `prefix` argument allows callers to add an arbitrary prefix before each line (even if there\n /// is only one line). Note that your prefix should contain a trailing space as the lines are\n /// printed directly after it.\n-fn write_allocation_bytes<Tag: Copy + Debug, Extra>(\n+fn write_allocation_bytes<Tag: Provenance, Extra>(\n     tcx: TyCtxt<'tcx>,\n     alloc: &Allocation<Tag, Extra>,\n     w: &mut dyn std::fmt::Write,\n@@ -847,15 +847,15 @@ fn write_allocation_bytes<Tag: Copy + Debug, Extra>(\n         if i != line_start {\n             write!(w, \" \")?;\n         }\n-        if let Some(&(tag, target_id)) = alloc.relocations().get(&i) {\n+        if let Some(&tag) = alloc.relocations().get(&i) {\n             // Memory with a relocation must be defined\n             let j = i.bytes_usize();\n             let offset = alloc\n                 .inspect_with_uninit_and_ptr_outside_interpreter(j..j + ptr_size.bytes_usize());\n             let offset = read_target_uint(tcx.data_layout.endian, offset).unwrap();\n             let offset = Size::from_bytes(offset);\n             let relocation_width = |bytes| bytes * 3;\n-            let ptr = Pointer::new_with_tag(target_id, offset, tag);\n+            let ptr = Pointer::new(tag, offset);\n             let mut target = format!(\"{:?}\", ptr);\n             if target.len() > relocation_width(ptr_size.bytes_usize() - 1) {\n                 // This is too long, try to save some space."}]}