{"sha": "f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY1ZjI0YTlhMmMyZTlkNWQ1ZmYxNTVlNzAwYjJiZjY0N2Y5MjZkNDc=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-05-24T19:52:01Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-05-24T19:52:01Z"}, "message": "Merge #8977\n\n8977: internal: minor `TokenMap` cleanups r=jonas-schievink a=jonas-schievink\n\nbors r+\n\nCo-authored-by: Jonas Schievink <jonasschievink@gmail.com>", "tree": {"sha": "273c8086766a31f0ff5df2a89cbe670828e887db", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/273c8086766a31f0ff5df2a89cbe670828e887db"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJgrAPhCRBK7hj4Ov3rIwAAvOEIADegr8+yX5M7KwEPv5uQ3v1c\n5kATFkqzIiv/kMIbjbHHGwzh/fNHWZzAs/zorEAHJ1jv2+d23tHLTM2SEcPjuO9A\njvZebtaQOumlJE9m+oNS6nbXeri+FUWvSs4pyfIxYTFxDZ89LRCTvGWZRsig6R5N\nNiyQ1L+wtDju3zexV2M6cfZjnu19On/m8i1GYS4xEFipeF829TB8tgMRWt/nOTdP\np5SZA73IUHgDahvW05pCTwAnzilt0yTl1FoFMcMnxqqpyq0BM4VisGwVGhQxVxbI\nTtKOU96SgVoU9ZsIqXf3hqMMdkd9HJzWuS1ApTPZcZjJJes0F5qBQrqTW9DaAQY=\n=DE17\n-----END PGP SIGNATURE-----\n", "payload": "tree 273c8086766a31f0ff5df2a89cbe670828e887db\nparent 1ebb53e5db32e32c00e4ce0ceba4277b53967056\nparent c8f40b1503cb461b935f5fb0a44fa8e26976c363\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1621885921 +0000\ncommitter GitHub <noreply@github.com> 1621885921 +0000\n\nMerge #8977\n\n8977: internal: minor `TokenMap` cleanups r=jonas-schievink a=jonas-schievink\n\nbors r+\n\nCo-authored-by: Jonas Schievink <jonasschievink@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "html_url": "https://github.com/rust-lang/rust/commit/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1ebb53e5db32e32c00e4ce0ceba4277b53967056", "url": "https://api.github.com/repos/rust-lang/rust/commits/1ebb53e5db32e32c00e4ce0ceba4277b53967056", "html_url": "https://github.com/rust-lang/rust/commit/1ebb53e5db32e32c00e4ce0ceba4277b53967056"}, {"sha": "c8f40b1503cb461b935f5fb0a44fa8e26976c363", "url": "https://api.github.com/repos/rust-lang/rust/commits/c8f40b1503cb461b935f5fb0a44fa8e26976c363", "html_url": "https://github.com/rust-lang/rust/commit/c8f40b1503cb461b935f5fb0a44fa8e26976c363"}], "stats": {"total": 191, "additions": 101, "deletions": 90}, "files": [{"sha": "625c26f0a09a88ee6d2ea647bdb3567df85fad29", "filename": "crates/hir_expand/src/db.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fdb.rs?ref=f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "patch": "@@ -155,7 +155,7 @@ pub fn expand_speculative(\n         mbe::token_tree_to_syntax_node(&speculative_expansion.value, fragment_kind).ok()?;\n \n     let token_id = macro_def.map_id_down(token_id);\n-    let range = tmap_2.range_by_token(token_id)?.by_kind(token_to_map.kind())?;\n+    let range = tmap_2.range_by_token(token_id, token_to_map.kind())?;\n     let token = node.syntax_node().covering_element(range).into_token()?;\n     Some((node.syntax_node(), token))\n }"}, {"sha": "d98913907ada12f5203674ce3de3b487137fb35e", "filename": "crates/hir_expand/src/hygiene.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs?ref=f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "patch": "@@ -154,7 +154,7 @@ impl HygieneInfo {\n             },\n         };\n \n-        let range = token_map.range_by_token(token_id)?.by_kind(SyntaxKind::IDENT)?;\n+        let range = token_map.range_by_token(token_id, SyntaxKind::IDENT)?;\n         Some((tt.with_value(range + tt.value), origin))\n     }\n }"}, {"sha": "6be4516a327dfb57ed0b95d99eb5adf897bbaa02", "filename": "crates/hir_expand/src/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fhir_expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fhir_expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Flib.rs?ref=f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "patch": "@@ -329,7 +329,7 @@ impl ExpansionInfo {\n         let token_id = self.macro_arg.1.token_by_range(range)?;\n         let token_id = self.macro_def.map_id_down(token_id);\n \n-        let range = self.exp_map.range_by_token(token_id)?.by_kind(token.value.kind())?;\n+        let range = self.exp_map.range_by_token(token_id, token.value.kind())?;\n \n         let token = self.expanded.value.covering_element(range).into_token()?;\n \n@@ -354,7 +354,7 @@ impl ExpansionInfo {\n             },\n         };\n \n-        let range = token_map.range_by_token(token_id)?.by_kind(token.value.kind())?;\n+        let range = token_map.range_by_token(token_id, token.value.kind())?;\n         let token =\n             tt.value.covering_element(range + tt.value.text_range().start()).into_token()?;\n         Some((tt.with_value(token), origin))"}, {"sha": "b95374b76dbfe7dfc35b2ce9c715be6d97866efe", "filename": "crates/mbe/src/lib.rs", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fmbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fmbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Flib.rs?ref=f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "patch": "@@ -14,6 +14,7 @@ mod tests;\n \n #[cfg(test)]\n mod benchmark;\n+mod token_map;\n \n use std::fmt;\n \n@@ -63,9 +64,12 @@ impl fmt::Display for ExpandError {\n     }\n }\n \n-pub use crate::syntax_bridge::{\n-    ast_to_token_tree, parse_exprs_with_sep, parse_to_token_tree, syntax_node_to_token_tree,\n-    token_tree_to_syntax_node, TokenMap,\n+pub use crate::{\n+    syntax_bridge::{\n+        ast_to_token_tree, parse_exprs_with_sep, parse_to_token_tree, syntax_node_to_token_tree,\n+        token_tree_to_syntax_node,\n+    },\n+    token_map::TokenMap,\n };\n \n /// This struct contains AST for a single `macro_rules` definition. What might"}, {"sha": "b11172caf026f6bd1fb8182ae9d05259f1c8b768", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 3, "deletions": 80, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "patch": "@@ -10,36 +10,8 @@ use syntax::{\n };\n use tt::buffer::{Cursor, TokenBuffer};\n \n-use crate::ExpandError;\n use crate::{subtree_source::SubtreeTokenSource, tt_iter::TtIter};\n-\n-#[derive(Debug, PartialEq, Eq, Clone, Copy)]\n-pub enum TokenTextRange {\n-    Token(TextRange),\n-    Delimiter(TextRange),\n-}\n-\n-impl TokenTextRange {\n-    pub fn by_kind(self, kind: SyntaxKind) -> Option<TextRange> {\n-        match self {\n-            TokenTextRange::Token(it) => Some(it),\n-            TokenTextRange::Delimiter(it) => match kind {\n-                T!['{'] | T!['('] | T!['['] => Some(TextRange::at(it.start(), 1.into())),\n-                T!['}'] | T![')'] | T![']'] => {\n-                    Some(TextRange::at(it.end() - TextSize::of('}'), 1.into()))\n-                }\n-                _ => None,\n-            },\n-        }\n-    }\n-}\n-\n-/// Maps `tt::TokenId` to the relative range of the original token.\n-#[derive(Debug, PartialEq, Eq, Clone, Default)]\n-pub struct TokenMap {\n-    /// Maps `tt::TokenId` to the *relative* source range.\n-    entries: Vec<(tt::TokenId, TokenTextRange)>,\n-}\n+use crate::{ExpandError, TokenMap};\n \n /// Convert the syntax tree (what user has written) to a `TokenTree` (what macro\n /// will consume).\n@@ -53,7 +25,7 @@ pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> (tt::Subtree, TokenMap) {\n     let global_offset = node.text_range().start();\n     let mut c = Convertor::new(node, global_offset);\n     let subtree = c.go();\n-    c.id_alloc.map.entries.shrink_to_fit();\n+    c.id_alloc.map.shrink_to_fit();\n     (subtree, c.id_alloc.map)\n }\n \n@@ -149,55 +121,6 @@ pub fn parse_exprs_with_sep(tt: &tt::Subtree, sep: char) -> Vec<tt::Subtree> {\n     res\n }\n \n-impl TokenMap {\n-    pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n-        let &(token_id, _) = self.entries.iter().find(|(_, range)| match range {\n-            TokenTextRange::Token(it) => *it == relative_range,\n-            TokenTextRange::Delimiter(it) => {\n-                let open = TextRange::at(it.start(), 1.into());\n-                let close = TextRange::at(it.end() - TextSize::of('}'), 1.into());\n-                open == relative_range || close == relative_range\n-            }\n-        })?;\n-        Some(token_id)\n-    }\n-\n-    pub fn range_by_token(&self, token_id: tt::TokenId) -> Option<TokenTextRange> {\n-        let &(_, range) = self.entries.iter().find(|(tid, _)| *tid == token_id)?;\n-        Some(range)\n-    }\n-\n-    fn insert(&mut self, token_id: tt::TokenId, relative_range: TextRange) {\n-        self.entries.push((token_id, TokenTextRange::Token(relative_range)));\n-    }\n-\n-    fn insert_delim(\n-        &mut self,\n-        token_id: tt::TokenId,\n-        open_relative_range: TextRange,\n-        close_relative_range: TextRange,\n-    ) -> usize {\n-        let res = self.entries.len();\n-        let cover = open_relative_range.cover(close_relative_range);\n-\n-        self.entries.push((token_id, TokenTextRange::Delimiter(cover)));\n-        res\n-    }\n-\n-    fn update_close_delim(&mut self, idx: usize, close_relative_range: TextRange) {\n-        let (_, token_text_range) = &mut self.entries[idx];\n-        if let TokenTextRange::Delimiter(dim) = token_text_range {\n-            let cover = dim.cover(close_relative_range);\n-            *token_text_range = TokenTextRange::Delimiter(cover);\n-        }\n-    }\n-\n-    fn remove_delim(&mut self, idx: usize) {\n-        // FIXME: This could be accidentally quadratic\n-        self.entries.remove(idx);\n-    }\n-}\n-\n /// Returns the textual content of a doc comment block as a quoted string\n /// That is, strips leading `///` (or `/**`, etc)\n /// and strips the ending `*/`\n@@ -634,7 +557,7 @@ impl<'a> TtTreeSink<'a> {\n     }\n \n     fn finish(mut self) -> (Parse<SyntaxNode>, TokenMap) {\n-        self.token_map.entries.shrink_to_fit();\n+        self.token_map.shrink_to_fit();\n         (self.inner.finish(), self.token_map)\n     }\n }"}, {"sha": "5f173f5134c6bd13aa658c46ab563515485b03b9", "filename": "crates/mbe/src/tests/expand.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fmbe%2Fsrc%2Ftests%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fmbe%2Fsrc%2Ftests%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Ftests%2Fexpand.rs?ref=f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "patch": "@@ -58,9 +58,8 @@ macro_rules! foobar {\n     let (node, token_map) = token_tree_to_syntax_node(&expanded, FragmentKind::Items).unwrap();\n     let content = node.syntax_node().to_string();\n \n-    let get_text = |id, kind| -> String {\n-        content[token_map.range_by_token(id).unwrap().by_kind(kind).unwrap()].to_string()\n-    };\n+    let get_text =\n+        |id, kind| -> String { content[token_map.range_by_token(id, kind).unwrap()].to_string() };\n \n     assert_eq!(expanded.token_trees.len(), 4);\n     // {($e:ident) => { fn $e() {} }}"}, {"sha": "6df3de3b3ea494e8aa13688e9f563fffe71947dd", "filename": "crates/mbe/src/token_map.rs", "status": "added", "additions": 85, "deletions": 0, "changes": 85, "blob_url": "https://github.com/rust-lang/rust/blob/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fmbe%2Fsrc%2Ftoken_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47/crates%2Fmbe%2Fsrc%2Ftoken_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Ftoken_map.rs?ref=f5f24a9a2c2e9d5d5ff155e700b2bf647f926d47", "patch": "@@ -0,0 +1,85 @@\n+//! Mapping between `TokenId`s and the token's position in macro definitions or inputs.\n+\n+use parser::{SyntaxKind, T};\n+use syntax::{TextRange, TextSize};\n+\n+#[derive(Debug, PartialEq, Eq, Clone, Copy)]\n+enum TokenTextRange {\n+    Token(TextRange),\n+    Delimiter(TextRange),\n+}\n+\n+impl TokenTextRange {\n+    fn by_kind(self, kind: SyntaxKind) -> Option<TextRange> {\n+        match self {\n+            TokenTextRange::Token(it) => Some(it),\n+            TokenTextRange::Delimiter(it) => match kind {\n+                T!['{'] | T!['('] | T!['['] => Some(TextRange::at(it.start(), 1.into())),\n+                T!['}'] | T![')'] | T![']'] => {\n+                    Some(TextRange::at(it.end() - TextSize::of('}'), 1.into()))\n+                }\n+                _ => None,\n+            },\n+        }\n+    }\n+}\n+\n+/// Maps `tt::TokenId` to the relative range of the original token.\n+#[derive(Debug, PartialEq, Eq, Clone, Default)]\n+pub struct TokenMap {\n+    /// Maps `tt::TokenId` to the *relative* source range.\n+    entries: Vec<(tt::TokenId, TokenTextRange)>,\n+}\n+\n+impl TokenMap {\n+    pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n+        let &(token_id, _) = self.entries.iter().find(|(_, range)| match range {\n+            TokenTextRange::Token(it) => *it == relative_range,\n+            TokenTextRange::Delimiter(it) => {\n+                let open = TextRange::at(it.start(), 1.into());\n+                let close = TextRange::at(it.end() - TextSize::of('}'), 1.into());\n+                open == relative_range || close == relative_range\n+            }\n+        })?;\n+        Some(token_id)\n+    }\n+\n+    pub fn range_by_token(&self, token_id: tt::TokenId, kind: SyntaxKind) -> Option<TextRange> {\n+        let &(_, range) = self.entries.iter().find(|(tid, _)| *tid == token_id)?;\n+        range.by_kind(kind)\n+    }\n+\n+    pub(crate) fn shrink_to_fit(&mut self) {\n+        self.entries.shrink_to_fit();\n+    }\n+\n+    pub(crate) fn insert(&mut self, token_id: tt::TokenId, relative_range: TextRange) {\n+        self.entries.push((token_id, TokenTextRange::Token(relative_range)));\n+    }\n+\n+    pub(crate) fn insert_delim(\n+        &mut self,\n+        token_id: tt::TokenId,\n+        open_relative_range: TextRange,\n+        close_relative_range: TextRange,\n+    ) -> usize {\n+        let res = self.entries.len();\n+        let cover = open_relative_range.cover(close_relative_range);\n+\n+        self.entries.push((token_id, TokenTextRange::Delimiter(cover)));\n+        res\n+    }\n+\n+    pub(crate) fn update_close_delim(&mut self, idx: usize, close_relative_range: TextRange) {\n+        let (_, token_text_range) = &mut self.entries[idx];\n+        if let TokenTextRange::Delimiter(dim) = token_text_range {\n+            let cover = dim.cover(close_relative_range);\n+            *token_text_range = TokenTextRange::Delimiter(cover);\n+        }\n+    }\n+\n+    pub(crate) fn remove_delim(&mut self, idx: usize) {\n+        // FIXME: This could be accidentally quadratic\n+        self.entries.remove(idx);\n+    }\n+}"}]}