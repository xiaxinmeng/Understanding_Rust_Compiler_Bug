{"sha": "aac9dfa46418603940ab2333cfea2190d9464d9e", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFhYzlkZmE0NjQxODYwMzk0MGFiMjMzM2NmZWEyMTkwZDk0NjRkOWU=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-06T12:14:28Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2019-04-06T12:14:28Z"}, "message": "Add TtCursorTokenSource and TtCursorTokenSink", "tree": {"sha": "83bc019e9961703ba1025c647a92ba4cd8e394af", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/83bc019e9961703ba1025c647a92ba4cd8e394af"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/aac9dfa46418603940ab2333cfea2190d9464d9e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/aac9dfa46418603940ab2333cfea2190d9464d9e", "html_url": "https://github.com/rust-lang/rust/commit/aac9dfa46418603940ab2333cfea2190d9464d9e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/aac9dfa46418603940ab2333cfea2190d9464d9e/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1d7735fbc6795c3ea5f02950b47413e0b35d6677", "url": "https://api.github.com/repos/rust-lang/rust/commits/1d7735fbc6795c3ea5f02950b47413e0b35d6677", "html_url": "https://github.com/rust-lang/rust/commit/1d7735fbc6795c3ea5f02950b47413e0b35d6677"}], "stats": {"total": 240, "additions": 216, "deletions": 24}, "files": [{"sha": "3a0702a30eb66a5895c8d9ac06868de83a33b8f0", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 36, "deletions": 22, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/aac9dfa46418603940ab2333cfea2190d9464d9e/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aac9dfa46418603940ab2333cfea2190d9464d9e/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=aac9dfa46418603940ab2333cfea2190d9464d9e", "patch": "@@ -104,15 +104,16 @@ fn convert_tt(\n }\n \n #[derive(Debug)]\n-struct TtTokenSource {\n-    tokens: Vec<TtToken>,\n+pub(crate) struct TtTokenSource {\n+    pub tokens: Vec<TtToken>,\n }\n \n #[derive(Debug)]\n-struct TtToken {\n-    kind: SyntaxKind,\n-    is_joint_to_next: bool,\n-    text: SmolStr,\n+pub(crate) struct TtToken {\n+    pub kind: SyntaxKind,\n+    pub is_joint_to_next: bool,\n+    pub text: SmolStr,\n+    pub n_tokens: usize,\n }\n \n // Some helper functions\n@@ -123,7 +124,7 @@ fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n     None\n }\n \n-struct TokenPeek<'a, I>\n+pub(crate) struct TokenPeek<'a, I>\n where\n     I: Iterator<Item = &'a tt::TokenTree>,\n {\n@@ -134,7 +135,11 @@ impl<'a, I> TokenPeek<'a, I>\n where\n     I: Iterator<Item = &'a tt::TokenTree>,\n {\n-    fn next(&mut self) -> Option<&tt::TokenTree> {\n+    pub fn new(iter: I) -> Self {\n+        TokenPeek { iter: itertools::multipeek(iter) }\n+    }\n+\n+    pub fn next(&mut self) -> Option<&tt::TokenTree> {\n         self.iter.next()\n     }\n \n@@ -161,14 +166,14 @@ where\n }\n \n impl TtTokenSource {\n-    fn new(tt: &tt::Subtree) -> TtTokenSource {\n+    pub fn new(tt: &tt::Subtree) -> TtTokenSource {\n         let mut res = TtTokenSource { tokens: Vec::new() };\n         res.convert_subtree(tt);\n         res\n     }\n     fn convert_subtree(&mut self, sub: &tt::Subtree) {\n         self.push_delim(sub.delimiter, false);\n-        let mut peek = TokenPeek { iter: itertools::multipeek(sub.token_trees.iter()) };\n+        let mut peek = TokenPeek::new(sub.token_trees.iter());\n         while let Some(tt) = peek.iter.next() {\n             self.convert_tt(tt, &mut peek);\n         }\n@@ -194,10 +199,17 @@ impl TtTokenSource {\n                 kind: classify_literal(&l.text).unwrap().kind,\n                 is_joint_to_next: false,\n                 text: l.text.clone(),\n+                n_tokens: 1,\n             },\n             tt::Leaf::Punct(p) => {\n-                if let Some(tt) = Self::convert_multi_char_punct(p, iter) {\n-                    tt\n+                if let Some((kind, is_joint_to_next, text, size)) =\n+                    Self::convert_multi_char_punct(p, iter)\n+                {\n+                    for _ in 0..size - 1 {\n+                        iter.next();\n+                    }\n+\n+                    TtToken { kind, is_joint_to_next, text: text.into(), n_tokens: size }\n                 } else {\n                     let kind = match p.char {\n                         // lexer may produce combpund tokens for these ones\n@@ -213,21 +225,26 @@ impl TtTokenSource {\n                         let s: &str = p.char.encode_utf8(&mut buf);\n                         SmolStr::new(s)\n                     };\n-                    TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text }\n+                    TtToken {\n+                        kind,\n+                        is_joint_to_next: p.spacing == tt::Spacing::Joint,\n+                        text,\n+                        n_tokens: 1,\n+                    }\n                 }\n             }\n             tt::Leaf::Ident(ident) => {\n                 let kind = SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT);\n-                TtToken { kind, is_joint_to_next: false, text: ident.text.clone() }\n+                TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n             }\n         };\n         self.tokens.push(tok)\n     }\n \n-    fn convert_multi_char_punct<'a, I>(\n+    pub(crate) fn convert_multi_char_punct<'a, I>(\n         p: &tt::Punct,\n         iter: &mut TokenPeek<'a, I>,\n-    ) -> Option<TtToken>\n+    ) -> Option<(SyntaxKind, bool, &'static str, usize)>\n     where\n         I: Iterator<Item = &'a tt::TokenTree>,\n     {\n@@ -239,9 +256,7 @@ impl TtTokenSource {\n                 ('.', '.', '=') => Some((DOTDOTEQ, \"..=\")),\n                 _ => None,\n             } {\n-                iter.next();\n-                iter.next();\n-                return Some(TtToken { kind, is_joint_to_next, text: text.into() });\n+                return Some((kind, is_joint_to_next, text, 3));\n             }\n         }\n \n@@ -273,8 +288,7 @@ impl TtTokenSource {\n \n                 _ => None,\n             } {\n-                iter.next();\n-                return Some(TtToken { kind, is_joint_to_next, text: text.into() });\n+                return Some((kind, is_joint_to_next, text, 2));\n             }\n         }\n \n@@ -291,7 +305,7 @@ impl TtTokenSource {\n         let idx = closing as usize;\n         let kind = kinds[idx];\n         let text = &texts[idx..texts.len() - (1 - idx)];\n-        let tok = TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text) };\n+        let tok = TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 };\n         self.tokens.push(tok)\n     }\n }"}, {"sha": "6ac3ac187db98b3b9036acb87fcef53455090041", "filename": "crates/ra_mbe/src/tt_cursor.rs", "status": "modified", "additions": 168, "deletions": 2, "changes": 170, "blob_url": "https://github.com/rust-lang/rust/blob/aac9dfa46418603940ab2333cfea2190d9464d9e/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aac9dfa46418603940ab2333cfea2190d9464d9e/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs?ref=aac9dfa46418603940ab2333cfea2190d9464d9e", "patch": "@@ -1,4 +1,124 @@\n use crate::ParseError;\n+use crate::syntax_bridge::{TtTokenSource, TtToken, TokenPeek};\n+use ra_parser::{TokenSource, TreeSink};\n+\n+use ra_syntax::{\n+    SyntaxKind\n+};\n+\n+struct TtCursorTokenSource {\n+    tt_pos: usize,\n+    inner: TtTokenSource,\n+}\n+\n+impl TtCursorTokenSource {\n+    fn new(subtree: &tt::Subtree, curr: usize) -> TtCursorTokenSource {\n+        let mut res = TtCursorTokenSource { inner: TtTokenSource::new(subtree), tt_pos: 1 };\n+\n+        // Matching `TtToken` cursor to `tt::TokenTree` cursor\n+        // It is because TtToken is not One to One mapping to tt::Token\n+        // There are 3 case (`TtToken` <=> `tt::TokenTree`) :\n+        // * One to One =>  ident, single char punch\n+        // * Many to One => `tt::TokenTree::SubTree`\n+        // * One to Many => multibyte punct\n+        //\n+        // Such that we cannot simpliy advance the cursor\n+        // We have to bump it one by one\n+        let mut pos = 0;\n+        while pos < curr {\n+            pos += res.bump(&subtree.token_trees[pos]);\n+        }\n+\n+        res\n+    }\n+\n+    fn skip_sibling_leaf(&self, leaf: &tt::Leaf, iter: &mut std::slice::Iter<tt::TokenTree>) {\n+        if let tt::Leaf::Punct(p) = leaf {\n+            let mut peek = TokenPeek::new(iter);\n+            if let Some((_, _, _, size)) = TtTokenSource::convert_multi_char_punct(p, &mut peek) {\n+                for _ in 0..size - 1 {\n+                    peek.next();\n+                }\n+            }\n+        }\n+    }\n+\n+    fn count_tt_tokens(\n+        &self,\n+        tt: &tt::TokenTree,\n+        iter: Option<&mut std::slice::Iter<tt::TokenTree>>,\n+    ) -> usize {\n+        assert!(!self.inner.tokens.is_empty());\n+\n+        match tt {\n+            tt::TokenTree::Subtree(sub_tree) => {\n+                let mut iter = sub_tree.token_trees.iter();\n+                let mut count = match sub_tree.delimiter {\n+                    tt::Delimiter::None => 0,\n+                    _ => 2,\n+                };\n+\n+                while let Some(tt) = iter.next() {\n+                    count += self.count_tt_tokens(&tt, Some(&mut iter));\n+                }\n+                count\n+            }\n+\n+            tt::TokenTree::Leaf(leaf) => {\n+                iter.map(|iter| {\n+                    self.skip_sibling_leaf(leaf, iter);\n+                });\n+\n+                1\n+            }\n+        }\n+    }\n+\n+    fn count(&self, tt: &tt::TokenTree) -> usize {\n+        self.count_tt_tokens(tt, None)\n+    }\n+\n+    fn bump(&mut self, tt: &tt::TokenTree) -> usize {\n+        let cur = self.current().unwrap();\n+        let n_tokens = cur.n_tokens;\n+        self.tt_pos += self.count(tt);\n+        n_tokens\n+    }\n+\n+    fn current(&self) -> Option<&TtToken> {\n+        self.inner.tokens.get(self.tt_pos)\n+    }\n+}\n+\n+impl TokenSource for TtCursorTokenSource {\n+    fn token_kind(&self, pos: usize) -> SyntaxKind {\n+        if let Some(tok) = self.inner.tokens.get(self.tt_pos + pos) {\n+            tok.kind\n+        } else {\n+            SyntaxKind::EOF\n+        }\n+    }\n+    fn is_token_joint_to_next(&self, pos: usize) -> bool {\n+        self.inner.tokens[self.tt_pos + pos].is_joint_to_next\n+    }\n+    fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n+        self.inner.tokens[self.tt_pos + pos].text == *kw\n+    }\n+}\n+\n+struct TtCursorTokenSink {\n+    token_pos: usize,\n+}\n+\n+impl TreeSink for TtCursorTokenSink {\n+    fn token(&mut self, _kind: SyntaxKind, n_tokens: u8) {\n+        self.token_pos += n_tokens as usize;\n+    }\n+\n+    fn start_node(&mut self, _kind: SyntaxKind) {}\n+    fn finish_node(&mut self) {}\n+    fn error(&mut self, _error: ra_parser::ParseError) {}\n+}\n \n #[derive(Clone)]\n pub(crate) struct TtCursor<'a> {\n@@ -78,8 +198,54 @@ impl<'a> TtCursor<'a> {\n         })\n     }\n \n-    pub(crate) fn eat_path(&mut self) -> Option<tt::Subtree> {        \n-        None\n+    fn eat_parse_result(\n+        &mut self,\n+        parsed_token: usize,\n+        src: &mut TtCursorTokenSource,\n+    ) -> Option<tt::TokenTree> {\n+        let mut res = vec![];\n+\n+        // Matching `TtToken` cursor to `tt::TokenTree` cursor\n+        // It is because TtToken is not One to One mapping to tt::Token\n+        // There are 3 case (`TtToken` <=> `tt::TokenTree`) :\n+        // * One to One =>  ident, single char punch\n+        // * Many to One => `tt::TokenTree::SubTree`\n+        // * One to Many => multibyte punct\n+        //\n+        // Such that we cannot simpliy advance the cursor\n+        // We have to bump it one by one\n+        let next_pos = src.tt_pos + parsed_token;\n+        while src.tt_pos < next_pos {\n+            let n = src.bump(self.current().unwrap());\n+            res.extend((0..n).map(|_| self.eat().unwrap()));\n+        }\n+\n+        let res: Vec<_> = res.into_iter().cloned().collect();\n+\n+        match res.len() {\n+            0 => None,\n+            1 => Some(res[0].clone()),\n+            _ => Some(tt::TokenTree::Subtree(tt::Subtree {\n+                delimiter: tt::Delimiter::None,\n+                token_trees: res,\n+            })),\n+        }\n+    }\n+\n+    fn eat_parse<F>(&mut self, f: F) -> Option<tt::TokenTree>\n+    where\n+        F: FnOnce(&dyn TokenSource, &mut dyn TreeSink),\n+    {\n+        let mut src = TtCursorTokenSource::new(self.subtree, self.pos);\n+        let mut sink = TtCursorTokenSink { token_pos: 0 };\n+\n+        f(&src, &mut sink);\n+\n+        self.eat_parse_result(sink.token_pos, &mut src)\n+    }\n+\n+    pub(crate) fn eat_path(&mut self) -> Option<tt::TokenTree> {\n+        self.eat_parse(ra_parser::parse_path)\n     }\n \n     pub(crate) fn expect_char(&mut self, char: char) -> Result<(), ParseError> {"}, {"sha": "c5f510e6b7779705d3995a8e453cdc4d271884bb", "filename": "crates/ra_parser/src/grammar.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/aac9dfa46418603940ab2333cfea2190d9464d9e/crates%2Fra_parser%2Fsrc%2Fgrammar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aac9dfa46418603940ab2333cfea2190d9464d9e/crates%2Fra_parser%2Fsrc%2Fgrammar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_parser%2Fsrc%2Fgrammar.rs?ref=aac9dfa46418603940ab2333cfea2190d9464d9e", "patch": "@@ -49,6 +49,10 @@ pub(crate) fn root(p: &mut Parser) {\n     m.complete(p, SOURCE_FILE);\n }\n \n+pub(crate) fn path(p: &mut Parser) {\n+    paths::type_path(p);\n+}\n+\n pub(crate) fn reparser(\n     node: SyntaxKind,\n     first_child: Option<SyntaxKind>,"}, {"sha": "3ceeeebd75150aba0f22ceaa3b5e9b6cae0b70e1", "filename": "crates/ra_parser/src/lib.rs", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/aac9dfa46418603940ab2333cfea2190d9464d9e/crates%2Fra_parser%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aac9dfa46418603940ab2333cfea2190d9464d9e/crates%2Fra_parser%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_parser%2Fsrc%2Flib.rs?ref=aac9dfa46418603940ab2333cfea2190d9464d9e", "patch": "@@ -61,6 +61,14 @@ pub fn parse(token_source: &dyn TokenSource, tree_sink: &mut dyn TreeSink) {\n     event::process(tree_sink, events);\n }\n \n+/// Parse given tokens into the given sink as a path\n+pub fn parse_path(token_source: &dyn TokenSource, tree_sink: &mut dyn TreeSink) {\n+    let mut p = parser::Parser::new(token_source);\n+    grammar::path(&mut p);\n+    let events = p.finish();\n+    event::process(tree_sink, events);\n+}\n+\n /// A parsing function for a specific braced-block.\n pub struct Reparser(fn(&mut parser::Parser));\n "}]}