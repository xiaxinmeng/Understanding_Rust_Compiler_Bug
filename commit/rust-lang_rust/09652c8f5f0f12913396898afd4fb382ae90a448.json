{"sha": "09652c8f5f0f12913396898afd4fb382ae90a448", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA5NjUyYzhmNWYwZjEyOTEzMzk2ODk4YWZkNGZiMzgyYWU5MGE0NDg=", "commit": {"author": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-05-24T19:38:45Z"}, "committer": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-05-24T21:39:22Z"}, "message": "Use an impl to access parse/common.rs", "tree": {"sha": "6d4c85ec703a1977edd4ecab8fa2dde835d234f9", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6d4c85ec703a1977edd4ecab8fa2dde835d234f9"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/09652c8f5f0f12913396898afd4fb382ae90a448", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/09652c8f5f0f12913396898afd4fb382ae90a448", "html_url": "https://github.com/rust-lang/rust/commit/09652c8f5f0f12913396898afd4fb382ae90a448", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/09652c8f5f0f12913396898afd4fb382ae90a448/comments", "author": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "committer": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "829c9834791cfccb6f79f860beec2f1fc4f1284d", "url": "https://api.github.com/repos/rust-lang/rust/commits/829c9834791cfccb6f79f860beec2f1fc4f1284d", "html_url": "https://github.com/rust-lang/rust/commit/829c9834791cfccb6f79f860beec2f1fc4f1284d"}], "stats": {"total": 884, "additions": 447, "deletions": 437}, "files": [{"sha": "d44b726f72c7fb82da4259695e21e0d5982ed046", "filename": "src/librustsyntax/parse.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/09652c8f5f0f12913396898afd4fb382ae90a448/src%2Flibrustsyntax%2Fparse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/09652c8f5f0f12913396898afd4fb382ae90a448/src%2Flibrustsyntax%2Fparse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustsyntax%2Fparse.rs?ref=09652c8f5f0f12913396898afd4fb382ae90a448", "patch": "@@ -13,6 +13,7 @@ export parse_item_from_source_str;\n export parse_from_source_str;\n \n import parser::parser;\n+import common::parser_common;\n import ast::node_id;\n import util::interner;\n import lexer::reader;\n@@ -56,7 +57,7 @@ fn parse_crate_from_crate_file(input: str, cfg: ast::crate_cfg,\n     let (m, attrs) = eval::eval_crate_directives_to_mod(\n         cx, cdirs, prefix, option::some(companionmod));\n     let mut hi = p.span.hi;\n-    parser::expect(p, token::EOF);\n+    p.expect(token::EOF);\n     ret @ast_util::respan(ast_util::mk_sp(lo, hi),\n                           {directives: cdirs,\n                            module: m,"}, {"sha": "8801eeba9eead4fb35ab17298696305a2a8f7576", "filename": "src/librustsyntax/parse/attr.rs", "status": "modified", "additions": 7, "deletions": 10, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/09652c8f5f0f12913396898afd4fb382ae90a448/src%2Flibrustsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/09652c8f5f0f12913396898afd4fb382ae90a448/src%2Flibrustsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustsyntax%2Fparse%2Fattr.rs?ref=09652c8f5f0f12913396898afd4fb382ae90a448", "patch": "@@ -1,9 +1,6 @@\n import either::{either, left, right};\n import ast_util::spanned;\n-import common::{parse_seq,\n-                seq_sep,\n-                expect,\n-                parse_ident};\n+import common::{parser_common, seq_sep};\n \n export attr_or_ext;\n export parse_outer_attributes;\n@@ -45,15 +42,15 @@ fn parse_outer_attributes(p: parser) -> [ast::attribute] {\n \n fn parse_attribute(p: parser, style: ast::attr_style) -> ast::attribute {\n     let lo = p.span.lo;\n-    expect(p, token::POUND);\n+    p.expect(token::POUND);\n     ret parse_attribute_naked(p, style, lo);\n }\n \n fn parse_attribute_naked(p: parser, style: ast::attr_style, lo: uint) ->\n    ast::attribute {\n-    expect(p, token::LBRACKET);\n+    p.expect(token::LBRACKET);\n     let meta_item = parse_meta_item(p);\n-    expect(p, token::RBRACKET);\n+    p.expect(token::RBRACKET);\n     let mut hi = p.span.hi;\n     ret spanned(lo, hi, {style: style, value: *meta_item});\n }\n@@ -91,7 +88,7 @@ fn parse_inner_attrs_and_next(p: parser) ->\n \n fn parse_meta_item(p: parser) -> @ast::meta_item {\n     let lo = p.span.lo;\n-    let ident = parse_ident(p);\n+    let ident = p.parse_ident();\n     alt p.token {\n       token::EQ {\n         p.bump();\n@@ -112,8 +109,8 @@ fn parse_meta_item(p: parser) -> @ast::meta_item {\n }\n \n fn parse_meta_seq(p: parser) -> [@ast::meta_item] {\n-    ret parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n-                  p, {|p| parse_meta_item(p)}).node;\n+    ret p.parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n+                    {|p| parse_meta_item(p)}).node;\n }\n \n fn parse_optional_meta(p: parser) -> [@ast::meta_item] {"}, {"sha": "4bfba482c4f5656c681984b81f516d738b743516", "filename": "src/librustsyntax/parse/common.rs", "status": "modified", "additions": 170, "deletions": 159, "changes": 329, "blob_url": "https://github.com/rust-lang/rust/blob/09652c8f5f0f12913396898afd4fb382ae90a448/src%2Flibrustsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/09652c8f5f0f12913396898afd4fb382ae90a448/src%2Flibrustsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustsyntax%2Fparse%2Fcommon.rs?ref=09652c8f5f0f12913396898afd4fb382ae90a448", "patch": "@@ -2,205 +2,216 @@ import std::map::{hashmap};\n import ast_util::spanned;\n import parser::parser;\n \n+type seq_sep = {\n+    sep: option<token::token>,\n+    trailing_opt: bool   // is trailing separator optional?\n+};\n+\n+fn seq_sep(t: token::token) -> seq_sep {\n+    ret {sep: option::some(t), trailing_opt: false};\n+}\n+fn seq_sep_opt(t: token::token) -> seq_sep {\n+    ret {sep: option::some(t), trailing_opt: true};\n+}\n+fn seq_sep_none() -> seq_sep {\n+    ret {sep: option::none, trailing_opt: false};\n+}\n+\n+\n fn token_to_str(reader: reader, token: token::token) -> str {\n     token::to_str(*reader.interner, token)\n }\n \n-fn unexpected_last(p: parser, t: token::token) -> ! {\n-    p.span_fatal(p.last_span,\n-                 \"unexpected token: '\" + token_to_str(p.reader, t) + \"'\");\n-}\n \n-fn unexpected(p: parser) -> ! {\n-    p.fatal(\"unexpected token: '\" + token_to_str(p.reader, p.token) + \"'\");\n-}\n+// This should be done with traits, once traits work\n+impl parser_common for parser {\n \n-fn expect(p: parser, t: token::token) {\n-    if p.token == t {\n-        p.bump();\n-    } else {\n-        let mut s: str = \"expecting '\";\n-        s += token_to_str(p.reader, t);\n-        s += \"' but found '\";\n-        s += token_to_str(p.reader, p.token);\n-        p.fatal(s + \"'\");\n+    fn unexpected_last(t: token::token) -> ! {\n+        self.span_fatal(self.last_span, \"unexpected token: '\"\n+                        + token_to_str(self.reader, t) + \"'\");\n     }\n-}\n \n-fn parse_ident(p: parser) -> ast::ident {\n-    alt p.token {\n-      token::IDENT(i, _) { p.bump(); ret p.get_str(i); }\n-      _ { p.fatal(\"expecting ident, found \"\n-                  + token_to_str(p.reader, p.token)); }\n+    fn unexpected() -> ! {\n+        self.fatal(\"unexpected token: '\"\n+                   + token_to_str(self.reader, self.token) + \"'\");\n     }\n-}\n-\n-fn parse_path_list_ident(p: parser) -> ast::path_list_ident {\n-    let lo = p.span.lo;\n-    let ident = parse_ident(p);\n-    let hi = p.span.hi;\n-    ret spanned(lo, hi, {name: ident, id: p.get_id()});\n-}\n \n-fn parse_value_ident(p: parser) -> ast::ident {\n-    check_restricted_keywords(p);\n-    ret parse_ident(p);\n-}\n+    fn expect(t: token::token) {\n+        if self.token == t {\n+            self.bump();\n+        } else {\n+            let mut s: str = \"expecting '\";\n+            s += token_to_str(self.reader, t);\n+            s += \"' but found '\";\n+            s += token_to_str(self.reader, self.token);\n+            self.fatal(s + \"'\");\n+        }\n+    }\n \n-fn eat(p: parser, tok: token::token) -> bool {\n-    ret if p.token == tok { p.bump(); true } else { false };\n-}\n+    fn parse_ident() -> ast::ident {\n+        alt self.token {\n+          token::IDENT(i, _) { self.bump(); ret self.get_str(i); }\n+          _ { self.fatal(\"expecting ident, found \"\n+                      + token_to_str(self.reader, self.token)); }\n+        }\n+    }\n \n-// A sanity check that the word we are asking for is a known keyword\n-fn require_keyword(p: parser, word: str) {\n-    if !p.keywords.contains_key(word) {\n-        p.bug(#fmt(\"unknown keyword: %s\", word));\n+    fn parse_path_list_ident() -> ast::path_list_ident {\n+        let lo = self.span.lo;\n+        let ident = self.parse_ident();\n+        let hi = self.span.hi;\n+        ret spanned(lo, hi, {name: ident, id: self.get_id()});\n     }\n-}\n \n-fn token_is_keyword(p: parser, word: str, tok: token::token) -> bool {\n-    require_keyword(p, word);\n-    alt tok {\n-      token::IDENT(sid, false) { str::eq(word, p.get_str(sid)) }\n-      _ { false }\n+    fn parse_value_ident() -> ast::ident {\n+        self.check_restricted_keywords();\n+        ret self.parse_ident();\n     }\n-}\n \n-fn is_keyword(p: parser, word: str) -> bool {\n-    token_is_keyword(p, word, p.token)\n-}\n+    fn eat(tok: token::token) -> bool {\n+        ret if self.token == tok { self.bump(); true } else { false };\n+    }\n \n-fn eat_keyword(p: parser, word: str) -> bool {\n-    require_keyword(p, word);\n-    alt p.token {\n-      token::IDENT(sid, false) {\n-        if str::eq(word, p.get_str(sid)) {\n-            p.bump();\n-            ret true;\n-        } else { ret false; }\n-      }\n-      _ { ret false; }\n+    // A sanity check that the word we are asking for is a known keyword\n+    fn require_keyword(word: str) {\n+        if !self.keywords.contains_key(word) {\n+            self.bug(#fmt(\"unknown keyword: %s\", word));\n+        }\n     }\n-}\n \n-fn expect_keyword(p: parser, word: str) {\n-    require_keyword(p, word);\n-    if !eat_keyword(p, word) {\n-        p.fatal(\"expecting \" + word + \", found \" +\n-                    token_to_str(p.reader, p.token));\n+    fn token_is_keyword(word: str, tok: token::token) -> bool {\n+        self.require_keyword(word);\n+        alt tok {\n+          token::IDENT(sid, false) { str::eq(word, self.get_str(sid)) }\n+          _ { false }\n+        }\n     }\n-}\n \n-fn is_restricted_keyword(p: parser, word: str) -> bool {\n-    p.restricted_keywords.contains_key(word)\n-}\n+    fn is_keyword(word: str) -> bool {\n+        self.token_is_keyword(word, self.token)\n+    }\n \n-fn check_restricted_keywords(p: parser) {\n-    alt p.token {\n-      token::IDENT(_, false) {\n-        let w = token_to_str(p.reader, p.token);\n-        check_restricted_keywords_(p, w);\n-      }\n-      _ { }\n+    fn eat_keyword(word: str) -> bool {\n+        self.require_keyword(word);\n+        alt self.token {\n+          token::IDENT(sid, false) {\n+            if str::eq(word, self.get_str(sid)) {\n+                self.bump();\n+                ret true;\n+            } else { ret false; }\n+          }\n+          _ { ret false; }\n+        }\n     }\n-}\n \n-fn check_restricted_keywords_(p: parser, w: ast::ident) {\n-    if is_restricted_keyword(p, w) {\n-        p.fatal(\"found `\" + w + \"` in restricted position\");\n+    fn expect_keyword(word: str) {\n+        self.require_keyword(word);\n+        if !self.eat_keyword(word) {\n+            self.fatal(\"expecting \" + word + \", found \" +\n+                    token_to_str(self.reader, self.token));\n     }\n }\n \n-fn expect_gt(p: parser) {\n-    if p.token == token::GT {\n-        p.bump();\n-    } else if p.token == token::BINOP(token::SHR) {\n-        p.swap(token::GT, p.span.lo + 1u, p.span.hi);\n-    } else {\n-        let mut s: str = \"expecting \";\n-        s += token_to_str(p.reader, token::GT);\n-        s += \", found \";\n-        s += token_to_str(p.reader, p.token);\n-        p.fatal(s);\n+    fn is_restricted_keyword(word: str) -> bool {\n+        self.restricted_keywords.contains_key(word)\n     }\n-}\n \n-fn parse_seq_to_before_gt<T: copy>(sep: option<token::token>,\n-                                   p: parser, f: fn(parser) -> T) -> [T] {\n-    let mut first = true;\n-    let mut v = [];\n-    while p.token != token::GT && p.token != token::BINOP(token::SHR) {\n-        alt sep {\n-          some(t) { if first { first = false; } else { expect(p, t); } }\n+    fn check_restricted_keywords() {\n+        alt self.token {\n+          token::IDENT(_, false) {\n+            let w = token_to_str(self.reader, self.token);\n+            self.check_restricted_keywords_(w);\n+          }\n           _ { }\n         }\n-        v += [f(p)];\n     }\n \n-    ret v;\n-}\n+    fn check_restricted_keywords_(w: ast::ident) {\n+        if self.is_restricted_keyword(w) {\n+            self.fatal(\"found `\" + w + \"` in restricted position\");\n+        }\n+    }\n \n-fn parse_seq_to_gt<T: copy>(sep: option<token::token>,\n-                            p: parser, f: fn(parser) -> T) -> [T] {\n-    let v = parse_seq_to_before_gt(sep, p, f);\n-    expect_gt(p);\n+    fn expect_gt() {\n+        if self.token == token::GT {\n+            self.bump();\n+        } else if self.token == token::BINOP(token::SHR) {\n+            self.swap(token::GT, self.span.lo + 1u, self.span.hi);\n+        } else {\n+            let mut s: str = \"expecting \";\n+            s += token_to_str(self.reader, token::GT);\n+            s += \", found \";\n+            s += token_to_str(self.reader, self.token);\n+            self.fatal(s);\n+        }\n+    }\n \n-    ret v;\n-}\n+    fn parse_seq_to_before_gt<T: copy>(sep: option<token::token>,\n+                                       f: fn(parser) -> T) -> [T] {\n+        let mut first = true;\n+        let mut v = [];\n+        while self.token != token::GT\n+            && self.token != token::BINOP(token::SHR) {\n+            alt sep {\n+              some(t) { if first { first = false; }\n+                       else { self.expect(t); } }\n+              _ { }\n+            }\n+            v += [f(self)];\n+        }\n \n-fn parse_seq_lt_gt<T: copy>(sep: option<token::token>,\n-                            p: parser, f: fn(parser) -> T) -> spanned<[T]> {\n-    let lo = p.span.lo;\n-    expect(p, token::LT);\n-    let result = parse_seq_to_before_gt::<T>(sep, p, f);\n-    let hi = p.span.hi;\n-    expect_gt(p);\n-    ret spanned(lo, hi, result);\n-}\n+        ret v;\n+    }\n \n-fn parse_seq_to_end<T: copy>(ket: token::token, sep: seq_sep, p: parser,\n-                             f: fn(parser) -> T) -> [T] {\n-    let val = parse_seq_to_before_end(ket, sep, p, f);\n-    p.bump();\n-    ret val;\n-}\n+    fn parse_seq_to_gt<T: copy>(sep: option<token::token>,\n+                                f: fn(parser) -> T) -> [T] {\n+        let v = self.parse_seq_to_before_gt(sep, f);\n+        self.expect_gt();\n \n-type seq_sep = {\n-    sep: option<token::token>,\n-    trailing_opt: bool   // is trailing separator optional?\n-};\n+        ret v;\n+    }\n \n-fn seq_sep(t: token::token) -> seq_sep {\n-    ret {sep: option::some(t), trailing_opt: false};\n-}\n-fn seq_sep_opt(t: token::token) -> seq_sep {\n-    ret {sep: option::some(t), trailing_opt: true};\n-}\n-fn seq_sep_none() -> seq_sep {\n-    ret {sep: option::none, trailing_opt: false};\n-}\n+    fn parse_seq_lt_gt<T: copy>(sep: option<token::token>,\n+                                f: fn(parser) -> T) -> spanned<[T]> {\n+        let lo = self.span.lo;\n+        self.expect(token::LT);\n+        let result = self.parse_seq_to_before_gt::<T>(sep, f);\n+        let hi = self.span.hi;\n+        self.expect_gt();\n+        ret spanned(lo, hi, result);\n+    }\n \n-fn parse_seq_to_before_end<T: copy>(ket: token::token, sep: seq_sep,\n-                                    p: parser, f: fn(parser) -> T) -> [T] {\n-    let mut first: bool = true;\n-    let mut v: [T] = [];\n-    while p.token != ket {\n-        alt sep.sep {\n-          some(t) { if first { first = false; } else { expect(p, t); } }\n-          _ { }\n+    fn parse_seq_to_end<T: copy>(ket: token::token, sep: seq_sep,\n+                                 f: fn(parser) -> T) -> [T] {\n+        let val = self.parse_seq_to_before_end(ket, sep, f);\n+        self.bump();\n+        ret val;\n+    }\n+\n+\n+    fn parse_seq_to_before_end<T: copy>(ket: token::token, sep: seq_sep,\n+                                        f: fn(parser) -> T) -> [T] {\n+        let mut first: bool = true;\n+        let mut v: [T] = [];\n+        while self.token != ket {\n+            alt sep.sep {\n+              some(t) { if first { first = false; }\n+                        else { self.expect(t); } }\n+              _ { }\n+            }\n+            if sep.trailing_opt && self.token == ket { break; }\n+            v += [f(self)];\n         }\n-        if sep.trailing_opt && p.token == ket { break; }\n-        v += [f(p)];\n+        ret v;\n     }\n-    ret v;\n-}\n \n-fn parse_seq<T: copy>(bra: token::token, ket: token::token, sep: seq_sep,\n-                      p: parser, f: fn(parser) -> T) -> spanned<[T]> {\n-    let lo = p.span.lo;\n-    expect(p, bra);\n-    let result = parse_seq_to_before_end::<T>(ket, sep, p, f);\n-    let hi = p.span.hi;\n-    p.bump();\n-    ret spanned(lo, hi, result);\n-}\n+    fn parse_seq<T: copy>(bra: token::token, ket: token::token, sep: seq_sep,\n+                          f: fn(parser) -> T) -> spanned<[T]> {\n+        let lo = self.span.lo;\n+        self.expect(bra);\n+        let result = self.parse_seq_to_before_end::<T>(ket, sep, f);\n+        let hi = self.span.hi;\n+        self.bump();\n+        ret spanned(lo, hi, result);\n+    }\n+}\n\\ No newline at end of file"}, {"sha": "686bbea38744e7816726e33e312050f6eaac3989", "filename": "src/librustsyntax/parse/parser.rs", "status": "modified", "additions": 268, "deletions": 267, "changes": 535, "blob_url": "https://github.com/rust-lang/rust/blob/09652c8f5f0f12913396898afd4fb382ae90a448/src%2Flibrustsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/09652c8f5f0f12913396898afd4fb382ae90a448/src%2Flibrustsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustsyntax%2Fparse%2Fparser.rs?ref=09652c8f5f0f12913396898afd4fb382ae90a448", "patch": "@@ -15,7 +15,6 @@ import attr::{parse_outer_attrs_or_ext,\n import common::*;\n import dvec::{dvec, extensions};\n \n-export expect;\n export file_type;\n export parser;\n export parse_expr;\n@@ -142,13 +141,13 @@ class parser {\n \n     fn parse_ty_fn() -> fn_decl {\n         let inputs =\n-            parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n-                      self) { |p|\n+            self.parse_seq(token::LPAREN, token::RPAREN,\n+                           seq_sep(token::COMMA)) { |p|\n             let mode = p.parse_arg_mode();\n             let name = if is_plain_ident(p.token)\n                 && p.look_ahead(1u) == token::COLON {\n \n-                let name = parse_value_ident(p);\n+                let name = self.parse_value_ident();\n                 p.bump();\n                 name\n             } else { \"\" };\n@@ -168,14 +167,14 @@ class parser {\n     }\n \n     fn parse_ty_methods() -> [ty_method] {\n-        (parse_seq(token::LBRACE, token::RBRACE, seq_sep_none(), self) { |p|\n+        (self.parse_seq(token::LBRACE, token::RBRACE, seq_sep_none()) { |p|\n             let attrs = parse_outer_attributes(p);\n             let flo = p.span.lo;\n             let pur = p.parse_fn_purity();\n             let ident = p.parse_method_name();\n             let tps = p.parse_ty_params();\n             let d = p.parse_ty_fn(), fhi = p.last_span.hi;\n-            expect(p, token::SEMI);\n+            self.expect(token::SEMI);\n             {ident: ident, attrs: attrs, decl: {purity: pur with d}, tps: tps,\n              span: mk_sp(flo, fhi)}\n         }).node\n@@ -190,8 +189,8 @@ class parser {\n     fn parse_ty_field() -> ty_field {\n         let lo = self.span.lo;\n         let mutbl = self.parse_mutability();\n-        let id = parse_ident(self);\n-        expect(self, token::COLON);\n+        let id = self.parse_ident();\n+        self.expect(token::COLON);\n         let ty = self.parse_ty(false);\n         ret spanned(lo, ty.span.hi, {ident: id, mt: {ty: ty, mutbl: mutbl}});\n     }\n@@ -207,7 +206,7 @@ class parser {\n     fn parse_type_constr_arg() -> @ty_constr_arg {\n         let sp = self.span;\n         let mut carg = carg_base;\n-        expect(self, token::BINOP(token::STAR));\n+        self.expect(token::BINOP(token::STAR));\n         if self.token == token::DOT {\n             // \"*...\" notation for record fields\n             self.bump();\n@@ -224,7 +223,7 @@ class parser {\n         if self.token == token::BINOP(token::STAR) {\n             self.bump();\n         } else {\n-            let i: ident = parse_value_ident(self);\n+            let i: ident = self.parse_value_ident();\n             carg = carg_ident(self.ident_index(args, i));\n         }\n         ret @{node: carg, span: sp};\n@@ -234,8 +233,9 @@ class parser {\n         let lo = self.span.lo;\n         let path = self.parse_path_without_tps();\n         let args: {node: [@constr_arg], span: span} =\n-            parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n-                      self, {|p| p.parse_constr_arg(fn_args)});\n+            self.parse_seq(token::LPAREN, token::RPAREN,\n+                           seq_sep(token::COMMA),\n+                           {|p| p.parse_constr_arg(fn_args)});\n         ret @spanned(lo, args.span.hi,\n                      {path: path, args: args.node, id: self.get_id()});\n     }\n@@ -244,8 +244,9 @@ class parser {\n         let lo = self.span.lo;\n         let path = self.parse_path_without_tps();\n         let args: [@ty_constr_arg] =\n-            parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n-                      self, {|p| p.parse_type_constr_arg()}).node;\n+            self.parse_seq(token::LPAREN, token::RPAREN,\n+                           seq_sep(token::COMMA),\n+                           {|p| p.parse_type_constr_arg()}).node;\n         let hi = self.span.lo;\n         let tc: ty_constr_ = {path: path, args: args, id: self.get_id()};\n         ret @spanned(lo, hi, tc);\n@@ -268,9 +269,9 @@ class parser {\n     }\n \n     fn parse_ret_ty() -> (ret_style, @ty) {\n-        ret if eat(self, token::RARROW) {\n+        ret if self.eat(token::RARROW) {\n             let lo = self.span.lo;\n-            if eat(self, token::NOT) {\n+            if self.eat(token::NOT) {\n                 (noreturn, @{id: self.get_id(),\n                              node: ty_bot,\n                              span: mk_sp(lo, self.last_span.hi)})\n@@ -296,7 +297,7 @@ class parser {\n \n     // Parses something like \"&x\"\n     fn parse_region() -> @region {\n-        expect(self, token::BINOP(token::AND));\n+        self.expect(token::BINOP(token::AND));\n         alt self.token {\n           token::IDENT(sid, _) {\n             self.bump();\n@@ -347,7 +348,7 @@ class parser {\n                 }\n                 let t = if vec::len(ts) == 1u { ts[0].node }\n                 else { ty_tup(ts) };\n-                expect(self, token::RPAREN);\n+                self.expect(token::RPAREN);\n                 t\n             }\n         } else if self.token == token::AT {\n@@ -360,11 +361,11 @@ class parser {\n             self.bump();\n             ty_ptr(self.parse_mt())\n         } else if self.token == token::LBRACE {\n-            let elems = parse_seq(token::LBRACE, token::RBRACE,\n-                                  seq_sep_opt(token::COMMA), self,\n-                                  {|p| p.parse_ty_field()});\n+            let elems = self.parse_seq(token::LBRACE, token::RBRACE,\n+                                       seq_sep_opt(token::COMMA),\n+                                       {|p| p.parse_ty_field()});\n             if vec::len(elems.node) == 0u {\n-                unexpected_last(self, token::RBRACE);\n+                self.unexpected_last(token::RBRACE);\n             }\n             let hi = elems.span.hi;\n \n@@ -377,24 +378,24 @@ class parser {\n                           self.parse_type_constraints())\n             } else { t }\n         } else if self.token == token::LBRACKET {\n-            expect(self, token::LBRACKET);\n+            self.expect(token::LBRACKET);\n             let t = ty_vec(self.parse_mt());\n-            expect(self, token::RBRACKET);\n+            self.expect(token::RBRACKET);\n             t\n         } else if self.token == token::BINOP(token::AND) {\n             self.bump();\n             let region = self.parse_region_dot();\n             let mt = self.parse_mt();\n             ty_rptr(region, mt)\n-        } else if eat_keyword(self, \"fn\") {\n+        } else if self.eat_keyword(\"fn\") {\n             let proto = self.parse_fn_ty_proto();\n             alt proto {\n               proto_bare { self.warn(\"fn is deprecated, use native fn\"); }\n               _ { /* fallthrough */ }\n             }\n             ty_fn(proto, self.parse_ty_fn())\n-        } else if eat_keyword(self, \"native\") {\n-            expect_keyword(self, \"fn\");\n+        } else if self.eat_keyword(\"native\") {\n+            self.expect_keyword(\"fn\");\n             ty_fn(proto_bare, self.parse_ty_fn())\n         } else if self.token == token::MOD_SEP || is_ident(self.token) {\n             let path = self.parse_path_with_tps(colons_before_params);\n@@ -413,14 +414,14 @@ class parser {\n     }\n \n     fn parse_arg_mode() -> mode {\n-        if eat(self, token::BINOP(token::AND)) {\n+        if self.eat(token::BINOP(token::AND)) {\n             expl(by_mutbl_ref)\n-        } else if eat(self, token::BINOP(token::MINUS)) {\n+        } else if self.eat(token::BINOP(token::MINUS)) {\n             expl(by_move)\n-        } else if eat(self, token::ANDAND) {\n+        } else if self.eat(token::ANDAND) {\n             expl(by_ref)\n-        } else if eat(self, token::BINOP(token::PLUS)) {\n-            if eat(self, token::BINOP(token::PLUS)) {\n+        } else if self.eat(token::BINOP(token::PLUS)) {\n+            if self.eat(token::BINOP(token::PLUS)) {\n                 expl(by_val)\n             } else {\n                 expl(by_copy)\n@@ -433,13 +434,13 @@ class parser {\n \n         fn parse_capture_item(p:parser, is_move: bool) -> capture_item {\n             let sp = mk_sp(p.span.lo, p.span.hi);\n-            let ident = parse_ident(p);\n+            let ident = p.parse_ident();\n             @{id: p.get_id(), is_move: is_move, name: ident, span: sp}\n         }\n \n-        if eat_keyword(self, \"move\") {\n+        if self.eat_keyword(\"move\") {\n             either::right(parse_capture_item(self, true))\n-        } else if eat_keyword(self, \"copy\") {\n+        } else if self.eat_keyword(\"copy\") {\n             either::right(parse_capture_item(self, false))\n         } else {\n             parse_arg_fn(self)\n@@ -448,8 +449,8 @@ class parser {\n \n     fn parse_arg() -> arg_or_capture_item {\n         let m = self.parse_arg_mode();\n-        let i = parse_value_ident(self);\n-        expect(self, token::COLON);\n+        let i = self.parse_value_ident();\n+        self.expect(token::COLON);\n         let t = self.parse_ty(false);\n         either::left({mode: m, ty: t, ident: i, id: self.get_id()})\n     }\n@@ -461,8 +462,8 @@ class parser {\n     fn parse_fn_block_arg() -> arg_or_capture_item {\n         self.parse_capture_item_or() {|p|\n             let m = p.parse_arg_mode();\n-            let i = parse_value_ident(p);\n-            let t = if eat(p, token::COLON) {\n+            let i = p.parse_value_ident();\n+            let t = if p.eat(token::COLON) {\n                 p.parse_ty(false)\n             } else {\n                 @{id: p.get_id(),\n@@ -486,7 +487,7 @@ class parser {\n               token::LPAREN {\n                 self.bump();\n                 let e = self.parse_expr();\n-                expect(self, token::RPAREN);\n+                self.expect(token::RPAREN);\n                 let hi = self.last_span.hi;\n                 some(mac_aq(mk_sp(lo,hi), e))\n               }\n@@ -533,16 +534,16 @@ class parser {\n           token::LIT_UINT(u, ut) { lit_uint(u, ut) }\n           token::LIT_FLOAT(s, ft) { lit_float(self.get_str(s), ft) }\n           token::LIT_STR(s) { lit_str(self.get_str(s)) }\n-          token::LPAREN { expect(self, token::RPAREN); lit_nil }\n-          _ { unexpected_last(self, tok); }\n+          token::LPAREN { self.expect(token::RPAREN); lit_nil }\n+          _ { self.unexpected_last(tok); }\n         }\n     }\n \n     fn parse_lit() -> lit {\n         let lo = self.span.lo;\n-        let lit = if eat_keyword(self, \"true\") {\n+        let lit = if self.eat_keyword(\"true\") {\n             lit_bool(true)\n-        } else if eat_keyword(self, \"false\") {\n+        } else if self.eat_keyword(\"false\") {\n             lit_bool(false)\n         } else {\n             let tok = self.token;\n@@ -553,15 +554,16 @@ class parser {\n     }\n \n     fn parse_path_without_tps() -> @path {\n-        self.parse_path_without_tps_(parse_ident, parse_ident)\n+        self.parse_path_without_tps_({|p| p.parse_ident()},\n+                                     {|p| p.parse_ident()})\n     }\n \n     fn parse_path_without_tps_(\n         parse_ident: fn(parser) -> ident,\n         parse_last_ident: fn(parser) -> ident) -> @path {\n \n         let lo = self.span.lo;\n-        let global = eat(self, token::MOD_SEP);\n+        let global = self.eat(token::MOD_SEP);\n         let mut ids = [];\n         loop {\n             let is_not_last =\n@@ -570,7 +572,7 @@ class parser {\n \n             if is_not_last {\n                 ids += [parse_ident(self)];\n-                expect(self, token::MOD_SEP);\n+                self.expect(token::MOD_SEP);\n             } else {\n                 ids += [parse_last_ident(self)];\n                 break;\n@@ -581,15 +583,16 @@ class parser {\n     }\n \n     fn parse_value_path() -> @path {\n-        self.parse_path_without_tps_(parse_ident, parse_value_ident)\n+        self.parse_path_without_tps_({|p| p.parse_ident()},\n+                                     {|p| p.parse_value_ident()})\n     }\n \n     fn parse_path_with_tps(colons: bool) -> @path {\n         #debug[\"parse_path_with_tps(colons=%b)\", colons];\n \n         let lo = self.span.lo;\n         let path = self.parse_path_without_tps();\n-        if colons && !eat(self, token::MOD_SEP) {\n+        if colons && !self.eat(token::MOD_SEP) {\n             ret path;\n         }\n \n@@ -604,7 +607,7 @@ class parser {\n             if self.token == token::BINOP(token::SLASH)\n                 && self.look_ahead(1u) == token::BINOP(token::AND) {\n \n-                expect(self, token::BINOP(token::SLASH));\n+                self.expect(token::BINOP(token::SLASH));\n                 some(self.parse_region())\n             } else {\n                 none\n@@ -614,8 +617,8 @@ class parser {\n         // Parse any type parameters which may appear:\n         let tps = {\n             if self.token == token::LT {\n-                parse_seq_lt_gt(some(token::COMMA), self,\n-                                {|p| p.parse_ty(false)})\n+                self.parse_seq_lt_gt(some(token::COMMA),\n+                                     {|p| p.parse_ty(false)})\n             } else {\n                 {node: [], span: path.span}\n             }\n@@ -627,11 +630,11 @@ class parser {\n     }\n \n     fn parse_mutability() -> mutability {\n-        if eat_keyword(self, \"mut\") {\n+        if self.eat_keyword(\"mut\") {\n             m_mutbl\n-        } else if eat_keyword(self, \"mut\") {\n+        } else if self.eat_keyword(\"mut\") {\n             m_mutbl\n-        } else if eat_keyword(self, \"const\") {\n+        } else if self.eat_keyword(\"const\") {\n             m_const\n         } else {\n             m_imm\n@@ -641,8 +644,8 @@ class parser {\n     fn parse_field(sep: token::token) -> field {\n         let lo = self.span.lo;\n         let m = self.parse_mutability();\n-        let i = parse_ident(self);\n-        expect(self, sep);\n+        let i = self.parse_ident();\n+        self.expect(sep);\n         let e = self.parse_expr();\n         ret spanned(lo, e.span.hi, {mutbl: m, ident: i, expr: e});\n     }\n@@ -700,7 +703,7 @@ class parser {\n                 self.bump(); es += [self.parse_expr()];\n             }\n             hi = self.span.hi;\n-            expect(self, token::RPAREN);\n+            self.expect(token::RPAREN);\n \n             // Note: we retain the expr_tup() even for simple\n             // parenthesized expressions, but only for a \"little while\".\n@@ -710,74 +713,74 @@ class parser {\n             ret self.mk_pexpr(lo, hi, expr_tup(es));\n         } else if self.token == token::LBRACE {\n             self.bump();\n-            if is_keyword(self, \"mut\") ||\n+            if self.is_keyword(\"mut\") ||\n                 is_plain_ident(self.token)\n                 && self.look_ahead(1u) == token::COLON {\n                 let mut fields = [self.parse_field(token::COLON)];\n                 let mut base = none;\n                 while self.token != token::RBRACE {\n-                    if eat_keyword(self, \"with\") {\n+                    if self.eat_keyword(\"with\") {\n                         base = some(self.parse_expr()); break;\n                     }\n-                    expect(self, token::COMMA);\n+                    self.expect(token::COMMA);\n                     if self.token == token::RBRACE {\n                         // record ends by an optional trailing comma\n                         break;\n                     }\n                     fields += [self.parse_field(token::COLON)];\n                 }\n                 hi = self.span.hi;\n-                expect(self, token::RBRACE);\n+                self.expect(token::RBRACE);\n                 ex = expr_rec(fields, base);\n             } else if token::is_bar(self.token) {\n                 ret pexpr(self.parse_fn_block_expr());\n             } else {\n                 let blk = self.parse_block_tail(lo, default_blk);\n                 ret self.mk_pexpr(blk.span.lo, blk.span.hi, expr_block(blk));\n             }\n-        } else if eat_keyword(self, \"new\") {\n-            expect(self, token::LPAREN);\n+        } else if self.eat_keyword(\"new\") {\n+            self.expect(token::LPAREN);\n             let r = self.parse_expr();\n-            expect(self, token::RPAREN);\n+            self.expect(token::RPAREN);\n             let v = self.parse_expr();\n             ret self.mk_pexpr(lo, self.span.hi,\n                               expr_new(r, self.get_id(), v));\n-        } else if eat_keyword(self, \"if\") {\n+        } else if self.eat_keyword(\"if\") {\n             ret pexpr(self.parse_if_expr());\n-        } else if eat_keyword(self, \"for\") {\n+        } else if self.eat_keyword(\"for\") {\n             ret pexpr(self.parse_for_expr());\n-        } else if eat_keyword(self, \"while\") {\n+        } else if self.eat_keyword(\"while\") {\n             ret pexpr(self.parse_while_expr());\n-        } else if eat_keyword(self, \"loop\") {\n+        } else if self.eat_keyword(\"loop\") {\n             ret pexpr(self.parse_loop_expr());\n-        } else if eat_keyword(self, \"alt\") {\n+        } else if self.eat_keyword(\"alt\") {\n             ret pexpr(self.parse_alt_expr());\n-        } else if eat_keyword(self, \"fn\") {\n+        } else if self.eat_keyword(\"fn\") {\n             let proto = self.parse_fn_ty_proto();\n             alt proto {\n               proto_bare { self.fatal(\"fn expr are deprecated, use fn@\"); }\n               proto_any { self.fatal(\"fn* cannot be used in an expression\"); }\n               _ { /* fallthrough */ }\n             }\n             ret pexpr(self.parse_fn_expr(proto));\n-        } else if eat_keyword(self, \"unchecked\") {\n+        } else if self.eat_keyword(\"unchecked\") {\n             ret pexpr(self.parse_block_expr(lo, unchecked_blk));\n-        } else if eat_keyword(self, \"unsafe\") {\n+        } else if self.eat_keyword(\"unsafe\") {\n             ret pexpr(self.parse_block_expr(lo, unsafe_blk));\n         } else if self.token == token::LBRACKET {\n             self.bump();\n             let mutbl = self.parse_mutability();\n             let es =\n-                parse_seq_to_end(token::RBRACKET, seq_sep(token::COMMA), self,\n-                                 {|p| p.parse_expr()});\n+                self.parse_seq_to_end(token::RBRACKET, seq_sep(token::COMMA),\n+                                      {|p| p.parse_expr()});\n             hi = self.span.hi;\n             ex = expr_vec(es, mutbl);\n         } else if self.token == token::POUND\n             && self.look_ahead(1u) == token::LT {\n             self.bump();\n             self.bump();\n             let ty = self.parse_ty(false);\n-            expect(self, token::GT);\n+            self.expect(token::GT);\n \n             /* hack: early return to take advantage of specialized function */\n             ret pexpr(self.mk_mac_expr(lo, self.span.hi,\n@@ -796,65 +799,65 @@ class parser {\n             let ex_ext = self.parse_syntax_ext();\n             hi = ex_ext.span.hi;\n             ex = ex_ext.node;\n-        } else if eat_keyword(self, \"bind\") {\n+        } else if self.eat_keyword(\"bind\") {\n             let e = self.parse_expr_res(RESTRICT_NO_CALL_EXPRS);\n-            let es =\n-                parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n-                          self, {|p| p.parse_expr_or_hole()});\n+            let es = self.parse_seq(token::LPAREN, token::RPAREN,\n+                                    seq_sep(token::COMMA),\n+                                    {|p| p.parse_expr_or_hole()});\n             hi = es.span.hi;\n             ex = expr_bind(e, es.node);\n-        } else if eat_keyword(self, \"fail\") {\n+        } else if self.eat_keyword(\"fail\") {\n             if can_begin_expr(self.token) {\n                 let e = self.parse_expr();\n                 hi = e.span.hi;\n                 ex = expr_fail(some(e));\n             } else { ex = expr_fail(none); }\n-        } else if eat_keyword(self, \"log\") {\n-            expect(self, token::LPAREN);\n+        } else if self.eat_keyword(\"log\") {\n+            self.expect(token::LPAREN);\n             let lvl = self.parse_expr();\n-            expect(self, token::COMMA);\n+            self.expect(token::COMMA);\n             let e = self.parse_expr();\n             ex = expr_log(2, lvl, e);\n             hi = self.span.hi;\n-            expect(self, token::RPAREN);\n-        } else if eat_keyword(self, \"assert\") {\n+            self.expect(token::RPAREN);\n+        } else if self.eat_keyword(\"assert\") {\n             let e = self.parse_expr();\n             ex = expr_assert(e);\n             hi = e.span.hi;\n-        } else if eat_keyword(self, \"check\") {\n+        } else if self.eat_keyword(\"check\") {\n             /* Should be a predicate (pure boolean function) applied to\n             arguments that are all either slot variables or literals.\n             but the typechecker enforces that. */\n             let e = self.parse_expr();\n             hi = e.span.hi;\n             ex = expr_check(checked_expr, e);\n-        } else if eat_keyword(self, \"claim\") {\n+        } else if self.eat_keyword(\"claim\") {\n             /* Same rules as check, except that if check-claims\n             is enabled (a command-line flag), then the parser turns\n             claims into check */\n \n             let e = self.parse_expr();\n             hi = e.span.hi;\n             ex = expr_check(claimed_expr, e);\n-        } else if eat_keyword(self, \"ret\") {\n+        } else if self.eat_keyword(\"ret\") {\n             if can_begin_expr(self.token) {\n                 let e = self.parse_expr();\n                 hi = e.span.hi;\n                 ex = expr_ret(some(e));\n             } else { ex = expr_ret(none); }\n-        } else if eat_keyword(self, \"break\") {\n+        } else if self.eat_keyword(\"break\") {\n             ex = expr_break;\n             hi = self.span.hi;\n-        } else if eat_keyword(self, \"cont\") {\n+        } else if self.eat_keyword(\"cont\") {\n             ex = expr_cont;\n             hi = self.span.hi;\n-        } else if eat_keyword(self, \"copy\") {\n+        } else if self.eat_keyword(\"copy\") {\n             let e = self.parse_expr();\n             ex = expr_copy(e);\n             hi = e.span.hi;\n         } else if self.token == token::MOD_SEP ||\n-            is_ident(self.token) && !is_keyword(self, \"true\") &&\n-            !is_keyword(self, \"false\") {\n+            is_ident(self.token) && !self.is_keyword(\"true\") &&\n+            !self.is_keyword(\"false\") {\n             let pth = self.parse_path_with_tps(true);\n             hi = pth.span.hi;\n             ex = expr_path(pth);\n@@ -884,14 +887,14 @@ class parser {\n     }\n \n     fn parse_block_expr(lo: uint, blk_mode: blk_check_mode) -> @expr {\n-        expect(self, token::LBRACE);\n+        self.expect(token::LBRACE);\n         let blk = self.parse_block_tail(lo, blk_mode);\n         ret self.mk_expr(blk.span.lo, blk.span.hi, expr_block(blk));\n     }\n \n     fn parse_syntax_ext() -> @expr {\n         let lo = self.span.lo;\n-        expect(self, token::POUND);\n+        self.expect(token::POUND);\n         ret self.parse_syntax_ext_naked(lo);\n     }\n \n@@ -907,11 +910,11 @@ class parser {\n         if (self.token == token::LPAREN || self.token == token::LBRACKET) {\n             let es =\n                 if self.token == token::LPAREN {\n-                parse_seq(token::LPAREN, token::RPAREN,\n-                          sep, self, {|p| p.parse_expr()})\n+                self.parse_seq(token::LPAREN, token::RPAREN,\n+                               sep, {|p| p.parse_expr()})\n         } else {\n-            parse_seq(token::LBRACKET, token::RBRACKET,\n-                      sep, self, {|p| p.parse_expr()})\n+            self.parse_seq(token::LBRACKET, token::RBRACKET,\n+                           sep, {|p| p.parse_expr()})\n         };\n         let hi = es.span.hi;\n         e = some(self.mk_expr(es.span.lo, hi,\n@@ -952,32 +955,31 @@ class parser {\n         let mut hi;\n         loop {\n             // expr.f\n-            if eat(self, token::DOT) {\n+            if self.eat(token::DOT) {\n                 alt self.token {\n                   token::IDENT(i, _) {\n                     hi = self.span.hi;\n                     self.bump();\n-                    let tys = if eat(self, token::MOD_SEP) {\n-                        expect(self, token::LT);\n-                        parse_seq_to_gt(some(token::COMMA), self,\n+                    let tys = if self.eat(token::MOD_SEP) {\n+                        self.expect(token::LT);\n+                        self.parse_seq_to_gt(some(token::COMMA),\n                                         {|p| p.parse_ty(false)})\n                     } else { [] };\n                     e = self.mk_pexpr(lo, hi, expr_field(self.to_expr(e),\n                                                          self.get_str(i),\n                                                          tys));\n                   }\n-                  _ { unexpected(self); }\n+                  _ { self.unexpected(); }\n                 }\n                 cont;\n             }\n             if self.expr_is_complete(e) { break; }\n             alt self.token {\n               // expr(...)\n               token::LPAREN if self.permits_call() {\n-                let es_opt =\n-                    parse_seq(token::LPAREN, token::RPAREN,\n-                              seq_sep(token::COMMA), self,\n-                              {|p| p.parse_expr_or_hole()});\n+                let es_opt = self.parse_seq(token::LPAREN, token::RPAREN,\n+                                            seq_sep(token::COMMA),\n+                                            {|p| p.parse_expr_or_hole()});\n                 hi = es_opt.span.hi;\n \n                 let nd =\n@@ -1012,7 +1014,7 @@ class parser {\n             self.bump();\n             let ix = self.parse_expr();\n             hi = ix.span.hi;\n-            expect(self, token::RBRACKET);\n+            self.expect(token::RBRACKET);\n             self.get_id(); // see ast_util::op_expr_callee_id\n             e = self.mk_pexpr(lo, hi, expr_index(self.to_expr(e), ix));\n           }\n@@ -1108,7 +1110,7 @@ class parser {\n           }\n           _ {}\n         }\n-        if as_prec > min_prec && eat_keyword(self, \"as\") {\n+        if as_prec > min_prec && self.eat_keyword(\"as\") {\n             let rhs = self.parse_ty(true);\n             let _as =\n                 self.mk_pexpr(lhs.span.lo, rhs.span.hi, expr_cast(lhs, rhs));\n@@ -1171,7 +1173,7 @@ class parser {\n         let thn = self.parse_block();\n         let mut els: option<@expr> = none;\n         let mut hi = thn.span.hi;\n-        if eat_keyword(self, \"else\") {\n+        if self.eat_keyword(\"else\") {\n             let elexpr = self.parse_else_expr();\n             els = some(elexpr);\n             hi = elexpr.span.hi;\n@@ -1180,7 +1182,7 @@ class parser {\n     }\n \n     fn parse_if_expr() -> @expr {\n-        if eat_keyword(self, \"check\") {\n+        if self.eat_keyword(\"check\") {\n             let q = self.parse_if_expr_1();\n             ret self.mk_expr(q.lo, q.hi,\n                              expr_if_check(q.cond, q.then, q.els));\n@@ -1216,7 +1218,7 @@ class parser {\n     }\n \n     fn parse_else_expr() -> @expr {\n-        if eat_keyword(self, \"if\") {\n+        if self.eat_keyword(\"if\") {\n             ret self.parse_if_expr();\n         } else {\n             let blk = self.parse_block();\n@@ -1258,15 +1260,15 @@ class parser {\n \n     fn parse_alt_expr() -> @expr {\n         let lo = self.last_span.lo;\n-        let mode = if eat_keyword(self, \"check\") { alt_check }\n+        let mode = if self.eat_keyword(\"check\") { alt_check }\n         else { alt_exhaustive };\n         let discriminant = self.parse_expr();\n-        expect(self, token::LBRACE);\n+        self.expect(token::LBRACE);\n         let mut arms: [arm] = [];\n         while self.token != token::RBRACE {\n             let pats = self.parse_pats();\n             let mut guard = none;\n-            if eat_keyword(self, \"if\") { guard = some(self.parse_expr()); }\n+            if self.eat_keyword(\"if\") { guard = some(self.parse_expr()); }\n             let blk = self.parse_block();\n             arms += [{pats: pats, guard: guard, body: blk}];\n         }\n@@ -1351,7 +1353,7 @@ class parser {\n             let mut first = true;\n             while self.token != token::RBRACE {\n                 if first { first = false; }\n-                else { expect(self, token::COMMA); }\n+                else { self.expect(token::COMMA); }\n \n                 if self.token == token::UNDERSCORE {\n                     self.bump();\n@@ -1365,9 +1367,9 @@ class parser {\n \n                 let lo1 = self.last_span.lo;\n                 let fieldname = if self.look_ahead(1u) == token::COLON {\n-                    parse_ident(self)\n+                    self.parse_ident()\n                 } else {\n-                    parse_value_ident(self)\n+                    self.parse_value_ident()\n                 };\n                 let hi1 = self.last_span.lo;\n                 let fieldpath = ast_util::ident_to_path(mk_sp(lo1, hi1),\n@@ -1401,17 +1403,17 @@ class parser {\n                     self.bump();\n                     fields += [self.parse_pat()];\n                 }\n-                if vec::len(fields) == 1u { expect(self, token::COMMA); }\n+                if vec::len(fields) == 1u { self.expect(token::COMMA); }\n                 hi = self.span.hi;\n-                expect(self, token::RPAREN);\n+                self.expect(token::RPAREN);\n                 pat = pat_tup(fields);\n             }\n           }\n           tok {\n-            if !is_ident(tok) || is_keyword(self, \"true\")\n-                || is_keyword(self, \"false\") {\n+            if !is_ident(tok) || self.is_keyword(\"true\")\n+                || self.is_keyword(\"false\") {\n                 let val = self.parse_expr_res(RESTRICT_NO_BAR_OP);\n-                if eat_keyword(self, \"to\") {\n+                if self.eat_keyword(\"to\") {\n                     let end = self.parse_expr_res(RESTRICT_NO_BAR_OP);\n                     hi = end.span.hi;\n                     pat = pat_range(val, end);\n@@ -1425,7 +1427,7 @@ class parser {\n                   _ { true }\n                 } {\n                 let name = self.parse_value_path();\n-                let sub = if eat(self, token::AT) { some(self.parse_pat()) }\n+                let sub = if self.eat(token::AT) { some(self.parse_pat()) }\n                 else { none };\n                 pat = pat_ident(name, sub);\n             } else {\n@@ -1440,12 +1442,12 @@ class parser {\n                         // This is a \"top constructor only\" pat\n                         self.bump(); self.bump();\n                         star_pat = true;\n-                        expect(self, token::RPAREN);\n+                        self.expect(token::RPAREN);\n                       }\n                       _ {\n-                        let a = parse_seq(token::LPAREN, token::RPAREN,\n-                                          seq_sep(token::COMMA), self,\n-                                          {|p| p.parse_pat()});\n+                        let a = self.parse_seq(token::LPAREN, token::RPAREN,\n+                                               seq_sep(token::COMMA),\n+                                               {|p| p.parse_pat()});\n                         args = a.node;\n                         hi = a.span.hi;\n                       }\n@@ -1477,18 +1479,18 @@ class parser {\n         let mut ty = @{id: self.get_id(),\n                        node: ty_infer,\n                        span: mk_sp(lo, lo)};\n-        if eat(self, token::COLON) { ty = self.parse_ty(false); }\n+        if self.eat(token::COLON) { ty = self.parse_ty(false); }\n         let init = if allow_init { self.parse_initializer() } else { none };\n         ret @spanned(lo, self.last_span.hi,\n                      {is_mutbl: is_mutbl, ty: ty, pat: pat,\n                       init: init, id: self.get_id()});\n     }\n \n     fn parse_let() -> @decl {\n-        let is_mutbl = eat_keyword(self, \"mut\");\n+        let is_mutbl = self.eat_keyword(\"mut\");\n         let lo = self.span.lo;\n         let mut locals = [self.parse_local(is_mutbl, true)];\n-        while eat(self, token::COMMA) {\n+        while self.eat(token::COMMA) {\n             locals += [self.parse_local(is_mutbl, true)];\n         }\n         ret @spanned(lo, self.last_span.hi, decl_local(locals));\n@@ -1498,14 +1500,14 @@ class parser {\n     fn parse_instance_var(pr: visibility) -> @class_member {\n         let mut is_mutbl = class_immutable;\n         let lo = self.span.lo;\n-        if eat_keyword(self, \"mut\") {\n+        if self.eat_keyword(\"mut\") {\n             is_mutbl = class_mutable;\n         }\n         if !is_plain_ident(self.token) {\n             self.fatal(\"expecting ident\");\n         }\n-        let name = parse_ident(self);\n-        expect(self, token::COLON);\n+        let name = self.parse_ident();\n+        self.expect(token::COLON);\n         let ty = self.parse_ty(false);\n         ret @{node: instance_var(name, ty, is_mutbl, self.get_id(), pr),\n               span: mk_sp(lo, self.last_span.hi)};\n@@ -1520,9 +1522,9 @@ class parser {\n         }\n \n         let lo = self.span.lo;\n-        if is_keyword(self, \"let\") {\n+        if self.is_keyword(\"let\") {\n             check_expected_item(self, first_item_attrs);\n-            expect_keyword(self, \"let\");\n+            self.expect_keyword(\"let\");\n             let decl = self.parse_let();\n             ret @spanned(lo, decl.span.hi, stmt_decl(decl, self.get_id()));\n         } else {\n@@ -1580,18 +1582,18 @@ class parser {\n         }\n \n         let lo = self.span.lo;\n-        if eat_keyword(self, \"unchecked\") {\n-            expect(self, token::LBRACE);\n+        if self.eat_keyword(\"unchecked\") {\n+            self.expect(token::LBRACE);\n             let {inner, next} = maybe_parse_inner_attrs_and_next(self,\n                                                                  parse_attrs);\n             ret (inner, self.parse_block_tail_(lo, unchecked_blk, next));\n-        } else if eat_keyword(self, \"unsafe\") {\n-            expect(self, token::LBRACE);\n+        } else if self.eat_keyword(\"unsafe\") {\n+            self.expect(token::LBRACE);\n             let {inner, next} = maybe_parse_inner_attrs_and_next(self,\n                                                                  parse_attrs);\n             ret (inner, self.parse_block_tail_(lo, unsafe_blk, next));\n         } else {\n-            expect(self, token::LBRACE);\n+            self.expect(token::LBRACE);\n             let {inner, next} = maybe_parse_inner_attrs_and_next(self,\n                                                                  parse_attrs);\n             ret (inner, self.parse_block_tail_(lo, default_blk, next));\n@@ -1658,7 +1660,7 @@ class parser {\n                     stmts += [stmt];\n \n                     if classify::stmt_ends_with_semi(*stmt) {\n-                        expect(self, token::SEMI);\n+                        self.expect(token::SEMI);\n                     }\n                   }\n                 }\n@@ -1674,28 +1676,27 @@ class parser {\n \n     fn parse_ty_param() -> ty_param {\n         let mut bounds = [];\n-        let ident = parse_ident(self);\n-        if eat(self, token::COLON) {\n+        let ident = self.parse_ident();\n+        if self.eat(token::COLON) {\n             while self.token != token::COMMA && self.token != token::GT {\n-                if eat_keyword(self, \"send\") { bounds += [bound_send]; }\n-                else if eat_keyword(self, \"copy\") { bounds += [bound_copy]; }\n+                if self.eat_keyword(\"send\") { bounds += [bound_send]; }\n+                else if self.eat_keyword(\"copy\") { bounds += [bound_copy]; }\n                 else { bounds += [bound_iface(self.parse_ty(false))]; }\n             }\n         }\n         ret {ident: ident, id: self.get_id(), bounds: @bounds};\n     }\n \n     fn parse_ty_params() -> [ty_param] {\n-        if eat(self, token::LT) {\n-            parse_seq_to_gt(some(token::COMMA), self,\n-                            {|p| p.parse_ty_param()})\n+        if self.eat(token::LT) {\n+            self.parse_seq_to_gt(some(token::COMMA), {|p| p.parse_ty_param()})\n         } else { [] }\n     }\n \n     // FIXME Remove after snapshot\n     fn parse_old_skool_capture_clause() -> [capture_item] {\n         fn expect_opt_trailing_semi(p: parser) {\n-            if !eat(p, token::SEMI) {\n+            if !p.eat(token::SEMI) {\n                 if p.token != token::RBRACKET {\n                     p.fatal(\"expecting ; or ]\");\n                 }\n@@ -1709,9 +1710,9 @@ class parser {\n                   token::IDENT(_, _) {\n                     let id = p.get_id();\n                     let sp = mk_sp(p.span.lo, p.span.hi);\n-                    let ident = parse_ident(p);\n+                    let ident = p.parse_ident();\n                     res += [@{id:id, is_move: is_move, name:ident, span:sp}];\n-                    if !eat(p, token::COMMA) {\n+                    if !p.eat(token::COMMA) {\n                         ret res;\n                     }\n                   }\n@@ -1723,12 +1724,12 @@ class parser {\n \n         let mut cap_items = [];\n \n-        if eat(self, token::LBRACKET) {\n-            while !eat(self, token::RBRACKET) {\n-                if eat_keyword(self, \"copy\") {\n+        if self.eat(token::LBRACKET) {\n+            while !self.eat(token::RBRACKET) {\n+                if self.eat_keyword(\"copy\") {\n                     cap_items += eat_ident_list(self, false);\n                     expect_opt_trailing_semi(self);\n-                } else if eat_keyword(self, \"move\") {\n+                } else if self.eat_keyword(\"move\") {\n                     cap_items += eat_ident_list(self, true);\n                     expect_opt_trailing_semi(self);\n                 } else {\n@@ -1746,8 +1747,8 @@ class parser {\n         -> (fn_decl, capture_clause) {\n \n         let args_or_capture_items: [arg_or_capture_item] =\n-            parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n-                      self, parse_arg_fn).node;\n+            self.parse_seq(token::LPAREN, token::RPAREN,\n+                           seq_sep(token::COMMA), parse_arg_fn).node;\n \n         let inputs = either::lefts(args_or_capture_items);\n         let capture_clause = @either::rights(args_or_capture_items);\n@@ -1770,15 +1771,15 @@ class parser {\n \n     fn parse_fn_block_decl() -> (fn_decl, capture_clause) {\n         let inputs_captures = {\n-            if eat(self, token::OROR) {\n+            if self.eat(token::OROR) {\n                 []\n             } else {\n-                parse_seq(token::BINOP(token::OR), token::BINOP(token::OR),\n-                          seq_sep(token::COMMA), self,\n-                          {|p| p.parse_fn_block_arg()}).node\n+                self.parse_seq(token::BINOP(token::OR),\n+                               token::BINOP(token::OR), seq_sep(token::COMMA),\n+                               {|p| p.parse_fn_block_arg()}).node\n             }\n         };\n-        let output = if eat(self, token::RARROW) {\n+        let output = if self.eat(token::RARROW) {\n             self.parse_ty(false)\n         } else {\n             @{id: self.get_id(), node: ty_infer, span: self.span}\n@@ -1792,7 +1793,7 @@ class parser {\n     }\n \n     fn parse_fn_header() -> {ident: ident, tps: [ty_param]} {\n-        let id = parse_value_ident(self);\n+        let id = self.parse_value_ident();\n         let ty_params = self.parse_ty_params();\n         ret {ident: id, tps: ty_params};\n     }\n@@ -1819,10 +1820,10 @@ class parser {\n         alt self.token {\n           token::BINOP(op) { self.bump(); token::binop_to_str(op) }\n           token::NOT { self.bump(); \"!\" }\n-          token::LBRACKET { self.bump(); expect(self, token::RBRACKET); \"[]\" }\n+          token::LBRACKET { self.bump(); self.expect(token::RBRACKET); \"[]\" }\n           _ {\n-            let id = parse_value_ident(self);\n-            if id == \"unary\" && eat(self, token::BINOP(token::MINUS)) {\n+            let id = self.parse_value_ident();\n+            if id == \"unary\" && self.eat(token::BINOP(token::MINUS)) {\n                 \"unary-\"\n             }\n             else { id }\n@@ -1844,7 +1845,7 @@ class parser {\n     }\n \n     fn parse_item_iface() -> item_info {\n-        let ident = parse_ident(self);\n+        let ident = self.parse_ident();\n         let rp = self.parse_region_param();\n         let tps = self.parse_ty_params();\n         let meths = self.parse_ty_methods();\n@@ -1865,15 +1866,15 @@ class parser {\n             } else if self.token == token::BINOP(token::SLASH) {\n                 (none, self.parse_region_param(), self.parse_ty_params())\n             }\n-            else if is_keyword(self, \"of\") {\n+            else if self.is_keyword(\"of\") {\n                 (none, rp_none, [])\n             } else {\n-                let id = parse_ident(self);\n+                let id = self.parse_ident();\n                 let rp = self.parse_region_param();\n                 (some(id), rp, self.parse_ty_params())\n             }\n         };\n-        let ifce = if eat_keyword(self, \"of\") {\n+        let ifce = if self.eat_keyword(\"of\") {\n             let path = self.parse_path_with_tps(false);\n             if option::is_none(ident) {\n                 ident = some(vec::last(path.idents));\n@@ -1882,27 +1883,27 @@ class parser {\n         } else { none };\n         let ident = alt ident {\n           some(name) { name }\n-          none { expect_keyword(self, \"of\"); fail; }\n+          none { self.expect_keyword(\"of\"); fail; }\n         };\n-        expect_keyword(self, \"for\");\n+        self.expect_keyword(\"for\");\n         let ty = self.parse_ty(false);\n         let mut meths = [];\n-        expect(self, token::LBRACE);\n-        while !eat(self, token::RBRACE) {\n+        self.expect(token::LBRACE);\n+        while !self.eat(token::RBRACE) {\n             meths += [self.parse_method(public)];\n         }\n         (ident, item_impl(tps, rp, ifce, ty, meths), none)\n     }\n \n     fn parse_item_res() -> item_info {\n-        let ident = parse_value_ident(self);\n+        let ident = self.parse_value_ident();\n         let rp = self.parse_region_param();\n         let ty_params = self.parse_ty_params();\n-        expect(self, token::LPAREN);\n-        let arg_ident = parse_value_ident(self);\n-        expect(self, token::COLON);\n+        self.expect(token::LPAREN);\n+        let arg_ident = self.parse_value_ident();\n+        self.expect(token::COLON);\n         let t = self.parse_ty(false);\n-        expect(self, token::RPAREN);\n+        self.expect(token::RPAREN);\n         let dtor = self.parse_block_no_value();\n         let decl = {\n             inputs: [{mode: expl(by_ref), ty: t,\n@@ -1946,19 +1947,19 @@ class parser {\n     }\n \n     fn parse_iface_ref_list() -> [@iface_ref] {\n-        parse_seq_to_before_end(token::LBRACE, seq_sep(token::COMMA), self,\n-                                {|p| p.parse_iface_ref()})\n+        self.parse_seq_to_before_end(token::LBRACE, seq_sep(token::COMMA),\n+                                     {|p| p.parse_iface_ref()})\n     }\n \n     fn parse_item_class() -> item_info {\n-        let class_name = parse_value_ident(self);\n+        let class_name = self.parse_value_ident();\n         let rp = self.parse_region_param();\n         let ty_params = self.parse_ty_params();\n         let class_path = self.ident_to_path_tys(class_name, rp, ty_params);\n-        let ifaces : [@iface_ref] = if eat_keyword(self, \"implements\")\n+        let ifaces : [@iface_ref] = if self.eat_keyword(\"implements\")\n             { self.parse_iface_ref_list() }\n         else { [] };\n-        expect(self, token::LBRACE);\n+        self.expect(token::LBRACE);\n         let mut ms: [@class_member] = [];\n         let ctor_id = self.get_id();\n         let mut the_ctor : option<(fn_decl, blk, codemap::span)> = none;\n@@ -2003,9 +2004,9 @@ class parser {\n \n     fn parse_single_class_item(vis: visibility)\n         -> @class_member {\n-        if eat_keyword(self, \"let\") {\n+        if self.eat_keyword(\"let\") {\n             let a_var = self.parse_instance_var(vis);\n-            expect(self, token::SEMI);\n+            self.expect(token::SEMI);\n             ret a_var;\n         }\n         else {\n@@ -2034,16 +2035,16 @@ class parser {\n \n     fn parse_class_item(class_name_with_tps: @path)\n         -> class_contents {\n-        if eat_keyword(self, \"new\") {\n+        if self.eat_keyword(\"new\") {\n             // result type is always the type of the class\n             ret self.parse_ctor(ty_path(class_name_with_tps,\n                                         self.get_id()));\n         }\n-        else if eat_keyword(self, \"drop\") {\n+        else if self.eat_keyword(\"drop\") {\n             ret self.parse_dtor();\n         }\n-        else if eat_keyword(self, \"priv\") {\n-            expect(self, token::LBRACE);\n+        else if self.eat_keyword(\"priv\") {\n+            self.expect(token::LBRACE);\n         let mut results = [];\n         while self.token != token::RBRACE {\n             results += [self.parse_single_class_item(private)];\n@@ -2058,8 +2059,8 @@ class parser {\n }\n \n     fn parse_visibility(def: visibility) -> visibility {\n-        if eat_keyword(self, \"pub\") { public }\n-        else if eat_keyword(self, \"priv\") { private }\n+        if self.eat_keyword(\"pub\") { public }\n+        else if self.eat_keyword(\"priv\") { private }\n         else { def }\n     }\n \n@@ -2094,21 +2095,21 @@ class parser {\n     }\n \n     fn parse_item_const() -> item_info {\n-        let id = parse_value_ident(self);\n-        expect(self, token::COLON);\n+        let id = self.parse_value_ident();\n+        self.expect(token::COLON);\n         let ty = self.parse_ty(false);\n-        expect(self, token::EQ);\n+        self.expect(token::EQ);\n         let e = self.parse_expr();\n-        expect(self, token::SEMI);\n+        self.expect(token::SEMI);\n         (id, item_const(ty, e), none)\n     }\n \n     fn parse_item_mod() -> item_info {\n-        let id = parse_ident(self);\n-        expect(self, token::LBRACE);\n+        let id = self.parse_ident();\n+        self.expect(token::LBRACE);\n         let inner_attrs = parse_inner_attrs_and_next(self);\n         let m = self.parse_mod_items(token::RBRACE, inner_attrs.next);\n-        expect(self, token::RBRACE);\n+        self.expect(token::RBRACE);\n         (id, item_mod(m), some(inner_attrs.inner))\n     }\n \n@@ -2118,7 +2119,7 @@ class parser {\n         let t = self.parse_fn_header();\n         let (decl, _) = self.parse_fn_decl(purity, {|p| p.parse_arg()});\n         let mut hi = self.span.hi;\n-        expect(self, token::SEMI);\n+        self.expect(token::SEMI);\n         ret @{ident: t.ident,\n               attrs: attrs,\n               node: native_item_fn(decl, t.tps),\n@@ -2127,15 +2128,15 @@ class parser {\n     }\n \n     fn parse_fn_purity() -> purity {\n-        if eat_keyword(self, \"fn\") { impure_fn }\n-        else if eat_keyword(self, \"pure\") {\n-            expect_keyword(self, \"fn\");\n+        if self.eat_keyword(\"fn\") { impure_fn }\n+        else if self.eat_keyword(\"pure\") {\n+            self.expect_keyword(\"fn\");\n             pure_fn\n-        } else if eat_keyword(self, \"unsafe\") {\n-            expect_keyword(self, \"fn\");\n+        } else if self.eat_keyword(\"unsafe\") {\n+            self.expect_keyword(\"fn\");\n             unsafe_fn\n         }\n-        else { unexpected(self); }\n+        else { self.unexpected(); }\n     }\n \n     fn parse_native_item(+attrs: [attribute]) ->\n@@ -2160,51 +2161,51 @@ class parser {\n     }\n \n     fn parse_item_native_mod() -> item_info {\n-        expect_keyword(self, \"mod\");\n-        let id = parse_ident(self);\n-        expect(self, token::LBRACE);\n+        self.expect_keyword(\"mod\");\n+        let id = self.parse_ident();\n+        self.expect(token::LBRACE);\n         let more_attrs = parse_inner_attrs_and_next(self);\n         let m = self.parse_native_mod_items(more_attrs.next);\n-        expect(self, token::RBRACE);\n+        self.expect(token::RBRACE);\n         (id, item_native_mod(m), some(more_attrs.inner))\n     }\n \n     fn parse_type_decl() -> {lo: uint, ident: ident} {\n         let lo = self.last_span.lo;\n-        let id = parse_ident(self);\n+        let id = self.parse_ident();\n         ret {lo: lo, ident: id};\n     }\n \n     fn parse_item_type() -> item_info {\n         let t = self.parse_type_decl();\n         let rp = self.parse_region_param();\n         let tps = self.parse_ty_params();\n-        expect(self, token::EQ);\n+        self.expect(token::EQ);\n         let ty = self.parse_ty(false);\n-        expect(self, token::SEMI);\n+        self.expect(token::SEMI);\n         (t.ident, item_ty(ty, tps, rp), none)\n     }\n \n     fn parse_region_param() -> region_param {\n-        if eat(self, token::BINOP(token::SLASH)) {\n-            expect(self, token::BINOP(token::AND));\n+        if self.eat(token::BINOP(token::SLASH)) {\n+            self.expect(token::BINOP(token::AND));\n             rp_self\n         } else {\n             rp_none\n         }\n     }\n \n     fn parse_item_enum(default_vis: visibility) -> item_info {\n-        let id = parse_ident(self);\n+        let id = self.parse_ident();\n         let rp = self.parse_region_param();\n         let ty_params = self.parse_ty_params();\n         let mut variants: [variant] = [];\n         // Newtype syntax\n         if self.token == token::EQ {\n-            check_restricted_keywords_(self, id);\n+            self.check_restricted_keywords_(id);\n             self.bump();\n             let ty = self.parse_ty(false);\n-            expect(self, token::SEMI);\n+            self.expect(token::SEMI);\n             let variant =\n                 spanned(ty.span.lo, ty.span.hi,\n                         {name: id,\n@@ -2215,25 +2216,25 @@ class parser {\n                          vis: public});\n             ret (id, item_enum([variant], ty_params, rp), none);\n         }\n-        expect(self, token::LBRACE);\n+        self.expect(token::LBRACE);\n \n         let mut all_nullary = true, have_disr = false;\n \n         while self.token != token::RBRACE {\n             let variant_attrs = parse_outer_attributes(self);\n             let vlo = self.span.lo;\n             let vis = self.parse_visibility(default_vis);\n-            let ident = parse_value_ident(self);\n+            let ident = self.parse_value_ident();\n             let mut args = [], disr_expr = none;\n             if self.token == token::LPAREN {\n                 all_nullary = false;\n-                let arg_tys = parse_seq(token::LPAREN, token::RPAREN,\n-                                        seq_sep(token::COMMA), self,\n-                                        {|p| p.parse_ty(false)});\n+                let arg_tys = self.parse_seq(token::LPAREN, token::RPAREN,\n+                                             seq_sep(token::COMMA),\n+                                             {|p| p.parse_ty(false)});\n                 for arg_tys.node.each {|ty|\n                     args += [{ty: ty, id: self.get_id()}];\n                 }\n-            } else if eat(self, token::EQ) {\n+            } else if self.eat(token::EQ) {\n                 have_disr = true;\n                 disr_expr = some(self.parse_expr());\n             }\n@@ -2243,9 +2244,9 @@ class parser {\n                       disr_expr: disr_expr, vis: vis};\n             variants += [spanned(vlo, self.last_span.hi, vr)];\n \n-            if !eat(self, token::COMMA) { break; }\n+            if !self.eat(token::COMMA) { break; }\n         }\n-        expect(self, token::RBRACE);\n+        self.expect(token::RBRACE);\n         if (have_disr && !all_nullary) {\n             self.fatal(\"discriminator values can only be used with a c-like \\\n                         enum\");\n@@ -2287,38 +2288,38 @@ class parser {\n     fn parse_item(+attrs: [attribute], vis: visibility)\n         -> option<@item> {\n         let lo = self.span.lo;\n-        let (ident, item_, extra_attrs) = if eat_keyword(self, \"const\") {\n+        let (ident, item_, extra_attrs) = if self.eat_keyword(\"const\") {\n             self.parse_item_const()\n-        } else if is_keyword(self, \"fn\") &&\n+        } else if self.is_keyword(\"fn\") &&\n             !self.fn_expr_lookahead(self.look_ahead(1u)) {\n             self.bump();\n             self.parse_item_fn(impure_fn)\n-        } else if eat_keyword(self, \"pure\") {\n-            expect_keyword(self, \"fn\");\n+        } else if self.eat_keyword(\"pure\") {\n+            self.expect_keyword(\"fn\");\n             self.parse_item_fn(pure_fn)\n-        } else if is_keyword(self, \"unsafe\")\n+        } else if self.is_keyword(\"unsafe\")\n             && self.look_ahead(1u) != token::LBRACE {\n             self.bump();\n-            expect_keyword(self, \"fn\");\n+            self.expect_keyword(\"fn\");\n             self.parse_item_fn(unsafe_fn)\n-        } else if eat_keyword(self, \"crust\") {\n-            expect_keyword(self, \"fn\");\n+        } else if self.eat_keyword(\"crust\") {\n+            self.expect_keyword(\"fn\");\n             self.parse_item_fn(crust_fn)\n-        } else if eat_keyword(self, \"mod\") {\n+        } else if self.eat_keyword(\"mod\") {\n             self.parse_item_mod()\n-        } else if eat_keyword(self, \"native\") {\n+        } else if self.eat_keyword(\"native\") {\n             self.parse_item_native_mod()\n-        } else if eat_keyword(self, \"type\") {\n+        } else if self.eat_keyword(\"type\") {\n             self.parse_item_type()\n-        } else if eat_keyword(self, \"enum\") {\n+        } else if self.eat_keyword(\"enum\") {\n             self.parse_item_enum(vis)\n-        } else if eat_keyword(self, \"iface\") {\n+        } else if self.eat_keyword(\"iface\") {\n             self.parse_item_iface()\n-        } else if eat_keyword(self, \"impl\") {\n+        } else if self.eat_keyword(\"impl\") {\n             self.parse_item_impl()\n-        } else if eat_keyword(self, \"resource\") {\n+        } else if self.eat_keyword(\"resource\") {\n             self.parse_item_res()\n-        } else if eat_keyword(self, \"class\") {\n+        } else if self.eat_keyword(\"class\") {\n             self.parse_item_class()\n         } else { ret none; };\n         some(self.mk_item(lo, self.last_span.hi, ident, item_, vis,\n@@ -2329,24 +2330,24 @@ class parser {\n     }\n \n     fn parse_use() -> view_item_ {\n-        let ident = parse_ident(self);\n+        let ident = self.parse_ident();\n         let metadata = parse_optional_meta(self);\n         ret view_item_use(ident, metadata, self.get_id());\n     }\n \n     fn parse_view_path() -> @view_path {\n         let lo = self.span.lo;\n-        let first_ident = parse_ident(self);\n+        let first_ident = self.parse_ident();\n         let mut path = [first_ident];\n         #debug(\"parsed view_path: %s\", first_ident);\n         alt self.token {\n           token::EQ {\n             // x = foo::bar\n             self.bump();\n-            path = [parse_ident(self)];\n+            path = [self.parse_ident()];\n             while self.token == token::MOD_SEP {\n                 self.bump();\n-                let id = parse_ident(self);\n+                let id = self.parse_ident();\n                 path += [id];\n             }\n             let path = @{span: mk_sp(lo, self.span.hi), global: false,\n@@ -2370,9 +2371,9 @@ class parser {\n                   // foo::bar::{a,b,c}\n                   token::LBRACE {\n                     let idents =\n-                        parse_seq(token::LBRACE, token::RBRACE,\n-                                  seq_sep(token::COMMA), self,\n-                                  {|p| parse_path_list_ident(p)}).node;\n+                        self.parse_seq(token::LBRACE, token::RBRACE,\n+                                       seq_sep(token::COMMA),\n+                                       {|p| p.parse_path_list_ident()}).node;\n                     let path = @{span: mk_sp(lo, self.span.hi),\n                                  global: false, idents: path,\n                                  rp: none, types: []};\n@@ -2413,24 +2414,24 @@ class parser {\n     }\n \n     fn is_view_item() -> bool {\n-        let tok = if !is_keyword(self, \"pub\") && !is_keyword(self, \"priv\") {\n+        let tok = if !self.is_keyword(\"pub\") && !self.is_keyword(\"priv\") {\n             self.token\n         } else { self.look_ahead(1u) };\n-        token_is_keyword(self, \"use\", tok)\n-            || token_is_keyword(self, \"import\", tok)\n-            || token_is_keyword(self, \"export\", tok)\n+        self.token_is_keyword(\"use\", tok)\n+            || self.token_is_keyword(\"import\", tok)\n+            || self.token_is_keyword(\"export\", tok)\n     }\n \n     fn parse_view_item(+attrs: [attribute]) -> @view_item {\n         let lo = self.span.lo, vis = self.parse_visibility(private);\n-        let node = if eat_keyword(self, \"use\") {\n+        let node = if self.eat_keyword(\"use\") {\n             self.parse_use()\n-        } else if eat_keyword(self, \"import\") {\n+        } else if self.eat_keyword(\"import\") {\n             view_item_import(self.parse_view_paths())\n-        } else if eat_keyword(self, \"export\") {\n+        } else if self.eat_keyword(\"export\") {\n             view_item_export(self.parse_view_paths())\n         } else { fail; };\n-        expect(self, token::SEMI);\n+        self.expect(token::SEMI);\n         @{node: node, attrs: attrs,\n           vis: vis, span: mk_sp(lo, self.last_span.hi)}\n     }\n@@ -2440,7 +2441,7 @@ class parser {\n                                           view_items: [@view_item]} {\n         let mut attrs = first_item_attrs + parse_outer_attributes(self);\n         let mut items = [];\n-        while if only_imports { is_keyword(self, \"import\") }\n+        while if only_imports { self.is_keyword(\"import\") }\n         else { self.is_view_item() } {\n             items += [self.parse_view_item(attrs)];\n             attrs = parse_outer_attributes(self);\n@@ -2485,9 +2486,9 @@ class parser {\n         let expect_mod = vec::len(outer_attrs) > 0u;\n \n         let lo = self.span.lo;\n-        if expect_mod || is_keyword(self, \"mod\") {\n-            expect_keyword(self, \"mod\");\n-            let id = parse_ident(self);\n+        if expect_mod || self.is_keyword(\"mod\") {\n+            self.expect_keyword(\"mod\");\n+            let id = self.parse_ident();\n             alt self.token {\n               // mod x = \"foo.rs\";\n               token::SEMI {\n@@ -2504,11 +2505,11 @@ class parser {\n                 let cdirs = self.parse_crate_directives(token::RBRACE,\n                                                         next_outer_attr);\n                 let mut hi = self.span.hi;\n-                expect(self, token::RBRACE);\n+                self.expect(token::RBRACE);\n                 ret spanned(lo, hi,\n                             cdir_dir_mod(id, cdirs, mod_attrs));\n               }\n-              _ { unexpected(self); }\n+              _ { self.unexpected(); }\n             }\n         } else if self.is_view_item() {\n             let vi = self.parse_view_item(outer_attrs);\n@@ -2524,7 +2525,7 @@ class parser {\n         // accept seeing the terminator next, so if we do see it then fail the\n         // same way parse_crate_directive would\n         if vec::len(first_outer_attr) > 0u && self.token == term {\n-            expect_keyword(self, \"mod\");\n+            self.expect_keyword(\"mod\");\n         }\n \n         let mut cdirs: [@crate_directive] = [];"}]}