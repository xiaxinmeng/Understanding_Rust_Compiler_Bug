{"sha": "ced33ad289abc621472fb0cdca9d5f09cafdadf8", "node_id": "C_kwDOAAsO6NoAKGNlZDMzYWQyODlhYmM2MjE0NzJmYjBjZGNhOWQ1ZjA5Y2FmZGFkZjg", "commit": {"author": {"name": "John K\u00e5re Alsaker", "email": "john.kare.alsaker@gmail.com", "date": "2023-03-13T19:52:25Z"}, "committer": {"name": "John K\u00e5re Alsaker", "email": "john.kare.alsaker@gmail.com", "date": "2023-03-21T02:29:19Z"}, "message": "Refactor `try_execute_query`", "tree": {"sha": "242994bee07d565f16760ccc88882dd7f4f5f1b7", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/242994bee07d565f16760ccc88882dd7f4f5f1b7"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ced33ad289abc621472fb0cdca9d5f09cafdadf8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ced33ad289abc621472fb0cdca9d5f09cafdadf8", "html_url": "https://github.com/rust-lang/rust/commit/ced33ad289abc621472fb0cdca9d5f09cafdadf8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ced33ad289abc621472fb0cdca9d5f09cafdadf8/comments", "author": {"login": "Zoxc", "id": 25784, "node_id": "MDQ6VXNlcjI1Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/25784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zoxc", "html_url": "https://github.com/Zoxc", "followers_url": "https://api.github.com/users/Zoxc/followers", "following_url": "https://api.github.com/users/Zoxc/following{/other_user}", "gists_url": "https://api.github.com/users/Zoxc/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zoxc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zoxc/subscriptions", "organizations_url": "https://api.github.com/users/Zoxc/orgs", "repos_url": "https://api.github.com/users/Zoxc/repos", "events_url": "https://api.github.com/users/Zoxc/events{/privacy}", "received_events_url": "https://api.github.com/users/Zoxc/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Zoxc", "id": 25784, "node_id": "MDQ6VXNlcjI1Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/25784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zoxc", "html_url": "https://github.com/Zoxc", "followers_url": "https://api.github.com/users/Zoxc/followers", "following_url": "https://api.github.com/users/Zoxc/following{/other_user}", "gists_url": "https://api.github.com/users/Zoxc/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zoxc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zoxc/subscriptions", "organizations_url": "https://api.github.com/users/Zoxc/orgs", "repos_url": "https://api.github.com/users/Zoxc/repos", "events_url": "https://api.github.com/users/Zoxc/events{/privacy}", "received_events_url": "https://api.github.com/users/Zoxc/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "822c10feb7d594f324d0160bef47ed999769a789", "url": "https://api.github.com/repos/rust-lang/rust/commits/822c10feb7d594f324d0160bef47ed999769a789", "html_url": "https://github.com/rust-lang/rust/commit/822c10feb7d594f324d0160bef47ed999769a789"}], "stats": {"total": 268, "additions": 134, "deletions": 134}, "files": [{"sha": "c9bc2240c2117ee1fe609075dd7b0f59a076dc94", "filename": "compiler/rustc_query_system/src/query/job.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ced33ad289abc621472fb0cdca9d5f09cafdadf8/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ced33ad289abc621472fb0cdca9d5f09cafdadf8/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs?ref=ced33ad289abc621472fb0cdca9d5f09cafdadf8", "patch": "@@ -124,8 +124,6 @@ impl<D: DepKind> QueryJob<D> {\n }\n \n impl QueryJobId {\n-    #[cold]\n-    #[inline(never)]\n     #[cfg(not(parallel_compiler))]\n     pub(super) fn find_cycle_in_stack<D: DepKind>(\n         &self,"}, {"sha": "ac9933582b44715e7ad208d0f51c898013821313", "filename": "compiler/rustc_query_system/src/query/plumbing.rs", "status": "modified", "additions": 134, "deletions": 132, "changes": 266, "blob_url": "https://github.com/rust-lang/rust/blob/ced33ad289abc621472fb0cdca9d5f09cafdadf8/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ced33ad289abc621472fb0cdca9d5f09cafdadf8/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs?ref=ced33ad289abc621472fb0cdca9d5f09cafdadf8", "patch": "@@ -6,18 +6,18 @@ use crate::dep_graph::{DepContext, DepKind, DepNode, DepNodeIndex, DepNodeParams\n use crate::dep_graph::{DepGraphData, HasDepContext};\n use crate::ich::StableHashingContext;\n use crate::query::caches::QueryCache;\n+#[cfg(parallel_compiler)]\n+use crate::query::job::QueryLatch;\n use crate::query::job::{report_cycle, QueryInfo, QueryJob, QueryJobId, QueryJobInfo};\n use crate::query::{QueryContext, QueryMap, QuerySideEffects, QueryStackFrame};\n use crate::values::Value;\n use crate::HandleCycleError;\n use rustc_data_structures::fingerprint::Fingerprint;\n use rustc_data_structures::fx::FxHashMap;\n-#[cfg(parallel_compiler)]\n-use rustc_data_structures::profiling::TimingGuard;\n-#[cfg(parallel_compiler)]\n-use rustc_data_structures::sharded::Sharded;\n use rustc_data_structures::stack::ensure_sufficient_stack;\n-use rustc_data_structures::sync::{Lock, LockGuard};\n+use rustc_data_structures::sync::Lock;\n+#[cfg(parallel_compiler)]\n+use rustc_data_structures::{cold_path, sharded::Sharded};\n use rustc_errors::{DiagnosticBuilder, ErrorGuaranteed, FatalError};\n use rustc_session::Session;\n use rustc_span::{Span, DUMMY_SP};\n@@ -116,7 +116,6 @@ where\n {\n     state: &'tcx QueryState<K, D>,\n     key: K,\n-    id: QueryJobId,\n }\n \n #[cold]\n@@ -166,81 +165,6 @@ impl<'tcx, K, D: DepKind> JobOwner<'tcx, K, D>\n where\n     K: Eq + Hash + Copy,\n {\n-    /// Either gets a `JobOwner` corresponding the query, allowing us to\n-    /// start executing the query, or returns with the result of the query.\n-    /// This function assumes that `try_get_cached` is already called and returned `lookup`.\n-    /// If the query is executing elsewhere, this will wait for it and return the result.\n-    /// If the query panicked, this will silently panic.\n-    ///\n-    /// This function is inlined because that results in a noticeable speed-up\n-    /// for some compile-time benchmarks.\n-    #[inline(always)]\n-    fn try_start<'b, Qcx>(\n-        qcx: &'b Qcx,\n-        state: &'b QueryState<K, Qcx::DepKind>,\n-        mut state_lock: LockGuard<'b, FxHashMap<K, QueryResult<Qcx::DepKind>>>,\n-        span: Span,\n-        key: K,\n-    ) -> TryGetJob<'b, K, D>\n-    where\n-        Qcx: QueryContext + HasDepContext<DepKind = D>,\n-    {\n-        let lock = &mut *state_lock;\n-        let current_job_id = qcx.current_query_job();\n-\n-        match lock.entry(key) {\n-            Entry::Vacant(entry) => {\n-                let id = qcx.next_job_id();\n-                let job = QueryJob::new(id, span, current_job_id);\n-\n-                let key = *entry.key();\n-                entry.insert(QueryResult::Started(job));\n-\n-                let owner = JobOwner { state, id, key };\n-                return TryGetJob::NotYetStarted(owner);\n-            }\n-            Entry::Occupied(mut entry) => {\n-                match entry.get_mut() {\n-                    #[cfg(not(parallel_compiler))]\n-                    QueryResult::Started(job) => {\n-                        let id = job.id;\n-                        drop(state_lock);\n-\n-                        // If we are single-threaded we know that we have cycle error,\n-                        // so we just return the error.\n-                        return TryGetJob::Cycle(id.find_cycle_in_stack(\n-                            qcx.try_collect_active_jobs().unwrap(),\n-                            &current_job_id,\n-                            span,\n-                        ));\n-                    }\n-                    #[cfg(parallel_compiler)]\n-                    QueryResult::Started(job) => {\n-                        // For parallel queries, we'll block and wait until the query running\n-                        // in another thread has completed. Record how long we wait in the\n-                        // self-profiler.\n-                        let query_blocked_prof_timer = qcx.dep_context().profiler().query_blocked();\n-\n-                        // Get the latch out\n-                        let latch = job.latch();\n-\n-                        drop(state_lock);\n-\n-                        // With parallel queries we might just have to wait on some other\n-                        // thread.\n-                        let result = latch.wait_on(current_job_id, span);\n-\n-                        match result {\n-                            Ok(()) => TryGetJob::JobCompleted(query_blocked_prof_timer),\n-                            Err(cycle) => TryGetJob::Cycle(cycle),\n-                        }\n-                    }\n-                    QueryResult::Poisoned => FatalError.raise(),\n-                }\n-            }\n-        }\n-    }\n-\n     /// Completes the query by updating the query cache with the `result`,\n     /// signals the waiter and forgets the JobOwner, so it won't poison the query\n     fn complete<C>(self, cache: &C, result: C::Value, dep_node_index: DepNodeIndex)\n@@ -307,25 +231,6 @@ pub(crate) struct CycleError<D: DepKind> {\n     pub cycle: Vec<QueryInfo<D>>,\n }\n \n-/// The result of `try_start`.\n-enum TryGetJob<'tcx, K, D>\n-where\n-    K: Eq + Hash + Copy,\n-    D: DepKind,\n-{\n-    /// The query is not yet started. Contains a guard to the cache eventually used to start it.\n-    NotYetStarted(JobOwner<'tcx, K, D>),\n-\n-    /// The query was already completed.\n-    /// Returns the result of the query and its dep-node index\n-    /// if it succeeded or a cycle error if it failed.\n-    #[cfg(parallel_compiler)]\n-    JobCompleted(TimingGuard<'tcx>),\n-\n-    /// Trying to execute the query resulted in a cycle.\n-    Cycle(CycleError<D>),\n-}\n-\n /// Checks if the query is already computed and in the cache.\n /// It returns the shard index and a lock guard to the shard,\n /// which will be used if the query is not in the cache and we need\n@@ -346,6 +251,65 @@ where\n     }\n }\n \n+#[cold]\n+#[inline(never)]\n+#[cfg(not(parallel_compiler))]\n+fn cycle_error<Q, Qcx>(\n+    query: Q,\n+    qcx: Qcx,\n+    try_execute: QueryJobId,\n+    span: Span,\n+) -> (Q::Value, Option<DepNodeIndex>)\n+where\n+    Q: QueryConfig<Qcx>,\n+    Qcx: QueryContext,\n+{\n+    let error = try_execute.find_cycle_in_stack(\n+        qcx.try_collect_active_jobs().unwrap(),\n+        &qcx.current_query_job(),\n+        span,\n+    );\n+    (mk_cycle(qcx, error, query.handle_cycle_error()), None)\n+}\n+\n+#[inline(always)]\n+#[cfg(parallel_compiler)]\n+fn wait_for_query<Q, Qcx>(\n+    query: Q,\n+    qcx: Qcx,\n+    span: Span,\n+    key: Q::Key,\n+    latch: QueryLatch<Qcx::DepKind>,\n+    current: Option<QueryJobId>,\n+) -> (Q::Value, Option<DepNodeIndex>)\n+where\n+    Q: QueryConfig<Qcx>,\n+    Qcx: QueryContext,\n+{\n+    // For parallel queries, we'll block and wait until the query running\n+    // in another thread has completed. Record how long we wait in the\n+    // self-profiler.\n+    let query_blocked_prof_timer = qcx.dep_context().profiler().query_blocked();\n+\n+    // With parallel queries we might just have to wait on some other\n+    // thread.\n+    let result = latch.wait_on(current, span);\n+\n+    match result {\n+        Ok(()) => {\n+            let Some((v, index)) = query.query_cache(qcx).lookup(&key) else {\n+                cold_path(|| panic!(\"value must be in cache after waiting\"))\n+            };\n+\n+            qcx.dep_context().profiler().query_cache_hit(index.into());\n+            query_blocked_prof_timer.finish_with_query_invocation_id(index.into());\n+\n+            (v, Some(index))\n+        }\n+        Err(cycle) => (mk_cycle(qcx, cycle, query.handle_cycle_error()), None),\n+    }\n+}\n+\n #[inline(never)]\n fn try_execute_query<Q, Qcx>(\n     query: Q,\n@@ -360,9 +324,9 @@ where\n {\n     let state = query.query_state(qcx);\n     #[cfg(parallel_compiler)]\n-    let state_lock = state.active.get_shard_by_value(&key).lock();\n+    let mut state_lock = state.active.get_shard_by_value(&key).lock();\n     #[cfg(not(parallel_compiler))]\n-    let state_lock = state.active.lock();\n+    let mut state_lock = state.active.lock();\n \n     // For the parallel compiler we need to check both the query cache and query state structures\n     // while holding the state lock to ensure that 1) the query has not yet completed and 2) the\n@@ -377,44 +341,82 @@ where\n         }\n     }\n \n-    match JobOwner::<'_, Q::Key, Qcx::DepKind>::try_start(&qcx, state, state_lock, span, key) {\n-        TryGetJob::NotYetStarted(job) => {\n-            let (result, dep_node_index) = match qcx.dep_context().dep_graph().data() {\n-                None => execute_job_non_incr(query, qcx, key, job.id),\n-                Some(data) => execute_job_incr(query, qcx, data, key, dep_node, job.id),\n-            };\n+    let current_job_id = qcx.current_query_job();\n+\n+    match state_lock.entry(key) {\n+        Entry::Vacant(entry) => {\n+            // Nothing has computed or is computing the query, so we start a new job and insert it in the\n+            // state map.\n+            let id = qcx.next_job_id();\n+            let job = QueryJob::new(id, span, current_job_id);\n+            entry.insert(QueryResult::Started(job));\n+\n+            // Drop the lock before we start executing the query\n+            drop(state_lock);\n+\n+            execute_job(query, qcx, state, key, id, dep_node)\n+        }\n+        Entry::Occupied(mut entry) => {\n+            match entry.get_mut() {\n+                #[cfg(not(parallel_compiler))]\n+                QueryResult::Started(job) => {\n+                    let id = job.id;\n+                    drop(state_lock);\n+\n+                    // If we are single-threaded we know that we have cycle error,\n+                    // so we just return the error.\n+                    cycle_error(query, qcx, id, span)\n+                }\n+                #[cfg(parallel_compiler)]\n+                QueryResult::Started(job) => {\n+                    // Get the latch out\n+                    let latch = job.latch();\n+                    drop(state_lock);\n \n-            let cache = query.query_cache(qcx);\n-            if query.feedable() {\n-                // We should not compute queries that also got a value via feeding.\n-                // This can't happen, as query feeding adds the very dependencies to the fed query\n-                // as its feeding query had. So if the fed query is red, so is its feeder, which will\n-                // get evaluated first, and re-feed the query.\n-                if let Some((cached_result, _)) = cache.lookup(&key) {\n-                    panic!(\n-                        \"fed query later has its value computed. The already cached value: {cached_result:?}\"\n-                    );\n+                    wait_for_query(query, qcx, span, key, latch, current_job_id)\n                 }\n+                QueryResult::Poisoned => FatalError.raise(),\n             }\n-            job.complete(cache, result, dep_node_index);\n-            (result, Some(dep_node_index))\n         }\n-        TryGetJob::Cycle(error) => {\n-            let result = mk_cycle(qcx, error, query.handle_cycle_error());\n-            (result, None)\n-        }\n-        #[cfg(parallel_compiler)]\n-        TryGetJob::JobCompleted(query_blocked_prof_timer) => {\n-            let Some((v, index)) = query.query_cache(qcx).lookup(&key) else {\n-                panic!(\"value must be in cache after waiting\")\n-            };\n+    }\n+}\n \n-            qcx.dep_context().profiler().query_cache_hit(index.into());\n-            query_blocked_prof_timer.finish_with_query_invocation_id(index.into());\n+#[inline(always)]\n+fn execute_job<Q, Qcx>(\n+    query: Q,\n+    qcx: Qcx,\n+    state: &QueryState<Q::Key, Qcx::DepKind>,\n+    key: Q::Key,\n+    id: QueryJobId,\n+    dep_node: Option<DepNode<Qcx::DepKind>>,\n+) -> (Q::Value, Option<DepNodeIndex>)\n+where\n+    Q: QueryConfig<Qcx>,\n+    Qcx: QueryContext,\n+{\n+    // Use `JobOwner` so the query will be poisoned if executing it panics.\n+    let job_owner = JobOwner { state, key };\n \n-            (v, Some(index))\n+    let (result, dep_node_index) = match qcx.dep_context().dep_graph().data() {\n+        None => execute_job_non_incr(query, qcx, key, id),\n+        Some(data) => execute_job_incr(query, qcx, data, key, dep_node, id),\n+    };\n+\n+    let cache = query.query_cache(qcx);\n+    if query.feedable() {\n+        // We should not compute queries that also got a value via feeding.\n+        // This can't happen, as query feeding adds the very dependencies to the fed query\n+        // as its feeding query had. So if the fed query is red, so is its feeder, which will\n+        // get evaluated first, and re-feed the query.\n+        if let Some((cached_result, _)) = cache.lookup(&key) {\n+            panic!(\n+                \"fed query later has its value computed. The already cached value: {cached_result:?}\"\n+            );\n         }\n     }\n+    job_owner.complete(cache, result, dep_node_index);\n+\n+    (result, Some(dep_node_index))\n }\n \n // Fast path for when incr. comp. is off."}]}