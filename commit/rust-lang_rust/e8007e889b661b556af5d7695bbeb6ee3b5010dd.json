{"sha": "e8007e889b661b556af5d7695bbeb6ee3b5010dd", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU4MDA3ZTg4OWI2NjFiNTU2YWY1ZDc2OTViYmViNmVlM2I1MDEwZGQ=", "commit": {"author": {"name": "Michael Rosenberg", "email": "42micro@gmail.com", "date": "2016-05-25T04:15:26Z"}, "committer": {"name": "Michael Rosenberg", "email": "42micro@gmail.com", "date": "2016-05-25T04:15:26Z"}, "message": "antlr grammar verification script now compiles under latest nightly", "tree": {"sha": "b8c7b584684d136fb6cbc9c7a6b97a06f53f4d22", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b8c7b584684d136fb6cbc9c7a6b97a06f53f4d22"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e8007e889b661b556af5d7695bbeb6ee3b5010dd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e8007e889b661b556af5d7695bbeb6ee3b5010dd", "html_url": "https://github.com/rust-lang/rust/commit/e8007e889b661b556af5d7695bbeb6ee3b5010dd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e8007e889b661b556af5d7695bbeb6ee3b5010dd/comments", "author": null, "committer": null, "parents": [{"sha": "8393d99c356e51128e0125aa23a7824d6ff513b2", "url": "https://api.github.com/repos/rust-lang/rust/commits/8393d99c356e51128e0125aa23a7824d6ff513b2", "html_url": "https://github.com/rust-lang/rust/commit/8393d99c356e51128e0125aa23a7824d6ff513b2"}], "stats": {"total": 214, "additions": 108, "deletions": 106}, "files": [{"sha": "a07fdec32801d270f0ec9f346832eed79969578c", "filename": "src/grammar/verify.rs", "status": "modified", "additions": 108, "deletions": 106, "changes": 214, "blob_url": "https://github.com/rust-lang/rust/blob/e8007e889b661b556af5d7695bbeb6ee3b5010dd/src%2Fgrammar%2Fverify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e8007e889b661b556af5d7695bbeb6ee3b5010dd/src%2Fgrammar%2Fverify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fgrammar%2Fverify.rs?ref=e8007e889b661b556af5d7695bbeb6ee3b5010dd", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-#![feature(plugin, rustc_private, str_char, collections)]\n+#![feature(plugin, rustc_private)]\n \n extern crate syntax;\n extern crate rustc;\n@@ -24,6 +24,7 @@ use std::path::Path;\n \n use syntax::parse;\n use syntax::parse::lexer;\n+use rustc::dep_graph::DepGraph;\n use rustc::session::{self, config};\n use rustc::middle::cstore::DummyCrateStore;\n \n@@ -32,17 +33,17 @@ use syntax::ast;\n use syntax::ast::Name;\n use syntax::codemap;\n use syntax::codemap::Pos;\n-use syntax::parse::token;\n+use syntax::parse::token::{self, BinOpToken, DelimToken, Lit, Token};\n use syntax::parse::lexer::TokenAndSpan;\n \n fn parse_token_list(file: &str) -> HashMap<String, token::Token> {\n     fn id() -> token::Token {\n-        token::Ident(ast::Ident::with_empty_ctxt(Name(0)), token::Plain)\n+        Token::Ident(ast::Ident::with_empty_ctxt(Name(0)))\n     }\n \n     let mut res = HashMap::new();\n \n-    res.insert(\"-1\".to_string(), token::Eof);\n+    res.insert(\"-1\".to_string(), Token::Eof);\n \n     for line in file.split('\\n') {\n         let eq = match line.trim().rfind('=') {\n@@ -54,65 +55,65 @@ fn parse_token_list(file: &str) -> HashMap<String, token::Token> {\n         let num = &line[eq + 1..];\n \n         let tok = match val {\n-            \"SHR\"               => token::BinOp(token::Shr),\n-            \"DOLLAR\"            => token::Dollar,\n-            \"LT\"                => token::Lt,\n-            \"STAR\"              => token::BinOp(token::Star),\n+            \"SHR\"               => Token::BinOp(BinOpToken::Shr),\n+            \"DOLLAR\"            => Token::Dollar,\n+            \"LT\"                => Token::Lt,\n+            \"STAR\"              => Token::BinOp(BinOpToken::Star),\n             \"FLOAT_SUFFIX\"      => id(),\n             \"INT_SUFFIX\"        => id(),\n-            \"SHL\"               => token::BinOp(token::Shl),\n-            \"LBRACE\"            => token::OpenDelim(token::Brace),\n-            \"RARROW\"            => token::RArrow,\n-            \"LIT_STR\"           => token::Literal(token::Str_(Name(0)), None),\n-            \"DOTDOT\"            => token::DotDot,\n-            \"MOD_SEP\"           => token::ModSep,\n-            \"DOTDOTDOT\"         => token::DotDotDot,\n-            \"NOT\"               => token::Not,\n-            \"AND\"               => token::BinOp(token::And),\n-            \"LPAREN\"            => token::OpenDelim(token::Paren),\n-            \"ANDAND\"            => token::AndAnd,\n-            \"AT\"                => token::At,\n-            \"LBRACKET\"          => token::OpenDelim(token::Bracket),\n-            \"LIT_STR_RAW\"       => token::Literal(token::StrRaw(Name(0), 0), None),\n-            \"RPAREN\"            => token::CloseDelim(token::Paren),\n-            \"SLASH\"             => token::BinOp(token::Slash),\n-            \"COMMA\"             => token::Comma,\n-            \"LIFETIME\"          => token::Lifetime(ast::Ident::with_empty_ctxt(Name(0))),\n-            \"CARET\"             => token::BinOp(token::Caret),\n-            \"TILDE\"             => token::Tilde,\n+            \"SHL\"               => Token::BinOp(BinOpToken::Shl),\n+            \"LBRACE\"            => Token::OpenDelim(DelimToken::Brace),\n+            \"RARROW\"            => Token::RArrow,\n+            \"LIT_STR\"           => Token::Literal(Lit::Str_(Name(0)), None),\n+            \"DOTDOT\"            => Token::DotDot,\n+            \"MOD_SEP\"           => Token::ModSep,\n+            \"DOTDOTDOT\"         => Token::DotDotDot,\n+            \"NOT\"               => Token::Not,\n+            \"AND\"               => Token::BinOp(BinOpToken::And),\n+            \"LPAREN\"            => Token::OpenDelim(DelimToken::Paren),\n+            \"ANDAND\"            => Token::AndAnd,\n+            \"AT\"                => Token::At,\n+            \"LBRACKET\"          => Token::OpenDelim(DelimToken::Bracket),\n+            \"LIT_STR_RAW\"       => Token::Literal(Lit::StrRaw(Name(0), 0), None),\n+            \"RPAREN\"            => Token::CloseDelim(DelimToken::Paren),\n+            \"SLASH\"             => Token::BinOp(BinOpToken::Slash),\n+            \"COMMA\"             => Token::Comma,\n+            \"LIFETIME\"          => Token::Lifetime(ast::Ident::with_empty_ctxt(Name(0))),\n+            \"CARET\"             => Token::BinOp(BinOpToken::Caret),\n+            \"TILDE\"             => Token::Tilde,\n             \"IDENT\"             => id(),\n-            \"PLUS\"              => token::BinOp(token::Plus),\n-            \"LIT_CHAR\"          => token::Literal(token::Char(Name(0)), None),\n-            \"LIT_BYTE\"          => token::Literal(token::Byte(Name(0)), None),\n-            \"EQ\"                => token::Eq,\n-            \"RBRACKET\"          => token::CloseDelim(token::Bracket),\n-            \"COMMENT\"           => token::Comment,\n-            \"DOC_COMMENT\"       => token::DocComment(Name(0)),\n-            \"DOT\"               => token::Dot,\n-            \"EQEQ\"              => token::EqEq,\n-            \"NE\"                => token::Ne,\n-            \"GE\"                => token::Ge,\n-            \"PERCENT\"           => token::BinOp(token::Percent),\n-            \"RBRACE\"            => token::CloseDelim(token::Brace),\n-            \"BINOP\"             => token::BinOp(token::Plus),\n-            \"POUND\"             => token::Pound,\n-            \"OROR\"              => token::OrOr,\n-            \"LIT_INTEGER\"       => token::Literal(token::Integer(Name(0)), None),\n-            \"BINOPEQ\"           => token::BinOpEq(token::Plus),\n-            \"LIT_FLOAT\"         => token::Literal(token::Float(Name(0)), None),\n-            \"WHITESPACE\"        => token::Whitespace,\n-            \"UNDERSCORE\"        => token::Underscore,\n-            \"MINUS\"             => token::BinOp(token::Minus),\n-            \"SEMI\"              => token::Semi,\n-            \"COLON\"             => token::Colon,\n-            \"FAT_ARROW\"         => token::FatArrow,\n-            \"OR\"                => token::BinOp(token::Or),\n-            \"GT\"                => token::Gt,\n-            \"LE\"                => token::Le,\n-            \"LIT_BYTE_STR\"      => token::Literal(token::ByteStr(Name(0)), None),\n-            \"LIT_BYTE_STR_RAW\"  => token::Literal(token::ByteStrRaw(Name(0), 0), None),\n-            \"QUESTION\"          => token::Question,\n-            \"SHEBANG\"           => token::Shebang(Name(0)),\n+            \"PLUS\"              => Token::BinOp(BinOpToken::Plus),\n+            \"LIT_CHAR\"          => Token::Literal(Lit::Char(Name(0)), None),\n+            \"LIT_BYTE\"          => Token::Literal(Lit::Byte(Name(0)), None),\n+            \"EQ\"                => Token::Eq,\n+            \"RBRACKET\"          => Token::CloseDelim(DelimToken::Bracket),\n+            \"COMMENT\"           => Token::Comment,\n+            \"DOC_COMMENT\"       => Token::DocComment(Name(0)),\n+            \"DOT\"               => Token::Dot,\n+            \"EQEQ\"              => Token::EqEq,\n+            \"NE\"                => Token::Ne,\n+            \"GE\"                => Token::Ge,\n+            \"PERCENT\"           => Token::BinOp(BinOpToken::Percent),\n+            \"RBRACE\"            => Token::CloseDelim(DelimToken::Brace),\n+            \"BINOP\"             => Token::BinOp(BinOpToken::Plus),\n+            \"POUND\"             => Token::Pound,\n+            \"OROR\"              => Token::OrOr,\n+            \"LIT_INTEGER\"       => Token::Literal(Lit::Integer(Name(0)), None),\n+            \"BINOPEQ\"           => Token::BinOpEq(BinOpToken::Plus),\n+            \"LIT_FLOAT\"         => Token::Literal(Lit::Float(Name(0)), None),\n+            \"WHITESPACE\"        => Token::Whitespace,\n+            \"UNDERSCORE\"        => Token::Underscore,\n+            \"MINUS\"             => Token::BinOp(BinOpToken::Minus),\n+            \"SEMI\"              => Token::Semi,\n+            \"COLON\"             => Token::Colon,\n+            \"FAT_ARROW\"         => Token::FatArrow,\n+            \"OR\"                => Token::BinOp(BinOpToken::Or),\n+            \"GT\"                => Token::Gt,\n+            \"LE\"                => Token::Le,\n+            \"LIT_BINARY\"        => Token::Literal(Lit::ByteStr(Name(0)), None),\n+            \"LIT_BINARY_RAW\"    => Token::Literal(Lit::ByteStrRaw(Name(0), 0), None),\n+            \"QUESTION\"          => Token::Question,\n+            \"SHEBANG\"           => Token::Shebang(Name(0)),\n             _                   => continue,\n         };\n \n@@ -125,30 +126,31 @@ fn parse_token_list(file: &str) -> HashMap<String, token::Token> {\n \n fn str_to_binop(s: &str) -> token::BinOpToken {\n     match s {\n-        \"+\"     => token::Plus,\n-        \"/\"     => token::Slash,\n-        \"-\"     => token::Minus,\n-        \"*\"     => token::Star,\n-        \"%\"     => token::Percent,\n-        \"^\"     => token::Caret,\n-        \"&\"     => token::And,\n-        \"|\"     => token::Or,\n-        \"<<\"    => token::Shl,\n-        \">>\"    => token::Shr,\n+        \"+\"     => BinOpToken::Plus,\n+        \"/\"     => BinOpToken::Slash,\n+        \"-\"     => BinOpToken::Minus,\n+        \"*\"     => BinOpToken::Star,\n+        \"%\"     => BinOpToken::Percent,\n+        \"^\"     => BinOpToken::Caret,\n+        \"&\"     => BinOpToken::And,\n+        \"|\"     => BinOpToken::Or,\n+        \"<<\"    => BinOpToken::Shl,\n+        \">>\"    => BinOpToken::Shr,\n         _       => panic!(\"Bad binop str `{}`\", s),\n     }\n }\n \n /// Assuming a string/byte string literal, strip out the leading/trailing\n /// hashes and surrounding quotes/raw/byte prefix.\n fn fix(mut lit: &str) -> ast::Name {\n-    if lit.char_at(0) == 'r' {\n-        if lit.char_at(1) == 'b' {\n+    let prefix: Vec<char> = lit.chars().take(2).collect();\n+    if prefix[0] == 'r' {\n+        if prefix[1] == 'b' {\n             lit = &lit[2..]\n         } else {\n             lit = &lit[1..];\n         }\n-    } else if lit.char_at(0) == 'b' {\n+    } else if prefix[0] == 'b' {\n         lit = &lit[1..];\n     }\n \n@@ -160,7 +162,8 @@ fn fix(mut lit: &str) -> ast::Name {\n \n /// Assuming a char/byte literal, strip the 'b' prefix and the single quotes.\n fn fixchar(mut lit: &str) -> ast::Name {\n-    if lit.char_at(0) == 'b' {\n+    let prefix = lit.chars().next().unwrap();\n+    if prefix == 'b' {\n         lit = &lit[1..];\n     }\n \n@@ -197,26 +200,25 @@ fn parse_antlr_token(s: &str, tokens: &HashMap<String, token::Token>, surrogate_\n     debug!(\"What we got: content (`{}`), proto: {:?}\", content, proto_tok);\n \n     let real_tok = match *proto_tok {\n-        token::BinOp(..)           => token::BinOp(str_to_binop(content)),\n-        token::BinOpEq(..)         => token::BinOpEq(str_to_binop(&content[..content.len() - 1])),\n-        token::Literal(token::Str_(..), n)      => token::Literal(token::Str_(fix(content)), n),\n-        token::Literal(token::StrRaw(..), n)    => token::Literal(token::StrRaw(fix(content),\n+        Token::BinOp(..)           => Token::BinOp(str_to_binop(content)),\n+        Token::BinOpEq(..)         => Token::BinOpEq(str_to_binop(&content[..content.len() - 1])),\n+        Token::Literal(Lit::Str_(..), n)      => Token::Literal(Lit::Str_(fix(content)), n),\n+        Token::Literal(Lit::StrRaw(..), n)    => Token::Literal(Lit::StrRaw(fix(content),\n                                                                              count(content)), n),\n-        token::Literal(token::Char(..), n)      => token::Literal(token::Char(fixchar(content)), n),\n-        token::Literal(token::Byte(..), n)      => token::Literal(token::Byte(fixchar(content)), n),\n-        token::DocComment(..)      => token::DocComment(nm),\n-        token::Literal(token::Integer(..), n)   => token::Literal(token::Integer(nm), n),\n-        token::Literal(token::Float(..), n)     => token::Literal(token::Float(nm), n),\n-        token::Literal(token::ByteStr(..), n)    => token::Literal(token::ByteStr(nm), n),\n-        token::Literal(token::ByteStrRaw(..), n) => token::Literal(token::ByteStrRaw(fix(content),\n+        Token::Literal(Lit::Char(..), n)      => Token::Literal(Lit::Char(fixchar(content)), n),\n+        Token::Literal(Lit::Byte(..), n)      => Token::Literal(Lit::Byte(fixchar(content)), n),\n+        Token::DocComment(..)      => Token::DocComment(nm),\n+        Token::Literal(Lit::Integer(..), n)   => Token::Literal(Lit::Integer(nm), n),\n+        Token::Literal(Lit::Float(..), n)     => Token::Literal(Lit::Float(nm), n),\n+        Token::Literal(Lit::ByteStr(..), n)    => Token::Literal(Lit::ByteStr(nm), n),\n+        Token::Literal(Lit::ByteStrRaw(..), n) => Token::Literal(Lit::ByteStrRaw(fix(content),\n                                                                                 count(content)), n),\n-        token::Ident(..)           => token::Ident(ast::Ident::with_empty_ctxt(nm),\n-                                                   token::ModName),\n-        token::Lifetime(..)        => token::Lifetime(ast::Ident::with_empty_ctxt(nm)),\n+        Token::Ident(..)           => Token::Ident(ast::Ident::with_empty_ctxt(nm)),\n+        Token::Lifetime(..)        => Token::Lifetime(ast::Ident::with_empty_ctxt(nm)),\n         ref t => t.clone()\n     };\n \n-    let start_offset = if real_tok == token::Eof {\n+    let start_offset = if real_tok == Token::Eof {\n         1\n     } else {\n         0\n@@ -245,8 +247,8 @@ fn parse_antlr_token(s: &str, tokens: &HashMap<String, token::Token>, surrogate_\n \n fn tok_cmp(a: &token::Token, b: &token::Token) -> bool {\n     match a {\n-        &token::Ident(id, _) => match b {\n-                &token::Ident(id2, _) => id == id2,\n+        &Token::Ident(id) => match b {\n+                &Token::Ident(id2) => id == id2,\n                 _ => false\n         },\n         _ => a == b\n@@ -287,7 +289,7 @@ fn main() {\n     debug!(\"Pairs: {:?}\", surrogate_pairs_pos);\n \n     let options = config::basic_options();\n-    let session = session::build_session(options, None,\n+    let session = session::build_session(options, &DepGraph::new(false), None,\n                                          syntax::diagnostics::registry::Registry::new(&[]),\n                                          Rc::new(DummyCrateStore));\n     let filemap = session.parse_sess.codemap().new_filemap(String::from(\"<n/a>\"), code);\n@@ -310,7 +312,7 @@ fn main() {\n \n     for antlr_tok in antlr_tokens {\n         let rustc_tok = next(&mut lexer);\n-        if rustc_tok.tok == token::Eof && antlr_tok.tok == token::Eof {\n+        if rustc_tok.tok == Token::Eof && antlr_tok.tok == Token::Eof {\n             continue\n         }\n \n@@ -337,19 +339,19 @@ fn main() {\n         }\n \n         matches!(\n-            token::Literal(token::Byte(..), _),\n-            token::Literal(token::Char(..), _),\n-            token::Literal(token::Integer(..), _),\n-            token::Literal(token::Float(..), _),\n-            token::Literal(token::Str_(..), _),\n-            token::Literal(token::StrRaw(..), _),\n-            token::Literal(token::ByteStr(..), _),\n-            token::Literal(token::ByteStrRaw(..), _),\n-            token::Ident(..),\n-            token::Lifetime(..),\n-            token::Interpolated(..),\n-            token::DocComment(..),\n-            token::Shebang(..)\n+            Token::Literal(Lit::Byte(..), _),\n+            Token::Literal(Lit::Char(..), _),\n+            Token::Literal(Lit::Integer(..), _),\n+            Token::Literal(Lit::Float(..), _),\n+            Token::Literal(Lit::Str_(..), _),\n+            Token::Literal(Lit::StrRaw(..), _),\n+            Token::Literal(Lit::ByteStr(..), _),\n+            Token::Literal(Lit::ByteStrRaw(..), _),\n+            Token::Ident(..),\n+            Token::Lifetime(..),\n+            Token::Interpolated(..),\n+            Token::DocComment(..),\n+            Token::Shebang(..)\n         );\n     }\n }"}]}