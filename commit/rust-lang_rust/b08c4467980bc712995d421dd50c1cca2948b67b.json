{"sha": "b08c4467980bc712995d421dd50c1cca2948b67b", "node_id": "MDY6Q29tbWl0NzI0NzEyOmIwOGM0NDY3OTgwYmM3MTI5OTVkNDIxZGQ1MGMxY2NhMjk0OGI2N2I=", "commit": {"author": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2013-06-16T00:00:36Z"}, "committer": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2013-06-16T00:00:36Z"}, "message": "Merge remote-tracking branch 'toddaaro/io' into io", "tree": {"sha": "7ab9a238f0461ec8edbea5fe4cfa5d792ae57d82", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7ab9a238f0461ec8edbea5fe4cfa5d792ae57d82"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b08c4467980bc712995d421dd50c1cca2948b67b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b08c4467980bc712995d421dd50c1cca2948b67b", "html_url": "https://github.com/rust-lang/rust/commit/b08c4467980bc712995d421dd50c1cca2948b67b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b08c4467980bc712995d421dd50c1cca2948b67b/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e7213aa21e9a79db01d2e9d1b76761a420e4c967", "url": "https://api.github.com/repos/rust-lang/rust/commits/e7213aa21e9a79db01d2e9d1b76761a420e4c967", "html_url": "https://github.com/rust-lang/rust/commit/e7213aa21e9a79db01d2e9d1b76761a420e4c967"}, {"sha": "d1ec8b5fb85cb6fd4caed64223c5cb3fd920daab", "url": "https://api.github.com/repos/rust-lang/rust/commits/d1ec8b5fb85cb6fd4caed64223c5cb3fd920daab", "html_url": "https://github.com/rust-lang/rust/commit/d1ec8b5fb85cb6fd4caed64223c5cb3fd920daab"}], "stats": {"total": 900, "additions": 807, "deletions": 93}, "files": [{"sha": "b01bd8f993c01bde1764018c11c3535b9310258c", "filename": "src/libstd/macros.rs", "status": "modified", "additions": 10, "deletions": 8, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fmacros.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -38,16 +38,18 @@ macro_rules! rtassert (\n     } )\n )\n \n+\n+// The do_abort function was originally inside the abort macro, but\n+// this was ICEing the compiler so it has been moved outside. Now this\n+// seems to work?\n+pub fn do_abort() -> ! {\n+    unsafe { ::libc::abort(); }\n+}\n+\n macro_rules! abort(\n     ($( $msg:expr),+) => ( {\n         rtdebug!($($msg),+);\n-\n-        do_abort();\n-\n-        // NB: This is in a fn to avoid putting the `unsafe` block in a macro,\n-        // which causes spurious 'unnecessary unsafe block' warnings.\n-        fn do_abort() -> ! {\n-            unsafe { ::libc::abort(); }\n-        }\n+        ::macros::do_abort();\n     } )\n )\n+"}, {"sha": "88c7b9a2bf2684ae8ee4fa0b347e0a6c532d9efa", "filename": "src/libstd/rt/comm.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Fcomm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Fcomm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fcomm.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -120,13 +120,13 @@ impl<T> ChanOne<T> {\n             match oldstate {\n                 STATE_BOTH => {\n                     // Port is not waiting yet. Nothing to do\n-                    do Local::borrow::<Scheduler> |sched| {\n+                    do Local::borrow::<Scheduler, ()> |sched| {\n                         rtdebug!(\"non-rendezvous send\");\n                         sched.metrics.non_rendezvous_sends += 1;\n                     }\n                 }\n                 STATE_ONE => {\n-                    do Local::borrow::<Scheduler> |sched| {\n+                    do Local::borrow::<Scheduler, ()> |sched| {\n                         rtdebug!(\"rendezvous send\");\n                         sched.metrics.rendezvous_sends += 1;\n                     }"}, {"sha": "6e0fbda5ec9a73cec4cf28914808c9e5c759999e", "filename": "src/libstd/rt/local.rs", "status": "modified", "additions": 30, "deletions": 5, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Flocal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Flocal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flocal.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -18,7 +18,7 @@ pub trait Local {\n     fn put(value: ~Self);\n     fn take() -> ~Self;\n     fn exists() -> bool;\n-    fn borrow(f: &fn(&mut Self));\n+    fn borrow<T>(f: &fn(&mut Self) -> T) -> T;\n     unsafe fn unsafe_borrow() -> *mut Self;\n     unsafe fn try_unsafe_borrow() -> Option<*mut Self>;\n }\n@@ -27,7 +27,20 @@ impl Local for Scheduler {\n     fn put(value: ~Scheduler) { unsafe { local_ptr::put(value) }}\n     fn take() -> ~Scheduler { unsafe { local_ptr::take() } }\n     fn exists() -> bool { local_ptr::exists() }\n-    fn borrow(f: &fn(&mut Scheduler)) { unsafe { local_ptr::borrow(f) } }\n+    fn borrow<T>(f: &fn(&mut Scheduler) -> T) -> T {\n+        let mut res: Option<T> = None;\n+        let res_ptr: *mut Option<T> = &mut res;\n+        unsafe {\n+            do local_ptr::borrow |sched| {\n+                let result = f(sched);\n+                *res_ptr = Some(result);\n+            }\n+        }\n+        match res {\n+            Some(r) => { r }\n+            None => abort!(\"function failed!\")\n+        }\n+    }\n     unsafe fn unsafe_borrow() -> *mut Scheduler { local_ptr::unsafe_borrow() }\n     unsafe fn try_unsafe_borrow() -> Option<*mut Scheduler> { abort!(\"unimpl\") }\n }\n@@ -36,8 +49,8 @@ impl Local for Task {\n     fn put(_value: ~Task) { abort!(\"unimpl\") }\n     fn take() -> ~Task { abort!(\"unimpl\") }\n     fn exists() -> bool { abort!(\"unimpl\") }\n-    fn borrow(f: &fn(&mut Task)) {\n-        do Local::borrow::<Scheduler> |sched| {\n+    fn borrow<T>(f: &fn(&mut Task) -> T) -> T {\n+        do Local::borrow::<Scheduler, T> |sched| {\n             match sched.current_task {\n                 Some(~ref mut task) => {\n                     f(&mut *task.task)\n@@ -74,7 +87,7 @@ impl Local for IoFactoryObject {\n     fn put(_value: ~IoFactoryObject) { abort!(\"unimpl\") }\n     fn take() -> ~IoFactoryObject { abort!(\"unimpl\") }\n     fn exists() -> bool { abort!(\"unimpl\") }\n-    fn borrow(_f: &fn(&mut IoFactoryObject)) { abort!(\"unimpl\") }\n+    fn borrow<T>(_f: &fn(&mut IoFactoryObject) -> T) -> T { abort!(\"unimpl\") }\n     unsafe fn unsafe_borrow() -> *mut IoFactoryObject {\n         let sched = Local::unsafe_borrow::<Scheduler>();\n         let io: *mut IoFactoryObject = (*sched).event_loop.io().unwrap();\n@@ -115,4 +128,16 @@ mod test {\n         }\n         let _scheduler: ~Scheduler = Local::take();\n     }\n+\n+    #[test]\n+    fn borrow_with_return() {\n+        let scheduler = ~new_test_uv_sched();\n+        Local::put(scheduler);\n+        let res = do Local::borrow::<Scheduler,bool> |_sched| {\n+            true\n+        };\n+        assert!(res)\n+        let _scheduler: ~Scheduler = Local::take();\n+    }\n+\n }"}, {"sha": "3198b2858763a98328074b511e30ed7c59bfe90e", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -208,7 +208,7 @@ pub fn context() -> RuntimeContext {\n     } else {\n         if Local::exists::<Scheduler>() {\n             let context = ::cell::empty_cell();\n-            do Local::borrow::<Scheduler> |sched| {\n+            do Local::borrow::<Scheduler, ()> |sched| {\n                 if sched.in_task_context() {\n                     context.put_back(TaskContext);\n                 } else {"}, {"sha": "3b8a31d1840b33a687157cfafebe1bd8be763451", "filename": "src/libstd/rt/sched.rs", "status": "modified", "additions": 596, "deletions": 65, "changes": 661, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fsched.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -26,6 +26,11 @@ use rt::local::Local;\n use rt::rtio::RemoteCallback;\n use rt::metrics::SchedMetrics;\n \n+//use to_str::ToStr;\n+\n+/// To allow for using pointers as scheduler ids\n+use ptr::{to_uint};\n+\n /// The Scheduler is responsible for coordinating execution of Coroutines\n /// on a single thread. When the scheduler is running it is owned by\n /// thread local storage and the running task is owned by the\n@@ -65,12 +70,15 @@ pub struct Scheduler {\n     /// An action performed after a context switch on behalf of the\n     /// code running before the context switch\n     priv cleanup_job: Option<CleanupJob>,\n-    metrics: SchedMetrics\n+    metrics: SchedMetrics,\n+    /// Should this scheduler run any task, or only pinned tasks?\n+    run_anything: bool\n }\n \n pub struct SchedHandle {\n     priv remote: ~RemoteCallbackObject,\n-    priv queue: MessageQueue<SchedMessage>\n+    priv queue: MessageQueue<SchedMessage>,\n+    sched_id: uint\n }\n \n pub struct Coroutine {\n@@ -81,12 +89,20 @@ pub struct Coroutine {\n     /// the task is dead\n     priv saved_context: Context,\n     /// The heap, GC, unwinding, local storage, logging\n-    task: ~Task\n+    task: ~Task,\n+}\n+\n+// A scheduler home is either a handle to the home scheduler, or an\n+// explicit \"AnySched\".\n+pub enum SchedHome {\n+    AnySched,\n+    Sched(SchedHandle)\n }\n \n pub enum SchedMessage {\n     Wake,\n-    Shutdown\n+    Shutdown,\n+    PinnedTask(~Coroutine)\n }\n \n enum CleanupJob {\n@@ -96,13 +112,25 @@ enum CleanupJob {\n \n pub impl Scheduler {\n \n+    pub fn sched_id(&self) -> uint { to_uint(self) }\n+\n     fn in_task_context(&self) -> bool { self.current_task.is_some() }\n \n     fn new(event_loop: ~EventLoopObject,\n            work_queue: WorkQueue<~Coroutine>,\n            sleeper_list: SleeperList)\n         -> Scheduler {\n \n+        Scheduler::new_special(event_loop, work_queue, sleeper_list, true)\n+\n+    }\n+\n+    fn new_special(event_loop: ~EventLoopObject,\n+           work_queue: WorkQueue<~Coroutine>,\n+           sleeper_list: SleeperList,\n+           run_anything: bool)\n+        -> Scheduler {\n+\n         // Lazily initialize the runtime TLS key\n         local_ptr::init_tls_key();\n \n@@ -117,7 +145,8 @@ pub impl Scheduler {\n             saved_context: Context::empty(),\n             current_task: None,\n             cleanup_job: None,\n-            metrics: SchedMetrics::new()\n+            metrics: SchedMetrics::new(),\n+            run_anything: run_anything\n         }\n     }\n \n@@ -147,11 +176,13 @@ pub impl Scheduler {\n             (*event_loop).run();\n         }\n \n+        rtdebug!(\"run taking sched\");\n         let sched = Local::take::<Scheduler>();\n         // XXX: Reenable this once we're using a per-task queue. With a shared\n         // queue this is not true\n         //assert!(sched.work_queue.is_empty());\n-        rtdebug!(\"scheduler metrics: %s\\n\", sched.metrics.to_str());\n+//        let out = sched.metrics.to_str();\n+//        rtdebug!(\"scheduler metrics: %s\\n\", out);\n         return sched;\n     }\n \n@@ -167,6 +198,7 @@ pub impl Scheduler {\n         if sched.interpret_message_queue() {\n             // We performed a scheduling action. There may be other work\n             // to do yet, so let's try again later.\n+            rtdebug!(\"run_sched_once, interpret_message_queue taking sched\");\n             let mut sched = Local::take::<Scheduler>();\n             sched.metrics.messages_received += 1;\n             sched.event_loop.callback(Scheduler::run_sched_once);\n@@ -175,6 +207,7 @@ pub impl Scheduler {\n         }\n \n         // Now, look in the work queue for tasks to run\n+        rtdebug!(\"run_sched_once taking\");\n         let sched = Local::take::<Scheduler>();\n         if sched.resume_task_from_queue() {\n             // We performed a scheduling action. There may be other work\n@@ -209,33 +242,56 @@ pub impl Scheduler {\n \n         return SchedHandle {\n             remote: remote,\n-            queue: self.message_queue.clone()\n+            queue: self.message_queue.clone(),\n+            sched_id: self.sched_id()\n         };\n     }\n \n     /// Schedule a task to be executed later.\n     ///\n-    /// Pushes the task onto the work stealing queue and tells the event loop\n-    /// to run it later. Always use this instead of pushing to the work queue\n-    /// directly.\n-    fn enqueue_task(&mut self, task: ~Coroutine) {\n-        self.work_queue.push(task);\n-        self.event_loop.callback(Scheduler::run_sched_once);\n-\n-        // We've made work available. Notify a sleeping scheduler.\n-        // XXX: perf. Check for a sleeper without synchronizing memory.\n-        // It's not critical that we always find it.\n-        // XXX: perf. If there's a sleeper then we might as well just send\n-        // it the task directly instead of pushing it to the\n-        // queue. That is essentially the intent here and it is less\n-        // work.\n-        match self.sleeper_list.pop() {\n+    /// Pushes the task onto the work stealing queue and tells the\n+    /// event loop to run it later. Always use this instead of pushing\n+    /// to the work queue directly.\n+\n+    fn enqueue_task(&mut self, mut task: ~Coroutine) {\n+\n+        // We don't want to queue tasks that belong on other threads,\n+        // so we send them home at enqueue time.\n+\n+        // The borrow checker doesn't like our disassembly of the\n+        // Coroutine struct and partial use and mutation of the\n+        // fields. So completely disassemble here and stop using?\n+\n+        // XXX perf: I think we might be able to shuffle this code to\n+        // only destruct when we need to.\n+\n+        rtdebug!(\"a task was queued on: %u\", self.sched_id());\n+\n+        let this = self;\n+\n+        // We push the task onto our local queue clone.\n+        this.work_queue.push(task);\n+        this.event_loop.callback(Scheduler::run_sched_once);\n+\n+        // We've made work available. Notify a\n+        // sleeping scheduler.\n+\n+        // XXX: perf. Check for a sleeper without\n+        // synchronizing memory.  It's not critical\n+        // that we always find it.\n+\n+        // XXX: perf. If there's a sleeper then we\n+        // might as well just send it the task\n+        // directly instead of pushing it to the\n+        // queue. That is essentially the intent here\n+        // and it is less work.\n+        match this.sleeper_list.pop() {\n             Some(handle) => {\n                 let mut handle = handle;\n                 handle.send(Wake)\n             }\n-            None => (/* pass */)\n-        }\n+            None => { (/* pass */) }\n+        };\n     }\n \n     // * Scheduler-context operations\n@@ -247,6 +303,15 @@ pub impl Scheduler {\n \n         let mut this = self;\n         match this.message_queue.pop() {\n+            Some(PinnedTask(task)) => {\n+                rtdebug!(\"recv BiasedTask message in sched: %u\",\n+                         this.sched_id());\n+                let mut task = task;\n+                task.task.home = Some(Sched(this.make_handle()));\n+                this.resume_task_immediately(task);\n+                return true;\n+            }\n+\n             Some(Wake) => {\n                 rtdebug!(\"recv Wake message\");\n                 this.sleepy = false;\n@@ -256,8 +321,9 @@ pub impl Scheduler {\n             Some(Shutdown) => {\n                 rtdebug!(\"recv Shutdown message\");\n                 if this.sleepy {\n-                    // There may be an outstanding handle on the sleeper list.\n-                    // Pop them all to make sure that's not the case.\n+                    // There may be an outstanding handle on the\n+                    // sleeper list.  Pop them all to make sure that's\n+                    // not the case.\n                     loop {\n                         match this.sleeper_list.pop() {\n                             Some(handle) => {\n@@ -268,8 +334,8 @@ pub impl Scheduler {\n                         }\n                     }\n                 }\n-                // No more sleeping. After there are no outstanding event loop\n-                // references we will shut down.\n+                // No more sleeping. After there are no outstanding\n+                // event loop references we will shut down.\n                 this.no_sleep = true;\n                 this.sleepy = false;\n                 Local::put(this);\n@@ -282,23 +348,93 @@ pub impl Scheduler {\n         }\n     }\n \n+    /// Given an input Coroutine sends it back to its home scheduler.\n+    fn send_task_home(task: ~Coroutine) {\n+        let mut task = task;\n+        let mut home = task.task.home.swap_unwrap();\n+        match home {\n+            Sched(ref mut home_handle) => {\n+                home_handle.send(PinnedTask(task));\n+            }\n+            AnySched => {\n+                abort!(\"error: cannot send anysched task home\");\n+            }\n+        }\n+    }\n+\n+    // Resume a task from the queue - but also take into account that\n+    // it might not belong here.\n     fn resume_task_from_queue(~self) -> bool {\n         assert!(!self.in_task_context());\n \n         rtdebug!(\"looking in work queue for task to schedule\");\n-\n         let mut this = self;\n+\n+        // The borrow checker imposes the possibly absurd requirement\n+        // that we split this into two match expressions. This is due\n+        // to the inspection of the internal bits of task, as that\n+        // can't be in scope when we act on task.\n         match this.work_queue.pop() {\n             Some(task) => {\n-                rtdebug!(\"resuming task from work queue\");\n-                this.resume_task_immediately(task);\n-                return true;\n+                let action_id = {\n+                    let home = &task.task.home;\n+                    match home {\n+                        &Some(Sched(ref home_handle))\n+                        if home_handle.sched_id != this.sched_id() => {\n+                            0\n+                        }\n+                        &Some(AnySched) if this.run_anything => {\n+                            1\n+                        }\n+                        &Some(AnySched) => {\n+                            2\n+                        }\n+                        &Some(Sched(_)) => {\n+                            3\n+                        }\n+                        &None => {\n+                            4\n+                        }\n+                    }\n+                };\n+\n+                match action_id {\n+                    0 => {\n+                        rtdebug!(\"sending task home\");\n+                        Scheduler::send_task_home(task);\n+                        Local::put(this);\n+                        return false;\n+                    }\n+                    1 => {\n+                        rtdebug!(\"resuming now\");\n+                        this.resume_task_immediately(task);\n+                        return true;\n+                    }\n+                    2 => {\n+                        rtdebug!(\"re-queueing\")\n+                        this.enqueue_task(task);\n+                        Local::put(this);\n+                        return false;\n+                    }\n+                    3 => {\n+                        rtdebug!(\"resuming now\");\n+                        this.resume_task_immediately(task);\n+                        return true;\n+                    }\n+                    4 => {\n+                        abort!(\"task home was None!\");\n+                    }\n+                    _ => {\n+                        abort!(\"literally, you should not be here\");\n+                    }\n+                }\n             }\n+\n             None => {\n-                rtdebug!(\"no tasks in queue\");\n-                Local::put(this);\n-                return false;\n-            }\n+               rtdebug!(\"no tasks in queue\");\n+               Local::put(this);\n+               return false;\n+           }\n         }\n     }\n \n@@ -319,21 +455,32 @@ pub impl Scheduler {\n         abort!(\"control reached end of task\");\n     }\n \n-    fn schedule_new_task(~self, task: ~Coroutine) {\n+    pub fn schedule_task(~self, task: ~Coroutine) {\n         assert!(self.in_task_context());\n \n-        do self.switch_running_tasks_and_then(task) |sched, last_task| {\n-            let last_task = Cell(last_task);\n-            sched.enqueue_task(last_task.take());\n-        }\n-    }\n+        // is the task home?\n+        let is_home = task.is_home_no_tls(&self);\n \n-    fn schedule_task(~self, task: ~Coroutine) {\n-        assert!(self.in_task_context());\n+        // does the task have a home?\n+        let homed = task.homed();\n \n-        do self.switch_running_tasks_and_then(task) |sched, last_task| {\n-            let last_task = Cell(last_task);\n-            sched.enqueue_task(last_task.take());\n+        let mut this = self;\n+\n+        if is_home || (!homed && this.run_anything) {\n+            // here we know we are home, execute now OR we know we\n+            // aren't homed, and that this sched doesn't care\n+            do this.switch_running_tasks_and_then(task) |sched, last_task| {\n+                let last_task = Cell(last_task);\n+                sched.enqueue_task(last_task.take());\n+            }\n+        } else if !homed && !this.run_anything {\n+            // the task isn't homed, but it can't be run here\n+            this.enqueue_task(task);\n+            Local::put(this);\n+        } else {\n+            // task isn't home, so don't run it here, send it home\n+            Scheduler::send_task_home(task);\n+            Local::put(this);\n         }\n     }\n \n@@ -515,25 +662,106 @@ impl SchedHandle {\n }\n \n pub impl Coroutine {\n+\n+    /// This function checks that a coroutine is running \"home\".\n+    fn is_home(&self) -> bool {\n+        rtdebug!(\"checking if coroutine is home\");\n+        do Local::borrow::<Scheduler,bool> |sched| {\n+            match self.task.home {\n+                Some(AnySched) => { false }\n+                Some(Sched(SchedHandle { sched_id: ref id, _ })) => {\n+                    *id == sched.sched_id()\n+                }\n+                None => { abort!(\"error: homeless task!\"); }\n+            }\n+        }\n+    }\n+\n+    /// Without access to self, but with access to the \"expected home\n+    /// id\", see if we are home.\n+    fn is_home_using_id(id: uint) -> bool {\n+        rtdebug!(\"checking if coroutine is home using id\");\n+        do Local::borrow::<Scheduler,bool> |sched| {\n+            if sched.sched_id() == id {\n+                true\n+            } else {\n+                false\n+            }\n+        }\n+    }\n+\n+    /// Check if this coroutine has a home\n+    fn homed(&self) -> bool {\n+        rtdebug!(\"checking if this coroutine has a home\");\n+        match self.task.home {\n+            Some(AnySched) => { false }\n+            Some(Sched(_)) => { true }\n+            None => { abort!(\"error: homeless task!\");\n+                    }\n+        }\n+    }\n+\n+    /// A version of is_home that does not need to use TLS, it instead\n+    /// takes local scheduler as a parameter.\n+    fn is_home_no_tls(&self, sched: &~Scheduler) -> bool {\n+        rtdebug!(\"checking if coroutine is home without tls\");\n+        match self.task.home {\n+            Some(AnySched) => { true }\n+            Some(Sched(SchedHandle { sched_id: ref id, _})) => {\n+                *id == sched.sched_id()\n+            }\n+            None => { abort!(\"error: homeless task!\"); }\n+        }\n+    }\n+\n+    /// Check TLS for the scheduler to see if we are on a special\n+    /// scheduler.\n+    pub fn on_special() -> bool {\n+        rtdebug!(\"checking if coroutine is executing on special sched\");\n+        do Local::borrow::<Scheduler,bool>() |sched| {\n+            !sched.run_anything\n+        }\n+    }\n+\n+    // Created new variants of \"new\" that takes a home scheduler\n+    // parameter. The original with_task now calls with_task_homed\n+    // using the AnySched paramter.\n+\n+    fn new_homed(stack_pool: &mut StackPool, home: SchedHome, start: ~fn()) -> Coroutine {\n+        Coroutine::with_task_homed(stack_pool, ~Task::new(), start, home)\n+    }\n+\n     fn new(stack_pool: &mut StackPool, start: ~fn()) -> Coroutine {\n         Coroutine::with_task(stack_pool, ~Task::new(), start)\n     }\n \n-    fn with_task(stack_pool: &mut StackPool,\n-                  task: ~Task,\n-                  start: ~fn()) -> Coroutine {\n+    fn with_task_homed(stack_pool: &mut StackPool,\n+                       task: ~Task,\n+                       start: ~fn(),\n+                       home: SchedHome) -> Coroutine {\n \n         static MIN_STACK_SIZE: uint = 10000000; // XXX: Too much stack\n \n         let start = Coroutine::build_start_wrapper(start);\n         let mut stack = stack_pool.take_segment(MIN_STACK_SIZE);\n         // NB: Context holds a pointer to that ~fn\n         let initial_context = Context::new(start, &mut stack);\n-        return Coroutine {\n+        let mut crt = Coroutine {\n             current_stack_segment: stack,\n             saved_context: initial_context,\n-            task: task\n+            task: task,\n         };\n+        crt.task.home = Some(home);\n+        return crt;\n+    }\n+\n+    fn with_task(stack_pool: &mut StackPool,\n+                 task: ~Task,\n+                 start: ~fn()) -> Coroutine {\n+        Coroutine::with_task_homed(stack_pool,\n+                                   task,\n+                                   start,\n+                                   AnySched)\n     }\n \n     priv fn build_start_wrapper(start: ~fn()) -> ~fn() {\n@@ -549,17 +777,20 @@ pub impl Coroutine {\n \n                 let sched = Local::unsafe_borrow::<Scheduler>();\n                 let task = (*sched).current_task.get_mut_ref();\n-                // FIXME #6141: shouldn't neet to put `start()` in another closure\n+                // FIXME #6141: shouldn't neet to put `start()` in\n+                // another closure\n                 let start_cell = Cell(start_cell.take());\n                 do task.task.run {\n-                    // N.B. Removing `start` from the start wrapper closure\n-                    // by emptying a cell is critical for correctness. The ~Task\n-                    // pointer, and in turn the closure used to initialize the first\n-                    // call frame, is destroyed in scheduler context, not task context.\n-                    // So any captured closures must not contain user-definable dtors\n-                    // that expect to be in task context. By moving `start` out of\n-                    // the closure, all the user code goes out of scope while\n-                    // the task is still running.\n+                    // N.B. Removing `start` from the start wrapper\n+                    // closure by emptying a cell is critical for\n+                    // correctness. The ~Task pointer, and in turn the\n+                    // closure used to initialize the first call\n+                    // frame, is destroyed in scheduler context, not\n+                    // task context.  So any captured closures must\n+                    // not contain user-definable dtors that expect to\n+                    // be in task context. By moving `start` out of\n+                    // the closure, all the user code goes out of\n+                    // scope while the task is still running.\n                     let start = start_cell.take();\n                     start();\n                 };\n@@ -603,6 +834,305 @@ mod test {\n     use rt::test::*;\n     use super::*;\n     use rt::thread::Thread;\n+    use ptr::to_uint;\n+\n+    // Confirm that a sched_id actually is the uint form of the\n+    // pointer to the scheduler struct.\n+\n+    #[test]\n+    fn simple_sched_id_test() {\n+        do run_in_bare_thread {\n+            let sched = ~new_test_uv_sched();\n+            assert!(to_uint(sched) == sched.sched_id());\n+        }\n+    }\n+\n+    // Compare two scheduler ids that are different, this should never\n+    // fail but may catch a mistake someday.\n+\n+    #[test]\n+    fn compare_sched_id_test() {\n+        do run_in_bare_thread {\n+            let sched_one = ~new_test_uv_sched();\n+            let sched_two = ~new_test_uv_sched();\n+            assert!(sched_one.sched_id() != sched_two.sched_id());\n+        }\n+    }\n+\n+    // A simple test to check if a homed task run on a single\n+    // scheduler ends up executing while home.\n+\n+    #[test]\n+    fn test_home_sched() {\n+        do run_in_bare_thread {\n+            let mut task_ran = false;\n+            let task_ran_ptr: *mut bool = &mut task_ran;\n+            let mut sched = ~new_test_uv_sched();\n+\n+            let sched_handle = sched.make_handle();\n+            let sched_id = sched.sched_id();\n+\n+            let task = ~do Coroutine::new_homed(&mut sched.stack_pool,\n+                                                Sched(sched_handle)) {\n+                unsafe { *task_ran_ptr = true };\n+                let sched = Local::take::<Scheduler>();\n+                assert!(sched.sched_id() == sched_id);\n+                Local::put::<Scheduler>(sched);\n+            };\n+            sched.enqueue_task(task);\n+            sched.run();\n+            assert!(task_ran);\n+        }\n+    }\n+\n+    // A test for each state of schedule_task\n+\n+    #[test]\n+    fn test_schedule_home_states() {\n+\n+        use rt::uv::uvio::UvEventLoop;\n+        use rt::sched::Shutdown;\n+        use rt::sleeper_list::SleeperList;\n+        use rt::work_queue::WorkQueue;\n+\n+        do run_in_bare_thread {\n+//            let nthreads = 2;\n+\n+            let sleepers = SleeperList::new();\n+            let work_queue = WorkQueue::new();\n+\n+            // our normal scheduler\n+            let mut normal_sched = ~Scheduler::new(\n+                ~UvEventLoop::new(),\n+                work_queue.clone(),\n+                sleepers.clone());\n+\n+            let normal_handle = Cell(normal_sched.make_handle());\n+\n+            // our special scheduler\n+            let mut special_sched = ~Scheduler::new_special(\n+                ~UvEventLoop::new(),\n+                work_queue.clone(),\n+                sleepers.clone(),\n+                true);\n+\n+            let special_handle = Cell(special_sched.make_handle());\n+            let special_handle2 = Cell(special_sched.make_handle());\n+            let special_id = special_sched.sched_id();\n+            let t1_handle = special_sched.make_handle();\n+            let t4_handle = special_sched.make_handle();\n+\n+            let t1f = ~do Coroutine::new_homed(&mut special_sched.stack_pool,\n+                                            Sched(t1_handle)) {\n+                let is_home = Coroutine::is_home_using_id(special_id);\n+                rtdebug!(\"t1 should be home: %b\", is_home);\n+                assert!(is_home);\n+            };\n+            let t1f = Cell(t1f);\n+\n+            let t2f = ~do Coroutine::new(&mut normal_sched.stack_pool) {\n+                let on_special = Coroutine::on_special();\n+                rtdebug!(\"t2 should not be on special: %b\", on_special);\n+                assert!(!on_special);\n+            };\n+            let t2f = Cell(t2f);\n+\n+            let t3f = ~do Coroutine::new(&mut normal_sched.stack_pool) {\n+                // not on special\n+                let on_special = Coroutine::on_special();\n+                rtdebug!(\"t3 should not be on special: %b\", on_special);\n+                assert!(!on_special);\n+            };\n+            let t3f = Cell(t3f);\n+\n+            let t4f = ~do Coroutine::new_homed(&mut special_sched.stack_pool,\n+                                            Sched(t4_handle)) {\n+                // is home\n+                let home = Coroutine::is_home_using_id(special_id);\n+                rtdebug!(\"t4 should be home: %b\", home);\n+                assert!(home);\n+            };\n+            let t4f = Cell(t4f);\n+\n+            // we have four tests, make them as closures\n+            let t1: ~fn() = || {\n+                // task is home on special\n+                let task = t1f.take();\n+                let sched = Local::take::<Scheduler>();\n+                sched.schedule_task(task);\n+            };\n+            let t2: ~fn() = || {\n+                // not homed, task doesn't care\n+                let task = t2f.take();\n+                let sched = Local::take::<Scheduler>();\n+                sched.schedule_task(task);\n+            };\n+            let t3: ~fn() = || {\n+                // task not homed, must leave\n+                let task = t3f.take();\n+                let sched = Local::take::<Scheduler>();\n+                sched.schedule_task(task);\n+            };\n+            let t4: ~fn() = || {\n+                // task not home, send home\n+                let task = t4f.take();\n+                let sched = Local::take::<Scheduler>();\n+                sched.schedule_task(task);\n+            };\n+\n+            let t1 = Cell(t1);\n+            let t2 = Cell(t2);\n+            let t3 = Cell(t3);\n+            let t4 = Cell(t4);\n+\n+            // build a main task that runs our four tests\n+            let main_task = ~do Coroutine::new(&mut normal_sched.stack_pool) {\n+                // the two tasks that require a normal start location\n+                t2.take()();\n+                t4.take()();\n+                normal_handle.take().send(Shutdown);\n+                special_handle.take().send(Shutdown);\n+            };\n+\n+            // task to run the two \"special start\" tests\n+            let special_task = ~do Coroutine::new_homed(\n+                &mut special_sched.stack_pool,\n+                Sched(special_handle2.take())) {\n+                t1.take()();\n+                t3.take()();\n+            };\n+\n+            // enqueue the main tasks\n+            normal_sched.enqueue_task(special_task);\n+            normal_sched.enqueue_task(main_task);\n+\n+            let nsched_cell = Cell(normal_sched);\n+            let normal_thread = do Thread::start {\n+                let sched = nsched_cell.take();\n+                sched.run();\n+            };\n+\n+            let ssched_cell = Cell(special_sched);\n+            let special_thread = do Thread::start {\n+                let sched = ssched_cell.take();\n+                sched.run();\n+            };\n+\n+            // wait for the end\n+            let _thread1 = normal_thread;\n+            let _thread2 = special_thread;\n+\n+        }\n+    }\n+\n+    // The following test is a bit of a mess, but it trys to do\n+    // something tricky so I'm not sure how to get around this in the\n+    // short term.\n+\n+    // A number of schedulers are created, and then a task is created\n+    // and assigned a home scheduler. It is then \"started\" on a\n+    // different scheduler. The scheduler it is started on should\n+    // observe that the task is not home, and send it home.\n+\n+    // This test is light in that it does very little.\n+\n+    #[test]\n+    fn test_transfer_task_home() {\n+\n+        use rt::uv::uvio::UvEventLoop;\n+        use rt::sched::Shutdown;\n+        use rt::sleeper_list::SleeperList;\n+        use rt::work_queue::WorkQueue;\n+        use uint;\n+        use container::Container;\n+        use old_iter::MutableIter;\n+        use vec::OwnedVector;\n+\n+        do run_in_bare_thread {\n+\n+            static N: uint = 8;\n+\n+            let sleepers = SleeperList::new();\n+            let work_queue = WorkQueue::new();\n+\n+            let mut handles = ~[];\n+            let mut scheds = ~[];\n+\n+            for uint::range(0, N) |_| {\n+                let loop_ = ~UvEventLoop::new();\n+                let mut sched = ~Scheduler::new(loop_,\n+                                                work_queue.clone(),\n+                                                sleepers.clone());\n+                let handle = sched.make_handle();\n+                rtdebug!(\"sched id: %u\", handle.sched_id);\n+                handles.push(handle);\n+                scheds.push(sched);\n+            };\n+\n+            let handles = Cell(handles);\n+\n+            let home_handle = scheds[6].make_handle();\n+            let home_id = home_handle.sched_id;\n+            let home = Sched(home_handle);\n+\n+            let main_task = ~do Coroutine::new_homed(&mut scheds[1].stack_pool, home) {\n+\n+                // Here we check if the task is running on its home.\n+                let sched = Local::take::<Scheduler>();\n+                rtdebug!(\"run location scheduler id: %u, home: %u\",\n+                         sched.sched_id(),\n+                         home_id);\n+                assert!(sched.sched_id() == home_id);\n+                Local::put::<Scheduler>(sched);\n+\n+                let mut handles = handles.take();\n+                for handles.each_mut |handle| {\n+                    handle.send(Shutdown);\n+                }\n+            };\n+\n+            scheds[0].enqueue_task(main_task);\n+\n+            let mut threads = ~[];\n+\n+            while !scheds.is_empty() {\n+                let sched = scheds.pop();\n+                let sched_cell = Cell(sched);\n+                let thread = do Thread::start {\n+                    let sched = sched_cell.take();\n+                    sched.run();\n+                };\n+                threads.push(thread);\n+            }\n+\n+            let _threads = threads;\n+        }\n+    }\n+\n+    // Do it a lot\n+\n+    #[test]\n+    fn test_stress_schedule_task_states() {\n+        let n = stress_factor() * 120;\n+        for int::range(0,n as int) |_| {\n+            test_schedule_home_states();\n+        }\n+    }\n+\n+    // The goal is that this is the high-stress test for making sure\n+    // homing is working. It allocates RUST_RT_STRESS tasks that\n+    // do nothing but assert that they are home at execution\n+    // time. These tasks are queued to random schedulers, so sometimes\n+    // they are home and sometimes not. It also runs RUST_RT_STRESS\n+    // times.\n+\n+    #[test]\n+    fn test_stress_homed_tasks() {\n+        let n = stress_factor();\n+        for int::range(0,n as int) |_| {\n+            run_in_mt_newsched_task_random_homed();\n+        }\n+    }\n \n     #[test]\n     fn test_simple_scheduling() {\n@@ -683,7 +1213,7 @@ mod test {\n             assert_eq!(count, MAX);\n \n             fn run_task(count_ptr: *mut int) {\n-                do Local::borrow::<Scheduler> |sched| {\n+                do Local::borrow::<Scheduler, ()> |sched| {\n                     let task = ~do Coroutine::new(&mut sched.stack_pool) {\n                         unsafe {\n                             *count_ptr = *count_ptr + 1;\n@@ -859,8 +1389,8 @@ mod test {\n     fn start_closure_dtor() {\n         use ops::Drop;\n \n-        // Regression test that the `start` task entrypoint can contain dtors\n-        // that use task resources\n+        // Regression test that the `start` task entrypoint can\n+        // contain dtors that use task resources\n         do run_in_newsched_task {\n             struct S { field: () }\n \n@@ -875,6 +1405,7 @@ mod test {\n             do spawntask {\n                 let _ss = &s;\n             }\n-        }        \n+        }\n     }\n+\n }"}, {"sha": "06318ac6623b034ff05a6ad48833b8500cfe4f26", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 13, "deletions": 5, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -19,14 +19,16 @@ use cast::transmute;\n use rt::local::Local;\n use super::local_heap::LocalHeap;\n use rt::logging::StdErrLogger;\n+use rt::sched::{SchedHome, AnySched};\n \n pub struct Task {\n     heap: LocalHeap,\n     gc: GarbageCollector,\n     storage: LocalStorage,\n     logger: StdErrLogger,\n     unwinder: Option<Unwinder>,\n-    destroyed: bool\n+    destroyed: bool,\n+    home: Option<SchedHome>\n }\n \n pub struct GarbageCollector;\n@@ -44,7 +46,8 @@ impl Task {\n             storage: LocalStorage(ptr::null(), None),\n             logger: StdErrLogger,\n             unwinder: Some(Unwinder { unwinding: false }),\n-            destroyed: false\n+            destroyed: false,\n+            home: Some(AnySched)\n         }\n     }\n \n@@ -55,14 +58,19 @@ impl Task {\n             storage: LocalStorage(ptr::null(), None),\n             logger: StdErrLogger,\n             unwinder: None,\n-            destroyed: false\n+            destroyed: false,\n+            home: Some(AnySched)\n         }\n     }\n \n+    pub fn give_home(&mut self, new_home: SchedHome) {\n+        self.home = Some(new_home);\n+    }\n+\n     pub fn run(&mut self, f: &fn()) {\n         // This is just an assertion that `run` was called unsafely\n         // and this instance of Task is still accessible.\n-        do Local::borrow::<Task> |task| {\n+        do Local::borrow::<Task, ()> |task| {\n             assert!(ptr::ref_eq(task, self));\n         }\n \n@@ -87,7 +95,7 @@ impl Task {\n     fn destroy(&mut self) {\n         // This is just an assertion that `destroy` was called unsafely\n         // and this instance of Task is still accessible.\n-        do Local::borrow::<Task> |task| {\n+        do Local::borrow::<Task, ()> |task| {\n             assert!(ptr::ref_eq(task, self));\n         }\n         match self.storage {"}, {"sha": "bb284c0254179d8816cb229442078d5bb0d6aaff", "filename": "src/libstd/rt/test.rs", "status": "modified", "additions": 149, "deletions": 1, "changes": 150, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftest.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -88,6 +88,7 @@ pub fn run_in_mt_newsched_task(f: ~fn()) {\n             let loop_ = ~UvEventLoop::new();\n             let mut sched = ~Scheduler::new(loop_, work_queue.clone(), sleepers.clone());\n             let handle = sched.make_handle();\n+\n             handles.push(handle);\n             scheds.push(sched);\n         }\n@@ -128,15 +129,128 @@ pub fn run_in_mt_newsched_task(f: ~fn()) {\n     }\n }\n \n+// THIS IS AWFUL. Copy-pasted the above initialization function but\n+// with a number of hacks to make it spawn tasks on a variety of\n+// schedulers with a variety of homes using the new spawn.\n+\n+pub fn run_in_mt_newsched_task_random_homed() {\n+    use libc;\n+    use os;\n+    use from_str::FromStr;\n+    use rt::uv::uvio::UvEventLoop;\n+    use rt::sched::Shutdown;\n+\n+    do run_in_bare_thread {\n+        let nthreads = match os::getenv(\"RUST_TEST_THREADS\") {\n+            Some(nstr) => FromStr::from_str(nstr).get(),\n+            None => unsafe {\n+                // Using more threads than cores in test code to force\n+                // the OS to preempt them frequently.  Assuming that\n+                // this help stress test concurrent types.\n+                rust_get_num_cpus() * 2\n+            }\n+        };\n+\n+        let sleepers = SleeperList::new();\n+        let work_queue = WorkQueue::new();\n+\n+        let mut handles = ~[];\n+        let mut scheds = ~[];\n+\n+        // create a few special schedulers, those with even indicies\n+        // will be pinned-only\n+        for uint::range(0, nthreads) |i| {\n+            let special = (i % 2) == 0;\n+            let loop_ = ~UvEventLoop::new();\n+            let mut sched = ~Scheduler::new_special(\n+                loop_, work_queue.clone(), sleepers.clone(), special);\n+            let handle = sched.make_handle();\n+            handles.push(handle);\n+            scheds.push(sched);\n+        }\n+\n+        // Schedule a pile o tasks\n+        let n = 5*stress_factor();\n+        for uint::range(0,n) |_i| {\n+                rtdebug!(\"creating task: %u\", _i);\n+                let hf: ~fn() = || { assert!(true) };\n+                spawntask_homed(&mut scheds, hf);\n+            }\n+\n+        // Now we want another pile o tasks that do not ever run on a\n+        // special scheduler, because they are normal tasks. Because\n+        // we can we put these in the \"main\" task.\n+\n+        let n = 5*stress_factor();\n+\n+        let f: ~fn() = || {\n+            for uint::range(0,n) |_| {\n+                let f: ~fn()  = || {\n+                    // Borrow the scheduler we run on and check if it is\n+                    // privileged.\n+                    do Local::borrow::<Scheduler,()> |sched| {\n+                        assert!(sched.run_anything);\n+                    };\n+                };\n+                spawntask_random(f);\n+            };\n+        };\n+\n+        let f_cell = Cell(f);\n+        let handles = Cell(handles);\n+\n+        rtdebug!(\"creating main task\");\n+\n+        let main_task = ~do Coroutine::new(&mut scheds[0].stack_pool) {\n+            f_cell.take()();\n+            let mut handles = handles.take();\n+            // Tell schedulers to exit\n+            for handles.each_mut |handle| {\n+                handle.send(Shutdown);\n+            }\n+        };\n+\n+        rtdebug!(\"queuing main task\")\n+\n+        scheds[0].enqueue_task(main_task);\n+\n+        let mut threads = ~[];\n+\n+        while !scheds.is_empty() {\n+            let sched = scheds.pop();\n+            let sched_cell = Cell(sched);\n+            let thread = do Thread::start {\n+                let sched = sched_cell.take();\n+                rtdebug!(\"running sched: %u\", sched.sched_id());\n+                sched.run();\n+            };\n+\n+            threads.push(thread);\n+        }\n+\n+        rtdebug!(\"waiting on scheduler threads\");\n+\n+        // Wait for schedulers\n+        let _threads = threads;\n+    }\n+\n+    extern {\n+        fn rust_get_num_cpus() -> libc::uintptr_t;\n+    }\n+}\n+\n+\n /// Test tasks will abort on failure instead of unwinding\n pub fn spawntask(f: ~fn()) {\n     use super::sched::*;\n \n+    rtdebug!(\"spawntask taking the scheduler from TLS\")\n     let mut sched = Local::take::<Scheduler>();\n     let task = ~Coroutine::with_task(&mut sched.stack_pool,\n                                      ~Task::without_unwinding(),\n                                      f);\n-    sched.schedule_new_task(task);\n+    rtdebug!(\"spawntask scheduling the new task\");\n+    sched.schedule_task(task);\n }\n \n /// Create a new task and run it right now. Aborts on failure\n@@ -188,6 +302,39 @@ pub fn spawntask_random(f: ~fn()) {\n     }\n }\n \n+/// Spawn a task, with the current scheduler as home, and queue it to\n+/// run later.\n+pub fn spawntask_homed(scheds: &mut ~[~Scheduler], f: ~fn()) {\n+    use super::sched::*;\n+    use rand::{rng, RngUtil};\n+    let mut rng = rng();\n+\n+    let task = {\n+        let sched = &mut scheds[rng.gen_int_range(0,scheds.len() as int)];\n+        let handle = sched.make_handle();\n+        let home_id = handle.sched_id;\n+\n+        // now that we know where this is going, build a new function\n+        // that can assert it is in the right place\n+        let af: ~fn() = || {\n+            do Local::borrow::<Scheduler,()>() |sched| {\n+                rtdebug!(\"home_id: %u, runtime loc: %u\",\n+                         home_id,\n+                         sched.sched_id());\n+                assert!(home_id == sched.sched_id());\n+            };\n+            f()\n+        };\n+\n+        ~Coroutine::with_task_homed(&mut sched.stack_pool,\n+                                    ~Task::without_unwinding(),\n+                                    af,\n+                                    Sched(handle))\n+    };\n+    let dest_sched = &mut scheds[rng.gen_int_range(0,scheds.len() as int)];\n+    // enqueue it for future execution\n+    dest_sched.enqueue_task(task);\n+}\n \n /// Spawn a task and wait for it to finish, returning whether it completed successfully or failed\n pub fn spawntask_try(f: ~fn()) -> Result<(), ()> {\n@@ -266,3 +413,4 @@ pub fn stress_factor() -> uint {\n     }\n }\n \n+"}, {"sha": "c94b0bd642362a02e4835b7b92db18b751413755", "filename": "src/libstd/rt/tube.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Ftube.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Ftube.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftube.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -155,7 +155,7 @@ mod test {\n                     if i == 100 { return; }\n \n                     let tube = Cell(Cell(tube));\n-                    do Local::borrow::<Scheduler> |sched| {\n+                    do Local::borrow::<Scheduler, ()> |sched| {\n                         let tube = tube.take();\n                         do sched.event_loop.callback {\n                             let mut tube = tube.take();"}, {"sha": "ebeb1c204514f21eb4bcf286b5efe935bfedd2e8", "filename": "src/libstd/rt/uv/uvio.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fuv%2Fuvio.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -167,7 +167,7 @@ mod test_remote {\n             let mut tube = Tube::new();\n             let tube_clone = tube.clone();\n             let remote_cell = cell::empty_cell();\n-            do Local::borrow::<Scheduler>() |sched| {\n+            do Local::borrow::<Scheduler, ()>() |sched| {\n                 let tube_clone = tube_clone.clone();\n                 let tube_clone_cell = Cell(tube_clone);\n                 let remote = do sched.event_loop.remote_callback {"}, {"sha": "df5b88207eccfc4c13473c0af1ebb262efae8915", "filename": "src/libstd/task/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Ftask%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Ftask%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fmod.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -514,7 +514,7 @@ pub fn failing() -> bool {\n         }\n         _ => {\n             let mut unwinding = false;\n-            do Local::borrow::<Task> |local| {\n+            do Local::borrow::<Task, ()> |local| {\n                 unwinding = match local.unwinder {\n                     Some(unwinder) => {\n                         unwinder.unwinding"}, {"sha": "5e507238f671fc52468f6cdb3a1b3d06e63ee1bb", "filename": "src/libstd/task/spawn.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Ftask%2Fspawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Ftask%2Fspawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fspawn.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -578,7 +578,7 @@ fn spawn_raw_newsched(_opts: TaskOpts, f: ~fn()) {\n \n     let mut sched = Local::take::<Scheduler>();\n     let task = ~Coroutine::new(&mut sched.stack_pool, f);\n-    sched.schedule_new_task(task);\n+    sched.schedule_task(task);\n }\n \n fn spawn_raw_oldsched(mut opts: TaskOpts, f: ~fn()) {"}, {"sha": "21ef347874468c8cf7f80fa9c6b80d3760cdfbed", "filename": "src/libstd/unstable/lang.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Funstable%2Flang.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b08c4467980bc712995d421dd50c1cca2948b67b/src%2Flibstd%2Funstable%2Flang.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Flang.rs?ref=b08c4467980bc712995d421dd50c1cca2948b67b", "patch": "@@ -244,7 +244,7 @@ pub unsafe fn local_malloc(td: *c_char, size: uintptr_t) -> *c_char {\n         }\n         _ => {\n             let mut alloc = ::ptr::null();\n-            do Local::borrow::<Task> |task| {\n+            do Local::borrow::<Task,()> |task| {\n                 alloc = task.heap.alloc(td as *c_void, size as uint) as *c_char;\n             }\n             return alloc;\n@@ -262,7 +262,7 @@ pub unsafe fn local_free(ptr: *c_char) {\n             rustrt::rust_upcall_free_noswitch(ptr);\n         }\n         _ => {\n-            do Local::borrow::<Task> |task| {\n+            do Local::borrow::<Task,()> |task| {\n                 task.heap.free(ptr as *c_void);\n             }\n         }"}]}