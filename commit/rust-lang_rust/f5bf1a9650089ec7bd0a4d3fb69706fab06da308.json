{"sha": "f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY1YmYxYTk2NTAwODllYzdiZDBhNGQzZmI2OTcwNmZhYjA2ZGEzMDg=", "commit": {"author": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2021-02-28T05:06:17Z"}, "committer": {"name": "Edwin Cheng", "email": "edwin0cheng@gmail.com", "date": "2021-02-28T05:06:17Z"}, "message": "Fix builtin macros split exprs on comma", "tree": {"sha": "c609fe476f5634a27e0f0342861d999c0e404b9d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c609fe476f5634a27e0f0342861d999c0e404b9d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "html_url": "https://github.com/rust-lang/rust/commit/f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/comments", "author": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "committer": {"login": "edwin0cheng", "id": 11014119, "node_id": "MDQ6VXNlcjExMDE0MTE5", "avatar_url": "https://avatars.githubusercontent.com/u/11014119?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edwin0cheng", "html_url": "https://github.com/edwin0cheng", "followers_url": "https://api.github.com/users/edwin0cheng/followers", "following_url": "https://api.github.com/users/edwin0cheng/following{/other_user}", "gists_url": "https://api.github.com/users/edwin0cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/edwin0cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edwin0cheng/subscriptions", "organizations_url": "https://api.github.com/users/edwin0cheng/orgs", "repos_url": "https://api.github.com/users/edwin0cheng/repos", "events_url": "https://api.github.com/users/edwin0cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/edwin0cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f682627da4be4777fa0c1527398ef4136cd929b1", "url": "https://api.github.com/repos/rust-lang/rust/commits/f682627da4be4777fa0c1527398ef4136cd929b1", "html_url": "https://github.com/rust-lang/rust/commit/f682627da4be4777fa0c1527398ef4136cd929b1"}], "stats": {"total": 233, "additions": 144, "deletions": 89}, "files": [{"sha": "6fbb9570a86a0596a0511e67cd6295734c791c9c", "filename": "crates/hir_expand/src/builtin_macro.rs", "status": "modified", "additions": 25, "deletions": 20, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fhir_expand%2Fsrc%2Fbuiltin_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fhir_expand%2Fsrc%2Fbuiltin_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fbuiltin_macro.rs?ref=f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "patch": "@@ -6,7 +6,7 @@ use crate::{\n \n use base_db::{AnchoredPath, FileId};\n use either::Either;\n-use mbe::{parse_to_token_tree, ExpandResult};\n+use mbe::{parse_exprs_with_sep, parse_to_token_tree, ExpandResult};\n use parser::FragmentKind;\n use syntax::ast::{self, AstToken};\n \n@@ -238,35 +238,21 @@ fn format_args_expand(\n     // ])\n     // ```,\n     // which is still not really correct, but close enough for now\n-    let mut args = Vec::new();\n-    let mut current = Vec::new();\n-    for tt in tt.token_trees.iter().cloned() {\n-        match tt {\n-            tt::TokenTree::Leaf(tt::Leaf::Punct(p)) if p.char == ',' => {\n-                args.push(current);\n-                current = Vec::new();\n-            }\n-            _ => {\n-                current.push(tt);\n-            }\n-        }\n-    }\n-    if !current.is_empty() {\n-        args.push(current);\n-    }\n+    let mut args = parse_exprs_with_sep(tt, ',');\n+\n     if args.is_empty() {\n         return ExpandResult::only_err(mbe::ExpandError::NoMatchingRule);\n     }\n     for arg in &mut args {\n         // Remove `key =`.\n-        if matches!(arg.get(1), Some(tt::TokenTree::Leaf(tt::Leaf::Punct(p))) if p.char == '=' && p.spacing != tt::Spacing::Joint)\n+        if matches!(arg.token_trees.get(1), Some(tt::TokenTree::Leaf(tt::Leaf::Punct(p))) if p.char == '=' && p.spacing != tt::Spacing::Joint)\n         {\n-            arg.drain(..2);\n+            arg.token_trees.drain(..2);\n         }\n     }\n     let _format_string = args.remove(0);\n     let arg_tts = args.into_iter().flat_map(|arg| {\n-        quote! { std::fmt::ArgumentV1::new(&(##arg), std::fmt::Display::fmt), }\n+        quote! { std::fmt::ArgumentV1::new(&(#arg), std::fmt::Display::fmt), }\n     }.token_trees).collect::<Vec<_>>();\n     let expanded = quote! {\n         std::fmt::Arguments::new_v1(&[], &[##arg_tts])\n@@ -719,6 +705,25 @@ mod tests {\n         );\n     }\n \n+    #[test]\n+    fn test_format_args_expand_with_comma_exprs() {\n+        let expanded = expand_builtin_macro(\n+            r#\"\n+            #[rustc_builtin_macro]\n+            macro_rules! format_args {\n+                ($fmt:expr) => ({ /* compiler built-in */ });\n+                ($fmt:expr, $($args:tt)*) => ({ /* compiler built-in */ })\n+            }\n+            format_args!(\"{} {:?}\", a::<A,B>(), b);\n+            \"#,\n+        );\n+\n+        assert_eq!(\n+            expanded,\n+            r#\"std::fmt::Arguments::new_v1(&[], &[std::fmt::ArgumentV1::new(&(a::<A,B>()),std::fmt::Display::fmt),std::fmt::ArgumentV1::new(&(b),std::fmt::Display::fmt),])\"#\n+        );\n+    }\n+\n     #[test]\n     fn test_include_bytes_expand() {\n         let expanded = expand_builtin_macro("}, {"sha": "e3bd4c09a0ea131a86678f8871df80878d61c97b", "filename": "crates/mbe/src/expander/matcher.rs", "status": "modified", "additions": 2, "deletions": 66, "changes": 68, "blob_url": "https://github.com/rust-lang/rust/blob/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fmbe%2Fsrc%2Fexpander%2Fmatcher.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fmbe%2Fsrc%2Fexpander%2Fmatcher.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fexpander%2Fmatcher.rs?ref=f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "patch": "@@ -3,15 +3,13 @@\n use crate::{\n     expander::{Binding, Bindings, Fragment},\n     parser::{Op, RepeatKind, Separator},\n-    subtree_source::SubtreeTokenSource,\n     tt_iter::TtIter,\n     ExpandError, MetaTemplate,\n };\n \n use super::ExpandResult;\n-use parser::{FragmentKind::*, TreeSink};\n-use syntax::{SmolStr, SyntaxKind};\n-use tt::buffer::{Cursor, TokenBuffer};\n+use parser::FragmentKind::*;\n+use syntax::SmolStr;\n \n impl Bindings {\n     fn push_optional(&mut self, name: &SmolStr) {\n@@ -409,68 +407,6 @@ impl<'a> TtIter<'a> {\n         .into())\n     }\n \n-    fn expect_fragment(\n-        &mut self,\n-        fragment_kind: parser::FragmentKind,\n-    ) -> ExpandResult<Option<tt::TokenTree>> {\n-        struct OffsetTokenSink<'a> {\n-            cursor: Cursor<'a>,\n-            error: bool,\n-        }\n-\n-        impl<'a> TreeSink for OffsetTokenSink<'a> {\n-            fn token(&mut self, kind: SyntaxKind, mut n_tokens: u8) {\n-                if kind == SyntaxKind::LIFETIME_IDENT {\n-                    n_tokens = 2;\n-                }\n-                for _ in 0..n_tokens {\n-                    self.cursor = self.cursor.bump_subtree();\n-                }\n-            }\n-            fn start_node(&mut self, _kind: SyntaxKind) {}\n-            fn finish_node(&mut self) {}\n-            fn error(&mut self, _error: parser::ParseError) {\n-                self.error = true;\n-            }\n-        }\n-\n-        let buffer = TokenBuffer::from_tokens(&self.inner.as_slice());\n-        let mut src = SubtreeTokenSource::new(&buffer);\n-        let mut sink = OffsetTokenSink { cursor: buffer.begin(), error: false };\n-\n-        parser::parse_fragment(&mut src, &mut sink, fragment_kind);\n-\n-        let mut err = None;\n-        if !sink.cursor.is_root() || sink.error {\n-            err = Some(err!(\"expected {:?}\", fragment_kind));\n-        }\n-\n-        let mut curr = buffer.begin();\n-        let mut res = vec![];\n-\n-        if sink.cursor.is_root() {\n-            while curr != sink.cursor {\n-                if let Some(token) = curr.token_tree() {\n-                    res.push(token);\n-                }\n-                curr = curr.bump();\n-            }\n-        }\n-        self.inner = self.inner.as_slice()[res.len()..].iter();\n-        if res.len() == 0 && err.is_none() {\n-            err = Some(err!(\"no tokens consumed\"));\n-        }\n-        let res = match res.len() {\n-            1 => Some(res[0].cloned()),\n-            0 => None,\n-            _ => Some(tt::TokenTree::Subtree(tt::Subtree {\n-                delimiter: None,\n-                token_trees: res.into_iter().map(|it| it.cloned()).collect(),\n-            })),\n-        };\n-        ExpandResult { value: res, err }\n-    }\n-\n     fn eat_vis(&mut self) -> Option<tt::TokenTree> {\n         let mut fork = self.clone();\n         match fork.expect_fragment(Visibility) {"}, {"sha": "4c298f85fb35b2c4ab3c94a0418937c89b0851c0", "filename": "crates/mbe/src/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fmbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fmbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Flib.rs?ref=f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "patch": "@@ -65,8 +65,8 @@ impl fmt::Display for ExpandError {\n }\n \n pub use crate::syntax_bridge::{\n-    ast_to_token_tree, parse_to_token_tree, syntax_node_to_token_tree, token_tree_to_syntax_node,\n-    TokenMap,\n+    ast_to_token_tree, parse_exprs_with_sep, parse_to_token_tree, syntax_node_to_token_tree,\n+    token_tree_to_syntax_node, TokenMap,\n };\n \n /// This struct contains AST for a single `macro_rules` definition. What might"}, {"sha": "5a91781fc4b0dc4d772bb3157d6d9ffa1cc76b89", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 38, "deletions": 1, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "patch": "@@ -10,8 +10,8 @@ use syntax::{\n };\n use tt::buffer::{Cursor, TokenBuffer};\n \n-use crate::subtree_source::SubtreeTokenSource;\n use crate::ExpandError;\n+use crate::{subtree_source::SubtreeTokenSource, tt_iter::TtIter};\n \n #[derive(Debug, PartialEq, Eq, Clone, Copy)]\n pub enum TokenTextRange {\n@@ -112,6 +112,43 @@ pub fn parse_to_token_tree(text: &str) -> Option<(tt::Subtree, TokenMap)> {\n     Some((subtree, conv.id_alloc.map))\n }\n \n+/// Split token tree with seperate expr: $($e:expr)SEP*\n+pub fn parse_exprs_with_sep(tt: &tt::Subtree, sep: char) -> Vec<tt::Subtree> {\n+    if tt.token_trees.is_empty() {\n+        return Vec::new();\n+    }\n+\n+    let mut iter = TtIter::new(tt);\n+    let mut res = Vec::new();\n+\n+    while iter.peek_n(0).is_some() {\n+        let expanded = iter.expect_fragment(FragmentKind::Expr);\n+        if expanded.err.is_some() {\n+            break;\n+        }\n+\n+        res.push(match expanded.value {\n+            None => break,\n+            Some(tt @ tt::TokenTree::Leaf(_)) => {\n+                tt::Subtree { delimiter: None, token_trees: vec![tt.into()] }\n+            }\n+            Some(tt::TokenTree::Subtree(tt)) => tt,\n+        });\n+\n+        let mut fork = iter.clone();\n+        if fork.expect_char(sep).is_err() {\n+            break;\n+        }\n+        iter = fork;\n+    }\n+\n+    if iter.peek_n(0).is_some() {\n+        res.push(tt::Subtree { delimiter: None, token_trees: iter.into_iter().cloned().collect() });\n+    }\n+\n+    res\n+}\n+\n impl TokenMap {\n     pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n         let &(token_id, _) = self.entries.iter().find(|(_, range)| match range {"}, {"sha": "a362d31fcff9a2e68c8c5c53c2c8dfaa9e04c773", "filename": "crates/mbe/src/tt_iter.rs", "status": "modified", "additions": 77, "deletions": 0, "changes": 77, "blob_url": "https://github.com/rust-lang/rust/blob/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fmbe%2Fsrc%2Ftt_iter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5bf1a9650089ec7bd0a4d3fb69706fab06da308/crates%2Fmbe%2Fsrc%2Ftt_iter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Ftt_iter.rs?ref=f5bf1a9650089ec7bd0a4d3fb69706fab06da308", "patch": "@@ -1,5 +1,20 @@\n //! FIXME: write short doc here\n \n+use crate::{subtree_source::SubtreeTokenSource, ExpandError, ExpandResult};\n+\n+use parser::TreeSink;\n+use syntax::SyntaxKind;\n+use tt::buffer::{Cursor, TokenBuffer};\n+\n+macro_rules! err {\n+    () => {\n+        ExpandError::BindingError(format!(\"\"))\n+    };\n+    ($($tt:tt)*) => {\n+        ExpandError::BindingError(format!($($tt)*))\n+    };\n+}\n+\n #[derive(Debug, Clone)]\n pub(crate) struct TtIter<'a> {\n     pub(crate) inner: std::slice::Iter<'a, tt::TokenTree>,\n@@ -56,6 +71,68 @@ impl<'a> TtIter<'a> {\n         }\n     }\n \n+    pub(crate) fn expect_fragment(\n+        &mut self,\n+        fragment_kind: parser::FragmentKind,\n+    ) -> ExpandResult<Option<tt::TokenTree>> {\n+        struct OffsetTokenSink<'a> {\n+            cursor: Cursor<'a>,\n+            error: bool,\n+        }\n+\n+        impl<'a> TreeSink for OffsetTokenSink<'a> {\n+            fn token(&mut self, kind: SyntaxKind, mut n_tokens: u8) {\n+                if kind == SyntaxKind::LIFETIME_IDENT {\n+                    n_tokens = 2;\n+                }\n+                for _ in 0..n_tokens {\n+                    self.cursor = self.cursor.bump_subtree();\n+                }\n+            }\n+            fn start_node(&mut self, _kind: SyntaxKind) {}\n+            fn finish_node(&mut self) {}\n+            fn error(&mut self, _error: parser::ParseError) {\n+                self.error = true;\n+            }\n+        }\n+\n+        let buffer = TokenBuffer::from_tokens(&self.inner.as_slice());\n+        let mut src = SubtreeTokenSource::new(&buffer);\n+        let mut sink = OffsetTokenSink { cursor: buffer.begin(), error: false };\n+\n+        parser::parse_fragment(&mut src, &mut sink, fragment_kind);\n+\n+        let mut err = None;\n+        if !sink.cursor.is_root() || sink.error {\n+            err = Some(err!(\"expected {:?}\", fragment_kind));\n+        }\n+\n+        let mut curr = buffer.begin();\n+        let mut res = vec![];\n+\n+        if sink.cursor.is_root() {\n+            while curr != sink.cursor {\n+                if let Some(token) = curr.token_tree() {\n+                    res.push(token);\n+                }\n+                curr = curr.bump();\n+            }\n+        }\n+        self.inner = self.inner.as_slice()[res.len()..].iter();\n+        if res.len() == 0 && err.is_none() {\n+            err = Some(err!(\"no tokens consumed\"));\n+        }\n+        let res = match res.len() {\n+            1 => Some(res[0].cloned()),\n+            0 => None,\n+            _ => Some(tt::TokenTree::Subtree(tt::Subtree {\n+                delimiter: None,\n+                token_trees: res.into_iter().map(|it| it.cloned()).collect(),\n+            })),\n+        };\n+        ExpandResult { value: res, err }\n+    }\n+\n     pub(crate) fn peek_n(&self, n: usize) -> Option<&tt::TokenTree> {\n         self.inner.as_slice().get(n)\n     }"}]}