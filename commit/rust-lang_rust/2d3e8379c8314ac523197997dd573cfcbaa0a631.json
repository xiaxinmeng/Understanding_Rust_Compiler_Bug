{"sha": "2d3e8379c8314ac523197997dd573cfcbaa0a631", "node_id": "MDY6Q29tbWl0NzI0NzEyOjJkM2U4Mzc5YzgzMTRhYzUyMzE5Nzk5N2RkNTczY2ZjYmFhMGE2MzE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-08-31T21:34:08Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-08-31T21:34:08Z"}, "message": "Auto merge of #28079 - huonw:simd, r=alexcrichton\n\nThis adds a new Python script (compatible with 2.7 and 3.x) that will consume some JSON files that define a platform's intrinsics. It can output a file that defines the intrinsics in the compiler, or an `extern` block that will import them.\r\n\r\nThe complexity of the generator is to be DRY: platforms (especially ARM and AArch64) have a lot of repetition with their intrinsics, for different versions with different types, so being able to write it once is nice.", "tree": {"sha": "fcc921c770b1c9498e819fac78fee4300aaf129b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/fcc921c770b1c9498e819fac78fee4300aaf129b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2d3e8379c8314ac523197997dd573cfcbaa0a631", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2d3e8379c8314ac523197997dd573cfcbaa0a631", "html_url": "https://github.com/rust-lang/rust/commit/2d3e8379c8314ac523197997dd573cfcbaa0a631", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2d3e8379c8314ac523197997dd573cfcbaa0a631/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f9f82f8dc8c936c9cd55d529d9941c5d925d9e67", "url": "https://api.github.com/repos/rust-lang/rust/commits/f9f82f8dc8c936c9cd55d529d9941c5d925d9e67", "html_url": "https://github.com/rust-lang/rust/commit/f9f82f8dc8c936c9cd55d529d9941c5d925d9e67"}, {"sha": "14f9c97356a9144a5b2ef1ff309140196dfea3da", "url": "https://api.github.com/repos/rust-lang/rust/commits/14f9c97356a9144a5b2ef1ff309140196dfea3da", "html_url": "https://github.com/rust-lang/rust/commit/14f9c97356a9144a5b2ef1ff309140196dfea3da"}], "stats": {"total": 8783, "additions": 8173, "deletions": 610}, "files": [{"sha": "dbccdc37d3f40eaaa9706729a94c008b4ed08a16", "filename": "src/etc/platform-intrinsics/aarch64.json", "status": "added", "additions": 550, "deletions": 0, "changes": 550, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Faarch64.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Faarch64.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Faarch64.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,550 @@\n+{\n+    \"platform\": \"aarch64\",\n+    \"intrinsic_prefix\": \"aarch64_v\",\n+    \"llvm_prefix\": \"llvm.aarch64.neon.\",\n+    \"number_info\": {\n+        \"signed\": {\n+            \"kind\": \"s\",\n+            \"data_type\": { \"pattern\": \"s{bitwidth}\" }\n+        },\n+        \"unsigned\": {\n+            \"kind\": \"u\",\n+            \"data_type\": { \"pattern\": \"u{bitwidth}\" }\n+        },\n+        \"float\": {\n+            \"kind\": \"f\",\n+            \"data_type\": { \"pattern\": \"f{bitwidth}\" }\n+        }\n+    },\n+    \"width_info\": {\n+        \"64\": { \"width\": \"\" },\n+        \"128\": { \"width\": \"q\" }\n+    },\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"hadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}hadd.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rhadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}rhadd.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}qadd.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"uqadd_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"suqadd.{0.llvm_name}\",\n+            \"ret\": \"s(8-64)\",\n+            \"args\": [\"0\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"sqadd_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"usqadd.{0.llvm_name}\",\n+            \"ret\": \"u(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"raddhn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"raddhn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"fmulx{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"fmulx.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"fma{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.fma.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qdmulh{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqdmulh.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrdmulh{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqrdmulh.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"mull_{1.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}mull.{0.llvm_name}\",\n+            \"ret\": \"i(16-64)\",\n+            \"args\": [\"0n\", \"0n\"]\n+        },\n+        {\n+            \"intrinsic\": \"qdmull{0.width}_{1.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"sqdmull.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0n\", \"0n\"]\n+        },\n+        {\n+            \"intrinsic\": \"hsub{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}hsub.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qsub{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}qsub.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsubhn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"rsubhn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"abd{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}abd.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f(32-64)\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"max{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}max.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f(32-64)\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"min{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}min.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f(32-64)\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"maxnm{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}maxnm.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"minnm{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}minnm.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"shl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}shl.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}qshl.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"rshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}rshl.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}qrshl.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshrun_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"sqshrun.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshrun_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"sqrshrun.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"{0.kind}qshrn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"rshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"rshrn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"{0.kind}qrshrn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"sri{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"vsri.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"sli{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"vsli.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"vqmovn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"{0.kind}qxtn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"abs{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"abs.{0.llvm_name}\",\n+            \"ret\": \"s(8-64)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"abs{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.fabs.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qabs{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"sqabs.{0.llvm_name}\",\n+            \"ret\": \"s(8-64)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qneg{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqneg.{0.llvm_name}\",\n+            \"ret\": \"s(8-64)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"clz{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.ctlz.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"cls{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"cls.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"cnt{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.ctpop.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"recpe{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}recpe.{0.llvm_name}\",\n+            \"ret\": [\"u32\",\"f(32-64)\"],\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"recps{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"frecps.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"sqrt{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.sqrt.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsqrte{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}rsqrte.{0.llvm_name}\",\n+            \"ret\": [\"u32\",\"f(32-64)\"],\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsqrts{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"frsqrts.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rbit{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"rbit.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"padd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"addp.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"padd{0.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"addp.{0.llvm_name}\",\n+            \"ret\": [\"i64\",\"f64\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"paddl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}addlp.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"i(16-64)\",\n+            \"args\": [\"0dn\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmax{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}maxp.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmax{0.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}maxp.{0.llvm_name}\",\n+            \"ret\": [\"i64\",\"f64\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmin{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}minp.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmin{0.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}minp.{0.llvm_name}\",\n+            \"ret\": [\"i64\",\"f64\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmaxnm{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}maxnmp.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmaxnm{0.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}maxnmp.{0.llvm_name}\",\n+            \"ret\": [\"i64\",\"f64\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pminnm{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}minnmp.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pminnm{0.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}minnmp.{0.llvm_name}\",\n+            \"ret\": \"f64\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"addv{1.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}addv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"I(8-32)\",\"F32\"],\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"addv{1.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}addv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"I64\",\"F64\"],\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"addlv{1.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}addlv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"I(16-64)\",\n+            \"args\": [\"0vdn\"]\n+        },\n+        {\n+            \"intrinsic\": \"maxv{1.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}maxv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"I(8-32)\",\"F32\"],\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"maxv{1.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}maxv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"F64\",\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"minv{1.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}minv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"I(8-32)\",\"F32\"],\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"minv{1.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}minv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"F64\",\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"maxnmv{1.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}maxnmv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"F32\",\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"maxnmv{1.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}maxnmv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"F64\",\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"minnmv{1.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"{0.kind}minnmv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"F32\",\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"minnmv{1.width}_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"{0.kind}minnmv.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"F64\",\n+            \"args\": [\"0v\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbl1{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"tbl1.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0x128\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbx1{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"tbx1.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"0x128\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbl2{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"tbl2.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0x128,0x128)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbx2{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"tbx2.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0x128,0x128)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbl3{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"tbl3.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0x128,0x128,0x128)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbx3{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"tbx3.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"(0x128,0x128,0x128)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbl4{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"tbl4.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0x128,0x128,0x128,0x128)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbx4{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"tbx4.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"(0x128,0x128,0x128,0x128)f\", \"0u\"]\n+        }\n+    ]\n+}"}, {"sha": "97db7cbb3e0a52fce179bc7c904e4fc460844bba", "filename": "src/etc/platform-intrinsics/arm.json", "status": "added", "additions": 396, "deletions": 0, "changes": 396, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Farm.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Farm.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Farm.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,396 @@\n+{\n+    \"platform\": \"arm\",\n+    \"intrinsic_prefix\": \"arm_v\",\n+    \"llvm_prefix\": \"llvm.neon.v\",\n+    \"number_info\": {\n+        \"signed\": {\n+            \"kind\": \"s\",\n+            \"data_type\": { \"pattern\": \"s{bitwidth}\" }\n+        },\n+        \"unsigned\": {\n+            \"kind\": \"u\",\n+            \"data_type\": { \"pattern\": \"u{bitwidth}\" }\n+        },\n+        \"float\": {\n+            \"kind\": \"f\",\n+            \"data_type\": { \"pattern\": \"f{bitwidth}\" }\n+        }\n+    },\n+    \"width_info\": {\n+        \"64\": { \"width\": \"\" },\n+        \"128\": { \"width\": \"q\" }\n+    },\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"hadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"hadd{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rhadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"rhadd{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"qadd{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"raddhn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"raddhn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"fma{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.fma.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qdmulh{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqdmulh.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrdmulh{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqrdmulh.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"mull_{1.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"mull{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(16-64)\",\n+            \"args\": [\"0n\", \"0n\"]\n+        },\n+        {\n+            \"intrinsic\": \"qdmull{0.width}_{1.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"sqdmull.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0n\", \"0n\"]\n+        },\n+        {\n+            \"intrinsic\": \"hsub{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"hsub{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qsub{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"qsub{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsubhn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"rsubhn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"abd{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"abd{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"max{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"max{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"min{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"min{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"shl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"shl{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"qshl{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"rshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"rshl{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"qrshl{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshrun_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"sqshrun.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshrun_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"sqrshrun.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"qshrn{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"rshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"rshrn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"qrshrn{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"sri{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"vsri.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"sli{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"vsli.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"vqmovn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"qxtn{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"abs{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"abs.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"abs{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.fabs.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qabs{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"sqabs.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qneg{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqneg.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"clz{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.ctlz.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"cls{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"cls.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"cnt{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.ctpop.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"recpe{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"recpe.{0.llvm_name}\",\n+            \"ret\": [\"u32\",\"f32\"],\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"recps{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"frecps.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"sqrt{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.sqrt.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsqrte{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"rsqrte.{0.llvm_name}\",\n+            \"ret\": [\"u32\",\"f32\"],\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsqrts{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"rsqrts.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"bsl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"bsl.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0u\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"padd{0.width}_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"padd.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"paddl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"paddl{0.kind}.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"i(16-64)\",\n+            \"args\": [\"0dn\"]\n+        },\n+        {\n+            \"intrinsic\": \"padal{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"padal{0.kind}.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"i(16-64)\",\n+            \"args\": [\"0\", \"0dn\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmax{0.width}_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"pmax{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmin{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"pmin{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"tbl1_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbl1\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"tbx1_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbx1\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"0\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"tbl2_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbl2\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"tbx2_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbx2\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"tbl3_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbl3\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0,0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"tbx3_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbx3\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"(0,0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"tbl4_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbl4\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0,0,0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"tbx4_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbx4\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"(0,0,0,0)f\", \"0u\"]\n+        }\n+    ]\n+}"}, {"sha": "97b2f57010b97fcfcdb66c2ac1a837a37e89cb81", "filename": "src/etc/platform-intrinsics/generator.py", "status": "added", "additions": 571, "deletions": 0, "changes": 571, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fgenerator.py", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fgenerator.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fgenerator.py?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,571 @@\n+# Copyright 2015 The Rust Project Developers. See the COPYRIGHT\n+# file at the top-level directory of this distribution and at\n+# http://rust-lang.org/COPYRIGHT.\n+#\n+# Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+# http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+# <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+# option. This file may not be copied, modified, or distributed\n+# except according to those terms.\n+\n+from __future__ import division, print_function\n+import json\n+import argparse\n+import sys\n+import re\n+import textwrap\n+\n+SPEC = re.compile(\n+    r'^(?:(?P<id>[iusfIUSF])(?:\\((?P<start>\\d+)-(?P<end>\\d+)\\)|'\n+    r'(?P<width>\\d+)(:?/(?P<llvm_width>\\d+))?)'\n+    r'|(?P<reference>\\d+)(?P<modifiers>[vShdnwus]*)(?P<force_width>x\\d+)?)$'\n+)\n+\n+class PlatformInfo(object):\n+    def __init__(self, json):\n+        self._platform = json['platform']\n+        self._intrinsic_prefix = json['intrinsic_prefix']\n+\n+    def intrinsic_prefix(self):\n+        return self._intrinsic_prefix\n+\n+class IntrinsicSet(object):\n+    def __init__(self, platform, json):\n+        self._llvm_prefix = json['llvm_prefix']\n+        self._type_info = json['number_info']\n+        self._intrinsics = json['intrinsics']\n+        self._widths = json['width_info']\n+        self._platform = platform\n+\n+    def intrinsics(self):\n+        for raw in self._intrinsics:\n+            yield GenericIntrinsic(self,\n+                                   raw['intrinsic'], raw['width'], raw['llvm'],\n+                                   raw['ret'], raw['args'])\n+\n+    def platform(self):\n+        return self._platform\n+\n+    def llvm_prefix(self):\n+        return self._llvm_prefix\n+\n+    def width_info(self, bitwidth):\n+        return self._widths[str(bitwidth)]\n+\n+    def number_type_info(self, value):\n+        data = self._type_info[value.__class__.__name__.lower()]\n+        bitwidth = value.bitwidth()\n+        def lookup(raw):\n+            if not isinstance(raw, dict):\n+                return raw\n+\n+            try:\n+                return raw[str(bitwidth)]\n+            except KeyError:\n+                return raw['pattern'].format(bitwidth = bitwidth)\n+\n+        return PlatformTypeInfo(value.llvm_name(),\n+                                {k: lookup(v) for k, v in data.items()})\n+\n+class PlatformTypeInfo(object):\n+    def __init__(self, llvm_name, properties):\n+        self.properties = properties\n+        self.llvm_name = llvm_name\n+\n+    def __getattr__(self, name):\n+        return self.properties[name]\n+\n+    def vectorize(self, length, width_info):\n+        props = self.properties.copy()\n+        props.update(width_info)\n+        return PlatformTypeInfo('v{}{}'.format(length, self.llvm_name), props)\n+\n+class Type(object):\n+    def __init__(self, bitwidth):\n+        self._bitwidth = bitwidth\n+\n+    def bitwidth(self):\n+        return self._bitwidth\n+\n+    def modify(self, spec, width):\n+        raise NotImplementedError()\n+\n+class Number(Type):\n+    def __init__(self, bitwidth):\n+        Type.__init__(self, bitwidth)\n+\n+    def modify(self, spec, width):\n+        if spec == 'u':\n+            return Unsigned(self.bitwidth())\n+        elif spec == 's':\n+            return Signed(self.bitwidth())\n+        elif spec == 'w':\n+            return self.__class__(self.bitwidth() * 2)\n+        elif spec == 'n':\n+            return self.__class__(self.bitwidth() // 2)\n+        elif spec == 'v':\n+            return Vector(self, width // self.bitwidth())\n+        else:\n+            raise ValueError('unknown modification spec {}', spec)\n+\n+    def type_info(self, platform_info):\n+        return platform_info.number_type_info(self)\n+\n+class Signed(Number):\n+    def __init__(self, bitwidth, llvm_bitwidth = None):\n+        Number.__init__(self, bitwidth)\n+        self._llvm_bitwidth = llvm_bitwidth\n+\n+    def compiler_ctor(self):\n+        if self._llvm_bitwidth is None:\n+            return 'i({})'.format(self.bitwidth())\n+        else:\n+            return 'i_({}, {})'.format(self.bitwidth(),\n+                                       self._llvm_bitwidth)\n+\n+    def llvm_name(self):\n+        bw = self._llvm_bitwidth or self.bitwidth()\n+        return 'i{}'.format(bw)\n+\n+    def rust_name(self):\n+        return 'i{}'.format(self.bitwidth())\n+\n+class Unsigned(Number):\n+    def __init__(self, bitwidth, llvm_bitwidth = None):\n+        Number.__init__(self, bitwidth)\n+        self._llvm_bitwidth = llvm_bitwidth\n+\n+    def compiler_ctor(self):\n+        if self._llvm_bitwidth is None:\n+            return 'u({})'.format(self.bitwidth())\n+        else:\n+            return 'u_({}, {})'.format(self.bitwidth(),\n+                                       self._llvm_bitwidth)\n+\n+    def llvm_name(self):\n+        bw = self._llvm_bitwidth or self.bitwidth()\n+        return 'i{}'.format(bw)\n+\n+    def rust_name(self):\n+        return 'u{}'.format(self.bitwidth())\n+\n+class Float(Number):\n+    def __init__(self, bitwidth):\n+        assert bitwidth in (32, 64)\n+        Number.__init__(self, bitwidth)\n+\n+    def compiler_ctor(self):\n+        return 'f({})'.format(self.bitwidth())\n+\n+    def llvm_name(self):\n+        return 'f{}'.format(self.bitwidth())\n+\n+    def rust_name(self):\n+        return 'f{}'.format(self.bitwidth())\n+\n+class Vector(Type):\n+    def __init__(self, elem, length):\n+        assert isinstance(elem, Type) and not isinstance(elem, Vector)\n+        Type.__init__(self,\n+                      elem.bitwidth() * length)\n+        self._length = length\n+        self._elem = elem\n+\n+    def modify(self, spec, width):\n+        if spec == 'h':\n+            return Vector(self._elem, self._length // 2)\n+        elif spec == 'd':\n+            return Vector(self._elem, self._length * 2)\n+        elif spec.startswith('x'):\n+            new_bitwidth = int(spec[1:])\n+            return Vector(self._elem, new_bitwidth // self._elem.bitwidth())\n+        else:\n+            return Vector(self._elem.modify(spec, width), self._length)\n+\n+    def compiler_ctor(self):\n+        return 'v({}, {})'.format(self._elem.compiler_ctor(), self._length)\n+\n+    def rust_name(self):\n+        return '{}x{}'.format(self._elem.rust_name(), self._length)\n+\n+    def type_info(self, platform_info):\n+        elem_info = self._elem.type_info(platform_info)\n+        return elem_info.vectorize(self._length,\n+                                   platform_info.width_info(self.bitwidth()))\n+\n+class Aggregate(Type):\n+    def __init__(self, flatten, elems):\n+        self._flatten = flatten\n+        self._elems = elems\n+        Type.__init__(self, sum(elem.bitwidth() for elem in elems))\n+\n+    def __repr__(self):\n+        return '<Aggregate {}>'.format(self._elems)\n+\n+    def compiler_ctor(self):\n+        return 'agg({}, vec![{}])'.format('true' if self._flatten else 'false',\n+                                          ', '.join(elem.compiler_ctor() for elem in self._elems))\n+\n+    def rust_name(self):\n+        return '({})'.format(', '.join(elem.rust_name() for elem in self._elems))\n+\n+    def type_info(self, platform_info):\n+        #return PlatformTypeInfo(None, None, self._llvm_name)\n+        return None\n+\n+\n+TYPE_ID_LOOKUP = {'i': [Signed, Unsigned],\n+                  's': [Signed],\n+                  'u': [Unsigned],\n+                  'f': [Float]}\n+\n+class TypeSpec(object):\n+    def __init__(self, spec):\n+        if not isinstance(spec, list):\n+            spec = [spec]\n+\n+        self.spec = spec\n+\n+    def enumerate(self, width):\n+        for spec in self.spec:\n+            match = SPEC.match(spec)\n+            if match:\n+                id = match.group('id')\n+                is_vector = id.islower()\n+                type_ctors = TYPE_ID_LOOKUP[id.lower()]\n+\n+                start = match.group('start')\n+                if start is not None:\n+                    end = match.group('end')\n+                    llvm_width = None\n+                else:\n+                    start = end = match.group('width')\n+                    llvm_width = match.group('llvm_width')\n+                start = int(start)\n+                end = int(end)\n+\n+                bitwidth = start\n+                while bitwidth <= end:\n+                    for ctor in type_ctors:\n+                        if llvm_width is not None:\n+                            assert not is_vector\n+                            llvm_width = int(llvm_width)\n+                            assert llvm_width < bitwidth\n+                            scalar = ctor(bitwidth, llvm_width)\n+                        else:\n+                            scalar = ctor(bitwidth)\n+\n+                        if is_vector:\n+                            yield Vector(scalar, width // bitwidth)\n+                        else:\n+                            yield scalar\n+                    bitwidth *= 2\n+            else:\n+                print('Failed to parse: `{}`'.format(spec), file=sys.stderr)\n+\n+    def resolve(self, width, zero):\n+        assert len(self.spec) == 1\n+        spec = self.spec[0]\n+        match = SPEC.match(spec)\n+        if match:\n+            id  = match.group('id')\n+            if id is not None:\n+                options = list(self.enumerate(width))\n+                assert len(options) == 1\n+                return options[0]\n+            reference = match.group('reference')\n+            if reference != '0':\n+                raise NotImplementedError('only argument 0 (return value) references are supported')\n+            ret = zero\n+            for x in match.group('modifiers') or []:\n+                ret = ret.modify(x, width)\n+            force = match.group('force_width')\n+            if force is not None:\n+                ret = ret.modify(force, width)\n+            return ret\n+        elif spec.startswith('('):\n+            if spec.endswith(')'):\n+                raise NotImplementedError()\n+            elif spec.endswith(')f'):\n+                true_spec = spec[1:-2]\n+                flatten = True\n+            elems = [TypeSpec(subspec).resolve(width, zero) for subspec in true_spec.split(',')]\n+            return Aggregate(flatten, elems)\n+\n+class GenericIntrinsic(object):\n+    def __init__(self, platform, intrinsic, widths, llvm_name, ret, args):\n+        self._platform = platform\n+        self.intrinsic = intrinsic\n+        self.widths = map(int, widths)\n+        self.llvm_name = llvm_name\n+        self.ret = TypeSpec(ret)\n+        self.args = list(map(TypeSpec, args))\n+\n+    def monomorphise(self):\n+        for width in self.widths:\n+            # must be a power of two\n+            assert width & (width - 1) == 0\n+            for ret in self.ret.enumerate(width):\n+                args = [arg.resolve(width, ret) for arg in self.args]\n+                yield MonomorphicIntrinsic(self._platform, self.intrinsic, width, self.llvm_name,\n+                                           ret, args)\n+\n+class MonomorphicIntrinsic(object):\n+    def __init__(self, platform, intrinsic, width, llvm_name, ret, args):\n+        self._platform = platform\n+        self._intrinsic = intrinsic\n+        self._width = '' if width == 64 else 'q'\n+        self._llvm_name = llvm_name\n+        self._ret_raw = ret\n+        self._ret = ret.type_info(platform)\n+        self._args_raw = args\n+        self._args = [arg.type_info(platform) for arg in args]\n+\n+    def llvm_name(self):\n+        if self._llvm_name.startswith('!'):\n+            return self._llvm_name[1:].format(self._ret, *self._args)\n+        else:\n+            return self._platform.llvm_prefix() + self._llvm_name.format(self._ret, *self._args)\n+\n+    def intrinsic_suffix(self):\n+        return self._intrinsic.format(self._ret,\n+                                      *self._args,\n+                                      width = self._width)\n+\n+    def intrinsic_name(self):\n+        return self._platform.platform().intrinsic_prefix() + self.intrinsic_suffix()\n+\n+    def compiler_args(self):\n+        return ', '.join(arg.compiler_ctor() for arg in self._args_raw)\n+\n+    def compiler_ret(self):\n+        return self._ret_raw.compiler_ctor()\n+\n+    def compiler_signature(self):\n+        return '({}) -> {}'.format(self.compiler_args(), self.compiler_ret())\n+\n+    def intrinsic_signature(self):\n+        names = 'xyzwabcdef'\n+        return '({}) -> {}'.format(', '.join('{}: {}'.format(name, arg.rust_name())\n+                                             for name, arg in zip(names, self._args_raw)),\n+                                   self._ret_raw.rust_name())\n+\n+def parse_args():\n+    parser = argparse.ArgumentParser(\n+        formatter_class = argparse.RawDescriptionHelpFormatter,\n+        description = 'Render an intrinsic definition JSON to various formats.',\n+        epilog = textwrap.dedent('''\\\n+        An intrinsic definition consists of a map with fields:\n+        - intrinsic: pattern for the name(s) of the vendor's C intrinsic(s)\n+        - llvm: pattern for the name(s) of the internal llvm intrinsic(s)\n+        - width: a vector of vector bit-widths the pattern works with\n+        - ret: type specifier for the return value\n+        - arguments: vector of type specifiers for arguments\n+\n+        The width and types describe a range of possible intrinsics,\n+        and these are fed back into the intrinsic and llvm patterns to\n+        create the appropriate definitions.\n+\n+        ## Type specifier grammar\n+\n+        ```\n+        type := vector | scalar | aggregate | reference\n+\n+        vector := vector_elem width |\n+        vector_elem := 'i' | 'u' | 's' | 'f'\n+\n+        scalar := scalar_type number llvm_width?\n+        scalar_type := 'U' | 'S' | 'F'\n+        llvm_width := '/' number\n+\n+        aggregate := '(' (type),* ')' 'f'?\n+\n+        reference := number modifiers*\n+        modifiers := 'v' | 'h' | 'd' | 'n' | 'w' | 'u' | 's' |\n+                     'x' number\n+\n+\n+        width = number | '(' number '-' number ')'\n+\n+        number = [0-9]+\n+        ```\n+\n+        ## Vectors\n+\n+        The vector grammar is a pattern describing many possibilities\n+        for arguments/return value. The `vector_elem` describes the\n+        types of elements to use, and the `width` describes the (range\n+        of) widths for those elements, which are then placed into a\n+        vector with the `width` bitwidth. E.g. if an intrinsic has a\n+        `width` that includes 128, and the return value is `i(8-32)`,\n+        then some instantiation of that intrinsic will be `u8x16`,\n+        `u32x4`, `i32x4`, etc.\n+\n+        ### Elements\n+\n+        - i: integer, both signed and unsigned\n+        - u: unsigned integer\n+        - s: signed integer\n+        - f: float\n+\n+        ## Scalars\n+\n+        Similar to vectors, but these describe a single concrete type,\n+        not a range. The number is the bitwidth. The optional\n+        `llvm_width` is the bitwidth of the integer that should be\n+        passed to LLVM (by truncating the Rust argument): this only\n+        works with scalar integers and the LLVM width must be smaller\n+        than the Rust width.\n+\n+        ### Types\n+\n+        - U: unsigned integer\n+        - S: signed integer\n+        - F: float\n+\n+        ## Aggregates\n+\n+        An aggregate is a collection of multiple types; a tuple in\n+        Rust terms, or an unnamed struct in LLVM. The `f` modifiers\n+        forces the tuple to be flattened in the LLVM\n+        intrinsic. E.g. if `llvm.foo` takes `(F32,S32)`:\n+\n+        - no `f` corresponds to `declare ... @llvm.foo({float, i32})`.\n+        - having an `f` corresponds to `declare ... @llvm.foo(float, i32)`.\n+\n+\n+        (Currently aggregates can not contain other aggregates.)\n+\n+        ## References\n+\n+        A reference uses the type of another argument, with possible\n+        modifications. The number refers to the type to use, starting\n+        with 0 == return value, 1 == first argument, 2 == second\n+        argument, etc. (Currently only referencing 0, the return\n+        value, is supported.)\n+\n+        ### Modifiers\n+\n+        - 'v': put a scalar into a vector of the current width (u32 -> u32x4, when width == 128)\n+        - 'h': half the length of the vector (u32x4 -> u32x2)\n+        - 'd': double the length of the vector (u32x2 -> u32x4)\n+        - 'n': narrow the element of the vector (u32x4 -> u16x4)\n+        - 'w': widen the element of the vector (u16x4 -> u32x4)\n+        - 'u': force an integer (vector or scalar) to be unsigned (i32x4 -> u32x4)\n+        - 's': force an integer (vector or scalar) to be signed (u32x4 -> i32x4)\n+        - 'x' number: force the type to be a vector of bitwidth `number`.\n+        '''))\n+    parser.add_argument('--format', choices=FORMATS, required=True,\n+                        help = 'Output format.')\n+    parser.add_argument('-o', '--out', type=argparse.FileType('w'), default=sys.stdout,\n+                        help = 'File to output to (default stdout).')\n+    parser.add_argument('-i', '--info', type=argparse.FileType('r'),\n+                        help = 'File containing platform specific information to merge into'\n+                                'the input files\\' header.')\n+    parser.add_argument('in_', metavar=\"FILE\", type=argparse.FileType('r'), nargs='+',\n+                        help = 'JSON files to load')\n+    return parser.parse_args()\n+\n+\n+class ExternBlock(object):\n+    def __init__(self):\n+        pass\n+\n+    def open(self, platform):\n+        return 'extern \"platform-intrinsic\" {'\n+\n+    def render(self, mono):\n+        return '    fn {}{};'.format(mono.intrinsic_name(),\n+                                     mono.intrinsic_signature())\n+\n+    def close(self):\n+        return '}'\n+\n+class CompilerDefs(object):\n+    def __init__(self):\n+        pass\n+\n+    def open(self, platform):\n+        return '''\\\n+// Copyright 2015 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// DO NOT EDIT: autogenerated by etc/platform-intrinsics/generator.py\n+// ignore-tidy-linelength\n+\n+#![allow(unused_imports)]\n+\n+use {{Intrinsic, i, i_, u, u_, f, v, agg}};\n+use IntrinsicDef::Named;\n+use rustc::middle::ty;\n+\n+pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {{\n+    if !name.starts_with(\"{0}\") {{ return None }}\n+    Some(match &name[\"{0}\".len()..] {{'''.format(platform.intrinsic_prefix())\n+\n+    def render(self, mono):\n+        return '''\\\n+        \"{}\" => Intrinsic {{\n+            inputs: vec![{}],\n+            output: {},\n+            definition: Named(\"{}\")\n+        }},'''.format(mono.intrinsic_suffix(),\n+                      mono.compiler_args(),\n+                      mono.compiler_ret(),\n+                      mono.llvm_name())\n+\n+    def close(self):\n+        return '''\\\n+        _ => return None,\n+    })\n+}'''\n+\n+FORMATS = {\n+    'extern-block': ExternBlock(),\n+    'compiler-defs': CompilerDefs(),\n+}\n+\n+\n+def main():\n+    args = parse_args()\n+    ins = args.in_\n+    out = args.out\n+    out_format = FORMATS[args.format]\n+    info = args.info\n+    one_file_no_info = False\n+    if len(ins) > 1 and info is None:\n+        print('error: cannot have multiple inputs without an info header.', file=sys.stderr)\n+        sys.exit(1)\n+\n+    elif info is None:\n+        info = ins[0]\n+        one_file_no_info = True\n+    info_json = json.load(info)\n+    platform = PlatformInfo(info_json)\n+\n+    print(out_format.open(platform), file=out)\n+\n+    for in_ in ins:\n+\n+        if one_file_no_info:\n+            data = info_json\n+        else:\n+            data = json.load(in_)\n+            data.update(info_json)\n+\n+        intrinsics = IntrinsicSet(platform, data)\n+        for intr in intrinsics.intrinsics():\n+            for mono in intr.monomorphise():\n+                print(out_format.render(mono), file=out)\n+\n+    print(out_format.close(), file=out)\n+\n+if __name__ == '__main__':\n+    main()"}, {"sha": "4ac82fb90e900870b4861db875c4cf4d8c1e2fa5", "filename": "src/etc/platform-intrinsics/x86/avx.json", "status": "added", "additions": 152, "deletions": 0, "changes": 152, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,152 @@\n+{\n+    \"llvm_prefix\": \"llvm.x86.avx.\",\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"256_addsub_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"addsub.{0.data_type}.256\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_dp_ps\",\n+            \"width\": [256],\n+            \"llvm\": \"dp.ps.256\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_hadd_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"hadd.{0.data_type}.256\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_hsub_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"hsub.{0.data_type}.256\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_max_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"max.{0.data_type}.256\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_min_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"min.{0.data_type}.256\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_movemask_ps\",\n+            \"width\": [256],\n+            \"llvm\": \"movmsk.ps.256\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f32\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_movemask_pd\",\n+            \"width\": [256],\n+            \"llvm\": \"movmsk.pd.256\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f64\"]\n+        },\n+        {\n+            \"intrinsic\": \"{0.width_mm}_permutevar_{0.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"vpermilvar.{0.data_type}{0.width_suffix}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_rcp_ps\",\n+            \"width\": [256],\n+            \"llvm\": \"rcp.ps.256\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"f32\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_rsqrt_ps\",\n+            \"width\": [256],\n+            \"llvm\": \"rsqrt.ps.256\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"f32\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_sqrt_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"!llvm.sqrt.{0.llvm_name}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"{1.width_mm}_testc_ps\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"vtestc.ps{1.width_suffix}\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f32\", \"f32\"]\n+        },\n+        {\n+            \"intrinsic\": \"{1.width_mm}_testc_pd\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"vtestc.pd{1.width_suffix}\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f64\", \"f64\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_testc_si256\",\n+            \"width\": [256],\n+            \"llvm\": \"ptestc.256\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"u64\", \"u64\"]\n+        },\n+        {\n+            \"intrinsic\": \"{1.width_mm}_testnzc_ps\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"vtestnzc.ps{1.width_suffix}\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f32\", \"f32\"]\n+        },\n+        {\n+            \"intrinsic\": \"{1.width_mm}_testnzc_pd\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"vtestnzc.pd{1.width_suffix}\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f64\", \"f64\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_testnzc_si256\",\n+            \"width\": [256],\n+            \"llvm\": \"ptestnzc.256\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"u64\", \"u64\"]\n+        },\n+        {\n+            \"intrinsic\": \"{1.width_mm}_testz_ps\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"vtestz.ps{1.width_suffix}\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f32\", \"f32\"]\n+        },\n+        {\n+            \"intrinsic\": \"{1.width_mm}_testz_pd\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"vtestz.pd{1.width_suffix}\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f64\", \"f64\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_testz_si256\",\n+            \"width\": [256],\n+            \"llvm\": \"ptestz.256\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"u64\", \"u64\"]\n+        }\n+    ]\n+}"}, {"sha": "bd260ec02e93078ea3d0eef710585d3036ce5efe", "filename": "src/etc/platform-intrinsics/x86/avx2.json", "status": "added", "additions": 159, "deletions": 0, "changes": 159, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx2.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx2.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx2.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,159 @@\n+{\n+    \"llvm_prefix\": \"llvm.x86.avx2.\",\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"256_abs_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"avx2.pabs.{0.data_type_short}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_adds_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"avx2.padd{0.kind_short}s.{0.data_type_short}\",\n+            \"ret\": \"i(8-16)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_avg_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"avx2.pavg.{0.data_type_short}\",\n+            \"ret\": \"u(8-16)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_hadd_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"phadd.{0.data_type_short}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_hadds_epi16\",\n+            \"width\": [256],\n+            \"llvm\": \"phadd.sw\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_hsub_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"phsub.{0.data_type_short}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_hsubs_epi16\",\n+            \"width\": [256],\n+            \"llvm\": \"phsub.sw\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_madd_epi16\",\n+            \"width\": [256],\n+            \"llvm\": \"pmadd.wd\",\n+            \"ret\": \"s32\",\n+            \"args\": [\"s16\", \"s16\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_maddubs_epi16\",\n+            \"width\": [256],\n+            \"llvm\": \"pmadd.ub.sw\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"s8\", \"s8\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_max_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"pmax{0.kind}.{0.data_type_short}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_min_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"pmin{0.kind}.{0.data_type_short}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_movemask_epi8\",\n+            \"width\": [256],\n+            \"llvm\": \"pmovmskb\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_mpsadbw_epu8\",\n+            \"width\": [256],\n+            \"llvm\": \"mpsadbw\",\n+            \"ret\": \"u16\",\n+            \"args\": [\"u8\", \"u8\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_mul_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"pmul{0.data_type_short}.dq\",\n+            \"ret\": \"i64\",\n+            \"args\": [\"0dn\", \"0dn\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_mulhi_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"pmulh{0.data_type_short}.w\",\n+            \"ret\": \"i16\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_mulhrs_epi16\",\n+            \"width\": [256],\n+            \"llvm\": \"pmul.hr.sw\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_pack{0.kind_short}s_{1.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"pack{0.kind}s{1.data_type_short}{0.data_type_short}\",\n+            \"ret\": \"i(8-16)\",\n+            \"args\": [\"0hws\", \"0hws\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_permutevar8x32_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"perm{0.data_type_short}\",\n+            \"ret\": [\"s32\", \"f32\"],\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_sad_epu8\",\n+            \"width\": [256],\n+            \"llvm\": \"psad.bw\",\n+            \"ret\": \"u8\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_shuffle_epi8\",\n+            \"width\": [256],\n+            \"llvm\": \"pshuf.b\",\n+            \"ret\": \"s8\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_sign_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"psign.{0.data_type_short}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_subs_{0.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"psub{0.kind_short}s.{0.data_type_short}\",\n+            \"ret\": \"i(8-16)\",\n+            \"args\": [\"0\", \"0\"]\n+        }\n+    ]\n+}"}, {"sha": "d48bcd268a0048fd87ee5635ea5f137fcd09dde9", "filename": "src/etc/platform-intrinsics/x86/info.json", "status": "added", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Finfo.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Finfo.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Finfo.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,28 @@\n+{\n+    \"platform\": \"x86\",\n+    \"intrinsic_prefix\": \"x86_mm\",\n+    \"number_info\": {\n+        \"signed\": {\n+            \"kind\": \"s\",\n+            \"kind_short\": \"\",\n+            \"data_type\": { \"pattern\": \"epi{bitwidth}\" },\n+            \"data_type_short\": { \"8\": \"b\", \"16\": \"w\", \"32\": \"d\", \"64\": \"q\" }\n+        },\n+        \"unsigned\": {\n+            \"kind\": \"u\",\n+            \"kind_short\": \"u\",\n+            \"data_type\": { \"pattern\": \"epu{bitwidth}\" },\n+            \"data_type_short\": { \"8\": \"b\", \"16\": \"w\", \"32\": \"d\", \"64\": \"q\" }\n+        },\n+        \"float\": {\n+            \"kind\": \"f\",\n+            \"data_type\": { \"32\": \"ps\", \"64\": \"pd\" },\n+            \"data_type_short\": { \"32\": \"ps\", \"64\": \"pd\" }\n+        }\n+    },\n+    \"width_info\": {\n+        \"128\": { \"width_mm\": \"\", \"width_suffix\": \"\" },\n+        \"256\": { \"width_mm\": \"256\", \"width_suffix\": \".256\" },\n+        \"512\": { \"width_mm\": \"512\", \"width_suffix\": \".512\" }\n+    }\n+}"}, {"sha": "27da842934c0cd1b7e7a841d492b4835bf0ad586", "filename": "src/etc/platform-intrinsics/x86/sse.json", "status": "added", "additions": 47, "deletions": 0, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,47 @@\n+{\n+    \"llvm_prefix\": \"llvm.x86.sse.\",\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"_movemask_ps\",\n+            \"width\": [128],\n+            \"llvm\": \"movmsk.ps\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f32\"]\n+        },\n+        {\n+            \"intrinsic\": \"_max_ps\",\n+            \"width\": [128],\n+            \"llvm\": \"max.ps\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_min_ps\",\n+            \"width\": [128],\n+            \"llvm\": \"min.ps\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_rsqrt_ps\",\n+            \"width\": [128],\n+            \"llvm\": \"rsqrt.ps\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_rcp_ps\",\n+            \"width\": [128],\n+            \"llvm\": \"rcp.ps\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_sqrt_ps\",\n+            \"width\": [128],\n+            \"llvm\": \"!llvm.sqrt.v4f32\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\"]\n+        }\n+    ]\n+}"}, {"sha": "b2a3fe60f1a427db2f0ee08c44eb68e130f53fea", "filename": "src/etc/platform-intrinsics/x86/sse2.json", "status": "added", "additions": 117, "deletions": 0, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse2.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse2.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse2.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,117 @@\n+{\n+    \"llvm_prefix\": \"llvm.x86.sse2.\",\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"_adds_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"padd{0.kind_short}s.{0.data_type_short}\",\n+            \"ret\": \"i(8-16)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_avg_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"pavg.{0.data_type_short}\",\n+            \"ret\": \"u(8-16)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_madd_epi16\",\n+            \"width\": [128],\n+            \"llvm\": \"pmadd.wd\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_max_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"pmax{0.kind}.{0.data_type_short}\",\n+            \"ret\": [\"s16\", \"u8\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_max_pd\",\n+            \"width\": [128],\n+            \"llvm\": \"max.pd\",\n+            \"ret\": \"f64\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_min_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"pmin{0.kind}.{0.data_type_short}\",\n+            \"ret\": [\"s16\", \"u8\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_min_pd\",\n+            \"width\": [128],\n+            \"llvm\": \"min.pd\",\n+            \"ret\": \"f64\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_movemask_pd\",\n+            \"width\": [128],\n+            \"llvm\": \"movmsk.pd\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"f64\"]\n+        },\n+        {\n+            \"intrinsic\": \"_movemask_epi8\",\n+            \"width\": [128],\n+            \"llvm\": \"pmovmskb.128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_mul_epu32\",\n+            \"width\": [128],\n+            \"llvm\": \"pmulu.dq\",\n+            \"ret\": \"s64\",\n+            \"args\": [\"0dn\", \"0dn\"]\n+        },\n+        {\n+            \"intrinsic\": \"_mulhi_ep{0.kind}16\",\n+            \"width\": [128],\n+            \"llvm\": \"pmulh{0.kind_short}.w\",\n+            \"ret\": \"i16\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_packs_{1.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"packss{1.data_type_short}{0.data_type_short}.128\",\n+            \"ret\": \"s(8-16)\",\n+            \"args\": [\"0hw\", \"0hw\"]\n+        },\n+        {\n+            \"intrinsic\": \"_packus_epi16\",\n+            \"width\": [128],\n+            \"llvm\": \"packuswb.128\",\n+            \"ret\": \"u8\",\n+            \"args\": [\"s16\", \"s16\"]\n+        },\n+        {\n+            \"intrinsic\": \"_sad_epu8\",\n+            \"width\": [128],\n+            \"llvm\": \"psad.bw\",\n+            \"ret\": \"u64\",\n+            \"args\": [\"u8\", \"u8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_sqrt_pd\",\n+            \"width\": [128],\n+            \"llvm\": \"!llvm.sqrt.v2f64\",\n+            \"ret\": \"f64\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_subs_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"psub{0.kind_short}s.{0.data_type_short}\",\n+            \"ret\": \"i(8-16)\",\n+            \"args\": [\"0\", \"0\"]\n+        }\n+    ]\n+}"}, {"sha": "376e32fa9156835eb6ce6e166ed59695c88654e8", "filename": "src/etc/platform-intrinsics/x86/sse3.json", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse3.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse3.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse3.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,26 @@\n+{\n+    \"llvm_prefix\": \"llvm.x86.sse3.\",\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"_addsub_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"addsub.{0.data_type}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_hadd_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"hadd.{0.data_type}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_hsub_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"hsub.{0.data_type}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        }\n+    ]\n+}"}, {"sha": "e835320e5cd18a84d4b185e3b8da3eb64fefb72d", "filename": "src/etc/platform-intrinsics/x86/sse41.json", "status": "added", "additions": 75, "deletions": 0, "changes": 75, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse41.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse41.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse41.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,75 @@\n+{\n+    \"llvm_prefix\": \"llvm.x86.sse41.\",\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"_dp_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"dp{0.data_type}\",\n+            \"ret\": \"f(32-64)\",\n+            \"args\": [\"0\", \"0\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_max_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"pmax{0.kind}{0.data_type_short}\",\n+            \"ret\": [\"s8\", \"u16\", \"i32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_min_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"pmin{0.kind}{0.data_type_short}\",\n+            \"ret\": [\"s8\", \"u16\", \"i32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_minpos_epu16\",\n+            \"width\": [128],\n+            \"llvm\": \"phminposuw\",\n+            \"ret\": \"u16\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_mpsadbw_epu8\",\n+            \"width\": [128],\n+            \"llvm\": \"mpsadbw\",\n+            \"ret\": \"u16\",\n+            \"args\": [\"u8\", \"u8\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_mul_epi32\",\n+            \"width\": [128],\n+            \"llvm\": \"muldq\",\n+            \"ret\": \"s64\",\n+            \"args\": [\"s32\", \"s32\"]\n+        },\n+        {\n+            \"intrinsic\": \"_packus_epi32\",\n+            \"width\": [128],\n+            \"llvm\": \"packusdw\",\n+            \"ret\": \"u16\",\n+            \"args\": [\"s32\", \"s32\"]\n+        },\n+        {\n+            \"intrinsic\": \"_testc_si128\",\n+            \"width\": [128],\n+            \"llvm\": \"ptestc\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"u64\", \"u64\"]\n+        },\n+        {\n+            \"intrinsic\": \"_testncz_si128\",\n+            \"width\": [128],\n+            \"llvm\": \"ptest.nzc\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"u64\", \"u64\"]\n+        },\n+        {\n+            \"intrinsic\": \"_testz_si128\",\n+            \"width\": [128],\n+            \"llvm\": \"ptestz\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"u64\", \"u64\"]\n+        }\n+    ]\n+}"}, {"sha": "c43ffef0dc578cc7459be1fa520401ed880aba79", "filename": "src/etc/platform-intrinsics/x86/sse42.json", "status": "added", "additions": 103, "deletions": 0, "changes": 103, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse42.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse42.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse42.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,103 @@\n+{\n+    \"llvm_prefix\": \"llvm.x86.sse42.\",\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"_cmpestra\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpestria128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"S32\", \"s8\", \"S32\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpestrc\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpestric128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"S32\", \"s8\", \"S32\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpestri\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpestri128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"S32\", \"s8\", \"S32\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpestrm\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpestrm128\",\n+            \"ret\": \"s8\",\n+            \"args\": [\"s8\", \"S32\", \"s8\", \"S32\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpestro\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpestrio128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"S32\", \"s8\", \"S32\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpestrs\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpestris128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"S32\", \"s8\", \"S32\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpestrz\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpestriz128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"S32\", \"s8\", \"S32\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpistra\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpistria128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"s8\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpistrc\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpistric128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"s8\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpistri\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpistri128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"s8\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpistrm\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpistrm128\",\n+            \"ret\": \"s8\",\n+            \"args\": [\"s8\", \"s8\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpistro\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpistrio128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"s8\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpistrs\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpistris128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"s8\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_cmpistrz\",\n+            \"width\": [128],\n+            \"llvm\": \"pcmpistriz128\",\n+            \"ret\": \"S32\",\n+            \"args\": [\"s8\", \"s8\", \"S32/8\"]\n+        }\n+    ]\n+}"}, {"sha": "bbe11380ff87045a109be36ac1c93a841e7ba2cb", "filename": "src/etc/platform-intrinsics/x86/ssse3.json", "status": "added", "additions": 68, "deletions": 0, "changes": 68, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fssse3.json", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fssse3.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fssse3.json?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -0,0 +1,68 @@\n+{\n+    \"llvm_prefix\": \"llvm.x86.ssse3.\",\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"_abs_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"pabs.{0.data_type_short}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_hadd_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"phadd.{0.data_type_short}.128\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_hadds_epi16\",\n+            \"width\": [128],\n+            \"llvm\": \"phadd.sw.128\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_hsub_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"phsub.{0.data_type_short}.128\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_hsubs_epi16\",\n+            \"width\": [128],\n+            \"llvm\": \"phsub.sw.128\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_maddubs_epi16\",\n+            \"width\": [128],\n+            \"llvm\": \"pmadd.ub.sw.128\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"s8\", \"s8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_mulhrs_epi16\",\n+            \"width\": [128],\n+            \"llvm\": \"pmul.hr.sw.128\",\n+            \"ret\": \"s16\",\n+            \"args\": [\"s16\", \"s16\"]\n+        },\n+        {\n+            \"intrinsic\": \"_shuffle_epi8\",\n+            \"width\": [128],\n+            \"llvm\": \"pshuf.b.128\",\n+            \"ret\": \"s8\",\n+            \"args\": [\"s8\", \"s8\"]\n+        },\n+        {\n+            \"intrinsic\": \"_sign_{0.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"psign.{0.data_type_short}.128\",\n+            \"ret\": \"s(8-16)\",\n+            \"args\": [\"0\", \"0\"]\n+        }\n+    ]\n+}"}, {"sha": "1f581d8ce855aa4995d84e26d82100d1266a5d67", "filename": "src/librustc_platform_intrinsics/aarch64.rs", "status": "modified", "additions": 2799, "deletions": 38, "changes": 2837, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_platform_intrinsics%2Faarch64.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_platform_intrinsics%2Faarch64.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Faarch64.rs?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631"}, {"sha": "8ea725ee95df8bb3a9e64975948d870873172dd8", "filename": "src/librustc_platform_intrinsics/arm.rs", "status": "modified", "additions": 2069, "deletions": 331, "changes": 2400, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_platform_intrinsics%2Farm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_platform_intrinsics%2Farm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Farm.rs?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -8,340 +8,2078 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use {Intrinsic, i, f, v};\n+// DO NOT EDIT: autogenerated by etc/platform-intrinsics/generator.py\n+// ignore-tidy-linelength\n+\n+#![allow(unused_imports)]\n+\n+use {Intrinsic, i, u, f, v, agg};\n+use IntrinsicDef::Named;\n use rustc::middle::ty;\n \n-macro_rules! p {\n-    ($name: expr, ($($inputs: tt),*) -> $output: tt) => {\n-        plain!(concat!(\"llvm.arm.neon.\", $name), ($($inputs),*) -> $output)\n-    }\n-}\n pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n-    if !name.starts_with(\"v\") { return None }\n-    Some(match &name[\"v\".len()..] {\n-        \"sqrtq_f32\" => plain!(\"llvm.sqrt.v4f32\", (f32x4) -> f32x4),\n-        \"sqrtq_f64\" => plain!(\"llvm.sqrt.v2f64\", (f64x2) -> f64x2),\n-\n-        \"hadd_s8\" => p!(\"vhadds.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"haddq_s8\" => p!(\"vhadds.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"hadd_s16\" => p!(\"vhadds.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"haddq_s16\" => p!(\"vhadds.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"hadd_s32\" => p!(\"vhadds.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"haddq_s32\" => p!(\"vhadds.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"hadd_u8\" => p!(\"vhaddu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"haddq_u8\" => p!(\"vhaddu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"hadd_u16\" => p!(\"vhaddu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"haddq_u16\" => p!(\"vhaddu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"hadd_u32\" => p!(\"vhaddu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"haddq_u32\" => p!(\"vhaddu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"rhadd_s8\" => p!(\"vrhadds.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"rhaddq_s8\" => p!(\"vrhadds.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"rhadd_s16\" => p!(\"vrhadds.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"rhaddq_s16\" => p!(\"vrhadds.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"rhadd_s32\" => p!(\"vrhadds.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"rhaddq_s32\" => p!(\"vrhadds.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"rhadd_u8\" => p!(\"vrhaddu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"rhaddq_u8\" => p!(\"vrhaddu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"rhadd_u16\" => p!(\"vrhaddu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"rhaddq_u16\" => p!(\"vrhaddu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"rhadd_u32\" => p!(\"vrhaddu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"rhaddq_u32\" => p!(\"vrhaddu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qadd_s8\" => p!(\"vqadds.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qaddq_s8\" => p!(\"vqadds.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qadd_s16\" => p!(\"vqadds.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qaddq_s16\" => p!(\"vqadds.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qadd_s32\" => p!(\"vqadds.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qaddq_s32\" => p!(\"vqadds.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qadd_s64\" => p!(\"vqaddu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qaddq_s64\" => p!(\"vqaddu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qadd_u8\" => p!(\"vqaddu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qaddq_u8\" => p!(\"vqaddu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qadd_u16\" => p!(\"vqaddu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qaddq_u16\" => p!(\"vqaddu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qadd_u32\" => p!(\"vqaddu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qaddq_u32\" => p!(\"vqaddu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qadd_u64\" => p!(\"vqaddu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qaddq_u64\" => p!(\"vqaddu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"raddhn_s16\" => p!(\"vraddhn.v8i8\", (i16x8, i16x8) -> i8x8),\n-        \"raddhn_s32\" => p!(\"vraddhn.v4i16\", (i32x4, i32x4) -> i16x4),\n-        \"raddhn_s64\" => p!(\"vraddhn.v2i32\", (i64x2, i64x2) -> i32x2),\n-        \"fma_f32\" => plain!(\"llvm.fma.v2f32\", (f32x2, f32x2, f32x2) -> f32x2),\n-        \"fmaq_f32\" => plain!(\"llvm.fma.v4f32\", (f32x4, f32x4, f32x4) -> f32x4),\n-        \"qdmulh_s16\" => p!(\"vqdmulh.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qdmulhq_s16\" => p!(\"vqdmulh.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qdmulh_s32\" => p!(\"vqdmulh.v2i32\", (i32x2, i32x2) -> i32x4),\n-        \"qdmulhq_s32\" => p!(\"vqdmulh.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qrdmulh_s16\" => p!(\"vqrdmulh.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qrdmulhqr_s16\" => p!(\"vqrdmulh.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qrdmulh_s32\" => p!(\"vqrdmulh.v2i32\", (i32x2, i32x2) -> i32x4),\n-        \"qrdmulhqr_s32\" => p!(\"vqrdmulh.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"mull_s8\" => p!(\"vmulls.v8i16\", (i8x8, i8x8) -> i16x8),\n-        \"mull_s16\" => p!(\"vmulls.v4i32\", (i16x4, i16x4) -> i32x4),\n-        \"mull_s32\" => p!(\"vmulls.v2i64\", (i32x2, i32x2) -> i64x2),\n-        \"mull_u8\" => p!(\"vmullu.v8i16\", (i8x8, i8x8) -> i16x8),\n-        \"mull_u16\" => p!(\"vmullu.v4i32\", (i16x4, i16x4) -> i32x4),\n-        \"mull_u32\" => p!(\"vmullu.v2i64\", (i32x2, i32x2) -> i64x2),\n-        \"qdmull_s16\" => p!(\"vqdmull.v4i32\", (i16x4, i16x4) -> i32x4),\n-        \"qdmull_s32\" => p!(\"vqdmull.v2i64\", (i32x2, i32x2) -> i64x2),\n-        \"hsub_s8\" => p!(\"vhsubs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"hsubq_s8\" => p!(\"vhsubs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"hsub_s16\" => p!(\"vhsubs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"hsubq_s16\" => p!(\"vhsubs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"hsub_s32\" => p!(\"vhsubs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"hsubq_s32\" => p!(\"vhsubs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"hsub_u8\" => p!(\"vhsubu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"hsubq_u8\" => p!(\"vhsubu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"hsub_u16\" => p!(\"vhsubu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"hsubq_u16\" => p!(\"vhsubu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"hsub_u32\" => p!(\"vhsubu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"hsubq_u32\" => p!(\"vhsubu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qsub_s8\" => p!(\"vqsubs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qsubq_s8\" => p!(\"vqsubs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qsub_s16\" => p!(\"vqsubs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qsubq_s16\" => p!(\"vqsubs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qsub_s32\" => p!(\"vqsubs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qsubq_s32\" => p!(\"vqsubs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qsub_s64\" => p!(\"vqsubu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qsubq_s64\" => p!(\"vqsubu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qsub_u8\" => p!(\"vqsubu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qsubq_u8\" => p!(\"vqsubu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qsub_u16\" => p!(\"vqsubu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qsubq_u16\" => p!(\"vqsubu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qsub_u32\" => p!(\"vqsubu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qsubq_u32\" => p!(\"vqsubu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qsub_u64\" => p!(\"vqsubu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qsubq_u64\" => p!(\"vqsubu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"abd_s8\" => p!(\"vabds.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"abdq_s8\" => p!(\"vabds.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"abd_s16\" => p!(\"vabds.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"abdq_s16\" => p!(\"vabds.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"abd_s32\" => p!(\"vabds.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"abdq_s32\" => p!(\"vabds.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"abd_u8\" => p!(\"vabdu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"abdq_u8\" => p!(\"vabdu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"abd_u16\" => p!(\"vabdu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"abdq_u16\" => p!(\"vabdu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"abd_u32\" => p!(\"vabdu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"abdq_u32\" => p!(\"vabdu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"abd_f32\" => p!(\"vabds.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"abdq_f32\" => p!(\"vabds.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"max_s8\" => p!(\"vmaxs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"maxq_s8\" => p!(\"vmaxs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"max_s16\" => p!(\"vmaxs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"maxq_s16\" => p!(\"vmaxs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"max_s32\" => p!(\"vmaxs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"maxq_s32\" => p!(\"vmaxs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"max_u8\" => p!(\"vmaxu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"maxq_u8\" => p!(\"vmaxu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"max_u16\" => p!(\"vmaxu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"maxq_u16\" => p!(\"vmaxu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"max_u32\" => p!(\"vmaxu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"maxq_u32\" => p!(\"vmaxu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"max_f32\" => p!(\"vmaxs.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"maxq_f32\" => p!(\"vmaxs.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"min_s8\" => p!(\"vmins.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"minq_s8\" => p!(\"vmins.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"min_s16\" => p!(\"vmins.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"minq_s16\" => p!(\"vmins.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"min_s32\" => p!(\"vmins.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"minq_s32\" => p!(\"vmins.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"min_u8\" => p!(\"vminu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"minq_u8\" => p!(\"vminu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"min_u16\" => p!(\"vminu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"minq_u16\" => p!(\"vminu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"min_u32\" => p!(\"vminu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"minq_u32\" => p!(\"vminu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"min_f32\" => p!(\"vmins.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"minq_f32\" => p!(\"vmins.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"shl_s8\" => p!(\"vshifts.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"shlq_s8\" => p!(\"vshifts.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"shl_s16\" => p!(\"vshifts.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"shlq_s16\" => p!(\"vshifts.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"shl_s32\" => p!(\"vshifts.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"shlq_s32\" => p!(\"vshifts.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"shl_s64\" => p!(\"vshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"shlq_s64\" => p!(\"vshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"shl_u8\" => p!(\"vshiftu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"shlq_u8\" => p!(\"vshiftu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"shl_u16\" => p!(\"vshiftu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"shlq_u16\" => p!(\"vshiftu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"shl_u32\" => p!(\"vshiftu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"shlq_u32\" => p!(\"vshiftu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"shl_u64\" => p!(\"vshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"shlq_u64\" => p!(\"vshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qshl_s8\" => p!(\"vqshifts.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qshlq_s8\" => p!(\"vqshifts.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qshl_s16\" => p!(\"vqshifts.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qshlq_s16\" => p!(\"vqshifts.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qshl_s32\" => p!(\"vqshifts.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qshlq_s32\" => p!(\"vqshifts.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qshl_s64\" => p!(\"vqshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qshlq_s64\" => p!(\"vqshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qshl_u8\" => p!(\"vqshiftu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qshlq_u8\" => p!(\"vqshiftu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qshl_u16\" => p!(\"vqshiftu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qshlq_u16\" => p!(\"vqshiftu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qshl_u32\" => p!(\"vqshiftu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qshlq_u32\" => p!(\"vqshiftu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qshl_u64\" => p!(\"vqshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qshlq_u64\" => p!(\"vqshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"rshl_s8\" => p!(\"vrshifts.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"rshlr_s8\" => p!(\"vrshifts.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"rshl_s16\" => p!(\"vrshifts.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"rshlr_s16\" => p!(\"vrshifts.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"rshl_s32\" => p!(\"vrshifts.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"rshlr_s32\" => p!(\"vrshifts.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"rshl_s64\" => p!(\"vrshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"rshlr_s64\" => p!(\"vrshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"rshl_u8\" => p!(\"vrshiftu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"rshlr_u8\" => p!(\"vrshiftu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"rshl_u16\" => p!(\"vrshiftu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"rshlr_u16\" => p!(\"vrshiftu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"rshl_u32\" => p!(\"vrshiftu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"rshlr_u32\" => p!(\"vrshiftu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"rshl_u64\" => p!(\"vrshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"rshlr_u64\" => p!(\"vrshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qrshl_s8\" => p!(\"vqrshifts.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qrshlqr_s8\" => p!(\"vqrshifts.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qrshl_s16\" => p!(\"vqrshifts.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qrshlqr_s16\" => p!(\"vqrshifts.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qrshl_s32\" => p!(\"vqrshifts.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qrshlqr_s32\" => p!(\"vqrshifts.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qrshl_s64\" => p!(\"vqrshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qrshlqr_s64\" => p!(\"vqrshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qrshl_u8\" => p!(\"vqrshiftu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qrshlqr_u8\" => p!(\"vqrshiftu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qrshl_u16\" => p!(\"vqrshiftu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qrshlqr_u16\" => p!(\"vqrshiftu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qrshl_u32\" => p!(\"vqrshiftu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qrshlqr_u32\" => p!(\"vqrshiftu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qrshl_u64\" => p!(\"vqrshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qrshlqr_u64\" => p!(\"vqrshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qmovn_s16\" => p!(\"vqmovns.v8i8\", (i16x8) -> i8x8),\n-        \"qmovn_s32\" => p!(\"vqmovns.v4i16\", (i32x4) -> i16x4),\n-        \"qmovn_s64\" => p!(\"vqmovns.v2i32\", (i64x2) -> i32x2),\n-        \"qmovn_u16\" => p!(\"vqmovnu.v8i8\", (i16x8) -> i8x8),\n-        \"qmovn_u32\" => p!(\"vqmovnu.v4i16\", (i32x4) -> i16x4),\n-        \"qmovn_u64\" => p!(\"vqmovnu.v2i32\", (i64x2) -> i32x2),\n-        \"qmovun_s16\" => p!(\"vqmovnsu.v8i8\", (i16x8) -> i8x8),\n-        \"qmovun_s32\" => p!(\"vqmovnsu.v4i16\", (i32x4) -> i16x4),\n-        \"qmovun_s64\" => p!(\"vqmovnsu.v2i32\", (i64x2) -> i32x2),\n-        \"abs_s8\" => p!(\"vabs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"absq_s8\" => p!(\"vabs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"abs_s16\" => p!(\"vabs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"absq_s16\" => p!(\"vabs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"abs_s32\" => p!(\"vabs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"absq_s32\" => p!(\"vabs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"abs_f32\" => p!(\"vabs.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"absq_f32\" => p!(\"vabs.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"qabs_s8\" => p!(\"vqabs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qabsq_s8\" => p!(\"vqabs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qabs_s16\" => p!(\"vqabs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qabsq_s16\" => p!(\"vqabs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qabs_s32\" => p!(\"vqabs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qabsq_s32\" => p!(\"vqabs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"neg_s8\" => p!(\"vneg.v8i8\", (i8x8) -> i8x8),\n-        \"negq_s8\" => p!(\"vneg.v16i8\", (i8x16) -> i8x16),\n-        \"neg_s16\" => p!(\"vneg.v4i16\", (i16x4) -> i16x4),\n-        \"negq_s16\" => p!(\"vneg.v8i16\", (i16x8) -> i16x8),\n-        \"neg_s32\" => p!(\"vneg.v2i32\", (i32x2) -> i32x2),\n-        \"negq_s32\" => p!(\"vneg.v4i32\", (i32x4) -> i32x4),\n-        \"neg_f32\" => p!(\"vneg.v2f32\", (f32x2) -> f32x2),\n-        \"negq_f32\" => p!(\"vneg.v4f32\", (f32x4) -> f32x4),\n-        \"qneg_s8\" => p!(\"vqneg.v8i8\", (i8x8) -> i8x8),\n-        \"qnegq_s8\" => p!(\"vqneg.v16i8\", (i8x16) -> i8x16),\n-        \"qneg_s16\" => p!(\"vqneg.v4i16\", (i16x4) -> i16x4),\n-        \"qnegq_s16\" => p!(\"vqneg.v8i16\", (i16x8) -> i16x8),\n-        \"qneg_s32\" => p!(\"vqneg.v2i32\", (i32x2) -> i32x2),\n-        \"qnegq_s32\" => p!(\"vqneg.v4i32\", (i32x4) -> i32x4),\n-        \"cls_s8\" => p!(\"vcls.v8i8\", (i8x8) -> i8x8),\n-        \"clsq_s8\" => p!(\"vcls.v16i8\", (i8x16) -> i8x16),\n-        \"cls_s16\" => p!(\"vcls.v4i16\", (i16x4) -> i16x4),\n-        \"clsq_s16\" => p!(\"vcls.v8i16\", (i16x8) -> i16x8),\n-        \"cls_s32\" => p!(\"vcls.v2i32\", (i32x2) -> i32x2),\n-        \"clsq_s32\" => p!(\"vcls.v4i32\", (i32x4) -> i32x4),\n-        \"clz_s8\" => p!(\"vclz.v8i8\", (i8x8) -> i8x8),\n-        \"clzq_s8\" => p!(\"vclz.v16i8\", (i8x16) -> i8x16),\n-        \"clz_s16\" => p!(\"vclz.v4i16\", (i16x4) -> i16x4),\n-        \"clzq_s16\" => p!(\"vclz.v8i16\", (i16x8) -> i16x8),\n-        \"clz_s32\" => p!(\"vclz.v2i32\", (i32x2) -> i32x2),\n-        \"clzq_s32\" => p!(\"vclz.v4i32\", (i32x4) -> i32x4),\n-        \"cnt_s8\" => p!(\"vcnt.v8i8\", (i8x8) -> i8x8),\n-        \"cntq_s8\" => p!(\"vcnt.v16i8\", (i8x16) -> i8x16),\n-        \"recpe_u32\" => p!(\"vrecpe.v2i32\", (i32x2) -> i32x2),\n-        \"recpeq_u32\" => p!(\"vrecpe.v4i32\", (i32x4) -> i32x4),\n-        \"recpe_f32\" => p!(\"vrecpe.v2f32\", (f32x2) -> f32x2),\n-        \"recpeq_f32\" => p!(\"vrecpe.v4f32\", (f32x4) -> f32x4),\n-        \"recps_f32\" => p!(\"vrecps.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"recpsq_f32\" => p!(\"vrecps.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"rsqrte_u32\" => p!(\"vrsqrte.v2i32\", (i32x2) -> i32x2),\n-        \"rsqrteq_u32\" => p!(\"vrsqrte.v4i32\", (i32x4) -> i32x4),\n-        \"rsqrte_f32\" => p!(\"vrsqrte.v2f32\", (f32x2) -> f32x2),\n-        \"rsqrteq_f32\" => p!(\"vrsqrte.v4f32\", (f32x4) -> f32x4),\n-        \"rsqrts_f32\" => p!(\"vrsqrts.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"rsqrtsq_f32\" => p!(\"vrsqrts.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"bsl_s8\" => p!(\"vsl.v8i8\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"bslq_s8\" => p!(\"vsl.v16i8\", (i8x16, i8x16, i8x16) -> i8x16),\n-        \"padd_s8\" => p!(\"vpadd.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"padd_s16\" => p!(\"vpadd.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"padd_s32\" => p!(\"vpadd.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"padd_u8\" => p!(\"vpadd.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"padd_u16\" => p!(\"vpadd.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"padd_u32\" => p!(\"vpadd.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"padd_f32\" => p!(\"vpadd.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"paddl_s8\" => p!(\"vpaddls.v4i16.v8i8\", (i8x8) -> i16x4),\n-        \"paddlq_s8\" => p!(\"vpaddls.v8i16.v16i8\", (i8x16) -> i16x8),\n-        \"paddl_s16\" => p!(\"vpaddls.v2i32.v4i16\", (i16x4) -> i32x2),\n-        \"paddlq_s16\" => p!(\"vpaddls.v4i32.v8i16\", (i16x8) -> i32x4),\n-        \"paddl_s32\" => p!(\"vpaddls.v1i64.v2i32\", (i32x2) -> i64x1),\n-        \"paddlq_s32\" => p!(\"vpaddls.v2i64.v4i32\", (i32x4) -> i64x2),\n-        \"paddl_u8\" => p!(\"vpaddlu.v4i16.v8i8\", (i8x8) -> i16x4),\n-        \"paddlq_u8\" => p!(\"vpaddlu.v8i16.v16i8\", (i8x16) -> i16x8),\n-        \"paddl_u16\" => p!(\"vpaddlu.v2i32.v4i16\", (i16x4) -> i32x2),\n-        \"paddlq_u16\" => p!(\"vpaddlu.v4i32.v8i16\", (i16x8) -> i32x4),\n-        \"paddl_u32\" => p!(\"vpaddlu.v1i64.v2i32\", (i32x2) -> i64x1),\n-        \"paddlq_u32\" => p!(\"vpaddlu.v2i64.v4i32\", (i32x4) -> i64x2),\n-        \"padal_s8\" => p!(\"vpadals.v4i16.v8i8\", (i16x4, i8x8) -> i16x4),\n-        \"padalq_s8\" => p!(\"vpadals.v8i16.v16i8\", (i16x8, i8x16) -> i16x8),\n-        \"padal_s16\" => p!(\"vpadals.v2i32.v4i16\", (i32x2, i16x4) -> i32x2),\n-        \"padalq_s16\" => p!(\"vpadals.v4i32.v8i16\", (i32x4, i16x8) -> i32x4),\n-        \"padal_s32\" => p!(\"vpadals.v1i64.v2i32\", (i64x1, i32x2) -> i64x1),\n-        \"padalq_s32\" => p!(\"vpadals.v2i64.v4i32\", (i64x2, i32x4) -> i64x2),\n-        \"padal_u8\" => p!(\"vpadalu.v4i16.v8i8\", (i16x4, i8x8) -> i16x4),\n-        \"padalq_u8\" => p!(\"vpadalu.v8i16.v16i8\", (i16x8, i8x16) -> i16x8),\n-        \"padal_u16\" => p!(\"vpadalu.v2i32.v4i16\", (i32x2, i16x4) -> i32x2),\n-        \"padalq_u16\" => p!(\"vpadalu.v4i32.v8i16\", (i32x4, i16x8) -> i32x4),\n-        \"padal_u32\" => p!(\"vpadalu.v1i64.v2i32\", (i64x1, i32x2) -> i64x1),\n-        \"padalq_u32\" => p!(\"vpadalu.v2i64.v4i32\", (i64x2, i32x4) -> i64x2),\n-        \"pmax_s16\" => p!(\"vpmaxs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"pmax_s32\" => p!(\"vpmaxs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"pmax_s8\" => p!(\"vpmaxs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"pmax_u16\" => p!(\"vpmaxu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"pmax_u32\" => p!(\"vpmaxu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"pmax_u8\" => p!(\"vpmaxu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"pmin_s16\" => p!(\"vpmins.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"pmin_s32\" => p!(\"vpmins.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"pmin_s8\" => p!(\"vpmins.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"pmin_u16\" => p!(\"vpminu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"pmin_u32\" => p!(\"vpminu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"pmin_u8\" => p!(\"vpminu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"tbl1_s8\" => p!(\"vtbl1\", (i8x8, i8x8) -> i8x8),\n-        \"tbl1_u8\" => p!(\"vtbl1\", (i8x8, i8x8) -> i8x8),\n-        // these aren't exactly the C intrinsics (they take one argument)\n-        \"tbl2_s8\" => p!(\"vtbl2\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl2_u8\" => p!(\"vtbl2\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl3_s8\" => p!(\"vtbl3\", (i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl3_u8\" => p!(\"vtbl3\", (i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl4_s8\" => p!(\"vtbl4\", (i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl4_u8\" => p!(\"vtbl4\", (i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx1_s8\" => p!(\"vtbx1\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx1_u8\" => p!(\"vtbx1\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx2_s8\" => p!(\"vtbx2\", (i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx2_u8\" => p!(\"vtbx2\", (i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx3_s8\" => p!(\"vtbx3\", (i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx3_u8\" => p!(\"vtbx3\", (i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx4_s8\" => p!(\"vtbx4\", (i8x8, i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx4_u8\" => p!(\"vtbx4\", (i8x8, i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n+    if !name.starts_with(\"arm_v\") { return None }\n+    Some(match &name[\"arm_v\".len()..] {\n+        \"hadd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vhadds.v8i8\")\n+        },\n+        \"hadd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vhaddu.v8i8\")\n+        },\n+        \"hadd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vhadds.v4i16\")\n+        },\n+        \"hadd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vhaddu.v4i16\")\n+        },\n+        \"hadd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vhadds.v2i32\")\n+        },\n+        \"hadd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vhaddu.v2i32\")\n+        },\n+        \"haddq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vhadds.v16i8\")\n+        },\n+        \"haddq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vhaddu.v16i8\")\n+        },\n+        \"haddq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vhadds.v8i16\")\n+        },\n+        \"haddq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vhaddu.v8i16\")\n+        },\n+        \"haddq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vhadds.v4i32\")\n+        },\n+        \"haddq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vhaddu.v4i32\")\n+        },\n+        \"rhadd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vrhadds.v8i8\")\n+        },\n+        \"rhadd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vrhaddu.v8i8\")\n+        },\n+        \"rhadd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vrhadds.v4i16\")\n+        },\n+        \"rhadd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vrhaddu.v4i16\")\n+        },\n+        \"rhadd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vrhadds.v2i32\")\n+        },\n+        \"rhadd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrhaddu.v2i32\")\n+        },\n+        \"rhaddq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vrhadds.v16i8\")\n+        },\n+        \"rhaddq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vrhaddu.v16i8\")\n+        },\n+        \"rhaddq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vrhadds.v8i16\")\n+        },\n+        \"rhaddq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vrhaddu.v8i16\")\n+        },\n+        \"rhaddq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vrhadds.v4i32\")\n+        },\n+        \"rhaddq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vrhaddu.v4i32\")\n+        },\n+        \"qadd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqadds.v8i8\")\n+        },\n+        \"qadd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqaddu.v8i8\")\n+        },\n+        \"qadd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqadds.v4i16\")\n+        },\n+        \"qadd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqaddu.v4i16\")\n+        },\n+        \"qadd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqadds.v2i32\")\n+        },\n+        \"qadd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqaddu.v2i32\")\n+        },\n+        \"qadd_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vqadds.v1i64\")\n+        },\n+        \"qadd_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vqaddu.v1i64\")\n+        },\n+        \"qaddq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vqadds.v16i8\")\n+        },\n+        \"qaddq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vqaddu.v16i8\")\n+        },\n+        \"qaddq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vqadds.v8i16\")\n+        },\n+        \"qaddq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vqaddu.v8i16\")\n+        },\n+        \"qaddq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vqadds.v4i32\")\n+        },\n+        \"qaddq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vqaddu.v4i32\")\n+        },\n+        \"qaddq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vqadds.v2i64\")\n+        },\n+        \"qaddq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vqaddu.v2i64\")\n+        },\n+        \"raddhn_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vraddhn.v8i8\")\n+        },\n+        \"raddhn_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vraddhn.v8i8\")\n+        },\n+        \"raddhn_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vraddhn.v4i16\")\n+        },\n+        \"raddhn_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vraddhn.v4i16\")\n+        },\n+        \"raddhn_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vraddhn.v2i32\")\n+        },\n+        \"raddhn_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vraddhn.v2i32\")\n+        },\n+        \"fma_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.fma.v2f32\")\n+        },\n+        \"fmaq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.fma.v4f32\")\n+        },\n+        \"qdmulh_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqdmulh.v4i16\")\n+        },\n+        \"qdmulh_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqdmulh.v2i32\")\n+        },\n+        \"qdmulhq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqdmulh.v8i16\")\n+        },\n+        \"qdmulhq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqdmulh.v4i32\")\n+        },\n+        \"qrdmulh_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqrdmulh.v4i16\")\n+        },\n+        \"qrdmulh_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqrdmulh.v2i32\")\n+        },\n+        \"qrdmulhq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqrdmulh.v8i16\")\n+        },\n+        \"qrdmulhq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqrdmulh.v4i32\")\n+        },\n+        \"mull_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vmulls.v8i16\")\n+        },\n+        \"mull_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vmullu.v8i16\")\n+        },\n+        \"mull_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vmulls.v4i32\")\n+        },\n+        \"mull_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vmullu.v4i32\")\n+        },\n+        \"mull_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vmulls.v2i64\")\n+        },\n+        \"mull_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vmullu.v2i64\")\n+        },\n+        \"qdmullq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqdmull.v8i16\")\n+        },\n+        \"qdmullq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqdmull.v4i32\")\n+        },\n+        \"hsub_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vhsubs.v8i8\")\n+        },\n+        \"hsub_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vhsubu.v8i8\")\n+        },\n+        \"hsub_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vhsubs.v4i16\")\n+        },\n+        \"hsub_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vhsubu.v4i16\")\n+        },\n+        \"hsub_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vhsubs.v2i32\")\n+        },\n+        \"hsub_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vhsubu.v2i32\")\n+        },\n+        \"hsubq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vhsubs.v16i8\")\n+        },\n+        \"hsubq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vhsubu.v16i8\")\n+        },\n+        \"hsubq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vhsubs.v8i16\")\n+        },\n+        \"hsubq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vhsubu.v8i16\")\n+        },\n+        \"hsubq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vhsubs.v4i32\")\n+        },\n+        \"hsubq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vhsubu.v4i32\")\n+        },\n+        \"qsub_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqsubs.v8i8\")\n+        },\n+        \"qsub_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqsubu.v8i8\")\n+        },\n+        \"qsub_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqsubs.v4i16\")\n+        },\n+        \"qsub_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqsubu.v4i16\")\n+        },\n+        \"qsub_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqsubs.v2i32\")\n+        },\n+        \"qsub_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqsubu.v2i32\")\n+        },\n+        \"qsub_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vqsubs.v1i64\")\n+        },\n+        \"qsub_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vqsubu.v1i64\")\n+        },\n+        \"qsubq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vqsubs.v16i8\")\n+        },\n+        \"qsubq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vqsubu.v16i8\")\n+        },\n+        \"qsubq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vqsubs.v8i16\")\n+        },\n+        \"qsubq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vqsubu.v8i16\")\n+        },\n+        \"qsubq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vqsubs.v4i32\")\n+        },\n+        \"qsubq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vqsubu.v4i32\")\n+        },\n+        \"qsubq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vqsubs.v2i64\")\n+        },\n+        \"qsubq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vqsubu.v2i64\")\n+        },\n+        \"rsubhn_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vrsubhn.v8i8\")\n+        },\n+        \"rsubhn_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vrsubhn.v8i8\")\n+        },\n+        \"rsubhn_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vrsubhn.v4i16\")\n+        },\n+        \"rsubhn_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vrsubhn.v4i16\")\n+        },\n+        \"rsubhn_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vrsubhn.v2i32\")\n+        },\n+        \"rsubhn_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrsubhn.v2i32\")\n+        },\n+        \"abd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vabds.v8i8\")\n+        },\n+        \"abd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vabdu.v8i8\")\n+        },\n+        \"abd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vabds.v4i16\")\n+        },\n+        \"abd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vabdu.v4i16\")\n+        },\n+        \"abd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vabds.v2i32\")\n+        },\n+        \"abd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vabdu.v2i32\")\n+        },\n+        \"abd_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vabdf.v2f32\")\n+        },\n+        \"abdq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vabds.v16i8\")\n+        },\n+        \"abdq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vabdu.v16i8\")\n+        },\n+        \"abdq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vabds.v8i16\")\n+        },\n+        \"abdq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vabdu.v8i16\")\n+        },\n+        \"abdq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vabds.v4i32\")\n+        },\n+        \"abdq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vabdu.v4i32\")\n+        },\n+        \"abdq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vabdf.v4f32\")\n+        },\n+        \"max_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vmaxs.v8i8\")\n+        },\n+        \"max_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vmaxu.v8i8\")\n+        },\n+        \"max_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vmaxs.v4i16\")\n+        },\n+        \"max_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vmaxu.v4i16\")\n+        },\n+        \"max_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vmaxs.v2i32\")\n+        },\n+        \"max_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vmaxu.v2i32\")\n+        },\n+        \"max_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vmaxf.v2f32\")\n+        },\n+        \"maxq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vmaxs.v16i8\")\n+        },\n+        \"maxq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vmaxu.v16i8\")\n+        },\n+        \"maxq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vmaxs.v8i16\")\n+        },\n+        \"maxq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vmaxu.v8i16\")\n+        },\n+        \"maxq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vmaxs.v4i32\")\n+        },\n+        \"maxq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vmaxu.v4i32\")\n+        },\n+        \"maxq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vmaxf.v4f32\")\n+        },\n+        \"min_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vmins.v8i8\")\n+        },\n+        \"min_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vminu.v8i8\")\n+        },\n+        \"min_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vmins.v4i16\")\n+        },\n+        \"min_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vminu.v4i16\")\n+        },\n+        \"min_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vmins.v2i32\")\n+        },\n+        \"min_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vminu.v2i32\")\n+        },\n+        \"min_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vminf.v2f32\")\n+        },\n+        \"minq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vmins.v16i8\")\n+        },\n+        \"minq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vminu.v16i8\")\n+        },\n+        \"minq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vmins.v8i16\")\n+        },\n+        \"minq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vminu.v8i16\")\n+        },\n+        \"minq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vmins.v4i32\")\n+        },\n+        \"minq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vminu.v4i32\")\n+        },\n+        \"minq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vminf.v4f32\")\n+        },\n+        \"shl_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vshls.v8i8\")\n+        },\n+        \"shl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vshlu.v8i8\")\n+        },\n+        \"shl_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vshls.v4i16\")\n+        },\n+        \"shl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vshlu.v4i16\")\n+        },\n+        \"shl_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vshls.v2i32\")\n+        },\n+        \"shl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vshlu.v2i32\")\n+        },\n+        \"shl_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vshls.v1i64\")\n+        },\n+        \"shl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vshlu.v1i64\")\n+        },\n+        \"shlq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vshls.v16i8\")\n+        },\n+        \"shlq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vshlu.v16i8\")\n+        },\n+        \"shlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vshls.v8i16\")\n+        },\n+        \"shlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vshlu.v8i16\")\n+        },\n+        \"shlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vshls.v4i32\")\n+        },\n+        \"shlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vshlu.v4i32\")\n+        },\n+        \"shlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vshls.v2i64\")\n+        },\n+        \"shlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vshlu.v2i64\")\n+        },\n+        \"qshl_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqshls.v8i8\")\n+        },\n+        \"qshl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqshlu.v8i8\")\n+        },\n+        \"qshl_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqshls.v4i16\")\n+        },\n+        \"qshl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqshlu.v4i16\")\n+        },\n+        \"qshl_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqshls.v2i32\")\n+        },\n+        \"qshl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqshlu.v2i32\")\n+        },\n+        \"qshl_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vqshls.v1i64\")\n+        },\n+        \"qshl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vqshlu.v1i64\")\n+        },\n+        \"qshlq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vqshls.v16i8\")\n+        },\n+        \"qshlq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vqshlu.v16i8\")\n+        },\n+        \"qshlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vqshls.v8i16\")\n+        },\n+        \"qshlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vqshlu.v8i16\")\n+        },\n+        \"qshlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vqshls.v4i32\")\n+        },\n+        \"qshlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vqshlu.v4i32\")\n+        },\n+        \"qshlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vqshls.v2i64\")\n+        },\n+        \"qshlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vqshlu.v2i64\")\n+        },\n+        \"rshl_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vrshls.v8i8\")\n+        },\n+        \"rshl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vrshlu.v8i8\")\n+        },\n+        \"rshl_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vrshls.v4i16\")\n+        },\n+        \"rshl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vrshlu.v4i16\")\n+        },\n+        \"rshl_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vrshls.v2i32\")\n+        },\n+        \"rshl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrshlu.v2i32\")\n+        },\n+        \"rshl_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vrshls.v1i64\")\n+        },\n+        \"rshl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vrshlu.v1i64\")\n+        },\n+        \"rshlq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vrshls.v16i8\")\n+        },\n+        \"rshlq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vrshlu.v16i8\")\n+        },\n+        \"rshlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vrshls.v8i16\")\n+        },\n+        \"rshlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vrshlu.v8i16\")\n+        },\n+        \"rshlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vrshls.v4i32\")\n+        },\n+        \"rshlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vrshlu.v4i32\")\n+        },\n+        \"rshlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vrshls.v2i64\")\n+        },\n+        \"rshlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vrshlu.v2i64\")\n+        },\n+        \"qrshl_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqrshls.v8i8\")\n+        },\n+        \"qrshl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqrshlu.v8i8\")\n+        },\n+        \"qrshl_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqrshls.v4i16\")\n+        },\n+        \"qrshl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqrshlu.v4i16\")\n+        },\n+        \"qrshl_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqrshls.v2i32\")\n+        },\n+        \"qrshl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqrshlu.v2i32\")\n+        },\n+        \"qrshl_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vqrshls.v1i64\")\n+        },\n+        \"qrshl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vqrshlu.v1i64\")\n+        },\n+        \"qrshlq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vqrshls.v16i8\")\n+        },\n+        \"qrshlq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vqrshlu.v16i8\")\n+        },\n+        \"qrshlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vqrshls.v8i16\")\n+        },\n+        \"qrshlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vqrshlu.v8i16\")\n+        },\n+        \"qrshlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vqrshls.v4i32\")\n+        },\n+        \"qrshlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vqrshlu.v4i32\")\n+        },\n+        \"qrshlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vqrshls.v2i64\")\n+        },\n+        \"qrshlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vqrshlu.v2i64\")\n+        },\n+        \"qshrun_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vsqshrun.v8i8\")\n+        },\n+        \"qshrun_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqshrun.v4i16\")\n+        },\n+        \"qshrun_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqshrun.v2i32\")\n+        },\n+        \"qrshrun_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vsqrshrun.v8i8\")\n+        },\n+        \"qrshrun_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqrshrun.v4i16\")\n+        },\n+        \"qrshrun_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqrshrun.v2i32\")\n+        },\n+        \"qshrn_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqshrns.v8i8\")\n+        },\n+        \"qshrn_n_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), u(32)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqshrnu.v8i8\")\n+        },\n+        \"qshrn_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqshrns.v4i16\")\n+        },\n+        \"qshrn_n_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), u(32)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqshrnu.v4i16\")\n+        },\n+        \"qshrn_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqshrns.v2i32\")\n+        },\n+        \"qshrn_n_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), u(32)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqshrnu.v2i32\")\n+        },\n+        \"rshrn_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vrshrn.v8i8\")\n+        },\n+        \"rshrn_n_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), u(32)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vrshrn.v8i8\")\n+        },\n+        \"rshrn_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vrshrn.v4i16\")\n+        },\n+        \"rshrn_n_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), u(32)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vrshrn.v4i16\")\n+        },\n+        \"rshrn_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vrshrn.v2i32\")\n+        },\n+        \"rshrn_n_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), u(32)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrshrn.v2i32\")\n+        },\n+        \"qrshrn_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqrshrns.v8i8\")\n+        },\n+        \"qrshrn_n_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), u(32)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqrshrnu.v8i8\")\n+        },\n+        \"qrshrn_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqrshrns.v4i16\")\n+        },\n+        \"qrshrn_n_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), u(32)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqrshrnu.v4i16\")\n+        },\n+        \"qrshrn_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqrshrns.v2i32\")\n+        },\n+        \"qrshrn_n_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), u(32)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqrshrnu.v2i32\")\n+        },\n+        \"sri_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vvsri.v8i8\")\n+        },\n+        \"sri_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vvsri.v8i8\")\n+        },\n+        \"sri_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vvsri.v4i16\")\n+        },\n+        \"sri_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vvsri.v4i16\")\n+        },\n+        \"sri_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vvsri.v2i32\")\n+        },\n+        \"sri_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vvsri.v2i32\")\n+        },\n+        \"sri_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vvsri.v1i64\")\n+        },\n+        \"sri_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vvsri.v1i64\")\n+        },\n+        \"sriq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vvsri.v16i8\")\n+        },\n+        \"sriq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vvsri.v16i8\")\n+        },\n+        \"sriq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vvsri.v8i16\")\n+        },\n+        \"sriq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vvsri.v8i16\")\n+        },\n+        \"sriq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vvsri.v4i32\")\n+        },\n+        \"sriq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vvsri.v4i32\")\n+        },\n+        \"sriq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vvsri.v2i64\")\n+        },\n+        \"sriq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vvsri.v2i64\")\n+        },\n+        \"sli_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vvsli.v8i8\")\n+        },\n+        \"sli_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vvsli.v8i8\")\n+        },\n+        \"sli_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vvsli.v4i16\")\n+        },\n+        \"sli_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vvsli.v4i16\")\n+        },\n+        \"sli_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vvsli.v2i32\")\n+        },\n+        \"sli_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vvsli.v2i32\")\n+        },\n+        \"sli_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vvsli.v1i64\")\n+        },\n+        \"sli_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vvsli.v1i64\")\n+        },\n+        \"sliq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vvsli.v16i8\")\n+        },\n+        \"sliq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vvsli.v16i8\")\n+        },\n+        \"sliq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vvsli.v8i16\")\n+        },\n+        \"sliq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vvsli.v8i16\")\n+        },\n+        \"sliq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vvsli.v4i32\")\n+        },\n+        \"sliq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vvsli.v4i32\")\n+        },\n+        \"sliq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vvsli.v2i64\")\n+        },\n+        \"sliq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vvsli.v2i64\")\n+        },\n+        \"vqmovn_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqxtns.v8i8\")\n+        },\n+        \"vqmovn_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqxtnu.v8i8\")\n+        },\n+        \"vqmovn_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqxtns.v4i16\")\n+        },\n+        \"vqmovn_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqxtnu.v4i16\")\n+        },\n+        \"vqmovn_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqxtns.v2i32\")\n+        },\n+        \"vqmovn_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqxtnu.v2i32\")\n+        },\n+        \"abs_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vabs.v8i8\")\n+        },\n+        \"abs_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vabs.v4i16\")\n+        },\n+        \"abs_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vabs.v2i32\")\n+        },\n+        \"absq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vabs.v16i8\")\n+        },\n+        \"absq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vabs.v8i16\")\n+        },\n+        \"absq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vabs.v4i32\")\n+        },\n+        \"abs_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.fabs.v2f32\")\n+        },\n+        \"absq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.fabs.v4f32\")\n+        },\n+        \"qabs_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vsqabs.v8i8\")\n+        },\n+        \"qabs_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqabs.v4i16\")\n+        },\n+        \"qabs_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqabs.v2i32\")\n+        },\n+        \"qabsq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vsqabs.v16i8\")\n+        },\n+        \"qabsq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqabs.v8i16\")\n+        },\n+        \"qabsq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqabs.v4i32\")\n+        },\n+        \"qneg_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vsqneg.v8i8\")\n+        },\n+        \"qneg_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqneg.v4i16\")\n+        },\n+        \"qneg_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqneg.v2i32\")\n+        },\n+        \"qnegq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vsqneg.v16i8\")\n+        },\n+        \"qnegq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqneg.v8i16\")\n+        },\n+        \"qnegq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqneg.v4i32\")\n+        },\n+        \"clz_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.ctlz.v8i8\")\n+        },\n+        \"clz_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.ctlz.v8i8\")\n+        },\n+        \"clz_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.ctlz.v4i16\")\n+        },\n+        \"clz_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.ctlz.v4i16\")\n+        },\n+        \"clz_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.ctlz.v2i32\")\n+        },\n+        \"clz_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.ctlz.v2i32\")\n+        },\n+        \"clzq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.ctlz.v16i8\")\n+        },\n+        \"clzq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.ctlz.v16i8\")\n+        },\n+        \"clzq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.ctlz.v8i16\")\n+        },\n+        \"clzq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.ctlz.v8i16\")\n+        },\n+        \"clzq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.ctlz.v4i32\")\n+        },\n+        \"clzq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.ctlz.v4i32\")\n+        },\n+        \"cls_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vcls.v8i8\")\n+        },\n+        \"cls_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vcls.v8i8\")\n+        },\n+        \"cls_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vcls.v4i16\")\n+        },\n+        \"cls_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vcls.v4i16\")\n+        },\n+        \"cls_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vcls.v2i32\")\n+        },\n+        \"cls_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vcls.v2i32\")\n+        },\n+        \"clsq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vcls.v16i8\")\n+        },\n+        \"clsq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vcls.v16i8\")\n+        },\n+        \"clsq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vcls.v8i16\")\n+        },\n+        \"clsq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vcls.v8i16\")\n+        },\n+        \"clsq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vcls.v4i32\")\n+        },\n+        \"clsq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vcls.v4i32\")\n+        },\n+        \"cnt_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.ctpop.v8i8\")\n+        },\n+        \"cnt_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.ctpop.v8i8\")\n+        },\n+        \"cntq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.ctpop.v16i8\")\n+        },\n+        \"cntq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.ctpop.v16i8\")\n+        },\n+        \"recpe_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrecpe.v2i32\")\n+        },\n+        \"recpe_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vrecpe.v2f32\")\n+        },\n+        \"recpeq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vrecpe.v4i32\")\n+        },\n+        \"recpeq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vrecpe.v4f32\")\n+        },\n+        \"recps_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vfrecps.v2f32\")\n+        },\n+        \"recpsq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vfrecps.v4f32\")\n+        },\n+        \"sqrt_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.sqrt.v2f32\")\n+        },\n+        \"sqrtq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.sqrt.v4f32\")\n+        },\n+        \"rsqrte_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrsqrte.v2i32\")\n+        },\n+        \"rsqrte_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vrsqrte.v2f32\")\n+        },\n+        \"rsqrteq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vrsqrte.v4i32\")\n+        },\n+        \"rsqrteq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vrsqrte.v4f32\")\n+        },\n+        \"rsqrts_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vrsqrts.v2f32\")\n+        },\n+        \"rsqrtsq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vrsqrts.v4f32\")\n+        },\n+        \"bsl_s8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vbsl.v8i8\")\n+        },\n+        \"bsl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vbsl.v8i8\")\n+        },\n+        \"bsl_s16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vbsl.v4i16\")\n+        },\n+        \"bsl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vbsl.v4i16\")\n+        },\n+        \"bsl_s32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vbsl.v2i32\")\n+        },\n+        \"bsl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vbsl.v2i32\")\n+        },\n+        \"bsl_s64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vbsl.v1i64\")\n+        },\n+        \"bsl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vbsl.v1i64\")\n+        },\n+        \"bslq_s8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vbsl.v16i8\")\n+        },\n+        \"bslq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vbsl.v16i8\")\n+        },\n+        \"bslq_s16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vbsl.v8i16\")\n+        },\n+        \"bslq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vbsl.v8i16\")\n+        },\n+        \"bslq_s32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vbsl.v4i32\")\n+        },\n+        \"bslq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vbsl.v4i32\")\n+        },\n+        \"bslq_s64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vbsl.v2i64\")\n+        },\n+        \"bslq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vbsl.v2i64\")\n+        },\n+        \"padd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vpadd.v8i8\")\n+        },\n+        \"padd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vpadd.v8i8\")\n+        },\n+        \"padd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpadd.v4i16\")\n+        },\n+        \"padd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpadd.v4i16\")\n+        },\n+        \"padd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpadd.v2i32\")\n+        },\n+        \"padd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpadd.v2i32\")\n+        },\n+        \"padd_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vpadd.v2f32\")\n+        },\n+        \"paddl_s16\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpaddls.v4i16.v8i8\")\n+        },\n+        \"paddl_u16\" => Intrinsic {\n+            inputs: vec![v(u(8), 8)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpaddlu.v4i16.v8i8\")\n+        },\n+        \"paddl_s32\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpaddls.v2i32.v4i16\")\n+        },\n+        \"paddl_u32\" => Intrinsic {\n+            inputs: vec![v(u(16), 4)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpaddlu.v2i32.v4i16\")\n+        },\n+        \"paddl_s64\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vpaddls.v1i64.v2i32\")\n+        },\n+        \"paddl_u64\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vpaddlu.v1i64.v2i32\")\n+        },\n+        \"paddlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vpaddls.v8i16.v16i8\")\n+        },\n+        \"paddlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(8), 16)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vpaddlu.v8i16.v16i8\")\n+        },\n+        \"paddlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vpaddls.v4i32.v8i16\")\n+        },\n+        \"paddlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vpaddlu.v4i32.v8i16\")\n+        },\n+        \"paddlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vpaddls.v2i64.v4i32\")\n+        },\n+        \"paddlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vpaddlu.v2i64.v4i32\")\n+        },\n+        \"padal_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(8), 8)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpadals.v4i16.v4i16\")\n+        },\n+        \"padal_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(8), 8)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpadalu.v4i16.v4i16\")\n+        },\n+        \"padal_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(16), 4)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpadals.v2i32.v2i32\")\n+        },\n+        \"padal_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(16), 4)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpadalu.v2i32.v2i32\")\n+        },\n+        \"padal_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(32), 2)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vpadals.v1i64.v1i64\")\n+        },\n+        \"padal_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(32), 2)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vpadalu.v1i64.v1i64\")\n+        },\n+        \"padalq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(8), 16)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vpadals.v8i16.v8i16\")\n+        },\n+        \"padalq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(8), 16)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vpadalu.v8i16.v8i16\")\n+        },\n+        \"padalq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(16), 8)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vpadals.v4i32.v4i32\")\n+        },\n+        \"padalq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(16), 8)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vpadalu.v4i32.v4i32\")\n+        },\n+        \"padalq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(32), 4)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vpadals.v2i64.v2i64\")\n+        },\n+        \"padalq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(32), 4)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vpadalu.v2i64.v2i64\")\n+        },\n+        \"pmax_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vpmaxs.v8i8\")\n+        },\n+        \"pmax_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vpmaxu.v8i8\")\n+        },\n+        \"pmax_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpmaxs.v4i16\")\n+        },\n+        \"pmax_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpmaxu.v4i16\")\n+        },\n+        \"pmax_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpmaxs.v2i32\")\n+        },\n+        \"pmax_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpmaxu.v2i32\")\n+        },\n+        \"pmax_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vpmaxf.v2f32\")\n+        },\n+        \"pmin_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vpmins.v8i8\")\n+        },\n+        \"pmin_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vpminu.v8i8\")\n+        },\n+        \"pmin_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpmins.v4i16\")\n+        },\n+        \"pmin_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpminu.v4i16\")\n+        },\n+        \"pmin_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpmins.v2i32\")\n+        },\n+        \"pmin_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpminu.v2i32\")\n+        },\n+        \"pmin_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vpminf.v2f32\")\n+        },\n+        \"pminq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vpmins.v16i8\")\n+        },\n+        \"pminq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vpminu.v16i8\")\n+        },\n+        \"pminq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vpmins.v8i16\")\n+        },\n+        \"pminq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vpminu.v8i16\")\n+        },\n+        \"pminq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vpmins.v4i32\")\n+        },\n+        \"pminq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vpminu.v4i32\")\n+        },\n+        \"pminq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vpminf.v4f32\")\n+        },\n+        \"tbl1_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbl1\")\n+        },\n+        \"tbl1_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbl1\")\n+        },\n+        \"tbx1_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbx1\")\n+        },\n+        \"tbx1_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbx1\")\n+        },\n+        \"tbl2_s8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbl2\")\n+        },\n+        \"tbl2_u8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbl2\")\n+        },\n+        \"tbx2_s8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbx2\")\n+        },\n+        \"tbx2_u8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbx2\")\n+        },\n+        \"tbl3_s8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbl3\")\n+        },\n+        \"tbl3_u8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbl3\")\n+        },\n+        \"tbx3_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), agg(true, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbx3\")\n+        },\n+        \"tbx3_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), agg(true, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbx3\")\n+        },\n+        \"tbl4_s8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbl4\")\n+        },\n+        \"tbl4_u8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbl4\")\n+        },\n+        \"tbx4_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), agg(true, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbx4\")\n+        },\n+        \"tbx4_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), agg(true, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbx4\")\n+        },\n         _ => return None,\n     })\n }"}, {"sha": "1727347ef7bd5bc5a9a2b588a2a70fce7ed4e2f5", "filename": "src/librustc_platform_intrinsics/lib.rs", "status": "modified", "additions": 12, "deletions": 44, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_platform_intrinsics%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_platform_intrinsics%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Flib.rs?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -30,58 +30,26 @@ pub struct Intrinsic {\n \n #[derive(Clone, Hash, Eq, PartialEq)]\n pub enum Type {\n-    Integer(u8),\n+    Integer(/* signed */ bool, u8, /* llvm width */ u8),\n     Float(u8),\n     Pointer(Box<Type>),\n     Vector(Box<Type>, u8),\n+    Aggregate(bool, Vec<Type>),\n }\n \n pub enum IntrinsicDef {\n     Named(&'static str),\n }\n \n-fn i(width: u8) -> Type { Type::Integer(width) }\n+fn i(width: u8) -> Type { Type::Integer(true, width, width) }\n+fn i_(width: u8, llvm_width: u8) -> Type { Type::Integer(true, width, llvm_width) }\n+fn u(width: u8) -> Type { Type::Integer(false, width, width) }\n+#[allow(dead_code)]\n+fn u_(width: u8, llvm_width: u8) -> Type { Type::Integer(false, width, llvm_width) }\n fn f(width: u8) -> Type { Type::Float(width) }\n fn v(x: Type, length: u8) -> Type { Type::Vector(Box::new(x), length) }\n-\n-macro_rules! ty {\n-    (f32x8) => (v(f(32), 8));\n-    (f64x4) => (v(f(64), 4));\n-\n-    (i8x32) => (v(i(8), 32));\n-    (i16x16) => (v(i(16), 16));\n-    (i32x8) => (v(i(32), 8));\n-    (i64x4) => (v(i(64), 4));\n-\n-    (f32x4) => (v(f(32), 4));\n-    (f64x2) => (v(f(64), 2));\n-\n-    (i8x16) => (v(i(8), 16));\n-    (i16x8) => (v(i(16), 8));\n-    (i32x4) => (v(i(32), 4));\n-    (i64x2) => (v(i(64), 2));\n-\n-    (f32x2) => (v(f(32), 2));\n-    (i8x8) => (v(i(8), 8));\n-    (i16x4) => (v(i(16), 4));\n-    (i32x2) => (v(i(32), 2));\n-    (i64x1)=> (v(i(64), 1));\n-\n-    (i64) => (i(64));\n-    (i32) => (i(32));\n-    (i16) => (i(16));\n-    (i8) => (i(8));\n-    (f32) => (f(32));\n-    (f64) => (f(64));\n-}\n-macro_rules! plain {\n-    ($name: expr, ($($inputs: tt),*) -> $output: tt) => {\n-        Intrinsic {\n-            inputs: vec![$(ty!($inputs)),*],\n-            output: ty!($output),\n-            definition: ::IntrinsicDef::Named($name)\n-        }\n-    }\n+fn agg(flatten: bool, types: Vec<Type>) -> Type {\n+    Type::Aggregate(flatten, types)\n }\n \n mod x86;\n@@ -91,11 +59,11 @@ mod aarch64;\n impl Intrinsic {\n     pub fn find<'tcx>(tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n         if name.starts_with(\"x86_\") {\n-            x86::find(tcx, &name[\"x86_\".len()..])\n+            x86::find(tcx, name)\n         } else if name.starts_with(\"arm_\") {\n-            arm::find(tcx, &name[\"arm_\".len()..])\n+            arm::find(tcx, name)\n         } else if name.starts_with(\"aarch64_\") {\n-            aarch64::find(tcx, &name[\"aarch64_\".len()..])\n+            aarch64::find(tcx, name)\n         } else {\n             None\n         }"}, {"sha": "a6fe8aef0b4394922ff5f7a01c2bda94d52e805a", "filename": "src/librustc_platform_intrinsics/x86.rs", "status": "modified", "additions": 866, "deletions": 174, "changes": 1040, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_platform_intrinsics%2Fx86.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_platform_intrinsics%2Fx86.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Fx86.rs?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -8,181 +8,873 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use {Intrinsic, i, f, v};\n-use rustc::middle::ty;\n-\n-macro_rules! p {\n-    ($name: expr, ($($inputs: tt),*) -> $output: tt) => {\n-        plain!(concat!(\"llvm.x86.\", $name), ($($inputs),*) -> $output)\n-    }\n-}\n-\n-pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n-    if name.starts_with(\"mm_\") {\n-        Some(match &name[\"mm_\".len()..] {\n-            \"sqrt_ps\" => plain!(\"llvm.sqrt.v4f32\", (f32x4) -> f32x4),\n-            \"sqrt_pd\" => plain!(\"llvm.sqrt.v2f64\", (f64x2) -> f64x2),\n-\n-            \"movemask_ps\" => p!(\"sse.movmsk.ps\", (f32x4) -> i32),\n-            \"max_ps\" => p!(\"sse.max.ps\", (f32x4, f32x4) -> f32x4),\n-            \"min_ps\" => p!(\"sse.min.ps\", (f32x4, f32x4) -> f32x4),\n-            \"rsqrt_ps\" => p!(\"sse.rsqrt.ps\", (f32x4) -> f32x4),\n-            \"rcp_ps\" => p!(\"sse.rcp.ps\", (f32x4) -> f32x4),\n-\n-            \"adds_epi16\" => p!(\"sse2.padds.w\", (i16x8, i16x8) -> i16x8),\n-            \"adds_epi8\" => p!(\"sse2.padds.b\", (i8x16, i8x16) -> i8x16),\n-            \"adds_epu16\" => p!(\"sse2.paddus.w\", (i16x8, i16x8) -> i16x8),\n-            \"adds_epu8\" => p!(\"sse2.paddus.b\", (i8x16, i8x16) -> i8x16),\n-            \"avg_epu16\" => p!(\"sse2.pavg.w\", (i16x8, i16x8) -> i16x8),\n-            \"avg_epu8\" => p!(\"sse2.pavg.b\", (i8x16, i8x16) -> i8x16),\n-            \"madd_epi16\" => p!(\"sse2.pmadd.wd\", (i16x8, i16x8) -> i32x4),\n-            \"max_epi16\" => p!(\"sse2.pmaxs.w\", (i16x8, i16x8) -> i16x8),\n-            \"max_epu8\" => p!(\"sse2.pmaxu.b\", (i8x16, i8x16) -> i8x16),\n-            \"max_pd\" => p!(\"sse2.max.pd\", (f64x2, f64x2) -> f64x2),\n-            \"min_epi16\" => p!(\"sse2.pmins.w\", (i16x8, i16x8) -> i16x8),\n-            \"min_epu8\" => p!(\"sse2.pminu.b\", (i8x16, i8x16) -> i8x16),\n-            \"min_pd\" => p!(\"sse2.min.pd\", (f64x2, f64x2) -> f64x2),\n-            \"movemask_pd\" => p!(\"sse2.movmsk.pd\", (f64x2) -> i32),\n-            \"movemask_epi8\" => p!(\"sse2.pmovmskb.128\", (i8x16) -> i32),\n-            \"mul_epu32\" => p!(\"sse2.pmulu.dq\", (i32x4, i32x4) -> i64x2),\n-            \"mulhi_epi16\" => p!(\"sse2.pmulh.w\", (i8x16, i8x16) -> i8x16),\n-            \"mulhi_epu16\" => p!(\"sse2.pmulhu.w\", (i8x16, i8x16) -> i8x16),\n-            \"packs_epi16\" => p!(\"sse2.packsswb.128\", (i16x8, i16x8) -> i8x16),\n-            \"packs_epi32\" => p!(\"sse2.packssdw.128\", (i32x4, i32x4) -> i16x8),\n-            \"packus_epi16\" => p!(\"sse2.packuswb.128\", (i16x8, i16x8) -> i8x16),\n-            \"sad_epu8\" => p!(\"sse2.psad.bw\", (i8x16, i8x16) -> i64x2),\n-            \"subs_epi16\" => p!(\"sse2.psubs.w\", (i16x8, i16x8) -> i16x8),\n-            \"subs_epi8\" => p!(\"sse2.psubs.b\", (i8x16, i8x16) -> i8x16),\n-            \"subs_epu16\" => p!(\"sse2.psubus.w\", (i16x8, i16x8) -> i16x8),\n-            \"subs_epu8\" => p!(\"sse2.psubus.b\", (i8x16, i8x16) -> i8x16),\n+// DO NOT EDIT: autogenerated by etc/platform-intrinsics/generator.py\n+// ignore-tidy-linelength\n \n-            \"addsub_pd\" => p!(\"sse3.addsub.pd\", (f64x2, f64x2) -> f64x2),\n-            \"addsub_ps\" => p!(\"sse3.addsub.ps\", (f32x4, f32x4) -> f32x4),\n-            \"hadd_pd\" => p!(\"sse3.hadd.pd\", (f64x2, f64x2) -> f64x2),\n-            \"hadd_ps\" => p!(\"sse3.hadd.ps\", (f32x4, f32x4) -> f32x4),\n-            \"hsub_pd\" => p!(\"sse3.hsub.pd\", (f64x2, f64x2) -> f64x2),\n-            \"hsub_ps\" => p!(\"sse3.hsub.ps\", (f32x4, f32x4) -> f32x4),\n+#![allow(unused_imports)]\n \n-            \"abs_epi16\" => p!(\"ssse3.pabs.w.128\", (i16x8) -> i16x8),\n-            \"abs_epi32\" => p!(\"ssse3.pabs.d.128\", (i32x4) -> i32x4),\n-            \"abs_epi8\" => p!(\"ssse3.pabs.b.128\", (i8x16) -> i8x16),\n-            \"hadd_epi16\" => p!(\"ssse3.phadd.w.128\", (i16x8, i16x8) -> i16x8),\n-            \"hadd_epi32\" => p!(\"ssse3.phadd.d.128\", (i32x4, i32x4) -> i32x4),\n-            \"hadds_epi16\" => p!(\"ssse3.phadd.sw.128\", (i16x8, i16x8) -> i16x8),\n-            \"hsub_epi16\" => p!(\"ssse3.phsub.w.128\", (i16x8, i16x8) -> i16x8),\n-            \"hsub_epi32\" => p!(\"ssse3.phsub.d.128\", (i32x4, i32x4) -> i32x4),\n-            \"hsubs_epi16\" => p!(\"ssse3.phsub.sw.128\", (i16x8, i16x8) -> i16x8),\n-            \"maddubs_epi16\" => p!(\"ssse3.pmadd.ub.sw.128\", (i8x16, i8x16) -> i16x8),\n-            \"mulhrs_epi16\" => p!(\"ssse3.pmul.hr.sw.128\", (i16x8, i16x8) -> i16x8),\n-            \"shuffle_epi8\" => p!(\"ssse3.pshuf.b.128\", (i8x16, i8x16) -> i8x16),\n-            \"sign_epi16\" => p!(\"ssse3.psign.w.128\", (i16x8, i16x8) -> i16x8),\n-            \"sign_epi32\" => p!(\"ssse3.psign.d.128\", (i32x4, i32x4) -> i32x4),\n-            \"sign_epi8\" => p!(\"ssse3.psign.b.128\", (i8x16, i8x16) -> i8x16),\n-\n-            \"max_epi32\" => p!(\"sse41.pmaxsd\", (i32x4, i32x4) -> i32x4),\n-            \"max_epi8\" => p!(\"sse41.pmaxsb\", (i8x16, i8x16) -> i8x16),\n-            \"max_epu16\" => p!(\"sse41.pmaxuw\", (i16x8, i16x8) -> i16x8),\n-            \"max_epu32\" => p!(\"sse41.pmaxud\", (i32x4, i32x4) -> i32x4),\n-            \"min_epi32\" => p!(\"sse41.pminsd\", (i32x4, i32x4) -> i32x4),\n-            \"min_epi8\" => p!(\"sse41.pminsb\", (i8x16, i8x16) -> i8x16),\n-            \"min_epu16\" => p!(\"sse41.pminuw\", (i16x8, i16x8) -> i16x8),\n-            \"min_epu32\" => p!(\"sse41.pminud\", (i32x4, i32x4) -> i32x4),\n-            \"minpos_epu16\" => p!(\"sse41.phminposuw\", (i16x8) -> i16x8),\n-            \"mul_epi32\" => p!(\"sse41.muldq\", (i32x4, i32x4) -> i64x2),\n-            \"packus_epi32\" => p!(\"sse41.packusdw\", (i32x4, i32x4) -> i16x8),\n-            \"testc_si128\" => p!(\"sse41.ptestc\", (i64x2, i64x2) -> i32),\n-            \"testnzc_si128\" => p!(\"sse41.ptestnzc\", (i64x2, i64x2) -> i32),\n-            \"testz_si128\" => p!(\"sse41.ptestz\", (i64x2, i64x2) -> i32),\n-\n-            \"permutevar_pd\" => p!(\"avx.vpermilvar.pd\", (f64x2, i64x2) -> f64x2),\n-            \"permutevar_ps\" => p!(\"avx.vpermilvar.ps\", (f32x4, i32x4) -> f32x4),\n-            \"testc_pd\" => p!(\"avx.vtestc.pd\", (f64x2, f64x2) -> i32),\n-            \"testc_ps\" => p!(\"avx.vtestc.ps\", (f32x4, f32x4) -> i32),\n-            \"testnzc_pd\" => p!(\"avx.vtestnzc.pd\", (f64x2, f64x2) -> i32),\n-            \"testnzc_ps\" => p!(\"avx.vtestnzc.ps\", (f32x4, f32x4) -> i32),\n-            \"testz_pd\" => p!(\"avx.vtestz.pd\", (f64x2, f64x2) -> i32),\n-            \"testz_ps\" => p!(\"avx.vtestz.ps\", (f32x4, f32x4) -> i32),\n-\n-            _ => return None\n-        })\n-    } else if name.starts_with(\"mm256_\") {\n-        Some(match &name[\"mm256_\".len()..] {\n-            \"addsub_pd\" => p!(\"avx.addsub.pd.256\", (f64x4, f64x4) -> f64x4),\n-            \"addsub_ps\" => p!(\"avx.addsub.ps.256\", (f32x8, f32x8) -> f32x8),\n-            \"hadd_pd\" => p!(\"avx.hadd.pd.256\", (f64x4, f64x4) -> f64x4),\n-            \"hadd_ps\" => p!(\"avx.hadd.ps.256\", (f32x8, f32x8) -> f32x8),\n-            \"hsub_pd\" => p!(\"avx.hsub.pd.256\", (f64x4, f64x4) -> f64x4),\n-            \"hsub_ps\" => p!(\"avx.hsub.ps.256\", (f32x8, f32x8) -> f32x8),\n-            \"max_pd\" => p!(\"avx.max.pd.256\", (f64x4, f64x4) -> f64x4),\n-            \"max_ps\" => p!(\"avx.max.ps.256\", (f32x8, f32x8) -> f32x8),\n-            \"min_pd\" => p!(\"avx.min.pd.256\", (f64x4, f64x4) -> f64x4),\n-            \"min_ps\" => p!(\"avx.min.ps.256\", (f32x8, f32x8) -> f32x8),\n-            \"permutevar_pd\" => p!(\"avx.vpermilvar.pd.256\", (f64x4, i64x4) -> f64x4),\n-            \"permutevar_ps\" => p!(\"avx.vpermilvar.ps.256\", (f32x8, i32x8) -> f32x8),\n-            \"rcp_ps\" => p!(\"avx.rcp.ps.256\", (f32x8) -> f32x8),\n-            \"rsqrt_ps\" => p!(\"avx.rsqrt.ps.256\", (f32x8) -> f32x8),\n-            \"sqrt_pd\" => p!(\"llvm.sqrt.v4f64\", (f64x4) -> f64x4),\n-            \"sqrt_ps\" => p!(\"llvm.sqrt.v8f32\", (f32x8) -> f32x8),\n-            \"testc_pd\" => p!(\"avx.vtestc.pd.256\", (f64x4, f64x4) -> i32),\n-            \"testc_ps\" => p!(\"avx.vtestc.ps.256\", (f32x8, f32x8) -> i32),\n-            \"testnzc_pd\" => p!(\"avx.vtestnzc.pd.256\", (f64x4, f64x4) -> i32),\n-            \"testnzc_ps\" => p!(\"avx.vtestnzc.ps.256\", (f32x8, f32x8) -> i32),\n-            \"testz_pd\" => p!(\"avx.vtestz.pd.256\", (f64x4, f64x4) -> i32),\n-            \"testz_ps\" => p!(\"avx.vtestz.ps.256\", (f32x8, f32x8) -> i32),\n-\n-            \"abs_epi16\" => p!(\"avx2.pabs.w\", (i16x16) -> i16x16),\n-            \"abs_epi32\" => p!(\"avx2.pabs.d\", (i32x8) -> i32x8),\n-            \"abs_epi8\" => p!(\"avx2.pabs.b\", (i8x32) -> i8x32),\n-            \"adds_epi16\" => p!(\"avx2.padds.w\", (i16x16, i16x16) -> i16x16),\n-            \"adds_epi8\" => p!(\"avx2.padds.b\", (i8x32, i8x32) -> i8x32),\n-            \"adds_epu16\" => p!(\"avx2.paddus.w\", (i16x16, i16x16) -> i16x16),\n-            \"adds_epu8\" => p!(\"avx2.paddus.b\", (i8x32, i8x32) -> i8x32),\n-            \"avg_epu16\" => p!(\"avx2.pavg.w\", (i16x16, i16x16) -> i16x16),\n-            \"avg_epu8\" => p!(\"avx2.pavg.b\", (i8x32, i8x32) -> i8x32),\n-            \"hadd_epi16\" => p!(\"avx2.phadd.w\", (i16x16, i16x16) -> i16x16),\n-            \"hadd_epi32\" => p!(\"avx2.phadd.d\", (i32x8, i32x8) -> i32x8),\n-            \"hadds_epi16\" => p!(\"avx2.phadd.sw\", (i16x16, i16x16) -> i16x16),\n-            \"hsub_epi16\" => p!(\"avx2.phsub.w\", (i16x16, i16x16) -> i16x16),\n-            \"hsub_epi32\" => p!(\"avx2.phsub.d\", (i32x8, i32x8) -> i32x8),\n-            \"hsubs_epi16\" => p!(\"avx2.phsub.sw\", (i16x16, i16x16) -> i16x16),\n-            \"madd_epi16\" => p!(\"avx2.pmadd.wd\", (i16x16, i16x16) -> i32x8),\n-            \"maddubs_epi16\" => p!(\"avx2.pmadd.ub.sw\", (i8x32, i8x32) -> i16x16),\n-            \"max_epi16\" => p!(\"avx2.pmaxs.w\", (i16x16, i16x16) -> i16x16),\n-            \"max_epi32\" => p!(\"avx2.pmaxs.d\", (i32x8, i32x8) -> i32x8),\n-            \"max_epi8\" => p!(\"avx2.pmaxs.b\", (i8x32, i8x32) -> i8x32),\n-            \"max_epu16\" => p!(\"avx2.pmaxu.w\", (i16x16, i16x16) -> i16x16),\n-            \"max_epu32\" => p!(\"avx2.pmaxu.d\", (i32x8, i32x8) -> i32x8),\n-            \"max_epu8\" => p!(\"avx2.pmaxu.b\", (i8x32, i8x32) -> i8x32),\n-            \"min_epi16\" => p!(\"avx2.pmins.w\", (i16x16, i16x16) -> i16x16),\n-            \"min_epi32\" => p!(\"avx2.pmins.d\", (i32x8, i32x8) -> i32x8),\n-            \"min_epi8\" => p!(\"avx2.pmins.b\", (i8x32, i8x32) -> i8x32),\n-            \"min_epu16\" => p!(\"avx2.pminu.w\", (i16x16, i16x16) -> i16x16),\n-            \"min_epu32\" => p!(\"avx2.pminu.d\", (i32x8, i32x8) -> i32x8),\n-            \"min_epu8\" => p!(\"avx2.pminu.b\", (i8x32, i8x32) -> i8x32),\n-            \"mul_epi32\" => p!(\"avx2.mul.dq\", (i32x8, i32x8) -> i64x4),\n-            \"mul_epu32\" => p!(\"avx2.mulu.dq\", (i32x8, i32x8) -> i64x4),\n-            \"mulhi_epi16\" => p!(\"avx2.pmulh.w\", (i8x32, i8x32) -> i8x32),\n-            \"mulhi_epu16\" => p!(\"avx2.pmulhu.w\", (i8x32, i8x32) -> i8x32),\n-            \"mulhrs_epi16\" => p!(\"avx2.pmul.hr.sw\", (i16x16, i16x16) -> i16x16),\n-            \"packs_epi16\" => p!(\"avx2.packsswb\", (i16x16, i16x16) -> i8x32),\n-            \"packs_epi32\" => p!(\"avx2.packssdw\", (i32x8, i32x8) -> i16x16),\n-            \"packus_epi16\" => p!(\"avx2.packuswb\", (i16x16, i16x16) -> i8x32),\n-            \"packus_epi32\" => p!(\"avx2.packusdw\", (i32x8, i32x8) -> i16x16),\n-            \"permutevar8x32_epi32\" => p!(\"avx2.permd\", (i32x8, i32x8) -> i32x8),\n-            \"permutevar8x32_ps\" => p!(\"avx2.permps\", (f32x8, i32x8) -> i32x8),\n-            \"sad_epu8\" => p!(\"avx2.psad.bw\", (i8x32, i8x32) -> i64x4),\n-            \"shuffle_epi8\" => p!(\"avx2.pshuf.b\", (i8x32, i8x32) -> i8x32),\n-            \"sign_epi16\" => p!(\"avx2.psign.w\", (i16x16, i16x16) -> i16x16),\n-            \"sign_epi32\" => p!(\"avx2.psign.d\", (i32x8, i32x8) -> i32x8),\n-            \"sign_epi8\" => p!(\"avx2.psign.b\", (i8x32, i8x32) -> i8x32),\n-            \"subs_epi16\" => p!(\"avx2.psubs.w\", (i16x16, i16x16) -> i16x16),\n-            \"subs_epi8\" => p!(\"avx2.psubs.b\", (i8x32, i8x32) -> i8x32),\n-            \"subs_epu16\" => p!(\"avx2.psubus.w\", (i16x16, i16x16) -> i16x16),\n-            \"subs_epu8\" => p!(\"avx2.psubus.b\", (i8x32, i8x32) -> i8x32),\n+use {Intrinsic, i, i_, u, u_, f, v, agg};\n+use IntrinsicDef::Named;\n+use rustc::middle::ty;\n \n-            _ => return None,\n-        })\n-    } else {\n-        None\n-    }\n+pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n+    if !name.starts_with(\"x86_mm\") { return None }\n+    Some(match &name[\"x86_mm\".len()..] {\n+        \"_movemask_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse.movmsk.ps\")\n+        },\n+        \"_max_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.sse.max.ps\")\n+        },\n+        \"_min_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.sse.min.ps\")\n+        },\n+        \"_rsqrt_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.sse.rsqrt.ps\")\n+        },\n+        \"_rcp_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.sse.rcp.ps\")\n+        },\n+        \"_sqrt_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.sqrt.v4f32\")\n+        },\n+        \"_adds_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.sse2.padds.b\")\n+        },\n+        \"_adds_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.x86.sse2.paddus.b\")\n+        },\n+        \"_adds_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.sse2.padds.w\")\n+        },\n+        \"_adds_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse2.paddus.w\")\n+        },\n+        \"_avg_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.x86.sse2.pavg.b\")\n+        },\n+        \"_avg_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse2.pavg.w\")\n+        },\n+        \"_madd_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.sse2.pmadd.wd\")\n+        },\n+        \"_max_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.sse2.pmaxs.w\")\n+        },\n+        \"_max_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.x86.sse2.pmaxu.b\")\n+        },\n+        \"_max_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.sse2.max.pd\")\n+        },\n+        \"_min_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.sse2.pmins.w\")\n+        },\n+        \"_min_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.x86.sse2.pminu.b\")\n+        },\n+        \"_min_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.sse2.min.pd\")\n+        },\n+        \"_movemask_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse2.movmsk.pd\")\n+        },\n+        \"_movemask_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse2.pmovmskb.128\")\n+        },\n+        \"_mul_epu32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.x86.sse2.pmulu.dq\")\n+        },\n+        \"_mulhi_eps16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.sse2.pmulh.w\")\n+        },\n+        \"_mulhi_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse2.pmulhu.w\")\n+        },\n+        \"_packs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.sse2.packsswb.128\")\n+        },\n+        \"_packs_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.sse2.packssdw.128\")\n+        },\n+        \"_packus_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.x86.sse2.packuswb.128\")\n+        },\n+        \"_sad_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.x86.sse2.psad.bw\")\n+        },\n+        \"_sqrt_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.sqrt.v2f64\")\n+        },\n+        \"_subs_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.sse2.psubs.b\")\n+        },\n+        \"_subs_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.x86.sse2.psubus.b\")\n+        },\n+        \"_subs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.sse2.psubs.w\")\n+        },\n+        \"_subs_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse2.psubus.w\")\n+        },\n+        \"_addsub_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.sse3.addsub.ps\")\n+        },\n+        \"_addsub_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.sse3.addsub.pd\")\n+        },\n+        \"_hadd_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.sse3.hadd.ps\")\n+        },\n+        \"_hadd_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.sse3.hadd.pd\")\n+        },\n+        \"_hsub_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.sse3.hsub.ps\")\n+        },\n+        \"_hsub_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.sse3.hsub.pd\")\n+        },\n+        \"_abs_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.ssse3.pabs.b\")\n+        },\n+        \"_abs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.ssse3.pabs.w\")\n+        },\n+        \"_abs_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.ssse3.pabs.d\")\n+        },\n+        \"_hadd_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.ssse3.phadd.w.128\")\n+        },\n+        \"_hadd_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.ssse3.phadd.d.128\")\n+        },\n+        \"_hadds_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.ssse3.phadd.sw.128\")\n+        },\n+        \"_hsub_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.ssse3.phsub.w.128\")\n+        },\n+        \"_hsub_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.ssse3.phsub.d.128\")\n+        },\n+        \"_hsubs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.ssse3.phsub.sw.128\")\n+        },\n+        \"_maddubs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.ssse3.pmadd.ub.sw.128\")\n+        },\n+        \"_mulhrs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.ssse3.pmul.hr.sw.128\")\n+        },\n+        \"_shuffle_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.ssse3.pshuf.b.128\")\n+        },\n+        \"_sign_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.ssse3.psign.b.128\")\n+        },\n+        \"_sign_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.x86.ssse3.psign.w.128\")\n+        },\n+        \"_dp_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4), i_(32, 8)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.sse41.dpps\")\n+        },\n+        \"_dp_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2), i_(32, 8)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.sse41.dppd\")\n+        },\n+        \"_max_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.sse41.pmaxsb\")\n+        },\n+        \"_max_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse41.pmaxuw\")\n+        },\n+        \"_max_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.sse41.pmaxsd\")\n+        },\n+        \"_max_epu32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.x86.sse41.pmaxud\")\n+        },\n+        \"_min_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.sse41.pminsb\")\n+        },\n+        \"_min_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse41.pminuw\")\n+        },\n+        \"_min_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.sse41.pminsd\")\n+        },\n+        \"_min_epu32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.x86.sse41.pminud\")\n+        },\n+        \"_minpos_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse41.phminposuw\")\n+        },\n+        \"_mpsadbw_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16), i_(32, 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse41.mpsadbw\")\n+        },\n+        \"_mul_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.x86.sse41.muldq\")\n+        },\n+        \"_packus_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.x86.sse41.packusdw\")\n+        },\n+        \"_testc_si128\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse41.ptestc\")\n+        },\n+        \"_testncz_si128\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse41.ptest.nzc\")\n+        },\n+        \"_testz_si128\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse41.ptestz\")\n+        },\n+        \"_cmpestra\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), i(32), v(i(8), 16), i(32), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpestria128\")\n+        },\n+        \"_cmpestrc\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), i(32), v(i(8), 16), i(32), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpestric128\")\n+        },\n+        \"_cmpestri\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), i(32), v(i(8), 16), i(32), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpestri128\")\n+        },\n+        \"_cmpestrm\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), i(32), v(i(8), 16), i(32), i_(32, 8)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.sse42.pcmpestrm128\")\n+        },\n+        \"_cmpestro\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), i(32), v(i(8), 16), i(32), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpestrio128\")\n+        },\n+        \"_cmpestrs\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), i(32), v(i(8), 16), i(32), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpestris128\")\n+        },\n+        \"_cmpestrz\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), i(32), v(i(8), 16), i(32), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpestriz128\")\n+        },\n+        \"_cmpistra\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpistria128\")\n+        },\n+        \"_cmpistrc\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpistric128\")\n+        },\n+        \"_cmpistri\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpistri128\")\n+        },\n+        \"_cmpistrm\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16), i_(32, 8)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.x86.sse42.pcmpistrm128\")\n+        },\n+        \"_cmpistro\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpistrio128\")\n+        },\n+        \"_cmpistrs\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpistris128\")\n+        },\n+        \"_cmpistrz\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16), i_(32, 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.sse42.pcmpistriz128\")\n+        },\n+        \"256_addsub_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.addsub.ps.256\")\n+        },\n+        \"256_addsub_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(f(64), 4)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx.addsub.pd.256\")\n+        },\n+        \"256_dp_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8), i_(32, 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.dp.ps.256\")\n+        },\n+        \"256_hadd_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.hadd.ps.256\")\n+        },\n+        \"256_hadd_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(f(64), 4)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx.hadd.pd.256\")\n+        },\n+        \"256_hsub_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.hsub.ps.256\")\n+        },\n+        \"256_hsub_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(f(64), 4)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx.hsub.pd.256\")\n+        },\n+        \"256_max_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.max.ps.256\")\n+        },\n+        \"256_max_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(f(64), 4)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx.max.pd.256\")\n+        },\n+        \"256_min_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.min.ps.256\")\n+        },\n+        \"256_min_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(f(64), 4)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx.min.pd.256\")\n+        },\n+        \"256_movemask_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.movmsk.ps.256\")\n+        },\n+        \"256_movemask_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.movmsk.pd.256\")\n+        },\n+        \"_permutevar_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(i(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.avx.vpermilvar.ps\")\n+        },\n+        \"_permutevar_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(i(64), 2)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.avx.vpermilvar.pd\")\n+        },\n+        \"256_permutevar_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(i(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.vpermilvar.ps.256\")\n+        },\n+        \"256_permutevar_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(i(64), 4)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx.vpermilvar.pd.256\")\n+        },\n+        \"256_rcp_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.rcp.ps.256\")\n+        },\n+        \"256_rsqrt_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.rsqrt.ps.256\")\n+        },\n+        \"256_sqrt_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.sqrt.v8f32\")\n+        },\n+        \"256_sqrt_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.sqrt.v4f64\")\n+        },\n+        \"_testc_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestc.ps\")\n+        },\n+        \"256_testc_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestc.ps.256\")\n+        },\n+        \"_testc_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestc.pd\")\n+        },\n+        \"256_testc_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(f(64), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestc.pd.256\")\n+        },\n+        \"256_testc_si256\" => Intrinsic {\n+            inputs: vec![v(u(64), 4), v(u(64), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.ptestc.256\")\n+        },\n+        \"_testnzc_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestnzc.ps\")\n+        },\n+        \"256_testnzc_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestnzc.ps.256\")\n+        },\n+        \"_testnzc_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestnzc.pd\")\n+        },\n+        \"256_testnzc_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(f(64), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestnzc.pd.256\")\n+        },\n+        \"256_testnzc_si256\" => Intrinsic {\n+            inputs: vec![v(u(64), 4), v(u(64), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.ptestnzc.256\")\n+        },\n+        \"_testz_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestz.ps\")\n+        },\n+        \"256_testz_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(f(32), 8)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestz.ps.256\")\n+        },\n+        \"_testz_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), v(f(64), 2)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestz.pd\")\n+        },\n+        \"256_testz_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), v(f(64), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.vtestz.pd.256\")\n+        },\n+        \"256_testz_si256\" => Intrinsic {\n+            inputs: vec![v(u(64), 4), v(u(64), 4)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx.ptestz.256\")\n+        },\n+        \"256_abs_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 32)],\n+            output: v(i(8), 32),\n+            definition: Named(\"llvm.x86.avx2.avx2.pabs.b\")\n+        },\n+        \"256_abs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.avx2.pabs.w\")\n+        },\n+        \"256_abs_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.avx2.pabs.d\")\n+        },\n+        \"256_adds_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 32), v(i(8), 32)],\n+            output: v(i(8), 32),\n+            definition: Named(\"llvm.x86.avx2.avx2.padds.b\")\n+        },\n+        \"256_adds_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 32), v(u(8), 32)],\n+            output: v(u(8), 32),\n+            definition: Named(\"llvm.x86.avx2.avx2.paddus.b\")\n+        },\n+        \"256_adds_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.avx2.padds.w\")\n+        },\n+        \"256_adds_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 16), v(u(16), 16)],\n+            output: v(u(16), 16),\n+            definition: Named(\"llvm.x86.avx2.avx2.paddus.w\")\n+        },\n+        \"256_avg_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 32), v(u(8), 32)],\n+            output: v(u(8), 32),\n+            definition: Named(\"llvm.x86.avx2.avx2.pavg.b\")\n+        },\n+        \"256_avg_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 16), v(u(16), 16)],\n+            output: v(u(16), 16),\n+            definition: Named(\"llvm.x86.avx2.avx2.pavg.w\")\n+        },\n+        \"256_hadd_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.phadd.w\")\n+        },\n+        \"256_hadd_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.phadd.d\")\n+        },\n+        \"256_hadds_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.phadd.sw\")\n+        },\n+        \"256_hsub_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.phsub.w\")\n+        },\n+        \"256_hsub_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.phsub.d\")\n+        },\n+        \"256_hsubs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.phsub.sw\")\n+        },\n+        \"256_madd_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.pmadd.wd\")\n+        },\n+        \"256_maddubs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(8), 32), v(i(8), 32)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.pmadd.ub.sw\")\n+        },\n+        \"256_max_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 32), v(i(8), 32)],\n+            output: v(i(8), 32),\n+            definition: Named(\"llvm.x86.avx2.pmaxs.b\")\n+        },\n+        \"256_max_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 32), v(u(8), 32)],\n+            output: v(u(8), 32),\n+            definition: Named(\"llvm.x86.avx2.pmaxu.b\")\n+        },\n+        \"256_max_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.pmaxs.w\")\n+        },\n+        \"256_max_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 16), v(u(16), 16)],\n+            output: v(u(16), 16),\n+            definition: Named(\"llvm.x86.avx2.pmaxu.w\")\n+        },\n+        \"256_max_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.pmaxs.d\")\n+        },\n+        \"256_max_epu32\" => Intrinsic {\n+            inputs: vec![v(u(32), 8), v(u(32), 8)],\n+            output: v(u(32), 8),\n+            definition: Named(\"llvm.x86.avx2.pmaxu.d\")\n+        },\n+        \"256_min_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 32), v(i(8), 32)],\n+            output: v(i(8), 32),\n+            definition: Named(\"llvm.x86.avx2.pmins.b\")\n+        },\n+        \"256_min_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 32), v(u(8), 32)],\n+            output: v(u(8), 32),\n+            definition: Named(\"llvm.x86.avx2.pminu.b\")\n+        },\n+        \"256_min_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.pmins.w\")\n+        },\n+        \"256_min_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 16), v(u(16), 16)],\n+            output: v(u(16), 16),\n+            definition: Named(\"llvm.x86.avx2.pminu.w\")\n+        },\n+        \"256_min_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.pmins.d\")\n+        },\n+        \"256_min_epu32\" => Intrinsic {\n+            inputs: vec![v(u(32), 8), v(u(32), 8)],\n+            output: v(u(32), 8),\n+            definition: Named(\"llvm.x86.avx2.pminu.d\")\n+        },\n+        \"256_movemask_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 32)],\n+            output: i(32),\n+            definition: Named(\"llvm.x86.avx2.pmovmskb\")\n+        },\n+        \"256_mpsadbw_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 32), v(u(8), 32), i_(32, 8)],\n+            output: v(u(16), 16),\n+            definition: Named(\"llvm.x86.avx2.mpsadbw\")\n+        },\n+        \"256_mul_epi64\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(i(64), 4),\n+            definition: Named(\"llvm.x86.avx2.pmulq.dq\")\n+        },\n+        \"256_mul_epu64\" => Intrinsic {\n+            inputs: vec![v(u(32), 8), v(u(32), 8)],\n+            output: v(u(64), 4),\n+            definition: Named(\"llvm.x86.avx2.pmulq.dq\")\n+        },\n+        \"256_mulhi_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.pmulhw.w\")\n+        },\n+        \"256_mulhi_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 16), v(u(16), 16)],\n+            output: v(u(16), 16),\n+            definition: Named(\"llvm.x86.avx2.pmulhw.w\")\n+        },\n+        \"256_mulhrs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.pmul.hr.sw\")\n+        },\n+        \"256_packs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(8), 32),\n+            definition: Named(\"llvm.x86.avx2.packsswb\")\n+        },\n+        \"256_packus_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(u(8), 32),\n+            definition: Named(\"llvm.x86.avx2.packuswb\")\n+        },\n+        \"256_packs_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.packssdw\")\n+        },\n+        \"256_packus_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(u(16), 16),\n+            definition: Named(\"llvm.x86.avx2.packusdw\")\n+        },\n+        \"256_permutevar8x32_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.permd\")\n+        },\n+        \"256_permutevar8x32_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), v(i(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx2.permps\")\n+        },\n+        \"256_sad_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 32), v(u(8), 32)],\n+            output: v(u(8), 32),\n+            definition: Named(\"llvm.x86.avx2.psad.bw\")\n+        },\n+        \"256_shuffle_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 32), v(i(8), 32)],\n+            output: v(i(8), 32),\n+            definition: Named(\"llvm.x86.avx2.pshuf.b\")\n+        },\n+        \"256_sign_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 32), v(i(8), 32)],\n+            output: v(i(8), 32),\n+            definition: Named(\"llvm.x86.avx2.psign.b\")\n+        },\n+        \"256_sign_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.psign.w\")\n+        },\n+        \"256_sign_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), v(i(32), 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.psign.d\")\n+        },\n+        \"256_subs_epi8\" => Intrinsic {\n+            inputs: vec![v(i(8), 32), v(i(8), 32)],\n+            output: v(i(8), 32),\n+            definition: Named(\"llvm.x86.avx2.psubs.b\")\n+        },\n+        \"256_subs_epu8\" => Intrinsic {\n+            inputs: vec![v(u(8), 32), v(u(8), 32)],\n+            output: v(u(8), 32),\n+            definition: Named(\"llvm.x86.avx2.psubus.b\")\n+        },\n+        \"256_subs_epi16\" => Intrinsic {\n+            inputs: vec![v(i(16), 16), v(i(16), 16)],\n+            output: v(i(16), 16),\n+            definition: Named(\"llvm.x86.avx2.psubs.w\")\n+        },\n+        \"256_subs_epu16\" => Intrinsic {\n+            inputs: vec![v(u(16), 16), v(u(16), 16)],\n+            output: v(u(16), 16),\n+            definition: Named(\"llvm.x86.avx2.psubus.w\")\n+        },\n+        _ => return None,\n+    })\n }"}, {"sha": "89208052fada6b71ef53c0c29a6a6ef2f95a4593", "filename": "src/librustc_trans/trans/intrinsic.rs", "status": "modified", "additions": 91, "deletions": 10, "changes": 101, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -171,9 +171,10 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n \n     let _icx = push_ctxt(\"trans_intrinsic_call\");\n \n-    let ret_ty = match callee_ty.sty {\n+    let (arg_tys, ret_ty) = match callee_ty.sty {\n         ty::TyBareFn(_, ref f) => {\n-            bcx.tcx().erase_late_bound_regions(&f.sig.output())\n+            (bcx.tcx().erase_late_bound_regions(&f.sig.inputs()),\n+             bcx.tcx().erase_late_bound_regions(&f.sig.output()))\n         }\n         _ => panic!(\"expected bare_fn in trans_intrinsic_call\")\n     };\n@@ -926,25 +927,105 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n                 Some(intr) => intr,\n                 None => ccx.sess().span_bug(foreign_item.span, \"unknown intrinsic\"),\n             };\n-            fn ty_to_type(ccx: &CrateContext, t: &intrinsics::Type) -> Type {\n+            fn one<T>(x: Vec<T>) -> T {\n+                assert_eq!(x.len(), 1);\n+                x.into_iter().next().unwrap()\n+            }\n+            fn ty_to_type(ccx: &CrateContext, t: &intrinsics::Type,\n+                          any_changes_needed: &mut bool) -> Vec<Type> {\n                 use intrinsics::Type::*;\n                 match *t {\n-                    Integer(x) => Type::ix(ccx, x as u64),\n+                    Integer(_signed, width, llvm_width) => {\n+                        *any_changes_needed |= width != llvm_width;\n+                        vec![Type::ix(ccx, llvm_width as u64)]\n+                    }\n                     Float(x) => {\n                         match x {\n-                            32 => Type::f32(ccx),\n-                            64 => Type::f64(ccx),\n+                            32 => vec![Type::f32(ccx)],\n+                            64 => vec![Type::f64(ccx)],\n                             _ => unreachable!()\n                         }\n                     }\n                     Pointer(_) => unimplemented!(),\n-                    Vector(ref t, length) => Type::vector(&ty_to_type(ccx, t),\n-                                                          length as u64)\n+                    Vector(ref t, length) => {\n+                        let elem = one(ty_to_type(ccx, t,\n+                                                  any_changes_needed));\n+                        vec![Type::vector(&elem,\n+                                          length as u64)]\n+                    }\n+                    Aggregate(false, _) => unimplemented!(),\n+                    Aggregate(true, ref contents) => {\n+                        *any_changes_needed = true;\n+                        contents.iter()\n+                                .flat_map(|t| ty_to_type(ccx, t, any_changes_needed))\n+                                .collect()\n+                    }\n+                }\n+            }\n+\n+            // This allows an argument list like `foo, (bar, baz),\n+            // qux` to be converted into `foo, bar, baz, qux`, and\n+            // integer arguments to be truncated as needed.\n+            fn modify_as_needed<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n+                                            t: &intrinsics::Type,\n+                                            arg_type: Ty<'tcx>,\n+                                            llarg: ValueRef)\n+                                            -> Vec<ValueRef>\n+            {\n+                match *t {\n+                    intrinsics::Type::Aggregate(true, ref contents) => {\n+                        // We found a tuple that needs squishing! So\n+                        // run over the tuple and load each field.\n+                        //\n+                        // This assumes the type is \"simple\", i.e. no\n+                        // destructors, and the contents are SIMD\n+                        // etc.\n+                        assert!(!bcx.fcx.type_needs_drop(arg_type));\n+\n+                        let repr = adt::represent_type(bcx.ccx(), arg_type);\n+                        let repr_ptr = &*repr;\n+                        (0..contents.len())\n+                            .map(|i| {\n+                                Load(bcx, adt::trans_field_ptr(bcx, repr_ptr, llarg, 0, i))\n+                            })\n+                            .collect()\n+                    }\n+                    intrinsics::Type::Integer(_, width, llvm_width) if width != llvm_width => {\n+                        // the LLVM intrinsic uses a smaller integer\n+                        // size than the C intrinsic's signature, so\n+                        // we have to trim it down here.\n+                        vec![Trunc(bcx, llarg, Type::ix(bcx.ccx(), llvm_width as u64))]\n+                    }\n+                    _ => vec![llarg],\n                 }\n             }\n \n-            let inputs = intr.inputs.iter().map(|t| ty_to_type(ccx, t)).collect::<Vec<_>>();\n-            let outputs = ty_to_type(ccx, &intr.output);\n+\n+            let mut any_changes_needed = false;\n+            let inputs = intr.inputs.iter()\n+                                    .flat_map(|t| ty_to_type(ccx, t, &mut any_changes_needed))\n+                                    .collect::<Vec<_>>();\n+\n+            let mut out_changes = false;\n+            let outputs = one(ty_to_type(ccx, &intr.output, &mut out_changes));\n+            // outputting a flattened aggregate is nonsense\n+            assert!(!out_changes);\n+\n+            let llargs = if !any_changes_needed {\n+                // no aggregates to flatten, so no change needed\n+                llargs\n+            } else {\n+                // there are some aggregates that need to be flattened\n+                // in the LLVM call, so we need to run over the types\n+                // again to find them and extract the arguments\n+                intr.inputs.iter()\n+                           .zip(&llargs)\n+                           .zip(&arg_tys)\n+                           .flat_map(|((t, llarg), ty)| modify_as_needed(bcx, t, ty, *llarg))\n+                           .collect()\n+            };\n+            assert_eq!(inputs.len(), llargs.len());\n+\n             match intr.definition {\n                 intrinsics::IntrinsicDef::Named(name) => {\n                     let f = declare::declare_cfn(ccx,"}, {"sha": "2baf6c2f7c7649c9bf9b82c694274ca2f86558c3", "filename": "src/librustc_typeck/check/intrinsic.rs", "status": "modified", "additions": 26, "deletions": 6, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -463,13 +463,16 @@ fn match_intrinsic_type_to_type<'tcx, 'a>(\n     };\n \n     match *expected {\n-        Integer(bits) => match (bits, &t.sty) {\n-            (8, &ty::TyInt(ast::TyI8)) | (8, &ty::TyUint(ast::TyU8)) |\n-            (16, &ty::TyInt(ast::TyI16)) | (16, &ty::TyUint(ast::TyU16)) |\n-            (32, &ty::TyInt(ast::TyI32)) | (32, &ty::TyUint(ast::TyU32)) |\n-            (64, &ty::TyInt(ast::TyI64)) | (64, &ty::TyUint(ast::TyU64)) => {},\n+        // (The width we pass to LLVM doesn't concern the type checker.)\n+        Integer(signed, bits, _llvm_width) => match (signed, bits, &t.sty) {\n+            (true, 8, &ty::TyInt(ast::TyI8)) | (false, 8, &ty::TyUint(ast::TyU8)) |\n+            (true, 16, &ty::TyInt(ast::TyI16)) | (false, 16, &ty::TyUint(ast::TyU16)) |\n+            (true, 32, &ty::TyInt(ast::TyI32)) | (false, 32, &ty::TyUint(ast::TyU32)) |\n+            (true, 64, &ty::TyInt(ast::TyI64)) | (false, 64, &ty::TyUint(ast::TyU64)) => {},\n             _ => simple_error(&format!(\"`{}`\", t),\n-                              &format!(\"`i{n}` or `u{n}`\", n = bits)),\n+                              &format!(\"`{}{n}`\",\n+                                       if signed {\"i\"} else {\"u\"},\n+                                       n = bits)),\n         },\n         Float(bits) => match (bits, &t.sty) {\n             (32, &ty::TyFloat(ast::TyF32)) |\n@@ -512,5 +515,22 @@ fn match_intrinsic_type_to_type<'tcx, 'a>(\n                                          inner_expected,\n                                          t_ty)\n         }\n+        Aggregate(_flatten, ref expected_contents) => {\n+            match t.sty {\n+                ty::TyTuple(ref contents) => {\n+                    if contents.len() != expected_contents.len() {\n+                        simple_error(&format!(\"tuple with length {}\", contents.len()),\n+                                     &format!(\"tuple with length {}\", expected_contents.len()));\n+                        return\n+                    }\n+                    for (e, c) in expected_contents.iter().zip(contents) {\n+                        match_intrinsic_type_to_type(tcx, position, span, structural_to_nominal,\n+                                                     e, c)\n+                    }\n+                }\n+                _ => simple_error(&format!(\"`{}`\", t),\n+                                  &format!(\"tuple\")),\n+            }\n+        }\n     }\n }"}, {"sha": "ef1f4d6f230b3639026f563c017c1f47d3b4ec04", "filename": "src/test/compile-fail/simd-intrinsic-declaration-type.rs", "status": "modified", "additions": 18, "deletions": 7, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Ftest%2Fcompile-fail%2Fsimd-intrinsic-declaration-type.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2d3e8379c8314ac523197997dd573cfcbaa0a631/src%2Ftest%2Fcompile-fail%2Fsimd-intrinsic-declaration-type.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fsimd-intrinsic-declaration-type.rs?ref=2d3e8379c8314ac523197997dd573cfcbaa0a631", "patch": "@@ -25,27 +25,38 @@ struct f32x4(f32, f32, f32, f32);\n #[repr(simd)]\n struct i64x2(i64, i64);\n \n-// signed vs. unsigned doesn't matter\n-mod i {\n-    use i16x8;\n+// correct signatures work well\n+mod right {\n+    use {i16x8, u16x8};\n     extern \"platform-intrinsic\" {\n         fn x86_mm_adds_epi16(x: i16x8, y: i16x8) -> i16x8;\n+        fn x86_mm_adds_epu16(x: u16x8, y: u16x8) -> u16x8;\n     }\n }\n-mod u {\n-    use u16x8;\n+// but incorrect ones don't.\n+\n+mod signedness {\n+    use {i16x8, u16x8};\n+    // signedness matters\n     extern \"platform-intrinsic\" {\n         fn x86_mm_adds_epi16(x: u16x8, y: u16x8) -> u16x8;\n+        //~^ ERROR intrinsic argument 1 has wrong type\n+        //~^^ ERROR intrinsic argument 2 has wrong type\n+        //~^^^ ERROR intrinsic return value has wrong type\n+        fn x86_mm_adds_epu16(x: i16x8, y: i16x8) -> i16x8;\n+        //~^ ERROR intrinsic argument 1 has wrong type\n+        //~^^ ERROR intrinsic argument 2 has wrong type\n+        //~^^^ ERROR intrinsic return value has wrong type\n     }\n }\n-// but lengths do\n+// as do lengths\n extern \"platform-intrinsic\" {\n     fn x86_mm_adds_epi16(x: i8x16, y: i32x4) -> i64x2;\n     //~^ ERROR intrinsic argument 1 has wrong type\n     //~^^ ERROR intrinsic argument 2 has wrong type\n     //~^^^ ERROR intrinsic return value has wrong type\n }\n-// and so does int vs. float\n+// and so does int vs. float:\n extern \"platform-intrinsic\" {\n     fn x86_mm_max_ps(x: i32x4, y: i32x4) -> i32x4;\n     //~^ ERROR intrinsic argument 1 has wrong type"}]}