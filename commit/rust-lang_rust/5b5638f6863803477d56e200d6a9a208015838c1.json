{"sha": "5b5638f6863803477d56e200d6a9a208015838c1", "node_id": "MDY6Q29tbWl0NzI0NzEyOjViNTYzOGY2ODYzODAzNDc3ZDU2ZTIwMGQ2YTlhMjA4MDE1ODM4YzE=", "commit": {"author": {"name": "Huon Wilson", "email": "dbau.pp+github@gmail.com", "date": "2014-11-18T23:17:40Z"}, "committer": {"name": "Huon Wilson", "email": "dbau.pp+github@gmail.com", "date": "2014-11-19T01:52:31Z"}, "message": "Switch to an independent enum for `Lit*` subtokens.", "tree": {"sha": "2416a92209706f29f9bb81c4becf35c7177adc4f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2416a92209706f29f9bb81c4becf35c7177adc4f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5b5638f6863803477d56e200d6a9a208015838c1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5b5638f6863803477d56e200d6a9a208015838c1", "html_url": "https://github.com/rust-lang/rust/commit/5b5638f6863803477d56e200d6a9a208015838c1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5b5638f6863803477d56e200d6a9a208015838c1/comments", "author": {"login": "huonw", "id": 1203825, "node_id": "MDQ6VXNlcjEyMDM4MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1203825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huonw", "html_url": "https://github.com/huonw", "followers_url": "https://api.github.com/users/huonw/followers", "following_url": "https://api.github.com/users/huonw/following{/other_user}", "gists_url": "https://api.github.com/users/huonw/gists{/gist_id}", "starred_url": "https://api.github.com/users/huonw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huonw/subscriptions", "organizations_url": "https://api.github.com/users/huonw/orgs", "repos_url": "https://api.github.com/users/huonw/repos", "events_url": "https://api.github.com/users/huonw/events{/privacy}", "received_events_url": "https://api.github.com/users/huonw/received_events", "type": "User", "site_admin": false}, "committer": {"login": "huonw", "id": 1203825, "node_id": "MDQ6VXNlcjEyMDM4MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1203825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huonw", "html_url": "https://github.com/huonw", "followers_url": "https://api.github.com/users/huonw/followers", "following_url": "https://api.github.com/users/huonw/following{/other_user}", "gists_url": "https://api.github.com/users/huonw/gists{/gist_id}", "starred_url": "https://api.github.com/users/huonw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huonw/subscriptions", "organizations_url": "https://api.github.com/users/huonw/orgs", "repos_url": "https://api.github.com/users/huonw/repos", "events_url": "https://api.github.com/users/huonw/events{/privacy}", "received_events_url": "https://api.github.com/users/huonw/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c8d6e3b2c2a780eff92299da5d1c02e081617088", "url": "https://api.github.com/repos/rust-lang/rust/commits/c8d6e3b2c2a780eff92299da5d1c02e081617088", "html_url": "https://github.com/rust-lang/rust/commit/c8d6e3b2c2a780eff92299da5d1c02e081617088"}], "stats": {"total": 233, "additions": 115, "deletions": 118}, "files": [{"sha": "84a288ef042d00524884a30194e9c0e70c3a38f2", "filename": "src/grammar/verify.rs", "status": "modified", "additions": 26, "deletions": 24, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Fgrammar%2Fverify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Fgrammar%2Fverify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fgrammar%2Fverify.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -61,7 +61,7 @@ fn parse_token_list(file: &str) -> HashMap<String, Token> {\n             \"SHL\"               => token::BinOp(token::Shl),\n             \"LBRACE\"            => token::OpenDelim(token::Brace),\n             \"RARROW\"            => token::Rarrow,\n-            \"LIT_STR\"           => token::LitStr(Name(0)),\n+            \"LIT_STR\"           => token::Literal(token::Str_(Name(0))),\n             \"DOTDOT\"            => token::DotDot,\n             \"MOD_SEP\"           => token::ModSep,\n             \"DOTDOTDOT\"         => token::DotDotDot,\n@@ -71,7 +71,7 @@ fn parse_token_list(file: &str) -> HashMap<String, Token> {\n             \"ANDAND\"            => token::AndAnd,\n             \"AT\"                => token::At,\n             \"LBRACKET\"          => token::OpenDelim(token::Bracket),\n-            \"LIT_STR_RAW\"       => token::LitStrRaw(Name(0), 0),\n+            \"LIT_STR_RAW\"       => token::Literal(token::StrRaw(Name(0), 0)),\n             \"RPAREN\"            => token::CloseDelim(token::Paren),\n             \"SLASH\"             => token::BinOp(token::Slash),\n             \"COMMA\"             => token::Comma,\n@@ -80,8 +80,8 @@ fn parse_token_list(file: &str) -> HashMap<String, Token> {\n             \"TILDE\"             => token::Tilde,\n             \"IDENT\"             => token::Id(),\n             \"PLUS\"              => token::BinOp(token::Plus),\n-            \"LIT_CHAR\"          => token::LitChar(Name(0)),\n-            \"LIT_BYTE\"          => token::LitByte(Name(0)),\n+            \"LIT_CHAR\"          => token::Literal(token::Char(Name(0))),\n+            \"LIT_BYTE\"          => token::Literal(token::Byte(Name(0))),\n             \"EQ\"                => token::Eq,\n             \"RBRACKET\"          => token::CloseDelim(token::Bracket),\n             \"COMMENT\"           => token::Comment,\n@@ -95,9 +95,9 @@ fn parse_token_list(file: &str) -> HashMap<String, Token> {\n             \"BINOP\"             => token::BinOp(token::Plus),\n             \"POUND\"             => token::Pound,\n             \"OROR\"              => token::OrOr,\n-            \"LIT_INTEGER\"       => token::LitInteger(Name(0)),\n+            \"LIT_INTEGER\"       => token::Literal(token::Integer(Name(0))),\n             \"BINOPEQ\"           => token::BinOpEq(token::Plus),\n-            \"LIT_FLOAT\"         => token::LitFloat(Name(0)),\n+            \"LIT_FLOAT\"         => token::Literal(token::Float(Name(0))),\n             \"WHITESPACE\"        => token::Whitespace,\n             \"UNDERSCORE\"        => token::Underscore,\n             \"MINUS\"             => token::BinOp(token::Minus),\n@@ -107,8 +107,8 @@ fn parse_token_list(file: &str) -> HashMap<String, Token> {\n             \"OR\"                => token::BinOp(token::Or),\n             \"GT\"                => token::Gt,\n             \"LE\"                => token::Le,\n-            \"LIT_BINARY\"        => token::LitBinary(Name(0)),\n-            \"LIT_BINARY_RAW\"    => token::LitBinaryRaw(Name(0), 0),\n+            \"LIT_BINARY\"        => token::Literal(token::Binary(Name(0))),\n+            \"LIT_BINARY_RAW\"    => token::Literal(token::BinaryRaw(Name(0), 0)),\n             _                   => continue,\n         };\n \n@@ -189,15 +189,17 @@ fn parse_antlr_token(s: &str, tokens: &HashMap<String, Token>) -> TokenAndSpan {\n         token::BinOp(..)           => token::BinOp(str_to_binop(content)),\n         token::BinOpEq(..)         => token::BinOpEq(str_to_binop(content.slice_to(\n                                                                     content.len() - 1))),\n-        token::LitStr(..)          => token::LitStr(fix(content)),\n-        token::LitStrRaw(..)       => token::LitStrRaw(fix(content), count(content)),\n-        token::LitChar(..)         => token::LitChar(fixchar(content)),\n-        token::LitByte(..)         => token::LitByte(fixchar(content)),\n+        token::Literal(token::Str_(..))      => token::Literal(token::Str_(fix(content))),\n+        token::Literal(token::StrRaw(..))    => token::Literal(token::StrRaw(fix(content),\n+                                                                             count(content))),\n+        token::Literal(token::Char(..))      => token::Literal(token::Char(fixchar(content))),\n+        token::Literal(token::Byte(..))      => token::Literal(token::Byte(fixchar(content))),\n         token::DocComment(..)      => token::DocComment(nm),\n-        token::LitInteger(..)      => token::LitInteger(nm),\n-        token::LitFloat(..)        => token::LitFloat(nm),\n-        token::LitBinary(..)       => token::LitBinary(nm),\n-        token::LitBinaryRaw(..)    => token::LitBinaryRaw(fix(content), count(content)),\n+        token::Literal(token::Integer(..))   => token::Literal(token::Integer(nm)),\n+        token::Literal(token::Float(..))     => token::Literal(token::Float(nm)),\n+        token::Literal(token::Binary(..))    => token::Literal(token::Binary(nm)),\n+        token::Literal(token::BinaryRaw(..)) => token::Literal(token::BinaryRaw(fix(content),\n+                                                                                count(content))),\n         token::Ident(..)           => token::Ident(ast::Ident { name: nm, ctxt: 0 },\n                                                    token::ModName),\n         token::Lifetime(..)        => token::Lifetime(ast::Ident { name: nm, ctxt: 0 }),\n@@ -284,14 +286,14 @@ fn main() {\n         )\n \n         matches!(\n-            LitByte(..),\n-            LitChar(..),\n-            LitInteger(..),\n-            LitFloat(..),\n-            LitStr(..),\n-            LitStrRaw(..),\n-            LitBinary(..),\n-            LitBinaryRaw(..),\n+            token::Literal(token::Byte(..)),\n+            token::Literal(token::Char(..)),\n+            token::Literal(token::Integer(..)),\n+            token::Literal(token::Float(..)),\n+            token::Literal(token::Str_(..)),\n+            token::Literal(token::StrRaw(..)),\n+            token::Literal(token::Binary(..)),\n+            token::Literal(token::BinaryRaw(..)),\n             Ident(..),\n             Lifetime(..),\n             Interpolated(..),"}, {"sha": "527ef553d99e53f6c59bb5ae4ecd1182402c1382", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -129,11 +129,12 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader,\n             }\n \n             // text literals\n-            token::LitByte(..) | token::LitBinary(..) | token::LitBinaryRaw(..) |\n-                token::LitChar(..) | token::LitStr(..) | token::LitStrRaw(..) => \"string\",\n+            token::Literal(token::Byte(..)) | token::Literal(token::Char(..)) |\n+                token::Literal(token::Binary(..)) | token::Literal(token::BinaryRaw(..)) |\n+                token::Literal(token::Str_(..)) | token::Literal(token::StrRaw(..)) => \"string\",\n \n             // number literals\n-            token::LitInteger(..) | token::LitFloat(..) => \"number\",\n+            token::Literal(token::Integer(..)) | token::Literal(token::Float(..)) => \"number\",\n \n             // keywords are also included in the identifier set\n             token::Ident(ident, _is_mod_sep) => {"}, {"sha": "2158bdb416c7e09cc349e5342abf55215243c935", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -838,7 +838,7 @@ impl TokenTree {\n                     tts: vec![TtToken(sp, token::Ident(token::str_to_ident(\"doc\"),\n                                                        token::Plain)),\n                               TtToken(sp, token::Eq),\n-                              TtToken(sp, token::LitStr(name))],\n+                              TtToken(sp, token::Literal(token::Str_(name)))],\n                     close_span: sp,\n                 }))\n             }"}, {"sha": "b928fc778e8bc394d3a5b30fec743c6f42fbb79c", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -87,7 +87,7 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt,\n         },\n         [ast::TtToken(_, token::Ident(ref code, _)),\n          ast::TtToken(_, token::Comma),\n-         ast::TtToken(_, token::LitStrRaw(description, _))] => {\n+         ast::TtToken(_, token::Literal(token::StrRaw(description, _)))] => {\n             (code, Some(description))\n         }\n         _ => unreachable!()"}, {"sha": "ec51ce00605fdea4fc6feb30a79887e5297162be", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 19, "deletions": 18, "changes": 37, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -542,6 +542,13 @@ fn mk_delim(cx: &ExtCtxt, sp: Span, delim: token::DelimToken) -> P<ast::Expr> {\n \n #[allow(non_upper_case_globals)]\n fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n+    macro_rules! mk_lit {\n+        ($name: expr, $($args: expr),*) => {{\n+            let inner = cx.expr_call(sp, mk_token_path(cx, sp, $name), vec![$($args),*]);\n+\n+            cx.expr_call(sp, mk_token_path(cx, sp, \"Literal\"), vec![inner])\n+        }}\n+    }\n     match *tok {\n         token::BinOp(binop) => {\n             return cx.expr_call(sp, mk_token_path(cx, sp, \"BinOp\"), vec!(mk_binop(cx, sp, binop)));\n@@ -560,38 +567,32 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n                                 vec![mk_delim(cx, sp, delim)]);\n         }\n \n-        token::LitByte(i) => {\n+        token::Literal(token::Byte(i)) => {\n             let e_byte = mk_name(cx, sp, i.ident());\n-\n-            return cx.expr_call(sp, mk_token_path(cx, sp, \"LitByte\"), vec!(e_byte));\n+            return mk_lit!(\"Byte\", e_byte);\n         }\n \n-        token::LitChar(i) => {\n+        token::Literal(token::Char(i)) => {\n             let e_char = mk_name(cx, sp, i.ident());\n-\n-            return cx.expr_call(sp, mk_token_path(cx, sp, \"LitChar\"), vec!(e_char));\n+            return mk_lit!(\"Char\", e_char);\n         }\n \n-        token::LitInteger(i) => {\n+        token::Literal(token::Integer(i)) => {\n             let e_int = mk_name(cx, sp, i.ident());\n-            return cx.expr_call(sp, mk_token_path(cx, sp, \"LitInteger\"), vec!(e_int));\n+            return mk_lit!(\"Integer\", e_int);\n         }\n \n-        token::LitFloat(fident) => {\n+        token::Literal(token::Float(fident)) => {\n             let e_fident = mk_name(cx, sp, fident.ident());\n-            return cx.expr_call(sp, mk_token_path(cx, sp, \"LitFloat\"), vec!(e_fident));\n+            return mk_lit!(\"Float\", e_fident);\n         }\n \n-        token::LitStr(ident) => {\n-            return cx.expr_call(sp,\n-                                mk_token_path(cx, sp, \"LitStr\"),\n-                                vec!(mk_name(cx, sp, ident.ident())));\n+        token::Literal(token::Str_(ident)) => {\n+            return mk_lit!(\"Str_\", mk_name(cx, sp, ident.ident()))\n         }\n \n-        token::LitStrRaw(ident, n) => {\n-            return cx.expr_call(sp,\n-                                mk_token_path(cx, sp, \"LitStrRaw\"),\n-                                vec!(mk_name(cx, sp, ident.ident()), cx.expr_uint(sp, n)));\n+        token::Literal(token::StrRaw(ident, n)) => {\n+            return mk_lit!(\"StrRaw\", mk_name(cx, sp, ident.ident()), cx.expr_uint(sp, n))\n         }\n \n         token::Ident(ident, style) => {"}, {"sha": "b7598c7c428201c4fddf429568403325f7bfacd7", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 21, "deletions": 20, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -655,17 +655,17 @@ impl<'a> StringReader<'a> {\n                 }\n                 'u' | 'i' => {\n                     self.scan_int_suffix();\n-                    return token::LitInteger(self.name_from(start_bpos));\n+                    return token::Literal(token::Integer(self.name_from(start_bpos)));\n                 },\n                 'f' => {\n                     let last_pos = self.last_pos;\n                     self.scan_float_suffix();\n                     self.check_float_base(start_bpos, last_pos, base);\n-                    return token::LitFloat(self.name_from(start_bpos));\n+                    return token::Literal(token::Float(self.name_from(start_bpos)));\n                 }\n                 _ => {\n                     // just a 0\n-                    return token::LitInteger(self.name_from(start_bpos));\n+                    return token::Literal(token::Integer(self.name_from(start_bpos)));\n                 }\n             }\n         } else if c.is_digit_radix(10) {\n@@ -678,7 +678,7 @@ impl<'a> StringReader<'a> {\n             self.err_span_(start_bpos, self.last_pos, \"no valid digits found for number\");\n             // eat any suffix\n             self.scan_int_suffix();\n-            return token::LitInteger(token::intern(\"0\"));\n+            return token::Literal(token::Integer(token::intern(\"0\")));\n         }\n \n         // might be a float, but don't be greedy if this is actually an\n@@ -696,25 +696,25 @@ impl<'a> StringReader<'a> {\n             }\n             let last_pos = self.last_pos;\n             self.check_float_base(start_bpos, last_pos, base);\n-            return token::LitFloat(self.name_from(start_bpos));\n+            return token::Literal(token::Float(self.name_from(start_bpos)));\n         } else if self.curr_is('f') {\n             // or it might be an integer literal suffixed as a float\n             self.scan_float_suffix();\n             let last_pos = self.last_pos;\n             self.check_float_base(start_bpos, last_pos, base);\n-            return token::LitFloat(self.name_from(start_bpos));\n+            return token::Literal(token::Float(self.name_from(start_bpos)));\n         } else {\n             // it might be a float if it has an exponent\n             if self.curr_is('e') || self.curr_is('E') {\n                 self.scan_float_exponent();\n                 self.scan_float_suffix();\n                 let last_pos = self.last_pos;\n                 self.check_float_base(start_bpos, last_pos, base);\n-                return token::LitFloat(self.name_from(start_bpos));\n+                return token::Literal(token::Float(self.name_from(start_bpos)));\n             }\n             // but we certainly have an integer!\n             self.scan_int_suffix();\n-            return token::LitInteger(self.name_from(start_bpos));\n+            return token::Literal(token::Integer(self.name_from(start_bpos)));\n         }\n     }\n \n@@ -1126,7 +1126,7 @@ impl<'a> StringReader<'a> {\n             }\n             let id = if valid { self.name_from(start) } else { token::intern(\"0\") };\n             self.bump(); // advance curr past token\n-            return token::LitChar(id);\n+            return token::Literal(token::Char(id));\n           }\n           'b' => {\n             self.bump();\n@@ -1157,7 +1157,7 @@ impl<'a> StringReader<'a> {\n             let id = if valid { self.name_from(start_bpos + BytePos(1)) }\n                      else { token::intern(\"??\") };\n             self.bump();\n-            return token::LitStr(id);\n+            return token::Literal(token::Str_(id));\n           }\n           'r' => {\n             let start_bpos = self.last_pos;\n@@ -1224,7 +1224,7 @@ impl<'a> StringReader<'a> {\n             } else {\n                 token::intern(\"??\")\n             };\n-            return token::LitStrRaw(id, hash_count);\n+            return token::Literal(token::StrRaw(id, hash_count));\n           }\n           '-' => {\n             if self.nextch_is('>') {\n@@ -1314,7 +1314,7 @@ impl<'a> StringReader<'a> {\n \n         let id = if valid { self.name_from(start) } else { token::intern(\"??\") };\n         self.bump(); // advance curr past token\n-        return token::LitByte(id);\n+        return token::Literal(token::Byte(id));\n     }\n \n     fn scan_byte_string(&mut self) -> token::Token {\n@@ -1336,7 +1336,7 @@ impl<'a> StringReader<'a> {\n         }\n         let id = if valid { self.name_from(start) } else { token::intern(\"??\") };\n         self.bump();\n-        return token::LitBinary(id);\n+        return token::Literal(token::Binary(id));\n     }\n \n     fn scan_raw_byte_string(&mut self) -> token::Token {\n@@ -1387,8 +1387,9 @@ impl<'a> StringReader<'a> {\n             self.bump();\n         }\n         self.bump();\n-        return token::LitBinaryRaw(self.name_from_to(content_start_bpos, content_end_bpos),\n-                                     hash_count);\n+        return token::Literal(token::BinaryRaw(self.name_from_to(content_start_bpos,\n+                                                                 content_end_bpos),\n+                                               hash_count));\n     }\n }\n \n@@ -1535,17 +1536,17 @@ mod test {\n \n     #[test] fn character_a() {\n         assert_eq!(setup(&mk_sh(), \"'a'\".to_string()).next_token().tok,\n-                   token::LitChar(token::intern(\"a\")));\n+                   token::Literal(token::Char(token::intern(\"a\"))));\n     }\n \n     #[test] fn character_space() {\n         assert_eq!(setup(&mk_sh(), \"' '\".to_string()).next_token().tok,\n-                   token::LitChar(token::intern(\" \")));\n+                   token::Literal(token::Char(token::intern(\" \"))));\n     }\n \n     #[test] fn character_escaped() {\n         assert_eq!(setup(&mk_sh(), \"'\\\\n'\".to_string()).next_token().tok,\n-                   token::LitChar(token::intern(\"\\\\n\")));\n+                   token::Literal(token::Char(token::intern(\"\\\\n\"))));\n     }\n \n     #[test] fn lifetime_name() {\n@@ -1557,7 +1558,7 @@ mod test {\n         assert_eq!(setup(&mk_sh(),\n                          \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string()).next_token()\n                                                                  .tok,\n-                   token::LitStrRaw(token::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3));\n+                   token::Literal(token::StrRaw(token::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3)));\n     }\n \n     #[test] fn line_doc_comments() {\n@@ -1573,7 +1574,7 @@ mod test {\n             token::Comment => { },\n             _ => panic!(\"expected a comment!\")\n         }\n-        assert_eq!(lexer.next_token().tok, token::LitChar(token::intern(\"a\")));\n+        assert_eq!(lexer.next_token().tok, token::Literal(token::Char(token::intern(\"a\"))));\n     }\n \n }"}, {"sha": "4edcb182e5385efcfd466914ee4ab42ab4d82650", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -1640,23 +1640,23 @@ impl<'a> Parser<'a> {\n     /// Matches token_lit = LIT_INTEGER | ...\n     pub fn lit_from_token(&mut self, tok: &token::Token) -> Lit_ {\n         match *tok {\n-            token::LitByte(i) => LitByte(parse::byte_lit(i.as_str()).val0()),\n-            token::LitChar(i) => LitChar(parse::char_lit(i.as_str()).val0()),\n-            token::LitInteger(s) => parse::integer_lit(s.as_str(),\n+            token::Literal(token::Byte(i)) => LitByte(parse::byte_lit(i.as_str()).val0()),\n+            token::Literal(token::Char(i)) => LitChar(parse::char_lit(i.as_str()).val0()),\n+            token::Literal(token::Integer(s)) => parse::integer_lit(s.as_str(),\n                                                         &self.sess.span_diagnostic,\n                                                        self.last_span),\n-            token::LitFloat(s) => parse::float_lit(s.as_str()),\n-            token::LitStr(s) => {\n+            token::Literal(token::Float(s)) => parse::float_lit(s.as_str()),\n+            token::Literal(token::Str_(s)) => {\n                 LitStr(token::intern_and_get_ident(parse::str_lit(s.as_str()).as_slice()),\n                        ast::CookedStr)\n             }\n-            token::LitStrRaw(s, n) => {\n+            token::Literal(token::StrRaw(s, n)) => {\n                 LitStr(token::intern_and_get_ident(parse::raw_str_lit(s.as_str()).as_slice()),\n                        ast::RawStr(n))\n             }\n-            token::LitBinary(i) =>\n+            token::Literal(token::Binary(i)) =>\n                 LitBinary(parse::binary_lit(i.as_str())),\n-            token::LitBinaryRaw(i, _) =>\n+            token::Literal(token::BinaryRaw(i, _)) =>\n                 LitBinary(Rc::new(i.as_str().as_bytes().iter().map(|&x| x).collect())),\n             _ => { self.unexpected_last(tok); }\n         }\n@@ -2424,7 +2424,7 @@ impl<'a> Parser<'a> {\n                         }\n                     }\n                   }\n-                  token::LitInteger(n) => {\n+                  token::Literal(token::Integer(n)) => {\n                     let index = n.as_str();\n                     let dot = self.last_span.hi;\n                     hi = self.span.hi;\n@@ -2449,7 +2449,7 @@ impl<'a> Parser<'a> {\n                         }\n                     }\n                   }\n-                  token::LitFloat(n) => {\n+                  token::Literal(token::Float(n)) => {\n                     self.bump();\n                     let last_span = self.last_span;\n                     let fstr = n.as_str();\n@@ -5085,7 +5085,7 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::Semi);\n                 (path, the_ident)\n             },\n-            token::LitStr(..) | token::LitStrRaw(..) => {\n+            token::Literal(token::Str_(..)) | token::Literal(token::StrRaw(..)) => {\n                 let path = self.parse_str();\n                 self.expect_keyword(keywords::As);\n                 let the_ident = self.parse_ident();\n@@ -5267,7 +5267,7 @@ impl<'a> Parser<'a> {\n     /// the `extern` keyword, if one is found.\n     fn parse_opt_abi(&mut self) -> Option<abi::Abi> {\n         match self.token {\n-            token::LitStr(s) | token::LitStrRaw(s, _) => {\n+            token::Literal(token::Str_(s)) | token::Literal(token::StrRaw(s, _)) => {\n                 self.bump();\n                 let the_string = s.as_str();\n                 match abi::lookup(the_string) {\n@@ -5904,8 +5904,8 @@ impl<'a> Parser<'a> {\n     pub fn parse_optional_str(&mut self)\n                               -> Option<(InternedString, ast::StrStyle)> {\n         let (s, style) = match self.token {\n-            token::LitStr(s) => (self.id_to_interned_str(s.ident()), ast::CookedStr),\n-            token::LitStrRaw(s, n) => {\n+            token::Literal(token::Str_(s)) => (self.id_to_interned_str(s.ident()), ast::CookedStr),\n+            token::Literal(token::StrRaw(s, n)) => {\n                 (self.id_to_interned_str(s.ident()), ast::RawStr(n))\n             }\n             _ => return None"}, {"sha": "bfa6ca798b2333d79cb53e09c12e110f8f8cfe8e", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 17, "deletions": 25, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -12,6 +12,7 @@ pub use self::BinOpToken::*;\n pub use self::Nonterminal::*;\n pub use self::DelimToken::*;\n pub use self::IdentStyle::*;\n+pub use self::Lit::*;\n pub use self::Token::*;\n \n use ast;\n@@ -59,6 +60,18 @@ pub enum IdentStyle {\n     Plain,\n }\n \n+#[deriving(Clone, Encodable, Decodable, PartialEq, Eq, Hash, Show)]\n+pub enum Lit {\n+    Byte(ast::Name),\n+    Char(ast::Name),\n+    Integer(ast::Name),\n+    Float(ast::Name),\n+    Str_(ast::Name),\n+    StrRaw(ast::Name, uint), /* raw str delimited by n hash symbols */\n+    Binary(ast::Name),\n+    BinaryRaw(ast::Name, uint), /* raw binary str delimited by n hash symbols */\n+}\n+\n #[allow(non_camel_case_types)]\n #[deriving(Clone, Encodable, Decodable, PartialEq, Eq, Hash, Show)]\n pub enum Token {\n@@ -98,14 +111,7 @@ pub enum Token {\n     CloseDelim(DelimToken),\n \n     /* Literals */\n-    LitByte(ast::Name),\n-    LitChar(ast::Name),\n-    LitInteger(ast::Name),\n-    LitFloat(ast::Name),\n-    LitStr(ast::Name),\n-    LitStrRaw(ast::Name, uint), /* raw str delimited by n hash symbols */\n-    LitBinary(ast::Name),\n-    LitBinaryRaw(ast::Name, uint), /* raw binary str delimited by n hash symbols */\n+    Literal(Lit),\n \n     /* Name components */\n     Ident(ast::Ident, IdentStyle),\n@@ -145,14 +151,7 @@ impl Token {\n             Ident(_, _)                 => true,\n             Underscore                  => true,\n             Tilde                       => true,\n-            LitByte(_)                  => true,\n-            LitChar(_)                  => true,\n-            LitInteger(_)               => true,\n-            LitFloat(_)                 => true,\n-            LitStr(_)                   => true,\n-            LitStrRaw(_, _)             => true,\n-            LitBinary(_)                => true,\n-            LitBinaryRaw(_, _)          => true,\n+            Literal(_)                  => true,\n             Pound                       => true,\n             At                          => true,\n             Not                         => true,\n@@ -173,15 +172,8 @@ impl Token {\n     /// Returns `true` if the token is any literal\n     pub fn is_lit(&self) -> bool {\n         match *self {\n-            LitByte(_)          => true,\n-            LitChar(_)          => true,\n-            LitInteger(_)       => true,\n-            LitFloat(_)         => true,\n-            LitStr(_)           => true,\n-            LitStrRaw(_, _)     => true,\n-            LitBinary(_)        => true,\n-            LitBinaryRaw(_, _)  => true,\n-            _                   => false,\n+            Literal(_) => true,\n+            _          => false,\n         }\n     }\n "}, {"sha": "7997c1ba4efcfde1cda86fa190c9b5cdca9c1d3a", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5b5638f6863803477d56e200d6a9a208015838c1/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=5b5638f6863803477d56e200d6a9a208015838c1", "patch": "@@ -236,18 +236,18 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::Question             => \"?\".into_string(),\n \n         /* Literals */\n-        token::LitByte(b)           => format!(\"b'{}'\", b.as_str()),\n-        token::LitChar(c)           => format!(\"'{}'\", c.as_str()),\n-        token::LitFloat(c)          => c.as_str().into_string(),\n-        token::LitInteger(c)        => c.as_str().into_string(),\n-        token::LitStr(s)            => format!(\"\\\"{}\\\"\", s.as_str()),\n-        token::LitStrRaw(s, n)      => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n-                                               delim=\"#\".repeat(n),\n-                                               string=s.as_str()),\n-        token::LitBinary(v)         => format!(\"b\\\"{}\\\"\", v.as_str()),\n-        token::LitBinaryRaw(s, n)   => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n-                                               delim=\"#\".repeat(n),\n-                                               string=s.as_str()),\n+        token::Literal(token::Byte(b))           => format!(\"b'{}'\", b.as_str()),\n+        token::Literal(token::Char(c))           => format!(\"'{}'\", c.as_str()),\n+        token::Literal(token::Float(c))          => c.as_str().into_string(),\n+        token::Literal(token::Integer(c))        => c.as_str().into_string(),\n+        token::Literal(token::Str_(s))           => format!(\"\\\"{}\\\"\", s.as_str()),\n+        token::Literal(token::StrRaw(s, n))      => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n+                                                            delim=\"#\".repeat(n),\n+                                                            string=s.as_str()),\n+        token::Literal(token::Binary(v))         => format!(\"b\\\"{}\\\"\", v.as_str()),\n+        token::Literal(token::BinaryRaw(s, n))   => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n+                                                            delim=\"#\".repeat(n),\n+                                                            string=s.as_str()),\n \n         /* Name components */\n         token::Ident(s, _)          => token::get_ident(s).get().into_string(),"}]}