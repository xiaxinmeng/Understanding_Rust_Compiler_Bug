{"sha": "f622f45afdd7688e19d511799e978c1c66889fb4", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY2MjJmNDVhZmRkNzY4OGUxOWQ1MTE3OTllOTc4YzFjNjY4ODlmYjQ=", "commit": {"author": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2020-07-24T07:01:07Z"}, "committer": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2020-07-26T22:37:03Z"}, "message": "Share serialization optimization between incr and metadata", "tree": {"sha": "a1d0110cb7a78c87e81a7db1cb97af349eb0bd00", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a1d0110cb7a78c87e81a7db1cb97af349eb0bd00"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f622f45afdd7688e19d511799e978c1c66889fb4", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE7J9Gc3TfBwj2K399tAh+UQ6YsWQFAl8eBY8ACgkQtAh+UQ6Y\nsWQc6xAAkBKEe9gZ4hIWaPwUuqdP8g8n6gTuP03UgdiuXRbmpQV6NCdhrCevR6Xj\navUfZ1veXYrTdGZOKLVRWU7dYJ97JRz4/HsgOog2WU6FpR2TVkF680WRhk5WxdfX\nH6KSe5uDrFj7LQo7BSkPBEHVVQoKkmExziPsi0S+09E9afkvJTEN90HdElD3LEkG\nJFHA/72DZ3+mz5ogF9h5+ryFIwntHAqLKhLUJ3tIDwYOXv0KrZBs/WPoI0pYeOXf\nZQvyR98lxSU0HswzoEixkiqEwF5o2f9VZPOkKcVbI3S6Pbh00RNcLNaMR+r+egSy\nRBUrDs3557772M/343ChIzy8bKkgmYDzQKqs13mp2be+qKhNYMm26G+CJYl2uFjL\neKlDJnPV1meCYk9m8L+Up0Pra0LkdMQk2P8QWgEFu7CXPrVtJfbnElKIS8Tqnp71\n4BjKBcu618u+w2kmv0xOzHBGQNF/rR0SLlvbBBFmdYMFBvGE5DfUjbEI3FZ+S2Ro\n0v5PuQ8//YBtfpOcs1wG9CI/pKnNqfhXbALnSl/dQQqCkEjFaK1cPVCONe5j9u/E\n41M77++u784NE3t/boT8vqHjoSYRvhY7n6NNIsrBWDzfuYRpFRHyXOL1vGsHqvwK\n19kGg/slHavN5KVUooNkucja6srtZhAxc26umCN85vgD39ePi0Q=\n=JQXI\n-----END PGP SIGNATURE-----", "payload": "tree a1d0110cb7a78c87e81a7db1cb97af349eb0bd00\nparent cf7bef302abb0fc7ab8bf40f22c3bc3a6aca68ff\nauthor Aaron Hill <aa1ronham@gmail.com> 1595574067 -0400\ncommitter Aaron Hill <aa1ronham@gmail.com> 1595803023 -0400\n\nShare serialization optimization between incr and metadata\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f622f45afdd7688e19d511799e978c1c66889fb4", "html_url": "https://github.com/rust-lang/rust/commit/f622f45afdd7688e19d511799e978c1c66889fb4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f622f45afdd7688e19d511799e978c1c66889fb4/comments", "author": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "cf7bef302abb0fc7ab8bf40f22c3bc3a6aca68ff", "url": "https://api.github.com/repos/rust-lang/rust/commits/cf7bef302abb0fc7ab8bf40f22c3bc3a6aca68ff", "html_url": "https://github.com/rust-lang/rust/commit/cf7bef302abb0fc7ab8bf40f22c3bc3a6aca68ff"}], "stats": {"total": 376, "additions": 198, "deletions": 178}, "files": [{"sha": "df4bb2502cbebcaaef99932e391d0185ec297fdd", "filename": "src/librustc_metadata/rmeta/decoder.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fdecoder.rs?ref=f622f45afdd7688e19d511799e978c1c66889fb4", "patch": "@@ -46,7 +46,7 @@ use std::num::NonZeroUsize;\n use std::path::Path;\n \n pub use cstore_impl::{provide, provide_extern};\n-use rustc_span::hygiene::HygieneContext;\n+use rustc_span::hygiene::HygieneDecodeContext;\n \n mod cstore_impl;\n \n@@ -111,10 +111,10 @@ crate struct CrateMetadata {\n \n     /// Additional data used for decoding `HygieneData` (e.g. `SyntaxContext`\n     /// and `ExpnId`).\n-    /// Note that we store a `HygieneContext` for each `CrateMetadat`. This is\n+    /// Note that we store a `HygieneDecodeContext` for each `CrateMetadat`. This is\n     /// because `SyntaxContext` ids are not globally unique, so we need\n     /// to track which ids we've decoded on a per-crate basis.\n-    hygiene_context: HygieneContext,\n+    hygiene_context: HygieneDecodeContext,\n \n     // --- Data used only for improving diagnostics ---\n     /// Information about the `extern crate` item or path that caused this crate to be loaded.\n@@ -1671,7 +1671,7 @@ impl CrateMetadata {\n             private_dep,\n             host_hash,\n             extern_crate: Lock::new(None),\n-            hygiene_context: HygieneContext::new(),\n+            hygiene_context: Default::default(),\n         }\n     }\n "}, {"sha": "dc8d14a44f806ee06ff01cc92a46d9a8d3a4d9ea", "filename": "src/librustc_metadata/rmeta/encoder.rs", "status": "modified", "additions": 50, "deletions": 110, "changes": 160, "blob_url": "https://github.com/rust-lang/rust/blob/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Frmeta%2Fencoder.rs?ref=f622f45afdd7688e19d511799e978c1c66889fb4", "patch": "@@ -30,7 +30,7 @@ use rustc_middle::ty::codec::{self as ty_codec, TyEncoder};\n use rustc_middle::ty::{self, SymbolName, Ty, TyCtxt};\n use rustc_serialize::{opaque, Encodable, Encoder, SpecializedEncoder, UseSpecializedEncodable};\n use rustc_session::config::CrateType;\n-use rustc_span::hygiene::ExpnDataEncodeMode;\n+use rustc_span::hygiene::{ExpnDataEncodeMode, HygieneEncodeContext};\n use rustc_span::source_map::Spanned;\n use rustc_span::symbol::{sym, Ident, Symbol};\n use rustc_span::{self, ExternalSource, FileName, SourceFile, Span, SyntaxContext};\n@@ -39,7 +39,7 @@ use std::hash::Hash;\n use std::num::NonZeroUsize;\n use std::path::Path;\n \n-struct EncodeContext<'tcx> {\n+struct EncodeContext<'a, 'tcx> {\n     opaque: opaque::Encoder,\n     tcx: TyCtxt<'tcx>,\n \n@@ -67,15 +67,7 @@ struct EncodeContext<'tcx> {\n     // with a result containing a foreign `Span`.\n     required_source_files: Option<GrowableBitSet<usize>>,\n     is_proc_macro: bool,\n-    /// All `SyntaxContexts` for which we have writen `SyntaxContextData` into crate metadata.\n-    /// This is `None` after we finish encoding `SyntaxContexts`, to ensure\n-    /// that we don't accidentally try to encode any more `SyntaxContexts`\n-    serialized_ctxts: Option<FxHashSet<SyntaxContext>>,\n-    /// The `SyntaxContexts` that we have serialized (e.g. as a result of encoding `Spans`)\n-    /// in the most recent 'round' of serializnig. Serializing `SyntaxContextData`\n-    /// may cause us to serialize more `SyntaxContext`s, so serialize in a loop\n-    /// until we reach a fixed point.\n-    latest_ctxts: Option<FxHashSet<SyntaxContext>>,\n+    hygiene_ctxt: &'a HygieneEncodeContext,\n }\n \n macro_rules! encoder_methods {\n@@ -86,7 +78,7 @@ macro_rules! encoder_methods {\n     }\n }\n \n-impl<'tcx> Encoder for EncodeContext<'tcx> {\n+impl<'a, 'tcx> Encoder for EncodeContext<'a, 'tcx> {\n     type Error = <opaque::Encoder as Encoder>::Error;\n \n     #[inline]\n@@ -117,13 +109,13 @@ impl<'tcx> Encoder for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx, T> SpecializedEncoder<Lazy<T, ()>> for EncodeContext<'tcx> {\n+impl<'a, 'tcx, T> SpecializedEncoder<Lazy<T, ()>> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, lazy: &Lazy<T>) -> Result<(), Self::Error> {\n         self.emit_lazy_distance(*lazy)\n     }\n }\n \n-impl<'tcx, T> SpecializedEncoder<Lazy<[T], usize>> for EncodeContext<'tcx> {\n+impl<'a, 'tcx, T> SpecializedEncoder<Lazy<[T], usize>> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, lazy: &Lazy<[T]>) -> Result<(), Self::Error> {\n         self.emit_usize(lazy.meta)?;\n         if lazy.meta == 0 {\n@@ -133,7 +125,7 @@ impl<'tcx, T> SpecializedEncoder<Lazy<[T], usize>> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx, I: Idx, T> SpecializedEncoder<Lazy<Table<I, T>, usize>> for EncodeContext<'tcx>\n+impl<'a, 'tcx, I: Idx, T> SpecializedEncoder<Lazy<Table<I, T>, usize>> for EncodeContext<'a, 'tcx>\n where\n     Option<T>: FixedSizeEncoding,\n {\n@@ -143,14 +135,14 @@ where\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<CrateNum> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<CrateNum> for EncodeContext<'a, 'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, cnum: &CrateNum) -> Result<(), Self::Error> {\n         self.emit_u32(cnum.as_u32())\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<DefId> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<DefId> for EncodeContext<'a, 'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, def_id: &DefId) -> Result<(), Self::Error> {\n         let DefId { krate, index } = *def_id;\n@@ -160,29 +152,31 @@ impl<'tcx> SpecializedEncoder<DefId> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<SyntaxContext> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<SyntaxContext> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, ctxt: &SyntaxContext) -> Result<(), Self::Error> {\n-        if !self.serialized_ctxts.as_ref().unwrap().contains(ctxt) {\n-            self.latest_ctxts.as_mut().unwrap().insert(*ctxt);\n-        }\n-        rustc_span::hygiene::raw_encode_syntax_context(*ctxt, self)\n+        rustc_span::hygiene::raw_encode_syntax_context(*ctxt, &self.hygiene_ctxt, self)\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<ExpnId> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<ExpnId> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, expn: &ExpnId) -> Result<(), Self::Error> {\n-        rustc_span::hygiene::raw_encode_expn_id(*expn, ExpnDataEncodeMode::Metadata, self)\n+        rustc_span::hygiene::raw_encode_expn_id(\n+            *expn,\n+            &mut self.hygiene_ctxt,\n+            ExpnDataEncodeMode::Metadata,\n+            self,\n+        )\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<DefIndex> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<DefIndex> for EncodeContext<'a, 'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, def_index: &DefIndex) -> Result<(), Self::Error> {\n         self.emit_u32(def_index.as_u32())\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<Span> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<Span> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, span: &Span) -> Result<(), Self::Error> {\n         if span.is_dummy() {\n             return TAG_INVALID_SPAN.encode(self);\n@@ -303,14 +297,14 @@ impl<'tcx> SpecializedEncoder<Span> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<LocalDefId> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<LocalDefId> for EncodeContext<'a, 'tcx> {\n     #[inline]\n     fn specialized_encode(&mut self, def_id: &LocalDefId) -> Result<(), Self::Error> {\n         self.specialized_encode(&def_id.to_def_id())\n     }\n }\n \n-impl<'a, 'b, 'tcx> SpecializedEncoder<&'a ty::TyS<'b>> for EncodeContext<'tcx>\n+impl<'a, 'b, 'c, 'tcx> SpecializedEncoder<&'a ty::TyS<'b>> for EncodeContext<'c, 'tcx>\n where\n     &'a ty::TyS<'b>: UseSpecializedEncodable,\n {\n@@ -321,7 +315,7 @@ where\n     }\n }\n \n-impl<'b, 'tcx> SpecializedEncoder<ty::Predicate<'b>> for EncodeContext<'tcx> {\n+impl<'a, 'b, 'tcx> SpecializedEncoder<ty::Predicate<'b>> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, predicate: &ty::Predicate<'b>) -> Result<(), Self::Error> {\n         debug_assert!(self.tcx.lift(predicate).is_some());\n         let predicate =\n@@ -332,7 +326,7 @@ impl<'b, 'tcx> SpecializedEncoder<ty::Predicate<'b>> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<interpret::AllocId> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<interpret::AllocId> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, alloc_id: &interpret::AllocId) -> Result<(), Self::Error> {\n         use std::collections::hash_map::Entry;\n         let index = match self.interpret_allocs.entry(*alloc_id) {\n@@ -349,13 +343,13 @@ impl<'tcx> SpecializedEncoder<interpret::AllocId> for EncodeContext<'tcx> {\n     }\n }\n \n-impl<'tcx> SpecializedEncoder<Fingerprint> for EncodeContext<'tcx> {\n+impl<'a, 'tcx> SpecializedEncoder<Fingerprint> for EncodeContext<'a, 'tcx> {\n     fn specialized_encode(&mut self, f: &Fingerprint) -> Result<(), Self::Error> {\n         f.encode_opaque(&mut self.opaque)\n     }\n }\n \n-impl<'tcx, T> SpecializedEncoder<mir::ClearCrossCrate<T>> for EncodeContext<'tcx>\n+impl<'a, 'tcx, T> SpecializedEncoder<mir::ClearCrossCrate<T>> for EncodeContext<'a, 'tcx>\n where\n     mir::ClearCrossCrate<T>: UseSpecializedEncodable,\n {\n@@ -364,25 +358,25 @@ where\n     }\n }\n \n-impl<'tcx> TyEncoder for EncodeContext<'tcx> {\n+impl<'a, 'tcx> TyEncoder for EncodeContext<'a, 'tcx> {\n     fn position(&self) -> usize {\n         self.opaque.position()\n     }\n }\n \n /// Helper trait to allow overloading `EncodeContext::lazy` for iterators.\n trait EncodeContentsForLazy<T: ?Sized + LazyMeta> {\n-    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'tcx>) -> T::Meta;\n+    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'a, 'tcx>) -> T::Meta;\n }\n \n impl<T: Encodable> EncodeContentsForLazy<T> for &T {\n-    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'tcx>) {\n+    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'a, 'tcx>) {\n         self.encode(ecx).unwrap()\n     }\n }\n \n impl<T: Encodable> EncodeContentsForLazy<T> for T {\n-    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'tcx>) {\n+    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'a, 'tcx>) {\n         self.encode(ecx).unwrap()\n     }\n }\n@@ -392,7 +386,7 @@ where\n     I: IntoIterator,\n     I::Item: EncodeContentsForLazy<T>,\n {\n-    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'tcx>) -> usize {\n+    fn encode_contents_for_lazy(self, ecx: &mut EncodeContext<'a, 'tcx>) -> usize {\n         self.into_iter().map(|value| value.encode_contents_for_lazy(ecx)).count()\n     }\n }\n@@ -409,7 +403,7 @@ macro_rules! record {\n     }};\n }\n \n-impl<'tcx> EncodeContext<'tcx> {\n+impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n     fn emit_lazy_distance<T: ?Sized + LazyMeta>(\n         &mut self,\n         lazy: Lazy<T>,\n@@ -628,7 +622,7 @@ impl<'tcx> EncodeContext<'tcx> {\n         // Therefore, we need to encode the hygiene data last to ensure that we encode\n         // any `SyntaxContext`s that might be used.\n         i = self.position();\n-        let (syntax_contexts, syntax_bytes, expn_data, expn_bytes) = self.encode_hygiene();\n+        let (syntax_contexts, expn_data) = self.encode_hygiene();\n         let hygiene_bytes = self.position() - i;\n \n         // Encode source_map. This needs to be done last,\n@@ -715,8 +709,6 @@ impl<'tcx> EncodeContext<'tcx> {\n             println!(\"            item bytes: {}\", item_bytes);\n             println!(\"           table bytes: {}\", tables_bytes);\n             println!(\"         hygiene bytes: {}\", hygiene_bytes);\n-            println!(\"   SyntaxContext bytes: {}\", syntax_bytes);\n-            println!(\"          ExpnId bytes: {}\", expn_bytes);\n             println!(\"            zero bytes: {}\", zero_bytes);\n             println!(\"           total bytes: {}\", total_bytes);\n         }\n@@ -725,7 +717,7 @@ impl<'tcx> EncodeContext<'tcx> {\n     }\n }\n \n-impl EncodeContext<'tcx> {\n+impl EncodeContext<'a, 'tcx> {\n     fn encode_variances_of(&mut self, def_id: DefId) {\n         debug!(\"EncodeContext::encode_variances_of({:?})\", def_id);\n         record!(self.tables.variances[def_id] <- &self.tcx.variances_of(def_id)[..]);\n@@ -1499,75 +1491,23 @@ impl EncodeContext<'tcx> {\n         self.lazy(foreign_modules.iter().cloned())\n     }\n \n-    fn encode_hygiene(&mut self) -> (SyntaxContextTable, usize, ExpnDataTable, usize) {\n+    fn encode_hygiene(&mut self) -> (SyntaxContextTable, ExpnDataTable) {\n         let mut syntax_contexts: TableBuilder<_, _> = Default::default();\n         let mut expn_data_table: TableBuilder<_, _> = Default::default();\n \n-        let mut i = self.position();\n-        // We need to encode the `ExpnData` *before* we encode\n-        // the `SyntaxContextData`, since encoding `ExpnData` may cause\n-        // us to use more `SyntaxContexts` when we encode the spans stored\n-        // inside `ExpnData`\n-        rustc_span::hygiene::for_all_expn_data(|index, expn_data| {\n-            // Don't encode the ExpnData for ExpnIds from foreign crates.\n-            // The crate that defines the ExpnId will store the ExpnData,\n-            // and the metadata decoder will look it from from that crate via the CStore\n-            if expn_data.krate == LOCAL_CRATE {\n-                expn_data_table.set(index, self.lazy(expn_data));\n-            }\n-            Ok::<(), !>(())\n-        })\n-        .unwrap();\n-\n-        let expn_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let mut num_serialized = 0;\n-\n-        // When we serialize a `SyntaxContextData`, we may end up serializing\n-        // a `SyntaxContext` that we haven't seen before. Therefore,\n-        while !self.latest_ctxts.as_ref().unwrap().is_empty() {\n-            debug!(\n-                \"encode_hygiene: Serializing a round of {:?} SyntaxContextDatas: {:?}\",\n-                self.latest_ctxts.as_ref().unwrap().len(),\n-                self.latest_ctxts.as_ref().unwrap()\n-            );\n-\n-            // Consume the current round of SyntaxContexts.\n-            let latest = self.latest_ctxts.replace(FxHashSet::default()).unwrap();\n-\n-            // It's fine to iterate over a HashMap, because thw serialization\n-            // of the table that we insert data into doesn't depend on insertion\n-            // order\n-            rustc_span::hygiene::for_all_data_in(latest.into_iter(), |(index, ctxt, data)| {\n-                if self.serialized_ctxts.as_mut().unwrap().insert(ctxt) {\n-                    syntax_contexts.set(index, self.lazy(data));\n-                    num_serialized += 1;\n-                }\n-                Ok::<_, !>(())\n-            })\n-            .unwrap();\n-        }\n-        debug!(\"encode_hygiene: Done serializing SyntaxContextData\");\n-        let syntax_bytes = self.position() - i;\n-\n-        let total = rustc_span::hygiene::num_syntax_ctxts();\n-        debug!(\n-            \"encode_hygiene: stored {}/{} ({})\",\n-            num_serialized,\n-            total,\n-            (num_serialized as f32) / (total as f32)\n+        let _: Result<(), !> = self.hygiene_ctxt.encode(\n+            &mut (&mut *self, &mut syntax_contexts, &mut expn_data_table),\n+            |(this, syntax_contexts, _), index, ctxt_data| {\n+                syntax_contexts.set(index, this.lazy(ctxt_data));\n+                Ok(())\n+            },\n+            |(this, _, expn_data_table), index, expn_data| {\n+                expn_data_table.set(index, this.lazy(expn_data));\n+                Ok(())\n+            },\n         );\n \n-        self.serialized_ctxts.take();\n-        self.latest_ctxts.take();\n-\n-        (\n-            syntax_contexts.encode(&mut self.opaque),\n-            syntax_bytes,\n-            expn_data_table.encode(&mut self.opaque),\n-            expn_bytes,\n-        )\n+        (syntax_contexts.encode(&mut self.opaque), expn_data_table.encode(&mut self.opaque))\n     }\n \n     fn encode_proc_macros(&mut self) -> Option<Lazy<[DefIndex]>> {\n@@ -1759,7 +1699,7 @@ impl EncodeContext<'tcx> {\n }\n \n // FIXME(eddyb) make metadata encoding walk over all definitions, instead of HIR.\n-impl Visitor<'tcx> for EncodeContext<'tcx> {\n+impl Visitor<'tcx> for EncodeContext<'a, 'tcx> {\n     type Map = Map<'tcx>;\n \n     fn nested_visit_map(&mut self) -> NestedVisitorMap<Self::Map> {\n@@ -1797,7 +1737,7 @@ impl Visitor<'tcx> for EncodeContext<'tcx> {\n     }\n }\n \n-impl EncodeContext<'tcx> {\n+impl EncodeContext<'a, 'tcx> {\n     fn encode_fields(&mut self, adt_def: &ty::AdtDef) {\n         for (variant_index, variant) in adt_def.variants.iter_enumerated() {\n             for (field_index, _field) in variant.fields.iter().enumerate() {\n@@ -2051,6 +1991,7 @@ fn encode_metadata_impl(tcx: TyCtxt<'_>) -> EncodedMetadata {\n     encoder.emit_raw_bytes(&[0, 0, 0, 0]);\n \n     let source_map_files = tcx.sess.source_map().files();\n+    let hygiene_ctxt = HygieneEncodeContext::default();\n \n     let mut ecx = EncodeContext {\n         opaque: encoder,\n@@ -2064,8 +2005,7 @@ fn encode_metadata_impl(tcx: TyCtxt<'_>) -> EncodedMetadata {\n         interpret_allocs_inverse: Default::default(),\n         required_source_files: Some(GrowableBitSet::with_capacity(source_map_files.len())),\n         is_proc_macro: tcx.sess.crate_types().contains(&CrateType::ProcMacro),\n-        serialized_ctxts: Some(Default::default()),\n-        latest_ctxts: Some(Default::default()),\n+        hygiene_ctxt: &hygiene_ctxt,\n     };\n     drop(source_map_files);\n "}, {"sha": "643fbe793ab8072540f6ca078aa4b279e6768877", "filename": "src/librustc_middle/ty/query/on_disk_cache.rs", "status": "modified", "additions": 34, "deletions": 28, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_middle%2Fty%2Fquery%2Fon_disk_cache.rs?ref=f622f45afdd7688e19d511799e978c1c66889fb4", "patch": "@@ -18,8 +18,8 @@ use rustc_serialize::{\n };\n use rustc_session::{CrateDisambiguator, Session};\n use rustc_span::hygiene::{\n-    ExpnDataDecodeMode, ExpnDataEncodeMode, ExpnId, HygieneContext, SyntaxContext,\n-    SyntaxContextData,\n+    ExpnDataDecodeMode, ExpnDataEncodeMode, ExpnId, HygieneDecodeContext, HygieneEncodeContext,\n+    SyntaxContext, SyntaxContextData,\n };\n use rustc_span::source_map::{SourceMap, StableSourceFileId};\n use rustc_span::symbol::Ident;\n@@ -83,7 +83,7 @@ pub struct OnDiskCache<'sess> {\n     // but it seemed easier to have `OnDiskCache` be independent of the `CStore`.\n     expn_data: FxHashMap<u32, AbsoluteBytePos>,\n     // Additional information used when decoding hygiene data.\n-    hygiene_context: HygieneContext,\n+    hygiene_context: HygieneDecodeContext,\n }\n \n // This type is used only for serialization and deserialization.\n@@ -158,7 +158,7 @@ impl<'sess> OnDiskCache<'sess> {\n             alloc_decoding_state: AllocDecodingState::new(footer.interpret_alloc_index),\n             syntax_contexts: footer.syntax_contexts,\n             expn_data: footer.expn_data,\n-            hygiene_context: HygieneContext::new(),\n+            hygiene_context: Default::default(),\n         }\n     }\n \n@@ -176,7 +176,7 @@ impl<'sess> OnDiskCache<'sess> {\n             alloc_decoding_state: AllocDecodingState::new(Vec::new()),\n             syntax_contexts: FxHashMap::default(),\n             expn_data: FxHashMap::default(),\n-            hygiene_context: HygieneContext::new(),\n+            hygiene_context: Default::default(),\n         }\n     }\n \n@@ -204,6 +204,8 @@ impl<'sess> OnDiskCache<'sess> {\n                 (file_to_file_index, file_index_to_stable_id)\n             };\n \n+            let hygiene_encode_context = HygieneEncodeContext::default();\n+\n             let mut encoder = CacheEncoder {\n                 tcx,\n                 encoder,\n@@ -213,6 +215,7 @@ impl<'sess> OnDiskCache<'sess> {\n                 interpret_allocs_inverse: Vec::new(),\n                 source_map: CachingSourceMapView::new(tcx.sess.source_map()),\n                 file_to_file_index,\n+                hygiene_context: &hygiene_encode_context,\n             };\n \n             // Load everything into memory so we can write it out to the on-disk\n@@ -293,29 +296,26 @@ impl<'sess> OnDiskCache<'sess> {\n                 .collect();\n \n             let mut syntax_contexts = FxHashMap::default();\n-            let mut expn_data = FxHashMap::default();\n+            let mut expn_ids = FxHashMap::default();\n \n             // Encode all hygiene data (`SyntaxContextData` and `ExpnData`) from the current\n             // session.\n-            // FIXME: Investigate tracking which `SyntaxContext`s and `ExpnId`s we actually\n-            // need, to avoid serializing data that will never be used. This will require\n-            // tracking which `SyntaxContext`s/`ExpnId`s are actually (transitively) referenced\n-            // from any of the `Span`s that we serialize.\n-\n-            rustc_span::hygiene::for_all_data(|(index, _ctxt, data)| {\n-                let pos = AbsoluteBytePos::new(encoder.position());\n-                encoder.encode_tagged(TAG_SYNTAX_CONTEXT, data)?;\n-                syntax_contexts.insert(index, pos);\n-                Ok(())\n-            })?;\n \n-            rustc_span::hygiene::for_all_expn_data(|index, data| {\n-                let pos = AbsoluteBytePos::new(encoder.position());\n-                encoder.encode_tagged(TAG_EXPN_DATA, data)?;\n-                //let hash = tcx.def_path_hash(data.def_id.unwrap());\n-                expn_data.insert(index, pos);\n-                Ok(())\n-            })?;\n+            hygiene_encode_context.encode(\n+                &mut encoder,\n+                |encoder, index, ctxt_data| {\n+                    let pos = AbsoluteBytePos::new(encoder.position());\n+                    encoder.encode_tagged(TAG_SYNTAX_CONTEXT, ctxt_data)?;\n+                    syntax_contexts.insert(index, pos);\n+                    Ok(())\n+                },\n+                |encoder, index, expn_data| {\n+                    let pos = AbsoluteBytePos::new(encoder.position());\n+                    encoder.encode_tagged(TAG_EXPN_DATA, expn_data)?;\n+                    expn_ids.insert(index, pos);\n+                    Ok(())\n+                },\n+            )?;\n \n             // `Encode the file footer.\n             let footer_pos = encoder.position() as u64;\n@@ -328,7 +328,7 @@ impl<'sess> OnDiskCache<'sess> {\n                     diagnostics_index,\n                     interpret_alloc_index,\n                     syntax_contexts,\n-                    expn_data,\n+                    expn_data: expn_ids,\n                 },\n             )?;\n \n@@ -503,7 +503,7 @@ struct CacheDecoder<'a, 'tcx> {\n     alloc_decoding_session: AllocDecodingSession<'a>,\n     syntax_contexts: &'a FxHashMap<u32, AbsoluteBytePos>,\n     expn_data: &'a FxHashMap<u32, AbsoluteBytePos>,\n-    hygiene_context: &'a HygieneContext,\n+    hygiene_context: &'a HygieneDecodeContext,\n }\n \n impl<'a, 'tcx> CacheDecoder<'a, 'tcx> {\n@@ -771,6 +771,7 @@ struct CacheEncoder<'a, 'tcx, E: ty_codec::TyEncoder> {\n     interpret_allocs_inverse: Vec<interpret::AllocId>,\n     source_map: CachingSourceMapView<'tcx>,\n     file_to_file_index: FxHashMap<*const SourceFile, SourceFileIndex>,\n+    hygiene_context: &'a HygieneEncodeContext,\n }\n \n impl<'a, 'tcx, E> CacheEncoder<'a, 'tcx, E>\n@@ -826,7 +827,7 @@ where\n     E: 'a + TyEncoder,\n {\n     fn specialized_encode(&mut self, ctxt: &SyntaxContext) -> Result<(), Self::Error> {\n-        rustc_span::hygiene::raw_encode_syntax_context(*ctxt, self)\n+        rustc_span::hygiene::raw_encode_syntax_context(*ctxt, self.hygiene_context, self)\n     }\n }\n \n@@ -835,7 +836,12 @@ where\n     E: 'a + TyEncoder,\n {\n     fn specialized_encode(&mut self, expn: &ExpnId) -> Result<(), Self::Error> {\n-        rustc_span::hygiene::raw_encode_expn_id(*expn, ExpnDataEncodeMode::IncrComp, self)\n+        rustc_span::hygiene::raw_encode_expn_id(\n+            *expn,\n+            self.hygiene_context,\n+            ExpnDataEncodeMode::IncrComp,\n+            self,\n+        )\n     }\n }\n "}, {"sha": "13bc1751831b977cabe33711938f791b3a93e2a5", "filename": "src/librustc_span/hygiene.rs", "status": "modified", "additions": 109, "deletions": 35, "changes": 144, "blob_url": "https://github.com/rust-lang/rust/blob/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_span%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_span%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_span%2Fhygiene.rs?ref=f622f45afdd7688e19d511799e978c1c66889fb4", "patch": "@@ -31,7 +31,7 @@ use crate::{Span, DUMMY_SP};\n \n use crate::def_id::{CrateNum, DefId, CRATE_DEF_INDEX, LOCAL_CRATE};\n use log::*;\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n use rustc_data_structures::sync::{Lock, Lrc};\n use rustc_macros::HashStable_Generic;\n use rustc_serialize::{\n@@ -889,8 +889,75 @@ impl DesugaringKind {\n impl UseSpecializedEncodable for ExpnId {}\n impl UseSpecializedDecodable for ExpnId {}\n \n+#[derive(Default)]\n+pub struct HygieneEncodeContext {\n+    /// All `SyntaxContexts` for which we have writen `SyntaxContextData` into crate metadata.\n+    /// This is `None` after we finish encoding `SyntaxContexts`, to ensure\n+    /// that we don't accidentally try to encode any more `SyntaxContexts`\n+    serialized_ctxts: Lock<FxHashSet<SyntaxContext>>,\n+    /// The `SyntaxContexts` that we have serialized (e.g. as a result of encoding `Spans`)\n+    /// in the most recent 'round' of serializnig. Serializing `SyntaxContextData`\n+    /// may cause us to serialize more `SyntaxContext`s, so serialize in a loop\n+    /// until we reach a fixed point.\n+    latest_ctxts: Lock<FxHashSet<SyntaxContext>>,\n+\n+    serialized_expns: Lock<FxHashSet<ExpnId>>,\n+\n+    latest_expns: Lock<FxHashSet<ExpnId>>,\n+}\n+\n+impl HygieneEncodeContext {\n+    pub fn encode<\n+        T,\n+        R,\n+        F: FnMut(&mut T, u32, &SyntaxContextData) -> Result<(), R>,\n+        G: FnMut(&mut T, u32, &ExpnData) -> Result<(), R>,\n+    >(\n+        &self,\n+        encoder: &mut T,\n+        mut encode_ctxt: F,\n+        mut encode_expn: G,\n+    ) -> Result<(), R> {\n+        // When we serialize a `SyntaxContextData`, we may end up serializing\n+        // a `SyntaxContext` that we haven't seen before\n+        while !self.latest_ctxts.lock().is_empty() || !self.latest_expns.lock().is_empty() {\n+            debug!(\n+                \"encode_hygiene: Serializing a round of {:?} SyntaxContextDatas: {:?}\",\n+                self.latest_ctxts.lock().len(),\n+                self.latest_ctxts\n+            );\n+\n+            // Consume the current round of SyntaxContexts.\n+            // Drop the lock() temporary early\n+            let latest_ctxts = { std::mem::take(&mut *self.latest_ctxts.lock()) };\n+\n+            // It's fine to iterate over a HashMap, because the serialization\n+            // of the table that we insert data into doesn't depend on insertion\n+            // order\n+            for_all_ctxts_in(latest_ctxts.into_iter(), |(index, ctxt, data)| {\n+                if self.serialized_ctxts.lock().insert(ctxt) {\n+                    encode_ctxt(encoder, index, data)?;\n+                }\n+                Ok(())\n+            })?;\n+\n+            let latest_expns = { std::mem::take(&mut *self.latest_expns.lock()) };\n+\n+            for_all_expns_in(latest_expns.into_iter(), |index, expn, data| {\n+                if self.serialized_expns.lock().insert(expn) {\n+                    encode_expn(encoder, index, data)?;\n+                }\n+                Ok(())\n+            })?;\n+        }\n+        debug!(\"encode_hygiene: Done serializing SyntaxContextData\");\n+        Ok(())\n+    }\n+}\n+\n+#[derive(Default)]\n /// Additional information used to assist in decoding hygiene data\n-pub struct HygieneContext {\n+pub struct HygieneDecodeContext {\n     // Maps serialized `SyntaxContext` ids to a `SyntaxContext` in the current\n     // global `HygieneData`. When we deserialize a `SyntaxContext`, we need to create\n     // a new id in the global `HygieneData`. This map tracks the ID we end up picking,\n@@ -901,20 +968,11 @@ pub struct HygieneContext {\n     remapped_expns: Lock<Vec<Option<ExpnId>>>,\n }\n \n-impl HygieneContext {\n-    pub fn new() -> HygieneContext {\n-        HygieneContext {\n-            remapped_ctxts: Lock::new(Vec::new()),\n-            remapped_expns: Lock::new(Vec::new()),\n-        }\n-    }\n-}\n-\n pub fn decode_expn_id<\n     'a,\n     D: Decoder,\n     F: FnOnce(&mut D, u32) -> Result<ExpnData, D::Error>,\n-    G: FnOnce(CrateNum) -> &'a HygieneContext,\n+    G: FnOnce(CrateNum) -> &'a HygieneDecodeContext,\n >(\n     d: &mut D,\n     mode: ExpnDataDecodeMode<'a, G>,\n@@ -963,21 +1021,19 @@ pub fn decode_expn_id<\n \n         hygiene_data.expn_data.push(Some(expn_data));\n \n-        // Drop lock() temporary early\n-        {\n-            let mut expns = outer_expns.lock();\n-            let new_len = index as usize + 1;\n-            if expns.len() < new_len {\n-                expns.resize(new_len, None);\n-            }\n-            expns[index as usize] = Some(expn_id);\n+        let mut expns = outer_expns.lock();\n+        let new_len = index as usize + 1;\n+        if expns.len() < new_len {\n+            expns.resize(new_len, None);\n         }\n+        expns[index as usize] = Some(expn_id);\n+        drop(expns);\n         expn_id\n     });\n     return Ok(expn_id);\n }\n \n-// Decodes `SyntaxContext`, using the provided `HygieneContext`\n+// Decodes `SyntaxContext`, using the provided `HygieneDecodeContext`\n // to track which `SyntaxContext`s we have already decoded.\n // The provided closure will be invoked to deserialize a `SyntaxContextData`\n // if we haven't already seen the id of the `SyntaxContext` we are deserializing.\n@@ -986,7 +1042,7 @@ pub fn decode_syntax_context<\n     F: FnOnce(&mut D, u32) -> Result<SyntaxContextData, D::Error>,\n >(\n     d: &mut D,\n-    context: &HygieneContext,\n+    context: &HygieneDecodeContext,\n     decode_data: F,\n ) -> Result<SyntaxContext, D::Error> {\n     let raw_id: u32 = Decodable::decode(d)?;\n@@ -1019,15 +1075,13 @@ pub fn decode_syntax_context<\n             opaque_and_semitransparent: SyntaxContext::root(),\n             dollar_crate_name: kw::Invalid,\n         });\n-        // Ensure that the lock() temporary is dropped early\n-        {\n-            let mut ctxts = outer_ctxts.lock();\n-            let new_len = raw_id as usize + 1;\n-            if ctxts.len() < new_len {\n-                ctxts.resize(new_len, None);\n-            }\n-            ctxts[raw_id as usize] = Some(new_ctxt);\n+        let mut ctxts = outer_ctxts.lock();\n+        let new_len = raw_id as usize + 1;\n+        if ctxts.len() < new_len {\n+            ctxts.resize(new_len, None);\n         }\n+        ctxts[raw_id as usize] = Some(new_ctxt);\n+        drop(ctxts);\n         new_ctxt\n     });\n \n@@ -1056,7 +1110,7 @@ pub fn num_syntax_ctxts() -> usize {\n     HygieneData::with(|data| data.syntax_context_data.len())\n }\n \n-pub fn for_all_data_in<E, F: FnMut((u32, SyntaxContext, &SyntaxContextData)) -> Result<(), E>>(\n+pub fn for_all_ctxts_in<E, F: FnMut((u32, SyntaxContext, &SyntaxContextData)) -> Result<(), E>>(\n     ctxts: impl Iterator<Item = SyntaxContext>,\n     mut f: F,\n ) -> Result<(), E> {\n@@ -1069,6 +1123,18 @@ pub fn for_all_data_in<E, F: FnMut((u32, SyntaxContext, &SyntaxContextData)) ->\n     Ok(())\n }\n \n+pub fn for_all_expns_in<E, F: FnMut(u32, ExpnId, &ExpnData) -> Result<(), E>>(\n+    expns: impl Iterator<Item = ExpnId>,\n+    mut f: F,\n+) -> Result<(), E> {\n+    let all_data: Vec<_> = HygieneData::with(|data| {\n+        expns.map(|expn| (expn, data.expn_data[expn.0 as usize].clone())).collect()\n+    });\n+    for (expn, data) in all_data.into_iter() {\n+        f(expn.0, expn, &data.unwrap_or_else(|| panic!(\"Missing data for {:?}\", expn)))?;\n+    }\n+    Ok(())\n+}\n pub fn for_all_data<E, F: FnMut((u32, SyntaxContext, &SyntaxContextData)) -> Result<(), E>>(\n     mut f: F,\n ) -> Result<(), E> {\n@@ -1089,16 +1155,24 @@ pub fn for_all_expn_data<E, F: FnMut(u32, &ExpnData) -> Result<(), E>>(mut f: F)\n \n pub fn raw_encode_syntax_context<E: Encoder>(\n     ctxt: SyntaxContext,\n+    context: &HygieneEncodeContext,\n     e: &mut E,\n ) -> Result<(), E::Error> {\n+    if !context.serialized_ctxts.lock().contains(&ctxt) {\n+        context.latest_ctxts.lock().insert(ctxt);\n+    }\n     ctxt.0.encode(e)\n }\n \n pub fn raw_encode_expn_id<E: Encoder>(\n     expn: ExpnId,\n+    context: &HygieneEncodeContext,\n     mode: ExpnDataEncodeMode,\n     e: &mut E,\n ) -> Result<(), E::Error> {\n+    if !context.serialized_expns.lock().contains(&expn) {\n+        context.latest_expns.lock().insert(expn);\n+    }\n     match mode {\n         ExpnDataEncodeMode::IncrComp => expn.0.encode(e),\n         ExpnDataEncodeMode::Metadata => {\n@@ -1114,13 +1188,13 @@ pub enum ExpnDataEncodeMode {\n     Metadata,\n }\n \n-pub enum ExpnDataDecodeMode<'a, F: FnOnce(CrateNum) -> &'a HygieneContext> {\n-    IncrComp(&'a HygieneContext),\n+pub enum ExpnDataDecodeMode<'a, F: FnOnce(CrateNum) -> &'a HygieneDecodeContext> {\n+    IncrComp(&'a HygieneDecodeContext),\n     Metadata(F),\n }\n \n-impl<'a> ExpnDataDecodeMode<'a, Box<dyn FnOnce(CrateNum) -> &'a HygieneContext>> {\n-    pub fn incr_comp(ctxt: &'a HygieneContext) -> Self {\n+impl<'a> ExpnDataDecodeMode<'a, Box<dyn FnOnce(CrateNum) -> &'a HygieneDecodeContext>> {\n+    pub fn incr_comp(ctxt: &'a HygieneDecodeContext) -> Self {\n         ExpnDataDecodeMode::IncrComp(ctxt)\n     }\n }"}, {"sha": "7087dc80b1daf5a88298301d4106d6af6c4ff1f6", "filename": "src/librustc_span/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_span%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Flibrustc_span%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_span%2Flib.rs?ref=f622f45afdd7688e19d511799e978c1c66889fb4", "patch": "@@ -13,6 +13,7 @@\n #![feature(optin_builtin_traits)]\n #![feature(min_specialization)]\n #![feature(option_expect_none)]\n+#![feature(refcell_take)]\n \n // FIXME(#56935): Work around ICEs during cross-compilation.\n #[allow(unused)]"}, {"sha": "91a9f63d39bfe4b71db6e64546facf39e06b249d", "filename": "src/test/incremental/hygiene/auxiliary/cached_hygiene.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Ftest%2Fincremental%2Fhygiene%2Fauxiliary%2Fcached_hygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f622f45afdd7688e19d511799e978c1c66889fb4/src%2Ftest%2Fincremental%2Fhygiene%2Fauxiliary%2Fcached_hygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fhygiene%2Fauxiliary%2Fcached_hygiene.rs?ref=f622f45afdd7688e19d511799e978c1c66889fb4", "patch": "@@ -34,4 +34,3 @@ macro_rules! print_loc {\n pub fn unchanged_fn() {\n     print_loc!();\n }\n-"}]}