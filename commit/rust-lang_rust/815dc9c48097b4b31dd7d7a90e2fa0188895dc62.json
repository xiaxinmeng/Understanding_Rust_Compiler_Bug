{"sha": "815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "node_id": "C_kwDOAAsO6NoAKDgxNWRjOWM0ODA5N2I0YjMxZGQ3ZDdhOTBlMmZhMDE4ODg5NWRjNjI", "commit": {"author": {"name": "Dylan DPC", "email": "99973273+Dylan-DPC@users.noreply.github.com", "date": "2023-02-03T17:34:51Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2023-02-03T17:34:51Z"}, "message": "Rollup merge of #107544 - nnethercote:improve-TokenCursor, r=petrochenkov\n\nImprove `TokenCursor`.\n\nSome small improvements, for things that were bugging me.\n\nBest reviewed one commit at a time.\n\nr? ``@petrochenkov``", "tree": {"sha": "09f441dd2590277d7e87ef4d414b91310d03453c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/09f441dd2590277d7e87ef4d414b91310d03453c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJj3UW7CRBK7hj4Ov3rIwAAd1QIAGObf5ylD7azB0xjra7TKuLu\nIg6kt0WkIW98anc6+7qmOusDawQTGSFVofr5rPe1VnVZ5Uj/eOl4PSxzxoZtH4DY\nnXDQdOp7hU6gvwWKT0AGVIcYHJmR8nJvQNMCwgDs9wpODkfj7NuAG/0bLYBQ5+f5\nT2tyqkHmPltZEOE39nDj8goIJJhhjzplIJImLEsL0zKhRvxntmZtrxR3MNu7hvmZ\n9IydelCDrGoxItS4tLwwNMoxcflks+HQTQg1cGE3aexu4f0NT7gCnfbCh8qoV3pd\n0oo4bYzQKXiolIjQicpGQClx6w3Nx9BEuDbyT7CHdwMjm9r3jcKDplOZ4Qe7/gY=\n=Vv77\n-----END PGP SIGNATURE-----\n", "payload": "tree 09f441dd2590277d7e87ef4d414b91310d03453c\nparent d9db35785d33e2b6c6e9b4971dfdbe0984a69b9e\nparent a86fc727fa9b9fa1ac60b67147736783b3376e91\nauthor Dylan DPC <99973273+Dylan-DPC@users.noreply.github.com> 1675445691 +0530\ncommitter GitHub <noreply@github.com> 1675445691 +0530\n\nRollup merge of #107544 - nnethercote:improve-TokenCursor, r=petrochenkov\n\nImprove `TokenCursor`.\n\nSome small improvements, for things that were bugging me.\n\nBest reviewed one commit at a time.\n\nr? ``@petrochenkov``\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "html_url": "https://github.com/rust-lang/rust/commit/815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/comments", "author": {"login": "Dylan-DPC", "id": 99973273, "node_id": "U_kgDOBfV4mQ", "avatar_url": "https://avatars.githubusercontent.com/u/99973273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dylan-DPC", "html_url": "https://github.com/Dylan-DPC", "followers_url": "https://api.github.com/users/Dylan-DPC/followers", "following_url": "https://api.github.com/users/Dylan-DPC/following{/other_user}", "gists_url": "https://api.github.com/users/Dylan-DPC/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dylan-DPC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dylan-DPC/subscriptions", "organizations_url": "https://api.github.com/users/Dylan-DPC/orgs", "repos_url": "https://api.github.com/users/Dylan-DPC/repos", "events_url": "https://api.github.com/users/Dylan-DPC/events{/privacy}", "received_events_url": "https://api.github.com/users/Dylan-DPC/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d9db35785d33e2b6c6e9b4971dfdbe0984a69b9e", "url": "https://api.github.com/repos/rust-lang/rust/commits/d9db35785d33e2b6c6e9b4971dfdbe0984a69b9e", "html_url": "https://github.com/rust-lang/rust/commit/d9db35785d33e2b6c6e9b4971dfdbe0984a69b9e"}, {"sha": "a86fc727fa9b9fa1ac60b67147736783b3376e91", "url": "https://api.github.com/repos/rust-lang/rust/commits/a86fc727fa9b9fa1ac60b67147736783b3376e91", "html_url": "https://github.com/rust-lang/rust/commit/a86fc727fa9b9fa1ac60b67147736783b3376e91"}], "stats": {"total": 189, "additions": 98, "deletions": 91}, "files": [{"sha": "f0a6a5e0725860b5f090f8f6a12223ad13b868f1", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 27, "deletions": 15, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "patch": "@@ -41,7 +41,8 @@ use std::{fmt, iter};\n /// Nothing special happens to misnamed or misplaced `SubstNt`s.\n #[derive(Debug, Clone, PartialEq, Encodable, Decodable, HashStable_Generic)]\n pub enum TokenTree {\n-    /// A single token.\n+    /// A single token. Should never be `OpenDelim` or `CloseDelim`, because\n+    /// delimiters are implicitly represented by `Delimited`.\n     Token(Token, Spacing),\n     /// A delimited sequence of token trees.\n     Delimited(DelimSpan, Delimiter, TokenStream),\n@@ -388,12 +389,12 @@ impl TokenStream {\n         self.0.len()\n     }\n \n-    pub fn trees(&self) -> CursorRef<'_> {\n-        CursorRef::new(self)\n+    pub fn trees(&self) -> RefTokenTreeCursor<'_> {\n+        RefTokenTreeCursor::new(self)\n     }\n \n-    pub fn into_trees(self) -> Cursor {\n-        Cursor::new(self)\n+    pub fn into_trees(self) -> TokenTreeCursor {\n+        TokenTreeCursor::new(self)\n     }\n \n     /// Compares two `TokenStream`s, checking equality without regarding span information.\n@@ -551,24 +552,25 @@ impl TokenStream {\n     }\n }\n \n-/// By-reference iterator over a [`TokenStream`].\n+/// By-reference iterator over a [`TokenStream`], that produces `&TokenTree`\n+/// items.\n #[derive(Clone)]\n-pub struct CursorRef<'t> {\n+pub struct RefTokenTreeCursor<'t> {\n     stream: &'t TokenStream,\n     index: usize,\n }\n \n-impl<'t> CursorRef<'t> {\n+impl<'t> RefTokenTreeCursor<'t> {\n     fn new(stream: &'t TokenStream) -> Self {\n-        CursorRef { stream, index: 0 }\n+        RefTokenTreeCursor { stream, index: 0 }\n     }\n \n     pub fn look_ahead(&self, n: usize) -> Option<&TokenTree> {\n         self.stream.0.get(self.index + n)\n     }\n }\n \n-impl<'t> Iterator for CursorRef<'t> {\n+impl<'t> Iterator for RefTokenTreeCursor<'t> {\n     type Item = &'t TokenTree;\n \n     fn next(&mut self) -> Option<&'t TokenTree> {\n@@ -579,15 +581,16 @@ impl<'t> Iterator for CursorRef<'t> {\n     }\n }\n \n-/// Owning by-value iterator over a [`TokenStream`].\n+/// Owning by-value iterator over a [`TokenStream`], that produces `TokenTree`\n+/// items.\n // FIXME: Many uses of this can be replaced with by-reference iterator to avoid clones.\n #[derive(Clone)]\n-pub struct Cursor {\n+pub struct TokenTreeCursor {\n     pub stream: TokenStream,\n     index: usize,\n }\n \n-impl Iterator for Cursor {\n+impl Iterator for TokenTreeCursor {\n     type Item = TokenTree;\n \n     fn next(&mut self) -> Option<TokenTree> {\n@@ -598,9 +601,9 @@ impl Iterator for Cursor {\n     }\n }\n \n-impl Cursor {\n+impl TokenTreeCursor {\n     fn new(stream: TokenStream) -> Self {\n-        Cursor { stream, index: 0 }\n+        TokenTreeCursor { stream, index: 0 }\n     }\n \n     #[inline]\n@@ -614,6 +617,15 @@ impl Cursor {\n     pub fn look_ahead(&self, n: usize) -> Option<&TokenTree> {\n         self.stream.0.get(self.index + n)\n     }\n+\n+    // Replace the previously obtained token tree with `tts`, and rewind to\n+    // just before them.\n+    pub fn replace_prev_and_rewind(&mut self, tts: Vec<TokenTree>) {\n+        assert!(self.index > 0);\n+        self.index -= 1;\n+        let stream = Lrc::make_mut(&mut self.stream.0);\n+        stream.splice(self.index..self.index + 1, tts);\n+    }\n }\n \n #[derive(Debug, Copy, Clone, PartialEq, Encodable, Decodable, HashStable_Generic)]"}, {"sha": "de34df0114a743c2f89327d94c2cd7f13fbad9a9", "filename": "compiler/rustc_expand/src/mbe/metavar_expr.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmetavar_expr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmetavar_expr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmetavar_expr.rs?ref=815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "patch": "@@ -1,5 +1,5 @@\n use rustc_ast::token::{self, Delimiter};\n-use rustc_ast::tokenstream::{CursorRef, TokenStream, TokenTree};\n+use rustc_ast::tokenstream::{RefTokenTreeCursor, TokenStream, TokenTree};\n use rustc_ast::{LitIntType, LitKind};\n use rustc_ast_pretty::pprust;\n use rustc_errors::{Applicability, PResult};\n@@ -72,7 +72,7 @@ impl MetaVarExpr {\n \n // Checks if there are any remaining tokens. For example, `${ignore(ident ... a b c ...)}`\n fn check_trailing_token<'sess>(\n-    iter: &mut CursorRef<'_>,\n+    iter: &mut RefTokenTreeCursor<'_>,\n     sess: &'sess ParseSess,\n ) -> PResult<'sess, ()> {\n     if let Some(tt) = iter.next() {\n@@ -88,7 +88,7 @@ fn check_trailing_token<'sess>(\n \n /// Parse a meta-variable `count` expression: `count(ident[, depth])`\n fn parse_count<'sess>(\n-    iter: &mut CursorRef<'_>,\n+    iter: &mut RefTokenTreeCursor<'_>,\n     sess: &'sess ParseSess,\n     span: Span,\n ) -> PResult<'sess, MetaVarExpr> {\n@@ -99,7 +99,7 @@ fn parse_count<'sess>(\n \n /// Parses the depth used by index(depth) and length(depth).\n fn parse_depth<'sess>(\n-    iter: &mut CursorRef<'_>,\n+    iter: &mut RefTokenTreeCursor<'_>,\n     sess: &'sess ParseSess,\n     span: Span,\n ) -> PResult<'sess, usize> {\n@@ -126,7 +126,7 @@ fn parse_depth<'sess>(\n \n /// Parses an generic ident\n fn parse_ident<'sess>(\n-    iter: &mut CursorRef<'_>,\n+    iter: &mut RefTokenTreeCursor<'_>,\n     sess: &'sess ParseSess,\n     span: Span,\n ) -> PResult<'sess, Ident> {\n@@ -152,7 +152,7 @@ fn parse_ident<'sess>(\n \n /// Tries to move the iterator forward returning `true` if there is a comma. If not, then the\n /// iterator is not modified and the result is `false`.\n-fn try_eat_comma(iter: &mut CursorRef<'_>) -> bool {\n+fn try_eat_comma(iter: &mut RefTokenTreeCursor<'_>) -> bool {\n     if let Some(TokenTree::Token(token::Token { kind: token::Comma, .. }, _)) = iter.look_ahead(0) {\n         let _ = iter.next();\n         return true;"}, {"sha": "dbd3b76786f42c56d67f44aee2c6d5f588212baa", "filename": "compiler/rustc_parse/src/parser/attr_wrapper.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs?ref=815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "patch": "@@ -469,6 +469,6 @@ mod size_asserts {\n     use rustc_data_structures::static_assert_size;\n     // tidy-alphabetical-start\n     static_assert_size!(AttrWrapper, 16);\n-    static_assert_size!(LazyAttrTokenStreamImpl, 144);\n+    static_assert_size!(LazyAttrTokenStreamImpl, 120);\n     // tidy-alphabetical-end\n }"}, {"sha": "8a6436b041b90c717b5eaa2d4a2abd055a2e1c6a", "filename": "compiler/rustc_parse/src/parser/expr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs?ref=815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "patch": "@@ -2141,7 +2141,7 @@ impl<'a> Parser<'a> {\n         }\n \n         if self.token.kind == TokenKind::Semi\n-            && matches!(self.token_cursor.frame.delim_sp, Some((Delimiter::Parenthesis, _)))\n+            && matches!(self.token_cursor.stack.last(), Some((_, Delimiter::Parenthesis, _)))\n             && self.may_recover()\n         {\n             // It is likely that the closure body is a block but where the"}, {"sha": "2ea55f838a37e3f1022476a98a91205e51a6466d", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 59, "deletions": 64, "changes": 123, "blob_url": "https://github.com/rust-lang/rust/blob/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "patch": "@@ -19,9 +19,8 @@ pub use path::PathStyle;\n \n use rustc_ast::ptr::P;\n use rustc_ast::token::{self, Delimiter, Nonterminal, Token, TokenKind};\n-use rustc_ast::tokenstream::AttributesData;\n-use rustc_ast::tokenstream::{self, DelimSpan, Spacing};\n-use rustc_ast::tokenstream::{TokenStream, TokenTree};\n+use rustc_ast::tokenstream::{AttributesData, DelimSpan, Spacing};\n+use rustc_ast::tokenstream::{TokenStream, TokenTree, TokenTreeCursor};\n use rustc_ast::util::case::Case;\n use rustc_ast::AttrId;\n use rustc_ast::DUMMY_NODE_ID;\n@@ -168,7 +167,7 @@ pub struct Parser<'a> {\n // This type is used a lot, e.g. it's cloned when matching many declarative macro rules with nonterminals. Make sure\n // it doesn't unintentionally get bigger.\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(Parser<'_>, 336);\n+rustc_data_structures::static_assert_size!(Parser<'_>, 312);\n \n /// Stores span information about a closure.\n #[derive(Clone)]\n@@ -221,18 +220,27 @@ impl<'a> Drop for Parser<'a> {\n     }\n }\n \n+/// Iterator over a `TokenStream` that produces `Token`s. It's a bit odd that\n+/// we (a) lex tokens into a nice tree structure (`TokenStream`), and then (b)\n+/// use this type to emit them as a linear sequence. But a linear sequence is\n+/// what the parser expects, for the most part.\n #[derive(Clone)]\n struct TokenCursor {\n-    // The current (innermost) frame. `frame` and `stack` could be combined,\n-    // but it's faster to have them separately to access `frame` directly\n-    // rather than via something like `stack.last().unwrap()` or\n-    // `stack[stack.len() - 1]`.\n-    frame: TokenCursorFrame,\n-    // Additional frames that enclose `frame`.\n-    stack: Vec<TokenCursorFrame>,\n+    // Cursor for the current (innermost) token stream. The delimiters for this\n+    // token stream are found in `self.stack.last()`; when that is `None` then\n+    // we are in the outermost token stream which never has delimiters.\n+    tree_cursor: TokenTreeCursor,\n+\n+    // Token streams surrounding the current one. The delimiters for stack[n]'s\n+    // tokens are in `stack[n-1]`. `stack[0]` (when present) has no delimiters\n+    // because it's the outermost token stream which never has delimiters.\n+    stack: Vec<(TokenTreeCursor, Delimiter, DelimSpan)>,\n+\n     desugar_doc_comments: bool,\n+\n     // Counts the number of calls to `{,inlined_}next`.\n     num_next_calls: usize,\n+\n     // During parsing, we may sometimes need to 'unglue' a\n     // glued token into two component tokens\n     // (e.g. '>>' into '>' and '>), so that the parser\n@@ -257,18 +265,6 @@ struct TokenCursor {\n     break_last_token: bool,\n }\n \n-#[derive(Clone)]\n-struct TokenCursorFrame {\n-    delim_sp: Option<(Delimiter, DelimSpan)>,\n-    tree_cursor: tokenstream::Cursor,\n-}\n-\n-impl TokenCursorFrame {\n-    fn new(delim_sp: Option<(Delimiter, DelimSpan)>, tts: TokenStream) -> Self {\n-        TokenCursorFrame { delim_sp, tree_cursor: tts.into_trees() }\n-    }\n-}\n-\n impl TokenCursor {\n     fn next(&mut self, desugar_doc_comments: bool) -> (Token, Spacing) {\n         self.inlined_next(desugar_doc_comments)\n@@ -281,38 +277,47 @@ impl TokenCursor {\n             // FIXME: we currently don't return `Delimiter` open/close delims. To fix #67062 we will\n             // need to, whereupon the `delim != Delimiter::Invisible` conditions below can be\n             // removed.\n-            if let Some(tree) = self.frame.tree_cursor.next_ref() {\n+            if let Some(tree) = self.tree_cursor.next_ref() {\n                 match tree {\n                     &TokenTree::Token(ref token, spacing) => match (desugar_doc_comments, token) {\n                         (true, &Token { kind: token::DocComment(_, attr_style, data), span }) => {\n-                            return self.desugar(attr_style, data, span);\n+                            let desugared = self.desugar(attr_style, data, span);\n+                            self.tree_cursor.replace_prev_and_rewind(desugared);\n+                            // Continue to get the first token of the desugared doc comment.\n+                        }\n+                        _ => {\n+                            debug_assert!(!matches!(\n+                                token.kind,\n+                                token::OpenDelim(_) | token::CloseDelim(_)\n+                            ));\n+                            return (token.clone(), spacing);\n                         }\n-                        _ => return (token.clone(), spacing),\n                     },\n                     &TokenTree::Delimited(sp, delim, ref tts) => {\n-                        // Set `open_delim` to true here because we deal with it immediately.\n-                        let frame = TokenCursorFrame::new(Some((delim, sp)), tts.clone());\n-                        self.stack.push(mem::replace(&mut self.frame, frame));\n+                        let trees = tts.clone().into_trees();\n+                        self.stack.push((mem::replace(&mut self.tree_cursor, trees), delim, sp));\n                         if delim != Delimiter::Invisible {\n                             return (Token::new(token::OpenDelim(delim), sp.open), Spacing::Alone);\n                         }\n                         // No open delimiter to return; continue on to the next iteration.\n                     }\n                 };\n-            } else if let Some(frame) = self.stack.pop() {\n-                if let Some((delim, span)) = self.frame.delim_sp && delim != Delimiter::Invisible {\n-                    self.frame = frame;\n+            } else if let Some((tree_cursor, delim, span)) = self.stack.pop() {\n+                // We have exhausted this token stream. Move back to its parent token stream.\n+                self.tree_cursor = tree_cursor;\n+                if delim != Delimiter::Invisible {\n                     return (Token::new(token::CloseDelim(delim), span.close), Spacing::Alone);\n                 }\n-                self.frame = frame;\n                 // No close delimiter to return; continue on to the next iteration.\n             } else {\n+                // We have exhausted the outermost token stream.\n                 return (Token::new(token::Eof, DUMMY_SP), Spacing::Alone);\n             }\n         }\n     }\n \n-    fn desugar(&mut self, attr_style: AttrStyle, data: Symbol, span: Span) -> (Token, Spacing) {\n+    // Desugar a doc comment into something like `#[doc = r\"foo\"]`.\n+    fn desugar(&mut self, attr_style: AttrStyle, data: Symbol, span: Span) -> Vec<TokenTree> {\n         // Searches for the occurrences of `\"#*` and returns the minimum number of `#`s\n         // required to wrap the text. E.g.\n         // - `abc d` is wrapped as `r\"abc d\"` (num_of_hashes = 0)\n@@ -346,27 +351,15 @@ impl TokenCursor {\n             .collect::<TokenStream>(),\n         );\n \n-        self.stack.push(mem::replace(\n-            &mut self.frame,\n-            TokenCursorFrame::new(\n-                None,\n-                if attr_style == AttrStyle::Inner {\n-                    [\n-                        TokenTree::token_alone(token::Pound, span),\n-                        TokenTree::token_alone(token::Not, span),\n-                        body,\n-                    ]\n-                    .into_iter()\n-                    .collect::<TokenStream>()\n-                } else {\n-                    [TokenTree::token_alone(token::Pound, span), body]\n-                        .into_iter()\n-                        .collect::<TokenStream>()\n-                },\n-            ),\n-        ));\n-\n-        self.next(/* desugar_doc_comments */ false)\n+        if attr_style == AttrStyle::Inner {\n+            vec![\n+                TokenTree::token_alone(token::Pound, span),\n+                TokenTree::token_alone(token::Not, span),\n+                body,\n+            ]\n+        } else {\n+            vec![TokenTree::token_alone(token::Pound, span), body]\n+        }\n     }\n }\n \n@@ -475,7 +468,7 @@ impl<'a> Parser<'a> {\n             restrictions: Restrictions::empty(),\n             expected_tokens: Vec::new(),\n             token_cursor: TokenCursor {\n-                frame: TokenCursorFrame::new(None, tokens),\n+                tree_cursor: tokens.into_trees(),\n                 stack: Vec::new(),\n                 num_next_calls: 0,\n                 desugar_doc_comments,\n@@ -1142,14 +1135,16 @@ impl<'a> Parser<'a> {\n             return looker(&self.token);\n         }\n \n-        let frame = &self.token_cursor.frame;\n-        if let Some((delim, span)) = frame.delim_sp && delim != Delimiter::Invisible {\n+        let tree_cursor = &self.token_cursor.tree_cursor;\n+        if let Some(&(_, delim, span)) = self.token_cursor.stack.last()\n+            && delim != Delimiter::Invisible\n+        {\n             let all_normal = (0..dist).all(|i| {\n-                let token = frame.tree_cursor.look_ahead(i);\n+                let token = tree_cursor.look_ahead(i);\n                 !matches!(token, Some(TokenTree::Delimited(_, Delimiter::Invisible, _)))\n             });\n             if all_normal {\n-                return match frame.tree_cursor.look_ahead(dist - 1) {\n+                return match tree_cursor.look_ahead(dist - 1) {\n                     Some(tree) => match tree {\n                         TokenTree::Token(token, _) => looker(token),\n                         TokenTree::Delimited(dspan, delim, _) => {\n@@ -1310,10 +1305,10 @@ impl<'a> Parser<'a> {\n     pub(crate) fn parse_token_tree(&mut self) -> TokenTree {\n         match self.token.kind {\n             token::OpenDelim(..) => {\n-                // Grab the tokens from this frame.\n-                let frame = &self.token_cursor.frame;\n-                let stream = frame.tree_cursor.stream.clone();\n-                let (delim, span) = frame.delim_sp.unwrap();\n+                // Grab the tokens within the delimiters.\n+                let tree_cursor = &self.token_cursor.tree_cursor;\n+                let stream = tree_cursor.stream.clone();\n+                let (_, delim, span) = *self.token_cursor.stack.last().unwrap();\n \n                 // Advance the token cursor through the entire delimited\n                 // sequence. After getting the `OpenDelim` we are *within* the"}, {"sha": "7978d8cba95412cb3ef9c51b8d1a40ec5b982294", "filename": "src/tools/rustfmt/src/macros.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/src%2Ftools%2Frustfmt%2Fsrc%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/815dc9c48097b4b31dd7d7a90e2fa0188895dc62/src%2Ftools%2Frustfmt%2Fsrc%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Frustfmt%2Fsrc%2Fmacros.rs?ref=815dc9c48097b4b31dd7d7a90e2fa0188895dc62", "patch": "@@ -13,7 +13,7 @@ use std::collections::HashMap;\n use std::panic::{catch_unwind, AssertUnwindSafe};\n \n use rustc_ast::token::{BinOpToken, Delimiter, Token, TokenKind};\n-use rustc_ast::tokenstream::{Cursor, TokenStream, TokenTree};\n+use rustc_ast::tokenstream::{TokenStream, TokenTree, TokenTreeCursor};\n use rustc_ast::{ast, ptr};\n use rustc_ast_pretty::pprust;\n use rustc_span::{\n@@ -736,7 +736,7 @@ impl MacroArgParser {\n         self.buf.clear();\n     }\n \n-    fn add_meta_variable(&mut self, iter: &mut Cursor) -> Option<()> {\n+    fn add_meta_variable(&mut self, iter: &mut TokenTreeCursor) -> Option<()> {\n         match iter.next() {\n             Some(TokenTree::Token(\n                 Token {\n@@ -768,7 +768,7 @@ impl MacroArgParser {\n         &mut self,\n         inner: Vec<ParsedMacroArg>,\n         delim: Delimiter,\n-        iter: &mut Cursor,\n+        iter: &mut TokenTreeCursor,\n     ) -> Option<()> {\n         let mut buffer = String::new();\n         let mut first = true;\n@@ -1121,7 +1121,7 @@ pub(crate) fn macro_style(mac: &ast::MacCall, context: &RewriteContext<'_>) -> D\n // Currently we do not attempt to parse any further than that.\n #[derive(new)]\n struct MacroParser {\n-    toks: Cursor,\n+    toks: TokenTreeCursor,\n }\n \n impl MacroParser {"}]}