{"sha": "de46b247585999ae70674f1fa0543d62f2889c7f", "node_id": "MDY6Q29tbWl0NzI0NzEyOmRlNDZiMjQ3NTg1OTk5YWU3MDY3NGYxZmEwNTQzZDYyZjI4ODljN2Y=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-12T23:32:00Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-17T08:16:49Z"}, "message": "Introduce `string_reader.parse_all_token_trees()`.", "tree": {"sha": "62272c5091275b581dbbc4558ff47256f6feda35", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/62272c5091275b581dbbc4558ff47256f6feda35"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/de46b247585999ae70674f1fa0543d62f2889c7f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/de46b247585999ae70674f1fa0543d62f2889c7f", "html_url": "https://github.com/rust-lang/rust/commit/de46b247585999ae70674f1fa0543d62f2889c7f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/de46b247585999ae70674f1fa0543d62f2889c7f/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6466f55ebca18e3795800d8d606622d36f6ee763", "url": "https://api.github.com/repos/rust-lang/rust/commits/6466f55ebca18e3795800d8d606622d36f6ee763", "html_url": "https://github.com/rust-lang/rust/commit/6466f55ebca18e3795800d8d606622d36f6ee763"}], "stats": {"total": 219, "additions": 192, "deletions": 27}, "files": [{"sha": "89525b27ed36af7d5f50d4e1b1b6c152a3fd7c2b", "filename": "src/librustc_save_analysis/span_utils.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Fspan_utils.rs?ref=de46b247585999ae70674f1fa0543d62f2889c7f", "patch": "@@ -17,9 +17,9 @@ use std::env;\n use std::path::Path;\n \n use syntax::ast;\n-use syntax::parse::lexer::{self, Reader, StringReader};\n+use syntax::parse::filemap_to_tts;\n+use syntax::parse::lexer::{self, StringReader};\n use syntax::parse::token::{self, Token};\n-use syntax::parse::parser::Parser;\n use syntax::symbol::keywords;\n use syntax::tokenstream::TokenTree;\n use syntax_pos::*;\n@@ -89,9 +89,9 @@ impl<'a> SpanUtils<'a> {\n     }\n \n     fn span_to_tts(&self, span: Span) -> Vec<TokenTree> {\n-        let srdr = self.retokenise_span(span);\n-        let mut p = Parser::new(&self.sess.parse_sess, Box::new(srdr), None, false);\n-        p.parse_all_token_trees().expect(\"Couldn't re-parse span\")\n+        let filename = String::from(\"<anon-dxr>\");\n+        let filemap = self.sess.codemap().new_filemap(filename, None, self.snippet(span));\n+        filemap_to_tts(&self.sess.parse_sess, filemap)\n     }\n \n     // Re-parses a path and returns the span for the last identifier in the path"}, {"sha": "ca4b2caaf552e5b81feaeda7adaa4d9d8f17b8f5", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 3, "deletions": 7, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=de46b247585999ae70674f1fa0543d62f2889c7f", "patch": "@@ -21,7 +21,7 @@ use ext::base::*;\n use feature_gate::{self, Features};\n use fold;\n use fold::*;\n-use parse::{ParseSess, DirectoryOwnership, PResult, lexer};\n+use parse::{ParseSess, DirectoryOwnership, PResult, filemap_to_tts};\n use parse::parser::Parser;\n use parse::token;\n use print::pprust;\n@@ -645,12 +645,8 @@ fn tts_for_attr(attr: &ast::Attribute, parse_sess: &ParseSess) -> Vec<TokenTree>\n }\n \n fn string_to_tts(text: String, parse_sess: &ParseSess) -> Vec<TokenTree> {\n-    let filemap = parse_sess.codemap()\n-                            .new_filemap(String::from(\"<macro expansion>\"), None, text);\n-\n-    let lexer = lexer::StringReader::new(parse_sess, filemap);\n-    let mut parser = Parser::new(parse_sess, Box::new(lexer), None, false);\n-    panictry!(parser.parse_all_token_trees())\n+    let filename = String::from(\"<macro expansion>\");\n+    filemap_to_tts(parse_sess, parse_sess.codemap().new_filemap(filename, None, text))\n }\n \n impl<'a, 'b> Folder for InvocationCollector<'a, 'b> {"}, {"sha": "c97b8ddf91972ac27e636e2a09e72fb0a2bf9048", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=de46b247585999ae70674f1fa0543d62f2889c7f", "patch": "@@ -13,10 +13,8 @@ pub use self::CommentStyle::*;\n use ast;\n use codemap::CodeMap;\n use syntax_pos::{BytePos, CharPos, Pos};\n-use parse::lexer::is_block_doc_comment;\n-use parse::lexer::{StringReader, TokenAndSpan};\n-use parse::lexer::{is_pattern_whitespace, Reader};\n-use parse::{lexer, ParseSess};\n+use parse::lexer::{is_block_doc_comment, is_pattern_whitespace};\n+use parse::lexer::{self, ParseSess, StringReader, TokenAndSpan};\n use print::pprust;\n use str::char_at;\n "}, {"sha": "6c6161998d711fa9a2bee421edb1d87dae03e16c", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 40, "deletions": 4, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=de46b247585999ae70674f1fa0543d62f2889c7f", "patch": "@@ -26,6 +26,7 @@ use std::rc::Rc;\n pub use ext::tt::transcribe::{TtReader, new_tt_reader};\n \n pub mod comments;\n+mod tokentrees;\n mod unicode_chars;\n \n pub trait Reader {\n@@ -105,9 +106,44 @@ pub struct StringReader<'a> {\n     // cache a direct reference to the source text, so that we don't have to\n     // retrieve it via `self.filemap.src.as_ref().unwrap()` all the time.\n     source_text: Rc<String>,\n+    /// Stack of open delimiters and their spans. Used for error message.\n+    token: token::Token,\n+    span: Span,\n+    open_braces: Vec<(token::DelimToken, Span)>,\n }\n \n-impl<'a> Reader for StringReader<'a> {\n+impl<'a> StringReader<'a> {\n+    fn next_token(&mut self) -> TokenAndSpan where Self: Sized {\n+        let res = self.try_next_token();\n+        self.unwrap_or_abort(res)\n+    }\n+    fn unwrap_or_abort(&mut self, res: Result<TokenAndSpan, ()>) -> TokenAndSpan {\n+        match res {\n+            Ok(tok) => tok,\n+            Err(_) => {\n+                self.emit_fatal_errors();\n+                panic!(FatalError);\n+            }\n+        }\n+    }\n+    fn try_real_token(&mut self) -> Result<TokenAndSpan, ()> {\n+        let mut t = self.try_next_token()?;\n+        loop {\n+            match t.tok {\n+                token::Whitespace | token::Comment | token::Shebang(_) => {\n+                    t = self.try_next_token()?;\n+                }\n+                _ => break,\n+            }\n+        }\n+        self.token = t.tok.clone();\n+        self.span = t.sp;\n+        Ok(t)\n+    }\n+    pub fn real_token(&mut self) -> TokenAndSpan {\n+        let res = self.try_real_token();\n+        self.unwrap_or_abort(res)\n+    }\n     fn is_eof(&self) -> bool {\n         if self.ch.is_none() {\n             return true;\n@@ -131,9 +167,6 @@ impl<'a> Reader for StringReader<'a> {\n     fn fatal(&self, m: &str) -> FatalError {\n         self.fatal_span(self.peek_span, m)\n     }\n-    fn err(&self, m: &str) {\n-        self.err_span(self.peek_span, m)\n-    }\n     fn emit_fatal_errors(&mut self) {\n         for err in &mut self.fatal_errs {\n             err.emit();\n@@ -209,6 +242,9 @@ impl<'a> StringReader<'a> {\n             peek_span: syntax_pos::DUMMY_SP,\n             source_text: source_text,\n             fatal_errs: Vec::new(),\n+            token: token::Eof,\n+            span: syntax_pos::DUMMY_SP,\n+            open_braces: Vec::new(),\n         }\n     }\n "}, {"sha": "7b6f00e0e8265c7415394698c3480609c55dd562", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "added", "additions": 138, "deletions": 0, "changes": 138, "blob_url": "https://github.com/rust-lang/rust/blob/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=de46b247585999ae70674f1fa0543d62f2889c7f", "patch": "@@ -0,0 +1,138 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use print::pprust::token_to_string;\n+use parse::lexer::StringReader;\n+use parse::{token, PResult};\n+use syntax_pos::Span;\n+use tokenstream::{Delimited, TokenTree};\n+\n+use std::rc::Rc;\n+\n+impl<'a> StringReader<'a> {\n+    // Parse a stream of tokens into a list of `TokenTree`s, up to an `Eof`.\n+    pub fn parse_all_token_trees(&mut self) -> PResult<'a, Vec<TokenTree>> {\n+        let mut tts = Vec::new();\n+        while self.token != token::Eof {\n+            tts.push(self.parse_token_tree()?);\n+        }\n+        Ok(tts)\n+    }\n+\n+    // Parse a stream of tokens into a list of `TokenTree`s, up to a `CloseDelim`.\n+    fn parse_token_trees_until_close_delim(&mut self) -> Vec<TokenTree> {\n+        let mut tts = vec![];\n+        loop {\n+            if let token::CloseDelim(..) = self.token {\n+                return tts;\n+            }\n+            match self.parse_token_tree() {\n+                Ok(tt) => tts.push(tt),\n+                Err(mut e) => {\n+                    e.emit();\n+                    return tts;\n+                }\n+            }\n+        }\n+    }\n+\n+    fn parse_token_tree(&mut self) -> PResult<'a, TokenTree> {\n+        match self.token {\n+            token::Eof => {\n+                let msg = \"this file contains an un-closed delimiter\";\n+                let mut err = self.sess.span_diagnostic.struct_span_err(self.span, msg);\n+                for &(_, sp) in &self.open_braces {\n+                    err.span_help(sp, \"did you mean to close this delimiter?\");\n+                }\n+                Err(err)\n+            },\n+            token::OpenDelim(delim) => {\n+                // The span for beginning of the delimited section\n+                let pre_span = self.span;\n+\n+                // Parse the open delimiter.\n+                self.open_braces.push((delim, self.span));\n+                let open_span = self.span;\n+                self.real_token();\n+\n+                // Parse the token trees within the delimiters.\n+                // We stop at any delimiter so we can try to recover if the user\n+                // uses an incorrect delimiter.\n+                let tts = self.parse_token_trees_until_close_delim();\n+\n+                let close_span = self.span;\n+                // Expand to cover the entire delimited token tree\n+                let span = Span { hi: close_span.hi, ..pre_span };\n+\n+                match self.token {\n+                    // Correct delimiter.\n+                    token::CloseDelim(d) if d == delim => {\n+                        self.open_braces.pop().unwrap();\n+\n+                        // Parse the close delimiter.\n+                        self.real_token();\n+                    }\n+                    // Incorrect delimiter.\n+                    token::CloseDelim(other) => {\n+                        let token_str = token_to_string(&self.token);\n+                        let msg = format!(\"incorrect close delimiter: `{}`\", token_str);\n+                        let mut err = self.sess.span_diagnostic.struct_span_err(self.span, &msg);\n+                        // This is a conservative error: only report the last unclosed delimiter.\n+                        // The previous unclosed delimiters could actually be closed! The parser\n+                        // just hasn't gotten to them yet.\n+                        if let Some(&(_, sp)) = self.open_braces.last() {\n+                            err.span_note(sp, \"unclosed delimiter\");\n+                        };\n+                        err.emit();\n+\n+                        self.open_braces.pop().unwrap();\n+\n+                        // If the incorrect delimiter matches an earlier opening\n+                        // delimiter, then don't consume it (it can be used to\n+                        // close the earlier one). Otherwise, consume it.\n+                        // E.g., we try to recover from:\n+                        // fn foo() {\n+                        //     bar(baz(\n+                        // }  // Incorrect delimiter but matches the earlier `{`\n+                        if !self.open_braces.iter().any(|&(b, _)| b == other) {\n+                            self.real_token();\n+                        }\n+                    }\n+                    token::Eof => {\n+                        // Silently recover, the EOF token will be seen again\n+                        // and an error emitted then. Thus we don't pop from\n+                        // self.open_braces here.\n+                    },\n+                    _ => {}\n+                }\n+\n+                Ok(TokenTree::Delimited(span, Rc::new(Delimited {\n+                    delim: delim,\n+                    open_span: open_span,\n+                    tts: tts,\n+                    close_span: close_span,\n+                })))\n+            },\n+            token::CloseDelim(_) => {\n+                // An unexpected closing delimiter (i.e., there is no\n+                // matching opening delimiter).\n+                let token_str = token_to_string(&self.token);\n+                let msg = format!(\"unexpected close delimiter: `{}`\", token_str);\n+                let err = self.sess.span_diagnostic.struct_span_err(self.span, &msg);\n+                Err(err)\n+            },\n+            _ => {\n+                let tt = TokenTree::Token(self.span, self.token.clone());\n+                self.real_token();\n+                Ok(tt)\n+            }\n+        }\n+    }\n+}"}, {"sha": "500e8285b4c05b6e3e1a1e93ed383224227d56ae", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 4, "deletions": 7, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/de46b247585999ae70674f1fa0543d62f2889c7f/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=de46b247585999ae70674f1fa0543d62f2889c7f", "patch": "@@ -219,13 +219,10 @@ fn file_to_filemap(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n }\n \n /// Given a filemap, produce a sequence of token-trees\n-pub fn filemap_to_tts(sess: &ParseSess, filemap: Rc<FileMap>)\n-    -> Vec<tokenstream::TokenTree> {\n-    // it appears to me that the cfg doesn't matter here... indeed,\n-    // parsing tt's probably shouldn't require a parser at all.\n-    let srdr = lexer::StringReader::new(sess, filemap);\n-    let mut p1 = Parser::new(sess, Box::new(srdr), None, false);\n-    panictry!(p1.parse_all_token_trees())\n+pub fn filemap_to_tts(sess: &ParseSess, filemap: Rc<FileMap>) -> Vec<tokenstream::TokenTree> {\n+    let mut srdr = lexer::StringReader::new(sess, filemap);\n+    srdr.real_token();\n+    panictry!(srdr.parse_all_token_trees())\n }\n \n /// Given tts and the ParseSess, produce a parser"}]}