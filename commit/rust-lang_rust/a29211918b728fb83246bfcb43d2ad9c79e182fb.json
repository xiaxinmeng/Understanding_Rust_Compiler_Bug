{"sha": "a29211918b728fb83246bfcb43d2ad9c79e182fb", "node_id": "MDY6Q29tbWl0NzI0NzEyOmEyOTIxMTkxOGI3MjhmYjgzMjQ2YmZjYjQzZDJhZDljNzllMTgyZmI=", "commit": {"author": {"name": "darksv", "email": "darek969-12@o2.pl", "date": "2018-09-15T11:35:55Z"}, "committer": {"name": "darksv", "email": "darek969-12@o2.pl", "date": "2018-09-15T11:35:55Z"}, "message": "create separated mod for reparsing functionality", "tree": {"sha": "cff6617f8d54570058a8aa45a98a039424f7b4ea", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/cff6617f8d54570058a8aa45a98a039424f7b4ea"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a29211918b728fb83246bfcb43d2ad9c79e182fb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a29211918b728fb83246bfcb43d2ad9c79e182fb", "html_url": "https://github.com/rust-lang/rust/commit/a29211918b728fb83246bfcb43d2ad9c79e182fb", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a29211918b728fb83246bfcb43d2ad9c79e182fb/comments", "author": {"login": "darksv", "id": 6718130, "node_id": "MDQ6VXNlcjY3MTgxMzA=", "avatar_url": "https://avatars.githubusercontent.com/u/6718130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/darksv", "html_url": "https://github.com/darksv", "followers_url": "https://api.github.com/users/darksv/followers", "following_url": "https://api.github.com/users/darksv/following{/other_user}", "gists_url": "https://api.github.com/users/darksv/gists{/gist_id}", "starred_url": "https://api.github.com/users/darksv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/darksv/subscriptions", "organizations_url": "https://api.github.com/users/darksv/orgs", "repos_url": "https://api.github.com/users/darksv/repos", "events_url": "https://api.github.com/users/darksv/events{/privacy}", "received_events_url": "https://api.github.com/users/darksv/received_events", "type": "User", "site_admin": false}, "committer": {"login": "darksv", "id": 6718130, "node_id": "MDQ6VXNlcjY3MTgxMzA=", "avatar_url": "https://avatars.githubusercontent.com/u/6718130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/darksv", "html_url": "https://github.com/darksv", "followers_url": "https://api.github.com/users/darksv/followers", "following_url": "https://api.github.com/users/darksv/following{/other_user}", "gists_url": "https://api.github.com/users/darksv/gists{/gist_id}", "starred_url": "https://api.github.com/users/darksv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/darksv/subscriptions", "organizations_url": "https://api.github.com/users/darksv/orgs", "repos_url": "https://api.github.com/users/darksv/repos", "events_url": "https://api.github.com/users/darksv/events{/privacy}", "received_events_url": "https://api.github.com/users/darksv/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bc94bf95ce858ef247ebee006d50cfdc33f6bf5f", "url": "https://api.github.com/repos/rust-lang/rust/commits/bc94bf95ce858ef247ebee006d50cfdc33f6bf5f", "html_url": "https://github.com/rust-lang/rust/commit/bc94bf95ce858ef247ebee006d50cfdc33f6bf5f"}], "stats": {"total": 370, "additions": 200, "deletions": 170}, "files": [{"sha": "014cdafee7f9815cd81ab097fe29830fdc63d518", "filename": "crates/libsyntax2/src/lib.rs", "status": "modified", "additions": 5, "deletions": 170, "changes": 175, "blob_url": "https://github.com/rust-lang/rust/blob/a29211918b728fb83246bfcb43d2ad9c79e182fb/crates%2Flibsyntax2%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a29211918b728fb83246bfcb43d2ad9c79e182fb/crates%2Flibsyntax2%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Flibsyntax2%2Fsrc%2Flib.rs?ref=a29211918b728fb83246bfcb43d2ad9c79e182fb", "patch": "@@ -35,6 +35,7 @@ mod token_set;\n mod parser_api;\n mod grammar;\n mod parser_impl;\n+mod reparsing;\n \n mod syntax_kinds;\n mod yellow;\n@@ -49,12 +50,11 @@ pub use {\n     lexer::{tokenize, Token},\n     syntax_kinds::SyntaxKind,\n     yellow::{SyntaxNode, SyntaxNodeRef, OwnedRoot, RefRoot, TreeRoot, SyntaxError},\n+    reparsing::AtomEdit,\n };\n \n use {\n-    SyntaxKind::*,\n     yellow::{GreenNode, SyntaxRoot},\n-    parser_api::Parser,\n };\n \n #[derive(Clone, Debug)]\n@@ -82,55 +82,11 @@ impl File {\n         self.incremental_reparse(edit).unwrap_or_else(|| self.full_reparse(edit))\n     }\n     pub fn incremental_reparse(&self, edit: &AtomEdit) -> Option<File> {\n-        let (node, green, new_errors) =\n-            self.reparse_leaf(&edit).or_else(|| self.reparse_block(&edit))?;\n-\n-        let green_root = node.replace_with(green);\n-        let errors = merge_errors(self.errors(), new_errors, node, edit);\n-        Some(File::new(green_root, errors))\n-    }\n-    fn reparse_leaf(&self, edit: &AtomEdit) -> Option<(SyntaxNodeRef, GreenNode, Vec<SyntaxError>)> {\n-        let node = algo::find_covering_node(self.syntax(), edit.delete);\n-        match node.kind() {\n-            | WHITESPACE\n-            | COMMENT\n-            | DOC_COMMENT\n-            | IDENT\n-            | STRING\n-            | RAW_STRING => {\n-                let text = get_text_after_edit(node, &edit);\n-                let tokens = tokenize(&text);\n-                let token = match tokens[..] {\n-                    [token] if token.kind == node.kind() => token,\n-                    _ => return None,\n-                };\n-\n-                if token.kind == IDENT && is_contextual_kw(&text) {\n-                    return None;\n-                }\n-\n-                let green = GreenNode::new_leaf(node.kind(), &text);\n-                let new_errors = vec![];\n-                Some((node, green, new_errors))\n-            },\n-            _ => None,\n-        }\n-    }\n-    fn reparse_block(&self, edit: &AtomEdit) -> Option<(SyntaxNodeRef, GreenNode, Vec<SyntaxError>)> {\n-        let (node, reparser) = find_reparsable_node(self.syntax(), edit.delete)?;\n-        let text = get_text_after_edit(node, &edit);\n-        let tokens = tokenize(&text);\n-        if !is_balanced(&tokens) {\n-            return None;\n-        }\n-        let (green, new_errors) =\n-            parser_impl::parse_with::<yellow::GreenBuilder>(\n-                &text, &tokens, reparser,\n-            );\n-        Some((node, green, new_errors))\n+        reparsing::incremental_reparse(self.syntax(), edit, self.errors())\n+            .map(|(green_node, errors)| File::new(green_node, errors))\n     }\n     fn full_reparse(&self, edit: &AtomEdit) -> File {\n-        let text = replace_range(self.syntax().text().to_string(), edit.delete, &edit.insert);\n+        let text = text_utils::replace_range(self.syntax().text().to_string(), edit.delete, &edit.insert);\n         File::parse(&text)\n     }\n     pub fn ast(&self) -> ast::Root {\n@@ -143,124 +99,3 @@ impl File {\n         self.syntax().root.syntax_root().errors.clone()\n     }\n }\n-\n-#[derive(Debug, Clone)]\n-pub struct AtomEdit {\n-    pub delete: TextRange,\n-    pub insert: String,\n-}\n-\n-impl AtomEdit {\n-    pub fn replace(range: TextRange, replace_with: String) -> AtomEdit {\n-        AtomEdit { delete: range, insert: replace_with }\n-    }\n-\n-    pub fn delete(range: TextRange) -> AtomEdit {\n-        AtomEdit::replace(range, String::new())\n-    }\n-\n-    pub fn insert(offset: TextUnit, text: String) -> AtomEdit {\n-        AtomEdit::replace(TextRange::offset_len(offset, 0.into()), text)\n-    }\n-}\n-\n-fn get_text_after_edit(node: SyntaxNodeRef, edit: &AtomEdit) -> String {\n-    replace_range(\n-        node.text().to_string(),\n-        edit.delete - node.range().start(),\n-        &edit.insert,\n-    )\n-}\n-\n-fn is_contextual_kw(text: &str) -> bool {\n-    match text {\n-        | \"auto\"\n-        | \"default\"\n-        | \"union\" => true,\n-        _ => false,\n-    }\n-}\n-\n-fn find_reparsable_node(node: SyntaxNodeRef, range: TextRange) -> Option<(SyntaxNodeRef, fn(&mut Parser))> {\n-    let node = algo::find_covering_node(node, range);\n-    return algo::ancestors(node)\n-        .filter_map(|node| reparser(node).map(|r| (node, r)))\n-        .next();\n-\n-    fn reparser(node: SyntaxNodeRef) -> Option<fn(&mut Parser)> {\n-        let res = match node.kind() {\n-            BLOCK => grammar::block,\n-            NAMED_FIELD_DEF_LIST => grammar::named_field_def_list,\n-            NAMED_FIELD_LIST => grammar::named_field_list,\n-            ENUM_VARIANT_LIST => grammar::enum_variant_list,\n-            MATCH_ARM_LIST => grammar::match_arm_list,\n-            USE_TREE_LIST => grammar::use_tree_list,\n-            EXTERN_ITEM_LIST => grammar::extern_item_list,\n-            TOKEN_TREE if node.first_child().unwrap().kind() == L_CURLY => grammar::token_tree,\n-            ITEM_LIST => {\n-                let parent = node.parent().unwrap();\n-                match parent.kind() {\n-                    IMPL_ITEM => grammar::impl_item_list,\n-                    TRAIT_DEF => grammar::trait_item_list,\n-                    MODULE => grammar::mod_item_list,\n-                    _ => return None,\n-                }\n-            },\n-            _ => return None,\n-        };\n-        Some(res)\n-    }\n-}\n-\n-pub /*(meh)*/ fn replace_range(mut text: String, range: TextRange, replace_with: &str) -> String {\n-    let start = u32::from(range.start()) as usize;\n-    let end = u32::from(range.end()) as usize;\n-    text.replace_range(start..end, replace_with);\n-    text\n-}\n-\n-fn is_balanced(tokens: &[Token]) -> bool {\n-    if tokens.len() == 0\n-       || tokens.first().unwrap().kind != L_CURLY\n-       || tokens.last().unwrap().kind != R_CURLY {\n-        return false\n-    }\n-    let mut balance = 0usize;\n-    for t in tokens.iter() {\n-        match t.kind {\n-            L_CURLY => balance += 1,\n-            R_CURLY => balance = match balance.checked_sub(1) {\n-                Some(b) => b,\n-                None => return false,\n-            },\n-            _ => (),\n-        }\n-    }\n-    balance == 0\n-}\n-\n-fn merge_errors(\n-    old_errors: Vec<SyntaxError>,\n-    new_errors: Vec<SyntaxError>,\n-    old_node: SyntaxNodeRef,\n-    edit: &AtomEdit,\n-) -> Vec<SyntaxError> {\n-    let mut res = Vec::new();\n-    for e in old_errors {\n-        if e.offset <= old_node.range().start() {\n-            res.push(e)\n-        } else if e.offset >= old_node.range().end() {\n-            res.push(SyntaxError {\n-                msg: e.msg,\n-                offset: e.offset + TextUnit::of_str(&edit.insert) - edit.delete.len(),\n-            })\n-        }\n-    }\n-    for e in new_errors {\n-        res.push(SyntaxError {\n-            msg: e.msg,\n-            offset: e.offset + old_node.range().start(),\n-        })\n-    }\n-    res\n-}"}, {"sha": "723ea2b8ba82c848e90514cadd09e331b5c9e198", "filename": "crates/libsyntax2/src/reparsing.rs", "status": "added", "additions": 188, "deletions": 0, "changes": 188, "blob_url": "https://github.com/rust-lang/rust/blob/a29211918b728fb83246bfcb43d2ad9c79e182fb/crates%2Flibsyntax2%2Fsrc%2Freparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a29211918b728fb83246bfcb43d2ad9c79e182fb/crates%2Flibsyntax2%2Fsrc%2Freparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Flibsyntax2%2Fsrc%2Freparsing.rs?ref=a29211918b728fb83246bfcb43d2ad9c79e182fb", "patch": "@@ -0,0 +1,188 @@\n+use algo;\n+use grammar;\n+use lexer::{tokenize, Token};\n+use text_unit::{TextRange, TextUnit};\n+use yellow::{self, SyntaxNodeRef, GreenNode, SyntaxError};\n+use parser_impl;\n+use parser_api::Parser;\n+use {\n+    SyntaxKind::*,\n+};\n+use text_utils::replace_range;\n+\n+#[derive(Debug, Clone)]\n+pub struct AtomEdit {\n+    pub delete: TextRange,\n+    pub insert: String,\n+}\n+\n+impl AtomEdit {\n+    pub fn replace(range: TextRange, replace_with: String) -> AtomEdit {\n+        AtomEdit { delete: range, insert: replace_with }\n+    }\n+\n+    pub fn delete(range: TextRange) -> AtomEdit {\n+        AtomEdit::replace(range, String::new())\n+    }\n+\n+    pub fn insert(offset: TextUnit, text: String) -> AtomEdit {\n+        AtomEdit::replace(TextRange::offset_len(offset, 0.into()), text)\n+    }\n+}\n+\n+pub(crate) fn incremental_reparse(\n+    node: SyntaxNodeRef,\n+    edit: &AtomEdit,\n+    errors: Vec<SyntaxError>,\n+) -> Option<(GreenNode, Vec<SyntaxError>)> {\n+    let (node, green, new_errors) =\n+        reparse_leaf(node, &edit).or_else(|| reparse_block(node, &edit))?;\n+    let green_root = node.replace_with(green);\n+    let errors = merge_errors(errors, new_errors, node, edit);\n+    Some((green_root, errors))\n+}\n+\n+fn reparse_leaf<'node>(\n+    node: SyntaxNodeRef<'node>,\n+    edit: &AtomEdit,\n+) -> Option<(SyntaxNodeRef<'node>, GreenNode, Vec<SyntaxError>)> {\n+    let node = algo::find_covering_node(node, edit.delete);\n+    match node.kind() {\n+        | WHITESPACE\n+        | COMMENT\n+        | DOC_COMMENT\n+        | IDENT\n+        | STRING\n+        | RAW_STRING => {\n+            let text = get_text_after_edit(node, &edit);\n+            let tokens = tokenize(&text);\n+            let token = match tokens[..] {\n+                [token] if token.kind == node.kind() => token,\n+                _ => return None,\n+            };\n+\n+            if token.kind == IDENT && is_contextual_kw(&text) {\n+                return None;\n+            }\n+\n+            let green = GreenNode::new_leaf(node.kind(), &text);\n+            let new_errors = vec![];\n+            Some((node, green, new_errors))\n+        }\n+        _ => None,\n+    }\n+}\n+\n+fn reparse_block<'node>(\n+    node: SyntaxNodeRef<'node>,\n+    edit: &AtomEdit,\n+) -> Option<(SyntaxNodeRef<'node>, GreenNode, Vec<SyntaxError>)> {\n+    let (node, reparser) = find_reparsable_node(node, edit.delete)?;\n+    let text = get_text_after_edit(node, &edit);\n+    let tokens = tokenize(&text);\n+    if !is_balanced(&tokens) {\n+        return None;\n+    }\n+    let (green, new_errors) =\n+        parser_impl::parse_with::<yellow::GreenBuilder>(\n+            &text, &tokens, reparser,\n+        );\n+    Some((node, green, new_errors))\n+}\n+\n+fn get_text_after_edit(node: SyntaxNodeRef, edit: &AtomEdit) -> String {\n+    replace_range(\n+        node.text().to_string(),\n+        edit.delete - node.range().start(),\n+        &edit.insert,\n+    )\n+}\n+\n+fn is_contextual_kw(text: &str) -> bool {\n+    match text {\n+        | \"auto\"\n+        | \"default\"\n+        | \"union\" => true,\n+        _ => false,\n+    }\n+}\n+\n+fn find_reparsable_node<'node>(\n+    node: SyntaxNodeRef<'node>,\n+    range: TextRange,\n+) -> Option<(SyntaxNodeRef<'node>, fn(&mut Parser))> {\n+    let node = algo::find_covering_node(node, range);\n+    return algo::ancestors(node)\n+        .filter_map(|node| reparser(node).map(|r| (node, r)))\n+        .next();\n+\n+    fn reparser(node: SyntaxNodeRef) -> Option<fn(&mut Parser)> {\n+        let res = match node.kind() {\n+            BLOCK => grammar::block,\n+            NAMED_FIELD_DEF_LIST => grammar::named_field_def_list,\n+            NAMED_FIELD_LIST => grammar::named_field_list,\n+            ENUM_VARIANT_LIST => grammar::enum_variant_list,\n+            MATCH_ARM_LIST => grammar::match_arm_list,\n+            USE_TREE_LIST => grammar::use_tree_list,\n+            EXTERN_ITEM_LIST => grammar::extern_item_list,\n+            TOKEN_TREE if node.first_child().unwrap().kind() == L_CURLY => grammar::token_tree,\n+            ITEM_LIST => {\n+                let parent = node.parent().unwrap();\n+                match parent.kind() {\n+                    IMPL_ITEM => grammar::impl_item_list,\n+                    TRAIT_DEF => grammar::trait_item_list,\n+                    MODULE => grammar::mod_item_list,\n+                    _ => return None,\n+                }\n+            }\n+            _ => return None,\n+        };\n+        Some(res)\n+    }\n+}\n+\n+fn is_balanced(tokens: &[Token]) -> bool {\n+    if tokens.len() == 0\n+        || tokens.first().unwrap().kind != L_CURLY\n+        || tokens.last().unwrap().kind != R_CURLY {\n+        return false;\n+    }\n+    let mut balance = 0usize;\n+    for t in tokens.iter() {\n+        match t.kind {\n+            L_CURLY => balance += 1,\n+            R_CURLY => balance = match balance.checked_sub(1) {\n+                Some(b) => b,\n+                None => return false,\n+            },\n+            _ => (),\n+        }\n+    }\n+    balance == 0\n+}\n+\n+fn merge_errors(\n+    old_errors: Vec<SyntaxError>,\n+    new_errors: Vec<SyntaxError>,\n+    old_node: SyntaxNodeRef,\n+    edit: &AtomEdit,\n+) -> Vec<SyntaxError> {\n+    let mut res = Vec::new();\n+    for e in old_errors {\n+        if e.offset <= old_node.range().start() {\n+            res.push(e)\n+        } else if e.offset >= old_node.range().end() {\n+            res.push(SyntaxError {\n+                msg: e.msg,\n+                offset: e.offset + TextUnit::of_str(&edit.insert) - edit.delete.len(),\n+            })\n+        }\n+    }\n+    for e in new_errors {\n+        res.push(SyntaxError {\n+            msg: e.msg,\n+            offset: e.offset + old_node.range().start(),\n+        })\n+    }\n+    res\n+}"}, {"sha": "58ae1e43e0a119ed559a84fddebf6349c25ec3fd", "filename": "crates/libsyntax2/src/text_utils.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/a29211918b728fb83246bfcb43d2ad9c79e182fb/crates%2Flibsyntax2%2Fsrc%2Ftext_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a29211918b728fb83246bfcb43d2ad9c79e182fb/crates%2Flibsyntax2%2Fsrc%2Ftext_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Flibsyntax2%2Fsrc%2Ftext_utils.rs?ref=a29211918b728fb83246bfcb43d2ad9c79e182fb", "patch": "@@ -17,3 +17,10 @@ pub fn intersect(r1: TextRange, r2: TextRange) -> Option<TextRange> {\n         None\n     }\n }\n+\n+pub fn replace_range(mut text: String, range: TextRange, replace_with: &str) -> String {\n+    let start = u32::from(range.start()) as usize;\n+    let end = u32::from(range.end()) as usize;\n+    text.replace_range(start..end, replace_with);\n+    text\n+}\n\\ No newline at end of file"}]}