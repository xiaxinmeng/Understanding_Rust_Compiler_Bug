{"sha": "b08c40f4eedfd7fa880b78c6f4524e6ddabed18f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjA4YzQwZjRlZWRmZDdmYTg4MGI3OGM2ZjQ1MjRlNmRkYWJlZDE4Zg==", "commit": {"author": {"name": "Johannes Pfau", "email": "johannespfau@gmail.com", "date": "2019-03-02T19:14:54Z"}, "committer": {"name": "Johannes Pfau", "email": "jpfau@gcc.gnu.org", "date": "2019-03-02T19:14:54Z"}, "message": "PR d/89177 - Fix unaligned access in std.digest.murmurhash\n\nlibphobos/ChangeLog:\n\n2019-02-24  Johannes Pfau  <johannespfau@gmail.com>\n\n\t* src/std/digest/murmurhash.d: PR d/89177: Backport from upstream.\n\tFixes unaligned data access (PR d/89177).\n\nFrom-SVN: r269343", "tree": {"sha": "6092a39fcce06a3ef7effe12cdec5608ee23eed7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6092a39fcce06a3ef7effe12cdec5608ee23eed7"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b08c40f4eedfd7fa880b78c6f4524e6ddabed18f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b08c40f4eedfd7fa880b78c6f4524e6ddabed18f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b08c40f4eedfd7fa880b78c6f4524e6ddabed18f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b08c40f4eedfd7fa880b78c6f4524e6ddabed18f/comments", "author": {"login": "jpf91", "id": 583238, "node_id": "MDQ6VXNlcjU4MzIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/583238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jpf91", "html_url": "https://github.com/jpf91", "followers_url": "https://api.github.com/users/jpf91/followers", "following_url": "https://api.github.com/users/jpf91/following{/other_user}", "gists_url": "https://api.github.com/users/jpf91/gists{/gist_id}", "starred_url": "https://api.github.com/users/jpf91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jpf91/subscriptions", "organizations_url": "https://api.github.com/users/jpf91/orgs", "repos_url": "https://api.github.com/users/jpf91/repos", "events_url": "https://api.github.com/users/jpf91/events{/privacy}", "received_events_url": "https://api.github.com/users/jpf91/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "4716603bf875cee4b4703bd139b6c2c1a3154886", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4716603bf875cee4b4703bd139b6c2c1a3154886", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4716603bf875cee4b4703bd139b6c2c1a3154886"}], "stats": {"total": 127, "additions": 106, "deletions": 21}, "files": [{"sha": "fc91bb63985f09b37e20d251a9c83089f50b2a54", "filename": "libphobos/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b08c40f4eedfd7fa880b78c6f4524e6ddabed18f/libphobos%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b08c40f4eedfd7fa880b78c6f4524e6ddabed18f/libphobos%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libphobos%2FChangeLog?ref=b08c40f4eedfd7fa880b78c6f4524e6ddabed18f", "patch": "@@ -1,3 +1,8 @@\n+2019-03-02  Johannes Pfau  <johannespfau@gmail.com>\n+\n+\t* src/std/digest/murmurhash.d: PR d/89177: Backport from upstream.\n+\tFixes unaligned data access (PR d/89177).\n+\n 2019-02-19  Bernd Edlinger  <bernd.edlinger@hotmail.de>\n \n \t* src/Makefile.am: Avoid the -D option which is not available"}, {"sha": "b5b5bc74f9802dbd7d900ca4f1621eb8750571fe", "filename": "libphobos/src/std/digest/murmurhash.d", "status": "modified", "additions": 101, "deletions": 21, "changes": 122, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b08c40f4eedfd7fa880b78c6f4524e6ddabed18f/libphobos%2Fsrc%2Fstd%2Fdigest%2Fmurmurhash.d", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b08c40f4eedfd7fa880b78c6f4524e6ddabed18f/libphobos%2Fsrc%2Fstd%2Fdigest%2Fmurmurhash.d", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libphobos%2Fsrc%2Fstd%2Fdigest%2Fmurmurhash.d?ref=b08c40f4eedfd7fa880b78c6f4524e6ddabed18f", "patch": "@@ -9,7 +9,7 @@ The older MurmurHash 1 and 2 are currently not supported.\n \n MurmurHash3 comes in three flavors, listed in increasing order of throughput:\n $(UL\n-$(LI $(D MurmurHash3!32) produces a 32-bit value and is optimized for 32-bit architectures)\n+$(LI `MurmurHash3!32` produces a 32-bit value and is optimized for 32-bit architectures)\n $(LI $(D MurmurHash3!(128, 32)) produces a 128-bit value and is optimized for 32-bit architectures)\n $(LI $(D MurmurHash3!(128, 64)) produces a 128-bit value and is optimized for 64-bit architectures)\n )\n@@ -26,7 +26,7 @@ This module conforms to the APIs defined in $(MREF std, digest).\n \n This module publicly imports $(MREF std, digest) and can be used as a stand-alone module.\n \n-Source: $(PHOBOSSRC std/digest/_murmurhash.d)\n+Source: $(PHOBOSSRC std/digest/murmurhash.d)\n License: $(HTTP www.boost.org/LICENSE_1_0.txt, Boost License 1.0).\n Authors: Guillaume Chatelet\n References: $(LINK2 https://github.com/aappleby/smhasher, Reference implementation)\n@@ -38,6 +38,11 @@ $(BR) $(LINK2 https://en.wikipedia.org/wiki/MurmurHash, Wikipedia)\n  */\n module std.digest.murmurhash;\n \n+version (X86)\n+    version = HaveUnalignedLoads;\n+else version (X86_64)\n+    version = HaveUnalignedLoads;\n+\n ///\n @safe unittest\n {\n@@ -500,28 +505,75 @@ struct MurmurHash3(uint size /* 32 or 128 */ , uint opt = size_t.sizeof == 8 ? 6\n         // Buffer should never be full while entering this function.\n         assert(bufferSize < Element.sizeof);\n \n-        // Check if we have some leftover data in the buffer. Then fill the first block buffer.\n+        // Check if the incoming data doesn't fill up a whole block buffer.\n         if (bufferSize + data.length < Element.sizeof)\n         {\n             buffer.data[bufferSize .. bufferSize + data.length] = data[];\n             bufferSize += data.length;\n             return;\n         }\n-        const bufferLeeway = Element.sizeof - bufferSize;\n-        assert(bufferLeeway <= Element.sizeof);\n-        buffer.data[bufferSize .. $] = data[0 .. bufferLeeway];\n-        putElement(buffer.block);\n-        data = data[bufferLeeway .. $];\n+\n+        // Check if there's some leftover data in the first block buffer, and\n+        // fill the remaining space first.\n+        if (bufferSize != 0)\n+        {\n+            const bufferLeeway = Element.sizeof - bufferSize;\n+            buffer.data[bufferSize .. $] = data[0 .. bufferLeeway];\n+            putElement(buffer.block);\n+            element_count += Element.sizeof;\n+            data = data[bufferLeeway .. $];\n+        }\n \n         // Do main work: process chunks of `Element.sizeof` bytes.\n         const numElements = data.length / Element.sizeof;\n         const remainderStart = numElements * Element.sizeof;\n-        foreach (ref const Element block; cast(const(Element[]))(data[0 .. remainderStart]))\n+        version (HaveUnalignedLoads)\n         {\n-            putElement(block);\n+            foreach (ref const Element block; cast(const(Element[])) data[0 .. remainderStart])\n+            {\n+                putElement(block);\n+            }\n         }\n-        // +1 for bufferLeeway Element.\n-        element_count += (numElements + 1) * Element.sizeof;\n+        else\n+        {\n+            void processChunks(T)() @trusted\n+            {\n+                alias TChunk = T[Element.sizeof / T.sizeof];\n+                foreach (ref const chunk; cast(const(TChunk[])) data[0 .. remainderStart])\n+                {\n+                    static if (T.alignof >= Element.alignof)\n+                    {\n+                        putElement(*cast(const(Element)*) chunk.ptr);\n+                    }\n+                    else\n+                    {\n+                        Element[1] alignedCopy = void;\n+                        (cast(T[]) alignedCopy)[] = chunk[];\n+                        putElement(alignedCopy[0]);\n+                    }\n+                }\n+            }\n+\n+            const startAddress = cast(size_t) data.ptr;\n+            static if (size >= 64)\n+            {\n+                if ((startAddress & 7) == 0)\n+                {\n+                    processChunks!ulong();\n+                    goto L_end;\n+                }\n+            }\n+            static assert(size >= 32);\n+            if ((startAddress & 3) == 0)\n+                processChunks!uint();\n+            else if ((startAddress & 1) == 0)\n+                processChunks!ushort();\n+            else\n+                processChunks!ubyte();\n+\n+L_end:\n+        }\n+        element_count += numElements * Element.sizeof;\n         data = data[remainderStart .. $];\n \n         // Now add remaining data to buffer.\n@@ -532,8 +584,8 @@ struct MurmurHash3(uint size /* 32 or 128 */ , uint opt = size_t.sizeof == 8 ? 6\n \n     /++\n     Finalizes the computation of the hash and returns the computed value.\n-    Note that $(D finish) can be called only once and that no subsequent calls\n-    to $(D put) is allowed.\n+    Note that `finish` can be called only once and that no subsequent calls\n+    to `put` is allowed.\n     +/\n     ubyte[Element.sizeof] finish() pure nothrow\n     {\n@@ -558,7 +610,7 @@ struct MurmurHash3(uint size /* 32 or 128 */ , uint opt = size_t.sizeof == 8 ? 6\n         static assert(isUnsigned!T);\n         debug assert(y >= 0 && y <= (T.sizeof * 8));\n     }\n-    body\n+    do\n     {\n         return ((x << y) | (x >> ((T.sizeof * 8) - y)));\n     }\n@@ -606,10 +658,35 @@ struct MurmurHash3(uint size /* 32 or 128 */ , uint opt = size_t.sizeof == 8 ? 6\n     }\n }\n \n-version (unittest)\n+\n+/// The convenient digest template allows for quick hashing of any data.\n+@safe unittest\n {\n-    import std.string : representation;\n+    ubyte[4] hashed = digest!(MurmurHash3!32)([1, 2, 3, 4]);\n+    assert(hashed == [0, 173, 69, 68]);\n+}\n \n+/**\n+One can also hash ubyte data piecewise by instanciating a hasher and call\n+the 'put' method.\n+*/\n+@safe unittest\n+{\n+    const(ubyte)[] data1 = [1, 2, 3];\n+    const(ubyte)[] data2 = [4, 5, 6, 7];\n+    // The incoming data will be buffered and hashed element by element.\n+    MurmurHash3!32 hasher;\n+    hasher.put(data1);\n+    hasher.put(data2);\n+    // The call to 'finish' ensures:\n+    // - the remaining bits are processed\n+    // - the hash gets finalized\n+    auto hashed = hasher.finish();\n+    assert(hashed == [181, 151, 88, 252]);\n+}\n+\n+version (unittest)\n+{\n     private auto hash(H, Element = H.Element)(string data)\n     {\n         H hasher;\n@@ -743,10 +820,13 @@ version (unittest)\n     // Pushing unaligned data and making sure the result is still coherent.\n     void testUnalignedHash(H)()\n     {\n-        immutable ubyte[1025] data = 0xAC;\n-        immutable alignedHash = digest!H(data[0 .. $ - 1]); // 0 .. 1023\n-        immutable unalignedHash = digest!H(data[1 .. $]); // 1 .. 1024\n-        assert(alignedHash == unalignedHash);\n+        immutable ubyte[1028] data = 0xAC;\n+        immutable alignedHash = digest!H(data[0 .. 1024]);\n+        foreach (i; 1 .. 5)\n+        {\n+            immutable unalignedHash = digest!H(data[i .. 1024 + i]);\n+            assert(alignedHash == unalignedHash);\n+        }\n     }\n \n     testUnalignedHash!(MurmurHash3!32)();"}]}