{"sha": "b0567726a311d3f2fcec5b62380675231cd610c9", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjA1Njc3MjZhMzExZDNmMmZjZWM1YjYyMzgwNjc1MjMxY2Q2MTBjOQ==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-08-30T11:11:02Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-08-30T11:11:02Z"}, "message": "[21/77] Replace SCALAR_INT_MODE_P checks with is_a <scalar_int_mode>\n\nThis patch replaces checks of \"SCALAR_INT_MODE_P (...)\" with\n\"is_a <scalar_int_mode> (..., &var)\" in cases where it becomes\nuseful to refer to the mode as a scalar_int_mode.  It also\nreplaces some checks for the two constituent classes (MODE_INT\nand MODE_PARTIAL_INT).\n\nThe patch also introduces is_a <scalar_int_mode> checks for some\nuses of HWI_COMPUTABLE_MODE_P, which is a subcondition of\nSCALAR_INT_MODE_P.\n\n2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n\t    Alan Hayward  <alan.hayward@arm.com>\n\t    David Sherwood  <david.sherwood@arm.com>\n\ngcc/\n\t* wide-int.h (int_traits<unsigned char>) New class.\n\t(int_traits<unsigned short>) Likewise.\n\t* cfgexpand.c (expand_debug_expr): Use is_a <scalar_int_mode>.\n\tUse GET_MODE_UNIT_PRECISION and remove redundant test for\n\tSCALAR_INT_MODE_P.\n\t* combine.c (set_nonzero_bits_and_sign_copies): Use\n\tis_a <scalar_int_mode>.\n\t(find_split_point): Likewise.\n\t(combine_simplify_rtx): Likewise.\n\t(simplify_logical): Likewise.\n\t(expand_compound_operation): Likewise.\n\t(expand_field_assignment): Likewise.\n\t(make_compound_operation): Likewise.\n\t(extended_count): Likewise.\n\t(change_zero_ext): Likewise.\n\t(simplify_comparison): Likewise.\n\t* dwarf2out.c (scompare_loc_descriptor): Likewise.\n\t(ucompare_loc_descriptor): Likewise.\n\t(minmax_loc_descriptor): Likewise.\n\t(mem_loc_descriptor): Likewise.\n\t(loc_descriptor): Likewise.\n\t* expmed.c (init_expmed_one_mode): Likewise.\n\t* lra-constraints.c (lra_constraint_offset): Likewise.\n\t* optabs.c (prepare_libcall_arg): Likewise.\n\t* postreload.c (move2add_note_store): Likewise.\n\t* reload.c (operands_match_p): Likewise.\n\t* rtl.h (load_extend_op): Likewise.\n\t* rtlhooks.c (gen_lowpart_general): Likewise.\n\t* simplify-rtx.c (simplify_truncation): Likewise.\n\t(simplify_unary_operation_1): Likewise.\n\t(simplify_binary_operation_1): Likewise.\n\t(simplify_const_binary_operation): Likewise.\n\t(simplify_const_relational_operation): Likewise.\n\t(simplify_subreg): Likewise.\n\t* stor-layout.c (bitwise_mode_for_mode): Likewise.\n\t* var-tracking.c (adjust_mems): Likewise.\n\t(prepare_call_arguments): Likewise.\n\ngcc/ada/\n\t* gcc-interface/decl.c (check_ok_for_atomic_type): Use\n\tis_a <scalar_int_mode>.\n\t* gcc-interface/trans.c (Pragma_to_gnu): Likewise.\n\t* gcc-interface/utils.c (gnat_type_for_mode): Likewise.\n\ngcc/fortran/\n\t* trans-types.c (gfc_type_for_mode): Use is_a <scalar_int_mode>.\n\nCo-Authored-By: Alan Hayward <alan.hayward@arm.com>\nCo-Authored-By: David Sherwood <david.sherwood@arm.com>\n\nFrom-SVN: r251473", "tree": {"sha": "7e4249e2fdac3895eaf6915bd78daf01006bc4c0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7e4249e2fdac3895eaf6915bd78daf01006bc4c0"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b0567726a311d3f2fcec5b62380675231cd610c9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b0567726a311d3f2fcec5b62380675231cd610c9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b0567726a311d3f2fcec5b62380675231cd610c9", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b0567726a311d3f2fcec5b62380675231cd610c9/comments", "author": null, "committer": null, "parents": [{"sha": "b4206259f10455603e0c90825566de1ea777c04a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b4206259f10455603e0c90825566de1ea777c04a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b4206259f10455603e0c90825566de1ea777c04a"}], "stats": {"total": 677, "additions": 381, "deletions": 296}, "files": [{"sha": "1e3b794f029b0d5a5cf8a03356910d64501cd0e5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 42, "deletions": 0, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -1,3 +1,45 @@\n+2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* wide-int.h (int_traits<unsigned char>) New class.\n+\t(int_traits<unsigned short>) Likewise.\n+\t* cfgexpand.c (expand_debug_expr): Use is_a <scalar_int_mode>.\n+\tUse GET_MODE_UNIT_PRECISION and remove redundant test for\n+\tSCALAR_INT_MODE_P.\n+\t* combine.c (set_nonzero_bits_and_sign_copies): Use\n+\tis_a <scalar_int_mode>.\n+\t(find_split_point): Likewise.\n+\t(combine_simplify_rtx): Likewise.\n+\t(simplify_logical): Likewise.\n+\t(expand_compound_operation): Likewise.\n+\t(expand_field_assignment): Likewise.\n+\t(make_compound_operation): Likewise.\n+\t(extended_count): Likewise.\n+\t(change_zero_ext): Likewise.\n+\t(simplify_comparison): Likewise.\n+\t* dwarf2out.c (scompare_loc_descriptor): Likewise.\n+\t(ucompare_loc_descriptor): Likewise.\n+\t(minmax_loc_descriptor): Likewise.\n+\t(mem_loc_descriptor): Likewise.\n+\t(loc_descriptor): Likewise.\n+\t* expmed.c (init_expmed_one_mode): Likewise.\n+\t* lra-constraints.c (lra_constraint_offset): Likewise.\n+\t* optabs.c (prepare_libcall_arg): Likewise.\n+\t* postreload.c (move2add_note_store): Likewise.\n+\t* reload.c (operands_match_p): Likewise.\n+\t* rtl.h (load_extend_op): Likewise.\n+\t* rtlhooks.c (gen_lowpart_general): Likewise.\n+\t* simplify-rtx.c (simplify_truncation): Likewise.\n+\t(simplify_unary_operation_1): Likewise.\n+\t(simplify_binary_operation_1): Likewise.\n+\t(simplify_const_binary_operation): Likewise.\n+\t(simplify_const_relational_operation): Likewise.\n+\t(simplify_subreg): Likewise.\n+\t* stor-layout.c (bitwise_mode_for_mode): Likewise.\n+\t* var-tracking.c (adjust_mems): Likewise.\n+\t(prepare_call_arguments): Likewise.\n+\n 2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "fa3525cacaa587349bd4413de1b1c20d94af401f", "filename": "gcc/ada/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fada%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fada%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2FChangeLog?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -1,3 +1,12 @@\n+2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* gcc-interface/decl.c (check_ok_for_atomic_type): Use\n+\tis_a <scalar_int_mode>.\n+\t* gcc-interface/trans.c (Pragma_to_gnu): Likewise.\n+\t* gcc-interface/utils.c (gnat_type_for_mode): Likewise.\n+\n 2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "c80960f7be1bcac92bc0fef2838c8b3c729a0983", "filename": "gcc/ada/gcc-interface/decl.c", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fada%2Fgcc-interface%2Fdecl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fada%2Fgcc-interface%2Fdecl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Fgcc-interface%2Fdecl.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -8801,9 +8801,10 @@ check_ok_for_atomic_type (tree type, Entity_Id gnat_entity, bool component_p)\n \n   /* Consider all aligned floating-point types atomic and any aligned types\n      that are represented by integers no wider than a machine word.  */\n+  scalar_int_mode int_mode;\n   if ((mclass == MODE_FLOAT\n-       || ((mclass == MODE_INT || mclass == MODE_PARTIAL_INT)\n-\t   && GET_MODE_BITSIZE (mode) <= BITS_PER_WORD))\n+       || (is_a <scalar_int_mode> (mode, &int_mode)\n+\t   && GET_MODE_BITSIZE (int_mode) <= BITS_PER_WORD))\n       && align >= GET_MODE_ALIGNMENT (mode))\n     return;\n "}, {"sha": "693c74f2a084355c54a56f7992ee7ad36167f20b", "filename": "gcc/ada/gcc-interface/trans.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fada%2Fgcc-interface%2Ftrans.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fada%2Fgcc-interface%2Ftrans.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Fgcc-interface%2Ftrans.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -1277,6 +1277,7 @@ Pragma_to_gnu (Node_Id gnat_node)\n \t  tree gnu_expr = gnat_to_gnu (gnat_expr);\n \t  int use_address;\n \t  machine_mode mode;\n+\t  scalar_int_mode int_mode;\n \t  tree asm_constraint = NULL_TREE;\n #ifdef ASM_COMMENT_START\n \t  char *comment;\n@@ -1288,9 +1289,8 @@ Pragma_to_gnu (Node_Id gnat_node)\n \t  /* Use the value only if it fits into a normal register,\n \t     otherwise use the address.  */\n \t  mode = TYPE_MODE (TREE_TYPE (gnu_expr));\n-\t  use_address = ((GET_MODE_CLASS (mode) != MODE_INT\n-\t\t\t  && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)\n-\t\t\t || GET_MODE_SIZE (mode) > UNITS_PER_WORD);\n+\t  use_address = (!is_a <scalar_int_mode> (mode, &int_mode)\n+\t\t\t || GET_MODE_SIZE (int_mode) > UNITS_PER_WORD);\n \n \t  if (use_address)\n \t    gnu_expr = build_unary_op (ADDR_EXPR, NULL_TREE, gnu_expr);"}, {"sha": "951089865e57bc1c777c4b5e84f19541f345f0cc", "filename": "gcc/ada/gcc-interface/utils.c", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fada%2Fgcc-interface%2Futils.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fada%2Fgcc-interface%2Futils.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Fgcc-interface%2Futils.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -3470,8 +3470,9 @@ gnat_type_for_mode (machine_mode mode, int unsignedp)\n     return float_type_for_precision (GET_MODE_PRECISION (float_mode),\n \t\t\t\t     float_mode);\n \n-  if (SCALAR_INT_MODE_P (mode))\n-    return gnat_type_for_size (GET_MODE_BITSIZE (mode), unsignedp);\n+  scalar_int_mode int_mode;\n+  if (is_a <scalar_int_mode> (mode, &int_mode))\n+    return gnat_type_for_size (GET_MODE_BITSIZE (int_mode), unsignedp);\n \n   if (VECTOR_MODE_P (mode))\n     {"}, {"sha": "ec242bbb081dff0dab8f1aeec27aa3083c265197", "filename": "gcc/cfgexpand.c", "status": "modified", "additions": 5, "deletions": 10, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fcfgexpand.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fcfgexpand.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgexpand.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -4139,6 +4139,7 @@ expand_debug_expr (tree exp)\n   machine_mode inner_mode = VOIDmode;\n   int unsignedp = TYPE_UNSIGNED (TREE_TYPE (exp));\n   addr_space_t as;\n+  scalar_int_mode op1_mode;\n \n   switch (TREE_CODE_CLASS (TREE_CODE (exp)))\n     {\n@@ -4188,16 +4189,10 @@ expand_debug_expr (tree exp)\n \tcase WIDEN_LSHIFT_EXPR:\n \t  /* Ensure second operand isn't wider than the first one.  */\n \t  inner_mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 1)));\n-\t  if (SCALAR_INT_MODE_P (inner_mode))\n-\t    {\n-\t      machine_mode opmode = mode;\n-\t      if (VECTOR_MODE_P (mode))\n-\t\topmode = GET_MODE_INNER (mode);\n-\t      if (SCALAR_INT_MODE_P (opmode)\n-\t\t  && (GET_MODE_PRECISION (opmode)\n-\t\t      < GET_MODE_PRECISION (inner_mode)))\n-\t\top1 = lowpart_subreg (opmode, op1, inner_mode);\n-\t    }\n+\t  if (is_a <scalar_int_mode> (inner_mode, &op1_mode)\n+\t      && (GET_MODE_UNIT_PRECISION (mode)\n+\t\t  < GET_MODE_PRECISION (op1_mode)))\n+\t    op1 = lowpart_subreg (GET_MODE_INNER (mode), op1, op1_mode);\n \t  break;\n \tdefault:\n \t  break;"}, {"sha": "b2f6c0932318759c3797d4324e5adddc5824af3a", "filename": "gcc/combine.c", "status": "modified", "additions": 78, "deletions": 75, "changes": 153, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -1706,20 +1706,22 @@ static void\n set_nonzero_bits_and_sign_copies (rtx x, const_rtx set, void *data)\n {\n   rtx_insn *insn = (rtx_insn *) data;\n+  scalar_int_mode mode;\n \n   if (REG_P (x)\n       && REGNO (x) >= FIRST_PSEUDO_REGISTER\n       /* If this register is undefined at the start of the file, we can't\n \t say what its contents were.  */\n       && ! REGNO_REG_SET_P\n \t   (DF_LR_IN (ENTRY_BLOCK_PTR_FOR_FN (cfun)->next_bb), REGNO (x))\n-      && HWI_COMPUTABLE_MODE_P (GET_MODE (x)))\n+      && is_a <scalar_int_mode> (GET_MODE (x), &mode)\n+      && HWI_COMPUTABLE_MODE_P (mode))\n     {\n       reg_stat_type *rsp = &reg_stat[REGNO (x)];\n \n       if (set == 0 || GET_CODE (set) == CLOBBER)\n \t{\n-\t  rsp->nonzero_bits = GET_MODE_MASK (GET_MODE (x));\n+\t  rsp->nonzero_bits = GET_MODE_MASK (mode);\n \t  rsp->sign_bit_copies = 1;\n \t  return;\n \t}\n@@ -1749,7 +1751,7 @@ set_nonzero_bits_and_sign_copies (rtx x, const_rtx set, void *data)\n \t      break;\n \t  if (!link)\n \t    {\n-\t      rsp->nonzero_bits = GET_MODE_MASK (GET_MODE (x));\n+\t      rsp->nonzero_bits = GET_MODE_MASK (mode);\n \t      rsp->sign_bit_copies = 1;\n \t      return;\n \t    }\n@@ -1768,7 +1770,7 @@ set_nonzero_bits_and_sign_copies (rtx x, const_rtx set, void *data)\n \tupdate_rsp_from_reg_equal (rsp, insn, set, x);\n       else\n \t{\n-\t  rsp->nonzero_bits = GET_MODE_MASK (GET_MODE (x));\n+\t  rsp->nonzero_bits = GET_MODE_MASK (mode);\n \t  rsp->sign_bit_copies = 1;\n \t}\n     }\n@@ -4926,37 +4928,38 @@ find_split_point (rtx *loc, rtx_insn *insn, bool set_src)\n       /* See if this is a bitfield assignment with everything constant.  If\n \t so, this is an IOR of an AND, so split it into that.  */\n       if (GET_CODE (SET_DEST (x)) == ZERO_EXTRACT\n-\t  && HWI_COMPUTABLE_MODE_P (GET_MODE (XEXP (SET_DEST (x), 0)))\n+\t  && is_a <scalar_int_mode> (GET_MODE (XEXP (SET_DEST (x), 0)),\n+\t\t\t\t     &inner_mode)\n+\t  && HWI_COMPUTABLE_MODE_P (inner_mode)\n \t  && CONST_INT_P (XEXP (SET_DEST (x), 1))\n \t  && CONST_INT_P (XEXP (SET_DEST (x), 2))\n \t  && CONST_INT_P (SET_SRC (x))\n \t  && ((INTVAL (XEXP (SET_DEST (x), 1))\n \t       + INTVAL (XEXP (SET_DEST (x), 2)))\n-\t      <= GET_MODE_PRECISION (GET_MODE (XEXP (SET_DEST (x), 0))))\n+\t      <= GET_MODE_PRECISION (inner_mode))\n \t  && ! side_effects_p (XEXP (SET_DEST (x), 0)))\n \t{\n \t  HOST_WIDE_INT pos = INTVAL (XEXP (SET_DEST (x), 2));\n \t  unsigned HOST_WIDE_INT len = INTVAL (XEXP (SET_DEST (x), 1));\n \t  unsigned HOST_WIDE_INT src = INTVAL (SET_SRC (x));\n \t  rtx dest = XEXP (SET_DEST (x), 0);\n-\t  machine_mode mode = GET_MODE (dest);\n \t  unsigned HOST_WIDE_INT mask\n \t    = (HOST_WIDE_INT_1U << len) - 1;\n \t  rtx or_mask;\n \n \t  if (BITS_BIG_ENDIAN)\n-\t    pos = GET_MODE_PRECISION (mode) - len - pos;\n+\t    pos = GET_MODE_PRECISION (inner_mode) - len - pos;\n \n-\t  or_mask = gen_int_mode (src << pos, mode);\n+\t  or_mask = gen_int_mode (src << pos, inner_mode);\n \t  if (src == mask)\n \t    SUBST (SET_SRC (x),\n-\t\t   simplify_gen_binary (IOR, mode, dest, or_mask));\n+\t\t   simplify_gen_binary (IOR, inner_mode, dest, or_mask));\n \t  else\n \t    {\n-\t      rtx negmask = gen_int_mode (~(mask << pos), mode);\n+\t      rtx negmask = gen_int_mode (~(mask << pos), inner_mode);\n \t      SUBST (SET_SRC (x),\n-\t\t     simplify_gen_binary (IOR, mode,\n-\t\t\t\t\t  simplify_gen_binary (AND, mode,\n+\t\t     simplify_gen_binary (IOR, inner_mode,\n+\t\t\t\t\t  simplify_gen_binary (AND, inner_mode,\n \t\t\t\t\t\t\t       dest, negmask),\n \t\t\t\t\t  or_mask));\n \t    }\n@@ -5796,15 +5799,18 @@ combine_simplify_rtx (rtx x, machine_mode op0_mode, int in_dest,\n \t  return temp;\n \n \t/* If op is known to have all lower bits zero, the result is zero.  */\n+\tscalar_int_mode int_mode, int_op0_mode;\n \tif (!in_dest\n-\t    && SCALAR_INT_MODE_P (mode)\n-\t    && SCALAR_INT_MODE_P (op0_mode)\n-\t    && GET_MODE_PRECISION (mode) < GET_MODE_PRECISION (op0_mode)\n-\t    && subreg_lowpart_offset (mode, op0_mode) == SUBREG_BYTE (x)\n-\t    && HWI_COMPUTABLE_MODE_P (op0_mode)\n-\t    && (nonzero_bits (SUBREG_REG (x), op0_mode)\n-\t\t& GET_MODE_MASK (mode)) == 0)\n-\t  return CONST0_RTX (mode);\n+\t    && is_a <scalar_int_mode> (mode, &int_mode)\n+\t    && is_a <scalar_int_mode> (op0_mode, &int_op0_mode)\n+\t    && (GET_MODE_PRECISION (int_mode)\n+\t\t< GET_MODE_PRECISION (int_op0_mode))\n+\t    && (subreg_lowpart_offset (int_mode, int_op0_mode)\n+\t\t== SUBREG_BYTE (x))\n+\t    && HWI_COMPUTABLE_MODE_P (int_op0_mode)\n+\t    && (nonzero_bits (SUBREG_REG (x), int_op0_mode)\n+\t\t& GET_MODE_MASK (int_mode)) == 0)\n+\t  return CONST0_RTX (int_mode);\n       }\n \n       /* Don't change the mode of the MEM if that would change the meaning\n@@ -5912,12 +5918,13 @@ combine_simplify_rtx (rtx x, machine_mode op0_mode, int in_dest,\n \t sign_extract.  The `and' may be a zero_extend and the two\n \t <c>, -<c> constants may be reversed.  */\n       if (GET_CODE (XEXP (x, 0)) == XOR\n+\t  && is_a <scalar_int_mode> (mode, &int_mode)\n \t  && CONST_INT_P (XEXP (x, 1))\n \t  && CONST_INT_P (XEXP (XEXP (x, 0), 1))\n \t  && INTVAL (XEXP (x, 1)) == -INTVAL (XEXP (XEXP (x, 0), 1))\n \t  && ((i = exact_log2 (UINTVAL (XEXP (XEXP (x, 0), 1)))) >= 0\n \t      || (i = exact_log2 (UINTVAL (XEXP (x, 1)))) >= 0)\n-\t  && HWI_COMPUTABLE_MODE_P (mode)\n+\t  && HWI_COMPUTABLE_MODE_P (int_mode)\n \t  && ((GET_CODE (XEXP (XEXP (x, 0), 0)) == AND\n \t       && CONST_INT_P (XEXP (XEXP (XEXP (x, 0), 0), 1))\n \t       && (UINTVAL (XEXP (XEXP (XEXP (x, 0), 0), 1))\n@@ -5926,11 +5933,11 @@ combine_simplify_rtx (rtx x, machine_mode op0_mode, int in_dest,\n \t\t  && (GET_MODE_PRECISION (GET_MODE (XEXP (XEXP (XEXP (x, 0), 0), 0)))\n \t\t      == (unsigned int) i + 1))))\n \treturn simplify_shift_const\n-\t  (NULL_RTX, ASHIFTRT, mode,\n-\t   simplify_shift_const (NULL_RTX, ASHIFT, mode,\n+\t  (NULL_RTX, ASHIFTRT, int_mode,\n+\t   simplify_shift_const (NULL_RTX, ASHIFT, int_mode,\n \t\t\t\t XEXP (XEXP (XEXP (x, 0), 0), 0),\n-\t\t\t\t GET_MODE_PRECISION (mode) - (i + 1)),\n-\t   GET_MODE_PRECISION (mode) - (i + 1));\n+\t\t\t\t GET_MODE_PRECISION (int_mode) - (i + 1)),\n+\t   GET_MODE_PRECISION (int_mode) - (i + 1));\n \n       /* If only the low-order bit of X is possibly nonzero, (plus x -1)\n \t can become (ashiftrt (ashift (xor x 1) C) C) where C is\n@@ -6946,17 +6953,18 @@ simplify_set (rtx x)\n static rtx\n simplify_logical (rtx x)\n {\n-  machine_mode mode = GET_MODE (x);\n   rtx op0 = XEXP (x, 0);\n   rtx op1 = XEXP (x, 1);\n+  scalar_int_mode mode;\n \n   switch (GET_CODE (x))\n     {\n     case AND:\n       /* We can call simplify_and_const_int only if we don't lose\n \t any (sign) bits when converting INTVAL (op1) to\n \t \"unsigned HOST_WIDE_INT\".  */\n-      if (CONST_INT_P (op1)\n+      if (is_a <scalar_int_mode> (GET_MODE (x), &mode)\n+\t  && CONST_INT_P (op1)\n \t  && (HWI_COMPUTABLE_MODE_P (mode)\n \t      || INTVAL (op1) > 0))\n \t{\n@@ -7031,6 +7039,7 @@ expand_compound_operation (rtx x)\n   int unsignedp = 0;\n   unsigned int modewidth;\n   rtx tem;\n+  scalar_int_mode inner_mode;\n \n   switch (GET_CODE (x))\n     {\n@@ -7049,25 +7058,24 @@ expand_compound_operation (rtx x)\n       if (CONST_INT_P (XEXP (x, 0)))\n \treturn x;\n \n+      /* Reject modes that aren't scalar integers because turning vector\n+\t or complex modes into shifts causes problems.  */\n+      if (!is_a <scalar_int_mode> (GET_MODE (XEXP (x, 0)), &inner_mode))\n+\treturn x;\n+\n       /* Return if (subreg:MODE FROM 0) is not a safe replacement for\n \t (zero_extend:MODE FROM) or (sign_extend:MODE FROM).  It is for any MEM\n \t because (SUBREG (MEM...)) is guaranteed to cause the MEM to be\n \t reloaded. If not for that, MEM's would very rarely be safe.\n \n-\t Reject MODEs bigger than a word, because we might not be able\n+\t Reject modes bigger than a word, because we might not be able\n \t to reference a two-register group starting with an arbitrary register\n \t (and currently gen_lowpart might crash for a SUBREG).  */\n \n-      if (GET_MODE_SIZE (GET_MODE (XEXP (x, 0))) > UNITS_PER_WORD)\n+      if (GET_MODE_SIZE (inner_mode) > UNITS_PER_WORD)\n \treturn x;\n \n-      /* Reject MODEs that aren't scalar integers because turning vector\n-\t or complex modes into shifts causes problems.  */\n-\n-      if (! SCALAR_INT_MODE_P (GET_MODE (XEXP (x, 0))))\n-\treturn x;\n-\n-      len = GET_MODE_PRECISION (GET_MODE (XEXP (x, 0)));\n+      len = GET_MODE_PRECISION (inner_mode);\n       /* If the inner object has VOIDmode (the only way this can happen\n \t is if it is an ASM_OPERANDS), we can't do anything since we don't\n \t know how much masking to do.  */\n@@ -7087,25 +7095,23 @@ expand_compound_operation (rtx x)\n \treturn XEXP (x, 0);\n \n       if (!CONST_INT_P (XEXP (x, 1))\n-\t  || !CONST_INT_P (XEXP (x, 2))\n-\t  || GET_MODE (XEXP (x, 0)) == VOIDmode)\n+\t  || !CONST_INT_P (XEXP (x, 2)))\n \treturn x;\n \n-      /* Reject MODEs that aren't scalar integers because turning vector\n+      /* Reject modes that aren't scalar integers because turning vector\n \t or complex modes into shifts causes problems.  */\n-\n-      if (! SCALAR_INT_MODE_P (GET_MODE (XEXP (x, 0))))\n+      if (!is_a <scalar_int_mode> (GET_MODE (XEXP (x, 0)), &inner_mode))\n \treturn x;\n \n       len = INTVAL (XEXP (x, 1));\n       pos = INTVAL (XEXP (x, 2));\n \n       /* This should stay within the object being extracted, fail otherwise.  */\n-      if (len + pos > GET_MODE_PRECISION (GET_MODE (XEXP (x, 0))))\n+      if (len + pos > GET_MODE_PRECISION (inner_mode))\n \treturn x;\n \n       if (BITS_BIG_ENDIAN)\n-\tpos = GET_MODE_PRECISION (GET_MODE (XEXP (x, 0))) - len - pos;\n+\tpos = GET_MODE_PRECISION (inner_mode) - len - pos;\n \n       break;\n \n@@ -7116,12 +7122,10 @@ expand_compound_operation (rtx x)\n      bit is not set, as this is easier to optimize.  It will be converted\n      back to cheaper alternative in make_extraction.  */\n   if (GET_CODE (x) == SIGN_EXTEND\n-      && (HWI_COMPUTABLE_MODE_P (GET_MODE (x))\n-\t  && ((nonzero_bits (XEXP (x, 0), GET_MODE (XEXP (x, 0)))\n-\t\t& ~(((unsigned HOST_WIDE_INT)\n-\t\t      GET_MODE_MASK (GET_MODE (XEXP (x, 0))))\n-\t\t     >> 1))\n-\t       == 0)))\n+      && HWI_COMPUTABLE_MODE_P (GET_MODE (x))\n+      && ((nonzero_bits (XEXP (x, 0), inner_mode)\n+\t   & ~(((unsigned HOST_WIDE_INT) GET_MODE_MASK (inner_mode)) >> 1))\n+\t  == 0))\n     {\n       machine_mode mode = GET_MODE (x);\n       rtx temp = gen_rtx_ZERO_EXTEND (mode, XEXP (x, 0));\n@@ -7148,7 +7152,7 @@ expand_compound_operation (rtx x)\n \t  && GET_MODE (XEXP (XEXP (x, 0), 0)) == GET_MODE (x)\n \t  && HWI_COMPUTABLE_MODE_P (GET_MODE (x))\n \t  && (nonzero_bits (XEXP (XEXP (x, 0), 0), GET_MODE (x))\n-\t      & ~GET_MODE_MASK (GET_MODE (XEXP (x, 0)))) == 0)\n+\t      & ~GET_MODE_MASK (inner_mode)) == 0)\n \treturn XEXP (XEXP (x, 0), 0);\n \n       /* Likewise for (zero_extend:DI (subreg:SI foo:DI 0)).  */\n@@ -7157,7 +7161,7 @@ expand_compound_operation (rtx x)\n \t  && subreg_lowpart_p (XEXP (x, 0))\n \t  && HWI_COMPUTABLE_MODE_P (GET_MODE (x))\n \t  && (nonzero_bits (SUBREG_REG (XEXP (x, 0)), GET_MODE (x))\n-\t      & ~GET_MODE_MASK (GET_MODE (XEXP (x, 0)))) == 0)\n+\t      & ~GET_MODE_MASK (inner_mode)) == 0)\n \treturn SUBREG_REG (XEXP (x, 0));\n \n       /* (zero_extend:DI (truncate:SI foo:DI)) is just foo:DI when foo\n@@ -7167,19 +7171,17 @@ expand_compound_operation (rtx x)\n       if (GET_CODE (XEXP (x, 0)) == TRUNCATE\n \t  && GET_MODE (XEXP (XEXP (x, 0), 0)) == GET_MODE (x)\n \t  && COMPARISON_P (XEXP (XEXP (x, 0), 0))\n-\t  && (GET_MODE_PRECISION (GET_MODE (XEXP (x, 0)))\n-\t      <= HOST_BITS_PER_WIDE_INT)\n-\t  && (STORE_FLAG_VALUE & ~GET_MODE_MASK (GET_MODE (XEXP (x, 0)))) == 0)\n+\t  && GET_MODE_PRECISION (inner_mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && (STORE_FLAG_VALUE & ~GET_MODE_MASK (inner_mode)) == 0)\n \treturn XEXP (XEXP (x, 0), 0);\n \n       /* Likewise for (zero_extend:DI (subreg:SI foo:DI 0)).  */\n       if (GET_CODE (XEXP (x, 0)) == SUBREG\n \t  && GET_MODE (SUBREG_REG (XEXP (x, 0))) == GET_MODE (x)\n \t  && subreg_lowpart_p (XEXP (x, 0))\n \t  && COMPARISON_P (SUBREG_REG (XEXP (x, 0)))\n-\t  && (GET_MODE_PRECISION (GET_MODE (XEXP (x, 0)))\n-\t      <= HOST_BITS_PER_WIDE_INT)\n-\t  && (STORE_FLAG_VALUE & ~GET_MODE_MASK (GET_MODE (XEXP (x, 0)))) == 0)\n+\t  && GET_MODE_PRECISION (inner_mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && (STORE_FLAG_VALUE & ~GET_MODE_MASK (inner_mode)) == 0)\n \treturn SUBREG_REG (XEXP (x, 0));\n \n     }\n@@ -7244,7 +7246,7 @@ expand_field_assignment (const_rtx x)\n   rtx pos;\t\t\t/* Always counts from low bit.  */\n   int len;\n   rtx mask, cleared, masked;\n-  machine_mode compute_mode;\n+  scalar_int_mode compute_mode;\n \n   /* Loop until we find something we can't simplify.  */\n   while (1)\n@@ -7312,17 +7314,15 @@ expand_field_assignment (const_rtx x)\n       while (GET_CODE (inner) == SUBREG && subreg_lowpart_p (inner))\n \tinner = SUBREG_REG (inner);\n \n-      compute_mode = GET_MODE (inner);\n-\n       /* Don't attempt bitwise arithmetic on non scalar integer modes.  */\n-      if (! SCALAR_INT_MODE_P (compute_mode))\n+      if (!is_a <scalar_int_mode> (GET_MODE (inner), &compute_mode))\n \t{\n \t  /* Don't do anything for vector or complex integral types.  */\n-\t  if (! FLOAT_MODE_P (compute_mode))\n+\t  if (! FLOAT_MODE_P (GET_MODE (inner)))\n \t    break;\n \n \t  /* Try to find an integral mode to pun with.  */\n-\t  if (!int_mode_for_size (GET_MODE_BITSIZE (compute_mode), 0)\n+\t  if (!int_mode_for_size (GET_MODE_BITSIZE (GET_MODE (inner)), 0)\n \t      .exists (&compute_mode))\n \t    break;\n \n@@ -8252,10 +8252,11 @@ make_compound_operation (rtx x, enum rtx_code in_code)\n \t\t  && XEXP (x, 1) == const0_rtx) ? COMPARE\n \t       : in_code == COMPARE || in_code == EQ ? SET : in_code);\n \n-  if (SCALAR_INT_MODE_P (GET_MODE (x)))\n+  scalar_int_mode mode;\n+  if (is_a <scalar_int_mode> (GET_MODE (x), &mode))\n     {\n-      rtx new_rtx = make_compound_operation_int (GET_MODE (x), &x,\n-\t\t\t\t\t\t in_code, &next_code);\n+      rtx new_rtx = make_compound_operation_int (mode, &x, in_code,\n+\t\t\t\t\t\t &next_code);\n       if (new_rtx)\n \treturn new_rtx;\n       code = GET_CODE (x);\n@@ -10095,10 +10096,12 @@ extended_count (const_rtx x, machine_mode mode, int unsignedp)\n   if (nonzero_sign_valid == 0)\n     return 0;\n \n+  scalar_int_mode int_mode;\n   return (unsignedp\n-\t  ? (HWI_COMPUTABLE_MODE_P (mode)\n-\t     ? (unsigned int) (GET_MODE_PRECISION (mode) - 1\n-\t\t\t       - floor_log2 (nonzero_bits (x, mode)))\n+\t  ? (is_a <scalar_int_mode> (mode, &int_mode)\n+\t     && HWI_COMPUTABLE_MODE_P (int_mode)\n+\t     ? (unsigned int) (GET_MODE_PRECISION (int_mode) - 1\n+\t\t\t       - floor_log2 (nonzero_bits (x, int_mode)))\n \t     : 0)\n \t  : num_sign_bit_copies (x, mode) - 1);\n }\n@@ -11268,7 +11271,9 @@ change_zero_ext (rtx pat)\n   FOR_EACH_SUBRTX_PTR (iter, array, src, NONCONST)\n     {\n       rtx x = **iter;\n-      machine_mode mode = GET_MODE (x);\n+      scalar_int_mode mode;\n+      if (!is_a <scalar_int_mode> (GET_MODE (x), &mode))\n+\tcontinue;\n       int size;\n \n       if (GET_CODE (x) == ZERO_EXTRACT\n@@ -11294,7 +11299,6 @@ change_zero_ext (rtx pat)\n \t    x = gen_lowpart_SUBREG (mode, x);\n \t}\n       else if (GET_CODE (x) == ZERO_EXTEND\n-\t       && SCALAR_INT_MODE_P (mode)\n \t       && GET_CODE (XEXP (x, 0)) == SUBREG\n \t       && SCALAR_INT_MODE_P (GET_MODE (SUBREG_REG (XEXP (x, 0))))\n \t       && !paradoxical_subreg_p (XEXP (x, 0))\n@@ -11306,7 +11310,6 @@ change_zero_ext (rtx pat)\n \t    x = gen_lowpart_SUBREG (mode, x);\n \t}\n       else if (GET_CODE (x) == ZERO_EXTEND\n-\t       && SCALAR_INT_MODE_P (mode)\n \t       && REG_P (XEXP (x, 0))\n \t       && HARD_REGISTER_P (XEXP (x, 0))\n \t       && can_change_dest_mode (XEXP (x, 0), 0, mode))\n@@ -12391,11 +12394,11 @@ simplify_comparison (enum rtx_code code, rtx *pop0, rtx *pop1)\n \t  if (GET_CODE (XEXP (op0, 0)) == SUBREG\n \t      && CONST_INT_P (XEXP (op0, 1)))\n \t    {\n-\t      tmode = GET_MODE (SUBREG_REG (XEXP (op0, 0)));\n \t      unsigned HOST_WIDE_INT c1 = INTVAL (XEXP (op0, 1));\n \t      /* Require an integral mode, to avoid creating something like\n \t\t (AND:SF ...).  */\n-\t      if (SCALAR_INT_MODE_P (tmode)\n+\t      if ((is_a <scalar_int_mode>\n+\t\t   (GET_MODE (SUBREG_REG (XEXP (op0, 0))), &tmode))\n \t\t  /* It is unsafe to commute the AND into the SUBREG if the\n \t\t     SUBREG is paradoxical and WORD_REGISTER_OPERATIONS is\n \t\t     not defined.  As originally written the upper bits"}, {"sha": "b24250ac3b1722a13298bab4074dc6d533c62f38", "filename": "gcc/dwarf2out.c", "status": "modified", "additions": 94, "deletions": 93, "changes": 187, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fdwarf2out.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fdwarf2out.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdwarf2out.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -14023,7 +14023,7 @@ scompare_loc_descriptor_narrow (enum dwarf_location_atom op, rtx rtl,\n   return compare_loc_descriptor (op, op0, op1);\n }\n \n-/* Return location descriptor for signed comparison OP RTL.  */\n+/* Return location descriptor for unsigned comparison OP RTL.  */\n \n static dw_loc_descr_ref\n scompare_loc_descriptor (enum dwarf_location_atom op, rtx rtl,\n@@ -14037,10 +14037,11 @@ scompare_loc_descriptor (enum dwarf_location_atom op, rtx rtl,\n   if (op_mode == VOIDmode)\n     return NULL;\n \n+  scalar_int_mode int_op_mode;\n   if (dwarf_strict\n       && dwarf_version < 5\n-      && (!SCALAR_INT_MODE_P (op_mode)\n-\t  || GET_MODE_SIZE (op_mode) > DWARF2_ADDR_SIZE))\n+      && (!is_a <scalar_int_mode> (op_mode, &int_op_mode)\n+\t  || GET_MODE_SIZE (int_op_mode) > DWARF2_ADDR_SIZE))\n     return NULL;\n \n   op0 = mem_loc_descriptor (XEXP (rtl, 0), op_mode, mem_mode,\n@@ -14051,13 +14052,13 @@ scompare_loc_descriptor (enum dwarf_location_atom op, rtx rtl,\n   if (op0 == NULL || op1 == NULL)\n     return NULL;\n \n-  if (SCALAR_INT_MODE_P (op_mode))\n+  if (is_a <scalar_int_mode> (op_mode, &int_op_mode))\n     {\n-      if (GET_MODE_SIZE (op_mode) < DWARF2_ADDR_SIZE)\n-\treturn scompare_loc_descriptor_narrow (op, rtl, op_mode, op0, op1);\n+      if (GET_MODE_SIZE (int_op_mode) < DWARF2_ADDR_SIZE)\n+\treturn scompare_loc_descriptor_narrow (op, rtl, int_op_mode, op0, op1);\n \n-      if (GET_MODE_SIZE (op_mode) > DWARF2_ADDR_SIZE)\n-\treturn scompare_loc_descriptor_wide (op, op_mode, op0, op1);\n+      if (GET_MODE_SIZE (int_op_mode) > DWARF2_ADDR_SIZE)\n+\treturn scompare_loc_descriptor_wide (op, int_op_mode, op0, op1);\n     }\n   return compare_loc_descriptor (op, op0, op1);\n }\n@@ -14068,14 +14069,14 @@ static dw_loc_descr_ref\n ucompare_loc_descriptor (enum dwarf_location_atom op, rtx rtl,\n \t\t\t machine_mode mem_mode)\n {\n-  machine_mode op_mode = GET_MODE (XEXP (rtl, 0));\n   dw_loc_descr_ref op0, op1;\n \n-  if (op_mode == VOIDmode)\n-    op_mode = GET_MODE (XEXP (rtl, 1));\n-  if (op_mode == VOIDmode)\n-    return NULL;\n-  if (!SCALAR_INT_MODE_P (op_mode))\n+  machine_mode test_op_mode = GET_MODE (XEXP (rtl, 0));\n+  if (test_op_mode == VOIDmode)\n+    test_op_mode = GET_MODE (XEXP (rtl, 1));\n+\n+  scalar_int_mode op_mode;\n+  if (!is_a <scalar_int_mode> (test_op_mode, &op_mode))\n     return NULL;\n \n   if (dwarf_strict\n@@ -14143,10 +14144,11 @@ minmax_loc_descriptor (rtx rtl, machine_mode mode,\n   dw_loc_descr_ref op0, op1, ret;\n   dw_loc_descr_ref bra_node, drop_node;\n \n+  scalar_int_mode int_mode;\n   if (dwarf_strict\n       && dwarf_version < 5\n-      && (!SCALAR_INT_MODE_P (mode)\n-\t  || GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE))\n+      && (!is_a <scalar_int_mode> (mode, &int_mode)\n+\t  || GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE))\n     return NULL;\n \n   op0 = mem_loc_descriptor (XEXP (rtl, 0), mode, mem_mode,\n@@ -14178,19 +14180,19 @@ minmax_loc_descriptor (rtx rtl, machine_mode mode,\n \t  add_loc_descr (&op1, new_loc_descr (DW_OP_plus_uconst, bias, 0));\n \t}\n     }\n-  else if (!SCALAR_INT_MODE_P (mode)\n-\t   && GET_MODE_SIZE (mode) < DWARF2_ADDR_SIZE)\n+  else if (is_a <scalar_int_mode> (mode, &int_mode)\n+\t   && GET_MODE_SIZE (int_mode) < DWARF2_ADDR_SIZE)\n     {\n-      int shift = (DWARF2_ADDR_SIZE - GET_MODE_SIZE (mode)) * BITS_PER_UNIT;\n+      int shift = (DWARF2_ADDR_SIZE - GET_MODE_SIZE (int_mode)) * BITS_PER_UNIT;\n       add_loc_descr (&op0, int_loc_descriptor (shift));\n       add_loc_descr (&op0, new_loc_descr (DW_OP_shl, 0, 0));\n       add_loc_descr (&op1, int_loc_descriptor (shift));\n       add_loc_descr (&op1, new_loc_descr (DW_OP_shl, 0, 0));\n     }\n-  else if (SCALAR_INT_MODE_P (mode)\n-\t   && GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE)\n+  else if (is_a <scalar_int_mode> (mode, &int_mode)\n+\t   && GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE)\n     {\n-      dw_die_ref type_die = base_type_for_mode (mode, 0);\n+      dw_die_ref type_die = base_type_for_mode (int_mode, 0);\n       dw_loc_descr_ref cvt;\n       if (type_die == NULL)\n \treturn NULL;\n@@ -14221,9 +14223,9 @@ minmax_loc_descriptor (rtx rtl, machine_mode mode,\n   bra_node->dw_loc_oprnd1.val_class = dw_val_class_loc;\n   bra_node->dw_loc_oprnd1.v.val_loc = drop_node;\n   if ((GET_CODE (rtl) == SMIN || GET_CODE (rtl) == SMAX)\n-      && SCALAR_INT_MODE_P (mode)\n-      && GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE)\n-    ret = convert_descriptor_to_mode (mode, ret);\n+      && is_a <scalar_int_mode> (mode, &int_mode)\n+      && GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE)\n+    ret = convert_descriptor_to_mode (int_mode, ret);\n   return ret;\n }\n \n@@ -14687,6 +14689,7 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n   if (mode != GET_MODE (rtl) && GET_MODE (rtl) != VOIDmode)\n     return NULL;\n \n+  scalar_int_mode int_mode, inner_mode;\n   switch (GET_CODE (rtl))\n     {\n     case POST_INC:\n@@ -14707,29 +14710,26 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n     case TRUNCATE:\n       if (inner == NULL_RTX)\n         inner = XEXP (rtl, 0);\n-      if (SCALAR_INT_MODE_P (mode)\n-\t  && SCALAR_INT_MODE_P (GET_MODE (inner))\n-\t  && (GET_MODE_SIZE (mode) <= DWARF2_ADDR_SIZE\n+      if (is_a <scalar_int_mode> (mode, &int_mode)\n+\t  && is_a <scalar_int_mode> (GET_MODE (inner), &inner_mode)\n+\t  && (GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE\n #ifdef POINTERS_EXTEND_UNSIGNED\n-\t      || (mode == Pmode && mem_mode != VOIDmode)\n+\t      || (int_mode == Pmode && mem_mode != VOIDmode)\n #endif\n \t     )\n-\t  && GET_MODE_SIZE (GET_MODE (inner)) <= DWARF2_ADDR_SIZE)\n+\t  && GET_MODE_SIZE (inner_mode) <= DWARF2_ADDR_SIZE)\n \t{\n \t  mem_loc_result = mem_loc_descriptor (inner,\n-\t\t\t\t\t       GET_MODE (inner),\n+\t\t\t\t\t       inner_mode,\n \t\t\t\t\t       mem_mode, initialized);\n \t  break;\n \t}\n       if (dwarf_strict && dwarf_version < 5)\n \tbreak;\n-      if (GET_MODE_SIZE (mode) > GET_MODE_SIZE (GET_MODE (inner)))\n-\tbreak;\n-      if (GET_MODE_SIZE (mode) != GET_MODE_SIZE (GET_MODE (inner))\n-\t  && (!SCALAR_INT_MODE_P (mode)\n-\t      || !SCALAR_INT_MODE_P (GET_MODE (inner))))\n-\tbreak;\n-      else\n+      if (is_a <scalar_int_mode> (mode, &int_mode)\n+\t  && is_a <scalar_int_mode> (GET_MODE (inner), &inner_mode)\n+\t  ? GET_MODE_SIZE (int_mode) <= GET_MODE_SIZE (inner_mode)\n+\t  : GET_MODE_SIZE (mode) == GET_MODE_SIZE (GET_MODE (inner)))\n \t{\n \t  dw_die_ref type_die;\n \t  dw_loc_descr_ref cvt;\n@@ -14754,8 +14754,8 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t  cvt->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n \t  cvt->dw_loc_oprnd1.v.val_die_ref.external = 0;\n \t  add_loc_descr (&mem_loc_result, cvt);\n-\t  if (SCALAR_INT_MODE_P (mode)\n-\t      && GET_MODE_SIZE (mode) <= DWARF2_ADDR_SIZE)\n+\t  if (is_a <scalar_int_mode> (mode, &int_mode)\n+\t      && GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE)\n \t    {\n \t      /* Convert it to untyped afterwards.  */\n \t      cvt = new_loc_descr (dwarf_OP (DW_OP_convert), 0, 0);\n@@ -14765,12 +14765,12 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n       break;\n \n     case REG:\n-      if (! SCALAR_INT_MODE_P (mode)\n-\t  || (GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE\n+      if (!is_a <scalar_int_mode> (mode, &int_mode)\n+\t  || (GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE\n \t      && rtl != arg_pointer_rtx\n \t      && rtl != frame_pointer_rtx\n #ifdef POINTERS_EXTEND_UNSIGNED\n-\t      && (mode != Pmode || mem_mode == VOIDmode)\n+\t      && (int_mode != Pmode || mem_mode == VOIDmode)\n #endif\n \t      ))\n \t{\n@@ -14824,14 +14824,14 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \n     case SIGN_EXTEND:\n     case ZERO_EXTEND:\n-      if (!SCALAR_INT_MODE_P (mode))\n+      if (!is_a <scalar_int_mode> (mode, &int_mode))\n \tbreak;\n       op0 = mem_loc_descriptor (XEXP (rtl, 0), GET_MODE (XEXP (rtl, 0)),\n \t\t\t\tmem_mode, VAR_INIT_STATUS_INITIALIZED);\n       if (op0 == 0)\n \tbreak;\n       else if (GET_CODE (rtl) == ZERO_EXTEND\n-\t       && GET_MODE_SIZE (mode) <= DWARF2_ADDR_SIZE\n+\t       && GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE\n \t       && GET_MODE_BITSIZE (GET_MODE (XEXP (rtl, 0)))\n \t\t  < HOST_BITS_PER_WIDE_INT\n \t       /* If DW_OP_const{1,2,4}u won't be used, it is shorter\n@@ -14845,7 +14845,7 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t\t\t int_loc_descriptor (GET_MODE_MASK (imode)));\n \t  add_loc_descr (&mem_loc_result, new_loc_descr (DW_OP_and, 0, 0));\n \t}\n-      else if (GET_MODE_SIZE (mode) <= DWARF2_ADDR_SIZE)\n+      else if (GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE)\n \t{\n \t  int shift = DWARF2_ADDR_SIZE\n \t\t      - GET_MODE_SIZE (GET_MODE (XEXP (rtl, 0)));\n@@ -14869,7 +14869,7 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t\t\t\t\t  GET_CODE (rtl) == ZERO_EXTEND);\n \t  if (type_die1 == NULL)\n \t    break;\n-\t  type_die2 = base_type_for_mode (mode, 1);\n+\t  type_die2 = base_type_for_mode (int_mode, 1);\n \t  if (type_die2 == NULL)\n \t    break;\n \t  mem_loc_result = op0;\n@@ -14904,8 +14904,8 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \tmem_loc_result = tls_mem_loc_descriptor (rtl);\n       if (mem_loc_result != NULL)\n \t{\n-\t  if (GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE\n-\t      || !SCALAR_INT_MODE_P(mode))\n+\t  if (!is_a <scalar_int_mode> (mode, &int_mode)\n+\t      || GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE)\n \t    {\n \t      dw_die_ref type_die;\n \t      dw_loc_descr_ref deref;\n@@ -14923,12 +14923,12 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t      deref->dw_loc_oprnd2.v.val_die_ref.external = 0;\n \t      add_loc_descr (&mem_loc_result, deref);\n \t    }\n-\t  else if (GET_MODE_SIZE (mode) == DWARF2_ADDR_SIZE)\n+\t  else if (GET_MODE_SIZE (int_mode) == DWARF2_ADDR_SIZE)\n \t    add_loc_descr (&mem_loc_result, new_loc_descr (DW_OP_deref, 0, 0));\n \t  else\n \t    add_loc_descr (&mem_loc_result,\n \t\t\t   new_loc_descr (DW_OP_deref_size,\n-\t\t\t\t\t  GET_MODE_SIZE (mode), 0));\n+\t\t\t\t\t  GET_MODE_SIZE (int_mode), 0));\n \t}\n       break;\n \n@@ -14941,10 +14941,10 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t pool.  */\n     case CONST:\n     case SYMBOL_REF:\n-      if (!SCALAR_INT_MODE_P (mode)\n-\t  || (GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE\n+      if (!is_a <scalar_int_mode> (mode, &int_mode)\n+\t  || (GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE\n #ifdef POINTERS_EXTEND_UNSIGNED\n-\t      && (mode != Pmode || mem_mode == VOIDmode)\n+\t      && (int_mode != Pmode || mem_mode == VOIDmode)\n #endif\n \t      ))\n \tbreak;\n@@ -14973,8 +14973,8 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n       if (!const_ok_for_output (rtl))\n \t{\n \t  if (GET_CODE (rtl) == CONST)\n-\t    mem_loc_result = mem_loc_descriptor (XEXP (rtl, 0), mode, mem_mode,\n-\t\t\t\t\t\t initialized);\n+\t    mem_loc_result = mem_loc_descriptor (XEXP (rtl, 0), int_mode,\n+\t\t\t\t\t\t mem_mode, initialized);\n \t  break;\n \t}\n \n@@ -14996,8 +14996,8 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \treturn NULL;\n       if (REG_P (ENTRY_VALUE_EXP (rtl)))\n \t{\n-\t  if (!SCALAR_INT_MODE_P (mode)\n-\t      || GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE)\n+\t  if (!is_a <scalar_int_mode> (mode, &int_mode)\n+\t      || GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE)\n \t    op0 = mem_loc_descriptor (ENTRY_VALUE_EXP (rtl), mode,\n \t\t\t\t      VOIDmode, VAR_INIT_STATUS_INITIALIZED);\n \t  else\n@@ -15051,10 +15051,10 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n     case PLUS:\n     plus:\n       if (is_based_loc (rtl)\n-\t  && (GET_MODE_SIZE (mode) <= DWARF2_ADDR_SIZE\n+\t  && is_a <scalar_int_mode> (mode, &int_mode)\n+\t  && (GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE\n \t      || XEXP (rtl, 0) == arg_pointer_rtx\n-\t      || XEXP (rtl, 0) == frame_pointer_rtx)\n-\t  && SCALAR_INT_MODE_P (mode))\n+\t      || XEXP (rtl, 0) == frame_pointer_rtx))\n \tmem_loc_result = based_loc_descr (XEXP (rtl, 0),\n \t\t\t\t\t  INTVAL (XEXP (rtl, 1)),\n \t\t\t\t\t  VAR_INIT_STATUS_INITIALIZED);\n@@ -15093,12 +15093,12 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \n     case DIV:\n       if ((!dwarf_strict || dwarf_version >= 5)\n-\t  && SCALAR_INT_MODE_P (mode)\n-\t  && GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE)\n+\t  && is_a <scalar_int_mode> (mode, &int_mode)\n+\t  && GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE)\n \t{\n \t  mem_loc_result = typed_binop (DW_OP_div, rtl,\n \t\t\t\t\tbase_type_for_mode (mode, 0),\n-\t\t\t\t\tmode, mem_mode);\n+\t\t\t\t\tint_mode, mem_mode);\n \t  break;\n \t}\n       op = DW_OP_div;\n@@ -15121,17 +15121,17 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n       goto do_shift;\n \n     do_shift:\n-      if (!SCALAR_INT_MODE_P (mode))\n+      if (!is_a <scalar_int_mode> (mode, &int_mode))\n \tbreak;\n-      op0 = mem_loc_descriptor (XEXP (rtl, 0), mode, mem_mode,\n+      op0 = mem_loc_descriptor (XEXP (rtl, 0), int_mode, mem_mode,\n \t\t\t\tVAR_INIT_STATUS_INITIALIZED);\n       {\n \trtx rtlop1 = XEXP (rtl, 1);\n \tif (GET_MODE (rtlop1) != VOIDmode\n \t    && GET_MODE_BITSIZE (GET_MODE (rtlop1))\n-\t       < GET_MODE_BITSIZE (mode))\n-\t  rtlop1 = gen_rtx_ZERO_EXTEND (mode, rtlop1);\n-\top1 = mem_loc_descriptor (rtlop1, mode, mem_mode,\n+\t       < GET_MODE_BITSIZE (int_mode))\n+\t  rtlop1 = gen_rtx_ZERO_EXTEND (int_mode, rtlop1);\n+\top1 = mem_loc_descriptor (rtlop1, int_mode, mem_mode,\n \t\t\t\t  VAR_INIT_STATUS_INITIALIZED);\n       }\n \n@@ -15198,16 +15198,16 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \n     case UDIV:\n       if ((!dwarf_strict || dwarf_version >= 5)\n-\t  && SCALAR_INT_MODE_P (mode))\n+\t  && is_a <scalar_int_mode> (mode, &int_mode))\n \t{\n-\t  if (GET_MODE_SIZE (mode) > DWARF2_ADDR_SIZE)\n+\t  if (GET_MODE_SIZE (int_mode) > DWARF2_ADDR_SIZE)\n \t    {\n \t      op = DW_OP_div;\n \t      goto do_binop;\n \t    }\n \t  mem_loc_result = typed_binop (DW_OP_div, rtl,\n-\t\t\t\t\tbase_type_for_mode (mode, 1),\n-\t\t\t\t\tmode, mem_mode);\n+\t\t\t\t\tbase_type_for_mode (int_mode, 1),\n+\t\t\t\t\tint_mode, mem_mode);\n \t}\n       break;\n \n@@ -15235,9 +15235,10 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n       break;\n \n     case CONST_INT:\n-      if (GET_MODE_SIZE (mode) <= DWARF2_ADDR_SIZE\n+      if (!is_a <scalar_int_mode> (mode, &int_mode)\n+\t  || GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE\n #ifdef POINTERS_EXTEND_UNSIGNED\n-\t  || (mode == Pmode\n+\t  || (int_mode == Pmode\n \t      && mem_mode != VOIDmode\n \t      && trunc_int_for_mode (INTVAL (rtl), ptr_mode) == INTVAL (rtl))\n #endif\n@@ -15247,10 +15248,10 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t  break;\n \t}\n       if ((!dwarf_strict || dwarf_version >= 5)\n-\t  && (GET_MODE_BITSIZE (mode) == HOST_BITS_PER_WIDE_INT\n-\t      || GET_MODE_BITSIZE (mode) == HOST_BITS_PER_DOUBLE_INT))\n+\t  && (GET_MODE_BITSIZE (int_mode) == HOST_BITS_PER_WIDE_INT\n+\t      || GET_MODE_BITSIZE (int_mode) == HOST_BITS_PER_DOUBLE_INT))\n \t{\n-\t  dw_die_ref type_die = base_type_for_mode (mode, 1);\n+\t  dw_die_ref type_die = base_type_for_mode (int_mode, 1);\n \t  scalar_int_mode amode;\n \t  if (type_die == NULL)\n \t    return NULL;\n@@ -15261,7 +15262,7 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t      /* const DW_OP_convert <XXX> vs.\n \t\t DW_OP_const_type <XXX, 1, const>.  */\n \t      && size_of_int_loc_descriptor (INTVAL (rtl)) + 1 + 1\n-\t\t < (unsigned long) 1 + 1 + 1 + GET_MODE_SIZE (mode))\n+\t\t < (unsigned long) 1 + 1 + 1 + GET_MODE_SIZE (int_mode))\n \t    {\n \t      mem_loc_result = int_loc_descriptor (INTVAL (rtl));\n \t      op0 = new_loc_descr (dwarf_OP (DW_OP_convert), 0, 0);\n@@ -15276,7 +15277,7 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t  mem_loc_result->dw_loc_oprnd1.val_class = dw_val_class_die_ref;\n \t  mem_loc_result->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n \t  mem_loc_result->dw_loc_oprnd1.v.val_die_ref.external = 0;\n-\t  if (GET_MODE_BITSIZE (mode) == HOST_BITS_PER_WIDE_INT)\n+\t  if (GET_MODE_BITSIZE (int_mode) == HOST_BITS_PER_WIDE_INT)\n \t    mem_loc_result->dw_loc_oprnd2.val_class = dw_val_class_const;\n \t  else\n \t    {\n@@ -15409,11 +15410,11 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n     case SIGN_EXTRACT:\n       if (CONST_INT_P (XEXP (rtl, 1))\n \t  && CONST_INT_P (XEXP (rtl, 2))\n+\t  && is_a <scalar_int_mode> (mode, &int_mode)\n \t  && ((unsigned) INTVAL (XEXP (rtl, 1))\n \t      + (unsigned) INTVAL (XEXP (rtl, 2))\n-\t      <= GET_MODE_BITSIZE (mode))\n-\t  && SCALAR_INT_MODE_P (mode)\n-\t  && GET_MODE_SIZE (mode) <= DWARF2_ADDR_SIZE\n+\t      <= GET_MODE_BITSIZE (int_mode))\n+\t  && GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE\n \t  && GET_MODE_SIZE (GET_MODE (XEXP (rtl, 0))) <= DWARF2_ADDR_SIZE)\n \t{\n \t  int shift, size;\n@@ -15489,12 +15490,11 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t\t\t\t    mem_mode, VAR_INIT_STATUS_INITIALIZED);\n \t  if (op0 == NULL)\n \t    break;\n-\t  if (SCALAR_INT_MODE_P (GET_MODE (XEXP (rtl, 0)))\n+\t  if (is_a <scalar_int_mode> (GET_MODE (XEXP (rtl, 0)), &int_mode)\n \t      && (GET_CODE (rtl) == FLOAT\n-\t\t  || GET_MODE_SIZE (GET_MODE (XEXP (rtl, 0)))\n-\t\t     <= DWARF2_ADDR_SIZE))\n+\t\t  || GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE))\n \t    {\n-\t      type_die = base_type_for_mode (GET_MODE (XEXP (rtl, 0)),\n+\t      type_die = base_type_for_mode (int_mode,\n \t\t\t\t\t     GET_CODE (rtl) == UNSIGNED_FLOAT);\n \t      if (type_die == NULL)\n \t\tbreak;\n@@ -15512,11 +15512,11 @@ mem_loc_descriptor (rtx rtl, machine_mode mode,\n \t  cvt->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n \t  cvt->dw_loc_oprnd1.v.val_die_ref.external = 0;\n \t  add_loc_descr (&op0, cvt);\n-\t  if (SCALAR_INT_MODE_P (mode)\n+\t  if (is_a <scalar_int_mode> (mode, &int_mode)\n \t      && (GET_CODE (rtl) == FIX\n-\t\t  || GET_MODE_SIZE (mode) < DWARF2_ADDR_SIZE))\n+\t\t  || GET_MODE_SIZE (int_mode) < DWARF2_ADDR_SIZE))\n \t    {\n-\t      op0 = convert_descriptor_to_mode (mode, op0);\n+\t      op0 = convert_descriptor_to_mode (int_mode, op0);\n \t      if (op0 == NULL)\n \t\tbreak;\n \t    }\n@@ -15757,6 +15757,7 @@ loc_descriptor (rtx rtl, machine_mode mode,\n \t\tenum var_init_status initialized)\n {\n   dw_loc_descr_ref loc_result = NULL;\n+  scalar_int_mode int_mode;\n \n   switch (GET_CODE (rtl))\n     {\n@@ -15983,9 +15984,9 @@ loc_descriptor (rtx rtl, machine_mode mode,\n       /* FALLTHRU */\n     do_default:\n     default:\n-      if ((SCALAR_INT_MODE_P (mode)\n-\t   && GET_MODE (rtl) == mode\n-\t   && GET_MODE_SIZE (GET_MODE (rtl)) <= DWARF2_ADDR_SIZE\n+      if ((is_a <scalar_int_mode> (mode, &int_mode)\n+\t   && GET_MODE (rtl) == int_mode\n+\t   && GET_MODE_SIZE (int_mode) <= DWARF2_ADDR_SIZE\n \t   && dwarf_version >= 4)\n \t  || (!dwarf_strict && mode != VOIDmode && mode != BLKmode))\n \t{"}, {"sha": "292fed343d2d93069a096e4f92933d23882c65bc", "filename": "gcc/expmed.c", "status": "modified", "additions": 9, "deletions": 7, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -202,15 +202,16 @@ init_expmed_one_mode (struct init_expmed_rtl *all,\n \t\t\t\t\t\t\tspeed));\n     }\n \n-  if (SCALAR_INT_MODE_P (mode))\n+  scalar_int_mode int_mode_to;\n+  if (is_a <scalar_int_mode> (mode, &int_mode_to))\n     {\n       for (mode_from = MIN_MODE_INT; mode_from <= MAX_MODE_INT;\n \t   mode_from = (machine_mode)(mode_from + 1))\n-\tinit_expmed_one_conv (all, mode, mode_from, speed);\n+\tinit_expmed_one_conv (all, int_mode_to, mode_from, speed);\n \n-      machine_mode wider_mode;\n-      if (GET_MODE_CLASS (mode) == MODE_INT\n-\t  && GET_MODE_WIDER_MODE (mode).exists (&wider_mode))\n+      scalar_int_mode wider_mode;\n+      if (GET_MODE_CLASS (int_mode_to) == MODE_INT\n+\t  && GET_MODE_WIDER_MODE (int_mode_to).exists (&wider_mode))\n \t{\n \t  PUT_MODE (all->zext, wider_mode);\n \t  PUT_MODE (all->wide_mult, wider_mode);\n@@ -219,8 +220,9 @@ init_expmed_one_mode (struct init_expmed_rtl *all,\n \n \t  set_mul_widen_cost (speed, wider_mode,\n \t\t\t      set_src_cost (all->wide_mult, wider_mode, speed));\n-\t  set_mul_highpart_cost (speed, mode,\n-\t\t\t\t set_src_cost (all->wide_trunc, mode, speed));\n+\t  set_mul_highpart_cost (speed, int_mode_to,\n+\t\t\t\t set_src_cost (all->wide_trunc,\n+\t\t\t\t\t       int_mode_to, speed));\n \t}\n     }\n }"}, {"sha": "247e04a697b308591cbd3420c4ed3a305d2bb0c5", "filename": "gcc/fortran/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Ffortran%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Ffortran%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2FChangeLog?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -1,3 +1,9 @@\n+2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* trans-types.c (gfc_type_for_mode): Use is_a <scalar_int_mode>.\n+\n 2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "48ba3acfd24c12f2cd5c9e313c77cd9fd44ceb77", "filename": "gcc/fortran/trans-types.c", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Ffortran%2Ftrans-types.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Ffortran%2Ftrans-types.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffortran%2Ftrans-types.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -3110,14 +3110,15 @@ gfc_type_for_mode (machine_mode mode, int unsignedp)\n {\n   int i;\n   tree *base;\n+  scalar_int_mode int_mode;\n \n   if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n     base = gfc_real_types;\n   else if (GET_MODE_CLASS (mode) == MODE_COMPLEX_FLOAT)\n     base = gfc_complex_types;\n-  else if (SCALAR_INT_MODE_P (mode))\n+  else if (is_a <scalar_int_mode> (mode, &int_mode))\n     {\n-      tree type = gfc_type_for_size (GET_MODE_PRECISION (mode), unsignedp);\n+      tree type = gfc_type_for_size (GET_MODE_PRECISION (int_mode), unsignedp);\n       return type != NULL_TREE && mode == TYPE_MODE (type) ? type : NULL_TREE;\n     }\n   else if (VECTOR_MODE_P (mode))"}, {"sha": "3ebc803ed9573f2404c12d3f15483f1de600b5e6", "filename": "gcc/lra-constraints.c", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Flra-constraints.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Flra-constraints.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flra-constraints.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -671,8 +671,11 @@ int\n lra_constraint_offset (int regno, machine_mode mode)\n {\n   lra_assert (regno < FIRST_PSEUDO_REGISTER);\n-  if (WORDS_BIG_ENDIAN && GET_MODE_SIZE (mode) > UNITS_PER_WORD\n-      && SCALAR_INT_MODE_P (mode))\n+\n+  scalar_int_mode int_mode;\n+  if (WORDS_BIG_ENDIAN\n+      && is_a <scalar_int_mode> (mode, &int_mode)\n+      && GET_MODE_SIZE (int_mode) > UNITS_PER_WORD)\n     return hard_regno_nregs[regno][mode] - 1;\n   return 0;\n }"}, {"sha": "02cd1082a37dcec29ebc02e4659d168fcf7ceb3e", "filename": "gcc/optabs.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Foptabs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Foptabs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -4997,9 +4997,9 @@ expand_fix (rtx to, rtx from, int unsignedp)\n static rtx\n prepare_libcall_arg (rtx arg, int uintp)\n {\n-  machine_mode mode = GET_MODE (arg);\n+  scalar_int_mode mode;\n   machine_mode arg_mode;\n-  if (SCALAR_INT_MODE_P (mode))\n+  if (is_a <scalar_int_mode> (GET_MODE (arg), &mode))\n     {\n       /*  If we need to promote the integer function argument we need to do\n \t  it here instead of inside emit_library_call_value because in"}, {"sha": "f76321d27d98074a0e46d806340dcf2850b60fe8", "filename": "gcc/postreload.c", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fpostreload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fpostreload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpostreload.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -2154,7 +2154,7 @@ move2add_note_store (rtx dst, const_rtx set, void *data)\n {\n   rtx_insn *insn = (rtx_insn *) data;\n   unsigned int regno = 0;\n-  machine_mode mode = GET_MODE (dst);\n+  scalar_int_mode mode;\n \n   /* Some targets do argument pushes without adding REG_INC notes.  */\n \n@@ -2174,8 +2174,10 @@ move2add_note_store (rtx dst, const_rtx set, void *data)\n   else\n     return;\n \n-  if (SCALAR_INT_MODE_P (mode)\n-      && GET_CODE (set) == SET)\n+  if (!is_a <scalar_int_mode> (GET_MODE (dst), &mode))\n+    goto invalidate;\n+\n+  if (GET_CODE (set) == SET)\n     {\n       rtx note, sym = NULL_RTX;\n       rtx off;\n@@ -2202,8 +2204,7 @@ move2add_note_store (rtx dst, const_rtx set, void *data)\n \t}\n     }\n \n-  if (SCALAR_INT_MODE_P (mode)\n-      && GET_CODE (set) == SET\n+  if (GET_CODE (set) == SET\n       && GET_CODE (SET_DEST (set)) != ZERO_EXTRACT\n       && GET_CODE (SET_DEST (set)) != STRICT_LOW_PART)\n     {"}, {"sha": "d742c32469009eea80b195abb36ebaaa153f9351", "filename": "gcc/reload.c", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Freload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Freload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -2262,14 +2262,18 @@ operands_match_p (rtx x, rtx y)\n \t multiple hard register group of scalar integer registers, so that\n \t for example (reg:DI 0) and (reg:SI 1) will be considered the same\n \t register.  */\n-      if (REG_WORDS_BIG_ENDIAN && GET_MODE_SIZE (GET_MODE (x)) > UNITS_PER_WORD\n-\t  && SCALAR_INT_MODE_P (GET_MODE (x))\n+      scalar_int_mode xmode;\n+      if (REG_WORDS_BIG_ENDIAN\n+\t  && is_a <scalar_int_mode> (GET_MODE (x), &xmode)\n+\t  && GET_MODE_SIZE (xmode) > UNITS_PER_WORD\n \t  && i < FIRST_PSEUDO_REGISTER)\n-\ti += hard_regno_nregs[i][GET_MODE (x)] - 1;\n-      if (REG_WORDS_BIG_ENDIAN && GET_MODE_SIZE (GET_MODE (y)) > UNITS_PER_WORD\n-\t  && SCALAR_INT_MODE_P (GET_MODE (y))\n+\ti += hard_regno_nregs[i][xmode] - 1;\n+      scalar_int_mode ymode;\n+      if (REG_WORDS_BIG_ENDIAN\n+\t  && is_a <scalar_int_mode> (GET_MODE (y), &ymode)\n+\t  && GET_MODE_SIZE (ymode) > UNITS_PER_WORD\n \t  && j < FIRST_PSEUDO_REGISTER)\n-\tj += hard_regno_nregs[j][GET_MODE (y)] - 1;\n+\tj += hard_regno_nregs[j][ymode] - 1;\n \n       return i == j;\n     }"}, {"sha": "39425778536c3219868968272821d22bdcff8918", "filename": "gcc/rtl.h", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -3837,9 +3837,10 @@ struct GTY(()) cgraph_rtl_info {\n inline rtx_code\n load_extend_op (machine_mode mode)\n {\n-  if (SCALAR_INT_MODE_P (mode)\n-      && GET_MODE_PRECISION (mode) < BITS_PER_WORD)\n-    return LOAD_EXTEND_OP (mode);\n+  scalar_int_mode int_mode;\n+  if (is_a <scalar_int_mode> (mode, &int_mode)\n+      && GET_MODE_PRECISION (int_mode) < BITS_PER_WORD)\n+    return LOAD_EXTEND_OP (int_mode);\n   return UNKNOWN;\n }\n "}, {"sha": "9704e2a774223e6e5ebbafa410d988a57ca602a6", "filename": "gcc/rtlhooks.c", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Frtlhooks.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Frtlhooks.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlhooks.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -64,11 +64,12 @@ gen_lowpart_general (machine_mode mode, rtx x)\n       gcc_assert (MEM_P (x));\n \n       /* The following exposes the use of \"x\" to CSE.  */\n-      if (GET_MODE_SIZE (GET_MODE (x)) <= UNITS_PER_WORD\n-\t  && SCALAR_INT_MODE_P (GET_MODE (x))\n-\t  && TRULY_NOOP_TRUNCATION_MODES_P (mode, GET_MODE (x))\n+      scalar_int_mode xmode;\n+      if (is_a <scalar_int_mode> (GET_MODE (x), &xmode)\n+\t  && GET_MODE_SIZE (xmode) <= UNITS_PER_WORD\n+\t  && TRULY_NOOP_TRUNCATION_MODES_P (mode, xmode)\n \t  && !reload_completed)\n-\treturn gen_lowpart_general (mode, force_reg (GET_MODE (x), x));\n+\treturn gen_lowpart_general (mode, force_reg (xmode, x));\n \n       if (WORDS_BIG_ENDIAN)\n \toffset = (MAX (GET_MODE_SIZE (GET_MODE (x)), UNITS_PER_WORD)"}, {"sha": "88180d91d38cffd80399e795365e9accd0839cc4", "filename": "gcc/simplify-rtx.c", "status": "modified", "additions": 70, "deletions": 65, "changes": 135, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fsimplify-rtx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fsimplify-rtx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsimplify-rtx.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -641,6 +641,8 @@ simplify_truncation (machine_mode mode, rtx op,\n {\n   unsigned int precision = GET_MODE_UNIT_PRECISION (mode);\n   unsigned int op_precision = GET_MODE_UNIT_PRECISION (op_mode);\n+  scalar_int_mode int_mode, int_op_mode, subreg_mode;\n+\n   gcc_assert (precision <= op_precision);\n \n   /* Optimize truncations of zero and sign extended values.  */\n@@ -806,19 +808,19 @@ simplify_truncation (machine_mode mode, rtx op,\n      if the MEM has a mode-dependent address.  */\n   if ((GET_CODE (op) == LSHIFTRT\n        || GET_CODE (op) == ASHIFTRT)\n-      && SCALAR_INT_MODE_P (op_mode)\n+      && is_a <scalar_int_mode> (op_mode, &int_op_mode)\n       && MEM_P (XEXP (op, 0))\n       && CONST_INT_P (XEXP (op, 1))\n       && (INTVAL (XEXP (op, 1)) % GET_MODE_BITSIZE (mode)) == 0\n       && INTVAL (XEXP (op, 1)) > 0\n-      && INTVAL (XEXP (op, 1)) < GET_MODE_BITSIZE (op_mode)\n+      && INTVAL (XEXP (op, 1)) < GET_MODE_BITSIZE (int_op_mode)\n       && ! mode_dependent_address_p (XEXP (XEXP (op, 0), 0),\n \t\t\t\t     MEM_ADDR_SPACE (XEXP (op, 0)))\n       && ! MEM_VOLATILE_P (XEXP (op, 0))\n       && (GET_MODE_SIZE (mode) >= UNITS_PER_WORD\n \t  || WORDS_BIG_ENDIAN == BYTES_BIG_ENDIAN))\n     {\n-      int byte = subreg_lowpart_offset (mode, op_mode);\n+      int byte = subreg_lowpart_offset (mode, int_op_mode);\n       int shifted_bytes = INTVAL (XEXP (op, 1)) / BITS_PER_UNIT;\n       return adjust_address_nv (XEXP (op, 0), mode,\n \t\t\t\t(WORDS_BIG_ENDIAN\n@@ -839,21 +841,20 @@ simplify_truncation (machine_mode mode, rtx op,\n   /* (truncate:A (subreg:B (truncate:C X) 0)) is\n      (truncate:A X).  */\n   if (GET_CODE (op) == SUBREG\n-      && SCALAR_INT_MODE_P (mode)\n+      && is_a <scalar_int_mode> (mode, &int_mode)\n       && SCALAR_INT_MODE_P (op_mode)\n-      && SCALAR_INT_MODE_P (GET_MODE (SUBREG_REG (op)))\n+      && is_a <scalar_int_mode> (GET_MODE (SUBREG_REG (op)), &subreg_mode)\n       && GET_CODE (SUBREG_REG (op)) == TRUNCATE\n       && subreg_lowpart_p (op))\n     {\n       rtx inner = XEXP (SUBREG_REG (op), 0);\n-      if (GET_MODE_PRECISION (mode)\n-\t  <= GET_MODE_PRECISION (GET_MODE (SUBREG_REG (op))))\n-\treturn simplify_gen_unary (TRUNCATE, mode, inner, GET_MODE (inner));\n+      if (GET_MODE_PRECISION (int_mode) <= GET_MODE_PRECISION (subreg_mode))\n+\treturn simplify_gen_unary (TRUNCATE, int_mode, inner,\n+\t\t\t\t   GET_MODE (inner));\n       else\n \t/* If subreg above is paradoxical and C is narrower\n \t   than A, return (subreg:A (truncate:C X) 0).  */\n-\treturn simplify_gen_subreg (mode, SUBREG_REG (op),\n-\t\t\t\t    GET_MODE (SUBREG_REG (op)), 0);\n+\treturn simplify_gen_subreg (int_mode, SUBREG_REG (op), subreg_mode, 0);\n     }\n \n   /* (truncate:A (truncate:B X)) is (truncate:A X).  */\n@@ -924,6 +925,7 @@ simplify_unary_operation_1 (enum rtx_code code, machine_mode mode, rtx op)\n {\n   enum rtx_code reversed;\n   rtx temp;\n+  scalar_int_mode inner;\n \n   switch (code)\n     {\n@@ -1156,9 +1158,8 @@ simplify_unary_operation_1 (enum rtx_code code, machine_mode mode, rtx op)\n       /* (neg (lt x 0)) is (lshiftrt X C) if STORE_FLAG_VALUE is -1.  */\n       if (GET_CODE (op) == LT\n \t  && XEXP (op, 1) == const0_rtx\n-\t  && SCALAR_INT_MODE_P (GET_MODE (XEXP (op, 0))))\n+\t  && is_a <scalar_int_mode> (GET_MODE (XEXP (op, 0)), &inner))\n \t{\n-\t  machine_mode inner = GET_MODE (XEXP (op, 0));\n \t  int isize = GET_MODE_PRECISION (inner);\n \t  if (STORE_FLAG_VALUE == 1)\n \t    {\n@@ -2137,6 +2138,7 @@ simplify_binary_operation_1 (enum rtx_code code, machine_mode mode,\n   rtx tem, reversed, opleft, opright;\n   HOST_WIDE_INT val;\n   unsigned int width = GET_MODE_PRECISION (mode);\n+  scalar_int_mode int_mode;\n \n   /* Even if we can't compute a constant result,\n      there are some cases worth simplifying.  */\n@@ -2187,66 +2189,66 @@ simplify_binary_operation_1 (enum rtx_code code, machine_mode mode,\n \t have X (if C is 2 in the example above).  But don't make\n \t something more expensive than we had before.  */\n \n-      if (SCALAR_INT_MODE_P (mode))\n+      if (is_a <scalar_int_mode> (mode, &int_mode))\n \t{\n \t  rtx lhs = op0, rhs = op1;\n \n-\t  wide_int coeff0 = wi::one (GET_MODE_PRECISION (mode));\n-\t  wide_int coeff1 = wi::one (GET_MODE_PRECISION (mode));\n+\t  wide_int coeff0 = wi::one (GET_MODE_PRECISION (int_mode));\n+\t  wide_int coeff1 = wi::one (GET_MODE_PRECISION (int_mode));\n \n \t  if (GET_CODE (lhs) == NEG)\n \t    {\n-\t      coeff0 = wi::minus_one (GET_MODE_PRECISION (mode));\n+\t      coeff0 = wi::minus_one (GET_MODE_PRECISION (int_mode));\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \t  else if (GET_CODE (lhs) == MULT\n \t\t   && CONST_SCALAR_INT_P (XEXP (lhs, 1)))\n \t    {\n-\t      coeff0 = rtx_mode_t (XEXP (lhs, 1), mode);\n+\t      coeff0 = rtx_mode_t (XEXP (lhs, 1), int_mode);\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \t  else if (GET_CODE (lhs) == ASHIFT\n \t\t   && CONST_INT_P (XEXP (lhs, 1))\n                    && INTVAL (XEXP (lhs, 1)) >= 0\n-\t\t   && INTVAL (XEXP (lhs, 1)) < GET_MODE_PRECISION (mode))\n+\t\t   && INTVAL (XEXP (lhs, 1)) < GET_MODE_PRECISION (int_mode))\n \t    {\n \t      coeff0 = wi::set_bit_in_zero (INTVAL (XEXP (lhs, 1)),\n-\t\t\t\t\t    GET_MODE_PRECISION (mode));\n+\t\t\t\t\t    GET_MODE_PRECISION (int_mode));\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \n \t  if (GET_CODE (rhs) == NEG)\n \t    {\n-\t      coeff1 = wi::minus_one (GET_MODE_PRECISION (mode));\n+\t      coeff1 = wi::minus_one (GET_MODE_PRECISION (int_mode));\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \t  else if (GET_CODE (rhs) == MULT\n \t\t   && CONST_INT_P (XEXP (rhs, 1)))\n \t    {\n-\t      coeff1 = rtx_mode_t (XEXP (rhs, 1), mode);\n+\t      coeff1 = rtx_mode_t (XEXP (rhs, 1), int_mode);\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \t  else if (GET_CODE (rhs) == ASHIFT\n \t\t   && CONST_INT_P (XEXP (rhs, 1))\n \t\t   && INTVAL (XEXP (rhs, 1)) >= 0\n-\t\t   && INTVAL (XEXP (rhs, 1)) < GET_MODE_PRECISION (mode))\n+\t\t   && INTVAL (XEXP (rhs, 1)) < GET_MODE_PRECISION (int_mode))\n \t    {\n \t      coeff1 = wi::set_bit_in_zero (INTVAL (XEXP (rhs, 1)),\n-\t\t\t\t\t    GET_MODE_PRECISION (mode));\n+\t\t\t\t\t    GET_MODE_PRECISION (int_mode));\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \n \t  if (rtx_equal_p (lhs, rhs))\n \t    {\n-\t      rtx orig = gen_rtx_PLUS (mode, op0, op1);\n+\t      rtx orig = gen_rtx_PLUS (int_mode, op0, op1);\n \t      rtx coeff;\n \t      bool speed = optimize_function_for_speed_p (cfun);\n \n-\t      coeff = immed_wide_int_const (coeff0 + coeff1, mode);\n+\t      coeff = immed_wide_int_const (coeff0 + coeff1, int_mode);\n \n-\t      tem = simplify_gen_binary (MULT, mode, lhs, coeff);\n-\t      return (set_src_cost (tem, mode, speed)\n-\t\t      <= set_src_cost (orig, mode, speed) ? tem : 0);\n+\t      tem = simplify_gen_binary (MULT, int_mode, lhs, coeff);\n+\t      return (set_src_cost (tem, int_mode, speed)\n+\t\t      <= set_src_cost (orig, int_mode, speed) ? tem : 0);\n \t    }\n \t}\n \n@@ -2364,67 +2366,67 @@ simplify_binary_operation_1 (enum rtx_code code, machine_mode mode,\n \t have X (if C is 2 in the example above).  But don't make\n \t something more expensive than we had before.  */\n \n-      if (SCALAR_INT_MODE_P (mode))\n+      if (is_a <scalar_int_mode> (mode, &int_mode))\n \t{\n \t  rtx lhs = op0, rhs = op1;\n \n-\t  wide_int coeff0 = wi::one (GET_MODE_PRECISION (mode));\n-\t  wide_int negcoeff1 = wi::minus_one (GET_MODE_PRECISION (mode));\n+\t  wide_int coeff0 = wi::one (GET_MODE_PRECISION (int_mode));\n+\t  wide_int negcoeff1 = wi::minus_one (GET_MODE_PRECISION (int_mode));\n \n \t  if (GET_CODE (lhs) == NEG)\n \t    {\n-\t      coeff0 = wi::minus_one (GET_MODE_PRECISION (mode));\n+\t      coeff0 = wi::minus_one (GET_MODE_PRECISION (int_mode));\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \t  else if (GET_CODE (lhs) == MULT\n \t\t   && CONST_SCALAR_INT_P (XEXP (lhs, 1)))\n \t    {\n-\t      coeff0 = rtx_mode_t (XEXP (lhs, 1), mode);\n+\t      coeff0 = rtx_mode_t (XEXP (lhs, 1), int_mode);\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \t  else if (GET_CODE (lhs) == ASHIFT\n \t\t   && CONST_INT_P (XEXP (lhs, 1))\n \t\t   && INTVAL (XEXP (lhs, 1)) >= 0\n-\t\t   && INTVAL (XEXP (lhs, 1)) < GET_MODE_PRECISION (mode))\n+\t\t   && INTVAL (XEXP (lhs, 1)) < GET_MODE_PRECISION (int_mode))\n \t    {\n \t      coeff0 = wi::set_bit_in_zero (INTVAL (XEXP (lhs, 1)),\n-\t\t\t\t\t    GET_MODE_PRECISION (mode));\n+\t\t\t\t\t    GET_MODE_PRECISION (int_mode));\n \t      lhs = XEXP (lhs, 0);\n \t    }\n \n \t  if (GET_CODE (rhs) == NEG)\n \t    {\n-\t      negcoeff1 = wi::one (GET_MODE_PRECISION (mode));\n+\t      negcoeff1 = wi::one (GET_MODE_PRECISION (int_mode));\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \t  else if (GET_CODE (rhs) == MULT\n \t\t   && CONST_INT_P (XEXP (rhs, 1)))\n \t    {\n-\t      negcoeff1 = wi::neg (rtx_mode_t (XEXP (rhs, 1), mode));\n+\t      negcoeff1 = wi::neg (rtx_mode_t (XEXP (rhs, 1), int_mode));\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \t  else if (GET_CODE (rhs) == ASHIFT\n \t\t   && CONST_INT_P (XEXP (rhs, 1))\n \t\t   && INTVAL (XEXP (rhs, 1)) >= 0\n-\t\t   && INTVAL (XEXP (rhs, 1)) < GET_MODE_PRECISION (mode))\n+\t\t   && INTVAL (XEXP (rhs, 1)) < GET_MODE_PRECISION (int_mode))\n \t    {\n \t      negcoeff1 = wi::set_bit_in_zero (INTVAL (XEXP (rhs, 1)),\n-\t\t\t\t\t       GET_MODE_PRECISION (mode));\n+\t\t\t\t\t       GET_MODE_PRECISION (int_mode));\n \t      negcoeff1 = -negcoeff1;\n \t      rhs = XEXP (rhs, 0);\n \t    }\n \n \t  if (rtx_equal_p (lhs, rhs))\n \t    {\n-\t      rtx orig = gen_rtx_MINUS (mode, op0, op1);\n+\t      rtx orig = gen_rtx_MINUS (int_mode, op0, op1);\n \t      rtx coeff;\n \t      bool speed = optimize_function_for_speed_p (cfun);\n \n-\t      coeff = immed_wide_int_const (coeff0 + negcoeff1, mode);\n+\t      coeff = immed_wide_int_const (coeff0 + negcoeff1, int_mode);\n \n-\t      tem = simplify_gen_binary (MULT, mode, lhs, coeff);\n-\t      return (set_src_cost (tem, mode, speed)\n-\t\t      <= set_src_cost (orig, mode, speed) ? tem : 0);\n+\t      tem = simplify_gen_binary (MULT, int_mode, lhs, coeff);\n+\t      return (set_src_cost (tem, int_mode, speed)\n+\t\t      <= set_src_cost (orig, int_mode, speed) ? tem : 0);\n \t    }\n \t}\n \n@@ -3899,8 +3901,6 @@ rtx\n simplify_const_binary_operation (enum rtx_code code, machine_mode mode,\n \t\t\t\t rtx op0, rtx op1)\n {\n-  unsigned int width = GET_MODE_PRECISION (mode);\n-\n   if (VECTOR_MODE_P (mode)\n       && code != VEC_CONCAT\n       && GET_CODE (op0) == CONST_VECTOR\n@@ -4094,15 +4094,15 @@ simplify_const_binary_operation (enum rtx_code code, machine_mode mode,\n     }\n \n   /* We can fold some multi-word operations.  */\n-  if ((GET_MODE_CLASS (mode) == MODE_INT\n-       || GET_MODE_CLASS (mode) == MODE_PARTIAL_INT)\n+  scalar_int_mode int_mode;\n+  if (is_a <scalar_int_mode> (mode, &int_mode)\n       && CONST_SCALAR_INT_P (op0)\n       && CONST_SCALAR_INT_P (op1))\n     {\n       wide_int result;\n       bool overflow;\n-      rtx_mode_t pop0 = rtx_mode_t (op0, mode);\n-      rtx_mode_t pop1 = rtx_mode_t (op1, mode);\n+      rtx_mode_t pop0 = rtx_mode_t (op0, int_mode);\n+      rtx_mode_t pop1 = rtx_mode_t (op1, int_mode);\n \n #if TARGET_SUPPORTS_WIDE_INT == 0\n       /* This assert keeps the simplification from producing a result\n@@ -4111,7 +4111,7 @@ simplify_const_binary_operation (enum rtx_code code, machine_mode mode,\n \t simplify something and so you if you added this to the test\n \t above the code would die later anyway.  If this assert\n \t happens, you just need to make the port support wide int.  */\n-      gcc_assert (width <= HOST_BITS_PER_DOUBLE_INT);\n+      gcc_assert (GET_MODE_PRECISION (int_mode) <= HOST_BITS_PER_DOUBLE_INT);\n #endif\n       switch (code)\n \t{\n@@ -4185,8 +4185,8 @@ simplify_const_binary_operation (enum rtx_code code, machine_mode mode,\n \t  {\n \t    wide_int wop1 = pop1;\n \t    if (SHIFT_COUNT_TRUNCATED)\n-\t      wop1 = wi::umod_trunc (wop1, width);\n-\t    else if (wi::geu_p (wop1, width))\n+\t      wop1 = wi::umod_trunc (wop1, GET_MODE_PRECISION (int_mode));\n+\t    else if (wi::geu_p (wop1, GET_MODE_PRECISION (int_mode)))\n \t      return NULL_RTX;\n \n \t    switch (code)\n@@ -4232,7 +4232,7 @@ simplify_const_binary_operation (enum rtx_code code, machine_mode mode,\n \tdefault:\n \t  return NULL_RTX;\n \t}\n-      return immed_wide_int_const (result, mode);\n+      return immed_wide_int_const (result, int_mode);\n     }\n \n   return NULL_RTX;\n@@ -5154,12 +5154,14 @@ simplify_const_relational_operation (enum rtx_code code,\n     }\n \n   /* Optimize comparisons with upper and lower bounds.  */\n-  if (HWI_COMPUTABLE_MODE_P (mode)\n-      && CONST_INT_P (trueop1)\n+  scalar_int_mode int_mode;\n+  if (CONST_INT_P (trueop1)\n+      && is_a <scalar_int_mode> (mode, &int_mode)\n+      && HWI_COMPUTABLE_MODE_P (int_mode)\n       && !side_effects_p (trueop0))\n     {\n       int sign;\n-      unsigned HOST_WIDE_INT nonzero = nonzero_bits (trueop0, mode);\n+      unsigned HOST_WIDE_INT nonzero = nonzero_bits (trueop0, int_mode);\n       HOST_WIDE_INT val = INTVAL (trueop1);\n       HOST_WIDE_INT mmin, mmax;\n \n@@ -5172,21 +5174,22 @@ simplify_const_relational_operation (enum rtx_code code,\n \tsign = 1;\n \n       /* Get a reduced range if the sign bit is zero.  */\n-      if (nonzero <= (GET_MODE_MASK (mode) >> 1))\n+      if (nonzero <= (GET_MODE_MASK (int_mode) >> 1))\n \t{\n \t  mmin = 0;\n \t  mmax = nonzero;\n \t}\n       else\n \t{\n \t  rtx mmin_rtx, mmax_rtx;\n-\t  get_mode_bounds (mode, sign, mode, &mmin_rtx, &mmax_rtx);\n+\t  get_mode_bounds (int_mode, sign, int_mode, &mmin_rtx, &mmax_rtx);\n \n \t  mmin = INTVAL (mmin_rtx);\n \t  mmax = INTVAL (mmax_rtx);\n \t  if (sign)\n \t    {\n-\t      unsigned int sign_copies = num_sign_bit_copies (trueop0, mode);\n+\t      unsigned int sign_copies\n+\t\t= num_sign_bit_copies (trueop0, int_mode);\n \n \t      mmin >>= (sign_copies - 1);\n \t      mmax >>= (sign_copies - 1);\n@@ -6238,12 +6241,14 @@ simplify_subreg (machine_mode outermode, rtx op,\n \treturn CONST0_RTX (outermode);\n     }\n \n-  if (SCALAR_INT_MODE_P (outermode)\n-      && SCALAR_INT_MODE_P (innermode)\n-      && GET_MODE_PRECISION (outermode) < GET_MODE_PRECISION (innermode)\n-      && byte == subreg_lowpart_offset (outermode, innermode))\n+  scalar_int_mode int_outermode, int_innermode;\n+  if (is_a <scalar_int_mode> (outermode, &int_outermode)\n+      && is_a <scalar_int_mode> (innermode, &int_innermode)\n+      && (GET_MODE_PRECISION (int_outermode)\n+\t  < GET_MODE_PRECISION (int_innermode))\n+      && byte == subreg_lowpart_offset (int_outermode, int_innermode))\n     {\n-      rtx tem = simplify_truncation (outermode, op, innermode);\n+      rtx tem = simplify_truncation (int_outermode, op, int_innermode);\n       if (tem)\n \treturn tem;\n     }"}, {"sha": "c859c8b07dedca77101f01d1de9b6c5ac9264251", "filename": "gcc/stor-layout.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fstor-layout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fstor-layout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -412,8 +412,10 @@ bitwise_mode_for_mode (machine_mode mode)\n {\n   /* Quick exit if we already have a suitable mode.  */\n   unsigned int bitsize = GET_MODE_BITSIZE (mode);\n-  if (SCALAR_INT_MODE_P (mode) && bitsize <= MAX_FIXED_MODE_SIZE)\n-    return mode;\n+  scalar_int_mode int_mode;\n+  if (is_a <scalar_int_mode> (mode, &int_mode)\n+      && GET_MODE_BITSIZE (int_mode) <= MAX_FIXED_MODE_SIZE)\n+    return int_mode;\n \n   /* Reuse the sanity checks from int_mode_for_mode.  */\n   gcc_checking_assert ((int_mode_for_mode (mode), true));"}, {"sha": "83a9e5af524caf90997212c9ccbc0dba31670fa8", "filename": "gcc/var-tracking.c", "status": "modified", "additions": 12, "deletions": 13, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fvar-tracking.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fvar-tracking.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvar-tracking.c?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -1008,6 +1008,7 @@ adjust_mems (rtx loc, const_rtx old_rtx, void *data)\n   rtx mem, addr = loc, tem;\n   machine_mode mem_mode_save;\n   bool store_save;\n+  scalar_int_mode tem_mode, tem_subreg_mode;\n   switch (GET_CODE (loc))\n     {\n     case REG:\n@@ -1122,16 +1123,14 @@ adjust_mems (rtx loc, const_rtx old_rtx, void *data)\n \t      || GET_CODE (SUBREG_REG (tem)) == MINUS\n \t      || GET_CODE (SUBREG_REG (tem)) == MULT\n \t      || GET_CODE (SUBREG_REG (tem)) == ASHIFT)\n-\t  && (GET_MODE_CLASS (GET_MODE (tem)) == MODE_INT\n-\t      || GET_MODE_CLASS (GET_MODE (tem)) == MODE_PARTIAL_INT)\n-\t  && (GET_MODE_CLASS (GET_MODE (SUBREG_REG (tem))) == MODE_INT\n-\t      || GET_MODE_CLASS (GET_MODE (SUBREG_REG (tem))) == MODE_PARTIAL_INT)\n-\t  && GET_MODE_PRECISION (GET_MODE (tem))\n-\t     < GET_MODE_PRECISION (GET_MODE (SUBREG_REG (tem)))\n+\t  && is_a <scalar_int_mode> (GET_MODE (tem), &tem_mode)\n+\t  && is_a <scalar_int_mode> (GET_MODE (SUBREG_REG (tem)),\n+\t\t\t\t     &tem_subreg_mode)\n+\t  && (GET_MODE_PRECISION (tem_mode)\n+\t      < GET_MODE_PRECISION (tem_subreg_mode))\n \t  && subreg_lowpart_p (tem)\n \t  && use_narrower_mode_test (SUBREG_REG (tem), tem))\n-\treturn use_narrower_mode (SUBREG_REG (tem), GET_MODE (tem),\n-\t\t\t\t  GET_MODE (SUBREG_REG (tem)));\n+\treturn use_narrower_mode (SUBREG_REG (tem), tem_mode, tem_subreg_mode);\n       return tem;\n     case ASM_OPERANDS:\n       /* Don't do any replacements in second and following\n@@ -6301,15 +6300,15 @@ prepare_call_arguments (basic_block bb, rtx_insn *insn)\n \telse if (REG_P (x))\n \t  {\n \t    cselib_val *val = cselib_lookup (x, GET_MODE (x), 0, VOIDmode);\n+\t    scalar_int_mode mode;\n \t    if (val && cselib_preserved_value_p (val))\n \t      item = val->val_rtx;\n-\t    else if (GET_MODE_CLASS (GET_MODE (x)) == MODE_INT\n-\t\t     || GET_MODE_CLASS (GET_MODE (x)) == MODE_PARTIAL_INT)\n+\t    else if (is_a <scalar_int_mode> (GET_MODE (x), &mode))\n \t      {\n-\t\tmachine_mode mode;\n-\n-\t\tFOR_EACH_WIDER_MODE (mode, GET_MODE (x))\n+\t\topt_scalar_int_mode mode_iter;\n+\t\tFOR_EACH_WIDER_MODE (mode_iter, mode)\n \t\t  {\n+\t\t    mode = mode_iter.require ();\n \t\t    if (GET_MODE_BITSIZE (mode) > BITS_PER_WORD)\n \t\t      break;\n "}, {"sha": "61d9aab2a83d31eb1ea1c373104679138f991d9f", "filename": "gcc/wide-int.h", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fwide-int.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b0567726a311d3f2fcec5b62380675231cd610c9/gcc%2Fwide-int.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fwide-int.h?ref=b0567726a311d3f2fcec5b62380675231cd610c9", "patch": "@@ -1467,6 +1467,14 @@ wi::primitive_int_traits <T, signed_p>::decompose (HOST_WIDE_INT *scratch,\n /* Allow primitive C types to be used in wi:: routines.  */\n namespace wi\n {\n+  template <>\n+  struct int_traits <unsigned char>\n+    : public primitive_int_traits <unsigned char, false> {};\n+\n+  template <>\n+  struct int_traits <unsigned short>\n+    : public primitive_int_traits <unsigned short, false> {};\n+\n   template <>\n   struct int_traits <int>\n     : public primitive_int_traits <int, true> {};"}]}