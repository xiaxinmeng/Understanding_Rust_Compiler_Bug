{"sha": "8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OGFmYWNmMmMzNjVhZmE5YzNiMDg0NzI4ZDNiYmM1ZDFmYTJmYjY5ZQ==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-08-30T11:08:00Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-08-30T11:08:00Z"}, "message": "Split out parts of scompare_loc_descriptor and emit_store_flag\n\nThis patch splits some cases out of scompare_loc_descriptor and\nemit_store_flag, which helps with the upcoming machmode series.\n\n2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n\ngcc/\n\t* dwarf2out.c (scompare_loc_descriptor_wide)\n\t(scompare_loc_descriptor_narrow): New functions, split out from...\n\t(scompare_loc_descriptor): ...here.\n\t* expmed.c (emit_store_flag_int): New function, split out from...\n\t(emit_store_flag): ...here.\n\nFrom-SVN: r251451", "tree": {"sha": "cdfcef0bf928cbc93a5be0080551cdc3dd1a676a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/cdfcef0bf928cbc93a5be0080551cdc3dd1a676a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e/comments", "author": null, "committer": null, "parents": [{"sha": "70704d4272d3930c29c583b2bca51bf99f570c73", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/70704d4272d3930c29c583b2bca51bf99f570c73", "html_url": "https://github.com/Rust-GCC/gccrs/commit/70704d4272d3930c29c583b2bca51bf99f570c73"}], "stats": {"total": 443, "additions": 246, "deletions": 197}, "files": [{"sha": "64aa109c4acc9940abb78b2e512b462ea612c0b9", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e", "patch": "@@ -1,3 +1,11 @@\n+2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n+\n+\t* dwarf2out.c (scompare_loc_descriptor_wide)\n+\t(scompare_loc_descriptor_narrow): New functions, split out from...\n+\t(scompare_loc_descriptor): ...here.\n+\t* expmed.c (emit_store_flag_int): New function, split out from...\n+\t(emit_store_flag): ...here.\n+\n 2017-08-30  Richard Biener  <rguenther@suse.de>\n \n \t* dwarf2out.c (dwarf2out_finish): Remove setting AT_pubnames."}, {"sha": "e17b58ab7b06a93b65de2a541826172ce48b3ab8", "filename": "gcc/dwarf2out.c", "status": "modified", "additions": 69, "deletions": 47, "changes": 116, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e/gcc%2Fdwarf2out.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e/gcc%2Fdwarf2out.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdwarf2out.c?ref=8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e", "patch": "@@ -13929,60 +13929,43 @@ compare_loc_descriptor (enum dwarf_location_atom op, dw_loc_descr_ref op0,\n   return ret;\n }\n \n-/* Return location descriptor for signed comparison OP RTL.  */\n+/* Subroutine of scompare_loc_descriptor for the case in which we're\n+   comparing two scalar integer operands OP0 and OP1 that have mode OP_MODE,\n+   and in which OP_MODE is bigger than DWARF2_ADDR_SIZE.  */\n \n static dw_loc_descr_ref\n-scompare_loc_descriptor (enum dwarf_location_atom op, rtx rtl,\n-\t\t\t machine_mode mem_mode)\n+scompare_loc_descriptor_wide (enum dwarf_location_atom op,\n+\t\t\t      machine_mode op_mode,\n+\t\t\t      dw_loc_descr_ref op0, dw_loc_descr_ref op1)\n {\n-  machine_mode op_mode = GET_MODE (XEXP (rtl, 0));\n-  dw_loc_descr_ref op0, op1;\n-  int shift;\n-\n-  if (op_mode == VOIDmode)\n-    op_mode = GET_MODE (XEXP (rtl, 1));\n-  if (op_mode == VOIDmode)\n-    return NULL;\n-\n-  if (dwarf_strict\n-      && dwarf_version < 5\n-      && (!SCALAR_INT_MODE_P (op_mode)\n-\t  || GET_MODE_SIZE (op_mode) > DWARF2_ADDR_SIZE))\n-    return NULL;\n-\n-  op0 = mem_loc_descriptor (XEXP (rtl, 0), op_mode, mem_mode,\n-\t\t\t    VAR_INIT_STATUS_INITIALIZED);\n-  op1 = mem_loc_descriptor (XEXP (rtl, 1), op_mode, mem_mode,\n-\t\t\t    VAR_INIT_STATUS_INITIALIZED);\n+  dw_die_ref type_die = base_type_for_mode (op_mode, 0);\n+  dw_loc_descr_ref cvt;\n \n-  if (op0 == NULL || op1 == NULL)\n+  if (type_die == NULL)\n     return NULL;\n+  cvt = new_loc_descr (dwarf_OP (DW_OP_convert), 0, 0);\n+  cvt->dw_loc_oprnd1.val_class = dw_val_class_die_ref;\n+  cvt->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n+  cvt->dw_loc_oprnd1.v.val_die_ref.external = 0;\n+  add_loc_descr (&op0, cvt);\n+  cvt = new_loc_descr (dwarf_OP (DW_OP_convert), 0, 0);\n+  cvt->dw_loc_oprnd1.val_class = dw_val_class_die_ref;\n+  cvt->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n+  cvt->dw_loc_oprnd1.v.val_die_ref.external = 0;\n+  add_loc_descr (&op1, cvt);\n+  return compare_loc_descriptor (op, op0, op1);\n+}\n \n-  if (!SCALAR_INT_MODE_P (op_mode)\n-      || GET_MODE_SIZE (op_mode) == DWARF2_ADDR_SIZE)\n-    return compare_loc_descriptor (op, op0, op1);\n-\n-  if (GET_MODE_SIZE (op_mode) > DWARF2_ADDR_SIZE)\n-    {\n-      dw_die_ref type_die = base_type_for_mode (op_mode, 0);\n-      dw_loc_descr_ref cvt;\n+/* Subroutine of scompare_loc_descriptor for the case in which we're\n+   comparing two scalar integer operands OP0 and OP1 that have mode OP_MODE,\n+   and in which OP_MODE is smaller than DWARF2_ADDR_SIZE.  */\n \n-      if (type_die == NULL)\n-\treturn NULL;\n-      cvt = new_loc_descr (dwarf_OP (DW_OP_convert), 0, 0);\n-      cvt->dw_loc_oprnd1.val_class = dw_val_class_die_ref;\n-      cvt->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n-      cvt->dw_loc_oprnd1.v.val_die_ref.external = 0;\n-      add_loc_descr (&op0, cvt);\n-      cvt = new_loc_descr (dwarf_OP (DW_OP_convert), 0, 0);\n-      cvt->dw_loc_oprnd1.val_class = dw_val_class_die_ref;\n-      cvt->dw_loc_oprnd1.v.val_die_ref.die = type_die;\n-      cvt->dw_loc_oprnd1.v.val_die_ref.external = 0;\n-      add_loc_descr (&op1, cvt);\n-      return compare_loc_descriptor (op, op0, op1);\n-    }\n-\n-  shift = (DWARF2_ADDR_SIZE - GET_MODE_SIZE (op_mode)) * BITS_PER_UNIT;\n+static dw_loc_descr_ref\n+scompare_loc_descriptor_narrow (enum dwarf_location_atom op, rtx rtl,\n+\t\t\t\tmachine_mode op_mode,\n+\t\t\t\tdw_loc_descr_ref op0, dw_loc_descr_ref op1)\n+{\n+  int shift = (DWARF2_ADDR_SIZE - GET_MODE_SIZE (op_mode)) * BITS_PER_UNIT;\n   /* For eq/ne, if the operands are known to be zero-extended,\n      there is no need to do the fancy shifting up.  */\n   if (op == DW_OP_eq || op == DW_OP_ne)\n@@ -14040,6 +14023,45 @@ scompare_loc_descriptor (enum dwarf_location_atom op, rtx rtl,\n   return compare_loc_descriptor (op, op0, op1);\n }\n \n+/* Return location descriptor for signed comparison OP RTL.  */\n+\n+static dw_loc_descr_ref\n+scompare_loc_descriptor (enum dwarf_location_atom op, rtx rtl,\n+\t\t\t machine_mode mem_mode)\n+{\n+  machine_mode op_mode = GET_MODE (XEXP (rtl, 0));\n+  dw_loc_descr_ref op0, op1;\n+\n+  if (op_mode == VOIDmode)\n+    op_mode = GET_MODE (XEXP (rtl, 1));\n+  if (op_mode == VOIDmode)\n+    return NULL;\n+\n+  if (dwarf_strict\n+      && dwarf_version < 5\n+      && (!SCALAR_INT_MODE_P (op_mode)\n+\t  || GET_MODE_SIZE (op_mode) > DWARF2_ADDR_SIZE))\n+    return NULL;\n+\n+  op0 = mem_loc_descriptor (XEXP (rtl, 0), op_mode, mem_mode,\n+\t\t\t    VAR_INIT_STATUS_INITIALIZED);\n+  op1 = mem_loc_descriptor (XEXP (rtl, 1), op_mode, mem_mode,\n+\t\t\t    VAR_INIT_STATUS_INITIALIZED);\n+\n+  if (op0 == NULL || op1 == NULL)\n+    return NULL;\n+\n+  if (SCALAR_INT_MODE_P (op_mode))\n+    {\n+      if (GET_MODE_SIZE (op_mode) < DWARF2_ADDR_SIZE)\n+\treturn scompare_loc_descriptor_narrow (op, rtl, op_mode, op0, op1);\n+\n+      if (GET_MODE_SIZE (op_mode) > DWARF2_ADDR_SIZE)\n+\treturn scompare_loc_descriptor_wide (op, op_mode, op0, op1);\n+    }\n+  return compare_loc_descriptor (op, op0, op1);\n+}\n+\n /* Return location descriptor for unsigned comparison OP RTL.  */\n \n static dw_loc_descr_ref"}, {"sha": "7eeadc1d694966c361fcd3778d8da5d4de0f9c21", "filename": "gcc/expmed.c", "status": "modified", "additions": 169, "deletions": 150, "changes": 319, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=8afacf2c365afa9c3b084728d3bbc5d1fa2fb69e", "patch": "@@ -5583,155 +5583,19 @@ emit_store_flag_1 (rtx target, enum rtx_code code, rtx op0, rtx op1,\n   return 0;\n }\n \n-/* Emit a store-flags instruction for comparison CODE on OP0 and OP1\n-   and storing in TARGET.  Normally return TARGET.\n-   Return 0 if that cannot be done.\n-\n-   MODE is the mode to use for OP0 and OP1 should they be CONST_INTs.  If\n-   it is VOIDmode, they cannot both be CONST_INT.\n-\n-   UNSIGNEDP is for the case where we have to widen the operands\n-   to perform the operation.  It says to use zero-extension.\n-\n-   NORMALIZEP is 1 if we should convert the result to be either zero\n-   or one.  Normalize is -1 if we should convert the result to be\n-   either zero or -1.  If NORMALIZEP is zero, the result will be left\n-   \"raw\" out of the scc insn.  */\n+/* Subroutine of emit_store_flag that handles cases in which the operands\n+   are scalar integers.  SUBTARGET is the target to use for temporary\n+   operations and TRUEVAL is the value to store when the condition is\n+   true.  All other arguments are as for emit_store_flag.  */\n \n rtx\n-emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n-\t\t machine_mode mode, int unsignedp, int normalizep)\n+emit_store_flag_int (rtx target, rtx subtarget, enum rtx_code code, rtx op0,\n+\t\t     rtx op1, machine_mode mode, int unsignedp,\n+\t\t     int normalizep, rtx trueval)\n {\n   machine_mode target_mode = target ? GET_MODE (target) : VOIDmode;\n-  enum rtx_code rcode;\n-  rtx subtarget;\n-  rtx tem, trueval;\n-  rtx_insn *last;\n-\n-  /* If we compare constants, we shouldn't use a store-flag operation,\n-     but a constant load.  We can get there via the vanilla route that\n-     usually generates a compare-branch sequence, but will in this case\n-     fold the comparison to a constant, and thus elide the branch.  */\n-  if (CONSTANT_P (op0) && CONSTANT_P (op1))\n-    return NULL_RTX;\n-\n-  tem = emit_store_flag_1 (target, code, op0, op1, mode, unsignedp, normalizep,\n-\t\t\t   target_mode);\n-  if (tem)\n-    return tem;\n-\n-  /* If we reached here, we can't do this with a scc insn, however there\n-     are some comparisons that can be done in other ways.  Don't do any\n-     of these cases if branches are very cheap.  */\n-  if (BRANCH_COST (optimize_insn_for_speed_p (), false) == 0)\n-    return 0;\n-\n-  /* See what we need to return.  We can only return a 1, -1, or the\n-     sign bit.  */\n-\n-  if (normalizep == 0)\n-    {\n-      if (STORE_FLAG_VALUE == 1 || STORE_FLAG_VALUE == -1)\n-\tnormalizep = STORE_FLAG_VALUE;\n-\n-      else if (val_signbit_p (mode, STORE_FLAG_VALUE))\n-\t;\n-      else\n-\treturn 0;\n-    }\n-\n-  last = get_last_insn ();\n-\n-  /* If optimizing, use different pseudo registers for each insn, instead\n-     of reusing the same pseudo.  This leads to better CSE, but slows\n-     down the compiler, since there are more pseudos */\n-  subtarget = (!optimize\n-\t       && (target_mode == mode)) ? target : NULL_RTX;\n-  trueval = GEN_INT (normalizep ? normalizep : STORE_FLAG_VALUE);\n-\n-  /* For floating-point comparisons, try the reverse comparison or try\n-     changing the \"orderedness\" of the comparison.  */\n-  if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n-    {\n-      enum rtx_code first_code;\n-      bool and_them;\n-\n-      rcode = reverse_condition_maybe_unordered (code);\n-      if (can_compare_p (rcode, mode, ccp_store_flag)\n-          && (code == ORDERED || code == UNORDERED\n-\t      || (! HONOR_NANS (mode) && (code == LTGT || code == UNEQ))\n-\t      || (! HONOR_SNANS (mode) && (code == EQ || code == NE))))\n-\t{\n-          int want_add = ((STORE_FLAG_VALUE == 1 && normalizep == -1)\n-\t\t          || (STORE_FLAG_VALUE == -1 && normalizep == 1));\n-\n-\t  /* For the reverse comparison, use either an addition or a XOR.  */\n-          if (want_add\n-\t      && rtx_cost (GEN_INT (normalizep), mode, PLUS, 1,\n-\t\t\t   optimize_insn_for_speed_p ()) == 0)\n-\t    {\n-\t      tem = emit_store_flag_1 (subtarget, rcode, op0, op1, mode, 0,\n-\t\t\t\t       STORE_FLAG_VALUE, target_mode);\n-\t      if (tem)\n-                return expand_binop (target_mode, add_optab, tem,\n-\t\t\t\t     gen_int_mode (normalizep, target_mode),\n-\t\t\t\t     target, 0, OPTAB_WIDEN);\n-\t    }\n-          else if (!want_add\n-\t           && rtx_cost (trueval, mode, XOR, 1,\n-\t\t\t        optimize_insn_for_speed_p ()) == 0)\n-\t    {\n-\t      tem = emit_store_flag_1 (subtarget, rcode, op0, op1, mode, 0,\n-\t\t\t\t       normalizep, target_mode);\n-\t      if (tem)\n-                return expand_binop (target_mode, xor_optab, tem, trueval,\n-\t\t\t\t     target, INTVAL (trueval) >= 0, OPTAB_WIDEN);\n-\t    }\n-\t}\n-\n-      delete_insns_since (last);\n-\n-      /* Cannot split ORDERED and UNORDERED, only try the above trick.   */\n-      if (code == ORDERED || code == UNORDERED)\n-\treturn 0;\n-\n-      and_them = split_comparison (code, mode, &first_code, &code);\n-\n-      /* If there are no NaNs, the first comparison should always fall through.\n-         Effectively change the comparison to the other one.  */\n-      if (!HONOR_NANS (mode))\n-\t{\n-          gcc_assert (first_code == (and_them ? ORDERED : UNORDERED));\n-\t  return emit_store_flag_1 (target, code, op0, op1, mode, 0, normalizep,\n-\t\t\t\t    target_mode);\n-\t}\n-\n-      if (!HAVE_conditional_move)\n-\treturn 0;\n-\n-      /* Try using a setcc instruction for ORDERED/UNORDERED, followed by a\n-\t conditional move.  */\n-      tem = emit_store_flag_1 (subtarget, first_code, op0, op1, mode, 0,\n-\t\t\t       normalizep, target_mode);\n-      if (tem == 0)\n-\treturn 0;\n-\n-      if (and_them)\n-        tem = emit_conditional_move (target, code, op0, op1, mode,\n-\t\t\t\t     tem, const0_rtx, GET_MODE (tem), 0);\n-      else\n-        tem = emit_conditional_move (target, code, op0, op1, mode,\n-\t\t\t\t     trueval, tem, GET_MODE (tem), 0);\n-\n-      if (tem == 0)\n-        delete_insns_since (last);\n-      return tem;\n-    }\n-\n-  /* The remaining tricks only apply to integer comparisons.  */\n-\n-  if (GET_MODE_CLASS (mode) != MODE_INT)\n-    return 0;\n+  rtx_insn *last = get_last_insn ();\n+  rtx tem;\n \n   /* If this is an equality comparison of integers, we can try to exclusive-or\n      (or subtract) the two operands and use a recursive call to try the\n@@ -5758,7 +5622,7 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n   /* For integer comparisons, try the reverse comparison.  However, for\n      small X and if we'd have anyway to extend, implementing \"X != 0\"\n      as \"-(int)X >> 31\" is still cheaper than inverting \"(int)X == 0\".  */\n-  rcode = reverse_condition (code);\n+  rtx_code rcode = reverse_condition (code);\n   if (can_compare_p (rcode, mode, ccp_store_flag)\n       && ! (optab_handler (cstore_optab, mode) == CODE_FOR_nothing\n \t    && code == NE\n@@ -5776,7 +5640,7 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n \t  tem = emit_store_flag_1 (subtarget, rcode, op0, op1, mode, 0,\n \t\t\t\t   STORE_FLAG_VALUE, target_mode);\n \t  if (tem != 0)\n-            tem = expand_binop (target_mode, add_optab, tem,\n+\t    tem = expand_binop (target_mode, add_optab, tem,\n \t\t\t\tgen_int_mode (normalizep, target_mode),\n \t\t\t\ttarget, 0, OPTAB_WIDEN);\n \t}\n@@ -5787,7 +5651,7 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n \t  tem = emit_store_flag_1 (subtarget, rcode, op0, op1, mode, 0,\n \t\t\t\t   normalizep, target_mode);\n \t  if (tem != 0)\n-            tem = expand_binop (target_mode, xor_optab, tem, trueval, target,\n+\t    tem = expand_binop (target_mode, xor_optab, tem, trueval, target,\n \t\t\t\tINTVAL (trueval) >= 0, OPTAB_WIDEN);\n \t}\n \n@@ -5888,7 +5752,7 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n       if (tem == 0\n \t  && (code == NE\n \t      || BRANCH_COST (optimize_insn_for_speed_p (),\n-\t\t      \t      false) > 1))\n+\t\t\t      false) > 1))\n \t{\n \t  if (rtx_equal_p (subtarget, op0))\n \t    subtarget = 0;\n@@ -5910,7 +5774,7 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n   if (tem)\n     {\n       if (!target)\n-        ;\n+\t;\n       else if (GET_MODE (tem) != target_mode)\n \t{\n \t  convert_move (target, tem, 0);\n@@ -5928,6 +5792,161 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n   return tem;\n }\n \n+/* Emit a store-flags instruction for comparison CODE on OP0 and OP1\n+   and storing in TARGET.  Normally return TARGET.\n+   Return 0 if that cannot be done.\n+\n+   MODE is the mode to use for OP0 and OP1 should they be CONST_INTs.  If\n+   it is VOIDmode, they cannot both be CONST_INT.\n+\n+   UNSIGNEDP is for the case where we have to widen the operands\n+   to perform the operation.  It says to use zero-extension.\n+\n+   NORMALIZEP is 1 if we should convert the result to be either zero\n+   or one.  Normalize is -1 if we should convert the result to be\n+   either zero or -1.  If NORMALIZEP is zero, the result will be left\n+   \"raw\" out of the scc insn.  */\n+\n+rtx\n+emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n+\t\t machine_mode mode, int unsignedp, int normalizep)\n+{\n+  machine_mode target_mode = target ? GET_MODE (target) : VOIDmode;\n+  enum rtx_code rcode;\n+  rtx subtarget;\n+  rtx tem, trueval;\n+  rtx_insn *last;\n+\n+  /* If we compare constants, we shouldn't use a store-flag operation,\n+     but a constant load.  We can get there via the vanilla route that\n+     usually generates a compare-branch sequence, but will in this case\n+     fold the comparison to a constant, and thus elide the branch.  */\n+  if (CONSTANT_P (op0) && CONSTANT_P (op1))\n+    return NULL_RTX;\n+\n+  tem = emit_store_flag_1 (target, code, op0, op1, mode, unsignedp, normalizep,\n+\t\t\t   target_mode);\n+  if (tem)\n+    return tem;\n+\n+  /* If we reached here, we can't do this with a scc insn, however there\n+     are some comparisons that can be done in other ways.  Don't do any\n+     of these cases if branches are very cheap.  */\n+  if (BRANCH_COST (optimize_insn_for_speed_p (), false) == 0)\n+    return 0;\n+\n+  /* See what we need to return.  We can only return a 1, -1, or the\n+     sign bit.  */\n+\n+  if (normalizep == 0)\n+    {\n+      if (STORE_FLAG_VALUE == 1 || STORE_FLAG_VALUE == -1)\n+\tnormalizep = STORE_FLAG_VALUE;\n+\n+      else if (val_signbit_p (mode, STORE_FLAG_VALUE))\n+\t;\n+      else\n+\treturn 0;\n+    }\n+\n+  last = get_last_insn ();\n+\n+  /* If optimizing, use different pseudo registers for each insn, instead\n+     of reusing the same pseudo.  This leads to better CSE, but slows\n+     down the compiler, since there are more pseudos.  */\n+  subtarget = (!optimize\n+\t       && (target_mode == mode)) ? target : NULL_RTX;\n+  trueval = GEN_INT (normalizep ? normalizep : STORE_FLAG_VALUE);\n+\n+  /* For floating-point comparisons, try the reverse comparison or try\n+     changing the \"orderedness\" of the comparison.  */\n+  if (GET_MODE_CLASS (mode) == MODE_FLOAT)\n+    {\n+      enum rtx_code first_code;\n+      bool and_them;\n+\n+      rcode = reverse_condition_maybe_unordered (code);\n+      if (can_compare_p (rcode, mode, ccp_store_flag)\n+\t  && (code == ORDERED || code == UNORDERED\n+\t      || (! HONOR_NANS (mode) && (code == LTGT || code == UNEQ))\n+\t      || (! HONOR_SNANS (mode) && (code == EQ || code == NE))))\n+\t{\n+\t  int want_add = ((STORE_FLAG_VALUE == 1 && normalizep == -1)\n+\t\t\t  || (STORE_FLAG_VALUE == -1 && normalizep == 1));\n+\n+\t  /* For the reverse comparison, use either an addition or a XOR.  */\n+\t  if (want_add\n+\t      && rtx_cost (GEN_INT (normalizep), mode, PLUS, 1,\n+\t\t\t   optimize_insn_for_speed_p ()) == 0)\n+\t    {\n+\t      tem = emit_store_flag_1 (subtarget, rcode, op0, op1, mode, 0,\n+\t\t\t\t       STORE_FLAG_VALUE, target_mode);\n+\t      if (tem)\n+\t\treturn expand_binop (target_mode, add_optab, tem,\n+\t\t\t\t     gen_int_mode (normalizep, target_mode),\n+\t\t\t\t     target, 0, OPTAB_WIDEN);\n+\t    }\n+\t  else if (!want_add\n+\t\t   && rtx_cost (trueval, mode, XOR, 1,\n+\t\t\t\toptimize_insn_for_speed_p ()) == 0)\n+\t    {\n+\t      tem = emit_store_flag_1 (subtarget, rcode, op0, op1, mode, 0,\n+\t\t\t\t       normalizep, target_mode);\n+\t      if (tem)\n+\t\treturn expand_binop (target_mode, xor_optab, tem, trueval,\n+\t\t\t\t     target, INTVAL (trueval) >= 0,\n+\t\t\t\t     OPTAB_WIDEN);\n+\t    }\n+\t}\n+\n+      delete_insns_since (last);\n+\n+      /* Cannot split ORDERED and UNORDERED, only try the above trick.  */\n+      if (code == ORDERED || code == UNORDERED)\n+\treturn 0;\n+\n+      and_them = split_comparison (code, mode, &first_code, &code);\n+\n+      /* If there are no NaNs, the first comparison should always fall through.\n+\t Effectively change the comparison to the other one.  */\n+      if (!HONOR_NANS (mode))\n+\t{\n+\t  gcc_assert (first_code == (and_them ? ORDERED : UNORDERED));\n+\t  return emit_store_flag_1 (target, code, op0, op1, mode, 0, normalizep,\n+\t\t\t\t    target_mode);\n+\t}\n+\n+      if (!HAVE_conditional_move)\n+\treturn 0;\n+\n+      /* Try using a setcc instruction for ORDERED/UNORDERED, followed by a\n+\t conditional move.  */\n+      tem = emit_store_flag_1 (subtarget, first_code, op0, op1, mode, 0,\n+\t\t\t       normalizep, target_mode);\n+      if (tem == 0)\n+\treturn 0;\n+\n+      if (and_them)\n+\ttem = emit_conditional_move (target, code, op0, op1, mode,\n+\t\t\t\t     tem, const0_rtx, GET_MODE (tem), 0);\n+      else\n+\ttem = emit_conditional_move (target, code, op0, op1, mode,\n+\t\t\t\t     trueval, tem, GET_MODE (tem), 0);\n+\n+      if (tem == 0)\n+\tdelete_insns_since (last);\n+      return tem;\n+    }\n+\n+  /* The remaining tricks only apply to integer comparisons.  */\n+\n+  if (GET_MODE_CLASS (mode) == MODE_INT)\n+    return emit_store_flag_int (target, subtarget, code, op0, op1, mode,\n+\t\t\t\tunsignedp, normalizep, trueval);\n+\n+  return 0;\n+}\n+\n /* Like emit_store_flag, but always succeeds.  */\n \n rtx"}]}