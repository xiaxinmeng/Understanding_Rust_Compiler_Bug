{"sha": "1165109b401377a2b8028a7beaa9f50684649f2b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTE2NTEwOWI0MDEzNzdhMmI4MDI4YTdiZWFhOWY1MDY4NDY0OWYyYg==", "commit": {"author": {"name": "Andrew Stubbs", "email": "ams@codesourcery.com", "date": "2020-03-04T16:11:04Z"}, "committer": {"name": "Andrew Stubbs", "email": "ams@codesourcery.com", "date": "2020-03-31T12:33:05Z"}, "message": "amdgcn: generalize vector insn modes\n\nReplace all relevant explicit uses of V64 vectors with an iterator (albeit\nwith only one entry).  This is prerequisite to adding extra vector lengths.\n\nThe changes are purely mechanical: comparing the mddump files from before\nand after shows only white-space differences and the use of GET_MODE_NUNITS.\n\n2020-03-31  Andrew Stubbs  <ams@codesourcery.com>\n\n\tgcc/\n\t* config/gcn/gcn-valu.md (V_QI, V_HI, V_HF, V_SI, V_SF, V_DI, V_DF):\n\tNew mode iterators.\n\t(vnsi, VnSI, vndi, VnDI): New mode attributes.\n\t(mov<mode>): Use <VnDI> in place of V64DI.\n\t(mov<mode>_exec): Likewise.\n\t(mov<mode>_sgprbase): Likewise.\n\t(reload_out<mode>): Likewise.\n\t(*vec_set<mode>_1): Use GET_MODE_NUNITS instead of constant 64.\n\t(gather_load<mode>v64si): Rename to ...\n\t(gather_load<mode><vnsi>): ... this, and use <VnSI> in place of V64SI,\n\tand <VnDI> in place of V64DI.\n\t(gather<mode>_insn_1offset<exec>): Use <VnDI> in place of V64DI.\n\t(gather<mode>_insn_1offset_ds<exec>): Use <VnSI> in place of V64SI.\n\t(gather<mode>_insn_2offsets<exec>): Use <VnSI> and <VnDI>.\n\t(scatter_store<mode>v64si): Rename to ...\n\t(scatter_store<mode><vnsi>): ... this, and use <VnSI> and <VnDI>.\n\t(scatter<mode>_expr<exec_scatter>): Use <VnSI> and <VnDI>.\n\t(scatter<mode>_insn_1offset<exec_scatter>): Likewise.\n\t(scatter<mode>_insn_1offset_ds<exec_scatter>): Likewise.\n\t(scatter<mode>_insn_2offsets<exec_scatter>): Likewise.\n\t(ds_bpermute<mode>): Use <VnSI>.\n\t(addv64si3_vcc<exec_vcc>): Rename to ...\n\t(add<mode>3_vcc<exec_vcc>): ... this, and use V_SI.\n\t(addv64si3_vcc_dup<exec_vcc>): Rename to ...\n\t(add<mode>3_vcc_dup<exec_vcc>): ... this, and use V_SI.\n\t(addcv64si3<exec_vcc>): Rename to ...\n\t(addc<mode>3<exec_vcc>): ... this, and use V_SI.\n\t(subv64si3_vcc<exec_vcc>): Rename to ...\n\t(sub<mode>3_vcc<exec_vcc>): ... this, and use V_SI.\n\t(subcv64si3<exec_vcc>): Rename to ...\n\t(subc<mode>3<exec_vcc>): ... this, and use V_SI.\n\t(addv64di3): Rename to ...\n\t(add<mode>3): ... this, and use V_DI.\n\t(addv64di3_exec): Rename to ...\n\t(add<mode>3_exec): ... this, and use V_DI.\n\t(subv64di3): Rename to ...\n\t(sub<mode>3): ... this, and use V_DI.\n\t(subv64di3_exec): Rename to ...\n\t(sub<mode>3_exec): ... this, and use V_DI.\n\t(addv64di3_zext): Rename to ...\n\t(add<mode>3_zext): ... this, and use V_DI and <VnSI>.\n\t(addv64di3_zext_exec): Rename to ...\n\t(add<mode>3_zext_exec): ... this, and use V_DI and <VnSI>.\n\t(addv64di3_zext_dup): Rename to ...\n\t(add<mode>3_zext_dup): ... this, and use V_DI and <VnSI>.\n\t(addv64di3_zext_dup_exec): Rename to ...\n\t(add<mode>3_zext_dup_exec): ... this, and use V_DI and <VnSI>.\n\t(addv64di3_zext_dup2): Rename to ...\n\t(add<mode>3_zext_dup2): ... this, and use V_DI and <VnSI>.\n\t(addv64di3_zext_dup2_exec): Rename to ...\n\t(add<mode>3_zext_dup2_exec): ... this, and use V_DI and <VnSI>.\n\t(addv64di3_sext_dup2): Rename to ...\n\t(add<mode>3_sext_dup2): ... this, and use V_DI and <VnSI>.\n\t(addv64di3_sext_dup2_exec): Rename to ...\n\t(add<mode>3_sext_dup2_exec): ... this, and use V_DI and <VnSI>.\n\t(<su>mulv64si3_highpart<exec>): Rename to ...\n\t(<su>mul<mode>3_highpart<exec>): ... this and use V_SI and <VnDI>.\n\t(mulv64di3): Rename to ...\n\t(mul<mode>3): ... this, and use V_DI and <VnSI>.\n\t(mulv64di3_exec): Rename to ...\n\t(mul<mode>3_exec): ... this, and use V_DI and <VnSI>.\n\t(mulv64di3_zext): Rename to ...\n\t(mul<mode>3_zext): ... this, and use V_DI and <VnSI>.\n\t(mulv64di3_zext_exec): Rename to ...\n\t(mul<mode>3_zext_exec): ... this, and use V_DI and <VnSI>.\n\t(mulv64di3_zext_dup2): Rename to ...\n\t(mul<mode>3_zext_dup2): ... this, and use V_DI and <VnSI>.\n\t(mulv64di3_zext_dup2_exec): Rename to ...\n\t(mul<mode>3_zext_dup2_exec): ... this, and use V_DI and <VnSI>.\n\t(<expander>v64di3): Rename to ...\n\t(<expander><mode>3): ... this, and use V_DI and <VnSI>.\n\t(<expander>v64di3_exec): Rename to ...\n\t(<expander><mode>3_exec): ... this, and use V_DI and <VnSI>.\n\t(<expander>v64si3<exec>): Rename to ...\n\t(<expander><mode>3<exec>): ... this, and use V_SI and <VnSI>.\n\t(v<expander>v64si3<exec>): Rename to ...\n\t(v<expander><mode>3<exec>): ... this, and use V_SI and <VnSI>.\n\t(<expander>v64si3<exec>): Rename to ...\n\t(<expander><vnsi>3<exec>): ... this, and use V_SI.\n\t(subv64df3<exec>): Rename to ...\n\t(sub<mode>3<exec>): ... this, and use V_DF.\n\t(truncv64di<mode>2): Rename to ...\n\t(trunc<vndi><mode>2): ... this, and use <VnDI>.\n\t(truncv64di<mode>2_exec): Rename to ...\n\t(trunc<vndi><mode>2_exec): ... this, and use <VnDI>.\n\t(<convop><mode>v64di2): Rename to ...\n\t(<convop><mode><vndi>2): ... this, and use <VnDI>.\n\t(<convop><mode>v64di2_exec): Rename to ...\n\t(<convop><mode><vndi>2_exec): ... this, and use <VnDI>.\n\t(vec_cmp<u>v64qidi): Rename to ...\n\t(vec_cmp<u><mode>di): ... this, and use <VnSI>.\n\t(vec_cmp<u>v64qidi_exec): Rename to ...\n\t(vec_cmp<u><mode>di_exec): ... this, and use <VnSI>.\n\t(vcond_mask_<mode>di): Use <VnDI>.\n\t(maskload<mode>di): Likewise.\n\t(maskstore<mode>di): Likewise.\n\t(mask_gather_load<mode>v64si): Rename to ...\n\t(mask_gather_load<mode><vnsi>): ... this, and use <VnSI> and <VnDI>.\n\t(mask_scatter_store<mode>v64si): Rename to ...\n\t(mask_scatter_store<mode><vnsi>): ... this, and use <VnSI> and <VnDI>.\n\t(*<reduc_op>_dpp_shr_v64di): Rename to ...\n\t(*<reduc_op>_dpp_shr_<mode>): ... this, and use V_DI and <VnSI>.\n\t(*plus_carry_in_dpp_shr_v64si): Rename to ...\n\t(*plus_carry_in_dpp_shr_<mode>): ... this, and use V_SI.\n\t(*plus_carry_dpp_shr_v64di): Rename to ...\n\t(*plus_carry_dpp_shr_<mode>): ... this, and use V_DI and <VnSI>.\n\t(vec_seriesv64si): Rename to ...\n\t(vec_series<mode>): ... this, and use V_SI.\n\t(vec_seriesv64di): Rename to ...\n\t(vec_series<mode>): ... this, and use V_DI.", "tree": {"sha": "fb9fb1bcffe452cb86796f1bfc6492bcc47eb762", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/fb9fb1bcffe452cb86796f1bfc6492bcc47eb762"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1165109b401377a2b8028a7beaa9f50684649f2b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1165109b401377a2b8028a7beaa9f50684649f2b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1165109b401377a2b8028a7beaa9f50684649f2b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1165109b401377a2b8028a7beaa9f50684649f2b/comments", "author": {"login": "ams-cs", "id": 2235130, "node_id": "MDQ6VXNlcjIyMzUxMzA=", "avatar_url": "https://avatars.githubusercontent.com/u/2235130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ams-cs", "html_url": "https://github.com/ams-cs", "followers_url": "https://api.github.com/users/ams-cs/followers", "following_url": "https://api.github.com/users/ams-cs/following{/other_user}", "gists_url": "https://api.github.com/users/ams-cs/gists{/gist_id}", "starred_url": "https://api.github.com/users/ams-cs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ams-cs/subscriptions", "organizations_url": "https://api.github.com/users/ams-cs/orgs", "repos_url": "https://api.github.com/users/ams-cs/repos", "events_url": "https://api.github.com/users/ams-cs/events{/privacy}", "received_events_url": "https://api.github.com/users/ams-cs/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ams-cs", "id": 2235130, "node_id": "MDQ6VXNlcjIyMzUxMzA=", "avatar_url": "https://avatars.githubusercontent.com/u/2235130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ams-cs", "html_url": "https://github.com/ams-cs", "followers_url": "https://api.github.com/users/ams-cs/followers", "following_url": "https://api.github.com/users/ams-cs/following{/other_user}", "gists_url": "https://api.github.com/users/ams-cs/gists{/gist_id}", "starred_url": "https://api.github.com/users/ams-cs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ams-cs/subscriptions", "organizations_url": "https://api.github.com/users/ams-cs/orgs", "repos_url": "https://api.github.com/users/ams-cs/repos", "events_url": "https://api.github.com/users/ams-cs/events{/privacy}", "received_events_url": "https://api.github.com/users/ams-cs/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "dc56917d1117770833e1f672afe8c65770be7109", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/dc56917d1117770833e1f672afe8c65770be7109", "html_url": "https://github.com/Rust-GCC/gccrs/commit/dc56917d1117770833e1f672afe8c65770be7109"}], "stats": {"total": 1465, "additions": 805, "deletions": 660}, "files": [{"sha": "d79ee54052c7fe0f5832c43371ee8fd13f7a8add", "filename": "gcc/ChangeLog", "status": "modified", "additions": 113, "deletions": 0, "changes": 113, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1165109b401377a2b8028a7beaa9f50684649f2b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1165109b401377a2b8028a7beaa9f50684649f2b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=1165109b401377a2b8028a7beaa9f50684649f2b", "patch": "@@ -1,3 +1,116 @@\n+2020-03-31  Andrew Stubbs  <ams@codesourcery.com>\n+\n+\t* config/gcn/gcn-valu.md (V_QI, V_HI, V_HF, V_SI, V_SF, V_DI, V_DF):\n+\tNew mode iterators.\n+\t(vnsi, VnSI, vndi, VnDI): New mode attributes.\n+\t(mov<mode>): Use <VnDI> in place of V64DI.\n+\t(mov<mode>_exec): Likewise.\n+\t(mov<mode>_sgprbase): Likewise.\n+\t(reload_out<mode>): Likewise.\n+\t(*vec_set<mode>_1): Use GET_MODE_NUNITS instead of constant 64.\n+\t(gather_load<mode>v64si): Rename to ...\n+\t(gather_load<mode><vnsi>): ... this, and use <VnSI> in place of V64SI,\n+\tand <VnDI> in place of V64DI.\n+\t(gather<mode>_insn_1offset<exec>): Use <VnDI> in place of V64DI.\n+\t(gather<mode>_insn_1offset_ds<exec>): Use <VnSI> in place of V64SI.\n+\t(gather<mode>_insn_2offsets<exec>): Use <VnSI> and <VnDI>.\n+\t(scatter_store<mode>v64si): Rename to ...\n+\t(scatter_store<mode><vnsi>): ... this, and use <VnSI> and <VnDI>.\n+\t(scatter<mode>_expr<exec_scatter>): Use <VnSI> and <VnDI>.\n+\t(scatter<mode>_insn_1offset<exec_scatter>): Likewise.\n+\t(scatter<mode>_insn_1offset_ds<exec_scatter>): Likewise.\n+\t(scatter<mode>_insn_2offsets<exec_scatter>): Likewise.\n+\t(ds_bpermute<mode>): Use <VnSI>.\n+\t(addv64si3_vcc<exec_vcc>): Rename to ...\n+\t(add<mode>3_vcc<exec_vcc>): ... this, and use V_SI.\n+\t(addv64si3_vcc_dup<exec_vcc>): Rename to ...\n+\t(add<mode>3_vcc_dup<exec_vcc>): ... this, and use V_SI.\n+\t(addcv64si3<exec_vcc>): Rename to ...\n+\t(addc<mode>3<exec_vcc>): ... this, and use V_SI.\n+\t(subv64si3_vcc<exec_vcc>): Rename to ...\n+\t(sub<mode>3_vcc<exec_vcc>): ... this, and use V_SI.\n+\t(subcv64si3<exec_vcc>): Rename to ...\n+\t(subc<mode>3<exec_vcc>): ... this, and use V_SI.\n+\t(addv64di3): Rename to ...\n+\t(add<mode>3): ... this, and use V_DI.\n+\t(addv64di3_exec): Rename to ...\n+\t(add<mode>3_exec): ... this, and use V_DI.\n+\t(subv64di3): Rename to ...\n+\t(sub<mode>3): ... this, and use V_DI.\n+\t(subv64di3_exec): Rename to ...\n+\t(sub<mode>3_exec): ... this, and use V_DI.\n+\t(addv64di3_zext): Rename to ...\n+\t(add<mode>3_zext): ... this, and use V_DI and <VnSI>.\n+\t(addv64di3_zext_exec): Rename to ...\n+\t(add<mode>3_zext_exec): ... this, and use V_DI and <VnSI>.\n+\t(addv64di3_zext_dup): Rename to ...\n+\t(add<mode>3_zext_dup): ... this, and use V_DI and <VnSI>.\n+\t(addv64di3_zext_dup_exec): Rename to ...\n+\t(add<mode>3_zext_dup_exec): ... this, and use V_DI and <VnSI>.\n+\t(addv64di3_zext_dup2): Rename to ...\n+\t(add<mode>3_zext_dup2): ... this, and use V_DI and <VnSI>.\n+\t(addv64di3_zext_dup2_exec): Rename to ...\n+\t(add<mode>3_zext_dup2_exec): ... this, and use V_DI and <VnSI>.\n+\t(addv64di3_sext_dup2): Rename to ...\n+\t(add<mode>3_sext_dup2): ... this, and use V_DI and <VnSI>.\n+\t(addv64di3_sext_dup2_exec): Rename to ...\n+\t(add<mode>3_sext_dup2_exec): ... this, and use V_DI and <VnSI>.\n+\t(<su>mulv64si3_highpart<exec>): Rename to ...\n+\t(<su>mul<mode>3_highpart<exec>): ... this and use V_SI and <VnDI>.\n+\t(mulv64di3): Rename to ...\n+\t(mul<mode>3): ... this, and use V_DI and <VnSI>.\n+\t(mulv64di3_exec): Rename to ...\n+\t(mul<mode>3_exec): ... this, and use V_DI and <VnSI>.\n+\t(mulv64di3_zext): Rename to ...\n+\t(mul<mode>3_zext): ... this, and use V_DI and <VnSI>.\n+\t(mulv64di3_zext_exec): Rename to ...\n+\t(mul<mode>3_zext_exec): ... this, and use V_DI and <VnSI>.\n+\t(mulv64di3_zext_dup2): Rename to ...\n+\t(mul<mode>3_zext_dup2): ... this, and use V_DI and <VnSI>.\n+\t(mulv64di3_zext_dup2_exec): Rename to ...\n+\t(mul<mode>3_zext_dup2_exec): ... this, and use V_DI and <VnSI>.\n+\t(<expander>v64di3): Rename to ...\n+\t(<expander><mode>3): ... this, and use V_DI and <VnSI>.\n+\t(<expander>v64di3_exec): Rename to ...\n+\t(<expander><mode>3_exec): ... this, and use V_DI and <VnSI>.\n+\t(<expander>v64si3<exec>): Rename to ...\n+\t(<expander><mode>3<exec>): ... this, and use V_SI and <VnSI>.\n+\t(v<expander>v64si3<exec>): Rename to ...\n+\t(v<expander><mode>3<exec>): ... this, and use V_SI and <VnSI>.\n+\t(<expander>v64si3<exec>): Rename to ...\n+\t(<expander><vnsi>3<exec>): ... this, and use V_SI.\n+\t(subv64df3<exec>): Rename to ...\n+\t(sub<mode>3<exec>): ... this, and use V_DF.\n+\t(truncv64di<mode>2): Rename to ...\n+\t(trunc<vndi><mode>2): ... this, and use <VnDI>.\n+\t(truncv64di<mode>2_exec): Rename to ...\n+\t(trunc<vndi><mode>2_exec): ... this, and use <VnDI>.\n+\t(<convop><mode>v64di2): Rename to ...\n+\t(<convop><mode><vndi>2): ... this, and use <VnDI>.\n+\t(<convop><mode>v64di2_exec): Rename to ...\n+\t(<convop><mode><vndi>2_exec): ... this, and use <VnDI>.\n+\t(vec_cmp<u>v64qidi): Rename to ...\n+\t(vec_cmp<u><mode>di): ... this, and use <VnSI>.\n+\t(vec_cmp<u>v64qidi_exec): Rename to ...\n+\t(vec_cmp<u><mode>di_exec): ... this, and use <VnSI>.\n+\t(vcond_mask_<mode>di): Use <VnDI>.\n+\t(maskload<mode>di): Likewise.\n+\t(maskstore<mode>di): Likewise.\n+\t(mask_gather_load<mode>v64si): Rename to ...\n+\t(mask_gather_load<mode><vnsi>): ... this, and use <VnSI> and <VnDI>.\n+\t(mask_scatter_store<mode>v64si): Rename to ...\n+\t(mask_scatter_store<mode><vnsi>): ... this, and use <VnSI> and <VnDI>.\n+\t(*<reduc_op>_dpp_shr_v64di): Rename to ...\n+\t(*<reduc_op>_dpp_shr_<mode>): ... this, and use V_DI and <VnSI>.\n+\t(*plus_carry_in_dpp_shr_v64si): Rename to ...\n+\t(*plus_carry_in_dpp_shr_<mode>): ... this, and use V_SI.\n+\t(*plus_carry_dpp_shr_v64di): Rename to ...\n+\t(*plus_carry_dpp_shr_<mode>): ... this, and use V_DI and <VnSI>.\n+\t(vec_seriesv64si): Rename to ...\n+\t(vec_series<mode>): ... this, and use V_SI.\n+\t(vec_seriesv64di): Rename to ...\n+\t(vec_series<mode>): ... this, and use V_DI.\n+\n 2020-03-31  Claudiu Zissulescu  <claziss@synopsys.com>\n \n \t* config/arc/arc.c (arc_print_operand): Use"}, {"sha": "24843a0b43ec919906a069ef8f13bd85c9a0b7ed", "filename": "gcc/config/gcn/gcn-valu.md", "status": "modified", "additions": 692, "deletions": 660, "changes": 1352, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1165109b401377a2b8028a7beaa9f50684649f2b/gcc%2Fconfig%2Fgcn%2Fgcn-valu.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1165109b401377a2b8028a7beaa9f50684649f2b/gcc%2Fconfig%2Fgcn%2Fgcn-valu.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fgcn-valu.md?ref=1165109b401377a2b8028a7beaa9f50684649f2b", "patch": "@@ -16,6 +16,23 @@\n \n ;; {{{ Vector iterators\n \n+; Vector modes for specific types\n+; (This will make more sense when there are multiple vector sizes)\n+(define_mode_iterator V_QI\n+\t\t      [V64QI])\n+(define_mode_iterator V_HI\n+\t\t      [V64HI])\n+(define_mode_iterator V_HF\n+\t\t      [V64HF])\n+(define_mode_iterator V_SI\n+\t\t      [V64SI])\n+(define_mode_iterator V_SF\n+\t\t      [V64SF])\n+(define_mode_iterator V_DI\n+\t\t      [V64DI])\n+(define_mode_iterator V_DF\n+\t\t      [V64DF])\n+\n ; Vector modes for sub-dword modes\n (define_mode_iterator V_QIHI\n \t\t      [V64QI V64HI])\n@@ -63,6 +80,22 @@\n   [(V64QI \"QI\") (V64HI \"HI\") (V64SI \"SI\")\n    (V64HF \"HF\") (V64SF \"SF\") (V64DI \"DI\") (V64DF \"DF\")])\n \n+(define_mode_attr vnsi\n+  [(V64QI \"v64si\") (V64HI \"v64si\") (V64HF \"v64si\") (V64SI \"v64si\")\n+   (V64SF \"v64si\") (V64DI \"v64si\") (V64DF \"v64si\")])\n+\n+(define_mode_attr VnSI\n+  [(V64QI \"V64SI\") (V64HI \"V64SI\") (V64HF \"V64SI\") (V64SI \"V64SI\")\n+   (V64SF \"V64SI\") (V64DI \"V64SI\") (V64DF \"V64SI\")])\n+\n+(define_mode_attr vndi\n+  [(V64QI \"v64di\") (V64HI \"v64di\") (V64HF \"v64di\") (V64SI \"v64di\")\n+   (V64SF \"v64di\") (V64DI \"v64di\") (V64DF \"v64di\")])\n+\n+(define_mode_attr VnDI\n+  [(V64QI \"V64DI\") (V64HI \"V64DI\") (V64HF \"V64DI\") (V64SI \"V64DI\")\n+   (V64SF \"V64DI\") (V64DI \"V64DI\") (V64DF \"V64DI\")])\n+\n (define_mode_attr sdwa [(V64QI \"BYTE_0\") (V64HI \"WORD_0\") (V64SI \"DWORD\")])\n \n ;; }}}\n@@ -148,7 +181,7 @@\n     if (MEM_P (operands[0]) && !lra_in_progress && !reload_completed)\n       {\n \toperands[1] = force_reg (<MODE>mode, operands[1]);\n-\trtx scratch = gen_rtx_SCRATCH (V64DImode);\n+\trtx scratch = gen_rtx_SCRATCH (<VnDI>mode);\n \trtx a = gen_rtx_CONST_INT (VOIDmode, MEM_ADDR_SPACE (operands[0]));\n \trtx v = gen_rtx_CONST_INT (VOIDmode, MEM_VOLATILE_P (operands[0]));\n \trtx expr = gcn_expand_scalar_to_vector_address (<MODE>mode, NULL,\n@@ -159,7 +192,7 @@\n       }\n     else if (MEM_P (operands[1]) && !lra_in_progress && !reload_completed)\n       {\n-\trtx scratch = gen_rtx_SCRATCH (V64DImode);\n+\trtx scratch = gen_rtx_SCRATCH (<VnDI>mode);\n \trtx a = gen_rtx_CONST_INT (VOIDmode, MEM_ADDR_SPACE (operands[1]));\n \trtx v = gen_rtx_CONST_INT (VOIDmode, MEM_VOLATILE_P (operands[1]));\n \trtx expr = gcn_expand_scalar_to_vector_address (<MODE>mode, NULL,\n@@ -171,7 +204,7 @@\n     else if ((MEM_P (operands[0]) || MEM_P (operands[1])))\n       {\n         gcc_assert (!reload_completed);\n-\trtx scratch = gen_reg_rtx (V64DImode);\n+\trtx scratch = gen_reg_rtx (<VnDI>mode);\n \temit_insn (gen_mov<mode>_sgprbase (operands[0], operands[1], scratch));\n \tDONE;\n       }\n@@ -202,7 +235,7 @@\n \t  (match_operand:V_1REG 3 \"gcn_alu_or_unspec_operand\"\n \t\t\t\t\t\t\t \"U0,U0,vA,vA,U0,U0\")\n \t  (match_operand:DI 2 \"register_operand\"\t \" e, e,cV,Sv, e, e\")))\n-   (clobber (match_scratch:V64DI 4\t\t\t \"=X, X, X, X,&v,&v\"))]\n+   (clobber (match_scratch:<VnDI> 4\t\t\t \"=X, X, X, X,&v,&v\"))]\n   \"!MEM_P (operands[0]) || REG_P (operands[1])\"\n   \"@\n    v_mov_b32\\t%0, %1\n@@ -223,7 +256,7 @@\n ;\t  (match_operand:V_1REG 1 \"general_operand\"\t\"vA,B, m, v\")\n ;\t  (match_dup 0)\n ;\t  (match_operand:DI 2 \"gcn_exec_reg_operand\"\t\" e,e, e, e\")))\n-;   (clobber (match_scratch:V64DI 3\t\t\t\"=X,X,&v,&v\"))]\n+;   (clobber (match_scratch:<VnDI> 3\t\t\t\"=X,X,&v,&v\"))]\n ;  \"!MEM_P (operands[0]) || REG_P (operands[1])\"\n ;  \"@\n ;  v_mov_b32\\t%0, %1\n@@ -253,7 +286,7 @@\n \t  (match_operand:V_2REG 3 \"gcn_alu_or_unspec_operand\"\n \t\t\t\t\t\t       \" U0,vDA0,vDA0,U0,U0\")\n \t  (match_operand:DI 2 \"register_operand\"       \"  e,  cV,  Sv, e, e\")))\n-   (clobber (match_scratch:V64DI 4\t\t       \"= X,   X,   X,&v,&v\"))]\n+   (clobber (match_scratch:<VnDI> 4\t\t       \"= X,   X,   X,&v,&v\"))]\n   \"!MEM_P (operands[0]) || REG_P (operands[1])\"\n   {\n     if (!REG_P (operands[1]) || REGNO (operands[0]) <= REGNO (operands[1]))\n@@ -295,7 +328,7 @@\n ;\t  (match_operand:V_2REG 1 \"general_operand\"\t\"vDB, m, v\")\n ;\t  (match_dup 0)\n ;\t  (match_operand:DI 2 \"gcn_exec_reg_operand\"\t\" e, e, e\")))\n-;   (clobber (match_scratch:V64DI 3\t\t\t\"=X,&v,&v\"))]\n+;   (clobber (match_scratch:<VnDI> 3\t\t\t\"=X,&v,&v\"))]\n ;  \"!MEM_P (operands[0]) || REG_P (operands[1])\"\n ;  \"@\n ;   * if (!REG_P (operands[1]) || REGNO (operands[0]) <= REGNO (operands[1])) \\\n@@ -324,7 +357,7 @@\n \t(unspec:V_1REG\n \t  [(match_operand:V_1REG 1 \"general_operand\"   \" vA,vB, m, v\")]\n \t  UNSPEC_SGPRBASE))\n-   (clobber (match_operand:V64DI 2 \"register_operand\"  \"=&v,&v,&v,&v\"))]\n+   (clobber (match_operand:<VnDI> 2 \"register_operand\"  \"=&v,&v,&v,&v\"))]\n   \"lra_in_progress || reload_completed\"\n   \"@\n    v_mov_b32\\t%0, %1\n@@ -339,7 +372,7 @@\n \t(unspec:V_2REG\n \t  [(match_operand:V_2REG 1 \"general_operand\"   \"vDB, m, v\")]\n \t  UNSPEC_SGPRBASE))\n-   (clobber (match_operand:V64DI 2 \"register_operand\"  \"=&v,&v,&v\"))]\n+   (clobber (match_operand:<VnDI> 2 \"register_operand\"  \"=&v,&v,&v\"))]\n   \"lra_in_progress || reload_completed\"\n   \"@\n    * if (!REG_P (operands[1]) || REGNO (operands[0]) <= REGNO (operands[1])) \\\n@@ -357,7 +390,7 @@\n (define_expand \"reload_in<mode>\"\n   [(set (match_operand:V_ALL 0 \"register_operand\"     \"= v\")\n \t(match_operand:V_ALL 1 \"memory_operand\"\t      \"  m\"))\n-   (clobber (match_operand:V64DI 2 \"register_operand\" \"=&v\"))]\n+   (clobber (match_operand:<VnDI> 2 \"register_operand\" \"=&v\"))]\n   \"\"\n   {\n     emit_insn (gen_mov<mode>_sgprbase (operands[0], operands[1], operands[2]));\n@@ -369,7 +402,7 @@\n (define_expand \"reload_out<mode>\"\n   [(set (match_operand:V_ALL 0 \"memory_operand\"\t      \"= m\")\n \t(match_operand:V_ALL 1 \"register_operand\"     \"  v\"))\n-   (clobber (match_operand:V64DI 2 \"register_operand\" \"=&v\"))]\n+   (clobber (match_operand:<VnDI> 2 \"register_operand\" \"=&v\"))]\n   \"\"\n   {\n     emit_insn (gen_mov<mode>_sgprbase (operands[0], operands[1], operands[2]));\n@@ -383,7 +416,7 @@\n \t(unspec:V_ALL\n \t  [(match_operand:V_ALL 1 \"general_operand\")]\n \t  UNSPEC_SGPRBASE))\n-   (clobber (match_scratch:V64DI 2))]\n+   (clobber (match_scratch:<VnDI> 2))]\n   \"\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK [(match_dup 5) (match_dup 1) (match_dup 6) (match_dup 7)]\n@@ -402,7 +435,7 @@\n \t  (match_operand:V_ALL 1 \"general_operand\")\n \t  (match_operand:V_ALL 2 \"\")\n \t  (match_operand:DI 3 \"gcn_exec_reg_operand\")))\n-   (clobber (match_scratch:V64DI 4))]\n+   (clobber (match_scratch:<VnDI> 4))]\n   \"\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK [(match_dup 5) (match_dup 1)\n@@ -422,7 +455,7 @@\n \t(unspec:V_ALL\n \t  [(match_operand:V_ALL 1 \"memory_operand\")]\n \t  UNSPEC_SGPRBASE))\n-   (clobber (match_scratch:V64DI 2))]\n+   (clobber (match_scratch:<VnDI> 2))]\n   \"\"\n   [(set (match_dup 0)\n \t(unspec:V_ALL [(match_dup 5) (match_dup 6) (match_dup 7)\n@@ -442,7 +475,7 @@\n \t  (match_operand:V_ALL 1 \"memory_operand\")\n \t  (match_operand:V_ALL 2 \"\")\n \t  (match_operand:DI 3 \"gcn_exec_reg_operand\")))\n-   (clobber (match_scratch:V64DI 4))]\n+   (clobber (match_scratch:<VnDI> 4))]\n   \"\"\n   [(set (match_dup 0)\n \t(vec_merge:V_ALL\n@@ -518,7 +551,7 @@\n \t    (match_operand:<SCALAR_MODE> 1 \"register_operand\"\t   \"Sv\"))\n \t  (match_operand:V_1REG 3 \"gcn_register_or_unspec_operand\" \"U0\")\n \t  (match_operand:SI 2 \"const_int_operand\"\t\t   \" i\")))]\n-  \"((unsigned) exact_log2 (INTVAL (operands[2])) < 64)\"\n+  \"((unsigned) exact_log2 (INTVAL (operands[2])) < GET_MODE_NUNITS (<MODE>mode))\"\n   {\n     operands[2] = GEN_INT (exact_log2 (INTVAL (operands[2])));\n     return \"v_writelane_b32 %0, %1, %2\";\n@@ -535,7 +568,7 @@\n \t    (match_operand:<SCALAR_MODE> 1 \"register_operand\"\t   \"Sv\"))\n \t  (match_operand:V_2REG 3 \"gcn_register_or_unspec_operand\" \"U0\")\n \t  (match_operand:SI 2 \"const_int_operand\"\t\t   \" i\")))]\n-  \"((unsigned) exact_log2 (INTVAL (operands[2])) < 64)\"\n+  \"((unsigned) exact_log2 (INTVAL (operands[2])) < GET_MODE_NUNITS (<MODE>mode))\"\n   {\n     operands[2] = GEN_INT (exact_log2 (INTVAL (operands[2])));\n     return \"v_writelane_b32 %L0, %L1, %2\\;v_writelane_b32 %H0, %H1, %2\";\n@@ -648,7 +681,7 @@\n ;; GCC does not permit MEM to hold vectors of addresses, so we must use an\n ;; unspec.  The unspec formats are as follows:\n ;;\n-;;     (unspec:V64??\n+;;     (unspec:V??\n ;;\t [(<address expression>)\n ;;\t  (<addr_space_t>)\n ;;\t  (<use_glc>)\n@@ -671,10 +704,10 @@\n ;;   fields normally found in a MEM.\n ;; - Multiple forms of address expression are supported, below.\n \n-(define_expand \"gather_load<mode>v64si\"\n+(define_expand \"gather_load<mode><vnsi>\"\n   [(match_operand:V_ALL 0 \"register_operand\")\n    (match_operand:DI 1 \"register_operand\")\n-   (match_operand:V64SI 2 \"register_operand\")\n+   (match_operand:<VnSI> 2 \"register_operand\")\n    (match_operand 3 \"immediate_operand\")\n    (match_operand:SI 4 \"gcn_alu_operand\")]\n   \"\"\n@@ -683,7 +716,7 @@\n \t\t\t\t\t  operands[2], operands[4],\n \t\t\t\t\t  INTVAL (operands[3]), NULL);\n \n-    if (GET_MODE (addr) == V64DImode)\n+    if (GET_MODE (addr) == <VnDI>mode)\n       emit_insn (gen_gather<mode>_insn_1offset (operands[0], addr, const0_rtx,\n \t\t\t\t\t\tconst0_rtx, const0_rtx));\n     else\n@@ -706,13 +739,13 @@\n     {})\n \n (define_insn \"gather<mode>_insn_1offset<exec>\"\n-  [(set (match_operand:V_ALL 0 \"register_operand\"\t\t \"=v\")\n+  [(set (match_operand:V_ALL 0 \"register_operand\"\t\t   \"=v\")\n \t(unspec:V_ALL\n-\t  [(plus:V64DI (match_operand:V64DI 1 \"register_operand\" \" v\")\n-\t\t       (vec_duplicate:V64DI\n-\t\t\t (match_operand 2 \"immediate_operand\"\t \" n\")))\n-\t   (match_operand 3 \"immediate_operand\"\t\t\t \" n\")\n-\t   (match_operand 4 \"immediate_operand\"\t\t\t \" n\")\n+\t  [(plus:<VnDI> (match_operand:<VnDI> 1 \"register_operand\" \" v\")\n+\t\t\t(vec_duplicate:<VnDI>\n+\t\t\t  (match_operand 2 \"immediate_operand\"\t   \" n\")))\n+\t   (match_operand 3 \"immediate_operand\"\t\t\t   \" n\")\n+\t   (match_operand 4 \"immediate_operand\"\t\t\t   \" n\")\n \t   (mem:BLK (scratch))]\n \t  UNSPEC_GATHER))]\n   \"(AS_FLAT_P (INTVAL (operands[3]))\n@@ -745,13 +778,13 @@\n    (set_attr \"length\" \"12\")])\n \n (define_insn \"gather<mode>_insn_1offset_ds<exec>\"\n-  [(set (match_operand:V_ALL 0 \"register_operand\"\t\t \"=v\")\n+  [(set (match_operand:V_ALL 0 \"register_operand\"\t\t   \"=v\")\n \t(unspec:V_ALL\n-\t  [(plus:V64SI (match_operand:V64SI 1 \"register_operand\" \" v\")\n-\t\t       (vec_duplicate:V64SI\n-\t\t\t (match_operand 2 \"immediate_operand\"\t \" n\")))\n-\t   (match_operand 3 \"immediate_operand\"\t\t\t \" n\")\n-\t   (match_operand 4 \"immediate_operand\"\t\t\t \" n\")\n+\t  [(plus:<VnSI> (match_operand:<VnSI> 1 \"register_operand\" \" v\")\n+\t\t\t(vec_duplicate:<VnSI>\n+\t\t\t  (match_operand 2 \"immediate_operand\"\t   \" n\")))\n+\t   (match_operand 3 \"immediate_operand\"\t\t\t   \" n\")\n+\t   (match_operand 4 \"immediate_operand\"\t\t\t   \" n\")\n \t   (mem:BLK (scratch))]\n \t  UNSPEC_GATHER))]\n   \"(AS_ANY_DS_P (INTVAL (operands[3]))\n@@ -767,17 +800,17 @@\n    (set_attr \"length\" \"12\")])\n \n (define_insn \"gather<mode>_insn_2offsets<exec>\"\n-  [(set (match_operand:V_ALL 0 \"register_operand\"\t\t       \"=v\")\n+  [(set (match_operand:V_ALL 0 \"register_operand\"\t\t\t\"=v\")\n \t(unspec:V_ALL\n-\t  [(plus:V64DI\n-\t     (plus:V64DI\n-\t       (vec_duplicate:V64DI\n-\t\t (match_operand:DI 1 \"register_operand\"\t\t       \"Sv\"))\n-\t       (sign_extend:V64DI\n-\t\t (match_operand:V64SI 2 \"register_operand\"\t       \" v\")))\n-\t     (vec_duplicate:V64DI (match_operand 3 \"immediate_operand\" \" n\")))\n-\t   (match_operand 4 \"immediate_operand\"\t\t\t       \" n\")\n-\t   (match_operand 5 \"immediate_operand\"\t\t\t       \" n\")\n+\t  [(plus:<VnDI>\n+\t     (plus:<VnDI>\n+\t       (vec_duplicate:<VnDI>\n+\t\t (match_operand:DI 1 \"register_operand\"\t\t\t\"Sv\"))\n+\t       (sign_extend:<VnDI>\n+\t\t (match_operand:<VnSI> 2 \"register_operand\"\t\t\" v\")))\n+\t     (vec_duplicate:<VnDI> (match_operand 3 \"immediate_operand\" \" n\")))\n+\t   (match_operand 4 \"immediate_operand\"\t\t\t\t\" n\")\n+\t   (match_operand 5 \"immediate_operand\"\t\t\t\t\" n\")\n \t   (mem:BLK (scratch))]\n \t  UNSPEC_GATHER))]\n   \"(AS_GLOBAL_P (INTVAL (operands[4]))\n@@ -803,9 +836,9 @@\n   [(set_attr \"type\" \"flat\")\n    (set_attr \"length\" \"12\")])\n \n-(define_expand \"scatter_store<mode>v64si\"\n+(define_expand \"scatter_store<mode><vnsi>\"\n   [(match_operand:DI 0 \"register_operand\")\n-   (match_operand:V64SI 1 \"register_operand\")\n+   (match_operand:<VnSI> 1 \"register_operand\")\n    (match_operand 2 \"immediate_operand\")\n    (match_operand:SI 3 \"gcn_alu_operand\")\n    (match_operand:V_ALL 4 \"register_operand\")]\n@@ -815,7 +848,7 @@\n \t\t\t\t\t  operands[1], operands[3],\n \t\t\t\t\t  INTVAL (operands[2]), NULL);\n \n-    if (GET_MODE (addr) == V64DImode)\n+    if (GET_MODE (addr) == <VnDI>mode)\n       emit_insn (gen_scatter<mode>_insn_1offset (addr, const0_rtx, operands[4],\n \t\t\t\t\t\t const0_rtx, const0_rtx));\n     else\n@@ -829,7 +862,7 @@\n (define_expand \"scatter<mode>_expr<exec_scatter>\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n-\t  [(match_operand:V64DI 0 \"\")\n+\t  [(match_operand:<VnDI> 0 \"\")\n \t   (match_operand:V_ALL 1 \"register_operand\")\n \t   (match_operand 2 \"immediate_operand\")\n \t   (match_operand 3 \"immediate_operand\")]\n@@ -840,12 +873,12 @@\n (define_insn \"scatter<mode>_insn_1offset<exec_scatter>\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n-\t  [(plus:V64DI (match_operand:V64DI 0 \"register_operand\" \"v\")\n-\t\t       (vec_duplicate:V64DI\n-\t\t\t (match_operand 1 \"immediate_operand\"\t \"n\")))\n-\t   (match_operand:V_ALL 2 \"register_operand\"\t\t \"v\")\n-\t   (match_operand 3 \"immediate_operand\"\t\t\t \"n\")\n-\t   (match_operand 4 \"immediate_operand\"\t\t\t \"n\")]\n+\t  [(plus:<VnDI> (match_operand:<VnDI> 0 \"register_operand\" \"v\")\n+\t\t\t(vec_duplicate:<VnDI>\n+\t\t\t  (match_operand 1 \"immediate_operand\"\t   \"n\")))\n+\t   (match_operand:V_ALL 2 \"register_operand\"\t\t   \"v\")\n+\t   (match_operand 3 \"immediate_operand\"\t\t\t   \"n\")\n+\t   (match_operand 4 \"immediate_operand\"\t\t\t   \"n\")]\n \t  UNSPEC_SCATTER))]\n   \"(AS_FLAT_P (INTVAL (operands[3]))\n     && (INTVAL(operands[1]) == 0\n@@ -878,12 +911,12 @@\n (define_insn \"scatter<mode>_insn_1offset_ds<exec_scatter>\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n-\t  [(plus:V64SI (match_operand:V64SI 0 \"register_operand\" \"v\")\n-\t\t       (vec_duplicate:V64SI\n-\t\t\t (match_operand 1 \"immediate_operand\"\t \"n\")))\n-\t   (match_operand:V_ALL 2 \"register_operand\"\t\t \"v\")\n-\t   (match_operand 3 \"immediate_operand\"\t\t\t \"n\")\n-\t   (match_operand 4 \"immediate_operand\"\t\t\t \"n\")]\n+\t  [(plus:<VnSI> (match_operand:<VnSI> 0 \"register_operand\" \"v\")\n+\t\t\t(vec_duplicate:<VnSI>\n+\t\t\t  (match_operand 1 \"immediate_operand\"\t   \"n\")))\n+\t   (match_operand:V_ALL 2 \"register_operand\"\t\t   \"v\")\n+\t   (match_operand 3 \"immediate_operand\"\t\t\t   \"n\")\n+\t   (match_operand 4 \"immediate_operand\"\t\t\t   \"n\")]\n \t  UNSPEC_SCATTER))]\n   \"(AS_ANY_DS_P (INTVAL (operands[3]))\n     && ((unsigned HOST_WIDE_INT)INTVAL(operands[1]) < 0x10000))\"\n@@ -900,16 +933,16 @@\n (define_insn \"scatter<mode>_insn_2offsets<exec_scatter>\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n-\t  [(plus:V64DI\n-\t     (plus:V64DI\n-\t       (vec_duplicate:V64DI\n-\t\t (match_operand:DI 0 \"register_operand\"\t\t       \"Sv\"))\n-\t       (sign_extend:V64DI\n-\t\t (match_operand:V64SI 1 \"register_operand\"\t       \" v\")))\n-\t     (vec_duplicate:V64DI (match_operand 2 \"immediate_operand\" \" n\")))\n-\t   (match_operand:V_ALL 3 \"register_operand\"\t\t       \" v\")\n-\t   (match_operand 4 \"immediate_operand\"\t\t\t       \" n\")\n-\t   (match_operand 5 \"immediate_operand\"\t\t\t       \" n\")]\n+\t  [(plus:<VnDI>\n+\t     (plus:<VnDI>\n+\t       (vec_duplicate:<VnDI>\n+\t\t (match_operand:DI 0 \"register_operand\"\t\t\t\"Sv\"))\n+\t       (sign_extend:<VnDI>\n+\t\t (match_operand:<VnSI> 1 \"register_operand\"\t\t\" v\")))\n+\t     (vec_duplicate:<VnDI> (match_operand 2 \"immediate_operand\" \" n\")))\n+\t   (match_operand:V_ALL 3 \"register_operand\"\t\t\t\" v\")\n+\t   (match_operand 4 \"immediate_operand\"\t\t\t\t\" n\")\n+\t   (match_operand 5 \"immediate_operand\"\t\t\t\t\" n\")]\n \t  UNSPEC_SCATTER))]\n   \"(AS_GLOBAL_P (INTVAL (operands[4]))\n     && (((unsigned HOST_WIDE_INT)INTVAL(operands[2]) + 0x1000) < 0x2000))\"\n@@ -941,7 +974,7 @@\n   [(set (match_operand:V_1REG 0 \"register_operand\"    \"=v\")\n \t(unspec:V_1REG\n \t  [(match_operand:V_1REG 2 \"register_operand\" \" v\")\n-\t   (match_operand:V64SI 1 \"register_operand\"  \" v\")\n+\t   (match_operand:<VnSI> 1 \"register_operand\" \" v\")\n \t   (match_operand:DI 3 \"gcn_exec_reg_operand\" \" e\")]\n \t  UNSPEC_BPERMUTE))]\n   \"\"\n@@ -953,16 +986,18 @@\n   [(set (match_operand:V_2REG 0 \"register_operand\"    \"=&v\")\n \t(unspec:V_2REG\n \t  [(match_operand:V_2REG 2 \"register_operand\" \" v0\")\n-\t   (match_operand:V64SI 1 \"register_operand\"  \"  v\")\n+\t   (match_operand:<VnSI> 1 \"register_operand\" \"  v\")\n \t   (match_operand:DI 3 \"gcn_exec_reg_operand\" \"  e\")]\n \t  UNSPEC_BPERMUTE))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n-  [(set (match_dup 4) (unspec:V64SI [(match_dup 6) (match_dup 1) (match_dup 3)]\n-\t\t\t\t    UNSPEC_BPERMUTE))\n-   (set (match_dup 5) (unspec:V64SI [(match_dup 7) (match_dup 1) (match_dup 3)]\n-\t\t\t\t    UNSPEC_BPERMUTE))]\n+  [(set (match_dup 4) (unspec:<VnSI>\n+\t\t\t[(match_dup 6) (match_dup 1) (match_dup 3)]\n+\t\t\tUNSPEC_BPERMUTE))\n+   (set (match_dup 5) (unspec:<VnSI>\n+\t\t\t[(match_dup 7) (match_dup 1) (match_dup 3)]\n+\t\t\tUNSPEC_BPERMUTE))]\n   {\n     operands[4] = gcn_operand_part (<MODE>mode, operands[0], 0);\n     operands[5] = gcn_operand_part (<MODE>mode, operands[0], 1);\n@@ -1012,13 +1047,13 @@\n   [(set_attr \"type\" \"vop2\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn \"addv64si3_vcc<exec_vcc>\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"   \"=  v,   v\")\n-\t(plus:V64SI\n-\t  (match_operand:V64SI 1 \"register_operand\" \"%  v,   v\")\n-\t  (match_operand:V64SI 2 \"gcn_alu_operand\"  \"vSvB,vSvB\")))\n-   (set (match_operand:DI 3 \"register_operand\"\t    \"= cV,  Sg\")\n-\t(ltu:DI (plus:V64SI (match_dup 1) (match_dup 2))\n+(define_insn \"add<mode>3_vcc<exec_vcc>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"   \"=  v,   v\")\n+\t(plus:V_SI\n+\t  (match_operand:V_SI 1 \"register_operand\" \"%  v,   v\")\n+\t  (match_operand:V_SI 2 \"gcn_alu_operand\"  \"vSvB,vSvB\")))\n+   (set (match_operand:DI 3 \"register_operand\"\t   \"= cV,  Sg\")\n+\t(ltu:DI (plus:V_SI (match_dup 1) (match_dup 2))\n \t\t(match_dup 1)))]\n   \"\"\n   \"v_add%^_u32\\t%0, %3, %2, %1\"\n@@ -1028,16 +1063,16 @@\n ; This pattern only changes the VCC bits when the corresponding lane is\n ; enabled, so the set must be described as an ior.\n \n-(define_insn \"addv64si3_vcc_dup<exec_vcc>\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"   \"= v,  v\")\n-\t(plus:V64SI\n-\t  (vec_duplicate:V64SI\n-\t    (match_operand:SI 1 \"gcn_alu_operand\"   \"SvB,SvB\"))\n-\t  (match_operand:V64SI 2 \"register_operand\" \"  v,  v\")))\n-   (set (match_operand:DI 3 \"register_operand\"\t    \"=cV, Sg\")\n-\t(ltu:DI (plus:V64SI (vec_duplicate:V64SI (match_dup 2))\n-\t\t\t    (match_dup 1))\n-\t\t(vec_duplicate:V64SI (match_dup 2))))]\n+(define_insn \"add<mode>3_vcc_dup<exec_vcc>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"   \"= v,  v\")\n+\t(plus:V_SI\n+\t  (vec_duplicate:V_SI\n+\t    (match_operand:SI 1 \"gcn_alu_operand\"  \"SvB,SvB\"))\n+\t  (match_operand:V_SI 2 \"register_operand\" \"  v,  v\")))\n+   (set (match_operand:DI 3 \"register_operand\"\t   \"=cV, Sg\")\n+\t(ltu:DI (plus:V_SI (vec_duplicate:V_SI (match_dup 2))\n+\t\t\t   (match_dup 1))\n+\t\t(vec_duplicate:V_SI (match_dup 2))))]\n   \"\"\n   \"v_add%^_u32\\t%0, %3, %2, %1\"\n   [(set_attr \"type\" \"vop2,vop3b\")\n@@ -1047,30 +1082,30 @@\n ; SGPR use and the number of SGPR operands is limited to 1.  It does not\n ; accept \"B\" immediate constants due to a related bus conflict.\n \n-(define_insn \"addcv64si3<exec_vcc>\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"    \"=v,   v\")\n-\t(plus:V64SI\n-\t  (plus:V64SI\n-\t    (vec_merge:V64SI\n-\t      (vec_duplicate:V64SI (const_int 1))\n-\t      (vec_duplicate:V64SI (const_int 0))\n+(define_insn \"addc<mode>3<exec_vcc>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"     \"=v,   v\")\n+\t(plus:V_SI\n+\t  (plus:V_SI\n+\t    (vec_merge:V_SI\n+\t      (vec_duplicate:V_SI (const_int 1))\n+\t      (vec_duplicate:V_SI (const_int 0))\n \t      (match_operand:DI 3 \"register_operand\" \" cV,cVSv\"))\n-\t    (match_operand:V64SI 1 \"gcn_alu_operand\" \"% v,  vA\"))\n-\t  (match_operand:V64SI 2 \"gcn_alu_operand\"   \" vA,  vA\")))\n+\t    (match_operand:V_SI 1 \"gcn_alu_operand\"  \"% v,  vA\"))\n+\t  (match_operand:V_SI 2 \"gcn_alu_operand\"    \" vA,  vA\")))\n    (set (match_operand:DI 4 \"register_operand\"\t     \"=cV,cVSg\")\n-\t(ior:DI (ltu:DI (plus:V64SI\n-\t\t\t  (plus:V64SI\n-\t\t\t    (vec_merge:V64SI\n-\t\t\t      (vec_duplicate:V64SI (const_int 1))\n-\t\t\t      (vec_duplicate:V64SI (const_int 0))\n+\t(ior:DI (ltu:DI (plus:V_SI\n+\t\t\t  (plus:V_SI\n+\t\t\t    (vec_merge:V_SI\n+\t\t\t      (vec_duplicate:V_SI (const_int 1))\n+\t\t\t      (vec_duplicate:V_SI (const_int 0))\n \t\t\t      (match_dup 3))\n \t\t\t    (match_dup 1))\n \t\t\t  (match_dup 2))\n \t\t\t(match_dup 2))\n-\t\t(ltu:DI (plus:V64SI\n-\t\t\t  (vec_merge:V64SI\n-\t\t\t    (vec_duplicate:V64SI (const_int 1))\n-\t\t\t    (vec_duplicate:V64SI (const_int 0))\n+\t\t(ltu:DI (plus:V_SI\n+\t\t\t  (vec_merge:V_SI\n+\t\t\t    (vec_duplicate:V_SI (const_int 1))\n+\t\t\t    (vec_duplicate:V_SI (const_int 0))\n \t\t\t    (match_dup 3))\n \t\t\t  (match_dup 1))\n \t\t\t(match_dup 1))))]\n@@ -1092,13 +1127,13 @@\n   [(set_attr \"type\" \"vop2\")\n    (set_attr \"length\" \"8,8\")])\n \n-(define_insn \"subv64si3_vcc<exec_vcc>\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"  \"=  v,   v,   v,   v\")\n-\t(minus:V64SI\n-\t  (match_operand:V64SI 1 \"gcn_alu_operand\" \"vSvB,vSvB,   v,   v\")\n-\t  (match_operand:V64SI 2 \"gcn_alu_operand\" \"   v,   v,vSvB,vSvB\")))\n-   (set (match_operand:DI 3 \"register_operand\"\t   \"= cV,  Sg,  cV,  Sg\")\n-\t(gtu:DI (minus:V64SI (match_dup 1) (match_dup 2))\n+(define_insn \"sub<mode>3_vcc<exec_vcc>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"  \"=  v,   v,   v,   v\")\n+\t(minus:V_SI\n+\t  (match_operand:V_SI 1 \"gcn_alu_operand\" \"vSvB,vSvB,   v,   v\")\n+\t  (match_operand:V_SI 2 \"gcn_alu_operand\" \"   v,   v,vSvB,vSvB\")))\n+   (set (match_operand:DI 3 \"register_operand\"\t  \"= cV,  Sg,  cV,  Sg\")\n+\t(gtu:DI (minus:V_SI (match_dup 1) (match_dup 2))\n \t\t(match_dup 1)))]\n   \"\"\n   \"@\n@@ -1113,30 +1148,30 @@\n ; SGPR use and the number of SGPR operands is limited to 1.  It does not\n ; accept \"B\" immediate constants due to a related bus conflict.\n \n-(define_insn \"subcv64si3<exec_vcc>\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"    \"= v, v, v, v\")\n-\t(minus:V64SI\n-\t  (minus:V64SI\n-\t    (vec_merge:V64SI\n-\t      (vec_duplicate:V64SI (const_int 1))\n-\t      (vec_duplicate:V64SI (const_int 0))\n-\t      (match_operand:DI 3 \"gcn_alu_operand\"  \" cV,cVSv,cV,cVSv\"))\n-\t    (match_operand:V64SI 1 \"gcn_alu_operand\" \" vA,  vA, v,  vA\"))\n-\t  (match_operand:V64SI 2 \"gcn_alu_operand\"   \"  v,  vA,vA,  vA\")))\n-   (set (match_operand:DI 4 \"register_operand\"\t     \"=cV,cVSg,cV,cVSg\")\n-\t(ior:DI (gtu:DI (minus:V64SI (minus:V64SI\n-\t\t\t\t       (vec_merge:V64SI\n-\t\t\t\t\t (vec_duplicate:V64SI (const_int 1))\n-\t\t\t\t\t (vec_duplicate:V64SI (const_int 0))\n-\t\t\t\t\t (match_dup 3))\n+(define_insn \"subc<mode>3<exec_vcc>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"    \"= v, v, v, v\")\n+\t(minus:V_SI\n+\t  (minus:V_SI\n+\t    (vec_merge:V_SI\n+\t      (vec_duplicate:V_SI (const_int 1))\n+\t      (vec_duplicate:V_SI (const_int 0))\n+\t      (match_operand:DI 3 \"gcn_alu_operand\" \" cV,cVSv,cV,cVSv\"))\n+\t    (match_operand:V_SI 1 \"gcn_alu_operand\" \" vA,  vA, v,  vA\"))\n+\t  (match_operand:V_SI 2 \"gcn_alu_operand\"   \"  v,  vA,vA,  vA\")))\n+   (set (match_operand:DI 4 \"register_operand\"\t    \"=cV,cVSg,cV,cVSg\")\n+\t(ior:DI (gtu:DI (minus:V_SI (minus:V_SI\n+\t\t\t\t      (vec_merge:V_SI\n+\t\t\t\t\t(vec_duplicate:V_SI (const_int 1))\n+\t\t\t\t\t(vec_duplicate:V_SI (const_int 0))\n+\t\t\t\t\t(match_dup 3))\n \t\t\t\t       (match_dup 1))\n \t\t\t\t     (match_dup 2))\n \t\t\t(match_dup 2))\n-\t\t(ltu:DI (minus:V64SI (vec_merge:V64SI\n-\t\t\t\t       (vec_duplicate:V64SI (const_int 1))\n-\t\t\t\t       (vec_duplicate:V64SI (const_int 0))\n-\t\t\t\t       (match_dup 3))\n-\t\t\t\t     (match_dup 1))\n+\t\t(ltu:DI (minus:V_SI (vec_merge:V_SI\n+\t\t\t\t      (vec_duplicate:V_SI (const_int 1))\n+\t\t\t\t      (vec_duplicate:V_SI (const_int 0))\n+\t\t\t\t      (match_dup 3))\n+\t\t\t\t    (match_dup 1))\n \t\t\t(match_dup 1))))]\n   \"\"\n   \"@\n@@ -1147,394 +1182,392 @@\n   [(set_attr \"type\" \"vop2,vop3b,vop2,vop3b\")\n    (set_attr \"length\" \"4,8,4,8\")])\n \n-(define_insn_and_split \"addv64di3\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"   \"=  v\")\n-\t(plus:V64DI\n-\t  (match_operand:V64DI 1 \"register_operand\" \"%vDb\")\n-\t  (match_operand:V64DI 2 \"gcn_alu_operand\"  \" vDb\")))\n+(define_insn_and_split \"add<mode>3\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"   \"=  v\")\n+\t(plus:V_DI\n+\t  (match_operand:V_DI 1 \"register_operand\" \"%vDb\")\n+\t  (match_operand:V_DI 2 \"gcn_alu_operand\"  \" vDb\")))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[1])\n-   && gcn_can_split_p (V64DImode, operands[2])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[1])\n+   && gcn_can_split_p (<MODE>mode, operands[2])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_addv64si3_vcc\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n-\t\t gcn_operand_part (V64DImode, operands[1], 0),\n-\t\t gcn_operand_part (V64DImode, operands[2], 0),\n+    emit_insn (gen_add<vnsi>3_vcc\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[1], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 0),\n \t\t vcc));\n-    emit_insn (gen_addcv64si3\n-\t\t(gcn_operand_part (V64DImode, operands[0], 1),\n-\t\t gcn_operand_part (V64DImode, operands[1], 1),\n-\t\t gcn_operand_part (V64DImode, operands[2], 1),\n+    emit_insn (gen_addc<vnsi>3\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[1], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 1),\n \t\t vcc, vcc));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t  \"=  v\")\n-\t(vec_merge:V64DI\n-\t  (plus:V64DI\n-\t    (match_operand:V64DI 1 \"register_operand\"\t\t  \"%vDb\")\n-\t    (match_operand:V64DI 2 \"gcn_alu_operand\"\t\t  \" vDb\"))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\" \"  U0\")\n-\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t  \"   e\")))\n+(define_insn_and_split \"add<mode>3_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t \"=  v\")\n+\t(vec_merge:V_DI\n+\t  (plus:V_DI\n+\t    (match_operand:V_DI 1 \"register_operand\"\t\t \"%vDb\")\n+\t    (match_operand:V_DI 2 \"gcn_alu_operand\"\t\t \" vDb\"))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\" \"  U0\")\n+\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t \"   e\")))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[1])\n-   && gcn_can_split_p (V64DImode, operands[2])\n-   && gcn_can_split_p (V64DImode, operands[4])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[1])\n+   && gcn_can_split_p (<MODE>mode, operands[2])\n+   && gcn_can_split_p (<MODE>mode, operands[4])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_addv64si3_vcc_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n-\t\t gcn_operand_part (V64DImode, operands[1], 0),\n-\t\t gcn_operand_part (V64DImode, operands[2], 0),\n+    emit_insn (gen_add<vnsi>3_vcc_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[1], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 0),\n \t\t vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 0),\n \t\t operands[4]));\n-    emit_insn (gen_addcv64si3_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 1),\n-\t\t gcn_operand_part (V64DImode, operands[1], 1),\n-\t\t gcn_operand_part (V64DImode, operands[2], 1),\n+    emit_insn (gen_addc<vnsi>3_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[1], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 1),\n \t\t vcc, vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 1),\n \t\t operands[4]));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"subv64di3\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"  \"= v,  v\")\n-\t(minus:V64DI                                        \n-\t  (match_operand:V64DI 1 \"gcn_alu_operand\" \"vDb,  v\")\n-\t  (match_operand:V64DI 2 \"gcn_alu_operand\" \"  v,vDb\")))\n+(define_insn_and_split \"sub<mode>3\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"  \"= v,  v\")\n+\t(minus:V_DI                                        \n+\t  (match_operand:V_DI 1 \"gcn_alu_operand\" \"vDb,  v\")\n+\t  (match_operand:V_DI 2 \"gcn_alu_operand\" \"  v,vDb\")))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[1])\n-   && gcn_can_split_p (V64DImode, operands[2])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[1])\n+   && gcn_can_split_p (<MODE>mode, operands[2])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_subv64si3_vcc\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n-\t\t gcn_operand_part (V64DImode, operands[1], 0),\n-\t\t gcn_operand_part (V64DImode, operands[2], 0),\n+    emit_insn (gen_sub<vnsi>3_vcc\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[1], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 0),\n \t\t vcc));\n-    emit_insn (gen_subcv64si3\n-\t\t(gcn_operand_part (V64DImode, operands[0], 1),\n-\t\t gcn_operand_part (V64DImode, operands[1], 1),\n-\t\t gcn_operand_part (V64DImode, operands[2], 1),\n+    emit_insn (gen_subc<vnsi>3\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[1], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 1),\n \t\t vcc, vcc));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"subv64di3_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t \"=  v,   v\")\n-\t(vec_merge:V64DI                                                         \n-\t  (minus:V64DI                                                           \n-\t    (match_operand:V64DI 1 \"gcn_alu_operand\"\t\t \"vSvB,   v\")\n-\t    (match_operand:V64DI 2 \"gcn_alu_operand\"\t\t \"   v,vSvB\"))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\" \" U0,  U0\")\n+(define_insn_and_split \"sub<mode>3_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t \"=  v,   v\")\n+\t(vec_merge:V_DI                                                         \n+\t  (minus:V_DI                                                           \n+\t    (match_operand:V_DI 1 \"gcn_alu_operand\"\t\t \"vSvB,   v\")\n+\t    (match_operand:V_DI 2 \"gcn_alu_operand\"\t\t \"   v,vSvB\"))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\" \" U0,  U0\")\n \t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t \"   e,   e\")))\n    (clobber (reg:DI VCC_REG))]\n   \"register_operand (operands[1], VOIDmode)\n    || register_operand (operands[2], VOIDmode)\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[1])\n-   && gcn_can_split_p (V64DImode, operands[2])\n-   && gcn_can_split_p (V64DImode, operands[3])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[1])\n+   && gcn_can_split_p (<MODE>mode, operands[2])\n+   && gcn_can_split_p (<MODE>mode, operands[3])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_subv64si3_vcc_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n-\t\t gcn_operand_part (V64DImode, operands[1], 0),\n-\t\t gcn_operand_part (V64DImode, operands[2], 0),\n+    emit_insn (gen_sub<vnsi>3_vcc_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[1], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 0),\n \t\t vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 0),\n \t\t operands[4]));\n-    emit_insn (gen_subcv64si3_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 1),\n-\t\t gcn_operand_part (V64DImode, operands[1], 1),\n-\t\t gcn_operand_part (V64DImode, operands[2], 1),\n+    emit_insn (gen_subc<vnsi>3_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[1], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 1),\n \t\t vcc, vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 1),\n \t\t operands[4]));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_zext\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"    \"= v,  v\")\n-\t(plus:V64DI\n-\t  (zero_extend:V64DI\n-\t    (match_operand:V64SI 1 \"gcn_alu_operand\" \" vA, vB\"))\n-\t  (match_operand:V64DI 2 \"gcn_alu_operand\"   \"vDb,vDA\")))\n+(define_insn_and_split \"add<mode>3_zext\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"      \"= v,  v\")\n+\t(plus:V_DI\n+\t  (zero_extend:V_DI\n+\t    (match_operand:<VnSI> 1 \"gcn_alu_operand\" \" vA, vB\"))\n+\t  (match_operand:V_DI 2 \"gcn_alu_operand\"     \"vDb,vDA\")))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[2])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[2])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_addv64si3_vcc\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n+    emit_insn (gen_add<vnsi>3_vcc\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n \t\t operands[1],\n-\t\t gcn_operand_part (V64DImode, operands[2], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 0),\n \t\t vcc));\n-    emit_insn (gen_addcv64si3\n-\t\t(gcn_operand_part (V64DImode, operands[0], 1),\n-\t\t gcn_operand_part (V64DImode, operands[2], 1),\n+    emit_insn (gen_addc<vnsi>3\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 1),\n \t\t const0_rtx, vcc, vcc));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_zext_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t  \"= v,  v\")\n-\t(vec_merge:V64DI\n-\t  (plus:V64DI\n-\t    (zero_extend:V64DI\n-\t      (match_operand:V64SI 1 \"gcn_alu_operand\"\t\t  \" vA, vB\"))\n-\t    (match_operand:V64DI 2 \"gcn_alu_operand\"\t\t  \"vDb,vDA\"))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\" \" U0, U0\")\n-\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t  \"  e,  e\")))\n+(define_insn_and_split \"add<mode>3_zext_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t \"= v,  v\")\n+\t(vec_merge:V_DI\n+\t  (plus:V_DI\n+\t    (zero_extend:V_DI\n+\t      (match_operand:<VnSI> 1 \"gcn_alu_operand\"\t\t \" vA, vB\"))\n+\t    (match_operand:V_DI 2 \"gcn_alu_operand\"\t\t \"vDb,vDA\"))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\" \" U0, U0\")\n+\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t \"  e,  e\")))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[2])\n-   && gcn_can_split_p (V64DImode, operands[3])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[2])\n+   && gcn_can_split_p (<MODE>mode, operands[3])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_addv64si3_vcc_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n+    emit_insn (gen_add<vnsi>3_vcc_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n \t\t operands[1],\n-\t\t gcn_operand_part (V64DImode, operands[2], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 0),\n \t\t vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 0),\n \t\t operands[4]));\n-    emit_insn (gen_addcv64si3_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 1),\n-\t\t gcn_operand_part (V64DImode, operands[2], 1),\n+    emit_insn (gen_addc<vnsi>3_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 1),\n \t\t const0_rtx, vcc, vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 1),\n \t\t operands[4]));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_zext_dup\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"   \"= v,  v\")\n-\t(plus:V64DI\n-\t  (zero_extend:V64DI\n-\t    (vec_duplicate:V64SI\n+(define_insn_and_split \"add<mode>3_zext_dup\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"    \"= v,  v\")\n+\t(plus:V_DI\n+\t  (zero_extend:V_DI\n+\t    (vec_duplicate:<VnSI>\n \t      (match_operand:SI 1 \"gcn_alu_operand\" \"BSv,ASv\")))\n-\t  (match_operand:V64DI 2 \"gcn_alu_operand\"  \"vDA,vDb\")))\n+\t  (match_operand:V_DI 2 \"gcn_alu_operand\"   \"vDA,vDb\")))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[2])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[2])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_addv64si3_vcc_dup\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n+    emit_insn (gen_add<vnsi>3_vcc_dup\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n \t\t gcn_operand_part (DImode, operands[1], 0),\n-\t\t gcn_operand_part (V64DImode, operands[2], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 0),\n \t\t vcc));\n-    emit_insn (gen_addcv64si3\n-\t\t(gcn_operand_part (V64DImode, operands[0], 1),\n-\t\t gcn_operand_part (V64DImode, operands[2], 1),\n+    emit_insn (gen_addc<vnsi>3\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 1),\n \t\t const0_rtx, vcc, vcc));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_zext_dup_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t  \"= v,  v\")\n-\t(vec_merge:V64DI\n-\t  (plus:V64DI\n-\t    (zero_extend:V64DI\n-\t      (vec_duplicate:V64SI\n-\t\t(match_operand:SI 1 \"gcn_alu_operand\"\t\t  \"ASv,BSv\")))\n-\t    (match_operand:V64DI 2 \"gcn_alu_operand\"\t\t  \"vDb,vDA\"))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\" \" U0, U0\")\n-\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t  \"  e,  e\")))\n+(define_insn_and_split \"add<mode>3_zext_dup_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t \"= v,  v\")\n+\t(vec_merge:V_DI\n+\t  (plus:V_DI\n+\t    (zero_extend:V_DI\n+\t      (vec_duplicate:<VnSI>\n+\t\t(match_operand:SI 1 \"gcn_alu_operand\"\t\t \"ASv,BSv\")))\n+\t    (match_operand:V_DI 2 \"gcn_alu_operand\"\t\t \"vDb,vDA\"))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\" \" U0, U0\")\n+\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t \"  e,  e\")))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[2])\n-   && gcn_can_split_p (V64DImode, operands[3])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[2])\n+   && gcn_can_split_p (<MODE>mode, operands[3])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_addv64si3_vcc_dup_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n+    emit_insn (gen_add<vnsi>3_vcc_dup_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n \t\t gcn_operand_part (DImode, operands[1], 0),\n-\t\t gcn_operand_part (V64DImode, operands[2], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 0),\n \t\t vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 0),\n \t\t operands[4]));\n-    emit_insn (gen_addcv64si3_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 1),\n-\t\t gcn_operand_part (V64DImode, operands[2], 1),\n+    emit_insn (gen_addc<vnsi>3_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[2], 1),\n \t\t const0_rtx, vcc, vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 1),\n \t\t operands[4]));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_zext_dup2\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t     \"=  v\")\n-\t(plus:V64DI\n-\t  (zero_extend:V64DI (match_operand:V64SI 1 \"gcn_alu_operand\" \" vA\"))\n-\t  (vec_duplicate:V64DI (match_operand:DI 2 \"gcn_alu_operand\" \"DbSv\"))))\n+(define_insn_and_split \"add<mode>3_zext_dup2\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t      \"=  v\")\n+\t(plus:V_DI\n+\t  (zero_extend:V_DI (match_operand:<VnSI> 1 \"gcn_alu_operand\" \" vA\"))\n+\t  (vec_duplicate:V_DI (match_operand:DI 2 \"gcn_alu_operand\"   \"DbSv\"))))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\"\n+  \"gcn_can_split_p (<MODE>mode, operands[0])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_addv64si3_vcc_dup\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n+    emit_insn (gen_add<vnsi>3_vcc_dup\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n \t\t gcn_operand_part (DImode, operands[2], 0),\n \t\t operands[1],\n \t\t vcc));\n-    rtx dsthi = gcn_operand_part (V64DImode, operands[0], 1);\n-    emit_insn (gen_vec_duplicatev64si\n+    rtx dsthi = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    emit_insn (gen_vec_duplicate<vnsi>\n \t\t(dsthi, gcn_operand_part (DImode, operands[2], 1)));\n-    emit_insn (gen_addcv64si3 (dsthi, dsthi, const0_rtx, vcc, vcc));\n+    emit_insn (gen_addc<vnsi>3 (dsthi, dsthi, const0_rtx, vcc, vcc));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_zext_dup2_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t       \"= v\")\n-\t(vec_merge:V64DI\n-\t  (plus:V64DI\n-\t    (zero_extend:V64DI (match_operand:V64SI 1 \"gcn_alu_operand\"\n-\t\t\t\t\t\t\t\t       \" vA\"))\n-\t    (vec_duplicate:V64DI (match_operand:DI 2 \"gcn_alu_operand\" \"BSv\")))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\"      \" U0\")\n+(define_insn_and_split \"add<mode>3_zext_dup2_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t       \"= v\")\n+\t(vec_merge:V_DI\n+\t  (plus:V_DI\n+\t    (zero_extend:V_DI (match_operand:<VnSI> 1 \"gcn_alu_operand\" \"vA\"))\n+\t    (vec_duplicate:V_DI (match_operand:DI 2 \"gcn_alu_operand\"  \"BSv\")))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\"       \" U0\")\n \t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t       \"  e\")))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[3])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[3])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_addv64si3_vcc_dup_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n+    emit_insn (gen_add<vnsi>3_vcc_dup_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n \t\t gcn_operand_part (DImode, operands[2], 0),\n \t\t operands[1],\n \t\t vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 0),\n \t\t operands[4]));\n-    rtx dsthi = gcn_operand_part (V64DImode, operands[0], 1);\n-    emit_insn (gen_vec_duplicatev64si_exec\n+    rtx dsthi = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    emit_insn (gen_vec_duplicate<vnsi>_exec\n \t\t(dsthi, gcn_operand_part (DImode, operands[2], 1),\n-\t\t gcn_gen_undef (V64SImode), operands[4]));\n-    emit_insn (gen_addcv64si3_exec\n+\t\t gcn_gen_undef (<VnSI>mode), operands[4]));\n+    emit_insn (gen_addc<vnsi>3_exec\n \t\t(dsthi, dsthi, const0_rtx, vcc, vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 1),\n \t\t operands[4]));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_sext_dup2\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t      \"= v\")\n-\t(plus:V64DI\n-\t  (sign_extend:V64DI (match_operand:V64SI 1 \"gcn_alu_operand\" \" vA\"))\n-\t  (vec_duplicate:V64DI (match_operand:DI 2 \"gcn_alu_operand\"  \"BSv\"))))\n-   (clobber (match_scratch:V64SI 3\t\t\t\t      \"=&v\"))\n+(define_insn_and_split \"add<mode>3_sext_dup2\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t      \"= v\")\n+\t(plus:V_DI\n+\t  (sign_extend:V_DI (match_operand:<VnSI> 1 \"gcn_alu_operand\" \" vA\"))\n+\t  (vec_duplicate:V_DI (match_operand:DI 2 \"gcn_alu_operand\"   \"BSv\"))))\n+   (clobber (match_scratch:<VnSI> 3\t\t\t\t      \"=&v\"))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_ashrv64si3 (operands[3], operands[1], GEN_INT (31)));\n-    emit_insn (gen_addv64si3_vcc_dup\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n+    emit_insn (gen_ashr<vnsi>3 (operands[3], operands[1], GEN_INT (31)));\n+    emit_insn (gen_add<vnsi>3_vcc_dup\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n \t\t gcn_operand_part (DImode, operands[2], 0),\n \t\t operands[1],\n \t\t vcc));\n-    rtx dsthi = gcn_operand_part (V64DImode, operands[0], 1);\n-    emit_insn (gen_vec_duplicatev64si\n+    rtx dsthi = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    emit_insn (gen_vec_duplicate<vnsi>\n \t\t(dsthi, gcn_operand_part (DImode, operands[2], 1)));\n-    emit_insn (gen_addcv64si3 (dsthi, dsthi, operands[3], vcc, vcc));\n+    emit_insn (gen_addc<vnsi>3 (dsthi, dsthi, operands[3], vcc, vcc));\n     DONE;\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"addv64di3_sext_dup2_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t       \"= v\")\n-\t(vec_merge:V64DI\n-\t  (plus:V64DI\n-\t    (sign_extend:V64DI (match_operand:V64SI 1 \"gcn_alu_operand\"\n-\t\t\t\t\t\t\t\t       \" vA\"))\n-\t    (vec_duplicate:V64DI (match_operand:DI 2 \"gcn_alu_operand\" \"BSv\")))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\"      \" U0\")\n+(define_insn_and_split \"add<mode>3_sext_dup2_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t       \"= v\")\n+\t(vec_merge:V_DI\n+\t  (plus:V_DI\n+\t    (sign_extend:V_DI (match_operand:<VnSI> 1 \"gcn_alu_operand\" \"vA\"))\n+\t    (vec_duplicate:V_DI (match_operand:DI 2 \"gcn_alu_operand\"  \"BSv\")))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\"       \" U0\")\n \t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t       \"  e\")))\n-   (clobber (match_scratch:V64SI 5\t\t\t\t       \"=&v\"))\n+   (clobber (match_scratch:<VnSI> 5\t\t\t\t       \"=&v\"))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n-  \"gcn_can_split_p  (V64DImode, operands[0])\n-   && gcn_can_split_p (V64DImode, operands[3])\"\n+  \"gcn_can_split_p  (<MODE>mode, operands[0])\n+   && gcn_can_split_p (<MODE>mode, operands[3])\"\n   [(const_int 0)]\n   {\n     rtx vcc = gen_rtx_REG (DImode, VCC_REG);\n-    emit_insn (gen_ashrv64si3_exec (operands[5], operands[1], GEN_INT (31),\n-\t\t\t\t    gcn_gen_undef (V64SImode), operands[4]));\n-    emit_insn (gen_addv64si3_vcc_dup_exec\n-\t\t(gcn_operand_part (V64DImode, operands[0], 0),\n+    emit_insn (gen_ashr<vnsi>3_exec (operands[5], operands[1], GEN_INT (31),\n+\t\t\t\t     gcn_gen_undef (<VnSI>mode), operands[4]));\n+    emit_insn (gen_add<vnsi>3_vcc_dup_exec\n+\t\t(gcn_operand_part (<MODE>mode, operands[0], 0),\n \t\t gcn_operand_part (DImode, operands[2], 0),\n \t\t operands[1],\n \t\t vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 0),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 0),\n \t\t operands[4]));\n-    rtx dsthi = gcn_operand_part (V64DImode, operands[0], 1);\n-    emit_insn (gen_vec_duplicatev64si_exec\n+    rtx dsthi = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    emit_insn (gen_vec_duplicate<vnsi>_exec\n \t\t(dsthi, gcn_operand_part (DImode, operands[2], 1),\n-\t\t gcn_gen_undef (V64SImode), operands[4]));\n-    emit_insn (gen_addcv64si3_exec\n+\t\t gcn_gen_undef (<VnSI>mode), operands[4]));\n+    emit_insn (gen_addc<vnsi>3_exec\n \t\t(dsthi, dsthi, operands[5], vcc, vcc,\n-\t\t gcn_operand_part (V64DImode, operands[3], 1),\n+\t\t gcn_operand_part (<MODE>mode, operands[3], 1),\n \t\t operands[4]));\n     DONE;\n   }\n@@ -1620,15 +1653,15 @@\n ;; }}}\n ;; {{{ ALU special case: mult\n \n-(define_insn \"<su>mulv64si3_highpart<exec>\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"\t \"=  v\")\n-\t(truncate:V64SI\n-\t  (lshiftrt:V64DI\n-\t    (mult:V64DI\n-\t      (any_extend:V64DI\n-\t\t(match_operand:V64SI 1 \"gcn_alu_operand\" \"  %v\"))\n-\t      (any_extend:V64DI\n-\t\t(match_operand:V64SI 2 \"gcn_alu_operand\" \"vSvA\")))\n+(define_insn \"<su>mul<mode>3_highpart<exec>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"        \"=  v\")\n+\t(truncate:V_SI\n+\t  (lshiftrt:<VnDI>\n+\t    (mult:<VnDI>\n+\t      (any_extend:<VnDI>\n+\t\t(match_operand:V_SI 1 \"gcn_alu_operand\" \"  %v\"))\n+\t      (any_extend:<VnDI>\n+\t\t(match_operand:V_SI 2 \"gcn_alu_operand\" \"vSvA\")))\n \t    (const_int 32))))]\n   \"\"\n   \"v_mul_hi<sgnsuffix>0\\t%0, %2, %1\"\n@@ -1656,223 +1689,223 @@\n   [(set_attr \"type\" \"vop3a\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"mulv64di3\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"  \"=&v\")\n-\t(mult:V64DI\n-\t  (match_operand:V64DI 1 \"gcn_alu_operand\" \"% v\")\n-\t  (match_operand:V64DI 2 \"gcn_alu_operand\" \"vDA\")))\n-   (clobber (match_scratch:V64SI 3\t\t   \"=&v\"))]\n+(define_insn_and_split \"mul<mode>3\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"  \"=&v\")\n+\t(mult:V_DI\n+\t  (match_operand:V_DI 1 \"gcn_alu_operand\" \"% v\")\n+\t  (match_operand:V_DI 2 \"gcn_alu_operand\" \"vDA\")))\n+   (clobber (match_scratch:<VnSI> 3\t\t  \"=&v\"))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx out_lo = gcn_operand_part (V64DImode, operands[0], 0);\n-    rtx out_hi = gcn_operand_part (V64DImode, operands[0], 1);\n-    rtx left_lo = gcn_operand_part (V64DImode, operands[1], 0);\n-    rtx left_hi = gcn_operand_part (V64DImode, operands[1], 1);\n-    rtx right_lo = gcn_operand_part (V64DImode, operands[2], 0);\n-    rtx right_hi = gcn_operand_part (V64DImode, operands[2], 1);\n+    rtx out_lo = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    rtx out_hi = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    rtx left_lo = gcn_operand_part (<MODE>mode, operands[1], 0);\n+    rtx left_hi = gcn_operand_part (<MODE>mode, operands[1], 1);\n+    rtx right_lo = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    rtx right_hi = gcn_operand_part (<MODE>mode, operands[2], 1);\n     rtx tmp = operands[3];\n \n-    emit_insn (gen_mulv64si3 (out_lo, left_lo, right_lo));\n-    emit_insn (gen_umulv64si3_highpart (out_hi, left_lo, right_lo));\n-    emit_insn (gen_mulv64si3 (tmp, left_hi, right_lo));\n-    emit_insn (gen_addv64si3 (out_hi, out_hi, tmp));\n-    emit_insn (gen_mulv64si3 (tmp, left_lo, right_hi));\n-    emit_insn (gen_addv64si3 (out_hi, out_hi, tmp));\n-    emit_insn (gen_mulv64si3 (tmp, left_hi, right_hi));\n-    emit_insn (gen_addv64si3 (out_hi, out_hi, tmp));\n+    emit_insn (gen_mul<vnsi>3 (out_lo, left_lo, right_lo));\n+    emit_insn (gen_umul<vnsi>3_highpart (out_hi, left_lo, right_lo));\n+    emit_insn (gen_mul<vnsi>3 (tmp, left_hi, right_lo));\n+    emit_insn (gen_add<vnsi>3 (out_hi, out_hi, tmp));\n+    emit_insn (gen_mul<vnsi>3 (tmp, left_lo, right_hi));\n+    emit_insn (gen_add<vnsi>3 (out_hi, out_hi, tmp));\n+    emit_insn (gen_mul<vnsi>3 (tmp, left_hi, right_hi));\n+    emit_insn (gen_add<vnsi>3 (out_hi, out_hi, tmp));\n     DONE;\n   })\n \n-(define_insn_and_split \"mulv64di3_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t  \"=&v\")\n-\t(vec_merge:V64DI\n-\t  (mult:V64DI\n-\t    (match_operand:V64DI 1 \"gcn_alu_operand\"\t\t  \"% v\")\n-\t    (match_operand:V64DI 2 \"gcn_alu_operand\"\t\t  \"vDA\"))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\" \" U0\")\n-\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t  \"  e\")))\n-   (clobber (match_scratch:V64SI 5                                \"=&v\"))]\n+(define_insn_and_split \"mul<mode>3_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t \"=&v\")\n+\t(vec_merge:V_DI\n+\t  (mult:V_DI\n+\t    (match_operand:V_DI 1 \"gcn_alu_operand\"\t\t \"% v\")\n+\t    (match_operand:V_DI 2 \"gcn_alu_operand\"\t\t \"vDA\"))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\" \" U0\")\n+\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t \"  e\")))\n+   (clobber (match_scratch:<VnSI> 5\t\t\t\t \"=&v\"))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx out_lo = gcn_operand_part (V64DImode, operands[0], 0);\n-    rtx out_hi = gcn_operand_part (V64DImode, operands[0], 1);\n-    rtx left_lo = gcn_operand_part (V64DImode, operands[1], 0);\n-    rtx left_hi = gcn_operand_part (V64DImode, operands[1], 1);\n-    rtx right_lo = gcn_operand_part (V64DImode, operands[2], 0);\n-    rtx right_hi = gcn_operand_part (V64DImode, operands[2], 1);\n+    rtx out_lo = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    rtx out_hi = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    rtx left_lo = gcn_operand_part (<MODE>mode, operands[1], 0);\n+    rtx left_hi = gcn_operand_part (<MODE>mode, operands[1], 1);\n+    rtx right_lo = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    rtx right_hi = gcn_operand_part (<MODE>mode, operands[2], 1);\n     rtx exec = operands[4];\n     rtx tmp = operands[5];\n \n     rtx old_lo, old_hi;\n     if (GET_CODE (operands[3]) == UNSPEC)\n       {\n-\told_lo = old_hi = gcn_gen_undef (V64SImode);\n+\told_lo = old_hi = gcn_gen_undef (<VnSI>mode);\n       }\n     else\n       {\n-\told_lo = gcn_operand_part (V64DImode, operands[3], 0);\n-\told_hi = gcn_operand_part (V64DImode, operands[3], 1);\n+\told_lo = gcn_operand_part (<MODE>mode, operands[3], 0);\n+\told_hi = gcn_operand_part (<MODE>mode, operands[3], 1);\n       }\n \n-    rtx undef = gcn_gen_undef (V64SImode);\n-\n-    emit_insn (gen_mulv64si3_exec (out_lo, left_lo, right_lo, old_lo, exec));\n-    emit_insn (gen_umulv64si3_highpart_exec (out_hi, left_lo, right_lo,\n-\t\t\t\t\t     old_hi, exec));\n-    emit_insn (gen_mulv64si3_exec (tmp, left_hi, right_lo, undef, exec));\n-    emit_insn (gen_addv64si3_exec (out_hi, out_hi, tmp, out_hi, exec));\n-    emit_insn (gen_mulv64si3_exec (tmp, left_lo, right_hi, undef, exec));\n-    emit_insn (gen_addv64si3_exec (out_hi, out_hi, tmp, out_hi, exec));\n-    emit_insn (gen_mulv64si3_exec (tmp, left_hi, right_hi, undef, exec));\n-    emit_insn (gen_addv64si3_exec (out_hi, out_hi, tmp, out_hi, exec));\n+    rtx undef = gcn_gen_undef (<VnSI>mode);\n+\n+    emit_insn (gen_mul<vnsi>3_exec (out_lo, left_lo, right_lo, old_lo, exec));\n+    emit_insn (gen_umul<vnsi>3_highpart_exec (out_hi, left_lo, right_lo,\n+\t\t\t\t\t      old_hi, exec));\n+    emit_insn (gen_mul<vnsi>3_exec (tmp, left_hi, right_lo, undef, exec));\n+    emit_insn (gen_add<vnsi>3_exec (out_hi, out_hi, tmp, out_hi, exec));\n+    emit_insn (gen_mul<vnsi>3_exec (tmp, left_lo, right_hi, undef, exec));\n+    emit_insn (gen_add<vnsi>3_exec (out_hi, out_hi, tmp, out_hi, exec));\n+    emit_insn (gen_mul<vnsi>3_exec (tmp, left_hi, right_hi, undef, exec));\n+    emit_insn (gen_add<vnsi>3_exec (out_hi, out_hi, tmp, out_hi, exec));\n     DONE;\n   })\n \n-(define_insn_and_split \"mulv64di3_zext\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"    \"=&v\")\n-\t(mult:V64DI\n-\t  (zero_extend:V64DI\n-\t    (match_operand:V64SI 1 \"gcn_alu_operand\" \"  v\"))\n-\t  (match_operand:V64DI 2 \"gcn_alu_operand\"   \"vDA\")))\n-   (clobber (match_scratch:V64SI 3\t\t     \"=&v\"))]\n+(define_insn_and_split \"mul<mode>3_zext\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"      \"=&v\")\n+\t(mult:V_DI\n+\t  (zero_extend:V_DI\n+\t    (match_operand:<VnSI> 1 \"gcn_alu_operand\" \"  v\"))\n+\t  (match_operand:V_DI 2 \"gcn_alu_operand\"     \"vDA\")))\n+   (clobber (match_scratch:<VnSI> 3\t\t      \"=&v\"))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx out_lo = gcn_operand_part (V64DImode, operands[0], 0);\n-    rtx out_hi = gcn_operand_part (V64DImode, operands[0], 1);\n+    rtx out_lo = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    rtx out_hi = gcn_operand_part (<MODE>mode, operands[0], 1);\n     rtx left = operands[1];\n-    rtx right_lo = gcn_operand_part (V64DImode, operands[2], 0);\n-    rtx right_hi = gcn_operand_part (V64DImode, operands[2], 1);\n+    rtx right_lo = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    rtx right_hi = gcn_operand_part (<MODE>mode, operands[2], 1);\n     rtx tmp = operands[3];\n \n-    emit_insn (gen_mulv64si3 (out_lo, left, right_lo));\n-    emit_insn (gen_umulv64si3_highpart (out_hi, left, right_lo));\n-    emit_insn (gen_mulv64si3 (tmp, left, right_hi));\n-    emit_insn (gen_addv64si3 (out_hi, out_hi, tmp));\n+    emit_insn (gen_mul<vnsi>3 (out_lo, left, right_lo));\n+    emit_insn (gen_umul<vnsi>3_highpart (out_hi, left, right_lo));\n+    emit_insn (gen_mul<vnsi>3 (tmp, left, right_hi));\n+    emit_insn (gen_add<vnsi>3 (out_hi, out_hi, tmp));\n     DONE;\n   })\n \n-(define_insn_and_split \"mulv64di3_zext_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t  \"=&v\")\n-\t(vec_merge:V64DI\n-\t  (mult:V64DI\n-\t    (zero_extend:V64DI\n-\t      (match_operand:V64SI 1 \"gcn_alu_operand\"\t\t  \"  v\"))\n-\t    (match_operand:V64DI 2 \"gcn_alu_operand\"\t\t  \"vDA\"))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\" \" U0\")\n-\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t  \"  e\")))\n-   (clobber (match_scratch:V64SI 5                                \"=&v\"))]\n+(define_insn_and_split \"mul<mode>3_zext_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t \"=&v\")\n+\t(vec_merge:V_DI\n+\t  (mult:V_DI\n+\t    (zero_extend:V_DI\n+\t      (match_operand:<VnSI> 1 \"gcn_alu_operand\"\t\t \"  v\"))\n+\t    (match_operand:V_DI 2 \"gcn_alu_operand\"\t\t \"vDA\"))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\" \" U0\")\n+\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t \"  e\")))\n+   (clobber (match_scratch:<VnSI> 5\t\t\t\t \"=&v\"))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx out_lo = gcn_operand_part (V64DImode, operands[0], 0);\n-    rtx out_hi = gcn_operand_part (V64DImode, operands[0], 1);\n+    rtx out_lo = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    rtx out_hi = gcn_operand_part (<MODE>mode, operands[0], 1);\n     rtx left = operands[1];\n-    rtx right_lo = gcn_operand_part (V64DImode, operands[2], 0);\n-    rtx right_hi = gcn_operand_part (V64DImode, operands[2], 1);\n+    rtx right_lo = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    rtx right_hi = gcn_operand_part (<MODE>mode, operands[2], 1);\n     rtx exec = operands[4];\n     rtx tmp = operands[5];\n \n     rtx old_lo, old_hi;\n     if (GET_CODE (operands[3]) == UNSPEC)\n       {\n-\told_lo = old_hi = gcn_gen_undef (V64SImode);\n+\told_lo = old_hi = gcn_gen_undef (<VnSI>mode);\n       }\n     else\n       {\n-\told_lo = gcn_operand_part (V64DImode, operands[3], 0);\n-\told_hi = gcn_operand_part (V64DImode, operands[3], 1);\n+\told_lo = gcn_operand_part (<MODE>mode, operands[3], 0);\n+\told_hi = gcn_operand_part (<MODE>mode, operands[3], 1);\n       }\n \n-    rtx undef = gcn_gen_undef (V64SImode);\n+    rtx undef = gcn_gen_undef (<VnSI>mode);\n \n-    emit_insn (gen_mulv64si3_exec (out_lo, left, right_lo, old_lo, exec));\n-    emit_insn (gen_umulv64si3_highpart_exec (out_hi, left, right_lo,\n-\t\t\t\t\t     old_hi, exec));\n-    emit_insn (gen_mulv64si3_exec (tmp, left, right_hi, undef, exec));\n-    emit_insn (gen_addv64si3_exec (out_hi, out_hi, tmp, out_hi, exec));\n+    emit_insn (gen_mul<vnsi>3_exec (out_lo, left, right_lo, old_lo, exec));\n+    emit_insn (gen_umul<vnsi>3_highpart_exec (out_hi, left, right_lo,\n+\t\t\t\t\t      old_hi, exec));\n+    emit_insn (gen_mul<vnsi>3_exec (tmp, left, right_hi, undef, exec));\n+    emit_insn (gen_add<vnsi>3_exec (out_hi, out_hi, tmp, out_hi, exec));\n     DONE;\n   })\n \n-(define_insn_and_split \"mulv64di3_zext_dup2\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"    \"= &v\")\n-\t(mult:V64DI\n-\t  (zero_extend:V64DI\n-\t    (match_operand:V64SI 1 \"gcn_alu_operand\" \"   v\"))\n-\t  (vec_duplicate:V64DI\n-\t    (match_operand:DI 2 \"gcn_alu_operand\"    \"SvDA\"))))\n-   (clobber (match_scratch:V64SI 3\t\t     \"= &v\"))]\n+(define_insn_and_split \"mul<mode>3_zext_dup2\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"      \"= &v\")\n+\t(mult:V_DI\n+\t  (zero_extend:V_DI\n+\t    (match_operand:<VnSI> 1 \"gcn_alu_operand\" \"   v\"))\n+\t  (vec_duplicate:V_DI\n+\t    (match_operand:DI 2 \"gcn_alu_operand\"     \"SvDA\"))))\n+   (clobber (match_scratch:<VnSI> 3\t\t      \"= &v\"))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx out_lo = gcn_operand_part (V64DImode, operands[0], 0);\n-    rtx out_hi = gcn_operand_part (V64DImode, operands[0], 1);\n+    rtx out_lo = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    rtx out_hi = gcn_operand_part (<MODE>mode, operands[0], 1);\n     rtx left = operands[1];\n-    rtx right_lo = gcn_operand_part (V64DImode, operands[2], 0);\n-    rtx right_hi = gcn_operand_part (V64DImode, operands[2], 1);\n+    rtx right_lo = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    rtx right_hi = gcn_operand_part (<MODE>mode, operands[2], 1);\n     rtx tmp = operands[3];\n \n-    emit_insn (gen_mulv64si3 (out_lo, left, right_lo));\n-    emit_insn (gen_umulv64si3_highpart (out_hi, left, right_lo));\n-    emit_insn (gen_mulv64si3 (tmp, left, right_hi));\n-    emit_insn (gen_addv64si3 (out_hi, out_hi, tmp));\n+    emit_insn (gen_mul<vnsi>3 (out_lo, left, right_lo));\n+    emit_insn (gen_umul<vnsi>3_highpart (out_hi, left, right_lo));\n+    emit_insn (gen_mul<vnsi>3 (tmp, left, right_hi));\n+    emit_insn (gen_add<vnsi>3 (out_hi, out_hi, tmp));\n     DONE;\n   })\n \n-(define_insn_and_split \"mulv64di3_zext_dup2_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\t  \"= &v\")\n-\t(vec_merge:V64DI\n-\t  (mult:V64DI\n-\t    (zero_extend:V64DI\n-\t      (match_operand:V64SI 1 \"gcn_alu_operand\"\t\t  \"   v\"))\n-\t    (vec_duplicate:V64DI\n-\t      (match_operand:DI 2 \"gcn_alu_operand\"\t\t  \"SvDA\")))\n-\t  (match_operand:V64DI 3 \"gcn_register_or_unspec_operand\" \"  U0\")\n-\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t  \"   e\")))\n-   (clobber (match_scratch:V64SI 5                                \"= &v\"))]\n+(define_insn_and_split \"mul<mode>3_zext_dup2_exec\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"\t\t \"= &v\")\n+\t(vec_merge:V_DI\n+\t  (mult:V_DI\n+\t    (zero_extend:V_DI\n+\t      (match_operand:<VnSI> 1 \"gcn_alu_operand\"\t\t \"   v\"))\n+\t    (vec_duplicate:V_DI\n+\t      (match_operand:DI 2 \"gcn_alu_operand\"\t\t \"SvDA\")))\n+\t  (match_operand:V_DI 3 \"gcn_register_or_unspec_operand\" \"  U0\")\n+\t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t \"   e\")))\n+   (clobber (match_scratch:<VnSI> 5\t\t\t\t \"= &v\"))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx out_lo = gcn_operand_part (V64DImode, operands[0], 0);\n-    rtx out_hi = gcn_operand_part (V64DImode, operands[0], 1);\n+    rtx out_lo = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    rtx out_hi = gcn_operand_part (<MODE>mode, operands[0], 1);\n     rtx left = operands[1];\n-    rtx right_lo = gcn_operand_part (V64DImode, operands[2], 0);\n-    rtx right_hi = gcn_operand_part (V64DImode, operands[2], 1);\n+    rtx right_lo = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    rtx right_hi = gcn_operand_part (<MODE>mode, operands[2], 1);\n     rtx exec = operands[4];\n     rtx tmp = operands[5];\n \n     rtx old_lo, old_hi;\n     if (GET_CODE (operands[3]) == UNSPEC)\n       {\n-\told_lo = old_hi = gcn_gen_undef (V64SImode);\n+\told_lo = old_hi = gcn_gen_undef (<VnSI>mode);\n       }\n     else\n       {\n-\told_lo = gcn_operand_part (V64DImode, operands[3], 0);\n-\told_hi = gcn_operand_part (V64DImode, operands[3], 1);\n+\told_lo = gcn_operand_part (<MODE>mode, operands[3], 0);\n+\told_hi = gcn_operand_part (<MODE>mode, operands[3], 1);\n       }\n \n-    rtx undef = gcn_gen_undef (V64SImode);\n+    rtx undef = gcn_gen_undef (<VnSI>mode);\n \n-    emit_insn (gen_mulv64si3_exec (out_lo, left, right_lo, old_lo, exec));\n-    emit_insn (gen_umulv64si3_highpart_exec (out_hi, left, right_lo,\n-\t\t\t\t\t     old_hi, exec));\n-    emit_insn (gen_mulv64si3_exec (tmp, left, right_hi, undef, exec));\n-    emit_insn (gen_addv64si3_exec (out_hi, out_hi, tmp, out_hi, exec));\n+    emit_insn (gen_mul<vnsi>3_exec (out_lo, left, right_lo, old_lo, exec));\n+    emit_insn (gen_umul<vnsi>3_highpart_exec (out_hi, left, right_lo,\n+\t\t\t\t\t      old_hi, exec));\n+    emit_insn (gen_mul<vnsi>3_exec (tmp, left, right_hi, undef, exec));\n+    emit_insn (gen_add<vnsi>3_exec (out_hi, out_hi, tmp, out_hi, exec));\n     DONE;\n   })\n \n@@ -1904,66 +1937,65 @@\n   [(set_attr \"type\" \"vop2,ds\")\n    (set_attr \"length\" \"8,8\")])\n \n-(define_insn_and_split \"<expander>v64di3\"\n-  [(set (match_operand:V64DI 0 \"gcn_valu_dst_operand\"\t    \"=  v,RD\")\n-\t(bitop:V64DI\n-\t  (match_operand:V64DI 1 \"gcn_valu_src0_operand\"    \"%  v,RD\")\n-\t  (match_operand:V64DI 2 \"gcn_valu_src1com_operand\" \"vSvB, v\")))]\n+(define_insn_and_split \"<expander><mode>3\"\n+  [(set (match_operand:V_DI 0 \"gcn_valu_dst_operand\"\t   \"=  v,RD\")\n+\t(bitop:V_DI\n+\t  (match_operand:V_DI 1 \"gcn_valu_src0_operand\"    \"%  v,RD\")\n+\t  (match_operand:V_DI 2 \"gcn_valu_src1com_operand\" \"vSvB, v\")))]\n   \"\"\n   \"@\n    #\n    ds_<mnemonic>0\\t%A0, %2%O0\"\n-  \"(reload_completed && !gcn_ds_memory_operand (operands[0], V64DImode))\"\n+  \"(reload_completed && !gcn_ds_memory_operand (operands[0], <MODE>mode))\"\n   [(set (match_dup 3)\n-\t(bitop:V64SI (match_dup 5) (match_dup 7)))\n+\t(bitop:<VnSI> (match_dup 5) (match_dup 7)))\n    (set (match_dup 4)\n-\t(bitop:V64SI (match_dup 6) (match_dup 8)))]\n-  {\n-    operands[3] = gcn_operand_part (V64DImode, operands[0], 0);\n-    operands[4] = gcn_operand_part (V64DImode, operands[0], 1);\n-    operands[5] = gcn_operand_part (V64DImode, operands[1], 0);\n-    operands[6] = gcn_operand_part (V64DImode, operands[1], 1);\n-    operands[7] = gcn_operand_part (V64DImode, operands[2], 0);\n-    operands[8] = gcn_operand_part (V64DImode, operands[2], 1);\n+\t(bitop:<VnSI> (match_dup 6) (match_dup 8)))]\n+  {\n+    operands[3] = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    operands[4] = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    operands[5] = gcn_operand_part (<MODE>mode, operands[1], 0);\n+    operands[6] = gcn_operand_part (<MODE>mode, operands[1], 1);\n+    operands[7] = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    operands[8] = gcn_operand_part (<MODE>mode, operands[2], 1);\n   }\n   [(set_attr \"type\" \"vmult,ds\")\n    (set_attr \"length\" \"16,8\")])\n \n-(define_insn_and_split \"<expander>v64di3_exec\"\n-  [(set (match_operand:V64DI 0 \"gcn_valu_dst_operand\"\t\t  \"=  v,RD\")\n-\t(vec_merge:V64DI\n-\t  (bitop:V64DI\n-\t    (match_operand:V64DI 1 \"gcn_valu_src0_operand\"\t  \"%  v,RD\")\n-\t    (match_operand:V64DI 2 \"gcn_valu_src1com_operand\"\t  \"vSvB, v\"))\n-\t  (match_operand:V64DI 3 \"gcn_register_ds_or_unspec_operand\"\n-\t\t\t\t\t\t\t\t  \"  U0,U0\")\n+(define_insn_and_split \"<expander><mode>3_exec\"\n+  [(set (match_operand:V_DI 0 \"gcn_valu_dst_operand\"\t\t  \"=  v,RD\")\n+\t(vec_merge:V_DI\n+\t  (bitop:V_DI\n+\t    (match_operand:V_DI 1 \"gcn_valu_src0_operand\"\t  \"%  v,RD\")\n+\t    (match_operand:V_DI 2 \"gcn_valu_src1com_operand\"\t  \"vSvB, v\"))\n+\t  (match_operand:V_DI 3 \"gcn_register_ds_or_unspec_operand\" \"U0,U0\")\n \t  (match_operand:DI 4 \"gcn_exec_reg_operand\"\t\t  \"   e, e\")))]\n   \"!memory_operand (operands[0], VOIDmode)\n    || (rtx_equal_p (operands[0], operands[1])\n        && register_operand (operands[2], VOIDmode))\"\n   \"@\n    #\n    ds_<mnemonic>0\\t%A0, %2%O0\"\n-  \"(reload_completed && !gcn_ds_memory_operand (operands[0], V64DImode))\"\n+  \"(reload_completed && !gcn_ds_memory_operand (operands[0], <MODE>mode))\"\n   [(set (match_dup 5)\n-\t(vec_merge:V64SI\n-\t  (bitop:V64SI (match_dup 7) (match_dup 9))\n+\t(vec_merge:<VnSI>\n+\t  (bitop:<VnSI> (match_dup 7) (match_dup 9))\n \t  (match_dup 11)\n \t  (match_dup 4)))\n    (set (match_dup 6)\n-\t(vec_merge:V64SI\n-\t  (bitop:V64SI (match_dup 8) (match_dup 10))\n+\t(vec_merge:<VnSI>\n+\t  (bitop:<VnSI> (match_dup 8) (match_dup 10))\n \t  (match_dup 12)\n \t  (match_dup 4)))]\n   {\n-    operands[5] = gcn_operand_part (V64DImode, operands[0], 0);\n-    operands[6] = gcn_operand_part (V64DImode, operands[0], 1);\n-    operands[7] = gcn_operand_part (V64DImode, operands[1], 0);\n-    operands[8] = gcn_operand_part (V64DImode, operands[1], 1);\n-    operands[9] = gcn_operand_part (V64DImode, operands[2], 0);\n-    operands[10] = gcn_operand_part (V64DImode, operands[2], 1);\n-    operands[11] = gcn_operand_part (V64DImode, operands[3], 0);\n-    operands[12] = gcn_operand_part (V64DImode, operands[3], 1);\n+    operands[5] = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    operands[6] = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    operands[7] = gcn_operand_part (<MODE>mode, operands[1], 0);\n+    operands[8] = gcn_operand_part (<MODE>mode, operands[1], 1);\n+    operands[9] = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    operands[10] = gcn_operand_part (<MODE>mode, operands[2], 1);\n+    operands[11] = gcn_operand_part (<MODE>mode, operands[3], 0);\n+    operands[12] = gcn_operand_part (<MODE>mode, operands[3], 1);\n   }\n   [(set_attr \"type\" \"vmult,ds\")\n    (set_attr \"length\" \"16,8\")])\n@@ -1978,22 +2010,22 @@\n   {\n     enum {ashift, lshiftrt, ashiftrt};\n     bool unsignedp = (<code> == lshiftrt);\n-    rtx insi1 = gen_reg_rtx (V64SImode);\n+    rtx insi1 = gen_reg_rtx (<VnSI>mode);\n     rtx insi2 = gen_reg_rtx (SImode);\n-    rtx outsi = gen_reg_rtx (V64SImode);\n+    rtx outsi = gen_reg_rtx (<VnSI>mode);\n \n     convert_move (insi1, operands[1], unsignedp);\n     convert_move (insi2, operands[2], unsignedp);\n-    emit_insn (gen_<expander>v64si3 (outsi, insi1, insi2));\n+    emit_insn (gen_<expander><vnsi>3 (outsi, insi1, insi2));\n     convert_move (operands[0], outsi, unsignedp);\n     DONE;\n   })\n \n-(define_insn \"<expander>v64si3<exec>\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"  \"= v\")\n-\t(shiftop:V64SI\n-\t  (match_operand:V64SI 1 \"gcn_alu_operand\" \"  v\")\n-\t  (vec_duplicate:V64SI\n+(define_insn \"<expander><mode>3<exec>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"  \"= v\")\n+\t(shiftop:V_SI\n+\t  (match_operand:V_SI 1 \"gcn_alu_operand\" \"  v\")\n+\t  (vec_duplicate:V_SI\n \t    (match_operand:SI 2 \"gcn_alu_operand\"  \"SvB\"))))]\n   \"\"\n   \"v_<revmnemonic>0\\t%0, %2, %1\"\n@@ -2009,22 +2041,22 @@\n   {\n     enum {ashift, lshiftrt, ashiftrt};\n     bool unsignedp = (<code> == ashift || <code> == ashiftrt);\n-    rtx insi1 = gen_reg_rtx (V64SImode);\n-    rtx insi2 = gen_reg_rtx (V64SImode);\n-    rtx outsi = gen_reg_rtx (V64SImode);\n+    rtx insi1 = gen_reg_rtx (<VnSI>mode);\n+    rtx insi2 = gen_reg_rtx (<VnSI>mode);\n+    rtx outsi = gen_reg_rtx (<VnSI>mode);\n \n     convert_move (insi1, operands[1], unsignedp);\n     convert_move (insi2, operands[2], unsignedp);\n-    emit_insn (gen_v<expander>v64si3 (outsi, insi1, insi2));\n+    emit_insn (gen_v<expander><vnsi>3 (outsi, insi1, insi2));\n     convert_move (operands[0], outsi, unsignedp);\n     DONE;\n   })\n \n-(define_insn \"v<expander>v64si3<exec>\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"  \"=v\")\n-\t(shiftop:V64SI\n-\t  (match_operand:V64SI 1 \"gcn_alu_operand\" \" v\")\n-\t  (match_operand:V64SI 2 \"gcn_alu_operand\" \"vB\")))]\n+(define_insn \"v<expander><mode>3<exec>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"  \"=v\")\n+\t(shiftop:V_SI\n+\t  (match_operand:V_SI 1 \"gcn_alu_operand\" \" v\")\n+\t  (match_operand:V_SI 2 \"gcn_alu_operand\" \"vB\")))]\n   \"\"\n   \"v_<revmnemonic>0\\t%0, %2, %1\"\n   [(set_attr \"type\" \"vop2\")\n@@ -2039,22 +2071,22 @@\n   {\n     enum {smin, umin, smax, umax};\n     bool unsignedp = (<code> == umax || <code> == umin);\n-    rtx insi1 = gen_reg_rtx (V64SImode);\n-    rtx insi2 = gen_reg_rtx (V64SImode);\n-    rtx outsi = gen_reg_rtx (V64SImode);\n+    rtx insi1 = gen_reg_rtx (<VnSI>mode);\n+    rtx insi2 = gen_reg_rtx (<VnSI>mode);\n+    rtx outsi = gen_reg_rtx (<VnSI>mode);\n \n     convert_move (insi1, operands[1], unsignedp);\n     convert_move (insi2, operands[2], unsignedp);\n-    emit_insn (gen_<code>v64si3 (outsi, insi1, insi2));\n+    emit_insn (gen_<code><vnsi>3 (outsi, insi1, insi2));\n     convert_move (operands[0], outsi, unsignedp);\n     DONE;\n   })\n \n-(define_insn \"<expander>v64si3<exec>\"\n-  [(set (match_operand:V64SI 0 \"gcn_valu_dst_operand\"\t    \"=  v,RD\")\n-\t(minmaxop:V64SI\n-\t  (match_operand:V64SI 1 \"gcn_valu_src0_operand\"    \"%  v, 0\")\n-\t  (match_operand:V64SI 2 \"gcn_valu_src1com_operand\" \"vSvB, v\")))]\n+(define_insn \"<expander><vnsi>3<exec>\"\n+  [(set (match_operand:V_SI 0 \"gcn_valu_dst_operand\"\t   \"=  v,RD\")\n+\t(minmaxop:V_SI\n+\t  (match_operand:V_SI 1 \"gcn_valu_src0_operand\"    \"%  v, 0\")\n+\t  (match_operand:V_SI 2 \"gcn_valu_src1com_operand\" \"vSvB, v\")))]\n   \"\"\n   \"@\n    v_<mnemonic>0\\t%0, %2, %1\n@@ -2068,11 +2100,11 @@\n ; GCN does not directly provide a DFmode subtract instruction, so we do it by\n ; adding the negated second operand to the first.\n \n-(define_insn \"subv64df3<exec>\"\n-  [(set (match_operand:V64DF 0 \"register_operand\"  \"=  v,   v\")\n-\t(minus:V64DF\n-\t  (match_operand:V64DF 1 \"gcn_alu_operand\" \"vSvB,   v\")\n-\t  (match_operand:V64DF 2 \"gcn_alu_operand\" \"   v,vSvB\")))]\n+(define_insn \"sub<mode>3<exec>\"\n+  [(set (match_operand:V_DF 0 \"register_operand\"  \"=  v,   v\")\n+\t(minus:V_DF\n+\t  (match_operand:V_DF 1 \"gcn_alu_operand\" \"vSvB,   v\")\n+\t  (match_operand:V_DF 2 \"gcn_alu_operand\" \"   v,vSvB\")))]\n   \"\"\n   \"@\n    v_add_f64\\t%0, %1, -%2\n@@ -2415,31 +2447,31 @@\n ;; Unfortunately you can't just do SUBREG on a vector to select the low part,\n ;; so there must be a few tricks here.\n \n-(define_insn_and_split \"truncv64di<mode>2\"\n+(define_insn_and_split \"trunc<vndi><mode>2\"\n   [(set (match_operand:V_INT_1REG 0 \"register_operand\" \"=v\")\n \t(truncate:V_INT_1REG\n-\t  (match_operand:V64DI 1 \"gcn_alu_operand\"     \" v\")))]\n+\t  (match_operand:<VnDI> 1 \"gcn_alu_operand\"     \" v\")))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx inlo = gcn_operand_part (V64DImode, operands[1], 0);\n+    rtx inlo = gcn_operand_part (<VnDI>mode, operands[1], 0);\n     rtx out = operands[0];\n \n-    if (<MODE>mode != V64SImode)\n-      emit_insn (gen_truncv64si<mode>2 (out, inlo));\n+    if (<MODE>mode != <VnSI>mode)\n+      emit_insn (gen_trunc<vnsi><mode>2 (out, inlo));\n     else\n       emit_move_insn (out, inlo);\n   }\n   [(set_attr \"type\" \"vop2\")\n    (set_attr \"length\" \"4\")])\n \n-(define_insn_and_split \"truncv64di<mode>2_exec\"\n+(define_insn_and_split \"trunc<vndi><mode>2_exec\"\n   [(set (match_operand:V_INT_1REG 0 \"register_operand\"\t\t  \"=v\")\n \t(vec_merge:V_INT_1REG\n \t  (truncate:V_INT_1REG\n-\t    (match_operand:V64DI 1 \"gcn_alu_operand\"\t\t  \" v\"))\n+\t    (match_operand:<VnDI> 1 \"gcn_alu_operand\"\t\t  \" v\"))\n \t  (match_operand:V_INT_1REG 2 \"gcn_alu_or_unspec_operand\" \"U0\")\n \t  (match_operand:DI 3 \"gcn_exec_operand\"\t\t  \" e\")))]\n   \"\"\n@@ -2448,72 +2480,72 @@\n   [(const_int 0)]\n   {\n     rtx out = operands[0];\n-    rtx inlo = gcn_operand_part (V64DImode, operands[1], 0);\n+    rtx inlo = gcn_operand_part (<VnDI>mode, operands[1], 0);\n     rtx merge = operands[2];\n     rtx exec = operands[3];\n \n-    if (<MODE>mode != V64SImode)\n-      emit_insn (gen_truncv64si<mode>2_exec (out, inlo, merge, exec));\n+    if (<MODE>mode != <VnSI>mode)\n+      emit_insn (gen_trunc<vnsi><mode>2_exec (out, inlo, merge, exec));\n     else\n       emit_insn (gen_mov<mode>_exec (out, inlo, exec, merge));\n   }\n   [(set_attr \"type\" \"vop2\")\n    (set_attr \"length\" \"4\")])\n \n-(define_insn_and_split \"<convop><mode>v64di2\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t\"=v\")\n-\t(any_extend:V64DI\n+(define_insn_and_split \"<convop><mode><vndi>2\"\n+  [(set (match_operand:<VnDI> 0 \"register_operand\"\t\"=v\")\n+\t(any_extend:<VnDI>\n \t  (match_operand:V_INT_1REG 1 \"gcn_alu_operand\" \" v\")))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx outlo = gcn_operand_part (V64DImode, operands[0], 0);\n-    rtx outhi = gcn_operand_part (V64DImode, operands[0], 1);\n+    rtx outlo = gcn_operand_part (<VnDI>mode, operands[0], 0);\n+    rtx outhi = gcn_operand_part (<VnDI>mode, operands[0], 1);\n     rtx in = operands[1];\n       \n-    if (<MODE>mode != V64SImode)\n-      emit_insn (gen_<convop><mode>v64si2 (outlo, in));\n+    if (<MODE>mode != <VnSI>mode)\n+      emit_insn (gen_<convop><mode><vnsi>2 (outlo, in));\n     else\n       emit_move_insn (outlo, in);\n     if ('<su>' == 's')\n-      emit_insn (gen_ashrv64si3 (outhi, outlo, GEN_INT (31)));\n+      emit_insn (gen_ashr<vnsi>3 (outhi, outlo, GEN_INT (31)));\n     else\n-      emit_insn (gen_vec_duplicatev64si (outhi, const0_rtx));\n+      emit_insn (gen_vec_duplicate<vnsi> (outhi, const0_rtx));\n   }\n   [(set_attr \"type\" \"mult\")\n    (set_attr \"length\" \"12\")])\n \n-(define_insn_and_split \"<convop><mode>v64di2_exec\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"\t     \"=v\")\n-\t(vec_merge:V64DI\n-\t  (any_extend:V64DI\n+(define_insn_and_split \"<convop><mode><vndi>2_exec\"\n+  [(set (match_operand:<VnDI> 0 \"register_operand\"\t     \"=v\")\n+\t(vec_merge:<VnDI>\n+\t  (any_extend:<VnDI>\n \t    (match_operand:V_INT_1REG 1 \"gcn_alu_operand\"    \" v\"))\n-\t  (match_operand:V64DI 2 \"gcn_alu_or_unspec_operand\" \"U0\")\n+\t  (match_operand:<VnDI> 2 \"gcn_alu_or_unspec_operand\" \"U0\")\n \t  (match_operand:DI 3 \"gcn_exec_operand\"\t     \" e\")))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(const_int 0)]\n   {\n-    rtx outlo = gcn_operand_part (V64DImode, operands[0], 0);\n-    rtx outhi = gcn_operand_part (V64DImode, operands[0], 1);\n+    rtx outlo = gcn_operand_part (<VnDI>mode, operands[0], 0);\n+    rtx outhi = gcn_operand_part (<VnDI>mode, operands[0], 1);\n     rtx in = operands[1];\n-    rtx mergelo = gcn_operand_part (V64DImode, operands[2], 0);\n-    rtx mergehi = gcn_operand_part (V64DImode, operands[2], 1);\n+    rtx mergelo = gcn_operand_part (<VnDI>mode, operands[2], 0);\n+    rtx mergehi = gcn_operand_part (<VnDI>mode, operands[2], 1);\n     rtx exec = operands[3];\n       \n-    if (<MODE>mode != V64SImode)\n-      emit_insn (gen_<convop><mode>v64si2_exec (outlo, in, mergelo, exec));\n+    if (<MODE>mode != <VnSI>mode)\n+      emit_insn (gen_<convop><mode><vnsi>2_exec (outlo, in, mergelo, exec));\n     else\n       emit_insn (gen_mov<mode>_exec (outlo, in, exec, mergelo));\n     if ('<su>' == 's')\n-      emit_insn (gen_ashrv64si3_exec (outhi, outlo, GEN_INT (31), mergehi,\n-\t\t\t\t      exec));\n+      emit_insn (gen_ashr<vnsi>3_exec (outhi, outlo, GEN_INT (31), mergehi,\n+\t\t\t\t       exec));\n     else\n-      emit_insn (gen_vec_duplicatev64si_exec (outhi, const0_rtx, mergehi,\n-\t\t\t\t\t      exec));\n+      emit_insn (gen_vec_duplicate<vnsi>_exec (outhi, const0_rtx, mergehi,\n+\t\t\t\t\t       exec));\n   }\n   [(set_attr \"type\" \"mult\")\n    (set_attr \"length\" \"12\")])\n@@ -2554,19 +2586,19 @@\n   })\n \n ; There's no instruction for 8-bit vector comparison, so we need to extend.\n-(define_expand \"vec_cmp<u>v64qidi\"\n+(define_expand \"vec_cmp<u><mode>di\"\n   [(match_operand:DI 0 \"register_operand\")\n    (match_operator 1 \"gcn_compare_operator\"\n-     [(any_extend:V64SI (match_operand:V64QI 2 \"gcn_alu_operand\"))\n-      (any_extend:V64SI (match_operand:V64QI 3 \"gcn_vop3_operand\"))])]\n+     [(any_extend:<VnSI> (match_operand:V_QI 2 \"gcn_alu_operand\"))\n+      (any_extend:<VnSI> (match_operand:V_QI 3 \"gcn_vop3_operand\"))])]\n   \"can_create_pseudo_p ()\"\n   {\n-    rtx sitmp1 = gen_reg_rtx (V64SImode);\n-    rtx sitmp2 = gen_reg_rtx (V64SImode);\n+    rtx sitmp1 = gen_reg_rtx (<VnSI>mode);\n+    rtx sitmp2 = gen_reg_rtx (<VnSI>mode);\n \n-    emit_insn (gen_<expander>v64qiv64si2 (sitmp1, operands[2]));\n-    emit_insn (gen_<expander>v64qiv64si2 (sitmp2, operands[3]));\n-    emit_insn (gen_vec_cmpv64sidi (operands[0], operands[1], sitmp1, sitmp2));\n+    emit_insn (gen_<expander><mode><vnsi>2 (sitmp1, operands[2]));\n+    emit_insn (gen_<expander><mode><vnsi>2 (sitmp2, operands[3]));\n+    emit_insn (gen_vec_cmp<vnsi>di (operands[0], operands[1], sitmp1, sitmp2));\n     DONE;\n   })\n \n@@ -2606,23 +2638,23 @@\n     DONE;\n   })\n \n-(define_expand \"vec_cmp<u>v64qidi_exec\"\n+(define_expand \"vec_cmp<u><mode>di_exec\"\n   [(match_operand:DI 0 \"register_operand\")\n    (match_operator 1 \"gcn_compare_operator\"\n-     [(any_extend:V64SI (match_operand:V64QI 2 \"gcn_alu_operand\"))\n-      (any_extend:V64SI (match_operand:V64QI 3 \"gcn_vop3_operand\"))])\n+     [(any_extend:<VnSI> (match_operand:V_QI 2 \"gcn_alu_operand\"))\n+      (any_extend:<VnSI> (match_operand:V_QI 3 \"gcn_vop3_operand\"))])\n    (match_operand:DI 4 \"gcn_exec_reg_operand\")]\n   \"can_create_pseudo_p ()\"\n   {\n-    rtx sitmp1 = gen_reg_rtx (V64SImode);\n-    rtx sitmp2 = gen_reg_rtx (V64SImode);\n+    rtx sitmp1 = gen_reg_rtx (<VnSI>mode);\n+    rtx sitmp2 = gen_reg_rtx (<VnSI>mode);\n \n-    emit_insn (gen_<expander>v64qiv64si2_exec (sitmp1, operands[2],\n-\t\t\t\t\t       operands[2], operands[4]));\n-    emit_insn (gen_<expander>v64qiv64si2_exec (sitmp2, operands[3],\n-\t\t\t\t\t       operands[3], operands[4]));\n-    emit_insn (gen_vec_cmpv64sidi_exec (operands[0], operands[1], sitmp1,\n-\t\t\t\t\tsitmp2, operands[4]));\n+    emit_insn (gen_<expander><mode><vnsi>2_exec (sitmp1, operands[2],\n+\t\t\t\t\t\t operands[2], operands[4]));\n+    emit_insn (gen_<expander><mode><vnsi>2_exec (sitmp2, operands[3],\n+\t\t\t\t\t\t operands[3], operands[4]));\n+    emit_insn (gen_vec_cmp<vnsi>di_exec (operands[0], operands[1], sitmp1,\n+\t\t\t\t\t sitmp2, operands[4]));\n     DONE;\n   })\n \n@@ -2671,7 +2703,7 @@\n \t    (match_operand:V_ALL 1 \"gcn_vop3_operand\" \"\")\n \t    (match_operand:V_ALL 2 \"gcn_alu_operand\" \"\")\n \t    (match_operand:DI 3\t\t     \"register_operand\" \"\")))\n-     (clobber (scratch:V64DI))])]\n+     (clobber (scratch:<VnDI>))])]\n   \"\"\n   \"\")\n \n@@ -2787,7 +2819,7 @@\n   {\n     rtx exec = force_reg (DImode, operands[2]);\n     rtx addr = gcn_expand_scalar_to_vector_address\n-\t\t(<MODE>mode, exec, operands[1], gen_rtx_SCRATCH (V64DImode));\n+\t\t(<MODE>mode, exec, operands[1], gen_rtx_SCRATCH (<VnDI>mode));\n     rtx as = gen_rtx_CONST_INT (VOIDmode, MEM_ADDR_SPACE (operands[1]));\n     rtx v = gen_rtx_CONST_INT (VOIDmode, MEM_VOLATILE_P (operands[1]));\n \n@@ -2807,17 +2839,17 @@\n   {\n     rtx exec = force_reg (DImode, operands[2]);\n     rtx addr = gcn_expand_scalar_to_vector_address\n-\t\t(<MODE>mode, exec, operands[0], gen_rtx_SCRATCH (V64DImode));\n+\t\t(<MODE>mode, exec, operands[0], gen_rtx_SCRATCH (<VnDI>mode));\n     rtx as = gen_rtx_CONST_INT (VOIDmode, MEM_ADDR_SPACE (operands[0]));\n     rtx v = gen_rtx_CONST_INT (VOIDmode, MEM_VOLATILE_P (operands[0]));\n     emit_insn (gen_scatter<mode>_expr_exec (addr, operands[1], as, v, exec));\n     DONE;\n   })\n \n-(define_expand \"mask_gather_load<mode>v64si\"\n+(define_expand \"mask_gather_load<mode><vnsi>\"\n   [(match_operand:V_ALL 0 \"register_operand\")\n    (match_operand:DI 1 \"register_operand\")\n-   (match_operand:V64SI 2 \"register_operand\")\n+   (match_operand:<VnSI> 2 \"register_operand\")\n    (match_operand 3 \"immediate_operand\")\n    (match_operand:SI 4 \"gcn_alu_operand\")\n    (match_operand:DI 5 \"\")]\n@@ -2832,7 +2864,7 @@\n     /* Masked lanes are required to hold zero.  */\n     emit_move_insn (operands[0], gcn_vec_constant (<MODE>mode, 0));\n \n-    if (GET_MODE (addr) == V64DImode)\n+    if (GET_MODE (addr) == <VnDI>mode)\n       emit_insn (gen_gather<mode>_insn_1offset_exec (operands[0], addr,\n \t\t\t\t\t\t     const0_rtx, const0_rtx,\n \t\t\t\t\t\t     const0_rtx, operands[0],\n@@ -2845,9 +2877,9 @@\n     DONE;\n   })\n \n-(define_expand \"mask_scatter_store<mode>v64si\"\n+(define_expand \"mask_scatter_store<mode><vnsi>\"\n   [(match_operand:DI 0 \"register_operand\")\n-   (match_operand:V64SI 1 \"register_operand\")\n+   (match_operand:<VnSI> 1 \"register_operand\")\n    (match_operand 2 \"immediate_operand\")\n    (match_operand:SI 3 \"gcn_alu_operand\")\n    (match_operand:V_ALL 4 \"register_operand\")\n@@ -2860,7 +2892,7 @@\n \t\t\t\t\t  operands[1], operands[3],\n \t\t\t\t\t  INTVAL (operands[2]), exec);\n \n-    if (GET_MODE (addr) == V64DImode)\n+    if (GET_MODE (addr) == <VnDI>mode)\n       emit_insn (gen_scatter<mode>_insn_1offset_exec (addr, const0_rtx,\n \t\t\t\t\t\t      operands[4], const0_rtx,\n \t\t\t\t\t\t      const0_rtx,\n@@ -2989,29 +3021,29 @@\n   [(set_attr \"type\" \"vop_dpp\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"*<reduc_op>_dpp_shr_v64di\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"   \"=v\")\n-\t(unspec:V64DI\n-\t  [(match_operand:V64DI 1 \"register_operand\" \"v\")\n-\t   (match_operand:V64DI 2 \"register_operand\" \"v\")\n-\t   (match_operand:SI 3 \"const_int_operand\"   \"n\")]\n+(define_insn_and_split \"*<reduc_op>_dpp_shr_<mode>\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"    \"=v\")\n+\t(unspec:V_DI\n+\t  [(match_operand:V_DI 1 \"register_operand\" \"v\")\n+\t   (match_operand:V_DI 2 \"register_operand\" \"v\")\n+\t   (match_operand:SI 3 \"const_int_operand\"  \"n\")]\n \t  REDUC_2REG_UNSPEC))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(set (match_dup 4)\n-\t(unspec:V64SI\n+\t(unspec:<VnSI>\n \t  [(match_dup 6) (match_dup 8) (match_dup 3)] REDUC_2REG_UNSPEC))\n    (set (match_dup 5)\n-\t(unspec:V64SI\n+\t(unspec:<VnSI>\n \t  [(match_dup 7) (match_dup 9) (match_dup 3)] REDUC_2REG_UNSPEC))]\n   {\n-    operands[4] = gcn_operand_part (V64DImode, operands[0], 0);\n-    operands[5] = gcn_operand_part (V64DImode, operands[0], 1);\n-    operands[6] = gcn_operand_part (V64DImode, operands[1], 0);\n-    operands[7] = gcn_operand_part (V64DImode, operands[1], 1);\n-    operands[8] = gcn_operand_part (V64DImode, operands[2], 0);\n-    operands[9] = gcn_operand_part (V64DImode, operands[2], 1);\n+    operands[4] = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    operands[5] = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    operands[6] = gcn_operand_part (<MODE>mode, operands[1], 0);\n+    operands[7] = gcn_operand_part (<MODE>mode, operands[1], 1);\n+    operands[8] = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    operands[9] = gcn_operand_part (<MODE>mode, operands[2], 1);\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"16\")])\n@@ -3028,59 +3060,59 @@\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   {\n-    return gcn_expand_dpp_shr_insn (V64SImode, \"v_add%^_u32\",\n+    return gcn_expand_dpp_shr_insn (<VnSI>mode, \"v_add%^_u32\",\n \t\t\t\t    UNSPEC_PLUS_CARRY_DPP_SHR,\n \t\t\t\t    INTVAL (operands[3]));\n   }\n   [(set_attr \"type\" \"vop_dpp\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn \"*plus_carry_in_dpp_shr_v64si\"\n-  [(set (match_operand:V64SI 0 \"register_operand\"   \"=v\")\n-\t(unspec:V64SI\n-\t  [(match_operand:V64SI 1 \"register_operand\" \"v\")\n-\t   (match_operand:V64SI 2 \"register_operand\" \"v\")\n-\t   (match_operand:SI 3 \"const_int_operand\"   \"n\")\n+(define_insn \"*plus_carry_in_dpp_shr_<mode>\"\n+  [(set (match_operand:V_SI 0 \"register_operand\"    \"=v\")\n+\t(unspec:V_SI\n+\t  [(match_operand:V_SI 1 \"register_operand\" \"v\")\n+\t   (match_operand:V_SI 2 \"register_operand\" \"v\")\n+\t   (match_operand:SI 3 \"const_int_operand\"  \"n\")\n \t   (match_operand:DI 4 \"register_operand\"   \"cV\")]\n \t  UNSPEC_PLUS_CARRY_IN_DPP_SHR))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   {\n-    return gcn_expand_dpp_shr_insn (V64SImode, \"v_addc%^_u32\",\n+    return gcn_expand_dpp_shr_insn (<MODE>mode, \"v_addc%^_u32\",\n \t\t\t\t    UNSPEC_PLUS_CARRY_IN_DPP_SHR,\n \t\t\t\t    INTVAL (operands[3]));\n   }\n   [(set_attr \"type\" \"vop_dpp\")\n    (set_attr \"length\" \"8\")])\n \n-(define_insn_and_split \"*plus_carry_dpp_shr_v64di\"\n-  [(set (match_operand:V64DI 0 \"register_operand\"   \"=v\")\n-\t(unspec:V64DI\n-\t  [(match_operand:V64DI 1 \"register_operand\" \"v\")\n-\t   (match_operand:V64DI 2 \"register_operand\" \"v\")\n-\t   (match_operand:SI 3 \"const_int_operand\"   \"n\")]\n+(define_insn_and_split \"*plus_carry_dpp_shr_<mode>\"\n+  [(set (match_operand:V_DI 0 \"register_operand\"    \"=v\")\n+\t(unspec:V_DI\n+\t  [(match_operand:V_DI 1 \"register_operand\" \"v\")\n+\t   (match_operand:V_DI 2 \"register_operand\" \"v\")\n+\t   (match_operand:SI 3 \"const_int_operand\"  \"n\")]\n \t  UNSPEC_PLUS_CARRY_DPP_SHR))\n    (clobber (reg:DI VCC_REG))]\n   \"\"\n   \"#\"\n   \"reload_completed\"\n   [(parallel [(set (match_dup 4)\n-\t\t(unspec:V64SI\n+\t\t(unspec:<VnSI>\n \t\t  [(match_dup 6) (match_dup 8) (match_dup 3)]\n \t\t  UNSPEC_PLUS_CARRY_DPP_SHR))\n \t      (clobber (reg:DI VCC_REG))])\n    (parallel [(set (match_dup 5)\n-\t\t(unspec:V64SI\n+\t\t(unspec:<VnSI>\n \t\t  [(match_dup 7) (match_dup 9) (match_dup 3) (reg:DI VCC_REG)]\n \t\t  UNSPEC_PLUS_CARRY_IN_DPP_SHR))\n \t      (clobber (reg:DI VCC_REG))])]\n   {\n-    operands[4] = gcn_operand_part (V64DImode, operands[0], 0);\n-    operands[5] = gcn_operand_part (V64DImode, operands[0], 1);\n-    operands[6] = gcn_operand_part (V64DImode, operands[1], 0);\n-    operands[7] = gcn_operand_part (V64DImode, operands[1], 1);\n-    operands[8] = gcn_operand_part (V64DImode, operands[2], 0);\n-    operands[9] = gcn_operand_part (V64DImode, operands[2], 1);\n+    operands[4] = gcn_operand_part (<MODE>mode, operands[0], 0);\n+    operands[5] = gcn_operand_part (<MODE>mode, operands[0], 1);\n+    operands[6] = gcn_operand_part (<MODE>mode, operands[1], 0);\n+    operands[7] = gcn_operand_part (<MODE>mode, operands[1], 1);\n+    operands[8] = gcn_operand_part (<MODE>mode, operands[2], 0);\n+    operands[9] = gcn_operand_part (<MODE>mode, operands[2], 1);\n   }\n   [(set_attr \"type\" \"vmult\")\n    (set_attr \"length\" \"16\")])\n@@ -3120,33 +3152,33 @@\n ;; }}}\n ;; {{{ Miscellaneous\n \n-(define_expand \"vec_seriesv64si\"\n-  [(match_operand:V64SI 0 \"register_operand\")\n+(define_expand \"vec_series<mode>\"\n+  [(match_operand:V_SI 0 \"register_operand\")\n    (match_operand:SI 1 \"gcn_alu_operand\")\n    (match_operand:SI 2 \"gcn_alu_operand\")]\n   \"\"\n   {\n-    rtx tmp = gen_reg_rtx (V64SImode);\n-    rtx v1 = gen_rtx_REG (V64SImode, VGPR_REGNO (1));\n+    rtx tmp = gen_reg_rtx (<MODE>mode);\n+    rtx v1 = gen_rtx_REG (<MODE>mode, VGPR_REGNO (1));\n \n-    emit_insn (gen_mulv64si3_dup (tmp, v1, operands[2]));\n-    emit_insn (gen_addv64si3_dup (operands[0], tmp, operands[1]));\n+    emit_insn (gen_mul<mode>3_dup (tmp, v1, operands[2]));\n+    emit_insn (gen_add<mode>3_dup (operands[0], tmp, operands[1]));\n     DONE;\n   })\n \n-(define_expand \"vec_seriesv64di\"\n-  [(match_operand:V64DI 0 \"register_operand\")\n+(define_expand \"vec_series<mode>\"\n+  [(match_operand:V_DI 0 \"register_operand\")\n    (match_operand:DI 1 \"gcn_alu_operand\")\n    (match_operand:DI 2 \"gcn_alu_operand\")]\n   \"\"\n   {\n-    rtx tmp = gen_reg_rtx (V64DImode);\n-    rtx v1 = gen_rtx_REG (V64SImode, VGPR_REGNO (1));\n-    rtx op1vec = gen_reg_rtx (V64DImode);\n+    rtx tmp = gen_reg_rtx (<MODE>mode);\n+    rtx v1 = gen_rtx_REG (<VnSI>mode, VGPR_REGNO (1));\n+    rtx op1vec = gen_reg_rtx (<MODE>mode);\n \n-    emit_insn (gen_mulv64di3_zext_dup2 (tmp, v1, operands[2]));\n-    emit_insn (gen_vec_duplicatev64di (op1vec, operands[1]));\n-    emit_insn (gen_addv64di3 (operands[0], tmp, op1vec));\n+    emit_insn (gen_mul<mode>3_zext_dup2 (tmp, v1, operands[2]));\n+    emit_insn (gen_vec_duplicate<mode> (op1vec, operands[1]));\n+    emit_insn (gen_add<mode>3 (operands[0], tmp, op1vec));\n     DONE;\n   })\n "}]}