{"sha": "997070498b0d713ecfb384dc12d1e68ebdbee5bd", "node_id": "C_kwDOANBUbNoAKDk5NzA3MDQ5OGIwZDcxM2VjZmIzODRkYzEyZDFlNjhlYmRiZWU1YmQ", "commit": {"author": {"name": "Richard Earnshaw", "email": "rearnsha@arm.com", "date": "2022-01-14T11:38:33Z"}, "committer": {"name": "Richard Earnshaw", "email": "rearnsha@arm.com", "date": "2022-01-20T11:15:26Z"}, "message": "arm: elide some cases where the AES erratum workaround is not required.\n\nSome common cases where the AES erratum workaround are not required\nare when there are 64- or 128-bit loads from memory, moving a 128-bit\nvalue from core registers, and where a 128-bit constant is being\nloaded from a literal pool.  The loads may also be misaligned or\ngenerated via a neon intrinsic function.\n\ngcc/ChangeLog:\n\n\t* config/arm/crypto.md (aes_op_protect): Allow moves from core\n\tregisters and from memory.\n\t(aes_op_protect_misalign_load): New pattern.\n\t(aes_op_protect_neon_vld1v16qi): New pattern.", "tree": {"sha": "6f9cf4eab5d369e327645258120f2e6116946a93", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6f9cf4eab5d369e327645258120f2e6116946a93"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/997070498b0d713ecfb384dc12d1e68ebdbee5bd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/997070498b0d713ecfb384dc12d1e68ebdbee5bd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/997070498b0d713ecfb384dc12d1e68ebdbee5bd", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/997070498b0d713ecfb384dc12d1e68ebdbee5bd/comments", "author": null, "committer": null, "parents": [{"sha": "2078550a005f3fde4c331ad4b8452c963c4cdb9d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2078550a005f3fde4c331ad4b8452c963c4cdb9d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2078550a005f3fde4c331ad4b8452c963c4cdb9d"}], "stats": {"total": 55, "additions": 47, "deletions": 8}, "files": [{"sha": "4c785073028e3259f9cddbf3dd6514b7d5784457", "filename": "gcc/config/arm/crypto.md", "status": "modified", "additions": 47, "deletions": 8, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/997070498b0d713ecfb384dc12d1e68ebdbee5bd/gcc%2Fconfig%2Farm%2Fcrypto.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/997070498b0d713ecfb384dc12d1e68ebdbee5bd/gcc%2Fconfig%2Farm%2Fcrypto.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcrypto.md?ref=997070498b0d713ecfb384dc12d1e68ebdbee5bd", "patch": "@@ -62,17 +62,56 @@\n   [(set_attr \"type\" \"<crypto_type>\")]\n )\n \n-; Mitigate against AES erratum on Cortex-A57 and Cortex-A72 by performing\n-; a 128-bit operation on an operand producer.  This can be eliminated only\n-; if we know that the operand was produced by a full-width operation.\n-; V16QImode matches <crypto_mode> for the AES instructions.\n+;; Mitigate against AES erratum on Cortex-A57 and Cortex-A72 by\n+;; performing a 128-bit operation on an operand producer.  This can be\n+;; eliminated only if we know that the operand was produced by a\n+;; full-width operation.  V16QImode matches <crypto_mode> for the AES\n+;; instructions.  Handle some very common cases where the source is\n+;; known to be safe (transfers from core registers and memory).\n (define_insn \"aes_op_protect\"\n-  [(set (match_operand:V16QI 0 \"register_operand\" \"=w\")\n-\t(unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"0\")]\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=w,w,w\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"general_operand\" \"w,r,Uni\")]\n+\t UNSPEC_AES_PROTECT))]\n+  \"TARGET_CRYPTO && fix_aes_erratum_1742098\"\n+  {\n+    switch (which_alternative)\n+      {\n+      case 0: return \"vmov\\t%q0, %q1\";\n+      case 1: return \"vmov\\t%e0, %Q1, %R1  @ V16QI\\;vmov\\t%f0, %J1, %K1\";\n+      case 2: return output_move_neon (operands);\n+      default: gcc_unreachable ();\n+      }\n+  }\n+  [(set_attr \"type\" \"neon_move_q,neon_from_gp_q,neon_load1_4reg\")\n+   (set_attr \"length\" \"4,8,8\")\n+   (set_attr \"arm_pool_range\" \"*,*,1020\")\n+   (set_attr \"thumb2_pool_range\" \"*,*,1018\")\n+   (set_attr \"neg_pool_range\" \"*,*,996\")]\n+)\n+\n+;; Another safe case is when a movmisalign load is used as the source.\n+(define_insn \"*aes_op_protect_misalign_load\"\n+  [(set (match_operand:V16QI 0 \"s_register_operand\" \"=w\")\n+\t(unspec:V16QI\n+\t [(unspec:V16QI\n+\t   [(match_operand:V16QI 1 \"neon_permissive_struct_operand\" \"Um\")]\n+\t   UNSPEC_MISALIGNED_ACCESS)]\n \t UNSPEC_AES_PROTECT))]\n   \"TARGET_CRYPTO && fix_aes_erratum_1742098\"\n-  \"vmov\\\\t%q0, %q1\"\n-  [(set_attr \"type\" \"neon_move_q\")]\n+  \"vld1.8\\t%{q0}, %A1\"\n+  [(set_attr \"type\" \"neon_load1_1reg_q\")]\n+)\n+\n+;; Similarly for the vld1 intrinsic\n+(define_insn \"aes_op_protect_neon_vld1v16qi\"\n+  [(set (match_operand:V16QI 0 \"s_register_operand\" \"=w\")\n+        (unspec:V16QI\n+\t [(unspec:V16QI [(match_operand:V16QI 1 \"neon_struct_operand\" \"Um\")]\n+           UNSPEC_VLD1)]\n+\t UNSPEC_AES_PROTECT))]\n+  \"TARGET_NEON\"\n+  \"vld1.8\\t%h0, %A1\"\n+  [(set_attr \"type\" \"neon_load1_1reg_q\")]\n )\n \n ;; An AESMC operation can feed directly into a subsequent AES"}]}