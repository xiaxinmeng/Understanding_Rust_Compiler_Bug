{"sha": "7b84aac03c4375c97843d5435f8548482028fa7a", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6N2I4NGFhYzAzYzQzNzVjOTc4NDNkNTQzNWY4NTQ4NDgyMDI4ZmE3YQ==", "commit": {"author": {"name": "Eric Botcazou", "email": "ebotcazou@adacore.com", "date": "2012-05-10T22:15:07Z"}, "committer": {"name": "Eric Botcazou", "email": "ebotcazou@gcc.gnu.org", "date": "2012-05-10T22:15:07Z"}, "message": "md.texi (Standard Names): Document probe_stack_address.\n\n\t* doc/md.texi (Standard Names): Document probe_stack_address.\n\t* explow.c (emit_stack_probe): Handle probe_stack_address.\n\t* config/ia64/ia64.md (UNSPECV_PROBE_STACK_ADDRESS): New constant.\n\t(UNSPECV_PROBE_STACK_RANGE): Likewise.\n\t(probe_stack_address): New insn.\n\t(probe_stack_range): Likewise.\n\t* config/ia64/ia64.c: Include common/common-target.h.\n\t(ia64_compute_frame_size): Mark r2 and r3 as used if static stack\n\tchecking is enabled.\n\t(ia64_emit_probe_stack_range): New function.\n\t(output_probe_stack_range): Likewise.\n\t(ia64_expand_prologue): Invoke ia64_emit_probe_stack_range if static\n\tbuiltin stack checking is enabled.\n\t(rtx_needs_barrier) <UNSPEC_VOLATILE>: Handle UNSPECV_PROBE_STACK_RANGE\n\tand UNSPECV_PROBE_STACK_ADDRESS.\n\t(unknown_for_bundling_p): New predicate.\n\t(group_barrier_needed): Use important_for_bundling_p.\n\t(ia64_dfa_new_cycle): Use unknown_for_bundling_p.\n\t(issue_nops_and_insn): Likewise.\n\t(bundling): Likewise.\n\t(final_emit_insn_group_barriers): Likewise.\n\t* config/ia64/ia64-protos.h (output_probe_stack_range): Declare.\n\t* config/ia64/hpux.h (STACK_CHECK_STATIC_BUILTIN): Define.\n\t(STACK_CHECK_PROTECT): Likewise.\n\t* config/ia64/linux.h (STACK_CHECK_STATIC_BUILTIN): Likewise.\n\nCo-Authored-By: Tristan Gingold <gingold@adacore.com>\n\nFrom-SVN: r187383", "tree": {"sha": "d8b039c3645b15a3789fe67a891798b24923faaa", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d8b039c3645b15a3789fe67a891798b24923faaa"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/7b84aac03c4375c97843d5435f8548482028fa7a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7b84aac03c4375c97843d5435f8548482028fa7a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7b84aac03c4375c97843d5435f8548482028fa7a", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7b84aac03c4375c97843d5435f8548482028fa7a/comments", "author": null, "committer": null, "parents": [{"sha": "f1016df4031ad7fbbe23bc5b4d91c87d609d2bf7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f1016df4031ad7fbbe23bc5b4d91c87d609d2bf7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f1016df4031ad7fbbe23bc5b4d91c87d609d2bf7"}], "stats": {"total": 374, "additions": 333, "deletions": 41}, "files": [{"sha": "856c6756ea960d06c99904447a88cb59354b28c7", "filename": "gcc/ChangeLog", "status": "modified", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=7b84aac03c4375c97843d5435f8548482028fa7a", "patch": "@@ -1,3 +1,32 @@\n+2012-05-10  Eric Botcazou  <ebotcazou@adacore.com>\n+\t    Tristan Gingold  <gingold@adacore.com>\n+\n+\t* doc/md.texi (Standard Names): Document probe_stack_address.\n+\t* explow.c (emit_stack_probe): Handle probe_stack_address.\n+\t* config/ia64/ia64.md (UNSPECV_PROBE_STACK_ADDRESS): New constant.\n+\t(UNSPECV_PROBE_STACK_RANGE): Likewise.\n+\t(probe_stack_address): New insn.\n+\t(probe_stack_range): Likewise.\n+\t* config/ia64/ia64.c: Include common/common-target.h.\n+\t(ia64_compute_frame_size): Mark r2 and r3 as used if static stack\n+\tchecking is enabled.\n+\t(ia64_emit_probe_stack_range): New function.\n+\t(output_probe_stack_range): Likewise.\n+\t(ia64_expand_prologue): Invoke ia64_emit_probe_stack_range if static\n+\tbuiltin stack checking is enabled.\n+\t(rtx_needs_barrier) <UNSPEC_VOLATILE>: Handle UNSPECV_PROBE_STACK_RANGE\n+\tand UNSPECV_PROBE_STACK_ADDRESS.\n+\t(unknown_for_bundling_p): New predicate.\n+\t(group_barrier_needed): Use important_for_bundling_p.\n+\t(ia64_dfa_new_cycle): Use unknown_for_bundling_p.\n+\t(issue_nops_and_insn): Likewise.\n+\t(bundling): Likewise.\n+\t(final_emit_insn_group_barriers): Likewise.\n+\t* config/ia64/ia64-protos.h (output_probe_stack_range): Declare.\n+\t* config/ia64/hpux.h (STACK_CHECK_STATIC_BUILTIN): Define.\n+\t(STACK_CHECK_PROTECT): Likewise.\n+\t* config/ia64/linux.h (STACK_CHECK_STATIC_BUILTIN): Likewise.\n+\n 2012-05-10  Jan Hubicka  <jh@suse.cz>\n \n \t* ipa-inline.c (update_all_callee_keys): Remove."}, {"sha": "ad106b4dee20838c61e33b33dd1593e604655445", "filename": "gcc/config/ia64/hpux.h", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Fhpux.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Fhpux.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fhpux.h?ref=7b84aac03c4375c97843d5435f8548482028fa7a", "patch": "@@ -228,3 +228,10 @@ do {\t\t\t\t\t\t\t\t\\\n #define TARGET_ASM_FUNCTION_SECTION ia64_hpux_function_section\n \n #define TARGET_POSIX_IO\n+\n+/* Define this to be nonzero if static stack checking is supported.  */\n+#define STACK_CHECK_STATIC_BUILTIN 1\n+\n+/* Minimum amount of stack required to recover from an anticipated stack\n+   overflow detection.  */\n+#define STACK_CHECK_PROTECT (24 * 1024)"}, {"sha": "458b1201c942baae6e10b793882f07a3b7582a11", "filename": "gcc/config/ia64/ia64-protos.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Fia64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Fia64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64-protos.h?ref=7b84aac03c4375c97843d5435f8548482028fa7a", "patch": "@@ -61,6 +61,7 @@ extern int ia64_hard_regno_rename_ok (int, int);\n extern enum reg_class ia64_secondary_reload_class (enum reg_class,\n \t\t\t\t\t\t   enum machine_mode, rtx);\n extern const char *get_bundle_name (int);\n+extern const char *output_probe_stack_range (rtx, rtx);\n \n extern void ia64_expand_vec_perm_even_odd (rtx, rtx, rtx, int);\n extern bool ia64_expand_vec_perm_const (rtx op[4]);"}, {"sha": "ccffa37fd87ffe9c9130578e3a904dcc8b23f5e1", "filename": "gcc/config/ia64/ia64.c", "status": "modified", "additions": 250, "deletions": 34, "changes": 284, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Fia64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Fia64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.c?ref=7b84aac03c4375c97843d5435f8548482028fa7a", "patch": "@@ -47,6 +47,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"timevar.h\"\n #include \"target.h\"\n #include \"target-def.h\"\n+#include \"common/common-target.h\"\n #include \"tm_p.h\"\n #include \"hashtab.h\"\n #include \"langhooks.h\"\n@@ -272,6 +273,7 @@ static int get_template (state_t, int);\n \n static rtx get_next_important_insn (rtx, rtx);\n static bool important_for_bundling_p (rtx);\n+static bool unknown_for_bundling_p (rtx);\n static void bundling (FILE *, int, rtx, rtx);\n \n static void ia64_output_mi_thunk (FILE *, tree, HOST_WIDE_INT,\n@@ -2672,6 +2674,10 @@ ia64_compute_frame_size (HOST_WIDE_INT size)\n   if (cfun->machine->ia64_eh_epilogue_bsp)\n     mark_reg_gr_used_mask (cfun->machine->ia64_eh_epilogue_bsp, NULL);\n \n+  /* Static stack checking uses r2 and r3.  */\n+  if (flag_stack_check == STATIC_BUILTIN_STACK_CHECK)\n+    current_frame_info.gr_used_mask |= 0xc;\n+\n   /* Find the size of the register stack frame.  We have only 80 local\n      registers, because we reserve 8 for the inputs and 8 for the\n      outputs.  */\n@@ -3230,6 +3236,213 @@ gen_fr_restore_x (rtx dest, rtx src, rtx offset ATTRIBUTE_UNUSED)\n   return gen_fr_restore (dest, src);\n }\n \n+#define PROBE_INTERVAL (1 << STACK_CHECK_PROBE_INTERVAL_EXP)\n+\n+/* See Table 6.2 of the IA-64 Software Developer Manual, Volume 2.  */\n+#define BACKING_STORE_SIZE(N) ((N) > 0 ? ((N) + (N)/63 + 1) * 8 : 0)\n+\n+/* Emit code to probe a range of stack addresses from FIRST to FIRST+SIZE,\n+   inclusive.  These are offsets from the current stack pointer.  SOL is the\n+   size of local registers.  ??? This clobbers r2 and r3.  */\n+\n+static void\n+ia64_emit_probe_stack_range (HOST_WIDE_INT first, HOST_WIDE_INT size, int sol)\n+{\n+ /* On the IA-64 there is a second stack in memory, namely the Backing Store\n+    of the Register Stack Engine.  We also need to probe it after checking\n+    that the 2 stacks don't overlap.  */\n+  const int bs_size = BACKING_STORE_SIZE (sol);\n+  rtx r2 = gen_rtx_REG (Pmode, GR_REG (2));\n+  rtx r3 = gen_rtx_REG (Pmode, GR_REG (3));\n+\n+  /* Detect collision of the 2 stacks if necessary.  */\n+  if (bs_size > 0 || size > 0)\n+    {\n+      rtx p6 = gen_rtx_REG (BImode, PR_REG (6));\n+\n+      emit_insn (gen_bsp_value (r3));\n+      emit_move_insn (r2, GEN_INT (-(first + size)));\n+\n+      /* Compare current value of BSP and SP registers.  */\n+      emit_insn (gen_rtx_SET (VOIDmode, p6,\n+\t\t\t      gen_rtx_fmt_ee (LTU, BImode,\n+\t\t\t\t\t      r3, stack_pointer_rtx)));\n+\n+      /* Compute the address of the probe for the Backing Store (which grows\n+\t towards higher addresses).  We probe only at the first offset of\n+\t the next page because some OS (eg Linux/ia64) only extend the\n+\t backing store when this specific address is hit (but generate a SEGV\n+\t on other address).  Page size is the worst case (4KB).  The reserve\n+\t size is at least 4096 - (96 + 2) * 8 = 3312 bytes, which is enough.\n+\t Also compute the address of the last probe for the memory stack\n+\t (which grows towards lower addresses).  */\n+      emit_insn (gen_rtx_SET (VOIDmode, r3, plus_constant (r3, 4095)));\n+      emit_insn (gen_rtx_SET (VOIDmode, r2,\n+\t\t\t      gen_rtx_PLUS (Pmode, stack_pointer_rtx, r2)));\n+\n+      /* Compare them and raise SEGV if the former has topped the latter.  */\n+      emit_insn (gen_rtx_COND_EXEC (VOIDmode,\n+\t\t\t\t    gen_rtx_fmt_ee (NE, VOIDmode, p6,\n+\t\t\t\t\t\t    const0_rtx),\n+\t\t\t\t    gen_rtx_SET (VOIDmode, p6,\n+\t\t\t\t\t\t gen_rtx_fmt_ee (GEU, BImode,\n+\t\t\t\t\t\t\t\t r3, r2))));\n+      emit_insn (gen_rtx_SET (VOIDmode,\n+\t\t\t      gen_rtx_ZERO_EXTRACT (DImode, r3, GEN_INT (12),\n+\t\t\t\t\t\t    const0_rtx),\n+\t\t\t      const0_rtx));\n+      emit_insn (gen_rtx_COND_EXEC (VOIDmode,\n+\t\t\t\t    gen_rtx_fmt_ee (NE, VOIDmode, p6,\n+\t\t\t\t\t\t    const0_rtx),\n+\t\t\t\t    gen_rtx_TRAP_IF (VOIDmode, const1_rtx,\n+\t\t\t\t\t\t     GEN_INT (11))));\n+    }\n+\n+  /* Probe the Backing Store if necessary.  */\n+  if (bs_size > 0)\n+    emit_stack_probe (r3);\n+\n+  /* Probe the memory stack if necessary.  */\n+  if (size == 0)\n+    ;\n+\n+  /* See if we have a constant small number of probes to generate.  If so,\n+     that's the easy case.  */\n+  else if (size <= PROBE_INTERVAL)\n+    emit_stack_probe (r2);\n+\n+  /* The run-time loop is made up of 8 insns in the generic case while this\n+     compile-time loop is made up of 5+2*(n-2) insns for n # of intervals.  */\n+  else if (size <= 4 * PROBE_INTERVAL)\n+    {\n+      HOST_WIDE_INT i;\n+\n+      emit_move_insn (r2, GEN_INT (-(first + PROBE_INTERVAL)));\n+      emit_insn (gen_rtx_SET (VOIDmode, r2,\n+\t\t\t      gen_rtx_PLUS (Pmode, stack_pointer_rtx, r2)));\n+      emit_stack_probe (r2);\n+\n+      /* Probe at FIRST + N * PROBE_INTERVAL for values of N from 2 until\n+\t it exceeds SIZE.  If only two probes are needed, this will not\n+\t generate any code.  Then probe at FIRST + SIZE.  */\n+      for (i = 2 * PROBE_INTERVAL; i < size; i += PROBE_INTERVAL)\n+\t{\n+\t  emit_insn (gen_rtx_SET (VOIDmode, r2,\n+\t\t\t\t  plus_constant (r2, -PROBE_INTERVAL)));\n+\t  emit_stack_probe (r2);\n+\t}\n+\n+      emit_insn (gen_rtx_SET (VOIDmode, r2,\n+\t\t\t      plus_constant (r2,\n+\t\t\t\t\t     (i - PROBE_INTERVAL) - size)));\n+      emit_stack_probe (r2);\n+    }\n+\n+  /* Otherwise, do the same as above, but in a loop.  Note that we must be\n+     extra careful with variables wrapping around because we might be at\n+     the very top (or the very bottom) of the address space and we have\n+     to be able to handle this case properly; in particular, we use an\n+     equality test for the loop condition.  */\n+  else\n+    {\n+      HOST_WIDE_INT rounded_size;\n+\n+      emit_move_insn (r2, GEN_INT (-first));\n+\n+\n+      /* Step 1: round SIZE to the previous multiple of the interval.  */\n+\n+      rounded_size = size & -PROBE_INTERVAL;\n+\n+\n+      /* Step 2: compute initial and final value of the loop counter.  */\n+\n+      /* TEST_ADDR = SP + FIRST.  */\n+      emit_insn (gen_rtx_SET (VOIDmode, r2,\n+\t\t\t      gen_rtx_PLUS (Pmode, stack_pointer_rtx, r2)));\n+\n+      /* LAST_ADDR = SP + FIRST + ROUNDED_SIZE.  */\n+      if (rounded_size > (1 << 21))\n+\t{\n+\t  emit_move_insn (r3, GEN_INT (-rounded_size));\n+\t  emit_insn (gen_rtx_SET (VOIDmode, r3, gen_rtx_PLUS (Pmode, r2, r3)));\n+\t}\n+      else\n+        emit_insn (gen_rtx_SET (VOIDmode, r3,\n+\t\t\t\tgen_rtx_PLUS (Pmode, r2,\n+\t\t\t\t\t      GEN_INT (-rounded_size))));\n+\n+\n+      /* Step 3: the loop\n+\n+\t while (TEST_ADDR != LAST_ADDR)\n+\t   {\n+\t     TEST_ADDR = TEST_ADDR + PROBE_INTERVAL\n+\t     probe at TEST_ADDR\n+\t   }\n+\n+\t probes at FIRST + N * PROBE_INTERVAL for values of N from 1\n+\t until it is equal to ROUNDED_SIZE.  */\n+\n+      emit_insn (gen_probe_stack_range (r2, r2, r3));\n+\n+\n+      /* Step 4: probe at FIRST + SIZE if we cannot assert at compile-time\n+\t that SIZE is equal to ROUNDED_SIZE.  */\n+\n+      /* TEMP = SIZE - ROUNDED_SIZE.  */\n+      if (size != rounded_size)\n+\t{\n+\t  emit_insn (gen_rtx_SET (VOIDmode, r2,\n+\t\t\t\t  plus_constant (r2, rounded_size - size)));\n+\t  emit_stack_probe (r2);\n+\t}\n+    }\n+\n+  /* Make sure nothing is scheduled before we are done.  */\n+  emit_insn (gen_blockage ());\n+}\n+\n+/* Probe a range of stack addresses from REG1 to REG2 inclusive.  These are\n+   absolute addresses.  */\n+\n+const char *\n+output_probe_stack_range (rtx reg1, rtx reg2)\n+{\n+  static int labelno = 0;\n+  char loop_lab[32], end_lab[32];\n+  rtx xops[3];\n+\n+  ASM_GENERATE_INTERNAL_LABEL (loop_lab, \"LPSRL\", labelno);\n+  ASM_GENERATE_INTERNAL_LABEL (end_lab, \"LPSRE\", labelno++);\n+\n+  ASM_OUTPUT_INTERNAL_LABEL (asm_out_file, loop_lab);\n+\n+  /* Jump to END_LAB if TEST_ADDR == LAST_ADDR.  */\n+  xops[0] = reg1;\n+  xops[1] = reg2;\n+  xops[2] = gen_rtx_REG (BImode, PR_REG (6));\n+  output_asm_insn (\"cmp.eq %2, %I2 = %0, %1\", xops);\n+  fprintf (asm_out_file, \"\\t(%s) br.cond.dpnt \", reg_names [REGNO (xops[2])]);\n+  assemble_name_raw (asm_out_file, end_lab);\n+  fputc ('\\n', asm_out_file);\n+\n+  /* TEST_ADDR = TEST_ADDR + PROBE_INTERVAL.  */\n+  xops[1] = GEN_INT (-PROBE_INTERVAL);\n+  output_asm_insn (\"addl %0 = %1, %0\", xops);\n+  fputs (\"\\t;;\\n\", asm_out_file);\n+\n+  /* Probe at TEST_ADDR and branch.  */\n+  output_asm_insn (\"probe.w.fault %0, 0\", xops);\n+  fprintf (asm_out_file, \"\\tbr \");\n+  assemble_name_raw (asm_out_file, loop_lab);\n+  fputc ('\\n', asm_out_file);\n+\n+  ASM_OUTPUT_INTERNAL_LABEL (asm_out_file, end_lab);\n+\n+  return \"\";\n+}\n+\n /* Called after register allocation to add any instructions needed for the\n    prologue.  Using a prologue insn is favored compared to putting all of the\n    instructions in output_function_prologue(), since it allows the scheduler\n@@ -3265,6 +3478,12 @@ ia64_expand_prologue (void)\n   if (flag_stack_usage_info)\n     current_function_static_stack_size = current_frame_info.total_size;\n \n+  if (flag_stack_check == STATIC_BUILTIN_STACK_CHECK)\n+    ia64_emit_probe_stack_range (STACK_CHECK_PROTECT,\n+\t\t\t\t current_frame_info.total_size,\n+\t\t\t\t current_frame_info.n_input_regs\n+\t\t\t\t   + current_frame_info.n_local_regs);\n+\n   if (dump_file) \n     {\n       fprintf (dump_file, \"ia64 frame related registers \"\n@@ -6529,6 +6748,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n \t  return 1;\n \n \tcase UNSPECV_SET_BSP:\n+\tcase UNSPECV_PROBE_STACK_RANGE:\n \t  need_barrier = 1;\n           break;\n \n@@ -6539,6 +6759,10 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n \tcase UNSPECV_PSAC_NORMAL:\n \t  return 0;\n \n+\tcase UNSPECV_PROBE_STACK_ADDRESS:\n+\t  need_barrier = rtx_needs_barrier (XVECEXP (x, 0, 0), flags, pred);\n+\t  break;\n+\n \tdefault:\n \t  gcc_unreachable ();\n \t}\n@@ -6700,10 +6924,7 @@ group_barrier_needed (rtx insn)\n       gcc_unreachable ();\n     }\n \n-  if (first_instruction && INSN_P (insn)\n-      && ia64_safe_itanium_class (insn) != ITANIUM_CLASS_IGNORE\n-      && GET_CODE (PATTERN (insn)) != USE\n-      && GET_CODE (PATTERN (insn)) != CLOBBER)\n+  if (first_instruction && important_for_bundling_p (insn))\n     {\n       need_barrier = 0;\n       first_instruction = 0;\n@@ -7397,8 +7618,7 @@ ia64_dfa_new_cycle (FILE *dump, int verbose, rtx insn, int last_clock,\n \t       && scheduled_good_insn (last_scheduled_insn))))\n       || (last_scheduled_insn\n \t  && (GET_CODE (last_scheduled_insn) == CALL_INSN\n-\t      || GET_CODE (PATTERN (last_scheduled_insn)) == ASM_INPUT\n-\t      || asm_noperands (PATTERN (last_scheduled_insn)) >= 0)))\n+\t      || unknown_for_bundling_p (last_scheduled_insn))))\n     {\n       init_insn_group_barriers ();\n \n@@ -7423,8 +7643,7 @@ ia64_dfa_new_cycle (FILE *dump, int verbose, rtx insn, int last_clock,\n \n       if (last_scheduled_insn)\n \t{\n-\t  if (GET_CODE (PATTERN (last_scheduled_insn)) == ASM_INPUT\n-\t      || asm_noperands (PATTERN (last_scheduled_insn)) >= 0)\n+\t  if (unknown_for_bundling_p (last_scheduled_insn))\n \t    state_reset (curr_state);\n \t  else\n \t    {\n@@ -8540,8 +8759,7 @@ issue_nops_and_insn (struct bundle_state *originator, int before_nops_num,\n       if (!try_issue_insn (curr_state, insn))\n \treturn;\n       curr_state->accumulated_insns_num++;\n-      gcc_assert (GET_CODE (PATTERN (insn)) != ASM_INPUT\n-\t\t  && asm_noperands (PATTERN (insn)) < 0);\n+      gcc_assert (!unknown_for_bundling_p (insn));\n \n       if (ia64_safe_type (insn) == TYPE_L)\n \tcurr_state->accumulated_insns_num++;\n@@ -8567,8 +8785,7 @@ issue_nops_and_insn (struct bundle_state *originator, int before_nops_num,\n       if (!try_issue_insn (curr_state, insn))\n \treturn;\n       curr_state->accumulated_insns_num++;\n-      if (GET_CODE (PATTERN (insn)) == ASM_INPUT\n-\t  || asm_noperands (PATTERN (insn)) >= 0)\n+      if (unknown_for_bundling_p (insn))\n \t{\n \t  /* Finish bundle containing asm insn.  */\n \t  curr_state->after_nops_num\n@@ -8702,6 +8919,7 @@ get_template (state_t state, int pos)\n }\n \n /* True when INSN is important for bundling.  */\n+\n static bool\n important_for_bundling_p (rtx insn)\n {\n@@ -8723,6 +8941,17 @@ get_next_important_insn (rtx insn, rtx tail)\n   return NULL_RTX;\n }\n \n+/* True when INSN is unknown, but important, for bundling.  */\n+\n+static bool\n+unknown_for_bundling_p (rtx insn)\n+{\n+  return (INSN_P (insn)\n+\t  && ia64_safe_itanium_class (insn) == ITANIUM_CLASS_UNKNOWN\n+\t  && GET_CODE (PATTERN (insn)) != USE\n+\t  && GET_CODE (PATTERN (insn)) != CLOBBER);\n+}\n+\n /* Add a bundle selector TEMPLATE0 before INSN.  */\n \n static void\n@@ -8850,19 +9079,14 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n        insn != tail;\n        insn = NEXT_INSN (insn))\n     if (INSN_P (insn)\n-\t&& (ia64_safe_itanium_class (insn) == ITANIUM_CLASS_IGNORE\n-\t    || GET_CODE (PATTERN (insn)) == USE\n-\t    || GET_CODE (PATTERN (insn)) == CLOBBER)\n+\t&& !important_for_bundling_p (insn)\n \t&& GET_MODE (insn) == TImode)\n       {\n \tPUT_MODE (insn, VOIDmode);\n \tfor (next_insn = NEXT_INSN (insn);\n \t     next_insn != tail;\n \t     next_insn = NEXT_INSN (next_insn))\n-\t  if (INSN_P (next_insn)\n-\t      && ia64_safe_itanium_class (next_insn) != ITANIUM_CLASS_IGNORE\n-\t      && GET_CODE (PATTERN (next_insn)) != USE\n-\t      && GET_CODE (PATTERN (next_insn)) != CLOBBER\n+\t  if (important_for_bundling_p (next_insn)\n \t      && INSN_CODE (next_insn) != CODE_FOR_insn_group_barrier)\n \t    {\n \t      PUT_MODE (next_insn, TImode);\n@@ -8874,10 +9098,7 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n        insn != NULL_RTX;\n        insn = next_insn)\n     {\n-      gcc_assert (INSN_P (insn)\n-\t\t  && ia64_safe_itanium_class (insn) != ITANIUM_CLASS_IGNORE\n-\t\t  && GET_CODE (PATTERN (insn)) != USE\n-\t\t  && GET_CODE (PATTERN (insn)) != CLOBBER);\n+      gcc_assert (important_for_bundling_p (insn));\n       type = ia64_safe_type (insn);\n       next_insn = get_next_important_insn (NEXT_INSN (insn), tail);\n       insn_num++;\n@@ -8894,7 +9115,7 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n \t  only_bundle_end_p\n \t    = (next_insn != NULL_RTX\n \t       && INSN_CODE (insn) == CODE_FOR_insn_group_barrier\n-\t       && ia64_safe_type (next_insn) == TYPE_UNKNOWN);\n+\t       && unknown_for_bundling_p (next_insn));\n \t  /* We may fill up the current bundle if it is the cycle end\n \t     without a group barrier.  */\n \t  bundle_end_p\n@@ -8978,8 +9199,7 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n        curr_state = curr_state->originator)\n     {\n       insn = curr_state->insn;\n-      asm_p = (GET_CODE (PATTERN (insn)) == ASM_INPUT\n-\t       || asm_noperands (PATTERN (insn)) >= 0);\n+      asm_p = unknown_for_bundling_p (insn);\n       insn_num++;\n       if (verbose >= 2 && dump)\n \t{\n@@ -9055,17 +9275,15 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n       /* Move the position backward in the window.  Group barrier has\n \t no slot.  Asm insn takes all bundle.  */\n       if (INSN_CODE (insn) != CODE_FOR_insn_group_barrier\n-\t  && GET_CODE (PATTERN (insn)) != ASM_INPUT\n-\t  && asm_noperands (PATTERN (insn)) < 0)\n+\t  && !unknown_for_bundling_p (insn))\n \tpos--;\n       /* Long insn takes 2 slots.  */\n       if (ia64_safe_type (insn) == TYPE_L)\n \tpos--;\n       gcc_assert (pos >= 0);\n       if (pos % 3 == 0\n \t  && INSN_CODE (insn) != CODE_FOR_insn_group_barrier\n-\t  && GET_CODE (PATTERN (insn)) != ASM_INPUT\n-\t  && asm_noperands (PATTERN (insn)) < 0)\n+\t  && !unknown_for_bundling_p (insn))\n \t{\n \t  /* The current insn is at the bundle start: emit the\n \t     template.  */\n@@ -9139,8 +9357,7 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n \t    if (recog_memoized (insn) == CODE_FOR_insn_group_barrier\n \t\t&& !start_bundle && !end_bundle\n \t\t&& next_insn\n-\t\t&& GET_CODE (PATTERN (next_insn)) != ASM_INPUT\n-\t\t&& asm_noperands (PATTERN (next_insn)) < 0)\n+\t\t&& !unknown_for_bundling_p (next_insn))\n \t      num--;\n \n \t    start_bundle = false;\n@@ -9270,8 +9487,7 @@ final_emit_insn_group_barriers (FILE *dump ATTRIBUTE_UNUSED)\n \t\t   && important_for_bundling_p (insn))\n \t    seen_good_insn = 1;\n \t  need_barrier_p = (GET_CODE (insn) == CALL_INSN\n-\t\t\t    || GET_CODE (PATTERN (insn)) == ASM_INPUT\n-\t\t\t    || asm_noperands (PATTERN (insn)) >= 0);\n+\t\t\t    || unknown_for_bundling_p (insn));\n \t}\n     }\n }"}, {"sha": "aa5e78636ea38f9c162d1cc1439841ccee2ce720", "filename": "gcc/config/ia64/ia64.md", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Fia64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Fia64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.md?ref=7b84aac03c4375c97843d5435f8548482028fa7a", "patch": "@@ -105,6 +105,8 @@\n    UNSPECV_PSAC_NORMAL\n    UNSPECV_SETJMP_RECEIVER\n    UNSPECV_GOTO_RECEIVER\n+   UNSPECV_PROBE_STACK_ADDRESS\n+   UNSPECV_PROBE_STACK_RANGE\n   ])\n \n (include \"predicates.md\")\n@@ -5182,6 +5184,26 @@\n  \"mov %0 = ip\"\n   [(set_attr \"itanium_class\" \"frbr\")])\n \n+;;\n+;; Stack checking\n+\n+(define_insn \"probe_stack_address\"\n+  [(unspec_volatile [(match_operand:DI 0 \"register_operand\" \"r\")]\n+\t\t    UNSPECV_PROBE_STACK_ADDRESS)]\n+  \"\"\n+  \"probe.w.fault %0, 0\"\n+[(set_attr \"itanium_class\" \"chk_s_i\")])\n+\n+(define_insn \"probe_stack_range\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n+\t(unspec_volatile:DI [(match_operand:DI 1 \"register_operand\" \"0\")\n+\t\t\t     (match_operand:DI 2 \"register_operand\" \"r\")]\n+\t\t\t     UNSPECV_PROBE_STACK_RANGE))]\n+  \"\"\n+  \"* return output_probe_stack_range (operands[0], operands[2]);\"\n+  [(set_attr \"itanium_class\" \"unknown\")\n+   (set_attr \"predicable\" \"no\")])\n+\n ;; Vector operations\n (include \"vect.md\")\n ;; Atomic operations"}, {"sha": "0e3b9be459cb833125e6c4f1240a541cd9dce4bd", "filename": "gcc/config/ia64/linux.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Flinux.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fconfig%2Fia64%2Flinux.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Flinux.h?ref=7b84aac03c4375c97843d5435f8548482028fa7a", "patch": "@@ -86,3 +86,6 @@ do {\t\t\t\t\t\t\\\n \n #undef TARGET_INIT_LIBFUNCS\n #define TARGET_INIT_LIBFUNCS ia64_soft_fp_init_libfuncs\n+\n+/* Define this to be nonzero if static stack checking is supported.  */\n+#define STACK_CHECK_STATIC_BUILTIN 1"}, {"sha": "73c800bbd043027c20400eb1405040122f6596f9", "filename": "gcc/doc/md.texi", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fdoc%2Fmd.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fdoc%2Fmd.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fmd.texi?ref=7b84aac03c4375c97843d5435f8548482028fa7a", "patch": "@@ -5614,6 +5614,13 @@ the stack farthest from the current stack pointer that you need to validate.\n Normally, on platforms where this pattern is needed, you would obtain the\n stack limit from a global or thread-specific variable or register.\n \n+@cindex @code{probe_stack_address} instruction pattern\n+@item @samp{probe_stack_address}\n+If stack checking (@pxref{Stack Checking}) can be done on your system by\n+probing the stack but without the need to actually access it, define this\n+pattern and signal an error if the stack has overflowed.  The single operand\n+is the memory address in the stack that needs to be probed.\n+\n @cindex @code{probe_stack} instruction pattern\n @item @samp{probe_stack}\n If stack checking (@pxref{Stack Checking}) can be done on your system by"}, {"sha": "5513a123e3dfb3250b470503bbcded81b4a73606", "filename": "gcc/explow.c", "status": "modified", "additions": 14, "deletions": 7, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fexplow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b84aac03c4375c97843d5435f8548482028fa7a/gcc%2Fexplow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexplow.c?ref=7b84aac03c4375c97843d5435f8548482028fa7a", "patch": "@@ -1525,17 +1525,24 @@ set_stack_check_libfunc (const char *libfunc_name)\n void\n emit_stack_probe (rtx address)\n {\n-  rtx memref = gen_rtx_MEM (word_mode, address);\n+#ifdef HAVE_probe_stack_address\n+  if (HAVE_probe_stack_address)\n+    emit_insn (gen_probe_stack_address (address));\n+  else\n+#endif\n+    {\n+      rtx memref = gen_rtx_MEM (word_mode, address);\n \n-  MEM_VOLATILE_P (memref) = 1;\n+      MEM_VOLATILE_P (memref) = 1;\n \n-  /* See if we have an insn to probe the stack.  */\n+      /* See if we have an insn to probe the stack.  */\n #ifdef HAVE_probe_stack\n-  if (HAVE_probe_stack)\n-    emit_insn (gen_probe_stack (memref));\n-  else\n+      if (HAVE_probe_stack)\n+        emit_insn (gen_probe_stack (memref));\n+      else\n #endif\n-    emit_move_insn (memref, const0_rtx);\n+        emit_move_insn (memref, const0_rtx);\n+    }\n }\n \n /* Probe a range of stack addresses from FIRST to FIRST+SIZE, inclusive."}]}