{"sha": "d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDY2MGMzNWVhMmJhN2MyMzA0OWQzYzhjMmUwN2JmN2RiY2YwYWVkOQ==", "commit": {"author": {"name": "Andrew MacLeod", "email": "amacleod@redhat.com", "date": "2011-11-10T20:38:33Z"}, "committer": {"name": "Andrew Macleod", "email": "amacleod@gcc.gnu.org", "date": "2011-11-10T20:38:33Z"}, "message": "re PR middle-end/51038 (29_atomics/atomic_flag/clear/1.cc test_and_set/explicit.cc implicit.cc)\n\n\tPR middle-end/51038\n\n\tlibstdc++-v3\n\t* include/bits/atomic_base.h (atomic_thread_fence): Call built-in.\n\t(atomic_signal_fence): Call built-in.\n\t(test_and_set, clear): Call new atomic built-ins.\n\n\tgcc\n\t* builtins.c (expand_builtin_atomic_clear): New.  Expand atomic_clear.\n\t(expand_builtin_atomic_test_and_set): New.  Expand atomic test_and_set.\n\t(expand_builtin): Add cases for test_and_set and clear.\n\t* sync-builtins.def (BUILT_IN_ATOMIC_TEST_AND_SET): New.\n\t(BUILT_IN_ATOMIC_CLEAR): New.\n\n\ttestsuite\n\t* gcc.dg/atomic-invalid.c: Add test for invalid __atomic_clear models.\n\t* gcc.dg/atomic-flag.c: New.  Test __atomic_test_and_set and\n\t__atomic_clear.\n\nFrom-SVN: r181271", "tree": {"sha": "4138d94b9a849ba000843310e148fa8a6d8d6c8a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4138d94b9a849ba000843310e148fa8a6d8d6c8a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/comments", "author": null, "committer": null, "parents": [{"sha": "49fe93f41068a64691cb450cd5b9490dc81880ae", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/49fe93f41068a64691cb450cd5b9490dc81880ae", "html_url": "https://github.com/Rust-GCC/gccrs/commit/49fe93f41068a64691cb450cd5b9490dc81880ae"}], "stats": {"total": 211, "additions": 159, "deletions": 52}, "files": [{"sha": "1f8a56af363902e0046b53f5ac4c9e74566da5bb", "filename": "gcc/ChangeLog", "status": "modified", "additions": 9, "deletions": 2, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "patch": "@@ -1,3 +1,12 @@\n+2011-11-10  Andrew MacLeod  <amacleod@redhat.com>\n+\n+\tPR middle-end/51038\n+\t* builtins.c (expand_builtin_atomic_clear): New.  Expand atomic_clear.\n+\t(expand_builtin_atomic_test_and_set): New.  Expand atomic test_and_set.\n+\t(expand_builtin): Add cases for test_and_set and clear.\n+\t* sync-builtins.def (BUILT_IN_ATOMIC_TEST_AND_SET): New.\n+\t(BUILT_IN_ATOMIC_CLEAR): New.\n+\n 2011-11-10  Roberto Agostino Vitillo  <ravitillo@lbl.gov>\n \n \tPR debug/50983\n@@ -37,8 +46,6 @@\n \tbe AND followed by NOT.\n \t* builtins.c (expand_builtin_atomic_fetch_op): Patchup code for NAND\n \tshould be AND followed by NOT.\n-\t* testsuite/gcc.dg/atomic-noinline[-aux].c: Test no-inline NAND and\n-\tpatchup code.\n \n 2011-11-10  Jakub Jelinek  <jakub@redhat.com>\n "}, {"sha": "98dc63604e7c3fe0b161554d8e9f119143a1a847", "filename": "gcc/builtins.c", "status": "modified", "additions": 71, "deletions": 0, "changes": 71, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "patch": "@@ -5474,6 +5474,71 @@ expand_builtin_atomic_fetch_op (enum machine_mode mode, tree exp, rtx target,\n   return ret;\n }\n \n+\n+/* Expand an atomic clear operation.\n+\tvoid _atomic_clear (BOOL *obj, enum memmodel)\n+   EXP is the call expression.  */\n+\n+static rtx\n+expand_builtin_atomic_clear (tree exp) \n+{\n+  enum machine_mode mode;\n+  rtx mem, ret;\n+  enum memmodel model;\n+\n+  mode = mode_for_size (BOOL_TYPE_SIZE, MODE_INT, 0);\n+  mem = get_builtin_sync_mem (CALL_EXPR_ARG (exp, 0), mode);\n+  model = get_memmodel (CALL_EXPR_ARG (exp, 1));\n+\n+  if (model == MEMMODEL_ACQUIRE || model == MEMMODEL_ACQ_REL)\n+    {\n+      error (\"invalid memory model for %<__atomic_store%>\");\n+      return const0_rtx;\n+    }\n+\n+  /* Try issuing an __atomic_store, and allow fallback to __sync_lock_release.\n+     Failing that, a store is issued by __atomic_store.  The only way this can\n+     fail is if the bool type is larger than a word size.  Unlikely, but\n+     handle it anyway for completeness.  Assume a single threaded model since\n+     there is no atomic support in this case, and no barriers are required.  */\n+  ret = expand_atomic_store (mem, const0_rtx, model, true);\n+  if (!ret)\n+    emit_move_insn (mem, const0_rtx);\n+  return const0_rtx;\n+}\n+\n+/* Expand an atomic test_and_set operation.\n+\tbool _atomic_test_and_set (BOOL *obj, enum memmodel)\n+   EXP is the call expression.  */\n+\n+static rtx\n+expand_builtin_atomic_test_and_set (tree exp)\n+{\n+  rtx mem, ret;\n+  enum memmodel model;\n+  enum machine_mode mode;\n+\n+  mode = mode_for_size (BOOL_TYPE_SIZE, MODE_INT, 0);\n+  mem = get_builtin_sync_mem (CALL_EXPR_ARG (exp, 0), mode);\n+  model = get_memmodel (CALL_EXPR_ARG (exp, 1));\n+\n+  /* Try issuing an exchange.  If it is lock free, or if there is a limited\n+     functionality __sync_lock_test_and_set, this will utilize it.  */\n+  ret = expand_atomic_exchange (NULL_RTX, mem, const1_rtx, model, true);\n+  if (ret)\n+    return ret;\n+\n+  /* Otherwise, there is no lock free support for test and set.  Simply\n+     perform a load and a store.  Since this presumes a non-atomic architecture,\n+     also assume single threadedness and don't issue barriers either. */\n+\n+  ret = gen_reg_rtx (mode);\n+  emit_move_insn (ret, mem);\n+  emit_move_insn (mem, const1_rtx);\n+  return ret;\n+}\n+\n+\n /* Return true if (optional) argument ARG1 of size ARG0 is always lock free on\n    this architecture.  If ARG1 is NULL, use typical alignment for size ARG0.  */\n \n@@ -6702,6 +6767,12 @@ expand_builtin (tree exp, rtx target, rtx subtarget, enum machine_mode mode,\n       if (target)\n \treturn target;\n       break;\n+\n+    case BUILT_IN_ATOMIC_TEST_AND_SET:\n+      return expand_builtin_atomic_test_and_set (exp);\n+\n+    case BUILT_IN_ATOMIC_CLEAR:\n+      return expand_builtin_atomic_clear (exp);\n  \n     case BUILT_IN_ATOMIC_ALWAYS_LOCK_FREE:\n       return expand_builtin_atomic_always_lock_free (exp);"}, {"sha": "15ff479bb5ec7ebd38204da84dd81eac7a3ab784", "filename": "gcc/sync-builtins.def", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Fsync-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Fsync-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsync-builtins.def?ref=d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "patch": "@@ -259,6 +259,12 @@ DEF_SYNC_BUILTIN (BUILT_IN_SYNC_SYNCHRONIZE, \"__sync_synchronize\",\n \n /* __sync* builtins for the C++ memory model.  */\n \n+DEF_SYNC_BUILTIN (BUILT_IN_ATOMIC_TEST_AND_SET, \"__atomic_test_and_set\",\n+\t\t  BT_FN_BOOL_VPTR_INT, ATTR_NOTHROW_LEAF_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_ATOMIC_CLEAR, \"__atomic_clear\", BT_FN_VOID_VPTR_INT,\n+\t\t  ATTR_NOTHROW_LEAF_LIST)\n+\n DEF_SYNC_BUILTIN (BUILT_IN_ATOMIC_EXCHANGE,\n \t\t  \"__atomic_exchange\",\n \t\t  BT_FN_VOID_SIZE_VPTR_PTR_PTR_INT, ATTR_NOTHROW_LEAF_LIST)"}, {"sha": "90eded987160b17ec98b4dd9fe95e430320cb77d", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "patch": "@@ -1,3 +1,16 @@\n+2011-11-10  Andrew MacLeod  <amacleod@redhat.com>\n+\n+\tPR middle-end/51038\n+\t* gcc.dg/atomic-invalid.c: Add test for invalid __atomic_clear models.\n+\t* gcc.dg/atomic-flag.c: New.  Test __atomic_test_and_set and\n+\t__atomic_clear.\n+\n+2011-11-10  Andrew MacLeod  <amacleod@redhat.com>\n+\n+\tPR rtl-optimization/51040\n+\t* testsuite/gcc.dg/atomic-noinline[-aux].c: Test no-inline NAND and\n+\tpatchup code.\n+\n 2011-11-10  Jason Merrill  <jason@redhat.com>\n \n \tPR c++/51079"}, {"sha": "771df2c6091eb4cba220e71e91a3750fc22f3f88", "filename": "gcc/testsuite/gcc.dg/atomic-flag.c", "status": "added", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Ftestsuite%2Fgcc.dg%2Fatomic-flag.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Ftestsuite%2Fgcc.dg%2Fatomic-flag.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fatomic-flag.c?ref=d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "patch": "@@ -0,0 +1,32 @@\n+/* Test __atomic routines for existence and execution.  */\n+/* { dg-do run } */\n+\n+#include <stdbool.h>\n+\n+/* Test that __atomic_test_and_set and __atomic_clear builtins execute.  */\n+\n+extern void abort(void);\n+bool a;\n+\n+main ()\n+{\n+  bool b;\n+\n+  __atomic_clear (&a, __ATOMIC_RELAXED);\n+  if (a != 0)\n+    abort ();\n+\n+  b = __atomic_test_and_set (&a, __ATOMIC_SEQ_CST);\n+  if (a != 1 || b != 0)\n+    abort ();\n+\n+  b = __atomic_test_and_set (&a, __ATOMIC_ACQ_REL);\n+  if (b != 1 || a != 1)\n+    abort ();\n+\n+  __atomic_clear (&a, __ATOMIC_SEQ_CST);\n+  if (a != 0)\n+    abort ();\n+\n+  return 0;\n+}"}, {"sha": "48de91f6c75b3c96098e1fd80621fe93c252b39f", "filename": "gcc/testsuite/gcc.dg/atomic-invalid.c", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Ftestsuite%2Fgcc.dg%2Fatomic-invalid.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/gcc%2Ftestsuite%2Fgcc.dg%2Fatomic-invalid.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fatomic-invalid.c?ref=d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "patch": "@@ -4,9 +4,11 @@\n /* { dg-require-effective-target sync_int_long } */\n \n #include <stddef.h>\n+#include <stdbool.h>\n \n int i, e, b;\n size_t s;\n+bool x;\n \n main ()\n {\n@@ -26,4 +28,9 @@ main ()\n   i = __atomic_always_lock_free (s, NULL); /* { dg-error \"non-constant argument\" } */\n \n   __atomic_load_n (&i, 44); /* { dg-warning \"invalid memory model\" } */\n+\n+  __atomic_clear (&x, __ATOMIC_ACQUIRE); /* { dg-error \"invalid memory model\" } */\n+\n+  __atomic_clear (&x, __ATOMIC_ACQ_REL); /* { dg-error \"invalid memory model\" } */\n+\n }"}, {"sha": "826ca4482dc44ef21d095f669eaf91578899dd12", "filename": "libstdc++-v3/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/libstdc%2B%2B-v3%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/libstdc%2B%2B-v3%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2FChangeLog?ref=d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "patch": "@@ -1,3 +1,10 @@\n+2011-11-10  Andrew MacLeod  <amacleod@redhat.com>\n+\n+\tPR middle-end/51038\n+\t* include/bits/atomic_base.h (atomic_thread_fence): Call built-in.\n+\t(atomic_signal_fence): Call built-in.\n+\t(test_and_set, clear): Call new atomic built-ins.\n+\n 2011-11-09  Jonathan Wakely  <jwakely.gcc@gmail.com>\n \n \t* include/bits/allocator.h (__shrink_to_fit_aux::_S_do_it): Create"}, {"sha": "f0336611d3f9a1ab054e6990c261949095ac0cba", "filename": "libstdc++-v3/include/bits/atomic_base.h", "status": "modified", "additions": 14, "deletions": 50, "changes": 64, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fatomic_base.h?ref=d660c35ea2ba7c23049d3c8c2e07bf7dbcf0aed9", "patch": "@@ -68,11 +68,17 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     return __mo2;\n   }\n \n-  void\n-  atomic_thread_fence(memory_order __m) noexcept;\n+  inline void\n+  atomic_thread_fence(memory_order __m) noexcept\n+  {\n+    __atomic_thread_fence (__m);\n+  }\n \n-  void\n-  atomic_signal_fence(memory_order __m) noexcept;\n+  inline void\n+  atomic_signal_fence(memory_order __m) noexcept\n+  {\n+    __atomic_thread_fence (__m);\n+  }\n \n   /// kill_dependency\n   template<typename _Tp>\n@@ -261,35 +267,13 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     bool\n     test_and_set(memory_order __m = memory_order_seq_cst) noexcept\n     {\n-      /* The standard *requires* this to be lock free.  If exchange is not\n-\t always lock free, the resort to the old test_and_set.  */\n-      if (__atomic_always_lock_free (sizeof (_M_i), 0))\n-\treturn __atomic_exchange_n(&_M_i, 1, __m);\n-      else\n-        {\n-\t  /* Sync test and set is only guaranteed to be acquire.  */\n-\t  if (__m == memory_order_seq_cst || __m == memory_order_release\n-\t      || __m == memory_order_acq_rel)\n-\t    atomic_thread_fence (__m);\n-\t  return __sync_lock_test_and_set (&_M_i, 1);\n-\t}\n+      return __atomic_test_and_set (&_M_i, __m);\n     }\n \n     bool\n     test_and_set(memory_order __m = memory_order_seq_cst) volatile noexcept\n     {\n-      /* The standard *requires* this to be lock free.  If exchange is not\n-\t always lock free, the resort to the old test_and_set.  */\n-      if (__atomic_always_lock_free (sizeof (_M_i), 0))\n-\treturn __atomic_exchange_n(&_M_i, 1, __m);\n-      else\n-        {\n-\t  /* Sync test and set is only guaranteed to be acquire.  */\n-\t  if (__m == memory_order_seq_cst || __m == memory_order_release\n-\t      || __m == memory_order_acq_rel)\n-\t    atomic_thread_fence (__m);\n-\t  return __sync_lock_test_and_set (&_M_i, 1);\n-\t}\n+      return __atomic_test_and_set (&_M_i, __m);\n     }\n \n     void\n@@ -299,17 +283,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       __glibcxx_assert(__m != memory_order_acquire);\n       __glibcxx_assert(__m != memory_order_acq_rel);\n \n-      /* The standard *requires* this to be lock free.  If store is not always\n-\t lock free, the resort to the old style __sync_lock_release.  */\n-      if (__atomic_always_lock_free (sizeof (_M_i), 0))\n-\t__atomic_store_n(&_M_i, 0, __m);\n-      else\n-        {\n-\t  __sync_lock_release (&_M_i, 0);\n-\t  /* __sync_lock_release is only guaranteed to be a release barrier.  */\n-\t  if (__m == memory_order_seq_cst)\n-\t    atomic_thread_fence (__m);\n-\t}\n+      __atomic_clear (&_M_i, __m);\n     }\n \n     void\n@@ -319,17 +293,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       __glibcxx_assert(__m != memory_order_acquire);\n       __glibcxx_assert(__m != memory_order_acq_rel);\n \n-      /* The standard *requires* this to be lock free.  If store is not always\n-\t lock free, the resort to the old style __sync_lock_release.  */\n-      if (__atomic_always_lock_free (sizeof (_M_i), 0))\n-\t__atomic_store_n(&_M_i, 0, __m);\n-      else\n-        {\n-\t  __sync_lock_release (&_M_i, 0);\n-\t  /* __sync_lock_release is only guaranteed to be a release barrier.  */\n-\t  if (__m == memory_order_seq_cst)\n-\t    atomic_thread_fence (__m);\n-\t}\n+      __atomic_clear (&_M_i, __m);\n     }\n   };\n "}]}