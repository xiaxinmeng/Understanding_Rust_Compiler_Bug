{"sha": "ad7e0b44aed61156b7599d56407b4443f34663e3", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWQ3ZTBiNDRhZWQ2MTE1NmI3NTk5ZDU2NDA3YjQ0NDNmMzQ2NjNlMw==", "commit": {"author": {"name": "John David Anglin", "email": "danglin@gcc.gnu.org", "date": "2015-12-17T00:11:55Z"}, "committer": {"name": "John David Anglin", "email": "danglin@gcc.gnu.org", "date": "2015-12-17T00:11:55Z"}, "message": "re PR target/68779 (HPPA/PARISC 32-bit Linux kernel build triggers multiple ICEs)\n\n\tPR target/68779\n\t* config/pa/pa.md (atomic_loaddi): Honor -mdisable-fpregs.\n\t(atomic_loaddi_1): Likewise.\n\t(atomic_storedi): Likewise.\n\t(atomic_storedi_1): Likewise.\n\t(atomic_loaddf): Likewise.\n\t(atomic_loaddf_1): Likewise.\n\t(atomic_storedf): Likewise.\n\t(atomic_storedf_1): Likewise.\n\tMove all atomic patterns to end of file.\n\nFrom-SVN: r231727", "tree": {"sha": "6271392b65d07cf91046a52ef3577aa52d10bbd9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6271392b65d07cf91046a52ef3577aa52d10bbd9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ad7e0b44aed61156b7599d56407b4443f34663e3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ad7e0b44aed61156b7599d56407b4443f34663e3", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ad7e0b44aed61156b7599d56407b4443f34663e3", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ad7e0b44aed61156b7599d56407b4443f34663e3/comments", "author": null, "committer": null, "parents": [{"sha": "f3b5cf3ddc88e8818a64173543157af431c8997f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f3b5cf3ddc88e8818a64173543157af431c8997f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f3b5cf3ddc88e8818a64173543157af431c8997f"}], "stats": {"total": 479, "additions": 248, "deletions": 231}, "files": [{"sha": "8b0a5e7921dd5e6e3e9e26b7a0b17a6f436358b5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ad7e0b44aed61156b7599d56407b4443f34663e3/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ad7e0b44aed61156b7599d56407b4443f34663e3/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ad7e0b44aed61156b7599d56407b4443f34663e3", "patch": "@@ -1,3 +1,16 @@\n+2015-12-16  John David Anglin  <danglin@gcc.gnu.org>\n+\n+\tPR target/68779\n+\t* config/pa/pa.md (atomic_loaddi): Honor -mdisable-fpregs.\n+\t(atomic_loaddi_1): Likewise.\n+\t(atomic_storedi): Likewise.\n+\t(atomic_storedi_1): Likewise.\n+\t(atomic_loaddf): Likewise.\n+\t(atomic_loaddf_1): Likewise.\n+\t(atomic_storedf): Likewise.\n+\t(atomic_storedf_1): Likewise.\n+\tMove all atomic patterns to end of file.\n+\n 2015-12-16  Abderrazek Zaafrani  <a.zaafrani@samsung.com>\n \n \t* graphite-isl-ast-to-gimple.c: Include isl/schedule_node.h."}, {"sha": "241d312fb1a4928410cc19ffc8a2b340d8829078", "filename": "gcc/config/pa/pa.md", "status": "modified", "additions": 235, "deletions": 231, "changes": 466, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ad7e0b44aed61156b7599d56407b4443f34663e3/gcc%2Fconfig%2Fpa%2Fpa.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ad7e0b44aed61156b7599d56407b4443f34663e3/gcc%2Fconfig%2Fpa%2Fpa.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Fpa.md?ref=ad7e0b44aed61156b7599d56407b4443f34663e3", "patch": "@@ -692,237 +692,6 @@\n (include \"predicates.md\")\n (include \"constraints.md\")\n \f\n-;; Atomic instructions\n-\n-;; All memory loads and stores access storage atomically except\n-;; for one exception.  The STORE BYTES, STORE DOUBLE BYTES, and\n-;; doubleword loads and stores are not guaranteed to be atomic\n-;; when referencing the I/O address space.\n-\n-;; The kernel cmpxchg operation on linux is not atomic with respect to\n-;; memory stores on SMP machines, so we must do stores using a cmpxchg\n-;; operation.\n-\n-;; Implement atomic QImode store using exchange.\n-\n-(define_expand \"atomic_storeqi\"\n-  [(match_operand:QI 0 \"memory_operand\")                ;; memory\n-   (match_operand:QI 1 \"register_operand\")              ;; val out\n-   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n-  \"\"\n-{\n-  if (TARGET_SYNC_LIBCALL)\n-    {\n-      rtx mem = operands[0];\n-      rtx val = operands[1];\n-      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n-\tDONE;\n-    }\n-  FAIL;\n-})\n-\n-;; Implement atomic HImode stores using exchange.\n-\n-(define_expand \"atomic_storehi\"\n-  [(match_operand:HI 0 \"memory_operand\")                ;; memory\n-   (match_operand:HI 1 \"register_operand\")              ;; val out\n-   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n-  \"\"\n-{\n-  if (TARGET_SYNC_LIBCALL)\n-    {\n-      rtx mem = operands[0];\n-      rtx val = operands[1];\n-      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n-\tDONE;\n-    }\n-  FAIL;\n-})\n-\n-;; Implement atomic SImode store using exchange.\n-\n-(define_expand \"atomic_storesi\"\n-  [(match_operand:SI 0 \"memory_operand\")                ;; memory\n-   (match_operand:SI 1 \"register_operand\")              ;; val out\n-   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n-  \"\"\n-{\n-  if (TARGET_SYNC_LIBCALL)\n-    {\n-      rtx mem = operands[0];\n-      rtx val = operands[1];\n-      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n-\tDONE;\n-    }\n-  FAIL;\n-})\n-\n-;; Implement atomic SFmode store using exchange.\n-\n-(define_expand \"atomic_storesf\"\n-  [(match_operand:SF 0 \"memory_operand\")                ;; memory\n-   (match_operand:SF 1 \"register_operand\")              ;; val out\n-   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n-  \"\"\n-{\n-  if (TARGET_SYNC_LIBCALL)\n-    {\n-      rtx mem = operands[0];\n-      rtx val = operands[1];\n-      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n-\tDONE;\n-    }\n-  FAIL;\n-})\n-\n-;; Implement atomic DImode load using 64-bit floating point load.\n-\n-(define_expand \"atomic_loaddi\"\n-  [(match_operand:DI 0 \"register_operand\")              ;; val out\n-   (match_operand:DI 1 \"memory_operand\")                ;; memory\n-   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n-  \"\"\n-{\n-  enum memmodel model;\n-\n-  if (TARGET_64BIT || TARGET_SOFT_FLOAT)\n-    FAIL;\n-\n-  model = memmodel_from_int (INTVAL (operands[2]));\n-  operands[1] = force_reg (SImode, XEXP (operands[1], 0));\n-  expand_mem_thread_fence (model);\n-  emit_insn (gen_atomic_loaddi_1 (operands[0], operands[1]));\n-  if (is_mm_seq_cst (model))\n-    expand_mem_thread_fence (model);\n-  DONE;\n-})\n-\n-(define_insn \"atomic_loaddi_1\"\n-  [(set (match_operand:DI 0 \"register_operand\" \"=f,r\")\n-        (mem:DI (match_operand:SI 1 \"register_operand\" \"r,r\")))\n-   (clobber (match_scratch:DI 2 \"=X,f\"))]\n-  \"!TARGET_64BIT && !TARGET_SOFT_FLOAT\"\n-  \"@\n-   {fldds|fldd} 0(%1),%0\n-   {fldds|fldd} 0(%1),%2\\n\\t{fstds|fstd} %2,-16(%%sp)\\n\\t{ldws|ldw} -16(%%sp),%0\\n\\t{ldws|ldw} -12(%%sp),%R0\"\n-  [(set_attr \"type\" \"move,move\")\n-   (set_attr \"length\" \"4,16\")])\n-\n-;; Implement atomic DImode store.\n-\n-(define_expand \"atomic_storedi\"\n-  [(match_operand:DI 0 \"memory_operand\")                ;; memory\n-   (match_operand:DI 1 \"register_operand\")              ;; val out\n-   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n-  \"\"\n-{\n-  enum memmodel model;\n-\n-  if (TARGET_SYNC_LIBCALL)\n-    {\n-      rtx mem = operands[0];\n-      rtx val = operands[1];\n-      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n-\tDONE;\n-    }\n-\n-  if (TARGET_64BIT || TARGET_SOFT_FLOAT)\n-    FAIL;\n-\n-  model = memmodel_from_int (INTVAL (operands[2]));\n-  operands[0] = force_reg (SImode, XEXP (operands[0], 0));\n-  expand_mem_thread_fence (model);\n-  emit_insn (gen_atomic_storedi_1 (operands[0], operands[1]));\n-  if (is_mm_seq_cst (model))\n-    expand_mem_thread_fence (model);\n-  DONE;\n-})\n-\n-(define_insn \"atomic_storedi_1\"\n-  [(set (mem:DI (match_operand:SI 0 \"register_operand\" \"r,r\"))\n-        (match_operand:DI 1 \"register_operand\" \"f,r\"))\n-   (clobber (match_scratch:DI 2 \"=X,f\"))]\n-  \"!TARGET_64BIT && !TARGET_SOFT_FLOAT && !TARGET_SYNC_LIBCALL\"\n-  \"@\n-   {fstds|fstd} %1,0(%0)\n-   {stws|stw} %1,-16(%%sp)\\n\\t{stws|stw} %R1,-12(%%sp)\\n\\t{fldds|fldd} -16(%%sp),%2\\n\\t{fstds|fstd} %2,0(%0)\"\n-  [(set_attr \"type\" \"move,move\")\n-   (set_attr \"length\" \"4,16\")])\n-\n-;; Implement atomic DFmode load using 64-bit floating point load.\n-\n-(define_expand \"atomic_loaddf\"\n-  [(match_operand:DF 0 \"register_operand\")              ;; val out\n-   (match_operand:DF 1 \"memory_operand\")                ;; memory\n-   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n-  \"\"\n-{\n-  enum memmodel model;\n-\n-  if (TARGET_64BIT || TARGET_SOFT_FLOAT)\n-    FAIL;\n-\n-  model = memmodel_from_int (INTVAL (operands[2]));\n-  operands[1] = force_reg (SImode, XEXP (operands[1], 0));\n-  expand_mem_thread_fence (model);\n-  emit_insn (gen_atomic_loaddf_1 (operands[0], operands[1]));\n-  if (is_mm_seq_cst (model))\n-    expand_mem_thread_fence (model);\n-  DONE;\n-})\n-\n-(define_insn \"atomic_loaddf_1\"\n-  [(set (match_operand:DF 0 \"register_operand\" \"=f,r\")\n-        (mem:DF (match_operand:SI 1 \"register_operand\" \"r,r\")))\n-   (clobber (match_scratch:DF 2 \"=X,f\"))]\n-  \"!TARGET_64BIT && !TARGET_SOFT_FLOAT\"\n-  \"@\n-   {fldds|fldd} 0(%1),%0\n-   {fldds|fldd} 0(%1),%2\\n\\t{fstds|fstd} %2,-16(%%sp)\\n\\t{ldws|ldw} -16(%%sp),%0\\n\\t{ldws|ldw} -12(%%sp),%R0\"\n-  [(set_attr \"type\" \"move,move\")\n-   (set_attr \"length\" \"4,16\")])\n-\n-;; Implement atomic DFmode store using 64-bit floating point store.\n-\n-(define_expand \"atomic_storedf\"\n-  [(match_operand:DF 0 \"memory_operand\")                ;; memory\n-   (match_operand:DF 1 \"register_operand\")              ;; val out\n-   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n-  \"\"\n-{\n-  enum memmodel model;\n-\n-  if (TARGET_SYNC_LIBCALL)\n-    {\n-      rtx mem = operands[0];\n-      rtx val = operands[1];\n-      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n-\tDONE;\n-    }\n-\n-  if (TARGET_64BIT || TARGET_SOFT_FLOAT)\n-    FAIL;\n-\n-  model = memmodel_from_int (INTVAL (operands[2]));\n-  operands[0] = force_reg (SImode, XEXP (operands[0], 0));\n-  expand_mem_thread_fence (model);\n-  emit_insn (gen_atomic_storedf_1 (operands[0], operands[1]));\n-  if (is_mm_seq_cst (model))\n-    expand_mem_thread_fence (model);\n-  DONE;\n-})\n-\n-(define_insn \"atomic_storedf_1\"\n-  [(set (mem:DF (match_operand:SI 0 \"register_operand\" \"r,r\"))\n-        (match_operand:DF 1 \"register_operand\" \"f,r\"))\n-   (clobber (match_scratch:DF 2 \"=X,f\"))]\n-  \"!TARGET_64BIT && !TARGET_SOFT_FLOAT\"\n-  \"@\n-   {fstds|fstd} %1,0(%0)\n-   {stws|stw} %1,-16(%%sp)\\n\\t{stws|stw} %R1,-12(%%sp)\\n\\t{fldds|fldd} -16(%%sp),%2\\n\\t{fstds|fstd} %2,0(%0)\"\n-  [(set_attr \"type\" \"move,move\")\n-   (set_attr \"length\" \"4,16\")])\n-\n ;; Compare instructions.\n ;; This controls RTL generation and register allocation.\n \n@@ -9930,3 +9699,238 @@ add,l %2,%3,%3\\;bv,n %%r0(%3)\"\n   \"addil LR'%1-$tls_leoff$,%2\\;ldo RR'%1-$tls_leoff$(%%r1),%0\"\n   [(set_attr \"type\" \"multi\")\n    (set_attr \"length\" \"8\")])\n+\n+;; Atomic instructions\n+\n+;; All memory loads and stores access storage atomically except\n+;; for one exception.  The STORE BYTES, STORE DOUBLE BYTES, and\n+;; doubleword loads and stores are not guaranteed to be atomic\n+;; when referencing the I/O address space.\n+\n+;; The kernel cmpxchg operation on linux is not atomic with respect to\n+;; memory stores on SMP machines, so we must do stores using a cmpxchg\n+;; operation.\n+\n+;; These patterns are at the bottom so the non atomic versions are preferred.\n+\n+;; Implement atomic QImode store using exchange.\n+\n+(define_expand \"atomic_storeqi\"\n+  [(match_operand:QI 0 \"memory_operand\")                ;; memory\n+   (match_operand:QI 1 \"register_operand\")              ;; val out\n+   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n+  \"\"\n+{\n+  if (TARGET_SYNC_LIBCALL)\n+    {\n+      rtx mem = operands[0];\n+      rtx val = operands[1];\n+      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n+\tDONE;\n+    }\n+  FAIL;\n+})\n+\n+;; Implement atomic HImode stores using exchange.\n+\n+(define_expand \"atomic_storehi\"\n+  [(match_operand:HI 0 \"memory_operand\")                ;; memory\n+   (match_operand:HI 1 \"register_operand\")              ;; val out\n+   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n+  \"\"\n+{\n+  if (TARGET_SYNC_LIBCALL)\n+    {\n+      rtx mem = operands[0];\n+      rtx val = operands[1];\n+      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n+\tDONE;\n+    }\n+  FAIL;\n+})\n+\n+;; Implement atomic SImode store using exchange.\n+\n+(define_expand \"atomic_storesi\"\n+  [(match_operand:SI 0 \"memory_operand\")                ;; memory\n+   (match_operand:SI 1 \"register_operand\")              ;; val out\n+   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n+  \"\"\n+{\n+  if (TARGET_SYNC_LIBCALL)\n+    {\n+      rtx mem = operands[0];\n+      rtx val = operands[1];\n+      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n+\tDONE;\n+    }\n+  FAIL;\n+})\n+\n+;; Implement atomic SFmode store using exchange.\n+\n+(define_expand \"atomic_storesf\"\n+  [(match_operand:SF 0 \"memory_operand\")                ;; memory\n+   (match_operand:SF 1 \"register_operand\")              ;; val out\n+   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n+  \"\"\n+{\n+  if (TARGET_SYNC_LIBCALL)\n+    {\n+      rtx mem = operands[0];\n+      rtx val = operands[1];\n+      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n+\tDONE;\n+    }\n+  FAIL;\n+})\n+\n+;; Implement atomic DImode load using 64-bit floating point load.\n+\n+(define_expand \"atomic_loaddi\"\n+  [(match_operand:DI 0 \"register_operand\")              ;; val out\n+   (match_operand:DI 1 \"memory_operand\")                ;; memory\n+   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n+  \"\"\n+{\n+  enum memmodel model;\n+\n+  if (TARGET_64BIT || TARGET_DISABLE_FPREGS || TARGET_SOFT_FLOAT)\n+    FAIL;\n+\n+  model = memmodel_from_int (INTVAL (operands[2]));\n+  operands[1] = force_reg (SImode, XEXP (operands[1], 0));\n+  expand_mem_thread_fence (model);\n+  emit_insn (gen_atomic_loaddi_1 (operands[0], operands[1]));\n+  if (is_mm_seq_cst (model))\n+    expand_mem_thread_fence (model);\n+  DONE;\n+})\n+\n+(define_insn \"atomic_loaddi_1\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=f,r\")\n+        (mem:DI (match_operand:SI 1 \"register_operand\" \"r,r\")))\n+   (clobber (match_scratch:DI 2 \"=X,f\"))]\n+  \"!TARGET_64BIT && !TARGET_DISABLE_FPREGS && !TARGET_SOFT_FLOAT\"\n+  \"@\n+   {fldds|fldd} 0(%1),%0\n+   {fldds|fldd} 0(%1),%2\\n\\t{fstds|fstd} %2,-16(%%sp)\\n\\t{ldws|ldw} -16(%%sp),%0\\n\\t{ldws|ldw} -12(%%sp),%R0\"\n+  [(set_attr \"type\" \"move,move\")\n+   (set_attr \"length\" \"4,16\")])\n+\n+;; Implement atomic DImode store.\n+\n+(define_expand \"atomic_storedi\"\n+  [(match_operand:DI 0 \"memory_operand\")                ;; memory\n+   (match_operand:DI 1 \"register_operand\")              ;; val out\n+   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n+  \"\"\n+{\n+  enum memmodel model;\n+\n+  if (TARGET_SYNC_LIBCALL)\n+    {\n+      rtx mem = operands[0];\n+      rtx val = operands[1];\n+      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n+\tDONE;\n+    }\n+\n+  if (TARGET_64BIT || TARGET_DISABLE_FPREGS || TARGET_SOFT_FLOAT)\n+    FAIL;\n+\n+  model = memmodel_from_int (INTVAL (operands[2]));\n+  operands[0] = force_reg (SImode, XEXP (operands[0], 0));\n+  expand_mem_thread_fence (model);\n+  emit_insn (gen_atomic_storedi_1 (operands[0], operands[1]));\n+  if (is_mm_seq_cst (model))\n+    expand_mem_thread_fence (model);\n+  DONE;\n+})\n+\n+(define_insn \"atomic_storedi_1\"\n+  [(set (mem:DI (match_operand:SI 0 \"register_operand\" \"r,r\"))\n+        (match_operand:DI 1 \"register_operand\" \"f,r\"))\n+   (clobber (match_scratch:DI 2 \"=X,f\"))]\n+  \"!TARGET_64BIT && !TARGET_DISABLE_FPREGS\n+   && !TARGET_SOFT_FLOAT && !TARGET_SYNC_LIBCALL\"\n+  \"@\n+   {fstds|fstd} %1,0(%0)\n+   {stws|stw} %1,-16(%%sp)\\n\\t{stws|stw} %R1,-12(%%sp)\\n\\t{fldds|fldd} -16(%%sp),%2\\n\\t{fstds|fstd} %2,0(%0)\"\n+  [(set_attr \"type\" \"move,move\")\n+   (set_attr \"length\" \"4,16\")])\n+\n+;; Implement atomic DFmode load using 64-bit floating point load.\n+\n+(define_expand \"atomic_loaddf\"\n+  [(match_operand:DF 0 \"register_operand\")              ;; val out\n+   (match_operand:DF 1 \"memory_operand\")                ;; memory\n+   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n+  \"\"\n+{\n+  enum memmodel model;\n+\n+  if (TARGET_64BIT || TARGET_DISABLE_FPREGS || TARGET_SOFT_FLOAT)\n+    FAIL;\n+\n+  model = memmodel_from_int (INTVAL (operands[2]));\n+  operands[1] = force_reg (SImode, XEXP (operands[1], 0));\n+  expand_mem_thread_fence (model);\n+  emit_insn (gen_atomic_loaddf_1 (operands[0], operands[1]));\n+  if (is_mm_seq_cst (model))\n+    expand_mem_thread_fence (model);\n+  DONE;\n+})\n+\n+(define_insn \"atomic_loaddf_1\"\n+  [(set (match_operand:DF 0 \"register_operand\" \"=f,r\")\n+        (mem:DF (match_operand:SI 1 \"register_operand\" \"r,r\")))\n+   (clobber (match_scratch:DF 2 \"=X,f\"))]\n+  \"!TARGET_64BIT && !TARGET_DISABLE_FPREGS && !TARGET_SOFT_FLOAT\"\n+  \"@\n+   {fldds|fldd} 0(%1),%0\n+   {fldds|fldd} 0(%1),%2\\n\\t{fstds|fstd} %2,-16(%%sp)\\n\\t{ldws|ldw} -16(%%sp),%0\\n\\t{ldws|ldw} -12(%%sp),%R0\"\n+  [(set_attr \"type\" \"move,move\")\n+   (set_attr \"length\" \"4,16\")])\n+\n+;; Implement atomic DFmode store using 64-bit floating point store.\n+\n+(define_expand \"atomic_storedf\"\n+  [(match_operand:DF 0 \"memory_operand\")                ;; memory\n+   (match_operand:DF 1 \"register_operand\")              ;; val out\n+   (match_operand:SI 2 \"const_int_operand\")]            ;; model\n+  \"\"\n+{\n+  enum memmodel model;\n+\n+  if (TARGET_SYNC_LIBCALL)\n+    {\n+      rtx mem = operands[0];\n+      rtx val = operands[1];\n+      if (pa_maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val))\n+\tDONE;\n+    }\n+\n+  if (TARGET_64BIT || TARGET_DISABLE_FPREGS || TARGET_SOFT_FLOAT)\n+    FAIL;\n+\n+  model = memmodel_from_int (INTVAL (operands[2]));\n+  operands[0] = force_reg (SImode, XEXP (operands[0], 0));\n+  expand_mem_thread_fence (model);\n+  emit_insn (gen_atomic_storedf_1 (operands[0], operands[1]));\n+  if (is_mm_seq_cst (model))\n+    expand_mem_thread_fence (model);\n+  DONE;\n+})\n+\n+(define_insn \"atomic_storedf_1\"\n+  [(set (mem:DF (match_operand:SI 0 \"register_operand\" \"r,r\"))\n+        (match_operand:DF 1 \"register_operand\" \"f,r\"))\n+   (clobber (match_scratch:DF 2 \"=X,f\"))]\n+  \"!TARGET_64BIT && !TARGET_DISABLE_FPREGS\n+   && !TARGET_SOFT_FLOAT && !TARGET_SYNC_LIBCALL\"\n+  \"@\n+   {fstds|fstd} %1,0(%0)\n+   {stws|stw} %1,-16(%%sp)\\n\\t{stws|stw} %R1,-12(%%sp)\\n\\t{fldds|fldd} -16(%%sp),%2\\n\\t{fstds|fstd} %2,0(%0)\"\n+  [(set_attr \"type\" \"move,move\")\n+   (set_attr \"length\" \"4,16\")])"}]}