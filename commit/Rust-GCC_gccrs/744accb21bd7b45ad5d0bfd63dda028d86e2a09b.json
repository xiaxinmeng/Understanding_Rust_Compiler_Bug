{"sha": "744accb21bd7b45ad5d0bfd63dda028d86e2a09b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzQ0YWNjYjIxYmQ3YjQ1YWQ1ZDBiZmQ2M2RkYTAyOGQ4NmUyYTA5Yg==", "commit": {"author": {"name": "Andrew MacLeod", "email": "amacleod@redhat.com", "date": "2011-11-24T23:14:31Z"}, "committer": {"name": "Andrew Macleod", "email": "amacleod@gcc.gnu.org", "date": "2011-11-24T23:14:31Z"}, "message": "optab.c (maybe_emit_atomic_exchange): New.\n\n\n2011-11-24  Andrew MacLeod  <amacleod@redhat.com>\n\n\t* optab.c (maybe_emit_atomic_exchange): New.  Try to emit an\n\tatomic_exchange pattern.\n\t(maybe_emit_sync_lock_test_and_set): New.  Try to emit an exchange\n\tusing __sync_lock_test_and_set.\n\t(maybe_emit_compare_and_swap_exchange_loop): New. Try to emit an\n\texchange using a compare_and_swap loop.\n\t(expand_sync_lock_test_and_set): New.  Expand sync_lock_test_and_set.\n\t(expand_atomic_test_and_set): New.  Expand test_and_set operation.\n\t(expand_atomic_exchange): Use new maybe_emit_* functions.\n\t(expand_atomic_store): Use new maybe_emit_* functions.\n\t* builtins.c (expand_builtin_sync_lock_test_and_set): Call\n\texpand_sync_lock_test_and_set routine.\n\t(expand_builtin_atomic_exchange): Remove parameter from call.\n\t(expand_builtin_atomic_clear): Use atomic_clear pattern if present.\n\t(expand_builtin_atomic_test_and_set): Add target and simply call\n\texpand_atomic_test_and_set.\n\t(expand_builtin): Add target to expand_builtin_atomic_test_and_set.\n\t* expr.h (expand_atomic_exchange): Add parameter.\n\t(expand_sync_lock_test_and_set): New prototype.\n\t(expand_atomic_test_and_set, expand_atomic_clear): New prototypes.\n\nFrom-SVN: r181702", "tree": {"sha": "bf092826976e956804e16b109cecf1f0d3830700", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/bf092826976e956804e16b109cecf1f0d3830700"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/744accb21bd7b45ad5d0bfd63dda028d86e2a09b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/744accb21bd7b45ad5d0bfd63dda028d86e2a09b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/744accb21bd7b45ad5d0bfd63dda028d86e2a09b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/comments", "author": null, "committer": null, "parents": [{"sha": "bee51209f65f0d80bc8cfd7a494d1d6c4f730c2b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bee51209f65f0d80bc8cfd7a494d1d6c4f730c2b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bee51209f65f0d80bc8cfd7a494d1d6c4f730c2b"}], "stats": {"total": 295, "additions": 214, "deletions": 81}, "files": [{"sha": "f4cf7e1c5318b15e3c95b56f6bfbda70f01ac371", "filename": "gcc/ChangeLog", "status": "modified", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=744accb21bd7b45ad5d0bfd63dda028d86e2a09b", "patch": "@@ -1,3 +1,26 @@\n+2011-11-24  Andrew MacLeod  <amacleod@redhat.com>\n+\n+\t* optab.c (maybe_emit_atomic_exchange): New.  Try to emit an\n+\tatomic_exchange pattern.\n+\t(maybe_emit_sync_lock_test_and_set): New.  Try to emit an exchange\n+\tusing __sync_lock_test_and_set.\n+\t(maybe_emit_compare_and_swap_exchange_loop): New. Try to emit an\n+\texchange using a compare_and_swap loop.\n+\t(expand_sync_lock_test_and_set): New.  Expand sync_lock_test_and_set.\n+\t(expand_atomic_test_and_set): New.  Expand test_and_set operation.\n+\t(expand_atomic_exchange): Use new maybe_emit_* functions.\n+\t(expand_atomic_store): Use new maybe_emit_* functions.\n+\t* builtins.c (expand_builtin_sync_lock_test_and_set): Call\n+\texpand_sync_lock_test_and_set routine.\n+\t(expand_builtin_atomic_exchange): Remove parameter from call.\n+\t(expand_builtin_atomic_clear): Use atomic_clear pattern if present.\n+\t(expand_builtin_atomic_test_and_set): Add target and simply call\n+\texpand_atomic_test_and_set.\n+\t(expand_builtin): Add target to expand_builtin_atomic_test_and_set.\n+\t* expr.h (expand_atomic_exchange): Add parameter.\n+\t(expand_sync_lock_test_and_set): New prototype.\n+\t(expand_atomic_test_and_set, expand_atomic_clear): New prototypes.\n+\n 2011-11-24  H.J. Lu  <hongjiu.lu@intel.com>\n \n \tPR target/51134"}, {"sha": "c9c02d105503fb06ab61e724c7c77815bb1e5041", "filename": "gcc/builtins.c", "status": "modified", "additions": 17, "deletions": 19, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=744accb21bd7b45ad5d0bfd63dda028d86e2a09b", "patch": "@@ -5227,7 +5227,7 @@ expand_builtin_sync_lock_test_and_set (enum machine_mode mode, tree exp,\n   mem = get_builtin_sync_mem (CALL_EXPR_ARG (exp, 0), mode);\n   val = expand_expr_force_mode (CALL_EXPR_ARG (exp, 1), mode);\n \n-  return expand_atomic_exchange (target, mem, val, MEMMODEL_ACQUIRE, true);\n+  return expand_sync_lock_test_and_set (target, mem, val);\n }\n \n /* Expand the __sync_lock_release intrinsic.  EXP is the CALL_EXPR.  */\n@@ -5291,7 +5291,7 @@ expand_builtin_atomic_exchange (enum machine_mode mode, tree exp, rtx target)\n   mem = get_builtin_sync_mem (CALL_EXPR_ARG (exp, 0), mode);\n   val = expand_expr_force_mode (CALL_EXPR_ARG (exp, 1), mode);\n \n-  return expand_atomic_exchange (target, mem, val, model, false);\n+  return expand_atomic_exchange (target, mem, val, model);\n }\n \n /* Expand the __atomic_compare_exchange intrinsic:\n@@ -5482,6 +5482,11 @@ expand_builtin_atomic_fetch_op (enum machine_mode mode, tree exp, rtx target,\n }\n \n \n+#ifndef HAVE_atomic_clear\n+# define HAVE_atomic_clear 0\n+# define gen_atomic_clear(x,y) (gcc_unreachable (), NULL_RTX)\n+#endif\n+\n /* Expand an atomic clear operation.\n \tvoid _atomic_clear (BOOL *obj, enum memmodel)\n    EXP is the call expression.  */\n@@ -5503,6 +5508,12 @@ expand_builtin_atomic_clear (tree exp)\n       return const0_rtx;\n     }\n \n+  if (HAVE_atomic_clear)\n+    {\n+      emit_insn (gen_atomic_clear (mem, model));\n+      return const0_rtx;\n+    }\n+\n   /* Try issuing an __atomic_store, and allow fallback to __sync_lock_release.\n      Failing that, a store is issued by __atomic_store.  The only way this can\n      fail is if the bool type is larger than a word size.  Unlikely, but\n@@ -5519,30 +5530,17 @@ expand_builtin_atomic_clear (tree exp)\n    EXP is the call expression.  */\n \n static rtx\n-expand_builtin_atomic_test_and_set (tree exp)\n+expand_builtin_atomic_test_and_set (tree exp, rtx target)\n {\n-  rtx mem, ret;\n+  rtx mem;\n   enum memmodel model;\n   enum machine_mode mode;\n \n   mode = mode_for_size (BOOL_TYPE_SIZE, MODE_INT, 0);\n   mem = get_builtin_sync_mem (CALL_EXPR_ARG (exp, 0), mode);\n   model = get_memmodel (CALL_EXPR_ARG (exp, 1));\n \n-  /* Try issuing an exchange.  If it is lock free, or if there is a limited\n-     functionality __sync_lock_test_and_set, this will utilize it.  */\n-  ret = expand_atomic_exchange (NULL_RTX, mem, const1_rtx, model, true);\n-  if (ret)\n-    return ret;\n-\n-  /* Otherwise, there is no lock free support for test and set.  Simply\n-     perform a load and a store.  Since this presumes a non-atomic architecture,\n-     also assume single threadedness and don't issue barriers either. */\n-\n-  ret = gen_reg_rtx (mode);\n-  emit_move_insn (ret, mem);\n-  emit_move_insn (mem, const1_rtx);\n-  return ret;\n+  return expand_atomic_test_and_set (target, mem, model);\n }\n \n \n@@ -6711,7 +6709,7 @@ expand_builtin (tree exp, rtx target, rtx subtarget, enum machine_mode mode,\n       break;\n \n     case BUILT_IN_ATOMIC_TEST_AND_SET:\n-      return expand_builtin_atomic_test_and_set (exp);\n+      return expand_builtin_atomic_test_and_set (exp, target);\n \n     case BUILT_IN_ATOMIC_CLEAR:\n       return expand_builtin_atomic_clear (exp);"}, {"sha": "7a323bacd6ac0b1e5d333cc0fe021355f168016b", "filename": "gcc/expr.h", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=744accb21bd7b45ad5d0bfd63dda028d86e2a09b", "patch": "@@ -214,12 +214,15 @@ rtx emit_conditional_add (rtx, enum rtx_code, rtx, rtx, enum machine_mode,\n \n rtx expand_sync_operation (rtx, rtx, enum rtx_code);\n rtx expand_sync_fetch_operation (rtx, rtx, enum rtx_code, bool, rtx);\n+rtx expand_sync_lock_test_and_set (rtx, rtx, rtx);\n \n-rtx expand_atomic_exchange (rtx, rtx, rtx, enum memmodel, bool);\n+rtx expand_atomic_exchange (rtx, rtx, rtx, enum memmodel);\n rtx expand_atomic_load (rtx, rtx, enum memmodel);\n rtx expand_atomic_store (rtx, rtx, enum memmodel, bool);\n rtx expand_atomic_fetch_op (rtx, rtx, rtx, enum rtx_code, enum memmodel, \n \t\t\t      bool);\n+rtx expand_atomic_test_and_set (rtx, rtx, enum memmodel);\n+rtx expand_atomic_clear (rtx, enum memmodel);\n void expand_atomic_thread_fence (enum memmodel);\n void expand_atomic_signal_fence (enum memmodel);\n "}, {"sha": "1aafd28b5bec7187eab90714988a71da5c8fc05b", "filename": "gcc/optabs.c", "status": "modified", "additions": 170, "deletions": 61, "changes": 231, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/gcc%2Foptabs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/744accb21bd7b45ad5d0bfd63dda028d86e2a09b/gcc%2Foptabs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.c?ref=744accb21bd7b45ad5d0bfd63dda028d86e2a09b", "patch": "@@ -7325,17 +7325,12 @@ expand_compare_and_swap_loop (rtx mem, rtx old_reg, rtx new_reg, rtx seq)\n }\n \n \n-/* This function expands the atomic exchange operation:\n-   atomically store VAL in MEM and return the previous value in MEM.\n-\n-   MEMMODEL is the memory model variant to use.\n-   TARGET is an optional place to stick the return value.  \n-   USE_TEST_AND_SET indicates whether __sync_lock_test_and_set should be used\n-   as a fall back if the atomic_exchange pattern does not exist.  */\n-\n-rtx\n-expand_atomic_exchange (rtx target, rtx mem, rtx val, enum memmodel model,\n-\t\t\tbool use_test_and_set)\t\t\t\n+/* This function tries to emit an atomic_exchange intruction.  VAL is written\n+   to *MEM using memory model MODEL. The previous contents of *MEM are returned,\n+   using TARGET if possible.  */\n+   \n+static rtx\n+maybe_emit_atomic_exchange (rtx target, rtx mem, rtx val, enum memmodel model)\n {\n   enum machine_mode mode = GET_MODE (mem);\n   enum insn_code icode;\n@@ -7355,65 +7350,78 @@ expand_atomic_exchange (rtx target, rtx mem, rtx val, enum memmodel model,\n \treturn ops[0].value;\n     }\n \n-  /* Legacy sync_lock_test_and_set works the same, but is only defined as an \n-     acquire barrier.  If the pattern exists, and the memory model is stronger\n-     than acquire, add a release barrier before the instruction.\n-     The barrier is not needed if sync_lock_test_and_set doesn't exist since\n-     it will expand into a compare-and-swap loop.\n+  return NULL_RTX;\n+}\n \n-     Some targets have non-compliant test_and_sets, so it would be incorrect\n-     to emit a test_and_set in place of an __atomic_exchange.  The test_and_set\n-     builtin shares this expander since exchange can always replace the\n-     test_and_set.  */\n+/* This function tries to implement an atomic exchange operation using\n+   __sync_lock_test_and_set. VAL is written to *MEM using memory model MODEL.\n+   The previous contents of *MEM are returned, using TARGET if possible.\n+   Since this instructionn is an acquire barrier only, stronger memory\n+   models may require additional barriers to be emitted.  */\n \n-  if (use_test_and_set)\n+static rtx\n+maybe_emit_sync_lock_test_and_set (rtx target, rtx mem, rtx val,\n+\t\t\t\t   enum memmodel model)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum insn_code icode;\n+  rtx last_insn = get_last_insn ();\n+\n+  icode = optab_handler (sync_lock_test_and_set_optab, mode);\n+\n+  /* Legacy sync_lock_test_and_set is an acquire barrier.  If the pattern\n+     exists, and the memory model is stronger than acquire, add a release \n+     barrier before the instruction.  */\n+\n+  if (model == MEMMODEL_SEQ_CST\n+      || model == MEMMODEL_RELEASE\n+      || model == MEMMODEL_ACQ_REL)\n+    expand_mem_thread_fence (model);\n+\n+  if (icode != CODE_FOR_nothing)\n     {\n-      icode = optab_handler (sync_lock_test_and_set_optab, mode);\n+      struct expand_operand ops[3];\n+      create_output_operand (&ops[0], target, mode);\n+      create_fixed_operand (&ops[1], mem);\n+      /* VAL may have been promoted to a wider mode.  Shrink it if so.  */\n+      create_convert_operand_to (&ops[2], val, mode, true);\n+      if (maybe_expand_insn (icode, 3, ops))\n+\treturn ops[0].value;\n+    }\n \n-      if (icode != CODE_FOR_nothing)\n+  /* If an external test-and-set libcall is provided, use that instead of\n+     any external compare-and-swap that we might get from the compare-and-\n+     swap-loop expansion later.  */\n+  if (!can_compare_and_swap_p (mode, false))\n+    {\n+      rtx libfunc = optab_libfunc (sync_lock_test_and_set_optab, mode);\n+      if (libfunc != NULL)\n \t{\n-\t  struct expand_operand ops[3];\n-\t  rtx last_insn = get_last_insn ();\n-\n-\t  if (model == MEMMODEL_SEQ_CST\n-\t      || model == MEMMODEL_RELEASE\n-\t      || model == MEMMODEL_ACQ_REL)\n-\t    expand_mem_thread_fence (model);\n-\n-\t  create_output_operand (&ops[0], target, mode);\n-\t  create_fixed_operand (&ops[1], mem);\n-\t  /* VAL may have been promoted to a wider mode.  Shrink it if so.  */\n-\t  create_convert_operand_to (&ops[2], val, mode, true);\n-\t  if (maybe_expand_insn (icode, 3, ops))\n-\t    return ops[0].value;\n-\n-\t  delete_insns_since (last_insn);\n+\t  rtx addr;\n+\n+\t  addr = convert_memory_address (ptr_mode, XEXP (mem, 0));\n+\t  return emit_library_call_value (libfunc, target, LCT_NORMAL,\n+\t\t\t\t\t  mode, 2, addr, ptr_mode,\n+\t\t\t\t\t  val, mode);\n \t}\n+    }\n \n-      /* If an external test-and-set libcall is provided, use that instead of\n-\t any external compare-and-swap that we might get from the compare-and-\n-\t swap-loop expansion below.  */\n-      if (!can_compare_and_swap_p (mode, false))\n-\t{\n-\t  rtx libfunc = optab_libfunc (sync_lock_test_and_set_optab, mode);\n-\t  if (libfunc != NULL)\n-\t    {\n-\t      rtx addr;\n+  /* If the test_and_set can't be emitted, eliminate any barrier that might\n+     have been emitted.  */\n+  delete_insns_since (last_insn);\n+  return NULL_RTX;\n+}\n \n-\t      if (model == MEMMODEL_SEQ_CST\n-\t\t  || model == MEMMODEL_RELEASE\n-\t\t  || model == MEMMODEL_ACQ_REL)\n-\t\texpand_mem_thread_fence (model);\n+/* This function tries to implement an atomic exchange operation using a \n+   compare_and_swap loop. VAL is written to *MEM.  The previous contents of\n+   *MEM are returned, using TARGET if possible.  No memory model is required\n+   since a compare_and_swap loop is seq-cst.  */\n \n-\t      addr = convert_memory_address (ptr_mode, XEXP (mem, 0));\n-\t      return emit_library_call_value (libfunc, target, LCT_NORMAL,\n-\t\t\t\t\t      mode, 2, addr, ptr_mode,\n-\t\t\t\t\t      val, mode);\n-\t    }\n-\t}\n-    }\n+static rtx \n+maybe_emit_compare_and_swap_exchange_loop (rtx target, rtx mem, rtx val)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n \n-  /* Otherwise, use a compare-and-swap loop for the exchange.  */\n   if (can_compare_and_swap_p (mode, true))\n     {\n       if (!target || !register_operand (target, mode))\n@@ -7427,6 +7435,105 @@ expand_atomic_exchange (rtx target, rtx mem, rtx val, enum memmodel model,\n   return NULL_RTX;\n }\n \n+#ifndef HAVE_atomic_test_and_set\n+#define HAVE_atomic_test_and_set 0\n+#define gen_atomic_test_and_set(x,y,z)  (gcc_unreachable (), NULL_RTX)\n+#endif\n+\n+/* This function expands the legacy _sync_lock test_and_set operation which is\n+   generally an atomic exchange.  Some limited targets only allow the\n+   constant 1 to be stored.  This is an ACQUIRE operation. \n+\n+   TARGET is an optional place to stick the return value.  \n+   MEM is where VAL is stored.  */\n+\n+rtx\n+expand_sync_lock_test_and_set (rtx target, rtx mem, rtx val)\n+{\n+  rtx ret;\n+\n+  /* Try an atomic_exchange first.  */\n+  ret = maybe_emit_atomic_exchange (target, mem, val, MEMMODEL_ACQUIRE);\n+\n+  if (!ret)\n+    ret = maybe_emit_sync_lock_test_and_set (target, mem, val,\n+\t\t\t\t\t     MEMMODEL_ACQUIRE);\n+  if (!ret)\n+    ret = maybe_emit_compare_and_swap_exchange_loop (target, mem, val);\n+\n+  /* If there are no other options, try atomic_test_and_set if the value\n+     being stored is 1.  */\n+  if (!ret && val == const1_rtx && HAVE_atomic_test_and_set)\n+    {\n+      ret = gen_atomic_test_and_set (target, mem, GEN_INT (MEMMODEL_ACQUIRE));\n+      emit_insn (ret);\n+    }\n+\n+  return ret;\n+}\n+\n+/* This function expands the atomic test_and_set operation:\n+   atomically store a boolean TRUE into MEM and return the previous value.\n+\n+   MEMMODEL is the memory model variant to use.\n+   TARGET is an optional place to stick the return value.  */\n+\n+rtx\n+expand_atomic_test_and_set (rtx target, rtx mem, enum memmodel model)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  rtx ret = NULL_RTX;\n+\n+  if (target == NULL_RTX)\n+    target = gen_reg_rtx (mode);\n+\n+  if (HAVE_atomic_test_and_set)\n+    {\n+      ret = gen_atomic_test_and_set (target, mem, GEN_INT (MEMMODEL_ACQUIRE));\n+      emit_insn (ret);\n+      return ret;\n+    }\n+\n+  /* If there is no test and set, try exchange, then a compare_and_swap loop,\n+     then __sync_test_and_set.  */\n+  ret = maybe_emit_atomic_exchange (target, mem, const1_rtx, model);\n+\n+  if (!ret)\n+    ret = maybe_emit_compare_and_swap_exchange_loop (target, mem, const1_rtx);\n+\n+  if (!ret)\n+    ret = maybe_emit_sync_lock_test_and_set (target, mem, const1_rtx, model);\n+\n+  if (ret)\n+    return ret;\n+\n+  /* Failing all else, assume a single threaded environment and simply perform\n+     the operation.  */\n+  emit_move_insn (target, mem);\n+  emit_move_insn (mem, const1_rtx);\n+  return target;\n+}\n+\n+/* This function expands the atomic exchange operation:\n+   atomically store VAL in MEM and return the previous value in MEM.\n+\n+   MEMMODEL is the memory model variant to use.\n+   TARGET is an optional place to stick the return value.  */\n+\n+rtx\n+expand_atomic_exchange (rtx target, rtx mem, rtx val, enum memmodel model)\n+{\n+  rtx ret;\n+\n+  ret = maybe_emit_atomic_exchange (target, mem, val, model);\n+\n+  /* Next try a compare-and-swap loop for the exchange.  */\n+  if (!ret)\n+    ret = maybe_emit_compare_and_swap_exchange_loop (target, mem, val);\n+\n+  return ret;\n+}\n+\n /* This function expands the atomic compare exchange operation:\n \n    *PTARGET_BOOL is an optional place to store the boolean success/failure.\n@@ -7726,7 +7833,9 @@ expand_atomic_store (rtx mem, rtx val, enum memmodel model, bool use_release)\n      the result.  If that doesn't work, don't do anything.  */\n   if (GET_MODE_PRECISION(mode) > BITS_PER_WORD)\n     {\n-      rtx target = expand_atomic_exchange (NULL_RTX, mem, val, model, false);\n+      rtx target = maybe_emit_atomic_exchange (NULL_RTX, mem, val, model);\n+      if (!target)\n+        target = maybe_emit_compare_and_swap_exchange_loop (NULL_RTX, mem, val);\n       if (target)\n         return const0_rtx;\n       else"}]}