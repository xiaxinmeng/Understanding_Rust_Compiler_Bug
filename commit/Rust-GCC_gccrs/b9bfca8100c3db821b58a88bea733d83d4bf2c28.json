{"sha": "b9bfca8100c3db821b58a88bea733d83d4bf2c28", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjliZmNhODEwMGMzZGI4MjFiNThhODhiZWE3MzNkODNkNGJmMmMyOA==", "commit": {"author": {"name": "Daniel Jacobowitz", "email": "dan@debian.org", "date": "2004-08-09T23:11:08Z"}, "committer": {"name": "Daniel Jacobowitz", "email": "drow@gcc.gnu.org", "date": "2004-08-09T23:11:08Z"}, "message": "ggc-zone.c (struct alloc_zone): Add statistics counters.\n\n\t* ggc-zone.c (struct alloc_zone): Add statistics counters.\n\t(always_collect): New flag.\n\t(ggc_alloc_zone_1): Update statistics support.  Don't include\n\toverhead in allocated counter.\n\t(sweep_pages): Update allocated counter for large pages.  Don'y\n\tinclude overhead.\n\t(ggc_collect_1): Always collect.\n\t(ggc_collect): Honor always_collect flag.  Sum all zones to decide\n\twhether to collect.\n\t(SCALE, LABEL): New macros.\n\t(ggc_print_statistics): Add statistics support.\n\nFrom-SVN: r85729", "tree": {"sha": "e8cd23456364903f50b737affe182e0729fd39fc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e8cd23456364903f50b737affe182e0729fd39fc"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b9bfca8100c3db821b58a88bea733d83d4bf2c28", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b9bfca8100c3db821b58a88bea733d83d4bf2c28", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b9bfca8100c3db821b58a88bea733d83d4bf2c28", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b9bfca8100c3db821b58a88bea733d83d4bf2c28/comments", "author": null, "committer": null, "parents": [{"sha": "fdded40102ee40d7acbcb6bc2518e5ec14245688", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fdded40102ee40d7acbcb6bc2518e5ec14245688", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fdded40102ee40d7acbcb6bc2518e5ec14245688"}], "stats": {"total": 266, "additions": 245, "deletions": 21}, "files": [{"sha": "004021f414a017713a4f373a365def984b14e4ee", "filename": "gcc/ChangeLog", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b9bfca8100c3db821b58a88bea733d83d4bf2c28/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b9bfca8100c3db821b58a88bea733d83d4bf2c28/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b9bfca8100c3db821b58a88bea733d83d4bf2c28", "patch": "@@ -1,3 +1,17 @@\n+2004-08-09  Daniel Jacobowitz  <dan@debian.org>\n+\n+\t* ggc-zone.c (struct alloc_zone): Add statistics counters.\n+\t(always_collect): New flag.\n+\t(ggc_alloc_zone_1): Update statistics support.  Don't include\n+\toverhead in allocated counter.\n+\t(sweep_pages): Update allocated counter for large pages.  Don'y\n+\tinclude overhead.\n+\t(ggc_collect_1): Always collect.\n+\t(ggc_collect): Honor always_collect flag.  Sum all zones to decide\n+\twhether to collect.\n+\t(SCALE, LABEL): New macros.\n+\t(ggc_print_statistics): Add statistics support.\n+\n 2004-08-09  Roger Sayle  <roger@eyesopen.com>\n \n \t* expmed.c (sdiv_pow2_cheap, smod_pow2_cheap): Change type to bool."}, {"sha": "fc605f49045472fc3c21d03011893d1b12bce584", "filename": "gcc/ggc-zone.c", "status": "modified", "additions": 231, "deletions": 21, "changes": 252, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b9bfca8100c3db821b58a88bea733d83d4bf2c28/gcc%2Fggc-zone.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b9bfca8100c3db821b58a88bea733d83d4bf2c28/gcc%2Fggc-zone.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fggc-zone.c?ref=b9bfca8100c3db821b58a88bea733d83d4bf2c28", "patch": "@@ -305,12 +305,37 @@ struct alloc_zone\n \n   /* True if this zone should be destroyed after the next collection.  */\n   bool dead;\n+\n+#ifdef GATHER_STATISTICS\n+  struct\n+  {\n+    /* Total memory allocated with ggc_alloc.  */\n+    unsigned long long total_allocated;\n+    /* Total overhead for memory to be allocated with ggc_alloc.  */\n+    unsigned long long total_overhead;\n+\n+    /* Total allocations and overhead for sizes less than 32, 64 and 128.\n+       These sizes are interesting because they are typical cache line\n+       sizes.  */\n+   \n+    unsigned long long total_allocated_under32;\n+    unsigned long long total_overhead_under32;\n+  \n+    unsigned long long total_allocated_under64;\n+    unsigned long long total_overhead_under64;\n+  \n+    unsigned long long total_allocated_under128;\n+    unsigned long long total_overhead_under128;\n+  } stats;\n+#endif\n } main_zone;\n \n struct alloc_zone *rtl_zone;\n struct alloc_zone *garbage_zone;\n struct alloc_zone *tree_zone;\n \n+static int always_collect;\n+\n /* Allocate pages in chunks of this size, to throttle calls to memory\n    allocation routines.  The first page is used, the rest go onto the\n    free list.  This cannot be larger than HOST_BITS_PER_INT for the\n@@ -569,14 +594,15 @@ free_chunk (struct alloc_chunk *chunk, size_t size, struct alloc_zone *zone)\n /* Allocate a chunk of memory of SIZE bytes.  */\n \n static void *\n-ggc_alloc_zone_1 (size_t size, struct alloc_zone *zone, short type\n+ggc_alloc_zone_1 (size_t orig_size, struct alloc_zone *zone, short type\n \t\t  MEM_STAT_DECL)\n {\n   size_t bin = 0;\n   size_t lsize = 0;\n   struct page_entry *entry;\n   struct alloc_chunk *chunk, *lchunk, **pp;\n   void *result;\n+  size_t size = orig_size;\n \n   /* Align size, so that we're assured of aligned allocations.  */\n   if (size < FREE_BIN_DELTA)\n@@ -662,9 +688,6 @@ ggc_alloc_zone_1 (size_t size, struct alloc_zone *zone, short type\n       free_chunk (lchunk, lsize, zone);\n       lsize = 0;\n     }\n-#ifdef GATHER_STATISTICS\n-  ggc_record_overhead (size, lsize PASS_MEM_STAT);\n-#endif\n \n   /* Calculate the object's address.  */\n  found:\n@@ -694,7 +717,35 @@ ggc_alloc_zone_1 (size_t size, struct alloc_zone *zone, short type\n \n   /* Keep track of how many bytes are being allocated.  This\n      information is used in deciding when to collect.  */\n-  zone->allocated += size + CHUNK_OVERHEAD;\n+  zone->allocated += size;\n+\n+#ifdef GATHER_STATISTICS\n+  ggc_record_overhead (orig_size, size + CHUNK_OVERHEAD - orig_size PASS_MEM_STAT);\n+\n+  {\n+    size_t object_size = size + CHUNK_OVERHEAD;\n+    size_t overhead = object_size - orig_size;\n+\n+    zone->stats.total_overhead += overhead;\n+    zone->stats.total_allocated += object_size;\n+\n+    if (orig_size <= 32)\n+      {\n+\tzone->stats.total_overhead_under32 += overhead;\n+\tzone->stats.total_allocated_under32 += object_size;\n+      }\n+    if (orig_size <= 64)\n+      {\n+\tzone->stats.total_overhead_under64 += overhead;\n+\tzone->stats.total_allocated_under64 += object_size;\n+      }\n+    if (orig_size <= 128)\n+      {\n+\tzone->stats.total_overhead_under128 += overhead;\n+\tzone->stats.total_allocated_under128 += object_size;\n+      }\n+  }\n+#endif\n \n   if (GGC_DEBUG_LEVEL >= 3)\n     fprintf (G.debug_file, \"Allocating object, chunk=%p size=%lu at %p\\n\",\n@@ -986,6 +1037,7 @@ sweep_pages (struct alloc_zone *zone)\n \t  if (((struct alloc_chunk *)p->page)->mark == 1)\n \t    {\n \t      ((struct alloc_chunk *)p->page)->mark = 0;\n+\t      allocated += p->bytes - CHUNK_OVERHEAD;\n \t      pp = &p->next;\n \t    }\n \t  else\n@@ -1030,7 +1082,7 @@ sweep_pages (struct alloc_zone *zone)\n \t\t}\n \t      if (chunk->mark)\n \t        {\n-\t          allocated += chunk->size + CHUNK_OVERHEAD;\n+\t          allocated += chunk->size;\n \t\t}\n \t      chunk->mark = 0;\n \t    }\n@@ -1083,21 +1135,6 @@ sweep_pages (struct alloc_zone *zone)\n static bool\n ggc_collect_1 (struct alloc_zone *zone, bool need_marking)\n {\n-  if (!zone->dead)\n-    {\n-      /* Avoid frequent unnecessary work by skipping collection if the\n-\t total allocations haven't expanded much since the last\n-\t collection.  */\n-      float allocated_last_gc =\n-\tMAX (zone->allocated_last_gc,\n-\t     (size_t) PARAM_VALUE (GGC_MIN_HEAPSIZE) * 1024);\n-\n-      float min_expand = allocated_last_gc * PARAM_VALUE (GGC_MIN_EXPAND) / 100;\n-\n-      if (zone->allocated < allocated_last_gc + min_expand)\n-\treturn false;\n-    }\n-\n   if (!quiet_flag)\n     fprintf (stderr, \" {%s GC %luk -> \",\n \t     zone->name, (unsigned long) zone->allocated / 1024);\n@@ -1183,6 +1220,29 @@ ggc_collect (void)\n \n   timevar_push (TV_GC);\n   check_cookies ();\n+\n+  if (!always_collect)\n+    {\n+      float allocated_last_gc = 0, allocated = 0, min_expand;\n+\n+      for (zone = G.zones; zone; zone = zone->next_zone)\n+\t{\n+\t  allocated_last_gc += zone->allocated_last_gc;\n+\t  allocated += zone->allocated;\n+\t}\n+\n+      allocated_last_gc =\n+\tMAX (allocated_last_gc,\n+\t     (size_t) PARAM_VALUE (GGC_MIN_HEAPSIZE) * 1024);\n+      min_expand = allocated_last_gc * PARAM_VALUE (GGC_MIN_EXPAND) / 100;\n+\n+      if (allocated < allocated_last_gc + min_expand)\n+\t{\n+\t  timevar_pop (TV_GC);\n+\t  return;\n+\t}\n+    }\n+\n   /* Start by possibly collecting the main zone.  */\n   main_zone.was_collected = false;\n   marked |= ggc_collect_1 (&main_zone, true);\n@@ -1195,6 +1255,8 @@ ggc_collect (void)\n      marking.  So if we mark twice as often as we used to, we'll be\n      twice as slow.  Hopefully we'll avoid this cost when we mark\n      zone-at-a-time.  */\n+  /* NOTE drow/2004-07-28: We now always collect the main zone, but\n+     keep this code in case the heuristics are further refined.  */\n \n   if (main_zone.was_collected)\n     {\n@@ -1281,10 +1343,158 @@ ggc_collect (void)\n }\n \n /* Print allocation statistics.  */\n+#define SCALE(x) ((unsigned long) ((x) < 1024*10 \\\n+\t\t  ? (x) \\\n+\t\t  : ((x) < 1024*1024*10 \\\n+\t\t     ? (x) / 1024 \\\n+\t\t     : (x) / (1024*1024))))\n+#define LABEL(x) ((x) < 1024*10 ? ' ' : ((x) < 1024*1024*10 ? 'k' : 'M'))\n \n void\n ggc_print_statistics (void)\n {\n+  struct alloc_zone *zone;\n+  struct ggc_statistics stats;\n+  size_t total_overhead = 0, total_allocated = 0, total_bytes_mapped = 0;\n+\n+  /* Clear the statistics.  */\n+  memset (&stats, 0, sizeof (stats));\n+\n+  /* Make sure collection will really occur, in all zones.  */\n+  always_collect = 1;\n+\n+  /* Collect and print the statistics common across collectors.  */\n+  ggc_print_common_statistics (stderr, &stats);\n+\n+  always_collect = 0;\n+\n+  /* Release free pages so that we will not count the bytes allocated\n+     there as part of the total allocated memory.  */\n+  for (zone = G.zones; zone; zone = zone->next_zone)\n+    release_pages (zone);\n+\n+  /* Collect some information about the various sizes of\n+     allocation.  */\n+  fprintf (stderr,\n+           \"Memory still allocated at the end of the compilation process\\n\");\n+\n+  fprintf (stderr, \"%20s %10s  %10s  %10s\\n\",\n+\t   \"Zone\", \"Allocated\", \"Used\", \"Overhead\");\n+  for (zone = G.zones; zone; zone = zone->next_zone)\n+    {\n+      page_entry *p;\n+      size_t allocated;\n+      size_t in_use;\n+      size_t overhead;\n+\n+      /* Skip empty entries.  */\n+      if (!zone->pages)\n+\tcontinue;\n+\n+      overhead = allocated = in_use = 0;\n+\n+      /* Figure out the total number of bytes allocated for objects of\n+\t this size, and how many of them are actually in use.  Also figure\n+\t out how much memory the page table is using.  */\n+      for (p = zone->pages; p; p = p->next)\n+\t{\n+\t  struct alloc_chunk *chunk;\n+\n+\t  /* We've also allocated sizeof (page_entry), but it's not in the\n+\t     \"managed\" area... */\n+\t  allocated += p->bytes;\n+\t  overhead += sizeof (page_entry);\n+\n+\t  if (p->large_p)\n+\t    {\n+\t      in_use += p->bytes - CHUNK_OVERHEAD;\n+\t      chunk = (struct alloc_chunk *) p->page;\n+\t      overhead += CHUNK_OVERHEAD;\n+\t      if (!chunk->type)\n+\t\tabort ();\n+\t      if (chunk->mark)\n+\t\tabort ();\n+\t      continue;\n+\t    }\n+\n+\t  for (chunk = (struct alloc_chunk *) p->page;\n+\t       (char *) chunk < (char *) p->page + p->bytes;\n+\t       chunk = (struct alloc_chunk *)(chunk->u.data + chunk->size))\n+\t    {\n+\t      overhead += CHUNK_OVERHEAD;\n+\t      if (chunk->type)\n+\t\tin_use += chunk->size;\n+\t      if (chunk->mark)\n+\t\tabort ();\n+\t    }\n+\t}\n+      fprintf (stderr, \"%20s %10lu%c %10lu%c %10lu%c\\n\",\n+\t       zone->name,\n+\t       SCALE (allocated), LABEL (allocated),\n+\t       SCALE (in_use), LABEL (in_use),\n+\t       SCALE (overhead), LABEL (overhead));\n+\n+      if (in_use != zone->allocated)\n+\tabort ();\n+\n+      total_overhead += overhead;\n+      total_allocated += zone->allocated;\n+      total_bytes_mapped += zone->bytes_mapped;\n+    }\n+\n+  fprintf (stderr, \"%20s %10lu%c %10lu%c %10lu%c\\n\", \"Total\",\n+\t   SCALE (total_bytes_mapped), LABEL (total_bytes_mapped),\n+\t   SCALE (total_allocated), LABEL(total_allocated),\n+\t   SCALE (total_overhead), LABEL (total_overhead));\n+\n+#ifdef GATHER_STATISTICS  \n+  {\n+    unsigned long long all_overhead = 0, all_allocated = 0;\n+    unsigned long long all_overhead_under32 = 0, all_allocated_under32 = 0;\n+    unsigned long long all_overhead_under64 = 0, all_allocated_under64 = 0;\n+    unsigned long long all_overhead_under128 = 0, all_allocated_under128 = 0;\n+\n+    fprintf (stderr, \"\\nTotal allocations and overheads during the compilation process\\n\");\n+\n+    for (zone = G.zones; zone; zone = zone->next_zone)\n+      {\n+\tall_overhead += zone->stats.total_overhead;\n+\tall_allocated += zone->stats.total_allocated;\n+\n+\tall_allocated_under32 += zone->stats.total_allocated_under32;\n+\tall_overhead_under32 += zone->stats.total_overhead_under32;\n+\n+\tall_allocated_under64 += zone->stats.total_allocated_under64;\n+\tall_overhead_under64 += zone->stats.total_overhead_under64;\n+\t\n+\tall_allocated_under128 += zone->stats.total_allocated_under128;\n+\tall_overhead_under128 += zone->stats.total_overhead_under128;\n+\n+\tfprintf (stderr, \"%20s:                  %10lld\\n\",\n+\t\t zone->name, zone->stats.total_allocated);\n+      }\n+\n+    fprintf (stderr, \"\\n\");\n+\n+    fprintf (stderr, \"Total Overhead:                        %10lld\\n\",\n+             all_overhead);\n+    fprintf (stderr, \"Total Allocated:                       %10lld\\n\",\n+             all_allocated);\n+\n+    fprintf (stderr, \"Total Overhead  under  32B:            %10lld\\n\",\n+             all_overhead_under32);\n+    fprintf (stderr, \"Total Allocated under  32B:            %10lld\\n\",\n+             all_allocated_under32);\n+    fprintf (stderr, \"Total Overhead  under  64B:            %10lld\\n\",\n+             all_overhead_under64);\n+    fprintf (stderr, \"Total Allocated under  64B:            %10lld\\n\",\n+             all_allocated_under64);\n+    fprintf (stderr, \"Total Overhead  under 128B:            %10lld\\n\",\n+             all_overhead_under128);\n+    fprintf (stderr, \"Total Allocated under 128B:            %10lld\\n\",\n+             all_allocated_under128);\n+  }\n+#endif\n }\n \n struct ggc_pch_data"}]}