{"sha": "db34470d17bd803cf74f747e7714f6029abd9b38", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZGIzNDQ3MGQxN2JkODAzY2Y3NGY3NDdlNzcxNGY2MDI5YWJkOWIzOA==", "commit": {"author": {"name": "Ghassan Shobaki", "email": "ghassan.shobaki@amd.com", "date": "2009-06-08T16:00:13Z"}, "committer": {"name": "Dwarakanath Rajagopal", "email": "dwarak@gcc.gnu.org", "date": "2009-06-08T16:00:13Z"}, "message": "2009-06-08  Ghassan Shobaki  <ghassan.shobaki@amd.com>\n            Dwarakanath Rajagopal  <dwarak.rajagopal@amd.com>\n        \n        * tree-ssa-loop-prefetch.c \n        (gather_memory_references): Introduced a counter for the number of \n        memory references.\n        (anything_to_prefetch_p): Introduced a counter for the number of \n        prefetches.\n        (is_loop_prefetching_profitable): New function with a cost model \n        for prefetching.\n        (loop_prefetch_arrays): Use the new cost model to determine if \n        prefetching is profitable.\n        * params.def (MIN_INSN_TO_PREFETCH_RATIO, \n        PREFETCH_MIN_INSN_TO_MEM_RATIO): New parameters.\n        * params.h (MIN_INSN_TO_PREFETCH_RATIO, \n        PREFETCH_MIN_INSN_TO_MEM_RATIO): New parameters.\n        * doc/invoke.texi (MIN_INSN_TO_PREFETCH_RATIO, \n        PREFETCH_MIN_INSN_TO_MEM_RATIO): New parameters.\n\n\nCo-Authored-By: Dwarakanath Rajagopal <dwarak.rajagopal@amd.com>\n\nFrom-SVN: r148277", "tree": {"sha": "c5aeb746f699ff4f72e543b2dfe4227803de6a85", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c5aeb746f699ff4f72e543b2dfe4227803de6a85"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/db34470d17bd803cf74f747e7714f6029abd9b38", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/db34470d17bd803cf74f747e7714f6029abd9b38", "html_url": "https://github.com/Rust-GCC/gccrs/commit/db34470d17bd803cf74f747e7714f6029abd9b38", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/db34470d17bd803cf74f747e7714f6029abd9b38/comments", "author": null, "committer": null, "parents": [{"sha": "b01630bb3d498de236ebcfffdeb243431776f311", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b01630bb3d498de236ebcfffdeb243431776f311", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b01630bb3d498de236ebcfffdeb243431776f311"}], "stats": {"total": 186, "additions": 160, "deletions": 26}, "files": [{"sha": "47126a1e649288b254fcabb10614f3e983b153f4", "filename": "gcc/ChangeLog", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=db34470d17bd803cf74f747e7714f6029abd9b38", "patch": "@@ -1,3 +1,22 @@\n+2009-06-08  Ghassan Shobaki  <ghassan.shobaki@amd.com>\n+            Dwarakanath Rajagopal  <dwarak.rajagopal@amd.com>\n+\t\n+\t* tree-ssa-loop-prefetch.c \n+\t(gather_memory_references): Introduced a counter for the number of \n+\tmemory references.\n+\t(anything_to_prefetch_p): Introduced a counter for the number of \n+\tprefetches.\n+\t(is_loop_prefetching_profitable): New function with a cost model \n+\tfor prefetching.\n+\t(loop_prefetch_arrays): Use the new cost model to determine if \n+\tprefetching is profitable.\n+\t* params.def (MIN_INSN_TO_PREFETCH_RATIO, \n+\tPREFETCH_MIN_INSN_TO_MEM_RATIO): New parameters.\n+\t* params.h (MIN_INSN_TO_PREFETCH_RATIO, \n+\tPREFETCH_MIN_INSN_TO_MEM_RATIO): New parameters.\n+\t* doc/invoke.texi (MIN_INSN_TO_PREFETCH_RATIO, \n+\tPREFETCH_MIN_INSN_TO_MEM_RATIO): New parameters.\n+\t\n 2009-06-08  Michael Matz  <matz@suse.de>\n \n \tPR debug/40012"}, {"sha": "8109cf3e7c7513beeb51b30c6e346a49d2bd3f68", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=db34470d17bd803cf74f747e7714f6029abd9b38", "patch": "@@ -7914,6 +7914,15 @@ The size of L1 cache, in kilobytes.\n @item l2-cache-size\n The size of L2 cache, in kilobytes.\n \n+@item min-insn-to-prefetch-ratio\n+The minimum ratio between the number of instructions and the \n+number of prefetches to enable prefetching in a loop with an \n+unknown trip count.\n+\n+@item prefetch-min-insn-to-mem-ratio\n+The minimum ratio between the number of instructions and the \n+number of memory references to enable prefetching in a loop.\n+\n @item use-canonical-types\n Whether the compiler should use the ``canonical'' type system.  By\n default, this should always be 1, which uses a more efficient internal"}, {"sha": "e3a6470120a339a726a42c37f2b64e4581253266", "filename": "gcc/params.def", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2Fparams.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2Fparams.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.def?ref=db34470d17bd803cf74f747e7714f6029abd9b38", "patch": "@@ -741,6 +741,17 @@ DEFPARAM (PARAM_SLP_MAX_INSNS_IN_BB,\n           \"Maximum number of instructions in basic block to be considered for SLP vectorization\",\n           1000, 0, 0)\n \n+DEFPARAM (PARAM_MIN_INSN_TO_PREFETCH_RATIO,\n+\t  \"min-insn-to-prefetch-ratio\",\n+\t  \"min. ratio of insns to prefetches to enable prefetching for \"\n+          \"a loop with an unknown trip count\",\n+\t  10, 0, 0)\n+\n+DEFPARAM (PARAM_PREFETCH_MIN_INSN_TO_MEM_RATIO,\n+\t  \"prefetch-min-insn-to-mem-ratio\",\n+\t  \"min. ratio of insns to mem ops to enable prefetching in a loop\",\n+\t  3, 0, 0)\n+\n /*\n Local variables:\n mode:c"}, {"sha": "a098fedc6e573d9c3bd7bc2ca3ff7288c6128cdf", "filename": "gcc/params.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2Fparams.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2Fparams.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fparams.h?ref=db34470d17bd803cf74f747e7714f6029abd9b38", "patch": "@@ -166,4 +166,8 @@ typedef enum compiler_param\n   PARAM_VALUE (PARAM_LOOP_INVARIANT_MAX_BBS_IN_LOOP)\n #define SLP_MAX_INSNS_IN_BB \\\n   PARAM_VALUE (PARAM_SLP_MAX_INSNS_IN_BB)\n+#define MIN_INSN_TO_PREFETCH_RATIO \\\n+  PARAM_VALUE (PARAM_MIN_INSN_TO_PREFETCH_RATIO)\n+#define PREFETCH_MIN_INSN_TO_MEM_RATIO \\\n+  PARAM_VALUE (PARAM_PREFETCH_MIN_INSN_TO_MEM_RATIO)\n #endif /* ! GCC_PARAMS_H */"}, {"sha": "dd5732069c71da012d0a215badc74b53da0454da", "filename": "gcc/tree-ssa-loop-prefetch.c", "status": "modified", "additions": 117, "deletions": 26, "changes": 143, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2Ftree-ssa-loop-prefetch.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/db34470d17bd803cf74f747e7714f6029abd9b38/gcc%2Ftree-ssa-loop-prefetch.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-prefetch.c?ref=db34470d17bd803cf74f747e7714f6029abd9b38", "patch": "@@ -109,6 +109,23 @@ along with GCC; see the file COPYING3.  If not see\n       prefetch instructions with guards in cases where 5) was not sufficient\n       to satisfy the constraints?\n \n+   The function is_loop_prefetching_profitable() implements a cost model\n+   to determine if prefetching is profitable for a given loop. The cost\n+   model has two heuristcs:\n+   1. A heuristic that determines whether the given loop has enough CPU\n+      ops that can be overlapped with cache missing memory ops.\n+      If not, the loop won't benefit from prefetching. This is implemented \n+      by requirung the ratio between the instruction count and the mem ref \n+      count to be above a certain minimum.\n+   2. A heuristic that disables prefetching in a loop with an unknown trip\n+      count if the prefetching cost is above a certain limit. The relative \n+      prefetching cost is estimated by taking the ratio between the\n+      prefetch count and the total intruction count (this models the I-cache\n+      cost).\n+   The limits used in these heuristics are defined as parameters with\n+   reasonable default values. Machine-specific default values will be \n+   added later.\n+ \n    Some other TODO:\n       -- write and use more general reuse analysis (that could be also used\n \t in other cache aimed loop optimizations)\n@@ -476,7 +493,7 @@ gather_memory_references_ref (struct loop *loop, struct mem_ref_group **refs,\n    true if there are no other memory references inside the loop.  */\n \n static struct mem_ref_group *\n-gather_memory_references (struct loop *loop, bool *no_other_refs)\n+gather_memory_references (struct loop *loop, bool *no_other_refs, unsigned *ref_count)\n {\n   basic_block *body = get_loop_body_in_dom_order (loop);\n   basic_block bb;\n@@ -487,6 +504,7 @@ gather_memory_references (struct loop *loop, bool *no_other_refs)\n   struct mem_ref_group *refs = NULL;\n \n   *no_other_refs = true;\n+  *ref_count = 0;\n \n   /* Scan the loop body in order, so that the former references precede the\n      later ones.  */\n@@ -513,11 +531,17 @@ gather_memory_references (struct loop *loop, bool *no_other_refs)\n \t  rhs = gimple_assign_rhs1 (stmt);\n \n \t  if (REFERENCE_CLASS_P (rhs))\n+\t    {\n \t    *no_other_refs &= gather_memory_references_ref (loop, &refs,\n \t\t\t\t\t\t\t    rhs, false, stmt);\n+\t    *ref_count += 1;\n+\t    }\n \t  if (REFERENCE_CLASS_P (lhs))\n+\t    {\n \t    *no_other_refs &= gather_memory_references_ref (loop, &refs,\n \t\t\t\t\t\t\t    lhs, true, stmt);\n+\t    *ref_count += 1;\n+\t    }\n \t}\n     }\n   free (body);\n@@ -846,20 +870,20 @@ schedule_prefetches (struct mem_ref_group *groups, unsigned unroll_factor,\n   return any;\n }\n \n-/* Determine whether there is any reference suitable for prefetching\n-   in GROUPS.  */\n+/* Estimate the number of prefetches in the given GROUPS.  */\n \n-static bool\n-anything_to_prefetch_p (struct mem_ref_group *groups)\n+static int\n+estimate_prefetch_count (struct mem_ref_group *groups)\n {\n   struct mem_ref *ref;\n+  int prefetch_count = 0;\n \n   for (; groups; groups = groups->next)\n     for (ref = groups->refs; ref; ref = ref->next)\n       if (should_issue_prefetch_p (ref))\n-\treturn true;\n+\t  prefetch_count++;\n \n-  return false;\n+  return prefetch_count;\n }\n \n /* Issue prefetches for the reference REF into loop as decided before.\n@@ -1449,6 +1473,71 @@ determine_loop_nest_reuse (struct loop *loop, struct mem_ref_group *refs,\n     }\n }\n \n+/* Do a cost-benefit analysis to determine if prefetching is profitable\n+   for the current loop given the following parameters:\n+   AHEAD: the iteration ahead distance,\n+   EST_NITER: the estimated trip count,  \n+   NINSNS: estimated number of instructions in the loop,\n+   PREFETCH_COUNT: an estimate of the number of prefetches\n+   MEM_REF_COUNT: total number of memory references in the loop.  */\n+\n+static bool \n+is_loop_prefetching_profitable (unsigned ahead, HOST_WIDE_INT est_niter, \n+\t\t\t\tunsigned ninsns, unsigned prefetch_count, \n+\t\t\t\tunsigned mem_ref_count)\n+{\n+  int insn_to_mem_ratio, insn_to_prefetch_ratio;\n+\n+  if (mem_ref_count == 0)\n+    return false;\n+\n+  /* Prefetching improves performance by overlapping cache missing \n+     memory accesses with CPU operations.  If the loop does not have \n+     enough CPU operations to overlap with memory operations, prefetching \n+     won't give a significant benefit.  One approximate way of checking \n+     this is to require the ratio of instructions to memory references to \n+     be above a certain limit.  This approximation works well in practice.\n+     TODO: Implement a more precise computation by estimating the time\n+     for each CPU or memory op in the loop. Time estimates for memory ops\n+     should account for cache misses.  */\n+  insn_to_mem_ratio = ninsns / mem_ref_count;  \n+\n+  if (insn_to_mem_ratio < PREFETCH_MIN_INSN_TO_MEM_RATIO)\n+    return false;\n+\n+  /* Profitability of prefetching is highly dependent on the trip count.\n+     For a given AHEAD distance, the first AHEAD iterations do not benefit \n+     from prefetching, and the last AHEAD iterations execute useless \n+     prefetches.  So, if the trip count is not large enough relative to AHEAD,\n+     prefetching may cause serious performance degradation.  To avoid this\n+     problem when the trip count is not known at compile time, we \n+     conservatively skip loops with high prefetching costs.  For now, only\n+     the I-cache cost is considered.  The relative I-cache cost is estimated \n+     by taking the ratio between the number of prefetches and the total\n+     number of instructions.  Since we are using integer arithmetic, we\n+     compute the reciprocal of this ratio.  \n+     TODO: Account for loop unrolling, which may reduce the costs of\n+     shorter stride prefetches.  Note that not accounting for loop \n+     unrolling over-estimates the cost and hence gives more conservative\n+     results.  */\n+  if (est_niter < 0)\n+    {\n+      insn_to_prefetch_ratio = ninsns / prefetch_count;      \n+      return insn_to_prefetch_ratio >= MIN_INSN_TO_PREFETCH_RATIO;\n+    }\n+       \n+  if (est_niter <= (HOST_WIDE_INT) ahead)\n+    {\n+      if (dump_file && (dump_flags & TDF_DETAILS))\n+\tfprintf (dump_file,\n+\t\t \"Not prefetching -- loop estimated to roll only %d times\\n\",\n+\t\t (int) est_niter);\n+      return false;\n+    }\n+  return true;\n+}\n+\n+\n /* Issue prefetch instructions for array references in LOOP.  Returns\n    true if the LOOP was unrolled.  */\n \n@@ -1460,6 +1549,8 @@ loop_prefetch_arrays (struct loop *loop)\n   HOST_WIDE_INT est_niter;\n   struct tree_niter_desc desc;\n   bool unrolled = false, no_other_refs;\n+  unsigned prefetch_count;\n+  unsigned mem_ref_count;\n \n   if (optimize_loop_nest_for_size_p (loop))\n     {\n@@ -1469,12 +1560,13 @@ loop_prefetch_arrays (struct loop *loop)\n     }\n \n   /* Step 1: gather the memory references.  */\n-  refs = gather_memory_references (loop, &no_other_refs);\n+  refs = gather_memory_references (loop, &no_other_refs, &mem_ref_count);\n \n   /* Step 2: estimate the reuse effects.  */\n   prune_by_reuse (refs);\n \n-  if (!anything_to_prefetch_p (refs))\n+  prefetch_count = estimate_prefetch_count (refs);\n+  if (prefetch_count == 0)\n     goto fail;\n \n   determine_loop_nest_reuse (loop, refs, no_other_refs);\n@@ -1485,27 +1577,22 @@ loop_prefetch_arrays (struct loop *loop)\n      the loop body.  */\n   time = tree_num_loop_insns (loop, &eni_time_weights);\n   ahead = (PREFETCH_LATENCY + time - 1) / time;\n-  est_niter = estimated_loop_iterations_int (loop, false);\n-\n-  /* The prefetches will run for AHEAD iterations of the original loop.  Unless\n-     the loop rolls at least AHEAD times, prefetching the references does not\n-     make sense.  */\n-  if (est_niter >= 0 && est_niter <= (HOST_WIDE_INT) ahead)\n-    {\n-      if (dump_file && (dump_flags & TDF_DETAILS))\n-\tfprintf (dump_file,\n-\t\t \"Not prefetching -- loop estimated to roll only %d times\\n\",\n-\t\t (int) est_niter);\n-      goto fail;\n-    }\n-\n-  mark_nontemporal_stores (loop, refs);\n+  est_niter = estimated_loop_iterations_int (loop, false);  \n \n   ninsns = tree_num_loop_insns (loop, &eni_size_weights);\n   unroll_factor = determine_unroll_factor (loop, refs, ninsns, &desc,\n \t\t\t\t\t   est_niter);\n   if (dump_file && (dump_flags & TDF_DETAILS))\n-    fprintf (dump_file, \"Ahead %d, unroll factor %d\\n\", ahead, unroll_factor);\n+    fprintf (dump_file, \"Ahead %d, unroll factor %d, trip count %ld\\n\"\n+\t     \"insn count %d, mem ref count %d, prefetch count %d\\n\", \n+\t     ahead, unroll_factor, est_niter, ninsns, mem_ref_count, \n+\t     prefetch_count);\n+\n+  if (!is_loop_prefetching_profitable (ahead, est_niter, ninsns, \n+\t\t\t\t       prefetch_count, mem_ref_count))\n+    goto fail;\n+\n+  mark_nontemporal_stores (loop, refs);\n \n   /* Step 4: what to prefetch?  */\n   if (!schedule_prefetches (refs, unroll_factor, ahead))\n@@ -1556,7 +1643,11 @@ tree_ssa_prefetch_arrays (void)\n       fprintf (dump_file, \"    L1 cache size: %d lines, %d kB\\n\",\n \t       L1_CACHE_SIZE_BYTES / L1_CACHE_LINE_SIZE, L1_CACHE_SIZE);\n       fprintf (dump_file, \"    L1 cache line size: %d\\n\", L1_CACHE_LINE_SIZE);\n-      fprintf (dump_file, \"    L2 cache size: %d kB\\n\", L2_CACHE_SIZE);\n+      fprintf (dump_file, \"    L2 cache size: %d kB\\n\", L2_CACHE_SIZE);      \n+      fprintf (dump_file, \"    min insn-to-prefetch ratio: %d \\n\", \n+\t       MIN_INSN_TO_PREFETCH_RATIO);\n+      fprintf (dump_file, \"    min insn-to-mem ratio: %d \\n\", \n+\t       PREFETCH_MIN_INSN_TO_MEM_RATIO);\n       fprintf (dump_file, \"\\n\");\n     }\n "}]}