{"sha": "b38ba46301ac50a5c0d8c93953aa150d748bff8b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjM4YmE0NjMwMWFjNTBhNWMwZDhjOTM5NTNhYTE1MGQ3NDhiZmY4Yg==", "commit": {"author": {"name": "Zack Weinberg", "email": "zack@gcc.gnu.org", "date": "2003-10-29T00:55:43Z"}, "committer": {"name": "Zack Weinberg", "email": "zack@gcc.gnu.org", "date": "2003-10-29T00:55:43Z"}, "message": "ia64.md (UNSPEC_SETF_EXP,UNSPEC_FR_SQRT_RECIP_APPROX): New constants.\n\n\t* ia64.md (UNSPEC_SETF_EXP,UNSPEC_FR_SQRT_RECIP_APPROX): New constants.\n\t(*sqrt_approx): New instruction pattern for approximate square roots.\n\t(*setf_exp_xf): New instruction pattern for exponentiation.\n\t(*maddxf4_alts_truncsf): New instruction pattern for truncation.\n\t(sqrtsf2_internal_thr): New define_and_split implementing\n\tthroughput-optimized inline calculation of SFmode square root.\n\t(sqrtdf2_internal_thr): Likewise for DFmode.\n\t(sqrtxf2_internal_thr): Likewise for XFmode.\n\t(sqrtsf2, sqrtdf2, sqrtxf2): New expanders to choose between\n\tlatency- and throughput-optimized square root algorithms.\n\t* ia64.h (MASK_INLINE_SQRT_LAT, MASK_INLINE_SQRT_THR,\n\tTARGET_INLINE_SQRT_LAT, TARGET_INLINE_SQRT_THR, TARGET_INLINE_SQRT):\n\tNew macros.\n\t(TARGET_SWITCHES): Add -minline-sqrt-min-latency and\n\t-minline-sqrt-max-throughput.\n\t* ia64.c (ia64_override_options): If both -minline-sqrt-min-latency\n\tand -minline-sqrt-max-throughput are given, notify the user\n\tthat both options cannot be used simultaneously.\n\tIf -minline-sqrt-min-latency is given, notify the user that\n\tthis mode is not yet implemented.\n\t(rtx_needs_barrier): Reformat initial comment to obey\n\t72-character width limit.  Support UNSPEC_SETF_EXP and\n\tUNSPEC_FR_SQRT_RECIP_APPROX.\n\nFrom-SVN: r73027", "tree": {"sha": "ef98c209a92bd82779ac5da489d6ce4b266ce19a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ef98c209a92bd82779ac5da489d6ce4b266ce19a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b38ba46301ac50a5c0d8c93953aa150d748bff8b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b38ba46301ac50a5c0d8c93953aa150d748bff8b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b38ba46301ac50a5c0d8c93953aa150d748bff8b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b38ba46301ac50a5c0d8c93953aa150d748bff8b/comments", "author": null, "committer": null, "parents": [{"sha": "1e8fee4a4272759c129f4f884d0288b98cb4943a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1e8fee4a4272759c129f4f884d0288b98cb4943a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1e8fee4a4272759c129f4f884d0288b98cb4943a"}], "stats": {"total": 538, "additions": 534, "deletions": 4}, "files": [{"sha": "585e25b6aefd6f478108374f2ca17b8fd1cc8bc9", "filename": "gcc/ChangeLog", "status": "modified", "additions": 27, "deletions": 1, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b38ba46301ac50a5c0d8c93953aa150d748bff8b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b38ba46301ac50a5c0d8c93953aa150d748bff8b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b38ba46301ac50a5c0d8c93953aa150d748bff8b", "patch": "@@ -1,3 +1,29 @@\n+2003-10-28  Zack Weinberg  <zack@codesourcery.com>\n+\n+\t* ia64.md (UNSPEC_SETF_EXP,UNSPEC_FR_SQRT_RECIP_APPROX): New constants.\n+\t(*sqrt_approx): New instruction pattern for approximate square roots.\n+\t(*setf_exp_xf): New instruction pattern for exponentiation.\n+\t(*maddxf4_alts_truncsf): New instruction pattern for truncation.\n+\t(sqrtsf2_internal_thr): New define_and_split implementing\n+\tthroughput-optimized inline calculation of SFmode square root.\n+\t(sqrtdf2_internal_thr): Likewise for DFmode.\n+\t(sqrtxf2_internal_thr): Likewise for XFmode.\n+\t(sqrtsf2, sqrtdf2, sqrtxf2): New expanders to choose between\n+\tlatency- and throughput-optimized square root algorithms.\n+\t* ia64.h (MASK_INLINE_SQRT_LAT, MASK_INLINE_SQRT_THR,\n+\tTARGET_INLINE_SQRT_LAT, TARGET_INLINE_SQRT_THR, TARGET_INLINE_SQRT):\n+\tNew macros.\n+\t(TARGET_SWITCHES): Add -minline-sqrt-min-latency and\n+\t-minline-sqrt-max-throughput.\n+\t* ia64.c (ia64_override_options): If both -minline-sqrt-min-latency\n+\tand -minline-sqrt-max-throughput are given, notify the user\n+\tthat both options cannot be used simultaneously.\n+\tIf -minline-sqrt-min-latency is given, notify the user that\n+\tthis mode is not yet implemented.\n+\t(rtx_needs_barrier): Reformat initial comment to obey\n+\t72-character width limit.  Support UNSPEC_SETF_EXP and\n+\tUNSPEC_FR_SQRT_RECIP_APPROX.\n+\n 2003-10-29  Alan Modra  <amodra@bigpond.net.au>\n \n \t* config/rs6000/rs6000.md (movdf_softfloat64): Allow dummy ctr,ctr\n@@ -12,7 +38,7 @@\n 2003-10-28  Richard Earnshaw  <rearnsha@arm.com>\n \n \t* arm.c (arm_output_epilogue): When using a frame pointer, don't emit\n-\tan extra stack adjustment insn if the stack pointer is already \n+\tan extra stack adjustment insn if the stack pointer is already\n \tpointing at the right place.\n \t(use_return_insn): Allow a return insn to be used when we have a\n \tframe pointer if the stack pointer is in the right place."}, {"sha": "a25c4c5a83d2d190ac6217ec3989d58fb77b2793", "filename": "gcc/config/ia64/ia64.c", "status": "modified", "additions": 17, "deletions": 3, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b38ba46301ac50a5c0d8c93953aa150d748bff8b/gcc%2Fconfig%2Fia64%2Fia64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b38ba46301ac50a5c0d8c93953aa150d748bff8b/gcc%2Fconfig%2Fia64%2Fia64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.c?ref=b38ba46301ac50a5c0d8c93953aa150d748bff8b", "patch": "@@ -4487,6 +4487,18 @@ ia64_override_options (void)\n       target_flags &= ~MASK_INLINE_INT_DIV_THR;\n     }\n \n+  if (TARGET_INLINE_SQRT_LAT && TARGET_INLINE_SQRT_THR)\n+    {\n+      warning (\"cannot optimize square root for both latency and throughput\");\n+      target_flags &= ~MASK_INLINE_SQRT_THR;\n+    }\n+\n+  if (TARGET_INLINE_SQRT_LAT)\n+    {\n+      warning (\"not yet implemented: latency-optimized inline square root\");\n+      target_flags &= ~MASK_INLINE_SQRT_LAT;\n+    }\n+\n   if (ia64_fixed_range_string)\n     fix_range (ia64_fixed_range_string);\n \n@@ -4896,9 +4908,9 @@ set_src_needs_barrier (rtx x, struct reg_flags flags, int pred, rtx cond)\n   return need_barrier;\n }\n \n-/* Handle an access to rtx X of type FLAGS using predicate register PRED.\n-   Return 1 is this access creates a dependency with an earlier instruction\n-   in the same group.  */\n+/* Handle an access to rtx X of type FLAGS using predicate register\n+   PRED.  Return 1 if this access creates a dependency with an earlier\n+   instruction in the same group.  */\n \n static int\n rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n@@ -5124,7 +5136,9 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n \tcase UNSPEC_FR_SPILL:\n \tcase UNSPEC_FR_RESTORE:\n \tcase UNSPEC_GETF_EXP:\n+\tcase UNSPEC_SETF_EXP:\n         case UNSPEC_ADDP4:\n+\tcase UNSPEC_FR_SQRT_RECIP_APPROX:\n \t  need_barrier = rtx_needs_barrier (XVECEXP (x, 0, 0), flags, pred);\n \t  break;\n "}, {"sha": "44ef6c6e1e9784f5c5c34f0a0431f00e88ecf840", "filename": "gcc/config/ia64/ia64.h", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b38ba46301ac50a5c0d8c93953aa150d748bff8b/gcc%2Fconfig%2Fia64%2Fia64.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b38ba46301ac50a5c0d8c93953aa150d748bff8b/gcc%2Fconfig%2Fia64%2Fia64.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.h?ref=b38ba46301ac50a5c0d8c93953aa150d748bff8b", "patch": "@@ -87,6 +87,10 @@ extern int target_flags;\n \n #define MASK_INLINE_INT_DIV_THR   0x00001000 /* inline div, max throughput.  */\n \n+#define MASK_INLINE_SQRT_LAT      0x00002000 /* inline sqrt, min latency.  */\n+\n+#define MASK_INLINE_SQRT_THR      0x00004000 /* inline sqrt, max throughput. */\n+\n #define MASK_DWARF2_ASM 0x40000000\t/* test dwarf2 line info via gas.  */\n \n #define MASK_EARLY_STOP_BITS 0x00002000 /* tune stop bits for the model.  */\n@@ -127,6 +131,13 @@ extern int target_flags;\n #define TARGET_INLINE_INT_DIV \\\n   (target_flags & (MASK_INLINE_INT_DIV_LAT | MASK_INLINE_INT_DIV_THR))\n \n+#define TARGET_INLINE_SQRT_LAT (target_flags & MASK_INLINE_SQRT_LAT)\n+\n+#define TARGET_INLINE_SQRT_THR (target_flags & MASK_INLINE_SQRT_THR)\n+\n+#define TARGET_INLINE_SQRT \\\n+  (target_flags & (MASK_INLINE_SQRT_LAT | MASK_INLINE_SQRT_THR))\n+\n #define TARGET_DWARF2_ASM\t(target_flags & MASK_DWARF2_ASM)\n \n extern int ia64_tls_size;\n@@ -186,6 +197,10 @@ extern int ia64_tls_size;\n       N_(\"Generate inline integer division, optimize for latency\") },\t\\\n   { \"inline-int-divide-max-throughput\", MASK_INLINE_INT_DIV_THR,\t\\\n       N_(\"Generate inline integer division, optimize for throughput\") },\\\n+  { \"inline-sqrt-min-latency\", MASK_INLINE_SQRT_LAT,\t\t\t\\\n+      N_(\"Generate inline square root, optimize for latency\") },\t\\\n+  { \"inline-sqrt-max-throughput\", MASK_INLINE_SQRT_THR,\t\t\t\\\n+      N_(\"Generate inline square root, optimize for throughput\") },     \\\n   { \"dwarf2-asm\", \tMASK_DWARF2_ASM,\t\t\t\t\\\n       N_(\"Enable Dwarf 2 line debug info via GNU as\")},\t\t\t\\\n   { \"no-dwarf2-asm\", \t-MASK_DWARF2_ASM,\t\t\t\t\\"}, {"sha": "ec66fd5a77de3e625ca9863d38667b9d896263fa", "filename": "gcc/config/ia64/ia64.md", "status": "modified", "additions": 475, "deletions": 0, "changes": 475, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b38ba46301ac50a5c0d8c93953aa150d748bff8b/gcc%2Fconfig%2Fia64%2Fia64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b38ba46301ac50a5c0d8c93953aa150d748bff8b/gcc%2Fconfig%2Fia64%2Fia64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.md?ref=b38ba46301ac50a5c0d8c93953aa150d748bff8b", "patch": "@@ -74,6 +74,8 @@\n    (UNSPEC_ADDP4\t\t24)\n    (UNSPEC_PROLOGUE_USE\t\t25)\n    (UNSPEC_RET_ADDR\t\t26)\n+   (UNSPEC_SETF_EXP             27)\n+   (UNSPEC_FR_SQRT_RECIP_APPROX 28)\n   ])\n \n (define_constants\n@@ -2757,6 +2759,155 @@\n   operands[10] = CONST1_RTX (XFmode);\n }\n   [(set_attr \"predicable\" \"no\")])\n+\n+;; Inline square root.\n+\n+(define_insn \"*sqrt_approx\"\n+  [(set (match_operand:XF 0 \"fr_register_operand\" \"=f\")\n+        (div:XF (const_int 1)\n+                (sqrt:XF (match_operand:XF 2 \"fr_register_operand\" \"f\"))))\n+   (set (match_operand:BI 1 \"register_operand\" \"=c\")\n+        (unspec:BI [(match_dup 2)] UNSPEC_FR_SQRT_RECIP_APPROX))\n+   (use (match_operand:SI 3 \"const_int_operand\" \"\")) ]\n+  \"\"\n+  \"frsqrta.s%3 %0, %1 = %2\"\n+  [(set_attr \"itanium_class\" \"fmisc\")\n+   (set_attr \"predicable\" \"no\")])\n+\n+(define_insn \"*setf_exp_xf\"\n+  [(set (match_operand:XF 0 \"fr_register_operand\" \"=f\")\n+        (unspec:XF [(match_operand:DI 1 \"register_operand\" \"r\")]\n+                  UNSPEC_SETF_EXP))]\n+  \"\"\n+  \"setf.exp %0 = %1\"\n+  [(set_attr \"itanium_class\" \"frfr\")])\n+\n+(define_expand \"sqrtsf2\"\n+  [(set (match_operand:SF 0 \"fr_register_operand\" \"=&f\")\n+\t(sqrt:SF (match_operand:SF 1 \"fr_register_operand\" \"f\")))]\n+  \"TARGET_INLINE_SQRT\"\n+{\n+  rtx insn;\n+  if (TARGET_INLINE_SQRT_LAT)\n+#if 0\n+    insn = gen_sqrtsf2_internal_lat (operands[0], operands[1]);\n+#else\n+    abort ();\n+#endif\n+  else\n+    insn = gen_sqrtsf2_internal_thr (operands[0], operands[1]);\n+  emit_insn (insn);\n+  DONE;\n+})\n+\n+;; Latency-optimized square root.\n+;; FIXME: Implement.\n+\n+;; Throughput-optimized square root.\n+\n+(define_insn_and_split \"sqrtsf2_internal_thr\"\n+  [(set (match_operand:SF 0 \"fr_register_operand\" \"=&f\")\n+\t(sqrt:SF (match_operand:SF 1 \"fr_register_operand\" \"f\")))\n+   ;; Register r2 in optimization guide.\n+   (clobber (match_scratch:DI 2 \"=r\"))\n+   ;; Register f8 in optimization guide\n+   (clobber (match_scratch:XF 3 \"=&f\"))\n+   ;; Register f9 in optimization guide\n+   (clobber (match_scratch:XF 4 \"=&f\"))\n+   ;; Register f10 in optimization guide\n+   (clobber (match_scratch:XF 5 \"=&f\"))\n+   ;; Register p6 in optimization guide.\n+   (clobber (match_scratch:BI 6 \"=c\"))]\n+  \"TARGET_INLINE_SQRT_THR\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [ ;; exponent of +1/2 in r2\n+    (set (match_dup 2) (const_int 65534))\n+    ;; +1/2 in f8\n+    (set (match_dup 3) \n+         (unspec:XF [(match_dup 2)] UNSPEC_SETF_EXP))\n+    ;; Step 1\n+    ;; y0 = 1/sqrt(a) in f7\n+    (parallel [(set (match_dup 7)\n+                    (div:XF (const_int 1)\n+                            (sqrt:XF (match_dup 8))))\n+               (set (match_dup 6)\n+                    (unspec:BI [(match_dup 8)]\n+                                 UNSPEC_FR_SQRT_RECIP_APPROX))\n+               (use (const_int 0))])\n+    ;; Step 2\n+    ;; H0 = 1/2 * y0 in f9\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+      (parallel [(set (match_dup 4)\n+                      (plus:XF (mult:XF (match_dup 3) (match_dup 7))\n+                               (match_dup 9)))\n+                 (use (const_int 1))]))\n+    ;; Step 3\n+    ;; S0 = a * y0 in f7\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+      (parallel [(set (match_dup 7)\n+                      (plus:XF (mult:XF (match_dup 8) (match_dup 7))\n+                               (match_dup 9)))\n+                 (use (const_int 1))]))\n+    ;; Step 4\n+    ;; d = 1/2 - S0 * H0 in f10\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+      (parallel [(set (match_dup 5)\n+                      (plus:XF (neg:XF (mult:XF (match_dup 7) (match_dup 4)))\n+                               (match_dup 3)))\n+                 (use (const_int 1))]))\n+    ;; Step 5\n+    ;; d' = d + 1/2 * d in f8\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 3)\n+                       (plus:XF (mult:XF (match_dup 3) (match_dup 5))\n+                                (match_dup 5)))\n+                  (use (const_int 1))]))\n+    ;; Step 6\n+    ;; e = d + d * d' in f8\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 3)\n+                       (plus:XF (mult:XF (match_dup 5) (match_dup 3))\n+                                (match_dup 5)))\n+                  (use (const_int 1))]))\n+    ;; Step 7\n+    ;; S1 = S0 + e * S0 in f7\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+      (parallel [(set (match_dup 0)\n+\t\t      (float_truncate:SF\n+                        (plus:XF (mult:XF (match_dup 3) (match_dup 7))\n+                                 (match_dup 7))))\n+                 (use (const_int 1))]))\n+    ;; Step 8\n+    ;; H1 = H0 + e * H0 in f8\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 3)\n+                       (plus:XF (mult:XF (match_dup 3) (match_dup 4))\n+                                (match_dup 4)))\n+                  (use (const_int 1))]))\n+    ;; Step 9 \n+    ;; d1 = a - S1 * S1 in f9\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 4)\n+                       (plus:XF (neg:XF (mult:XF (match_dup 7) (match_dup 7)))\n+                                (match_dup 8)))\n+                  (use (const_int 1))]))\n+    ;; Step 10\n+    ;; S = S1 + d1 * H1 in f7\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 0)\n+                       (float_truncate:SF\n+                         (plus:XF (mult:XF (match_dup 4) (match_dup 3))\n+                                  (match_dup 7))))\n+                  (use (const_int 0))]))]\n+{\n+  /* Generate 82-bit versions of the input and output operands.  */\n+  operands[7] = gen_rtx_REG (XFmode, REGNO (operands[0]));\n+  operands[8] = gen_rtx_REG (XFmode, REGNO (operands[1]));\n+  /* Generate required floating-point constants.  */\n+  operands[9] = CONST0_RTX (XFmode);\n+}\n+  [(set_attr \"predicable\" \"no\")])\n \f\n ;; ::::::::::::::::::::\n ;; ::\n@@ -3102,6 +3253,155 @@\n   operands[10] = CONST1_RTX (XFmode);\n }\n   [(set_attr \"predicable\" \"no\")])\n+\n+;; Inline square root.\n+\n+(define_expand \"sqrtdf2\"\n+  [(set (match_operand:DF 0 \"fr_register_operand\" \"=&f\")\n+\t(sqrt:DF (match_operand:DF 1 \"fr_register_operand\" \"f\")))]\n+  \"TARGET_INLINE_SQRT\"\n+{\n+  rtx insn;\n+  if (TARGET_INLINE_SQRT_LAT)\n+#if 0\n+    insn = gen_sqrtdf2_internal_lat (operands[0], operands[1]);\n+#else\n+    abort ();\n+#endif\n+  else\n+    insn = gen_sqrtdf2_internal_thr (operands[0], operands[1]);\n+  emit_insn (insn);\n+  DONE;\n+})\n+\n+;; Latency-optimized square root.\n+;; FIXME: Implement.\n+\n+;; Throughput-optimized square root.\n+\n+(define_insn_and_split \"sqrtdf2_internal_thr\"\n+  [(set (match_operand:DF 0 \"fr_register_operand\" \"=&f\")\n+\t(sqrt:DF (match_operand:DF 1 \"fr_register_operand\" \"f\")))\n+   ;; Register r2 in optimization guide.\n+   (clobber (match_scratch:DI 2 \"=r\"))\n+   ;; Register f8 in optimization guide\n+   (clobber (match_scratch:XF 3 \"=&f\"))\n+   ;; Register f9 in optimization guide\n+   (clobber (match_scratch:XF 4 \"=&f\"))\n+   ;; Register f10 in optimization guide\n+   (clobber (match_scratch:XF 5 \"=&f\"))\n+   ;; Register p6 in optimization guide.\n+   (clobber (match_scratch:BI 6 \"=c\"))]\n+  \"TARGET_INLINE_SQRT_THR\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [ ;; exponent of +1/2 in r2\n+    (set (match_dup 2) (const_int 65534))\n+    ;; +1/2 in f10\n+    (set (match_dup 5) \n+         (unspec:XF [(match_dup 2)] UNSPEC_SETF_EXP))\n+    ;; Step 1\n+    ;; y0 = 1/sqrt(a) in f7\n+    (parallel [(set (match_dup 7)\n+                    (div:XF (const_int 1)\n+                            (sqrt:XF (match_dup 8))))\n+               (set (match_dup 6)\n+                    (unspec:BI [(match_dup 8)]\n+                                 UNSPEC_FR_SQRT_RECIP_APPROX))\n+               (use (const_int 0))])\n+    ;; Step 2\n+    ;; H0 = 1/2 * y0 in f8\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+      (parallel [(set (match_dup 3)\n+                      (plus:XF (mult:XF (match_dup 5) (match_dup 7))\n+                               (match_dup 9)))\n+                 (use (const_int 1))]))\n+    ;; Step 3\n+    ;; G0 = a * y0 in f7\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+      (parallel [(set (match_dup 7)\n+                      (plus:XF (mult:XF (match_dup 8) (match_dup 7))\n+                               (match_dup 9)))\n+                 (use (const_int 1))]))\n+    ;; Step 4\n+    ;; r0 = 1/2 - G0 * H0 in f9\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+      (parallel [(set (match_dup 4)\n+                      (plus:XF (neg:XF (mult:XF (match_dup 7) (match_dup 3)))\n+                               (match_dup 5)))\n+                 (use (const_int 1))]))\n+    ;; Step 5\n+    ;; H1 = H0 + r0 * H0 in f8\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 3)\n+                       (plus:XF (mult:XF (match_dup 4) (match_dup 3))\n+                                (match_dup 3)))\n+                  (use (const_int 1))]))\n+    ;; Step 6\n+    ;; G1 = G0 + r0 * G0 in f7\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 7)\n+                       (plus:XF (mult:XF (match_dup 4) (match_dup 7))\n+                                (match_dup 7)))\n+                  (use (const_int 1))]))\n+    ;; Step 7\n+    ;; r1 = 1/2 - G1 * H1 in f9\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+      (parallel [(set (match_dup 4)\n+                      (plus:XF (neg:XF (mult:XF (match_dup 7) (match_dup 3)))\n+                               (match_dup 5)))\n+                 (use (const_int 1))]))\n+    ;; Step 8\n+    ;; H2 = H1 + r1 * H1 in f8\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 3)\n+                       (plus:XF (mult:XF (match_dup 4) (match_dup 3))\n+                                (match_dup 3)))\n+                  (use (const_int 1))]))\n+    ;; Step 9 \n+    ;; G2 = G1 + r1 * G1 in f7\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 7)\n+                       (plus:XF (mult:XF (match_dup 4) (match_dup 7))\n+                                (match_dup 7)))\n+                  (use (const_int 1))]))\n+    ;; Step 10\n+    ;; d2 = a - G2 * G2 in f9\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 4)\n+                       (plus:XF (neg:XF (mult:XF (match_dup 7) (match_dup 7)))\n+                                (match_dup 8)))\n+                  (use (const_int 1))]))\n+    ;; Step 11\n+    ;; G3 = G2 + d2 * H2 in f7\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 7)\n+                       (plus:XF (mult:XF (match_dup 4) (match_dup 3))\n+                                (match_dup 7)))\n+                  (use (const_int 1))]))\n+    ;; Step 12\n+    ;; d3 = a - G3 * G3 in f9\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 4)\n+                       (plus:XF (neg:XF (mult:XF (match_dup 7) (match_dup 7)))\n+                                (match_dup 8)))\n+                  (use (const_int 1))]))\n+    ;; Step 13\n+    ;; S = G3 + d3 * H2 in f7\n+    (cond_exec (ne (match_dup 6) (const_int 0))\n+       (parallel [(set (match_dup 0)\n+                       (float_truncate:DF\n+                         (plus:XF (mult:XF (match_dup 4) (match_dup 3))\n+                                  (match_dup 7))))\n+                  (use (const_int 0))]))]\n+{\n+  /* Generate 82-bit versions of the input and output operands.  */\n+  operands[7] = gen_rtx_REG (XFmode, REGNO (operands[0]));\n+  operands[8] = gen_rtx_REG (XFmode, REGNO (operands[1]));\n+  /* Generate required floating-point constants.  */\n+  operands[9] = CONST0_RTX (XFmode);\n+}\n+  [(set_attr \"predicable\" \"no\")])\n \f\n ;; ::::::::::::::::::::\n ;; ::\n@@ -3292,6 +3592,17 @@\n   \"fma.s%4 %0 = %F1, %F2, %F3\"\n   [(set_attr \"itanium_class\" \"fmac\")])\n \n+(define_insn \"*maddxf4_alts_truncsf\"\n+  [(set (match_operand:SF 0 \"fr_register_operand\" \"=f\")\n+\t(float_truncate:SF\n+\t  (plus:XF (mult:XF (match_operand:XF 1 \"xfreg_or_fp01_operand\" \"fG\")\n+\t\t\t    (match_operand:XF 2 \"xfreg_or_fp01_operand\" \"fG\"))\n+\t\t   (match_operand:XF 3 \"xfreg_or_fp01_operand\" \"fG\"))))\n+   (use (match_operand:SI 4 \"const_int_operand\" \"\"))]\n+  \"\"\n+  \"fma.s.s%4 %0 = %F1, %F2, %F3\"\n+  [(set_attr \"itanium_class\" \"fmac\")])\n+\n (define_insn \"*maddxf4_alts_truncdf\"\n   [(set (match_operand:DF 0 \"fr_register_operand\" \"=f\")\n \t(float_truncate:DF\n@@ -3591,6 +3902,170 @@\n   \"operands[6] = CONST1_RTX (XFmode);\"\n   [(set_attr \"predicable\" \"no\")])\n \n+;; Inline square root.\n+\n+(define_expand \"sqrtxf2\"\n+  [(set (match_operand:XF 0 \"fr_register_operand\" \"=&f\")\n+\t(sqrt:XF (match_operand:XF 1 \"fr_register_operand\" \"f\")))]\n+  \"TARGET_INLINE_SQRT\"\n+{\n+  rtx insn;\n+  if (TARGET_INLINE_SQRT_LAT)\n+#if 0\n+    insn = gen_sqrtxf2_internal_lat (operands[0], operands[1]);\n+#else\n+    abort ();\n+#endif\n+  else\n+    insn = gen_sqrtxf2_internal_thr (operands[0], operands[1]);\n+  emit_insn (insn);\n+  DONE;\n+})\n+\n+;; Latency-optimized square root.\n+;; FIXME: Implement.\n+\n+;; Throughput-optimized square root.\n+\n+(define_insn_and_split \"sqrtxf2_internal_thr\"\n+  [(set (match_operand:XF 0 \"fr_register_operand\" \"=&f\")\n+\t(sqrt:XF (match_operand:XF 1 \"fr_register_operand\" \"f\")))\n+   ;; Register r2 in optimization guide.\n+   (clobber (match_scratch:DI 2 \"=r\"))\n+   ;; Register f8 in optimization guide\n+   (clobber (match_scratch:XF 3 \"=&f\"))\n+   ;; Register f9 in optimization guide\n+   (clobber (match_scratch:XF 4 \"=&f\"))\n+   ;; Register f10 in optimization guide\n+   (clobber (match_scratch:XF 5 \"=&f\"))\n+   ;; Register f11 in optimization guide\n+   (clobber (match_scratch:XF 6 \"=&f\"))\n+   ;; Register p6 in optimization guide.\n+   (clobber (match_scratch:BI 7 \"=c\"))]\n+  \"TARGET_INLINE_SQRT_THR\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [ ;; exponent of +1/2 in r2\n+    (set (match_dup 2) (const_int 65534))\n+    ;; +1/2 in f8.  The Intel manual mistakenly specifies f10.\n+    (set (match_dup 3) \n+         (unspec:XF [(match_dup 2)] UNSPEC_SETF_EXP))\n+    ;; Step 1\n+    ;; y0 = 1/sqrt(a) in f7\n+    (parallel [(set (match_dup 8)\n+                    (div:XF (const_int 1)\n+                            (sqrt:XF (match_dup 9))))\n+               (set (match_dup 7)\n+                    (unspec:BI [(match_dup 9)]\n+                                 UNSPEC_FR_SQRT_RECIP_APPROX))\n+               (use (const_int 0))])\n+    ;; Step 2\n+    ;; H0 = 1/2 * y0 in f9\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+      (parallel [(set (match_dup 4)\n+                      (plus:XF (mult:XF (match_dup 3) (match_dup 8))\n+                               (match_dup 10)))\n+                 (use (const_int 1))]))\n+    ;; Step 3\n+    ;; S0 = a * y0 in f7\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+      (parallel [(set (match_dup 8)\n+                      (plus:XF (mult:XF (match_dup 9) (match_dup 8))\n+                               (match_dup 10)))\n+                 (use (const_int 1))]))\n+    ;; Step 4\n+    ;; d0 = 1/2 - S0 * H0 in f10\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+      (parallel [(set (match_dup 5)\n+                      (plus:XF (neg:XF (mult:XF (match_dup 8) (match_dup 4)))\n+                               (match_dup 3)))\n+                 (use (const_int 1))]))\n+    ;; Step 5\n+    ;; H1 = H0 + d0 * H0 in f9\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 4)\n+                       (plus:XF (mult:XF (match_dup 5) (match_dup 4))\n+                                (match_dup 4)))\n+                  (use (const_int 1))]))\n+    ;; Step 6\n+    ;; S1 = S0 + d0 * S0 in f7\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 8)\n+                       (plus:XF (mult:XF (match_dup 5) (match_dup 8))\n+                                (match_dup 8)))\n+                  (use (const_int 1))]))\n+    ;; Step 7\n+    ;; d1 = 1/2 - S1 * H1 in f10\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+      (parallel [(set (match_dup 5)\n+                      (plus:XF (neg:XF (mult:XF (match_dup 8) (match_dup 4)))\n+                               (match_dup 3)))\n+                 (use (const_int 1))]))\n+    ;; Step 8\n+    ;; H2 = H1 + d1 * H1 in f9\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 4)\n+                       (plus:XF (mult:XF (match_dup 5) (match_dup 4))\n+                                (match_dup 4)))\n+                  (use (const_int 1))]))\n+    ;; Step 9 \n+    ;; S2 = S1 + d1 * S1 in f7\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 8)\n+                       (plus:XF (mult:XF (match_dup 5) (match_dup 8))\n+                                (match_dup 8)))\n+                  (use (const_int 1))]))\n+    ;; Step 10\n+    ;; d2 = 1/2 - S2 * H2 in f10\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 5)\n+                       (plus:XF (neg:XF (mult:XF (match_dup 8) (match_dup 4)))\n+                                (match_dup 3)))\n+                  (use (const_int 1))]))\n+    ;; Step 11\n+    ;; e2 = a - S2 * S2 in f8\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 3)\n+                       (plus:XF (neg:XF (mult:XF (match_dup 8) (match_dup 8)))\n+                                (match_dup 9)))\n+                  (use (const_int 1))]))\n+    ;; Step 12\n+    ;; S3 = S2 + e2 * H2 in f7\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 8)\n+                       (plus:XF (mult:XF (match_dup 3) (match_dup 4))\n+                                (match_dup 8)))\n+                  (use (const_int 1))]))\n+    ;; Step 13\n+    ;; H3 = H2 + d2 * H2 in f9\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 4)\n+                       (plus:XF (mult:XF (match_dup 5) (match_dup 4))\n+                                (match_dup 4)))\n+                  (use (const_int 1))]))\n+    ;; Step 14\n+    ;; e3 = a - S3 * S3 in f8\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 3)\n+                       (plus:XF (neg:XF (mult:XF (match_dup 8) (match_dup 8)))\n+                                (match_dup 9)))\n+                  (use (const_int 1))]))\n+    ;; Step 15\n+    ;; S = S3 + e3 * H3 in f7\n+    (cond_exec (ne (match_dup 7) (const_int 0))\n+       (parallel [(set (match_dup 0)\n+                       (plus:XF (mult:XF (match_dup 3) (match_dup 4))\n+                                (match_dup 8)))\n+                  (use (const_int 0))]))]\n+{\n+  /* Generate 82-bit versions of the input and output operands.  */\n+  operands[8] = gen_rtx_REG (XFmode, REGNO (operands[0]));\n+  operands[9] = gen_rtx_REG (XFmode, REGNO (operands[1]));\n+  /* Generate required floating-point constants.  */\n+  operands[10] = CONST0_RTX (XFmode);\n+}\n+  [(set_attr \"predicable\" \"no\")])\n+\n ;; ??? frcpa works like cmp.foo.unc.\n \n (define_insn \"*recip_approx\""}]}