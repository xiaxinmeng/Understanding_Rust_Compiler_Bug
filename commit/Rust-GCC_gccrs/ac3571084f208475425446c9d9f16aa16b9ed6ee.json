{"sha": "ac3571084f208475425446c9d9f16aa16b9ed6ee", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWMzNTcxMDg0ZjIwODQ3NTQyNTQ0NmM5ZDlmMTZhYTE2YjllZDZlZQ==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2012-06-25T20:41:42Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2012-06-25T20:41:42Z"}, "message": "i386: Cleanup and unify widening multiply patterns\n\nPrepares for exposing builtin_mul_widen_even/odd hooks\nfor more efficient reduction.  Adds QImode multiplication.\nShares code between mulv4si3 and the widening multiplies.\n\nFrom-SVN: r188957", "tree": {"sha": "8e01bfa6461b108b0a82f996e66e9f474cbcb112", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8e01bfa6461b108b0a82f996e66e9f474cbcb112"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ac3571084f208475425446c9d9f16aa16b9ed6ee", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ac3571084f208475425446c9d9f16aa16b9ed6ee", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ac3571084f208475425446c9d9f16aa16b9ed6ee", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ac3571084f208475425446c9d9f16aa16b9ed6ee/comments", "author": null, "committer": null, "parents": [{"sha": "f008d5dc431d4d95973f13b77a3a10c52750c3db", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f008d5dc431d4d95973f13b77a3a10c52750c3db", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f008d5dc431d4d95973f13b77a3a10c52750c3db"}], "stats": {"total": 454, "additions": 213, "deletions": 241}, "files": [{"sha": "673275ab7ff96ae9deb3b8f33e35dfeb503009ab", "filename": "gcc/ChangeLog", "status": "modified", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ac3571084f208475425446c9d9f16aa16b9ed6ee", "patch": "@@ -1,3 +1,28 @@\n+2012-06-25  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/i386/i386.c (ix86_rtx_costs) [MULT]: Only apply XOP cost\n+\tto V16QImode.\n+\t(ix86_expand_vec_interleave): New.\n+\t(ix86_expand_mul_widen_evenodd): New.\n+\t(ix86_expand_mul_widen_hilo): New.\n+\t(ix86_expand_sse2_mulv4si3): Use ix86_expand_mul_widen_evenodd.\n+\t* config/i386/i386.md (u_bool) New code attr.\n+\t* config/i386/predicates.md\n+\t(nonimmediate_or_const_vector_operand): Remove.\n+\t* config/i386/sse.md (mul<VI4_AVX2>3): Don't use it; don't test\n+\tboth AVX and SSE4_1.\n+\t(vec_widen<s>mult_hi_<VI2_AVX2>): Remove.\n+\t(vec_widen<s>mult_lo_<VI2_AVX2>): Remove.\n+\t(vec_widen<s>mult_hi_v8si): Remove.\n+\t(vec_widen<s>mult_lo_v8si): Remove.\n+\t(vec_widen_smult_hi_v4si): Remove.\n+\t(vec_widen_smult_lo_v4si): Remove.\n+\t(vec_widen_umult_hi_v4si): Remove.\n+\t(vec_widen_umult_lo_v4si): Remove.\n+\t(vec_widen_<s>mult_hi_<VI124_AVX2>): New.\n+\t(vec_widen_<s>mult_lo_<VI124_AVX2>): New.\n+\t* config/i386/i386-protos.h: Update.\n+\n 2012-06-25  Christophe Lyon  <christophe.lyon@st.com>\n \n \t* config/arm/neon.md (UNSPEC_VLD1_DUP): Remove."}, {"sha": "c860e5a3c74f256b0e0d7a4c55e4328b5bbec187", "filename": "gcc/config/i386/i386-protos.h", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-protos.h?ref=ac3571084f208475425446c9d9f16aa16b9ed6ee", "patch": "@@ -1,6 +1,6 @@\n /* Definitions of target machine for GCC for IA-32.\n    Copyright (C) 1988, 1992, 1994, 1995, 1996, 1996, 1997, 1998, 1999,\n-   2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011\n+   2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012\n    Free Software Foundation, Inc.\n \n This file is part of GCC.\n@@ -224,6 +224,8 @@ extern void ix86_expand_reduc (rtx (*)(rtx, rtx, rtx), rtx, rtx);\n \n extern void ix86_expand_vec_extract_even_odd (rtx, rtx, rtx, unsigned);\n extern bool ix86_expand_pinsr (rtx *);\n+extern void ix86_expand_mul_widen_evenodd (rtx, rtx, rtx, bool, bool);\n+extern void ix86_expand_mul_widen_hilo (rtx, rtx, rtx, bool, bool);\n extern void ix86_expand_sse2_mulv4si3 (rtx, rtx, rtx);\n \n /* In i386-c.c  */"}, {"sha": "a1b7628aa2516e1eb30371a6079e1bf274ae03e3", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 166, "deletions": 45, "changes": 211, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=ac3571084f208475425446c9d9f16aa16b9ed6ee", "patch": "@@ -32101,7 +32101,7 @@ ix86_rtx_costs (rtx x, int code_i, int outer_code_i, int opno, int *total,\n \t  /* V*QImode is emulated with 1-11 insns.  */\n \t  if (mode == V16QImode || mode == V32QImode)\n \t    {\n-\t      int count;\n+\t      int count = 11;\n \t      if (TARGET_XOP && mode == V16QImode)\n \t\t{\n \t\t  /* For XOP we use vpshab, which requires a broadcast of the\n@@ -32117,8 +32117,8 @@ ix86_rtx_costs (rtx x, int code_i, int outer_code_i, int opno, int *total,\n \t\t    }\n \t\t  count = 3;\n \t\t}\n-\t      else\n-\t\tcount = TARGET_SSSE3 ? 7 : 11;\n+\t      else if (TARGET_SSSE3)\n+\t\tcount = 7;\n \t      *total = cost->fabs * count;\n \t    }\n \t  else\n@@ -32199,7 +32199,11 @@ ix86_rtx_costs (rtx x, int code_i, int outer_code_i, int opno, int *total,\n \t  /* V*QImode is emulated with 7-13 insns.  */\n \t  if (mode == V16QImode || mode == V32QImode)\n \t    {\n-\t      int extra = TARGET_XOP ? 5 : TARGET_SSSE3 ? 6 : 11;\n+\t      int extra = 11;\n+\t      if (TARGET_XOP && mode == V16QImode)\n+\t\textra = 5;\n+\t      else if (TARGET_SSSE3)\n+\t\textra = 6;\n \t      *total = cost->fmul * 2 + cost->fabs * extra;\n \t    }\n \t  /* Without sse4.1, we don't have PMULLD; it's emulated with 7\n@@ -38519,6 +38523,34 @@ ix86_expand_vec_extract_even_odd (rtx targ, rtx op0, rtx op1, unsigned odd)\n   expand_vec_perm_even_odd_1 (&d, odd);\n }\n \n+static void\n+ix86_expand_vec_interleave (rtx targ, rtx op0, rtx op1, bool high_p)\n+{\n+  struct expand_vec_perm_d d;\n+  unsigned i, nelt, base;\n+  bool ok;\n+\n+  d.target = targ;\n+  d.op0 = op0;\n+  d.op1 = op1;\n+  d.vmode = GET_MODE (targ);\n+  d.nelt = nelt = GET_MODE_NUNITS (d.vmode);\n+  d.one_operand_p = false;\n+  d.testing_p = false;\n+\n+  base = high_p ? nelt / 2 : 0;\n+  for (i = 0; i < nelt / 2; ++i)\n+    {\n+      d.perm[i * 2] = i + base;\n+      d.perm[i * 2 + 1] = i + base + nelt;\n+    }\n+\n+  /* Note that for AVX this isn't one instruction.  */\n+  ok = ix86_expand_vec_perm_const_1 (&d);\n+  gcc_assert (ok);\n+}\n+\n+\n /* Expand a vector operation CODE for a V*QImode in terms of the\n    same operation on V*HImode.  */\n \n@@ -38627,59 +38659,148 @@ ix86_expand_vecop_qihi (enum rtx_code code, rtx dest, rtx op1, rtx op2)\n }\n \n void\n-ix86_expand_sse2_mulv4si3 (rtx op0, rtx op1, rtx op2)\n+ix86_expand_mul_widen_evenodd (rtx dest, rtx op1, rtx op2,\n+\t\t\t       bool uns_p, bool odd_p)\n {\n-  rtx op1_m1, op1_m2;\n-  rtx op2_m1, op2_m2;\n-  rtx res_1, res_2;\n+  enum machine_mode mode = GET_MODE (op1);\n+  rtx x;\n \n-  /* Shift both input vectors down one element, so that elements 3\n-     and 1 are now in the slots for elements 2 and 0.  For K8, at\n-     least, this is faster than using a shuffle.  */\n-  op1_m1 = op1 = force_reg (V4SImode, op1);\n-  op1_m2 = gen_reg_rtx (V4SImode);\n-  emit_insn (gen_sse2_lshrv1ti3 (gen_lowpart (V1TImode, op1_m2),\n-\t\t\t\t gen_lowpart (V1TImode, op1),\n-\t\t\t\t GEN_INT (32)));\n+  /* We only play even/odd games with vectors of SImode.  */\n+  gcc_assert (mode == V4SImode || mode == V8SImode);\n \n-  if (GET_CODE (op2) == CONST_VECTOR)\n+  /* If we're looking for the odd results, shift those members down to\n+     the even slots.  For some cpus this is faster than a PSHUFD.  */\n+  if (odd_p)\n     {\n-      rtvec v;\n+      enum machine_mode wmode = GET_MODE (dest);\n \n-      /* Constant propagate the vector shift, leaving the dont-care\n-\t vector elements as zero.  */\n-      v = rtvec_alloc (4);\n-      RTVEC_ELT (v, 0) = CONST_VECTOR_ELT (op2, 0);\n-      RTVEC_ELT (v, 2) = CONST_VECTOR_ELT (op2, 2);\n-      RTVEC_ELT (v, 1) = const0_rtx;\n-      RTVEC_ELT (v, 3) = const0_rtx;\n-      op2_m1 = gen_rtx_CONST_VECTOR (V4SImode, v);\n-      op2_m1 = force_reg (V4SImode, op2_m1);\n-\n-      v = rtvec_alloc (4);\n-      RTVEC_ELT (v, 0) = CONST_VECTOR_ELT (op2, 1);\n-      RTVEC_ELT (v, 2) = CONST_VECTOR_ELT (op2, 3);\n-      RTVEC_ELT (v, 1) = const0_rtx;\n-      RTVEC_ELT (v, 3) = const0_rtx;\n-      op2_m2 = gen_rtx_CONST_VECTOR (V4SImode, v);\n-      op2_m2 = force_reg (V4SImode, op2_m2);\n+      op1 = expand_binop (wmode, lshr_optab, gen_lowpart (wmode, op1),\n+\t\t\t  GEN_INT (GET_MODE_UNIT_BITSIZE (mode)), NULL,\n+\t\t\t  1, OPTAB_DIRECT);\n+      op2 = expand_binop (wmode, lshr_optab, gen_lowpart (wmode, op2),\n+\t\t\t  GEN_INT (GET_MODE_UNIT_BITSIZE (mode)), NULL,\n+\t\t\t  1, OPTAB_DIRECT);\n+      op1 = gen_lowpart (mode, op1);\n+      op2 = gen_lowpart (mode, op2);\n+    }\n+\n+  if (mode == V8SImode)\n+    {\n+      if (uns_p)\n+\tx = gen_avx2_umulv4siv4di3 (dest, op1, op2);\n+      else\n+\tx = gen_avx2_mulv4siv4di3 (dest, op1, op2);\n+    }\n+  else if (uns_p)\n+    x = gen_sse2_umulv2siv2di3 (dest, op1, op2);\n+  else if (TARGET_SSE4_1)\n+    x = gen_sse4_1_mulv2siv2di3 (dest, op1, op2);\n+  else if (TARGET_XOP)\n+    {\n+      x = force_reg (V2DImode, CONST0_RTX (V2DImode));\n+      x = gen_xop_pmacsdql (dest, op1, op2, x);\n     }\n   else\n+    gcc_unreachable ();\n+  emit_insn (x);\n+}\n+\n+void\n+ix86_expand_mul_widen_hilo (rtx dest, rtx op1, rtx op2,\n+\t\t\t    bool uns_p, bool high_p)\n+{\n+  enum machine_mode wmode = GET_MODE (dest);\n+  enum machine_mode mode = GET_MODE (op1);\n+  rtx t1, t2, t3, t4, mask;\n+\n+  switch (mode)\n     {\n-      op2_m1 = op2 = force_reg (V4SImode, op2);\n-      op2_m2 = gen_reg_rtx (V4SImode);\n-      emit_insn (gen_sse2_lshrv1ti3 (gen_lowpart (V1TImode, op2_m2),\n-\t\t\t\t     gen_lowpart (V1TImode, op2),\n-\t\t\t\t     GEN_INT (32)));\n+    case V4SImode:\n+      t1 = gen_reg_rtx (mode);\n+      t2 = gen_reg_rtx (mode);\n+      if (TARGET_XOP && !uns_p)\n+\t{\n+\t  /* With XOP, we have pmacsdqh, aka mul_widen_odd.  In this case,\n+\t     shuffle the elements once so that all elements are in the right\n+\t     place for immediate use: { A C B D }.  */\n+\t  emit_insn (gen_sse2_pshufd_1 (t1, op1, const0_rtx, const2_rtx,\n+\t\t\t\t\tconst1_rtx, GEN_INT (3)));\n+\t  emit_insn (gen_sse2_pshufd_1 (t2, op2, const0_rtx, const2_rtx,\n+\t\t\t\t\tconst1_rtx, GEN_INT (3)));\n+\t}\n+      else\n+\t{\n+\t  /* Put the elements into place for the multiply.  */\n+\t  ix86_expand_vec_interleave (t1, op1, op1, high_p);\n+\t  ix86_expand_vec_interleave (t2, op2, op2, high_p);\n+\t  high_p = false;\n+\t}\n+      ix86_expand_mul_widen_evenodd (dest, t1, t2, uns_p, high_p);\n+      break;\n+\n+    case V8SImode:\n+      /* Shuffle the elements between the lanes.  After this we\n+\t have { A B E F | C D G H } for each operand.  */\n+      t1 = gen_reg_rtx (V4DImode);\n+      t2 = gen_reg_rtx (V4DImode);\n+      emit_insn (gen_avx2_permv4di_1 (t1, gen_lowpart (V4DImode, op1),\n+\t\t\t\t      const0_rtx, const2_rtx,\n+\t\t\t\t      const1_rtx, GEN_INT (3)));\n+      emit_insn (gen_avx2_permv4di_1 (t2, gen_lowpart (V4DImode, op2),\n+\t\t\t\t      const0_rtx, const2_rtx,\n+\t\t\t\t      const1_rtx, GEN_INT (3)));\n+\n+      /* Shuffle the elements within the lanes.  After this we\n+\t have { A A B B | C C D D } or { E E F F | G G H H }.  */\n+      t3 = gen_reg_rtx (V8SImode);\n+      t4 = gen_reg_rtx (V8SImode);\n+      mask = GEN_INT (high_p\n+\t\t      ? 2 + (2 << 2) + (3 << 4) + (3 << 6)\n+\t\t      : 0 + (0 << 2) + (1 << 4) + (1 << 6));\n+      emit_insn (gen_avx2_pshufdv3 (t3, gen_lowpart (V8SImode, t1), mask));\n+      emit_insn (gen_avx2_pshufdv3 (t4, gen_lowpart (V8SImode, t2), mask));\n+\n+      ix86_expand_mul_widen_evenodd (dest, t3, t4, uns_p, false);\n+      break;\n+\n+    case V8HImode:\n+    case V16HImode:\n+      t1 = expand_binop (mode, smul_optab, op1, op2, NULL_RTX,\n+\t\t\t uns_p, OPTAB_DIRECT);\n+      t2 = expand_binop (mode,\n+\t\t\t uns_p ? umul_highpart_optab : smul_highpart_optab,\n+\t\t\t op1, op2, NULL_RTX, uns_p, OPTAB_DIRECT);\n+      gcc_assert (t1 && t2);\n+\n+      ix86_expand_vec_interleave (gen_lowpart (mode, dest), t1, t2, high_p);\n+      break;\n+\n+    case V16QImode:\n+    case V32QImode:\n+      t1 = gen_reg_rtx (wmode);\n+      t2 = gen_reg_rtx (wmode);\n+      ix86_expand_sse_unpack (t1, op1, uns_p, high_p);\n+      ix86_expand_sse_unpack (t2, op2, uns_p, high_p);\n+\n+      emit_insn (gen_rtx_SET (VOIDmode, dest, gen_rtx_MULT (wmode, t1, t2)));\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n     }\n+}\n+\n+void\n+ix86_expand_sse2_mulv4si3 (rtx op0, rtx op1, rtx op2)\n+{\n+  rtx res_1, res_2;\n \n-  /* Widening multiply of elements 0+2, and 1+3.  */\n   res_1 = gen_reg_rtx (V4SImode);\n   res_2 = gen_reg_rtx (V4SImode);\n-  emit_insn (gen_sse2_umulv2siv2di3 (gen_lowpart (V2DImode, res_1),\n-\t\t\t\t     op1_m1, op2_m1));\n-  emit_insn (gen_sse2_umulv2siv2di3 (gen_lowpart (V2DImode, res_2),\n-\t\t\t\t     op1_m2, op2_m2));\n+  ix86_expand_mul_widen_evenodd (gen_lowpart (V2DImode, res_1),\n+\t\t\t\t op1, op2, true, false);\n+  ix86_expand_mul_widen_evenodd (gen_lowpart (V2DImode, res_2),\n+\t\t\t\t op1, op2, true, true);\n \n   /* Move the results in element 2 down to element 1; we don't care\n      what goes in elements 2 and 3.  Then we can merge the parts"}, {"sha": "60aa65a88bf005269729e375da4e300512b1d759", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=ac3571084f208475425446c9d9f16aa16b9ed6ee", "patch": "@@ -744,6 +744,7 @@\n ;; Prefix for define_insn\n (define_code_attr u [(sign_extend \"\") (zero_extend \"u\")])\n (define_code_attr s [(sign_extend \"s\") (zero_extend \"u\")])\n+(define_code_attr u_bool [(sign_extend \"false\") (zero_extend \"true\")])\n \n ;; All integer modes.\n (define_mode_iterator SWI1248x [QI HI SI DI])"}, {"sha": "92db80912befaec5c3ef2909ab7185ca4a00d6f5", "filename": "gcc/config/i386/predicates.md", "status": "modified", "additions": 0, "deletions": 7, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fpredicates.md?ref=ac3571084f208475425446c9d9f16aa16b9ed6ee", "patch": "@@ -816,13 +816,6 @@\n   return false;\n })\n \n-;; Return true when OP is a nonimmediate or a vector constant.  Note\n-;; that most vector constants are not legitimate operands, so we need\n-;; to special-case this.\n-(define_predicate \"nonimmediate_or_const_vector_operand\"\n-  (ior (match_code \"const_vector\")\n-       (match_operand 0 \"nonimmediate_operand\")))\n-\n ;; Return true if OP is a register or a zero.\n (define_predicate \"reg_or_0_operand\"\n   (ior (match_operand 0 \"register_operand\")"}, {"sha": "4c125815f066d2e293990a06ba8c88b8fca43f99", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 18, "deletions": 188, "changes": 206, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ac3571084f208475425446c9d9f16aa16b9ed6ee/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=ac3571084f208475425446c9d9f16aa16b9ed6ee", "patch": "@@ -5555,10 +5555,10 @@\n   [(set (match_operand:VI4_AVX2 0 \"register_operand\")\n \t(mult:VI4_AVX2\n \t  (match_operand:VI4_AVX2 1 \"nonimmediate_operand\")\n-\t  (match_operand:VI4_AVX2 2 \"nonimmediate_or_const_vector_operand\")))]\n+\t  (match_operand:VI4_AVX2 2 \"nonimmediate_operand\")))]\n   \"TARGET_SSE2\"\n {\n-  if (TARGET_SSE4_1 || TARGET_AVX)\n+  if (TARGET_SSE4_1)\n     {\n       if (CONSTANT_P (operands[2]))\n \toperands[2] = force_const_mem (<MODE>mode, operands[2]);\n@@ -5677,198 +5677,28 @@\n (define_expand \"vec_widen_<s>mult_hi_<mode>\"\n   [(match_operand:<sseunpackmode> 0 \"register_operand\")\n    (any_extend:<sseunpackmode>\n-     (match_operand:VI2_AVX2 1 \"register_operand\"))\n-   (match_operand:VI2_AVX2 2 \"register_operand\")]\n-  \"TARGET_SSE2\"\n-{\n-  rtx op1, op2, t1, t2, dest;\n-\n-  op1 = operands[1];\n-  op2 = operands[2];\n-  t1 = gen_reg_rtx (<MODE>mode);\n-  t2 = gen_reg_rtx (<MODE>mode);\n-  dest = gen_lowpart (<MODE>mode, operands[0]);\n-\n-  emit_insn (gen_mul<mode>3 (t1, op1, op2));\n-  emit_insn (gen_<s>mul<mode>3_highpart (t2, op1, op2));\n-  emit_insn (gen_vec_interleave_high<mode> (dest, t1, t2));\n+     (match_operand:VI124_AVX2 1 \"register_operand\"))\n+   (match_operand:VI124_AVX2 2 \"register_operand\")]\n+  ; Note that SSE2 does not have signed SI multiply\n+  \"TARGET_XOP || TARGET_SSE4_1\n+   || (TARGET_SSE2 && (<u_bool> || <MODE>mode != V4SImode))\"\n+{\n+  ix86_expand_mul_widen_hilo (operands[0], operands[1], operands[2],\n+\t\t\t      <u_bool>, true);\n   DONE;\n })\n \n (define_expand \"vec_widen_<s>mult_lo_<mode>\"\n   [(match_operand:<sseunpackmode> 0 \"register_operand\")\n    (any_extend:<sseunpackmode>\n-     (match_operand:VI2_AVX2 1 \"register_operand\"))\n-   (match_operand:VI2_AVX2 2 \"register_operand\")]\n-  \"TARGET_SSE2\"\n-{\n-  rtx op1, op2, t1, t2, dest;\n-\n-  op1 = operands[1];\n-  op2 = operands[2];\n-  t1 = gen_reg_rtx (<MODE>mode);\n-  t2 = gen_reg_rtx (<MODE>mode);\n-  dest = gen_lowpart (<MODE>mode, operands[0]);\n-\n-  emit_insn (gen_mul<mode>3 (t1, op1, op2));\n-  emit_insn (gen_<s>mul<mode>3_highpart (t2, op1, op2));\n-  emit_insn (gen_vec_interleave_low<mode> (dest, t1, t2));\n-  DONE;\n-})\n-\n-(define_expand \"vec_widen_<s>mult_hi_v8si\"\n-  [(match_operand:V4DI 0 \"register_operand\")\n-   (any_extend:V4DI (match_operand:V8SI 1 \"nonimmediate_operand\"))\n-   (match_operand:V8SI 2 \"nonimmediate_operand\")]\n-  \"TARGET_AVX2\"\n-{\n-  rtx t1, t2, t3, t4;\n-\n-  t1 = gen_reg_rtx (V4DImode);\n-  t2 = gen_reg_rtx (V4DImode);\n-  t3 = gen_reg_rtx (V8SImode);\n-  t4 = gen_reg_rtx (V8SImode);\n-  emit_insn (gen_avx2_permv4di_1 (t1, gen_lowpart (V4DImode, operands[1]),\n-\t\t\t\t  const0_rtx, const2_rtx,\n-\t\t\t\t  const1_rtx, GEN_INT (3)));\n-  emit_insn (gen_avx2_permv4di_1 (t2, gen_lowpart (V4DImode, operands[2]),\n-\t\t\t\t  const0_rtx, const2_rtx,\n-\t\t\t\t  const1_rtx, GEN_INT (3)));\n-  emit_insn (gen_avx2_pshufdv3 (t3, gen_lowpart (V8SImode, t1),\n-\t\t\t\tGEN_INT (2 + (2 << 2) + (3 << 4) + (3 << 6))));\n-  emit_insn (gen_avx2_pshufdv3 (t4, gen_lowpart (V8SImode, t2),\n-\t\t\t\tGEN_INT (2 + (2 << 2) + (3 << 4) + (3 << 6))));\n-  emit_insn (gen_avx2_<u>mulv4siv4di3 (operands[0], t3, t4));\n-  DONE;\n-})\n-\n-(define_expand \"vec_widen_<s>mult_lo_v8si\"\n-  [(match_operand:V4DI 0 \"register_operand\")\n-   (any_extend:V4DI (match_operand:V8SI 1 \"nonimmediate_operand\"))\n-   (match_operand:V8SI 2 \"nonimmediate_operand\")]\n-  \"TARGET_AVX2\"\n-{\n-  rtx t1, t2, t3, t4;\n-\n-  t1 = gen_reg_rtx (V4DImode);\n-  t2 = gen_reg_rtx (V4DImode);\n-  t3 = gen_reg_rtx (V8SImode);\n-  t4 = gen_reg_rtx (V8SImode);\n-  emit_insn (gen_avx2_permv4di_1 (t1, gen_lowpart (V4DImode, operands[1]),\n-\t\t\t\t  const0_rtx, const2_rtx,\n-\t\t\t\t  const1_rtx, GEN_INT (3)));\n-  emit_insn (gen_avx2_permv4di_1 (t2,  gen_lowpart (V4DImode, operands[2]),\n-\t\t\t\t  const0_rtx, const2_rtx,\n-\t\t\t\t  const1_rtx, GEN_INT (3)));\n-  emit_insn (gen_avx2_pshufdv3 (t3, gen_lowpart (V8SImode, t1),\n-\t\t\t\tGEN_INT (0 + (0 << 2) + (1 << 4) + (1 << 6))));\n-  emit_insn (gen_avx2_pshufdv3 (t4, gen_lowpart (V8SImode, t2),\n-\t\t\t\tGEN_INT (0 + (0 << 2) + (1 << 4) + (1 << 6))));\n-  emit_insn (gen_avx2_<u>mulv4siv4di3 (operands[0], t3, t4));\n-  DONE;\n-})\n-\n-(define_expand \"vec_widen_smult_hi_v4si\"\n-  [(match_operand:V2DI 0 \"register_operand\")\n-   (match_operand:V4SI 1 \"register_operand\")\n-   (match_operand:V4SI 2 \"register_operand\")]\n-  \"TARGET_SSE4_1\"\n-{\n-  rtx op1, op2, t1, t2;\n-\n-  op1 = operands[1];\n-  op2 = operands[2];\n-  t1 = gen_reg_rtx (V4SImode);\n-  t2 = gen_reg_rtx (V4SImode);\n-\n-  if (TARGET_XOP)\n-    {\n-      rtx t3 = gen_reg_rtx (V2DImode);\n-\n-      emit_insn (gen_sse2_pshufd_1 (t1, op1, GEN_INT (0), GEN_INT (2),\n-\t\t\t\t    GEN_INT (1), GEN_INT (3)));\n-      emit_insn (gen_sse2_pshufd_1 (t2, op2, GEN_INT (0), GEN_INT (2),\n-\t\t\t\t    GEN_INT (1), GEN_INT (3)));\n-      emit_move_insn (t3, CONST0_RTX (V2DImode));\n-\n-      emit_insn (gen_xop_pmacsdqh (operands[0], t1, t2, t3));\n-      DONE;\n-    }\n-\n-  emit_insn (gen_vec_interleave_highv4si (t1, op1, op1));\n-  emit_insn (gen_vec_interleave_highv4si (t2, op2, op2));\n-  emit_insn (gen_sse4_1_mulv2siv2di3 (operands[0], t1, t2));\n-  DONE;\n-})\n-\n-(define_expand \"vec_widen_smult_lo_v4si\"\n-  [(match_operand:V2DI 0 \"register_operand\")\n-   (match_operand:V4SI 1 \"register_operand\")\n-   (match_operand:V4SI 2 \"register_operand\")]\n-  \"TARGET_SSE4_1\"\n-{\n-  rtx op1, op2, t1, t2;\n-\n-  op1 = operands[1];\n-  op2 = operands[2];\n-  t1 = gen_reg_rtx (V4SImode);\n-  t2 = gen_reg_rtx (V4SImode);\n-\n-  if (TARGET_XOP)\n-    {\n-      rtx t3 = gen_reg_rtx (V2DImode);\n-\n-      emit_insn (gen_sse2_pshufd_1 (t1, op1, GEN_INT (0), GEN_INT (2),\n-\t\t\t\t    GEN_INT (1), GEN_INT (3)));\n-      emit_insn (gen_sse2_pshufd_1 (t2, op2, GEN_INT (0), GEN_INT (2),\n-\t\t\t\t    GEN_INT (1), GEN_INT (3)));\n-      emit_move_insn (t3, CONST0_RTX (V2DImode));\n-\n-      emit_insn (gen_xop_pmacsdql (operands[0], t1, t2, t3));\n-      DONE;\n-    }\n-\n-  emit_insn (gen_vec_interleave_lowv4si (t1, op1, op1));\n-  emit_insn (gen_vec_interleave_lowv4si (t2, op2, op2));\n-  emit_insn (gen_sse4_1_mulv2siv2di3 (operands[0], t1, t2));\n-  DONE;\n-})\n-\n-(define_expand \"vec_widen_umult_hi_v4si\"\n-  [(match_operand:V2DI 0 \"register_operand\")\n-   (match_operand:V4SI 1 \"register_operand\")\n-   (match_operand:V4SI 2 \"register_operand\")]\n-  \"TARGET_SSE2\"\n-{\n-  rtx op1, op2, t1, t2;\n-\n-  op1 = operands[1];\n-  op2 = operands[2];\n-  t1 = gen_reg_rtx (V4SImode);\n-  t2 = gen_reg_rtx (V4SImode);\n-\n-  emit_insn (gen_vec_interleave_highv4si (t1, op1, op1));\n-  emit_insn (gen_vec_interleave_highv4si (t2, op2, op2));\n-  emit_insn (gen_sse2_umulv2siv2di3 (operands[0], t1, t2));\n-  DONE;\n-})\n-\n-(define_expand \"vec_widen_umult_lo_v4si\"\n-  [(match_operand:V2DI 0 \"register_operand\")\n-   (match_operand:V4SI 1 \"register_operand\")\n-   (match_operand:V4SI 2 \"register_operand\")]\n-  \"TARGET_SSE2\"\n-{\n-  rtx op1, op2, t1, t2;\n-\n-  op1 = operands[1];\n-  op2 = operands[2];\n-  t1 = gen_reg_rtx (V4SImode);\n-  t2 = gen_reg_rtx (V4SImode);\n-\n-  emit_insn (gen_vec_interleave_lowv4si (t1, op1, op1));\n-  emit_insn (gen_vec_interleave_lowv4si (t2, op2, op2));\n-  emit_insn (gen_sse2_umulv2siv2di3 (operands[0], t1, t2));\n+     (match_operand:VI124_AVX2 1 \"register_operand\"))\n+   (match_operand:VI124_AVX2 2 \"register_operand\")]\n+  ; Note that SSE2 does not have signed SI multiply\n+  \"TARGET_XOP || TARGET_SSE4_1\n+   || (TARGET_SSE2 && (<u_bool> || <MODE>mode != V4SImode))\"\n+{\n+  ix86_expand_mul_widen_hilo (operands[0], operands[1], operands[2],\n+\t\t\t      <u_bool>, false);\n   DONE;\n })\n "}]}