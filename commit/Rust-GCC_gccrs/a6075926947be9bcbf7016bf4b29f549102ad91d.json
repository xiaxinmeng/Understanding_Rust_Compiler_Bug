{"sha": "a6075926947be9bcbf7016bf4b29f549102ad91d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YTYwNzU5MjY5NDdiZTliY2JmNzAxNmJmNGIyOWY1NDkxMDJhZDkxZA==", "commit": {"author": {"name": "Jonathan Wright", "email": "jonathan.wright@arm.com", "date": "2021-07-29T11:24:17Z"}, "committer": {"name": "Jonathan Wright", "email": "jonathan.wright@arm.com", "date": "2021-08-06T10:01:52Z"}, "message": "aarch64: Use memcpy to copy structures in vst4[q]_lane intrinsics\n\nUse __builtin_memcpy to copy vector structures instead of using a\nunion - or constructing a new opaque structure one vector at a time -\nin each of the vst4[q]_lane Neon intrinsics in arm_neon.h.\n\nAdd new code generation tests to verify that superfluous move\ninstructions are not generated for the vst4q_lane intrinsics.\n\ngcc/ChangeLog:\n\n2021-07-29  Jonathan Wright  <jonathan.wright@arm.com>\n\n\t* config/aarch64/arm_neon.h (__ST4_LANE_FUNC): Delete.\n\t(__ST4Q_LANE_FUNC): Delete.\n\t(vst4_lane_f16): Use __builtin_memcpy to copy vector\n\tstructure instead of constructing __builtin_aarch64_simd_xi\n\tone vector at a time.\n\t(vst4_lane_f32): Likewise.\n\t(vst4_lane_f64): Likewise.\n\t(vst4_lane_p8): Likewise.\n\t(vst4_lane_p16): Likewise.\n\t(vst4_lane_p64): Likewise.\n\t(vst4_lane_s8): Likewise.\n\t(vst4_lane_s16): Likewise.\n\t(vst4_lane_s32): Likewise.\n\t(vst4_lane_s64): Likewise.\n\t(vst4_lane_u8): Likewise.\n\t(vst4_lane_u16): Likewise.\n\t(vst4_lane_u32): Likewise.\n\t(vst4_lane_u64): Likewise.\n\t(vst4_lane_bf16): Likewise.\n\t(vst4q_lane_f16): Use __builtin_memcpy to copy vector\n\tstructure instead of using a union.\n\t(vst4q_lane_f32): Likewise.\n\t(vst4q_lane_f64): Likewise.\n\t(vst4q_lane_p8): Likewise.\n\t(vst4q_lane_p16): Likewise.\n\t(vst4q_lane_p64): Likewise.\n\t(vst4q_lane_s8): Likewise.\n\t(vst4q_lane_s16): Likewise.\n\t(vst4q_lane_s32): Likewise.\n\t(vst4q_lane_s64): Likewise.\n\t(vst4q_lane_u8): Likewise.\n\t(vst4q_lane_u16): Likewise.\n\t(vst4q_lane_u32): Likewise.\n\t(vst4q_lane_u64): Likewise.\n\t(vst4q_lane_bf16): Likewise.\n\ngcc/testsuite/ChangeLog:\n\n\t* gcc.target/aarch64/vector_structure_intrinsics.c: Add new\n\ttests.", "tree": {"sha": "4f55681dc74b7cd440adea2cb8c03b35b1156dac", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4f55681dc74b7cd440adea2cb8c03b35b1156dac"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/a6075926947be9bcbf7016bf4b29f549102ad91d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a6075926947be9bcbf7016bf4b29f549102ad91d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a6075926947be9bcbf7016bf4b29f549102ad91d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a6075926947be9bcbf7016bf4b29f549102ad91d/comments", "author": {"login": "jwright-arm", "id": 31624044, "node_id": "MDQ6VXNlcjMxNjI0MDQ0", "avatar_url": "https://avatars.githubusercontent.com/u/31624044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwright-arm", "html_url": "https://github.com/jwright-arm", "followers_url": "https://api.github.com/users/jwright-arm/followers", "following_url": "https://api.github.com/users/jwright-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jwright-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwright-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwright-arm/subscriptions", "organizations_url": "https://api.github.com/users/jwright-arm/orgs", "repos_url": "https://api.github.com/users/jwright-arm/repos", "events_url": "https://api.github.com/users/jwright-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwright-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jwright-arm", "id": 31624044, "node_id": "MDQ6VXNlcjMxNjI0MDQ0", "avatar_url": "https://avatars.githubusercontent.com/u/31624044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwright-arm", "html_url": "https://github.com/jwright-arm", "followers_url": "https://api.github.com/users/jwright-arm/followers", "following_url": "https://api.github.com/users/jwright-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jwright-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwright-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwright-arm/subscriptions", "organizations_url": "https://api.github.com/users/jwright-arm/orgs", "repos_url": "https://api.github.com/users/jwright-arm/repos", "events_url": "https://api.github.com/users/jwright-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwright-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "318113a961220c8da79d8d29619138827ccc69f1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/318113a961220c8da79d8d29619138827ccc69f1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/318113a961220c8da79d8d29619138827ccc69f1"}], "stats": {"total": 543, "additions": 453, "deletions": 90}, "files": [{"sha": "6999b8147b1ee1093a8a8e00ac9b7ad3d1645b5d", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 429, "deletions": 88, "changes": 517, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a6075926947be9bcbf7016bf4b29f549102ad91d/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a6075926947be9bcbf7016bf4b29f549102ad91d/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=a6075926947be9bcbf7016bf4b29f549102ad91d", "patch": "@@ -9369,94 +9369,411 @@ __ST3Q_LANE_FUNC (uint16x8x3_t, uint16_t, v8hi, hi, u16)\n __ST3Q_LANE_FUNC (uint32x4x3_t, uint32_t, v4si, si, u32)\n __ST3Q_LANE_FUNC (uint64x2x3_t, uint64_t, v2di, di, u64)\n \n-#define __ST4_LANE_FUNC(intype, largetype, ptrtype, mode,\t\t     \\\n-\t\t\tqmode, ptr_mode, funcsuffix, signedtype)\t     \\\n-__extension__ extern __inline void\t\t\t\t\t     \\\n-__attribute__ ((__always_inline__, __gnu_inline__, __artificial__)) \\\n-vst4_lane_ ## funcsuffix (ptrtype *__ptr,\t\t\t\t     \\\n-\t\t\t  intype __b, const int __c)\t\t\t     \\\n-{\t\t\t\t\t\t\t\t\t     \\\n-  __builtin_aarch64_simd_xi __o;\t\t\t\t\t     \\\n-  largetype __temp;\t\t\t\t\t\t\t     \\\n-  __temp.val[0]\t\t\t\t\t\t\t\t     \\\n-    = vcombine_##funcsuffix (__b.val[0],\t\t\t\t     \\\n-\t\t\t     vcreate_##funcsuffix (__AARCH64_UINT64_C (0))); \\\n-  __temp.val[1]\t\t\t\t\t\t\t\t     \\\n-    = vcombine_##funcsuffix (__b.val[1],\t\t\t\t     \\\n-\t\t\t     vcreate_##funcsuffix (__AARCH64_UINT64_C (0))); \\\n-  __temp.val[2]\t\t\t\t\t\t\t\t     \\\n-    = vcombine_##funcsuffix (__b.val[2],\t\t\t\t     \\\n-\t\t\t     vcreate_##funcsuffix (__AARCH64_UINT64_C (0))); \\\n-  __temp.val[3]\t\t\t\t\t\t\t\t     \\\n-    = vcombine_##funcsuffix (__b.val[3],\t\t\t\t     \\\n-\t\t\t     vcreate_##funcsuffix (__AARCH64_UINT64_C (0))); \\\n-  __o = __builtin_aarch64_set_qregxi##qmode (__o,\t\t\t     \\\n-\t\t\t\t\t     (signedtype) __temp.val[0], 0); \\\n-  __o = __builtin_aarch64_set_qregxi##qmode (__o,\t\t\t     \\\n-\t\t\t\t\t     (signedtype) __temp.val[1], 1); \\\n-  __o = __builtin_aarch64_set_qregxi##qmode (__o,\t\t\t     \\\n-\t\t\t\t\t     (signedtype) __temp.val[2], 2); \\\n-  __o = __builtin_aarch64_set_qregxi##qmode (__o,\t\t\t     \\\n-\t\t\t\t\t     (signedtype) __temp.val[3], 3); \\\n-  __builtin_aarch64_st4_lane##mode ((__builtin_aarch64_simd_ ## ptr_mode *)  \\\n-\t\t\t\t     __ptr, __o, __c);\t\t\t     \\\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_f16 (float16_t *__ptr, float16x4x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  float16x8x4_t __temp;\n+  __temp.val[0] = vcombine_f16 (__val.val[0],\n+\t\t\t\tvcreate_f16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_f16 (__val.val[1],\n+\t\t\t\tvcreate_f16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_f16 (__val.val[2],\n+\t\t\t\tvcreate_f16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_f16 (__val.val[3],\n+\t\t\t\tvcreate_f16 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev4hf ((__builtin_aarch64_simd_hf *) __ptr, __o,\n+\t\t\t\t  __lane);\n }\n \n-__ST4_LANE_FUNC (float16x4x4_t, float16x8x4_t, float16_t, v4hf, v8hf, hf, f16,\n-\t\t float16x8_t)\n-__ST4_LANE_FUNC (float32x2x4_t, float32x4x4_t, float32_t, v2sf, v4sf, sf, f32,\n-\t\t float32x4_t)\n-__ST4_LANE_FUNC (float64x1x4_t, float64x2x4_t, float64_t, df, v2df, df, f64,\n-\t\t float64x2_t)\n-__ST4_LANE_FUNC (poly8x8x4_t, poly8x16x4_t, poly8_t, v8qi, v16qi, qi, p8,\n-\t\t int8x16_t)\n-__ST4_LANE_FUNC (poly16x4x4_t, poly16x8x4_t, poly16_t, v4hi, v8hi, hi, p16,\n-\t\t int16x8_t)\n-__ST4_LANE_FUNC (poly64x1x4_t, poly64x2x4_t, poly64_t, di, v2di_ssps, di, p64,\n-\t\t poly64x2_t)\n-__ST4_LANE_FUNC (int8x8x4_t, int8x16x4_t, int8_t, v8qi, v16qi, qi, s8,\n-\t\t int8x16_t)\n-__ST4_LANE_FUNC (int16x4x4_t, int16x8x4_t, int16_t, v4hi, v8hi, hi, s16,\n-\t\t int16x8_t)\n-__ST4_LANE_FUNC (int32x2x4_t, int32x4x4_t, int32_t, v2si, v4si, si, s32,\n-\t\t int32x4_t)\n-__ST4_LANE_FUNC (int64x1x4_t, int64x2x4_t, int64_t, di, v2di, di, s64,\n-\t\t int64x2_t)\n-__ST4_LANE_FUNC (uint8x8x4_t, uint8x16x4_t, uint8_t, v8qi, v16qi, qi, u8,\n-\t\t int8x16_t)\n-__ST4_LANE_FUNC (uint16x4x4_t, uint16x8x4_t, uint16_t, v4hi, v8hi, hi, u16,\n-\t\t int16x8_t)\n-__ST4_LANE_FUNC (uint32x2x4_t, uint32x4x4_t, uint32_t, v2si, v4si, si, u32,\n-\t\t int32x4_t)\n-__ST4_LANE_FUNC (uint64x1x4_t, uint64x2x4_t, uint64_t, di, v2di, di, u64,\n-\t\t int64x2_t)\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_f32 (float32_t *__ptr, float32x2x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  float32x4x4_t __temp;\n+  __temp.val[0] = vcombine_f32 (__val.val[0],\n+\t\t\t\tvcreate_f32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_f32 (__val.val[1],\n+\t\t\t\tvcreate_f32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_f32 (__val.val[2],\n+\t\t\t\tvcreate_f32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_f32 (__val.val[3],\n+\t\t\t\tvcreate_f32 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev2sf ((__builtin_aarch64_simd_sf *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n \n-#define __ST4Q_LANE_FUNC(intype, ptrtype, mode, ptr_mode, funcsuffix)\t    \\\n-__extension__ extern __inline void\t\t\t\t\t    \\\n-__attribute__ ((__always_inline__, __gnu_inline__, __artificial__)) \\\n-vst4q_lane_ ## funcsuffix (ptrtype *__ptr,\t\t\t\t    \\\n-\t\t\t   intype __b, const int __c)\t\t\t    \\\n-{\t\t\t\t\t\t\t\t\t    \\\n-  union { intype __i;\t\t\t\t\t\t\t    \\\n-\t  __builtin_aarch64_simd_xi __o; } __temp = { __b };\t\t    \\\n-  __builtin_aarch64_st4_lane##mode ((__builtin_aarch64_simd_ ## ptr_mode *) \\\n-\t\t\t\t    __ptr, __temp.__o, __c);\t\t    \\\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_f64 (float64_t *__ptr, float64x1x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  float64x2x4_t __temp;\n+  __temp.val[0] = vcombine_f64 (__val.val[0],\n+\t\t\t\tvcreate_f64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_f64 (__val.val[1],\n+\t\t\t\tvcreate_f64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_f64 (__val.val[2],\n+\t\t\t\tvcreate_f64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_f64 (__val.val[3],\n+\t\t\t\tvcreate_f64 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanedf ((__builtin_aarch64_simd_df *) __ptr, __o,\n+\t\t\t\t__lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_p8 (poly8_t *__ptr, poly8x8x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  poly8x16x4_t __temp;\n+  __temp.val[0] = vcombine_p8 (__val.val[0],\n+\t\t\t       vcreate_p8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_p8 (__val.val[1],\n+\t\t\t       vcreate_p8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_p8 (__val.val[2],\n+\t\t\t       vcreate_p8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_p8 (__val.val[3],\n+\t\t\t       vcreate_p8 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev8qi ((__builtin_aarch64_simd_qi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_p16 (poly16_t *__ptr, poly16x4x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  poly16x8x4_t __temp;\n+  __temp.val[0] = vcombine_p16 (__val.val[0],\n+\t\t\t\tvcreate_p16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_p16 (__val.val[1],\n+\t\t\t\tvcreate_p16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_p16 (__val.val[2],\n+\t\t\t\tvcreate_p16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_p16 (__val.val[3],\n+\t\t\t\tvcreate_p16 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev4hi ((__builtin_aarch64_simd_hi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_p64 (poly64_t *__ptr, poly64x1x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  poly64x2x4_t __temp;\n+  __temp.val[0] = vcombine_p64 (__val.val[0],\n+\t\t\t\tvcreate_p64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_p64 (__val.val[1],\n+\t\t\t\tvcreate_p64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_p64 (__val.val[2],\n+\t\t\t\tvcreate_p64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_p64 (__val.val[3],\n+\t\t\t\tvcreate_p64 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanedi ((__builtin_aarch64_simd_di *) __ptr, __o,\n+\t\t\t\t__lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_s8 (int8_t *__ptr, int8x8x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  int8x16x4_t __temp;\n+  __temp.val[0] = vcombine_s8 (__val.val[0],\n+\t\t\t       vcreate_s8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_s8 (__val.val[1],\n+\t\t\t       vcreate_s8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_s8 (__val.val[2],\n+\t\t\t       vcreate_s8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_s8 (__val.val[3],\n+\t\t\t       vcreate_s8 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev8qi ((__builtin_aarch64_simd_qi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_s16 (int16_t *__ptr, int16x4x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  int16x8x4_t __temp;\n+  __temp.val[0] = vcombine_s16 (__val.val[0],\n+\t\t\t\tvcreate_s16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_s16 (__val.val[1],\n+\t\t\t\tvcreate_s16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_s16 (__val.val[2],\n+\t\t\t\tvcreate_s16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_s16 (__val.val[3],\n+\t\t\t\tvcreate_s16 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev4hi ((__builtin_aarch64_simd_hi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_s32 (int32_t *__ptr, int32x2x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  int32x4x4_t __temp;\n+  __temp.val[0] = vcombine_s32 (__val.val[0],\n+\t\t\t\tvcreate_s32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_s32 (__val.val[1],\n+\t\t\t\tvcreate_s32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_s32 (__val.val[2],\n+\t\t\t\tvcreate_s32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_s32 (__val.val[3],\n+\t\t\t\tvcreate_s32 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev2si ((__builtin_aarch64_simd_si *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_s64 (int64_t *__ptr, int64x1x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  int64x2x4_t __temp;\n+  __temp.val[0] = vcombine_s64 (__val.val[0],\n+\t\t\t\tvcreate_s64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_s64 (__val.val[1],\n+\t\t\t\tvcreate_s64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_s64 (__val.val[2],\n+\t\t\t\tvcreate_s64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_s64 (__val.val[3],\n+\t\t\t\tvcreate_s64 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanedi ((__builtin_aarch64_simd_di *) __ptr, __o,\n+\t\t\t\t__lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_u8 (uint8_t *__ptr, uint8x8x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  uint8x16x4_t __temp;\n+  __temp.val[0] = vcombine_u8 (__val.val[0],\n+\t\t\t       vcreate_u8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_u8 (__val.val[1],\n+\t\t\t       vcreate_u8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_u8 (__val.val[2],\n+\t\t\t       vcreate_u8 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_u8 (__val.val[3],\n+\t\t\t       vcreate_u8 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev8qi ((__builtin_aarch64_simd_qi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_u16 (uint16_t *__ptr, uint16x4x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  uint16x8x4_t __temp;\n+  __temp.val[0] = vcombine_u16 (__val.val[0],\n+\t\t\t\tvcreate_u16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_u16 (__val.val[1],\n+\t\t\t\tvcreate_u16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_u16 (__val.val[2],\n+\t\t\t\tvcreate_u16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_u16 (__val.val[3],\n+\t\t\t\tvcreate_u16 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev4hi ((__builtin_aarch64_simd_hi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_u32 (uint32_t *__ptr, uint32x2x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  uint32x4x4_t __temp;\n+  __temp.val[0] = vcombine_u32 (__val.val[0],\n+\t\t\t\tvcreate_u32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_u32 (__val.val[1],\n+\t\t\t\tvcreate_u32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_u32 (__val.val[2],\n+\t\t\t\tvcreate_u32 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_u32 (__val.val[3],\n+\t\t\t\tvcreate_u32 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev2si ((__builtin_aarch64_simd_si *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_u64 (uint64_t *__ptr, uint64x1x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  uint64x2x4_t __temp;\n+  __temp.val[0] = vcombine_u64 (__val.val[0],\n+\t\t\t\tvcreate_u64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_u64 (__val.val[1],\n+\t\t\t\tvcreate_u64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_u64 (__val.val[2],\n+\t\t\t\tvcreate_u64 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_u64 (__val.val[3],\n+\t\t\t\tvcreate_u64 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanedi ((__builtin_aarch64_simd_di *) __ptr, __o,\n+\t\t\t\t__lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_f16 (float16_t *__ptr, float16x8x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev8hf ((__builtin_aarch64_simd_hf *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_f32 (float32_t *__ptr, float32x4x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev4sf ((__builtin_aarch64_simd_sf *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_f64 (float64_t *__ptr, float64x2x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev2df ((__builtin_aarch64_simd_df *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_p8 (poly8_t *__ptr, poly8x16x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev16qi ((__builtin_aarch64_simd_qi *) __ptr, __o,\n+\t\t\t\t   __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_p16 (poly16_t *__ptr, poly16x8x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev8hi ((__builtin_aarch64_simd_hi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_p64 (poly64_t *__ptr, poly64x2x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev2di ((__builtin_aarch64_simd_di *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_s8 (int8_t *__ptr, int8x16x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev16qi ((__builtin_aarch64_simd_qi *) __ptr, __o,\n+\t\t\t\t   __lane);\n }\n \n-__ST4Q_LANE_FUNC (float16x8x4_t, float16_t, v8hf, hf, f16)\n-__ST4Q_LANE_FUNC (float32x4x4_t, float32_t, v4sf, sf, f32)\n-__ST4Q_LANE_FUNC (float64x2x4_t, float64_t, v2df, df, f64)\n-__ST4Q_LANE_FUNC (poly8x16x4_t, poly8_t, v16qi, qi, p8)\n-__ST4Q_LANE_FUNC (poly16x8x4_t, poly16_t, v8hi, hi, p16)\n-__ST4Q_LANE_FUNC (poly64x2x4_t, poly64_t, v2di, di, p64)\n-__ST4Q_LANE_FUNC (int8x16x4_t, int8_t, v16qi, qi, s8)\n-__ST4Q_LANE_FUNC (int16x8x4_t, int16_t, v8hi, hi, s16)\n-__ST4Q_LANE_FUNC (int32x4x4_t, int32_t, v4si, si, s32)\n-__ST4Q_LANE_FUNC (int64x2x4_t, int64_t, v2di, di, s64)\n-__ST4Q_LANE_FUNC (uint8x16x4_t, uint8_t, v16qi, qi, u8)\n-__ST4Q_LANE_FUNC (uint16x8x4_t, uint16_t, v8hi, hi, u16)\n-__ST4Q_LANE_FUNC (uint32x4x4_t, uint32_t, v4si, si, u32)\n-__ST4Q_LANE_FUNC (uint64x2x4_t, uint64_t, v2di, di, u64)\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_s16 (int16_t *__ptr, int16x8x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev8hi ((__builtin_aarch64_simd_hi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_s32 (int32_t *__ptr, int32x4x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev4si ((__builtin_aarch64_simd_si *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_s64 (int64_t *__ptr, int64x2x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev2di ((__builtin_aarch64_simd_di *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_u8 (uint8_t *__ptr, uint8x16x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev16qi ((__builtin_aarch64_simd_qi *) __ptr, __o,\n+\t\t\t\t   __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_u16 (uint16_t *__ptr, uint16x8x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev8hi ((__builtin_aarch64_simd_hi *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_u32 (uint32_t *__ptr, uint32x4x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev4si ((__builtin_aarch64_simd_si *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_u64 (uint64_t *__ptr, uint64x2x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev2di ((__builtin_aarch64_simd_di *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n \n __extension__ extern __inline int64_t\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n@@ -33729,9 +34046,35 @@ __ST2Q_LANE_FUNC (bfloat16x8x2_t, bfloat16_t, v8bf, bf, bf16)\n __ST3_LANE_FUNC (bfloat16x4x3_t, bfloat16x8x3_t, bfloat16_t, v4bf, v8bf, bf,\n \t\t bf16, bfloat16x8_t)\n __ST3Q_LANE_FUNC (bfloat16x8x3_t, bfloat16_t, v8bf, bf, bf16)\n-__ST4_LANE_FUNC (bfloat16x4x4_t, bfloat16x8x4_t, bfloat16_t, v4bf, v8bf, bf,\n-\t\t bf16, bfloat16x8_t)\n-__ST4Q_LANE_FUNC (bfloat16x8x4_t, bfloat16_t, v8bf, bf, bf16)\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4_lane_bf16 (bfloat16_t *__ptr, bfloat16x4x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  bfloat16x8x4_t __temp;\n+  __temp.val[0] = vcombine_bf16 (__val.val[0],\n+\t\t\t\t vcreate_bf16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[1] = vcombine_bf16 (__val.val[1],\n+\t\t\t\t vcreate_bf16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[2] = vcombine_bf16 (__val.val[2],\n+\t\t\t\t vcreate_bf16 (__AARCH64_UINT64_C (0)));\n+  __temp.val[3] = vcombine_bf16 (__val.val[3],\n+\t\t\t\t vcreate_bf16 (__AARCH64_UINT64_C (0)));\n+  __builtin_memcpy (&__o, &__temp, sizeof (__temp));\n+  __builtin_aarch64_st4_lanev4bf ((__builtin_aarch64_simd_bf *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n+\n+__extension__ extern __inline void\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vst4q_lane_bf16 (bfloat16_t *__ptr, bfloat16x8x4_t __val, const int __lane)\n+{\n+  __builtin_aarch64_simd_xi __o;\n+  __builtin_memcpy (&__o, &__val, sizeof (__val));\n+  __builtin_aarch64_st4_lanev8bf ((__builtin_aarch64_simd_bf *) __ptr, __o,\n+\t\t\t\t  __lane);\n+}\n \n #pragma GCC pop_options\n \n@@ -33956,7 +34299,5 @@ vaddq_p128 (poly128_t __a, poly128_t __b)\n #undef __ST2Q_LANE_FUNC\n #undef __ST3_LANE_FUNC\n #undef __ST3Q_LANE_FUNC\n-#undef __ST4_LANE_FUNC\n-#undef __ST4Q_LANE_FUNC\n \n #endif"}, {"sha": "7504153991d6016f4a6cc7e33f51a6014358e9d4", "filename": "gcc/testsuite/gcc.target/aarch64/vector_structure_intrinsics.c", "status": "modified", "additions": 24, "deletions": 2, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a6075926947be9bcbf7016bf4b29f549102ad91d/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a6075926947be9bcbf7016bf4b29f549102ad91d/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c?ref=a6075926947be9bcbf7016bf4b29f549102ad91d", "patch": "@@ -1,5 +1,5 @@\n /* { dg-do compile } */\n-/* { dg-options \"-O3\" } */\n+/* { dg-options \"-O3 -march=armv8.2-a+bf16\" } */\n \n #include <arm_neon.h>\n \n@@ -139,6 +139,28 @@ TEST_ST3 (vst3q, uint64x2x3_t, uint64_t*, u64);\n TEST_ST3 (vst3q, float64x2x3_t, float64_t*, f64);\n TEST_ST3 (vst3q, poly64x2x3_t, poly64_t*, p64);\n \n+#define TEST_STX_LANE(name, tbltype, ptrtype, ts) \\\n+  void test_ ## name ## _ ## ts (ptrtype a, tbltype b) \\\n+\t{ \\\n+\t\tname ## _ ## ts (a, b, 1); \\\n+\t}\n+\n+TEST_STX_LANE (vst4q_lane, int8x16x4_t, int8_t*, s8);\n+TEST_STX_LANE (vst4q_lane, uint8x16x4_t, uint8_t*, u8);\n+TEST_STX_LANE (vst4q_lane, poly8x16x4_t, poly8_t*, p8);\n+TEST_STX_LANE (vst4q_lane, int16x8x4_t, int16_t*, s16);\n+TEST_STX_LANE (vst4q_lane, uint16x8x4_t, uint16_t*, u16);\n+TEST_STX_LANE (vst4q_lane, poly16x8x4_t, poly16_t*, p16);\n+TEST_STX_LANE (vst4q_lane, float16x8x4_t, float16_t*, f16);\n+TEST_STX_LANE (vst4q_lane, bfloat16x8x4_t, bfloat16_t*, bf16);\n+TEST_STX_LANE (vst4q_lane, int32x4x4_t, int32_t*, s32);\n+TEST_STX_LANE (vst4q_lane, uint32x4x4_t, uint32_t*, u32);\n+TEST_STX_LANE (vst4q_lane, float32x4x4_t, float32_t*, f32);\n+TEST_STX_LANE (vst4q_lane, int64x2x4_t, int64_t*, s64);\n+TEST_STX_LANE (vst4q_lane, uint64x2x4_t, uint64_t*, u64);\n+TEST_STX_LANE (vst4q_lane, float64x2x4_t, float64_t*, f64);\n+TEST_STX_LANE (vst4q_lane, poly64x2x4_t, poly64_t*, p64);\n+\n #define TEST_ST1xN(name, tbltype, ptrtype, ts, xn) \\\n   void test_ ## name ## _ ## ts ## _ ## xn (ptrtype a, tbltype b) \\\n \t{ \\\n@@ -201,7 +223,7 @@ TEST_ST1x3 (vst1q, float64x2x3_t, float64_t*, f64, x3);\n \n /* { dg-final { scan-assembler-times \"tbl\\\\t\" 18} }  */\n /* { dg-final { scan-assembler-times \"tbx\\\\t\" 18} }  */\n-/* { dg-final { scan-assembler-times \"st4\\\\t\" 14} }  */\n+/* { dg-final { scan-assembler-times \"st4\\\\t\" 29} }  */\n /* { dg-final { scan-assembler-times \"st3\\\\t\" 14} }  */\n /* { dg-final { scan-assembler-times \"st2\\\\t\" 14} }  */\n /* { dg-final { scan-assembler-times \"st1\\\\t\" 42} }  */"}]}