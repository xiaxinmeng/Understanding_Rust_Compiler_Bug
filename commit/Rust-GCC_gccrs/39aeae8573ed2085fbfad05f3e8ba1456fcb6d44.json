{"sha": "39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzlhZWFlODU3M2VkMjA4NWZiZmFkMDVmM2U4YmExNDU2ZmNiNmQ0NA==", "commit": {"author": {"name": "Sa Liu", "email": "saliu@de.ibm.com", "date": "2007-07-13T18:31:08Z"}, "committer": {"name": "Ulrich Weigand", "email": "uweigand@gcc.gnu.org", "date": "2007-07-13T18:31:08Z"}, "message": "config.gcc: Add options for arch and tune on SPU.\n\n2007-07-13  Sa Liu  <saliu@de.ibm.com>\n\n\t* config.gcc: Add options for arch and tune on SPU.\n\t* config/spu/predicates.md: Add constant operands 0 and 1.\n\t* config/spu/spu-builtins.def: Add builtins for double precision \n\tfloating point comparison: si_dfceq, si_dfcmeq,\tsi_dfcgt, si_dfcmgt, \n\tsi_dftsv, spu_cmpeq_13, spu_cmpabseq_1, spu_cmpgt_13, spu_cmpabsgt_1,\n\tspu_testsv.\n\t* config/spu/spu-c.c: Define __SPU_EDP__ when builtins invoked with \n\ta CELLEDP target.\n\t* config/spu/spu-protos.h: Add new function prototypes. \n\t* config/spu/spu.c (spu_override_options): Check options -march and\n\t-mtune.\n\t(spu_comp_icode): Add comparison code for DFmode and vector mode.\n\t(spu_emit_branch_or_set): Use the new code for DFmode and vector \n\tmode comparison.\n\t(spu_const_from_int): New.  Create a vector constant from 4 ints.\n\t(get_vec_cmp_insn): New.  Get insn index of vector compare instruction.\n\t(spu_emit_vector_compare): New.  Emit vector compare.\n\t(spu_emit_vector_cond_expr): New.  Emit vector conditional expression.\n\t* config/spu/spu.h: Add options -march and -mtune.  Define processor\n\ttypes PROCESSOR_CELL and PROCESSOR_CELLEDP.  Define macro\n\tCANONICALIZE_COMPARISON.\n\t* config/spu/spu.md: Add new insns for double precision compare\n\tand double precision vector compare.  Add vcond and smax/smin patterns\n\tto enable DFmode vector conditional expression.\n\t* config/spu/spu.opt: Add options -march and -mtune.\n\t* config/spu/spu_internals.h: Add builtins for CELLEDP target:\n\tsi_dfceq, si_dfcmeq, si_dfcgt, si_dfcmgt, si_dftsv.  Add builtin for\n\tboth CELL and CELLEDP targets: spu_testsv.\n\t* config/spu/spu_intrinsics.h: Add flag mnemonics for test special \n\tvalues.\n\ntestsuite/\n\t* gcc.dg/vect/fast-math-vect-reduc-7.c: Switch on test\n\tfor V2DFmode vector conditional expression.\n\t* gcc.target/spu/dfcmeq.c: New.  Test combination of abs\n\tand dfceq patterns.\n\t* gcc.target/spu/dfcmgt.c: New.  Test combination of abs\n\tand dfcgt patterns.\n\t* gcc.target/spu/intrinsics-2.c: New.  Test intrinsics for\n\tV2DFmode comparison and test special values.\n\t* lib/target-supports.exp: Switch on test for V2DFmode \n\tvector conditional expression.\n\nFrom-SVN: r126626", "tree": {"sha": "5426797cdb67dde5f5c7640c88b2c18b729ddd9b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/5426797cdb67dde5f5c7640c88b2c18b729ddd9b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "html_url": "https://github.com/Rust-GCC/gccrs/commit/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/comments", "author": {"login": "sa-liu", "id": 47213938, "node_id": "MDQ6VXNlcjQ3MjEzOTM4", "avatar_url": "https://avatars.githubusercontent.com/u/47213938?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sa-liu", "html_url": "https://github.com/sa-liu", "followers_url": "https://api.github.com/users/sa-liu/followers", "following_url": "https://api.github.com/users/sa-liu/following{/other_user}", "gists_url": "https://api.github.com/users/sa-liu/gists{/gist_id}", "starred_url": "https://api.github.com/users/sa-liu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sa-liu/subscriptions", "organizations_url": "https://api.github.com/users/sa-liu/orgs", "repos_url": "https://api.github.com/users/sa-liu/repos", "events_url": "https://api.github.com/users/sa-liu/events{/privacy}", "received_events_url": "https://api.github.com/users/sa-liu/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "2826df069f786fb321bb60525340fffaa1f22b6b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2826df069f786fb321bb60525340fffaa1f22b6b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2826df069f786fb321bb60525340fffaa1f22b6b"}], "stats": {"total": 1129, "additions": 1062, "deletions": 67}, "files": [{"sha": "6aeca7e06b9b9d72d9926bd8a3501c5bee3fcc75", "filename": "gcc/ChangeLog", "status": "modified", "additions": 33, "deletions": 0, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -1,3 +1,36 @@\n+2007-07-13  Sa Liu  <saliu@de.ibm.com>\n+\n+\t* config.gcc: Add options for arch and tune on SPU.\n+\t* config/spu/predicates.md: Add constant operands 0 and 1.\n+\t* config/spu/spu-builtins.def: Add builtins for double precision \n+\tfloating point comparison: si_dfceq, si_dfcmeq,\tsi_dfcgt, si_dfcmgt, \n+\tsi_dftsv, spu_cmpeq_13, spu_cmpabseq_1, spu_cmpgt_13, spu_cmpabsgt_1,\n+\tspu_testsv.\n+\t* config/spu/spu-c.c: Define __SPU_EDP__ when builtins invoked with \n+\ta CELLEDP target.\n+\t* config/spu/spu-protos.h: Add new function prototypes. \n+\t* config/spu/spu.c (spu_override_options): Check options -march and\n+\t-mtune.\n+\t(spu_comp_icode): Add comparison code for DFmode and vector mode.\n+\t(spu_emit_branch_or_set): Use the new code for DFmode and vector \n+\tmode comparison.\n+\t(spu_const_from_int): New.  Create a vector constant from 4 ints.\n+\t(get_vec_cmp_insn): New.  Get insn index of vector compare instruction.\n+\t(spu_emit_vector_compare): New.  Emit vector compare.\n+\t(spu_emit_vector_cond_expr): New.  Emit vector conditional expression.\n+\t* config/spu/spu.h: Add options -march and -mtune.  Define processor\n+\ttypes PROCESSOR_CELL and PROCESSOR_CELLEDP.  Define macro\n+\tCANONICALIZE_COMPARISON.\n+\t* config/spu/spu.md: Add new insns for double precision compare\n+\tand double precision vector compare.  Add vcond and smax/smin patterns\n+\tto enable DFmode vector conditional expression.\n+\t* config/spu/spu.opt: Add options -march and -mtune.\n+\t* config/spu/spu_internals.h: Add builtins for CELLEDP target:\n+\tsi_dfceq, si_dfcmeq, si_dfcgt, si_dfcmgt, si_dftsv.  Add builtin for\n+\tboth CELL and CELLEDP targets: spu_testsv.\n+\t* config/spu/spu_intrinsics.h: Add flag mnemonics for test special \n+\tvalues.\n+\n 2007-07-13  Richard Guenther  <rguenther@suse.de>\n \n \tPR tree-optimization/32721"}, {"sha": "f13d7db31d6f4b2f177d1cf95965a8e5668a5f9e", "filename": "gcc/config.gcc", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -3142,6 +3142,23 @@ case \"${target}\" in\n \t\tesac\n \t\t;;\n \n+\tspu-*-*)\n+\t\tsupported_defaults=\"arch tune\"\n+\n+\t\tfor which in arch tune; do\n+\t\t\teval \"val=\\$with_$which\"\n+\t\t\tcase ${val} in\n+\t\t\t\"\" | cell | celledp)\n+\t\t\t\t# OK\n+\t\t\t\t;;\n+\t\t\t*)\n+\t\t\t\techo \"Unknown cpu used in --with-$which=$val.\" 1>&2\n+\t\t\t\texit 1\n+\t\t\t\t;;\n+\t\t\tesac\n+\t\tdone\n+\t\t;;\n+\n \tv850*-*-*)\n \t\tsupported_defaults=cpu\n \t\tcase ${with_cpu} in"}, {"sha": "74659c3a19f7443467867d38da50e7806e4954dd", "filename": "gcc/config/spu/predicates.md", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fpredicates.md?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -16,6 +16,15 @@\n ;; Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n ;; 02110-1301, USA.\n \n+;; Return 1 if operand is constant zero of its mode\n+(define_predicate \"const_zero_operand\"\n+  (and (match_code \"const_int,const,const_double,const_vector\")\n+       (match_test \"op == CONST0_RTX (mode)\")))\n+\n+(define_predicate \"const_one_operand\"\n+  (and (match_code \"const_int,const,const_double,const_vector\")\n+       (match_test \"op == CONST1_RTX (mode)\")))\n+\n (define_predicate \"spu_reg_operand\"\n   (and (match_operand 0 \"register_operand\")\n        (ior (not (match_code \"subreg\"))"}, {"sha": "9ab1b5d8cd1f8e5b0a8a755a6d7ebd00d6296ec8", "filename": "gcc/config/spu/spu-builtins.def", "status": "modified", "additions": 14, "deletions": 2, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-builtins.def?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -189,9 +189,14 @@ DEF_BUILTIN (SI_CFLTU,       CODE_FOR_spu_cfltu,     \"si_cfltu\",       B_INSN,\n DEF_BUILTIN (SI_FRDS,        CODE_FOR_spu_frds,      \"si_frds\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_FESD,        CODE_FOR_spu_fesd,      \"si_fesd\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_FCEQ,        CODE_FOR_ceq_v4sf,      \"si_fceq\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFCEQ,       CODE_FOR_ceq_v2df,      \"si_dfceq\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_FCMEQ,       CODE_FOR_cmeq_v4sf,     \"si_fcmeq\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFCMEQ,      CODE_FOR_cmeq_v2df,     \"si_dfcmeq\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_FCGT,        CODE_FOR_cgt_v4sf,      \"si_fcgt\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFCGT,       CODE_FOR_cgt_v2df,      \"si_dfcgt\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_FCMGT,       CODE_FOR_cmgt_v4sf,     \"si_fcmgt\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFCMGT,      CODE_FOR_cmgt_v2df,     \"si_dfcmgt\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFTSV,       CODE_FOR_dftsv,         \"si_dftsv\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_U7))\n DEF_BUILTIN (SI_STOP,        CODE_FOR_spu_stop,      \"si_stop\",        B_INSN,   _A2(SPU_BTI_VOID,     SPU_BTI_U14))\n DEF_BUILTIN (SI_STOPD,       CODE_FOR_spu_stopd,     \"si_stopd\",       B_INSN,   _A4(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_LNOP,        CODE_FOR_lnop,          \"si_lnop\",        B_INSN,   _A1(SPU_BTI_VOID))\n@@ -245,11 +250,10 @@ DEF_BUILTIN (SPU_SUMB,       CODE_FOR_spu_sumb,       \"spu_sumb\",       B_INSN,\n DEF_BUILTIN (SPU_BISLED,     CODE_FOR_spu_bisled,     \"spu_bisled\",     B_BISLED,   _A3(SPU_BTI_VOID,    SPU_BTI_PTR,   SPU_BTI_PTR))\n DEF_BUILTIN (SPU_BISLED_D,   CODE_FOR_spu_bisledd,    \"spu_bisled_d\",   B_BISLED,   _A3(SPU_BTI_VOID,    SPU_BTI_PTR,   SPU_BTI_PTR))\n DEF_BUILTIN (SPU_BISLED_E,   CODE_FOR_spu_bislede,    \"spu_bisled_e\",   B_BISLED,   _A3(SPU_BTI_VOID,    SPU_BTI_PTR,   SPU_BTI_PTR))\n-DEF_BUILTIN (SPU_CMPABSEQ,   CODE_FOR_cmeq_v4sf,      \"spu_cmpabseq\",   B_INSN,     _A3(SPU_BTI_UV4SI,    SPU_BTI_V4SF,   SPU_BTI_V4SF))\n-DEF_BUILTIN (SPU_CMPABSGT,   CODE_FOR_cmgt_v4sf,      \"spu_cmpabsgt\",   B_INSN,     _A3(SPU_BTI_UV4SI,    SPU_BTI_V4SF,   SPU_BTI_V4SF))\n DEF_BUILTIN (SPU_IDISABLE,   CODE_FOR_spu_idisable,   \"spu_idisable\",   B_INSN,     _A1(SPU_BTI_VOID))\n DEF_BUILTIN (SPU_IENABLE,    CODE_FOR_spu_ienable,    \"spu_ienable\",    B_INSN,     _A1(SPU_BTI_VOID))\n DEF_BUILTIN (SPU_MASK_FOR_LOAD,    CODE_FOR_spu_lvsr, \"spu_lvsr\",       B_INSN,     _A2(SPU_BTI_V16QI, SPU_BTI_PTR))\n+DEF_BUILTIN (SPU_TESTSV,     CODE_FOR_dftsv,          \"spu_testsv\",     B_INSN,     _A3(SPU_BTI_UV2DI, SPU_BTI_V2DF, SPU_BTI_U7))\n \n /* definitions to support overloaded generic builtin functions:  */\n \n@@ -339,6 +343,10 @@ DEF_BUILTIN (SPU_CMPEQ_9,          CODE_FOR_ceq_v8hi,      \"spu_cmpeq_9\",\n DEF_BUILTIN (SPU_CMPEQ_10,         CODE_FOR_ceq_v8hi,      \"spu_cmpeq_10\",         B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_V8HI,   SPU_BTI_INTHI))\n DEF_BUILTIN (SPU_CMPEQ_11,         CODE_FOR_ceq_v4si,      \"spu_cmpeq_11\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n DEF_BUILTIN (SPU_CMPEQ_12,         CODE_FOR_ceq_v4si,      \"spu_cmpeq_12\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_CMPEQ_13,         CODE_FOR_ceq_v2df,      \"spu_cmpeq_13\",         B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_CMPABSEQ,         CODE_FOR_nothing,       \"spu_cmpabseq\",         B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_CMPABSEQ_0,       CODE_FOR_cmeq_v4sf,     \"spu_cmpabseq_0\",       B_INTERNAL, _A3(SPU_BTI_UV4SI, SPU_BTI_V4SF, SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_CMPABSEQ_1,       CODE_FOR_cmeq_v2df,     \"spu_cmpabseq_1\",       B_INTERNAL, _A3(SPU_BTI_UV2DI, SPU_BTI_V2DF, SPU_BTI_V2DF))\n DEF_BUILTIN (SPU_CMPGT,            CODE_FOR_nothing,       \"spu_cmpgt\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n DEF_BUILTIN (SPU_CMPGT_0,          CODE_FOR_clgt_v16qi,    \"spu_cmpgt_0\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n DEF_BUILTIN (SPU_CMPGT_1,          CODE_FOR_cgt_v16qi,     \"spu_cmpgt_1\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_V16QI,  SPU_BTI_V16QI))\n@@ -353,6 +361,10 @@ DEF_BUILTIN (SPU_CMPGT_9,          CODE_FOR_clgt_v8hi,     \"spu_cmpgt_9\",\n DEF_BUILTIN (SPU_CMPGT_10,         CODE_FOR_cgt_v8hi,      \"spu_cmpgt_10\",         B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_V8HI,   SPU_BTI_INTHI))\n DEF_BUILTIN (SPU_CMPGT_11,         CODE_FOR_cgt_v4si,      \"spu_cmpgt_11\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_V4SI,   SPU_BTI_INTSI))\n DEF_BUILTIN (SPU_CMPGT_12,         CODE_FOR_clgt_v4si,     \"spu_cmpgt_12\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_CMPGT_13,         CODE_FOR_cgt_v2df,      \"spu_cmpgt_13\",         B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_CMPABSGT,         CODE_FOR_nothing,       \"spu_cmpabsgt\",         B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_CMPABSGT_0,       CODE_FOR_cmgt_v4sf,     \"spu_cmpabsgt_0\",       B_INTERNAL, _A3(SPU_BTI_UV4SI, SPU_BTI_V4SF, SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_CMPABSGT_1,       CODE_FOR_cmgt_v2df,     \"spu_cmpabsgt_1\",       B_INTERNAL, _A3(SPU_BTI_UV2DI, SPU_BTI_V2DF, SPU_BTI_V2DF))\n DEF_BUILTIN (SPU_HCMPEQ,           CODE_FOR_nothing,       \"spu_hcmpeq\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n DEF_BUILTIN (SPU_HCMPEQ_0,         CODE_FOR_spu_heq,       \"spu_hcmpeq_0\",         B_INTERNAL, _A3(SPU_BTI_VOID,  SPU_BTI_INTSI,  SPU_BTI_INTSI))\n DEF_BUILTIN (SPU_HCMPEQ_1,         CODE_FOR_spu_heq,       \"spu_hcmpeq_1\",         B_INTERNAL, _A3(SPU_BTI_VOID,  SPU_BTI_UINTSI, SPU_BTI_UINTSI))"}, {"sha": "56ddefb7b1182b00f1259a6cc634cd8fa4372340", "filename": "gcc/config/spu/spu-c.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-c.c?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -138,6 +138,8 @@ spu_cpu_cpp_builtins (struct cpp_reader *pfile)\n   builtin_define_std (\"__SPU__\");\n   cpp_assert (pfile, \"cpu=spu\");\n   cpp_assert (pfile, \"machine=spu\");\n+  if (spu_arch == PROCESSOR_CELLEDP)\n+    builtin_define_std (\"__SPU_EDP__\");\n   builtin_define_std (\"__vector=__attribute__((__spu_vector__))\");\n }\n "}, {"sha": "d06953694d40ba57333f537689185841c3d8afe0", "filename": "gcc/config/spu/spu-protos.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-protos.h?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -32,6 +32,7 @@ extern void spu_expand_insv (rtx * ops);\n extern int spu_expand_block_move (rtx * ops);\n extern void spu_emit_branch_or_set (int is_set, enum rtx_code code,\n \t\t\t\t    rtx * operands);\n+extern int spu_emit_vector_cond_expr (rtx, rtx, rtx, rtx, rtx, rtx);\n extern HOST_WIDE_INT const_double_to_hwint (rtx x);\n extern rtx hwint_to_const_double (enum machine_mode mode, HOST_WIDE_INT v);\n extern void print_operand_address (FILE * file, register rtx addr);\n@@ -43,6 +44,8 @@ extern void spu_expand_prologue (void);\n extern void spu_expand_epilogue (unsigned char sibcall_p);\n extern rtx spu_return_addr (int count, rtx frame);\n extern rtx spu_const (enum machine_mode mode, HOST_WIDE_INT val);\n+extern rtx spu_const_from_ints (enum machine_mode mode, \n+\t\t\t        int a, int b, int c, int d);\n extern struct rtx_def *spu_float_const (const char *string,\n \t\t\t\t\tenum machine_mode mode);\n extern int immediate_load_p (rtx op, enum machine_mode mode);"}, {"sha": "e283d87c0d4f06234d1d297506b0fb8249978dcc", "filename": "gcc/config/spu/spu.c", "status": "modified", "additions": 287, "deletions": 20, "changes": 307, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.c?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -95,6 +95,8 @@ static void emit_nop_for_insn (rtx insn);\n static bool insn_clobbers_hbr (rtx insn);\n static void spu_emit_branch_hint (rtx before, rtx branch, rtx target,\n \t\t\t\t  int distance);\n+static rtx spu_emit_vector_compare (enum rtx_code rcode, rtx op0, rtx op1,\n+\t                            enum machine_mode dmode);\n static rtx get_branch_target (rtx branch);\n static void insert_branch_hints (void);\n static void insert_nops (void);\n@@ -138,6 +140,11 @@ static int spu_builtin_vectorization_cost (bool);\n extern const char *reg_names[];\n rtx spu_compare_op0, spu_compare_op1;\n \n+/* Which instruction set architecture to use.  */\n+int spu_arch;\n+/* Which cpu are we tuning for.  */\n+int spu_tune;\n+\n enum spu_immediate {\n   SPU_NONE,\n   SPU_IL,\n@@ -298,6 +305,28 @@ spu_override_options (void)\n \n   if (spu_fixed_range_string)\n     fix_range (spu_fixed_range_string);\n+\n+  /* Determine processor architectural level.  */\n+  if (spu_arch_string)\n+    {\n+      if (strcmp (&spu_arch_string[0], \"cell\") == 0)\n+        spu_arch = PROCESSOR_CELL;\n+      else if (strcmp (&spu_arch_string[0], \"celledp\") == 0)\n+        spu_arch = PROCESSOR_CELLEDP;\n+      else\n+        error (\"Unknown architecture '%s'\", &spu_arch_string[0]);\n+    }\n+\n+  /* Determine processor to tune for.  */\n+  if (spu_tune_string)\n+    {\n+      if (strcmp (&spu_tune_string[0], \"cell\") == 0)\n+        spu_tune = PROCESSOR_CELL;\n+      else if (strcmp (&spu_tune_string[0], \"celledp\") == 0)\n+        spu_tune = PROCESSOR_CELLEDP;\n+      else\n+        error (\"Unknown architecture '%s'\", &spu_tune_string[0]);\n+    }\n }\n \f\n /* Handle an attribute requiring a FUNCTION_DECL; arguments as in\n@@ -646,16 +675,19 @@ spu_expand_block_move (rtx ops[])\n enum spu_comp_code\n { SPU_EQ, SPU_GT, SPU_GTU };\n \n-\n-int spu_comp_icode[8][3] = {\n-  {CODE_FOR_ceq_qi, CODE_FOR_cgt_qi, CODE_FOR_clgt_qi},\n-  {CODE_FOR_ceq_hi, CODE_FOR_cgt_hi, CODE_FOR_clgt_hi},\n-  {CODE_FOR_ceq_si, CODE_FOR_cgt_si, CODE_FOR_clgt_si},\n-  {CODE_FOR_ceq_di, CODE_FOR_cgt_di, CODE_FOR_clgt_di},\n-  {CODE_FOR_ceq_ti, CODE_FOR_cgt_ti, CODE_FOR_clgt_ti},\n-  {CODE_FOR_ceq_sf, CODE_FOR_cgt_sf, 0},\n-  {0, 0, 0},\n-  {CODE_FOR_ceq_vec, 0, 0},\n+int spu_comp_icode[12][3] = {\n+ {CODE_FOR_ceq_qi, CODE_FOR_cgt_qi, CODE_FOR_clgt_qi},\n+ {CODE_FOR_ceq_hi, CODE_FOR_cgt_hi, CODE_FOR_clgt_hi},\n+ {CODE_FOR_ceq_si, CODE_FOR_cgt_si, CODE_FOR_clgt_si},\n+ {CODE_FOR_ceq_di, CODE_FOR_cgt_di, CODE_FOR_clgt_di},\n+ {CODE_FOR_ceq_ti, CODE_FOR_cgt_ti, CODE_FOR_clgt_ti},\n+ {CODE_FOR_ceq_sf, CODE_FOR_cgt_sf, 0},\n+ {CODE_FOR_ceq_df, CODE_FOR_cgt_df, 0},\n+ {CODE_FOR_ceq_v16qi, CODE_FOR_cgt_v16qi, CODE_FOR_clgt_v16qi},\n+ {CODE_FOR_ceq_v8hi,  CODE_FOR_cgt_v8hi,  CODE_FOR_clgt_v8hi},\n+ {CODE_FOR_ceq_v4si,  CODE_FOR_cgt_v4si,  CODE_FOR_clgt_v4si},\n+ {CODE_FOR_ceq_v4sf,  CODE_FOR_cgt_v4sf, 0},\n+ {CODE_FOR_ceq_v2df,  CODE_FOR_cgt_v2df, 0},\n };\n \n /* Generate a compare for CODE.  Return a brand-new rtx that represents\n@@ -786,30 +818,46 @@ spu_emit_branch_or_set (int is_set, enum rtx_code code, rtx operands[])\n       index = 6;\n       break;\n     case V16QImode:\n+      index = 7;\n+      comp_mode = op_mode;\n+      break;\n     case V8HImode:\n+      index = 8;\n+      comp_mode = op_mode;\n+      break;\n     case V4SImode:\n-    case V2DImode:\n+      index = 9;\n+      comp_mode = op_mode;\n+      break;\n     case V4SFmode:\n+      index = 10;\n+      comp_mode = V4SImode;\n+      break;\n     case V2DFmode:\n-      index = 7;\n+      index = 11;\n+      comp_mode = V2DImode;\n       break;\n+    case V2DImode:\n     default:\n       abort ();\n     }\n \n   if (GET_MODE (spu_compare_op1) == DFmode)\n     {\n       rtx reg = gen_reg_rtx (DFmode);\n-      if (!flag_unsafe_math_optimizations\n+      if ((!flag_unsafe_math_optimizations && spu_arch == PROCESSOR_CELL)\n \t  || (scode != SPU_GT && scode != SPU_EQ))\n \tabort ();\n-      if (reverse_compare)\n-\temit_insn (gen_subdf3 (reg, spu_compare_op1, spu_compare_op0));\n-      else\n-\temit_insn (gen_subdf3 (reg, spu_compare_op0, spu_compare_op1));\n-      reverse_compare = 0;\n-      spu_compare_op0 = reg;\n-      spu_compare_op1 = CONST0_RTX (DFmode);\n+      if (spu_arch == PROCESSOR_CELL)\n+      {\n+        if (reverse_compare)\n+\t  emit_insn (gen_subdf3 (reg, spu_compare_op1, spu_compare_op0));\n+        else\n+\t  emit_insn (gen_subdf3 (reg, spu_compare_op0, spu_compare_op1));\n+        reverse_compare = 0;\n+        spu_compare_op0 = reg;\n+        spu_compare_op1 = CONST0_RTX (DFmode);\n+      }\n     }\n \n   if (is_set == 0 && spu_compare_op1 == const0_rtx\n@@ -1884,6 +1932,30 @@ spu_const (enum machine_mode mode, HOST_WIDE_INT val)\n    size.) */\n int spu_hint_dist = (8 * 4);\n \n+/* Create a MODE vector constant from 4 ints. */\n+rtx\n+spu_const_from_ints(enum machine_mode mode, int a, int b, int c, int d)\n+{\n+  unsigned char arr[16];\n+  arr[0] = (a >> 24) & 0xff;\n+  arr[1] = (a >> 16) & 0xff;\n+  arr[2] = (a >> 8) & 0xff;\n+  arr[3] = (a >> 0) & 0xff;\n+  arr[4] = (b >> 24) & 0xff;\n+  arr[5] = (b >> 16) & 0xff;\n+  arr[6] = (b >> 8) & 0xff;\n+  arr[7] = (b >> 0) & 0xff;\n+  arr[8] = (c >> 24) & 0xff;\n+  arr[9] = (c >> 16) & 0xff;\n+  arr[10] = (c >> 8) & 0xff;\n+  arr[11] = (c >> 0) & 0xff;\n+  arr[12] = (d >> 24) & 0xff;\n+  arr[13] = (d >> 16) & 0xff;\n+  arr[14] = (d >> 8) & 0xff;\n+  arr[15] = (d >> 0) & 0xff;\n+  return array_to_constant(mode, arr);\n+}\n+\n /* An array of these is used to propagate hints to predecessor blocks. */\n struct spu_bb_info\n {\n@@ -4857,6 +4929,201 @@ spu_expand_vector_init (rtx target, rtx vals)\n     }\n }\n \n+/* Return insn index for the vector compare instruction for given CODE,\n+   and DEST_MODE, OP_MODE. Return -1 if valid insn is not available.  */\n+\n+static int\n+get_vec_cmp_insn (enum rtx_code code,\n+                  enum machine_mode dest_mode,\n+                  enum machine_mode op_mode)\n+\n+{\n+  switch (code)\n+    {\n+    case EQ:\n+      if (dest_mode == V16QImode && op_mode == V16QImode)\n+        return CODE_FOR_ceq_v16qi;\n+      if (dest_mode == V8HImode && op_mode == V8HImode)\n+        return CODE_FOR_ceq_v8hi;\n+      if (dest_mode == V4SImode && op_mode == V4SImode)\n+        return CODE_FOR_ceq_v4si;\n+      if (dest_mode == V4SImode && op_mode == V4SFmode)\n+        return CODE_FOR_ceq_v4sf;\n+      if (dest_mode == V2DImode && op_mode == V2DFmode)\n+        return CODE_FOR_ceq_v2df;\n+      break;\n+    case GT:\n+      if (dest_mode == V16QImode && op_mode == V16QImode)\n+        return CODE_FOR_cgt_v16qi;\n+      if (dest_mode == V8HImode && op_mode == V8HImode)\n+        return CODE_FOR_cgt_v8hi;\n+      if (dest_mode == V4SImode && op_mode == V4SImode)\n+        return CODE_FOR_cgt_v4si;\n+      if (dest_mode == V4SImode && op_mode == V4SFmode)\n+        return CODE_FOR_cgt_v4sf;\n+      if (dest_mode == V2DImode && op_mode == V2DFmode)\n+        return CODE_FOR_cgt_v2df;\n+      break;\n+    case GTU:\n+      if (dest_mode == V16QImode && op_mode == V16QImode)\n+        return CODE_FOR_clgt_v16qi;\n+      if (dest_mode == V8HImode && op_mode == V8HImode)\n+        return CODE_FOR_clgt_v8hi;\n+      if (dest_mode == V4SImode && op_mode == V4SImode)\n+        return CODE_FOR_clgt_v4si;\n+      break;\n+    default:\n+      break;\n+    }\n+  return -1;\n+}\n+\n+/* Emit vector compare for operands OP0 and OP1 using code RCODE.\n+   DMODE is expected destination mode. This is a recursive function.  */\n+\n+static rtx\n+spu_emit_vector_compare (enum rtx_code rcode,\n+                         rtx op0, rtx op1,\n+                         enum machine_mode dmode)\n+{\n+  int vec_cmp_insn;\n+  rtx mask;\n+  enum machine_mode dest_mode;\n+  enum machine_mode op_mode = GET_MODE (op1);\n+\n+  gcc_assert (GET_MODE (op0) == GET_MODE (op1));\n+\n+  /* Floating point vector compare instructions uses destination V4SImode.\n+     Double floating point vector compare instructions uses destination V2DImode.\n+     Move destination to appropriate mode later.  */\n+  if (dmode == V4SFmode)\n+    dest_mode = V4SImode;\n+  else if (dmode == V2DFmode)\n+    dest_mode = V2DImode;\n+  else\n+    dest_mode = dmode;\n+\n+  mask = gen_reg_rtx (dest_mode);\n+  vec_cmp_insn = get_vec_cmp_insn (rcode, dest_mode, op_mode);\n+\n+  if (vec_cmp_insn == -1)\n+    {\n+      bool swap_operands = false;\n+      bool try_again = false;\n+      switch (rcode)\n+        {\n+        case LT:\n+          rcode = GT;\n+          swap_operands = true;\n+          try_again = true;\n+          break;\n+        case LTU:\n+          rcode = GTU;\n+          swap_operands = true;\n+          try_again = true;\n+          break;\n+        case NE:\n+          /* Treat A != B as ~(A==B).  */\n+          {\n+            enum insn_code nor_code;\n+            rtx eq_rtx = spu_emit_vector_compare (EQ, op0, op1, dest_mode);\n+            nor_code = one_cmpl_optab->handlers[(int)dest_mode].insn_code;\n+            gcc_assert (nor_code != CODE_FOR_nothing);\n+            emit_insn (GEN_FCN (nor_code) (mask, eq_rtx));\n+            if (dmode != dest_mode)\n+              {\n+                rtx temp = gen_reg_rtx (dest_mode);\n+                convert_move (temp, mask, 0);\n+                return temp;\n+              }\n+            return mask;\n+          }\n+          break;\n+        case GE:\n+        case GEU:\n+        case LE:\n+        case LEU:\n+          /* Try GT/GTU/LT/LTU OR EQ */\n+          {\n+            rtx c_rtx, eq_rtx;\n+            enum insn_code ior_code;\n+            enum rtx_code new_code;\n+\n+            switch (rcode)\n+              {\n+              case GE:  new_code = GT;  break;\n+              case GEU: new_code = GTU; break;\n+              case LE:  new_code = LT;  break;\n+              case LEU: new_code = LTU; break;\n+              default:\n+                gcc_unreachable ();\n+              }\n+\n+            c_rtx = spu_emit_vector_compare (new_code, op0, op1, dest_mode);\n+            eq_rtx = spu_emit_vector_compare (EQ, op0, op1, dest_mode);\n+\n+            ior_code = ior_optab->handlers[(int)dest_mode].insn_code;\n+            gcc_assert (ior_code != CODE_FOR_nothing);\n+            emit_insn (GEN_FCN (ior_code) (mask, c_rtx, eq_rtx));\n+            if (dmode != dest_mode)\n+              {\n+                rtx temp = gen_reg_rtx (dest_mode);\n+                convert_move (temp, mask, 0);\n+                return temp;\n+              }\n+            return mask;\n+          }\n+          break;\n+        default:\n+          gcc_unreachable ();\n+        }\n+\n+      /* You only get two chances.  */\n+      if (try_again)\n+          vec_cmp_insn = get_vec_cmp_insn (rcode, dest_mode, op_mode);\n+\n+      gcc_assert (vec_cmp_insn != -1);\n+\n+      if (swap_operands)\n+        {\n+          rtx tmp;\n+          tmp = op0;\n+          op0 = op1;\n+          op1 = tmp;\n+        }\n+    }\n+\n+  emit_insn (GEN_FCN (vec_cmp_insn) (mask, op0, op1));\n+  if (dmode != dest_mode)\n+    {\n+      rtx temp = gen_reg_rtx (dest_mode);\n+      convert_move (temp, mask, 0);\n+      return temp;\n+    }\n+  return mask;\n+}\n+\n+\n+/* Emit vector conditional expression.\n+   DEST is destination. OP1 and OP2 are two VEC_COND_EXPR operands.\n+   CC_OP0 and CC_OP1 are the two operands for the relation operation COND.  */\n+\n+int\n+spu_emit_vector_cond_expr (rtx dest, rtx op1, rtx op2,\n+                           rtx cond, rtx cc_op0, rtx cc_op1)\n+{   \n+  enum machine_mode dest_mode = GET_MODE (dest);\n+  enum rtx_code rcode = GET_CODE (cond);\n+  rtx mask;\n+    \n+  /* Get the vector mask for the given relational operations.  */\n+  mask = spu_emit_vector_compare (rcode, cc_op0, cc_op1, dest_mode);\n+\n+  emit_insn(gen_selb (dest, op2, op1, mask));\n+\n+  return 1;\n+}\n+\n static rtx\n spu_force_reg (enum machine_mode mode, rtx op)\n {"}, {"sha": "8de32f872d70c64b685970c496b0227c701243a0", "filename": "gcc/config/spu/spu.h", "status": "modified", "additions": 29, "deletions": 1, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.h?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -32,6 +32,23 @@\n extern int target_flags;\n extern const char *spu_fixed_range_string;\n \n+/* Which processor to generate code or schedule for.  */\n+enum processor_type\n+{\n+  PROCESSOR_CELL,\n+  PROCESSOR_CELLEDP\n+};\n+\n+extern GTY(()) int spu_arch;\n+extern GTY(()) int spu_tune;\n+\n+/* Support for a compile-time default architecture and tuning.  The rules are:\n+   --with-arch is ignored if -march is specified.\n+   --with-tune is ignored if -mtune is specified.  */\n+#define OPTION_DEFAULT_SPECS \\\n+  {\"arch\", \"%{!march=*:-march=%(VALUE)}\" }, \\\n+  {\"tune\", \"%{!mtune=*:-mtune=%(VALUE)}\" }\n+\n /* Default target_flags if no switches specified.  */\n #ifndef TARGET_DEFAULT\n #define TARGET_DEFAULT (MASK_ERROR_RELOC | MASK_SAFE_DMA | MASK_BRANCH_HINTS)\n@@ -605,7 +622,18 @@ targetm.resolve_overloaded_builtin = spu_resolve_overloaded_builtin;\t\\\n #define NO_IMPLICIT_EXTERN_C 1\n \n #define HANDLE_PRAGMA_PACK_PUSH_POP 1\n-\f\n+\n+/* Canonicalize a comparison from one we don't have to one we do have.  */\n+#define CANONICALIZE_COMPARISON(CODE,OP0,OP1) \\\n+  do {                                                                    \\\n+    if (((CODE) == LE || (CODE) == LT || (CODE) == LEU || (CODE) == LTU)) \\\n+      {                                                                   \\\n+        rtx tem = (OP0);                                                  \\\n+        (OP0) = (OP1);                                                    \\\n+        (OP1) = tem;                                                      \\\n+        (CODE) = swap_condition (CODE);                                   \\\n+      }                                                                   \\\n+  } while (0)\n \n /* These are set by the cmp patterns and used while expanding\n    conditional branches. */"}, {"sha": "0b339c659fbcf2c3902c96e38a023fec97140596", "filename": "gcc/config/spu/spu.md", "status": "modified", "additions": 624, "deletions": 38, "changes": 662, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.md?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -29,6 +29,7 @@\n (define_attr \"length\" \"\"\n \t\t(const_int 4))\n \n+(define_attr \"tune\" \"cell,celledp\" (const (symbol_ref \"spu_tune\")))\n ;; Processor type -- this attribute must exactly match the processor_type\n ;; enumeration in spu.h.\n \n@@ -59,9 +60,17 @@\n ;; for 6 cycles and the rest of the operation pipelines for\n ;; 7 cycles.  The simplest way to model this is to simply ignore\n ;; the 6 cyle stall.\n-(define_insn_reservation \"FPD\" 7 (eq_attr \"type\" \"fpd\")\n+(define_insn_reservation \"FPD\" 7 \n+  (and (eq_attr \"tune\" \"cell\")\n+       (eq_attr \"type\" \"fpd\"))\n     \"pipe0 + pipe1, fp, nothing*5\")\n \n+;; Tune for CELLEDP, 9 cycles, dual-issuable, fully pipelined\n+(define_insn_reservation \"FPD_CELLEDP\" 9\n+  (and (eq_attr \"tune\" \"celledp\")\n+       (eq_attr \"type\" \"fpd\"))\n+  \"pipe0 + fp, nothing*8\")\n+\n (define_insn_reservation \"LNOP\" 1 (eq_attr \"type\" \"lnop\")\n     \"pipe1\")\n \n@@ -144,6 +153,7 @@\n  (UNSPEC_WRCH           48)\n  (UNSPEC_SPU_REALIGN_LOAD 49)\n  (UNSPEC_SPU_MASK_FOR_LOAD 50)\n+ (UNSPEC_DFTSV\t\t 51)\n ])\n \n (include \"predicates.md\")\n@@ -192,6 +202,16 @@\n (define_mode_macro VSF [SF V4SF])\n (define_mode_macro VDF [DF V2DF])\n \n+(define_mode_macro VCMP [V16QI\n+\t\t\t V8HI\n+\t\t\t V4SI\n+                         V4SF\n+                         V2DF])\n+\n+(define_mode_macro VCMPU [V16QI\n+\t\t\t  V8HI\n+\t\t\t  V4SI])\n+\n (define_mode_attr bh  [(QI \"b\")  (V16QI \"b\")\n \t\t       (HI \"h\")  (V8HI \"h\")\n \t\t       (SI \"\")   (V4SI \"\")])\n@@ -200,9 +220,14 @@\n                        (DF \"d\")  (V2DF \"d\")])\n (define_mode_attr d6  [(SF \"6\")  (V4SF \"6\")\n                        (DF \"d\")  (V2DF \"d\")])\n-(define_mode_attr f2i [(SF \"SI\") (V4SF \"V4SI\")\n+\n+(define_mode_attr f2i [(SF \"si\") (V4SF \"v4si\")\n+                       (DF \"di\") (V2DF \"v2di\")])\n+(define_mode_attr F2I [(SF \"SI\") (V4SF \"V4SI\")\n                        (DF \"DI\") (V2DF \"V2DI\")])\n \n+(define_mode_attr DF2I [(DF \"SI\") (V2DF \"V2DI\")])\n+\n (define_mode_attr umask  [(HI \"f\")  (V8HI \"f\")\n \t\t          (SI \"g\")  (V4SI \"g\")])\n (define_mode_attr nmask  [(HI \"F\")  (V8HI \"F\")\n@@ -990,31 +1015,31 @@\n \t  (neg:VSF (match_operand:VSF 1 \"spu_reg_operand\" \"\")))\n      (use (match_dup 2))])]\n   \"\"\n-  \"operands[2] = gen_reg_rtx (<f2i>mode);\n-   emit_move_insn (operands[2], spu_const (<f2i>mode, -0x80000000ull));\")\n+  \"operands[2] = gen_reg_rtx (<F2I>mode);\n+   emit_move_insn (operands[2], spu_const (<F2I>mode, -0x80000000ull));\")\n \n (define_expand \"neg<mode>2\"\n   [(parallel\n     [(set (match_operand:VDF 0 \"spu_reg_operand\" \"\")\n \t  (neg:VDF (match_operand:VDF 1 \"spu_reg_operand\" \"\")))\n      (use (match_dup 2))])]\n   \"\"\n-  \"operands[2] = gen_reg_rtx (<f2i>mode);\n-   emit_move_insn (operands[2], spu_const (<f2i>mode, -0x8000000000000000ull));\")\n+  \"operands[2] = gen_reg_rtx (<F2I>mode);\n+   emit_move_insn (operands[2], spu_const (<F2I>mode, -0x8000000000000000ull));\")\n \n (define_insn_and_split \"_neg<mode>2\"\n   [(set (match_operand:VSDF 0 \"spu_reg_operand\" \"=r\")\n \t(neg:VSDF (match_operand:VSDF 1 \"spu_reg_operand\" \"r\")))\n-   (use (match_operand:<f2i> 2 \"spu_reg_operand\" \"r\"))]\n+   (use (match_operand:<F2I> 2 \"spu_reg_operand\" \"r\"))]\n   \"\"\n   \"#\"\n   \"\"\n-  [(set (match_dup:<f2i> 3)\n-\t(xor:<f2i> (match_dup:<f2i> 4)\n-\t\t   (match_dup:<f2i> 2)))]\n+  [(set (match_dup:<F2I> 3)\n+\t(xor:<F2I> (match_dup:<F2I> 4)\n+\t\t   (match_dup:<F2I> 2)))]\n   {\n-    operands[3] = spu_gen_subreg (<f2i>mode, operands[0]);\n-    operands[4] = spu_gen_subreg (<f2i>mode, operands[1]);\n+    operands[3] = spu_gen_subreg (<F2I>mode, operands[0]);\n+    operands[4] = spu_gen_subreg (<F2I>mode, operands[1]);\n   })\n \n \f\n@@ -1026,31 +1051,31 @@\n \t  (abs:VSF (match_operand:VSF 1 \"spu_reg_operand\" \"\")))\n      (use (match_dup 2))])]\n   \"\"\n-  \"operands[2] = gen_reg_rtx (<f2i>mode);\n-   emit_move_insn (operands[2], spu_const (<f2i>mode, 0x7fffffffull));\")\n+  \"operands[2] = gen_reg_rtx (<F2I>mode);\n+   emit_move_insn (operands[2], spu_const (<F2I>mode, 0x7fffffffull));\")\n \n (define_expand \"abs<mode>2\"\n   [(parallel\n     [(set (match_operand:VDF 0 \"spu_reg_operand\" \"\")\n \t  (abs:VDF (match_operand:VDF 1 \"spu_reg_operand\" \"\")))\n      (use (match_dup 2))])]\n   \"\"\n-  \"operands[2] = gen_reg_rtx (<f2i>mode);\n-   emit_move_insn (operands[2], spu_const (<f2i>mode, 0x7fffffffffffffffull));\")\n+  \"operands[2] = gen_reg_rtx (<F2I>mode);\n+   emit_move_insn (operands[2], spu_const (<F2I>mode, 0x7fffffffffffffffull));\")\n \n (define_insn_and_split \"_abs<mode>2\"\n   [(set (match_operand:VSDF 0 \"spu_reg_operand\" \"=r\")\n \t(abs:VSDF (match_operand:VSDF 1 \"spu_reg_operand\" \"r\")))\n-   (use (match_operand:<f2i> 2 \"spu_reg_operand\" \"r\"))]\n+   (use (match_operand:<F2I> 2 \"spu_reg_operand\" \"r\"))]\n   \"\"\n   \"#\"\n   \"\"\n-  [(set (match_dup:<f2i> 3)\n-\t(and:<f2i> (match_dup:<f2i> 4)\n-\t\t   (match_dup:<f2i> 2)))]\n+  [(set (match_dup:<F2I> 3)\n+\t(and:<F2I> (match_dup:<F2I> 4)\n+\t\t   (match_dup:<F2I> 2)))]\n   {\n-    operands[3] = spu_gen_subreg (<f2i>mode, operands[0]);\n-    operands[4] = spu_gen_subreg (<f2i>mode, operands[1]);\n+    operands[3] = spu_gen_subreg (<F2I>mode, operands[0]);\n+    operands[4] = spu_gen_subreg (<F2I>mode, operands[1]);\n   })\n \n \f\n@@ -2493,27 +2518,173 @@\n    (set_attr \"length\" \"12\")])\n \n (define_insn \"ceq_<mode>\"\n-  [(set (match_operand:<f2i> 0 \"spu_reg_operand\" \"=r\")\n-\t(eq:<f2i> (match_operand:VSF 1 \"spu_reg_operand\" \"r\")\n+  [(set (match_operand:<F2I> 0 \"spu_reg_operand\" \"=r\")\n+\t(eq:<F2I> (match_operand:VSF 1 \"spu_reg_operand\" \"r\")\n \t\t  (match_operand:VSF 2 \"spu_reg_operand\" \"r\")))]\n   \"\"\n   \"fceq\\t%0,%1,%2\")\n \n (define_insn \"cmeq_<mode>\"\n-  [(set (match_operand:<f2i> 0 \"spu_reg_operand\" \"=r\")\n-\t(eq:<f2i> (abs:VSF (match_operand:VSF 1 \"spu_reg_operand\" \"r\"))\n+  [(set (match_operand:<F2I> 0 \"spu_reg_operand\" \"=r\")\n+\t(eq:<F2I> (abs:VSF (match_operand:VSF 1 \"spu_reg_operand\" \"r\"))\n \t          (abs:VSF (match_operand:VSF 2 \"spu_reg_operand\" \"r\"))))]\n   \"\"\n   \"fcmeq\\t%0,%1,%2\")\n \n-(define_insn \"ceq_vec\"\n+;; These implementations of ceq_df and cgt_df do not correctly handle\n+;; NAN or INF.  We will also get incorrect results when the result\n+;; of the double subtract is too small.\n+(define_expand \"ceq_df\"\n   [(set (match_operand:SI 0 \"spu_reg_operand\" \"=r\")\n-\t(eq:SI (match_operand 1 \"spu_reg_operand\" \"r\")\n-\t       (match_operand 2 \"spu_reg_operand\" \"r\")))]\n-  \"VECTOR_MODE_P(GET_MODE(operands[1]))\n-   && GET_MODE(operands[1]) == GET_MODE(operands[2])\"\n-  \"ceq\\t%0,%1,%2\\;gb\\t%0,%0\\;ceqi\\t%0,%0,15\"\n-  [(set_attr \"length\" \"12\")])\n+        (eq:SI (match_operand:DF 1 \"spu_reg_operand\" \"r\")\n+               (match_operand:DF 2 \"const_zero_operand\" \"i\")))]\n+  \"\"\n+{\n+  if (flag_unsafe_math_optimizations && spu_arch == PROCESSOR_CELL)\n+    {\n+      rtx s0_ti = gen_reg_rtx(TImode);\n+      rtx s1_v4 = gen_reg_rtx(V4SImode);\n+      rtx s0_v4 = spu_gen_subreg(V4SImode, s0_ti);\n+      rtx to_ti = gen_reg_rtx(TImode);\n+      rtx to_v4 = gen_reg_rtx(V4SImode);\n+      rtx l_v4 = gen_reg_rtx(V4SImode);\n+      emit_insn (gen_spu_convert (l_v4, operands[1]));\n+      emit_insn (gen_movv4si(s1_v4, spu_const(V4SImode, -0x80000000ll)));\n+      emit_insn (gen_ceq_v4si(s0_v4, l_v4, CONST0_RTX(V4SImode)));\n+      emit_insn (gen_ceq_v4si(s1_v4, l_v4, s1_v4));\n+      emit_insn (gen_rotqby_ti(to_ti, s0_ti, GEN_INT(4)));\n+      emit_insn (gen_spu_convert (to_v4, to_ti));\n+      emit_insn (gen_iorv4si3(s1_v4, s0_v4, s1_v4));\n+      emit_insn (gen_andv4si3(to_v4, to_v4, s1_v4));\n+      emit_insn (gen_spu_convert (operands[0], to_v4));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"ceq_<mode>_celledp\"\n+  [(set (match_operand:<DF2I> 0 \"spu_reg_operand\" \"=r\")\n+        (eq:<DF2I> (match_operand:VDF 1 \"spu_reg_operand\" \"r\")\n+                   (match_operand:VDF 2 \"spu_reg_operand\" \"r\")))]\n+  \"spu_arch == PROCESSOR_CELLEDP\"\n+  \"dfceq\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fpd\")])\n+\n+(define_insn \"cmeq_<mode>_celledp\"\n+  [(set (match_operand:<DF2I> 0 \"spu_reg_operand\" \"=r\")\n+        (eq:<DF2I> (abs:VDF (match_operand:VDF 1 \"spu_reg_operand\" \"r\"))\n+                   (abs:VDF (match_operand:VDF 2 \"spu_reg_operand\" \"r\"))))]\n+  \"spu_arch == PROCESSOR_CELLEDP\"\n+  \"dfcmeq\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fpd\")])\n+\n+(define_expand \"ceq_v2df\"\n+  [(set (match_operand:V2DI 0 \"spu_reg_operand\" \"=r\")\n+        (eq:V2DI (match_operand:V2DF 1 \"spu_reg_operand\" \"r\")\n+                 (match_operand:V2DF 2 \"spu_reg_operand\" \"r\")))]\n+  \"\"\n+{\n+  if (spu_arch == PROCESSOR_CELL)\n+    {\n+      rtx ra = spu_gen_subreg (V4SImode, operands[1]);\n+      rtx rb = spu_gen_subreg (V4SImode, operands[2]);\n+      rtx temp = gen_reg_rtx (TImode);\n+      rtx temp_v4si = spu_gen_subreg (V4SImode, temp);\n+      rtx temp2 = gen_reg_rtx (V4SImode);\n+      rtx biteq = gen_reg_rtx (V4SImode);\n+      rtx ahi_inf = gen_reg_rtx (V4SImode);\n+      rtx a_nan = gen_reg_rtx (V4SImode);\n+      rtx a_abs = gen_reg_rtx (V4SImode);\n+      rtx b_abs = gen_reg_rtx (V4SImode);\n+      rtx iszero = gen_reg_rtx (V4SImode);\n+      rtx pat = spu_const_from_ints (V4SImode, 0x7FFFFFFF, 0xFFFFFFFF,\n+                                               0x7FFFFFFF, 0xFFFFFFFF);\n+      rtx sign_mask = gen_reg_rtx (V4SImode);\n+      rtx nan_mask = gen_reg_rtx (V4SImode);\n+      rtx hihi_promote = gen_reg_rtx (TImode);\n+\n+      emit_move_insn (sign_mask, pat);\n+      pat = spu_const_from_ints (V4SImode, 0x7FF00000, 0x0, \n+\t\t\t\t\t     0x7FF00000, 0x0);\n+      emit_move_insn (nan_mask, pat);\n+      pat = spu_const_from_ints (TImode, 0x00010203, 0x10111213, \n+\t\t\t\t\t   0x08090A0B, 0x18191A1B);\n+      emit_move_insn (hihi_promote, pat);\n+\n+      emit_insn (gen_ceq_v4si (biteq, ra, rb));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, biteq), \n+                              GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (biteq, biteq, temp_v4si));\n+      emit_insn (gen_andv4si3 (a_abs, ra, sign_mask));\n+      emit_insn (gen_andv4si3 (b_abs, rb, sign_mask));\n+      emit_insn (gen_clgt_v4si (a_nan, a_abs, nan_mask));\n+      emit_insn (gen_ceq_v4si (ahi_inf, a_abs, nan_mask));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, a_nan), \n+                              GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (temp2, temp_v4si, ahi_inf));\n+      emit_insn (gen_iorv4si3 (a_nan, a_nan, temp2));\n+      emit_insn (gen_iorv4si3 (temp2, a_abs, b_abs));\n+      emit_insn (gen_ceq_v4si (iszero, temp2, CONST0_RTX (V4SImode)));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, iszero), \n+                              GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (iszero, iszero, temp_v4si));\n+      emit_insn (gen_iorv4si3 (temp2, biteq, iszero));\n+      emit_insn (gen_andc_v4si (temp2, temp2, a_nan));\n+      emit_insn (gen_shufb (operands[0], temp2, temp2, hihi_promote));\n+      DONE;\n+  }\n+})\n+\n+(define_expand \"cmeq_v2df\"\n+  [(set (match_operand:V2DI 0 \"spu_reg_operand\" \"=r\")\n+        (eq:V2DI (abs:V2DF (match_operand:V2DF 1 \"spu_reg_operand\" \"r\"))\n+                 (abs:V2DF (match_operand:V2DF 2 \"spu_reg_operand\" \"r\"))))]\n+  \"\"\n+{\n+  if(spu_arch == PROCESSOR_CELL)\n+    {\n+      rtx ra = spu_gen_subreg (V4SImode, operands[1]);\n+      rtx rb = spu_gen_subreg (V4SImode, operands[2]);\n+      rtx temp = gen_reg_rtx (TImode);\n+      rtx temp_v4si = spu_gen_subreg (V4SImode, temp);\n+      rtx temp2 = gen_reg_rtx (V4SImode);\n+      rtx biteq = gen_reg_rtx (V4SImode);\n+      rtx ahi_inf = gen_reg_rtx (V4SImode);\n+      rtx a_nan = gen_reg_rtx (V4SImode);\n+      rtx a_abs = gen_reg_rtx (V4SImode);\n+      rtx b_abs = gen_reg_rtx (V4SImode);\n+\n+      rtx pat = spu_const_from_ints (V4SImode, 0x7FFFFFFF, 0xFFFFFFFF, \n+                                               0x7FFFFFFF, 0xFFFFFFFF);\n+      rtx sign_mask = gen_reg_rtx (V4SImode);\n+      rtx nan_mask = gen_reg_rtx (V4SImode);\n+      rtx hihi_promote = gen_reg_rtx (TImode);\n+\n+      emit_move_insn (sign_mask, pat);\n+\n+      pat = spu_const_from_ints (V4SImode, 0x7FF00000, 0x0, \n+                                           0x7FF00000, 0x0);\n+      emit_move_insn (nan_mask, pat);\n+      pat = spu_const_from_ints (TImode, 0x00010203, 0x10111213, \n+                                         0x08090A0B, 0x18191A1B);\n+      emit_move_insn (hihi_promote, pat);\n+\n+      emit_insn (gen_andv4si3 (a_abs, ra, sign_mask));\n+      emit_insn (gen_andv4si3 (b_abs, rb, sign_mask));\n+      emit_insn (gen_ceq_v4si (biteq, a_abs, b_abs));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, biteq), \n+                                                    GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (biteq, biteq, temp_v4si));\n+      emit_insn (gen_clgt_v4si (a_nan, a_abs, nan_mask));\n+      emit_insn (gen_ceq_v4si (ahi_inf, a_abs, nan_mask));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, a_nan), \n+                                                    GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (temp2, temp_v4si, ahi_inf));\n+      emit_insn (gen_iorv4si3 (a_nan, a_nan, temp2));\n+      emit_insn (gen_andc_v4si (temp2, biteq, a_nan));\n+      emit_insn (gen_shufb (operands[0], temp2, temp2, hihi_promote));\n+      DONE;\n+  }\n+})\n \n \f\n ;; cgt\n@@ -2584,19 +2755,215 @@ selb\\t%0,%5,%0,%3\"\n    (set_attr \"length\" \"36\")])\n \n (define_insn \"cgt_<mode>\"\n-  [(set (match_operand:<f2i> 0 \"spu_reg_operand\" \"=r\")\n-\t(gt:<f2i> (match_operand:VSF 1 \"spu_reg_operand\" \"r\")\n+  [(set (match_operand:<F2I> 0 \"spu_reg_operand\" \"=r\")\n+\t(gt:<F2I> (match_operand:VSF 1 \"spu_reg_operand\" \"r\")\n \t\t  (match_operand:VSF 2 \"spu_reg_operand\" \"r\")))]\n   \"\"\n   \"fcgt\\t%0,%1,%2\")\n \n (define_insn \"cmgt_<mode>\"\n-  [(set (match_operand:<f2i> 0 \"spu_reg_operand\" \"=r\")\n-\t(gt:<f2i> (abs:VSF (match_operand:VSF 1 \"spu_reg_operand\" \"r\"))\n+  [(set (match_operand:<F2I> 0 \"spu_reg_operand\" \"=r\")\n+\t(gt:<F2I> (abs:VSF (match_operand:VSF 1 \"spu_reg_operand\" \"r\"))\n \t\t  (abs:VSF (match_operand:VSF 2 \"spu_reg_operand\" \"r\"))))]\n   \"\"\n   \"fcmgt\\t%0,%1,%2\")\n \n+(define_expand \"cgt_df\"\n+  [(set (match_operand:SI 0 \"spu_reg_operand\" \"=r\")\n+        (gt:SI (match_operand:DF 1 \"spu_reg_operand\" \"r\")\n+               (match_operand:DF 2 \"const_zero_operand\" \"i\")))]\n+  \"\"\n+{\n+  if (flag_unsafe_math_optimizations && spu_arch == PROCESSOR_CELL)\n+    {\n+      rtx s0_ti = gen_reg_rtx(TImode);\n+      rtx s1_v4 = gen_reg_rtx(V4SImode);\n+      rtx s0_v4 = spu_gen_subreg(V4SImode, s0_ti);\n+      rtx to_ti = gen_reg_rtx(TImode);\n+      rtx to_v4 = gen_reg_rtx(V4SImode);\n+      rtx l_v4 = gen_reg_rtx(V4SImode);\n+      emit_insn (gen_spu_convert(l_v4, operands[1]));\n+      emit_insn (gen_ceq_v4si(s0_v4, l_v4, const0_rtx));\n+      emit_insn (gen_cgt_v4si(s1_v4, l_v4, const0_rtx));\n+      emit_insn (gen_rotqby_ti(to_ti, s0_ti, GEN_INT(4)));\n+      emit_insn (gen_spu_convert(to_v4, to_ti));\n+      emit_insn (gen_andc_v4si(to_v4, s0_v4, to_v4));\n+      emit_insn (gen_iorv4si3(to_v4, to_v4, s1_v4));\n+      emit_insn (gen_spu_convert(operands[0], to_v4));\n+      DONE;\n+    } \n+})\n+\n+(define_insn \"cgt_<mode>_celledp\"\n+  [(set (match_operand:<DF2I> 0 \"spu_reg_operand\" \"=r\")\n+        (gt:<DF2I> (match_operand:VDF 1 \"spu_reg_operand\" \"r\")\n+                   (match_operand:VDF 2 \"spu_reg_operand\" \"r\")))]\n+  \"spu_arch == PROCESSOR_CELLEDP\"\n+  \"dfcgt\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fpd\")])\n+\n+(define_insn \"cmgt_<mode>_celledp\"\n+  [(set (match_operand:<DF2I> 0 \"spu_reg_operand\" \"=r\")\n+        (gt:<DF2I> (abs:VDF (match_operand:VDF 1 \"spu_reg_operand\" \"r\"))\n+                   (abs:VDF (match_operand:VDF 2 \"spu_reg_operand\" \"r\"))))]\n+  \"spu_arch == PROCESSOR_CELLEDP\"\n+  \"dfcmgt\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fpd\")])\n+\n+(define_expand \"cgt_v2df\"\n+  [(set (match_operand:V2DI 0 \"spu_reg_operand\" \"=r\")\n+        (gt:V2DI (match_operand:V2DF 1 \"spu_reg_operand\" \"r\")\n+                 (match_operand:V2DF 2 \"spu_reg_operand\" \"r\")))]\n+  \"\"\n+{\n+  if(spu_arch == PROCESSOR_CELL)\n+    {\n+      rtx ra = spu_gen_subreg (V4SImode, operands[1]);\n+      rtx rb = spu_gen_subreg (V4SImode, operands[2]);\n+      rtx zero = gen_reg_rtx (V4SImode);\n+      rtx temp = gen_reg_rtx (TImode);\n+      rtx temp_v4si = spu_gen_subreg (V4SImode, temp);\n+      rtx temp2 = gen_reg_rtx (V4SImode);\n+      rtx hi_inf = gen_reg_rtx (V4SImode);\n+      rtx a_nan = gen_reg_rtx (V4SImode);\n+      rtx b_nan = gen_reg_rtx (V4SImode);\n+      rtx a_abs = gen_reg_rtx (V4SImode);\n+      rtx b_abs = gen_reg_rtx (V4SImode);\n+      rtx asel = gen_reg_rtx (V4SImode);\n+      rtx bsel = gen_reg_rtx (V4SImode);\n+      rtx abor = gen_reg_rtx (V4SImode);\n+      rtx bbor = gen_reg_rtx (V4SImode);\n+      rtx gt_hi = gen_reg_rtx (V4SImode);\n+      rtx gt_lo = gen_reg_rtx (V4SImode);\n+      rtx sign_mask = gen_reg_rtx (V4SImode);\n+      rtx nan_mask = gen_reg_rtx (V4SImode);\n+      rtx hi_promote = gen_reg_rtx (TImode);\n+      rtx borrow_shuffle = gen_reg_rtx (TImode);\n+      rtx pat = spu_const_from_ints (V4SImode, 0x7FFFFFFF, 0xFFFFFFFF, \n+                                               0x7FFFFFFF, 0xFFFFFFFF);\n+      emit_move_insn (sign_mask, pat);\n+      pat = spu_const_from_ints (V4SImode, 0x7FF00000, 0x0, \n+                                           0x7FF00000, 0x0);\n+      emit_move_insn (nan_mask, pat);\n+      pat = spu_const_from_ints (TImode, 0x00010203, 0x00010203, \n+                                         0x08090A0B, 0x08090A0B);\n+      emit_move_insn (hi_promote, pat);\n+      pat = spu_const_from_ints (TImode, 0x04050607, 0xC0C0C0C0, \n+                                         0x0C0D0E0F, 0xC0C0C0C0);\n+      emit_move_insn (borrow_shuffle, pat);\n+\n+      emit_insn (gen_andv4si3 (a_nan, ra, sign_mask));\n+      emit_insn (gen_ceq_v4si (hi_inf, a_nan, nan_mask));\n+      emit_insn (gen_clgt_v4si (a_nan, a_nan, nan_mask));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, a_nan), \n+                                                    GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (temp2, temp_v4si, hi_inf));\n+      emit_insn (gen_iorv4si3 (a_nan, a_nan, temp2));\n+      emit_insn (gen_shufb (a_nan, a_nan, a_nan, hi_promote));\n+      emit_insn (gen_andv4si3 (b_nan, rb, sign_mask));\n+      emit_insn (gen_ceq_v4si (hi_inf, b_nan, nan_mask));\n+      emit_insn (gen_clgt_v4si (b_nan, b_nan, nan_mask));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, b_nan), \n+                                                    GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (temp2, temp_v4si, hi_inf));\n+      emit_insn (gen_iorv4si3 (b_nan, b_nan, temp2));\n+      emit_insn (gen_shufb (b_nan, b_nan, b_nan, hi_promote));\n+      emit_insn (gen_iorv4si3 (a_nan, a_nan, b_nan));\n+      emit_move_insn (zero, CONST0_RTX (V4SImode));\n+      emit_insn (gen_ashrv4si3 (asel, ra, spu_const (V4SImode, 31)));\n+      emit_insn (gen_shufb (asel, asel, asel, hi_promote));\n+      emit_insn (gen_andv4si3 (a_abs, ra, sign_mask));\n+      emit_insn (gen_bg_v4si (abor, zero, a_abs));\n+      emit_insn (gen_shufb (abor, abor, abor, borrow_shuffle));\n+      emit_insn (gen_sfx_v4si (abor, zero, a_abs, abor));\n+      emit_insn (gen_selb (abor, a_abs, abor, asel));\n+      emit_insn (gen_ashrv4si3 (bsel, rb, spu_const (V4SImode, 31)));\n+      emit_insn (gen_shufb (bsel, bsel, bsel, hi_promote));\n+      emit_insn (gen_andv4si3 (b_abs, rb, sign_mask));\n+      emit_insn (gen_bg_v4si (bbor, zero, b_abs));\n+      emit_insn (gen_shufb (bbor, bbor, bbor, borrow_shuffle));\n+      emit_insn (gen_sfx_v4si (bbor, zero, b_abs, bbor));\n+      emit_insn (gen_selb (bbor, b_abs, bbor, bsel));\n+      emit_insn (gen_cgt_v4si (gt_hi, abor, bbor));\n+      emit_insn (gen_clgt_v4si (gt_lo, abor, bbor));\n+      emit_insn (gen_ceq_v4si (temp2, abor, bbor));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, gt_lo), \n+                                                    GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (temp2, temp2, temp_v4si));\n+      emit_insn (gen_iorv4si3 (temp2, gt_hi, temp2));\n+\n+      emit_insn (gen_shufb (temp2, temp2, temp2, hi_promote));\n+      emit_insn (gen_andc_v4si (temp2, temp2, a_nan));\n+      emit_move_insn (operands[0], spu_gen_subreg (V2DImode, temp2));\n+      DONE;\n+    } \n+})\n+\n+(define_expand \"cmgt_v2df\"\n+  [(set (match_operand:V2DI 0 \"spu_reg_operand\" \"=r\")\n+        (gt:V2DI (abs:V2DF (match_operand:V2DF 1 \"spu_reg_operand\" \"r\"))\n+                 (abs:V2DF (match_operand:V2DF 2 \"spu_reg_operand\" \"r\"))))]\n+  \"\"\n+{\n+  if(spu_arch == PROCESSOR_CELL)\n+    {\n+      rtx ra = spu_gen_subreg (V4SImode, operands[1]);\n+      rtx rb = spu_gen_subreg (V4SImode, operands[2]);\n+      rtx temp = gen_reg_rtx (TImode);\n+      rtx temp_v4si = spu_gen_subreg (V4SImode, temp);\n+      rtx temp2 = gen_reg_rtx (V4SImode);\n+      rtx hi_inf = gen_reg_rtx (V4SImode);\n+      rtx a_nan = gen_reg_rtx (V4SImode);\n+      rtx b_nan = gen_reg_rtx (V4SImode);\n+      rtx a_abs = gen_reg_rtx (V4SImode);\n+      rtx b_abs = gen_reg_rtx (V4SImode);\n+      rtx gt_hi = gen_reg_rtx (V4SImode);\n+      rtx gt_lo = gen_reg_rtx (V4SImode);\n+      rtx sign_mask = gen_reg_rtx (V4SImode);\n+      rtx nan_mask = gen_reg_rtx (V4SImode);\n+      rtx hi_promote = gen_reg_rtx (TImode);\n+      rtx pat = spu_const_from_ints (V4SImode, 0x7FFFFFFF, 0xFFFFFFFF, \n+                                               0x7FFFFFFF, 0xFFFFFFFF);\n+      emit_move_insn (sign_mask, pat);\n+      pat = spu_const_from_ints (V4SImode, 0x7FF00000, 0x0, \n+                                           0x7FF00000, 0x0);\n+      emit_move_insn (nan_mask, pat);\n+      pat = spu_const_from_ints (TImode, 0x00010203, 0x00010203, \n+                                         0x08090A0B, 0x08090A0B);\n+      emit_move_insn (hi_promote, pat);\n+\n+      emit_insn (gen_andv4si3 (a_abs, ra, sign_mask));\n+      emit_insn (gen_ceq_v4si (hi_inf, a_abs, nan_mask));\n+      emit_insn (gen_clgt_v4si (a_nan, a_abs, nan_mask));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, a_nan), \n+                                                    GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (temp2, temp_v4si, hi_inf));\n+      emit_insn (gen_iorv4si3 (a_nan, a_nan, temp2));\n+      emit_insn (gen_shufb (a_nan, a_nan, a_nan, hi_promote));\n+      emit_insn (gen_andv4si3 (b_abs, rb, sign_mask));\n+      emit_insn (gen_ceq_v4si (hi_inf, b_abs, nan_mask));\n+      emit_insn (gen_clgt_v4si (b_nan, b_abs, nan_mask));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, b_nan), \n+                                                    GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (temp2, temp_v4si, hi_inf));\n+      emit_insn (gen_iorv4si3 (b_nan, b_nan, temp2));\n+      emit_insn (gen_shufb (b_nan, b_nan, b_nan, hi_promote));\n+      emit_insn (gen_iorv4si3 (a_nan, a_nan, b_nan));\n+\n+      emit_insn (gen_clgt_v4si (gt_hi, a_abs, b_abs));\n+      emit_insn (gen_clgt_v4si (gt_lo, a_abs, b_abs));\n+      emit_insn (gen_ceq_v4si (temp2, a_abs, b_abs));\n+      emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, gt_lo), \n+                                                    GEN_INT (4 * 8)));\n+      emit_insn (gen_andv4si3 (temp2, temp2, temp_v4si));\n+      emit_insn (gen_iorv4si3 (temp2, gt_hi, temp2));\n+      emit_insn (gen_shufb (temp2, temp2, temp2, hi_promote));\n+      emit_insn (gen_andc_v4si (temp2, temp2, a_nan));\n+      emit_move_insn (operands[0], spu_gen_subreg (V2DImode, temp2));\n+      DONE;\n+    }\n+})\n+\n \f\n ;; clgt\n \n@@ -2656,6 +3023,150 @@ selb\\t%0,%4,%0,%3\"\n    (set_attr \"length\" \"32\")])\n \n \f\n+;; dftsv\n+(define_insn \"dftsv_celledp\"\n+  [(set (match_operand:V2DI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec [(match_operand:V2DF 1 \"spu_reg_operand\"  \"r\")\n+                 (match_operand:SI   2 \"const_int_operand\" \"i\")] UNSPEC_DFTSV))]\n+  \"spu_arch == PROCESSOR_CELLEDP\"\n+  \"dftsv\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fpd\")])\n+\n+(define_expand \"dftsv\"\n+  [(set (match_operand:V2DI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec [(match_operand:V2DF 1 \"spu_reg_operand\" \"r\")\n+                 (match_operand:SI   2 \"const_int_operand\" \"i\")] UNSPEC_DFTSV))]\n+  \"\"\n+{\n+  if(spu_arch == PROCESSOR_CELL)\n+    {\n+      rtx result = gen_reg_rtx (V4SImode);\n+      emit_move_insn (result, CONST0_RTX (V4SImode));\n+\n+      if (INTVAL (operands[2]))\n+        {\n+          rtx ra = spu_gen_subreg (V4SImode, operands[1]);\n+          rtx abs = gen_reg_rtx (V4SImode);\n+          rtx sign = gen_reg_rtx (V4SImode);\n+          rtx temp = gen_reg_rtx (TImode);\n+          rtx temp_v4si = spu_gen_subreg (V4SImode, temp);\n+          rtx temp2 = gen_reg_rtx (V4SImode);\n+          rtx pat = spu_const_from_ints (V4SImode, 0x7FFFFFFF, 0xFFFFFFFF, \n+                                                   0x7FFFFFFF, 0xFFFFFFFF);\n+          rtx sign_mask = gen_reg_rtx (V4SImode);\n+          rtx hi_promote = gen_reg_rtx (TImode);\n+          emit_move_insn (sign_mask, pat);\n+          pat = spu_const_from_ints (TImode, 0x00010203, 0x00010203, \n+                                             0x08090A0B, 0x08090A0B);\n+          emit_move_insn (hi_promote, pat);\n+\n+          emit_insn (gen_ashrv4si3 (sign, ra, spu_const (V4SImode, 31)));\n+          emit_insn (gen_shufb (sign, sign, sign, hi_promote));\n+          emit_insn (gen_andv4si3 (abs, ra, sign_mask));\n+\n+          /* NaN  or +inf or -inf */\n+          if (INTVAL (operands[2]) & 0x70)\n+            {\n+              rtx nan_mask = gen_reg_rtx (V4SImode);\n+              rtx isinf = gen_reg_rtx (V4SImode);\n+              pat = spu_const_from_ints (V4SImode, 0x7FF00000, 0x0, \n+\t\t   \t\t\t           0x7FF00000, 0x0);\n+              emit_move_insn (nan_mask, pat);\n+              emit_insn (gen_ceq_v4si (isinf, abs, nan_mask));\n+\n+              /* NaN  */\n+              if (INTVAL (operands[2]) & 0x40)\n+                {\n+                  rtx isnan = gen_reg_rtx (V4SImode);\n+                  emit_insn (gen_clgt_v4si (isnan, abs, nan_mask));\n+                  emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, isnan), \n+                                                             GEN_INT (4 * 8)));\n+                  emit_insn (gen_andv4si3 (temp2, temp_v4si, isinf));\n+                  emit_insn (gen_iorv4si3 (isnan, isnan, temp2));\n+                  emit_insn (gen_shufb (isnan, isnan, isnan, hi_promote));\n+                  emit_insn (gen_iorv4si3 (result, result, isnan));\n+                }\n+              /* +inf or -inf  */\n+              if (INTVAL (operands[2]) & 0x30)\n+                {\n+                  emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, isinf), \n+                                                             GEN_INT (4 * 8)));\n+                  emit_insn (gen_andv4si3 (isinf, isinf, temp_v4si));\n+                  emit_insn (gen_shufb (isinf, isinf, isinf, hi_promote));\n+\n+                  /* +inf  */\n+                  if (INTVAL (operands[2]) & 0x20)\n+                    {\n+                      emit_insn (gen_andc_v4si (temp2, isinf, sign));\n+                      emit_insn (gen_iorv4si3 (result, result, temp2));\n+                    }\n+                  /* -inf  */\n+                  if (INTVAL (operands[2]) & 0x10)\n+                    {\n+                      emit_insn (gen_andv4si3 (temp2, isinf, sign));\n+                      emit_insn (gen_iorv4si3 (result, result, temp2));\n+                    }\n+                }\n+            }\n+\n+          /* 0 or denorm  */\n+          if (INTVAL (operands[2]) & 0xF)\n+            {\n+              rtx iszero = gen_reg_rtx (V4SImode);\n+              emit_insn (gen_ceq_v4si (iszero, abs, CONST0_RTX (V4SImode)));\n+              emit_insn (gen_rotlti3 (temp, spu_gen_subreg (TImode, iszero), \n+                                                          GEN_INT (4 * 8)));\n+              emit_insn (gen_andv4si3 (iszero, iszero, temp_v4si));\n+\n+              /* denorm  */\n+              if (INTVAL (operands[2]) & 0x3)\n+                {\n+                  rtx isdenorm = gen_reg_rtx (V4SImode);\n+                  rtx denorm_mask = gen_reg_rtx (V4SImode);\n+                  emit_move_insn (denorm_mask, spu_const (V4SImode, 0xFFFFF));\n+                  emit_insn (gen_clgt_v4si (isdenorm, abs, denorm_mask));\n+                  emit_insn (gen_nor_v4si (isdenorm, isdenorm, iszero));\n+                  emit_insn (gen_shufb (isdenorm, isdenorm, \n+                                        isdenorm, hi_promote));\n+                  /* +denorm  */\n+                  if (INTVAL (operands[2]) & 0x2)\n+                    {\n+                      emit_insn (gen_andc_v4si (temp2, isdenorm, sign));\n+                      emit_insn (gen_iorv4si3 (result, result, temp2));\n+                    }\n+                  /* -denorm  */\n+                  if (INTVAL (operands[2]) & 0x1)\n+                    {\n+                      emit_insn (gen_andv4si3 (temp2, isdenorm, sign));\n+                      emit_insn (gen_iorv4si3 (result, result, temp2));\n+                    }\n+                }\n+\n+              /* 0  */\n+              if (INTVAL (operands[2]) & 0xC)\n+                {\n+                  emit_insn (gen_shufb (iszero, iszero, iszero, hi_promote));\n+                  /* +0  */\n+                  if (INTVAL (operands[2]) & 0x8)\n+                    {\n+                      emit_insn (gen_andc_v4si (temp2, iszero, sign));\n+                      emit_insn (gen_iorv4si3 (result, result, temp2));\n+                    }\n+                  /* -0  */\n+                  if (INTVAL (operands[2]) & 0x4)\n+                    {\n+                      emit_insn (gen_andv4si3 (temp2, iszero, sign));\n+                      emit_insn (gen_iorv4si3 (result, result, temp2));\n+                    }\n+                }\n+             }\n+          }\n+      emit_move_insn (operands[0], spu_gen_subreg (V2DImode, result));\n+      DONE;\n+    }\n+})\n+\n+\n ;; branches\n \n (define_insn \"\"\n@@ -2747,6 +3258,53 @@ selb\\t%0,%4,%0,%3\"\n     DONE;\n   })\n \n+(define_expand \"cmpdf\"\n+  [(set (cc0)\n+        (compare (match_operand:DF 0 \"register_operand\" \"\")\n+                 (match_operand:DF 1 \"register_operand\" \"\")))]\n+  \"(flag_unsafe_math_optimizations && spu_arch == PROCESSOR_CELL) \n+    || spu_arch == PROCESSOR_CELLEDP \"\n+  \"{\n+  spu_compare_op0 = operands[0];\n+  spu_compare_op1 = operands[1];\n+  DONE;\n+}\")\n+\n+;; vector conditional compare patterns\n+(define_expand \"vcond<mode>\"\n+  [(set (match_operand:VCMP 0 \"spu_reg_operand\" \"=r\")\n+        (if_then_else:VCMP\n+          (match_operator 3 \"comparison_operator\"\n+            [(match_operand:VCMP 4 \"spu_reg_operand\" \"r\")\n+             (match_operand:VCMP 5 \"spu_reg_operand\" \"r\")])\n+          (match_operand:VCMP 1 \"spu_reg_operand\" \"r\")\n+          (match_operand:VCMP 2 \"spu_reg_operand\" \"r\")))]\n+  \"\"\n+  {\n+    if (spu_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n+                                   operands[3], operands[4], operands[5]))\n+    DONE;\n+    else\n+    FAIL;\n+  })\n+\n+(define_expand \"vcondu<mode>\"\n+  [(set (match_operand:VCMPU 0 \"spu_reg_operand\" \"=r\")\n+        (if_then_else:VCMPU\n+          (match_operator 3 \"comparison_operator\"\n+            [(match_operand:VCMPU 4 \"spu_reg_operand\" \"r\")\n+             (match_operand:VCMPU 5 \"spu_reg_operand\" \"r\")])\n+          (match_operand:VCMPU 1 \"spu_reg_operand\" \"r\")\n+          (match_operand:VCMPU 2 \"spu_reg_operand\" \"r\")))]\n+  \"\"\n+  {\n+    if (spu_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n+                                   operands[3], operands[4], operands[5]))\n+    DONE;\n+    else\n+    FAIL;\n+  })\n+\t\n \f\n ;; branch on condition\n \n@@ -3376,7 +3934,7 @@ selb\\t%0,%4,%0,%3\"\n \n (define_expand \"sminv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=r\")\n-        (smax:V4SF (match_operand:V4SF 1 \"register_operand\" \"r\")\n+        (smin:V4SF (match_operand:V4SF 1 \"register_operand\" \"r\")\n                  (match_operand:V4SF 2 \"register_operand\" \"r\")))]\n   \"\"\n   \"\n@@ -3388,6 +3946,34 @@ selb\\t%0,%4,%0,%3\"\n   DONE;\n }\") \n \n+(define_expand \"smaxv2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=r\")\n+        (smax:V2DF (match_operand:V2DF 1 \"register_operand\" \"r\")\n+                 (match_operand:V2DF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"\n+{\n+  rtx mask = gen_reg_rtx (V2DImode);\n+  emit_insn (gen_cgt_v2df (mask, operands[1], operands[2]));\n+  emit_insn (gen_selb (operands[0], operands[2], operands[1], \n+\t\t       spu_gen_subreg (V4SImode, mask)));\n+  DONE;\n+}\")\n+\n+(define_expand \"sminv2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=r\")\n+        (smin:V2DF (match_operand:V2DF 1 \"register_operand\" \"r\")\n+                 (match_operand:V2DF 2 \"register_operand\" \"r\")))]\n+  \"\"\n+  \"\n+{\n+  rtx mask = gen_reg_rtx (V2DImode);\n+  emit_insn (gen_cgt_v2df (mask, operands[1], operands[2]));\n+  emit_insn (gen_selb (operands[0], operands[1], operands[2], \n+\t\t       spu_gen_subreg (V4SImode, mask)));\n+  DONE;\n+}\")\n+\n (define_expand \"vec_widen_umult_hi_v8hi\"\n   [(set (match_operand:V4SI 0 \"register_operand\"   \"=r\")\n         (mult:V4SI"}, {"sha": "e8c11d1edb7fbb0496fe55f0f3b0ab7088a613aa", "filename": "gcc/config/spu/spu.opt", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.opt?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -55,3 +55,11 @@ Generate code for 32 bit addressing\n mfixed-range=\n Target RejectNegative Joined Var(spu_fixed_range_string)\n Specify range of registers to make fixed\n+\n+march=\n+Target RejectNegative Joined Var(spu_arch_string)\n+Generate code for given CPU\n+\n+mtune=\n+Target RejectNegative Joined Var(spu_tune_string)\n+Schedule code for given CPU"}, {"sha": "fb42c8709837f537a72326e0c6190829dd641834", "filename": "gcc/config/spu/spu_internals.h", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu_internals.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu_internals.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu_internals.h?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -233,6 +233,15 @@\n #define si_rchcnt(imm)       __builtin_si_rchcnt(imm)\n #define si_wrch(imm,ra)      __builtin_si_wrch(imm,ra)\n \n+/* celledp only instructions  */\n+#ifdef __SPU_EDP__\n+#define si_dfceq(ra,rb)      __builtin_si_dfceq(ra,rb)\n+#define si_dfcmeq(ra,rb)     __builtin_si_dfcmeq(ra,rb)\n+#define si_dfcgt(ra,rb)      __builtin_si_dfcgt(ra,rb)\n+#define si_dfcmgt(ra,rb)     __builtin_si_dfcmgt(ra,rb)\n+#define si_dftsv(ra,imm)     __builtin_si_dftsv(ra,imm)\n+#endif /* __SPU_EDP__  */\n+\n #define si_from_char(scalar)    __builtin_si_from_char(scalar)\n #define si_from_uchar(scalar)   __builtin_si_from_uchar(scalar)\n #define si_from_short(scalar)   __builtin_si_from_short(scalar)\n@@ -295,6 +304,7 @@\n #define spu_cmpabsgt(ra,rb)       __builtin_spu_cmpabsgt(ra,rb) \n #define spu_cmpeq(ra,rb)          __builtin_spu_cmpeq(ra,rb) \n #define spu_cmpgt(ra,rb)          __builtin_spu_cmpgt(ra,rb) \n+#define spu_testsv(ra,imm)        __builtin_spu_testsv(ra,imm) \n #define spu_hcmpeq(ra,rb)         __builtin_spu_hcmpeq(ra,rb) \n #define spu_hcmpgt(ra,rb)         __builtin_spu_hcmpgt(ra,rb) \n #define spu_cntb(ra)              __builtin_spu_cntb(ra) "}, {"sha": "faaf8a6801fa5ad78982f77d3e04b0e181cf32df", "filename": "gcc/config/spu/spu_intrinsics.h", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu_intrinsics.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Fconfig%2Fspu%2Fspu_intrinsics.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu_intrinsics.h?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -70,6 +70,16 @@\n #define MFC_WrListStallAck\t26 \n #define MFC_RdAtomicStat\t27 \n \n+/* Bit flag mnemonics for test special value.\n+ */\n+#define SPU_SV_NEG_DENORM       0x01    /* negative denormalized number  */\n+#define SPU_SV_POS_DENORM       0x02    /* positive denormalized number  */\n+#define SPU_SV_NEG_ZERO         0x04    /* negative zero                 */\n+#define SPU_SV_POS_ZERO         0x08    /* positive zero                 */\n+#define SPU_SV_NEG_INFINITY     0x10    /* negative infinity             */\n+#define SPU_SV_POS_INFINITY     0x20    /* positive infinity             */\n+#define SPU_SV_NAN              0x40    /* not a number                  */\n+\n #include <spu_internals.h>\n \n #endif /* _SPU_INTRINSICS_H */"}, {"sha": "8a309c6f816275766f580efaa67e6bc2d3d11d04", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -1,3 +1,16 @@\n+2007-07-13  Sa Liu  <saliu@de.ibm.com>\n+\n+\t* gcc.dg/vect/fast-math-vect-reduc-7.c: Switch on test\n+\tfor V2DFmode vector conditional expression.\n+\t* gcc.target/spu/dfcmeq.c: New.  Test combination of abs\n+\tand dfceq patterns.\n+\t* gcc.target/spu/dfcmgt.c: New.  Test combination of abs\n+\tand dfcgt patterns.\n+\t* gcc.target/spu/intrinsics-2.c: New.  Test intrinsics for\n+\tV2DFmode comparison and test special values.\n+\t* lib/target-supports.exp: Switch on test for V2DFmode \n+\tvector conditional expression.\n+\n 2007-07-13  Richard Guenther  <rguenther@suse.de>\n \n \tPR tree-optimization/32721"}, {"sha": "b25e1145b1e8e356b29fa66ea5a687a21225931f", "filename": "gcc/testsuite/gcc.dg/vect/fast-math-vect-reduc-7.c", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Ffast-math-vect-reduc-7.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Ffast-math-vect-reduc-7.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Ffast-math-vect-reduc-7.c?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -50,6 +50,5 @@ int main (void)\n   return 0;\n }\n \n-/* { dg-final { scan-tree-dump-times \"vectorized 3 loops\" 1 \"vect\" { xfail vect_no_compare_double } } } */\n-/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\" { target vect_no_compare_double } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorized 3 loops\" 1 \"vect\" } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "cdcb456414b8f76756071f6b83d39b752fc40835", "filename": "gcc/testsuite/lib/target-supports.exp", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/39aeae8573ed2085fbfad05f3e8ba1456fcb6d44/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp?ref=39aeae8573ed2085fbfad05f3e8ba1456fcb6d44", "patch": "@@ -1659,7 +1659,7 @@ proc check_effective_target_vect_double { } {\n     return $et_vect_double_saved\n }\n \n-# Return 0 if the target supports hardware comparison of vectors of double, 0 otherwise.\n+# Return 1 if the target supports hardware comparison of vectors of double, 0 otherwise.\n #\n # This won't change for different subtargets so cache the result.\n \n@@ -1670,9 +1670,6 @@ proc check_effective_target_vect_no_compare_double { } {\n         verbose \"check_effective_target_vect_no_compare_double: using cached result\" 2\n     } else {\n         set et_vect_no_compare_double_saved 0\n-        if { [istarget spu-*-*] } {\n-           set et_vect_no_compare_double_saved 1\n-        }\n     }\n \n     verbose \"check_effective_target_vect_no_compare_double: returning $et_vect_no_compare_double_saved\" 2\n@@ -2025,6 +2022,7 @@ proc check_effective_target_vect_condition { } {\n \tif { [istarget powerpc*-*-*]\n \t     || [istarget ia64-*-*]\n \t     || [istarget i?86-*-*]\n+\t     || [istarget spu-*-*]\n \t     || [istarget x86_64-*-*] } {\n \t   set et_vect_cond_saved 1\n \t}"}]}