{"sha": "f1657f05ef0fbc5183051de277141159f15a9472", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZjE2NTdmMDVlZjBmYmM1MTgzMDUxZGUyNzcxNDExNTlmMTVhOTQ3Mg==", "commit": {"author": {"name": "Trevor Saunders", "email": "tbsaunde+gcc@tbsaunde.org", "date": "2015-07-09T02:49:51Z"}, "committer": {"name": "Trevor Saunders", "email": "tbsaunde@gcc.gnu.org", "date": "2015-07-09T02:49:51Z"}, "message": "reduce conditional compilation for LOAD_EXTEND_OP\n\nProvide a default in files where that is possible, so that everything\nelse there can be unconditionally compiled.  However rtlanal.c and\nreload.c do tricky things that break providing a global default, so we\ncan't do that yet.\n\ngcc/ChangeLog:\n\n2015-07-08  Trevor Saunders  <tbsaunde+gcc@tbsaunde.org>\n\n\t* combine.c (try_combine): Don't check if LOAD_EXTEND_OP is\n\tdefined.\n\t(simplify_set): Likewise.\n\t* cse.c (cse_insn): Likewise.\n\t* fold-const.c (fold_single_bit_test): Likewise.\n\t(fold_unary_loc): Likewise.\n\t* postreload.c (reload_cse_simplify_set): Likewise.\n\t(reload_cse_simplify_operands): Likewise.\n\nFrom-SVN: r225591", "tree": {"sha": "e4dc3a562a1e0900ee3ab1384aba87e00500bcef", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e4dc3a562a1e0900ee3ab1384aba87e00500bcef"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/f1657f05ef0fbc5183051de277141159f15a9472", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f1657f05ef0fbc5183051de277141159f15a9472", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f1657f05ef0fbc5183051de277141159f15a9472", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f1657f05ef0fbc5183051de277141159f15a9472/comments", "author": null, "committer": null, "parents": [{"sha": "1acfc9ca30d79133bca85399440c0d7fa123fb51", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1acfc9ca30d79133bca85399440c0d7fa123fb51", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1acfc9ca30d79133bca85399440c0d7fa123fb51"}], "stats": {"total": 53, "additions": 29, "deletions": 24}, "files": [{"sha": "b8e63660bb09e32cf921de448f7bd27474534f0d", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=f1657f05ef0fbc5183051de277141159f15a9472", "patch": "@@ -1,3 +1,14 @@\n+2015-07-08  Trevor Saunders  <tbsaunde+gcc@tbsaunde.org>\n+\n+\t* combine.c (try_combine): Don't check if LOAD_EXTEND_OP is\n+\tdefined.\n+\t(simplify_set): Likewise.\n+\t* cse.c (cse_insn): Likewise.\n+\t* fold-const.c (fold_single_bit_test): Likewise.\n+\t(fold_unary_loc): Likewise.\n+\t* postreload.c (reload_cse_simplify_set): Likewise.\n+\t(reload_cse_simplify_operands): Likewise.\n+\n 2015-07-08  Jiong Wang  <jiong.wang@arm.com>\n \n \t* config/aarch64/aarch64.c (aarch64_unspec_may_trap_p): New function."}, {"sha": "11cee8559c10e15e740f440fe3a1c2239f984a02", "filename": "gcc/combine.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=f1657f05ef0fbc5183051de277141159f15a9472", "patch": "@@ -113,6 +113,10 @@ along with GCC; see the file COPYING3.  If not see\n #include \"obstack.h\"\n #include \"rtl-iter.h\"\n \n+#ifndef LOAD_EXTEND_OP\n+#define LOAD_EXTEND_OP(M) UNKNOWN\n+#endif\n+\n /* Number of attempts to combine instructions in this function.  */\n \n static int combine_attempts;\n@@ -3744,15 +3748,13 @@ try_combine (rtx_insn *i3, rtx_insn *i2, rtx_insn *i1, rtx_insn *i0,\n \t     be written as a ZERO_EXTEND.  */\n \t  if (split_code == SUBREG && MEM_P (SUBREG_REG (*split)))\n \t    {\n-#ifdef LOAD_EXTEND_OP\n \t      /* Or as a SIGN_EXTEND if LOAD_EXTEND_OP says that that's\n \t\t what it really is.  */\n \t      if (LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (*split)))\n \t\t  == SIGN_EXTEND)\n \t\tSUBST (*split, gen_rtx_SIGN_EXTEND (split_mode,\n \t\t\t\t\t\t    SUBREG_REG (*split)));\n \t      else\n-#endif\n \t\tSUBST (*split, gen_rtx_ZERO_EXTEND (split_mode,\n \t\t\t\t\t\t    SUBREG_REG (*split)));\n \t    }\n@@ -6772,7 +6774,6 @@ simplify_set (rtx x)\n \t}\n     }\n \n-#ifdef LOAD_EXTEND_OP\n   /* If we have (set FOO (subreg:M (mem:N BAR) 0)) with M wider than N, this\n      would require a paradoxical subreg.  Replace the subreg with a\n      zero_extend to avoid the reload that would otherwise be required.  */\n@@ -6790,7 +6791,6 @@ simplify_set (rtx x)\n \n       src = SET_SRC (x);\n     }\n-#endif\n \n   /* If we don't have a conditional move, SET_SRC is an IF_THEN_ELSE, and we\n      are comparing an item known to be 0 or -1 against 0, use a logical"}, {"sha": "af06543cf06ce195c45caaa13c54e4c440dfc7dd", "filename": "gcc/cse.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=f1657f05ef0fbc5183051de277141159f15a9472", "patch": "@@ -51,6 +51,10 @@ along with GCC; see the file COPYING3.  If not see\n #include \"dbgcnt.h\"\n #include \"rtl-iter.h\"\n \n+#ifndef LOAD_EXTEND_OP\n+#define LOAD_EXTEND_OP(M) UNKNOWN\n+#endif\n+\n /* The basic idea of common subexpression elimination is to go\n    through the code, keeping a record of expressions that would\n    have the same value at the current scan point, and replacing\n@@ -4867,7 +4871,6 @@ cse_insn (rtx_insn *insn)\n \t    }\n \t}\n \n-#ifdef LOAD_EXTEND_OP\n       /* See if a MEM has already been loaded with a widening operation;\n \t if it has, we can use a subreg of that.  Many CISC machines\n \t also have such operations, but this is only likely to be\n@@ -4913,7 +4916,6 @@ cse_insn (rtx_insn *insn)\n \t\tbreak;\n \t    }\n \t}\n-#endif /* LOAD_EXTEND_OP */\n \n       /* Try to express the constant using a register+offset expression\n \t derived from a constant anchor.  */"}, {"sha": "61eee4ae83095083e4e495e73ebb54d87b2e10d3", "filename": "gcc/fold-const.c", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=f1657f05ef0fbc5183051de277141159f15a9472", "patch": "@@ -77,6 +77,10 @@ along with GCC; see the file COPYING3.  If not see\n #include \"generic-match.h\"\n #include \"optabs.h\"\n \n+#ifndef LOAD_EXTEND_OP\n+#define LOAD_EXTEND_OP(M) UNKNOWN\n+#endif\n+\n /* Nonzero if we are folding constants inside an initializer; zero\n    otherwise.  */\n int folding_initializer = 0;\n@@ -6646,12 +6650,8 @@ fold_single_bit_test (location_t loc, enum tree_code code,\n       /* If we are going to be able to omit the AND below, we must do our\n \t operations as unsigned.  If we must use the AND, we have a choice.\n \t Normally unsigned is faster, but for some machines signed is.  */\n-#ifdef LOAD_EXTEND_OP\n       ops_unsigned = (LOAD_EXTEND_OP (operand_mode) == SIGN_EXTEND\n \t\t      && !flag_syntax_only) ? 0 : 1;\n-#else\n-      ops_unsigned = 1;\n-#endif\n \n       signed_type = lang_hooks.types.type_for_mode (operand_mode, 0);\n       unsigned_type = lang_hooks.types.type_for_mode (operand_mode, 1);\n@@ -7815,7 +7815,6 @@ fold_unary_loc (location_t loc, enum tree_code code, tree type, tree op0)\n \t      cst &= HOST_WIDE_INT_M1U\n \t\t     << (TYPE_PRECISION (TREE_TYPE (and1)) - 1);\n \t      change = (cst == 0);\n-#ifdef LOAD_EXTEND_OP\n \t      if (change\n \t\t  && !flag_syntax_only\n \t\t  && (LOAD_EXTEND_OP (TYPE_MODE (TREE_TYPE (and0)))\n@@ -7825,7 +7824,6 @@ fold_unary_loc (location_t loc, enum tree_code code, tree type, tree op0)\n \t\t  and0 = fold_convert_loc (loc, uns, and0);\n \t\t  and1 = fold_convert_loc (loc, uns, and1);\n \t\t}\n-#endif\n \t    }\n \t  if (change)\n \t    {"}, {"sha": "03babc87695c2613011565ef1337a87814bfc31c", "filename": "gcc/postreload.c", "status": "modified", "additions": 6, "deletions": 12, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2Fpostreload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f1657f05ef0fbc5183051de277141159f15a9472/gcc%2Fpostreload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpostreload.c?ref=f1657f05ef0fbc5183051de277141159f15a9472", "patch": "@@ -54,6 +54,10 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-pass.h\"\n #include \"dbgcnt.h\"\n \n+#ifndef LOAD_EXTEND_OP\n+#define LOAD_EXTEND_OP(M) UNKNOWN\n+#endif\n+\n static int reload_cse_noop_set_p (rtx);\n static bool reload_cse_simplify (rtx_insn *, rtx);\n static void reload_cse_regs_1 (void);\n@@ -254,9 +258,7 @@ reload_cse_simplify_set (rtx set, rtx_insn *insn)\n   int old_cost;\n   cselib_val *val;\n   struct elt_loc_list *l;\n-#ifdef LOAD_EXTEND_OP\n   enum rtx_code extend_op = UNKNOWN;\n-#endif\n   bool speed = optimize_bb_for_speed_p (BLOCK_FOR_INSN (insn));\n \n   dreg = true_regnum (SET_DEST (set));\n@@ -269,7 +271,6 @@ reload_cse_simplify_set (rtx set, rtx_insn *insn)\n \n   dclass = REGNO_REG_CLASS (dreg);\n \n-#ifdef LOAD_EXTEND_OP\n   /* When replacing a memory with a register, we need to honor assumptions\n      that combine made wrt the contents of sign bits.  We'll do this by\n      generating an extend instruction instead of a reg->reg copy.  Thus\n@@ -279,7 +280,6 @@ reload_cse_simplify_set (rtx set, rtx_insn *insn)\n       && (extend_op = LOAD_EXTEND_OP (GET_MODE (src))) != UNKNOWN\n       && !REG_P (SET_DEST (set)))\n     return 0;\n-#endif\n \n   val = cselib_lookup (src, GET_MODE (SET_DEST (set)), 0, VOIDmode);\n   if (! val)\n@@ -301,7 +301,6 @@ reload_cse_simplify_set (rtx set, rtx_insn *insn)\n \n       if (CONSTANT_P (this_rtx) && ! references_value_p (this_rtx, 0))\n \t{\n-#ifdef LOAD_EXTEND_OP\n \t  if (extend_op != UNKNOWN)\n \t    {\n \t      wide_int result;\n@@ -326,19 +325,17 @@ reload_cse_simplify_set (rtx set, rtx_insn *insn)\n \t\t}\n \t      this_rtx = immed_wide_int_const (result, word_mode);\n \t    }\n-#endif\n+\n \t  this_cost = set_src_cost (this_rtx, GET_MODE (SET_DEST (set)), speed);\n \t}\n       else if (REG_P (this_rtx))\n \t{\n-#ifdef LOAD_EXTEND_OP\n \t  if (extend_op != UNKNOWN)\n \t    {\n \t      this_rtx = gen_rtx_fmt_e (extend_op, word_mode, this_rtx);\n \t      this_cost = set_src_cost (this_rtx, word_mode, speed);\n \t    }\n \t  else\n-#endif\n \t    this_cost = register_move_cost (GET_MODE (this_rtx),\n \t\t\t\t\t    REGNO_REG_CLASS (REGNO (this_rtx)),\n \t\t\t\t\t    dclass);\n@@ -353,7 +350,6 @@ reload_cse_simplify_set (rtx set, rtx_insn *insn)\n \t      && REG_P (this_rtx)\n \t      && !REG_P (SET_SRC (set))))\n \t{\n-#ifdef LOAD_EXTEND_OP\n \t  if (GET_MODE_BITSIZE (GET_MODE (SET_DEST (set))) < BITS_PER_WORD\n \t      && extend_op != UNKNOWN\n #ifdef CANNOT_CHANGE_MODE_CLASS\n@@ -367,7 +363,6 @@ reload_cse_simplify_set (rtx set, rtx_insn *insn)\n \t      ORIGINAL_REGNO (wide_dest) = ORIGINAL_REGNO (SET_DEST (set));\n \t      validate_change (insn, &SET_DEST (set), wide_dest, 1);\n \t    }\n-#endif\n \n \t  validate_unshare_change (insn, &SET_SRC (set), this_rtx, 1);\n \t  old_cost = this_cost, did_change = 1;\n@@ -439,7 +434,6 @@ reload_cse_simplify_operands (rtx_insn *insn, rtx testreg)\n \tcontinue;\n \n       op = recog_data.operand[i];\n-#ifdef LOAD_EXTEND_OP\n       if (MEM_P (op)\n \t  && GET_MODE_BITSIZE (GET_MODE (op)) < BITS_PER_WORD\n \t  && LOAD_EXTEND_OP (GET_MODE (op)) != UNKNOWN)\n@@ -490,7 +484,7 @@ reload_cse_simplify_operands (rtx_insn *insn, rtx testreg)\n \t       safe to optimize, but is it worth the trouble?  */\n \t    continue;\n \t}\n-#endif /* LOAD_EXTEND_OP */\n+\n       if (side_effects_p (op))\n \tcontinue;\n       v = cselib_lookup (op, recog_data.operand_mode[i], 0, VOIDmode);"}]}