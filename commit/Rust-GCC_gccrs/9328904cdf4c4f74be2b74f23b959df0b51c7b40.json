{"sha": "9328904cdf4c4f74be2b74f23b959df0b51c7b40", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTMyODkwNGNkZjRjNGY3NGJlMmI3NGYyM2I5NTlkZjBiNTFjN2I0MA==", "commit": {"author": {"name": "Mark Mitchell", "email": "mark@codesourcery.com", "date": "2000-03-13T09:12:50Z"}, "committer": {"name": "Mark Mitchell", "email": "mmitchel@gcc.gnu.org", "date": "2000-03-13T09:12:50Z"}, "message": "tree.h (record_layout_info_s): New structure.\n\n\t* tree.h (record_layout_info_s): New structure.\n\t(record_layout_info): New type.\n\t(new_record_layout_info): New function.\n\t(layout_field): Likewise.\n\t(finish_record_layout): Likewise.\n\t* stor-layout.c (layout_record): Remove.\n\t(new_record_layout_info): New function.\n\t(layout_field): New function, broken out from layout_record.\n\t(finalize_record_size): Likewise.\n\t(compute_record_mode): Likewise.\n\t(finalize_type_size): New function, broken out from layout_type.\n\t(finish_record_layout): Likewise.\n\t(layout_type): Use them.\n\nFrom-SVN: r32503", "tree": {"sha": "436a9081b94cbee253bfc1c9b70ba08564ec5627", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/436a9081b94cbee253bfc1c9b70ba08564ec5627"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/9328904cdf4c4f74be2b74f23b959df0b51c7b40", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9328904cdf4c4f74be2b74f23b959df0b51c7b40", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9328904cdf4c4f74be2b74f23b959df0b51c7b40", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9328904cdf4c4f74be2b74f23b959df0b51c7b40/comments", "author": null, "committer": null, "parents": [{"sha": "05e126b36023b1f79a1cbe16a3345200ba13c247", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/05e126b36023b1f79a1cbe16a3345200ba13c247", "html_url": "https://github.com/Rust-GCC/gccrs/commit/05e126b36023b1f79a1cbe16a3345200ba13c247"}], "stats": {"total": 928, "additions": 519, "deletions": 409}, "files": [{"sha": "d5c91d3bcd883c16473ee8e6950752ab6360b695", "filename": "gcc/ChangeLog", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9328904cdf4c4f74be2b74f23b959df0b51c7b40/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9328904cdf4c4f74be2b74f23b959df0b51c7b40/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=9328904cdf4c4f74be2b74f23b959df0b51c7b40", "patch": "@@ -1,3 +1,19 @@\n+2000-03-13  Mark Mitchell  <mark@codesourcery.com>\n+\n+\t* tree.h (record_layout_info_s): New structure.\n+\t(record_layout_info): New type.\n+\t(new_record_layout_info): New function.\n+\t(layout_field): Likewise.\n+\t(finish_record_layout): Likewise.\n+\t* stor-layout.c (layout_record): Remove.\n+\t(new_record_layout_info): New function.\n+\t(layout_field): New function, broken out from layout_record.\n+\t(finalize_record_size): Likewise.\n+\t(compute_record_mode): Likewise.\n+\t(finalize_type_size): New function, broken out from layout_type.\n+\t(finish_record_layout): Likewise.\n+\t(layout_type): Use them.\n+\t\n 2000-03-12  Zack Weinberg  <zack@wolery.cumb.org>\n \n  \t* cpphash.c: Don't include version.h."}, {"sha": "d2c4b7b41bfb58e165cf88e387ed833aa011e1f6", "filename": "gcc/stor-layout.c", "status": "modified", "additions": 466, "deletions": 406, "changes": 872, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9328904cdf4c4f74be2b74f23b959df0b51c7b40/gcc%2Fstor-layout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9328904cdf4c4f74be2b74f23b959df0b51c7b40/gcc%2Fstor-layout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.c?ref=9328904cdf4c4f74be2b74f23b959df0b51c7b40", "patch": "@@ -50,8 +50,10 @@ unsigned int maximum_field_alignment;\n    May be overridden by front-ends.  */\n unsigned int set_alignment = 0;\n \n-static tree layout_record\tPARAMS ((tree));\n static void layout_union\tPARAMS ((tree));\n+static void finalize_record_size PARAMS ((record_layout_info));\n+static void compute_record_mode PARAMS ((tree));\n+static void finalize_type_size PARAMS ((tree));\n \f\n /* SAVE_EXPRs for sizes of types and decls, waiting to be expanded.  */\n \n@@ -400,343 +402,353 @@ layout_decl (decl, known_align)\n     }\n }\n \f\n-/* Lay out a RECORD_TYPE type (a C struct).\n-   This means laying out the fields, determining their positions,\n-   and computing the overall size and required alignment of the record.\n-   Note that if you set the TYPE_ALIGN before calling this\n-   then the struct is aligned to at least that boundary.\n-\n-   If the type has basetypes, you must call layout_basetypes\n-   before calling this function.\n-\n-   The return value is a list of static members of the record.\n-   They still need to be laid out.  */\n+/* Create a new record_layout_info for the RECORD_TYPE T.  It is the\n+   responsibility of the caller to call `free' for the storage the\n+   returned.  */\n \n-static tree\n-layout_record (rec)\n-     tree rec;\n+record_layout_info\n+new_record_layout_info (t)\n+     tree t;\n {\n-  register tree field;\n-  unsigned int record_align = MAX (BITS_PER_UNIT, TYPE_ALIGN (rec));\n-  unsigned int unpacked_align = record_align;\n-  /* These must be laid out *after* the record is.  */\n-  tree pending_statics = NULL_TREE;\n-  /* Record size so far is CONST_SIZE + VAR_SIZE bits,\n-     where CONST_SIZE is an integer\n-     and VAR_SIZE is a tree expression.\n-     If VAR_SIZE is null, the size is just CONST_SIZE.\n-     Naturally we try to avoid using VAR_SIZE.  */\n-  unsigned HOST_WIDE_INT const_size = 0;\n-  tree var_size = 0;\n-  /* Once we start using VAR_SIZE, this is the maximum alignment\n-     that we know VAR_SIZE has.  */\n-  unsigned int var_align = BITS_PER_UNIT;\n-  int packed_maybe_necessary = 0;\n+  record_layout_info rli \n+    = (record_layout_info) xcalloc (1, sizeof (struct record_layout_info_s));\n+\n+  rli->t = t;\n+  /* If the type has a minimum specified alignment (via an attribute\n+     declaration, for example) use it -- otherwise, start with a\n+     one-byte alignment.  */\n+  rli->record_align = MAX (BITS_PER_UNIT, TYPE_ALIGN (t));\n+  rli->unpacked_align = rli->record_align;\n \n #ifdef STRUCTURE_SIZE_BOUNDARY\n   /* Packed structures don't need to have minimum size.  */\n   if (! TYPE_PACKED (rec))\n-    record_align = MAX (record_align, STRUCTURE_SIZE_BOUNDARY);\n+    rli->record_align = MAX (rli->record_align, STRUCTURE_SIZE_BOUNDARY);\n #endif\n \n-  for (field = TYPE_FIELDS (rec); field; field = TREE_CHAIN (field))\n-    {\n-      unsigned int known_align = var_size ? var_align : const_size;\n-      unsigned int desired_align = 0;\n-      tree type = TREE_TYPE (field);\n-\n-      /* If FIELD is static, then treat it like a separate variable,\n-\t not really like a structure field.\n-\t If it is a FUNCTION_DECL, it's a method.\n-\t In both cases, all we do is lay out the decl,\n-\t and we do it *after* the record is laid out.  */\n+  return rli;\n+}\n \n-      if (TREE_CODE (field) == VAR_DECL)\n-\t{\n-\t  pending_statics = tree_cons (NULL_TREE, field, pending_statics);\n-\t  continue;\n-\t}\n+/* RLI contains information about the layout of a RECORD_TYPE.  FIELD\n+   is a FIELD_DECL to be added after those fields already present in\n+   T.  (FIELD is not actually added to the TYPE_FIELDS list here;\n+   callers that desire that behavior must manually perform that step.)  */\n \n-      /* Enumerators and enum types which are local to this class need not\n-\t be laid out.  Likewise for initialized constant fields.  */\n-      if (TREE_CODE (field) != FIELD_DECL)\n-\tcontinue;\n+void\n+layout_field (rli, field)\n+     record_layout_info rli;\n+     tree field;\n+{\n+  /* The alignment required for FIELD.  */\n+  unsigned int desired_align;\n+  /* The alignment FIELD would have if we just dropped it into the\n+     record as it presently stands.  */\n+  unsigned int known_align;\n+  /* The type of this field.  */\n+  tree type = TREE_TYPE (field);\n+  /* The size of this field, in bits.  */\n+  tree dsize;\n+\n+  /* If FIELD is static, then treat it like a separate variable, not\n+     really like a structure field.  If it is a FUNCTION_DECL, it's a\n+     method.  In both cases, all we do is lay out the decl, and we do\n+     it *after* the record is laid out.  */\n+  if (TREE_CODE (field) == VAR_DECL)\n+    {\n+      rli->pending_statics = tree_cons (NULL_TREE, field,\n+\t\t\t\t\trli->pending_statics);\n+      return;\n+    }\n+  /* Enumerators and enum types which are local to this class need not\n+     be laid out.  Likewise for initialized constant fields.  */\n+  else if (TREE_CODE (field) != FIELD_DECL)\n+    return;\n \n-      /* Lay out the field so we know what alignment it needs.\n-\t For a packed field, use the alignment as specified,\n-\t disregarding what the type would want.  */\n-      if (DECL_PACKED (field))\n-\tdesired_align = DECL_ALIGN (field);\n-      layout_decl (field, known_align);\n-      if (! DECL_PACKED (field))\n-\tdesired_align = DECL_ALIGN (field);\n-      /* Some targets (i.e. VMS) limit struct field alignment\n-\t to a lower boundary than alignment of variables.  */\n+  /* Work out the known alignment so far.  */\n+  known_align = rli->var_size ? rli->var_align : rli->const_size;\n+\n+  /* Lay out the field so we know what alignment it needs.  For a\n+     packed field, use the alignment as specified, disregarding what\n+     the type would want.  */\n+  if (DECL_PACKED (field))\n+    desired_align = DECL_ALIGN (field);\n+  layout_decl (field, known_align);\n+  if (! DECL_PACKED (field))\n+    desired_align = DECL_ALIGN (field);\n+  /* Some targets (i.e. VMS) limit struct field alignment\n+     to a lower boundary than alignment of variables.  */\n #ifdef BIGGEST_FIELD_ALIGNMENT\n-      desired_align = MIN (desired_align, BIGGEST_FIELD_ALIGNMENT);\n+  desired_align = MIN (desired_align, BIGGEST_FIELD_ALIGNMENT);\n #endif\n #ifdef ADJUST_FIELD_ALIGN\n-      desired_align = ADJUST_FIELD_ALIGN (field, desired_align);\n+  desired_align = ADJUST_FIELD_ALIGN (field, desired_align);\n #endif\n \n-      /* Record must have at least as much alignment as any field.\n-\t Otherwise, the alignment of the field within the record\n-\t is meaningless.  */\n-\n+  /* Record must have at least as much alignment as any field.\n+     Otherwise, the alignment of the field within the record is\n+     meaningless.  */\n #ifdef PCC_BITFIELD_TYPE_MATTERS\n-      if (PCC_BITFIELD_TYPE_MATTERS && type != error_mark_node\n-\t  && DECL_BIT_FIELD_TYPE (field)\n-\t  && ! integer_zerop (TYPE_SIZE (type)))\n+  if (PCC_BITFIELD_TYPE_MATTERS && type != error_mark_node\n+      && DECL_BIT_FIELD_TYPE (field)\n+      && ! integer_zerop (TYPE_SIZE (type)))\n+    {\n+      /* For these machines, a zero-length field does not\n+\t affect the alignment of the structure as a whole.\n+\t It does, however, affect the alignment of the next field\n+\t within the structure.  */\n+      if (! integer_zerop (DECL_SIZE (field)))\n+\trli->record_align = MAX (rli->record_align, desired_align);\n+      else if (! DECL_PACKED (field))\n+\tdesired_align = TYPE_ALIGN (type);\n+      /* A named bit field of declared type `int'\n+\t forces the entire structure to have `int' alignment.  */\n+      if (DECL_NAME (field) != 0)\n \t{\n-\t  /* For these machines, a zero-length field does not\n-\t     affect the alignment of the structure as a whole.\n-\t     It does, however, affect the alignment of the next field\n-\t     within the structure.  */\n-\t  if (! integer_zerop (DECL_SIZE (field)))\n-\t    record_align = MAX (record_align, desired_align);\n-\t  else if (! DECL_PACKED (field))\n-\t    desired_align = TYPE_ALIGN (type);\n-\t  /* A named bit field of declared type `int'\n-\t     forces the entire structure to have `int' alignment.  */\n-\t  if (DECL_NAME (field) != 0)\n-\t    {\n-\t      unsigned int type_align = TYPE_ALIGN (type);\n+\t  unsigned int type_align = TYPE_ALIGN (type);\n \n-\t      if (maximum_field_alignment != 0)\n-\t\ttype_align = MIN (type_align, maximum_field_alignment);\n-\t      else if (DECL_PACKED (field))\n-\t\ttype_align = MIN (type_align, BITS_PER_UNIT);\n+\t  if (maximum_field_alignment != 0)\n+\t    type_align = MIN (type_align, maximum_field_alignment);\n+\t  else if (DECL_PACKED (field))\n+\t    type_align = MIN (type_align, BITS_PER_UNIT);\n \n-\t      record_align = MAX (record_align, type_align);\n-\t      if (warn_packed)\n-\t\tunpacked_align = MAX (unpacked_align, TYPE_ALIGN (type));\n-\t    }\n-\t}\n-      else\n-#endif\n-\t{\n-\t  record_align = MAX (record_align, desired_align);\n+\t  rli->record_align = MAX (rli->record_align, type_align);\n \t  if (warn_packed)\n-\t    unpacked_align = MAX (unpacked_align, TYPE_ALIGN (type));\n+\t    rli->unpacked_align = MAX (rli->unpacked_align, \n+\t\t\t\t       TYPE_ALIGN (type));\n \t}\n+    }\n+  else\n+#endif\n+    {\n+      rli->record_align = MAX (rli->record_align, desired_align);\n+      if (warn_packed)\n+\trli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));\n+    }\n \n-      if (warn_packed && DECL_PACKED (field))\n+  if (warn_packed && DECL_PACKED (field))\n+    {\n+      if (rli->const_size % TYPE_ALIGN (type) == 0\n+\t  || (rli->var_align % TYPE_ALIGN (type) == 0 \n+\t      && rli->var_size != NULL_TREE))\n \t{\n-\t  if (const_size % TYPE_ALIGN (type) == 0\n-\t      || (var_align % TYPE_ALIGN (type) == 0 && var_size != NULL_TREE))\n+\t  if (TYPE_ALIGN (type) > desired_align)\n \t    {\n-\t      if (TYPE_ALIGN (type) > desired_align)\n-\t\t{\n-\t\t  if (STRICT_ALIGNMENT)\n-\t\t    warning_with_decl (field, \"packed attribute causes inefficient alignment for `%s'\");\n-\t\t  else\n-\t\t    warning_with_decl (field, \"packed attribute is unnecessary for `%s'\");\n-\t\t}\n+\t      if (STRICT_ALIGNMENT)\n+\t\twarning_with_decl (field, \"packed attribute causes inefficient alignment for `%s'\");\n+\t      else\n+\t\twarning_with_decl (field, \"packed attribute is unnecessary for `%s'\");\n \t    }\n-\t  else\n-\t    packed_maybe_necessary = 1;\n \t}\n+      else\n+\trli->packed_maybe_necessary = 1;\n+    }\n \n-      /* Does this field automatically have alignment it needs\n-\t by virtue of the fields that precede it and the record's\n-\t own alignment?  */\n-\n-      if (const_size % desired_align != 0\n-\t  || (var_align % desired_align != 0 && var_size != NULL_TREE))\n-\t{\n-\t  /* No, we need to skip space before this field.\n-\t     Bump the cumulative size to multiple of field alignment.  */\n+  /* Does this field automatically have alignment it needs by virtue\n+     of the fields that precede it and the record's own alignment?  */\n+  if (rli->const_size % desired_align != 0\n+      || (rli->var_align % desired_align != 0 \n+\t  && rli->var_size != NULL_TREE))\n+    {\n+      /* No, we need to skip space before this field.\n+\t Bump the cumulative size to multiple of field alignment.  */\n \n-\t  if (warn_padded)\n-\t    warning_with_decl (field, \"padding struct to align `%s'\");\n+      if (warn_padded)\n+\twarning_with_decl (field, \"padding struct to align `%s'\");\n \n-\t  if (var_size == NULL_TREE || var_align % desired_align == 0)\n-\t    const_size\n-\t      = CEIL (const_size, desired_align) * desired_align;\n-\t  else\n-\t    {\n-\t      if (const_size > 0)\n-\t\tvar_size = size_binop (PLUS_EXPR, var_size,\n-\t\t\t\t       bitsize_int (const_size));\n-\t      const_size = 0;\n-\t      var_size = round_up (var_size, desired_align);\n-\t      var_align = MIN (var_align, desired_align);\n-\t    }\n+      if (rli->var_size == NULL_TREE || rli->var_align % desired_align == 0)\n+\trli->const_size\n+\t  = CEIL (rli->const_size, desired_align) * desired_align;\n+      else\n+\t{\n+\t  if (rli->const_size > 0)\n+\t    rli->var_size = size_binop (PLUS_EXPR, rli->var_size,\n+\t\t\t\t\tbitsize_int (rli->const_size));\n+\t  rli->const_size = 0;\n+\t  rli->var_size = round_up (rli->var_size, desired_align);\n+\t  rli->var_align = MIN (rli->var_align, desired_align);\n \t}\n+    }\n \n #ifdef PCC_BITFIELD_TYPE_MATTERS\n-      if (PCC_BITFIELD_TYPE_MATTERS\n-\t  && TREE_CODE (field) == FIELD_DECL\n-\t  && type != error_mark_node\n-\t  && DECL_BIT_FIELD_TYPE (field)\n-\t  && !DECL_PACKED (field)\n-\t  && maximum_field_alignment == 0\n-\t  && !integer_zerop (DECL_SIZE (field)))\n-\t{\n-\t  unsigned int type_align = TYPE_ALIGN (type);\n-\t  register tree dsize = DECL_SIZE (field);\n-\t  unsigned int field_size = TREE_INT_CST_LOW (dsize);\n-\n-\t  /* A bit field may not span more units of alignment of its type\n-\t     than its type itself.  Advance to next boundary if necessary.  */\n-\t  if (((const_size + field_size + type_align - 1) / type_align\n-\t       - const_size / type_align)\n-\t      > TREE_INT_CST_LOW (TYPE_SIZE (TREE_TYPE (field))) / type_align)\n-\t    const_size = CEIL (const_size, type_align) * type_align;\n-\t}\n+  if (PCC_BITFIELD_TYPE_MATTERS\n+      && TREE_CODE (field) == FIELD_DECL\n+      && type != error_mark_node\n+      && DECL_BIT_FIELD_TYPE (field)\n+      && !DECL_PACKED (field)\n+      && maximum_field_alignment == 0\n+      && !integer_zerop (DECL_SIZE (field)))\n+    {\n+      unsigned int type_align = TYPE_ALIGN (type);\n+      register tree dsize = DECL_SIZE (field);\n+      unsigned int field_size = TREE_INT_CST_LOW (dsize);\n+\n+      /* A bit field may not span more units of alignment of its type\n+\t than its type itself.  Advance to next boundary if necessary.  */\n+      if (((rli->const_size + field_size + type_align - 1) / type_align\n+\t   - rli->const_size / type_align)\n+\t  > TREE_INT_CST_LOW (TYPE_SIZE (TREE_TYPE (field))) / type_align)\n+\trli->const_size = CEIL (rli->const_size, type_align) * type_align;\n+    }\n #endif\n \n-/* No existing machine description uses this parameter.\n-   So I have made it in this aspect identical to PCC_BITFIELD_TYPE_MATTERS.  */\n+  /* No existing machine description uses this parameter.  So I have\n+     made it in this aspect identical to PCC_BITFIELD_TYPE_MATTERS.  */\n #ifdef BITFIELD_NBYTES_LIMITED\n-      if (BITFIELD_NBYTES_LIMITED\n-\t  && TREE_CODE (field) == FIELD_DECL\n-\t  && type != error_mark_node\n-\t  && DECL_BIT_FIELD_TYPE (field)\n-\t  && !DECL_PACKED (field)\n-\t  && !integer_zerop (DECL_SIZE (field)))\n-\t{\n-\t  unsigned int type_align = TYPE_ALIGN (type);\n-\t  register tree dsize = DECL_SIZE (field);\n-\t  int field_size = TREE_INT_CST_LOW (dsize);\n-\n-\t  if (maximum_field_alignment != 0)\n-\t    type_align = MIN (type_align, maximum_field_alignment);\n-\t  /* ??? This test is opposite the test in the containing if\n-\t     statement, so this code is unreachable currently.  */\n-\t  else if (DECL_PACKED (field))\n-\t    type_align = MIN (type_align, BITS_PER_UNIT);\n+  if (BITFIELD_NBYTES_LIMITED\n+      && TREE_CODE (field) == FIELD_DECL\n+      && type != error_mark_node\n+      && DECL_BIT_FIELD_TYPE (field)\n+      && !DECL_PACKED (field)\n+      && !integer_zerop (DECL_SIZE (field)))\n+    {\n+      unsigned int type_align = TYPE_ALIGN (type);\n+      register tree dsize = DECL_SIZE (field);\n+      int field_size = TREE_INT_CST_LOW (dsize);\n \n-\t  /* A bit field may not span the unit of alignment of its type.\n-\t     Advance to next boundary if necessary.  */\n-\t  /* ??? This code should match the code above for the\n-\t     PCC_BITFIELD_TYPE_MATTERS case.  */\n-\t  if (const_size / type_align\n-\t      != (const_size + field_size - 1) / type_align)\n-\t    const_size = CEIL (const_size, type_align) * type_align;\n-\t}\n+      if (maximum_field_alignment != 0)\n+\ttype_align = MIN (type_align, maximum_field_alignment);\n+      /* ??? This test is opposite the test in the containing if\n+\t statement, so this code is unreachable currently.  */\n+      else if (DECL_PACKED (field))\n+\ttype_align = MIN (type_align, BITS_PER_UNIT);\n+\n+      /* A bit field may not span the unit of alignment of its type.\n+\t Advance to next boundary if necessary.  */\n+      /* ??? This code should match the code above for the\n+\t PCC_BITFIELD_TYPE_MATTERS case.  */\n+      if (rli->const_size / type_align\n+\t  != (rli->const_size + field_size - 1) / type_align)\n+\trli->const_size = CEIL (rli->const_size, type_align) * type_align;\n+    }\n #endif\n \n-      /* Size so far becomes the position of this field.  */\n+  /* Size so far becomes the position of this field.  */\n \n-      if (var_size && const_size)\n-\tDECL_FIELD_BITPOS (field)\n-\t  = size_binop (PLUS_EXPR, var_size, bitsize_int (const_size));\n-      else if (var_size)\n-\tDECL_FIELD_BITPOS (field) = var_size;\n-      else\n-\t{\n-\t  DECL_FIELD_BITPOS (field) = bitsize_int (const_size);\n-\n-\t  /* If this field ended up more aligned than we thought it\n-\t     would be (we approximate this by seeing if its position\n-\t     changed), lay out the field again; perhaps we can use an\n-\t     integral mode for it now.  */\n-\t  if (known_align != const_size)\n-\t    layout_decl (field, const_size);\n-\t}\n-\n-      /* Now add size of this field to the size of the record.  */\n+  if (rli->var_size && rli->const_size)\n+    DECL_FIELD_BITPOS (field)\n+      = size_binop (PLUS_EXPR, rli->var_size, bitsize_int (rli->const_size));\n+  else if (rli->var_size)\n+    DECL_FIELD_BITPOS (field) = rli->var_size;\n+  else\n+    {\n+      DECL_FIELD_BITPOS (field) = bitsize_int (rli->const_size);\n+\n+      /* If this field ended up more aligned than we thought it\n+\t would be (we approximate this by seeing if its position\n+\t changed), lay out the field again; perhaps we can use an\n+\t integral mode for it now.  */\n+      if (known_align != rli->const_size)\n+\tlayout_decl (field, rli->const_size);\n+    }\n \n-      {\n-        register tree dsize = DECL_SIZE (field);\n-\n-\t/* This can happen when we have an invalid nested struct definition,\n-\t   such as struct j { struct j { int i; } }.  The error message is\n-\t   printed in finish_struct.  */\n-\tif (dsize == 0)\n-\t  /* Do nothing.  */;\n-\telse if (TREE_CODE (dsize) == INTEGER_CST\n-\t\t && ! TREE_CONSTANT_OVERFLOW (dsize)\n-\t\t && TREE_INT_CST_HIGH (dsize) == 0\n-\t\t && TREE_INT_CST_LOW (dsize) + const_size >= const_size)\n-\t  /* Use const_size if there's no overflow.  */\n-\t  const_size += TREE_INT_CST_LOW (dsize);\n-\telse\n-\t  {\n-\t    if (var_size == NULL_TREE)\n-\t      var_size = dsize;\n-\t    else\n-\t      var_size = size_binop (PLUS_EXPR, var_size, dsize);\n-\t  }\n-      }\n+  /* Now add size of this field to the size of the record.  */\n+  dsize = DECL_SIZE (field);\n+\n+  /* This can happen when we have an invalid nested struct definition,\n+     such as struct j { struct j { int i; } }.  The error message is\n+     printed in finish_struct.  */\n+  if (dsize == 0)\n+    /* Do nothing.  */;\n+  else if (TREE_CODE (dsize) == INTEGER_CST\n+\t   && ! TREE_CONSTANT_OVERFLOW (dsize)\n+\t   && TREE_INT_CST_HIGH (dsize) == 0\n+\t   && TREE_INT_CST_LOW (dsize) + rli->const_size >= rli->const_size)\n+    /* Use const_size if there's no overflow.  */\n+    rli->const_size += TREE_INT_CST_LOW (dsize);\n+  else\n+    {\n+      if (rli->var_size == NULL_TREE)\n+\trli->var_size = dsize;\n+      else\n+\trli->var_size = size_binop (PLUS_EXPR, rli->var_size, dsize);\n     }\n+}\n \n-  /* Work out the total size and alignment of the record\n-     as one expression and store in the record type.\n-     Round it up to a multiple of the record's alignment.  */\n+/* Assuming that all the fields have been laid out, this function uses\n+   RLI to compute the final TYPE_SIZE, TYPE_ALIGN, etc. for the type\n+   inidicated by RLI.  */\n \n-  if (var_size == NULL_TREE)\n-    TYPE_SIZE (rec) = bitsize_int (const_size);\n+static void\n+finalize_record_size (rli)\n+     record_layout_info rli;\n+{\n+  /* Work out the total size and alignment of the record as one\n+     expression and store in the record type.  Round it up to a\n+     multiple of the record's alignment.  */\n+  if (rli->var_size == NULL_TREE)\n+    TYPE_SIZE (rli->t) = bitsize_int (rli->const_size);\n   else\n     {\n-      if (const_size)\n-\tvar_size = size_binop (PLUS_EXPR, var_size, bitsize_int (const_size));\n-\n-      TYPE_SIZE (rec) = var_size;\n+      if (rli->const_size)\n+\trli->var_size = size_binop (PLUS_EXPR, rli->var_size,\n+\t\t\t\t    bitsize_int (rli->const_size));\n+      TYPE_SIZE (rli->t) = rli->var_size;\n     }\n \n   /* Determine the desired alignment.  */\n #ifdef ROUND_TYPE_ALIGN\n-  TYPE_ALIGN (rec) = ROUND_TYPE_ALIGN (rec, TYPE_ALIGN (rec), record_align);\n+  TYPE_ALIGN (rli->t) = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t),\n+\t\t\t\t\t  record_align);\n #else\n-  TYPE_ALIGN (rec) = MAX (TYPE_ALIGN (rec), record_align);\n+  TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);\n #endif\n \n   /* Record the un-rounded size in the binfo node.  But first we check\n      the size of TYPE_BINFO to make sure that BINFO_SIZE is available.  */\n-  if (TYPE_BINFO (rec) && TREE_VEC_LENGTH (TYPE_BINFO (rec)) > 6)\n+  if (TYPE_BINFO (rli->t) && TREE_VEC_LENGTH (TYPE_BINFO (rli->t)) > 6)\n     {\n-      TYPE_BINFO_SIZE (rec) = TYPE_SIZE (rec);\n-      TYPE_BINFO_SIZE_UNIT (rec)\n+      TYPE_BINFO_SIZE (rli->t) = TYPE_SIZE (rli->t);\n+      TYPE_BINFO_SIZE_UNIT (rli->t)\n \t= convert (sizetype,\n-\t\t   size_binop (FLOOR_DIV_EXPR, TYPE_SIZE (rec),\n+\t\t   size_binop (FLOOR_DIV_EXPR, TYPE_SIZE (rli->t),\n \t\t\t       bitsize_int (BITS_PER_UNIT)));\n     }\n   \n   {\n-    tree unpadded_size = TYPE_SIZE (rec);\n+    tree unpadded_size = TYPE_SIZE (rli->t);\n \n #ifdef ROUND_TYPE_SIZE\n-    TYPE_SIZE (rec) = ROUND_TYPE_SIZE (rec, TYPE_SIZE (rec), TYPE_ALIGN (rec));\n+    TYPE_SIZE (rli->t) = ROUND_TYPE_SIZE (rli->t, TYPE_SIZE (rli->t),\n+\t\t\t\t\t  TYPE_ALIGN (rli->t));\n #else\n     /* Round the size up to be a multiple of the required alignment */\n-    TYPE_SIZE (rec) = round_up (TYPE_SIZE (rec), TYPE_ALIGN (rec));\n+    TYPE_SIZE (rli->t) = round_up (TYPE_SIZE (rli->t), TYPE_ALIGN (rli->t));\n #endif\n \n-    if (warn_padded && var_size == NULL_TREE\n-\t&& simple_cst_equal (unpadded_size, TYPE_SIZE (rec)) == 0)\n+    if (warn_padded && rli->var_size == NULL_TREE\n+\t&& simple_cst_equal (unpadded_size, TYPE_SIZE (rli->t)) == 0)\n       warning (\"padding struct size to alignment boundary\");\n   }\n   \n-  if (warn_packed && TYPE_PACKED (rec) && !packed_maybe_necessary\n-      && var_size == NULL_TREE)\n+  if (warn_packed && TYPE_PACKED (rli->t) && !rli->packed_maybe_necessary\n+      && rli->var_size == NULL_TREE)\n     {\n       tree unpacked_size;\n \n-      TYPE_PACKED (rec) = 0;\n+      TYPE_PACKED (rli->t) = 0;\n #ifdef ROUND_TYPE_ALIGN\n-      unpacked_align\n-\t= ROUND_TYPE_ALIGN (rec, TYPE_ALIGN (rec), unpacked_align);\n+      rli->unpacked_align\n+\t= ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t), rli->unpacked_align);\n #else\n-      unpacked_align = MAX (TYPE_ALIGN (rec), unpacked_align);\n+      rli->unpacked_align = MAX (TYPE_ALIGN (rli->t), rli->unpacked_align);\n #endif\n #ifdef ROUND_TYPE_SIZE\n-      unpacked_size = ROUND_TYPE_SIZE (rec, TYPE_SIZE (rec), unpacked_align);\n+      unpacked_size = ROUND_TYPE_SIZE (rli->t, TYPE_SIZE (rli->t),\n+\t\t\t\t       rli->unpacked_align);\n #else\n-      unpacked_size = round_up (TYPE_SIZE (rec), unpacked_align);\n+      unpacked_size = round_up (TYPE_SIZE (rli->t), rli->unpacked_align);\n #endif\n \n-      if (simple_cst_equal (unpacked_size, TYPE_SIZE (rec)))\n+      if (simple_cst_equal (unpacked_size, TYPE_SIZE (rli->t)))\n \t{\n-\t  if (TYPE_NAME (rec))\n+\t  if (TYPE_NAME (rli->t))\n \t    {\n \t      char *name;\n \n-\t      if (TREE_CODE (TYPE_NAME (rec)) == IDENTIFIER_NODE)\n-\t\tname = IDENTIFIER_POINTER (TYPE_NAME (rec));\n+\t      if (TREE_CODE (TYPE_NAME (rli->t)) == IDENTIFIER_NODE)\n+\t\tname = IDENTIFIER_POINTER (TYPE_NAME (rli->t));\n \t      else\n-\t\tname = IDENTIFIER_POINTER (DECL_NAME (TYPE_NAME (rec)));\n+\t\tname = IDENTIFIER_POINTER (DECL_NAME (TYPE_NAME (rli->t)));\n \t      if (STRICT_ALIGNMENT)\n \t\twarning (\"packed attribute causes inefficient alignment for `%s'\", name);\n \t      else\n@@ -750,11 +762,192 @@ layout_record (rec)\n \t\twarning (\"packed attribute is unnecessary\");\n \t    }\n \t}\n-      TYPE_PACKED (rec) = 1;\n+      TYPE_PACKED (rli->t) = 1;\n     }\n+}\n+\n+/* Compute the TYPE_MODE for the TYPE (which is a RECORD_TYPE).  */\n \n-  return pending_statics;\n+static void\n+compute_record_mode (type)\n+     tree type;\n+{\n+  /* Most RECORD_TYPEs have BLKmode, so we start off assuming that.\n+     However, if possible, we use a mode that fits in a register\n+     instead, in order to allow for better optimization down the\n+     line.  */\n+  TYPE_MODE (type) = BLKmode;\n+  if (TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST)\n+    {\n+      tree field;\n+      enum machine_mode mode = VOIDmode;\n+\n+      /* A record which has any BLKmode members must itself be\n+\t BLKmode; it can't go in a register.  Unless the member is\n+\t BLKmode only because it isn't aligned.  */\n+      for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n+\t{\n+\t  unsigned HOST_WIDE_INT bitpos;\n+\n+\t  if (TREE_CODE (field) != FIELD_DECL\n+\t      || TREE_CODE (TREE_TYPE (field)) == ERROR_MARK)\n+\t    continue;\n+\n+\t  if (TYPE_MODE (TREE_TYPE (field)) == BLKmode\n+\t      && ! TYPE_NO_FORCE_BLK (TREE_TYPE (field)))\n+\t    return;\n+\n+\t  if (TREE_CODE (DECL_FIELD_BITPOS (field)) != INTEGER_CST)\n+\t    return;\n+\n+\t  bitpos = TREE_INT_CST_LOW (DECL_FIELD_BITPOS (field));\n+\n+\t  /* Must be BLKmode if any field crosses a word boundary,\n+\t     since extract_bit_field can't handle that in registers.  */\n+\t  if (bitpos / BITS_PER_WORD\n+\t      != ((TREE_INT_CST_LOW (DECL_SIZE (field)) + bitpos - 1)\n+\t\t  / BITS_PER_WORD)\n+\t      /* But there is no problem if the field is entire words.  */\n+\t      && TREE_INT_CST_LOW (DECL_SIZE (field)) % BITS_PER_WORD != 0)\n+\t    return;\n+\n+\t  /* If this field is the whole struct, remember its mode so\n+\t     that, say, we can put a double in a class into a DF\n+\t     register instead of forcing it to live in the stack.  */\n+\t  if (simple_cst_equal (TYPE_SIZE (type), DECL_SIZE (field)))\n+\t    mode = DECL_MODE (field);\n+\n+#ifdef STRUCT_FORCE_BLK\n+\t  /* With some targets, eg. c4x, it is sub-optimal\n+\t     to access an aligned BLKmode structure as a scalar.  */\n+\t  if (mode == VOIDmode && STRUCT_FORCE_BLK (field))\n+\t    return;\n+#endif /* STRUCT_FORCE_BLK  */\n+\t}\n+\n+      if (mode != VOIDmode)\n+\t/* We only have one real field; use its mode.  */\n+\tTYPE_MODE (type) = mode;\n+      else\n+\tTYPE_MODE (type)\n+\t  = mode_for_size_tree (TYPE_SIZE (type), MODE_INT, 1);\n+\n+      /* If structure's known alignment is less than what the scalar\n+\t mode would need, and it matters, then stick with BLKmode.  */\n+      if (TYPE_MODE (type) != BLKmode\n+\t  && STRICT_ALIGNMENT\n+\t  && ! (TYPE_ALIGN (type) >= BIGGEST_ALIGNMENT\n+\t\t|| (TYPE_ALIGN (type) >=\n+\t\t    GET_MODE_ALIGNMENT (TYPE_MODE (type)))))\n+\t{\n+\t  /* If this is the only reason this type is BLKmode, then\n+\t     don't force containing types to be BLKmode.  */\n+\t  TYPE_NO_FORCE_BLK (type) = 1;\n+\t  TYPE_MODE (type) = BLKmode;\n+\t}\n+    }\n }\n+\n+/* Compute TYPE_SIZE and TYPE_ALIGN for TYPE, once it has been laid\n+   out.  */\n+\n+static void\n+finalize_type_size (type)\n+     tree type;\n+{\n+  /* Normally, use the alignment corresponding to the mode chosen.\n+     However, where strict alignment is not required, avoid\n+     over-aligning structures, since most compilers do not do this\n+     alignment.  */\n+\n+  if (TYPE_MODE (type) != BLKmode && TYPE_MODE (type) != VOIDmode\n+      && (STRICT_ALIGNMENT\n+\t  || (TREE_CODE (type) != RECORD_TYPE && TREE_CODE (type) != UNION_TYPE\n+\t      && TREE_CODE (type) != QUAL_UNION_TYPE\n+\t      && TREE_CODE (type) != ARRAY_TYPE)))\n+    TYPE_ALIGN (type) = GET_MODE_ALIGNMENT (TYPE_MODE (type));\n+\n+  /* Do machine-dependent extra alignment.  */\n+#ifdef ROUND_TYPE_ALIGN\n+  TYPE_ALIGN (type)\n+    = ROUND_TYPE_ALIGN (type, TYPE_ALIGN (type), BITS_PER_UNIT);\n+#endif\n+\n+#ifdef ROUND_TYPE_SIZE\n+  if (TYPE_SIZE (type) != 0)\n+    TYPE_SIZE (type)\n+      = ROUND_TYPE_SIZE (type, TYPE_SIZE (type), TYPE_ALIGN (type));\n+#endif\n+\n+  /* Evaluate nonconstant size only once, either now or as soon as safe.  */\n+  if (TYPE_SIZE (type) != 0 && TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n+    TYPE_SIZE (type) = variable_size (TYPE_SIZE (type));\n+\n+  /* If we failed to find a simple way to calculate the unit size\n+     of the type above, find it by division.  */\n+  if (TYPE_SIZE_UNIT (type) == 0 && TYPE_SIZE (type) != 0)\n+    /* TYPE_SIZE (type) is computed in bitsizetype.  After the division, the\n+       result will fit in sizetype.  We will get more efficient code using\n+       sizetype, so we force a conversion.  */\n+    TYPE_SIZE_UNIT (type)\n+      = convert (sizetype,\n+\t\t size_binop (FLOOR_DIV_EXPR, TYPE_SIZE (type),\n+\t\t\t     bitsize_int (BITS_PER_UNIT)));\n+\n+  /* Once again evaluate only once, either now or as soon as safe.  */\n+  if (TYPE_SIZE_UNIT (type) != 0\n+      && TREE_CODE (TYPE_SIZE_UNIT (type)) != INTEGER_CST)\n+    TYPE_SIZE_UNIT (type) = variable_size (TYPE_SIZE_UNIT (type));\n+\n+  /* Also layout any other variants of the type.  */\n+  if (TYPE_NEXT_VARIANT (type)\n+      || type != TYPE_MAIN_VARIANT (type))\n+    {\n+      tree variant;\n+      /* Record layout info of this variant.  */\n+      tree size = TYPE_SIZE (type);\n+      tree size_unit = TYPE_SIZE_UNIT (type);\n+      unsigned int align = TYPE_ALIGN (type);\n+      enum machine_mode mode = TYPE_MODE (type);\n+\n+      /* Copy it into all variants.  */\n+      for (variant = TYPE_MAIN_VARIANT (type);\n+\t   variant != 0;\n+\t   variant = TYPE_NEXT_VARIANT (variant))\n+\t{\n+\t  TYPE_SIZE (variant) = size;\n+\t  TYPE_SIZE_UNIT (variant) = size_unit;\n+\t  TYPE_ALIGN (variant) = align;\n+\t  TYPE_MODE (variant) = mode;\n+\t}\n+    }\n+}\n+\n+/* Do all of the work required to layout the type indicated by RLI,\n+   once the fields have been laid out.  This function will call `free'\n+   for RLI.  */\n+\n+void\n+finish_record_layout (rli)\n+     record_layout_info rli;\n+{\n+  /* Compute the final size.  */\n+  finalize_record_size (rli);\n+  /* Compute the TYPE_MODE for the record.  */\n+  compute_record_mode (rli->t);\n+  /* Lay out any static members.  This is done now because their type\n+     may use the record's type.  */\n+  while (rli->pending_statics)\n+    {\n+      layout_decl (TREE_VALUE (rli->pending_statics), 0);\n+      rli->pending_statics = TREE_CHAIN (rli->pending_statics);\n+    }\n+  /* Perform any last tweaks to the TYPE_SIZE, etc.  */\n+  finalize_type_size (rli->t);\n+  /* Clean up.  */\n+  free (rli);\n+}\n+\n \f\n /* Lay out a UNION_TYPE or QUAL_UNION_TYPE type.\n    Lay out all the fields, set their positions to zero,\n@@ -877,7 +1070,6 @@ layout_type (type)\n      tree type;\n {\n   int old;\n-  tree pending_statics;\n \n   if (type == 0)\n     abort ();\n@@ -886,8 +1078,8 @@ layout_type (type)\n   if (TYPE_SIZE (type))\n     return;\n \n-  /* Make sure all nodes we allocate are not momentary;\n-     they must last past the current statement.  */\n+  /* Make sure all nodes we allocate are not momentary; they must last\n+     past the current statement.  */\n   old = suspend_momentary ();\n \n   /* Put all our nodes into the same obstack as the type.  Also,\n@@ -1095,88 +1287,18 @@ layout_type (type)\n       }\n \n     case RECORD_TYPE:\n-      pending_statics = layout_record (type);\n-      TYPE_MODE (type) = BLKmode;\n-      if (TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST)\n-\t{\n-\t  tree field;\n-\t  enum machine_mode mode = VOIDmode;\n-\n-\t  /* A record which has any BLKmode members must itself be BLKmode;\n-\t     it can't go in a register.\n-\t     Unless the member is BLKmode only because it isn't aligned.  */\n-\t  for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n-\t    {\n-\t      unsigned HOST_WIDE_INT bitpos;\n-\n-\t      if (TREE_CODE (field) != FIELD_DECL\n-\t\t  || TREE_CODE (TREE_TYPE (field)) == ERROR_MARK)\n-\t\tcontinue;\n-\n-\t      if (TYPE_MODE (TREE_TYPE (field)) == BLKmode\n-\t\t  && ! TYPE_NO_FORCE_BLK (TREE_TYPE (field)))\n-\t\tgoto record_lose;\n-\n-\t      if (TREE_CODE (DECL_FIELD_BITPOS (field)) != INTEGER_CST)\n-\t\tgoto record_lose;\n-\n-\t      bitpos = TREE_INT_CST_LOW (DECL_FIELD_BITPOS (field));\n-\n-\t      /* Must be BLKmode if any field crosses a word boundary,\n-\t\t since extract_bit_field can't handle that in registers.  */\n-\t      if (bitpos / BITS_PER_WORD\n-\t\t  != ((TREE_INT_CST_LOW (DECL_SIZE (field)) + bitpos - 1)\n-\t\t      / BITS_PER_WORD)\n-\t\t  /* But there is no problem if the field is entire words.  */\n-\t\t  && TREE_INT_CST_LOW (DECL_SIZE (field)) % BITS_PER_WORD != 0)\n-\t\tgoto record_lose;\n-\n-\t      /* If this field is the whole struct, remember its mode so\n-\t\t that, say, we can put a double in a class into a DF\n-\t\t register instead of forcing it to live in the stack.  */\n-\t      if (simple_cst_equal (TYPE_SIZE (type), DECL_SIZE (field)))\n-\t\tmode = DECL_MODE (field);\n-\n-#ifdef STRUCT_FORCE_BLK\n-\t      /* With some targets, eg. c4x, it is sub-optimal\n-\t\t to access an aligned BLKmode structure as a scalar.  */\n-\t      if (mode == VOIDmode && STRUCT_FORCE_BLK (field))\n-\t\t  goto record_lose;\n-#endif /* STRUCT_FORCE_BLK  */\n-\t    }\n-\n-\t  if (mode != VOIDmode)\n-\t    /* We only have one real field; use its mode.  */\n-\t    TYPE_MODE (type) = mode;\n-\t  else\n-\t    TYPE_MODE (type)\n-\t      = mode_for_size_tree (TYPE_SIZE (type), MODE_INT, 1);\n-\n-\t  /* If structure's known alignment is less than\n-\t     what the scalar mode would need, and it matters,\n-\t     then stick with BLKmode.  */\n-\t  if (TYPE_MODE (type) != BLKmode\n-\t      && STRICT_ALIGNMENT\n-\t      && ! (TYPE_ALIGN (type) >= BIGGEST_ALIGNMENT\n-\t\t    || (TYPE_ALIGN (type) >=\n-\t\t\tGET_MODE_ALIGNMENT (TYPE_MODE (type)))))\n-\t    {\n-\t      /* If this is the only reason this type is BLKmode,\n-\t\t then don't force containing types to be BLKmode.  */\n-\t      TYPE_NO_FORCE_BLK (type) = 1;\n-\t      TYPE_MODE (type) = BLKmode;\n-\t    }\n-\n-\trecord_lose: ;\n-\t}\n-\n-      /* Lay out any static members.  This is done now\n-\t because their type may use the record's type.  */\n-      while (pending_statics)\n-\t{\n-\t  layout_decl (TREE_VALUE (pending_statics), 0);\n-\t  pending_statics = TREE_CHAIN (pending_statics);\n-\t}\n+      {\n+\ttree field;\n+\trecord_layout_info rli;\n+\n+\t/* Initialize the layout information.  */\n+\trli = new_record_layout_info (type);\n+\t/* Layout all the fields.  */\n+\tfor (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))\n+\t  layout_field (rli, field);\n+\t/* Finish laying out the record.  */\n+\tfinish_record_layout (rli);\n+      }\n       break;\n \n     case UNION_TYPE:\n@@ -1253,73 +1375,11 @@ layout_type (type)\n       abort ();\n     }\n \n-  /* Normally, use the alignment corresponding to the mode chosen.\n-     However, where strict alignment is not required, avoid\n-     over-aligning structures, since most compilers do not do this\n-     alignment.  */\n-\n-  if (TYPE_MODE (type) != BLKmode && TYPE_MODE (type) != VOIDmode\n-      && (STRICT_ALIGNMENT\n-\t  || (TREE_CODE (type) != RECORD_TYPE && TREE_CODE (type) != UNION_TYPE\n-\t      && TREE_CODE (type) != QUAL_UNION_TYPE\n-\t      && TREE_CODE (type) != ARRAY_TYPE)))\n-    TYPE_ALIGN (type) = GET_MODE_ALIGNMENT (TYPE_MODE (type));\n+  /* Compute the final TYPE_SIZE, TYPE_ALIGN, etc. for TYPE.  For\n+     RECORD_TYPEs, finish_record_layout already called this function.  */\n+  if (TREE_CODE (type) != RECORD_TYPE)\n+    finalize_type_size (type);\n \n-  /* Do machine-dependent extra alignment.  */\n-#ifdef ROUND_TYPE_ALIGN\n-  TYPE_ALIGN (type)\n-    = ROUND_TYPE_ALIGN (type, TYPE_ALIGN (type), BITS_PER_UNIT);\n-#endif\n-\n-#ifdef ROUND_TYPE_SIZE\n-  if (TYPE_SIZE (type) != 0)\n-    TYPE_SIZE (type)\n-      = ROUND_TYPE_SIZE (type, TYPE_SIZE (type), TYPE_ALIGN (type));\n-#endif\n-\n-  /* Evaluate nonconstant size only once, either now or as soon as safe.  */\n-  if (TYPE_SIZE (type) != 0 && TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)\n-    TYPE_SIZE (type) = variable_size (TYPE_SIZE (type));\n-\n-  /* If we failed to find a simple way to calculate the unit size\n-     of the type above, find it by division.  */\n-  if (TYPE_SIZE_UNIT (type) == 0 && TYPE_SIZE (type) != 0)\n-    /* TYPE_SIZE (type) is computed in bitsizetype.  After the division, the\n-       result will fit in sizetype.  We will get more efficient code using\n-       sizetype, so we force a conversion.  */\n-    TYPE_SIZE_UNIT (type)\n-      = convert (sizetype,\n-\t\t size_binop (FLOOR_DIV_EXPR, TYPE_SIZE (type),\n-\t\t\t     bitsize_int (BITS_PER_UNIT)));\n-\n-  /* Once again evaluate only once, either now or as soon as safe.  */\n-  if (TYPE_SIZE_UNIT (type) != 0\n-      && TREE_CODE (TYPE_SIZE_UNIT (type)) != INTEGER_CST)\n-    TYPE_SIZE_UNIT (type) = variable_size (TYPE_SIZE_UNIT (type));\n-\n-  /* Also layout any other variants of the type.  */\n-  if (TYPE_NEXT_VARIANT (type)\n-      || type != TYPE_MAIN_VARIANT (type))\n-    {\n-      tree variant;\n-      /* Record layout info of this variant.  */\n-      tree size = TYPE_SIZE (type);\n-      tree size_unit = TYPE_SIZE_UNIT (type);\n-      unsigned int align = TYPE_ALIGN (type);\n-      enum machine_mode mode = TYPE_MODE (type);\n-\n-      /* Copy it into all variants.  */\n-      for (variant = TYPE_MAIN_VARIANT (type);\n-\t   variant != 0;\n-\t   variant = TYPE_NEXT_VARIANT (variant))\n-\t{\n-\t  TYPE_SIZE (variant) = size;\n-\t  TYPE_SIZE_UNIT (variant) = size_unit;\n-\t  TYPE_ALIGN (variant) = align;\n-\t  TYPE_MODE (variant) = mode;\n-\t}\n-    }\n-\t\n   pop_obstacks ();\n   resume_momentary (old);\n "}, {"sha": "faa4a907d1af7ecfc46970856d53a2c125148d51", "filename": "gcc/tree.h", "status": "modified", "additions": 37, "deletions": 3, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9328904cdf4c4f74be2b74f23b959df0b51c7b40/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9328904cdf4c4f74be2b74f23b959df0b51c7b40/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=9328904cdf4c4f74be2b74f23b959df0b51c7b40", "patch": "@@ -1776,12 +1776,46 @@ extern tree build_qualified_type        PARAMS ((tree, int));\n extern tree build_type_copy\t\tPARAMS ((tree));\n \n /* Given a ..._TYPE node, calculate the TYPE_SIZE, TYPE_SIZE_UNIT,\n-   TYPE_ALIGN and TYPE_MODE fields.\n-   If called more than once on one node, does nothing except\n-   for the first time.  */\n+   TYPE_ALIGN and TYPE_MODE fields.  If called more than once on one\n+   node, does nothing except for the first time.  */\n \n extern void layout_type\t\t\tPARAMS ((tree));\n \n+/* These functions allow a front-end to perform a manual layout of a\n+   RECORD_TYPE.  (For instance, if the placement of subsequent fields\n+   depends on the placement of fields so far.)  Begin by calling\n+   new_record_layout_info.  Then, call layout_field for each of the\n+   fields.  Then, call finish_record_layout.  See layout_type for the\n+   default way in which these functions are used.  */\n+\n+struct record_layout_info_s\n+{\n+  /* The RECORD_TYPE that we are laying out.  */\n+  tree t;\n+  /* The size of the record so far, in bits.  */\n+  unsigned HOST_WIDE_INT const_size;\n+  /* The alignment of the record so far, in bits.  */\n+  unsigned int record_align;\n+  /* If the record can have a variable size, then this will be\n+     non-NULL, and the total size will be CONST_SIZE + VAR_SIZE.  */\n+  tree var_size;\n+  /* If the record can have a variable size, then this will be the\n+     maximum alignment that we know VAR_SIZE has.  */\n+  unsigned int var_align;\n+  /* The static variables (i.e., class variables, as opposed to\n+     instance variables) encountered in T.  */\n+  tree pending_statics;\n+  unsigned int unpacked_align;\n+  int packed_maybe_necessary;\n+};\n+\n+typedef struct record_layout_info_s *record_layout_info;\n+\n+extern record_layout_info new_record_layout_info \n+                                        PARAMS ((tree));\n+extern void layout_field                PARAMS ((record_layout_info, tree));\n+extern void finish_record_layout        PARAMS ((record_layout_info));\n+\n /* Given a hashcode and a ..._TYPE node (for which the hashcode was made),\n    return a canonicalized ..._TYPE node, so that duplicates are not made.\n    How the hash code is computed is up to the caller, as long as any two"}]}