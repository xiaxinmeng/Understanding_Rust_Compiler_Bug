{"sha": "1282988ba15337f21a940cd5d1c0b34a62378a2f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTI4Mjk4OGJhMTUzMzdmMjFhOTQwY2Q1ZDFjMGIzNGE2MjM3OGEyZg==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-03-26T16:08:30Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-03-26T16:08:30Z"}, "message": "aarch64: Add vector costs for SVE CLAST[AB] and FADDA\n\nFollowing on from the previous reduction costs patch, this one\nadds costs for the SVE CLAST[AB] and FADDA instructions.\nThese instructions occur within the loop body, whereas the\nreductions handled by the previous patch occur outside.\n\nLike with the previous patch, this one only becomes active if\na CPU selects use_new_vector_costs.  It should therefore have\na very low impact on other CPUs.\n\ngcc/\n\t* config/aarch64/aarch64-protos.h (sve_vec_cost): Turn into a\n\tderived class of simd_vec_cost.  Add information about CLAST[AB]\n\tand FADDA instructions.\n\t* config/aarch64/aarch64.c (generic_sve_vector_cost): Update\n\taccordingly, using the vec_to_scalar costs for the new fields.\n\t(a64fx_sve_vector_cost): Likewise.\n\t(aarch64_reduc_type): New function.\n\t(aarch64_sve_in_loop_reduction_latency): Likewise.\n\t(aarch64_detect_vector_stmt_subtype): Take a vinfo parameter.\n\tUse aarch64_sve_in_loop_reduction_latency to handle SVE reductions\n\tthat occur in the loop body.\n\t(aarch64_add_stmt_cost): Update call accordingly.", "tree": {"sha": "febb0bfa72bc81fd50d2b34b7761ceb27ecbad7d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/febb0bfa72bc81fd50d2b34b7761ceb27ecbad7d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1282988ba15337f21a940cd5d1c0b34a62378a2f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1282988ba15337f21a940cd5d1c0b34a62378a2f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1282988ba15337f21a940cd5d1c0b34a62378a2f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1282988ba15337f21a940cd5d1c0b34a62378a2f/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e253bb8b796dbf88a2650e350a040cd0e0df41cd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e253bb8b796dbf88a2650e350a040cd0e0df41cd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e253bb8b796dbf88a2650e350a040cd0e0df41cd"}], "stats": {"total": 178, "additions": 141, "deletions": 37}, "files": [{"sha": "bfcab72b122e07265aabbe946cbedc2292093c13", "filename": "gcc/config/aarch64/aarch64-protos.h", "status": "modified", "additions": 27, "deletions": 1, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1282988ba15337f21a940cd5d1c0b34a62378a2f/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1282988ba15337f21a940cd5d1c0b34a62378a2f/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h?ref=1282988ba15337f21a940cd5d1c0b34a62378a2f", "patch": "@@ -237,7 +237,33 @@ struct simd_vec_cost\n };\n \n typedef struct simd_vec_cost advsimd_vec_cost;\n-typedef struct simd_vec_cost sve_vec_cost;\n+\n+/* SVE-specific extensions to the information provided by simd_vec_cost.  */\n+struct sve_vec_cost : simd_vec_cost\n+{\n+  constexpr sve_vec_cost (const simd_vec_cost &base,\n+\t\t\t  unsigned int clast_cost,\n+\t\t\t  unsigned int fadda_f16_cost,\n+\t\t\t  unsigned int fadda_f32_cost,\n+\t\t\t  unsigned int fadda_f64_cost)\n+    : simd_vec_cost (base),\n+      clast_cost (clast_cost),\n+      fadda_f16_cost (fadda_f16_cost),\n+      fadda_f32_cost (fadda_f32_cost),\n+      fadda_f64_cost (fadda_f64_cost)\n+  {}\n+\n+  /* The cost of a vector-to-scalar CLASTA or CLASTB instruction,\n+     with the scalar being stored in FP registers.  This cost is\n+     assumed to be a cycle latency.  */\n+  const int clast_cost;\n+\n+  /* The costs of FADDA for the three data types that it supports.\n+     These costs are assumed to be cycle latencies.  */\n+  const int fadda_f16_cost;\n+  const int fadda_f32_cost;\n+  const int fadda_f64_cost;\n+};\n \n /* Cost for vector insn classes.  */\n struct cpu_vector_cost"}, {"sha": "b62169a267a7502ac07687603b5acb2feaeaff69", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 114, "deletions": 36, "changes": 150, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1282988ba15337f21a940cd5d1c0b34a62378a2f/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1282988ba15337f21a940cd5d1c0b34a62378a2f/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=1282988ba15337f21a940cd5d1c0b34a62378a2f", "patch": "@@ -609,22 +609,28 @@ static const advsimd_vec_cost generic_advsimd_vector_cost =\n /* Generic costs for SVE vector operations.  */\n static const sve_vec_cost generic_sve_vector_cost =\n {\n-  1, /* int_stmt_cost  */\n-  1, /* fp_stmt_cost  */\n-  2, /* permute_cost  */\n-  2, /* reduc_i8_cost  */\n-  2, /* reduc_i16_cost  */\n-  2, /* reduc_i32_cost  */\n-  2, /* reduc_i64_cost  */\n-  2, /* reduc_f16_cost  */\n-  2, /* reduc_f32_cost  */\n-  2, /* reduc_f64_cost  */\n-  2, /* vec_to_scalar_cost  */\n-  1, /* scalar_to_vec_cost  */\n-  1, /* align_load_cost  */\n-  1, /* unalign_load_cost  */\n-  1, /* unalign_store_cost  */\n-  1  /* store_cost  */\n+  {\n+    1, /* int_stmt_cost  */\n+    1, /* fp_stmt_cost  */\n+    2, /* permute_cost  */\n+    2, /* reduc_i8_cost  */\n+    2, /* reduc_i16_cost  */\n+    2, /* reduc_i32_cost  */\n+    2, /* reduc_i64_cost  */\n+    2, /* reduc_f16_cost  */\n+    2, /* reduc_f32_cost  */\n+    2, /* reduc_f64_cost  */\n+    2, /* vec_to_scalar_cost  */\n+    1, /* scalar_to_vec_cost  */\n+    1, /* align_load_cost  */\n+    1, /* unalign_load_cost  */\n+    1, /* unalign_store_cost  */\n+    1  /* store_cost  */\n+  },\n+  2, /* clast_cost  */\n+  2, /* fadda_f16_cost  */\n+  2, /* fadda_f32_cost  */\n+  2 /* fadda_f64_cost  */\n };\n \n /* Generic costs for vector insn classes.  */\n@@ -662,22 +668,28 @@ static const advsimd_vec_cost a64fx_advsimd_vector_cost =\n \n static const sve_vec_cost a64fx_sve_vector_cost =\n {\n-  2, /* int_stmt_cost  */\n-  5, /* fp_stmt_cost  */\n-  3, /* permute_cost  */\n-  13, /* reduc_i8_cost  */\n-  13, /* reduc_i16_cost  */\n-  13, /* reduc_i32_cost  */\n-  13, /* reduc_i64_cost  */\n-  13, /* reduc_f16_cost  */\n-  13, /* reduc_f32_cost  */\n-  13, /* reduc_f64_cost  */\n-  13, /* vec_to_scalar_cost  */\n-  4, /* scalar_to_vec_cost  */\n-  6, /* align_load_cost  */\n-  6, /* unalign_load_cost  */\n-  1, /* unalign_store_cost  */\n-  1  /* store_cost  */\n+  {\n+    2, /* int_stmt_cost  */\n+    5, /* fp_stmt_cost  */\n+    3, /* permute_cost  */\n+    13, /* reduc_i8_cost  */\n+    13, /* reduc_i16_cost  */\n+    13, /* reduc_i32_cost  */\n+    13, /* reduc_i64_cost  */\n+    13, /* reduc_f16_cost  */\n+    13, /* reduc_f32_cost  */\n+    13, /* reduc_f64_cost  */\n+    13, /* vec_to_scalar_cost  */\n+    4, /* scalar_to_vec_cost  */\n+    6, /* align_load_cost  */\n+    6, /* unalign_load_cost  */\n+    1, /* unalign_store_cost  */\n+    1  /* store_cost  */\n+  },\n+  13, /* clast_cost  */\n+  13, /* fadda_f16_cost  */\n+  13, /* fadda_f32_cost  */\n+  13 /* fadda_f64_cost  */\n };\n \n static const struct cpu_vector_cost a64fx_vector_cost =\n@@ -14060,6 +14072,20 @@ aarch64_is_reduction (stmt_vec_info stmt_info)\n \t  || VECTORIZABLE_CYCLE_DEF (STMT_VINFO_DEF_TYPE (stmt_info)));\n }\n \n+/* If STMT_INFO describes a reduction, return the type of reduction\n+   it describes, otherwise return -1.  */\n+static int\n+aarch64_reduc_type (vec_info *vinfo, stmt_vec_info stmt_info)\n+{\n+  if (loop_vec_info loop_vinfo = dyn_cast<loop_vec_info> (vinfo))\n+    if (STMT_VINFO_REDUC_DEF (stmt_info))\n+      {\n+\tstmt_vec_info reduc_info = info_for_reduction (loop_vinfo, stmt_info);\n+\treturn int (STMT_VINFO_REDUC_TYPE (reduc_info));\n+      }\n+  return -1;\n+}\n+\n /* Return true if creating multiple copies of STMT_INFO for Advanced SIMD\n    vectors would produce a series of LDP or STP operations.  KIND is the\n    kind of statement that STMT_INFO represents.  */\n@@ -14123,19 +14149,71 @@ aarch64_integer_truncation_p (stmt_vec_info stmt_info)\n \t  && TYPE_PRECISION (lhs_type) < TYPE_PRECISION (rhs_type));\n }\n \n+/* We are considering implementing STMT_INFO using SVE vector type VECTYPE.\n+   If STMT_INFO is an in-loop reduction that SVE supports directly, return\n+   its latency in cycles, otherwise return zero.  SVE_COSTS specifies the\n+   latencies of the relevant instructions.  */\n+static unsigned int\n+aarch64_sve_in_loop_reduction_latency (vec_info *vinfo,\n+\t\t\t\t       stmt_vec_info stmt_info,\n+\t\t\t\t       tree vectype,\n+\t\t\t\t       const sve_vec_cost *sve_costs)\n+{\n+  switch (aarch64_reduc_type (vinfo, stmt_info))\n+    {\n+    case EXTRACT_LAST_REDUCTION:\n+      return sve_costs->clast_cost;\n+\n+    case FOLD_LEFT_REDUCTION:\n+      switch (GET_MODE_INNER (TYPE_MODE (vectype)))\n+\t{\n+\tcase E_HFmode:\n+\tcase E_BFmode:\n+\t  return sve_costs->fadda_f16_cost;\n+\n+\tcase E_SFmode:\n+\t  return sve_costs->fadda_f32_cost;\n+\n+\tcase E_DFmode:\n+\t  return sve_costs->fadda_f64_cost;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+      break;\n+    }\n+\n+  return 0;\n+}\n+\n /* STMT_COST is the cost calculated by aarch64_builtin_vectorization_cost\n    for the vectorized form of STMT_INFO, which has cost kind KIND and which\n    when vectorized would operate on vector type VECTYPE.  Try to subdivide\n    the target-independent categorization provided by KIND to get a more\n    accurate cost.  WHERE specifies where the cost associated with KIND\n    occurs.  */\n static unsigned int\n-aarch64_detect_vector_stmt_subtype (vect_cost_for_stmt kind,\n+aarch64_detect_vector_stmt_subtype (vec_info *vinfo, vect_cost_for_stmt kind,\n \t\t\t\t    stmt_vec_info stmt_info, tree vectype,\n \t\t\t\t    enum vect_cost_model_location where,\n \t\t\t\t    unsigned int stmt_cost)\n {\n   const simd_vec_cost *simd_costs = aarch64_simd_vec_costs (vectype);\n+  const sve_vec_cost *sve_costs = nullptr;\n+  if (aarch64_sve_mode_p (TYPE_MODE (vectype)))\n+    sve_costs = aarch64_tune_params.vec_costs->sve;\n+\n+  /* Detect cases in which vec_to_scalar represents an in-loop reduction.  */\n+  if (kind == vec_to_scalar\n+      && where == vect_body\n+      && sve_costs)\n+    {\n+      unsigned int latency\n+\t= aarch64_sve_in_loop_reduction_latency (vinfo, stmt_info, vectype,\n+\t\t\t\t\t\t sve_costs);\n+      if (latency)\n+\treturn latency;\n+    }\n \n   /* Detect cases in which vec_to_scalar represents a single reduction\n      instruction like FADDP or MAXV.  */\n@@ -14260,9 +14338,9 @@ aarch64_add_stmt_cost (class vec_info *vinfo, void *data, int count,\n       /* Try to get a more accurate cost by looking at STMT_INFO instead\n \t of just looking at KIND.  */\n       if (stmt_info && vectype && aarch64_use_new_vector_costs_p ())\n-\tstmt_cost = aarch64_detect_vector_stmt_subtype (kind, stmt_info,\n-\t\t\t\t\t\t\tvectype, where,\n-\t\t\t\t\t\t\tstmt_cost);\n+\tstmt_cost = aarch64_detect_vector_stmt_subtype (vinfo, kind,\n+\t\t\t\t\t\t\tstmt_info, vectype,\n+\t\t\t\t\t\t\twhere, stmt_cost);\n \n       /* Do any SVE-specific adjustments to the cost.  */\n       if (stmt_info && vectype && aarch64_sve_mode_p (TYPE_MODE (vectype)))"}]}