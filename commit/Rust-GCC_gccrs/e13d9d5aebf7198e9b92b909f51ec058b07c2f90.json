{"sha": "e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTEzZDlkNWFlYmY3MTk4ZTliOTJiOTA5ZjUxZWMwNThiMDdjMmY5MA==", "commit": {"author": {"name": "Georg-Johann Lay", "email": "avr@gjlay.de", "date": "2012-11-22T10:00:13Z"}, "committer": {"name": "Georg-Johann Lay", "email": "gjl@gcc.gnu.org", "date": "2012-11-22T10:00:13Z"}, "message": "Adjust decimal point of signed accum mode to GCC default.\n\nlibgcc/\n\tAdjust decimal point of signed accum mode to GCC default.\n\n\tPR target/54222\n\t* config/avr/t-avr (LIB1ASMFUNCS): Add _fractsfsq _fractsfusq,\n\t_divqq_helper.\n\t* config/avr/lib1funcs-fixed.S (__fractqqsf, __fracthqsf)\n\t(__fractsasf, __fractsfha, __fractusqsf, __fractsfsa)\n\t(__mulha3, __mulsa3)\n\t(__divqq3, __divha3, __divsa3): Adjust to new position of\n\tdecimal point of signed accum types. \n\t\n\t(__mulusa3_round): New function.\n\t(__mulusa3): Use it.\n\t(__divqq_helper): New function.\n\t(__udivuqq3): Use it.\n\ngcc/\n\tAdjust decimal point of signed accum mode to GCC default.\n\n\tPR target/54222\n\t* config/avr/avr-modes.def (HA, SA, DA): Remove mode adjustments.\n\t(TA): Move decimal point one bit to the right.\n\t* config/avr/avr.c (avr_out_fract): Rewrite.\n\nFrom-SVN: r193721", "tree": {"sha": "eabc8ea539916ca2cfbd3ccf1d3efabdd0791b90", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/eabc8ea539916ca2cfbd3ccf1d3efabdd0791b90"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/comments", "author": null, "committer": {"login": "sprintersb", "id": 8905355, "node_id": "MDQ6VXNlcjg5MDUzNTU=", "avatar_url": "https://avatars.githubusercontent.com/u/8905355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sprintersb", "html_url": "https://github.com/sprintersb", "followers_url": "https://api.github.com/users/sprintersb/followers", "following_url": "https://api.github.com/users/sprintersb/following{/other_user}", "gists_url": "https://api.github.com/users/sprintersb/gists{/gist_id}", "starred_url": "https://api.github.com/users/sprintersb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sprintersb/subscriptions", "organizations_url": "https://api.github.com/users/sprintersb/orgs", "repos_url": "https://api.github.com/users/sprintersb/repos", "events_url": "https://api.github.com/users/sprintersb/events{/privacy}", "received_events_url": "https://api.github.com/users/sprintersb/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5eb4cb476809652a10652ff9577fb7ede71b80e5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5eb4cb476809652a10652ff9577fb7ede71b80e5", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5eb4cb476809652a10652ff9577fb7ede71b80e5"}], "stats": {"total": 915, "additions": 499, "deletions": 416}, "files": [{"sha": "bad8461fa0cda4770d15d2b4c83d9bf6a8d1f162", "filename": "gcc/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "patch": "@@ -1,3 +1,12 @@\n+2012-11-22  Georg-Johann Lay  <avr@gjlay.de>\n+\n+\tAdjust decimal point of signed accum mode to GCC default.\n+\n+\tPR target/54222\n+\t* config/avr/avr-modes.def (HA, SA, DA): Remove mode adjustments.\n+\t(TA): Move decimal point one bit to the right.\n+\t* config/avr/avr.c (avr_out_fract): Rewrite.\n+\n 2012-11-21  Matthias Klose  <doko@ubuntu.com>\n \n \t* config/alpha/t-linux: New file; define MULTIARCH_DIRNAME."}, {"sha": "04268cdf5b3a03be81dca90845539da322d4e541", "filename": "gcc/config/avr/avr-modes.def", "status": "modified", "additions": 2, "deletions": 15, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/gcc%2Fconfig%2Favr%2Favr-modes.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/gcc%2Fconfig%2Favr%2Favr-modes.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Favr%2Favr-modes.def?ref=e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "patch": "@@ -1,26 +1,13 @@\n FRACTIONAL_INT_MODE (PSI, 24, 3);\n \n-/* On 8 bit machines it requires fewer instructions for fixed point\n-   routines if the decimal place is on a byte boundary which is not\n-   the default for signed accum types.  */\n-\n-ADJUST_IBIT (HA, 7);\n-ADJUST_FBIT (HA, 8);\n-\n-ADJUST_IBIT (SA, 15);\n-ADJUST_FBIT (SA, 16);\n-\n-ADJUST_IBIT (DA, 31);\n-ADJUST_FBIT (DA, 32);\n-\n /* Make TA and UTA 64 bits wide.\n    128 bit wide modes would be insane on a 8-bit machine.\n    This needs special treatment in avr.c and avr-lib.h.  */\n \n ADJUST_BYTESIZE  (TA, 8);\n ADJUST_ALIGNMENT (TA, 1);\n-ADJUST_IBIT (TA, 15);\n-ADJUST_FBIT (TA, 48);\n+ADJUST_IBIT (TA, 16);\n+ADJUST_FBIT (TA, 47);\n \n ADJUST_BYTESIZE  (UTA, 8);\n ADJUST_ALIGNMENT (UTA, 1);"}, {"sha": "cc0290475cd3f5cf9d2500556e5922ff3d486ad7", "filename": "gcc/config/avr/avr.c", "status": "modified", "additions": 326, "deletions": 342, "changes": 668, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/gcc%2Fconfig%2Favr%2Favr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/gcc%2Fconfig%2Favr%2Favr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Favr%2Favr.c?ref=e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "patch": "@@ -6974,6 +6974,332 @@ avr_out_addto_sp (rtx *op, int *plen)\n }\n \n \n+/* Outputs instructions needed for fixed point type conversion.\n+   This includes converting between any fixed point type, as well\n+   as converting to any integer type.  Conversion between integer\n+   types is not supported.\n+\n+   Converting signed fractional types requires a bit shift if converting\n+   to or from any unsigned fractional type because the decimal place is\n+   shifted by 1 bit.  When the destination is a signed fractional, the sign\n+   is stored in either the carry or T bit.  */\n+\n+const char*\n+avr_out_fract (rtx insn, rtx operands[], bool intsigned, int *plen)\n+{\n+  size_t i;\n+  rtx xop[6];\n+  RTX_CODE shift = UNKNOWN;\n+  bool sign_in_carry = false;\n+  bool msb_in_carry = false;\n+  bool lsb_in_carry = false;\n+  const char *code_ashift = \"lsl %0\";\n+\n+  \n+#define MAY_CLOBBER(RR)                                                 \\\n+  /* Shorthand used below.  */                                          \\\n+  ((sign_bytes                                                          \\\n+    && IN_RANGE (RR, dest.regno_msb - sign_bytes + 1, dest.regno_msb))  \\\n+   || (reg_unused_after (insn, all_regs_rtx[RR])                        \\\n+       && !IN_RANGE (RR, dest.regno, dest.regno_msb)))\n+\n+  struct\n+  {\n+    /* bytes       : Length of operand in bytes.\n+       ibyte       : Length of integral part in bytes.\n+       fbyte, fbit : Length of fractional part in bytes, bits.  */\n+\n+    bool sbit;\n+    unsigned fbit, bytes, ibyte, fbyte;\n+    unsigned regno, regno_msb;\n+  } dest, src, *val[2] = { &dest, &src };\n+\n+  if (plen)\n+    *plen = 0;\n+\n+  /* Step 0:  Determine information on source and destination operand we\n+     ======   will need in the remainder.  */\n+\n+  for (i = 0; i < sizeof (val) / sizeof (*val); i++)\n+    {\n+      enum machine_mode mode;\n+\n+      xop[i] = operands[i];\n+\n+      mode = GET_MODE (xop[i]);\n+\n+      val[i]->bytes = GET_MODE_SIZE (mode);\n+      val[i]->regno = REGNO (xop[i]);\n+      val[i]->regno_msb = REGNO (xop[i]) + val[i]->bytes - 1;\n+\n+      if (SCALAR_INT_MODE_P (mode))\n+        {\n+          val[i]->sbit = intsigned;\n+          val[i]->fbit = 0;\n+        }\n+      else if (ALL_SCALAR_FIXED_POINT_MODE_P (mode))\n+        {\n+          val[i]->sbit = SIGNED_SCALAR_FIXED_POINT_MODE_P (mode);\n+          val[i]->fbit = GET_MODE_FBIT (mode);\n+        }\n+      else\n+        fatal_insn (\"unsupported fixed-point conversion\", insn);\n+\n+      val[i]->fbyte = (1 + val[i]->fbit) / BITS_PER_UNIT;\n+      val[i]->ibyte = val[i]->bytes - val[i]->fbyte;\n+    }\n+\n+  // Byte offset of the decimal point taking into account different place\n+  // of the decimal point in input and output and different register numbers\n+  // of input and output.\n+  int offset = dest.regno - src.regno + dest.fbyte - src.fbyte;\n+\n+  // Number of destination bytes that will come from sign / zero extension.\n+  int sign_bytes = (dest.ibyte - src.ibyte) * (dest.ibyte > src.ibyte);\n+\n+  // Number of bytes at the low end to be filled with zeros.\n+  int zero_bytes = (dest.fbyte - src.fbyte) * (dest.fbyte > src.fbyte);\n+\n+  // Do we have a 16-Bit register that is cleared?\n+  rtx clrw = NULL_RTX;\n+      \n+  bool sign_extend = src.sbit && sign_bytes;\n+\n+  if (0 == dest.fbit % 8 && 7 == src.fbit % 8)\n+    shift = ASHIFT;\n+  else if (7 == dest.fbit % 8 && 0 == src.fbit % 8)\n+    shift = ASHIFTRT;\n+  else if (dest.fbit % 8 == src.fbit % 8)\n+    shift = UNKNOWN;\n+  else\n+    gcc_unreachable();\n+\n+  /* Step 1:  Clear bytes at the low end and copy payload bits from source\n+     ======   to destination.  */\n+\n+  int step = offset < 0 ? 1 : -1;\n+  unsigned d0 = offset < 0 ? dest.regno : dest.regno_msb;\n+\n+  // We leared at least that number of registers.\n+  int clr_n = 0;\n+\n+  for (; d0 >= dest.regno && d0 <= dest.regno_msb; d0 += step)\n+    {\n+      // Next regno of destination is needed for MOVW\n+      unsigned d1 = d0 + step;\n+\n+      // Current and next regno of source\n+      unsigned s0 = d0 - offset;\n+      unsigned s1 = s0 + step;\n+\n+      // Must current resp. next regno be CLRed?  This applies to the low\n+      // bytes of the destination that have no associated source bytes.\n+      bool clr0 = s0 < src.regno;\n+      bool clr1 = s1 < src.regno && d1 >= dest.regno;\n+\n+      // First gather what code to emit (if any) and additional step to\n+      // apply if a MOVW is in use.  xop[2] is destination rtx and xop[3]\n+      // is the source rtx for the current loop iteration.\n+      const char *code = NULL;\n+      int stepw = 0;\n+      \n+      if (clr0)\n+        {\n+          if (AVR_HAVE_MOVW && clr1 && clrw)\n+            {\n+              xop[2] = all_regs_rtx[d0 & ~1];\n+              xop[3] = clrw;\n+              code = \"movw %2,%3\";\n+              stepw = step;\n+            }\n+          else\n+            {\n+              xop[2] = all_regs_rtx[d0];\n+              code = \"clr %2\";\n+\n+              if (++clr_n >= 2\n+                  && !clrw\n+                  && d0 % 2 == (step > 0))\n+                {\n+                  clrw = all_regs_rtx[d0 & ~1];\n+                }\n+            }\n+        }\n+      else if (offset && s0 <= src.regno_msb)\n+        {\n+          int movw = AVR_HAVE_MOVW && offset % 2 == 0\n+            && d0 % 2 == (offset > 0)\n+            && d1 <= dest.regno_msb && d1 >= dest.regno\n+            && s1 <= src.regno_msb  && s1 >= src.regno;\n+\n+          xop[2] = all_regs_rtx[d0 & ~movw];\n+          xop[3] = all_regs_rtx[s0 & ~movw];\n+          code = movw ? \"movw %2,%3\" : \"mov %2,%3\";\n+          stepw = step * movw;\n+        }\n+\n+      if (code)\n+        {\n+          if (sign_extend && shift != ASHIFT && !sign_in_carry\n+              && (d0 == src.regno_msb || d0 + stepw == src.regno_msb))\n+            {\n+              /* We are going to override the sign bit.  If we sign-extend,\n+                 store the sign in the Carry flag.  This is not needed if\n+                 the destination will be ASHIFT is the remainder because\n+                 the ASHIFT will set Carry without extra instruction.  */\n+\n+              avr_asm_len (\"lsl %0\", &all_regs_rtx[src.regno_msb], plen, 1);\n+              sign_in_carry = true;\n+            }\n+\n+          unsigned src_msb = dest.regno_msb - sign_bytes - offset + 1;\n+\n+          if (!sign_extend && shift == ASHIFTRT && !msb_in_carry\n+              && src.ibyte > dest.ibyte\n+              && (d0 == src_msb || d0 + stepw == src_msb))\n+            {\n+              /* We are going to override the MSB.  If we shift right,\n+                 store the MSB in the Carry flag.  This is only needed if\n+                 we don't sign-extend becaue with sign-extension the MSB\n+                 (the sign) will be produced by the sign extension.  */\n+\n+              avr_asm_len (\"lsr %0\", &all_regs_rtx[src_msb], plen, 1);\n+              msb_in_carry = true;\n+            }\n+\n+          unsigned src_lsb = dest.regno - offset -1;\n+\n+          if (shift == ASHIFT && src.fbyte > dest.fbyte && !lsb_in_carry\n+              && (d0 == src_lsb || d0 + stepw == src_lsb))\n+            {\n+              /* We are going to override the new LSB; store it into carry.  */\n+\n+              avr_asm_len (\"lsl %0\", &all_regs_rtx[src_lsb], plen, 1);\n+              code_ashift = \"rol %0\";\n+              lsb_in_carry = true;\n+            }\n+\n+          avr_asm_len (code, xop, plen, 1);\n+          d0 += stepw;\n+        }\n+    }\n+\n+  /* Step 2:  Shift destination left by 1 bit position.  This might be needed\n+     ======   for signed input and unsigned output.  */\n+\n+  if (shift == ASHIFT && src.fbyte > dest.fbyte && !lsb_in_carry)\n+    {\n+      unsigned s0 = dest.regno - offset -1;\n+\n+      if (MAY_CLOBBER (s0))\n+        avr_asm_len (\"lsl %0\", &all_regs_rtx[s0], plen, 1);\n+      else\n+        avr_asm_len (\"mov __tmp_reg__,%0\" CR_TAB\n+                     \"lsl __tmp_reg__\", &all_regs_rtx[s0], plen, 2);\n+\n+      code_ashift = \"rol %0\";\n+      lsb_in_carry = true;\n+    }\n+\n+  if (shift == ASHIFT)\n+    {\n+      for (d0 = dest.regno + zero_bytes;\n+           d0 <= dest.regno_msb - sign_bytes; d0++)\n+        {\n+          avr_asm_len (code_ashift, &all_regs_rtx[d0], plen, 1);\n+          code_ashift = \"rol %0\";\n+        }\n+\n+      lsb_in_carry = false;\n+      sign_in_carry = true;\n+    }\n+\n+  /* Step 4a:  Store MSB in carry if we don't already have it or will produce\n+     =======   it in sign-extension below.  */\n+\n+  if (!sign_extend && shift == ASHIFTRT && !msb_in_carry\n+      && src.ibyte > dest.ibyte)\n+    {\n+      unsigned s0 = dest.regno_msb - sign_bytes - offset + 1;\n+\n+      if (MAY_CLOBBER (s0))\n+        avr_asm_len (\"lsr %0\", &all_regs_rtx[s0], plen, 1);\n+      else\n+        avr_asm_len (\"mov __tmp_reg__,%0\" CR_TAB\n+                     \"lsr __tmp_reg__\", &all_regs_rtx[s0], plen, 2);\n+\n+      msb_in_carry = true;\n+    }\n+\n+  /* Step 3:  Sign-extend or zero-extend the destination as needed.\n+     ======   */\n+\n+  if (sign_extend && !sign_in_carry)\n+    {\n+      unsigned s0 = src.regno_msb;\n+      \n+      if (MAY_CLOBBER (s0))\n+        avr_asm_len (\"lsl %0\", &all_regs_rtx[s0], plen, 1);\n+      else\n+        avr_asm_len (\"mov __tmp_reg__,%0\" CR_TAB\n+                     \"lsl __tmp_reg__\", &all_regs_rtx[s0], plen, 2);\n+\n+      sign_in_carry = true;\n+  }\n+\n+  gcc_assert (sign_in_carry + msb_in_carry + lsb_in_carry <= 1);\n+\n+  unsigned copies = 0;\n+  rtx movw = sign_extend ? NULL_RTX : clrw;\n+\n+  for (d0 = dest.regno_msb - sign_bytes + 1; d0 <= dest.regno_msb; d0++)\n+    {\n+      if (AVR_HAVE_MOVW && movw\n+          && d0 % 2 == 0 && d0 + 1 <= dest.regno_msb)\n+        {\n+          xop[2] = all_regs_rtx[d0];\n+          xop[3] = movw;\n+          avr_asm_len (\"movw %2,%3\", xop, plen, 1);\n+          d0++;\n+        }\n+      else\n+        {\n+          avr_asm_len (sign_extend ? \"sbc %0,%0\" : \"clr %0\",\n+                       &all_regs_rtx[d0], plen, 1);\n+\n+          if (++copies >= 2 && !movw && d0 % 2 == 1)\n+            movw = all_regs_rtx[d0-1];\n+        }\n+    } /* for */\n+\n+\n+  /* Step 4:  Right shift the destination.  This might be needed for\n+     ======   conversions from unsigned to signed.  */\n+\n+  if (shift == ASHIFTRT)\n+    {\n+      const char *code_ashiftrt = \"lsr %0\";\n+\n+      if (sign_extend || msb_in_carry)\n+        code_ashiftrt = \"ror %0\";\n+\n+      if (src.sbit && src.ibyte == dest.ibyte)\n+        code_ashiftrt = \"asr %0\";\n+\n+      for (d0 = dest.regno_msb - sign_bytes;\n+           d0 >= dest.regno + zero_bytes - 1 && d0 >= dest.regno; d0--)\n+        {\n+          avr_asm_len (code_ashiftrt, &all_regs_rtx[d0], plen, 1);\n+          code_ashiftrt = \"ror %0\";\n+        }\n+    }\n+\n+#undef MAY_CLOBBER\n+\n+  return \"\";\n+}\n+\n+\n /* Create RTL split patterns for byte sized rotate expressions.  This\n   produces a series of move instructions and considers overlap situations.\n   Overlapping non-HImode operands need a scratch register.  */\n@@ -7123,348 +7449,6 @@ avr_rotate_bytes (rtx operands[])\n }\n \n \n-/* Outputs instructions needed for fixed point type conversion.\n-   This includes converting between any fixed point type, as well\n-   as converting to any integer type.  Conversion between integer\n-   types is not supported.\n-\n-   The number of instructions generated depends on the types\n-   being converted and the registers assigned to them.\n-\n-   The number of instructions required to complete the conversion\n-   is least if the registers for source and destination are overlapping\n-   and are aligned at the decimal place as actual movement of data is\n-   completely avoided.  In some cases, the conversion may already be\n-   complete without any instructions needed.\n-\n-   When converting to signed types from signed types, sign extension\n-   is implemented.\n-\n-   Converting signed fractional types requires a bit shift if converting\n-   to or from any unsigned fractional type because the decimal place is\n-   shifted by 1 bit.  When the destination is a signed fractional, the sign\n-   is stored in either the carry or T bit.  */\n-\n-const char*\n-avr_out_fract (rtx insn, rtx operands[], bool intsigned, int *plen)\n-{\n-  int i;\n-  bool sbit[2];\n-  /* ilen: Length of integral part (in bytes)\n-     flen: Length of fractional part (in bytes)\n-     tlen: Length of operand (in bytes)\n-     blen: Length of operand (in bits) */\n-  int ilen[2], flen[2], tlen[2], blen[2];\n-  int rdest, rsource, offset;\n-  int start, end, dir;\n-  bool sign_in_T = false, sign_in_Carry = false, sign_done = false;\n-  bool widening_sign_extend = false;\n-  int clrword = -1, lastclr = 0, clr = 0;\n-  rtx xop[6];\n-\n-  const int dest = 0;\n-  const int src = 1;\n-\n-  xop[dest] = operands[dest];\n-  xop[src] = operands[src];\n-\n-  if (plen)\n-    *plen = 0;\n-\n-  /* Determine format (integer and fractional parts)\n-     of types needing conversion.  */\n-\n-  for (i = 0; i < 2; i++)\n-    {\n-      enum machine_mode mode = GET_MODE (xop[i]);\n-\n-      tlen[i] = GET_MODE_SIZE (mode);\n-      blen[i] = GET_MODE_BITSIZE (mode);\n-\n-      if (SCALAR_INT_MODE_P (mode))\n-        {\n-          sbit[i] = intsigned;\n-          ilen[i] = GET_MODE_SIZE (mode);\n-          flen[i] = 0;\n-        }\n-      else if (ALL_SCALAR_FIXED_POINT_MODE_P (mode))\n-        {\n-          sbit[i] = SIGNED_SCALAR_FIXED_POINT_MODE_P (mode);\n-          ilen[i] = (GET_MODE_IBIT (mode) + 1) / 8;\n-          flen[i] = (GET_MODE_FBIT (mode) + 1) / 8;\n-        }\n-      else\n-        fatal_insn (\"unsupported fixed-point conversion\", insn);\n-    }\n-\n-  /* Perform sign extension if source and dest are both signed,\n-     and there are more integer parts in dest than in source.  */\n-\n-  widening_sign_extend = sbit[dest] && sbit[src] && ilen[dest] > ilen[src];\n-\n-  rdest = REGNO (xop[dest]);\n-  rsource = REGNO (xop[src]);\n-  offset = flen[src] - flen[dest];\n-\n-  /* Position of MSB resp. sign bit.  */\n-\n-  xop[2] = GEN_INT (blen[dest] - 1);\n-  xop[3] = GEN_INT (blen[src] - 1);\n-\n-  /* Store the sign bit if the destination is a signed fract and the source\n-     has a sign in the integer part.  */\n-\n-  if (sbit[dest] && ilen[dest] == 0 && sbit[src] && ilen[src] > 0)\n-    {\n-      /* To avoid using BST and BLD if the source and destination registers\n-         overlap or the source is unused after, we can use LSL to store the\n-         sign bit in carry since we don't need the integral part of the source.\n-         Restoring the sign from carry saves one BLD instruction below.  */\n-\n-      if (reg_unused_after (insn, xop[src])\n-          || (rdest < rsource + tlen[src]\n-              && rdest + tlen[dest] > rsource))\n-        {\n-          avr_asm_len (\"lsl %T1%t3\", xop, plen, 1);\n-          sign_in_Carry = true;\n-        }\n-      else\n-        {\n-          avr_asm_len (\"bst %T1%T3\", xop, plen, 1);\n-          sign_in_T = true;\n-        }\n-    }\n-\n-  /* Pick the correct direction to shift bytes.  */\n-\n-  if (rdest < rsource + offset)\n-    {\n-      dir = 1;\n-      start = 0;\n-      end = tlen[dest];\n-    }\n-  else\n-    {\n-      dir = -1;\n-      start = tlen[dest] - 1;\n-      end = -1;\n-    }\n-\n-  /* Perform conversion by moving registers into place, clearing\n-     destination registers that do not overlap with any source.  */\n-\n-  for (i = start; i != end; i += dir)\n-    {\n-      int destloc = rdest + i;\n-      int sourceloc = rsource + i + offset;\n-\n-      /* Source register location is outside range of source register,\n-         so clear this byte in the dest.  */\n-\n-      if (sourceloc < rsource\n-          || sourceloc >= rsource + tlen[src])\n-        {\n-          if (AVR_HAVE_MOVW\n-              && i + dir != end\n-              && (sourceloc + dir < rsource\n-                  || sourceloc + dir >= rsource + tlen[src])\n-              && ((dir == 1 && !(destloc % 2) && !(sourceloc % 2))\n-                  || (dir == -1 && (destloc % 2) && (sourceloc % 2)))\n-              && clrword != -1)\n-            {\n-              /* Use already cleared word to clear two bytes at a time.  */\n-\n-              int even_i = i & ~1;\n-              int even_clrword = clrword & ~1;\n-\n-              xop[4] = GEN_INT (8 * even_i);\n-              xop[5] = GEN_INT (8 * even_clrword);\n-              avr_asm_len (\"movw %T0%t4,%T0%t5\", xop, plen, 1);\n-              i += dir;\n-            }\n-          else\n-            {\n-              if (i == tlen[dest] - 1\n-                  && widening_sign_extend\n-                  && blen[src] - 1 - 8 * offset < 0)\n-                {\n-                  /* The SBRC below that sign-extends would come\n-                     up with a negative bit number because the sign\n-                     bit is out of reach.  ALso avoid some early-clobber\n-                     situations because of premature CLR.  */\n-\n-                  if (reg_unused_after (insn, xop[src]))\n-                    avr_asm_len (\"lsl %T1%t3\" CR_TAB\n-                                 \"sbc %T0%t2,%T0%t2\", xop, plen, 2);\n-                  else\n-                    avr_asm_len (\"mov __tmp_reg__,%T1%t3\"  CR_TAB\n-                                 \"lsl __tmp_reg__\"         CR_TAB\n-                                 \"sbc %T0%t2,%T0%t2\", xop, plen, 3);\n-                  sign_done = true;\n-\n-                  continue;\n-                }\n-              \n-              /* Do not clear the register if it is going to get\n-                 sign extended with a MOV later.  */\n-\n-              if (sbit[dest] && sbit[src]\n-                  && i != tlen[dest] - 1\n-                  && i >= flen[dest])\n-                {\n-                  continue;\n-                }\n-\n-              xop[4] = GEN_INT (8 * i);\n-              avr_asm_len (\"clr %T0%t4\", xop, plen, 1);\n-\n-              /* If the last byte was cleared too, we have a cleared\n-                 word we can MOVW to clear two bytes at a time.  */\n-\n-              if (lastclr) \n-                clrword = i;\n-\n-              clr = 1;\n-            }\n-        }\n-      else if (destloc == sourceloc)\n-        {\n-          /* Source byte is already in destination:  Nothing needed.  */\n-\n-          continue;\n-        }\n-      else\n-        {\n-          /* Registers do not line up and source register location\n-             is within range:  Perform move, shifting with MOV or MOVW.  */\n-\n-          if (AVR_HAVE_MOVW\n-              && i + dir != end\n-              && sourceloc + dir >= rsource\n-              && sourceloc + dir < rsource + tlen[src]\n-              && ((dir == 1 && !(destloc % 2) && !(sourceloc % 2))\n-                  || (dir == -1 && (destloc % 2) && (sourceloc % 2))))\n-            {\n-              int even_i = i & ~1;\n-              int even_i_plus_offset = (i + offset) & ~1;\n-\n-              xop[4] = GEN_INT (8 * even_i);\n-              xop[5] = GEN_INT (8 * even_i_plus_offset);\n-              avr_asm_len (\"movw %T0%t4,%T1%t5\", xop, plen, 1);\n-              i += dir;\n-            }\n-          else\n-            {\n-              xop[4] = GEN_INT (8 * i);\n-              xop[5] = GEN_INT (8 * (i + offset));\n-              avr_asm_len (\"mov %T0%t4,%T1%t5\", xop, plen, 1);\n-            }\n-        }\n-\n-      lastclr = clr;\n-      clr = 0;\n-    }\n-      \n-  /* Perform sign extension if source and dest are both signed,\n-     and there are more integer parts in dest than in source.  */\n-\n-  if (widening_sign_extend)\n-    {\n-      if (!sign_done)\n-        {\n-          xop[4] = GEN_INT (blen[src] - 1 - 8 * offset);\n-\n-          /* Register was cleared above, so can become 0xff and extended.\n-             Note:  Instead of the CLR/SBRC/COM the sign extension could\n-             be performed after the LSL below by means of a SBC if only\n-             one byte has to be shifted left.  */\n-\n-          avr_asm_len (\"sbrc %T0%T4\" CR_TAB\n-                       \"com %T0%t2\", xop, plen, 2);\n-        }\n-\n-      /* Sign extend additional bytes by MOV and MOVW.  */\n-\n-      start = tlen[dest] - 2;\n-      end = flen[dest] + ilen[src] - 1;\n-\n-      for (i = start; i != end; i--)\n-        {\n-          if (AVR_HAVE_MOVW && i != start && i-1 != end)\n-            {\n-              i--;\n-              xop[4] = GEN_INT (8 * i);\n-              xop[5] = GEN_INT (8 * (tlen[dest] - 2));\n-              avr_asm_len (\"movw %T0%t4,%T0%t5\", xop, plen, 1);\n-            }\n-          else\n-            {\n-              xop[4] = GEN_INT (8 * i);\n-              xop[5] = GEN_INT (8 * (tlen[dest] - 1));\n-              avr_asm_len (\"mov %T0%t4,%T0%t5\", xop, plen, 1);\n-            }\n-        }\n-    }\n-\n-  /* If destination is a signed fract, and the source was not, a shift\n-     by 1 bit is needed.  Also restore sign from carry or T.  */\n-\n-  if (sbit[dest] && !ilen[dest] && (!sbit[src] || ilen[src]))\n-    {\n-      /* We have flen[src] non-zero fractional bytes to shift.\n-         Because of the right shift, handle one byte more so that the\n-         LSB won't be lost.  */\n-\n-      int nonzero = flen[src] + 1;\n-\n-      /* If the LSB is in the T flag and there are no fractional\n-         bits, the high byte is zero and no shift needed.  */\n-      \n-      if (flen[src] == 0 && sign_in_T)\n-        nonzero = 0;\n-\n-      start = flen[dest] - 1;\n-      end = start - nonzero;\n-\n-      for (i = start; i > end && i >= 0; i--)\n-        {\n-          xop[4] = GEN_INT (8 * i);\n-          if (i == start && !sign_in_Carry)\n-            avr_asm_len (\"lsr %T0%t4\", xop, plen, 1);\n-          else\n-            avr_asm_len (\"ror %T0%t4\", xop, plen, 1);\n-        }\n-\n-      if (sign_in_T)\n-        {\n-          avr_asm_len (\"bld %T0%T2\", xop, plen, 1);\n-        }\n-    }\n-  else if (sbit[src] && !ilen[src] && (!sbit[dest] || ilen[dest]))\n-    {\n-      /* If source was a signed fract and dest was not, shift 1 bit\n-         other way.  */\n-\n-      start = flen[dest] - flen[src];\n-\n-      if (start < 0)\n-        start = 0;\n-\n-      for (i = start; i < flen[dest]; i++)\n-        {\n-          xop[4] = GEN_INT (8 * i);\n-\n-          if (i == start)\n-            avr_asm_len (\"lsl %T0%t4\", xop, plen, 1);\n-          else\n-            avr_asm_len (\"rol %T0%t4\", xop, plen, 1);\n-        }\n-    }\n-\n-  return \"\";\n-}\n-\n-\n /* Modifies the length assigned to instruction INSN\n    LEN is the initially computed length of the insn.  */\n "}, {"sha": "c547dcb06c6df26eee58e2f0c74d8ec51417b792", "filename": "libgcc/ChangeLog", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/libgcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/libgcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2FChangeLog?ref=e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "patch": "@@ -1,3 +1,21 @@\n+2012-11-22  Georg-Johann Lay  <avr@gjlay.de>\n+\n+\tAdjust decimal point of signed accum mode to GCC default.\n+\n+\tPR target/54222\n+\t* config/avr/t-avr (LIB1ASMFUNCS): Add _fractsfsq _fractsfusq,\n+\t_divqq_helper.\n+\t* config/avr/lib1funcs-fixed.S (__fractqqsf, __fracthqsf)\n+\t(__fractsasf, __fractsfha, __fractusqsf, __fractsfsa)\n+\t(__mulha3, __mulsa3)\n+\t(__divqq3, __divha3, __divsa3): Adjust to new position of\n+\tdecimal point of signed accum types. \n+\t\n+\t(__mulusa3_round): New function.\n+\t(__mulusa3): Use it.\n+\t(__divqq_helper): New function.\n+\t(__udivuqq3): Use it.\n+\n 2012-11-20  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR bootstrap/55370"}, {"sha": "a9fd7d91f2046b2974ae95196e5172ce42a251cf", "filename": "libgcc/config/avr/lib1funcs-fixed.S", "status": "modified", "additions": 142, "deletions": 57, "changes": 199, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/libgcc%2Fconfig%2Favr%2Flib1funcs-fixed.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/libgcc%2Fconfig%2Favr%2Flib1funcs-fixed.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Favr%2Flib1funcs-fixed.S?ref=e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "patch": "@@ -43,8 +43,8 @@ DEFUN __fractqqsf\n     ;; Move in place for SA -> SF conversion\n     clr     r22\n     mov     r23, r24\n-    lsl     r23\n     ;; Sign-extend\n+    lsl     r24\n     sbc     r24, r24\n     mov     r25, r24\n     XJMP    __fractsasf\n@@ -67,9 +67,8 @@ ENDF __fractuqqsf\n DEFUN __fracthqsf\n     ;; Move in place for SA -> SF conversion\n     wmov    22, 24\n-    lsl     r22\n-    rol     r23\n     ;; Sign-extend\n+    lsl     r25\n     sbc     r24, r24\n     mov     r25, r24\n     XJMP    __fractsasf\n@@ -140,11 +139,13 @@ ENDF __fractusqsf\n #if defined (L_fractsasf)\n DEFUN __fractsasf\n     XCALL   __floatsisf\n-    ;; Divide non-zero results by 2^16 to move the\n+    ;; Divide non-zero results by 2^15 to move the\n     ;; decimal point into place\n-    cpse    r25, __zero_reg__\n-    subi    r25, exp_hi (16)\n-    ret\n+    tst     r25\n+    breq    0f\n+    subi    r24, exp_lo (15)\n+    sbci    r25, exp_hi (15)\n+0:  ret\n ENDF __fractsasf\n #endif  /* L_fractsasf */\n \n@@ -186,8 +187,9 @@ ENDF __fractsfuqq\n \n #if defined (L_fractsfha)\n DEFUN __fractsfha\n-    ;; Multiply with 2^24 to get a HA result in r25:r24\n-    subi    r25, exp_hi (-24)\n+    ;; Multiply with 2^{16+7} to get a HA result in r25:r24\n+    subi    r24, exp_lo (-23)\n+    sbci    r25, exp_hi (-23)\n     XJMP    __fixsfsi\n ENDF __fractsfha\n #endif  /* L_fractsfha */\n@@ -201,8 +203,7 @@ ENDF __fractsfuha\n #endif  /* L_fractsfuha */\n \n #if defined (L_fractsfhq)\n-DEFUN __fractsfsq\n-ENDF  __fractsfsq\n+FALIAS __fractsfsq\n \n DEFUN __fractsfhq\n     ;; Multiply with 2^{16+15} to get a HQ result in r25:r24\n@@ -214,8 +215,7 @@ ENDF __fractsfhq\n #endif  /* L_fractsfhq */\n \n #if defined (L_fractsfuhq)\n-DEFUN __fractsfusq\n-ENDF  __fractsfusq\n+FALIAS __fractsfusq\n \n DEFUN __fractsfuhq\n     ;; Multiply with 2^{16+16} to get a UHQ result in r25:r24\n@@ -227,8 +227,9 @@ ENDF __fractsfuhq\n \n #if defined (L_fractsfsa)\n DEFUN __fractsfsa\n-    ;; Multiply with 2^16 to get a SA result in r25:r22\n-    subi    r25, exp_hi (-16)\n+    ;; Multiply with 2^15 to get a SA result in r25:r22\n+    subi    r24, exp_lo (-15)\n+    sbci    r25, exp_hi (-15)\n     XJMP    __fixsfsi\n ENDF __fractsfsa\n #endif  /* L_fractsfsa */\n@@ -325,6 +326,9 @@ ENDF __muluhq3\n ;;; Rounding:  -0.5 LSB  <=  error  <=  0.5 LSB\n DEFUN   __mulha3\n     XCALL   __mulhisi3\n+    lsl     r22\n+    rol     r23\n+    rol     r24\n     XJMP    __muluha3_round\n ENDF __mulha3\n #endif  /* L_mulha3 */\n@@ -359,6 +363,9 @@ ENDF __muluha3_round\n     Fixed  Multiplication  16.16 x 16.16\n *******************************************************/\n \n+;; Bits outside the result (below LSB), used in the signed version\n+#define GUARD __tmp_reg__\n+\n #if defined (__AVR_HAVE_MUL__)\n \n ;; Multiplier\n@@ -381,9 +388,16 @@ ENDF __muluha3_round\n \n #if defined (L_mulusa3)\n ;;; (C3:C0) = (A3:A0) * (B3:B0)\n-;;; Clobbers: __tmp_reg__\n-;;; Rounding:  -0.5 LSB  <  error  <=  0.5 LSB\n-DEFUN   __mulusa3\n+DEFUN __mulusa3\n+    set\n+    ;; Fallthru\n+ENDF  __mulusa3\n+\n+;;; Round for last digit iff T = 1\n+;;; Return guard bits in GUARD (__tmp_reg__).\n+;;; Rounding, T = 0:  -1.0 LSB  <  error  <=  0   LSB\n+;;; Rounding, T = 1:  -0.5 LSB  <  error  <=  0.5 LSB\n+DEFUN __mulusa3_round\n     ;; Some of the MUL instructions have LSBs outside the result.\n     ;; Don't ignore these LSBs in order to tame rounding error.\n     ;; Use C2/C3 for these LSBs.\n@@ -395,9 +409,12 @@ DEFUN   __mulusa3\n     mul A1, B0  $  add  C3, r0  $  adc C0, r1\n     mul A0, B1  $  add  C3, r0  $  adc C0, r1  $  rol C1\n     \n-    ;; Round\n+    ;; Round if T = 1.  Store guarding bits outside the result for rounding\n+    ;; and left-shift by the signed version (function below).\n+    brtc 0f\n     sbrc C3, 7\n     adiw C0, 1\n+0:  push C3\n     \n     ;; The following MULs don't have LSBs outside the result.\n     ;; C2/C3 is the high part.\n@@ -420,25 +437,42 @@ DEFUN   __mulusa3\n     mul  A2, B3  $  add C3, r0\n     mul  A3, B2  $  add C3, r0\n \n+    ;; Guard bits used in the signed version below.\n+    pop  GUARD\n     clr  __zero_reg__\n     ret\n-ENDF __mulusa3\n+ENDF __mulusa3_round\n #endif /* L_mulusa3 */\n \n #if defined (L_mulsa3)\n ;;; (C3:C0) = (A3:A0) * (B3:B0)\n-;;; Clobbers: __tmp_reg__\n+;;; Clobbers: __tmp_reg__, T\n ;;; Rounding:  -0.5 LSB  <=  error  <=  0.5 LSB\n DEFUN __mulsa3\n-    XCALL   __mulusa3\n+    clt\n+    XCALL   __mulusa3_round\n+    ;; A posteriori sign extension of the operands\n     tst     B3\n-    brpl    1f\n+    brpl 1f\n     sub     C2, A0\n     sbc     C3, A1\n 1:  sbrs    A3, 7\n-    ret\n+    rjmp 2f\n     sub     C2, B0\n     sbc     C3, B1\n+2:\n+    ;;  Shift 1 bit left to adjust for 15 fractional bits\n+    lsl     GUARD\n+    rol     C0\n+    rol     C1\n+    rol     C2\n+    rol     C3\n+    ;; Round last digit\n+    lsl     GUARD\n+    adc     C0, __zero_reg__\n+    adc     C1, __zero_reg__\n+    adc     C2, __zero_reg__\n+    adc     C3, __zero_reg__\n     ret\n ENDF __mulsa3\n #endif /* L_mulsa3 */\n@@ -492,27 +526,56 @@ ENDF __mulsa3\n DEFUN   __mulsa3\n     push    B0\n     push    B1\n-    bst     B3, 7\n-    XCALL   __mulusa3\n-    ;; A survived in  31:30:27:26\n-    rcall 1f\n-    pop     AA1\n-    pop     AA0\n+    push    B3\n+    clt\n+    XCALL   __mulusa3_round\n+    pop     r30\n+    ;; sign-extend B\n+    bst     r30, 7\n+    brtc 1f\n+    ;; A1, A0 survived in  R27:R26\n+    sub     C2, AA0\n+    sbc     C3, AA1\n+1:\n+    pop     AA1  ;; B1\n+    pop     AA0  ;; B0\n+\n+    ;; sign-extend A.  A3 survived in  R31\n     bst     AA3, 7\n-1:  brtc  9f\n-    ;; 1-extend A/B\n+    brtc 2f\n     sub     C2, AA0\n     sbc     C3, AA1\n-9:  ret\n+2:\n+    ;;  Shift 1 bit left to adjust for 15 fractional bits\n+    lsl     GUARD\n+    rol     C0\n+    rol     C1\n+    rol     C2\n+    rol     C3\n+    ;; Round last digit\n+    lsl     GUARD\n+    adc     C0, __zero_reg__\n+    adc     C1, __zero_reg__\n+    adc     C2, __zero_reg__\n+    adc     C3, __zero_reg__\n+    ret\n ENDF __mulsa3\n #endif  /* L_mulsa3 */\n \n #if defined (L_mulusa3)\n ;;; (R25:R22)  *=  (R21:R18)\n-;;; Clobbers: ABI, called by optabs and __mulsua\n+;;; Clobbers: ABI, called by optabs\n ;;; Rounding:  -1 LSB  <=  error  <=  1 LSB\n-;;; Does not clobber T and A[] survives in 26, 27, 30, 31\n-DEFUN   __mulusa3\n+DEFUN __mulusa3\n+    set\n+    ;; Fallthru\n+ENDF  __mulusa3\n+\n+;;; A[] survives in 26, 27, 30, 31\n+;;; Also used by __mulsa3 with T = 0\n+;;; Round if T = 1\n+;;; Return Guard bits in GUARD (__tmp_reg__), used by signed version.\n+DEFUN __mulusa3_round\n     push    CC2\n     push    CC3\n     ; clear result\n@@ -560,21 +623,26 @@ DEFUN   __mulusa3\n     sbci    B0, 0\n     brne 5b\n \n-    ;; Move result into place and round\n+    ;; Save guard bits and set carry for rounding\n+    push    B3\n     lsl     B3\n+    ;; Move result into place\n     wmov    C2, CC2\n     wmov    C0, CC0\n     clr     __zero_reg__\n+    brtc 6f\n+    ;; Round iff T = 1\n     adc     C0, __zero_reg__\n     adc     C1, __zero_reg__\n     adc     C2, __zero_reg__\n     adc     C3, __zero_reg__\n-    \n+6:  \n+    pop     GUARD\n     ;; Epilogue\n     pop     CC3\n     pop     CC2\n     ret\n-ENDF __mulusa3\n+ENDF __mulusa3_round\n #endif  /* L_mulusa3 */\n \n #undef A0\n@@ -600,37 +668,47 @@ ENDF __mulusa3\n \n #endif /* __AVR_HAVE_MUL__ */\n \n+#undef GUARD\n+\n /*******************************************************\n       Fractional Division 8 / 8\n *******************************************************/\n \n #define r_divd  r25     /* dividend */\n #define r_quo   r24     /* quotient */\n #define r_div   r22     /* divisor */\n+#define r_sign  __tmp_reg__\n \n #if defined (L_divqq3)\n DEFUN   __divqq3\n-    mov     r0, r_divd\n-    eor     r0, r_div\n+    mov     r_sign, r_divd\n+    eor     r_sign, r_div\n     sbrc    r_div, 7\n     neg     r_div\n     sbrc    r_divd, 7\n     neg     r_divd\n-    cp      r_divd, r_div\n-    breq    __divqq3_minus1  ; if equal return -1\n-    XCALL   __udivuqq3\n+    XCALL   __divqq_helper\n     lsr     r_quo\n-    sbrc    r0, 7   ; negate result if needed\n+    sbrc    r_sign, 7   ; negate result if needed\n     neg     r_quo\n     ret\n-__divqq3_minus1:\n-    ldi     r_quo, 0x80\n-    ret\n ENDF __divqq3\n-#endif  /* defined (L_divqq3) */\n+#endif  /* L_divqq3 */\n \n #if defined (L_udivuqq3)\n DEFUN   __udivuqq3\n+    cp      r_divd, r_div\n+    brsh    0f\n+    XJMP __divqq_helper\n+    ;; Result is out of [0, 1)  ==>  Return 1 - eps.\n+0:  ldi     r_quo, 0xff\n+    ret\n+ENDF __udivuqq3\n+#endif  /* L_udivuqq3 */\n+\n+\n+#if defined (L_divqq_helper)\n+DEFUN   __divqq_helper\n     clr     r_quo           ; clear quotient\n     inc     __zero_reg__    ; init loop counter, used per shift\n __udivuqq3_loop:\n@@ -649,12 +727,13 @@ __udivuqq3_cont:\n     com     r_quo           ; complement result\n                             ; because C flag was complemented in loop\n     ret\n-ENDF __udivuqq3\n-#endif  /* defined (L_udivuqq3) */\n+ENDF __divqq_helper\n+#endif  /* L_divqq_helper */\n \n #undef  r_divd\n #undef  r_quo\n #undef  r_div\n+#undef  r_sign\n \n \n /*******************************************************\n@@ -746,6 +825,8 @@ DEFUN   __divha3\n     NEG2    r_divdL\n 2:\n     XCALL   __udivuha3\n+    lsr     r_quoH  ; adjust to 7 fractional bits\n+    ror     r_quoL\n     sbrs    r0, 7   ; negate result if needed\n     ret\n     NEG2    r_quoL\n@@ -806,6 +887,10 @@ DEFUN   __divsa3\n     NEG4    r_arg1L\n 2:\n     XCALL   __udivusa3\n+    lsr     r_quoHH ; adjust to 15 fractional bits\n+    ror     r_quoHL\n+    ror     r_quoH\n+    ror     r_quoL\n     sbrs    r0, 7   ; negate result if needed\n     ret\n     ;; negate r_quoL\n@@ -1024,8 +1109,8 @@ DEFUN __usadd_8\n     XCALL   __adddi3\n     brcs 0f\n     ret\n-\t;; A[] = 0xffffffff\n-0:  XJMP    __sbc_8\n+0:  ;; A[] = 0xffffffff\n+    XJMP    __sbc_8\n ENDF __usadd_8\n #endif /* L_usadd_8 */\n \n@@ -1038,8 +1123,8 @@ DEFUN __ussub_8\n     XCALL   __subdi3\n     brcs 0f\n     ret\n-\t;; A[] = 0\n-0:  XJMP    __clr_8\n+0:  ;; A[] = 0\n+    XJMP    __clr_8\n ENDF __ussub_8\n #endif /* L_ussub_8 */\n \n@@ -1049,9 +1134,9 @@ FALIAS __ssaddda3\n FALIAS __ssadddq3\n \n DEFUN __ssadd_8\n-    ;; A = (B >= 0) ? INT64_MAX : INT64_MIN\n     XCALL   __adddi3\n     brvc 0f\n+    ;; A = (B >= 0) ? INT64_MAX : INT64_MIN\n     cpi     B7, 0x80\n     XCALL   __sbc_8\n     subi    A7, 0x80\n@@ -1067,7 +1152,7 @@ FALIAS __sssubdq3\n DEFUN __sssub_8\n     XCALL   __subdi3\n     brvc 0f\n-\t;; A = (B < 0) ? INT64_MAX : INT64_MIN\n+    ;; A = (B < 0) ? INT64_MAX : INT64_MIN\n     ldi     A7, 0x7f\n     cp      A7, B7\n     XCALL   __sbc_8"}, {"sha": "d609199168ddbcc8fd2ced5afe7499d587962833", "filename": "libgcc/config/avr/t-avr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/libgcc%2Fconfig%2Favr%2Ft-avr", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e13d9d5aebf7198e9b92b909f51ec058b07c2f90/libgcc%2Fconfig%2Favr%2Ft-avr", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgcc%2Fconfig%2Favr%2Ft-avr?ref=e13d9d5aebf7198e9b92b909f51ec058b07c2f90", "patch": "@@ -64,12 +64,12 @@ LIB1ASMFUNCS += \\\n \t\\\n \t_fractsfqq _fractsfuqq \\\n \t_fractsfhq _fractsfuhq _fractsfha _fractsfuha \\\n-\t_fractsfsa _fractsfusa \\\n+\t_fractsfsq _fractsfusq _fractsfsa _fractsfusa \\\n \t_mulqq3 \\\n \t_mulhq3 _muluhq3 \\\n \t_mulha3 _muluha3 _muluha3_round \\\n \t_mulsa3 _mulusa3 \\\n-\t_divqq3 _udivuqq3 \\\n+\t_divqq3 _udivuqq3 _divqq_helper \\\n \t_divhq3 _udivuhq3 \\\n \t_divha3 _udivuha3 \\\n \t_divsa3 _udivusa3 \\"}]}