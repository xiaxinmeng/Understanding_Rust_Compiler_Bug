{"sha": "4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NGVkNWJjZmIxZWQ0MTVjMzJiZGQ4NzM1YjJjZDBlYTBlZDM3ZThiNg==", "commit": {"author": {"name": "Neil Booth", "email": "neil@daikokuya.demon.co.uk", "date": "2001-09-24T22:53:12Z"}, "committer": {"name": "Neil Booth", "email": "neil@gcc.gnu.org", "date": "2001-09-24T22:53:12Z"}, "message": "c-lex.c (cb_def_pragma): Update.\n\n\t* c-lex.c (cb_def_pragma): Update.\n\t(c_lex): Update, and skip padding.\n\t* cppexp.c (lex, parse_defined): Update, remove unused variable.\n\t* cpphash.h (struct toklist): Delete.\n\t(union utoken): New.\n\t(struct cpp_context): Update.\n\t(struct cpp_reader): New members eof, avoid_paste.\n\t(_cpp_temp_token): New.\n\t* cppinit.c (cpp_create_reader): Update.\n\t* cpplex.c (_cpp_temp_token): New.\n\t(_cpp_lex_direct): Add PREV_WHITE when parsing args.\n\t(cpp_output_token): Don't print leading whitespace.\n\t(cpp_output_line): Update.\n\t* cpplib.c (glue_header_name, parse_include, get__Pragma_string,\n\tdo_include_common, do_line, do_ident, do_pragma,\n\tdo_pragma_dependency, _cpp_do__Pragma, parse_answer,\n\tparse_assertion): Update.\n\t(get_token_no_padding): New.\n\t* cpplib.h (CPP_PADDING): New.\n\t(AVOID_LPASTE): Delete.\n\t(struct cpp_token): New union member source.\n\t(cpp_get_token): Update.\n\t* cppmacro.c (macro_arg): Convert to use pointers to const tokens.\n\t(builtin_macro, paste_all_tokens, paste_tokens, funlike_invocation_p,\n\treplace_args, quote_string, stringify_arg, parse_arg, next_context,\n\tenter_macro_context, expand_arg, _cpp_pop_context, cpp_scan_nooutput,\n\t_cpp_backup_tokens, _cpp_create_definition): Update.\n\t(push_arg_context): Delete.\n\t(padding_token, push_token_context, push_ptoken_context): New.\n\t(make_string_token, make_number_token): Update, rename.\n\t(cpp_get_token): Update to handle tokens as pointers to const,\n\tand insert padding appropriately.\n\t* cppmain.c (struct printer): New member prev.\n\t(check_multiline_token): Constify.\n\t(do_preprocessing, cb_line_change): Update.\n\t(scan_translation_unit): Update to handle spacing.\n\t* scan-decls.c (get_a_token): New.\n\t(skip_to_closing_brace, scan_decls): Update.\n\t* fix-header.c (read_scan_file): Update.\n\n\t* doc/cpp.texi: Update.\n\n\t* gcc.dg/cpp/macro10.c: New test.\n\t* gcc.dg/cpp/strify3.c: New test.\n\t* gcc.dg/cpp/spacing1.c: Add tests.\n\t* gcc.dg/cpp/19990703-1.c: Remove bogus test.\n\t* gcc.dg/cpp/20000625-2.c: Fudge to pass.\n\nFrom-SVN: r45793", "tree": {"sha": "f2b5dd04bb961bbe8dac8d988d52d574f0cb2b47", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f2b5dd04bb961bbe8dac8d988d52d574f0cb2b47"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/comments", "author": null, "committer": null, "parents": [{"sha": "ad43d46f3abe6f4d9b41f5b1d7b46a0c320efda8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ad43d46f3abe6f4d9b41f5b1d7b46a0c320efda8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ad43d46f3abe6f4d9b41f5b1d7b46a0c320efda8"}], "stats": {"total": 1360, "additions": 794, "deletions": 566}, "files": [{"sha": "2ef183d2b35085b61ac22bfecb1b0ee922163321", "filename": "gcc/ChangeLog", "status": "modified", "additions": 44, "deletions": 0, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -1,3 +1,47 @@\n+2001-09-24  Neil Booth  <neil@daikokuya.demon.co.uk>\n+\n+\t* c-lex.c (cb_def_pragma): Update.\n+\t(c_lex): Update, and skip padding.\n+\t* cppexp.c (lex, parse_defined): Update, remove unused variable.\n+\t* cpphash.h (struct toklist): Delete.\n+\t(union utoken): New.\n+\t(struct cpp_context): Update.\n+\t(struct cpp_reader): New members eof, avoid_paste.\n+\t(_cpp_temp_token): New.\n+\t* cppinit.c (cpp_create_reader): Update.\n+\t* cpplex.c (_cpp_temp_token): New.\n+\t(_cpp_lex_direct): Add PREV_WHITE when parsing args.\n+\t(cpp_output_token): Don't print leading whitespace.\n+\t(cpp_output_line): Update.\n+\t* cpplib.c (glue_header_name, parse_include, get__Pragma_string,\n+\tdo_include_common, do_line, do_ident, do_pragma,\n+\tdo_pragma_dependency, _cpp_do__Pragma, parse_answer,\n+\tparse_assertion): Update.\n+\t(get_token_no_padding): New.\n+\t* cpplib.h (CPP_PADDING): New.\n+\t(AVOID_LPASTE): Delete.\n+\t(struct cpp_token): New union member source.\n+\t(cpp_get_token): Update.\n+\t* cppmacro.c (macro_arg): Convert to use pointers to const tokens.\n+\t(builtin_macro, paste_all_tokens, paste_tokens, funlike_invocation_p,\n+\treplace_args, quote_string, stringify_arg, parse_arg, next_context,\n+\tenter_macro_context, expand_arg, _cpp_pop_context, cpp_scan_nooutput,\n+\t_cpp_backup_tokens, _cpp_create_definition): Update.\n+\t(push_arg_context): Delete.\n+\t(padding_token, push_token_context, push_ptoken_context): New.\n+\t(make_string_token, make_number_token): Update, rename.\n+\t(cpp_get_token): Update to handle tokens as pointers to const,\n+\tand insert padding appropriately.\n+\t* cppmain.c (struct printer): New member prev.\n+\t(check_multiline_token): Constify.\n+\t(do_preprocessing, cb_line_change): Update.\n+\t(scan_translation_unit): Update to handle spacing.\n+\t* scan-decls.c (get_a_token): New.\n+\t(skip_to_closing_brace, scan_decls): Update.\n+\t* fix-header.c (read_scan_file): Update.\n+\n+\t* doc/cpp.texi: Update.\n+\n 2001-09-24  Kaveh R. Ghazi  <ghazi@caip.rutgers.edu>\n \n \t* c-aux-info.c (affix_data_type): Use ATTRIBUTE_MALLOC.  Avoid"}, {"sha": "8e6582f06dbc6c7d7007d53442bd46d388806e8c", "filename": "gcc/c-lex.c", "status": "modified", "additions": 21, "deletions": 21, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fc-lex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fc-lex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-lex.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -335,13 +335,13 @@ cb_def_pragma (pfile, line)\n   if (warn_unknown_pragmas > in_system_header)\n     {\n       const unsigned char *space, *name = 0;\n-      cpp_token s;\n+      const cpp_token *s;\n \n-      cpp_get_token (pfile, &s);\n-      space = cpp_token_as_text (pfile, &s);\n-      cpp_get_token (pfile, &s);\n-      if (s.type == CPP_NAME)\n-\tname = cpp_token_as_text (pfile, &s);\n+      s = cpp_get_token (pfile);\n+      space = cpp_token_as_text (pfile, s);\n+      s = cpp_get_token (pfile);\n+      if (s->type == CPP_NAME)\n+\tname = cpp_token_as_text (pfile, s);\n \n       lineno = SOURCE_LINE (map, line);\n       if (name)\n@@ -767,12 +767,13 @@ int\n c_lex (value)\n      tree *value;\n {\n-  cpp_token tok;\n-  enum cpp_ttype type;\n+  const cpp_token *tok;\n \n   retry:\n   timevar_push (TV_CPP);\n-  cpp_get_token (parse_in, &tok);\n+  do\n+    tok = cpp_get_token (parse_in);\n+  while (tok->type == CPP_PADDING);\n   timevar_pop (TV_CPP);\n \n   /* The C++ front end does horrible things with the current line\n@@ -781,37 +782,36 @@ c_lex (value)\n   lineno = src_lineno;\n \n   *value = NULL_TREE;\n-  type = tok.type;\n-  switch (type)\n+  switch (tok->type)\n     {\n     case CPP_OPEN_BRACE:  indent_level++;  break;\n     case CPP_CLOSE_BRACE: indent_level--;  break;\n \n-    /* Issue this error here, where we can get at tok.val.c.  */\n+    /* Issue this error here, where we can get at tok->val.c.  */\n     case CPP_OTHER:\n-      if (ISGRAPH (tok.val.c))\n-\terror (\"stray '%c' in program\", tok.val.c);\n+      if (ISGRAPH (tok->val.c))\n+\terror (\"stray '%c' in program\", tok->val.c);\n       else\n-\terror (\"stray '\\\\%o' in program\", tok.val.c);\n+\terror (\"stray '\\\\%o' in program\", tok->val.c);\n       goto retry;\n       \n     case CPP_NAME:\n-      *value = HT_IDENT_TO_GCC_IDENT (HT_NODE (tok.val.node));\n+      *value = HT_IDENT_TO_GCC_IDENT (HT_NODE (tok->val.node));\n       break;\n \n     case CPP_NUMBER:\n-      *value = lex_number ((const char *)tok.val.str.text, tok.val.str.len);\n+      *value = lex_number ((const char *)tok->val.str.text, tok->val.str.len);\n       break;\n \n     case CPP_CHAR:\n     case CPP_WCHAR:\n-      *value = lex_charconst (&tok);\n+      *value = lex_charconst (tok);\n       break;\n \n     case CPP_STRING:\n     case CPP_WSTRING:\n-      *value = lex_string ((const char *)tok.val.str.text,\n-\t\t\t   tok.val.str.len, tok.type == CPP_WSTRING);\n+      *value = lex_string ((const char *)tok->val.str.text,\n+\t\t\t   tok->val.str.len, tok->type == CPP_WSTRING);\n       break;\n \n       /* These tokens should not be visible outside cpplib.  */\n@@ -823,7 +823,7 @@ c_lex (value)\n     default: break;\n     }\n \n-  return type;\n+  return tok->type;\n }\n \n #define ERROR(msgid) do { error(msgid); goto syntax_error; } while(0)"}, {"sha": "c79f20d2be94e9f488de4586808762e8e2a87476", "filename": "gcc/cppexp.c", "status": "modified", "additions": 16, "deletions": 23, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcppexp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcppexp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppexp.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -36,7 +36,7 @@ static HOST_WIDEST_INT right_shift PARAMS ((cpp_reader *, HOST_WIDEST_INT,\n \t\t\t\t\t    unsigned HOST_WIDEST_INT));\n static struct op parse_number PARAMS ((cpp_reader *, const cpp_token *));\n static struct op parse_defined PARAMS ((cpp_reader *));\n-static struct op lex PARAMS ((cpp_reader *, int, cpp_token *));\n+static struct op lex PARAMS ((cpp_reader *, int));\n static const unsigned char *op_as_text PARAMS ((cpp_reader *, enum cpp_ttype));\n \n struct op\n@@ -217,44 +217,40 @@ parse_defined (pfile)\n {\n   int paren = 0;\n   cpp_hashnode *node = 0;\n-  cpp_token token;\n+  const cpp_token *token;\n   struct op op;\n \n   /* Don't expand macros.  */\n   pfile->state.prevent_expansion++;\n \n-  cpp_get_token (pfile, &token);\n-  if (token.type == CPP_OPEN_PAREN)\n+  token = cpp_get_token (pfile);\n+  if (token->type == CPP_OPEN_PAREN)\n     {\n       paren = 1;\n-      cpp_get_token (pfile, &token);\n+      token = cpp_get_token (pfile);\n     }\n \n-  if (token.type == CPP_NAME)\n+  if (token->type == CPP_NAME)\n     {\n-      node = token.val.node;\n-      if (paren)\n+      node = token->val.node;\n+      if (paren && cpp_get_token (pfile)->type != CPP_CLOSE_PAREN)\n \t{\n-\t  cpp_get_token (pfile, &token);\n-\t  if (token.type != CPP_CLOSE_PAREN)\n-\t    {\n-\t      cpp_error (pfile, \"missing ')' after \\\"defined\\\"\");\n-\t      node = 0;\n-\t    }\n+\t  cpp_error (pfile, \"missing ')' after \\\"defined\\\"\");\n+\t  node = 0;\n \t}\n     }\n   else\n     {\n       cpp_error (pfile, \"operator \\\"defined\\\" requires an identifier\");\n-      if (token.flags & NAMED_OP)\n+      if (token->flags & NAMED_OP)\n \t{\n \t  cpp_token op;\n \n \t  op.flags = 0;\n-\t  op.type = token.type;\n+\t  op.type = token->type;\n \t  cpp_error (pfile,\n \t\t     \"(\\\"%s\\\" is an alternative token for \\\"%s\\\" in C++)\",\n-\t\t     cpp_token_as_text (pfile, &token),\n+\t\t     cpp_token_as_text (pfile, token),\n \t\t     cpp_token_as_text (pfile, &op));\n \t}\n     }\n@@ -282,14 +278,12 @@ parse_defined (pfile)\n    CPP_EOF, or the type of an operator token.  */\n \n static struct op\n-lex (pfile, skip_evaluation, token)\n+lex (pfile, skip_evaluation)\n      cpp_reader *pfile;\n      int skip_evaluation;\n-     cpp_token *token;\n {\n   struct op op;\n-\n-  cpp_get_token (pfile, token);\n+  const cpp_token *token = cpp_get_token (pfile);\n \n   switch (token->type)\n     {\n@@ -578,7 +572,6 @@ _cpp_parse_expr (pfile)\n   struct op init_stack[INIT_STACK_SIZE];\n   struct op *stack = init_stack;\n   struct op *limit = stack + INIT_STACK_SIZE;\n-  cpp_token token;\n   register struct op *top = stack + 1;\n   int skip_evaluation = 0;\n   int result;\n@@ -603,7 +596,7 @@ _cpp_parse_expr (pfile)\n       struct op op;\n \n       /* Read a token */\n-      op = lex (pfile, skip_evaluation, &token);\n+      op = lex (pfile, skip_evaluation);\n       lex_count++;\n \n       /* If the token is an operand, push its value and get next"}, {"sha": "001ac60c53e2226a320cfa68095657c40e83e4a6", "filename": "gcc/cpphash.h", "status": "modified", "additions": 13, "deletions": 5, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcpphash.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcpphash.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpphash.h?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -95,11 +95,10 @@ struct search_path\n /* #include types.  */\n enum include_type {IT_INCLUDE, IT_INCLUDE_NEXT, IT_IMPORT, IT_CMDLINE};\n \n-typedef struct toklist toklist;\n-struct toklist\n+union utoken\n {\n-  cpp_token *first;\n-  cpp_token *limit;\n+  const cpp_token *token;\n+  const cpp_token **ptoken;\n };\n \n typedef struct tokenrun tokenrun;\n@@ -117,10 +116,14 @@ struct cpp_context\n \n   /* Contexts other than the base context are contiguous tokens.\n      e.g. macro expansions, expanded argument tokens.  */\n-  struct toklist list;\n+  union utoken first;\n+  union utoken last;\n \n   /* For a macro context, these are the macro and its arguments.  */\n   cpp_macro *macro;\n+\n+  /* True if utoken element is token, else ptoken.  */\n+  bool direct_p;\n };\n \n struct lexer_state\n@@ -294,6 +297,10 @@ struct cpp_reader\n   cpp_token date;\n   cpp_token time;\n \n+  /* EOF token, and a token forcing paste avoidance.  */\n+  cpp_token avoid_paste;\n+  cpp_token eof;\n+\n   /* Opaque handle to the dependencies of mkdeps.c.  Used by -M etc.  */\n   struct deps *deps;\n \n@@ -398,6 +405,7 @@ extern void _cpp_pop_file_buffer\tPARAMS ((cpp_reader *,\n extern int _cpp_parse_expr\t\tPARAMS ((cpp_reader *));\n \n /* In cpplex.c */\n+extern cpp_token *_cpp_temp_token\tPARAMS ((cpp_reader *));\n extern const cpp_token *_cpp_lex_token\tPARAMS ((cpp_reader *));\n extern cpp_token *_cpp_lex_direct\tPARAMS ((cpp_reader *));\n extern int _cpp_equiv_tokens\t\tPARAMS ((const cpp_token *,"}, {"sha": "11c86aa337791ca79ddc6d50d2faae105de4f792", "filename": "gcc/cppinit.c", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcppinit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcppinit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppinit.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -510,8 +510,12 @@ cpp_create_reader (table, lang)\n   /* Initialize lexer state.  */\n   pfile->state.save_comments = ! CPP_OPTION (pfile, discard_comments);\n \n-  /* Indicate date and time not yet calculated.  */\n+  /* Set up static tokens.  */\n   pfile->date.type = CPP_EOF;\n+  pfile->avoid_paste.type = CPP_PADDING;\n+  pfile->avoid_paste.val.source = NULL;\n+  pfile->eof.type = CPP_EOF;\n+  pfile->eof.flags = 0;\n \n   /* Create a token buffer for the lexer.  */\n   _cpp_init_tokenrun (&pfile->base_run, 250);"}, {"sha": "e822ba577198df17bd6e71504f49abd59cf33a66", "filename": "gcc/cpplex.c", "status": "modified", "additions": 37, "deletions": 13, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcpplex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcpplex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplex.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -931,6 +931,29 @@ next_tokenrun (run)\n   return run->next;\n }\n \n+/* Allocate a single token that is invalidated at the same time as the\n+   rest of the tokens on the line.  Has its line and col set to the\n+   same as the last lexed token, so that diagnostics appear in the\n+   right place.  */\n+cpp_token *\n+_cpp_temp_token (pfile)\n+     cpp_reader *pfile;\n+{\n+  cpp_token *old, *result;\n+\n+  old = pfile->cur_token - 1;\n+  if (pfile->cur_token == pfile->cur_run->limit)\n+    {\n+      pfile->cur_run = next_tokenrun (pfile->cur_run);\n+      pfile->cur_token = pfile->cur_run->base;\n+    }\n+\n+  result = pfile->cur_token++;\n+  result->line = old->line;\n+  result->col = old->col;\n+  return result;\n+}\n+\n /* Lex a token into RESULT (external interface).  Takes care of issues\n    like directive handling, token lookahead, multiple include\n    opimisation and skipping.  */\n@@ -1057,6 +1080,8 @@ _cpp_lex_direct (pfile)\n       buffer->saved_flags = BOL;\n       if (! pfile->state.in_directive)\n \t{\n+\t  if (pfile->state.parsing_args == 2)\n+\t    buffer->saved_flags |= PREV_WHITE;\n \t  if (!pfile->keep_tokens)\n \t    {\n \t      pfile->cur_run = &pfile->base_run;\n@@ -1476,17 +1501,14 @@ cpp_type2name (type)\n   return (const char *) token_spellings[type].name;\n }\n \n-/* Writes the spelling of token to FP.  Separate from cpp_spell_token\n-   for efficiency - to avoid double-buffering.  Also, outputs a space\n-   if PREV_WHITE is flagged.  */\n+/* Writes the spelling of token to FP, without any preceding space.\n+   Separated from cpp_spell_token for efficiency - to avoid stdio\n+   double-buffering.  */\n void\n cpp_output_token (token, fp)\n      const cpp_token *token;\n      FILE *fp;\n {\n-  if (token->flags & PREV_WHITE)\n-    putc (' ', fp);\n-\n   switch (TOKEN_SPELL (token))\n     {\n     case SPELL_OPERATOR:\n@@ -1729,20 +1751,22 @@ cpp_avoid_paste (pfile, token1, token2)\n }\n \n /* Output all the remaining tokens on the current line, and a newline\n-   character, to FP.  Leading whitespace is removed.  */\n+   character, to FP.  Leading whitespace is removed.  If there are\n+   macros, special token padding is not performed.  */\n void\n cpp_output_line (pfile, fp)\n      cpp_reader *pfile;\n      FILE *fp;\n {\n-  cpp_token token;\n+  const cpp_token *token;\n \n-  cpp_get_token (pfile, &token);\n-  token.flags &= ~PREV_WHITE;\n-  while (token.type != CPP_EOF)\n+  token = cpp_get_token (pfile);\n+  while (token->type != CPP_EOF)\n     {\n-      cpp_output_token (&token, fp);\n-      cpp_get_token (pfile, &token);\n+      cpp_output_token (token, fp);\n+      token = cpp_get_token (pfile);\n+      if (token->flags & PREV_WHITE)\n+\tputc (' ', fp);\n     }\n \n   putc ('\\n', fp);"}, {"sha": "d164b4e249279a5dba44ebbbbbbf40068ab00e78", "filename": "gcc/cpplib.c", "status": "modified", "additions": 103, "deletions": 84, "changes": 187, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcpplib.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcpplib.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplib.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -86,8 +86,8 @@ static void directive_diagnostics\n \tPARAMS ((cpp_reader *, const directive *, int));\n static void run_directive\tPARAMS ((cpp_reader *, int,\n \t\t\t\t\t const char *, size_t));\n-static int glue_header_name\tPARAMS ((cpp_reader *, cpp_token *));\n-static int  parse_include\tPARAMS ((cpp_reader *, cpp_token *));\n+static const cpp_token *glue_header_name PARAMS ((cpp_reader *));\n+static const cpp_token *parse_include PARAMS ((cpp_reader *));\n static void push_conditional\tPARAMS ((cpp_reader *, int, int,\n \t\t\t\t\t const cpp_hashnode *));\n static unsigned int read_flag\tPARAMS ((cpp_reader *, unsigned int));\n@@ -100,7 +100,8 @@ static void do_pragma_once\tPARAMS ((cpp_reader *));\n static void do_pragma_poison\tPARAMS ((cpp_reader *));\n static void do_pragma_system_header\tPARAMS ((cpp_reader *));\n static void do_pragma_dependency\tPARAMS ((cpp_reader *));\n-static int get__Pragma_string\tPARAMS ((cpp_reader *, cpp_token *));\n+static const cpp_token *get_token_no_padding PARAMS ((cpp_reader *));\n+static const cpp_token *get__Pragma_string PARAMS ((cpp_reader *));\n static unsigned char *destringize\tPARAMS ((const cpp_string *,\n \t\t\t\t\t\t unsigned int *));\n static int parse_answer PARAMS ((cpp_reader *, struct answer **, int));\n@@ -485,13 +486,13 @@ do_undef (pfile)\n \n /* Helper routine used by parse_include.  Reinterpret the current line\n    as an h-char-sequence (< ... >); we are looking at the first token\n-   after the <.  Returns zero on success.  */\n-static int\n-glue_header_name (pfile, header)\n+   after the <.  Returns the header as a token, or NULL on failure.  */\n+static const cpp_token *\n+glue_header_name (pfile)\n      cpp_reader *pfile;\n-     cpp_token *header;\n {\n-  cpp_token token;\n+  cpp_token *header = NULL;\n+  const cpp_token *token;\n   unsigned char *buffer, *token_mem;\n   size_t len, total_len = 0, capacity = 1024;\n \n@@ -501,76 +502,79 @@ glue_header_name (pfile, header)\n   buffer = (unsigned char *) xmalloc (capacity);\n   for (;;)\n     {\n-      cpp_get_token (pfile, &token);\n+      token = cpp_get_token (pfile);\n \n-      if (token.type == CPP_GREATER || token.type == CPP_EOF)\n+      if (token->type == CPP_GREATER || token->type == CPP_EOF)\n \tbreak;\n \n-      len = cpp_token_len (&token);\n+      len = cpp_token_len (token);\n       if (total_len + len > capacity)\n \t{\n \t  capacity = (capacity + len) * 2;\n \t  buffer = (unsigned char *) xrealloc (buffer, capacity);\n \t}\n \n-      if (token.flags & PREV_WHITE)\n+      if (token->flags & PREV_WHITE)\n \tbuffer[total_len++] = ' ';\n \n-      total_len = cpp_spell_token (pfile, &token, &buffer[total_len]) - buffer;\n+      total_len = cpp_spell_token (pfile, token, &buffer[total_len]) - buffer;\n     }\n \n-  if (token.type == CPP_EOF)\n+  if (token->type == CPP_EOF)\n     cpp_error (pfile, \"missing terminating > character\");\n   else\n     {\n       token_mem = _cpp_pool_alloc (&pfile->ident_pool, total_len + 1);\n       memcpy (token_mem, buffer, total_len);\n       token_mem[total_len] = '\\0';\n \n+      header = _cpp_temp_token (pfile);\n       header->type = CPP_HEADER_NAME;\n       header->flags &= ~PREV_WHITE;\n       header->val.str.len = total_len;\n       header->val.str.text = token_mem;\n     }\n \n   free ((PTR) buffer);\n-  return token.type == CPP_EOF;\n+  return header;\n }\n \n-/* Parse the header name of #include, #include_next, #import and\n-   #pragma dependency.  Returns zero on success.  */\n-static int\n-parse_include (pfile, header)\n+/* Returns the header string of #include, #include_next, #import and\n+   #pragma dependency.  Returns NULL on error.  */\n+static const cpp_token *\n+parse_include (pfile)\n      cpp_reader *pfile;\n-     cpp_token *header;\n {\n   const unsigned char *dir;\n+  const cpp_token *header;\n \n   if (pfile->directive == &dtable[T_PRAGMA])\n     dir = U\"pragma dependency\";\n   else\n     dir = pfile->directive->name;\n \n   /* Allow macro expansion.  */\n-  cpp_get_token (pfile, header);\n+  header = cpp_get_token (pfile);\n   if (header->type != CPP_STRING && header->type != CPP_HEADER_NAME)\n     {\n       if (header->type != CPP_LESS)\n \t{\n \t  cpp_error (pfile, \"#%s expects \\\"FILENAME\\\" or <FILENAME>\", dir);\n-\t  return 1;\n+\t  return NULL;\n \t}\n-      if (glue_header_name (pfile, header))\n-\treturn 1;\n+\n+      header = glue_header_name (pfile);\n+      if (header == NULL)\n+\treturn header;\n     }\n \n   if (header->val.str.len == 0)\n     {\n       cpp_error (pfile, \"empty file name in #%s\", dir);\n-      return 1;\n+      return NULL;\n     }\n \n-  return 0;\n+  return header;\n }\n \n /* Handle #include, #include_next and #import.  */\n@@ -579,7 +583,7 @@ do_include_common (pfile, type)\n      cpp_reader *pfile;\n      enum include_type type;\n {\n-  cpp_token header;\n+  const cpp_token *header;\n \n   /* For #include_next, if this is the primary source file, warn and\n      use the normal search logic.  */\n@@ -595,7 +599,8 @@ do_include_common (pfile, type)\n \t   \"#import is obsolete, use an #ifndef wrapper in the header file\");\n     }\n \n-  if (!parse_include (pfile, &header))\n+  header = parse_include (pfile);\n+  if (header)\n     {\n       /* Prevent #include recursion.  */\n       if (pfile->line_maps.depth >= CPP_STACK_MAX)\n@@ -607,9 +612,9 @@ do_include_common (pfile, type)\n \t  skip_rest_of_line (pfile);\n \t  if (pfile->cb.include)\n \t    (*pfile->cb.include) (pfile, pfile->directive_line,\n-\t\t\t\t  pfile->directive->name, &header);\n+\t\t\t\t  pfile->directive->name, header);\n \n-\t  _cpp_execute_include (pfile, &header, type);\n+\t  _cpp_execute_include (pfile, header, type);\n \t}\n     }\n }\n@@ -693,7 +698,7 @@ static void\n do_line (pfile)\n      cpp_reader *pfile;\n {\n-  cpp_token token;\n+  const cpp_token *token;\n   const char *new_file = pfile->map->to_file;\n   unsigned long new_lineno;\n   unsigned int cap, new_sysp = pfile->map->sysp;\n@@ -708,23 +713,24 @@ do_line (pfile)\n     _cpp_backup_tokens (pfile, 1);\n \n   /* #line commands expand macros.  */\n-  cpp_get_token (pfile, &token);\n-  if (token.type != CPP_NUMBER\n-      || strtoul_for_line (token.val.str.text, token.val.str.len, &new_lineno))\n+  token = cpp_get_token (pfile);\n+  if (token->type != CPP_NUMBER\n+      || strtoul_for_line (token->val.str.text, token->val.str.len,\n+\t\t\t   &new_lineno))\n     {\n       cpp_error (pfile, \"\\\"%s\\\" after #line is not a positive integer\",\n-\t\t cpp_token_as_text (pfile, &token));\n+\t\t cpp_token_as_text (pfile, token));\n       return;\n     }      \n \n   if (CPP_PEDANTIC (pfile) && ! pfile->state.line_extension\n       && (new_lineno == 0 || new_lineno > cap))\n     cpp_pedwarn (pfile, \"line number out of range\");\n \n-  cpp_get_token (pfile, &token);\n-  if (token.type == CPP_STRING)\n+  token = cpp_get_token (pfile);\n+  if (token->type == CPP_STRING)\n     {\n-      new_file = (const char *) token.val.str.text;\n+      new_file = (const char *) token->val.str.text;\n \n       /* Only accept flags for the # 55 form.  */\n       if (pfile->state.line_extension)\n@@ -755,10 +761,10 @@ do_line (pfile)\n \t}\n       check_eol (pfile);\n     }\n-  else if (token.type != CPP_EOF)\n+  else if (token->type != CPP_EOF)\n     {\n       cpp_error (pfile, \"\\\"%s\\\" is not a valid filename\",\n-\t\t cpp_token_as_text (pfile, &token));\n+\t\t cpp_token_as_text (pfile, token));\n       return;\n     }\n \n@@ -827,13 +833,12 @@ static void\n do_ident (pfile)\n      cpp_reader *pfile;\n {\n-  cpp_token str;\n+  const cpp_token *str = cpp_get_token (pfile);\n \n-  cpp_get_token (pfile, &str);\n-  if (str.type != CPP_STRING)\n-    cpp_error (pfile, \"invalid #ident\");\n+  if (str->type != CPP_STRING)\n+    cpp_error (pfile, \"invalid #ident directive\");\n   else if (pfile->cb.ident)\n-    (*pfile->cb.ident) (pfile, pfile->directive_line, &str.val.str);\n+    (*pfile->cb.ident) (pfile, pfile->directive_line, &str->val.str);\n \n   check_eol (pfile);\n }\n@@ -950,18 +955,18 @@ do_pragma (pfile)\n {\n   pragma_cb handler = NULL;\n   const struct pragma_entry *p;\n-  cpp_token tok;\n+  const cpp_token *token;\n   unsigned int count = 0;\n \n   p = pfile->pragmas;\n   pfile->state.prevent_expansion++;\n \n  new_space:\n   count++;\n-  cpp_get_token (pfile, &tok);\n-  if (tok.type == CPP_NAME)\n+  token = cpp_get_token (pfile);\n+  if (token->type == CPP_NAME)\n     {\n-      const cpp_hashnode *node = tok.val.node;\n+      const cpp_hashnode *node = token->val.node;\n       size_t len = NODE_LEN (node);\n \n       while (p)\n@@ -990,7 +995,7 @@ do_pragma (pfile)\n      themselves.  Stand-alone CPP must ignore us, otherwise it will\n      prefix the directive with spaces, hence the 1.  Ugh.  */\n   if (pfile->cb.line_change)\n-    (*pfile->cb.line_change)(pfile, &tok, 1);\n+    (*pfile->cb.line_change)(pfile, token, 1);\n \n   if (handler)\n     (*handler) (pfile);\n@@ -1078,47 +1083,61 @@ static void\n do_pragma_dependency (pfile)\n      cpp_reader *pfile;\n {\n-  cpp_token header, msg;\n+  const cpp_token *header;\n   int ordering;\n  \n-  if (parse_include (pfile, &header))\n+  header = parse_include (pfile);\n+  if (!header)\n     return;\n \n-  ordering = _cpp_compare_file_date (pfile, &header);\n+  ordering = _cpp_compare_file_date (pfile, header);\n   if (ordering < 0)\n     cpp_warning (pfile, \"cannot find source %s\",\n-\t\t cpp_token_as_text (pfile, &header));\n+\t\t cpp_token_as_text (pfile, header));\n   else if (ordering > 0)\n     {\n       cpp_warning (pfile, \"current file is older than %s\",\n-\t\t   cpp_token_as_text (pfile, &header));\n-      cpp_get_token (pfile, &msg);\n-      if (msg.type != CPP_EOF)\n+\t\t   cpp_token_as_text (pfile, header));\n+      if (cpp_get_token (pfile)->type != CPP_EOF)\n \t{\n \t  _cpp_backup_tokens (pfile, 1);\n \t  do_diagnostic (pfile, WARNING, 0);\n \t}\n     }\n }\n \n-/* Check syntax is \"(string-literal)\".  Returns 0 on success.  */\n-static int\n-get__Pragma_string (pfile, string)\n+/* Get a token but skip padding.  */\n+static const cpp_token *\n+get_token_no_padding (pfile)\n      cpp_reader *pfile;\n-     cpp_token *string;\n {\n-  cpp_token paren;\n+  for (;;)\n+    {\n+      const cpp_token *result = cpp_get_token (pfile);\n+      if (result->type != CPP_PADDING)\n+\treturn result;\n+    }\n+}\n \n-  cpp_get_token (pfile, &paren);\n-  if (paren.type != CPP_OPEN_PAREN)\n-    return 1;\n+/* Check syntax is \"(string-literal)\".  Returns the string on success,\n+   or NULL on failure.  */\n+static const cpp_token *\n+get__Pragma_string (pfile)\n+     cpp_reader *pfile;\n+{\n+  const cpp_token *string;\n \n-  cpp_get_token (pfile, string);\n+  if (get_token_no_padding (pfile)->type != CPP_OPEN_PAREN)\n+    return NULL;\n+\n+  string = get_token_no_padding (pfile);\n   if (string->type != CPP_STRING && string->type != CPP_WSTRING)\n-    return 1;\n+    return NULL;\n+\n+  if (get_token_no_padding (pfile)->type != CPP_CLOSE_PAREN)\n+    return NULL;\n \n-  cpp_get_token (pfile, &paren);\n-  return paren.type != CPP_CLOSE_PAREN;\n+  return string;\n }\n \n /* Returns a malloced buffer containing a destringized cpp_string by\n@@ -1148,11 +1167,11 @@ void\n _cpp_do__Pragma (pfile)\n      cpp_reader *pfile;\n {\n-  cpp_token string;\n+  const cpp_token *string = get__Pragma_string (pfile);\n   unsigned char *buffer;\n   unsigned int len;\n \n-  if (get__Pragma_string (pfile, &string))\n+  if (!string)\n     cpp_error (pfile, \"_Pragma takes a parenthesized string literal\");\n   else\n     {\n@@ -1167,7 +1186,7 @@ _cpp_do__Pragma (pfile)\n \t Getting these correct line markers is a little tricky.  */\n \n       unsigned int orig_line = pfile->line;\n-      buffer = destringize (&string.val.str, &len);\n+      buffer = destringize (&string->val.str, &len);\n       run_directive (pfile, T_PRAGMA, (char *) buffer, len);\n       free ((PTR) buffer);\n       pfile->line = orig_line;\n@@ -1386,7 +1405,7 @@ parse_answer (pfile, answerp, type)\n      struct answer **answerp;\n      int type;\n {\n-  cpp_token paren, *token;\n+  const cpp_token *paren;\n   struct answer *answer;\n \n   if (POOL_FRONT (&pfile->macro_pool) + sizeof (struct answer) >\n@@ -1397,10 +1416,10 @@ parse_answer (pfile, answerp, type)\n \n   /* In a conditional, it is legal to not have an open paren.  We\n      should save the following token in this case.  */\n-  cpp_get_token (pfile, &paren);\n+  paren = cpp_get_token (pfile);\n \n   /* If not a paren, see if we're OK.  */\n-  if (paren.type != CPP_OPEN_PAREN)\n+  if (paren->type != CPP_OPEN_PAREN)\n     {\n       /* In a conditional no answer is a test for any answer.  It\n          could be followed by any token.  */\n@@ -1411,7 +1430,7 @@ parse_answer (pfile, answerp, type)\n \t}\n \n       /* #unassert with no answer is valid - it removes all answers.  */\n-      if (type == T_UNASSERT && paren.type == CPP_EOF)\n+      if (type == T_UNASSERT && paren->type == CPP_EOF)\n \treturn 0;\n \n       cpp_error (pfile, \"missing '(' after predicate\");\n@@ -1420,7 +1439,7 @@ parse_answer (pfile, answerp, type)\n \n   for (;;)\n     {\n-      token = &answer->first[answer->count];\n+      cpp_token *token = &answer->first[answer->count];\n       /* Check we have room for the token.  */\n       if ((unsigned char *) (token + 1) >= POOL_LIMIT (&pfile->macro_pool))\n \t{\n@@ -1429,7 +1448,7 @@ parse_answer (pfile, answerp, type)\n \t  token = &answer->first[answer->count];\n \t}\n \n-      cpp_get_token (pfile, token);\n+      *token = *cpp_get_token (pfile);\n       if (token->type == CPP_CLOSE_PAREN)\n \tbreak;\n \n@@ -1466,25 +1485,25 @@ parse_assertion (pfile, answerp, type)\n      int type;\n {\n   cpp_hashnode *result = 0;\n-  cpp_token predicate;\n+  const cpp_token *predicate;\n \n   /* We don't expand predicates or answers.  */\n   pfile->state.prevent_expansion++;\n \n   *answerp = 0;\n-  cpp_get_token (pfile, &predicate);\n-  if (predicate.type == CPP_EOF)\n+  predicate = cpp_get_token (pfile);\n+  if (predicate->type == CPP_EOF)\n     cpp_error (pfile, \"assertion without predicate\");\n-  else if (predicate.type != CPP_NAME)\n+  else if (predicate->type != CPP_NAME)\n     cpp_error (pfile, \"predicate must be an identifier\");\n   else if (parse_answer (pfile, answerp, type) == 0)\n     {\n-      unsigned int len = NODE_LEN (predicate.val.node);\n+      unsigned int len = NODE_LEN (predicate->val.node);\n       unsigned char *sym = alloca (len + 1);\n \n       /* Prefix '#' to get it out of macro namespace.  */\n       sym[0] = '#';\n-      memcpy (sym + 1, NODE_NAME (predicate.val.node), len);\n+      memcpy (sym + 1, NODE_NAME (predicate->val.node), len);\n       result = cpp_lookup (pfile, sym, len + 1);\n     }\n "}, {"sha": "b8db3663794efbfedb8b063af7ce452125561a45", "filename": "gcc/cpplib.h", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcpplib.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcpplib.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcpplib.h?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -134,6 +134,7 @@ struct file_name_map_list;\n \\\n   TK(CPP_COMMENT,\tSPELL_STRING)\t/* Only if output comments.  */ \\\n   TK(CPP_MACRO_ARG,\tSPELL_NONE)\t/* Macro argument.  */\t\t\\\n+  OP(CPP_PADDING,\t\"\")\t\t/* Whitespace for cpp0.  */\t\\\n   OP(CPP_EOF,\t\t\"EOL\")\t\t/* End of line or file.  */\n \n #define OP(e, s) e,\n@@ -164,8 +165,7 @@ struct cpp_string\n #define PASTE_LEFT\t(1 << 3) /* If on LHS of a ## operator.  */\n #define NAMED_OP\t(1 << 4) /* C++ named operators.  */\n #define NO_EXPAND\t(1 << 5) /* Do not macro-expand this token.  */\n-#define AVOID_LPASTE\t(1 << 6) /* Check left for accidental pastes.  */\n-#define BOL\t\t(1 << 7) /* Token at beginning of line.  */\n+#define BOL\t\t(1 << 6) /* Token at beginning of line.  */\n \n /* A preprocessing token.  This has been carefully packed and should\n    occupy 12 bytes on 32-bit hosts and 16 bytes on 64-bit hosts.  */\n@@ -179,6 +179,7 @@ struct cpp_token\n   union\n   {\n     cpp_hashnode *node;\t\t/* An identifier.  */\n+    const cpp_token *source;\t/* Inherit padding from this token.  */\n     struct cpp_string str;\t/* A string, or number.  */\n     unsigned int arg_no;\t/* Argument no. for a CPP_MACRO_ARG.  */\n     unsigned char c;\t\t/* Character represented by CPP_OTHER.  */\n@@ -235,6 +236,9 @@ struct cpp_options\n   /* The language we're preprocessing.  */\n   enum c_lang lang;\n \n+  /* Nonzero means to return spacing characters for stand-alone CPP.  */\n+  unsigned char spacing;\n+\n   /* Non-0 means -v, so print the full set of include dirs.  */\n   unsigned char verbose;\n \n@@ -497,7 +501,7 @@ extern int cpp_avoid_paste PARAMS ((cpp_reader *, const cpp_token *,\n \t\t\t\t    const cpp_token *));\n extern enum cpp_ttype cpp_can_paste PARAMS ((cpp_reader *, const cpp_token *,\n \t\t\t\t\t     const cpp_token *, int *));\n-extern void cpp_get_token PARAMS ((cpp_reader *, cpp_token *));\n+extern const cpp_token *cpp_get_token PARAMS ((cpp_reader *));\n extern const unsigned char *cpp_macro_definition PARAMS ((cpp_reader *,\n \t\t\t\t\t\t  const cpp_hashnode *));\n extern void _cpp_backup_tokens PARAMS ((cpp_reader *, unsigned int));"}, {"sha": "6cc45022288a5f48385f3e507490a8575a0e4386", "filename": "gcc/cppmacro.c", "status": "modified", "additions": 387, "deletions": 336, "changes": 723, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcppmacro.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcppmacro.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppmacro.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -45,9 +45,9 @@ struct cpp_macro\n typedef struct macro_arg macro_arg;\n struct macro_arg\n {\n-  cpp_token *first;\t\t/* First token in unexpanded argument.  */\n-  cpp_token *expanded;\t\t/* Macro-expanded argument.   */\n-  cpp_token *stringified;\t/* Stringified argument.  */\n+  const cpp_token **first;\t/* First token in unexpanded argument.  */\n+  const cpp_token **expanded;\t/* Macro-expanded argument.   */\n+  const cpp_token *stringified;\t/* Stringified argument.  */\n   unsigned int count;\t\t/* # of tokens in argument.  */\n   unsigned int expanded_count;\t/* # of tokens in expanded argument.  */\n };\n@@ -57,25 +57,29 @@ struct macro_arg\n static void lock_pools PARAMS ((cpp_reader *));\n static void unlock_pools PARAMS ((cpp_reader *));\n static int enter_macro_context PARAMS ((cpp_reader *, cpp_hashnode *));\n-static void builtin_macro PARAMS ((cpp_reader *, cpp_token *));\n-static cpp_context *push_arg_context PARAMS ((cpp_reader *, macro_arg *));\n+static const cpp_token *builtin_macro PARAMS ((cpp_reader *, cpp_hashnode *));\n+static void push_token_context\n+  PARAMS ((cpp_reader *, cpp_macro *, const cpp_token *, unsigned int));\n+static void push_ptoken_context\n+  PARAMS ((cpp_reader *, cpp_macro *, const cpp_token **, unsigned int));\n static enum cpp_ttype parse_arg PARAMS ((cpp_reader *, macro_arg *, int));\n static macro_arg *parse_args PARAMS ((cpp_reader *, const cpp_hashnode *));\n static cpp_context *next_context PARAMS ((cpp_reader *));\n+static const cpp_token *padding_token\n+  PARAMS ((cpp_reader *, const cpp_token *));\n static void expand_arg PARAMS ((cpp_reader *, macro_arg *));\n static unsigned char *quote_string PARAMS ((unsigned char *,\n \t\t\t\t\t    const unsigned char *,\n \t\t\t\t\t    unsigned int));\n-static void make_string_token PARAMS ((cpp_pool *, cpp_token *,\n-\t\t\t\t       const U_CHAR *, unsigned int));\n-static void make_number_token PARAMS ((cpp_reader *, cpp_token *, int));\n-static void stringify_arg PARAMS ((cpp_reader *, macro_arg *));\n-static void paste_all_tokens PARAMS ((cpp_reader *, cpp_token *));\n-static int paste_tokens PARAMS ((cpp_reader *, cpp_token *, cpp_token *));\n-static int funlike_invocation_p PARAMS ((cpp_reader *, const cpp_hashnode *,\n-\t\t\t\t\t  struct toklist *));\n-static void replace_args PARAMS ((cpp_reader *, cpp_macro *, macro_arg *,\n-\t\t\t\t  struct toklist *));\n+static const cpp_token *new_string_token PARAMS ((cpp_reader *, U_CHAR *,\n+\t\t\t\t\t\t  unsigned int));\n+static const cpp_token *new_number_token PARAMS ((cpp_reader *, int));\n+static const cpp_token *stringify_arg PARAMS ((cpp_reader *, macro_arg *));\n+static void paste_all_tokens PARAMS ((cpp_reader *, const cpp_token *));\n+static int paste_tokens PARAMS ((cpp_reader *, cpp_token *,\n+\t\t\t\t const cpp_token *));\n+static int funlike_invocation_p PARAMS ((cpp_reader *, const cpp_hashnode *));\n+static void replace_args PARAMS ((cpp_reader *, cpp_macro *, macro_arg *));\n \n /* #define directive parsing and handling.  */\n \n@@ -89,39 +93,39 @@ static void check_trad_stringification PARAMS ((cpp_reader *,\n \t\t\t\t\t\tconst cpp_macro *,\n \t\t\t\t\t\tconst cpp_string *));\n \n-/* Allocates a buffer to hold a token's TEXT, and converts TOKEN to a\n-   CPP_STRING token containing TEXT in quoted form.  */\n-static void\n-make_string_token (pool, token, text, len)\n-     cpp_pool *pool;\n-     cpp_token *token;\n-     const U_CHAR *text;\n+/* Allocates and returns a CPP_STRING token, containing TEXT of length\n+   LEN, after null-terminating it.  TEXT must be in permanent storage.  */\n+static const cpp_token *\n+new_string_token (pfile, text, len)\n+     cpp_reader *pfile;\n+     unsigned char *text;\n      unsigned int len;\n {\n-  U_CHAR *buf = _cpp_pool_alloc (pool, len * 4 + 1);\n+  cpp_token *token = _cpp_temp_token (pfile);\n \n+  text[len] = '\\0';\n   token->type = CPP_STRING;\n-  token->val.str.text = buf;\n-  token->val.str.len = quote_string (buf, text, len) - buf;\n-  buf[token->val.str.len] = '\\0';\n+  token->val.str.len = len;\n+  token->val.str.text = text;\n   token->flags = 0;\n+  return token;\n }\n \n-/* Allocates and converts a temporary token to a CPP_NUMBER token,\n-   evaluating to NUMBER.  */\n-static void\n-make_number_token (pfile, token, number)\n+/* Allocates and returns a CPP_NUMBER token evaluating to NUMBER.  */\n+static const cpp_token *\n+new_number_token (pfile, number)\n      cpp_reader *pfile;\n-     cpp_token *token;\n      int number;\n {\n+  cpp_token *token = _cpp_temp_token (pfile);\n   unsigned char *buf = _cpp_pool_alloc (&pfile->ident_pool, 20);\n \n   sprintf ((char *) buf, \"%d\", number);\n   token->type = CPP_NUMBER;\n   token->val.str.text = buf;\n   token->val.str.len = ustrlen (buf);\n   token->flags = 0;\n+  return token;\n }\n \n static const char * const monthnames[] =\n@@ -131,85 +135,87 @@ static const char * const monthnames[] =\n };\n \n /* Handle builtin macros like __FILE__.  */\n-static void\n-builtin_macro (pfile, token)\n+static const cpp_token *\n+builtin_macro (pfile, node)\n      cpp_reader *pfile;\n-     cpp_token *token;\n+     cpp_hashnode *node;\n {\n-  unsigned char flags = ((token->flags & (PREV_WHITE | BOL)) | AVOID_LPASTE);\n-  cpp_hashnode *node = token->val.node;\n-\n   switch (node->value.builtin)\n     {\n+    default:\n+      cpp_ice (pfile, \"invalid builtin macro \\\"%s\\\"\", NODE_NAME (node));\n+      return new_number_token (pfile, 1);\n+\n     case BT_FILE:\n     case BT_BASE_FILE:\n       {\n+\tunsigned int len;\n \tconst char *name;\n+\tU_CHAR *buf;\n \tconst struct line_map *map = pfile->map;\n \n \tif (node->value.builtin == BT_BASE_FILE)\n \t  while (! MAIN_FILE_P (map))\n \t    map = INCLUDED_FROM (&pfile->line_maps, map);\n \n \tname = map->to_file;\n-\tmake_string_token (&pfile->ident_pool, token,\n-\t\t\t   (const unsigned char *) name, strlen (name));\n+\tlen = strlen (name);\n+\tbuf = _cpp_pool_alloc (&pfile->ident_pool, len * 4 + 1);\n+\tlen = quote_string (buf, (const unsigned char *) name, len) - buf;\n+\n+\treturn new_string_token (pfile, buf, len);\n       }\n-      break;\n \t\n     case BT_INCLUDE_LEVEL:\n       /* The line map depth counts the primary source as level 1, but\n \t historically __INCLUDE_DEPTH__ has called the primary source\n \t level 0.  */\n-      make_number_token (pfile, token, pfile->line_maps.depth - 1);\n-      break;\n+      return new_number_token (pfile, pfile->line_maps.depth - 1);\n \n     case BT_SPECLINE:\n       /* If __LINE__ is embedded in a macro, it must expand to the\n \t line of the macro's invocation, not its definition.\n \t Otherwise things like assert() will not work properly.  */\n-      make_number_token (pfile, token,\n-\t\t\t SOURCE_LINE (pfile->map, pfile->cur_token[-1].line));\n-      break;\n+      return new_number_token (pfile, SOURCE_LINE (pfile->map,\n+\t\t\t\t\t\t   pfile->cur_token[-1].line));\n \n     case BT_STDC:\n       {\n \tint stdc = (!CPP_IN_SYSTEM_HEADER (pfile)\n \t\t    || pfile->spec_nodes.n__STRICT_ANSI__->type != NT_VOID);\n-\tmake_number_token (pfile, token, stdc);\n+\treturn new_number_token (pfile, stdc);\n       }\n-      break;\n \n     case BT_DATE:\n     case BT_TIME:\n       if (pfile->date.type == CPP_EOF)\n \t{\n-\t  /* Allocate __DATE__ and __TIME__ from permanent storage,\n-\t     and save them in pfile so we don't have to do this again.\n-\t     We don't generate these strings at init time because\n-\t     time() and localtime() are very slow on some systems.  */\n+\t  /* Allocate __DATE__ and __TIME__ strings from permanent\n+\t     storage.  We only do this once, and don't generate them\n+\t     at init time, because time() and localtime() are very\n+\t     slow on some systems.  */\n \t  time_t tt = time (NULL);\n \t  struct tm *tb = localtime (&tt);\n \n-\t  make_string_token (&pfile->ident_pool, &pfile->date,\n-\t\t\t     DSC(\"Oct 11 1347\"));\n-\t  make_string_token (&pfile->ident_pool, &pfile->time,\n-\t\t\t     DSC(\"12:34:56\"));\n-\n+\t  pfile->date.val.str.text =\n+\t    _cpp_pool_alloc (&pfile->ident_pool, sizeof (\"Oct 11 1347\"));\n+\t  pfile->date.val.str.len = sizeof (\"Oct 11 1347\") - 1;\n+\t  pfile->date.type = CPP_STRING;\n+\t  pfile->date.flags = 0;\n \t  sprintf ((char *) pfile->date.val.str.text, \"%s %2d %4d\",\n \t\t   monthnames[tb->tm_mon], tb->tm_mday, tb->tm_year + 1900);\n+\n+\t  pfile->time.val.str.text =\n+\t    _cpp_pool_alloc (&pfile->ident_pool, sizeof (\"12:34:56\"));\n+\t  pfile->time.val.str.len = sizeof (\"12:34:56\") - 1;\n+\t  pfile->time.type = CPP_STRING;\n+\t  pfile->time.flags = 0;\n \t  sprintf ((char *) pfile->time.val.str.text, \"%02d:%02d:%02d\",\n \t\t   tb->tm_hour, tb->tm_min, tb->tm_sec);\n \t}\n-      *token = node->value.builtin == BT_DATE ? pfile->date: pfile->time;\n-      break;\n \n-    default:\n-      cpp_ice (pfile, \"invalid builtin macro \\\"%s\\\"\", NODE_NAME (node));\n-      break;\n+      return node->value.builtin == BT_DATE ? &pfile->date: &pfile->time;\n     }\n-\n-  token->flags = flags;\n }\n \n static void\n@@ -260,25 +266,34 @@ quote_string (dest, src, len)\n \n /* Convert a token sequence to a single string token according to the\n    rules of the ISO C #-operator.  */\n-static void\n+static const cpp_token *\n stringify_arg (pfile, arg)\n      cpp_reader *pfile;\n      macro_arg *arg;\n {\n   cpp_pool *pool = &pfile->ident_pool;\n   unsigned char *start = POOL_FRONT (pool);\n   unsigned int i, escape_it, total_len = 0, backslash_count = 0;\n+  const cpp_token *source = NULL;\n \n   /* Loop, reading in the argument's tokens.  */\n   for (i = 0; i < arg->count; i++)\n     {\n       unsigned char *dest;\n-      const cpp_token *token = &arg->first[i];\n-      unsigned int len = cpp_token_len (token);\n+      const cpp_token *token = arg->first[i];\n+      unsigned int len;\n+\n+      if (token->type == CPP_PADDING)\n+\t{\n+\t  if (source == NULL)\n+\t    source = token->val.source;\n+\t  continue;\n+\t}\n \n       escape_it = (token->type == CPP_STRING || token->type == CPP_WSTRING\n \t\t   || token->type == CPP_CHAR || token->type == CPP_WCHAR);\n \n+      len = cpp_token_len (token);\n       if (escape_it)\n \t/* Worst case is each char is octal.  */\n \tlen *= 4;\n@@ -291,9 +306,15 @@ stringify_arg (pfile, arg)\n \t  dest = &start[total_len];\n \t}\n \n-      /* No leading white space.  */\n-      if (token->flags & PREV_WHITE && total_len > 0)\n-\t*dest++ = ' ';\n+      /* Leading white space?  */\n+      if (total_len)\n+\t{\n+\t  if (source == NULL)\n+\t    source = token;\n+\t  if (source->flags & PREV_WHITE)\n+\t    *dest++ = ' ';\n+\t}\n+      source = NULL;\n \n       if (escape_it)\n \t{\n@@ -320,15 +341,9 @@ stringify_arg (pfile, arg)\n       total_len--;\n     }\n \n-  /* Null terminate, and commit the memory.  */\n-  start[total_len] = '\\0';\n+  /* Commit the memory, including NUL, and return the token.  */\n   POOL_COMMIT (pool, total_len + 1);\n-\n-  arg->stringified = xnew (cpp_token);\n-  arg->stringified->flags = 0;\n-  arg->stringified->type = CPP_STRING;\n-  arg->stringified->val.str.text = start;\n-  arg->stringified->val.str.len = total_len;\n+  return new_string_token (pfile, start, total_len);\n }\n \n /* Try to paste two tokens.  On success, the LHS becomes the pasted\n@@ -337,9 +352,10 @@ stringify_arg (pfile, arg)\n static int\n paste_tokens (pfile, lhs, rhs)\n      cpp_reader *pfile;\n-     cpp_token *lhs, *rhs;\n+     cpp_token *lhs;\n+     const cpp_token *rhs;\n {\n-  unsigned char flags;\n+  unsigned char flags = 0;\n   int digraph = 0;\n   enum cpp_ttype type;\n \n@@ -353,20 +369,9 @@ paste_tokens (pfile, lhs, rhs)\n \t \"pasting \\\"%s\\\" and \\\"%s\\\" does not give a valid preprocessing token\",\n \t\t     cpp_token_as_text (pfile, lhs),\n \t\t     cpp_token_as_text (pfile, rhs));\n-\n-      /* The standard states that behaviour is undefined.  By the\n-         principle of least surpise, we step back before the RHS, and\n-         mark it to prevent macro expansion.  Tests in the testsuite\n-         rely on clearing PREV_WHITE here, though you could argue we\n-         should actually set it.  Assembler can have '.' in labels and\n-         so requires that we don't insert spaces there.  Maybe we should\n-\t change this to put out a space unless it's assembler.  */\n-      rhs->flags &= ~PREV_WHITE;\n-      rhs->flags |= NO_EXPAND;\n       return 1;\n     }\n \n-  flags = lhs->flags & ~DIGRAPH;\n   if (digraph)\n     flags |= DIGRAPH;\n \n@@ -416,10 +421,17 @@ paste_tokens (pfile, lhs, rhs)\n static void\n paste_all_tokens (pfile, lhs)\n      cpp_reader *pfile;\n-     cpp_token *lhs;\n+     const cpp_token *lhs;\n {\n-  cpp_token *rhs;\n-  unsigned char orig_flags = lhs->flags;\n+  cpp_token *pasted;\n+  const cpp_token *rhs;\n+  cpp_context *context = pfile->context;\n+\n+  /* Copy lhs to pasted, but preserve original line and column.  */\n+  pasted = _cpp_temp_token (pfile);\n+  pasted->type = lhs->type;\n+  pasted->flags = lhs->flags;\n+  pasted->val.str = lhs->val.str;\n \n   do\n     {\n@@ -428,20 +440,25 @@ paste_all_tokens (pfile, lhs)\n \t object-like macro, or a function-like macro with arguments\n \t inserted.  In either case, the constraints to #define\n \t guarantee we have at least one more token.  */\n-      rhs = pfile->context->list.first++;\n-      if (paste_tokens (pfile, lhs, rhs))\n+      if (context->direct_p)\n+\trhs = context->first.token++;\n+      else\n+\trhs = *context->first.ptoken++;\n+\n+      if (rhs->type == CPP_PADDING)\n+\tabort ();\n+\n+      if (paste_tokens (pfile, pasted, rhs))\n \t{\n-\t  /* We failed.  Step back so we read the RHS in next.  */\n-\t  pfile->context->list.first--;\n+\t  _cpp_backup_tokens (pfile, 1);\n \t  break;\n \t}\n     }\n   while (rhs->flags & PASTE_LEFT);\n \n-  /* The pasted token has the PREV_WHITE flag of the LHS, is no longer\n-     PASTE_LEFT, and is subject to macro expansion.  */\n-  lhs->flags &= ~(PREV_WHITE | BOL | PASTE_LEFT | NO_EXPAND);\n-  lhs->flags |= orig_flags & (PREV_WHITE | BOL | AVOID_LPASTE);\n+  /* Clear PASTE_LEFT flag, put the token in its own context.  */\n+  pasted->flags &= ~PASTE_LEFT;\n+  push_token_context (pfile, NULL, pasted, 1);\n }\n \n /* Reads the unexpanded tokens of a macro argument into ARG.  VAR_ARGS\n@@ -455,26 +472,24 @@ parse_arg (pfile, arg, variadic)\n {\n   enum cpp_ttype result;\n   unsigned int paren = 0;\n-  unsigned int line;\n \n-  arg->first = (cpp_token *) POOL_FRONT (&pfile->argument_pool);\n+  arg->first = (const cpp_token **) POOL_FRONT (&pfile->argument_pool);\n   for (;; arg->count++)\n     {\n-      cpp_token *token = &arg->first[arg->count];\n-      if ((unsigned char *) (token + 1) >= POOL_LIMIT (&pfile->argument_pool))\n+      const cpp_token *token;\n+      const cpp_token **ptoken = &arg->first[arg->count];\n+      if ((unsigned char *) (ptoken + 2) >= POOL_LIMIT (&pfile->argument_pool))\n \t{\n-\t  _cpp_next_chunk (&pfile->argument_pool, sizeof (cpp_token),\n+\t  _cpp_next_chunk (&pfile->argument_pool, 2 * sizeof (cpp_token *),\n \t\t\t   (unsigned char **) &arg->first);\n-\t  token = &arg->first[arg->count];\n+\t  ptoken = &arg->first[arg->count];\n \t}\n \n-      /* Newlines in arguments are white space (6.10.3.10).  */\n-      line = pfile->line;\n-      cpp_get_token (pfile, token);\n-\n-      if (line != pfile->line)\n-\ttoken->flags |= PREV_WHITE;\n-\n+      /* Drop leading padding.  */\n+      do\n+\ttoken = cpp_get_token (pfile);\n+      while (arg->count == 0 && token->type == CPP_PADDING);\n+      *ptoken++ = token;\n       result = token->type;\n \n       if (result == CPP_OPEN_PAREN)\n@@ -511,12 +526,15 @@ parse_arg (pfile, arg, variadic)\n \t}\n     }\n \n+  /* Drop trailing padding.  */\n+  while (arg->count > 0 && arg->first[arg->count - 1]->type == CPP_PADDING)\n+    arg->count--;\n+\n   /* Commit the memory used to store the arguments.  We make the last\n      argument a CPP_EOF, so that it terminates macro pre-expansion,\n      but it is not included in arg->count.  */\n-  arg->first[arg->count].type = CPP_EOF;  \n-  POOL_COMMIT (&pfile->argument_pool, (arg->count + 1) * sizeof (cpp_token));\n-\n+  arg->first[arg->count] = &pfile->eof;  \n+  POOL_COMMIT (&pfile->argument_pool, (arg->count + 1) * sizeof (cpp_token *));\n   return result;\n }\n \n@@ -599,22 +617,23 @@ parse_args (pfile, node)\n }\n \n static int\n-funlike_invocation_p (pfile, node, list)\n+funlike_invocation_p (pfile, node)\n      cpp_reader *pfile;\n      const cpp_hashnode *node;\n-     struct toklist *list;\n {\n-  cpp_token maybe_paren;\n+  const cpp_token *maybe_paren;\n   macro_arg *args = 0;\n \n-  pfile->state.parsing_args = 1;\n   pfile->state.prevent_expansion++;\n-\n   pfile->keep_tokens++;\n-  cpp_get_token (pfile, &maybe_paren);\n+\n+  pfile->state.parsing_args = 1;\n+  do\n+    maybe_paren = cpp_get_token (pfile);\n+  while (maybe_paren->type == CPP_PADDING);\n   pfile->state.parsing_args = 2;\n \n-  if (maybe_paren.type == CPP_OPEN_PAREN)\n+  if (maybe_paren->type == CPP_OPEN_PAREN)\n     args = parse_args (pfile, node);\n   else\n     {\n@@ -625,14 +644,14 @@ funlike_invocation_p (pfile, node, list)\n \t\t     NODE_NAME (node));\n     }\n \n-  pfile->state.prevent_expansion--;\n   pfile->state.parsing_args = 0;\n   pfile->keep_tokens--;\n+  pfile->state.prevent_expansion--;\n \n   if (args)\n     {\n       if (node->value.macro->paramc > 0)\n-\treplace_args (pfile, node->value.macro, args, list);\n+\treplace_args (pfile, node->value.macro, args);\n       free (args);\n     }\n \n@@ -648,247 +667,288 @@ enter_macro_context (pfile, node)\n      cpp_reader *pfile;\n      cpp_hashnode *node;\n {\n-  cpp_context *context;\n-  cpp_macro *macro = node->value.macro;\n-  struct toklist list;\n-\n-  /* Save the position of the outermost macro invocation.  */\n-  if (!pfile->context->prev)\n-    lock_pools (pfile);\n-\n-  if (macro->fun_like && !funlike_invocation_p (pfile, node, &list))\n-    {\n-      if (!pfile->context->prev)\n-\tunlock_pools (pfile);\n-      return 0;\n-    }\n-\n-  if (macro->paramc == 0)\n+  if (node->flags & NODE_BUILTIN)\n+    push_token_context (pfile, NULL, builtin_macro (pfile, node), 1);\n+  else\n     {\n-      list.first = macro->expansion;\n-      list.limit = macro->expansion + macro->count;\n-    }\n+      cpp_macro *macro = node->value.macro;\n \n-  context = next_context (pfile);\n-  context->list = list;\n-  context->macro = macro;\n-      \n-  /* Disable the macro within its expansion.  */\n-  macro->disabled = 1;\n+      if (!pfile->context->prev)\n+\tlock_pools (pfile);\n \n-  return 1;\n-}\n+      if (macro->fun_like && !funlike_invocation_p (pfile, node))\n+\t{\n+\t  if (!pfile->context->prev)\n+\t    unlock_pools (pfile);\n+\t  return 0;\n+\t}\n \n-/* Move to the next context.  Create one if there is none.  */\n-static cpp_context *\n-next_context (pfile)\n-     cpp_reader *pfile;\n-{\n-  cpp_context *prev = pfile->context;\n-  cpp_context *result = prev->next;\n+      /* Disable the macro within its expansion.  */\n+      macro->disabled = 1;\n \n-  if (result == 0)\n-    {\n-      result = xnew (cpp_context);\n-      prev->next = result;\n-      result->prev = prev;\n-      result->next = 0;\n+      if (macro->paramc == 0)\n+\tpush_token_context (pfile, macro, macro->expansion, macro->count);\n     }\n-\n-  pfile->context = result;\n-  return result;\n+ \n+  return 1;\n }\n \n+/* Take the expansion of a function-like MACRO, replacing parameters\n+   with the actual arguments.  Each instance is first macro-expanded,\n+   unless that paramter is operated upon by the # or ## operators.  */\n static void\n-replace_args (pfile, macro, args, list)\n+replace_args (pfile, macro, args)\n      cpp_reader *pfile;\n      cpp_macro *macro;\n      macro_arg *args;\n-     struct toklist *list;\n {\n-  unsigned char flags = 0;\n   unsigned int i, total;\n   const cpp_token *src, *limit;\n-  cpp_token *dest;\n+  const cpp_token **dest, **first;\n   macro_arg *arg;\n \n-  src = macro->expansion;\n-  limit = src + macro->count;\n-\n   /* First, fully macro-expand arguments, calculating the number of\n      tokens in the final expansion as we go.  This ensures that the\n-     possible recursive use of argument_pool is fine.  */\n-  total = limit - src;\n-  for (; src < limit; src++)\n+     possible recursive use of argument_pool is fine.  The ordering of\n+     the if statements below is subtle; we must handle stringification\n+     before pasting.  */\n+  total = macro->count;\n+  limit = macro->expansion + macro->count;\n+\n+  for (src = macro->expansion; src < limit; src++)\n     if (src->type == CPP_MACRO_ARG)\n       {\n+\t/* Leading and trailing padding tokens.  */\n+\ttotal += 2;\n+\n \t/* We have an argument.  If it is not being stringified or\n \t   pasted it is macro-replaced before insertion.  */\n \targ = &args[src->val.arg_no - 1];\n \n \tif (src->flags & STRINGIFY_ARG)\n \t  {\n \t    if (!arg->stringified)\n-\t      stringify_arg (pfile, arg);\n+\t      arg->stringified = stringify_arg (pfile, arg);\n \t  }\n \telse if ((src->flags & PASTE_LEFT)\n \t\t || (src > macro->expansion && (src[-1].flags & PASTE_LEFT)))\n \t  total += arg->count - 1;\n \telse\n \t  {\n \t    if (!arg->expanded)\n-\t      {\n-\t\targ->expanded_count = 0;\n-\t\tif (arg->count)\n-\t\t  expand_arg (pfile, arg);\n-\t      }\n+\t      expand_arg (pfile, arg);\n \t    total += arg->expanded_count - 1;\n \t  }\n       }\n \n-  dest = (cpp_token *) _cpp_pool_alloc (&pfile->argument_pool,\n-\t\t\t\t\ttotal * sizeof (cpp_token));\n-  list->first = dest;\n+  /* Now allocate space for the expansion, copy the tokens and replace\n+     the arguments.  */\n+  first = (const cpp_token **) _cpp_pool_alloc (&pfile->argument_pool,\n+\t\t\t\t\t\ttotal * sizeof (cpp_token *));\n+  dest = first;\n \n   for (src = macro->expansion; src < limit; src++)\n-    if (src->type == CPP_MACRO_ARG)\n-      {\n-\tunsigned int count;\n-\tconst cpp_token *from;\n+    {\n+      unsigned int count;\n+      const cpp_token **from, **paste_flag;\n \n-\targ = &args[src->val.arg_no - 1];\n-\tif (src->flags & STRINGIFY_ARG)\n-\t  {\n-\t    from = arg->stringified, count = 1;\n-\t    /* Ugh.  Maintain position of original argument.  */\n-\t    arg->stringified->line = src->line;\n-\t    arg->stringified->col = src->col;\n-\t  }\n-\telse if (src->flags & PASTE_LEFT)\n-\t  count = arg->count, from = arg->first;\n-\telse if (src > macro->expansion && (src[-1].flags & PASTE_LEFT))\n-\t  {\n-\t    count = arg->count, from = arg->first;\n-\t    if (dest != list->first)\n-\t      {\n-\t\t/* GCC has special semantics for , ## b where b is a\n-\t\t   varargs parameter: the comma disappears if b was\n-\t\t   given no actual arguments (not merely if b is an\n-\t\t   empty argument); otherwise pasting is turned off.  */\n-\t\tif (dest[-1].type == CPP_COMMA\n-\t\t    && macro->variadic\n-\t\t    && src->val.arg_no == macro->paramc)\n-\t\t  {\n-\t\t    if (count == 0)\n-\t\t      dest--;\n-\t\t    else\n-\t\t      dest[-1].flags &= ~PASTE_LEFT;\n-\t\t  }\n-\t\t/* Count == 0 is the RHS a placemarker case.  */\n-\t\telse if (count == 0)\n-\t\t  dest[-1].flags &= ~PASTE_LEFT;\n-\t      }\n-\t  }\n-\telse\n-\t  count = arg->expanded_count, from = arg->expanded;\n+      if (src->type != CPP_MACRO_ARG)\n+\t{\n+\t  *dest++ = src;\n+\t  continue;\n+\t}\n \n-\t/* Count == 0 is the LHS a placemarker case.  */\n-\tif (count)\n-\t  {\n-\t    memcpy (dest, from, count * sizeof (cpp_token));\n+      paste_flag = 0;\n+      arg = &args[src->val.arg_no - 1];\n+      if (src->flags & STRINGIFY_ARG)\n+\tcount = 1, from = &arg->stringified;\n+      else if (src->flags & PASTE_LEFT)\n+\tcount = arg->count, from = arg->first;\n+      else if (src != macro->expansion && (src[-1].flags & PASTE_LEFT))\n+\t{\n+\t  count = arg->count, from = arg->first;\n+\t  if (dest != first)\n+\t    {\n+\t      /* GCC has special semantics for , ## b where b is a\n+\t\t varargs parameter: the comma disappears if b was\n+\t\t given no actual arguments (not merely if b is an\n+\t\t empty argument); otherwise the paste flag is removed.  */\n+\t      if (dest[-1]->type == CPP_COMMA\n+\t\t  && macro->variadic\n+\t\t  && src->val.arg_no == macro->paramc)\n+\t\t{\n+\t\t  if (count == 0)\n+\t\t    dest--;\n+\t\t  else\n+\t\t    paste_flag = dest - 1;\n+\t\t}\n+\t      /* Remove the paste flag if the RHS is a placemarker.  */\n+\t      else if (count == 0)\n+\t\tpaste_flag = dest - 1;\n+\t    }\n+\t}\n+      else\n+\tcount = arg->expanded_count, from = arg->expanded;\n \n-\t    /* The first token gets PREV_WHITE of the CPP_MACRO_ARG.  */\n-\t    dest->flags &= ~(PREV_WHITE | BOL);\n-\t    dest->flags |= src->flags & (PREV_WHITE | BOL);\n-\t    dest->flags |= AVOID_LPASTE;\n+      /* Padding on the left of an argument (unless RHS of ##).  */\n+      if (!pfile->state.in_directive\n+\t  && src != macro->expansion && !(src[-1].flags & PASTE_LEFT))\n+\t*dest++ = padding_token (pfile, src);\n \n-\t    /* The last token gets the PASTE_LEFT of the CPP_MACRO_ARG.  */\n-\t    dest[count - 1].flags |= src->flags & PASTE_LEFT;\n+      if (count)\n+\t{\n+\t  memcpy (dest, from, count * sizeof (cpp_token *));\n+\t  dest += count;\n \n-\t    dest += count;\n-\t  }\n+\t  /* With a non-empty argument on the LHS of ##, the last\n+\t     token should be flagged PASTE_LEFT.  */\n+\t  if (src->flags & PASTE_LEFT)\n+\t    paste_flag = dest - 1;\n+\t}\n \n-\t/* The token after the argument must avoid an accidental paste.  */\n-\tflags = AVOID_LPASTE;\n-      }\n-    else\n-      {\n-\t*dest = *src;\n-\tdest->flags |= flags;\n-\tdest++;\n-\tflags = 0;\n-      }\n+      /* Avoid paste on RHS (even case count == 0).  */\n+      if (!pfile->state.in_directive && !(src->flags & PASTE_LEFT))\n+\t*dest++ = &pfile->avoid_paste;\n \n-  list->limit = dest;\n+      /* Add a new paste flag, or remove an unwanted one.  */\n+      if (paste_flag)\n+\t{\n+\t  cpp_token *token = _cpp_temp_token (pfile);\n+\t  token->type = (*paste_flag)->type;\n+\t  token->val.str = (*paste_flag)->val.str;\n+\t  if (src->flags & PASTE_LEFT)\n+\t    token->flags = (*paste_flag)->flags | PASTE_LEFT;\n+\t  else\n+\t    token->flags = (*paste_flag)->flags & ~PASTE_LEFT;\n+\t  *paste_flag = token;\n+\t}\n+    }\n \n   /* Free the expanded arguments.  */\n   for (i = 0; i < macro->paramc; i++)\n+    if (args[i].expanded)\n+      free (args[i].expanded);\n+\n+  push_ptoken_context (pfile, macro, first, dest - first);\n+}\n+\n+/* Return a special padding token, with padding inherited from SOURCE.  */\n+static const cpp_token *\n+padding_token (pfile, source)\n+     cpp_reader *pfile;\n+     const cpp_token *source;\n+{\n+  cpp_token *result = _cpp_temp_token (pfile);\n+\n+  result->type = CPP_PADDING;\n+  result->val.source = source;\n+  result->flags = 0;\n+  return result;\n+}\n+\n+/* Move to the next context.  Create one if there is none.  */\n+static cpp_context *\n+next_context (pfile)\n+     cpp_reader *pfile;\n+{\n+  cpp_context *result = pfile->context->next;\n+\n+  if (result == 0)\n     {\n-      if (args[i].expanded)\n-\tfree (args[i].expanded);\n-      if (args[i].stringified)\n-\tfree (args[i].stringified);\n+      result = xnew (cpp_context);\n+      result->prev = pfile->context;\n+      result->next = 0;\n+      pfile->context->next = result;\n     }\n+\n+  pfile->context = result;\n+  return result;\n }\n \n-/* Subroutine of expand_arg to put the unexpanded tokens on the\n-   context stack.  */\n-static cpp_context *\n-push_arg_context (pfile, arg)\n+/* Push a list of pointers to tokens.  */\n+static void\n+push_ptoken_context (pfile, macro, first, count)\n      cpp_reader *pfile;\n-     macro_arg *arg;\n+     cpp_macro *macro;\n+     const cpp_token **first;\n+     unsigned int count;\n+{\n+  cpp_context *context = next_context (pfile);\n+\n+  context->direct_p = false;\n+  context->macro = macro;\n+  context->first.ptoken = first;\n+  context->last.ptoken = first + count;\n+}\n+\n+/* Push a list of tokens.  */\n+static void\n+push_token_context (pfile, macro, first, count)\n+     cpp_reader *pfile;\n+     cpp_macro *macro;\n+     const cpp_token *first;\n+     unsigned int count;\n {\n   cpp_context *context = next_context (pfile);\n-  context->macro = 0;\n-  context->list.first = arg->first;\n-  context->list.limit = arg->first + arg->count + 1;\n \n-  return context;\n+  context->direct_p = true;\n+  context->macro = macro;\n+  context->first.token = first;\n+  context->last.token = first + count;\n }\n \n static void\n expand_arg (pfile, arg)\n      cpp_reader *pfile;\n      macro_arg *arg;\n {\n-  cpp_token *token;\n-  unsigned int capacity = 256;\n+  unsigned int capacity;\n+\n+  arg->expanded_count = 0;\n+  if (arg->count == 0)\n+    return;\n \n   /* Loop, reading in the arguments.  */\n-  arg->expanded = (cpp_token *) xmalloc (capacity * sizeof (cpp_token));\n+  capacity = 256;\n+  arg->expanded = (const cpp_token **)\n+    xmalloc (capacity * sizeof (cpp_token *));\n \n-  push_arg_context (pfile, arg);\n-  do\n+  push_ptoken_context (pfile, NULL, arg->first, arg->count + 1);\n+  for (;;)\n     {\n-      if (arg->expanded_count >= capacity)\n+      const cpp_token *token;\n+\n+      if (arg->expanded_count + 1 >= capacity)\n \t{\n \t  capacity *= 2;\n-\t  arg->expanded = (cpp_token *)\n-\t    xrealloc (arg->expanded, capacity * sizeof (cpp_token));\n+\t  arg->expanded = (const cpp_token **)\n+\t    xrealloc (arg->expanded, capacity * sizeof (cpp_token *));\n \t}\n-      token = &arg->expanded[arg->expanded_count++];\n-      cpp_get_token (pfile, token);\n-    }\n-  while (token->type != CPP_EOF);\n \n-  arg->expanded_count--;\n+      token = cpp_get_token (pfile);\n+\n+      if (token->type == CPP_EOF)\n+\tbreak;\n+\n+      arg->expanded[arg->expanded_count++] = token;\n+    }\n \n-  /* Pop the context we pushed.  */ \n+  /* Avoid the unlock_pools test of _cpp_pop_context.  Change this to\n+     call _cpp_pop_context once we remove pool locking.  */\n   pfile->context = pfile->context->prev;\n }\n \n void\n _cpp_pop_context (pfile)\n      cpp_reader *pfile;\n {\n-  cpp_context *context = pfile->context;\n+  /* Re-enable a macro when leaving its expansion.  */\n+  if (pfile->context->macro)\n+    pfile->context->macro->disabled = 0;\n \n-  pfile->context = context->prev;\n+  pfile->context = pfile->context->prev;\n   if (!pfile->context->prev && !pfile->state.parsing_args)\n     unlock_pools (pfile);\n-\n-  /* Re-enable a macro when leaving its expansion.  */\n-  context->macro->disabled = 0;\n }\n \n /* Eternal routine to get a token.  Also used nearly everywhere\n@@ -902,84 +962,84 @@ _cpp_pop_context (pfile)\n    a directive inside a macro call, when at the end of a directive and\n    state.in_directive is still 1, and at the end of argument\n    pre-expansion.  */\n-void\n-cpp_get_token (pfile, token)\n+const cpp_token *\n+cpp_get_token (pfile)\n      cpp_reader *pfile;\n-     cpp_token *token;\n {\n+  const cpp_token *result;\n+\n   for (;;)\n     {\n+      cpp_hashnode *node;\n       cpp_context *context = pfile->context;\n \n       /* Context->prev == 0 <=> base context.  */\n       if (!context->prev)\n-\t*token = *_cpp_lex_token (pfile);\n-      else if (context->list.first != context->list.limit)\n+\tresult = _cpp_lex_token (pfile);\n+      else if (context->first.token != context->last.token)\n \t{\n-\t  *token = *context->list.first++;\n-\t  token->flags |= pfile->buffer->saved_flags;\n-\t  pfile->buffer->saved_flags = 0;\n-\t  /* PASTE_LEFT tokens can only appear in macro expansions.  */\n-\t  if (token->flags & PASTE_LEFT)\n+\t  if (context->direct_p)\n+\t    result = context->first.token++;\n+\t  else\n+\t    result = *context->first.ptoken++;\n+\n+\t  if (result->flags & PASTE_LEFT)\n \t    {\n-\t      /* Maintains position of original token.  */\n-\t      paste_all_tokens (pfile, token);\n-\t      pfile->buffer->saved_flags = AVOID_LPASTE;\n+\t      paste_all_tokens (pfile, result);\n+\t      if (pfile->state.in_directive)\n+\t\tcontinue;\n+\t      return padding_token (pfile, result);\n \t    }\n \t}\n       else\n \t{\n-\t  if (!context->macro)\n-\t    cpp_ice (pfile, \"context->macro == 0\");\n-\n-\t  /* Avoid accidental paste at the end of a macro.  */\n-\t  pfile->buffer->saved_flags |= AVOID_LPASTE;\n \t  _cpp_pop_context (pfile);\n-\t  continue;\n+\t  if (pfile->state.in_directive)\n+\t    continue;\n+\t  return &pfile->avoid_paste;\n \t}\n \n-      if (token->type != CPP_NAME)\n+      if (result->type != CPP_NAME)\n \tbreak;\n \n+      node = result->val.node;\n+\n       /* Handle macros and the _Pragma operator.  */\n-      if (token->val.node->type == NT_MACRO\n-\t  && !pfile->state.prevent_expansion\n-\t  && !(token->flags & NO_EXPAND))\n+      if (node->type == NT_MACRO && !(result->flags & NO_EXPAND))\n \t{\n-\t  cpp_hashnode *node = token->val.node;\n-\n \t  /* Macros invalidate controlling macros.  */\n \t  pfile->mi_valid = false;\n \n-\t  if (node->flags & NODE_BUILTIN)\n+\t  if (!(node->flags & NODE_BUILTIN) && node->value.macro->disabled)\n \t    {\n-\t      /* Maintains position of original token.  */\n-\t      builtin_macro (pfile, token);\n-\t      pfile->buffer->saved_flags = AVOID_LPASTE;\n-\t      break;\n+\t      /* Flag this token as always unexpandable.  */\n+\t      cpp_token *t = _cpp_temp_token (pfile);\n+\t      t->type = result->type;\n+\t      t->flags = result->flags | NO_EXPAND;\n+\t      t->val.str = result->val.str;\n+\t      result = t;\n \t    }\n-\n-\t  if (node->value.macro->disabled)\n-\t    token->flags |= NO_EXPAND;\n-\t  else if (enter_macro_context (pfile, node))\n+\t  else if (!pfile->state.prevent_expansion\n+\t\t   && enter_macro_context (pfile, node))\n \t    {\n-\t      /* Pass AVOID_LPASTE and our PREV_WHITE to next token.  */\n-\t      pfile->buffer->saved_flags = ((token->flags & (PREV_WHITE | BOL))\n-\t\t\t\t\t    | AVOID_LPASTE);\n-\t      continue;\n+\t      if (pfile->state.in_directive)\n+\t\tcontinue;\n+\t      return padding_token (pfile, result);\n \t    }\n \t}\n \n       /* Don't interpret _Pragma within directives.  The standard is\n          not clear on this, but to me this makes most sense.  */\n-      if (token->val.node != pfile->spec_nodes.n__Pragma\n+      if (node != pfile->spec_nodes.n__Pragma\n \t  || pfile->state.in_directive)\n \tbreak;\n \n       /* Handle it, and loop back for another token.  MI is cleared\n          since this token came from either the lexer or a macro.  */\n       _cpp_do__Pragma (pfile);\n     }\n+\n+  return result;\n }\n \n /* Returns true if we're expanding an object-like macro that was\n@@ -1000,11 +1060,8 @@ void\n cpp_scan_nooutput (pfile)\n      cpp_reader *pfile;\n {\n-  cpp_token token;\n-\n-  do\n-    cpp_get_token (pfile, &token);\n-  while (token.type != CPP_EOF);\n+  while (cpp_get_token (pfile)->type != CPP_EOF)\n+    ;\n }\n \n /* Step back one (or more) tokens.  Can only step mack more than 1 if\n@@ -1031,7 +1088,10 @@ _cpp_backup_tokens (pfile, count)\n     {\n       if (count != 1)\n \tabort ();\n-      pfile->context->list.first--;\n+      if (pfile->context->direct_p)\n+\tpfile->context->first.token--;\n+      else\n+\tpfile->context->first.ptoken--;\n     }\n }\n \n@@ -1330,8 +1390,6 @@ _cpp_create_definition (pfile, node)\n \t    }\n \n \t  token[-1].flags |= PASTE_LEFT;\n-\t  /* Give it a PREV_WHITE for -dM etc.  */\n-\t  token->flags |= PREV_WHITE;\n \t}\n \n       token = lex_expansion_token (pfile, macro);\n@@ -1340,13 +1398,6 @@ _cpp_create_definition (pfile, node)\n   /* Don't count the CPP_EOF.  */\n   macro->count--;\n \n-  /* Clear the whitespace flag from the leading token, but put a space\n-     in front of a leading # which might be used to fake a directive.  */\n-  if (macro->expansion[0].type == CPP_HASH)\n-    macro->expansion[0].flags |= PREV_WHITE;\n-  else\n-    macro->expansion[0].flags &= ~PREV_WHITE;\n-\n   /* Implement the macro-defined-to-itself optimisation.  */\n   macro->disabled = (macro->count == 1 && !macro->fun_like\n \t\t     && macro->expansion[0].type == CPP_NAME"}, {"sha": "a1b8b67f54cff6a26e38d37030d5f983fc34ff99", "filename": "gcc/cppmain.c", "status": "modified", "additions": 34, "deletions": 10, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcppmain.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fcppmain.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcppmain.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -32,6 +32,7 @@ struct printer\n {\n   FILE *outf;\t\t\t/* Stream to write to.  */\n   const struct line_map *map;\t/* Logical to physical line mappings.  */\n+  const cpp_token *prev;\t/* Previous token.  */\n   unsigned int line;\t\t/* Line currently being written.  */\n   unsigned char printed;\t/* Nonzero if something output at line.  */\n };\n@@ -43,7 +44,7 @@ static void setup_callbacks PARAMS ((void));\n \n /* General output routines.  */\n static void scan_translation_unit PARAMS ((cpp_reader *));\n-static void check_multiline_token PARAMS ((cpp_string *));\n+static void check_multiline_token PARAMS ((const cpp_string *));\n static int dump_macro PARAMS ((cpp_reader *, cpp_hashnode *, void *));\n \n static void print_line PARAMS ((const struct line_map *, unsigned int,\n@@ -144,6 +145,7 @@ do_preprocessing (argc, argv)\n      cause a linemarker to be output by maybe_print_line.  */\n   print.line = (unsigned int) -1;\n   print.printed = 0;\n+  print.prev = 0;\n   print.map = 0;\n   \n   /* Open the output now.  We must do so even if no_output is on,\n@@ -219,22 +221,43 @@ static void\n scan_translation_unit (pfile)\n      cpp_reader *pfile;\n {\n-  unsigned int index;\n-  cpp_token tokens[2], *token;\n+  bool avoid_paste = false;\n+  const cpp_token *source = NULL;\n \n-  for (index = 0;; index = 1 - index)\n+  for (;;)\n     {\n-      token = &tokens[index];\n-      cpp_get_token (pfile, token);\n+      const cpp_token *token = cpp_get_token (pfile);\n+\n+      if (token->type == CPP_PADDING)\n+\t{\n+\t  avoid_paste = true;\n+\t  if (source == NULL\n+\t      || (!(source->flags & PREV_WHITE) && token->val.source == NULL))\n+\t    source = token->val.source;\n+\t  continue;\n+\t}\n \n       if (token->type == CPP_EOF)\n \tbreak;\n \n-      if ((token->flags & (PREV_WHITE | AVOID_LPASTE | BOL)) == AVOID_LPASTE\n-\t  && cpp_avoid_paste (pfile, &tokens[1 - index], token))\n-\ttoken->flags |= PREV_WHITE;\n+      /* Subtle logic to output a space if and only if necessary.  */\n+      if (avoid_paste)\n+\t{\n+\t  if (source == NULL)\n+\t    source = token;\n+\t  if (source->flags & PREV_WHITE\n+\t      || (print.prev && cpp_avoid_paste (pfile, print.prev, token))\n+\t      || (print.prev == NULL && token->type == CPP_HASH))\n+\t    putc (' ', print.outf);\n+\t}\n+      else if (token->flags & PREV_WHITE)\n+\tputc (' ', print.outf);\n \n+      avoid_paste = false;\n+      source = NULL;\n+      print.prev = token;\n       cpp_output_token (token, print.outf);\n+\n       if (token->type == CPP_STRING || token->type == CPP_WSTRING\n \t  || token->type == CPP_COMMENT)\n \tcheck_multiline_token (&token->val.str);\n@@ -244,7 +267,7 @@ scan_translation_unit (pfile)\n /* Adjust print.line for newlines embedded in tokens.  */\n static void\n check_multiline_token (str)\n-     cpp_string *str;\n+     const cpp_string *str;\n {\n   unsigned int i;\n \n@@ -324,6 +347,7 @@ cb_line_change (pfile, token, parsing_args)\n \n   maybe_print_line (print.map, token->line);\n   print.printed = 1;\n+  print.prev = 0;\n \n   /* Supply enough spaces to put this token in its original column,\n      one space per column greater than 2, since scan_translation_unit"}, {"sha": "e8f7e9e7a68732925f79d5de0d8683ba211540ed", "filename": "gcc/doc/cpp.texi", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fdoc%2Fcpp.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fdoc%2Fcpp.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fcpp.texi?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -1515,10 +1515,10 @@ token pasting.\n However, two tokens that don't together form a valid token cannot be\n pasted together.  For example, you cannot concatenate @code{x} with\n @code{+} in either order.  If you try, the preprocessor issues a warning\n-and emits the two tokens as if they had been written next to each other.\n-It is common to find unnecessary uses of @samp{##} in complex macros.\n-If you get this warning, it is likely that you can simply remove the\n-@samp{##}.\n+and emits the two tokens.  Whether it puts white space between the\n+tokens is undefined.  It is common to find unnecessary uses of @samp{##}\n+in complex macros.  If you get this warning, it is likely that you can\n+simply remove the @samp{##}.\n \n Both the tokens combined by @samp{##} could come from the macro body,\n but you could just as well write them as one token in the first place."}, {"sha": "cf37a41a21dbe8cbb9270563195087ae5444827e", "filename": "gcc/fix-header.c", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ffix-header.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ffix-header.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffix-header.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -661,12 +661,11 @@ read_scan_file (in_fname, argc, argv)\n \t\t       /* from_stage3 */ true, 1);\n       for (;;)\n \t{\n-\t  cpp_token t;\n+\t  const cpp_token *t = cpp_get_token (scan_in);\n \n-\t  cpp_get_token (scan_in, &t);\n-\t  if (t.type == CPP_EOF)\n+\t  if (t->type == CPP_EOF)\n \t    break;\n-\t  else if (cpp_ideq (&t, \"_filbuf\"))\n+\t  else if (cpp_ideq (t, \"_filbuf\"))\n \t    seen_filbuf++;\n \t}\n "}, {"sha": "cbd99004e9c923f8e1a6a4600d15b349fb4440fd", "filename": "gcc/scan-decls.c", "status": "modified", "additions": 46, "deletions": 34, "changes": 80, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fscan-decls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Fscan-decls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fscan-decls.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -24,6 +24,7 @@ Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.\n #include \"scan.h\"\n \n static void skip_to_closing_brace PARAMS ((cpp_reader *));\n+static const cpp_token *get_a_token PARAMS ((cpp_reader *));\n \n int brace_nesting = 0;\n \n@@ -38,18 +39,28 @@ char extern_C_braces[20];\n    prefixed by extern \"C\".  */\n int current_extern_C = 0;\n \n+/* Get a token but skip padding.  */\n+static const cpp_token *\n+get_a_token (pfile)\n+     cpp_reader *pfile;\n+{\n+  for (;;)\n+    {\n+      const cpp_token *result = cpp_get_token (pfile);\n+      if (result->type != CPP_PADDING)\n+\treturn result;\n+    }\n+}\n+\n static void\n skip_to_closing_brace (pfile)\n      cpp_reader *pfile;\n {\n   int nesting = 1;\n   for (;;)\n     {\n-      cpp_token tok;\n-      enum cpp_ttype token;\n+      enum cpp_ttype token = get_a_token (pfile)->type;\n \n-      cpp_get_token (pfile, &tok);\n-      token = tok.type;\n       if (token == CPP_EOF)\n \tbreak;\n       if (token == CPP_OPEN_BRACE)\n@@ -88,16 +99,17 @@ scan_decls (pfile, argc, argv)\n      char **argv ATTRIBUTE_UNUSED;\n {\n   int saw_extern, saw_inline;\n-  cpp_token token, prev_id;\n+  cpp_token prev_id;\n+  const cpp_token *token;\n \n  new_statement:\n-  cpp_get_token (pfile, &token);\n+  token = get_a_token (pfile);\n \n  handle_statement:\n   current_extern_C = 0;\n   saw_extern = 0;\n   saw_inline = 0;\n-  if (token.type == CPP_OPEN_BRACE)\n+  if (token->type == CPP_OPEN_BRACE)\n     {\n       /* Pop an 'extern \"C\"' nesting level, if appropriate.  */\n       if (extern_C_braces_length\n@@ -106,24 +118,24 @@ scan_decls (pfile, argc, argv)\n       brace_nesting--;\n       goto new_statement;\n     }\n-  if (token.type == CPP_OPEN_BRACE)\n+  if (token->type == CPP_OPEN_BRACE)\n     {\n       brace_nesting++;\n       goto new_statement;\n     }\n \n-  if (token.type == CPP_EOF)\n+  if (token->type == CPP_EOF)\n     return 0;\n \n-  if (token.type == CPP_SEMICOLON)\n+  if (token->type == CPP_SEMICOLON)\n     goto new_statement;\n-  if (token.type != CPP_NAME)\n+  if (token->type != CPP_NAME)\n     goto new_statement;\n \n   prev_id.type = CPP_EOF;\n   for (;;)\n     {\n-      switch (token.type)\n+      switch (token->type)\n \t{\n \tdefault:\n \t  goto handle_statement;\n@@ -138,7 +150,7 @@ scan_decls (pfile, argc, argv)\n \t    {\n \t      recognized_extern (&prev_id);\n \t    }\n-\t  if (token.type == CPP_COMMA)\n+\t  if (token->type == CPP_COMMA)\n \t    break;\n \t  /* ... fall through ...  */\n \tcase CPP_OPEN_BRACE:  case CPP_CLOSE_BRACE:\n@@ -155,27 +167,27 @@ scan_decls (pfile, argc, argv)\n \t      int have_arg_list = 0;\n \t      for (;;)\n \t\t{\n-\t\t  cpp_get_token (pfile, &token);\n-\t\t  if (token.type == CPP_OPEN_PAREN)\n+\t\t  token = get_a_token (pfile);\n+\t\t  if (token->type == CPP_OPEN_PAREN)\n \t\t    nesting++;\n-\t\t  else if (token.type == CPP_CLOSE_PAREN)\n+\t\t  else if (token->type == CPP_CLOSE_PAREN)\n \t\t    {\n \t\t      nesting--;\n \t\t      if (nesting == 0)\n \t\t\tbreak;\n \t\t    }\n-\t\t  else if (token.type == CPP_EOF)\n+\t\t  else if (token->type == CPP_EOF)\n \t\t    break;\n-\t\t  else if (token.type == CPP_NAME\n-\t\t\t   || token.type == CPP_ELLIPSIS)\n+\t\t  else if (token->type == CPP_NAME\n+\t\t\t   || token->type == CPP_ELLIPSIS)\n \t\t    have_arg_list = 1;\n \t\t}\n-\t      recognized_function (&prev_id, token.line,\n+\t      recognized_function (&prev_id, token->line,\n \t\t\t\t   (saw_inline ? 'I'\n \t\t\t\t    : in_extern_C_brace || current_extern_C\n \t\t\t\t    ? 'F' : 'f'), have_arg_list);\n-\t      cpp_get_token (pfile, &token);\n-\t      if (token.type == CPP_OPEN_BRACE)\n+\t      token = get_a_token (pfile);\n+\t      if (token->type == CPP_OPEN_BRACE)\n \t\t{\n \t\t  /* skip body of (normally) inline function */\n \t\t  skip_to_closing_brace (pfile);\n@@ -184,28 +196,28 @@ scan_decls (pfile, argc, argv)\n \n \t      /* skip a possible __attribute__ or throw expression after the\n \t\t parameter list */\n-\t      while (token.type != CPP_SEMICOLON && token.type != CPP_EOF)\n-\t\tcpp_get_token (pfile, &token);\n+\t      while (token->type != CPP_SEMICOLON && token->type != CPP_EOF)\n+\t\ttoken = get_a_token (pfile);\n \t      goto new_statement;\n \t    }\n \t  break;\n \tcase CPP_NAME:\n \t  /* \"inline\" and \"extern\" are recognized but skipped */\n-\t  if (cpp_ideq (&token, \"inline\"))\n+\t  if (cpp_ideq (token, \"inline\"))\n \t    {\n \t      saw_inline = 1;\n \t    }\n-\t  else if (cpp_ideq (&token, \"extern\"))\n+\t  else if (cpp_ideq (token, \"extern\"))\n \t    {\n \t      saw_extern = 1;\n-\t      cpp_get_token (pfile, &token);\n-\t      if (token.type == CPP_STRING\n-\t\t  && token.val.str.len == 1\n-\t\t  && token.val.str.text[0] == 'C')\n+\t      token = get_a_token (pfile);\n+\t      if (token->type == CPP_STRING\n+\t\t  && token->val.str.len == 1\n+\t\t  && token->val.str.text[0] == 'C')\n \t\t{\n \t\t  current_extern_C = 1;\n-\t\t  cpp_get_token (pfile, &token);\n-\t\t  if (token.type == CPP_OPEN_BRACE)\n+\t\t  token = get_a_token (pfile);\n+\t\t  if (token->type == CPP_OPEN_BRACE)\n \t\t    {\n \t\t      brace_nesting++;\n \t\t      extern_C_braces[extern_C_braces_length++]\n@@ -218,9 +230,9 @@ scan_decls (pfile, argc, argv)\n \t      break;\n \t    }\n \t  /* This may be the name of a variable or function.  */\n-\t  prev_id = token;\n+\t  prev_id = *token;\n \t  break;\n \t}\n-      cpp_get_token (pfile, &token);\n+      token = get_a_token (pfile);\n     }\n }"}, {"sha": "f1ebfd165f59ae7ec3195391800dd942cf7ec603", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -1,3 +1,11 @@\n+2001-09-24  Neil Booth  <neil@daikokuya.demon.co.uk>\n+\n+\t* gcc.dg/cpp/macro10.c: New test.\n+\t* gcc.dg/cpp/strify3.c: New test.\n+\t* gcc.dg/cpp/spacing1.c: Add tests.\n+\t* gcc.dg/cpp/19990703-1.c: Remove bogus test.\n+\t* gcc.dg/cpp/20000625-2.c: Fudge to pass.\n+\n 2001-09-24  DJ Delorie  <dj@redhat.com>\n \n \t* gcc.c-torture/execute/20010924-1.c: New test."}, {"sha": "c3ac2330055bc736e5f3b502a2e07b177fb58190", "filename": "gcc/testsuite/gcc.dg/cpp/19990703-1.c", "status": "removed", "additions": 0, "deletions": 24, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ad43d46f3abe6f4d9b41f5b1d7b46a0c320efda8/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2F19990703-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ad43d46f3abe6f4d9b41f5b1d7b46a0c320efda8/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2F19990703-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2F19990703-1.c?ref=ad43d46f3abe6f4d9b41f5b1d7b46a0c320efda8", "patch": "@@ -1,24 +0,0 @@\n-/* { dg-do run } */\n-\n-/* Test of obscure case in token pasting in the preprocessor.\n-   I can't think of any way to make this problem provoke a syntax error.\n-   Based on a bug report by Manfred Hollstein.  */\n-\n-#include <string.h>\n-\n-#define SP1(x, y) SP2(x, y)\n-#define SP2(x, y) SP3(x##y)\n-#define SP3(x) #x\n-#define MZ -0\n-\n-int\n-main(void)\n-{\n-    char *x = SP1(0,MZ);  /* { dg-warning \"valid preprocessing token\" \"\" } */\n-    char *y = \"0-0\";  /* should be the expansion of SP1(0,MZ) */\n-\n-    if(strcmp(x, y))\n-\treturn 1;\n-    else\n-\treturn 0;\n-}"}, {"sha": "c9e3fe23b9c96953104738a390a0b59b6b18b8cf", "filename": "gcc/testsuite/gcc.dg/cpp/20000625-2.c", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2F20000625-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2F20000625-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2F20000625-2.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -8,7 +8,10 @@\n #define str(x) xstr(x)\n #define xstr(x) #x\n \n-const char a[] = str(symbol_version(getrlimit, GLIBC_2.0));\n+/* This testcase is bogus, as it testing undefined behaviour.  We can\n+   get the behaviour GLIBC desires by removing the space before\n+   GCLIB_2.0 in this line.  */\n+const char a[] = str(symbol_version(getrlimit,GLIBC_2.0));\n /* { dg-warning \"valid preprocessing token\" \"\" { target *-*-* } 11 } */\n const char b[] = str(getrlimit@GLIBC_2.0);\n const char c[] = \"getrlimit@GLIBC_2.0\";"}, {"sha": "20d4911e64878ea42d4049915df93fb540380fd5", "filename": "gcc/testsuite/gcc.dg/cpp/macro10.c", "status": "added", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fmacro10.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fmacro10.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fmacro10.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -0,0 +1,25 @@\n+/* Copyright (C) 2001 Free Software Foundation, Inc.  */\n+\n+/* { dg-do preprocess } */\n+\n+/* Source: Neil Booth, 23 Sep 2001.\n+\n+   A tricky, pathological corner case we used to get wrong.  Expansion\n+   should go as follows.  The asterisk indicates the token has \"blue\n+   paint\" can no longer be macro expanded.  We used to lose that\n+   information when parsing arguments and dropping to the lexer to get\n+   the ')'.\n+\n+   foo )\n+   bar foo* )\n+   func (foo* )\n+   foo*   \n+\n+   If we try and expand the final foo, we get an \"unterminated\n+   argument list invoking macro <func>\" error.  If we do the right\n+   thing and leave it as is, no diagnostics are emitted.  */\n+\n+#define func(x) x\n+#define bar func(\n+#define foo bar foo\n+foo )"}, {"sha": "9a3933b7308f18c35345de08af33cb075f1b5346", "filename": "gcc/testsuite/gcc.dg/cpp/spacing1.c", "status": "modified", "additions": 8, "deletions": 3, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fspacing1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fspacing1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fspacing1.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -1,4 +1,4 @@\n-/* Copyright (C) 2000 Free Software Foundation, Inc.  */\n+/* Copyright (C) 2000, 2001 Free Software Foundation, Inc.  */\n \n /* { dg-do preprocess } */\n \n@@ -8,20 +8,24 @@\n    not be a macro invocation.  Also, multiple macro invocations spread\n    across many lines.\n \n-   Neil Booth, 1 Dec 2000.  */\n+   Neil Booth, 1 Dec 2000, 23 Sep 2001.  */\n \n #define str(x) #x\n #define f(x) x\n+#define glue(x, y) x ## y\n+#define EMPTY\n \n /* The correct output is shown here.  Note the spaces, and the way\n    everything after the invocation of f appears on the same line.\n \n+ 44 ;\n f\n bar\n g \"1 2\" bam baz\n \n */\n \n+glue (EMPTY 4, 4) EMPTY;\n f\n bar\n f (g) str\n@@ -33,9 +37,10 @@ f (g) str\n \n /*\n    { dg-final { if ![file exists spacing1.i] { return }                   } }\n+   { dg-final { if \\{ [grep spacing1.i \" 44 ;\"] != \"\" \\}  \\{              } }\n    { dg-final { if \\{ [grep spacing1.i \"f.*bar\"] == \"\" \\} \\{              } }\n    { dg-final { if \\{ [grep spacing1.i \"^bar\"] != \"\" \\}   \\{              } }\n    { dg-final { if \\{ [grep spacing1.i \"g \\\"1 2\\\" bam baz\"] != \"\" \\} \\{   } }\n-   { dg-final { return \\} \\} \\}                                           } }\n+   { dg-final { return \\} \\} \\} \\}                                        } }\n    { dg-final { fail \"spacing1.c: spacing and new-line preservation\"      } }\n */"}, {"sha": "5d76b5e750fb1b0e01b82512368f4a56fd42052f", "filename": "gcc/testsuite/gcc.dg/cpp/strify3.c", "status": "added", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fstrify3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fstrify3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fcpp%2Fstrify3.c?ref=4ed5bcfb1ed415c32bdd8735b2cd0ea0ed37e8b6", "patch": "@@ -0,0 +1,29 @@\n+/* Copyright (C) 2001 Free Software Foundation, Inc.  */\n+\n+/* { dg-do run } */\n+\n+/* Tests we stringify without inserting a space.  GCC 2.95.x and\n+   earlier would insert a bogus space before bar in the string, simply\n+   because a space was there in the invocation.\n+\n+   Neil Booth, 24 Sep 2001.  */\n+\n+extern int strcmp (const char *, const char *);\n+extern int puts (const char *);\n+extern void abort (void);\n+#define err(str) do { puts(str); abort(); } while (0)\n+\n+#define str(x) #x\n+#define xstr(x) str(x)\n+#define glibc_hack(x, y) x@y\n+\n+int main (int argc, char *argv[])\n+{\n+  /* The space before \"bar\" here is vital.  */\n+  char a[] = xstr(glibc_hack(foo, bar));\n+\n+  if (strcmp (a, \"foo@bar\"))\n+    err (\"stringification without spaces\");\n+\n+  return 0;\n+}"}]}