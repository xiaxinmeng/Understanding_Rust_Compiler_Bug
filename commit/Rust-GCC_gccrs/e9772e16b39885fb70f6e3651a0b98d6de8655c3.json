{"sha": "e9772e16b39885fb70f6e3651a0b98d6de8655c3", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTk3NzJlMTZiMzk4ODVmYjcwZjZlMzY1MWEwYjk4ZDZkZTg2NTVjMw==", "commit": {"author": {"name": "Kostya Serebryany", "email": "kcc@google.com", "date": "2013-01-10T12:44:08Z"}, "committer": {"name": "Kostya Serebryany", "email": "kcc@gcc.gnu.org", "date": "2013-01-10T12:44:08Z"}, "message": "libsanitizer mege from upstream r171973\n\nFrom-SVN: r195083", "tree": {"sha": "23cebf7ab15836f70e055aee309f853c0c377de6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/23cebf7ab15836f70e055aee309f853c0c377de6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e9772e16b39885fb70f6e3651a0b98d6de8655c3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e9772e16b39885fb70f6e3651a0b98d6de8655c3", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e9772e16b39885fb70f6e3651a0b98d6de8655c3", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e9772e16b39885fb70f6e3651a0b98d6de8655c3/comments", "author": {"login": "kcc", "id": 1789297, "node_id": "MDQ6VXNlcjE3ODkyOTc=", "avatar_url": "https://avatars.githubusercontent.com/u/1789297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kcc", "html_url": "https://github.com/kcc", "followers_url": "https://api.github.com/users/kcc/followers", "following_url": "https://api.github.com/users/kcc/following{/other_user}", "gists_url": "https://api.github.com/users/kcc/gists{/gist_id}", "starred_url": "https://api.github.com/users/kcc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kcc/subscriptions", "organizations_url": "https://api.github.com/users/kcc/orgs", "repos_url": "https://api.github.com/users/kcc/repos", "events_url": "https://api.github.com/users/kcc/events{/privacy}", "received_events_url": "https://api.github.com/users/kcc/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "e1f674e4c21be4834cfad53666b5b7a9492cf0a5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e1f674e4c21be4834cfad53666b5b7a9492cf0a5", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e1f674e4c21be4834cfad53666b5b7a9492cf0a5"}], "stats": {"total": 5524, "additions": 4522, "deletions": 1002}, "files": [{"sha": "3943c2fed041974d6df919c3e708326d21e6b076", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -1,3 +1,7 @@\n+2013-01-10  Kostya Serebryany  <kcc@google.com>\n+\n+\t* g++.dg/asan/asan_test.cc: Sync from upstream.\n+\n 2013-01-10  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR tree-optimization/55921"}, {"sha": "9cfa9e04ef812f24791eba87adaa6fe584c173dc", "filename": "gcc/testsuite/g++.dg/asan/asan_test.cc", "status": "modified", "additions": 352, "deletions": 138, "changes": 490, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fasan%2Fasan_test.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fasan%2Fasan_test.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fasan%2Fasan_test.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -17,6 +17,15 @@\n #include <stdint.h>\n #include <setjmp.h>\n #include <assert.h>\n+#include <algorithm>\n+\n+#ifdef __linux__\n+# include <sys/prctl.h>\n+# include <sys/types.h>\n+# include <sys/stat.h>\n+# include <fcntl.h>\n+#include <unistd.h>\n+#endif\n \n #if defined(__i386__) || defined(__x86_64__)\n #include <emmintrin.h>\n@@ -242,7 +251,7 @@ void OOBTest() {\n     for (int i = 0; i < (int)(size - sizeof(T) + 1); i++)\n       oob_test<T>(size, i);\n \n-    for (int i = size - sizeof(T) + 1; i <= (int)(size + 3 * sizeof(T)); i++) {\n+    for (int i = size - sizeof(T) + 1; i <= (int)(size + 2 * sizeof(T)); i++) {\n       const char *str =\n           \"is located.*%d byte.*to the right\";\n       int off = i >= size ? (i - size) : 0;\n@@ -298,6 +307,18 @@ TEST(AddressSanitizer, OOBRightTest) {\n   }\n }\n \n+#if ASAN_ALLOCATOR_VERSION == 2  // Broken with the asan_allocator1\n+TEST(AddressSanitizer, LargeOOBRightTest) {\n+  size_t large_power_of_two = 1 << 19;\n+  for (size_t i = 16; i <= 256; i *= 2) {\n+    size_t size = large_power_of_two - i;\n+    char *p = Ident(new char[size]);\n+    EXPECT_DEATH(p[size] = 0, \"is located 0 bytes to the right\");\n+    delete [] p;\n+  }\n+}\n+#endif  // ASAN_ALLOCATOR_VERSION == 2\n+\n TEST(AddressSanitizer, UAF_char) {\n   const char *uaf_string = \"AddressSanitizer:.*heap-use-after-free\";\n   EXPECT_DEATH(uaf_test<U1>(1, 0), uaf_string);\n@@ -456,6 +477,24 @@ TEST(AddressSanitizer, HugeMallocTest) {\n }\n #endif\n \n+#ifndef __APPLE__\n+void MemalignRun(size_t align, size_t size, int idx) {\n+  char *p = (char *)memalign(align, size);\n+  Ident(p)[idx] = 0;\n+  free(p);\n+}\n+\n+TEST(AddressSanitizer, memalign) {\n+  for (int align = 16; align <= (1 << 23); align *= 2) {\n+    size_t size = align * 5;\n+    EXPECT_DEATH(MemalignRun(align, size, -1),\n+                 \"is located 1 bytes to the left\");\n+    EXPECT_DEATH(MemalignRun(align, size, size + 1),\n+                 \"is located 1 bytes to the right\");\n+  }\n+}\n+#endif\n+\n TEST(AddressSanitizer, ThreadedMallocStressTest) {\n   const int kNumThreads = 4;\n   const int kNumIterations = (ASAN_LOW_MEMORY) ? 10000 : 100000;\n@@ -784,14 +823,39 @@ TEST(AddressSanitizer, Store128Test) {\n }\n #endif\n \n-static string RightOOBErrorMessage(int oob_distance) {\n+static string RightOOBErrorMessage(int oob_distance, bool is_write) {\n   assert(oob_distance >= 0);\n   char expected_str[100];\n-  sprintf(expected_str, \"located %d bytes to the right\", oob_distance);\n+  sprintf(expected_str, ASAN_PCRE_DOTALL \"%s.*located %d bytes to the right\",\n+          is_write ? \"WRITE\" : \"READ\", oob_distance);\n   return string(expected_str);\n }\n \n-static string LeftOOBErrorMessage(int oob_distance) {\n+static string RightOOBWriteMessage(int oob_distance) {\n+  return RightOOBErrorMessage(oob_distance, /*is_write*/true);\n+}\n+\n+static string RightOOBReadMessage(int oob_distance) {\n+  return RightOOBErrorMessage(oob_distance, /*is_write*/false);\n+}\n+\n+static string LeftOOBErrorMessage(int oob_distance, bool is_write) {\n+  assert(oob_distance > 0);\n+  char expected_str[100];\n+  sprintf(expected_str, ASAN_PCRE_DOTALL \"%s.*located %d bytes to the left\",\n+          is_write ? \"WRITE\" : \"READ\", oob_distance);\n+  return string(expected_str);\n+}\n+\n+static string LeftOOBWriteMessage(int oob_distance) {\n+  return LeftOOBErrorMessage(oob_distance, /*is_write*/true);\n+}\n+\n+static string LeftOOBReadMessage(int oob_distance) {\n+  return LeftOOBErrorMessage(oob_distance, /*is_write*/false);\n+}\n+\n+static string LeftOOBAccessMessage(int oob_distance) {\n   assert(oob_distance > 0);\n   char expected_str[100];\n   sprintf(expected_str, \"located %d bytes to the left\", oob_distance);\n@@ -805,44 +869,48 @@ void MemSetOOBTestTemplate(size_t length) {\n   T *array = Ident((T*)malloc(size));\n   int element = Ident(42);\n   int zero = Ident(0);\n+  void *(*MEMSET)(void *s, int c, size_t n) = Ident(memset);\n   // memset interval inside array\n-  memset(array, element, size);\n-  memset(array, element, size - 1);\n-  memset(array + length - 1, element, sizeof(T));\n-  memset(array, element, 1);\n+  MEMSET(array, element, size);\n+  MEMSET(array, element, size - 1);\n+  MEMSET(array + length - 1, element, sizeof(T));\n+  MEMSET(array, element, 1);\n \n   // memset 0 bytes\n-  memset(array - 10, element, zero);\n-  memset(array - 1, element, zero);\n-  memset(array, element, zero);\n-  memset(array + length, 0, zero);\n-  memset(array + length + 1, 0, zero);\n+  MEMSET(array - 10, element, zero);\n+  MEMSET(array - 1, element, zero);\n+  MEMSET(array, element, zero);\n+  MEMSET(array + length, 0, zero);\n+  MEMSET(array + length + 1, 0, zero);\n \n   // try to memset bytes to the right of array\n-  EXPECT_DEATH(memset(array, 0, size + 1),\n-               RightOOBErrorMessage(0));\n-  EXPECT_DEATH(memset((char*)(array + length) - 1, element, 6),\n-               RightOOBErrorMessage(4));\n-  EXPECT_DEATH(memset(array + 1, element, size + sizeof(T)),\n-               RightOOBErrorMessage(2 * sizeof(T) - 1));\n+  EXPECT_DEATH(MEMSET(array, 0, size + 1),\n+               RightOOBWriteMessage(0));\n+  EXPECT_DEATH(MEMSET((char*)(array + length) - 1, element, 6),\n+               RightOOBWriteMessage(0));\n+  EXPECT_DEATH(MEMSET(array + 1, element, size + sizeof(T)),\n+               RightOOBWriteMessage(0));\n   // whole interval is to the right\n-  EXPECT_DEATH(memset(array + length + 1, 0, 10),\n-               RightOOBErrorMessage(sizeof(T)));\n+  EXPECT_DEATH(MEMSET(array + length + 1, 0, 10),\n+               RightOOBWriteMessage(sizeof(T)));\n \n   // try to memset bytes to the left of array\n-  EXPECT_DEATH(memset((char*)array - 1, element, size),\n-               LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(memset((char*)array - 5, 0, 6),\n-               LeftOOBErrorMessage(5));\n-  EXPECT_DEATH(memset(array - 5, element, size + 5 * sizeof(T)),\n-               LeftOOBErrorMessage(5 * sizeof(T)));\n+  EXPECT_DEATH(MEMSET((char*)array - 1, element, size),\n+               LeftOOBWriteMessage(1));\n+  EXPECT_DEATH(MEMSET((char*)array - 5, 0, 6),\n+               LeftOOBWriteMessage(5));\n+  if (length >= 100) {\n+    // Large OOB, we find it only if the redzone is large enough.\n+    EXPECT_DEATH(memset(array - 5, element, size + 5 * sizeof(T)),\n+                 LeftOOBWriteMessage(5 * sizeof(T)));\n+  }\n   // whole interval is to the left\n-  EXPECT_DEATH(memset(array - 2, 0, sizeof(T)),\n-               LeftOOBErrorMessage(2 * sizeof(T)));\n+  EXPECT_DEATH(MEMSET(array - 2, 0, sizeof(T)),\n+               LeftOOBWriteMessage(2 * sizeof(T)));\n \n   // try to memset bytes both to the left & to the right\n-  EXPECT_DEATH(memset((char*)array - 2, element, size + 4),\n-               LeftOOBErrorMessage(2));\n+  EXPECT_DEATH(MEMSET((char*)array - 2, element, size + 4),\n+               LeftOOBWriteMessage(2));\n \n   free(array);\n }\n@@ -854,6 +922,51 @@ TEST(AddressSanitizer, MemSetOOBTest) {\n   // We can test arrays of structres/classes here, but what for?\n }\n \n+// Try to allocate two arrays of 'size' bytes that are near each other.\n+// Strictly speaking we are not guaranteed to find such two pointers,\n+// but given the structure of asan's allocator we will.\n+static bool AllocateTwoAdjacentArrays(char **x1, char **x2, size_t size) {\n+  vector<char *> v;\n+  bool res = false;\n+  for (size_t i = 0; i < 1000U && !res; i++) {\n+    v.push_back(new char[size]);\n+    if (i == 0) continue;\n+    sort(v.begin(), v.end());\n+    for (size_t j = 1; j < v.size(); j++) {\n+      assert(v[j] > v[j-1]);\n+      if ((size_t)(v[j] - v[j-1]) < size * 2) {\n+        *x2 = v[j];\n+        *x1 = v[j-1];\n+        res = true;\n+        break;\n+      }\n+    }\n+  }\n+\n+  for (size_t i = 0; i < v.size(); i++) {\n+    if (res && v[i] == *x1) continue;\n+    if (res && v[i] == *x2) continue;\n+    delete [] v[i];\n+  }\n+  return res;\n+}\n+\n+TEST(AddressSanitizer, LargeOOBInMemset) {\n+  for (size_t size = 200; size < 100000; size += size / 2) {\n+    char *x1, *x2;\n+    if (!Ident(AllocateTwoAdjacentArrays)(&x1, &x2, size))\n+      continue;\n+    // fprintf(stderr, \"  large oob memset: %p %p %zd\\n\", x1, x2, size);\n+    // Do a memset on x1 with huge out-of-bound access that will end up in x2.\n+    EXPECT_DEATH(Ident(memset)(x1, 0, size * 2),\n+                 \"is located 0 bytes to the right\");\n+    delete [] x1;\n+    delete [] x2;\n+    return;\n+  }\n+  assert(0 && \"Did not find two adjacent malloc-ed pointers\");\n+}\n+\n // Same test for memcpy and memmove functions\n template <typename T, class M>\n void MemTransferOOBTestTemplate(size_t length) {\n@@ -877,27 +990,27 @@ void MemTransferOOBTestTemplate(size_t length) {\n \n   // try to change mem to the right of dest\n   EXPECT_DEATH(M::transfer(dest + 1, src, size),\n-               RightOOBErrorMessage(sizeof(T) - 1));\n+               RightOOBWriteMessage(0));\n   EXPECT_DEATH(M::transfer((char*)(dest + length) - 1, src, 5),\n-               RightOOBErrorMessage(3));\n+               RightOOBWriteMessage(0));\n \n   // try to change mem to the left of dest\n   EXPECT_DEATH(M::transfer(dest - 2, src, size),\n-               LeftOOBErrorMessage(2 * sizeof(T)));\n+               LeftOOBWriteMessage(2 * sizeof(T)));\n   EXPECT_DEATH(M::transfer((char*)dest - 3, src, 4),\n-               LeftOOBErrorMessage(3));\n+               LeftOOBWriteMessage(3));\n \n   // try to access mem to the right of src\n   EXPECT_DEATH(M::transfer(dest, src + 2, size),\n-               RightOOBErrorMessage(2 * sizeof(T) - 1));\n+               RightOOBReadMessage(0));\n   EXPECT_DEATH(M::transfer(dest, (char*)(src + length) - 3, 6),\n-               RightOOBErrorMessage(2));\n+               RightOOBReadMessage(0));\n \n   // try to access mem to the left of src\n   EXPECT_DEATH(M::transfer(dest, src - 1, size),\n-               LeftOOBErrorMessage(sizeof(T)));\n+               LeftOOBReadMessage(sizeof(T)));\n   EXPECT_DEATH(M::transfer(dest, (char*)src - 6, 7),\n-               LeftOOBErrorMessage(6));\n+               LeftOOBReadMessage(6));\n \n   // Generally we don't need to test cases where both accessing src and writing\n   // to dest address to poisoned memory.\n@@ -906,10 +1019,10 @@ void MemTransferOOBTestTemplate(size_t length) {\n   T *big_dest = Ident((T*)malloc(size * 2));\n   // try to change mem to both sides of dest\n   EXPECT_DEATH(M::transfer(dest - 1, big_src, size * 2),\n-               LeftOOBErrorMessage(sizeof(T)));\n+               LeftOOBWriteMessage(sizeof(T)));\n   // try to access mem to both sides of src\n   EXPECT_DEATH(M::transfer(big_dest, src - 2, size * 2),\n-               LeftOOBErrorMessage(2 * sizeof(T)));\n+               LeftOOBReadMessage(2 * sizeof(T)));\n \n   free(src);\n   free(dest);\n@@ -920,7 +1033,7 @@ void MemTransferOOBTestTemplate(size_t length) {\n class MemCpyWrapper {\n  public:\n   static void* transfer(void *to, const void *from, size_t size) {\n-    return memcpy(to, from, size);\n+    return Ident(memcpy)(to, from, size);\n   }\n };\n TEST(AddressSanitizer, MemCpyOOBTest) {\n@@ -931,7 +1044,7 @@ TEST(AddressSanitizer, MemCpyOOBTest) {\n class MemMoveWrapper {\n  public:\n   static void* transfer(void *to, const void *from, size_t size) {\n-    return memmove(to, from, size);\n+    return Ident(memmove)(to, from, size);\n   }\n };\n TEST(AddressSanitizer, MemMoveOOBTest) {\n@@ -958,15 +1071,15 @@ void StrLenOOBTestTemplate(char *str, size_t length, bool is_global) {\n   // Arg of strlen is not malloced, OOB access\n   if (!is_global) {\n     // We don't insert RedZones to the left of global variables\n-    EXPECT_DEATH(Ident(strlen(str - 1)), LeftOOBErrorMessage(1));\n-    EXPECT_DEATH(Ident(strlen(str - 5)), LeftOOBErrorMessage(5));\n+    EXPECT_DEATH(Ident(strlen(str - 1)), LeftOOBReadMessage(1));\n+    EXPECT_DEATH(Ident(strlen(str - 5)), LeftOOBReadMessage(5));\n   }\n-  EXPECT_DEATH(Ident(strlen(str + length + 1)), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strlen(str + length + 1)), RightOOBReadMessage(0));\n   // Overwrite terminator\n   str[length] = 'a';\n   // String is not zero-terminated, strlen will lead to OOB access\n-  EXPECT_DEATH(Ident(strlen(str)), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Ident(strlen(str + length)), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strlen(str)), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Ident(strlen(str + length)), RightOOBReadMessage(0));\n   // Restore terminator\n   str[length] = 0;\n }\n@@ -1010,11 +1123,11 @@ TEST(AddressSanitizer, StrNLenOOBTest) {\n   str[size - 1] = '\\0';\n   Ident(strnlen(str, 2 * size));\n   // Argument points to not allocated memory.\n-  EXPECT_DEATH(Ident(strnlen(str - 1, 1)), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(strnlen(str + size, 1)), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strnlen(str - 1, 1)), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(strnlen(str + size, 1)), RightOOBReadMessage(0));\n   // Overwrite the terminating '\\0' and hit unallocated memory.\n   str[size - 1] = 'z';\n-  EXPECT_DEATH(Ident(strnlen(str, size + 1)), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strnlen(str, size + 1)), RightOOBReadMessage(0));\n   free(str);\n }\n #endif\n@@ -1030,11 +1143,11 @@ TEST(AddressSanitizer, StrDupOOBTest) {\n   new_str = strdup(str + size - 1);\n   free(new_str);\n   // Argument points to not allocated memory.\n-  EXPECT_DEATH(Ident(strdup(str - 1)), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(strdup(str + size)), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strdup(str - 1)), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(strdup(str + size)), RightOOBReadMessage(0));\n   // Overwrite the terminating '\\0' and hit unallocated memory.\n   str[size - 1] = 'z';\n-  EXPECT_DEATH(Ident(strdup(str)), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strdup(str)), RightOOBReadMessage(0));\n   free(str);\n }\n \n@@ -1048,15 +1161,15 @@ TEST(AddressSanitizer, StrCpyOOBTest) {\n   strcpy(to, from);\n   strcpy(to + to_size - from_size, from);\n   // Length of \"from\" is too small.\n-  EXPECT_DEATH(Ident(strcpy(from, \"hello2\")), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strcpy(from, \"hello2\")), RightOOBWriteMessage(0));\n   // \"to\" or \"from\" points to not allocated memory.\n-  EXPECT_DEATH(Ident(strcpy(to - 1, from)), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(strcpy(to, from - 1)), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(strcpy(to, from + from_size)), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Ident(strcpy(to + to_size, from)), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strcpy(to - 1, from)), LeftOOBWriteMessage(1));\n+  EXPECT_DEATH(Ident(strcpy(to, from - 1)), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(strcpy(to, from + from_size)), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Ident(strcpy(to + to_size, from)), RightOOBWriteMessage(0));\n   // Overwrite the terminating '\\0' character and hit unallocated memory.\n   from[from_size - 1] = '!';\n-  EXPECT_DEATH(Ident(strcpy(to, from)), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(strcpy(to, from)), RightOOBReadMessage(0));\n   free(to);\n   free(from);\n }\n@@ -1078,25 +1191,25 @@ TEST(AddressSanitizer, StrNCpyOOBTest) {\n   strncpy(to + to_size - 1, from, 1);\n   // One of {to, from} points to not allocated memory\n   EXPECT_DEATH(Ident(strncpy(to, from - 1, from_size)),\n-               LeftOOBErrorMessage(1));\n+               LeftOOBReadMessage(1));\n   EXPECT_DEATH(Ident(strncpy(to - 1, from, from_size)),\n-               LeftOOBErrorMessage(1));\n+               LeftOOBWriteMessage(1));\n   EXPECT_DEATH(Ident(strncpy(to, from + from_size, 1)),\n-               RightOOBErrorMessage(0));\n+               RightOOBReadMessage(0));\n   EXPECT_DEATH(Ident(strncpy(to + to_size, from, 1)),\n-               RightOOBErrorMessage(0));\n+               RightOOBWriteMessage(0));\n   // Length of \"to\" is too small\n   EXPECT_DEATH(Ident(strncpy(to + to_size - from_size + 1, from, from_size)),\n-               RightOOBErrorMessage(0));\n+               RightOOBWriteMessage(0));\n   EXPECT_DEATH(Ident(strncpy(to + 1, from, to_size)),\n-               RightOOBErrorMessage(0));\n+               RightOOBWriteMessage(0));\n   // Overwrite terminator in from\n   from[from_size - 1] = '!';\n   // normal strncpy call\n   strncpy(to, from, from_size);\n   // Length of \"from\" is too small\n   EXPECT_DEATH(Ident(strncpy(to, from, to_size)),\n-               RightOOBErrorMessage(0));\n+               RightOOBReadMessage(0));\n   free(to);\n   free(from);\n }\n@@ -1117,11 +1230,11 @@ USED static void RunStrChrTest(PointerToStrChr1 StrChr) {\n   EXPECT_EQ(str + 10, StrChr(str, 'q'));\n   EXPECT_EQ(NULL, StrChr(str, 'a'));\n   // StrChr argument points to not allocated memory.\n-  EXPECT_DEATH(Ident(StrChr(str - 1, 'z')), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(StrChr(str + size, 'z')), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(StrChr(str - 1, 'z')), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(StrChr(str + size, 'z')), RightOOBReadMessage(0));\n   // Overwrite the terminator and hit not allocated memory.\n   str[11] = 'z';\n-  EXPECT_DEATH(Ident(StrChr(str, 'a')), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(StrChr(str, 'a')), RightOOBReadMessage(0));\n   free(str);\n }\n USED static void RunStrChrTest(PointerToStrChr2 StrChr) {\n@@ -1133,11 +1246,11 @@ USED static void RunStrChrTest(PointerToStrChr2 StrChr) {\n   EXPECT_EQ(str + 10, StrChr(str, 'q'));\n   EXPECT_EQ(NULL, StrChr(str, 'a'));\n   // StrChr argument points to not allocated memory.\n-  EXPECT_DEATH(Ident(StrChr(str - 1, 'z')), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(StrChr(str + size, 'z')), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(StrChr(str - 1, 'z')), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(StrChr(str + size, 'z')), RightOOBReadMessage(0));\n   // Overwrite the terminator and hit not allocated memory.\n   str[11] = 'z';\n-  EXPECT_DEATH(Ident(StrChr(str, 'a')), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(StrChr(str, 'a')), RightOOBReadMessage(0));\n   free(str);\n }\n \n@@ -1198,8 +1311,9 @@ TEST(AddressSanitizer, StrCmpAndFriendsLogicTest) {\n typedef int(*PointerToStrCmp)(const char*, const char*);\n void RunStrCmpTest(PointerToStrCmp StrCmp) {\n   size_t size = Ident(100);\n-  char *s1 = MallocAndMemsetString(size);\n-  char *s2 = MallocAndMemsetString(size);\n+  int fill = 'o';\n+  char *s1 = MallocAndMemsetString(size, fill);\n+  char *s2 = MallocAndMemsetString(size, fill);\n   s1[size - 1] = '\\0';\n   s2[size - 1] = '\\0';\n   // Normal StrCmp calls\n@@ -1210,14 +1324,14 @@ void RunStrCmpTest(PointerToStrCmp StrCmp) {\n   s2[size - 1] = 'x';\n   Ident(StrCmp(s1, s2));\n   // One of arguments points to not allocated memory.\n-  EXPECT_DEATH(Ident(StrCmp)(s1 - 1, s2), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(StrCmp)(s1, s2 - 1), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(StrCmp)(s1 + size, s2), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Ident(StrCmp)(s1, s2 + size), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(StrCmp)(s1 - 1, s2), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(StrCmp)(s1, s2 - 1), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(StrCmp)(s1 + size, s2), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Ident(StrCmp)(s1, s2 + size), RightOOBReadMessage(0));\n   // Hit unallocated memory and die.\n-  s2[size - 1] = 'z';\n-  EXPECT_DEATH(Ident(StrCmp)(s1, s1), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Ident(StrCmp)(s1 + size - 1, s2), RightOOBErrorMessage(0));\n+  s1[size - 1] = fill;\n+  EXPECT_DEATH(Ident(StrCmp)(s1, s1), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Ident(StrCmp)(s1 + size - 1, s2), RightOOBReadMessage(0));\n   free(s1);\n   free(s2);\n }\n@@ -1246,13 +1360,13 @@ void RunStrNCmpTest(PointerToStrNCmp StrNCmp) {\n   Ident(StrNCmp(s1 - 1, s2 - 1, 0));\n   Ident(StrNCmp(s1 + size - 1, s2 + size - 1, 1));\n   // One of arguments points to not allocated memory.\n-  EXPECT_DEATH(Ident(StrNCmp)(s1 - 1, s2, 1), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(StrNCmp)(s1, s2 - 1, 1), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(StrNCmp)(s1 + size, s2, 1), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Ident(StrNCmp)(s1, s2 + size, 1), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(StrNCmp)(s1 - 1, s2, 1), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(StrNCmp)(s1, s2 - 1, 1), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(StrNCmp)(s1 + size, s2, 1), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Ident(StrNCmp)(s1, s2 + size, 1), RightOOBReadMessage(0));\n   // Hit unallocated memory and die.\n-  EXPECT_DEATH(Ident(StrNCmp)(s1 + 1, s2 + 1, size), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Ident(StrNCmp)(s1 + size - 1, s2, 2), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(StrNCmp)(s1 + 1, s2 + 1, size), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Ident(StrNCmp)(s1 + size - 1, s2, 2), RightOOBReadMessage(0));\n   free(s1);\n   free(s2);\n }\n@@ -1274,22 +1388,23 @@ TEST(AddressSanitizer, MemCmpOOBTest) {\n   Ident(memcmp(s1 + size - 1, s2 + size - 1, 1));\n   Ident(memcmp(s1 - 1, s2 - 1, 0));\n   // One of arguments points to not allocated memory.\n-  EXPECT_DEATH(Ident(memcmp)(s1 - 1, s2, 1), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(memcmp)(s1, s2 - 1, 1), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(Ident(memcmp)(s1 + size, s2, 1), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Ident(memcmp)(s1, s2 + size, 1), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(memcmp)(s1 - 1, s2, 1), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(memcmp)(s1, s2 - 1, 1), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(Ident(memcmp)(s1 + size, s2, 1), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Ident(memcmp)(s1, s2 + size, 1), RightOOBReadMessage(0));\n   // Hit unallocated memory and die.\n-  EXPECT_DEATH(Ident(memcmp)(s1 + 1, s2 + 1, size), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Ident(memcmp)(s1 + size - 1, s2, 2), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(memcmp)(s1 + 1, s2 + 1, size), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Ident(memcmp)(s1 + size - 1, s2, 2), RightOOBReadMessage(0));\n   // Zero bytes are not terminators and don't prevent from OOB.\n   s1[size - 1] = '\\0';\n   s2[size - 1] = '\\0';\n-  EXPECT_DEATH(Ident(memcmp)(s1, s2, size + 1), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Ident(memcmp)(s1, s2, size + 1), RightOOBReadMessage(0));\n   free(s1);\n   free(s2);\n }\n \n TEST(AddressSanitizer, StrCatOOBTest) {\n+  // strcat() reads strlen(to) bytes from |to| before concatenating.\n   size_t to_size = Ident(100);\n   char *to = MallocAndMemsetString(to_size);\n   to[0] = '\\0';\n@@ -1302,23 +1417,23 @@ TEST(AddressSanitizer, StrCatOOBTest) {\n   strcat(to + from_size, from + from_size - 2);\n   // Passing an invalid pointer is an error even when concatenating an empty\n   // string.\n-  EXPECT_DEATH(strcat(to - 1, from + from_size - 1), LeftOOBErrorMessage(1));\n+  EXPECT_DEATH(strcat(to - 1, from + from_size - 1), LeftOOBAccessMessage(1));\n   // One of arguments points to not allocated memory.\n-  EXPECT_DEATH(strcat(to - 1, from), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(strcat(to, from - 1), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(strcat(to + to_size, from), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(strcat(to, from + from_size), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(strcat(to - 1, from), LeftOOBAccessMessage(1));\n+  EXPECT_DEATH(strcat(to, from - 1), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(strcat(to + to_size, from), RightOOBWriteMessage(0));\n+  EXPECT_DEATH(strcat(to, from + from_size), RightOOBReadMessage(0));\n \n   // \"from\" is not zero-terminated.\n   from[from_size - 1] = 'z';\n-  EXPECT_DEATH(strcat(to, from), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(strcat(to, from), RightOOBReadMessage(0));\n   from[from_size - 1] = '\\0';\n   // \"to\" is not zero-terminated.\n   memset(to, 'z', to_size);\n-  EXPECT_DEATH(strcat(to, from), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(strcat(to, from), RightOOBWriteMessage(0));\n   // \"to\" is too short to fit \"from\".\n   to[to_size - from_size + 1] = '\\0';\n-  EXPECT_DEATH(strcat(to, from), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(strcat(to, from), RightOOBWriteMessage(0));\n   // length of \"to\" is just enough.\n   strcat(to, from + 1);\n \n@@ -1327,6 +1442,7 @@ TEST(AddressSanitizer, StrCatOOBTest) {\n }\n \n TEST(AddressSanitizer, StrNCatOOBTest) {\n+  // strncat() reads strlen(to) bytes from |to| before concatenating.\n   size_t to_size = Ident(100);\n   char *to = MallocAndMemsetString(to_size);\n   to[0] = '\\0';\n@@ -1338,25 +1454,25 @@ TEST(AddressSanitizer, StrNCatOOBTest) {\n   from[from_size - 1] = '\\0';\n   strncat(to, from, 2 * from_size);\n   // Catenating empty string with an invalid string is still an error.\n-  EXPECT_DEATH(strncat(to - 1, from, 0), LeftOOBErrorMessage(1));\n+  EXPECT_DEATH(strncat(to - 1, from, 0), LeftOOBAccessMessage(1));\n   strncat(to, from + from_size - 1, 10);\n   // One of arguments points to not allocated memory.\n-  EXPECT_DEATH(strncat(to - 1, from, 2), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(strncat(to, from - 1, 2), LeftOOBErrorMessage(1));\n-  EXPECT_DEATH(strncat(to + to_size, from, 2), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(strncat(to, from + from_size, 2), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(strncat(to - 1, from, 2), LeftOOBAccessMessage(1));\n+  EXPECT_DEATH(strncat(to, from - 1, 2), LeftOOBReadMessage(1));\n+  EXPECT_DEATH(strncat(to + to_size, from, 2), RightOOBWriteMessage(0));\n+  EXPECT_DEATH(strncat(to, from + from_size, 2), RightOOBReadMessage(0));\n \n   memset(from, 'z', from_size);\n   memset(to, 'z', to_size);\n   to[0] = '\\0';\n   // \"from\" is too short.\n-  EXPECT_DEATH(strncat(to, from, from_size + 1), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(strncat(to, from, from_size + 1), RightOOBReadMessage(0));\n   // \"to\" is not zero-terminated.\n-  EXPECT_DEATH(strncat(to + 1, from, 1), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(strncat(to + 1, from, 1), RightOOBWriteMessage(0));\n   // \"to\" is too short to fit \"from\".\n   to[0] = 'z';\n   to[to_size - from_size + 1] = '\\0';\n-  EXPECT_DEATH(strncat(to, from, from_size - 1), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(strncat(to, from, from_size - 1), RightOOBWriteMessage(0));\n   // \"to\" is just enough.\n   strncat(to, from, from_size - 2);\n \n@@ -1447,10 +1563,10 @@ typedef void(*PointerToCallAtoi)(const char*);\n void RunAtoiOOBTest(PointerToCallAtoi Atoi) {\n   char *array = MallocAndMemsetString(10, '1');\n   // Invalid pointer to the string.\n-  EXPECT_DEATH(Atoi(array + 11), RightOOBErrorMessage(1));\n-  EXPECT_DEATH(Atoi(array - 1), LeftOOBErrorMessage(1));\n+  EXPECT_DEATH(Atoi(array + 11), RightOOBReadMessage(1));\n+  EXPECT_DEATH(Atoi(array - 1), LeftOOBReadMessage(1));\n   // Die if a buffer doesn't have terminating NULL.\n-  EXPECT_DEATH(Atoi(array), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Atoi(array), RightOOBReadMessage(0));\n   // Make last symbol a terminating NULL or other non-digit.\n   array[9] = '\\0';\n   Atoi(array);\n@@ -1459,13 +1575,13 @@ void RunAtoiOOBTest(PointerToCallAtoi Atoi) {\n   Atoi(array + 9);\n   // Sometimes we need to detect overflow if no digits are found.\n   memset(array, ' ', 10);\n-  EXPECT_DEATH(Atoi(array), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Atoi(array), RightOOBReadMessage(0));\n   array[9] = '-';\n-  EXPECT_DEATH(Atoi(array), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Atoi(array + 9), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Atoi(array), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Atoi(array + 9), RightOOBReadMessage(0));\n   array[8] = '-';\n   Atoi(array);\n-  delete array;\n+  free(array);\n }\n \n TEST(AddressSanitizer, AtoiAndFriendsOOBTest) {\n@@ -1489,16 +1605,16 @@ void RunStrtolOOBTest(PointerToCallStrtol Strtol) {\n   array[1] = '2';\n   array[2] = '3';\n   // Invalid pointer to the string.\n-  EXPECT_DEATH(Strtol(array + 3, NULL, 0), RightOOBErrorMessage(0));\n-  EXPECT_DEATH(Strtol(array - 1, NULL, 0), LeftOOBErrorMessage(1));\n+  EXPECT_DEATH(Strtol(array + 3, NULL, 0), RightOOBReadMessage(0));\n+  EXPECT_DEATH(Strtol(array - 1, NULL, 0), LeftOOBReadMessage(1));\n   // Buffer overflow if there is no terminating null (depends on base).\n   Strtol(array, &endptr, 3);\n   EXPECT_EQ(array + 2, endptr);\n-  EXPECT_DEATH(Strtol(array, NULL, 0), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Strtol(array, NULL, 0), RightOOBReadMessage(0));\n   array[2] = 'z';\n   Strtol(array, &endptr, 35);\n   EXPECT_EQ(array + 2, endptr);\n-  EXPECT_DEATH(Strtol(array, NULL, 36), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Strtol(array, NULL, 36), RightOOBReadMessage(0));\n   // Add terminating zero to get rid of overflow.\n   array[2] = '\\0';\n   Strtol(array, NULL, 36);\n@@ -1507,19 +1623,19 @@ void RunStrtolOOBTest(PointerToCallStrtol Strtol) {\n   Strtol(array + 3, NULL, 1);\n   // Sometimes we need to detect overflow if no digits are found.\n   array[0] = array[1] = array[2] = ' ';\n-  EXPECT_DEATH(Strtol(array, NULL, 0), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Strtol(array, NULL, 0), RightOOBReadMessage(0));\n   array[2] = '+';\n-  EXPECT_DEATH(Strtol(array, NULL, 0), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Strtol(array, NULL, 0), RightOOBReadMessage(0));\n   array[2] = '-';\n-  EXPECT_DEATH(Strtol(array, NULL, 0), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(Strtol(array, NULL, 0), RightOOBReadMessage(0));\n   array[1] = '+';\n   Strtol(array, NULL, 0);\n   array[1] = array[2] = 'z';\n   Strtol(array, &endptr, 0);\n   EXPECT_EQ(array, endptr);\n   Strtol(array + 2, NULL, 0);\n   EXPECT_EQ(array, endptr);\n-  delete array;\n+  free(array);\n }\n \n TEST(AddressSanitizer, StrtollOOBTest) {\n@@ -1538,15 +1654,15 @@ typedef void*(*PointerToMemSet)(void*, int, size_t);\n void CallMemSetByPointer(PointerToMemSet MemSet) {\n   size_t size = Ident(100);\n   char *array = Ident((char*)malloc(size));\n-  EXPECT_DEATH(MemSet(array, 0, 101), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(MemSet(array, 0, 101), RightOOBWriteMessage(0));\n   free(array);\n }\n \n void CallMemTransferByPointer(PointerToMemTransfer MemTransfer) {\n   size_t size = Ident(100);\n   char *src = Ident((char*)malloc(size));\n   char *dst = Ident((char*)malloc(size));\n-  EXPECT_DEATH(MemTransfer(dst, src, 101), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(MemTransfer(dst, src, 101), RightOOBWriteMessage(0));\n   free(src);\n   free(dst);\n }\n@@ -1557,12 +1673,51 @@ TEST(AddressSanitizer, DISABLED_MemIntrinsicCallByPointerTest) {\n   CallMemTransferByPointer(&memmove);\n }\n \n+#if defined(__linux__) && !defined(ANDROID) && !defined(__ANDROID__)\n+TEST(AddressSanitizer, pread) {\n+  char *x = new char[10];\n+  int fd = open(\"/proc/self/stat\", O_RDONLY);\n+  ASSERT_GT(fd, 0);\n+  EXPECT_DEATH(pread(fd, x, 15, 0),\n+               ASAN_PCRE_DOTALL\n+               \"AddressSanitizer: heap-buffer-overflow\"\n+               \".* is located 0 bytes to the right of 10-byte region\");\n+  close(fd);\n+  delete [] x;\n+}\n+\n+TEST(AddressSanitizer, pread64) {\n+  char *x = new char[10];\n+  int fd = open(\"/proc/self/stat\", O_RDONLY);\n+  ASSERT_GT(fd, 0);\n+  EXPECT_DEATH(pread64(fd, x, 15, 0),\n+               ASAN_PCRE_DOTALL\n+               \"AddressSanitizer: heap-buffer-overflow\"\n+               \".* is located 0 bytes to the right of 10-byte region\");\n+  close(fd);\n+  delete [] x;\n+}\n+\n+TEST(AddressSanitizer, read) {\n+  char *x = new char[10];\n+  int fd = open(\"/proc/self/stat\", O_RDONLY);\n+  ASSERT_GT(fd, 0);\n+  EXPECT_DEATH(read(fd, x, 15),\n+               ASAN_PCRE_DOTALL\n+               \"AddressSanitizer: heap-buffer-overflow\"\n+               \".* is located 0 bytes to the right of 10-byte region\");\n+  close(fd);\n+  delete [] x;\n+}\n+\n+#endif  // defined(__linux__) && !defined(ANDROID) && !defined(__ANDROID__)\n+\n // This test case fails\n // Clang optimizes memcpy/memset calls which lead to unaligned access\n TEST(AddressSanitizer, DISABLED_MemIntrinsicUnalignedAccessTest) {\n   int size = Ident(4096);\n   char *s = Ident((char*)malloc(size));\n-  EXPECT_DEATH(memset(s + size - 1, 0, 2), RightOOBErrorMessage(0));\n+  EXPECT_DEATH(memset(s + size - 1, 0, 2), RightOOBWriteMessage(0));\n   free(s);\n }\n \n@@ -1617,19 +1772,30 @@ TEST(AddressSanitizer, DISABLED_MallocFreeUnwindAndSymbolizeTest) {\n                \"malloc_fff.*malloc_eee.*malloc_ddd\");\n }\n \n+static bool TryToSetThreadName(const char *name) {\n+#if defined(__linux__) && defined(PR_SET_NAME)\n+  return 0 == prctl(PR_SET_NAME, (unsigned long)name, 0, 0, 0);\n+#else\n+  return false;\n+#endif\n+}\n+\n void *ThreadedTestAlloc(void *a) {\n+  EXPECT_EQ(true, TryToSetThreadName(\"AllocThr\"));\n   int **p = (int**)a;\n   *p = new int;\n   return 0;\n }\n \n void *ThreadedTestFree(void *a) {\n+  EXPECT_EQ(true, TryToSetThreadName(\"FreeThr\"));\n   int **p = (int**)a;\n   delete *p;\n   return 0;\n }\n \n void *ThreadedTestUse(void *a) {\n+  EXPECT_EQ(true, TryToSetThreadName(\"UseThr\"));\n   int **p = (int**)a;\n   **p = 1;\n   return 0;\n@@ -1654,6 +1820,30 @@ TEST(AddressSanitizer, ThreadedTest) {\n                \".*Thread T.*created\");\n }\n \n+void *ThreadedTestFunc(void *unused) {\n+  // Check if prctl(PR_SET_NAME) is supported. Return if not.\n+  if (!TryToSetThreadName(\"TestFunc\"))\n+    return 0;\n+  EXPECT_DEATH(ThreadedTestSpawn(),\n+               ASAN_PCRE_DOTALL\n+               \"WRITE .*thread T. .UseThr.\"\n+               \".*freed by thread T. .FreeThr. here:\"\n+               \".*previously allocated by thread T. .AllocThr. here:\"\n+               \".*Thread T. .UseThr. created by T.*TestFunc\"\n+               \".*Thread T. .FreeThr. created by T\"\n+               \".*Thread T. .AllocThr. created by T\"\n+               \"\");\n+  return 0;\n+}\n+\n+TEST(AddressSanitizer, ThreadNamesTest) {\n+  // Run ThreadedTestFunc in a separate thread because it tries to set a\n+  // thread name and we don't want to change the main thread's name.\n+  pthread_t t;\n+  PTHREAD_CREATE(&t, 0, ThreadedTestFunc, 0);\n+  PTHREAD_JOIN(t, 0);\n+}\n+\n #if ASAN_NEEDS_SEGV\n TEST(AddressSanitizer, ShadowGapTest) {\n #if SANITIZER_WORDSIZE == 32\n@@ -1868,6 +2058,27 @@ TEST(AddressSanitizer, AttributeNoAddressSafetyTest) {\n   Ident(NoAddressSafety)();\n }\n \n+static string MismatchStr(const string &str) {\n+  return string(\"AddressSanitizer: alloc-dealloc-mismatch \\\\(\") + str;\n+}\n+\n+// This test is disabled until we enable alloc_dealloc_mismatch by default.\n+// The feature is also tested by lit tests.\n+TEST(AddressSanitizer, DISABLED_AllocDeallocMismatch) {\n+  EXPECT_DEATH(free(Ident(new int)),\n+               MismatchStr(\"operator new vs free\"));\n+  EXPECT_DEATH(free(Ident(new int[2])),\n+               MismatchStr(\"operator new \\\\[\\\\] vs free\"));\n+  EXPECT_DEATH(delete (Ident(new int[2])),\n+               MismatchStr(\"operator new \\\\[\\\\] vs operator delete\"));\n+  EXPECT_DEATH(delete (Ident((int*)malloc(2 * sizeof(int)))),\n+               MismatchStr(\"malloc vs operator delete\"));\n+  EXPECT_DEATH(delete [] (Ident(new int)),\n+               MismatchStr(\"operator new vs operator delete \\\\[\\\\]\"));\n+  EXPECT_DEATH(delete [] (Ident((int*)malloc(2 * sizeof(int)))),\n+               MismatchStr(\"malloc vs operator delete \\\\[\\\\]\"));\n+}\n+\n // ------------------ demo tests; run each one-by-one -------------\n // e.g. --gtest_filter=*DemoOOBLeftHigh --gtest_also_run_disabled_tests\n TEST(AddressSanitizer, DISABLED_DemoThreadedTest) {\n@@ -2033,53 +2244,56 @@ TEST(AddressSanitizerMac, DISABLED_CFAllocatorMallocZoneDoubleFree) {\n   EXPECT_DEATH(CFAllocatorMallocZoneDoubleFree(), \"attempting double-free\");\n }\n \n+// For libdispatch tests below we check that ASan got to the shadow byte\n+// legend, i.e. managed to print the thread stacks (this almost certainly\n+// means that the libdispatch task creation has been intercepted correctly).\n TEST(AddressSanitizerMac, GCDDispatchAsync) {\n   // Make sure the whole ASan report is printed, i.e. that we don't die\n   // on a CHECK.\n-  EXPECT_DEATH(TestGCDDispatchAsync(), \"Shadow byte and word\");\n+  EXPECT_DEATH(TestGCDDispatchAsync(), \"Shadow byte legend\");\n }\n \n TEST(AddressSanitizerMac, GCDDispatchSync) {\n   // Make sure the whole ASan report is printed, i.e. that we don't die\n   // on a CHECK.\n-  EXPECT_DEATH(TestGCDDispatchSync(), \"Shadow byte and word\");\n+  EXPECT_DEATH(TestGCDDispatchSync(), \"Shadow byte legend\");\n }\n \n \n TEST(AddressSanitizerMac, GCDReuseWqthreadsAsync) {\n   // Make sure the whole ASan report is printed, i.e. that we don't die\n   // on a CHECK.\n-  EXPECT_DEATH(TestGCDReuseWqthreadsAsync(), \"Shadow byte and word\");\n+  EXPECT_DEATH(TestGCDReuseWqthreadsAsync(), \"Shadow byte legend\");\n }\n \n TEST(AddressSanitizerMac, GCDReuseWqthreadsSync) {\n   // Make sure the whole ASan report is printed, i.e. that we don't die\n   // on a CHECK.\n-  EXPECT_DEATH(TestGCDReuseWqthreadsSync(), \"Shadow byte and word\");\n+  EXPECT_DEATH(TestGCDReuseWqthreadsSync(), \"Shadow byte legend\");\n }\n \n TEST(AddressSanitizerMac, GCDDispatchAfter) {\n   // Make sure the whole ASan report is printed, i.e. that we don't die\n   // on a CHECK.\n-  EXPECT_DEATH(TestGCDDispatchAfter(), \"Shadow byte and word\");\n+  EXPECT_DEATH(TestGCDDispatchAfter(), \"Shadow byte legend\");\n }\n \n TEST(AddressSanitizerMac, GCDSourceEvent) {\n   // Make sure the whole ASan report is printed, i.e. that we don't die\n   // on a CHECK.\n-  EXPECT_DEATH(TestGCDSourceEvent(), \"Shadow byte and word\");\n+  EXPECT_DEATH(TestGCDSourceEvent(), \"Shadow byte legend\");\n }\n \n TEST(AddressSanitizerMac, GCDSourceCancel) {\n   // Make sure the whole ASan report is printed, i.e. that we don't die\n   // on a CHECK.\n-  EXPECT_DEATH(TestGCDSourceCancel(), \"Shadow byte and word\");\n+  EXPECT_DEATH(TestGCDSourceCancel(), \"Shadow byte legend\");\n }\n \n TEST(AddressSanitizerMac, GCDGroupAsync) {\n   // Make sure the whole ASan report is printed, i.e. that we don't die\n   // on a CHECK.\n-  EXPECT_DEATH(TestGCDGroupAsync(), \"Shadow byte and word\");\n+  EXPECT_DEATH(TestGCDGroupAsync(), \"Shadow byte legend\");\n }\n \n void *MallocIntrospectionLockWorker(void *_) {\n@@ -2172,7 +2386,7 @@ TEST(AddressSanitizerMac, NSURLDeallocation) {\n TEST(AddressSanitizerMac, Mstats) {\n   malloc_statistics_t stats1, stats2;\n   malloc_zone_statistics(/*all zones*/NULL, &stats1);\n-  const int kMallocSize = 100000;\n+  const size_t kMallocSize = 100000;\n   void *alloc = Ident(malloc(kMallocSize));\n   malloc_zone_statistics(/*all zones*/NULL, &stats2);\n   EXPECT_GT(stats2.blocks_in_use, stats1.blocks_in_use);"}, {"sha": "e0e39c3e72c8564de393cd8c71949bd742f83c85", "filename": "libsanitizer/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2FChangeLog?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -1,3 +1,13 @@\n+2013-01-10  Kostya Serebryany  <kcc@google.com>\n+\n+\t* All source files: Merge from upstream r171973.\n+\t* sanitizer_common/Makefile.am: Added new files.\n+\t* asan/Makefile.am: Likewise.\n+\t* tsan/Makefile.am: Likewise.\n+\t* sanitizer_common/Makefile.in: Regenerated.\n+\t* asan/Makefile.in: Likewise.\n+\t* tsan/Makefile.in: Likewise.\n+\n 2013-01-07  H.J. Lu  <hongjiu.lu@intel.com>\n \n \t* asan/Makefile.am (libasan_la_LIBADD): Replace"}, {"sha": "ff637c242ba7bcbe26635cb45e5f8abd12f86835", "filename": "libsanitizer/MERGE", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2FMERGE", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2FMERGE", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2FMERGE?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -1,4 +1,4 @@\n-169392\n+171973\n \n The first line of this file holds the svn revision number of the\n last merge done from the master library sources."}, {"sha": "7d675001a37f522e374444cf4de624609876e9c9", "filename": "libsanitizer/asan/Makefile.am", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2FMakefile.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2FMakefile.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2FMakefile.am?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -15,6 +15,7 @@ toolexeclib_LTLIBRARIES = libasan.la\n \n asan_files = \\\n \tasan_allocator.cc \\\n+\tasan_allocator2.cc \\\n \tasan_interceptors.cc \\\n \tasan_mac.cc \\\n \tasan_malloc_mac.cc \\\n@@ -23,6 +24,7 @@ asan_files = \\\n \tasan_rtl.cc \\\n \tasan_stats.cc \\\n \tasan_thread_registry.cc \\\n+\tasan_fake_stack.cc \\\n \tasan_globals.cc \\\n \tasan_linux.cc \\\n \tasan_malloc_linux.cc \\"}, {"sha": "4578391b3c08b7605cb5560bf628702eba036f90", "filename": "libsanitizer/asan/Makefile.in", "status": "modified", "additions": 18, "deletions": 13, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2FMakefile.in?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -84,19 +84,20 @@ am__DEPENDENCIES_1 =\n @USING_MAC_INTERPOSE_FALSE@\t$(am__DEPENDENCIES_1)\n @USING_MAC_INTERPOSE_TRUE@libasan_la_DEPENDENCIES = $(top_builddir)/sanitizer_common/libsanitizer_common.la \\\n @USING_MAC_INTERPOSE_TRUE@\t$(am__DEPENDENCIES_1)\n-am__libasan_la_SOURCES_DIST = asan_allocator.cc asan_interceptors.cc \\\n-\tasan_mac.cc asan_malloc_mac.cc asan_new_delete.cc \\\n-\tasan_posix.cc asan_rtl.cc asan_stats.cc \\\n-\tasan_thread_registry.cc asan_globals.cc asan_linux.cc \\\n-\tasan_malloc_linux.cc asan_malloc_win.cc asan_poisoning.cc \\\n-\tasan_report.cc asan_stack.cc asan_thread.cc asan_win.cc \\\n-\tdynamic/asan_interceptors_dynamic.cc\n-am__objects_1 = asan_allocator.lo asan_interceptors.lo asan_mac.lo \\\n-\tasan_malloc_mac.lo asan_new_delete.lo asan_posix.lo \\\n-\tasan_rtl.lo asan_stats.lo asan_thread_registry.lo \\\n-\tasan_globals.lo asan_linux.lo asan_malloc_linux.lo \\\n-\tasan_malloc_win.lo asan_poisoning.lo asan_report.lo \\\n-\tasan_stack.lo asan_thread.lo asan_win.lo\n+am__libasan_la_SOURCES_DIST = asan_allocator.cc asan_allocator2.cc \\\n+\tasan_interceptors.cc asan_mac.cc asan_malloc_mac.cc \\\n+\tasan_new_delete.cc asan_posix.cc asan_rtl.cc asan_stats.cc \\\n+\tasan_thread_registry.cc asan_fake_stack.cc asan_globals.cc \\\n+\tasan_linux.cc asan_malloc_linux.cc asan_malloc_win.cc \\\n+\tasan_poisoning.cc asan_report.cc asan_stack.cc asan_thread.cc \\\n+\tasan_win.cc dynamic/asan_interceptors_dynamic.cc\n+am__objects_1 = asan_allocator.lo asan_allocator2.lo \\\n+\tasan_interceptors.lo asan_mac.lo asan_malloc_mac.lo \\\n+\tasan_new_delete.lo asan_posix.lo asan_rtl.lo asan_stats.lo \\\n+\tasan_thread_registry.lo asan_fake_stack.lo asan_globals.lo \\\n+\tasan_linux.lo asan_malloc_linux.lo asan_malloc_win.lo \\\n+\tasan_poisoning.lo asan_report.lo asan_stack.lo asan_thread.lo \\\n+\tasan_win.lo\n @USING_MAC_INTERPOSE_TRUE@am__objects_2 =  \\\n @USING_MAC_INTERPOSE_TRUE@\tasan_interceptors_dynamic.lo\n am_libasan_la_OBJECTS = $(am__objects_1) $(am__objects_2)\n@@ -269,6 +270,7 @@ ACLOCAL_AMFLAGS = -I $(top_srcdir) -I $(top_srcdir)/config\n toolexeclib_LTLIBRARIES = libasan.la\n asan_files = \\\n \tasan_allocator.cc \\\n+\tasan_allocator2.cc \\\n \tasan_interceptors.cc \\\n \tasan_mac.cc \\\n \tasan_malloc_mac.cc \\\n@@ -277,6 +279,7 @@ asan_files = \\\n \tasan_rtl.cc \\\n \tasan_stats.cc \\\n \tasan_thread_registry.cc \\\n+\tasan_fake_stack.cc \\\n \tasan_globals.cc \\\n \tasan_linux.cc \\\n \tasan_malloc_linux.cc \\\n@@ -409,6 +412,8 @@ distclean-compile:\n \t-rm -f *.tab.c\n \n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/asan_allocator.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/asan_allocator2.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/asan_fake_stack.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/asan_globals.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/asan_interceptors.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/asan_interceptors_dynamic.Plo@am__quote@"}, {"sha": "b170fe723d2d3882b471745482926aa065b0c672", "filename": "libsanitizer/asan/asan_allocator.cc", "status": "modified", "additions": 46, "deletions": 285, "changes": 331, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_allocator.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_allocator.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_allocator.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -22,8 +22,9 @@\n // Once freed, the body of the chunk contains the stack trace of the free call.\n //\n //===----------------------------------------------------------------------===//\n-\n #include \"asan_allocator.h\"\n+\n+#if ASAN_ALLOCATOR_VERSION == 1\n #include \"asan_interceptors.h\"\n #include \"asan_internal.h\"\n #include \"asan_lock.h\"\n@@ -35,10 +36,6 @@\n #include \"sanitizer/asan_interface.h\"\n #include \"sanitizer_common/sanitizer_atomic.h\"\n \n-#if defined(_WIN32) && !defined(__clang__)\n-#include <intrin.h>\n-#endif\n-\n namespace __asan {\n \n #define REDZONE ((uptr)(flags()->redzone))\n@@ -58,42 +55,6 @@ static const uptr kMallocSizeClassStep = 1UL << kMallocSizeClassStepLog;\n static const uptr kMaxAllowedMallocSize =\n     (SANITIZER_WORDSIZE == 32) ? 3UL << 30 : 8UL << 30;\n \n-static inline bool IsAligned(uptr a, uptr alignment) {\n-  return (a & (alignment - 1)) == 0;\n-}\n-\n-static inline uptr Log2(uptr x) {\n-  CHECK(IsPowerOfTwo(x));\n-#if !defined(_WIN32) || defined(__clang__)\n-  return __builtin_ctzl(x);\n-#elif defined(_WIN64)\n-  unsigned long ret;  // NOLINT\n-  _BitScanForward64(&ret, x);\n-  return ret;\n-#else\n-  unsigned long ret;  // NOLINT\n-  _BitScanForward(&ret, x);\n-  return ret;\n-#endif\n-}\n-\n-static inline uptr RoundUpToPowerOfTwo(uptr size) {\n-  CHECK(size);\n-  if (IsPowerOfTwo(size)) return size;\n-\n-  unsigned long up;  // NOLINT\n-#if !defined(_WIN32) || defined(__clang__)\n-  up = SANITIZER_WORDSIZE - 1 - __builtin_clzl(size);\n-#elif defined(_WIN64)\n-  _BitScanReverse64(&up, size);\n-#else\n-  _BitScanReverse(&up, size);\n-#endif\n-  CHECK(size < (1ULL << (up + 1)));\n-  CHECK(size > (1ULL << up));\n-  return 1UL << (up + 1);\n-}\n-\n static inline uptr SizeClassToSize(u8 size_class) {\n   CHECK(size_class < kNumberOfSizeClasses);\n   if (size_class <= kMallocSizeClassStepLog) {\n@@ -165,7 +126,8 @@ struct ChunkBase {\n \n   // Second 8 bytes.\n   uptr alignment_log : 8;\n-  uptr used_size : FIRST_32_SECOND_64(32, 56);  // Size requested by the user.\n+  uptr alloc_type    : 2;\n+  uptr used_size : FIRST_32_SECOND_64(32, 54);  // Size requested by the user.\n \n   // This field may overlap with the user area and thus should not\n   // be used while the chunk is in CHUNK_ALLOCATED state.\n@@ -215,33 +177,6 @@ void AsanChunkView::GetFreeStack(StackTrace *stack) {\n                               chunk_->compressed_free_stack_size());\n }\n \n-bool AsanChunkView::AddrIsInside(uptr addr, uptr access_size, uptr *offset) {\n-  if (addr >= Beg() && (addr + access_size) <= End()) {\n-    *offset = addr - Beg();\n-    return true;\n-  }\n-  return false;\n-}\n-\n-bool AsanChunkView::AddrIsAtLeft(uptr addr, uptr access_size, uptr *offset) {\n-  if (addr < Beg()) {\n-    *offset = Beg() - addr;\n-    return true;\n-  }\n-  return false;\n-}\n-\n-bool AsanChunkView::AddrIsAtRight(uptr addr, uptr access_size, uptr *offset) {\n-  if (addr + access_size >= End()) {\n-    if (addr <= End())\n-      *offset = 0;\n-    else\n-      *offset = addr - End();\n-    return true;\n-  }\n-  return false;\n-}\n-\n static AsanChunk *PtrToChunk(uptr ptr) {\n   AsanChunk *m = (AsanChunk*)(ptr - REDZONE);\n   if (m->chunk_state == CHUNK_MEMALIGN) {\n@@ -252,34 +187,13 @@ static AsanChunk *PtrToChunk(uptr ptr) {\n \n void AsanChunkFifoList::PushList(AsanChunkFifoList *q) {\n   CHECK(q->size() > 0);\n-  if (last_) {\n-    CHECK(first_);\n-    CHECK(!last_->next);\n-    last_->next = q->first_;\n-    last_ = q->last_;\n-  } else {\n-    CHECK(!first_);\n-    last_ = q->last_;\n-    first_ = q->first_;\n-    CHECK(first_);\n-  }\n-  CHECK(last_);\n-  CHECK(!last_->next);\n   size_ += q->size();\n+  append_back(q);\n   q->clear();\n }\n \n void AsanChunkFifoList::Push(AsanChunk *n) {\n-  CHECK(n->next == 0);\n-  if (last_) {\n-    CHECK(first_);\n-    CHECK(!last_->next);\n-    last_->next = n;\n-    last_ = n;\n-  } else {\n-    CHECK(!first_);\n-    last_ = first_ = n;\n-  }\n+  push_back(n);\n   size_ += n->Size();\n }\n \n@@ -288,15 +202,9 @@ void AsanChunkFifoList::Push(AsanChunk *n) {\n // ago. Not sure if we can or want to do anything with this.\n AsanChunk *AsanChunkFifoList::Pop() {\n   CHECK(first_);\n-  AsanChunk *res = first_;\n-  first_ = first_->next;\n-  if (first_ == 0)\n-    last_ = 0;\n-  CHECK(size_ >= res->Size());\n+  AsanChunk *res = front();\n   size_ -= res->Size();\n-  if (last_) {\n-    CHECK(!last_->next);\n-  }\n+  pop_front();\n   return res;\n }\n \n@@ -588,7 +496,8 @@ AsanChunkView FindHeapChunkByAddress(uptr address) {\n   return AsanChunkView(malloc_info.FindChunkByAddr(address));\n }\n \n-static u8 *Allocate(uptr alignment, uptr size, StackTrace *stack) {\n+static u8 *Allocate(uptr alignment, uptr size, StackTrace *stack,\n+                    AllocType alloc_type) {\n   __asan_init();\n   CHECK(stack);\n   if (size == 0) {\n@@ -645,6 +554,7 @@ static u8 *Allocate(uptr alignment, uptr size, StackTrace *stack) {\n   CHECK(m);\n   CHECK(m->chunk_state == CHUNK_AVAILABLE);\n   m->chunk_state = CHUNK_ALLOCATED;\n+  m->alloc_type = alloc_type;\n   m->next = 0;\n   CHECK(m->Size() == size_to_allocate);\n   uptr addr = (uptr)m + REDZONE;\n@@ -679,7 +589,7 @@ static u8 *Allocate(uptr alignment, uptr size, StackTrace *stack) {\n   return (u8*)addr;\n }\n \n-static void Deallocate(u8 *ptr, StackTrace *stack) {\n+static void Deallocate(u8 *ptr, StackTrace *stack, AllocType alloc_type) {\n   if (!ptr) return;\n   CHECK(stack);\n \n@@ -700,6 +610,9 @@ static void Deallocate(u8 *ptr, StackTrace *stack) {\n     ReportFreeNotMalloced((uptr)ptr, stack);\n   }\n   CHECK(old_chunk_state == CHUNK_ALLOCATED);\n+  if (m->alloc_type != alloc_type && flags()->alloc_dealloc_mismatch)\n+    ReportAllocTypeMismatch((uptr)ptr, stack,\n+                            (AllocType)m->alloc_type, (AllocType)alloc_type);\n   // With REDZONE==16 m->next is in the user area, otherwise it should be 0.\n   CHECK(REDZONE <= 16 || !m->next);\n   CHECK(m->free_tid == kInvalidTid);\n@@ -744,18 +657,19 @@ static u8 *Reallocate(u8 *old_ptr, uptr new_size,\n   CHECK(m->chunk_state == CHUNK_ALLOCATED);\n   uptr old_size = m->used_size;\n   uptr memcpy_size = Min(new_size, old_size);\n-  u8 *new_ptr = Allocate(0, new_size, stack);\n+  u8 *new_ptr = Allocate(0, new_size, stack, FROM_MALLOC);\n   if (new_ptr) {\n     CHECK(REAL(memcpy) != 0);\n     REAL(memcpy)(new_ptr, old_ptr, memcpy_size);\n-    Deallocate(old_ptr, stack);\n+    Deallocate(old_ptr, stack, FROM_MALLOC);\n   }\n   return new_ptr;\n }\n \n }  // namespace __asan\n \n-// Default (no-op) implementation of malloc hooks.\n+#if !SANITIZER_SUPPORTS_WEAK_HOOKS\n+// Provide default (no-op) implementation of malloc hooks.\n extern \"C\" {\n SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE\n void __asan_malloc_hook(void *ptr, uptr size) {\n@@ -767,53 +681,58 @@ void __asan_free_hook(void *ptr) {\n   (void)ptr;\n }\n }  // extern \"C\"\n+#endif\n \n namespace __asan {\n \n+void PrintInternalAllocatorStats() {\n+}\n+\n SANITIZER_INTERFACE_ATTRIBUTE\n-void *asan_memalign(uptr alignment, uptr size, StackTrace *stack) {\n-  void *ptr = (void*)Allocate(alignment, size, stack);\n-  __asan_malloc_hook(ptr, size);\n+void *asan_memalign(uptr alignment, uptr size, StackTrace *stack,\n+                    AllocType alloc_type) {\n+  void *ptr = (void*)Allocate(alignment, size, stack, alloc_type);\n+  ASAN_MALLOC_HOOK(ptr, size);\n   return ptr;\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n-void asan_free(void *ptr, StackTrace *stack) {\n-  __asan_free_hook(ptr);\n-  Deallocate((u8*)ptr, stack);\n+void asan_free(void *ptr, StackTrace *stack, AllocType alloc_type) {\n+  ASAN_FREE_HOOK(ptr);\n+  Deallocate((u8*)ptr, stack, alloc_type);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n void *asan_malloc(uptr size, StackTrace *stack) {\n-  void *ptr = (void*)Allocate(0, size, stack);\n-  __asan_malloc_hook(ptr, size);\n+  void *ptr = (void*)Allocate(0, size, stack, FROM_MALLOC);\n+  ASAN_MALLOC_HOOK(ptr, size);\n   return ptr;\n }\n \n void *asan_calloc(uptr nmemb, uptr size, StackTrace *stack) {\n-  void *ptr = (void*)Allocate(0, nmemb * size, stack);\n+  void *ptr = (void*)Allocate(0, nmemb * size, stack, FROM_MALLOC);\n   if (ptr)\n     REAL(memset)(ptr, 0, nmemb * size);\n-  __asan_malloc_hook(ptr, nmemb * size);\n+  ASAN_MALLOC_HOOK(ptr, size);\n   return ptr;\n }\n \n void *asan_realloc(void *p, uptr size, StackTrace *stack) {\n   if (p == 0) {\n-    void *ptr = (void*)Allocate(0, size, stack);\n-    __asan_malloc_hook(ptr, size);\n+    void *ptr = (void*)Allocate(0, size, stack, FROM_MALLOC);\n+    ASAN_MALLOC_HOOK(ptr, size);\n     return ptr;\n   } else if (size == 0) {\n-    __asan_free_hook(p);\n-    Deallocate((u8*)p, stack);\n+    ASAN_FREE_HOOK(p);\n+    Deallocate((u8*)p, stack, FROM_MALLOC);\n     return 0;\n   }\n   return Reallocate((u8*)p, size, stack);\n }\n \n void *asan_valloc(uptr size, StackTrace *stack) {\n-  void *ptr = (void*)Allocate(GetPageSizeCached(), size, stack);\n-  __asan_malloc_hook(ptr, size);\n+  void *ptr = (void*)Allocate(GetPageSizeCached(), size, stack, FROM_MALLOC);\n+  ASAN_MALLOC_HOOK(ptr, size);\n   return ptr;\n }\n \n@@ -824,16 +743,16 @@ void *asan_pvalloc(uptr size, StackTrace *stack) {\n     // pvalloc(0) should allocate one page.\n     size = PageSize;\n   }\n-  void *ptr = (void*)Allocate(PageSize, size, stack);\n-  __asan_malloc_hook(ptr, size);\n+  void *ptr = (void*)Allocate(PageSize, size, stack, FROM_MALLOC);\n+  ASAN_MALLOC_HOOK(ptr, size);\n   return ptr;\n }\n \n int asan_posix_memalign(void **memptr, uptr alignment, uptr size,\n                           StackTrace *stack) {\n-  void *ptr = Allocate(alignment, size, stack);\n+  void *ptr = Allocate(alignment, size, stack, FROM_MALLOC);\n   CHECK(IsAligned((uptr)ptr, alignment));\n-  __asan_malloc_hook(ptr, size);\n+  ASAN_MALLOC_HOOK(ptr, size);\n   *memptr = ptr;\n   return 0;\n }\n@@ -860,170 +779,11 @@ void asan_mz_force_unlock() {\n   malloc_info.ForceUnlock();\n }\n \n-// ---------------------- Fake stack-------------------- {{{1\n-FakeStack::FakeStack() {\n-  CHECK(REAL(memset) != 0);\n-  REAL(memset)(this, 0, sizeof(*this));\n-}\n-\n-bool FakeStack::AddrIsInSizeClass(uptr addr, uptr size_class) {\n-  uptr mem = allocated_size_classes_[size_class];\n-  uptr size = ClassMmapSize(size_class);\n-  bool res = mem && addr >= mem && addr < mem + size;\n-  return res;\n-}\n-\n-uptr FakeStack::AddrIsInFakeStack(uptr addr) {\n-  for (uptr i = 0; i < kNumberOfSizeClasses; i++) {\n-    if (AddrIsInSizeClass(addr, i)) return allocated_size_classes_[i];\n-  }\n-  return 0;\n-}\n-\n-// We may want to compute this during compilation.\n-inline uptr FakeStack::ComputeSizeClass(uptr alloc_size) {\n-  uptr rounded_size = RoundUpToPowerOfTwo(alloc_size);\n-  uptr log = Log2(rounded_size);\n-  CHECK(alloc_size <= (1UL << log));\n-  if (!(alloc_size > (1UL << (log-1)))) {\n-    Printf(\"alloc_size %zu log %zu\\n\", alloc_size, log);\n-  }\n-  CHECK(alloc_size > (1UL << (log-1)));\n-  uptr res = log < kMinStackFrameSizeLog ? 0 : log - kMinStackFrameSizeLog;\n-  CHECK(res < kNumberOfSizeClasses);\n-  CHECK(ClassSize(res) >= rounded_size);\n-  return res;\n-}\n-\n-void FakeFrameFifo::FifoPush(FakeFrame *node) {\n-  CHECK(node);\n-  node->next = 0;\n-  if (first_ == 0 && last_ == 0) {\n-    first_ = last_ = node;\n-  } else {\n-    CHECK(first_);\n-    CHECK(last_);\n-    last_->next = node;\n-    last_ = node;\n-  }\n-}\n-\n-FakeFrame *FakeFrameFifo::FifoPop() {\n-  CHECK(first_ && last_ && \"Exhausted fake stack\");\n-  FakeFrame *res = 0;\n-  if (first_ == last_) {\n-    res = first_;\n-    first_ = last_ = 0;\n-  } else {\n-    res = first_;\n-    first_ = first_->next;\n-  }\n-  return res;\n-}\n-\n-void FakeStack::Init(uptr stack_size) {\n-  stack_size_ = stack_size;\n-  alive_ = true;\n-}\n-\n-void FakeStack::Cleanup() {\n-  alive_ = false;\n-  for (uptr i = 0; i < kNumberOfSizeClasses; i++) {\n-    uptr mem = allocated_size_classes_[i];\n-    if (mem) {\n-      PoisonShadow(mem, ClassMmapSize(i), 0);\n-      allocated_size_classes_[i] = 0;\n-      UnmapOrDie((void*)mem, ClassMmapSize(i));\n-    }\n-  }\n-}\n-\n-uptr FakeStack::ClassMmapSize(uptr size_class) {\n-  return RoundUpToPowerOfTwo(stack_size_);\n-}\n-\n-void FakeStack::AllocateOneSizeClass(uptr size_class) {\n-  CHECK(ClassMmapSize(size_class) >= GetPageSizeCached());\n-  uptr new_mem = (uptr)MmapOrDie(\n-      ClassMmapSize(size_class), __FUNCTION__);\n-  // Printf(\"T%d new_mem[%zu]: %p-%p mmap %zu\\n\",\n-  //       asanThreadRegistry().GetCurrent()->tid(),\n-  //       size_class, new_mem, new_mem + ClassMmapSize(size_class),\n-  //       ClassMmapSize(size_class));\n-  uptr i;\n-  for (i = 0; i < ClassMmapSize(size_class);\n-       i += ClassSize(size_class)) {\n-    size_classes_[size_class].FifoPush((FakeFrame*)(new_mem + i));\n-  }\n-  CHECK(i == ClassMmapSize(size_class));\n-  allocated_size_classes_[size_class] = new_mem;\n-}\n-\n-uptr FakeStack::AllocateStack(uptr size, uptr real_stack) {\n-  if (!alive_) return real_stack;\n-  CHECK(size <= kMaxStackMallocSize && size > 1);\n-  uptr size_class = ComputeSizeClass(size);\n-  if (!allocated_size_classes_[size_class]) {\n-    AllocateOneSizeClass(size_class);\n-  }\n-  FakeFrame *fake_frame = size_classes_[size_class].FifoPop();\n-  CHECK(fake_frame);\n-  fake_frame->size_minus_one = size - 1;\n-  fake_frame->real_stack = real_stack;\n-  while (FakeFrame *top = call_stack_.top()) {\n-    if (top->real_stack > real_stack) break;\n-    call_stack_.LifoPop();\n-    DeallocateFrame(top);\n-  }\n-  call_stack_.LifoPush(fake_frame);\n-  uptr ptr = (uptr)fake_frame;\n-  PoisonShadow(ptr, size, 0);\n-  return ptr;\n-}\n-\n-void FakeStack::DeallocateFrame(FakeFrame *fake_frame) {\n-  CHECK(alive_);\n-  uptr size = fake_frame->size_minus_one + 1;\n-  uptr size_class = ComputeSizeClass(size);\n-  CHECK(allocated_size_classes_[size_class]);\n-  uptr ptr = (uptr)fake_frame;\n-  CHECK(AddrIsInSizeClass(ptr, size_class));\n-  CHECK(AddrIsInSizeClass(ptr + size - 1, size_class));\n-  size_classes_[size_class].FifoPush(fake_frame);\n-}\n-\n-void FakeStack::OnFree(uptr ptr, uptr size, uptr real_stack) {\n-  FakeFrame *fake_frame = (FakeFrame*)ptr;\n-  CHECK(fake_frame->magic = kRetiredStackFrameMagic);\n-  CHECK(fake_frame->descr != 0);\n-  CHECK(fake_frame->size_minus_one == size - 1);\n-  PoisonShadow(ptr, size, kAsanStackAfterReturnMagic);\n-}\n-\n }  // namespace __asan\n \n // ---------------------- Interface ---------------- {{{1\n using namespace __asan;  // NOLINT\n \n-uptr __asan_stack_malloc(uptr size, uptr real_stack) {\n-  if (!flags()->use_fake_stack) return real_stack;\n-  AsanThread *t = asanThreadRegistry().GetCurrent();\n-  if (!t) {\n-    // TSD is gone, use the real stack.\n-    return real_stack;\n-  }\n-  uptr ptr = t->fake_stack().AllocateStack(size, real_stack);\n-  // Printf(\"__asan_stack_malloc %p %zu %p\\n\", ptr, size, real_stack);\n-  return ptr;\n-}\n-\n-void __asan_stack_free(uptr ptr, uptr size, uptr real_stack) {\n-  if (!flags()->use_fake_stack) return;\n-  if (ptr != real_stack) {\n-    FakeStack::OnFree(ptr, size, real_stack);\n-  }\n-}\n-\n // ASan allocator doesn't reserve extra bytes, so normally we would\n // just return \"size\".\n uptr __asan_get_estimated_allocated_size(uptr size) {\n@@ -1040,8 +800,9 @@ uptr __asan_get_allocated_size(const void *p) {\n   uptr allocated_size = malloc_info.AllocationSize((uptr)p);\n   // Die if p is not malloced or if it is already freed.\n   if (allocated_size == 0) {\n-    GET_STACK_TRACE_HERE(kStackTraceMax);\n+    GET_STACK_TRACE_FATAL_HERE;\n     ReportAsanGetAllocatedSizeNotOwned((uptr)p, &stack);\n   }\n   return allocated_size;\n }\n+#endif  // ASAN_ALLOCATOR_VERSION"}, {"sha": "4ade352a3e57d818b18bef736803182a839dc006", "filename": "libsanitizer/asan/asan_allocator.h", "status": "modified", "additions": 96, "deletions": 9, "changes": 105, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_allocator.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_allocator.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_allocator.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -15,9 +15,22 @@\n \n #include \"asan_internal.h\"\n #include \"asan_interceptors.h\"\n+#include \"sanitizer_common/sanitizer_list.h\"\n+\n+// We are in the process of transitioning from the old allocator (version 1)\n+// to a new one (version 2). The change is quite intrusive so both allocators\n+// will co-exist in the source base for a while. The actual allocator is chosen\n+// at build time by redefining this macrozz.\n+#define ASAN_ALLOCATOR_VERSION 1\n \n namespace __asan {\n \n+enum AllocType {\n+  FROM_MALLOC = 1,  // Memory block came from malloc, calloc, realloc, etc.\n+  FROM_NEW = 2,     // Memory block came from operator new.\n+  FROM_NEW_BR = 3   // Memory block came from operator new [ ]\n+};\n+\n static const uptr kNumberOfSizeClasses = 255;\n struct AsanChunk;\n \n@@ -32,16 +45,40 @@ class AsanChunkView {\n   uptr FreeTid();\n   void GetAllocStack(StackTrace *stack);\n   void GetFreeStack(StackTrace *stack);\n-  bool AddrIsInside(uptr addr, uptr access_size, uptr *offset);\n-  bool AddrIsAtLeft(uptr addr, uptr access_size, uptr *offset);\n-  bool AddrIsAtRight(uptr addr, uptr access_size, uptr *offset);\n+  bool AddrIsInside(uptr addr, uptr access_size, uptr *offset) {\n+    if (addr >= Beg() && (addr + access_size) <= End()) {\n+      *offset = addr - Beg();\n+      return true;\n+    }\n+    return false;\n+  }\n+  bool AddrIsAtLeft(uptr addr, uptr access_size, uptr *offset) {\n+    (void)access_size;\n+    if (addr < Beg()) {\n+      *offset = Beg() - addr;\n+      return true;\n+    }\n+    return false;\n+  }\n+  bool AddrIsAtRight(uptr addr, uptr access_size, uptr *offset) {\n+    if (addr + access_size >= End()) {\n+      if (addr <= End())\n+        *offset = 0;\n+      else\n+        *offset = addr - End();\n+      return true;\n+    }\n+    return false;\n+  }\n+\n  private:\n   AsanChunk *const chunk_;\n };\n \n AsanChunkView FindHeapChunkByAddress(uptr address);\n \n-class AsanChunkFifoList {\n+// List of AsanChunks with total size.\n+class AsanChunkFifoList: public IntrusiveList<AsanChunk> {\n  public:\n   explicit AsanChunkFifoList(LinkerInitialized) { }\n   AsanChunkFifoList() { clear(); }\n@@ -50,12 +87,10 @@ class AsanChunkFifoList {\n   AsanChunk *Pop();\n   uptr size() { return size_; }\n   void clear() {\n-    first_ = last_ = 0;\n+    IntrusiveList<AsanChunk>::clear();\n     size_ = 0;\n   }\n  private:\n-  AsanChunk *first_;\n-  AsanChunk *last_;\n   uptr size_;\n };\n \n@@ -68,7 +103,11 @@ struct AsanThreadLocalMallocStorage {\n   }\n \n   AsanChunkFifoList quarantine_;\n+#if ASAN_ALLOCATOR_VERSION == 1\n   AsanChunk *free_lists_[kNumberOfSizeClasses];\n+#else\n+  uptr allocator2_cache[1024];  // Opaque.\n+#endif\n   void CommitBack();\n };\n \n@@ -156,8 +195,9 @@ class FakeStack {\n   FakeFrameLifo call_stack_;\n };\n \n-void *asan_memalign(uptr alignment, uptr size, StackTrace *stack);\n-void asan_free(void *ptr, StackTrace *stack);\n+void *asan_memalign(uptr alignment, uptr size, StackTrace *stack,\n+                    AllocType alloc_type);\n+void asan_free(void *ptr, StackTrace *stack, AllocType alloc_type);\n \n void *asan_malloc(uptr size, StackTrace *stack);\n void *asan_calloc(uptr nmemb, uptr size, StackTrace *stack);\n@@ -173,5 +213,52 @@ uptr asan_mz_size(const void *ptr);\n void asan_mz_force_lock();\n void asan_mz_force_unlock();\n \n+void PrintInternalAllocatorStats();\n+\n+// Log2 and RoundUpToPowerOfTwo should be inlined for performance.\n+#if defined(_WIN32) && !defined(__clang__)\n+extern \"C\" {\n+unsigned char _BitScanForward(unsigned long *index, unsigned long mask);  // NOLINT\n+unsigned char _BitScanReverse(unsigned long *index, unsigned long mask);  // NOLINT\n+#if defined(_WIN64)\n+unsigned char _BitScanForward64(unsigned long *index, unsigned __int64 mask);  // NOLINT\n+unsigned char _BitScanReverse64(unsigned long *index, unsigned __int64 mask);  // NOLINT\n+#endif\n+}\n+#endif\n+\n+static inline uptr Log2(uptr x) {\n+  CHECK(IsPowerOfTwo(x));\n+#if !defined(_WIN32) || defined(__clang__)\n+  return __builtin_ctzl(x);\n+#elif defined(_WIN64)\n+  unsigned long ret;  // NOLINT\n+  _BitScanForward64(&ret, x);\n+  return ret;\n+#else\n+  unsigned long ret;  // NOLINT\n+  _BitScanForward(&ret, x);\n+  return ret;\n+#endif\n+}\n+\n+static inline uptr RoundUpToPowerOfTwo(uptr size) {\n+  CHECK(size);\n+  if (IsPowerOfTwo(size)) return size;\n+\n+  unsigned long up;  // NOLINT\n+#if !defined(_WIN32) || defined(__clang__)\n+  up = SANITIZER_WORDSIZE - 1 - __builtin_clzl(size);\n+#elif defined(_WIN64)\n+  _BitScanReverse64(&up, size);\n+#else\n+  _BitScanReverse(&up, size);\n+#endif\n+  CHECK(size < (1ULL << (up + 1)));\n+  CHECK(size > (1ULL << up));\n+  return 1UL << (up + 1);\n+}\n+\n+\n }  // namespace __asan\n #endif  // ASAN_ALLOCATOR_H"}, {"sha": "d12ccb7f23b6b98f6ff781ee847868962e553de6", "filename": "libsanitizer/asan/asan_allocator2.cc", "status": "added", "additions": 714, "deletions": 0, "changes": 714, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_allocator2.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_allocator2.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_allocator2.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,714 @@\n+//===-- asan_allocator2.cc ------------------------------------------------===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of AddressSanitizer, an address sanity checker.\n+//\n+// Implementation of ASan's memory allocator, 2-nd version.\n+// This variant uses the allocator from sanitizer_common, i.e. the one shared\n+// with ThreadSanitizer and MemorySanitizer.\n+//\n+// Status: under development, not enabled by default yet.\n+//===----------------------------------------------------------------------===//\n+#include \"asan_allocator.h\"\n+#if ASAN_ALLOCATOR_VERSION == 2\n+\n+#include \"asan_mapping.h\"\n+#include \"asan_report.h\"\n+#include \"asan_thread.h\"\n+#include \"asan_thread_registry.h\"\n+#include \"sanitizer/asan_interface.h\"\n+#include \"sanitizer_common/sanitizer_allocator.h\"\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+#include \"sanitizer_common/sanitizer_list.h\"\n+#include \"sanitizer_common/sanitizer_stackdepot.h\"\n+\n+namespace __asan {\n+\n+struct AsanMapUnmapCallback {\n+  void OnMap(uptr p, uptr size) const {\n+    PoisonShadow(p, size, kAsanHeapLeftRedzoneMagic);\n+    // Statistics.\n+    AsanStats &thread_stats = asanThreadRegistry().GetCurrentThreadStats();\n+    thread_stats.mmaps++;\n+    thread_stats.mmaped += size;\n+  }\n+  void OnUnmap(uptr p, uptr size) const {\n+    PoisonShadow(p, size, 0);\n+    // We are about to unmap a chunk of user memory.\n+    // Mark the corresponding shadow memory as not needed.\n+    // Since asan's mapping is compacting, the shadow chunk may be\n+    // not page-aligned, so we only flush the page-aligned portion.\n+    uptr page_size = GetPageSizeCached();\n+    uptr shadow_beg = RoundUpTo(MemToShadow(p), page_size);\n+    uptr shadow_end = RoundDownTo(MemToShadow(p + size), page_size);\n+    FlushUnneededShadowMemory(shadow_beg, shadow_end - shadow_beg);\n+    // Statistics.\n+    AsanStats &thread_stats = asanThreadRegistry().GetCurrentThreadStats();\n+    thread_stats.munmaps++;\n+    thread_stats.munmaped += size;\n+  }\n+};\n+\n+#if SANITIZER_WORDSIZE == 64\n+const uptr kAllocatorSpace = 0x600000000000ULL;\n+const uptr kAllocatorSize  =  0x10000000000ULL;  // 1T.\n+typedef DefaultSizeClassMap SizeClassMap;\n+typedef SizeClassAllocator64<kAllocatorSpace, kAllocatorSize, 0 /*metadata*/,\n+    SizeClassMap, AsanMapUnmapCallback> PrimaryAllocator;\n+#elif SANITIZER_WORDSIZE == 32\n+static const u64 kAddressSpaceSize = 1ULL << 32;\n+typedef CompactSizeClassMap SizeClassMap;\n+typedef SizeClassAllocator32<0, kAddressSpaceSize, 16,\n+  SizeClassMap, AsanMapUnmapCallback> PrimaryAllocator;\n+#endif\n+\n+typedef SizeClassAllocatorLocalCache<PrimaryAllocator> AllocatorCache;\n+typedef LargeMmapAllocator<AsanMapUnmapCallback> SecondaryAllocator;\n+typedef CombinedAllocator<PrimaryAllocator, AllocatorCache,\n+    SecondaryAllocator> Allocator;\n+\n+// We can not use THREADLOCAL because it is not supported on some of the\n+// platforms we care about (OSX 10.6, Android).\n+// static THREADLOCAL AllocatorCache cache;\n+AllocatorCache *GetAllocatorCache(AsanThreadLocalMallocStorage *ms) {\n+  CHECK(ms);\n+  CHECK_LE(sizeof(AllocatorCache), sizeof(ms->allocator2_cache));\n+  return reinterpret_cast<AllocatorCache *>(ms->allocator2_cache);\n+}\n+\n+static Allocator allocator;\n+\n+static const uptr kMaxAllowedMallocSize =\n+  FIRST_32_SECOND_64(3UL << 30, 8UL << 30);\n+\n+static const uptr kMaxThreadLocalQuarantine =\n+  FIRST_32_SECOND_64(1 << 18, 1 << 20);\n+\n+static const uptr kReturnOnZeroMalloc = 2048;  // Zero page is protected.\n+\n+static int inited = 0;\n+\n+static void Init() {\n+  if (inited) return;\n+  __asan_init();\n+  inited = true;  // this must happen before any threads are created.\n+  allocator.Init();\n+}\n+\n+// Every chunk of memory allocated by this allocator can be in one of 3 states:\n+// CHUNK_AVAILABLE: the chunk is in the free list and ready to be allocated.\n+// CHUNK_ALLOCATED: the chunk is allocated and not yet freed.\n+// CHUNK_QUARANTINE: the chunk was freed and put into quarantine zone.\n+enum {\n+  CHUNK_AVAILABLE  = 0,  // 0 is the default value even if we didn't set it.\n+  CHUNK_ALLOCATED  = 2,\n+  CHUNK_QUARANTINE = 3\n+};\n+\n+// Valid redzone sizes are 16, 32, 64, ... 2048, so we encode them in 3 bits.\n+// We use adaptive redzones: for larger allocation larger redzones are used.\n+static u32 RZLog2Size(u32 rz_log) {\n+  CHECK_LT(rz_log, 8);\n+  return 16 << rz_log;\n+}\n+\n+static u32 RZSize2Log(u32 rz_size) {\n+  CHECK_GE(rz_size, 16);\n+  CHECK_LE(rz_size, 2048);\n+  CHECK(IsPowerOfTwo(rz_size));\n+  u32 res = __builtin_ctz(rz_size) - 4;\n+  CHECK_EQ(rz_size, RZLog2Size(res));\n+  return res;\n+}\n+\n+static uptr ComputeRZLog(uptr user_requested_size) {\n+  u32 rz_log =\n+    user_requested_size <= 64        - 16   ? 0 :\n+    user_requested_size <= 128       - 32   ? 1 :\n+    user_requested_size <= 512       - 64   ? 2 :\n+    user_requested_size <= 4096      - 128  ? 3 :\n+    user_requested_size <= (1 << 14) - 256  ? 4 :\n+    user_requested_size <= (1 << 15) - 512  ? 5 :\n+    user_requested_size <= (1 << 16) - 1024 ? 6 : 7;\n+  return Max(rz_log, RZSize2Log(flags()->redzone));\n+}\n+\n+// The memory chunk allocated from the underlying allocator looks like this:\n+// L L L L L L H H U U U U U U R R\n+//   L -- left redzone words (0 or more bytes)\n+//   H -- ChunkHeader (16 bytes), which is also a part of the left redzone.\n+//   U -- user memory.\n+//   R -- right redzone (0 or more bytes)\n+// ChunkBase consists of ChunkHeader and other bytes that overlap with user\n+// memory.\n+\n+// If a memory chunk is allocated by memalign and we had to increase the\n+// allocation size to achieve the proper alignment, then we store this magic\n+// value in the first uptr word of the memory block and store the address of\n+// ChunkBase in the next uptr.\n+// M B ? ? ? L L L L L L  H H U U U U U U\n+//   M -- magic value kMemalignMagic\n+//   B -- address of ChunkHeader pointing to the first 'H'\n+static const uptr kMemalignMagic = 0xCC6E96B9;\n+\n+struct ChunkHeader {\n+  // 1-st 8 bytes.\n+  u32 chunk_state       : 8;  // Must be first.\n+  u32 alloc_tid         : 24;\n+\n+  u32 free_tid          : 24;\n+  u32 from_memalign     : 1;\n+  u32 alloc_type        : 2;\n+  u32 rz_log            : 3;\n+  // 2-nd 8 bytes\n+  // This field is used for small sizes. For large sizes it is equal to\n+  // SizeClassMap::kMaxSize and the actual size is stored in the\n+  // SecondaryAllocator's metadata.\n+  u32 user_requested_size;\n+  u32 alloc_context_id;\n+};\n+\n+struct ChunkBase : ChunkHeader {\n+  // Header2, intersects with user memory.\n+  AsanChunk *next;\n+  u32 free_context_id;\n+};\n+\n+static const uptr kChunkHeaderSize = sizeof(ChunkHeader);\n+static const uptr kChunkHeader2Size = sizeof(ChunkBase) - kChunkHeaderSize;\n+COMPILER_CHECK(kChunkHeaderSize == 16);\n+COMPILER_CHECK(kChunkHeader2Size <= 16);\n+\n+struct AsanChunk: ChunkBase {\n+  uptr Beg() { return reinterpret_cast<uptr>(this) + kChunkHeaderSize; }\n+  uptr UsedSize() {\n+    if (user_requested_size != SizeClassMap::kMaxSize)\n+      return user_requested_size;\n+    return *reinterpret_cast<uptr *>(allocator.GetMetaData(AllocBeg()));\n+  }\n+  void *AllocBeg() {\n+    if (from_memalign)\n+      return allocator.GetBlockBegin(reinterpret_cast<void *>(this));\n+    return reinterpret_cast<void*>(Beg() - RZLog2Size(rz_log));\n+  }\n+  // We store the alloc/free stack traces in the chunk itself.\n+  u32 *AllocStackBeg() {\n+    return (u32*)(Beg() - RZLog2Size(rz_log));\n+  }\n+  uptr AllocStackSize() {\n+    CHECK_LE(RZLog2Size(rz_log), kChunkHeaderSize);\n+    return (RZLog2Size(rz_log) - kChunkHeaderSize) / sizeof(u32);\n+  }\n+  u32 *FreeStackBeg() {\n+    return (u32*)(Beg() + kChunkHeader2Size);\n+  }\n+  uptr FreeStackSize() {\n+    if (user_requested_size < kChunkHeader2Size) return 0;\n+    uptr available = RoundUpTo(user_requested_size, SHADOW_GRANULARITY);\n+    return (available - kChunkHeader2Size) / sizeof(u32);\n+  }\n+};\n+\n+uptr AsanChunkView::Beg() { return chunk_->Beg(); }\n+uptr AsanChunkView::End() { return Beg() + UsedSize(); }\n+uptr AsanChunkView::UsedSize() { return chunk_->UsedSize(); }\n+uptr AsanChunkView::AllocTid() { return chunk_->alloc_tid; }\n+uptr AsanChunkView::FreeTid() { return chunk_->free_tid; }\n+\n+static void GetStackTraceFromId(u32 id, StackTrace *stack) {\n+  CHECK(id);\n+  uptr size = 0;\n+  const uptr *trace = StackDepotGet(id, &size);\n+  CHECK_LT(size, kStackTraceMax);\n+  internal_memcpy(stack->trace, trace, sizeof(uptr) * size);\n+  stack->size = size;\n+}\n+\n+void AsanChunkView::GetAllocStack(StackTrace *stack) {\n+  if (flags()->use_stack_depot)\n+    GetStackTraceFromId(chunk_->alloc_context_id, stack);\n+  else\n+    StackTrace::UncompressStack(stack, chunk_->AllocStackBeg(),\n+                                chunk_->AllocStackSize());\n+}\n+\n+void AsanChunkView::GetFreeStack(StackTrace *stack) {\n+  if (flags()->use_stack_depot)\n+    GetStackTraceFromId(chunk_->free_context_id, stack);\n+  else\n+    StackTrace::UncompressStack(stack, chunk_->FreeStackBeg(),\n+                                chunk_->FreeStackSize());\n+}\n+\n+class Quarantine: public AsanChunkFifoList {\n+ public:\n+  void SwallowThreadLocalQuarantine(AsanThreadLocalMallocStorage *ms) {\n+    AsanChunkFifoList *q = &ms->quarantine_;\n+    if (!q->size()) return;\n+    SpinMutexLock l(&mutex_);\n+    PushList(q);\n+    PopAndDeallocateLoop(ms);\n+  }\n+\n+  void BypassThreadLocalQuarantine(AsanChunk *m) {\n+    SpinMutexLock l(&mutex_);\n+    Push(m);\n+  }\n+\n+ private:\n+  void PopAndDeallocateLoop(AsanThreadLocalMallocStorage *ms) {\n+    while (size() > (uptr)flags()->quarantine_size) {\n+      PopAndDeallocate(ms);\n+    }\n+  }\n+  void PopAndDeallocate(AsanThreadLocalMallocStorage *ms) {\n+    CHECK_GT(size(), 0);\n+    AsanChunk *m = Pop();\n+    CHECK(m);\n+    CHECK(m->chunk_state == CHUNK_QUARANTINE);\n+    m->chunk_state = CHUNK_AVAILABLE;\n+    CHECK_NE(m->alloc_tid, kInvalidTid);\n+    CHECK_NE(m->free_tid, kInvalidTid);\n+    PoisonShadow(m->Beg(),\n+                 RoundUpTo(m->UsedSize(), SHADOW_GRANULARITY),\n+                 kAsanHeapLeftRedzoneMagic);\n+    void *p = reinterpret_cast<void *>(m->AllocBeg());\n+    if (m->from_memalign) {\n+      uptr *memalign_magic = reinterpret_cast<uptr *>(p);\n+      CHECK_EQ(memalign_magic[0], kMemalignMagic);\n+      CHECK_EQ(memalign_magic[1], reinterpret_cast<uptr>(m));\n+    }\n+\n+    // Statistics.\n+    AsanStats &thread_stats = asanThreadRegistry().GetCurrentThreadStats();\n+    thread_stats.real_frees++;\n+    thread_stats.really_freed += m->UsedSize();\n+\n+    allocator.Deallocate(GetAllocatorCache(ms), p);\n+  }\n+  SpinMutex mutex_;\n+};\n+\n+static Quarantine quarantine;\n+\n+void AsanChunkFifoList::PushList(AsanChunkFifoList *q) {\n+  CHECK(q->size() > 0);\n+  size_ += q->size();\n+  append_back(q);\n+  q->clear();\n+}\n+\n+void AsanChunkFifoList::Push(AsanChunk *n) {\n+  push_back(n);\n+  size_ += n->UsedSize();\n+}\n+\n+// Interesting performance observation: this function takes up to 15% of overal\n+// allocator time. That's because *first_ has been evicted from cache long time\n+// ago. Not sure if we can or want to do anything with this.\n+AsanChunk *AsanChunkFifoList::Pop() {\n+  CHECK(first_);\n+  AsanChunk *res = front();\n+  size_ -= res->UsedSize();\n+  pop_front();\n+  return res;\n+}\n+\n+static void *Allocate(uptr size, uptr alignment, StackTrace *stack,\n+                      AllocType alloc_type) {\n+  Init();\n+  CHECK(stack);\n+  const uptr min_alignment = SHADOW_GRANULARITY;\n+  if (alignment < min_alignment)\n+    alignment = min_alignment;\n+  if (size == 0) {\n+    if (alignment <= kReturnOnZeroMalloc)\n+      return reinterpret_cast<void *>(kReturnOnZeroMalloc);\n+    else\n+      return 0;  // 0 bytes with large alignment requested. Just return 0.\n+  }\n+  CHECK(IsPowerOfTwo(alignment));\n+  uptr rz_log = ComputeRZLog(size);\n+  uptr rz_size = RZLog2Size(rz_log);\n+  uptr rounded_size = RoundUpTo(size, alignment);\n+  if (rounded_size < kChunkHeader2Size)\n+    rounded_size = kChunkHeader2Size;\n+  uptr needed_size = rounded_size + rz_size;\n+  if (alignment > min_alignment)\n+    needed_size += alignment;\n+  bool using_primary_allocator = true;\n+  // If we are allocating from the secondary allocator, there will be no\n+  // automatic right redzone, so add the right redzone manually.\n+  if (!PrimaryAllocator::CanAllocate(needed_size, alignment)) {\n+    needed_size += rz_size;\n+    using_primary_allocator = false;\n+  }\n+  CHECK(IsAligned(needed_size, min_alignment));\n+  if (size > kMaxAllowedMallocSize || needed_size > kMaxAllowedMallocSize) {\n+    Report(\"WARNING: AddressSanitizer failed to allocate %p bytes\\n\",\n+           (void*)size);\n+    return 0;\n+  }\n+\n+  AsanThread *t = asanThreadRegistry().GetCurrent();\n+  AllocatorCache *cache = t ? GetAllocatorCache(&t->malloc_storage()) : 0;\n+  void *allocated = allocator.Allocate(cache, needed_size, 8, false);\n+  uptr alloc_beg = reinterpret_cast<uptr>(allocated);\n+  uptr alloc_end = alloc_beg + needed_size;\n+  uptr beg_plus_redzone = alloc_beg + rz_size;\n+  uptr user_beg = beg_plus_redzone;\n+  if (!IsAligned(user_beg, alignment))\n+    user_beg = RoundUpTo(user_beg, alignment);\n+  uptr user_end = user_beg + size;\n+  CHECK_LE(user_end, alloc_end);\n+  uptr chunk_beg = user_beg - kChunkHeaderSize;\n+  AsanChunk *m = reinterpret_cast<AsanChunk *>(chunk_beg);\n+  m->chunk_state = CHUNK_ALLOCATED;\n+  m->alloc_type = alloc_type;\n+  m->rz_log = rz_log;\n+  u32 alloc_tid = t ? t->tid() : 0;\n+  m->alloc_tid = alloc_tid;\n+  CHECK_EQ(alloc_tid, m->alloc_tid);  // Does alloc_tid fit into the bitfield?\n+  m->free_tid = kInvalidTid;\n+  m->from_memalign = user_beg != beg_plus_redzone;\n+  if (m->from_memalign) {\n+    CHECK_LE(beg_plus_redzone + 2 * sizeof(uptr), user_beg);\n+    uptr *memalign_magic = reinterpret_cast<uptr *>(alloc_beg);\n+    memalign_magic[0] = kMemalignMagic;\n+    memalign_magic[1] = chunk_beg;\n+  }\n+  if (using_primary_allocator) {\n+    CHECK(size);\n+    m->user_requested_size = size;\n+    CHECK(allocator.FromPrimary(allocated));\n+  } else {\n+    CHECK(!allocator.FromPrimary(allocated));\n+    m->user_requested_size = SizeClassMap::kMaxSize;\n+    uptr *meta = reinterpret_cast<uptr *>(allocator.GetMetaData(allocated));\n+    meta[0] = size;\n+    meta[1] = chunk_beg;\n+  }\n+\n+  if (flags()->use_stack_depot) {\n+    m->alloc_context_id = StackDepotPut(stack->trace, stack->size);\n+  } else {\n+    m->alloc_context_id = 0;\n+    StackTrace::CompressStack(stack, m->AllocStackBeg(), m->AllocStackSize());\n+  }\n+\n+  uptr size_rounded_down_to_granularity = RoundDownTo(size, SHADOW_GRANULARITY);\n+  // Unpoison the bulk of the memory region.\n+  if (size_rounded_down_to_granularity)\n+    PoisonShadow(user_beg, size_rounded_down_to_granularity, 0);\n+  // Deal with the end of the region if size is not aligned to granularity.\n+  if (size != size_rounded_down_to_granularity && flags()->poison_heap) {\n+    u8 *shadow = (u8*)MemToShadow(user_beg + size_rounded_down_to_granularity);\n+    *shadow = size & (SHADOW_GRANULARITY - 1);\n+  }\n+\n+  AsanStats &thread_stats = asanThreadRegistry().GetCurrentThreadStats();\n+  thread_stats.mallocs++;\n+  thread_stats.malloced += size;\n+  thread_stats.malloced_redzones += needed_size - size;\n+  uptr class_id = Min(kNumberOfSizeClasses, SizeClassMap::ClassID(needed_size));\n+  thread_stats.malloced_by_size[class_id]++;\n+  if (needed_size > SizeClassMap::kMaxSize)\n+    thread_stats.malloc_large++;\n+\n+  void *res = reinterpret_cast<void *>(user_beg);\n+  ASAN_MALLOC_HOOK(res, size);\n+  return res;\n+}\n+\n+static void Deallocate(void *ptr, StackTrace *stack, AllocType alloc_type) {\n+  uptr p = reinterpret_cast<uptr>(ptr);\n+  if (p == 0 || p == kReturnOnZeroMalloc) return;\n+  uptr chunk_beg = p - kChunkHeaderSize;\n+  AsanChunk *m = reinterpret_cast<AsanChunk *>(chunk_beg);\n+\n+  // Flip the chunk_state atomically to avoid race on double-free.\n+  u8 old_chunk_state = atomic_exchange((atomic_uint8_t*)m, CHUNK_QUARANTINE,\n+                                       memory_order_acq_rel);\n+\n+  if (old_chunk_state == CHUNK_QUARANTINE)\n+    ReportDoubleFree((uptr)ptr, stack);\n+  else if (old_chunk_state != CHUNK_ALLOCATED)\n+    ReportFreeNotMalloced((uptr)ptr, stack);\n+  CHECK(old_chunk_state == CHUNK_ALLOCATED);\n+  if (m->alloc_type != alloc_type && flags()->alloc_dealloc_mismatch)\n+    ReportAllocTypeMismatch((uptr)ptr, stack,\n+                            (AllocType)m->alloc_type, (AllocType)alloc_type);\n+\n+  CHECK_GE(m->alloc_tid, 0);\n+  if (SANITIZER_WORDSIZE == 64)  // On 32-bits this resides in user area.\n+    CHECK_EQ(m->free_tid, kInvalidTid);\n+  AsanThread *t = asanThreadRegistry().GetCurrent();\n+  m->free_tid = t ? t->tid() : 0;\n+  if (flags()->use_stack_depot) {\n+    m->free_context_id = StackDepotPut(stack->trace, stack->size);\n+  } else {\n+    m->free_context_id = 0;\n+    StackTrace::CompressStack(stack, m->FreeStackBeg(), m->FreeStackSize());\n+  }\n+  CHECK(m->chunk_state == CHUNK_QUARANTINE);\n+  // Poison the region.\n+  PoisonShadow(m->Beg(),\n+               RoundUpTo(m->UsedSize(), SHADOW_GRANULARITY),\n+               kAsanHeapFreeMagic);\n+\n+  AsanStats &thread_stats = asanThreadRegistry().GetCurrentThreadStats();\n+  thread_stats.frees++;\n+  thread_stats.freed += m->UsedSize();\n+\n+  // Push into quarantine.\n+  if (t) {\n+    AsanChunkFifoList &q = t->malloc_storage().quarantine_;\n+    q.Push(m);\n+\n+    if (q.size() > kMaxThreadLocalQuarantine)\n+      quarantine.SwallowThreadLocalQuarantine(&t->malloc_storage());\n+  } else {\n+    quarantine.BypassThreadLocalQuarantine(m);\n+  }\n+\n+  ASAN_FREE_HOOK(ptr);\n+}\n+\n+static void *Reallocate(void *old_ptr, uptr new_size, StackTrace *stack) {\n+  CHECK(old_ptr && new_size);\n+  uptr p = reinterpret_cast<uptr>(old_ptr);\n+  uptr chunk_beg = p - kChunkHeaderSize;\n+  AsanChunk *m = reinterpret_cast<AsanChunk *>(chunk_beg);\n+\n+  AsanStats &thread_stats = asanThreadRegistry().GetCurrentThreadStats();\n+  thread_stats.reallocs++;\n+  thread_stats.realloced += new_size;\n+\n+  CHECK(m->chunk_state == CHUNK_ALLOCATED);\n+  uptr old_size = m->UsedSize();\n+  uptr memcpy_size = Min(new_size, old_size);\n+  void *new_ptr = Allocate(new_size, 8, stack, FROM_MALLOC);\n+  if (new_ptr) {\n+    CHECK(REAL(memcpy) != 0);\n+    REAL(memcpy)(new_ptr, old_ptr, memcpy_size);\n+    Deallocate(old_ptr, stack, FROM_MALLOC);\n+  }\n+  return new_ptr;\n+}\n+\n+static AsanChunk *GetAsanChunkByAddr(uptr p) {\n+  void *ptr = reinterpret_cast<void *>(p);\n+  uptr alloc_beg = reinterpret_cast<uptr>(allocator.GetBlockBegin(ptr));\n+  if (!alloc_beg) return 0;\n+  uptr *memalign_magic = reinterpret_cast<uptr *>(alloc_beg);\n+  if (memalign_magic[0] == kMemalignMagic) {\n+    AsanChunk *m = reinterpret_cast<AsanChunk *>(memalign_magic[1]);\n+    CHECK(m->from_memalign);\n+    return m;\n+  }\n+  if (!allocator.FromPrimary(ptr)) {\n+    uptr *meta = reinterpret_cast<uptr *>(\n+        allocator.GetMetaData(reinterpret_cast<void *>(alloc_beg)));\n+    AsanChunk *m = reinterpret_cast<AsanChunk *>(meta[1]);\n+    return m;\n+  }\n+  uptr actual_size = allocator.GetActuallyAllocatedSize(ptr);\n+  CHECK_LE(actual_size, SizeClassMap::kMaxSize);\n+  // We know the actually allocted size, but we don't know the redzone size.\n+  // Just try all possible redzone sizes.\n+  for (u32 rz_log = 0; rz_log < 8; rz_log++) {\n+    u32 rz_size = RZLog2Size(rz_log);\n+    uptr max_possible_size = actual_size - rz_size;\n+    if (ComputeRZLog(max_possible_size) != rz_log)\n+      continue;\n+    return reinterpret_cast<AsanChunk *>(\n+        alloc_beg + rz_size - kChunkHeaderSize);\n+  }\n+  return 0;\n+}\n+\n+static uptr AllocationSize(uptr p) {\n+  AsanChunk *m = GetAsanChunkByAddr(p);\n+  if (!m) return 0;\n+  if (m->chunk_state != CHUNK_ALLOCATED) return 0;\n+  if (m->Beg() != p) return 0;\n+  return m->UsedSize();\n+}\n+\n+// We have an address between two chunks, and we want to report just one.\n+AsanChunk *ChooseChunk(uptr addr,\n+                       AsanChunk *left_chunk, AsanChunk *right_chunk) {\n+  // Prefer an allocated chunk over freed chunk and freed chunk\n+  // over available chunk.\n+  if (left_chunk->chunk_state != right_chunk->chunk_state) {\n+    if (left_chunk->chunk_state == CHUNK_ALLOCATED)\n+      return left_chunk;\n+    if (right_chunk->chunk_state == CHUNK_ALLOCATED)\n+      return right_chunk;\n+    if (left_chunk->chunk_state == CHUNK_QUARANTINE)\n+      return left_chunk;\n+    if (right_chunk->chunk_state == CHUNK_QUARANTINE)\n+      return right_chunk;\n+  }\n+  // Same chunk_state: choose based on offset.\n+  uptr l_offset = 0, r_offset = 0;\n+  CHECK(AsanChunkView(left_chunk).AddrIsAtRight(addr, 1, &l_offset));\n+  CHECK(AsanChunkView(right_chunk).AddrIsAtLeft(addr, 1, &r_offset));\n+  if (l_offset < r_offset)\n+    return left_chunk;\n+  return right_chunk;\n+}\n+\n+AsanChunkView FindHeapChunkByAddress(uptr addr) {\n+  AsanChunk *m1 = GetAsanChunkByAddr(addr);\n+  if (!m1) return AsanChunkView(m1);\n+  uptr offset = 0;\n+  if (AsanChunkView(m1).AddrIsAtLeft(addr, 1, &offset)) {\n+    // The address is in the chunk's left redzone, so maybe it is actually\n+    // a right buffer overflow from the other chunk to the left.\n+    // Search a bit to the left to see if there is another chunk.\n+    AsanChunk *m2 = 0;\n+    for (uptr l = 1; l < GetPageSizeCached(); l++) {\n+      m2 = GetAsanChunkByAddr(addr - l);\n+      if (m2 == m1) continue;  // Still the same chunk.\n+      break;\n+    }\n+    if (m2 && AsanChunkView(m2).AddrIsAtRight(addr, 1, &offset))\n+      m1 = ChooseChunk(addr, m2, m1);\n+  }\n+  return AsanChunkView(m1);\n+}\n+\n+void AsanThreadLocalMallocStorage::CommitBack() {\n+  quarantine.SwallowThreadLocalQuarantine(this);\n+  allocator.SwallowCache(GetAllocatorCache(this));\n+}\n+\n+void PrintInternalAllocatorStats() {\n+  allocator.PrintStats();\n+}\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void *asan_memalign(uptr alignment, uptr size, StackTrace *stack,\n+                    AllocType alloc_type) {\n+  return Allocate(size, alignment, stack, alloc_type);\n+}\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void asan_free(void *ptr, StackTrace *stack, AllocType alloc_type) {\n+  Deallocate(ptr, stack, alloc_type);\n+}\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void *asan_malloc(uptr size, StackTrace *stack) {\n+  return Allocate(size, 8, stack, FROM_MALLOC);\n+}\n+\n+void *asan_calloc(uptr nmemb, uptr size, StackTrace *stack) {\n+  void *ptr = Allocate(nmemb * size, 8, stack, FROM_MALLOC);\n+  if (ptr)\n+    REAL(memset)(ptr, 0, nmemb * size);\n+  return ptr;\n+}\n+\n+void *asan_realloc(void *p, uptr size, StackTrace *stack) {\n+  if (p == 0)\n+    return Allocate(size, 8, stack, FROM_MALLOC);\n+  if (size == 0) {\n+    Deallocate(p, stack, FROM_MALLOC);\n+    return 0;\n+  }\n+  return Reallocate(p, size, stack);\n+}\n+\n+void *asan_valloc(uptr size, StackTrace *stack) {\n+  return Allocate(size, GetPageSizeCached(), stack, FROM_MALLOC);\n+}\n+\n+void *asan_pvalloc(uptr size, StackTrace *stack) {\n+  uptr PageSize = GetPageSizeCached();\n+  size = RoundUpTo(size, PageSize);\n+  if (size == 0) {\n+    // pvalloc(0) should allocate one page.\n+    size = PageSize;\n+  }\n+  return Allocate(size, PageSize, stack, FROM_MALLOC);\n+}\n+\n+int asan_posix_memalign(void **memptr, uptr alignment, uptr size,\n+                        StackTrace *stack) {\n+  void *ptr = Allocate(size, alignment, stack, FROM_MALLOC);\n+  CHECK(IsAligned((uptr)ptr, alignment));\n+  *memptr = ptr;\n+  return 0;\n+}\n+\n+uptr asan_malloc_usable_size(void *ptr, StackTrace *stack) {\n+  CHECK(stack);\n+  if (ptr == 0) return 0;\n+  uptr usable_size = AllocationSize(reinterpret_cast<uptr>(ptr));\n+  if (flags()->check_malloc_usable_size && (usable_size == 0))\n+    ReportMallocUsableSizeNotOwned((uptr)ptr, stack);\n+  return usable_size;\n+}\n+\n+uptr asan_mz_size(const void *ptr) {\n+  UNIMPLEMENTED();\n+  return 0;\n+}\n+\n+void asan_mz_force_lock() {\n+  UNIMPLEMENTED();\n+}\n+\n+void asan_mz_force_unlock() {\n+  UNIMPLEMENTED();\n+}\n+\n+}  // namespace __asan\n+\n+// ---------------------- Interface ---------------- {{{1\n+using namespace __asan;  // NOLINT\n+\n+// ASan allocator doesn't reserve extra bytes, so normally we would\n+// just return \"size\". We don't want to expose our redzone sizes, etc here.\n+uptr __asan_get_estimated_allocated_size(uptr size) {\n+  return size;\n+}\n+\n+bool __asan_get_ownership(const void *p) {\n+  return AllocationSize(reinterpret_cast<uptr>(p)) > 0;\n+}\n+\n+uptr __asan_get_allocated_size(const void *p) {\n+  if (p == 0) return 0;\n+  uptr allocated_size = AllocationSize(reinterpret_cast<uptr>(p));\n+  // Die if p is not malloced or if it is already freed.\n+  if (allocated_size == 0) {\n+    GET_STACK_TRACE_FATAL_HERE;\n+    ReportAsanGetAllocatedSizeNotOwned(reinterpret_cast<uptr>(p), &stack);\n+  }\n+  return allocated_size;\n+}\n+\n+#if !SANITIZER_SUPPORTS_WEAK_HOOKS\n+// Provide default (no-op) implementation of malloc hooks.\n+extern \"C\" {\n+SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE\n+void __asan_malloc_hook(void *ptr, uptr size) {\n+  (void)ptr;\n+  (void)size;\n+}\n+SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE\n+void __asan_free_hook(void *ptr) {\n+  (void)ptr;\n+}\n+}  // extern \"C\"\n+#endif\n+\n+\n+#endif  // ASAN_ALLOCATOR_VERSION"}, {"sha": "e8d1e78488b82a688c95cfdcb5aa70b4b8a49899", "filename": "libsanitizer/asan/asan_fake_stack.cc", "status": "added", "additions": 180, "deletions": 0, "changes": 180, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_fake_stack.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_fake_stack.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_fake_stack.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,180 @@\n+//===-- asan_fake_stack.cc ------------------------------------------------===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of AddressSanitizer, an address sanity checker.\n+//\n+// FakeStack is used to detect use-after-return bugs.\n+//===----------------------------------------------------------------------===//\n+#include \"asan_allocator.h\"\n+#include \"asan_thread.h\"\n+#include \"asan_thread_registry.h\"\n+#include \"sanitizer/asan_interface.h\"\n+\n+namespace __asan {\n+\n+FakeStack::FakeStack() {\n+  CHECK(REAL(memset) != 0);\n+  REAL(memset)(this, 0, sizeof(*this));\n+}\n+\n+bool FakeStack::AddrIsInSizeClass(uptr addr, uptr size_class) {\n+  uptr mem = allocated_size_classes_[size_class];\n+  uptr size = ClassMmapSize(size_class);\n+  bool res = mem && addr >= mem && addr < mem + size;\n+  return res;\n+}\n+\n+uptr FakeStack::AddrIsInFakeStack(uptr addr) {\n+  for (uptr i = 0; i < kNumberOfSizeClasses; i++) {\n+    if (AddrIsInSizeClass(addr, i)) return allocated_size_classes_[i];\n+  }\n+  return 0;\n+}\n+\n+// We may want to compute this during compilation.\n+inline uptr FakeStack::ComputeSizeClass(uptr alloc_size) {\n+  uptr rounded_size = RoundUpToPowerOfTwo(alloc_size);\n+  uptr log = Log2(rounded_size);\n+  CHECK(alloc_size <= (1UL << log));\n+  if (!(alloc_size > (1UL << (log-1)))) {\n+    Printf(\"alloc_size %zu log %zu\\n\", alloc_size, log);\n+  }\n+  CHECK(alloc_size > (1UL << (log-1)));\n+  uptr res = log < kMinStackFrameSizeLog ? 0 : log - kMinStackFrameSizeLog;\n+  CHECK(res < kNumberOfSizeClasses);\n+  CHECK(ClassSize(res) >= rounded_size);\n+  return res;\n+}\n+\n+void FakeFrameFifo::FifoPush(FakeFrame *node) {\n+  CHECK(node);\n+  node->next = 0;\n+  if (first_ == 0 && last_ == 0) {\n+    first_ = last_ = node;\n+  } else {\n+    CHECK(first_);\n+    CHECK(last_);\n+    last_->next = node;\n+    last_ = node;\n+  }\n+}\n+\n+FakeFrame *FakeFrameFifo::FifoPop() {\n+  CHECK(first_ && last_ && \"Exhausted fake stack\");\n+  FakeFrame *res = 0;\n+  if (first_ == last_) {\n+    res = first_;\n+    first_ = last_ = 0;\n+  } else {\n+    res = first_;\n+    first_ = first_->next;\n+  }\n+  return res;\n+}\n+\n+void FakeStack::Init(uptr stack_size) {\n+  stack_size_ = stack_size;\n+  alive_ = true;\n+}\n+\n+void FakeStack::Cleanup() {\n+  alive_ = false;\n+  for (uptr i = 0; i < kNumberOfSizeClasses; i++) {\n+    uptr mem = allocated_size_classes_[i];\n+    if (mem) {\n+      PoisonShadow(mem, ClassMmapSize(i), 0);\n+      allocated_size_classes_[i] = 0;\n+      UnmapOrDie((void*)mem, ClassMmapSize(i));\n+    }\n+  }\n+}\n+\n+uptr FakeStack::ClassMmapSize(uptr size_class) {\n+  return RoundUpToPowerOfTwo(stack_size_);\n+}\n+\n+void FakeStack::AllocateOneSizeClass(uptr size_class) {\n+  CHECK(ClassMmapSize(size_class) >= GetPageSizeCached());\n+  uptr new_mem = (uptr)MmapOrDie(\n+      ClassMmapSize(size_class), __FUNCTION__);\n+  // Printf(\"T%d new_mem[%zu]: %p-%p mmap %zu\\n\",\n+  //       asanThreadRegistry().GetCurrent()->tid(),\n+  //       size_class, new_mem, new_mem + ClassMmapSize(size_class),\n+  //       ClassMmapSize(size_class));\n+  uptr i;\n+  for (i = 0; i < ClassMmapSize(size_class);\n+       i += ClassSize(size_class)) {\n+    size_classes_[size_class].FifoPush((FakeFrame*)(new_mem + i));\n+  }\n+  CHECK(i == ClassMmapSize(size_class));\n+  allocated_size_classes_[size_class] = new_mem;\n+}\n+\n+uptr FakeStack::AllocateStack(uptr size, uptr real_stack) {\n+  if (!alive_) return real_stack;\n+  CHECK(size <= kMaxStackMallocSize && size > 1);\n+  uptr size_class = ComputeSizeClass(size);\n+  if (!allocated_size_classes_[size_class]) {\n+    AllocateOneSizeClass(size_class);\n+  }\n+  FakeFrame *fake_frame = size_classes_[size_class].FifoPop();\n+  CHECK(fake_frame);\n+  fake_frame->size_minus_one = size - 1;\n+  fake_frame->real_stack = real_stack;\n+  while (FakeFrame *top = call_stack_.top()) {\n+    if (top->real_stack > real_stack) break;\n+    call_stack_.LifoPop();\n+    DeallocateFrame(top);\n+  }\n+  call_stack_.LifoPush(fake_frame);\n+  uptr ptr = (uptr)fake_frame;\n+  PoisonShadow(ptr, size, 0);\n+  return ptr;\n+}\n+\n+void FakeStack::DeallocateFrame(FakeFrame *fake_frame) {\n+  CHECK(alive_);\n+  uptr size = fake_frame->size_minus_one + 1;\n+  uptr size_class = ComputeSizeClass(size);\n+  CHECK(allocated_size_classes_[size_class]);\n+  uptr ptr = (uptr)fake_frame;\n+  CHECK(AddrIsInSizeClass(ptr, size_class));\n+  CHECK(AddrIsInSizeClass(ptr + size - 1, size_class));\n+  size_classes_[size_class].FifoPush(fake_frame);\n+}\n+\n+void FakeStack::OnFree(uptr ptr, uptr size, uptr real_stack) {\n+  FakeFrame *fake_frame = (FakeFrame*)ptr;\n+  CHECK(fake_frame->magic = kRetiredStackFrameMagic);\n+  CHECK(fake_frame->descr != 0);\n+  CHECK(fake_frame->size_minus_one == size - 1);\n+  PoisonShadow(ptr, size, kAsanStackAfterReturnMagic);\n+}\n+\n+}  // namespace __asan\n+\n+// ---------------------- Interface ---------------- {{{1\n+using namespace __asan;  // NOLINT\n+\n+uptr __asan_stack_malloc(uptr size, uptr real_stack) {\n+  if (!flags()->use_fake_stack) return real_stack;\n+  AsanThread *t = asanThreadRegistry().GetCurrent();\n+  if (!t) {\n+    // TSD is gone, use the real stack.\n+    return real_stack;\n+  }\n+  uptr ptr = t->fake_stack().AllocateStack(size, real_stack);\n+  // Printf(\"__asan_stack_malloc %p %zu %p\\n\", ptr, size, real_stack);\n+  return ptr;\n+}\n+\n+void __asan_stack_free(uptr ptr, uptr size, uptr real_stack) {\n+  if (!flags()->use_fake_stack) return;\n+  if (ptr != real_stack) {\n+    FakeStack::OnFree(ptr, size, real_stack);\n+  }\n+}"}, {"sha": "49a907300843fe961a9e261537ae8dadc563c3b0", "filename": "libsanitizer/asan/asan_flags.h", "status": "modified", "additions": 12, "deletions": 1, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_flags.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_flags.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_flags.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -43,7 +43,7 @@ struct Flags {\n   int  report_globals;\n   // If set, attempts to catch initialization order issues.\n   bool check_initialization_order;\n-  // Max number of stack frames kept for each allocation.\n+  // Max number of stack frames kept for each allocation/deallocation.\n   int  malloc_context_size;\n   // If set, uses custom wrappers and replacements for libc string functions\n   // to find more errors.\n@@ -93,6 +93,17 @@ struct Flags {\n   bool print_full_thread_history;\n   // ASan will write logs to \"log_path.pid\" instead of stderr.\n   const char *log_path;\n+  // Use fast (frame-pointer-based) unwinder on fatal errors (if available).\n+  bool fast_unwind_on_fatal;\n+  // Use fast (frame-pointer-based) unwinder on malloc/free (if available).\n+  bool fast_unwind_on_malloc;\n+  // Poison (or not) the heap memory on [de]allocation. Zero value is useful\n+  // for benchmarking the allocator or instrumentator.\n+  bool poison_heap;\n+  // Report errors on malloc/delete, new/free, new/delete[], etc.\n+  bool alloc_dealloc_mismatch;\n+  // Use stack depot instead of storing stacks in the redzones.\n+  bool use_stack_depot;\n };\n \n Flags *flags();"}, {"sha": "8341bc65745569f801506390d88c96d9f3dbbfc0", "filename": "libsanitizer/asan/asan_intercepted_functions.h", "status": "modified", "additions": 18, "deletions": 2, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_intercepted_functions.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_intercepted_functions.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_intercepted_functions.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -14,6 +14,7 @@\n \n #include \"asan_internal.h\"\n #include \"interception/interception.h\"\n+#include \"sanitizer_common/sanitizer_platform_interceptors.h\"\n \n using __sanitizer::uptr;\n \n@@ -39,8 +40,10 @@ using __sanitizer::uptr;\n \n #if defined(__linux__)\n # define ASAN_USE_ALIAS_ATTRIBUTE_FOR_INDEX 1\n+# define ASAN_INTERCEPT_PRCTL 1\n #else\n # define ASAN_USE_ALIAS_ATTRIBUTE_FOR_INDEX 0\n+# define ASAN_INTERCEPT_PRCTL 0\n #endif\n \n #if !defined(__APPLE__)\n@@ -149,10 +152,23 @@ DECLARE_FUNCTION_AND_WRAPPER(long long, atoll, const char *nptr);  // NOLINT\n DECLARE_FUNCTION_AND_WRAPPER(long long, strtoll, const char *nptr, char **endptr, int base);  // NOLINT\n # endif\n \n+// unistd.h\n+# if SANITIZER_INTERCEPT_READ\n+DECLARE_FUNCTION_AND_WRAPPER(SSIZE_T, read, int fd, void *buf, SIZE_T count);\n+# endif\n+# if SANITIZER_INTERCEPT_PREAD\n+DECLARE_FUNCTION_AND_WRAPPER(SSIZE_T, pread, int fd, void *buf,\n+                             SIZE_T count, OFF_T offset);\n+# endif\n+# if SANITIZER_INTERCEPT_PREAD64\n+DECLARE_FUNCTION_AND_WRAPPER(SSIZE_T, pread64, int fd, void *buf,\n+                             SIZE_T count, OFF64_T offset);\n+# endif\n+\n # if ASAN_INTERCEPT_MLOCKX\n // mlock/munlock\n-DECLARE_FUNCTION_AND_WRAPPER(int, mlock, const void *addr, size_t len);\n-DECLARE_FUNCTION_AND_WRAPPER(int, munlock, const void *addr, size_t len);\n+DECLARE_FUNCTION_AND_WRAPPER(int, mlock, const void *addr, SIZE_T len);\n+DECLARE_FUNCTION_AND_WRAPPER(int, munlock, const void *addr, SIZE_T len);\n DECLARE_FUNCTION_AND_WRAPPER(int, mlockall, int flags);\n DECLARE_FUNCTION_AND_WRAPPER(int, munlockall, void);\n # endif"}, {"sha": "26daee1727cf47a2dba3c2de4505b39b3af866be", "filename": "libsanitizer/asan/asan_interceptors.cc", "status": "modified", "additions": 45, "deletions": 33, "changes": 78, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_interceptors.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_interceptors.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_interceptors.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -25,38 +25,20 @@\n \n namespace __asan {\n \n-// Instruments read/write access to a single byte in memory.\n-// On error calls __asan_report_error, which aborts the program.\n-#define ACCESS_ADDRESS(address, isWrite)   do {         \\\n-  if (!AddrIsInMem(address) || AddressIsPoisoned(address)) {                \\\n-    GET_CURRENT_PC_BP_SP;                               \\\n-    __asan_report_error(pc, bp, sp, address, isWrite, /* access_size */ 1); \\\n-  } \\\n-} while (0)\n-\n // We implement ACCESS_MEMORY_RANGE, ASAN_READ_RANGE,\n // and ASAN_WRITE_RANGE as macro instead of function so\n // that no extra frames are created, and stack trace contains\n // relevant information only.\n-\n-// Instruments read/write access to a memory range.\n-// More complex implementation is possible, for now just\n-// checking the first and the last byte of a range.\n-#define ACCESS_MEMORY_RANGE(offset, size, isWrite) do { \\\n-  if (size > 0) { \\\n-    uptr ptr = (uptr)(offset); \\\n-    ACCESS_ADDRESS(ptr, isWrite); \\\n-    ACCESS_ADDRESS(ptr + (size) - 1, isWrite); \\\n-  } \\\n+// We check all shadow bytes.\n+#define ACCESS_MEMORY_RANGE(offset, size, isWrite) do {                  \\\n+  if (uptr __ptr = __asan_region_is_poisoned((uptr)(offset), size)) {    \\\n+    GET_CURRENT_PC_BP_SP;                                                \\\n+    __asan_report_error(pc, bp, sp, __ptr, isWrite, /* access_size */1); \\\n+  }                                                                      \\\n } while (0)\n \n-#define ASAN_READ_RANGE(offset, size) do { \\\n-  ACCESS_MEMORY_RANGE(offset, size, false); \\\n-} while (0)\n-\n-#define ASAN_WRITE_RANGE(offset, size) do { \\\n-  ACCESS_MEMORY_RANGE(offset, size, true); \\\n-} while (0)\n+#define ASAN_READ_RANGE(offset, size) ACCESS_MEMORY_RANGE(offset, size, false)\n+#define ASAN_WRITE_RANGE(offset, size) ACCESS_MEMORY_RANGE(offset, size, true);\n \n // Behavior of functions like \"memcpy\" or \"strcpy\" is undefined\n // if memory intervals overlap. We report error in this case.\n@@ -69,7 +51,7 @@ static inline bool RangesOverlap(const char *offset1, uptr length1,\n   const char *offset1 = (const char*)_offset1; \\\n   const char *offset2 = (const char*)_offset2; \\\n   if (RangesOverlap(offset1, length1, offset2, length2)) { \\\n-    GET_STACK_TRACE_HERE(kStackTraceMax); \\\n+    GET_STACK_TRACE_FATAL_HERE; \\\n     ReportStringFunctionMemoryRangesOverlap(name, offset1, length1, \\\n                                             offset2, length2, &stack); \\\n   } \\\n@@ -96,6 +78,11 @@ static inline uptr MaybeRealStrnlen(const char *s, uptr maxlen) {\n // ---------------------- Wrappers ---------------- {{{1\n using namespace __asan;  // NOLINT\n \n+#define COMMON_INTERCEPTOR_WRITE_RANGE(ptr, size) ASAN_WRITE_RANGE(ptr, size)\n+#define COMMON_INTERCEPTOR_READ_RANGE(ptr, size) ASAN_READ_RANGE(ptr, size)\n+#define COMMON_INTERCEPTOR_ENTER(func, ...) ENSURE_ASAN_INITED()\n+#include \"sanitizer_common/sanitizer_common_interceptors.h\"\n+\n static thread_return_t THREAD_CALLING_CONV asan_thread_start(void *arg) {\n   AsanThread *t = (AsanThread*)arg;\n   asanThreadRegistry().SetCurrent(t);\n@@ -105,7 +92,7 @@ static thread_return_t THREAD_CALLING_CONV asan_thread_start(void *arg) {\n #if ASAN_INTERCEPT_PTHREAD_CREATE\n INTERCEPTOR(int, pthread_create, void *thread,\n     void *attr, void *(*start_routine)(void*), void *arg) {\n-  GET_STACK_TRACE_HERE(kStackTraceMax);\n+  GET_STACK_TRACE_THREAD;\n   u32 current_tid = asanThreadRegistry().GetCurrentTidOrInvalid();\n   AsanThread *t = AsanThread::Create(current_tid, start_routine, arg, &stack);\n   asanThreadRegistry().RegisterThread(t);\n@@ -175,6 +162,25 @@ INTERCEPTOR(void, siglongjmp, void *env, int val) {\n }\n #endif\n \n+#if ASAN_INTERCEPT_PRCTL\n+#define PR_SET_NAME 15\n+INTERCEPTOR(int, prctl, int option,\n+            unsigned long arg2, unsigned long arg3,  // NOLINT\n+            unsigned long arg4, unsigned long arg5) {  // NOLINT\n+  int res = REAL(prctl(option, arg2, arg3, arg4, arg5));\n+  if (option == PR_SET_NAME) {\n+    AsanThread *t = asanThreadRegistry().GetCurrent();\n+    if (t) {\n+      char buff[17];\n+      internal_strncpy(buff, (char*)arg2, 16);\n+      buff[16] = 0;\n+      t->summary()->set_name(buff);\n+    }\n+  }\n+  return res;\n+}\n+#endif\n+\n #if ASAN_INTERCEPT___CXA_THROW\n INTERCEPTOR(void, __cxa_throw, void *a, void *b, void *c) {\n   CHECK(REAL(__cxa_throw));\n@@ -256,8 +262,8 @@ INTERCEPTOR(void*, memcpy, void *to, const void *from, uptr size) {\n       // See http://llvm.org/bugs/show_bug.cgi?id=11763.\n       CHECK_RANGES_OVERLAP(\"memcpy\", to, size, from, size);\n     }\n-    ASAN_WRITE_RANGE(from, size);\n-    ASAN_READ_RANGE(to, size);\n+    ASAN_READ_RANGE(from, size);\n+    ASAN_WRITE_RANGE(to, size);\n   }\n #if MAC_INTERPOSE_FUNCTIONS\n   // Interposing of resolver functions is broken on Mac OS 10.7 and 10.8.\n@@ -275,8 +281,8 @@ INTERCEPTOR(void*, memmove, void *to, const void *from, uptr size) {\n   }\n   ENSURE_ASAN_INITED();\n   if (flags()->replace_intrin) {\n-    ASAN_WRITE_RANGE(from, size);\n-    ASAN_READ_RANGE(to, size);\n+    ASAN_READ_RANGE(from, size);\n+    ASAN_WRITE_RANGE(to, size);\n   }\n #if MAC_INTERPOSE_FUNCTIONS\n   // Interposing of resolver functions is broken on Mac OS 10.7 and 10.8.\n@@ -621,7 +627,7 @@ INTERCEPTOR_WINAPI(DWORD, CreateThread,\n                    void* security, uptr stack_size,\n                    DWORD (__stdcall *start_routine)(void*), void* arg,\n                    DWORD flags, void* tid) {\n-  GET_STACK_TRACE_HERE(kStackTraceMax);\n+  GET_STACK_TRACE_THREAD;\n   u32 current_tid = asanThreadRegistry().GetCurrentTidOrInvalid();\n   AsanThread *t = AsanThread::Create(current_tid, start_routine, arg, &stack);\n   asanThreadRegistry().RegisterThread(t);\n@@ -646,6 +652,9 @@ void InitializeAsanInterceptors() {\n #if MAC_INTERPOSE_FUNCTIONS\n   return;\n #endif\n+\n+  SANITIZER_COMMON_INTERCEPTORS_INIT;\n+\n   // Intercept mem* functions.\n   ASAN_INTERCEPT_FUNC(memcmp);\n   ASAN_INTERCEPT_FUNC(memmove);\n@@ -718,6 +727,9 @@ void InitializeAsanInterceptors() {\n #if ASAN_INTERCEPT_SIGLONGJMP\n   ASAN_INTERCEPT_FUNC(siglongjmp);\n #endif\n+#if ASAN_INTERCEPT_PRCTL\n+  ASAN_INTERCEPT_FUNC(prctl);\n+#endif\n \n   // Intercept exception handling functions.\n #if ASAN_INTERCEPT___CXA_THROW"}, {"sha": "1717fce66fb5f094abce3078e94c1e1745480d47", "filename": "libsanitizer/asan/asan_internal.h", "status": "modified", "additions": 11, "deletions": 2, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_internal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_internal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_internal.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -81,9 +81,9 @@\n // If set, values like allocator chunk size, as well as defaults for some flags\n // will be changed towards less memory overhead.\n #ifndef ASAN_LOW_MEMORY\n-# ifdef ASAN_ANDROID\n+#if SANITIZER_WORDSIZE == 32\n #  define ASAN_LOW_MEMORY 1\n-# else\n+#else\n #  define ASAN_LOW_MEMORY 0\n # endif\n #endif\n@@ -143,6 +143,15 @@ bool PlatformHasDifferentMemcpyAndMemmove();\n # define PLATFORM_HAS_DIFFERENT_MEMCPY_AND_MEMMOVE true\n #endif  // __APPLE__\n \n+// Add convenient macro for interface functions that may be represented as\n+// weak hooks.\n+#define ASAN_MALLOC_HOOK(ptr, size) \\\n+  if (&__asan_malloc_hook) __asan_malloc_hook(ptr, size)\n+#define ASAN_FREE_HOOK(ptr) \\\n+  if (&__asan_free_hook) __asan_free_hook(ptr)\n+#define ASAN_ON_ERROR() \\\n+  if (&__asan_on_error) __asan_on_error()\n+\n extern int asan_inited;\n // Used to avoid infinite recursion in __asan_init().\n extern bool asan_init_is_running;"}, {"sha": "0e6c6280f0b553a35d97e93829b87db73ac8aa38", "filename": "libsanitizer/asan/asan_linux.cc", "status": "modified", "additions": 8, "deletions": 40, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_linux.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_linux.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_linux.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -120,53 +120,21 @@ void AsanLock::Unlock() {\n   pthread_mutex_unlock((pthread_mutex_t*)&opaque_storage_);\n }\n \n-#ifdef __arm__\n-#define UNWIND_STOP _URC_END_OF_STACK\n-#define UNWIND_CONTINUE _URC_NO_REASON\n-#else\n-#define UNWIND_STOP _URC_NORMAL_STOP\n-#define UNWIND_CONTINUE _URC_NO_REASON\n-#endif\n-\n-uptr Unwind_GetIP(struct _Unwind_Context *ctx) {\n-#ifdef __arm__\n-  uptr val;\n-  _Unwind_VRS_Result res = _Unwind_VRS_Get(ctx, _UVRSC_CORE,\n-      15 /* r15 = PC */, _UVRSD_UINT32, &val);\n-  CHECK(res == _UVRSR_OK && \"_Unwind_VRS_Get failed\");\n-  // Clear the Thumb bit.\n-  return val & ~(uptr)1;\n-#else\n-  return _Unwind_GetIP(ctx);\n+void GetStackTrace(StackTrace *stack, uptr max_s, uptr pc, uptr bp, bool fast) {\n+#if defined(__arm__) || \\\n+    defined(__powerpc__) || defined(__powerpc64__) || \\\n+    defined(__sparc__)\n+  fast = false;\n #endif\n-}\n-\n-_Unwind_Reason_Code Unwind_Trace(struct _Unwind_Context *ctx,\n-    void *param) {\n-  StackTrace *b = (StackTrace*)param;\n-  CHECK(b->size < b->max_size);\n-  uptr pc = Unwind_GetIP(ctx);\n-  b->trace[b->size++] = pc;\n-  if (b->size == b->max_size) return UNWIND_STOP;\n-  return UNWIND_CONTINUE;\n-}\n-\n-void GetStackTrace(StackTrace *stack, uptr max_s, uptr pc, uptr bp) {\n+  if (!fast)\n+    return stack->SlowUnwindStack(pc, max_s);\n   stack->size = 0;\n   stack->trace[0] = pc;\n-  if ((max_s) > 1) {\n+  if (max_s > 1) {\n     stack->max_size = max_s;\n-#if defined(__arm__) || \\\n-    defined(__powerpc__) || defined(__powerpc64__) || \\\n-    defined(__sparc__)\n-    _Unwind_Backtrace(Unwind_Trace, stack);\n-    // Pop off the two ASAN functions from the backtrace.\n-    stack->PopStackFrames(2);\n-#else\n     if (!asan_inited) return;\n     if (AsanThread *t = asanThreadRegistry().GetCurrent())\n       stack->FastUnwindStack(pc, bp, t->stack_top(), t->stack_bottom());\n-#endif\n   }\n }\n "}, {"sha": "094c69ff6a26c00046aef7f8351191a8bf4eca5e", "filename": "libsanitizer/asan/asan_mac.cc", "status": "modified", "additions": 11, "deletions": 10, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_mac.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_mac.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_mac.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -158,7 +158,8 @@ void AsanLock::Unlock() {\n   OSSpinLockUnlock((OSSpinLock*)&opaque_storage_);\n }\n \n-void GetStackTrace(StackTrace *stack, uptr max_s, uptr pc, uptr bp) {\n+void GetStackTrace(StackTrace *stack, uptr max_s, uptr pc, uptr bp, bool fast) {\n+  (void)fast;\n   stack->size = 0;\n   stack->trace[0] = pc;\n   if ((max_s) > 1) {\n@@ -306,7 +307,7 @@ void asan_register_worker_thread(int parent_tid, StackTrace *stack) {\n // alloc_asan_context().\n extern \"C\"\n void asan_dispatch_call_block_and_release(void *block) {\n-  GET_STACK_TRACE_HERE(kStackTraceMax);\n+  GET_STACK_TRACE_THREAD;\n   asan_block_context_t *context = (asan_block_context_t*)block;\n   if (flags()->verbosity >= 2) {\n     Report(\"asan_dispatch_call_block_and_release(): \"\n@@ -316,7 +317,7 @@ void asan_dispatch_call_block_and_release(void *block) {\n   asan_register_worker_thread(context->parent_tid, &stack);\n   // Call the original dispatcher for the block.\n   context->func(context->block);\n-  asan_free(context, &stack);\n+  asan_free(context, &stack, FROM_MALLOC);\n }\n \n }  // namespace __asan\n@@ -341,7 +342,7 @@ asan_block_context_t *alloc_asan_context(void *ctxt, dispatch_function_t func,\n #define INTERCEPT_DISPATCH_X_F_3(dispatch_x_f)                                \\\n   INTERCEPTOR(void, dispatch_x_f, dispatch_queue_t dq, void *ctxt,            \\\n                                   dispatch_function_t func) {                 \\\n-    GET_STACK_TRACE_HERE(kStackTraceMax);                                     \\\n+    GET_STACK_TRACE_THREAD;                                                   \\\n     asan_block_context_t *asan_ctxt = alloc_asan_context(ctxt, func, &stack); \\\n     if (flags()->verbosity >= 2) {                                            \\\n       Report(#dispatch_x_f \"(): context: %p, pthread_self: %p\\n\",             \\\n@@ -359,7 +360,7 @@ INTERCEPT_DISPATCH_X_F_3(dispatch_barrier_async_f)\n INTERCEPTOR(void, dispatch_after_f, dispatch_time_t when,\n                                     dispatch_queue_t dq, void *ctxt,\n                                     dispatch_function_t func) {\n-  GET_STACK_TRACE_HERE(kStackTraceMax);\n+  GET_STACK_TRACE_THREAD;\n   asan_block_context_t *asan_ctxt = alloc_asan_context(ctxt, func, &stack);\n   if (flags()->verbosity >= 2) {\n     Report(\"dispatch_after_f: %p\\n\", asan_ctxt);\n@@ -372,7 +373,7 @@ INTERCEPTOR(void, dispatch_after_f, dispatch_time_t when,\n INTERCEPTOR(void, dispatch_group_async_f, dispatch_group_t group,\n                                           dispatch_queue_t dq, void *ctxt,\n                                           dispatch_function_t func) {\n-  GET_STACK_TRACE_HERE(kStackTraceMax);\n+  GET_STACK_TRACE_THREAD;\n   asan_block_context_t *asan_ctxt = alloc_asan_context(ctxt, func, &stack);\n   if (flags()->verbosity >= 2) {\n     Report(\"dispatch_group_async_f(): context: %p, pthread_self: %p\\n\",\n@@ -407,7 +408,7 @@ void dispatch_source_set_event_handler(dispatch_source_t ds, void(^work)(void));\n   void (^asan_block)(void);  \\\n   int parent_tid = asanThreadRegistry().GetCurrentTidOrInvalid(); \\\n   asan_block = ^(void) { \\\n-    GET_STACK_TRACE_HERE(kStackTraceMax); \\\n+    GET_STACK_TRACE_THREAD; \\\n     asan_register_worker_thread(parent_tid, &stack); \\\n     work(); \\\n   }\n@@ -457,15 +458,15 @@ void *wrap_workitem_func(void *arg) {\n   asan_block_context_t *ctxt = (asan_block_context_t*)arg;\n   worker_t fn = (worker_t)(ctxt->func);\n   void *result =  fn(ctxt->block);\n-  GET_STACK_TRACE_HERE(kStackTraceMax);\n-  asan_free(arg, &stack);\n+  GET_STACK_TRACE_THREAD;\n+  asan_free(arg, &stack, FROM_MALLOC);\n   return result;\n }\n \n INTERCEPTOR(int, pthread_workqueue_additem_np, pthread_workqueue_t workq,\n     void *(*workitem_func)(void *), void * workitem_arg,\n     pthread_workitem_handle_t * itemhandlep, unsigned int *gencountp) {\n-  GET_STACK_TRACE_HERE(kStackTraceMax);\n+  GET_STACK_TRACE_THREAD;\n   asan_block_context_t *asan_ctxt =\n       (asan_block_context_t*) asan_malloc(sizeof(asan_block_context_t), &stack);\n   asan_ctxt->block = workitem_arg;"}, {"sha": "e33d0c0d4d33b2144b311dd140ce568a5a071d1f", "filename": "libsanitizer/asan/asan_malloc_linux.cc", "status": "modified", "additions": 19, "deletions": 13, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_malloc_linux.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_malloc_linux.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_malloc_linux.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -17,6 +17,8 @@\n #include \"asan_interceptors.h\"\n #include \"asan_internal.h\"\n #include \"asan_stack.h\"\n+#include \"asan_thread_registry.h\"\n+#include \"sanitizer/asan_interface.h\"\n \n #if ASAN_ANDROID\n DECLARE_REAL_AND_INTERCEPTOR(void*, malloc, uptr size)\n@@ -57,17 +59,17 @@ void ReplaceSystemMalloc() {\n using namespace __asan;  // NOLINT\n \n INTERCEPTOR(void, free, void *ptr) {\n-  GET_STACK_TRACE_HERE_FOR_FREE(ptr);\n-  asan_free(ptr, &stack);\n+  GET_STACK_TRACE_FREE;\n+  asan_free(ptr, &stack, FROM_MALLOC);\n }\n \n INTERCEPTOR(void, cfree, void *ptr) {\n-  GET_STACK_TRACE_HERE_FOR_FREE(ptr);\n-  asan_free(ptr, &stack);\n+  GET_STACK_TRACE_FREE;\n+  asan_free(ptr, &stack, FROM_MALLOC);\n }\n \n INTERCEPTOR(void*, malloc, uptr size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_malloc(size, &stack);\n }\n \n@@ -83,25 +85,25 @@ INTERCEPTOR(void*, calloc, uptr nmemb, uptr size) {\n     CHECK(allocated < kCallocPoolSize);\n     return mem;\n   }\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_calloc(nmemb, size, &stack);\n }\n \n INTERCEPTOR(void*, realloc, void *ptr, uptr size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_realloc(ptr, size, &stack);\n }\n \n INTERCEPTOR(void*, memalign, uptr boundary, uptr size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n-  return asan_memalign(boundary, size, &stack);\n+  GET_STACK_TRACE_MALLOC;\n+  return asan_memalign(boundary, size, &stack, FROM_MALLOC);\n }\n \n INTERCEPTOR(void*, __libc_memalign, uptr align, uptr s)\n   ALIAS(\"memalign\");\n \n INTERCEPTOR(uptr, malloc_usable_size, void *ptr) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_malloc_usable_size(ptr, &stack);\n }\n \n@@ -124,19 +126,23 @@ INTERCEPTOR(int, mallopt, int cmd, int value) {\n }\n \n INTERCEPTOR(int, posix_memalign, void **memptr, uptr alignment, uptr size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   // Printf(\"posix_memalign: %zx %zu\\n\", alignment, size);\n   return asan_posix_memalign(memptr, alignment, size, &stack);\n }\n \n INTERCEPTOR(void*, valloc, uptr size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_valloc(size, &stack);\n }\n \n INTERCEPTOR(void*, pvalloc, uptr size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_pvalloc(size, &stack);\n }\n \n+INTERCEPTOR(void, malloc_stats, void) {\n+  __asan_print_accumulated_stats();\n+}\n+\n #endif  // __linux__"}, {"sha": "97aa4424d33364775ed96bc20243584be1f132b6", "filename": "libsanitizer/asan/asan_malloc_mac.cc", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_malloc_mac.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_malloc_mac.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_malloc_mac.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -90,8 +90,8 @@ INTERCEPTOR(void, free, void *ptr) {\n #endif\n   } else {\n     if (!asan_mz_size(ptr)) ptr = get_saved_cfallocator_ref(ptr);\n-    GET_STACK_TRACE_HERE_FOR_FREE(ptr);\n-    asan_free(ptr, &stack);\n+    GET_STACK_TRACE_FREE;\n+    asan_free(ptr, &stack, FROM_MALLOC);\n   }\n }\n \n@@ -128,7 +128,7 @@ void *mz_malloc(malloc_zone_t *zone, size_t size) {\n     CHECK(system_malloc_zone);\n     return malloc_zone_malloc(system_malloc_zone, size);\n   }\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_malloc(size, &stack);\n }\n \n@@ -137,7 +137,7 @@ void *cf_malloc(CFIndex size, CFOptionFlags hint, void *info) {\n     CHECK(system_malloc_zone);\n     return malloc_zone_malloc(system_malloc_zone, size);\n   }\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_malloc(size, &stack);\n }\n \n@@ -153,7 +153,7 @@ void *mz_calloc(malloc_zone_t *zone, size_t nmemb, size_t size) {\n     CHECK(allocated < kCallocPoolSize);\n     return mem;\n   }\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_calloc(nmemb, size, &stack);\n }\n \n@@ -162,8 +162,8 @@ void *mz_valloc(malloc_zone_t *zone, size_t size) {\n     CHECK(system_malloc_zone);\n     return malloc_zone_valloc(system_malloc_zone, size);\n   }\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n-  return asan_memalign(GetPageSizeCached(), size, &stack);\n+  GET_STACK_TRACE_MALLOC;\n+  return asan_memalign(GetPageSizeCached(), size, &stack, FROM_MALLOC);\n }\n \n #define GET_ZONE_FOR_PTR(ptr) \\\n@@ -173,8 +173,8 @@ void *mz_valloc(malloc_zone_t *zone, size_t size) {\n void ALWAYS_INLINE free_common(void *context, void *ptr) {\n   if (!ptr) return;\n   if (asan_mz_size(ptr)) {\n-    GET_STACK_TRACE_HERE_FOR_FREE(ptr);\n-    asan_free(ptr, &stack);\n+    GET_STACK_TRACE_FREE;\n+    asan_free(ptr, &stack, FROM_MALLOC);\n   } else {\n     // If the pointer does not belong to any of the zones, use one of the\n     // fallback methods to free memory.\n@@ -188,9 +188,9 @@ void ALWAYS_INLINE free_common(void *context, void *ptr) {\n       // If the memory chunk pointer was moved to store additional\n       // CFAllocatorRef, fix it back.\n       ptr = get_saved_cfallocator_ref(ptr);\n-      GET_STACK_TRACE_HERE_FOR_FREE(ptr);\n+      GET_STACK_TRACE_FREE;\n       if (!flags()->mac_ignore_invalid_free) {\n-        asan_free(ptr, &stack);\n+        asan_free(ptr, &stack, FROM_MALLOC);\n       } else {\n         GET_ZONE_FOR_PTR(ptr);\n         WarnMacFreeUnallocated((uptr)ptr, (uptr)zone_ptr, zone_name, &stack);\n@@ -211,17 +211,17 @@ void cf_free(void *ptr, void *info) {\n \n void *mz_realloc(malloc_zone_t *zone, void *ptr, size_t size) {\n   if (!ptr) {\n-    GET_STACK_TRACE_HERE_FOR_MALLOC;\n+    GET_STACK_TRACE_MALLOC;\n     return asan_malloc(size, &stack);\n   } else {\n     if (asan_mz_size(ptr)) {\n-      GET_STACK_TRACE_HERE_FOR_MALLOC;\n+      GET_STACK_TRACE_MALLOC;\n       return asan_realloc(ptr, size, &stack);\n     } else {\n       // We can't recover from reallocating an unknown address, because\n       // this would require reading at most |size| bytes from\n       // potentially unaccessible memory.\n-      GET_STACK_TRACE_HERE_FOR_FREE(ptr);\n+      GET_STACK_TRACE_FREE;\n       GET_ZONE_FOR_PTR(ptr);\n       ReportMacMzReallocUnknown((uptr)ptr, (uptr)zone_ptr, zone_name, &stack);\n     }\n@@ -230,17 +230,17 @@ void *mz_realloc(malloc_zone_t *zone, void *ptr, size_t size) {\n \n void *cf_realloc(void *ptr, CFIndex size, CFOptionFlags hint, void *info) {\n   if (!ptr) {\n-    GET_STACK_TRACE_HERE_FOR_MALLOC;\n+    GET_STACK_TRACE_MALLOC;\n     return asan_malloc(size, &stack);\n   } else {\n     if (asan_mz_size(ptr)) {\n-      GET_STACK_TRACE_HERE_FOR_MALLOC;\n+      GET_STACK_TRACE_MALLOC;\n       return asan_realloc(ptr, size, &stack);\n     } else {\n       // We can't recover from reallocating an unknown address, because\n       // this would require reading at most |size| bytes from\n       // potentially unaccessible memory.\n-      GET_STACK_TRACE_HERE_FOR_FREE(ptr);\n+      GET_STACK_TRACE_FREE;\n       GET_ZONE_FOR_PTR(ptr);\n       ReportMacCfReallocUnknown((uptr)ptr, (uptr)zone_ptr, zone_name, &stack);\n     }\n@@ -259,8 +259,8 @@ void *mz_memalign(malloc_zone_t *zone, size_t align, size_t size) {\n     CHECK(system_malloc_zone);\n     return malloc_zone_memalign(system_malloc_zone, align, size);\n   }\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n-  return asan_memalign(align, size, &stack);\n+  GET_STACK_TRACE_MALLOC;\n+  return asan_memalign(align, size, &stack, FROM_MALLOC);\n }\n \n // This function is currently unused, and we build with -Werror."}, {"sha": "437079f5d1dd84819665f3c3a3a0612cc42156b6", "filename": "libsanitizer/asan/asan_malloc_win.cc", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_malloc_win.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_malloc_win.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_malloc_win.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -29,8 +29,8 @@ using namespace __asan;  // NOLINT\n \n extern \"C\" {\n void free(void *ptr) {\n-  GET_STACK_TRACE_HERE_FOR_FREE(ptr);\n-  return asan_free(ptr, &stack);\n+  GET_STACK_TRACE_FREE;\n+  return asan_free(ptr, &stack, FROM_MALLOC);\n }\n \n void _free_dbg(void* ptr, int) {\n@@ -42,7 +42,7 @@ void cfree(void *ptr) {\n }\n \n void *malloc(size_t size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_malloc(size, &stack);\n }\n \n@@ -51,7 +51,7 @@ void* _malloc_dbg(size_t size, int , const char*, int) {\n }\n \n void *calloc(size_t nmemb, size_t size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_calloc(nmemb, size, &stack);\n }\n \n@@ -64,7 +64,7 @@ void *_calloc_impl(size_t nmemb, size_t size, int *errno_tmp) {\n }\n \n void *realloc(void *ptr, size_t size) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_realloc(ptr, size, &stack);\n }\n \n@@ -83,7 +83,7 @@ void* _recalloc(void* p, size_t n, size_t elem_size) {\n }\n \n size_t _msize(void *ptr) {\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\n+  GET_STACK_TRACE_MALLOC;\n   return asan_malloc_usable_size(ptr, &stack);\n }\n "}, {"sha": "54e21b79678cdc2c163b0a1630af8ac2ebe7e679", "filename": "libsanitizer/asan/asan_mapping.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_mapping.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_mapping.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_mapping.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -18,8 +18,8 @@\n // http://code.google.com/p/address-sanitizer/wiki/AddressSanitizerAlgorithm\n \n #if ASAN_FLEXIBLE_MAPPING_AND_OFFSET == 1\n-extern __attribute__((visibility(\"default\"))) uptr __asan_mapping_scale;\n-extern __attribute__((visibility(\"default\"))) uptr __asan_mapping_offset;\n+extern SANITIZER_INTERFACE_ATTRIBUTE uptr __asan_mapping_scale;\n+extern SANITIZER_INTERFACE_ATTRIBUTE uptr __asan_mapping_offset;\n # define SHADOW_SCALE (__asan_mapping_scale)\n # define SHADOW_OFFSET (__asan_mapping_offset)\n #else"}, {"sha": "6597b93366f1f4dc1d02f1da60ce869aa09e6b3f", "filename": "libsanitizer/asan/asan_new_delete.cc", "status": "modified", "additions": 16, "deletions": 14, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_new_delete.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_new_delete.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_new_delete.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -33,32 +33,34 @@ namespace std {\n struct nothrow_t {};\n }  // namespace std\n \n-#define OPERATOR_NEW_BODY \\\n-  GET_STACK_TRACE_HERE_FOR_MALLOC;\\\n-  return asan_memalign(0, size, &stack);\n+#define OPERATOR_NEW_BODY(type) \\\n+  GET_STACK_TRACE_MALLOC;\\\n+  return asan_memalign(0, size, &stack, type);\n \n INTERCEPTOR_ATTRIBUTE\n-void *operator new(size_t size) { OPERATOR_NEW_BODY; }\n+void *operator new(size_t size) { OPERATOR_NEW_BODY(FROM_NEW); }\n INTERCEPTOR_ATTRIBUTE\n-void *operator new[](size_t size) { OPERATOR_NEW_BODY; }\n+void *operator new[](size_t size) { OPERATOR_NEW_BODY(FROM_NEW_BR); }\n INTERCEPTOR_ATTRIBUTE\n-void *operator new(size_t size, std::nothrow_t const&) { OPERATOR_NEW_BODY; }\n+void *operator new(size_t size, std::nothrow_t const&)\n+{ OPERATOR_NEW_BODY(FROM_NEW); }\n INTERCEPTOR_ATTRIBUTE\n-void *operator new[](size_t size, std::nothrow_t const&) { OPERATOR_NEW_BODY; }\n+void *operator new[](size_t size, std::nothrow_t const&)\n+{ OPERATOR_NEW_BODY(FROM_NEW_BR); }\n \n-#define OPERATOR_DELETE_BODY \\\n-  GET_STACK_TRACE_HERE_FOR_FREE(ptr);\\\n-  asan_free(ptr, &stack);\n+#define OPERATOR_DELETE_BODY(type) \\\n+  GET_STACK_TRACE_FREE;\\\n+  asan_free(ptr, &stack, type);\n \n INTERCEPTOR_ATTRIBUTE\n-void operator delete(void *ptr) { OPERATOR_DELETE_BODY; }\n+void operator delete(void *ptr) { OPERATOR_DELETE_BODY(FROM_NEW); }\n INTERCEPTOR_ATTRIBUTE\n-void operator delete[](void *ptr) { OPERATOR_DELETE_BODY; }\n+void operator delete[](void *ptr) { OPERATOR_DELETE_BODY(FROM_NEW_BR); }\n INTERCEPTOR_ATTRIBUTE\n void operator delete(void *ptr, std::nothrow_t const&)\n-{ OPERATOR_DELETE_BODY; }\n+{ OPERATOR_DELETE_BODY(FROM_NEW); }\n INTERCEPTOR_ATTRIBUTE\n void operator delete[](void *ptr, std::nothrow_t const&)\n-{ OPERATOR_DELETE_BODY; }\n+{ OPERATOR_DELETE_BODY(FROM_NEW_BR); }\n \n #endif"}, {"sha": "a00bafffae0a0d59faf9419af02ab3dde757f3c5", "filename": "libsanitizer/asan/asan_poisoning.cc", "status": "modified", "additions": 31, "deletions": 1, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_poisoning.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_poisoning.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_poisoning.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -14,10 +14,12 @@\n #include \"asan_internal.h\"\n #include \"asan_mapping.h\"\n #include \"sanitizer/asan_interface.h\"\n+#include \"sanitizer_common/sanitizer_libc.h\"\n \n namespace __asan {\n \n void PoisonShadow(uptr addr, uptr size, u8 value) {\n+  if (!flags()->poison_heap) return;\n   CHECK(AddrIsAlignedByGranularity(addr));\n   CHECK(AddrIsAlignedByGranularity(addr + size));\n   uptr shadow_beg = MemToShadow(addr);\n@@ -30,6 +32,7 @@ void PoisonShadowPartialRightRedzone(uptr addr,\n                                      uptr size,\n                                      uptr redzone_size,\n                                      u8 value) {\n+  if (!flags()->poison_heap) return;\n   CHECK(AddrIsAlignedByGranularity(addr));\n   u8 *shadow = (u8*)MemToShadow(addr);\n   for (uptr i = 0; i < redzone_size;\n@@ -150,6 +153,33 @@ bool __asan_address_is_poisoned(void const volatile *addr) {\n   return __asan::AddressIsPoisoned((uptr)addr);\n }\n \n+uptr __asan_region_is_poisoned(uptr beg, uptr size) {\n+  if (!size) return 0;\n+  uptr end = beg + size;\n+  if (!AddrIsInMem(beg)) return beg;\n+  if (!AddrIsInMem(end)) return end;\n+  uptr aligned_b = RoundUpTo(beg, SHADOW_GRANULARITY);\n+  uptr aligned_e = RoundDownTo(end, SHADOW_GRANULARITY);\n+  uptr shadow_beg = MemToShadow(aligned_b);\n+  uptr shadow_end = MemToShadow(aligned_e);\n+  // First check the first and the last application bytes,\n+  // then check the SHADOW_GRANULARITY-aligned region by calling\n+  // mem_is_zero on the corresponding shadow.\n+  if (!__asan::AddressIsPoisoned(beg) &&\n+      !__asan::AddressIsPoisoned(end - 1) &&\n+      (shadow_end <= shadow_beg ||\n+       __sanitizer::mem_is_zero((const char *)shadow_beg,\n+                                shadow_end - shadow_beg)))\n+    return 0;\n+  // The fast check failed, so we have a poisoned byte somewhere.\n+  // Find it slowly.\n+  for (; beg < end; beg++)\n+    if (__asan::AddressIsPoisoned(beg))\n+      return beg;\n+  UNREACHABLE(\"mem_is_zero returned false, but poisoned byte was not found\");\n+  return 0;\n+}\n+\n // This is a simplified version of __asan_(un)poison_memory_region, which\n // assumes that left border of region to be poisoned is properly aligned.\n static void PoisonAlignedStackMemory(uptr addr, uptr size, bool do_poison) {\n@@ -166,7 +196,7 @@ static void PoisonAlignedStackMemory(uptr addr, uptr size, bool do_poison) {\n     // If possible, mark all the bytes mapping to last shadow byte as\n     // unaddressable.\n     if (end_value > 0 && end_value <= end_offset)\n-      *shadow_end = kAsanStackUseAfterScopeMagic;\n+      *shadow_end = (s8)kAsanStackUseAfterScopeMagic;\n   } else {\n     // If necessary, mark few first bytes mapping to last shadow byte\n     // as addressable"}, {"sha": "ed18ab2509847143b163aeff18dccfac4d527290", "filename": "libsanitizer/asan/asan_report.cc", "status": "modified", "additions": 209, "deletions": 27, "changes": 236, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_report.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_report.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_report.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -16,6 +16,9 @@\n #include \"asan_stack.h\"\n #include \"asan_thread.h\"\n #include \"asan_thread_registry.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_report_decorator.h\"\n+#include \"sanitizer_common/sanitizer_symbolizer.h\"\n \n namespace __asan {\n \n@@ -38,14 +41,79 @@ void AppendToErrorMessageBuffer(const char *buffer) {\n   }\n }\n \n+// ---------------------- Decorator ------------------------------ {{{1\n+bool PrintsToTtyCached() {\n+  static int cached = 0;\n+  static bool prints_to_tty;\n+  if (!cached) {  // Ok wrt threads since we are printing only from one thread.\n+    prints_to_tty = PrintsToTty();\n+    cached = 1;\n+  }\n+  return prints_to_tty;\n+}\n+class Decorator: private __sanitizer::AnsiColorDecorator {\n+ public:\n+  Decorator() : __sanitizer::AnsiColorDecorator(PrintsToTtyCached()) { }\n+  const char *Warning()    { return Red(); }\n+  const char *EndWarning() { return Default(); }\n+  const char *Access()     { return Blue(); }\n+  const char *EndAccess()  { return Default(); }\n+  const char *Location()   { return Green(); }\n+  const char *EndLocation() { return Default(); }\n+  const char *Allocation()  { return Magenta(); }\n+  const char *EndAllocation()  { return Default(); }\n+\n+  const char *ShadowByte(u8 byte) {\n+    switch (byte) {\n+      case kAsanHeapLeftRedzoneMagic:\n+      case kAsanHeapRightRedzoneMagic:\n+        return Red();\n+      case kAsanHeapFreeMagic:\n+        return Magenta();\n+      case kAsanStackLeftRedzoneMagic:\n+      case kAsanStackMidRedzoneMagic:\n+      case kAsanStackRightRedzoneMagic:\n+      case kAsanStackPartialRedzoneMagic:\n+        return Red();\n+      case kAsanStackAfterReturnMagic:\n+        return Magenta();\n+      case kAsanInitializationOrderMagic:\n+        return Cyan();\n+      case kAsanUserPoisonedMemoryMagic:\n+        return Blue();\n+      case kAsanStackUseAfterScopeMagic:\n+        return Magenta();\n+      case kAsanGlobalRedzoneMagic:\n+        return Red();\n+      case kAsanInternalHeapMagic:\n+        return Yellow();\n+      default:\n+        return Default();\n+    }\n+  }\n+  const char *EndShadowByte() { return Default(); }\n+};\n+\n // ---------------------- Helper functions ----------------------- {{{1\n \n-static void PrintBytes(const char *before, uptr *a) {\n-  u8 *bytes = (u8*)a;\n-  uptr byte_num = (SANITIZER_WORDSIZE) / 8;\n-  Printf(\"%s%p:\", before, (void*)a);\n-  for (uptr i = 0; i < byte_num; i++) {\n-    Printf(\" %x%x\", bytes[i] >> 4, bytes[i] & 15);\n+static void PrintShadowByte(const char *before, u8 byte,\n+                            const char *after = \"\\n\") {\n+  Decorator d;\n+  Printf(\"%s%s%x%x%s%s\", before,\n+         d.ShadowByte(byte), byte >> 4, byte & 15, d.EndShadowByte(), after);\n+}\n+\n+static void PrintShadowBytes(const char *before, u8 *bytes,\n+                             u8 *guilty, uptr n) {\n+  Decorator d;\n+  if (before)\n+    Printf(\"%s%p:\", before, bytes);\n+  for (uptr i = 0; i < n; i++) {\n+    u8 *p = bytes + i;\n+    const char *before = p == guilty ? \"[\" :\n+        p - 1 == guilty ? \"\" : \" \";\n+    const char *after = p == guilty ? \"]\" : \"\";\n+    PrintShadowByte(before, *p, after);\n   }\n   Printf(\"\\n\");\n }\n@@ -54,15 +122,35 @@ static void PrintShadowMemoryForAddress(uptr addr) {\n   if (!AddrIsInMem(addr))\n     return;\n   uptr shadow_addr = MemToShadow(addr);\n-  Printf(\"Shadow byte and word:\\n\");\n-  Printf(\"  %p: %x\\n\", (void*)shadow_addr, *(unsigned char*)shadow_addr);\n-  uptr aligned_shadow = shadow_addr & ~(kWordSize - 1);\n-  PrintBytes(\"  \", (uptr*)(aligned_shadow));\n-  Printf(\"More shadow bytes:\\n\");\n-  for (int i = -4; i <= 4; i++) {\n+  const uptr n_bytes_per_row = 16;\n+  uptr aligned_shadow = shadow_addr & ~(n_bytes_per_row - 1);\n+  Printf(\"Shadow bytes around the buggy address:\\n\");\n+  for (int i = -5; i <= 5; i++) {\n     const char *prefix = (i == 0) ? \"=>\" : \"  \";\n-    PrintBytes(prefix, (uptr*)(aligned_shadow + i * kWordSize));\n+    PrintShadowBytes(prefix,\n+                     (u8*)(aligned_shadow + i * n_bytes_per_row),\n+                     (u8*)shadow_addr, n_bytes_per_row);\n   }\n+  Printf(\"Shadow byte legend (one shadow byte represents %d \"\n+         \"application bytes):\\n\", (int)SHADOW_GRANULARITY);\n+  PrintShadowByte(\"  Addressable:           \", 0);\n+  Printf(\"  Partially addressable: \");\n+  for (uptr i = 1; i < SHADOW_GRANULARITY; i++)\n+    PrintShadowByte(\"\", i, \" \");\n+  Printf(\"\\n\");\n+  PrintShadowByte(\"  Heap left redzone:     \", kAsanHeapLeftRedzoneMagic);\n+  PrintShadowByte(\"  Heap righ redzone:     \", kAsanHeapRightRedzoneMagic);\n+  PrintShadowByte(\"  Freed Heap region:     \", kAsanHeapFreeMagic);\n+  PrintShadowByte(\"  Stack left redzone:    \", kAsanStackLeftRedzoneMagic);\n+  PrintShadowByte(\"  Stack mid redzone:     \", kAsanStackMidRedzoneMagic);\n+  PrintShadowByte(\"  Stack right redzone:   \", kAsanStackRightRedzoneMagic);\n+  PrintShadowByte(\"  Stack partial redzone: \", kAsanStackPartialRedzoneMagic);\n+  PrintShadowByte(\"  Stack after return:    \", kAsanStackAfterReturnMagic);\n+  PrintShadowByte(\"  Stack use after scope: \", kAsanStackUseAfterScopeMagic);\n+  PrintShadowByte(\"  Global redzone:        \", kAsanGlobalRedzoneMagic);\n+  PrintShadowByte(\"  Global init order:     \", kAsanInitializationOrderMagic);\n+  PrintShadowByte(\"  Poisoned by user:      \", kAsanUserPoisonedMemoryMagic);\n+  PrintShadowByte(\"  ASan internal:         \", kAsanInternalHeapMagic);\n }\n \n static void PrintZoneForPointer(uptr ptr, uptr zone_ptr,\n@@ -98,6 +186,8 @@ static void PrintGlobalNameIfASCII(const __asan_global &g) {\n bool DescribeAddressRelativeToGlobal(uptr addr, const __asan_global &g) {\n   if (addr < g.beg - kGlobalAndStackRedzone) return false;\n   if (addr >= g.beg + g.size_with_redzone) return false;\n+  Decorator d;\n+  Printf(\"%s\", d.Location());\n   Printf(\"%p is located \", (void*)addr);\n   if (addr < g.beg) {\n     Printf(\"%zd bytes to the left\", g.beg - addr);\n@@ -108,6 +198,7 @@ bool DescribeAddressRelativeToGlobal(uptr addr, const __asan_global &g) {\n   }\n   Printf(\" of global variable '%s' (0x%zx) of size %zu\\n\",\n              g.name, g.beg, g.size);\n+  Printf(\"%s\", d.EndLocation());\n   PrintGlobalNameIfASCII(g);\n   return true;\n }\n@@ -151,9 +242,12 @@ bool DescribeAddressIfStack(uptr addr, uptr access_size) {\n   internal_strncat(buf, frame_descr,\n                    Min(kBufSize,\n                        static_cast<sptr>(name_end - frame_descr)));\n+  Decorator d;\n+  Printf(\"%s\", d.Location());\n   Printf(\"Address %p is located at offset %zu \"\n              \"in frame <%s> of T%d's stack:\\n\",\n-             (void*)addr, offset, buf, t->tid());\n+             (void*)addr, offset, Demangle(buf), t->tid());\n+  Printf(\"%s\", d.EndLocation());\n   // Report the number of stack objects.\n   char *p;\n   uptr n_objects = internal_simple_strtoll(name_end, &p, 10);\n@@ -187,6 +281,8 @@ bool DescribeAddressIfStack(uptr addr, uptr access_size) {\n static void DescribeAccessToHeapChunk(AsanChunkView chunk, uptr addr,\n                                       uptr access_size) {\n   uptr offset;\n+  Decorator d;\n+  Printf(\"%s\", d.Location());\n   Printf(\"%p is located \", (void*)addr);\n   if (chunk.AddrIsInside(addr, access_size, &offset)) {\n     Printf(\"%zu bytes inside of\", offset);\n@@ -199,6 +295,26 @@ static void DescribeAccessToHeapChunk(AsanChunkView chunk, uptr addr,\n   }\n   Printf(\" %zu-byte region [%p,%p)\\n\", chunk.UsedSize(),\n          (void*)(chunk.Beg()), (void*)(chunk.End()));\n+  Printf(\"%s\", d.EndLocation());\n+}\n+\n+// Return \" (thread_name) \" or an empty string if the name is empty.\n+const char *ThreadNameWithParenthesis(AsanThreadSummary *t, char buff[],\n+                                      uptr buff_len) {\n+  const char *name = t->name();\n+  if (*name == 0) return \"\";\n+  buff[0] = 0;\n+  internal_strncat(buff, \" (\", 3);\n+  internal_strncat(buff, name, buff_len - 4);\n+  internal_strncat(buff, \")\", 2);\n+  return buff;\n+}\n+\n+const char *ThreadNameWithParenthesis(u32 tid, char buff[],\n+                                      uptr buff_len) {\n+  if (tid == kInvalidTid) return \"\";\n+  AsanThreadSummary *t = asanThreadRegistry().FindByTid(tid);\n+  return ThreadNameWithParenthesis(t, buff, buff_len);\n }\n \n void DescribeHeapAddress(uptr addr, uptr access_size) {\n@@ -212,20 +328,31 @@ void DescribeHeapAddress(uptr addr, uptr access_size) {\n   chunk.GetAllocStack(&alloc_stack);\n   AsanThread *t = asanThreadRegistry().GetCurrent();\n   CHECK(t);\n+  char tname[128];\n+  Decorator d;\n   if (chunk.FreeTid() != kInvalidTid) {\n     AsanThreadSummary *free_thread =\n         asanThreadRegistry().FindByTid(chunk.FreeTid());\n-    Printf(\"freed by thread T%d here:\\n\", free_thread->tid());\n+    Printf(\"%sfreed by thread T%d%s here:%s\\n\", d.Allocation(),\n+           free_thread->tid(),\n+           ThreadNameWithParenthesis(free_thread, tname, sizeof(tname)),\n+           d.EndAllocation());\n     StackTrace free_stack;\n     chunk.GetFreeStack(&free_stack);\n     PrintStack(&free_stack);\n-    Printf(\"previously allocated by thread T%d here:\\n\", alloc_thread->tid());\n+    Printf(\"%spreviously allocated by thread T%d%s here:%s\\n\",\n+           d.Allocation(), alloc_thread->tid(),\n+           ThreadNameWithParenthesis(alloc_thread, tname, sizeof(tname)),\n+           d.EndAllocation());\n     PrintStack(&alloc_stack);\n     DescribeThread(t->summary());\n     DescribeThread(free_thread);\n     DescribeThread(alloc_thread);\n   } else {\n-    Printf(\"allocated by thread T%d here:\\n\", alloc_thread->tid());\n+    Printf(\"%sallocated by thread T%d%s here:%s\\n\", d.Allocation(),\n+           alloc_thread->tid(),\n+           ThreadNameWithParenthesis(alloc_thread, tname, sizeof(tname)),\n+           d.EndAllocation());\n     PrintStack(&alloc_stack);\n     DescribeThread(t->summary());\n     DescribeThread(alloc_thread);\n@@ -254,8 +381,13 @@ void DescribeThread(AsanThreadSummary *summary) {\n     return;\n   }\n   summary->set_announced(true);\n-  Printf(\"Thread T%d created by T%d here:\\n\",\n-         summary->tid(), summary->parent_tid());\n+  char tname[128];\n+  Printf(\"Thread T%d%s\", summary->tid(),\n+         ThreadNameWithParenthesis(summary->tid(), tname, sizeof(tname)));\n+  Printf(\" created by T%d%s here:\\n\",\n+         summary->parent_tid(),\n+         ThreadNameWithParenthesis(summary->parent_tid(),\n+                                   tname, sizeof(tname)));\n   PrintStack(summary->stack());\n   // Recursively described parent thread if needed.\n   if (flags()->print_full_thread_history) {\n@@ -291,7 +423,7 @@ class ScopedInErrorReport {\n       // Die() to bypass any additional checks.\n       Exit(flags()->exitcode);\n     }\n-    __asan_on_error();\n+    ASAN_ON_ERROR();\n     reporting_thread_tid = asanThreadRegistry().GetCurrentTidOrInvalid();\n     Printf(\"====================================================\"\n            \"=============\\n\");\n@@ -322,44 +454,79 @@ class ScopedInErrorReport {\n \n void ReportSIGSEGV(uptr pc, uptr sp, uptr bp, uptr addr) {\n   ScopedInErrorReport in_report;\n+  Decorator d;\n+  Printf(\"%s\", d.Warning());\n   Report(\"ERROR: AddressSanitizer: SEGV on unknown address %p\"\n              \" (pc %p sp %p bp %p T%d)\\n\",\n              (void*)addr, (void*)pc, (void*)sp, (void*)bp,\n              asanThreadRegistry().GetCurrentTidOrInvalid());\n+  Printf(\"%s\", d.EndWarning());\n   Printf(\"AddressSanitizer can not provide additional info.\\n\");\n-  GET_STACK_TRACE_WITH_PC_AND_BP(kStackTraceMax, pc, bp);\n+  GET_STACK_TRACE_FATAL(pc, bp);\n   PrintStack(&stack);\n }\n \n void ReportDoubleFree(uptr addr, StackTrace *stack) {\n   ScopedInErrorReport in_report;\n+  Decorator d;\n+  Printf(\"%s\", d.Warning());\n   Report(\"ERROR: AddressSanitizer: attempting double-free on %p:\\n\", addr);\n+  Printf(\"%s\", d.EndWarning());\n   PrintStack(stack);\n   DescribeHeapAddress(addr, 1);\n }\n \n void ReportFreeNotMalloced(uptr addr, StackTrace *stack) {\n   ScopedInErrorReport in_report;\n+  Decorator d;\n+  Printf(\"%s\", d.Warning());\n   Report(\"ERROR: AddressSanitizer: attempting free on address \"\n              \"which was not malloc()-ed: %p\\n\", addr);\n+  Printf(\"%s\", d.EndWarning());\n   PrintStack(stack);\n   DescribeHeapAddress(addr, 1);\n }\n \n+void ReportAllocTypeMismatch(uptr addr, StackTrace *stack,\n+                             AllocType alloc_type,\n+                             AllocType dealloc_type) {\n+  static const char *alloc_names[] =\n+    {\"INVALID\", \"malloc\", \"operator new\", \"operator new []\"};\n+  static const char *dealloc_names[] =\n+    {\"INVALID\", \"free\", \"operator delete\", \"operator delete []\"};\n+  CHECK_NE(alloc_type, dealloc_type);\n+  ScopedInErrorReport in_report;\n+  Decorator d;\n+  Printf(\"%s\", d.Warning());\n+  Report(\"ERROR: AddressSanitizer: alloc-dealloc-mismatch (%s vs %s) on %p\\n\",\n+        alloc_names[alloc_type], dealloc_names[dealloc_type], addr);\n+  Printf(\"%s\", d.EndWarning());\n+  PrintStack(stack);\n+  DescribeHeapAddress(addr, 1);\n+  Report(\"HINT: if you don't care about these warnings you may set \"\n+         \"ASAN_OPTIONS=alloc_dealloc_mismatch=0\\n\");\n+}\n+\n void ReportMallocUsableSizeNotOwned(uptr addr, StackTrace *stack) {\n   ScopedInErrorReport in_report;\n+  Decorator d;\n+  Printf(\"%s\", d.Warning());\n   Report(\"ERROR: AddressSanitizer: attempting to call \"\n              \"malloc_usable_size() for pointer which is \"\n              \"not owned: %p\\n\", addr);\n+  Printf(\"%s\", d.EndWarning());\n   PrintStack(stack);\n   DescribeHeapAddress(addr, 1);\n }\n \n void ReportAsanGetAllocatedSizeNotOwned(uptr addr, StackTrace *stack) {\n   ScopedInErrorReport in_report;\n+  Decorator d;\n+  Printf(\"%s\", d.Warning());\n   Report(\"ERROR: AddressSanitizer: attempting to call \"\n              \"__asan_get_allocated_size() for pointer which is \"\n              \"not owned: %p\\n\", addr);\n+  Printf(\"%s\", d.EndWarning());\n   PrintStack(stack);\n   DescribeHeapAddress(addr, 1);\n }\n@@ -368,9 +535,12 @@ void ReportStringFunctionMemoryRangesOverlap(\n     const char *function, const char *offset1, uptr length1,\n     const char *offset2, uptr length2, StackTrace *stack) {\n   ScopedInErrorReport in_report;\n+  Decorator d;\n+  Printf(\"%s\", d.Warning());\n   Report(\"ERROR: AddressSanitizer: %s-param-overlap: \"\n              \"memory ranges [%p,%p) and [%p, %p) overlap\\n\", \\\n              function, offset1, offset1 + length1, offset2, offset2 + length2);\n+  Printf(\"%s\", d.EndWarning());\n   PrintStack(stack);\n   DescribeAddress((uptr)offset1, length1);\n   DescribeAddress((uptr)offset2, length2);\n@@ -463,17 +633,23 @@ void __asan_report_error(uptr pc, uptr bp, uptr sp,\n         break;\n     }\n   }\n-\n+  Decorator d;\n+  Printf(\"%s\", d.Warning());\n   Report(\"ERROR: AddressSanitizer: %s on address \"\n              \"%p at pc 0x%zx bp 0x%zx sp 0x%zx\\n\",\n              bug_descr, (void*)addr, pc, bp, sp);\n+  Printf(\"%s\", d.EndWarning());\n \n   u32 curr_tid = asanThreadRegistry().GetCurrentTidOrInvalid();\n-  Printf(\"%s of size %zu at %p thread T%d\\n\",\n-             access_size ? (is_write ? \"WRITE\" : \"READ\") : \"ACCESS\",\n-             access_size, (void*)addr, curr_tid);\n-\n-  GET_STACK_TRACE_WITH_PC_AND_BP(kStackTraceMax, pc, bp);\n+  char tname[128];\n+  Printf(\"%s%s of size %zu at %p thread T%d%s%s\\n\",\n+         d.Access(),\n+         access_size ? (is_write ? \"WRITE\" : \"READ\") : \"ACCESS\",\n+         access_size, (void*)addr, curr_tid,\n+         ThreadNameWithParenthesis(curr_tid, tname, sizeof(tname)),\n+         d.EndAccess());\n+\n+  GET_STACK_TRACE_FATAL(pc, bp);\n   PrintStack(&stack);\n \n   DescribeAddress(addr, access_size);\n@@ -491,7 +667,13 @@ void NOINLINE __asan_set_error_report_callback(void (*callback)(const char*)) {\n   }\n }\n \n+void __asan_describe_address(uptr addr) {\n+  DescribeAddress(addr, 1);\n+}\n+\n+#if !SANITIZER_SUPPORTS_WEAK_HOOKS\n // Provide default implementation of __asan_on_error that does nothing\n // and may be overriden by user.\n SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE NOINLINE\n void __asan_on_error() {}\n+#endif"}, {"sha": "a7e0e5816b7eeed0e63a20d5e71b6e3822871e1a", "filename": "libsanitizer/asan/asan_report.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_report.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_report.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_report.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -10,6 +10,7 @@\n // ASan-private header for error reporting functions.\n //===----------------------------------------------------------------------===//\n \n+#include \"asan_allocator.h\"\n #include \"asan_internal.h\"\n #include \"asan_thread.h\"\n #include \"sanitizer/asan_interface.h\"\n@@ -32,6 +33,9 @@ void DescribeThread(AsanThreadSummary *summary);\n void NORETURN ReportSIGSEGV(uptr pc, uptr sp, uptr bp, uptr addr);\n void NORETURN ReportDoubleFree(uptr addr, StackTrace *stack);\n void NORETURN ReportFreeNotMalloced(uptr addr, StackTrace *stack);\n+void NORETURN ReportAllocTypeMismatch(uptr addr, StackTrace *stack,\n+                                      AllocType alloc_type,\n+                                      AllocType dealloc_type);\n void NORETURN ReportMallocUsableSizeNotOwned(uptr addr,\n                                              StackTrace *stack);\n void NORETURN ReportAsanGetAllocatedSizeNotOwned(uptr addr,"}, {"sha": "6480bf4cc3591d92377b2490b1b1cf45d9a67fcb", "filename": "libsanitizer/asan/asan_rtl.cc", "status": "modified", "additions": 31, "deletions": 19, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_rtl.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_rtl.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_rtl.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -52,7 +52,7 @@ static void AsanCheckFailed(const char *file, int line, const char *cond,\n              file, line, cond, (uptr)v1, (uptr)v2);\n   // FIXME: check for infinite recursion without a thread-local counter here.\n   PRINT_CURRENT_STACK();\n-  ShowStatsAndAbort();\n+  Die();\n }\n \n // -------------------------- Flags ------------------------- {{{1\n@@ -64,6 +64,10 @@ Flags *flags() {\n   return &asan_flags;\n }\n \n+static const char *MaybeCallAsanDefaultOptions() {\n+  return (&__asan_default_options) ? __asan_default_options() : \"\";\n+}\n+\n static void ParseFlagsFromString(Flags *f, const char *str) {\n   ParseFlag(str, &f->quarantine_size, \"quarantine_size\");\n   ParseFlag(str, &f->symbolize, \"symbolize\");\n@@ -98,21 +102,20 @@ static void ParseFlagsFromString(Flags *f, const char *str) {\n   ParseFlag(str, &f->allow_reexec, \"allow_reexec\");\n   ParseFlag(str, &f->print_full_thread_history, \"print_full_thread_history\");\n   ParseFlag(str, &f->log_path, \"log_path\");\n+  ParseFlag(str, &f->fast_unwind_on_fatal, \"fast_unwind_on_fatal\");\n+  ParseFlag(str, &f->fast_unwind_on_malloc, \"fast_unwind_on_malloc\");\n+  ParseFlag(str, &f->poison_heap, \"poison_heap\");\n+  ParseFlag(str, &f->alloc_dealloc_mismatch, \"alloc_dealloc_mismatch\");\n+  ParseFlag(str, &f->use_stack_depot, \"use_stack_depot\");\n }\n \n-extern \"C\" {\n-SANITIZER_WEAK_ATTRIBUTE\n-SANITIZER_INTERFACE_ATTRIBUTE\n-const char* __asan_default_options() { return \"\"; }\n-}  // extern \"C\"\n-\n void InitializeFlags(Flags *f, const char *env) {\n   internal_memset(f, 0, sizeof(*f));\n \n   f->quarantine_size = (ASAN_LOW_MEMORY) ? 1UL << 26 : 1UL << 28;\n   f->symbolize = false;\n   f->verbosity = 0;\n-  f->redzone = (ASAN_LOW_MEMORY) ? 64 : 128;\n+  f->redzone = ASAN_ALLOCATOR_VERSION == 2 ? 16 : (ASAN_LOW_MEMORY) ? 64 : 128;\n   f->debug = false;\n   f->report_globals = 1;\n   f->check_initialization_order = true;\n@@ -137,12 +140,17 @@ void InitializeFlags(Flags *f, const char *env) {\n   f->allow_reexec = true;\n   f->print_full_thread_history = true;\n   f->log_path = 0;\n+  f->fast_unwind_on_fatal = true;\n+  f->fast_unwind_on_malloc = true;\n+  f->poison_heap = true;\n+  f->alloc_dealloc_mismatch = true;\n+  f->use_stack_depot = true;  // Only affects allocator2.\n \n   // Override from user-specified string.\n-  ParseFlagsFromString(f, __asan_default_options());\n+  ParseFlagsFromString(f, MaybeCallAsanDefaultOptions());\n   if (flags()->verbosity) {\n     Report(\"Using the defaults from __asan_default_options: %s\\n\",\n-           __asan_default_options());\n+           MaybeCallAsanDefaultOptions());\n   }\n \n   // Override from command line.\n@@ -239,15 +247,12 @@ static NOINLINE void force_interface_symbols() {\n     case 27: __asan_set_error_exit_code(0); break;\n     case 28: __asan_stack_free(0, 0, 0); break;\n     case 29: __asan_stack_malloc(0, 0); break;\n-    case 30: __asan_on_error(); break;\n-    case 31: __asan_default_options(); break;\n-    case 32: __asan_before_dynamic_init(0, 0); break;\n-    case 33: __asan_after_dynamic_init(); break;\n-    case 34: __asan_malloc_hook(0, 0); break;\n-    case 35: __asan_free_hook(0); break;\n-    case 36: __asan_symbolize(0, 0, 0); break;\n-    case 37: __asan_poison_stack_memory(0, 0); break;\n-    case 38: __asan_unpoison_stack_memory(0, 0); break;\n+    case 30: __asan_before_dynamic_init(0, 0); break;\n+    case 31: __asan_after_dynamic_init(); break;\n+    case 32: __asan_poison_stack_memory(0, 0); break;\n+    case 33: __asan_unpoison_stack_memory(0, 0); break;\n+    case 34: __asan_region_is_poisoned(0, 0); break;\n+    case 35: __asan_describe_address(0); break;\n   }\n }\n \n@@ -261,6 +266,13 @@ static void asan_atexit() {\n // ---------------------- Interface ---------------- {{{1\n using namespace __asan;  // NOLINT\n \n+#if !SANITIZER_SUPPORTS_WEAK_HOOKS\n+extern \"C\" {\n+SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE\n+const char* __asan_default_options() { return \"\"; }\n+}  // extern \"C\"\n+#endif\n+\n int NOINLINE __asan_set_error_exit_code(int exit_code) {\n   int old = flags()->exitcode;\n   flags()->exitcode = exit_code;"}, {"sha": "9b6a28e8082ef7cf6885e7dd425b3205cb288df7", "filename": "libsanitizer/asan/asan_stack.cc", "status": "modified", "additions": 8, "deletions": 2, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_stack.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_stack.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_stack.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -15,9 +15,15 @@\n \n namespace __asan {\n \n+static bool MaybeCallAsanSymbolize(const void *pc, char *out_buffer,\n+                                   int out_size) {\n+  return (&__asan_symbolize) ? __asan_symbolize(pc, out_buffer, out_size)\n+                             : false;\n+}\n+\n void PrintStack(StackTrace *stack) {\n   stack->PrintStack(stack->trace, stack->size, flags()->symbolize,\n-                    flags()->strip_path_prefix, __asan_symbolize);\n+                    flags()->strip_path_prefix, MaybeCallAsanSymbolize);\n }\n \n }  // namespace __asan\n@@ -27,7 +33,7 @@ void PrintStack(StackTrace *stack) {\n // Provide default implementation of __asan_symbolize that does nothing\n // and may be overriden by user if he wants to use his own symbolization.\n // ASan on Windows has its own implementation of this.\n-#ifndef _WIN32\n+#if !defined(_WIN32) && !SANITIZER_SUPPORTS_WEAK_HOOKS\n SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE NOINLINE\n bool __asan_symbolize(const void *pc, char *out_buffer, int out_size) {\n   return false;"}, {"sha": "6a5ffc934cca84b22c8f07d860c467a15f1cac60", "filename": "libsanitizer/asan/asan_stack.h", "status": "modified", "additions": 22, "deletions": 10, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_stack.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_stack.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_stack.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -13,10 +13,11 @@\n #define ASAN_STACK_H\n \n #include \"sanitizer_common/sanitizer_stacktrace.h\"\n+#include \"asan_flags.h\"\n \n namespace __asan {\n \n-void GetStackTrace(StackTrace *stack, uptr max_s, uptr pc, uptr bp);\n+void GetStackTrace(StackTrace *stack, uptr max_s, uptr pc, uptr bp, bool fast);\n void PrintStack(StackTrace *stack);\n \n }  // namespace __asan\n@@ -25,27 +26,38 @@ void PrintStack(StackTrace *stack);\n // The pc will be in the position 0 of the resulting stack trace.\n // The bp may refer to the current frame or to the caller's frame.\n // fast_unwind is currently unused.\n-#define GET_STACK_TRACE_WITH_PC_AND_BP(max_s, pc, bp)               \\\n+#define GET_STACK_TRACE_WITH_PC_AND_BP(max_s, pc, bp, fast)     \\\n   StackTrace stack;                                             \\\n-  GetStackTrace(&stack, max_s, pc, bp)\n+  GetStackTrace(&stack, max_s, pc, bp, fast)\n \n // NOTE: A Rule of thumb is to retrieve stack trace in the interceptors\n // as early as possible (in functions exposed to the user), as we generally\n // don't want stack trace to contain functions from ASan internals.\n \n-#define GET_STACK_TRACE_HERE(max_size)                        \\\n+#define GET_STACK_TRACE(max_size, fast)                       \\\n   GET_STACK_TRACE_WITH_PC_AND_BP(max_size,                    \\\n-      StackTrace::GetCurrentPc(), GET_CURRENT_FRAME())\n+      StackTrace::GetCurrentPc(), GET_CURRENT_FRAME(), fast)\n \n-#define GET_STACK_TRACE_HERE_FOR_MALLOC                             \\\n-  GET_STACK_TRACE_HERE(flags()->malloc_context_size)\n+#define GET_STACK_TRACE_FATAL(pc, bp)                                 \\\n+  GET_STACK_TRACE_WITH_PC_AND_BP(kStackTraceMax, pc, bp,              \\\n+                                 flags()->fast_unwind_on_fatal)\n \n-#define GET_STACK_TRACE_HERE_FOR_FREE(ptr)                          \\\n-  GET_STACK_TRACE_HERE(flags()->malloc_context_size)\n+#define GET_STACK_TRACE_FATAL_HERE                           \\\n+  GET_STACK_TRACE(kStackTraceMax, flags()->fast_unwind_on_fatal)\n+\n+#define GET_STACK_TRACE_THREAD                              \\\n+  GET_STACK_TRACE(kStackTraceMax, true)\n+\n+#define GET_STACK_TRACE_MALLOC                             \\\n+  GET_STACK_TRACE(flags()->malloc_context_size,            \\\n+                  flags()->fast_unwind_on_malloc)\n+\n+#define GET_STACK_TRACE_FREE GET_STACK_TRACE_MALLOC\n \n #define PRINT_CURRENT_STACK()                    \\\n   {                                              \\\n-    GET_STACK_TRACE_HERE(kStackTraceMax);        \\\n+    GET_STACK_TRACE(kStackTraceMax,              \\\n+      flags()->fast_unwind_on_fatal);            \\\n     PrintStack(&stack);                          \\\n   }\n "}, {"sha": "94dd741d3259d4f24f7759253f56b4862b4ba46d", "filename": "libsanitizer/asan/asan_stats.cc", "status": "modified", "additions": 8, "deletions": 2, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_stats.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_stats.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_stats.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -15,6 +15,7 @@\n #include \"asan_stats.h\"\n #include \"asan_thread_registry.h\"\n #include \"sanitizer/asan_interface.h\"\n+#include \"sanitizer_common/sanitizer_stackdepot.h\"\n \n namespace __asan {\n \n@@ -40,8 +41,9 @@ void AsanStats::Print() {\n   Printf(\"Stats: %zuM freed by %zu calls\\n\", freed>>20, frees);\n   Printf(\"Stats: %zuM really freed by %zu calls\\n\",\n              really_freed>>20, real_frees);\n-  Printf(\"Stats: %zuM (%zu full pages) mmaped in %zu calls\\n\",\n-             mmaped>>20, mmaped / GetPageSizeCached(), mmaps);\n+  Printf(\"Stats: %zuM (%zuM-%zuM) mmaped; %zu maps, %zu unmaps\\n\",\n+             (mmaped-munmaped)>>20, mmaped>>20, munmaped>>20,\n+             mmaps, munmaps);\n \n   PrintMallocStatsArray(\"  mmaps   by size class: \", mmaped_by_size);\n   PrintMallocStatsArray(\"  mallocs by size class: \", malloced_by_size);\n@@ -59,6 +61,10 @@ static void PrintAccumulatedStats() {\n   // Use lock to keep reports from mixing up.\n   ScopedLock lock(&print_lock);\n   stats.Print();\n+  StackDepotStats *stack_depot_stats = StackDepotGetStats();\n+  Printf(\"Stats: StackDepot: %zd ids; %zdM mapped\\n\",\n+         stack_depot_stats->n_uniq_ids, stack_depot_stats->mapped >> 20);\n+  PrintInternalAllocatorStats();\n }\n \n }  // namespace __asan"}, {"sha": "fd27451aef25699f495d824ebb26a69ec9f7b5da", "filename": "libsanitizer/asan/asan_stats.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_stats.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_stats.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_stats.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -35,6 +35,8 @@ struct AsanStats {\n   uptr realloced;\n   uptr mmaps;\n   uptr mmaped;\n+  uptr munmaps;\n+  uptr munmaped;\n   uptr mmaped_by_size[kNumberOfSizeClasses];\n   uptr malloced_by_size[kNumberOfSizeClasses];\n   uptr freed_by_size[kNumberOfSizeClasses];"}, {"sha": "f385ec35fcda30421b39fbbb859d0b0923ae1794", "filename": "libsanitizer/asan/asan_thread.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_thread.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_thread.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_thread.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -37,6 +37,7 @@ class AsanThreadSummary {\n       internal_memcpy(&stack_, stack, sizeof(*stack));\n     }\n     thread_ = 0;\n+    name_[0] = 0;\n   }\n   u32 tid() { return tid_; }\n   void set_tid(u32 tid) { tid_ = tid; }\n@@ -47,15 +48,23 @@ class AsanThreadSummary {\n   AsanThread *thread() { return thread_; }\n   void set_thread(AsanThread *thread) { thread_ = thread; }\n   static void TSDDtor(void *tsd);\n+  void set_name(const char *name) {\n+    internal_strncpy(name_, name, sizeof(name_) - 1);\n+  }\n+  const char *name() { return name_; }\n \n  private:\n   u32 tid_;\n   u32 parent_tid_;\n   bool announced_;\n   StackTrace stack_;\n   AsanThread *thread_;\n+  char name_[128];\n };\n \n+// AsanThreadSummary objects are never freed, so we need many of them.\n+COMPILER_CHECK(sizeof(AsanThreadSummary) <= 4094);\n+\n // AsanThread are stored in TSD and destroyed when the thread dies.\n class AsanThread {\n  public:"}, {"sha": "8db6a57cdff7cd0b177717323155b97cbe39d92f", "filename": "libsanitizer/asan/asan_thread_registry.cc", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_thread_registry.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_thread_registry.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_thread_registry.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -121,13 +121,14 @@ uptr AsanThreadRegistry::GetCurrentAllocatedBytes() {\n uptr AsanThreadRegistry::GetHeapSize() {\n   ScopedLock lock(&mu_);\n   UpdateAccumulatedStatsUnlocked();\n-  return accumulated_stats_.mmaped;\n+  return accumulated_stats_.mmaped - accumulated_stats_.munmaped;\n }\n \n uptr AsanThreadRegistry::GetFreeBytes() {\n   ScopedLock lock(&mu_);\n   UpdateAccumulatedStatsUnlocked();\n   uptr total_free = accumulated_stats_.mmaped\n+                  - accumulated_stats_.munmaped\n                   + accumulated_stats_.really_freed\n                   + accumulated_stats_.really_freed_redzones;\n   uptr total_used = accumulated_stats_.malloced"}, {"sha": "02a2e08868ed0971e4117d9f43b4ffed5216ca98", "filename": "libsanitizer/asan/asan_win.cc", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_win.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fasan%2Fasan_win.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_win.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -30,7 +30,8 @@ static AsanLock dbghelp_lock(LINKER_INITIALIZED);\n static bool dbghelp_initialized = false;\n #pragma comment(lib, \"dbghelp.lib\")\n \n-void GetStackTrace(StackTrace *stack, uptr max_s, uptr pc, uptr bp) {\n+void GetStackTrace(StackTrace *stack, uptr max_s, uptr pc, uptr bp, bool fast) {\n+  (void)fast;\n   stack->max_size = max_s;\n   void *tmp[kStackTraceMax];\n "}, {"sha": "47f780ceaa39ba2d8005f3311e7d57d9225535ae", "filename": "libsanitizer/include/sanitizer/asan_interface.h", "status": "modified", "additions": 18, "deletions": 9, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Finclude%2Fsanitizer%2Fasan_interface.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Finclude%2Fsanitizer%2Fasan_interface.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finclude%2Fsanitizer%2Fasan_interface.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -115,6 +115,15 @@ extern \"C\" {\n   bool __asan_address_is_poisoned(void const volatile *addr)\n       SANITIZER_INTERFACE_ATTRIBUTE;\n \n+  // If at least on byte in [beg, beg+size) is poisoned, return the address\n+  // of the first such byte. Otherwise return 0.\n+  uptr __asan_region_is_poisoned(uptr beg, uptr size)\n+      SANITIZER_INTERFACE_ATTRIBUTE;\n+\n+  // Print the description of addr (useful when debugging in gdb).\n+  void __asan_describe_address(uptr addr)\n+      SANITIZER_INTERFACE_ATTRIBUTE;\n+\n   // This is an internal function that is called to report an error.\n   // However it is still a part of the interface because users may want to\n   // set a breakpoint on this function in a debugger.\n@@ -138,15 +147,16 @@ extern \"C\" {\n   // User may provide function that would be called right when ASan detects\n   // an error. This can be used to notice cases when ASan detects an error, but\n   // the program crashes before ASan report is printed.\n-  void __asan_on_error()\n+  /* OPTIONAL */ void __asan_on_error()\n       SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE;\n \n   // User may provide its own implementation for symbolization function.\n   // It should print the description of instruction at address \"pc\" to\n   // \"out_buffer\". Description should be at most \"out_size\" bytes long.\n   // User-specified function should return true if symbolization was\n   // successful.\n-  bool __asan_symbolize(const void *pc, char *out_buffer, int out_size)\n+  /* OPTIONAL */ bool __asan_symbolize(const void *pc, char *out_buffer,\n+                                       int out_size)\n       SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE;\n \n   // Returns the estimated number of bytes that will be reserved by allocator\n@@ -186,20 +196,19 @@ extern \"C\" {\n   void __asan_print_accumulated_stats()\n       SANITIZER_INTERFACE_ATTRIBUTE;\n \n-  // This function may be overriden by user to provide a string containing\n-  // ASan runtime options. See asan_flags.h for details.\n-  const char* __asan_default_options()\n+  // This function may be optionally provided by user and should return\n+  // a string containing ASan runtime options. See asan_flags.h for details.\n+  /* OPTIONAL */ const char* __asan_default_options()\n       SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE;\n \n-  // Malloc hooks that may be overriden by user.\n+  // Malloc hooks that may be optionally provided by user.\n   // __asan_malloc_hook(ptr, size) is called immediately after\n   //   allocation of \"size\" bytes, which returned \"ptr\".\n   // __asan_free_hook(ptr) is called immediately before\n   //   deallocation of \"ptr\".\n-  // If user doesn't provide implementations of these hooks, they are no-op.\n-  void __asan_malloc_hook(void *ptr, uptr size)\n+  /* OPTIONAL */ void __asan_malloc_hook(void *ptr, uptr size)\n       SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE;\n-  void __asan_free_hook(void *ptr)\n+  /* OPTIONAL */ void __asan_free_hook(void *ptr)\n       SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE;\n }  // extern \"C\"\n "}, {"sha": "9fba976a041154b2b9f49343005ba35f89e2c21f", "filename": "libsanitizer/include/sanitizer/common_interface_defs.h", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Finclude%2Fsanitizer%2Fcommon_interface_defs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Finclude%2Fsanitizer%2Fcommon_interface_defs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finclude%2Fsanitizer%2Fcommon_interface_defs.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -28,6 +28,12 @@\n # define SANITIZER_WEAK_ATTRIBUTE  __attribute__((weak))\n #endif\n \n+#ifdef __linux__\n+# define SANITIZER_SUPPORTS_WEAK_HOOKS 1\n+#else\n+# define SANITIZER_SUPPORTS_WEAK_HOOKS 0\n+#endif\n+\n // __has_feature\n #if !defined(__has_feature)\n # define __has_feature(x) 0\n@@ -73,6 +79,12 @@ extern \"C\" {\n   // stderr.\n   void __sanitizer_set_report_fd(int fd)\n       SANITIZER_INTERFACE_ATTRIBUTE;\n+\n+  // Notify the tools that the sandbox is going to be turned on. The reserved\n+  // parameter will be used in the future to hold a structure with functions\n+  // that the tools may call to bypass the sandbox.\n+  void __sanitizer_sandbox_on_notify(void *reserved)\n+      SANITIZER_WEAK_ATTRIBUTE SANITIZER_INTERFACE_ATTRIBUTE;\n }  // extern \"C\"\n \n #endif  // SANITIZER_COMMON_INTERFACE_DEFS_H"}, {"sha": "66bdd8830f3a66be70a892b2d1f5329eee7a2c3c", "filename": "libsanitizer/interception/interception.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Finterception%2Finterception.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Finterception%2Finterception.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finterception%2Finterception.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -17,6 +17,15 @@\n # error \"Interception doesn't work on this operating system.\"\n #endif\n \n+#include \"sanitizer/common_interface_defs.h\"\n+\n+// These typedefs should be used only in the interceptor definitions to replace\n+// the standard system types (e.g. SSIZE_T instead of ssize_t)\n+typedef __sanitizer::uptr SIZE_T;\n+typedef __sanitizer::sptr SSIZE_T;\n+typedef __sanitizer::u64  OFF_T;\n+typedef __sanitizer::u64  OFF64_T;\n+\n // How to use this library:\n //      1) Include this header to define your own interceptors\n //         (see details below)."}, {"sha": "cc23dc2425c6538acdb03f6f88e48b62d604bac9", "filename": "libsanitizer/sanitizer_common/Makefile.am", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2FMakefile.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2FMakefile.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2FMakefile.am?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -22,6 +22,7 @@ sanitizer_common_files = \\\n         sanitizer_stackdepot.cc \\\n         sanitizer_stacktrace.cc \\\n         sanitizer_symbolizer.cc \\\n+\tsanitizer_symbolizer_itanium.cc \\\n         sanitizer_symbolizer_linux.cc \\\n         sanitizer_symbolizer_mac.cc \\\n         sanitizer_symbolizer_win.cc \\"}, {"sha": "77b1f1e215dc0324c0a85cff30cb1bc4a0b1e250", "filename": "libsanitizer/sanitizer_common/Makefile.in", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2FMakefile.in?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -59,9 +59,9 @@ am__objects_1 = sanitizer_allocator.lo sanitizer_common.lo \\\n \tsanitizer_flags.lo sanitizer_libc.lo sanitizer_linux.lo \\\n \tsanitizer_mac.lo sanitizer_posix.lo sanitizer_printf.lo \\\n \tsanitizer_stackdepot.lo sanitizer_stacktrace.lo \\\n-\tsanitizer_symbolizer.lo sanitizer_symbolizer_linux.lo \\\n-\tsanitizer_symbolizer_mac.lo sanitizer_symbolizer_win.lo \\\n-\tsanitizer_win.lo\n+\tsanitizer_symbolizer.lo sanitizer_symbolizer_itanium.lo \\\n+\tsanitizer_symbolizer_linux.lo sanitizer_symbolizer_mac.lo \\\n+\tsanitizer_symbolizer_win.lo sanitizer_win.lo\n am_libsanitizer_common_la_OBJECTS = $(am__objects_1)\n libsanitizer_common_la_OBJECTS = $(am_libsanitizer_common_la_OBJECTS)\n DEFAULT_INCLUDES = -I.@am__isrc@\n@@ -236,6 +236,7 @@ sanitizer_common_files = \\\n         sanitizer_stackdepot.cc \\\n         sanitizer_stacktrace.cc \\\n         sanitizer_symbolizer.cc \\\n+\tsanitizer_symbolizer_itanium.cc \\\n         sanitizer_symbolizer_linux.cc \\\n         sanitizer_symbolizer_mac.cc \\\n         sanitizer_symbolizer_win.cc \\\n@@ -345,6 +346,7 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sanitizer_stackdepot.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sanitizer_stacktrace.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sanitizer_symbolizer.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sanitizer_symbolizer_itanium.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sanitizer_symbolizer_linux.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sanitizer_symbolizer_mac.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sanitizer_symbolizer_win.Plo@am__quote@"}, {"sha": "d0fc315b97e1e18c5b823000db22569bd549fa98", "filename": "libsanitizer/sanitizer_common/sanitizer_allocator.h", "status": "modified", "additions": 528, "deletions": 128, "changes": 656, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -20,88 +20,186 @@\n \n namespace __sanitizer {\n \n-// Maps size class id to size and back.\n-template <uptr l0, uptr l1, uptr l2, uptr l3, uptr l4, uptr l5,\n-          uptr s0, uptr s1, uptr s2, uptr s3, uptr s4,\n-          uptr c0, uptr c1, uptr c2, uptr c3, uptr c4>\n-class SplineSizeClassMap {\n- private:\n-  // Here we use a spline composed of 5 polynomials of oder 1.\n-  // The first size class is l0, then the classes go with step s0\n-  // untill they reach l1, after which they go with step s1 and so on.\n-  // Steps should be powers of two for cheap division.\n-  // The size of the last size class should be a power of two.\n-  // There should be at most 256 size classes.\n-  static const uptr u0 = 0  + (l1 - l0) / s0;\n-  static const uptr u1 = u0 + (l2 - l1) / s1;\n-  static const uptr u2 = u1 + (l3 - l2) / s2;\n-  static const uptr u3 = u2 + (l4 - l3) / s3;\n-  static const uptr u4 = u3 + (l5 - l4) / s4;\n+// SizeClassMap maps allocation sizes into size classes and back.\n+// Class 0 corresponds to size 0.\n+// Classes 1 - 16 correspond to sizes 8 - 128 (size = class_id * 8).\n+// Next 8 classes: 128 + i * 16 (i = 1 to 8).\n+// Next 8 classes: 256 + i * 32 (i = 1 to 8).\n+// ...\n+// Next 8 classes: 2^k + i * 2^(k-3) (i = 1 to 8).\n+// Last class corresponds to kMaxSize = 1 << kMaxSizeLog.\n+//\n+// This structure of the size class map gives us:\n+//   - Efficient table-free class-to-size and size-to-class functions.\n+//   - Difference between two consequent size classes is betweed 12% and 6%\n+//\n+// This class also gives a hint to a thread-caching allocator about the amount\n+// of chunks that need to be cached per-thread:\n+//  - kMaxNumCached is the maximal number of chunks per size class.\n+//  - (1 << kMaxBytesCachedLog) is the maximal number of bytes per size class.\n+//\n+// Part of output of SizeClassMap::Print():\n+//    c00 => s: 0 diff: +0 00% l 0 cached: 0 0; id 0\n+//    c01 => s: 8 diff: +8 00% l 3 cached: 256 2048; id 1\n+//    c02 => s: 16 diff: +8 100% l 4 cached: 256 4096; id 2\n+//    ...\n+//    c07 => s: 56 diff: +8 16% l 5 cached: 256 14336; id 7\n+//\n+//    c08 => s: 64 diff: +8 14% l 6 cached: 256 16384; id 8\n+//    ...\n+//    c15 => s: 120 diff: +8 07% l 6 cached: 256 30720; id 15\n+//\n+//    c16 => s: 128 diff: +8 06% l 7 cached: 256 32768; id 16\n+//    c17 => s: 144 diff: +16 12% l 7 cached: 227 32688; id 17\n+//    ...\n+//    c23 => s: 240 diff: +16 07% l 7 cached: 136 32640; id 23\n+//\n+//    c24 => s: 256 diff: +16 06% l 8 cached: 128 32768; id 24\n+//    c25 => s: 288 diff: +32 12% l 8 cached: 113 32544; id 25\n+//    ...\n+//    c31 => s: 480 diff: +32 07% l 8 cached: 68 32640; id 31\n+//\n+//    c32 => s: 512 diff: +32 06% l 9 cached: 64 32768; id 32\n \n- public:\n-  // The number of size classes should be a power of two for fast division.\n-  static const uptr kNumClasses = u4 + 1;\n-  static const uptr kMaxSize = l5;\n-  static const uptr kMinSize = l0;\n \n-  COMPILER_CHECK(kNumClasses <= 256);\n-  COMPILER_CHECK((kNumClasses & (kNumClasses - 1)) == 0);\n-  COMPILER_CHECK((kMaxSize & (kMaxSize - 1)) == 0);\n+template <uptr kMaxSizeLog, uptr kMaxNumCached, uptr kMaxBytesCachedLog>\n+class SizeClassMap {\n+  static const uptr kMinSizeLog = 3;\n+  static const uptr kMidSizeLog = kMinSizeLog + 4;\n+  static const uptr kMinSize = 1 << kMinSizeLog;\n+  static const uptr kMidSize = 1 << kMidSizeLog;\n+  static const uptr kMidClass = kMidSize / kMinSize;\n+  static const uptr S = 3;\n+  static const uptr M = (1 << S) - 1;\n+\n+ public:\n+  static const uptr kMaxSize = 1 << kMaxSizeLog;\n+  static const uptr kNumClasses =\n+      kMidClass + ((kMaxSizeLog - kMidSizeLog) << S) + 1;\n+  COMPILER_CHECK(kNumClasses >= 32 && kNumClasses <= 256);\n+  static const uptr kNumClassesRounded =\n+      kNumClasses == 32  ? 32 :\n+      kNumClasses <= 64  ? 64 :\n+      kNumClasses <= 128 ? 128 : 256;\n \n   static uptr Size(uptr class_id) {\n-    if (class_id <= u0) return l0 + s0 * (class_id - 0);\n-    if (class_id <= u1) return l1 + s1 * (class_id - u0);\n-    if (class_id <= u2) return l2 + s2 * (class_id - u1);\n-    if (class_id <= u3) return l3 + s3 * (class_id - u2);\n-    if (class_id <= u4) return l4 + s4 * (class_id - u3);\n-    return 0;\n+    if (class_id <= kMidClass)\n+      return kMinSize * class_id;\n+    class_id -= kMidClass;\n+    uptr t = kMidSize << (class_id >> S);\n+    return t + (t >> S) * (class_id & M);\n   }\n+\n   static uptr ClassID(uptr size) {\n-    if (size <= l1) return 0  + (size - l0 + s0 - 1) / s0;\n-    if (size <= l2) return u0 + (size - l1 + s1 - 1) / s1;\n-    if (size <= l3) return u1 + (size - l2 + s2 - 1) / s2;\n-    if (size <= l4) return u2 + (size - l3 + s3 - 1) / s3;\n-    if (size <= l5) return u3 + (size - l4 + s4 - 1) / s4;\n-    return 0;\n+    if (size <= kMidSize)\n+      return (size + kMinSize - 1) >> kMinSizeLog;\n+    if (size > kMaxSize) return 0;\n+    uptr l = SANITIZER_WORDSIZE - 1 - __builtin_clzl(size);\n+    uptr hbits = (size >> (l - S)) & M;\n+    uptr lbits = size & ((1 << (l - S)) - 1);\n+    uptr l1 = l - kMidSizeLog;\n+    return kMidClass + (l1 << S) + hbits + (lbits > 0);\n   }\n \n   static uptr MaxCached(uptr class_id) {\n-    if (class_id <= u0) return c0;\n-    if (class_id <= u1) return c1;\n-    if (class_id <= u2) return c2;\n-    if (class_id <= u3) return c3;\n-    if (class_id <= u4) return c4;\n-    return 0;\n+    if (class_id == 0) return 0;\n+    uptr n = (1UL << kMaxBytesCachedLog) / Size(class_id);\n+    return Max(1UL, Min(kMaxNumCached, n));\n   }\n-};\n \n-class DefaultSizeClassMap: public SplineSizeClassMap<\n-  /* l: */1 << 4, 1 << 9,  1 << 12, 1 << 15, 1 << 18, 1 << 21,\n-  /* s: */1 << 4, 1 << 6,  1 << 9,  1 << 12, 1 << 15,\n-  /* c: */256,    64,      16,      4,       1> {\n- private:\n-  COMPILER_CHECK(kNumClasses == 256);\n+  static void Print() {\n+    uptr prev_s = 0;\n+    uptr total_cached = 0;\n+    for (uptr i = 0; i < kNumClasses; i++) {\n+      uptr s = Size(i);\n+      if (s >= kMidSize / 2 && (s & (s - 1)) == 0)\n+        Printf(\"\\n\");\n+      uptr d = s - prev_s;\n+      uptr p = prev_s ? (d * 100 / prev_s) : 0;\n+      uptr l = SANITIZER_WORDSIZE - 1 - __builtin_clzl(s);\n+      uptr cached = MaxCached(i) * s;\n+      Printf(\"c%02zd => s: %zd diff: +%zd %02zd%% l %zd \"\n+             \"cached: %zd %zd; id %zd\\n\",\n+             i, Size(i), d, p, l, MaxCached(i), cached, ClassID(s));\n+      total_cached += cached;\n+      prev_s = s;\n+    }\n+    Printf(\"Total cached: %zd\\n\", total_cached);\n+  }\n+\n+  static void Validate() {\n+    for (uptr c = 1; c < kNumClasses; c++) {\n+      // Printf(\"Validate: c%zd\\n\", c);\n+      uptr s = Size(c);\n+      CHECK_EQ(ClassID(s), c);\n+      if (c != kNumClasses - 1)\n+        CHECK_EQ(ClassID(s + 1), c + 1);\n+      CHECK_EQ(ClassID(s - 1), c);\n+      if (c)\n+        CHECK_GT(Size(c), Size(c-1));\n+    }\n+    CHECK_EQ(ClassID(kMaxSize + 1), 0);\n+\n+    for (uptr s = 1; s <= kMaxSize; s++) {\n+      uptr c = ClassID(s);\n+      // Printf(\"s%zd => c%zd\\n\", s, c);\n+      CHECK_LT(c, kNumClasses);\n+      CHECK_GE(Size(c), s);\n+      if (c > 0)\n+        CHECK_LT(Size(c-1), s);\n+    }\n+  }\n };\n \n-class CompactSizeClassMap: public SplineSizeClassMap<\n-  /* l: */1 << 3, 1 << 4,  1 << 7, 1 << 8, 1 << 12, 1 << 15,\n-  /* s: */1 << 3, 1 << 4,  1 << 7, 1 << 8, 1 << 12,\n-  /* c: */256,    64,      16,      4,       1> {\n- private:\n-  COMPILER_CHECK(kNumClasses <= 32);\n-};\n+typedef SizeClassMap<15, 256, 16> DefaultSizeClassMap;\n+typedef SizeClassMap<15, 64, 14> CompactSizeClassMap;\n+\n \n struct AllocatorListNode {\n   AllocatorListNode *next;\n };\n \n typedef IntrusiveList<AllocatorListNode> AllocatorFreeList;\n \n+// Move at most max_count chunks from allocate_from to allocate_to.\n+// This function is better be a method of AllocatorFreeList, but we can't\n+// inherit it from IntrusiveList as the ancient gcc complains about non-PODness.\n+static inline uptr BulkMove(uptr max_count,\n+                            AllocatorFreeList *allocate_from,\n+                            AllocatorFreeList *allocate_to) {\n+  CHECK(!allocate_from->empty());\n+  CHECK(allocate_to->empty());\n+  uptr res = 0;\n+  if (allocate_from->size() <= max_count) {\n+    res = allocate_from->size();\n+    allocate_to->append_front(allocate_from);\n+    CHECK(allocate_from->empty());\n+  } else {\n+    for (uptr i = 0; i < max_count; i++) {\n+      AllocatorListNode *node = allocate_from->front();\n+      allocate_from->pop_front();\n+      allocate_to->push_front(node);\n+    }\n+    res = max_count;\n+    CHECK(!allocate_from->empty());\n+  }\n+  CHECK(!allocate_to->empty());\n+  return res;\n+}\n+\n+// Allocators call these callbacks on mmap/munmap.\n+struct NoOpMapUnmapCallback {\n+  void OnMap(uptr p, uptr size) const { }\n+  void OnUnmap(uptr p, uptr size) const { }\n+};\n+\n // SizeClassAllocator64 -- allocator for 64-bit address space.\n //\n // Space: a portion of address space of kSpaceSize bytes starting at\n // a fixed address (kSpaceBeg). Both constants are powers of two and\n // kSpaceBeg is kSpaceSize-aligned.\n+// At the beginning the entire space is mprotect-ed, then small parts of it\n+// are mapped on demand.\n //\n // Region: a part of Space dedicated to a single size class.\n // There are kNumClasses Regions of equal size.\n@@ -112,22 +210,35 @@ typedef IntrusiveList<AllocatorListNode> AllocatorFreeList;\n // A Region looks like this:\n // UserChunk1 ... UserChunkN <gap> MetaChunkN ... MetaChunk1\n template <const uptr kSpaceBeg, const uptr kSpaceSize,\n-          const uptr kMetadataSize, class SizeClassMap>\n+          const uptr kMetadataSize, class SizeClassMap,\n+          class MapUnmapCallback = NoOpMapUnmapCallback>\n class SizeClassAllocator64 {\n  public:\n   void Init() {\n-    CHECK_EQ(AllocBeg(), reinterpret_cast<uptr>(MmapFixedNoReserve(\n-             AllocBeg(), AllocSize())));\n+    CHECK_EQ(kSpaceBeg,\n+             reinterpret_cast<uptr>(Mprotect(kSpaceBeg, kSpaceSize)));\n+    MapWithCallback(kSpaceEnd, AdditionalSize());\n   }\n \n-  bool CanAllocate(uptr size, uptr alignment) {\n+  void MapWithCallback(uptr beg, uptr size) {\n+    CHECK_EQ(beg, reinterpret_cast<uptr>(MmapFixedOrDie(beg, size)));\n+    MapUnmapCallback().OnMap(beg, size);\n+  }\n+\n+  void UnmapWithCallback(uptr beg, uptr size) {\n+    MapUnmapCallback().OnUnmap(beg, size);\n+    UnmapOrDie(reinterpret_cast<void *>(beg), size);\n+  }\n+\n+  static bool CanAllocate(uptr size, uptr alignment) {\n     return size <= SizeClassMap::kMaxSize &&\n       alignment <= SizeClassMap::kMaxSize;\n   }\n \n   void *Allocate(uptr size, uptr alignment) {\n+    if (size < alignment) size = alignment;\n     CHECK(CanAllocate(size, alignment));\n-    return AllocateBySizeClass(SizeClassMap::ClassID(size));\n+    return AllocateBySizeClass(ClassID(size));\n   }\n \n   void Deallocate(void *p) {\n@@ -143,25 +254,16 @@ class SizeClassAllocator64 {\n     if (region->free_list.empty()) {\n       PopulateFreeList(class_id, region);\n     }\n-    CHECK(!region->free_list.empty());\n-    uptr count = SizeClassMap::MaxCached(class_id);\n-    if (region->free_list.size() <= count) {\n-      free_list->append_front(&region->free_list);\n-    } else {\n-      for (uptr i = 0; i < count; i++) {\n-        AllocatorListNode *node = region->free_list.front();\n-        region->free_list.pop_front();\n-        free_list->push_front(node);\n-      }\n-    }\n-    CHECK(!free_list->empty());\n+    region->n_allocated += BulkMove(SizeClassMap::MaxCached(class_id),\n+                                    &region->free_list, free_list);\n   }\n \n   // Swallow the entire free_list for the given class_id.\n   void BulkDeallocate(uptr class_id, AllocatorFreeList *free_list) {\n     CHECK_LT(class_id, kNumClasses);\n     RegionInfo *region = GetRegionInfo(class_id);\n     SpinMutexLock l(&region->mutex);\n+    region->n_freed += free_list->size();\n     region->free_list.append_front(free_list);\n   }\n \n@@ -170,16 +272,20 @@ class SizeClassAllocator64 {\n   }\n \n   static uptr GetSizeClass(void *p) {\n-    return (reinterpret_cast<uptr>(p) / kRegionSize) % kNumClasses;\n+    return (reinterpret_cast<uptr>(p) / kRegionSize) % kNumClassesRounded;\n   }\n \n-  static void *GetBlockBegin(void *p) {\n+  void *GetBlockBegin(void *p) {\n     uptr class_id = GetSizeClass(p);\n     uptr size = SizeClassMap::Size(class_id);\n     uptr chunk_idx = GetChunkIdx((uptr)p, size);\n     uptr reg_beg = (uptr)p & ~(kRegionSize - 1);\n-    uptr begin = reg_beg + chunk_idx * size;\n-    return (void*)begin;\n+    uptr beg = chunk_idx * size;\n+    uptr next_beg = beg + size;\n+    RegionInfo *region = GetRegionInfo(class_id);\n+    if (region->mapped_user >= next_beg)\n+      return reinterpret_cast<void*>(reg_beg + beg);\n+    return 0;\n   }\n \n   static uptr GetActuallyAllocatedSize(void *p) {\n@@ -206,39 +312,66 @@ class SizeClassAllocator64 {\n \n   // Test-only.\n   void TestOnlyUnmap() {\n-    UnmapOrDie(reinterpret_cast<void*>(AllocBeg()), AllocSize());\n+    UnmapWithCallback(kSpaceBeg, kSpaceSize + AdditionalSize());\n+  }\n+\n+  void PrintStats() {\n+    uptr total_mapped = 0;\n+    uptr n_allocated = 0;\n+    uptr n_freed = 0;\n+    for (uptr class_id = 1; class_id < kNumClasses; class_id++) {\n+      RegionInfo *region = GetRegionInfo(class_id);\n+      total_mapped += region->mapped_user;\n+      n_allocated += region->n_allocated;\n+      n_freed += region->n_freed;\n+    }\n+    Printf(\"Stats: SizeClassAllocator64: %zdM mapped in %zd allocations; \"\n+           \"remains %zd\\n\",\n+           total_mapped >> 20, n_allocated, n_allocated - n_freed);\n+    for (uptr class_id = 1; class_id < kNumClasses; class_id++) {\n+      RegionInfo *region = GetRegionInfo(class_id);\n+      if (region->mapped_user == 0) continue;\n+      Printf(\"  %02zd (%zd): total: %zd K allocs: %zd remains: %zd\\n\",\n+             class_id,\n+             SizeClassMap::Size(class_id),\n+             region->mapped_user >> 10,\n+             region->n_allocated,\n+             region->n_allocated - region->n_freed);\n+    }\n   }\n \n-  static uptr AllocBeg()  { return kSpaceBeg; }\n-  static uptr AllocSize() { return kSpaceSize + AdditionalSize(); }\n-\n   typedef SizeClassMap SizeClassMapT;\n-  static const uptr kNumClasses = SizeClassMap::kNumClasses;  // 2^k <= 256\n+  static const uptr kNumClasses = SizeClassMap::kNumClasses;\n+  static const uptr kNumClassesRounded = SizeClassMap::kNumClassesRounded;\n \n  private:\n-  static const uptr kRegionSize = kSpaceSize / kNumClasses;\n+  static const uptr kRegionSize = kSpaceSize / kNumClassesRounded;\n+  static const uptr kSpaceEnd = kSpaceBeg + kSpaceSize;\n   COMPILER_CHECK(kSpaceBeg % kSpaceSize == 0);\n-  COMPILER_CHECK(kNumClasses <= SizeClassMap::kNumClasses);\n   // kRegionSize must be >= 2^32.\n   COMPILER_CHECK((kRegionSize) >= (1ULL << (SANITIZER_WORDSIZE / 2)));\n   // Populate the free list with at most this number of bytes at once\n   // or with one element if its size is greater.\n-  static const uptr kPopulateSize = 1 << 18;\n+  static const uptr kPopulateSize = 1 << 15;\n+  // Call mmap for user memory with at least this size.\n+  static const uptr kUserMapSize = 1 << 15;\n+  // Call mmap for metadata memory with at least this size.\n+  static const uptr kMetaMapSize = 1 << 16;\n \n   struct RegionInfo {\n     SpinMutex mutex;\n     AllocatorFreeList free_list;\n     uptr allocated_user;  // Bytes allocated for user memory.\n     uptr allocated_meta;  // Bytes allocated for metadata.\n-    char padding[kCacheLineSize - 3 * sizeof(uptr) - sizeof(AllocatorFreeList)];\n+    uptr mapped_user;  // Bytes mapped for user memory.\n+    uptr mapped_meta;  // Bytes mapped for metadata.\n+    uptr n_allocated, n_freed;  // Just stats.\n   };\n-  COMPILER_CHECK(sizeof(RegionInfo) == kCacheLineSize);\n+  COMPILER_CHECK(sizeof(RegionInfo) >= kCacheLineSize);\n \n   static uptr AdditionalSize() {\n-    uptr PageSize = GetPageSizeCached();\n-    uptr res = Max(sizeof(RegionInfo) * kNumClasses, PageSize);\n-    CHECK_EQ(res % PageSize, 0);\n-    return res;\n+    return RoundUpTo(sizeof(RegionInfo) * kNumClassesRounded,\n+                     GetPageSizeCached());\n   }\n \n   RegionInfo *GetRegionInfo(uptr class_id) {\n@@ -256,11 +389,20 @@ class SizeClassAllocator64 {\n   }\n \n   void PopulateFreeList(uptr class_id, RegionInfo *region) {\n+    CHECK(region->free_list.empty());\n     uptr size = SizeClassMap::Size(class_id);\n     uptr beg_idx = region->allocated_user;\n     uptr end_idx = beg_idx + kPopulateSize;\n-    region->free_list.clear();\n     uptr region_beg = kSpaceBeg + kRegionSize * class_id;\n+    if (end_idx + size > region->mapped_user) {\n+      // Do the mmap for the user memory.\n+      uptr map_size = kUserMapSize;\n+      while (end_idx + size > region->mapped_user + map_size)\n+        map_size += kUserMapSize;\n+      CHECK_GE(region->mapped_user + map_size, end_idx);\n+      MapWithCallback(region_beg + region->mapped_user, map_size);\n+      region->mapped_user += map_size;\n+    }\n     uptr idx = beg_idx;\n     uptr i = 0;\n     do {  // do-while loop because we need to put at least one item.\n@@ -270,7 +412,19 @@ class SizeClassAllocator64 {\n       i++;\n     } while (idx < end_idx);\n     region->allocated_user += idx - beg_idx;\n+    CHECK_LE(region->allocated_user, region->mapped_user);\n     region->allocated_meta += i * kMetadataSize;\n+    if (region->allocated_meta > region->mapped_meta) {\n+      uptr map_size = kMetaMapSize;\n+      while (region->allocated_meta > region->mapped_meta + map_size)\n+        map_size += kMetaMapSize;\n+      // Do the mmap for the metadata.\n+      CHECK_GE(region->mapped_meta + map_size, region->allocated_meta);\n+      MapWithCallback(region_beg + kRegionSize -\n+                      region->mapped_meta - map_size, map_size);\n+      region->mapped_meta += map_size;\n+    }\n+    CHECK_LE(region->allocated_meta, region->mapped_meta);\n     if (region->allocated_user + region->allocated_meta > kRegionSize) {\n       Printf(\"Out of memory. Dying.\\n\");\n       Printf(\"The process has exhausted %zuMB for size class %zu.\\n\",\n@@ -289,14 +443,219 @@ class SizeClassAllocator64 {\n     CHECK(!region->free_list.empty());\n     AllocatorListNode *node = region->free_list.front();\n     region->free_list.pop_front();\n+    region->n_allocated++;\n     return reinterpret_cast<void*>(node);\n   }\n \n   void DeallocateBySizeClass(void *p, uptr class_id) {\n     RegionInfo *region = GetRegionInfo(class_id);\n     SpinMutexLock l(&region->mutex);\n     region->free_list.push_front(reinterpret_cast<AllocatorListNode*>(p));\n+    region->n_freed++;\n+  }\n+};\n+\n+// SizeClassAllocator32 -- allocator for 32-bit address space.\n+// This allocator can theoretically be used on 64-bit arch, but there it is less\n+// efficient than SizeClassAllocator64.\n+//\n+// [kSpaceBeg, kSpaceBeg + kSpaceSize) is the range of addresses which can\n+// be returned by MmapOrDie().\n+//\n+// Region:\n+//   a result of a single call to MmapAlignedOrDie(kRegionSize, kRegionSize).\n+// Since the regions are aligned by kRegionSize, there are exactly\n+// kNumPossibleRegions possible regions in the address space and so we keep\n+// an u8 array possible_regions[kNumPossibleRegions] to store the size classes.\n+// 0 size class means the region is not used by the allocator.\n+//\n+// One Region is used to allocate chunks of a single size class.\n+// A Region looks like this:\n+// UserChunk1 .. UserChunkN <gap> MetaChunkN .. MetaChunk1\n+//\n+// In order to avoid false sharing the objects of this class should be\n+// chache-line aligned.\n+template <const uptr kSpaceBeg, const u64 kSpaceSize,\n+          const uptr kMetadataSize, class SizeClassMap,\n+          class MapUnmapCallback = NoOpMapUnmapCallback>\n+class SizeClassAllocator32 {\n+ public:\n+  void Init() {\n+    state_ = reinterpret_cast<State *>(MapWithCallback(sizeof(State)));\n+  }\n+\n+  void *MapWithCallback(uptr size) {\n+    size = RoundUpTo(size, GetPageSizeCached());\n+    void *res = MmapOrDie(size, \"SizeClassAllocator32\");\n+    MapUnmapCallback().OnMap((uptr)res, size);\n+    return res;\n+  }\n+  void UnmapWithCallback(uptr beg, uptr size) {\n+    MapUnmapCallback().OnUnmap(beg, size);\n+    UnmapOrDie(reinterpret_cast<void *>(beg), size);\n+  }\n+\n+  static bool CanAllocate(uptr size, uptr alignment) {\n+    return size <= SizeClassMap::kMaxSize &&\n+      alignment <= SizeClassMap::kMaxSize;\n+  }\n+\n+  void *Allocate(uptr size, uptr alignment) {\n+    if (size < alignment) size = alignment;\n+    CHECK(CanAllocate(size, alignment));\n+    return AllocateBySizeClass(ClassID(size));\n+  }\n+\n+  void Deallocate(void *p) {\n+    CHECK(PointerIsMine(p));\n+    DeallocateBySizeClass(p, GetSizeClass(p));\n+  }\n+\n+  void *GetMetaData(void *p) {\n+    CHECK(PointerIsMine(p));\n+    uptr mem = reinterpret_cast<uptr>(p);\n+    uptr beg = ComputeRegionBeg(mem);\n+    uptr size = SizeClassMap::Size(GetSizeClass(p));\n+    u32 offset = mem - beg;\n+    uptr n = offset / (u32)size;  // 32-bit division\n+    uptr meta = (beg + kRegionSize) - (n + 1) * kMetadataSize;\n+    return reinterpret_cast<void*>(meta);\n+  }\n+\n+  // Allocate several chunks of the given class_id.\n+  void BulkAllocate(uptr class_id, AllocatorFreeList *free_list) {\n+    SizeClassInfo *sci = GetSizeClassInfo(class_id);\n+    SpinMutexLock l(&sci->mutex);\n+    EnsureSizeClassHasAvailableChunks(sci, class_id);\n+    CHECK(!sci->free_list.empty());\n+    BulkMove(SizeClassMap::MaxCached(class_id), &sci->free_list, free_list);\n+  }\n+\n+  // Swallow the entire free_list for the given class_id.\n+  void BulkDeallocate(uptr class_id, AllocatorFreeList *free_list) {\n+    SizeClassInfo *sci = GetSizeClassInfo(class_id);\n+    SpinMutexLock l(&sci->mutex);\n+    sci->free_list.append_front(free_list);\n+  }\n+\n+  bool PointerIsMine(void *p) {\n+    return GetSizeClass(p) != 0;\n+  }\n+\n+  uptr GetSizeClass(void *p) {\n+    return state_->possible_regions[ComputeRegionId(reinterpret_cast<uptr>(p))];\n+  }\n+\n+  void *GetBlockBegin(void *p) {\n+    CHECK(PointerIsMine(p));\n+    uptr mem = reinterpret_cast<uptr>(p);\n+    uptr beg = ComputeRegionBeg(mem);\n+    uptr size = SizeClassMap::Size(GetSizeClass(p));\n+    u32 offset = mem - beg;\n+    u32 n = offset / (u32)size;  // 32-bit division\n+    uptr res = beg + (n * (u32)size);\n+    return reinterpret_cast<void*>(res);\n+  }\n+\n+  uptr GetActuallyAllocatedSize(void *p) {\n+    CHECK(PointerIsMine(p));\n+    return SizeClassMap::Size(GetSizeClass(p));\n+  }\n+\n+  uptr ClassID(uptr size) { return SizeClassMap::ClassID(size); }\n+\n+  uptr TotalMemoryUsed() {\n+    // No need to lock here.\n+    uptr res = 0;\n+    for (uptr i = 0; i < kNumPossibleRegions; i++)\n+      if (state_->possible_regions[i])\n+        res += kRegionSize;\n+    return res;\n+  }\n+\n+  void TestOnlyUnmap() {\n+    for (uptr i = 0; i < kNumPossibleRegions; i++)\n+      if (state_->possible_regions[i])\n+        UnmapWithCallback((i * kRegionSize), kRegionSize);\n+    UnmapWithCallback(reinterpret_cast<uptr>(state_), sizeof(State));\n+  }\n+\n+  void PrintStats() {\n+  }\n+\n+  typedef SizeClassMap SizeClassMapT;\n+  static const uptr kNumClasses = SizeClassMap::kNumClasses;\n+\n+ private:\n+  static const uptr kRegionSizeLog = SANITIZER_WORDSIZE == 64 ? 24 : 20;\n+  static const uptr kRegionSize = 1 << kRegionSizeLog;\n+  static const uptr kNumPossibleRegions = kSpaceSize / kRegionSize;\n+\n+  struct SizeClassInfo {\n+    SpinMutex mutex;\n+    AllocatorFreeList free_list;\n+    char padding[kCacheLineSize - sizeof(uptr) - sizeof(AllocatorFreeList)];\n+  };\n+  COMPILER_CHECK(sizeof(SizeClassInfo) == kCacheLineSize);\n+\n+  uptr ComputeRegionId(uptr mem) {\n+    uptr res = mem >> kRegionSizeLog;\n+    CHECK_LT(res, kNumPossibleRegions);\n+    return res;\n+  }\n+\n+  uptr ComputeRegionBeg(uptr mem) {\n+    return mem & ~(kRegionSize - 1);\n+  }\n+\n+  uptr AllocateRegion(uptr class_id) {\n+    CHECK_LT(class_id, kNumClasses);\n+    uptr res = reinterpret_cast<uptr>(MmapAlignedOrDie(kRegionSize, kRegionSize,\n+                                      \"SizeClassAllocator32\"));\n+    MapUnmapCallback().OnMap(res, kRegionSize);\n+    CHECK_EQ(0U, (res & (kRegionSize - 1)));\n+    CHECK_EQ(0U, state_->possible_regions[ComputeRegionId(res)]);\n+    state_->possible_regions[ComputeRegionId(res)] = class_id;\n+    return res;\n+  }\n+\n+  SizeClassInfo *GetSizeClassInfo(uptr class_id) {\n+    CHECK_LT(class_id, kNumClasses);\n+    return &state_->size_class_info_array[class_id];\n+  }\n+\n+  void EnsureSizeClassHasAvailableChunks(SizeClassInfo *sci, uptr class_id) {\n+    if (!sci->free_list.empty()) return;\n+    uptr size = SizeClassMap::Size(class_id);\n+    uptr reg = AllocateRegion(class_id);\n+    uptr n_chunks = kRegionSize / (size + kMetadataSize);\n+    for (uptr i = reg; i < reg + n_chunks * size; i += size)\n+      sci->free_list.push_back(reinterpret_cast<AllocatorListNode*>(i));\n+  }\n+\n+  void *AllocateBySizeClass(uptr class_id) {\n+    CHECK_LT(class_id, kNumClasses);\n+    SizeClassInfo *sci = GetSizeClassInfo(class_id);\n+    SpinMutexLock l(&sci->mutex);\n+    EnsureSizeClassHasAvailableChunks(sci, class_id);\n+    CHECK(!sci->free_list.empty());\n+    AllocatorListNode *node = sci->free_list.front();\n+    sci->free_list.pop_front();\n+    return reinterpret_cast<void*>(node);\n   }\n+\n+  void DeallocateBySizeClass(void *p, uptr class_id) {\n+    CHECK_LT(class_id, kNumClasses);\n+    SizeClassInfo *sci = GetSizeClassInfo(class_id);\n+    SpinMutexLock l(&sci->mutex);\n+    sci->free_list.push_front(reinterpret_cast<AllocatorListNode*>(p));\n+  }\n+\n+  struct State {\n+    u8 possible_regions[kNumPossibleRegions];\n+    SizeClassInfo size_class_info_array[kNumClasses];\n+  };\n+  State *state_;\n };\n \n // Objects of this type should be used as local caches for SizeClassAllocator64.\n@@ -312,6 +671,7 @@ struct SizeClassAllocatorLocalCache {\n   }\n \n   void *Allocate(SizeClassAllocator *allocator, uptr class_id) {\n+    CHECK_NE(class_id, 0UL);\n     CHECK_LT(class_id, kNumClasses);\n     AllocatorFreeList *free_list = &free_lists_[class_id];\n     if (free_list->empty())\n@@ -323,6 +683,7 @@ struct SizeClassAllocatorLocalCache {\n   }\n \n   void Deallocate(SizeClassAllocator *allocator, uptr class_id, void *p) {\n+    CHECK_NE(class_id, 0UL);\n     CHECK_LT(class_id, kNumClasses);\n     AllocatorFreeList *free_list = &free_lists_[class_id];\n     free_list->push_front(reinterpret_cast<AllocatorListNode*>(p));\n@@ -358,6 +719,7 @@ struct SizeClassAllocatorLocalCache {\n // This class can (de)allocate only large chunks of memory using mmap/unmap.\n // The main purpose of this allocator is to cover large and rare allocation\n // sizes not covered by more efficient allocators (e.g. SizeClassAllocator64).\n+template <class MapUnmapCallback = NoOpMapUnmapCallback>\n class LargeMmapAllocator {\n  public:\n   void Init() {\n@@ -372,6 +734,7 @@ class LargeMmapAllocator {\n     if (map_size < size) return 0;  // Overflow.\n     uptr map_beg = reinterpret_cast<uptr>(\n         MmapOrDie(map_size, \"LargeMmapAllocator\"));\n+    MapUnmapCallback().OnMap(map_beg, map_size);\n     uptr map_end = map_beg + map_size;\n     uptr res = map_beg + page_size_;\n     if (res & (alignment - 1))  // Align.\n@@ -384,11 +747,13 @@ class LargeMmapAllocator {\n     h->map_size = map_size;\n     {\n       SpinMutexLock l(&mutex_);\n-      h->next = list_;\n-      h->prev = 0;\n-      if (list_)\n-        list_->prev = h;\n-      list_ = h;\n+      uptr idx = n_chunks_++;\n+      CHECK_LT(idx, kMaxNumChunks);\n+      h->chunk_idx = idx;\n+      chunks_[idx] = h;\n+      stats.n_allocs++;\n+      stats.currently_allocated += map_size;\n+      stats.max_allocated = Max(stats.max_allocated, stats.currently_allocated);\n     }\n     return reinterpret_cast<void*>(res);\n   }\n@@ -397,63 +762,81 @@ class LargeMmapAllocator {\n     Header *h = GetHeader(p);\n     {\n       SpinMutexLock l(&mutex_);\n-      Header *prev = h->prev;\n-      Header *next = h->next;\n-      if (prev)\n-        prev->next = next;\n-      if (next)\n-        next->prev = prev;\n-      if (h == list_)\n-        list_ = next;\n+      uptr idx = h->chunk_idx;\n+      CHECK_EQ(chunks_[idx], h);\n+      CHECK_LT(idx, n_chunks_);\n+      chunks_[idx] = chunks_[n_chunks_ - 1];\n+      chunks_[idx]->chunk_idx = idx;\n+      n_chunks_--;\n+      stats.n_frees++;\n+      stats.currently_allocated -= h->map_size;\n     }\n+    MapUnmapCallback().OnUnmap(h->map_beg, h->map_size);\n     UnmapOrDie(reinterpret_cast<void*>(h->map_beg), h->map_size);\n   }\n \n   uptr TotalMemoryUsed() {\n     SpinMutexLock l(&mutex_);\n     uptr res = 0;\n-    for (Header *l = list_; l; l = l->next) {\n-      res += RoundUpMapSize(l->size);\n+    for (uptr i = 0; i < n_chunks_; i++) {\n+      Header *h = chunks_[i];\n+      CHECK_EQ(h->chunk_idx, i);\n+      res += RoundUpMapSize(h->size);\n     }\n     return res;\n   }\n \n   bool PointerIsMine(void *p) {\n-    // Fast check.\n-    if ((reinterpret_cast<uptr>(p) & (page_size_ - 1))) return false;\n-    SpinMutexLock l(&mutex_);\n-    for (Header *l = list_; l; l = l->next) {\n-      if (GetUser(l) == p) return true;\n-    }\n-    return false;\n+    return GetBlockBegin(p) != 0;\n   }\n \n   uptr GetActuallyAllocatedSize(void *p) {\n-    return RoundUpMapSize(GetHeader(p)->size) - page_size_;\n+    return RoundUpTo(GetHeader(p)->size, page_size_);\n   }\n \n   // At least page_size_/2 metadata bytes is available.\n   void *GetMetaData(void *p) {\n+    // Too slow: CHECK_EQ(p, GetBlockBegin(p));\n+    CHECK(IsAligned(reinterpret_cast<uptr>(p), page_size_));\n     return GetHeader(p) + 1;\n   }\n \n-  void *GetBlockBegin(void *p) {\n+  void *GetBlockBegin(void *ptr) {\n+    uptr p = reinterpret_cast<uptr>(ptr);\n     SpinMutexLock l(&mutex_);\n-    for (Header *l = list_; l; l = l->next) {\n-      void *b = GetUser(l);\n-      if (p >= b && p < (u8*)b + l->size)\n-        return b;\n+    uptr nearest_chunk = 0;\n+    // Cache-friendly linear search.\n+    for (uptr i = 0; i < n_chunks_; i++) {\n+      uptr ch = reinterpret_cast<uptr>(chunks_[i]);\n+      if (p < ch) continue;  // p is at left to this chunk, skip it.\n+      if (p - ch < p - nearest_chunk)\n+        nearest_chunk = ch;\n     }\n-    return 0;\n+    if (!nearest_chunk)\n+      return 0;\n+    Header *h = reinterpret_cast<Header *>(nearest_chunk);\n+    CHECK_GE(nearest_chunk, h->map_beg);\n+    CHECK_LT(nearest_chunk, h->map_beg + h->map_size);\n+    CHECK_LE(nearest_chunk, p);\n+    if (h->map_beg + h->map_size < p)\n+      return 0;\n+    return GetUser(h);\n+  }\n+\n+  void PrintStats() {\n+    Printf(\"Stats: LargeMmapAllocator: allocated %zd times, \"\n+           \"remains %zd (%zd K) max %zd M\\n\",\n+           stats.n_allocs, stats.n_allocs - stats.n_frees,\n+           stats.currently_allocated >> 10, stats.max_allocated >> 20);\n   }\n \n  private:\n+  static const int kMaxNumChunks = 1 << FIRST_32_SECOND_64(15, 18);\n   struct Header {\n     uptr map_beg;\n     uptr map_size;\n     uptr size;\n-    Header *next;\n-    Header *prev;\n+    uptr chunk_idx;\n   };\n \n   Header *GetHeader(uptr p) {\n@@ -472,7 +855,11 @@ class LargeMmapAllocator {\n   }\n \n   uptr page_size_;\n-  Header *list_;\n+  Header *chunks_[kMaxNumChunks];\n+  uptr n_chunks_;\n+  struct Stats {\n+    uptr n_allocs, n_frees, currently_allocated, max_allocated;\n+  } stats;\n   SpinMutex mutex_;\n };\n \n@@ -501,10 +888,14 @@ class CombinedAllocator {\n     if (alignment > 8)\n       size = RoundUpTo(size, alignment);\n     void *res;\n-    if (primary_.CanAllocate(size, alignment))\n-      res = cache->Allocate(&primary_, primary_.ClassID(size));\n-    else\n+    if (primary_.CanAllocate(size, alignment)) {\n+      if (cache)  // Allocate from cache.\n+        res = cache->Allocate(&primary_, primary_.ClassID(size));\n+      else  // No thread-local cache, allocate directly from primary allocator.\n+        res = primary_.Allocate(size, alignment);\n+    } else {  // Secondary allocator does not use cache.\n       res = secondary_.Allocate(size, alignment);\n+    }\n     if (alignment > 8)\n       CHECK_EQ(reinterpret_cast<uptr>(res) & (alignment - 1), 0);\n     if (cleared && res)\n@@ -544,6 +935,10 @@ class CombinedAllocator {\n     return secondary_.PointerIsMine(p);\n   }\n \n+  bool FromPrimary(void *p) {\n+    return primary_.PointerIsMine(p);\n+  }\n+\n   void *GetMetaData(void *p) {\n     if (primary_.PointerIsMine(p))\n       return primary_.GetMetaData(p);\n@@ -572,6 +967,11 @@ class CombinedAllocator {\n     cache->Drain(&primary_);\n   }\n \n+  void PrintStats() {\n+    primary_.PrintStats();\n+    secondary_.PrintStats();\n+  }\n+\n  private:\n   PrimaryAllocator primary_;\n   SecondaryAllocator secondary_;"}, {"sha": "55e00e2204c5d476b88333fa27e0ec327e30013a", "filename": "libsanitizer/sanitizer_common/sanitizer_atomic_msvc.h", "status": "modified", "additions": 24, "deletions": 2, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_atomic_msvc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_atomic_msvc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_atomic_msvc.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -22,9 +22,31 @@ extern \"C\" void _mm_pause();\n extern \"C\" long _InterlockedExchangeAdd(  // NOLINT\n     long volatile * Addend, long Value);  // NOLINT\n #pragma intrinsic(_InterlockedExchangeAdd)\n-extern \"C\" void *InterlockedCompareExchangePointer(\n+\n+#ifdef _WIN64\n+extern \"C\" void *_InterlockedCompareExchangePointer(\n     void *volatile *Destination,\n     void *Exchange, void *Comparand);\n+#pragma intrinsic(_InterlockedCompareExchangePointer)\n+#else\n+// There's no _InterlockedCompareExchangePointer intrinsic on x86,\n+// so call _InterlockedCompareExchange instead.\n+extern \"C\"\n+long __cdecl _InterlockedCompareExchange(  // NOLINT\n+    long volatile *Destination,            // NOLINT\n+    long Exchange, long Comparand);        // NOLINT\n+#pragma intrinsic(_InterlockedCompareExchange)\n+\n+inline static void *_InterlockedCompareExchangePointer(\n+    void *volatile *Destination,\n+    void *Exchange, void *Comparand) {\n+  return reinterpret_cast<void*>(\n+      _InterlockedCompareExchange(\n+          reinterpret_cast<long volatile*>(Destination),  // NOLINT\n+          reinterpret_cast<long>(Exchange),               // NOLINT\n+          reinterpret_cast<long>(Comparand)));            // NOLINT\n+}\n+#endif\n \n namespace __sanitizer {\n \n@@ -113,7 +135,7 @@ INLINE bool atomic_compare_exchange_strong(volatile atomic_uintptr_t *a,\n                                            uptr xchg,\n                                            memory_order mo) {\n   uptr cmpv = *cmp;\n-  uptr prev = (uptr)InterlockedCompareExchangePointer(\n+  uptr prev = (uptr)_InterlockedCompareExchangePointer(\n       (void*volatile*)&a->val_dont_use, (void*)xchg, (void*)cmpv);\n   if (prev == cmpv)\n     return true;"}, {"sha": "96e8808f6d14512de7e1f5796697874ace0adfea", "filename": "libsanitizer/sanitizer_common/sanitizer_common.cc", "status": "modified", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -153,6 +153,27 @@ void SortArray(uptr *array, uptr size) {\n   }\n }\n \n+// We want to map a chunk of address space aligned to 'alignment'.\n+// We do it by maping a bit more and then unmaping redundant pieces.\n+// We probably can do it with fewer syscalls in some OS-dependent way.\n+void *MmapAlignedOrDie(uptr size, uptr alignment, const char *mem_type) {\n+// uptr PageSize = GetPageSizeCached();\n+  CHECK(IsPowerOfTwo(size));\n+  CHECK(IsPowerOfTwo(alignment));\n+  uptr map_size = size + alignment;\n+  uptr map_res = (uptr)MmapOrDie(map_size, mem_type);\n+  uptr map_end = map_res + map_size;\n+  uptr res = map_res;\n+  if (res & (alignment - 1))  // Not aligned.\n+    res = (map_res + alignment) & ~(alignment - 1);\n+  uptr end = res + size;\n+  if (res != map_res)\n+    UnmapOrDie((void*)map_res, res - map_res);\n+  if (end != map_end)\n+    UnmapOrDie((void*)end, map_end - end);\n+  return (void*)res;\n+}\n+\n }  // namespace __sanitizer\n \n using namespace __sanitizer;  // NOLINT\n@@ -178,4 +199,9 @@ void __sanitizer_set_report_fd(int fd) {\n     internal_close(report_fd);\n   report_fd = fd;\n }\n+\n+void NOINLINE __sanitizer_sandbox_on_notify(void *reserved) {\n+  (void)reserved;\n+  PrepareForSandboxing();\n+}\n }  // extern \"C\""}, {"sha": "6b104884342301083988d20c6ae85818a46f99a2", "filename": "libsanitizer/sanitizer_common/sanitizer_common.h", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -42,9 +42,13 @@ void GetThreadStackTopAndBottom(bool at_initialization, uptr *stack_top,\n void *MmapOrDie(uptr size, const char *mem_type);\n void UnmapOrDie(void *addr, uptr size);\n void *MmapFixedNoReserve(uptr fixed_addr, uptr size);\n+void *MmapFixedOrDie(uptr fixed_addr, uptr size);\n void *Mprotect(uptr fixed_addr, uptr size);\n+// Map aligned chunk of address space; size and alignment are powers of two.\n+void *MmapAlignedOrDie(uptr size, uptr alignment, const char *mem_type);\n // Used to check if we can map shadow memory to a fixed location.\n bool MemoryRangeIsAvailable(uptr range_start, uptr range_end);\n+void FlushUnneededShadowMemory(uptr addr, uptr size);\n \n // Internal allocator\n void *InternalAlloc(uptr size);\n@@ -119,6 +123,7 @@ const char *GetPwd();\n void ReExec();\n bool StackSizeIsUnlimited();\n void SetStackSizeLimitInBytes(uptr limit);\n+void PrepareForSandboxing();\n \n // Other\n void SleepForSeconds(int seconds);\n@@ -133,6 +138,13 @@ void NORETURN Die();\n void NORETURN SANITIZER_INTERFACE_ATTRIBUTE\n CheckFailed(const char *file, int line, const char *cond, u64 v1, u64 v2);\n \n+// Set the name of the current thread to 'name', return true on succees.\n+// The name may be truncated to a system-dependent limit.\n+bool SanitizerSetThreadName(const char *name);\n+// Get the name of the current thread (no more than max_len bytes),\n+// return true on succees. name should have space for at least max_len+1 bytes.\n+bool SanitizerGetThreadName(char *name, int max_len);\n+\n // Specific tools may override behavior of \"Die\" and \"CheckFailed\" functions\n // to do tool-specific job.\n void SetDieCallback(void (*callback)(void));\n@@ -148,6 +160,12 @@ INLINE uptr RoundUpTo(uptr size, uptr boundary) {\n   CHECK(IsPowerOfTwo(boundary));\n   return (size + boundary - 1) & ~(boundary - 1);\n }\n+INLINE uptr RoundDownTo(uptr x, uptr boundary) {\n+  return x & ~(boundary - 1);\n+}\n+INLINE bool IsAligned(uptr a, uptr alignment) {\n+  return (a & (alignment - 1)) == 0;\n+}\n // Don't use std::min, std::max or std::swap, to minimize dependency\n // on libstdc++.\n template<class T> T Min(T a, T b) { return a < b ? a : b; }"}, {"sha": "97c6b6f7beb0105a828fc2c14230b07470cbea20", "filename": "libsanitizer/sanitizer_common/sanitizer_common_interceptors.h", "status": "added", "additions": 77, "deletions": 0, "changes": 77, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,77 @@\n+//===-- sanitizer_common_interceptors.h -------------------------*- C++ -*-===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// Common function interceptors for tools like AddressSanitizer,\n+// ThreadSanitizer, MemorySanitizer, etc.\n+//\n+// This file should be included into the tool's interceptor file,\n+// which has to define it's own macros:\n+//   COMMON_INTERCEPTOR_ENTER\n+//   COMMON_INTERCEPTOR_READ_RANGE\n+//   COMMON_INTERCEPTOR_WRITE_RANGE\n+//\n+//===----------------------------------------------------------------------===//\n+#ifndef SANITIZER_COMMON_INTERCEPTORS_H\n+#define SANITIZER_COMMON_INTERCEPTORS_H\n+\n+#include \"interception/interception.h\"\n+#include \"sanitizer_platform_interceptors.h\"\n+\n+#if SANITIZER_INTERCEPT_READ\n+INTERCEPTOR(SSIZE_T, read, int fd, void *ptr, SIZE_T count) {\n+  COMMON_INTERCEPTOR_ENTER(read, fd, ptr, count);\n+  SSIZE_T res = REAL(read)(fd, ptr, count);\n+  if (res > 0)\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ptr, res);\n+  return res;\n+}\n+#endif\n+\n+#if SANITIZER_INTERCEPT_PREAD\n+INTERCEPTOR(SSIZE_T, pread, int fd, void *ptr, SIZE_T count, OFF_T offset) {\n+  COMMON_INTERCEPTOR_ENTER(pread, fd, ptr, count, offset);\n+  SSIZE_T res = REAL(pread)(fd, ptr, count, offset);\n+  if (res > 0)\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ptr, res);\n+  return res;\n+}\n+#endif\n+\n+#if SANITIZER_INTERCEPT_PREAD64\n+INTERCEPTOR(SSIZE_T, pread64, int fd, void *ptr, SIZE_T count, OFF64_T offset) {\n+  COMMON_INTERCEPTOR_ENTER(pread64, fd, ptr, count, offset);\n+  SSIZE_T res = REAL(pread64)(fd, ptr, count, offset);\n+  if (res > 0)\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ptr, res);\n+  return res;\n+}\n+#endif\n+\n+#if SANITIZER_INTERCEPT_READ\n+# define INIT_READ INTERCEPT_FUNCTION(read)\n+#else\n+# define INIT_READ\n+#endif\n+\n+#if SANITIZER_INTERCEPT_PREAD\n+# define INIT_PREAD INTERCEPT_FUNCTION(pread)\n+#else\n+# define INIT_PREAD\n+#endif\n+\n+#if SANITIZER_INTERCEPT_PREAD64\n+# define INIT_PREAD64 INTERCEPT_FUNCTION(pread64)\n+#else\n+# define INIT_PREAD64\n+#endif\n+\n+#define SANITIZER_COMMON_INTERCEPTORS_INIT \\\n+  INIT_READ;                               \\\n+  INIT_PREAD;                              \\\n+  INIT_PREAD64;                            \\\n+\n+#endif  // SANITIZER_COMMON_INTERCEPTORS_H"}, {"sha": "b02cbd4aced227888af469f2faf557500c47ccae", "filename": "libsanitizer/sanitizer_common/sanitizer_libc.cc", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -203,4 +203,23 @@ s64 internal_simple_strtoll(const char *nptr, char **endptr, int base) {\n   }\n }\n \n+bool mem_is_zero(const char *beg, uptr size) {\n+  CHECK_LE(size, 1UL << FIRST_32_SECOND_64(30, 40));  // Sanity check.\n+  const char *end = beg + size;\n+  uptr *aligned_beg = (uptr *)RoundUpTo((uptr)beg, sizeof(uptr));\n+  uptr *aligned_end = (uptr *)RoundDownTo((uptr)end, sizeof(uptr));\n+  uptr all = 0;\n+  // Prologue.\n+  for (const char *mem = beg; mem < (char*)aligned_beg && mem < end; mem++)\n+    all |= *mem;\n+  // Aligned loop.\n+  for (; aligned_beg < aligned_end; aligned_beg++)\n+    all |= *aligned_beg;\n+  // Epilogue.\n+  if ((char*)aligned_end >= beg)\n+    for (const char *mem = (char*)aligned_end; mem < end; mem++)\n+      all |= *mem;\n+  return all == 0;\n+}\n+\n }  // namespace __sanitizer"}, {"sha": "f193017f953eb3e2405502d4bd4a33493ff081ba", "filename": "libsanitizer/sanitizer_common/sanitizer_libc.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -45,6 +45,11 @@ char *internal_strstr(const char *haystack, const char *needle);\n // Works only for base=10 and doesn't set errno.\n s64 internal_simple_strtoll(const char *nptr, char **endptr, int base);\n \n+// Return true if all bytes in [mem, mem+size) are zero.\n+// Optimized for the case when the result is true.\n+bool mem_is_zero(const char *mem, uptr size);\n+\n+\n // Memory\n void *internal_mmap(void *addr, uptr length, int prot, int flags,\n                     int fd, u64 offset);"}, {"sha": "1d0bf02192cad893b1d209045aef5227557d2424", "filename": "libsanitizer/sanitizer_common/sanitizer_linux.cc", "status": "modified", "additions": 80, "deletions": 0, "changes": 80, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -17,6 +17,7 @@\n #include \"sanitizer_mutex.h\"\n #include \"sanitizer_placement_new.h\"\n #include \"sanitizer_procmaps.h\"\n+#include \"sanitizer_stacktrace.h\"\n \n #include <fcntl.h>\n #include <pthread.h>\n@@ -28,7 +29,9 @@\n #include <sys/time.h>\n #include <sys/types.h>\n #include <unistd.h>\n+#include <unwind.h>\n #include <errno.h>\n+#include <sys/prctl.h>\n \n // Are we using 32-bit or 64-bit syscalls?\n // x32 (which defines __x86_64__) has SANITIZER_WORDSIZE == 32\n@@ -215,6 +218,14 @@ void ReExec() {\n   execv(argv[0], argv.data());\n }\n \n+void PrepareForSandboxing() {\n+  // Some kinds of sandboxes may forbid filesystem access, so we won't be able\n+  // to read the file mappings from /proc/self/maps. Luckily, neither the\n+  // process will be able to load additional libraries, so it's fine to use the\n+  // cached mappings.\n+  MemoryMappingLayout::CacheMemoryMappings();\n+}\n+\n // ----------------- sanitizer_procmaps.h\n // Linker initialized.\n ProcSelfMapsBuff MemoryMappingLayout::cached_proc_self_maps_;\n@@ -354,6 +365,75 @@ bool MemoryMappingLayout::GetObjectNameAndOffset(uptr addr, uptr *offset,\n   return IterateForObjectNameAndOffset(addr, offset, filename, filename_size);\n }\n \n+bool SanitizerSetThreadName(const char *name) {\n+  return 0 == prctl(PR_SET_NAME, (unsigned long)name, 0, 0, 0);  // NOLINT\n+}\n+\n+bool SanitizerGetThreadName(char *name, int max_len) {\n+  char buff[17];\n+  if (prctl(PR_GET_NAME, (unsigned long)buff, 0, 0, 0))  // NOLINT\n+    return false;\n+  internal_strncpy(name, buff, max_len);\n+  name[max_len] = 0;\n+  return true;\n+}\n+\n+#ifndef SANITIZER_GO\n+//------------------------- SlowUnwindStack -----------------------------------\n+#ifdef __arm__\n+#define UNWIND_STOP _URC_END_OF_STACK\n+#define UNWIND_CONTINUE _URC_NO_REASON\n+#else\n+#define UNWIND_STOP _URC_NORMAL_STOP\n+#define UNWIND_CONTINUE _URC_NO_REASON\n+#endif\n+\n+uptr Unwind_GetIP(struct _Unwind_Context *ctx) {\n+#ifdef __arm__\n+  uptr val;\n+  _Unwind_VRS_Result res = _Unwind_VRS_Get(ctx, _UVRSC_CORE,\n+      15 /* r15 = PC */, _UVRSD_UINT32, &val);\n+  CHECK(res == _UVRSR_OK && \"_Unwind_VRS_Get failed\");\n+  // Clear the Thumb bit.\n+  return val & ~(uptr)1;\n+#else\n+  return _Unwind_GetIP(ctx);\n+#endif\n+}\n+\n+_Unwind_Reason_Code Unwind_Trace(struct _Unwind_Context *ctx, void *param) {\n+  StackTrace *b = (StackTrace*)param;\n+  CHECK(b->size < b->max_size);\n+  uptr pc = Unwind_GetIP(ctx);\n+  b->trace[b->size++] = pc;\n+  if (b->size == b->max_size) return UNWIND_STOP;\n+  return UNWIND_CONTINUE;\n+}\n+\n+static bool MatchPc(uptr cur_pc, uptr trace_pc) {\n+  return cur_pc - trace_pc <= 64 || trace_pc - cur_pc <= 64;\n+}\n+\n+void StackTrace::SlowUnwindStack(uptr pc, uptr max_depth) {\n+  this->size = 0;\n+  this->max_size = max_depth;\n+  if (max_depth > 1) {\n+    _Unwind_Backtrace(Unwind_Trace, this);\n+    // We need to pop a few frames so that pc is on top.\n+    // trace[0] belongs to the current function so we always pop it.\n+    int to_pop = 1;\n+    /**/ if (size > 1 && MatchPc(pc, trace[1])) to_pop = 1;\n+    else if (size > 2 && MatchPc(pc, trace[2])) to_pop = 2;\n+    else if (size > 3 && MatchPc(pc, trace[3])) to_pop = 3;\n+    else if (size > 4 && MatchPc(pc, trace[4])) to_pop = 4;\n+    else if (size > 5 && MatchPc(pc, trace[5])) to_pop = 5;\n+    this->PopStackFrames(to_pop);\n+  }\n+  this->trace[0] = pc;\n+}\n+\n+#endif  // #ifndef SANITIZER_GO\n+\n }  // namespace __sanitizer\n \n #endif  // __linux__"}, {"sha": "0f64b306afb8b93918012b435ef0d80afbc1a5e6", "filename": "libsanitizer/sanitizer_common/sanitizer_mac.cc", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -124,6 +124,10 @@ void ReExec() {\n   UNIMPLEMENTED();\n }\n \n+void PrepareForSandboxing() {\n+  // Nothing here for now.\n+}\n+\n // ----------------- sanitizer_procmaps.h\n \n MemoryMappingLayout::MemoryMappingLayout() {"}, {"sha": "e32206cb6d476c83617bdc6e383f9541c5ab8d6f", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_interceptors.h", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_interceptors.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_interceptors.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_interceptors.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,27 @@\n+//===-- sanitizer_platform_interceptors.h -----------------------*- C++ -*-===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file defines macro telling whether sanitizer tools can/should intercept\n+// given library functions on a given platform.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#include \"sanitizer_internal_defs.h\"\n+\n+#if !defined(_WIN32)\n+# define SANITIZER_INTERCEPT_READ 1\n+# define SANITIZER_INTERCEPT_PREAD 1\n+#else\n+# define SANITIZER_INTERCEPT_READ 0\n+# define SANITIZER_INTERCEPT_PREAD 0\n+#endif\n+\n+#if defined(__linux__) && !defined(ANDROID)\n+# define SANITIZER_INTERCEPT_PREAD64 1\n+#else\n+# define SANITIZER_INTERCEPT_PREAD64 0\n+#endif"}, {"sha": "17287cd950e70c51056760566d2f48ccfdcefe06", "filename": "libsanitizer/sanitizer_common/sanitizer_posix.cc", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -91,13 +91,32 @@ void *MmapFixedNoReserve(uptr fixed_addr, uptr size) {\n   return p;\n }\n \n+void *MmapFixedOrDie(uptr fixed_addr, uptr size) {\n+  uptr PageSize = GetPageSizeCached();\n+  void *p = internal_mmap((void*)(fixed_addr & ~(PageSize - 1)),\n+      RoundUpTo(size, PageSize),\n+      PROT_READ | PROT_WRITE,\n+      MAP_PRIVATE | MAP_ANON | MAP_FIXED,\n+      -1, 0);\n+  if (p == (void*)-1) {\n+    Report(\"ERROR: Failed to allocate 0x%zx (%zd) bytes at address %p (%d)\\n\",\n+           size, size, fixed_addr, errno);\n+    CHECK(\"unable to mmap\" && 0);\n+  }\n+  return p;\n+}\n+\n void *Mprotect(uptr fixed_addr, uptr size) {\n   return internal_mmap((void*)fixed_addr, size,\n                        PROT_NONE,\n                        MAP_PRIVATE | MAP_ANON | MAP_FIXED | MAP_NORESERVE,\n                        -1, 0);\n }\n \n+void FlushUnneededShadowMemory(uptr addr, uptr size) {\n+  madvise((void*)addr, size, MADV_DONTNEED);\n+}\n+\n void *MapFileToMemory(const char *file_name, uptr *buff_size) {\n   fd_t fd = internal_open(file_name, false);\n   CHECK_NE(fd, kInvalidFd);"}, {"sha": "7771e1d34a144f4c1f61e157ff54efaafcbd11f2", "filename": "libsanitizer/sanitizer_common/sanitizer_printf.cc", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_printf.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_printf.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_printf.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -92,7 +92,7 @@ static int AppendPointer(char **buff, const char *buff_end, u64 ptr_value) {\n int VSNPrintf(char *buff, int buff_length,\n               const char *format, va_list args) {\n   static const char *kPrintfFormatsHelp =\n-    \"Supported Printf formats: %%(0[0-9]*)?(z|ll)?{d,u,x}; %%p; %%s; %%c\\n\";\n+    \"Supported Printf formats: %(0[0-9]*)?(z|ll)?{d,u,x}; %p; %s; %c\\n\";\n   RAW_CHECK(format);\n   RAW_CHECK(buff_length > 0);\n   const char *buff_end = &buff[buff_length - 1];"}, {"sha": "17f0b2edd2f95d0caa34c4ba9f2a8f7d1e073a6e", "filename": "libsanitizer/sanitizer_common/sanitizer_report_decorator.h", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_report_decorator.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_report_decorator.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_report_decorator.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,35 @@\n+//===-- sanitizer_report_decorator.h ----------------------------*- C++ -*-===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// Tags to decorate the sanitizer reports.\n+// Currently supported tags:\n+//   * None.\n+//   * ANSI color sequences.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef SANITIZER_ALLOCATOR_H\n+#define SANITIZER_ALLOCATOR_H\n+\n+namespace __sanitizer {\n+class AnsiColorDecorator {\n+ public:\n+  explicit AnsiColorDecorator(bool use_ansi_colors) : ansi_(use_ansi_colors) { }\n+  const char *Black()        { return ansi_ ? \"\\033[1m\\033[30m\" : \"\"; }\n+  const char *Red()          { return ansi_ ? \"\\033[1m\\033[31m\" : \"\"; }\n+  const char *Green()        { return ansi_ ? \"\\033[1m\\033[32m\" : \"\"; }\n+  const char *Yellow()       { return ansi_ ? \"\\033[1m\\033[33m\" : \"\"; }\n+  const char *Blue()         { return ansi_ ? \"\\033[1m\\033[34m\" : \"\"; }\n+  const char *Magenta()      { return ansi_ ? \"\\033[1m\\033[35m\" : \"\"; }\n+  const char *Cyan()         { return ansi_ ? \"\\033[1m\\033[36m\" : \"\"; }\n+  const char *White()        { return ansi_ ? \"\\033[1m\\033[37m\" : \"\"; }\n+  const char *Default()      { return ansi_ ? \"\\033[1m\\033[0m\"  : \"\"; }\n+ private:\n+  bool ansi_;\n+};\n+}  // namespace __sanitizer\n+#endif  // SANITIZER_ALLOCATOR_H"}, {"sha": "2e22155fa7523bb5618e88ee23b77d9597723625", "filename": "libsanitizer/sanitizer_common/sanitizer_stackdepot.cc", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_stackdepot.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_stackdepot.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stackdepot.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -40,6 +40,12 @@ static struct {\n   atomic_uint32_t seq[kPartCount];  // Unique id generators.\n } depot;\n \n+static StackDepotStats stats;\n+\n+StackDepotStats *StackDepotGetStats() {\n+  return &stats;\n+}\n+\n static u32 hash(const uptr *stack, uptr size) {\n   // murmur2\n   const u32 m = 0x5bd1e995;\n@@ -75,7 +81,7 @@ static StackDesc *tryallocDesc(uptr memsz) {\n }\n \n static StackDesc *allocDesc(uptr size) {\n-  // Frist, try to allocate optimisitically.\n+  // First, try to allocate optimisitically.\n   uptr memsz = sizeof(StackDesc) + (size - 1) * sizeof(uptr);\n   StackDesc *s = tryallocDesc(memsz);\n   if (s)\n@@ -91,6 +97,7 @@ static StackDesc *allocDesc(uptr size) {\n     if (allocsz < memsz)\n       allocsz = memsz;\n     uptr mem = (uptr)MmapOrDie(allocsz, \"stack depot\");\n+    stats.mapped += allocsz;\n     atomic_store(&depot.region_end, mem + allocsz, memory_order_release);\n     atomic_store(&depot.region_pos, mem, memory_order_release);\n   }\n@@ -154,6 +161,7 @@ u32 StackDepotPut(const uptr *stack, uptr size) {\n   }\n   uptr part = (h % kTabSize) / kPartSize;\n   id = atomic_fetch_add(&depot.seq[part], 1, memory_order_relaxed) + 1;\n+  stats.n_uniq_ids++;\n   CHECK_LT(id, kMaxId);\n   id |= part << kPartShift;\n   CHECK_NE(id, 0);"}, {"sha": "1e917eb53bb459c9aba8a80556baf7ae4205e36e", "filename": "libsanitizer/sanitizer_common/sanitizer_stackdepot.h", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_stackdepot.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_stackdepot.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stackdepot.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -22,6 +22,13 @@ u32 StackDepotPut(const uptr *stack, uptr size);\n // Retrieves a stored stack trace by the id.\n const uptr *StackDepotGet(u32 id, uptr *size);\n \n+struct StackDepotStats {\n+  uptr n_uniq_ids;\n+  uptr mapped;\n+};\n+\n+StackDepotStats *StackDepotGetStats();\n+\n }  // namespace __sanitizer\n \n #endif  // SANITIZER_STACKDEPOT_H"}, {"sha": "59af1c352923126fd938425c88fd93ac4b3e1ef8", "filename": "libsanitizer/sanitizer_common/sanitizer_stacktrace.cc", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -23,10 +23,7 @@ static const char *StripPathPrefix(const char *filepath,\n }\n \n // ----------------------- StackTrace ----------------------------- {{{1\n-// PCs in stack traces are actually the return addresses, that is,\n-// addresses of the next instructions after the call. That's why we\n-// decrement them.\n-static uptr patch_pc(uptr pc) {\n+uptr StackTrace::GetPreviousInstructionPc(uptr pc) {\n #ifdef __arm__\n   // Cancel Thumb bit.\n   pc = pc & (~1);\n@@ -69,7 +66,9 @@ void StackTrace::PrintStack(const uptr *addr, uptr size,\n   InternalScopedBuffer<AddressInfo> addr_frames(64);\n   uptr frame_num = 0;\n   for (uptr i = 0; i < size && addr[i]; i++) {\n-    uptr pc = patch_pc(addr[i]);\n+    // PCs in stack traces are actually the return addresses, that is,\n+    // addresses of the next instructions after the call.\n+    uptr pc = GetPreviousInstructionPc(addr[i]);\n     uptr addr_frames_num = 0;  // The number of stack frames for current\n                                // instruction address.\n     if (symbolize_callback) {"}, {"sha": "c939644401cd0f6ed41717988c50fcd0441afff5", "filename": "libsanitizer/sanitizer_common/sanitizer_stacktrace.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -42,10 +42,12 @@ struct StackTrace {\n   }\n \n   void FastUnwindStack(uptr pc, uptr bp, uptr stack_top, uptr stack_bottom);\n+  void SlowUnwindStack(uptr pc, uptr max_depth);\n \n   void PopStackFrames(uptr count);\n \n   static uptr GetCurrentPc();\n+  static uptr GetPreviousInstructionPc(uptr pc);\n \n   static uptr CompressStack(StackTrace *stack,\n                             u32 *compressed, uptr size);"}, {"sha": "0714b3824fbce7dd022a6eb8e8e7c9a4375a0beb", "filename": "libsanitizer/sanitizer_common/sanitizer_symbolizer.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -58,6 +58,9 @@ struct AddressInfo {\n uptr SymbolizeCode(uptr address, AddressInfo *frames, uptr max_frames);\n bool SymbolizeData(uptr address, AddressInfo *frame);\n \n+// Attempts to demangle the provided C++ mangled name.\n+const char *Demangle(const char *Name);\n+\n // Starts external symbolizer program in a subprocess. Sanitizer communicates\n // with external symbolizer via pipes.\n bool InitializeExternalSymbolizer(const char *path_to_symbolizer);"}, {"sha": "b356f9a09e30cb425ebe499f0d5012071ec96116", "filename": "libsanitizer/sanitizer_common/sanitizer_symbolizer_itanium.cc", "status": "added", "additions": 40, "deletions": 0, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_itanium.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_itanium.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_itanium.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,40 @@\n+//===-- sanitizer_symbolizer_itanium.cc -----------------------------------===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is shared between the sanitizer run-time libraries.\n+// Itanium C++ ABI-specific implementation of symbolizer parts.\n+//===----------------------------------------------------------------------===//\n+#if defined(__APPLE__) || defined(__linux__)\n+\n+#include \"sanitizer_symbolizer.h\"\n+\n+#include <stdlib.h>\n+\n+// C++ demangling function, as required by Itanium C++ ABI. This is weak,\n+// because we do not require a C++ ABI library to be linked to a program\n+// using sanitizers; if it's not present, we'll just use the mangled name.\n+namespace __cxxabiv1 {\n+  extern \"C\" char *__cxa_demangle(const char *mangled, char *buffer,\n+                                  size_t *length, int *status)\n+    SANITIZER_WEAK_ATTRIBUTE;\n+}\n+\n+const char *__sanitizer::Demangle(const char *MangledName) {\n+  // FIXME: __cxa_demangle aggressively insists on allocating memory.\n+  // There's not much we can do about that, short of providing our\n+  // own demangler (libc++abi's implementation could be adapted so that\n+  // it does not allocate). For now, we just call it anyway, and we leak\n+  // the returned value.\n+  if (__cxxabiv1::__cxa_demangle)\n+    if (const char *Demangled =\n+          __cxxabiv1::__cxa_demangle(MangledName, 0, 0, 0))\n+      return Demangled;\n+\n+  return MangledName;\n+}\n+\n+#endif  // __APPLE__ || __linux__"}, {"sha": "ad0053234f06def454a8fecefeaef9aaa61b7637", "filename": "libsanitizer/sanitizer_common/sanitizer_symbolizer_win.cc", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_win.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_win.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_win.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -26,6 +26,10 @@ uptr GetListOfModules(LoadedModule *modules, uptr max_modules) {\n   UNIMPLEMENTED();\n };\n \n+const char *Demangle(const char *MangledName) {\n+  return MangledName;\n+}\n+\n }  // namespace __sanitizer\n \n #endif  // _WIN32"}, {"sha": "f7300a18b60beb13252629e57c1c3e2f0b940dd0", "filename": "libsanitizer/sanitizer_common/sanitizer_win.cc", "status": "modified", "additions": 12, "deletions": 1, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_win.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Fsanitizer_common%2Fsanitizer_win.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_win.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -13,6 +13,7 @@\n #define WIN32_LEAN_AND_MEAN\n #define NOGDI\n #include <stdlib.h>\n+#include <io.h>\n #include <windows.h>\n \n #include \"sanitizer_common.h\"\n@@ -73,6 +74,8 @@ void UnmapOrDie(void *addr, uptr size) {\n }\n \n void *MmapFixedNoReserve(uptr fixed_addr, uptr size) {\n+  // FIXME: is this really \"NoReserve\"? On Win32 this does not matter much,\n+  // but on Win64 it does.\n   void *p = VirtualAlloc((LPVOID)fixed_addr, size,\n       MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE);\n   if (p == 0)\n@@ -81,6 +84,10 @@ void *MmapFixedNoReserve(uptr fixed_addr, uptr size) {\n   return p;\n }\n \n+void *MmapFixedOrDie(uptr fixed_addr, uptr size) {\n+  return MmapFixedNoReserve(fixed_addr, size);\n+}\n+\n void *Mprotect(uptr fixed_addr, uptr size) {\n   return VirtualAlloc((LPVOID)fixed_addr, size,\n                       MEM_RESERVE | MEM_COMMIT, PAGE_NOACCESS);\n@@ -127,6 +134,10 @@ void ReExec() {\n   UNIMPLEMENTED();\n }\n \n+void PrepareForSandboxing() {\n+  // Nothing here for now.\n+}\n+\n bool StackSizeIsUnlimited() {\n   UNIMPLEMENTED();\n }\n@@ -173,7 +184,7 @@ int internal_close(fd_t fd) {\n }\n \n int internal_isatty(fd_t fd) {\n-  UNIMPLEMENTED();\n+  return _isatty(fd);\n }\n \n fd_t internal_open(const char *filename, bool write) {"}, {"sha": "fa9c26cb73d245c0d18ccfbaa087820d87940d68", "filename": "libsanitizer/tsan/Makefile.am", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2FMakefile.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2FMakefile.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2FMakefile.am?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -31,6 +31,9 @@ tsan_files = \\\n         tsan_interface_ann.cc \\\n         tsan_mman.cc \\\n         tsan_rtl_report.cc \\\n+\ttsan_fd.cc \\\n+        tsan_interface_java.cc \\\n+        tsan_mutexset.cc \\\n         tsan_symbolize_addr2line_linux.cc\n \n libtsan_la_SOURCES = $(tsan_files) "}, {"sha": "c739e701c17a477641aa898cf63249e1f5762c71", "filename": "libsanitizer/tsan/Makefile.in", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2FMakefile.in?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -87,7 +87,8 @@ am__objects_1 = tsan_clock.lo tsan_interface_atomic.lo tsan_mutex.lo \\\n \ttsan_rtl.lo tsan_stat.lo tsan_sync.lo tsan_interceptors.lo \\\n \ttsan_md5.lo tsan_platform_mac.lo tsan_rtl_mutex.lo \\\n \ttsan_suppressions.lo tsan_interface_ann.lo tsan_mman.lo \\\n-\ttsan_rtl_report.lo tsan_symbolize_addr2line_linux.lo\n+\ttsan_rtl_report.lo tsan_fd.lo tsan_interface_java.lo \\\n+\ttsan_mutexset.lo tsan_symbolize_addr2line_linux.lo\n am_libtsan_la_OBJECTS = $(am__objects_1)\n libtsan_la_OBJECTS = $(am_libtsan_la_OBJECTS)\n libtsan_la_LINK = $(LIBTOOL) --tag=CXX $(AM_LIBTOOLFLAGS) \\\n@@ -273,6 +274,9 @@ tsan_files = \\\n         tsan_interface_ann.cc \\\n         tsan_mman.cc \\\n         tsan_rtl_report.cc \\\n+\ttsan_fd.cc \\\n+        tsan_interface_java.cc \\\n+        tsan_mutexset.cc \\\n         tsan_symbolize_addr2line_linux.cc\n \n libtsan_la_SOURCES = $(tsan_files) \n@@ -393,14 +397,17 @@ distclean-compile:\n \t-rm -f *.tab.c\n \n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_clock.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_fd.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_flags.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_interceptors.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_interface.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_interface_ann.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_interface_atomic.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_interface_java.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_md5.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_mman.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_mutex.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_mutexset.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_platform_linux.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_platform_mac.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_report.Plo@am__quote@"}, {"sha": "6683a4e1abb0164a1e7560900bcb2808030b5c84", "filename": "libsanitizer/tsan/tsan_defs.h", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_defs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_defs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_defs.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -137,6 +137,12 @@ T RoundDown(T p, u64 align) {\n   return (T)((u64)p & ~(align - 1));\n }\n \n+// Zeroizes high part, returns 'bits' lsb bits.\n+template<typename T>\n+T GetLsb(T v, int bits) {\n+  return (T)((u64)v & ((1ull << bits) - 1));\n+}\n+\n struct MD5Hash {\n   u64 hash[2];\n   bool operator==(const MD5Hash &other) const;"}, {"sha": "9aca9c51b38f0dcab31b070424272cdfb6af4af6", "filename": "libsanitizer/tsan/tsan_fd.cc", "status": "added", "additions": 257, "deletions": 0, "changes": 257, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_fd.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_fd.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_fd.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,257 @@\n+//===-- tsan_fd.cc --------------------------------------------------------===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#include \"tsan_fd.h\"\n+#include \"tsan_rtl.h\"\n+#include <sanitizer_common/sanitizer_atomic.h>\n+\n+namespace __tsan {\n+\n+const int kTableSizeL1 = 1024;\n+const int kTableSizeL2 = 1024;\n+const int kTableSize = kTableSizeL1 * kTableSizeL2;\n+\n+struct FdSync {\n+  atomic_uint64_t rc;\n+};\n+\n+struct FdDesc {\n+  FdSync *sync;\n+  int creation_tid;\n+  u32 creation_stack;\n+};\n+\n+struct FdContext {\n+  atomic_uintptr_t tab[kTableSizeL1];\n+  // Addresses used for synchronization.\n+  FdSync globsync;\n+  FdSync filesync;\n+  FdSync socksync;\n+  u64 connectsync;\n+};\n+\n+static FdContext fdctx;\n+\n+static FdSync *allocsync() {\n+  FdSync *s = (FdSync*)internal_alloc(MBlockFD, sizeof(FdSync));\n+  atomic_store(&s->rc, 1, memory_order_relaxed);\n+  return s;\n+}\n+\n+static FdSync *ref(FdSync *s) {\n+  if (s && atomic_load(&s->rc, memory_order_relaxed) != (u64)-1)\n+    atomic_fetch_add(&s->rc, 1, memory_order_relaxed);\n+  return s;\n+}\n+\n+static void unref(ThreadState *thr, uptr pc, FdSync *s) {\n+  if (s && atomic_load(&s->rc, memory_order_relaxed) != (u64)-1) {\n+    if (atomic_fetch_sub(&s->rc, 1, memory_order_acq_rel) == 1) {\n+      CHECK_NE(s, &fdctx.globsync);\n+      CHECK_NE(s, &fdctx.filesync);\n+      CHECK_NE(s, &fdctx.socksync);\n+      SyncVar *v = CTX()->synctab.GetAndRemove(thr, pc, (uptr)s);\n+      if (v)\n+        DestroyAndFree(v);\n+      internal_free(s);\n+    }\n+  }\n+}\n+\n+static FdDesc *fddesc(ThreadState *thr, uptr pc, int fd) {\n+  CHECK_LT(fd, kTableSize);\n+  atomic_uintptr_t *pl1 = &fdctx.tab[fd / kTableSizeL2];\n+  uptr l1 = atomic_load(pl1, memory_order_consume);\n+  if (l1 == 0) {\n+    uptr size = kTableSizeL2 * sizeof(FdDesc);\n+    void *p = internal_alloc(MBlockFD, size);\n+    internal_memset(p, 0, size);\n+    MemoryResetRange(thr, (uptr)&fddesc, (uptr)p, size);\n+    if (atomic_compare_exchange_strong(pl1, &l1, (uptr)p, memory_order_acq_rel))\n+      l1 = (uptr)p;\n+    else\n+      internal_free(p);\n+  }\n+  return &((FdDesc*)l1)[fd % kTableSizeL2];  // NOLINT\n+}\n+\n+// pd must be already ref'ed.\n+static void init(ThreadState *thr, uptr pc, int fd, FdSync *s) {\n+  FdDesc *d = fddesc(thr, pc, fd);\n+  // As a matter of fact, we don't intercept all close calls.\n+  // See e.g. libc __res_iclose().\n+  if (d->sync) {\n+    unref(thr, pc, d->sync);\n+    d->sync = 0;\n+  }\n+  if (flags()->io_sync == 0) {\n+    unref(thr, pc, s);\n+  } else if (flags()->io_sync == 1) {\n+    d->sync = s;\n+  } else if (flags()->io_sync == 2) {\n+    unref(thr, pc, s);\n+    d->sync = &fdctx.globsync;\n+  }\n+  d->creation_tid = thr->tid;\n+  d->creation_stack = CurrentStackId(thr, pc);\n+  // To catch races between fd usage and open.\n+  MemoryRangeImitateWrite(thr, pc, (uptr)d, 8);\n+}\n+\n+void FdInit() {\n+  atomic_store(&fdctx.globsync.rc, (u64)-1, memory_order_relaxed);\n+  atomic_store(&fdctx.filesync.rc, (u64)-1, memory_order_relaxed);\n+  atomic_store(&fdctx.socksync.rc, (u64)-1, memory_order_relaxed);\n+}\n+\n+void FdOnFork(ThreadState *thr, uptr pc) {\n+  // On fork() we need to reset all fd's, because the child is going\n+  // close all them, and that will cause races between previous read/write\n+  // and the close.\n+  for (int l1 = 0; l1 < kTableSizeL1; l1++) {\n+    FdDesc *tab = (FdDesc*)atomic_load(&fdctx.tab[l1], memory_order_relaxed);\n+    if (tab == 0)\n+      break;\n+    for (int l2 = 0; l2 < kTableSizeL2; l2++) {\n+      FdDesc *d = &tab[l2];\n+      MemoryResetRange(thr, pc, (uptr)d, 8);\n+    }\n+  }\n+}\n+\n+bool FdLocation(uptr addr, int *fd, int *tid, u32 *stack) {\n+  for (int l1 = 0; l1 < kTableSizeL1; l1++) {\n+    FdDesc *tab = (FdDesc*)atomic_load(&fdctx.tab[l1], memory_order_relaxed);\n+    if (tab == 0)\n+      break;\n+    if (addr >= (uptr)tab && addr < (uptr)(tab + kTableSizeL2)) {\n+      int l2 = (addr - (uptr)tab) / sizeof(FdDesc);\n+      FdDesc *d = &tab[l2];\n+      *fd = l1 * kTableSizeL1 + l2;\n+      *tid = d->creation_tid;\n+      *stack = d->creation_stack;\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+void FdAcquire(ThreadState *thr, uptr pc, int fd) {\n+  FdDesc *d = fddesc(thr, pc, fd);\n+  FdSync *s = d->sync;\n+  DPrintf(\"#%d: FdAcquire(%d) -> %p\\n\", thr->tid, fd, s);\n+  MemoryRead8Byte(thr, pc, (uptr)d);\n+  if (s)\n+    Acquire(thr, pc, (uptr)s);\n+}\n+\n+void FdRelease(ThreadState *thr, uptr pc, int fd) {\n+  FdDesc *d = fddesc(thr, pc, fd);\n+  FdSync *s = d->sync;\n+  DPrintf(\"#%d: FdRelease(%d) -> %p\\n\", thr->tid, fd, s);\n+  if (s)\n+    Release(thr, pc, (uptr)s);\n+  MemoryRead8Byte(thr, pc, (uptr)d);\n+}\n+\n+void FdClose(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdClose(%d)\\n\", thr->tid, fd);\n+  FdDesc *d = fddesc(thr, pc, fd);\n+  // To catch races between fd usage and close.\n+  MemoryWrite8Byte(thr, pc, (uptr)d);\n+  // We need to clear it, because if we do not intercept any call out there\n+  // that creates fd, we will hit false postives.\n+  MemoryResetRange(thr, pc, (uptr)d, 8);\n+  unref(thr, pc, d->sync);\n+  d->sync = 0;\n+  d->creation_tid = 0;\n+  d->creation_stack = 0;\n+}\n+\n+void FdFileCreate(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdFileCreate(%d)\\n\", thr->tid, fd);\n+  init(thr, pc, fd, &fdctx.filesync);\n+}\n+\n+void FdDup(ThreadState *thr, uptr pc, int oldfd, int newfd) {\n+  DPrintf(\"#%d: FdDup(%d, %d)\\n\", thr->tid, oldfd, newfd);\n+  // Ignore the case when user dups not yet connected socket.\n+  FdDesc *od = fddesc(thr, pc, oldfd);\n+  MemoryRead8Byte(thr, pc, (uptr)od);\n+  FdClose(thr, pc, newfd);\n+  init(thr, pc, newfd, ref(od->sync));\n+}\n+\n+void FdPipeCreate(ThreadState *thr, uptr pc, int rfd, int wfd) {\n+  DPrintf(\"#%d: FdCreatePipe(%d, %d)\\n\", thr->tid, rfd, wfd);\n+  FdSync *s = allocsync();\n+  init(thr, pc, rfd, ref(s));\n+  init(thr, pc, wfd, ref(s));\n+  unref(thr, pc, s);\n+}\n+\n+void FdEventCreate(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdEventCreate(%d)\\n\", thr->tid, fd);\n+  init(thr, pc, fd, allocsync());\n+}\n+\n+void FdSignalCreate(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdSignalCreate(%d)\\n\", thr->tid, fd);\n+  init(thr, pc, fd, 0);\n+}\n+\n+void FdInotifyCreate(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdInotifyCreate(%d)\\n\", thr->tid, fd);\n+  init(thr, pc, fd, 0);\n+}\n+\n+void FdPollCreate(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdPollCreate(%d)\\n\", thr->tid, fd);\n+  init(thr, pc, fd, allocsync());\n+}\n+\n+void FdSocketCreate(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdSocketCreate(%d)\\n\", thr->tid, fd);\n+  // It can be a UDP socket.\n+  init(thr, pc, fd, &fdctx.socksync);\n+}\n+\n+void FdSocketAccept(ThreadState *thr, uptr pc, int fd, int newfd) {\n+  DPrintf(\"#%d: FdSocketAccept(%d, %d)\\n\", thr->tid, fd, newfd);\n+  // Synchronize connect->accept.\n+  Acquire(thr, pc, (uptr)&fdctx.connectsync);\n+  init(thr, pc, newfd, &fdctx.socksync);\n+}\n+\n+void FdSocketConnecting(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdSocketConnecting(%d)\\n\", thr->tid, fd);\n+  // Synchronize connect->accept.\n+  Release(thr, pc, (uptr)&fdctx.connectsync);\n+}\n+\n+void FdSocketConnect(ThreadState *thr, uptr pc, int fd) {\n+  DPrintf(\"#%d: FdSocketConnect(%d)\\n\", thr->tid, fd);\n+  init(thr, pc, fd, &fdctx.socksync);\n+}\n+\n+uptr File2addr(char *path) {\n+  (void)path;\n+  static u64 addr;\n+  return (uptr)&addr;\n+}\n+\n+uptr Dir2addr(char *path) {\n+  (void)path;\n+  static u64 addr;\n+  return (uptr)&addr;\n+}\n+\n+}  //  namespace __tsan"}, {"sha": "b4189a37df50a531d4c92c9ac2f56378086d12bf", "filename": "libsanitizer/tsan/tsan_fd.h", "status": "added", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_fd.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_fd.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_fd.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,62 @@\n+//===-- tsan_fd.h -----------------------------------------------*- C++ -*-===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+// This file handles synchronization via IO.\n+// People use IO for synchronization along the lines of:\n+//\n+// int X;\n+// int client_socket;  // initialized elsewhere\n+// int server_socket;  // initialized elsewhere\n+//\n+// Thread 1:\n+// X = 42;\n+// send(client_socket, ...);\n+//\n+// Thread 2:\n+// if (recv(server_socket, ...) > 0)\n+//   assert(X == 42);\n+//\n+// This file determines the scope of the file descriptor (pipe, socket,\n+// all local files, etc) and executes acquire and release operations on\n+// the scope as necessary.  Some scopes are very fine grained (e.g. pipe\n+// operations synchronize only with operations on the same pipe), while\n+// others are corse-grained (e.g. all operations on local files synchronize\n+// with each other).\n+//===----------------------------------------------------------------------===//\n+#ifndef TSAN_FD_H\n+#define TSAN_FD_H\n+\n+#include \"tsan_rtl.h\"\n+\n+namespace __tsan {\n+\n+void FdInit();\n+void FdAcquire(ThreadState *thr, uptr pc, int fd);\n+void FdRelease(ThreadState *thr, uptr pc, int fd);\n+void FdClose(ThreadState *thr, uptr pc, int fd);\n+void FdFileCreate(ThreadState *thr, uptr pc, int fd);\n+void FdDup(ThreadState *thr, uptr pc, int oldfd, int newfd);\n+void FdPipeCreate(ThreadState *thr, uptr pc, int rfd, int wfd);\n+void FdEventCreate(ThreadState *thr, uptr pc, int fd);\n+void FdSignalCreate(ThreadState *thr, uptr pc, int fd);\n+void FdInotifyCreate(ThreadState *thr, uptr pc, int fd);\n+void FdPollCreate(ThreadState *thr, uptr pc, int fd);\n+void FdSocketCreate(ThreadState *thr, uptr pc, int fd);\n+void FdSocketAccept(ThreadState *thr, uptr pc, int fd, int newfd);\n+void FdSocketConnecting(ThreadState *thr, uptr pc, int fd);\n+void FdSocketConnect(ThreadState *thr, uptr pc, int fd);\n+bool FdLocation(uptr addr, int *fd, int *tid, u32 *stack);\n+void FdOnFork(ThreadState *thr, uptr pc);\n+\n+uptr File2addr(char *path);\n+uptr Dir2addr(char *path);\n+\n+}  // namespace __tsan\n+\n+#endif  // TSAN_INTERFACE_H"}, {"sha": "630bd75769bccad3c4b988c9cdf4ed114dc556a0", "filename": "libsanitizer/tsan/tsan_flags.cc", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_flags.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_flags.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_flags.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -56,6 +56,7 @@ void InitializeFlags(Flags *f, const char *env) {\n   f->running_on_valgrind = false;\n   f->external_symbolizer_path = \"\";\n   f->history_size = kGoMode ? 1 : 2;  // There are a lot of goroutines in Go.\n+  f->io_sync = 1;\n \n   // Let a frontend override.\n   OverrideFlags(f);\n@@ -81,6 +82,7 @@ void InitializeFlags(Flags *f, const char *env) {\n   ParseFlag(env, &f->stop_on_start, \"stop_on_start\");\n   ParseFlag(env, &f->external_symbolizer_path, \"external_symbolizer_path\");\n   ParseFlag(env, &f->history_size, \"history_size\");\n+  ParseFlag(env, &f->io_sync, \"io_sync\");\n \n   if (!f->report_bugs) {\n     f->report_thread_leaks = false;\n@@ -93,6 +95,12 @@ void InitializeFlags(Flags *f, const char *env) {\n            \" (must be [0..7])\\n\");\n     Die();\n   }\n+\n+  if (f->io_sync < 0 || f->io_sync > 2) {\n+    Printf(\"ThreadSanitizer: incorrect value for io_sync\"\n+           \" (must be [0..2])\\n\");\n+    Die();\n+  }\n }\n \n }  // namespace __tsan"}, {"sha": "ed27363c2ffff559f47c3d8ab84f308cf6b9d48d", "filename": "libsanitizer/tsan/tsan_flags.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_flags.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_flags.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_flags.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -75,6 +75,11 @@ struct Flags {\n   // the amount of memory accesses, up to history_size=7 that amounts to\n   // 4M memory accesses.  The default value is 2 (128K memory accesses).\n   int history_size;\n+  // Controls level of synchronization implied by IO operations.\n+  // 0 - no synchronization\n+  // 1 - reasonable level of synchronization (write->read)\n+  // 2 - global synchronization of all IO operations\n+  int io_sync;\n };\n \n Flags *flags();"}, {"sha": "88acebf8e81bfcc6539abe903c5eb4f7f779294e", "filename": "libsanitizer/tsan/tsan_interceptors.cc", "status": "modified", "additions": 311, "deletions": 65, "changes": 376, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interceptors.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interceptors.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interceptors.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -7,6 +7,8 @@\n //\n // This file is a part of ThreadSanitizer (TSan), a race detector.\n //\n+// FIXME: move as many interceptors as possible into\n+// sanitizer_common/sanitizer_common_interceptors.h\n //===----------------------------------------------------------------------===//\n \n #include \"sanitizer_common/sanitizer_atomic.h\"\n@@ -18,6 +20,7 @@\n #include \"tsan_platform.h\"\n #include \"tsan_rtl.h\"\n #include \"tsan_mman.h\"\n+#include \"tsan_fd.h\"\n \n using namespace __tsan;  // NOLINT\n \n@@ -50,6 +53,7 @@ extern \"C\" void *pthread_self();\n extern \"C\" void _exit(int status);\n extern \"C\" int __cxa_atexit(void (*func)(void *arg), void *arg, void *dso);\n extern \"C\" int *__errno_location();\n+extern \"C\" int fileno_unlocked(void *stream);\n const int PTHREAD_MUTEX_RECURSIVE = 1;\n const int PTHREAD_MUTEX_RECURSIVE_NP = 1;\n const int kPthreadAttrSize = 56;\n@@ -124,10 +128,8 @@ static SignalContext *SigCtx(ThreadState *thr) {\n   SignalContext *ctx = (SignalContext*)thr->signal_ctx;\n   if (ctx == 0 && thr->is_alive) {\n     ScopedInRtl in_rtl;\n-    ctx = (SignalContext*)internal_alloc(\n-        MBlockSignal, sizeof(*ctx));\n-    MemoryResetRange(thr, 0, (uptr)ctx, sizeof(*ctx));\n-    internal_memset(ctx, 0, sizeof(*ctx));\n+    ctx = (SignalContext*)MmapOrDie(sizeof(*ctx), \"SignalContext\");\n+    MemoryResetRange(thr, (uptr)&SigCtx, (uptr)ctx, sizeof(*ctx));\n     thr->signal_ctx = ctx;\n   }\n   return ctx;\n@@ -173,8 +175,8 @@ ScopedInterceptor::~ScopedInterceptor() {\n     StatInc(thr, StatInt_##func); \\\n     const uptr caller_pc = GET_CALLER_PC(); \\\n     ScopedInterceptor si(thr, #func, caller_pc); \\\n-    /* Subtract one from pc as we need current instruction address */ \\\n-    const uptr pc = __sanitizer::StackTrace::GetCurrentPc() - 1; \\\n+    const uptr pc = __sanitizer::StackTrace::GetPreviousInstructionPc( \\\n+        __sanitizer::StackTrace::GetCurrentPc()); \\\n     (void)pc; \\\n /**/\n \n@@ -306,30 +308,6 @@ TSAN_INTERCEPTOR(void, siglongjmp, void *env, int val) {\n   Die();\n }\n \n-static uptr fd2addr(int fd) {\n-  (void)fd;\n-  static u64 addr;\n-  return (uptr)&addr;\n-}\n-\n-static uptr epollfd2addr(int fd) {\n-  (void)fd;\n-  static u64 addr;\n-  return (uptr)&addr;\n-}\n-\n-static uptr file2addr(char *path) {\n-  (void)path;\n-  static u64 addr;\n-  return (uptr)&addr;\n-}\n-\n-static uptr dir2addr(char *path) {\n-  (void)path;\n-  static u64 addr;\n-  return (uptr)&addr;\n-}\n-\n TSAN_INTERCEPTOR(void*, malloc, uptr size) {\n   void *p = 0;\n   {\n@@ -660,7 +638,7 @@ static void thread_finalize(void *v) {\n     SignalContext *sctx = thr->signal_ctx;\n     if (sctx) {\n       thr->signal_ctx = 0;\n-      internal_free(sctx);\n+      UnmapOrDie(sctx, sizeof(*sctx));\n     }\n   }\n }\n@@ -934,11 +912,15 @@ TSAN_INTERCEPTOR(int, pthread_rwlock_unlock, void *m) {\n   return res;\n }\n \n+// libpthread.so contains several versions of pthread_cond_init symbol.\n+// When we just dlsym() it, we get the wrong (old) version.\n+/*\n TSAN_INTERCEPTOR(int, pthread_cond_init, void *c, void *a) {\n   SCOPED_TSAN_INTERCEPTOR(pthread_cond_init, c, a);\n   int res = REAL(pthread_cond_init)(c, a);\n   return res;\n }\n+*/\n \n TSAN_INTERCEPTOR(int, pthread_cond_destroy, void *c) {\n   SCOPED_TSAN_INTERCEPTOR(pthread_cond_destroy, c);\n@@ -1080,141 +1062,363 @@ TSAN_INTERCEPTOR(int, sem_getvalue, void *s, int *sval) {\n   return res;\n }\n \n+TSAN_INTERCEPTOR(int, open, const char *name, int flags, int mode) {\n+  SCOPED_TSAN_INTERCEPTOR(open, name, flags, mode);\n+  int fd = REAL(open)(name, flags, mode);\n+  if (fd >= 0)\n+    FdFileCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, open64, const char *name, int flags, int mode) {\n+  SCOPED_TSAN_INTERCEPTOR(open64, name, flags, mode);\n+  int fd = REAL(open64)(name, flags, mode);\n+  if (fd >= 0)\n+    FdFileCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, creat, const char *name, int mode) {\n+  SCOPED_TSAN_INTERCEPTOR(creat, name, mode);\n+  int fd = REAL(creat)(name, mode);\n+  if (fd >= 0)\n+    FdFileCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, creat64, const char *name, int mode) {\n+  SCOPED_TSAN_INTERCEPTOR(creat64, name, mode);\n+  int fd = REAL(creat64)(name, mode);\n+  if (fd >= 0)\n+    FdFileCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, dup, int oldfd) {\n+  SCOPED_TSAN_INTERCEPTOR(dup, oldfd);\n+  int newfd = REAL(dup)(oldfd);\n+  if (oldfd >= 0 && newfd >= 0 && newfd != oldfd)\n+    FdDup(thr, pc, oldfd, newfd);\n+  return newfd;\n+}\n+\n+TSAN_INTERCEPTOR(int, dup2, int oldfd, int newfd) {\n+  SCOPED_TSAN_INTERCEPTOR(dup2, oldfd, newfd);\n+  int newfd2 = REAL(dup2)(oldfd, newfd);\n+  if (oldfd >= 0 && newfd2 >= 0 && newfd2 != oldfd)\n+    FdDup(thr, pc, oldfd, newfd2);\n+  return newfd2;\n+}\n+\n+TSAN_INTERCEPTOR(int, dup3, int oldfd, int newfd, int flags) {\n+  SCOPED_TSAN_INTERCEPTOR(dup3, oldfd, newfd, flags);\n+  int newfd2 = REAL(dup3)(oldfd, newfd, flags);\n+  if (oldfd >= 0 && newfd2 >= 0 && newfd2 != oldfd)\n+    FdDup(thr, pc, oldfd, newfd2);\n+  return newfd2;\n+}\n+\n+TSAN_INTERCEPTOR(int, eventfd, unsigned initval, int flags) {\n+  SCOPED_TSAN_INTERCEPTOR(eventfd, initval, flags);\n+  int fd = REAL(eventfd)(initval, flags);\n+  if (fd >= 0)\n+    FdEventCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, signalfd, int fd, void *mask, int flags) {\n+  SCOPED_TSAN_INTERCEPTOR(signalfd, fd, mask, flags);\n+  if (fd >= 0)\n+    FdClose(thr, pc, fd);\n+  fd = REAL(signalfd)(fd, mask, flags);\n+  if (fd >= 0)\n+    FdSignalCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, inotify_init, int fake) {\n+  SCOPED_TSAN_INTERCEPTOR(inotify_init, fake);\n+  int fd = REAL(inotify_init)(fake);\n+  if (fd >= 0)\n+    FdInotifyCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, inotify_init1, int flags) {\n+  SCOPED_TSAN_INTERCEPTOR(inotify_init1, flags);\n+  int fd = REAL(inotify_init1)(flags);\n+  if (fd >= 0)\n+    FdInotifyCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, socket, int domain, int type, int protocol) {\n+  SCOPED_TSAN_INTERCEPTOR(socket, domain, type, protocol);\n+  int fd = REAL(socket)(domain, type, protocol);\n+  if (fd >= 0)\n+    FdSocketCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, socketpair, int domain, int type, int protocol, int *fd) {\n+  SCOPED_TSAN_INTERCEPTOR(socketpair, domain, type, protocol, fd);\n+  int res = REAL(socketpair)(domain, type, protocol, fd);\n+  if (res == 0 && fd[0] >= 0 && fd[1] >= 0)\n+    FdPipeCreate(thr, pc, fd[0], fd[1]);\n+  return res;\n+}\n+\n+TSAN_INTERCEPTOR(int, connect, int fd, void *addr, unsigned addrlen) {\n+  SCOPED_TSAN_INTERCEPTOR(connect, fd, addr, addrlen);\n+  FdSocketConnecting(thr, pc, fd);\n+  int res = REAL(connect)(fd, addr, addrlen);\n+  if (res == 0 && fd >= 0)\n+    FdSocketConnect(thr, pc, fd);\n+  return res;\n+}\n+\n+TSAN_INTERCEPTOR(int, accept, int fd, void *addr, unsigned *addrlen) {\n+  SCOPED_TSAN_INTERCEPTOR(accept, fd, addr, addrlen);\n+  int fd2 = REAL(accept)(fd, addr, addrlen);\n+  if (fd >= 0 && fd2 >= 0)\n+    FdSocketAccept(thr, pc, fd, fd2);\n+  return fd2;\n+}\n+\n+TSAN_INTERCEPTOR(int, accept4, int fd, void *addr, unsigned *addrlen, int f) {\n+  SCOPED_TSAN_INTERCEPTOR(accept4, fd, addr, addrlen, f);\n+  int fd2 = REAL(accept4)(fd, addr, addrlen, f);\n+  if (fd >= 0 && fd2 >= 0)\n+    FdSocketAccept(thr, pc, fd, fd2);\n+  return fd2;\n+}\n+\n+TSAN_INTERCEPTOR(int, epoll_create, int size) {\n+  SCOPED_TSAN_INTERCEPTOR(epoll_create, size);\n+  int fd = REAL(epoll_create)(size);\n+  if (fd >= 0)\n+    FdPollCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, epoll_create1, int flags) {\n+  SCOPED_TSAN_INTERCEPTOR(epoll_create1, flags);\n+  int fd = REAL(epoll_create1)(flags);\n+  if (fd >= 0)\n+    FdPollCreate(thr, pc, fd);\n+  return fd;\n+}\n+\n+TSAN_INTERCEPTOR(int, close, int fd) {\n+  SCOPED_TSAN_INTERCEPTOR(close, fd);\n+  if (fd >= 0)\n+    FdClose(thr, pc, fd);\n+  return REAL(close)(fd);\n+}\n+\n+TSAN_INTERCEPTOR(int, __close, int fd) {\n+  SCOPED_TSAN_INTERCEPTOR(__close, fd);\n+  if (fd >= 0)\n+    FdClose(thr, pc, fd);\n+  return REAL(__close)(fd);\n+}\n+\n+TSAN_INTERCEPTOR(int, pipe, int *pipefd) {\n+  SCOPED_TSAN_INTERCEPTOR(pipe, pipefd);\n+  int res = REAL(pipe)(pipefd);\n+  if (res == 0 && pipefd[0] >= 0 && pipefd[1] >= 0)\n+    FdPipeCreate(thr, pc, pipefd[0], pipefd[1]);\n+  return res;\n+}\n+\n+TSAN_INTERCEPTOR(int, pipe2, int *pipefd, int flags) {\n+  SCOPED_TSAN_INTERCEPTOR(pipe2, pipefd, flags);\n+  int res = REAL(pipe2)(pipefd, flags);\n+  if (res == 0 && pipefd[0] >= 0 && pipefd[1] >= 0)\n+    FdPipeCreate(thr, pc, pipefd[0], pipefd[1]);\n+  return res;\n+}\n+\n TSAN_INTERCEPTOR(long_t, read, int fd, void *buf, long_t sz) {\n   SCOPED_TSAN_INTERCEPTOR(read, fd, buf, sz);\n   int res = REAL(read)(fd, buf, sz);\n-  if (res >= 0) {\n-    Acquire(thr, pc, fd2addr(fd));\n+  if (res >= 0 && fd >= 0) {\n+    FdAcquire(thr, pc, fd);\n   }\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, pread, int fd, void *buf, long_t sz, unsigned off) {\n   SCOPED_TSAN_INTERCEPTOR(pread, fd, buf, sz, off);\n   int res = REAL(pread)(fd, buf, sz, off);\n-  if (res >= 0) {\n-    Acquire(thr, pc, fd2addr(fd));\n+  if (res >= 0 && fd >= 0) {\n+    FdAcquire(thr, pc, fd);\n   }\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, pread64, int fd, void *buf, long_t sz, u64 off) {\n   SCOPED_TSAN_INTERCEPTOR(pread64, fd, buf, sz, off);\n   int res = REAL(pread64)(fd, buf, sz, off);\n-  if (res >= 0) {\n-    Acquire(thr, pc, fd2addr(fd));\n+  if (res >= 0 && fd >= 0) {\n+    FdAcquire(thr, pc, fd);\n   }\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, readv, int fd, void *vec, int cnt) {\n   SCOPED_TSAN_INTERCEPTOR(readv, fd, vec, cnt);\n   int res = REAL(readv)(fd, vec, cnt);\n-  if (res >= 0) {\n-    Acquire(thr, pc, fd2addr(fd));\n+  if (res >= 0 && fd >= 0) {\n+    FdAcquire(thr, pc, fd);\n   }\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, preadv64, int fd, void *vec, int cnt, u64 off) {\n   SCOPED_TSAN_INTERCEPTOR(preadv64, fd, vec, cnt, off);\n   int res = REAL(preadv64)(fd, vec, cnt, off);\n-  if (res >= 0) {\n-    Acquire(thr, pc, fd2addr(fd));\n+  if (res >= 0 && fd >= 0) {\n+    FdAcquire(thr, pc, fd);\n   }\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, write, int fd, void *buf, long_t sz) {\n   SCOPED_TSAN_INTERCEPTOR(write, fd, buf, sz);\n-  Release(thr, pc, fd2addr(fd));\n+  if (fd >= 0)\n+    FdRelease(thr, pc, fd);\n   int res = REAL(write)(fd, buf, sz);\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, pwrite, int fd, void *buf, long_t sz, unsigned off) {\n   SCOPED_TSAN_INTERCEPTOR(pwrite, fd, buf, sz, off);\n-  Release(thr, pc, fd2addr(fd));\n+  if (fd >= 0)\n+    FdRelease(thr, pc, fd);\n   int res = REAL(pwrite)(fd, buf, sz, off);\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, pwrite64, int fd, void *buf, long_t sz, u64 off) {\n   SCOPED_TSAN_INTERCEPTOR(pwrite64, fd, buf, sz, off);\n-  Release(thr, pc, fd2addr(fd));\n+  if (fd >= 0)\n+    FdRelease(thr, pc, fd);\n   int res = REAL(pwrite64)(fd, buf, sz, off);\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, writev, int fd, void *vec, int cnt) {\n   SCOPED_TSAN_INTERCEPTOR(writev, fd, vec, cnt);\n-  Release(thr, pc, fd2addr(fd));\n+  if (fd >= 0)\n+    FdRelease(thr, pc, fd);\n   int res = REAL(writev)(fd, vec, cnt);\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, pwritev64, int fd, void *vec, int cnt, u64 off) {\n   SCOPED_TSAN_INTERCEPTOR(pwritev64, fd, vec, cnt, off);\n-  Release(thr, pc, fd2addr(fd));\n+  if (fd >= 0)\n+    FdRelease(thr, pc, fd);\n   int res = REAL(pwritev64)(fd, vec, cnt, off);\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, send, int fd, void *buf, long_t len, int flags) {\n   SCOPED_TSAN_INTERCEPTOR(send, fd, buf, len, flags);\n-  Release(thr, pc, fd2addr(fd));\n+  if (fd >= 0)\n+    FdRelease(thr, pc, fd);\n   int res = REAL(send)(fd, buf, len, flags);\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, sendmsg, int fd, void *msg, int flags) {\n   SCOPED_TSAN_INTERCEPTOR(sendmsg, fd, msg, flags);\n-  Release(thr, pc, fd2addr(fd));\n+  if (fd >= 0)\n+    FdRelease(thr, pc, fd);\n   int res = REAL(sendmsg)(fd, msg, flags);\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, recv, int fd, void *buf, long_t len, int flags) {\n   SCOPED_TSAN_INTERCEPTOR(recv, fd, buf, len, flags);\n   int res = REAL(recv)(fd, buf, len, flags);\n-  if (res >= 0) {\n-    Acquire(thr, pc, fd2addr(fd));\n+  if (res >= 0 && fd >= 0) {\n+    FdAcquire(thr, pc, fd);\n   }\n   return res;\n }\n \n TSAN_INTERCEPTOR(long_t, recvmsg, int fd, void *msg, int flags) {\n   SCOPED_TSAN_INTERCEPTOR(recvmsg, fd, msg, flags);\n   int res = REAL(recvmsg)(fd, msg, flags);\n-  if (res >= 0) {\n-    Acquire(thr, pc, fd2addr(fd));\n+  if (res >= 0 && fd >= 0) {\n+    FdAcquire(thr, pc, fd);\n   }\n   return res;\n }\n \n TSAN_INTERCEPTOR(int, unlink, char *path) {\n   SCOPED_TSAN_INTERCEPTOR(unlink, path);\n-  Release(thr, pc, file2addr(path));\n+  Release(thr, pc, File2addr(path));\n   int res = REAL(unlink)(path);\n   return res;\n }\n \n TSAN_INTERCEPTOR(void*, fopen, char *path, char *mode) {\n   SCOPED_TSAN_INTERCEPTOR(fopen, path, mode);\n   void *res = REAL(fopen)(path, mode);\n-  Acquire(thr, pc, file2addr(path));\n+  Acquire(thr, pc, File2addr(path));\n+  if (res) {\n+    int fd = fileno_unlocked(res);\n+    if (fd >= 0)\n+      FdFileCreate(thr, pc, fd);\n+  }\n   return res;\n }\n \n+TSAN_INTERCEPTOR(void*, freopen, char *path, char *mode, void *stream) {\n+  SCOPED_TSAN_INTERCEPTOR(freopen, path, mode, stream);\n+  if (stream) {\n+    int fd = fileno_unlocked(stream);\n+    if (fd >= 0)\n+      FdClose(thr, pc, fd);\n+  }\n+  void *res = REAL(freopen)(path, mode, stream);\n+  Acquire(thr, pc, File2addr(path));\n+  if (res) {\n+    int fd = fileno_unlocked(res);\n+    if (fd >= 0)\n+      FdFileCreate(thr, pc, fd);\n+  }\n+  return res;\n+}\n+\n+TSAN_INTERCEPTOR(int, fclose, void *stream) {\n+  {\n+    SCOPED_TSAN_INTERCEPTOR(fclose, stream);\n+    if (stream) {\n+      int fd = fileno_unlocked(stream);\n+      if (fd >= 0)\n+        FdClose(thr, pc, fd);\n+    }\n+  }\n+  return REAL(fclose)(stream);\n+}\n+\n TSAN_INTERCEPTOR(uptr, fread, void *ptr, uptr size, uptr nmemb, void *f) {\n-  SCOPED_TSAN_INTERCEPTOR(fread, ptr, size, nmemb, f);\n-  MemoryAccessRange(thr, pc, (uptr)ptr, size * nmemb, true);\n+  {\n+    SCOPED_TSAN_INTERCEPTOR(fread, ptr, size, nmemb, f);\n+    MemoryAccessRange(thr, pc, (uptr)ptr, size * nmemb, true);\n+  }\n   return REAL(fread)(ptr, size, nmemb, f);\n }\n \n TSAN_INTERCEPTOR(uptr, fwrite, const void *p, uptr size, uptr nmemb, void *f) {\n-  SCOPED_TSAN_INTERCEPTOR(fwrite, p, size, nmemb, f);\n-  MemoryAccessRange(thr, pc, (uptr)p, size * nmemb, false);\n+  {\n+    SCOPED_TSAN_INTERCEPTOR(fwrite, p, size, nmemb, f);\n+    MemoryAccessRange(thr, pc, (uptr)p, size * nmemb, false);\n+  }\n   return REAL(fwrite)(p, size, nmemb, f);\n }\n \n@@ -1226,22 +1430,23 @@ TSAN_INTERCEPTOR(int, puts, const char *s) {\n \n TSAN_INTERCEPTOR(int, rmdir, char *path) {\n   SCOPED_TSAN_INTERCEPTOR(rmdir, path);\n-  Release(thr, pc, dir2addr(path));\n+  Release(thr, pc, Dir2addr(path));\n   int res = REAL(rmdir)(path);\n   return res;\n }\n \n TSAN_INTERCEPTOR(void*, opendir, char *path) {\n   SCOPED_TSAN_INTERCEPTOR(opendir, path);\n   void *res = REAL(opendir)(path);\n-  Acquire(thr, pc, dir2addr(path));\n+  if (res != 0)\n+    Acquire(thr, pc, Dir2addr(path));\n   return res;\n }\n \n TSAN_INTERCEPTOR(int, epoll_ctl, int epfd, int op, int fd, void *ev) {\n   SCOPED_TSAN_INTERCEPTOR(epoll_ctl, epfd, op, fd, ev);\n-  if (op == EPOLL_CTL_ADD) {\n-    Release(thr, pc, epollfd2addr(epfd));\n+  if (op == EPOLL_CTL_ADD && epfd >= 0) {\n+    FdRelease(thr, pc, epfd);\n   }\n   int res = REAL(epoll_ctl)(epfd, op, fd, ev);\n   return res;\n@@ -1250,8 +1455,8 @@ TSAN_INTERCEPTOR(int, epoll_ctl, int epfd, int op, int fd, void *ev) {\n TSAN_INTERCEPTOR(int, epoll_wait, int epfd, void *ev, int cnt, int timeout) {\n   SCOPED_TSAN_INTERCEPTOR(epoll_wait, epfd, ev, cnt, timeout);\n   int res = BLOCK_REAL(epoll_wait)(epfd, ev, cnt, timeout);\n-  if (res > 0) {\n-    Acquire(thr, pc, epollfd2addr(epfd));\n+  if (res > 0 && epfd >= 0) {\n+    FdAcquire(thr, pc, epfd);\n   }\n   return res;\n }\n@@ -1423,6 +1628,19 @@ TSAN_INTERCEPTOR(int, munlockall, void) {\n   return 0;\n }\n \n+TSAN_INTERCEPTOR(int, fork, int fake) {\n+  SCOPED_TSAN_INTERCEPTOR(fork, fake);\n+  // It's intercepted merely to process pending signals.\n+  int pid = REAL(fork)(fake);\n+  if (pid == 0) {\n+    // child\n+    FdOnFork(thr, pc);\n+  } else if (pid > 0) {\n+    // parent\n+  }\n+  return pid;\n+}\n+\n namespace __tsan {\n \n void ProcessPendingSignals(ThreadState *thr) {\n@@ -1545,7 +1763,7 @@ void InitializeInterceptors() {\n   TSAN_INTERCEPT(pthread_rwlock_timedwrlock);\n   TSAN_INTERCEPT(pthread_rwlock_unlock);\n \n-  TSAN_INTERCEPT(pthread_cond_init);\n+  // TSAN_INTERCEPT(pthread_cond_init);\n   TSAN_INTERCEPT(pthread_cond_destroy);\n   TSAN_INTERCEPT(pthread_cond_signal);\n   TSAN_INTERCEPT(pthread_cond_broadcast);\n@@ -1566,6 +1784,28 @@ void InitializeInterceptors() {\n   TSAN_INTERCEPT(sem_post);\n   TSAN_INTERCEPT(sem_getvalue);\n \n+  TSAN_INTERCEPT(open);\n+  TSAN_INTERCEPT(open64);\n+  TSAN_INTERCEPT(creat);\n+  TSAN_INTERCEPT(creat64);\n+  TSAN_INTERCEPT(dup);\n+  TSAN_INTERCEPT(dup2);\n+  TSAN_INTERCEPT(dup3);\n+  TSAN_INTERCEPT(eventfd);\n+  TSAN_INTERCEPT(signalfd);\n+  TSAN_INTERCEPT(inotify_init);\n+  TSAN_INTERCEPT(inotify_init1);\n+  TSAN_INTERCEPT(socket);\n+  TSAN_INTERCEPT(socketpair);\n+  TSAN_INTERCEPT(connect);\n+  TSAN_INTERCEPT(accept);\n+  TSAN_INTERCEPT(accept4);\n+  TSAN_INTERCEPT(epoll_create);\n+  TSAN_INTERCEPT(epoll_create1);\n+  TSAN_INTERCEPT(close);\n+  TSAN_INTERCEPT(pipe);\n+  TSAN_INTERCEPT(pipe2);\n+\n   TSAN_INTERCEPT(read);\n   TSAN_INTERCEPT(pread);\n   TSAN_INTERCEPT(pread64);\n@@ -1583,6 +1823,8 @@ void InitializeInterceptors() {\n \n   TSAN_INTERCEPT(unlink);\n   TSAN_INTERCEPT(fopen);\n+  TSAN_INTERCEPT(freopen);\n+  TSAN_INTERCEPT(fclose);\n   TSAN_INTERCEPT(fread);\n   TSAN_INTERCEPT(fwrite);\n   TSAN_INTERCEPT(puts);\n@@ -1608,6 +1850,8 @@ void InitializeInterceptors() {\n   TSAN_INTERCEPT(mlockall);\n   TSAN_INTERCEPT(munlockall);\n \n+  TSAN_INTERCEPT(fork);\n+\n   // Need to setup it, because interceptors check that the function is resolved.\n   // But atexit is emitted directly into the module, so can't be resolved.\n   REAL(atexit) = (int(*)(void(*)()))unreachable;\n@@ -1623,6 +1867,8 @@ void InitializeInterceptors() {\n     Printf(\"ThreadSanitizer: failed to create thread key\\n\");\n     Die();\n   }\n+\n+  FdInit();\n }\n \n void internal_start_thread(void(*func)(void *arg), void *arg) {"}, {"sha": "770f8bd1014dd26cf8b4dfdc8d8a91fc916e0683", "filename": "libsanitizer/tsan/tsan_interface_atomic.cc", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interface_atomic.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interface_atomic.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface_atomic.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -229,7 +229,7 @@ static T AtomicLoad(ThreadState *thr, uptr pc, const volatile T *a,\n   // Assume the access is atomic.\n   if (!IsAcquireOrder(mo) && sizeof(T) <= sizeof(a))\n     return *a;\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, (uptr)a, false);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, (uptr)a, false);\n   thr->clock.set(thr->tid, thr->fast_state.epoch());\n   thr->clock.acquire(&s->clock);\n   T v = *a;\n@@ -251,7 +251,7 @@ static void AtomicStore(ThreadState *thr, uptr pc, volatile T *a, T v,\n     return;\n   }\n   __sync_synchronize();\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, (uptr)a, true);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, (uptr)a, true);\n   thr->clock.set(thr->tid, thr->fast_state.epoch());\n   thr->clock.ReleaseStore(&s->clock);\n   *a = v;\n@@ -263,7 +263,7 @@ static void AtomicStore(ThreadState *thr, uptr pc, volatile T *a, T v,\n \n template<typename T, T (*F)(volatile T *v, T op)>\n static T AtomicRMW(ThreadState *thr, uptr pc, volatile T *a, T v, morder mo) {\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, (uptr)a, true);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, (uptr)a, true);\n   thr->clock.set(thr->tid, thr->fast_state.epoch());\n   if (IsAcqRelOrder(mo))\n     thr->clock.acq_rel(&s->clock);\n@@ -322,7 +322,7 @@ template<typename T>\n static bool AtomicCAS(ThreadState *thr, uptr pc,\n     volatile T *a, T *c, T v, morder mo, morder fmo) {\n   (void)fmo;  // Unused because llvm does not pass it yet.\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, (uptr)a, true);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, (uptr)a, true);\n   thr->clock.set(thr->tid, thr->fast_state.epoch());\n   if (IsAcqRelOrder(mo))\n     thr->clock.acq_rel(&s->clock);"}, {"sha": "c500614acc4cae36f6ba8976a1727c9818e23dc1", "filename": "libsanitizer/tsan/tsan_interface_atomic.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interface_atomic.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interface_atomic.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface_atomic.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -26,7 +26,7 @@ typedef long     __tsan_atomic64;  // NOLINT\n \n #if defined(__SIZEOF_INT128__) \\\n     || (__clang_major__ * 100 + __clang_minor__ >= 302)\n-typedef __int128 __tsan_atomic128;\n+__extension__ typedef __int128 __tsan_atomic128;\n #define __TSAN_HAS_INT128 1\n #else\n typedef char     __tsan_atomic128;"}, {"sha": "d7325dcb2c4c7e9405f624e255170c0287a70f0b", "filename": "libsanitizer/tsan/tsan_interface_java.cc", "status": "added", "additions": 303, "deletions": 0, "changes": 303, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interface_java.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interface_java.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface_java.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,303 @@\n+//===-- tsan_interface_java.cc --------------------------------------------===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#include \"tsan_interface_java.h\"\n+#include \"tsan_rtl.h\"\n+#include \"tsan_mutex.h\"\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n+#include \"sanitizer_common/sanitizer_placement_new.h\"\n+\n+using namespace __tsan;  // NOLINT\n+\n+namespace __tsan {\n+\n+const uptr kHeapShadow = 0x300000000000ull;\n+const uptr kHeapAlignment = 8;\n+\n+struct BlockDesc {\n+  bool begin;\n+  Mutex mtx;\n+  SyncVar *head;\n+\n+  BlockDesc()\n+      : mtx(MutexTypeJavaMBlock, StatMtxJavaMBlock)\n+      , head() {\n+    CHECK_EQ(begin, false);\n+    begin = true;\n+  }\n+\n+  ~BlockDesc() {\n+    CHECK_EQ(begin, true);\n+    begin = false;\n+    ThreadState *thr = cur_thread();\n+    SyncVar *s = head;\n+    while (s) {\n+      SyncVar *s1 = s->next;\n+      StatInc(thr, StatSyncDestroyed);\n+      s->mtx.Lock();\n+      s->mtx.Unlock();\n+      thr->mset.Remove(s->GetId());\n+      DestroyAndFree(s);\n+      s = s1;\n+    }\n+  }\n+};\n+\n+struct JavaContext {\n+  const uptr heap_begin;\n+  const uptr heap_size;\n+  BlockDesc *heap_shadow;\n+\n+  JavaContext(jptr heap_begin, jptr heap_size)\n+      : heap_begin(heap_begin)\n+      , heap_size(heap_size) {\n+    uptr size = heap_size / kHeapAlignment * sizeof(BlockDesc);\n+    heap_shadow = (BlockDesc*)MmapFixedNoReserve(kHeapShadow, size);\n+    if ((uptr)heap_shadow != kHeapShadow) {\n+      Printf(\"ThreadSanitizer: failed to mmap Java heap shadow\\n\");\n+      Die();\n+    }\n+  }\n+};\n+\n+class ScopedJavaFunc {\n+ public:\n+  ScopedJavaFunc(ThreadState *thr, uptr pc)\n+      : thr_(thr) {\n+    Initialize(thr_);\n+    FuncEntry(thr, pc);\n+    CHECK_EQ(thr_->in_rtl, 0);\n+    thr_->in_rtl++;\n+  }\n+\n+  ~ScopedJavaFunc() {\n+    thr_->in_rtl--;\n+    CHECK_EQ(thr_->in_rtl, 0);\n+    FuncExit(thr_);\n+    // FIXME(dvyukov): process pending signals.\n+  }\n+\n+ private:\n+  ThreadState *thr_;\n+};\n+\n+static u64 jctx_buf[sizeof(JavaContext) / sizeof(u64) + 1];\n+static JavaContext *jctx;\n+\n+static BlockDesc *getblock(uptr addr) {\n+  uptr i = (addr - jctx->heap_begin) / kHeapAlignment;\n+  return &jctx->heap_shadow[i];\n+}\n+\n+static uptr USED getmem(BlockDesc *b) {\n+  uptr i = b - jctx->heap_shadow;\n+  uptr p = jctx->heap_begin + i * kHeapAlignment;\n+  CHECK_GE(p, jctx->heap_begin);\n+  CHECK_LT(p, jctx->heap_begin + jctx->heap_size);\n+  return p;\n+}\n+\n+static BlockDesc *getblockbegin(uptr addr) {\n+  for (BlockDesc *b = getblock(addr);; b--) {\n+    CHECK_GE(b, jctx->heap_shadow);\n+    if (b->begin)\n+      return b;\n+  }\n+  return 0;\n+}\n+\n+SyncVar* GetJavaSync(ThreadState *thr, uptr pc, uptr addr,\n+                     bool write_lock, bool create) {\n+  if (jctx == 0 || addr < jctx->heap_begin\n+      || addr >= jctx->heap_begin + jctx->heap_size)\n+    return 0;\n+  BlockDesc *b = getblockbegin(addr);\n+  DPrintf(\"#%d: GetJavaSync %p->%p\\n\", thr->tid, addr, b);\n+  Lock l(&b->mtx);\n+  SyncVar *s = b->head;\n+  for (; s; s = s->next) {\n+    if (s->addr == addr) {\n+      DPrintf(\"#%d: found existing sync for %p\\n\", thr->tid, addr);\n+      break;\n+    }\n+  }\n+  if (s == 0 && create) {\n+    DPrintf(\"#%d: creating new sync for %p\\n\", thr->tid, addr);\n+    s = CTX()->synctab.Create(thr, pc, addr);\n+    s->next = b->head;\n+    b->head = s;\n+  }\n+  if (s) {\n+    if (write_lock)\n+      s->mtx.Lock();\n+    else\n+      s->mtx.ReadLock();\n+  }\n+  return s;\n+}\n+\n+SyncVar* GetAndRemoveJavaSync(ThreadState *thr, uptr pc, uptr addr) {\n+  // We do not destroy Java mutexes other than in __tsan_java_free().\n+  return 0;\n+}\n+\n+}  // namespace __tsan {\n+\n+#define SCOPED_JAVA_FUNC(func) \\\n+  ThreadState *thr = cur_thread(); \\\n+  const uptr caller_pc = GET_CALLER_PC(); \\\n+  const uptr pc = (uptr)&func; \\\n+  (void)pc; \\\n+  ScopedJavaFunc scoped(thr, caller_pc); \\\n+/**/\n+\n+void __tsan_java_init(jptr heap_begin, jptr heap_size) {\n+  SCOPED_JAVA_FUNC(__tsan_java_init);\n+  DPrintf(\"#%d: java_init(%p, %p)\\n\", thr->tid, heap_begin, heap_size);\n+  CHECK_EQ(jctx, 0);\n+  CHECK_GT(heap_begin, 0);\n+  CHECK_GT(heap_size, 0);\n+  CHECK_EQ(heap_begin % kHeapAlignment, 0);\n+  CHECK_EQ(heap_size % kHeapAlignment, 0);\n+  CHECK_LT(heap_begin, heap_begin + heap_size);\n+  jctx = new(jctx_buf) JavaContext(heap_begin, heap_size);\n+}\n+\n+int  __tsan_java_fini() {\n+  SCOPED_JAVA_FUNC(__tsan_java_fini);\n+  DPrintf(\"#%d: java_fini()\\n\", thr->tid);\n+  CHECK_NE(jctx, 0);\n+  // FIXME(dvyukov): this does not call atexit() callbacks.\n+  int status = Finalize(thr);\n+  DPrintf(\"#%d: java_fini() = %d\\n\", thr->tid, status);\n+  return status;\n+}\n+\n+void __tsan_java_alloc(jptr ptr, jptr size) {\n+  SCOPED_JAVA_FUNC(__tsan_java_alloc);\n+  DPrintf(\"#%d: java_alloc(%p, %p)\\n\", thr->tid, ptr, size);\n+  CHECK_NE(jctx, 0);\n+  CHECK_NE(size, 0);\n+  CHECK_EQ(ptr % kHeapAlignment, 0);\n+  CHECK_EQ(size % kHeapAlignment, 0);\n+  CHECK_GE(ptr, jctx->heap_begin);\n+  CHECK_LE(ptr + size, jctx->heap_begin + jctx->heap_size);\n+\n+  BlockDesc *b = getblock(ptr);\n+  new(b) BlockDesc();\n+}\n+\n+void __tsan_java_free(jptr ptr, jptr size) {\n+  SCOPED_JAVA_FUNC(__tsan_java_free);\n+  DPrintf(\"#%d: java_free(%p, %p)\\n\", thr->tid, ptr, size);\n+  CHECK_NE(jctx, 0);\n+  CHECK_NE(size, 0);\n+  CHECK_EQ(ptr % kHeapAlignment, 0);\n+  CHECK_EQ(size % kHeapAlignment, 0);\n+  CHECK_GE(ptr, jctx->heap_begin);\n+  CHECK_LE(ptr + size, jctx->heap_begin + jctx->heap_size);\n+\n+  BlockDesc *beg = getblock(ptr);\n+  BlockDesc *end = getblock(ptr + size);\n+  for (BlockDesc *b = beg; b != end; b++) {\n+    if (b->begin)\n+      b->~BlockDesc();\n+  }\n+}\n+\n+void __tsan_java_move(jptr src, jptr dst, jptr size) {\n+  SCOPED_JAVA_FUNC(__tsan_java_move);\n+  DPrintf(\"#%d: java_move(%p, %p, %p)\\n\", thr->tid, src, dst, size);\n+  CHECK_NE(jctx, 0);\n+  CHECK_NE(size, 0);\n+  CHECK_EQ(src % kHeapAlignment, 0);\n+  CHECK_EQ(dst % kHeapAlignment, 0);\n+  CHECK_EQ(size % kHeapAlignment, 0);\n+  CHECK_GE(src, jctx->heap_begin);\n+  CHECK_LE(src + size, jctx->heap_begin + jctx->heap_size);\n+  CHECK_GE(dst, jctx->heap_begin);\n+  CHECK_LE(dst + size, jctx->heap_begin + jctx->heap_size);\n+  CHECK(dst >= src + size || src >= dst + size);\n+\n+  // Assuming it's not running concurrently with threads that do\n+  // memory accesses and mutex operations (stop-the-world phase).\n+  {  // NOLINT\n+    BlockDesc *s = getblock(src);\n+    BlockDesc *d = getblock(dst);\n+    BlockDesc *send = getblock(src + size);\n+    for (; s != send; s++, d++) {\n+      CHECK_EQ(d->begin, false);\n+      if (s->begin) {\n+        DPrintf(\"#%d: moving block %p->%p\\n\", thr->tid, getmem(s), getmem(d));\n+        new(d) BlockDesc;\n+        d->head = s->head;\n+        for (SyncVar *sync = d->head; sync; sync = sync->next) {\n+          uptr newaddr = sync->addr - src + dst;\n+          DPrintf(\"#%d: moving sync %p->%p\\n\", thr->tid, sync->addr, newaddr);\n+          sync->addr = newaddr;\n+        }\n+        s->head = 0;\n+        s->~BlockDesc();\n+      }\n+    }\n+  }\n+\n+  {  // NOLINT\n+    u64 *s = (u64*)MemToShadow(src);\n+    u64 *d = (u64*)MemToShadow(dst);\n+    u64 *send = (u64*)MemToShadow(src + size);\n+    for (; s != send; s++, d++) {\n+      *d = *s;\n+      *s = 0;\n+    }\n+  }\n+}\n+\n+void __tsan_java_mutex_lock(jptr addr) {\n+  SCOPED_JAVA_FUNC(__tsan_java_mutex_lock);\n+  DPrintf(\"#%d: java_mutex_lock(%p)\\n\", thr->tid, addr);\n+  CHECK_NE(jctx, 0);\n+  CHECK_GE(addr, jctx->heap_begin);\n+  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+\n+  MutexLock(thr, pc, addr);\n+}\n+\n+void __tsan_java_mutex_unlock(jptr addr) {\n+  SCOPED_JAVA_FUNC(__tsan_java_mutex_unlock);\n+  DPrintf(\"#%d: java_mutex_unlock(%p)\\n\", thr->tid, addr);\n+  CHECK_NE(jctx, 0);\n+  CHECK_GE(addr, jctx->heap_begin);\n+  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+\n+  MutexUnlock(thr, pc, addr);\n+}\n+\n+void __tsan_java_mutex_read_lock(jptr addr) {\n+  SCOPED_JAVA_FUNC(__tsan_java_mutex_read_lock);\n+  DPrintf(\"#%d: java_mutex_read_lock(%p)\\n\", thr->tid, addr);\n+  CHECK_NE(jctx, 0);\n+  CHECK_GE(addr, jctx->heap_begin);\n+  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+\n+  MutexReadLock(thr, pc, addr);\n+}\n+\n+void __tsan_java_mutex_read_unlock(jptr addr) {\n+  SCOPED_JAVA_FUNC(__tsan_java_mutex_read_unlock);\n+  DPrintf(\"#%d: java_mutex_read_unlock(%p)\\n\", thr->tid, addr);\n+  CHECK_NE(jctx, 0);\n+  CHECK_GE(addr, jctx->heap_begin);\n+  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+\n+  MutexReadUnlock(thr, pc, addr);\n+}"}, {"sha": "01922bc923193d375686e3f4d9fe865b6856eab9", "filename": "libsanitizer/tsan/tsan_interface_java.h", "status": "added", "additions": 72, "deletions": 0, "changes": 72, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interface_java.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_interface_java.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface_java.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,72 @@\n+//===-- tsan_interface_java.h -----------------------------------*- C++ -*-===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+// Interface for verification of Java or mixed Java/C++ programs.\n+// The interface is intended to be used from within a JVM and notify TSan\n+// about such events like Java locks and GC memory compaction.\n+//\n+// For plain memory accesses and function entry/exit a JVM is intended to use\n+// C++ interfaces: __tsan_readN/writeN and __tsan_func_enter/exit.\n+//\n+// For volatile memory accesses and atomic operations JVM is intended to use\n+// standard atomics API: __tsan_atomicN_load/store/etc.\n+//\n+// For usage examples see lit_tests/java_*.cc\n+//===----------------------------------------------------------------------===//\n+#ifndef TSAN_INTERFACE_JAVA_H\n+#define TSAN_INTERFACE_JAVA_H\n+\n+#ifndef INTERFACE_ATTRIBUTE\n+# define INTERFACE_ATTRIBUTE __attribute__((visibility(\"default\")))\n+#endif\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+typedef unsigned long jptr;  // NOLINT\n+\n+// Must be called before any other callback from Java.\n+void __tsan_java_init(jptr heap_begin, jptr heap_size) INTERFACE_ATTRIBUTE;\n+// Must be called when the application exits.\n+// Not necessary the last callback (concurrently running threads are OK).\n+// Returns exit status or 0 if tsan does not want to override it.\n+int  __tsan_java_fini() INTERFACE_ATTRIBUTE;\n+\n+// Callback for memory allocations.\n+// May be omitted for allocations that are not subject to data races\n+// nor contain synchronization objects (e.g. String).\n+void __tsan_java_alloc(jptr ptr, jptr size) INTERFACE_ATTRIBUTE;\n+// Callback for memory free.\n+// Can be aggregated for several objects (preferably).\n+void __tsan_java_free(jptr ptr, jptr size) INTERFACE_ATTRIBUTE;\n+// Callback for memory move by GC.\n+// Can be aggregated for several objects (preferably).\n+// The ranges must not overlap.\n+void __tsan_java_move(jptr src, jptr dst, jptr size) INTERFACE_ATTRIBUTE;\n+\n+// Mutex lock.\n+// Addr is any unique address associated with the mutex.\n+// Must not be called on recursive reentry.\n+// Object.wait() is handled as a pair of unlock/lock.\n+void __tsan_java_mutex_lock(jptr addr) INTERFACE_ATTRIBUTE;\n+// Mutex unlock.\n+void __tsan_java_mutex_unlock(jptr addr) INTERFACE_ATTRIBUTE;\n+// Mutex read lock.\n+void __tsan_java_mutex_read_lock(jptr addr) INTERFACE_ATTRIBUTE;\n+// Mutex read unlock.\n+void __tsan_java_mutex_read_unlock(jptr addr) INTERFACE_ATTRIBUTE;\n+\n+#ifdef __cplusplus\n+}  // extern \"C\"\n+#endif\n+\n+#undef INTERFACE_ATTRIBUTE\n+\n+#endif  // #ifndef TSAN_INTERFACE_JAVA_H"}, {"sha": "9a8a524f2622036a4a19d63ba855dbf001efed81", "filename": "libsanitizer/tsan/tsan_mman.cc", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mman.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mman.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mman.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -58,8 +58,9 @@ void *user_alloc(ThreadState *thr, uptr pc, uptr sz, uptr align) {\n   void *p = allocator()->Allocate(&thr->alloc_cache, sz, align);\n   if (p == 0)\n     return 0;\n-  MBlock *b = (MBlock*)allocator()->GetMetaData(p);\n+  MBlock *b = new(allocator()->GetMetaData(p)) MBlock;\n   b->size = sz;\n+  b->head = 0;\n   b->alloc_tid = thr->unique_id;\n   b->alloc_stack_id = CurrentStackId(thr, pc);\n   if (CTX() && CTX()->initialized) {\n@@ -90,6 +91,7 @@ void user_free(ThreadState *thr, uptr pc, void *p) {\n   if (CTX() && CTX()->initialized && thr->in_rtl == 1) {\n     MemoryRangeFreed(thr, pc, (uptr)p, b->size);\n   }\n+  b->~MBlock();\n   allocator()->Deallocate(&thr->alloc_cache, p);\n   SignalUnsafeCall(thr, pc);\n }\n@@ -115,9 +117,11 @@ void *user_realloc(ThreadState *thr, uptr pc, void *p, uptr sz) {\n }\n \n MBlock *user_mblock(ThreadState *thr, void *p) {\n-  // CHECK_GT(thr->in_rtl, 0);\n   CHECK_NE(p, (void*)0);\n-  return (MBlock*)allocator()->GetMetaData(p);\n+  Allocator *a = allocator();\n+  void *b = a->GetBlockBegin(p);\n+  CHECK_NE(b, 0);\n+  return (MBlock*)a->GetMetaData(b);\n }\n \n void invoke_malloc_hook(void *ptr, uptr size) {"}, {"sha": "8697d228730800d8b5acf2dba77e191c13e09a8b", "filename": "libsanitizer/tsan/tsan_mman.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mman.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mman.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mman.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -57,6 +57,7 @@ enum MBlockType {\n   MBlockSuppression,\n   MBlockExpectRace,\n   MBlockSignal,\n+  MBlockFD,\n \n   // This must be the last.\n   MBlockTypeCount"}, {"sha": "716722b0897b62e51ab6869936b6ae575a6c17ee", "filename": "libsanitizer/tsan/tsan_mutex.cc", "status": "modified", "additions": 20, "deletions": 9, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mutex.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mutex.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mutex.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -23,22 +23,28 @@ namespace __tsan {\n // then Report mutex can be locked while under Threads mutex.\n // The leaf mutexes can be locked under any other mutexes.\n // Recursive locking is not supported.\n+#if TSAN_DEBUG && !TSAN_GO\n const MutexType MutexTypeLeaf = (MutexType)-1;\n static MutexType CanLockTab[MutexTypeCount][MutexTypeCount] = {\n-  /*0 MutexTypeInvalid*/     {},\n-  /*1 MutexTypeTrace*/       {MutexTypeLeaf},\n-  /*2 MutexTypeThreads*/     {MutexTypeReport},\n-  /*3 MutexTypeReport*/      {},\n-  /*4 MutexTypeSyncVar*/     {},\n-  /*5 MutexTypeSyncTab*/     {MutexTypeSyncVar},\n-  /*6 MutexTypeSlab*/        {MutexTypeLeaf},\n-  /*7 MutexTypeAnnotations*/ {},\n-  /*8 MutexTypeAtExit*/      {MutexTypeSyncTab},\n+  /*0  MutexTypeInvalid*/     {},\n+  /*1  MutexTypeTrace*/       {MutexTypeLeaf},\n+  /*2  MutexTypeThreads*/     {MutexTypeReport},\n+  /*3  MutexTypeReport*/      {MutexTypeSyncTab, MutexTypeMBlock,\n+                               MutexTypeJavaMBlock},\n+  /*4  MutexTypeSyncVar*/     {},\n+  /*5  MutexTypeSyncTab*/     {MutexTypeSyncVar},\n+  /*6  MutexTypeSlab*/        {MutexTypeLeaf},\n+  /*7  MutexTypeAnnotations*/ {},\n+  /*8  MutexTypeAtExit*/      {MutexTypeSyncTab},\n+  /*9  MutexTypeMBlock*/      {MutexTypeSyncVar},\n+  /*10 MutexTypeJavaMBlock*/  {MutexTypeSyncVar},\n };\n \n static bool CanLockAdj[MutexTypeCount][MutexTypeCount];\n+#endif\n \n void InitializeMutex() {\n+#if TSAN_DEBUG && !TSAN_GO\n   // Build the \"can lock\" adjacency matrix.\n   // If [i][j]==true, then one can lock mutex j while under mutex i.\n   const int N = MutexTypeCount;\n@@ -112,14 +118,18 @@ void InitializeMutex() {\n       Die();\n     }\n   }\n+#endif\n }\n \n DeadlockDetector::DeadlockDetector() {\n   // Rely on zero initialization because some mutexes can be locked before ctor.\n }\n \n+#if TSAN_DEBUG && !TSAN_GO\n void DeadlockDetector::Lock(MutexType t) {\n   // Printf(\"LOCK %d @%zu\\n\", t, seq_ + 1);\n+  CHECK_GT(t, MutexTypeInvalid);\n+  CHECK_LT(t, MutexTypeCount);\n   u64 max_seq = 0;\n   u64 max_idx = MutexTypeInvalid;\n   for (int i = 0; i != MutexTypeCount; i++) {\n@@ -148,6 +158,7 @@ void DeadlockDetector::Unlock(MutexType t) {\n   CHECK(locked_[t]);\n   locked_[t] = 0;\n }\n+#endif\n \n const uptr kUnlocked = 0;\n const uptr kWriteLock = 1;"}, {"sha": "6d1450593301d6bd0129b855d48ad38154563f19", "filename": "libsanitizer/tsan/tsan_mutex.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mutex.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mutex.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mutex.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -27,6 +27,8 @@ enum MutexType {\n   MutexTypeSlab,\n   MutexTypeAnnotations,\n   MutexTypeAtExit,\n+  MutexTypeMBlock,\n+  MutexTypeJavaMBlock,\n \n   // This must be the last.\n   MutexTypeCount"}, {"sha": "3ebae3a57bc07a815548522d8e6e086c26d136b7", "filename": "libsanitizer/tsan/tsan_mutexset.cc", "status": "added", "additions": 87, "deletions": 0, "changes": 87, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mutexset.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mutexset.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mutexset.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,87 @@\n+//===-- tsan_mutexset.cc --------------------------------------------------===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+//===----------------------------------------------------------------------===//\n+#include \"tsan_mutexset.h\"\n+#include \"tsan_rtl.h\"\n+\n+namespace __tsan {\n+\n+const uptr MutexSet::kMaxSize;\n+\n+MutexSet::MutexSet() {\n+  size_ = 0;\n+  internal_memset(&descs_, 0, sizeof(descs_));\n+}\n+\n+void MutexSet::Add(u64 id, bool write, u64 epoch) {\n+  // Look up existing mutex with the same id.\n+  for (uptr i = 0; i < size_; i++) {\n+    if (descs_[i].id == id) {\n+      descs_[i].count++;\n+      descs_[i].epoch = epoch;\n+      return;\n+    }\n+  }\n+  // On overflow, find the oldest mutex and drop it.\n+  if (size_ == kMaxSize) {\n+    u64 minepoch = (u64)-1;\n+    u64 mini = (u64)-1;\n+    for (uptr i = 0; i < size_; i++) {\n+      if (descs_[i].epoch < minepoch) {\n+        minepoch = descs_[i].epoch;\n+        mini = i;\n+      }\n+    }\n+    RemovePos(mini);\n+    CHECK_EQ(size_, kMaxSize - 1);\n+  }\n+  // Add new mutex descriptor.\n+  descs_[size_].id = id;\n+  descs_[size_].write = write;\n+  descs_[size_].epoch = epoch;\n+  descs_[size_].count = 1;\n+  size_++;\n+}\n+\n+void MutexSet::Del(u64 id, bool write) {\n+  for (uptr i = 0; i < size_; i++) {\n+    if (descs_[i].id == id) {\n+      if (--descs_[i].count == 0)\n+        RemovePos(i);\n+      return;\n+    }\n+  }\n+}\n+\n+void MutexSet::Remove(u64 id) {\n+  for (uptr i = 0; i < size_; i++) {\n+    if (descs_[i].id == id) {\n+      RemovePos(i);\n+      return;\n+    }\n+  }\n+}\n+\n+void MutexSet::RemovePos(uptr i) {\n+  CHECK_LT(i, size_);\n+  descs_[i] = descs_[size_ - 1];\n+  size_--;\n+}\n+\n+uptr MutexSet::Size() const {\n+  return size_;\n+}\n+\n+MutexSet::Desc MutexSet::Get(uptr i) const {\n+  CHECK_LT(i, size_);\n+  return descs_[i];\n+}\n+\n+}  // namespace __tsan"}, {"sha": "6924eade4c647ca840d9dc6a3462df868d23470d", "filename": "libsanitizer/tsan/tsan_mutexset.h", "status": "added", "additions": 63, "deletions": 0, "changes": 63, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mutexset.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_mutexset.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mutexset.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -0,0 +1,63 @@\n+//===-- tsan_mutexset.h -----------------------------------------*- C++ -*-===//\n+//\n+// This file is distributed under the University of Illinois Open Source\n+// License. See LICENSE.TXT for details.\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+// MutexSet holds the set of mutexes currently held by a thread.\n+//===----------------------------------------------------------------------===//\n+#ifndef TSAN_MUTEXSET_H\n+#define TSAN_MUTEXSET_H\n+\n+#include \"tsan_defs.h\"\n+\n+namespace __tsan {\n+\n+class MutexSet {\n+ public:\n+  // Holds limited number of mutexes.\n+  // The oldest mutexes are discarded on overflow.\n+  static const uptr kMaxSize = 64;\n+  struct Desc {\n+    u64 id;\n+    u64 epoch;\n+    int count;\n+    bool write;\n+  };\n+\n+  MutexSet();\n+  // The 'id' is obtained from SyncVar::GetId().\n+  void Add(u64 id, bool write, u64 epoch);\n+  void Del(u64 id, bool write);\n+  void Remove(u64 id);  // Removes the mutex completely (if it's destroyed).\n+  uptr Size() const;\n+  Desc Get(uptr i) const;\n+\n+ private:\n+#ifndef TSAN_GO\n+  uptr size_;\n+  Desc descs_[kMaxSize];\n+#endif\n+\n+  void RemovePos(uptr i);\n+};\n+\n+// Go does not have mutexes, so do not spend memory and time.\n+// (Go sync.Mutex is actually a semaphore -- can be unlocked\n+// in different goroutine).\n+#ifdef TSAN_GO\n+MutexSet::MutexSet() {}\n+void MutexSet::Add(u64 id, bool write, u64 epoch) {}\n+void MutexSet::Del(u64 id, bool write) {}\n+void MutexSet::Remove(u64 id) {}\n+void MutexSet::RemovePos(uptr i) {}\n+uptr MutexSet::Size() const { return 0; }\n+MutexSet::Desc MutexSet::Get(uptr i) const { return Desc(); }\n+#endif\n+\n+}  // namespace __tsan\n+\n+#endif  // TSAN_REPORT_H"}, {"sha": "9fdc4dd46e7a5dd4018336894dfdf411a53e9bbc", "filename": "libsanitizer/tsan/tsan_platform.h", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_platform.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_platform.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_platform.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -135,7 +135,6 @@ void FlushShadowMemory();\n \n const char *InitializePlatform();\n void FinalizePlatform();\n-void MapThreadTrace(uptr addr, uptr size);\n uptr ALWAYS_INLINE INLINE GetThreadTrace(int tid) {\n   uptr p = kTraceMemBegin + (uptr)tid * kTraceSize * sizeof(Event);\n   DCHECK_LT(p, kTraceMemBegin + kTraceMemSize);"}, {"sha": "2e7cd5138d6c12907e8205ab4068ceed050f9981", "filename": "libsanitizer/tsan/tsan_platform_linux.cc", "status": "modified", "additions": 33, "deletions": 43, "changes": 76, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_platform_linux.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_platform_linux.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_platform_linux.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -69,9 +69,7 @@ uptr GetShadowMemoryConsumption() {\n }\n \n void FlushShadowMemory() {\n-  madvise((void*)kLinuxShadowBeg,\n-          kLinuxShadowEnd - kLinuxShadowBeg,\n-          MADV_DONTNEED);\n+  FlushUnneededShadowMemory(kLinuxShadowBeg, kLinuxShadowEnd - kLinuxShadowBeg);\n }\n \n #ifndef TSAN_GO\n@@ -118,16 +116,6 @@ void InitializeShadowMemory() {\n }\n #endif\n \n-void MapThreadTrace(uptr addr, uptr size) {\n-  DPrintf(\"Mapping trace at %p-%p(0x%zx)\\n\", addr, addr + size, size);\n-  CHECK_GE(addr, kTraceMemBegin);\n-  CHECK_LE(addr + size, kTraceMemBegin + kTraceMemSize);\n-  if (addr != (uptr)MmapFixedNoReserve(addr, size)) {\n-    Printf(\"FATAL: ThreadSanitizer can not mmap thread trace\\n\");\n-    Die();\n-  }\n-}\n-\n static uptr g_data_start;\n static uptr g_data_end;\n \n@@ -180,18 +168,14 @@ static uptr g_tls_size;\n #else\n # define INTERNAL_FUNCTION\n #endif\n-extern \"C\" void _dl_get_tls_static_info(size_t*, size_t*)\n-    __attribute__((weak)) INTERNAL_FUNCTION;\n \n static int InitTlsSize() {\n   typedef void (*get_tls_func)(size_t*, size_t*) INTERNAL_FUNCTION;\n-  get_tls_func get_tls = &_dl_get_tls_static_info;\n-  if (get_tls == 0) {\n-    void *get_tls_static_info_ptr = dlsym(RTLD_NEXT, \"_dl_get_tls_static_info\");\n-    CHECK_EQ(sizeof(get_tls), sizeof(get_tls_static_info_ptr));\n-    internal_memcpy(&get_tls, &get_tls_static_info_ptr,\n-                    sizeof(get_tls_static_info_ptr));\n-  }\n+  get_tls_func get_tls;\n+  void *get_tls_static_info_ptr = dlsym(RTLD_NEXT, \"_dl_get_tls_static_info\");\n+  CHECK_EQ(sizeof(get_tls), sizeof(get_tls_static_info_ptr));\n+  internal_memcpy(&get_tls, &get_tls_static_info_ptr,\n+                  sizeof(get_tls_static_info_ptr));\n   CHECK_NE(get_tls, 0);\n   size_t tls_size = 0;\n   size_t tls_align = 0;\n@@ -220,29 +204,35 @@ const char *InitializePlatform() {\n     // Disable core dumps, dumping of 16TB usually takes a bit long.\n     setlim(RLIMIT_CORE, 0);\n   }\n-  bool reexec = false;\n-  // TSan doesn't play well with unlimited stack size (as stack\n-  // overlaps with shadow memory). If we detect unlimited stack size,\n-  // we re-exec the program with limited stack size as a best effort.\n-  if (getlim(RLIMIT_STACK) == (rlim_t)-1) {\n-    const uptr kMaxStackSize = 32 * 1024 * 1024;\n-    Report(\"WARNING: Program is run with unlimited stack size, which \"\n-           \"wouldn't work with ThreadSanitizer.\\n\");\n-    Report(\"Re-execing with stack size limited to %zd bytes.\\n\", kMaxStackSize);\n-    SetStackSizeLimitInBytes(kMaxStackSize);\n-    reexec = true;\n-  }\n \n-  if (getlim(RLIMIT_AS) != (rlim_t)-1) {\n-    Report(\"WARNING: Program is run with limited virtual address space, which \"\n-           \"wouldn't work with ThreadSanitizer.\\n\");\n-    Report(\"Re-execing with unlimited virtual address space.\\n\");\n-    setlim(RLIMIT_AS, -1);\n-    reexec = true;\n-  }\n+  // Go maps shadow memory lazily and works fine with limited address space.\n+  // Unlimited stack is not a problem as well, because the executable\n+  // is not compiled with -pie.\n+  if (kCppMode) {\n+    bool reexec = false;\n+    // TSan doesn't play well with unlimited stack size (as stack\n+    // overlaps with shadow memory). If we detect unlimited stack size,\n+    // we re-exec the program with limited stack size as a best effort.\n+    if (getlim(RLIMIT_STACK) == (rlim_t)-1) {\n+      const uptr kMaxStackSize = 32 * 1024 * 1024;\n+      Report(\"WARNING: Program is run with unlimited stack size, which \"\n+             \"wouldn't work with ThreadSanitizer.\\n\");\n+      Report(\"Re-execing with stack size limited to %zd bytes.\\n\",\n+             kMaxStackSize);\n+      SetStackSizeLimitInBytes(kMaxStackSize);\n+      reexec = true;\n+    }\n \n-  if (reexec)\n-    ReExec();\n+    if (getlim(RLIMIT_AS) != (rlim_t)-1) {\n+      Report(\"WARNING: Program is run with limited virtual address space,\"\n+             \" which wouldn't work with ThreadSanitizer.\\n\");\n+      Report(\"Re-execing with unlimited virtual address space.\\n\");\n+      setlim(RLIMIT_AS, -1);\n+      reexec = true;\n+    }\n+    if (reexec)\n+      ReExec();\n+  }\n \n #ifndef TSAN_GO\n   CheckPIE();"}, {"sha": "ca35266290251874b257ec0785c4795de43cc7b0", "filename": "libsanitizer/tsan/tsan_report.cc", "status": "modified", "additions": 49, "deletions": 20, "changes": 69, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_report.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_report.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_report.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -23,12 +23,24 @@ ReportDesc::ReportDesc()\n     , sleep() {\n }\n \n+ReportMop::ReportMop()\n+    : mset(MBlockReportMutex) {\n+}\n+\n ReportDesc::~ReportDesc() {\n   // FIXME(dvyukov): it must be leaking a lot of memory.\n }\n \n #ifndef TSAN_GO\n \n+const int kThreadBufSize = 32;\n+const char *thread_name(char *buf, int tid) {\n+  if (tid == 0)\n+    return \"main thread\";\n+  internal_snprintf(buf, kThreadBufSize, \"thread T%d\", tid);\n+  return buf;\n+}\n+\n static void PrintHeader(ReportType typ) {\n   Printf(\"WARNING: ThreadSanitizer: \");\n \n@@ -65,52 +77,69 @@ void PrintStack(const ReportStack *ent) {\n   Printf(\"\\n\");\n }\n \n+static void PrintMutexSet(Vector<ReportMopMutex> const& mset) {\n+  for (uptr i = 0; i < mset.Size(); i++) {\n+    if (i == 0)\n+      Printf(\" (mutexes:\");\n+    const ReportMopMutex m = mset[i];\n+    Printf(\" %s M%llu\", m.write ? \"write\" : \"read\", m.id);\n+    Printf(i == mset.Size() - 1 ? \")\" : \",\");\n+  }\n+}\n+\n static void PrintMop(const ReportMop *mop, bool first) {\n-  Printf(\"  %s of size %d at %p\",\n+  char thrbuf[kThreadBufSize];\n+  Printf(\"  %s of size %d at %p by %s\",\n       (first ? (mop->write ? \"Write\" : \"Read\")\n              : (mop->write ? \"Previous write\" : \"Previous read\")),\n-      mop->size, (void*)mop->addr);\n-  if (mop->tid == 0)\n-    Printf(\" by main thread:\\n\");\n-  else\n-    Printf(\" by thread %d:\\n\", mop->tid);\n+      mop->size, (void*)mop->addr,\n+      thread_name(thrbuf, mop->tid));\n+  PrintMutexSet(mop->mset);\n+  Printf(\":\\n\");\n   PrintStack(mop->stack);\n }\n \n static void PrintLocation(const ReportLocation *loc) {\n+  char thrbuf[kThreadBufSize];\n   if (loc->type == ReportLocationGlobal) {\n     Printf(\"  Location is global '%s' of size %zu at %zx %s:%d (%s+%p)\\n\\n\",\n                loc->name, loc->size, loc->addr, loc->file, loc->line,\n                loc->module, loc->offset);\n   } else if (loc->type == ReportLocationHeap) {\n-    Printf(\"  Location is heap block of size %zu at %p allocated\",\n-        loc->size, loc->addr);\n-    if (loc->tid == 0)\n-      Printf(\" by main thread:\\n\");\n-    else\n-      Printf(\" by thread %d:\\n\", loc->tid);\n+    char thrbuf[kThreadBufSize];\n+    Printf(\"  Location is heap block of size %zu at %p allocated by %s:\\n\",\n+        loc->size, loc->addr, thread_name(thrbuf, loc->tid));\n     PrintStack(loc->stack);\n   } else if (loc->type == ReportLocationStack) {\n-    Printf(\"  Location is stack of thread %d:\\n\\n\", loc->tid);\n+    Printf(\"  Location is stack of %s\\n\\n\", thread_name(thrbuf, loc->tid));\n+  } else if (loc->type == ReportLocationFD) {\n+    Printf(\"  Location is file descriptor %d created by %s at:\\n\",\n+        loc->fd, thread_name(thrbuf, loc->tid));\n+    PrintStack(loc->stack);\n   }\n }\n \n static void PrintMutex(const ReportMutex *rm) {\n-  if (rm->stack == 0)\n-    return;\n-  Printf(\"  Mutex %d created at:\\n\", rm->id);\n-  PrintStack(rm->stack);\n+  if (rm->destroyed) {\n+    Printf(\"  Mutex M%llu is already destroyed.\\n\\n\", rm->id);\n+  } else {\n+    Printf(\"  Mutex M%llu created at:\\n\", rm->id);\n+    PrintStack(rm->stack);\n+  }\n }\n \n static void PrintThread(const ReportThread *rt) {\n   if (rt->id == 0)  // Little sense in describing the main thread.\n     return;\n-  Printf(\"  Thread %d\", rt->id);\n+  Printf(\"  Thread T%d\", rt->id);\n   if (rt->name)\n     Printf(\" '%s'\", rt->name);\n-  Printf(\" (tid=%zu, %s)\", rt->pid, rt->running ? \"running\" : \"finished\");\n+  char thrbuf[kThreadBufSize];\n+  Printf(\" (tid=%zu, %s) created by %s\",\n+    rt->pid, rt->running ? \"running\" : \"finished\",\n+    thread_name(thrbuf, rt->parent_tid));\n   if (rt->stack)\n-    Printf(\" created at:\");\n+    Printf(\" at:\");\n   Printf(\"\\n\");\n   PrintStack(rt->stack);\n }"}, {"sha": "23fbc68420937c669d24e69972d7a3937b51242a", "filename": "libsanitizer/tsan/tsan_report.h", "status": "modified", "additions": 14, "deletions": 4, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_report.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_report.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_report.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -36,20 +36,27 @@ struct ReportStack {\n   int col;\n };\n \n+struct ReportMopMutex {\n+  u64 id;\n+  bool write;\n+};\n+\n struct ReportMop {\n   int tid;\n   uptr addr;\n   int size;\n   bool write;\n-  int nmutex;\n-  int *mutex;\n+  Vector<ReportMopMutex> mset;\n   ReportStack *stack;\n+\n+  ReportMop();\n };\n \n enum ReportLocationType {\n   ReportLocationGlobal,\n   ReportLocationHeap,\n-  ReportLocationStack\n+  ReportLocationStack,\n+  ReportLocationFD\n };\n \n struct ReportLocation {\n@@ -59,6 +66,7 @@ struct ReportLocation {\n   char *module;\n   uptr offset;\n   int tid;\n+  int fd;\n   char *name;\n   char *file;\n   int line;\n@@ -70,11 +78,13 @@ struct ReportThread {\n   uptr pid;\n   bool running;\n   char *name;\n+  int parent_tid;\n   ReportStack *stack;\n };\n \n struct ReportMutex {\n-  int id;\n+  u64 id;\n+  bool destroyed;\n   ReportStack *stack;\n };\n "}, {"sha": "3615a7a9c2f6e1538362799fc47fc91867f0e998", "filename": "libsanitizer/tsan/tsan_rtl.cc", "status": "modified", "additions": 12, "deletions": 1, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -164,6 +164,16 @@ void MapShadow(uptr addr, uptr size) {\n   MmapFixedNoReserve(MemToShadow(addr), size * kShadowMultiplier);\n }\n \n+void MapThreadTrace(uptr addr, uptr size) {\n+  DPrintf(\"#0: Mapping trace at %p-%p(0x%zx)\\n\", addr, addr + size, size);\n+  CHECK_GE(addr, kTraceMemBegin);\n+  CHECK_LE(addr + size, kTraceMemBegin + kTraceMemSize);\n+  if (addr != (uptr)MmapFixedNoReserve(addr, size)) {\n+    Printf(\"FATAL: ThreadSanitizer can not mmap thread trace\\n\");\n+    Die();\n+  }\n+}\n+\n void Initialize(ThreadState *thr) {\n   // Thread safe because done before all threads exist.\n   static bool is_initialized = false;\n@@ -289,6 +299,7 @@ void TraceSwitch(ThreadState *thr) {\n   TraceHeader *hdr = &thr->trace.headers[trace];\n   hdr->epoch0 = thr->fast_state.epoch();\n   hdr->stack0.ObtainCurrent(thr, 0);\n+  hdr->mset0 = thr->mset;\n   thr->nomalloc--;\n }\n \n@@ -443,7 +454,7 @@ ALWAYS_INLINE\n void MemoryAccess(ThreadState *thr, uptr pc, uptr addr,\n     int kAccessSizeLog, bool kAccessIsWrite) {\n   u64 *shadow_mem = (u64*)MemToShadow(addr);\n-  DPrintf2(\"#%d: tsan::OnMemoryAccess: @%p %p size=%d\"\n+  DPrintf2(\"#%d: MemoryAccess: @%p %p size=%d\"\n       \" is_write=%d shadow_mem=%p {%zx, %zx, %zx, %zx}\\n\",\n       (int)thr->fast_state.tid(), (void*)pc, (void*)addr,\n       (int)(1 << kAccessSizeLog), kAccessIsWrite, shadow_mem,"}, {"sha": "b911791c18747bffe2bc60b593c7a33e9c5bc96f", "filename": "libsanitizer/tsan/tsan_rtl.h", "status": "modified", "additions": 34, "deletions": 4, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -34,6 +34,7 @@\n #include \"tsan_vector.h\"\n #include \"tsan_report.h\"\n #include \"tsan_platform.h\"\n+#include \"tsan_mutexset.h\"\n \n #if SANITIZER_WORDSIZE != 64\n # error \"ThreadSanitizer is supported only on 64-bit platforms\"\n@@ -48,6 +49,10 @@ struct MBlock {\n   u32 alloc_tid;\n   u32 alloc_stack_id;\n   SyncVar *head;\n+\n+  MBlock()\n+    : mtx(MutexTypeMBlock, StatMtxMBlock) {\n+  }\n };\n \n #ifndef TSAN_GO\n@@ -58,10 +63,22 @@ const uptr kAllocatorSpace = 0x7d0000000000ULL;\n #endif\n const uptr kAllocatorSize  =  0x10000000000ULL;  // 1T.\n \n+struct TsanMapUnmapCallback {\n+  void OnMap(uptr p, uptr size) const { }\n+  void OnUnmap(uptr p, uptr size) const {\n+    // We are about to unmap a chunk of user memory.\n+    // Mark the corresponding shadow memory as not needed.\n+    uptr shadow_beg = MemToShadow(p);\n+    uptr shadow_end = MemToShadow(p + size);\n+    CHECK(IsAligned(shadow_end|shadow_beg, GetPageSizeCached()));\n+    FlushUnneededShadowMemory(shadow_beg, shadow_end - shadow_beg);\n+  }\n+};\n+\n typedef SizeClassAllocator64<kAllocatorSpace, kAllocatorSize, sizeof(MBlock),\n     DefaultSizeClassMap> PrimaryAllocator;\n typedef SizeClassAllocatorLocalCache<PrimaryAllocator> AllocatorCache;\n-typedef LargeMmapAllocator SecondaryAllocator;\n+typedef LargeMmapAllocator<TsanMapUnmapCallback> SecondaryAllocator;\n typedef CombinedAllocator<PrimaryAllocator, AllocatorCache,\n     SecondaryAllocator> Allocator;\n Allocator *allocator();\n@@ -298,6 +315,7 @@ struct ThreadState {\n   uptr *shadow_stack;\n   uptr *shadow_stack_end;\n #endif\n+  MutexSet mset;\n   ThreadClock clock;\n #ifndef TSAN_GO\n   AllocatorCache alloc_cache;\n@@ -369,6 +387,7 @@ struct ThreadContext {\n   u64 epoch0;\n   u64 epoch1;\n   StackTrace creation_stack;\n+  int creation_tid;\n   ThreadDeadInfo *dead_info;\n   ThreadContext *dead_next;  // In dead thread list.\n   char *name;  // As annotated by user.\n@@ -445,7 +464,8 @@ class ScopedReport {\n   ~ScopedReport();\n \n   void AddStack(const StackTrace *stack);\n-  void AddMemoryAccess(uptr addr, Shadow s, const StackTrace *stack);\n+  void AddMemoryAccess(uptr addr, Shadow s, const StackTrace *stack,\n+                       const MutexSet *mset);\n   void AddThread(const ThreadContext *tctx);\n   void AddMutex(const SyncVar *s);\n   void AddLocation(uptr addr, uptr size);\n@@ -457,11 +477,13 @@ class ScopedReport {\n   Context *ctx_;\n   ReportDesc *rep_;\n \n+  void AddMutex(u64 id);\n+\n   ScopedReport(const ScopedReport&);\n   void operator = (const ScopedReport&);\n };\n \n-void RestoreStack(int tid, const u64 epoch, StackTrace *stk);\n+void RestoreStack(int tid, const u64 epoch, StackTrace *stk, MutexSet *mset);\n \n void StatAggregate(u64 *dst, u64 *src);\n void StatOutput(u64 *stat);\n@@ -471,6 +493,7 @@ void ALWAYS_INLINE INLINE StatInc(ThreadState *thr, StatType typ, u64 n = 1) {\n }\n \n void MapShadow(uptr addr, uptr size);\n+void MapThreadTrace(uptr addr, uptr size);\n void InitializeShadowMemory();\n void InitializeInterceptors();\n void InitializeDynamicAnnotations();\n@@ -502,6 +525,10 @@ void PrintCurrentStack(ThreadState *thr, uptr pc);\n void Initialize(ThreadState *thr);\n int Finalize(ThreadState *thr);\n \n+SyncVar* GetJavaSync(ThreadState *thr, uptr pc, uptr addr,\n+                     bool write_lock, bool create);\n+SyncVar* GetAndRemoveJavaSync(ThreadState *thr, uptr pc, uptr addr);\n+\n void MemoryAccess(ThreadState *thr, uptr pc, uptr addr,\n     int kAccessSizeLog, bool kAccessIsWrite);\n void MemoryAccessImpl(ThreadState *thr, uptr addr,\n@@ -575,7 +602,10 @@ uptr TraceParts();\n \n extern \"C\" void __tsan_trace_switch();\n void ALWAYS_INLINE INLINE TraceAddEvent(ThreadState *thr, FastState fs,\n-                                        EventType typ, uptr addr) {\n+                                        EventType typ, u64 addr) {\n+  DCHECK_GE((int)typ, 0);\n+  DCHECK_LE((int)typ, 7);\n+  DCHECK_EQ(GetLsb(addr, 61), addr);\n   StatInc(thr, StatEvents);\n   u64 pos = fs.GetTracePos();\n   if (UNLIKELY((pos % kTracePartSize) == 0)) {"}, {"sha": "8dd0e6d4d9b17b0f6682954bb4286395af8f64bc", "filename": "libsanitizer/tsan/tsan_rtl_mutex.cc", "status": "modified", "additions": 25, "deletions": 17, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl_mutex.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl_mutex.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl_mutex.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -26,7 +26,7 @@ void MutexCreate(ThreadState *thr, uptr pc, uptr addr,\n   StatInc(thr, StatMutexCreate);\n   if (!linker_init && IsAppMem(addr))\n     MemoryWrite1Byte(thr, pc, addr);\n-  SyncVar *s = ctx->synctab.GetAndLock(thr, pc, addr, true);\n+  SyncVar *s = ctx->synctab.GetOrCreateAndLock(thr, pc, addr, true);\n   s->is_rw = rw;\n   s->is_recursive = recursive;\n   s->is_linker_init = linker_init;\n@@ -59,11 +59,12 @@ void MutexDestroy(ThreadState *thr, uptr pc, uptr addr) {\n     trace.ObtainCurrent(thr, pc);\n     rep.AddStack(&trace);\n     FastState last(s->last_lock);\n-    RestoreStack(last.tid(), last.epoch(), &trace);\n+    RestoreStack(last.tid(), last.epoch(), &trace, 0);\n     rep.AddStack(&trace);\n     rep.AddLocation(s->addr, 1);\n     OutputReport(ctx, rep);\n   }\n+  thr->mset.Remove(s->GetId());\n   DestroyAndFree(s);\n }\n \n@@ -72,9 +73,9 @@ void MutexLock(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: MutexLock %zx\\n\", thr->tid, addr);\n   if (IsAppMem(addr))\n     MemoryRead1Byte(thr, pc, addr);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, addr, true);\n   thr->fast_state.IncrementEpoch();\n-  TraceAddEvent(thr, thr->fast_state, EventTypeLock, addr);\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, addr, true);\n+  TraceAddEvent(thr, thr->fast_state, EventTypeLock, s->GetId());\n   if (s->owner_tid == SyncVar::kInvalidTid) {\n     CHECK_EQ(s->recursion, 0);\n     s->owner_tid = thr->tid;\n@@ -96,6 +97,7 @@ void MutexLock(ThreadState *thr, uptr pc, uptr addr) {\n     StatInc(thr, StatMutexRecLock);\n   }\n   s->recursion++;\n+  thr->mset.Add(s->GetId(), true, thr->fast_state.epoch());\n   s->mtx.Unlock();\n }\n \n@@ -104,9 +106,9 @@ void MutexUnlock(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: MutexUnlock %zx\\n\", thr->tid, addr);\n   if (IsAppMem(addr))\n     MemoryRead1Byte(thr, pc, addr);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, addr, true);\n   thr->fast_state.IncrementEpoch();\n-  TraceAddEvent(thr, thr->fast_state, EventTypeUnlock, addr);\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, addr, true);\n+  TraceAddEvent(thr, thr->fast_state, EventTypeUnlock, s->GetId());\n   if (s->recursion == 0) {\n     if (!s->is_broken) {\n       s->is_broken = true;\n@@ -132,6 +134,7 @@ void MutexUnlock(ThreadState *thr, uptr pc, uptr addr) {\n       StatInc(thr, StatMutexRecUnlock);\n     }\n   }\n+  thr->mset.Del(s->GetId(), true);\n   s->mtx.Unlock();\n }\n \n@@ -141,9 +144,9 @@ void MutexReadLock(ThreadState *thr, uptr pc, uptr addr) {\n   StatInc(thr, StatMutexReadLock);\n   if (IsAppMem(addr))\n     MemoryRead1Byte(thr, pc, addr);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, addr, false);\n   thr->fast_state.IncrementEpoch();\n-  TraceAddEvent(thr, thr->fast_state, EventTypeRLock, addr);\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, addr, false);\n+  TraceAddEvent(thr, thr->fast_state, EventTypeRLock, s->GetId());\n   if (s->owner_tid != SyncVar::kInvalidTid) {\n     Printf(\"ThreadSanitizer WARNING: read lock of a write locked mutex\\n\");\n     PrintCurrentStack(thr, pc);\n@@ -152,6 +155,7 @@ void MutexReadLock(ThreadState *thr, uptr pc, uptr addr) {\n   thr->clock.acquire(&s->clock);\n   s->last_lock = thr->fast_state.raw();\n   StatInc(thr, StatSyncAcquire);\n+  thr->mset.Add(s->GetId(), false, thr->fast_state.epoch());\n   s->mtx.ReadUnlock();\n }\n \n@@ -161,9 +165,9 @@ void MutexReadUnlock(ThreadState *thr, uptr pc, uptr addr) {\n   StatInc(thr, StatMutexReadUnlock);\n   if (IsAppMem(addr))\n     MemoryRead1Byte(thr, pc, addr);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, addr, true);\n   thr->fast_state.IncrementEpoch();\n-  TraceAddEvent(thr, thr->fast_state, EventTypeRUnlock, addr);\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, addr, true);\n+  TraceAddEvent(thr, thr->fast_state, EventTypeRUnlock, s->GetId());\n   if (s->owner_tid != SyncVar::kInvalidTid) {\n     Printf(\"ThreadSanitizer WARNING: read unlock of a write \"\n                \"locked mutex\\n\");\n@@ -174,25 +178,30 @@ void MutexReadUnlock(ThreadState *thr, uptr pc, uptr addr) {\n   thr->clock.release(&s->read_clock);\n   StatInc(thr, StatSyncRelease);\n   s->mtx.Unlock();\n+  thr->mset.Del(s->GetId(), false);\n }\n \n void MutexReadOrWriteUnlock(ThreadState *thr, uptr pc, uptr addr) {\n   CHECK_GT(thr->in_rtl, 0);\n   DPrintf(\"#%d: MutexReadOrWriteUnlock %zx\\n\", thr->tid, addr);\n   if (IsAppMem(addr))\n     MemoryRead1Byte(thr, pc, addr);\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, addr, true);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, addr, true);\n+  bool write = true;\n   if (s->owner_tid == SyncVar::kInvalidTid) {\n     // Seems to be read unlock.\n+    write = false;\n     StatInc(thr, StatMutexReadUnlock);\n     thr->fast_state.IncrementEpoch();\n-    TraceAddEvent(thr, thr->fast_state, EventTypeRUnlock, addr);\n+    TraceAddEvent(thr, thr->fast_state, EventTypeRUnlock, s->GetId());\n     thr->clock.set(thr->tid, thr->fast_state.epoch());\n     thr->fast_synch_epoch = thr->fast_state.epoch();\n     thr->clock.release(&s->read_clock);\n     StatInc(thr, StatSyncRelease);\n   } else if (s->owner_tid == thr->tid) {\n     // Seems to be write unlock.\n+    thr->fast_state.IncrementEpoch();\n+    TraceAddEvent(thr, thr->fast_state, EventTypeUnlock, s->GetId());\n     CHECK_GT(s->recursion, 0);\n     s->recursion--;\n     if (s->recursion == 0) {\n@@ -202,8 +211,6 @@ void MutexReadOrWriteUnlock(ThreadState *thr, uptr pc, uptr addr) {\n       // The sequence of events is quite tricky and doubled in several places.\n       // First, it's a bug to increment the epoch w/o writing to the trace.\n       // Then, the acquire/release logic can be factored out as well.\n-      thr->fast_state.IncrementEpoch();\n-      TraceAddEvent(thr, thr->fast_state, EventTypeUnlock, addr);\n       thr->clock.set(thr->tid, thr->fast_state.epoch());\n       thr->fast_synch_epoch = thr->fast_state.epoch();\n       thr->clock.ReleaseStore(&s->clock);\n@@ -216,13 +223,14 @@ void MutexReadOrWriteUnlock(ThreadState *thr, uptr pc, uptr addr) {\n     Printf(\"ThreadSanitizer WARNING: mutex unlock by another thread\\n\");\n     PrintCurrentStack(thr, pc);\n   }\n+  thr->mset.Del(s->GetId(), write);\n   s->mtx.Unlock();\n }\n \n void Acquire(ThreadState *thr, uptr pc, uptr addr) {\n   CHECK_GT(thr->in_rtl, 0);\n   DPrintf(\"#%d: Acquire %zx\\n\", thr->tid, addr);\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, addr, false);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, addr, false);\n   thr->clock.set(thr->tid, thr->fast_state.epoch());\n   thr->clock.acquire(&s->clock);\n   StatInc(thr, StatSyncAcquire);\n@@ -246,7 +254,7 @@ void AcquireGlobal(ThreadState *thr, uptr pc) {\n void Release(ThreadState *thr, uptr pc, uptr addr) {\n   CHECK_GT(thr->in_rtl, 0);\n   DPrintf(\"#%d: Release %zx\\n\", thr->tid, addr);\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, addr, true);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, addr, true);\n   thr->clock.set(thr->tid, thr->fast_state.epoch());\n   thr->clock.release(&s->clock);\n   StatInc(thr, StatSyncRelease);\n@@ -256,7 +264,7 @@ void Release(ThreadState *thr, uptr pc, uptr addr) {\n void ReleaseStore(ThreadState *thr, uptr pc, uptr addr) {\n   CHECK_GT(thr->in_rtl, 0);\n   DPrintf(\"#%d: ReleaseStore %zx\\n\", thr->tid, addr);\n-  SyncVar *s = CTX()->synctab.GetAndLock(thr, pc, addr, true);\n+  SyncVar *s = CTX()->synctab.GetOrCreateAndLock(thr, pc, addr, true);\n   thr->clock.set(thr->tid, thr->fast_state.epoch());\n   thr->clock.ReleaseStore(&s->clock);\n   StatInc(thr, StatSyncRelease);"}, {"sha": "b65b24fce8998b0a1350426817af5263b6b542ff", "filename": "libsanitizer/tsan/tsan_rtl_report.cc", "status": "modified", "additions": 99, "deletions": 7, "changes": 106, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl_report.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl_report.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl_report.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -12,6 +12,7 @@\n #include \"sanitizer_common/sanitizer_libc.h\"\n #include \"sanitizer_common/sanitizer_placement_new.h\"\n #include \"sanitizer_common/sanitizer_stackdepot.h\"\n+#include \"sanitizer_common/sanitizer_common.h\"\n #include \"tsan_platform.h\"\n #include \"tsan_rtl.h\"\n #include \"tsan_suppressions.h\"\n@@ -20,9 +21,12 @@\n #include \"tsan_sync.h\"\n #include \"tsan_mman.h\"\n #include \"tsan_flags.h\"\n+#include \"tsan_fd.h\"\n \n namespace __tsan {\n \n+using namespace __sanitizer;  // NOLINT\n+\n void TsanCheckFailed(const char *file, int line, const char *cond,\n                      u64 v1, u64 v2) {\n   ScopedInRtl in_rtl;\n@@ -132,16 +136,35 @@ void ScopedReport::AddStack(const StackTrace *stack) {\n }\n \n void ScopedReport::AddMemoryAccess(uptr addr, Shadow s,\n-                                   const StackTrace *stack) {\n+    const StackTrace *stack, const MutexSet *mset) {\n   void *mem = internal_alloc(MBlockReportMop, sizeof(ReportMop));\n   ReportMop *mop = new(mem) ReportMop;\n   rep_->mops.PushBack(mop);\n   mop->tid = s.tid();\n   mop->addr = addr + s.addr0();\n   mop->size = s.size();\n   mop->write = s.is_write();\n-  mop->nmutex = 0;\n   mop->stack = SymbolizeStack(*stack);\n+  for (uptr i = 0; i < mset->Size(); i++) {\n+    MutexSet::Desc d = mset->Get(i);\n+    u64 uid = 0;\n+    uptr addr = SyncVar::SplitId(d.id, &uid);\n+    SyncVar *s = ctx_->synctab.GetIfExistsAndLock(addr, false);\n+    // Check that the mutex is still alive.\n+    // Another mutex can be created at the same address,\n+    // so check uid as well.\n+    if (s && s->CheckId(uid)) {\n+      ReportMopMutex mtx = {s->uid, d.write};\n+      mop->mset.PushBack(mtx);\n+      AddMutex(s);\n+    } else {\n+      ReportMopMutex mtx = {d.id, d.write};\n+      mop->mset.PushBack(mtx);\n+      AddMutex(d.id);\n+    }\n+    if (s)\n+      s->mtx.ReadUnlock();\n+  }\n }\n \n void ScopedReport::AddThread(const ThreadContext *tctx) {\n@@ -156,6 +179,7 @@ void ScopedReport::AddThread(const ThreadContext *tctx) {\n   rt->pid = tctx->os_id;\n   rt->running = (tctx->status == ThreadStatusRunning);\n   rt->name = tctx->name ? internal_strdup(tctx->name) : 0;\n+  rt->parent_tid = tctx->creation_tid;\n   rt->stack = SymbolizeStack(tctx->creation_stack);\n }\n \n@@ -173,17 +197,58 @@ static ThreadContext *FindThread(int unique_id) {\n #endif\n \n void ScopedReport::AddMutex(const SyncVar *s) {\n+  for (uptr i = 0; i < rep_->mutexes.Size(); i++) {\n+    if (rep_->mutexes[i]->id == s->uid)\n+      return;\n+  }\n   void *mem = internal_alloc(MBlockReportMutex, sizeof(ReportMutex));\n   ReportMutex *rm = new(mem) ReportMutex();\n   rep_->mutexes.PushBack(rm);\n-  rm->id = 42;\n+  rm->id = s->uid;\n+  rm->destroyed = false;\n   rm->stack = SymbolizeStack(s->creation_stack);\n }\n \n+void ScopedReport::AddMutex(u64 id) {\n+  for (uptr i = 0; i < rep_->mutexes.Size(); i++) {\n+    if (rep_->mutexes[i]->id == id)\n+      return;\n+  }\n+  void *mem = internal_alloc(MBlockReportMutex, sizeof(ReportMutex));\n+  ReportMutex *rm = new(mem) ReportMutex();\n+  rep_->mutexes.PushBack(rm);\n+  rm->id = id;\n+  rm->destroyed = true;\n+  rm->stack = 0;\n+}\n+\n void ScopedReport::AddLocation(uptr addr, uptr size) {\n   if (addr == 0)\n     return;\n #ifndef TSAN_GO\n+  int fd = -1;\n+  int creat_tid = -1;\n+  u32 creat_stack = 0;\n+  if (FdLocation(addr, &fd, &creat_tid, &creat_stack)\n+      || FdLocation(AlternativeAddress(addr), &fd, &creat_tid, &creat_stack)) {\n+    void *mem = internal_alloc(MBlockReportLoc, sizeof(ReportLocation));\n+    ReportLocation *loc = new(mem) ReportLocation();\n+    rep_->locs.PushBack(loc);\n+    loc->type = ReportLocationFD;\n+    loc->fd = fd;\n+    loc->tid = creat_tid;\n+    uptr ssz = 0;\n+    const uptr *stack = StackDepotGet(creat_stack, &ssz);\n+    if (stack) {\n+      StackTrace trace;\n+      trace.Init(stack, ssz);\n+      loc->stack = SymbolizeStack(trace);\n+    }\n+    ThreadContext *tctx = FindThread(creat_tid);\n+    if (tctx)\n+      AddThread(tctx);\n+    return;\n+  }\n   if (allocator()->PointerIsMine((void*)addr)) {\n     MBlock *b = user_mblock(0, (void*)addr);\n     ThreadContext *tctx = FindThread(b->alloc_tid);\n@@ -246,7 +311,10 @@ const ReportDesc *ScopedReport::GetReport() const {\n   return rep_;\n }\n \n-void RestoreStack(int tid, const u64 epoch, StackTrace *stk) {\n+void RestoreStack(int tid, const u64 epoch, StackTrace *stk, MutexSet *mset) {\n+  // This function restores stack trace and mutex set for the thread/epoch.\n+  // It does so by getting stack trace and mutex set at the beginning of\n+  // trace part, and then replaying the trace till the given epoch.\n   ThreadContext *tctx = CTX()->threads[tid];\n   if (tctx == 0)\n     return;\n@@ -267,6 +335,7 @@ void RestoreStack(int tid, const u64 epoch, StackTrace *stk) {\n   TraceHeader* hdr = &trace->headers[partidx];\n   if (epoch < hdr->epoch0)\n     return;\n+  const u64 epoch0 = RoundDown(epoch, TraceSize());\n   const u64 eend = epoch % TraceSize();\n   const u64 ebegin = RoundDown(eend, kTracePartSize);\n   DPrintf(\"#%d: RestoreStack epoch=%zu ebegin=%zu eend=%zu partidx=%d\\n\",\n@@ -276,12 +345,14 @@ void RestoreStack(int tid, const u64 epoch, StackTrace *stk) {\n     stack[i] = hdr->stack0.Get(i);\n     DPrintf2(\"  #%02lu: pc=%zx\\n\", i, stack[i]);\n   }\n+  if (mset)\n+    *mset = hdr->mset0;\n   uptr pos = hdr->stack0.Size();\n   Event *events = (Event*)GetThreadTrace(tid);\n   for (uptr i = ebegin; i <= eend; i++) {\n     Event ev = events[i];\n     EventType typ = (EventType)(ev >> 61);\n-    uptr pc = (uptr)(ev & 0xffffffffffffull);\n+    uptr pc = (uptr)(ev & ((1ull << 61) - 1));\n     DPrintf2(\"  %zu typ=%d pc=%zx\\n\", i, typ, pc);\n     if (typ == EventTypeMop) {\n       stack[pos] = pc;\n@@ -291,6 +362,17 @@ void RestoreStack(int tid, const u64 epoch, StackTrace *stk) {\n       if (pos > 0)\n         pos--;\n     }\n+    if (mset) {\n+      if (typ == EventTypeLock) {\n+        mset->Add(pc, true, epoch0 + i);\n+      } else if (typ == EventTypeUnlock) {\n+        mset->Del(pc, true);\n+      } else if (typ == EventTypeRLock) {\n+        mset->Add(pc, false, epoch0 + i);\n+      } else if (typ == EventTypeRUnlock) {\n+        mset->Del(pc, false);\n+      }\n+    }\n     for (uptr j = 0; j <= pos; j++)\n       DPrintf2(\"      #%zu: %zx\\n\", j, stack[j]);\n   }\n@@ -400,8 +482,11 @@ static bool IsJavaNonsense(const ReportDesc *rep) {\n     if (frame != 0 && frame->func != 0\n         && (internal_strcmp(frame->func, \"memset\") == 0\n         || internal_strcmp(frame->func, \"memcpy\") == 0\n+        || internal_strcmp(frame->func, \"memmove\") == 0\n         || internal_strcmp(frame->func, \"strcmp\") == 0\n         || internal_strcmp(frame->func, \"strncpy\") == 0\n+        || internal_strcmp(frame->func, \"strlen\") == 0\n+        || internal_strcmp(frame->func, \"free\") == 0\n         || internal_strcmp(frame->func, \"pthread_mutex_lock\") == 0)) {\n       frame = frame->next;\n       if (frame == 0\n@@ -423,6 +508,10 @@ void ReportRace(ThreadState *thr) {\n     return;\n   ScopedInRtl in_rtl;\n \n+  if (thr->in_signal_handler)\n+    Printf(\"ThreadSanitizer: printing report from signal handler.\"\n+           \" Can crash or hang.\\n\");\n+\n   bool freed = false;\n   {\n     Shadow s(thr->racy_state[1]);\n@@ -454,15 +543,18 @@ void ReportRace(ThreadState *thr) {\n   traces[0].ObtainCurrent(thr, toppc);\n   if (IsFiredSuppression(ctx, rep, traces[0]))\n     return;\n+  InternalScopedBuffer<MutexSet> mset2(1);\n+  new(mset2.data()) MutexSet();\n   Shadow s2(thr->racy_state[1]);\n-  RestoreStack(s2.tid(), s2.epoch(), &traces[1]);\n+  RestoreStack(s2.tid(), s2.epoch(), &traces[1], mset2.data());\n \n   if (HandleRacyStacks(thr, traces, addr_min, addr_max))\n     return;\n \n   for (uptr i = 0; i < kMop; i++) {\n     Shadow s(thr->racy_state[i]);\n-    rep.AddMemoryAccess(addr, s, &traces[i]);\n+    rep.AddMemoryAccess(addr, s, &traces[i],\n+                        i == 0 ? &thr->mset : mset2.data());\n   }\n \n   if (flags()->suppress_java && IsJavaNonsense(rep.GetReport()))"}, {"sha": "d5b3444be6d606246c984b02728e8c9b9b50dc70", "filename": "libsanitizer/tsan/tsan_rtl_thread.cc", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl_thread.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_rtl_thread.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl_thread.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -154,6 +154,7 @@ int ThreadCreate(ThreadState *thr, uptr pc, uptr uid, bool detached) {\n     thr->clock.release(&tctx->sync);\n     StatInc(thr, StatSyncRelease);\n     tctx->creation_stack.ObtainCurrent(thr, pc);\n+    tctx->creation_tid = thr->tid;\n   }\n   return tid;\n }\n@@ -303,6 +304,7 @@ void ThreadJoin(ThreadState *thr, uptr pc, int tid) {\n     Printf(\"ThreadSanitizer: join of non-existent thread\\n\");\n     return;\n   }\n+  // FIXME(dvyukov): print message and continue (it's user error).\n   CHECK_EQ(tctx->detached, false);\n   CHECK_EQ(tctx->status, ThreadStatusFinished);\n   thr->clock.acquire(&tctx->sync);"}, {"sha": "394c911162609f3c720346eda2ebb9b8e9e36187", "filename": "libsanitizer/tsan/tsan_stat.cc", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_stat.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_stat.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_stat.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -179,6 +179,28 @@ void StatOutput(u64 *stat) {\n   name[StatInt_sem_timedwait]            = \"  sem_timedwait                   \";\n   name[StatInt_sem_post]                 = \"  sem_post                        \";\n   name[StatInt_sem_getvalue]             = \"  sem_getvalue                    \";\n+  name[StatInt_open]                     = \"  open                            \";\n+  name[StatInt_open64]                   = \"  open64                          \";\n+  name[StatInt_creat]                    = \"  creat                           \";\n+  name[StatInt_creat64]                  = \"  creat64                         \";\n+  name[StatInt_dup]                      = \"  dup                             \";\n+  name[StatInt_dup2]                     = \"  dup2                            \";\n+  name[StatInt_dup3]                     = \"  dup3                            \";\n+  name[StatInt_eventfd]                  = \"  eventfd                         \";\n+  name[StatInt_signalfd]                 = \"  signalfd                        \";\n+  name[StatInt_inotify_init]             = \"  inotify_init                    \";\n+  name[StatInt_inotify_init1]            = \"  inotify_init1                   \";\n+  name[StatInt_socket]                   = \"  socket                          \";\n+  name[StatInt_socketpair]               = \"  socketpair                      \";\n+  name[StatInt_connect]                  = \"  connect                         \";\n+  name[StatInt_accept]                   = \"  accept                          \";\n+  name[StatInt_accept4]                  = \"  accept4                         \";\n+  name[StatInt_epoll_create]             = \"  epoll_create                    \";\n+  name[StatInt_epoll_create1]            = \"  epoll_create1                   \";\n+  name[StatInt_close]                    = \"  close                           \";\n+  name[StatInt___close]                  = \"  __close                         \";\n+  name[StatInt_pipe]                     = \"  pipe                            \";\n+  name[StatInt_pipe2]                    = \"  pipe2                           \";\n   name[StatInt_read]                     = \"  read                            \";\n   name[StatInt_pread]                    = \"  pread                           \";\n   name[StatInt_pread64]                  = \"  pread64                         \";\n@@ -195,6 +217,8 @@ void StatOutput(u64 *stat) {\n   name[StatInt_recvmsg]                  = \"  recvmsg                         \";\n   name[StatInt_unlink]                   = \"  unlink                          \";\n   name[StatInt_fopen]                    = \"  fopen                           \";\n+  name[StatInt_freopen]                  = \"  freopen                         \";\n+  name[StatInt_fclose]                   = \"  fclose                          \";\n   name[StatInt_fread]                    = \"  fread                           \";\n   name[StatInt_fwrite]                   = \"  fwrite                          \";\n   name[StatInt_puts]                     = \"  puts                            \";\n@@ -208,6 +232,7 @@ void StatOutput(u64 *stat) {\n   name[StatInt_usleep]                   = \"  usleep                          \";\n   name[StatInt_nanosleep]                = \"  nanosleep                       \";\n   name[StatInt_gettimeofday]             = \"  gettimeofday                    \";\n+  name[StatInt_fork]                     = \"  fork                            \";\n \n   name[StatAnnotation]                   = \"Dynamic annotations               \";\n   name[StatAnnotateHappensBefore]        = \"  HappensBefore                   \";\n@@ -251,6 +276,8 @@ void StatOutput(u64 *stat) {\n   name[StatMtxSlab]                      = \"  Slab                            \";\n   name[StatMtxAtExit]                    = \"  Atexit                          \";\n   name[StatMtxAnnotations]               = \"  Annotations                     \";\n+  name[StatMtxMBlock]                    = \"  MBlock                          \";\n+  name[StatMtxJavaMBlock]                = \"  JavaMBlock                      \";\n \n   Printf(\"Statistics:\\n\");\n   for (int i = 0; i < StatCnt; i++)"}, {"sha": "cdd57365baefa1c482a8a3d4105126b4fbe93b70", "filename": "libsanitizer/tsan/tsan_stat.h", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_stat.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_stat.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_stat.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -174,6 +174,28 @@ enum StatType {\n   StatInt_sem_timedwait,\n   StatInt_sem_post,\n   StatInt_sem_getvalue,\n+  StatInt_open,\n+  StatInt_open64,\n+  StatInt_creat,\n+  StatInt_creat64,\n+  StatInt_dup,\n+  StatInt_dup2,\n+  StatInt_dup3,\n+  StatInt_eventfd,\n+  StatInt_signalfd,\n+  StatInt_inotify_init,\n+  StatInt_inotify_init1,\n+  StatInt_socket,\n+  StatInt_socketpair,\n+  StatInt_connect,\n+  StatInt_accept,\n+  StatInt_accept4,\n+  StatInt_epoll_create,\n+  StatInt_epoll_create1,\n+  StatInt_close,\n+  StatInt___close,\n+  StatInt_pipe,\n+  StatInt_pipe2,\n   StatInt_read,\n   StatInt_pread,\n   StatInt_pread64,\n@@ -190,6 +212,8 @@ enum StatType {\n   StatInt_recvmsg,\n   StatInt_unlink,\n   StatInt_fopen,\n+  StatInt_freopen,\n+  StatInt_fclose,\n   StatInt_fread,\n   StatInt_fwrite,\n   StatInt_puts,\n@@ -207,6 +231,7 @@ enum StatType {\n   StatInt_usleep,\n   StatInt_nanosleep,\n   StatInt_gettimeofday,\n+  StatInt_fork,\n \n   // Dynamic annotations.\n   StatAnnotation,\n@@ -253,6 +278,8 @@ enum StatType {\n   StatMtxSlab,\n   StatMtxAnnotations,\n   StatMtxAtExit,\n+  StatMtxMBlock,\n+  StatMtxJavaMBlock,\n \n   // This must be the last.\n   StatCnt"}, {"sha": "9bdd1ffdc5e603c6a83f359edef3a317bb2ce385", "filename": "libsanitizer/tsan/tsan_symbolize_addr2line_linux.cc", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_symbolize_addr2line_linux.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_symbolize_addr2line_linux.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_symbolize_addr2line_linux.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -102,11 +102,11 @@ static int dl_iterate_phdr_cb(dl_phdr_info *info, size_t size, void *arg) {\n   m->base = (uptr)info->dlpi_addr;\n   m->inp_fd = -1;\n   m->out_fd = -1;\n-  DPrintf(\"Module %s %zx\\n\", m->name, m->base);\n+  DPrintf2(\"Module %s %zx\\n\", m->name, m->base);\n   for (int i = 0; i < info->dlpi_phnum; i++) {\n     const Elf64_Phdr *s = &info->dlpi_phdr[i];\n-    DPrintf(\"  Section p_type=%zx p_offset=%zx p_vaddr=%zx p_paddr=%zx\"\n-            \" p_filesz=%zx p_memsz=%zx p_flags=%zx p_align=%zx\\n\",\n+    DPrintf2(\"  Section p_type=%zx p_offset=%zx p_vaddr=%zx p_paddr=%zx\"\n+        \" p_filesz=%zx p_memsz=%zx p_flags=%zx p_align=%zx\\n\",\n             (uptr)s->p_type, (uptr)s->p_offset, (uptr)s->p_vaddr,\n             (uptr)s->p_paddr, (uptr)s->p_filesz, (uptr)s->p_memsz,\n             (uptr)s->p_flags, (uptr)s->p_align);\n@@ -119,7 +119,7 @@ static int dl_iterate_phdr_cb(dl_phdr_info *info, size_t size, void *arg) {\n     sec->end = sec->base + s->p_memsz;\n     sec->next = ctx->sections;\n     ctx->sections = sec;\n-    DPrintf(\"  Section %zx-%zx\\n\", sec->base, sec->end);\n+    DPrintf2(\"  Section %zx-%zx\\n\", sec->base, sec->end);\n   }\n   return 0;\n }"}, {"sha": "d392408fd888f23aa0279d99a60e707e7480c80c", "filename": "libsanitizer/tsan/tsan_sync.cc", "status": "modified", "additions": 43, "deletions": 12, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_sync.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_sync.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_sync.cc?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -15,9 +15,10 @@\n \n namespace __tsan {\n \n-SyncVar::SyncVar(uptr addr)\n+SyncVar::SyncVar(uptr addr, u64 uid)\n   : mtx(MutexTypeSyncVar, StatMtxSyncVar)\n   , addr(addr)\n+  , uid(uid)\n   , owner_tid(kInvalidTid)\n   , last_lock()\n   , recursion()\n@@ -45,9 +46,38 @@ SyncTab::~SyncTab() {\n   }\n }\n \n+SyncVar* SyncTab::GetOrCreateAndLock(ThreadState *thr, uptr pc,\n+                                     uptr addr, bool write_lock) {\n+  return GetAndLock(thr, pc, addr, write_lock, true);\n+}\n+\n+SyncVar* SyncTab::GetIfExistsAndLock(uptr addr, bool write_lock) {\n+  return GetAndLock(0, 0, addr, write_lock, false);\n+}\n+\n+SyncVar* SyncTab::Create(ThreadState *thr, uptr pc, uptr addr) {\n+  StatInc(thr, StatSyncCreated);\n+  void *mem = internal_alloc(MBlockSync, sizeof(SyncVar));\n+  const u64 uid = atomic_fetch_add(&uid_gen_, 1, memory_order_relaxed);\n+  SyncVar *res = new(mem) SyncVar(addr, uid);\n+#ifndef TSAN_GO\n+  res->creation_stack.ObtainCurrent(thr, pc);\n+#endif\n+  return res;\n+}\n+\n SyncVar* SyncTab::GetAndLock(ThreadState *thr, uptr pc,\n-                             uptr addr, bool write_lock) {\n+                             uptr addr, bool write_lock, bool create) {\n #ifndef TSAN_GO\n+  {  // NOLINT\n+    SyncVar *res = GetJavaSync(thr, pc, addr, write_lock, create);\n+    if (res)\n+      return res;\n+  }\n+\n+  // Here we ask only PrimaryAllocator, because\n+  // SecondaryAllocator::PointerIsMine() is slow and we have fallback on\n+  // the hashmap anyway.\n   if (PrimaryAllocator::PointerIsMine((void*)addr)) {\n     MBlock *b = user_mblock(thr, (void*)addr);\n     Lock l(&b->mtx);\n@@ -57,10 +87,9 @@ SyncVar* SyncTab::GetAndLock(ThreadState *thr, uptr pc,\n         break;\n     }\n     if (res == 0) {\n-      StatInc(thr, StatSyncCreated);\n-      void *mem = internal_alloc(MBlockSync, sizeof(SyncVar));\n-      res = new(mem) SyncVar(addr);\n-      res->creation_stack.ObtainCurrent(thr, pc);\n+      if (!create)\n+        return 0;\n+      res = Create(thr, pc, addr);\n       res->next = b->head;\n       b->head = res;\n     }\n@@ -85,6 +114,8 @@ SyncVar* SyncTab::GetAndLock(ThreadState *thr, uptr pc,\n       }\n     }\n   }\n+  if (!create)\n+    return 0;\n   {\n     Lock l(&p->mtx);\n     SyncVar *res = p->val;\n@@ -93,12 +124,7 @@ SyncVar* SyncTab::GetAndLock(ThreadState *thr, uptr pc,\n         break;\n     }\n     if (res == 0) {\n-      StatInc(thr, StatSyncCreated);\n-      void *mem = internal_alloc(MBlockSync, sizeof(SyncVar));\n-      res = new(mem) SyncVar(addr);\n-#ifndef TSAN_GO\n-      res->creation_stack.ObtainCurrent(thr, pc);\n-#endif\n+      res = Create(thr, pc, addr);\n       res->next = p->val;\n       p->val = res;\n     }\n@@ -112,6 +138,11 @@ SyncVar* SyncTab::GetAndLock(ThreadState *thr, uptr pc,\n \n SyncVar* SyncTab::GetAndRemove(ThreadState *thr, uptr pc, uptr addr) {\n #ifndef TSAN_GO\n+  {  // NOLINT\n+    SyncVar *res = GetAndRemoveJavaSync(thr, pc, addr);\n+    if (res)\n+      return res;\n+  }\n   if (PrimaryAllocator::PointerIsMine((void*)addr)) {\n     MBlock *b = user_mblock(thr, (void*)addr);\n     SyncVar *res = 0;"}, {"sha": "4dbb055a17e1de215df92f4512fcadb4faea8af5", "filename": "libsanitizer/tsan/tsan_sync.h", "status": "modified", "additions": 24, "deletions": 5, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_sync.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_sync.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_sync.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -48,12 +48,13 @@ class StackTrace {\n };\n \n struct SyncVar {\n-  explicit SyncVar(uptr addr);\n+  explicit SyncVar(uptr addr, u64 uid);\n \n   static const int kInvalidTid = -1;\n \n   Mutex mtx;\n-  const uptr addr;\n+  uptr addr;\n+  const u64 uid;  // Globally unique id.\n   SyncClock clock;\n   SyncClock read_clock;  // Used for rw mutexes only.\n   StackTrace creation_stack;\n@@ -67,20 +68,34 @@ struct SyncVar {\n   SyncVar *next;  // In SyncTab hashtable.\n \n   uptr GetMemoryConsumption();\n+  u64 GetId() const {\n+    // 47 lsb is addr, then 14 bits is low part of uid, then 3 zero bits.\n+    return GetLsb((u64)addr | (uid << 47), 61);\n+  }\n+  bool CheckId(u64 uid) const {\n+    CHECK_EQ(uid, GetLsb(uid, 14));\n+    return GetLsb(this->uid, 14) == uid;\n+  }\n+  static uptr SplitId(u64 id, u64 *uid) {\n+    *uid = id >> 47;\n+    return (uptr)GetLsb(id, 47);\n+  }\n };\n \n class SyncTab {\n  public:\n   SyncTab();\n   ~SyncTab();\n \n-  // If the SyncVar does not exist yet, it is created.\n-  SyncVar* GetAndLock(ThreadState *thr, uptr pc,\n-                      uptr addr, bool write_lock);\n+  SyncVar* GetOrCreateAndLock(ThreadState *thr, uptr pc,\n+                              uptr addr, bool write_lock);\n+  SyncVar* GetIfExistsAndLock(uptr addr, bool write_lock);\n \n   // If the SyncVar does not exist, returns 0.\n   SyncVar* GetAndRemove(ThreadState *thr, uptr pc, uptr addr);\n \n+  SyncVar* Create(ThreadState *thr, uptr pc, uptr addr);\n+\n   uptr GetMemoryConsumption(uptr *nsync);\n \n  private:\n@@ -94,9 +109,13 @@ class SyncTab {\n   // FIXME: Implement something more sane.\n   static const int kPartCount = 1009;\n   Part tab_[kPartCount];\n+  atomic_uint64_t uid_gen_;\n \n   int PartIdx(uptr addr);\n \n+  SyncVar* GetAndLock(ThreadState *thr, uptr pc,\n+                      uptr addr, bool write_lock, bool create);\n+\n   SyncTab(const SyncTab&);  // Not implemented.\n   void operator = (const SyncTab&);  // Not implemented.\n };"}, {"sha": "69864838e267e835bff5bd7df822b19ca82063a0", "filename": "libsanitizer/tsan/tsan_trace.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_trace.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e9772e16b39885fb70f6e3651a0b98d6de8655c3/libsanitizer%2Ftsan%2Ftsan_trace.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_trace.h?ref=e9772e16b39885fb70f6e3651a0b98d6de8655c3", "patch": "@@ -14,6 +14,7 @@\n #include \"tsan_defs.h\"\n #include \"tsan_mutex.h\"\n #include \"tsan_sync.h\"\n+#include \"tsan_mutexset.h\"\n \n namespace __tsan {\n \n@@ -41,6 +42,7 @@ typedef u64 Event;\n struct TraceHeader {\n   StackTrace stack0;  // Start stack for the trace.\n   u64        epoch0;  // Start epoch for the trace.\n+  MutexSet   mset0;\n #ifndef TSAN_GO\n   uptr       stack0buf[kTraceStackSize];\n #endif"}]}