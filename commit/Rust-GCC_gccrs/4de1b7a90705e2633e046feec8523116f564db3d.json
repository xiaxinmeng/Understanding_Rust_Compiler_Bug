{"sha": "4de1b7a90705e2633e046feec8523116f564db3d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NGRlMWI3YTkwNzA1ZTI2MzNlMDQ2ZmVlYzg1MjMxMTZmNTY0ZGIzZA==", "commit": {"author": {"name": "J\"orn Rennecke", "email": "joern.rennecke@superh.com", "date": "2002-06-25T20:39:18Z"}, "committer": {"name": "Joern Rennecke", "email": "amylaar@gcc.gnu.org", "date": "2002-06-25T20:39:18Z"}, "message": "lib1funcs.asm (udivdi3): Make first divide step produce a 32 bit result before normalization...\n\n\t* config/sh/lib1funcs.asm (udivdi3): Make first divide step\n\tproduce a 32 bit result before normalization, then normalize with a\n\tleft shift.  Compute approximative error of 2nd reciprocal\n\tapproximation in 2's complement.  Fix mask generation from upper\n\tlongword of second divide stage result.\n\tFor large divisor, fix shift count used to truncate first stage\n\tdivide result; make decision if to adjust upwards based on comparison\n\tof higher parts of normalized values.\n\t(udivdi): Likewise.  Undo normalization of result for large divisor\n\tcase.\n\nFrom-SVN: r54993", "tree": {"sha": "36fecfa562a5580522328656aed4a9f40a513966", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/36fecfa562a5580522328656aed4a9f40a513966"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4de1b7a90705e2633e046feec8523116f564db3d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4de1b7a90705e2633e046feec8523116f564db3d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4de1b7a90705e2633e046feec8523116f564db3d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4de1b7a90705e2633e046feec8523116f564db3d/comments", "author": null, "committer": null, "parents": [{"sha": "0e20c0b56f39546c2e70864c23e9de0a40a44571", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0e20c0b56f39546c2e70864c23e9de0a40a44571", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0e20c0b56f39546c2e70864c23e9de0a40a44571"}], "stats": {"total": 70, "additions": 43, "deletions": 27}, "files": [{"sha": "541c41a4a0ceed08d9a404a723d7f620c4fa5c55", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4de1b7a90705e2633e046feec8523116f564db3d/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4de1b7a90705e2633e046feec8523116f564db3d/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4de1b7a90705e2633e046feec8523116f564db3d", "patch": "@@ -1,3 +1,16 @@\n+Tue Jun 25 20:59:56 2002  J\"orn Rennecke <joern.rennecke@superh.com>\n+\n+\t* config/sh/lib1funcs.asm (udivdi3): Make first divide step \n+\tproduce a 32 bit result before normalization, then normalize with a\n+\tleft shift.  Compute approximative error of 2nd reciprocal\n+\tapproximation in 2's complement.  Fix mask generation from upper\n+\tlongword of second divide stage result.\n+\tFor large divisor, fix shift count used to truncate first stage\n+\tdivide result; make decision if to adjust upwards based on comparison\n+\tof higher parts of normalized values.\n+\t(udivdi): Likewise.  Undo normalization of result for large divisor\n+\tcase.\n+\n 2002-06-25  David S. Miller  <davem@redhat.com>\n \n \t* config/sparc/sparc.md: Change \\\\{t,n} to \\{t,n}."}, {"sha": "1021c9ba3b56ccc13b8a6bbddde06c7a4c13a2a2", "filename": "gcc/config/sh/lib1funcs.asm", "status": "modified", "additions": 30, "deletions": 27, "changes": 57, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4de1b7a90705e2633e046feec8523116f564db3d/gcc%2Fconfig%2Fsh%2Flib1funcs.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4de1b7a90705e2633e046feec8523116f564db3d/gcc%2Fconfig%2Fsh%2Flib1funcs.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Flib1funcs.asm?ref=4de1b7a90705e2633e046feec8523116f564db3d", "patch": "@@ -1501,33 +1501,33 @@ GLOBAL(udivdi3):\n \tshlri r6,32,r7\n \tbgt/u r9,r63,tr0 // large_divisor\n \tmmulfx.w r5,r4,r4\n-\tshlri r2,32,r19\n-\taddi r20,14-1,r0\n+\tshlri r2,32+14,r19\n+\taddi r22,-31,r0\n \tmsub.w r1,r4,r1\n \n \tmulu.l r1,r7,r4\n \taddi r1,-3,r5\n \tmulu.l r5,r19,r5\n+\tsub r63,r4,r4 // Negate to make sure r1 ends up <= 1/r2\n \tshlri r4,2,r4 /* chop off leading %0000000000000000 001.00000000000 - or, as\n \t                 the case may be, %0000000000000000 000.11111111111, still */\n \tmuls.l r1,r4,r4 /* leaving at least one sign bit.  */\n-\tshlrd r5,r0,r8\n-\tmulu.l r8,r3,r5\n+\tmulu.l r5,r3,r8\n \tmshalds.l r1,r21,r1\n \tshari r4,26,r4\n-\tshlli r5,32,r5\n-\tsub r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n-\tsub r2,r5,r2\n+\tshlld r8,r0,r8\n+\tadd r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n+\tsub r2,r8,r2\n \t/* Can do second step of 64 : 32 div now, using r1 and the rest in r2.  */\n \n \tshlri r2,22,r21\n \tmulu.l r21,r1,r21\n+\tshlld r5,r0,r8\n \taddi r20,30-22,r0\n-\tshlli r8,32,r8\n \tshlrd r21,r0,r21\n \tmulu.l r21,r3,r5\n \tadd r8,r21,r8\n-\tmcmpeq.l r21,r63,r21 // See Note 1\n+\tmcmpgt.l r21,r63,r21 // See Note 1\n \taddi r20,30,r0\n \tmshfhi.l r63,r21,r21\n \tsub r2,r5,r2\n@@ -1555,14 +1555,15 @@ LOCAL(large_divisor):\n \tmulu.l r1,r7,r4\n \taddi r1,-3,r5\n \tmulu.l r5,r8,r5\n+\tsub r63,r4,r4 // Negate to make sure r1 ends up <= 1/r2\n \tshlri r4,2,r4 /* chop off leading %0000000000000000 001.00000000000 - or, as\n \t                 the case may be, %0000000000000000 000.11111111111, still */\n \tmuls.l r1,r4,r4 /* leaving at least one sign bit.  */\n-\tshlri r5,14-1+32,r8\n+\tshlri r5,14-1,r8\n \tmulu.l r8,r7,r5\n \tmshalds.l r1,r21,r1\n \tshari r4,26,r4\n-\tsub r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n+\tadd r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n \tsub r25,r5,r25\n \t/* Can do second step of 64 : 32 div now, using r1 and the rest in r25.  */\n \n@@ -1575,11 +1576,11 @@ LOCAL(large_divisor):\n \tadd r8,r21,r8\n \tshlld r2,r0,r2\n \tsub r25,r5,r25\n-\tmextr4 r2,r25,r2\n-\tbgtu/u r6,r2,tr0 // no_lo_adj\n+\tbgtu/u r7,r25,tr0 // no_lo_adj\n \taddi r8,1,r8\n-\tsub r2,r6,r2\n+\tsub r25,r7,r25\n LOCAL(no_lo_adj):\n+\tmextr4 r2,r25,r2\n \n \t/* large_divisor: only needs a few adjustments.  */\n \tmulu.l r8,r6,r5\n@@ -1647,22 +1648,22 @@ GLOBAL(umoddi3):\n \tshlri r6,32,r7\n \tbgt/u r9,r63,tr0 // large_divisor\n \tmmulfx.w r5,r4,r4\n-\tshlri r2,32,r19\n-\taddi r20,14-1,r0\n+\tshlri r2,32+14,r19\n+\taddi r22,-31,r0\n \tmsub.w r1,r4,r1\n \n \tmulu.l r1,r7,r4\n \taddi r1,-3,r5\n \tmulu.l r5,r19,r5\n+\tsub r63,r4,r4 // Negate to make sure r1 ends up <= 1/r2\n \tshlri r4,2,r4 /* chop off leading %0000000000000000 001.00000000000 - or, as\n \t                 the case may be, %0000000000000000 000.11111111111, still */\n \tmuls.l r1,r4,r4 /* leaving at least one sign bit.  */\n-\tshlrd r5,r0,r8\n-\tmulu.l r8,r3,r5\n+\tmulu.l r5,r3,r5\n \tmshalds.l r1,r21,r1\n \tshari r4,26,r4\n-\tshlli r5,32,r5\n-\tsub r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n+\tshlld r5,r0,r5\n+\tadd r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n \tsub r2,r5,r2\n \t/* Can do second step of 64 : 32 div now, using r1 and the rest in r2.  */\n \n@@ -1672,7 +1673,7 @@ GLOBAL(umoddi3):\n \t/* bubble */ /* could test r3 here to check for divide by zero.  */\n \tshlrd r21,r0,r21\n \tmulu.l r21,r3,r5\n-\tmcmpeq.l r21,r63,r21 // See Note 1\n+\tmcmpgt.l r21,r63,r21 // See Note 1\n \taddi r20,30,r0\n \tmshfhi.l r63,r21,r21\n \tsub r2,r5,r2\n@@ -1700,14 +1701,15 @@ LOCAL(large_divisor):\n \tmulu.l r1,r7,r4\n \taddi r1,-3,r5\n \tmulu.l r5,r8,r5\n+\tsub r63,r4,r4 // Negate to make sure r1 ends up <= 1/r2\n \tshlri r4,2,r4 /* chop off leading %0000000000000000 001.00000000000 - or, as\n \t                 the case may be, %0000000000000000 000.11111111111, still */\n \tmuls.l r1,r4,r4 /* leaving at least one sign bit.  */\n-\tshlri r5,14-1+32,r8\n+\tshlri r5,14-1,r8\n \tmulu.l r8,r7,r5\n \tmshalds.l r1,r21,r1\n \tshari r4,26,r4\n-\tsub r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n+\tadd r1,r4,r1 // 31 bit unsigned reciprocal now in r1 (msb equiv. 0.5)\n \tsub r25,r5,r25\n \t/* Can do second step of 64 : 32 div now, using r1 and the rest in r25.  */\n \n@@ -1720,19 +1722,20 @@ LOCAL(large_divisor):\n \tadd r8,r21,r8\n \tshlld r2,r0,r2\n \tsub r25,r5,r25\n-\tmextr4 r2,r25,r2\n-\tbgtu/u r6,r2,tr0 // no_lo_adj\n+\tbgtu/u r7,r25,tr0 // no_lo_adj\n \taddi r8,1,r8\n-\tsub r2,r6,r2\n+\tsub r25,r7,r25\n LOCAL(no_lo_adj):\n+\tmextr4 r2,r25,r2\n \n \t/* large_divisor: only needs a few adjustments.  */\n \tmulu.l r8,r6,r5\n \tptabs r18,tr0\n-\tadd r2,r3,r7\n+\tadd r2,r6,r7\n \tcmpgtu r5,r2,r8\n \tcmvne r8,r7,r2\n \tsub r2,r5,r2\n+\tshlrd r2,r22,r2\n \tblink tr0,r63\n /* Note 1: To shift the result of the second divide stage so that the result\n    always fits into 32 bits, yet we still reduce the rest sufficiently"}]}