{"sha": "c48d2d35a122798c047ca7a0f7e0d64293023c44", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzQ4ZDJkMzVhMTIyNzk4YzA0N2NhN2EwZjdlMGQ2NDI5MzAyM2M0NA==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2018-01-03T21:47:26Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2018-01-03T21:47:26Z"}, "message": "Split gather load handling out of vectorizable_{mask_load_store,load}\n\nvectorizable_mask_load_store and vectorizable_load used the same\ncode to build a gather load call, except that the former also\nvectorised a mask argument and used it for both the merge and mask\ninputs.  The latter instead used a merge input of zero and a mask\ninput of all-ones.  This patch splits it out into a subroutine.\n\n2018-01-03  Richard Sandiford  <richard.sandiford@linaro.org>\n\ngcc/\n\t* tree-vect-stmts.c (vect_build_gather_load_calls): New function,\n\tsplit out from..,\n\t(vectorizable_mask_load_store): ...here.\n\t(vectorizable_load): ...and here.\n\nFrom-SVN: r256215", "tree": {"sha": "5aa12c5ea2e28465c05b6b91666c98449c59266a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/5aa12c5ea2e28465c05b6b91666c98449c59266a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c48d2d35a122798c047ca7a0f7e0d64293023c44", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c48d2d35a122798c047ca7a0f7e0d64293023c44", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c48d2d35a122798c047ca7a0f7e0d64293023c44", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c48d2d35a122798c047ca7a0f7e0d64293023c44/comments", "author": null, "committer": null, "parents": [{"sha": "bc9587eb19f6407f5815d46d68325890e29f076a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bc9587eb19f6407f5815d46d68325890e29f076a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bc9587eb19f6407f5815d46d68325890e29f076a"}], "stats": {"total": 520, "additions": 214, "deletions": 306}, "files": [{"sha": "7ae8c3dc3d3f292e36c25556df73ae5203c04ba0", "filename": "gcc/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c48d2d35a122798c047ca7a0f7e0d64293023c44/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c48d2d35a122798c047ca7a0f7e0d64293023c44/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c48d2d35a122798c047ca7a0f7e0d64293023c44", "patch": "@@ -1,3 +1,10 @@\n+2018-01-03  Richard Sandiford  <richard.sandiford@linaro.org>\n+\n+\t* tree-vect-stmts.c (vect_build_gather_load_calls): New function,\n+\tsplit out from..,\n+\t(vectorizable_mask_load_store): ...here.\n+\t(vectorizable_load): ...and here.\n+\n 2018-01-03  Richard Sandiford  <richard.sandiford@linaro.org>\n \n \t* tree-vect-stmts.c (vect_build_all_ones_mask)"}, {"sha": "7a5158298526eb27fe33be87cbe0396be16aed71", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 207, "deletions": 306, "changes": 513, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c48d2d35a122798c047ca7a0f7e0d64293023c44/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c48d2d35a122798c047ca7a0f7e0d64293023c44/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=c48d2d35a122798c047ca7a0f7e0d64293023c44", "patch": "@@ -2194,6 +2194,210 @@ vect_build_zero_merge_argument (gimple *stmt, tree vectype)\n   return vect_init_vector (stmt, merge, vectype, NULL);\n }\n \n+/* Build a gather load call while vectorizing STMT.  Insert new instructions\n+   before GSI and add them to VEC_STMT.  GS_INFO describes the gather load\n+   operation.  If the load is conditional, MASK is the unvectorized\n+   condition, otherwise MASK is null.  */\n+\n+static void\n+vect_build_gather_load_calls (gimple *stmt, gimple_stmt_iterator *gsi,\n+\t\t\t      gimple **vec_stmt, gather_scatter_info *gs_info,\n+\t\t\t      tree mask)\n+{\n+  stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n+  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  struct loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n+  tree vectype = STMT_VINFO_VECTYPE (stmt_info);\n+  poly_uint64 nunits = TYPE_VECTOR_SUBPARTS (vectype);\n+  int ncopies = vect_get_num_copies (loop_vinfo, vectype);\n+  edge pe = loop_preheader_edge (loop);\n+  enum { NARROW, NONE, WIDEN } modifier;\n+  poly_uint64 gather_off_nunits\n+    = TYPE_VECTOR_SUBPARTS (gs_info->offset_vectype);\n+\n+  tree arglist = TYPE_ARG_TYPES (TREE_TYPE (gs_info->decl));\n+  tree rettype = TREE_TYPE (TREE_TYPE (gs_info->decl));\n+  tree srctype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n+  tree ptrtype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n+  tree idxtype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n+  tree masktype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n+  tree scaletype = TREE_VALUE (arglist);\n+  gcc_checking_assert (types_compatible_p (srctype, rettype)\n+\t\t       && (!mask || types_compatible_p (srctype, masktype)));\n+\n+  tree perm_mask = NULL_TREE;\n+  tree mask_perm_mask = NULL_TREE;\n+  if (known_eq (nunits, gather_off_nunits))\n+    modifier = NONE;\n+  else if (known_eq (nunits * 2, gather_off_nunits))\n+    {\n+      modifier = WIDEN;\n+\n+      /* Currently widening gathers and scatters are only supported for\n+\t fixed-length vectors.  */\n+      int count = gather_off_nunits.to_constant ();\n+      vec_perm_builder sel (count, count, 1);\n+      for (int i = 0; i < count; ++i)\n+\tsel.quick_push (i | (count / 2));\n+\n+      vec_perm_indices indices (sel, 1, count);\n+      perm_mask = vect_gen_perm_mask_checked (gs_info->offset_vectype,\n+\t\t\t\t\t      indices);\n+    }\n+  else if (known_eq (nunits, gather_off_nunits * 2))\n+    {\n+      modifier = NARROW;\n+\n+      /* Currently narrowing gathers and scatters are only supported for\n+\t fixed-length vectors.  */\n+      int count = nunits.to_constant ();\n+      vec_perm_builder sel (count, count, 1);\n+      sel.quick_grow (count);\n+      for (int i = 0; i < count; ++i)\n+\tsel[i] = i < count / 2 ? i : i + count / 2;\n+      vec_perm_indices indices (sel, 2, count);\n+      perm_mask = vect_gen_perm_mask_checked (vectype, indices);\n+\n+      ncopies *= 2;\n+\n+      if (mask)\n+\t{\n+\t  for (int i = 0; i < count; ++i)\n+\t    sel[i] = i | (count / 2);\n+\t  indices.new_vector (sel, 2, count);\n+\t  mask_perm_mask = vect_gen_perm_mask_checked (masktype, indices);\n+\t}\n+    }\n+  else\n+    gcc_unreachable ();\n+\n+  tree vec_dest = vect_create_destination_var (gimple_get_lhs (stmt),\n+\t\t\t\t\t       vectype);\n+\n+  tree ptr = fold_convert (ptrtype, gs_info->base);\n+  if (!is_gimple_min_invariant (ptr))\n+    {\n+      gimple_seq seq;\n+      ptr = force_gimple_operand (ptr, &seq, true, NULL_TREE);\n+      basic_block new_bb = gsi_insert_seq_on_edge_immediate (pe, seq);\n+      gcc_assert (!new_bb);\n+    }\n+\n+  tree scale = build_int_cst (scaletype, gs_info->scale);\n+\n+  tree vec_oprnd0 = NULL_TREE;\n+  tree vec_mask = NULL_TREE;\n+  tree src_op = NULL_TREE;\n+  tree mask_op = NULL_TREE;\n+  tree prev_res = NULL_TREE;\n+  stmt_vec_info prev_stmt_info = NULL;\n+\n+  if (!mask)\n+    {\n+      src_op = vect_build_zero_merge_argument (stmt, rettype);\n+      mask_op = vect_build_all_ones_mask (stmt, masktype);\n+    }\n+\n+  for (int j = 0; j < ncopies; ++j)\n+    {\n+      tree op, var;\n+      gimple *new_stmt;\n+      if (modifier == WIDEN && (j & 1))\n+\top = permute_vec_elements (vec_oprnd0, vec_oprnd0,\n+\t\t\t\t   perm_mask, stmt, gsi);\n+      else if (j == 0)\n+\top = vec_oprnd0\n+\t  = vect_get_vec_def_for_operand (gs_info->offset, stmt);\n+      else\n+\top = vec_oprnd0\n+\t  = vect_get_vec_def_for_stmt_copy (gs_info->offset_dt, vec_oprnd0);\n+\n+      if (!useless_type_conversion_p (idxtype, TREE_TYPE (op)))\n+\t{\n+\t  gcc_assert (known_eq (TYPE_VECTOR_SUBPARTS (TREE_TYPE (op)),\n+\t\t\t\tTYPE_VECTOR_SUBPARTS (idxtype)));\n+\t  var = vect_get_new_ssa_name (idxtype, vect_simple_var);\n+\t  op = build1 (VIEW_CONVERT_EXPR, idxtype, op);\n+\t  new_stmt = gimple_build_assign (var, VIEW_CONVERT_EXPR, op);\n+\t  vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+\t  op = var;\n+\t}\n+\n+      if (mask)\n+\t{\n+\t  if (mask_perm_mask && (j & 1))\n+\t    mask_op = permute_vec_elements (mask_op, mask_op,\n+\t\t\t\t\t    mask_perm_mask, stmt, gsi);\n+\t  else\n+\t    {\n+\t      if (j == 0)\n+\t\tvec_mask = vect_get_vec_def_for_operand (mask, stmt);\n+\t      else\n+\t\t{\n+\t\t  gimple *def_stmt;\n+\t\t  enum vect_def_type dt;\n+\t\t  vect_is_simple_use (vec_mask, loop_vinfo, &def_stmt, &dt);\n+\t\t  vec_mask = vect_get_vec_def_for_stmt_copy (dt, vec_mask);\n+\t\t}\n+\n+\t      mask_op = vec_mask;\n+\t      if (!useless_type_conversion_p (masktype, TREE_TYPE (vec_mask)))\n+\t\t{\n+\t\t  gcc_assert\n+\t\t    (known_eq (TYPE_VECTOR_SUBPARTS (TREE_TYPE (mask_op)),\n+\t\t\t       TYPE_VECTOR_SUBPARTS (masktype)));\n+\t\t  var = vect_get_new_ssa_name (masktype, vect_simple_var);\n+\t\t  mask_op = build1 (VIEW_CONVERT_EXPR, masktype, mask_op);\n+\t\t  new_stmt = gimple_build_assign (var, VIEW_CONVERT_EXPR,\n+\t\t\t\t\t\t  mask_op);\n+\t\t  vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+\t\t  mask_op = var;\n+\t\t}\n+\t    }\n+\t  src_op = mask_op;\n+\t}\n+\n+      new_stmt = gimple_build_call (gs_info->decl, 5, src_op, ptr, op,\n+\t\t\t\t    mask_op, scale);\n+\n+      if (!useless_type_conversion_p (vectype, rettype))\n+\t{\n+\t  gcc_assert (known_eq (TYPE_VECTOR_SUBPARTS (vectype),\n+\t\t\t\tTYPE_VECTOR_SUBPARTS (rettype)));\n+\t  op = vect_get_new_ssa_name (rettype, vect_simple_var);\n+\t  gimple_call_set_lhs (new_stmt, op);\n+\t  vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+\t  var = make_ssa_name (vec_dest);\n+\t  op = build1 (VIEW_CONVERT_EXPR, vectype, op);\n+\t  new_stmt = gimple_build_assign (var, VIEW_CONVERT_EXPR, op);\n+\t}\n+      else\n+\t{\n+\t  var = make_ssa_name (vec_dest, new_stmt);\n+\t  gimple_call_set_lhs (new_stmt, var);\n+\t}\n+\n+      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+\n+      if (modifier == NARROW)\n+\t{\n+\t  if ((j & 1) == 0)\n+\t    {\n+\t      prev_res = var;\n+\t      continue;\n+\t    }\n+\t  var = permute_vec_elements (prev_res, var, perm_mask, stmt, gsi);\n+\t  new_stmt = SSA_NAME_DEF_STMT (var);\n+\t}\n+\n+      if (prev_stmt_info == NULL)\n+\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt;\n+      else\n+\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt;\n+      prev_stmt_info = vinfo_for_stmt (new_stmt);\n+    }\n+}\n+\n /* Function vectorizable_mask_load_store.\n \n    Check if STMT performs a conditional load or store that can be vectorized.\n@@ -2220,9 +2424,8 @@ vectorizable_mask_load_store (gimple *stmt, gimple_stmt_iterator *gsi,\n   tree dummy;\n   tree dataref_ptr = NULL_TREE;\n   gimple *ptr_incr;\n-  poly_uint64 nunits = TYPE_VECTOR_SUBPARTS (vectype);\n   int ncopies;\n-  int i, j;\n+  int i;\n   bool inv_p;\n   gather_scatter_info gs_info;\n   vec_load_store_type vls_type;\n@@ -2320,174 +2523,7 @@ vectorizable_mask_load_store (gimple *stmt, gimple_stmt_iterator *gsi,\n \n   if (memory_access_type == VMAT_GATHER_SCATTER)\n     {\n-      tree vec_oprnd0 = NULL_TREE, op;\n-      tree arglist = TYPE_ARG_TYPES (TREE_TYPE (gs_info.decl));\n-      tree rettype, srctype, ptrtype, idxtype, masktype, scaletype;\n-      tree ptr, vec_mask = NULL_TREE, mask_op = NULL_TREE, var, scale;\n-      tree perm_mask = NULL_TREE, prev_res = NULL_TREE;\n-      tree mask_perm_mask = NULL_TREE;\n-      edge pe = loop_preheader_edge (loop);\n-      gimple_seq seq;\n-      basic_block new_bb;\n-      enum { NARROW, NONE, WIDEN } modifier;\n-      poly_uint64 gather_off_nunits\n-\t= TYPE_VECTOR_SUBPARTS (gs_info.offset_vectype);\n-\n-      rettype = TREE_TYPE (TREE_TYPE (gs_info.decl));\n-      srctype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n-      ptrtype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n-      idxtype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n-      masktype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n-      scaletype = TREE_VALUE (arglist);\n-      gcc_checking_assert (types_compatible_p (srctype, rettype)\n-\t\t\t   && types_compatible_p (srctype, masktype));\n-\n-      if (known_eq (nunits, gather_off_nunits))\n-\tmodifier = NONE;\n-      else if (known_eq (nunits * 2, gather_off_nunits))\n-\t{\n-\t  modifier = WIDEN;\n-\n-\t  /* Currently widening gathers and scatters are only supported for\n-\t     fixed-length vectors.  */\n-\t  int count = gather_off_nunits.to_constant ();\n-\t  vec_perm_builder sel (count, count, 1);\n-\t  for (i = 0; i < count; ++i)\n-\t    sel.quick_push (i | (count / 2));\n-\n-\t  vec_perm_indices indices (sel, 1, count);\n-\t  perm_mask = vect_gen_perm_mask_checked (gs_info.offset_vectype,\n-\t\t\t\t\t\t  indices);\n-\t}\n-      else if (known_eq (nunits, gather_off_nunits * 2))\n-\t{\n-\t  modifier = NARROW;\n-\n-\t  /* Currently narrowing gathers and scatters are only supported for\n-\t     fixed-length vectors.  */\n-\t  int count = nunits.to_constant ();\n-\t  vec_perm_builder sel (count, count, 1);\n-\t  sel.quick_grow (count);\n-\t  for (i = 0; i < count; ++i)\n-\t    sel[i] = i < count / 2 ? i : i + count / 2;\n-\t  vec_perm_indices indices (sel, 2, count);\n-\t  perm_mask = vect_gen_perm_mask_checked (vectype, indices);\n-\n-\t  ncopies *= 2;\n-\t  for (i = 0; i < count; ++i)\n-\t    sel[i] = i | (count / 2);\n-\t  indices.new_vector (sel, 2, count);\n-\t  mask_perm_mask = vect_gen_perm_mask_checked (masktype, indices);\n-\t}\n-      else\n-\tgcc_unreachable ();\n-\n-      vec_dest = vect_create_destination_var (gimple_call_lhs (stmt), vectype);\n-\n-      ptr = fold_convert (ptrtype, gs_info.base);\n-      if (!is_gimple_min_invariant (ptr))\n-\t{\n-\t  ptr = force_gimple_operand (ptr, &seq, true, NULL_TREE);\n-\t  new_bb = gsi_insert_seq_on_edge_immediate (pe, seq);\n-\t  gcc_assert (!new_bb);\n-\t}\n-\n-      scale = build_int_cst (scaletype, gs_info.scale);\n-\n-      prev_stmt_info = NULL;\n-      for (j = 0; j < ncopies; ++j)\n-\t{\n-\t  if (modifier == WIDEN && (j & 1))\n-\t    op = permute_vec_elements (vec_oprnd0, vec_oprnd0,\n-\t\t\t\t       perm_mask, stmt, gsi);\n-\t  else if (j == 0)\n-\t    op = vec_oprnd0\n-\t      = vect_get_vec_def_for_operand (gs_info.offset, stmt);\n-\t  else\n-\t    op = vec_oprnd0\n-\t      = vect_get_vec_def_for_stmt_copy (gs_info.offset_dt, vec_oprnd0);\n-\n-\t  if (!useless_type_conversion_p (idxtype, TREE_TYPE (op)))\n-\t    {\n-\t      gcc_assert (known_eq (TYPE_VECTOR_SUBPARTS (TREE_TYPE (op)),\n-\t\t\t\t    TYPE_VECTOR_SUBPARTS (idxtype)));\n-\t      var = vect_get_new_ssa_name (idxtype, vect_simple_var);\n-\t      op = build1 (VIEW_CONVERT_EXPR, idxtype, op);\n-\t      new_stmt\n-\t\t= gimple_build_assign (var, VIEW_CONVERT_EXPR, op);\n-\t      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\t      op = var;\n-\t    }\n-\n-\t  if (mask_perm_mask && (j & 1))\n-\t    mask_op = permute_vec_elements (mask_op, mask_op,\n-\t\t\t\t\t    mask_perm_mask, stmt, gsi);\n-\t  else\n-\t    {\n-\t      if (j == 0)\n-\t\tvec_mask = vect_get_vec_def_for_operand (mask, stmt);\n-\t      else\n-\t\t{\n-\t\t  vect_is_simple_use (vec_mask, loop_vinfo, &def_stmt, &dt);\n-\t\t  vec_mask = vect_get_vec_def_for_stmt_copy (dt, vec_mask);\n-\t\t}\n-\n-\t      mask_op = vec_mask;\n-\t      if (!useless_type_conversion_p (masktype, TREE_TYPE (vec_mask)))\n-\t\t{\n-\t\t  gcc_assert\n-\t\t    (known_eq (TYPE_VECTOR_SUBPARTS (TREE_TYPE (mask_op)),\n-\t\t\t       TYPE_VECTOR_SUBPARTS (masktype)));\n-\t\t  var = vect_get_new_ssa_name (masktype, vect_simple_var);\n-\t\t  mask_op = build1 (VIEW_CONVERT_EXPR, masktype, mask_op);\n-\t\t  new_stmt\n-\t\t    = gimple_build_assign (var, VIEW_CONVERT_EXPR, mask_op);\n-\t\t  vect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\t\t  mask_op = var;\n-\t\t}\n-\t    }\n-\n-\t  new_stmt\n-\t    = gimple_build_call (gs_info.decl, 5, mask_op, ptr, op, mask_op,\n-\t\t\t\t scale);\n-\n-\t  if (!useless_type_conversion_p (vectype, rettype))\n-\t    {\n-\t      gcc_assert (known_eq (TYPE_VECTOR_SUBPARTS (vectype),\n-\t\t\t\t    TYPE_VECTOR_SUBPARTS (rettype)));\n-\t      op = vect_get_new_ssa_name (rettype, vect_simple_var);\n-\t      gimple_call_set_lhs (new_stmt, op);\n-\t      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\t      var = make_ssa_name (vec_dest);\n-\t      op = build1 (VIEW_CONVERT_EXPR, vectype, op);\n-\t      new_stmt = gimple_build_assign (var, VIEW_CONVERT_EXPR, op);\n-\t    }\n-\t  else\n-\t    {\n-\t      var = make_ssa_name (vec_dest, new_stmt);\n-\t      gimple_call_set_lhs (new_stmt, var);\n-\t    }\n-\n-\t  vect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\n-\t  if (modifier == NARROW)\n-\t    {\n-\t      if ((j & 1) == 0)\n-\t\t{\n-\t\t  prev_res = var;\n-\t\t  continue;\n-\t\t}\n-\t      var = permute_vec_elements (prev_res, var,\n-\t\t\t\t\t  perm_mask, stmt, gsi);\n-\t      new_stmt = SSA_NAME_DEF_STMT (var);\n-\t    }\n-\n-\t  if (prev_stmt_info == NULL)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt;\n-\t  prev_stmt_info = vinfo_for_stmt (new_stmt);\n-\t}\n+      vect_build_gather_load_calls (stmt, gsi, vec_stmt, &gs_info, mask);\n       return true;\n     }\n   else if (vls_type != VLS_LOAD)\n@@ -6998,142 +7034,7 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \n   if (memory_access_type == VMAT_GATHER_SCATTER)\n     {\n-      tree vec_oprnd0 = NULL_TREE, op;\n-      tree arglist = TYPE_ARG_TYPES (TREE_TYPE (gs_info.decl));\n-      tree rettype, srctype, ptrtype, idxtype, masktype, scaletype;\n-      tree ptr, mask, var, scale, merge, perm_mask = NULL_TREE, prev_res = NULL_TREE;\n-      edge pe = loop_preheader_edge (loop);\n-      gimple_seq seq;\n-      basic_block new_bb;\n-      enum { NARROW, NONE, WIDEN } modifier;\n-      poly_uint64 gather_off_nunits\n-\t= TYPE_VECTOR_SUBPARTS (gs_info.offset_vectype);\n-\n-      if (known_eq (nunits, gather_off_nunits))\n-\tmodifier = NONE;\n-      else if (known_eq (nunits * 2, gather_off_nunits))\n-\t{\n-\t  modifier = WIDEN;\n-\n-\t  /* Currently widening gathers are only supported for\n-\t     fixed-length vectors.  */\n-\t  int count = gather_off_nunits.to_constant ();\n-\t  vec_perm_builder sel (count, count, 1);\n-\t  for (i = 0; i < count; ++i)\n-\t    sel.quick_push (i | (count / 2));\n-\n-\t  vec_perm_indices indices (sel, 1, count);\n-\t  perm_mask = vect_gen_perm_mask_checked (gs_info.offset_vectype,\n-\t\t\t\t\t\t  indices);\n-\t}\n-      else if (known_eq (nunits, gather_off_nunits * 2))\n-\t{\n-\t  modifier = NARROW;\n-\n-\t  /* Currently narrowing gathers are only supported for\n-\t     fixed-length vectors.  */\n-\t  int count = nunits.to_constant ();\n-\t  vec_perm_builder sel (count, count, 1);\n-\t  for (i = 0; i < count; ++i)\n-\t    sel.quick_push (i < count / 2 ? i : i + count / 2);\n-\n-\t  vec_perm_indices indices (sel, 2, count);\n-\t  perm_mask = vect_gen_perm_mask_checked (vectype, indices);\n-\t  ncopies *= 2;\n-\t}\n-      else\n-\tgcc_unreachable ();\n-\n-      rettype = TREE_TYPE (TREE_TYPE (gs_info.decl));\n-      srctype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n-      ptrtype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n-      idxtype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n-      masktype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n-      scaletype = TREE_VALUE (arglist);\n-      gcc_checking_assert (types_compatible_p (srctype, rettype));\n-\n-      vec_dest = vect_create_destination_var (scalar_dest, vectype);\n-\n-      ptr = fold_convert (ptrtype, gs_info.base);\n-      if (!is_gimple_min_invariant (ptr))\n-\t{\n-\t  ptr = force_gimple_operand (ptr, &seq, true, NULL_TREE);\n-\t  new_bb = gsi_insert_seq_on_edge_immediate (pe, seq);\n-\t  gcc_assert (!new_bb);\n-\t}\n-\n-      /* Currently we support only unconditional gather loads,\n-\t so mask should be all ones.  */\n-      mask = vect_build_all_ones_mask (stmt, masktype);\n-      scale = build_int_cst (scaletype, gs_info.scale);\n-      merge = vect_build_zero_merge_argument (stmt, rettype);\n-\n-      prev_stmt_info = NULL;\n-      for (j = 0; j < ncopies; ++j)\n-\t{\n-\t  if (modifier == WIDEN && (j & 1))\n-\t    op = permute_vec_elements (vec_oprnd0, vec_oprnd0,\n-\t\t\t\t       perm_mask, stmt, gsi);\n-\t  else if (j == 0)\n-\t    op = vec_oprnd0\n-\t      = vect_get_vec_def_for_operand (gs_info.offset, stmt);\n-\t  else\n-\t    op = vec_oprnd0\n-\t      = vect_get_vec_def_for_stmt_copy (gs_info.offset_dt, vec_oprnd0);\n-\n-\t  if (!useless_type_conversion_p (idxtype, TREE_TYPE (op)))\n-\t    {\n-\t      gcc_assert (known_eq (TYPE_VECTOR_SUBPARTS (TREE_TYPE (op)),\n-\t\t\t\t    TYPE_VECTOR_SUBPARTS (idxtype)));\n-\t      var = vect_get_new_ssa_name (idxtype, vect_simple_var);\n-\t      op = build1 (VIEW_CONVERT_EXPR, idxtype, op);\n-\t      new_stmt\n-\t\t= gimple_build_assign (var, VIEW_CONVERT_EXPR, op);\n-\t      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\t      op = var;\n-\t    }\n-\n-\t  new_stmt\n-\t    = gimple_build_call (gs_info.decl, 5, merge, ptr, op, mask, scale);\n-\n-\t  if (!useless_type_conversion_p (vectype, rettype))\n-\t    {\n-\t      gcc_assert (known_eq (TYPE_VECTOR_SUBPARTS (vectype),\n-\t\t\t\t    TYPE_VECTOR_SUBPARTS (rettype)));\n-\t      op = vect_get_new_ssa_name (rettype, vect_simple_var);\n-\t      gimple_call_set_lhs (new_stmt, op);\n-\t      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\t      var = make_ssa_name (vec_dest);\n-\t      op = build1 (VIEW_CONVERT_EXPR, vectype, op);\n-\t      new_stmt\n-\t\t= gimple_build_assign (var, VIEW_CONVERT_EXPR, op);\n-\t    }\n-\t  else\n-\t    {\n-\t      var = make_ssa_name (vec_dest, new_stmt);\n-\t      gimple_call_set_lhs (new_stmt, var);\n-\t    }\n-\n-\t  vect_finish_stmt_generation (stmt, new_stmt, gsi);\n-\n-\t  if (modifier == NARROW)\n-\t    {\n-\t      if ((j & 1) == 0)\n-\t\t{\n-\t\t  prev_res = var;\n-\t\t  continue;\n-\t\t}\n-\t      var = permute_vec_elements (prev_res, var,\n-\t\t\t\t\t  perm_mask, stmt, gsi);\n-\t      new_stmt = SSA_NAME_DEF_STMT (var);\n-\t    }\n-\n-\t  if (prev_stmt_info == NULL)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt;\n-\t  prev_stmt_info = vinfo_for_stmt (new_stmt);\n-\t}\n+      vect_build_gather_load_calls (stmt, gsi, vec_stmt, &gs_info, NULL_TREE);\n       return true;\n     }\n "}]}