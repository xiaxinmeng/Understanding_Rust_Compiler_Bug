{"sha": "1bff101b7e66feed0efc7f656468647e0b5fb48c", "node_id": "C_kwDOANBUbNoAKDFiZmYxMDFiN2U2NmZlZWQwZWZjN2Y2NTY0Njg2NDdlMGI1ZmI0OGM", "commit": {"author": {"name": "Ju-Zhe Zhong", "email": "juzhe.zhong@rivai.ai", "date": "2023-02-27T10:32:25Z"}, "committer": {"name": "Kito Cheng", "email": "kito.cheng@sifive.com", "date": "2023-03-05T09:16:30Z"}, "message": "RISC-V: Add permutation C/C++ support\n\ngcc/ChangeLog:\n\n\t* config/riscv/riscv-protos.h (enum vlen_enum): New enum.\n\t(slide1_sew64_helper): New function.\n\t* config/riscv/riscv-v.cc (compute_vlmax): Ditto.\n\t(get_unknown_min_value): Ditto.\n\t(force_vector_length_operand): Ditto.\n\t(gen_no_side_effects_vsetvl_rtx): Ditto.\n\t(get_vl_x2_rtx): Ditto.\n\t(slide1_sew64_helper): Ditto.\n\t* config/riscv/riscv-vector-builtins-bases.cc (class slideop): New class.\n\t(class vrgather): Ditto.\n\t(class vrgatherei16): Ditto.\n\t(class vcompress): Ditto.\n\t(BASE): Ditto.\n\t* config/riscv/riscv-vector-builtins-bases.h: Ditto.\n\t* config/riscv/riscv-vector-builtins-functions.def (vslideup): Ditto.\n\t(vslidedown): Ditto.\n\t(vslide1up): Ditto.\n\t(vslide1down): Ditto.\n\t(vfslide1up): Ditto.\n\t(vfslide1down): Ditto.\n\t(vrgather): Ditto.\n\t(vrgatherei16): Ditto.\n\t(vcompress): Ditto.\n\t* config/riscv/riscv-vector-builtins-types.def (DEF_RVV_EI16_OPS): New macro.\n\t(vint8mf8_t): Ditto.\n\t(vint8mf4_t): Ditto.\n\t(vint8mf2_t): Ditto.\n\t(vint8m1_t): Ditto.\n\t(vint8m2_t): Ditto.\n\t(vint8m4_t): Ditto.\n\t(vint16mf4_t): Ditto.\n\t(vint16mf2_t): Ditto.\n\t(vint16m1_t): Ditto.\n\t(vint16m2_t): Ditto.\n\t(vint16m4_t): Ditto.\n\t(vint16m8_t): Ditto.\n\t(vint32mf2_t): Ditto.\n\t(vint32m1_t): Ditto.\n\t(vint32m2_t): Ditto.\n\t(vint32m4_t): Ditto.\n\t(vint32m8_t): Ditto.\n\t(vint64m1_t): Ditto.\n\t(vint64m2_t): Ditto.\n\t(vint64m4_t): Ditto.\n\t(vint64m8_t): Ditto.\n\t(vuint8mf8_t): Ditto.\n\t(vuint8mf4_t): Ditto.\n\t(vuint8mf2_t): Ditto.\n\t(vuint8m1_t): Ditto.\n\t(vuint8m2_t): Ditto.\n\t(vuint8m4_t): Ditto.\n\t(vuint16mf4_t): Ditto.\n\t(vuint16mf2_t): Ditto.\n\t(vuint16m1_t): Ditto.\n\t(vuint16m2_t): Ditto.\n\t(vuint16m4_t): Ditto.\n\t(vuint16m8_t): Ditto.\n\t(vuint32mf2_t): Ditto.\n\t(vuint32m1_t): Ditto.\n\t(vuint32m2_t): Ditto.\n\t(vuint32m4_t): Ditto.\n\t(vuint32m8_t): Ditto.\n\t(vuint64m1_t): Ditto.\n\t(vuint64m2_t): Ditto.\n\t(vuint64m4_t): Ditto.\n\t(vuint64m8_t): Ditto.\n\t(vfloat32mf2_t): Ditto.\n\t(vfloat32m1_t): Ditto.\n\t(vfloat32m2_t): Ditto.\n\t(vfloat32m4_t): Ditto.\n\t(vfloat32m8_t): Ditto.\n\t(vfloat64m1_t): Ditto.\n\t(vfloat64m2_t): Ditto.\n\t(vfloat64m4_t): Ditto.\n\t(vfloat64m8_t): Ditto.\n\t* config/riscv/riscv-vector-builtins.cc (DEF_RVV_EI16_OPS): Ditto.\n\t* config/riscv/riscv.md: Adjust RVV instruction types.\n\t* config/riscv/vector-iterators.md (down): New iterator.\n\t(=vd,vr): New attribute.\n\t(UNSPEC_VSLIDE1UP): New unspec.\n\t* config/riscv/vector.md (@pred_slide<ud><mode>): New pattern.\n\t(*pred_slide<ud><mode>): Ditto.\n\t(*pred_slide<ud><mode>_extended): Ditto.\n\t(@pred_gather<mode>): Ditto.\n\t(@pred_gather<mode>_scalar): Ditto.\n\t(@pred_gatherei16<mode>): Ditto.\n\t(@pred_compress<mode>): Ditto.\n\ngcc/testsuite/ChangeLog:\n\n\t* gcc.target/riscv/rvv/base/binop_vx_constraint-167.c: New test.\n\t* gcc.target/riscv/rvv/base/binop_vx_constraint-168.c: New test.\n\t* gcc.target/riscv/rvv/base/binop_vx_constraint-169.c: New test.\n\t* gcc.target/riscv/rvv/base/binop_vx_constraint-170.c: New test.\n\t* gcc.target/riscv/rvv/base/binop_vx_constraint-171.c: New test.\n\t* gcc.target/riscv/rvv/base/binop_vx_constraint-172.c: New test.\n\t* gcc.target/riscv/rvv/base/binop_vx_constraint-173.c: New test.\n\t* gcc.target/riscv/rvv/base/binop_vx_constraint-174.c: New test.", "tree": {"sha": "31cd30bc7de0db1dd7261285cea3d5a41ef297fc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/31cd30bc7de0db1dd7261285cea3d5a41ef297fc"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1bff101b7e66feed0efc7f656468647e0b5fb48c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1bff101b7e66feed0efc7f656468647e0b5fb48c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1bff101b7e66feed0efc7f656468647e0b5fb48c", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1bff101b7e66feed0efc7f656468647e0b5fb48c/comments", "author": {"login": "zhongjuzhe", "id": 66454988, "node_id": "MDQ6VXNlcjY2NDU0OTg4", "avatar_url": "https://avatars.githubusercontent.com/u/66454988?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhongjuzhe", "html_url": "https://github.com/zhongjuzhe", "followers_url": "https://api.github.com/users/zhongjuzhe/followers", "following_url": "https://api.github.com/users/zhongjuzhe/following{/other_user}", "gists_url": "https://api.github.com/users/zhongjuzhe/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhongjuzhe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhongjuzhe/subscriptions", "organizations_url": "https://api.github.com/users/zhongjuzhe/orgs", "repos_url": "https://api.github.com/users/zhongjuzhe/repos", "events_url": "https://api.github.com/users/zhongjuzhe/events{/privacy}", "received_events_url": "https://api.github.com/users/zhongjuzhe/received_events", "type": "User", "site_admin": false}, "committer": {"login": "kito-cheng", "id": 2723185, "node_id": "MDQ6VXNlcjI3MjMxODU=", "avatar_url": "https://avatars.githubusercontent.com/u/2723185?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kito-cheng", "html_url": "https://github.com/kito-cheng", "followers_url": "https://api.github.com/users/kito-cheng/followers", "following_url": "https://api.github.com/users/kito-cheng/following{/other_user}", "gists_url": "https://api.github.com/users/kito-cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/kito-cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kito-cheng/subscriptions", "organizations_url": "https://api.github.com/users/kito-cheng/orgs", "repos_url": "https://api.github.com/users/kito-cheng/repos", "events_url": "https://api.github.com/users/kito-cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/kito-cheng/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f8ba8a45edcff7fe117f88deff7184dffe3af311", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f8ba8a45edcff7fe117f88deff7184dffe3af311", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f8ba8a45edcff7fe117f88deff7184dffe3af311"}], "stats": {"total": 1688, "additions": 1647, "deletions": 41}, "files": [{"sha": "0e342b5d8324f641e76120615444101eea820402", "filename": "gcc/config/riscv/riscv-protos.h", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Friscv-protos.h?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -185,6 +185,18 @@ bool has_vi_variant_p (rtx_code, rtx);\n bool sew64_scalar_helper (rtx *, rtx *, rtx, machine_mode, machine_mode,\n \t\t\t  bool, void (*)(rtx *, rtx));\n rtx gen_scalar_move_mask (machine_mode);\n+\n+/* RVV vector register sizes.\n+   TODO: Currently, we only add RVV_32/RVV_64/RVV_128, we may need to\n+   support other values in the future.  */\n+enum vlen_enum\n+{\n+  RVV_32 = 32,\n+  RVV_64 = 64,\n+  RVV_65536 = 65536\n+};\n+bool slide1_sew64_helper (int, machine_mode, machine_mode,\n+\t\t\t  machine_mode, rtx *);\n }\n \n /* We classify builtin types into two classes:"}, {"sha": "d65c65b26cd7c96721b1e5e3db0291c312677600", "filename": "gcc/config/riscv/riscv-v.cc", "status": "modified", "additions": 171, "deletions": 0, "changes": 171, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-v.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-v.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Friscv-v.cc?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -495,4 +495,175 @@ gen_scalar_move_mask (machine_mode mode)\n   return builder.build ();\n }\n \n+static unsigned\n+compute_vlmax (unsigned vector_bits, unsigned elt_size, unsigned min_size)\n+{\n+  // Original equation:\n+  //   VLMAX = (VectorBits / EltSize) * LMUL\n+  //   where LMUL = MinSize / TARGET_MIN_VLEN\n+  // The following equations have been reordered to prevent loss of precision\n+  // when calculating fractional LMUL.\n+  return ((vector_bits / elt_size) * min_size) / TARGET_MIN_VLEN;\n+}\n+\n+static unsigned\n+get_unknown_min_value (machine_mode mode)\n+{\n+  enum vlmul_type vlmul = get_vlmul (mode);\n+  switch (vlmul)\n+    {\n+    case LMUL_1:\n+      return TARGET_MIN_VLEN;\n+    case LMUL_2:\n+      return TARGET_MIN_VLEN * 2;\n+    case LMUL_4:\n+      return TARGET_MIN_VLEN * 4;\n+    case LMUL_8:\n+      return TARGET_MIN_VLEN * 8;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+static rtx\n+force_vector_length_operand (rtx vl)\n+{\n+  if (CONST_INT_P (vl) && !satisfies_constraint_K (vl))\n+    return force_reg (Pmode, vl);\n+  return vl;\n+}\n+\n+static rtx\n+gen_no_side_effects_vsetvl_rtx (machine_mode vmode, rtx vl, rtx avl)\n+{\n+  unsigned int sew = GET_MODE_CLASS (vmode) == MODE_VECTOR_BOOL\n+\t\t       ? 8\n+\t\t       : GET_MODE_BITSIZE (GET_MODE_INNER (vmode));\n+  return gen_vsetvl_no_side_effects (Pmode, vl, avl, gen_int_mode (sew, Pmode),\n+\t\t\t\t     gen_int_mode (get_vlmul (vmode), Pmode),\n+\t\t\t\t     const0_rtx, const0_rtx);\n+}\n+\n+/* GET VL * 2 rtx.  */\n+static rtx\n+get_vl_x2_rtx (rtx avl, machine_mode mode, machine_mode demote_mode)\n+{\n+  rtx i32vl = NULL_RTX;\n+  if (CONST_INT_P (avl))\n+    {\n+      unsigned elt_size = GET_MODE_BITSIZE (GET_MODE_INNER (mode));\n+      unsigned min_size = get_unknown_min_value (mode);\n+      unsigned vlen_max = RVV_65536;\n+      unsigned vlmax_max = compute_vlmax (vlen_max, elt_size, min_size);\n+      unsigned vlen_min = TARGET_MIN_VLEN;\n+      unsigned vlmax_min = compute_vlmax (vlen_min, elt_size, min_size);\n+\n+      unsigned HOST_WIDE_INT avl_int = INTVAL (avl);\n+      if (avl_int <= vlmax_min)\n+\ti32vl = gen_int_mode (2 * avl_int, Pmode);\n+      else if (avl_int >= 2 * vlmax_max)\n+\t{\n+\t  // Just set i32vl to VLMAX in this situation\n+\t  i32vl = gen_reg_rtx (Pmode);\n+\t  emit_insn (\n+\t    gen_no_side_effects_vsetvl_rtx (demote_mode, i32vl, RVV_VLMAX));\n+\t}\n+      else\n+\t{\n+\t  // For AVL between (MinVLMAX, 2 * MaxVLMAX), the actual working vl\n+\t  // is related to the hardware implementation.\n+\t  // So let the following code handle\n+\t}\n+    }\n+  if (!i32vl)\n+    {\n+      // Using vsetvli instruction to get actually used length which related to\n+      // the hardware implementation\n+      rtx i64vl = gen_reg_rtx (Pmode);\n+      emit_insn (\n+\tgen_no_side_effects_vsetvl_rtx (mode, i64vl, force_reg (Pmode, avl)));\n+      // scale 2 for 32-bit length\n+      i32vl = gen_reg_rtx (Pmode);\n+      emit_insn (\n+\tgen_rtx_SET (i32vl, gen_rtx_ASHIFT (Pmode, i64vl, const1_rtx)));\n+    }\n+\n+  return force_vector_length_operand (i32vl);\n+}\n+\n+bool\n+slide1_sew64_helper (int unspec, machine_mode mode, machine_mode demote_mode,\n+\t\t     machine_mode demote_mask_mode, rtx *ops)\n+{\n+  rtx scalar_op = ops[4];\n+  rtx avl = ops[5];\n+  machine_mode scalar_mode = GET_MODE_INNER (mode);\n+  if (rtx_equal_p (scalar_op, const0_rtx))\n+    {\n+      ops[5] = force_vector_length_operand (ops[5]);\n+      return false;\n+    }\n+\n+  if (TARGET_64BIT)\n+    {\n+      ops[4] = force_reg (scalar_mode, scalar_op);\n+      ops[5] = force_vector_length_operand (ops[5]);\n+      return false;\n+    }\n+\n+  if (immediate_operand (scalar_op, Pmode))\n+    {\n+      ops[4] = gen_rtx_SIGN_EXTEND (scalar_mode, force_reg (Pmode, scalar_op));\n+      ops[5] = force_vector_length_operand (ops[5]);\n+      return false;\n+    }\n+\n+  if (CONST_INT_P (scalar_op))\n+    scalar_op = force_reg (scalar_mode, scalar_op);\n+\n+  rtx vl_x2 = get_vl_x2_rtx (avl, mode, demote_mode);\n+\n+  rtx demote_scalar_op1, demote_scalar_op2;\n+  if (unspec == UNSPEC_VSLIDE1UP)\n+    {\n+      demote_scalar_op1 = gen_highpart (Pmode, scalar_op);\n+      demote_scalar_op2 = gen_lowpart (Pmode, scalar_op);\n+    }\n+  else\n+    {\n+      demote_scalar_op1 = gen_lowpart (Pmode, scalar_op);\n+      demote_scalar_op2 = gen_highpart (Pmode, scalar_op);\n+    }\n+\n+  rtx temp = gen_reg_rtx (demote_mode);\n+  rtx ta = gen_int_mode (get_prefer_tail_policy (), Pmode);\n+  rtx ma = gen_int_mode (get_prefer_mask_policy (), Pmode);\n+  rtx merge = RVV_VUNDEF (demote_mode);\n+  /* Handle vslide1<ud>_tu.  */\n+  if (register_operand (ops[2], mode)\n+      && rtx_equal_p (ops[1], CONSTM1_RTX (GET_MODE (ops[1]))))\n+    {\n+      merge = gen_lowpart (demote_mode, ops[2]);\n+      ta = ops[6];\n+      ma = ops[7];\n+    }\n+\n+  emit_insn (gen_pred_slide (unspec, demote_mode, temp,\n+\t\t\t     CONSTM1_RTX (demote_mask_mode), merge,\n+\t\t\t     gen_lowpart (demote_mode, ops[3]),\n+\t\t\t     demote_scalar_op1, vl_x2, ta, ma, ops[8]));\n+  emit_insn (gen_pred_slide (unspec, demote_mode,\n+\t\t\t     gen_lowpart (demote_mode, ops[0]),\n+\t\t\t     CONSTM1_RTX (demote_mask_mode), merge, temp,\n+\t\t\t     demote_scalar_op2, vl_x2, ta, ma, ops[8]));\n+\n+  if (rtx_equal_p (ops[1], CONSTM1_RTX (GET_MODE (ops[1]))))\n+    return true;\n+  else\n+    emit_insn (gen_pred_merge (mode, ops[0], ops[2], ops[2], ops[0], ops[1],\n+\t\t\t       force_vector_length_operand (ops[5]), ops[6],\n+\t\t\t       ops[8]));\n+  return true;\n+}\n+\n } // namespace riscv_vector"}, {"sha": "1797c70e7b1c4b0d0fbaf1ef3f26fb00b3966fc9", "filename": "gcc/config/riscv/riscv-vector-builtins-bases.cc", "status": "modified", "additions": 73, "deletions": 0, "changes": 73, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-bases.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-bases.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-bases.cc?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -1367,6 +1367,61 @@ class vmv_s : public function_base\n   }\n };\n \n+template<int UNSPEC>\n+class slideop : public function_base\n+{\n+public:\n+  bool has_merge_operand_p () const override\n+  {\n+    if (UNSPEC == UNSPEC_VSLIDEUP)\n+      return false;\n+    return true;\n+  }\n+\n+  rtx expand (function_expander &e) const override\n+  {\n+    return e.use_exact_insn (code_for_pred_slide (UNSPEC, e.vector_mode ()));\n+  }\n+};\n+\n+class vrgather : public function_base\n+{\n+public:\n+  rtx expand (function_expander &e) const override\n+  {\n+    switch (e.op_info->op)\n+      {\n+      case OP_TYPE_vx:\n+\treturn e.use_exact_insn (\n+\t  code_for_pred_gather_scalar (e.vector_mode ()));\n+      case OP_TYPE_vv:\n+\treturn e.use_exact_insn (code_for_pred_gather (e.vector_mode ()));\n+      default:\n+\tgcc_unreachable ();\n+      }\n+  }\n+};\n+\n+class vrgatherei16 : public function_base\n+{\n+public:\n+  rtx expand (function_expander &e) const override\n+  {\n+    return e.use_exact_insn (code_for_pred_gatherei16 (e.vector_mode ()));\n+  }\n+};\n+\n+class vcompress : public function_base\n+{\n+public:\n+  bool apply_mask_policy_p () const override { return false; }\n+  bool use_mask_predication_p () const override { return false; }\n+  rtx expand (function_expander &e) const override\n+  {\n+    return e.use_exact_insn (code_for_pred_compress (e.vector_mode ()));\n+  }\n+};\n+\n static CONSTEXPR const vsetvl<false> vsetvl_obj;\n static CONSTEXPR const vsetvl<true> vsetvlmax_obj;\n static CONSTEXPR const loadstore<false, LST_UNIT_STRIDE, false> vle_obj;\n@@ -1560,6 +1615,15 @@ static CONSTEXPR const vmv vmv_x_obj;\n static CONSTEXPR const vmv_s vmv_s_obj;\n static CONSTEXPR const vmv vfmv_f_obj;\n static CONSTEXPR const vmv_s vfmv_s_obj;\n+static CONSTEXPR const slideop<UNSPEC_VSLIDEUP> vslideup_obj;\n+static CONSTEXPR const slideop<UNSPEC_VSLIDEDOWN> vslidedown_obj;\n+static CONSTEXPR const slideop<UNSPEC_VSLIDE1UP> vslide1up_obj;\n+static CONSTEXPR const slideop<UNSPEC_VSLIDE1DOWN> vslide1down_obj;\n+static CONSTEXPR const slideop<UNSPEC_VFSLIDE1UP> vfslide1up_obj;\n+static CONSTEXPR const slideop<UNSPEC_VFSLIDE1DOWN> vfslide1down_obj;\n+static CONSTEXPR const vrgather vrgather_obj;\n+static CONSTEXPR const vrgatherei16 vrgatherei16_obj;\n+static CONSTEXPR const vcompress vcompress_obj;\n \n /* Declare the function base NAME, pointing it to an instance\n    of class <NAME>_obj.  */\n@@ -1759,5 +1823,14 @@ BASE (vmv_x)\n BASE (vmv_s)\n BASE (vfmv_f)\n BASE (vfmv_s)\n+BASE (vslideup)\n+BASE (vslidedown)\n+BASE (vslide1up)\n+BASE (vslide1down)\n+BASE (vfslide1up)\n+BASE (vfslide1down)\n+BASE (vrgather)\n+BASE (vrgatherei16)\n+BASE (vcompress)\n \n } // end namespace riscv_vector"}, {"sha": "5078bcf9c72af28b59e2fd219d69bf9cbfd0efdb", "filename": "gcc/config/riscv/riscv-vector-builtins-bases.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-bases.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-bases.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-bases.h?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -223,6 +223,15 @@ extern const function_base *const vmv_x;\n extern const function_base *const vmv_s;\n extern const function_base *const vfmv_f;\n extern const function_base *const vfmv_s;\n+extern const function_base *const vslideup;\n+extern const function_base *const vslidedown;\n+extern const function_base *const vslide1up;\n+extern const function_base *const vslide1down;\n+extern const function_base *const vfslide1up;\n+extern const function_base *const vfslide1down;\n+extern const function_base *const vrgather;\n+extern const function_base *const vrgatherei16;\n+extern const function_base *const vcompress;\n }\n \n } // end namespace riscv_vector"}, {"sha": "638daa2459648d5e13018350aec682ca95e92336", "filename": "gcc/config/riscv/riscv-vector-builtins-functions.def", "status": "modified", "additions": 10, "deletions": 2, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-functions.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-functions.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-functions.def?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -475,11 +475,19 @@ DEF_RVV_FUNCTION (vfmv_f, scalar_move, none_preds, f_f_s_ops)\n DEF_RVV_FUNCTION (vfmv_s, move, none_tu_preds, f_s_f_ops)\n \n // 16.3. Vector Slide Instructions\n+DEF_RVV_FUNCTION (vslideup, alu, full_preds, all_vvvx_ops)\n+DEF_RVV_FUNCTION (vslidedown, alu, full_preds, all_vvx_ops)\n+DEF_RVV_FUNCTION (vslide1up, alu, full_preds, iu_vvx_ops)\n+DEF_RVV_FUNCTION (vslide1down, alu, full_preds, iu_vvx_ops)\n+DEF_RVV_FUNCTION (vfslide1up, alu, full_preds, f_vvf_ops)\n+DEF_RVV_FUNCTION (vfslide1down, alu, full_preds, f_vvf_ops)\n \n // 16.4. Vector Register Gather Instructions\n+DEF_RVV_FUNCTION (vrgather, alu, full_preds, all_gather_vvv_ops)\n+DEF_RVV_FUNCTION (vrgather, alu, full_preds, all_gather_vvx_ops)\n+DEF_RVV_FUNCTION (vrgatherei16, alu, full_preds, all_gatherei16_vvv_ops)\n \n // 16.5. Vector Compress Instruction\n-\n-// 16.6. Whole Vector Register Move\n+DEF_RVV_FUNCTION (vcompress, alu, none_tu_preds, all_vvm_ops)\n \n #undef DEF_RVV_FUNCTION"}, {"sha": "a77024f823fa8582e1579f9278852f1ab8a12ad5", "filename": "gcc/config/riscv/riscv-vector-builtins-types.def", "status": "modified", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-types.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-types.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins-types.def?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -151,6 +151,12 @@ along with GCC; see the file COPYING3. If not see\n #define DEF_RVV_WF_OPS(TYPE, REQUIRE)\n #endif\n \n+/* Use \"DEF_RVV_EI16_OPS\" macro include all types for vrgatherei16 which will be\n+   iterated and registered as intrinsic functions.  */\n+#ifndef DEF_RVV_EI16_OPS\n+#define DEF_RVV_EI16_OPS(TYPE, REQUIRE)\n+#endif\n+\n DEF_RVV_I_OPS (vint8mf8_t, RVV_REQUIRE_ZVE64)\n DEF_RVV_I_OPS (vint8mf4_t, 0)\n DEF_RVV_I_OPS (vint8mf2_t, 0)\n@@ -407,6 +413,58 @@ DEF_RVV_WF_OPS (vfloat32m2_t, RVV_REQUIRE_ELEN_FP_32)\n DEF_RVV_WF_OPS (vfloat32m4_t, RVV_REQUIRE_ELEN_FP_32)\n DEF_RVV_WF_OPS (vfloat32m8_t, RVV_REQUIRE_ELEN_FP_32)\n \n+DEF_RVV_EI16_OPS (vint8mf8_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vint8mf4_t, 0)\n+DEF_RVV_EI16_OPS (vint8mf2_t, 0)\n+DEF_RVV_EI16_OPS (vint8m1_t, 0)\n+DEF_RVV_EI16_OPS (vint8m2_t, 0)\n+DEF_RVV_EI16_OPS (vint8m4_t, 0)\n+DEF_RVV_EI16_OPS (vint16mf4_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vint16mf2_t, 0)\n+DEF_RVV_EI16_OPS (vint16m1_t, 0)\n+DEF_RVV_EI16_OPS (vint16m2_t, 0)\n+DEF_RVV_EI16_OPS (vint16m4_t, 0)\n+DEF_RVV_EI16_OPS (vint16m8_t, 0)\n+DEF_RVV_EI16_OPS (vint32mf2_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vint32m1_t, 0)\n+DEF_RVV_EI16_OPS (vint32m2_t, 0)\n+DEF_RVV_EI16_OPS (vint32m4_t, 0)\n+DEF_RVV_EI16_OPS (vint32m8_t, 0)\n+DEF_RVV_EI16_OPS (vint64m1_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vint64m2_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vint64m4_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vint64m8_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vuint8mf8_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vuint8mf4_t, 0)\n+DEF_RVV_EI16_OPS (vuint8mf2_t, 0)\n+DEF_RVV_EI16_OPS (vuint8m1_t, 0)\n+DEF_RVV_EI16_OPS (vuint8m2_t, 0)\n+DEF_RVV_EI16_OPS (vuint8m4_t, 0)\n+DEF_RVV_EI16_OPS (vuint16mf4_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vuint16mf2_t, 0)\n+DEF_RVV_EI16_OPS (vuint16m1_t, 0)\n+DEF_RVV_EI16_OPS (vuint16m2_t, 0)\n+DEF_RVV_EI16_OPS (vuint16m4_t, 0)\n+DEF_RVV_EI16_OPS (vuint16m8_t, 0)\n+DEF_RVV_EI16_OPS (vuint32mf2_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vuint32m1_t, 0)\n+DEF_RVV_EI16_OPS (vuint32m2_t, 0)\n+DEF_RVV_EI16_OPS (vuint32m4_t, 0)\n+DEF_RVV_EI16_OPS (vuint32m8_t, 0)\n+DEF_RVV_EI16_OPS (vuint64m1_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vuint64m2_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vuint64m4_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vuint64m8_t, RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vfloat32mf2_t, RVV_REQUIRE_ELEN_FP_32 | RVV_REQUIRE_ZVE64)\n+DEF_RVV_EI16_OPS (vfloat32m1_t, RVV_REQUIRE_ELEN_FP_32)\n+DEF_RVV_EI16_OPS (vfloat32m2_t, RVV_REQUIRE_ELEN_FP_32)\n+DEF_RVV_EI16_OPS (vfloat32m4_t, RVV_REQUIRE_ELEN_FP_32)\n+DEF_RVV_EI16_OPS (vfloat32m8_t, RVV_REQUIRE_ELEN_FP_32)\n+DEF_RVV_EI16_OPS (vfloat64m1_t, RVV_REQUIRE_ELEN_FP_64)\n+DEF_RVV_EI16_OPS (vfloat64m2_t, RVV_REQUIRE_ELEN_FP_64)\n+DEF_RVV_EI16_OPS (vfloat64m4_t, RVV_REQUIRE_ELEN_FP_64)\n+DEF_RVV_EI16_OPS (vfloat64m8_t, RVV_REQUIRE_ELEN_FP_64)\n+\n #undef DEF_RVV_I_OPS\n #undef DEF_RVV_U_OPS\n #undef DEF_RVV_F_OPS\n@@ -428,3 +486,4 @@ DEF_RVV_WF_OPS (vfloat32m8_t, RVV_REQUIRE_ELEN_FP_32)\n #undef DEF_RVV_WI_OPS\n #undef DEF_RVV_WU_OPS\n #undef DEF_RVV_WF_OPS\n+#undef DEF_RVV_EI16_OPS"}, {"sha": "6b32b28952a877e783064da1a6763642ca74c4e0", "filename": "gcc/config/riscv/riscv-vector-builtins.cc", "status": "modified", "additions": 82, "deletions": 6, "changes": 88, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Friscv-vector-builtins.cc?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -219,6 +219,12 @@ static const rvv_type_info all_ops[] = {\n #include \"riscv-vector-builtins-types.def\"\n   {NUM_VECTOR_TYPES, 0}};\n \n+/* A list of all types will be registered for intrinsic functions.  */\n+static const rvv_type_info ei16_ops[] = {\n+#define DEF_RVV_EI16_OPS(TYPE, REQUIRE) {VECTOR_TYPE_##TYPE, REQUIRE},\n+#include \"riscv-vector-builtins-types.def\"\n+  {NUM_VECTOR_TYPES, 0}};\n+\n /* A list of all bool will be registered for intrinsic functions.  */\n static const rvv_type_info b_ops[] = {\n #define DEF_RVV_B_OPS(TYPE, REQUIRE) {VECTOR_TYPE_##TYPE, REQUIRE},\n@@ -399,6 +405,12 @@ static CONSTEXPR const rvv_arg_type_info vvm_args[]\n   = {rvv_arg_type_info (RVV_BASE_vector), rvv_arg_type_info (RVV_BASE_vector),\n      rvv_arg_type_info (RVV_BASE_mask), rvv_arg_type_info_end};\n \n+/* A list of args for vector_type func (vector_type, mask_type)\n+ * function.  */\n+static CONSTEXPR const rvv_arg_type_info vm_args[]\n+  = {rvv_arg_type_info (RVV_BASE_vector), rvv_arg_type_info (RVV_BASE_mask),\n+     rvv_arg_type_info_end};\n+\n /* A list of args for vector_type func (vector_type, scalar_type, mask_type)\n  * function.  */\n static CONSTEXPR const rvv_arg_type_info vxm_args[]\n@@ -427,6 +439,16 @@ static CONSTEXPR const rvv_arg_type_info shift_vv_args[]\n   = {rvv_arg_type_info (RVV_BASE_vector),\n      rvv_arg_type_info (RVV_BASE_shift_vector), rvv_arg_type_info_end};\n \n+/* A list of args for vector_type func (vector_type, shift_type) function.  */\n+static CONSTEXPR const rvv_arg_type_info gather_vv_args[]\n+  = {rvv_arg_type_info (RVV_BASE_vector),\n+     rvv_arg_type_info (RVV_BASE_unsigned_vector), rvv_arg_type_info_end};\n+\n+/* A list of args for vector_type func (vector_type, shift_type) function.  */\n+static CONSTEXPR const rvv_arg_type_info gatherei16_vv_args[]\n+  = {rvv_arg_type_info (RVV_BASE_vector),\n+     rvv_arg_type_info (RVV_BASE_uint16_index), rvv_arg_type_info_end};\n+\n /* A list of args for double demote type func (vector_type, shift_type)\n  * function.  */\n static CONSTEXPR const rvv_arg_type_info shift_wv_args[]\n@@ -471,10 +493,16 @@ static CONSTEXPR const rvv_arg_type_info x_args[]\n   = {rvv_arg_type_info (RVV_BASE_scalar), rvv_arg_type_info_end};\n \n /* A list of args for vector_type func (vector_type, size) function.  */\n-static CONSTEXPR const rvv_arg_type_info vector_size_args[]\n+static CONSTEXPR const rvv_arg_type_info v_size_args[]\n   = {rvv_arg_type_info (RVV_BASE_vector), rvv_arg_type_info (RVV_BASE_size),\n      rvv_arg_type_info_end};\n \n+/* A list of args for vector_type func (vector_type, vector_type, size)\n+ * function.  */\n+static CONSTEXPR const rvv_arg_type_info vv_size_args[]\n+  = {rvv_arg_type_info (RVV_BASE_vector), rvv_arg_type_info (RVV_BASE_vector),\n+     rvv_arg_type_info (RVV_BASE_size), rvv_arg_type_info_end};\n+\n /* A list of args for vector_type func (double demote type) function.  */\n static CONSTEXPR const rvv_arg_type_info vf2_args[]\n   = {rvv_arg_type_info (RVV_BASE_double_trunc_vector), rvv_arg_type_info_end};\n@@ -848,6 +876,14 @@ static CONSTEXPR const rvv_op_info all_vvvm_ops\n      rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n      vvm_args /* Args */};\n \n+/* A static operand information for vector_type func (vector_type, vector_type,\n+ * mask_type) function registration. */\n+static CONSTEXPR const rvv_op_info all_vvm_ops\n+  = {all_ops,\t\t\t\t  /* Types */\n+     OP_TYPE_vm,\t\t\t  /* Suffix */\n+     rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n+     vm_args /* Args */};\n+\n /* A static operand information for vector_type func (vector_type, scalar_type,\n  * mask_type) function registration. */\n static CONSTEXPR const rvv_op_info iu_vvxm_ops\n@@ -1008,6 +1044,22 @@ static CONSTEXPR const rvv_op_info iu_vvx_ops\n      rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n      vx_args /* Args */};\n \n+/* A static operand information for vector_type func (vector_type, scalar_type)\n+ * function registration. */\n+static CONSTEXPR const rvv_op_info all_vvx_ops\n+  = {all_ops,\t\t\t\t  /* Types */\n+     OP_TYPE_vx,\t\t\t  /* Suffix */\n+     rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n+     v_size_args /* Args */};\n+\n+/* A static operand information for vector_type func (vector_type, vector_type,\n+ * scalar_type) function registration. */\n+static CONSTEXPR const rvv_op_info all_vvvx_ops\n+  = {all_ops,\t\t\t\t  /* Types */\n+     OP_TYPE_vx,\t\t\t  /* Suffix */\n+     rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n+     vv_size_args /* Args */};\n+\n /* A static operand information for vector_type func (vector_type, scalar_type)\n  * function registration. */\n static CONSTEXPR const rvv_op_info i_vvx_ops\n@@ -1063,7 +1115,7 @@ static CONSTEXPR const rvv_op_info iu_shift_vvx_ops\n   = {iu_ops,\t\t\t\t  /* Types */\n      OP_TYPE_vx,\t\t\t  /* Suffix */\n      rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n-     vector_size_args /* Args */};\n+     v_size_args /* Args */};\n \n /* A static operand information for vector_type func (vector_type, shift_type)\n  * function registration. */\n@@ -1079,7 +1131,7 @@ static CONSTEXPR const rvv_op_info i_shift_vvx_ops\n   = {i_ops,\t\t\t\t  /* Types */\n      OP_TYPE_vx,\t\t\t  /* Suffix */\n      rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n-     vector_size_args /* Args */};\n+     v_size_args /* Args */};\n \n /* A static operand information for vector_type func (vector_type, shift_type)\n  * function registration. */\n@@ -1095,7 +1147,31 @@ static CONSTEXPR const rvv_op_info u_shift_vvx_ops\n   = {u_ops,\t\t\t\t  /* Types */\n      OP_TYPE_vx,\t\t\t  /* Suffix */\n      rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n-     vector_size_args /* Args */};\n+     v_size_args /* Args */};\n+\n+/* A static operand information for vector_type func (vector_type, index_type)\n+ * function registration. */\n+static CONSTEXPR const rvv_op_info all_gather_vvv_ops\n+  = {all_ops,\t\t\t\t  /* Types */\n+     OP_TYPE_vv,\t\t\t  /* Suffix */\n+     rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n+     gather_vv_args /* Args */};\n+\n+/* A static operand information for vector_type func (vector_type, size_t)\n+ * function registration. */\n+static CONSTEXPR const rvv_op_info all_gather_vvx_ops\n+  = {all_ops,\t\t\t\t  /* Types */\n+     OP_TYPE_vx,\t\t\t  /* Suffix */\n+     rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n+     v_size_args /* Args */};\n+\n+/* A static operand information for vector_type func (vector_type, index_type)\n+ * function registration. */\n+static CONSTEXPR const rvv_op_info all_gatherei16_vvv_ops\n+  = {ei16_ops,\t\t\t\t  /* Types */\n+     OP_TYPE_vv,\t\t\t  /* Suffix */\n+     rvv_arg_type_info (RVV_BASE_vector), /* Return type */\n+     gatherei16_vv_args /* Args */};\n \n /* A static operand information for vector_type func (vector_type)\n  * function registration. */\n@@ -1600,15 +1676,15 @@ static CONSTEXPR const rvv_op_info i_narrow_shift_vwx_ops\n   = {wexti_ops,\t\t\t\t\t       /* Types */\n      OP_TYPE_wx,\t\t\t\t       /* Suffix */\n      rvv_arg_type_info (RVV_BASE_double_trunc_vector), /* Return type */\n-     vector_size_args /* Args */};\n+     v_size_args /* Args */};\n \n /* A static operand information for double demote type func (vector_type,\n  * size_t) function registration. */\n static CONSTEXPR const rvv_op_info u_narrow_shift_vwx_ops\n   = {wextu_ops,\t\t\t\t\t       /* Types */\n      OP_TYPE_wx,\t\t\t\t       /* Suffix */\n      rvv_arg_type_info (RVV_BASE_double_trunc_vector), /* Return type */\n-     vector_size_args /* Args */};\n+     v_size_args /* Args */};\n \n /* A static operand information for double demote type func (vector_type)\n  * function registration. */"}, {"sha": "20697b88e1c333fa756cbbc019e62a48d3c5748e", "filename": "gcc/config/riscv/riscv.md", "status": "modified", "additions": 16, "deletions": 12, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Friscv.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Friscv.md?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -311,7 +311,7 @@\n ;; viwred      vector widening integer reduction instructions\n ;; vfredu      vector single-width floating-point un-ordered reduction instruction\n ;; vfredo      vector single-width floating-point ordered reduction instruction\n-;; vfwredu      vector widening floating-point un-ordered reduction instruction\n+;; vfwredu     vector widening floating-point un-ordered reduction instruction\n ;; vfwredo     vector widening floating-point ordered reduction instruction\n ;; 15. Vector mask instructions\n ;; vmalu       vector mask-register logical instructions\n@@ -321,16 +321,19 @@\n ;; vmiota      vector iota\n ;; vmidx       vector element index instruction\n ;; 16. Vector permutation instructions\n-;; vimovvx     integer scalar move instructions\n-;; vimovxv     integer scalar move instructions\n-;; vfmovvf     floating-point scalar move instructions\n-;; vfmovfv     floating-point scalar move instructions\n-;; vislide     vector slide instructions\n-;; vislide1    vector slide instructions\n-;; vfslide1    vector slide instructions\n-;; vgather     vector register gather instructions\n-;; vcompress   vector compress instruction\n-;; vmov        whole vector register move\n+;; vimovvx      integer scalar move instructions\n+;; vimovxv      integer scalar move instructions\n+;; vfmovvf      floating-point scalar move instructions\n+;; vfmovfv      floating-point scalar move instructions\n+;; vslideup     vector slide instructions\n+;; vslidedown   vector slide instructions\n+;; vislide1up   vector slide instructions\n+;; vislide1down vector slide instructions\n+;; vfslide1up   vector slide instructions\n+;; vfslide1down vector slide instructions\n+;; vgather      vector register gather instructions\n+;; vcompress    vector compress instruction\n+;; vmov         whole vector register move\n (define_attr \"type\"\n   \"unknown,branch,jump,call,load,fpload,store,fpstore,\n    mtc,mfc,const,arith,logical,shift,slt,imul,idiv,move,fmove,fadd,fmul,\n@@ -346,7 +349,8 @@\n    vfwcvtftof,vfncvtitof,vfncvtftoi,vfncvtftof,\n    vired,viwred,vfredu,vfredo,vfwredu,vfwredo,\n    vmalu,vmpop,vmffs,vmsfs,vmiota,vmidx,vimovvx,vimovxv,vfmovvf,vfmovfv,\n-   vislide,vislide1,vfslide1,vgather,vcompress,vmov\"\n+   vslideup,vslidedown,vislide1up,vislide1down,vfslide1up,vfslide1down,\n+   vgather,vcompress,vmov\"\n   (cond [(eq_attr \"got\" \"load\") (const_string \"load\")\n \n \t ;; If a doubleword move uses these expensive instructions,"}, {"sha": "0eebe53f121d485673dcae7f1bed91bddf14ab3c", "filename": "gcc/config/riscv/vector-iterators.md", "status": "modified", "additions": 77, "deletions": 0, "changes": 77, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Fvector-iterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Fvector-iterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Fvector-iterators.md?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -70,6 +70,15 @@\n   UNSPEC_REDUC\n   UNSPEC_WREDUC_SUM\n   UNSPEC_WREDUC_USUM\n+  UNSPEC_VSLIDEUP\n+  UNSPEC_VSLIDEDOWN\n+  UNSPEC_VSLIDE1UP\n+  UNSPEC_VSLIDE1DOWN\n+  UNSPEC_VFSLIDE1UP\n+  UNSPEC_VFSLIDE1DOWN\n+  UNSPEC_VRGATHER\n+  UNSPEC_VRGATHEREI16\n+  UNSPEC_VCOMPRESS\n ])\n \n (define_mode_iterator V [\n@@ -89,6 +98,23 @@\n   (VNx8DF \"TARGET_VECTOR_ELEN_FP_64\")\n ])\n \n+(define_mode_iterator VEI16 [\n+  VNx1QI VNx2QI VNx4QI VNx8QI VNx16QI VNx32QI\n+  VNx1HI VNx2HI VNx4HI VNx8HI VNx16HI (VNx32HI \"TARGET_MIN_VLEN > 32\")\n+  VNx1SI VNx2SI VNx4SI VNx8SI (VNx16SI \"TARGET_MIN_VLEN > 32\")\n+  (VNx1DI \"TARGET_MIN_VLEN > 32\") (VNx2DI \"TARGET_MIN_VLEN > 32\")\n+  (VNx4DI \"TARGET_MIN_VLEN > 32\") (VNx8DI \"TARGET_MIN_VLEN > 32\")\n+  (VNx1SF \"TARGET_VECTOR_ELEN_FP_32\")\n+  (VNx2SF \"TARGET_VECTOR_ELEN_FP_32\")\n+  (VNx4SF \"TARGET_VECTOR_ELEN_FP_32\")\n+  (VNx8SF \"TARGET_VECTOR_ELEN_FP_32\")\n+  (VNx16SF \"TARGET_VECTOR_ELEN_FP_32 && TARGET_MIN_VLEN > 32\")\n+  (VNx1DF \"TARGET_VECTOR_ELEN_FP_64\")\n+  (VNx2DF \"TARGET_VECTOR_ELEN_FP_64\")\n+  (VNx4DF \"TARGET_VECTOR_ELEN_FP_64\")\n+  (VNx8DF \"TARGET_VECTOR_ELEN_FP_64\")\n+])\n+\n (define_mode_iterator VI [\n   VNx1QI VNx2QI VNx4QI VNx8QI VNx16QI VNx32QI (VNx64QI \"TARGET_MIN_VLEN > 32\")\n   VNx1HI VNx2HI VNx4HI VNx8HI VNx16HI (VNx32HI \"TARGET_MIN_VLEN > 32\")\n@@ -291,6 +317,32 @@\n   (VNx4DI \"TARGET_MIN_VLEN > 32\") (VNx8DI \"TARGET_MIN_VLEN > 32\")\n ])\n \n+(define_mode_attr VINDEX [\n+  (VNx1QI \"VNx1QI\") (VNx2QI \"VNx2QI\") (VNx4QI \"VNx4QI\") (VNx8QI \"VNx8QI\")\n+  (VNx16QI \"VNx16QI\") (VNx32QI \"VNx32QI\") (VNx64QI \"VNx64QI\")\n+  (VNx1HI \"VNx1HI\") (VNx2HI \"VNx2HI\") (VNx4HI \"VNx4HI\") (VNx8HI \"VNx8HI\")\n+  (VNx16HI \"VNx16HI\") (VNx32HI \"VNx32HI\")\n+  (VNx1SI \"VNx1SI\") (VNx2SI \"VNx2SI\") (VNx4SI \"VNx4SI\") (VNx8SI \"VNx8SI\")\n+  (VNx16SI \"VNx16SI\")\n+  (VNx1DI \"VNx1DI\") (VNx2DI \"VNx2DI\") (VNx4DI \"VNx4DI\") (VNx8DI \"VNx8DI\")\n+  (VNx1SF \"VNx1SI\") (VNx2SF \"VNx2SI\") (VNx4SF \"VNx4SI\") (VNx8SF \"VNx8SI\")\n+  (VNx16SF \"VNx16SI\")\n+  (VNx1DF \"VNx1DI\") (VNx2DF \"VNx2DI\") (VNx4DF \"VNx4DI\") (VNx8DF \"VNx8DI\")\n+])\n+\n+(define_mode_attr VINDEXEI16 [\n+  (VNx1QI \"VNx1HI\") (VNx2QI \"VNx2HI\") (VNx4QI \"VNx4HI\") (VNx8QI \"VNx8HI\")\n+  (VNx16QI \"VNx16HI\") (VNx32QI \"VNx32HI\")\n+  (VNx1HI \"VNx1HI\") (VNx2HI \"VNx2HI\") (VNx4HI \"VNx4HI\") (VNx8HI \"VNx8HI\")\n+  (VNx16HI \"VNx16HI\") (VNx32HI \"VNx32HI\")\n+  (VNx1SI \"VNx1HI\") (VNx2SI \"VNx2HI\") (VNx4SI \"VNx4HI\") (VNx8SI \"VNx8HI\")\n+  (VNx16SI \"VNx16HI\")\n+  (VNx1DI \"VNx1HI\") (VNx2DI \"VNx2HI\") (VNx4DI \"VNx4HI\") (VNx8DI \"VNx8HI\")\n+  (VNx1SF \"VNx1HI\") (VNx2SF \"VNx2HI\") (VNx4SF \"VNx4HI\") (VNx8SF \"VNx8HI\")\n+  (VNx16SF \"VNx16HI\")\n+  (VNx1DF \"VNx1HI\") (VNx2DF \"VNx2HI\") (VNx4DF \"VNx4HI\") (VNx8DF \"VNx8HI\")\n+])\n+\n (define_mode_attr VM [\n   (VNx1QI \"VNx1BI\") (VNx2QI \"VNx2BI\") (VNx4QI \"VNx4BI\") (VNx8QI \"VNx8BI\") (VNx16QI \"VNx16BI\") (VNx32QI \"VNx32BI\") (VNx64QI \"VNx64BI\")\n   (VNx1HI \"VNx1BI\") (VNx2HI \"VNx2BI\") (VNx4HI \"VNx4BI\") (VNx8HI \"VNx8BI\") (VNx16HI \"VNx16BI\") (VNx32HI \"VNx32BI\")\n@@ -454,6 +506,16 @@\n   (VNx8HI \"vnx1si\") (VNx16HI \"vnx1SI\")\n ])\n \n+(define_mode_attr VDEMOTE [\n+  (VNx1DI \"VNx2SI\") (VNx2DI \"VNx4SI\")\n+  (VNx4DI \"VNx8SI\") (VNx8DI \"VNx16SI\")\n+])\n+\n+(define_mode_attr VMDEMOTE [\n+  (VNx1DI \"VNx2BI\") (VNx2DI \"VNx4BI\")\n+  (VNx4DI \"VNx8BI\") (VNx8DI \"VNx16BI\")\n+])\n+\n (define_int_iterator WREDUC [UNSPEC_WREDUC_SUM UNSPEC_WREDUC_USUM])\n \n (define_int_iterator ORDER [UNSPEC_ORDERED UNSPEC_UNORDERED])\n@@ -462,6 +524,10 @@\n \n (define_int_iterator VNCLIP [UNSPEC_VNCLIP UNSPEC_VNCLIPU])\n \n+(define_int_iterator VSLIDES [UNSPEC_VSLIDEUP UNSPEC_VSLIDEDOWN])\n+(define_int_iterator VSLIDES1 [UNSPEC_VSLIDE1UP UNSPEC_VSLIDE1DOWN])\n+(define_int_iterator VFSLIDES1 [UNSPEC_VFSLIDE1UP UNSPEC_VFSLIDE1DOWN])\n+\n (define_int_iterator VSAT_OP [UNSPEC_VAADDU UNSPEC_VAADD\n \t\t\t      UNSPEC_VASUBU UNSPEC_VASUB UNSPEC_VSMUL\n \t\t\t      UNSPEC_VSSRL UNSPEC_VSSRA])\n@@ -508,6 +574,17 @@\n (define_int_attr nx [(UNSPEC_VCOPYSIGN \"\") (UNSPEC_VNCOPYSIGN \"n\")\n \t\t     (UNSPEC_VXORSIGN \"x\")])\n \n+(define_int_attr ud [(UNSPEC_VSLIDEUP \"up\") (UNSPEC_VSLIDEDOWN \"down\")\n+\t\t     (UNSPEC_VSLIDE1UP \"1up\") (UNSPEC_VSLIDE1DOWN \"1down\")\n+\t\t     (UNSPEC_VFSLIDE1UP \"1up\") (UNSPEC_VFSLIDE1DOWN \"1down\")])\n+\n+(define_int_attr ud_constraint [(UNSPEC_VSLIDEUP \"=&vr,&vr\") (UNSPEC_VSLIDEDOWN \"=vd,vr\")\n+\t\t\t\t(UNSPEC_VSLIDE1UP \"=&vr,&vr\") (UNSPEC_VSLIDE1DOWN \"=vd,vr\")\n+\t\t\t\t(UNSPEC_VFSLIDE1UP \"=&vr,&vr\") (UNSPEC_VFSLIDE1DOWN \"=vd,vr\")])\n+\n+(define_int_attr UNSPEC [(UNSPEC_VSLIDE1UP \"UNSPEC_VSLIDE1UP\")\n+\t\t\t (UNSPEC_VSLIDE1DOWN \"UNSPEC_VSLIDE1DOWN\")])\n+\n (define_code_iterator any_int_binop [plus minus and ior xor ashift ashiftrt lshiftrt\n   smax umax smin umin mult div udiv mod umod\n ])"}, {"sha": "62e1abbb2daca9606d8630a8a6fcef55ae4df5f6", "filename": "gcc/config/riscv/vector.md", "status": "modified", "additions": 234, "deletions": 21, "changes": 255, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Fvector.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Fconfig%2Friscv%2Fvector.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Friscv%2Fvector.md?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -50,7 +50,8 @@\n \t\t\t  vfwcvtftof,vfncvtitof,vfncvtftoi,vfncvtftof,\\\n \t\t\t  vired,viwred,vfredu,vfredo,vfwredu,vfwredo,\\\n \t\t\t  vmalu,vmpop,vmffs,vmsfs,vmiota,vmidx,vimovvx,vimovxv,vfmovvf,vfmovfv,\\\n-\t\t\t  vislide,vislide1,vfslide1,vgather,vcompress\")\n+\t\t\t  vslideup,vslidedown,vislide1up,vislide1down,vfslide1up,vfslide1down,\\\n+\t\t\t  vgather,vcompress\")\n \t (const_string \"true\")]\n \t(const_string \"false\")))\n \n@@ -70,7 +71,8 @@\n \t\t\t  vfwcvtftof,vfncvtitof,vfncvtftoi,vfncvtftof,\\\n \t\t\t  vired,viwred,vfredu,vfredo,vfwredu,vfwredo,\\\n \t\t\t  vmalu,vmpop,vmffs,vmsfs,vmiota,vmidx,vimovxv,vfmovfv,\\\n-\t\t\t  vislide,vislide1,vfslide1,vgather,vcompress\")\n+\t\t\t  vslideup,vslidedown,vislide1up,vislide1down,vfslide1up,vfslide1down,\\\n+\t\t\t  vgather,vcompress\")\n \t (const_string \"true\")]\n \t(const_string \"false\")))\n \n@@ -153,7 +155,9 @@\n \t\t\t  vfwcvtftoi,vfwcvtftof,vfncvtitof,vfncvtftoi,\\\n \t\t\t  vfncvtftof,vfmuladd,vfwmuladd,vfclass,vired,\\\n \t\t\t  viwred,vfredu,vfredo,vfwredu,vfwredo,vimovvx,\\\n-\t\t\t  vimovxv,vfmovvf,vfmovfv\")\n+\t\t\t  vimovxv,vfmovvf,vfmovfv,vslideup,vslidedown,\\\n+\t\t\t  vislide1up,vislide1down,vfslide1up,vfslide1down,\\\n+\t\t\t  vgather,vcompress\")\n \t   (const_int INVALID_ATTRIBUTE)\n \t (eq_attr \"mode\" \"VNx1QI,VNx1BI\")\n \t   (symbol_ref \"riscv_vector::get_ratio(E_VNx1QImode)\")\n@@ -209,10 +213,12 @@\n \t\t\t\tvmiota,vmidx,vfalu,vfmul,vfminmax,vfdiv,vfwalu,vfwmul,\\\n \t\t\t\tvfsqrt,vfrecp,vfsgnj,vfcmp,vfcvtitof,vfcvtftoi,vfwcvtitof,\\\n \t\t\t\tvfwcvtftoi,vfwcvtftof,vfncvtitof,vfncvtftoi,vfncvtftof,vfclass,\\\n-\t\t\t\tvired,viwred,vfredu,vfredo,vfwredu,vfwredo,vimovxv,vfmovfv\")\n+\t\t\t\tvired,viwred,vfredu,vfredo,vfwredu,vfwredo,vimovxv,vfmovfv,\\\n+\t\t\t\tvslideup,vslidedown,vislide1up,vislide1down,vfslide1up,vfslide1down,\\\n+\t\t\t\tvgather\")\n \t       (const_int 2)\n \n-\t       (eq_attr \"type\" \"vimerge,vfmerge\")\n+\t       (eq_attr \"type\" \"vimerge,vfmerge,vcompress\")\n \t       (const_int 1)\n \n \t       (eq_attr \"type\" \"vimuladd,viwmuladd,vfmuladd,vfwmuladd\")\n@@ -224,7 +230,7 @@\n   (cond [(eq_attr \"type\" \"vlde,vste,vimov,vfmov,vldm,vstm,vmalu,vsts,vstux,\\\n \t\t\t  vstox,vext,vmsfs,vmiota,vfsqrt,vfrecp,vfcvtitof,\\\n \t\t\t  vfcvtftoi,vfwcvtitof,vfwcvtftoi,vfwcvtftof,vfncvtitof,\\\n-\t\t\t  vfncvtftoi,vfncvtftof,vfclass,vimovxv,vfmovfv\")\n+\t\t\t  vfncvtftoi,vfncvtftof,vfclass,vimovxv,vfmovfv,vcompress\")\n \t   (const_int 4)\n \n \t ;; If operands[3] of \"vlds\" is not vector mode, it is pred_broadcast.\n@@ -237,7 +243,9 @@\n \t (eq_attr \"type\" \"vldux,vldox,vialu,vshift,viminmax,vimul,vidiv,vsalu,\\\n \t\t\t  viwalu,viwmul,vnshift,vimerge,vaalu,vsmul,\\\n \t\t\t  vsshift,vnclip,vfalu,vfmul,vfminmax,vfdiv,vfwalu,vfwmul,\\\n-\t\t\t  vfsgnj,vfmerge,vired,viwred,vfredu,vfredo,vfwredu,vfwredo\")\n+\t\t\t  vfsgnj,vfmerge,vired,viwred,vfredu,vfredo,vfwredu,vfwredo,\\\n+\t\t\t  vslideup,vslidedown,vislide1up,vislide1down,vfslide1up,vfslide1down,\\\n+\t\t\t  vgather\")\n \t   (const_int 5)\n \n \t (eq_attr \"type\" \"vicmp,vimuladd,viwmuladd,vfcmp,vfmuladd,vfwmuladd\")\n@@ -251,7 +259,8 @@\n (define_attr \"ta\" \"\"\n   (cond [(eq_attr \"type\" \"vlde,vimov,vfmov,vext,vmiota,vfsqrt,vfrecp,\\\n \t\t\t  vfcvtitof,vfcvtftoi,vfwcvtitof,vfwcvtftoi,vfwcvtftof,\\\n-\t\t\t  vfncvtitof,vfncvtftoi,vfncvtftof,vfclass,vimovxv,vfmovfv\")\n+\t\t\t  vfncvtitof,vfncvtftoi,vfncvtftof,vfclass,vimovxv,vfmovfv,\\\n+\t\t\t  vcompress\")\n \t   (symbol_ref \"riscv_vector::get_ta(operands[5])\")\n \n \t ;; If operands[3] of \"vlds\" is not vector mode, it is pred_broadcast.\n@@ -265,7 +274,8 @@\n \t\t\t  viwalu,viwmul,vnshift,vimerge,vaalu,vsmul,\\\n \t\t\t  vsshift,vnclip,vfalu,vfmul,vfminmax,vfdiv,\\\n \t\t\t  vfwalu,vfwmul,vfsgnj,vfmerge,vired,viwred,vfredu,\\\n-\t\t\t  vfredo,vfwredu,vfwredo\")\n+\t\t\t  vfredo,vfwredu,vfwredo,vslideup,vslidedown,vislide1up,\\\n+\t\t\t  vislide1down,vfslide1up,vfslide1down,vgather\")\n \t   (symbol_ref \"riscv_vector::get_ta(operands[6])\")\n \n \t (eq_attr \"type\" \"vimuladd,viwmuladd,vfmuladd,vfwmuladd\")\n@@ -292,7 +302,8 @@\n \t (eq_attr \"type\" \"vldux,vldox,vialu,vshift,viminmax,vimul,vidiv,vsalu,\\\n \t\t\t  viwalu,viwmul,vnshift,vaalu,vsmul,vsshift,\\\n \t\t\t  vnclip,vicmp,vfalu,vfmul,vfminmax,vfdiv,\\\n-\t\t\t  vfwalu,vfwmul,vfsgnj,vfcmp\")\n+\t\t\t  vfwalu,vfwmul,vfsgnj,vfcmp,vslideup,vslidedown,\\\n+\t\t\t  vislide1up,vislide1down,vfslide1up,vfslide1down,vgather\")\n \t   (symbol_ref \"riscv_vector::get_ma(operands[7])\")\n \n \t (eq_attr \"type\" \"vimuladd,viwmuladd,vfmuladd,vfwmuladd\")\n@@ -323,15 +334,16 @@\n \t (eq_attr \"type\" \"vldux,vldox,vialu,vshift,viminmax,vimul,vidiv,vsalu,\\\n \t\t\t  viwalu,viwmul,vnshift,vimuladd,vaalu,vsmul,vsshift,\\\n \t\t\t  vnclip,vicmp,vfalu,vfmul,vfminmax,vfdiv,vfwalu,vfwmul,\\\n-\t\t\t  vfsgnj,vfcmp,vfmuladd\")\n+\t\t\t  vfsgnj,vfcmp,vfmuladd,vslideup,vslidedown,vislide1up,\\\n+\t\t\t  vislide1down,vfslide1up,vfslide1down,vgather\")\n \t   (symbol_ref \"INTVAL (operands[8])\")\n \t (eq_attr \"type\" \"vstux,vstox\")\n \t   (symbol_ref \"INTVAL (operands[5])\")\n \n \t (eq_attr \"type\" \"vimuladd,viwmuladd,vfwmuladd\")\n \t   (symbol_ref \"INTVAL (operands[9])\")\n \n-\t (eq_attr \"type\" \"vmsfs,vmidx\")\n+\t (eq_attr \"type\" \"vmsfs,vmidx,vcompress\")\n \t   (symbol_ref \"INTVAL (operands[6])\")\n \n \t (eq_attr \"type\" \"vmpop,vmffs\")\n@@ -4838,7 +4850,7 @@\n \t     (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n \t  (commutative_float_binop:VF\n \t    (vec_duplicate:VF\n-\t      (match_operand:<VEL> 4 \"register_operand\"  \"  r,  r\"))\n+\t      (match_operand:<VEL> 4 \"register_operand\"  \"  f,  f\"))\n \t    (match_operand:VF 3 \"register_operand\"       \" vr, vr\"))\n \t  (match_operand:VF 2 \"vector_merge_operand\"     \"0vu,0vu\")))]\n   \"TARGET_VECTOR\"\n@@ -4860,7 +4872,7 @@\n \t  (non_commutative_float_binop:VF\n \t    (match_operand:VF 3 \"register_operand\"       \" vr, vr\")\n \t    (vec_duplicate:VF\n-\t      (match_operand:<VEL> 4 \"register_operand\"  \"  r,  r\")))\n+\t      (match_operand:<VEL> 4 \"register_operand\"  \"  f,  f\")))\n \t  (match_operand:VF 2 \"vector_merge_operand\"     \"0vu,0vu\")))]\n   \"TARGET_VECTOR\"\n   \"vf<insn>.vf\\t%0,%3,%4%p1\"\n@@ -4880,7 +4892,7 @@\n \t     (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n \t  (non_commutative_float_binop:VF\n \t    (vec_duplicate:VF\n-\t      (match_operand:<VEL> 4 \"register_operand\"  \"  r,  r\"))\n+\t      (match_operand:<VEL> 4 \"register_operand\"  \"  f,  f\"))\n \t    (match_operand:VF 3 \"register_operand\"       \" vr, vr\"))\n \t  (match_operand:VF 2 \"vector_merge_operand\"     \"0vu,0vu\")))]\n   \"TARGET_VECTOR\"\n@@ -5748,7 +5760,7 @@\n \t    (mult:VWEXTF\n \t      (float_extend:VWEXTF\n \t        (vec_duplicate:<V_DOUBLE_TRUNC>\n-\t          (match_operand:<VSUBEL> 3 \"register_operand\"       \"    r\")))\n+\t          (match_operand:<VSUBEL> 3 \"register_operand\"       \"    f\")))\n \t      (float_extend:VWEXTF\n \t        (match_operand:<V_DOUBLE_TRUNC> 4 \"register_operand\" \"   vr\"))))\n \t  (match_operand:VWEXTF 5 \"vector_merge_operand\"             \"  0vu\")))]\n@@ -5799,7 +5811,7 @@\n \t      (mult:VWEXTF\n \t        (float_extend:VWEXTF\n \t          (vec_duplicate:<V_DOUBLE_TRUNC>\n-\t            (match_operand:<VSUBEL> 3 \"register_operand\"       \"    r\")))\n+\t            (match_operand:<VSUBEL> 3 \"register_operand\"       \"    f\")))\n \t        (float_extend:VWEXTF\n \t          (match_operand:<V_DOUBLE_TRUNC> 4 \"register_operand\" \"   vr\")))))\n \t  (match_operand:VWEXTF 5 \"vector_merge_operand\"               \"  0vu\")))]\n@@ -5904,7 +5916,7 @@\n \t  (match_operator:<VM> 3 \"signed_order_operator\"\n \t     [(match_operand:VF 4 \"register_operand\"          \"   vr\")\n \t      (vec_duplicate:VF\n-\t        (match_operand:<VEL> 5 \"register_operand\"     \"    r\"))])\n+\t        (match_operand:<VEL> 5 \"register_operand\"     \"    f\"))])\n \t  (match_operand:<VM> 2 \"vector_merge_operand\"        \"  0vu\")))]\n   \"TARGET_VECTOR && known_le (GET_MODE_SIZE (<MODE>mode), BYTES_PER_RISCV_VECTOR)\"\n   \"vmf%B3.vf\\t%0,%4,%5%p1\"\n@@ -5925,7 +5937,7 @@\n \t  (match_operator:<VM> 3 \"signed_order_operator\"\n \t     [(match_operand:VF 4 \"register_operand\"          \"   vr\")\n \t      (vec_duplicate:VF\n-\t        (match_operand:<VEL> 5 \"register_operand\"     \"    r\"))])\n+\t        (match_operand:<VEL> 5 \"register_operand\"     \"    f\"))])\n \t  (match_operand:<VM> 2 \"vector_merge_operand\"        \"  0vu\")))]\n   \"TARGET_VECTOR && known_gt (GET_MODE_SIZE (<MODE>mode), BYTES_PER_RISCV_VECTOR)\"\n   \"vmf%B3.vf\\t%0,%4,%5%p1\"\n@@ -5963,7 +5975,7 @@\n \t     (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n \t  (match_operator:<VM> 3 \"equality_operator\"\n \t     [(vec_duplicate:VF\n-\t        (match_operand:<VEL> 5 \"register_operand\"     \"    r\"))\n+\t        (match_operand:<VEL> 5 \"register_operand\"     \"    f\"))\n \t      (match_operand:VF 4 \"register_operand\"          \"   vr\")])\n \t  (match_operand:<VM> 2 \"vector_merge_operand\"        \"  0vu\")))]\n   \"TARGET_VECTOR && known_le (GET_MODE_SIZE (<MODE>mode), BYTES_PER_RISCV_VECTOR)\"\n@@ -5984,7 +5996,7 @@\n \t     (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n \t  (match_operator:<VM> 3 \"equality_operator\"\n \t     [(vec_duplicate:VF\n-\t        (match_operand:<VEL> 5 \"register_operand\"     \"    r\"))\n+\t        (match_operand:<VEL> 5 \"register_operand\"     \"    f\"))\n \t      (match_operand:VF 4 \"register_operand\"          \"   vr\")])\n \t  (match_operand:<VM> 2 \"vector_merge_operand\"        \"  0vu\")))]\n   \"TARGET_VECTOR && known_gt (GET_MODE_SIZE (<MODE>mode), BYTES_PER_RISCV_VECTOR)\"\n@@ -6577,3 +6589,204 @@\n   \"vfmv.f.s\\t%0,%1\"\n   [(set_attr \"type\" \"vfmovvf\")\n    (set_attr \"mode\" \"<MODE>\")])\n+\n+;; vslide instructions\n+(define_insn \"@pred_slide<ud><mode>\"\n+  [(set (match_operand:V 0 \"register_operand\"             \"<ud_constraint>\")\n+\t(unspec:V\n+\t  [(unspec:<VM>\n+\t     [(match_operand:<VM> 1 \"vector_mask_operand\" \"     vm,    Wc1\")\n+\t      (match_operand 5 \"vector_length_operand\"    \"     rK,     rK\")\n+\t      (match_operand 6 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 7 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 8 \"const_int_operand\"        \"      i,      i\")\n+\t      (reg:SI VL_REGNUM)\n+\t      (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t   (match_operand:V 2 \"vector_merge_operand\"      \"    0vu,    0vu\")\n+\t   (match_operand:V 3 \"register_operand\"          \"     vr,     vr\")\n+\t   (match_operand 4 \"pmode_reg_or_uimm5_operand\"  \"     rK,     rK\")] VSLIDES))]\n+  \"TARGET_VECTOR\"\n+  \"vslide<ud>.v%o4\\t%0,%3,%4%p1\"\n+  [(set_attr \"type\" \"vslide<ud>\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; vslide1 instructions\n+(define_insn \"@pred_slide<ud><mode>\"\n+  [(set (match_operand:VI_QHS 0 \"register_operand\"        \"<ud_constraint>\")\n+\t(unspec:VI_QHS\n+\t  [(unspec:<VM>\n+\t     [(match_operand:<VM> 1 \"vector_mask_operand\" \"     vm,    Wc1\")\n+\t      (match_operand 5 \"vector_length_operand\"    \"     rK,     rK\")\n+\t      (match_operand 6 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 7 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 8 \"const_int_operand\"        \"      i,      i\")\n+\t      (reg:SI VL_REGNUM)\n+\t      (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t   (match_operand:VI_QHS 2 \"vector_merge_operand\" \"    0vu,    0vu\")\n+\t   (match_operand:VI_QHS 3 \"register_operand\"     \"     vr,     vr\")\n+\t   (match_operand:<VEL> 4 \"reg_or_0_operand\"      \"     rJ,     rJ\")] VSLIDES1))]\n+  \"TARGET_VECTOR\"\n+  \"vslide<ud>.vx\\t%0,%3,%z4%p1\"\n+  [(set_attr \"type\" \"vislide<ud>\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_expand \"@pred_slide<ud><mode>\"\n+  [(set (match_operand:VI_D 0 \"register_operand\")\n+\t(unspec:VI_D\n+\t  [(unspec:<VM>\n+\t     [(match_operand:<VM> 1 \"vector_mask_operand\")\n+\t      (match_operand 5 \"reg_or_int_operand\")\n+\t      (match_operand 6 \"const_int_operand\")\n+\t      (match_operand 7 \"const_int_operand\")\n+\t      (match_operand 8 \"const_int_operand\")\n+\t      (reg:SI VL_REGNUM)\n+\t      (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t   (match_operand:VI_D 2 \"vector_merge_operand\")\n+\t   (match_operand:VI_D 3 \"register_operand\")\n+\t   (match_operand:<VEL> 4 \"reg_or_int_operand\")] VSLIDES1))]\n+  \"TARGET_VECTOR\"\n+{\n+  if (riscv_vector::slide1_sew64_helper (<UNSPEC>, <MODE>mode,\n+\t\t\t\t\t <VDEMOTE>mode, <VMDEMOTE>mode,\n+\t\t\t\t\t operands))\n+    DONE;\n+})\n+\n+(define_insn \"*pred_slide<ud><mode>\"\n+  [(set (match_operand:VI_D 0 \"register_operand\"          \"<ud_constraint>\")\n+\t(unspec:VI_D\n+\t  [(unspec:<VM>\n+\t     [(match_operand:<VM> 1 \"vector_mask_operand\" \"     vm,    Wc1\")\n+\t      (match_operand 5 \"vector_length_operand\"    \"     rK,     rK\")\n+\t      (match_operand 6 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 7 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 8 \"const_int_operand\"        \"      i,      i\")\n+\t      (reg:SI VL_REGNUM)\n+\t      (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t   (match_operand:VI_D 2 \"vector_merge_operand\"   \"    0vu,    0vu\")\n+\t   (match_operand:VI_D 3 \"register_operand\"       \"     vr,     vr\")\n+\t   (match_operand:<VEL> 4 \"reg_or_0_operand\"      \"     rJ,     rJ\")] VSLIDES1))]\n+  \"TARGET_VECTOR\"\n+  \"vslide<ud>.vx\\t%0,%3,%z4%p1\"\n+  [(set_attr \"type\" \"vislide<ud>\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"*pred_slide<ud><mode>_extended\"\n+  [(set (match_operand:VI_D 0 \"register_operand\"          \"<ud_constraint>\")\n+\t(unspec:VI_D\n+\t  [(unspec:<VM>\n+\t     [(match_operand:<VM> 1 \"vector_mask_operand\" \"     vm,    Wc1\")\n+\t      (match_operand 5 \"vector_length_operand\"    \"     rK,     rK\")\n+\t      (match_operand 6 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 7 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 8 \"const_int_operand\"        \"      i,      i\")\n+\t      (reg:SI VL_REGNUM)\n+\t      (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t   (match_operand:VI_D 2 \"vector_merge_operand\"   \"    0vu,    0vu\")\n+\t   (match_operand:VI_D 3 \"register_operand\"       \"     vr,     vr\")\n+\t   (sign_extend:<VEL>\n+\t     (match_operand:<VSUBEL> 4 \"reg_or_0_operand\" \"     rJ,     rJ\"))] VSLIDES1))]\n+  \"TARGET_VECTOR\"\n+  \"vslide<ud>.vx\\t%0,%3,%z4%p1\"\n+  [(set_attr \"type\" \"vislide<ud>\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; vfslide1 instructions\n+(define_insn \"@pred_slide<ud><mode>\"\n+  [(set (match_operand:VF 0 \"register_operand\"            \"<ud_constraint>\")\n+\t(unspec:VF\n+\t  [(unspec:<VM>\n+\t     [(match_operand:<VM> 1 \"vector_mask_operand\" \"     vm,    Wc1\")\n+\t      (match_operand 5 \"vector_length_operand\"    \"     rK,     rK\")\n+\t      (match_operand 6 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 7 \"const_int_operand\"        \"      i,      i\")\n+\t      (match_operand 8 \"const_int_operand\"        \"      i,      i\")\n+\t      (reg:SI VL_REGNUM)\n+\t      (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t   (match_operand:VF 2 \"vector_merge_operand\"     \"    0vu,    0vu\")\n+\t   (match_operand:VF 3 \"register_operand\"         \"     vr,     vr\")\n+\t   (match_operand:<VEL> 4 \"register_operand\"      \"      f,      f\")] VFSLIDES1))]\n+  \"TARGET_VECTOR\"\n+  \"vfslide<ud>.vf\\t%0,%3,%4%p1\"\n+  [(set_attr \"type\" \"vfslide<ud>\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; vrgather\n+(define_insn \"@pred_gather<mode>\"\n+  [(set (match_operand:V 0 \"register_operand\"              \"=&vr\")\n+\t(if_then_else:V\n+\t  (unspec:<VM>\n+\t    [(match_operand:<VM> 1 \"vector_mask_operand\"  \"vmWc1\")\n+\t     (match_operand 5 \"vector_length_operand\"     \"   rK\")\n+\t     (match_operand 6 \"const_int_operand\"         \"    i\")\n+\t     (match_operand 7 \"const_int_operand\"         \"    i\")\n+\t     (match_operand 8 \"const_int_operand\"         \"    i\")\n+\t     (reg:SI VL_REGNUM)\n+\t     (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t  (unspec:V\n+\t    [(match_operand:V 3 \"register_operand\"        \"   vr\")\n+\t     (match_operand:<VINDEX> 4 \"register_operand\" \"   vr\")] UNSPEC_VRGATHER)\n+\t  (match_operand:V 2 \"vector_merge_operand\"       \"  0vu\")))]\n+  \"TARGET_VECTOR\"\n+  \"vrgather.vv\\t%0,%3,%4%p1\"\n+  [(set_attr \"type\" \"vgather\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"@pred_gather<mode>_scalar\"\n+  [(set (match_operand:V 0 \"register_operand\"               \"=&vr\")\n+\t(if_then_else:V\n+\t  (unspec:<VM>\n+\t    [(match_operand:<VM> 1 \"vector_mask_operand\"   \"vmWc1\")\n+\t     (match_operand 5 \"vector_length_operand\"      \"   rK\")\n+\t     (match_operand 6 \"const_int_operand\"          \"    i\")\n+\t     (match_operand 7 \"const_int_operand\"          \"    i\")\n+\t     (match_operand 8 \"const_int_operand\"          \"    i\")\n+\t     (reg:SI VL_REGNUM)\n+\t     (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t  (unspec:V\n+\t    [(match_operand:V 3 \"register_operand\"         \"   vr\")\n+\t     (match_operand 4 \"pmode_reg_or_uimm5_operand\" \"   rK\")] UNSPEC_VRGATHER)\n+\t  (match_operand:V 2 \"vector_merge_operand\"        \"  0vu\")))]\n+  \"TARGET_VECTOR\"\n+  \"vrgather.v%o4\\t%0,%3,%4%p1\"\n+  [(set_attr \"type\" \"vgather\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; vrgatherei16\n+(define_insn \"@pred_gatherei16<mode>\"\n+  [(set (match_operand:VEI16 0 \"register_operand\"              \"=&vr\")\n+\t(if_then_else:VEI16\n+\t  (unspec:<VM>\n+\t    [(match_operand:<VM> 1 \"vector_mask_operand\"      \"vmWc1\")\n+\t     (match_operand 5 \"vector_length_operand\"         \"   rK\")\n+\t     (match_operand 6 \"const_int_operand\"             \"    i\")\n+\t     (match_operand 7 \"const_int_operand\"             \"    i\")\n+\t     (match_operand 8 \"const_int_operand\"             \"    i\")\n+\t     (reg:SI VL_REGNUM)\n+\t     (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t  (unspec:VEI16\n+\t    [(match_operand:VEI16 3 \"register_operand\"        \"   vr\")\n+\t     (match_operand:<VINDEXEI16> 4 \"register_operand\" \"   vr\")] UNSPEC_VRGATHEREI16)\n+\t  (match_operand:VEI16 2 \"vector_merge_operand\"       \"  0vu\")))]\n+  \"TARGET_VECTOR\"\n+  \"vrgatherei16.vv\\t%0,%3,%4%p1\"\n+  [(set_attr \"type\" \"vgather\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+;; vcompress\n+(define_insn \"@pred_compress<mode>\"\n+  [(set (match_operand:V 0 \"register_operand\"            \"=&vr\")\n+\t(unspec:V\n+\t  [(unspec:<VM>\n+\t    [(match_operand:<VM> 3 \"register_operand\"    \"  vm\")\n+\t     (match_operand 4 \"vector_length_operand\"    \"  rK\")\n+\t     (match_operand 5 \"const_int_operand\"        \"   i\")\n+\t     (match_operand 6 \"const_int_operand\"        \"   i\")\n+\t     (reg:SI VL_REGNUM)\n+\t     (reg:SI VTYPE_REGNUM)] UNSPEC_VPREDICATE)\n+\t   (match_operand:V 2 \"register_operand\"          \"  vr\")\n+\t   (match_operand:V 1 \"vector_merge_operand\"        \" 0vu\")] UNSPEC_VCOMPRESS))]\n+  \"TARGET_VECTOR\"\n+  \"vcompress.vm\\t%0,%2,%3\"\n+  [(set_attr \"type\" \"vcompress\")\n+   (set_attr \"mode\" \"<MODE>\")])"}, {"sha": "9095faf58eeb102bcf5ef6459166bad88845becd", "filename": "gcc/testsuite/gcc.target/riscv/rvv/base/binop_vx_constraint-167.c", "status": "added", "additions": 143, "deletions": 0, "changes": 143, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-167.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-167.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-167.c?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -0,0 +1,143 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-march=rv64gcv -mabi=lp64d -O3 -fno-schedule-insns -fno-schedule-insns2\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include \"riscv_vector.h\"\n+\n+/*\n+** f0:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f0 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, -16, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, -16, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f1:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f1 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 15, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 15, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f2:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f2 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 16, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 16, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f3:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f3 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 0xAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 0xAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f4:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f4 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 0xAAAAAAAAAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 0xAAAAAAAAAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f5:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f5 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 0xAAAAAAAAAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 0xAAAAAAAAAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f6:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f6 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, x, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, x, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f7:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**  ...\n+**\tret\n+*/\n+void f7 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 0, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 0, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/* { dg-final { scan-assembler-not {vmv} } } */"}, {"sha": "f671ffa305837122dce0497ab0a02b29bb7dc3d3", "filename": "gcc/testsuite/gcc.target/riscv/rvv/base/binop_vx_constraint-168.c", "status": "added", "additions": 143, "deletions": 0, "changes": 143, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-168.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-168.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-168.c?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -0,0 +1,143 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-march=rv64gcv -mabi=lp64d -O3 -fno-schedule-insns -fno-schedule-insns2\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include \"riscv_vector.h\"\n+\n+/*\n+** f0:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f0 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, -16, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, -16, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f1:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f1 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 15, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 15, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f2:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f2 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 16, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 16, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f3:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f3 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 0xAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 0xAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f4:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f4 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 0xAAAAAAAAAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 0xAAAAAAAAAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f5:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f5 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 0xAAAAAAAAAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 0xAAAAAAAAAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f6:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f6 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, x, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, x, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f7:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**  ...\n+**\tret\n+*/\n+void f7 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 0, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 0, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/* { dg-final { scan-assembler-not {vmv} } } */"}, {"sha": "8585d552668d866ef116dcd55047f591d8c4c113", "filename": "gcc/testsuite/gcc.target/riscv/rvv/base/binop_vx_constraint-169.c", "status": "added", "additions": 163, "deletions": 0, "changes": 163, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-169.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-169.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-169.c?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -0,0 +1,163 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-march=rv32gcv -mabi=ilp32d -O3 -fno-schedule-insns -fno-schedule-insns2\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include \"riscv_vector.h\"\n+\n+/*\n+** f0:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f0 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, -16, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, -16, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f1:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f1 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 15, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 15, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f2:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f2 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 16, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 16, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f3:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**  ...\n+**\tret\n+*/\n+void f3 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 0xAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 0xAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f4:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f4 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 0xAAAAAAAAAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 0xAAAAAAAAAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f5:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f5 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 0xAAAAAAAAAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 0xAAAAAAAAAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f6:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f6 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, x, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, x, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f7:\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**  ...\n+**\tret\n+*/\n+void f7 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, 0, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1 (v3, 0, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/* { dg-final { scan-assembler-not {vmv} } } */"}, {"sha": "0596417b32c499d8527b0ff8d271a5a62f5158bf", "filename": "gcc/testsuite/gcc.target/riscv/rvv/base/binop_vx_constraint-170.c", "status": "added", "additions": 163, "deletions": 0, "changes": 163, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-170.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-170.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-170.c?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -0,0 +1,163 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-march=rv32gcv -mabi=ilp32d -O3 -fno-schedule-insns -fno-schedule-insns2\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include \"riscv_vector.h\"\n+\n+/*\n+** f0:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f0 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, -16, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, -16, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f1:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f1 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 15, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 15, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f2:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f2 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 16, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 16, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f3:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f3 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 0xAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 0xAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f4:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f4 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 0xAAAAAAAAAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 0xAAAAAAAAAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f5:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f5 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 0xAAAAAAAAAAAAAAAA, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 0xAAAAAAAAAAAAAAAA, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f6:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tret\n+*/\n+void f6 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, x, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, x, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/*\n+** f7:\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*zero\n+**  ...\n+**\tret\n+*/\n+void f7 (void * in, void *out, int64_t x, int n)\n+{\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, 0, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1 (v3, 0, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v4, 4);\n+}\n+\n+/* { dg-final { scan-assembler-not {vmv} } } */"}, {"sha": "dae5eff42ce10dac46d73ce6ab7b5031c469878d", "filename": "gcc/testsuite/gcc.target/riscv/rvv/base/binop_vx_constraint-171.c", "status": "added", "additions": 75, "deletions": 0, "changes": 75, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-171.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-171.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-171.c?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -0,0 +1,75 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-march=rv32gcv -mabi=ilp32d -O3 -fno-schedule-insns -fno-schedule-insns2\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include \"riscv_vector.h\"\n+\n+/*\n+** f1:\n+**  ...\n+**\tvsetivli\\t[a-x0-9]+,\\s*4,e64,m1,tu,m[au]\n+**  ...\n+**\tvsetvli\\tzero,\\s*[a-x0-9]+,e32,m1,tu,m[au]\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvmerge\\.vvm\\tv[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+\n+**  ...\n+**\tret\n+*/\n+void f1 (void * in, void *out, int64_t x, int n)\n+{\n+  vbool64_t m = __riscv_vlm_v_b64 (in, 4);\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, x, 4);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1_tu (v3, v3, x, 4);\n+  vint64m1_t v5 = __riscv_vslide1down_vx_i64m1_tumu (m, v4, v4, x, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v5, 4);\n+}\n+\n+/*\n+** f2:\n+**  ...\n+**\tvsetivli\\t[a-x0-9]+,\\s*4,e64,m1,tu,m[au]\n+**  ...\n+**\tvsetvli\\tzero,\\s*[a-x0-9]+,e32,m1,tu,m[au]\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvmerge\\.vvm\\tv[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+\n+**  ...\n+**\tret\n+*/\n+void f2 (void * in, void *out, int64_t x, int n)\n+{\n+  vbool64_t m = __riscv_vlm_v_b64 (in, 4);\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, x, 4);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1_tu (v3, v3, x, 4);\n+  vint64m1_t v5 = __riscv_vslide1up_vx_i64m1_tumu (m, v4, v4, x, 4);\n+  __riscv_vse64_v_i64m1 (out + 2, v5, 4);\n+}\n+\n+/* { dg-final { scan-assembler-times {vmv} 3 } } */"}, {"sha": "060c853a698896c1349606d3d5ebb3ed4090bd46", "filename": "gcc/testsuite/gcc.target/riscv/rvv/base/binop_vx_constraint-172.c", "status": "added", "additions": 71, "deletions": 0, "changes": 71, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-172.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-172.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-172.c?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -0,0 +1,71 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-march=rv32gcv -mabi=ilp32d -O3 -fno-schedule-insns -fno-schedule-insns2\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include \"riscv_vector.h\"\n+\n+/*\n+** f1:\n+**  ...\n+**\tvsetivli\\tzero,\\s*4,e32,m1,tu,m[au]\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvmerge\\.vvm\\tv[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+\n+**  ...\n+**\tret\n+*/\n+void f1 (void * in, void *out, int64_t x, int n)\n+{\n+  vbool64_t m = __riscv_vlm_v_b64 (in, 4);\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, x, 2);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1_tu (v3, v3, x, 2);\n+  vint64m1_t v5 = __riscv_vslide1down_vx_i64m1_tumu (m, v4, v4, x, 2);\n+  __riscv_vse64_v_i64m1 (out + 2, v5, 4);\n+}\n+\n+/*\n+** f2:\n+**  ...\n+**\tvsetivli\\tzero,\\s*4,e32,m1,tu,m[au]\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvmerge\\.vvm\\tv[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+\n+**  ...\n+**\tret\n+*/\n+void f2 (void * in, void *out, int64_t x, int n)\n+{\n+  vbool64_t m = __riscv_vlm_v_b64 (in, 4);\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, 4);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, 4);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, x, 2);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1_tu (v3, v3, x, 2);\n+  vint64m1_t v5 = __riscv_vslide1up_vx_i64m1_tumu (m, v4, v4, x, 2);\n+  __riscv_vse64_v_i64m1 (out + 2, v5, 4);\n+}\n+\n+/* { dg-final { scan-assembler-times {vmv} 3 } } */"}, {"sha": "0d5a2603856ab26332ab299740e6d59b3e7157b8", "filename": "gcc/testsuite/gcc.target/riscv/rvv/base/binop_vx_constraint-173.c", "status": "added", "additions": 75, "deletions": 0, "changes": 75, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-173.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-173.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-173.c?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -0,0 +1,75 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-march=rv32gcv -mabi=ilp32d -O3 -fno-schedule-insns -fno-schedule-insns2\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include \"riscv_vector.h\"\n+\n+/*\n+** f1:\n+**  ...\n+**\tvsetvli\\t[a-x0-9]+,\\s*[a-x0-9]+,e64,m1,tu,m[au]\n+**  ...\n+**\tvsetvli\\tzero,\\s*[a-x0-9]+,e32,m1,tu,m[au]\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvmerge\\.vvm\\tv[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+\n+**  ...\n+**\tret\n+*/\n+void f1 (void * in, void *out, int64_t x, int vl)\n+{\n+  vbool64_t m = __riscv_vlm_v_b64 (in, vl);\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, vl);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, vl);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, x, vl);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1_tu (v3, v3, x, vl);\n+  vint64m1_t v5 = __riscv_vslide1down_vx_i64m1_tumu (m, v4, v4, x, vl);\n+  __riscv_vse64_v_i64m1 (out + 2, v5, vl);\n+}\n+\n+/*\n+** f2:\n+**  ...\n+**\tvsetvli\\t[a-x0-9]+,\\s*[a-x0-9]+,e64,m1,tu,m[au]\n+**  ...\n+**\tvsetvli\\tzero,\\s*[a-x0-9]+,e32,m1,tu,m[au]\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvmerge\\.vvm\\tv[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+\n+**  ...\n+**\tret\n+*/\n+void f2 (void * in, void *out, int64_t x, int vl)\n+{\n+  vbool64_t m = __riscv_vlm_v_b64 (in, vl);\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, vl);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, vl);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, x, vl);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1_tu (v3, v3, x, vl);\n+  vint64m1_t v5 = __riscv_vslide1up_vx_i64m1_tumu (m, v4, v4, x, vl);\n+  __riscv_vse64_v_i64m1 (out + 2, v5, vl);\n+}\n+\n+/* { dg-final { scan-assembler-times {vmv} 3 } } */"}, {"sha": "f2e5d40ceb790f8606588eac51f1a162ecb310d1", "filename": "gcc/testsuite/gcc.target/riscv/rvv/base/binop_vx_constraint-174.c", "status": "added", "additions": 71, "deletions": 0, "changes": 71, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-174.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1bff101b7e66feed0efc7f656468647e0b5fb48c/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-174.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Friscv%2Frvv%2Fbase%2Fbinop_vx_constraint-174.c?ref=1bff101b7e66feed0efc7f656468647e0b5fb48c", "patch": "@@ -0,0 +1,71 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-march=rv32gcv -mabi=ilp32d -O3 -fno-schedule-insns -fno-schedule-insns2\" } */\n+/* { dg-final { check-function-bodies \"**\" \"\" } } */\n+\n+#include \"riscv_vector.h\"\n+\n+/*\n+** f1:\n+**  ...\n+**\tvsetvli\\t[a-x0-9]+,\\s*zero,e32,m1,tu,m[au]\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1down\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvmerge\\.vvm\\tv[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+\n+**  ...\n+**\tret\n+*/\n+void f1 (void * in, void *out, int64_t x, int vl)\n+{\n+  vbool64_t m = __riscv_vlm_v_b64 (in, vl);\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, vl);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, vl);\n+  vint64m1_t v3 = __riscv_vslide1down_vx_i64m1 (v2, x, 0x80000000);\n+  vint64m1_t v4 = __riscv_vslide1down_vx_i64m1_tu (v3, v3, x, 0x80000000);\n+  vint64m1_t v5 = __riscv_vslide1down_vx_i64m1_tumu (m, v4, v4, x, 0x80000000);\n+  __riscv_vse64_v_i64m1 (out + 2, v5, vl);\n+}\n+\n+/*\n+** f2:\n+**  ...\n+**\tvsetvli\\t[a-x0-9]+,\\s*zero,e32,m1,tu,m[au]\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvslide1up\\.vx\\tv[0-9]+,\\s*v[0-9]+,\\s*[a-x0-9]+\n+**  ...\n+**\tvmerge\\.vvm\\tv[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+,\\s*v[0-9]+\n+**  ...\n+**\tret\n+*/\n+void f2 (void * in, void *out, int64_t x, int vl)\n+{\n+  vbool64_t m = __riscv_vlm_v_b64 (in, vl);\n+  vint64m1_t v = __riscv_vle64_v_i64m1 (in + 1, vl);\n+  vint64m1_t v2 = __riscv_vle64_v_i64m1_tu (v, in + 2, vl);\n+  vint64m1_t v3 = __riscv_vslide1up_vx_i64m1 (v2, x, 0x80000000);\n+  vint64m1_t v4 = __riscv_vslide1up_vx_i64m1_tu (v3, v3, x, 0x80000000);\n+  vint64m1_t v5 = __riscv_vslide1up_vx_i64m1_tumu (m, v4, v4, x, 0x80000000);\n+  __riscv_vse64_v_i64m1 (out + 2, v5, vl);\n+}\n+\n+/* { dg-final { scan-assembler-times {vmv} 3 } } */"}]}