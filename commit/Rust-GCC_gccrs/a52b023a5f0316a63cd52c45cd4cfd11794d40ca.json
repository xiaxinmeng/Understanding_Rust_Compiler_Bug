{"sha": "a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YTUyYjAyM2E1ZjAzMTZhNjNjZDUyYzQ1Y2Q0Y2ZkMTE3OTRkNDBjYQ==", "commit": {"author": {"name": "Paolo Bonzini", "email": "bonzini@gnu.org", "date": "2006-11-04T08:36:45Z"}, "committer": {"name": "Paolo Bonzini", "email": "bonzini@gcc.gnu.org", "date": "2006-11-04T08:36:45Z"}, "message": "fwprop.c: New file.\n\n2006-11-03  Paolo Bonzini  <bonzini@gnu.org>\n            Steven Bosscher  <stevenb.gcc@gmail.com>\n\n        * fwprop.c: New file.\n        * Makefile.in: Add fwprop.o.\n        * tree-pass.h (pass_rtl_fwprop, pass_rtl_fwprop_with_addr): New.\n        * passes.c (init_optimization_passes): Schedule forward propagation.\n        * rtlanal.c (loc_mentioned_in_p): Support NULL value of the second\n        parameter.\n        * timevar.def (TV_FWPROP): New.\n        * common.opt (-fforward-propagate): New.\n        * opts.c (decode_options): Enable forward propagation at -O2.\n        * gcse.c (one_cprop_pass): Do not run local cprop unless touching jumps.\n        * cse.c (fold_rtx_subreg, fold_rtx_mem, fold_rtx_mem_1, find_best_addr,\n        canon_for_address, table_size): Remove.\n        (new_basic_block, insert, remove_from_table): Remove references to\n        table_size.\n        (fold_rtx): Process SUBREGs and MEMs with equiv_constant, make\n        simplification loop more straightforward by not calling fold_rtx\n        recursively.\n        (equiv_constant): Move here a small part of fold_rtx_subreg,\n        do not call fold_rtx.  Call avoid_constant_pool_reference\n        to process MEMs.\n        * recog.c (canonicalize_change_group): New.\n        * recog.h (canonicalize_change_group): New.\n\n        * doc/invoke.texi (Optimization Options): Document fwprop.\n        * doc/passes.texi (RTL passes): Document fwprop.\n\n\nCo-Authored-By: Steven Bosscher <stevenb.gcc@gmail.com>\n\nFrom-SVN: r118475", "tree": {"sha": "ba024c11cf4d0fba9de80471ac1eedc16e891dca", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ba024c11cf4d0fba9de80471ac1eedc16e891dca"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/comments", "author": {"login": "bonzini", "id": 42082, "node_id": "MDQ6VXNlcjQyMDgy", "avatar_url": "https://avatars.githubusercontent.com/u/42082?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bonzini", "html_url": "https://github.com/bonzini", "followers_url": "https://api.github.com/users/bonzini/followers", "following_url": "https://api.github.com/users/bonzini/following{/other_user}", "gists_url": "https://api.github.com/users/bonzini/gists{/gist_id}", "starred_url": "https://api.github.com/users/bonzini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bonzini/subscriptions", "organizations_url": "https://api.github.com/users/bonzini/orgs", "repos_url": "https://api.github.com/users/bonzini/repos", "events_url": "https://api.github.com/users/bonzini/events{/privacy}", "received_events_url": "https://api.github.com/users/bonzini/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "c7cc12b01d5c608fb214cb7a69e7f40a35ac8fe8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c7cc12b01d5c608fb214cb7a69e7f40a35ac8fe8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c7cc12b01d5c608fb214cb7a69e7f40a35ac8fe8"}], "stats": {"total": 2104, "additions": 1212, "deletions": 892}, "files": [{"sha": "029b1c9d66afbbb5a53b1c5318fc56ba81ba27e1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 29, "deletions": 1, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -1,3 +1,32 @@\n+2006-11-03  Paolo Bonzini  <bonzini@gnu.org>\n+            Steven Bosscher  <stevenb.gcc@gmail.com>\n+\n+        * fwprop.c: New file.\n+        * Makefile.in: Add fwprop.o.\n+        * tree-pass.h (pass_rtl_fwprop, pass_rtl_fwprop_with_addr): New.\n+        * passes.c (init_optimization_passes): Schedule forward propagation.\n+        * rtlanal.c (loc_mentioned_in_p): Support NULL value of the second\n+        parameter.\n+        * timevar.def (TV_FWPROP): New.\n+        * common.opt (-fforward-propagate): New.\n+        * opts.c (decode_options): Enable forward propagation at -O2.\n+        * gcse.c (one_cprop_pass): Do not run local cprop unless touching jumps.\n+        * cse.c (fold_rtx_subreg, fold_rtx_mem, fold_rtx_mem_1, find_best_addr,\n+        canon_for_address, table_size): Remove.\n+        (new_basic_block, insert, remove_from_table): Remove references to\n+        table_size.\n+        (fold_rtx): Process SUBREGs and MEMs with equiv_constant, make\n+        simplification loop more straightforward by not calling fold_rtx\n+        recursively.\n+        (equiv_constant): Move here a small part of fold_rtx_subreg,\n+        do not call fold_rtx.  Call avoid_constant_pool_reference\n+        to process MEMs.\n+        * recog.c (canonicalize_change_group): New.\n+        * recog.h (canonicalize_change_group): New.\n+\n+        * doc/invoke.texi (Optimization Options): Document fwprop.\n+        * doc/passes.texi (RTL passes): Document fwprop.\n+\n 2006-11-03  Geoffrey Keating  <geoffk@apple.com>\n \n \t* c-decl.c (WANT_C99_INLINE_SEMANTICS): New, set to 1.\n@@ -23,7 +52,6 @@\n \n 2006-11-03  Paul Brook  <paul@codesourcery.com>\n \n-\tgcc/\n \t* config/arm/arm.c (arm_file_start): New function.\n \t(TARGET_ASM_FILE_START): Define.\n \t(arm_default_cpu): New variable."}, {"sha": "59be2fe09c6e0ae98a4c291af5417755f3c03e93", "filename": "gcc/Makefile.in", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -997,7 +997,7 @@ OBJS-common = \\\n  debug.o df-core.o df-problems.o df-scan.o dfp.o diagnostic.o dojump.o     \\\n  dominance.o loop-doloop.o\t   \t\t\t\t\t   \\\n  dwarf2asm.o dwarf2out.o emit-rtl.o except.o explow.o loop-iv.o\t\t   \\\n- expmed.o expr.o final.o flow.o fold-const.o function.o gcse.o\t\t   \\\n+ expmed.o expr.o final.o flow.o fold-const.o function.o fwprop.o gcse.o\t   \\\n  genrtl.o ggc-common.o global.o graph.o gtype-desc.o\t\t\t   \\\n  haifa-sched.o hooks.o ifcvt.o insn-attrtab.o insn-emit.o insn-modes.o\t   \\\n  insn-extract.o insn-opinit.o insn-output.o insn-peep.o insn-recog.o\t   \\\n@@ -2336,6 +2336,9 @@ cse.o : cse.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(REGS_H) \\\n    hard-reg-set.h $(FLAGS_H) insn-config.h $(RECOG_H) $(EXPR_H) toplev.h \\\n    output.h $(FUNCTION_H) $(BASIC_BLOCK_H) $(GGC_H) $(TM_P_H) $(TIMEVAR_H) \\\n    except.h $(TARGET_H) $(PARAMS_H) rtlhooks-def.h tree-pass.h $(REAL_H)\n+fwprop.o : fwprop.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n+   toplev.h insn-config.h $(RECOG_H) $(FLAGS_H) $(OBSTACK_H) $(BASIC_BLOCK_H) \\\n+   output.h $(DF_H) alloc-pool.h $(TIMEVAR_H) tree-pass.h\n web.o : web.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) \\\n    hard-reg-set.h $(FLAGS_H) $(BASIC_BLOCK_H) $(FUNCTION_H) output.h toplev.h \\\n    $(DF_H) $(OBSTACK_H) $(TIMEVAR_H) tree-pass.h"}, {"sha": "4aaa4d20f18e47a111d147e17efedae7f4c22f60", "filename": "gcc/common.opt", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fcommon.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fcommon.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcommon.opt?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -444,6 +444,10 @@ fforce-mem\n Common Report Var(flag_force_mem)\n Copy memory operands into registers before use\n \n+fforward-propagate\n+Common Report Var(flag_forward_propagate)\n+Perform a forward propagation pass on RTL\n+\n ; Nonzero means don't put addresses of constant functions in registers.\n ; Used for compiling the Unix kernel, where strange substitutions are\n ; done on the assembly output."}, {"sha": "198837774ffd6d495fb2367b9962fc10782fe472", "filename": "gcc/cse.c", "status": "modified", "additions": 83, "deletions": 886, "changes": 969, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -528,10 +528,6 @@ struct table_elt\n \n static struct table_elt *table[HASH_SIZE];\n \n-/* Number of elements in the hash table.  */\n-\n-static unsigned int table_size;\n-\n /* Chain of `struct table_elt's made so far for this function\n    but currently removed from the table.  */\n \n@@ -604,7 +600,6 @@ static inline unsigned safe_hash (rtx, enum machine_mode);\n static unsigned hash_rtx_string (const char *);\n \n static rtx canon_reg (rtx, rtx);\n-static void find_best_addr (rtx, rtx *, enum machine_mode);\n static enum rtx_code find_comparison_args (enum rtx_code, rtx *, rtx *,\n \t\t\t\t\t   enum machine_mode *,\n \t\t\t\t\t   enum machine_mode *);\n@@ -735,57 +730,6 @@ approx_reg_cost (rtx x)\n   return cost;\n }\n \n-/* Returns a canonical version of X for the address, from the point of view,\n-   that all multiplications are represented as MULT instead of the multiply\n-   by a power of 2 being represented as ASHIFT.  */\n-\n-static rtx\n-canon_for_address (rtx x)\n-{\n-  enum rtx_code code;\n-  enum machine_mode mode;\n-  rtx new = 0;\n-  int i;\n-  const char *fmt;\n-  \n-  if (!x)\n-    return x;\n-  \n-  code = GET_CODE (x);\n-  mode = GET_MODE (x);\n-  \n-  switch (code)\n-    {\n-    case ASHIFT:\n-      if (GET_CODE (XEXP (x, 1)) == CONST_INT\n-\t  && INTVAL (XEXP (x, 1)) < GET_MODE_BITSIZE (mode)\n-\t  && INTVAL (XEXP (x, 1)) >= 0)\n-        {\n-\t  new = canon_for_address (XEXP (x, 0));\n-\t  new = gen_rtx_MULT (mode, new,\n-\t\t\t      gen_int_mode ((HOST_WIDE_INT) 1\n-\t\t\t\t            << INTVAL (XEXP (x, 1)),\n-\t\t\t\t\t    mode));\n-\t}\n-      break;\n-    default:\n-      break;\n-      \n-    }\n-  if (new)\n-    return new;\n-  \n-  /* Now recursively process each operand of this operation.  */\n-  fmt = GET_RTX_FORMAT (code);\n-  for (i = 0; i < GET_RTX_LENGTH (code); i++)\n-    if (fmt[i] == 'e')\n-      {\n-\tnew = canon_for_address (XEXP (x, i));\n-\tXEXP (x, i) = new;\n-      }\n-  return x;\n-}\n-\n /* Return a negative value if an rtx A, whose costs are given by COST_A\n    and REGCOST_A, is more desirable than an rtx B.\n    Return a positive value if A is less desirable, or 0 if the two are\n@@ -965,8 +909,6 @@ new_basic_block (void)\n \t}\n     }\n \n-  table_size = 0;\n-\n #ifdef HAVE_cc0\n   prev_insn = 0;\n   prev_insn_cc0 = 0;\n@@ -1377,8 +1319,6 @@ remove_from_table (struct table_elt *elt, unsigned int hash)\n   /* Now add it to the free element chain.  */\n   elt->next_same_hash = free_element_chain;\n   free_element_chain = elt;\n-\n-  table_size--;\n }\n \n /* Look up X in the hash table and return its table element,\n@@ -1656,8 +1596,6 @@ insert (rtx x, struct table_elt *classp, unsigned int hash, enum machine_mode mo\n \t}\n     }\n \n-  table_size++;\n-\n   return elt;\n }\n \f\n@@ -2824,231 +2762,6 @@ canon_reg (rtx x, rtx insn)\n   return x;\n }\n \f\n-/* LOC is a location within INSN that is an operand address (the contents of\n-   a MEM).  Find the best equivalent address to use that is valid for this\n-   insn.\n-\n-   On most CISC machines, complicated address modes are costly, and rtx_cost\n-   is a good approximation for that cost.  However, most RISC machines have\n-   only a few (usually only one) memory reference formats.  If an address is\n-   valid at all, it is often just as cheap as any other address.  Hence, for\n-   RISC machines, we use `address_cost' to compare the costs of various\n-   addresses.  For two addresses of equal cost, choose the one with the\n-   highest `rtx_cost' value as that has the potential of eliminating the\n-   most insns.  For equal costs, we choose the first in the equivalence\n-   class.  Note that we ignore the fact that pseudo registers are cheaper than\n-   hard registers here because we would also prefer the pseudo registers.  */\n-\n-static void\n-find_best_addr (rtx insn, rtx *loc, enum machine_mode mode)\n-{\n-  struct table_elt *elt;\n-  rtx addr = *loc;\n-  struct table_elt *p;\n-  int found_better = 1;\n-  int save_do_not_record = do_not_record;\n-  int save_hash_arg_in_memory = hash_arg_in_memory;\n-  int addr_volatile;\n-  int regno;\n-  unsigned hash;\n-\n-  /* Do not try to replace constant addresses or addresses of local and\n-     argument slots.  These MEM expressions are made only once and inserted\n-     in many instructions, as well as being used to control symbol table\n-     output.  It is not safe to clobber them.\n-\n-     There are some uncommon cases where the address is already in a register\n-     for some reason, but we cannot take advantage of that because we have\n-     no easy way to unshare the MEM.  In addition, looking up all stack\n-     addresses is costly.  */\n-  if ((GET_CODE (addr) == PLUS\n-       && REG_P (XEXP (addr, 0))\n-       && GET_CODE (XEXP (addr, 1)) == CONST_INT\n-       && (regno = REGNO (XEXP (addr, 0)),\n-\t   regno == FRAME_POINTER_REGNUM || regno == HARD_FRAME_POINTER_REGNUM\n-\t   || regno == ARG_POINTER_REGNUM))\n-      || (REG_P (addr)\n-\t  && (regno = REGNO (addr), regno == FRAME_POINTER_REGNUM\n-\t      || regno == HARD_FRAME_POINTER_REGNUM\n-\t      || regno == ARG_POINTER_REGNUM))\n-      || CONSTANT_ADDRESS_P (addr))\n-    return;\n-\n-  /* If this address is not simply a register, try to fold it.  This will\n-     sometimes simplify the expression.  Many simplifications\n-     will not be valid, but some, usually applying the associative rule, will\n-     be valid and produce better code.  */\n-  if (!REG_P (addr))\n-    {\n-      rtx folded = canon_for_address (fold_rtx (addr, NULL_RTX));\n-\n-      if (folded != addr)\n-\t{\n-\t  int addr_folded_cost = address_cost (folded, mode);\n-\t  int addr_cost = address_cost (addr, mode);\n-\n-\t  if ((addr_folded_cost < addr_cost\n-\t       || (addr_folded_cost == addr_cost\n-\t\t   /* ??? The rtx_cost comparison is left over from an older\n-\t\t      version of this code.  It is probably no longer helpful.*/\n-\t\t   && (rtx_cost (folded, MEM) > rtx_cost (addr, MEM)\n-\t\t       || approx_reg_cost (folded) < approx_reg_cost (addr))))\n-\t      && validate_change (insn, loc, folded, 0))\n-\t    addr = folded;\n-\t}\n-    }\n-\n-  /* If this address is not in the hash table, we can't look for equivalences\n-     of the whole address.  Also, ignore if volatile.  */\n-\n-  do_not_record = 0;\n-  hash = HASH (addr, Pmode);\n-  addr_volatile = do_not_record;\n-  do_not_record = save_do_not_record;\n-  hash_arg_in_memory = save_hash_arg_in_memory;\n-\n-  if (addr_volatile)\n-    return;\n-\n-  elt = lookup (addr, hash, Pmode);\n-\n-  if (elt)\n-    {\n-      /* We need to find the best (under the criteria documented above) entry\n-\t in the class that is valid.  We use the `flag' field to indicate\n-\t choices that were invalid and iterate until we can't find a better\n-\t one that hasn't already been tried.  */\n-\n-      for (p = elt->first_same_value; p; p = p->next_same_value)\n-\tp->flag = 0;\n-\n-      while (found_better)\n-\t{\n-\t  int best_addr_cost = address_cost (*loc, mode);\n-\t  int best_rtx_cost = (elt->cost + 1) >> 1;\n-\t  int exp_cost;\n-\t  struct table_elt *best_elt = elt;\n-\n-\t  found_better = 0;\n-\t  for (p = elt->first_same_value; p; p = p->next_same_value)\n-\t    if (! p->flag)\n-\t      {\n-\t\tif ((REG_P (p->exp)\n-\t\t     || exp_equiv_p (p->exp, p->exp, 1, false))\n-\t\t    && ((exp_cost = address_cost (p->exp, mode)) < best_addr_cost\n-\t\t\t|| (exp_cost == best_addr_cost\n-\t\t\t    && ((p->cost + 1) >> 1) > best_rtx_cost)))\n-\t\t  {\n-\t\t    found_better = 1;\n-\t\t    best_addr_cost = exp_cost;\n-\t\t    best_rtx_cost = (p->cost + 1) >> 1;\n-\t\t    best_elt = p;\n-\t\t  }\n-\t      }\n-\n-\t  if (found_better)\n-\t    {\n-\t      if (validate_change (insn, loc,\n-\t\t\t\t   canon_reg (copy_rtx (best_elt->exp),\n-\t\t\t\t\t      NULL_RTX), 0))\n-\t\treturn;\n-\t      else\n-\t\tbest_elt->flag = 1;\n-\t    }\n-\t}\n-    }\n-\n-  /* If the address is a binary operation with the first operand a register\n-     and the second a constant, do the same as above, but looking for\n-     equivalences of the register.  Then try to simplify before checking for\n-     the best address to use.  This catches a few cases:  First is when we\n-     have REG+const and the register is another REG+const.  We can often merge\n-     the constants and eliminate one insn and one register.  It may also be\n-     that a machine has a cheap REG+REG+const.  Finally, this improves the\n-     code on the Alpha for unaligned byte stores.  */\n-\n-  if (flag_expensive_optimizations\n-      && ARITHMETIC_P (*loc)\n-      && REG_P (XEXP (*loc, 0)))\n-    {\n-      rtx op1 = XEXP (*loc, 1);\n-\n-      do_not_record = 0;\n-      hash = HASH (XEXP (*loc, 0), Pmode);\n-      do_not_record = save_do_not_record;\n-      hash_arg_in_memory = save_hash_arg_in_memory;\n-\n-      elt = lookup (XEXP (*loc, 0), hash, Pmode);\n-      if (elt == 0)\n-\treturn;\n-\n-      /* We need to find the best (under the criteria documented above) entry\n-\t in the class that is valid.  We use the `flag' field to indicate\n-\t choices that were invalid and iterate until we can't find a better\n-\t one that hasn't already been tried.  */\n-\n-      for (p = elt->first_same_value; p; p = p->next_same_value)\n-\tp->flag = 0;\n-\n-      while (found_better)\n-\t{\n-\t  int best_addr_cost = address_cost (*loc, mode);\n-\t  int best_rtx_cost = (COST (*loc) + 1) >> 1;\n-\t  struct table_elt *best_elt = elt;\n-\t  rtx best_rtx = *loc;\n-\t  int count;\n-\n-\t  /* This is at worst case an O(n^2) algorithm, so limit our search\n-\t     to the first 32 elements on the list.  This avoids trouble\n-\t     compiling code with very long basic blocks that can easily\n-\t     call simplify_gen_binary so many times that we run out of\n-\t     memory.  */\n-\n-\t  found_better = 0;\n-\t  for (p = elt->first_same_value, count = 0;\n-\t       p && count < 32;\n-\t       p = p->next_same_value, count++)\n-\t    if (! p->flag\n-\t\t&& (REG_P (p->exp)\n-\t\t    || (GET_CODE (p->exp) != EXPR_LIST\n-\t\t\t&& exp_equiv_p (p->exp, p->exp, 1, false))))\n-\n-\t      {\n-\t\trtx new = simplify_gen_binary (GET_CODE (*loc), Pmode,\n-\t\t\t\t\t       p->exp, op1);\n-\t\tint new_cost;\n-\t\t\n-\t\t/* Get the canonical version of the address so we can accept\n-\t\t   more.  */\n-\t\tnew = canon_for_address (new);\n-\t\t\n-\t\tnew_cost = address_cost (new, mode);\n-\n-\t\tif (new_cost < best_addr_cost\n-\t\t    || (new_cost == best_addr_cost\n-\t\t\t&& (COST (new) + 1) >> 1 > best_rtx_cost))\n-\t\t  {\n-\t\t    found_better = 1;\n-\t\t    best_addr_cost = new_cost;\n-\t\t    best_rtx_cost = (COST (new) + 1) >> 1;\n-\t\t    best_elt = p;\n-\t\t    best_rtx = new;\n-\t\t  }\n-\t      }\n-\n-\t  if (found_better)\n-\t    {\n-\t      if (validate_change (insn, loc,\n-\t\t\t\t   canon_reg (copy_rtx (best_rtx),\n-\t\t\t\t\t      NULL_RTX), 0))\n-\t\treturn;\n-\t      else\n-\t\tbest_elt->flag = 1;\n-\t    }\n-\t}\n-    }\n-}\n-\f\n /* Given an operation (CODE, *PARG1, *PARG2), where code is a comparison\n    operation (EQ, NE, GT, etc.), follow it back through the hash table and\n    what values are being compared.\n@@ -3243,425 +2956,14 @@ find_comparison_args (enum rtx_code code, rtx *parg1, rtx *parg2,\n   return code;\n }\n \f\n-/* Fold SUBREG.  */\n-\n-static rtx\n-fold_rtx_subreg (rtx x, rtx insn)\n-{\n-  enum machine_mode mode = GET_MODE (x);\n-  rtx folded_arg0;\n-  rtx const_arg0;\n-  rtx new;\n-\n-  /* See if we previously assigned a constant value to this SUBREG.  */\n-  if ((new = lookup_as_function (x, CONST_INT)) != 0\n-      || (new = lookup_as_function (x, CONST_DOUBLE)) != 0)\n-    return new;\n-\n-  /* If this is a paradoxical SUBREG, we have no idea what value the\n-     extra bits would have.  However, if the operand is equivalent to\n-     a SUBREG whose operand is the same as our mode, and all the modes\n-     are within a word, we can just use the inner operand because\n-     these SUBREGs just say how to treat the register.\n-\n-     Similarly if we find an integer constant.  */\n-\n-  if (GET_MODE_SIZE (mode) > GET_MODE_SIZE (GET_MODE (SUBREG_REG (x))))\n-    {\n-      enum machine_mode imode = GET_MODE (SUBREG_REG (x));\n-      struct table_elt *elt;\n-\n-      if (GET_MODE_SIZE (mode) <= UNITS_PER_WORD\n-\t  && GET_MODE_SIZE (imode) <= UNITS_PER_WORD\n-\t  && (elt = lookup (SUBREG_REG (x), HASH (SUBREG_REG (x), imode),\n-\t\t\t    imode)) != 0)\n-\tfor (elt = elt->first_same_value; elt; elt = elt->next_same_value)\n-\t  {\n-\t    if (CONSTANT_P (elt->exp)\n-\t\t&& GET_MODE (elt->exp) == VOIDmode)\n-\t      return elt->exp;\n-\n-\t    if (GET_CODE (elt->exp) == SUBREG\n-\t\t&& GET_MODE (SUBREG_REG (elt->exp)) == mode\n-\t\t&& exp_equiv_p (elt->exp, elt->exp, 1, false))\n-\t      return copy_rtx (SUBREG_REG (elt->exp));\n-\t  }\n-\n-      return x;\n-    }\n-\n-  /* Fold SUBREG_REG.  If it changed, see if we can simplify the\n-     SUBREG.  We might be able to if the SUBREG is extracting a single\n-     word in an integral mode or extracting the low part.  */\n-\n-  folded_arg0 = fold_rtx (SUBREG_REG (x), insn);\n-  const_arg0 = equiv_constant (folded_arg0);\n-  if (const_arg0)\n-    folded_arg0 = const_arg0;\n-\n-  if (folded_arg0 != SUBREG_REG (x))\n-    {\n-      new = simplify_subreg (mode, folded_arg0,\n-\t\t\t     GET_MODE (SUBREG_REG (x)), SUBREG_BYTE (x));\n-      if (new)\n-\treturn new;\n-    }\n-\n-  if (REG_P (folded_arg0)\n-      && GET_MODE_SIZE (mode) < GET_MODE_SIZE (GET_MODE (folded_arg0)))\n-    {\n-      struct table_elt *elt;\n-\n-      elt = lookup (folded_arg0,\n-\t\t    HASH (folded_arg0, GET_MODE (folded_arg0)),\n-\t\t    GET_MODE (folded_arg0));\n-\n-      if (elt)\n-\telt = elt->first_same_value;\n-\n-      if (subreg_lowpart_p (x))\n-\t/* If this is a narrowing SUBREG and our operand is a REG, see\n-\t   if we can find an equivalence for REG that is an arithmetic\n-\t   operation in a wider mode where both operands are\n-\t   paradoxical SUBREGs from objects of our result mode.  In\n-\t   that case, we couldn-t report an equivalent value for that\n-\t   operation, since we don't know what the extra bits will be.\n-\t   But we can find an equivalence for this SUBREG by folding\n-\t   that operation in the narrow mode.  This allows us to fold\n-\t   arithmetic in narrow modes when the machine only supports\n-\t   word-sized arithmetic.\n-\n-\t   Also look for a case where we have a SUBREG whose operand\n-\t   is the same as our result.  If both modes are smaller than\n-\t   a word, we are simply interpreting a register in different\n-\t   modes and we can use the inner value.  */\n-\n-\tfor (; elt; elt = elt->next_same_value)\n-\t  {\n-\t    enum rtx_code eltcode = GET_CODE (elt->exp);\n-\n-\t    /* Just check for unary and binary operations.  */\n-\t    if (UNARY_P (elt->exp)\n-\t\t&& eltcode != SIGN_EXTEND\n-\t\t&& eltcode != ZERO_EXTEND\n-\t\t&& GET_CODE (XEXP (elt->exp, 0)) == SUBREG\n-\t\t&& GET_MODE (SUBREG_REG (XEXP (elt->exp, 0))) == mode\n-\t\t&& (GET_MODE_CLASS (mode)\n-\t\t    == GET_MODE_CLASS (GET_MODE (XEXP (elt->exp, 0)))))\n-\t      {\n-\t\trtx op0 = SUBREG_REG (XEXP (elt->exp, 0));\n-\n-\t\tif (!REG_P (op0) && ! CONSTANT_P (op0))\n-\t\t  op0 = fold_rtx (op0, NULL_RTX);\n-\n-\t\top0 = equiv_constant (op0);\n-\t\tif (op0)\n-\t\t  new = simplify_unary_operation (GET_CODE (elt->exp), mode,\n-\t\t\t\t\t\t  op0, mode);\n-\t      }\n-\t    else if (ARITHMETIC_P (elt->exp)\n-\t\t     && eltcode != DIV && eltcode != MOD\n-\t\t     && eltcode != UDIV && eltcode != UMOD\n-\t\t     && eltcode != ASHIFTRT && eltcode != LSHIFTRT\n-\t\t     && eltcode != ROTATE && eltcode != ROTATERT\n-\t\t     && ((GET_CODE (XEXP (elt->exp, 0)) == SUBREG\n-\t\t\t  && (GET_MODE (SUBREG_REG (XEXP (elt->exp, 0)))\n-\t\t\t      == mode))\n-\t\t\t || CONSTANT_P (XEXP (elt->exp, 0)))\n-\t\t     && ((GET_CODE (XEXP (elt->exp, 1)) == SUBREG\n-\t\t\t  && (GET_MODE (SUBREG_REG (XEXP (elt->exp, 1)))\n-\t\t\t      == mode))\n-\t\t\t || CONSTANT_P (XEXP (elt->exp, 1))))\n-\t      {\n-\t\trtx op0 = gen_lowpart_common (mode, XEXP (elt->exp, 0));\n-\t\trtx op1 = gen_lowpart_common (mode, XEXP (elt->exp, 1));\n-\n-\t\tif (op0 && !REG_P (op0) && ! CONSTANT_P (op0))\n-\t\t  op0 = fold_rtx (op0, NULL_RTX);\n-\n-\t\tif (op0)\n-\t\t  op0 = equiv_constant (op0);\n-\n-\t\tif (op1 && !REG_P (op1) && ! CONSTANT_P (op1))\n-\t\t  op1 = fold_rtx (op1, NULL_RTX);\n-\n-\t\tif (op1)\n-\t\t  op1 = equiv_constant (op1);\n-\n-\t\t/* If we are looking for the low SImode part of\n-\t\t   (ashift:DI c (const_int 32)), it doesn't work to\n-\t\t   compute that in SImode, because a 32-bit shift in\n-\t\t   SImode is unpredictable.  We know the value is\n-\t\t   0.  */\n-\t\tif (op0 && op1\n-\t\t    && GET_CODE (elt->exp) == ASHIFT\n-\t\t    && GET_CODE (op1) == CONST_INT\n-\t\t    && INTVAL (op1) >= GET_MODE_BITSIZE (mode))\n-\t\t  {\n-\t\t    if (INTVAL (op1)\n-\t\t\t< GET_MODE_BITSIZE (GET_MODE (elt->exp)))\n-\t\t      /* If the count fits in the inner mode's width,\n-\t\t\t but exceeds the outer mode's width, the value\n-\t\t\t will get truncated to 0 by the subreg.  */\n-\t\t      new = CONST0_RTX (mode);\n-\t\t    else\n-\t\t      /* If the count exceeds even the inner mode's width,\n-\t\t\t don't fold this expression.  */\n-\t\t      new = 0;\n-\t\t  }\n-\t\telse if (op0 && op1)\n-\t\t  new = simplify_binary_operation (GET_CODE (elt->exp),\n-\t\t\t\t\t\t   mode, op0, op1);\n-\t      }\n-\n-\t    else if (GET_CODE (elt->exp) == SUBREG\n-\t\t     && GET_MODE (SUBREG_REG (elt->exp)) == mode\n-\t\t     && (GET_MODE_SIZE (GET_MODE (folded_arg0))\n-\t\t\t <= UNITS_PER_WORD)\n-\t\t     && exp_equiv_p (elt->exp, elt->exp, 1, false))\n-\t      new = copy_rtx (SUBREG_REG (elt->exp));\n-\n-\t    if (new)\n-\t      return new;\n-\t  }\n-      else\n-\t/* A SUBREG resulting from a zero extension may fold to zero\n-\t   if it extracts higher bits than the ZERO_EXTEND's source\n-\t   bits.  FIXME: if combine tried to, er, combine these\n-\t   instructions, this transformation may be moved to\n-\t   simplify_subreg.  */\n-\tfor (; elt; elt = elt->next_same_value)\n-\t  {\n-\t    if (GET_CODE (elt->exp) == ZERO_EXTEND\n-\t\t&& subreg_lsb (x)\n-\t\t>= GET_MODE_BITSIZE (GET_MODE (XEXP (elt->exp, 0))))\n-\t      return CONST0_RTX (mode);\n-\t  }\n-    }\n-\n-  return x;\n-}\n-\n-/* Fold MEM.  Not to be called directly, see fold_rtx_mem instead.  */\n-\n-static rtx\n-fold_rtx_mem_1 (rtx x, rtx insn)\n-{\n-  enum machine_mode mode = GET_MODE (x);\n-  rtx new;\n-\n-  /* If we are not actually processing an insn, don't try to find the\n-     best address.  Not only don't we care, but we could modify the\n-     MEM in an invalid way since we have no insn to validate\n-     against.  */\n-  if (insn != 0)\n-    find_best_addr (insn, &XEXP (x, 0), mode);\n-\n-  {\n-    /* Even if we don't fold in the insn itself, we can safely do so\n-       here, in hopes of getting a constant.  */\n-    rtx addr = fold_rtx (XEXP (x, 0), NULL_RTX);\n-    rtx base = 0;\n-    HOST_WIDE_INT offset = 0;\n-\n-    if (REG_P (addr)\n-\t&& REGNO_QTY_VALID_P (REGNO (addr)))\n-      {\n-\tint addr_q = REG_QTY (REGNO (addr));\n-\tstruct qty_table_elem *addr_ent = &qty_table[addr_q];\n-\n-\tif (GET_MODE (addr) == addr_ent->mode\n-\t    && addr_ent->const_rtx != NULL_RTX)\n-\t  addr = addr_ent->const_rtx;\n-      }\n-\n-    /* Call target hook to avoid the effects of -fpic etc....  */\n-    addr = targetm.delegitimize_address (addr);\n-\n-    /* If address is constant, split it into a base and integer\n-       offset.  */\n-    if (GET_CODE (addr) == SYMBOL_REF || GET_CODE (addr) == LABEL_REF)\n-      base = addr;\n-    else if (GET_CODE (addr) == CONST && GET_CODE (XEXP (addr, 0)) == PLUS\n-\t     && GET_CODE (XEXP (XEXP (addr, 0), 1)) == CONST_INT)\n-      {\n-\tbase = XEXP (XEXP (addr, 0), 0);\n-\toffset = INTVAL (XEXP (XEXP (addr, 0), 1));\n-      }\n-    else if (GET_CODE (addr) == LO_SUM\n-\t     && GET_CODE (XEXP (addr, 1)) == SYMBOL_REF)\n-      base = XEXP (addr, 1);\n-\n-    /* If this is a constant pool reference, we can fold it into its\n-       constant to allow better value tracking.  */\n-    if (base && GET_CODE (base) == SYMBOL_REF\n-\t&& CONSTANT_POOL_ADDRESS_P (base))\n-      {\n-\trtx constant = get_pool_constant (base);\n-\tenum machine_mode const_mode = get_pool_mode (base);\n-\trtx new;\n-\n-\tif (CONSTANT_P (constant) && GET_CODE (constant) != CONST_INT)\n-\t  {\n-\t    constant_pool_entries_cost = COST (constant);\n-\t    constant_pool_entries_regcost = approx_reg_cost (constant);\n-\t  }\n-\n-\t/* If we are loading the full constant, we have an\n-\t   equivalence.  */\n-\tif (offset == 0 && mode == const_mode)\n-\t  return constant;\n-\n-\t/* If this actually isn't a constant (weird!), we can't do\n-\t   anything.  Otherwise, handle the two most common cases:\n-\t   extracting a word from a multi-word constant, and\n-\t   extracting the low-order bits.  Other cases don't seem\n-\t   common enough to worry about.  */\n-\tif (! CONSTANT_P (constant))\n-\t  return x;\n-\n-\tif (GET_MODE_CLASS (mode) == MODE_INT\n-\t    && GET_MODE_SIZE (mode) == UNITS_PER_WORD\n-\t    && offset % UNITS_PER_WORD == 0\n-\t    && (new = operand_subword (constant,\n-\t\t\t\t       offset / UNITS_PER_WORD,\n-\t\t\t\t       0, const_mode)) != 0)\n-\t  return new;\n-\n-\tif (((BYTES_BIG_ENDIAN\n-\t      && offset == GET_MODE_SIZE (GET_MODE (constant)) - 1)\n-\t     || (! BYTES_BIG_ENDIAN && offset == 0))\n-\t    && (new = gen_lowpart (mode, constant)) != 0)\n-\t  return new;\n-      }\n-\n-    /* If this is a reference to a label at a known position in a jump\n-       table, we also know its value.  */\n-    if (base && GET_CODE (base) == LABEL_REF)\n-      {\n-\trtx label = XEXP (base, 0);\n-\trtx table_insn = NEXT_INSN (label);\n-\n-\tif (table_insn && JUMP_P (table_insn)\n-\t    && GET_CODE (PATTERN (table_insn)) == ADDR_VEC)\n-\t  {\n-\t    rtx table = PATTERN (table_insn);\n-\n-\t    if (offset >= 0\n-\t\t&& (offset / GET_MODE_SIZE (GET_MODE (table))\n-\t\t    < XVECLEN (table, 0)))\n-\t      {\n-\t\trtx label = XVECEXP\n-\t\t  (table, 0, offset / GET_MODE_SIZE (GET_MODE (table)));\n-\t\trtx set;\n-\n-\t\t/* If we have an insn that loads the label from the\n-\t\t   jumptable into a reg, we don't want to set the reg\n-\t\t   to the label, because this may cause a reference to\n-\t\t   the label to remain after the label is removed in\n-\t\t   some very obscure cases (PR middle-end/18628).  */\n-\t\tif (!insn)\n-\t\t  return label;\n-\n-\t\tset = single_set (insn);\n+/* If X is a nontrivial arithmetic operation on an argument for which\n+   a constant value can be determined, return the result of operating\n+   on that value, as a constant.  Otherwise, return X, possibly with\n+   one or more operands changed to a forward-propagated constant.\n \n-\t\tif (! set || SET_SRC (set) != x)\n-\t\t  return x;\n-\n-\t\t/* If it's a jump, it's safe to reference the label.  */\n-\t\tif (SET_DEST (set) == pc_rtx)\n-\t\t  return label;\n-\n-\t\treturn x;\n-\t      }\n-\t  }\n-\tif (table_insn && JUMP_P (table_insn)\n-\t    && GET_CODE (PATTERN (table_insn)) == ADDR_DIFF_VEC)\n-\t  {\n-\t    rtx table = PATTERN (table_insn);\n-\n-\t    if (offset >= 0\n-\t\t&& (offset / GET_MODE_SIZE (GET_MODE (table))\n-\t\t    < XVECLEN (table, 1)))\n-\t      {\n-\t\toffset /= GET_MODE_SIZE (GET_MODE (table));\n-\t\tnew = gen_rtx_MINUS (Pmode, XVECEXP (table, 1, offset),\n-\t\t\t\t     XEXP (table, 0));\n-\n-\t\tif (GET_MODE (table) != Pmode)\n-\t\t  new = gen_rtx_TRUNCATE (GET_MODE (table), new);\n-\n-\t\t/* Indicate this is a constant.  This isn't a valid\n-\t\t   form of CONST, but it will only be used to fold the\n-\t\t   next insns and then discarded, so it should be\n-\t\t   safe.\n-\n-\t\t   Note this expression must be explicitly discarded,\n-\t\t   by cse_insn, else it may end up in a REG_EQUAL note\n-\t\t   and \"escape\" to cause problems elsewhere.  */\n-\t\treturn gen_rtx_CONST (GET_MODE (new), new);\n-\t      }\n-\t  }\n-      }\n-\n-    return x;\n-  }\n-}\n-\n-/* Fold MEM.  */\n-\n-static rtx\n-fold_rtx_mem (rtx x, rtx insn)\n-{\n-  /* To avoid infinite oscillations between fold_rtx and fold_rtx_mem,\n-     refuse to allow recursion of the latter past n levels.  This can\n-     happen because fold_rtx_mem will try to fold the address of the\n-     memory reference it is passed, i.e. conceptually throwing away\n-     the MEM and reinjecting the bare address into fold_rtx.  As a\n-     result, patterns like\n-\n-       set (reg1)\n-\t   (plus (reg)\n-\t\t (mem (plus (reg2) (const_int))))\n-\n-       set (reg2)\n-\t   (plus (reg)\n-\t\t (mem (plus (reg1) (const_int))))\n-\n-     will defeat any \"first-order\" short-circuit put in either\n-     function to prevent these infinite oscillations.\n-\n-     The heuristics for determining n is as follows: since each time\n-     it is invoked fold_rtx_mem throws away a MEM, and since MEMs\n-     are generically not nested, we assume that each invocation of\n-     fold_rtx_mem corresponds to a new \"top-level\" operand, i.e.\n-     the source or the destination of a SET.  So fold_rtx_mem is\n-     bound to stop or cycle before n recursions, n being the number\n-     of expressions recorded in the hash table.  We also leave some\n-     play to account for the initial steps.  */\n-\n-  static unsigned int depth;\n-  rtx ret;\n-\n-  if (depth > 3 + table_size)\n-    return x;\n-\n-  depth++;\n-  ret = fold_rtx_mem_1 (x, insn);\n-  depth--;\n-\n-  return ret;\n-}\n-\n-/* If X is a nontrivial arithmetic operation on an argument\n-   for which a constant value can be determined, return\n-   the result of operating on that value, as a constant.\n-   Otherwise, return X, possibly with one or more operands\n-   modified by recursive calls to this function.\n-\n-   If X is a register whose contents are known, we do NOT\n-   return those contents here.  equiv_constant is called to\n-   perform that task.\n+   If X is a register whose contents are known, we do NOT return\n+   those contents here; equiv_constant is called to perform that task.\n+   For SUBREGs and MEMs, we do that both here and in equiv_constant.\n \n    INSN is the insn that we may be modifying.  If it is 0, make a copy\n    of X before modifying it.  */\n@@ -3674,10 +2976,9 @@ fold_rtx (rtx x, rtx insn)\n   const char *fmt;\n   int i;\n   rtx new = 0;\n-  int copied = 0;\n-  int must_swap = 0;\n+  int changed = 0;\n \n-  /* Folded equivalents of first two operands of X.  */\n+  /* Operands of X.  */\n   rtx folded_arg0;\n   rtx folded_arg1;\n \n@@ -3694,10 +2995,16 @@ fold_rtx (rtx x, rtx insn)\n   if (x == 0)\n     return x;\n \n-  mode = GET_MODE (x);\n+  /* Try to perform some initial simplifications on X.  */\n   code = GET_CODE (x);\n   switch (code)\n     {\n+    case MEM:\n+    case SUBREG:\n+      if ((new = equiv_constant (x)) != NULL_RTX)\n+        return new;\n+      return x;\n+\n     case CONST:\n     case CONST_INT:\n     case CONST_DOUBLE:\n@@ -3717,41 +3024,28 @@ fold_rtx (rtx x, rtx insn)\n       return prev_insn_cc0;\n #endif\n \n-    case SUBREG:\n-      return fold_rtx_subreg (x, insn);\n-\n-    case NOT:\n-    case NEG:\n-      /* If we have (NOT Y), see if Y is known to be (NOT Z).\n-\t If so, (NOT Y) simplifies to Z.  Similarly for NEG.  */\n-      new = lookup_as_function (XEXP (x, 0), code);\n-      if (new)\n-\treturn fold_rtx (copy_rtx (XEXP (new, 0)), insn);\n-      break;\n-\n-    case MEM:\n-      return fold_rtx_mem (x, insn);\n-\n-#ifdef NO_FUNCTION_CSE\n-    case CALL:\n-      if (CONSTANT_P (XEXP (XEXP (x, 0), 0)))\n-\treturn x;\n-      break;\n-#endif\n-\n     case ASM_OPERANDS:\n       if (insn)\n \t{\n \t  for (i = ASM_OPERANDS_INPUT_LENGTH (x) - 1; i >= 0; i--)\n \t    validate_change (insn, &ASM_OPERANDS_INPUT (x, i),\n \t\t\t     fold_rtx (ASM_OPERANDS_INPUT (x, i), insn), 0);\n \t}\n+      return x;\n+\n+#ifdef NO_FUNCTION_CSE\n+    case CALL:\n+      if (CONSTANT_P (XEXP (XEXP (x, 0), 0)))\n+\treturn x;\n       break;\n+#endif\n \n+    /* Anything else goes through the loop below.  */\n     default:\n       break;\n     }\n \n+  mode = GET_MODE (x);\n   const_arg0 = 0;\n   const_arg1 = 0;\n   const_arg2 = 0;\n@@ -3764,55 +3058,13 @@ fold_rtx (rtx x, rtx insn)\n   for (i = GET_RTX_LENGTH (code) - 1; i >= 0; i--)\n     if (fmt[i] == 'e')\n       {\n-\trtx arg = XEXP (x, i);\n-\trtx folded_arg = arg, const_arg = 0;\n-\tenum machine_mode mode_arg = GET_MODE (arg);\n-\trtx cheap_arg, expensive_arg;\n-\trtx replacements[2];\n-\tint j;\n-\tint old_cost = COST_IN (XEXP (x, i), code);\n-\n-\t/* Most arguments are cheap, so handle them specially.  */\n-\tswitch (GET_CODE (arg))\n-\t  {\n-\t  case REG:\n-\t    /* This is the same as calling equiv_constant; it is duplicated\n-\t       here for speed.  */\n-\t    if (REGNO_QTY_VALID_P (REGNO (arg)))\n-\t      {\n-\t\tint arg_q = REG_QTY (REGNO (arg));\n-\t\tstruct qty_table_elem *arg_ent = &qty_table[arg_q];\n-\n-\t\tif (arg_ent->const_rtx != NULL_RTX\n-\t\t    && !REG_P (arg_ent->const_rtx)\n-\t\t    && GET_CODE (arg_ent->const_rtx) != PLUS)\n-\t\t  const_arg\n-\t\t    = gen_lowpart (GET_MODE (arg),\n-\t\t\t\t\t       arg_ent->const_rtx);\n-\t      }\n-\t    break;\n-\n-\t  case CONST:\n-\t  case CONST_INT:\n-\t  case SYMBOL_REF:\n-\t  case LABEL_REF:\n-\t  case CONST_DOUBLE:\n-\t  case CONST_VECTOR:\n-\t    const_arg = arg;\n-\t    break;\n-\n+\trtx folded_arg = XEXP (x, i), const_arg;\n+\tenum machine_mode mode_arg = GET_MODE (folded_arg);\n #ifdef HAVE_cc0\n-\t  case CC0:\n-\t    folded_arg = prev_insn_cc0;\n-\t    mode_arg = prev_insn_cc0_mode;\n-\t    const_arg = equiv_constant (folded_arg);\n-\t    break;\n+\tif (CC0_P (folded_arg))\n+\t  folded_arg = prev_insn_cc0, mode_arg = prev_insn_cc0_mode;\n #endif\n-\n-\t  default:\n-\t    folded_arg = fold_rtx (arg, insn);\n-\t    const_arg = equiv_constant (folded_arg);\n-\t  }\n+\tconst_arg = equiv_constant (folded_arg);\n \n \t/* For the first three operands, see if the operand\n \t   is constant or equivalent to a constant.  */\n@@ -3832,120 +3084,50 @@ fold_rtx (rtx x, rtx insn)\n \t    break;\n \t  }\n \n-\t/* Pick the least expensive of the folded argument and an\n-\t   equivalent constant argument.  */\n-\tif (const_arg == 0 || const_arg == folded_arg\n-\t    || COST_IN (const_arg, code) > COST_IN (folded_arg, code))\n-\t  cheap_arg = folded_arg, expensive_arg = const_arg;\n-\telse\n-\t  cheap_arg = const_arg, expensive_arg = folded_arg;\n-\n-\t/* Try to replace the operand with the cheapest of the two\n-\t   possibilities.  If it doesn't work and this is either of the first\n-\t   two operands of a commutative operation, try swapping them.\n-\t   If THAT fails, try the more expensive, provided it is cheaper\n-\t   than what is already there.  */\n-\n-\tif (cheap_arg == XEXP (x, i))\n-\t  continue;\n-\n-\tif (insn == 0 && ! copied)\n-\t  {\n-\t    x = copy_rtx (x);\n-\t    copied = 1;\n-\t  }\n-\n-\t/* Order the replacements from cheapest to most expensive.  */\n-\treplacements[0] = cheap_arg;\n-\treplacements[1] = expensive_arg;\n-\n-\tfor (j = 0; j < 2 && replacements[j]; j++)\n-\t  {\n-\t    int new_cost = COST_IN (replacements[j], code);\n-\n-\t    /* Stop if what existed before was cheaper.  Prefer constants\n-\t       in the case of a tie.  */\n-\t    if (new_cost > old_cost\n-\t\t|| (new_cost == old_cost && CONSTANT_P (XEXP (x, i))))\n-\t      break;\n+\t/* Pick the least expensive of the argument and an equivalent constant\n+\t   argument.  */\n+\tif (const_arg != 0\n+\t    && const_arg != folded_arg\n+\t    && COST_IN (const_arg, code) <= COST_IN (folded_arg, code)\n \n \t    /* It's not safe to substitute the operand of a conversion\n \t       operator with a constant, as the conversion's identity\n \t       depends upon the mode of its operand.  This optimization\n \t       is handled by the call to simplify_unary_operation.  */\n-\t    if (GET_RTX_CLASS (code) == RTX_UNARY\n-\t\t&& GET_MODE (replacements[j]) != mode_arg0\n-\t\t&& (code == ZERO_EXTEND\n-\t\t    || code == SIGN_EXTEND\n-\t\t    || code == TRUNCATE\n-\t\t    || code == FLOAT_TRUNCATE\n-\t\t    || code == FLOAT_EXTEND\n-\t\t    || code == FLOAT\n-\t\t    || code == FIX\n-\t\t    || code == UNSIGNED_FLOAT\n-\t\t    || code == UNSIGNED_FIX))\n-\t      continue;\n-\n-\t    if (validate_change (insn, &XEXP (x, i), replacements[j], 0))\n-\t      break;\n-\n-\t    if (GET_RTX_CLASS (code) == RTX_COMM_COMPARE\n-\t\t|| GET_RTX_CLASS (code) == RTX_COMM_ARITH)\n-\t      {\n-\t\tvalidate_change (insn, &XEXP (x, i), XEXP (x, 1 - i), 1);\n-\t\tvalidate_change (insn, &XEXP (x, 1 - i), replacements[j], 1);\n-\n-\t\tif (apply_change_group ())\n-\t\t  {\n-\t\t    /* Swap them back to be invalid so that this loop can\n-\t\t       continue and flag them to be swapped back later.  */\n-\t\t    rtx tem;\n-\n-\t\t    tem = XEXP (x, 0); XEXP (x, 0) = XEXP (x, 1);\n-\t\t\t\t       XEXP (x, 1) = tem;\n-\t\t    must_swap = 1;\n-\t\t    break;\n-\t\t  }\n-\t      }\n-\t  }\n-      }\n+\t    && (GET_RTX_CLASS (code) != RTX_UNARY\n+\t\t|| GET_MODE (const_arg) == mode_arg0\n+\t\t|| (code != ZERO_EXTEND\n+\t\t    && code != SIGN_EXTEND\n+\t\t    && code != TRUNCATE\n+\t\t    && code != FLOAT_TRUNCATE\n+\t\t    && code != FLOAT_EXTEND\n+\t\t    && code != FLOAT\n+\t\t    && code != FIX\n+\t\t    && code != UNSIGNED_FLOAT\n+\t\t    && code != UNSIGNED_FIX)))\n+\t  folded_arg = const_arg;\n+\n+\tif (folded_arg == XEXP (x, i))\n+\t  continue;\n \n-    else\n-      {\n-\tif (fmt[i] == 'E')\n-\t  /* Don't try to fold inside of a vector of expressions.\n-\t     Doing nothing is harmless.  */\n-\t  {;}\n+\tif (insn == NULL_RTX && !changed)\n+\t  x = copy_rtx (x);\n+\tchanged = 1;\n+\tvalidate_change (insn, &XEXP (x, i), folded_arg, 1);\n       }\n \n-  /* If a commutative operation, place a constant integer as the second\n-     operand unless the first operand is also a constant integer.  Otherwise,\n-     place any constant second unless the first operand is also a constant.  */\n-\n-  if (COMMUTATIVE_P (x))\n+  if (changed)\n     {\n-      if (must_swap\n-\t  || swap_commutative_operands_p (const_arg0 ? const_arg0\n-\t\t\t\t\t\t     : XEXP (x, 0),\n-\t\t\t\t\t  const_arg1 ? const_arg1\n-\t\t\t\t\t\t     : XEXP (x, 1)))\n+      /* Canonicalize X if necessary, and keep const_argN and folded_argN\n+\t consistent with the order in X.  */\n+      if (canonicalize_change_group (insn, x))\n \t{\n-\t  rtx tem = XEXP (x, 0);\n-\n-\t  if (insn == 0 && ! copied)\n-\t    {\n-\t      x = copy_rtx (x);\n-\t      copied = 1;\n-\t    }\n-\n-\t  validate_change (insn, &XEXP (x, 0), XEXP (x, 1), 1);\n-\t  validate_change (insn, &XEXP (x, 1), tem, 1);\n-\t  if (apply_change_group ())\n-\t    {\n-\t      tem = const_arg0, const_arg0 = const_arg1, const_arg1 = tem;\n-\t      tem = folded_arg0, folded_arg0 = folded_arg1, folded_arg1 = tem;\n-\t    }\n+\t  rtx tem;\n+\t  tem = const_arg0, const_arg0 = const_arg1, const_arg1 = tem;\n+\t  tem = folded_arg0, folded_arg0 = folded_arg1, folded_arg1 = tem;\n \t}\n+\n+      apply_change_group ();\n     }\n \n   /* If X is an arithmetic operation, see if we can simplify it.  */\n@@ -4477,16 +3659,31 @@ equiv_constant (rtx x)\n   if (x == 0 || CONSTANT_P (x))\n     return x;\n \n-  /* If X is a MEM, try to fold it outside the context of any insn to see if\n-     it might be equivalent to a constant.  That handles the case where it\n-     is a constant-pool reference.  Then try to look it up in the hash table\n-     in case it is something whose value we have seen before.  */\n+  if (GET_CODE (x) == SUBREG)\n+    {\n+      rtx new;\n+\n+      /* See if we previously assigned a constant value to this SUBREG.  */\n+      if ((new = lookup_as_function (x, CONST_INT)) != 0\n+          || (new = lookup_as_function (x, CONST_DOUBLE)) != 0)\n+        return new;\n+\n+      if (REG_P (SUBREG_REG (x))\n+\t  && (new = equiv_constant (SUBREG_REG (x))) != 0)\n+        return simplify_subreg (GET_MODE (x), SUBREG_REG (x),\n+\t\t\t\tGET_MODE (SUBREG_REG (x)), SUBREG_BYTE (x));\n+\n+      return 0;\n+    }\n+\n+  /* If X is a MEM, see if it is a constant-pool reference, or look it up in\n+     the hash table in case its value was seen before.  */\n \n   if (MEM_P (x))\n     {\n       struct table_elt *elt;\n \n-      x = fold_rtx (x, NULL_RTX);\n+      x = avoid_constant_pool_reference (x);\n       if (CONSTANT_P (x))\n \treturn x;\n "}, {"sha": "2e0de418bc490af016ae561a9c6ba5b5aab986c8", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 11, "deletions": 1, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -310,7 +310,7 @@ Objective-C and Objective-C++ Dialects}.\n -fcse-skip-blocks  -fcx-limited-range  -fdata-sections @gol\n -fdelayed-branch  -fdelete-null-pointer-checks -fearly-inlining @gol\n -fexpensive-optimizations  -ffast-math  -ffloat-store @gol\n--fforce-addr  -ffunction-sections @gol\n+-fforce-addr  -fforward-propagate  -ffunction-sections @gol\n -fgcse  -fgcse-lm  -fgcse-sm  -fgcse-las  -fgcse-after-reload @gol\n -fcrossjumping  -fif-conversion  -fif-conversion2 @gol\n -finline-functions  -finline-functions-called-once @gol\n@@ -4621,6 +4621,16 @@ register-load. This option is now a nop and will be removed in 4.2.\n Force memory address constants to be copied into registers before\n doing arithmetic on them.\n \n+@item -fforward-propagate\n+@opindex fforward-propagate\n+Perform a forward propagation pass on RTL.  The pass tries to combine two\n+instructions and checks if the result can be simplified.  If loop unrolling\n+is active, two passes are performed and the second is scheduled after\n+loop unrolling.\n+\n+This option is enabled by default at optimization levels @option{-O2},\n+@option{-O3}, @option{-Os}.\n+\n @item -fomit-frame-pointer\n @opindex fomit-frame-pointer\n Don't keep the frame pointer in a register for functions that"}, {"sha": "fc6aa2696a4435a30846cb98cf697fe4a6de9760", "filename": "gcc/doc/passes.texi", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fdoc%2Fpasses.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fdoc%2Fpasses.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fpasses.texi?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -685,6 +685,15 @@ optimization pass''.  The bulk of the code for this pass is in\n @file{cfgcleanup.c}, and there are support routines in @file{cfgrtl.c}\n and @file{jump.c}.\n \n+@item Forward propagation of single-def values\n+\n+This pass attempts to remove redundant computation by substituting\n+variables that come from a single definition, and\n+seeing if the result can be simplified.  It performs copy propagation\n+and addressing mode selection.  The pass is run twice, with values\n+being propagated into loops only on the second run.  It is located in\n+@file{fwprop.c}.\n+\n @item Common subexpression elimination\n \n This pass removes redundant computation within basic blocks, and"}, {"sha": "1e4f749eb122204c4928a49cd5411df17514913e", "filename": "gcc/fwprop.c", "status": "added", "additions": 1034, "deletions": 0, "changes": 1034, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Ffwprop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Ffwprop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffwprop.c?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -0,0 +1,1034 @@\n+/* RTL-based forward propagation pass for GNU compiler.\n+   Copyright (C) 2005, 2006 Free Software Foundation, Inc.\n+   Contributed by Paolo Bonzini and Steven Bosscher.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+02110-1301, USA.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"toplev.h\"\n+\n+#include \"timevar.h\"\n+#include \"rtl.h\"\n+#include \"tm_p.h\"\n+#include \"emit-rtl.h\"\n+#include \"insn-config.h\"\n+#include \"recog.h\"\n+#include \"flags.h\"\n+#include \"obstack.h\"\n+#include \"basic-block.h\"\n+#include \"output.h\"\n+#include \"df.h\"\n+#include \"target.h\"\n+#include \"cfgloop.h\"\n+#include \"tree-pass.h\"\n+\n+\n+/* This pass does simple forward propagation and simplification when an\n+   operand of an insn can only come from a single def.  This pass uses\n+   df.c, so it is global.  However, we only do limited analysis of\n+   available expressions.\n+\n+   1) The pass tries to propagate the source of the def into the use,\n+   and checks if the result is independent of the substituted value.\n+   For example, the high word of a (zero_extend:DI (reg:SI M)) is always\n+   zero, independent of the source register.\n+\n+   In particular, we propagate constants into the use site.  Sometimes\n+   RTL expansion did not put the constant in the same insn on purpose,\n+   to satisfy a predicate, and the result will fail to be recognized;\n+   but this happens rarely and in this case we can still create a\n+   REG_EQUAL note.  For multi-word operations, this\n+\n+      (set (subreg:SI (reg:DI 120) 0) (const_int 0))\n+      (set (subreg:SI (reg:DI 120) 4) (const_int -1))\n+      (set (subreg:SI (reg:DI 122) 0)\n+         (ior:SI (subreg:SI (reg:DI 119) 0) (subreg:SI (reg:DI 120) 0)))\n+      (set (subreg:SI (reg:DI 122) 4)\n+         (ior:SI (subreg:SI (reg:DI 119) 4) (subreg:SI (reg:DI 120) 4)))\n+\n+   can be simplified to the much simpler\n+\n+      (set (subreg:SI (reg:DI 122) 0) (subreg:SI (reg:DI 119)))\n+      (set (subreg:SI (reg:DI 122) 4) (const_int -1))\n+\n+   This particular propagation is also effective at putting together\n+   complex addressing modes.  We are more aggressive inside MEMs, in\n+   that all definitions are propagated if the use is in a MEM; if the\n+   result is a valid memory address we check address_cost to decide\n+   whether the substitution is worthwhile.\n+\n+   2) The pass propagates register copies.  This is not as effective as\n+   the copy propagation done by CSE's canon_reg, which works by walking\n+   the instruction chain, it can help the other transformations.\n+\n+   We should consider removing this optimization, and instead reorder the\n+   RTL passes, because GCSE does this transformation too.  With some luck,\n+   the CSE pass at the end of rest_of_handle_gcse could also go away.\n+\n+   3) The pass looks for paradoxical subregs that are actually unnecessary.\n+   Things like this:\n+\n+     (set (reg:QI 120) (subreg:QI (reg:SI 118) 0))\n+     (set (reg:QI 121) (subreg:QI (reg:SI 119) 0))\n+     (set (reg:SI 122) (plus:SI (subreg:SI (reg:QI 120) 0)\n+                                (subreg:SI (reg:QI 121) 0)))\n+\n+   are very common on machines that can only do word-sized operations.\n+   For each use of a paradoxical subreg (subreg:WIDER (reg:NARROW N) 0),\n+   if it has a single def and it is (subreg:NARROW (reg:WIDE M) 0),\n+   we can replace the paradoxical subreg with simply (reg:WIDE M).  The\n+   above will simplify this to\n+\n+     (set (reg:QI 120) (subreg:QI (reg:SI 118) 0))\n+     (set (reg:QI 121) (subreg:QI (reg:SI 119) 0))\n+     (set (reg:SI 122) (plus:SI (reg:SI 118) (reg:SI 119)))\n+\n+   where the first two insns are now dead.  */\n+\n+\n+static struct loops loops;\n+static struct df *df;\n+static int num_changes;\n+\n+\f\n+/* Do not try to replace constant addresses or addresses of local and\n+   argument slots.  These MEM expressions are made only once and inserted\n+   in many instructions, as well as being used to control symbol table\n+   output.  It is not safe to clobber them.\n+\n+   There are some uncommon cases where the address is already in a register\n+   for some reason, but we cannot take advantage of that because we have\n+   no easy way to unshare the MEM.  In addition, looking up all stack\n+   addresses is costly.  */\n+\n+static bool\n+can_simplify_addr (rtx addr)\n+{\n+  rtx reg;\n+\n+  if (CONSTANT_ADDRESS_P (addr))\n+    return false;\n+\n+  if (GET_CODE (addr) == PLUS)\n+    reg = XEXP (addr, 0);\n+  else\n+    reg = addr;\n+\n+  return (!REG_P (reg)\n+\t  || (REGNO (reg) != FRAME_POINTER_REGNUM\n+\t      && REGNO (reg) != HARD_FRAME_POINTER_REGNUM\n+\t      && REGNO (reg) != ARG_POINTER_REGNUM));\n+}\n+\n+/* Returns a canonical version of X for the address, from the point of view,\n+   that all multiplications are represented as MULT instead of the multiply\n+   by a power of 2 being represented as ASHIFT.\n+\n+   Every ASHIFT we find has been made by simplify_gen_binary and was not\n+   there before, so it is not shared.  So we can do this in place.  */\n+\n+static void\n+canonicalize_address (rtx x)\n+{\n+  for (;;)\n+    switch (GET_CODE (x))\n+      {\n+      case ASHIFT:\n+        if (GET_CODE (XEXP (x, 1)) == CONST_INT\n+            && INTVAL (XEXP (x, 1)) < GET_MODE_BITSIZE (GET_MODE (x))\n+            && INTVAL (XEXP (x, 1)) >= 0)\n+\t  {\n+\t    HOST_WIDE_INT shift = INTVAL (XEXP (x, 1));\n+\t    PUT_CODE (x, MULT);\n+\t    XEXP (x, 1) = gen_int_mode ((HOST_WIDE_INT) 1 << shift,\n+\t\t\t\t\tGET_MODE (x));\n+\t  }\n+\n+\tx = XEXP (x, 0);\n+        break;\n+\n+      case PLUS:\n+        if (GET_CODE (XEXP (x, 0)) == PLUS\n+\t    || GET_CODE (XEXP (x, 0)) == ASHIFT\n+\t    || GET_CODE (XEXP (x, 0)) == CONST)\n+\t  canonicalize_address (XEXP (x, 0));\n+\n+\tx = XEXP (x, 1);\n+        break;\n+\n+      case CONST:\n+\tx = XEXP (x, 0);\n+        break;\n+\n+      default:\n+        return;\n+      }\n+}\n+\n+/* OLD is a memory address.  Return whether it is good to use NEW instead,\n+   for a memory access in the given MODE.  */\n+\n+static bool\n+should_replace_address (rtx old, rtx new, enum machine_mode mode)\n+{\n+  int gain;\n+\n+  if (rtx_equal_p (old, new) || !memory_address_p (mode, new))\n+    return false;\n+\n+  /* Copy propagation is always ok.  */\n+  if (REG_P (old) && REG_P (new))\n+    return true;\n+\n+  /* Prefer the new address if it is less expensive.  */\n+  gain = address_cost (old, mode) - address_cost (new, mode);\n+\n+  /* If the addresses have equivalent cost, prefer the new address\n+     if it has the highest `rtx_cost'.  That has the potential of\n+     eliminating the most insns without additional costs, and it\n+     is the same that cse.c used to do.  */\n+  if (gain == 0)\n+    gain = rtx_cost (new, SET) - rtx_cost (old, SET);\n+\n+  return (gain > 0);\n+}\n+\n+/* Replace all occurrences of OLD in *PX with NEW and try to simplify the\n+   resulting expression.  Replace *PX with a new RTL expression if an\n+   occurrence of OLD was found.\n+\n+   If CAN_APPEAR is true, we always return true; if it is false, we\n+   can return false if, for at least one occurrence OLD, we failed to\n+   collapse the result to a constant.  For example, (mult:M (reg:M A)\n+   (minus:M (reg:M B) (reg:M A))) may collapse to zero if replacing\n+   (reg:M B) with (reg:M A).\n+\n+   CAN_APPEAR is disregarded inside MEMs: in that case, we always return\n+   true if the simplification is a cheaper and valid memory address.\n+\n+   This is only a wrapper around simplify-rtx.c: do not add any pattern\n+   matching code here.  (The sole exception is the handling of LO_SUM, but\n+   that is because there is no simplify_gen_* function for LO_SUM).  */\n+\n+static bool\n+propagate_rtx_1 (rtx *px, rtx old, rtx new, bool can_appear)\n+{\n+  rtx x = *px, tem = NULL_RTX, op0, op1, op2;\n+  enum rtx_code code = GET_CODE (x);\n+  enum machine_mode mode = GET_MODE (x);\n+  enum machine_mode op_mode;\n+  bool valid_ops = true;\n+\n+  /* If X is OLD_RTX, return NEW_RTX.  Otherwise, if this is an expression,\n+     try to build a new expression from recursive substitution.  */\n+\n+  if (x == old)\n+    {\n+      *px = new;\n+      return can_appear;\n+    }\n+\n+  switch (GET_RTX_CLASS (code))\n+    {\n+    case RTX_UNARY:\n+      op0 = XEXP (x, 0);\n+      op_mode = GET_MODE (op0);\n+      valid_ops &= propagate_rtx_1 (&op0, old, new, can_appear);\n+      if (op0 == XEXP (x, 0))\n+\treturn true;\n+      tem = simplify_gen_unary (code, mode, op0, op_mode);\n+      break;\n+\n+    case RTX_BIN_ARITH:\n+    case RTX_COMM_ARITH:\n+      op0 = XEXP (x, 0);\n+      op1 = XEXP (x, 1);\n+      valid_ops &= propagate_rtx_1 (&op0, old, new, can_appear);\n+      valid_ops &= propagate_rtx_1 (&op1, old, new, can_appear);\n+      if (op0 == XEXP (x, 0) && op1 == XEXP (x, 1))\n+\treturn true;\n+      tem = simplify_gen_binary (code, mode, op0, op1);\n+      break;\n+\n+    case RTX_COMPARE:\n+    case RTX_COMM_COMPARE:\n+      op0 = XEXP (x, 0);\n+      op1 = XEXP (x, 1);\n+      op_mode = GET_MODE (op0) != VOIDmode ? GET_MODE (op0) : GET_MODE (op1);\n+      valid_ops &= propagate_rtx_1 (&op0, old, new, can_appear);\n+      valid_ops &= propagate_rtx_1 (&op1, old, new, can_appear);\n+      if (op0 == XEXP (x, 0) && op1 == XEXP (x, 1))\n+\treturn true;\n+      tem = simplify_gen_relational (code, mode, op_mode, op0, op1);\n+      break;\n+\n+    case RTX_TERNARY:\n+    case RTX_BITFIELD_OPS:\n+      op0 = XEXP (x, 0);\n+      op1 = XEXP (x, 1);\n+      op2 = XEXP (x, 2);\n+      op_mode = GET_MODE (op0);\n+      valid_ops &= propagate_rtx_1 (&op0, old, new, can_appear);\n+      valid_ops &= propagate_rtx_1 (&op1, old, new, can_appear);\n+      valid_ops &= propagate_rtx_1 (&op2, old, new, can_appear);\n+      if (op0 == XEXP (x, 0) && op1 == XEXP (x, 1) && op2 == XEXP (x, 2))\n+\treturn true;\n+      if (op_mode == VOIDmode)\n+\top_mode = GET_MODE (op0);\n+      tem = simplify_gen_ternary (code, mode, op_mode, op0, op1, op2);\n+      break;\n+\n+    case RTX_EXTRA:\n+      /* The only case we try to handle is a SUBREG.  */\n+      if (code == SUBREG)\n+\t{\n+          op0 = XEXP (x, 0);\n+\t  valid_ops &= propagate_rtx_1 (&op0, old, new, can_appear);\n+          if (op0 == XEXP (x, 0))\n+\t    return true;\n+\t  tem = simplify_gen_subreg (mode, op0, GET_MODE (SUBREG_REG (x)),\n+\t\t\t\t     SUBREG_BYTE (x));\n+\t}\n+      break;\n+\n+    case RTX_OBJ:\n+      if (code == MEM && x != new)\n+\t{\n+\t  rtx new_op0;\n+\t  op0 = XEXP (x, 0);\n+\n+\t  /* There are some addresses that we cannot work on.  */\n+\t  if (!can_simplify_addr (op0))\n+\t    return true;\n+\n+\t  op0 = new_op0 = targetm.delegitimize_address (op0);\n+\t  valid_ops &= propagate_rtx_1 (&new_op0, old, new, true);\n+\n+\t  /* Dismiss transformation that we do not want to carry on.  */\n+\t  if (!valid_ops\n+\t      || new_op0 == op0\n+\t      || GET_MODE (new_op0) != GET_MODE (op0))\n+\t    return true;\n+\n+\t  canonicalize_address (new_op0);\n+\n+\t  /* Copy propagations are always ok.  Otherwise check the costs.  */\n+\t  if (!(REG_P (old) && REG_P (new))\n+\t      && !should_replace_address (op0, new_op0, GET_MODE (x)))\n+\t    return true;\n+\n+\t  tem = replace_equiv_address_nv (x, new_op0);\n+\t}\n+\n+      else if (code == LO_SUM)\n+\t{\n+          op0 = XEXP (x, 0);\n+          op1 = XEXP (x, 1);\n+\n+\t  /* The only simplification we do attempts to remove references to op0\n+\t     or make it constant -- in both cases, op0's invalidity will not\n+\t     make the result invalid.  */\n+\t  propagate_rtx_1 (&op0, old, new, true);\n+\t  valid_ops &= propagate_rtx_1 (&op1, old, new, can_appear);\n+          if (op0 == XEXP (x, 0) && op1 == XEXP (x, 1))\n+\t    return true;\n+\n+\t  /* (lo_sum (high x) x) -> x  */\n+\t  if (GET_CODE (op0) == HIGH && rtx_equal_p (XEXP (op0, 0), op1))\n+\t    tem = op1;\n+\t  else\n+\t    tem = gen_rtx_LO_SUM (mode, op0, op1);\n+\n+\t  /* OP1 is likely not a legitimate address, otherwise there would have\n+\t     been no LO_SUM.  We want it to disappear if it is invalid, return\n+\t     false in that case.  */\n+\t  return memory_address_p (mode, tem);\n+\t}\n+\n+      else if (code == REG)\n+\t{\n+\t  if (rtx_equal_p (x, old))\n+\t    {\n+              *px = new;\n+              return can_appear;\n+\t    }\n+\t}\n+      break;\n+\n+    default:\n+      break;\n+    }\n+\n+  /* No change, no trouble.  */\n+  if (tem == NULL_RTX)\n+    return true;\n+\n+  *px = tem;\n+\n+  /* The replacement we made so far is valid, if all of the recursive\n+     replacements were valid, or we could simplify everything to\n+     a constant.  */\n+  return valid_ops || can_appear || CONSTANT_P (tem);\n+}\n+\n+/* Replace all occurrences of OLD in X with NEW and try to simplify the\n+   resulting expression (in mode MODE).  Return a new expresion if it is\n+   a constant, otherwise X.\n+\n+   Simplifications where occurrences of NEW collapse to a constant are always\n+   accepted.  All simplifications are accepted if NEW is a pseudo too.\n+   Otherwise, we accept simplifications that have a lower or equal cost.  */\n+\n+static rtx\n+propagate_rtx (rtx x, enum machine_mode mode, rtx old, rtx new)\n+{\n+  rtx tem;\n+  bool collapsed;\n+\n+  if (REG_P (new) && REGNO (new) < FIRST_PSEUDO_REGISTER)\n+    return NULL_RTX;\n+\n+  new = copy_rtx (new);\n+\n+  tem = x;\n+  collapsed = propagate_rtx_1 (&tem, old, new, REG_P (new) || CONSTANT_P (new));\n+  if (tem == x || !collapsed)\n+    return NULL_RTX;\n+\n+  /* gen_lowpart_common will not be able to process VOIDmode entities other\n+     than CONST_INTs.  */\n+  if (GET_MODE (tem) == VOIDmode && GET_CODE (tem) != CONST_INT)\n+    return NULL_RTX;\n+\n+  if (GET_MODE (tem) == VOIDmode)\n+    tem = rtl_hooks.gen_lowpart_no_emit (mode, tem);\n+  else\n+    gcc_assert (GET_MODE (tem) == mode);\n+\n+  return tem;\n+}\n+\n+\n+\f\n+\n+/* Return true if the register from reference REF is killed\n+   between FROM to (but not including) TO.  */\n+\n+static bool \n+local_ref_killed_between_p (struct df_ref * ref, rtx from, rtx to)\n+{\n+  rtx insn;\n+  struct df_ref *def;\n+\n+  for (insn = from; insn != to; insn = NEXT_INSN (insn))\n+    {\n+      if (!INSN_P (insn))\n+\tcontinue;\n+\n+      def = DF_INSN_DEFS (df, insn);\n+      while (def)\n+\t{\n+\t  if (DF_REF_REGNO (ref) == DF_REF_REGNO (def))\n+\t    return true;\n+\t  def = def->next_ref;\n+\t}\n+    }\n+  return false;\n+}\n+\n+\n+/* Check if the given DEF is available in INSN.  This would require full\n+   computation of available expressions; we check only restricted conditions:\n+   - if DEF is the sole definition of its register, go ahead;\n+   - in the same basic block, we check for no definitions killing the\n+     definition of DEF_INSN;\n+   - if USE's basic block has DEF's basic block as the sole predecessor,\n+     we check if the definition is killed after DEF_INSN or before\n+     TARGET_INSN insn, in their respective basic blocks.  */\n+static bool\n+use_killed_between (struct df_ref *use, rtx def_insn, rtx target_insn)\n+{\n+  basic_block def_bb, target_bb;\n+  int regno;\n+  struct df_ref * def;\n+\n+  /* Check if the reg in USE has only one definition.  We already\n+     know that this definition reaches use, or we wouldn't be here.  */\n+  regno = DF_REF_REGNO (use);\n+  def = DF_REG_DEF_GET (df, regno)->reg_chain;\n+  if (def && (def->next_reg == NULL))\n+    return false;\n+\n+  /* Check if we are in the same basic block.  */\n+  def_bb = BLOCK_FOR_INSN (def_insn);\n+  target_bb = BLOCK_FOR_INSN (target_insn);\n+  if (def_bb == target_bb)\n+    {\n+      /* In some obscure situations we can have a def reaching a use\n+\t that is _before_ the def.  In other words the def does not\n+\t dominate the use even though the use and def are in the same\n+\t basic block.  This can happen when a register may be used\n+\t uninitialized in a loop.  In such cases, we must assume that\n+\t DEF is not available.  */\n+      if (DF_INSN_LUID (df, def_insn) >= DF_INSN_LUID (df, target_insn))\n+\treturn true;\n+\n+      return local_ref_killed_between_p (use, def_insn, target_insn);\n+    }\n+\n+  /* Finally, if DEF_BB is the sole predecessor of TARGET_BB.  */\n+  if (single_pred_p (target_bb)\n+      && single_pred (target_bb) == def_bb)\n+    {\n+      struct df_ref *x;\n+\n+      /* See if USE is killed between DEF_INSN and the last insn in the\n+\t basic block containing DEF_INSN.  */\n+      x = df_bb_regno_last_def_find (df, def_bb, regno);\n+      if (x && DF_INSN_LUID (df, x->insn) >= DF_INSN_LUID (df, def_insn))\n+\treturn true;\n+\n+      /* See if USE is killed between TARGET_INSN and the first insn in the\n+\t basic block containing TARGET_INSN.  */\n+      x = df_bb_regno_first_def_find (df, target_bb, regno);\n+      if (x && DF_INSN_LUID (df, x->insn) < DF_INSN_LUID (df, target_insn))\n+\treturn true;\n+\n+      return false;\n+    }\n+\n+  /* Otherwise assume the worst case.  */\n+  return true;\n+}\n+\n+\n+/* for_each_rtx traversal function that returns 1 if BODY points to\n+   a non-constant mem.  */\n+\n+static int\n+varying_mem_p (rtx *body, void *data ATTRIBUTE_UNUSED)\n+{\n+  rtx x = *body;\n+  return MEM_P (x) && !MEM_READONLY_P (x);\n+}\n+            \n+/* Check if all uses in DEF_INSN can be used in TARGET_INSN.  This\n+   would require full computation of available expressions;\n+   we check only restricted conditions, see use_killed_between.  */\n+static bool\n+all_uses_available_at (rtx def_insn, rtx target_insn)\n+{\n+  struct df_ref * use;\n+  rtx def_set = single_set (def_insn);\n+\n+  gcc_assert (def_set);\n+\n+  /* If target_insn comes right after def_insn, which is very common\n+     for addresses, we can use a quicker test.  */\n+  if (NEXT_INSN (def_insn) == target_insn\n+      && REG_P (SET_DEST (def_set)))\n+    {\n+      rtx def_reg = SET_DEST (def_set);\n+\n+      /* If the insn uses the reg that it defines, the substitution is\n+         invalid.  */\n+      for (use = DF_INSN_USES (df, def_insn); use; use = use->next_ref)\n+        if (rtx_equal_p (use->reg, def_reg))\n+          return false;\n+    }\n+  else\n+    {\n+      /* Look at all the uses of DEF_INSN, and see if they are not\n+\t killed between DEF_INSN and TARGET_INSN.  */\n+      for (use = DF_INSN_USES (df, def_insn); use; use = use->next_ref)\n+\tif (use_killed_between (use, def_insn, target_insn))\n+\t  return false;\n+    }\n+\n+  /* We don't do any analysis of memories or aliasing.  Reject any\n+     instruction that involves references to non-constant memory.  */\n+  return !for_each_rtx (&SET_SRC (def_set), varying_mem_p, NULL);\n+}\n+\n+\f\n+struct find_occurrence_data\n+{\n+  rtx find;\n+  rtx *retval;\n+};\n+\n+/* Callback for for_each_rtx, used in find_occurrence.\n+   See if PX is the rtx we have to find.  Return 1 to stop for_each_rtx\n+   if successful, or 0 to continue traversing otherwise.  */\n+\n+static int\n+find_occurrence_callback (rtx *px, void *data)\n+{\n+  struct find_occurrence_data *fod = (struct find_occurrence_data *) data;\n+  rtx x = *px;\n+  rtx find = fod->find;\n+\n+  if (x == find)\n+    {\n+      fod->retval = px;\n+      return 1;\n+    }\n+\n+  return 0;\n+}\n+\n+/* Return a pointer to one of the occurrences of register FIND in *PX.  */\n+\n+static rtx *\n+find_occurrence (rtx *px, rtx find)\n+{\n+  struct find_occurrence_data data;\n+\n+  gcc_assert (REG_P (find)\n+\t      || (GET_CODE (find) == SUBREG\n+\t\t  && REG_P (SUBREG_REG (find))));\n+\n+  data.find = find;\n+  data.retval = NULL;\n+  for_each_rtx (px, find_occurrence_callback, &data);\n+  return data.retval;\n+}\n+\n+\f\n+/* Inside INSN, the expression rooted at *LOC has been changed, moving some\n+   uses from ORIG_USES.  Find those that are present, and create new items\n+   in the data flow object of the pass.  Mark any new uses as having the\n+   given TYPE.  */\n+static void\n+update_df (rtx insn, rtx *loc, struct df_ref *orig_uses, enum df_ref_type type,\n+\t   int new_flags)\n+{\n+  struct df_ref *use;\n+\n+  /* Add a use for the registers that were propagated.  */\n+  for (use = orig_uses; use; use = use->next_ref)\n+    {\n+      struct df_ref *orig_use = use, *new_use;\n+      rtx *new_loc = find_occurrence (loc, DF_REF_REG (orig_use));\n+\n+      if (!new_loc)\n+\tcontinue;\n+\n+      /* Add a new insn use.  Use the original type, because it says if the\n+         use was within a MEM.  */\n+      new_use = df_ref_create (df, DF_REF_REG (orig_use), new_loc,\n+\t\t\t       insn, BLOCK_FOR_INSN (insn),\n+\t\t\t       type, DF_REF_FLAGS (orig_use) | new_flags);\n+\n+      /* Set up the use-def chain.  */\n+      df_chain_copy (df->problems_by_index[DF_CHAIN], \n+\t\t     new_use, DF_REF_CHAIN (orig_use));\n+    }\n+}\n+\n+\n+/* Try substituting NEW into LOC, which originated from forward propagation\n+   of USE's value from DEF_INSN.  SET_REG_EQUAL says whether we are\n+   substituting the whole SET_SRC, so we can set a REG_EQUAL note if the\n+   new insn is not recognized.  Return whether the substitution was\n+   performed.  */\n+\n+static bool\n+try_fwprop_subst (struct df_ref *use, rtx *loc, rtx new, rtx def_insn, bool set_reg_equal)\n+{\n+  rtx insn = DF_REF_INSN (use);\n+  enum df_ref_type type = DF_REF_TYPE (use);\n+  int flags = DF_REF_FLAGS (use);\n+\n+  if (dump_file)\n+    {\n+      fprintf (dump_file, \"\\nIn insn %d, replacing\\n \", INSN_UID (insn));\n+      print_inline_rtx (dump_file, *loc, 2);\n+      fprintf (dump_file, \"\\n with \");\n+      print_inline_rtx (dump_file, new, 2);\n+      fprintf (dump_file, \"\\n\");\n+    }\n+\n+  if (validate_change (insn, loc, new, false))\n+    {\n+      num_changes++;\n+      if (dump_file)\n+\tfprintf (dump_file, \"Changed insn %d\\n\", INSN_UID (insn));\n+\n+      /* Unlink the use that we changed.  */\n+      df_ref_remove (df, use);\n+      if (!CONSTANT_P (new))\n+\tupdate_df (insn, loc, DF_INSN_USES (df, def_insn), type, flags);\n+\n+      return true;\n+    }\n+  else\n+    {\n+      if (dump_file)\n+\tfprintf (dump_file, \"Changes to insn %d not recognized\\n\",\n+\t\t INSN_UID (insn));\n+\n+      /* Can also record a simplified value in a REG_EQUAL note, making a\n+\t new one if one does not already exist.  */\n+      if (set_reg_equal)\n+\t{\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \" Setting REG_EQUAL note\\n\");\n+\n+\t  REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_EQUAL, copy_rtx (new),\n+\t\t\t\t\t\tREG_NOTES (insn));\n+\n+          if (!CONSTANT_P (new))\n+\t    update_df (insn, loc, DF_INSN_USES (df, def_insn),\n+\t\t       type, DF_REF_IN_NOTE);\n+\t}\n+\n+      return false;\n+    }\n+}\n+\n+\n+/* If USE is a paradoxical subreg, see if it can be replaced by a pseudo.  */\n+\n+static bool\n+forward_propagate_subreg (struct df_ref *use, rtx def_insn, rtx def_set)\n+{\n+  rtx use_reg = DF_REF_REG (use);\n+  rtx use_insn, src;\n+\n+  /* Only consider paradoxical subregs... */\n+  enum machine_mode use_mode = GET_MODE (use_reg);\n+  if (GET_CODE (use_reg) != SUBREG\n+      || !REG_P (SET_DEST (def_set))\n+      || GET_MODE_SIZE (use_mode)\n+\t <= GET_MODE_SIZE (GET_MODE (SUBREG_REG (use_reg))))\n+    return false;\n+\n+  /* If this is a paradoxical SUBREG, we have no idea what value the\n+     extra bits would have.  However, if the operand is equivalent to\n+     a SUBREG whose operand is the same as our mode, and all the modes\n+     are within a word, we can just use the inner operand because\n+     these SUBREGs just say how to treat the register.  */\n+  use_insn = DF_REF_INSN (use);\n+  src = SET_SRC (def_set);\n+  if (GET_CODE (src) == SUBREG\n+      && REG_P (SUBREG_REG (src))\n+      && GET_MODE (SUBREG_REG (src)) == use_mode\n+      && subreg_lowpart_p (src)\n+      && all_uses_available_at (def_insn, use_insn))\n+    return try_fwprop_subst (use, DF_REF_LOC (use), SUBREG_REG (src),\n+\t\t\t     def_insn, false);\n+  else\n+    return false;\n+}\n+\n+/* Try to replace USE with SRC (defined in DEF_INSN) and simplify the\n+   result.  */\n+\n+static bool\n+forward_propagate_and_simplify (struct df_ref *use, rtx def_insn, rtx def_set)\n+{\n+  rtx use_insn = DF_REF_INSN (use);\n+  rtx use_set = single_set (use_insn);\n+  rtx src, reg, new, *loc;\n+  bool set_reg_equal;\n+  enum machine_mode mode;\n+\n+  if (!use_set)\n+    return false;\n+\n+  /* Do not propagate into PC, CC0, etc.  */\n+  if (GET_MODE (SET_DEST (use_set)) == VOIDmode)\n+    return false;\n+\n+  /* If def and use are subreg, check if they match.  */\n+  reg = DF_REF_REG (use);\n+  if (GET_CODE (reg) == SUBREG\n+      && GET_CODE (SET_DEST (def_set)) == SUBREG\n+      && (SUBREG_BYTE (SET_DEST (def_set)) != SUBREG_BYTE (reg)\n+\t  || GET_MODE (SET_DEST (def_set)) != GET_MODE (reg)))\n+    return false;\n+\n+  /* Check if the def had a subreg, but the use has the whole reg.  */\n+  if (REG_P (reg) && GET_CODE (SET_DEST (def_set)) == SUBREG)\n+    return false;\n+\n+  /* Check if the use has a subreg, but the def had the whole reg.  Unlike the\n+     previous case, the optimization is possible and often useful indeed.  */\n+  if (GET_CODE (reg) == SUBREG && REG_P (SET_DEST (def_set)))\n+    reg = SUBREG_REG (reg);\n+\n+  /* Check if the substitution is valid (last, because it's the most\n+     expensive check!).  */\n+  src = SET_SRC (def_set);\n+  if (!CONSTANT_P (src) && !all_uses_available_at (def_insn, use_insn))\n+    return false;\n+\n+  /* Check if the def is loading something from the constant pool; in this\n+     case we would undo optimization such as compress_float_constant.\n+     Still, we can set a REG_EQUAL note.  */\n+  if (MEM_P (src) && MEM_READONLY_P (src))\n+    {\n+      rtx x = avoid_constant_pool_reference (src);\n+      if (x != src)\n+\t{\n+          rtx note = find_reg_note (use_insn, REG_EQUAL, NULL_RTX);\n+\t  rtx old = note ? XEXP (note, 0) : SET_SRC (use_set);\n+\t  rtx new = simplify_replace_rtx (old, src, x);\n+\t  if (old != new)\t\n+            set_unique_reg_note (use_insn, REG_EQUAL, copy_rtx (new));\n+\t}\n+      return false;\n+    }\n+\n+  /* Else try simplifying.  */\n+\n+  if (DF_REF_TYPE (use) == DF_REF_REG_MEM_STORE)\n+    {\n+      loc = &SET_DEST (use_set);\n+      set_reg_equal = false;\n+    }\n+  else\n+    {\n+      rtx note = find_reg_note (use_insn, REG_EQUAL, NULL_RTX);\n+      if (DF_REF_FLAGS (use) & DF_REF_IN_NOTE)\n+\tloc = &XEXP (note, 0);\n+      else\n+\tloc = &SET_SRC (use_set);\n+\t  \n+      /* Do not replace an existing REG_EQUAL note if the insn is not\n+\t recognized.  Either we're already replacing in the note, or\n+\t we'll separately try plugging the definition in the note and\n+\t simplifying.  */\n+      set_reg_equal = (note == NULL_RTX);\n+    }\n+\n+  if (GET_MODE (*loc) == VOIDmode)\n+    mode = GET_MODE (SET_DEST (use_set));\n+  else\n+    mode = GET_MODE (*loc);\n+\n+  new = propagate_rtx (*loc, mode, reg, src);\n+  \n+  if (!new)\n+    return false;\n+\n+  return try_fwprop_subst (use, loc, new, def_insn, set_reg_equal);\n+}\n+\n+\n+/* Given a use USE of an insn, if it has a single reaching\n+   definition, try to forward propagate it into that insn.  */\n+\n+static void\n+forward_propagate_into (struct df_ref *use)\n+{\n+  struct df_link *defs;\n+  struct df_ref *def;\n+  rtx def_insn, def_set, use_insn;\n+  rtx parent;  \n+\n+  if (DF_REF_FLAGS (use) & DF_REF_READ_WRITE)\n+    return;\n+\n+  /* Only consider uses that have a single definition.  */\n+  defs = DF_REF_CHAIN (use);\n+  if (!defs || defs->next)\n+    return;\n+\n+  def = defs->ref;\n+  if (DF_REF_FLAGS (def) & DF_REF_READ_WRITE)\n+    return;\n+\n+  /* Do not propagate loop invariant definitions inside the loop if\n+     we are going to unroll.  */\n+  if (loops.num > 0\n+      && DF_REF_BB (def)->loop_father != DF_REF_BB (use)->loop_father)\n+    return;\n+\n+  /* Check if the use is still present in the insn!  */\n+  use_insn = DF_REF_INSN (use);\n+  if (DF_REF_FLAGS (use) & DF_REF_IN_NOTE)\n+    parent = find_reg_note (use_insn, REG_EQUAL, NULL_RTX);\n+  else\n+    parent = PATTERN (use_insn);\n+\n+  if (!loc_mentioned_in_p (DF_REF_LOC (use), parent))\n+    return;\n+\n+  def_insn = DF_REF_INSN (def);\n+  def_set = single_set (def_insn);\n+  if (!def_set)\n+    return;\n+\n+  /* Only try one kind of propagation.  If two are possible, we'll\n+     do it on the following iterations.  */\n+  if (!forward_propagate_and_simplify (use, def_insn, def_set))\n+    forward_propagate_subreg (use, def_insn, def_set);\n+}\n+\n+\f\n+static void\n+fwprop_init (void)\n+{\n+  num_changes = 0;\n+\n+  /* We do not always want to propagate into loops, so we have to find\n+     loops and be careful about them.  But we have to call flow_loops_find\n+     before df_analyze, because flow_loops_find may introduce new jump\n+     insns (sadly) if we are not working in cfglayout mode.  */\n+  if (flag_rerun_cse_after_loop && (flag_unroll_loops || flag_peel_loops))\n+    {\n+      calculate_dominance_info (CDI_DOMINATORS);\n+      flow_loops_find (&loops);\n+    }\n+\n+  /* Now set up the dataflow problem (we only want use-def chains) and\n+     put the dataflow solver to work.  */\n+  df = df_init (DF_SUBREGS | DF_EQUIV_NOTES);\n+  df_chain_add_problem (df, DF_UD_CHAIN);\n+  df_analyze (df);\n+  df_dump (df, dump_file);\n+}\n+\n+static void\n+fwprop_done (void)\n+{\n+  df_finish (df);\n+\n+  if (flag_rerun_cse_after_loop && (flag_unroll_loops || flag_peel_loops))\n+    {\n+      flow_loops_free (&loops);\n+      free_dominance_info (CDI_DOMINATORS);\n+      loops.num = 0;\n+    }\n+\n+  cleanup_cfg (0);\n+  delete_trivially_dead_insns (get_insns (), max_reg_num ());\n+\n+  if (dump_file)\n+    fprintf (dump_file,\n+\t     \"\\nNumber of successful forward propagations: %d\\n\\n\",\n+\t     num_changes);\n+}\n+\n+\n+\n+/* Main entry point.  */\n+\n+static bool\n+gate_fwprop (void)\n+{\n+  return optimize > 0 && flag_forward_propagate;\n+}\n+\n+static unsigned int\n+fwprop (void)\n+{\n+  unsigned i;\n+\n+  fwprop_init ();\n+\n+  /* Go through all the uses.  update_df will create new ones at the\n+     end, and we'll go through them as well.\n+\n+     Do not forward propagate addresses into loops until after unrolling.\n+     CSE did so because it was able to fix its own mess, but we are not.  */\n+\n+  df_reorganize_refs (&df->use_info);\n+  for (i = 0; i < DF_USES_SIZE (df); i++)\n+    {\n+      struct df_ref *use = DF_USES_GET (df, i);\n+      if (use)\n+\tif (loops.num == 0\n+\t    || DF_REF_TYPE (use) == DF_REF_REG_USE\n+\t    || DF_REF_BB (use)->loop_father == NULL)\n+\t  forward_propagate_into (use);\n+    }\n+\n+  fwprop_done ();\n+\n+  return 0;\n+}\n+\n+struct tree_opt_pass pass_rtl_fwprop =\n+{\n+  \"fwprop1\",                            /* name */\n+  gate_fwprop,\t\t\t\t/* gate */   \n+  fwprop,\t\t\t\t/* execute */       \n+  NULL,                                 /* sub */\n+  NULL,                                 /* next */\n+  0,                                    /* static_pass_number */\n+  TV_FWPROP,                            /* tv_id */\n+  0,                                    /* properties_required */\n+  0,                                    /* properties_provided */\n+  0,                                    /* properties_destroyed */\n+  0,                                    /* todo_flags_start */\n+  TODO_dump_func,                       /* todo_flags_finish */\n+  0                                     /* letter */\n+};\n+\n+static bool\n+gate_fwprop_addr (void)\n+{\n+  return optimize > 0 && flag_forward_propagate && flag_rerun_cse_after_loop\n+  \t && (flag_unroll_loops || flag_peel_loops);\n+}\n+\n+static unsigned int\n+fwprop_addr (void)\n+{\n+  unsigned i;\n+  fwprop_init ();\n+\n+  /* Go through all the uses.  update_df will create new ones at the\n+     end, and we'll go through them as well.  */\n+  df_reorganize_refs (&df->use_info);\n+  for (i = 0; i < DF_USES_SIZE (df); i++)\n+    {\n+      struct df_ref *use = DF_USES_GET (df, i);\n+      if (use)\n+\tif (DF_REF_TYPE (use) != DF_REF_REG_USE\n+\t    && DF_REF_BB (use)->loop_father != NULL)\n+\t  forward_propagate_into (use);\n+    }\n+\n+  fwprop_done ();\n+\n+  return 0;\n+}\n+\n+struct tree_opt_pass pass_rtl_fwprop_addr =\n+{\n+  \"fwprop2\",                            /* name */\n+  gate_fwprop_addr,\t\t\t/* gate */   \n+  fwprop_addr,\t\t\t\t/* execute */       \n+  NULL,                                 /* sub */\n+  NULL,                                 /* next */\n+  0,                                    /* static_pass_number */\n+  TV_FWPROP,                            /* tv_id */\n+  0,                                    /* properties_required */\n+  0,                                    /* properties_provided */\n+  0,                                    /* properties_destroyed */\n+  0,                                    /* todo_flags_start */\n+  TODO_dump_func,                       /* todo_flags_finish */\n+  0                                     /* letter */\n+};"}, {"sha": "f1214952b24be09fdbba612a90b720bea3980949", "filename": "gcc/gcse.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fgcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fgcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgcse.c?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -3396,7 +3396,8 @@ one_cprop_pass (int pass, bool cprop_jumps, bool bypass_jumps)\n   global_const_prop_count = local_const_prop_count = 0;\n   global_copy_prop_count = local_copy_prop_count = 0;\n \n-  local_cprop_pass (cprop_jumps);\n+  if (cprop_jumps)\n+    local_cprop_pass (cprop_jumps);\n \n   /* Determine implicit sets.  */\n   implicit_sets = XCNEWVEC (rtx, last_basic_block);"}, {"sha": "da16f7bf341f46c395305acd144c61ba39be7720", "filename": "gcc/opts.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fopts.c?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -474,6 +474,7 @@ decode_options (unsigned int argc, const char **argv)\n       flag_thread_jumps = 1;\n       flag_crossjumping = 1;\n       flag_optimize_sibling_calls = 1;\n+      flag_forward_propagate = 1;\n       flag_cse_follow_jumps = 1;\n       flag_gcse = 1;\n       flag_expensive_optimizations = 1;"}, {"sha": "9d585d3bf6a4bcea61618730ff57f4d2bc07d528", "filename": "gcc/passes.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fpasses.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Fpasses.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.c?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -635,6 +635,7 @@ init_optimization_passes (void)\n   NEXT_PASS (pass_instantiate_virtual_regs);\n   NEXT_PASS (pass_jump2);\n   NEXT_PASS (pass_cse);\n+  NEXT_PASS (pass_rtl_fwprop);\n   NEXT_PASS (pass_gcse);\n   NEXT_PASS (pass_jump_bypass);\n   NEXT_PASS (pass_rtl_ifcvt);\n@@ -645,6 +646,7 @@ init_optimization_passes (void)\n   NEXT_PASS (pass_loop2);\n   NEXT_PASS (pass_web);\n   NEXT_PASS (pass_cse2);\n+  NEXT_PASS (pass_rtl_fwprop_addr);\n   NEXT_PASS (pass_life);\n   NEXT_PASS (pass_combine);\n   NEXT_PASS (pass_if_after_combine);"}, {"sha": "18ad72f2d4e61233d1de835d8a7d2a90d2b3ffb4", "filename": "gcc/recog.c", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Frecog.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Frecog.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frecog.c?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -238,6 +238,28 @@ validate_change (rtx object, rtx *loc, rtx new, int in_group)\n     return apply_change_group ();\n }\n \n+/* Keep X canonicalized if some changes have made it non-canonical; only\n+   modifies the operands of X, not (for example) its code.  Simplifications\n+   are not the job of this routine.\n+\n+   Return true if anything was changed.  */\n+bool\n+canonicalize_change_group (rtx insn, rtx x)\n+{\n+  if (COMMUTATIVE_P (x)\n+      && swap_commutative_operands_p (XEXP (x, 0), XEXP (x, 1)))\n+    {\n+      /* Oops, the caller has made X no longer canonical.\n+\t Let's redo the changes in the correct order.  */\n+      rtx tem = XEXP (x, 0);\n+      validate_change (insn, &XEXP (x, 0), XEXP (x, 1), 1);\n+      validate_change (insn, &XEXP (x, 1), tem, 1);\n+      return true;\n+    }\n+  else\n+    return false;\n+}\n+  \n \n /* This subroutine of apply_change_group verifies whether the changes to INSN\n    were valid; i.e. whether INSN can still be recognized.  */"}, {"sha": "b921b8074dc481da0d7b663e45503fd2e75af462", "filename": "gcc/recog.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Frecog.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Frecog.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frecog.h?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -74,6 +74,7 @@ extern void init_recog_no_volatile (void);\n extern int check_asm_operands (rtx);\n extern int asm_operand_ok (rtx, const char *);\n extern int validate_change (rtx, rtx *, rtx, int);\n+extern bool canonicalize_change_group (rtx insn, rtx x);\n extern int insn_invalid_p (rtx);\n extern int verify_changes (int);\n extern void confirm_change_group (void);"}, {"sha": "8a7c914022c6ddc3a2c20ccfd174875ca4c5ed31", "filename": "gcc/rtlanal.c", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Frtlanal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Frtlanal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlanal.c?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -2837,10 +2837,15 @@ auto_inc_p (rtx x)\n int\n loc_mentioned_in_p (rtx *loc, rtx in)\n {\n-  enum rtx_code code = GET_CODE (in);\n-  const char *fmt = GET_RTX_FORMAT (code);\n+  enum rtx_code code;\n+  const char *fmt;\n   int i, j;\n \n+  if (!in)\n+    return 0;\n+\n+  code = GET_CODE (in);\n+  fmt = GET_RTX_FORMAT (code);\n   for (i = GET_RTX_LENGTH (code) - 1; i >= 0; i--)\n     {\n       if (loc == &in->u.fld[i].rt_rtx)"}, {"sha": "bdfe9ae201cae42a991d3fdbeb69b48147732734", "filename": "gcc/timevar.def", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Ftimevar.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Ftimevar.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftimevar.def?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -128,6 +128,7 @@ DEFTIMEVAR (TV_TEMPLATE_INSTANTIATION, \"template instantiation\")\n DEFTIMEVAR (TV_EXPAND\t\t     , \"expand\")\n DEFTIMEVAR (TV_VARCONST              , \"varconst\")\n DEFTIMEVAR (TV_JUMP                  , \"jump\")\n+DEFTIMEVAR (TV_FWPROP                , \"forward prop\")\n DEFTIMEVAR (TV_CSE                   , \"CSE\")\n DEFTIMEVAR (TV_LOOP                  , \"loop analysis\")\n DEFTIMEVAR (TV_GCSE                  , \"global CSE\")"}, {"sha": "3ab0ef730b713696bc01e8066b0c2d31f733992d", "filename": "gcc/tree-pass.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Ftree-pass.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a52b023a5f0316a63cd52c45cd4cfd11794d40ca/gcc%2Ftree-pass.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pass.h?ref=a52b023a5f0316a63cd52c45cd4cfd11794d40ca", "patch": "@@ -330,6 +330,8 @@ extern struct tree_opt_pass pass_rtl_eh;\n extern struct tree_opt_pass pass_initial_value_sets;\n extern struct tree_opt_pass pass_unshare_all_rtl;\n extern struct tree_opt_pass pass_instantiate_virtual_regs;\n+extern struct tree_opt_pass pass_rtl_fwprop;\n+extern struct tree_opt_pass pass_rtl_fwprop_addr;\n extern struct tree_opt_pass pass_jump2;\n extern struct tree_opt_pass pass_cse;\n extern struct tree_opt_pass pass_gcse;"}]}