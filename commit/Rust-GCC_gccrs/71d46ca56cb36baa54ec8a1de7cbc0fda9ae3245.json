{"sha": "71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzFkNDZjYTU2Y2IzNmJhYTU0ZWM4YTFkZTdjYmMwZmRhOWFlMzI0NQ==", "commit": {"author": {"name": "Michael Meissner", "email": "michael.meissner@amd.com", "date": "2008-05-14T20:07:53Z"}, "committer": {"name": "Michael Meissner", "email": "meissner@gcc.gnu.org", "date": "2008-05-14T20:07:53Z"}, "message": "Add SSE5 vector shift/rotate; Update SSE5 vector multiply\n\nCo-Authored-By: Dwarakanath Rajagopal <dwarak.rajagopal@amd.com>\nCo-Authored-By: Paolo Bonzini <bonzini@gnu.org>\n\nFrom-SVN: r135304", "tree": {"sha": "b9a9ff4a7540533104609eb87beb98cc4f84d114", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b9a9ff4a7540533104609eb87beb98cc4f84d114"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "html_url": "https://github.com/Rust-GCC/gccrs/commit/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/comments", "author": null, "committer": null, "parents": [{"sha": "550c9cf0fe26d6da75cfaeea41a766fe69ddee4e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/550c9cf0fe26d6da75cfaeea41a766fe69ddee4e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/550c9cf0fe26d6da75cfaeea41a766fe69ddee4e"}], "stats": {"total": 1756, "additions": 1449, "deletions": 307}, "files": [{"sha": "cfc8b09d5e453ddc069ec3e6a81364b21258019e", "filename": "gcc/ChangeLog", "status": "modified", "additions": 151, "deletions": 0, "changes": 151, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -1,3 +1,154 @@\n+2008-05-14  Michael Meissner  <michael.meissner@amd.com>\n+\t    Dwarakanath Rajagopal  <dwarak.rajagopal@amd.com>\n+\n+\t* optabs.h (optab_index): Add OTI_vashl, OTI_vlshr, OTI_vashr,\n+\tOTI_vrotl, OTI_vrotr to support vector/vector shifts.\n+\t(vashl_optab): New optab for vector/vector shifts.\n+\t(vashr_optab): Ditto.\n+\t(vlshr_optab): Ditto.\n+\t(vrotl_optab): Ditto.\n+\t(vrotr_optab): Ditto.\n+\t(optab_subtype): New enum for optab_for_tree_code call.\n+\t(optab_for_tree_code): Add enum optab_subtype argument.\n+\n+\t* optabs.c (optab_for_tree_code): Take an additional argument to\n+\tdistinguish between a vector shift by a scalar and vector shift by\n+\ta vector.  Make lshr/ashr/ashl/rotl/rotr optabs just vector\n+\tshifted by a scalar.  Use vlshr/vashr/vashl/vrotl/vrotr for the\n+\tvector shift by a vector.\n+\t(expand_widen_pattern_expr): Pass additional argument to\n+\toptab_for_tree_code.\n+\n+\t* genopinit.c (optabs): Add vashr_optab, vashl_optab, vlshr_optab,\n+\tvrotl_optab, vrotr_optab.\n+\n+\t* expr.c (expand_expr_real_1): Update calls to\n+\toptab_for_tree_code to distinguish between vector shifted by a\n+\tscalar and vector shifted by a vector.\n+\t* tree-vectorizer.c (supportable_widening_operation): Ditto.\n+\t(supportable_narrowing_operation): Ditto.\n+\t* tree-vect-analyze.c (vect_build_slp_tree): Ditto.\n+\t* tree-vect-patterns.c (vect_pattern_recog_1): Ditto.\n+\t* tree-vect-transform.c (vect_model_reduction_cost): Ditto.\n+\t(vect_create_epilog_for_reduction): Ditto.\n+\t(vectorizable_reduction): Ditto.\n+\t(vectorizable_operation): Ditto.\n+\t(vect_strided_store_supported): Ditto.\n+\t(vect_strided_load_supported): Ditto.\n+\t* tree-vect-generic.c (expand_vector_operations_1): Ditto.\n+\t* expmed.c (expand_shift): Ditto.\n+\n+\t* doc/md.texi (ashl@var{m}3): Document that operand 2 is always a\n+\tscalar type.\n+\t(ashr@var{m}3): Ditto.\n+\t(vashl@var{m}3): Document new vector/vector shift standard name.\n+\t(vashr@var{m}3): Ditto.\n+\t(vlshr@var{m}3): Ditto.\n+\t(vrotl@var{m}3): Ditto.\n+\t(vrotr@var{m}3): Ditto.\n+\n+\t* config/i386/i386.md (PPERM_SRC): Move PPERM masks here from\n+\ti386.c.\n+\t(PPERM_INVERT): Ditto.\n+\t(PPERM_REVERSE): Ditto.\n+\t(PPERM_REV_INV): Ditto.\n+\t(PPERM_ZERO): Ditto.\n+\t(PPERM_ONES): Ditto.\n+\t(PPERM_SIGN): Ditto.\n+\t(PPERM_INV_SIGN): Ditto.\n+\t(PPERM_SRC1): Ditto.\n+\t(PPERM_SRC2): Ditto.\n+\n+\t* config/i386/sse.md (mulv2di3): Add SSE5 support.\n+\t(sse5_pmacsdql_mem): New SSE5 define_and_split that temporarily\n+\tallows a memory operand to be the value being added, and split it\n+\tto improve vectorization.\n+\t(sse5_pmacsdqh_mem): Ditto.\n+\t(sse5_mulv2div2di3_low): SSE5 32-bit multiply and extend function.\n+\t(sse5_mulv2div2di3_high): Ditto.\n+\t(vec_pack_trunc_v8hi): Add SSE5 pperm support.\n+\t(vec_pack_trunc_v4si): Ditto.\n+\t(vec_pack_trunc_v2di): Ditto.\n+\t(sse5_pcmov_<mode>): Remove code that tried to use use\n+\tandps/andnps instead of pcmov.\n+\t(vec_widen_smult_hi_v4si): If we have SSE5, use the pmacsdql and\n+\tpmacsdqh instructions.\n+\t(vec_widen_smult_lo_v4si): Ditto.\n+\n+\t* config/i386/i386.c (PPERM_SRC): Move PPERM masks to i386.md.\n+\t(PPERM_INVERT): Ditto.\n+\t(PPERM_REVERSE): Ditto.\n+\t(PPERM_REV_INV): Ditto.\n+\t(PPERM_ZERO): Ditto.\n+\t(PPERM_ONES): Ditto.\n+\t(PPERM_SIGN): Ditto.\n+\t(PPERM_INV_SIGN): Ditto.\n+\t(PPERM_SRC1): Ditto.\n+\t(PPERM_SRC2): Ditto.\n+\t(ix86_expand_sse_movcc): Move the SSE5 test after the if\n+\ttrue/false tests.\n+\t(ix86_expand_int_vcond): If SSE5 generate all possible integer\n+\tcomparisons.\n+\t(ix86_sse5_valid_op_p): Allow num_memory to be negative, which\n+\tsays ignore whether the last reference is a memory operand.\n+\n+2008-05-14  Michael Meissner  <michael.meissner@amd.com>\n+\t    Paolo Bonzini <bonzini at gnu dot org>\n+\n+\t* config/rs6000/rs6000.c (bdesc_2arg): Change the names of vector\n+\tshift patterns.\n+\n+\t* config/rs6000/altivec.md (vashl<mode>3): Rename from\n+\tashl<mode>3.\n+\t(vlshr<mode>3): Rename from vlshr<mode>3.\n+\t(vashr<mode>3): Rename from vashr<mode>3.\n+\t(mulv4sf3): Change the names of vector shift patterns.\n+\t(mulv4si3): Ditto.\n+\t(negv4sf2): Ditt.\n+\n+\t* config/spu/spu.c (spu_initialize_trampoline): Rename vector\n+\tshift insns.\n+\n+\t* config/spu/spu-builtins.def (SI_SHLH): Rename vector shift\n+\tinsns.\n+\t(SI_SHLHI): Ditto.\n+\t(SI_SHL): Ditto.\n+\t(SI_SHLI): Ditto.\n+\t(SI_ROTH): Ditto.\n+\t(SI_ROTHI): Ditto.\n+\t(SI_ROT): Ditto.\n+\t(SI_ROTI): Ditto.\n+\t(SPU_RL_0): Ditto.\n+\t(SPU_RL_1): Ditto.\n+\t(SPU_RL_2): Ditto.\n+\t(SPU_RL_3): Ditto.\n+\t(SPU_RL_4): Ditto.\n+\t(SPU_RL_5): Ditto.\n+\t(SPU_RL_6): Ditto.\n+\t(SPU_RL_7): Ditto.\n+\t(SPU_SL_0): Ditto.\n+\t(SPU_SL_1): Ditto.\n+\t(SPU_SL_2): Ditto.\n+\t(SPU_SL_3): Ditto.\n+\t(SPU_SL_4): Ditto.\n+\t(SPU_SL_5): Ditto.\n+\t(SPU_SL_6): Ditto.\n+\t(SPU_SL_7): Ditto.\n+\n+\t* config/spu/spu.md (v): New iterator macro to add v for vector types.\n+\t(floatunssidf2_internal): Change vector/vector shift names.\n+\t(floatunsdidf2_internal): Ditto.\n+\t(mulv8hi3): Ditto.\n+\t(ashrdi3): Ditto.\n+\t(ashrti3): Ditto.\n+\t(cgt_df): Ditto.\n+\t(cgt_v2df): Ditto.\n+\t(dftsv): Ditto.\n+\t(vashl<mode>3): Rename from ashl<mode>3.\n+\t(vashr<mode>3): Rename from ashr<mode>3.\n+\t(vlshr<mode>3): Rename from lshr<mode>3.\n+\t(vrotl<mode>3): Rename from rotl<mode>3.\n+\n 2008-05-14  Michael Meissner  <michael.meissner@amd.com>\n \n \tPR target/36224"}, {"sha": "d8fdc22226c73f239d7c122e5512b7108934afc6", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 128, "deletions": 122, "changes": 250, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -13306,15 +13306,7 @@ ix86_expand_sse_movcc (rtx dest, rtx cmp, rtx op_true, rtx op_false)\n   enum machine_mode mode = GET_MODE (dest);\n   rtx t2, t3, x;\n \n-  if (TARGET_SSE5)\n-    {\n-      rtx pcmov = gen_rtx_SET (mode, dest,\n-\t\t\t       gen_rtx_IF_THEN_ELSE (mode, cmp,\n-\t\t\t\t\t\t     op_true,\n-\t\t\t\t\t\t     op_false));\n-      emit_insn (pcmov);\n-    }\n-  else if (op_false == CONST0_RTX (mode))\n+  if (op_false == CONST0_RTX (mode))\n     {\n       op_true = force_reg (mode, op_true);\n       x = gen_rtx_AND (mode, cmp, op_true);\n@@ -13327,6 +13319,14 @@ ix86_expand_sse_movcc (rtx dest, rtx cmp, rtx op_true, rtx op_false)\n       x = gen_rtx_AND (mode, x, op_false);\n       emit_insn (gen_rtx_SET (VOIDmode, dest, x));\n     }\n+  else if (TARGET_SSE5)\n+    {\n+      rtx pcmov = gen_rtx_SET (mode, dest,\n+\t\t\t       gen_rtx_IF_THEN_ELSE (mode, cmp,\n+\t\t\t\t\t\t     op_true,\n+\t\t\t\t\t\t     op_false));\n+      emit_insn (pcmov);\n+    }\n   else\n     {\n       op_true = force_reg (mode, op_true);\n@@ -13472,115 +13472,119 @@ ix86_expand_int_vcond (rtx operands[])\n   cop0 = operands[4];\n   cop1 = operands[5];\n \n-  /* Canonicalize the comparison to EQ, GT, GTU.  */\n-  switch (code)\n-    {\n-    case EQ:\n-    case GT:\n-    case GTU:\n-      break;\n-\n-    case NE:\n-    case LE:\n-    case LEU:\n-      code = reverse_condition (code);\n-      negate = true;\n-      break;\n-\n-    case GE:\n-    case GEU:\n-      code = reverse_condition (code);\n-      negate = true;\n-      /* FALLTHRU */\n-\n-    case LT:\n-    case LTU:\n-      code = swap_condition (code);\n-      x = cop0, cop0 = cop1, cop1 = x;\n-      break;\n-\n-    default:\n-      gcc_unreachable ();\n-    }\n-\n-  /* Only SSE4.1/SSE4.2 supports V2DImode.  */\n-  if (mode == V2DImode)\n+  /* SSE5 supports all of the comparisons on all vector int types.  */\n+  if (!TARGET_SSE5)\n     {\n+      /* Canonicalize the comparison to EQ, GT, GTU.  */\n       switch (code)\n \t{\n \tcase EQ:\n-\t  /* SSE4.1 supports EQ.  */\n-\t  if (!TARGET_SSE4_1)\n-\t    return false;\n-\t  break;\n-\n \tcase GT:\n \tcase GTU:\n-\t  /* SSE4.2 supports GT/GTU.  */\n-\t  if (!TARGET_SSE4_2)\n-\t    return false;\n+\t  break;\n+\n+\tcase NE:\n+\tcase LE:\n+\tcase LEU:\n+\t  code = reverse_condition (code);\n+\t  negate = true;\n+\t  break;\n+\n+\tcase GE:\n+\tcase GEU:\n+\t  code = reverse_condition (code);\n+\t  negate = true;\n+\t  /* FALLTHRU */\n+\n+\tcase LT:\n+\tcase LTU:\n+\t  code = swap_condition (code);\n+\t  x = cop0, cop0 = cop1, cop1 = x;\n \t  break;\n \n \tdefault:\n \t  gcc_unreachable ();\n \t}\n-    }\n \n-  /* Unsigned parallel compare is not supported by the hardware.  Play some\n-     tricks to turn this into a signed comparison against 0.  */\n-  if (code == GTU)\n-    {\n-      cop0 = force_reg (mode, cop0);\n+      /* Only SSE4.1/SSE4.2 supports V2DImode.  */\n+      if (mode == V2DImode)\n+\t{\n+\t  switch (code)\n+\t    {\n+\t    case EQ:\n+\t      /* SSE4.1 supports EQ.  */\n+\t      if (!TARGET_SSE4_1)\n+\t\treturn false;\n+\t      break;\n \n-      switch (mode)\n+\t    case GT:\n+\t    case GTU:\n+\t      /* SSE4.2 supports GT/GTU.  */\n+\t      if (!TARGET_SSE4_2)\n+\t\treturn false;\n+\t      break;\n+\n+\t    default:\n+\t      gcc_unreachable ();\n+\t    }\n+\t}\n+\n+      /* Unsigned parallel compare is not supported by the hardware.  Play some\n+\t tricks to turn this into a signed comparison against 0.  */\n+      if (code == GTU)\n \t{\n-\tcase V4SImode:\n-\tcase V2DImode:\n-\t  {\n-\t    rtx t1, t2, mask;\n-\n-\t    /* Perform a parallel modulo subtraction.  */\n-\t    t1 = gen_reg_rtx (mode);\n-\t    emit_insn ((mode == V4SImode\n-\t\t\t? gen_subv4si3\n-\t\t\t: gen_subv2di3) (t1, cop0, cop1));\n-\n-\t    /* Extract the original sign bit of op0.  */\n-\t    mask = ix86_build_signbit_mask (GET_MODE_INNER (mode),\n-\t\t\t\t\t    true, false);\n-\t    t2 = gen_reg_rtx (mode);\n-\t    emit_insn ((mode == V4SImode\n-\t\t\t? gen_andv4si3\n-\t\t\t: gen_andv2di3) (t2, cop0, mask));\n-\n-\t    /* XOR it back into the result of the subtraction.  This results\n-\t       in the sign bit set iff we saw unsigned underflow.  */\n-\t    x = gen_reg_rtx (mode);\n-\t    emit_insn ((mode == V4SImode\n-\t\t\t? gen_xorv4si3\n-\t\t\t: gen_xorv2di3) (x, t1, t2));\n-\n-\t    code = GT;\n-\t  }\n-\t  break;\n+\t  cop0 = force_reg (mode, cop0);\n \n-\tcase V16QImode:\n-\tcase V8HImode:\n-\t  /* Perform a parallel unsigned saturating subtraction.  */\n-\t  x = gen_reg_rtx (mode);\n-\t  emit_insn (gen_rtx_SET (VOIDmode, x,\n-\t\t\t\t  gen_rtx_US_MINUS (mode, cop0, cop1)));\n+\t  switch (mode)\n+\t    {\n+\t    case V4SImode:\n+\t    case V2DImode:\n+\t      {\n+\t\trtx t1, t2, mask;\n+\n+\t\t/* Perform a parallel modulo subtraction.  */\n+\t\tt1 = gen_reg_rtx (mode);\n+\t\temit_insn ((mode == V4SImode\n+\t\t\t    ? gen_subv4si3\n+\t\t\t    : gen_subv2di3) (t1, cop0, cop1));\n+\n+\t\t/* Extract the original sign bit of op0.  */\n+\t\tmask = ix86_build_signbit_mask (GET_MODE_INNER (mode),\n+\t\t\t\t\t\ttrue, false);\n+\t\tt2 = gen_reg_rtx (mode);\n+\t\temit_insn ((mode == V4SImode\n+\t\t\t    ? gen_andv4si3\n+\t\t\t    : gen_andv2di3) (t2, cop0, mask));\n+\n+\t\t/* XOR it back into the result of the subtraction.  This results\n+\t\t   in the sign bit set iff we saw unsigned underflow.  */\n+\t\tx = gen_reg_rtx (mode);\n+\t\temit_insn ((mode == V4SImode\n+\t\t\t    ? gen_xorv4si3\n+\t\t\t    : gen_xorv2di3) (x, t1, t2));\n+\n+\t\tcode = GT;\n+\t      }\n+\t      break;\n \n-\t  code = EQ;\n-\t  negate = !negate;\n-\t  break;\n+\t    case V16QImode:\n+\t    case V8HImode:\n+\t      /* Perform a parallel unsigned saturating subtraction.  */\n+\t      x = gen_reg_rtx (mode);\n+\t      emit_insn (gen_rtx_SET (VOIDmode, x,\n+\t\t\t\t      gen_rtx_US_MINUS (mode, cop0, cop1)));\n \n-\tdefault:\n-\t  gcc_unreachable ();\n-\t}\n+\t      code = EQ;\n+\t      negate = !negate;\n+\t      break;\n+\n+\t    default:\n+\t      gcc_unreachable ();\n+\t    }\n \n-      cop0 = x;\n-      cop1 = CONST0_RTX (mode);\n+\t  cop0 = x;\n+\t  cop1 = CONST0_RTX (mode);\n+\t}\n     }\n \n   x = ix86_expand_sse_cmp (operands[0], code, cop0, cop1,\n@@ -13687,19 +13691,7 @@ ix86_expand_sse4_unpack (rtx operands[2], bool unsigned_p, bool high_p)\n }\n \n /* This function performs the same task as ix86_expand_sse_unpack,\n-   but with amdfam15 instructions.  */\n-\n-#define PPERM_SRC\t0x00\t\t/* copy source */\n-#define PPERM_INVERT\t0x20\t\t/* invert source */\n-#define PPERM_REVERSE\t0x40\t\t/* bit reverse source */\n-#define PPERM_REV_INV\t0x60\t\t/* bit reverse & invert src */\n-#define PPERM_ZERO\t0x80\t\t/* all 0's */\n-#define PPERM_ONES\t0xa0\t\t/* all 1's */\n-#define PPERM_SIGN\t0xc0\t\t/* propagate sign bit */\n-#define PPERM_INV_SIGN\t0xe0\t\t/* invert & propagate sign */\n-\n-#define PPERM_SRC1\t0x00\t\t/* use first source byte */\n-#define PPERM_SRC2\t0x10\t\t/* use second source byte */\n+   but with sse5 instructions.  */\n \n void\n ix86_expand_sse5_unpack (rtx operands[2], bool unsigned_p, bool high_p)\n@@ -18773,14 +18765,14 @@ static const struct builtin_description bdesc_multi_arg[] =\n   { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmacsdqh,          \"__builtin_ia32_pmacsdqh\",   IX86_BUILTIN_PMACSDQH,   0,            (int)MULTI_ARG_3_SI_DI },\n   { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmadcsswd,         \"__builtin_ia32_pmadcsswd\",  IX86_BUILTIN_PMADCSSWD,  0,            (int)MULTI_ARG_3_HI_SI },\n   { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_pmadcswd,          \"__builtin_ia32_pmadcswd\",   IX86_BUILTIN_PMADCSWD,   0,            (int)MULTI_ARG_3_HI_SI },\n-  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv2di3,         \"__builtin_ia32_protq\",      IX86_BUILTIN_PROTQ,      0,            (int)MULTI_ARG_2_DI },\n-  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv4si3,         \"__builtin_ia32_protd\",      IX86_BUILTIN_PROTD,      0,            (int)MULTI_ARG_2_SI },\n-  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv8hi3,         \"__builtin_ia32_protw\",      IX86_BUILTIN_PROTW,      0,            (int)MULTI_ARG_2_HI },\n-  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv16qi3,        \"__builtin_ia32_protb\",      IX86_BUILTIN_PROTB,      0,            (int)MULTI_ARG_2_QI },\n-  { OPTION_MASK_ISA_SSE5, CODE_FOR_rotlv2di3,              \"__builtin_ia32_protqi\",     IX86_BUILTIN_PROTQ_IMM,  0,            (int)MULTI_ARG_2_DI_IMM },\n-  { OPTION_MASK_ISA_SSE5, CODE_FOR_rotlv4si3,              \"__builtin_ia32_protdi\",     IX86_BUILTIN_PROTD_IMM,  0,            (int)MULTI_ARG_2_SI_IMM },\n-  { OPTION_MASK_ISA_SSE5, CODE_FOR_rotlv8hi3,              \"__builtin_ia32_protwi\",     IX86_BUILTIN_PROTW_IMM,  0,            (int)MULTI_ARG_2_HI_IMM },\n-  { OPTION_MASK_ISA_SSE5, CODE_FOR_rotlv16qi3,             \"__builtin_ia32_protbi\",     IX86_BUILTIN_PROTB_IMM,  0,            (int)MULTI_ARG_2_QI_IMM },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vrotlv2di3,        \"__builtin_ia32_protq\",      IX86_BUILTIN_PROTQ,      0,            (int)MULTI_ARG_2_DI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vrotlv4si3,        \"__builtin_ia32_protd\",      IX86_BUILTIN_PROTD,      0,            (int)MULTI_ARG_2_SI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vrotlv8hi3,        \"__builtin_ia32_protw\",      IX86_BUILTIN_PROTW,      0,            (int)MULTI_ARG_2_HI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_vrotlv16qi3,       \"__builtin_ia32_protb\",      IX86_BUILTIN_PROTB,      0,            (int)MULTI_ARG_2_QI },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv2di3,         \"__builtin_ia32_protqi\",     IX86_BUILTIN_PROTQ_IMM,  0,            (int)MULTI_ARG_2_DI_IMM },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv4si3,         \"__builtin_ia32_protdi\",     IX86_BUILTIN_PROTD_IMM,  0,            (int)MULTI_ARG_2_SI_IMM },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv8hi3,         \"__builtin_ia32_protwi\",     IX86_BUILTIN_PROTW_IMM,  0,            (int)MULTI_ARG_2_HI_IMM },\n+  { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_rotlv16qi3,        \"__builtin_ia32_protbi\",     IX86_BUILTIN_PROTB_IMM,  0,            (int)MULTI_ARG_2_QI_IMM },\n   { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_ashlv2di3,         \"__builtin_ia32_pshaq\",      IX86_BUILTIN_PSHAQ,      0,            (int)MULTI_ARG_2_DI },\n   { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_ashlv4si3,         \"__builtin_ia32_pshad\",      IX86_BUILTIN_PSHAD,      0,            (int)MULTI_ARG_2_SI },\n   { OPTION_MASK_ISA_SSE5, CODE_FOR_sse5_ashlv8hi3,         \"__builtin_ia32_pshaw\",      IX86_BUILTIN_PSHAW,      0,            (int)MULTI_ARG_2_HI },\n@@ -25331,8 +25323,10 @@ ix86_expand_round (rtx operand0, rtx operand1)\n    NUM is the number of operands.\n    USES_OC0 is true if the instruction uses OC0 and provides 4 variants.\n    NUM_MEMORY is the maximum number of memory operands to accept.  */\n+\n bool\n-ix86_sse5_valid_op_p (rtx operands[], rtx insn, int num, bool uses_oc0, int num_memory)\n+ix86_sse5_valid_op_p (rtx operands[], rtx insn ATTRIBUTE_UNUSED, int num,\n+\t\t      bool uses_oc0, int num_memory)\n {\n   int mem_mask;\n   int mem_count;\n@@ -25366,6 +25360,18 @@ ix86_sse5_valid_op_p (rtx operands[], rtx insn, int num, bool uses_oc0, int num_\n \t}\n     }\n \n+  /* Special case pmacsdq{l,h} where we allow the 3rd argument to be\n+     a memory operation.  */\n+  if (num_memory < 0)\n+    {\n+      num_memory = -num_memory;\n+      if ((mem_mask & (1 << (num-1))) != 0)\n+\t{\n+\t  mem_mask &= ~(1 << (num-1));\n+\t  mem_count--;\n+\t}\n+    }\n+\n   /* If there were no memory operations, allow the insn */\n   if (mem_mask == 0)\n     return true;"}, {"sha": "145c373ff7522846fa08942407061211ce5747dd", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 17, "deletions": 5, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -181,11 +181,9 @@\n    (UNSPEC_SSE5_UNSIGNED_CMP\t151)\n    (UNSPEC_SSE5_TRUEFALSE\t152)\n    (UNSPEC_SSE5_PERMUTE\t\t153)\n-   (UNSPEC_SSE5_ASHIFT\t\t154)\n-   (UNSPEC_SSE5_LSHIFT\t\t155)\n-   (UNSPEC_FRCZ\t\t\t156)\n-   (UNSPEC_CVTPH2PS\t\t157)\n-   (UNSPEC_CVTPS2PH\t\t158)\n+   (UNSPEC_FRCZ\t\t\t154)\n+   (UNSPEC_CVTPH2PS\t\t155)\n+   (UNSPEC_CVTPS2PH\t\t156)\n \n    ; For AES support\n    (UNSPEC_AESENC\t\t159)\n@@ -227,6 +225,20 @@\n    (COM_TRUE_P\t\t\t5)\n   ])\n \n+;; Constants used in the SSE5 pperm instruction\n+(define_constants\n+  [(PPERM_SRC\t\t\t0x00)\t/* copy source */\n+   (PPERM_INVERT\t\t0x20)\t/* invert source */\n+   (PPERM_REVERSE\t\t0x40)\t/* bit reverse source */\n+   (PPERM_REV_INV\t\t0x60)\t/* bit reverse & invert src */\n+   (PPERM_ZERO\t\t\t0x80)\t/* all 0's */\n+   (PPERM_ONES\t\t\t0xa0)\t/* all 1's */\n+   (PPERM_SIGN\t\t\t0xc0)\t/* propagate sign bit */\n+   (PPERM_INV_SIGN\t\t0xe0)\t/* invert & propagate sign */\n+   (PPERM_SRC1\t\t\t0x00)\t/* use first source byte */\n+   (PPERM_SRC2\t\t\t0x10)\t/* use second source byte */\n+   ])\n+\n ;; Registers by name.\n (define_constants\n   [(AX_REG\t\t\t 0)"}, {"sha": "6ee090a6b4ad21693859a963b716dd095ca95f09", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 549, "deletions": 26, "changes": 575, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -53,7 +53,14 @@\n (define_mode_attr sserotatemax [(V16QI \"7\") (V8HI \"15\") (V4SI \"31\") (V2DI \"63\")])\n \n ;; Mapping of vector modes back to the scalar modes\n-(define_mode_attr ssescalarmode [(V4SF \"SF\") (V2DF \"DF\")])\n+(define_mode_attr ssescalarmode [(V4SF \"SF\") (V2DF \"DF\")\n+\t\t\t\t (V16QI \"QI\") (V8HI \"HI\")\n+\t\t\t\t (V4SI \"SI\") (V2DI \"DI\")])\n+\n+;; Number of scalar elements in each vector type\n+(define_mode_attr ssescalarnum [(V4SF \"4\") (V2DF \"2\")\n+\t\t\t\t(V16QI \"16\") (V8HI \"8\")\n+\t\t\t\t(V4SI \"4\") (V2DI \"2\")])\n \n ;; Mapping of immediate bits for blend instructions\n (define_mode_attr blendbits [(V4SF \"15\") (V2DF \"3\")])\n@@ -3154,7 +3161,7 @@\n ;; We don't have a straight 32-bit parallel multiply on SSE5, so fake it with a\n ;; multiply/add.  In general, we expect the define_split to occur before\n ;; register allocation, so we have to handle the corner case where the target\n-;; is used as the base or index register in operands 1/2.\n+;; is the same as one of the inputs.\n (define_insn_and_split \"*sse5_mulv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=&x\")\n \t(mult:V4SI (match_operand:V4SI 1 \"register_operand\" \"%x\")\n@@ -3242,6 +3249,42 @@\n   rtx t1, t2, t3, t4, t5, t6, thirtytwo;\n   rtx op0, op1, op2;\n \n+  if (TARGET_SSE5)\n+    {\n+      /* op1: A,B,C,D, op2: E,F,G,H */\n+      op0 = operands[0];\n+      op1 = gen_lowpart (V4SImode, operands[1]);\n+      op2 = gen_lowpart (V4SImode, operands[2]);\n+      t1 = gen_reg_rtx (V4SImode);\n+      t2 = gen_reg_rtx (V4SImode);\n+      t3 = gen_reg_rtx (V4SImode);\n+      t4 = gen_reg_rtx (V2DImode);\n+      t5 = gen_reg_rtx (V2DImode);\n+\n+      /* t1: B,A,D,C */\n+      emit_insn (gen_sse2_pshufd_1 (t1, op1,\n+\t\t\t\t    GEN_INT (1),\n+\t\t\t\t    GEN_INT (0),\n+\t\t\t\t    GEN_INT (3),\n+\t\t\t\t    GEN_INT (2)));\n+\n+      /* t2: 0 */\n+      emit_move_insn (t2, CONST0_RTX (V4SImode));\n+\n+      /* t3: (B*E),(A*F),(D*G),(C*H) */\n+      emit_insn (gen_sse5_pmacsdd (t3, t1, op2, t2));\n+\n+      /* t4: (B*E)+(A*F), (D*G)+(C*H) */\n+      emit_insn (gen_sse5_phadddq (t4, t3));\n+\n+      /* t5: ((B*E)+(A*F))<<32, ((D*G)+(C*H))<<32 */\n+      emit_insn (gen_ashlv2di3 (t5, t4, GEN_INT (32)));\n+\n+      /* op0: (((B*E)+(A*F))<<32)+(B*F), (((D*G)+(C*H))<<32)+(D*H) */\n+      emit_insn (gen_sse5_pmacsdql (op0, op1, op2, t5));\n+      DONE;\n+    }\n+\n   op0 = operands[0];\n   op1 = operands[1];\n   op2 = operands[2];\n@@ -3357,6 +3400,57 @@\n   DONE;\n })\n \n+(define_expand \"vec_widen_smult_hi_v4si\"\n+  [(match_operand:V2DI 0 \"register_operand\" \"\")\n+   (match_operand:V4SI 1 \"register_operand\" \"\")\n+   (match_operand:V4SI 2 \"register_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtx t1, t2;\n+\n+  t1 = gen_reg_rtx (V4SImode);\n+  t2 = gen_reg_rtx (V4SImode);\n+\n+  emit_insn (gen_sse2_pshufd_1 (t1, operands[1],\n+\t\t\t\tGEN_INT (0),\n+\t\t\t\tGEN_INT (2),\n+\t\t\t\tGEN_INT (1),\n+\t\t\t\tGEN_INT (3)));\n+  emit_insn (gen_sse2_pshufd_1 (t2, operands[2],\n+\t\t\t\tGEN_INT (0),\n+\t\t\t\tGEN_INT (2),\n+\t\t\t\tGEN_INT (1),\n+\t\t\t\tGEN_INT (3)));\n+  emit_insn (gen_sse5_mulv2div2di3_high (operands[0], t1, t2));\n+  DONE;\n+})\n+\n+(define_expand \"vec_widen_smult_lo_v4si\"\n+  [(match_operand:V2DI 0 \"register_operand\" \"\")\n+   (match_operand:V4SI 1 \"register_operand\" \"\")\n+   (match_operand:V4SI 2 \"register_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtx t1, t2;\n+\n+  t1 = gen_reg_rtx (V4SImode);\n+  t2 = gen_reg_rtx (V4SImode);\n+\n+  emit_insn (gen_sse2_pshufd_1 (t1, operands[1],\n+\t\t\t\tGEN_INT (0),\n+\t\t\t\tGEN_INT (2),\n+\t\t\t\tGEN_INT (1),\n+\t\t\t\tGEN_INT (3)));\n+  emit_insn (gen_sse2_pshufd_1 (t2, operands[2],\n+\t\t\t\tGEN_INT (0),\n+\t\t\t\tGEN_INT (2),\n+\t\t\t\tGEN_INT (1),\n+\t\t\t\tGEN_INT (3)));\n+  emit_insn (gen_sse5_mulv2div2di3_low (operands[0], t1, t2));\n+  DONE;\n+  DONE;\n+})\n+\n (define_expand \"vec_widen_umult_hi_v4si\"\n   [(match_operand:V2DI 0 \"register_operand\" \"\")\n    (match_operand:V4SI 1 \"register_operand\" \"\")\n@@ -3893,6 +3987,12 @@\n {\n   rtx op1, op2, h1, l1, h2, l2, h3, l3;\n \n+  if (TARGET_SSE5)\n+    {\n+      ix86_expand_sse5_pack (operands);\n+      DONE;\t\n+    }\t\n+ \n   op1 = gen_lowpart (V16QImode, operands[1]);\n   op2 = gen_lowpart (V16QImode, operands[2]);\n   h1 = gen_reg_rtx (V16QImode);\n@@ -3928,6 +4028,12 @@\n {\n   rtx op1, op2, h1, l1, h2, l2;\n \n+  if (TARGET_SSE5)\n+    {\n+      ix86_expand_sse5_pack (operands);\n+      DONE;\t\n+    }\t\n+ \n   op1 = gen_lowpart (V8HImode, operands[1]);\n   op2 = gen_lowpart (V8HImode, operands[2]);\n   h1 = gen_reg_rtx (V8HImode);\n@@ -3957,6 +4063,12 @@\n {\n   rtx op1, op2, h1, l1;\n \n+  if (TARGET_SSE5)\n+    {\n+      ix86_expand_sse5_pack (operands);\n+      DONE;\t\n+    }\t\n+ \n   op1 = gen_lowpart (V4SImode, operands[1]);\n   op2 = gen_lowpart (V4SImode, operands[2]);\n   h1 = gen_reg_rtx (V4SImode);\n@@ -7024,6 +7136,87 @@\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn_and_split \"*sse5_pmacsdql_mem\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=&x,&x,&x\")\n+\t(plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)]))))\n+\t (match_operand:V2DI 3 \"memory_operand\" \"m,m,m\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, -1)\"\n+  \"#\"\n+  \"&& (reload_completed\n+       || (!reg_mentioned_p (operands[0], operands[1])\n+\t   && !reg_mentioned_p (operands[0], operands[2])))\"\n+  [(set (match_dup 0)\n+\t(match_dup 3))\n+   (set (match_dup 0)\n+\t(plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_dup 2)\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)]))))\n+\t (match_dup 0)))])\n+\n+;; We don't have a straight 32-bit parallel multiply and extend on SSE5, so\n+;; fake it with a multiply/add.  In general, we expect the define_split to\n+;; occur before register allocation, so we have to handle the corner case where\n+;; the target is the same as operands 1/2\n+(define_insn_and_split \"sse5_mulv2div2di3_low\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=&x\")\n+\t(mult:V2DI\n+\t  (sign_extend:V2DI\n+\t    (vec_select:V2SI\n+\t      (match_operand:V4SI 1 \"nonimmediate_operand\" \"%x\")\n+\t      (parallel [(const_int 1)\n+\t\t\t (const_int 3)])))\n+\t  (sign_extend:V2DI\n+\t    (vec_select:V2SI\n+\t      (match_operand:V4SI 2 \"nonimmediate_operand\" \"xm\")\n+\t      (parallel [(const_int 1)\n+\t\t\t (const_int 3)])))))]\n+  \"TARGET_SSE5\"\n+  \"#\"\n+  \"&& (reload_completed\n+       || (!reg_mentioned_p (operands[0], operands[1])\n+\t   && !reg_mentioned_p (operands[0], operands[2])))\"\n+  [(set (match_dup 0)\n+\t(match_dup 3))\n+   (set (match_dup 0)\n+\t(plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_dup 2)\n+\t    (parallel [(const_int 1)\n+\t\t       (const_int 3)]))))\n+\t (match_dup 0)))]\n+{\n+  operands[3] = CONST0_RTX (V2DImode);\n+}\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n (define_insn \"sse5_pmacsdqh\"\n   [(set (match_operand:V2DI 0 \"register_operand\" \"=x,x,x\")\n \t(plus:V2DI\n@@ -7047,6 +7240,87 @@\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn_and_split \"*sse5_pmacsdqh_mem\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=&x,&x,&x\")\n+\t(plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 1 \"nonimmediate_operand\" \"x,x,m\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_operand:V4SI 2 \"nonimmediate_operand\" \"x,m,x\")\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)]))))\n+\t (match_operand:V2DI 3 \"memory_operand\" \"m,m,m\")))]\n+  \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, false, -1)\"\n+  \"#\"\n+  \"&& (reload_completed\n+       || (!reg_mentioned_p (operands[0], operands[1])\n+\t   && !reg_mentioned_p (operands[0], operands[2])))\"\n+  [(set (match_dup 0)\n+\t(match_dup 3))\n+   (set (match_dup 0)\n+\t(plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_dup 2)\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)]))))\n+\t (match_dup 0)))])\n+\n+;; We don't have a straight 32-bit parallel multiply and extend on SSE5, so\n+;; fake it with a multiply/add.  In general, we expect the define_split to\n+;; occur before register allocation, so we have to handle the corner case where\n+;; the target is the same as either operands[1] or operands[2]\n+(define_insn_and_split \"sse5_mulv2div2di3_high\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=&x\")\n+\t(mult:V2DI\n+\t  (sign_extend:V2DI\n+\t    (vec_select:V2SI\n+\t      (match_operand:V4SI 1 \"nonimmediate_operand\" \"%x\")\n+\t      (parallel [(const_int 0)\n+\t\t\t (const_int 2)])))\n+\t  (sign_extend:V2DI\n+\t    (vec_select:V2SI\n+\t      (match_operand:V4SI 2 \"nonimmediate_operand\" \"xm\")\n+\t      (parallel [(const_int 0)\n+\t\t\t (const_int 2)])))))]\n+  \"TARGET_SSE5\"\n+  \"#\"\n+  \"&& (reload_completed\n+       || (!reg_mentioned_p (operands[0], operands[1])\n+\t   && !reg_mentioned_p (operands[0], operands[2])))\"\n+  [(set (match_dup 0)\n+\t(match_dup 3))\n+   (set (match_dup 0)\n+\t(plus:V2DI\n+\t (mult:V2DI\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_dup 1)\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)])))\n+\t  (sign_extend:V2DI\n+\t   (vec_select:V2SI\n+\t    (match_dup 2)\n+\t    (parallel [(const_int 0)\n+\t\t       (const_int 2)]))))\n+\t (match_dup 0)))]\n+{\n+  operands[3] = CONST0_RTX (V2DImode);\n+}\n+  [(set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"TI\")])\n+\n ;; SSE5 parallel integer multiply/add instructions for the intrinisics\n (define_insn \"sse5_pmacsswd\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x,x\")\n@@ -7190,19 +7464,17 @@\n \n ;; SSE5 parallel XMM conditional moves\n (define_insn \"sse5_pcmov_<mode>\"\n-  [(set (match_operand:SSEMODE 0 \"register_operand\" \"=x,x,x,x,x,x\")\n+  [(set (match_operand:SSEMODE 0 \"register_operand\" \"=x,x,x,x\")\n \t(if_then_else:SSEMODE\n-\t  (match_operand:SSEMODE 3 \"nonimmediate_operand\" \"0,0,xm,x,0,0\")\n-\t  (match_operand:SSEMODE 1 \"vector_move_operand\" \"x,xm,0,0,C,x\")\n-\t  (match_operand:SSEMODE 2 \"vector_move_operand\" \"xm,x,x,xm,x,C\")))]\n+\t  (match_operand:SSEMODE 3 \"nonimmediate_operand\" \"0,0,xm,x\")\n+\t  (match_operand:SSEMODE 1 \"vector_move_operand\" \"x,xm,0,0\")\n+\t  (match_operand:SSEMODE 2 \"vector_move_operand\" \"xm,x,x,xm\")))]\n   \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 4, true, 1)\"\n   \"@\n    pcmov\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n    pcmov\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n    pcmov\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n-   pcmov\\t{%3, %2, %1, %0|%0, %1, %2, %3}\n-   andps\\t{%2, %0|%0, %2}\n-   andnps\\t{%1, %0|%0, %1}\"\n+   pcmov\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n   [(set_attr \"type\" \"sse4arg\")])\n \n ;; SSE5 horizontal add/subtract instructions\n@@ -7801,7 +8073,71 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n ;; SSE5 packed rotate instructions\n-(define_insn \"rotl<mode>3\"\n+(define_expand \"rotl<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"\")\n+\t(rotate:SSEMODE1248\n+\t (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"\")\n+\t (match_operand:SI 2 \"general_operand\")))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we were given a scalar, convert it to parallel */\n+  if (! const_0_to_<sserotatemax>_operand (operands[2], SImode))\n+    {\n+      rtvec vs = rtvec_alloc (<ssescalarnum>);\n+      rtx par = gen_rtx_PARALLEL (<MODE>mode, vs);\n+      rtx reg = gen_reg_rtx (<MODE>mode);\n+      rtx op2 = operands[2];\n+      int i;\n+\n+      if (GET_MODE (op2) != <ssescalarmode>mode)\n+        {\n+\t  op2 = gen_reg_rtx (<ssescalarmode>mode);\n+\t  convert_move (op2, operands[2], false);\n+\t}\n+\n+      for (i = 0; i < <ssescalarnum>; i++)\n+\tRTVEC_ELT (vs, i) = op2;\n+\n+      emit_insn (gen_vec_init<mode> (reg, par));\n+      emit_insn (gen_sse5_vrotl<mode>3 (operands[0], operands[1], reg));\n+      DONE;\n+    }\n+})\n+\n+(define_expand \"rotr<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"\")\n+\t(rotatert:SSEMODE1248\n+\t (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"\")\n+\t (match_operand:SI 2 \"general_operand\")))]\n+  \"TARGET_SSE5\"\n+{\n+  /* If we were given a scalar, convert it to parallel */\n+  if (! const_0_to_<sserotatemax>_operand (operands[2], SImode))\n+    {\n+      rtvec vs = rtvec_alloc (<ssescalarnum>);\n+      rtx par = gen_rtx_PARALLEL (<MODE>mode, vs);\n+      rtx neg = gen_reg_rtx (<MODE>mode);\n+      rtx reg = gen_reg_rtx (<MODE>mode);\n+      rtx op2 = operands[2];\n+      int i;\n+\n+      if (GET_MODE (op2) != <ssescalarmode>mode)\n+        {\n+\t  op2 = gen_reg_rtx (<ssescalarmode>mode);\n+\t  convert_move (op2, operands[2], false);\n+\t}\n+\n+      for (i = 0; i < <ssescalarnum>; i++)\n+\tRTVEC_ELT (vs, i) = op2;\n+\n+      emit_insn (gen_vec_init<mode> (reg, par));\n+      emit_insn (gen_neg<mode>2 (neg, reg));\n+      emit_insn (gen_sse5_vrotl<mode>3 (operands[0], operands[1], neg));\n+      DONE;\n+    }\n+})\n+\n+(define_insn \"sse5_rotl<mode>3\"\n   [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x\")\n \t(rotate:SSEMODE1248\n \t (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"xm\")\n@@ -7811,42 +8147,229 @@\n   [(set_attr \"type\" \"sseishft\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"sse5_rotl<mode>3\"\n+(define_insn \"sse5_rotr<mode>3\"\n+  [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x\")\n+\t(rotatert:SSEMODE1248\n+\t (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"xm\")\n+\t (match_operand:SI 2 \"const_0_to_<sserotatemax>_operand\" \"n\")))]\n+  \"TARGET_SSE5\"\n+{\n+  operands[3] = GEN_INT ((<ssescalarnum> * 8) - INTVAL (operands[2]));\n+  return \\\"prot<ssevecsize>\\t{%3, %1, %0|%0, %1, %3}\\\";\n+}\n+  [(set_attr \"type\" \"sseishft\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_expand \"vrotr<mode>3\"\n+  [(match_operand:SSEMODE1248 0 \"register_operand\" \"\")\n+   (match_operand:SSEMODE1248 1 \"register_operand\" \"\")\n+   (match_operand:SSEMODE1248 2 \"register_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtx reg = gen_reg_rtx (<MODE>mode);\n+  emit_insn (gen_neg<mode>2 (reg, operands[2]));\n+  emit_insn (gen_sse5_vrotl<mode>3 (operands[0], operands[1], reg));\n+  DONE;\n+})\n+\n+(define_expand \"vrotl<mode>3\"\n+  [(match_operand:SSEMODE1248 0 \"register_operand\" \"\")\n+   (match_operand:SSEMODE1248 1 \"register_operand\" \"\")\n+   (match_operand:SSEMODE1248 2 \"register_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  emit_insn (gen_sse5_vrotl<mode>3 (operands[0], operands[1], operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"sse5_vrotl<mode>3\"\n   [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x,x\")\n-\t(rotate:SSEMODE1248\n-\t (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n-\t (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")))]\n+\t(if_then_else:SSEMODE1248\n+\t (ge:SSEMODE1248\n+\t  (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")\n+\t  (const_int 0))\n+\t (rotate:SSEMODE1248\n+\t  (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n+\t  (match_dup 2))\n+\t (rotatert:SSEMODE1248\n+\t  (match_dup 1)\n+\t  (neg:SSEMODE1248 (match_dup 2)))))]\n   \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 3, true, 1)\"\n   \"prot<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n    (set_attr \"mode\" \"TI\")])\n \n-;; SSE5 packed shift instructions.  Note negative values for the shift amount\n-;; convert this into a right shift instead of left shift.  For now, model this\n-;; with an UNSPEC instead of using ashift/lshift since the rest of the x86 does\n-;; not have the concept of negating the shift amount.  Also, there is no LSHIFT\n+;; SSE5 packed shift instructions.\n+;; FIXME: add V2DI back in\n+(define_expand \"vlshr<mode>3\"\n+  [(match_operand:SSEMODE124 0 \"register_operand\" \"\")\n+   (match_operand:SSEMODE124 1 \"register_operand\" \"\")\n+   (match_operand:SSEMODE124 2 \"register_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtx neg = gen_reg_rtx (<MODE>mode);\n+  emit_insn (gen_neg<mode>2 (neg, operands[2]));\n+  emit_insn (gen_sse5_lshl<mode>3 (operands[0], operands[1], neg));\n+  DONE;\n+})\n+\n+(define_expand \"vashr<mode>3\"\n+  [(match_operand:SSEMODE124 0 \"register_operand\" \"\")\n+   (match_operand:SSEMODE124 1 \"register_operand\" \"\")\n+   (match_operand:SSEMODE124 2 \"register_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtx neg = gen_reg_rtx (<MODE>mode);\n+  emit_insn (gen_neg<mode>2 (neg, operands[2]));\n+  emit_insn (gen_sse5_ashl<mode>3 (operands[0], operands[1], neg));\n+  DONE;\n+})\n+\n+(define_expand \"vashl<mode>3\"\n+  [(match_operand:SSEMODE124 0 \"register_operand\" \"\")\n+   (match_operand:SSEMODE124 1 \"register_operand\" \"\")\n+   (match_operand:SSEMODE124 2 \"register_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  emit_insn (gen_sse5_ashl<mode>3 (operands[0], operands[1], operands[2]));\n+  DONE;\n+})\n+\n (define_insn \"sse5_ashl<mode>3\"\n   [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODE1248\n-\t [(match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n-\t  (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")]\n-\t UNSPEC_SSE5_ASHIFT))]\n+\t(if_then_else:SSEMODE1248\n+\t (ge:SSEMODE1248\n+\t  (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")\n+\t  (const_int 0))\n+\t (ashift:SSEMODE1248\n+\t  (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n+\t  (match_dup 2))\n+\t (ashiftrt:SSEMODE1248\n+\t  (match_dup 1)\n+\t  (neg:SSEMODE1248 (match_dup 2)))))]\n   \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 3, true, 1)\"\n   \"psha<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n    (set_attr \"mode\" \"TI\")])\n \n (define_insn \"sse5_lshl<mode>3\"\n   [(set (match_operand:SSEMODE1248 0 \"register_operand\" \"=x,x\")\n-\t(unspec:SSEMODE1248\n-\t [(match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n-\t  (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")]\n-\t UNSPEC_SSE5_LSHIFT))]\n+\t(if_then_else:SSEMODE1248\n+\t (ge:SSEMODE1248\n+\t  (match_operand:SSEMODE1248 2 \"nonimmediate_operand\" \"xm,x\")\n+\t  (const_int 0))\n+\t (ashift:SSEMODE1248\n+\t  (match_operand:SSEMODE1248 1 \"nonimmediate_operand\" \"x,xm\")\n+\t  (match_dup 2))\n+\t (lshiftrt:SSEMODE1248\n+\t  (match_dup 1)\n+\t  (neg:SSEMODE1248 (match_dup 2)))))]\n   \"TARGET_SSE5 && ix86_sse5_valid_op_p (operands, insn, 3, true, 1)\"\n   \"pshl<ssevecsize>\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n    (set_attr \"mode\" \"TI\")])\n \n+;; SSE2 doesn't have some shift varients, so define versions for SSE5\n+(define_expand \"ashlv16qi3\"\n+  [(match_operand:V16QI 0 \"register_operand\" \"\")\n+   (match_operand:V16QI 1 \"register_operand\" \"\")\n+   (match_operand:SI 2 \"nonmemory_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtvec vs = rtvec_alloc (16);\n+  rtx par = gen_rtx_PARALLEL (V16QImode, vs);\n+  rtx reg = gen_reg_rtx (V16QImode);\n+  int i;\n+  for (i = 0; i < 16; i++)\n+    RTVEC_ELT (vs, i) = operands[2];\n+\n+  emit_insn (gen_vec_initv16qi (reg, par));\n+  emit_insn (gen_sse5_ashlv16qi3 (operands[0], operands[1], reg));\n+  DONE;\n+})\n+\n+(define_expand \"lshlv16qi3\"\n+  [(match_operand:V16QI 0 \"register_operand\" \"\")\n+   (match_operand:V16QI 1 \"register_operand\" \"\")\n+   (match_operand:SI 2 \"nonmemory_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtvec vs = rtvec_alloc (16);\n+  rtx par = gen_rtx_PARALLEL (V16QImode, vs);\n+  rtx reg = gen_reg_rtx (V16QImode);\n+  int i;\n+  for (i = 0; i < 16; i++)\n+    RTVEC_ELT (vs, i) = operands[2];\n+\n+  emit_insn (gen_vec_initv16qi (reg, par));\n+  emit_insn (gen_sse5_lshlv16qi3 (operands[0], operands[1], reg));\n+  DONE;\n+})\n+\n+(define_expand \"ashrv16qi3\"\n+  [(match_operand:V16QI 0 \"register_operand\" \"\")\n+   (match_operand:V16QI 1 \"register_operand\" \"\")\n+   (match_operand:SI 2 \"nonmemory_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtvec vs = rtvec_alloc (16);\n+  rtx par = gen_rtx_PARALLEL (V16QImode, vs);\n+  rtx reg = gen_reg_rtx (V16QImode);\n+  int i;\n+  rtx ele = ((GET_CODE (operands[2]) == CONST_INT)\n+\t     ? GEN_INT (- INTVAL (operands[2]))\n+\t     : operands[2]);\n+\n+  for (i = 0; i < 16; i++)\n+    RTVEC_ELT (vs, i) = ele;\n+\n+  emit_insn (gen_vec_initv16qi (reg, par));\n+\n+  if (GET_CODE (operands[2]) != CONST_INT)\n+    {\n+      rtx neg = gen_reg_rtx (V16QImode);\n+      emit_insn (gen_negv16qi2 (neg, reg));\n+      emit_insn (gen_sse5_ashlv16qi3 (operands[0], operands[1], neg));\n+    }\n+  else\n+    emit_insn (gen_sse5_ashlv16qi3 (operands[0], operands[1], reg));\n+\n+  DONE;\n+})\n+\n+(define_expand \"ashrv2di3\"\n+  [(match_operand:V2DI 0 \"register_operand\" \"\")\n+   (match_operand:V2DI 1 \"register_operand\" \"\")\n+   (match_operand:DI 2 \"nonmemory_operand\" \"\")]\n+  \"TARGET_SSE5\"\n+{\n+  rtvec vs = rtvec_alloc (2);\n+  rtx par = gen_rtx_PARALLEL (V2DImode, vs);\n+  rtx reg = gen_reg_rtx (V2DImode);\n+  rtx ele;\n+\n+  if (GET_CODE (operands[2]) == CONST_INT)\n+    ele = GEN_INT (- INTVAL (operands[2]));\n+  else if (GET_MODE (operands[2]) != DImode)\n+    {\n+      rtx move = gen_reg_rtx (DImode);\n+      ele = gen_reg_rtx (DImode);\n+      convert_move (move, operands[2], false);\n+      emit_insn (gen_negdi2 (ele, move));\n+    }\n+  else\n+    {\n+      ele = gen_reg_rtx (DImode);\n+      emit_insn (gen_negdi2 (ele, operands[2]));\n+    }\n+\n+  RTVEC_ELT (vs, 0) = ele;\n+  RTVEC_ELT (vs, 1) = ele;\n+  emit_insn (gen_vec_initv2di (reg, par));\n+  emit_insn (gen_sse5_ashlv2di3 (operands[0], operands[1], reg));\n+  DONE;\n+})\n+\n ;; SSE5 FRCZ support\n ;; parallel insns\n (define_insn \"sse5_frcz<mode>2\""}, {"sha": "f8ed145350e51a0bff99527dccbedca17931b661", "filename": "gcc/config/rs6000/altivec.md", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Frs6000%2Faltivec.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Frs6000%2Faltivec.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Faltivec.md?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -575,7 +575,7 @@\n   /* Generate [-0.0, -0.0, -0.0, -0.0].  */\n   neg0 = gen_reg_rtx (V4SImode);\n   emit_insn (gen_altivec_vspltisw (neg0, constm1_rtx));\n-  emit_insn (gen_ashlv4si3 (neg0, neg0, neg0));\n+  emit_insn (gen_vashlv4si3 (neg0, neg0, neg0));\n \n   /* Use the multiply-add.  */\n   emit_insn (gen_altivec_vmaddfp (operands[0], operands[1], operands[2],\n@@ -634,7 +634,7 @@\n    high_product = gen_reg_rtx (V4SImode);\n    emit_insn (gen_altivec_vmsumuhm (high_product, one, small_swap, zero));\n  \n-   emit_insn (gen_ashlv4si3 (high_product, high_product, sixteen));\n+   emit_insn (gen_vashlv4si3 (high_product, high_product, sixteen));\n  \n    emit_insn (gen_addv4si3 (operands[0], high_product, low_product));\n    \n@@ -1238,23 +1238,23 @@\n   \"vslo %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"ashl<mode>3\"\n+(define_insn \"vashl<mode>3\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n         (ashift:VI (match_operand:VI 1 \"register_operand\" \"v\")\n                    (match_operand:VI 2 \"register_operand\" \"v\") ))]\n   \"TARGET_ALTIVEC\"\n   \"vsl<VI_char> %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"lshr<mode>3\"\n+(define_insn \"vlshr<mode>3\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n         (lshiftrt:VI (match_operand:VI 1 \"register_operand\" \"v\")\n                     (match_operand:VI 2 \"register_operand\" \"v\") ))]\n   \"TARGET_ALTIVEC\"\n   \"vsr<VI_char> %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"ashr<mode>3\"\n+(define_insn \"vashr<mode>3\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n         (ashiftrt:VI (match_operand:VI 1 \"register_operand\" \"v\")\n                     (match_operand:VI 2 \"register_operand\" \"v\") ))]\n@@ -2640,7 +2640,7 @@\n   /* Generate [-0.0, -0.0, -0.0, -0.0].  */\n   neg0 = gen_reg_rtx (V4SImode);\n   emit_insn (gen_altivec_vspltisw (neg0, constm1_rtx));\n-  emit_insn (gen_ashlv4si3 (neg0, neg0, neg0));\n+  emit_insn (gen_vashlv4si3 (neg0, neg0, neg0));\n \n   /* XOR */\n   emit_insn (gen_xorv4sf3 (operands[0],"}, {"sha": "076cf6cce04900742ee9d94997f62a71c1adf69a", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -7109,20 +7109,20 @@ static struct builtin_description bdesc_2arg[] =\n   { MASK_ALTIVEC, CODE_FOR_altivec_vrlb, \"__builtin_altivec_vrlb\", ALTIVEC_BUILTIN_VRLB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vrlh, \"__builtin_altivec_vrlh\", ALTIVEC_BUILTIN_VRLH },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vrlw, \"__builtin_altivec_vrlw\", ALTIVEC_BUILTIN_VRLW },\n-  { MASK_ALTIVEC, CODE_FOR_ashlv16qi3, \"__builtin_altivec_vslb\", ALTIVEC_BUILTIN_VSLB },\n-  { MASK_ALTIVEC, CODE_FOR_ashlv8hi3, \"__builtin_altivec_vslh\", ALTIVEC_BUILTIN_VSLH },\n-  { MASK_ALTIVEC, CODE_FOR_ashlv4si3, \"__builtin_altivec_vslw\", ALTIVEC_BUILTIN_VSLW },\n+  { MASK_ALTIVEC, CODE_FOR_vashlv16qi3, \"__builtin_altivec_vslb\", ALTIVEC_BUILTIN_VSLB },\n+  { MASK_ALTIVEC, CODE_FOR_vashlv8hi3, \"__builtin_altivec_vslh\", ALTIVEC_BUILTIN_VSLH },\n+  { MASK_ALTIVEC, CODE_FOR_vashlv4si3, \"__builtin_altivec_vslw\", ALTIVEC_BUILTIN_VSLW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsl, \"__builtin_altivec_vsl\", ALTIVEC_BUILTIN_VSL },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vslo, \"__builtin_altivec_vslo\", ALTIVEC_BUILTIN_VSLO },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vspltb, \"__builtin_altivec_vspltb\", ALTIVEC_BUILTIN_VSPLTB },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsplth, \"__builtin_altivec_vsplth\", ALTIVEC_BUILTIN_VSPLTH },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vspltw, \"__builtin_altivec_vspltw\", ALTIVEC_BUILTIN_VSPLTW },\n-  { MASK_ALTIVEC, CODE_FOR_lshrv16qi3, \"__builtin_altivec_vsrb\", ALTIVEC_BUILTIN_VSRB },\n-  { MASK_ALTIVEC, CODE_FOR_lshrv8hi3, \"__builtin_altivec_vsrh\", ALTIVEC_BUILTIN_VSRH },\n-  { MASK_ALTIVEC, CODE_FOR_lshrv4si3, \"__builtin_altivec_vsrw\", ALTIVEC_BUILTIN_VSRW },\n-  { MASK_ALTIVEC, CODE_FOR_ashrv16qi3, \"__builtin_altivec_vsrab\", ALTIVEC_BUILTIN_VSRAB },\n-  { MASK_ALTIVEC, CODE_FOR_ashrv8hi3, \"__builtin_altivec_vsrah\", ALTIVEC_BUILTIN_VSRAH },\n-  { MASK_ALTIVEC, CODE_FOR_ashrv4si3, \"__builtin_altivec_vsraw\", ALTIVEC_BUILTIN_VSRAW },\n+  { MASK_ALTIVEC, CODE_FOR_vlshrv16qi3, \"__builtin_altivec_vsrb\", ALTIVEC_BUILTIN_VSRB },\n+  { MASK_ALTIVEC, CODE_FOR_vlshrv8hi3, \"__builtin_altivec_vsrh\", ALTIVEC_BUILTIN_VSRH },\n+  { MASK_ALTIVEC, CODE_FOR_vlshrv4si3, \"__builtin_altivec_vsrw\", ALTIVEC_BUILTIN_VSRW },\n+  { MASK_ALTIVEC, CODE_FOR_vashrv16qi3, \"__builtin_altivec_vsrab\", ALTIVEC_BUILTIN_VSRAB },\n+  { MASK_ALTIVEC, CODE_FOR_vashrv8hi3, \"__builtin_altivec_vsrah\", ALTIVEC_BUILTIN_VSRAH },\n+  { MASK_ALTIVEC, CODE_FOR_vashrv4si3, \"__builtin_altivec_vsraw\", ALTIVEC_BUILTIN_VSRAW },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsr, \"__builtin_altivec_vsr\", ALTIVEC_BUILTIN_VSR },\n   { MASK_ALTIVEC, CODE_FOR_altivec_vsro, \"__builtin_altivec_vsro\", ALTIVEC_BUILTIN_VSRO },\n   { MASK_ALTIVEC, CODE_FOR_subv16qi3, \"__builtin_altivec_vsububm\", ALTIVEC_BUILTIN_VSUBUBM },"}, {"sha": "eecd337f73ffee3dbb5c47ad1f18c361de451df3", "filename": "gcc/config/spu/spu-builtins.def", "status": "modified", "additions": 24, "deletions": 24, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fspu%2Fspu-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fspu%2Fspu-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-builtins.def?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -107,19 +107,19 @@ DEF_BUILTIN (SI_NOR,         CODE_FOR_nor_v16qi,     \"si_nor\",         B_INSN,\n DEF_BUILTIN (SI_EQV,         CODE_FOR_eqv_v16qi,     \"si_eqv\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_SELB,        CODE_FOR_selb,          \"si_selb\",        B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_SHUFB,       CODE_FOR_shufb,         \"si_shufb\",       B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n-DEF_BUILTIN (SI_SHLH,        CODE_FOR_ashlv8hi3,     \"si_shlh\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n-DEF_BUILTIN (SI_SHLHI,       CODE_FOR_ashlv8hi3,     \"si_shlhi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n-DEF_BUILTIN (SI_SHL,         CODE_FOR_ashlv4si3,     \"si_shl\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n-DEF_BUILTIN (SI_SHLI,        CODE_FOR_ashlv4si3,     \"si_shli\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_SHLH,        CODE_FOR_vashlv8hi3,     \"si_shlh\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SHLHI,       CODE_FOR_vashlv8hi3,     \"si_shlhi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_SHL,         CODE_FOR_vashlv4si3,     \"si_shl\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SHLI,        CODE_FOR_vashlv4si3,     \"si_shli\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n DEF_BUILTIN (SI_SHLQBI,      CODE_FOR_shlqbi_ti,     \"si_shlqbi\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_SHLQBII,     CODE_FOR_shlqbi_ti,     \"si_shlqbii\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n DEF_BUILTIN (SI_SHLQBY,      CODE_FOR_shlqby_ti,     \"si_shlqby\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_SHLQBYI,     CODE_FOR_shlqby_ti,     \"si_shlqbyi\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n DEF_BUILTIN (SI_SHLQBYBI,    CODE_FOR_shlqbybi_ti,   \"si_shlqbybi\",    B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n-DEF_BUILTIN (SI_ROTH,        CODE_FOR_rotlv8hi3,     \"si_roth\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n-DEF_BUILTIN (SI_ROTHI,       CODE_FOR_rotlv8hi3,     \"si_rothi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n-DEF_BUILTIN (SI_ROT,         CODE_FOR_rotlv4si3,     \"si_rot\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n-DEF_BUILTIN (SI_ROTI,        CODE_FOR_rotlv4si3,     \"si_roti\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTH,        CODE_FOR_vrotlv8hi3,    \"si_roth\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTHI,       CODE_FOR_vrotlv8hi3,    \"si_rothi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROT,         CODE_FOR_vrotlv4si3,    \"si_rot\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTI,        CODE_FOR_vrotlv4si3,    \"si_roti\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n DEF_BUILTIN (SI_ROTQBY,      CODE_FOR_rotqby_ti,     \"si_rotqby\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n DEF_BUILTIN (SI_ROTQBYI,     CODE_FOR_rotqby_ti,     \"si_rotqbyi\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n DEF_BUILTIN (SI_ROTQBYBI,    CODE_FOR_rotqbybi_ti,   \"si_rotqbybi\",    B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n@@ -536,14 +536,14 @@ DEF_BUILTIN (SPU_XOR_13,           CODE_FOR_xorv8hi3,      \"spu_xor_13\",\n DEF_BUILTIN (SPU_XOR_14,           CODE_FOR_xorv4si3,      \"spu_xor_14\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n DEF_BUILTIN (SPU_XOR_15,           CODE_FOR_xorv4si3,      \"spu_xor_15\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n DEF_BUILTIN (SPU_RL,               CODE_FOR_nothing,       \"spu_rl\",               B_OVERLOAD, _A1(SPU_BTI_VOID))\n-DEF_BUILTIN (SPU_RL_0,             CODE_FOR_rotlv8hi3,     \"spu_rl_0\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_V8HI))\n-DEF_BUILTIN (SPU_RL_1,             CODE_FOR_rotlv8hi3,     \"spu_rl_1\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n-DEF_BUILTIN (SPU_RL_2,             CODE_FOR_rotlv4si3,     \"spu_rl_2\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_V4SI))\n-DEF_BUILTIN (SPU_RL_3,             CODE_FOR_rotlv4si3,     \"spu_rl_3\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n-DEF_BUILTIN (SPU_RL_4,             CODE_FOR_rotlv8hi3,     \"spu_rl_4\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTHI))\n-DEF_BUILTIN (SPU_RL_5,             CODE_FOR_rotlv8hi3,     \"spu_rl_5\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTHI))\n-DEF_BUILTIN (SPU_RL_6,             CODE_FOR_rotlv4si3,     \"spu_rl_6\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n-DEF_BUILTIN (SPU_RL_7,             CODE_FOR_rotlv4si3,     \"spu_rl_7\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RL_0,             CODE_FOR_vrotlv8hi3,    \"spu_rl_0\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_RL_1,             CODE_FOR_vrotlv8hi3,    \"spu_rl_1\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_RL_2,             CODE_FOR_vrotlv4si3,    \"spu_rl_2\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_RL_3,             CODE_FOR_vrotlv4si3,    \"spu_rl_3\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_RL_4,             CODE_FOR_vrotlv8hi3,    \"spu_rl_4\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_RL_5,             CODE_FOR_vrotlv8hi3,    \"spu_rl_5\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_RL_6,             CODE_FOR_vrotlv4si3,    \"spu_rl_6\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RL_7,             CODE_FOR_vrotlv4si3,    \"spu_rl_7\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n DEF_BUILTIN (SPU_RLQW,             CODE_FOR_nothing,       \"spu_rlqw\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n DEF_BUILTIN (SPU_RLQW_0,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_0\",           B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n DEF_BUILTIN (SPU_RLQW_1,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_1\",           B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n@@ -629,14 +629,14 @@ DEF_BUILTIN (SPU_RLMASKQWBYTEBC_7, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_7\n DEF_BUILTIN (SPU_RLMASKQWBYTEBC_8, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_8\", B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_INTSI))\n DEF_BUILTIN (SPU_RLMASKQWBYTEBC_9, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_9\", B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_INTSI))\n DEF_BUILTIN (SPU_SL,               CODE_FOR_nothing,       \"spu_sl\",               B_OVERLOAD, _A1(SPU_BTI_VOID))\n-DEF_BUILTIN (SPU_SL_0,             CODE_FOR_ashlv8hi3,     \"spu_sl_0\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n-DEF_BUILTIN (SPU_SL_1,             CODE_FOR_ashlv8hi3,     \"spu_sl_1\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UV8HI))\n-DEF_BUILTIN (SPU_SL_2,             CODE_FOR_ashlv4si3,     \"spu_sl_2\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n-DEF_BUILTIN (SPU_SL_3,             CODE_FOR_ashlv4si3,     \"spu_sl_3\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UV4SI))\n-DEF_BUILTIN (SPU_SL_4,             CODE_FOR_ashlv8hi3,     \"spu_sl_4\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTSI))\n-DEF_BUILTIN (SPU_SL_5,             CODE_FOR_ashlv8hi3,     \"spu_sl_5\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UINTSI))\n-DEF_BUILTIN (SPU_SL_6,             CODE_FOR_ashlv4si3,     \"spu_sl_6\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n-DEF_BUILTIN (SPU_SL_7,             CODE_FOR_ashlv4si3,     \"spu_sl_7\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SL_0,             CODE_FOR_vashlv8hi3,     \"spu_sl_0\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_SL_1,             CODE_FOR_vashlv8hi3,     \"spu_sl_1\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_SL_2,             CODE_FOR_vashlv4si3,     \"spu_sl_2\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SL_3,             CODE_FOR_vashlv4si3,     \"spu_sl_3\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SL_4,             CODE_FOR_vashlv8hi3,     \"spu_sl_4\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SL_5,             CODE_FOR_vashlv8hi3,     \"spu_sl_5\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SL_6,             CODE_FOR_vashlv4si3,     \"spu_sl_6\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SL_7,             CODE_FOR_vashlv4si3,     \"spu_sl_7\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UINTSI))\n DEF_BUILTIN (SPU_SLQW,             CODE_FOR_nothing,       \"spu_slqw\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n DEF_BUILTIN (SPU_SLQW_0,           CODE_FOR_shlqbi_ti,     \"spu_slqw_0\",           B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_UINTSI))\n DEF_BUILTIN (SPU_SLQW_1,           CODE_FOR_shlqbi_ti,     \"spu_slqw_1\",           B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UINTSI))"}, {"sha": "692a8dae34fe16d6f670a7d024d5db96169adc89", "filename": "gcc/config/spu/spu.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fspu%2Fspu.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fspu%2Fspu.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -4799,7 +4799,7 @@ spu_initialize_trampoline (rtx tramp, rtx fnaddr, rtx cxt)\n       insnc = force_reg (V4SImode, array_to_constant (V4SImode, insna));\n \n       emit_insn (gen_shufb (shuf, fnaddr, cxt, shufc));\n-      emit_insn (gen_rotlv4si3 (rotl, shuf, spu_const (V4SImode, 7)));\n+      emit_insn (gen_vrotlv4si3 (rotl, shuf, spu_const (V4SImode, 7)));\n       emit_insn (gen_movv4si (mask, spu_const (V4SImode, 0xffff << 7)));\n       emit_insn (gen_selb (insn, insnc, rotl, mask));\n "}, {"sha": "6985a6836977b24836f90583315bea064d2a2787", "filename": "gcc/config/spu/spu.md", "status": "modified", "additions": 21, "deletions": 18, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fspu%2Fspu.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fconfig%2Fspu%2Fspu.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.md?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -211,6 +211,9 @@\n \t\t\t  V8HI\n \t\t\t  V4SI])\n \n+(define_mode_attr v\t [(V8HI  \"v\") (V4SI  \"v\")\n+\t\t\t  (HI    \"\") (SI    \"\")])\n+\n (define_mode_attr bh  [(QI \"b\")  (V16QI \"b\")\n \t\t       (HI \"h\")  (V8HI \"h\")\n \t\t       (SI \"\")   (V4SI \"\")])\n@@ -727,7 +730,7 @@\n     rtx op6_ti = gen_rtx_REG (TImode, REGNO (ops[6]));\n     emit_insn (gen_clzv4si2 (ops[3],op1_v4si));\n     emit_move_insn (ops[6], spu_const (V4SImode, 1023+31));\n-    emit_insn (gen_ashlv4si3 (ops[4],op1_v4si,ops[3]));\n+    emit_insn (gen_vashlv4si3 (ops[4],op1_v4si,ops[3]));\n     emit_insn (gen_ceq_v4si (ops[5],ops[3],spu_const (V4SImode, 32)));\n     emit_insn (gen_subv4si3 (ops[6],ops[6],ops[3]));\n     emit_insn (gen_addv4si3 (ops[4],ops[4],ops[4]));\n@@ -822,7 +825,7 @@\n     rtx op4_df = gen_rtx_REG (DFmode, REGNO(ops[4]));\n     rtx op5_df = gen_rtx_REG (DFmode, REGNO(ops[5]));\n     emit_insn (gen_clzv4si2 (ops[4],op1_v4si));\n-    emit_insn (gen_ashlv4si3 (ops[5],op1_v4si,ops[4]));\n+    emit_insn (gen_vashlv4si3 (ops[5],op1_v4si,ops[4]));\n     emit_insn (gen_ceq_v4si (ops[6],ops[4],spu_const (V4SImode, 32)));\n     emit_insn (gen_subv4si3 (ops[4],ops[3],ops[4]));\n     emit_insn (gen_addv4si3 (ops[5],ops[5],ops[5]));\n@@ -1222,7 +1225,7 @@\n     emit_move_insn (mask, spu_const (V4SImode, 0x0000ffff));\n     emit_insn (gen_spu_mpyhh (high, operands[1], operands[2]));\n     emit_insn (gen_spu_mpy (low, operands[1], operands[2]));\n-    emit_insn (gen_ashlv4si3 (shift, high, spu_const(V4SImode, 16)));\n+    emit_insn (gen_vashlv4si3 (shift, high, spu_const(V4SImode, 16)));\n     emit_insn (gen_selb (result, shift, low, mask));\n     DONE;\n    }\")\n@@ -2100,9 +2103,9 @@\n   [(set_attr \"type\" \"fxb\")])\n \n \f\n-;; ashl\n+;; ashl, vashl\n \n-(define_insn \"ashl<mode>3\"\n+(define_insn \"<v>ashl<mode>3\"\n   [(set (match_operand:VHSI 0 \"spu_reg_operand\" \"=r,r\")\n \t(ashift:VHSI (match_operand:VHSI 1 \"spu_reg_operand\" \"r,r\")\n \t\t     (match_operand:VHSI 2 \"spu_nonmem_operand\" \"r,W\")))]\n@@ -2234,9 +2237,9 @@\n   [(set_attr \"type\" \"shuf,shuf\")])\n \n \f\n-;; lshr\n+;; lshr, vlshr\n \n-(define_insn_and_split \"lshr<mode>3\"\n+(define_insn_and_split \"<v>lshr<mode>3\"\n   [(set (match_operand:VHSI 0 \"spu_reg_operand\" \"=r,r\")\n \t(lshiftrt:VHSI (match_operand:VHSI 1 \"spu_reg_operand\" \"r,r\")\n \t\t       (match_operand:VHSI 2 \"spu_nonmem_operand\" \"r,W\")))\n@@ -2363,9 +2366,9 @@\n   [(set_attr \"type\" \"shuf\")])\n \n \f\n-;; ashr\n+;; ashr, vashr\n \n-(define_insn_and_split \"ashr<mode>3\"\n+(define_insn_and_split \"<v>ashr<mode>3\"\n   [(set (match_operand:VHSI 0 \"spu_reg_operand\" \"=r,r\")\n \t(ashiftrt:VHSI (match_operand:VHSI 1 \"spu_reg_operand\" \"r,r\")\n \t\t       (match_operand:VHSI 2 \"spu_nonmem_operand\" \"r,W\")))\n@@ -2430,7 +2433,7 @@\n \temit_insn (gen_lshrti3 (op0, op1, GEN_INT (32)));\n \temit_insn (gen_spu_xswd (op0d, op0v));\n         if (val > 32)\n-\t  emit_insn (gen_ashrv4si3 (op0v, op0v, spu_const (V4SImode, val - 32)));\n+\t  emit_insn (gen_vashrv4si3 (op0v, op0v, spu_const (V4SImode, val - 32)));\n       }\n     else\n       {\n@@ -2479,7 +2482,7 @@\n     rtx op1_v4si = spu_gen_subreg (V4SImode, operands[1]);\n     rtx t = gen_reg_rtx (TImode);\n     emit_insn (gen_subsi3 (sign_shift, GEN_INT (128), force_reg (SImode, operands[2])));\n-    emit_insn (gen_ashrv4si3 (sign_mask_v4si, op1_v4si, spu_const (V4SImode, 31)));\n+    emit_insn (gen_vashrv4si3 (sign_mask_v4si, op1_v4si, spu_const (V4SImode, 31)));\n     emit_insn (gen_fsm_ti (sign_mask, sign_mask));\n     emit_insn (gen_ashlti3 (sign_mask, sign_mask, sign_shift));\n     emit_insn (gen_lshrti3 (t, operands[1], operands[2]));\n@@ -2496,9 +2499,9 @@\n   [(set_attr \"type\" \"shuf\")])\n \n \f\n-;; rotl\n+;; vrotl, rotl\n \n-(define_insn \"rotl<mode>3\"\n+(define_insn \"<v>rotl<mode>3\"\n   [(set (match_operand:VHSI 0 \"spu_reg_operand\" \"=r,r\")\n \t(rotate:VHSI (match_operand:VHSI 1 \"spu_reg_operand\" \"r,r\")\n \t\t     (match_operand:VHSI 2 \"spu_nonmem_operand\" \"r,W\")))]\n@@ -3046,14 +3049,14 @@ selb\\t%0,%5,%0,%3\"\n           emit_insn (gen_iorv4si3 (a_nan, a_nan, b_nan));\n \t}\n       emit_move_insn (zero, CONST0_RTX (V4SImode));\n-      emit_insn (gen_ashrv4si3 (asel, ra, spu_const (V4SImode, 31)));\n+      emit_insn (gen_vashrv4si3 (asel, ra, spu_const (V4SImode, 31)));\n       emit_insn (gen_shufb (asel, asel, asel, hi_promote));\n       emit_insn (gen_bg_v4si (abor, zero, a_abs));\n       emit_insn (gen_shufb (abor, abor, abor, borrow_shuffle));\n       emit_insn (gen_sfx_v4si (abor, zero, a_abs, abor));\n       emit_insn (gen_selb (abor, a_abs, abor, asel));\n \n-      emit_insn (gen_ashrv4si3 (bsel, rb, spu_const (V4SImode, 31)));\n+      emit_insn (gen_vashrv4si3 (bsel, rb, spu_const (V4SImode, 31)));\n       emit_insn (gen_shufb (bsel, bsel, bsel, hi_promote));\n       emit_insn (gen_bg_v4si (bbor, zero, b_abs));\n       emit_insn (gen_shufb (bbor, bbor, bbor, borrow_shuffle));\n@@ -3154,13 +3157,13 @@ selb\\t%0,%5,%0,%3\"\n       emit_insn (gen_shufb (b_nan, b_nan, b_nan, hi_promote));\n       emit_insn (gen_iorv4si3 (a_nan, a_nan, b_nan));\n       emit_move_insn (zero, CONST0_RTX (V4SImode));\n-      emit_insn (gen_ashrv4si3 (asel, ra, spu_const (V4SImode, 31)));\n+      emit_insn (gen_vashrv4si3 (asel, ra, spu_const (V4SImode, 31)));\n       emit_insn (gen_shufb (asel, asel, asel, hi_promote));\n       emit_insn (gen_bg_v4si (abor, zero, a_abs));\n       emit_insn (gen_shufb (abor, abor, abor, borrow_shuffle));\n       emit_insn (gen_sfx_v4si (abor, zero, a_abs, abor));\n       emit_insn (gen_selb (abor, a_abs, abor, asel));\n-      emit_insn (gen_ashrv4si3 (bsel, rb, spu_const (V4SImode, 31)));\n+      emit_insn (gen_vashrv4si3 (bsel, rb, spu_const (V4SImode, 31)));\n       emit_insn (gen_shufb (bsel, bsel, bsel, hi_promote));\n       emit_insn (gen_bg_v4si (bbor, zero, b_abs));\n       emit_insn (gen_shufb (bbor, bbor, bbor, borrow_shuffle));\n@@ -3344,7 +3347,7 @@ selb\\t%0,%4,%0,%3\"\n                                              0x08090A0B, 0x08090A0B);\n           emit_move_insn (hi_promote, pat);\n \n-          emit_insn (gen_ashrv4si3 (sign, ra, spu_const (V4SImode, 31)));\n+          emit_insn (gen_vashrv4si3 (sign, ra, spu_const (V4SImode, 31)));\n           emit_insn (gen_shufb (sign, sign, sign, hi_promote));\n           emit_insn (gen_andv4si3 (abs, ra, sign_mask));\n "}, {"sha": "a8e43ead2fd3e8aaa981e760842bcedff13f3e1e", "filename": "gcc/doc/md.texi", "status": "modified", "additions": 11, "deletions": 2, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fdoc%2Fmd.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fdoc%2Fmd.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fmd.texi?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -3848,15 +3848,24 @@ operand 0 and operand 1; operand 2's mode is specified by the\n instruction pattern, and the compiler will convert the operand to that\n mode before generating the instruction.  The meaning of out-of-range shift\n counts can optionally be specified by @code{TARGET_SHIFT_TRUNCATION_MASK}.\n-@xref{TARGET_SHIFT_TRUNCATION_MASK}.\n+@xref{TARGET_SHIFT_TRUNCATION_MASK}.  Operand 2 is always a scalar type.\n \n @cindex @code{ashr@var{m}3} instruction pattern\n @cindex @code{lshr@var{m}3} instruction pattern\n @cindex @code{rotl@var{m}3} instruction pattern\n @cindex @code{rotr@var{m}3} instruction pattern\n @item @samp{ashr@var{m}3}, @samp{lshr@var{m}3}, @samp{rotl@var{m}3}, @samp{rotr@var{m}3}\n Other shift and rotate instructions, analogous to the\n-@code{ashl@var{m}3} instructions.\n+@code{ashl@var{m}3} instructions.  Operand 2 is always a scalar type.\n+\n+@cindex @code{vashl@var{m}3} instruction pattern\n+@cindex @code{vashr@var{m}3} instruction pattern\n+@cindex @code{vlshr@var{m}3} instruction pattern\n+@cindex @code{vrotl@var{m}3} instruction pattern\n+@cindex @code{vrotr@var{m}3} instruction pattern\n+@item @samp{vashl@var{m}3}, @samp{vashr@var{m}3}, @samp{vlshr@var{m}3}, @samp{vrotl@var{m}3}, @samp{vrotr@var{m}3}\n+Vector shift and rotate instructions that take vectors as operand 2\n+instead of a scalar type.\n \n @cindex @code{neg@var{m}2} instruction pattern\n @cindex @code{ssneg@var{m}2} instruction pattern"}, {"sha": "ab5057a9e8f91e24a466ce4649453c972659bfa3", "filename": "gcc/expmed.c", "status": "modified", "additions": 23, "deletions": 5, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -2044,14 +2044,32 @@ expand_shift (enum tree_code code, enum machine_mode mode, rtx shifted,\n   rtx op1, temp = 0;\n   int left = (code == LSHIFT_EXPR || code == LROTATE_EXPR);\n   int rotate = (code == LROTATE_EXPR || code == RROTATE_EXPR);\n+  optab lshift_optab = ashl_optab;\n+  optab rshift_arith_optab = ashr_optab;\n+  optab rshift_uns_optab = lshr_optab;\n+  optab lrotate_optab = rotl_optab;\n+  optab rrotate_optab = rotr_optab;\n+  enum machine_mode op1_mode;\n   int try;\n \n+  op1 = expand_normal (amount);\n+  op1_mode = GET_MODE (op1);\n+\n+  /* Determine whether the shift/rotate amount is a vector, or scalar.  If the\n+     shift amount is a vector, use the vector/vector shift patterns.  */\n+  if (VECTOR_MODE_P (mode) && VECTOR_MODE_P (op1_mode))\n+    {\n+      lshift_optab = vashl_optab;\n+      rshift_arith_optab = vashr_optab;\n+      rshift_uns_optab = vlshr_optab;\n+      lrotate_optab = vrotl_optab;\n+      rrotate_optab = vrotr_optab;\n+    }\n+\n   /* Previously detected shift-counts computed by NEGATE_EXPR\n      and shifted in the other direction; but that does not work\n      on all machines.  */\n \n-  op1 = expand_normal (amount);\n-\n   if (SHIFT_COUNT_TRUNCATED)\n     {\n       if (GET_CODE (op1) == CONST_INT\n@@ -2141,12 +2159,12 @@ expand_shift (enum tree_code code, enum machine_mode mode, rtx shifted,\n \t    }\n \n \t  temp = expand_binop (mode,\n-\t\t\t       left ? rotl_optab : rotr_optab,\n+\t\t\t       left ? lrotate_optab : rrotate_optab,\n \t\t\t       shifted, op1, target, unsignedp, methods);\n \t}\n       else if (unsignedp)\n \ttemp = expand_binop (mode,\n-\t\t\t     left ? ashl_optab : lshr_optab,\n+\t\t\t     left ? lshift_optab : rshift_uns_optab,\n \t\t\t     shifted, op1, target, unsignedp, methods);\n \n       /* Do arithmetic shifts.\n@@ -2165,7 +2183,7 @@ expand_shift (enum tree_code code, enum machine_mode mode, rtx shifted,\n \t  /* Arithmetic shift */\n \n \t  temp = expand_binop (mode,\n-\t\t\t       left ? ashl_optab : ashr_optab,\n+\t\t\t       left ? lshift_optab : rshift_arith_optab,\n \t\t\t       shifted, op1, target, unsignedp, methods1);\n \t}\n "}, {"sha": "0a0f401e9c3d91c8dbd782413ece3d895b5b42ab", "filename": "gcc/expr.c", "status": "modified", "additions": 15, "deletions": 14, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -8691,7 +8691,8 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       if (modifier == EXPAND_STACK_PARM)\n \ttarget = 0;\n       temp = expand_unop (mode,\n-      \t\t\t  optab_for_tree_code (NEGATE_EXPR, type),\n+      \t\t\t  optab_for_tree_code (NEGATE_EXPR, type,\n+\t\t\t\t\t       optab_default),\n \t\t\t  op0, target, 0);\n       gcc_assert (temp);\n       return REDUCE_BIT_FIELD (temp);\n@@ -8730,7 +8731,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       /* First try to do it with a special MIN or MAX instruction.\n \t If that does not win, use a conditional jump to select the proper\n \t value.  */\n-      this_optab = optab_for_tree_code (code, type);\n+      this_optab = optab_for_tree_code (code, type, optab_default);\n       temp = expand_binop (mode, this_optab, op0, op1, target, unsignedp,\n \t\t\t   OPTAB_WIDEN);\n       if (temp != 0)\n@@ -8868,12 +8869,11 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \n     case LROTATE_EXPR:\n     case RROTATE_EXPR:\n-      /* The expansion code only handles expansion of mode precision\n-\t rotates.  */\n-      gcc_assert (GET_MODE_PRECISION (TYPE_MODE (type))\n-\t\t  == TYPE_PRECISION (type));\n+      gcc_assert (VECTOR_MODE_P (TYPE_MODE (type))\n+\t\t  || (GET_MODE_PRECISION (TYPE_MODE (type))\n+\t\t      == TYPE_PRECISION (type)));\n+      /* fall through */\n \n-      /* Falltrough.  */\n     case LSHIFT_EXPR:\n     case RSHIFT_EXPR:\n       /* If this is a fixed-point operation, then we cannot use the code\n@@ -9215,7 +9215,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n         tree oprnd2 = TREE_OPERAND (exp, 2);\n         rtx op2;\n \n-        this_optab = optab_for_tree_code (code, type);\n+        this_optab = optab_for_tree_code (code, type, optab_default);\n         expand_operands (oprnd0, oprnd1, NULL_RTX, &op0, &op1, EXPAND_NORMAL);\n         op2 = expand_normal (oprnd2);\n         temp = expand_ternary_op (mode, this_optab, op0, op1, op2,\n@@ -9254,7 +9254,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n     case REDUC_PLUS_EXPR:\n       {\n         op0 = expand_normal (TREE_OPERAND (exp, 0));\n-        this_optab = optab_for_tree_code (code, type);\n+        this_optab = optab_for_tree_code (code, type, optab_default);\n         temp = expand_unop (mode, this_optab, op0, target, unsignedp);\n         gcc_assert (temp);\n         return temp;\n@@ -9265,7 +9265,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       {\n         expand_operands (TREE_OPERAND (exp, 0),  TREE_OPERAND (exp, 1),\n                          NULL_RTX, &op0, &op1, 0);\n-        this_optab = optab_for_tree_code (code, type);\n+        this_optab = optab_for_tree_code (code, type, optab_default);\n         temp = expand_binop (mode, this_optab, op0, op1, target, unsignedp,\n                              OPTAB_WIDEN);\n         gcc_assert (temp);\n@@ -9277,7 +9277,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       {\n         expand_operands (TREE_OPERAND (exp, 0),  TREE_OPERAND (exp, 1),\n                          NULL_RTX, &op0, &op1, 0);\n-        this_optab = optab_for_tree_code (code, type);\n+        this_optab = optab_for_tree_code (code, type, optab_default);\n         temp = expand_binop (mode, this_optab, op0, op1, target, unsignedp,\n                              OPTAB_WIDEN);\n         gcc_assert (temp);\n@@ -9295,7 +9295,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n     case VEC_UNPACK_LO_EXPR:\n       {\n \top0 = expand_normal (TREE_OPERAND (exp, 0));\n-\tthis_optab = optab_for_tree_code (code, type);\n+\tthis_optab = optab_for_tree_code (code, type, optab_default);\n \ttemp = expand_widen_pattern_expr (exp, op0, NULL_RTX, NULL_RTX,\n \t\t\t\t\t  target, unsignedp);\n \tgcc_assert (temp);\n@@ -9308,7 +9308,8 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \top0 = expand_normal (TREE_OPERAND (exp, 0));\n \t/* The signedness is determined from input operand.  */\n \tthis_optab = optab_for_tree_code (code,\n-\t\t\t\t\t  TREE_TYPE (TREE_OPERAND (exp, 0)));\n+\t\t\t\t\t  TREE_TYPE (TREE_OPERAND (exp, 0)),\n+\t\t\t\t\t  optab_default);\n \ttemp = expand_widen_pattern_expr\n \t  (exp, op0, NULL_RTX, NULL_RTX,\n \t   target, TYPE_UNSIGNED (TREE_TYPE (TREE_OPERAND (exp, 0))));\n@@ -9355,7 +9356,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n   expand_operands (TREE_OPERAND (exp, 0), TREE_OPERAND (exp, 1),\n \t\t   subtarget, &op0, &op1, 0);\n  binop2:\n-  this_optab = optab_for_tree_code (code, type);\n+  this_optab = optab_for_tree_code (code, type, optab_default);\n  binop3:\n   if (modifier == EXPAND_STACK_PARM)\n     target = 0;"}, {"sha": "f5a18a3a0c08129ab67c65ea6c5d19755e7fa43d", "filename": "gcc/genopinit.c", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fgenopinit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Fgenopinit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgenopinit.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -130,6 +130,11 @@ static const char * const optabs[] =\n   \"optab_handler (lshr_optab, $A)->insn_code = CODE_FOR_$(lshr$a3$)\",\n   \"optab_handler (rotl_optab, $A)->insn_code = CODE_FOR_$(rotl$a3$)\",\n   \"optab_handler (rotr_optab, $A)->insn_code = CODE_FOR_$(rotr$a3$)\",\n+  \"optab_handler (vashr_optab, $A)->insn_code = CODE_FOR_$(vashr$a3$)\",\n+  \"optab_handler (vlshr_optab, $A)->insn_code = CODE_FOR_$(vlshr$a3$)\",\n+  \"optab_handler (vashl_optab, $A)->insn_code = CODE_FOR_$(vashl$a3$)\",\n+  \"optab_handler (vrotl_optab, $A)->insn_code = CODE_FOR_$(vrotl$a3$)\",\n+  \"optab_handler (vrotr_optab, $A)->insn_code = CODE_FOR_$(vrotr$a3$)\",\n   \"optab_handler (smin_optab, $A)->insn_code = CODE_FOR_$(smin$a3$)\",\n   \"optab_handler (smax_optab, $A)->insn_code = CODE_FOR_$(smax$a3$)\",\n   \"optab_handler (umin_optab, $A)->insn_code = CODE_FOR_$(umin$I$a3$)\","}, {"sha": "f10b1705dd6bc6be1147ece216e1ee4e0e66a14e", "filename": "gcc/optabs.c", "status": "modified", "additions": 35, "deletions": 7, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Foptabs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Foptabs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -334,13 +334,13 @@ widen_operand (rtx op, enum machine_mode mode, enum machine_mode oldmode,\n   return result;\n }\n \f\n-/* Return the optab used for computing the operation given by\n-   the tree code, CODE.  This function is not always usable (for\n-   example, it cannot give complete results for multiplication\n-   or division) but probably ought to be relied on more widely\n-   throughout the expander.  */\n+/* Return the optab used for computing the operation given by the tree code,\n+   CODE and the tree EXP.  This function is not always usable (for example, it\n+   cannot give complete results for multiplication or division) but probably\n+   ought to be relied on more widely throughout the expander.  */\n optab\n-optab_for_tree_code (enum tree_code code, const_tree type)\n+optab_for_tree_code (enum tree_code code, const_tree type,\n+\t\t     enum optab_subtype subtype)\n {\n   bool trapv;\n   switch (code)\n@@ -374,17 +374,45 @@ optab_for_tree_code (enum tree_code code, const_tree type)\n       return TYPE_UNSIGNED (type) ? udiv_optab : sdiv_optab;\n \n     case LSHIFT_EXPR:\n+      if (VECTOR_MODE_P (TYPE_MODE (type)))\n+\t{\n+\t  if (subtype == optab_vector)\n+\t    return TYPE_SATURATING (type) ? NULL : vashl_optab;\n+\n+\t  gcc_assert (subtype == optab_scalar);\n+\t}\n       if (TYPE_SATURATING(type))\n \treturn TYPE_UNSIGNED(type) ? usashl_optab : ssashl_optab;\n       return ashl_optab;\n \n     case RSHIFT_EXPR:\n+      if (VECTOR_MODE_P (TYPE_MODE (type)))\n+\t{\n+\t  if (subtype == optab_vector)\n+\t    return TYPE_UNSIGNED (type) ? vlshr_optab : vashr_optab;\n+\n+\t  gcc_assert (subtype == optab_scalar);\n+\t}\n       return TYPE_UNSIGNED (type) ? lshr_optab : ashr_optab;\n \n     case LROTATE_EXPR:\n+      if (VECTOR_MODE_P (TYPE_MODE (type)))\n+\t{\n+\t  if (subtype == optab_vector)\n+\t    return vrotl_optab;\n+\n+\t  gcc_assert (subtype == optab_scalar);\n+\t}\n       return rotl_optab;\n \n     case RROTATE_EXPR:\n+      if (VECTOR_MODE_P (TYPE_MODE (type)))\n+\t{\n+\t  if (subtype == optab_vector)\n+\t    return vrotr_optab;\n+\n+\t  gcc_assert (subtype == optab_scalar);\n+\t}\n       return rotr_optab;\n \n     case MAX_EXPR:\n@@ -540,7 +568,7 @@ expand_widen_pattern_expr (tree exp, rtx op0, rtx op1, rtx wide_op, rtx target,\n   oprnd0 = TREE_OPERAND (exp, 0);\n   tmode0 = TYPE_MODE (TREE_TYPE (oprnd0));\n   widen_pattern_optab =\n-        optab_for_tree_code (TREE_CODE (exp), TREE_TYPE (oprnd0));\n+    optab_for_tree_code (TREE_CODE (exp), TREE_TYPE (oprnd0), optab_default);\n   icode = (int) optab_handler (widen_pattern_optab, tmode0)->insn_code;\n   gcc_assert (icode != CODE_FOR_nothing);\n   xmode0 = insn_data[icode].operand[1].mode;"}, {"sha": "0b55c4fc8cc35a974dc5cdca176967aa48bb6d0c", "filename": "gcc/optabs.h", "status": "modified", "additions": 32, "deletions": 4, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Foptabs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Foptabs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.h?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -167,6 +167,18 @@ enum optab_index\n   OTI_rotl,\n   /* Rotate right */\n   OTI_rotr,\n+\n+  /* Arithmetic shift left of vector by vector */\n+  OTI_vashl,\n+  /* Logical shift right of vector by vector */\n+  OTI_vlshr,\n+  /* Arithmetic shift right of vector by vector */\n+  OTI_vashr,\n+  /* Rotate left of vector by vector */\n+  OTI_vrotl,\n+  /* Rotate right of vector by vector */\n+  OTI_vrotr,\n+\n   /* Signed and floating-point minimum value */\n   OTI_smin,\n   /* Signed and floating-point maximum value */\n@@ -412,6 +424,11 @@ extern struct optab optab_table[OTI_MAX];\n #define ashr_optab (&optab_table[OTI_ashr])\n #define rotl_optab (&optab_table[OTI_rotl])\n #define rotr_optab (&optab_table[OTI_rotr])\n+#define vashl_optab (&optab_table[OTI_vashl])\n+#define vlshr_optab (&optab_table[OTI_vlshr])\n+#define vashr_optab (&optab_table[OTI_vashr])\n+#define vrotl_optab (&optab_table[OTI_vrotl])\n+#define vrotr_optab (&optab_table[OTI_vrotr])\n #define smin_optab (&optab_table[OTI_smin])\n #define smax_optab (&optab_table[OTI_smax])\n #define umin_optab (&optab_table[OTI_umin])\n@@ -714,6 +731,21 @@ extern void maybe_encapsulate_block (rtx, rtx, rtx);\n extern void emit_cmp_insn (rtx, rtx, enum rtx_code, rtx, enum machine_mode,\n \t\t\t   int);\n \n+/* An extra flag to control optab_for_tree_code's behavior.  This is needed to\n+   distinguish between machines with a vector shift that takes a scalar for the\n+   shift amount vs. machines that take a vector for the shift amount.  */\n+enum optab_subtype\n+{\n+  optab_default,\n+  optab_scalar,\n+  optab_vector\n+};\n+\n+/* Return the optab used for computing the given operation on the type given by\n+   the second argument.  The third argument distinguishes between the types of\n+   vector shifts and rotates */\n+extern optab optab_for_tree_code (enum tree_code, const_tree, enum optab_subtype);\n+\n /* The various uses that a comparison can have; used by can_compare_p:\n    jumps, conditional moves, store flag operations.  */\n enum can_compare_purpose\n@@ -723,10 +755,6 @@ enum can_compare_purpose\n   ccp_store_flag\n };\n \n-/* Return the optab used for computing the given operation on the type\n-   given by the second argument.  */\n-extern optab optab_for_tree_code (enum tree_code, const_tree);\n-\n /* Nonzero if a compare of mode MODE can be done straightforwardly\n    (without splitting it into pieces).  */\n extern int can_compare_p (enum rtx_code, enum machine_mode,"}, {"sha": "ab790da0667499d056d99bc8d12ebce3e387fb99", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -1,3 +1,16 @@\n+2008-05-14  Michael Meissner  <michael.meissner@amd.com>\n+\t    Dwarakanath Rajagopal  <dwarak.rajagopal@amd.com>\n+\n+\t* gcc.target/i386/sse5-imul32widen-vector.c: New file to test x86\n+\tSSE5 optimizations.\n+\t* gcc.target/i386/sse5-imul64-vector.c: Ditto.\n+\t* gcc.target/i386/sse5-rotate1-vector.c: Ditto.\n+\t* gcc.target/i386/sse5-rotate2-vector.c: Ditto.\n+\t* gcc.target/i386/sse5-rotate3-vector.c: Ditto.\n+\t* gcc.target/i386/sse5-shift1-vector.c: Ditto.\n+\t* gcc.target/i386/sse5-shift2-vector.c: Ditto.\n+\t* gcc.target/i386/sse5-shift3-vector.c: Ditto.\n+\n 2008-05-14  Michael Meissner  <michael.meissner@amd.com>\n \n \tPR target/36224"}, {"sha": "ef29d081473f2f9c2ca886b32e997af8f64a316b", "filename": "gcc/testsuite/gcc.target/i386/sse5-imul32widen-vector.c", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-imul32widen-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-imul32widen-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-imul32widen-vector.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -0,0 +1,36 @@\n+/* Test that the compiler properly optimizes floating point multiply and add\n+   instructions vector into pmacsdd/etc. on SSE5 systems.  */\n+\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long __m128i  __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i i_align;\n+  int i32[SIZE];\n+  long i64[SIZE];\n+} a, b, c, d;\n+\n+void\n+imul32_to_64 (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.i64[i] = ((long)b.i32[i]) * ((long)c.i32[i]);\n+}\n+\n+int main ()\n+{\n+  imul32_to_64 ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"pmacsdql\" } } */\n+/* { dg-final { scan-assembler \"pmacsdqh\" } } */"}, {"sha": "06ad1d2e96e07a3997f702535fdd47e0c24ae95d", "filename": "gcc/testsuite/gcc.target/i386/sse5-imul64-vector.c", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-imul64-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-imul64-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-imul64-vector.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -0,0 +1,36 @@\n+/* Test that the compiler properly optimizes floating point multiply and add\n+   instructions vector into pmacsdd/etc. on SSE5 systems.  */\n+\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long __m128i  __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i i_align;\n+  long i64[SIZE];\n+} a, b, c, d;\n+\n+void\n+imul64 (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.i64[i] = b.i64[i] * c.i64[i];\n+}\n+\n+int main ()\n+{\n+  imul64 ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"pmacsdd\" } } */\n+/* { dg-final { scan-assembler \"phadddq\" } } */\n+/* { dg-final { scan-assembler \"pmacsdql\" } } */"}, {"sha": "0db9b9f790a0400e697043aadc638fe11a560ce2", "filename": "gcc/testsuite/gcc.target/i386/sse5-rotate1-vector.c", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate1-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate1-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate1-vector.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -0,0 +1,35 @@\n+/* Test that the compiler properly optimizes vector rotate instructions vector\n+   into prot on SSE5 systems.  */\n+\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long __m128i  __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i i_align;\n+  unsigned u32[SIZE];\n+} a, b, c;\n+\n+void\n+left_rotate32 (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.u32[i] = (b.u32[i] << ((sizeof (int) * 8) - 4)) | (b.u32[i] >> 4);\n+}\n+\n+int\n+main ()\n+{\n+  left_rotate32 ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"protd\" } } */"}, {"sha": "4ea762a208ee79ec0fab3fb3fb12d33f3c4799f6", "filename": "gcc/testsuite/gcc.target/i386/sse5-rotate2-vector.c", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate2-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate2-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate2-vector.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -0,0 +1,35 @@\n+/* Test that the compiler properly optimizes vector rotate instructions vector\n+   into prot on SSE5 systems.  */\n+\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long __m128i  __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i i_align;\n+  unsigned u32[SIZE];\n+} a, b, c;\n+\n+void\n+right_rotate32_b (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.u32[i] = (b.u32[i] >> ((sizeof (int) * 8) - 4)) | (b.u32[i] << 4);\n+}\n+\n+int\n+main ()\n+{\n+  right_rotate ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"prot\" } } */"}, {"sha": "de7272439ab44f5a21d08b731faf08c9a81ec026", "filename": "gcc/testsuite/gcc.target/i386/sse5-rotate3-vector.c", "status": "added", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate3-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate3-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-rotate3-vector.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -0,0 +1,34 @@\n+/* Test that the compiler properly optimizes vector rotate instructions vector\n+   into prot on SSE5 systems.  */\n+\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long __m128i  __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i i_align;\n+  unsigned u32[SIZE];\n+} a, b, c;\n+\n+void\n+vector_rotate32 (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.u32[i] = (b.u32[i] >> ((sizeof (int) * 8) - c.u32[i])) | (b.u32[i] << c.u32[i]);\n+}\n+\n+int main ()\n+{\n+  vector_rotate32 ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"protd\" } } */"}, {"sha": "c1ce023263cf246c3c72ce362f8adc6d642ddf4c", "filename": "gcc/testsuite/gcc.target/i386/sse5-shift1-vector.c", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift1-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift1-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift1-vector.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -0,0 +1,35 @@\n+/* Test that the compiler properly optimizes vector shift instructions into\n+   psha/pshl on SSE5 systems.  */\n+\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long __m128i  __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i i_align;\n+  int i32[SIZE];\n+  unsigned u32[SIZE];\n+} a, b, c;\n+\n+void\n+left_shift32 (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.i32[i] = b.i32[i] << c.i32[i];\n+}\n+\n+int main ()\n+{\n+  left_shfit32 ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"pshad\" } } */"}, {"sha": "c0d97bc3d4aba1159c2ada02d4918599c2b2fc91", "filename": "gcc/testsuite/gcc.target/i386/sse5-shift2-vector.c", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift2-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift2-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift2-vector.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -0,0 +1,35 @@\n+/* Test that the compiler properly optimizes vector shift instructions into\n+   psha/pshl on SSE5 systems.  */\n+\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long __m128i  __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i i_align;\n+  int i32[SIZE];\n+  unsigned u32[SIZE];\n+} a, b, c;\n+\n+void\n+right_sign_shift32 (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.i32[i] = b.i32[i] >> c.i32[i];\n+}\n+\n+int main ()\n+{\n+  right_sign_shfit32 ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"pshad\" } } */"}, {"sha": "0027457e384c42dff7ef77a38728baa923123164", "filename": "gcc/testsuite/gcc.target/i386/sse5-shift3-vector.c", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift3-vector.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift3-vector.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse5-shift3-vector.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -0,0 +1,35 @@\n+/* Test that the compiler properly optimizes vector shift instructions into\n+   psha/pshl on SSE5 systems.  */\n+\n+/* { dg-do compile } */\n+/* { dg-require-effective-target lp64 } */\n+/* { dg-options \"-O2 -msse5 -ftree-vectorize\" } */\n+\n+extern void exit (int);\n+\n+typedef long __m128i  __attribute__ ((__vector_size__ (16), __may_alias__));\n+\n+#define SIZE 10240\n+\n+union {\n+  __m128i i_align;\n+  int i32[SIZE];\n+  unsigned u32[SIZE];\n+} a, b, c;\n+\n+void\n+right_uns_shift32 (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < SIZE; i++)\n+    a.u32[i] = b.u32[i] >> c.i32[i];\n+}\n+\n+int main ()\n+{\n+  right_uns_shfit32 ();\n+  exit (0);\n+}\n+\n+/* { dg-final { scan-assembler \"pshld\" } } */"}, {"sha": "66d83a5c32808d9becf32507b3bf1bde46d6ab80", "filename": "gcc/tree-vect-analyze.c", "status": "modified", "additions": 35, "deletions": 20, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vect-analyze.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vect-analyze.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-analyze.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -2706,29 +2706,44 @@ vect_build_slp_tree (loop_vec_info loop_vinfo, slp_tree *node,\n \n \t  /* Shift arguments should be equal in all the packed stmts for a \n \t     vector shift with scalar shift operand.  */\n-\t  if (TREE_CODE (rhs) == LSHIFT_EXPR || TREE_CODE (rhs) == RSHIFT_EXPR)\n+\t  if (TREE_CODE (rhs) == LSHIFT_EXPR || TREE_CODE (rhs) == RSHIFT_EXPR\n+\t      || TREE_CODE (rhs) == LROTATE_EXPR\n+\t      || TREE_CODE (rhs) == RROTATE_EXPR)\n \t    {\n \t      vec_mode = TYPE_MODE (vectype);\n-\t      optab = optab_for_tree_code (TREE_CODE (rhs), vectype);\n-\t      if (!optab)\n-\t\t{\n-\t\t  if (vect_print_dump_info (REPORT_SLP))\n-\t\t    fprintf (vect_dump, \"Build SLP failed: no optab.\");\n-\t\t  return false;\n-\t\t}\n-\t      icode = (int) optab->handlers[(int) vec_mode].insn_code;\n-\t      if (icode == CODE_FOR_nothing)\n-\t\t{\n-\t\t  if (vect_print_dump_info (REPORT_SLP))\n-\t\t    fprintf (vect_dump,\n-\t\t\t     \"Build SLP failed: op not supported by target.\");\n-\t\t  return false;\n-\t\t}\n-\t      optab_op2_mode = insn_data[icode].operand[2].mode;\n-\t      if (!VECTOR_MODE_P (optab_op2_mode))\n+\n+\t      /* First see if we have a vector/vector shift.  */\n+\t      optab = optab_for_tree_code (TREE_CODE (rhs), vectype,\n+\t\t\t\t\t   optab_vector);\n+\n+\t      if (!optab\n+\t\t  || (optab->handlers[(int) vec_mode].insn_code\n+\t\t      == CODE_FOR_nothing))\n \t\t{\n-\t\t  need_same_oprnds = true;\n-\t\t  first_op1 = TREE_OPERAND (rhs, 1);\n+\t\t  /* No vector/vector shift, try for a vector/scalar shift.  */\n+\t\t  optab = optab_for_tree_code (TREE_CODE (rhs), vectype,\n+\t\t\t\t\t       optab_scalar);\n+\n+\t\t  if (!optab)\n+\t\t    {\n+\t\t      if (vect_print_dump_info (REPORT_SLP))\n+\t\t\tfprintf (vect_dump, \"Build SLP failed: no optab.\");\n+\t\t      return false;\n+\t\t    }\n+\t\t  icode = (int) optab->handlers[(int) vec_mode].insn_code;\n+\t\t  if (icode == CODE_FOR_nothing)\n+\t\t    {\n+\t\t      if (vect_print_dump_info (REPORT_SLP))\n+\t\t\tfprintf (vect_dump,\n+\t\t\t\t \"Build SLP failed: op not supported by target.\");\n+\t\t      return false;\n+\t\t    }\n+\t\t  optab_op2_mode = insn_data[icode].operand[2].mode;\n+\t\t  if (!VECTOR_MODE_P (optab_op2_mode))\n+\t\t    {\n+\t\t      need_same_oprnds = true;\n+\t\t      first_op1 = TREE_OPERAND (rhs, 1);\n+\t\t    }\n \t\t}\n \t    }\n \t}"}, {"sha": "8313e54bdbc34eeb91782eb8dafa7731389c623b", "filename": "gcc/tree-vect-generic.c", "status": "modified", "additions": 23, "deletions": 2, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vect-generic.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vect-generic.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-generic.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -437,7 +437,28 @@ expand_vector_operations_1 (block_stmt_iterator *bsi)\n       || code == VEC_UNPACK_FLOAT_LO_EXPR)\n     type = TREE_TYPE (TREE_OPERAND (rhs, 0));\n \n-  op = optab_for_tree_code (code, type);\n+  /* Choose between vector shift/rotate by vector and vector shift/rotate by\n+     scalar */\n+  if (code == LSHIFT_EXPR || code == RSHIFT_EXPR || code == LROTATE_EXPR\n+      || code == RROTATE_EXPR)\n+    {\n+      /* If the 2nd argument is vector, we need a vector/vector shift */\n+      if (VECTOR_MODE_P (TYPE_MODE (TREE_TYPE (TREE_OPERAND (rhs, 1)))))\n+\top = optab_for_tree_code (code, type, optab_vector);\n+\n+      else\n+\t{\n+\t  /* Try for a vector/scalar shift, and if we don't have one, see if we\n+\t     have a vector/vector shift */\n+\t  op = optab_for_tree_code (code, type, optab_scalar);\n+\t  if (!op\n+\t      || (op->handlers[(int) TYPE_MODE (type)].insn_code\n+\t\t  == CODE_FOR_nothing))\n+\t    op = optab_for_tree_code (code, type, optab_vector);\n+\t}\n+    }\n+  else\n+    op = optab_for_tree_code (code, type, optab_default);\n \n   /* For widening/narrowing vector operations, the relevant type is of the \n      arguments, not the widened result.  VEC_UNPACK_FLOAT_*_EXPR is\n@@ -458,7 +479,7 @@ expand_vector_operations_1 (block_stmt_iterator *bsi)\n   if (op == NULL\n       && code == NEGATE_EXPR\n       && INTEGRAL_TYPE_P (TREE_TYPE (type)))\n-    op = optab_for_tree_code (MINUS_EXPR, type);\n+    op = optab_for_tree_code (MINUS_EXPR, type, optab_default);\n \n   /* For very wide vectors, try using a smaller vector mode.  */\n   compute_type = type;"}, {"sha": "b9a302d8430b01d99afc466bee52be3bd4eaeb37", "filename": "gcc/tree-vect-patterns.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vect-patterns.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vect-patterns.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-patterns.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -685,7 +685,8 @@ vect_pattern_recog_1 (\n       if (!pattern_vectype)\n         return;\n \n-      optab = optab_for_tree_code (TREE_CODE (pattern_expr), pattern_vectype);\n+      optab = optab_for_tree_code (TREE_CODE (pattern_expr), pattern_vectype,\n+\t\t\t\t   optab_default);\n       vec_mode = TYPE_MODE (pattern_vectype);\n       if (!optab\n           || (icode = optab_handler (optab, vec_mode)->insn_code) =="}, {"sha": "82a4c84893a80ee3f459f669d75e0268fdb86ae1", "filename": "gcc/tree-vect-transform.c", "status": "modified", "additions": 62, "deletions": 35, "changes": 97, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vect-transform.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vect-transform.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-transform.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -502,7 +502,7 @@ vect_model_reduction_cost (stmt_vec_info stmt_info, enum tree_code reduc_code,\n \t  int element_bitsize = tree_low_cst (bitsize, 1);\n \t  int nelements = vec_size_in_bits / element_bitsize;\n \n-\t  optab = optab_for_tree_code (code, vectype);\n+\t  optab = optab_for_tree_code (code, vectype, optab_default);\n \n \t  /* We have a whole vector shift available.  */\n \t  if (VECTOR_MODE_P (mode)\n@@ -2458,7 +2458,7 @@ vect_create_epilog_for_reduction (tree vect_def, tree stmt,\n \thave_whole_vector_shift = false;\n       else\n \t{\n-\t  optab optab = optab_for_tree_code (code, vectype);\n+\t  optab optab = optab_for_tree_code (code, vectype, optab_default);\n \t  if (optab_handler (optab, mode)->insn_code == CODE_FOR_nothing)\n \t    have_whole_vector_shift = false;\n \t}\n@@ -2818,7 +2818,7 @@ vectorizable_reduction (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt)\n   /* 4. Supportable by target?  */\n \n   /* 4.1. check support for the operation in the loop  */\n-  optab = optab_for_tree_code (code, vectype);\n+  optab = optab_for_tree_code (code, vectype, optab_default);\n   if (!optab)\n     {\n       if (vect_print_dump_info (REPORT_DETAILS))\n@@ -2909,7 +2909,7 @@ vectorizable_reduction (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt)\n \n   if (!reduction_code_for_scalar_code (orig_code, &epilog_reduc_code))\n     return false;\n-  reduc_optab = optab_for_tree_code (epilog_reduc_code, vectype);\n+  reduc_optab = optab_for_tree_code (epilog_reduc_code, vectype, optab_default);\n   if (!reduc_optab)\n     {\n       if (vect_print_dump_info (REPORT_DETAILS))\n@@ -3852,6 +3852,7 @@ vectorizable_operation (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt,\n   VEC(tree,heap) *vec_oprnds0 = NULL, *vec_oprnds1 = NULL;\n   tree vop0, vop1;\n   unsigned int k;\n+  bool shift_p = false;\n   bool scalar_shift_arg = false;\n \n   /* FORNOW: SLP with multiple types is not supported. The SLP analysis verifies\n@@ -3896,8 +3897,6 @@ vectorizable_operation (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt,\n   if (code == POINTER_PLUS_EXPR)\n     code = PLUS_EXPR;\n \n-  optab = optab_for_tree_code (code, vectype);\n-\n   /* Support only unary or binary operations.  */\n   op_type = TREE_OPERAND_LENGTH (operation);\n   if (op_type != unary_op && op_type != binary_op)\n@@ -3926,6 +3925,56 @@ vectorizable_operation (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt,\n \t}\n     }\n \n+  /* If this is a shift/rotate, determine whether the shift amount is a vector,\n+     or scalar.  If the shift/rotate amount is a vector, use the vector/vector\n+     shift optabs.  */\n+  if (code == LSHIFT_EXPR || code == RSHIFT_EXPR || code == LROTATE_EXPR\n+      || code == RROTATE_EXPR)\n+    {\n+      shift_p = true;\n+\n+      /* vector shifted by vector */\n+      if (dt[1] == vect_loop_def)\n+\t{\n+\t  optab = optab_for_tree_code (code, vectype, optab_vector);\n+\t  if (vect_print_dump_info (REPORT_DETAILS))\n+\t    fprintf (vect_dump, \"vector/vector shift/rotate found.\");\n+\t}\n+\n+      /* See if the machine has a vector shifted by scalar insn and if not\n+\t then see if it has a vector shifted by vector insn */\n+      else if (dt[1] == vect_constant_def || dt[1] == vect_invariant_def)\n+\t{\n+\t  optab = optab_for_tree_code (code, vectype, optab_scalar);\n+\t  if (optab\n+\t      && (optab_handler (optab, TYPE_MODE (vectype))->insn_code\n+\t\t  != CODE_FOR_nothing))\n+\t    {\n+\t      scalar_shift_arg = true;\n+\t      if (vect_print_dump_info (REPORT_DETAILS))\n+\t\tfprintf (vect_dump, \"vector/scalar shift/rotate found.\");\n+\t    }\n+\t  else\n+\t    {\n+\t      optab = optab_for_tree_code (code, vectype, optab_vector);\n+\t      if (vect_print_dump_info (REPORT_DETAILS)\n+\t\t  && optab\n+\t\t  && (optab_handler (optab, TYPE_MODE (vectype))->insn_code\n+\t\t      != CODE_FOR_nothing))\n+\t\tfprintf (vect_dump, \"vector/vector shift/rotate found.\");\n+\t    }\n+\t}\n+\n+      else\n+\t{\n+\t  if (vect_print_dump_info (REPORT_DETAILS))\n+\t    fprintf (vect_dump, \"operand mode requires invariant argument.\");\n+\t  return false;\n+\t}\n+    }\n+  else\n+    optab = optab_for_tree_code (code, vectype, optab_default);\n+\n   /* Supportable by target?  */\n   if (!optab)\n     {\n@@ -3960,29 +4009,6 @@ vectorizable_operation (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt,\n       return false;\n     }\n \n-  if (code == LSHIFT_EXPR || code == RSHIFT_EXPR)\n-    {\n-      /* FORNOW: not yet supported.  */\n-      if (!VECTOR_MODE_P (vec_mode))\n-\treturn false;\n-\n-      /* Invariant argument is needed for a vector shift\n-\t by a scalar shift operand.  */\n-      optab_op2_mode = insn_data[icode].operand[2].mode;\n-      if (!VECTOR_MODE_P (optab_op2_mode))\n-\t{\n-\t  if (dt[1] != vect_constant_def && dt[1] != vect_invariant_def)\n-\t    {\n-\t      if (vect_print_dump_info (REPORT_DETAILS))\n-\t        fprintf (vect_dump, \"operand mode requires invariant\"\n-                                    \" argument.\");\n-\t      return false;\n-\t    }\n-\n-          scalar_shift_arg = true;\n-        }\n-    }\n-\n   if (!vec_stmt) /* transformation not required.  */\n     {\n       STMT_VINFO_TYPE (stmt_info) = op_vec_info_type;\n@@ -4075,8 +4101,7 @@ vectorizable_operation (tree stmt, block_stmt_iterator *bsi, tree *vec_stmt,\n       /* Handle uses.  */\n       if (j == 0)\n \t{\n-\t  if (op_type == binary_op\n-\t      && (code == LSHIFT_EXPR || code == RSHIFT_EXPR))\n+\t  if (op_type == binary_op && scalar_shift_arg)\n \t    {\n \t      /* Vector shl and shr insn patterns can be defined with scalar \n \t\t operand 2 (shift operand). In this case, use constant or loop \n@@ -4495,9 +4520,9 @@ vect_strided_store_supported (tree vectype)\n       \n   /* Check that the operation is supported.  */\n   interleave_high_optab = optab_for_tree_code (VEC_INTERLEAVE_HIGH_EXPR, \n-\t\t\t\t\t       vectype);\n+\t\t\t\t\t       vectype, optab_default);\n   interleave_low_optab = optab_for_tree_code (VEC_INTERLEAVE_LOW_EXPR, \n-\t\t\t\t\t      vectype);\n+\t\t\t\t\t      vectype, optab_default);\n   if (!interleave_high_optab || !interleave_low_optab)\n     {\n       if (vect_print_dump_info (REPORT_DETAILS))\n@@ -5238,7 +5263,8 @@ vect_strided_load_supported (tree vectype)\n \n   mode = (int) TYPE_MODE (vectype);\n \n-  perm_even_optab = optab_for_tree_code (VEC_EXTRACT_EVEN_EXPR, vectype);\n+  perm_even_optab = optab_for_tree_code (VEC_EXTRACT_EVEN_EXPR, vectype,\n+\t\t\t\t\t optab_default);\n   if (!perm_even_optab)\n     {\n       if (vect_print_dump_info (REPORT_DETAILS))\n@@ -5253,7 +5279,8 @@ vect_strided_load_supported (tree vectype)\n       return false;\n     }\n \n-  perm_odd_optab = optab_for_tree_code (VEC_EXTRACT_ODD_EXPR, vectype);\n+  perm_odd_optab = optab_for_tree_code (VEC_EXTRACT_ODD_EXPR, vectype,\n+\t\t\t\t\toptab_default);\n   if (!perm_odd_optab)\n     {\n       if (vect_print_dump_info (REPORT_DETAILS))"}, {"sha": "79a7461a1a9aee75d9deba700ab1ae5bf40c2ca1", "filename": "gcc/tree-vectorizer.c", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vectorizer.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245/gcc%2Ftree-vectorizer.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.c?ref=71d46ca56cb36baa54ec8a1de7cbc0fda9ae3245", "patch": "@@ -2211,13 +2211,13 @@ supportable_widening_operation (enum tree_code code, tree stmt, tree vectype,\n   if (code == FIX_TRUNC_EXPR)\n     {\n       /* The signedness is determined from output operand.  */\n-      optab1 = optab_for_tree_code (c1, type);\n-      optab2 = optab_for_tree_code (c2, type);\n+      optab1 = optab_for_tree_code (c1, type, optab_default);\n+      optab2 = optab_for_tree_code (c2, type, optab_default);\n     }\n   else\n     {\n-      optab1 = optab_for_tree_code (c1, vectype);\n-      optab2 = optab_for_tree_code (c2, vectype);\n+      optab1 = optab_for_tree_code (c1, vectype, optab_default);\n+      optab2 = optab_for_tree_code (c2, vectype, optab_default);\n     }\n \n   if (!optab1 || !optab2)\n@@ -2285,9 +2285,9 @@ supportable_narrowing_operation (enum tree_code code,\n \n   if (code == FIX_TRUNC_EXPR)\n     /* The signedness is determined from output operand.  */\n-    optab1 = optab_for_tree_code (c1, type);\n+    optab1 = optab_for_tree_code (c1, type, optab_default);\n   else\n-    optab1 = optab_for_tree_code (c1, vectype);\n+    optab1 = optab_for_tree_code (c1, vectype, optab_default);\n \n   if (!optab1)\n     return false;"}]}