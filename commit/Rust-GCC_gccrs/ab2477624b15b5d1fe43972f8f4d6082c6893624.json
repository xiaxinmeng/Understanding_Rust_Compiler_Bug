{"sha": "ab2477624b15b5d1fe43972f8f4d6082c6893624", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWIyNDc3NjI0YjE1YjVkMWZlNDM5NzJmOGY0ZDYwODJjNjg5MzYyNA==", "commit": {"author": {"name": "Maxim Kuvyrkov", "email": "maxim@codesourcery.com", "date": "2010-12-02T15:47:08Z"}, "committer": {"name": "Maxim Kuvyrkov", "email": "mkuvyrkov@gcc.gnu.org", "date": "2010-12-02T15:47:08Z"}, "message": "Define tuning for Core 2 and Core i7.\n\n\t* config/i386/i386-c.c (ix86_target_macros_internal): Update.\n\t* config/i386/i386.c (core2_cost): Delete, use generic costs instead.\n\t(m_CORE2): Replace with m_CORE2_{32,64}.\n\t(m_CORE2I7{,_32,_64}): New macros.\n\t(m_GENERIC32, m_GENERIC64): Update.\n\t(initial_ix86_tune_features, x86_accumulate_outgoing_args,)\n\t(x86_arch_always_fancy_math_387): Set m_CORE2I7_32 iff m_GENERIC32 and\n\tset m_CORE2I7_64 iff m_GENERIC64.\n\t(processor_target_table): Use generic costs for Core 2 and Core i7.\n\t(ix86_option_override_internal): Update entries for Core 2 and Core i7.\n\t(ix86_issue_rate): Remove entry for Core 2.\n\t(ia32_multipass_dfa_lookahead, ix86_sched_init_global): Update.\n\t* config/i386/i386.h (TARGET_CORE2_32, TARGET_CORE2_64): New macros.\n\t(TARGET_CORE2): Update.\n\t(PROCESSOR_CORE2_32, PROCESSOR_CORE2_64): New constants.\n\t(PROCESSOR_CORE2): Remove.\n\nFrom-SVN: r167374", "tree": {"sha": "81a98591b01fce240d4525e1e3aed774ea86a694", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/81a98591b01fce240d4525e1e3aed774ea86a694"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ab2477624b15b5d1fe43972f8f4d6082c6893624", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ab2477624b15b5d1fe43972f8f4d6082c6893624", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ab2477624b15b5d1fe43972f8f4d6082c6893624", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ab2477624b15b5d1fe43972f8f4d6082c6893624/comments", "author": null, "committer": null, "parents": [{"sha": "edaadf74d4cd2bc4f0ef72456a4a6df8a4502470", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/edaadf74d4cd2bc4f0ef72456a4a6df8a4502470", "html_url": "https://github.com/Rust-GCC/gccrs/commit/edaadf74d4cd2bc4f0ef72456a4a6df8a4502470"}], "stats": {"total": 203, "additions": 84, "deletions": 119}, "files": [{"sha": "6d851c1350d2f221acd2e0f94e002c8a082a3b43", "filename": "gcc/ChangeLog", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ab2477624b15b5d1fe43972f8f4d6082c6893624/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ab2477624b15b5d1fe43972f8f4d6082c6893624/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ab2477624b15b5d1fe43972f8f4d6082c6893624", "patch": "@@ -1,3 +1,24 @@\n+2010-12-02  Maxim Kuvyrkov  <maxim@codesourcery.com>\n+\n+\tDefine tuning for Core 2 and Core i7.\n+\n+\t* config/i386/i386-c.c (ix86_target_macros_internal): Update.\n+\t* config/i386/i386.c (core2_cost): Delete, use generic costs instead.\n+\t(m_CORE2): Replace with m_CORE2_{32,64}.\n+\t(m_CORE2I7{,_32,_64}): New macros.\n+\t(m_GENERIC32, m_GENERIC64): Update.\n+\t(initial_ix86_tune_features, x86_accumulate_outgoing_args,)\n+\t(x86_arch_always_fancy_math_387): Set m_CORE2I7_32 iff m_GENERIC32 and\n+\tset m_CORE2I7_64 iff m_GENERIC64.\n+\t(processor_target_table): Use generic costs for Core 2 and Core i7.\n+\t(ix86_option_override_internal): Update entries for Core 2 and Core i7.\n+\t(ix86_issue_rate): Remove entry for Core 2.\n+\t(ia32_multipass_dfa_lookahead, ix86_sched_init_global): Update.\n+\t* config/i386/i386.h (TARGET_CORE2_32, TARGET_CORE2_64): New macros.\n+\t(TARGET_CORE2): Update.\n+\t(PROCESSOR_CORE2_32, PROCESSOR_CORE2_64): New constants.\n+\t(PROCESSOR_CORE2): Remove.\n+\n 2010-12-02  Richard Guenther  <rguenther@suse.de>\n \n \t* lto-streamer.h (LTO_major_version): Bump to 2."}, {"sha": "6adf61367916fab3dda860ce6a7e95801a4a92ac", "filename": "gcc/config/i386/i386-c.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ab2477624b15b5d1fe43972f8f4d6082c6893624/gcc%2Fconfig%2Fi386%2Fi386-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ab2477624b15b5d1fe43972f8f4d6082c6893624/gcc%2Fconfig%2Fi386%2Fi386-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-c.c?ref=ab2477624b15b5d1fe43972f8f4d6082c6893624", "patch": "@@ -118,7 +118,8 @@ ix86_target_macros_internal (int isa_flag,\n       def_or_undef (parse_in, \"__nocona\");\n       def_or_undef (parse_in, \"__nocona__\");\n       break;\n-    case PROCESSOR_CORE2:\n+    case PROCESSOR_CORE2_32:\n+    case PROCESSOR_CORE2_64:\n       def_or_undef (parse_in, \"__core2\");\n       def_or_undef (parse_in, \"__core2__\");\n       break;\n@@ -199,7 +200,8 @@ ix86_target_macros_internal (int isa_flag,\n     case PROCESSOR_NOCONA:\n       def_or_undef (parse_in, \"__tune_nocona__\");\n       break;\n-    case PROCESSOR_CORE2:\n+    case PROCESSOR_CORE2_32:\n+    case PROCESSOR_CORE2_64:\n       def_or_undef (parse_in, \"__tune_core2__\");\n       break;\n     case PROCESSOR_COREI7_32:"}, {"sha": "93c105dd658a6f304dd6aa4aec06281127ae3ddc", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 54, "deletions": 115, "changes": 169, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ab2477624b15b5d1fe43972f8f4d6082c6893624/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ab2477624b15b5d1fe43972f8f4d6082c6893624/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=ab2477624b15b5d1fe43972f8f4d6082c6893624", "patch": "@@ -1409,79 +1409,6 @@ struct processor_costs nocona_cost = {\n   1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n };\n \n-static const\n-struct processor_costs core2_cost = {\n-  COSTS_N_INSNS (1),\t\t\t/* cost of an add instruction */\n-  COSTS_N_INSNS (1) + 1,\t\t/* cost of a lea instruction */\n-  COSTS_N_INSNS (1),\t\t\t/* variable shift costs */\n-  COSTS_N_INSNS (1),\t\t\t/* constant shift costs */\n-  {COSTS_N_INSNS (3),\t\t\t/* cost of starting multiply for QI */\n-   COSTS_N_INSNS (3),\t\t\t/*\t\t\t\t HI */\n-   COSTS_N_INSNS (3),\t\t\t/*\t\t\t\t SI */\n-   COSTS_N_INSNS (3),\t\t\t/*\t\t\t\t DI */\n-   COSTS_N_INSNS (3)},\t\t\t/*\t\t\t      other */\n-  0,\t\t\t\t\t/* cost of multiply per each bit set */\n-  {COSTS_N_INSNS (22),\t\t\t/* cost of a divide/mod for QI */\n-   COSTS_N_INSNS (22),\t\t\t/*\t\t\t    HI */\n-   COSTS_N_INSNS (22),\t\t\t/*\t\t\t    SI */\n-   COSTS_N_INSNS (22),\t\t\t/*\t\t\t    DI */\n-   COSTS_N_INSNS (22)},\t\t\t/*\t\t\t    other */\n-  COSTS_N_INSNS (1),\t\t\t/* cost of movsx */\n-  COSTS_N_INSNS (1),\t\t\t/* cost of movzx */\n-  8,\t\t\t\t\t/* \"large\" insn */\n-  16,\t\t\t\t\t/* MOVE_RATIO */\n-  2,\t\t\t\t     /* cost for loading QImode using movzbl */\n-  {6, 6, 6},\t\t\t\t/* cost of loading integer registers\n-\t\t\t\t\t   in QImode, HImode and SImode.\n-\t\t\t\t\t   Relative to reg-reg move (2).  */\n-  {4, 4, 4},\t\t\t\t/* cost of storing integer registers */\n-  2,\t\t\t\t\t/* cost of reg,reg fld/fst */\n-  {6, 6, 6},\t\t\t\t/* cost of loading fp registers\n-\t\t\t\t\t   in SFmode, DFmode and XFmode */\n-  {4, 4, 4},\t\t\t\t/* cost of storing fp registers\n-\t\t\t\t\t   in SFmode, DFmode and XFmode */\n-  2,\t\t\t\t\t/* cost of moving MMX register */\n-  {6, 6},\t\t\t\t/* cost of loading MMX registers\n-\t\t\t\t\t   in SImode and DImode */\n-  {4, 4},\t\t\t\t/* cost of storing MMX registers\n-\t\t\t\t\t   in SImode and DImode */\n-  2,\t\t\t\t\t/* cost of moving SSE register */\n-  {6, 6, 6},\t\t\t\t/* cost of loading SSE registers\n-\t\t\t\t\t   in SImode, DImode and TImode */\n-  {4, 4, 4},\t\t\t\t/* cost of storing SSE registers\n-\t\t\t\t\t   in SImode, DImode and TImode */\n-  2,\t\t\t\t\t/* MMX or SSE register to integer */\n-  32,\t\t\t\t\t/* size of l1 cache.  */\n-  2048,\t\t\t\t\t/* size of l2 cache.  */\n-  128,\t\t\t\t\t/* size of prefetch block */\n-  8,\t\t\t\t\t/* number of parallel prefetches */\n-  3,\t\t\t\t\t/* Branch cost */\n-  COSTS_N_INSNS (3),\t\t\t/* cost of FADD and FSUB insns.  */\n-  COSTS_N_INSNS (5),\t\t\t/* cost of FMUL instruction.  */\n-  COSTS_N_INSNS (32),\t\t\t/* cost of FDIV instruction.  */\n-  COSTS_N_INSNS (1),\t\t\t/* cost of FABS instruction.  */\n-  COSTS_N_INSNS (1),\t\t\t/* cost of FCHS instruction.  */\n-  COSTS_N_INSNS (58),\t\t\t/* cost of FSQRT instruction.  */\n-  {{libcall, {{11, loop}, {-1, rep_prefix_4_byte}}},\n-   {libcall, {{32, loop}, {64, rep_prefix_4_byte},\n-\t      {8192, rep_prefix_8_byte}, {-1, libcall}}}},\n-  {{libcall, {{8, loop}, {15, unrolled_loop},\n-\t      {2048, rep_prefix_4_byte}, {-1, libcall}}},\n-   {libcall, {{24, loop}, {32, unrolled_loop},\n-\t      {8192, rep_prefix_8_byte}, {-1, libcall}}}},\n-  1,\t\t\t\t\t/* scalar_stmt_cost.  */\n-  1,\t\t\t\t\t/* scalar load_cost.  */\n-  1,\t\t\t\t\t/* scalar_store_cost.  */\n-  1,\t\t\t\t\t/* vec_stmt_cost.  */\n-  1,\t\t\t\t\t/* vec_to_scalar_cost.  */\n-  1,\t\t\t\t\t/* scalar_to_vec_cost.  */\n-  1,\t\t\t\t\t/* vec_align_load_cost.  */\n-  2,\t\t\t\t\t/* vec_unalign_load_cost.  */\n-  1,\t\t\t\t\t/* vec_store_cost.  */\n-  3,\t\t\t\t\t/* cond_taken_branch_cost.  */\n-  1,\t\t\t\t\t/* cond_not_taken_branch_cost.  */\n-};\n-\n static const\n struct processor_costs atom_cost = {\n   COSTS_N_INSNS (1),\t\t\t/* cost of an add instruction */\n@@ -1713,9 +1640,13 @@ const struct processor_costs *ix86_cost = &pentium_cost;\n #define m_PPRO (1<<PROCESSOR_PENTIUMPRO)\n #define m_PENT4  (1<<PROCESSOR_PENTIUM4)\n #define m_NOCONA  (1<<PROCESSOR_NOCONA)\n-#define m_CORE2  (1<<PROCESSOR_CORE2)\n+#define m_CORE2_32  (1<<PROCESSOR_CORE2_32)\n+#define m_CORE2_64  (1<<PROCESSOR_CORE2_64)\n #define m_COREI7_32  (1<<PROCESSOR_COREI7_32)\n #define m_COREI7_64  (1<<PROCESSOR_COREI7_64)\n+#define m_CORE2I7_32  (m_CORE2_32 | m_COREI7_32)\n+#define m_CORE2I7_64  (m_CORE2_64 | m_COREI7_64)\n+#define m_CORE2I7  (m_CORE2I7_32 | m_CORE2I7_64)\n #define m_ATOM  (1<<PROCESSOR_ATOM)\n \n #define m_GEODE  (1<<PROCESSOR_GEODE)\n@@ -1728,8 +1659,8 @@ const struct processor_costs *ix86_cost = &pentium_cost;\n #define m_BDVER1  (1<<PROCESSOR_BDVER1)\n #define m_AMD_MULTIPLE  (m_K8 | m_ATHLON | m_AMDFAM10 | m_BDVER1)\n \n-#define m_GENERIC32 (1<<PROCESSOR_GENERIC32 | m_COREI7_32)\n-#define m_GENERIC64 (1<<PROCESSOR_GENERIC64 | m_COREI7_64)\n+#define m_GENERIC32 (1<<PROCESSOR_GENERIC32)\n+#define m_GENERIC64 (1<<PROCESSOR_GENERIC64)\n \n /* Generic instruction choice should be common subset of supported CPUs\n    (PPro/PENT4/NOCONA/CORE2/Athlon/K8).  */\n@@ -1745,21 +1676,22 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n      negatively, so enabling for Generic64 seems like good code size\n      tradeoff.  We can't enable it for 32bit generic because it does not\n      work well with PPro base chips.  */\n-  m_386 | m_K6_GEODE | m_AMD_MULTIPLE | m_CORE2 | m_GENERIC64,\n+  m_386 | m_K6_GEODE | m_AMD_MULTIPLE | m_CORE2I7_64 | m_GENERIC64,\n \n   /* X86_TUNE_PUSH_MEMORY */\n   m_386 | m_K6_GEODE | m_AMD_MULTIPLE | m_PENT4\n-  | m_NOCONA | m_CORE2 | m_GENERIC,\n+  | m_NOCONA | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_ZERO_EXTEND_WITH_AND */\n   m_486 | m_PENT,\n \n   /* X86_TUNE_UNROLL_STRLEN */\n   m_486 | m_PENT | m_ATOM | m_PPRO | m_AMD_MULTIPLE | m_K6\n-  | m_CORE2 | m_GENERIC,\n+  | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_DEEP_BRANCH_PREDICTION */\n-  m_ATOM | m_PPRO | m_K6_GEODE | m_AMD_MULTIPLE | m_PENT4 | m_GENERIC,\n+  m_ATOM | m_PPRO | m_K6_GEODE | m_AMD_MULTIPLE | m_PENT4\n+  | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_BRANCH_PREDICTION_HINTS: Branch hints were put in P4 based\n      on simulation result. But after P4 was made, no performance benefit\n@@ -1772,12 +1704,12 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n \n   /* X86_TUNE_USE_SAHF */\n   m_ATOM | m_PPRO | m_K6_GEODE | m_K8 | m_AMDFAM10 | m_BDVER1 | m_PENT4\n-  | m_NOCONA | m_CORE2 | m_GENERIC,\n+  | m_NOCONA | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_MOVX: Enable to zero extend integer registers to avoid\n      partial dependencies.  */\n   m_AMD_MULTIPLE | m_ATOM | m_PPRO | m_PENT4 | m_NOCONA\n-  | m_CORE2 | m_GENERIC | m_GEODE /* m_386 | m_K6 */,\n+  | m_CORE2I7 | m_GENERIC | m_GEODE /* m_386 | m_K6 */,\n \n   /* X86_TUNE_PARTIAL_REG_STALL: We probably ought to watch for partial\n      register stalls on Generic32 compilation setting as well.  However\n@@ -1790,19 +1722,19 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n   m_PPRO,\n \n   /* X86_TUNE_PARTIAL_FLAG_REG_STALL */\n-  m_CORE2 | m_GENERIC,\n+  m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_USE_HIMODE_FIOP */\n   m_386 | m_486 | m_K6_GEODE,\n \n   /* X86_TUNE_USE_SIMODE_FIOP */\n-  ~(m_PPRO | m_AMD_MULTIPLE | m_PENT | m_ATOM | m_CORE2 | m_GENERIC),\n+  ~(m_PPRO | m_AMD_MULTIPLE | m_PENT | m_ATOM | m_CORE2I7 | m_GENERIC),\n \n   /* X86_TUNE_USE_MOV0 */\n   m_K6,\n \n   /* X86_TUNE_USE_CLTD */\n-  ~(m_PENT | m_ATOM | m_K6 | m_CORE2 | m_GENERIC),\n+  ~(m_PENT | m_ATOM | m_K6 | m_CORE2I7 | m_GENERIC),\n \n   /* X86_TUNE_USE_XCHGB: Use xchgb %rh,%rl instead of rolw/rorw $8,rx.  */\n   m_PENT4,\n@@ -1818,7 +1750,7 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n \n   /* X86_TUNE_PROMOTE_QIMODE */\n   m_K6_GEODE | m_PENT | m_ATOM | m_386 | m_486 | m_AMD_MULTIPLE\n-  | m_CORE2 | m_GENERIC /* | m_PENT4 ? */,\n+  | m_CORE2I7 | m_GENERIC /* | m_PENT4 ? */,\n \n   /* X86_TUNE_FAST_PREFIX */\n   ~(m_PENT | m_486 | m_386),\n@@ -1859,11 +1791,11 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n \n   /* X86_TUNE_INTEGER_DFMODE_MOVES: Enable if integer moves are preferred\n      for DFmode copies */\n-  ~(m_AMD_MULTIPLE | m_ATOM | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2\n+  ~(m_AMD_MULTIPLE | m_ATOM | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2I7\n     | m_GENERIC | m_GEODE),\n \n   /* X86_TUNE_PARTIAL_REG_DEPENDENCY */\n-  m_AMD_MULTIPLE | m_ATOM | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_ATOM | m_PENT4 | m_NOCONA | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_SSE_PARTIAL_REG_DEPENDENCY: In the Generic model we have a\n      conflict here in between PPro/Pentium4 based chips that thread 128bit\n@@ -1874,7 +1806,7 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n      shows that disabling this option on P4 brings over 20% SPECfp regression,\n      while enabling it on K8 brings roughly 2.4% regression that can be partly\n      masked by careful scheduling of moves.  */\n-  m_ATOM | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2 | m_GENERIC\n+  m_ATOM | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2I7 | m_GENERIC\n   | m_AMDFAM10 | m_BDVER1,\n \n   /* X86_TUNE_SSE_UNALIGNED_LOAD_OPTIMAL */\n@@ -1899,13 +1831,13 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n   m_PPRO | m_PENT4 | m_NOCONA,\n \n   /* X86_TUNE_MEMORY_MISMATCH_STALL */\n-  m_AMD_MULTIPLE | m_ATOM | m_PENT4 | m_NOCONA | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_ATOM | m_PENT4 | m_NOCONA | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_PROLOGUE_USING_MOVE */\n-  m_ATHLON_K8 | m_ATOM | m_PPRO | m_CORE2 | m_GENERIC,\n+  m_ATHLON_K8 | m_ATOM | m_PPRO | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_EPILOGUE_USING_MOVE */\n-  m_ATHLON_K8 | m_ATOM | m_PPRO | m_CORE2 | m_GENERIC,\n+  m_ATHLON_K8 | m_ATOM | m_PPRO | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_SHIFT1 */\n   ~m_486,\n@@ -1914,53 +1846,53 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n   m_AMD_MULTIPLE,\n \n   /* X86_TUNE_INTER_UNIT_MOVES */\n-  ~(m_AMD_MULTIPLE | m_GENERIC),\n+  ~(m_AMD_MULTIPLE | m_CORE2I7 | m_GENERIC),\n \n   /* X86_TUNE_INTER_UNIT_CONVERSIONS */\n   ~(m_AMDFAM10 | m_BDVER1),\n \n   /* X86_TUNE_FOUR_JUMP_LIMIT: Some CPU cores are not able to predict more\n      than 4 branch instructions in the 16 byte window.  */\n-  m_ATOM | m_PPRO | m_AMD_MULTIPLE | m_PENT4 | m_NOCONA | m_CORE2\n+  m_ATOM | m_PPRO | m_AMD_MULTIPLE | m_PENT4 | m_NOCONA | m_CORE2I7\n   | m_GENERIC,\n \n   /* X86_TUNE_SCHEDULE */\n-  m_PPRO | m_AMD_MULTIPLE | m_K6_GEODE | m_PENT | m_ATOM | m_CORE2\n+  m_PPRO | m_AMD_MULTIPLE | m_K6_GEODE | m_PENT | m_ATOM | m_CORE2I7\n   | m_GENERIC,\n \n   /* X86_TUNE_USE_BT */\n-  m_AMD_MULTIPLE | m_ATOM | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_ATOM | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_USE_INCDEC */\n-  ~(m_PENT4 | m_NOCONA | m_GENERIC | m_ATOM),\n+  ~(m_PENT4 | m_NOCONA | m_CORE2I7 | m_GENERIC | m_ATOM),\n \n   /* X86_TUNE_PAD_RETURNS */\n-  m_AMD_MULTIPLE | m_CORE2 | m_GENERIC,\n+  m_AMD_MULTIPLE | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_PAD_SHORT_FUNCTION: Pad short funtion.  */\n   m_ATOM,\n \n   /* X86_TUNE_EXT_80387_CONSTANTS */\n   m_K6_GEODE | m_ATHLON_K8 | m_ATOM | m_PENT4 | m_NOCONA | m_PPRO\n-  | m_CORE2 | m_GENERIC,\n+  | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_SHORTEN_X87_SSE */\n   ~m_K8,\n \n   /* X86_TUNE_AVOID_VECTOR_DECODE */\n-  m_K8 | m_GENERIC64,\n+  m_K8 | m_CORE2I7_64 | m_GENERIC64,\n \n   /* X86_TUNE_PROMOTE_HIMODE_IMUL: Modern CPUs have same latency for HImode\n      and SImode multiply, but 386 and 486 do HImode multiply faster.  */\n   ~(m_386 | m_486),\n \n   /* X86_TUNE_SLOW_IMUL_IMM32_MEM: Imul of 32-bit constant and memory is\n      vector path on AMD machines.  */\n-  m_K8 | m_GENERIC64 | m_AMDFAM10 | m_BDVER1,\n+  m_K8 | m_CORE2I7_64 | m_GENERIC64 | m_AMDFAM10 | m_BDVER1,\n \n   /* X86_TUNE_SLOW_IMUL_IMM8: Imul of 8-bit constant is vector path on AMD\n      machines.  */\n-  m_K8 | m_GENERIC64 | m_AMDFAM10 | m_BDVER1,\n+  m_K8 | m_CORE2I7_64 | m_GENERIC64 | m_AMDFAM10 | m_BDVER1,\n \n   /* X86_TUNE_MOVE_M1_VIA_OR: On pentiums, it is faster to load -1 via OR\n      than a MOV.  */\n@@ -1977,7 +1909,7 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n \n   /* X86_TUNE_USE_VECTOR_FP_CONVERTS: Prefer vector packed SSE conversion\n      from FP to FP. */\n-  m_AMDFAM10 | m_GENERIC,\n+  m_AMDFAM10 | m_CORE2I7 | m_GENERIC,\n \n   /* X86_TUNE_USE_VECTOR_CONVERTS: Prefer vector packed SSE conversion\n      from integer to FP. */\n@@ -1986,7 +1918,7 @@ static unsigned int initial_ix86_tune_features[X86_TUNE_LAST] = {\n   /* X86_TUNE_FUSE_CMP_AND_BRANCH: Fuse a compare or test instruction\n      with a subsequent conditional jump instruction into a single\n      compare-and-branch uop.  */\n-  m_CORE2 | m_BDVER1,\n+  m_BDVER1,\n \n   /* X86_TUNE_OPT_AGU: Optimize for Address Generation Unit. This flag\n      will impact LEA instruction selection. */\n@@ -2020,12 +1952,12 @@ static unsigned int initial_ix86_arch_features[X86_ARCH_LAST] = {\n };\n \n static const unsigned int x86_accumulate_outgoing_args\n-  = m_AMD_MULTIPLE | m_ATOM | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2\n+  = m_AMD_MULTIPLE | m_ATOM | m_PENT4 | m_NOCONA | m_PPRO | m_CORE2I7\n     | m_GENERIC;\n \n static const unsigned int x86_arch_always_fancy_math_387\n   = m_PENT | m_ATOM | m_PPRO | m_AMD_MULTIPLE | m_PENT4\n-    | m_NOCONA | m_CORE2 | m_GENERIC;\n+    | m_NOCONA | m_CORE2I7 | m_GENERIC;\n \n static enum stringop_alg stringop_alg = no_stringop;\n \n@@ -2540,7 +2472,10 @@ static const struct ptt processor_target_table[PROCESSOR_max] =\n   {&pentium4_cost, 0, 0, 0, 0, 0},\n   {&k8_cost, 16, 7, 16, 7, 16},\n   {&nocona_cost, 0, 0, 0, 0, 0},\n-  {&core2_cost, 16, 10, 16, 10, 16},\n+  /* Core 2 32-bit.  */\n+  {&generic32_cost, 16, 10, 16, 10, 16},\n+  /* Core 2 64-bit.  */\n+  {&generic64_cost, 16, 10, 16, 10, 16},\n   /* Core i7 32-bit.  */\n   {&generic32_cost, 16, 10, 16, 10, 16},\n   /* Core i7 64-bit.  */\n@@ -3296,12 +3231,12 @@ ix86_option_override_internal (bool main_args_p)\n       {\"nocona\", PROCESSOR_NOCONA, CPU_NONE,\n \tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n \t| PTA_CX16 | PTA_NO_SAHF},\n-      {\"core2\", PROCESSOR_CORE2, CPU_CORE2,\n+      {\"core2\", PROCESSOR_CORE2_64, CPU_GENERIC64,\n \tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n \t| PTA_SSSE3 | PTA_CX16},\n       {\"corei7\", PROCESSOR_COREI7_64, CPU_GENERIC64,\n-       PTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n-       | PTA_SSSE3 | PTA_SSE4_1 | PTA_SSE4_2 | PTA_CX16},\n+\tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n+\t| PTA_SSSE3 | PTA_SSE4_1 | PTA_SSE4_2 | PTA_CX16},\n       {\"atom\", PROCESSOR_ATOM, CPU_ATOM,\n \tPTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3\n \t| PTA_SSSE3 | PTA_CX16 | PTA_MOVBE},\n@@ -3676,6 +3611,11 @@ ix86_option_override_internal (bool main_args_p)\n \t\tix86_schedule = CPU_PENTIUMPRO;\n \t\tbreak;\n \n+\t      case PROCESSOR_CORE2_64:\n+\t\tix86_tune = PROCESSOR_CORE2_32;\n+\t\tix86_schedule = CPU_PENTIUMPRO;\n+\t\tbreak;\n+\n \t      case PROCESSOR_COREI7_64:\n \t\tix86_tune = PROCESSOR_COREI7_32;\n \t\tix86_schedule = CPU_PENTIUMPRO;\n@@ -22242,9 +22182,6 @@ ix86_issue_rate (void)\n     case PROCESSOR_BDVER1:\n       return 3;\n \n-    case PROCESSOR_CORE2:\n-      return 4;\n-\n     default:\n       return 1;\n     }\n@@ -22483,7 +22420,8 @@ ia32_multipass_dfa_lookahead (void)\n     case PROCESSOR_K6:\n       return 1;\n \n-    case PROCESSOR_CORE2:\n+    case PROCESSOR_CORE2_32:\n+    case PROCESSOR_CORE2_64:\n     case PROCESSOR_COREI7_32:\n     case PROCESSOR_COREI7_64:\n       /* Generally, we want haifa-sched:max_issue() to look ahead as far\n@@ -22705,7 +22643,8 @@ ix86_sched_init_global (FILE *dump ATTRIBUTE_UNUSED,\n      they are actually used.  */\n   switch (ix86_tune)\n     {\n-    case PROCESSOR_CORE2:\n+    case PROCESSOR_CORE2_32:\n+    case PROCESSOR_CORE2_64:\n     case PROCESSOR_COREI7_32:\n     case PROCESSOR_COREI7_64:\n       targetm.sched.dfa_post_advance_cycle"}, {"sha": "510506aa8dbce85de68c3bd104a796f469517b6a", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ab2477624b15b5d1fe43972f8f4d6082c6893624/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ab2477624b15b5d1fe43972f8f4d6082c6893624/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=ab2477624b15b5d1fe43972f8f4d6082c6893624", "patch": "@@ -240,7 +240,9 @@ extern const struct processor_costs ix86_size_cost;\n #define TARGET_K8 (ix86_tune == PROCESSOR_K8)\n #define TARGET_ATHLON_K8 (TARGET_K8 || TARGET_ATHLON)\n #define TARGET_NOCONA (ix86_tune == PROCESSOR_NOCONA)\n-#define TARGET_CORE2 (ix86_tune == PROCESSOR_CORE2)\n+#define TARGET_CORE2_32 (ix86_tune == PROCESSOR_CORE2_32)\n+#define TARGET_CORE2_64 (ix86_tune == PROCESSOR_CORE2_64)\n+#define TARGET_CORE2 (TARGET_CORE2_32 || TARGET_CORE2_64)\n #define TARGET_COREI7_32 (ix86_tune == PROCESSOR_COREI7_32)\n #define TARGET_COREI7_64 (ix86_tune == PROCESSOR_COREI7_64)\n #define TARGET_COREI7 (TARGET_COREI7_32 || TARGET_COREI7_64)\n@@ -2050,7 +2052,8 @@ enum processor_type\n   PROCESSOR_PENTIUM4,\n   PROCESSOR_K8,\n   PROCESSOR_NOCONA,\n-  PROCESSOR_CORE2,\n+  PROCESSOR_CORE2_32,\n+  PROCESSOR_CORE2_64,\n   PROCESSOR_COREI7_32,\n   PROCESSOR_COREI7_64,\n   PROCESSOR_GENERIC32,"}]}