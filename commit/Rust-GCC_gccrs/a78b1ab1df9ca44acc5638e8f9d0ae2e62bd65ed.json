{"sha": "a78b1ab1df9ca44acc5638e8f9d0ae2e62bd65ed", "node_id": "C_kwDOANBUbNoAKGE3OGIxYWIxZGY5Y2E0NGFjYzU2MzhlOGY5ZDBhZTJlNjJiZDY1ZWQ", "commit": {"author": {"name": "Kwok Cheung Yeung", "email": "kcy@codesourcery.com", "date": "2019-08-29T17:16:42Z"}, "committer": {"name": "Thomas Schwinge", "email": "thomas@codesourcery.com", "date": "2022-01-16T16:25:36Z"}, "message": "amdgcn: Tune default OpenMP/OpenACC GPU utilization\n\n\tlibgomp/\n\t* plugin/plugin-gcn.c (parse_target_attributes): Automatically set\n\tthe number of teams and threads if necessary.\n\t(gcn_exec): Automatically set the number of gangs and workers if\n\tnecessary.\n\nCo-Authored-By: Andrew Stubbs  <ams@codesourcery.com>", "tree": {"sha": "6274158d73c22dcb8afdc8161ee9df4051517b7e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6274158d73c22dcb8afdc8161ee9df4051517b7e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/a78b1ab1df9ca44acc5638e8f9d0ae2e62bd65ed", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a78b1ab1df9ca44acc5638e8f9d0ae2e62bd65ed", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a78b1ab1df9ca44acc5638e8f9d0ae2e62bd65ed", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a78b1ab1df9ca44acc5638e8f9d0ae2e62bd65ed/comments", "author": {"login": "k-yeung", "id": 16960193, "node_id": "MDQ6VXNlcjE2OTYwMTkz", "avatar_url": "https://avatars.githubusercontent.com/u/16960193?v=4", "gravatar_id": "", "url": "https://api.github.com/users/k-yeung", "html_url": "https://github.com/k-yeung", "followers_url": "https://api.github.com/users/k-yeung/followers", "following_url": "https://api.github.com/users/k-yeung/following{/other_user}", "gists_url": "https://api.github.com/users/k-yeung/gists{/gist_id}", "starred_url": "https://api.github.com/users/k-yeung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/k-yeung/subscriptions", "organizations_url": "https://api.github.com/users/k-yeung/orgs", "repos_url": "https://api.github.com/users/k-yeung/repos", "events_url": "https://api.github.com/users/k-yeung/events{/privacy}", "received_events_url": "https://api.github.com/users/k-yeung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "tschwinge", "id": 21753, "node_id": "MDQ6VXNlcjIxNzUz", "avatar_url": "https://avatars.githubusercontent.com/u/21753?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tschwinge", "html_url": "https://github.com/tschwinge", "followers_url": "https://api.github.com/users/tschwinge/followers", "following_url": "https://api.github.com/users/tschwinge/following{/other_user}", "gists_url": "https://api.github.com/users/tschwinge/gists{/gist_id}", "starred_url": "https://api.github.com/users/tschwinge/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tschwinge/subscriptions", "organizations_url": "https://api.github.com/users/tschwinge/orgs", "repos_url": "https://api.github.com/users/tschwinge/repos", "events_url": "https://api.github.com/users/tschwinge/events{/privacy}", "received_events_url": "https://api.github.com/users/tschwinge/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9d7e19255c06e05ad791e9bf5aefc4783a12c4f9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9d7e19255c06e05ad791e9bf5aefc4783a12c4f9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9d7e19255c06e05ad791e9bf5aefc4783a12c4f9"}], "stats": {"total": 82, "additions": 67, "deletions": 15}, "files": [{"sha": "f305d7268740821819bb2c1e843f58c2443dd506", "filename": "libgomp/plugin/plugin-gcn.c", "status": "modified", "additions": 67, "deletions": 15, "changes": 82, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a78b1ab1df9ca44acc5638e8f9d0ae2e62bd65ed/libgomp%2Fplugin%2Fplugin-gcn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a78b1ab1df9ca44acc5638e8f9d0ae2e62bd65ed/libgomp%2Fplugin%2Fplugin-gcn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fplugin%2Fplugin-gcn.c?ref=a78b1ab1df9ca44acc5638e8f9d0ae2e62bd65ed", "patch": "@@ -1219,24 +1219,55 @@ parse_target_attributes (void **input,\n \n   if (gcn_dims_found)\n     {\n+      bool gfx900_workaround_p = false;\n+\n       if (agent->device_isa == EF_AMDGPU_MACH_AMDGCN_GFX900\n \t  && gcn_threads == 0 && override_z_dim == 0)\n \t{\n-\t  gcn_threads = 4;\n+\t  gfx900_workaround_p = true;\n \t  GCN_WARNING (\"VEGA BUG WORKAROUND: reducing default number of \"\n-\t\t       \"threads to 4 per team.\\n\");\n+\t\t       \"threads to at most 4 per team.\\n\");\n \t  GCN_WARNING (\" - If this is not a Vega 10 device, please use \"\n \t\t       \"GCN_NUM_THREADS=16\\n\");\n \t}\n \n+      /* Ideally, when a dimension isn't explicitly specified, we should\n+\t tune it to run 40 (or 32?) threads per CU with no threads getting queued.\n+\t In practice, we tune for peak performance on BabelStream, which\n+\t for OpenACC is currently 32 threads per CU.  */\n       def->ndim = 3;\n-      /* Fiji has 64 CUs, but Vega20 has 60.  */\n-      def->gdims[0] = (gcn_teams > 0) ? gcn_teams : get_cu_count (agent);\n-      /* Each thread is 64 work items wide.  */\n-      def->gdims[1] = 64;\n-      /* A work group can have 16 wavefronts.  */\n-      def->gdims[2] = (gcn_threads > 0) ? gcn_threads : 16;\n-      def->wdims[0] = 1; /* Single team per work-group.  */\n+      if (gcn_teams <= 0 && gcn_threads <= 0)\n+\t{\n+\t  /* Set up a reasonable number of teams and threads.  */\n+\t  gcn_threads = gfx900_workaround_p ? 4 : 16; // 8;\n+\t  def->gdims[0] = get_cu_count (agent); // * (40 / gcn_threads);\n+\t  def->gdims[2] = gcn_threads;\n+\t}\n+      else if (gcn_teams <= 0 && gcn_threads > 0)\n+\t{\n+\t  /* Auto-scale the number of teams with the number of threads.  */\n+\t  def->gdims[0] = get_cu_count (agent); // * (40 / gcn_threads);\n+\t  def->gdims[2] = gcn_threads;\n+\t}\n+      else if (gcn_teams > 0 && gcn_threads <= 0)\n+\t{\n+\t  int max_threads = gfx900_workaround_p ? 4 : 16;\n+\n+\t  /* Auto-scale the number of threads with the number of teams.  */\n+\t  def->gdims[0] = gcn_teams;\n+\t  def->gdims[2] = 16; // get_cu_count (agent) * 40 / gcn_teams;\n+\t  if (def->gdims[2] == 0)\n+\t    def->gdims[2] = 1;\n+\t  else if (def->gdims[2] > max_threads)\n+\t    def->gdims[2] = max_threads;\n+\t}\n+      else\n+\t{\n+\t  def->gdims[0] = gcn_teams;\n+\t  def->gdims[2] = gcn_threads;\n+\t}\n+      def->gdims[1] = 64; /* Each thread is 64 work items wide.  */\n+      def->wdims[0] = 1;  /* Single team per work-group.  */\n       def->wdims[1] = 64;\n       def->wdims[2] = 16;\n       *result = def;\n@@ -3031,13 +3062,34 @@ gcn_exec (struct kernel_info *kernel, size_t mapnum, void **hostaddrs,\n   if (hsa_kernel_desc->oacc_dims[2] > 0)\n     dims[2] = hsa_kernel_desc->oacc_dims[2];\n \n-  /* If any of the OpenACC dimensions remain 0 then we get to pick a number.\n-     There isn't really a correct answer for this without a clue about the\n-     problem size, so let's do a reasonable number of single-worker gangs.\n-     64 gangs matches a typical Fiji device.  */\n+  /* Ideally, when a dimension isn't explicitly specified, we should\n+     tune it to run 40 (or 32?) threads per CU with no threads getting queued.\n+     In practice, we tune for peak performance on BabelStream, which\n+     for OpenACC is currently 32 threads per CU.  */\n+  if (dims[0] == 0 && dims[1] == 0)\n+    {\n+      /* If any of the OpenACC dimensions remain 0 then we get to pick a\n+\t number.  There isn't really a correct answer for this without a clue\n+\t about the problem size, so let's do a reasonable number of workers\n+\t and gangs.  */\n \n-  if (dims[0] == 0) dims[0] = get_cu_count (kernel->agent); /* Gangs.  */\n-  if (dims[1] == 0) dims[1] = 16; /* Workers.  */\n+      dims[0] = get_cu_count (kernel->agent) * 4; /* Gangs.  */\n+      dims[1] = 8; /* Workers.  */\n+    }\n+  else if (dims[0] == 0 && dims[1] > 0)\n+    {\n+      /* Auto-scale the number of gangs with the requested number of workers.  */\n+      dims[0] = get_cu_count (kernel->agent) * (32 / dims[1]);\n+    }\n+  else if (dims[0] > 0 && dims[1] == 0)\n+    {\n+      /* Auto-scale the number of workers with the requested number of gangs.  */\n+      dims[1] = get_cu_count (kernel->agent) * 32 / dims[0];\n+      if (dims[1] == 0)\n+\tdims[1] = 1;\n+      if (dims[1] > 16)\n+\tdims[1] = 16;\n+    }\n \n   /* The incoming dimensions are expressed in terms of gangs, workers, and\n      vectors.  The HSA dimensions are expressed in terms of \"work-items\","}]}