{"sha": "18f6990f842d0bdcb2cf9541ca98d67b414d5802", "node_id": "C_kwDOANBUbNoAKDE4ZjY5OTBmODQyZDBiZGNiMmNmOTU0MWNhOThkNjdiNDE0ZDU4MDI", "commit": {"author": {"name": "Joel Phillips", "email": "simplytheother@gmail.com", "date": "2022-08-23T15:11:00Z"}, "committer": {"name": "Arthur Cohen", "email": "arthur.cohen@embecosm.com", "date": "2022-12-13T13:00:04Z"}, "message": "gccrs: Add Lexer for Rust front-end\n\nThe lexer is referred to as a ManagedTokenSource within the parser. This\nlexer does not currently support Unicode, but serves as a starting point\nto do so.\n\n\tgcc/rust/\n\t* lex/rust-codepoint.h: New.\n\t* lex/rust-lex.cc: New.\n\t* lex/rust-lex.h: New.\n\t* lex/rust-token.cc: New.\n\t* lex/rust-token.h: New.\n\t* rust-buffered-queue.h: New.\n\nCo-authored-by: Philip Herron <philip.herron@embecosm.com>\nCo-authored-by: Arthur Cohen <arthur.cohen@embecosm.com>\nCo-authored-by: Mark Wielaard <mark@klomp.org>\n\nSigned-off-by: Joel Phillips <simplytheother@gmail.com>", "tree": {"sha": "6a9cc48fb9b8eadf5c967d5ab7625f710833f99c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6a9cc48fb9b8eadf5c967d5ab7625f710833f99c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/18f6990f842d0bdcb2cf9541ca98d67b414d5802", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/18f6990f842d0bdcb2cf9541ca98d67b414d5802", "html_url": "https://github.com/Rust-GCC/gccrs/commit/18f6990f842d0bdcb2cf9541ca98d67b414d5802", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/18f6990f842d0bdcb2cf9541ca98d67b414d5802/comments", "author": {"login": "SimplyTheOther", "id": 19371469, "node_id": "MDQ6VXNlcjE5MzcxNDY5", "avatar_url": "https://avatars.githubusercontent.com/u/19371469?v=4", "gravatar_id": "", "url": "https://api.github.com/users/SimplyTheOther", "html_url": "https://github.com/SimplyTheOther", "followers_url": "https://api.github.com/users/SimplyTheOther/followers", "following_url": "https://api.github.com/users/SimplyTheOther/following{/other_user}", "gists_url": "https://api.github.com/users/SimplyTheOther/gists{/gist_id}", "starred_url": "https://api.github.com/users/SimplyTheOther/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/SimplyTheOther/subscriptions", "organizations_url": "https://api.github.com/users/SimplyTheOther/orgs", "repos_url": "https://api.github.com/users/SimplyTheOther/repos", "events_url": "https://api.github.com/users/SimplyTheOther/events{/privacy}", "received_events_url": "https://api.github.com/users/SimplyTheOther/received_events", "type": "User", "site_admin": false}, "committer": {"login": "CohenArthur", "id": 43524065, "node_id": "MDQ6VXNlcjQzNTI0MDY1", "avatar_url": "https://avatars.githubusercontent.com/u/43524065?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CohenArthur", "html_url": "https://github.com/CohenArthur", "followers_url": "https://api.github.com/users/CohenArthur/followers", "following_url": "https://api.github.com/users/CohenArthur/following{/other_user}", "gists_url": "https://api.github.com/users/CohenArthur/gists{/gist_id}", "starred_url": "https://api.github.com/users/CohenArthur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CohenArthur/subscriptions", "organizations_url": "https://api.github.com/users/CohenArthur/orgs", "repos_url": "https://api.github.com/users/CohenArthur/repos", "events_url": "https://api.github.com/users/CohenArthur/events{/privacy}", "received_events_url": "https://api.github.com/users/CohenArthur/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5b981e9c7411e68bdd73365dbd94ed3844bce2c8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5b981e9c7411e68bdd73365dbd94ed3844bce2c8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5b981e9c7411e68bdd73365dbd94ed3844bce2c8"}], "stats": {"total": 3831, "additions": 3831, "deletions": 0}, "files": [{"sha": "1a9f0ca7a2112f6847e07b6577396ed9a020d51a", "filename": "gcc/rust/lex/rust-codepoint.h", "status": "added", "additions": 46, "deletions": 0, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-codepoint.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-codepoint.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-codepoint.h?ref=18f6990f842d0bdcb2cf9541ca98d67b414d5802", "patch": "@@ -0,0 +1,46 @@\n+// Copyright (C) 2020-2022 Free Software Foundation, Inc.\n+\n+// This file is part of GCC.\n+\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#ifndef RUST_CODEPOINT_H\n+#define RUST_CODEPOINT_H\n+\n+#include \"rust-system.h\"\n+\n+namespace Rust {\n+struct Codepoint\n+{\n+  uint32_t value;\n+\n+  // Creates a zero codepoint.\n+  Codepoint () : value (0) {}\n+\n+  // Creates a codepoint from an encoded UTF-8 value.\n+  Codepoint (uint32_t value) : value (value) {}\n+\n+  static Codepoint eof () { return Codepoint (UINT32_MAX); }\n+  bool is_eof () const { return value == UINT32_MAX; }\n+\n+  // Returns a C++ string containing string value of codepoint.\n+  std::string as_string ();\n+\n+  bool operator== (Codepoint other) const { return value == other.value; }\n+  bool operator!= (Codepoint other) const { return !operator== (other); }\n+};\n+} // namespace Rust\n+\n+#endif"}, {"sha": "82949f5fe5f69f1b032d125782b97706f2654c1d", "filename": "gcc/rust/lex/rust-lex.cc", "status": "added", "additions": 2728, "deletions": 0, "changes": 2728, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-lex.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-lex.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-lex.cc?ref=18f6990f842d0bdcb2cf9541ca98d67b414d5802", "patch": "@@ -0,0 +1,2728 @@\n+// Copyright (C) 2020-2022 Free Software Foundation, Inc.\n+\n+// This file is part of GCC.\n+\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#include \"rust-system.h\"\n+#include \"rust-lex.h\"\n+#include \"rust-diagnostics.h\"\n+#include \"rust-linemap.h\"\n+#include \"rust-session-manager.h\"\n+#include \"safe-ctype.h\"\n+\n+namespace Rust {\n+// TODO: move to separate compilation unit?\n+// overload += for uint32_t to allow 32-bit encoded utf-8 to be added\n+std::string &\n+operator+= (std::string &str, Codepoint char32)\n+{\n+  if (char32.value < 0x80)\n+    {\n+      str += static_cast<char> (char32.value);\n+    }\n+  else if (char32.value < (0x1F + 1) << (1 * 6))\n+    {\n+      str += static_cast<char> (0xC0 | ((char32.value >> 6) & 0x1F));\n+      str += static_cast<char> (0x80 | ((char32.value >> 0) & 0x3F));\n+    }\n+  else if (char32.value < (0x0F + 1) << (2 * 6))\n+    {\n+      str += static_cast<char> (0xE0 | ((char32.value >> 12) & 0x0F));\n+      str += static_cast<char> (0x80 | ((char32.value >> 6) & 0x3F));\n+      str += static_cast<char> (0x80 | ((char32.value >> 0) & 0x3F));\n+    }\n+  else if (char32.value < (0x07 + 1) << (3 * 6))\n+    {\n+      str += static_cast<char> (0xF0 | ((char32.value >> 18) & 0x07));\n+      str += static_cast<char> (0x80 | ((char32.value >> 12) & 0x3F));\n+      str += static_cast<char> (0x80 | ((char32.value >> 6) & 0x3F));\n+      str += static_cast<char> (0x80 | ((char32.value >> 0) & 0x3F));\n+    }\n+  else\n+    {\n+      rust_debug (\"Invalid unicode codepoint found: '%u' \", char32.value);\n+    }\n+  return str;\n+}\n+\n+std::string\n+Codepoint::as_string ()\n+{\n+  std::string str;\n+\n+  // str += Codepoint (value);\n+  str += *this;\n+\n+  return str;\n+}\n+\n+/* Includes all allowable float digits EXCEPT _ and . as that needs lookahead\n+ * for handling. */\n+bool\n+is_float_digit (char number)\n+{\n+  return ISDIGIT (number) || number == 'E' || number == 'e';\n+}\n+\n+/* Basically ISXDIGIT from safe-ctype but may change if Rust's encoding or\n+ * whatever is different */\n+bool\n+is_x_digit (char number)\n+{\n+  return ISXDIGIT (number);\n+}\n+\n+bool\n+is_octal_digit (char number)\n+{\n+  return number >= '0' && number <= '7';\n+}\n+\n+bool\n+is_bin_digit (char number)\n+{\n+  return number == '0' || number == '1';\n+}\n+\n+bool\n+check_valid_float_dot_end (char character)\n+{\n+  return character != '.' && character != '_' && !ISALPHA (character);\n+}\n+\n+// ISSPACE from safe-ctype but may change in future\n+bool\n+is_whitespace (char character)\n+{\n+  return ISSPACE (character);\n+}\n+\n+bool\n+is_non_decimal_int_literal_separator (char character)\n+{\n+  return character == 'x' || character == 'o' || character == 'b';\n+}\n+\n+Lexer::Lexer (const std::string &input)\n+  : input (RAIIFile::create_error ()), current_line (1), current_column (1),\n+    line_map (nullptr), raw_input_source (new BufferInputSource (input, 0)),\n+    input_queue{*raw_input_source}, token_queue (TokenSource (this))\n+{}\n+\n+Lexer::Lexer (const char *filename, RAIIFile file_input, Linemap *linemap)\n+  : input (std::move (file_input)), current_line (1), current_column (1),\n+    line_map (linemap),\n+    raw_input_source (new FileInputSource (input.get_raw ())),\n+    input_queue{*raw_input_source}, token_queue (TokenSource (this))\n+{\n+  // inform line_table that file is being entered and is in line 1\n+  if (linemap)\n+    line_map->start_file (filename, current_line);\n+}\n+\n+Lexer::~Lexer ()\n+{\n+  /* ok apparently stop (which is equivalent of original code in destructor) is\n+   * meant to be called after all files have finished parsing, for cleanup. On\n+   * the other hand, actual code that it calls to leave a certain line map is\n+   * mentioned in GCC docs as being useful for \"just leaving an included header\"\n+   * and stuff like that, so this line mapping functionality may need fixing.\n+   * FIXME: find out whether this occurs. */\n+\n+  // line_map->stop();\n+}\n+\n+/* TODO: need to optimise somehow to avoid the virtual function call in the\n+ * tight loop. Best idea at the moment is CRTP, but that might make lexer\n+ * implementation annoying when storing the \"base class\" (i.e. would need\n+ * template parameter everywhere), although in practice it would mostly just\n+ * look ugly and make enclosing classes like Parser also require a type\n+ * parameter. At this point a macro might be better. OK I guess macros can be\n+ * replaced by constexpr if or something if possible. */\n+Location\n+Lexer::get_current_location ()\n+{\n+  if (line_map)\n+    return line_map->get_location (current_column);\n+  else\n+    // If we have no linemap, we're lexing something without proper locations\n+    return Location ();\n+}\n+\n+int\n+Lexer::peek_input (int n)\n+{\n+  return input_queue.peek (n);\n+}\n+\n+int\n+Lexer::peek_input ()\n+{\n+  return peek_input (0);\n+}\n+\n+void\n+Lexer::skip_input (int n)\n+{\n+  input_queue.skip (n);\n+}\n+\n+void\n+Lexer::skip_input ()\n+{\n+  skip_input (0);\n+}\n+\n+void\n+Lexer::replace_current_token (TokenPtr replacement)\n+{\n+  token_queue.replace_current_value (replacement);\n+\n+  rust_debug (\"called 'replace_current_token' - this is deprecated\");\n+}\n+\n+/* shitty anonymous namespace that can only be accessed inside the compilation\n+ * unit - used for classify_keyword binary search in sorted array of keywords\n+ * created with x-macros. */\n+namespace {\n+// TODO: make constexpr when update to c++20\n+const std::string keyword_index[] = {\n+#define RS_TOKEN(x, y)\n+#define RS_TOKEN_KEYWORD(name, keyword) keyword,\n+  RS_TOKEN_LIST\n+#undef RS_TOKEN_KEYWORD\n+#undef RS_TOKEN\n+};\n+\n+constexpr TokenId keyword_keys[] = {\n+#define RS_TOKEN(x, y)\n+#define RS_TOKEN_KEYWORD(name, keyword) name,\n+  RS_TOKEN_LIST\n+#undef RS_TOKEN_KEYWORD\n+#undef RS_TOKEN\n+};\n+\n+constexpr int num_keywords = sizeof (keyword_index) / sizeof (*keyword_index);\n+} // namespace\n+\n+/* Determines whether the string passed in is a keyword or not. If it is, it\n+ * returns the keyword name.  */\n+TokenId\n+Lexer::classify_keyword (const std::string &str)\n+{\n+  const std::string *last = keyword_index + num_keywords;\n+  const std::string *idx = std::lower_bound (keyword_index, last, str);\n+\n+  if (idx == last || str != *idx)\n+    return IDENTIFIER;\n+\n+  // TODO: possibly replace this x-macro system with something like hash map?\n+\n+  // We now have the expected token ID of the reserved keyword. However, some\n+  // keywords are reserved starting in certain editions. For example, `try` is\n+  // only a reserved keyword in editions >=2018. The language might gain new\n+  // reserved keywords in the future.\n+  //\n+  // https://doc.rust-lang.org/reference/keywords.html#reserved-keywords\n+  auto id = keyword_keys[idx - keyword_index];\n+\n+  // `try` is not a reserved keyword before 2018\n+  if (Session::get_instance ().options.get_edition ()\n+\t== CompileOptions::Edition::E2015\n+      && id == TRY)\n+    return IDENTIFIER;\n+\n+  return id;\n+}\n+\n+TokenPtr\n+Lexer::build_token ()\n+{\n+  // loop to go through multiple characters to build a single token\n+  while (true)\n+    {\n+      Location loc = get_current_location ();\n+      current_char = peek_input ();\n+      skip_input ();\n+\n+      // detect UTF8 bom\n+      //\n+      // Must be the first thing on the first line.\n+      // There might be an optional BOM (Byte Order Mark), which for UTF-8 is\n+      // the three bytes 0xEF, 0xBB and 0xBF. These can simply be skipped.\n+      if (current_line == 1 && current_column == 1 && current_char == 0xef\n+\t  && peek_input () == 0xbb && peek_input (1) == 0xbf)\n+\t{\n+\t  skip_input (1);\n+\t  current_char = peek_input ();\n+\t  skip_input ();\n+\t}\n+\n+      // detect shebang\n+      // Must be the first thing on the first line, starting with #!\n+      // But since an attribute can also start with an #! we don't count it as a\n+      // shebang line when after any whitespace or comments there is a [. If it\n+      // is a shebang line we simple drop the line. Otherwise we don't consume\n+      // any characters and fall through to the real tokenizer.\n+      if (current_line == 1 && current_column == 1 && current_char == '#'\n+\t  && peek_input () == '!')\n+\t{\n+\t  int n = 1;\n+\t  while (true)\n+\t    {\n+\t      int next_char = peek_input (n);\n+\t      if (is_whitespace (next_char))\n+\t\tn++;\n+\t      else if ((next_char == '/' && peek_input (n + 1) == '/'\n+\t\t\t&& peek_input (n + 2) != '!'\n+\t\t\t&& peek_input (n + 2) != '/')\n+\t\t       || (next_char == '/' && peek_input (n + 1) == '/'\n+\t\t\t   && peek_input (n + 2) == '/'\n+\t\t\t   && peek_input (n + 3) == '/'))\n+\t\t{\n+\t\t  // two // or four ////\n+\t\t  // A single line comment\n+\t\t  // (but not an inner or outer doc comment)\n+\t\t  n += 2;\n+\t\t  next_char = peek_input (n);\n+\t\t  while (next_char != '\\n' && next_char != EOF)\n+\t\t    {\n+\t\t      n++;\n+\t\t      next_char = peek_input (n);\n+\t\t    }\n+\t\t  if (next_char == '\\n')\n+\t\t    n++;\n+\t\t}\n+\t      else if (next_char == '/' && peek_input (n + 1) == '*'\n+\t\t       && peek_input (n + 2) == '*'\n+\t\t       && peek_input (n + 3) == '/')\n+\t\t{\n+\t\t  /**/\n+\t\t  n += 4;\n+\t\t}\n+\t      else if (next_char == '/' && peek_input (n + 1) == '*'\n+\t\t       && peek_input (n + 2) == '*' && peek_input (n + 3) == '*'\n+\t\t       && peek_input (n + 4) == '/')\n+\t\t{\n+\t\t  /***/\n+\t\t  n += 5;\n+\t\t}\n+\t      else if ((next_char == '/' && peek_input (n + 1) == '*'\n+\t\t\t&& peek_input (n + 2) != '*'\n+\t\t\t&& peek_input (n + 2) != '!')\n+\t\t       || (next_char == '/' && peek_input (n + 1) == '*'\n+\t\t\t   && peek_input (n + 2) == '*'\n+\t\t\t   && peek_input (n + 3) == '*'))\n+\t\t{\n+\t\t  // one /* or three /***\n+\t\t  // Start of a block comment\n+\t\t  // (but not an inner or outer doc comment)\n+\t\t  n += 2;\n+\t\t  int level = 1;\n+\t\t  while (level > 0)\n+\t\t    {\n+\t\t      if (peek_input (n) == EOF)\n+\t\t\tbreak;\n+\t\t      else if (peek_input (n) == '/'\n+\t\t\t       && peek_input (n + 1) == '*')\n+\t\t\t{\n+\t\t\t  n += 2;\n+\t\t\t  level += 1;\n+\t\t\t}\n+\t\t      else if (peek_input (n) == '*'\n+\t\t\t       && peek_input (n + 1) == '/')\n+\t\t\t{\n+\t\t\t  n += 2;\n+\t\t\t  level -= 1;\n+\t\t\t}\n+\t\t      else\n+\t\t\tn++;\n+\t\t    }\n+\t\t}\n+\t      else if (next_char != '[')\n+\t\t{\n+\t\t  // definitely shebang, ignore the first line\n+\t\t  while (current_char != '\\n' && current_char != EOF)\n+\t\t    {\n+\t\t      current_char = peek_input ();\n+\t\t      skip_input ();\n+\t\t    }\n+\n+\t\t  // newline\n+\t\t  current_line++;\n+\t\t  current_column = 1;\n+\t\t  // tell line_table that new line starts\n+\t\t  start_line (current_line, max_column_hint);\n+\t\t  break;\n+\t\t}\n+\t      else\n+\t\tbreak; /* Definitely not a shebang line. */\n+\t    }\n+\t}\n+\n+      // return end of file token if end of file\n+      if (current_char == EOF)\n+\treturn Token::make (END_OF_FILE, loc);\n+\n+      // if not end of file, start tokenising\n+      switch (current_char)\n+\t{\n+\t/* ignore whitespace characters for tokens but continue updating\n+\t * location */\n+\tcase '\\n': // newline\n+\t  current_line++;\n+\t  current_column = 1;\n+\t  // tell line_table that new line starts\n+\t  start_line (current_line, max_column_hint);\n+\t  continue;\n+\tcase '\\r': // cr\n+\t  // Ignore, we expect a newline (lf) soon.\n+\t  continue;\n+\tcase ' ': // space\n+\t  current_column++;\n+\t  continue;\n+\tcase '\\t': // tab\n+\t  // width of a tab is not well-defined, assume 8 spaces\n+\t  current_column += 8;\n+\t  continue;\n+\n+\t// punctuation - actual tokens\n+\tcase '=':\n+\t  if (peek_input () == '>')\n+\t    {\n+\t      // match arm arrow\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (MATCH_ARROW, loc);\n+\t    }\n+\t  else if (peek_input () == '=')\n+\t    {\n+\t      // equality operator\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (EQUAL_EQUAL, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // assignment operator\n+\t      current_column++;\n+\t      return Token::make (EQUAL, loc);\n+\t    }\n+\tcase '(':\n+\t  current_column++;\n+\t  return Token::make (LEFT_PAREN, loc);\n+\tcase '-':\n+\t  if (peek_input () == '>')\n+\t    {\n+\t      // return type specifier\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (RETURN_TYPE, loc);\n+\t    }\n+\t  else if (peek_input () == '=')\n+\t    {\n+\t      // minus-assign\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (MINUS_EQ, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // minus\n+\t      current_column++;\n+\t      return Token::make (MINUS, loc);\n+\t    }\n+\tcase '+':\n+\t  if (peek_input () == '=')\n+\t    {\n+\t      // add-assign\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (PLUS_EQ, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // add\n+\t      current_column++;\n+\t      return Token::make (PLUS, loc);\n+\t    }\n+\tcase ')':\n+\t  current_column++;\n+\t  return Token::make (RIGHT_PAREN, loc);\n+\tcase ';':\n+\t  current_column++;\n+\t  return Token::make (SEMICOLON, loc);\n+\tcase '*':\n+\t  if (peek_input () == '=')\n+\t    {\n+\t      // multiplication-assign\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (ASTERISK_EQ, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // multiplication\n+\t      current_column++;\n+\t      return Token::make (ASTERISK, loc);\n+\t    }\n+\tcase ',':\n+\t  current_column++;\n+\t  return Token::make (COMMA, loc);\n+\tcase '/':\n+\t  if (peek_input () == '=')\n+\t    {\n+\t      // division-assign\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (DIV_EQ, loc);\n+\t    }\n+\t  else if ((peek_input () == '/' && peek_input (1) != '!'\n+\t\t    && peek_input (1) != '/')\n+\t\t   || (peek_input () == '/' && peek_input (1) == '/'\n+\t\t       && peek_input (2) == '/'))\n+\t    {\n+\t      // two // or four ////\n+\t      // single line comment\n+\t      // (but not an inner or outer doc comment)\n+\t      skip_input ();\n+\t      current_column += 2;\n+\t      current_char = peek_input ();\n+\n+\t      // basically ignore until line finishes\n+\t      while (current_char != '\\n' && current_char != EOF)\n+\t\t{\n+\t\t  skip_input ();\n+\t\t  current_column++; // not used\n+\t\t  current_char = peek_input ();\n+\t\t}\n+\t      continue;\n+\t    }\n+\t  else if (peek_input () == '/'\n+\t\t   && (peek_input (1) == '!' || peek_input (1) == '/'))\n+\t    {\n+\t      /* single line doc comment, inner or outer.  */\n+\t      bool is_inner = peek_input (1) == '!';\n+\t      skip_input (1);\n+\t      current_column += 3;\n+\n+\t      std::string str;\n+\t      str.reserve (32);\n+\t      current_char = peek_input ();\n+\t      while (current_char != '\\n')\n+\t\t{\n+\t\t  skip_input ();\n+\t\t  if (current_char == '\\r')\n+\t\t    {\n+\t\t      char next_char = peek_input ();\n+\t\t      if (next_char == '\\n')\n+\t\t\t{\n+\t\t\t  current_char = '\\n';\n+\t\t\t  break;\n+\t\t\t}\n+\t\t      rust_error_at (\n+\t\t\tloc, \"Isolated CR %<\\\\r%> not allowed in doc comment\");\n+\t\t      current_char = next_char;\n+\t\t      continue;\n+\t\t    }\n+\t\t  if (current_char == EOF)\n+\t\t    {\n+\t\t      rust_error_at (\n+\t\t\tloc, \"unexpected EOF while looking for end of comment\");\n+\t\t      break;\n+\t\t    }\n+\t\t  str += current_char;\n+\t\t  current_char = peek_input ();\n+\t\t}\n+\t      skip_input ();\n+\t      current_line++;\n+\t      current_column = 1;\n+\t      // tell line_table that new line starts\n+\t      start_line (current_line, max_column_hint);\n+\n+\t      str.shrink_to_fit ();\n+\t      if (is_inner)\n+\t\treturn Token::make_inner_doc_comment (loc, std::move (str));\n+\t      else\n+\t\treturn Token::make_outer_doc_comment (loc, std::move (str));\n+\t    }\n+\t  else if (peek_input () == '*' && peek_input (1) == '*'\n+\t\t   && peek_input (2) == '/')\n+\t    {\n+\t      /**/\n+\t      skip_input (2);\n+\t      current_column += 4;\n+\t      continue;\n+\t    }\n+\t  else if (peek_input () == '*' && peek_input (1) == '*'\n+\t\t   && peek_input (2) == '*' && peek_input (3) == '/')\n+\t    {\n+\t      /***/\n+\t      skip_input (3);\n+\t      current_column += 5;\n+\t      continue;\n+\t    }\n+\t  else if ((peek_input () == '*' && peek_input (1) != '!'\n+\t\t    && peek_input (1) != '*')\n+\t\t   || (peek_input () == '*' && peek_input (1) == '*'\n+\t\t       && peek_input (2) == '*'))\n+\t    {\n+\t      // one /* or three /***\n+\t      // block comment\n+\t      // (but not an inner or outer doc comment)\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      int level = 1;\n+\t      while (level > 0)\n+\t\t{\n+\t\t  current_char = peek_input ();\n+\n+\t\t  if (current_char == EOF)\n+\t\t    {\n+\t\t      rust_error_at (\n+\t\t\tloc, \"unexpected EOF while looking for end of comment\");\n+\t\t      break;\n+\t\t    }\n+\n+\t\t  // if /* found\n+\t\t  if (current_char == '/' && peek_input (1) == '*')\n+\t\t    {\n+\t\t      // skip /* characters\n+\t\t      skip_input (1);\n+\n+\t\t      current_column += 2;\n+\n+\t\t      level += 1;\n+\t\t      continue;\n+\t\t    }\n+\n+\t\t  // ignore until */ is found\n+\t\t  if (current_char == '*' && peek_input (1) == '/')\n+\t\t    {\n+\t\t      // skip */ characters\n+\t\t      skip_input (1);\n+\n+\t\t      current_column += 2;\n+\n+\t\t      level -= 1;\n+\t\t      continue;\n+\t\t    }\n+\n+\t\t  if (current_char == '\\n')\n+\t\t    {\n+\t\t      skip_input ();\n+\t\t      current_line++;\n+\t\t      current_column = 1;\n+\t\t      // tell line_table that new line starts\n+\t\t      start_line (current_line, max_column_hint);\n+\t\t      continue;\n+\t\t    }\n+\n+\t\t  skip_input ();\n+\t\t  current_column++;\n+\t\t}\n+\n+\t      // refresh new token\n+\t      continue;\n+\t    }\n+\t  else if (peek_input () == '*'\n+\t\t   && (peek_input (1) == '!' || peek_input (1) == '*'))\n+\t    {\n+\t      // block doc comment, inner /*! or outer /**\n+\t      bool is_inner = peek_input (1) == '!';\n+\t      skip_input (1);\n+\t      current_column += 3;\n+\n+\t      std::string str;\n+\t      str.reserve (96);\n+\n+\t      int level = 1;\n+\t      while (level > 0)\n+\t\t{\n+\t\t  current_char = peek_input ();\n+\n+\t\t  if (current_char == EOF)\n+\t\t    {\n+\t\t      rust_error_at (\n+\t\t\tloc, \"unexpected EOF while looking for end of comment\");\n+\t\t      break;\n+\t\t    }\n+\n+\t\t  // if /* found\n+\t\t  if (current_char == '/' && peek_input (1) == '*')\n+\t\t    {\n+\t\t      // skip /* characters\n+\t\t      skip_input (1);\n+\t\t      current_column += 2;\n+\n+\t\t      level += 1;\n+\t\t      str += \"/*\";\n+\t\t      continue;\n+\t\t    }\n+\n+\t\t  // ignore until */ is found\n+\t\t  if (current_char == '*' && peek_input (1) == '/')\n+\t\t    {\n+\t\t      // skip */ characters\n+\t\t      skip_input (1);\n+\t\t      current_column += 2;\n+\n+\t\t      level -= 1;\n+\t\t      if (level > 0)\n+\t\t\tstr += \"*/\";\n+\t\t      continue;\n+\t\t    }\n+\n+\t\t  if (current_char == '\\r' && peek_input (1) != '\\n')\n+\t\t    rust_error_at (\n+\t\t      loc, \"Isolated CR %<\\\\r%> not allowed in doc comment\");\n+\n+\t\t  if (current_char == '\\n')\n+\t\t    {\n+\t\t      skip_input ();\n+\t\t      current_line++;\n+\t\t      current_column = 1;\n+\t\t      // tell line_table that new line starts\n+\t\t      start_line (current_line, max_column_hint);\n+\t\t      str += '\\n';\n+\t\t      continue;\n+\t\t    }\n+\n+\t\t  str += current_char;\n+\t\t  skip_input ();\n+\t\t  current_column++;\n+\t\t}\n+\n+\t      str.shrink_to_fit ();\n+\t      if (is_inner)\n+\t\treturn Token::make_inner_doc_comment (loc, std::move (str));\n+\t      else\n+\t\treturn Token::make_outer_doc_comment (loc, std::move (str));\n+\t    }\n+\t  else\n+\t    {\n+\t      // division\n+\t      current_column++;\n+\t      return Token::make (DIV, loc);\n+\t    }\n+\tcase '%':\n+\t  if (peek_input () == '=')\n+\t    {\n+\t      // modulo-assign\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (PERCENT_EQ, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // modulo\n+\t      current_column++;\n+\t      return Token::make (PERCENT, loc);\n+\t    }\n+\tcase '^':\n+\t  if (peek_input () == '=')\n+\t    {\n+\t      // xor-assign?\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (CARET_EQ, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // xor?\n+\t      current_column++;\n+\t      return Token::make (CARET, loc);\n+\t    }\n+\tcase '<':\n+\t  if (peek_input () == '<')\n+\t    {\n+\t      if (peek_input (1) == '=')\n+\t\t{\n+\t\t  // left-shift assign\n+\t\t  skip_input (1);\n+\t\t  current_column += 3;\n+\n+\t\t  return Token::make (LEFT_SHIFT_EQ, loc);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  // left-shift\n+\t\t  skip_input ();\n+\t\t  current_column += 2;\n+\n+\t\t  return Token::make (LEFT_SHIFT, loc);\n+\t\t}\n+\t    }\n+\t  else if (peek_input () == '=')\n+\t    {\n+\t      // smaller than or equal to\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (LESS_OR_EQUAL, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // smaller than\n+\t      current_column++;\n+\t      return Token::make (LEFT_ANGLE, loc);\n+\t    }\n+\t  break;\n+\tcase '>':\n+\t  if (peek_input () == '>')\n+\t    {\n+\t      if (peek_input (1) == '=')\n+\t\t{\n+\t\t  // right-shift-assign\n+\t\t  skip_input (1);\n+\t\t  current_column += 3;\n+\n+\t\t  return Token::make (RIGHT_SHIFT_EQ, loc);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  // right-shift\n+\t\t  skip_input ();\n+\t\t  current_column += 2;\n+\n+\t\t  return Token::make (RIGHT_SHIFT, loc);\n+\t\t}\n+\t    }\n+\t  else if (peek_input () == '=')\n+\t    {\n+\t      // larger than or equal to\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (GREATER_OR_EQUAL, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // larger than\n+\t      current_column++;\n+\t      return Token::make (RIGHT_ANGLE, loc);\n+\t    }\n+\tcase ':':\n+\t  if (peek_input () == ':')\n+\t    {\n+\t      // scope resolution ::\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (SCOPE_RESOLUTION, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // single colon :\n+\t      current_column++;\n+\t      return Token::make (COLON, loc);\n+\t    }\n+\tcase '!':\n+\t  // no special handling for macros in lexer?\n+\t  if (peek_input () == '=')\n+\t    {\n+\t      // not equal boolean operator\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (NOT_EQUAL, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // not equal unary operator\n+\t      current_column++;\n+\n+\t      return Token::make (EXCLAM, loc);\n+\t    }\n+\tcase '?':\n+\t  current_column++;\n+\t  return Token::make (QUESTION_MARK, loc);\n+\tcase '#':\n+\t  current_column++;\n+\t  return Token::make (HASH, loc);\n+\tcase '[':\n+\t  current_column++;\n+\t  return Token::make (LEFT_SQUARE, loc);\n+\tcase ']':\n+\t  current_column++;\n+\t  return Token::make (RIGHT_SQUARE, loc);\n+\tcase '{':\n+\t  current_column++;\n+\t  return Token::make (LEFT_CURLY, loc);\n+\tcase '}':\n+\t  current_column++;\n+\t  return Token::make (RIGHT_CURLY, loc);\n+\tcase '@':\n+\t  current_column++;\n+\t  return Token::make (PATTERN_BIND, loc);\n+\tcase '$':\n+\t  current_column++;\n+\t  return Token::make (DOLLAR_SIGN, loc);\n+\tcase '~':\n+\t  current_column++;\n+\t  return Token::make (TILDE, loc);\n+\tcase '\\\\':\n+\t  current_column++;\n+\t  return Token::make (BACKSLASH, loc);\n+\tcase '`':\n+\t  current_column++;\n+\t  return Token::make (BACKTICK, loc);\n+\tcase '|':\n+\t  if (peek_input () == '=')\n+\t    {\n+\t      // bitwise or-assign?\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (PIPE_EQ, loc);\n+\t    }\n+\t  else if (peek_input () == '|')\n+\t    {\n+\t      // logical or\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (OR, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // bitwise or\n+\t      current_column++;\n+\n+\t      return Token::make (PIPE, loc);\n+\t    }\n+\tcase '&':\n+\t  if (peek_input () == '=')\n+\t    {\n+\t      // bitwise and-assign?\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (AMP_EQ, loc);\n+\t    }\n+\t  else if (peek_input () == '&')\n+\t    {\n+\t      // logical and\n+\t      skip_input ();\n+\t      current_column += 2;\n+\n+\t      return Token::make (LOGICAL_AND, loc);\n+\t    }\n+\t  else\n+\t    {\n+\t      // bitwise and/reference\n+\t      current_column++;\n+\n+\t      return Token::make (AMP, loc);\n+\t    }\n+\tcase '.':\n+\t  if (peek_input () == '.')\n+\t    {\n+\t      if (peek_input (1) == '.')\n+\t\t{\n+\t\t  // ellipsis\n+\t\t  skip_input (1);\n+\t\t  current_column += 3;\n+\n+\t\t  return Token::make (ELLIPSIS, loc);\n+\t\t}\n+\t      else if (peek_input (1) == '=')\n+\t\t{\n+\t\t  // ..=\n+\t\t  skip_input (1);\n+\t\t  current_column += 3;\n+\n+\t\t  return Token::make (DOT_DOT_EQ, loc);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  // ..\n+\t\t  skip_input ();\n+\t\t  current_column += 2;\n+\n+\t\t  return Token::make (DOT_DOT, loc);\n+\t\t}\n+\t    }\n+\t  else /*if (!ISDIGIT (peek_input ()))*/\n+\t    {\n+\t      // single dot .\n+\t      // Only if followed by a non-number - otherwise is float\n+\t      // nope, float cannot start with '.'.\n+\t      current_column++;\n+\t      return Token::make (DOT, loc);\n+\t    }\n+\t}\n+      // TODO: special handling of _ in the lexer? instead of being identifier\n+\n+      // byte character, byte string and raw byte string literals\n+      if (current_char == 'b')\n+\t{\n+\t  if (peek_input () == '\\'')\n+\t    return parse_byte_char (loc);\n+\t  else if (peek_input () == '\"')\n+\t    return parse_byte_string (loc);\n+\t  else if (peek_input () == 'r'\n+\t\t   && (peek_input (1) == '#' || peek_input (1) == '\"'))\n+\t    return parse_raw_byte_string (loc);\n+\t}\n+\n+      // raw identifiers and raw strings\n+      if (current_char == 'r')\n+\t{\n+\t  int peek = peek_input ();\n+\t  int peek1 = peek_input (1);\n+\n+\t  if (peek == '#' && (ISALPHA (peek1) || peek1 == '_'))\n+\t    {\n+\t      TokenPtr raw_ident_ptr = parse_raw_identifier (loc);\n+\t      if (raw_ident_ptr != nullptr)\n+\t\treturn raw_ident_ptr;\n+\t      else\n+\t\tcontinue; /* input got parsed, it just wasn't valid. An error\n+\t\t\t     was produced. */\n+\t    }\n+\t  else\n+\t    {\n+\t      TokenPtr maybe_raw_string_ptr = maybe_parse_raw_string (loc);\n+\t      if (maybe_raw_string_ptr != nullptr)\n+\t\treturn maybe_raw_string_ptr;\n+\t    }\n+\t}\n+\n+      // find identifiers and keywords\n+      if (ISALPHA (current_char) || current_char == '_')\n+\treturn parse_identifier_or_keyword (loc);\n+\n+      // int and float literals\n+      if (ISDIGIT (current_char))\n+\t{ //  _ not allowed as first char\n+\t  if (current_char == '0'\n+\t      && is_non_decimal_int_literal_separator (peek_input ()))\n+\t    {\n+\t      // handle binary, octal, hex literals\n+\t      TokenPtr non_dec_int_lit_ptr\n+\t\t= parse_non_decimal_int_literals (loc);\n+\t      if (non_dec_int_lit_ptr != nullptr)\n+\t\treturn non_dec_int_lit_ptr;\n+\t    }\n+\t  else\n+\t    {\n+\t      // handle decimals (integer or float)\n+\t      TokenPtr decimal_or_float_ptr = parse_decimal_int_or_float (loc);\n+\t      if (decimal_or_float_ptr != nullptr)\n+\t\treturn decimal_or_float_ptr;\n+\t    }\n+\t}\n+\n+      // string literals\n+      if (current_char == '\"')\n+\treturn parse_string (loc);\n+\n+      // char literals and lifetime names\n+      if (current_char == '\\'')\n+\t{\n+\t  TokenPtr char_or_lifetime_ptr = parse_char_or_lifetime (loc);\n+\t  if (char_or_lifetime_ptr != nullptr)\n+\t    return char_or_lifetime_ptr;\n+\t}\n+\n+      // DEBUG: check for specific character problems:\n+      if (current_char == '0')\n+\trust_debug (\"'0' uncaught before unexpected character\");\n+      else if (current_char == ']')\n+\trust_debug (\"']' uncaught before unexpected character\");\n+      else if (current_char == 0x5d)\n+\trust_debug (\"whatever 0x5d is (not '0' or ']') uncaught before \"\n+\t\t    \"unexpected character\");\n+\n+      // didn't match anything so error\n+      rust_error_at (loc, \"unexpected character %<%x%>\", current_char);\n+      current_column++;\n+    }\n+}\n+\n+// Parses in a type suffix.\n+std::pair<PrimitiveCoreType, int>\n+Lexer::parse_in_type_suffix ()\n+{\n+  std::string suffix;\n+  suffix.reserve (5);\n+\n+  int additional_length_offset = 0;\n+\n+  // get suffix\n+  while (ISALPHA (current_char) || ISDIGIT (current_char)\n+\t || current_char == '_')\n+    {\n+      if (current_char == '_')\n+\t{\n+\t  // don't add _ to suffix\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\n+\t  additional_length_offset++;\n+\n+\t  continue;\n+\t}\n+\n+      additional_length_offset++;\n+\n+      suffix += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+\n+  if (suffix.empty ())\n+    {\n+      // no type suffix: do nothing but also no error\n+      return std::make_pair (CORETYPE_UNKNOWN, additional_length_offset);\n+    }\n+  else if (suffix == \"f32\")\n+    {\n+      return std::make_pair (CORETYPE_F32, additional_length_offset);\n+    }\n+  else if (suffix == \"f64\")\n+    {\n+      return std::make_pair (CORETYPE_F64, additional_length_offset);\n+    }\n+  else if (suffix == \"i8\")\n+    {\n+      return std::make_pair (CORETYPE_I8, additional_length_offset);\n+    }\n+  else if (suffix == \"i16\")\n+    {\n+      return std::make_pair (CORETYPE_I16, additional_length_offset);\n+    }\n+  else if (suffix == \"i32\")\n+    {\n+      return std::make_pair (CORETYPE_I32, additional_length_offset);\n+    }\n+  else if (suffix == \"i64\")\n+    {\n+      return std::make_pair (CORETYPE_I64, additional_length_offset);\n+    }\n+  else if (suffix == \"i128\")\n+    {\n+      return std::make_pair (CORETYPE_I128, additional_length_offset);\n+    }\n+  else if (suffix == \"isize\")\n+    {\n+      return std::make_pair (CORETYPE_ISIZE, additional_length_offset);\n+    }\n+  else if (suffix == \"u8\")\n+    {\n+      return std::make_pair (CORETYPE_U8, additional_length_offset);\n+    }\n+  else if (suffix == \"u16\")\n+    {\n+      return std::make_pair (CORETYPE_U16, additional_length_offset);\n+    }\n+  else if (suffix == \"u32\")\n+    {\n+      return std::make_pair (CORETYPE_U32, additional_length_offset);\n+    }\n+  else if (suffix == \"u64\")\n+    {\n+      return std::make_pair (CORETYPE_U64, additional_length_offset);\n+    }\n+  else if (suffix == \"u128\")\n+    {\n+      return std::make_pair (CORETYPE_U128, additional_length_offset);\n+    }\n+  else if (suffix == \"usize\")\n+    {\n+      return std::make_pair (CORETYPE_USIZE, additional_length_offset);\n+    }\n+  else\n+    {\n+      rust_error_at (get_current_location (), \"unknown number suffix %qs\",\n+\t\t     suffix.c_str ());\n+\n+      return std::make_pair (CORETYPE_UNKNOWN, additional_length_offset);\n+    }\n+}\n+\n+// Parses in the exponent part (if any) of a float literal.\n+std::pair<std::string, int>\n+Lexer::parse_in_exponent_part ()\n+{\n+  int additional_length_offset = 0;\n+  std::string str;\n+  if (current_char == 'E' || current_char == 'e')\n+    {\n+      // add exponent to string as strtod works with it\n+      str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+\n+      additional_length_offset++;\n+\n+      // special - and + handling\n+      if (current_char == '-')\n+\t{\n+\t  str += '-';\n+\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\n+\t  additional_length_offset++;\n+\t}\n+      else if (current_char == '+')\n+\t{\n+\t  // don't add + but still skip input\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\n+\t  additional_length_offset++;\n+\t}\n+\n+      // parse another decimal number for exponent\n+      auto str_length = parse_in_decimal ();\n+      str += std::get<0> (str_length);\n+      additional_length_offset += std::get<1> (str_length);\n+    }\n+  return std::make_pair (str, additional_length_offset);\n+}\n+\n+// Parses a decimal integer.\n+std::tuple<std::string, int, bool>\n+Lexer::parse_in_decimal ()\n+{\n+  /* A pure decimal contains only digits.  */\n+  bool pure_decimal = true;\n+  int additional_length_offset = 0;\n+  std::string str;\n+  while (ISDIGIT (current_char) || current_char == '_')\n+    {\n+      if (current_char == '_')\n+\t{\n+\t  pure_decimal = false;\n+\t  // don't add _ to number\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\n+\t  additional_length_offset++;\n+\n+\t  continue;\n+\t}\n+\n+      additional_length_offset++;\n+\n+      str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+  return std::make_tuple (str, additional_length_offset, pure_decimal);\n+}\n+\n+/* Parses escapes (and string continues) in \"byte\" strings and characters. Does\n+ * not support unicode. */\n+std::tuple<char, int, bool>\n+Lexer::parse_escape (char opening_char)\n+{\n+  int additional_length_offset = 0;\n+  char output_char = 0;\n+\n+  // skip to actual letter\n+  skip_input ();\n+  current_char = peek_input ();\n+  additional_length_offset++;\n+\n+  switch (current_char)\n+    {\n+      case 'x': {\n+\tauto hex_escape_pair = parse_partial_hex_escape ();\n+\tlong hexLong = hex_escape_pair.first;\n+\tadditional_length_offset += hex_escape_pair.second;\n+\n+\tif (hexLong > 255 || hexLong < 0)\n+\t  rust_error_at (\n+\t    get_current_location (),\n+\t    \"byte \\\\x escape %<\\\\x%x%> out of range - allows up to %<\\\\xFF%>\",\n+\t    static_cast<unsigned int> (hexLong));\n+\t/* TODO: restore capital for escape output - gcc pretty-printer doesn't\n+\t * support %X directly */\n+\tchar hexChar = static_cast<char> (hexLong);\n+\n+\toutput_char = hexChar;\n+      }\n+      break;\n+    case 'n':\n+      output_char = '\\n';\n+      break;\n+    case 'r':\n+      output_char = '\\r';\n+      break;\n+    case 't':\n+      output_char = '\\t';\n+      break;\n+    case '\\\\':\n+      output_char = '\\\\';\n+      break;\n+    case '0':\n+      output_char = '\\0';\n+      break;\n+    case '\\'':\n+      output_char = '\\'';\n+      break;\n+    case '\"':\n+      output_char = '\"';\n+      break;\n+    case 'u':\n+      rust_error_at (get_current_location (),\n+\t\t     \"cannot have a unicode escape \\\\u in a byte %s\",\n+\t\t     opening_char == '\\'' ? \"character\" : \"string\");\n+      // Try to parse it anyway, just to skip it\n+      parse_partial_unicode_escape ();\n+      return std::make_tuple (output_char, additional_length_offset, false);\n+    case '\\r':\n+    case '\\n':\n+      // string continue\n+      return std::make_tuple (0, parse_partial_string_continue (), true);\n+    default:\n+      rust_error_at (get_current_location (),\n+\t\t     \"unknown escape sequence %<\\\\%c%>\", current_char);\n+      // returns false if no parsing could be done\n+      // return false;\n+      return std::make_tuple (output_char, additional_length_offset, false);\n+      break;\n+    }\n+  // all non-special cases (string continue) should skip their used char\n+  skip_input ();\n+  current_char = peek_input ();\n+  additional_length_offset++;\n+\n+  // returns true if parsing was successful\n+  // return true;\n+  return std::make_tuple (output_char, additional_length_offset, false);\n+}\n+\n+/* Parses an escape (or string continue) in a string or character. Supports\n+ * unicode escapes. */\n+std::tuple<Codepoint, int, bool>\n+Lexer::parse_utf8_escape (char opening_char)\n+{\n+  Codepoint output_char;\n+  int additional_length_offset = 0;\n+\n+  // skip to actual letter\n+  skip_input ();\n+  current_char = peek_input ();\n+  additional_length_offset++;\n+\n+  switch (current_char)\n+    {\n+      case 'x': {\n+\tauto hex_escape_pair = parse_partial_hex_escape ();\n+\tlong hexLong = hex_escape_pair.first;\n+\tadditional_length_offset += hex_escape_pair.second;\n+\n+\tif (hexLong > 127 || hexLong < 0)\n+\t  rust_error_at (\n+\t    get_current_location (),\n+\t    \"ascii \\\\x escape %<\\\\x%x%> out of range - allows up to %<\\\\x7F%>\",\n+\t    static_cast<unsigned int> (hexLong));\n+\t/* TODO: restore capital for escape output - gcc pretty-printer doesn't\n+\t * support %X directly */\n+\tchar hexChar = static_cast<char> (hexLong);\n+\n+\toutput_char = hexChar;\n+      }\n+      break;\n+    case 'n':\n+      output_char = '\\n';\n+      break;\n+    case 'r':\n+      output_char = '\\r';\n+      break;\n+    case 't':\n+      output_char = '\\t';\n+      break;\n+    case '\\\\':\n+      output_char = '\\\\';\n+      break;\n+    case '0':\n+      output_char = '\\0';\n+      break;\n+    case '\\'':\n+      output_char = '\\'';\n+      break;\n+    case '\"':\n+      output_char = '\"';\n+      break;\n+      case 'u': {\n+\tauto unicode_escape_pair = parse_partial_unicode_escape ();\n+\toutput_char = unicode_escape_pair.first;\n+\tadditional_length_offset += unicode_escape_pair.second;\n+\n+\treturn std::make_tuple (output_char, additional_length_offset, false);\n+      }\n+      break;\n+    case '\\r':\n+    case '\\n':\n+      // string continue\n+      return std::make_tuple (0, parse_partial_string_continue (), true);\n+    default:\n+      rust_error_at (get_current_location (),\n+\t\t     \"unknown escape sequence %<\\\\%c%>\", current_char);\n+      // returns false if no parsing could be done\n+      // return false;\n+      return std::make_tuple (output_char, additional_length_offset, false);\n+      break;\n+    }\n+  /* all non-special cases (unicode, string continue) should skip their used\n+   * char */\n+  skip_input ();\n+  current_char = peek_input ();\n+  additional_length_offset++;\n+\n+  // returns true if parsing was successful\n+  // return true;\n+  return std::make_tuple (output_char, additional_length_offset, false);\n+}\n+\n+// Parses the body of a string continue that has been found in an escape.\n+int\n+Lexer::parse_partial_string_continue ()\n+{\n+  int additional_length_offset = 1;\n+\n+  // string continue\n+  while (is_whitespace (current_char))\n+    {\n+      if (current_char == '\\n')\n+\t{\n+\t  current_line++;\n+\t  current_column = 1;\n+\t  // tell line_table that new line starts\n+\t  start_line (current_line, max_column_hint);\n+\n+\t  // reset \"length\"\n+\t  additional_length_offset = 1;\n+\n+\t  // get next char\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\n+\t  continue;\n+\t}\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+      additional_length_offset++;\n+    }\n+\n+  return additional_length_offset;\n+}\n+\n+/* Parses the body of a '\\x' escape. Note that it does not check that the number\n+ * is valid and smaller than 255. */\n+std::pair<long, int>\n+Lexer::parse_partial_hex_escape ()\n+{\n+  // hex char string (null-terminated)\n+  char hexNum[3] = {0, 0, 0};\n+\n+  // first hex char\n+  current_char = peek_input (1);\n+  int additional_length_offset = 1;\n+\n+  if (!is_x_digit (current_char))\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"invalid character %<\\\\x%c%> in \\\\x sequence\",\n+\t\t     current_char);\n+      return std::make_pair (0, 0);\n+    }\n+  hexNum[0] = current_char;\n+\n+  // second hex char\n+  skip_input ();\n+  current_char = peek_input (1);\n+  additional_length_offset++;\n+\n+  if (!is_x_digit (current_char))\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"invalid character %<\\\\x%c%c%> in \\\\x sequence\", hexNum[0],\n+\t\t     current_char);\n+      return std::make_pair (0, 1);\n+    }\n+  skip_input ();\n+  hexNum[1] = current_char;\n+\n+  long hexLong = std::strtol (hexNum, nullptr, 16);\n+\n+  return std::make_pair (hexLong, additional_length_offset);\n+}\n+\n+// Parses the body of a unicode escape.\n+std::pair<Codepoint, int>\n+Lexer::parse_partial_unicode_escape ()\n+{\n+  skip_input ();\n+  current_char = peek_input ();\n+  int additional_length_offset = 0;\n+\n+  if (current_char != '{')\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"unicode escape should start with %<{%>\");\n+      /* Skip what should probaby have been between brackets.  */\n+      while (is_x_digit (current_char) || current_char == '_')\n+\t{\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\t  additional_length_offset++;\n+\t}\n+      return std::make_pair (Codepoint (0), additional_length_offset);\n+    }\n+\n+  skip_input ();\n+  current_char = peek_input ();\n+  additional_length_offset++;\n+\n+  if (current_char == '_')\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"unicode escape cannot start with %<_%>\");\n+      skip_input ();\n+      current_char = peek_input ();\n+      additional_length_offset++;\n+      // fallthrough and try to parse the rest anyway\n+    }\n+\n+  // parse unicode escape - 1-6 hex digits\n+  std::string num_str;\n+  num_str.reserve (6);\n+\n+  // loop through to add entire hex number to string\n+  while (is_x_digit (current_char) || current_char == '_')\n+    {\n+      if (current_char == '_')\n+\t{\n+\t  // don't add _ to number\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\n+\t  additional_length_offset++;\n+\n+\t  continue;\n+\t}\n+\n+      additional_length_offset++;\n+\n+      // add raw hex numbers\n+      num_str += current_char;\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+\n+  if (current_char == '}')\n+    {\n+      skip_input ();\n+      current_char = peek_input ();\n+      additional_length_offset++;\n+    }\n+  else\n+    {\n+      // actually an error, but allow propagation anyway Assume that\n+      // wrong bracketm whitespace or single/double quotes are wrong\n+      // termination, otherwise it is a wrong character, then skip to the actual\n+      // terminator.\n+      if (current_char == '{' || is_whitespace (current_char)\n+\t  || current_char == '\\'' || current_char == '\"')\n+\t{\n+\t  rust_error_at (get_current_location (),\n+\t\t\t \"expected terminating %<}%> in unicode escape\");\n+\t  return std::make_pair (Codepoint (0), additional_length_offset);\n+\t}\n+      else\n+\t{\n+\t  rust_error_at (get_current_location (),\n+\t\t\t \"invalid character %<%c%> in unicode escape\",\n+\t\t\t current_char);\n+\t  while (current_char != '}' && current_char != '{'\n+\t\t && !is_whitespace (current_char) && current_char != '\\''\n+\t\t && current_char != '\"')\n+\t    {\n+\t      skip_input ();\n+\t      current_char = peek_input ();\n+\t      additional_length_offset++;\n+\t    }\n+\t  // Consume the actual closing bracket if found\n+\t  if (current_char == '}')\n+\t    {\n+\t      skip_input ();\n+\t      current_char = peek_input ();\n+\t      additional_length_offset++;\n+\t    }\n+\t  return std::make_pair (Codepoint (0), additional_length_offset);\n+\t}\n+    }\n+\n+  // ensure 1-6 hex characters\n+  if (num_str.length () > 6 || num_str.length () < 1)\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"unicode escape should be between 1 and 6 hex \"\n+\t\t     \"characters; it is %lu\",\n+\t\t     (unsigned long) num_str.length ());\n+      // return false;\n+      return std::make_pair (Codepoint (0), additional_length_offset);\n+    }\n+\n+  unsigned long hex_num = std::strtoul (num_str.c_str (), nullptr, 16);\n+\n+  if (hex_num > 0xd7ff && hex_num < 0xe000)\n+    {\n+      rust_error_at (\n+\tget_current_location (),\n+\t\"unicode escape cannot be a surrogate value (D800 to DFFF)\");\n+      return std::make_pair (Codepoint (0), additional_length_offset);\n+    }\n+\n+  if (hex_num > 0x10ffff)\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"unicode escape cannot be larger than 10FFFF\");\n+      return std::make_pair (Codepoint (0), additional_length_offset);\n+    }\n+\n+  // return true;\n+  return std::make_pair (Codepoint (static_cast<uint32_t> (hex_num)),\n+\t\t\t additional_length_offset);\n+}\n+\n+// Parses a byte character.\n+TokenPtr\n+Lexer::parse_byte_char (Location loc)\n+{\n+  skip_input ();\n+  current_column++;\n+  // make current char the next character\n+  current_char = peek_input ();\n+\n+  int length = 1;\n+\n+  // char to save\n+  char byte_char = 0;\n+\n+  // detect escapes\n+  if (current_char == '\\\\')\n+    {\n+      auto escape_length_pair = parse_escape ('\\'');\n+      byte_char = std::get<0> (escape_length_pair);\n+      length += std::get<1> (escape_length_pair);\n+\n+      current_char = peek_input ();\n+\n+      if (current_char != '\\'')\n+\t{\n+\t  rust_error_at (get_current_location (), \"unclosed %<byte char%>\");\n+\t}\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+      length++; // go to next char\n+    }\n+  else if (current_char != '\\'')\n+    {\n+      // otherwise, get character from direct input character\n+      byte_char = current_char;\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+      length++;\n+\n+      if (current_char != '\\'')\n+\t{\n+\t  rust_error_at (get_current_location (), \"unclosed %<byte char%>\");\n+\t}\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+      length++; // go to next char\n+    }\n+  else\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"no character inside %<%> for %<byte char%>\");\n+    }\n+\n+  current_column += length;\n+\n+  return Token::make_byte_char (loc, byte_char);\n+}\n+\n+// Parses a byte string.\n+TokenPtr\n+Lexer::parse_byte_string (Location loc)\n+{\n+  // byte string\n+\n+  // skip quote character\n+  skip_input ();\n+  current_column++;\n+\n+  std::string str;\n+  str.reserve (16); // some sensible default\n+\n+  int length = 1;\n+  current_char = peek_input ();\n+\n+  while (current_char != '\"' && current_char != EOF)\n+    {\n+      if (current_char == '\\\\')\n+\t{\n+\t  auto escape_length_pair = parse_escape ('\"');\n+\t  char output_char = std::get<0> (escape_length_pair);\n+\n+\t  if (output_char == 0 && std::get<2> (escape_length_pair))\n+\t    length = std::get<1> (escape_length_pair) - 1;\n+\t  else\n+\t    length += std::get<1> (escape_length_pair);\n+\n+\t  if (output_char != 0 || !std::get<2> (escape_length_pair))\n+\t    str += output_char;\n+\n+\t  continue;\n+\t}\n+\n+      length++;\n+\n+      str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+\n+  current_column += length;\n+\n+  if (current_char == '\"')\n+    {\n+      current_column++;\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+  else if (current_char == EOF)\n+    {\n+      rust_error_at (get_current_location (), \"unended byte string literal\");\n+      return Token::make (END_OF_FILE, get_current_location ());\n+    }\n+  else\n+    {\n+      gcc_unreachable ();\n+    }\n+\n+  str.shrink_to_fit ();\n+\n+  return Token::make_byte_string (loc, std::move (str));\n+}\n+\n+// Parses a raw byte string.\n+TokenPtr\n+Lexer::parse_raw_byte_string (Location loc)\n+{\n+  // raw byte string literals\n+  std::string str;\n+  str.reserve (16); // some sensible default\n+\n+  int length = 1;\n+  int hash_count = 0;\n+\n+  // get hash count at beginnning\n+  skip_input ();\n+  current_char = peek_input ();\n+  length++;\n+  while (current_char == '#')\n+    {\n+      hash_count++;\n+      length++;\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+\n+  if (current_char != '\"')\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"raw byte string has no opening %<\\\"%>\");\n+    }\n+\n+  skip_input ();\n+  current_char = peek_input ();\n+  length++;\n+\n+  while (true)\n+    {\n+      if (current_char == '\"')\n+\t{\n+\t  bool enough_hashes = true;\n+\n+\t  for (int i = 0; i < hash_count; i++)\n+\t    {\n+\t      if (peek_input (i + 1) != '#')\n+\t\t{\n+\t\t  enough_hashes = false;\n+\t\t  break;\n+\t\t}\n+\t    }\n+\n+\t  if (enough_hashes)\n+\t    {\n+\t      // skip enough input and peek enough input\n+\t      skip_input (hash_count);\n+\t      current_char = peek_input ();\n+\t      length += hash_count + 1;\n+\t      break;\n+\t    }\n+\t}\n+\n+      if ((unsigned char) current_char > 127)\n+\t{\n+\t  rust_error_at (get_current_location (),\n+\t\t\t \"character %<%c%> in raw byte string out of range\",\n+\t\t\t current_char);\n+\t  current_char = 0;\n+\t}\n+\n+      length++;\n+\n+      str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+\n+  current_column += length;\n+\n+  str.shrink_to_fit ();\n+\n+  return Token::make_byte_string (loc, std::move (str));\n+}\n+\n+// Parses a raw identifier.\n+TokenPtr\n+Lexer::parse_raw_identifier (Location loc)\n+{\n+  // raw identifier\n+  std::string str;\n+  str.reserve (16); // default\n+\n+  skip_input ();\n+  current_char = peek_input ();\n+\n+  current_column += 2;\n+\n+  bool first_is_underscore = current_char == '_';\n+\n+  int length = 0;\n+  current_char = peek_input ();\n+  // loop through entire name\n+  while (ISALPHA (current_char) || ISDIGIT (current_char)\n+\t || current_char == '_')\n+    {\n+      length++;\n+\n+      str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+\n+  current_column += length;\n+\n+  // if just a single underscore, not an identifier\n+  if (first_is_underscore && length == 1)\n+    rust_error_at (get_current_location (),\n+\t\t   \"%<_%> is not a valid raw identifier\");\n+\n+  if (str == \"crate\" || str == \"extern\" || str == \"self\" || str == \"super\"\n+      || str == \"Self\")\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"%qs is a forbidden raw identifier\", str.c_str ());\n+\n+      return nullptr;\n+    }\n+  else\n+    {\n+      str.shrink_to_fit ();\n+\n+      return Token::make_identifier (loc, std::move (str));\n+    }\n+}\n+\n+// skip broken string input (unterminated strings)\n+void\n+Lexer::skip_broken_string_input (int current_char)\n+{\n+  while (current_char != '\"' && current_char != EOF)\n+    {\n+      if (current_char == '\\n')\n+\t{\n+\t  current_line++;\n+\t  current_column = 1;\n+\t}\n+      else\n+\t{\n+\t  current_column++;\n+\t}\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+  if (current_char == '\"')\n+    {\n+      current_column++;\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+  rust_debug (\"skipped to %d:%d due to bad quotes\", current_line,\n+\t      current_column);\n+}\n+\n+// Parses a unicode string.\n+TokenPtr\n+Lexer::parse_string (Location loc)\n+{\n+  Codepoint current_char32;\n+\n+  std::string str;\n+  str.reserve (16); // some sensible default\n+\n+  int length = 1;\n+  current_char32 = peek_codepoint_input ();\n+\n+  // FIXME: This fails if the input ends. How do we check for EOF?\n+  while (current_char32.value != '\"' && !current_char32.is_eof ())\n+    {\n+      if (current_char32.value == '\\\\')\n+\t{\n+\t  // parse escape\n+\t  auto utf8_escape_pair = parse_utf8_escape ('\\'');\n+\t  current_char32 = std::get<0> (utf8_escape_pair);\n+\n+\t  if (current_char32 == Codepoint (0) && std::get<2> (utf8_escape_pair))\n+\t    length = std::get<1> (utf8_escape_pair) - 1;\n+\t  else\n+\t    length += std::get<1> (utf8_escape_pair);\n+\n+\t  if (current_char32 != Codepoint (0)\n+\t      || !std::get<2> (utf8_escape_pair))\n+\t    str += current_char32;\n+\n+\t  // required as parsing utf8 escape only changes current_char\n+\t  current_char32 = peek_codepoint_input ();\n+\n+\t  continue;\n+\t}\n+\n+      length += get_input_codepoint_length ();\n+\n+      str += current_char32;\n+      skip_codepoint_input ();\n+      current_char32 = peek_codepoint_input ();\n+    }\n+\n+  current_column += length;\n+\n+  if (current_char32.value == '\"')\n+    {\n+      current_column++;\n+\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+  else if (current_char32.is_eof ())\n+    {\n+      rust_error_at (get_current_location (), \"unended string literal\");\n+      return Token::make (END_OF_FILE, get_current_location ());\n+    }\n+  else\n+    {\n+      gcc_unreachable ();\n+    }\n+\n+  str.shrink_to_fit ();\n+  return Token::make_string (loc, std::move (str));\n+}\n+\n+// Parses an identifier or keyword.\n+TokenPtr\n+Lexer::parse_identifier_or_keyword (Location loc)\n+{\n+  std::string str;\n+  str.reserve (16); // default\n+  str += current_char;\n+\n+  bool first_is_underscore = current_char == '_';\n+\n+  int length = 1;\n+  current_char = peek_input ();\n+  // loop through entire name\n+  while (ISALPHA (current_char) || ISDIGIT (current_char)\n+\t || current_char == '_')\n+    {\n+      length++;\n+\n+      str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+\n+  current_column += length;\n+\n+  // if just a single underscore, not an identifier\n+  if (first_is_underscore && length == 1)\n+    return Token::make (UNDERSCORE, loc);\n+\n+  str.shrink_to_fit ();\n+\n+  TokenId keyword = classify_keyword (str);\n+  if (keyword == IDENTIFIER)\n+    return Token::make_identifier (loc, std::move (str));\n+  else\n+    return Token::make (keyword, loc);\n+}\n+\n+// Possibly returns a raw string token if it exists - otherwise returns null.\n+TokenPtr\n+Lexer::maybe_parse_raw_string (Location loc)\n+{\n+  int peek_index = 0;\n+  while (peek_input (peek_index) == '#')\n+    peek_index++;\n+\n+  if (peek_input (peek_index) == '\"')\n+    return parse_raw_string (loc, peek_index);\n+  else\n+    return nullptr;\n+}\n+\n+// Returns a raw string token.\n+TokenPtr\n+Lexer::parse_raw_string (Location loc, int initial_hash_count)\n+{\n+  // raw string literals\n+  std::string str;\n+  str.reserve (16); // some sensible default\n+\n+  int length = 1 + initial_hash_count;\n+\n+  if (initial_hash_count > 0)\n+    skip_input (initial_hash_count - 1);\n+\n+  current_char = peek_input ();\n+\n+  if (current_char != '\"')\n+    rust_error_at (get_current_location (), \"raw string has no opening %<\\\"%>\");\n+\n+  length++;\n+  skip_input ();\n+  Codepoint current_char32 = peek_codepoint_input ();\n+\n+  while (!current_char32.is_eof ())\n+    {\n+      if (current_char32.value == '\"')\n+\t{\n+\t  bool enough_hashes = true;\n+\n+\t  for (int i = 0; i < initial_hash_count; i++)\n+\t    {\n+\t      if (peek_input (i + 1) != '#')\n+\t\t{\n+\t\t  enough_hashes = false;\n+\t\t  break;\n+\t\t}\n+\t    }\n+\n+\t  if (enough_hashes)\n+\t    {\n+\t      // skip enough input and peek enough input\n+\t      skip_input (initial_hash_count);\n+\t      current_char = peek_input ();\n+\t      length += initial_hash_count + 1;\n+\t      break;\n+\t    }\n+\t}\n+\n+      length++;\n+\n+      str += current_char32;\n+      skip_codepoint_input ();\n+      current_char32 = peek_codepoint_input ();\n+    }\n+\n+  current_column += length;\n+\n+  str.shrink_to_fit ();\n+\n+  return Token::make_string (loc, std::move (str));\n+}\n+\n+template <typename IsDigitFunc>\n+TokenPtr\n+Lexer::parse_non_decimal_int_literal (Location loc, IsDigitFunc is_digit_func,\n+\t\t\t\t      std::string existent_str, int base)\n+{\n+  int length = 1;\n+\n+  skip_input ();\n+  current_char = peek_input ();\n+\n+  length++;\n+\n+  // loop through to add entire number to string\n+  while (is_digit_func (current_char) || current_char == '_')\n+    {\n+      if (current_char == '_')\n+\t{\n+\t  // don't add _ to number\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\n+\t  length++;\n+\n+\t  continue;\n+\t}\n+\n+      length++;\n+\n+      // add raw numbers\n+      existent_str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+    }\n+\n+  // convert value to decimal representation\n+  long dec_num = std::strtol (existent_str.c_str (), nullptr, base);\n+\n+  existent_str = std::to_string (dec_num);\n+\n+  // parse in type suffix if it exists\n+  auto type_suffix_pair = parse_in_type_suffix ();\n+  PrimitiveCoreType type_hint = type_suffix_pair.first;\n+  length += type_suffix_pair.second;\n+\n+  current_column += length;\n+\n+  if (type_hint == CORETYPE_F32 || type_hint == CORETYPE_F64)\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"invalid type suffix %qs for integer (%s) literal\",\n+\t\t     get_type_hint_string (type_hint),\n+\t\t     base == 16\n+\t\t       ? \"hex\"\n+\t\t       : (base == 8 ? \"octal\"\n+\t\t\t\t    : (base == 2 ? \"binary\"\n+\t\t\t\t\t\t : \"<insert unknown base>\")));\n+      return nullptr;\n+    }\n+  return Token::make_int (loc, std::move (existent_str), type_hint);\n+}\n+\n+// Parses a hex, binary or octal int literal.\n+TokenPtr\n+Lexer::parse_non_decimal_int_literals (Location loc)\n+{\n+  std::string str;\n+  str.reserve (16); // some sensible default\n+  str += current_char;\n+\n+  current_char = peek_input ();\n+\n+  if (current_char == 'x')\n+    {\n+      // hex (integer only)\n+      return parse_non_decimal_int_literal (loc, is_x_digit, str + \"x\", 16);\n+    }\n+  else if (current_char == 'o')\n+    {\n+      // octal (integer only)\n+      return parse_non_decimal_int_literal (loc, is_octal_digit,\n+\t\t\t\t\t    std::move (str), 8);\n+    }\n+  else if (current_char == 'b')\n+    {\n+      // binary (integer only)\n+      return parse_non_decimal_int_literal (loc, is_bin_digit, std::move (str),\n+\t\t\t\t\t    2);\n+    }\n+  else\n+    {\n+      return nullptr;\n+    }\n+}\n+\n+// Parses a decimal-based int literal or float literal.\n+TokenPtr\n+Lexer::parse_decimal_int_or_float (Location loc)\n+{\n+  std::string str;\n+  str.reserve (16); // some sensible default\n+  str += current_char;\n+\n+  int length = 1;\n+  bool first_zero = current_char == '0';\n+\n+  current_char = peek_input ();\n+\n+  // parse initial decimal integer (or first integer part of float) literal\n+  auto initial_decimal = parse_in_decimal ();\n+  str += std::get<0> (initial_decimal);\n+  length += std::get<1> (initial_decimal);\n+\n+  // detect float literal\n+  if (current_char == '.' && is_float_digit (peek_input (1)))\n+    {\n+      // float with a '.', parse another decimal into it\n+\n+      // add . to str\n+      str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+      length++;\n+\n+      // parse another decimal number for float\n+      auto second_decimal = parse_in_decimal ();\n+      str += std::get<0> (second_decimal);\n+      length += std::get<1> (second_decimal);\n+\n+      // parse in exponent part if it exists\n+      auto exponent_pair = parse_in_exponent_part ();\n+      str += exponent_pair.first;\n+      length += exponent_pair.second;\n+\n+      // parse in type suffix if it exists\n+      auto type_suffix_pair = parse_in_type_suffix ();\n+      PrimitiveCoreType type_hint = type_suffix_pair.first;\n+      length += type_suffix_pair.second;\n+\n+      if (type_hint != CORETYPE_F32 && type_hint != CORETYPE_F64\n+\t  && type_hint != CORETYPE_UNKNOWN)\n+\t{\n+\t  rust_error_at (get_current_location (),\n+\t\t\t \"invalid type suffix %qs for floating-point literal\",\n+\t\t\t get_type_hint_string (type_hint));\n+\t  // ignore invalid type suffix as everything else seems fine\n+\t  type_hint = CORETYPE_UNKNOWN;\n+\t}\n+\n+      current_column += length;\n+\n+      str.shrink_to_fit ();\n+      return Token::make_float (loc, std::move (str), type_hint);\n+    }\n+  else if (current_char == '.' && check_valid_float_dot_end (peek_input (1)))\n+    {\n+      // float that is just an integer with a terminating '.' character\n+\n+      // add . to str\n+      str += current_char;\n+      skip_input ();\n+      current_char = peek_input ();\n+      length++;\n+\n+      // add a '0' after the . to prevent ambiguity\n+      str += '0';\n+\n+      // type hint not allowed\n+\n+      current_column += length;\n+\n+      str.shrink_to_fit ();\n+      return Token::make_float (loc, std::move (str), CORETYPE_UNKNOWN);\n+    }\n+  else if (current_char == 'E' || current_char == 'e')\n+    {\n+      // exponent float with no '.' character\n+\n+      // parse exponent part\n+      auto exponent_pair = parse_in_exponent_part ();\n+      str += exponent_pair.first;\n+      length += exponent_pair.second;\n+\n+      // parse in type suffix if it exists\n+      auto type_suffix_pair = parse_in_type_suffix ();\n+      PrimitiveCoreType type_hint = type_suffix_pair.first;\n+      length += type_suffix_pair.second;\n+\n+      if (type_hint != CORETYPE_F32 && type_hint != CORETYPE_F64\n+\t  && type_hint != CORETYPE_UNKNOWN)\n+\t{\n+\t  rust_error_at (get_current_location (),\n+\t\t\t \"invalid type suffix %qs for floating-point literal\",\n+\t\t\t get_type_hint_string (type_hint));\n+\t  // ignore invalid type suffix as everything else seems fine\n+\t  type_hint = CORETYPE_UNKNOWN;\n+\t}\n+\n+      current_column += length;\n+\n+      str.shrink_to_fit ();\n+      return Token::make_float (loc, std::move (str), type_hint);\n+    }\n+  else\n+    {\n+      // is an integer\n+\n+      // parse in type suffix if it exists\n+      auto type_suffix_pair = parse_in_type_suffix ();\n+      PrimitiveCoreType type_hint = type_suffix_pair.first;\n+      /* A \"real\" pure decimal doesn't have a suffix and no zero prefix.  */\n+      if (type_hint == CORETYPE_UNKNOWN)\n+\t{\n+\t  bool pure_decimal = std::get<2> (initial_decimal);\n+\t  if (pure_decimal && (!first_zero || str.size () == 1))\n+\t    type_hint = CORETYPE_PURE_DECIMAL;\n+\t}\n+      length += type_suffix_pair.second;\n+\n+      current_column += length;\n+\n+      str.shrink_to_fit ();\n+      return Token::make_int (loc, std::move (str), type_hint);\n+    }\n+}\n+\n+TokenPtr\n+Lexer::parse_char_or_lifetime (Location loc)\n+{\n+  Codepoint current_char32;\n+\n+  int length = 1;\n+\n+  current_char32 = peek_codepoint_input ();\n+  if (current_char32.is_eof ())\n+    return nullptr;\n+\n+  // parse escaped char literal\n+  if (current_char32.value == '\\\\')\n+    {\n+      // parse escape\n+      auto utf8_escape_pair = parse_utf8_escape ('\\'');\n+      current_char32 = std::get<0> (utf8_escape_pair);\n+      length += std::get<1> (utf8_escape_pair);\n+\n+      if (peek_codepoint_input ().value != '\\'')\n+\t{\n+\t  rust_error_at (get_current_location (), \"unended character literal\");\n+\t}\n+      else\n+\t{\n+\t  skip_codepoint_input ();\n+\t  current_char = peek_input ();\n+\t  length++;\n+\t}\n+\n+      current_column += length;\n+\n+      return Token::make_char (loc, current_char32);\n+    }\n+  else\n+    {\n+      skip_codepoint_input ();\n+\n+      if (peek_codepoint_input ().value == '\\'')\n+\t{\n+\t  // parse non-escaped char literal\n+\n+\t  // skip the ' character\n+\t  skip_input ();\n+\t  current_char = peek_input ();\n+\n+\t  // TODO fix due to different widths of utf-8 chars?\n+\t  current_column += 3;\n+\n+\t  return Token::make_char (loc, current_char32);\n+\t}\n+      else if (ISDIGIT (current_char32.value) || ISALPHA (current_char32.value)\n+\t       || current_char32.value == '_')\n+\t{\n+\t  // parse lifetime name\n+\t  std::string str;\n+\t  str += current_char32;\n+\t  length++;\n+\n+\t  current_char = peek_input ();\n+\t  while (ISDIGIT (current_char) || ISALPHA (current_char)\n+\t\t || current_char == '_')\n+\t    {\n+\t      str += current_char;\n+\t      skip_input ();\n+\t      current_char = peek_input ();\n+\t      length++;\n+\t    }\n+\n+\t  current_column += length;\n+\n+\t  str.shrink_to_fit ();\n+\t  return Token::make_lifetime (loc, std::move (str));\n+\t}\n+      else\n+\t{\n+\t  rust_error_at (\n+\t    get_current_location (),\n+\t    \"expected %' after character constant in character literal\");\n+\t  return nullptr;\n+\t}\n+    }\n+}\n+\n+// Returns the length of the codepoint at the current position.\n+int\n+Lexer::get_input_codepoint_length ()\n+{\n+  uint8_t input = peek_input ();\n+\n+  if ((int8_t) input == EOF)\n+    return 0;\n+\n+  if (input < 128)\n+    {\n+      // ascii -- 1 byte\n+      // return input;\n+\n+      return 1;\n+    }\n+  else if ((input & 0xC0) == 0x80)\n+    {\n+      // invalid (continuation; can't be first char)\n+      // return 0xFFFE;\n+\n+      return 0;\n+    }\n+  else if ((input & 0xE0) == 0xC0)\n+    {\n+      // 2 bytes\n+      uint8_t input2 = peek_input (1);\n+      if ((input2 & 0xC0) != 0x80)\n+\treturn 0;\n+      // return 0xFFFE;\n+\n+      // uint32_t output = ((input & 0x1F) << 6) | ((input2 & 0x3F) << 0);\n+      // return output;\n+      return 2;\n+    }\n+  else if ((input & 0xF0) == 0xE0)\n+    {\n+      // 3 bytes\n+      uint8_t input2 = peek_input (1);\n+      if ((input2 & 0xC0) != 0x80)\n+\treturn 0;\n+      // return 0xFFFE;\n+\n+      uint8_t input3 = peek_input (2);\n+      if ((input3 & 0xC0) != 0x80)\n+\treturn 0;\n+      // return 0xFFFE;\n+\n+      /*uint32_t output\n+\t= ((input & 0x0F) << 12) | ((input2 & 0x3F) << 6) | ((input3 & 0x3F) <<\n+      0); return output;*/\n+      return 3;\n+    }\n+  else if ((input & 0xF8) == 0xF0)\n+    {\n+      // 4 bytes\n+      uint8_t input2 = peek_input (1);\n+      if ((input2 & 0xC0) != 0x80)\n+\treturn 0;\n+      // return 0xFFFE;\n+\n+      uint8_t input3 = peek_input (2);\n+      if ((input3 & 0xC0) != 0x80)\n+\treturn 0;\n+      // return 0xFFFE;\n+\n+      uint8_t input4 = peek_input (3);\n+      if ((input4 & 0xC0) != 0x80)\n+\treturn 0;\n+      // return 0xFFFE;\n+\n+      /*uint32_t output = ((input & 0x07) << 18) | ((input2 & 0x3F) << 12)\n+\t\t\t| ((input3 & 0x3F) << 6) | ((input4 & 0x3F) << 0);\n+      return output;*/\n+      return 4;\n+    }\n+  else\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"invalid UTF-8 [FIRST] (too long)\");\n+      return 0;\n+    }\n+}\n+\n+// Returns the codepoint at the current position.\n+Codepoint\n+Lexer::peek_codepoint_input ()\n+{\n+  uint8_t input = peek_input ();\n+\n+  if ((int8_t) input == EOF)\n+    return Codepoint::eof ();\n+\n+  if (input < 128)\n+    {\n+      // ascii -- 1 byte\n+      return {input};\n+    }\n+  else if ((input & 0xC0) == 0x80)\n+    {\n+      // invalid (continuation; can't be first char)\n+      return {0xFFFE};\n+    }\n+  else if ((input & 0xE0) == 0xC0)\n+    {\n+      // 2 bytes\n+      uint8_t input2 = peek_input (1);\n+      if ((input2 & 0xC0) != 0x80)\n+\treturn {0xFFFE};\n+\n+      uint32_t output = ((input & 0x1F) << 6) | ((input2 & 0x3F) << 0);\n+      return {output};\n+    }\n+  else if ((input & 0xF0) == 0xE0)\n+    {\n+      // 3 bytes\n+      uint8_t input2 = peek_input (1);\n+      if ((input2 & 0xC0) != 0x80)\n+\treturn {0xFFFE};\n+\n+      uint8_t input3 = peek_input (2);\n+      if ((input3 & 0xC0) != 0x80)\n+\treturn {0xFFFE};\n+\n+      uint32_t output = ((input & 0x0F) << 12) | ((input2 & 0x3F) << 6)\n+\t\t\t| ((input3 & 0x3F) << 0);\n+      return {output};\n+    }\n+  else if ((input & 0xF8) == 0xF0)\n+    {\n+      // 4 bytes\n+      uint8_t input2 = peek_input (1);\n+      if ((input2 & 0xC0) != 0x80)\n+\treturn {0xFFFE};\n+\n+      uint8_t input3 = peek_input (2);\n+      if ((input3 & 0xC0) != 0x80)\n+\treturn {0xFFFE};\n+\n+      uint8_t input4 = peek_input (3);\n+      if ((input4 & 0xC0) != 0x80)\n+\treturn {0xFFFE};\n+\n+      uint32_t output = ((input & 0x07) << 18) | ((input2 & 0x3F) << 12)\n+\t\t\t| ((input3 & 0x3F) << 6) | ((input4 & 0x3F) << 0);\n+      return {output};\n+    }\n+  else\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"invalid UTF-8 [SECND] (too long)\");\n+      return {0xFFFE};\n+    }\n+}\n+\n+void\n+Lexer::skip_codepoint_input ()\n+{\n+  int toSkip = get_input_codepoint_length ();\n+  gcc_assert (toSkip >= 1);\n+\n+  skip_input (toSkip - 1);\n+}\n+\n+int\n+Lexer::test_get_input_codepoint_n_length (int n_start_offset)\n+{\n+  uint8_t input = peek_input (n_start_offset);\n+\n+  if (input < 128)\n+    {\n+      // ascii -- 1 byte\n+      // return input;\n+      return 1;\n+    }\n+  else if ((input & 0xC0) == 0x80)\n+    {\n+      // invalid (continuation; can't be first char)\n+      // return 0xFFFE;\n+      return 0;\n+    }\n+  else if ((input & 0xE0) == 0xC0)\n+    {\n+      // 2 bytes\n+      uint8_t input2 = peek_input (n_start_offset + 1);\n+      if ((input2 & 0xC0) != 0x80)\n+\t// return 0xFFFE;\n+\treturn 0;\n+\n+      // uint32_t output = ((input & 0x1F) << 6) | ((input2 & 0x3F) << 0);\n+      // return output;\n+      return 2;\n+    }\n+  else if ((input & 0xF0) == 0xE0)\n+    {\n+      // 3 bytes\n+      uint8_t input2 = peek_input (n_start_offset + 1);\n+      if ((input2 & 0xC0) != 0x80)\n+\t// return 0xFFFE;\n+\treturn 0;\n+\n+      uint8_t input3 = peek_input (n_start_offset + 2);\n+      if ((input3 & 0xC0) != 0x80)\n+\t// return 0xFFFE;\n+\treturn 0;\n+\n+      /*uint32_t output\n+\t= ((input & 0x0F) << 12) | ((input2 & 0x3F) << 6) | ((input3 & 0x3F) <<\n+      0); return output;*/\n+      return 3;\n+    }\n+  else if ((input & 0xF8) == 0xF0)\n+    {\n+      // 4 bytes\n+      uint8_t input2 = peek_input (n_start_offset + 1);\n+      if ((input2 & 0xC0) != 0x80)\n+\t// return 0xFFFE;\n+\treturn 0;\n+\n+      uint8_t input3 = peek_input (n_start_offset + 2);\n+      if ((input3 & 0xC0) != 0x80)\n+\t// return 0xFFFE;\n+\treturn 0;\n+\n+      uint8_t input4 = peek_input (n_start_offset + 3);\n+      if ((input4 & 0xC0) != 0x80)\n+\t// return 0xFFFE;\n+\treturn 0;\n+\n+      /*uint32_t output = ((input & 0x07) << 18) | ((input2 & 0x3F) << 12)\n+\t\t\t| ((input3 & 0x3F) << 6) | ((input4 & 0x3F) << 0);\n+      return output;*/\n+      return 4;\n+    }\n+  else\n+    {\n+      rust_error_at (get_current_location (),\n+\t\t     \"invalid UTF-8 [THIRD] (too long)\");\n+      return 0;\n+    }\n+}\n+\n+// peeks the codepoint input at n codepoints ahead of current codepoint - try\n+// not to use\n+Codepoint\n+Lexer::test_peek_codepoint_input (int n)\n+{\n+  int totalOffset = 0;\n+\n+  // add up all offsets into total offset? does this do what I want?\n+  for (int i = 0; i < n; i++)\n+    {\n+      totalOffset += test_get_input_codepoint_n_length (totalOffset);\n+    }\n+  // issues: this would have (at least) O(n) lookup time, not O(1) like the\n+  // rest?\n+\n+  // TODO: implement if still needed\n+\n+  // error out of function as it is not implemented\n+  gcc_assert (1 == 0);\n+  return {0};\n+  /*\n+\t  uint8_t input = peek_input();\n+\n+\t  if (input < 128) {\n+\t      // ascii -- 1 byte\n+\t      return input;\n+\t  } else if ((input & 0xC0) == 0x80) {\n+\t      // invalid (continuation; can't be first char)\n+\t      return 0xFFFE;\n+\t  } else if ((input & 0xE0) == 0xC0) {\n+\t      // 2 bytes\n+\t      uint8_t input2 = peek_input(1);\n+\t      if ((input2 & 0xC0) != 0x80)\n+\t\t  return 0xFFFE;\n+\n+\t      uint32_t output = ((input & 0x1F) << 6) | ((input2 & 0x3F) << 0);\n+\t      return output;\n+\t  } else if ((input & 0xF0) == 0xE0) {\n+\t      // 3 bytes\n+\t      uint8_t input2 = peek_input(1);\n+\t      if ((input2 & 0xC0) != 0x80)\n+\t\t  return 0xFFFE;\n+\n+\t      uint8_t input3 = peek_input(2);\n+\t      if ((input3 & 0xC0) != 0x80)\n+\t\t  return 0xFFFE;\n+\n+\t      uint32_t output\n+\t\t= ((input & 0x0F) << 12) | ((input2 & 0x3F) << 6) | ((input3 &\n+     0x3F) << 0); return output; } else if ((input & 0xF8) == 0xF0) {\n+\t      // 4 bytes\n+\t      uint8_t input2 = peek_input(1);\n+\t      if ((input2 & 0xC0) != 0x80)\n+\t\t  return 0xFFFE;\n+\n+\t      uint8_t input3 = peek_input(2);\n+\t      if ((input3 & 0xC0) != 0x80)\n+\t\t  return 0xFFFE;\n+\n+\t      uint8_t input4 = peek_input(3);\n+\t      if ((input4 & 0xC0) != 0x80)\n+\t\t  return 0xFFFE;\n+\n+\t      uint32_t output = ((input & 0x07) << 18) | ((input2 & 0x3F) << 12)\n+\t\t\t\t| ((input3 & 0x3F) << 6) | ((input4 & 0x3F) <<\n+     0); return output; } else { rust_error_at(get_current_location(), \"invalid\n+     UTF-8 (too long)\"); return 0xFFFE;\n+\t  }*/\n+}\n+\n+void\n+Lexer::split_current_token (TokenId new_left, TokenId new_right)\n+{\n+  /* TODO: assert that this TokenId is a \"simple token\" like punctuation and not\n+   * like \"IDENTIFIER\"? */\n+  Location current_loc = peek_token ()->get_locus ();\n+  TokenPtr new_left_tok = Token::make (new_left, current_loc);\n+  TokenPtr new_right_tok = Token::make (new_right, current_loc + 1);\n+\n+  token_queue.replace_current_value (std::move (new_left_tok));\n+  token_queue.insert (1, std::move (new_right_tok));\n+}\n+\n+void\n+Lexer::start_line (int current_line, int current_column)\n+{\n+  if (line_map)\n+    line_map->start_line (current_line, current_column);\n+}\n+\n+} // namespace Rust"}, {"sha": "d5a6c53719ff24b82d728da88132d8f4e5429e80", "filename": "gcc/rust/lex/rust-lex.h", "status": "added", "additions": 271, "deletions": 0, "changes": 271, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-lex.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-lex.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-lex.h?ref=18f6990f842d0bdcb2cf9541ca98d67b414d5802", "patch": "@@ -0,0 +1,271 @@\n+// Copyright (C) 2020-2022 Free Software Foundation, Inc.\n+\n+// This file is part of GCC.\n+\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#ifndef RUST_LEX_H\n+#define RUST_LEX_H\n+\n+#include \"rust-linemap.h\"\n+#include \"rust-buffered-queue.h\"\n+#include \"rust-token.h\"\n+\n+namespace Rust {\n+// Simple wrapper for FILE* that simplifies destruction.\n+struct RAIIFile\n+{\n+private:\n+  FILE *file;\n+  const char *filename;\n+\n+  void close ()\n+  {\n+    if (file != nullptr && file != stdin)\n+      fclose (file);\n+  }\n+\n+public:\n+  RAIIFile (const char *filename) : filename (filename)\n+  {\n+    if (strcmp (filename, \"-\") == 0)\n+      file = stdin;\n+    else\n+      file = fopen (filename, \"r\");\n+  }\n+\n+  /**\n+   * Create a RAIIFile from an existing instance of FILE*\n+   */\n+  RAIIFile (FILE *raw, const char *filename = nullptr)\n+    : file (raw), filename (filename)\n+  {}\n+\n+  RAIIFile (const RAIIFile &other) = delete;\n+  RAIIFile &operator= (const RAIIFile &other) = delete;\n+\n+  // have to specify setting file to nullptr, otherwise unintended fclose occurs\n+  RAIIFile (RAIIFile &&other) : file (other.file), filename (other.filename)\n+  {\n+    other.file = nullptr;\n+  }\n+\n+  RAIIFile &operator= (RAIIFile &&other)\n+  {\n+    close ();\n+    file = other.file;\n+    filename = other.filename;\n+    other.file = nullptr;\n+\n+    return *this;\n+  }\n+\n+  static RAIIFile create_error () { return RAIIFile (nullptr, nullptr); }\n+\n+  ~RAIIFile () { close (); }\n+\n+  FILE *get_raw () { return file; }\n+  const char *get_filename () { return filename; }\n+\n+  bool ok () const { return file; }\n+};\n+\n+class Lexer\n+{\n+private:\n+  // Request new Location for current column in line_table\n+  Location get_current_location ();\n+\n+  // Skips the current input char.\n+  void skip_input ();\n+  // Advances current input char to n + 1 chars ahead of current position.\n+  void skip_input (int n);\n+\n+  // Returns char n chars ahead of current position.\n+  int peek_input ();\n+  // Peeks the current char.\n+  int peek_input (int n);\n+\n+  // Classifies keyword (i.e. gets id for keyword).\n+  TokenId classify_keyword (const std::string &str);\n+\n+  // Builds a token from the input queue.\n+  TokenPtr build_token ();\n+\n+  std::tuple<std::string, int, bool> parse_in_decimal ();\n+  std::pair<std::string, int> parse_in_exponent_part ();\n+  std::pair<PrimitiveCoreType, int> parse_in_type_suffix ();\n+  std::tuple<char, int, bool> parse_escape (char opening_char);\n+  std::tuple<Codepoint, int, bool> parse_utf8_escape (char opening_char);\n+  int parse_partial_string_continue ();\n+  std::pair<long, int> parse_partial_hex_escape ();\n+  std::pair<Codepoint, int> parse_partial_unicode_escape ();\n+\n+  int get_input_codepoint_length ();\n+  int test_get_input_codepoint_n_length (int n_start_offset);\n+  Codepoint peek_codepoint_input ();\n+  Codepoint test_peek_codepoint_input (int n);\n+  void skip_codepoint_input ();\n+  void skip_broken_string_input (int current_char);\n+\n+  TokenPtr parse_byte_char (Location loc);\n+  TokenPtr parse_byte_string (Location loc);\n+  TokenPtr parse_raw_byte_string (Location loc);\n+  TokenPtr parse_raw_identifier (Location loc);\n+  TokenPtr parse_string (Location loc);\n+  TokenPtr maybe_parse_raw_string (Location loc);\n+  TokenPtr parse_raw_string (Location loc, int initial_hash_count);\n+  TokenPtr parse_non_decimal_int_literals (Location loc);\n+  TokenPtr parse_decimal_int_or_float (Location loc);\n+  TokenPtr parse_char_or_lifetime (Location loc);\n+  TokenPtr parse_identifier_or_keyword (Location loc);\n+\n+  template <typename IsDigitFunc>\n+  TokenPtr parse_non_decimal_int_literal (Location loc,\n+\t\t\t\t\t  IsDigitFunc is_digit_func,\n+\t\t\t\t\t  std::string existent_str, int base);\n+\n+public:\n+  // Construct lexer with input file and filename provided\n+  Lexer (const char *filename, RAIIFile input, Linemap *linemap);\n+\n+  // Lex the contents of a string instead of a file\n+  Lexer (const std::string &input);\n+\n+  // dtor\n+  ~Lexer ();\n+\n+  // don't allow copy semantics (for now, at least)\n+  Lexer (const Lexer &other) = delete;\n+  Lexer &operator= (const Lexer &other) = delete;\n+\n+  // enable move semantics\n+  Lexer (Lexer &&other) = default;\n+  Lexer &operator= (Lexer &&other) = default;\n+\n+  // Returns token n tokens ahead of current position.\n+  const_TokenPtr peek_token (int n) { return token_queue.peek (n); }\n+  // Peeks the current token.\n+  const_TokenPtr peek_token () { return peek_token (0); }\n+\n+  // Advances current token to n + 1 tokens ahead of current position.\n+  void skip_token (int n) { token_queue.skip (n); }\n+  // Skips the current token.\n+  void skip_token () { skip_token (0); }\n+\n+  // Replaces the current token with a specified token.\n+  void replace_current_token (TokenPtr replacement);\n+  // FIXME: don't use anymore\n+\n+  /* Splits the current token into two. Intended for use with nested generics\n+   * closes (i.e. T<U<X>> where >> is wrongly lexed as one token). Note that\n+   * this will only work with \"simple\" tokens like punctuation. */\n+  void split_current_token (TokenId new_left, TokenId new_right);\n+\n+  Linemap *get_line_map () { return line_map; }\n+  std::string get_filename () { return std::string (input.get_filename ()); }\n+\n+private:\n+  void start_line (int current_line, int current_column);\n+\n+  // File for use as input.\n+  RAIIFile input;\n+  // TODO is this actually required? could just have file storage in InputSource\n+\n+  // Current line number.\n+  int current_line;\n+  // Current column number.\n+  int current_column;\n+  // Current character.\n+  int current_char;\n+  // Line map.\n+  Linemap *line_map;\n+\n+  /* Max column number that can be quickly allocated - higher may require\n+   * allocating new linemap */\n+  static const int max_column_hint = 80;\n+\n+  // Input source wrapper thing.\n+  class InputSource\n+  {\n+  public:\n+    virtual ~InputSource () {}\n+\n+    // Overload operator () to return next char from input stream.\n+    virtual int next () = 0;\n+  };\n+\n+  class FileInputSource : public InputSource\n+  {\n+  private:\n+    // Input source file.\n+    FILE *input;\n+\n+  public:\n+    // Create new input source from file.\n+    FileInputSource (FILE *input) : input (input) {}\n+\n+    int next () override { return fgetc (input); }\n+  };\n+\n+  class BufferInputSource : public InputSource\n+  {\n+  private:\n+    const std::string &buffer;\n+    size_t offs;\n+\n+  public:\n+    // Create new input source from file.\n+    BufferInputSource (const std::string &b, size_t offset)\n+      : buffer (b), offs (offset)\n+    {}\n+\n+    int next () override\n+    {\n+      if (offs >= buffer.size ())\n+\treturn EOF;\n+\n+      return buffer.at (offs++);\n+    }\n+  };\n+\n+  // The input source for the lexer.\n+  // InputSource input_source;\n+  // Input file queue.\n+  std::unique_ptr<InputSource> raw_input_source;\n+  buffered_queue<int, InputSource &> input_queue;\n+\n+  // Token source wrapper thing.\n+  struct TokenSource\n+  {\n+    // The lexer object that will use this TokenSource.\n+    Lexer *lexer;\n+\n+    // Create a new TokenSource with given lexer.\n+    TokenSource (Lexer *parLexer) : lexer (parLexer) {}\n+\n+    // Overload operator () to build token in lexer.\n+    TokenPtr next () { return lexer->build_token (); }\n+  };\n+\n+  // The token source for the lexer.\n+  // TokenSource token_source;\n+  // Token stream queue.\n+  buffered_queue<std::shared_ptr<Token>, TokenSource> token_queue;\n+};\n+\n+} // namespace Rust\n+\n+#endif"}, {"sha": "6aef8cc1c678325393388a886c5f2a9eee508d33", "filename": "gcc/rust/lex/rust-token.cc", "status": "added", "additions": 134, "deletions": 0, "changes": 134, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-token.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-token.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-token.cc?ref=18f6990f842d0bdcb2cf9541ca98d67b414d5802", "patch": "@@ -0,0 +1,134 @@\n+// Copyright (C) 2020-2022 Free Software Foundation, Inc.\n+\n+// This file is part of GCC.\n+\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#include \"rust-token.h\"\n+#include \"rust-diagnostics.h\"\n+\n+namespace Rust {\n+// Hackily defined way to get token description for enum value using x-macros\n+const char *\n+get_token_description (TokenId id)\n+{\n+  switch (id)\n+    {\n+#define RS_TOKEN(name, descr)                                                  \\\n+  case name:                                                                   \\\n+    return descr;\n+#define RS_TOKEN_KEYWORD(x, y) RS_TOKEN (x, y)\n+      RS_TOKEN_LIST\n+#undef RS_TOKEN_KEYWORD\n+#undef RS_TOKEN\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Hackily defined way to get token description as a string for enum value using\n+ * x-macros */\n+const char *\n+token_id_to_str (TokenId id)\n+{\n+  switch (id)\n+    {\n+#define RS_TOKEN(name, _)                                                      \\\n+  case name:                                                                   \\\n+    return #name;\n+#define RS_TOKEN_KEYWORD(x, y) RS_TOKEN (x, y)\n+      RS_TOKEN_LIST\n+#undef RS_TOKEN_KEYWORD\n+#undef RS_TOKEN\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+const char *\n+get_type_hint_string (PrimitiveCoreType type)\n+{\n+  switch (type)\n+    {\n+    case CORETYPE_BOOL:\n+      return \"bool\";\n+    case CORETYPE_CHAR:\n+      return \"char\";\n+    case CORETYPE_STR:\n+      return \"str\";\n+    // case CORETYPE_INT:\n+    case CORETYPE_ISIZE:\n+      return \"isize\";\n+    // case CORETYPE_UINT:\n+    case CORETYPE_USIZE:\n+      return \"usize\";\n+    case CORETYPE_F32:\n+      return \"f32\";\n+    case CORETYPE_F64:\n+      return \"f64\";\n+    case CORETYPE_I8:\n+      return \"i8\";\n+    case CORETYPE_I16:\n+      return \"i16\";\n+    case CORETYPE_I32:\n+      return \"i32\";\n+    case CORETYPE_I64:\n+      return \"i64\";\n+    case CORETYPE_I128:\n+      return \"i128\";\n+    case CORETYPE_U8:\n+      return \"u8\";\n+    case CORETYPE_U16:\n+      return \"u16\";\n+    case CORETYPE_U32:\n+      return \"u32\";\n+    case CORETYPE_U64:\n+      return \"u64\";\n+    case CORETYPE_U128:\n+      return \"u128\";\n+    case CORETYPE_PURE_DECIMAL:\n+      return \"pure_decimal\";\n+    case CORETYPE_UNKNOWN:\n+    default:\n+      return \"unknown\";\n+    }\n+}\n+\n+const char *\n+Token::get_type_hint_str () const\n+{\n+  return get_type_hint_string (type_hint);\n+}\n+\n+const std::string &\n+Token::get_str () const\n+{\n+  // FIXME: attempt to return null again\n+  // gcc_assert(str != NULL);\n+\n+  // HACK: allow referencing an empty string\n+  static const std::string empty = \"\";\n+\n+  if (str == NULL)\n+    {\n+      rust_error_at (get_locus (),\n+\t\t     \"attempted to get string for %<%s%>, which has no string. \"\n+\t\t     \"returning empty string instead\",\n+\t\t     get_token_description ());\n+      return empty;\n+    }\n+  return *str;\n+}\n+} // namespace Rust"}, {"sha": "ae4bcfb726ebf144f1b8d581128d2cb00dbb0ec0", "filename": "gcc/rust/lex/rust-token.h", "status": "added", "additions": 448, "deletions": 0, "changes": 448, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-token.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Flex%2Frust-token.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-token.h?ref=18f6990f842d0bdcb2cf9541ca98d67b414d5802", "patch": "@@ -0,0 +1,448 @@\n+// Copyright (C) 2020-2022 Free Software Foundation, Inc.\n+\n+// This file is part of GCC.\n+\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#ifndef RUST_TOKEN_H\n+#define RUST_TOKEN_H\n+\n+#include \"rust-system.h\"\n+#include \"rust-linemap.h\"\n+#include \"rust-codepoint.h\"\n+\n+namespace Rust {\n+// \"Primitive core types\" in Rust - the different int and float types, as well\n+// as some others\n+enum PrimitiveCoreType\n+{\n+  CORETYPE_UNKNOWN,\n+  // named primitives\n+  CORETYPE_BOOL,\n+  CORETYPE_CHAR,\n+  CORETYPE_STR,\n+  // okay technically int and uint are arch-dependent (pointer size)\n+  CORETYPE_INT,\n+  CORETYPE_UINT,\n+  // numbered number primitives\n+  CORETYPE_F32,\n+  CORETYPE_F64,\n+  CORETYPE_I8,\n+  CORETYPE_I16,\n+  CORETYPE_I32,\n+  CORETYPE_I64,\n+  CORETYPE_I128,\n+  CORETYPE_U8,\n+  CORETYPE_U16,\n+  CORETYPE_U32,\n+  CORETYPE_U64,\n+  CORETYPE_U128,\n+  // Pure decimals are used for tuple index.\n+  // Also means there is no type hint.\n+  CORETYPE_PURE_DECIMAL,\n+  // arch-dependent pointer sizes\n+  CORETYPE_ISIZE = CORETYPE_INT,\n+  CORETYPE_USIZE = CORETYPE_UINT\n+};\n+\n+// RS_TOKEN(name, description)\n+// RS_TOKEN_KEYWORD(name, identifier)\n+//\n+// Keep RS_TOKEN_KEYWORD sorted\n+\n+/* note that abstract, async, become, box, do, final, macro, override, priv,\n+ * try, typeof, unsized, virtual, and yield are unused */\n+#define RS_TOKEN_LIST                                                          \\\n+  RS_TOKEN (FIRST_TOKEN, \"<first-token-marker>\")                               \\\n+  RS_TOKEN (END_OF_FILE, \"end of file\")                                        \\\n+  RS_TOKEN (EXCLAM, \"!\")                                                       \\\n+  RS_TOKEN (NOT_EQUAL, \"!=\")                                                   \\\n+  RS_TOKEN (PERCENT, \"%\")                                                      \\\n+  RS_TOKEN (PERCENT_EQ, \"%=\")                                                  \\\n+  RS_TOKEN (AMP, \"&\")                                                          \\\n+  RS_TOKEN (AMP_EQ, \"&=\")                                                      \\\n+  RS_TOKEN (LOGICAL_AND, \"&&\")                                                 \\\n+  RS_TOKEN (ASTERISK, \"*\")                                                     \\\n+  RS_TOKEN (ASTERISK_EQ, \"*=\")                                                 \\\n+  RS_TOKEN (PLUS, \"+\")                                                         \\\n+  RS_TOKEN (PLUS_EQ, \"+=\")                                                     \\\n+  RS_TOKEN (COMMA, \",\")                                                        \\\n+  RS_TOKEN (MINUS, \"-\")                                                        \\\n+  RS_TOKEN (MINUS_EQ, \"-=\")                                                    \\\n+  RS_TOKEN (RETURN_TYPE, \"->\")                                                 \\\n+  RS_TOKEN (DOT, \".\")                                                          \\\n+  RS_TOKEN (DOT_DOT, \"..\")                                                     \\\n+  RS_TOKEN (DOT_DOT_EQ, \"..=\")                                                 \\\n+  RS_TOKEN (ELLIPSIS, \"...\")                                                   \\\n+  RS_TOKEN (DIV, \"/\")                                                          \\\n+  RS_TOKEN (DIV_EQ, \"/=\")                                                      \\\n+  RS_TOKEN (COLON, \":\")                                                        \\\n+  RS_TOKEN (SEMICOLON, \";\")                                                    \\\n+  RS_TOKEN (LEFT_SHIFT, \"<<\")                                                  \\\n+  RS_TOKEN (LEFT_SHIFT_EQ, \"<<=\")                                              \\\n+  RS_TOKEN (LEFT_ANGLE, \"<\")                                                   \\\n+  RS_TOKEN (LESS_OR_EQUAL, \"<=\")                                               \\\n+  RS_TOKEN (EQUAL, \"=\")                                                        \\\n+  RS_TOKEN (EQUAL_EQUAL, \"==\")                                                 \\\n+  RS_TOKEN (MATCH_ARROW, \"=>\")                                                 \\\n+  RS_TOKEN (RIGHT_ANGLE, \">\")                                                  \\\n+  RS_TOKEN (GREATER_OR_EQUAL, \">=\")                                            \\\n+  RS_TOKEN (RIGHT_SHIFT, \">>\")                                                 \\\n+  RS_TOKEN (RIGHT_SHIFT_EQ, \">>=\")                                             \\\n+  RS_TOKEN (PATTERN_BIND, \"@\")                                                 \\\n+  RS_TOKEN (TILDE, \"~\")                                                        \\\n+  RS_TOKEN (BACKSLASH, \"\\\\\")                                                   \\\n+  RS_TOKEN (BACKTICK, \"`\")                                                     \\\n+  RS_TOKEN (CARET, \"^\")                                                        \\\n+  RS_TOKEN (CARET_EQ, \"^=\")                                                    \\\n+  RS_TOKEN (PIPE, \"|\")                                                         \\\n+  RS_TOKEN (PIPE_EQ, \"|=\")                                                     \\\n+  RS_TOKEN (OR, \"||\")                                                          \\\n+  RS_TOKEN (QUESTION_MARK, \"?\")                                                \\\n+  RS_TOKEN (HASH, \"#\")                                                         \\\n+  /* from here on, dodgy and may not be correct. not operators and may be      \\\n+   * symbols */                                                                \\\n+  /* RS_TOKEN(SPACE, \" \") probably too dodgy */                                \\\n+  /* RS_TOKEN(NEWLINE, \"\\n\")*/                                                 \\\n+  RS_TOKEN (SCOPE_RESOLUTION, \"::\") /* dodgy */                                \\\n+  RS_TOKEN (SINGLE_QUOTE, \"'\") /* should i differentiate from lifetime? */     \\\n+  RS_TOKEN (DOUBLE_QUOTE, \"\\\"\")                                                \\\n+  RS_TOKEN (UNDERSCORE,                                                        \\\n+\t    \"_\") /* TODO: treat as reserved word like mrustc instead? */       \\\n+  RS_TOKEN (IDENTIFIER, \"identifier\")                                          \\\n+  RS_TOKEN (INT_LITERAL,                                                       \\\n+\t    \"integer literal\") /* do different int and float types need        \\\n+\t\t\t\t  different literal types? */                  \\\n+  RS_TOKEN (FLOAT_LITERAL, \"float literal\")                                    \\\n+  RS_TOKEN (STRING_LITERAL, \"string literal\")                                  \\\n+  RS_TOKEN (CHAR_LITERAL, \"character literal\")                                 \\\n+  RS_TOKEN (BYTE_STRING_LITERAL, \"byte string literal\")                        \\\n+  RS_TOKEN (BYTE_CHAR_LITERAL, \"byte character literal\")                       \\\n+  RS_TOKEN (LIFETIME, \"lifetime\") /* TODO: improve token type */               \\\n+  /* Have \"interpolated\" tokens (whatever that means)? identifer, path, type,  \\\n+   * pattern, */                                                               \\\n+  /* expression, statement, block, meta, item in mrustc (but not directly in   \\\n+   * lexer). */                                                                \\\n+  RS_TOKEN (LEFT_PAREN, \"(\")                                                   \\\n+  RS_TOKEN (RIGHT_PAREN, \")\")                                                  \\\n+  RS_TOKEN (LEFT_CURLY, \"{\")                                                   \\\n+  RS_TOKEN (RIGHT_CURLY, \"}\")                                                  \\\n+  RS_TOKEN (LEFT_SQUARE, \"[\")                                                  \\\n+  RS_TOKEN (RIGHT_SQUARE, \"]\")                                                 \\\n+  /* Macros */                                                                 \\\n+  RS_TOKEN (DOLLAR_SIGN, \"$\")                                                  \\\n+  /* Doc Comments */                                                           \\\n+  RS_TOKEN (INNER_DOC_COMMENT, \"#![doc]\")                                      \\\n+  RS_TOKEN (OUTER_DOC_COMMENT, \"#[doc]\")                                       \\\n+  /* have \"weak\" union and 'static keywords? */                                \\\n+  RS_TOKEN_KEYWORD (ABSTRACT, \"abstract\") /* unused */                         \\\n+  RS_TOKEN_KEYWORD (AS, \"as\")                                                  \\\n+  RS_TOKEN_KEYWORD (ASYNC, \"async\")   /* unused */                             \\\n+  RS_TOKEN_KEYWORD (BECOME, \"become\") /* unused */                             \\\n+  RS_TOKEN_KEYWORD (BOX, \"box\")\t      /* unused */                             \\\n+  RS_TOKEN_KEYWORD (BREAK, \"break\")                                            \\\n+  RS_TOKEN_KEYWORD (CONST, \"const\")                                            \\\n+  RS_TOKEN_KEYWORD (CONTINUE, \"continue\")                                      \\\n+  RS_TOKEN_KEYWORD (CRATE, \"crate\")                                            \\\n+  /* FIXME: Do we need to add $crate (DOLLAR_CRATE) as a reserved kw? */       \\\n+  RS_TOKEN_KEYWORD (DO, \"do\") /* unused */                                     \\\n+  RS_TOKEN_KEYWORD (DYN, \"dyn\")                                                \\\n+  RS_TOKEN_KEYWORD (ELSE, \"else\")                                              \\\n+  RS_TOKEN_KEYWORD (ENUM_TOK, \"enum\")                                          \\\n+  RS_TOKEN_KEYWORD (EXTERN_TOK, \"extern\")                                      \\\n+  RS_TOKEN_KEYWORD (FALSE_LITERAL, \"false\")                                    \\\n+  RS_TOKEN_KEYWORD (FINAL_TOK, \"final\") /* unused */                           \\\n+  RS_TOKEN_KEYWORD (FN_TOK, \"fn\")                                              \\\n+  RS_TOKEN_KEYWORD (FOR, \"for\")                                                \\\n+  RS_TOKEN_KEYWORD (IF, \"if\")                                                  \\\n+  RS_TOKEN_KEYWORD (IMPL, \"impl\")                                              \\\n+  RS_TOKEN_KEYWORD (IN, \"in\")                                                  \\\n+  RS_TOKEN_KEYWORD (LET, \"let\")                                                \\\n+  RS_TOKEN_KEYWORD (LOOP, \"loop\")                                              \\\n+  RS_TOKEN_KEYWORD (MACRO, \"macro\") /* unused */                               \\\n+  RS_TOKEN_KEYWORD (MATCH_TOK, \"match\")                                        \\\n+  RS_TOKEN_KEYWORD (MOD, \"mod\")                                                \\\n+  RS_TOKEN_KEYWORD (MOVE, \"move\")                                              \\\n+  RS_TOKEN_KEYWORD (MUT, \"mut\")                                                \\\n+  RS_TOKEN_KEYWORD (OVERRIDE_TOK, \"override\") /* unused */                     \\\n+  RS_TOKEN_KEYWORD (PRIV, \"priv\")\t      /* unused */                     \\\n+  RS_TOKEN_KEYWORD (PUB, \"pub\")                                                \\\n+  RS_TOKEN_KEYWORD (REF, \"ref\")                                                \\\n+  RS_TOKEN_KEYWORD (RETURN_TOK, \"return\")                                      \\\n+  RS_TOKEN_KEYWORD (SELF_ALIAS,                                                \\\n+\t\t    \"Self\") /* mrustc does not treat this as a reserved word*/ \\\n+  RS_TOKEN_KEYWORD (SELF, \"self\")                                              \\\n+  RS_TOKEN_KEYWORD (STATIC_TOK, \"static\")                                      \\\n+  RS_TOKEN_KEYWORD (STRUCT_TOK, \"struct\")                                      \\\n+  RS_TOKEN_KEYWORD (SUPER, \"super\")                                            \\\n+  RS_TOKEN_KEYWORD (TRAIT, \"trait\")                                            \\\n+  RS_TOKEN_KEYWORD (TRUE_LITERAL, \"true\")                                      \\\n+  RS_TOKEN_KEYWORD (TRY, \"try\") /* unused */                                   \\\n+  RS_TOKEN_KEYWORD (TYPE, \"type\")                                              \\\n+  RS_TOKEN_KEYWORD (TYPEOF, \"typeof\") /* unused */                             \\\n+  RS_TOKEN_KEYWORD (UNSAFE, \"unsafe\")                                          \\\n+  RS_TOKEN_KEYWORD (UNSIZED, \"unsized\") /* unused */                           \\\n+  RS_TOKEN_KEYWORD (USE, \"use\")                                                \\\n+  RS_TOKEN_KEYWORD (VIRTUAL, \"virtual\") /* unused */                           \\\n+  RS_TOKEN_KEYWORD (WHERE, \"where\")                                            \\\n+  RS_TOKEN_KEYWORD (WHILE, \"while\")                                            \\\n+  RS_TOKEN_KEYWORD (YIELD, \"yield\") /* unused */                               \\\n+  RS_TOKEN (LAST_TOKEN, \"<last-token-marker>\")\n+\n+// Contains all token types. Crappy implementation via x-macros.\n+enum TokenId\n+{\n+#define RS_TOKEN(name, _) name,\n+#define RS_TOKEN_KEYWORD(x, y) RS_TOKEN (x, y)\n+  RS_TOKEN_LIST\n+#undef RS_TOKEN_KEYWORD\n+#undef RS_TOKEN\n+};\n+\n+// dodgy \"TokenPtr\" declaration with Token forward declaration\n+class Token;\n+// A smart pointer (shared_ptr) to Token.\n+typedef std::shared_ptr<Token> TokenPtr;\n+// A smart pointer (shared_ptr) to a constant Token.\n+typedef std::shared_ptr<const Token> const_TokenPtr;\n+\n+// Hackily defined way to get token description for enum value using x-macros\n+const char *\n+get_token_description (TokenId id);\n+/* Hackily defined way to get token description as a string for enum value using\n+ * x-macros */\n+const char *\n+token_id_to_str (TokenId id);\n+// Get type hint description as a string.\n+const char *\n+get_type_hint_string (PrimitiveCoreType type);\n+\n+// Represents a single token. Create using factory static methods.\n+class Token\n+{\n+private:\n+  // Token kind.\n+  TokenId token_id;\n+  // Token location.\n+  Location locus;\n+  // Associated text (if any) of token.\n+  std::unique_ptr<std::string> str;\n+  // TODO: maybe remove issues and just store std::string as value?\n+  /* Type hint for token based on lexer data (e.g. type suffix). Does not exist\n+   * for most tokens. */\n+  PrimitiveCoreType type_hint;\n+\n+  // Token constructor from token id and location. Has a null string.\n+  Token (TokenId token_id, Location location)\n+    : token_id (token_id), locus (location), str (nullptr),\n+      type_hint (CORETYPE_UNKNOWN)\n+  {}\n+\n+  // Token constructor from token id, location, and a string.\n+  Token (TokenId token_id, Location location, std::string &&paramStr)\n+    : token_id (token_id), locus (location),\n+      str (new std::string (std::move (paramStr))), type_hint (CORETYPE_UNKNOWN)\n+  {}\n+\n+  // Token constructor from token id, location, and a char.\n+  Token (TokenId token_id, Location location, char paramChar)\n+    : token_id (token_id), locus (location),\n+      str (new std::string (1, paramChar)), type_hint (CORETYPE_UNKNOWN)\n+  {}\n+\n+  // Token constructor from token id, location, and a \"codepoint\".\n+  Token (TokenId token_id, Location location, Codepoint paramCodepoint)\n+    : token_id (token_id), locus (location),\n+      str (new std::string (paramCodepoint.as_string ())),\n+      type_hint (CORETYPE_UNKNOWN)\n+  {}\n+\n+  // Token constructor from token id, location, a string, and type hint.\n+  Token (TokenId token_id, Location location, std::string &&paramStr,\n+\t PrimitiveCoreType parType)\n+    : token_id (token_id), locus (location),\n+      str (new std::string (std::move (paramStr))), type_hint (parType)\n+  {}\n+\n+public:\n+  // No default constructor.\n+  Token () = delete;\n+  // Do not copy/assign tokens.\n+  Token (const Token &) = delete;\n+  Token &operator= (const Token &) = delete;\n+\n+  // Allow moving tokens.\n+  Token (Token &&other) = default;\n+  Token &operator= (Token &&other) = default;\n+\n+  ~Token () = default;\n+\n+  /* TODO: make_shared (which saves a heap allocation) does not work with the\n+   * private constructor */\n+\n+  // Makes and returns a new TokenPtr (with null string).\n+  static TokenPtr make (TokenId token_id, Location locus)\n+  {\n+    // return std::make_shared<Token> (token_id, locus);\n+    return TokenPtr (new Token (token_id, locus));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type IDENTIFIER.\n+  static TokenPtr make_identifier (Location locus, std::string &&str)\n+  {\n+    // return std::make_shared<Token> (IDENTIFIER, locus, str);\n+    return TokenPtr (new Token (IDENTIFIER, locus, std::move (str)));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type INT_LITERAL.\n+  static TokenPtr make_int (Location locus, std::string &&str,\n+\t\t\t    PrimitiveCoreType type_hint = CORETYPE_UNKNOWN)\n+  {\n+    // return std::make_shared<Token> (INT_LITERAL, locus, str, type_hint);\n+    return TokenPtr (\n+      new Token (INT_LITERAL, locus, std::move (str), type_hint));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type FLOAT_LITERAL.\n+  static TokenPtr make_float (Location locus, std::string &&str,\n+\t\t\t      PrimitiveCoreType type_hint = CORETYPE_UNKNOWN)\n+  {\n+    // return std::make_shared<Token> (FLOAT_LITERAL, locus, str, type_hint);\n+    return TokenPtr (\n+      new Token (FLOAT_LITERAL, locus, std::move (str), type_hint));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type STRING_LITERAL.\n+  static TokenPtr make_string (Location locus, std::string &&str)\n+  {\n+    // return std::make_shared<Token> (STRING_LITERAL, locus, str,\n+    // CORETYPE_STR);\n+    return TokenPtr (\n+      new Token (STRING_LITERAL, locus, std::move (str), CORETYPE_STR));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type CHAR_LITERAL.\n+  static TokenPtr make_char (Location locus, Codepoint char_lit)\n+  {\n+    // return std::make_shared<Token> (CHAR_LITERAL, locus, char_lit);\n+    return TokenPtr (new Token (CHAR_LITERAL, locus, char_lit));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type BYTE_CHAR_LITERAL.\n+  static TokenPtr make_byte_char (Location locus, char byte_char)\n+  {\n+    // return std::make_shared<Token> (BYTE_CHAR_LITERAL, locus, byte_char);\n+    return TokenPtr (new Token (BYTE_CHAR_LITERAL, locus, byte_char));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type BYTE_STRING_LITERAL (fix).\n+  static TokenPtr make_byte_string (Location locus, std::string &&str)\n+  {\n+    // return std::make_shared<Token> (BYTE_STRING_LITERAL, locus, str);\n+    return TokenPtr (new Token (BYTE_STRING_LITERAL, locus, std::move (str)));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type INNER_DOC_COMMENT.\n+  static TokenPtr make_inner_doc_comment (Location locus, std::string &&str)\n+  {\n+    return TokenPtr (new Token (INNER_DOC_COMMENT, locus, std::move (str)));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type OUTER_DOC_COMMENT.\n+  static TokenPtr make_outer_doc_comment (Location locus, std::string &&str)\n+  {\n+    return TokenPtr (new Token (OUTER_DOC_COMMENT, locus, std::move (str)));\n+  }\n+\n+  // Makes and returns a new TokenPtr of type LIFETIME.\n+  static TokenPtr make_lifetime (Location locus, std::string &&str)\n+  {\n+    // return std::make_shared<Token> (LIFETIME, locus, str);\n+    return TokenPtr (new Token (LIFETIME, locus, std::move (str)));\n+  }\n+\n+  // Gets id of the token.\n+  TokenId get_id () const { return token_id; }\n+\n+  // Gets location of the token.\n+  Location get_locus () const { return locus; }\n+\n+  // Gets string description of the token.\n+  const std::string &\n+  get_str () const; /*{\n+// FIXME: put in header again when fix null problem\n+//gcc_assert(str != nullptr);\n+if (str == nullptr) {\n+error_at(get_locus(), \"attempted to get string for '%s', which has no string.\n+returning empty string instead.\", get_token_description()); return \"\";\n+}\n+return *str;\n+}*/\n+\n+  // Gets token's type hint info.\n+  PrimitiveCoreType get_type_hint () const\n+  {\n+    return type_hint == CORETYPE_PURE_DECIMAL ? CORETYPE_UNKNOWN : type_hint;\n+  }\n+\n+  // diagnostics (error reporting)\n+  const char *get_token_description () const\n+  {\n+    return Rust::get_token_description (token_id);\n+  }\n+\n+  // debugging\n+  const char *token_id_to_str () const\n+  {\n+    return Rust::token_id_to_str (token_id);\n+  }\n+\n+  // debugging\n+  const char *get_type_hint_str () const;\n+\n+  /* Returns whether the token is a literal of any type (int, float, char,\n+   * string, byte char, byte string). */\n+  bool is_literal () const\n+  {\n+    switch (token_id)\n+      {\n+      case INT_LITERAL:\n+      case FLOAT_LITERAL:\n+      case CHAR_LITERAL:\n+      case STRING_LITERAL:\n+      case BYTE_CHAR_LITERAL:\n+      case BYTE_STRING_LITERAL:\n+\treturn true;\n+      default:\n+\treturn false;\n+      }\n+  }\n+\n+  /* Returns whether the token actually has a string (regardless of whether it\n+   * should or not). */\n+  bool has_str () const { return str != nullptr; }\n+\n+  // Returns whether the token should have a string.\n+  bool should_have_str () const\n+  {\n+    return is_literal () || token_id == IDENTIFIER || token_id == LIFETIME;\n+  }\n+\n+  // Returns whether the token is a pure decimal int literal\n+  bool is_pure_decimal () const { return type_hint == CORETYPE_PURE_DECIMAL; }\n+};\n+} // namespace Rust\n+\n+#endif"}, {"sha": "afcc4670cac75925be8beeb2662cb7312305dd08", "filename": "gcc/rust/rust-buffered-queue.h", "status": "added", "additions": 204, "deletions": 0, "changes": 204, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Frust-buffered-queue.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f6990f842d0bdcb2cf9541ca98d67b414d5802/gcc%2Frust%2Frust-buffered-queue.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Frust-buffered-queue.h?ref=18f6990f842d0bdcb2cf9541ca98d67b414d5802", "patch": "@@ -0,0 +1,204 @@\n+// Copyright (C) 2020-2022 Free Software Foundation, Inc.\n+\n+// This file is part of GCC.\n+\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#ifndef RUST_BUFFERED_QUEUE_H\n+#define RUST_BUFFERED_QUEUE_H\n+\n+#include \"rust-system.h\"\n+\n+namespace Rust {\n+/* Buffered queue implementation. Items are of type T, queue source is of type\n+ * Source. Note that this is owning of the source. */\n+template <typename T, typename Source> class buffered_queue\n+{\n+public:\n+  // Construct empty queue from Source src.\n+  buffered_queue (Source src) : source (src), start (0), end (0), buffer () {}\n+\n+  /* disable copying (since source is probably non-copyable)\n+   * TODO is this actually a good idea? If source is non-copyable, it would\n+   * just delete the copy constructor anyway.*/\n+  buffered_queue (const buffered_queue &other) = delete;\n+  buffered_queue &operator= (const buffered_queue &other) = delete;\n+\n+  // enable moving\n+  buffered_queue (buffered_queue &&other) = default;\n+  buffered_queue &operator= (buffered_queue &&other) = default;\n+\n+  // Returns token at position start + n (i.e. n tokens ahead).\n+  T peek (int n)\n+  {\n+    // n should not be behind\n+    rust_assert (n >= 0);\n+\n+    int num_queued_items = end - start;\n+    int num_items_required = n + 1;\n+\n+    // if required items go past end of queue, add them to queue\n+    if (num_items_required > num_queued_items)\n+      {\n+\tint num_items_to_read = num_items_required - num_queued_items;\n+\n+\t/* if queue length + extra items is larger than buffer size, expand\n+\t * buffer */\n+\tif (end + num_items_to_read > (int) buffer.size ())\n+\t  {\n+\t    // Resize the buffer by 1.5x\n+\t    int new_size = (buffer.size () + num_items_to_read);\n+\t    new_size += (new_size >> 1);\n+\n+\t    // old method:\n+\t    /*\n+\t\t  // create new queue buffer with new size\n+\t\t  std::vector<T> new_queue (new_size);\n+\t\t  std::copy (buffer.begin () + start, buffer.begin () + end,\n+\t\t\t     new_queue.begin ());\n+\t\t  start = 0;\n+\t\t  end = num_queued_items;\n+\t\t  // TODO: would move be better here? optimisation for move with\n+\t\t  // shared pointer?\n+\n+\t\t  // swap member buffer and new queue buffer\n+\t\t  std::swap (buffer, new_queue);\n+\t    */\n+\n+\t    // TODO: determine overhead of this approach vs copy. Should be\n+\t    // lower.\n+\t    std::vector<T> new_queue;\n+\t    new_queue.reserve (new_size);\n+\t    new_queue.insert (new_queue.begin (),\n+\t\t\t      std::make_move_iterator (buffer.begin () + start),\n+\t\t\t      std::make_move_iterator (buffer.begin () + end));\n+\t    start = 0;\n+\t    end = num_queued_items;\n+\t    // fill up rest of vector with junk so that indexing can work\n+\t    new_queue.insert (new_queue.begin () + end,\n+\t\t\t      new_size - new_queue.size (), T ());\n+\n+\t    buffer = std::move (new_queue);\n+\t    /* this should be best method - std::move(range) would have\n+\t     * allocation problems; initial construction would require\n+\t     * reallocation upon resizing */\n+\n+\t    // validate that buffer is large enough now\n+\t    rust_assert (end + num_items_to_read <= (int) buffer.size ());\n+\t  }\n+\n+\t/* iterate through buffer and invoke operator () on source on values\n+\t * past original end */\n+\tfor (int i = 0; i < num_items_to_read; i++)\n+\t  buffer[end + i] = source.next ();\n+\n+\t// move end based on additional items added\n+\tend += num_items_to_read;\n+      }\n+\n+    rust_assert (0 <= start);\n+    rust_assert (start <= end);\n+    rust_assert (end <= (int) buffer.size ());\n+\n+    rust_assert (start + n < end);\n+\n+    // return value at start + n in buffer\n+    return buffer[start + n];\n+  }\n+\n+  /* TODO: add faster peek current token to remove overhead of conditional\n+   * branches? */\n+\n+  // Advances start by n + 1.\n+  void skip (int n)\n+  {\n+    // Call peek to ensure requested n is actually in queue.\n+    peek (n);\n+\n+    // Clear queue values from start to n (inclusive).\n+    for (int i = 0; i < (n + 1); i++)\n+      buffer[start + i] = T ();\n+\n+    // Move start forward by n + 1.\n+    start += (n + 1);\n+\n+    // Ensure start is not impossible somehow\n+    rust_assert (0 <= start);\n+    rust_assert (start <= end);\n+\n+    // Compact buffer if empty\n+    if (start == end)\n+      start = end = 0;\n+  }\n+\n+  /* Inserts element at front of vector. Really dirty hack with terrible\n+   * performance, only use when really needed. */\n+  void insert_at_front (T elem_to_insert)\n+  {\n+    // TODO: test as this may not work properly\n+\n+    // Insert actual element in buffer at start.\n+    buffer.insert (buffer.begin (), elem_to_insert);\n+\n+    /* Increase the end number since added element means all others have shifted\n+     * one along */\n+    end++;\n+  }\n+\n+  // Insert at arbitrary position (attempt)\n+  void insert (int index, T elem_to_insert)\n+  {\n+    // TODO: test as this may not work properly\n+\n+    // n should not be behind\n+    rust_assert (index >= 0);\n+\n+    // call peek to ensure that the items behind this (at least) are in queue\n+    if (index >= 1)\n+      peek (index - 1);\n+    else\n+      peek (index);\n+\n+    buffer.insert (buffer.begin () + start + index, std::move (elem_to_insert));\n+\n+    end++;\n+  }\n+\n+  // Replaces the current value in the buffer. Total HACK.\n+  void replace_current_value (T replacement)\n+  {\n+    // call peek to ensure value exists\n+    peek (0);\n+\n+    buffer[start] = std::move (replacement);\n+\n+    // don't move start or end\n+  }\n+\n+private:\n+  // Source of tokens for queue.\n+  Source source;\n+\n+  // Begin of range in buffer, inclusive.\n+  int start;\n+  // End of range in buffer, exclusive.\n+  int end;\n+\n+  // Queue buffer.\n+  std::vector<T> buffer;\n+};\n+} // namespace Rust\n+\n+#endif"}]}