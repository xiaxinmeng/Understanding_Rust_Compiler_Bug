{"sha": "5b3e666315f8d173a883a778dc7b500730977cd5", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NWIzZTY2NjMxNWY4ZDE3M2E4ODNhNzc4ZGM3YjUwMDczMDk3N2NkNQ==", "commit": {"author": {"name": "Paul Brook", "email": "paul@codesourcery.com", "date": "2007-01-03T23:48:10Z"}, "committer": {"name": "Paul Brook", "email": "pbrook@gcc.gnu.org", "date": "2007-01-03T23:48:10Z"}, "message": "backport: thumb2.md: New file.\n\n2007-01-03  Paul Brook  <paul@codesourcery.com>\n\n\tMerge from sourcerygxx-4_1.\n\tgcc/\n\t* config/arm/thumb2.md: New file.\n\t* config/arm/elf.h (JUMP_TABLES_IN_TEXT_SECTION): Return True for\n\tThumb-2.\n\t* config/arm/coff.h (JUMP_TABLES_IN_TEXT_SECTION): Ditto.\n\t* config/arm/aout.h (ASM_OUTPUT_ADDR_VEC_ELT): Add !Thumb-2 assertion.\n\t(ASM_OUTPUT_ADDR_DIFF_ELT): Output Thumb-2 jump tables.\n\t* config/arm/aof.h (ASM_OUTPUT_ADDR_DIFF_ELT): Output Thumb-2 jump\n\ttables.\n\t(ASM_OUTPUT_ADDR_VEC_ELT): Add !Thumb-2 assertion.\n\t* config/arm/ieee754-df.S: Use macros for Thumb-2/Unified asm\n\tcomptibility.\n\t* config/arm/ieee754-sf.S: Ditto.\n\t* config/arm/arm.c (thumb_base_register_rtx_p): Rename...\n\t(thumb1_base_register_rtx_p): ... to this.\n\t(thumb_index_register_rtx_p): Rename...\n\t(thumb1_index_register_rtx_p): ... to this.\n\t(thumb_output_function_prologue): Rename...\n\t(thumb1_output_function_prologue): ... to this.\n\t(thumb_legitimate_address_p): Rename...\n\t(thumb1_legitimate_address_p): ... to this.\n\t(thumb_rtx_costs): Rename...\n\t(thumb1_rtx_costs): ... to this.\n\t(thumb_compute_save_reg_mask): Rename...\n\t(thumb1_compute_save_reg_mask): ... to this.\n\t(thumb_final_prescan_insn): Rename...\n\t(thumb1_final_prescan_insn): ... to this.\n\t(thumb_expand_epilogue): Rename...\n\t(thumb1_expand_epilogue): ... to this.\n\t(arm_unwind_emit_stm): Rename...\n\t(arm_unwind_emit_sequence): ... to this.\n\t(thumb2_legitimate_index_p, thumb2_legitimate_address_p,\n\tthumb1_compute_save_reg_mask, arm_dwarf_handle_frame_unspec,\n\tthumb2_index_mul_operand, output_move_vfp, arm_shift_nmem,\n\tarm_save_coproc_regs, thumb_set_frame_pointer, arm_print_condition,\n\tthumb2_final_prescan_insn, thumb2_asm_output_opcode, arm_output_shift,\n\tthumb2_output_casesi): New functions.\n\t(TARGET_DWARF_HANDLE_FRAME_UNSPEC): Define.\n\t(FL_THUMB2, FL_NOTM, FL_DIV, FL_FOR_ARCH6T2, FL_FOR_ARCH7,\n\tFL_FOR_ARCH7A, FL_FOR_ARCH7R, FL_FOR_ARCH7M, ARM_LSL_NAME,\n\tTHUMB2_WORK_REGS): Define.\n\t(arm_arch_notm, arm_arch_thumb2, arm_arch_hwdiv, arm_condexec_count,\n\tarm_condexec_mask, arm_condexec_masklen)): New variables.\n\t(all_architectures): Add armv6t2, armv7, armv7a, armv7r and armv7m.\n\t(arm_override_options): Check new CPU capabilities.\n\tSet new architecture flag variables.\n\t(arm_isr_value): Handle v7m interrupt functions.\n\t(user_return_insn): Return 0 for v7m interrupt functions.  Handle\n\tThumb-2.\n\t(const_ok_for_arm): Handle Thumb-2 constants.\n\t(arm_gen_constant): Ditto.  Use movw when available.\n\t(arm_function_ok_for_sibcall): Return false for v7m interrupt\n\tfunctions.\n\t(legitimize_pic_address, arm_call_tls_get_addr): Handle Thumb-2.\n\t(thumb_find_work_register, arm_load_pic_register,\n\tlegitimize_tls_address, arm_address_cost, load_multiple_sequence,\n\temit_ldm_seq, emit_stm_seq, arm_select_cc_mode, get_jump_table_size,\n\tprint_multi_reg, output_mov_long_double_fpa_from_arm,\n\toutput_mov_long_double_arm_from_fpa, output_mov_double_fpa_from_arm,\n\toutput_mov_double_fpa_from_arm, output_move_double,\n\tarm_compute_save_reg_mask, arm_compute_save_reg0_reg12_mask,\n\toutput_return_instruction, arm_output_function_prologue,\n\tarm_output_epilogue, arm_get_frame_offsets, arm_regno_class,\n\tarm_output_mi_thunk, thumb_set_return_address): Ditto.\n\t(arm_expand_prologue): Handle Thumb-2.  Use arm_save_coproc_regs.\n\t(arm_coproc_mem_operand): Allow POST_INC/PRE_DEC.\n\t(arithmetic_instr, shift_op): Use arm_shift_nmem.\n\t(arm_print_operand): Use arm_print_condition.  Handle '(', ')', '.',\n\t'!' and 'L'.\n\t(arm_final_prescan_insn): Use extract_constrain_insn_cached.\n\t(thumb_expand_prologue): Use thumb_set_frame_pointer.\n\t(arm_file_start): Output directive for unified syntax.\n\t(arm_unwind_emit_set): Handle stack alignment instruction.\n\t* config/arm/lib1funcs.asm: Remove default for __ARM_ARCH__.\n\tAdd v6t2, v7, v7a, v7r and v7m.\n\t(RETLDM): Add Thumb-2 code.\n\t(do_it, shift1, do_push, do_pop, COND, THUMB_SYNTAX): New macros.\n\t* config/arm/arm.h (TARGET_CPU_CPP_BUILTINS): Define __thumb2__.\n\t(TARGET_THUMB1, TARGET_32BIT, TARGET_THUMB2, TARGET_DSP_MULTIPLY,\n\tTARGET_INT_SIMD, TARGET_UNIFIED_ASM, ARM_FT_STACKALIGN, IS_STACKALIGN,\n\tTHUMB2_TRAMPOLINE_TEMPLATE, TRAMPOLINE_ADJUST_ADDRESS,\n\tASM_OUTPUT_OPCODE, THUMB2_GO_IF_LEGITIMATE_ADDRESS,\n\tTHUMB2_LEGITIMIZE_ADDRESS, CASE_VECTOR_PC_RELATIVE,\n\tCASE_VECTOR_SHORTEN_MODE, ADDR_VEC_ALIGN, ASM_OUTPUT_CASE_END,\n\tADJUST_INSN_LENGTH): Define.\n\t(TARGET_REALLY_IWMMXT, TARGET_IWMMXT_ABI, CONDITIONAL_REGISTER_USAGE,\n\tSTATIC_CHAIN_REGNUM, HARD_REGNO_NREGS, INDEX_REG_CLASS,\n\tBASE_REG_CLASS, MODE_BASE_REG_CLASS, SMALL_REGISTER_CLASSES,\n\tPREFERRED_RELOAD_CLASS, SECONDARY_OUTPUT_RELOAD_CLASS,\n\tSECONDARY_INPUT_RELOAD_CLASS, LIBCALL_VALUE, FUNCTION_VALUE_REGNO_P,\n\tTRAMPOLINE_SIZE, INITIALIZE_TRAMPOLINE, HAVE_PRE_INCREMENT,\n\tHAVE_POST_DECREMENT, HAVE_PRE_DECREMENT, HAVE_PRE_MODIFY_DISP,\n\tHAVE_POST_MODIFY_DISP, HAVE_PRE_MODIFY_REG, HAVE_POST_MODIFY_REG,\n\tREGNO_MODE_OK_FOR_BASE_P, LEGITIMATE_CONSTANT_P,\n\tREG_MODE_OK_FOR_BASE_P, REG_OK_FOR_INDEX_P, GO_IF_LEGITIMATE_ADDRESS,\n\tLEGITIMIZE_ADDRESS, THUMB2_LEGITIMIZE_ADDRESS,\n\tGO_IF_MODE_DEPENDENT_ADDRESS, MEMORY_MOVE_COST, BRANCH_COST,\n\tASM_APP_OFF, ASM_OUTPUT_CASE_LABEL, ARM_DECLARE_FUNCTION_NAME,\n\tFINAL_PRESCAN_INSN, PRINT_OPERAND_PUNCT_VALID_P,\n\tPRINT_OPERAND_ADDRESS): Adjust for Thumb-2.\n\t(arm_arch_notm, arm_arch_thumb2, arm_arch_hwdiv): New declarations.\n\t* config/arm/arm-cores.def: Add arm1156t2-s, cortex-a8, cortex-r4 and\n\tcortex-m3.\n\t* config/arm/arm-tune.md: Regenerate.\n\t* config/arm/arm-protos.h: Update prototypes.\n\t* config/arm/vfp.md: Enable patterns for Thumb-2.\n\t(arm_movsi_vfp): Add movw alternative.  Use output_move_vfp.\n\t(arm_movdi_vfp, movsf_vfp, movdf_vfp): Use output_move_vfp.\n\t(thumb2_movsi_vfp, thumb2_movdi_vfp, thumb2_movsf_vfp,\n\tthumb2_movdf_vfp, thumb2_movsfcc_vfp, thumb2_movdfcc_vfp): New.\n\t* config/arm/libunwind.S: Add Thumb-2 code.\n\t* config/arm/constraints.md: Update include Thumb-2.\n\t* config/arm/ieee754-sf.S: Add Thumb-2/Unified asm support.\n\t* config/arm/ieee754-df.S: Ditto.\n\t* config/arm/bpabi.S: Ditto.\n\t* config/arm/t-arm (MD_INCLUDES): Add thumb2.md.\n\t* config/arm/predicates.md (low_register_operand,\n\tlow_reg_or_int_operand, thumb_16bit_operator): New.\n\t(thumb_cmp_operand, thumb_cmpneg_operand): Rename...\n\t(thumb1_cmp_operand, thumb1_cmpneg_operand): ... to this.\n\t* config/arm/t-arm-elf: Add armv7 multilib.\n\t* config/arm/arm.md: Update patterns for Thumb-2 and Unified asm.\n\tInclude thumb2.md.\n\t(UNSPEC_STACK_ALIGN, ce_count): New.\n\t(arm_incscc, arm_decscc, arm_umaxsi3, arm_uminsi3,\n\tarm_zero_extendsidi2, arm_zero_extendqidi2): New\n\tinsns/expanders.\n\t* config/arm/fpa.md: Update patterns for Thumb-2 and Unified asm.\n\t(thumb2_movsf_fpa, thumb2_movdf_fpa, thumb2_movxf_fpa,\n\tthumb2_movsfcc_fpa, thumb2_movdfcc_fpa): New insns.\n\t* config/arm/cirrus.md: Update patterns for Thumb-2 and Unified asm.\n\t(cirrus_thumb2_movdi, cirrus_thumb2_movsi_insn,\n\tthumb2_cirrus_movsf_hard_insn, thumb2_cirrus_movdf_hard_insn): New\n\tinsns.\n\t* doc/extend.texi: Document ARMv7-M interrupt functions.\n\t* doc/invoke.texi: Document Thumb-2 new cores+architectures.\n\nFrom-SVN: r120408", "tree": {"sha": "e7fbd881338bffa6ed838d87847ff2484257e411", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e7fbd881338bffa6ed838d87847ff2484257e411"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5b3e666315f8d173a883a778dc7b500730977cd5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5b3e666315f8d173a883a778dc7b500730977cd5", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5b3e666315f8d173a883a778dc7b500730977cd5", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5b3e666315f8d173a883a778dc7b500730977cd5/comments", "author": null, "committer": null, "parents": [{"sha": "f8e7718c6ff2e04fdfb21ab4cc060259c007044b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f8e7718c6ff2e04fdfb21ab4cc060259c007044b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f8e7718c6ff2e04fdfb21ab4cc060259c007044b"}], "stats": {"total": 6009, "additions": 4642, "deletions": 1367}, "files": [{"sha": "ae2fc67ec622e36b9611145c2e8a45e307c4ee75", "filename": "gcc/ChangeLog", "status": "modified", "additions": 139, "deletions": 0, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,3 +1,142 @@\n+2007-01-03  Paul Brook  <paul@codesourcery.com>\n+\n+\tMerge from sourcerygxx-4_1.\n+\t* config/arm/thumb2.md: New file.\n+\t* config/arm/elf.h (JUMP_TABLES_IN_TEXT_SECTION): Return True for\n+\tThumb-2.\n+\t* config/arm/coff.h (JUMP_TABLES_IN_TEXT_SECTION): Ditto.\n+\t* config/arm/aout.h (ASM_OUTPUT_ADDR_VEC_ELT): Add !Thumb-2 assertion.\n+\t(ASM_OUTPUT_ADDR_DIFF_ELT): Output Thumb-2 jump tables.\n+\t* config/arm/aof.h (ASM_OUTPUT_ADDR_DIFF_ELT): Output Thumb-2 jump\n+\ttables.\n+\t(ASM_OUTPUT_ADDR_VEC_ELT): Add !Thumb-2 assertion.\n+\t* config/arm/ieee754-df.S: Use macros for Thumb-2/Unified asm\n+\tcomptibility.\n+\t* config/arm/ieee754-sf.S: Ditto.\n+\t* config/arm/arm.c (thumb_base_register_rtx_p): Rename...\n+\t(thumb1_base_register_rtx_p): ... to this.\n+\t(thumb_index_register_rtx_p): Rename...\n+\t(thumb1_index_register_rtx_p): ... to this.\n+\t(thumb_output_function_prologue): Rename...\n+\t(thumb1_output_function_prologue): ... to this.\n+\t(thumb_legitimate_address_p): Rename...\n+\t(thumb1_legitimate_address_p): ... to this.\n+\t(thumb_rtx_costs): Rename...\n+\t(thumb1_rtx_costs): ... to this.\n+\t(thumb_compute_save_reg_mask): Rename...\n+\t(thumb1_compute_save_reg_mask): ... to this.\n+\t(thumb_final_prescan_insn): Rename...\n+\t(thumb1_final_prescan_insn): ... to this.\n+\t(thumb_expand_epilogue): Rename...\n+\t(thumb1_expand_epilogue): ... to this.\n+\t(arm_unwind_emit_stm): Rename...\n+\t(arm_unwind_emit_sequence): ... to this.\n+\t(thumb2_legitimate_index_p, thumb2_legitimate_address_p,\n+\tthumb1_compute_save_reg_mask, arm_dwarf_handle_frame_unspec,\n+\tthumb2_index_mul_operand, output_move_vfp, arm_shift_nmem,\n+\tarm_save_coproc_regs, thumb_set_frame_pointer, arm_print_condition,\n+\tthumb2_final_prescan_insn, thumb2_asm_output_opcode, arm_output_shift,\n+\tthumb2_output_casesi): New functions.\n+\t(TARGET_DWARF_HANDLE_FRAME_UNSPEC): Define.\n+\t(FL_THUMB2, FL_NOTM, FL_DIV, FL_FOR_ARCH6T2, FL_FOR_ARCH7,\n+\tFL_FOR_ARCH7A, FL_FOR_ARCH7R, FL_FOR_ARCH7M, ARM_LSL_NAME,\n+\tTHUMB2_WORK_REGS): Define.\n+\t(arm_arch_notm, arm_arch_thumb2, arm_arch_hwdiv, arm_condexec_count,\n+\tarm_condexec_mask, arm_condexec_masklen)): New variables.\n+\t(all_architectures): Add armv6t2, armv7, armv7a, armv7r and armv7m.\n+\t(arm_override_options): Check new CPU capabilities.\n+\tSet new architecture flag variables.\n+\t(arm_isr_value): Handle v7m interrupt functions.\n+\t(user_return_insn): Return 0 for v7m interrupt functions.  Handle\n+\tThumb-2.\n+\t(const_ok_for_arm): Handle Thumb-2 constants.\n+\t(arm_gen_constant): Ditto.  Use movw when available.\n+\t(arm_function_ok_for_sibcall): Return false for v7m interrupt\n+\tfunctions.\n+\t(legitimize_pic_address, arm_call_tls_get_addr): Handle Thumb-2.\n+\t(thumb_find_work_register, arm_load_pic_register,\n+\tlegitimize_tls_address, arm_address_cost, load_multiple_sequence,\n+\temit_ldm_seq, emit_stm_seq, arm_select_cc_mode, get_jump_table_size,\n+\tprint_multi_reg, output_mov_long_double_fpa_from_arm,\n+\toutput_mov_long_double_arm_from_fpa, output_mov_double_fpa_from_arm,\n+\toutput_mov_double_fpa_from_arm, output_move_double,\n+\tarm_compute_save_reg_mask, arm_compute_save_reg0_reg12_mask,\n+\toutput_return_instruction, arm_output_function_prologue,\n+\tarm_output_epilogue, arm_get_frame_offsets, arm_regno_class,\n+\tarm_output_mi_thunk, thumb_set_return_address): Ditto.\n+\t(arm_expand_prologue): Handle Thumb-2.  Use arm_save_coproc_regs.\n+\t(arm_coproc_mem_operand): Allow POST_INC/PRE_DEC.\n+\t(arithmetic_instr, shift_op): Use arm_shift_nmem.\n+\t(arm_print_operand): Use arm_print_condition.  Handle '(', ')', '.',\n+\t'!' and 'L'.\n+\t(arm_final_prescan_insn): Use extract_constrain_insn_cached.\n+\t(thumb_expand_prologue): Use thumb_set_frame_pointer.\n+\t(arm_file_start): Output directive for unified syntax.\n+\t(arm_unwind_emit_set): Handle stack alignment instruction.\n+\t* config/arm/lib1funcs.asm: Remove default for __ARM_ARCH__.\n+\tAdd v6t2, v7, v7a, v7r and v7m.\n+\t(RETLDM): Add Thumb-2 code.\n+\t(do_it, shift1, do_push, do_pop, COND, THUMB_SYNTAX): New macros.\n+\t* config/arm/arm.h (TARGET_CPU_CPP_BUILTINS): Define __thumb2__.\n+\t(TARGET_THUMB1, TARGET_32BIT, TARGET_THUMB2, TARGET_DSP_MULTIPLY,\n+\tTARGET_INT_SIMD, TARGET_UNIFIED_ASM, ARM_FT_STACKALIGN, IS_STACKALIGN,\n+\tTHUMB2_TRAMPOLINE_TEMPLATE, TRAMPOLINE_ADJUST_ADDRESS,\n+\tASM_OUTPUT_OPCODE, THUMB2_GO_IF_LEGITIMATE_ADDRESS,\n+\tTHUMB2_LEGITIMIZE_ADDRESS, CASE_VECTOR_PC_RELATIVE,\n+\tCASE_VECTOR_SHORTEN_MODE, ADDR_VEC_ALIGN, ASM_OUTPUT_CASE_END,\n+\tADJUST_INSN_LENGTH): Define.\n+\t(TARGET_REALLY_IWMMXT, TARGET_IWMMXT_ABI, CONDITIONAL_REGISTER_USAGE,\n+\tSTATIC_CHAIN_REGNUM, HARD_REGNO_NREGS, INDEX_REG_CLASS,\n+\tBASE_REG_CLASS, MODE_BASE_REG_CLASS, SMALL_REGISTER_CLASSES,\n+\tPREFERRED_RELOAD_CLASS, SECONDARY_OUTPUT_RELOAD_CLASS,\n+\tSECONDARY_INPUT_RELOAD_CLASS, LIBCALL_VALUE, FUNCTION_VALUE_REGNO_P,\n+\tTRAMPOLINE_SIZE, INITIALIZE_TRAMPOLINE, HAVE_PRE_INCREMENT,\n+\tHAVE_POST_DECREMENT, HAVE_PRE_DECREMENT, HAVE_PRE_MODIFY_DISP,\n+\tHAVE_POST_MODIFY_DISP, HAVE_PRE_MODIFY_REG, HAVE_POST_MODIFY_REG,\n+\tREGNO_MODE_OK_FOR_BASE_P, LEGITIMATE_CONSTANT_P,\n+\tREG_MODE_OK_FOR_BASE_P, REG_OK_FOR_INDEX_P, GO_IF_LEGITIMATE_ADDRESS,\n+\tLEGITIMIZE_ADDRESS, THUMB2_LEGITIMIZE_ADDRESS,\n+\tGO_IF_MODE_DEPENDENT_ADDRESS, MEMORY_MOVE_COST, BRANCH_COST,\n+\tASM_APP_OFF, ASM_OUTPUT_CASE_LABEL, ARM_DECLARE_FUNCTION_NAME,\n+\tFINAL_PRESCAN_INSN, PRINT_OPERAND_PUNCT_VALID_P,\n+\tPRINT_OPERAND_ADDRESS): Adjust for Thumb-2.\n+\t(arm_arch_notm, arm_arch_thumb2, arm_arch_hwdiv): New declarations.\n+\t* config/arm/arm-cores.def: Add arm1156t2-s, cortex-a8, cortex-r4 and\n+\tcortex-m3.\n+\t* config/arm/arm-tune.md: Regenerate.\n+\t* config/arm/arm-protos.h: Update prototypes.\n+\t* config/arm/vfp.md: Enable patterns for Thumb-2.\n+\t(arm_movsi_vfp): Add movw alternative.  Use output_move_vfp.\n+\t(arm_movdi_vfp, movsf_vfp, movdf_vfp): Use output_move_vfp.\n+\t(thumb2_movsi_vfp, thumb2_movdi_vfp, thumb2_movsf_vfp,\n+\tthumb2_movdf_vfp, thumb2_movsfcc_vfp, thumb2_movdfcc_vfp): New.\n+\t* config/arm/libunwind.S: Add Thumb-2 code.\n+\t* config/arm/constraints.md: Update include Thumb-2.\n+\t* config/arm/ieee754-sf.S: Add Thumb-2/Unified asm support.\n+\t* config/arm/ieee754-df.S: Ditto.\n+\t* config/arm/bpabi.S: Ditto.\n+\t* config/arm/t-arm (MD_INCLUDES): Add thumb2.md.\n+\t* config/arm/predicates.md (low_register_operand,\n+\tlow_reg_or_int_operand, thumb_16bit_operator): New.\n+\t(thumb_cmp_operand, thumb_cmpneg_operand): Rename...\n+\t(thumb1_cmp_operand, thumb1_cmpneg_operand): ... to this.\n+\t* config/arm/t-arm-elf: Add armv7 multilib.\n+\t* config/arm/arm.md: Update patterns for Thumb-2 and Unified asm.\n+\tInclude thumb2.md.\n+\t(UNSPEC_STACK_ALIGN, ce_count): New.\n+\t(arm_incscc, arm_decscc, arm_umaxsi3, arm_uminsi3,\n+\tarm_zero_extendsidi2, arm_zero_extendqidi2): New\n+\tinsns/expanders.\n+\t* config/arm/fpa.md: Update patterns for Thumb-2 and Unified asm.\n+\t(thumb2_movsf_fpa, thumb2_movdf_fpa, thumb2_movxf_fpa,\n+\tthumb2_movsfcc_fpa, thumb2_movdfcc_fpa): New insns.\n+\t* config/arm/cirrus.md: Update patterns for Thumb-2 and Unified asm.\n+\t(cirrus_thumb2_movdi, cirrus_thumb2_movsi_insn,\n+\tthumb2_cirrus_movsf_hard_insn, thumb2_cirrus_movdf_hard_insn): New\n+\tinsns.\n+\t* doc/extend.texi: Document ARMv7-M interrupt functions.\n+\t* doc/invoke.texi: Document Thumb-2 new cores+architectures.\n+\n 2007-01-03  Jakub Jelinek  <jakub@redhat.com>\n \n \t* unwind-dw2.c (SIGNAL_FRAME_BIT, EXTENDED_CONTEXT_BIT): Define."}, {"sha": "e6694dc1bc74571715a8ced40a3b655381a5523b", "filename": "gcc/config/arm/aof.h", "status": "modified", "additions": 40, "deletions": 11, "changes": 51, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Faof.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Faof.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Faof.h?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,6 +1,6 @@\n /* Definitions of target machine for GNU compiler, for Advanced RISC Machines\n    ARM compilation, AOF Assembler.\n-   Copyright (C) 1995, 1996, 1997, 2000, 2003, 2004\n+   Copyright (C) 1995, 1996, 1997, 2000, 2003, 2004, 2007\n    Free Software Foundation, Inc.\n    Contributed by Richard Earnshaw (rearnsha@armltd.co.uk)\n \n@@ -258,18 +258,47 @@ do {\t\t\t\t\t\\\n #define ARM_MCOUNT_NAME \"_mcount\"\n \n /* Output of Dispatch Tables.  */\n-#define ASM_OUTPUT_ADDR_DIFF_ELT(STREAM, BODY, VALUE, REL)\t\t\t\\\n-  do\t\t\t\t\t\t\t\t\t\t\\\n-    {\t\t\t\t\t\t\t\t\t\t\\\n-      if (TARGET_ARM)\t\t\t\t\t\t\t\t\\\n-        fprintf ((STREAM), \"\\tb\\t|L..%d|\\n\", (VALUE));\t\t\t\t\\\n-      else\t\t\t\t\t\t\t\t\t\\\n-        fprintf ((STREAM), \"\\tDCD\\t|L..%d| - |L..%d|\\n\", (VALUE), (REL));\t\\\n-    }\t\t\t\t\t\t\t\t\t\t\\\n+#define ASM_OUTPUT_ADDR_DIFF_ELT(STREAM, BODY, VALUE, REL)\t\t\\\n+  do\t\t\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      if (TARGET_ARM)\t\t\t\t\t\t\t\\\n+        fprintf ((STREAM), \"\\tb\\t|L..%d|\\n\", (VALUE));\t\t\t\\\n+      else if (TARGET_THUMB1)\t\t\t\t\t\t\\\n+        fprintf ((STREAM), \"\\tDCD\\t|L..%d| - |L..%d|\\n\", (VALUE), (REL)); \\\n+      else /* Thumb-2 */\t\t\t\t\t\t\\\n+\t{\t\t\t\t\t\t\t\t\\\n+\t  switch (GET_MODE(body))\t\t\t\t\t\\\n+\t    {\t\t\t\t\t\t\t\t\\\n+\t    case QImode: /* TBB */\t\t\t\t\t\\\n+\t      asm_fprintf (STREAM, \"\\tDCB\\t(|L..%d| - |L..%d|)/2\\n\",\t\\\n+\t\t\t   VALUE, REL);\t\t\t\t\t\\\n+\t      break;\t\t\t\t\t\t\t\\\n+\t    case HImode: /* TBH */\t\t\t\t\t\\\n+\t      asm_fprintf (STREAM, \"\\tDCW\\t|L..%d| - |L..%d|)/2\\n\",\t\\\n+\t\t\t   VALUE, REL);\t\t\t\t\t\\\n+\t      break;\t\t\t\t\t\t\t\\\n+\t    case SImode:\t\t\t\t\t\t\\\n+\t      if (flag_pic)\t\t\t\t\t\t\\\n+\t\tasm_fprintf (STREAM, \"\\tDCD\\t|L..%d| + 1 - |L..%d|\\n\",\t\\\n+\t\t\t     VALUE, REL);\t\t\t\t\\\n+\t      else\t\t\t\t\t\t\t\\\n+\t\tasm_fprintf (STREAM, \"\\tDCD\\t|L..%d| + 1\\n\", VALUE);\t\\\n+\t      break;\t\t\t\t\t\t\t\\\n+\t    default:\t\t\t\t\t\t\t\\\n+\t      gcc_unreachable();\t\t\t\t\t\\\n+\t    }\t\t\t\t\t\t\t\t\\\n+\t}\t\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n   while (0)\n \n-#define ASM_OUTPUT_ADDR_VEC_ELT(STREAM, VALUE)\t\\\n-  fprintf ((STREAM), \"\\tDCD\\t|L..%d|\\n\", (VALUE))\n+#define ASM_OUTPUT_ADDR_VEC_ELT(STREAM, VALUE)\t\t\t\\\n+  do\t\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\\\n+      gcc_assert (!TARGET_THUMB2)\t\t\t\t\\\n+      fprintf ((STREAM), \"\\tDCD\\t|L..%d|\\n\", (VALUE))\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+  while (0)\n+\t\n \n /* A label marking the start of a jump table is a data label.  */\n #define ASM_OUTPUT_CASE_LABEL(STREAM, PREFIX, NUM, TABLE)\t\\"}, {"sha": "b91031814bbf95a3023c20a0a6ac33fd73164016", "filename": "gcc/config/arm/aout.h", "status": "modified", "additions": 35, "deletions": 4, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Faout.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Faout.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Faout.h?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n /* Definitions of target machine for GNU compiler, for ARM with a.out\n-   Copyright (C) 1995, 1996, 1997, 1998, 1999, 2000, 2004\n+   Copyright (C) 1995, 1996, 1997, 1998, 1999, 2000, 2004, 2007\n    Free Software Foundation, Inc.\n    Contributed by Richard Earnshaw (rearnsha@armltd.co.uk).\n    \n@@ -214,16 +214,47 @@\n #endif\n      \n /* Output an element of a dispatch table.  */\n-#define ASM_OUTPUT_ADDR_VEC_ELT(STREAM, VALUE)  \\\n-  asm_fprintf (STREAM, \"\\t.word\\t%LL%d\\n\", VALUE)\n+#define ASM_OUTPUT_ADDR_VEC_ELT(STREAM, VALUE)\t\t\t\\\n+  do\t\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\\\n+      gcc_assert (!TARGET_THUMB2);\t\t\t\t\\\n+      asm_fprintf (STREAM, \"\\t.word\\t%LL%d\\n\", VALUE);\t\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+  while (0)\n+\t  \n \n+/* Thumb-2 always uses addr_diff_elf so that the Table Branch instructions\n+   can be used.  For non-pic code where the offsets do not suitable for\n+   TBB/TBH the elements are output as absolute labels.  */\n #define ASM_OUTPUT_ADDR_DIFF_ELT(STREAM, BODY, VALUE, REL)\t\t\\\n   do\t\t\t\t\t\t\t\t\t\\\n     {\t\t\t\t\t\t\t\t\t\\\n       if (TARGET_ARM)\t\t\t\t\t\t\t\\\n \tasm_fprintf (STREAM, \"\\tb\\t%LL%d\\n\", VALUE);\t\t\t\\\n-      else\t\t\t\t\t\t\t\t\\\n+      else if (TARGET_THUMB1)\t\t\t\t\t\t\\\n \tasm_fprintf (STREAM, \"\\t.word\\t%LL%d-%LL%d\\n\", VALUE, REL);\t\\\n+      else /* Thumb-2 */\t\t\t\t\t\t\\\n+\t{\t\t\t\t\t\t\t\t\\\n+\t  switch (GET_MODE(body))\t\t\t\t\t\\\n+\t    {\t\t\t\t\t\t\t\t\\\n+\t    case QImode: /* TBB */\t\t\t\t\t\\\n+\t      asm_fprintf (STREAM, \"\\t.byte\\t(%LL%d-%LL%d)/2\\n\",\t\\\n+\t\t\t   VALUE, REL);\t\t\t\t\t\\\n+\t      break;\t\t\t\t\t\t\t\\\n+\t    case HImode: /* TBH */\t\t\t\t\t\\\n+\t      asm_fprintf (STREAM, \"\\t.2byte\\t(%LL%d-%LL%d)/2\\n\",\t\\\n+\t\t\t   VALUE, REL);\t\t\t\t\t\\\n+\t      break;\t\t\t\t\t\t\t\\\n+\t    case SImode:\t\t\t\t\t\t\\\n+\t      if (flag_pic)\t\t\t\t\t\t\\\n+\t\tasm_fprintf (STREAM, \"\\t.word\\t%LL%d+1-%LL%d\\n\", VALUE, REL); \\\n+\t      else\t\t\t\t\t\t\t\\\n+\t\tasm_fprintf (STREAM, \"\\t.word\\t%LL%d+1\\n\", VALUE);\t\\\n+\t      break;\t\t\t\t\t\t\t\\\n+\t    default:\t\t\t\t\t\t\t\\\n+\t      gcc_unreachable();\t\t\t\t\t\\\n+\t    }\t\t\t\t\t\t\t\t\\\n+\t}\t\t\t\t\t\t\t\t\\\n     }\t\t\t\t\t\t\t\t\t\\\n   while (0)\n "}, {"sha": "0241cdfcc0fba8710a7db5fe106761637aa36187", "filename": "gcc/config/arm/arm-cores.def", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm-cores.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm-cores.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm-cores.def?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n /* ARM CPU Cores\n-   Copyright (C) 2003, 2005 Free Software Foundation, Inc.\n+   Copyright (C) 2003, 2005, 2006, 2007 Free Software Foundation, Inc.\n    Written by CodeSourcery, LLC\n \n    This file is part of GCC.\n@@ -115,3 +115,7 @@ ARM_CORE(\"arm1176jz-s\",\t  arm1176jzs,\t6ZK,\t\t\t\t FL_LDSCHED, 9e)\n ARM_CORE(\"arm1176jzf-s\",  arm1176jzfs,\t6ZK,\t\t\t\t FL_LDSCHED | FL_VFPV2, 9e)\n ARM_CORE(\"mpcorenovfp\",\t  mpcorenovfp,\t6K,\t\t\t\t FL_LDSCHED, 9e)\n ARM_CORE(\"mpcore\",\t  mpcore,\t6K,\t\t\t\t FL_LDSCHED | FL_VFPV2, 9e)\n+ARM_CORE(\"arm1156t2-s\",\t  arm1156t2s,\t6T2,\t\t\t\t FL_LDSCHED, 9e)\n+ARM_CORE(\"cortex-a8\",\t  cortexa8,\t7A,\t\t\t\t FL_LDSCHED, 9e)\n+ARM_CORE(\"cortex-r4\",\t  cortexr4,\t7R,\t\t\t\t FL_LDSCHED, 9e)\n+ARM_CORE(\"cortex-m3\",\t  cortexm3,\t7M,\t\t\t\t FL_LDSCHED, 9e)"}, {"sha": "6a9a5492c1c3bd40298e1161e2d5c26d37f04954", "filename": "gcc/config/arm/arm-protos.h", "status": "modified", "additions": 11, "deletions": 7, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm-protos.h?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n /* Prototypes for exported functions defined in arm.c and pe.c\n-   Copyright (C) 1999, 2000, 2001, 2002, 2003, 2004, 2005\n+   Copyright (C) 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007\n    Free Software Foundation, Inc.\n    Contributed by Richard Earnshaw (rearnsha@arm.com)\n    Minor hacks by Nick Clifton (nickc@cygnus.com)\n@@ -33,6 +33,7 @@ extern const char *arm_output_epilogue (rtx);\n extern void arm_expand_prologue (void);\n extern const char *arm_strip_name_encoding (const char *);\n extern void arm_asm_output_labelref (FILE *, const char *);\n+extern void thumb2_asm_output_opcode (FILE *);\n extern unsigned long arm_current_func_type (void);\n extern HOST_WIDE_INT arm_compute_initial_elimination_offset (unsigned int,\n \t\t\t\t\t\t\t     unsigned int);\n@@ -58,7 +59,8 @@ extern int legitimate_pic_operand_p (rtx);\n extern rtx legitimize_pic_address (rtx, enum machine_mode, rtx);\n extern rtx legitimize_tls_address (rtx, rtx);\n extern int arm_legitimate_address_p  (enum machine_mode, rtx, RTX_CODE, int);\n-extern int thumb_legitimate_address_p (enum machine_mode, rtx, int);\n+extern int thumb1_legitimate_address_p (enum machine_mode, rtx, int);\n+extern int thumb2_legitimate_address_p  (enum machine_mode, rtx, int);\n extern int thumb_legitimate_offset_p (enum machine_mode, HOST_WIDE_INT);\n extern rtx arm_legitimize_address (rtx, rtx, enum machine_mode);\n extern rtx thumb_legitimize_address (rtx, rtx, enum machine_mode);\n@@ -108,6 +110,7 @@ extern const char *output_mov_long_double_arm_from_arm (rtx *);\n extern const char *output_mov_double_fpa_from_arm (rtx *);\n extern const char *output_mov_double_arm_from_fpa (rtx *);\n extern const char *output_move_double (rtx *);\n+extern const char *output_move_vfp (rtx *operands);\n extern const char *output_add_immediate (rtx *);\n extern const char *arithmetic_instr (rtx, int);\n extern void output_ascii_pseudo_op (FILE *, const unsigned char *, int);\n@@ -116,14 +119,14 @@ extern void arm_poke_function_name (FILE *, const char *);\n extern void arm_print_operand (FILE *, rtx, int);\n extern void arm_print_operand_address (FILE *, rtx);\n extern void arm_final_prescan_insn (rtx);\n-extern int arm_go_if_legitimate_address (enum machine_mode, rtx);\n extern int arm_debugger_arg_offset (int, rtx);\n extern int arm_is_longcall_p (rtx, int, int);\n extern int    arm_emit_vector_const (FILE *, rtx);\n extern const char * arm_output_load_gr (rtx *);\n extern const char *vfp_output_fstmd (rtx *);\n extern void arm_set_return_address (rtx, rtx);\n extern int arm_eliminable_register (rtx);\n+extern const char *arm_output_shift(rtx *, int);\n \n extern bool arm_output_addr_const_extra (FILE *, rtx);\n \n@@ -151,23 +154,24 @@ extern int arm_float_words_big_endian (void);\n /* Thumb functions.  */\n extern void arm_init_expanders (void);\n extern const char *thumb_unexpanded_epilogue (void);\n-extern void thumb_expand_prologue (void);\n-extern void thumb_expand_epilogue (void);\n+extern void thumb1_expand_prologue (void);\n+extern void thumb1_expand_epilogue (void);\n #ifdef TREE_CODE\n extern int is_called_in_ARM_mode (tree);\n #endif\n extern int thumb_shiftable_const (unsigned HOST_WIDE_INT);\n #ifdef RTX_CODE\n-extern void thumb_final_prescan_insn (rtx);\n+extern void thumb1_final_prescan_insn (rtx);\n+extern void thumb2_final_prescan_insn (rtx);\n extern const char *thumb_load_double_from_address (rtx *);\n extern const char *thumb_output_move_mem_multiple (int, rtx *);\n extern const char *thumb_call_via_reg (rtx);\n extern void thumb_expand_movmemqi (rtx *);\n-extern int thumb_go_if_legitimate_address (enum machine_mode, rtx);\n extern rtx arm_return_addr (int, rtx);\n extern void thumb_reload_out_hi (rtx *);\n extern void thumb_reload_in_hi (rtx *);\n extern void thumb_set_return_address (rtx, rtx);\n+extern const char *thumb2_output_casesi(rtx *);\n #endif\n \n /* Defined in pe.c.  */"}, {"sha": "5b4c46f07b7ac6c397fa93f01f347dc533fb6c49", "filename": "gcc/config/arm/arm-tune.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm-tune.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm-tune.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm-tune.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n ;; -*- buffer-read-only: t -*-\n ;; Generated automatically by gentune.sh from arm-cores.def\n (define_attr \"tune\"\n-\t\"arm2,arm250,arm3,arm6,arm60,arm600,arm610,arm620,arm7,arm7d,arm7di,arm70,arm700,arm700i,arm710,arm720,arm710c,arm7100,arm7500,arm7500fe,arm7m,arm7dm,arm7dmi,arm8,arm810,strongarm,strongarm110,strongarm1100,strongarm1110,arm7tdmi,arm7tdmis,arm710t,arm720t,arm740t,arm9,arm9tdmi,arm920,arm920t,arm922t,arm940t,ep9312,arm10tdmi,arm1020t,arm9e,arm946es,arm966es,arm968es,arm10e,arm1020e,arm1022e,xscale,iwmmxt,arm926ejs,arm1026ejs,arm1136js,arm1136jfs,arm1176jzs,arm1176jzfs,mpcorenovfp,mpcore\"\n+\t\"arm2,arm250,arm3,arm6,arm60,arm600,arm610,arm620,arm7,arm7d,arm7di,arm70,arm700,arm700i,arm710,arm720,arm710c,arm7100,arm7500,arm7500fe,arm7m,arm7dm,arm7dmi,arm8,arm810,strongarm,strongarm110,strongarm1100,strongarm1110,arm7tdmi,arm7tdmis,arm710t,arm720t,arm740t,arm9,arm9tdmi,arm920,arm920t,arm922t,arm940t,ep9312,arm10tdmi,arm1020t,arm9e,arm946es,arm966es,arm968es,arm10e,arm1020e,arm1022e,xscale,iwmmxt,arm926ejs,arm1026ejs,arm1136js,arm1136jfs,arm1176jzs,arm1176jzfs,mpcorenovfp,mpcore,arm1156t2s,cortexa8,cortexr4,cortexm3\"\n \t(const (symbol_ref \"arm_tune\")))"}, {"sha": "9558275c6c74e02f15f00a3515401181c2485285", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 1184, "deletions": 366, "changes": 1550, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,6 +1,6 @@\n /* Output routines for GCC for ARM.\n    Copyright (C) 1991, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001,\n-   2002, 2003, 2004, 2005, 2006  Free Software Foundation, Inc.\n+   2002, 2003, 2004, 2005, 2006, 2007  Free Software Foundation, Inc.\n    Contributed by Pieter `Tiggr' Schoenmakers (rcpieter@win.tue.nl)\n    and Martin Simmons (@harleqn.co.uk).\n    More major hacks by Richard Earnshaw (rearnsha@arm.com).\n@@ -67,10 +67,12 @@ static int arm_gen_constant (enum rtx_code, enum machine_mode, rtx,\n static unsigned bit_count (unsigned long);\n static int arm_address_register_rtx_p (rtx, int);\n static int arm_legitimate_index_p (enum machine_mode, rtx, RTX_CODE, int);\n-static int thumb_base_register_rtx_p (rtx, enum machine_mode, int);\n-inline static int thumb_index_register_rtx_p (rtx, int);\n+static int thumb2_legitimate_index_p (enum machine_mode, rtx, int);\n+static int thumb1_base_register_rtx_p (rtx, enum machine_mode, int);\n+inline static int thumb1_index_register_rtx_p (rtx, int);\n static int thumb_far_jump_used_p (void);\n static bool thumb_force_lr_save (void);\n+static unsigned long thumb1_compute_save_reg_mask (void);\n static int const_ok_for_op (HOST_WIDE_INT, enum rtx_code);\n static rtx emit_sfm (int, int);\n static int arm_size_return_regs (void);\n@@ -114,7 +116,7 @@ static tree arm_handle_notshared_attribute (tree *, tree, tree, int, bool *);\n #endif\n static void arm_output_function_epilogue (FILE *, HOST_WIDE_INT);\n static void arm_output_function_prologue (FILE *, HOST_WIDE_INT);\n-static void thumb_output_function_prologue (FILE *, HOST_WIDE_INT);\n+static void thumb1_output_function_prologue (FILE *, HOST_WIDE_INT);\n static int arm_comp_type_attributes (tree, tree);\n static void arm_set_default_type_attributes (tree);\n static int arm_adjust_cost (rtx, rtx, rtx, int);\n@@ -177,6 +179,7 @@ static bool arm_must_pass_in_stack (enum machine_mode, tree);\n static void arm_unwind_emit (FILE *, rtx);\n static bool arm_output_ttype (rtx);\n #endif\n+static void arm_dwarf_handle_frame_unspec (const char *, rtx, int);\n \n static tree arm_cxx_guard_type (void);\n static bool arm_cxx_guard_mask_bit (void);\n@@ -205,7 +208,6 @@ static bool arm_tls_symbol_p (rtx x);\n \n #undef TARGET_ASM_FILE_START\n #define TARGET_ASM_FILE_START arm_file_start\n-\n #undef TARGET_ASM_FILE_END\n #define TARGET_ASM_FILE_END arm_file_end\n \n@@ -361,6 +363,9 @@ static bool arm_tls_symbol_p (rtx x);\n #define TARGET_ARM_EABI_UNWINDER true\n #endif /* TARGET_UNWIND_INFO */\n \n+#undef TARGET_DWARF_HANDLE_FRAME_UNSPEC\n+#define TARGET_DWARF_HANDLE_FRAME_UNSPEC arm_dwarf_handle_frame_unspec\n+\n #undef  TARGET_CANNOT_COPY_INSN_P\n #define TARGET_CANNOT_COPY_INSN_P arm_cannot_copy_insn_p\n \n@@ -441,11 +446,15 @@ static int thumb_call_reg_needed;\n #define FL_WBUF\t      (1 << 14)\t      /* Schedule for write buffer ops.\n \t\t\t\t\t Note: ARM6 & 7 derivatives only.  */\n #define FL_ARCH6K     (1 << 15)       /* Architecture rel 6 K extensions.  */\n+#define FL_THUMB2     (1 << 16)\t      /* Thumb-2.  */\n+#define FL_NOTM\t      (1 << 17)\t      /* Instructions not present in the 'M'\n+\t\t\t\t\t profile.  */\n+#define FL_DIV\t      (1 << 18)\t      /* Hardware divde.  */\n \n #define FL_IWMMXT     (1 << 29)\t      /* XScale v2 or \"Intel Wireless MMX technology\".  */\n \n-#define FL_FOR_ARCH2\t0\n-#define FL_FOR_ARCH3\tFL_MODE32\n+#define FL_FOR_ARCH2\tFL_NOTM\n+#define FL_FOR_ARCH3\t(FL_FOR_ARCH2 | FL_MODE32)\n #define FL_FOR_ARCH3M\t(FL_FOR_ARCH3 | FL_ARCH3M)\n #define FL_FOR_ARCH4\t(FL_FOR_ARCH3M | FL_ARCH4)\n #define FL_FOR_ARCH4T\t(FL_FOR_ARCH4 | FL_THUMB)\n@@ -459,6 +468,11 @@ static int thumb_call_reg_needed;\n #define FL_FOR_ARCH6K\t(FL_FOR_ARCH6 | FL_ARCH6K)\n #define FL_FOR_ARCH6Z\tFL_FOR_ARCH6\n #define FL_FOR_ARCH6ZK\tFL_FOR_ARCH6K\n+#define FL_FOR_ARCH6T2\t(FL_FOR_ARCH6 | FL_THUMB2)\n+#define FL_FOR_ARCH7\t(FL_FOR_ARCH6T2 &~ FL_NOTM)\n+#define FL_FOR_ARCH7A\t(FL_FOR_ARCH7 | FL_NOTM)\n+#define FL_FOR_ARCH7R\t(FL_FOR_ARCH7A | FL_DIV)\n+#define FL_FOR_ARCH7M\t(FL_FOR_ARCH7 | FL_DIV)\n \n /* The bits in this mask specify which\n    instructions we are allowed to generate.  */\n@@ -492,6 +506,9 @@ int arm_arch6 = 0;\n /* Nonzero if this chip supports the ARM 6K extensions.  */\n int arm_arch6k = 0;\n \n+/* Nonzero if instructions not present in the 'M' profile can be used.  */\n+int arm_arch_notm = 0;\n+\n /* Nonzero if this chip can benefit from load scheduling.  */\n int arm_ld_sched = 0;\n \n@@ -524,6 +541,12 @@ int thumb_code = 0;\n    interworking clean.  */\n int arm_cpp_interwork = 0;\n \n+/* Nonzero if chip supports Thumb 2.  */\n+int arm_arch_thumb2;\n+\n+/* Nonzero if chip supports integer division instruction.  */\n+int arm_arch_hwdiv;\n+\n /* In case of a PRE_INC, POST_INC, PRE_DEC, POST_DEC memory reference, we\n    must report the mode of the memory reference from PRINT_OPERAND to\n    PRINT_OPERAND_ADDRESS.  */\n@@ -545,9 +568,17 @@ static int arm_constant_limit = 3;\n \n /* For an explanation of these variables, see final_prescan_insn below.  */\n int arm_ccfsm_state;\n+/* arm_current_cc is also used for Thumb-2 cond_exec blocks.  */\n enum arm_cond_code arm_current_cc;\n rtx arm_target_insn;\n int arm_target_label;\n+/* The number of conditionally executed insns, including the current insn.  */\n+int arm_condexec_count = 0;\n+/* A bitmask specifying the patterns for the IT block.\n+   Zero means do not output an IT block before this insn. */\n+int arm_condexec_mask = 0;\n+/* The number of bits used in arm_condexec_mask.  */\n+int arm_condexec_masklen = 0;\n \n /* The condition codes of the ARM, and the inverse function.  */\n static const char * const arm_condition_codes[] =\n@@ -556,7 +587,12 @@ static const char * const arm_condition_codes[] =\n   \"hi\", \"ls\", \"ge\", \"lt\", \"gt\", \"le\", \"al\", \"nv\"\n };\n \n+#define ARM_LSL_NAME (TARGET_UNIFIED_ASM ? \"lsl\" : \"asl\")\n #define streq(string1, string2) (strcmp (string1, string2) == 0)\n+\n+#define THUMB2_WORK_REGS (0xff & ~(  (1 << THUMB_HARD_FRAME_POINTER_REGNUM) \\\n+\t\t\t\t   | (1 << SP_REGNUM) | (1 << PC_REGNUM) \\\n+\t\t\t\t   | (1 << PIC_OFFSET_TABLE_REGNUM)))\n \f\n /* Initialization code.  */\n \n@@ -604,6 +640,11 @@ static const struct processors all_architectures[] =\n   {\"armv6k\",  mpcore,\t  \"6K\",  FL_CO_PROC |             FL_FOR_ARCH6K, NULL},\n   {\"armv6z\",  arm1176jzs, \"6Z\",  FL_CO_PROC |             FL_FOR_ARCH6Z, NULL},\n   {\"armv6zk\", arm1176jzs, \"6ZK\", FL_CO_PROC |             FL_FOR_ARCH6ZK, NULL},\n+  {\"armv6t2\", arm1156t2s, \"6T2\", FL_CO_PROC |             FL_FOR_ARCH6T2, NULL},\n+  {\"armv7\",   cortexa8,\t  \"7\",\t FL_CO_PROC |\t\t  FL_FOR_ARCH7, NULL},\n+  {\"armv7-a\", cortexa8,\t  \"7A\",\t FL_CO_PROC |\t\t  FL_FOR_ARCH7A, NULL},\n+  {\"armv7-r\", cortexr4,\t  \"7R\",\t FL_CO_PROC |\t\t  FL_FOR_ARCH7R, NULL},\n+  {\"armv7-m\", cortexm3,\t  \"7M\",\t FL_CO_PROC |\t\t  FL_FOR_ARCH7M, NULL},\n   {\"ep9312\",  ep9312,     \"4T\",  FL_LDSCHED | FL_CIRRUS | FL_FOR_ARCH4, NULL},\n   {\"iwmmxt\",  iwmmxt,     \"5TE\", FL_LDSCHED | FL_STRONG | FL_FOR_ARCH5TE | FL_XSCALE | FL_IWMMXT , NULL},\n   {NULL, arm_none, NULL, 0 , NULL}\n@@ -1044,6 +1085,9 @@ arm_override_options (void)\n \n   /* Make sure that the processor choice does not conflict with any of the\n      other command line choices.  */\n+  if (TARGET_ARM && !(insn_flags & FL_NOTM))\n+    error (\"target CPU does not support ARM mode\");\n+\n   if (TARGET_INTERWORK && !(insn_flags & FL_THUMB))\n     {\n       warning (0, \"target CPU does not support interworking\" );\n@@ -1117,6 +1161,8 @@ arm_override_options (void)\n   arm_arch5e = (insn_flags & FL_ARCH5E) != 0;\n   arm_arch6 = (insn_flags & FL_ARCH6) != 0;\n   arm_arch6k = (insn_flags & FL_ARCH6K) != 0;\n+  arm_arch_notm = (insn_flags & FL_NOTM) != 0;\n+  arm_arch_thumb2 = (insn_flags & FL_THUMB2) != 0;\n   arm_arch_xscale = (insn_flags & FL_XSCALE) != 0;\n   arm_arch_cirrus = (insn_flags & FL_CIRRUS) != 0;\n \n@@ -1126,6 +1172,7 @@ arm_override_options (void)\n   arm_tune_wbuf = (tune_flags & FL_WBUF) != 0;\n   arm_tune_xscale = (tune_flags & FL_XSCALE) != 0;\n   arm_arch_iwmmxt = (insn_flags & FL_IWMMXT) != 0;\n+  arm_arch_hwdiv = (insn_flags & FL_DIV) != 0;\n \n   /* V5 code we generate is completely interworking capable, so we turn off\n      TARGET_INTERWORK here to avoid many tests later on.  */\n@@ -1240,6 +1287,10 @@ arm_override_options (void)\n   if (TARGET_IWMMXT && !TARGET_SOFT_FLOAT)\n     sorry (\"iWMMXt and hardware floating point\");\n \n+  /* ??? iWMMXt insn patterns need auditing for Thumb-2.  */\n+  if (TARGET_THUMB2 && TARGET_IWMMXT)\n+    sorry (\"Thumb-2 iWMMXt\");\n+\n   /* If soft-float is specified then don't use FPU.  */\n   if (TARGET_SOFT_FLOAT)\n     arm_fpu_arch = FPUTYPE_NONE;\n@@ -1273,8 +1324,8 @@ arm_override_options (void)\n \ttarget_thread_pointer = TP_SOFT;\n     }\n \n-  if (TARGET_HARD_TP && TARGET_THUMB)\n-    error (\"can not use -mtp=cp15 with -mthumb\");\n+  if (TARGET_HARD_TP && TARGET_THUMB1)\n+    error (\"can not use -mtp=cp15 with 16-bit Thumb\");\n \n   /* Override the default structure alignment for AAPCS ABI.  */\n   if (TARGET_AAPCS_BASED)\n@@ -1309,6 +1360,7 @@ arm_override_options (void)\n \tarm_pic_register = pic_register;\n     }\n \n+  /* ??? We might want scheduling for thumb2.  */\n   if (TARGET_THUMB && flag_schedule_insns)\n     {\n       /* Don't warn since it's on by default in -O2.  */\n@@ -1390,6 +1442,9 @@ arm_isr_value (tree argument)\n   const isr_attribute_arg * ptr;\n   const char *              arg;\n \n+  if (!arm_arch_notm)\n+    return ARM_FT_NORMAL | ARM_FT_STACKALIGN;\n+\n   /* No argument - default to IRQ.  */\n   if (argument == NULL_TREE)\n     return ARM_FT_ISR;\n@@ -1483,9 +1538,9 @@ use_return_insn (int iscond, rtx sibling)\n \n   func_type = arm_current_func_type ();\n \n-  /* Naked functions and volatile functions need special\n+  /* Naked, volatile and stack alignment functions need special\n      consideration.  */\n-  if (func_type & (ARM_FT_VOLATILE | ARM_FT_NAKED))\n+  if (func_type & (ARM_FT_VOLATILE | ARM_FT_NAKED | ARM_FT_STACKALIGN))\n     return 0;\n \n   /* So do interrupt functions that use the frame pointer.  */\n@@ -1522,7 +1577,7 @@ use_return_insn (int iscond, rtx sibling)\n      We test for !arm_arch5 here, because code for any architecture\n      less than this could potentially be run on one of the buggy\n      chips.  */\n-  if (stack_adjust == 4 && !arm_arch5)\n+  if (stack_adjust == 4 && !arm_arch5 && TARGET_ARM)\n     {\n       /* Validate that r3 is a call-clobbered register (always true in\n \t the default abi) ...  */\n@@ -1616,17 +1671,36 @@ const_ok_for_arm (HOST_WIDE_INT i)\n   if ((i & ~(unsigned HOST_WIDE_INT) 0xff) == 0)\n     return TRUE;\n \n-  /* Get the number of trailing zeros, rounded down to the nearest even\n-     number.  */\n-  lowbit = (ffs ((int) i) - 1) & ~1;\n+  /* Get the number of trailing zeros.  */\n+  lowbit = ffs((int) i) - 1;\n+  \n+  /* Only even shifts are allowed in ARM mode so round down to the\n+     nearest even number.  */\n+  if (TARGET_ARM)\n+    lowbit &= ~1;\n \n   if ((i & ~(((unsigned HOST_WIDE_INT) 0xff) << lowbit)) == 0)\n     return TRUE;\n-  else if (lowbit <= 4\n+\n+  if (TARGET_ARM)\n+    {\n+      /* Allow rotated constants in ARM mode.  */\n+      if (lowbit <= 4\n \t   && ((i & ~0xc000003f) == 0\n \t       || (i & ~0xf000000f) == 0\n \t       || (i & ~0xfc000003) == 0))\n-    return TRUE;\n+\treturn TRUE;\n+    }\n+  else\n+    {\n+      HOST_WIDE_INT v;\n+\n+      /* Allow repeated pattern.  */\n+      v = i & 0xff;\n+      v |= v << 16;\n+      if (i == v || i == (v | (v << 8)))\n+\treturn TRUE;\n+    }\n \n   return FALSE;\n }\n@@ -1666,6 +1740,7 @@ const_ok_for_op (HOST_WIDE_INT i, enum rtx_code code)\n    either produce a simpler sequence, or we will want to cse the values.\n    Return value is the number of insns emitted.  */\n \n+/* ??? Tweak this for thumb2.  */\n int\n arm_split_constant (enum rtx_code code, enum machine_mode mode, rtx insn,\n \t\t    HOST_WIDE_INT val, rtx target, rtx source, int subtargets)\n@@ -1724,6 +1799,8 @@ arm_split_constant (enum rtx_code code, enum machine_mode mode, rtx insn,\n \t\t\t   1);\n }\n \n+/* Return the number of ARM instructions required to synthesize the given\n+   constant.  */\n static int\n count_insns_for_constant (HOST_WIDE_INT remainder, int i)\n {\n@@ -1765,6 +1842,7 @@ emit_constant_insn (rtx cond, rtx pattern)\n \n /* As above, but extra parameter GENERATE which, if clear, suppresses\n    RTL generation.  */\n+/* ??? This needs more work for thumb2.  */\n \n static int\n arm_gen_constant (enum rtx_code code, enum machine_mode mode, rtx cond,\n@@ -1941,6 +2019,15 @@ arm_gen_constant (enum rtx_code code, enum machine_mode mode, rtx cond,\n   switch (code)\n     {\n     case SET:\n+      /* See if we can use movw.  */\n+      if (arm_arch_thumb2 && (remainder & 0xffff0000) == 0)\n+\t{\n+\t  if (generate)\n+\t    emit_constant_insn (cond, gen_rtx_SET (VOIDmode, target,\n+\t\t\t\t\t\t   GEN_INT (val)));\n+\t  return 1;\n+\t}\n+\n       /* See if we can do this by sign_extending a constant that is known\n \t to be negative.  This is a good, way of doing it, since the shift\n \t may well merge into a subsequent insn.  */\n@@ -2282,59 +2369,67 @@ arm_gen_constant (enum rtx_code code, enum machine_mode mode, rtx cond,\n      We start by looking for the largest block of zeros that are aligned on\n      a 2-bit boundary, we then fill up the temps, wrapping around to the\n      top of the word when we drop off the bottom.\n-     In the worst case this code should produce no more than four insns.  */\n+     In the worst case this code should produce no more than four insns.\n+     Thumb-2 constants are shifted, not rotated, so the MSB is always the\n+     best place to start.  */\n+\n+  /* ??? Use thumb2 replicated constants when the high and low halfwords are\n+     the same.  */\n   {\n     int best_start = 0;\n-    int best_consecutive_zeros = 0;\n-\n-    for (i = 0; i < 32; i += 2)\n+    if (!TARGET_THUMB2)\n       {\n-\tint consecutive_zeros = 0;\n+\tint best_consecutive_zeros = 0;\n \n-\tif (!(remainder & (3 << i)))\n+\tfor (i = 0; i < 32; i += 2)\n \t  {\n-\t    while ((i < 32) && !(remainder & (3 << i)))\n-\t      {\n-\t\tconsecutive_zeros += 2;\n-\t\ti += 2;\n-\t      }\n-\t    if (consecutive_zeros > best_consecutive_zeros)\n+\t    int consecutive_zeros = 0;\n+\n+\t    if (!(remainder & (3 << i)))\n \t      {\n-\t\tbest_consecutive_zeros = consecutive_zeros;\n-\t\tbest_start = i - consecutive_zeros;\n+\t\twhile ((i < 32) && !(remainder & (3 << i)))\n+\t\t  {\n+\t\t    consecutive_zeros += 2;\n+\t\t    i += 2;\n+\t\t  }\n+\t\tif (consecutive_zeros > best_consecutive_zeros)\n+\t\t  {\n+\t\t    best_consecutive_zeros = consecutive_zeros;\n+\t\t    best_start = i - consecutive_zeros;\n+\t\t  }\n+\t\ti -= 2;\n \t      }\n-\t    i -= 2;\n \t  }\n-      }\n-\n-    /* So long as it won't require any more insns to do so, it's\n-       desirable to emit a small constant (in bits 0...9) in the last\n-       insn.  This way there is more chance that it can be combined with\n-       a later addressing insn to form a pre-indexed load or store\n-       operation.  Consider:\n-\n-\t       *((volatile int *)0xe0000100) = 1;\n-\t       *((volatile int *)0xe0000110) = 2;\n \n-       We want this to wind up as:\n-\n-\t\tmov rA, #0xe0000000\n-\t\tmov rB, #1\n-\t\tstr rB, [rA, #0x100]\n-\t\tmov rB, #2\n-\t\tstr rB, [rA, #0x110]\n-\n-       rather than having to synthesize both large constants from scratch.\n-\n-       Therefore, we calculate how many insns would be required to emit\n-       the constant starting from `best_start', and also starting from\n-       zero (i.e. with bit 31 first to be output).  If `best_start' doesn't\n-       yield a shorter sequence, we may as well use zero.  */\n-    if (best_start != 0\n-\t&& ((((unsigned HOST_WIDE_INT) 1) << best_start) < remainder)\n-\t&& (count_insns_for_constant (remainder, 0) <=\n-\t    count_insns_for_constant (remainder, best_start)))\n-      best_start = 0;\n+\t/* So long as it won't require any more insns to do so, it's\n+\t   desirable to emit a small constant (in bits 0...9) in the last\n+\t   insn.  This way there is more chance that it can be combined with\n+\t   a later addressing insn to form a pre-indexed load or store\n+\t   operation.  Consider:\n+\n+\t\t   *((volatile int *)0xe0000100) = 1;\n+\t\t   *((volatile int *)0xe0000110) = 2;\n+\n+\t   We want this to wind up as:\n+\n+\t\t    mov rA, #0xe0000000\n+\t\t    mov rB, #1\n+\t\t    str rB, [rA, #0x100]\n+\t\t    mov rB, #2\n+\t\t    str rB, [rA, #0x110]\n+\n+\t   rather than having to synthesize both large constants from scratch.\n+\n+\t   Therefore, we calculate how many insns would be required to emit\n+\t   the constant starting from `best_start', and also starting from\n+\t   zero (i.e. with bit 31 first to be output).  If `best_start' doesn't\n+\t   yield a shorter sequence, we may as well use zero.  */\n+\tif (best_start != 0\n+\t    && ((((unsigned HOST_WIDE_INT) 1) << best_start) < remainder)\n+\t    && (count_insns_for_constant (remainder, 0) <=\n+\t\tcount_insns_for_constant (remainder, best_start)))\n+\t  best_start = 0;\n+      }\n \n     /* Now start emitting the insns.  */\n     i = best_start;\n@@ -2400,9 +2495,17 @@ arm_gen_constant (enum rtx_code code, enum machine_mode mode, rtx cond,\n \t      code = PLUS;\n \n \t    insns++;\n-\t    i -= 6;\n+\t    if (TARGET_ARM)\n+\t      i -= 6;\n+\t    else\n+\t      i -= 7;\n \t  }\n-\ti -= 2;\n+\t/* Arm allows rotates by a multiple of two. Thumb-2 allows arbitary\n+\t   shifts.  */\n+\tif (TARGET_ARM)\n+\t  i -= 2;\n+\telse\n+\t  i--;\n       }\n     while (remainder);\n   }\n@@ -3149,6 +3252,7 @@ static bool\n arm_function_ok_for_sibcall (tree decl, tree exp ATTRIBUTE_UNUSED)\n {\n   int call_type = TARGET_LONG_CALLS ? CALL_LONG : CALL_NORMAL;\n+  unsigned long func_type;\n \n   if (cfun->machine->sibcall_blocked)\n     return false;\n@@ -3176,8 +3280,13 @@ arm_function_ok_for_sibcall (tree decl, tree exp ATTRIBUTE_UNUSED)\n   if (TARGET_INTERWORK && TREE_PUBLIC (decl) && !TREE_ASM_WRITTEN (decl))\n     return false;\n \n+  func_type = arm_current_func_type ();\n   /* Never tailcall from an ISR routine - it needs a special exit sequence.  */\n-  if (IS_INTERRUPT (arm_current_func_type ()))\n+  if (IS_INTERRUPT (func_type))\n+    return false;\n+\n+  /* Never tailcall if function may be called with a misaligned SP.  */\n+  if (IS_STACKALIGN (func_type))\n     return false;\n \n   /* Everything else is ok.  */\n@@ -3276,8 +3385,10 @@ legitimize_pic_address (rtx orig, enum machine_mode mode, rtx reg)\n \n       if (TARGET_ARM)\n \temit_insn (gen_pic_load_addr_arm (address, orig));\n-      else\n-\temit_insn (gen_pic_load_addr_thumb (address, orig));\n+      else if (TARGET_THUMB2)\n+\temit_insn (gen_pic_load_addr_thumb2 (address, orig));\n+      else /* TARGET_THUMB1 */\n+\temit_insn (gen_pic_load_addr_thumb1 (address, orig));\n \n       if ((GET_CODE (orig) == LABEL_REF\n \t   || (GET_CODE (orig) == SYMBOL_REF &&\n@@ -3352,7 +3463,7 @@ legitimize_pic_address (rtx orig, enum machine_mode mode, rtx reg)\n }\n \n \n-/* Find a spare low register to use during the prolog of a function.  */\n+/* Find a spare register to use during the prolog of a function.  */\n \n static int\n thumb_find_work_register (unsigned long pushed_regs_mask)\n@@ -3401,6 +3512,13 @@ thumb_find_work_register (unsigned long pushed_regs_mask)\n     if (pushed_regs_mask & (1 << reg))\n       return reg;\n \n+  if (TARGET_THUMB2)\n+    {\n+      /* Thumb-2 can use high regs.  */\n+      for (reg = FIRST_HI_REGNUM; reg < 15; reg ++)\n+\tif (pushed_regs_mask & (1 << reg))\n+\t  return reg;\n+    }\n   /* Something went wrong - thumb_compute_save_reg_mask()\n      should have arranged for a suitable register to be pushed.  */\n   gcc_unreachable ();\n@@ -3448,7 +3566,27 @@ arm_load_pic_register (unsigned long saved_regs ATTRIBUTE_UNUSED)\n       emit_insn (gen_pic_add_dot_plus_eight (cfun->machine->pic_reg,\n \t\t\t\t\t     cfun->machine->pic_reg, labelno));\n     }\n-  else\n+  else if (TARGET_THUMB2)\n+    {\n+      /* Thumb-2 only allows very limited access to the PC.  Calculate the\n+\t address in a temporary register.  */\n+      if (arm_pic_register != INVALID_REGNUM)\n+\t{\n+\t  pic_tmp = gen_rtx_REG (SImode,\n+\t\t\t\t thumb_find_work_register (saved_regs));\n+\t}\n+      else\n+\t{\n+\t  gcc_assert (!no_new_pseudos);\n+\t  pic_tmp = gen_reg_rtx (Pmode);\n+\t}\n+\n+      emit_insn (gen_pic_load_addr_thumb2 (cfun->machine->pic_reg, pic_rtx));\n+      emit_insn (gen_pic_load_dot_plus_four (pic_tmp, labelno));\n+      emit_insn (gen_addsi3(cfun->machine->pic_reg, cfun->machine->pic_reg,\n+\t\t\t    pic_tmp));\n+    }\n+  else /* TARGET_THUMB1 */\n     {\n       if (arm_pic_register != INVALID_REGNUM\n \t  && REGNO (cfun->machine->pic_reg) > LAST_LO_REGNUM)\n@@ -3457,11 +3595,11 @@ arm_load_pic_register (unsigned long saved_regs ATTRIBUTE_UNUSED)\n \t     able to find a work register.  */\n \t  pic_tmp = gen_rtx_REG (SImode,\n \t\t\t\t thumb_find_work_register (saved_regs));\n-\t  emit_insn (gen_pic_load_addr_thumb (pic_tmp, pic_rtx));\n+\t  emit_insn (gen_pic_load_addr_thumb1 (pic_tmp, pic_rtx));\n \t  emit_insn (gen_movsi (pic_offset_table_rtx, pic_tmp));\n \t}\n       else\n-\temit_insn (gen_pic_load_addr_thumb (cfun->machine->pic_reg, pic_rtx));\n+\temit_insn (gen_pic_load_addr_thumb1 (cfun->machine->pic_reg, pic_rtx));\n       emit_insn (gen_pic_add_dot_plus_four (cfun->machine->pic_reg,\n \t\t\t\t\t    cfun->machine->pic_reg, labelno));\n     }\n@@ -3591,6 +3729,80 @@ arm_legitimate_address_p (enum machine_mode mode, rtx x, RTX_CODE outer,\n   return 0;\n }\n \n+/* Return nonzero if X is a valid Thumb-2 address operand.  */\n+int\n+thumb2_legitimate_address_p (enum machine_mode mode, rtx x, int strict_p)\n+{\n+  bool use_ldrd;\n+  enum rtx_code code = GET_CODE (x);\n+  \n+  if (arm_address_register_rtx_p (x, strict_p))\n+    return 1;\n+\n+  use_ldrd = (TARGET_LDRD\n+\t      && (mode == DImode\n+\t\t  || (mode == DFmode && (TARGET_SOFT_FLOAT || TARGET_VFP))));\n+\n+  if (code == POST_INC || code == PRE_DEC\n+      || ((code == PRE_INC || code == POST_DEC)\n+\t  && (use_ldrd || GET_MODE_SIZE (mode) <= 4)))\n+    return arm_address_register_rtx_p (XEXP (x, 0), strict_p);\n+\n+  else if ((code == POST_MODIFY || code == PRE_MODIFY)\n+\t   && arm_address_register_rtx_p (XEXP (x, 0), strict_p)\n+\t   && GET_CODE (XEXP (x, 1)) == PLUS\n+\t   && rtx_equal_p (XEXP (XEXP (x, 1), 0), XEXP (x, 0)))\n+    {\n+      /* Thumb-2 only has autoincrement by constant.  */\n+      rtx addend = XEXP (XEXP (x, 1), 1);\n+      HOST_WIDE_INT offset;\n+\n+      if (GET_CODE (addend) != CONST_INT)\n+\treturn 0;\n+\n+      offset = INTVAL(addend);\n+      if (GET_MODE_SIZE (mode) <= 4)\n+\treturn (offset > -256 && offset < 256);\n+      \n+      return (use_ldrd && offset > -1024 && offset < 1024\n+\t      && (offset & 3) == 0);\n+    }\n+\n+  /* After reload constants split into minipools will have addresses\n+     from a LABEL_REF.  */\n+  else if (reload_completed\n+\t   && (code == LABEL_REF\n+\t       || (code == CONST\n+\t\t   && GET_CODE (XEXP (x, 0)) == PLUS\n+\t\t   && GET_CODE (XEXP (XEXP (x, 0), 0)) == LABEL_REF\n+\t\t   && GET_CODE (XEXP (XEXP (x, 0), 1)) == CONST_INT)))\n+    return 1;\n+\n+  else if (mode == TImode)\n+    return 0;\n+\n+  else if (code == PLUS)\n+    {\n+      rtx xop0 = XEXP (x, 0);\n+      rtx xop1 = XEXP (x, 1);\n+\n+      return ((arm_address_register_rtx_p (xop0, strict_p)\n+\t       && thumb2_legitimate_index_p (mode, xop1, strict_p))\n+\t      || (arm_address_register_rtx_p (xop1, strict_p)\n+\t\t  && thumb2_legitimate_index_p (mode, xop0, strict_p)));\n+    }\n+\n+  else if (GET_MODE_CLASS (mode) != MODE_FLOAT\n+\t   && code == SYMBOL_REF\n+\t   && CONSTANT_POOL_ADDRESS_P (x)\n+\t   && ! (flag_pic\n+\t\t && symbol_mentioned_p (get_pool_constant (x))\n+\t\t && ! pcrel_constant_p (get_pool_constant (x))))\n+    return 1;\n+\n+  return 0;\n+}\n+\n /* Return nonzero if INDEX is valid for an address index operand in\n    ARM state.  */\n static int\n@@ -3678,9 +3890,87 @@ arm_legitimate_index_p (enum machine_mode mode, rtx index, RTX_CODE outer,\n \t  && INTVAL (index) > -range);\n }\n \n-/* Return nonzero if X is valid as a Thumb state base register.  */\n+/* Return true if OP is a valid index scaling factor for Thumb-2 address\n+   index operand.  i.e. 1, 2, 4 or 8.  */\n+static bool\n+thumb2_index_mul_operand (rtx op)\n+{\n+  HOST_WIDE_INT val;\n+  \n+  if (GET_CODE(op) != CONST_INT)\n+    return false;\n+\n+  val = INTVAL(op);\n+  return (val == 1 || val == 2 || val == 4 || val == 8);\n+}\n+  \n+/* Return nonzero if INDEX is a valid Thumb-2 address index operand.  */\n+static int\n+thumb2_legitimate_index_p (enum machine_mode mode, rtx index, int strict_p)\n+{\n+  enum rtx_code code = GET_CODE (index);\n+\n+  /* ??? Combine arm and thumb2 coprocessor addressing modes.  */\n+  /* Standard coprocessor addressing modes.  */\n+  if (TARGET_HARD_FLOAT\n+      && (TARGET_FPA || TARGET_MAVERICK)\n+      && (GET_MODE_CLASS (mode) == MODE_FLOAT\n+\t  || (TARGET_MAVERICK && mode == DImode)))\n+    return (code == CONST_INT && INTVAL (index) < 1024\n+\t    && INTVAL (index) > -1024\n+\t    && (INTVAL (index) & 3) == 0);\n+\n+  if (TARGET_REALLY_IWMMXT && VALID_IWMMXT_REG_MODE (mode))\n+    return (code == CONST_INT\n+\t    && INTVAL (index) < 1024\n+\t    && INTVAL (index) > -1024\n+\t    && (INTVAL (index) & 3) == 0);\n+\n+  if (arm_address_register_rtx_p (index, strict_p)\n+      && (GET_MODE_SIZE (mode) <= 4))\n+    return 1;\n+\n+  if (mode == DImode || mode == DFmode)\n+    {\n+      HOST_WIDE_INT val = INTVAL (index);\n+      /* ??? Can we assume ldrd for thumb2?  */\n+      /* Thumb-2 ldrd only has reg+const addressing modes.  */\n+      if (code != CONST_INT)\n+\treturn 0;\n+\n+      /* ldrd supports offsets of +-1020.\n+         However the ldr fallback does not.  */\n+      return val > -256 && val < 256 && (val & 3) == 0;\n+    }\n+\n+  if (code == MULT)\n+    {\n+      rtx xiop0 = XEXP (index, 0);\n+      rtx xiop1 = XEXP (index, 1);\n+\n+      return ((arm_address_register_rtx_p (xiop0, strict_p)\n+\t       && thumb2_index_mul_operand (xiop1))\n+\t      || (arm_address_register_rtx_p (xiop1, strict_p)\n+\t\t  && thumb2_index_mul_operand (xiop0)));\n+    }\n+  else if (code == ASHIFT)\n+    {\n+      rtx op = XEXP (index, 1);\n+\n+      return (arm_address_register_rtx_p (XEXP (index, 0), strict_p)\n+\t      && GET_CODE (op) == CONST_INT\n+\t      && INTVAL (op) > 0\n+\t      && INTVAL (op) <= 3);\n+    }\n+\n+  return (code == CONST_INT\n+\t  && INTVAL (index) < 4096\n+\t  && INTVAL (index) > -256);\n+}\n+\n+/* Return nonzero if X is valid as a 16-bit Thumb state base register.  */\n static int\n-thumb_base_register_rtx_p (rtx x, enum machine_mode mode, int strict_p)\n+thumb1_base_register_rtx_p (rtx x, enum machine_mode mode, int strict_p)\n {\n   int regno;\n \n@@ -3690,7 +3980,7 @@ thumb_base_register_rtx_p (rtx x, enum machine_mode mode, int strict_p)\n   regno = REGNO (x);\n \n   if (strict_p)\n-    return THUMB_REGNO_MODE_OK_FOR_BASE_P (regno, mode);\n+    return THUMB1_REGNO_MODE_OK_FOR_BASE_P (regno, mode);\n \n   return (regno <= LAST_LO_REGNUM\n \t  || regno > LAST_VIRTUAL_REGISTER\n@@ -3705,12 +3995,12 @@ thumb_base_register_rtx_p (rtx x, enum machine_mode mode, int strict_p)\n /* Return nonzero if x is a legitimate index register.  This is the case\n    for any base register that can access a QImode object.  */\n inline static int\n-thumb_index_register_rtx_p (rtx x, int strict_p)\n+thumb1_index_register_rtx_p (rtx x, int strict_p)\n {\n-  return thumb_base_register_rtx_p (x, QImode, strict_p);\n+  return thumb1_base_register_rtx_p (x, QImode, strict_p);\n }\n \n-/* Return nonzero if x is a legitimate Thumb-state address.\n+/* Return nonzero if x is a legitimate 16-bit Thumb-state address.\n \n    The AP may be eliminated to either the SP or the FP, so we use the\n    least common denominator, e.g. SImode, and offsets from 0 to 64.\n@@ -3728,7 +4018,7 @@ thumb_index_register_rtx_p (rtx x, int strict_p)\n    reload pass starts.  This is so that eliminating such addresses\n    into stack based ones won't produce impossible code.  */\n int\n-thumb_legitimate_address_p (enum machine_mode mode, rtx x, int strict_p)\n+thumb1_legitimate_address_p (enum machine_mode mode, rtx x, int strict_p)\n {\n   /* ??? Not clear if this is right.  Experiment.  */\n   if (GET_MODE_SIZE (mode) < 4\n@@ -3742,7 +4032,7 @@ thumb_legitimate_address_p (enum machine_mode mode, rtx x, int strict_p)\n     return 0;\n \n   /* Accept any base register.  SP only in SImode or larger.  */\n-  else if (thumb_base_register_rtx_p (x, mode, strict_p))\n+  else if (thumb1_base_register_rtx_p (x, mode, strict_p))\n     return 1;\n \n   /* This is PC relative data before arm_reorg runs.  */\n@@ -3762,7 +4052,7 @@ thumb_legitimate_address_p (enum machine_mode mode, rtx x, int strict_p)\n \n   /* Post-inc indexing only supported for SImode and larger.  */\n   else if (GET_CODE (x) == POST_INC && GET_MODE_SIZE (mode) >= 4\n-\t   && thumb_index_register_rtx_p (XEXP (x, 0), strict_p))\n+\t   && thumb1_index_register_rtx_p (XEXP (x, 0), strict_p))\n     return 1;\n \n   else if (GET_CODE (x) == PLUS)\n@@ -3774,12 +4064,12 @@ thumb_legitimate_address_p (enum machine_mode mode, rtx x, int strict_p)\n       if (GET_MODE_SIZE (mode) <= 4\n \t  && XEXP (x, 0) != frame_pointer_rtx\n \t  && XEXP (x, 1) != frame_pointer_rtx\n-\t  && thumb_index_register_rtx_p (XEXP (x, 0), strict_p)\n-\t  && thumb_index_register_rtx_p (XEXP (x, 1), strict_p))\n+\t  && thumb1_index_register_rtx_p (XEXP (x, 0), strict_p)\n+\t  && thumb1_index_register_rtx_p (XEXP (x, 1), strict_p))\n \treturn 1;\n \n       /* REG+const has 5-7 bit offset for non-SP registers.  */\n-      else if ((thumb_index_register_rtx_p (XEXP (x, 0), strict_p)\n+      else if ((thumb1_index_register_rtx_p (XEXP (x, 0), strict_p)\n \t\t|| XEXP (x, 0) == arg_pointer_rtx)\n \t       && GET_CODE (XEXP (x, 1)) == CONST_INT\n \t       && thumb_legitimate_offset_p (mode, INTVAL (XEXP (x, 1))))\n@@ -3914,7 +4204,16 @@ arm_call_tls_get_addr (rtx x, rtx reg, rtx *valuep, int reloc)\n \n   if (TARGET_ARM)\n     emit_insn (gen_pic_add_dot_plus_eight (reg, reg, labelno));\n-  else\n+  else if (TARGET_THUMB2)\n+    {\n+      rtx tmp;\n+      /* Thumb-2 only allows very limited access to the PC.  Calculate\n+\t the address in a temporary register.  */\n+      tmp = gen_reg_rtx (SImode);\n+      emit_insn (gen_pic_load_dot_plus_four (tmp, labelno));\n+      emit_insn (gen_addsi3(reg, reg, tmp));\n+    }\n+  else /* TARGET_THUMB1 */\n     emit_insn (gen_pic_add_dot_plus_four (reg, reg, labelno));\n \n   *valuep = emit_library_call_value (get_tls_get_addr (), NULL_RTX, LCT_PURE, /* LCT_CONST?  */\n@@ -3968,6 +4267,16 @@ legitimize_tls_address (rtx x, rtx reg)\n \n       if (TARGET_ARM)\n \temit_insn (gen_tls_load_dot_plus_eight (reg, reg, labelno));\n+      else if (TARGET_THUMB2)\n+\t{\n+\t  rtx tmp;\n+\t  /* Thumb-2 only allows very limited access to the PC.  Calculate\n+\t     the address in a temporary register.  */\n+\t  tmp = gen_reg_rtx (SImode);\n+\t  emit_insn (gen_pic_load_dot_plus_four (tmp, labelno));\n+\t  emit_insn (gen_addsi3(reg, reg, tmp));\n+\t  emit_move_insn (reg, gen_const_mem (SImode, reg));\n+\t}\n       else\n \t{\n \t  emit_insn (gen_pic_add_dot_plus_four (reg, reg, labelno));\n@@ -4275,7 +4584,7 @@ arm_tls_referenced_p (rtx x)\n #define COSTS_N_INSNS(N) ((N) * 4 - 2)\n #endif\n static inline int\n-thumb_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer)\n+thumb1_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer)\n {\n   enum machine_mode mode = GET_MODE (x);\n \n@@ -4393,6 +4702,7 @@ thumb_rtx_costs (rtx x, enum rtx_code code, enum rtx_code outer)\n \n \n /* Worker routine for arm_rtx_costs.  */\n+/* ??? This needs updating for thumb2.  */\n static inline int\n arm_rtx_costs_1 (rtx x, enum rtx_code code, enum rtx_code outer)\n {\n@@ -4574,6 +4884,7 @@ arm_rtx_costs_1 (rtx x, enum rtx_code code, enum rtx_code outer)\n       return 4 + (mode == DImode ? 4 : 0);\n \n     case SIGN_EXTEND:\n+      /* ??? value extensions are cheaper on armv6. */\n       if (GET_MODE (XEXP (x, 0)) == QImode)\n \treturn (4 + (mode == DImode ? 4 : 0)\n \t\t+ (GET_CODE (XEXP (x, 0)) == MEM ? 10 : 0));\n@@ -4644,7 +4955,7 @@ arm_size_rtx_costs (rtx x, int code, int outer_code, int *total)\n   if (TARGET_THUMB)\n     {\n       /* XXX TBD.  For now, use the standard costs.  */\n-      *total = thumb_rtx_costs (x, code, outer_code);\n+      *total = thumb1_rtx_costs (x, code, outer_code);\n       return true;\n     }\n \n@@ -4856,7 +5167,8 @@ arm_size_rtx_costs (rtx x, int code, int outer_code, int *total)\n     }\n }\n \n-/* RTX costs for cores with a slow MUL implementation.  */\n+/* RTX costs for cores with a slow MUL implementation.  Thumb-2 is not\n+   supported on any \"slowmul\" cores, so it can be ignored.  */\n \n static bool\n arm_slowmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n@@ -4865,7 +5177,7 @@ arm_slowmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n \n   if (TARGET_THUMB)\n     {\n-      *total = thumb_rtx_costs (x, code, outer_code);\n+      *total = thumb1_rtx_costs (x, code, outer_code);\n       return true;\n     }\n \n@@ -4917,12 +5229,13 @@ arm_fastmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n {\n   enum machine_mode mode = GET_MODE (x);\n \n-  if (TARGET_THUMB)\n+  if (TARGET_THUMB1)\n     {\n-      *total = thumb_rtx_costs (x, code, outer_code);\n+      *total = thumb1_rtx_costs (x, code, outer_code);\n       return true;\n     }\n \n+  /* ??? should thumb2 use different costs?  */\n   switch (code)\n     {\n     case MULT:\n@@ -4976,7 +5289,8 @@ arm_fastmul_rtx_costs (rtx x, int code, int outer_code, int *total)\n }\n \n \n-/* RTX cost for XScale CPUs.  */\n+/* RTX cost for XScale CPUs.  Thumb-2 is not supported on any xscale cores,\n+   so it can be ignored.  */\n \n static bool\n arm_xscale_rtx_costs (rtx x, int code, int outer_code, int *total)\n@@ -4985,7 +5299,7 @@ arm_xscale_rtx_costs (rtx x, int code, int outer_code, int *total)\n \n   if (TARGET_THUMB)\n     {\n-      *total = thumb_rtx_costs (x, code, outer_code);\n+      *total = thumb1_rtx_costs (x, code, outer_code);\n       return true;\n     }\n \n@@ -5066,7 +5380,7 @@ arm_9e_rtx_costs (rtx x, int code, int outer_code, int *total)\n   int nonreg_cost;\n   int cost;\n \n-  if (TARGET_THUMB)\n+  if (TARGET_THUMB1)\n     {\n       switch (code)\n \t{\n@@ -5075,7 +5389,7 @@ arm_9e_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t  return true;\n \n \tdefault:\n-\t  *total = thumb_rtx_costs (x, code, outer_code);\n+\t  *total = thumb1_rtx_costs (x, code, outer_code);\n \t  return true;\n \t}\n     }\n@@ -5167,7 +5481,7 @@ arm_thumb_address_cost (rtx x)\n static int\n arm_address_cost (rtx x)\n {\n-  return TARGET_ARM ? arm_arm_address_cost (x) : arm_thumb_address_cost (x);\n+  return TARGET_32BIT ? arm_arm_address_cost (x) : arm_thumb_address_cost (x);\n }\n \n static int\n@@ -5360,7 +5674,9 @@ cirrus_memory_offset (rtx op)\n }\n \n /* Return TRUE if OP is a valid coprocessor memory address pattern.\n-   WB if true if writeback address modes are allowed.  */\n+   WB is true if full writeback address modes are allowed and is false\n+   if limited writeback address modes (POST_INC and PRE_DEC) are\n+   allowed.  */\n \n int\n arm_coproc_mem_operand (rtx op, bool wb)\n@@ -5395,12 +5711,15 @@ arm_coproc_mem_operand (rtx op, bool wb)\n   if (GET_CODE (ind) == REG)\n     return arm_address_register_rtx_p (ind, 0);\n \n-  /* Autoincremment addressing modes.  */\n-  if (wb\n-      && (GET_CODE (ind) == PRE_INC\n-\t  || GET_CODE (ind) == POST_INC\n-\t  || GET_CODE (ind) == PRE_DEC\n-\t  || GET_CODE (ind) == POST_DEC))\n+  /* Autoincremment addressing modes.  POST_INC and PRE_DEC are\n+     acceptable in any case (subject to verification by\n+     arm_address_register_rtx_p).  We need WB to be true to accept\n+     PRE_INC and POST_DEC.  */\n+  if (GET_CODE (ind) == POST_INC\n+      || GET_CODE (ind) == PRE_DEC\n+      || (wb\n+\t  && (GET_CODE (ind) == PRE_INC\n+\t      || GET_CODE (ind) == POST_DEC)))\n     return arm_address_register_rtx_p (XEXP (ind, 0), 0);\n \n   if (wb\n@@ -5948,10 +6267,10 @@ load_multiple_sequence (rtx *operands, int nops, int *regs, int *base,\n   if (unsorted_offsets[order[0]] == 0)\n     return 1; /* ldmia */\n \n-  if (unsorted_offsets[order[0]] == 4)\n+  if (TARGET_ARM && unsorted_offsets[order[0]] == 4)\n     return 2; /* ldmib */\n \n-  if (unsorted_offsets[order[nops - 1]] == 0)\n+  if (TARGET_ARM && unsorted_offsets[order[nops - 1]] == 0)\n     return 3; /* ldmda */\n \n   if (unsorted_offsets[order[nops - 1]] == -4)\n@@ -6007,19 +6326,19 @@ emit_ldm_seq (rtx *operands, int nops)\n   switch (load_multiple_sequence (operands, nops, regs, &base_reg, &offset))\n     {\n     case 1:\n-      strcpy (buf, \"ldm%?ia\\t\");\n+      strcpy (buf, \"ldm%(ia%)\\t\");\n       break;\n \n     case 2:\n-      strcpy (buf, \"ldm%?ib\\t\");\n+      strcpy (buf, \"ldm%(ib%)\\t\");\n       break;\n \n     case 3:\n-      strcpy (buf, \"ldm%?da\\t\");\n+      strcpy (buf, \"ldm%(da%)\\t\");\n       break;\n \n     case 4:\n-      strcpy (buf, \"ldm%?db\\t\");\n+      strcpy (buf, \"ldm%(db%)\\t\");\n       break;\n \n     case 5:\n@@ -6033,7 +6352,7 @@ emit_ldm_seq (rtx *operands, int nops)\n \t\t (long) -offset);\n       output_asm_insn (buf, operands);\n       base_reg = regs[0];\n-      strcpy (buf, \"ldm%?ia\\t\");\n+      strcpy (buf, \"ldm%(ia%)\\t\");\n       break;\n \n     default:\n@@ -6196,19 +6515,19 @@ emit_stm_seq (rtx *operands, int nops)\n   switch (store_multiple_sequence (operands, nops, regs, &base_reg, &offset))\n     {\n     case 1:\n-      strcpy (buf, \"stm%?ia\\t\");\n+      strcpy (buf, \"stm%(ia%)\\t\");\n       break;\n \n     case 2:\n-      strcpy (buf, \"stm%?ib\\t\");\n+      strcpy (buf, \"stm%(ib%)\\t\");\n       break;\n \n     case 3:\n-      strcpy (buf, \"stm%?da\\t\");\n+      strcpy (buf, \"stm%(da%)\\t\");\n       break;\n \n     case 4:\n-      strcpy (buf, \"stm%?db\\t\");\n+      strcpy (buf, \"stm%(db%)\\t\");\n       break;\n \n     default:\n@@ -6769,7 +7088,7 @@ arm_select_cc_mode (enum rtx_code op, rtx x, rtx y)\n   /* An operation (on Thumb) where we want to test for a single bit.\n      This is done by shifting that bit up into the top bit of a\n      scratch register; we can then branch on the sign bit.  */\n-  if (TARGET_THUMB\n+  if (TARGET_THUMB1\n       && GET_MODE (x) == SImode\n       && (op == EQ || op == NE)\n       && GET_CODE (x) == ZERO_EXTRACT\n@@ -6780,6 +7099,7 @@ arm_select_cc_mode (enum rtx_code op, rtx x, rtx y)\n      V flag is not set correctly, so we can only use comparisons where\n      this doesn't matter.  (For LT and GE we can use \"mi\" and \"pl\"\n      instead.)  */\n+  /* ??? Does the ZERO_EXTRACT case really apply to thumb2?  */\n   if (GET_MODE (x) == SImode\n       && y == const0_rtx\n       && (op == EQ || op == NE || op == LT || op == GE)\n@@ -6790,7 +7110,7 @@ arm_select_cc_mode (enum rtx_code op, rtx x, rtx y)\n \t  || GET_CODE (x) == LSHIFTRT\n \t  || GET_CODE (x) == ASHIFT || GET_CODE (x) == ASHIFTRT\n \t  || GET_CODE (x) == ROTATERT\n-\t  || (TARGET_ARM && GET_CODE (x) == ZERO_EXTRACT)))\n+\t  || (TARGET_32BIT && GET_CODE (x) == ZERO_EXTRACT)))\n     return CC_NOOVmode;\n \n   if (GET_MODE (x) == QImode && (op == EQ || op == NE))\n@@ -7373,8 +7693,29 @@ get_jump_table_size (rtx insn)\n     {\n       rtx body = PATTERN (insn);\n       int elt = GET_CODE (body) == ADDR_DIFF_VEC ? 1 : 0;\n+      HOST_WIDE_INT size;\n+      HOST_WIDE_INT modesize;\n \n-      return GET_MODE_SIZE (GET_MODE (body)) * XVECLEN (body, elt);\n+      modesize = GET_MODE_SIZE (GET_MODE (body));\n+      size = modesize * XVECLEN (body, elt);\n+      switch (modesize)\n+\t{\n+\tcase 1:\n+\t  /* Round up size  of TBB table to a hafword boundary.  */\n+\t  size = (size + 1) & ~(HOST_WIDE_INT)1;\n+\t  break;\n+\tcase 2:\n+\t  /* No padding neccessary for TBH.  */\n+\t  break;\n+\tcase 4:\n+\t  /* Add two bytes for alignment on Thumb.  */\n+\t  if (TARGET_THUMB)\n+\t    size += 2;\n+\t  break;\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+      return size;\n     }\n \n   return 0;\n@@ -8409,7 +8750,7 @@ print_multi_reg (FILE *stream, const char *instr, unsigned reg,\n \n   fputc ('\\t', stream);\n   asm_fprintf (stream, instr, reg);\n-  fputs (\", {\", stream);\n+  fputc ('{', stream);\n \n   for (i = 0; i <= LAST_ARM_REGNUM; i++)\n     if (mask & (1 << i))\n@@ -8634,7 +8975,7 @@ output_mov_long_double_fpa_from_arm (rtx *operands)\n   ops[1] = gen_rtx_REG (SImode, 1 + arm_reg0);\n   ops[2] = gen_rtx_REG (SImode, 2 + arm_reg0);\n \n-  output_asm_insn (\"stm%?fd\\t%|sp!, {%0, %1, %2}\", ops);\n+  output_asm_insn (\"stm%(fd%)\\t%|sp!, {%0, %1, %2}\", ops);\n   output_asm_insn (\"ldf%?e\\t%0, [%|sp], #12\", operands);\n \n   return \"\";\n@@ -8656,7 +8997,7 @@ output_mov_long_double_arm_from_fpa (rtx *operands)\n   ops[2] = gen_rtx_REG (SImode, 2 + arm_reg0);\n \n   output_asm_insn (\"stf%?e\\t%1, [%|sp, #-12]!\", operands);\n-  output_asm_insn (\"ldm%?fd\\t%|sp!, {%0, %1, %2}\", ops);\n+  output_asm_insn (\"ldm%(fd%)\\t%|sp!, {%0, %1, %2}\", ops);\n   return \"\";\n }\n \n@@ -8708,7 +9049,7 @@ output_mov_double_fpa_from_arm (rtx *operands)\n \n   ops[0] = gen_rtx_REG (SImode, arm_reg0);\n   ops[1] = gen_rtx_REG (SImode, 1 + arm_reg0);\n-  output_asm_insn (\"stm%?fd\\t%|sp!, {%0, %1}\", ops);\n+  output_asm_insn (\"stm%(fd%)\\t%|sp!, {%0, %1}\", ops);\n   output_asm_insn (\"ldf%?d\\t%0, [%|sp], #8\", operands);\n   return \"\";\n }\n@@ -8727,7 +9068,7 @@ output_mov_double_arm_from_fpa (rtx *operands)\n   ops[0] = gen_rtx_REG (SImode, arm_reg0);\n   ops[1] = gen_rtx_REG (SImode, 1 + arm_reg0);\n   output_asm_insn (\"stf%?d\\t%1, [%|sp, #-8]!\", operands);\n-  output_asm_insn (\"ldm%?fd\\t%|sp!, {%0, %1}\", ops);\n+  output_asm_insn (\"ldm%(fd%)\\t%|sp!, {%0, %1}\", ops);\n   return \"\";\n }\n \n@@ -8752,25 +9093,28 @@ output_move_double (rtx *operands)\n       switch (GET_CODE (XEXP (operands[1], 0)))\n \t{\n \tcase REG:\n-\t  output_asm_insn (\"ldm%?ia\\t%m1, %M0\", operands);\n+\t  output_asm_insn (\"ldm%(ia%)\\t%m1, %M0\", operands);\n \t  break;\n \n \tcase PRE_INC:\n \t  gcc_assert (TARGET_LDRD);\n-\t  output_asm_insn (\"ldr%?d\\t%0, [%m1, #8]!\", operands);\n+\t  output_asm_insn (\"ldr%(d%)\\t%0, [%m1, #8]!\", operands);\n \t  break;\n \n \tcase PRE_DEC:\n-\t  output_asm_insn (\"ldm%?db\\t%m1!, %M0\", operands);\n+\t  if (TARGET_LDRD)\n+\t    output_asm_insn (\"ldr%(d%)\\t%0, [%m1, #-8]!\", operands);\n+\t  else\n+\t    output_asm_insn (\"ldm%(db%)\\t%m1!, %M0\", operands);\n \t  break;\n \n \tcase POST_INC:\n-\t  output_asm_insn (\"ldm%?ia\\t%m1!, %M0\", operands);\n+\t  output_asm_insn (\"ldm%(ia%)\\t%m1!, %M0\", operands);\n \t  break;\n \n \tcase POST_DEC:\n \t  gcc_assert (TARGET_LDRD);\n-\t  output_asm_insn (\"ldr%?d\\t%0, [%m1], #-8\", operands);\n+\t  output_asm_insn (\"ldr%(d%)\\t%0, [%m1], #-8\", operands);\n \t  break;\n \n \tcase PRE_MODIFY:\n@@ -8785,24 +9129,25 @@ output_move_double (rtx *operands)\n \t\t{\n \t\t  /* Registers overlap so split out the increment.  */\n \t\t  output_asm_insn (\"add%?\\t%1, %1, %2\", otherops);\n-\t\t  output_asm_insn (\"ldr%?d\\t%0, [%1] @split\", otherops);\n+\t\t  output_asm_insn (\"ldr%(d%)\\t%0, [%1] @split\", otherops);\n \t\t}\n \t      else\n-\t\toutput_asm_insn (\"ldr%?d\\t%0, [%1, %2]!\", otherops);\n+\t\toutput_asm_insn (\"ldr%(d%)\\t%0, [%1, %2]!\", otherops);\n \t    }\n \t  else\n \t    {\n \t      /* We only allow constant increments, so this is safe.  */\n-\t      output_asm_insn (\"ldr%?d\\t%0, [%1], %2\", otherops);\n+\t      output_asm_insn (\"ldr%(d%)\\t%0, [%1], %2\", otherops);\n \t    }\n \t  break;\n \n \tcase LABEL_REF:\n \tcase CONST:\n \t  output_asm_insn (\"adr%?\\t%0, %1\", operands);\n-\t  output_asm_insn (\"ldm%?ia\\t%0, %M0\", operands);\n+\t  output_asm_insn (\"ldm%(ia%)\\t%0, %M0\", operands);\n \t  break;\n \n+\t  /* ??? This needs checking for thumb2.  */\n \tdefault:\n \t  if (arm_add_operand (XEXP (XEXP (operands[1], 0), 1),\n \t\t\t       GET_MODE (XEXP (XEXP (operands[1], 0), 1))))\n@@ -8818,13 +9163,17 @@ output_move_double (rtx *operands)\n \t\t      switch ((int) INTVAL (otherops[2]))\n \t\t\t{\n \t\t\tcase -8:\n-\t\t\t  output_asm_insn (\"ldm%?db\\t%1, %M0\", otherops);\n+\t\t\t  output_asm_insn (\"ldm%(db%)\\t%1, %M0\", otherops);\n \t\t\t  return \"\";\n \t\t\tcase -4:\n-\t\t\t  output_asm_insn (\"ldm%?da\\t%1, %M0\", otherops);\n+\t\t\t  if (TARGET_THUMB2)\n+\t\t\t    break;\n+\t\t\t  output_asm_insn (\"ldm%(da%)\\t%1, %M0\", otherops);\n \t\t\t  return \"\";\n \t\t\tcase 4:\n-\t\t\t  output_asm_insn (\"ldm%?ib\\t%1, %M0\", otherops);\n+\t\t\t  if (TARGET_THUMB2)\n+\t\t\t    break;\n+\t\t\t  output_asm_insn (\"ldm%(ib%)\\t%1, %M0\", otherops);\n \t\t\t  return \"\";\n \t\t\t}\n \t\t    }\n@@ -8847,11 +9196,11 @@ output_move_double (rtx *operands)\n \t\t      if (reg_overlap_mentioned_p (otherops[0], otherops[2]))\n \t\t\t{\n \t\t\t  output_asm_insn (\"add%?\\t%1, %1, %2\", otherops);\n-\t\t\t  output_asm_insn (\"ldr%?d\\t%0, [%1]\",\n+\t\t\t  output_asm_insn (\"ldr%(d%)\\t%0, [%1]\",\n \t\t\t\t\t   otherops);\n \t\t\t}\n \t\t      else\n-\t\t\toutput_asm_insn (\"ldr%?d\\t%0, [%1, %2]\", otherops);\n+\t\t\toutput_asm_insn (\"ldr%(d%)\\t%0, [%1, %2]\", otherops);\n \t\t      return \"\";\n \t\t    }\n \n@@ -8868,7 +9217,7 @@ output_move_double (rtx *operands)\n \t      else\n \t\toutput_asm_insn (\"sub%?\\t%0, %1, %2\", otherops);\n \n-\t      return \"ldm%?ia\\t%0, %M0\";\n+\t      return \"ldm%(ia%)\\t%0, %M0\";\n \t    }\n \t  else\n \t    {\n@@ -8896,25 +9245,28 @@ output_move_double (rtx *operands)\n       switch (GET_CODE (XEXP (operands[0], 0)))\n         {\n \tcase REG:\n-\t  output_asm_insn (\"stm%?ia\\t%m0, %M1\", operands);\n+\t  output_asm_insn (\"stm%(ia%)\\t%m0, %M1\", operands);\n \t  break;\n \n         case PRE_INC:\n \t  gcc_assert (TARGET_LDRD);\n-\t  output_asm_insn (\"str%?d\\t%1, [%m0, #8]!\", operands);\n+\t  output_asm_insn (\"str%(d%)\\t%1, [%m0, #8]!\", operands);\n \t  break;\n \n         case PRE_DEC:\n-\t  output_asm_insn (\"stm%?db\\t%m0!, %M1\", operands);\n+\t  if (TARGET_LDRD)\n+\t    output_asm_insn (\"str%(d%)\\t%1, [%m0, #-8]!\", operands);\n+\t  else\n+\t    output_asm_insn (\"stm%(db%)\\t%m0!, %M1\", operands);\n \t  break;\n \n         case POST_INC:\n-\t  output_asm_insn (\"stm%?ia\\t%m0!, %M1\", operands);\n+\t  output_asm_insn (\"stm%(ia%)\\t%m0!, %M1\", operands);\n \t  break;\n \n         case POST_DEC:\n \t  gcc_assert (TARGET_LDRD);\n-\t  output_asm_insn (\"str%?d\\t%1, [%m0], #-8\", operands);\n+\t  output_asm_insn (\"str%(d%)\\t%1, [%m0], #-8\", operands);\n \t  break;\n \n \tcase PRE_MODIFY:\n@@ -8924,9 +9276,9 @@ output_move_double (rtx *operands)\n \t  otherops[2] = XEXP (XEXP (XEXP (operands[0], 0), 1), 1);\n \n \t  if (GET_CODE (XEXP (operands[0], 0)) == PRE_MODIFY)\n-\t    output_asm_insn (\"str%?d\\t%0, [%1, %2]!\", otherops);\n+\t    output_asm_insn (\"str%(d%)\\t%0, [%1, %2]!\", otherops);\n \t  else\n-\t    output_asm_insn (\"str%?d\\t%0, [%1], %2\", otherops);\n+\t    output_asm_insn (\"str%(d%)\\t%0, [%1], %2\", otherops);\n \t  break;\n \n \tcase PLUS:\n@@ -8936,15 +9288,19 @@ output_move_double (rtx *operands)\n \t      switch ((int) INTVAL (XEXP (XEXP (operands[0], 0), 1)))\n \t\t{\n \t\tcase -8:\n-\t\t  output_asm_insn (\"stm%?db\\t%m0, %M1\", operands);\n+\t\t  output_asm_insn (\"stm%(db%)\\t%m0, %M1\", operands);\n \t\t  return \"\";\n \n \t\tcase -4:\n-\t\t  output_asm_insn (\"stm%?da\\t%m0, %M1\", operands);\n+\t\t  if (TARGET_THUMB2)\n+\t\t    break;\n+\t\t  output_asm_insn (\"stm%(da%)\\t%m0, %M1\", operands);\n \t\t  return \"\";\n \n \t\tcase 4:\n-\t\t  output_asm_insn (\"stm%?ib\\t%m0, %M1\", operands);\n+\t\t  if (TARGET_THUMB2)\n+\t\t    break;\n+\t\t  output_asm_insn (\"stm%(ib%)\\t%m0, %M1\", operands);\n \t\t  return \"\";\n \t\t}\n \t    }\n@@ -8956,7 +9312,7 @@ output_move_double (rtx *operands)\n \t    {\n \t      otherops[0] = operands[1];\n \t      otherops[1] = XEXP (XEXP (operands[0], 0), 0);\n-\t      output_asm_insn (\"str%?d\\t%0, [%1, %2]\", otherops);\n+\t      output_asm_insn (\"str%(d%)\\t%0, [%1, %2]\", otherops);\n \t      return \"\";\n \t    }\n \t  /* Fall through */\n@@ -8972,6 +9328,62 @@ output_move_double (rtx *operands)\n   return \"\";\n }\n \n+/* Output a VFP load or store instruction.  */\n+\n+const char *\n+output_move_vfp (rtx *operands)\n+{\n+  rtx reg, mem, addr, ops[2];\n+  int load = REG_P (operands[0]);\n+  int dp = GET_MODE_SIZE (GET_MODE (operands[0])) == 8;\n+  int integer_p = GET_MODE_CLASS (GET_MODE (operands[0])) == MODE_INT;\n+  const char *template;\n+  char buff[50];\n+\n+  reg = operands[!load];\n+  mem = operands[load];\n+\n+  gcc_assert (REG_P (reg));\n+  gcc_assert (IS_VFP_REGNUM (REGNO (reg)));\n+  gcc_assert (GET_MODE (reg) == SFmode\n+\t      || GET_MODE (reg) == DFmode\n+\t      || GET_MODE (reg) == SImode\n+\t      || GET_MODE (reg) == DImode);\n+  gcc_assert (MEM_P (mem));\n+\n+  addr = XEXP (mem, 0);\n+\n+  switch (GET_CODE (addr))\n+    {\n+    case PRE_DEC:\n+      template = \"f%smdb%c%%?\\t%%0!, {%%%s1}%s\";\n+      ops[0] = XEXP (addr, 0);\n+      ops[1] = reg;\n+      break;\n+\n+    case POST_INC:\n+      template = \"f%smia%c%%?\\t%%0!, {%%%s1}%s\";\n+      ops[0] = XEXP (addr, 0);\n+      ops[1] = reg;\n+      break;\n+\n+    default:\n+      template = \"f%s%c%%?\\t%%%s0, %%1%s\";\n+      ops[0] = reg;\n+      ops[1] = mem;\n+      break;\n+    }\n+\n+  sprintf (buff, template,\n+\t   load ? \"ld\" : \"st\",\n+\t   dp ? 'd' : 's',\n+\t   dp ? \"P\" : \"\",\n+\t   integer_p ? \"\\t%@ int\" : \"\");\n+  output_asm_insn (buff, ops);\n+\n+  return \"\";\n+}\n+\n /* Output an ADD r, s, #n where n may be too big for one instruction.\n    If adding zero to one register, output nothing.  */\n const char *\n@@ -9035,6 +9447,29 @@ output_multi_immediate (rtx *operands, const char *instr1, const char *instr2,\n   return \"\";\n }\n \n+/* Return the name of a shifter operation.  */\n+static const char *\n+arm_shift_nmem(enum rtx_code code)\n+{\n+  switch (code)\n+    {\n+    case ASHIFT:\n+      return ARM_LSL_NAME;\n+\n+    case ASHIFTRT:\n+      return \"asr\";\n+\n+    case LSHIFTRT:\n+      return \"lsr\";\n+\n+    case ROTATERT:\n+      return \"ror\";\n+\n+    default:\n+      abort();\n+    }\n+}\n+\n /* Return the appropriate ARM instruction for the operation code.\n    The returned result should not be overwritten.  OP is the rtx of the\n    operation.  SHIFT_FIRST_ARG is TRUE if the first argument of the operator\n@@ -9059,6 +9494,12 @@ arithmetic_instr (rtx op, int shift_first_arg)\n     case AND:\n       return \"and\";\n \n+    case ASHIFT:\n+    case ASHIFTRT:\n+    case LSHIFTRT:\n+    case ROTATERT:\n+      return arm_shift_nmem(GET_CODE(op));\n+\n     default:\n       gcc_unreachable ();\n     }\n@@ -9092,34 +9533,26 @@ shift_op (rtx op, HOST_WIDE_INT *amountp)\n \n   switch (code)\n     {\n-    case ASHIFT:\n-      mnem = \"asl\";\n-      break;\n-\n-    case ASHIFTRT:\n-      mnem = \"asr\";\n-      break;\n-\n-    case LSHIFTRT:\n-      mnem = \"lsr\";\n-      break;\n-\n     case ROTATE:\n       gcc_assert (*amountp != -1);\n       *amountp = 32 - *amountp;\n+      code = ROTATERT;\n \n       /* Fall through.  */\n \n+    case ASHIFT:\n+    case ASHIFTRT:\n+    case LSHIFTRT:\n     case ROTATERT:\n-      mnem = \"ror\";\n+      mnem = arm_shift_nmem(code);\n       break;\n \n     case MULT:\n       /* We never have to worry about the amount being other than a\n \t power of 2, since this case can never be reloaded from a reg.  */\n       gcc_assert (*amountp != -1);\n       *amountp = int_log2 (*amountp);\n-      return \"asl\";\n+      return ARM_LSL_NAME;\n \n     default:\n       gcc_unreachable ();\n@@ -9129,7 +9562,7 @@ shift_op (rtx op, HOST_WIDE_INT *amountp)\n     {\n       /* This is not 100% correct, but follows from the desire to merge\n \t multiplication by a power of 2 with the recognizer for a\n-\t shift.  >=32 is not a valid shift for \"asl\", so we must try and\n+\t shift.  >=32 is not a valid shift for \"lsl\", so we must try and\n \t output a shift that produces the correct arithmetical result.\n \t Using lsr #32 is identical except for the fact that the carry bit\n \t is not set correctly if we set the flags; but we never use the\n@@ -9259,17 +9692,22 @@ arm_compute_save_reg0_reg12_mask (void)\n     }\n   else\n     {\n+      /* In arm mode we handle r11 (FP) as a special case.  */\n+      unsigned last_reg = TARGET_ARM ? 10 : 11;\n+      \n       /* In the normal case we only need to save those registers\n \t which are call saved and which are used by this function.  */\n-      for (reg = 0; reg <= 10; reg++)\n+      for (reg = 0; reg <= last_reg; reg++)\n \tif (regs_ever_live[reg] && ! call_used_regs [reg])\n \t  save_reg_mask |= (1 << reg);\n \n       /* Handle the frame pointer as a special case.  */\n-      if (! TARGET_APCS_FRAME\n-\t  && ! frame_pointer_needed\n-\t  && regs_ever_live[HARD_FRAME_POINTER_REGNUM]\n-\t  && ! call_used_regs[HARD_FRAME_POINTER_REGNUM])\n+      if (TARGET_THUMB2 && frame_pointer_needed)\n+\tsave_reg_mask |= 1 << HARD_FRAME_POINTER_REGNUM;\n+      else if (! TARGET_APCS_FRAME\n+\t       && ! frame_pointer_needed\n+\t       && regs_ever_live[HARD_FRAME_POINTER_REGNUM]\n+\t       && ! call_used_regs[HARD_FRAME_POINTER_REGNUM])\n \tsave_reg_mask |= 1 << HARD_FRAME_POINTER_REGNUM;\n \n       /* If we aren't loading the PIC register,\n@@ -9280,6 +9718,10 @@ arm_compute_save_reg0_reg12_mask (void)\n \t  && (regs_ever_live[PIC_OFFSET_TABLE_REGNUM]\n \t      || current_function_uses_pic_offset_table))\n \tsave_reg_mask |= 1 << PIC_OFFSET_TABLE_REGNUM;\n+\n+      /* The prologue will copy SP into R0, so save it.  */\n+      if (IS_STACKALIGN (func_type))\n+\tsave_reg_mask |= 1;\n     }\n \n   /* Save registers so the exception handler can modify them.  */\n@@ -9299,6 +9741,7 @@ arm_compute_save_reg0_reg12_mask (void)\n   return save_reg_mask;\n }\n \n+\n /* Compute a bit mask of which registers need to be\n    saved on the stack for the current function.  */\n \n@@ -9307,14 +9750,15 @@ arm_compute_save_reg_mask (void)\n {\n   unsigned int save_reg_mask = 0;\n   unsigned long func_type = arm_current_func_type ();\n+  unsigned int reg;\n \n   if (IS_NAKED (func_type))\n     /* This should never really happen.  */\n     return 0;\n \n   /* If we are creating a stack frame, then we must save the frame pointer,\n      IP (which will hold the old stack pointer), LR and the PC.  */\n-  if (frame_pointer_needed)\n+  if (frame_pointer_needed && TARGET_ARM)\n     save_reg_mask |=\n       (1 << ARM_HARD_FRAME_POINTER_REGNUM)\n       | (1 << IP_REGNUM)\n@@ -9351,8 +9795,6 @@ arm_compute_save_reg_mask (void)\n       && ((bit_count (save_reg_mask)\n \t   + ARM_NUM_INTS (current_function_pretend_args_size)) % 2) != 0)\n     {\n-      unsigned int reg;\n-\n       /* The total number of registers that are going to be pushed\n \t onto the stack is odd.  We need to ensure that the stack\n \t is 64-bit aligned before we start to save iWMMXt registers,\n@@ -9375,14 +9817,24 @@ arm_compute_save_reg_mask (void)\n \t}\n     }\n \n+  /* We may need to push an additional register for use initializing the\n+     PIC base register.  */\n+  if (TARGET_THUMB2 && IS_NESTED (func_type) && flag_pic\n+      && (save_reg_mask & THUMB2_WORK_REGS) == 0)\n+    {\n+      reg = thumb_find_work_register (1 << 4);\n+      if (!call_used_regs[reg])\n+\tsave_reg_mask |= (1 << reg);\n+    }\n+\n   return save_reg_mask;\n }\n \n \n /* Compute a bit mask of which registers need to be\n    saved on the stack for the current function.  */\n static unsigned long\n-thumb_compute_save_reg_mask (void)\n+thumb1_compute_save_reg_mask (void)\n {\n   unsigned long mask;\n   unsigned reg;\n@@ -9578,7 +10030,7 @@ output_return_instruction (rtx operand, int really_return, int reverse)\n \t      stack_adjust = offsets->outgoing_args - offsets->saved_regs;\n \t      gcc_assert (stack_adjust == 0 || stack_adjust == 4);\n \n-\t      if (stack_adjust && arm_arch5)\n+\t      if (stack_adjust && arm_arch5 && TARGET_ARM)\n \t\tsprintf (instr, \"ldm%sib\\t%%|sp, {\", conditional);\n \t      else\n \t\t{\n@@ -9643,6 +10095,7 @@ output_return_instruction (rtx operand, int really_return, int reverse)\n \t{\n \tcase ARM_FT_ISR:\n \tcase ARM_FT_FIQ:\n+\t  /* ??? This is wrong for unified assembly syntax.  */\n \t  sprintf (instr, \"sub%ss\\t%%|pc, %%|lr, #4\", conditional);\n \t  break;\n \n@@ -9651,6 +10104,7 @@ output_return_instruction (rtx operand, int really_return, int reverse)\n \t  break;\n \n \tcase ARM_FT_EXCEPTION:\n+\t  /* ??? This is wrong for unified assembly syntax.  */\n \t  sprintf (instr, \"mov%ss\\t%%|pc, %%|lr\", conditional);\n \t  break;\n \n@@ -9718,9 +10172,9 @@ arm_output_function_prologue (FILE *f, HOST_WIDE_INT frame_size)\n {\n   unsigned long func_type;\n \n-  if (!TARGET_ARM)\n+  if (TARGET_THUMB1)\n     {\n-      thumb_output_function_prologue (f, frame_size);\n+      thumb1_output_function_prologue (f, frame_size);\n       return;\n     }\n \n@@ -9756,6 +10210,8 @@ arm_output_function_prologue (FILE *f, HOST_WIDE_INT frame_size)\n \n   if (IS_NESTED (func_type))\n     asm_fprintf (f, \"\\t%@ Nested: function declared inside another function.\\n\");\n+  if (IS_STACKALIGN (func_type))\n+    asm_fprintf (f, \"\\t%@ Stack Align: May be called with mis-aligned SP.\\n\");\n \n   asm_fprintf (f, \"\\t%@ args = %d, pretend = %d, frame = %wd\\n\",\n \t       current_function_args_size,\n@@ -9834,7 +10290,7 @@ arm_output_epilogue (rtx sibling)\n     if (saved_regs_mask & (1 << reg))\n       floats_offset += 4;\n \n-  if (frame_pointer_needed)\n+  if (frame_pointer_needed && TARGET_ARM)\n     {\n       /* This variable is for the Virtual Frame Pointer, not VFP regs.  */\n       int vfp_offset = offsets->frame;\n@@ -9971,22 +10427,40 @@ arm_output_epilogue (rtx sibling)\n \t  || current_function_calls_alloca)\n \tasm_fprintf (f, \"\\tsub\\t%r, %r, #%d\\n\", SP_REGNUM, FP_REGNUM,\n \t\t     4 * bit_count (saved_regs_mask));\n-      print_multi_reg (f, \"ldmfd\\t%r\", SP_REGNUM, saved_regs_mask);\n+      print_multi_reg (f, \"ldmfd\\t%r, \", SP_REGNUM, saved_regs_mask);\n \n       if (IS_INTERRUPT (func_type))\n \t/* Interrupt handlers will have pushed the\n \t   IP onto the stack, so restore it now.  */\n-\tprint_multi_reg (f, \"ldmfd\\t%r!\", SP_REGNUM, 1 << IP_REGNUM);\n+\tprint_multi_reg (f, \"ldmfd\\t%r!, \", SP_REGNUM, 1 << IP_REGNUM);\n     }\n   else\n     {\n+      HOST_WIDE_INT amount;\n       /* Restore stack pointer if necessary.  */\n-      if (offsets->outgoing_args != offsets->saved_regs)\n+      if (frame_pointer_needed)\n \t{\n-\t  operands[0] = operands[1] = stack_pointer_rtx;\n-\t  operands[2] = GEN_INT (offsets->outgoing_args - offsets->saved_regs);\n+\t  /* For Thumb-2 restore sp from the frame pointer.\n+\t     Operand restrictions mean we have to incrememnt FP, then copy\n+\t     to SP.  */\n+\t  amount = offsets->locals_base - offsets->saved_regs;\n+\t  operands[0] = hard_frame_pointer_rtx;\n+\t}\n+      else\n+\t{\n+\t  operands[0] = stack_pointer_rtx;\n+\t  amount = offsets->outgoing_args - offsets->saved_regs;\n+\t}\n+\n+      if (amount)\n+\t{\n+\t  operands[1] = operands[0];\n+\t  operands[2] = GEN_INT (amount);\n \t  output_add_immediate (operands);\n \t}\n+      if (frame_pointer_needed)\n+\tasm_fprintf (f, \"\\tmov\\t%r, %r\\n\",\n+\t\t     SP_REGNUM, HARD_FRAME_POINTER_REGNUM);\n \n       if (arm_fpu_arch == FPUTYPE_FPA_EMU2)\n \t{\n@@ -10054,6 +10528,7 @@ arm_output_epilogue (rtx sibling)\n \n       /* If we can, restore the LR into the PC.  */\n       if (ARM_FUNC_TYPE (func_type) == ARM_FT_NORMAL\n+\t  && !IS_STACKALIGN (func_type)\n \t  && really_return\n \t  && current_function_pretend_args_size == 0\n \t  && saved_regs_mask & (1 << LR_REGNUM)\n@@ -10064,8 +10539,9 @@ arm_output_epilogue (rtx sibling)\n \t}\n \n       /* Load the registers off the stack.  If we only have one register\n-\t to load use the LDR instruction - it is faster.  */\n-      if (saved_regs_mask == (1 << LR_REGNUM))\n+\t to load use the LDR instruction - it is faster.  For Thumb-2\n+\t always use pop and the assembler will pick the best instruction.*/\n+      if (TARGET_ARM && saved_regs_mask == (1 << LR_REGNUM))\n \t{\n \t  asm_fprintf (f, \"\\tldr\\t%r, [%r], #4\\n\", LR_REGNUM, SP_REGNUM);\n \t}\n@@ -10076,9 +10552,11 @@ arm_output_epilogue (rtx sibling)\n \t       (i.e. \"ldmfd sp!...\").  We know that the stack pointer is\n \t       in the list of registers and if we add writeback the\n \t       instruction becomes UNPREDICTABLE.  */\n-\t    print_multi_reg (f, \"ldmfd\\t%r\", SP_REGNUM, saved_regs_mask);\n+\t    print_multi_reg (f, \"ldmfd\\t%r, \", SP_REGNUM, saved_regs_mask);\n+\t  else if (TARGET_ARM)\n+\t    print_multi_reg (f, \"ldmfd\\t%r!, \", SP_REGNUM, saved_regs_mask);\n \t  else\n-\t    print_multi_reg (f, \"ldmfd\\t%r!\", SP_REGNUM, saved_regs_mask);\n+\t    print_multi_reg (f, \"pop\\t\", SP_REGNUM, saved_regs_mask);\n \t}\n \n       if (current_function_pretend_args_size)\n@@ -10116,6 +10594,11 @@ arm_output_epilogue (rtx sibling)\n       break;\n \n     default:\n+      if (IS_STACKALIGN (func_type))\n+\t{\n+\t  /* See comment in arm_expand_prologue.  */\n+\t  asm_fprintf (f, \"\\tmov\\t%r, %r\\n\", SP_REGNUM, 0);\n+\t}\n       if (arm_arch5 || arm_arch4t)\n \tasm_fprintf (f, \"\\tbx\\t%r\\n\", LR_REGNUM);\n       else\n@@ -10132,7 +10615,7 @@ arm_output_function_epilogue (FILE *file ATTRIBUTE_UNUSED,\n {\n   arm_stack_offsets *offsets;\n \n-  if (TARGET_THUMB)\n+  if (TARGET_THUMB1)\n     {\n       int regno;\n \n@@ -10156,7 +10639,7 @@ arm_output_function_epilogue (FILE *file ATTRIBUTE_UNUSED,\n \t RTL for it.  This does not happen for inline functions.  */\n       return_used_this_function = 0;\n     }\n-  else\n+  else /* TARGET_32BIT */\n     {\n       /* We need to take into account any stack-frame rounding.  */\n       offsets = arm_get_frame_offsets ();\n@@ -10464,9 +10947,10 @@ arm_get_frame_offsets (void)\n   /* Space for variadic functions.  */\n   offsets->saved_args = current_function_pretend_args_size;\n \n+  /* In Thumb mode this is incorrect, but never used.  */\n   offsets->frame = offsets->saved_args + (frame_pointer_needed ? 4 : 0);\n \n-  if (TARGET_ARM)\n+  if (TARGET_32BIT)\n     {\n       unsigned int regno;\n \n@@ -10499,9 +10983,9 @@ arm_get_frame_offsets (void)\n \t    saved += arm_get_vfp_saved_size ();\n \t}\n     }\n-  else /* TARGET_THUMB */\n+  else /* TARGET_THUMB1 */\n     {\n-      saved = bit_count (thumb_compute_save_reg_mask ()) * 4;\n+      saved = bit_count (thumb1_compute_save_reg_mask ()) * 4;\n       if (TARGET_BACKTRACE)\n \tsaved += 16;\n     }\n@@ -10618,11 +11102,132 @@ arm_compute_initial_elimination_offset (unsigned int from, unsigned int to)\n }\n \n \n-/* Generate the prologue instructions for entry into an ARM function.  */\n+/* Emit RTL to save coprocessor registers on funciton entry.  Returns the\n+   number of bytes pushed.  */\n+\n+static int\n+arm_save_coproc_regs(void)\n+{\n+  int saved_size = 0;\n+  unsigned reg;\n+  unsigned start_reg;\n+  rtx insn;\n+\n+  for (reg = LAST_IWMMXT_REGNUM; reg >= FIRST_IWMMXT_REGNUM; reg--)\n+    if (regs_ever_live[reg] && ! call_used_regs [reg])\n+      {\n+\tinsn = gen_rtx_PRE_DEC (V2SImode, stack_pointer_rtx);\n+\tinsn = gen_rtx_MEM (V2SImode, insn);\n+\tinsn = emit_set_insn (insn, gen_rtx_REG (V2SImode, reg));\n+\tRTX_FRAME_RELATED_P (insn) = 1;\n+\tsaved_size += 8;\n+      }\n+\n+  /* Save any floating point call-saved registers used by this\n+     function.  */\n+  if (arm_fpu_arch == FPUTYPE_FPA_EMU2)\n+    {\n+      for (reg = LAST_FPA_REGNUM; reg >= FIRST_FPA_REGNUM; reg--)\n+\tif (regs_ever_live[reg] && !call_used_regs[reg])\n+\t  {\n+\t    insn = gen_rtx_PRE_DEC (XFmode, stack_pointer_rtx);\n+\t    insn = gen_rtx_MEM (XFmode, insn);\n+\t    insn = emit_set_insn (insn, gen_rtx_REG (XFmode, reg));\n+\t    RTX_FRAME_RELATED_P (insn) = 1;\n+\t    saved_size += 12;\n+\t  }\n+    }\n+  else\n+    {\n+      start_reg = LAST_FPA_REGNUM;\n+\n+      for (reg = LAST_FPA_REGNUM; reg >= FIRST_FPA_REGNUM; reg--)\n+\t{\n+\t  if (regs_ever_live[reg] && !call_used_regs[reg])\n+\t    {\n+\t      if (start_reg - reg == 3)\n+\t\t{\n+\t\t  insn = emit_sfm (reg, 4);\n+\t\t  RTX_FRAME_RELATED_P (insn) = 1;\n+\t\t  saved_size += 48;\n+\t\t  start_reg = reg - 1;\n+\t\t}\n+\t    }\n+\t  else\n+\t    {\n+\t      if (start_reg != reg)\n+\t\t{\n+\t\t  insn = emit_sfm (reg + 1, start_reg - reg);\n+\t\t  RTX_FRAME_RELATED_P (insn) = 1;\n+\t\t  saved_size += (start_reg - reg) * 12;\n+\t\t}\n+\t      start_reg = reg - 1;\n+\t    }\n+\t}\n+\n+      if (start_reg != reg)\n+\t{\n+\t  insn = emit_sfm (reg + 1, start_reg - reg);\n+\t  saved_size += (start_reg - reg) * 12;\n+\t  RTX_FRAME_RELATED_P (insn) = 1;\n+\t}\n+    }\n+  if (TARGET_HARD_FLOAT && TARGET_VFP)\n+    {\n+      start_reg = FIRST_VFP_REGNUM;\n+\n+      for (reg = FIRST_VFP_REGNUM; reg < LAST_VFP_REGNUM; reg += 2)\n+\t{\n+\t  if ((!regs_ever_live[reg] || call_used_regs[reg])\n+\t      && (!regs_ever_live[reg + 1] || call_used_regs[reg + 1]))\n+\t    {\n+\t      if (start_reg != reg)\n+\t\tsaved_size += vfp_emit_fstmd (start_reg,\n+\t\t\t\t\t      (reg - start_reg) / 2);\n+\t      start_reg = reg + 2;\n+\t    }\n+\t}\n+      if (start_reg != reg)\n+\tsaved_size += vfp_emit_fstmd (start_reg,\n+\t\t\t\t      (reg - start_reg) / 2);\n+    }\n+  return saved_size;\n+}\n+\n+\n+/* Set the Thumb frame pointer from the stack pointer.  */\n+\n+static void\n+thumb_set_frame_pointer (arm_stack_offsets *offsets)\n+{\n+  HOST_WIDE_INT amount;\n+  rtx insn, dwarf;\n+\n+  amount = offsets->outgoing_args - offsets->locals_base;\n+  if (amount < 1024)\n+    insn = emit_insn (gen_addsi3 (hard_frame_pointer_rtx,\n+\t\t\t\t  stack_pointer_rtx, GEN_INT (amount)));\n+  else\n+    {\n+      emit_insn (gen_movsi (hard_frame_pointer_rtx, GEN_INT (amount)));\n+      insn = emit_insn (gen_addsi3 (hard_frame_pointer_rtx,\n+\t\t\t\t    hard_frame_pointer_rtx,\n+\t\t\t\t    stack_pointer_rtx));\n+      dwarf = gen_rtx_SET (VOIDmode, hard_frame_pointer_rtx,\n+\t\t\t   plus_constant (stack_pointer_rtx, amount));\n+      RTX_FRAME_RELATED_P (dwarf) = 1;\n+      REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_FRAME_RELATED_EXPR, dwarf,\n+\t\t\t\t\t    REG_NOTES (insn));\n+    }\n+\n+  RTX_FRAME_RELATED_P (insn) = 1;\n+}\n+\n+/* Generate the prologue instructions for entry into an ARM or Thumb-2\n+   function.  */\n void\n arm_expand_prologue (void)\n {\n-  int reg;\n   rtx amount;\n   rtx insn;\n   rtx ip_rtx;\n@@ -10648,7 +11253,38 @@ arm_expand_prologue (void)\n \n   ip_rtx = gen_rtx_REG (SImode, IP_REGNUM);\n \n-  if (frame_pointer_needed)\n+  if (IS_STACKALIGN (func_type))\n+    {\n+      rtx dwarf;\n+      rtx r0;\n+      rtx r1;\n+      /* Handle a word-aligned stack pointer.  We generate the following:\n+\n+\t  mov r0, sp\n+\t  bic r1, r0, #7\n+\t  mov sp, r1\n+\t  <save and restore r0 in normal prologue/epilogue>\n+\t  mov sp, r0\n+\t  bx lr\n+\n+\t The unwinder doesn't need to know about the stack realignment.\n+\t Just tell it we saved SP in r0.  */\n+      gcc_assert (TARGET_THUMB2 && !arm_arch_notm && args_to_push == 0);\n+\n+      r0 = gen_rtx_REG (SImode, 0);\n+      r1 = gen_rtx_REG (SImode, 1);\n+      dwarf = gen_rtx_UNSPEC (SImode, NULL_RTVEC, UNSPEC_STACK_ALIGN);\n+      dwarf = gen_rtx_SET (VOIDmode, r0, dwarf);\n+      insn = gen_movsi (r0, stack_pointer_rtx);\n+      RTX_FRAME_RELATED_P (insn) = 1;\n+      REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_FRAME_RELATED_EXPR,\n+\t\t\t\t\t    dwarf, REG_NOTES (insn));\n+      emit_insn (insn);\n+      emit_insn (gen_andsi3 (r1, r0, GEN_INT (~(HOST_WIDE_INT)7)));\n+      emit_insn (gen_movsi (stack_pointer_rtx, r1));\n+    }\n+\n+  if (frame_pointer_needed && TARGET_ARM)\n     {\n       if (IS_INTERRUPT (func_type))\n \t{\n@@ -10767,113 +11403,32 @@ arm_expand_prologue (void)\n       RTX_FRAME_RELATED_P (insn) = 1;\n     }\n \n-  if (TARGET_IWMMXT)\n-    for (reg = LAST_IWMMXT_REGNUM; reg >= FIRST_IWMMXT_REGNUM; reg--)\n-      if (regs_ever_live[reg] && ! call_used_regs [reg])\n-\t{\n-\t  insn = gen_rtx_PRE_DEC (V2SImode, stack_pointer_rtx);\n-\t  insn = gen_frame_mem (V2SImode, insn);\n-\t  insn = emit_set_insn (insn, gen_rtx_REG (V2SImode, reg));\n-\t  RTX_FRAME_RELATED_P (insn) = 1;\n-\t  saved_regs += 8;\n-\t}\n-\n   if (! IS_VOLATILE (func_type))\n-    {\n-      int start_reg;\n-\n-      /* Save any floating point call-saved registers used by this\n-\t function.  */\n-      if (arm_fpu_arch == FPUTYPE_FPA_EMU2)\n-\t{\n-\t  for (reg = LAST_FPA_REGNUM; reg >= FIRST_FPA_REGNUM; reg--)\n-\t    if (regs_ever_live[reg] && !call_used_regs[reg])\n-\t      {\n-\t\tinsn = gen_rtx_PRE_DEC (XFmode, stack_pointer_rtx);\n-\t\tinsn = gen_frame_mem (XFmode, insn);\n-\t\tinsn = emit_set_insn (insn, gen_rtx_REG (XFmode, reg));\n-\t\tRTX_FRAME_RELATED_P (insn) = 1;\n-\t\tsaved_regs += 12;\n-\t      }\n-\t}\n-      else\n-\t{\n-\t  start_reg = LAST_FPA_REGNUM;\n-\n-\t  for (reg = LAST_FPA_REGNUM; reg >= FIRST_FPA_REGNUM; reg--)\n-\t    {\n-\t      if (regs_ever_live[reg] && !call_used_regs[reg])\n-\t\t{\n-\t\t  if (start_reg - reg == 3)\n-\t\t    {\n-\t\t      insn = emit_sfm (reg, 4);\n-\t\t      RTX_FRAME_RELATED_P (insn) = 1;\n-\t\t      saved_regs += 48;\n-\t\t      start_reg = reg - 1;\n-\t\t    }\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  if (start_reg != reg)\n-\t\t    {\n-\t\t      insn = emit_sfm (reg + 1, start_reg - reg);\n-\t\t      RTX_FRAME_RELATED_P (insn) = 1;\n-\t\t      saved_regs += (start_reg - reg) * 12;\n-\t\t    }\n-\t\t  start_reg = reg - 1;\n-\t\t}\n-\t    }\n+    saved_regs += arm_save_coproc_regs ();\n \n-\t  if (start_reg != reg)\n-\t    {\n-\t      insn = emit_sfm (reg + 1, start_reg - reg);\n-\t      saved_regs += (start_reg - reg) * 12;\n-\t      RTX_FRAME_RELATED_P (insn) = 1;\n-\t    }\n-\t}\n-      if (TARGET_HARD_FLOAT && TARGET_VFP)\n+  if (frame_pointer_needed && TARGET_ARM)\n+    {\n+      /* Create the new frame pointer.  */\n \t{\n-\t  start_reg = FIRST_VFP_REGNUM;\n+\t  insn = GEN_INT (-(4 + args_to_push + fp_offset));\n+\t  insn = emit_insn (gen_addsi3 (hard_frame_pointer_rtx, ip_rtx, insn));\n+\t  RTX_FRAME_RELATED_P (insn) = 1;\n \n- \t  for (reg = FIRST_VFP_REGNUM; reg < LAST_VFP_REGNUM; reg += 2)\n+\t  if (IS_NESTED (func_type))\n \t    {\n-\t      if ((!regs_ever_live[reg] || call_used_regs[reg])\n-\t\t  && (!regs_ever_live[reg + 1] || call_used_regs[reg + 1]))\n+\t      /* Recover the static chain register.  */\n+\t      if (regs_ever_live [3] == 0\n+\t\t  || saved_pretend_args)\n+\t\tinsn = gen_rtx_REG (SImode, 3);\n+\t      else /* if (current_function_pretend_args_size == 0) */\n \t\t{\n-\t\t  if (start_reg != reg)\n-\t\t    saved_regs += vfp_emit_fstmd (start_reg,\n-\t\t\t\t\t\t  (reg - start_reg) / 2);\n-\t\t  start_reg = reg + 2;\n+\t\t  insn = plus_constant (hard_frame_pointer_rtx, 4);\n+\t\t  insn = gen_frame_mem (SImode, insn);\n \t\t}\n+\t      emit_set_insn (ip_rtx, insn);\n+\t      /* Add a USE to stop propagate_one_insn() from barfing.  */\n+\t      emit_insn (gen_prologue_use (ip_rtx));\n \t    }\n-\t  if (start_reg != reg)\n-\t    saved_regs += vfp_emit_fstmd (start_reg,\n-\t\t\t\t\t  (reg - start_reg) / 2);\n-\t}\n-    }\n-\n-  if (frame_pointer_needed)\n-    {\n-      /* Create the new frame pointer.  */\n-      insn = GEN_INT (-(4 + args_to_push + fp_offset));\n-      insn = emit_insn (gen_addsi3 (hard_frame_pointer_rtx, ip_rtx, insn));\n-      RTX_FRAME_RELATED_P (insn) = 1;\n-\n-      if (IS_NESTED (func_type))\n-\t{\n-\t  /* Recover the static chain register.  */\n-\t  if (regs_ever_live [3] == 0\n-\t      || saved_pretend_args)\n-\t    insn = gen_rtx_REG (SImode, 3);\n-\t  else /* if (current_function_pretend_args_size == 0) */\n-\t    {\n-\t      insn = plus_constant (hard_frame_pointer_rtx, 4);\n-\t      insn = gen_frame_mem (SImode, insn);\n-\t    }\n-\n-\t  emit_set_insn (ip_rtx, insn);\n-\t  /* Add a USE to stop propagate_one_insn() from barfing.  */\n-\t  emit_insn (gen_prologue_use (ip_rtx));\n \t}\n     }\n \n@@ -10905,8 +11460,19 @@ arm_expand_prologue (void)\n     }\n \n \n+  if (frame_pointer_needed && TARGET_THUMB2)\n+    thumb_set_frame_pointer (offsets);\n+\n   if (flag_pic && arm_pic_register != INVALID_REGNUM)\n-    arm_load_pic_register (0UL);\n+    {\n+      unsigned long mask;\n+\n+      mask = live_regs_mask;\n+      mask &= THUMB2_WORK_REGS;\n+      if (!IS_NESTED (func_type))\n+\tmask |= (1 << IP_REGNUM);\n+      arm_load_pic_register (mask);\n+    }\n \n   /* If we are profiling, make sure no instructions are scheduled before\n      the call to mcount.  Similarly if the user has requested no\n@@ -10926,6 +11492,43 @@ arm_expand_prologue (void)\n     }\n }\n \f\n+/* Print condition code to STREAM.  Helper function for arm_print_operand.  */\n+static void\n+arm_print_condition (FILE *stream)\n+{\n+  if (arm_ccfsm_state == 3 || arm_ccfsm_state == 4)\n+    {\n+      /* Branch conversion is not implemented for Thumb-2.  */\n+      if (TARGET_THUMB)\n+\t{\n+\t  output_operand_lossage (\"predicated Thumb instruction\");\n+\t  return;\n+\t}\n+      if (current_insn_predicate != NULL)\n+\t{\n+\t  output_operand_lossage\n+\t    (\"predicated instruction in conditional sequence\");\n+\t  return;\n+\t}\n+\n+      fputs (arm_condition_codes[arm_current_cc], stream);\n+    }\n+  else if (current_insn_predicate)\n+    {\n+      enum arm_cond_code code;\n+\n+      if (TARGET_THUMB1)\n+\t{\n+\t  output_operand_lossage (\"predicated Thumb instruction\");\n+\t  return;\n+\t}\n+\n+      code = get_arm_condition_code (current_insn_predicate);\n+      fputs (arm_condition_codes[code], stream);\n+    }\n+}\n+\n+\n /* If CODE is 'd', then the X is a condition operand and the instruction\n    should only be executed if the condition is true.\n    if CODE is 'D', then the X is a condition operand and the instruction\n@@ -10957,37 +11560,46 @@ arm_print_operand (FILE *stream, rtx x, int code)\n       return;\n \n     case '?':\n-      if (arm_ccfsm_state == 3 || arm_ccfsm_state == 4)\n-\t{\n-\t  if (TARGET_THUMB)\n-\t    {\n-\t      output_operand_lossage (\"predicated Thumb instruction\");\n-\t      break;\n-\t    }\n-\t  if (current_insn_predicate != NULL)\n-\t    {\n-\t      output_operand_lossage\n-\t\t(\"predicated instruction in conditional sequence\");\n-\t      break;\n-\t    }\n+      arm_print_condition (stream);\n+      return;\n \n-\t  fputs (arm_condition_codes[arm_current_cc], stream);\n+    case '(':\n+      /* Nothing in unified syntax, otherwise the current condition code.  */\n+      if (!TARGET_UNIFIED_ASM)\n+\tarm_print_condition (stream);\n+      break;\n+\n+    case ')':\n+      /* The current condition code in unified syntax, otherwise nothing.  */\n+      if (TARGET_UNIFIED_ASM)\n+\tarm_print_condition (stream);\n+      break;\n+  \n+    case '.':\n+      /* The current condition code for a condition code setting instruction.\n+\t Preceeded by 's' in unified syntax, otherwise followed by 's'.  */\n+      if (TARGET_UNIFIED_ASM)\n+\t{\n+\t  fputc('s', stream);\n+\t  arm_print_condition (stream);\n \t}\n-      else if (current_insn_predicate)\n+      else\n \t{\n-\t  enum arm_cond_code code;\n-\n-\t  if (TARGET_THUMB)\n-\t    {\n-\t      output_operand_lossage (\"predicated Thumb instruction\");\n-\t      break;\n-\t    }\n-\n-\t  code = get_arm_condition_code (current_insn_predicate);\n-\t  fputs (arm_condition_codes[code], stream);\n+\t  arm_print_condition (stream);\n+\t  fputc('s', stream);\n \t}\n       return;\n \n+    case '!':\n+      /* If the instruction is conditionally executed then print\n+\t the current condition code, otherwise print 's'.  */\n+      gcc_assert (TARGET_THUMB2 && TARGET_UNIFIED_ASM);\n+      if (current_insn_predicate)\n+\tarm_print_condition (stream);\n+      else\n+\tfputc('s', stream);\n+      break;\n+\n     case 'N':\n       {\n \tREAL_VALUE_TYPE r;\n@@ -11011,6 +11623,11 @@ arm_print_operand (FILE *stream, rtx x, int code)\n \t}\n       return;\n \n+    case 'L':\n+      /* The low 16 bits of an immediate constant.  */\n+      fprintf (stream, HOST_WIDE_INT_PRINT_DEC, INTVAL(x) & 0xffff);\n+      return;\n+\n     case 'i':\n       fprintf (stream, \"%s\", arithmetic_instr (x, 1));\n       return;\n@@ -11419,6 +12036,13 @@ arm_elf_asm_constructor (rtx symbol, int priority)\n    time.  But then, I want to reduce the code size to somewhere near what\n    /bin/cc produces.  */\n \n+/* In addition to this, state is maintained for Thumb-2 COND_EXEC\n+   instructions.  When a COND_EXEC instruction is seen the subsequent\n+   instructions are scanned so that multiple conditional instructions can be\n+   combined into a single IT block.  arm_condexec_count and arm_condexec_mask\n+   specify the length and true/false mask for the IT block.  These will be\n+   decremented/zeroed by arm_asm_output_opcode as the insns are output.  */\n+\n /* Returns the index of the ARM condition code string in\n    `arm_condition_codes'.  COMPARISON should be an rtx like\n    `(eq (...) (...))'.  */\n@@ -11548,6 +12172,88 @@ get_arm_condition_code (rtx comparison)\n     }\n }\n \n+/* Tell arm_asm_ouput_opcode to output IT blocks for conditionally executed\n+   instructions.  */\n+void\n+thumb2_final_prescan_insn (rtx insn)\n+{\n+  rtx first_insn = insn;\n+  rtx body = PATTERN (insn);\n+  rtx predicate;\n+  enum arm_cond_code code;\n+  int n;\n+  int mask;\n+\n+  /* Remove the previous insn from the count of insns to be output.  */\n+  if (arm_condexec_count)\n+      arm_condexec_count--;\n+\n+  /* Nothing to do if we are already inside a conditional block.  */\n+  if (arm_condexec_count)\n+    return;\n+\n+  if (GET_CODE (body) != COND_EXEC)\n+    return;\n+\n+  /* Conditional jumps are implemented directly.  */\n+  if (GET_CODE (insn) == JUMP_INSN)\n+    return;\n+\n+  predicate = COND_EXEC_TEST (body);\n+  arm_current_cc = get_arm_condition_code (predicate);\n+\n+  n = get_attr_ce_count (insn);\n+  arm_condexec_count = 1;\n+  arm_condexec_mask = (1 << n) - 1;\n+  arm_condexec_masklen = n;\n+  /* See if subsequent instructions can be combined into the same block.  */\n+  for (;;)\n+    {\n+      insn = next_nonnote_insn (insn);\n+\n+      /* Jumping into the middle of an IT block is illegal, so a label or\n+         barrier terminates the block.  */\n+      if (GET_CODE (insn) != INSN && GET_CODE(insn) != JUMP_INSN)\n+\tbreak;\n+\n+      body = PATTERN (insn);\n+      /* USE and CLOBBER aren't really insns, so just skip them.  */\n+      if (GET_CODE (body) == USE\n+\t  || GET_CODE (body) == CLOBBER)\n+\t{\n+\t  arm_condexec_count++;\n+\t  continue;\n+\t}\n+\n+      /* ??? Recognise conditional jumps, and combine them with IT blocks.  */\n+      if (GET_CODE (body) != COND_EXEC)\n+\tbreak;\n+      /* Allow up to 4 conditionally executed instructions in a block.  */\n+      n = get_attr_ce_count (insn);\n+      if (arm_condexec_masklen + n > 4)\n+\tbreak;\n+\n+      predicate = COND_EXEC_TEST (body);\n+      code = get_arm_condition_code (predicate);\n+      mask = (1 << n) - 1;\n+      if (arm_current_cc == code)\n+\tarm_condexec_mask |= (mask << arm_condexec_masklen);\n+      else if (arm_current_cc != ARM_INVERSE_CONDITION_CODE(code))\n+\tbreak;\n+\n+      arm_condexec_count++;\n+      arm_condexec_masklen += n;\n+\n+      /* A jump must be the last instruction in a conditional block.  */\n+      if (GET_CODE(insn) == JUMP_INSN)\n+\tbreak;\n+    }\n+  /* Restore recog_data (getting the attributes of other insns can\n+     destroy this array, but final.c assumes that it remains intact\n+     across this call).  */\n+  extract_constrain_insn_cached (first_insn);\n+}\n+\n void\n arm_final_prescan_insn (rtx insn)\n {\n@@ -11852,7 +12558,7 @@ arm_final_prescan_insn (rtx insn)\n \t      if (!this_insn)\n \t        {\n \t\t  /* Oh, dear! we ran off the end.. give up.  */\n-\t\t  recog (PATTERN (insn), insn, NULL);\n+\t\t  extract_constrain_insn_cached (insn);\n \t\t  arm_ccfsm_state = 0;\n \t\t  arm_target_insn = NULL;\n \t\t  return;\n@@ -11885,9 +12591,26 @@ arm_final_prescan_insn (rtx insn)\n \n       /* Restore recog_data (getting the attributes of other insns can\n \t destroy this array, but final.c assumes that it remains intact\n-\t across this call; since the insn has been recognized already we\n-\t call recog direct).  */\n-      recog (PATTERN (insn), insn, NULL);\n+\t across this call.  */\n+      extract_constrain_insn_cached (insn);\n+    }\n+}\n+\n+/* Output IT instructions.  */\n+void\n+thumb2_asm_output_opcode (FILE * stream)\n+{\n+  char buff[5];\n+  int n;\n+\n+  if (arm_condexec_mask)\n+    {\n+      for (n = 0; n < arm_condexec_masklen; n++)\n+\tbuff[n] = (arm_condexec_mask & (1 << n)) ? 't' : 'e';\n+      buff[n] = 0;\n+      asm_fprintf(stream, \"i%s\\t%s\\n\\t\", buff,\n+\t\t  arm_condition_codes[arm_current_cc]);\n+      arm_condexec_mask = 0;\n     }\n }\n \n@@ -11901,7 +12624,7 @@ arm_hard_regno_mode_ok (unsigned int regno, enum machine_mode mode)\n \t    || (TARGET_HARD_FLOAT && TARGET_VFP\n \t\t&& regno == VFPCC_REGNUM));\n \n-  if (TARGET_THUMB)\n+  if (TARGET_THUMB1)\n     /* For the Thumb we only allow values bigger than SImode in\n        registers 0 - 6, so that there is always a second low\n        register available to hold the upper part of the value.\n@@ -11958,10 +12681,12 @@ arm_hard_regno_mode_ok (unsigned int regno, enum machine_mode mode)\n \t  && regno <= LAST_FPA_REGNUM);\n }\n \n+/* For efficiency and historical reasons LO_REGS, HI_REGS and CC_REGS are\n+   not used in arm mode.  */\n int\n arm_regno_class (int regno)\n {\n-  if (TARGET_THUMB)\n+  if (TARGET_THUMB1)\n     {\n       if (regno == STACK_POINTER_REGNUM)\n \treturn STACK_REG;\n@@ -11972,13 +12697,16 @@ arm_regno_class (int regno)\n       return HI_REGS;\n     }\n \n+  if (TARGET_THUMB2 && regno < 8)\n+    return LO_REGS;\n+\n   if (   regno <= LAST_ARM_REGNUM\n       || regno == FRAME_POINTER_REGNUM\n       || regno == ARG_POINTER_REGNUM)\n-    return GENERAL_REGS;\n+    return TARGET_THUMB2 ? HI_REGS : GENERAL_REGS;\n \n   if (regno == CC_REGNUM || regno == VFPCC_REGNUM)\n-    return NO_REGS;\n+    return TARGET_THUMB2 ? CC_REG : NO_REGS;\n \n   if (IS_CIRRUS_REGNUM (regno))\n     return CIRRUS_REGS;\n@@ -12017,6 +12745,7 @@ arm_debugger_arg_offset (int value, rtx addr)\n \n   /* If we are using the stack pointer to point at the\n      argument, then an offset of 0 is correct.  */\n+  /* ??? Check this is consistent with thumb2 frame layout.  */\n   if ((TARGET_THUMB || !frame_pointer_needed)\n       && REGNO (addr) == SP_REGNUM)\n     return 0;\n@@ -13293,7 +14022,7 @@ thumb_exit (FILE *f, int reg_containing_return_addr)\n \n \f\n void\n-thumb_final_prescan_insn (rtx insn)\n+thumb1_final_prescan_insn (rtx insn)\n {\n   if (flag_print_asm_name)\n     asm_fprintf (asm_out_file, \"%@ 0x%04x\\n\",\n@@ -13420,7 +14149,7 @@ thumb_unexpanded_epilogue (void)\n   if (IS_NAKED (arm_current_func_type ()))\n     return \"\";\n \n-  live_regs_mask = thumb_compute_save_reg_mask ();\n+  live_regs_mask = thumb1_compute_save_reg_mask ();\n   high_regs_pushed = bit_count (live_regs_mask & 0x0f00);\n \n   /* If we can deduce the registers used from the function's return value.\n@@ -13658,10 +14387,9 @@ thumb_compute_initial_elimination_offset (unsigned int from, unsigned int to)\n     }\n }\n \n-\n /* Generate the rest of a function's prologue.  */\n void\n-thumb_expand_prologue (void)\n+thumb1_expand_prologue (void)\n {\n   rtx insn, dwarf;\n \n@@ -13683,7 +14411,7 @@ thumb_expand_prologue (void)\n       return;\n     }\n \n-  live_regs_mask = thumb_compute_save_reg_mask ();\n+  live_regs_mask = thumb1_compute_save_reg_mask ();\n   /* Load the pic register before setting the frame pointer,\n      so we can use r7 as a temporary work register.  */\n   if (flag_pic && arm_pic_register != INVALID_REGNUM)\n@@ -13782,27 +14510,7 @@ thumb_expand_prologue (void)\n     }\n \n   if (frame_pointer_needed)\n-    {\n-      amount = offsets->outgoing_args - offsets->locals_base;\n-\n-      if (amount < 1024)\n-\tinsn = emit_insn (gen_addsi3 (hard_frame_pointer_rtx,\n-\t\t\t\t      stack_pointer_rtx, GEN_INT (amount)));\n-      else\n-\t{\n-\t  emit_insn (gen_movsi (hard_frame_pointer_rtx, GEN_INT (amount)));\n-\t  insn = emit_insn (gen_addsi3 (hard_frame_pointer_rtx,\n-\t\t\t\t\thard_frame_pointer_rtx,\n-\t\t\t\t\tstack_pointer_rtx));\n-\t  dwarf = gen_rtx_SET (VOIDmode, hard_frame_pointer_rtx,\n-\t\t\t       plus_constant (stack_pointer_rtx, amount));\n-\t  RTX_FRAME_RELATED_P (dwarf) = 1;\n-\t  REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_FRAME_RELATED_EXPR, dwarf,\n-\t\t\t\t\t\tREG_NOTES (insn));\n-\t}\n-\n-      RTX_FRAME_RELATED_P (insn) = 1;\n-    }\n+    thumb_set_frame_pointer (offsets);\n \n   /* If we are profiling, make sure no instructions are scheduled before\n      the call to mcount.  Similarly if the user has requested no\n@@ -13825,7 +14533,7 @@ thumb_expand_prologue (void)\n \n \n void\n-thumb_expand_epilogue (void)\n+thumb1_expand_epilogue (void)\n {\n   HOST_WIDE_INT amount;\n   arm_stack_offsets *offsets;\n@@ -13877,7 +14585,7 @@ thumb_expand_epilogue (void)\n }\n \n static void\n-thumb_output_function_prologue (FILE *f, HOST_WIDE_INT size ATTRIBUTE_UNUSED)\n+thumb1_output_function_prologue (FILE *f, HOST_WIDE_INT size ATTRIBUTE_UNUSED)\n {\n   unsigned long live_regs_mask = 0;\n   unsigned long l_mask;\n@@ -13963,7 +14671,7 @@ thumb_output_function_prologue (FILE *f, HOST_WIDE_INT size ATTRIBUTE_UNUSED)\n     }\n \n   /* Get the registers we are going to push.  */\n-  live_regs_mask = thumb_compute_save_reg_mask ();\n+  live_regs_mask = thumb1_compute_save_reg_mask ();\n   /* Extract a mask of the ones we can give to the Thumb's push instruction.  */\n   l_mask = live_regs_mask & 0x40ff;\n   /* Then count how many other high registers will need to be pushed.  */\n@@ -14428,6 +15136,9 @@ arm_file_start (void)\n {\n   int val;\n \n+  if (TARGET_UNIFIED_ASM)\n+    asm_fprintf (asm_out_file, \"\\t.syntax unified\\n\");\n+\n   if (TARGET_BPABI)\n     {\n       const char *fpu_name;\n@@ -14846,7 +15557,8 @@ arm_output_mi_thunk (FILE *file, tree thunk ATTRIBUTE_UNUSED,\n                     ? 1 : 0);\n   if (mi_delta < 0)\n     mi_delta = - mi_delta;\n-  if (TARGET_THUMB)\n+  /* When generating 16-bit thumb code, thunks are entered in arm mode.  */\n+  if (TARGET_THUMB1)\n     {\n       int labelno = thunk_label++;\n       ASM_GENERATE_INTERNAL_LABEL (label, \"LTHUMBFUNC\", labelno);\n@@ -14871,6 +15583,7 @@ arm_output_mi_thunk (FILE *file, tree thunk ATTRIBUTE_UNUSED,\n \t  fputs (\"\\tadd\\tr12, pc, r12\\n\", file);\n \t}\n     }\n+  /* TODO: Use movw/movt for large constants when available.  */\n   while (mi_delta != 0)\n     {\n       if ((mi_delta & (3 << shift)) == 0)\n@@ -14884,7 +15597,7 @@ arm_output_mi_thunk (FILE *file, tree thunk ATTRIBUTE_UNUSED,\n           shift += 8;\n         }\n     }\n-  if (TARGET_THUMB)\n+  if (TARGET_THUMB1)\n     {\n       fprintf (file, \"\\tbx\\tr12\\n\");\n       ASM_OUTPUT_ALIGN (file, 2);\n@@ -15273,38 +15986,41 @@ thumb_set_return_address (rtx source, rtx scratch)\n {\n   arm_stack_offsets *offsets;\n   HOST_WIDE_INT delta;\n+  HOST_WIDE_INT limit;\n   int reg;\n   rtx addr;\n   unsigned long mask;\n \n   emit_insn (gen_rtx_USE (VOIDmode, source));\n \n-  mask = thumb_compute_save_reg_mask ();\n+  mask = thumb1_compute_save_reg_mask ();\n   if (mask & (1 << LR_REGNUM))\n     {\n       offsets = arm_get_frame_offsets ();\n \n+      limit = 1024;\n       /* Find the saved regs.  */\n       if (frame_pointer_needed)\n \t{\n \t  delta = offsets->soft_frame - offsets->saved_args;\n \t  reg = THUMB_HARD_FRAME_POINTER_REGNUM;\n+\t  if (TARGET_THUMB1)\n+\t    limit = 128;\n \t}\n       else\n \t{\n \t  delta = offsets->outgoing_args - offsets->saved_args;\n \t  reg = SP_REGNUM;\n \t}\n       /* Allow for the stack frame.  */\n-      if (TARGET_BACKTRACE)\n+      if (TARGET_THUMB1 && TARGET_BACKTRACE)\n \tdelta -= 16;\n       /* The link register is always the first saved register.  */\n       delta -= 4;\n \n       /* Construct the address.  */\n       addr = gen_rtx_REG (SImode, reg);\n-      if ((reg != SP_REGNUM && delta >= 128)\n-\t  || delta >= 1024)\n+      if (delta > limit)\n \t{\n \t  emit_insn (gen_movsi (scratch, GEN_INT (delta)));\n \t  emit_insn (gen_addsi3 (scratch, scratch, stack_pointer_rtx));\n@@ -15370,12 +16086,13 @@ arm_dbx_register_number (unsigned int regno)\n \n \n #ifdef TARGET_UNWIND_INFO\n-/* Emit unwind directives for a store-multiple instruction.  This should\n-   only ever be generated by the function prologue code, so we expect it\n-   to have a particular form.  */\n+/* Emit unwind directives for a store-multiple instruction or stack pointer\n+   push during alignment.\n+   These should only ever be generated by the function prologue code, so\n+   expect them to have a particular form.  */\n \n static void\n-arm_unwind_emit_stm (FILE * asm_out_file, rtx p)\n+arm_unwind_emit_sequence (FILE * asm_out_file, rtx p)\n {\n   int i;\n   HOST_WIDE_INT offset;\n@@ -15385,8 +16102,11 @@ arm_unwind_emit_stm (FILE * asm_out_file, rtx p)\n   unsigned lastreg;\n   rtx e;\n \n-  /* First insn will adjust the stack pointer.  */\n   e = XVECEXP (p, 0, 0);\n+  if (GET_CODE (e) != SET)\n+    abort ();\n+\n+  /* First insn will adjust the stack pointer.  */\n   if (GET_CODE (e) != SET\n       || GET_CODE (XEXP (e, 0)) != REG\n       || REGNO (XEXP (e, 0)) != SP_REGNUM\n@@ -15483,6 +16203,7 @@ arm_unwind_emit_set (FILE * asm_out_file, rtx p)\n {\n   rtx e0;\n   rtx e1;\n+  unsigned reg;\n \n   e0 = XEXP (p, 0);\n   e1 = XEXP (p, 1);\n@@ -15519,7 +16240,6 @@ arm_unwind_emit_set (FILE * asm_out_file, rtx p)\n       else if (REGNO (e0) == HARD_FRAME_POINTER_REGNUM)\n \t{\n \t  HOST_WIDE_INT offset;\n-\t  unsigned reg;\n \n \t  if (GET_CODE (e1) == PLUS)\n \t    {\n@@ -15555,6 +16275,13 @@ arm_unwind_emit_set (FILE * asm_out_file, rtx p)\n \t  asm_fprintf (asm_out_file, \"\\t.movsp %r, #%d\\n\",\n \t\t       REGNO (e0), (int)INTVAL(XEXP (e1, 1)));\n \t}\n+      else if (GET_CODE (e1) == UNSPEC && XINT (e1, 1) == UNSPEC_STACK_ALIGN)\n+\t{\n+\t  /* Stack pointer save before alignment.  */\n+\t  reg = REGNO (e0);\n+\t  asm_fprintf (asm_out_file, \"\\t.unwind_raw 0, 0x%x @ vsp = r%d\\n\",\n+\t\t       reg + 0x90, reg);\n+\t}\n       else\n \tabort ();\n       break;\n@@ -15592,7 +16319,7 @@ arm_unwind_emit (FILE * asm_out_file, rtx insn)\n \n     case SEQUENCE:\n       /* Store multiple.  */\n-      arm_unwind_emit_stm (asm_out_file, pat);\n+      arm_unwind_emit_sequence (asm_out_file, pat);\n       break;\n \n     default:\n@@ -15620,6 +16347,30 @@ arm_output_ttype (rtx x)\n #endif /* TARGET_UNWIND_INFO */\n \n \n+/* Handle UNSPEC DWARF call frame instructions.  These are needed for dynamic\n+   stack alignment.  */\n+\n+static void\n+arm_dwarf_handle_frame_unspec (const char *label, rtx pattern, int index)\n+{\n+  rtx unspec = SET_SRC (pattern);\n+  gcc_assert (GET_CODE (unspec) == UNSPEC);\n+\n+  switch (index)\n+    {\n+    case UNSPEC_STACK_ALIGN:\n+      /* ??? We should set the CFA = (SP & ~7).  At this point we haven't\n+         put anything on the stack, so hopefully it won't matter.\n+         CFA = SP will be correct after alignment.  */\n+      dwarf2out_reg_save_reg (label, stack_pointer_rtx,\n+                              SET_DEST (pattern));\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+\n /* Output unwind directives for the start/end of a function.  */\n \n void\n@@ -15705,4 +16456,71 @@ arm_output_addr_const_extra (FILE *fp, rtx x)\n   return FALSE;\n }\n \n+/* Output assembly for a shift instruction.\n+   SET_FLAGS determines how the instruction modifies the condition codes.\n+   0 - Do not set conditiona codes.\n+   1 - Set condition codes.\n+   2 - Use smallest instruction.  */\n+const char *\n+arm_output_shift(rtx * operands, int set_flags)\n+{\n+  char pattern[100];\n+  static const char flag_chars[3] = {'?', '.', '!'};\n+  const char *shift;\n+  HOST_WIDE_INT val;\n+  char c;\n+  \n+  c = flag_chars[set_flags];\n+  if (TARGET_UNIFIED_ASM)\n+    {\n+      shift = shift_op(operands[3], &val);\n+      if (shift)\n+\t{\n+\t  if (val != -1)\n+\t    operands[2] = GEN_INT(val);\n+\t  sprintf (pattern, \"%s%%%c\\t%%0, %%1, %%2\", shift, c);\n+\t}\n+      else\n+\tsprintf (pattern, \"mov%%%c\\t%%0, %%1\", c);\n+    }\n+  else\n+    sprintf (pattern, \"mov%%%c\\t%%0, %%1%%S3\", c);\n+  output_asm_insn (pattern, operands);\n+  return \"\";\n+}\n+\n+/* Output a Thumb-2 casesi instruction.  */\n+const char *\n+thumb2_output_casesi (rtx *operands)\n+{\n+  rtx diff_vec = PATTERN (next_real_insn (operands[2]));\n+\n+  gcc_assert (GET_CODE (diff_vec) == ADDR_DIFF_VEC);\n+\n+  output_asm_insn (\"cmp\\t%0, %1\", operands);\n+  output_asm_insn (\"bhi\\t%l3\", operands);\n+  switch (GET_MODE(diff_vec))\n+    {\n+    case QImode:\n+      return \"tbb\\t[%|pc, %0]\";\n+    case HImode:\n+      return \"tbh\\t[%|pc, %0, lsl #1]\";\n+    case SImode:\n+      if (flag_pic)\n+\t{\n+\t  output_asm_insn (\"adr\\t%4, %l2\", operands);\n+\t  output_asm_insn (\"ldr\\t%5, [%4, %0, lsl #2]\", operands);\n+\t  output_asm_insn (\"add\\t%4, %4, %5\", operands);\n+\t  return \"bx\\t%4\";\n+\t}\n+      else\n+\t{\n+\t  output_asm_insn (\"adr\\t%4, %l2\", operands);\n+\t  return \"ldr\\t%|pc, [%4, %0, lsl #2]\";\n+\t}\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n #include \"gt-arm.h\""}, {"sha": "d2f493b6fed615743c4117699fc43916b6fb3caa", "filename": "gcc/config/arm/arm.h", "status": "modified", "additions": 209, "deletions": 96, "changes": 305, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.h?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,6 +1,6 @@\n /* Definitions of target machine for GNU compiler, for ARM.\n    Copyright (C) 1991, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n-   2001, 2002, 2003, 2004, 2005, 2006 Free Software Foundation, Inc.\n+   2001, 2002, 2003, 2004, 2005, 2006, 2007 Free Software Foundation, Inc.\n    Contributed by Pieter `Tiggr' Schoenmakers (rcpieter@win.tue.nl)\n    and Martin Simmons (@harleqn.co.uk).\n    More major hacks by Richard Earnshaw (rearnsha@arm.com)\n@@ -39,6 +39,8 @@ extern char arm_arch_name[];\n \tbuiltin_define (\"__APCS_32__\");\t\t\t\\\n \tif (TARGET_THUMB)\t\t\t\t\\\n \t  builtin_define (\"__thumb__\");\t\t\t\\\n+\tif (TARGET_THUMB2)\t\t\t\t\\\n+\t  builtin_define (\"__thumb2__\");\t\t\\\n \t\t\t\t\t\t\t\\\n \tif (TARGET_BIG_END)\t\t\t\t\\\n \t  {\t\t\t\t\t\t\\\n@@ -181,8 +183,8 @@ extern GTY(()) rtx aof_pic_label;\n #define TARGET_MAVERICK\t\t\t(arm_fp_model == ARM_FP_MODEL_MAVERICK)\n #define TARGET_VFP\t\t\t(arm_fp_model == ARM_FP_MODEL_VFP)\n #define TARGET_IWMMXT\t\t\t(arm_arch_iwmmxt)\n-#define TARGET_REALLY_IWMMXT\t\t(TARGET_IWMMXT && TARGET_ARM)\n-#define TARGET_IWMMXT_ABI (TARGET_ARM && arm_abi == ARM_ABI_IWMMXT)\n+#define TARGET_REALLY_IWMMXT\t\t(TARGET_IWMMXT && TARGET_32BIT)\n+#define TARGET_IWMMXT_ABI (TARGET_32BIT && arm_abi == ARM_ABI_IWMMXT)\n #define TARGET_ARM                      (! TARGET_THUMB)\n #define TARGET_EITHER\t\t\t1 /* (TARGET_ARM | TARGET_THUMB) */\n #define TARGET_BACKTRACE\t        (leaf_function_p () \\\n@@ -195,6 +197,25 @@ extern GTY(()) rtx aof_pic_label;\n #define TARGET_HARD_TP\t\t\t(target_thread_pointer == TP_CP15)\n #define TARGET_SOFT_TP\t\t\t(target_thread_pointer == TP_SOFT)\n \n+/* Only 16-bit thumb code.  */\n+#define TARGET_THUMB1\t\t\t(TARGET_THUMB && !arm_arch_thumb2)\n+/* Arm or Thumb-2 32-bit code.  */\n+#define TARGET_32BIT\t\t\t(TARGET_ARM || arm_arch_thumb2)\n+/* 32-bit Thumb-2 code.  */\n+#define TARGET_THUMB2\t\t\t(TARGET_THUMB && arm_arch_thumb2)\n+\n+/* \"DSP\" multiply instructions, eg. SMULxy.  */\n+#define TARGET_DSP_MULTIPLY \\\n+  (TARGET_32BIT && arm_arch5e && arm_arch_notm)\n+/* Integer SIMD instructions, and extend-accumulate instructions.  */\n+#define TARGET_INT_SIMD \\\n+  (TARGET_32BIT && arm_arch6 && arm_arch_notm)\n+\n+/* We could use unified syntax for arm mode, but for now we just use it\n+   for Thumb-2.  */\n+#define TARGET_UNIFIED_ASM TARGET_THUMB2\n+\n+\n /* True iff the full BPABI is being used.  If TARGET_BPABI is true,\n    then TARGET_AAPCS_BASED must be true -- but the converse does not\n    hold.  TARGET_BPABI implies the use of the BPABI runtime library,\n@@ -320,6 +341,9 @@ extern int arm_arch5e;\n /* Nonzero if this chip supports the ARM Architecture 6 extensions.  */\n extern int arm_arch6;\n \n+/* Nonzero if instructions not present in the 'M' profile can be used.  */\n+extern int arm_arch_notm;\n+\n /* Nonzero if this chip can benefit from load scheduling.  */\n extern int arm_ld_sched;\n \n@@ -351,6 +375,12 @@ extern int arm_tune_wbuf;\n    interworking clean.  */\n extern int arm_cpp_interwork;\n \n+/* Nonzero if chip supports Thumb 2.  */\n+extern int arm_arch_thumb2;\n+\n+/* Nonzero if chip supports integer division instruction.  */\n+extern int arm_arch_hwdiv;\n+\n #ifndef TARGET_DEFAULT\n #define TARGET_DEFAULT  (MASK_APCS_FRAME)\n #endif\n@@ -648,7 +678,7 @@ extern int arm_structure_size_boundary;\n {\t\t\t\t\t\t\t\t\\\n   int regno;\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\\\n-  if (TARGET_SOFT_FLOAT || TARGET_THUMB || !TARGET_FPA)\t\t\\\n+  if (TARGET_SOFT_FLOAT || TARGET_THUMB1 || !TARGET_FPA)\t\\\n     {\t\t\t\t\t\t\t\t\\\n       for (regno = FIRST_FPA_REGNUM;\t\t\t\t\\\n \t   regno <= LAST_FPA_REGNUM; ++regno)\t\t\t\\\n@@ -660,6 +690,7 @@ extern int arm_structure_size_boundary;\n       /* When optimizing for size, it's better not to use\t\\\n \t the HI regs, because of the overhead of stacking \t\\\n \t them.  */\t\t\t\t\t\t\\\n+      /* ??? Is this still true for thumb2?  */\t\t\t\\\n       for (regno = FIRST_HI_REGNUM;\t\t\t\t\\\n \t   regno <= LAST_HI_REGNUM; ++regno)\t\t\t\\\n \tfixed_regs[regno] = call_used_regs[regno] = 1;\t\t\\\n@@ -668,10 +699,10 @@ extern int arm_structure_size_boundary;\n   /* The link register can be clobbered by any branch insn,\t\\\n      but we have no way to track that at present, so mark\t\\\n      it as unavailable.  */\t\t\t\t\t\\\n-  if (TARGET_THUMB)\t\t\t\t\t\t\\\n+  if (TARGET_THUMB1)\t\t\t\t\t\t\\\n     fixed_regs[LR_REGNUM] = call_used_regs[LR_REGNUM] = 1;\t\\\n \t\t\t\t\t\t\t\t\\\n-  if (TARGET_ARM && TARGET_HARD_FLOAT)\t\t\t\t\\\n+  if (TARGET_32BIT && TARGET_HARD_FLOAT)\t\t\t\\\n     {\t\t\t\t\t\t\t\t\\\n       if (TARGET_MAVERICK)\t\t\t\t\t\\\n \t{\t\t\t\t\t\t\t\\\n@@ -807,7 +838,7 @@ extern int arm_structure_size_boundary;\n /* The native (Norcroft) Pascal compiler for the ARM passes the static chain\n    as an invisible last argument (possible since varargs don't exist in\n    Pascal), so the following is not true.  */\n-#define STATIC_CHAIN_REGNUM\t(TARGET_ARM ? 12 : 9)\n+#define STATIC_CHAIN_REGNUM\t12\n \n /* Define this to be where the real frame pointer is if it is not possible to\n    work out the offset between the frame pointer and the automatic variables\n@@ -901,7 +932,7 @@ extern int arm_structure_size_boundary;\n    On the ARM regs are UNITS_PER_WORD bits wide; FPA regs can hold any FP\n    mode.  */\n #define HARD_REGNO_NREGS(REGNO, MODE)  \t\\\n-  ((TARGET_ARM \t\t\t\t\\\n+  ((TARGET_32BIT\t\t\t\\\n     && REGNO >= FIRST_FPA_REGNUM\t\\\n     && REGNO != FRAME_POINTER_REGNUM\t\\\n     && REGNO != ARG_POINTER_REGNUM)\t\\\n@@ -1042,14 +1073,14 @@ enum reg_class\n      || (CLASS) == CC_REG)\n \n /* The class value for index registers, and the one for base regs.  */\n-#define INDEX_REG_CLASS  (TARGET_THUMB ? LO_REGS : GENERAL_REGS)\n-#define BASE_REG_CLASS   (TARGET_THUMB ? LO_REGS : GENERAL_REGS)\n+#define INDEX_REG_CLASS  (TARGET_THUMB1 ? LO_REGS : GENERAL_REGS)\n+#define BASE_REG_CLASS   (TARGET_THUMB1 ? LO_REGS : GENERAL_REGS)\n \n /* For the Thumb the high registers cannot be used as base registers\n    when addressing quantities in QI or HI mode; if we don't know the\n    mode, then we must be conservative.  */\n #define MODE_BASE_REG_CLASS(MODE)\t\t\t\t\t\\\n-    (TARGET_ARM ? GENERAL_REGS :\t\t\t\t\t\\\n+    (TARGET_32BIT ? GENERAL_REGS :\t\t\t\t\t\\\n      (((MODE) == SImode) ? BASE_REGS : LO_REGS))\n \n /* For Thumb we can not support SP+reg addressing, so we return LO_REGS\n@@ -1060,15 +1091,16 @@ enum reg_class\n    registers explicitly used in the rtl to be used as spill registers\n    but prevents the compiler from extending the lifetime of these\n    registers.  */\n-#define SMALL_REGISTER_CLASSES   TARGET_THUMB\n+#define SMALL_REGISTER_CLASSES   TARGET_THUMB1\n \n /* Given an rtx X being reloaded into a reg required to be\n    in class CLASS, return the class of reg to actually use.\n-   In general this is just CLASS, but for the Thumb we prefer\n-   a LO_REGS class or a subset.  */\n-#define PREFERRED_RELOAD_CLASS(X, CLASS)\t\\\n-  (TARGET_ARM ? (CLASS) :\t\t\t\\\n-   ((CLASS) == BASE_REGS ? (CLASS) : LO_REGS))\n+   In general this is just CLASS, but for the Thumb core registers and\n+   immediate constants we prefer a LO_REGS class or a subset.  */\n+#define PREFERRED_RELOAD_CLASS(X, CLASS)\t\t\\\n+  (TARGET_ARM ? (CLASS) :\t\t\t\t\\\n+   ((CLASS) == GENERAL_REGS || (CLASS) == HI_REGS\t\\\n+    || (CLASS) == NO_REGS ? LO_REGS : (CLASS)))\n \n /* Must leave BASE_REGS reloads alone */\n #define THUMB_SECONDARY_INPUT_RELOAD_CLASS(CLASS, MODE, X)\t\t\\\n@@ -1093,7 +1125,7 @@ enum reg_class\n   ((TARGET_VFP && TARGET_HARD_FLOAT\t\t\t\t\\\n     && (CLASS) == VFP_REGS)\t\t\t\t\t\\\n    ? vfp_secondary_reload_class (MODE, X)\t\t\t\\\n-   : TARGET_ARM\t\t\t\t\t\t\t\\\n+   : TARGET_32BIT\t\t\t\t\t\t\\\n    ? (((MODE) == HImode && ! arm_arch4 && true_regnum (X) == -1) \\\n     ? GENERAL_REGS : NO_REGS)\t\t\t\t\t\\\n    : THUMB_SECONDARY_OUTPUT_RELOAD_CLASS (CLASS, MODE, X))\n@@ -1109,7 +1141,7 @@ enum reg_class\n      && (CLASS) == CIRRUS_REGS\t\t\t\t\t\\\n      && (CONSTANT_P (X) || GET_CODE (X) == SYMBOL_REF))\t\t\\\n     ? GENERAL_REGS :\t\t\t\t\t\t\\\n-  (TARGET_ARM ?\t\t\t\t\t\t\t\\\n+  (TARGET_32BIT ?\t\t\t\t\t\t\\\n    (((CLASS) == IWMMXT_REGS || (CLASS) == IWMMXT_GR_REGS)\t\\\n       && CONSTANT_P (X))\t\t\t\t\t\\\n    ? GENERAL_REGS :\t\t\t\t\t\t\\\n@@ -1188,6 +1220,7 @@ enum reg_class\n /* We could probably achieve better results by defining PROMOTE_MODE to help\n    cope with the variances between the Thumb's signed and unsigned byte and\n    halfword load instructions.  */\n+/* ??? This should be safe for thumb2, but we may be able to do better.  */\n #define THUMB_LEGITIMIZE_RELOAD_ADDRESS(X, MODE, OPNUM, TYPE, IND_L, WIN)     \\\n do {\t\t\t\t\t\t\t\t\t      \\\n   rtx new_x = thumb_legitimize_reload_address (&X, MODE, OPNUM, TYPE, IND_L); \\\n@@ -1215,7 +1248,7 @@ do {\t\t\t\t\t\t\t\t\t      \\\n \n /* Moves between FPA_REGS and GENERAL_REGS are two memory insns.  */\n #define REGISTER_MOVE_COST(MODE, FROM, TO)\t\t\\\n-  (TARGET_ARM ?\t\t\t\t\t\t\\\n+  (TARGET_32BIT ?\t\t\t\t\t\t\\\n    ((FROM) == FPA_REGS && (TO) != FPA_REGS ? 20 :\t\\\n     (FROM) != FPA_REGS && (TO) == FPA_REGS ? 20 :\t\\\n     (FROM) == VFP_REGS && (TO) != VFP_REGS ? 10 :  \\\n@@ -1289,10 +1322,10 @@ do {\t\t\t\t\t\t\t\t\t      \\\n /* Define how to find the value returned by a library function\n    assuming the value has mode MODE.  */\n #define LIBCALL_VALUE(MODE)  \\\n-  (TARGET_ARM && TARGET_HARD_FLOAT_ABI && TARGET_FPA\t\t\t\\\n+  (TARGET_32BIT && TARGET_HARD_FLOAT_ABI && TARGET_FPA\t\t\t\\\n    && GET_MODE_CLASS (MODE) == MODE_FLOAT\t\t\t\t\\\n    ? gen_rtx_REG (MODE, FIRST_FPA_REGNUM)\t\t\t\t\\\n-   : TARGET_ARM && TARGET_HARD_FLOAT_ABI && TARGET_MAVERICK\t\t\\\n+   : TARGET_32BIT && TARGET_HARD_FLOAT_ABI && TARGET_MAVERICK\t\t\\\n      && GET_MODE_CLASS (MODE) == MODE_FLOAT\t\t\t\t\\\n    ? gen_rtx_REG (MODE, FIRST_CIRRUS_FP_REGNUM) \t\t\t\\\n    : TARGET_IWMMXT_ABI && arm_vector_mode_supported_p (MODE)    \t\\\n@@ -1311,10 +1344,10 @@ do {\t\t\t\t\t\t\t\t\t      \\\n /* On a Cirrus chip, mvf0 can return results.  */\n #define FUNCTION_VALUE_REGNO_P(REGNO)  \\\n   ((REGNO) == ARG_REGISTER (1) \\\n-   || (TARGET_ARM && ((REGNO) == FIRST_CIRRUS_FP_REGNUM)\t\t\\\n+   || (TARGET_32BIT && ((REGNO) == FIRST_CIRRUS_FP_REGNUM)\t\t\\\n        && TARGET_HARD_FLOAT_ABI && TARGET_MAVERICK)\t\t\t\\\n    || ((REGNO) == FIRST_IWMMXT_REGNUM && TARGET_IWMMXT_ABI) \\\n-   || (TARGET_ARM && ((REGNO) == FIRST_FPA_REGNUM)\t\t\t\\\n+   || (TARGET_32BIT && ((REGNO) == FIRST_FPA_REGNUM)\t\t\t\\\n        && TARGET_HARD_FLOAT_ABI && TARGET_FPA))\n \n /* Amount of memory needed for an untyped call to save all possible return\n@@ -1362,13 +1395,15 @@ do {\t\t\t\t\t\t\t\t\t      \\\n #define ARM_FT_NAKED\t\t(1 << 3) /* No prologue or epilogue.  */\n #define ARM_FT_VOLATILE\t\t(1 << 4) /* Does not return.  */\n #define ARM_FT_NESTED\t\t(1 << 5) /* Embedded inside another func.  */\n+#define ARM_FT_STACKALIGN\t(1 << 6) /* Called with misaligned stack.  */\n \n /* Some macros to test these flags.  */\n #define ARM_FUNC_TYPE(t)\t(t & ARM_FT_TYPE_MASK)\n #define IS_INTERRUPT(t)\t\t(t & ARM_FT_INTERRUPT)\n #define IS_VOLATILE(t)     \t(t & ARM_FT_VOLATILE)\n #define IS_NAKED(t)        \t(t & ARM_FT_NAKED)\n #define IS_NESTED(t)       \t(t & ARM_FT_NESTED)\n+#define IS_STACKALIGN(t)       \t(t & ARM_FT_STACKALIGN)\n \n \n /* Structure used to hold the function stack frame layout.  Offsets are\n@@ -1570,6 +1605,8 @@ typedef struct\n \n /* Determine if the epilogue should be output as RTL.\n    You should override this if you define FUNCTION_EXTRA_EPILOGUE.  */\n+/* This is disabled for Thumb-2 because it will confuse the\n+   conditional insn counter.  */\n #define USE_RETURN_INSN(ISCOND)\t\t\t\t\\\n   (TARGET_ARM ? use_return_insn (ISCOND, NULL) : 0)\n \n@@ -1646,37 +1683,57 @@ typedef struct\n   assemble_aligned_integer (UNITS_PER_WORD, const0_rtx);\t\\\n }\n \n-/* On the Thumb we always switch into ARM mode to execute the trampoline.\n-   Why - because it is easier.  This code will always be branched to via\n-   a BX instruction and since the compiler magically generates the address\n-   of the function the linker has no opportunity to ensure that the\n-   bottom bit is set.  Thus the processor will be in ARM mode when it\n-   reaches this code.  So we duplicate the ARM trampoline code and add\n-   a switch into Thumb mode as well.  */\n-#define THUMB_TRAMPOLINE_TEMPLATE(FILE)\t\t\\\n+/* The Thumb-2 trampoline is similar to the arm implementation.\n+   Unlike 16-bit Thumb, we enter the stub in thumb mode.  */\n+#define THUMB2_TRAMPOLINE_TEMPLATE(FILE)\t\t\t\\\n+{\t\t\t\t\t\t\t\t\\\n+  asm_fprintf (FILE, \"\\tldr.w\\t%r, [%r, #4]\\n\",\t\t\t\\\n+\t       STATIC_CHAIN_REGNUM, PC_REGNUM);\t\t\t\\\n+  asm_fprintf (FILE, \"\\tldr.w\\t%r, [%r, #4]\\n\",\t\t\t\\\n+\t       PC_REGNUM, PC_REGNUM);\t\t\t\t\\\n+  assemble_aligned_integer (UNITS_PER_WORD, const0_rtx);\t\\\n+  assemble_aligned_integer (UNITS_PER_WORD, const0_rtx);\t\\\n+}\n+\n+#define THUMB1_TRAMPOLINE_TEMPLATE(FILE)\t\\\n {\t\t\t\t\t\t\\\n-  fprintf (FILE, \"\\t.code 32\\n\");\t\t\\\n+  ASM_OUTPUT_ALIGN(FILE, 2);\t\t\t\\\n+  fprintf (FILE, \"\\t.code\\t16\\n\");\t\t\\\n   fprintf (FILE, \".Ltrampoline_start:\\n\");\t\\\n-  asm_fprintf (FILE, \"\\tldr\\t%r, [%r, #8]\\n\",\t\\\n-\t       STATIC_CHAIN_REGNUM, PC_REGNUM);\t\\\n-  asm_fprintf (FILE, \"\\tldr\\t%r, [%r, #8]\\n\",\t\\\n-\t       IP_REGNUM, PC_REGNUM);\t\t\\\n-  asm_fprintf (FILE, \"\\torr\\t%r, %r, #1\\n\",     \\\n-\t       IP_REGNUM, IP_REGNUM);     \t\\\n-  asm_fprintf (FILE, \"\\tbx\\t%r\\n\", IP_REGNUM);\t\\\n-  fprintf (FILE, \"\\t.word\\t0\\n\");\t\t\\\n-  fprintf (FILE, \"\\t.word\\t0\\n\");\t\t\\\n-  fprintf (FILE, \"\\t.code 16\\n\");\t\t\\\n+  asm_fprintf (FILE, \"\\tpush\\t{r0, r1}\\n\");\t\\\n+  asm_fprintf (FILE, \"\\tldr\\tr0, [%r, #8]\\n\",\t\\\n+\t       PC_REGNUM);\t\t\t\\\n+  asm_fprintf (FILE, \"\\tmov\\t%r, r0\\n\",\t\t\\\n+\t       STATIC_CHAIN_REGNUM);\t\t\\\n+  asm_fprintf (FILE, \"\\tldr\\tr0, [%r, #8]\\n\",\t\\\n+\t       PC_REGNUM);\t\t\t\\\n+  asm_fprintf (FILE, \"\\tstr\\tr0, [%r, #4]\\n\",\t\\\n+\t       SP_REGNUM);\t\t\t\\\n+  asm_fprintf (FILE, \"\\tpop\\t{r0, %r}\\n\",\t\\\n+\t       PC_REGNUM);\t\t\t\\\n+  assemble_aligned_integer (UNITS_PER_WORD, const0_rtx);\t\\\n+  assemble_aligned_integer (UNITS_PER_WORD, const0_rtx);\t\\\n }\n \n #define TRAMPOLINE_TEMPLATE(FILE)\t\t\\\n   if (TARGET_ARM)\t\t\t\t\\\n     ARM_TRAMPOLINE_TEMPLATE (FILE)\t\t\\\n+  else if (TARGET_THUMB2)\t\t\t\\\n+    THUMB2_TRAMPOLINE_TEMPLATE (FILE)\t\t\\\n   else\t\t\t\t\t\t\\\n-    THUMB_TRAMPOLINE_TEMPLATE (FILE)\n+    THUMB1_TRAMPOLINE_TEMPLATE (FILE)\n+\n+/* Thumb trampolines should be entered in thumb mode, so set the bottom bit\n+   of the address.  */\n+#define TRAMPOLINE_ADJUST_ADDRESS(ADDR) do\t\t\t\t    \\\n+{\t\t\t\t\t\t\t\t\t    \\\n+  if (TARGET_THUMB)\t\t\t\t\t\t\t    \\\n+    (ADDR) = expand_simple_binop (Pmode, IOR, (ADDR), GEN_INT(1),\t    \\\n+\t\t\t\t  gen_reg_rtx (Pmode), 0, OPTAB_LIB_WIDEN); \\\n+} while(0)\n \n /* Length in units of the trampoline for entering a nested function.  */\n-#define TRAMPOLINE_SIZE  (TARGET_ARM ? 16 : 24)\n+#define TRAMPOLINE_SIZE  (TARGET_32BIT ? 16 : 20)\n \n /* Alignment required for a trampoline in bits.  */\n #define TRAMPOLINE_ALIGNMENT  32\n@@ -1690,11 +1747,11 @@ typedef struct\n {\t\t\t\t\t\t\t\t\t\\\n   emit_move_insn (gen_rtx_MEM (SImode,\t\t\t\t\t\\\n \t\t\t       plus_constant (TRAMP,\t\t\t\\\n-\t\t\t\t\t      TARGET_ARM ? 8 : 16)),\t\\\n+\t\t\t\t\t      TARGET_32BIT ? 8 : 12)),\t\\\n \t\t  CXT);\t\t\t\t\t\t\t\\\n   emit_move_insn (gen_rtx_MEM (SImode,\t\t\t\t\t\\\n \t\t\t       plus_constant (TRAMP,\t\t\t\\\n-\t\t\t\t\t      TARGET_ARM ? 12 : 20)),\t\\\n+\t\t\t\t\t      TARGET_32BIT ? 12 : 16)),\t\\\n \t\t  FNADDR);\t\t\t\t\t\t\\\n   emit_library_call (gen_rtx_SYMBOL_REF (Pmode, \"__clear_cache\"),\t\\\n \t\t     0, VOIDmode, 2, TRAMP, Pmode,\t\t\t\\\n@@ -1705,13 +1762,13 @@ typedef struct\n \f\n /* Addressing modes, and classification of registers for them.  */\n #define HAVE_POST_INCREMENT   1\n-#define HAVE_PRE_INCREMENT    TARGET_ARM\n-#define HAVE_POST_DECREMENT   TARGET_ARM\n-#define HAVE_PRE_DECREMENT    TARGET_ARM\n-#define HAVE_PRE_MODIFY_DISP  TARGET_ARM\n-#define HAVE_POST_MODIFY_DISP TARGET_ARM\n-#define HAVE_PRE_MODIFY_REG   TARGET_ARM\n-#define HAVE_POST_MODIFY_REG  TARGET_ARM\n+#define HAVE_PRE_INCREMENT    TARGET_32BIT\n+#define HAVE_POST_DECREMENT   TARGET_32BIT\n+#define HAVE_PRE_DECREMENT    TARGET_32BIT\n+#define HAVE_PRE_MODIFY_DISP  TARGET_32BIT\n+#define HAVE_POST_MODIFY_DISP TARGET_32BIT\n+#define HAVE_PRE_MODIFY_REG   TARGET_32BIT\n+#define HAVE_POST_MODIFY_REG  TARGET_32BIT\n \n /* Macros to check register numbers against specific register classes.  */\n \n@@ -1723,20 +1780,20 @@ typedef struct\n #define TEST_REGNO(R, TEST, VALUE) \\\n   ((R TEST VALUE) || ((unsigned) reg_renumber[R] TEST VALUE))\n \n-/*   On the ARM, don't allow the pc to be used.  */\n+/* Don't allow the pc to be used.  */\n #define ARM_REGNO_OK_FOR_BASE_P(REGNO)\t\t\t\\\n   (TEST_REGNO (REGNO, <, PC_REGNUM)\t\t\t\\\n    || TEST_REGNO (REGNO, ==, FRAME_POINTER_REGNUM)\t\\\n    || TEST_REGNO (REGNO, ==, ARG_POINTER_REGNUM))\n \n-#define THUMB_REGNO_MODE_OK_FOR_BASE_P(REGNO, MODE)\t\t\\\n+#define THUMB1_REGNO_MODE_OK_FOR_BASE_P(REGNO, MODE)\t\t\\\n   (TEST_REGNO (REGNO, <=, LAST_LO_REGNUM)\t\t\t\\\n    || (GET_MODE_SIZE (MODE) >= 4\t\t\t\t\\\n        && TEST_REGNO (REGNO, ==, STACK_POINTER_REGNUM)))\n \n #define REGNO_MODE_OK_FOR_BASE_P(REGNO, MODE)\t\t\\\n-  (TARGET_THUMB\t\t\t\t\t\t\\\n-   ? THUMB_REGNO_MODE_OK_FOR_BASE_P (REGNO, MODE)\t\\\n+  (TARGET_THUMB1\t\t\t\t\t\\\n+   ? THUMB1_REGNO_MODE_OK_FOR_BASE_P (REGNO, MODE)\t\\\n    : ARM_REGNO_OK_FOR_BASE_P (REGNO))\n \n /* Nonzero if X can be the base register in a reg+reg addressing mode.\n@@ -1763,6 +1820,7 @@ typedef struct\n \n #else\n \n+/* ??? Should the TARGET_ARM here also apply to thumb2?  */\n #define CONSTANT_ADDRESS_P(X)  \t\t\t\\\n   (GET_CODE (X) == SYMBOL_REF \t\t\t\\\n    && (CONSTANT_POOL_ADDRESS_P (X)\t\t\\\n@@ -1788,8 +1846,8 @@ typedef struct\n \n #define LEGITIMATE_CONSTANT_P(X)\t\t\t\\\n   (!arm_tls_referenced_p (X)\t\t\t\t\\\n-   && (TARGET_ARM ? ARM_LEGITIMATE_CONSTANT_P (X)\t\\\n-\t\t  : THUMB_LEGITIMATE_CONSTANT_P (X)))\n+   && (TARGET_32BIT ? ARM_LEGITIMATE_CONSTANT_P (X)\t\\\n+\t\t    : THUMB_LEGITIMATE_CONSTANT_P (X)))\n \n /* Special characters prefixed to function names\n    in order to encode attribute like information.\n@@ -1823,6 +1881,11 @@ typedef struct\n #define ASM_OUTPUT_LABELREF(FILE, NAME)\t\t\\\n    arm_asm_output_labelref (FILE, NAME)\n \n+/* Output IT instructions for conditonally executed Thumb-2 instructions.  */\n+#define ASM_OUTPUT_OPCODE(STREAM, PTR)\t\\\n+  if (TARGET_THUMB2)\t\t\t\\\n+    thumb2_asm_output_opcode (STREAM);\n+\n /* The EABI specifies that constructors should go in .init_array.\n    Other targets use .ctors for compatibility.  */\n #ifndef ARM_EABI_CTORS_SECTION_OP\n@@ -1898,7 +1961,8 @@ typedef struct\n    We have two alternate definitions for each of them.\n    The usual definition accepts all pseudo regs; the other rejects\n    them unless they have been allocated suitable hard regs.\n-   The symbol REG_OK_STRICT causes the latter definition to be used.  */\n+   The symbol REG_OK_STRICT causes the latter definition to be used.\n+   Thumb-2 has the same restictions as arm.  */\n #ifndef REG_OK_STRICT\n \n #define ARM_REG_OK_FOR_BASE_P(X)\t\t\\\n@@ -1907,7 +1971,7 @@ typedef struct\n    || REGNO (X) == FRAME_POINTER_REGNUM\t\t\\\n    || REGNO (X) == ARG_POINTER_REGNUM)\n \n-#define THUMB_REG_MODE_OK_FOR_BASE_P(X, MODE)\t\\\n+#define THUMB1_REG_MODE_OK_FOR_BASE_P(X, MODE)\t\\\n   (REGNO (X) <= LAST_LO_REGNUM\t\t\t\\\n    || REGNO (X) >= FIRST_PSEUDO_REGISTER\t\\\n    || (GET_MODE_SIZE (MODE) >= 4\t\t\\\n@@ -1922,8 +1986,8 @@ typedef struct\n #define ARM_REG_OK_FOR_BASE_P(X) \t\t\\\n   ARM_REGNO_OK_FOR_BASE_P (REGNO (X))\n \n-#define THUMB_REG_MODE_OK_FOR_BASE_P(X, MODE)\t\\\n-  THUMB_REGNO_MODE_OK_FOR_BASE_P (REGNO (X), MODE)\n+#define THUMB1_REG_MODE_OK_FOR_BASE_P(X, MODE)\t\\\n+  THUMB1_REGNO_MODE_OK_FOR_BASE_P (REGNO (X), MODE)\n \n #define REG_STRICT_P 1\n \n@@ -1932,22 +1996,23 @@ typedef struct\n /* Now define some helpers in terms of the above.  */\n \n #define REG_MODE_OK_FOR_BASE_P(X, MODE)\t\t\\\n-  (TARGET_THUMB\t\t\t\t\t\\\n-   ? THUMB_REG_MODE_OK_FOR_BASE_P (X, MODE)\t\\\n+  (TARGET_THUMB1\t\t\t\t\\\n+   ? THUMB1_REG_MODE_OK_FOR_BASE_P (X, MODE)\t\\\n    : ARM_REG_OK_FOR_BASE_P (X))\n \n #define ARM_REG_OK_FOR_INDEX_P(X) ARM_REG_OK_FOR_BASE_P (X)\n \n-/* For Thumb, a valid index register is anything that can be used in\n+/* For 16-bit Thumb, a valid index register is anything that can be used in\n    a byte load instruction.  */\n-#define THUMB_REG_OK_FOR_INDEX_P(X) THUMB_REG_MODE_OK_FOR_BASE_P (X, QImode)\n+#define THUMB1_REG_OK_FOR_INDEX_P(X) \\\n+  THUMB1_REG_MODE_OK_FOR_BASE_P (X, QImode)\n \n /* Nonzero if X is a hard reg that can be used as an index\n    or if it is a pseudo reg.  On the Thumb, the stack pointer\n    is not suitable.  */\n #define REG_OK_FOR_INDEX_P(X)\t\t\t\\\n-  (TARGET_THUMB\t\t\t\t\t\\\n-   ? THUMB_REG_OK_FOR_INDEX_P (X)\t\t\\\n+  (TARGET_THUMB1\t\t\t\t\\\n+   ? THUMB1_REG_OK_FOR_INDEX_P (X)\t\t\\\n    : ARM_REG_OK_FOR_INDEX_P (X))\n \n /* Nonzero if X can be the base register in a reg+reg addressing mode.\n@@ -1972,17 +2037,25 @@ typedef struct\n       goto WIN;\t\t\t\t\t\t\t\\\n   }\n \n-#define THUMB_GO_IF_LEGITIMATE_ADDRESS(MODE,X,WIN)\t\t\\\n+#define THUMB2_GO_IF_LEGITIMATE_ADDRESS(MODE,X,WIN)\t\t\\\n   {\t\t\t\t\t\t\t\t\\\n-    if (thumb_legitimate_address_p (MODE, X, REG_STRICT_P))\t\\\n+    if (thumb2_legitimate_address_p (MODE, X, REG_STRICT_P))\t\\\n+      goto WIN;\t\t\t\t\t\t\t\\\n+  }\n+\n+#define THUMB1_GO_IF_LEGITIMATE_ADDRESS(MODE,X,WIN)\t\t\\\n+  {\t\t\t\t\t\t\t\t\\\n+    if (thumb1_legitimate_address_p (MODE, X, REG_STRICT_P))\t\\\n       goto WIN;\t\t\t\t\t\t\t\\\n   }\n \n #define GO_IF_LEGITIMATE_ADDRESS(MODE, X, WIN)\t\t\t\t\\\n   if (TARGET_ARM)\t\t\t\t\t\t\t\\\n     ARM_GO_IF_LEGITIMATE_ADDRESS (MODE, X, WIN)  \t\t\t\\\n-  else /* if (TARGET_THUMB) */\t\t\t\t\t\t\\\n-    THUMB_GO_IF_LEGITIMATE_ADDRESS (MODE, X, WIN)\n+  else if (TARGET_THUMB2)\t\t\t\t\t\t\\\n+    THUMB2_GO_IF_LEGITIMATE_ADDRESS (MODE, X, WIN)  \t\t\t\\\n+  else /* if (TARGET_THUMB1) */\t\t\t\t\t\t\\\n+    THUMB1_GO_IF_LEGITIMATE_ADDRESS (MODE, X, WIN)\n \n \f\n /* Try machine-dependent ways of modifying an illegitimate address\n@@ -1992,7 +2065,12 @@ do {\t\t\t\t\t\t\t\\\n   X = arm_legitimize_address (X, OLDX, MODE);\t\t\\\n } while (0)\n \n-#define THUMB_LEGITIMIZE_ADDRESS(X, OLDX, MODE, WIN)\t\\\n+/* ??? Implement LEGITIMIZE_ADDRESS for thumb2.  */\n+#define THUMB2_LEGITIMIZE_ADDRESS(X, OLDX, MODE, WIN)\t\\\n+do {\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+#define THUMB1_LEGITIMIZE_ADDRESS(X, OLDX, MODE, WIN)\t\\\n do {\t\t\t\t\t\t\t\\\n   X = thumb_legitimize_address (X, OLDX, MODE);\t\t\\\n } while (0)\n@@ -2001,8 +2079,10 @@ do {\t\t\t\t\t\t\t\\\n do {\t\t\t\t\t\t\t\\\n   if (TARGET_ARM)\t\t\t\t\t\\\n     ARM_LEGITIMIZE_ADDRESS (X, OLDX, MODE, WIN);\t\\\n+  else if (TARGET_THUMB2)\t\t\t\t\\\n+    THUMB2_LEGITIMIZE_ADDRESS (X, OLDX, MODE, WIN);\t\\\n   else\t\t\t\t\t\t\t\\\n-    THUMB_LEGITIMIZE_ADDRESS (X, OLDX, MODE, WIN);\t\\\n+    THUMB1_LEGITIMIZE_ADDRESS (X, OLDX, MODE, WIN);\t\\\n \t\t\t\t\t\t\t\\\n   if (memory_address_p (MODE, X))\t\t\t\\\n     goto WIN;\t\t\t\t\t\t\\\n@@ -2019,14 +2099,21 @@ do {\t\t\t\t\t\t\t\\\n \n /* Nothing helpful to do for the Thumb */\n #define GO_IF_MODE_DEPENDENT_ADDRESS(ADDR, LABEL)\t\\\n-  if (TARGET_ARM)\t\t\t\t\t\\\n+  if (TARGET_32BIT)\t\t\t\t\t\\\n     ARM_GO_IF_MODE_DEPENDENT_ADDRESS (ADDR, LABEL)\n \f\n \n /* Specify the machine mode that this machine uses\n    for the index in the tablejump instruction.  */\n #define CASE_VECTOR_MODE Pmode\n \n+#define CASE_VECTOR_PC_RELATIVE TARGET_THUMB2\n+\n+#define CASE_VECTOR_SHORTEN_MODE(min, max, body)\t\t\\\n+   ((min < 0 || max >= 0x2000 || !TARGET_THUMB2) ? SImode\t\\\n+   : (max >= 0x200) ? HImode\t\t\t\t\t\\\n+   : QImode)\n+\n /* signed 'char' is most compatible, but RISC OS wants it unsigned.\n    unsigned is probably best, but may break some code.  */\n #ifndef DEFAULT_SIGNED_CHAR\n@@ -2085,14 +2172,14 @@ do {\t\t\t\t\t\t\t\\\n \n /* Moves to and from memory are quite expensive */\n #define MEMORY_MOVE_COST(M, CLASS, IN)\t\t\t\\\n-  (TARGET_ARM ? 10 :\t\t\t\t\t\\\n+  (TARGET_32BIT ? 10 :\t\t\t\t\t\\\n    ((GET_MODE_SIZE (M) < 4 ? 8 : 2 * GET_MODE_SIZE (M))\t\\\n     * (CLASS == LO_REGS ? 1 : 2)))\n \n /* Try to generate sequences that don't involve branches, we can then use\n    conditional instructions */\n #define BRANCH_COST \\\n-  (TARGET_ARM ? 4 : (optimize > 0 ? 2 : 0))\n+  (TARGET_32BIT ? 4 : (optimize > 0 ? 2 : 0))\n \f\n /* Position Independent Code.  */\n /* We decide which register to use based on the compilation options and\n@@ -2160,7 +2247,8 @@ extern int making_const_table;\n #define CLZ_DEFINED_VALUE_AT_ZERO(MODE, VALUE)  ((VALUE) = 32, 1)\n \f\n #undef  ASM_APP_OFF\n-#define ASM_APP_OFF (TARGET_THUMB ? \"\\t.code\\t16\\n\" : \"\")\n+#define ASM_APP_OFF (TARGET_THUMB1 ? \"\\t.code\\t16\\n\" : \\\n+\t\t     TARGET_THUMB2 ? \"\\t.thumb\\n\" : \"\")\n \n /* Output a push or a pop instruction (only used when profiling).  */\n #define ASM_OUTPUT_REG_PUSH(STREAM, REGNO)\t\t\\\n@@ -2184,28 +2272,42 @@ extern int making_const_table;\n \tasm_fprintf (STREAM, \"\\tpop {%r}\\n\", REGNO);\t\\\n     } while (0)\n \n+/* Jump table alignment is explicit in ASM_OUTPUT_CASE_LABEL.  */\n+#define ADDR_VEC_ALIGN(JUMPTABLE) 0\n+\n /* This is how to output a label which precedes a jumptable.  Since\n    Thumb instructions are 2 bytes, we may need explicit alignment here.  */\n #undef  ASM_OUTPUT_CASE_LABEL\n-#define ASM_OUTPUT_CASE_LABEL(FILE, PREFIX, NUM, JUMPTABLE)\t\\\n-  do\t\t\t\t\t\t\t\t\\\n-    {\t\t\t\t\t\t\t\t\\\n-      if (TARGET_THUMB)\t\t\t\t\t\t\\\n-        ASM_OUTPUT_ALIGN (FILE, 2);\t\t\t\t\\\n-      (*targetm.asm_out.internal_label) (FILE, PREFIX, NUM);\t\\\n-    }\t\t\t\t\t\t\t\t\\\n+#define ASM_OUTPUT_CASE_LABEL(FILE, PREFIX, NUM, JUMPTABLE)\t\t\\\n+  do\t\t\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      if (TARGET_THUMB && GET_MODE (PATTERN (JUMPTABLE)) == SImode)\t\\\n+        ASM_OUTPUT_ALIGN (FILE, 2);\t\t\t\t\t\\\n+      (*targetm.asm_out.internal_label) (FILE, PREFIX, NUM);\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+  while (0)\n+\n+/* Make sure subsequent insns are aligned after a TBB.  */\n+#define ASM_OUTPUT_CASE_END(FILE, NUM, JUMPTABLE)\t\\\n+  do\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\\\n+      if (GET_MODE (PATTERN (JUMPTABLE)) == QImode)\t\\\n+\tASM_OUTPUT_ALIGN (FILE, 1);\t\t\t\\\n+    }\t\t\t\t\t\t\t\\\n   while (0)\n \n #define ARM_DECLARE_FUNCTION_NAME(STREAM, NAME, DECL) \t\\\n   do\t\t\t\t\t\t\t\\\n     {\t\t\t\t\t\t\t\\\n       if (TARGET_THUMB) \t\t\t\t\\\n         {\t\t\t\t\t\t\\\n-          if (is_called_in_ARM_mode (DECL)      \\\n-\t\t\t  || current_function_is_thunk)\t\t\\\n+          if (is_called_in_ARM_mode (DECL)\t\t\\\n+\t      || (TARGET_THUMB1 && current_function_is_thunk))\t\\\n             fprintf (STREAM, \"\\t.code 32\\n\") ;\t\t\\\n+          else if (TARGET_THUMB1)\t\t\t\\\n+           fprintf (STREAM, \"\\t.code\\t16\\n\\t.thumb_func\\n\") ;\t\\\n           else\t\t\t\t\t\t\\\n-           fprintf (STREAM, \"\\t.code 16\\n\\t.thumb_func\\n\") ;\t\\\n+           fprintf (STREAM, \"\\t.thumb\\n\\t.thumb_func\\n\") ;\t\\\n         }\t\t\t\t\t\t\\\n       if (TARGET_POKE_FUNCTION_NAME)\t\t\t\\\n         arm_poke_function_name (STREAM, (char *) NAME);\t\\\n@@ -2247,17 +2349,28 @@ extern int making_const_table;\n     }\n #endif\n \f\n+/* Add two bytes to the length of conditionally executed Thumb-2\n+   instructions for the IT instruction.  */\n+#define ADJUST_INSN_LENGTH(insn, length) \\\n+  if (TARGET_THUMB2 && GET_CODE (PATTERN (insn)) == COND_EXEC) \\\n+    length += 2;\n+\n /* Only perform branch elimination (by making instructions conditional) if\n-   we're optimizing.  Otherwise it's of no use anyway.  */\n+   we're optimizing.  For Thumb-2 check if any IT instructions need\n+   outputting.  */\n #define FINAL_PRESCAN_INSN(INSN, OPVEC, NOPERANDS)\t\\\n   if (TARGET_ARM && optimize)\t\t\t\t\\\n     arm_final_prescan_insn (INSN);\t\t\t\\\n-  else if (TARGET_THUMB)\t\t\t\t\\\n-    thumb_final_prescan_insn (INSN)\n+  else if (TARGET_THUMB2)\t\t\t\t\\\n+    thumb2_final_prescan_insn (INSN);\t\t\t\\\n+  else if (TARGET_THUMB1)\t\t\t\t\\\n+    thumb1_final_prescan_insn (INSN)\n \n #define PRINT_OPERAND_PUNCT_VALID_P(CODE)\t\\\n-  (CODE == '@' || CODE == '|'\t\t\t\\\n-   || (TARGET_ARM   && (CODE == '?'))\t\t\\\n+  (CODE == '@' || CODE == '|' || CODE == '.'\t\\\n+   || CODE == '(' || CODE == ')'\t\t\\\n+   || (TARGET_32BIT && (CODE == '?'))\t\t\\\n+   || (TARGET_THUMB2 && (CODE == '!'))\t\t\\\n    || (TARGET_THUMB && (CODE == '_')))\n \n /* Output an operand of an instruction.  */\n@@ -2390,7 +2503,7 @@ extern int making_const_table;\n }\n \n #define PRINT_OPERAND_ADDRESS(STREAM, X)\t\\\n-  if (TARGET_ARM)\t\t\t\t\\\n+  if (TARGET_32BIT)\t\t\t\t\\\n     ARM_PRINT_OPERAND_ADDRESS (STREAM, X)\t\\\n   else\t\t\t\t\t\t\\\n     THUMB_PRINT_OPERAND_ADDRESS (STREAM, X)"}, {"sha": "7253f0c1517d1d9291cb5e206e8154ee4f30c4d2", "filename": "gcc/config/arm/arm.md", "status": "modified", "additions": 668, "deletions": 508, "changes": 1176, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Farm.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5"}, {"sha": "c9f6d21c06dbd5fe3ca68d8fce5fd6e74978c1f9", "filename": "gcc/config/arm/bpabi.S", "status": "modified", "additions": 23, "deletions": 6, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fbpabi.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fbpabi.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fbpabi.S?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,6 +1,6 @@\n /* Miscellaneous BPABI functions.\n \n-   Copyright (C) 2003, 2004  Free Software Foundation, Inc.\n+   Copyright (C) 2003, 2004, 2007  Free Software Foundation, Inc.\n    Contributed by CodeSourcery, LLC.\n \n    This file is free software; you can redistribute it and/or modify it\n@@ -44,7 +44,8 @@\n ARM_FUNC_START aeabi_lcmp\n \tsubs\tip, xxl, yyl\n \tsbcs\tip, xxh, yyh\n-\tsubeqs  ip, xxl, yyl\n+\tdo_it\teq\n+\tCOND(sub,s,eq)  ip, xxl, yyl\n \tmov\tr0, ip\n \tRET\n \tFUNC_END aeabi_lcmp\n@@ -55,12 +56,18 @@ ARM_FUNC_START aeabi_lcmp\n \n ARM_FUNC_START aeabi_ulcmp\n \tcmp\txxh, yyh\n+\tdo_it\tlo\n \tmovlo\tr0, #-1\n+\tdo_it\thi\n \tmovhi\tr0, #1\n+\tdo_it\tne\n \tRETc(ne)\n \tcmp\txxl, yyl\n+\tdo_it\tlo\n \tmovlo\tr0, #-1\n+\tdo_it\thi\n \tmovhi\tr0, #1\n+\tdo_it\teq\n \tmoveq\tr0, #0\n \tRET\n \tFUNC_END aeabi_ulcmp\n@@ -71,11 +78,16 @@ ARM_FUNC_START aeabi_ulcmp\n \n ARM_FUNC_START aeabi_ldivmod\n \tsub sp, sp, #8\n-\tstmfd sp!, {sp, lr}\n+#if defined(__thumb2__)\n+\tmov ip, sp\n+\tpush {ip, lr}\n+#else\n+\tdo_push {sp, lr}\n+#endif\n \tbl SYM(__gnu_ldivmod_helper) __PLT__\n \tldr lr, [sp, #4]\n \tadd sp, sp, #8\n-\tldmfd sp!, {r2, r3}\n+\tdo_pop {r2, r3}\n \tRET\n \t\n #endif /* L_aeabi_ldivmod */\n@@ -84,11 +96,16 @@ ARM_FUNC_START aeabi_ldivmod\n \n ARM_FUNC_START aeabi_uldivmod\n \tsub sp, sp, #8\n-\tstmfd sp!, {sp, lr}\n+#if defined(__thumb2__)\n+\tmov ip, sp\n+\tpush {ip, lr}\n+#else\n+\tdo_push {sp, lr}\n+#endif\n \tbl SYM(__gnu_uldivmod_helper) __PLT__\n \tldr lr, [sp, #4]\n \tadd sp, sp, #8\n-\tldmfd sp!, {r2, r3}\n+\tdo_pop {r2, r3}\n \tRET\n \t\n #endif /* L_aeabi_divmod */"}, {"sha": "e7b3015d820da01131f29d54e448b7e92f9fc962", "filename": "gcc/config/arm/cirrus.md", "status": "modified", "additions": 145, "deletions": 37, "changes": 182, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fcirrus.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fcirrus.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcirrus.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n ;; Cirrus EP9312 \"Maverick\" ARM floating point co-processor description.\n-;; Copyright (C) 2003, 2004, 2005 Free Software Foundation, Inc.\n+;; Copyright (C) 2003, 2004, 2005, 2007 Free Software Foundation, Inc.\n ;; Contributed by Red Hat.\n ;; Written by Aldy Hernandez (aldyh@redhat.com)\n \n@@ -34,7 +34,7 @@\n   [(set (match_operand:DI          0 \"cirrus_fp_register\" \"=v\")\n \t(plus:DI (match_operand:DI 1 \"cirrus_fp_register\"  \"v\")\n \t\t (match_operand:DI 2 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfadd64%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -44,7 +44,7 @@\n   [(set (match_operand:SI          0 \"cirrus_fp_register\" \"=v\")\n \t(plus:SI (match_operand:SI 1 \"cirrus_fp_register\" \"v\")\n \t\t (match_operand:SI 2 \"cirrus_fp_register\" \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfadd32%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -54,7 +54,7 @@\n   [(set (match_operand:SF          0 \"cirrus_fp_register\" \"=v\")\n \t(plus:SF (match_operand:SF 1 \"cirrus_fp_register\" \"v\")\n \t\t (match_operand:SF 2 \"cirrus_fp_register\" \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfadds%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -64,7 +64,7 @@\n   [(set (match_operand:DF          0 \"cirrus_fp_register\" \"=v\")\n \t(plus:DF (match_operand:DF 1 \"cirrus_fp_register\" \"v\")\n \t\t (match_operand:DF 2 \"cirrus_fp_register\" \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfaddd%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -74,7 +74,7 @@\n   [(set (match_operand:DI           0 \"cirrus_fp_register\" \"=v\")\n \t(minus:DI (match_operand:DI 1 \"cirrus_fp_register\"  \"v\")\n \t\t  (match_operand:DI 2 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfsub64%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -84,7 +84,7 @@\n   [(set (match_operand:SI           0 \"cirrus_fp_register\" \"=v\")\n \t(minus:SI (match_operand:SI 1 \"cirrus_fp_register\" \"v\")\n \t\t  (match_operand:SI 2 \"cirrus_fp_register\" \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfsub32%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -94,7 +94,7 @@\n   [(set (match_operand:SF           0 \"cirrus_fp_register\" \"=v\")\n \t(minus:SF (match_operand:SF 1 \"cirrus_fp_register\"  \"v\")\n \t\t  (match_operand:SF 2 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfsubs%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -104,7 +104,7 @@\n   [(set (match_operand:DF           0 \"cirrus_fp_register\" \"=v\")\n \t(minus:DF (match_operand:DF 1 \"cirrus_fp_register\" \"v\")\n \t\t  (match_operand:DF 2 \"cirrus_fp_register\" \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfsubd%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -114,7 +114,7 @@\n   [(set (match_operand:SI          0 \"cirrus_fp_register\" \"=v\")\n \t(mult:SI (match_operand:SI 2 \"cirrus_fp_register\"  \"v\")\n \t\t (match_operand:SI 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfmul32%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -124,7 +124,7 @@\n   [(set (match_operand:DI          0 \"cirrus_fp_register\" \"=v\")\n \t(mult:DI (match_operand:DI 2 \"cirrus_fp_register\"  \"v\")\n \t\t (match_operand:DI 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfmul64%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_dmult\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -136,7 +136,7 @@\n \t  (mult:SI (match_operand:SI 1 \"cirrus_fp_register\"  \"v\")\n \t\t   (match_operand:SI 2 \"cirrus_fp_register\"  \"v\"))\n \t  (match_operand:SI          3 \"cirrus_fp_register\"  \"0\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfmac32%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -149,7 +149,7 @@\n \t  (match_operand:SI          1 \"cirrus_fp_register\"  \"0\")\n \t  (mult:SI (match_operand:SI 2 \"cirrus_fp_register\"  \"v\")\n \t\t   (match_operand:SI 3 \"cirrus_fp_register\"  \"v\"))))]\n-  \"0 && TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"0 && TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfmsc32%?\\\\t%V0, %V2, %V3\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -159,7 +159,7 @@\n   [(set (match_operand:SF          0 \"cirrus_fp_register\" \"=v\")\n \t(mult:SF (match_operand:SF 1 \"cirrus_fp_register\"  \"v\")\n \t\t (match_operand:SF 2 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfmuls%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_farith\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -169,7 +169,7 @@\n   [(set (match_operand:DF          0 \"cirrus_fp_register\" \"=v\")\n \t(mult:DF (match_operand:DF 1 \"cirrus_fp_register\"  \"v\")\n \t\t (match_operand:DF 2 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfmuld%?\\\\t%V0, %V1, %V2\"\n   [(set_attr \"type\" \"mav_dmult\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -179,7 +179,7 @@\n   [(set (match_operand:SI            0 \"cirrus_fp_register\" \"=v\")\n \t(ashift:SI (match_operand:SI 1 \"cirrus_fp_register\"  \"v\")\n \t\t   (match_operand:SI 2 \"cirrus_shift_const\"  \"\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfsh32%?\\\\t%V0, %V1, #%s2\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -188,7 +188,7 @@\n   [(set (match_operand:SI\t       0 \"cirrus_fp_register\" \"=v\")\n \t(ashiftrt:SI (match_operand:SI 1 \"cirrus_fp_register\"  \"v\")\n \t\t     (match_operand:SI 2 \"cirrus_shift_const\"  \"\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfsh32%?\\\\t%V0, %V1, #-%s2\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -197,7 +197,7 @@\n   [(set (match_operand:SI            0 \"cirrus_fp_register\" \"=v\")\n \t(ashift:SI (match_operand:SI 1 \"cirrus_fp_register\"  \"v\")\n \t\t   (match_operand:SI 2 \"register_operand\"    \"r\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfrshl32%?\\\\t%V1, %V0, %s2\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -206,7 +206,7 @@\n   [(set (match_operand:DI            0 \"cirrus_fp_register\" \"=v\")\n \t(ashift:DI (match_operand:DI 1 \"cirrus_fp_register\"  \"v\")\n \t\t   (match_operand:SI 2 \"register_operand\"    \"r\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfrshl64%?\\\\t%V1, %V0, %s2\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -215,7 +215,7 @@\n   [(set (match_operand:DI            0 \"cirrus_fp_register\" \"=v\")\n \t(ashift:DI (match_operand:DI 1 \"cirrus_fp_register\"  \"v\")\n \t\t   (match_operand:SI 2 \"cirrus_shift_const\"  \"\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfsh64%?\\\\t%V0, %V1, #%s2\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -224,15 +224,15 @@\n   [(set (match_operand:DI            0 \"cirrus_fp_register\" \"=v\")\n \t(ashiftrt:DI (match_operand:DI 1 \"cirrus_fp_register\"  \"v\")\n \t\t     (match_operand:SI 2 \"cirrus_shift_const\"  \"\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfsh64%?\\\\t%V0, %V1, #-%s2\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n \n (define_insn \"*cirrus_absdi2\"\n   [(set (match_operand:DI         0 \"cirrus_fp_register\" \"=v\")\n \t(abs:DI (match_operand:DI 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfabs64%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -242,31 +242,31 @@\n   [(set (match_operand:DI         0 \"cirrus_fp_register\" \"=v\")\n \t(neg:DI (match_operand:DI 1 \"cirrus_fp_register\"  \"v\")))\n    (clobber (reg:CC CC_REGNUM))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfneg64%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n \n (define_insn \"*cirrus_negsi2\"\n   [(set (match_operand:SI         0 \"cirrus_fp_register\" \"=v\")\n \t(neg:SI (match_operand:SI 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfneg32%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n \n (define_insn \"*cirrus_negsf2\"\n   [(set (match_operand:SF         0 \"cirrus_fp_register\" \"=v\")\n \t(neg:SF (match_operand:SF 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfnegs%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n \n (define_insn \"*cirrus_negdf2\"\n   [(set (match_operand:DF         0 \"cirrus_fp_register\" \"=v\")\n \t(neg:DF (match_operand:DF 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfnegd%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -276,23 +276,23 @@\n   [(set (match_operand:SI         0 \"cirrus_fp_register\" \"=v\")\n         (abs:SI (match_operand:SI 1 \"cirrus_fp_register\"  \"v\")))\n    (clobber (reg:CC CC_REGNUM))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\"\n   \"cfabs32%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n \n (define_insn \"*cirrus_abssf2\"\n   [(set (match_operand:SF         0 \"cirrus_fp_register\" \"=v\")\n         (abs:SF (match_operand:SF 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfabss%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n \n (define_insn \"*cirrus_absdf2\"\n   [(set (match_operand:DF         0 \"cirrus_fp_register\" \"=v\")\n         (abs:DF (match_operand:DF 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfabsd%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -302,7 +302,7 @@\n   [(set (match_operand:SF           0 \"cirrus_fp_register\" \"=v\")\n  \t(float:SF (match_operand:SI 1 \"s_register_operand\"  \"r\")))\n    (clobber (match_scratch:DF 2 \"=v\"))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfmv64lr%?\\\\t%Z2, %1\\;cfcvt32s%?\\\\t%V0, %Y2\"\n   [(set_attr \"length\" \"8\")\n    (set_attr \"cirrus\" \"move\")]\n@@ -312,7 +312,7 @@\n   [(set (match_operand:DF           0 \"cirrus_fp_register\" \"=v\")\n \t(float:DF (match_operand:SI 1 \"s_register_operand\" \"r\")))\n    (clobber (match_scratch:DF 2 \"=v\"))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfmv64lr%?\\\\t%Z2, %1\\;cfcvt32d%?\\\\t%V0, %Y2\"\n   [(set_attr \"length\" \"8\")\n    (set_attr \"cirrus\" \"move\")]\n@@ -321,22 +321,22 @@\n (define_insn \"floatdisf2\"\n   [(set (match_operand:SF           0 \"cirrus_fp_register\" \"=v\")\n \t(float:SF (match_operand:DI 1 \"cirrus_fp_register\" \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfcvt64s%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")])\n \n (define_insn \"floatdidf2\"\n   [(set (match_operand:DF 0 \"cirrus_fp_register\" \"=v\")\n \t(float:DF (match_operand:DI 1 \"cirrus_fp_register\" \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfcvt64d%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")])\n \n (define_insn \"cirrus_truncsfsi2\"\n   [(set (match_operand:SI         0 \"s_register_operand\" \"=r\")\n \t(fix:SI (fix:SF (match_operand:SF 1 \"cirrus_fp_register\"  \"v\"))))\n    (clobber (match_scratch:DF     2                      \"=v\"))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cftruncs32%?\\\\t%Y2, %V1\\;cfmvr64l%?\\\\t%0, %Z2\"\n   [(set_attr \"length\" \"8\")\n    (set_attr \"cirrus\" \"normal\")]\n@@ -346,7 +346,7 @@\n   [(set (match_operand:SI         0 \"s_register_operand\" \"=r\")\n \t(fix:SI (fix:DF (match_operand:DF 1 \"cirrus_fp_register\"  \"v\"))))\n    (clobber (match_scratch:DF     2                      \"=v\"))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cftruncd32%?\\\\t%Y2, %V1\\;cfmvr64l%?\\\\t%0, %Z2\"\n   [(set_attr \"length\" \"8\")]\n )\n@@ -355,15 +355,15 @@\n   [(set (match_operand:SF  0 \"cirrus_fp_register\" \"=v\")\n         (float_truncate:SF\n          (match_operand:DF 1 \"cirrus_fp_register\" \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfcvtds%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n \n (define_insn \"*cirrus_extendsfdf2\"\n   [(set (match_operand:DF                  0 \"cirrus_fp_register\" \"=v\")\n         (float_extend:DF (match_operand:SF 1 \"cirrus_fp_register\"  \"v\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n   \"cfcvtsd%?\\\\t%V0, %V1\"\n   [(set_attr \"cirrus\" \"normal\")]\n )\n@@ -478,3 +478,111 @@\n    (set_attr \"cirrus\"         \" not,   not,not,   not, not,normal,double,move,normal,double\")]\n )\n \n+(define_insn \"*cirrus_thumb2_movdi\"\n+  [(set (match_operand:DI 0 \"nonimmediate_di_operand\" \"=r,r,o<>,v,r,v,m,v\")\n+\t(match_operand:DI 1 \"di_operand\"              \"rIK,mi,r,r,v,mi,v,v\"))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_MAVERICK\"\n+  \"*\n+  {\n+  switch (which_alternative)\n+    {\n+    case 0:\n+    case 1:\n+    case 2:\n+      return (output_move_double (operands));\n+\n+    case 3: return \\\"cfmv64lr%?\\\\t%V0, %Q1\\;cfmv64hr%?\\\\t%V0, %R1\\\";\n+    case 4: return \\\"cfmvr64l%?\\\\t%Q0, %V1\\;cfmvr64h%?\\\\t%R0, %V1\\\";\n+\n+    case 5: return \\\"cfldr64%?\\\\t%V0, %1\\\";\n+    case 6: return \\\"cfstr64%?\\\\t%V1, %0\\\";\n+\n+    /* Shifting by 0 will just copy %1 into %0.  */\n+    case 7: return \\\"cfsh64%?\\\\t%V0, %V1, #0\\\";\n+\n+    default: abort ();\n+    }\n+  }\"\n+  [(set_attr \"length\"         \"  8,   8,     8,   8,     8,     4,     4,     4\")\n+   (set_attr \"type\"           \"  *,load2,store2,   *,     *,  load2,store2,     *\")\n+   (set_attr \"pool_range\"     \"  *,4096,     *,   *,     *,  1020,     *,     *\")\n+   (set_attr \"neg_pool_range\" \"  *,   0,     *,   *,     *,  1008,     *,     *\")\n+   (set_attr \"cirrus\"         \"not, not,   not,move,normal,double,double,normal\")]\n+)\n+\n+;; Cirrus SI values have been outlawed.  Look in arm.h for the comment\n+;; on HARD_REGNO_MODE_OK.\n+\n+(define_insn \"*cirrus_thumb2_movsi_insn\"\n+  [(set (match_operand:SI 0 \"general_operand\" \"=r,r,r,m,*v,r,*v,T,*v\")\n+        (match_operand:SI 1 \"general_operand\" \"rI,K,mi,r,r,*v,T,*v,*v\"))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_MAVERICK && 0\n+   && (register_operand (operands[0], SImode)\n+       || register_operand (operands[1], SImode))\"\n+  \"@\n+   mov%?\\\\t%0, %1\n+   mvn%?\\\\t%0, #%B1\n+   ldr%?\\\\t%0, %1\n+   str%?\\\\t%1, %0\n+   cfmv64lr%?\\\\t%Z0, %1\n+   cfmvr64l%?\\\\t%0, %Z1\n+   cfldr32%?\\\\t%V0, %1\n+   cfstr32%?\\\\t%V1, %0\n+   cfsh32%?\\\\t%V0, %V1, #0\"\n+  [(set_attr \"type\"           \"*,  *,  load1,store1,   *,     *,  load1,store1,     *\")\n+   (set_attr \"pool_range\"     \"*,  *,  4096,     *,   *,     *,  1024,     *,     *\")\n+   (set_attr \"neg_pool_range\" \"*,  *,     0,     *,   *,     *,  1012,     *,     *\")\n+   (set_attr \"cirrus\"         \"not,not, not,   not,move,normal,normal,normal,normal\")]\n+)\n+\n+(define_insn \"*thumb2_cirrus_movsf_hard_insn\"\n+  [(set (match_operand:SF 0 \"nonimmediate_operand\" \"=v,v,v,r,m,r,r,m\")\n+        (match_operand:SF 1 \"general_operand\"      \"v,mE,r,v,v,r,mE,r\"))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_MAVERICK\n+   && (GET_CODE (operands[0]) != MEM\n+       || register_operand (operands[1], SFmode))\"\n+  \"@\n+   cfcpys%?\\\\t%V0, %V1\n+   cfldrs%?\\\\t%V0, %1\n+   cfmvsr%?\\\\t%V0, %1\n+   cfmvrs%?\\\\t%0, %V1\n+   cfstrs%?\\\\t%V1, %0\n+   mov%?\\\\t%0, %1\n+   ldr%?\\\\t%0, %1\\\\t%@ float\n+   str%?\\\\t%1, %0\\\\t%@ float\"\n+  [(set_attr \"length\"         \"     *,     *,   *,     *,     *,  4,   4,     4\")\n+   (set_attr \"type\"           \"     *,  load1,   *,     *,store1,  *,load1,store1\")\n+   (set_attr \"pool_range\"     \"     *,   1020,   *,     *,     *,  *,4096,     *\")\n+   (set_attr \"neg_pool_range\" \"     *,   1008,   *,     *,     *,  *,   0,     *\")\n+   (set_attr \"cirrus\"         \"normal,normal,move,normal,normal,not, not,   not\")]\n+)\n+\n+(define_insn \"*thumb2_cirrus_movdf_hard_insn\"\n+  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=r,Q,r,m,r,v,v,v,r,m\")\n+\t(match_operand:DF 1 \"general_operand\"       \"Q,r,r,r,mF,v,mF,r,v,v\"))]\n+  \"TARGET_THUMB2\n+   && TARGET_HARD_FLOAT && TARGET_MAVERICK\n+   && (GET_CODE (operands[0]) != MEM\n+       || register_operand (operands[1], DFmode))\"\n+  \"*\n+  {\n+  switch (which_alternative)\n+    {\n+    case 0: return \\\"ldm%?ia\\\\t%m1, %M0\\\\t%@ double\\\";\n+    case 1: return \\\"stm%?ia\\\\t%m0, %M1\\\\t%@ double\\\";\n+    case 2: case 3: case 4: return output_move_double (operands);\n+    case 5: return \\\"cfcpyd%?\\\\t%V0, %V1\\\";\n+    case 6: return \\\"cfldrd%?\\\\t%V0, %1\\\";\n+    case 7: return \\\"cfmvdlr\\\\t%V0, %Q1\\;cfmvdhr%?\\\\t%V0, %R1\\\";\n+    case 8: return \\\"cfmvrdl%?\\\\t%Q0, %V1\\;cfmvrdh%?\\\\t%R0, %V1\\\";\n+    case 9: return \\\"cfstrd%?\\\\t%V1, %0\\\";\n+    default: abort ();\n+    }\n+  }\"\n+  [(set_attr \"type\"           \"load1,store2,  *,store2,load1,     *,  load1,   *,     *,store2\")\n+   (set_attr \"length\"         \"   4,     4,  8,     8,   8,     4,     4,   8,     8,     4\")\n+   (set_attr \"pool_range\"     \"   *,     *,  *,     *,4092,     *,  1020,   *,     *,     *\")\n+   (set_attr \"neg_pool_range\" \"   *,     *,  *,     *,   0,     *,  1008,   *,     *,     *\")\n+   (set_attr \"cirrus\"         \" not,   not,not,   not, not,normal,double,move,normal,double\")]\n+)\n+"}, {"sha": "4087d98baea0bcc411490da1c5fad97b90371dae", "filename": "gcc/config/arm/coff.h", "status": "modified", "additions": 6, "deletions": 5, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fcoff.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fcoff.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcoff.h?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,7 +1,7 @@\n /* Definitions of target machine for GNU compiler.\n    For ARM with COFF object format.\n-   Copyright (C) 1995, 1996, 1997, 1998, 1999, 2000, 2002, 2003, 2004, 2005\n-   Free Software Foundation, Inc.\n+   Copyright (C) 1995, 1996, 1997, 1998, 1999, 2000, 2002, 2003, 2004, 2005,\n+   2007  Free Software Foundation, Inc.\n    Contributed by Doug Evans (devans@cygnus.com).\n    \n    This file is part of GCC.\n@@ -59,9 +59,10 @@\n /* Define this macro if jump tables (for `tablejump' insns) should be\n    output in the text section, along with the assembler instructions.\n    Otherwise, the readonly data section is used.  */\n-/* We put ARM jump tables in the text section, because it makes the code\n-   more efficient, but for Thumb it's better to put them out of band.  */\n-#define JUMP_TABLES_IN_TEXT_SECTION (TARGET_ARM)\n+/* We put ARM and Thumb-2 jump tables in the text section, because it makes\n+   the code more efficient, but for Thumb-1 it's better to put them out of\n+   band.  */\n+#define JUMP_TABLES_IN_TEXT_SECTION (TARGET_32BIT)\n \n #undef  READONLY_DATA_SECTION_ASM_OP\n #define READONLY_DATA_SECTION_ASM_OP\t\"\\t.section .rdata\""}, {"sha": "9a60671f1042b3981d5ce8998c37b8d2bc705ce9", "filename": "gcc/config/arm/constraints.md", "status": "modified", "additions": 46, "deletions": 41, "changes": 87, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fconstraints.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fconstraints.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fconstraints.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n ;; Constraint definitions for ARM and Thumb\n-;; Copyright (C) 2006 Free Software Foundation, Inc.\n+;; Copyright (C) 2006, 2007 Free Software Foundation, Inc.\n ;; Contributed by ARM Ltd.\n \n ;; This file is part of GCC.\n@@ -20,20 +20,21 @@\n ;; Boston, MA 02110-1301, USA.\n \n ;; The following register constraints have been used:\n-;; - in ARM state: f, v, w, y, z\n+;; - in ARM/Thumb-2 state: f, v, w, y, z\n ;; - in Thumb state: h, k, b\n ;; - in both states: l, c\n ;; In ARM state, 'l' is an alias for 'r'\n \n ;; The following normal constraints have been used:\n-;; in ARM state: G, H, I, J, K, L, M\n-;; in Thumb state: I, J, K, L, M, N, O\n+;; in ARM/Thumb-2 state: G, H, I, J, K, L, M\n+;; in Thumb-1 state: I, J, K, L, M, N, O\n \n ;; The following multi-letter normal constraints have been used:\n-;; in ARM state: Da, Db, Dc\n+;; in ARM/Thumb-2 state: Da, Db, Dc\n \n ;; The following memory constraints have been used:\n-;; in ARM state: Q, Uq, Uv, Uy\n+;; in ARM/Thumb-2 state: Q, Uv, Uy\n+;; in ARM state: Uq\n \n \n (define_register_constraint \"f\" \"TARGET_ARM ? FPA_REGS : NO_REGS\"\n@@ -70,99 +71,103 @@\n  \"@internal The condition code register.\")\n \n (define_constraint \"I\"\n- \"In ARM state a constant that can be used as an immediate value in a Data\n-  Processing instruction.  In Thumb state a constant in the range 0-255.\"\n+ \"In ARM/Thumb-2 state a constant that can be used as an immediate value in a\n+  Data Processing instruction.  In Thumb-1 state a constant in the range\n+  0-255.\"\n  (and (match_code \"const_int\")\n-      (match_test \"TARGET_ARM ? const_ok_for_arm (ival)\n+      (match_test \"TARGET_32BIT ? const_ok_for_arm (ival)\n \t\t   : ival >= 0 && ival <= 255\")))\n \n (define_constraint \"J\"\n- \"In ARM state a constant in the range @minus{}4095-4095.  In Thumb state\n-  a constant in the range @minus{}255-@minus{}1.\"\n+ \"In ARM/Thumb-2 state a constant in the range @minus{}4095-4095.  In Thumb-1\n+  state a constant in the range @minus{}255-@minus{}1.\"\n  (and (match_code \"const_int\")\n-      (match_test \"TARGET_ARM ? (ival >= -4095 && ival <= 4095)\n+      (match_test \"TARGET_32BIT ? (ival >= -4095 && ival <= 4095)\n \t\t   : (ival >= -255 && ival <= -1)\")))\n \n (define_constraint \"K\"\n- \"In ARM state a constant that satisfies the @code{I} constraint if inverted.\n-  In Thumb state a constant that satisfies the @code{I} constraint multiplied \n-  by any power of 2.\"\n+ \"In ARM/Thumb-2 state a constant that satisfies the @code{I} constraint if\n+  inverted.  In Thumb-1 state a constant that satisfies the @code{I}\n+  constraint multiplied by any power of 2.\"\n  (and (match_code \"const_int\")\n-      (match_test \"TARGET_ARM ? const_ok_for_arm (~ival)\n+      (match_test \"TARGET_32BIT ? const_ok_for_arm (~ival)\n \t\t   : thumb_shiftable_const (ival)\")))\n \n (define_constraint \"L\"\n- \"In ARM state a constant that satisfies the @code{I} constraint if negated.\n-  In Thumb state a constant in the range @minus{}7-7.\"\n+ \"In ARM/Thumb-2 state a constant that satisfies the @code{I} constraint if\n+  negated.  In Thumb-1 state a constant in the range @minus{}7-7.\"\n  (and (match_code \"const_int\")\n-      (match_test \"TARGET_ARM ? const_ok_for_arm (-ival)\n+      (match_test \"TARGET_32BIT ? const_ok_for_arm (-ival)\n \t\t   : (ival >= -7 && ival <= 7)\")))\n \n ;; The ARM state version is internal...\n-;; @internal In ARM state a constant in the range 0-32 or any power of 2.\n+;; @internal In ARM/Thumb-2 state a constant in the range 0-32 or any\n+;; power of 2.\n (define_constraint \"M\"\n- \"In Thumb state a constant that is a multiple of 4 in the range 0-1020.\"\n+ \"In Thumb-1 state a constant that is a multiple of 4 in the range 0-1020.\"\n  (and (match_code \"const_int\")\n-      (match_test \"TARGET_ARM ? ((ival >= 0 && ival <= 32)\n+      (match_test \"TARGET_32BIT ? ((ival >= 0 && ival <= 32)\n \t\t\t\t || ((ival & (ival - 1)) == 0))\n \t\t   : ((ival >= 0 && ival <= 1020) && ((ival & 3) == 0))\")))\n \n (define_constraint \"N\"\n- \"In Thumb state a constant in the range 0-31.\"\n+ \"In ARM/Thumb-2 state a constant suitable for a MOVW instruction.\n+  In Thumb-1 state a constant in the range 0-31.\"\n  (and (match_code \"const_int\")\n-      (match_test \"TARGET_THUMB && ival >= 0 && ival <= 31\")))\n+      (match_test \"TARGET_32BIT ? arm_arch_thumb2 && ((ival & 0xffff0000) == 0)\n+\t\t\t\t: (ival >= 0 && ival <= 31)\")))\n \n (define_constraint \"O\"\n- \"In Thumb state a constant that is a multiple of 4 in the range\n+ \"In Thumb-1 state a constant that is a multiple of 4 in the range\n   @minus{}508-508.\"\n  (and (match_code \"const_int\")\n-      (match_test \"TARGET_THUMB && ival >= -508 && ival <= 508\n+      (match_test \"TARGET_THUMB1 && ival >= -508 && ival <= 508\n \t\t   && ((ival & 3) == 0)\")))\n \n (define_constraint \"G\"\n- \"In ARM state a valid FPA immediate constant.\"\n+ \"In ARM/Thumb-2 state a valid FPA immediate constant.\"\n  (and (match_code \"const_double\")\n-      (match_test \"TARGET_ARM && arm_const_double_rtx (op)\")))\n+      (match_test \"TARGET_32BIT && arm_const_double_rtx (op)\")))\n \n (define_constraint \"H\"\n- \"In ARM state a valid FPA immediate constant when negated.\"\n+ \"In ARM/Thumb-2 state a valid FPA immediate constant when negated.\"\n  (and (match_code \"const_double\")\n-      (match_test \"TARGET_ARM && neg_const_double_rtx_ok_for_fpa (op)\")))\n+      (match_test \"TARGET_32BIT && neg_const_double_rtx_ok_for_fpa (op)\")))\n \n (define_constraint \"Da\"\n  \"@internal\n-  In ARM state a const_int, const_double or const_vector that can\n+  In ARM/Thumb-2 state a const_int, const_double or const_vector that can\n   be generated with two Data Processing insns.\"\n  (and (match_code \"const_double,const_int,const_vector\")\n-      (match_test \"TARGET_ARM && arm_const_double_inline_cost (op) == 2\")))\n+      (match_test \"TARGET_32BIT && arm_const_double_inline_cost (op) == 2\")))\n \n (define_constraint \"Db\"\n  \"@internal\n-  In ARM state a const_int, const_double or const_vector that can\n+  In ARM/Thumb-2 state a const_int, const_double or const_vector that can\n   be generated with three Data Processing insns.\"\n  (and (match_code \"const_double,const_int,const_vector\")\n-      (match_test \"TARGET_ARM && arm_const_double_inline_cost (op) == 3\")))\n+      (match_test \"TARGET_32BIT && arm_const_double_inline_cost (op) == 3\")))\n \n (define_constraint \"Dc\"\n  \"@internal\n-  In ARM state a const_int, const_double or const_vector that can\n+  In ARM/Thumb-2 state a const_int, const_double or const_vector that can\n   be generated with four Data Processing insns.  This pattern is disabled\n   if optimizing for space or when we have load-delay slots to fill.\"\n  (and (match_code \"const_double,const_int,const_vector\")\n-      (match_test \"TARGET_ARM && arm_const_double_inline_cost (op) == 4\n+      (match_test \"TARGET_32BIT && arm_const_double_inline_cost (op) == 4\n \t\t   && !(optimize_size || arm_ld_sched)\")))\n \n (define_memory_constraint \"Uv\"\n  \"@internal\n-  In ARM state a valid VFP load/store address.\"\n+  In ARM/Thumb-2 state a valid VFP load/store address.\"\n  (and (match_code \"mem\")\n-      (match_test \"TARGET_ARM && arm_coproc_mem_operand (op, FALSE)\")))\n+      (match_test \"TARGET_32BIT && arm_coproc_mem_operand (op, FALSE)\")))\n \n (define_memory_constraint \"Uy\"\n  \"@internal\n-  In ARM state a valid iWMMX load/store address.\"\n+  In ARM/Thumb-2 state a valid iWMMX load/store address.\"\n  (and (match_code \"mem\")\n-      (match_test \"TARGET_ARM && arm_coproc_mem_operand (op, TRUE)\")))\n+      (match_test \"TARGET_32BIT && arm_coproc_mem_operand (op, TRUE)\")))\n \n (define_memory_constraint \"Uq\"\n  \"@internal\n@@ -174,7 +179,7 @@\n \n (define_memory_constraint \"Q\"\n  \"@internal\n-  In ARM state an address that is a single base register.\"\n+  In ARM/Thumb-2 state an address that is a single base register.\"\n  (and (match_code \"mem\")\n       (match_test \"REG_P (XEXP (op, 0))\")))\n "}, {"sha": "41bc77412a92f9d38c952f794b457e918d9530cb", "filename": "gcc/config/arm/elf.h", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Felf.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Felf.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Felf.h?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,6 +1,6 @@\n /* Definitions of target machine for GNU compiler.\n    For ARM with ELF obj format.\n-   Copyright (C) 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2004, 2005\n+   Copyright (C) 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2004, 2005, 2007\n    Free Software Foundation, Inc.\n    Contributed by Philip Blundell <philb@gnu.org> and\n    Catherine Moore <clm@cygnus.com>\n@@ -96,9 +96,10 @@\n /* Define this macro if jump tables (for `tablejump' insns) should be\n    output in the text section, along with the assembler instructions.\n    Otherwise, the readonly data section is used.  */\n-/* We put ARM jump tables in the text section, because it makes the code\n-   more efficient, but for Thumb it's better to put them out of band.  */\n-#define JUMP_TABLES_IN_TEXT_SECTION (TARGET_ARM)\n+/* We put ARM and Thumb-2 jump tables in the text section, because it makes\n+   the code more efficient, but for Thumb-1 it's better to put them out of\n+   band.  */\n+#define JUMP_TABLES_IN_TEXT_SECTION (TARGET_32BIT)\n \n #ifndef LINK_SPEC\n #define LINK_SPEC \"%{mbig-endian:-EB} %{mlittle-endian:-EL} -X\""}, {"sha": "d821a507ebdbc868b0f5be37ed9a62827def7fdb", "filename": "gcc/config/arm/fpa.md", "status": "modified", "additions": 191, "deletions": 51, "changes": 242, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Ffpa.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Ffpa.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Ffpa.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,6 +1,6 @@\n ;;- Machine description for FPA co-processor for ARM cpus.\n ;;  Copyright 1991, 1993, 1994, 1995, 1996, 1996, 1997, 1998, 1999, 2000,\n-;;  2001, 2002, 2003, 2004, 2005  Free Software Foundation, Inc.\n+;;  2001, 2002, 2003, 2004, 2005, 2007  Free Software Foundation, Inc.\n ;;  Contributed by Pieter `Tiggr' Schoenmakers (rcpieter@win.tue.nl)\n ;;  and Martin Simmons (@harleqn.co.uk).\n ;;  More major hacks by Richard Earnshaw (rearnsha@arm.com).\n@@ -22,6 +22,10 @@\n ;; the Free Software Foundation, 51 Franklin Street, Fifth Floor,\n ;; Boston, MA 02110-1301, USA.\n \n+;; Some FPA mnemonics are ambiguous between conditional infixes and\n+;; conditional suffixes.  All instructions use a conditional infix,\n+;; even in unified assembly mode.\n+\n ;; FPA automaton.\n (define_automaton \"armfp\")\n \n@@ -101,7 +105,7 @@\n   [(set (match_operand:SF          0 \"s_register_operand\" \"=f,f\")\n \t(plus:SF (match_operand:SF 1 \"s_register_operand\" \"%f,f\")\n \t\t (match_operand:SF 2 \"arm_float_add_operand\"    \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    adf%?s\\\\t%0, %1, %2\n    suf%?s\\\\t%0, %1, #%N2\"\n@@ -113,7 +117,7 @@\n   [(set (match_operand:DF          0 \"s_register_operand\" \"=f,f\")\n \t(plus:DF (match_operand:DF 1 \"s_register_operand\" \"%f,f\")\n \t\t (match_operand:DF 2 \"arm_float_add_operand\"    \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    adf%?d\\\\t%0, %1, %2\n    suf%?d\\\\t%0, %1, #%N2\"\n@@ -126,7 +130,7 @@\n \t(plus:DF (float_extend:DF\n \t\t  (match_operand:SF 1 \"s_register_operand\"  \"f,f\"))\n \t\t (match_operand:DF  2 \"arm_float_add_operand\"    \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    adf%?d\\\\t%0, %1, %2\n    suf%?d\\\\t%0, %1, #%N2\"\n@@ -139,7 +143,7 @@\n \t(plus:DF (match_operand:DF  1 \"s_register_operand\"  \"f\")\n \t\t (float_extend:DF\n \t\t  (match_operand:SF 2 \"s_register_operand\"  \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"adf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"farith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -151,7 +155,7 @@\n \t\t  (match_operand:SF 1 \"s_register_operand\" \"f\"))\n \t\t (float_extend:DF\n \t\t  (match_operand:SF 2 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"adf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"farith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -161,7 +165,7 @@\n   [(set (match_operand:SF 0 \"s_register_operand\" \"=f,f\")\n \t(minus:SF (match_operand:SF 1 \"arm_float_rhs_operand\" \"f,G\")\n \t\t  (match_operand:SF 2 \"arm_float_rhs_operand\" \"fG,f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    suf%?s\\\\t%0, %1, %2\n    rsf%?s\\\\t%0, %2, %1\"\n@@ -172,7 +176,7 @@\n   [(set (match_operand:DF           0 \"s_register_operand\" \"=f,f\")\n \t(minus:DF (match_operand:DF 1 \"arm_float_rhs_operand\"     \"f,G\")\n \t\t  (match_operand:DF 2 \"arm_float_rhs_operand\"    \"fG,f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    suf%?d\\\\t%0, %1, %2\n    rsf%?d\\\\t%0, %2, %1\"\n@@ -185,7 +189,7 @@\n \t(minus:DF (float_extend:DF\n \t\t   (match_operand:SF 1 \"s_register_operand\"  \"f\"))\n \t\t  (match_operand:DF  2 \"arm_float_rhs_operand\"    \"fG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"suf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"farith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -196,7 +200,7 @@\n \t(minus:DF (match_operand:DF 1 \"arm_float_rhs_operand\" \"f,G\")\n \t\t  (float_extend:DF\n \t\t   (match_operand:SF 2 \"s_register_operand\" \"f,f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    suf%?d\\\\t%0, %1, %2\n    rsf%?d\\\\t%0, %2, %1\"\n@@ -210,7 +214,7 @@\n \t\t   (match_operand:SF 1 \"s_register_operand\" \"f\"))\n \t\t  (float_extend:DF\n \t\t   (match_operand:SF 2 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"suf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"farith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -220,7 +224,7 @@\n   [(set (match_operand:SF 0 \"s_register_operand\" \"=f\")\n \t(mult:SF (match_operand:SF 1 \"s_register_operand\" \"f\")\n \t\t (match_operand:SF 2 \"arm_float_rhs_operand\" \"fG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"fml%?s\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"ffmul\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -230,7 +234,7 @@\n   [(set (match_operand:DF 0 \"s_register_operand\" \"=f\")\n \t(mult:DF (match_operand:DF 1 \"s_register_operand\" \"f\")\n \t\t (match_operand:DF 2 \"arm_float_rhs_operand\" \"fG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"muf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fmul\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -241,7 +245,7 @@\n \t(mult:DF (float_extend:DF\n \t\t  (match_operand:SF 1 \"s_register_operand\" \"f\"))\n \t\t (match_operand:DF 2 \"arm_float_rhs_operand\" \"fG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"muf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fmul\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -252,7 +256,7 @@\n \t(mult:DF (match_operand:DF 1 \"s_register_operand\" \"f\")\n \t\t (float_extend:DF\n \t\t  (match_operand:SF 2 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"muf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fmul\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -263,7 +267,7 @@\n \t(mult:DF\n \t (float_extend:DF (match_operand:SF 1 \"s_register_operand\" \"f\"))\n \t (float_extend:DF (match_operand:SF 2 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"muf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fmul\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -275,7 +279,7 @@\n   [(set (match_operand:SF 0 \"s_register_operand\" \"=f,f\")\n \t(div:SF (match_operand:SF 1 \"arm_float_rhs_operand\" \"f,G\")\n \t\t(match_operand:SF 2 \"arm_float_rhs_operand\" \"fG,f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    fdv%?s\\\\t%0, %1, %2\n    frd%?s\\\\t%0, %2, %1\"\n@@ -287,7 +291,7 @@\n   [(set (match_operand:DF 0 \"s_register_operand\" \"=f,f\")\n \t(div:DF (match_operand:DF 1 \"arm_float_rhs_operand\" \"f,G\")\n \t\t(match_operand:DF 2 \"arm_float_rhs_operand\" \"fG,f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    dvf%?d\\\\t%0, %1, %2\n    rdf%?d\\\\t%0, %2, %1\"\n@@ -300,7 +304,7 @@\n \t(div:DF (float_extend:DF\n \t\t (match_operand:SF 1 \"s_register_operand\" \"f\"))\n \t\t(match_operand:DF 2 \"arm_float_rhs_operand\" \"fG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"dvf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fdivd\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -311,7 +315,7 @@\n \t(div:DF (match_operand:DF 1 \"arm_float_rhs_operand\" \"fG\")\n \t\t(float_extend:DF\n \t\t (match_operand:SF 2 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"rdf%?d\\\\t%0, %2, %1\"\n   [(set_attr \"type\" \"fdivd\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -323,7 +327,7 @@\n \t\t (match_operand:SF 1 \"s_register_operand\" \"f\"))\n \t\t(float_extend:DF\n \t\t (match_operand:SF 2 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"dvf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fdivd\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -333,7 +337,7 @@\n   [(set (match_operand:SF 0 \"s_register_operand\" \"=f\")\n \t(mod:SF (match_operand:SF 1 \"s_register_operand\" \"f\")\n \t\t(match_operand:SF 2 \"arm_float_rhs_operand\" \"fG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"rmf%?s\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fdivs\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -343,7 +347,7 @@\n   [(set (match_operand:DF 0 \"s_register_operand\" \"=f\")\n \t(mod:DF (match_operand:DF 1 \"s_register_operand\" \"f\")\n \t\t(match_operand:DF 2 \"arm_float_rhs_operand\" \"fG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"rmf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fdivd\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -354,7 +358,7 @@\n \t(mod:DF (float_extend:DF\n \t\t (match_operand:SF 1 \"s_register_operand\" \"f\"))\n \t\t(match_operand:DF 2 \"arm_float_rhs_operand\" \"fG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"rmf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fdivd\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -365,7 +369,7 @@\n \t(mod:DF (match_operand:DF 1 \"s_register_operand\" \"f\")\n \t\t(float_extend:DF\n \t\t (match_operand:SF 2 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"rmf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fdivd\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -377,7 +381,7 @@\n \t\t (match_operand:SF 1 \"s_register_operand\" \"f\"))\n \t\t(float_extend:DF\n \t\t (match_operand:SF 2 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"rmf%?d\\\\t%0, %1, %2\"\n   [(set_attr \"type\" \"fdivd\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -386,7 +390,7 @@\n (define_insn \"*negsf2_fpa\"\n   [(set (match_operand:SF         0 \"s_register_operand\" \"=f\")\n \t(neg:SF (match_operand:SF 1 \"s_register_operand\" \"f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"mnf%?s\\\\t%0, %1\"\n   [(set_attr \"type\" \"ffarith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -395,7 +399,7 @@\n (define_insn \"*negdf2_fpa\"\n   [(set (match_operand:DF         0 \"s_register_operand\" \"=f\")\n \t(neg:DF (match_operand:DF 1 \"s_register_operand\" \"f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"mnf%?d\\\\t%0, %1\"\n   [(set_attr \"type\" \"ffarith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -405,7 +409,7 @@\n   [(set (match_operand:DF 0 \"s_register_operand\" \"=f\")\n \t(neg:DF (float_extend:DF\n \t\t (match_operand:SF 1 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"mnf%?d\\\\t%0, %1\"\n   [(set_attr \"type\" \"ffarith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -414,7 +418,7 @@\n (define_insn \"*abssf2_fpa\"\n   [(set (match_operand:SF          0 \"s_register_operand\" \"=f\")\n \t (abs:SF (match_operand:SF 1 \"s_register_operand\" \"f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"abs%?s\\\\t%0, %1\"\n   [(set_attr \"type\" \"ffarith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -423,7 +427,7 @@\n (define_insn \"*absdf2_fpa\"\n   [(set (match_operand:DF         0 \"s_register_operand\" \"=f\")\n \t(abs:DF (match_operand:DF 1 \"s_register_operand\" \"f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"abs%?d\\\\t%0, %1\"\n   [(set_attr \"type\" \"ffarith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -433,7 +437,7 @@\n   [(set (match_operand:DF 0 \"s_register_operand\" \"=f\")\n \t(abs:DF (float_extend:DF\n \t\t (match_operand:SF 1 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"abs%?d\\\\t%0, %1\"\n   [(set_attr \"type\" \"ffarith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -442,7 +446,7 @@\n (define_insn \"*sqrtsf2_fpa\"\n   [(set (match_operand:SF 0 \"s_register_operand\" \"=f\")\n \t(sqrt:SF (match_operand:SF 1 \"s_register_operand\" \"f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"sqt%?s\\\\t%0, %1\"\n   [(set_attr \"type\" \"float_em\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -451,7 +455,7 @@\n (define_insn \"*sqrtdf2_fpa\"\n   [(set (match_operand:DF 0 \"s_register_operand\" \"=f\")\n \t(sqrt:DF (match_operand:DF 1 \"s_register_operand\" \"f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"sqt%?d\\\\t%0, %1\"\n   [(set_attr \"type\" \"float_em\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -461,7 +465,7 @@\n   [(set (match_operand:DF 0 \"s_register_operand\" \"=f\")\n \t(sqrt:DF (float_extend:DF\n \t\t  (match_operand:SF 1 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"sqt%?d\\\\t%0, %1\"\n   [(set_attr \"type\" \"float_em\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -470,7 +474,7 @@\n (define_insn \"*floatsisf2_fpa\"\n   [(set (match_operand:SF           0 \"s_register_operand\" \"=f\")\n \t(float:SF (match_operand:SI 1 \"s_register_operand\" \"r\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"flt%?s\\\\t%0, %1\"\n   [(set_attr \"type\" \"r_2_f\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -479,7 +483,7 @@\n (define_insn \"*floatsidf2_fpa\"\n   [(set (match_operand:DF           0 \"s_register_operand\" \"=f\")\n \t(float:DF (match_operand:SI 1 \"s_register_operand\" \"r\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"flt%?d\\\\t%0, %1\"\n   [(set_attr \"type\" \"r_2_f\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -488,7 +492,7 @@\n (define_insn \"*fix_truncsfsi2_fpa\"\n   [(set (match_operand:SI         0 \"s_register_operand\" \"=r\")\n \t(fix:SI (fix:SF (match_operand:SF 1 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"fix%?z\\\\t%0, %1\"\n   [(set_attr \"type\" \"f_2_r\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -497,7 +501,7 @@\n (define_insn \"*fix_truncdfsi2_fpa\"\n   [(set (match_operand:SI         0 \"s_register_operand\" \"=r\")\n \t(fix:SI (fix:DF (match_operand:DF 1 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"fix%?z\\\\t%0, %1\"\n   [(set_attr \"type\" \"f_2_r\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -507,7 +511,7 @@\n   [(set (match_operand:SF 0 \"s_register_operand\" \"=f\")\n \t(float_truncate:SF\n \t (match_operand:DF 1 \"s_register_operand\" \"f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"mvf%?s\\\\t%0, %1\"\n   [(set_attr \"type\" \"ffarith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -516,7 +520,7 @@\n (define_insn \"*extendsfdf2_fpa\"\n   [(set (match_operand:DF                  0 \"s_register_operand\" \"=f\")\n \t(float_extend:DF (match_operand:SF 1 \"s_register_operand\"  \"f\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"mvf%?d\\\\t%0, %1\"\n   [(set_attr \"type\" \"ffarith\")\n    (set_attr \"predicable\" \"yes\")]\n@@ -561,8 +565,8 @@\n   switch (which_alternative)\n     {\n     default:\n-    case 0: return \\\"ldm%?ia\\\\t%m1, %M0\\\\t%@ double\\\";\n-    case 1: return \\\"stm%?ia\\\\t%m0, %M1\\\\t%@ double\\\";\n+    case 0: return \\\"ldm%(ia%)\\\\t%m1, %M0\\\\t%@ double\\\";\n+    case 1: return \\\"stm%(ia%)\\\\t%m0, %M1\\\\t%@ double\\\";\n     case 2: return \\\"#\\\";\n     case 3: case 4: return output_move_double (operands);\n     case 5: return \\\"mvf%?d\\\\t%0, %1\\\";\n@@ -609,11 +613,102 @@\n    (set_attr \"type\" \"ffarith,f_load,f_store\")]\n )\n \n+;; stfs/ldfs always use a conditional infix.  This works around the\n+;; ambiguity between \"stf pl s\" and \"sftp ls\".\n+(define_insn \"*thumb2_movsf_fpa\"\n+  [(set (match_operand:SF 0 \"nonimmediate_operand\" \"=f,f,f, m,f,r,r,r, m\")\n+\t(match_operand:SF 1 \"general_operand\"      \"fG,H,mE,f,r,f,r,mE,r\"))]\n+  \"TARGET_THUMB2\n+   && TARGET_HARD_FLOAT && TARGET_FPA\n+   && (GET_CODE (operands[0]) != MEM\n+       || register_operand (operands[1], SFmode))\"\n+  \"@\n+   mvf%?s\\\\t%0, %1\n+   mnf%?s\\\\t%0, #%N1\n+   ldf%?s\\\\t%0, %1\n+   stf%?s\\\\t%1, %0\n+   str%?\\\\t%1, [%|sp, #-4]!\\;ldf%?s\\\\t%0, [%|sp], #4\n+   stf%?s\\\\t%1, [%|sp, #-4]!\\;ldr%?\\\\t%0, [%|sp], #4\n+   mov%?\\\\t%0, %1 @bar\n+   ldr%?\\\\t%0, %1\\\\t%@ float\n+   str%?\\\\t%1, %0\\\\t%@ float\"\n+  [(set_attr \"length\" \"4,4,4,4,8,8,4,4,4\")\n+   (set_attr \"ce_count\" \"1,1,1,1,2,2,1,1,1\")\n+   (set_attr \"predicable\" \"yes\")\n+   (set_attr \"type\"\n+\t \"ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r,*,load1,store1\")\n+   (set_attr \"pool_range\" \"*,*,1024,*,*,*,*,4096,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,1012,*,*,*,*,0,*\")]\n+)\n+\n+;; Not predicable because we don't know the number of instructions.\n+(define_insn \"*thumb2_movdf_fpa\"\n+  [(set (match_operand:DF 0 \"nonimmediate_operand\"\n+\t\t\t\t\t\t\"=r,Q,r,m,r, f, f,f, m,!f,!r\")\n+\t(match_operand:DF 1 \"general_operand\"\n+\t\t\t\t\t\t\"Q, r,r,r,mF,fG,H,mF,f,r, f\"))]\n+  \"TARGET_THUMB2\n+   && TARGET_HARD_FLOAT && TARGET_FPA\n+   && (GET_CODE (operands[0]) != MEM\n+       || register_operand (operands[1], DFmode))\"\n+  \"*\n+  {\n+  switch (which_alternative)\n+    {\n+    default:\n+    case 0: return \\\"ldm%(ia%)\\\\t%m1, %M0\\\\t%@ double\\\";\n+    case 1: return \\\"stm%(ia%)\\\\t%m0, %M1\\\\t%@ double\\\";\n+    case 2: case 3: case 4: return output_move_double (operands);\n+    case 5: return \\\"mvf%?d\\\\t%0, %1\\\";\n+    case 6: return \\\"mnf%?d\\\\t%0, #%N1\\\";\n+    case 7: return \\\"ldf%?d\\\\t%0, %1\\\";\n+    case 8: return \\\"stf%?d\\\\t%1, %0\\\";\n+    case 9: return output_mov_double_fpa_from_arm (operands);\n+    case 10: return output_mov_double_arm_from_fpa (operands);\n+    }\n+  }\n+  \"\n+  [(set_attr \"length\" \"4,4,8,8,8,4,4,4,4,8,8\")\n+   (set_attr \"type\"\n+    \"load1,store2,*,store2,load1,ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r\")\n+   (set_attr \"pool_range\" \"*,*,*,*,4092,*,*,1024,*,*,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,*,*,0,*,*,1020,*,*,*\")]\n+)\n+\n+;; Saving and restoring the floating point registers in the prologue should\n+;; be done in XFmode, even though we don't support that for anything else\n+;; (Well, strictly it's 'internal representation', but that's effectively\n+;; XFmode).\n+;; Not predicable because we don't know the number of instructions.\n+\n+(define_insn \"*thumb2_movxf_fpa\"\n+  [(set (match_operand:XF 0 \"nonimmediate_operand\" \"=f,f,f,m,f,r,r\")\n+\t(match_operand:XF 1 \"general_operand\" \"fG,H,m,f,r,f,r\"))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_FPA && reload_completed\"\n+  \"*\n+  switch (which_alternative)\n+    {\n+    default:\n+    case 0: return \\\"mvf%?e\\\\t%0, %1\\\";\n+    case 1: return \\\"mnf%?e\\\\t%0, #%N1\\\";\n+    case 2: return \\\"ldf%?e\\\\t%0, %1\\\";\n+    case 3: return \\\"stf%?e\\\\t%1, %0\\\";\n+    case 4: return output_mov_long_double_fpa_from_arm (operands);\n+    case 5: return output_mov_long_double_arm_from_fpa (operands);\n+    case 6: return output_mov_long_double_arm_from_arm (operands);\n+    }\n+  \"\n+  [(set_attr \"length\" \"4,4,4,4,8,8,12\")\n+   (set_attr \"type\" \"ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r,*\")\n+   (set_attr \"pool_range\" \"*,*,1024,*,*,*,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,1004,*,*,*,*\")]\n+)\n+\n (define_insn \"*cmpsf_fpa\"\n   [(set (reg:CCFP CC_REGNUM)\n \t(compare:CCFP (match_operand:SF 0 \"s_register_operand\" \"f,f\")\n \t\t      (match_operand:SF 1 \"arm_float_add_operand\" \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    cmf%?\\\\t%0, %1\n    cnf%?\\\\t%0, #%N1\"\n@@ -625,7 +720,7 @@\n   [(set (reg:CCFP CC_REGNUM)\n \t(compare:CCFP (match_operand:DF 0 \"s_register_operand\" \"f,f\")\n \t\t      (match_operand:DF 1 \"arm_float_add_operand\" \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    cmf%?\\\\t%0, %1\n    cnf%?\\\\t%0, #%N1\"\n@@ -638,7 +733,7 @@\n \t(compare:CCFP (float_extend:DF\n \t\t       (match_operand:SF 0 \"s_register_operand\" \"f,f\"))\n \t\t      (match_operand:DF 1 \"arm_float_add_operand\" \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    cmf%?\\\\t%0, %1\n    cnf%?\\\\t%0, #%N1\"\n@@ -651,7 +746,7 @@\n \t(compare:CCFP (match_operand:DF 0 \"s_register_operand\" \"f\")\n \t\t      (float_extend:DF\n \t\t       (match_operand:SF 1 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"cmf%?\\\\t%0, %1\"\n   [(set_attr \"conds\" \"set\")\n    (set_attr \"type\" \"f_2_r\")]\n@@ -661,7 +756,7 @@\n   [(set (reg:CCFPE CC_REGNUM)\n \t(compare:CCFPE (match_operand:SF 0 \"s_register_operand\" \"f,f\")\n \t\t       (match_operand:SF 1 \"arm_float_add_operand\" \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    cmf%?e\\\\t%0, %1\n    cnf%?e\\\\t%0, #%N1\"\n@@ -673,7 +768,7 @@\n   [(set (reg:CCFPE CC_REGNUM)\n \t(compare:CCFPE (match_operand:DF 0 \"s_register_operand\" \"f,f\")\n \t\t       (match_operand:DF 1 \"arm_float_add_operand\" \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    cmf%?e\\\\t%0, %1\n    cnf%?e\\\\t%0, #%N1\"\n@@ -686,7 +781,7 @@\n \t(compare:CCFPE (float_extend:DF\n \t\t\t(match_operand:SF 0 \"s_register_operand\" \"f,f\"))\n \t\t       (match_operand:DF 1 \"arm_float_add_operand\" \"fG,H\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"@\n    cmf%?e\\\\t%0, %1\n    cnf%?e\\\\t%0, #%N1\"\n@@ -699,7 +794,7 @@\n \t(compare:CCFPE (match_operand:DF 0 \"s_register_operand\" \"f\")\n \t\t       (float_extend:DF\n \t\t\t(match_operand:SF 1 \"s_register_operand\" \"f\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_FPA\"\n   \"cmf%?e\\\\t%0, %1\"\n   [(set_attr \"conds\" \"set\")\n    (set_attr \"type\" \"f_2_r\")]\n@@ -748,3 +843,48 @@\n    (set_attr \"type\" \"ffarith\")\n    (set_attr \"conds\" \"use\")]\n )\n+\n+(define_insn \"*thumb2_movsfcc_fpa\"\n+  [(set (match_operand:SF 0 \"s_register_operand\" \"=f,f,f,f,f,f,f,f\")\n+\t(if_then_else:SF\n+\t (match_operator 3 \"arm_comparison_operator\" \n+\t  [(match_operand 4 \"cc_register\" \"\") (const_int 0)])\n+\t (match_operand:SF 1 \"arm_float_add_operand\" \"0,0,fG,H,fG,fG,H,H\")\n+\t (match_operand:SF 2 \"arm_float_add_operand\" \"fG,H,0,0,fG,H,fG,H\")))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"@\n+   it\\\\t%D3\\;mvf%D3s\\\\t%0, %2\n+   it\\\\t%D3\\;mnf%D3s\\\\t%0, #%N2\n+   it\\\\t%d3\\;mvf%d3s\\\\t%0, %1\n+   it\\\\t%d3\\;mnf%d3s\\\\t%0, #%N1\n+   ite\\\\t%d3\\;mvf%d3s\\\\t%0, %1\\;mvf%D3s\\\\t%0, %2\n+   ite\\\\t%d3\\;mvf%d3s\\\\t%0, %1\\;mnf%D3s\\\\t%0, #%N2\n+   ite\\\\t%d3\\;mnf%d3s\\\\t%0, #%N1\\;mvf%D3s\\\\t%0, %2\n+   ite\\\\t%d3\\;mnf%d3s\\\\t%0, #%N1\\;mnf%D3s\\\\t%0, #%N2\"\n+  [(set_attr \"length\" \"6,6,6,6,10,10,10,10\")\n+   (set_attr \"type\" \"ffarith\")\n+   (set_attr \"conds\" \"use\")]\n+)\n+\n+(define_insn \"*thumb2_movdfcc_fpa\"\n+  [(set (match_operand:DF 0 \"s_register_operand\" \"=f,f,f,f,f,f,f,f\")\n+\t(if_then_else:DF\n+\t (match_operator 3 \"arm_comparison_operator\"\n+\t  [(match_operand 4 \"cc_register\" \"\") (const_int 0)])\n+\t (match_operand:DF 1 \"arm_float_add_operand\" \"0,0,fG,H,fG,fG,H,H\")\n+\t (match_operand:DF 2 \"arm_float_add_operand\" \"fG,H,0,0,fG,H,fG,H\")))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_FPA\"\n+  \"@\n+   it\\\\t%D3\\;mvf%D3d\\\\t%0, %2\n+   it\\\\t%D3\\;mnf%D3d\\\\t%0, #%N2\n+   it\\\\t%d3\\;mvf%d3d\\\\t%0, %1\n+   it\\\\t%d3\\;mnf%d3d\\\\t%0, #%N1\n+   ite\\\\t%d3\\;mvf%d3d\\\\t%0, %1\\;mvf%D3d\\\\t%0, %2\n+   ite\\\\t%d3\\;mvf%d3d\\\\t%0, %1\\;mnf%D3d\\\\t%0, #%N2\n+   ite\\\\t%d3\\;mnf%d3d\\\\t%0, #%N1\\;mvf%D3d\\\\t%0, %2\n+   ite\\\\t%d3\\;mnf%d3d\\\\t%0, #%N1\\;mnf%D3d\\\\t%0, #%N2\"\n+  [(set_attr \"length\" \"6,6,6,6,10,10,10,10\")\n+   (set_attr \"type\" \"ffarith\")\n+   (set_attr \"conds\" \"use\")]\n+)\n+"}, {"sha": "7a428a2564991f0b2c6e653ce282814ab1e52270", "filename": "gcc/config/arm/ieee754-df.S", "status": "modified", "additions": 195, "deletions": 81, "changes": 276, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fieee754-df.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fieee754-df.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fieee754-df.S?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,6 +1,6 @@\n /* ieee754-df.S double-precision floating point support for ARM\n \n-   Copyright (C) 2003, 2004, 2005  Free Software Foundation, Inc.\n+   Copyright (C) 2003, 2004, 2005, 2007  Free Software Foundation, Inc.\n    Contributed by Nicolas Pitre (nico@cam.org)\n \n    This file is free software; you can redistribute it and/or modify it\n@@ -88,23 +88,26 @@ ARM_FUNC_ALIAS aeabi_dsub subdf3\n ARM_FUNC_START adddf3\n ARM_FUNC_ALIAS aeabi_dadd adddf3\n \n-1:\tstmfd\tsp!, {r4, r5, lr}\n+1:\tdo_push\t{r4, r5, lr}\n \n \t@ Look for zeroes, equal values, INF, or NAN.\n-\tmov\tr4, xh, lsl #1\n-\tmov\tr5, yh, lsl #1\n+\tshift1\tlsl, r4, xh, #1\n+\tshift1\tlsl, r5, yh, #1\n \tteq\tr4, r5\n+\tdo_it\teq\n \tteqeq\txl, yl\n-\torrnes\tip, r4, xl\n-\torrnes\tip, r5, yl\n-\tmvnnes\tip, r4, asr #21\n-\tmvnnes\tip, r5, asr #21\n+\tdo_it\tne, ttt\n+\tCOND(orr,s,ne)\tip, r4, xl\n+\tCOND(orr,s,ne)\tip, r5, yl\n+\tCOND(mvn,s,ne)\tip, r4, asr #21\n+\tCOND(mvn,s,ne)\tip, r5, asr #21\n \tbeq\tLSYM(Lad_s)\n \n \t@ Compute exponent difference.  Make largest exponent in r4,\n \t@ corresponding arg in xh-xl, and positive exponent difference in r5.\n-\tmov\tr4, r4, lsr #21\n+\tshift1\tlsr, r4, r4, #21\n \trsbs\tr5, r4, r5, lsr #21\n+\tdo_it\tlt\n \trsblt\tr5, r5, #0\n \tble\t1f\n \tadd\tr4, r4, r5\n@@ -119,6 +122,7 @@ ARM_FUNC_ALIAS aeabi_dadd adddf3\n \t@ already in xh-xl.  We need up to 54 bit to handle proper rounding\n \t@ of 0x1p54 - 1.1.\n \tcmp\tr5, #54\n+\tdo_it\thi\n \tRETLDM\t\"r4, r5\" hi\n \n \t@ Convert mantissa to signed integer.\n@@ -127,15 +131,25 @@ ARM_FUNC_ALIAS aeabi_dadd adddf3\n \tmov\tip, #0x00100000\n \torr\txh, ip, xh, lsr #12\n \tbeq\t1f\n+#if defined(__thumb2__)\n+\tnegs\txl, xl\n+\tsbc\txh, xh, xh, lsl #1\n+#else\n \trsbs\txl, xl, #0\n \trsc\txh, xh, #0\n+#endif\n 1:\n \ttst\tyh, #0x80000000\n \tmov\tyh, yh, lsl #12\n \torr\tyh, ip, yh, lsr #12\n \tbeq\t1f\n+#if defined(__thumb2__)\n+\tnegs\tyl, yl\n+\tsbc\tyh, yh, yh, lsl #1\n+#else\n \trsbs\tyl, yl, #0\n \trsc\tyh, yh, #0\n+#endif\n 1:\n \t@ If exponent == difference, one or both args were denormalized.\n \t@ Since this is not common case, rescale them off line.\n@@ -149,27 +163,35 @@ LSYM(Lad_x):\n \t@ Shift yh-yl right per r5, add to xh-xl, keep leftover bits into ip.\n \trsbs\tlr, r5, #32\n \tblt\t1f\n-\tmov\tip, yl, lsl lr\n-\tadds\txl, xl, yl, lsr r5\n+\tshift1\tlsl, ip, yl, lr\n+\tshiftop adds xl xl yl lsr r5 yl\n \tadc\txh, xh, #0\n-\tadds\txl, xl, yh, lsl lr\n-\tadcs\txh, xh, yh, asr r5\n+\tshiftop adds xl xl yh lsl lr yl\n+\tshiftop adcs xh xh yh asr r5 yh\n \tb\t2f\n 1:\tsub\tr5, r5, #32\n \tadd\tlr, lr, #32\n \tcmp\tyl, #1\n-\tmov\tip, yh, lsl lr\n+\tshift1\tlsl,ip, yh, lr\n+\tdo_it\tcs\n \torrcs\tip, ip, #2\t\t@ 2 not 1, to allow lsr #1 later\n-\tadds\txl, xl, yh, asr r5\n+\tshiftop adds xl xl yh asr r5 yh\n \tadcs\txh, xh, yh, asr #31\n 2:\n \t@ We now have a result in xh-xl-ip.\n \t@ Keep absolute value in xh-xl-ip, sign in r5 (the n bit was set above)\n \tand\tr5, xh, #0x80000000\n \tbpl\tLSYM(Lad_p)\n+#if defined(__thumb2__)\n+\tmov\tlr, #0\n+\tnegs\tip, ip\n+\tsbcs\txl, lr, xl\n+\tsbc\txh, lr, xh\n+#else\n \trsbs\tip, ip, #0\n \trscs\txl, xl, #0\n \trsc\txh, xh, #0\n+#endif\n \n \t@ Determine how to normalize the result.\n LSYM(Lad_p):\n@@ -195,7 +217,8 @@ LSYM(Lad_p):\n \t@ Pack final result together.\n LSYM(Lad_e):\n \tcmp\tip, #0x80000000\n-\tmoveqs\tip, xl, lsr #1\n+\tdo_it\teq\n+\tCOND(mov,s,eq)\tip, xl, lsr #1\n \tadcs\txl, xl, #0\n \tadc\txh, xh, r4, lsl #20\n \torr\txh, xh, r5\n@@ -238,9 +261,11 @@ LSYM(Lad_l):\n #else\n \n \tteq\txh, #0\n+\tdo_it\teq, t\n \tmoveq\txh, xl\n \tmoveq\txl, #0\n \tclz\tr3, xh\n+\tdo_it\teq\n \taddeq\tr3, r3, #32\n \tsub\tr3, r3, #11\n \n@@ -256,20 +281,29 @@ LSYM(Lad_l):\n \t@ since a register switch happened above.\n \tadd\tip, r2, #20\n \trsb\tr2, r2, #12\n-\tmov\txl, xh, lsl ip\n-\tmov\txh, xh, lsr r2\n+\tshift1\tlsl, xl, xh, ip\n+\tshift1\tlsr, xh, xh, r2\n \tb\t3f\n \n \t@ actually shift value left 1 to 20 bits, which might also represent\n \t@ 32 to 52 bits if counting the register switch that happened earlier.\n 1:\tadd\tr2, r2, #20\n-2:\trsble\tip, r2, #32\n-\tmov\txh, xh, lsl r2\n+2:\tdo_it\tle\n+\trsble\tip, r2, #32\n+\tshift1\tlsl, xh, xh, r2\n+#if defined(__thumb2__)\n+\tlsr\tip, xl, ip\n+\titt\tle\n+\torrle\txh, xh, ip\n+\tlslle\txl, xl, r2\n+#else\n \torrle\txh, xh, xl, lsr ip\n \tmovle\txl, xl, lsl r2\n+#endif\n \n \t@ adjust exponent accordingly.\n 3:\tsubs\tr4, r4, r3\n+\tdo_it\tge, tt\n \taddge\txh, xh, r4, lsl #20\n \torrge\txh, xh, r5\n \tRETLDM\t\"r4, r5\" ge\n@@ -285,23 +319,23 @@ LSYM(Lad_l):\n \t@ shift result right of 1 to 20 bits, sign is in r5.\n \tadd\tr4, r4, #20\n \trsb\tr2, r4, #32\n-\tmov\txl, xl, lsr r4\n-\torr\txl, xl, xh, lsl r2\n-\torr\txh, r5, xh, lsr r4\n+\tshift1\tlsr, xl, xl, r4\n+\tshiftop orr xl xl xh lsl r2 yh\n+\tshiftop orr xh r5 xh lsr r4 yh\n \tRETLDM\t\"r4, r5\"\n \n \t@ shift result right of 21 to 31 bits, or left 11 to 1 bits after\n \t@ a register switch from xh to xl.\n 1:\trsb\tr4, r4, #12\n \trsb\tr2, r4, #32\n-\tmov\txl, xl, lsr r2\n-\torr\txl, xl, xh, lsl r4\n+\tshift1\tlsr, xl, xl, r2\n+\tshiftop orr xl xl xh lsl r4 yh\n \tmov\txh, r5\n \tRETLDM\t\"r4, r5\"\n \n \t@ Shift value right of 32 to 64 bits, or 0 to 32 bits after a switch\n \t@ from xh to xl.\n-2:\tmov\txl, xh, lsr r4\n+2:\tshift1\tlsr, xl, xh, r4\n \tmov\txh, r5\n \tRETLDM\t\"r4, r5\"\n \n@@ -310,6 +344,7 @@ LSYM(Lad_l):\n LSYM(Lad_d):\n \tteq\tr4, #0\n \teor\tyh, yh, #0x00100000\n+\tdo_it\teq, te\n \teoreq\txh, xh, #0x00100000\n \taddeq\tr4, r4, #1\n \tsubne\tr5, r5, #1\n@@ -318,22 +353,26 @@ LSYM(Lad_d):\n \n LSYM(Lad_s):\n \tmvns\tip, r4, asr #21\n-\tmvnnes\tip, r5, asr #21\n+\tdo_it\tne\n+\tCOND(mvn,s,ne)\tip, r5, asr #21\n \tbeq\tLSYM(Lad_i)\n \n \tteq\tr4, r5\n+\tdo_it\teq\n \tteqeq\txl, yl\n \tbeq\t1f\n \n \t@ Result is x + 0.0 = x or 0.0 + y = y.\n \tteq\tr4, #0\n+\tdo_it\teq, t\n \tmoveq\txh, yh\n \tmoveq\txl, yl\n \tRETLDM\t\"r4, r5\"\n \n 1:\tteq\txh, yh\n \n \t@ Result is x - x = 0.\n+\tdo_it\tne, tt\n \tmovne\txh, #0\n \tmovne\txl, #0\n \tRETLDM\t\"r4, r5\" ne\n@@ -343,9 +382,11 @@ LSYM(Lad_s):\n \tbne\t2f\n \tmovs\txl, xl, lsl #1\n \tadcs\txh, xh, xh\n+\tdo_it\tcs\n \torrcs\txh, xh, #0x80000000\n \tRETLDM\t\"r4, r5\"\n 2:\tadds\tr4, r4, #(2 << 21)\n+\tdo_it\tcc, t\n \taddcc\txh, xh, #(1 << 20)\n \tRETLDM\t\"r4, r5\" cc\n \tand\tr5, xh, #0x80000000\n@@ -365,13 +406,16 @@ LSYM(Lad_o):\n \t@   otherwise return xh-xl (which is INF or -INF)\n LSYM(Lad_i):\n \tmvns\tip, r4, asr #21\n+\tdo_it\tne, te\n \tmovne\txh, yh\n \tmovne\txl, yl\n-\tmvneqs\tip, r5, asr #21\n+\tCOND(mvn,s,eq)\tip, r5, asr #21\n+\tdo_it\tne, t\n \tmovne\tyh, xh\n \tmovne\tyl, xl\n \torrs\tr4, xl, xh, lsl #12\n-\torreqs\tr5, yl, yh, lsl #12\n+\tdo_it\teq, te\n+\tCOND(orr,s,eq)\tr5, yl, yh, lsl #12\n \tteqeq\txh, yh\n \torrne\txh, xh, #0x00080000\t@ quiet NAN\n \tRETLDM\t\"r4, r5\"\n@@ -385,9 +429,10 @@ ARM_FUNC_START floatunsidf\n ARM_FUNC_ALIAS aeabi_ui2d floatunsidf\n \n \tteq\tr0, #0\n+\tdo_it\teq, t\n \tmoveq\tr1, #0\n \tRETc(eq)\n-\tstmfd\tsp!, {r4, r5, lr}\n+\tdo_push\t{r4, r5, lr}\n \tmov\tr4, #0x400\t\t@ initial exponent\n \tadd\tr4, r4, #(52-1 - 1)\n \tmov\tr5, #0\t\t\t@ sign bit is 0\n@@ -404,12 +449,14 @@ ARM_FUNC_START floatsidf\n ARM_FUNC_ALIAS aeabi_i2d floatsidf\n \n \tteq\tr0, #0\n+\tdo_it\teq, t\n \tmoveq\tr1, #0\n \tRETc(eq)\n-\tstmfd\tsp!, {r4, r5, lr}\n+\tdo_push\t{r4, r5, lr}\n \tmov\tr4, #0x400\t\t@ initial exponent\n \tadd\tr4, r4, #(52-1 - 1)\n \tands\tr5, r0, #0x80000000\t@ sign bit in r5\n+\tdo_it\tmi\n \trsbmi\tr0, r0, #0\t\t@ absolute value\n \t.ifnc\txl, r0\n \tmov\txl, r0\n@@ -427,17 +474,19 @@ ARM_FUNC_ALIAS aeabi_f2d extendsfdf2\n \tmov\txh, r2, asr #3\t\t@ stretch exponent\n \tmov\txh, xh, rrx\t\t@ retrieve sign bit\n \tmov\txl, r2, lsl #28\t\t@ retrieve remaining bits\n-\tandnes\tr3, r2, #0xff000000\t@ isolate exponent\n+\tdo_it\tne, ttt\n+\tCOND(and,s,ne)\tr3, r2, #0xff000000\t@ isolate exponent\n \tteqne\tr3, #0xff000000\t\t@ if not 0, check if INF or NAN\n \teorne\txh, xh, #0x38000000\t@ fixup exponent otherwise.\n \tRETc(ne)\t\t\t@ and return it.\n \n \tteq\tr2, #0\t\t\t@ if actually 0\n+\tdo_it\tne, e\n \tteqne\tr3, #0xff000000\t\t@ or INF or NAN\n \tRETc(eq)\t\t\t@ we are done already.\n \n \t@ value was denormalized.  We can normalize it now.\n-\tstmfd\tsp!, {r4, r5, lr}\n+\tdo_push\t{r4, r5, lr}\n \tmov\tr4, #0x380\t\t@ setup corresponding exponent\n \tand\tr5, xh, #0x80000000\t@ move sign bit in r5\n \tbic\txh, xh, #0x80000000\n@@ -451,7 +500,10 @@ ARM_FUNC_ALIAS aeabi_ul2d floatundidf\n \n \torrs\tr2, r0, r1\n #if !defined (__VFP_FP__) && !defined(__SOFTFP__)\n+\tdo_it\teq, t\n \tmvfeqd\tf0, #0.0\n+#else\n+\tdo_it\teq\n #endif\n \tRETc(eq)\n \n@@ -460,9 +512,9 @@ ARM_FUNC_ALIAS aeabi_ul2d floatundidf\n \t@ we can return the result in f0 as well as in r0/r1 for backwards\n \t@ compatibility.\n \tadr\tip, LSYM(f0_ret)\n-\tstmfd\tsp!, {r4, r5, ip, lr}\n+\tdo_push\t{r4, r5, ip, lr}\n #else\n-\tstmfd\tsp!, {r4, r5, lr}\n+\tdo_push\t{r4, r5, lr}\n #endif\n \n \tmov\tr5, #0\n@@ -473,7 +525,10 @@ ARM_FUNC_ALIAS aeabi_l2d floatdidf\n \n \torrs\tr2, r0, r1\n #if !defined (__VFP_FP__) && !defined(__SOFTFP__)\n+\tdo_itt\teq\n \tmvfeqd\tf0, #0.0\n+#else\n+\tdo_it\teq\n #endif\n \tRETc(eq)\n \n@@ -482,15 +537,20 @@ ARM_FUNC_ALIAS aeabi_l2d floatdidf\n \t@ we can return the result in f0 as well as in r0/r1 for backwards\n \t@ compatibility.\n \tadr\tip, LSYM(f0_ret)\n-\tstmfd\tsp!, {r4, r5, ip, lr}\n+\tdo_push\t{r4, r5, ip, lr}\n #else\n-\tstmfd\tsp!, {r4, r5, lr}\n+\tdo_push\t{r4, r5, lr}\n #endif\n \n \tands\tr5, ah, #0x80000000\t@ sign bit in r5\n \tbpl\t2f\n+#if defined(__thumb2__)\n+\tnegs\tal, al\n+\tsbc\tah, ah, ah, lsl #1\n+#else\n \trsbs\tal, al, #0\n \trsc\tah, ah, #0\n+#endif\n 2:\n \tmov\tr4, #0x400\t\t@ initial exponent\n \tadd\tr4, r4, #(52-1 - 1)\n@@ -508,16 +568,18 @@ ARM_FUNC_ALIAS aeabi_l2d floatdidf\n \t@ The value is too big.  Scale it down a bit...\n \tmov\tr2, #3\n \tmovs\tip, ip, lsr #3\n+\tdo_it\tne\n \taddne\tr2, r2, #3\n \tmovs\tip, ip, lsr #3\n+\tdo_it\tne\n \taddne\tr2, r2, #3\n \tadd\tr2, r2, ip, lsr #3\n \n \trsb\tr3, r2, #32\n-\tmov\tip, xl, lsl r3\n-\tmov\txl, xl, lsr r2\n-\torr\txl, xl, xh, lsl r3\n-\tmov\txh, xh, lsr r2\n+\tshift1\tlsl, ip, xl, r3\n+\tshift1\tlsr, xl, xl, r2\n+\tshiftop orr xl xl xh lsl r3 lr\n+\tshift1\tlsr, xh, xh, r2\n \tadd\tr4, r4, r2\n \tb\tLSYM(Lad_p)\n \n@@ -526,7 +588,7 @@ ARM_FUNC_ALIAS aeabi_l2d floatdidf\n \t@ Legacy code expects the result to be returned in f0.  Copy it\n \t@ there as well.\n LSYM(f0_ret):\n-\tstmfd\tsp!, {r0, r1}\n+\tdo_push\t{r0, r1}\n \tldfd\tf0, [sp], #8\n \tRETLDM\n \n@@ -543,13 +605,14 @@ LSYM(f0_ret):\n \n ARM_FUNC_START muldf3\n ARM_FUNC_ALIAS aeabi_dmul muldf3\n-\tstmfd\tsp!, {r4, r5, r6, lr}\n+\tdo_push\t{r4, r5, r6, lr}\n \n \t@ Mask out exponents, trap any zero/denormal/INF/NAN.\n \tmov\tip, #0xff\n \torr\tip, ip, #0x700\n \tands\tr4, ip, xh, lsr #20\n-\tandnes\tr5, ip, yh, lsr #20\n+\tdo_it\tne, tte\n+\tCOND(and,s,ne)\tr5, ip, yh, lsr #20\n \tteqne\tr4, ip\n \tteqne\tr5, ip\n \tbleq\tLSYM(Lml_s)\n@@ -565,7 +628,8 @@ ARM_FUNC_ALIAS aeabi_dmul muldf3\n \tbic\txh, xh, ip, lsl #21\n \tbic\tyh, yh, ip, lsl #21\n \torrs\tr5, xl, xh, lsl #12\n-\torrnes\tr5, yl, yh, lsl #12\n+\tdo_it\tne\n+\tCOND(orr,s,ne)\tr5, yl, yh, lsl #12\n \torr\txh, xh, #0x00100000\n \torr\tyh, yh, #0x00100000\n \tbeq\tLSYM(Lml_1)\n@@ -646,6 +710,7 @@ ARM_FUNC_ALIAS aeabi_dmul muldf3\n \t@ The LSBs in ip are only significant for the final rounding.\n \t@ Fold them into lr.\n \tteq\tip, #0\n+\tdo_it\tne\n \torrne\tlr, lr, #1\n \n \t@ Adjust result upon the MSB position.\n@@ -666,12 +731,14 @@ ARM_FUNC_ALIAS aeabi_dmul muldf3\n \n \t@ Check exponent range for under/overflow.\n \tsubs\tip, r4, #(254 - 1)\n+\tdo_it\thi\n \tcmphi\tip, #0x700\n \tbhi\tLSYM(Lml_u)\n \n \t@ Round the result, merge final exponent.\n \tcmp\tlr, #0x80000000\n-\tmoveqs\tlr, xl, lsr #1\n+\tdo_it\teq\n+\tCOND(mov,s,eq)\tlr, xl, lsr #1\n \tadcs\txl, xl, #0\n \tadc\txh, xh, r4, lsl #20\n \tRETLDM\t\"r4, r5, r6\"\n@@ -683,7 +750,8 @@ LSYM(Lml_1):\n \torr\txl, xl, yl\n \teor\txh, xh, yh\n \tsubs\tr4, r4, ip, lsr #1\n-\trsbgts\tr5, r4, ip\n+\tdo_it\tgt, tt\n+\tCOND(rsb,s,gt)\tr5, r4, ip\n \torrgt\txh, xh, r4, lsl #20\n \tRETLDM\t\"r4, r5, r6\" gt\n \n@@ -698,6 +766,7 @@ LSYM(Lml_u):\n \n \t@ Check if denormalized result is possible, otherwise return signed 0.\n \tcmn\tr4, #(53 + 1)\n+\tdo_it\tle, tt\n \tmovle\txl, #0\n \tbicle\txh, xh, #0x7fffffff\n \tRETLDM\t\"r4, r5, r6\" le\n@@ -712,42 +781,45 @@ LSYM(Lml_u):\n \t@ shift result right of 1 to 20 bits, preserve sign bit, round, etc.\n \tadd\tr4, r4, #20\n \trsb\tr5, r4, #32\n-\tmov\tr3, xl, lsl r5\n-\tmov\txl, xl, lsr r4\n-\torr\txl, xl, xh, lsl r5\n+\tshift1\tlsl, r3, xl, r5\n+\tshift1\tlsr, xl, xl, r4\n+\tshiftop orr xl xl xh lsl r5 r2\n \tand\tr2, xh, #0x80000000\n \tbic\txh, xh, #0x80000000\n \tadds\txl, xl, r3, lsr #31\n-\tadc\txh, r2, xh, lsr r4\n+\tshiftop adc xh r2 xh lsr r4 r6\n \torrs\tlr, lr, r3, lsl #1\n+\tdo_it\teq\n \tbiceq\txl, xl, r3, lsr #31\n \tRETLDM\t\"r4, r5, r6\"\n \n \t@ shift result right of 21 to 31 bits, or left 11 to 1 bits after\n \t@ a register switch from xh to xl. Then round.\n 1:\trsb\tr4, r4, #12\n \trsb\tr5, r4, #32\n-\tmov\tr3, xl, lsl r4\n-\tmov\txl, xl, lsr r5\n-\torr\txl, xl, xh, lsl r4\n+\tshift1\tlsl, r3, xl, r4\n+\tshift1\tlsr, xl, xl, r5\n+\tshiftop orr xl xl xh lsl r4 r2\n \tbic\txh, xh, #0x7fffffff\n \tadds\txl, xl, r3, lsr #31\n \tadc\txh, xh, #0\n \torrs\tlr, lr, r3, lsl #1\n+\tdo_it\teq\n \tbiceq\txl, xl, r3, lsr #31\n \tRETLDM\t\"r4, r5, r6\"\n \n \t@ Shift value right of 32 to 64 bits, or 0 to 32 bits after a switch\n \t@ from xh to xl.  Leftover bits are in r3-r6-lr for rounding.\n 2:\trsb\tr5, r4, #32\n-\torr\tlr, lr, xl, lsl r5\n-\tmov\tr3, xl, lsr r4\n-\torr\tr3, r3, xh, lsl r5\n-\tmov\txl, xh, lsr r4\n+\tshiftop orr lr lr xl lsl r5 r2\n+\tshift1\tlsr, r3, xl, r4\n+\tshiftop orr r3 r3 xh lsl r5 r2\n+\tshift1\tlsr, xl, xh, r4\n \tbic\txh, xh, #0x7fffffff\n-\tbic\txl, xl, xh, lsr r4\n+\tshiftop bic xl xl xh lsr r4 r2\n \tadd\txl, xl, r3, lsr #31\n \torrs\tlr, lr, r3, lsl #1\n+\tdo_it\teq\n \tbiceq\txl, xl, r3, lsr #31\n \tRETLDM\t\"r4, r5, r6\"\n \n@@ -760,15 +832,18 @@ LSYM(Lml_d):\n 1:\tmovs\txl, xl, lsl #1\n \tadc\txh, xh, xh\n \ttst\txh, #0x00100000\n+\tdo_it\teq\n \tsubeq\tr4, r4, #1\n \tbeq\t1b\n \torr\txh, xh, r6\n \tteq\tr5, #0\n+\tdo_it\tne\n \tmovne\tpc, lr\n 2:\tand\tr6, yh, #0x80000000\n 3:\tmovs\tyl, yl, lsl #1\n \tadc\tyh, yh, yh\n \ttst\tyh, #0x00100000\n+\tdo_it\teq\n \tsubeq\tr5, r5, #1\n \tbeq\t3b\n \torr\tyh, yh, r6\n@@ -778,26 +853,29 @@ LSYM(Lml_s):\n \t@ Isolate the INF and NAN cases away\n \tteq\tr4, ip\n \tand\tr5, ip, yh, lsr #20\n+\tdo_it\tne\n \tteqne\tr5, ip\n \tbeq\t1f\n \n \t@ Here, one or more arguments are either denormalized or zero.\n \torrs\tr6, xl, xh, lsl #1\n-\torrnes\tr6, yl, yh, lsl #1\n+\tdo_it\tne\n+\tCOND(orr,s,ne)\tr6, yl, yh, lsl #1\n \tbne\tLSYM(Lml_d)\n \n \t@ Result is 0, but determine sign anyway.\n LSYM(Lml_z):\n \teor\txh, xh, yh\n-\tbic\txh, xh, #0x7fffffff\n+\tand\txh, xh, #0x80000000\n \tmov\txl, #0\n \tRETLDM\t\"r4, r5, r6\"\n \n 1:\t@ One or both args are INF or NAN.\n \torrs\tr6, xl, xh, lsl #1\n+\tdo_it\teq, te\n \tmoveq\txl, yl\n \tmoveq\txh, yh\n-\torrnes\tr6, yl, yh, lsl #1\n+\tCOND(orr,s,ne)\tr6, yl, yh, lsl #1\n \tbeq\tLSYM(Lml_n)\t\t@ 0 * INF or INF * 0 -> NAN\n \tteq\tr4, ip\n \tbne\t1f\n@@ -806,6 +884,7 @@ LSYM(Lml_z):\n 1:\tteq\tr5, ip\n \tbne\tLSYM(Lml_i)\n \torrs\tr6, yl, yh, lsl #12\n+\tdo_it\tne, t\n \tmovne\txl, yl\n \tmovne\txh, yh\n \tbne\tLSYM(Lml_n)\t\t@ <anything> * NAN -> NAN\n@@ -834,13 +913,14 @@ LSYM(Lml_n):\n ARM_FUNC_START divdf3\n ARM_FUNC_ALIAS aeabi_ddiv divdf3\n \t\n-\tstmfd\tsp!, {r4, r5, r6, lr}\n+\tdo_push\t{r4, r5, r6, lr}\n \n \t@ Mask out exponents, trap any zero/denormal/INF/NAN.\n \tmov\tip, #0xff\n \torr\tip, ip, #0x700\n \tands\tr4, ip, xh, lsr #20\n-\tandnes\tr5, ip, yh, lsr #20\n+\tdo_it\tne, tte\n+\tCOND(and,s,ne)\tr5, ip, yh, lsr #20\n \tteqne\tr4, ip\n \tteqne\tr5, ip\n \tbleq\tLSYM(Ldv_s)\n@@ -871,6 +951,7 @@ ARM_FUNC_ALIAS aeabi_ddiv divdf3\n \t@ Ensure result will land to known bit position.\n \t@ Apply exponent bias accordingly.\n \tcmp\tr5, yh\n+\tdo_it\teq\n \tcmpeq\tr6, yl\n \tadc\tr4, r4, #(255 - 2)\n \tadd\tr4, r4, #0x300\n@@ -889,27 +970,31 @@ ARM_FUNC_ALIAS aeabi_ddiv divdf3\n \t@ The actual division loop.\n 1:\tsubs\tlr, r6, yl\n \tsbcs\tlr, r5, yh\n+\tdo_it\tcs, tt\n \tsubcs\tr6, r6, yl\n \tmovcs\tr5, lr\n \torrcs\txl, xl, ip\n \tmovs\tyh, yh, lsr #1\n \tmov\tyl, yl, rrx\n \tsubs\tlr, r6, yl\n \tsbcs\tlr, r5, yh\n+\tdo_it\tcs, tt\n \tsubcs\tr6, r6, yl\n \tmovcs\tr5, lr\n \torrcs\txl, xl, ip, lsr #1\n \tmovs\tyh, yh, lsr #1\n \tmov\tyl, yl, rrx\n \tsubs\tlr, r6, yl\n \tsbcs\tlr, r5, yh\n+\tdo_it\tcs, tt\n \tsubcs\tr6, r6, yl\n \tmovcs\tr5, lr\n \torrcs\txl, xl, ip, lsr #2\n \tmovs\tyh, yh, lsr #1\n \tmov\tyl, yl, rrx\n \tsubs\tlr, r6, yl\n \tsbcs\tlr, r5, yh\n+\tdo_it\tcs, tt\n \tsubcs\tr6, r6, yl\n \tmovcs\tr5, lr\n \torrcs\txl, xl, ip, lsr #3\n@@ -936,18 +1021,21 @@ ARM_FUNC_ALIAS aeabi_ddiv divdf3\n 2:\n \t@ Be sure result starts in the high word.\n \ttst\txh, #0x00100000\n+\tdo_it\teq, t\n \torreq\txh, xh, xl\n \tmoveq\txl, #0\n 3:\n \t@ Check exponent range for under/overflow.\n \tsubs\tip, r4, #(254 - 1)\n+\tdo_it\thi\n \tcmphi\tip, #0x700\n \tbhi\tLSYM(Lml_u)\n \n \t@ Round the result, merge final exponent.\n \tsubs\tip, r5, yh\n-\tsubeqs\tip, r6, yl\n-\tmoveqs\tip, xl, lsr #1\n+\tdo_it\teq, t\n+\tCOND(sub,s,eq)\tip, r6, yl\n+\tCOND(mov,s,eq)\tip, xl, lsr #1\n \tadcs\txl, xl, #0\n \tadc\txh, xh, r4, lsl #20\n \tRETLDM\t\"r4, r5, r6\"\n@@ -957,7 +1045,8 @@ LSYM(Ldv_1):\n \tand\tlr, lr, #0x80000000\n \torr\txh, lr, xh, lsr #12\n \tadds\tr4, r4, ip, lsr #1\n-\trsbgts\tr5, r4, ip\n+\tdo_it\tgt, tt\n+\tCOND(rsb,s,gt)\tr5, r4, ip\n \torrgt\txh, xh, r4, lsl #20\n \tRETLDM\t\"r4, r5, r6\" gt\n \n@@ -976,6 +1065,7 @@ LSYM(Ldv_u):\n LSYM(Ldv_s):\n \tand\tr5, ip, yh, lsr #20\n \tteq\tr4, ip\n+\tdo_it\teq\n \tteqeq\tr5, ip\n \tbeq\tLSYM(Lml_n)\t\t@ INF/NAN / INF/NAN -> NAN\n \tteq\tr4, ip\n@@ -996,7 +1086,8 @@ LSYM(Ldv_s):\n \tb\tLSYM(Lml_n)\t\t@ <anything> / NAN -> NAN\n 2:\t@ If both are nonzero, we need to normalize and resume above.\n \torrs\tr6, xl, xh, lsl #1\n-\torrnes\tr6, yl, yh, lsl #1\n+\tdo_it\tne\n+\tCOND(orr,s,ne)\tr6, yl, yh, lsl #1\n \tbne\tLSYM(Lml_d)\n \t@ One or both arguments are 0.\n \torrs\tr4, xl, xh, lsl #1\n@@ -1035,14 +1126,17 @@ ARM_FUNC_ALIAS eqdf2 cmpdf2\n \tmov\tip, xh, lsl #1\n \tmvns\tip, ip, asr #21\n \tmov\tip, yh, lsl #1\n-\tmvnnes\tip, ip, asr #21\n+\tdo_it\tne\n+\tCOND(mvn,s,ne)\tip, ip, asr #21\n \tbeq\t3f\n \n \t@ Test for equality.\n \t@ Note that 0.0 is equal to -0.0.\n 2:\torrs\tip, xl, xh, lsl #1\t@ if x == 0.0 or -0.0\n-\torreqs\tip, yl, yh, lsl #1\t@ and y == 0.0 or -0.0\n+\tdo_it\teq, e\n+\tCOND(orr,s,eq)\tip, yl, yh, lsl #1\t@ and y == 0.0 or -0.0\n \tteqne\txh, yh\t\t\t@ or xh == yh\n+\tdo_it\teq, tt\n \tteqeq\txl, yl\t\t\t@ and xl == yl\n \tmoveq\tr0, #0\t\t\t@ then equal.\n \tRETc(eq)\n@@ -1054,10 +1148,13 @@ ARM_FUNC_ALIAS eqdf2 cmpdf2\n \tteq\txh, yh\n \n \t@ Compare values if same sign\n+\tdo_it\tpl\n \tcmppl\txh, yh\n+\tdo_it\teq\n \tcmpeq\txl, yl\n \n \t@ Result:\n+\tdo_it\tcs, e\n \tmovcs\tr0, yh, asr #31\n \tmvncc\tr0, yh, asr #31\n \torr\tr0, r0, #1\n@@ -1100,14 +1197,15 @@ ARM_FUNC_ALIAS aeabi_cdcmple aeabi_cdcmpeq\n \n \t@ The status-returning routines are required to preserve all\n \t@ registers except ip, lr, and cpsr.\n-6:\tstmfd\tsp!, {r0, lr}\n+6:\tdo_push\t{r0, lr}\n \tARM_CALL cmpdf2\n \t@ Set the Z flag correctly, and the C flag unconditionally.\n-\tcmp\t r0, #0\n+\tcmp\tr0, #0\n \t@ Clear the C flag if the return value was -1, indicating\n \t@ that the first operand was smaller than the second.\n-\tcmnmi\t r0, #0\n-\tRETLDM   \"r0\"\n+\tdo_it\tmi\n+\tcmnmi\tr0, #0\n+\tRETLDM\t\"r0\"\n \n \tFUNC_END aeabi_cdcmple\n \tFUNC_END aeabi_cdcmpeq\n@@ -1117,6 +1215,7 @@ ARM_FUNC_START\taeabi_dcmpeq\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cdcmple\n+\tdo_it\teq, e\n \tmoveq\tr0, #1\t@ Equal to.\n \tmovne\tr0, #0\t@ Less than, greater than, or unordered.\n \tRETLDM\n@@ -1127,6 +1226,7 @@ ARM_FUNC_START\taeabi_dcmplt\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cdcmple\n+\tdo_it\tcc, e\n \tmovcc\tr0, #1\t@ Less than.\n \tmovcs\tr0, #0\t@ Equal to, greater than, or unordered.\n \tRETLDM\n@@ -1137,6 +1237,7 @@ ARM_FUNC_START\taeabi_dcmple\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cdcmple\n+\tdo_it\tls, e\n \tmovls\tr0, #1  @ Less than or equal to.\n \tmovhi\tr0, #0\t@ Greater than or unordered.\n \tRETLDM\n@@ -1147,6 +1248,7 @@ ARM_FUNC_START\taeabi_dcmpge\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cdrcmple\n+\tdo_it\tls, e\n \tmovls\tr0, #1\t@ Operand 2 is less than or equal to operand 1.\n \tmovhi\tr0, #0\t@ Operand 2 greater than operand 1, or unordered.\n \tRETLDM\n@@ -1157,6 +1259,7 @@ ARM_FUNC_START\taeabi_dcmpgt\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cdrcmple\n+\tdo_it\tcc, e\n \tmovcc\tr0, #1\t@ Operand 2 is less than operand 1.\n \tmovcs\tr0, #0  @ Operand 2 is greater than or equal to operand 1,\n \t\t\t@ or they are unordered.\n@@ -1211,7 +1314,8 @@ ARM_FUNC_ALIAS aeabi_d2iz fixdfsi\n \torr\tr3, r3, #0x80000000\n \torr\tr3, r3, xl, lsr #21\n \ttst\txh, #0x80000000\t\t@ the sign bit\n-\tmov\tr0, r3, lsr r2\n+\tshift1\tlsr, r0, r3, r2\n+\tdo_it\tne\n \trsbne\tr0, r0, #0\n \tRET\n \n@@ -1221,6 +1325,7 @@ ARM_FUNC_ALIAS aeabi_d2iz fixdfsi\n 2:\torrs\txl, xl, xh, lsl #12\n \tbne\t4f\t\t\t@ x is NAN.\n 3:\tands\tr0, xh, #0x80000000\t@ the sign bit\n+\tdo_it\teq\n \tmoveq\tr0, #0x7fffffff\t\t@ maximum signed positive si\n \tRET\n \n@@ -1251,7 +1356,7 @@ ARM_FUNC_ALIAS aeabi_d2uiz fixunsdfsi\n \tmov\tr3, xh, lsl #11\n \torr\tr3, r3, #0x80000000\n \torr\tr3, r3, xl, lsr #21\n-\tmov\tr0, r3, lsr r2\n+\tshift1\tlsr, r0, r3, r2\n \tRET\n \n 1:\tmov\tr0, #0\n@@ -1278,8 +1383,9 @@ ARM_FUNC_ALIAS aeabi_d2f truncdfsf2\n \t@ check exponent range.\n \tmov\tr2, xh, lsl #1\n \tsubs\tr3, r2, #((1023 - 127) << 21)\n-\tsubcss\tip, r3, #(1 << 21)\n-\trsbcss\tip, ip, #(254 << 21)\n+\tdo_it\tcs, t\n+\tCOND(sub,s,cs)\tip, r3, #(1 << 21)\n+\tCOND(rsb,s,cs)\tip, ip, #(254 << 21)\n \tbls\t2f\t\t\t@ value is out of range\n \n 1:\t@ shift and round mantissa\n@@ -1288,6 +1394,7 @@ ARM_FUNC_ALIAS aeabi_d2f truncdfsf2\n \torr\txl, ip, xl, lsr #29\n \tcmp\tr2, #0x80000000\n \tadc\tr0, xl, r3, lsl #2\n+\tdo_it\teq\n \tbiceq\tr0, r0, #1\n \tRET\n \n@@ -1297,6 +1404,7 @@ ARM_FUNC_ALIAS aeabi_d2f truncdfsf2\n \n \t@ check if denormalized value is possible\n \tadds\tr2, r3, #(23 << 21)\n+\tdo_it\tlt, t\n \tandlt\tr0, xh, #0x80000000\t@ too small, return signed 0.\n \tRETc(lt)\n \n@@ -1305,20 +1413,26 @@ ARM_FUNC_ALIAS aeabi_d2f truncdfsf2\n \tmov\tr2, r2, lsr #21\n \trsb\tr2, r2, #24\n \trsb\tip, r2, #32\n+#if defined(__thumb2__)\n+\tlsls\tr3, xl, ip\n+#else\n \tmovs\tr3, xl, lsl ip\n-\tmov\txl, xl, lsr r2\n+#endif\n+\tshift1\tlsr, xl, xl, r2\n+\tdo_it\tne\n \torrne\txl, xl, #1\t\t@ fold r3 for rounding considerations. \n \tmov\tr3, xh, lsl #11\n \tmov\tr3, r3, lsr #11\n-\torr\txl, xl, r3, lsl ip\n-\tmov\tr3, r3, lsr r2\n+\tshiftop orr xl xl r3 lsl ip ip\n+\tshift1\tlsr, r3, r3, r2\n \tmov\tr3, r3, lsl #1\n \tb\t1b\n \n 3:\t@ chech for NAN\n \tmvns\tr3, r2, asr #21\n \tbne\t5f\t\t\t@ simple overflow\n \torrs\tr3, xl, xh, lsl #12\n+\tdo_it\tne, tt\n \tmovne\tr0, #0x7f000000\n \torrne\tr0, r0, #0x00c00000\n \tRETc(ne)\t\t\t@ return NAN"}, {"sha": "e36b4a4ed7eec2b0777947ff2c95a7ca3de72684", "filename": "gcc/config/arm/ieee754-sf.S", "status": "modified", "additions": 127, "deletions": 39, "changes": 166, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fieee754-sf.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fieee754-sf.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fieee754-sf.S?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,6 +1,6 @@\n /* ieee754-sf.S single-precision floating point support for ARM\n \n-   Copyright (C) 2003, 2004, 2005  Free Software Foundation, Inc.\n+   Copyright (C) 2003, 2004, 2005, 2007  Free Software Foundation, Inc.\n    Contributed by Nicolas Pitre (nico@cam.org)\n \n    This file is free software; you can redistribute it and/or modify it\n@@ -71,36 +71,42 @@ ARM_FUNC_ALIAS aeabi_fadd addsf3\n \n 1:\t@ Look for zeroes, equal values, INF, or NAN.\n \tmovs\tr2, r0, lsl #1\n-\tmovnes\tr3, r1, lsl #1\n+\tdo_it\tne, ttt\n+\tCOND(mov,s,ne)\tr3, r1, lsl #1\n \tteqne\tr2, r3\n-\tmvnnes\tip, r2, asr #24\n-\tmvnnes\tip, r3, asr #24\n+\tCOND(mvn,s,ne)\tip, r2, asr #24\n+\tCOND(mvn,s,ne)\tip, r3, asr #24\n \tbeq\tLSYM(Lad_s)\n \n \t@ Compute exponent difference.  Make largest exponent in r2,\n \t@ corresponding arg in r0, and positive exponent difference in r3.\n \tmov\tr2, r2, lsr #24\n \trsbs\tr3, r2, r3, lsr #24\n+\tdo_it\tgt, ttt\n \taddgt\tr2, r2, r3\n \teorgt\tr1, r0, r1\n \teorgt\tr0, r1, r0\n \teorgt\tr1, r0, r1\n+\tdo_it\tlt\n \trsblt\tr3, r3, #0\n \n \t@ If exponent difference is too large, return largest argument\n \t@ already in r0.  We need up to 25 bit to handle proper rounding\n \t@ of 0x1p25 - 1.1.\n \tcmp\tr3, #25\n+\tdo_it\thi\n \tRETc(hi)\n \n \t@ Convert mantissa to signed integer.\n \ttst\tr0, #0x80000000\n \torr\tr0, r0, #0x00800000\n \tbic\tr0, r0, #0xff000000\n+\tdo_it\tne\n \trsbne\tr0, r0, #0\n \ttst\tr1, #0x80000000\n \torr\tr1, r1, #0x00800000\n \tbic\tr1, r1, #0xff000000\n+\tdo_it\tne\n \trsbne\tr1, r1, #0\n \n \t@ If exponent == difference, one or both args were denormalized.\n@@ -114,15 +120,20 @@ LSYM(Lad_x):\n \n \t@ Shift and add second arg to first arg in r0.\n \t@ Keep leftover bits into r1.\n-\tadds\tr0, r0, r1, asr r3\n+\tshiftop adds r0 r0 r1 asr r3 ip\n \trsb\tr3, r3, #32\n-\tmov\tr1, r1, lsl r3\n+\tshift1\tlsl, r1, r1, r3\n \n \t@ Keep absolute value in r0-r1, sign in r3 (the n bit was set above)\n \tand\tr3, r0, #0x80000000\n \tbpl\tLSYM(Lad_p)\n+#if defined(__thumb2__)\n+\tnegs\tr1, r1\n+\tsbc\tr0, r0, r0, lsl #1\n+#else\n \trsbs\tr1, r1, #0\n \trsc\tr0, r0, #0\n+#endif\n \n \t@ Determine how to normalize the result.\n LSYM(Lad_p):\n@@ -147,6 +158,7 @@ LSYM(Lad_p):\n LSYM(Lad_e):\n \tcmp\tr1, #0x80000000\n \tadc\tr0, r0, r2, lsl #23\n+\tdo_it\teq\n \tbiceq\tr0, r0, #1\n \torr\tr0, r0, r3\n \tRET\n@@ -185,23 +197,31 @@ LSYM(Lad_l):\n \tclz\tip, r0\n \tsub\tip, ip, #8\n \tsubs\tr2, r2, ip\n-\tmov\tr0, r0, lsl ip\n+\tshift1\tlsl, r0, r0, ip\n \n #endif\n \n \t@ Final result with sign\n \t@ If exponent negative, denormalize result.\n+\tdo_it\tge, et\n \taddge\tr0, r0, r2, lsl #23\n \trsblt\tr2, r2, #0\n \torrge\tr0, r0, r3\n+#if defined(__thumb2__)\n+\tdo_it\tlt, t\n+\tlsrlt\tr0, r0, r2\n+\torrlt\tr0, r3, r0\n+#else\n \torrlt\tr0, r3, r0, lsr r2\n+#endif\n \tRET\n \n \t@ Fixup and adjust bit position for denormalized arguments.\n \t@ Note that r2 must not remain equal to 0.\n LSYM(Lad_d):\n \tteq\tr2, #0\n \teor\tr1, r1, #0x00800000\n+\tdo_it\teq, te\n \teoreq\tr0, r0, #0x00800000\n \taddeq\tr2, r2, #1\n \tsubne\tr3, r3, #1\n@@ -211,30 +231,35 @@ LSYM(Lad_s):\n \tmov\tr3, r1, lsl #1\n \n \tmvns\tip, r2, asr #24\n-\tmvnnes\tip, r3, asr #24\n+\tdo_it\tne\n+\tCOND(mvn,s,ne)\tip, r3, asr #24\n \tbeq\tLSYM(Lad_i)\n \n \tteq\tr2, r3\n \tbeq\t1f\n \n \t@ Result is x + 0.0 = x or 0.0 + y = y.\n \tteq\tr2, #0\n+\tdo_it\teq\n \tmoveq\tr0, r1\n \tRET\n \n 1:\tteq\tr0, r1\n \n \t@ Result is x - x = 0.\n+\tdo_it\tne, t\n \tmovne\tr0, #0\n \tRETc(ne)\n \n \t@ Result is x + x = 2x.\n \ttst\tr2, #0xff000000\n \tbne\t2f\n \tmovs\tr0, r0, lsl #1\n+\tdo_it\tcs\n \torrcs\tr0, r0, #0x80000000\n \tRET\n 2:\tadds\tr2, r2, #(2 << 24)\n+\tdo_it\tcc, t\n \taddcc\tr0, r0, #(1 << 23)\n \tRETc(cc)\n \tand\tr3, r0, #0x80000000\n@@ -253,11 +278,13 @@ LSYM(Lad_o):\n \t@   otherwise return r0 (which is INF or -INF)\n LSYM(Lad_i):\n \tmvns\tr2, r2, asr #24\n+\tdo_it\tne, et\n \tmovne\tr0, r1\n-\tmvneqs\tr3, r3, asr #24\n+\tCOND(mvn,s,eq)\tr3, r3, asr #24\n \tmovne\tr1, r0\n \tmovs\tr2, r0, lsl #9\n-\tmoveqs\tr3, r1, lsl #9\n+\tdo_it\teq, te\n+\tCOND(mov,s,eq)\tr3, r1, lsl #9\n \tteqeq\tr0, r1\n \torrne\tr0, r0, #0x00400000\t@ quiet NAN\n \tRET\n@@ -278,9 +305,11 @@ ARM_FUNC_START floatsisf\n ARM_FUNC_ALIAS aeabi_i2f floatsisf\n \t\n \tands\tr3, r0, #0x80000000\n+\tdo_it\tmi\n \trsbmi\tr0, r0, #0\n \n 1:\tmovs\tip, r0\n+\tdo_it\teq\n \tRETc(eq)\n \n \t@ Add initial exponent to sign\n@@ -302,7 +331,10 @@ ARM_FUNC_ALIAS aeabi_ul2f floatundisf\n \n \torrs\tr2, r0, r1\n #if !defined (__VFP_FP__) && !defined(__SOFTFP__)\n+\tdo_itt\teq\n \tmvfeqs\tf0, #0.0\n+#else\n+\tdo_it\teq\n #endif\n \tRETc(eq)\n \n@@ -314,14 +346,22 @@ ARM_FUNC_ALIAS aeabi_l2f floatdisf\n \n \torrs\tr2, r0, r1\n #if !defined (__VFP_FP__) && !defined(__SOFTFP__)\n+\tdo_it\teq, t\n \tmvfeqs\tf0, #0.0\n+#else\n+\tdo_it\teq\n #endif\n \tRETc(eq)\n \n \tands\tr3, ah, #0x80000000\t@ sign bit in r3\n \tbpl\t1f\n+#if defined(__thumb2__)\n+\tnegs\tal, al\n+\tsbc\tah, ah, ah, lsl #1\n+#else\n \trsbs\tal, al, #0\n \trsc\tah, ah, #0\n+#endif\n 1:\n #if !defined (__VFP_FP__) && !defined(__SOFTFP__)\n \t@ For hard FPA code we want to return via the tail below so that\n@@ -332,28 +372,34 @@ ARM_FUNC_ALIAS aeabi_l2f floatdisf\n #endif\n \n \tmovs\tip, ah\n+\tdo_it\teq, tt\n \tmoveq\tip, al\n \tmoveq\tah, al\n \tmoveq\tal, #0\n \n \t@ Add initial exponent to sign\n \torr\tr3, r3, #((127 + 23 + 32) << 23)\n+\tdo_it\teq\n \tsubeq\tr3, r3, #(32 << 23)\n 2:\tsub\tr3, r3, #(1 << 23)\n \n #if __ARM_ARCH__ < 5\n \n \tmov\tr2, #23\n \tcmp\tip, #(1 << 16)\n+\tdo_it\ths, t\n \tmovhs\tip, ip, lsr #16\n \tsubhs\tr2, r2, #16\n \tcmp\tip, #(1 << 8)\n+\tdo_it\ths, t\n \tmovhs\tip, ip, lsr #8\n \tsubhs\tr2, r2, #8\n \tcmp\tip, #(1 << 4)\n+\tdo_it\ths, t\n \tmovhs\tip, ip, lsr #4\n \tsubhs\tr2, r2, #4\n \tcmp\tip, #(1 << 2)\n+\tdo_it\ths, e\n \tsubhs\tr2, r2, #2\n \tsublo\tr2, r2, ip, lsr #1\n \tsubs\tr2, r2, ip, lsr #3\n@@ -368,19 +414,21 @@ ARM_FUNC_ALIAS aeabi_l2f floatdisf\n \tsub\tr3, r3, r2, lsl #23\n \tblt\t3f\n \n-\tadd\tr3, r3, ah, lsl r2\n-\tmov\tip, al, lsl r2\n+\tshiftop add r3 r3 ah lsl r2 ip\n+\tshift1\tlsl, ip, al, r2\n \trsb\tr2, r2, #32\n \tcmp\tip, #0x80000000\n-\tadc\tr0, r3, al, lsr r2\n+\tshiftop adc r0 r3 al lsr r2 r2\n+\tdo_it\teq\n \tbiceq\tr0, r0, #1\n \tRET\n \n 3:\tadd\tr2, r2, #32\n-\tmov\tip, ah, lsl r2\n+\tshift1\tlsl, ip, ah, r2\n \trsb\tr2, r2, #32\n \torrs\tal, al, ip, lsl #1\n-\tadc\tr0, r3, ah, lsr r2\n+\tshiftop adc r0 r3 ah lsr r2 r2\n+\tdo_it\teq\n \tbiceq\tr0, r0, ip, lsr #31\n \tRET\n \n@@ -408,7 +456,8 @@ ARM_FUNC_ALIAS aeabi_fmul mulsf3\n \t@ Mask out exponents, trap any zero/denormal/INF/NAN.\n \tmov\tip, #0xff\n \tands\tr2, ip, r0, lsr #23\n-\tandnes\tr3, ip, r1, lsr #23\n+\tdo_it\tne, tt\n+\tCOND(and,s,ne)\tr3, ip, r1, lsr #23\n \tteqne\tr2, ip\n \tteqne\tr3, ip\n \tbeq\tLSYM(Lml_s)\n@@ -424,7 +473,8 @@ LSYM(Lml_x):\n \t@ If power of two, branch to a separate path.\n \t@ Make up for final alignment.\n \tmovs\tr0, r0, lsl #9\n-\tmovnes\tr1, r1, lsl #9\n+\tdo_it\tne\n+\tCOND(mov,s,ne)\tr1, r1, lsl #9\n \tbeq\tLSYM(Lml_1)\n \tmov\tr3, #0x08000000\n \torr\tr0, r3, r0, lsr #5\n@@ -436,7 +486,7 @@ LSYM(Lml_x):\n \tand\tr3, ip, #0x80000000\n \n \t@ Well, no way to make it shorter without the umull instruction.\n-\tstmfd\tsp!, {r3, r4, r5}\n+\tdo_push\t{r3, r4, r5}\n \tmov\tr4, r0, lsr #16\n \tmov\tr5, r1, lsr #16\n \tbic\tr0, r0, r4, lsl #16\n@@ -447,7 +497,7 @@ LSYM(Lml_x):\n \tmla\tr0, r4, r1, r0\n \tadds\tr3, r3, r0, lsl #16\n \tadc\tr1, ip, r0, lsr #16\n-\tldmfd\tsp!, {r0, r4, r5}\n+\tdo_pop\t{r0, r4, r5}\n \n #else\n \n@@ -461,6 +511,7 @@ LSYM(Lml_x):\n \n \t@ Adjust result upon the MSB position.\n \tcmp\tr1, #(1 << 23)\n+\tdo_it\tcc, tt\n \tmovcc\tr1, r1, lsl #1\n \torrcc\tr1, r1, r3, lsr #31\n \tmovcc\tr3, r3, lsl #1\n@@ -476,18 +527,21 @@ LSYM(Lml_x):\n \t@ Round the result, merge final exponent.\n \tcmp\tr3, #0x80000000\n \tadc\tr0, r0, r2, lsl #23\n+\tdo_it\teq\n \tbiceq\tr0, r0, #1\n \tRET\n \n \t@ Multiplication by 0x1p*: let''s shortcut a lot of code.\n LSYM(Lml_1):\n \tteq\tr0, #0\n \tand\tip, ip, #0x80000000\n+\tdo_it\teq\n \tmoveq\tr1, r1, lsl #9\n \torr\tr0, ip, r0, lsr #9\n \torr\tr0, r0, r1, lsr #9\n \tsubs\tr2, r2, #127\n-\trsbgts\tr3, r2, #255\n+\tdo_it\tgt, tt\n+\tCOND(rsb,s,gt)\tr3, r2, #255\n \torrgt\tr0, r0, r2, lsl #23\n \tRETc(gt)\n \n@@ -502,18 +556,20 @@ LSYM(Lml_u):\n \n \t@ Check if denormalized result is possible, otherwise return signed 0.\n \tcmn\tr2, #(24 + 1)\n+\tdo_it\tle, t\n \tbicle\tr0, r0, #0x7fffffff\n \tRETc(le)\n \n \t@ Shift value right, round, etc.\n \trsb\tr2, r2, #0\n \tmovs\tr1, r0, lsl #1\n-\tmov\tr1, r1, lsr r2\n+\tshift1\tlsr, r1, r1, r2\n \trsb\tr2, r2, #32\n-\tmov\tip, r0, lsl r2\n+\tshift1\tlsl, ip, r0, r2\n \tmovs\tr0, r1, rrx\n \tadc\tr0, r0, #0\n \torrs\tr3, r3, ip, lsl #1\n+\tdo_it\teq\n \tbiceq\tr0, r0, ip, lsr #31\n \tRET\n \n@@ -522,14 +578,16 @@ LSYM(Lml_u):\n LSYM(Lml_d):\n \tteq\tr2, #0\n \tand\tip, r0, #0x80000000\n-1:\tmoveq\tr0, r0, lsl #1\n+1:\tdo_it\teq, tt\n+\tmoveq\tr0, r0, lsl #1\n \ttsteq\tr0, #0x00800000\n \tsubeq\tr2, r2, #1\n \tbeq\t1b\n \torr\tr0, r0, ip\n \tteq\tr3, #0\n \tand\tip, r1, #0x80000000\n-2:\tmoveq\tr1, r1, lsl #1\n+2:\tdo_it\teq, tt\n+\tmoveq\tr1, r1, lsl #1\n \ttsteq\tr1, #0x00800000\n \tsubeq\tr3, r3, #1\n \tbeq\t2b\n@@ -540,12 +598,14 @@ LSYM(Lml_s):\n \t@ Isolate the INF and NAN cases away\n \tand\tr3, ip, r1, lsr #23\n \tteq\tr2, ip\n+\tdo_it\tne\n \tteqne\tr3, ip\n \tbeq\t1f\n \n \t@ Here, one or more arguments are either denormalized or zero.\n \tbics\tip, r0, #0x80000000\n-\tbicnes\tip, r1, #0x80000000\n+\tdo_it\tne\n+\tCOND(bic,s,ne)\tip, r1, #0x80000000\n \tbne\tLSYM(Lml_d)\n \n \t@ Result is 0, but determine sign anyway.\n@@ -556,6 +616,7 @@ LSYM(Lml_z):\n \n 1:\t@ One or both args are INF or NAN.\n \tteq\tr0, #0x0\n+\tdo_it\tne, ett\n \tteqne\tr0, #0x80000000\n \tmoveq\tr0, r1\n \tteqne\tr1, #0x0\n@@ -568,6 +629,7 @@ LSYM(Lml_z):\n 1:\tteq\tr3, ip\n \tbne\tLSYM(Lml_i)\n \tmovs\tr3, r1, lsl #9\n+\tdo_it\tne\n \tmovne\tr0, r1\n \tbne\tLSYM(Lml_n)\t\t@ <anything> * NAN -> NAN\n \n@@ -597,7 +659,8 @@ ARM_FUNC_ALIAS aeabi_fdiv divsf3\n \t@ Mask out exponents, trap any zero/denormal/INF/NAN.\n \tmov\tip, #0xff\n \tands\tr2, ip, r0, lsr #23\n-\tandnes\tr3, ip, r1, lsr #23\n+\tdo_it\tne, tt\n+\tCOND(and,s,ne)\tr3, ip, r1, lsr #23\n \tteqne\tr2, ip\n \tteqne\tr3, ip\n \tbeq\tLSYM(Ldv_s)\n@@ -624,25 +687,31 @@ LSYM(Ldv_x):\n \t@ Ensure result will land to known bit position.\n \t@ Apply exponent bias accordingly.\n \tcmp\tr3, r1\n+\tdo_it\tcc\n \tmovcc\tr3, r3, lsl #1\n \tadc\tr2, r2, #(127 - 2)\n \n \t@ The actual division loop.\n \tmov\tip, #0x00800000\n 1:\tcmp\tr3, r1\n+\tdo_it\tcs, t\n \tsubcs\tr3, r3, r1\n \torrcs\tr0, r0, ip\n \tcmp\tr3, r1, lsr #1\n+\tdo_it\tcs, t\n \tsubcs\tr3, r3, r1, lsr #1\n \torrcs\tr0, r0, ip, lsr #1\n \tcmp\tr3, r1, lsr #2\n+\tdo_it\tcs, t\n \tsubcs\tr3, r3, r1, lsr #2\n \torrcs\tr0, r0, ip, lsr #2\n \tcmp\tr3, r1, lsr #3\n+\tdo_it\tcs, t\n \tsubcs\tr3, r3, r1, lsr #3\n \torrcs\tr0, r0, ip, lsr #3\n \tmovs\tr3, r3, lsl #4\n-\tmovnes\tip, ip, lsr #4\n+\tdo_it\tne\n+\tCOND(mov,s,ne)\tip, ip, lsr #4\n \tbne\t1b\n \n \t@ Check exponent for under/overflow.\n@@ -652,6 +721,7 @@ LSYM(Ldv_x):\n \t@ Round the result, merge final exponent.\n \tcmp\tr3, r1\n \tadc\tr0, r0, r2, lsl #23\n+\tdo_it\teq\n \tbiceq\tr0, r0, #1\n \tRET\n \n@@ -660,7 +730,8 @@ LSYM(Ldv_1):\n \tand\tip, ip, #0x80000000\n \torr\tr0, ip, r0, lsr #9\n \tadds\tr2, r2, #127\n-\trsbgts\tr3, r2, #255\n+\tdo_it\tgt, tt\n+\tCOND(rsb,s,gt)\tr3, r2, #255\n \torrgt\tr0, r0, r2, lsl #23\n \tRETc(gt)\n \n@@ -674,14 +745,16 @@ LSYM(Ldv_1):\n LSYM(Ldv_d):\n \tteq\tr2, #0\n \tand\tip, r0, #0x80000000\n-1:\tmoveq\tr0, r0, lsl #1\n+1:\tdo_it\teq, tt\n+\tmoveq\tr0, r0, lsl #1\n \ttsteq\tr0, #0x00800000\n \tsubeq\tr2, r2, #1\n \tbeq\t1b\n \torr\tr0, r0, ip\n \tteq\tr3, #0\n \tand\tip, r1, #0x80000000\n-2:\tmoveq\tr1, r1, lsl #1\n+2:\tdo_it\teq, tt\n+\tmoveq\tr1, r1, lsl #1\n \ttsteq\tr1, #0x00800000\n \tsubeq\tr3, r3, #1\n \tbeq\t2b\n@@ -707,7 +780,8 @@ LSYM(Ldv_s):\n \tb\tLSYM(Lml_n)\t\t@ <anything> / NAN -> NAN\n 2:\t@ If both are nonzero, we need to normalize and resume above.\n \tbics\tip, r0, #0x80000000\n-\tbicnes\tip, r1, #0x80000000\n+\tdo_it\tne\n+\tCOND(bic,s,ne)\tip, r1, #0x80000000\n \tbne\tLSYM(Ldv_d)\n \t@ One or both arguments are zero.\n \tbics\tr2, r0, #0x80000000\n@@ -759,18 +833,24 @@ ARM_FUNC_ALIAS eqsf2 cmpsf2\n \tmov\tr2, r0, lsl #1\n \tmov\tr3, r1, lsl #1\n \tmvns\tip, r2, asr #24\n-\tmvnnes\tip, r3, asr #24\n+\tdo_it\tne\n+\tCOND(mvn,s,ne)\tip, r3, asr #24\n \tbeq\t3f\n \n \t@ Compare values.\n \t@ Note that 0.0 is equal to -0.0.\n 2:\torrs\tip, r2, r3, lsr #1\t@ test if both are 0, clear C flag\n+\tdo_it\tne\n \tteqne\tr0, r1\t\t\t@ if not 0 compare sign\n-\tsubpls\tr0, r2, r3\t\t@ if same sign compare values, set r0\n+\tdo_it\tpl\n+\tCOND(sub,s,pl)\tr0, r2, r3\t\t@ if same sign compare values, set r0\n \n \t@ Result:\n+\tdo_it\thi\n \tmovhi\tr0, r1, asr #31\n+\tdo_it\tlo\n \tmvnlo\tr0, r1, asr #31\n+\tdo_it\tne\n \torrne\tr0, r0, #1\n \tRET\n \n@@ -806,14 +886,15 @@ ARM_FUNC_ALIAS aeabi_cfcmple aeabi_cfcmpeq\n \n \t@ The status-returning routines are required to preserve all\n \t@ registers except ip, lr, and cpsr.\n-6:\tstmfd\tsp!, {r0, r1, r2, r3, lr}\n+6:\tdo_push\t{r0, r1, r2, r3, lr}\n \tARM_CALL cmpsf2\n \t@ Set the Z flag correctly, and the C flag unconditionally.\n-\tcmp\t r0, #0\n+\tcmp\tr0, #0\n \t@ Clear the C flag if the return value was -1, indicating\n \t@ that the first operand was smaller than the second.\n-\tcmnmi\t r0, #0\n-\tRETLDM  \"r0, r1, r2, r3\"\n+\tdo_it\tmi\n+\tcmnmi\tr0, #0\n+\tRETLDM\t\"r0, r1, r2, r3\"\n \n \tFUNC_END aeabi_cfcmple\n \tFUNC_END aeabi_cfcmpeq\n@@ -823,6 +904,7 @@ ARM_FUNC_START\taeabi_fcmpeq\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cfcmple\n+\tdo_it\teq, e\n \tmoveq\tr0, #1\t@ Equal to.\n \tmovne\tr0, #0\t@ Less than, greater than, or unordered.\n \tRETLDM\n@@ -833,6 +915,7 @@ ARM_FUNC_START\taeabi_fcmplt\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cfcmple\n+\tdo_it\tcc, e\n \tmovcc\tr0, #1\t@ Less than.\n \tmovcs\tr0, #0\t@ Equal to, greater than, or unordered.\n \tRETLDM\n@@ -843,6 +926,7 @@ ARM_FUNC_START\taeabi_fcmple\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cfcmple\n+\tdo_it\tls, e\n \tmovls\tr0, #1  @ Less than or equal to.\n \tmovhi\tr0, #0\t@ Greater than or unordered.\n \tRETLDM\n@@ -853,6 +937,7 @@ ARM_FUNC_START\taeabi_fcmpge\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cfrcmple\n+\tdo_it\tls, e\n \tmovls\tr0, #1\t@ Operand 2 is less than or equal to operand 1.\n \tmovhi\tr0, #0\t@ Operand 2 greater than operand 1, or unordered.\n \tRETLDM\n@@ -863,6 +948,7 @@ ARM_FUNC_START\taeabi_fcmpgt\n \n \tstr\tlr, [sp, #-8]!\n \tARM_CALL aeabi_cfrcmple\n+\tdo_it\tcc, e\n \tmovcc\tr0, #1\t@ Operand 2 is less than operand 1.\n \tmovcs\tr0, #0  @ Operand 2 is greater than or equal to operand 1,\n \t\t\t@ or they are unordered.\n@@ -914,7 +1000,8 @@ ARM_FUNC_ALIAS aeabi_f2iz fixsfsi\n \tmov\tr3, r0, lsl #8\n \torr\tr3, r3, #0x80000000\n \ttst\tr0, #0x80000000\t\t@ the sign bit\n-\tmov\tr0, r3, lsr r2\n+\tshift1\tlsr, r0, r3, r2\n+\tdo_it\tne\n \trsbne\tr0, r0, #0\n \tRET\n \n@@ -926,6 +1013,7 @@ ARM_FUNC_ALIAS aeabi_f2iz fixsfsi\n \tmovs\tr2, r0, lsl #9\n \tbne\t4f\t\t\t@ r0 is NAN.\n 3:\tands\tr0, r0, #0x80000000\t@ the sign bit\n+\tdo_it\teq\n \tmoveq\tr0, #0x7fffffff\t\t@ the maximum signed positive si\n \tRET\n \n@@ -954,7 +1042,7 @@ ARM_FUNC_ALIAS aeabi_f2uiz fixunssfsi\n \t@ scale the value\n \tmov\tr3, r0, lsl #8\n \torr\tr3, r3, #0x80000000\n-\tmov\tr0, r3, lsr r2\n+\tshift1\tlsr, r0, r3, r2\n \tRET\n \n 1:\tmov\tr0, #0"}, {"sha": "10b915d7748eec477ab20b1db4628a82d2eb648a", "filename": "gcc/config/arm/iwmmxt.md", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fiwmmxt.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fiwmmxt.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fiwmmxt.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,6 @@\n+;; ??? This file needs auditing for thumb2\n ;; Patterns for the Intel Wireless MMX technology architecture.\n-;; Copyright (C) 2003, 2004, 2005 Free Software Foundation, Inc.\n+;; Copyright (C) 2003, 2004, 2005, 2007 Free Software Foundation, Inc.\n ;; Contributed by Red Hat.\n \n ;; This file is part of GCC."}, {"sha": "f0cf5db85e8cff66d19fe41275b0ca4a08e6036d", "filename": "gcc/config/arm/lib1funcs.asm", "status": "modified", "additions": 80, "deletions": 12, "changes": 92, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Flib1funcs.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Flib1funcs.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Flib1funcs.asm?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,7 +1,7 @@\n @ libgcc routines for ARM cpu.\n @ Division routines, written by Richard Earnshaw, (rearnsha@armltd.co.uk)\n \n-/* Copyright 1995, 1996, 1998, 1999, 2000, 2003, 2004, 2005\n+/* Copyright 1995, 1996, 1998, 1999, 2000, 2003, 2004, 2005, 2007\n    Free Software Foundation, Inc.\n \n This file is free software; you can redistribute it and/or modify it\n@@ -69,31 +69,30 @@ Boston, MA 02110-1301, USA.  */\n \n /* Function end macros.  Variants for interworking.  */\n \n-@ This selects the minimum architecture level required.\n-#define __ARM_ARCH__ 3\n-\n #if defined(__ARM_ARCH_3M__) || defined(__ARM_ARCH_4__) \\\n \t|| defined(__ARM_ARCH_4T__)\n /* We use __ARM_ARCH__ set to 4 here, but in reality it's any processor with\n    long multiply instructions.  That includes v3M.  */\n-# undef __ARM_ARCH__\n # define __ARM_ARCH__ 4\n #endif\n \t\n #if defined(__ARM_ARCH_5__) || defined(__ARM_ARCH_5T__) \\\n \t|| defined(__ARM_ARCH_5E__) || defined(__ARM_ARCH_5TE__) \\\n \t|| defined(__ARM_ARCH_5TEJ__)\n-# undef __ARM_ARCH__\n # define __ARM_ARCH__ 5\n #endif\n \n #if defined(__ARM_ARCH_6__) || defined(__ARM_ARCH_6J__) \\\n \t|| defined(__ARM_ARCH_6K__) || defined(__ARM_ARCH_6Z__) \\\n-\t|| defined(__ARM_ARCH_6ZK__)\n-# undef __ARM_ARCH__\n+\t|| defined(__ARM_ARCH_6ZK__) || defined(__ARM_ARCH_6T2__)\n # define __ARM_ARCH__ 6\n #endif\n \n+#if defined(__ARM_ARCH_7__) || defined(__ARM_ARCH_7A__) \\\n+\t|| defined(__ARM_ARCH_7R__) || defined(__ARM_ARCH_7M__)\n+# define __ARM_ARCH__ 7\n+#endif\n+\n #ifndef __ARM_ARCH__\n #error Unable to determine architecture.\n #endif\n@@ -193,22 +192,63 @@ LSYM(Lend_fde):\n \t.ifc \"\\regs\",\"\"\n \tldr\\cond\tlr, [sp], #8\n \t.else\n+# if defined(__thumb2__)\n+\tpop\\cond\t{\\regs, lr}\n+# else\n \tldm\\cond\\dirn\tsp!, {\\regs, lr}\n+# endif\n \t.endif\n \t.ifnc \"\\unwind\", \"\"\n \t/* Mark LR as restored.  */\n 97:\tcfi_pop 97b - \\unwind, 0xe, 0x0\n \t.endif\n \tbx\\cond\tlr\n #else\n+\t/* Caller is responsible for providing IT instruction.  */\n \t.ifc \"\\regs\",\"\"\n \tldr\\cond\tpc, [sp], #8\n \t.else\n-\tldm\\cond\\dirn\tsp!, {\\regs, pc}\n+# if defined(__thumb2__)\n+\tpop\\cond\t{\\regs, pc}\n+# else\n+\tldm\\cond\\dirn\tsp!, {\\regs, lr}\n+# endif\n \t.endif\n #endif\n .endm\n \n+/* The Unified assembly syntax allows the same code to be assembled for both\n+   ARM and Thumb-2.  However this is only supported by recent gas, so define\n+   a set of macros to allow ARM code on older assemblers.  */\n+#if defined(__thumb2__)\n+.macro do_it cond, suffix=\"\"\n+\tit\\suffix\t\\cond\n+.endm\n+.macro shift1 op, arg0, arg1, arg2\n+\t\\op\t\\arg0, \\arg1, \\arg2\n+.endm\n+#define do_push\tpush\n+#define do_pop\tpop\n+#define COND(op1, op2, cond) op1 ## op2 ## cond\n+/* Perform an arithmetic operation with a variable shift operand.  This\n+   requires two instructions and a scratch register on Thumb-2.  */\n+.macro shiftop name, dest, src1, src2, shiftop, shiftreg, tmp\n+\t\\shiftop \\tmp, \\src2, \\shiftreg\n+\t\\name \\dest, \\src1, \\tmp\n+.endm\n+#else\n+.macro do_it cond, suffix=\"\"\n+.endm\n+.macro shift1 op, arg0, arg1, arg2\n+\tmov\t\\arg0, \\arg1, \\op \\arg2\n+.endm\n+#define do_push\tstmfd sp!,\n+#define do_pop\tldmfd sp!,\n+#define COND(op1, op2, cond) op1 ## cond ## op2\n+.macro shiftop name, dest, src1, src2, shiftop, shiftreg, tmp\n+\t\\name \\dest, \\src1, \\src2, \\shiftop \\shiftreg\n+.endm\n+#endif\n \n .macro ARM_LDIV0 name\n \tstr\tlr, [sp, #-8]!\n@@ -260,25 +300,45 @@ SYM (\\name):\n #ifdef __thumb__\n #define THUMB_FUNC .thumb_func\n #define THUMB_CODE .force_thumb\n+# if defined(__thumb2__)\n+#define THUMB_SYNTAX .syntax divided\n+# else\n+#define THUMB_SYNTAX\n+# endif\n #else\n #define THUMB_FUNC\n #define THUMB_CODE\n+#define THUMB_SYNTAX\n #endif\n-\t\n+\n .macro FUNC_START name\n \t.text\n \t.globl SYM (__\\name)\n \tTYPE (__\\name)\n \t.align 0\n \tTHUMB_CODE\n \tTHUMB_FUNC\n+\tTHUMB_SYNTAX\n SYM (__\\name):\n .endm\n \n /* Special function that will always be coded in ARM assembly, even if\n    in Thumb-only compilation.  */\n \n-#if defined(__INTERWORKING_STUBS__)\n+#if defined(__thumb2__)\n+\n+/* For Thumb-2 we build everything in thumb mode.  */\n+.macro ARM_FUNC_START name\n+       FUNC_START \\name\n+       .syntax unified\n+.endm\n+#define EQUIV .thumb_set\n+.macro  ARM_CALL name\n+\tbl\t__\\name\n+.endm\n+\n+#elif defined(__INTERWORKING_STUBS__)\n+\n .macro\tARM_FUNC_START name\n \tFUNC_START \\name\n \tbx\tpc\n@@ -294,7 +354,9 @@ _L__\\name:\n .macro  ARM_CALL name\n \tbl\t_L__\\name\n .endm\n-#else\n+\n+#else /* !(__INTERWORKING_STUBS__ || __thumb2__) */\n+\n .macro\tARM_FUNC_START name\n \t.text\n \t.globl SYM (__\\name)\n@@ -307,6 +369,7 @@ SYM (__\\name):\n .macro  ARM_CALL name\n \tbl\t__\\name\n .endm\n+\n #endif\n \n .macro\tFUNC_ALIAS new old\n@@ -1183,6 +1246,10 @@ LSYM(Lover12):\n \n #endif /* L_call_via_rX */\n \n+/* Don't bother with the old interworking routines for Thumb-2.  */\n+/* ??? Maybe only omit these on v7m.  */\n+#ifndef __thumb2__\n+\n #if defined L_interwork_call_via_rX\n \n /* These labels & instructions are used by the Arm/Thumb interworking code,\n@@ -1307,6 +1374,7 @@ LSYM(Lchange_\\register):\n \tSIZE\t(_interwork_call_via_lr)\n \t\n #endif /* L_interwork_call_via_rX */\n+#endif /* !__thumb2__ */\n #endif /* Arch supports thumb.  */\n \n #ifndef __symbian__"}, {"sha": "ef3f89aafcb882b33486a73ed4a6cf9453aab7f5", "filename": "gcc/config/arm/libunwind.S", "status": "modified", "additions": 21, "deletions": 4, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Flibunwind.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Flibunwind.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Flibunwind.S?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n /* Support functions for the unwinder.\n-   Copyright (C) 2003, 2004, 2005  Free Software Foundation, Inc.\n+   Copyright (C) 2003, 2004, 2005, 2007  Free Software Foundation, Inc.\n    Contributed by Paul Brook\n \n    This file is free software; you can redistribute it and/or modify it\n@@ -49,7 +49,14 @@ ARM_FUNC_START restore_core_regs\n \t   this.  */\n \tadd r1, r0, #52\n \tldmia r1, {r3, r4, r5}  /* {sp, lr, pc}.  */\n-#ifdef __INTERWORKING__\n+#if defined(__thumb2__)\n+\t/* Thumb-2 doesn't allow sp in a load-multiple instruction, so push\n+\t   the target address onto the target stack.  This is safe as\n+\t   we're always returning to somewhere further up the call stack.  */\n+\tmov ip, r3\n+\tmov lr, r4\n+\tstr r5, [ip, #-4]!\n+#elif defined(__INTERWORKING__)\n \t/* Restore pc into ip.  */\n \tmov r2, r5\n \tstmfd sp!, {r2, r3, r4}\n@@ -58,8 +65,12 @@ ARM_FUNC_START restore_core_regs\n #endif\n \t/* Don't bother restoring ip.  */\n \tldmia r0, {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, sl, fp}\n+#if defined(__thumb2__)\n+\t/* Pop the return address off the target stack.  */\n+\tmov sp, ip\n+\tpop {pc}\n+#elif defined(__INTERWORKING__)\n \t/* Pop the three registers we pushed earlier.  */\n-#ifdef __INTERWORKING__\n \tldmfd sp, {ip, sp, lr}\n \tbx ip\n #else\n@@ -114,7 +125,13 @@ ARM_FUNC_START gnu_Unwind_Save_VFP_D_16_to_31\n \tARM_FUNC_START \\name\n \t/* Create a phase2_vrs structure.  */\n \t/* Split reg push in two to ensure the correct value for sp.  */\n+#if defined(__thumb2__)\n+\tmov ip, sp\n+\tpush {lr} /* PC is ignored.  */\n+\tpush {ip, lr} /* Push original SP and LR.  */\n+#else\n \tstmfd sp!, {sp, lr, pc}\n+#endif\n \tstmfd sp!, {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, sl, fp, ip}\n \t\n \t/* Demand-save flags, plus an extra word for alignment.  */\n@@ -123,7 +140,7 @@ ARM_FUNC_START gnu_Unwind_Save_VFP_D_16_to_31\n \n \t/* Point r1 at the block.  Pass r[0..nargs) unchanged.  */\n \tadd r\\nargs, sp, #4\n-#if defined(__thumb__)\n+#if defined(__thumb__) && !defined(__thumb2__)\n \t/* Switch back to thumb mode to avoid interworking hassle.  */\n \tadr ip, .L1_\\name\n \torr ip, ip, #1"}, {"sha": "06d83711d54e37c68343cb12498fbaa6ebdb2299", "filename": "gcc/config/arm/predicates.md", "status": "modified", "additions": 17, "deletions": 3, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fpredicates.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n ;; Predicate definitions for ARM and Thumb\n-;; Copyright (C) 2004 Free Software Foundation, Inc.\n+;; Copyright (C) 2004, 2007 Free Software Foundation, Inc.\n ;; Contributed by ARM Ltd.\n \n ;; This file is part of GCC.\n@@ -39,6 +39,16 @@\n   return REGNO (op) < FIRST_PSEUDO_REGISTER;\n })\n \n+;; A low register.\n+(define_predicate \"low_register_operand\"\n+  (and (match_code \"reg\")\n+       (match_test \"REGNO (op) <= LAST_LO_REGNUM\")))\n+\n+;; A low register or const_int.\n+(define_predicate \"low_reg_or_int_operand\"\n+  (ior (match_code \"const_int\")\n+       (match_operand 0 \"low_register_operand\")))\n+\n ;; Any core register, or any pseudo.  */ \n (define_predicate \"arm_general_register_operand\"\n   (match_code \"reg,subreg\")\n@@ -174,6 +184,10 @@\n \t    (match_code \"ashift,ashiftrt,lshiftrt,rotatert\"))\n        (match_test \"mode == GET_MODE (op)\")))\n \n+;; True for operators that have 16-bit thumb variants.  */\n+(define_special_predicate \"thumb_16bit_operator\"\n+  (match_code \"plus,minus,and,ior,xor\"))\n+\n ;; True for EQ & NE\n (define_special_predicate \"equality_operator\"\n   (match_code \"eq,ne\"))\n@@ -399,13 +413,13 @@\n ;; Thumb predicates\n ;;\n \n-(define_predicate \"thumb_cmp_operand\"\n+(define_predicate \"thumb1_cmp_operand\"\n   (ior (and (match_code \"reg,subreg\")\n \t    (match_operand 0 \"s_register_operand\"))\n        (and (match_code \"const_int\")\n \t    (match_test \"((unsigned HOST_WIDE_INT) INTVAL (op)) < 256\"))))\n \n-(define_predicate \"thumb_cmpneg_operand\"\n+(define_predicate \"thumb1_cmpneg_operand\"\n   (and (match_code \"const_int\")\n        (match_test \"INTVAL (op) < 0 && INTVAL (op) > -256\")))\n "}, {"sha": "172740722ca63f600c64d0eedb3c7d73142a0f37", "filename": "gcc/config/arm/t-arm", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Ft-arm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Ft-arm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Ft-arm?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -10,7 +10,8 @@ MD_INCLUDES= \t$(srcdir)/config/arm/arm-tune.md \\\n \t\t$(srcdir)/config/arm/cirrus.md \\\n \t\t$(srcdir)/config/arm/fpa.md \\\n \t\t$(srcdir)/config/arm/iwmmxt.md \\\n-\t\t$(srcdir)/config/arm/vfp.md\n+\t\t$(srcdir)/config/arm/vfp.md \\\n+\t\t$(srcdir)/config/arm/thumb2.md\n \n s-config s-conditions s-flags s-codes s-constants s-emit s-recog s-preds \\\n \ts-opinit s-extract s-peep s-attr s-attrtab s-output: $(MD_INCLUDES)"}, {"sha": "b423bbb3597ecf14a807324a0e687cfb463c5c0c", "filename": "gcc/config/arm/t-arm-elf", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Ft-arm-elf", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Ft-arm-elf", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Ft-arm-elf?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -11,6 +11,16 @@ MULTILIB_DIRNAMES    = arm thumb\n MULTILIB_EXCEPTIONS  = \n MULTILIB_MATCHES     =\n \n+#MULTILIB_OPTIONS      += march=armv7\n+#MULTILIB_DIRNAMES     += thumb2\n+#MULTILIB_EXCEPTIONS   += march=armv7* marm/*march=armv7*\n+#MULTILIB_MATCHES      += march?armv7=march?armv7-a\n+#MULTILIB_MATCHES      += march?armv7=march?armv7-r\n+#MULTILIB_MATCHES      += march?armv7=march?armv7-m\n+#MULTILIB_MATCHES      += march?armv7=mcpu?cortex-a8\n+#MULTILIB_MATCHES      += march?armv7=mcpu?cortex-r4\n+#MULTILIB_MATCHES      += march?armv7=mcpu?cortex-m3\n+\n # MULTILIB_OPTIONS    += mcpu=ep9312\n # MULTILIB_DIRNAMES   += ep9312\n # MULTILIB_EXCEPTIONS += *mthumb/*mcpu=ep9312*"}, {"sha": "7406b74883c953a1eb49a88609bf0ebebc940e64", "filename": "gcc/config/arm/thumb2.md", "status": "added", "additions": 1188, "deletions": 0, "changes": 1188, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fthumb2.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fthumb2.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fthumb2.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -0,0 +1,1188 @@\n+;; ARM Thumb-2 Machine Description\n+;; Copyright (C) 2007 Free Software Foundation, Inc.\n+;; Written by CodeSourcery, LLC.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify it\n+;; under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 2, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful, but\n+;; WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+;; General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING.  If not, write to the Free\n+;; Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+;; 02111-1307, USA.  */\n+\n+;; Note: Thumb-2 is the variant of the Thumb architecture that adds\n+;; 32-bit encodings of [almost all of] the Arm instruction set.\n+;; Some old documents refer to the relatively minor interworking\n+;; changes made in armv5t as \"thumb2\".  These are considered part\n+;; the 16-bit Thumb-1 instruction set.\n+\n+(define_insn \"*thumb2_incscc\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r\")\n+        (plus:SI (match_operator:SI 2 \"arm_comparison_operator\"\n+                    [(match_operand:CC 3 \"cc_register\" \"\") (const_int 0)])\n+                 (match_operand:SI 1 \"s_register_operand\" \"0,?r\")))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+  it\\\\t%d2\\;add%d2\\\\t%0, %1, #1\n+  ite\\\\t%D2\\;mov%D2\\\\t%0, %1\\;add%d2\\\\t%0, %1, #1\"\n+  [(set_attr \"conds\" \"use\")\n+   (set_attr \"length\" \"6,10\")]\n+)\n+\n+(define_insn \"*thumb2_decscc\"\n+  [(set (match_operand:SI            0 \"s_register_operand\" \"=r,r\")\n+        (minus:SI (match_operand:SI  1 \"s_register_operand\" \"0,?r\")\n+\t\t  (match_operator:SI 2 \"arm_comparison_operator\"\n+                   [(match_operand   3 \"cc_register\" \"\") (const_int 0)])))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   it\\\\t%d2\\;sub%d2\\\\t%0, %1, #1\n+   ite\\\\t%D2\\;mov%D2\\\\t%0, %1\\;sub%d2\\\\t%0, %1, #1\"\n+  [(set_attr \"conds\" \"use\")\n+   (set_attr \"length\" \"6,10\")]\n+)\n+\n+;; Thumb-2 only allows shift by constant on data processing instructions \n+(define_insn \"*thumb_andsi_not_shiftsi_si\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(and:SI (not:SI (match_operator:SI 4 \"shift_operator\"\n+\t\t\t [(match_operand:SI 2 \"s_register_operand\" \"r\")\n+\t\t\t  (match_operand:SI 3 \"const_int_operand\" \"M\")]))\n+\t\t(match_operand:SI 1 \"s_register_operand\" \"r\")))]\n+  \"TARGET_ARM\"\n+  \"bic%?\\\\t%0, %1, %2%S4\"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"shift\" \"2\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_smaxsi3\"\n+  [(set (match_operand:SI          0 \"s_register_operand\" \"=r,r,r\")\n+\t(smax:SI (match_operand:SI 1 \"s_register_operand\"  \"0,r,?r\")\n+\t\t (match_operand:SI 2 \"arm_rhs_operand\"    \"rI,0,rI\")))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   cmp\\\\t%1, %2\\;it\\\\tlt\\;movlt\\\\t%0, %2\n+   cmp\\\\t%1, %2\\;it\\\\tge\\;movge\\\\t%0, %1\n+   cmp\\\\t%1, %2\\;ite\\\\tge\\;movge\\\\t%0, %1\\;movlt\\\\t%0, %2\"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"10,10,14\")]\n+)\n+\n+(define_insn \"*thumb2_sminsi3\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r,r\")\n+\t(smin:SI (match_operand:SI 1 \"s_register_operand\" \"0,r,?r\")\n+\t\t (match_operand:SI 2 \"arm_rhs_operand\" \"rI,0,rI\")))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   cmp\\\\t%1, %2\\;it\\\\tge\\;movge\\\\t%0, %2\n+   cmp\\\\t%1, %2\\;it\\\\tlt\\;movlt\\\\t%0, %1\n+   cmp\\\\t%1, %2\\;ite\\\\tlt\\;movlt\\\\t%0, %1\\;movge\\\\t%0, %2\"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"10,10,14\")]\n+)\n+\n+(define_insn \"*thumb32_umaxsi3\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r,r\")\n+\t(umax:SI (match_operand:SI 1 \"s_register_operand\" \"0,r,?r\")\n+\t\t (match_operand:SI 2 \"arm_rhs_operand\" \"rI,0,rI\")))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   cmp\\\\t%1, %2\\;it\\\\tcc\\;movcc\\\\t%0, %2\n+   cmp\\\\t%1, %2\\;it\\\\tcs\\;movcs\\\\t%0, %1\n+   cmp\\\\t%1, %2\\;ite\\\\tcs\\;movcs\\\\t%0, %1\\;movcc\\\\t%0, %2\"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"10,10,14\")]\n+)\n+\n+(define_insn \"*thumb2_uminsi3\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r,r\")\n+\t(umin:SI (match_operand:SI 1 \"s_register_operand\" \"0,r,?r\")\n+\t\t (match_operand:SI 2 \"arm_rhs_operand\" \"rI,0,rI\")))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   cmp\\\\t%1, %2\\;it\\\\tcs\\;movcs\\\\t%0, %2\n+   cmp\\\\t%1, %2\\;it\\\\tcc\\;movcc\\\\t%0, %1\n+   cmp\\\\t%1, %2\\;ite\\\\tcc\\;movcc\\\\t%0, %1\\;movcs\\\\t%0, %2\"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"10,10,14\")]\n+)\n+\n+(define_insn \"*thumb2_notsi_shiftsi\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(not:SI (match_operator:SI 3 \"shift_operator\"\n+\t\t [(match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t  (match_operand:SI 2 \"const_int_operand\"  \"M\")])))]\n+  \"TARGET_THUMB2\"\n+  \"mvn%?\\\\t%0, %1%S3\"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"shift\" \"1\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_notsi_shiftsi_compare0\"\n+  [(set (reg:CC_NOOV CC_REGNUM)\n+\t(compare:CC_NOOV (not:SI (match_operator:SI 3 \"shift_operator\"\n+\t\t\t  [(match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t\t   (match_operand:SI 2 \"const_int_operand\"  \"M\")]))\n+\t\t\t (const_int 0)))\n+   (set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(not:SI (match_op_dup 3 [(match_dup 1) (match_dup 2)])))]\n+  \"TARGET_THUMB2\"\n+  \"mvn%.\\\\t%0, %1%S3\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"1\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_not_shiftsi_compare0_scratch\"\n+  [(set (reg:CC_NOOV CC_REGNUM)\n+\t(compare:CC_NOOV (not:SI (match_operator:SI 3 \"shift_operator\"\n+\t\t\t  [(match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t\t   (match_operand:SI 2 \"const_int_operand\"  \"M\")]))\n+\t\t\t (const_int 0)))\n+   (clobber (match_scratch:SI 0 \"=r\"))]\n+  \"TARGET_THUMB2\"\n+  \"mvn%.\\\\t%0, %1%S3\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"1\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+;; Thumb-2 does not have rsc, so use a clever trick with shifter operands.\n+(define_insn \"*thumb2_negdi2\"\n+  [(set (match_operand:DI         0 \"s_register_operand\" \"=&r,r\")\n+\t(neg:DI (match_operand:DI 1 \"s_register_operand\"  \"?r,0\")))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"negs\\\\t%Q0, %Q1\\;sbc\\\\t%R0, %R1, %R1, lsl #1\"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"8\")]\n+)\n+\n+(define_insn \"*thumb2_abssi2\"\n+  [(set (match_operand:SI         0 \"s_register_operand\" \"=r,&r\")\n+\t(abs:SI (match_operand:SI 1 \"s_register_operand\" \"0,r\")))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   cmp\\\\t%0, #0\\;it\\tlt\\;rsblt\\\\t%0, %0, #0\n+   eor%?\\\\t%0, %1, %1, asr #31\\;sub%?\\\\t%0, %0, %1, asr #31\"\n+  [(set_attr \"conds\" \"clob,*\")\n+   (set_attr \"shift\" \"1\")\n+   ;; predicable can't be set based on the variant, so left as no\n+   (set_attr \"length\" \"10,8\")]\n+)\n+\n+(define_insn \"*thumb2_neg_abssi2\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,&r\")\n+\t(neg:SI (abs:SI (match_operand:SI 1 \"s_register_operand\" \"0,r\"))))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   cmp\\\\t%0, #0\\;it\\\\tgt\\;rsbgt\\\\t%0, %0, #0\n+   eor%?\\\\t%0, %1, %1, asr #31\\;rsb%?\\\\t%0, %0, %1, asr #31\"\n+  [(set_attr \"conds\" \"clob,*\")\n+   (set_attr \"shift\" \"1\")\n+   ;; predicable can't be set based on the variant, so left as no\n+   (set_attr \"length\" \"10,8\")]\n+)\n+\n+(define_insn \"*thumb2_movdi\"\n+  [(set (match_operand:DI 0 \"nonimmediate_di_operand\" \"=r, r, r, r, m\")\n+\t(match_operand:DI 1 \"di_operand\"              \"rDa,Db,Dc,mi,r\"))]\n+  \"TARGET_THUMB2\n+  && !(TARGET_HARD_FLOAT && (TARGET_MAVERICK || TARGET_VFP))\n+  && !TARGET_IWMMXT\"\n+  \"*\n+  switch (which_alternative)\n+    {\n+    case 0:\n+    case 1:\n+    case 2:\n+      return \\\"#\\\";\n+    default:\n+      return output_move_double (operands);\n+    }\n+  \"\n+  [(set_attr \"length\" \"8,12,16,8,8\")\n+   (set_attr \"type\" \"*,*,*,load2,store2\")\n+   (set_attr \"pool_range\" \"*,*,*,4096,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,*,0,*\")]\n+)\n+\n+(define_insn \"*thumb2_movsi_insn\"\n+  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,r,r,r, m\")\n+\t(match_operand:SI 1 \"general_operand\"\t   \"rI,K,N,mi,r\"))]\n+  \"TARGET_THUMB2 && ! TARGET_IWMMXT\n+   && !(TARGET_HARD_FLOAT && TARGET_VFP)\n+   && (   register_operand (operands[0], SImode)\n+       || register_operand (operands[1], SImode))\"\n+  \"@\n+   mov%?\\\\t%0, %1\n+   mvn%?\\\\t%0, #%B1\n+   movw%?\\\\t%0, %1\n+   ldr%?\\\\t%0, %1\n+   str%?\\\\t%1, %0\"\n+  [(set_attr \"type\" \"*,*,*,load1,store1\")\n+   (set_attr \"predicable\" \"yes\")\n+   (set_attr \"pool_range\" \"*,*,*,4096,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,*,0,*\")]\n+)\n+\n+;; ??? We can probably do better with thumb2\n+(define_insn \"pic_load_addr_thumb2\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(unspec:SI [(match_operand:SI 1 \"\" \"mX\")] UNSPEC_PIC_SYM))]\n+  \"TARGET_THUMB2 && flag_pic\"\n+  \"ldr%?\\\\t%0, %1\"\n+  [(set_attr \"type\" \"load1\")\n+   (set_attr \"pool_range\" \"4096\")\n+   (set_attr \"neg_pool_range\" \"0\")]\n+)\n+\n+;; Set reg to the address of this instruction plus four.  The low two\n+;; bits of the PC are always read as zero, so ensure the instructions is\n+;; word aligned.\n+(define_insn \"pic_load_dot_plus_four\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(unspec:SI [(const (plus:SI (pc) (const_int 4)))]\n+\t\t   UNSPEC_PIC_BASE))\n+   (use (match_operand 1 \"\" \"\"))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+  assemble_align(BITS_PER_WORD);\n+  (*targetm.asm_out.internal_label) (asm_out_file, \\\"LPIC\\\",\n+\t\t\t     INTVAL (operands[1]));\n+  /* We use adr because some buggy gas assemble add r8, pc, #0\n+     to add.w r8, pc, #0, not addw r8, pc, #0.  */\n+  asm_fprintf (asm_out_file, \\\"\\\\tadr\\\\t%r, %LLPIC%d + 4\\\\n\\\",\n+\t       REGNO(operands[0]), (int)INTVAL (operands[1]));\n+  return \\\"\\\";\n+  \"\n+  [(set_attr \"length\" \"6\")]\n+)\n+\n+;; Thumb-2 always has load/store halfword instructions, so we can avoid a lot\n+;; of the messyness assocuated with the ARM patterns.\n+(define_insn \"*thumb2_movhi_insn\"\n+  [(set (match_operand:HI 0 \"nonimmediate_operand\" \"=r,r,m,r\")    \n+\t(match_operand:HI 1 \"general_operand\"      \"rI,n,r,m\"))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   mov%?\\\\t%0, %1\\\\t%@ movhi\n+   movw%?\\\\t%0, %L1\\\\t%@ movhi\n+   str%(h%)\\\\t%1, %0\\\\t%@ movhi\n+   ldr%(h%)\\\\t%0, %1\\\\t%@ movhi\"\n+  [(set_attr \"type\" \"*,*,store1,load1\")\n+   (set_attr \"predicable\" \"yes\")\n+   (set_attr \"pool_range\" \"*,*,*,4096\")\n+   (set_attr \"neg_pool_range\" \"*,*,*,250\")]\n+)\n+\n+(define_insn \"*thumb2_movsf_soft_insn\"\n+  [(set (match_operand:SF 0 \"nonimmediate_operand\" \"=r,r,m\")\n+\t(match_operand:SF 1 \"general_operand\"  \"r,mE,r\"))]\n+  \"TARGET_THUMB2\n+   && TARGET_SOFT_FLOAT\n+   && (GET_CODE (operands[0]) != MEM\n+       || register_operand (operands[1], SFmode))\"\n+  \"@\n+   mov%?\\\\t%0, %1\n+   ldr%?\\\\t%0, %1\\\\t%@ float\n+   str%?\\\\t%1, %0\\\\t%@ float\"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"type\" \"*,load1,store1\")\n+   (set_attr \"pool_range\" \"*,4096,*\")\n+   (set_attr \"neg_pool_range\" \"*,0,*\")]\n+)\n+\n+(define_insn \"*thumb2_movdf_soft_insn\"\n+  [(set (match_operand:DF 0 \"nonimmediate_soft_df_operand\" \"=r,r,r,r,m\")\n+\t(match_operand:DF 1 \"soft_df_operand\" \"rDa,Db,Dc,mF,r\"))]\n+  \"TARGET_THUMB2 && TARGET_SOFT_FLOAT\n+   && (   register_operand (operands[0], DFmode)\n+       || register_operand (operands[1], DFmode))\"\n+  \"*\n+  switch (which_alternative)\n+    {\n+    case 0:\n+    case 1:\n+    case 2:\n+      return \\\"#\\\";\n+    default:\n+      return output_move_double (operands);\n+    }\n+  \"\n+  [(set_attr \"length\" \"8,12,16,8,8\")\n+   (set_attr \"type\" \"*,*,*,load2,store2\")\n+   (set_attr \"pool_range\" \"1020\")\n+   (set_attr \"neg_pool_range\" \"0\")]\n+)\n+\n+(define_insn \"*thumb2_cmpsi_shiftsi\"\n+  [(set (reg:CC CC_REGNUM)\n+\t(compare:CC (match_operand:SI   0 \"s_register_operand\" \"r\")\n+\t\t    (match_operator:SI  3 \"shift_operator\"\n+\t\t     [(match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t      (match_operand:SI 2 \"const_int_operand\"  \"M\")])))]\n+  \"TARGET_THUMB2\"\n+  \"cmp%?\\\\t%0, %1%S3\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"1\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_cmpsi_shiftsi_swp\"\n+  [(set (reg:CC_SWP CC_REGNUM)\n+\t(compare:CC_SWP (match_operator:SI 3 \"shift_operator\"\n+\t\t\t [(match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t\t  (match_operand:SI 2 \"const_int_operand\" \"M\")])\n+\t\t\t(match_operand:SI 0 \"s_register_operand\" \"r\")))]\n+  \"TARGET_THUMB2\"\n+  \"cmp%?\\\\t%0, %1%S3\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"1\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_cmpsi_neg_shiftsi\"\n+  [(set (reg:CC CC_REGNUM)\n+\t(compare:CC (match_operand:SI 0 \"s_register_operand\" \"r\")\n+\t\t    (neg:SI (match_operator:SI 3 \"shift_operator\"\n+\t\t\t     [(match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t\t      (match_operand:SI 2 \"const_int_operand\" \"M\")]))))]\n+  \"TARGET_THUMB2\"\n+  \"cmn%?\\\\t%0, %1%S3\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"1\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_mov_scc\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(match_operator:SI 1 \"arm_comparison_operator\"\n+\t [(match_operand 2 \"cc_register\" \"\") (const_int 0)]))]\n+  \"TARGET_THUMB2\"\n+  \"ite\\\\t%D1\\;mov%D1\\\\t%0, #0\\;mov%d1\\\\t%0, #1\"\n+  [(set_attr \"conds\" \"use\")\n+   (set_attr \"length\" \"10\")]\n+)\n+\n+(define_insn \"*thumb2_mov_negscc\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(neg:SI (match_operator:SI 1 \"arm_comparison_operator\"\n+\t\t [(match_operand 2 \"cc_register\" \"\") (const_int 0)])))]\n+  \"TARGET_THUMB2\"\n+  \"ite\\\\t%D1\\;mov%D1\\\\t%0, #0\\;mvn%d1\\\\t%0, #0\"\n+  [(set_attr \"conds\" \"use\")\n+   (set_attr \"length\" \"10\")]\n+)\n+\n+(define_insn \"*thumb2_mov_notscc\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(not:SI (match_operator:SI 1 \"arm_comparison_operator\"\n+\t\t [(match_operand 2 \"cc_register\" \"\") (const_int 0)])))]\n+  \"TARGET_THUMB2\"\n+  \"ite\\\\t%D1\\;mov%D1\\\\t%0, #0\\;mvn%d1\\\\t%0, #1\"\n+  [(set_attr \"conds\" \"use\")\n+   (set_attr \"length\" \"10\")]\n+)\n+\n+(define_insn \"*thumb2_movsicc_insn\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r,r,r,r,r,r,r\")\n+\t(if_then_else:SI\n+\t (match_operator 3 \"arm_comparison_operator\"\n+\t  [(match_operand 4 \"cc_register\" \"\") (const_int 0)])\n+\t (match_operand:SI 1 \"arm_not_operand\" \"0,0,rI,K,rI,rI,K,K\")\n+\t (match_operand:SI 2 \"arm_not_operand\" \"rI,K,0,0,rI,K,rI,K\")))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   it\\\\t%D3\\;mov%D3\\\\t%0, %2\n+   it\\\\t%D3\\;mvn%D3\\\\t%0, #%B2\n+   it\\\\t%d3\\;mov%d3\\\\t%0, %1\n+   it\\\\t%d3\\;mvn%d3\\\\t%0, #%B1\n+   ite\\\\t%d3\\;mov%d3\\\\t%0, %1\\;mov%D3\\\\t%0, %2\n+   ite\\\\t%d3\\;mov%d3\\\\t%0, %1\\;mvn%D3\\\\t%0, #%B2\n+   ite\\\\t%d3\\;mvn%d3\\\\t%0, #%B1\\;mov%D3\\\\t%0, %2\n+   ite\\\\t%d3\\;mvn%d3\\\\t%0, #%B1\\;mvn%D3\\\\t%0, #%B2\"\n+  [(set_attr \"length\" \"6,6,6,6,10,10,10,10\")\n+   (set_attr \"conds\" \"use\")]\n+)\n+\n+(define_insn \"*thumb2_movsfcc_soft_insn\"\n+  [(set (match_operand:SF 0 \"s_register_operand\" \"=r,r\")\n+\t(if_then_else:SF (match_operator 3 \"arm_comparison_operator\"\n+\t\t\t  [(match_operand 4 \"cc_register\" \"\") (const_int 0)])\n+\t\t\t (match_operand:SF 1 \"s_register_operand\" \"0,r\")\n+\t\t\t (match_operand:SF 2 \"s_register_operand\" \"r,0\")))]\n+  \"TARGET_THUMB2 && TARGET_SOFT_FLOAT\"\n+  \"@\n+   it\\\\t%D3\\;mov%D3\\\\t%0, %2\n+   it\\\\t%d3\\;mov%d3\\\\t%0, %1\"\n+  [(set_attr \"length\" \"6,6\")\n+   (set_attr \"conds\" \"use\")]\n+)\n+\n+(define_insn \"*call_reg_thumb2\"\n+  [(call (mem:SI (match_operand:SI 0 \"s_register_operand\" \"r\"))\n+         (match_operand 1 \"\" \"\"))\n+   (use (match_operand 2 \"\" \"\"))\n+   (clobber (reg:SI LR_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"blx%?\\\\t%0\"\n+  [(set_attr \"type\" \"call\")]\n+)\n+\n+(define_insn \"*call_value_reg_thumb2\"\n+  [(set (match_operand 0 \"\" \"\")\n+\t(call (mem:SI (match_operand:SI 1 \"register_operand\" \"l*r\"))\n+\t      (match_operand 2 \"\" \"\")))\n+   (use (match_operand 3 \"\" \"\"))\n+   (clobber (reg:SI LR_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"blx\\\\t%1\"\n+  [(set_attr \"type\" \"call\")]\n+)\n+\n+(define_insn \"*thumb2_indirect_jump\"\n+  [(set (pc)\n+\t(match_operand:SI 0 \"register_operand\" \"l*r\"))]\n+  \"TARGET_THUMB2\"\n+  \"bx\\\\t%0\"\n+  [(set_attr \"conds\" \"clob\")]\n+)\n+;; Don't define thumb2_load_indirect_jump because we can't guarantee label\n+;; addresses will have the thumb bit set correctly. \n+\n+\n+;; Patterns to allow combination of arithmetic, cond code and shifts\n+\n+(define_insn \"*thumb2_arith_shiftsi\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+        (match_operator:SI 1 \"shiftable_operator\"\n+          [(match_operator:SI 3 \"shift_operator\"\n+             [(match_operand:SI 4 \"s_register_operand\" \"r\")\n+              (match_operand:SI 5 \"const_int_operand\" \"M\")])\n+           (match_operand:SI 2 \"s_register_operand\" \"r\")]))]\n+  \"TARGET_THUMB2\"\n+  \"%i1%?\\\\t%0, %2, %4%S3\"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"shift\" \"4\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+;; ??? What does this splitter do?  Copied from the ARM version\n+(define_split\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"\")\n+\t(match_operator:SI 1 \"shiftable_operator\"\n+\t [(match_operator:SI 2 \"shiftable_operator\"\n+\t   [(match_operator:SI 3 \"shift_operator\"\n+\t     [(match_operand:SI 4 \"s_register_operand\" \"\")\n+\t      (match_operand:SI 5 \"const_int_operand\" \"\")])\n+\t    (match_operand:SI 6 \"s_register_operand\" \"\")])\n+\t  (match_operand:SI 7 \"arm_rhs_operand\" \"\")]))\n+   (clobber (match_operand:SI 8 \"s_register_operand\" \"\"))]\n+  \"TARGET_32BIT\"\n+  [(set (match_dup 8)\n+\t(match_op_dup 2 [(match_op_dup 3 [(match_dup 4) (match_dup 5)])\n+\t\t\t (match_dup 6)]))\n+   (set (match_dup 0)\n+\t(match_op_dup 1 [(match_dup 8) (match_dup 7)]))]\n+  \"\")\n+\n+(define_insn \"*thumb2_arith_shiftsi_compare0\"\n+  [(set (reg:CC_NOOV CC_REGNUM)\n+        (compare:CC_NOOV (match_operator:SI 1 \"shiftable_operator\"\n+\t\t          [(match_operator:SI 3 \"shift_operator\"\n+\t\t            [(match_operand:SI 4 \"s_register_operand\" \"r\")\n+\t\t             (match_operand:SI 5 \"const_int_operand\" \"M\")])\n+\t\t           (match_operand:SI 2 \"s_register_operand\" \"r\")])\n+\t\t\t (const_int 0)))\n+   (set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(match_op_dup 1 [(match_op_dup 3 [(match_dup 4) (match_dup 5)])\n+\t\t\t (match_dup 2)]))]\n+  \"TARGET_32BIT\"\n+  \"%i1%.\\\\t%0, %2, %4%S3\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"4\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_arith_shiftsi_compare0_scratch\"\n+  [(set (reg:CC_NOOV CC_REGNUM)\n+        (compare:CC_NOOV (match_operator:SI 1 \"shiftable_operator\"\n+\t\t          [(match_operator:SI 3 \"shift_operator\"\n+\t\t            [(match_operand:SI 4 \"s_register_operand\" \"r\")\n+\t\t             (match_operand:SI 5 \"const_int_operand\" \"M\")])\n+\t\t           (match_operand:SI 2 \"s_register_operand\" \"r\")])\n+\t\t\t (const_int 0)))\n+   (clobber (match_scratch:SI 0 \"=r\"))]\n+  \"TARGET_THUMB2\"\n+  \"%i1%.\\\\t%0, %2, %4%S3\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"4\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_sub_shiftsi\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(minus:SI (match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t  (match_operator:SI 2 \"shift_operator\"\n+\t\t   [(match_operand:SI 3 \"s_register_operand\" \"r\")\n+\t\t    (match_operand:SI 4 \"const_int_operand\" \"M\")])))]\n+  \"TARGET_THUMB2\"\n+  \"sub%?\\\\t%0, %1, %3%S2\"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"shift\" \"3\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_sub_shiftsi_compare0\"\n+  [(set (reg:CC_NOOV CC_REGNUM)\n+\t(compare:CC_NOOV\n+\t (minus:SI (match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t   (match_operator:SI 2 \"shift_operator\"\n+\t\t    [(match_operand:SI 3 \"s_register_operand\" \"r\")\n+\t\t     (match_operand:SI 4 \"const_int_operand\" \"M\")]))\n+\t (const_int 0)))\n+   (set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(minus:SI (match_dup 1) (match_op_dup 2 [(match_dup 3)\n+\t\t\t\t\t\t (match_dup 4)])))]\n+  \"TARGET_THUMB2\"\n+  \"sub%.\\\\t%0, %1, %3%S2\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"3\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_sub_shiftsi_compare0_scratch\"\n+  [(set (reg:CC_NOOV CC_REGNUM)\n+\t(compare:CC_NOOV\n+\t (minus:SI (match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t   (match_operator:SI 2 \"shift_operator\"\n+\t\t    [(match_operand:SI 3 \"s_register_operand\" \"r\")\n+\t\t     (match_operand:SI 4 \"const_int_operand\" \"M\")]))\n+\t (const_int 0)))\n+   (clobber (match_scratch:SI 0 \"=r\"))]\n+  \"TARGET_THUMB2\"\n+  \"sub%.\\\\t%0, %1, %3%S2\"\n+  [(set_attr \"conds\" \"set\")\n+   (set_attr \"shift\" \"3\")\n+   (set_attr \"type\" \"alu_shift\")]\n+)\n+\n+(define_insn \"*thumb2_and_scc\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(and:SI (match_operator:SI 1 \"arm_comparison_operator\"\n+\t\t [(match_operand 3 \"cc_register\" \"\") (const_int 0)])\n+\t\t(match_operand:SI 2 \"s_register_operand\" \"r\")))]\n+  \"TARGET_THUMB2\"\n+  \"ite\\\\t%D1\\;mov%D1\\\\t%0, #0\\;and%d1\\\\t%0, %2, #1\"\n+  [(set_attr \"conds\" \"use\")\n+   (set_attr \"length\" \"10\")]\n+)\n+\n+(define_insn \"*thumb2_ior_scc\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r\")\n+\t(ior:SI (match_operator:SI 2 \"arm_comparison_operator\"\n+\t\t [(match_operand 3 \"cc_register\" \"\") (const_int 0)])\n+\t\t(match_operand:SI 1 \"s_register_operand\" \"0,?r\")))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   it\\\\t%d2\\;orr%d2\\\\t%0, %1, #1\n+   ite\\\\t%D2\\;mov%D2\\\\t%0, %1\\;orr%d2\\\\t%0, %1, #1\"\n+  [(set_attr \"conds\" \"use\")\n+   (set_attr \"length\" \"6,10\")]\n+)\n+\n+(define_insn \"*thumb2_compare_scc\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r\")\n+\t(match_operator:SI 1 \"arm_comparison_operator\"\n+\t [(match_operand:SI 2 \"s_register_operand\" \"r,r\")\n+\t  (match_operand:SI 3 \"arm_add_operand\" \"rI,L\")]))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+    if (operands[3] == const0_rtx)\n+      {\n+\tif (GET_CODE (operands[1]) == LT)\n+\t  return \\\"lsr\\\\t%0, %2, #31\\\";\n+\n+\tif (GET_CODE (operands[1]) == GE)\n+\t  return \\\"mvn\\\\t%0, %2\\;lsr\\\\t%0, %0, #31\\\";\n+\n+\tif (GET_CODE (operands[1]) == EQ)\n+\t  return \\\"rsbs\\\\t%0, %2, #1\\;it\\\\tcc\\;movcc\\\\t%0, #0\\\";\n+      }\n+\n+    if (GET_CODE (operands[1]) == NE)\n+      {\n+        if (which_alternative == 1)\n+\t  return \\\"adds\\\\t%0, %2, #%n3\\;it\\\\tne\\;movne\\\\t%0, #1\\\";\n+        return \\\"subs\\\\t%0, %2, %3\\;it\\\\tne\\;movne\\\\t%0, #1\\\";\n+      }\n+    if (which_alternative == 1)\n+      output_asm_insn (\\\"cmn\\\\t%2, #%n3\\\", operands);\n+    else\n+      output_asm_insn (\\\"cmp\\\\t%2, %3\\\", operands);\n+    return \\\"ite\\\\t%D1\\;mov%D1\\\\t%0, #0\\;mov%d1\\\\t%0, #1\\\";\n+  \"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"14\")]\n+)\n+\n+(define_insn \"*thumb2_cond_move\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r,r\")\n+\t(if_then_else:SI (match_operator 3 \"equality_operator\"\n+\t\t\t  [(match_operator 4 \"arm_comparison_operator\"\n+\t\t\t    [(match_operand 5 \"cc_register\" \"\") (const_int 0)])\n+\t\t\t   (const_int 0)])\n+\t\t\t (match_operand:SI 1 \"arm_rhs_operand\" \"0,rI,?rI\")\n+\t\t\t (match_operand:SI 2 \"arm_rhs_operand\" \"rI,0,rI\")))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+    if (GET_CODE (operands[3]) == NE)\n+      {\n+        if (which_alternative != 1)\n+\t  output_asm_insn (\\\"it\\\\t%D4\\;mov%D4\\\\t%0, %2\\\", operands);\n+        if (which_alternative != 0)\n+\t  output_asm_insn (\\\"it\\\\t%d4\\;mov%d4\\\\t%0, %1\\\", operands);\n+        return \\\"\\\";\n+      }\n+    switch (which_alternative)\n+      {\n+      case 0:\n+\toutput_asm_insn (\\\"it\\\\t%d4\\\", operands);\n+\tbreak;\n+      case 1:\n+\toutput_asm_insn (\\\"it\\\\t%D4\\\", operands);\n+\tbreak;\n+      case 2:\n+\toutput_asm_insn (\\\"ite\\\\t%D4\\\", operands);\n+\tbreak;\n+      default:\n+\tabort();\n+      }\n+    if (which_alternative != 0)\n+      output_asm_insn (\\\"mov%D4\\\\t%0, %1\\\", operands);\n+    if (which_alternative != 1)\n+      output_asm_insn (\\\"mov%d4\\\\t%0, %2\\\", operands);\n+    return \\\"\\\";\n+  \"\n+  [(set_attr \"conds\" \"use\")\n+   (set_attr \"length\" \"6,6,10\")]\n+)\n+\n+(define_insn \"*thumb2_cond_arith\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r\")\n+        (match_operator:SI 5 \"shiftable_operator\" \n+\t [(match_operator:SI 4 \"arm_comparison_operator\"\n+           [(match_operand:SI 2 \"s_register_operand\" \"r,r\")\n+\t    (match_operand:SI 3 \"arm_rhs_operand\" \"rI,rI\")])\n+          (match_operand:SI 1 \"s_register_operand\" \"0,?r\")]))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+    if (GET_CODE (operands[4]) == LT && operands[3] == const0_rtx)\n+      return \\\"%i5\\\\t%0, %1, %2, lsr #31\\\";\n+\n+    output_asm_insn (\\\"cmp\\\\t%2, %3\\\", operands);\n+    if (GET_CODE (operands[5]) == AND)\n+      {\n+\toutput_asm_insn (\\\"ite\\\\t%D4\\\", operands);\n+\toutput_asm_insn (\\\"mov%D4\\\\t%0, #0\\\", operands);\n+      }\n+    else if (GET_CODE (operands[5]) == MINUS)\n+      {\n+\toutput_asm_insn (\\\"ite\\\\t%D4\\\", operands);\n+\toutput_asm_insn (\\\"rsb%D4\\\\t%0, %1, #0\\\", operands);\n+      }\n+    else if (which_alternative != 0)\n+      {\n+\toutput_asm_insn (\\\"ite\\\\t%D4\\\", operands);\n+\toutput_asm_insn (\\\"mov%D4\\\\t%0, %1\\\", operands);\n+      }\n+    else\n+      output_asm_insn (\\\"it\\\\t%d4\\\", operands);\n+    return \\\"%i5%d4\\\\t%0, %1, #1\\\";\n+  \"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"14\")]\n+)\n+\n+(define_insn \"*thumb2_cond_sub\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r\")\n+        (minus:SI (match_operand:SI 1 \"s_register_operand\" \"0,?r\")\n+\t\t  (match_operator:SI 4 \"arm_comparison_operator\"\n+                   [(match_operand:SI 2 \"s_register_operand\" \"r,r\")\n+\t\t    (match_operand:SI 3 \"arm_rhs_operand\" \"rI,rI\")])))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+    output_asm_insn (\\\"cmp\\\\t%2, %3\\\", operands);\n+    if (which_alternative != 0)\n+      {\n+\toutput_asm_insn (\\\"ite\\\\t%D4\\\", operands);\n+\toutput_asm_insn (\\\"mov%D4\\\\t%0, %1\\\", operands);\n+      }\n+    else\n+      output_asm_insn (\\\"it\\\\t%d4\\\", operands);\n+    return \\\"sub%d4\\\\t%0, %1, #1\\\";\n+  \"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"10,14\")]\n+)\n+\n+(define_insn \"*thumb2_negscc\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(neg:SI (match_operator 3 \"arm_comparison_operator\"\n+\t\t [(match_operand:SI 1 \"s_register_operand\" \"r\")\n+\t\t  (match_operand:SI 2 \"arm_rhs_operand\" \"rI\")])))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+  if (GET_CODE (operands[3]) == LT && operands[3] == const0_rtx)\n+    return \\\"asr\\\\t%0, %1, #31\\\";\n+\n+  if (GET_CODE (operands[3]) == NE)\n+    return \\\"subs\\\\t%0, %1, %2\\;it\\\\tne\\;mvnne\\\\t%0, #0\\\";\n+\n+  if (GET_CODE (operands[3]) == GT)\n+    return \\\"subs\\\\t%0, %1, %2\\;it\\\\tne\\;mvnne\\\\t%0, %0, asr #31\\\";\n+\n+  output_asm_insn (\\\"cmp\\\\t%1, %2\\\", operands);\n+  output_asm_insn (\\\"ite\\\\t%D3\\\", operands);\n+  output_asm_insn (\\\"mov%D3\\\\t%0, #0\\\", operands);\n+  return \\\"mvn%d3\\\\t%0, #0\\\";\n+  \"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"14\")]\n+)\n+\n+(define_insn \"*thumb2_movcond\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r,r\")\n+\t(if_then_else:SI\n+\t (match_operator 5 \"arm_comparison_operator\"\n+\t  [(match_operand:SI 3 \"s_register_operand\" \"r,r,r\")\n+\t   (match_operand:SI 4 \"arm_add_operand\" \"rIL,rIL,rIL\")])\n+\t (match_operand:SI 1 \"arm_rhs_operand\" \"0,rI,?rI\")\n+\t (match_operand:SI 2 \"arm_rhs_operand\" \"rI,0,rI\")))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+  if (GET_CODE (operands[5]) == LT\n+      && (operands[4] == const0_rtx))\n+    {\n+      if (which_alternative != 1 && GET_CODE (operands[1]) == REG)\n+\t{\n+\t  if (operands[2] == const0_rtx)\n+\t    return \\\"and\\\\t%0, %1, %3, asr #31\\\";\n+\t  return \\\"ands\\\\t%0, %1, %3, asr #32\\;it\\\\tcc\\;movcc\\\\t%0, %2\\\";\n+\t}\n+      else if (which_alternative != 0 && GET_CODE (operands[2]) == REG)\n+\t{\n+\t  if (operands[1] == const0_rtx)\n+\t    return \\\"bic\\\\t%0, %2, %3, asr #31\\\";\n+\t  return \\\"bics\\\\t%0, %2, %3, asr #32\\;it\\\\tcs\\;movcs\\\\t%0, %1\\\";\n+\t}\n+      /* The only case that falls through to here is when both ops 1 & 2\n+\t are constants.  */\n+    }\n+\n+  if (GET_CODE (operands[5]) == GE\n+      && (operands[4] == const0_rtx))\n+    {\n+      if (which_alternative != 1 && GET_CODE (operands[1]) == REG)\n+\t{\n+\t  if (operands[2] == const0_rtx)\n+\t    return \\\"bic\\\\t%0, %1, %3, asr #31\\\";\n+\t  return \\\"bics\\\\t%0, %1, %3, asr #32\\;it\\\\tcs\\;movcs\\\\t%0, %2\\\";\n+\t}\n+      else if (which_alternative != 0 && GET_CODE (operands[2]) == REG)\n+\t{\n+\t  if (operands[1] == const0_rtx)\n+\t    return \\\"and\\\\t%0, %2, %3, asr #31\\\";\n+\t  return \\\"ands\\\\t%0, %2, %3, asr #32\\;it\\tcc\\;movcc\\\\t%0, %1\\\";\n+\t}\n+      /* The only case that falls through to here is when both ops 1 & 2\n+\t are constants.  */\n+    }\n+  if (GET_CODE (operands[4]) == CONST_INT\n+      && !const_ok_for_arm (INTVAL (operands[4])))\n+    output_asm_insn (\\\"cmn\\\\t%3, #%n4\\\", operands);\n+  else\n+    output_asm_insn (\\\"cmp\\\\t%3, %4\\\", operands);\n+  switch (which_alternative)\n+    {\n+    case 0:\n+      output_asm_insn (\\\"it\\\\t%D5\\\", operands);\n+      break;\n+    case 1:\n+      output_asm_insn (\\\"it\\\\t%d5\\\", operands);\n+      break;\n+    case 2:\n+      output_asm_insn (\\\"ite\\\\t%d5\\\", operands);\n+      break;\n+    default:\n+      abort();\n+    }\n+  if (which_alternative != 0)\n+    output_asm_insn (\\\"mov%d5\\\\t%0, %1\\\", operands);\n+  if (which_alternative != 1)\n+    output_asm_insn (\\\"mov%D5\\\\t%0, %2\\\", operands);\n+  return \\\"\\\";\n+  \"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"10,10,14\")]\n+)\n+\n+;; Zero and sign extension instructions.\n+\n+(define_insn \"*thumb2_zero_extendsidi2\"\n+  [(set (match_operand:DI 0 \"s_register_operand\" \"=r\")\n+        (zero_extend:DI (match_operand:SI 1 \"s_register_operand\" \"r\")))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+    /* ??? Output both instructions unconditionally, otherwise the conditional\n+       executon insn counter gets confused.\n+    if (REGNO (operands[1])\n+        != REGNO (operands[0]) + (WORDS_BIG_ENDIAN ? 1 : 0)) */\n+      output_asm_insn (\\\"mov%?\\\\t%Q0, %1\\\", operands);\n+    return \\\"mov%?\\\\t%R0, #0\\\";\n+  \"\n+  [(set_attr \"length\" \"8\")\n+   (set_attr \"ce_count\" \"2\")\n+   (set_attr \"predicable\" \"yes\")]\n+)\n+\n+(define_insn \"*thumb2_zero_extendqidi2\"\n+  [(set (match_operand:DI                 0 \"s_register_operand\"  \"=r,r\")\n+\t(zero_extend:DI (match_operand:QI 1 \"nonimmediate_operand\" \"r,m\")))]\n+  \"TARGET_THUMB2\"\n+  \"@\n+   and%?\\\\t%Q0, %1, #255\\;mov%?\\\\t%R0, #0\n+   ldr%(b%)\\\\t%Q0, %1\\;mov%?\\\\t%R0, #0\"\n+  [(set_attr \"length\" \"8\")\n+   (set_attr \"ce_count\" \"2\")\n+   (set_attr \"predicable\" \"yes\")\n+   (set_attr \"type\" \"*,load_byte\")\n+   (set_attr \"pool_range\" \"*,4092\")\n+   (set_attr \"neg_pool_range\" \"*,250\")]\n+)\n+\n+(define_insn \"*thumb2_extendsidi2\"\n+  [(set (match_operand:DI 0 \"s_register_operand\" \"=r\")\n+        (sign_extend:DI (match_operand:SI 1 \"s_register_operand\" \"r\")))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+    /* ??? Output both instructions unconditionally, otherwise the conditional\n+       executon insn counter gets confused.\n+    if (REGNO (operands[1])\n+        != REGNO (operands[0]) + (WORDS_BIG_ENDIAN ? 1 : 0)) */\n+      output_asm_insn (\\\"mov%?\\\\t%Q0, %1\\\", operands);\n+    return \\\"asr%?\\\\t%R0, %Q0, #31\\\";\n+  \"\n+  [(set_attr \"length\" \"8\")\n+   (set_attr \"ce_count\" \"2\")\n+   (set_attr \"shift\" \"1\")\n+   (set_attr \"predicable\" \"yes\")]\n+)\n+\n+;; All supported Thumb2 implementations are armv6, so only that case is\n+;; provided.\n+(define_insn \"*thumb2_extendqisi_v6\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r\")\n+\t(sign_extend:SI (match_operand:QI 1 \"nonimmediate_operand\" \"r,m\")))]\n+  \"TARGET_THUMB2 && arm_arch6\"\n+  \"@\n+   sxtb%?\\\\t%0, %1\n+   ldr%(sb%)\\\\t%0, %1\"\n+  [(set_attr \"type\" \"alu_shift,load_byte\")\n+   (set_attr \"predicable\" \"yes\")\n+   (set_attr \"pool_range\" \"*,4096\")\n+   (set_attr \"neg_pool_range\" \"*,250\")]\n+)\n+\n+(define_insn \"*thumb2_zero_extendhisi2_v6\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r\")\n+\t(zero_extend:SI (match_operand:HI 1 \"nonimmediate_operand\" \"r,m\")))]\n+  \"TARGET_THUMB2 && arm_arch6\"\n+  \"@\n+   uxth%?\\\\t%0, %1\n+   ldr%(h%)\\\\t%0, %1\"\n+  [(set_attr \"type\" \"alu_shift,load_byte\")\n+   (set_attr \"predicable\" \"yes\")\n+   (set_attr \"pool_range\" \"*,4096\")\n+   (set_attr \"neg_pool_range\" \"*,250\")]\n+)\n+\n+(define_insn \"*thumb2_zero_extendqisi2_v6\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r,r\")\n+\t(zero_extend:SI (match_operand:QI 1 \"nonimmediate_operand\" \"r,m\")))]\n+  \"TARGET_THUMB2 && arm_arch6\"\n+  \"@\n+   uxtb%(%)\\\\t%0, %1\n+   ldr%(b%)\\\\t%0, %1\\\\t%@ zero_extendqisi2\"\n+  [(set_attr \"type\" \"alu_shift,load_byte\")\n+   (set_attr \"predicable\" \"yes\")\n+   (set_attr \"pool_range\" \"*,4096\")\n+   (set_attr \"neg_pool_range\" \"*,250\")]\n+)\n+\n+(define_insn \"thumb2_casesi_internal\"\n+  [(parallel [(set (pc)\n+\t       (if_then_else\n+\t\t(leu (match_operand:SI 0 \"s_register_operand\" \"r\")\n+\t\t     (match_operand:SI 1 \"arm_rhs_operand\" \"rI\"))\n+\t\t(mem:SI (plus:SI (mult:SI (match_dup 0) (const_int 4))\n+\t\t\t\t (label_ref (match_operand 2 \"\" \"\"))))\n+\t\t(label_ref (match_operand 3 \"\" \"\"))))\n+\t      (clobber (reg:CC CC_REGNUM))\n+\t      (clobber (match_scratch:SI 4 \"=r\"))\n+\t      (use (label_ref (match_dup 2)))])]\n+  \"TARGET_THUMB2 && !flag_pic\"\n+  \"* return thumb2_output_casesi(operands);\"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"16\")]\n+)\n+\n+(define_insn \"thumb2_casesi_internal_pic\"\n+  [(parallel [(set (pc)\n+\t       (if_then_else\n+\t\t(leu (match_operand:SI 0 \"s_register_operand\" \"r\")\n+\t\t     (match_operand:SI 1 \"arm_rhs_operand\" \"rI\"))\n+\t\t(mem:SI (plus:SI (mult:SI (match_dup 0) (const_int 4))\n+\t\t\t\t (label_ref (match_operand 2 \"\" \"\"))))\n+\t\t(label_ref (match_operand 3 \"\" \"\"))))\n+\t      (clobber (reg:CC CC_REGNUM))\n+\t      (clobber (match_scratch:SI 4 \"=r\"))\n+\t      (clobber (match_scratch:SI 5 \"=r\"))\n+\t      (use (label_ref (match_dup 2)))])]\n+  \"TARGET_THUMB2 && flag_pic\"\n+  \"* return thumb2_output_casesi(operands);\"\n+  [(set_attr \"conds\" \"clob\")\n+   (set_attr \"length\" \"20\")]\n+)\n+\n+(define_insn_and_split \"thumb2_eh_return\"\n+  [(unspec_volatile [(match_operand:SI 0 \"s_register_operand\" \"r\")]\n+\t\t    VUNSPEC_EH_RETURN)\n+   (clobber (match_scratch:SI 1 \"=&r\"))]\n+  \"TARGET_THUMB2\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n+  \"\n+  {\n+    thumb_set_return_address (operands[0], operands[1]);\n+    DONE;\n+  }\"\n+)\n+\n+;; Peepholes and insns for 16-bit flag clobbering instructions.\n+;; The conditional forms of these instructions do not clobber CC.\n+;; However by the time peepholes are run it is probably too late to do\n+;; anything useful with this information.\n+(define_peephole2\n+  [(set (match_operand:SI          0 \"low_register_operand\" \"\")\n+        (match_operator:SI 3 \"thumb_16bit_operator\"\n+\t [(match_operand:SI 1  \"low_register_operand\" \"\")\n+\t  (match_operand:SI 2 \"low_register_operand\" \"\")]))]\n+  \"TARGET_THUMB2 && rtx_equal_p(operands[0], operands[1])\n+   && peep2_regno_dead_p(0, CC_REGNUM)\"\n+  [(parallel\n+    [(set (match_dup 0)\n+\t  (match_op_dup 3\n+\t   [(match_dup 1)\n+\t    (match_dup 2)]))\n+     (clobber (reg:CC CC_REGNUM))])]\n+  \"\"\n+)\n+\n+(define_insn \"*thumb2_alusi3_short\"\n+  [(set (match_operand:SI          0 \"s_register_operand\" \"=l\")\n+        (match_operator:SI 3 \"thumb_16bit_operator\"\n+\t [(match_operand:SI 1 \"s_register_operand\" \"0\")\n+\t  (match_operand:SI 2 \"s_register_operand\" \"l\")]))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2 && reload_completed\"\n+  \"%I3%!\\\\t%0, %1, %2\"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"length\" \"2\")]\n+)\n+\n+;; Similarly for 16-bit shift instructions\n+;; There is no 16-bit rotate by immediate instruction.\n+(define_peephole2\n+  [(set (match_operand:SI   0 \"low_register_operand\" \"\")\n+\t(match_operator:SI  3 \"shift_operator\"\n+\t [(match_operand:SI 1 \"low_register_operand\" \"\")\n+\t  (match_operand:SI 2 \"low_reg_or_int_operand\" \"\")]))]\n+  \"TARGET_THUMB2\n+   && peep2_regno_dead_p(0, CC_REGNUM)\n+   && ((GET_CODE(operands[3]) != ROTATE && GET_CODE(operands[3]) != ROTATERT)\n+       || REG_P(operands[2]))\"\n+  [(parallel\n+    [(set (match_dup 0)\n+\t  (match_op_dup 3\n+\t   [(match_dup 1)\n+\t    (match_dup 2)]))\n+     (clobber (reg:CC CC_REGNUM))])]\n+  \"\"\n+)\n+\n+(define_insn \"*thumb2_shiftsi3_short\"\n+  [(set (match_operand:SI   0 \"low_register_operand\" \"=l\")\n+\t(match_operator:SI  3 \"shift_operator\"\n+\t [(match_operand:SI 1 \"low_register_operand\"  \"l\")\n+\t  (match_operand:SI 2 \"low_reg_or_int_operand\" \"lM\")]))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2 && reload_completed\n+   && ((GET_CODE(operands[3]) != ROTATE && GET_CODE(operands[3]) != ROTATERT)\n+       || REG_P(operands[2]))\"\n+  \"* return arm_output_shift(operands, 2);\"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"shift\" \"1\")\n+   (set_attr \"length\" \"2\")\n+   (set (attr \"type\") (if_then_else (match_operand 2 \"const_int_operand\" \"\")\n+\t\t      (const_string \"alu_shift\")\n+\t\t      (const_string \"alu_shift_reg\")))]\n+)\n+\n+;; 16-bit load immediate\n+(define_peephole2\n+  [(set (match_operand:SI 0 \"low_register_operand\" \"\")\n+\t(match_operand:SI 1 \"const_int_operand\" \"\"))]\n+  \"TARGET_THUMB2\n+   && peep2_regno_dead_p(0, CC_REGNUM)\n+   && (unsigned HOST_WIDE_INT) INTVAL(operands[1]) < 256\"\n+  [(parallel\n+    [(set (match_dup 0)\n+\t  (match_dup 1))\n+     (clobber (reg:CC CC_REGNUM))])]\n+  \"\"\n+)\n+\n+(define_insn \"*thumb2_movsi_shortim\"\n+  [(set (match_operand:SI 0 \"low_register_operand\" \"=l\")\n+\t(match_operand:SI 1 \"const_int_operand\" \"I\"))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2 && reload_completed\"\n+  \"mov%!\\t%0, %1\"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"length\" \"2\")]\n+)\n+\n+;; 16-bit add/sub immediate\n+(define_peephole2\n+  [(set (match_operand:SI 0 \"low_register_operand\" \"\")\n+\t(plus:SI (match_operand:SI 1 \"low_register_operand\" \"\")\n+\t\t (match_operand:SI 2 \"const_int_operand\" \"\")))]\n+  \"TARGET_THUMB2\n+   && peep2_regno_dead_p(0, CC_REGNUM)\n+   && ((rtx_equal_p(operands[0], operands[1])\n+\t&& INTVAL(operands[2]) > -256 && INTVAL(operands[2]) < 256)\n+       || (INTVAL(operands[2]) > -8 && INTVAL(operands[2]) < 8))\"\n+  [(parallel\n+    [(set (match_dup 0)\n+\t  (plus:SI (match_dup 1)\n+\t\t   (match_dup 2)))\n+     (clobber (reg:CC CC_REGNUM))])]\n+  \"\"\n+)\n+\n+(define_insn \"*thumb2_addsi_shortim\"\n+  [(set (match_operand:SI 0 \"low_register_operand\" \"=l\")\n+\t(plus:SI (match_operand:SI 1 \"low_register_operand\" \"l\")\n+\t\t (match_operand:SI 2 \"const_int_operand\" \"IL\")))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2 && reload_completed\"\n+  \"*\n+    HOST_WIDE_INT val;\n+\n+    val = INTVAL(operands[2]);\n+    /* We prefer eg. subs rn, rn, #1 over adds rn, rn, #0xffffffff.  */\n+    if (val < 0 && const_ok_for_arm(ARM_SIGN_EXTEND (-val)))\n+      return \\\"sub%!\\\\t%0, %1, #%n2\\\";\n+    else\n+      return \\\"add%!\\\\t%0, %1, %2\\\";\n+  \"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"length\" \"2\")]\n+)\n+\n+(define_insn \"divsi3\"\n+  [(set (match_operand:SI\t  0 \"s_register_operand\" \"=r\")\n+\t(div:SI (match_operand:SI 1 \"s_register_operand\"  \"r\")\n+\t\t(match_operand:SI 2 \"s_register_operand\"  \"r\")))]\n+  \"TARGET_THUMB2 && arm_arch_hwdiv\"\n+  \"sdiv%?\\t%0, %1, %2\"\n+  [(set_attr \"predicable\" \"yes\")]\n+)\n+\n+(define_insn \"udivsi3\"\n+  [(set (match_operand:SI\t   0 \"s_register_operand\" \"=r\")\n+\t(udiv:SI (match_operand:SI 1 \"s_register_operand\"  \"r\")\n+\t\t (match_operand:SI 2 \"s_register_operand\"  \"r\")))]\n+  \"TARGET_THUMB2 && arm_arch_hwdiv\"\n+  \"udiv%?\\t%0, %1, %2\"\n+  [(set_attr \"predicable\" \"yes\")]\n+)\n+\n+(define_insn \"*thumb2_cbz\"\n+  [(set (pc) (if_then_else\n+\t      (eq (match_operand:SI 0 \"s_register_operand\" \"l,?r\")\n+\t\t  (const_int 0))\n+\t      (label_ref (match_operand 1 \"\" \"\"))\n+\t      (pc)))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+  if (get_attr_length (insn) == 2 && which_alternative == 0)\n+    return \\\"cbz\\\\t%0, %l1\\\";\n+  else\n+    return \\\"cmp\\\\t%0, #0\\;beq\\\\t%l1\\\";\n+  \"\n+  [(set (attr \"length\") \n+        (if_then_else\n+\t    (and (ge (minus (match_dup 1) (pc)) (const_int 2))\n+\t         (le (minus (match_dup 1) (pc)) (const_int 128)))\n+\t    (const_int 2)\n+\t    (const_int 8)))]\n+)\n+\n+(define_insn \"*thumb2_cbnz\"\n+  [(set (pc) (if_then_else\n+\t      (ne (match_operand:SI 0 \"s_register_operand\" \"l,?r\")\n+\t\t  (const_int 0))\n+\t      (label_ref (match_operand 1 \"\" \"\"))\n+\t      (pc)))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_THUMB2\"\n+  \"*\n+  if (get_attr_length (insn) == 2 && which_alternative == 0)\n+    return \\\"cbnz\\\\t%0, %l1\\\";\n+  else\n+    return \\\"cmp\\\\t%0, #0\\;bne\\\\t%l1\\\";\n+  \"\n+  [(set (attr \"length\") \n+        (if_then_else\n+\t    (and (ge (minus (match_dup 1) (pc)) (const_int 2))\n+\t         (le (minus (match_dup 1) (pc)) (const_int 128)))\n+\t    (const_int 2)\n+\t    (const_int 8)))]\n+)"}, {"sha": "7d5a7dcb9b63dcd48c92f108914bfa47cfefb1ee", "filename": "gcc/config/arm/vfp.md", "status": "modified", "additions": 277, "deletions": 82, "changes": 359, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fvfp.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fconfig%2Farm%2Fvfp.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fvfp.md?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n ;; ARM VFP coprocessor Machine Description\n-;; Copyright (C) 2003, 2005 Free Software Foundation, Inc.\n+;; Copyright (C) 2003, 2005, 2006, 2007 Free Software Foundation, Inc.\n ;; Written by CodeSourcery, LLC.\n ;;\n ;; This file is part of GCC.\n@@ -121,25 +121,77 @@\n ;; ??? For now do not allow loading constants into vfp regs.  This causes\n ;; problems because small constants get converted into adds.\n (define_insn \"*arm_movsi_vfp\"\n-  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,r,r ,m,*w,r,*w,*w, *Uv\")\n-      (match_operand:SI 1 \"general_operand\"\t   \"rI,K,mi,r,r,*w,*w,*Uvi,*w\"))]\n+  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,r,r,r ,m,*w,r,*w,*w, *Uv\")\n+      (match_operand:SI 1 \"general_operand\"\t   \"rI,K,N,mi,r,r,*w,*w,*Uvi,*w\"))]\n   \"TARGET_ARM && TARGET_VFP && TARGET_HARD_FLOAT\n    && (   s_register_operand (operands[0], SImode)\n        || s_register_operand (operands[1], SImode))\"\n-  \"@\n-  mov%?\\\\t%0, %1\n-  mvn%?\\\\t%0, #%B1\n-  ldr%?\\\\t%0, %1\n-  str%?\\\\t%1, %0\n-  fmsr%?\\\\t%0, %1\\\\t%@ int\n-  fmrs%?\\\\t%0, %1\\\\t%@ int\n-  fcpys%?\\\\t%0, %1\\\\t%@ int\n-  flds%?\\\\t%0, %1\\\\t%@ int\n-  fsts%?\\\\t%1, %0\\\\t%@ int\"\n+  \"*\n+  switch (which_alternative)\n+    {\n+    case 0:\n+      return \\\"mov%?\\\\t%0, %1\\\";\n+    case 1:\n+      return \\\"mvn%?\\\\t%0, #%B1\\\";\n+    case 2:\n+      return \\\"movw%?\\\\t%0, %1\\\";\n+    case 3:\n+      return \\\"ldr%?\\\\t%0, %1\\\";\n+    case 4:\n+      return \\\"str%?\\\\t%1, %0\\\";\n+    case 5:\n+      return \\\"fmsr%?\\\\t%0, %1\\\\t%@ int\\\";\n+    case 6:\n+      return \\\"fmrs%?\\\\t%0, %1\\\\t%@ int\\\";\n+    case 7:\n+      return \\\"fcpys%?\\\\t%0, %1\\\\t%@ int\\\";\n+    case 8: case 9:\n+      return output_move_vfp (operands);\n+    default:\n+      gcc_unreachable ();\n+    }\n+  \"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"type\" \"*,*,*,load1,store1,r_2_f,f_2_r,ffarith,f_loads,f_stores\")\n+   (set_attr \"pool_range\"     \"*,*,*,4096,*,*,*,*,1020,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,*,4084,*,*,*,*,1008,*\")]\n+)\n+\n+(define_insn \"*thumb2_movsi_vfp\"\n+  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,r,r,r,m,*w,r,*w,*w, *Uv\")\n+      (match_operand:SI 1 \"general_operand\"\t   \"rI,K,N,mi,r,r,*w,*w,*Uvi,*w\"))]\n+  \"TARGET_THUMB2 && TARGET_VFP && TARGET_HARD_FLOAT\n+   && (   s_register_operand (operands[0], SImode)\n+       || s_register_operand (operands[1], SImode))\"\n+  \"*\n+  switch (which_alternative)\n+    {\n+    case 0:\n+      return \\\"mov%?\\\\t%0, %1\\\";\n+    case 1:\n+      return \\\"mvn%?\\\\t%0, #%B1\\\";\n+    case 2:\n+      return \\\"movw%?\\\\t%0, %1\\\";\n+    case 3:\n+      return \\\"ldr%?\\\\t%0, %1\\\";\n+    case 4:\n+      return \\\"str%?\\\\t%1, %0\\\";\n+    case 5:\n+      return \\\"fmsr%?\\\\t%0, %1\\\\t%@ int\\\";\n+    case 6:\n+      return \\\"fmrs%?\\\\t%0, %1\\\\t%@ int\\\";\n+    case 7:\n+      return \\\"fcpys%?\\\\t%0, %1\\\\t%@ int\\\";\n+    case 8: case 9:\n+      return output_move_vfp (operands);\n+    default:\n+      gcc_unreachable ();\n+    }\n+  \"\n   [(set_attr \"predicable\" \"yes\")\n-   (set_attr \"type\" \"*,*,load1,store1,r_2_f,f_2_r,ffarith,f_loads,f_stores\")\n-   (set_attr \"pool_range\"     \"*,*,4096,*,*,*,*,1020,*\")\n-   (set_attr \"neg_pool_range\" \"*,*,4084,*,*,*,*,1008,*\")]\n+   (set_attr \"type\" \"*,*,*,load1,store1,r_2_f,f_2_r,ffarith,f_load,f_store\")\n+   (set_attr \"pool_range\"     \"*,*,*,4096,*,*,*,*,1020,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,*,   0,*,*,*,*,1008,*\")]\n )\n \n \n@@ -165,10 +217,8 @@\n       return \\\"fmrrd%?\\\\t%Q0, %R0, %P1\\\\t%@ int\\\";\n     case 5:\n       return \\\"fcpyd%?\\\\t%P0, %P1\\\\t%@ int\\\";\n-    case 6:\n-      return \\\"fldd%?\\\\t%P0, %1\\\\t%@ int\\\";\n-    case 7:\n-      return \\\"fstd%?\\\\t%P1, %0\\\\t%@ int\\\";\n+    case 6: case 7:\n+      return output_move_vfp (operands);\n     default:\n       gcc_unreachable ();\n     }\n@@ -179,6 +229,33 @@\n    (set_attr \"neg_pool_range\" \"*,1008,*,*,*,*,1008,*\")]\n )\n \n+(define_insn \"*thumb2_movdi_vfp\"\n+  [(set (match_operand:DI 0 \"nonimmediate_di_operand\" \"=r, r,m,w,r,w,w, Uv\")\n+\t(match_operand:DI 1 \"di_operand\"              \"rIK,mi,r,r,w,w,Uvi,w\"))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"*\n+  switch (which_alternative)\n+    {\n+    case 0: case 1: case 2:\n+      return (output_move_double (operands));\n+    case 3:\n+      return \\\"fmdrr%?\\\\t%P0, %Q1, %R1\\\\t%@ int\\\";\n+    case 4:\n+      return \\\"fmrrd%?\\\\t%Q0, %R0, %P1\\\\t%@ int\\\";\n+    case 5:\n+      return \\\"fcpyd%?\\\\t%P0, %P1\\\\t%@ int\\\";\n+    case 6: case 7:\n+      return output_move_vfp (operands);\n+    default:\n+      abort ();\n+    }\n+  \"\n+  [(set_attr \"type\" \"*,load2,store2,r_2_f,f_2_r,ffarith,f_load,f_store\")\n+   (set_attr \"length\" \"8,8,8,4,4,4,4,4\")\n+   (set_attr \"pool_range\"     \"*,4096,*,*,*,*,1020,*\")\n+   (set_attr \"neg_pool_range\" \"*,   0,*,*,*,*,1008,*\")]\n+)\n+\n \n ;; SFmode moves\n ;; Disparage the w<->r cases because reloading an invalid address is\n@@ -190,21 +267,66 @@\n   \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\n    && (   s_register_operand (operands[0], SFmode)\n        || s_register_operand (operands[1], SFmode))\"\n-  \"@\n-  fmsr%?\\\\t%0, %1\n-  fmrs%?\\\\t%0, %1\n-  flds%?\\\\t%0, %1\n-  fsts%?\\\\t%1, %0\n-  ldr%?\\\\t%0, %1\\\\t%@ float\n-  str%?\\\\t%1, %0\\\\t%@ float\n-  fcpys%?\\\\t%0, %1\n-  mov%?\\\\t%0, %1\\\\t%@ float\"\n+  \"*\n+  switch (which_alternative)\n+    {\n+    case 0:\n+      return \\\"fmsr%?\\\\t%0, %1\\\";\n+    case 1:\n+      return \\\"fmrs%?\\\\t%0, %1\\\";\n+    case 2: case 3:\n+      return output_move_vfp (operands);\n+    case 4:\n+      return \\\"ldr%?\\\\t%0, %1\\\\t%@ float\\\";\n+    case 5:\n+      return \\\"str%?\\\\t%1, %0\\\\t%@ float\\\";\n+    case 6:\n+      return \\\"fcpys%?\\\\t%0, %1\\\";\n+    case 7:\n+      return \\\"mov%?\\\\t%0, %1\\\\t%@ float\\\";\n+    default:\n+      gcc_unreachable ();\n+    }\n+  \"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"r_2_f,f_2_r,ffarith,*,f_loads,f_stores,load1,store1\")\n    (set_attr \"pool_range\" \"*,*,1020,*,4096,*,*,*\")\n    (set_attr \"neg_pool_range\" \"*,*,1008,*,4080,*,*,*\")]\n )\n \n+(define_insn \"*thumb2_movsf_vfp\"\n+  [(set (match_operand:SF 0 \"nonimmediate_operand\" \"=w,?r,w  ,Uv,r ,m,w,r\")\n+\t(match_operand:SF 1 \"general_operand\"\t   \" ?r,w,UvE,w, mE,r,w,r\"))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP\n+   && (   s_register_operand (operands[0], SFmode)\n+       || s_register_operand (operands[1], SFmode))\"\n+  \"*\n+  switch (which_alternative)\n+    {\n+    case 0:\n+      return \\\"fmsr%?\\\\t%0, %1\\\";\n+    case 1:\n+      return \\\"fmrs%?\\\\t%0, %1\\\";\n+    case 2: case 3:\n+      return output_move_vfp (operands);\n+    case 4:\n+      return \\\"ldr%?\\\\t%0, %1\\\\t%@ float\\\";\n+    case 5:\n+      return \\\"str%?\\\\t%1, %0\\\\t%@ float\\\";\n+    case 6:\n+      return \\\"fcpys%?\\\\t%0, %1\\\";\n+    case 7:\n+      return \\\"mov%?\\\\t%0, %1\\\\t%@ float\\\";\n+    default:\n+      gcc_unreachable ();\n+    }\n+  \"\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"type\" \"r_2_f,f_2_r,ffarith,*,f_load,f_store,load1,store1\")\n+   (set_attr \"pool_range\" \"*,*,1020,*,4092,*,*,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,1008,*,0,*,*,*\")]\n+)\n+\n \n ;; DFmode moves\n \n@@ -224,10 +346,8 @@\n \treturn \\\"fmrrd%?\\\\t%Q0, %R0, %P1\\\";\n       case 2: case 3:\n \treturn output_move_double (operands);\n-      case 4:\n-\treturn \\\"fldd%?\\\\t%P0, %1\\\";\n-      case 5:\n-\treturn \\\"fstd%?\\\\t%P1, %0\\\";\n+      case 4: case 5:\n+\treturn output_move_vfp (operands);\n       case 6:\n \treturn \\\"fcpyd%?\\\\t%P0, %P1\\\";\n       case 7:\n@@ -243,6 +363,35 @@\n    (set_attr \"neg_pool_range\" \"*,*,1008,*,1008,*,*,*\")]\n )\n \n+(define_insn \"*thumb2_movdf_vfp\"\n+  [(set (match_operand:DF 0 \"nonimmediate_soft_df_operand\" \"=w,?r,r, m,w  ,Uv,w,r\")\n+\t(match_operand:DF 1 \"soft_df_operand\"\t\t   \" ?r,w,mF,r,UvF,w, w,r\"))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"*\n+  {\n+    switch (which_alternative)\n+      {\n+      case 0:\n+\treturn \\\"fmdrr%?\\\\t%P0, %Q1, %R1\\\";\n+      case 1:\n+\treturn \\\"fmrrd%?\\\\t%Q0, %R0, %P1\\\";\n+      case 2: case 3: case 7:\n+\treturn output_move_double (operands);\n+      case 4: case 5:\n+\treturn output_move_vfp (operands);\n+      case 6:\n+\treturn \\\"fcpyd%?\\\\t%P0, %P1\\\";\n+      default:\n+\tabort ();\n+      }\n+    }\n+  \"\n+  [(set_attr \"type\" \"r_2_f,f_2_r,ffarith,*,load2,store2,f_load,f_store\")\n+   (set_attr \"length\" \"4,4,8,8,4,4,4,8\")\n+   (set_attr \"pool_range\" \"*,*,4096,*,1020,*,*,*\")\n+   (set_attr \"neg_pool_range\" \"*,*,0,*,1008,*,*,*\")]\n+)\n+\n \n ;; Conditional move patterns\n \n@@ -269,6 +418,29 @@\n     (set_attr \"type\" \"ffarith,ffarith,ffarith,r_2_f,r_2_f,r_2_f,f_2_r,f_2_r,f_2_r\")]\n )\n \n+(define_insn \"*thumb2_movsfcc_vfp\"\n+  [(set (match_operand:SF   0 \"s_register_operand\" \"=w,w,w,w,w,w,?r,?r,?r\")\n+\t(if_then_else:SF\n+\t  (match_operator   3 \"arm_comparison_operator\"\n+\t    [(match_operand 4 \"cc_register\" \"\") (const_int 0)])\n+\t  (match_operand:SF 1 \"s_register_operand\" \"0,w,w,0,?r,?r,0,w,w\")\n+\t  (match_operand:SF 2 \"s_register_operand\" \"w,0,w,?r,0,?r,w,0,w\")))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"@\n+   it\\\\t%D3\\;fcpys%D3\\\\t%0, %2\n+   it\\\\t%d3\\;fcpys%d3\\\\t%0, %1\n+   ite\\\\t%D3\\;fcpys%D3\\\\t%0, %2\\;fcpys%d3\\\\t%0, %1\n+   it\\\\t%D3\\;fmsr%D3\\\\t%0, %2\n+   it\\\\t%d3\\;fmsr%d3\\\\t%0, %1\n+   ite\\\\t%D3\\;fmsr%D3\\\\t%0, %2\\;fmsr%d3\\\\t%0, %1\n+   it\\\\t%D3\\;fmrs%D3\\\\t%0, %2\n+   it\\\\t%d3\\;fmrs%d3\\\\t%0, %1\n+   ite\\\\t%D3\\;fmrs%D3\\\\t%0, %2\\;fmrs%d3\\\\t%0, %1\"\n+   [(set_attr \"conds\" \"use\")\n+    (set_attr \"length\" \"6,6,10,6,6,10,6,6,10\")\n+    (set_attr \"type\" \"ffarith,ffarith,ffarith,r_2_f,r_2_f,r_2_f,f_2_r,f_2_r,f_2_r\")]\n+)\n+\n (define_insn \"*movdfcc_vfp\"\n   [(set (match_operand:DF   0 \"s_register_operand\" \"=w,w,w,w,w,w,?r,?r,?r\")\n \t(if_then_else:DF\n@@ -292,13 +464,36 @@\n     (set_attr \"type\" \"ffarith,ffarith,ffarith,r_2_f,r_2_f,r_2_f,f_2_r,f_2_r,f_2_r\")]\n )\n \n+(define_insn \"*thumb2_movdfcc_vfp\"\n+  [(set (match_operand:DF   0 \"s_register_operand\" \"=w,w,w,w,w,w,?r,?r,?r\")\n+\t(if_then_else:DF\n+\t  (match_operator   3 \"arm_comparison_operator\"\n+\t    [(match_operand 4 \"cc_register\" \"\") (const_int 0)])\n+\t  (match_operand:DF 1 \"s_register_operand\" \"0,w,w,0,?r,?r,0,w,w\")\n+\t  (match_operand:DF 2 \"s_register_operand\" \"w,0,w,?r,0,?r,w,0,w\")))]\n+  \"TARGET_THUMB2 && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"@\n+   it\\\\t%D3\\;fcpyd%D3\\\\t%P0, %P2\n+   it\\\\t%d3\\;fcpyd%d3\\\\t%P0, %P1\n+   ite\\\\t%D3\\;fcpyd%D3\\\\t%P0, %P2\\;fcpyd%d3\\\\t%P0, %P1\n+   it\\t%D3\\;fmdrr%D3\\\\t%P0, %Q2, %R2\n+   it\\t%d3\\;fmdrr%d3\\\\t%P0, %Q1, %R1\n+   ite\\\\t%D3\\;fmdrr%D3\\\\t%P0, %Q2, %R2\\;fmdrr%d3\\\\t%P0, %Q1, %R1\n+   it\\t%D3\\;fmrrd%D3\\\\t%Q0, %R0, %P2\n+   it\\t%d3\\;fmrrd%d3\\\\t%Q0, %R0, %P1\n+   ite\\\\t%D3\\;fmrrd%D3\\\\t%Q0, %R0, %P2\\;fmrrd%d3\\\\t%Q0, %R0, %P1\"\n+   [(set_attr \"conds\" \"use\")\n+    (set_attr \"length\" \"6,6,10,6,6,10,6,6,10\")\n+    (set_attr \"type\" \"ffarith,ffarith,ffarith,r_2_f,r_2_f,r_2_f,f_2_r,f_2_r,f_2_r\")]\n+)\n+\n \n ;; Sign manipulation functions\n \n (define_insn \"*abssf2_vfp\"\n   [(set (match_operand:SF\t  0 \"s_register_operand\" \"=w\")\n \t(abs:SF (match_operand:SF 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fabss%?\\\\t%0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"ffarith\")]\n@@ -307,7 +502,7 @@\n (define_insn \"*absdf2_vfp\"\n   [(set (match_operand:DF\t  0 \"s_register_operand\" \"=w\")\n \t(abs:DF (match_operand:DF 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fabsd%?\\\\t%P0, %P1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"ffarith\")]\n@@ -316,7 +511,7 @@\n (define_insn \"*negsf2_vfp\"\n   [(set (match_operand:SF\t  0 \"s_register_operand\" \"=w,?r\")\n \t(neg:SF (match_operand:SF 1 \"s_register_operand\" \"w,r\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"@\n    fnegs%?\\\\t%0, %1\n    eor%?\\\\t%0, %1, #-2147483648\"\n@@ -327,12 +522,12 @@\n (define_insn_and_split \"*negdf2_vfp\"\n   [(set (match_operand:DF\t  0 \"s_register_operand\" \"=w,?r,?r\")\n \t(neg:DF (match_operand:DF 1 \"s_register_operand\" \"w,0,r\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"@\n    fnegd%?\\\\t%P0, %P1\n    #\n    #\"\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP && reload_completed\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP && reload_completed\n    && arm_general_register_operand (operands[0], DFmode)\"\n   [(set (match_dup 0) (match_dup 1))]\n   \"\n@@ -377,7 +572,7 @@\n   [(set (match_operand:SF\t   0 \"s_register_operand\" \"=w\")\n \t(plus:SF (match_operand:SF 1 \"s_register_operand\" \"w\")\n \t\t (match_operand:SF 2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fadds%?\\\\t%0, %1, %2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -387,7 +582,7 @@\n   [(set (match_operand:DF\t   0 \"s_register_operand\" \"=w\")\n \t(plus:DF (match_operand:DF 1 \"s_register_operand\" \"w\")\n \t\t (match_operand:DF 2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"faddd%?\\\\t%P0, %P1, %P2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -398,7 +593,7 @@\n   [(set (match_operand:SF\t    0 \"s_register_operand\" \"=w\")\n \t(minus:SF (match_operand:SF 1 \"s_register_operand\" \"w\")\n \t\t  (match_operand:SF 2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fsubs%?\\\\t%0, %1, %2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -408,7 +603,7 @@\n   [(set (match_operand:DF\t    0 \"s_register_operand\" \"=w\")\n \t(minus:DF (match_operand:DF 1 \"s_register_operand\" \"w\")\n \t\t  (match_operand:DF 2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fsubd%?\\\\t%P0, %P1, %P2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -421,7 +616,7 @@\n   [(set (match_operand:SF\t  0 \"s_register_operand\" \"+w\")\n \t(div:SF (match_operand:SF 1 \"s_register_operand\" \"w\")\n \t\t(match_operand:SF 2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fdivs%?\\\\t%0, %1, %2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fdivs\")]\n@@ -431,7 +626,7 @@\n   [(set (match_operand:DF\t  0 \"s_register_operand\" \"+w\")\n \t(div:DF (match_operand:DF 1 \"s_register_operand\" \"w\")\n \t\t(match_operand:DF 2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fdivd%?\\\\t%P0, %P1, %P2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fdivd\")]\n@@ -444,7 +639,7 @@\n   [(set (match_operand:SF\t   0 \"s_register_operand\" \"+w\")\n \t(mult:SF (match_operand:SF 1 \"s_register_operand\" \"w\")\n \t\t (match_operand:SF 2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fmuls%?\\\\t%0, %1, %2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -454,7 +649,7 @@\n   [(set (match_operand:DF\t   0 \"s_register_operand\" \"+w\")\n \t(mult:DF (match_operand:DF 1 \"s_register_operand\" \"w\")\n \t\t (match_operand:DF 2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fmuld%?\\\\t%P0, %P1, %P2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fmul\")]\n@@ -465,7 +660,7 @@\n   [(set (match_operand:SF\t\t   0 \"s_register_operand\" \"+w\")\n \t(mult:SF (neg:SF (match_operand:SF 1 \"s_register_operand\" \"w\"))\n \t\t (match_operand:SF\t   2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fnmuls%?\\\\t%0, %1, %2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -475,7 +670,7 @@\n   [(set (match_operand:DF\t\t   0 \"s_register_operand\" \"+w\")\n \t(mult:DF (neg:DF (match_operand:DF 1 \"s_register_operand\" \"w\"))\n \t\t (match_operand:DF\t   2 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fnmuld%?\\\\t%P0, %P1, %P2\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fmul\")]\n@@ -490,7 +685,7 @@\n \t(plus:SF (mult:SF (match_operand:SF 2 \"s_register_operand\" \"w\")\n \t\t\t  (match_operand:SF 3 \"s_register_operand\" \"w\"))\n \t\t (match_operand:SF\t    1 \"s_register_operand\" \"0\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fmacs%?\\\\t%0, %2, %3\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -501,7 +696,7 @@\n \t(plus:DF (mult:DF (match_operand:DF 2 \"s_register_operand\" \"w\")\n \t\t\t  (match_operand:DF 3 \"s_register_operand\" \"w\"))\n \t\t (match_operand:DF\t    1 \"s_register_operand\" \"0\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fmacd%?\\\\t%P0, %P2, %P3\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fmul\")]\n@@ -513,7 +708,7 @@\n \t(minus:SF (mult:SF (match_operand:SF 2 \"s_register_operand\" \"w\")\n \t\t\t   (match_operand:SF 3 \"s_register_operand\" \"w\"))\n \t\t  (match_operand:SF\t     1 \"s_register_operand\" \"0\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fmscs%?\\\\t%0, %2, %3\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -524,7 +719,7 @@\n \t(minus:DF (mult:DF (match_operand:DF 2 \"s_register_operand\" \"w\")\n \t\t\t   (match_operand:DF 3 \"s_register_operand\" \"w\"))\n \t\t  (match_operand:DF\t     1 \"s_register_operand\" \"0\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fmscd%?\\\\t%P0, %P2, %P3\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fmul\")]\n@@ -536,7 +731,7 @@\n \t(minus:SF (match_operand:SF\t     1 \"s_register_operand\" \"0\")\n \t\t  (mult:SF (match_operand:SF 2 \"s_register_operand\" \"w\")\n \t\t\t   (match_operand:SF 3 \"s_register_operand\" \"w\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fnmacs%?\\\\t%0, %2, %3\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -547,7 +742,7 @@\n \t(minus:DF (match_operand:DF\t     1 \"s_register_operand\" \"0\")\n \t\t  (mult:DF (match_operand:DF 2 \"s_register_operand\" \"w\")\n \t\t\t   (match_operand:DF 3 \"s_register_operand\" \"w\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fnmacd%?\\\\t%P0, %P2, %P3\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fmul\")]\n@@ -561,7 +756,7 @@\n \t\t    (neg:SF (match_operand:SF 2 \"s_register_operand\" \"w\"))\n \t\t    (match_operand:SF\t      3 \"s_register_operand\" \"w\"))\n \t\t  (match_operand:SF\t      1 \"s_register_operand\" \"0\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fnmscs%?\\\\t%0, %2, %3\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"farith\")]\n@@ -573,7 +768,7 @@\n \t\t    (neg:DF (match_operand:DF 2 \"s_register_operand\" \"w\"))\n \t\t    (match_operand:DF\t      3 \"s_register_operand\" \"w\"))\n \t\t  (match_operand:DF\t      1 \"s_register_operand\" \"0\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fnmscd%?\\\\t%P0, %P2, %P3\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fmul\")]\n@@ -585,7 +780,7 @@\n (define_insn \"*extendsfdf2_vfp\"\n   [(set (match_operand:DF\t\t   0 \"s_register_operand\" \"=w\")\n \t(float_extend:DF (match_operand:SF 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fcvtds%?\\\\t%P0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -594,7 +789,7 @@\n (define_insn \"*truncdfsf2_vfp\"\n   [(set (match_operand:SF\t\t   0 \"s_register_operand\" \"=w\")\n \t(float_truncate:SF (match_operand:DF 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fcvtsd%?\\\\t%0, %P1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -603,7 +798,7 @@\n (define_insn \"*truncsisf2_vfp\"\n   [(set (match_operand:SI\t\t  0 \"s_register_operand\" \"=w\")\n \t(fix:SI (fix:SF (match_operand:SF 1 \"s_register_operand\" \"w\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"ftosizs%?\\\\t%0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -612,7 +807,7 @@\n (define_insn \"*truncsidf2_vfp\"\n   [(set (match_operand:SI\t\t  0 \"s_register_operand\" \"=w\")\n \t(fix:SI (fix:DF (match_operand:DF 1 \"s_register_operand\" \"w\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"ftosizd%?\\\\t%0, %P1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -622,7 +817,7 @@\n (define_insn \"fixuns_truncsfsi2\"\n   [(set (match_operand:SI\t\t  0 \"s_register_operand\" \"=w\")\n \t(unsigned_fix:SI (fix:SF (match_operand:SF 1 \"s_register_operand\" \"w\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"ftouizs%?\\\\t%0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -631,7 +826,7 @@\n (define_insn \"fixuns_truncdfsi2\"\n   [(set (match_operand:SI\t\t  0 \"s_register_operand\" \"=w\")\n \t(unsigned_fix:SI (fix:DF (match_operand:DF 1 \"s_register_operand\" \"w\"))))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"ftouizd%?\\\\t%0, %P1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -641,7 +836,7 @@\n (define_insn \"*floatsisf2_vfp\"\n   [(set (match_operand:SF\t    0 \"s_register_operand\" \"=w\")\n \t(float:SF (match_operand:SI 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fsitos%?\\\\t%0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -650,7 +845,7 @@\n (define_insn \"*floatsidf2_vfp\"\n   [(set (match_operand:DF\t    0 \"s_register_operand\" \"=w\")\n \t(float:DF (match_operand:SI 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fsitod%?\\\\t%P0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -660,7 +855,7 @@\n (define_insn \"floatunssisf2\"\n   [(set (match_operand:SF\t    0 \"s_register_operand\" \"=w\")\n \t(unsigned_float:SF (match_operand:SI 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fuitos%?\\\\t%0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -669,7 +864,7 @@\n (define_insn \"floatunssidf2\"\n   [(set (match_operand:DF\t    0 \"s_register_operand\" \"=w\")\n \t(unsigned_float:DF (match_operand:SI 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fuitod%?\\\\t%P0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"f_cvt\")]\n@@ -681,7 +876,7 @@\n (define_insn \"*sqrtsf2_vfp\"\n   [(set (match_operand:SF\t   0 \"s_register_operand\" \"=w\")\n \t(sqrt:SF (match_operand:SF 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fsqrts%?\\\\t%0, %1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fdivs\")]\n@@ -690,7 +885,7 @@\n (define_insn \"*sqrtdf2_vfp\"\n   [(set (match_operand:DF\t   0 \"s_register_operand\" \"=w\")\n \t(sqrt:DF (match_operand:DF 1 \"s_register_operand\" \"w\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fsqrtd%?\\\\t%P0, %P1\"\n   [(set_attr \"predicable\" \"yes\")\n    (set_attr \"type\" \"fdivd\")]\n@@ -702,7 +897,7 @@\n (define_insn \"*movcc_vfp\"\n   [(set (reg CC_REGNUM)\n \t(reg VFPCC_REGNUM))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"fmstat%?\"\n   [(set_attr \"conds\" \"set\")\n    (set_attr \"type\" \"f_flag\")]\n@@ -712,9 +907,9 @@\n   [(set (reg:CCFP CC_REGNUM)\n \t(compare:CCFP (match_operand:SF 0 \"s_register_operand\"  \"w\")\n \t\t      (match_operand:SF 1 \"vfp_compare_operand\" \"wG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"#\"\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   [(set (reg:CCFP VFPCC_REGNUM)\n \t(compare:CCFP (match_dup 0)\n \t\t      (match_dup 1)))\n@@ -727,9 +922,9 @@\n   [(set (reg:CCFPE CC_REGNUM)\n \t(compare:CCFPE (match_operand:SF 0 \"s_register_operand\"  \"w\")\n \t\t       (match_operand:SF 1 \"vfp_compare_operand\" \"wG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"#\"\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   [(set (reg:CCFPE VFPCC_REGNUM)\n \t(compare:CCFPE (match_dup 0)\n \t\t       (match_dup 1)))\n@@ -742,9 +937,9 @@\n   [(set (reg:CCFP CC_REGNUM)\n \t(compare:CCFP (match_operand:DF 0 \"s_register_operand\"  \"w\")\n \t\t      (match_operand:DF 1 \"vfp_compare_operand\" \"wG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"#\"\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   [(set (reg:CCFP VFPCC_REGNUM)\n \t(compare:CCFP (match_dup 0)\n \t\t       (match_dup 1)))\n@@ -757,9 +952,9 @@\n   [(set (reg:CCFPE CC_REGNUM)\n \t(compare:CCFPE (match_operand:DF 0 \"s_register_operand\"  \"w\")\n \t\t       (match_operand:DF 1 \"vfp_compare_operand\" \"wG\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"#\"\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   [(set (reg:CCFPE VFPCC_REGNUM)\n \t(compare:CCFPE (match_dup 0)\n \t\t       (match_dup 1)))\n@@ -775,7 +970,7 @@\n   [(set (reg:CCFP VFPCC_REGNUM)\n \t(compare:CCFP (match_operand:SF 0 \"s_register_operand\"  \"w,w\")\n \t\t      (match_operand:SF 1 \"vfp_compare_operand\" \"w,G\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"@\n    fcmps%?\\\\t%0, %1\n    fcmpzs%?\\\\t%0\"\n@@ -787,7 +982,7 @@\n   [(set (reg:CCFPE VFPCC_REGNUM)\n \t(compare:CCFPE (match_operand:SF 0 \"s_register_operand\"  \"w,w\")\n \t\t       (match_operand:SF 1 \"vfp_compare_operand\" \"w,G\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"@\n    fcmpes%?\\\\t%0, %1\n    fcmpezs%?\\\\t%0\"\n@@ -799,7 +994,7 @@\n   [(set (reg:CCFP VFPCC_REGNUM)\n \t(compare:CCFP (match_operand:DF 0 \"s_register_operand\"  \"w,w\")\n \t\t      (match_operand:DF 1 \"vfp_compare_operand\" \"w,G\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"@\n    fcmpd%?\\\\t%P0, %P1\n    fcmpzd%?\\\\t%P0\"\n@@ -811,7 +1006,7 @@\n   [(set (reg:CCFPE VFPCC_REGNUM)\n \t(compare:CCFPE (match_operand:DF 0 \"s_register_operand\"  \"w,w\")\n \t\t       (match_operand:DF 1 \"vfp_compare_operand\" \"w,G\")))]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"@\n    fcmped%?\\\\t%P0, %P1\n    fcmpezd%?\\\\t%P0\"\n@@ -827,7 +1022,7 @@\n     [(set (match_operand:BLK 0 \"memory_operand\" \"=m\")\n \t  (unspec:BLK [(match_operand:DF 1 \"s_register_operand\" \"w\")]\n \t\t      UNSPEC_PUSH_MULT))])]\n-  \"TARGET_ARM && TARGET_HARD_FLOAT && TARGET_VFP\"\n+  \"TARGET_32BIT && TARGET_HARD_FLOAT && TARGET_VFP\"\n   \"* return vfp_output_fstmd (operands);\"\n   [(set_attr \"type\" \"f_stored\")]\n )"}, {"sha": "3d05ad47c68936f817b316adbd567523ee5a7c74", "filename": "gcc/doc/extend.texi", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fdoc%2Fextend.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fdoc%2Fextend.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fextend.texi?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,5 @@\n @c Copyright (C) 1988, 1989, 1992, 1993, 1994, 1996, 1998, 1999, 2000,\n-@c 2001, 2002, 2003, 2004, 2005, 2006 Free Software Foundation, Inc.\n+@c 2001, 2002, 2003, 2004, 2005, 2006, 2007 Free Software Foundation, Inc.\n \n @c This is part of the GCC manual.\n @c For copying conditions, see the file gcc.texi.\n@@ -1965,6 +1965,9 @@ void f () __attribute__ ((interrupt (\"IRQ\")));\n \n Permissible values for this parameter are: IRQ, FIQ, SWI, ABORT and UNDEF@.\n \n+On ARMv7-M the interrupt type is ignored, and the attibute means the function\n+may be called with a word aligned stack pointer.\n+\n @item interrupt_handler\n @cindex interrupt handler functions on the Blackfin, m68k, H8/300 and SH processors\n Use this attribute on the Blackfin, m68k, H8/300, H8/300H, H8S, and SH to"}, {"sha": "0b1ab49ce49f7a9ca57b4e7062b812d4562dc3c4", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 11, "deletions": 5, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5b3e666315f8d173a883a778dc7b500730977cd5/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=5b3e666315f8d173a883a778dc7b500730977cd5", "patch": "@@ -1,5 +1,6 @@\n @c Copyright (C) 1988, 1989, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n-@c 2000, 2001, 2002, 2003, 2004, 2005, 2006 Free Software Foundation, Inc.\n+@c 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007\n+@c Free Software Foundation, Inc.\n @c This is part of the GCC manual.\n @c For copying conditions, see the file gcc.texi.\n \n@@ -7605,8 +7606,9 @@ assembly code.  Permissible names are: @samp{arm2}, @samp{arm250},\n @samp{arm10tdmi}, @samp{arm1020t}, @samp{arm1026ej-s},\n @samp{arm10e}, @samp{arm1020e}, @samp{arm1022e},\n @samp{arm1136j-s}, @samp{arm1136jf-s}, @samp{mpcore}, @samp{mpcorenovfp},\n-@samp{arm1176jz-s}, @samp{arm1176jzf-s}, @samp{xscale}, @samp{iwmmxt},\n-@samp{ep9312}.\n+@samp{arm1156t2-s}, @samp{arm1176jz-s}, @samp{arm1176jzf-s},\n+@samp{cortex-a8}, @samp{cortex-r4}, @samp{cortex-m3},\n+@samp{xscale}, @samp{iwmmxt}, @samp{ep9312}.\n \n @itemx -mtune=@var{name}\n @opindex mtune\n@@ -7627,7 +7629,8 @@ assembly code.  This option can be used in conjunction with or instead\n of the @option{-mcpu=} option.  Permissible names are: @samp{armv2},\n @samp{armv2a}, @samp{armv3}, @samp{armv3m}, @samp{armv4}, @samp{armv4t},\n @samp{armv5}, @samp{armv5t}, @samp{armv5te}, @samp{armv6}, @samp{armv6j},\n-@samp{iwmmxt}, @samp{ep9312}.\n+@samp{armv6t2}, @samp{armv6z}, @samp{armv6zk}, @samp{armv7}, @samp{armv7-a},\n+@samp{armv7-r}, @samp{armv7-m}, @samp{iwmmxt}, @samp{ep9312}.\n \n @item -mfpu=@var{name}\n @itemx -mfpe=@var{number}\n@@ -7745,8 +7748,11 @@ and has length @code{((pc[-3]) & 0xff000000)}.\n \n @item -mthumb\n @opindex mthumb\n-Generate code for the 16-bit Thumb instruction set.  The default is to\n+Generate code for the Thumb instruction set.  The default is to\n use the 32-bit ARM instruction set.\n+This option automatically enables either 16-bit Thumb-1 or\n+mixed 16/32-bit Thumb-2 instructions based on the @option{-mcpu=@var{name}}\n+and @option{-march=@var{name}} options.\n \n @item -mtpcs-frame\n @opindex mtpcs-frame"}]}