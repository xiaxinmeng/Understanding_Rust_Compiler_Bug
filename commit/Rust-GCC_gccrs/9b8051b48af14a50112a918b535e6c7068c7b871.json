{"sha": "9b8051b48af14a50112a918b535e6c7068c7b871", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OWI4MDUxYjQ4YWYxNGE1MDExMmE5MThiNTM1ZTZjNzA2OGM3Yjg3MQ==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2010-07-03T19:33:14Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2010-07-03T19:33:14Z"}, "message": "ipa-inline.c (update_edge_key): Break out from ...\n\n\t* ipa-inline.c (update_edge_key): Break out from ...\n\tupdate_callers_keys): ... here;\n\t(update_callee_keys): Update only the edges from caller to callee.\n\t(update_all_calle_keys): Do what update_calle_keys did.\n\t(decide_inlining_of_small_functions): Avoid recomputing of all\n\tcallees when badness increase.\n\nFrom-SVN: r161778", "tree": {"sha": "096ac0fcb65e76873d32d9a6794846250e11aa7b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/096ac0fcb65e76873d32d9a6794846250e11aa7b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/9b8051b48af14a50112a918b535e6c7068c7b871", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9b8051b48af14a50112a918b535e6c7068c7b871", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9b8051b48af14a50112a918b535e6c7068c7b871", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9b8051b48af14a50112a918b535e6c7068c7b871/comments", "author": null, "committer": null, "parents": [{"sha": "3e78185c79c148cbf594b57b036b0de1f9d206ac", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3e78185c79c148cbf594b57b036b0de1f9d206ac", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3e78185c79c148cbf594b57b036b0de1f9d206ac"}], "stats": {"total": 109, "additions": 86, "deletions": 23}, "files": [{"sha": "07ec6f5c55a7634013687754dcbd5e0e1d22b094", "filename": "gcc/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9b8051b48af14a50112a918b535e6c7068c7b871/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9b8051b48af14a50112a918b535e6c7068c7b871/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=9b8051b48af14a50112a918b535e6c7068c7b871", "patch": "@@ -1,3 +1,12 @@\n+2010-07-03  Jan Hubicka  <jh@suse.cz>\n+\n+\t* ipa-inline.c (update_edge_key): Break out from ...\n+\tupdate_callers_keys): ... here;\n+\t(update_callee_keys): Update only the edges from caller to callee.\n+\t(update_all_calle_keys): Do what update_calle_keys did.\n+\t(decide_inlining_of_small_functions): Avoid recomputing of all\n+\tcallees when badness increase.\n+\n 2010-07-03  Jie Zhang  <jie@codesourcery.com>\n \n \t* config/arm/arm.c (arm_attr_length_move_neon): New."}, {"sha": "08f2ac3607d41c36267dcf5107804d8a76a751fe", "filename": "gcc/ipa-inline.c", "status": "modified", "additions": 77, "deletions": 23, "changes": 100, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9b8051b48af14a50112a918b535e6c7068c7b871/gcc%2Fipa-inline.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9b8051b48af14a50112a918b535e6c7068c7b871/gcc%2Fipa-inline.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-inline.c?ref=9b8051b48af14a50112a918b535e6c7068c7b871", "patch": "@@ -661,6 +661,30 @@ cgraph_edge_badness (struct cgraph_edge *edge, bool dump)\n     return badness;\n }\n \n+/* Recompute badness of EDGE and update its key in HEAP if needed.  */\n+static void\n+update_edge_key (fibheap_t heap, struct cgraph_edge *edge)\n+{\n+  int badness = cgraph_edge_badness (edge, false);\n+  if (edge->aux)\n+    {\n+      fibnode_t n = (fibnode_t) edge->aux;\n+      gcc_checking_assert (n->data == edge);\n+\n+      /* fibheap_replace_key only decrease the keys.\n+\t When we increase the key we do not update heap\n+\t and instead re-insert the element once it becomes\n+\t a minium of heap.  */\n+      if (badness < n->key)\n+\t{\n+\t  fibheap_replace_key (heap, n, badness);\n+\t  gcc_checking_assert (n->key == badness);\n+\t}\n+    }\n+  else\n+    edge->aux = fibheap_insert (heap, badness, edge);\n+}\n+\n /* Recompute heap nodes for each of caller edge.  */\n \n static void\n@@ -678,8 +702,6 @@ update_caller_keys (fibheap_t heap, struct cgraph_node *node,\n   bitmap_set_bit (updated_nodes, node->uid);\n   node->global.estimated_growth = INT_MIN;\n \n-  if (!node->local.inlinable)\n-    return;\n   /* See if there is something to do.  */\n   for (edge = node->callers; edge; edge = edge->next_caller)\n     if (edge->inline_failed)\n@@ -702,37 +724,62 @@ update_caller_keys (fibheap_t heap, struct cgraph_node *node,\n \n   for (; edge; edge = edge->next_caller)\n     if (edge->inline_failed)\n+      update_edge_key (heap, edge);\n+}\n+\n+/* Recompute heap nodes for each uninlined call.\n+   This is used when we know that edge badnesses are going only to increase\n+   (we introduced new call site) and thus all we need is to insert newly\n+   created edges into heap.  */\n+\n+static void\n+update_callee_keys (fibheap_t heap, struct cgraph_node *node,\n+\t\t    bitmap updated_nodes)\n+{\n+  struct cgraph_edge *e = node->callees;\n+  node->global.estimated_growth = INT_MIN;\n+\n+  if (!e)\n+    return;\n+  while (true)\n+    if (!e->inline_failed && e->callee->callees)\n+      e = e->callee->callees;\n+    else\n       {\n-\tint badness = cgraph_edge_badness (edge, false);\n-\tif (edge->aux)\n+\tif (e->inline_failed\n+\t    && e->callee->local.inlinable\n+\t    && !bitmap_bit_p (updated_nodes, e->callee->uid))\n \t  {\n-\t    fibnode_t n = (fibnode_t) edge->aux;\n-\t    gcc_assert (n->data == edge);\n-\t    if (n->key == badness)\n-\t      continue;\n-\n-\t    /* fibheap_replace_key only decrease the keys.\n-\t       When we increase the key we do not update heap\n-\t       and instead re-insert the element once it becomes\n-\t       a minium of heap.  */\n-\t    if (badness < n->key)\n+\t    node->global.estimated_growth = INT_MIN;\n+\t    /* If function becomes uninlinable, we need to remove it from the heap.  */\n+\t    if (!cgraph_default_inline_p (e->callee, &e->inline_failed))\n+\t      update_caller_keys (heap, e->callee, updated_nodes);\n+\t    else\n+\t    /* Otherwise update just edge E.  */\n+\t      update_edge_key (heap, e);\n+\t  }\n+\tif (e->next_callee)\n+\t  e = e->next_callee;\n+\telse\n+\t  {\n+\t    do\n \t      {\n-\t\tfibheap_replace_key (heap, n, badness);\n-\t\tgcc_assert (n->key == badness);\n-\t        continue;\n+\t\tif (e->caller == node)\n+\t\t  return;\n+\t\te = e->caller->callers;\n \t      }\n+\t    while (!e->next_callee);\n+\t    e = e->next_callee;\n \t  }\n-\telse\n-\t  edge->aux = fibheap_insert (heap, badness, edge);\n       }\n }\n \n /* Recompute heap nodes for each of caller edges of each of callees.\n    Walk recursively into all inline clones.  */\n \n static void\n-update_callee_keys (fibheap_t heap, struct cgraph_node *node,\n-\t\t    bitmap updated_nodes)\n+update_all_callee_keys (fibheap_t heap, struct cgraph_node *node,\n+\t\t\tbitmap updated_nodes)\n {\n   struct cgraph_edge *e = node->callees;\n   node->global.estimated_growth = INT_MIN;\n@@ -1166,7 +1213,7 @@ cgraph_decide_inlining_of_small_functions (void)\n \t    continue;\n \t  if (flag_indirect_inlining)\n \t    add_new_edges_to_heap (heap, new_indirect_edges);\n-          update_callee_keys (heap, where, updated_nodes);\n+          update_all_callee_keys (heap, where, updated_nodes);\n \t}\n       else\n \t{\n@@ -1182,11 +1229,18 @@ cgraph_decide_inlining_of_small_functions (void)\n \t      continue;\n \t    }\n \t  callee = edge->callee;\n+\t  gcc_checking_assert (!callee->global.inlined_to);\n \t  cgraph_mark_inline_edge (edge, true, &new_indirect_edges);\n \t  if (flag_indirect_inlining)\n \t    add_new_edges_to_heap (heap, new_indirect_edges);\n \n-\t  update_callee_keys (heap, callee, updated_nodes);\n+\t  /* We inlined last offline copy to the body.  This might lead\n+\t     to callees of function having fewer call sites and thus they\n+\t     may need updating.  */\n+\t  if (callee->global.inlined_to)\n+\t    update_all_callee_keys (heap, callee, updated_nodes);\n+\t  else\n+\t    update_callee_keys (heap, edge->callee, updated_nodes);\n \t}\n       where = edge->caller;\n       if (where->global.inlined_to)"}]}