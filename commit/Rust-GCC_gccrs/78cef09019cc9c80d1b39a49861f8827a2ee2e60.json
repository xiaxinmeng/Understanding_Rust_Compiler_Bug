{"sha": "78cef09019cc9c80d1b39a49861f8827a2ee2e60", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzhjZWYwOTAxOWNjOWM4MGQxYjM5YTQ5ODYxZjg4MjdhMmVlMmU2MA==", "commit": {"author": {"name": "Jakub Jelinek", "email": "jakub@redhat.com", "date": "2020-04-29T15:30:22Z"}, "committer": {"name": "Jakub Jelinek", "email": "jakub@redhat.com", "date": "2020-04-29T15:30:22Z"}, "message": "x86: Fix -O0 intrinsic *gather*/*scatter* macros [PR94832]\n\nAs reported in the PR, while most intrinsic -O0 macro argument uses\nare properly wrapped in ()s or used in context where having a complex\nexpression passed as the argument doesn't pose a problem (e.g. when\nmacro argument use is in between commas, or between ( and comma, or\nbetween comma and ) etc.), especially the gather/scatter macros don't do\nthis and if one passes to some macro e.g. x + y as argument, the\ncorresponding inline function would do cast on the argument, but\nthe macro does (int) ARG, then it is (int) x + y rather than (int) (x + y).\n\nThe following patch fixes those issues in *gather/*scatter*; additionally,\nthe AVX2 macros were passing incorrect mask of e.g.\n(__v2df)_mm_set1_pd((double)(long long int) -1)\nwhich is IMHO equivalent to\n(__v2df){-1.0, -1.0}\nwhen it really wants to pass __v2df vector with all bits set.\nI've used what the inline functions use for those cases.\n\n2020-04-29  Jakub Jelinek  <jakub@redhat.com>\n\n\tPR target/94832\n\t* config/i386/avx2intrin.h (_mm_mask_i32gather_pd,\n\t_mm256_mask_i32gather_pd, _mm_mask_i64gather_pd,\n\t_mm256_mask_i64gather_pd, _mm_mask_i32gather_ps,\n\t_mm256_mask_i32gather_ps, _mm_mask_i64gather_ps,\n\t_mm256_mask_i64gather_ps, _mm_i32gather_epi64,\n\t_mm_mask_i32gather_epi64, _mm256_i32gather_epi64,\n\t_mm256_mask_i32gather_epi64, _mm_i64gather_epi64,\n\t_mm_mask_i64gather_epi64, _mm256_i64gather_epi64,\n\t_mm256_mask_i64gather_epi64, _mm_i32gather_epi32,\n\t_mm_mask_i32gather_epi32, _mm256_i32gather_epi32,\n\t_mm256_mask_i32gather_epi32, _mm_i64gather_epi32,\n\t_mm_mask_i64gather_epi32, _mm256_i64gather_epi32,\n\t_mm256_mask_i64gather_epi32): Surround macro parameter uses with\n\tparens.\n\t(_mm_i32gather_pd, _mm256_i32gather_pd, _mm_i64gather_pd,\n\t_mm256_i64gather_pd, _mm_i32gather_ps, _mm256_i32gather_ps,\n\t_mm_i64gather_ps, _mm256_i64gather_ps): Likewise.  Don't use\n\tas mask vector containing -1.0 or -1.0f elts, but instead vector\n\twith all bits set using _mm*_cmpeq_p? with zero operands.\n\t* config/i386/avx512fintrin.h (_mm512_i32gather_ps,\n\t_mm512_mask_i32gather_ps, _mm512_i32gather_pd,\n\t_mm512_mask_i32gather_pd, _mm512_i64gather_ps,\n\t_mm512_mask_i64gather_ps, _mm512_i64gather_pd,\n\t_mm512_mask_i64gather_pd, _mm512_i32gather_epi32,\n\t_mm512_mask_i32gather_epi32, _mm512_i32gather_epi64,\n\t_mm512_mask_i32gather_epi64, _mm512_i64gather_epi32,\n\t_mm512_mask_i64gather_epi32, _mm512_i64gather_epi64,\n\t_mm512_mask_i64gather_epi64, _mm512_i32scatter_ps,\n\t_mm512_mask_i32scatter_ps, _mm512_i32scatter_pd,\n\t_mm512_mask_i32scatter_pd, _mm512_i64scatter_ps,\n\t_mm512_mask_i64scatter_ps, _mm512_i64scatter_pd,\n\t_mm512_mask_i64scatter_pd, _mm512_i32scatter_epi32,\n\t_mm512_mask_i32scatter_epi32, _mm512_i32scatter_epi64,\n\t_mm512_mask_i32scatter_epi64, _mm512_i64scatter_epi32,\n\t_mm512_mask_i64scatter_epi32, _mm512_i64scatter_epi64,\n\t_mm512_mask_i64scatter_epi64): Surround macro parameter uses with\n\tparens.\n\t* config/i386/avx512pfintrin.h (_mm512_prefetch_i32gather_pd,\n\t_mm512_prefetch_i32gather_ps, _mm512_mask_prefetch_i32gather_pd,\n\t_mm512_mask_prefetch_i32gather_ps, _mm512_prefetch_i64gather_pd,\n\t_mm512_prefetch_i64gather_ps, _mm512_mask_prefetch_i64gather_pd,\n\t_mm512_mask_prefetch_i64gather_ps, _mm512_prefetch_i32scatter_pd,\n\t_mm512_prefetch_i32scatter_ps, _mm512_mask_prefetch_i32scatter_pd,\n\t_mm512_mask_prefetch_i32scatter_ps, _mm512_prefetch_i64scatter_pd,\n\t_mm512_prefetch_i64scatter_ps, _mm512_mask_prefetch_i64scatter_pd,\n\t_mm512_mask_prefetch_i64scatter_ps): Likewise.\n\t* config/i386/avx512vlintrin.h (_mm256_mmask_i32gather_ps,\n\t_mm_mmask_i32gather_ps, _mm256_mmask_i32gather_pd,\n\t_mm_mmask_i32gather_pd, _mm256_mmask_i64gather_ps,\n\t_mm_mmask_i64gather_ps, _mm256_mmask_i64gather_pd,\n\t_mm_mmask_i64gather_pd, _mm256_mmask_i32gather_epi32,\n\t_mm_mmask_i32gather_epi32, _mm256_mmask_i32gather_epi64,\n\t_mm_mmask_i32gather_epi64, _mm256_mmask_i64gather_epi32,\n\t_mm_mmask_i64gather_epi32, _mm256_mmask_i64gather_epi64,\n\t_mm_mmask_i64gather_epi64, _mm256_i32scatter_ps,\n\t_mm256_mask_i32scatter_ps, _mm_i32scatter_ps, _mm_mask_i32scatter_ps,\n\t_mm256_i32scatter_pd, _mm256_mask_i32scatter_pd, _mm_i32scatter_pd,\n\t_mm_mask_i32scatter_pd, _mm256_i64scatter_ps,\n\t_mm256_mask_i64scatter_ps, _mm_i64scatter_ps, _mm_mask_i64scatter_ps,\n\t_mm256_i64scatter_pd, _mm256_mask_i64scatter_pd, _mm_i64scatter_pd,\n\t_mm_mask_i64scatter_pd, _mm256_i32scatter_epi32,\n\t_mm256_mask_i32scatter_epi32, _mm_i32scatter_epi32,\n\t_mm_mask_i32scatter_epi32, _mm256_i32scatter_epi64,\n\t_mm256_mask_i32scatter_epi64, _mm_i32scatter_epi64,\n\t_mm_mask_i32scatter_epi64, _mm256_i64scatter_epi32,\n\t_mm256_mask_i64scatter_epi32, _mm_i64scatter_epi32,\n\t_mm_mask_i64scatter_epi32, _mm256_i64scatter_epi64,\n\t_mm256_mask_i64scatter_epi64, _mm_i64scatter_epi64,\n\t_mm_mask_i64scatter_epi64): Likewise.", "tree": {"sha": "58f8a8a1b5df41e04a1e1c6a4c38e45aa62ca9cf", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/58f8a8a1b5df41e04a1e1c6a4c38e45aa62ca9cf"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/78cef09019cc9c80d1b39a49861f8827a2ee2e60", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/78cef09019cc9c80d1b39a49861f8827a2ee2e60", "html_url": "https://github.com/Rust-GCC/gccrs/commit/78cef09019cc9c80d1b39a49861f8827a2ee2e60", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/78cef09019cc9c80d1b39a49861f8827a2ee2e60/comments", "author": {"login": "jakubjelinek", "id": 9370665, "node_id": "MDQ6VXNlcjkzNzA2NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/9370665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubjelinek", "html_url": "https://github.com/jakubjelinek", "followers_url": "https://api.github.com/users/jakubjelinek/followers", "following_url": "https://api.github.com/users/jakubjelinek/following{/other_user}", "gists_url": "https://api.github.com/users/jakubjelinek/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubjelinek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubjelinek/subscriptions", "organizations_url": "https://api.github.com/users/jakubjelinek/orgs", "repos_url": "https://api.github.com/users/jakubjelinek/repos", "events_url": "https://api.github.com/users/jakubjelinek/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubjelinek/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jakubjelinek", "id": 9370665, "node_id": "MDQ6VXNlcjkzNzA2NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/9370665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubjelinek", "html_url": "https://github.com/jakubjelinek", "followers_url": "https://api.github.com/users/jakubjelinek/followers", "following_url": "https://api.github.com/users/jakubjelinek/following{/other_user}", "gists_url": "https://api.github.com/users/jakubjelinek/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubjelinek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubjelinek/subscriptions", "organizations_url": "https://api.github.com/users/jakubjelinek/orgs", "repos_url": "https://api.github.com/users/jakubjelinek/repos", "events_url": "https://api.github.com/users/jakubjelinek/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubjelinek/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "27594524d8a93cddb197ad8c9d4075c5870f1473", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/27594524d8a93cddb197ad8c9d4075c5870f1473", "html_url": "https://github.com/Rust-GCC/gccrs/commit/27594524d8a93cddb197ad8c9d4075c5870f1473"}], "stats": {"total": 1062, "additions": 589, "deletions": 473}, "files": [{"sha": "16e05d1fa60c2c7649cc3b13fefb740e533788f7", "filename": "gcc/ChangeLog", "status": "modified", "additions": 73, "deletions": 0, "changes": 73, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=78cef09019cc9c80d1b39a49861f8827a2ee2e60", "patch": "@@ -1,3 +1,76 @@\n+2020-04-29  Jakub Jelinek  <jakub@redhat.com>\n+\n+\tPR target/94832\n+\t* config/i386/avx2intrin.h (_mm_mask_i32gather_pd,\n+\t_mm256_mask_i32gather_pd, _mm_mask_i64gather_pd,\n+\t_mm256_mask_i64gather_pd, _mm_mask_i32gather_ps,\n+\t_mm256_mask_i32gather_ps, _mm_mask_i64gather_ps,\n+\t_mm256_mask_i64gather_ps, _mm_i32gather_epi64,\n+\t_mm_mask_i32gather_epi64, _mm256_i32gather_epi64,\n+\t_mm256_mask_i32gather_epi64, _mm_i64gather_epi64,\n+\t_mm_mask_i64gather_epi64, _mm256_i64gather_epi64,\n+\t_mm256_mask_i64gather_epi64, _mm_i32gather_epi32,\n+\t_mm_mask_i32gather_epi32, _mm256_i32gather_epi32,\n+\t_mm256_mask_i32gather_epi32, _mm_i64gather_epi32,\n+\t_mm_mask_i64gather_epi32, _mm256_i64gather_epi32,\n+\t_mm256_mask_i64gather_epi32): Surround macro parameter uses with\n+\tparens.\n+\t(_mm_i32gather_pd, _mm256_i32gather_pd, _mm_i64gather_pd,\n+\t_mm256_i64gather_pd, _mm_i32gather_ps, _mm256_i32gather_ps,\n+\t_mm_i64gather_ps, _mm256_i64gather_ps): Likewise.  Don't use\n+\tas mask vector containing -1.0 or -1.0f elts, but instead vector\n+\twith all bits set using _mm*_cmpeq_p? with zero operands.\n+\t* config/i386/avx512fintrin.h (_mm512_i32gather_ps,\n+\t_mm512_mask_i32gather_ps, _mm512_i32gather_pd,\n+\t_mm512_mask_i32gather_pd, _mm512_i64gather_ps,\n+\t_mm512_mask_i64gather_ps, _mm512_i64gather_pd,\n+\t_mm512_mask_i64gather_pd, _mm512_i32gather_epi32,\n+\t_mm512_mask_i32gather_epi32, _mm512_i32gather_epi64,\n+\t_mm512_mask_i32gather_epi64, _mm512_i64gather_epi32,\n+\t_mm512_mask_i64gather_epi32, _mm512_i64gather_epi64,\n+\t_mm512_mask_i64gather_epi64, _mm512_i32scatter_ps,\n+\t_mm512_mask_i32scatter_ps, _mm512_i32scatter_pd,\n+\t_mm512_mask_i32scatter_pd, _mm512_i64scatter_ps,\n+\t_mm512_mask_i64scatter_ps, _mm512_i64scatter_pd,\n+\t_mm512_mask_i64scatter_pd, _mm512_i32scatter_epi32,\n+\t_mm512_mask_i32scatter_epi32, _mm512_i32scatter_epi64,\n+\t_mm512_mask_i32scatter_epi64, _mm512_i64scatter_epi32,\n+\t_mm512_mask_i64scatter_epi32, _mm512_i64scatter_epi64,\n+\t_mm512_mask_i64scatter_epi64): Surround macro parameter uses with\n+\tparens.\n+\t* config/i386/avx512pfintrin.h (_mm512_prefetch_i32gather_pd,\n+\t_mm512_prefetch_i32gather_ps, _mm512_mask_prefetch_i32gather_pd,\n+\t_mm512_mask_prefetch_i32gather_ps, _mm512_prefetch_i64gather_pd,\n+\t_mm512_prefetch_i64gather_ps, _mm512_mask_prefetch_i64gather_pd,\n+\t_mm512_mask_prefetch_i64gather_ps, _mm512_prefetch_i32scatter_pd,\n+\t_mm512_prefetch_i32scatter_ps, _mm512_mask_prefetch_i32scatter_pd,\n+\t_mm512_mask_prefetch_i32scatter_ps, _mm512_prefetch_i64scatter_pd,\n+\t_mm512_prefetch_i64scatter_ps, _mm512_mask_prefetch_i64scatter_pd,\n+\t_mm512_mask_prefetch_i64scatter_ps): Likewise.\n+\t* config/i386/avx512vlintrin.h (_mm256_mmask_i32gather_ps,\n+\t_mm_mmask_i32gather_ps, _mm256_mmask_i32gather_pd,\n+\t_mm_mmask_i32gather_pd, _mm256_mmask_i64gather_ps,\n+\t_mm_mmask_i64gather_ps, _mm256_mmask_i64gather_pd,\n+\t_mm_mmask_i64gather_pd, _mm256_mmask_i32gather_epi32,\n+\t_mm_mmask_i32gather_epi32, _mm256_mmask_i32gather_epi64,\n+\t_mm_mmask_i32gather_epi64, _mm256_mmask_i64gather_epi32,\n+\t_mm_mmask_i64gather_epi32, _mm256_mmask_i64gather_epi64,\n+\t_mm_mmask_i64gather_epi64, _mm256_i32scatter_ps,\n+\t_mm256_mask_i32scatter_ps, _mm_i32scatter_ps, _mm_mask_i32scatter_ps,\n+\t_mm256_i32scatter_pd, _mm256_mask_i32scatter_pd, _mm_i32scatter_pd,\n+\t_mm_mask_i32scatter_pd, _mm256_i64scatter_ps,\n+\t_mm256_mask_i64scatter_ps, _mm_i64scatter_ps, _mm_mask_i64scatter_ps,\n+\t_mm256_i64scatter_pd, _mm256_mask_i64scatter_pd, _mm_i64scatter_pd,\n+\t_mm_mask_i64scatter_pd, _mm256_i32scatter_epi32,\n+\t_mm256_mask_i32scatter_epi32, _mm_i32scatter_epi32,\n+\t_mm_mask_i32scatter_epi32, _mm256_i32scatter_epi64,\n+\t_mm256_mask_i32scatter_epi64, _mm_i32scatter_epi64,\n+\t_mm_mask_i32scatter_epi64, _mm256_i64scatter_epi32,\n+\t_mm256_mask_i64scatter_epi32, _mm_i64scatter_epi32,\n+\t_mm_mask_i64scatter_epi32, _mm256_i64scatter_epi64,\n+\t_mm256_mask_i64scatter_epi64, _mm_i64scatter_epi64,\n+\t_mm_mask_i64scatter_epi64): Likewise.\n+\n 2020-04-29  Jeff Law  <law@redhat.com>\n \n \t* config/h8300/h8300.md (H8/SX div patterns): All H8/SX specific"}, {"sha": "6bf1f8c43334e39407cc7b50b5f395e13b915e26", "filename": "gcc/config/i386/avx2intrin.h", "status": "modified", "additions": 183, "deletions": 171, "changes": 354, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2Fconfig%2Fi386%2Favx2intrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2Fconfig%2Fi386%2Favx2intrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx2intrin.h?ref=78cef09019cc9c80d1b39a49861f8827a2ee2e60", "patch": "@@ -1670,234 +1670,246 @@ _mm256_mask_i64gather_epi32 (__m128i __src, int const *__base,\n #else /* __OPTIMIZE__ */\n #define _mm_i32gather_pd(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128d) __builtin_ia32_gathersiv2df ((__v2df) _mm_setzero_pd (),\t\\\n-\t\t\t\t\t (double const *)BASE,\t\t\\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n-\t\t\t\t\t (__v2df)_mm_set1_pd(\t\t\\\n-\t\t\t\t\t   (double)(long long int) -1), \\\n-\t\t\t\t\t (int)SCALE)\n-\n-#define _mm_mask_i32gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \\\n-  (__m128d) __builtin_ia32_gathersiv2df ((__v2df)(__m128d)SRC,\t \\\n-\t\t\t\t\t (double const *)BASE,\t \\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX, \\\n-\t\t\t\t\t (__v2df)(__m128d)MASK,\t \\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (double const *) (BASE),\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v2df)\t\t\t\\\n+\t\t\t\t\t _mm_cmpeq_pd (_mm_setzero_pd (),\\\n+\t\t\t\t\t\t       _mm_setzero_pd ()),\\\n+\t\t\t\t\t (int) (SCALE))\n+\n+#define _mm_mask_i32gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \t\\\n+  (__m128d) __builtin_ia32_gathersiv2df ((__v2df)(__m128d) (SRC),\t\\\n+\t\t\t\t\t (double const *) (BASE),\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v2df)(__m128d) (MASK),\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm256_i32gather_pd(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m256d) __builtin_ia32_gathersiv4df ((__v4df) _mm256_setzero_pd (),\t\\\n-\t\t\t\t\t (double const *)BASE,\t\t\\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n-\t\t\t\t\t (__v4df)_mm256_set1_pd(\t\\\n-\t\t\t\t\t   (double)(long long int) -1), \\\n-\t\t\t\t\t (int)SCALE)\n-\n-#define _mm256_mask_i32gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \\\n-  (__m256d) __builtin_ia32_gathersiv4df ((__v4df)(__m256d)SRC,\t \\\n-\t\t\t\t\t (double const *)BASE,\t \\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX, \\\n-\t\t\t\t\t (__v4df)(__m256d)MASK,\t \\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (double const *) (BASE),\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v4df)\t\t\t\\\n+\t\t\t\t\t _mm256_cmp_pd (_mm256_setzero_pd (),\\\n+\t\t\t\t\t\t\t_mm256_setzero_pd (),\\\n+\t\t\t\t\t\t\t_CMP_EQ_OQ),\t\\\n+\t\t\t\t\t (int) (SCALE))\n+\n+#define _mm256_mask_i32gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t\t\\\n+  (__m256d) __builtin_ia32_gathersiv4df ((__v4df)(__m256d) (SRC),\t\\\n+\t\t\t\t\t (double const *) (BASE),\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v4df)(__m256d) (MASK),\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm_i64gather_pd(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128d) __builtin_ia32_gatherdiv2df ((__v2df) _mm_setzero_pd (),\t\\\n-\t\t\t\t\t (double const *)BASE,\t\t\\\n-\t\t\t\t\t (__v2di)(__m128i)INDEX,\t\\\n-\t\t\t\t\t (__v2df)_mm_set1_pd(\t\t\\\n-\t\t\t\t\t   (double)(long long int) -1), \\\n-\t\t\t\t\t (int)SCALE)\n-\n-#define _mm_mask_i64gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \\\n-  (__m128d) __builtin_ia32_gatherdiv2df ((__v2df)(__m128d)SRC,\t \\\n-\t\t\t\t\t (double const *)BASE,\t \\\n-\t\t\t\t\t (__v2di)(__m128i)INDEX, \\\n-\t\t\t\t\t (__v2df)(__m128d)MASK,\t \\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (double const *) (BASE),\t\\\n+\t\t\t\t\t (__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v2df)\t\t\t\\\n+\t\t\t\t\t _mm_cmpeq_pd (_mm_setzero_pd (),\\\n+\t\t\t\t\t\t       _mm_setzero_pd ()),\\\n+\t\t\t\t\t (int) (SCALE))\n+\n+#define _mm_mask_i64gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t\t\\\n+  (__m128d) __builtin_ia32_gatherdiv2df ((__v2df)(__m128d) (SRC),\t\\\n+\t\t\t\t\t (double const *) (BASE),\t\\\n+\t\t\t\t\t (__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v2df)(__m128d) (MASK),\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm256_i64gather_pd(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m256d) __builtin_ia32_gatherdiv4df ((__v4df) _mm256_setzero_pd (),\t\\\n-\t\t\t\t\t (double const *)BASE,\t\t\\\n-\t\t\t\t\t (__v4di)(__m256i)INDEX,\t\\\n-\t\t\t\t\t (__v4df)_mm256_set1_pd(\t\\\n-\t\t\t\t\t   (double)(long long int) -1), \\\n-\t\t\t\t\t (int)SCALE)\n-\n-#define _mm256_mask_i64gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \\\n-  (__m256d) __builtin_ia32_gatherdiv4df ((__v4df)(__m256d)SRC,\t \\\n-\t\t\t\t\t (double const *)BASE,\t \\\n-\t\t\t\t\t (__v4di)(__m256i)INDEX, \\\n-\t\t\t\t\t (__v4df)(__m256d)MASK,\t \\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (double const *) (BASE),\t\\\n+\t\t\t\t\t (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__v4df)\t\t\t\\\n+\t\t\t\t\t _mm256_cmp_pd (_mm256_setzero_pd (),\\\n+\t\t\t\t\t\t\t_mm256_setzero_pd (),\\\n+\t\t\t\t\t\t\t_CMP_EQ_OQ),\t\\\n+\t\t\t\t\t (int) (SCALE))\n+\n+#define _mm256_mask_i64gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \t\\\n+  (__m256d) __builtin_ia32_gatherdiv4df ((__v4df)(__m256d) (SRC),\t\\\n+\t\t\t\t\t (double const *) (BASE),\t\\\n+\t\t\t\t\t (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__v4df)(__m256d) (MASK),\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm_i32gather_ps(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128) __builtin_ia32_gathersiv4sf ((__v4sf) _mm_setzero_ps (),\t\\\n-\t\t\t\t\t(float const *)BASE,\t\t\\\n-\t\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\\\n-\t\t\t\t\t_mm_set1_ps ((float)(int) -1),\t\\\n-\t\t\t\t\t(int)SCALE)\n-\n-#define _mm_mask_i32gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t \\\n-  (__m128) __builtin_ia32_gathersiv4sf ((__v4sf)(__m128)SRC,\t \\\n-\t\t\t\t\t(float const *)BASE,\t \\\n-\t\t\t\t\t(__v4si)(__m128i)INDEX,\t \\\n-\t\t\t\t\t(__v4sf)(__m128)MASK,\t \\\n-\t\t\t\t\t(int)SCALE)\n-\n-#define _mm256_i32gather_ps(BASE, INDEX, SCALE)\t\t\t       \\\n-  (__m256) __builtin_ia32_gathersiv8sf ((__v8sf) _mm256_setzero_ps (), \\\n-\t\t\t\t\t(float const *)BASE,\t       \\\n-\t\t\t\t\t(__v8si)(__m256i)INDEX,\t       \\\n-\t\t\t\t\t(__v8sf)_mm256_set1_ps (       \\\n-\t\t\t\t\t  (float)(int) -1),\t       \\\n-\t\t\t\t\t(int)SCALE)\n-\n-#define _mm256_mask_i32gather_ps(SRC, BASE, INDEX, MASK, SCALE) \\\n-  (__m256) __builtin_ia32_gathersiv8sf ((__v8sf)(__m256)SRC,\t\\\n-\t\t\t\t\t(float const *)BASE,\t\\\n-\t\t\t\t\t(__v8si)(__m256i)INDEX, \\\n-\t\t\t\t\t(__v8sf)(__m256)MASK,\t\\\n-\t\t\t\t\t(int)SCALE)\n+\t\t\t\t\t(float const *) (BASE),\t\t\\\n+\t\t\t\t\t(__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t(__v4sf)\t\t\t\\\n+\t\t\t\t\t_mm_cmpeq_ps (_mm_setzero_ps (),\\\n+\t\t\t\t\t\t      _mm_setzero_ps ()),\\\n+\t\t\t\t\t(int) (SCALE))\n+\n+#define _mm_mask_i32gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t \t\\\n+  (__m128) __builtin_ia32_gathersiv4sf ((__v4sf)(__m128) (SRC),\t\t\\\n+\t\t\t\t\t(float const *) (BASE),\t\t\\\n+\t\t\t\t\t(__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t(__v4sf)(__m128) (MASK),\t\\\n+\t\t\t\t\t(int) (SCALE))\n+\n+#define _mm256_i32gather_ps(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m256) __builtin_ia32_gathersiv8sf ((__v8sf) _mm256_setzero_ps (),\t\\\n+\t\t\t\t\t(float const *) (BASE),\t\t\\\n+\t\t\t\t\t(__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t(__v8sf)\t\t\t\\\n+\t\t\t\t\t_mm256_cmp_ps (_mm256_setzero_ps (),\\\n+\t\t\t\t\t\t       _mm256_setzero_ps (),\\\n+\t\t\t\t\t\t       _CMP_EQ_OQ),\t\\\n+\t\t\t\t\t(int) (SCALE))\n+\n+#define _mm256_mask_i32gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t\t\\\n+  (__m256) __builtin_ia32_gathersiv8sf ((__v8sf)(__m256) (SRC),\t\t\\\n+\t\t\t\t\t(float const *) (BASE),\t\t\\\n+\t\t\t\t\t(__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t(__v8sf)(__m256) (MASK),\t\\\n+\t\t\t\t\t(int) (SCALE))\n \n #define _mm_i64gather_ps(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128) __builtin_ia32_gatherdiv4sf ((__v4sf) _mm_setzero_pd (),\t\\\n-\t\t\t\t\t(float const *)BASE,\t\t\\\n-\t\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\\\n-\t\t\t\t\t(__v4sf)_mm_set1_ps (\t\t\\\n-\t\t\t\t\t  (float)(int) -1),\t\t\\\n-\t\t\t\t\t(int)SCALE)\n-\n-#define _mm_mask_i64gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t \\\n-  (__m128) __builtin_ia32_gatherdiv4sf ((__v4sf)(__m128)SRC,\t \\\n-\t\t\t\t\t(float const *)BASE,\t \\\n-\t\t\t\t\t(__v2di)(__m128i)INDEX,\t \\\n-\t\t\t\t\t(__v4sf)(__m128)MASK,\t \\\n-\t\t\t\t\t(int)SCALE)\n+\t\t\t\t\t(float const *) (BASE),\t\t\\\n+\t\t\t\t\t(__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t(__v4sf)\t\t\t\\\n+\t\t\t\t\t_mm_cmpeq_ps (_mm_setzero_ps (),\\\n+\t\t\t\t\t\t      _mm_setzero_ps ()),\\\n+\t\t\t\t\t(int) (SCALE))\n+\n+#define _mm_mask_i64gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t\t\\\n+  (__m128) __builtin_ia32_gatherdiv4sf ((__v4sf)(__m128) (SRC),\t\t\\\n+\t\t\t\t\t(float const *) (BASE),\t\t\\\n+\t\t\t\t\t(__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t(__v4sf)(__m128) (MASK),\t\\\n+\t\t\t\t\t(int) (SCALE))\n \n #define _mm256_i64gather_ps(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128) __builtin_ia32_gatherdiv4sf256 ((__v4sf) _mm_setzero_ps (),\t\\\n-\t\t\t\t\t   (float const *)BASE,\t\t\\\n-\t\t\t\t\t   (__v4di)(__m256i)INDEX,\t\\\n-\t\t\t\t\t   (__v4sf)_mm_set1_ps(\t\t\\\n-\t\t\t\t\t     (float)(int) -1),\t\t\\\n-\t\t\t\t\t   (int)SCALE)\n-\n-#define _mm256_mask_i64gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t   \\\n-  (__m128) __builtin_ia32_gatherdiv4sf256 ((__v4sf)(__m128)SRC,\t   \\\n-\t\t\t\t\t   (float const *)BASE,\t   \\\n-\t\t\t\t\t   (__v4di)(__m256i)INDEX, \\\n-\t\t\t\t\t   (__v4sf)(__m128)MASK,   \\\n-\t\t\t\t\t   (int)SCALE)\n+\t\t\t\t\t   (float const *) (BASE),\t\\\n+\t\t\t\t\t   (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t   (__v4sf)\t\t\t\\\n+\t\t\t\t\t   _mm_cmpeq_ps (_mm_setzero_ps (),\\\n+\t\t\t\t\t\t\t _mm_setzero_ps ()),\\\n+\t\t\t\t\t   (int) (SCALE))\n+\n+#define _mm256_mask_i64gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t   \t\\\n+  (__m128) __builtin_ia32_gatherdiv4sf256 ((__v4sf)(__m128) (SRC),\t\\\n+\t\t\t\t\t   (float const *) (BASE),\t\\\n+\t\t\t\t\t   (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t   (__v4sf)(__m128) (MASK),\t\\\n+\t\t\t\t\t   (int) (SCALE))\n \n #define _mm_i32gather_epi64(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128i) __builtin_ia32_gathersiv2di ((__v2di) _mm_setzero_si128 (), \\\n-\t\t\t\t\t (long long const *)BASE,\t\\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (long long const *) (BASE),\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n \t\t\t\t\t (__v2di)_mm_set1_epi64x (-1),\t\\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (int) (SCALE))\n \n-#define _mm_mask_i32gather_epi64(SRC, BASE, INDEX, MASK, SCALE)\t  \\\n-  (__m128i) __builtin_ia32_gathersiv2di ((__v2di)(__m128i)SRC,\t  \\\n-\t\t\t\t\t (long long const *)BASE, \\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX,  \\\n-\t\t\t\t\t (__v2di)(__m128i)MASK,\t  \\\n-\t\t\t\t\t (int)SCALE)\n+#define _mm_mask_i32gather_epi64(SRC, BASE, INDEX, MASK, SCALE)\t  \t\\\n+  (__m128i) __builtin_ia32_gathersiv2di ((__v2di)(__m128i) (SRC),\t\\\n+\t\t\t\t\t (long long const *) (BASE),\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v2di)(__m128i) (MASK),\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm256_i32gather_epi64(BASE, INDEX, SCALE)\t\t\t   \\\n   (__m256i) __builtin_ia32_gathersiv4di ((__v4di) _mm256_setzero_si256 (), \\\n-\t\t\t\t\t (long long const *)BASE,\t   \\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX,\t   \\\n+\t\t\t\t\t (long long const *) (BASE),\t   \\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t   \\\n \t\t\t\t\t (__v4di)_mm256_set1_epi64x (-1),  \\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (int) (SCALE))\n \n-#define _mm256_mask_i32gather_epi64(SRC, BASE, INDEX, MASK, SCALE) \\\n-  (__m256i) __builtin_ia32_gathersiv4di ((__v4di)(__m256i)SRC,\t   \\\n-\t\t\t\t\t (long long const *)BASE,  \\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX,   \\\n-\t\t\t\t\t (__v4di)(__m256i)MASK,\t   \\\n-\t\t\t\t\t (int)SCALE)\n+#define _mm256_mask_i32gather_epi64(SRC, BASE, INDEX, MASK, SCALE)\t\\\n+  (__m256i) __builtin_ia32_gathersiv4di ((__v4di)(__m256i) (SRC),\t\\\n+\t\t\t\t\t (long long const *) (BASE),\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v4di)(__m256i) (MASK),\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm_i64gather_epi64(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128i) __builtin_ia32_gatherdiv2di ((__v2di) _mm_setzero_si128 (), \\\n-\t\t\t\t\t (long long const *)BASE,\t\\\n-\t\t\t\t\t (__v2di)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (long long const *) (BASE),\t\\\n+\t\t\t\t\t (__v2di)(__m128i) (INDEX),\t\\\n \t\t\t\t\t (__v2di)_mm_set1_epi64x (-1),\t\\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (int) (SCALE))\n \n-#define _mm_mask_i64gather_epi64(SRC, BASE, INDEX, MASK, SCALE)\t  \\\n-  (__m128i) __builtin_ia32_gatherdiv2di ((__v2di)(__m128i)SRC,\t  \\\n-\t\t\t\t\t (long long const *)BASE, \\\n-\t\t\t\t\t (__v2di)(__m128i)INDEX,  \\\n-\t\t\t\t\t (__v2di)(__m128i)MASK,\t  \\\n-\t\t\t\t\t (int)SCALE)\n+#define _mm_mask_i64gather_epi64(SRC, BASE, INDEX, MASK, SCALE)\t\t\\\n+  (__m128i) __builtin_ia32_gatherdiv2di ((__v2di)(__m128i) (SRC),\t\\\n+\t\t\t\t\t (long long const *) (BASE),\t\\\n+\t\t\t\t\t (__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__v2di)(__m128i) (MASK),\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm256_i64gather_epi64(BASE, INDEX, SCALE)\t\t\t   \\\n   (__m256i) __builtin_ia32_gatherdiv4di ((__v4di) _mm256_setzero_si256 (), \\\n-\t\t\t\t\t (long long const *)BASE,\t   \\\n-\t\t\t\t\t (__v4di)(__m256i)INDEX,\t   \\\n+\t\t\t\t\t (long long const *) (BASE),\t   \\\n+\t\t\t\t\t (__v4di)(__m256i) (INDEX),\t   \\\n \t\t\t\t\t (__v4di)_mm256_set1_epi64x (-1),  \\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (int) (SCALE))\n \n-#define _mm256_mask_i64gather_epi64(SRC, BASE, INDEX, MASK, SCALE) \\\n-  (__m256i) __builtin_ia32_gatherdiv4di ((__v4di)(__m256i)SRC,\t   \\\n-\t\t\t\t\t (long long const *)BASE,  \\\n-\t\t\t\t\t (__v4di)(__m256i)INDEX,   \\\n-\t\t\t\t\t (__v4di)(__m256i)MASK,\t   \\\n-\t\t\t\t\t (int)SCALE)\n+#define _mm256_mask_i64gather_epi64(SRC, BASE, INDEX, MASK, SCALE) \t\\\n+  (__m256i) __builtin_ia32_gatherdiv4di ((__v4di)(__m256i) (SRC),\t\\\n+\t\t\t\t\t (long long const *) (BASE),\t\\\n+\t\t\t\t\t (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__v4di)(__m256i) (MASK),\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm_i32gather_epi32(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128i) __builtin_ia32_gathersiv4si ((__v4si) _mm_setzero_si128 (),\t\\\n-\t\t\t\t\t (int const *)BASE,\t\t\\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (int const *) (BASE),\t\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n \t\t\t\t\t (__v4si)_mm_set1_epi32 (-1),\t\\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (int) (SCALE))\n \n-#define _mm_mask_i32gather_epi32(SRC, BASE, INDEX, MASK, SCALE) \\\n-  (__m128i) __builtin_ia32_gathersiv4si ((__v4si)(__m128i)SRC,\t\\\n-\t\t\t\t\t(int const *)BASE,\t\\\n-\t\t\t\t\t(__v4si)(__m128i)INDEX, \\\n-\t\t\t\t\t(__v4si)(__m128i)MASK,\t\\\n-\t\t\t\t\t(int)SCALE)\n+#define _mm_mask_i32gather_epi32(SRC, BASE, INDEX, MASK, SCALE)\t\t\\\n+  (__m128i) __builtin_ia32_gathersiv4si ((__v4si)(__m128i) (SRC),\t\\\n+\t\t\t\t\t(int const *) (BASE),\t\t\\\n+\t\t\t\t\t(__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t(__v4si)(__m128i) (MASK),\t\\\n+\t\t\t\t\t(int) (SCALE))\n \n #define _mm256_i32gather_epi32(BASE, INDEX, SCALE)\t\t\t   \\\n   (__m256i) __builtin_ia32_gathersiv8si ((__v8si) _mm256_setzero_si256 (), \\\n-\t\t\t\t\t (int const *)BASE,\t\t   \\\n-\t\t\t\t\t (__v8si)(__m256i)INDEX,\t   \\\n+\t\t\t\t\t (int const *) (BASE),\t\t   \\\n+\t\t\t\t\t (__v8si)(__m256i) (INDEX),\t   \\\n \t\t\t\t\t (__v8si)_mm256_set1_epi32 (-1),   \\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (int) (SCALE))\n \n-#define _mm256_mask_i32gather_epi32(SRC, BASE, INDEX, MASK, SCALE) \\\n-  (__m256i) __builtin_ia32_gathersiv8si ((__v8si)(__m256i)SRC,\t   \\\n-\t\t\t\t\t(int const *)BASE,\t   \\\n-\t\t\t\t\t(__v8si)(__m256i)INDEX,\t   \\\n-\t\t\t\t\t(__v8si)(__m256i)MASK,\t   \\\n-\t\t\t\t\t(int)SCALE)\n+#define _mm256_mask_i32gather_epi32(SRC, BASE, INDEX, MASK, SCALE)\t\\\n+  (__m256i) __builtin_ia32_gathersiv8si ((__v8si)(__m256i) (SRC),\t\\\n+\t\t\t\t\t(int const *) (BASE),\t   \t\\\n+\t\t\t\t\t(__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t(__v8si)(__m256i) (MASK),\t\\\n+\t\t\t\t\t(int) (SCALE))\n \n #define _mm_i64gather_epi32(BASE, INDEX, SCALE)\t\t\t\t\\\n   (__m128i) __builtin_ia32_gatherdiv4si ((__v4si) _mm_setzero_si128 (),\t\\\n-\t\t\t\t\t (int const *)BASE,\t\t\\\n-\t\t\t\t\t (__v2di)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (int const *) (BASE),\t\t\\\n+\t\t\t\t\t (__v2di)(__m128i) (INDEX),\t\\\n \t\t\t\t\t (__v4si)_mm_set1_epi32 (-1),\t\\\n-\t\t\t\t\t (int)SCALE)\n+\t\t\t\t\t (int) (SCALE))\n \n-#define _mm_mask_i64gather_epi32(SRC, BASE, INDEX, MASK, SCALE) \\\n-  (__m128i) __builtin_ia32_gatherdiv4si ((__v4si)(__m128i)SRC,\t\\\n-\t\t\t\t\t(int const *)BASE,\t\\\n-\t\t\t\t\t(__v2di)(__m128i)INDEX, \\\n-\t\t\t\t\t(__v4si)(__m128i)MASK,\t\\\n-\t\t\t\t\t(int)SCALE)\n+#define _mm_mask_i64gather_epi32(SRC, BASE, INDEX, MASK, SCALE)\t\t\\\n+  (__m128i) __builtin_ia32_gatherdiv4si ((__v4si)(__m128i) (SRC),\t\\\n+\t\t\t\t\t(int const *) (BASE),\t\t\\\n+\t\t\t\t\t(__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t(__v4si)(__m128i) (MASK),\t\\\n+\t\t\t\t\t(int) (SCALE))\n \n #define _mm256_i64gather_epi32(BASE, INDEX, SCALE)\t\t\t   \\\n   (__m128i) __builtin_ia32_gatherdiv4si256 ((__v4si) _mm_setzero_si128 (), \\\n-\t\t\t\t\t    (int const *)BASE,\t\t   \\\n-\t\t\t\t\t    (__v4di)(__m256i)INDEX,\t   \\\n+\t\t\t\t\t    (int const *) (BASE),\t   \\\n+\t\t\t\t\t    (__v4di)(__m256i) (INDEX),\t   \\\n \t\t\t\t\t    (__v4si)_mm_set1_epi32(-1),\t   \\\n-\t\t\t\t\t    (int)SCALE)\n-\n-#define _mm256_mask_i64gather_epi32(SRC, BASE, INDEX, MASK, SCALE) \\\n-  (__m128i) __builtin_ia32_gatherdiv4si256 ((__v4si)(__m128i)SRC,  \\\n-\t\t\t\t\t   (int const *)BASE,\t   \\\n-\t\t\t\t\t   (__v4di)(__m256i)INDEX, \\\n-\t\t\t\t\t   (__v4si)(__m128i)MASK,  \\\n-\t\t\t\t\t   (int)SCALE)\n+\t\t\t\t\t    (int) (SCALE))\n+\n+#define _mm256_mask_i64gather_epi32(SRC, BASE, INDEX, MASK, SCALE)\t\\\n+  (__m128i) __builtin_ia32_gatherdiv4si256 ((__v4si)(__m128i) (SRC),\t\\\n+\t\t\t\t\t   (int const *) (BASE),\t\\\n+\t\t\t\t\t   (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t   (__v4si)(__m128i) (MASK),\t\\\n+\t\t\t\t\t   (int) (SCALE))\n #endif  /* __OPTIMIZE__ */\n \n #ifdef __DISABLE_AVX2__"}, {"sha": "c86982ab9c8bcac3f0cd5fe41f5b851c2d3710c2", "filename": "gcc/config/i386/avx512fintrin.h", "status": "modified", "additions": 120, "deletions": 110, "changes": 230, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2Fconfig%2Fi386%2Favx512fintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2Fconfig%2Fi386%2Favx512fintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512fintrin.h?ref=78cef09019cc9c80d1b39a49861f8827a2ee2e60", "patch": "@@ -10468,179 +10468,189 @@ _mm512_mask_i64scatter_epi64 (void *__addr, __mmask8 __mask,\n #else\n #define _mm512_i32gather_ps(INDEX, ADDR, SCALE)\t\t\t\t\\\n   (__m512) __builtin_ia32_gathersiv16sf ((__v16sf)_mm512_undefined_ps(),\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v16si)(__m512i)INDEX,\t\\\n-\t\t\t\t\t (__mmask16)0xFFFF, (int)SCALE)\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v16si)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask16)0xFFFF,\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm512_mask_i32gather_ps(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m512) __builtin_ia32_gathersiv16sf ((__v16sf)(__m512)V1OLD,\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v16si)(__m512i)INDEX,\t\\\n-\t\t\t\t\t (__mmask16)MASK, (int)SCALE)\n+  (__m512) __builtin_ia32_gathersiv16sf ((__v16sf)(__m512) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v16si)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask16) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm512_i32gather_pd(INDEX, ADDR, SCALE)\t\t\t\t\\\n   (__m512d) __builtin_ia32_gathersiv8df ((__v8df)_mm512_undefined_pd(),\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8si)(__m256i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)0xFF, (int)SCALE)\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8)0xFF, (int) (SCALE))\n \n #define _mm512_mask_i32gather_pd(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m512d) __builtin_ia32_gathersiv8df ((__v8df)(__m512d)V1OLD,\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8si)(__m256i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n+  (__m512d) __builtin_ia32_gathersiv8df ((__v8df)(__m512d) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm512_i64gather_ps(INDEX, ADDR, SCALE)\t\t\t\t\\\n   (__m256) __builtin_ia32_gatherdiv16sf ((__v8sf)_mm256_undefined_ps(),\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8di)(__m512i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)0xFF, (int)SCALE)\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8di)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8)0xFF, (int) (SCALE))\n \n #define _mm512_mask_i64gather_ps(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m256) __builtin_ia32_gatherdiv16sf ((__v8sf)(__m256)V1OLD,\t\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8di)(__m512i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n+  (__m256) __builtin_ia32_gatherdiv16sf ((__v8sf)(__m256) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8di)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm512_i64gather_pd(INDEX, ADDR, SCALE)\t\t\t\t\\\n   (__m512d) __builtin_ia32_gatherdiv8df ((__v8df)_mm512_undefined_pd(),\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8di)(__m512i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)0xFF, (int)SCALE)\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8di)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8)0xFF, (int) (SCALE))\n \n #define _mm512_mask_i64gather_pd(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m512d) __builtin_ia32_gatherdiv8df ((__v8df)(__m512d)V1OLD,\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8di)(__m512i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n+  (__m512d) __builtin_ia32_gatherdiv8df ((__v8df)(__m512d) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8di)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm512_i32gather_epi32(INDEX, ADDR, SCALE)\t\t\t\\\n-  (__m512i) __builtin_ia32_gathersiv16si ((__v16si)_mm512_undefined_epi32 (),\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v16si)(__m512i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask16)0xFFFF, (int)SCALE)\n+  (__m512i) __builtin_ia32_gathersiv16si ((__v16si)_mm512_undefined_epi32 (),\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v16si)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask16)0xFFFF,\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm512_mask_i32gather_epi32(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m512i) __builtin_ia32_gathersiv16si ((__v16si)(__m512i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v16si)(__m512i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask16)MASK, (int)SCALE)\n+  (__m512i) __builtin_ia32_gathersiv16si ((__v16si)(__m512i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v16si)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask16) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm512_i32gather_epi64(INDEX, ADDR, SCALE)\t\t\t\\\n-  (__m512i) __builtin_ia32_gathersiv8di ((__v8di)_mm512_undefined_epi32 (),\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8si)(__m256i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)0xFF, (int)SCALE)\n+  (__m512i) __builtin_ia32_gathersiv8di ((__v8di)_mm512_undefined_epi32 (),\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8)0xFF, (int) (SCALE))\n \n #define _mm512_mask_i32gather_epi64(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m512i) __builtin_ia32_gathersiv8di ((__v8di)(__m512i)V1OLD,\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8si)(__m256i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n-\n-#define _mm512_i64gather_epi32(INDEX, ADDR, SCALE)\t\t\t  \\\n-  (__m256i) __builtin_ia32_gatherdiv16si ((__v8si)_mm256_undefined_si256(), \\\n-\t\t\t\t\t  (void const *)ADDR,\t\t  \\\n-\t\t\t\t\t  (__v8di)(__m512i)INDEX,\t  \\\n-\t\t\t\t\t  (__mmask8)0xFF, (int)SCALE)\n+  (__m512i) __builtin_ia32_gathersiv8di ((__v8di)(__m512i) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n+\n+#define _mm512_i64gather_epi32(INDEX, ADDR, SCALE)\t\t\t   \\\n+  (__m256i) __builtin_ia32_gatherdiv16si ((__v8si)_mm256_undefined_si256(),\\\n+\t\t\t\t\t  (void const *) (ADDR),\t   \\\n+\t\t\t\t\t  (__v8di)(__m512i) (INDEX),\t   \\\n+\t\t\t\t\t  (__mmask8)0xFF, (int) (SCALE))\n \n #define _mm512_mask_i64gather_epi32(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m256i) __builtin_ia32_gatherdiv16si ((__v8si)(__m256i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v8di)(__m512i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m256i) __builtin_ia32_gatherdiv16si ((__v8si)(__m256i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v8di)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm512_i64gather_epi64(INDEX, ADDR, SCALE)\t\t\t\\\n-  (__m512i) __builtin_ia32_gatherdiv8di ((__v8di)_mm512_undefined_epi32 (),\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8di)(__m512i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)0xFF, (int)SCALE)\n+  (__m512i) __builtin_ia32_gatherdiv8di ((__v8di)_mm512_undefined_epi32 (),\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8di)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8)0xFF, (int) (SCALE))\n \n #define _mm512_mask_i64gather_epi64(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m512i) __builtin_ia32_gatherdiv8di ((__v8di)(__m512i)V1OLD,\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8di)(__m512i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n+  (__m512i) __builtin_ia32_gatherdiv8di ((__v8di)(__m512i) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8di)(__m512i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm512_i32scatter_ps(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv16sf ((void *)ADDR, (__mmask16)0xFFFF,\t\\\n-\t\t\t\t (__v16si)(__m512i)INDEX,\t\t\\\n-\t\t\t\t (__v16sf)(__m512)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv16sf ((void *) (ADDR), (__mmask16)0xFFFF,\t\\\n+\t\t\t\t (__v16si)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t (__v16sf)(__m512) (V1), (int) (SCALE))\n \n #define _mm512_mask_i32scatter_ps(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scattersiv16sf ((void *)ADDR, (__mmask16)MASK,\t\t\\\n-\t\t\t\t (__v16si)(__m512i)INDEX,\t\t\\\n-\t\t\t\t (__v16sf)(__m512)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv16sf ((void *) (ADDR), (__mmask16) (MASK),\t\\\n+\t\t\t\t (__v16si)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t (__v16sf)(__m512) (V1), (int) (SCALE))\n \n #define _mm512_i32scatter_pd(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv8df ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v8si)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8df)(__m512d)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv8df ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v8si)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v8df)(__m512d) (V1), (int) (SCALE))\n \n #define _mm512_mask_i32scatter_pd(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scattersiv8df ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v8si)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8df)(__m512d)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv8df ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v8si)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v8df)(__m512d) (V1), (int) (SCALE))\n \n #define _mm512_i64scatter_ps(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv16sf ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t (__v8di)(__m512i)INDEX,\t\t\\\n-\t\t\t\t (__v8sf)(__m256)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv16sf ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t (__v8di)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t (__v8sf)(__m256) (V1), (int) (SCALE))\n \n #define _mm512_mask_i64scatter_ps(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scatterdiv16sf ((void *)ADDR, (__mmask16)MASK,\t\t\\\n-\t\t\t\t (__v8di)(__m512i)INDEX,\t\t\\\n-\t\t\t\t (__v8sf)(__m256)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv16sf ((void *) (ADDR), (__mmask16) (MASK),\t\\\n+\t\t\t\t (__v8di)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t (__v8sf)(__m256) (V1), (int) (SCALE))\n \n #define _mm512_i64scatter_pd(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv8df ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v8di)(__m512i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8df)(__m512d)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv8df ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v8di)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t(__v8df)(__m512d) (V1), (int) (SCALE))\n \n #define _mm512_mask_i64scatter_pd(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scatterdiv8df ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v8di)(__m512i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8df)(__m512d)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv8df ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v8di)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t(__v8df)(__m512d) (V1), (int) (SCALE))\n \n #define _mm512_i32scatter_epi32(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv16si ((void *)ADDR, (__mmask16)0xFFFF,\t\\\n-\t\t\t\t (__v16si)(__m512i)INDEX,\t\t\\\n-\t\t\t\t (__v16si)(__m512i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv16si ((void *) (ADDR), (__mmask16)0xFFFF,\t\\\n+\t\t\t\t (__v16si)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t (__v16si)(__m512i) (V1), (int) (SCALE))\n \n #define _mm512_mask_i32scatter_epi32(ADDR, MASK, INDEX, V1, SCALE)\t\\\n-  __builtin_ia32_scattersiv16si ((void *)ADDR, (__mmask16)MASK,\t\t\\\n-\t\t\t\t (__v16si)(__m512i)INDEX,\t\t\\\n-\t\t\t\t (__v16si)(__m512i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv16si ((void *) (ADDR), (__mmask16) (MASK),\t\\\n+\t\t\t\t (__v16si)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t (__v16si)(__m512i) (V1), (int) (SCALE))\n \n #define _mm512_i32scatter_epi64(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv8di ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v8si)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8di)(__m512i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv8di ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v8si)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v8di)(__m512i) (V1), (int) (SCALE))\n \n #define _mm512_mask_i32scatter_epi64(ADDR, MASK, INDEX, V1, SCALE)\t\\\n-  __builtin_ia32_scattersiv8di ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v8si)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8di)(__m512i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv8di ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v8si)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v8di)(__m512i) (V1), (int) (SCALE))\n \n #define _mm512_i64scatter_epi32(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv16si ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t (__v8di)(__m512i)INDEX,\t\t\\\n-\t\t\t\t (__v8si)(__m256i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv16si ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t (__v8di)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t (__v8si)(__m256i) (V1), (int) (SCALE))\n \n #define _mm512_mask_i64scatter_epi32(ADDR, MASK, INDEX, V1, SCALE)\t\\\n-  __builtin_ia32_scatterdiv16si ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t (__v8di)(__m512i)INDEX,\t\t\\\n-\t\t\t\t (__v8si)(__m256i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv16si ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t (__v8di)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t (__v8si)(__m256i) (V1), (int) (SCALE))\n \n #define _mm512_i64scatter_epi64(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv8di ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v8di)(__m512i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8di)(__m512i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv8di ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v8di)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t(__v8di)(__m512i) (V1), (int) (SCALE))\n \n #define _mm512_mask_i64scatter_epi64(ADDR, MASK, INDEX, V1, SCALE)\t\\\n-  __builtin_ia32_scatterdiv8di ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v8di)(__m512i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8di)(__m512i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv8di ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v8di)(__m512i) (INDEX),\t\t\\\n+\t\t\t\t(__v8di)(__m512i) (V1), (int) (SCALE))\n #endif\n \n extern __inline __m512d"}, {"sha": "6227039fea3f066994072b01dad5aa0d81d590d5", "filename": "gcc/config/i386/avx512pfintrin.h", "status": "modified", "additions": 37, "deletions": 32, "changes": 69, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2Fconfig%2Fi386%2Favx512pfintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2Fconfig%2Fi386%2Favx512pfintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512pfintrin.h?ref=78cef09019cc9c80d1b39a49861f8827a2ee2e60", "patch": "@@ -192,68 +192,73 @@ _mm512_mask_prefetch_i64scatter_ps (void *__addr, __mmask8 __mask,\n \n #else\n #define _mm512_prefetch_i32gather_pd(INDEX, ADDR, SCALE, HINT)\t\t     \\\n-  __builtin_ia32_gatherpfdpd ((__mmask8)0xFF, (__v8si)(__m256i)INDEX,\t     \\\n-\t\t\t      (void const *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_gatherpfdpd ((__mmask8)0xFF, (__v8si)(__m256i) (INDEX),     \\\n+\t\t\t      (void const *) (ADDR), (int) (SCALE),\t     \\\n+\t\t\t      (int) (HINT))\n \n #define _mm512_prefetch_i32gather_ps(INDEX, ADDR, SCALE, HINT)\t\t     \\\n-  __builtin_ia32_gatherpfdps ((__mmask16)0xFFFF, (__v16si)(__m512i)INDEX,    \\\n-\t\t\t      (void const *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_gatherpfdps ((__mmask16)0xFFFF, (__v16si)(__m512i) (INDEX), \\\n+\t\t\t      (void const *) (ADDR), (int) (SCALE),\t     \\\n+\t\t\t      (int) (HINT))\n \n #define _mm512_mask_prefetch_i32gather_pd(INDEX, MASK, ADDR, SCALE, HINT)    \\\n-  __builtin_ia32_gatherpfdpd ((__mmask8)MASK, (__v8si)(__m256i)INDEX,\t     \\\n-\t\t\t      (void const *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_gatherpfdpd ((__mmask8) (MASK), (__v8si)(__m256i) (INDEX),  \\\n+\t\t\t      (void const *) (ADDR), (int) (SCALE),\t     \\\n+\t\t\t      (int) (HINT))\n \n #define _mm512_mask_prefetch_i32gather_ps(INDEX, MASK, ADDR, SCALE, HINT)    \\\n-  __builtin_ia32_gatherpfdps ((__mmask16)MASK, (__v16si)(__m512i)INDEX,      \\\n-\t\t\t      (void const *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_gatherpfdps ((__mmask16) (MASK), (__v16si)(__m512i) (INDEX),\\\n+\t\t\t      (void const *) (ADDR), (int) (SCALE),\t     \\\n+\t\t\t      (int) (HINT))\n \n #define _mm512_prefetch_i64gather_pd(INDEX, ADDR, SCALE, HINT)\t\t     \\\n-  __builtin_ia32_gatherpfqpd ((__mmask8)0xFF, (__v8di)(__m512i)INDEX,\t     \\\n-\t\t\t      (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_gatherpfqpd ((__mmask8)0xFF, (__v8di)(__m512i) (INDEX),     \\\n+\t\t\t      (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_prefetch_i64gather_ps(INDEX, ADDR, SCALE, HINT)\t\t     \\\n-  __builtin_ia32_gatherpfqps ((__mmask8)0xFF, (__v8di)(__m512i)INDEX,\t     \\\n-\t\t\t      (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_gatherpfqps ((__mmask8)0xFF, (__v8di)(__m512i) (INDEX),     \\\n+\t\t\t      (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_mask_prefetch_i64gather_pd(INDEX, MASK, ADDR, SCALE, HINT)    \\\n-  __builtin_ia32_gatherpfqpd ((__mmask8)MASK, (__v8di)(__m512i)INDEX,\t     \\\n-\t\t\t      (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_gatherpfqpd ((__mmask8) (MASK), (__v8di)(__m512i) (INDEX),  \\\n+\t\t\t      (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_mask_prefetch_i64gather_ps(INDEX, MASK, ADDR, SCALE, HINT)    \\\n-  __builtin_ia32_gatherpfqps ((__mmask8)MASK, (__v8di)(__m512i)INDEX,\t     \\\n-\t\t\t      (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_gatherpfqps ((__mmask8) (MASK), (__v8di)(__m512i) (INDEX),  \\\n+\t\t\t      (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_prefetch_i32scatter_pd(ADDR, INDEX, SCALE, HINT)              \\\n-  __builtin_ia32_scatterpfdpd ((__mmask8)0xFF, (__v8si)(__m256i)INDEX,       \\\n-\t\t\t       (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_scatterpfdpd ((__mmask8)0xFF, (__v8si)(__m256i) (INDEX),    \\\n+\t\t\t       (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_prefetch_i32scatter_ps(ADDR, INDEX, SCALE, HINT)              \\\n-  __builtin_ia32_scatterpfdps ((__mmask16)0xFFFF, (__v16si)(__m512i)INDEX,   \\\n-\t\t\t       (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_scatterpfdps ((__mmask16)0xFFFF, (__v16si)(__m512i) (INDEX),\\\n+\t\t\t       (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_mask_prefetch_i32scatter_pd(ADDR, MASK, INDEX, SCALE, HINT)   \\\n-  __builtin_ia32_scatterpfdpd ((__mmask8)MASK, (__v8si)(__m256i)INDEX,       \\\n-\t\t\t       (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_scatterpfdpd ((__mmask8) (MASK), (__v8si)(__m256i) (INDEX), \\\n+\t\t\t       (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_mask_prefetch_i32scatter_ps(ADDR, MASK, INDEX, SCALE, HINT)   \\\n-  __builtin_ia32_scatterpfdps ((__mmask16)MASK, (__v16si)(__m512i)INDEX,     \\\n-\t\t\t       (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_scatterpfdps ((__mmask16) (MASK),\t\t\t     \\\n+\t\t\t       (__v16si)(__m512i) (INDEX),\t\t     \\\n+\t\t\t       (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_prefetch_i64scatter_pd(ADDR, INDEX, SCALE, HINT)              \\\n-  __builtin_ia32_scatterpfqpd ((__mmask8)0xFF, (__v8di)(__m512i)INDEX,\t     \\\n-\t\t\t       (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_scatterpfqpd ((__mmask8)0xFF, (__v8di)(__m512i) (INDEX),    \\\n+\t\t\t       (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_prefetch_i64scatter_ps(ADDR, INDEX, SCALE, HINT)              \\\n-  __builtin_ia32_scatterpfqps ((__mmask8)0xFF, (__v8di)(__m512i)INDEX,\t     \\\n-\t\t\t       (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_scatterpfqps ((__mmask8)0xFF, (__v8di)(__m512i) (INDEX),    \\\n+\t\t\t       (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_mask_prefetch_i64scatter_pd(ADDR, MASK, INDEX, SCALE, HINT)   \\\n-  __builtin_ia32_scatterpfqpd ((__mmask8)MASK, (__v8di)(__m512i)INDEX,\t     \\\n-\t\t\t       (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_scatterpfqpd ((__mmask8) (MASK), (__v8di)(__m512i) (INDEX), \\\n+\t\t\t       (void *) (ADDR), (int) (SCALE), (int) (HINT))\n \n #define _mm512_mask_prefetch_i64scatter_ps(ADDR, MASK, INDEX, SCALE, HINT)   \\\n-  __builtin_ia32_scatterpfqps ((__mmask8)MASK, (__v8di)(__m512i)INDEX,\t     \\\n-\t\t\t       (void *)ADDR, (int)SCALE, (int)HINT)\n+  __builtin_ia32_scatterpfqps ((__mmask8) (MASK), (__v8di)(__m512i) (INDEX), \\\n+\t\t\t       (void *) (ADDR), (int) (SCALE), (int) (HINT))\n #endif\n \n #ifdef __DISABLE_AVX512PF__"}, {"sha": "7685bdfa391cb7a7965925e1dc04a4389c31fe35", "filename": "gcc/config/i386/avx512vlintrin.h", "status": "modified", "additions": 176, "deletions": 160, "changes": 336, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2Fconfig%2Fi386%2Favx512vlintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/78cef09019cc9c80d1b39a49861f8827a2ee2e60/gcc%2Fconfig%2Fi386%2Favx512vlintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512vlintrin.h?ref=78cef09019cc9c80d1b39a49861f8827a2ee2e60", "patch": "@@ -13000,260 +13000,276 @@ _mm256_permutex_pd (__m256d __X, const int __M)\n                                           (__mmask8)(U)))\n \n #define _mm256_mmask_i32gather_ps(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m256) __builtin_ia32_gather3siv8sf ((__v8sf)(__m256)V1OLD,\t\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v8si)(__m256i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n+  (__m256) __builtin_ia32_gather3siv8sf ((__v8sf)(__m256) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm_mmask_i32gather_ps(V1OLD, MASK, INDEX, ADDR, SCALE)\t\t\\\n-  (__m128) __builtin_ia32_gather3siv4sf ((__v4sf)(__m128)V1OLD,\t\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n+  (__m128) __builtin_ia32_gather3siv4sf ((__v4sf)(__m128) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm256_mmask_i32gather_pd(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m256d) __builtin_ia32_gather3siv4df ((__v4df)(__m256d)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v4si)(__m128i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m256d) __builtin_ia32_gather3siv4df ((__v4df)(__m256d) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm_mmask_i32gather_pd(V1OLD, MASK, INDEX, ADDR, SCALE)\t\t\\\n-  (__m128d) __builtin_ia32_gather3siv2df ((__v2df)(__m128d)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v4si)(__m128i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m128d) __builtin_ia32_gather3siv2df ((__v2df)(__m128d) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm256_mmask_i64gather_ps(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m128) __builtin_ia32_gather3div8sf ((__v4sf)(__m128)V1OLD,\t\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v4di)(__m256i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n+  (__m128) __builtin_ia32_gather3div8sf ((__v4sf)(__m128) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm_mmask_i64gather_ps(V1OLD, MASK, INDEX, ADDR, SCALE)\t\t\\\n-  (__m128) __builtin_ia32_gather3div4sf ((__v4sf)(__m128)V1OLD,\t\t\\\n-\t\t\t\t\t (void const *)ADDR,\t\t\\\n-\t\t\t\t\t (__v2di)(__m128i)INDEX,\t\\\n-\t\t\t\t\t (__mmask8)MASK, (int)SCALE)\n+  (__m128) __builtin_ia32_gather3div4sf ((__v4sf)(__m128) (V1OLD),\t\\\n+\t\t\t\t\t (void const *) (ADDR),\t\t\\\n+\t\t\t\t\t (__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t (int) (SCALE))\n \n #define _mm256_mmask_i64gather_pd(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m256d) __builtin_ia32_gather3div4df ((__v4df)(__m256d)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v4di)(__m256i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m256d) __builtin_ia32_gather3div4df ((__v4df)(__m256d) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm_mmask_i64gather_pd(V1OLD, MASK, INDEX, ADDR, SCALE)\t\t\\\n-  (__m128d) __builtin_ia32_gather3div2df ((__v2df)(__m128d)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v2di)(__m128i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m128d) __builtin_ia32_gather3div2df ((__v2df)(__m128d) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm256_mmask_i32gather_epi32(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m256i) __builtin_ia32_gather3siv8si ((__v8si)(__m256i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v8si)(__m256i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m256i) __builtin_ia32_gather3siv8si ((__v8si)(__m256i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v8si)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm_mmask_i32gather_epi32(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m128i) __builtin_ia32_gather3siv4si ((__v4si)(__m128i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v4si)(__m128i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m128i) __builtin_ia32_gather3siv4si ((__v4si)(__m128i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm256_mmask_i32gather_epi64(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m256i) __builtin_ia32_gather3siv4di ((__v4di)(__m256i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v4si)(__m128i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m256i) __builtin_ia32_gather3siv4di ((__v4di)(__m256i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm_mmask_i32gather_epi64(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m128i) __builtin_ia32_gather3siv2di ((__v2di)(__m128i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v4si)(__m128i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m128i) __builtin_ia32_gather3siv2di ((__v2di)(__m128i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v4si)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm256_mmask_i64gather_epi32(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m128i) __builtin_ia32_gather3div8si ((__v4si)(__m128i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v4di)(__m256i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m128i) __builtin_ia32_gather3div8si ((__v4si)(__m128i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm_mmask_i64gather_epi32(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m128i) __builtin_ia32_gather3div4si ((__v4si)(__m128i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v2di)(__m128i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m128i) __builtin_ia32_gather3div4si ((__v4si)(__m128i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm256_mmask_i64gather_epi64(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m256i) __builtin_ia32_gather3div4di ((__v4di)(__m256i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v4di)(__m256i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m256i) __builtin_ia32_gather3div4di ((__v4di)(__m256i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v4di)(__m256i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm_mmask_i64gather_epi64(V1OLD, MASK, INDEX, ADDR, SCALE)\t\\\n-  (__m128i) __builtin_ia32_gather3div2di ((__v2di)(__m128i)V1OLD,\t\\\n-\t\t\t\t\t  (void const *)ADDR,\t\t\\\n-\t\t\t\t\t  (__v2di)(__m128i)INDEX,\t\\\n-\t\t\t\t\t  (__mmask8)MASK, (int)SCALE)\n+  (__m128i) __builtin_ia32_gather3div2di ((__v2di)(__m128i) (V1OLD),\t\\\n+\t\t\t\t\t  (void const *) (ADDR),\t\\\n+\t\t\t\t\t  (__v2di)(__m128i) (INDEX),\t\\\n+\t\t\t\t\t  (__mmask8) (MASK),\t\t\\\n+\t\t\t\t\t  (int) (SCALE))\n \n #define _mm256_i32scatter_ps(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv8sf ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v8si)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8sf)(__m256)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv8sf ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v8si)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v8sf)(__m256) (V1), (int) (SCALE))\n \n #define _mm256_mask_i32scatter_ps(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scattersiv8sf ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v8si)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8sf)(__m256)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv8sf ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v8si)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v8sf)(__m256) (V1), (int) (SCALE))\n \n #define _mm_i32scatter_ps(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv4sf ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4sf)(__m128)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv4sf ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4sf)(__m128) (V1), (int) (SCALE))\n \n #define _mm_mask_i32scatter_ps(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scattersiv4sf ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4sf)(__m128)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv4sf ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4sf)(__m128) (V1), (int) (SCALE))\n \n #define _mm256_i32scatter_pd(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv4df ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4df)(__m256d)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv4df ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4df)(__m256d) (V1), (int) (SCALE))\n \n #define _mm256_mask_i32scatter_pd(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scattersiv4df ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4df)(__m256d)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv4df ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4df)(__m256d) (V1), (int) (SCALE))\n \n #define _mm_i32scatter_pd(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv2df ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v2df)(__m128d)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv2df ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v2df)(__m128d) (V1), (int) (SCALE))\n \n #define _mm_mask_i32scatter_pd(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scattersiv2df ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v2df)(__m128d)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv2df ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v2df)(__m128d) (V1), (int) (SCALE))\n \n #define _mm256_i64scatter_ps(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv8sf ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4di)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4sf)(__m128)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv8sf ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4di)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v4sf)(__m128) (V1), (int) (SCALE))\n \n #define _mm256_mask_i64scatter_ps(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scatterdiv8sf ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4di)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4sf)(__m128)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv8sf ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4di)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v4sf)(__m128) (V1), (int) (SCALE))\n \n #define _mm_i64scatter_ps(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv4sf ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4sf)(__m128)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv4sf ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v2di)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4sf)(__m128) (V1), (int) (SCALE))\n \n #define _mm_mask_i64scatter_ps(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scatterdiv4sf ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4sf)(__m128)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv4sf ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v2di)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4sf)(__m128) (V1), (int) (SCALE))\n \n #define _mm256_i64scatter_pd(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv4df ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4di)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4df)(__m256d)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv4df ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4di)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v4df)(__m256d) (V1), (int) (SCALE))\n \n #define _mm256_mask_i64scatter_pd(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scatterdiv4df ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4di)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4df)(__m256d)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv4df ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4di)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v4df)(__m256d) (V1), (int) (SCALE))\n \n #define _mm_i64scatter_pd(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv2df ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v2df)(__m128d)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv2df ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v2di)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v2df)(__m128d) (V1), (int) (SCALE))\n \n #define _mm_mask_i64scatter_pd(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scatterdiv2df ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v2df)(__m128d)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv2df ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v2di)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v2df)(__m128d) (V1), (int) (SCALE))\n \n #define _mm256_i32scatter_epi32(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv8si ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v8si)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8si)(__m256i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv8si ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v8si)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v8si)(__m256i) (V1), (int) (SCALE))\n \n #define _mm256_mask_i32scatter_epi32(ADDR, MASK, INDEX, V1, SCALE)\t\\\n-  __builtin_ia32_scattersiv8si ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v8si)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v8si)(__m256i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv8si ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v8si)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v8si)(__m256i) (V1), (int) (SCALE))\n \n #define _mm_i32scatter_epi32(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv4si ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4si)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv4si ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4si)(__m128i) (V1), (int) (SCALE))\n \n #define _mm_mask_i32scatter_epi32(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scattersiv4si ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4si)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv4si ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4si)(__m128i) (V1), (int) (SCALE))\n \n #define _mm256_i32scatter_epi64(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv4di ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4di)(__m256i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv4di ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4di)(__m256i) (V1), (int) (SCALE))\n \n #define _mm256_mask_i32scatter_epi64(ADDR, MASK, INDEX, V1, SCALE)\t\\\n-  __builtin_ia32_scattersiv4di ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4di)(__m256i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv4di ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4di)(__m256i) (V1), (int) (SCALE))\n \n #define _mm_i32scatter_epi64(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scattersiv2di ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v2di)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv2di ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v2di)(__m128i) (V1), (int) (SCALE))\n \n #define _mm_mask_i32scatter_epi64(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scattersiv2di ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v2di)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scattersiv2di ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4si)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v2di)(__m128i) (V1), (int) (SCALE))\n \n #define _mm256_i64scatter_epi32(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv8si ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4di)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4si)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv8si ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4di)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v4si)(__m128i) (V1), (int) (SCALE))\n \n #define _mm256_mask_i64scatter_epi32(ADDR, MASK, INDEX, V1, SCALE)\t\\\n-  __builtin_ia32_scatterdiv8si ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4di)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4si)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv8si ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4di)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v4si)(__m128i) (V1), (int) (SCALE))\n \n #define _mm_i64scatter_epi32(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv4si ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4si)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv4si ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v2di)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4si)(__m128i) (V1), (int) (SCALE))\n \n #define _mm_mask_i64scatter_epi32(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scatterdiv4si ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4si)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv4si ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v2di)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v4si)(__m128i) (V1), (int) (SCALE))\n \n #define _mm256_i64scatter_epi64(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv4di ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v4di)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4di)(__m256i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv4di ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v4di)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v4di)(__m256i) (V1), (int) (SCALE))\n \n #define _mm256_mask_i64scatter_epi64(ADDR, MASK, INDEX, V1, SCALE)\t\\\n-  __builtin_ia32_scatterdiv4di ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v4di)(__m256i)INDEX,\t\t\t\\\n-\t\t\t\t(__v4di)(__m256i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv4di ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v4di)(__m256i) (INDEX),\t\t\\\n+\t\t\t\t(__v4di)(__m256i) (V1), (int) (SCALE))\n \n #define _mm_i64scatter_epi64(ADDR, INDEX, V1, SCALE)\t\t\t\\\n-  __builtin_ia32_scatterdiv2di ((void *)ADDR, (__mmask8)0xFF,\t\t\\\n-\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v2di)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv2di ((void *) (ADDR), (__mmask8)0xFF,\t\\\n+\t\t\t\t(__v2di)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v2di)(__m128i) (V1), (int) (SCALE))\n \n #define _mm_mask_i64scatter_epi64(ADDR, MASK, INDEX, V1, SCALE)\t\t\\\n-  __builtin_ia32_scatterdiv2di ((void *)ADDR, (__mmask8)MASK,\t\t\\\n-\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\t\\\n-\t\t\t\t(__v2di)(__m128i)V1, (int)SCALE)\n+  __builtin_ia32_scatterdiv2di ((void *) (ADDR), (__mmask8) (MASK),\t\\\n+\t\t\t\t(__v2di)(__m128i) (INDEX),\t\t\\\n+\t\t\t\t(__v2di)(__m128i) (V1), (int) (SCALE))\n \n #define _mm256_mask_shuffle_epi32(W, U, X, C)                                       \\\n   ((__m256i)  __builtin_ia32_pshufd256_mask ((__v8si)(__m256i)(X), (int)(C),        \\"}]}