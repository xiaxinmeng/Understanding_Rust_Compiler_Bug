{"sha": "fdb904a1822c38db5d69a50878b21041c476f045", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZmRiOTA0YTE4MjJjMzhkYjVkNjlhNTA4NzhiMjEwNDFjNDc2ZjA0NQ==", "commit": {"author": {"name": "Kyrylo Tkachov", "email": "kyrylo.tkachov@arm.com", "date": "2021-01-22T14:16:30Z"}, "committer": {"name": "Kyrylo Tkachov", "email": "kyrylo.tkachov@arm.com", "date": "2021-01-28T11:42:20Z"}, "message": "aarch64: Reimplement vshrn_n* intrinsics using builtins\n\nThis patch reimplements the vshrn_n* intrinsics to use RTL builtins.\nThese perform a narrowing right shift.\n\nAlthough the intrinsic generates the half-width mode (e.g. V8HI ->\nV8QI), the new pattern generates a full 128-bit mode (V8HI -> V16QI) by representing the\nfill-with-zeroes semantics of the SHRN instruction. The narrower (V8QI) result is extracted with a\nlowpart subreg.\nI found this allows the RTL optimisers to do a better job at optimising\nredundant moves away in frequently-occurring SHRN+SRHN2 pairs, like in:\nuint8x16_t\nfoo (uint16x8_t in1, uint16x8_t in2)\n{\n  uint8x8_t tmp = vshrn_n_u16 (in2, 7);\n  uint8x16_t tmp2 = vshrn_high_n_u16 (tmp, in1, 4);\n  return tmp2;\n}\n\ngcc/ChangeLog:\n\n\t* config/aarch64/aarch64-simd-builtins.def (shrn): Define\n\tbuiltin.\n\t* config/aarch64/aarch64-simd.md (aarch64_shrn<mode>_insn_le):\n\tDefine.\n\t(aarch64_shrn<mode>_insn_be): Likewise.\n\t(aarch64_shrn<mode>): Likewise.\n\t* config/aarch64/arm_neon.h (vshrn_n_s16): Reimplement using\n\tbuiltins.\n\t(vshrn_n_s32): Likewise.\n\t(vshrn_n_s64): Likewise.\n\t(vshrn_n_u16): Likewise.\n\t(vshrn_n_u32): Likewise.\n\t(vshrn_n_u64): Likewise.\n\t* config/aarch64/iterators.md (vn_mode): New mode attribute.", "tree": {"sha": "069b5ee9963928cb913c37021fa5d5e7a43b9824", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/069b5ee9963928cb913c37021fa5d5e7a43b9824"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/fdb904a1822c38db5d69a50878b21041c476f045", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fdb904a1822c38db5d69a50878b21041c476f045", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fdb904a1822c38db5d69a50878b21041c476f045", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fdb904a1822c38db5d69a50878b21041c476f045/comments", "author": {"login": "ktkachov-arm", "id": 74917949, "node_id": "MDQ6VXNlcjc0OTE3OTQ5", "avatar_url": "https://avatars.githubusercontent.com/u/74917949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktkachov-arm", "html_url": "https://github.com/ktkachov-arm", "followers_url": "https://api.github.com/users/ktkachov-arm/followers", "following_url": "https://api.github.com/users/ktkachov-arm/following{/other_user}", "gists_url": "https://api.github.com/users/ktkachov-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktkachov-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktkachov-arm/subscriptions", "organizations_url": "https://api.github.com/users/ktkachov-arm/orgs", "repos_url": "https://api.github.com/users/ktkachov-arm/repos", "events_url": "https://api.github.com/users/ktkachov-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/ktkachov-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ktkachov-arm", "id": 74917949, "node_id": "MDQ6VXNlcjc0OTE3OTQ5", "avatar_url": "https://avatars.githubusercontent.com/u/74917949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktkachov-arm", "html_url": "https://github.com/ktkachov-arm", "followers_url": "https://api.github.com/users/ktkachov-arm/followers", "following_url": "https://api.github.com/users/ktkachov-arm/following{/other_user}", "gists_url": "https://api.github.com/users/ktkachov-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktkachov-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktkachov-arm/subscriptions", "organizations_url": "https://api.github.com/users/ktkachov-arm/orgs", "repos_url": "https://api.github.com/users/ktkachov-arm/repos", "events_url": "https://api.github.com/users/ktkachov-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/ktkachov-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f7a6d314e7f7eeb6240a4f62511c189c90ef300c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f7a6d314e7f7eeb6240a4f62511c189c90ef300c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f7a6d314e7f7eeb6240a4f62511c189c90ef300c"}], "stats": {"total": 169, "additions": 97, "deletions": 72}, "files": [{"sha": "13bc6928d4de83513bc9d92e9429fdff90565100", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/fdb904a1822c38db5d69a50878b21041c476f045/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/fdb904a1822c38db5d69a50878b21041c476f045/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=fdb904a1822c38db5d69a50878b21041c476f045", "patch": "@@ -188,6 +188,9 @@\n   /* Implemented by aarch64_mls_n<mode>.  */\n   BUILTIN_VDQHS (TERNOP, mls_n, 0, NONE)\n \n+  /* Implemented by aarch64_shrn<mode>\".  */\n+  BUILTIN_VQN (SHIFTIMM, shrn, 0, NONE)\n+\n   /* Implemented by aarch64_<su>mlsl<mode>.  */\n   BUILTIN_VD_BHSI (TERNOP, smlsl, 0, NONE)\n   BUILTIN_VD_BHSI (TERNOPU, umlsl, 0, NONE)"}, {"sha": "872aa83fc926dfa449223f6fdd116e1b2af436dd", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/fdb904a1822c38db5d69a50878b21041c476f045/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/fdb904a1822c38db5d69a50878b21041c476f045/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=fdb904a1822c38db5d69a50878b21041c476f045", "patch": "@@ -1679,6 +1679,56 @@\n   DONE;\n })\n \n+(define_insn \"aarch64_shrn<mode>_insn_le\"\n+  [(set (match_operand:<VNARROWQ2> 0 \"register_operand\" \"=w\")\n+\t(vec_concat:<VNARROWQ2>\n+\t  (truncate:<VNARROWQ>\n+\t    (lshiftrt:VQN (match_operand:VQN 1 \"register_operand\" \"w\")\n+\t\t  (match_operand:VQN 2 \"aarch64_simd_rshift_imm\")))\n+\t  (match_operand:<VNARROWQ> 3 \"aarch64_simd_or_scalar_imm_zero\")))]\n+  \"TARGET_SIMD && !BYTES_BIG_ENDIAN\"\n+  \"shrn\\\\t%0.<Vntype>, %1.<Vtype>, %2\"\n+  [(set_attr \"type\" \"neon_shift_imm_narrow_q\")]\n+)\n+\n+(define_insn \"aarch64_shrn<mode>_insn_be\"\n+  [(set (match_operand:<VNARROWQ2> 0 \"register_operand\" \"=w\")\n+\t(vec_concat:<VNARROWQ2>\n+\t  (match_operand:<VNARROWQ> 3 \"aarch64_simd_or_scalar_imm_zero\")\n+\t  (truncate:<VNARROWQ>\n+\t    (lshiftrt:VQN (match_operand:VQN 1 \"register_operand\" \"w\")\n+\t\t  (match_operand:VQN 2 \"aarch64_simd_rshift_imm\")))))]\n+  \"TARGET_SIMD && BYTES_BIG_ENDIAN\"\n+  \"shrn\\\\t%0.<Vntype>, %1.<Vtype>, %2\"\n+  [(set_attr \"type\" \"neon_shift_imm_narrow_q\")]\n+)\n+\n+(define_expand \"aarch64_shrn<mode>\"\n+  [(set (match_operand:<VNARROWQ> 0 \"register_operand\")\n+\t(truncate:<VNARROWQ>\n+\t  (lshiftrt:VQN (match_operand:VQN 1 \"register_operand\")\n+\t    (match_operand:SI 2 \"aarch64_simd_shift_imm_offset_<vn_mode>\"))))]\n+  \"TARGET_SIMD\"\n+  {\n+    operands[2] = aarch64_simd_gen_const_vector_dup (<MODE>mode,\n+\t\t\t\t\t\t INTVAL (operands[2]));\n+    rtx tmp = gen_reg_rtx (<VNARROWQ2>mode);\n+    if (BYTES_BIG_ENDIAN)\n+      emit_insn (gen_aarch64_shrn<mode>_insn_be (tmp, operands[1],\n+\t\t\t\toperands[2], CONST0_RTX (<VNARROWQ>mode)));\n+    else\n+      emit_insn (gen_aarch64_shrn<mode>_insn_le (tmp, operands[1],\n+\t\t\t\toperands[2], CONST0_RTX (<VNARROWQ>mode)));\n+\n+    /* The intrinsic expects a narrow result, so emit a subreg that will get\n+       optimized away as appropriate.  */\n+    emit_move_insn (operands[0], lowpart_subreg (<VNARROWQ>mode, tmp,\n+\t\t\t\t\t\t <VNARROWQ2>mode));\n+    DONE;\n+  }\n+)\n+\n+\n ;; For quads.\n \n (define_insn \"vec_pack_trunc_<mode>\""}, {"sha": "80d75555a71817637035bf25b3a5cccd87947242", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 41, "deletions": 72, "changes": 113, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/fdb904a1822c38db5d69a50878b21041c476f045/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/fdb904a1822c38db5d69a50878b21041c476f045/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=fdb904a1822c38db5d69a50878b21041c476f045", "patch": "@@ -8584,6 +8584,47 @@ vmovn_u64 (uint64x2_t __a)\n   return (uint32x2_t) __builtin_aarch64_xtnv2di ((int64x2_t) __a);\n }\n \n+__extension__ extern __inline int8x8_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_n_s16 (int16x8_t __a, const int __b)\n+{\n+  return __builtin_aarch64_shrnv8hi (__a, __b);\n+}\n+\n+__extension__ extern __inline int16x4_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_n_s32 (int32x4_t __a, const int __b)\n+{\n+  return __builtin_aarch64_shrnv4si (__a, __b);\n+}\n+\n+__extension__ extern __inline int32x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_n_s64 (int64x2_t __a, const int __b)\n+{\n+  return __builtin_aarch64_shrnv2di (__a, __b);\n+}\n+\n+__extension__ extern __inline uint8x8_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_n_u16 (uint16x8_t __a, const int __b)\n+{\n+  return (uint8x8_t)__builtin_aarch64_shrnv8hi ((int16x8_t)__a, __b);\n+}\n+\n+__extension__ extern __inline uint16x4_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_n_u32 (uint32x4_t __a, const int __b)\n+{\n+  return (uint16x4_t)__builtin_aarch64_shrnv4si ((int32x4_t)__a, __b);\n+}\n+\n+__extension__ extern __inline uint32x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n+vshrn_n_u64 (uint64x2_t __a, const int __b)\n+{\n+  return (uint32x2_t)__builtin_aarch64_shrnv2di ((int64x2_t)__a, __b);\n+}\n #define vmull_high_lane_s16(a, b, c)                                    \\\n   __extension__                                                         \\\n     ({                                                                  \\\n@@ -9858,78 +9899,6 @@ vrsqrteq_u32 (uint32x4_t __a)\n        result;                                                          \\\n      })\n \n-#define vshrn_n_s16(a, b)                                               \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x8_t a_ = (a);                                              \\\n-       int8x8_t result;                                                 \\\n-       __asm__ (\"shrn %0.8b,%1.8h,%2\"                                   \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"i\"(b)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vshrn_n_s32(a, b)                                               \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x4_t a_ = (a);                                              \\\n-       int16x4_t result;                                                \\\n-       __asm__ (\"shrn %0.4h,%1.4s,%2\"                                   \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"i\"(b)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vshrn_n_s64(a, b)                                               \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int64x2_t a_ = (a);                                              \\\n-       int32x2_t result;                                                \\\n-       __asm__ (\"shrn %0.2s,%1.2d,%2\"                                   \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"i\"(b)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vshrn_n_u16(a, b)                                               \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x8_t a_ = (a);                                             \\\n-       uint8x8_t result;                                                \\\n-       __asm__ (\"shrn %0.8b,%1.8h,%2\"                                   \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"i\"(b)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vshrn_n_u32(a, b)                                               \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x4_t a_ = (a);                                             \\\n-       uint16x4_t result;                                               \\\n-       __asm__ (\"shrn %0.4h,%1.4s,%2\"                                   \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"i\"(b)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vshrn_n_u64(a, b)                                               \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint64x2_t a_ = (a);                                             \\\n-       uint32x2_t result;                                               \\\n-       __asm__ (\"shrn %0.2s,%1.2d,%2\"                                   \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"i\"(b)                                       \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n #define vsli_n_p8(a, b, c)                                              \\\n   __extension__                                                         \\\n     ({                                                                  \\"}, {"sha": "7db343e1c995a0adf3811fe8be6a66aedb627b88", "filename": "gcc/config/aarch64/iterators.md", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/fdb904a1822c38db5d69a50878b21041c476f045/gcc%2Fconfig%2Faarch64%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/fdb904a1822c38db5d69a50878b21041c476f045/gcc%2Fconfig%2Faarch64%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fiterators.md?ref=fdb904a1822c38db5d69a50878b21041c476f045", "patch": "@@ -1458,6 +1458,9 @@\n \t\t\t   (QI   \"qi\") (HI    \"hi\")\n \t\t\t   (SI   \"si\")])\n \n+;; Like ve_mode but for the half-width modes.\n+(define_mode_attr vn_mode [(V8HI  \"qi\") (V4SI  \"hi\") (V2DI  \"si\")])\n+\n ;; Vm for lane instructions is restricted to FP_LO_REGS.\n (define_mode_attr vwx [(V4HI \"x\") (V8HI \"x\") (HI \"x\")\n \t\t       (V2SI \"w\") (V4SI \"w\") (SI \"w\")])"}]}