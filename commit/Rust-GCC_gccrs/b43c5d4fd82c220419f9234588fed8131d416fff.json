{"sha": "b43c5d4fd82c220419f9234588fed8131d416fff", "node_id": "C_kwDOANBUbNoAKGI0M2M1ZDRmZDgyYzIyMDQxOWY5MjM0NTg4ZmVkODEzMWQ0MTZmZmY", "commit": {"author": {"name": "Raiki Tamura", "email": "tamaron1203@gmail.com", "date": "2022-11-16T08:15:24Z"}, "committer": {"name": "Raiki Tamura", "email": "tamaron1203@gmail.com", "date": "2022-11-18T22:58:38Z"}, "message": "Improve lexer dump", "tree": {"sha": "c7de82082b75f16b15ec6a800f9025250ea512f9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c7de82082b75f16b15ec6a800f9025250ea512f9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b43c5d4fd82c220419f9234588fed8131d416fff", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b43c5d4fd82c220419f9234588fed8131d416fff", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b43c5d4fd82c220419f9234588fed8131d416fff", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b43c5d4fd82c220419f9234588fed8131d416fff/comments", "author": {"login": "tamaroning", "id": 20992019, "node_id": "MDQ6VXNlcjIwOTkyMDE5", "avatar_url": "https://avatars.githubusercontent.com/u/20992019?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tamaroning", "html_url": "https://github.com/tamaroning", "followers_url": "https://api.github.com/users/tamaroning/followers", "following_url": "https://api.github.com/users/tamaroning/following{/other_user}", "gists_url": "https://api.github.com/users/tamaroning/gists{/gist_id}", "starred_url": "https://api.github.com/users/tamaroning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tamaroning/subscriptions", "organizations_url": "https://api.github.com/users/tamaroning/orgs", "repos_url": "https://api.github.com/users/tamaroning/repos", "events_url": "https://api.github.com/users/tamaroning/events{/privacy}", "received_events_url": "https://api.github.com/users/tamaroning/received_events", "type": "User", "site_admin": false}, "committer": {"login": "tamaroning", "id": 20992019, "node_id": "MDQ6VXNlcjIwOTkyMDE5", "avatar_url": "https://avatars.githubusercontent.com/u/20992019?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tamaroning", "html_url": "https://github.com/tamaroning", "followers_url": "https://api.github.com/users/tamaroning/followers", "following_url": "https://api.github.com/users/tamaroning/following{/other_user}", "gists_url": "https://api.github.com/users/tamaroning/gists{/gist_id}", "starred_url": "https://api.github.com/users/tamaroning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tamaroning/subscriptions", "organizations_url": "https://api.github.com/users/tamaroning/orgs", "repos_url": "https://api.github.com/users/tamaroning/repos", "events_url": "https://api.github.com/users/tamaroning/events{/privacy}", "received_events_url": "https://api.github.com/users/tamaroning/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "716ae8d024dcddd5000f65fa5c7c0dbd9f03c869", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/716ae8d024dcddd5000f65fa5c7c0dbd9f03c869", "html_url": "https://github.com/Rust-GCC/gccrs/commit/716ae8d024dcddd5000f65fa5c7c0dbd9f03c869"}], "stats": {"total": 144, "additions": 72, "deletions": 72}, "files": [{"sha": "ea17ecc731f36524e37ea5162ea0e9d207e7728f", "filename": "gcc/rust/lex/rust-lex.cc", "status": "modified", "additions": 44, "deletions": 3, "changes": 47, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Flex%2Frust-lex.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Flex%2Frust-lex.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-lex.cc?ref=b43c5d4fd82c220419f9234588fed8131d416fff", "patch": "@@ -118,13 +118,15 @@ is_non_decimal_int_literal_separator (char character)\n \n Lexer::Lexer (const std::string &input)\n   : input (RAIIFile::create_error ()), current_line (1), current_column (1),\n-    line_map (nullptr), raw_input_source (new BufferInputSource (input, 0)),\n+    line_map (nullptr), dump_lex_out (Optional<std::ofstream &>::none ()),\n+    raw_input_source (new BufferInputSource (input, 0)),\n     input_queue{*raw_input_source}, token_queue (TokenSource (this))\n {}\n \n-Lexer::Lexer (const char *filename, RAIIFile file_input, Linemap *linemap)\n+Lexer::Lexer (const char *filename, RAIIFile file_input, Linemap *linemap,\n+\t      Optional<std::ofstream &> dump_lex_opt)\n   : input (std::move (file_input)), current_line (1), current_column (1),\n-    line_map (linemap),\n+    line_map (linemap), dump_lex_out (dump_lex_opt),\n     raw_input_source (new FileInputSource (input.get_raw ())),\n     input_queue{*raw_input_source}, token_queue (TokenSource (this))\n {\n@@ -186,6 +188,45 @@ Lexer::skip_input ()\n   skip_input (0);\n }\n \n+void\n+Lexer::skip_token (int n)\n+{\n+  // dump tokens if dump-lex option is enabled\n+  if (dump_lex_out.is_some ())\n+    dump_and_skip (n);\n+  else\n+    token_queue.skip (n);\n+}\n+\n+void\n+Lexer::dump_and_skip (int n)\n+{\n+  std::ofstream &out = dump_lex_out.get ();\n+  bool found_eof = false;\n+  const_TokenPtr tok;\n+  for (int i = 0; i < n + 1; i++)\n+    {\n+      if (!found_eof)\n+\t{\n+\t  tok = peek_token ();\n+\t  found_eof |= tok->get_id () == Rust::END_OF_FILE;\n+\n+\t  Location loc = tok->get_locus ();\n+\n+\t  out << \"<id=\";\n+\t  out << tok->token_id_to_str ();\n+\t  out << (tok->has_str () ? (std::string (\", text=\") + tok->get_str ()\n+\t\t\t\t     + std::string (\", typehint=\")\n+\t\t\t\t     + std::string (tok->get_type_hint_str ()))\n+\t\t\t\t  : \"\")\n+\t      << \" \";\n+\t  out << get_line_map ()->to_string (loc) << \" \";\n+\t}\n+\n+      token_queue.skip (0);\n+    }\n+}\n+\n void\n Lexer::replace_current_token (TokenPtr replacement)\n {"}, {"sha": "c05e2678c3d4504fb574540917169699c21e547c", "filename": "gcc/rust/lex/rust-lex.h", "status": "modified", "additions": 10, "deletions": 2, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Flex%2Frust-lex.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Flex%2Frust-lex.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-lex.h?ref=b43c5d4fd82c220419f9234588fed8131d416fff", "patch": "@@ -22,6 +22,7 @@\n #include \"rust-linemap.h\"\n #include \"rust-buffered-queue.h\"\n #include \"rust-token.h\"\n+#include \"rust-optional.h\"\n \n namespace Rust {\n // Simple wrapper for FILE* that simplifies destruction.\n@@ -139,7 +140,9 @@ class Lexer\n \n public:\n   // Construct lexer with input file and filename provided\n-  Lexer (const char *filename, RAIIFile input, Linemap *linemap);\n+  Lexer (const char *filename, RAIIFile input, Linemap *linemap,\n+\t Optional<std::ofstream &> dump_lex_opt\n+\t = Optional<std::ofstream &>::none ());\n \n   // Lex the contents of a string instead of a file\n   Lexer (const std::string &input);\n@@ -161,10 +164,13 @@ class Lexer\n   const_TokenPtr peek_token () { return peek_token (0); }\n \n   // Advances current token to n + 1 tokens ahead of current position.\n-  void skip_token (int n) { token_queue.skip (n); }\n+  void skip_token (int n);\n   // Skips the current token.\n   void skip_token () { skip_token (0); }\n \n+  // Dumps and advances by n + 1 tokens.\n+  void dump_and_skip (int n);\n+\n   // Replaces the current token with a specified token.\n   void replace_current_token (TokenPtr replacement);\n   // FIXME: don't use anymore\n@@ -197,6 +203,8 @@ class Lexer\n    * allocating new linemap */\n   static const int max_column_hint = 80;\n \n+  Optional<std::ofstream &> dump_lex_out;\n+\n   // Input source wrapper thing.\n   class InputSource\n   {"}, {"sha": "0346ce68a2372713fec9d0a2d3568bf696507eda", "filename": "gcc/rust/parse/rust-parse-impl.h", "status": "modified", "additions": 0, "deletions": 41, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Fparse%2Frust-parse-impl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Fparse%2Frust-parse-impl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Fparse%2Frust-parse-impl.h?ref=b43c5d4fd82c220419f9234588fed8131d416fff", "patch": "@@ -14887,47 +14887,6 @@ Parser<ManagedTokenSource>::done_end ()\n   return (t->get_id () == RIGHT_CURLY || t->get_id () == END_OF_FILE);\n }\n \n-// Dumps lexer output to stderr.\n-template <typename ManagedTokenSource>\n-void\n-Parser<ManagedTokenSource>::debug_dump_lex_output (std::ostream &out)\n-{\n-  /* TODO: a better implementation of \"lexer dump\" (as in dump what was\n-   * actually tokenised) would actually be to \"write\" a token to a file every\n-   * time skip_token() here was called. This would reflect the parser\n-   * modifications to the token stream, such as fixing the template angle\n-   * brackets. */\n-\n-  const_TokenPtr tok = lexer.peek_token ();\n-\n-  while (true)\n-    {\n-      if (tok->get_id () == Rust::END_OF_FILE)\n-\tbreak;\n-\n-      bool has_text = tok->get_id () == Rust::IDENTIFIER\n-\t\t      || tok->get_id () == Rust::INT_LITERAL\n-\t\t      || tok->get_id () == Rust::FLOAT_LITERAL\n-\t\t      || tok->get_id () == Rust::STRING_LITERAL\n-\t\t      || tok->get_id () == Rust::CHAR_LITERAL\n-\t\t      || tok->get_id () == Rust::BYTE_STRING_LITERAL\n-\t\t      || tok->get_id () == Rust::BYTE_CHAR_LITERAL;\n-\n-      Location loc = tok->get_locus ();\n-\n-      out << \"<id=\";\n-      out << tok->token_id_to_str ();\n-      out << has_text ? (std::string (\", text=\") + tok->get_str ()\n-\t\t\t + std::string (\", typehint=\")\n-\t\t\t + std::string (tok->get_type_hint_str ()))\n-\t\t      : \"\";\n-      out << lexer.get_line_map ()->to_string (loc);\n-\n-      lexer.skip_token ();\n-      tok = lexer.peek_token ();\n-    }\n-}\n-\n // Parses crate and dumps AST to stderr, recursively.\n template <typename ManagedTokenSource>\n void"}, {"sha": "8449181b12f3ad8cd9c51f076b5b05e894da3791", "filename": "gcc/rust/parse/rust-parse.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Fparse%2Frust-parse.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Fparse%2Frust-parse.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Fparse%2Frust-parse.h?ref=b43c5d4fd82c220419f9234588fed8131d416fff", "patch": "@@ -671,8 +671,6 @@ template <typename ManagedTokenSource> class Parser\n   // Main entry point for parser.\n   std::unique_ptr<AST::Crate> parse_crate ();\n \n-  // Dumps all lexer output.\n-  void debug_dump_lex_output (std::ostream &out);\n   void debug_dump_ast_output (AST::Crate &crate, std::ostream &out);\n \n   // Returns whether any parsing errors have occurred."}, {"sha": "513bf50cb88fcec9abba7a2d7ceff9043d9816fa", "filename": "gcc/rust/rust-session-manager.cc", "status": "modified", "additions": 17, "deletions": 24, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Frust-session-manager.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Frust-session-manager.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Frust-session-manager.cc?ref=b43c5d4fd82c220419f9234588fed8131d416fff", "patch": "@@ -439,7 +439,22 @@ Session::compile_crate (const char *filename)\n   // parse file here\n   /* create lexer and parser - these are file-specific and so aren't instance\n    * variables */\n-  Lexer lex (filename, std::move (file_wrap), linemap);\n+  Optional<std::ofstream &> dump_lex_opt = Optional<std::ofstream &>::none ();\n+  std::ofstream dump_lex_stream;\n+  if (options.dump_option_enabled (CompileOptions::LEXER_DUMP))\n+    {\n+      dump_lex_stream.open (kLexDumpFile);\n+      if (dump_lex_stream.fail ())\n+\t{\n+\t  rust_error_at (Linemap::unknown_location (),\n+\t\t\t \"cannot open %s:%m; ignored\", kLexDumpFile);\n+\t}\n+      auto stream = Optional<std::ofstream &>::some (dump_lex_stream);\n+      dump_lex_opt = std::move (stream);\n+    }\n+\n+  Lexer lex (filename, std::move (file_wrap), linemap, dump_lex_opt);\n+\n   Parser<Lexer> parser (lex);\n \n   // generate crate from parser\n@@ -448,11 +463,7 @@ Session::compile_crate (const char *filename)\n   // handle crate name\n   handle_crate_name (*ast_crate.get ());\n \n-  // dump options\n-  if (options.dump_option_enabled (CompileOptions::LEXER_DUMP))\n-    {\n-      dump_lex (parser);\n-    }\n+  // dump options except lexer dump\n   if (options.dump_option_enabled (CompileOptions::PARSER_AST_DUMP))\n     {\n       dump_ast (parser, *ast_crate.get ());\n@@ -819,24 +830,6 @@ Session::expansion (AST::Crate &crate)\n   rust_debug (\"finished expansion\");\n }\n \n-void\n-Session::dump_lex (Parser<Lexer> &parser) const\n-{\n-  std::ofstream out;\n-  out.open (kLexDumpFile);\n-  if (out.fail ())\n-    {\n-      rust_error_at (Linemap::unknown_location (), \"cannot open %s:%m; ignored\",\n-\t\t     kLexDumpFile);\n-      return;\n-    }\n-\n-  // TODO: rewrite lexer dump or something so that it allows for the crate\n-  // to already be parsed\n-  parser.debug_dump_lex_output (out);\n-  out.close ();\n-}\n-\n void\n Session::dump_ast (Parser<Lexer> &parser, AST::Crate &crate) const\n {"}, {"sha": "0d87a9c31d18433e974359db6205314e33ed87b7", "filename": "gcc/rust/util/rust-optional.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Futil%2Frust-optional.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b43c5d4fd82c220419f9234588fed8131d416fff/gcc%2Frust%2Futil%2Frust-optional.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Futil%2Frust-optional.h?ref=b43c5d4fd82c220419f9234588fed8131d416fff", "patch": "@@ -194,6 +194,7 @@ template <typename T> class Optional<T &>\n public:\n   Optional (const Optional &other) = default;\n   Optional (Optional &&other) = default;\n+  Optional &operator= (Optional &&other) = default;\n \n   static Optional<T &> some (T &value)\n   {"}]}