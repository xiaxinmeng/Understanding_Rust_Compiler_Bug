{"sha": "aac5cc1620c19d41b26c09982ed666e0dae3d453", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWFjNWNjMTYyMGMxOWQ0MWIyNmMwOTk4MmVkNjY2ZTBkYWUzZDQ1Mw==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@cygnus.com", "date": "1998-07-01T05:10:51Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "1998-07-01T05:10:51Z"}, "message": "expr.c (emit_group_load, [...]): Rewrite considering the size and alignment of the structure being manipulated.\n\n        * expr.c (emit_group_load, emit_group_store): Rewrite considering\n        the size and alignment of the structure being manipulated.\n        * expr.c, calls.c, function.c: Update all callers.\n        * expr.h: Update prototypes.\n        * cse.c (invalidate): Cope with parallels.\n\nFrom-SVN: r20867", "tree": {"sha": "828f62b36645dd969e85f79cb627a5fabb232ee1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/828f62b36645dd969e85f79cb627a5fabb232ee1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/aac5cc1620c19d41b26c09982ed666e0dae3d453", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/aac5cc1620c19d41b26c09982ed666e0dae3d453", "html_url": "https://github.com/Rust-GCC/gccrs/commit/aac5cc1620c19d41b26c09982ed666e0dae3d453", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/aac5cc1620c19d41b26c09982ed666e0dae3d453/comments", "author": null, "committer": null, "parents": [{"sha": "1eac9f59f2a15474966ffa2fe591119cc5a4360b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1eac9f59f2a15474966ffa2fe591119cc5a4360b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1eac9f59f2a15474966ffa2fe591119cc5a4360b"}], "stats": {"total": 276, "additions": 200, "deletions": 76}, "files": [{"sha": "ff467bfd9ace083e03fa2b1259b6ddf0a82e0207", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=aac5cc1620c19d41b26c09982ed666e0dae3d453", "patch": "@@ -1,3 +1,11 @@\n+Wed Jul  1 05:04:41 1998  Richard Henderson  <rth@cygnus.com>\n+\n+\t* expr.c (emit_group_load, emit_group_store): Rewrite considering\n+\tthe size and alignment of the structure being manipulated. \n+\t* expr.c, calls.c, function.c: Update all callers.\n+\t* expr.h: Update prototypes.\n+\t* cse.c (invalidate): Cope with parallels.\n+\n Wed Jul  1 04:22:23 1998  Richard Henderson  <rth@cygnus.com>\n \n \t* sparc.c (function_arg_record_value): Take a MODE arg with which to"}, {"sha": "8b140190c7e3691d14fde541294e3955c156ec94", "filename": "gcc/calls.c", "status": "modified", "additions": 10, "deletions": 3, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Fcalls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Fcalls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcalls.c?ref=aac5cc1620c19d41b26c09982ed666e0dae3d453", "patch": "@@ -1922,7 +1922,12 @@ expand_call (exp, target, ignore)\n \t     locations.  The Irix 6 ABI has examples of this.  */\n \n \t  if (GET_CODE (reg) == PARALLEL)\n-\t    emit_group_load (reg, args[i].value);\n+\t    {\n+\t      emit_group_load (reg, args[i].value,\n+\t\t\t       int_size_in_bytes (TREE_TYPE (args[i].tree_value)),\n+\t\t\t       (TYPE_ALIGN (TREE_TYPE (args[i].tree_value))\n+\t\t\t\t/ BITS_PER_UNIT));\n+\t    }\n \n \t  /* If simple case, just do move.  If normal partial, store_one_arg\n \t     has already loaded the register for us.  In all other cases,\n@@ -2089,15 +2094,17 @@ expand_call (exp, target, ignore)\n      The Irix 6 ABI has examples of this.  */\n   else if (GET_CODE (valreg) == PARALLEL)\n     {\n+      int bytes = int_size_in_bytes (TREE_TYPE (exp));\n+\n       if (target == 0)\n \t{\n-\t  int bytes = int_size_in_bytes (TREE_TYPE (exp));\n \t  target = assign_stack_temp (TYPE_MODE (TREE_TYPE (exp)), bytes, 0);\n \t  MEM_IN_STRUCT_P (target) = AGGREGATE_TYPE_P (TREE_TYPE (exp));\n \t  preserve_temp_slots (target);\n \t}\n \n-      emit_group_store (target, valreg);\n+      emit_group_store (target, valreg, bytes,\n+\t\t\tTYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n     }\n   else if (target && GET_MODE (target) == TYPE_MODE (TREE_TYPE (exp))\n \t   && GET_MODE (target) == GET_MODE (valreg))"}, {"sha": "37055110575fa0c0756a03f52a467de22debe644", "filename": "gcc/cse.c", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=aac5cc1620c19d41b26c09982ed666e0dae3d453", "patch": "@@ -1609,6 +1609,24 @@ invalidate (x, full_mode)\n       return;\n     }\n \n+  /* If X is a parallel, invalidate all of its elements.  */\n+\n+  if (GET_CODE (x) == PARALLEL)\n+    {\n+      for (i = XVECLEN (x, 0) - 1; i >= 0 ; --i)\n+\tinvalidate (XVECEXP (x, 0, i), VOIDmode);\n+      return;\n+    }\n+\n+  /* If X is an expr_list, this is part of a disjoint return value;\n+     extract the location in question ignoring the offset.  */\n+\n+  if (GET_CODE (x) == EXPR_LIST)\n+    {\n+      invalidate (XEXP (x, 0), VOIDmode);\n+      return;\n+    }\n+\n   /* X is not a register; it must be a memory reference with\n      a nonvarying address.  Remove all hash table elements\n      that refer to overlapping pieces of memory.  */"}, {"sha": "a7abc5ab8323c7211577c457463c0d321cd6c318", "filename": "gcc/expr.c", "status": "modified", "additions": 154, "deletions": 68, "changes": 222, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=aac5cc1620c19d41b26c09982ed666e0dae3d453", "patch": "@@ -1822,103 +1822,187 @@ move_block_from_reg (regno, x, nregs, size)\n     }\n }\n \n-/* Emit code to move a block Y to a block X, where X is non-consecutive\n-   registers represented by a PARALLEL.  */\n+/* Emit code to move a block SRC to a block DST, where DST is non-consecutive\n+   registers represented by a PARALLEL.  SSIZE represents the total size of\n+   block SRC in bytes, or -1 if not known.  ALIGN is the known alignment of\n+   SRC in bits.  */\n+/* ??? If SSIZE % UNITS_PER_WORD != 0, we make the blatent assumption that\n+   the balance will be in what would be the low-order memory addresses, i.e.\n+   left justified for big endian, right justified for little endian.  This\n+   happens to be true for the targets currently using this support.  If this\n+   ever changes, a new target macro along the lines of FUNCTION_ARG_PADDING\n+   would be needed.  */\n \n void\n-emit_group_load (x, y)\n-     rtx x, y;\n+emit_group_load (dst, orig_src, ssize, align)\n+     rtx dst, orig_src;\n+     int align, ssize;\n {\n-  rtx target_reg, source;\n-  int i;\n+  rtx *tmps, src;\n+  int start, i;\n \n-  if (GET_CODE (x) != PARALLEL)\n+  if (GET_CODE (dst) != PARALLEL)\n     abort ();\n \n   /* Check for a NULL entry, used to indicate that the parameter goes\n      both on the stack and in registers.  */\n-  if (XEXP (XVECEXP (x, 0, 0), 0))\n-    i = 0;\n+  if (XEXP (XVECEXP (dst, 0, 0), 0))\n+    start = 0;\n   else\n-    i = 1;\n-\n-  for (; i < XVECLEN (x, 0); i++)\n-    {\n-      rtx element = XVECEXP (x, 0, i);\n-\n-      target_reg = XEXP (element, 0);\n-\n-      if (GET_CODE (y) == MEM)\n-\tsource = change_address (y, GET_MODE (target_reg),\n-\t\t\t\t plus_constant (XEXP (y, 0),\n-\t\t\t\t\t\tINTVAL (XEXP (element, 1))));\n-      else if (XEXP (element, 1) == const0_rtx)\n-\t{\n-\t  if (GET_MODE (target_reg) == GET_MODE (y))\n-\t    source = y;\n-\t  /* Allow for the target_reg to be smaller than the input register\n-\t     to allow for AIX with 4 DF arguments after a single SI arg.  The\n-\t     last DF argument will only load 1 word into the integer registers,\n-\t     but load a DF value into the float registers.  */\n-\t  else if ((GET_MODE_SIZE (GET_MODE (target_reg))\n-\t\t    <= GET_MODE_SIZE (GET_MODE (y)))\n-\t\t   && GET_MODE (target_reg) == word_mode)\n-\t    /* This might be a const_double, so we can't just use SUBREG.  */\n-\t    source = operand_subword (y, 0, 0, VOIDmode);\n-\t  else if (GET_MODE_SIZE (GET_MODE (target_reg))\n-\t\t   == GET_MODE_SIZE (GET_MODE (y)))\n-\t    source = gen_lowpart (GET_MODE (target_reg), y);\n-\t  else\n-\t    abort ();\t    \n+    start = 1;\n+\n+  tmps = (rtx *) alloca (sizeof(rtx) * XVECLEN (dst, 0));\n+\n+  /* If we won't be loading directly from memory, protect the real source\n+     from strange tricks we might play.  */\n+  src = orig_src;\n+  if (GET_CODE (src) != MEM)\n+    {\n+      src = gen_reg_rtx (GET_MODE (orig_src));\n+      emit_move_insn (src, orig_src);\n+    }\n+\n+  /* Process the pieces.  */\n+  for (i = start; i < XVECLEN (dst, 0); i++)\n+    {\n+      enum machine_mode mode = GET_MODE (XEXP (XVECEXP (dst, 0, i), 0));\n+      int bytepos = INTVAL (XEXP (XVECEXP (dst, 0, i), 1));\n+      int bytelen = GET_MODE_SIZE (mode);\n+      int shift = 0;\n+\n+      /* Handle trailing fragments that run over the size of the struct.  */\n+      if (ssize >= 0 && bytepos + bytelen > ssize)\n+\t{\n+\t  shift = (bytelen - (ssize - bytepos)) * BITS_PER_UNIT;\n+\t  bytelen = ssize - bytepos;\n+\t  if (bytelen <= 0)\n+\t    abort();\n+\t}\n+\n+      /* Optimize the access just a bit.  */\n+      if (GET_CODE (src) == MEM\n+\t  && align*BITS_PER_UNIT >= GET_MODE_ALIGNMENT (mode)\n+\t  && bytepos*BITS_PER_UNIT % GET_MODE_ALIGNMENT (mode) == 0\n+\t  && bytelen == GET_MODE_SIZE (mode))\n+\t{\n+\t  tmps[i] = gen_reg_rtx (mode);\n+\t  emit_move_insn (tmps[i],\n+\t\t\t  change_address (src, mode,\n+\t\t\t\t\t  plus_constant (XEXP (src, 0),\n+\t\t\t\t\t\t\t bytepos)));\n \t}\n       else\n-\tabort ();\n+\t{\n+\t  tmps[i] = extract_bit_field (src, bytelen*BITS_PER_UNIT,\n+\t\t\t\t       bytepos*BITS_PER_UNIT, 1, NULL_RTX,\n+\t\t\t\t       mode, mode, align, ssize);\n+\t}\n \n-      emit_move_insn (target_reg, source);\n+      if (BYTES_BIG_ENDIAN && shift)\n+\t{\n+\t  expand_binop (mode, ashl_optab, tmps[i], GEN_INT (shift),\n+\t\t\ttmps[i], 0, OPTAB_WIDEN);\n+\t}\n     }\n+  emit_queue();\n+\n+  /* Copy the extracted pieces into the proper (probable) hard regs.  */\n+  for (i = start; i < XVECLEN (dst, 0); i++)\n+    emit_move_insn (XEXP (XVECEXP (dst, 0, i), 0), tmps[i]);\n }\n \n-/* Emit code to move a block Y to a block X, where Y is non-consecutive\n-   registers represented by a PARALLEL.  */\n+/* Emit code to move a block SRC to a block DST, where SRC is non-consecutive\n+   registers represented by a PARALLEL.  SSIZE represents the total size of\n+   block DST, or -1 if not known.  ALIGN is the known alignment of DST.  */\n \n void\n-emit_group_store (x, y)\n-     rtx x, y;\n+emit_group_store (orig_dst, src, ssize, align)\n+     rtx orig_dst, src;\n+     int ssize, align;\n {\n-  rtx source_reg, target;\n-  int i;\n+  rtx *tmps, dst;\n+  int start, i;\n \n-  if (GET_CODE (y) != PARALLEL)\n+  if (GET_CODE (src) != PARALLEL)\n     abort ();\n \n   /* Check for a NULL entry, used to indicate that the parameter goes\n      both on the stack and in registers.  */\n-  if (XEXP (XVECEXP (y, 0, 0), 0))\n-    i = 0;\n+  if (XEXP (XVECEXP (src, 0, 0), 0))\n+    start = 0;\n   else\n-    i = 1;\n+    start = 1;\n \n-  for (; i < XVECLEN (y, 0); i++)\n+  tmps = (rtx *) alloca (sizeof(rtx) * XVECLEN (src, 0));\n+\n+  /* Copy the (probable) hard regs into pseudos.  */\n+  for (i = start; i < XVECLEN (src, 0); i++)\n     {\n-      rtx element = XVECEXP (y, 0, i);\n+      rtx reg = XEXP (XVECEXP (src, 0, i), 0);\n+      tmps[i] = gen_reg_rtx (GET_MODE (reg));\n+      emit_move_insn (tmps[i], reg);\n+    }\n+  emit_queue();\n \n-      source_reg = XEXP (element, 0);\n+  /* If we won't be storing directly into memory, protect the real destination\n+     from strange tricks we might play.  */\n+  dst = orig_dst;\n+  if (GET_CODE (dst) != MEM)\n+    {\n+      dst = gen_reg_rtx (GET_MODE (orig_dst));\n+      /* Make life a bit easier for combine.  */\n+      emit_move_insn (dst, const0_rtx);\n+    }\n+  else if (! MEM_IN_STRUCT_P (dst))\n+    {\n+      /* store_bit_field requires that memory operations have\n+\t mem_in_struct_p set; we might not.  */\n \n-      if (GET_CODE (x) == MEM)\n-\ttarget = change_address (x, GET_MODE (source_reg),\n-\t\t\t\t plus_constant (XEXP (x, 0),\n-\t\t\t\t\t\tINTVAL (XEXP (element, 1))));\n-      else if (XEXP (element, 1) == const0_rtx)\n+      dst = copy_rtx (orig_dst);\n+      MEM_IN_STRUCT_P (dst) = 1;\n+    }\n+\n+  /* Process the pieces.  */\n+  for (i = start; i < XVECLEN (src, 0); i++)\n+    {\n+      int bytepos = INTVAL (XEXP (XVECEXP (src, 0, i), 1));\n+      enum machine_mode mode = GET_MODE (tmps[i]);\n+      int bytelen = GET_MODE_SIZE (mode);\n+\n+      /* Handle trailing fragments that run over the size of the struct.  */\n+      if (ssize >= 0 && bytepos + bytelen > ssize)\n \t{\n-\t  target = x;\n-\t  if (GET_MODE (target) != GET_MODE (source_reg))\n-\t    target = gen_lowpart (GET_MODE (source_reg), target);\n+\t  if (BYTES_BIG_ENDIAN)\n+\t    {\n+\t      int shift = (bytelen - (ssize - bytepos)) * BITS_PER_UNIT;\n+\t      expand_binop (mode, ashr_optab, tmps[i], GEN_INT (shift),\n+\t\t\t    tmps[i], 0, OPTAB_WIDEN);\n+\t    }\n+\t  bytelen = ssize - bytepos;\n \t}\n-      else\n-\tabort ();\n \n-      emit_move_insn (target, source_reg);\n+      /* Optimize the access just a bit.  */\n+      if (GET_CODE (dst) == MEM\n+\t  && align*BITS_PER_UNIT >= GET_MODE_ALIGNMENT (mode)\n+\t  && bytepos*BITS_PER_UNIT % GET_MODE_ALIGNMENT (mode) == 0\n+\t  && bytelen == GET_MODE_SIZE (mode))\n+\t{\n+\t  emit_move_insn (change_address (dst, mode,\n+\t\t\t\t\t  plus_constant (XEXP (dst, 0),\n+\t\t\t\t\t\t\t bytepos)),\n+\t\t\t  tmps[i]);\n+\t}\n+      else\n+\t{\n+\t  store_bit_field (dst, bytelen*BITS_PER_UNIT, bytepos*BITS_PER_UNIT,\n+\t\t\t   mode, tmps[i], align, ssize);\n+\t}\n     }\n+  emit_queue();\n+\n+  /* Copy from the pseudo into the (probable) hard reg.  */\n+  if (GET_CODE (dst) == REG)\n+    emit_move_insn (orig_dst, dst);\n }\n \n /* Add a USE expression for REG to the (possibly empty) list pointed\n@@ -2862,7 +2946,7 @@ emit_push_insn (x, mode, type, size, align, partial, reg, extra,\n       /* Handle calls that pass values in multiple non-contiguous locations.\n \t The Irix 6 ABI has examples of this.  */\n       if (GET_CODE (reg) == PARALLEL)\n-\temit_group_load (reg, x);\n+\temit_group_load (reg, x, -1, align);  /* ??? size? */\n       else\n \tmove_block_to_reg (REGNO (reg), x, partial, mode);\n     }\n@@ -3071,7 +3155,8 @@ expand_assignment (to, from, want_value, suggest_reg)\n       /* Handle calls that return values in multiple non-contiguous locations.\n \t The Irix 6 ABI has examples of this.  */\n       if (GET_CODE (to_rtx) == PARALLEL)\n-\temit_group_load (to_rtx, value);\n+\temit_group_load (to_rtx, value, int_size_in_bytes (TREE_TYPE (from)),\n+\t\t\t TYPE_ALIGN (TREE_TYPE (from)) / BITS_PER_UNIT);\n       else if (GET_MODE (to_rtx) == BLKmode)\n \temit_block_move (to_rtx, value, expr_size (from),\n \t\t\t TYPE_ALIGN (TREE_TYPE (from)) / BITS_PER_UNIT);\n@@ -3476,7 +3561,8 @@ store_expr (exp, target, want_value)\n       /* Handle calls that return values in multiple non-contiguous locations.\n \t The Irix 6 ABI has examples of this.  */\n       else if (GET_CODE (target) == PARALLEL)\n-\temit_group_load (target, temp);\n+\temit_group_load (target, temp, int_size_in_bytes (TREE_TYPE (exp)),\n+\t\t\t TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n       else if (GET_MODE (temp) == BLKmode)\n \temit_block_move (target, temp, expr_size (exp),\n \t\t\t TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);"}, {"sha": "11f4673efa12cb4aca238c9f53898f8655f706ac", "filename": "gcc/expr.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=aac5cc1620c19d41b26c09982ed666e0dae3d453", "patch": "@@ -714,10 +714,10 @@ extern void move_block_from_reg PROTO((int, rtx, int, int));\n \n /* Load a BLKmode value into non-consecutive registers represented by a\n    PARALLEL.  */\n-extern void emit_group_load PROTO((rtx, rtx));\n+extern void emit_group_load PROTO((rtx, rtx, int, int));\n /* Store a BLKmode value from non-consecutive registers represented by a\n    PARALLEL.  */\n-extern void emit_group_store PROTO((rtx, rtx));\n+extern void emit_group_store PROTO((rtx, rtx, int, int));\n \n /* Mark REG as holding a parameter for the next CALL_INSN.  */\n extern void use_reg PROTO((rtx *, rtx));"}, {"sha": "67bbc698cfe8473a4faaab5feb2eff900a24e234", "filename": "gcc/function.c", "status": "modified", "additions": 8, "deletions": 3, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Ffunction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aac5cc1620c19d41b26c09982ed666e0dae3d453/gcc%2Ffunction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.c?ref=aac5cc1620c19d41b26c09982ed666e0dae3d453", "patch": "@@ -3945,8 +3945,10 @@ assign_parms (fndecl, second_time)\n \t\t  /* Handle calls that pass values in multiple non-contiguous\n \t\t     locations.  The Irix 6 ABI has examples of this.  */\n \t\t  if (GET_CODE (entry_parm) == PARALLEL)\n-\t\t    emit_group_store (validize_mem (stack_parm),\n-\t\t\t\t\t entry_parm);\n+\t\t    emit_group_store (validize_mem (stack_parm), entry_parm,\n+\t\t\t\t      int_size_in_bytes (TREE_TYPE (parm)),\n+\t\t\t\t      (TYPE_ALIGN (TREE_TYPE (parm))\n+\t\t\t\t       / BITS_PER_UNIT));\n \t\t  else\n \t\t    move_block_from_reg (REGNO (entry_parm),\n \t\t\t\t\t validize_mem (stack_parm), nregs,\n@@ -4116,7 +4118,10 @@ assign_parms (fndecl, second_time)\n \t      /* Handle calls that pass values in multiple non-contiguous\n \t\t locations.  The Irix 6 ABI has examples of this.  */\n \t      if (GET_CODE (entry_parm) == PARALLEL)\n-\t\temit_group_store (validize_mem (stack_parm), entry_parm);\n+\t\temit_group_store (validize_mem (stack_parm), entry_parm,\n+\t\t\t\t  int_size_in_bytes (TREE_TYPE (parm)),\n+\t\t\t\t  (TYPE_ALIGN (TREE_TYPE (parm))\n+\t\t\t\t   / BITS_PER_UNIT));\n \t      else\n \t\tmove_block_from_reg (REGNO (entry_parm),\n \t\t\t\t     validize_mem (stack_parm),"}]}