{"sha": "a499aac5dfa5d9be4945c162167d13cfc07b2a81", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YTQ5OWFhYzVkZmE1ZDliZTQ5NDVjMTYyMTY3ZDEzY2ZjMDdiMmE4MQ==", "commit": {"author": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2014-11-07T09:00:32Z"}, "committer": {"name": "Richard Biener", "email": "rguenth@gcc.gnu.org", "date": "2014-11-07T09:00:32Z"}, "message": "match.pd: Add patterns for POINTER_PLUS_EXPR association and special patterns from...\n\n2014-11-07  Richard Biener  <rguenther@suse.de>\n\n\t* match.pd: Add patterns for POINTER_PLUS_EXPR association\n\tand special patterns from tree-ssa-forwprop.c\n\t* fold-const.c (fold_binary_loc): Remove them here.\n\t* tree-ssa-forwprop.c (to_purge): New global bitmap.\n\t(fwprop_set_lattice_val): New function.\n\t(fwprop_invalidate_lattice): Likewise.\n\t(remove_prop_source_from_use): Instead of purging dead EH\n\tedges record blocks to do that in to_purge.\n\t(tidy_after_forward_propagate_addr): Likewise.\n\t(forward_propagate_addr_expr): Invalidate the lattice for\n\tSSA names we release.\n\t(simplify_conversion_from_bitmask): Likewise.\n\t(simplify_builtin_call): Likewise.\n\t(associate_pointerplus_align): Remove.\n\t(associate_pointerplus_diff): Likewise.\n\t(associate_pointerplus): Likewise.\n\t(fold_all_stmts): Merge with ...\n\t(pass_forwprop::execute): ... the original loop over all\n\tbasic-blocks.  Delay purging dead EH edges and invalidate\n\tthe lattice for SSA names we release.\n\nFrom-SVN: r217213", "tree": {"sha": "696202c55daf649efb88070f8b62853e03d748c2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/696202c55daf649efb88070f8b62853e03d748c2"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/a499aac5dfa5d9be4945c162167d13cfc07b2a81", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a499aac5dfa5d9be4945c162167d13cfc07b2a81", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a499aac5dfa5d9be4945c162167d13cfc07b2a81", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a499aac5dfa5d9be4945c162167d13cfc07b2a81/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "a8cfbbdc7413f05278fa54d4c4644ec6eb5d943b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a8cfbbdc7413f05278fa54d4c4644ec6eb5d943b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a8cfbbdc7413f05278fa54d4c4644ec6eb5d943b"}], "stats": {"total": 409, "additions": 157, "deletions": 252}, "files": [{"sha": "8541a6ce3af366e35b0fce17b1b58146ea1b6d4d", "filename": "gcc/ChangeLog", "status": "modified", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a499aac5dfa5d9be4945c162167d13cfc07b2a81/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a499aac5dfa5d9be4945c162167d13cfc07b2a81/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=a499aac5dfa5d9be4945c162167d13cfc07b2a81", "patch": "@@ -1,3 +1,26 @@\n+2014-11-07  Richard Biener  <rguenther@suse.de>\n+\n+\t* match.pd: Add patterns for POINTER_PLUS_EXPR association\n+\tand special patterns from tree-ssa-forwprop.c\n+\t* fold-const.c (fold_binary_loc): Remove them here.\n+\t* tree-ssa-forwprop.c (to_purge): New global bitmap.\n+\t(fwprop_set_lattice_val): New function.\n+\t(fwprop_invalidate_lattice): Likewise.\n+\t(remove_prop_source_from_use): Instead of purging dead EH\n+\tedges record blocks to do that in to_purge.\n+\t(tidy_after_forward_propagate_addr): Likewise.\n+\t(forward_propagate_addr_expr): Invalidate the lattice for\n+\tSSA names we release.\n+\t(simplify_conversion_from_bitmask): Likewise.\n+\t(simplify_builtin_call): Likewise.\n+\t(associate_pointerplus_align): Remove.\n+\t(associate_pointerplus_diff): Likewise.\n+\t(associate_pointerplus): Likewise.\n+\t(fold_all_stmts): Merge with ...\n+\t(pass_forwprop::execute): ... the original loop over all\n+\tbasic-blocks.  Delay purging dead EH edges and invalidate\n+\tthe lattice for SSA names we release.\n+\n 2014-11-07  Terry Guo  <terry.guo@arm.com>\n \n \t* config/arm/arm.opt (masm-syntax-unified): New option."}, {"sha": "cff9c106f1e969967c05d0b9048f99d8d71f6745", "filename": "gcc/fold-const.c", "status": "modified", "additions": 0, "deletions": 17, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a499aac5dfa5d9be4945c162167d13cfc07b2a81/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a499aac5dfa5d9be4945c162167d13cfc07b2a81/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=a499aac5dfa5d9be4945c162167d13cfc07b2a81", "patch": "@@ -10009,10 +10009,6 @@ fold_binary_loc (location_t loc,\n       return NULL_TREE;\n \n     case POINTER_PLUS_EXPR:\n-      /* 0 +p index -> (type)index */\n-      if (integer_zerop (arg0))\n-\treturn non_lvalue_loc (loc, fold_convert_loc (loc, type, arg1));\n-\n       /* INT +p INT -> (PTR)(INT + INT).  Stripping types allows for this. */\n       if (INTEGRAL_TYPE_P (TREE_TYPE (arg1))\n \t   && INTEGRAL_TYPE_P (TREE_TYPE (arg0)))\n@@ -10023,19 +10019,6 @@ fold_binary_loc (location_t loc,\n \t\t\t\t\t      fold_convert_loc (loc, sizetype,\n \t\t\t\t\t\t\t\targ0)));\n \n-      /* (PTR +p B) +p A -> PTR +p (B + A) */\n-      if (TREE_CODE (arg0) == POINTER_PLUS_EXPR)\n-\t{\n-\t  tree inner;\n-\t  tree arg01 = fold_convert_loc (loc, sizetype, TREE_OPERAND (arg0, 1));\n-\t  tree arg00 = TREE_OPERAND (arg0, 0);\n-\t  inner = fold_build2_loc (loc, PLUS_EXPR, sizetype,\n-\t\t\t       arg01, fold_convert_loc (loc, sizetype, arg1));\n-\t  return fold_convert_loc (loc, type,\n-\t\t\t\t   fold_build_pointer_plus_loc (loc,\n-\t\t\t\t\t\t\t\targ00, inner));\n-\t}\n-\n       /* PTR_CST +p CST -> CST1 */\n       if (TREE_CODE (arg0) == INTEGER_CST && TREE_CODE (arg1) == INTEGER_CST)\n \treturn fold_build2_loc (loc, PLUS_EXPR, type, arg0,"}, {"sha": "bbff19a792395d5e71c5779a949031f2b8b08dda", "filename": "gcc/match.pd", "status": "modified", "additions": 39, "deletions": 3, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a499aac5dfa5d9be4945c162167d13cfc07b2a81/gcc%2Fmatch.pd", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a499aac5dfa5d9be4945c162167d13cfc07b2a81/gcc%2Fmatch.pd", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmatch.pd?ref=a499aac5dfa5d9be4945c162167d13cfc07b2a81", "patch": "@@ -39,6 +39,11 @@ along with GCC; see the file COPYING3.  If not see\n     (op @0 integer_zerop)\n     (non_lvalue @0)))\n \n+/* 0 +p index -> (type)index */\n+(simplify\n+ (pointer_plus integer_zerop @1)\n+ (non_lvalue (convert @1)))\n+\n /* Simplify x - x.\n    This is unsafe for certain floats even in non-IEEE formats.\n    In IEEE, it is unsafe because it does wrong for NaNs.\n@@ -228,19 +233,50 @@ along with GCC; see the file COPYING3.  If not see\n        && TYPE_PRECISION (TREE_TYPE (@1)) == 1)\n    (le @0 @1)))\n \n-/* From tree-ssa-forwprop.c:simplify_not_neg_expr.  */\n-\n /* ~~x -> x */\n (simplify\n   (bit_not (bit_not @0))\n   @0)\n \n-/* The corresponding (negate (negate @0)) -> @0 is in match-plusminus.pd.  */\n (simplify\n  (negate (negate @0))\n  @0)\n \n \n+/* Associate (p +p off1) +p off2 as (p +p (off1 + off2)).  */\n+(simplify\n+  (pointer_plus (pointer_plus @0 @1) @3)\n+  (pointer_plus @0 (plus @1 @3)))\n+\n+/* Pattern match\n+     tem1 = (long) ptr1;\n+     tem2 = (long) ptr2;\n+     tem3 = tem2 - tem1;\n+     tem4 = (unsigned long) tem3;\n+     tem5 = ptr1 + tem4;\n+   and produce\n+     tem5 = ptr2;  */\n+(simplify\n+  (pointer_plus @0 (convert?@2 (minus@3 (convert @1) (convert @0))))\n+  /* Conditionally look through a sign-changing conversion.  */\n+  (if (TYPE_PRECISION (TREE_TYPE (@2)) == TYPE_PRECISION (TREE_TYPE (@3))\n+       && ((GIMPLE && useless_type_conversion_p (type, TREE_TYPE (@1)))\n+\t    || (GENERIC && type == TREE_TYPE (@1))))\n+   @1))\n+\n+/* Pattern match\n+     tem = (sizetype) ptr;\n+     tem = tem & algn;\n+     tem = -tem;\n+     ... = ptr p+ tem;\n+   and produce the simpler and easier to analyze with respect to alignment\n+     ... = ptr & ~algn;  */\n+(simplify\n+  (pointer_plus @0 (negate (bit_and (convert @0) INTEGER_CST@1)))\n+  (with { tree algn = wide_int_to_tree (TREE_TYPE (@0), wi::bit_not (@1)); }\n+   (bit_and @0 { algn; })))\n+\n+\n /* Simplifications of conversions.  */\n \n /* Basic strip-useless-type-conversions / strip_nops.  */"}, {"sha": "58f38981e934128344593994b70f935817106f5a", "filename": "gcc/tree-ssa-forwprop.c", "status": "modified", "additions": 95, "deletions": 232, "changes": 327, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a499aac5dfa5d9be4945c162167d13cfc07b2a81/gcc%2Ftree-ssa-forwprop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a499aac5dfa5d9be4945c162167d13cfc07b2a81/gcc%2Ftree-ssa-forwprop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-forwprop.c?ref=a499aac5dfa5d9be4945c162167d13cfc07b2a81", "patch": "@@ -202,6 +202,37 @@ static bool cfg_changed;\n \n static tree rhs_to_tree (tree type, gimple stmt);\n \n+static bitmap to_purge;\n+\n+/* Const-and-copy lattice.  */\n+static vec<tree> lattice;\n+\n+/* Set the lattice entry for NAME to VAL.  */\n+static void\n+fwprop_set_lattice_val (tree name, tree val)\n+{\n+  if (TREE_CODE (name) == SSA_NAME)\n+    {\n+      if (SSA_NAME_VERSION (name) >= lattice.length ())\n+\t{\n+\t  lattice.reserve (num_ssa_names - lattice.length ());\n+\t  lattice.quick_grow_cleared (num_ssa_names);\n+\t}\n+      lattice[SSA_NAME_VERSION (name)] = val;\n+    }\n+}\n+\n+/* Invalidate the lattice entry for NAME, done when releasing SSA names.  */\n+static void\n+fwprop_invalidate_lattice (tree name)\n+{\n+  if (name\n+      && TREE_CODE (name) == SSA_NAME\n+      && SSA_NAME_VERSION (name) < lattice.length ())\n+    lattice[SSA_NAME_VERSION (name)] = NULL_TREE;\n+}\n+\n+\n /* Get the next statement we can propagate NAME's value into skipping\n    trivial copies.  Returns the statement that is suitable as a\n    propagation destination or NULL_TREE if there is no such one.\n@@ -346,7 +377,8 @@ remove_prop_source_from_use (tree name)\n     gsi = gsi_for_stmt (stmt);\n     unlink_stmt_vdef (stmt);\n     if (gsi_remove (&gsi, true))\n-      cfg_changed |= gimple_purge_dead_eh_edges (bb);\n+      bitmap_set_bit (to_purge, bb->index);\n+    fwprop_invalidate_lattice (gimple_get_lhs (stmt));\n     release_defs (stmt);\n \n     name = is_gimple_assign (stmt) ? gimple_assign_rhs1 (stmt) : NULL_TREE;\n@@ -714,9 +746,8 @@ static void\n tidy_after_forward_propagate_addr (gimple stmt)\n {\n   /* We may have turned a trapping insn into a non-trapping insn.  */\n-  if (maybe_clean_or_replace_eh_stmt (stmt, stmt)\n-      && gimple_purge_dead_eh_edges (gimple_bb (stmt)))\n-    cfg_changed = true;\n+  if (maybe_clean_or_replace_eh_stmt (stmt, stmt))\n+    bitmap_set_bit (to_purge, gimple_bb (stmt)->index);\n \n   if (TREE_CODE (gimple_assign_rhs1 (stmt)) == ADDR_EXPR)\n      recompute_tree_invariant_for_addr_expr (gimple_assign_rhs1 (stmt));\n@@ -1089,6 +1120,7 @@ forward_propagate_addr_expr (tree name, tree rhs, bool parent_single_use_p)\n \t  && has_zero_uses (gimple_assign_lhs (use_stmt)))\n \t{\n \t  gimple_stmt_iterator gsi = gsi_for_stmt (use_stmt);\n+\t  fwprop_invalidate_lattice (gimple_get_lhs (use_stmt));\n \t  release_defs (use_stmt);\n \t  gsi_remove (&gsi, true);\n \t}\n@@ -1244,6 +1276,7 @@ simplify_conversion_from_bitmask (gimple_stmt_iterator *gsi_p)\n \t  gimple_stmt_iterator si;\n \t  si = gsi_for_stmt (rhs_def_stmt);\n \t  gsi_remove (&si, true);\n+\t  fwprop_invalidate_lattice (gimple_get_lhs (rhs_def_stmt));\n \t  release_defs (rhs_def_stmt);\n \t  return true;\n \t}\n@@ -1636,9 +1669,13 @@ simplify_builtin_call (gimple_stmt_iterator *gsi_p, tree callee2)\n \t      update_stmt (stmt1);\n \t      unlink_stmt_vdef (stmt2);\n \t      gsi_remove (gsi_p, true);\n+\t      fwprop_invalidate_lattice (gimple_get_lhs (stmt2));\n \t      release_defs (stmt2);\n \t      if (lhs1 && DECL_FUNCTION_CODE (callee1) == BUILT_IN_MEMPCPY)\n-\t\trelease_ssa_name (lhs1);\n+\t\t{\n+\t\t  fwprop_invalidate_lattice (lhs1);\n+\t\t  release_ssa_name (lhs1);\n+\t\t}\n \t      return true;\n \t    }\n \t  else\n@@ -1659,6 +1696,7 @@ simplify_builtin_call (gimple_stmt_iterator *gsi_p, tree callee2)\n \t\t\t\t   build_int_cst (TREE_TYPE (len2), src_len));\n \t      unlink_stmt_vdef (stmt1);\n \t      gsi_remove (&gsi, true);\n+\t      fwprop_invalidate_lattice (gimple_get_lhs (stmt1));\n \t      release_defs (stmt1);\n \t      update_stmt (stmt2);\n \t      return false;\n@@ -2307,157 +2345,6 @@ associate_plusminus (gimple_stmt_iterator *gsi)\n   return false;\n }\n \n-/* Associate operands of a POINTER_PLUS_EXPR assignmen at *GSI.  Returns\n-   true if anything changed, false otherwise.  */\n-\n-static bool\n-associate_pointerplus_align (gimple_stmt_iterator *gsi)\n-{\n-  gimple stmt = gsi_stmt (*gsi);\n-  gimple def_stmt;\n-  tree ptr, rhs, algn;\n-\n-  /* Pattern match\n-       tem = (sizetype) ptr;\n-       tem = tem & algn;\n-       tem = -tem;\n-       ... = ptr p+ tem;\n-     and produce the simpler and easier to analyze with respect to alignment\n-       ... = ptr & ~algn;  */\n-  ptr = gimple_assign_rhs1 (stmt);\n-  rhs = gimple_assign_rhs2 (stmt);\n-  if (TREE_CODE (rhs) != SSA_NAME)\n-    return false;\n-  def_stmt = SSA_NAME_DEF_STMT (rhs);\n-  if (!is_gimple_assign (def_stmt)\n-      || gimple_assign_rhs_code (def_stmt) != NEGATE_EXPR)\n-    return false;\n-  rhs = gimple_assign_rhs1 (def_stmt);\n-  if (TREE_CODE (rhs) != SSA_NAME)\n-    return false;\n-  def_stmt = SSA_NAME_DEF_STMT (rhs);\n-  if (!is_gimple_assign (def_stmt)\n-      || gimple_assign_rhs_code (def_stmt) != BIT_AND_EXPR)\n-    return false;\n-  rhs = gimple_assign_rhs1 (def_stmt);\n-  algn = gimple_assign_rhs2 (def_stmt);\n-  if (TREE_CODE (rhs) != SSA_NAME\n-      || TREE_CODE (algn) != INTEGER_CST)\n-    return false;\n-  def_stmt = SSA_NAME_DEF_STMT (rhs);\n-  if (!is_gimple_assign (def_stmt)\n-      || !CONVERT_EXPR_CODE_P (gimple_assign_rhs_code (def_stmt)))\n-    return false;\n-  if (gimple_assign_rhs1 (def_stmt) != ptr)\n-    return false;\n-\n-  algn = wide_int_to_tree (TREE_TYPE (ptr), wi::bit_not (algn));\n-  gimple_assign_set_rhs_with_ops (gsi, BIT_AND_EXPR, ptr, algn);\n-  fold_stmt_inplace (gsi);\n-  update_stmt (stmt);\n-\n-  return true;\n-}\n-\n-/* Associate operands of a POINTER_PLUS_EXPR assignmen at *GSI.  Returns\n-   true if anything changed, false otherwise.  */\n-\n-static bool\n-associate_pointerplus_diff (gimple_stmt_iterator *gsi)\n-{\n-  gimple stmt = gsi_stmt (*gsi);\n-  gimple def_stmt;\n-  tree ptr1, rhs;\n-\n-  /* Pattern match\n-       tem1 = (long) ptr1;\n-       tem2 = (long) ptr2;\n-       tem3 = tem2 - tem1;\n-       tem4 = (unsigned long) tem3;\n-       tem5 = ptr1 + tem4;\n-     and produce\n-       tem5 = ptr2;  */\n-  ptr1 = gimple_assign_rhs1 (stmt);\n-  rhs = gimple_assign_rhs2 (stmt);\n-  if (TREE_CODE (rhs) != SSA_NAME)\n-    return false;\n-  gimple minus = SSA_NAME_DEF_STMT (rhs);\n-  /* Conditionally look through a sign-changing conversion.  */\n-  if (is_gimple_assign (minus)\n-      && CONVERT_EXPR_CODE_P (gimple_assign_rhs_code (minus))\n-      && (TYPE_PRECISION (TREE_TYPE (gimple_assign_rhs1 (minus)))\n-\t  == TYPE_PRECISION (TREE_TYPE (rhs)))\n-      && TREE_CODE (gimple_assign_rhs1 (minus)) == SSA_NAME)\n-    minus = SSA_NAME_DEF_STMT (gimple_assign_rhs1 (minus));\n-  if (!is_gimple_assign (minus))\n-    return false;\n-  if (gimple_assign_rhs_code (minus) != MINUS_EXPR)\n-    return false;\n-  rhs = gimple_assign_rhs2 (minus);\n-  if (TREE_CODE (rhs) != SSA_NAME)\n-    return false;\n-  def_stmt = SSA_NAME_DEF_STMT (rhs);\n-  if (!is_gimple_assign (def_stmt)\n-      || ! CONVERT_EXPR_CODE_P (gimple_assign_rhs_code (def_stmt))\n-      || gimple_assign_rhs1 (def_stmt) != ptr1)\n-    return false;\n-  rhs = gimple_assign_rhs1 (minus);\n-  if (TREE_CODE (rhs) != SSA_NAME)\n-    return false;\n-  def_stmt = SSA_NAME_DEF_STMT (rhs);\n-  if (!is_gimple_assign (def_stmt)\n-      || ! CONVERT_EXPR_CODE_P (gimple_assign_rhs_code (def_stmt)))\n-    return false;\n-  rhs = gimple_assign_rhs1 (def_stmt);\n-  if (! useless_type_conversion_p (TREE_TYPE (ptr1), TREE_TYPE (rhs)))\n-    return false;\n-\n-  gimple_assign_set_rhs_with_ops (gsi, TREE_CODE (rhs), rhs, NULL_TREE);\n-  update_stmt (stmt);\n-\n-  return true;\n-}\n-\n-/* Associate operands of a POINTER_PLUS_EXPR assignmen at *GSI.  Returns\n-   true if anything changed, false otherwise.  */\n-\n-static bool\n-associate_pointerplus (gimple_stmt_iterator *gsi)\n-{\n-  gimple stmt = gsi_stmt (*gsi);\n-  gimple def_stmt;\n-  tree ptr, off1, off2;\n-\n-  if (associate_pointerplus_align (gsi)\n-      || associate_pointerplus_diff (gsi))\n-    return true;\n-\n-  /* Associate (p +p off1) +p off2 as (p +p (off1 + off2)).  */\n-  ptr = gimple_assign_rhs1 (stmt);\n-  off1 = gimple_assign_rhs2 (stmt);\n-  if (TREE_CODE (ptr) != SSA_NAME\n-      || !has_single_use (ptr))\n-    return false;\n-  def_stmt = SSA_NAME_DEF_STMT (ptr);\n-  if (!is_gimple_assign (def_stmt)\n-      || gimple_assign_rhs_code (def_stmt) != POINTER_PLUS_EXPR\n-      || !can_propagate_from (def_stmt))\n-    return false;\n-  ptr = gimple_assign_rhs1 (def_stmt);\n-  off2 = gimple_assign_rhs2 (def_stmt);\n-  if (!types_compatible_p (TREE_TYPE (off1), TREE_TYPE (off2)))\n-    return false;\n-\n-  tree off = make_ssa_name (TREE_TYPE (off1), NULL);\n-  gimple ostmt = gimple_build_assign_with_ops (PLUS_EXPR, off, off1, off2);\n-  gsi_insert_before (gsi, ostmt, GSI_SAME_STMT);\n-\n-  gimple_assign_set_rhs_with_ops (gsi, POINTER_PLUS_EXPR, ptr, off);\n-  update_stmt (stmt);\n-\n-  return true;\n-}\n-\n /* Combine two conversions in a row for the second conversion at *GSI.\n    Returns 1 if there were any changes made, 2 if cfg-cleanup needs to\n    run.  Else it returns 0.  */\n@@ -3019,9 +2906,6 @@ simplify_mult (gimple_stmt_iterator *gsi)\n }\n \n \n-/* Const-and-copy lattice for fold_all_stmts.  */\n-static vec<tree> lattice;\n-\n /* Primitive \"lattice\" function for gimple_simplify.  */\n \n static tree\n@@ -3041,67 +2925,6 @@ fwprop_ssa_val (tree name)\n   return name;\n }\n \n-/* Fold all stmts using fold_stmt following only single-use chains\n-   and using a simple const-and-copy lattice.  */\n-\n-static bool\n-fold_all_stmts (struct function *fun)\n-{\n-  bool cfg_changed = false;\n-\n-  /* Combine stmts with the stmts defining their operands.  Do that\n-     in an order that guarantees visiting SSA defs before SSA uses.  */\n-  lattice.create (num_ssa_names);\n-  lattice.quick_grow_cleared (num_ssa_names);\n-  int *postorder = XNEWVEC (int, n_basic_blocks_for_fn (fun));\n-  int postorder_num = inverted_post_order_compute (postorder);\n-  for (int i = 0; i < postorder_num; ++i)\n-    {\n-      basic_block bb = BASIC_BLOCK_FOR_FN (fun, postorder[i]);\n-      for (gimple_stmt_iterator gsi = gsi_start_bb (bb);\n-\t   !gsi_end_p (gsi); gsi_next (&gsi))\n-\t{\n-\t  gimple stmt = gsi_stmt (gsi);\n-\t  gimple orig_stmt = stmt;\n-\n-\t  if (fold_stmt (&gsi, fwprop_ssa_val))\n-\t    {\n-\t      stmt = gsi_stmt (gsi);\n-\t      if (maybe_clean_or_replace_eh_stmt (orig_stmt, stmt)\n-\t\t  && gimple_purge_dead_eh_edges (bb))\n-\t\tcfg_changed = true;\n-\t      /* Cleanup the CFG if we simplified a condition to\n-\t         true or false.  */\n-\t      if (gimple_code (stmt) == GIMPLE_COND\n-\t\t  && (gimple_cond_true_p (stmt)\n-\t\t      || gimple_cond_false_p (stmt)))\n-\t\tcfg_changed = true;\n-\t      update_stmt (stmt);\n-\t    }\n-\n-\t  /* Fill up the lattice.  */\n-\t  if (gimple_assign_single_p (stmt))\n-\t    {\n-\t      tree lhs = gimple_assign_lhs (stmt);\n-\t      tree rhs = gimple_assign_rhs1 (stmt);\n-\t      if (TREE_CODE (lhs) == SSA_NAME)\n-\t\t{\n-\t\t  if (TREE_CODE (rhs) == SSA_NAME)\n-\t\t    lattice[SSA_NAME_VERSION (lhs)] = fwprop_ssa_val (rhs);\n-\t\t  else if (is_gimple_min_invariant (rhs))\n-\t\t    lattice[SSA_NAME_VERSION (lhs)] = rhs;\n-\t\t  else\n-\t\t    lattice[SSA_NAME_VERSION (lhs)] = lhs;\n-\t\t}\n-\t    }\n-\t}\n-    }\n-  free (postorder);\n-  lattice.release ();\n-\n-  return cfg_changed;\n-}\n-\n /* Main entry point for the forward propagation and statement combine\n    optimizer.  */\n \n@@ -3137,14 +2960,21 @@ class pass_forwprop : public gimple_opt_pass\n unsigned int\n pass_forwprop::execute (function *fun)\n {\n-  basic_block bb;\n   unsigned int todoflags = 0;\n \n   cfg_changed = false;\n \n-  FOR_EACH_BB_FN (bb, fun)\n+  /* Combine stmts with the stmts defining their operands.  Do that\n+     in an order that guarantees visiting SSA defs before SSA uses.  */\n+  lattice.create (num_ssa_names);\n+  lattice.quick_grow_cleared (num_ssa_names);\n+  int *postorder = XNEWVEC (int, n_basic_blocks_for_fn (fun));\n+  int postorder_num = inverted_post_order_compute (postorder);\n+  to_purge = BITMAP_ALLOC (NULL);\n+  for (int i = 0; i < postorder_num; ++i)\n     {\n       gimple_stmt_iterator gsi;\n+      basic_block bb = BASIC_BLOCK_FOR_FN (fun, postorder[i]);\n \n       /* Apply forward propagation to all stmts in the basic-block.\n \t Note we update GSI within the loop as necessary.  */\n@@ -3186,6 +3016,7 @@ pass_forwprop::execute (function *fun)\n \t\t  && !stmt_references_abnormal_ssa_name (stmt)\n \t\t  && forward_propagate_addr_expr (lhs, rhs, true))\n \t\t{\n+\t\t  fwprop_invalidate_lattice (gimple_get_lhs (stmt));\n \t\t  release_defs (stmt);\n \t\t  gsi_remove (&gsi, true);\n \t\t}\n@@ -3210,6 +3041,7 @@ pass_forwprop::execute (function *fun)\n \t\t\t\t\t\t fold_convert (ptr_type_node,\n \t\t\t\t\t\t\t       off))), true))\n \t\t{\n+\t\t  fwprop_invalidate_lattice (gimple_get_lhs (stmt));\n \t\t  release_defs (stmt);\n \t\t  gsi_remove (&gsi, true);\n \t\t}\n@@ -3238,11 +3070,27 @@ pass_forwprop::execute (function *fun)\n       for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi);)\n \t{\n \t  gimple stmt = gsi_stmt (gsi);\n+\t  gimple orig_stmt = stmt;\n \t  bool changed = false;\n \n \t  /* Mark stmt as potentially needing revisiting.  */\n \t  gimple_set_plf (stmt, GF_PLF_1, false);\n \n+\t  if (fold_stmt (&gsi, fwprop_ssa_val))\n+\t    {\n+\t      changed = true;\n+\t      stmt = gsi_stmt (gsi);\n+\t      if (maybe_clean_or_replace_eh_stmt (orig_stmt, stmt))\n+\t\tbitmap_set_bit (to_purge, bb->index);\n+\t      /* Cleanup the CFG if we simplified a condition to\n+\t         true or false.  */\n+\t      if (gimple_code (stmt) == GIMPLE_COND\n+\t\t  && (gimple_cond_true_p (stmt)\n+\t\t      || gimple_cond_false_p (stmt)))\n+\t\tcfg_changed = true;\n+\t      update_stmt (stmt);\n+\t    }\n+\n \t  switch (gimple_code (stmt))\n \t    {\n \t    case GIMPLE_ASSIGN:\n@@ -3278,21 +3126,17 @@ pass_forwprop::execute (function *fun)\n \t\t  {\n \t\t    changed = simplify_mult (&gsi);\n \t\t    if (changed\n-\t\t\t&& maybe_clean_or_replace_eh_stmt (stmt, stmt)\n-\t\t\t&& gimple_purge_dead_eh_edges (bb))\n-\t\t      cfg_changed = true;\n+\t\t\t&& maybe_clean_or_replace_eh_stmt (stmt, stmt))\n+\t\t      bitmap_set_bit (to_purge, bb->index);\n \t\t  }\n \t\telse if (code == PLUS_EXPR\n \t\t\t || code == MINUS_EXPR)\n \t\t  {\n \t\t    changed = associate_plusminus (&gsi);\n \t\t    if (changed\n-\t\t\t&& maybe_clean_or_replace_eh_stmt (stmt, stmt)\n-\t\t\t&& gimple_purge_dead_eh_edges (bb))\n-\t\t      cfg_changed = true;\n+\t\t\t&& maybe_clean_or_replace_eh_stmt (stmt, stmt))\n+\t\t      bitmap_set_bit (to_purge, bb->index);\n \t\t  }\n-\t\telse if (code == POINTER_PLUS_EXPR)\n-\t\t  changed = associate_pointerplus (&gsi);\n \t\telse if (CONVERT_EXPR_CODE_P (code)\n \t\t\t || code == FLOAT_EXPR\n \t\t\t || code == FIX_TRUNC_EXPR)\n@@ -3377,13 +3221,32 @@ pass_forwprop::execute (function *fun)\n \t    {\n \t      /* Stmt no longer needs to be revisited.  */\n \t      gimple_set_plf (stmt, GF_PLF_1, true);\n+\n+\t      /* Fill up the lattice.  */\n+\t      if (gimple_assign_single_p (stmt))\n+\t\t{\n+\t\t  tree lhs = gimple_assign_lhs (stmt);\n+\t\t  tree rhs = gimple_assign_rhs1 (stmt);\n+\t\t  if (TREE_CODE (lhs) == SSA_NAME)\n+\t\t    {\n+\t\t      tree val = lhs;\n+\t\t      if (TREE_CODE (rhs) == SSA_NAME)\n+\t\t\tval = fwprop_ssa_val (rhs);\n+\t\t      else if (is_gimple_min_invariant (rhs))\n+\t\t\tval = rhs;\n+\t\t      fwprop_set_lattice_val (lhs, val);\n+\t\t    }\n+\t\t}\n+\n \t      gsi_next (&gsi);\n \t    }\n \t}\n     }\n+  free (postorder);\n+  lattice.release ();\n \n-  /* At the end fold all statements.  */\n-  cfg_changed |= fold_all_stmts (fun);\n+  cfg_changed |= gimple_purge_all_dead_eh_edges (to_purge);\n+  BITMAP_FREE (to_purge);\n \n   if (cfg_changed)\n     todoflags |= TODO_cleanup_cfg;"}]}