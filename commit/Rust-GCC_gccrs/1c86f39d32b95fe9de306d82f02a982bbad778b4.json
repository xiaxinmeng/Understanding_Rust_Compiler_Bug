{"sha": "1c86f39d32b95fe9de306d82f02a982bbad778b4", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWM4NmYzOWQzMmI5NWZlOWRlMzA2ZDgyZjAyYTk4MmJiYWQ3NzhiNA==", "commit": {"author": {"name": "Benjamin Kosnik", "email": "bkoz@gcc.gnu.org", "date": "2004-02-12T01:11:48Z"}, "committer": {"name": "Benjamin Kosnik", "email": "bkoz@gcc.gnu.org", "date": "2004-02-12T01:11:48Z"}, "message": "[multiple changes]\n\n\n2004-02-11  Stefan Olsson  <stefan@xapa.se>\n\n\t* docs/html/ext/mt_allocator.html: New.\n\n2004-02-11  Benjamin Kosnik  <bkoz@redhat.com>\n\n\t* docs/html/20_util/allocator.html: New file, consolidate\n\tallocator information here. Revamp.\n\t* docs/html/documentation.html: Change links.\n\t* docs/html/20_util/howto.html: Same.\n\t* docs/html/ext/howto.html: Same.\n\nFrom-SVN: r77687", "tree": {"sha": "5caf25dbf9a9f9aa18a5e5af6a075584352c60f1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/5caf25dbf9a9f9aa18a5e5af6a075584352c60f1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1c86f39d32b95fe9de306d82f02a982bbad778b4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1c86f39d32b95fe9de306d82f02a982bbad778b4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1c86f39d32b95fe9de306d82f02a982bbad778b4", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1c86f39d32b95fe9de306d82f02a982bbad778b4/comments", "author": null, "committer": null, "parents": [{"sha": "9288d1120423d9743dd6b4c419f201c4749122f6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9288d1120423d9743dd6b4c419f201c4749122f6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9288d1120423d9743dd6b4c419f201c4749122f6"}], "stats": {"total": 1149, "additions": 900, "deletions": 249}, "files": [{"sha": "b74af678a174441f21c611f6bc643ae134339496", "filename": "libstdc++-v3/ChangeLog", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2FChangeLog?ref=1c86f39d32b95fe9de306d82f02a982bbad778b4", "patch": "@@ -1,3 +1,15 @@\n+2004-02-11  Stefan Olsson  <stefan@xapa.se>\n+\n+\t* docs/html/ext/mt_allocator.html: New.\n+\n+2004-02-11  Benjamin Kosnik  <bkoz@redhat.com>\n+\n+\t* docs/html/20_util/allocator.html: New file, consolidate\n+\tallocator information here. Revamp.\n+\t* docs/html/documentation.html: Change links.\n+\t* docs/html/20_util/howto.html: Same.\n+\t* docs/html/ext/howto.html: Same.\n+\n 2004-02-11  Paolo Carlini  <pcarlini@suse.de>\n \n \tPR libstdc++/13731 (first part: write)"}, {"sha": "43aaae7e0794c222336ba3f6558a855eb488ae97", "filename": "libstdc++-v3/docs/html/20_util/allocator.html", "status": "added", "additions": 468, "deletions": 0, "changes": 468, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2F20_util%2Fallocator.html", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2F20_util%2Fallocator.html", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2F20_util%2Fallocator.html?ref=1c86f39d32b95fe9de306d82f02a982bbad778b4", "patch": "@@ -0,0 +1,468 @@\n+<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n+<!DOCTYPE html\n+          PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n+          \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n+\n+<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n+<head>\n+   <meta name=\"AUTHOR\" content=\"pme@gcc.gnu.org (Phil Edwards) and bkoz@gcc.gnu.org (Benjamin Kosnik)\" />\n+   <meta name=\"KEYWORDS\" content=\"c++, libstdc++, g++, allocator, memory\" />\n+   <meta name=\"DESCRIPTION\" content=\"Allocators and allocation\" />\n+   <meta name=\"GENERATOR\" content=\"emacs and ten fingers\" />\n+   <title>Allocators and allocation</title>\n+<link rel=\"StyleSheet\" href=\"../lib3styles.css\" type=\"text/css\" />\n+<link rel=\"Copyright\" href=\"../17_intro/license.html\" type=\"text/html\" />\n+</head>\n+<body>\n+\n+<h1 class=\"centered\"><a name=\"top\">Allocators and allocation</a></h1>\n+\n+<p class=\"fineprint\"><em>\n+   The latest version of this document is always available at\n+   <a href=\"http://gcc.gnu.org/onlinedocs/libstdc++/20_util/allocator.html\">\n+   http://gcc.gnu.org/onlinedocs/libstdc++/20_util/allocator.html</a>.\n+</em></p>\n+\n+<p><em>\n+   To the <a href=\"http://gcc.gnu.org/libstdc++/\">libstdc++-v3 homepage</a>.\n+</em></p>\n+\n+<!-- ####################################################### -->\n+<hr />\n+<p> The C++ Standard encapsulates memory management characteristics\n+   for strings, container classes, and parts of iostreams in a\n+   template class called <code>std::allocator</code>.\n+</p>\n+\n+<h3 class=\"left\">\n+  <a name=\"standard requirements\">Standard requirements</a>\n+</h3>\n+   <p>The C++ standard only gives a few directives in this area:\n+   </p>\n+   <ul>\n+     <li>When you add elements to a container, and the container must allocate\n+         more memory to hold them, the container makes the request via its\n+         <code>Allocator</code> template parameter.  This includes adding\n+         chars to the string class, which acts as a regular STL container\n+         in this respect.\n+     </li>\n+     <li>The default <code>Allocator</code> of every container-of-T is\n+         <code>std::allocator&lt;T&gt;</code>.\n+     </li>\n+     <li>The interface of the <code>allocator&lt;T&gt;</code> class is\n+         extremely simple.  It has about 20 public declarations (nested\n+         typedefs, member functions, etc), but the two which concern us most\n+         are:\n+         <pre>\n+      T*    allocate   (size_type n, const void* hint = 0);\n+      void  deallocate (T* p, size_type n);</pre>\n+         (This is a simplification; the real signatures use nested typedefs.)\n+         The <code>&quot;n&quot;</code> arguments in both those functions is a\n+         <em>count</em> of the number of T's to allocate space for,\n+         <em>not their total size</em>.\n+     </li>\n+     <li>&quot;The storage is obtained by calling\n+         <code>::operator new(size_t)</code>, but it is unspecified when or\n+         how often this function is called.  The use of <code>hint</code>\n+         is unspecified, but intended as an aid to locality if an\n+         implementation so desires.&quot; [20.4.1.1]/6\n+      </li>\n+   </ul>\n+\n+   <p> Complete details cam be found in the C++ standard, look in\n+   [20.4 Memory].\n+   </p>\n+\n+<h3 class=\"left\">\n+  <a name=\"probs possibilities\">Problems and Possibilities</a>\n+</h3>\n+   <p>The easiest way of fulfilling the requirements is to call operator new\n+      each time a container needs memory, and to call operator delete each\n+      time the container releases memory.  <strong>BUT</strong>\n+      <a href=\"http://gcc.gnu.org/ml/libstdc++/2001-05/msg00105.html\">this\n+      method is horribly slow</a>.\n+   </p>\n+   <p>Or we can keep old memory around, and reuse it in a pool to save time.\n+      The old libstdc++-v2 used a memory pool, and so do we.  As of 3.0,\n+      <a href=\"http://gcc.gnu.org/ml/libstdc++/2001-05/msg00136.html\">it's\n+      on by default</a>.  The pool is shared among all the containers in the\n+      program:  when your program's std::vector&lt;int&gt; gets cut in half\n+      and frees a bunch of its storage, that memory can be reused by the\n+      private std::list&lt;WonkyWidget&gt; brought in from a KDE library\n+      that you linked against.  And we don't have to call operators new and\n+      delete to pass the memory on, either, which is a speed bonus.\n+      <strong>BUT</strong>...\n+   </p>\n+   <p>What about threads?  No problem:  in a threadsafe environment, the\n+      memory pool is manipulated atomically, so you can grow a container in\n+      one thread and shrink it in another, etc.  <strong>BUT</strong> what\n+      if threads in libstdc++-v3 aren't set up properly?\n+      <a href=\"../faq/index.html#5_6\">That's been answered already</a>.\n+   </p>\n+   <p><strong>BUT</strong> what if you want to use your own allocator?  What\n+      if you plan on using a runtime-loadable version of malloc() which uses\n+      shared telepathic anonymous mmap'd sections serializable over a\n+      network, so that memory requests <em>should</em> go through malloc?\n+      And what if you need to debug it?\n+   </p>\n+\n+<h3 class=\"left\">\n+  <a name=\"stdallocator\">Implementation details of <code>std::allocator</code></a>\n+</h3>\n+   <p> The implementation of <code> std::allocator</code> has continued\n+      to evolve through successive releases. Here's a brief history.\n+   </p>\n+\n+<h5 class=\"left\">\n+  <a name=\"30allocator\"> 3.0, 3.1, 3.2, 3.3 </a>\n+</h5>\n+   <p> During this period, all allocators were written to the SGI\n+   style, and all STL containers expected this interface. This\n+   interface had a traits class called <code>_Alloc_traits</code> that\n+   attempted to provide more information for compile-time allocation\n+   selection and optimization. This traits class had another allocator\n+   wrapper, <code>__simple_alloc&lt;T,A&gt;</code>, which was a\n+   wrapper around another allocator, A, which itself is an allocator\n+   for instances of T. But wait, there's more:\n+   <code>__allocator&lt;T,A&gt;</code> is another adapter.  Many of\n+   the provided allocator classes were SGI style: such classes can be\n+   changed to a conforming interface with this wrapper:\n+   <code>__allocator&lt;T, __alloc&gt;</code> is thus the same as\n+   <code>allocator&lt;T&gt;</code>.\n+   </p>\n+\n+   <p> The class <code>std::allocator</code> use the typedef\n+   <code>__alloc</code> to select an underlying allocator that\n+   satisfied memory allocation requests. The selection of this\n+   underlying allocator was not user-configurable.\n+   </p>\n+\n+<h5 class=\"left\">\n+  <a name=\"34allocator\"> 3.4 </a>\n+</h5>\n+   <p> For this and later releases, the only allocator interface that\n+   is support is the standard C++ interface. As such, all STL\n+   containers have been adjusted, and all external allocators have\n+   been modified to support this change. Because of this,\n+   <code>__simple_alloc, __allocator, __alloc, </code> and <code>\n+   _Alloc_traits</code> have all been removed.\n+   </p>\n+\n+   <p> The class <code>std::allocator</code> just has typedef,\n+   constructor, and rebind members. It inherits from one of the\n+   high-speed extension allocators, covered below. Thus, all\n+   allocation and deallocation depends on the base class.\n+   </p>\n+\n+  <p> The base class that <code>std::allocator</code> is derived from\n+  is not user-configurable.\n+  </p>\n+\n+<h5 class=\"left\">\n+  <a name=\"benchmarks\"> How the default allocation strategy is selected.</a>\n+</h5>\n+   <p> It's difficult to pick an allocation strategy that will provide\n+   maximum utility, without excessively penalizing some behavior. In\n+   fact, it's difficult just deciding which typical actions to measure\n+   for speed.\n+   </p>\n+\n+   <p> Three synthetic benchmarks have been created that provide data\n+   that is used to compare different C++ allocators. These tests are:\n+   </p>\n+\n+   <ul>\n+     <li>Insertion. Over multiple iterations, various STL container\n+     objects have elements inserted to some maximum amount. A variety\n+     of allocators are tested.  \n+     Test source <a\n+     href=\"http://gcc.gnu.org/cgi-bin/cvsweb.cgi/gcc/libstdc%2b%2b-v3/testsuite/performance/20_util/allocator/insert.cc?only_with_tag=MAIN\">here.</a>\n+     </li>\n+\n+     <li>Insertion, clear, and re-insertion in a multi-threaded\n+     environment.  Over multiple iterations, several threads are\n+     started that insert elements into a STL container, then assign a\n+     null instance of the same type to clear memory, and then\n+     re-insert the same number of elements. Several STL containers and\n+     multiple allocators are tested. This test shows the ability of\n+     the allocator to reclaim memory on a pre-thread basis, as well as\n+     measuring thread contention for memory resources. \n+     Test source \n+    <a href=\"http://gcc.gnu.org/cgi-bin/cvsweb.cgi/gcc/libstdc%2b%2b-v3/testsuite/performance/20_util/allocator/insert_insert.cc\"> \n+    here.</a>\n+     </li>\n+\n+     <li>A threaded producer/consumer model.\n+     Test source \n+    <a href=\"http://gcc.gnu.org/cgi-bin/cvsweb.cgi/gcc/libstdc%2b%2b-v3/testsuite/performance/20_util/allocator/producer_consumer.cc\"> \n+    here.</a>\n+     </li>\n+   </ul>\n+\n+<h5 class=\"left\">\n+  <a name=\"forcenew\"> Disabling memory caching.</a>\n+</h5>\n+   <p> In use, <code>std::allocator</code> may allocate and deallocate\n+   using implementation-specified strategies and heuristics. Because of\n+   this, every call to an allocator object's <code> allocate</code>\n+   member function may not actually call the global operator new. This\n+   situation is also duplicated for calls to the <code>\n+   deallocate</code> member function.\n+   </p>\n+\n+   <p> This can be confusing. \n+   </p>\n+\n+   <p> In particular, this can make debugging memory errors more\n+   difficult, especially when using third party tools like valgrind or\n+   debug versions of <code> new</code>. \n+   </p>\n+\n+   <p> There are various ways to solve this problem. One would be to\n+   use a custom allocator that just called operators <code> new\n+   </code> and <code> delete</code> directly, for every\n+   allocation. (See include/ext/new_allocator.h, for instance.)\n+   However, that option would involve changing source code to use the a\n+   non-default allocator. Another option is to force the default\n+   allocator to remove caching and pools, and to directly allocate\n+   with every call of <code> allocate</code> and directly deallocate\n+   with every call of <code> deallocate</code>, regardless of\n+   efficiency. As it turns out, this last option is available,\n+   although the exact mechanism has evolved with time.\n+   </p>\n+\n+   <p> For GCC releases from 2.95 through the 3.1 series, defining\n+   <code>__USE_MALLOC</code> on the gcc command line would change the\n+   default allocation strategy to instead use <code> malloc</code> and\n+   <code> free</code>. See \n+   <a href=\"../23_containers/howto.html#3\">this note</a> \n+   for details as to why this was something needing improvement.\n+   </p> \n+\n+   <p>Starting with GCC 3.2, and continued in the 3.3 series, to\n+      globally disable memory caching within the library for the\n+      default allocator, merely set GLIBCPP_FORCE_NEW (at this time,\n+      with any value) in the system's environment before running the\n+      program. If your program crashes with GLIBCPP_FORCE_NEW in the\n+      environment, it likely means that you linked against objects\n+      built against the older library.  Code to support this extension\n+      is fully compatible with 3.2 code if GLIBCPP_FORCE_NEW is not in\n+      the environment. \n+   </p>\n+\n+   <p> As it turns out, the 3.4 code base continues to use this\n+   mechanism, only the environment variable has been changed to\n+   GLIBCXX_FORCE_NEW.\n+   </p> \n+\n+<h3 class=\"left\">\n+  <a name=\"ext allocators\">Other allocators</a>\n+</h3>\n+   <p> Several other allocators are provided as part of this\n+   implementation.  The location of the extension allocators and their\n+   names have changed, but in all cases, functionality is\n+   equivalent. Starting with gcc-3.4, all extension allocators are\n+   standard style. Before this point, SGI style was the norm. Because of\n+   this, the number of template arguments also changed. Here's a simple\n+   chart to track the changes.\n+   </p>\n+\n+<table title=\"extension allocators\" border=\"1\">\n+  <tr>\n+    <th>Allocator (3.4)</th>\n+    <th>Header (3.4)</th>\n+    <th>Allocator (3.[0-3])</th>\n+    <th>Header (3.[0-3])</th>\n+  </tr>\n+  <tr>\n+    <td>__gnu_cxx::new_allocator&lt;T&gt;</td>\n+    <td>&lt;ext/new_allocator.h&gt;</td>\n+    <td>std::__new_alloc</td>\n+    <td>&lt;memory&gt;</td>\n+  </tr>\n+  <tr>\n+    <td>__gnu_cxx::malloc_allocator&lt;T&gt;</td>\n+    <td>&lt;ext/malloc_allocator.h&gt;</td>\n+    <td>std::__malloc_alloc_template&lt;int&gt;</td>\n+    <td>&lt;memory&gt;</td>\n+  </tr>\n+  <tr>\n+    <td>__gnu_cxx::debug_allocator&lt;T&gt;</td>\n+    <td>&lt;ext/debug_allocator.h&gt;</td>\n+    <td>std::debug_alloc&lt;T&gt;</td>\n+    <td>&lt;memory&gt;</td>\n+  </tr>\n+  <tr>\n+    <td>__gnu_cxx::__pool_alloc&lt;bool, int&gt;</td>\n+    <td>&lt;ext/pool_allocator.h&gt;</td>\n+    <td>std::__default_alloc_template&lt;bool,int&gt;</td>\n+    <td>&lt;memory&gt;</td>\n+  </tr>\n+  <tr>\n+    <td>__gnu_cxx::__mt_alloc&lt;T&gt;</td>\n+    <td>&lt;ext/mt_allocator.h&gt;</td>\n+    <td></td>\n+    <td></td>\n+  </tr>\n+</table>\n+\n+   <p>More details on each of these allocators follows. </p>\n+   <ul>\n+     <li><code>new_allocator</code> \n+     <p>Simply wraps <code>::operator new</code>\n+         and <code>::operator delete</code>.\n+     </p>\n+     </li>\n+     <li><code>malloc_allocator</code> \n+     <p>Simply wraps\n+         <code>malloc</code> and <code>free</code>.  There is also a hook\n+         for an out-of-memory handler (for new/delete this is taken care of\n+         elsewhere).  \n+     </p>\n+     </li>\n+     <li><code>debug_allocator</code> \n+     <p> A wrapper around an\n+         arbitrary allocator A.  It passes on slightly increased size\n+         requests to A, and uses the extra memory to store size information.\n+         When a pointer is passed to <code>deallocate()</code>, the stored\n+         size is checked, and assert() is used to guarantee they match. \n+     </p>\n+     </li>\n+     <li><code>__pool_alloc</code>\n+     <p> A high-performance, single pool allocator.  The reusable\n+      memory is shared among identical instantiations of this type.\n+      It calls through <code>::operator new</code> to obtain new memory\n+      when its lists run out.  If a client container requests a block\n+      larger than a certain threshold size, then the pool is bypassed,\n+      and the allocate/deallocate request is passed to\n+      <code>::operator new</code> directly.  </p>\n+\n+   <p> This class take a boolean template parameter, called\n+      <code>thr</code>, and an integer template parameter, called\n+      <code>inst</code>.\n+   </p>\n+   <p>The <code>inst</code> number is used to track additional memory\n+      pools.  The point of the number is to allow multiple\n+      instantiations of the classes without changing the semantics at\n+      all.  All three of\n+   </p>\n+\n+   <pre>\n+    typedef  __pool_alloc&lt;true,0&gt;    normal;\n+    typedef  __pool_alloc&lt;true,1&gt;    private;\n+    typedef  __pool_alloc&lt;true,42&gt;   also_private;</pre>\n+   <p>behave exactly the same way.  However, the memory pool for each type\n+      (and remember that different instantiations result in different types)\n+      remains separate.\n+   </p>\n+   <p>The library uses <strong>0</strong> in all its instantiations.  If you\n+      wish to keep separate free lists for a particular purpose, use a\n+      different number.\n+   </p>\n+   <p>The <code>thr</code> boolean determines whether the pool should\n+      be manipulated atomically or not.  When thr=true, the allocator\n+      is is threadsafe, while thr=false, and is slightly faster but\n+      unsafe for multiple threads.\n+   </p>\n+   <p>(Note that the GCC thread abstraction layer allows us to provide safe\n+      zero-overhead stubs for the threading routines, if threads were\n+      disabled at configuration time.)\n+   </p>\n+\n+     </li>\n+\n+     <li><code>__mt_alloc</code> \n+     <p>A high-performance\n+     fixed-size allocator. It has its own documentation, found <a\n+     href=\"../ext/mt_allocator.html\">here</a>.\n+     </p>\n+     </li>\n+   </ul>\n+\n+\n+<h3 class=\"left\">\n+  <a name=\"using custom allocators\">Using a specific allocator</a>\n+</h3>\n+   <p>You can specify different memory management schemes on a\n+      per-container basis, by overriding the default\n+      <code>Allocator</code> template parameter.  For example, an easy\n+      (but non-portable) method of specifying that only malloc/free\n+      should be used instead of the default node allocator is:\n+   </p>\n+   <pre>\n+    std::list &lt;int, __gnu_cxx::malloc_allocator&lt;int&gt; &gt;  malloc_list;</pre>\n+      Likewise, a debugging form of whichever allocator is currently in use:\n+      <pre>\n+    std::deque &lt;int, __gnu_cxx::debug_allocator&lt;std::allocator&lt;int&gt; &gt; &gt;  debug_deque;</pre>\n+\n+\n+<h3 class=\"left\">\n+  <a name=\"custom allocators\">Writing custom allocators</a>\n+</h3>\n+   <p> Writing a portable C++ allocator would dictate that the\n+   interface would look much like the one specified for <code>\n+   std::allocator</code>. Additional member functions, but not\n+   subtractions, would be permissible.\n+   </p>\n+\n+   <p> Probably the best place to start would be to copy one of the\n+   extension allocators already shipped with libstdc++: say, <code>\n+   new_allocator </code>.\n+   </p>\n+\n+\n+<h3 class=\"left\">\n+  <a name=\"biblio\">Bibliography / Further Reading</a>\n+</h3>\n+   <p>\n+   ISO/IEC 14882:1998 Programming languages - C++ [20.4 Memory]\n+   </p>\n+\n+   <p>\n+   Austern, Matt, C/C++ Users Journal.\n+   <a href=\"http://www.cuj.com/documents/s=8000/cujcexp1812austern/\">The Standard Librarian: What Are Allocators Good\n+   For?</a>\n+   </p>\n+\n+   <p>\n+   Berger, Emery, \n+   <a href=\"http://www.cs.umass.edu/~emery/hoard/\"> The Hoard memory allocator </a>\n+   </p>\n+\n+   <p>\n+   Berger, Emery with Ben Zorn & Kathryn McKinley, OOPSLA 2002\n+   <a href=\"http://www.cs.umass.edu/~emery/pubs/berger-oopsla2002.pdf\">Reconsidering Custom Memory Allocation</a>\n+   </p>\n+\n+   <p>\n+   Kreft, Klaus and Angelika Langer, C++ Report, June 1998\n+   <a href=\"http://www.langer.camelot.de/Articles/C++Report/Allocators/Allocators.html\">Allocator Types</a>\n+   </p>\n+\n+   <p>\n+   Stroustrup, Bjarne, 19.4 Allocators, The C++ Programming\n+   Language, Special Edition, Addison Wesley, Inc. 2000\n+   </p>\n+\n+   <p>\n+   Yen, Felix, <a href=\"http://home.earthlink.net/~brimar/yalloc/\">Yalloc: A Recycling C++ Allocator</a>\n+   </p>\n+\n+<hr />\n+<p>Return <a href=\"#top\">to the top of the page</a> or\n+   <a href=\"http://gcc.gnu.org/libstdc++/\">to the libstdc++ homepage</a>.\n+</p>\n+\n+\n+<!-- ####################################################### -->\n+\n+<hr />\n+<p class=\"fineprint\"><em>\n+See <a href=\"../17_intro/license.html\">license.html</a> for copying conditions.\n+Comments and suggestions are welcome, and may be sent to\n+<a href=\"mailto:libstdc++@gcc.gnu.org\">the libstdc++ mailing list</a>.\n+</em></p>\n+\n+\n+</body>\n+</html>"}, {"sha": "9597707a8be3018effa5cbad8837fca86a6e27d9", "filename": "libstdc++-v3/docs/html/20_util/howto.html", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2F20_util%2Fhowto.html", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2F20_util%2Fhowto.html", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2F20_util%2Fhowto.html?ref=1c86f39d32b95fe9de306d82f02a982bbad778b4", "patch": "@@ -219,7 +219,7 @@ <h2><a name=\"4\">Pairs</a></h2>\n <hr />\n <h2><a name=\"5\">Memory allocators</a></h2>\n    <p>The available free store (&quot;heap&quot;) management classes are\n-      described <a href=\"../ext/howto.html\">here</a>.\n+      described <a href=\"allocator.html\">here</a>.\n    </p>\n    <p>Return <a href=\"#top\">to top of page</a> or\n       <a href=\"../faq/index.html\">to the FAQ</a>."}, {"sha": "54bd59e8745feea912b9521779fdec32f56bcd33", "filename": "libstdc++-v3/docs/html/documentation.html", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fdocumentation.html", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fdocumentation.html", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fdocumentation.html?ref=1c86f39d32b95fe9de306d82f02a982bbad778b4", "patch": "@@ -126,8 +126,8 @@ <h2><a name=\"3\">Chapter-Specific Documentation</a></h2>\n      <li><a href=\"18_support/howto.html#2\">Implementation properties</a></li>\n      <li><a href=\"18_support/howto.html#3\">Start and Termination</a></li>\n      <li><a href=\"18_support/howto.html#4\">Verbose <code>terminate</code></a></li>\n-     <li><a href=\"18_support/howto.html#6\">Dynamic memory management</a></li>\n-     <li><a href=\"18_support/howto.html#7\">RTTI, the ABI, and demangling</a></li>\n+     <li><a href=\"18_support/howto.html#5\">Dynamic memory management</a></li>\n+     <li><a href=\"18_support/howto.html#6\">RTTI, the ABI, and demangling</a></li>\n    </ul>\n    </li>\n \n@@ -145,7 +145,7 @@ <h2><a name=\"3\">Chapter-Specific Documentation</a></h2>\n      <li><a href=\"20_util/howto.html#2\"><code>auto_ptr</code> inside container classes</a></li>\n      <li><a href=\"20_util/howto.html#3\">Functors</a></li>\n      <li><a href=\"20_util/howto.html#4\">Pairs</a></li>\n-     <li><a href=\"20_util/howto.html#5\">Memory allocators</a></li>\n+     <li><a href=\"20_util/allocator.html\">Allocators and allocation</a></li>\n    </ul>\n    </li>\n \n@@ -226,8 +226,7 @@ <h2><a name=\"3\">Chapter-Specific Documentation</a></h2>\n    <ul>\n      <li><a href=\"ext/howto.html#1\">Ropes and trees and hashes, oh my!</a></li>\n      <li><a href=\"ext/howto.html#2\">Added members and types</a></li>\n-     <li><a href=\"ext/howto.html#3\">Allocators (versions 3.0, 3.1, 3.2, 3.3)</a></li>\n-     <li><a href=\"ext/howto.html#6\">Allocators (version 3.4)</a></li>\n+     <li><a href=\"ext/mt_allocator.html\"><code>__mt_alloc</code> </a></li>\n      <li><a href=\"ext/howto.html#4\">Compile-time checks</a></li>\n      <li><a href=\"ext/howto.html#5\">LWG Issues</a></li>\n      <li><a href=\"ext/../18_support/howto.html#5\">Demangling</a></li>"}, {"sha": "3e5c35c476cd8df343b960ed286bb158f90bdc38", "filename": "libstdc++-v3/docs/html/ext/howto.html", "status": "modified", "additions": 1, "deletions": 243, "changes": 244, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fext%2Fhowto.html", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fext%2Fhowto.html", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fext%2Fhowto.html?ref=1c86f39d32b95fe9de306d82f02a982bbad778b4", "patch": "@@ -48,8 +48,7 @@ <h1>Contents</h1>\n <ul>\n    <li><a href=\"#1\">Ropes and trees and hashes, oh my!</a></li>\n    <li><a href=\"#2\">Added members and types</a></li>\n-   <li><a href=\"#3\">Allocators (versions 3.0, 3.1, 3.2, 3.3)</a></li>\n-   <li><a href=\"#6\">Allocators (version 3.4)</a></li>\n+   <li><a href=\"mt_allocator.html\"><code>__mt_alloc</code> </a></li>\n    <li><a href=\"#4\">Compile-time checks</a></li>\n    <li><a href=\"#5\">LWG Issues</a></li>\n    <li><a href=\"../18_support/howto.html#5\">Demangling</a></li>\n@@ -140,247 +139,6 @@ <h2><a name=\"2\">Added members and types</a></h2>\n       <a href=\"../faq/index.html\">to the FAQ</a>.\n    </p>\n \n-<hr />\n-<h2><a name=\"3\">Allocators (versions 3.0, 3.1, 3.2, 3.3)</a></h2>\n-   <p>Thread-safety, space efficiency, high speed, portability... this is a\n-      mess.  Where to begin?\n-   </p>\n-   <h3>The Rules</h3>\n-   <p>The C++ standard only gives a few directives in this area:\n-   </p>\n-   <ul>\n-     <li>When you add elements to a container, and the container must allocate\n-         more memory to hold them, the container makes the request via its\n-         <code>Allocator</code> template parameter.  This includes adding\n-         char's to the string class, which acts as a regular STL container\n-         in this respect.\n-     </li>\n-     <li>The default <code>Allocator</code> of every container-of-T is\n-         <code>std::allocator&lt;T&gt;</code>.\n-     </li>\n-     <li>The interface of the <code>allocator&lt;T&gt;</code> class is\n-         extremely simple.  It has about 20 public declarations (nested\n-         typedefs, member functions, etc), but the two which concern us most\n-         are:\n-         <pre>\n-      T*    allocate   (size_type n, const void* hint = 0);\n-      void  deallocate (T* p, size_type n);</pre>\n-         (This is a simplicifcation; the real signatures use nested typedefs.)\n-         The <code>&quot;n&quot;</code> arguments in both those functions is a\n-         <em>count</em> of the number of T's to allocate space for,\n-         <em>not their total size</em>.\n-     </li>\n-     <li>&quot;The storage is obtained by calling\n-         <code>::operator new(size_t)</code>, but it is unspecified when or\n-         how often this function is called.  The use of <code>hint</code>\n-         is unspecified, but intended as an aid to locality if an\n-         implementation so desires.&quot; [20.4.1.1]/6\n-      </li>\n-   </ul>\n-   <h3>Problems and Possibilities</h3>\n-   <p>The easiest way of fulfilling the requirements is to call operator new\n-      each time a container needs memory, and to call operator delete each\n-      time the container releases memory.  <strong>BUT</strong>\n-      <a href=\"http://gcc.gnu.org/ml/libstdc++/2001-05/msg00105.html\">this\n-      method is horribly slow</a>.\n-   </p>\n-   <p>Or we can keep old memory around, and reuse it in a pool to save time.\n-      The old libstdc++-v2 used a memory pool, and so do we.  As of 3.0,\n-      <a href=\"http://gcc.gnu.org/ml/libstdc++/2001-05/msg00136.html\">it's\n-      on by default</a>.  The pool is shared among all the containers in the\n-      program:  when your program's std::vector&lt;int&gt; gets cut in half\n-      and frees a bunch of its storage, that memory can be reused by the\n-      private std::list&lt;WonkyWidget&gt; brought in from a KDE library\n-      that you linked against.  And we don't have to call operators new and\n-      delete to pass the memory on, either, which is a speed bonus.\n-      <strong>BUT</strong>...\n-   </p>\n-   <p>What about threads?  No problem:  in a threadsafe environment, the\n-      memory pool is manipulated atomically, so you can grow a container in\n-      one thread and shrink it in another, etc.  <strong>BUT</strong> what\n-      if threads in libstdc++-v3 aren't set up properly?\n-      <a href=\"../faq/index.html#5_6\">That's been answered already</a>.\n-   </p>\n-   <p><strong>BUT</strong> what if you want to use your own allocator?  What\n-      if you plan on using a runtime-loadable version of malloc() which uses\n-      shared telepathic anonymous mmap'd sections serializable over a\n-      network, so that memory requests <em>should</em> go through malloc?\n-      And what if you need to debug it?\n-   </p>\n-   <p>Well then:\n-   </p>\n-   <h3>Available allocators in namespace std</h3>\n-   <p>First I'll describe the situation as it exists for the code which\n-      was released in GCC 3.1 and 3.2.  Then I'll describe the differences\n-      for 3.0.  The allocator classes also have source documentation,\n-      which is described <a href=\"../documentation.html#4\">here</a> (you\n-      will need to retrieve the maintainer-level docs, as almost none of\n-      these entities are in the ISO standard).\n-   </p>\n-   <p>As a general rule of thumb, users are not allowed to use names which\n-      begin with an underscore.  This means that to be portable between\n-      compilers, none of the following may be used in your program directly.\n-      (If you decide to be unportable, then you're free do do what you want,\n-      but it's not our fault if stuff breaks.)  They are presented here for\n-      information for maintainers and contributors in addition to users.\n-   </p>\n-   <p>These classes are always available:\n-   </p>\n-   <ul>\n-     <li><code>__new_alloc</code> simply wraps <code>::operator new</code>\n-         and <code>::operator delete</code>.\n-     </li>\n-     <li><code>__malloc_alloc_template&lt;int inst&gt;</code> simply wraps\n-         <code>malloc</code> and <code>free</code>.  There is also a hook\n-         for an out-of-memory handler (for new/delete this is taken care of\n-         elsewhere).  The <code>inst</code> parameter is described below.\n-         This class was called <code>malloc_alloc</code> in earlier versions.\n-     </li>\n-     <li><code>allocator&lt;T&gt;</code> has already been described; it is\n-         The Standard Allocator for instances of T.  It uses the internal\n-         <code>__alloc</code> typedef (see below) to satisy its requests.\n-     </li>\n-     <li><code>__simple_alloc&lt;T,A&gt;</code> is a wrapper around another\n-         allocator, A, which itself is an allocator for instances of T.\n-         This is primarily used in an internal &quot;allocator traits&quot;\n-         class which helps encapsulate the different styles of allocators.\n-     </li>\n-     <li><code>__debug_alloc&lt;A&gt;</code> is also a wrapper around an\n-         arbitrary allocator A.  It passes on slightly increased size\n-         requests to A, and uses the extra memory to store size information.\n-         When a pointer is passed to <code>deallocate()</code>, the stored\n-         size is checked, and assert() is used to guarantee they match.\n-     </li>\n-     <li><code>__allocator&lt;T,A&gt;</code> is an adaptor.  Many of these\n-         allocator classes have a consistent yet non-standard interface.\n-         Such classes can be changed to a conforming interface with this\n-         wrapper:  <code>__allocator&lt;T, __alloc&gt;</code> is thus the\n-         same as <code>allocator&lt;T&gt;</code>.\n-     </li>\n-   </ul>\n-   <p>Normally,\n-      <code> __default_alloc_template&lt;bool thr, int inst&gt; </code>\n-      is also available.  This is the high-speed pool, called the default\n-      node allocator.  The reusable memory is shared among identical\n-      instantiations of\n-      this type.  It calls through <code>__new_alloc</code> to obtain\n-      new memory when its lists run out.  If a client container requests a\n-      block larger than a certain threshold size, then the pool is bypassed,\n-      and the allocate/deallocate request is passed to\n-      <code>__new_alloc</code> directly.\n-   </p>\n-   <p>Its <code>inst</code> parameter is described below.  The\n-      <code>thr</code> boolean determines whether the pool should be\n-      manipulated atomically or not.  Two typedefs are provided:\n-      <code>__alloc</code> is defined as this node allocator with thr=true,\n-      and therefore is threadsafe, while <code>__single_client_alloc</code>\n-      defines thr=false, and is slightly faster but unsafe for multiple\n-      threads.\n-   </p>\n-   <p>(Note that the GCC thread abstraction layer allows us to provide safe\n-      zero-overhead stubs for the threading routines, if threads were\n-      disabled at configuration time.  In this situation,\n-      <code>__alloc</code> should not be noticably slower than\n-      <code>__single_client_alloc</code>.)\n-   </p>\n-   <p>[Another threadsafe allocator where each thread keeps its own free\n-      list, so that no locking is needed, might be described here.]\n-   </p>\n-   <h3>A cannon to swat a fly:<code>  __USE_MALLOC</code></h3>\n-   <p>If you've already read <a href=\"../23_containers/howto.html#3\">this\n-      advice</a> but still think you remember how to use this macro from\n-      SGI STL days.  We have removed it in gcc 3.3.  See next section\n-      for the new way to get the same effect.\n-   </p>\n-   <h3>Globally disabling memory caching:<code>  GLIBCXX_FORCE_NEW</code></h3>\n-   <p>Starting with gcc 3.3, if you want to globally disable memory\n-      caching within the library for the default allocator (i.e.\n-      the one you get for all library objects when you do not specify\n-      which one to use), merely set GLIBCXX_FORCE_NEW (at this time,\n-      with any value) into your environment before running the\n-      program.  You will obtain a similar effect without having to\n-      recompile your entire program and the entire library (the new\n-      operator in gcc is a light wrapper around malloc).  If your\n-      program crashes with GLIBCXX_FORCE_NEW in the environment,\n-      it likely means that you linked against objects built against\n-      the older library.  Code to support this extension is fully\n-      compatible with 3.2 code if GLIBCXX_FORCE_NEW is not in the\n-      environment. Prior to GCC 3.4, this variable was spelt\n-      GLIBCPP_FORCE_NEW.\n-   </p>\n-   <h3>Writing your own allocators</h3>\n-   <p>Depending on your application (a specific program, a generic library,\n-      etc), allocator classes tend to be one of two styles:  &quot;SGI&quot;\n-      or &quot;standard&quot;.  See the comments in stl_alloc.h for more\n-      information on this crucial difference.\n-   </p>\n-   <p>At the bottom of that header is a helper type,\n-      <code>_Alloc_traits</code>, and various specializations of it.  This\n-      allows the container classes to make possible compile-time\n-      optimizations based on features of the allocator.  You should provide\n-      a specialization of this type for your allocator (doing so takes only\n-      two or three statements).\n-   </p>\n-   <h3>Using non-default allocators</h3>\n-   <p>You can specify different memory management schemes on a per-container\n-      basis, by overriding the default <code>Allocator</code> template\n-      parameter.  For example, an easy\n-      (but nonportable)\n-      method of specifying that only malloc/free should be used instead of\n-      the default node allocator is:\n-   </p>\n-   <pre>\n-    std::list &lt;my_type, std::__malloc_alloc_template&lt;0&gt; &gt;  my_malloc_based_list;</pre>\n-      Likewise, a debugging form of whichever allocator is currently in use:\n-      <pre>\n-    std::deque &lt;my_type, std::__debug_alloc&lt;std::__alloc&gt; &gt;  debug_deque;</pre>\n-   <h3><code>inst</code></h3>\n-   <p>The <code>__malloc_alloc_template</code> and\n-      <code>__default_alloc_template</code> classes take an integer parameter,\n-      called inst here.  This number is completely unused.\n-   </p>\n-   <p>The point of the number is to allow multiple instantiations of the\n-      classes without changing the semantics at all.  All three of\n-   </p>\n-   <pre>\n-    typedef  __default_alloc_template&lt;true,0&gt;    normal;\n-    typedef  __default_alloc_template&lt;true,1&gt;    private;\n-    typedef  __default_alloc_template&lt;true,42&gt;   also_private;</pre>\n-   <p>behave exactly the same way.  However, the memory pool for each type\n-      (and remember that different instantiations result in different types)\n-      remains separate.\n-   </p>\n-   <p>The library uses <strong>0</strong> in all its instantiations.  If you\n-      wish to keep separate free lists for a particular purpose, use a\n-      different number.\n-   </p>\n-   <h3>3.0.x</h3>\n-   <p>For 3.0.x, many of the names were incorrectly <em>not</em> prefixed\n-      with underscores.  So symbols such as &quot;std::single_client_alloc&quot;\n-      are present.  Be very careful to not depend on these names any more\n-      than you would depend on implementation-only names.\n-   </p>\n-   <p>Certain macros like <code>_NOTHREADS</code> and <code>__STL_THREADS</code>\n-      can affect the 3.0.x allocators.  Do not use them.  Those macros have\n-      been completely removed for 3.1.\n-   </p>\n-   <p>Return <a href=\"#top\">to top of page</a> or\n-      <a href=\"../faq/index.html\">to the FAQ</a>.\n-   </p>\n-\n-<hr />\n-<h2><a name=\"6\">Allocators (version 3.4)</a></h2>\n-   <p>Changes are coming...\n-   </p>\n-   <p>If you plan on writing your own allocators,\n-      <a href=\"../documentation.html#4\">source documentation</a> is\n-      available.  You'll need to get the &quot;maintainers&quot; collection\n-      in order to see the helper classes and extra notes.\n-   </p>\n-   <p>Return <a href=\"#top\">to top of page</a> or\n-      <a href=\"../faq/index.html\">to the FAQ</a>.\n-   </p>\n-\n <hr />\n <h2><a name=\"4\">Compile-time checks</a></h2>\n    <p>Currently libstdc++-v3 uses the concept checkers from the Boost"}, {"sha": "93a5bfb8ee0533a11b7050ae2ab5289aaf86abd2", "filename": "libstdc++-v3/docs/html/ext/mt_allocator.html", "status": "added", "additions": 414, "deletions": 0, "changes": 414, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fext%2Fmt_allocator.html", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c86f39d32b95fe9de306d82f02a982bbad778b4/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fext%2Fmt_allocator.html", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Fdocs%2Fhtml%2Fext%2Fmt_allocator.html?ref=1c86f39d32b95fe9de306d82f02a982bbad778b4", "patch": "@@ -0,0 +1,414 @@\n+<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n+<!DOCTYPE html\n+          PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n+          \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n+\n+<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n+<head>\n+   <meta name=\"AUTHOR\" content=\"Stefan Olsson <stefan@xapa.se>\" />\n+   <meta name=\"KEYWORDS\" content=\"c++, libstdc++, g++, allocator, memory\" />\n+   <meta name=\"DESCRIPTION\" content=\"Allocators and allocation\" />\n+   <meta name=\"GENERATOR\" content=\"emacs and ten fingers\" />\n+   <title>A fixed-size, multi-thread optimized allocator</title>\n+<link rel=\"StyleSheet\" href=\"../lib3styles.css\" type=\"text/css\" />\n+<link rel=\"Copyright\" href=\"../17_intro/license.html\" type=\"text/html\" />\n+</head>\n+<body>\n+\n+<h1 class=\"centered\"><a name=\"top\">A fixed-size, multi-thread optimized allocator</a></h1>\n+\n+<p class=\"fineprint\"><em>\n+   The latest version of this document is always available at\n+   <a href=\"http://gcc.gnu.org/onlinedocs/libstdc++/ext/mt_allocator.html\">\n+   http://gcc.gnu.org/onlinedocs/libstdc++/ext/mt_allocator.html</a>.\n+</em></p>\n+\n+<p><em>\n+   To the <a href=\"http://gcc.gnu.org/libstdc++/\">libstdc++-v3 homepage</a>.\n+</em></p>\n+\n+<!-- ####################################################### -->\n+<hr />\n+<h3 class=\"left\">\n+  <a name=\"intro\">Introduction</a>\n+</h3>\n+\n+<p> The mt allocator [hereinafter referred to simply as \"the\n+allocator\"] is a fixed size (power of two) allocator that was\n+initially developed specifically to suit the needs of multi threaded\n+applications [hereinafter referred to as an MT application]. Over time\n+the allocator has evolved and been improved in many ways, one of the\n+being that it now also does a good job in single threaded applications\n+[hereinafter referred to as a ST application].  (Note: In this\n+document, when referring to single threaded applications this also\n+includes applications that are compiled with gcc without thread\n+support enabled. This is accomplished using ifdef's on __GTHREADS)\n+</p>\n+\n+<p>\n+The aim of this document is to describe - from a application point of\n+view - the \"inner workings\" of the allocator.\n+</p>\n+\n+\n+<h3 class=\"left\">\n+  <a name=\"init\">Initialization</a>\n+</h3>\n+\n+<p>\n+The static variables (pointers to freelists, tuning parameters etc)\n+are initialized to their default values at file scope, i.e.:\n+</p>\n+\n+<pre>\n+  template<typename _Tp> size_t\n+  __mt_alloc<_Tp>::_S_freelist_headroom = 10;\n+</pre>\n+\n+<p>\n+The very first allocate() call will always call the _S_init() function. \n+In order to make sure that this function is called exactly once we make use\n+of a __gthread_once (with _S_once_mt and _S_init as arguments) call in MT \n+applications and check a static bool (_S_initialized) in ST applications.\n+</p>\n+\n+<p>\n+The _S_init() function:\n+- If the GLIBCXX_FORCE_NEW environment variable is set, it sets the bool\n+  _S_force_new to true and then returns. This will cause subsequent calls to\n+  allocate() to return memory directly from a new() call, and deallocate will\n+  only do a delete() call.\n+</p>\n+\n+<p>\n+- If the GLIBCXX_FORCE_NEW environment variable is not set, both ST and MT \n+  applications will:\n+  - Calculate the number of bins needed. A bin is a specific power of two size\n+    of bytes. I.e., by default the allocator will deal with requests of up to \n+    128 bytes (or whatever the value of _S_max_bytes is when _S_init() is \n+    called). This means that there will be bins of the following sizes \n+    (in bytes): 1, 2, 4, 8, 16, 32, 64, 128. \n+\n+  - Create the _S_binmap array. All requests are rounded up to the next \n+    \"large enough\" bin. I.e., a request for 29 bytes will cause a block from \n+    the \"32 byte bin\" to be returned to the application. The purpose of \n+    _S_binmap is to speed up the process of finding out which bin to use. \n+    I.e., the value of _S_binmap[ 29 ] is initialized to 5 (bin 5 = 32 bytes).\n+</p>\n+<p>\n+  - Create the _S_bin array. This array consists of bin_records. There will be\n+    as many bin_records in this array as the number of bins that we calculated\n+    earlier. I.e., if _S_max_bytes = 128 there will be 8 entries.\n+    Each bin_record is then initialized:\n+    - bin_record->first = An array of pointers to block_records. There will be\n+      as many block_records pointers as there are maximum number of threads \n+      (in a ST application there is only 1 thread, in a MT application there \n+      are _S_max_threads).\n+      This holds the pointer to the first free block for each thread in this\n+      bin. I.e., if we would like to know where the first free block of size 32\n+      for thread number 3 is we would look this up by: _S_bin[ 5 ].first[ 3 ]\n+    - bin_record->last = See above, the only difference being that this points\n+      to the last record on the same freelist.\n+\n+    The above created block_record pointers members are now initialized to \n+    their initial values. I.e. _S_bin[ n ].first[ n ] = NULL;\n+</p>\n+\n+<p>\n+- Additionally a MT application will:\n+  - Create a list of free thread id's. The pointer to the first entry\n+    is stored in _S_thread_freelist_first. The reason for this approach is \n+    that the __gthread_self() call will not return a value that corresponds to \n+    the maximum number of threads allowed but rather a process id number or\n+    something else. So what we do is that we create a list of thread_records.\n+    This list is _S_max_threads long and each entry holds a size_t thread_id\n+    which is initialized to 1, 2, 3, 4, 5 and so on up to _S_max_threads.\n+    Each time a thread calls allocate() or deallocate() we call \n+    _S_get_thread_id() which looks at the value of _S_thread_key which is a\n+    thread local storage pointer. If this is NULL we know that this is a newly\n+    created thread and we pop the first entry from this list and saves the\n+    pointer to this record in the _S_thread_key variable. The next time \n+    we will get the pointer to the thread_record back and we use the \n+    thread_record->thread_id as identification. I.e., the first thread that \n+    calls allocate will get the first record in this list and thus be thread\n+    number 1 and will then find the pointer to its first free 32 byte block\n+    in _S_bin[ 5 ].first[ 1 ]\n+    When we create the _S_thread_key we also define a destructor \n+    (_S_thread_key_destr) which means that when the thread dies, this\n+    thread_record is returned to the front of this list and the thread id\n+    can then be reused if a new thread is created.\n+    This list is protected by a mutex (_S_thread_freelist_mutex) which is only\n+    locked when records are removed/added to the list.\n+</p>\n+<p>\n+  - Initialize the free and used counters of each bin_record:\n+    - bin_record->free = An array of size_t. This keeps track of the number\n+      of blocks on a specific thread's freelist in each bin. I.e., if a thread\n+      has 12 32-byte blocks on it's freelists and allocates one of these, this\n+      counter would be decreased to 11.\n+\n+    - bin_record->used = An array of size_t. This keeps track of the number\n+      of blocks currently in use of this size by this thread. I.e., if a thread\n+      has made 678 requests (and no deallocations...) of 32-byte blocks this\n+      counter will read 678.\n+\n+    The above created arrays are now initialized with their initial values. \n+    I.e. _S_bin[ n ].free[ n ] = 0;\n+</p>\n+<p>\n+  - Initialize the mutex of each bin_record:\n+    The bin_record->mutex is used to protect the global freelist. This concept\n+    of a global freelist is explained in more detail in the section\n+    \"A multi threaded example\", but basically this mutex is locked whenever \n+    a block of memory is retrieved or returned to the global freelist for this\n+    specific bin. This only occurs when a number of blocks are grabbed from the\n+    global list to a thread specific list or when a thread decides to return \n+    some blocks to the global freelist.\n+</p>\n+\n+<h3 class=\"left\">\n+  <a name=\"st_example\">A single threaded example (and a primer for the multi threaded example!)</a>\n+</h3>\n+\n+<p>\n+Let's start by describing how the data on a freelist is laid out in memory.\n+This is the first two blocks in freelist for thread id 3 in bin 3 (8 bytes):\n+</p>\n+<pre>\n++----------------+\n+| next* ---------|--+  (_S_bin[ 3 ].first[ 3 ] points here)\n+|                |  |\n+|                |  |\n+|                |  |\n++----------------+  |\n+| thread_id = 3  |  |\n+|                |  |\n+|                |  |\n+|                |  |\n++----------------+  |\n+| DATA           |  |  (A pointer to here is what is returned to the\n+|                |  |   the application when needed)\n+|                |  |\n+|                |  |\n+|                |  |\n+|                |  |\n+|                |  |\n+|                |  |\n++----------------+  |\n++----------------+  |\n+| next*          |<-+  (If next == NULL it's the last one on the list and\n+|                |      then the _S_bin[ 3 ].last[ 3 ] pointer points to\n+|                |      here as well)\n+|                |\n++----------------+\n+| thread_id = 3  |\n+|                |\n+|                |\n+|                |\n++----------------+\n+| DATA           |\n+|                |\n+|                |\n+|                |\n+|                |\n+|                |\n+|                |\n+|                |\n++----------------+\n+</pre>\n+\n+<p>\n+With this in mind we simplify things a bit for a while and say that there is\n+only one thread (a ST application). In this case all operations are made to \n+what is referred to as the global pool - thread id 0 (No thread may be\n+assigned this id since they span from 1 to _S_max_threads in a MT application).\n+</p>\n+<p>\n+When the application requests memory (calling allocate()) we first look at the\n+requested size and if this is > _S_max_bytes we call new() directly and return.\n+</p>\n+<p>\n+If the requested size is within limits we start by finding out from which \n+bin we should serve this request by looking in _S_binmap.\n+</p>\n+<p>\n+A quick look at _S_bin[ bin ].first[ 0 ] tells us if there are any blocks of\n+this size on the freelist (0). If this is not NULL - fine, just remove the\n+block that _S_bin[ bin ].first[ 0 ] points to from the list, \n+update _S_bin[ bin ].first[ 0 ] and return a pointer to that blocks data.\n+</p>\n+<p>\n+If the freelist is empty (the pointer is NULL) we must get memory from the \n+system and build us a freelist within this memory. All requests for new memory\n+is made in chunks of _S_chunk_size. Knowing the size of a block_record and \n+the bytes that this bin stores we then calculate how many blocks we can create \n+within this chunk, build the list, remove the first block, update the pointers\n+(_S_bin[ bin ].first[ 0 ] and _S_bin[ bin ].last[ 0 ]) and return a pointer \n+to that blocks data. \n+</p>\n+\n+<p>\n+Deallocation is equally simple; the pointer is casted back to a block_record\n+pointer, lookup which bin to use based on the size, add the block to the end \n+of the global freelist (with the next pointer set to NULL) and update the \n+pointers as needed (_S_bin[ bin ].first[ 0 ] and _S_bin[ bin ].last[ 0 ]).\n+</p>\n+\n+<h3 class=\"left\">\n+  <a name=\"mt_example\">A multi threaded example</a>\n+</h3>\n+\n+<p>\n+In the ST example we never used the thread_id variable present in each block. \n+Let's start by explaining the purpose of this in a MT application. \n+</p>\n+\n+<p>\n+The concept of \"ownership\" was introduced since many MT applications\n+allocate and deallocate memory to shared containers from different\n+threads (such as a cache shared amongst all threads). This introduces\n+a problem if the allocator only returns memory to the current threads\n+freelist (I.e., there might be one thread doing all the allocation and\n+thus obtaining ever more memory from the system and another thread\n+that is getting a longer and longer freelist - this will in the end\n+consume all available memory).\n+</p>\n+\n+<p>\n+Each time a block is moved from the global list (where ownership is\n+irrelevant), to a threads freelist (or when a new freelist is built\n+from a chunk directly onto a threads freelist or when a deallocation\n+occurs on a block which was not allocated by the same thread id as the\n+one doing the deallocation) the thread id is set to the current one.\n+</p>\n+\n+<p>\n+What's the use? Well, when a deallocation occurs we can now look at\n+the thread id and find out if it was allocated by another thread id\n+and decrease the used counter of that thread instead, thus keeping the\n+free and used counters correct. And keeping the free and used counters\n+corrects is very important since the relationship between these two\n+variables decides if memory should be returned to the global pool or\n+not when a deallocation occurs.\n+</p>\n+\n+<p>\n+When the application requests memory (calling allocate()) we first\n+look at the requested size and if this is > _S_max_bytes we call new()\n+directly and return.\n+</p>\n+\n+<p>\n+If the requested size is within limits we start by finding out from which \n+bin we should serve this request by looking in _S_binmap.\n+</p>\n+\n+<p>\n+A call to _S_get_thread_id() returns the thread id for the calling thread \n+(and if no value has been set in _S_thread_key, a new id is assigned and\n+returned).\n+</p>\n+\n+<p>\n+A quick look at _S_bin[ bin ].first[ thread_id ] tells us if there are\n+any blocks of this size on the current threads freelist. If this is\n+not NULL - fine, just remove the block that _S_bin[ bin ].first[\n+thread_id ] points to from the list, update _S_bin[ bin ].first[\n+thread_id ], update the free and used counters and return a pointer to\n+that blocks data.\n+</p>\n+\n+<p>\n+If the freelist is empty (the pointer is NULL) we start by looking at\n+the global freelist (0). If there are blocks available on the global\n+freelist we lock this bins mutex and move up to block_count (the\n+number of blocks of this bins size that will fit into a _S_chunk_size)\n+or until end of list - whatever comes first - to the current threads\n+freelist and at the same time change the thread_id ownership and\n+update the counters and pointers. When the bins mutex has been\n+unlocked, we remove the block that _S_bin[ bin ].first[ thread_id ]\n+points to from the list, update _S_bin[ bin ].first[ thread_id ],\n+update the free and used counters, and return a pointer to that blocks\n+data.\n+</p>\n+\n+<p>\n+The reason that the number of blocks moved to the current threads\n+freelist is limited to block_count is to minimize the chance that a\n+subsequent deallocate() call will return the excess blocks to the\n+global freelist (based on the _S_freelist_headroom calculation, see\n+below).\n+</p>\n+\n+<p>\n+However if there isn't any memory on the global pool we need to get\n+memory from the system - this is done in exactly the same way as in a\n+single threaded application with one major difference; the list built\n+in the newly allocated memory (of _S_chunk_size size) is added to the\n+current threads freelist instead of to the global.\n+</p>\n+\n+<p>\n+The basic process of a deallocation call is simple: always add the\n+block to the end of the current threads freelist and update the\n+counters and pointers (as described earlier with the specific check of\n+ownership that causes the used counter of the thread that originally\n+allocated the block to be decreased instead of the current threads\n+counter).\n+</p>\n+\n+<p>\n+And here comes the free and used counters to service. Each time a\n+deallocation() call is made, the length of the current threads\n+freelist is compared to the amount memory in use by this thread.\n+</p>\n+\n+<p>\n+Let's go back to the example of an application that has one thread\n+that does all the allocations and one that deallocates. Both these\n+threads use say 516 32-byte blocks that was allocated during thread\n+creation for example.  Their used counters will both say 516 at this\n+point. The allocation thread now grabs 1000 32-byte blocks and puts\n+them in a shared container. The used counter for this thread is now\n+1516.\n+</p>\n+\n+<p>\n+The deallocation thread now deallocates 500 of these blocks. For each\n+deallocation made the used counter of the allocating thread is\n+decreased and the freelist of the deallocation thread gets longer and\n+longer. But the calculation made in deallocate() will limit the length\n+of the freelist in the deallocation thread to _S_freelist_headroom %\n+of it's used counter.  In this case, when the freelist (given that the\n+_S_freelist_headroom is at it's default value of 10%) exceeds 52\n+(516/10) blocks will be returned to the global pool where the\n+allocating thread may pick them up and reuse them.\n+</p>\n+\n+<p>\n+In order to reduce lock contention (since this requires this bins\n+mutex to be locked) this operation is also made in chunks of blocks\n+(just like when chunks of blocks are moved from the global freelist to\n+a threads freelist mentioned above). The \"formula\" used can probably\n+be improved to further reduce the risk of blocks being \"bounced back\n+and forth\" between freelists.\n+</p>\n+\n+<hr />\n+<p>Return <a href=\"#top\">to the top of the page</a> or\n+   <a href=\"http://gcc.gnu.org/libstdc++/\">to the libstdc++ homepage</a>.\n+</p>\n+\n+\n+<!-- ####################################################### -->\n+\n+<hr />\n+<p class=\"fineprint\"><em>\n+See <a href=\"../17_intro/license.html\">license.html</a> for copying conditions.\n+Comments and suggestions are welcome, and may be sent to\n+<a href=\"mailto:libstdc++@gcc.gnu.org\">the libstdc++ mailing list</a>.\n+</em></p>\n+\n+\n+</body>\n+</html>"}]}