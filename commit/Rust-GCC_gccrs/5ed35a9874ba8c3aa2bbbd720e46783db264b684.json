{"sha": "5ed35a9874ba8c3aa2bbbd720e46783db264b684", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NWVkMzVhOTg3NGJhOGMzYWEyYmJiZDcyMGU0Njc4M2RiMjY0YjY4NA==", "commit": {"author": {"name": "Jonathan Wright", "email": "jonathan.wright@arm.com", "date": "2021-08-12T11:27:15Z"}, "committer": {"name": "Jonathan Wright", "email": "jonathan.wright@arm.com", "date": "2021-08-17T10:44:07Z"}, "message": "aarch64: Remove macros for vld2[q]_lane Neon intrinsics\n\nRemove macros for vld2[q]_lane Neon intrinsics. This is a preparatory\nstep before adding new modes for structures of Advanced SIMD vectors.\n\ngcc/ChangeLog:\n\n2021-08-12  Jonathan Wright  <jonathan.wright@arm.com>\n\n\t* config/aarch64/arm_neon.h (__LD2_LANE_FUNC): Delete.\n\t(__LD2Q_LANE_FUNC): Likewise.\n\t(vld2_lane_u8): Define without macro.\n\t(vld2_lane_u16): Likewise.\n\t(vld2_lane_u32): Likewise.\n\t(vld2_lane_u64): Likewise.\n\t(vld2_lane_s8): Likewise.\n\t(vld2_lane_s16): Likewise.\n\t(vld2_lane_s32): Likewise.\n\t(vld2_lane_s64): Likewise.\n\t(vld2_lane_f16): Likewise.\n\t(vld2_lane_f32): Likewise.\n\t(vld2_lane_f64): Likewise.\n\t(vld2_lane_p8): Likewise.\n\t(vld2_lane_p16): Likewise.\n\t(vld2_lane_p64): Likewise.\n\t(vld2q_lane_u8): Likewise.\n\t(vld2q_lane_u16): Likewise.\n\t(vld2q_lane_u32): Likewise.\n\t(vld2q_lane_u64): Likewise.\n\t(vld2q_lane_s8): Likewise.\n\t(vld2q_lane_s16): Likewise.\n\t(vld2q_lane_s32): Likewise.\n\t(vld2q_lane_s64): Likewise.\n\t(vld2q_lane_f16): Likewise.\n\t(vld2q_lane_f32): Likewise.\n\t(vld2q_lane_f64): Likewise.\n\t(vld2q_lane_p8): Likewise.\n\t(vld2q_lane_p16): Likewise.\n\t(vld2q_lane_p64): Likewise.\n\t(vld2_lane_bf16): Likewise.\n\t(vld2q_lane_bf16): Likewise.", "tree": {"sha": "8568129962073bbe2e6832147eac9722e92dea2d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8568129962073bbe2e6832147eac9722e92dea2d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5ed35a9874ba8c3aa2bbbd720e46783db264b684", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5ed35a9874ba8c3aa2bbbd720e46783db264b684", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5ed35a9874ba8c3aa2bbbd720e46783db264b684", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5ed35a9874ba8c3aa2bbbd720e46783db264b684/comments", "author": {"login": "jwright-arm", "id": 31624044, "node_id": "MDQ6VXNlcjMxNjI0MDQ0", "avatar_url": "https://avatars.githubusercontent.com/u/31624044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwright-arm", "html_url": "https://github.com/jwright-arm", "followers_url": "https://api.github.com/users/jwright-arm/followers", "following_url": "https://api.github.com/users/jwright-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jwright-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwright-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwright-arm/subscriptions", "organizations_url": "https://api.github.com/users/jwright-arm/orgs", "repos_url": "https://api.github.com/users/jwright-arm/repos", "events_url": "https://api.github.com/users/jwright-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwright-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jwright-arm", "id": 31624044, "node_id": "MDQ6VXNlcjMxNjI0MDQ0", "avatar_url": "https://avatars.githubusercontent.com/u/31624044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwright-arm", "html_url": "https://github.com/jwright-arm", "followers_url": "https://api.github.com/users/jwright-arm/followers", "following_url": "https://api.github.com/users/jwright-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jwright-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwright-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwright-arm/subscriptions", "organizations_url": "https://api.github.com/users/jwright-arm/orgs", "repos_url": "https://api.github.com/users/jwright-arm/repos", "events_url": "https://api.github.com/users/jwright-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwright-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "92aadbd593c1aef6798e7a64b8f7a91fed32aa68", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/92aadbd593c1aef6798e7a64b8f7a91fed32aa68", "html_url": "https://github.com/Rust-GCC/gccrs/commit/92aadbd593c1aef6798e7a64b8f7a91fed32aa68"}], "stats": {"total": 558, "additions": 474, "deletions": 84}, "files": [{"sha": "91c072fe4572ff0012aced11e0f609168e4afc10", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 474, "deletions": 84, "changes": 558, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5ed35a9874ba8c3aa2bbbd720e46783db264b684/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5ed35a9874ba8c3aa2bbbd720e46783db264b684/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=5ed35a9874ba8c3aa2bbbd720e46783db264b684", "patch": "@@ -19882,92 +19882,455 @@ vld4q_dup_p64 (const poly64_t * __a)\n \n /* vld2_lane */\n \n-#define __LD2_LANE_FUNC(intype, vectype, largetype, ptrtype, mode,\t   \\\n-\t\t\t qmode, ptrmode, funcsuffix, signedtype)\t   \\\n-__extension__ extern __inline intype \\\n-__attribute__ ((__always_inline__, __gnu_inline__,__artificial__)) \\\n-vld2_lane_##funcsuffix (const ptrtype * __ptr, intype __b, const int __c)  \\\n-{\t\t\t\t\t\t\t\t\t   \\\n-  __builtin_aarch64_simd_oi __o;\t\t\t\t\t   \\\n-  largetype __temp;\t\t\t\t\t\t\t   \\\n-  __temp.val[0] =\t\t\t\t\t\t\t   \\\n-    vcombine_##funcsuffix (__b.val[0], vcreate_##funcsuffix (0));\t   \\\n-  __temp.val[1] =\t\t\t\t\t\t\t   \\\n-    vcombine_##funcsuffix (__b.val[1], vcreate_##funcsuffix (0));\t   \\\n-  __o = __builtin_aarch64_set_qregoi##qmode (__o,\t\t\t   \\\n-\t\t\t\t\t    (signedtype) __temp.val[0],\t   \\\n-\t\t\t\t\t    0);\t\t\t\t   \\\n-  __o = __builtin_aarch64_set_qregoi##qmode (__o,\t\t\t   \\\n-\t\t\t\t\t    (signedtype) __temp.val[1],\t   \\\n-\t\t\t\t\t    1);\t\t\t\t   \\\n-  __o =\t__builtin_aarch64_ld2_lane##mode (\t\t\t\t   \\\n-\t  (__builtin_aarch64_simd_##ptrmode *) __ptr, __o, __c);\t   \\\n-  __b.val[0] = (vectype) __builtin_aarch64_get_dregoidi (__o, 0);\t   \\\n-  __b.val[1] = (vectype) __builtin_aarch64_get_dregoidi (__o, 1);\t   \\\n-  return __b;\t\t\t\t\t\t\t\t   \\\n+__extension__ extern __inline uint8x8x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_u8 (const uint8_t * __ptr, uint8x8x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  uint8x16x2_t __temp;\n+  __temp.val[0] = vcombine_u8 (__b.val[0], vcreate_u8 (0));\n+  __temp.val[1] = vcombine_u8 (__b.val[1], vcreate_u8 (0));\n+  __o = __builtin_aarch64_set_qregoiv16qi (__o, (int8x16_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv16qi (__o, (int8x16_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev8qi (\n+\t  (__builtin_aarch64_simd_qi *) __ptr, __o, __c);\n+  __b.val[0] = (uint8x8_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (uint8x8_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n }\n \n-__LD2_LANE_FUNC (float16x4x2_t, float16x4_t, float16x8x2_t, float16_t, v4hf,\n-\t\t v8hf, hf, f16, float16x8_t)\n-__LD2_LANE_FUNC (float32x2x2_t, float32x2_t, float32x4x2_t, float32_t, v2sf, v4sf,\n-\t\t sf, f32, float32x4_t)\n-__LD2_LANE_FUNC (float64x1x2_t, float64x1_t, float64x2x2_t, float64_t, df, v2df,\n-\t\t df, f64, float64x2_t)\n-__LD2_LANE_FUNC (poly8x8x2_t, poly8x8_t, poly8x16x2_t, poly8_t, v8qi, v16qi, qi, p8,\n-\t\t int8x16_t)\n-__LD2_LANE_FUNC (poly16x4x2_t, poly16x4_t, poly16x8x2_t, poly16_t, v4hi, v8hi, hi,\n-\t\t p16, int16x8_t)\n-__LD2_LANE_FUNC (poly64x1x2_t, poly64x1_t, poly64x2x2_t, poly64_t, di,\n-\t\t v2di_ssps, di, p64, poly64x2_t)\n-__LD2_LANE_FUNC (int8x8x2_t, int8x8_t, int8x16x2_t, int8_t, v8qi, v16qi, qi, s8,\n-\t\t int8x16_t)\n-__LD2_LANE_FUNC (int16x4x2_t, int16x4_t, int16x8x2_t, int16_t, v4hi, v8hi, hi, s16,\n-\t\t int16x8_t)\n-__LD2_LANE_FUNC (int32x2x2_t, int32x2_t, int32x4x2_t, int32_t, v2si, v4si, si, s32,\n-\t\t int32x4_t)\n-__LD2_LANE_FUNC (int64x1x2_t, int64x1_t, int64x2x2_t, int64_t, di, v2di, di, s64,\n-\t\t int64x2_t)\n-__LD2_LANE_FUNC (uint8x8x2_t, uint8x8_t, uint8x16x2_t, uint8_t, v8qi, v16qi, qi, u8,\n-\t\t int8x16_t)\n-__LD2_LANE_FUNC (uint16x4x2_t, uint16x4_t, uint16x8x2_t, uint16_t, v4hi, v8hi, hi,\n-\t\t u16, int16x8_t)\n-__LD2_LANE_FUNC (uint32x2x2_t, uint32x2_t, uint32x4x2_t, uint32_t, v2si, v4si, si,\n-\t\t u32, int32x4_t)\n-__LD2_LANE_FUNC (uint64x1x2_t, uint64x1_t, uint64x2x2_t, uint64_t, di, v2di, di,\n-\t\t u64, int64x2_t)\n+__extension__ extern __inline uint16x4x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_u16 (const uint16_t * __ptr, uint16x4x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  uint16x8x2_t __temp;\n+  __temp.val[0] = vcombine_u16 (__b.val[0], vcreate_u16 (0));\n+  __temp.val[1] = vcombine_u16 (__b.val[1], vcreate_u16 (0));\n+  __o = __builtin_aarch64_set_qregoiv8hi (__o, (int16x8_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv8hi (__o, (int16x8_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev4hi (\n+\t  (__builtin_aarch64_simd_hi *) __ptr, __o, __c);\n+  __b.val[0] = (uint16x4_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (uint16x4_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline uint32x2x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_u32 (const uint32_t * __ptr, uint32x2x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  uint32x4x2_t __temp;\n+  __temp.val[0] = vcombine_u32 (__b.val[0], vcreate_u32 (0));\n+  __temp.val[1] = vcombine_u32 (__b.val[1], vcreate_u32 (0));\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev2si (\n+\t  (__builtin_aarch64_simd_si *) __ptr, __o, __c);\n+  __b.val[0] = (uint32x2_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (uint32x2_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline uint64x1x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_u64 (const uint64_t * __ptr, uint64x1x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  uint64x2x2_t __temp;\n+  __temp.val[0] = vcombine_u64 (__b.val[0], vcreate_u64 (0));\n+  __temp.val[1] = vcombine_u64 (__b.val[1], vcreate_u64 (0));\n+  __o = __builtin_aarch64_set_qregoiv2di (__o, (int64x2_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv2di (__o, (int64x2_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanedi (\n+\t  (__builtin_aarch64_simd_di *) __ptr, __o, __c);\n+  __b.val[0] = (uint64x1_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (uint64x1_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline int8x8x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_s8 (const int8_t * __ptr, int8x8x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  int8x16x2_t __temp;\n+  __temp.val[0] = vcombine_s8 (__b.val[0], vcreate_s8 (0));\n+  __temp.val[1] = vcombine_s8 (__b.val[1], vcreate_s8 (0));\n+  __o = __builtin_aarch64_set_qregoiv16qi (__o, (int8x16_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv16qi (__o, (int8x16_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev8qi (\n+\t  (__builtin_aarch64_simd_qi *) __ptr, __o, __c);\n+  __b.val[0] = (int8x8_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (int8x8_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline int16x4x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_s16 (const int16_t * __ptr, int16x4x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  int16x8x2_t __temp;\n+  __temp.val[0] = vcombine_s16 (__b.val[0], vcreate_s16 (0));\n+  __temp.val[1] = vcombine_s16 (__b.val[1], vcreate_s16 (0));\n+  __o = __builtin_aarch64_set_qregoiv8hi (__o, (int16x8_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv8hi (__o, (int16x8_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev4hi (\n+\t  (__builtin_aarch64_simd_hi *) __ptr, __o, __c);\n+  __b.val[0] = (int16x4_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (int16x4_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline int32x2x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_s32 (const int32_t * __ptr, int32x2x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  int32x4x2_t __temp;\n+  __temp.val[0] = vcombine_s32 (__b.val[0], vcreate_s32 (0));\n+  __temp.val[1] = vcombine_s32 (__b.val[1], vcreate_s32 (0));\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev2si (\n+\t  (__builtin_aarch64_simd_si *) __ptr, __o, __c);\n+  __b.val[0] = (int32x2_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (int32x2_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline int64x1x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_s64 (const int64_t * __ptr, int64x1x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  int64x2x2_t __temp;\n+  __temp.val[0] = vcombine_s64 (__b.val[0], vcreate_s64 (0));\n+  __temp.val[1] = vcombine_s64 (__b.val[1], vcreate_s64 (0));\n+  __o = __builtin_aarch64_set_qregoiv2di (__o, (int64x2_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv2di (__o, (int64x2_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanedi (\n+\t  (__builtin_aarch64_simd_di *) __ptr, __o, __c);\n+  __b.val[0] = (int64x1_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (int64x1_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline float16x4x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_f16 (const float16_t * __ptr, float16x4x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  float16x8x2_t __temp;\n+  __temp.val[0] = vcombine_f16 (__b.val[0], vcreate_f16 (0));\n+  __temp.val[1] = vcombine_f16 (__b.val[1], vcreate_f16 (0));\n+  __o = __builtin_aarch64_set_qregoiv8hf (__o, (float16x8_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv8hf (__o, (float16x8_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev4hf (\n+\t  (__builtin_aarch64_simd_hf *) __ptr, __o, __c);\n+  __b.val[0] = (float16x4_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (float16x4_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline float32x2x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_f32 (const float32_t * __ptr, float32x2x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  float32x4x2_t __temp;\n+  __temp.val[0] = vcombine_f32 (__b.val[0], vcreate_f32 (0));\n+  __temp.val[1] = vcombine_f32 (__b.val[1], vcreate_f32 (0));\n+  __o = __builtin_aarch64_set_qregoiv4sf (__o, (float32x4_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4sf (__o, (float32x4_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev2sf (\n+\t  (__builtin_aarch64_simd_sf *) __ptr, __o, __c);\n+  __b.val[0] = (float32x2_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (float32x2_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline float64x1x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_f64 (const float64_t * __ptr, float64x1x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  float64x2x2_t __temp;\n+  __temp.val[0] = vcombine_f64 (__b.val[0], vcreate_f64 (0));\n+  __temp.val[1] = vcombine_f64 (__b.val[1], vcreate_f64 (0));\n+  __o = __builtin_aarch64_set_qregoiv2df (__o, (float64x2_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv2df (__o, (float64x2_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanedf (\n+\t  (__builtin_aarch64_simd_df *) __ptr, __o, __c);\n+  __b.val[0] = (float64x1_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (float64x1_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline poly8x8x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_p8 (const poly8_t * __ptr, poly8x8x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  poly8x16x2_t __temp;\n+  __temp.val[0] = vcombine_p8 (__b.val[0], vcreate_p8 (0));\n+  __temp.val[1] = vcombine_p8 (__b.val[1], vcreate_p8 (0));\n+  __o = __builtin_aarch64_set_qregoiv16qi (__o, (int8x16_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv16qi (__o, (int8x16_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev8qi (\n+\t  (__builtin_aarch64_simd_qi *) __ptr, __o, __c);\n+  __b.val[0] = (poly8x8_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (poly8x8_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline poly16x4x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_p16 (const poly16_t * __ptr, poly16x4x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  poly16x8x2_t __temp;\n+  __temp.val[0] = vcombine_p16 (__b.val[0], vcreate_p16 (0));\n+  __temp.val[1] = vcombine_p16 (__b.val[1], vcreate_p16 (0));\n+  __o = __builtin_aarch64_set_qregoiv8hi (__o, (int16x8_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv8hi (__o, (int16x8_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev4hi (\n+\t  (__builtin_aarch64_simd_hi *) __ptr, __o, __c);\n+  __b.val[0] = (poly16x4_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (poly16x4_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline poly64x1x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_p64 (const poly64_t * __ptr, poly64x1x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  poly64x2x2_t __temp;\n+  __temp.val[0] = vcombine_p64 (__b.val[0], vcreate_p64 (0));\n+  __temp.val[1] = vcombine_p64 (__b.val[1], vcreate_p64 (0));\n+  __o = __builtin_aarch64_set_qregoiv2di (__o, (int64x2_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv2di (__o, (int64x2_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanedi (\n+\t  (__builtin_aarch64_simd_di *) __ptr, __o, __c);\n+  __b.val[0] = (poly64x1_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (poly64x1_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n \n /* vld2q_lane */\n \n-#define __LD2Q_LANE_FUNC(intype, vtype, ptrtype, mode, ptrmode, funcsuffix) \\\n-__extension__ extern __inline intype \\\n-__attribute__ ((__always_inline__, __gnu_inline__,__artificial__)) \\\n-vld2q_lane_##funcsuffix (const ptrtype * __ptr, intype __b, const int __c) \\\n-{\t\t\t\t\t\t\t\t\t   \\\n-  __builtin_aarch64_simd_oi __o;\t\t\t\t\t   \\\n-  intype ret;\t\t\t\t\t\t\t\t   \\\n-  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0); \\\n-  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1); \\\n-  __o = __builtin_aarch64_ld2_lane##mode (\t\t\t\t   \\\n-\t(__builtin_aarch64_simd_##ptrmode *) __ptr, __o, __c);\t\t   \\\n-  ret.val[0] = (vtype) __builtin_aarch64_get_qregoiv4si (__o, 0);\t   \\\n-  ret.val[1] = (vtype) __builtin_aarch64_get_qregoiv4si (__o, 1);\t   \\\n-  return ret;\t\t\t\t\t\t\t\t   \\\n+__extension__ extern __inline uint8x16x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_u8 (const uint8_t * __ptr, uint8x16x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  uint8x16x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev16qi (\n+\t(__builtin_aarch64_simd_qi *) __ptr, __o, __c);\n+  ret.val[0] = (uint8x16_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (uint8x16_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n }\n \n-__LD2Q_LANE_FUNC (float16x8x2_t, float16x8_t, float16_t, v8hf, hf, f16)\n-__LD2Q_LANE_FUNC (float32x4x2_t, float32x4_t, float32_t, v4sf, sf, f32)\n-__LD2Q_LANE_FUNC (float64x2x2_t, float64x2_t, float64_t, v2df, df, f64)\n-__LD2Q_LANE_FUNC (poly8x16x2_t, poly8x16_t, poly8_t, v16qi, qi, p8)\n-__LD2Q_LANE_FUNC (poly16x8x2_t, poly16x8_t, poly16_t, v8hi, hi, p16)\n-__LD2Q_LANE_FUNC (poly64x2x2_t, poly64x2_t, poly64_t, v2di, di, p64)\n-__LD2Q_LANE_FUNC (int8x16x2_t, int8x16_t, int8_t, v16qi, qi, s8)\n-__LD2Q_LANE_FUNC (int16x8x2_t, int16x8_t, int16_t, v8hi, hi, s16)\n-__LD2Q_LANE_FUNC (int32x4x2_t, int32x4_t, int32_t, v4si, si, s32)\n-__LD2Q_LANE_FUNC (int64x2x2_t, int64x2_t, int64_t, v2di, di, s64)\n-__LD2Q_LANE_FUNC (uint8x16x2_t, uint8x16_t, uint8_t, v16qi, qi, u8)\n-__LD2Q_LANE_FUNC (uint16x8x2_t, uint16x8_t, uint16_t, v8hi, hi, u16)\n-__LD2Q_LANE_FUNC (uint32x4x2_t, uint32x4_t, uint32_t, v4si, si, u32)\n-__LD2Q_LANE_FUNC (uint64x2x2_t, uint64x2_t, uint64_t, v2di, di, u64)\n+__extension__ extern __inline uint16x8x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_u16 (const uint16_t * __ptr, uint16x8x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  uint16x8x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev8hi (\n+\t(__builtin_aarch64_simd_hi *) __ptr, __o, __c);\n+  ret.val[0] = (uint16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (uint16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline uint32x4x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_u32 (const uint32_t * __ptr, uint32x4x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  uint32x4x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev4si (\n+\t(__builtin_aarch64_simd_si *) __ptr, __o, __c);\n+  ret.val[0] = (uint32x4_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (uint32x4_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline uint64x2x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_u64 (const uint64_t * __ptr, uint64x2x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  uint64x2x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev2di (\n+\t(__builtin_aarch64_simd_di *) __ptr, __o, __c);\n+  ret.val[0] = (uint64x2_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (uint64x2_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline int8x16x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_s8 (const int8_t * __ptr, int8x16x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  int8x16x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev16qi (\n+\t(__builtin_aarch64_simd_qi *) __ptr, __o, __c);\n+  ret.val[0] = (int8x16_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (int8x16_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline int16x8x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_s16 (const int16_t * __ptr, int16x8x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  int16x8x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev8hi (\n+\t(__builtin_aarch64_simd_hi *) __ptr, __o, __c);\n+  ret.val[0] = (int16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (int16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline int32x4x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_s32 (const int32_t * __ptr, int32x4x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  int32x4x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev4si (\n+\t(__builtin_aarch64_simd_si *) __ptr, __o, __c);\n+  ret.val[0] = __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline int64x2x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_s64 (const int64_t * __ptr, int64x2x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  int64x2x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev2di (\n+\t(__builtin_aarch64_simd_di *) __ptr, __o, __c);\n+  ret.val[0] = (int64x2_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (int64x2_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline float16x8x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_f16 (const float16_t * __ptr, float16x8x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  float16x8x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev8hf (\n+\t(__builtin_aarch64_simd_hf *) __ptr, __o, __c);\n+  ret.val[0] = (float16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (float16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline float32x4x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_f32 (const float32_t * __ptr, float32x4x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  float32x4x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev4sf (\n+\t(__builtin_aarch64_simd_sf *) __ptr, __o, __c);\n+  ret.val[0] = (float32x4_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (float32x4_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline float64x2x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_f64 (const float64_t * __ptr, float64x2x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  float64x2x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev2df (\n+\t(__builtin_aarch64_simd_df *) __ptr, __o, __c);\n+  ret.val[0] = (float64x2_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (float64x2_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline poly8x16x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_p8 (const poly8_t * __ptr, poly8x16x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  poly8x16x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev16qi (\n+\t(__builtin_aarch64_simd_qi *) __ptr, __o, __c);\n+  ret.val[0] = (poly8x16_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (poly8x16_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline poly16x8x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_p16 (const poly16_t * __ptr, poly16x8x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  poly16x8x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev8hi (\n+\t(__builtin_aarch64_simd_hi *) __ptr, __o, __c);\n+  ret.val[0] = (poly16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (poly16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n+__extension__ extern __inline poly64x2x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_p64 (const poly64_t * __ptr, poly64x2x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  poly64x2x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev2di (\n+\t(__builtin_aarch64_simd_di *) __ptr, __o, __c);\n+  ret.val[0] = (poly64x2_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (poly64x2_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n \n /* vld3_lane */\n \n@@ -34584,9 +34947,38 @@ vcopyq_laneq_bf16 (bfloat16x8_t __a, const int __lane1,\n \t\t\t\t  __a, __lane1);\n }\n \n-__LD2_LANE_FUNC (bfloat16x4x2_t, bfloat16x4_t, bfloat16x8x2_t, bfloat16_t, v4bf,\n-\t\t v8bf, bf, bf16, bfloat16x8_t)\n-__LD2Q_LANE_FUNC (bfloat16x8x2_t, bfloat16x8_t, bfloat16_t, v8bf, bf, bf16)\n+__extension__ extern __inline bfloat16x4x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2_lane_bf16 (const bfloat16_t * __ptr, bfloat16x4x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  bfloat16x8x2_t __temp;\n+  __temp.val[0] = vcombine_bf16 (__b.val[0], vcreate_bf16 (0));\n+  __temp.val[1] = vcombine_bf16 (__b.val[1], vcreate_bf16 (0));\n+  __o = __builtin_aarch64_set_qregoiv8bf (__o, (bfloat16x8_t) __temp.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv8bf (__o, (bfloat16x8_t) __temp.val[1], 1);\n+  __o =\t__builtin_aarch64_ld2_lanev4bf (\n+\t  (__builtin_aarch64_simd_bf *) __ptr, __o, __c);\n+  __b.val[0] = (bfloat16x4_t) __builtin_aarch64_get_dregoidi (__o, 0);\n+  __b.val[1] = (bfloat16x4_t) __builtin_aarch64_get_dregoidi (__o, 1);\n+  return __b;\n+}\n+\n+__extension__ extern __inline bfloat16x8x2_t\n+__attribute__ ((__always_inline__, __gnu_inline__,__artificial__))\n+vld2q_lane_bf16 (const bfloat16_t * __ptr, bfloat16x8x2_t __b, const int __c)\n+{\n+  __builtin_aarch64_simd_oi __o;\n+  bfloat16x8x2_t ret;\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[0], 0);\n+  __o = __builtin_aarch64_set_qregoiv4si (__o, (int32x4_t) __b.val[1], 1);\n+  __o = __builtin_aarch64_ld2_lanev8bf (\n+\t(__builtin_aarch64_simd_bf *) __ptr, __o, __c);\n+  ret.val[0] = (bfloat16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 0);\n+  ret.val[1] = (bfloat16x8_t) __builtin_aarch64_get_qregoiv4si (__o, 1);\n+  return ret;\n+}\n+\n __LD3_LANE_FUNC (bfloat16x4x3_t, bfloat16x4_t, bfloat16x8x3_t, bfloat16_t, v4bf,\n \t\t v8bf, bf, bf16, bfloat16x8_t)\n __LD3Q_LANE_FUNC (bfloat16x8x3_t, bfloat16x8_t, bfloat16_t, v8bf, bf, bf16)\n@@ -34888,8 +35280,6 @@ vaddq_p128 (poly128_t __a, poly128_t __b)\n #undef __aarch64_vdupq_laneq_u32\n #undef __aarch64_vdupq_laneq_u64\n \n-#undef __LD2_LANE_FUNC\n-#undef __LD2Q_LANE_FUNC\n #undef __LD3_LANE_FUNC\n #undef __LD3Q_LANE_FUNC\n #undef __LD4_LANE_FUNC"}]}