{"sha": "73b7582775254b764fd92ddb252a33dc15872c69", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzNiNzU4Mjc3NTI1NGI3NjRmZDkyZGRiMjUyYTMzZGMxNTg3MmM2OQ==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2020-12-17T00:15:11Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2020-12-17T00:15:11Z"}, "message": "Add rtl-ssa\n\nThis patch adds the RTL SSA infrastructure itself.  The following\nfwprop.c patch will make use of it.\n\ngcc/\n\t* configure.ac: Add rtl-ssa to the list of dependence directories.\n\t* configure: Regenerate.\n\t* Makefile.in (rtl-ssa-warn): New variable.\n\t(OBJS): Add the rtl-ssa object files.\n\t* emit-rtl.h (rtl_data::ssa): New field.\n\t* rtl-ssa.h: New file.\n\t* system.h: Include <functional> when INCLUDE_FUNCTIONAL is defined.\n\t* rtl-ssa/access-utils.h: Likewise.\n\t* rtl-ssa/accesses.h: New file.\n\t* rtl-ssa/accesses.cc: Likewise.\n\t* rtl-ssa/blocks.h: New file.\n\t* rtl-ssa/blocks.cc: Likewise.\n\t* rtl-ssa/change-utils.h: Likewise.\n\t* rtl-ssa/changes.h: New file.\n\t* rtl-ssa/changes.cc: Likewise.\n\t* rtl-ssa/functions.h: New file.\n\t* rtl-ssa/functions.cc: Likewise.\n\t* rtl-ssa/insn-utils.h: Likewise.\n\t* rtl-ssa/insns.h: New file.\n\t* rtl-ssa/insns.cc: Likewise.\n\t* rtl-ssa/internals.inl: Likewise.\n\t* rtl-ssa/is-a.inl: Likewise.\n\t* rtl-ssa/member-fns.inl: Likewise.\n\t* rtl-ssa/movement.h: Likewise.", "tree": {"sha": "38129e29d87038770d57774a028345d7a78eb3e6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/38129e29d87038770d57774a028345d7a78eb3e6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/73b7582775254b764fd92ddb252a33dc15872c69", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/73b7582775254b764fd92ddb252a33dc15872c69", "html_url": "https://github.com/Rust-GCC/gccrs/commit/73b7582775254b764fd92ddb252a33dc15872c69", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/73b7582775254b764fd92ddb252a33dc15872c69/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "47d52e17adf48093cc30d01707652018deb32a6c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/47d52e17adf48093cc30d01707652018deb32a6c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/47d52e17adf48093cc30d01707652018deb32a6c"}], "stats": {"total": 10063, "additions": 10061, "deletions": 2}, "files": [{"sha": "178e4eaa513793db62f7152b065fbe74f7e6f51a", "filename": "gcc/Makefile.in", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -207,6 +207,7 @@ VALGRIND_DRIVER_DEFINES = @valgrind_path_defines@\n # This is how we control whether or not the additional warnings are applied.\n .-warn = $(STRICT_WARN)\n build-warn = $(STRICT_WARN)\n+rtl-ssa-warn = $(STRICT_WARN)\n GCC_WARN_CFLAGS = $(LOOSE_WARN) $(C_LOOSE_WARN) $($(@D)-warn) $(if $(filter-out $(STRICT_WARN),$($(@D)-warn)),,$(C_STRICT_WARN)) $(NOCOMMON_FLAG) $($@-warn)\n GCC_WARN_CXXFLAGS = $(LOOSE_WARN) $($(@D)-warn) $(NOCOMMON_FLAG) $($@-warn)\n \n@@ -1525,6 +1526,11 @@ OBJS = \\\n \treorg.o \\\n \tresource.o \\\n \trtl-error.o \\\n+\trtl-ssa/accesses.o \\\n+\trtl-ssa/blocks.o \\\n+\trtl-ssa/changes.o \\\n+\trtl-ssa/functions.o \\\n+\trtl-ssa/insns.o \\\n \trtl-tests.o \\\n \trtl.o \\\n \trtlhash.o \\"}, {"sha": "fe649b277a83bca2eed26723db668bed7c6ea9af", "filename": "gcc/configure", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Fconfigure", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Fconfigure", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfigure?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -33265,7 +33265,7 @@ $as_echo \"$as_me: executing $ac_file commands\" >&6;}\n     \"depdir\":C) $SHELL $ac_aux_dir/mkinstalldirs $DEPDIR ;;\n     \"gccdepdir\":C)\n   ${CONFIG_SHELL-/bin/sh} $ac_aux_dir/mkinstalldirs build/$DEPDIR\n-  for lang in $subdirs c-family common analyzer\n+  for lang in $subdirs c-family common analyzer rtl-ssa\n   do\n       ${CONFIG_SHELL-/bin/sh} $ac_aux_dir/mkinstalldirs $lang/$DEPDIR\n   done ;;"}, {"sha": "37557222607ccdf7e5145e8e35e1787a7d11ec77", "filename": "gcc/configure.ac", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Fconfigure.ac", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Fconfigure.ac", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfigure.ac?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -1242,7 +1242,7 @@ AC_CHECK_HEADERS(ext/hash_map)\n ZW_CREATE_DEPDIR\n AC_CONFIG_COMMANDS([gccdepdir],[\n   ${CONFIG_SHELL-/bin/sh} $ac_aux_dir/mkinstalldirs build/$DEPDIR\n-  for lang in $subdirs c-family common analyzer\n+  for lang in $subdirs c-family common analyzer rtl-ssa\n   do\n       ${CONFIG_SHELL-/bin/sh} $ac_aux_dir/mkinstalldirs $lang/$DEPDIR\n   done], [subdirs=\"$subdirs\" ac_aux_dir=$ac_aux_dir DEPDIR=$DEPDIR])"}, {"sha": "b20cd76ea74bbe7d11addabd97a5c20f5c6a1d48", "filename": "gcc/emit-rtl.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Femit-rtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Femit-rtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Femit-rtl.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -23,6 +23,7 @@ along with GCC; see the file COPYING3.  If not see\n class temp_slot;\n typedef class temp_slot *temp_slot_p;\n class predefined_function_abi;\n+namespace rtl_ssa { class function_info; }\n \n /* Information mainlined about RTL representation of incoming arguments.  */\n struct GTY(()) incoming_args {\n@@ -73,6 +74,8 @@ struct GTY(()) rtl_data {\n      different ABIs.  */\n   const predefined_function_abi *GTY((skip)) abi;\n \n+  rtl_ssa::function_info *GTY((skip)) ssa;\n+\n   /* For function.c  */\n \n   /* # of bytes of outgoing arguments.  If ACCUMULATE_OUTGOING_ARGS is"}, {"sha": "60cdad03dc048679270629a9a6d747043d3b0c8a", "filename": "gcc/rtl-ssa.h", "status": "added", "additions": 71, "deletions": 0, "changes": 71, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,71 @@\n+// On-the-side RTL SSA representation                               -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#ifndef GCC_RTL_SSA_H\n+#define GCC_RTL_SSA_H 1\n+\n+// This is an aggregation header file.  This means it should contain only\n+// other include files.\n+\n+#if 0\n+// Files that use this one should first have:\n+#define INCLUDE_ALGORITHM\n+#define INCLUDE_FUNCTIONAL\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"rtl.h\"\n+#include \"df.h\"\n+#endif\n+\n+// Needed by splay-tree-utils.h and directly by rtl-ssa.\n+#include \"pretty-print.h\"\n+\n+// Needed directly by recog.h.\n+#include \"insn-config.h\"\n+\n+// Needed directly by rtl-ssa.\n+#include \"splay-tree-utils.h\"\n+#include \"recog.h\"\n+#include \"regs.h\"\n+#include \"function-abi.h\"\n+#include \"obstack-utils.h\"\n+#include \"mux-utils.h\"\n+#include \"rtlanal.h\"\n+\n+// Provides the global crtl->ssa.\n+#include \"tm_p.h\"\n+#include \"memmodel.h\"\n+#include \"emit-rtl.h\"\n+\n+// The rtl-ssa files themselves.\n+#include \"rtl-ssa/accesses.h\"\n+#include \"rtl-ssa/insns.h\"\n+#include \"rtl-ssa/blocks.h\"\n+#include \"rtl-ssa/changes.h\"\n+#include \"rtl-ssa/functions.h\"\n+#include \"rtl-ssa/is-a.inl\"\n+#include \"rtl-ssa/access-utils.h\"\n+#include \"rtl-ssa/insn-utils.h\"\n+#include \"rtl-ssa/movement.h\"\n+#include \"rtl-ssa/change-utils.h\"\n+#include \"rtl-ssa/member-fns.inl\"\n+\n+#endif"}, {"sha": "b200e3416d766296073847d294f3931f4e1dd475", "filename": "gcc/rtl-ssa/access-utils.h", "status": "added", "additions": 553, "deletions": 0, "changes": 553, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Faccess-utils.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Faccess-utils.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Faccess-utils.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,553 @@\n+// Access-related utilities for RTL SSA                             -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// Return a referene to the whole of register REGNO.\n+inline resource_info\n+full_register (unsigned int regno)\n+{\n+  return { reg_raw_mode[regno], regno };\n+}\n+\n+// Return true if sorted array ACCESSES includes an access to hard registers.\n+inline bool\n+accesses_include_hard_registers (const access_array &accesses)\n+{\n+  return accesses.size () && HARD_REGISTER_NUM_P (accesses.front ()->regno ());\n+}\n+\n+// Return true if sorted array ACCESSES includes an access to memory.\n+inline bool\n+accesses_include_memory (const access_array &accesses)\n+{\n+  return accesses.size () && accesses.back ()->is_mem ();\n+}\n+\n+// If sorted array ACCESSES includes an access to memory, return the access,\n+// otherwise return null.\n+template<typename T>\n+inline auto\n+memory_access (T accesses) -> decltype (accesses[0])\n+{\n+  if (accesses.size () && accesses.back ()->is_mem ())\n+    return accesses.back ();\n+  return nullptr;\n+}\n+\n+// If sorted array ACCESSES includes a reference to REGNO, return the\n+// access, otherwise return null.\n+template<typename T>\n+inline auto\n+find_access (T accesses, unsigned int regno) -> decltype (accesses[0])\n+{\n+  unsigned int start = 0;\n+  unsigned int end = accesses.size ();\n+  while (start < end)\n+    {\n+      unsigned int mid = (start + end) / 2;\n+      unsigned int found = accesses[mid]->regno ();\n+      if (found == regno)\n+\treturn accesses[mid];\n+      if (found < regno)\n+\tstart = mid + 1;\n+      else\n+\tend = mid;\n+    }\n+  return nullptr;\n+}\n+\n+// If sorted array ACCESSES includes a reference to REGNO, return the\n+// index of the access, otherwise return -1.\n+inline int\n+find_access_index (access_array accesses, unsigned int regno)\n+{\n+  unsigned int start = 0;\n+  unsigned int end = accesses.size ();\n+  while (start < end)\n+    {\n+      unsigned int mid = (start + end) / 2;\n+      unsigned int found = accesses[mid]->regno ();\n+      if (found == regno)\n+\treturn mid;\n+      if (found < regno)\n+\tstart = mid + 1;\n+      else\n+\tend = mid;\n+    }\n+  return -1;\n+}\n+\n+// If ACCESS is a set whose result is used by at least one instruction,\n+// return the access as a set_info, otherwise return null.\n+inline const set_info *\n+set_with_nondebug_insn_uses (const access_info *access)\n+{\n+  if (access->is_set_with_nondebug_insn_uses ())\n+    // No need for as_a; this test is just as definitive.\n+    return static_cast<const set_info *> (access);\n+  return nullptr;\n+}\n+\n+// A non-const version of the above.\n+inline set_info *\n+set_with_nondebug_insn_uses (access_info *access)\n+{\n+  if (access->is_set_with_nondebug_insn_uses ())\n+    return static_cast<set_info *> (access);\n+  return nullptr;\n+}\n+\n+// Return true if SET is the only set of SET->resource () and if it\n+// dominates all uses (excluding uses of SET->resource () at points\n+// where SET->resource () is always undefined).\n+inline bool\n+is_single_dominating_def (const set_info *set)\n+{\n+  return set->is_first_def () && set->is_last_def ();\n+}\n+\n+// SET is known to be available on entry to BB.  Return true if it is\n+// also available on exit from BB.  (The value might or might not be live.)\n+inline bool\n+remains_available_on_exit (const set_info *set, bb_info *bb)\n+{\n+  return (set->is_last_def ()\n+\t  || *set->next_def ()->insn () > *bb->end_insn ());\n+}\n+\n+// ACCESS is known to be associated with an instruction rather than\n+// a phi node.  Return which instruction that is.\n+inline insn_info *\n+access_insn (const access_info *access)\n+{\n+  // In release builds this function reduces to a single pointer reference.\n+  if (auto *def = dyn_cast<const def_info *> (access))\n+    return def->insn ();\n+  return as_a<const use_info *> (access)->insn ();\n+}\n+\n+// If ACCESS records a use, return the value that it uses.  If ACCESS records\n+// a set, return that set.  If ACCESS records a clobber, return null.\n+inline const set_info *\n+access_value (const access_info *access)\n+{\n+  if (!access)\n+    return nullptr;\n+\n+  if (auto *use = dyn_cast<const use_info *> (access))\n+    return use->def ();\n+\n+  return dyn_cast<const set_info *> (access);\n+}\n+\n+// A non-const version of the above.\n+inline set_info *\n+access_value (access_info *access)\n+{\n+  auto *const_access = const_cast<const access_info *> (access);\n+  return const_cast<set_info *> (access_value (const_access));\n+}\n+\n+// If ACCESS is a degenerate phi, return the set_info that defines its input,\n+// otherwise return ACCESS itself.\n+template<typename T>\n+inline const T *\n+look_through_degenerate_phi (const T *access)\n+{\n+  if (auto *phi = dyn_cast<const phi_info *> (access))\n+    if (phi->is_degenerate ())\n+      return phi->input_value (0);\n+  return access;\n+}\n+\n+// A non-const version of the above.\n+template<typename T>\n+inline T *\n+look_through_degenerate_phi (T *access)\n+{\n+  auto *const_access = const_cast<const T *> (access);\n+  return const_cast<T *> (look_through_degenerate_phi (const_access));\n+}\n+\n+// If CLOBBER is in a group, return the first clobber in the group,\n+// otherwise return CLOBBER itself.\n+inline clobber_info *\n+first_clobber_in_group (clobber_info *clobber)\n+{\n+  if (clobber->is_in_group ())\n+    return clobber->group ()->first_clobber ();\n+  return clobber;\n+}\n+\n+// If CLOBBER is in a group, return the last clobber in the group,\n+// otherwise return CLOBBER itself.\n+inline clobber_info *\n+last_clobber_in_group (clobber_info *clobber)\n+{\n+  if (clobber->is_in_group ())\n+    return clobber->group ()->last_clobber ();\n+  return clobber;\n+}\n+\n+// If DEF is a clobber in a group, return the containing group,\n+// otherwise return DEF.\n+inline def_mux\n+clobber_group_or_single_def (def_info *def)\n+{\n+  if (auto *clobber = dyn_cast<clobber_info *> (def))\n+    if (clobber->is_in_group ())\n+      return clobber->group ();\n+  return def;\n+}\n+\n+// Return the first definition associated with NODE.  If NODE holds\n+// a single set, the result is that set.  If NODE holds a clobber_group,\n+// the result is the first clobber in the group.\n+inline def_info *\n+first_def (def_node *node)\n+{\n+  return node->first_def ();\n+}\n+\n+// Likewise for something that is either a node or a single definition.\n+inline def_info *\n+first_def (def_mux mux)\n+{\n+  return mux.first_def ();\n+}\n+\n+// Return the last definition associated with NODE.  If NODE holds\n+// a single set, the result is that set.  If NODE holds a clobber_group,\n+// the result is the last clobber in the group.\n+inline def_info *\n+last_def (def_node *node)\n+{\n+  if (auto *group = dyn_cast<clobber_group *> (node))\n+    return group->last_clobber ();\n+  return node->first_def ();\n+}\n+\n+// Likewise for something that is either a node or a single definition.\n+inline def_info *\n+last_def (def_mux mux)\n+{\n+  return mux.last_def ();\n+}\n+\n+int lookup_use (splay_tree<use_info *> &, insn_info *);\n+int lookup_def (def_splay_tree &, insn_info *);\n+int lookup_clobber (clobber_tree &, insn_info *);\n+int lookup_call_clobbers (insn_call_clobbers_tree &, insn_info *);\n+\n+// Search backwards from immediately before INSN for the first instruction\n+// recorded in TREE, ignoring any instruction I for which IGNORE (I) is true.\n+// Return null if no such instruction exists.\n+template<typename IgnorePredicate>\n+insn_info *\n+prev_call_clobbers_ignoring (insn_call_clobbers_tree &tree, insn_info *insn,\n+\t\t\t     IgnorePredicate ignore)\n+{\n+  if (!tree)\n+    return nullptr;\n+\n+  int comparison = lookup_call_clobbers (tree, insn);\n+  while (comparison <= 0 || ignore (tree->insn ()))\n+    {\n+      if (!tree.splay_prev_node ())\n+\treturn nullptr;\n+\n+      comparison = 1;\n+    }\n+  return tree->insn ();\n+}\n+\n+// Search forwards from immediately after INSN for the first instruction\n+// recorded in TREE, ignoring any instruction I for which IGNORE (I) is true.\n+// Return null if no such instruction exists.\n+template<typename IgnorePredicate>\n+insn_info *\n+next_call_clobbers_ignoring (insn_call_clobbers_tree &tree, insn_info *insn,\n+\t\t\t     IgnorePredicate ignore)\n+{\n+  if (!tree)\n+    return nullptr;\n+\n+  int comparison = lookup_call_clobbers (tree, insn);\n+  while (comparison >= 0 || ignore (tree->insn ()))\n+    {\n+      if (!tree.splay_next_node ())\n+\treturn nullptr;\n+\n+      comparison = -1;\n+    }\n+  return tree->insn ();\n+}\n+\n+// If ACCESS is a set, return the first use of ACCESS by a nondebug insn I\n+// for which IGNORE (I) is false.  Return null if ACCESS is not a set or if\n+// no such use exists.\n+template<typename IgnorePredicate>\n+inline use_info *\n+first_nondebug_insn_use_ignoring (const access_info *access,\n+\t\t\t\t  IgnorePredicate ignore)\n+{\n+  if (const set_info *set = set_with_nondebug_insn_uses (access))\n+    {\n+      // Written this way to emphasize to the compiler that first_use\n+      // must be nonnull in this situation.\n+      use_info *use = set->first_use ();\n+      do\n+\t{\n+\t  if (!ignore (use->insn ()))\n+\t    return use;\n+\t  use = use->next_nondebug_insn_use ();\n+\t}\n+      while (use);\n+    }\n+  return nullptr;\n+}\n+\n+// If ACCESS is a set, return the last use of ACCESS by a nondebug insn I for\n+// which IGNORE (I) is false.  Return null if ACCESS is not a set or if no\n+// such use exists.\n+template<typename IgnorePredicate>\n+inline use_info *\n+last_nondebug_insn_use_ignoring (const access_info *access,\n+\t\t\t\t IgnorePredicate ignore)\n+{\n+  if (const set_info *set = set_with_nondebug_insn_uses (access))\n+    {\n+      // Written this way to emphasize to the compiler that\n+      // last_nondebug_insn_use must be nonnull in this situation.\n+      use_info *use = set->last_nondebug_insn_use ();\n+      do\n+\t{\n+\t  if (!ignore (use->insn ()))\n+\t    return use;\n+\t  use = use->prev_use ();\n+\t}\n+      while (use);\n+    }\n+  return nullptr;\n+}\n+\n+// If DEF is null, return null.\n+//\n+// Otherwise, search backwards for an access to DEF->resource (), starting at\n+// the end of DEF's live range.  Ignore clobbers if IGNORE_CLOBBERS_SETTING\n+// is YES, otherwise treat them like any other access.  Also ignore any\n+// access A for which IGNORE (access_insn (A)) is true.\n+//\n+// Thus if DEF is a set that is used by nondebug insns, the first access\n+// that the function considers is the last such use of the set.  Otherwise,\n+// the first access that the function considers is DEF itself.\n+//\n+// Return the access found, or null if there is no access that meets\n+// the criteria.\n+//\n+// Note that this function does not consider separately-recorded call clobbers,\n+// although such clobbers are only relevant if IGNORE_CLOBBERS_SETTING is NO.\n+template<typename IgnorePredicate>\n+access_info *\n+last_access_ignoring (def_info *def, ignore_clobbers ignore_clobbers_setting,\n+\t\t      IgnorePredicate ignore)\n+{\n+  while (def)\n+    {\n+      auto *clobber = dyn_cast<clobber_info *> (def);\n+      if (clobber && ignore_clobbers_setting == ignore_clobbers::YES)\n+\tdef = first_clobber_in_group (clobber);\n+      else\n+\t{\n+\t  if (use_info *use = last_nondebug_insn_use_ignoring (def, ignore))\n+\t    return use;\n+\n+\t  insn_info *insn = def->insn ();\n+\t  if (!ignore (insn))\n+\t    return def;\n+\t}\n+      def = def->prev_def ();\n+    }\n+  return nullptr;\n+}\n+\n+// Search backwards for an access to DEF->resource (), starting\n+// immediately before the point at which DEF occurs.  Ignore clobbers\n+// if IGNORE_CLOBBERS_SETTING is YES, otherwise treat them like any other\n+// access.  Also ignore any access A for which IGNORE (access_insn (A))\n+// is true.\n+//\n+// Thus if DEF->insn () uses DEF->resource (), that use is the first access\n+// that the function considers, since an instruction's uses occur strictly\n+// before its definitions.\n+//\n+// Note that this function does not consider separately-recorded call clobbers,\n+// although such clobbers are only relevant if IGNORE_CLOBBERS_SETTING is NO.\n+template<typename IgnorePredicate>\n+inline access_info *\n+prev_access_ignoring (def_info *def, ignore_clobbers ignore_clobbers_setting,\n+\t\t      IgnorePredicate ignore)\n+{\n+  return last_access_ignoring (def->prev_def (), ignore_clobbers_setting,\n+\t\t\t       ignore);\n+}\n+\n+// If DEF is null, return null.\n+//\n+// Otherwise, search forwards for a definition of DEF->resource (),\n+// starting at DEF itself.  Ignore clobbers if IGNORE_CLOBBERS_SETTING\n+// is YES, otherwise treat them like any other access.  Also ignore any\n+// definition D for which IGNORE (D->insn ()) is true.\n+//\n+// Return the definition found, or null if there is no access that meets\n+// the criteria.\n+//\n+// Note that this function does not consider separately-recorded call clobbers,\n+// although such clobbers are only relevant if IGNORE_CLOBBERS_SETTING is NO.\n+template<typename IgnorePredicate>\n+def_info *\n+first_def_ignoring (def_info *def, ignore_clobbers ignore_clobbers_setting,\n+\t\t    IgnorePredicate ignore)\n+{\n+  while (def)\n+    {\n+      auto *clobber = dyn_cast<clobber_info *> (def);\n+      if (clobber && ignore_clobbers_setting == ignore_clobbers::YES)\n+\tdef = last_clobber_in_group (clobber);\n+      else if (!ignore (def->insn ()))\n+\treturn def;\n+\n+      def = def->next_def ();\n+    }\n+  return nullptr;\n+}\n+\n+// Search forwards for the next access to DEF->resource (),\n+// starting immediately after DEF's instruction.  Ignore clobbers if\n+// IGNORE_CLOBBERS_SETTING is YES, otherwise treat them like any other access.\n+// Also ignore any access A for which IGNORE (access_insn (A)) is true;\n+// in this context, ignoring a set includes ignoring all uses of the set.\n+//\n+// Thus if DEF is a set with uses by nondebug insns, the first access that the\n+// function considers is the first such use of the set.\n+//\n+// Return the access found, or null if there is no access that meets the\n+// criteria.\n+//\n+// Note that this function does not consider separately-recorded call clobbers,\n+// although such clobbers are only relevant if IGNORE_CLOBBERS_SETTING is NO.\n+template<typename IgnorePredicate>\n+access_info *\n+next_access_ignoring (def_info *def, ignore_clobbers ignore_clobbers_setting,\n+\t\t      IgnorePredicate ignore)\n+{\n+  if (use_info *use = first_nondebug_insn_use_ignoring (def, ignore))\n+    return use;\n+\n+  return first_def_ignoring (def->next_def (), ignore_clobbers_setting,\n+\t\t\t     ignore);\n+}\n+\n+// Return true if ACCESS1 should before ACCESS2 in an access_array.\n+inline bool\n+compare_access_infos (const access_info *access1, const access_info *access2)\n+{\n+  gcc_checking_assert (access1 == access2\n+\t\t       || access1->regno () != access2->regno ());\n+  return access1->regno () < access2->regno ();\n+}\n+\n+// Sort [BEGIN, END) into ascending regno order.  The sequence must have\n+// at most one access to a given a regno.\n+inline void\n+sort_accesses (access_info **begin, access_info **end)\n+{\n+  auto count = end - begin;\n+  if (count <= 1)\n+    return;\n+\n+  if (count == 2)\n+    {\n+      gcc_checking_assert (begin[0]->regno () != begin[1]->regno ());\n+      if (begin[0]->regno () > begin[1]->regno ())\n+\tstd::swap (begin[0], begin[1]);\n+      return;\n+    }\n+\n+  std::sort (begin, end, compare_access_infos);\n+}\n+\n+// Sort the accesses in CONTAINER, which contains pointers to access_infos.\n+template<typename T>\n+inline void\n+sort_accesses (T &container)\n+{\n+  return sort_accesses (container.begin (), container.end ());\n+}\n+\n+// The underlying non-template implementation of merge_access_arrays.\n+access_array merge_access_arrays_base (obstack_watermark &, access_array,\n+\t\t\t\t       access_array);\n+// Merge access arrays ACCESSES1 and ACCESSES2, including the allocation\n+// in the area governed by WATERMARK.  Return an invalid access_array if\n+// ACCESSES1 and ACCESSES2 contain conflicting accesses to the same resource.\n+//\n+// T can be an access_array, a def_array or a use_array.\n+template<typename T>\n+inline T\n+merge_access_arrays (obstack_watermark &watermark, T accesses1, T accesses2)\n+{\n+  return T (merge_access_arrays_base (watermark, accesses1, accesses2));\n+}\n+\n+// The underlying non-template implementation of insert_access.\n+access_array insert_access_base (obstack_watermark &, access_info *,\n+\t\t\t\t access_array);\n+\n+// Return a new access_array that contains the result of inserting ACCESS1\n+// into sorted access array ACCESSES2.  Allocate the returned array in the\n+// area governed by WATERMARK.  Return an invalid access_array if ACCESSES2\n+// contains a conflicting access to the same resource as ACCESS1.\n+//\n+// T can be an access_array, a def_array or a use_array.\n+template<typename T>\n+inline T\n+insert_access (obstack_watermark &watermark,\n+\t       typename T::value_type access1, T accesses2)\n+{\n+  return T (insert_access_base (watermark, access1, accesses2));\n+}\n+\n+// The underlying non-template implementation of remove_note_accesses.\n+access_array remove_note_accesses_base (obstack_watermark &, access_array);\n+\n+// If ACCESSES contains accesses that only occur in notes, return a new\n+// array without such accesses, allocating it in the area governed by\n+// WATERMARK.  Return ACCESSES itself otherwise.\n+//\n+// T can be an access_array, a def_array or a use_array.\n+template<typename T>\n+inline T\n+remove_note_accesses (obstack_watermark &watermark, T accesses)\n+{\n+  return T (remove_note_accesses_base (watermark, accesses));\n+}\n+\n+}"}, {"sha": "6a28007c97ccfcd5938579415a8b0434f66ccf7c", "filename": "gcc/rtl-ssa/accesses.cc", "status": "added", "additions": 1594, "deletions": 0, "changes": 1594, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Faccesses.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Faccesses.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Faccesses.cc?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,1594 @@\n+// Implementation of access-related functions for RTL SSA           -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#define INCLUDE_ALGORITHM\n+#define INCLUDE_FUNCTIONAL\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"rtl.h\"\n+#include \"df.h\"\n+#include \"rtl-ssa.h\"\n+#include \"rtl-ssa/internals.inl\"\n+\n+using namespace rtl_ssa;\n+\n+// This clobber belongs to a clobber_group but m_group appears to be\n+// out of date.  Update it and return the new (correct) value.\n+clobber_group *\n+clobber_info::recompute_group ()\n+{\n+  using splay_tree = clobber_info::splay_tree;\n+\n+  // Splay this clobber to the root of the tree while searching for a node\n+  // that has the correct group.  The root always has the correct group,\n+  // so the search always breaks early and does not install this clobber\n+  // as the root.\n+  clobber_info *cursor = m_parent;\n+  auto find_group = [](clobber_info *node, unsigned int)\n+    {\n+      return node->m_group->has_been_superceded () ? nullptr : node->m_group;\n+    };\n+  clobber_group *group = splay_tree::splay_and_search (this, nullptr,\n+\t\t\t\t\t\t       find_group);\n+  gcc_checking_assert (m_parent);\n+\n+  // If the previous splay operation did anything, this clobber is now an\n+  // ancestor of CURSOR, and all the nodes inbetween have a stale group.\n+  // Since we have visited the nodes, we might as well update them too.\n+  //\n+  // If the previous splay operation did nothing, start the update from\n+  // this clobber instead.  In that case we change at most two clobbers:\n+  // this clobber and possibly its parent.\n+  if (cursor == m_parent)\n+    cursor = this;\n+\n+  // Walk up the tree from CURSOR updating clobbers that need it.\n+  // This walk always includes this clobber.\n+  while (cursor->m_group != group)\n+    {\n+      cursor->m_group = group;\n+      cursor = cursor->m_parent;\n+    }\n+\n+  gcc_checking_assert (m_group == group);\n+  return group;\n+}\n+\n+// See the comment above the declaration.\n+void\n+resource_info::print_identifier (pretty_printer *pp) const\n+{\n+  if (is_mem ())\n+    pp_string (pp, \"mem\");\n+  else\n+    {\n+      char tmp[3 * sizeof (regno) + 2];\n+      snprintf (tmp, sizeof (tmp), \"r%d\", regno);\n+      pp_string (pp, tmp);\n+    }\n+}\n+\n+// See the comment above the declaration.\n+void\n+resource_info::print_context (pretty_printer *pp) const\n+{\n+  if (HARD_REGISTER_NUM_P (regno))\n+    {\n+      if (const char *name = reg_names[regno])\n+\t{\n+\t  pp_space (pp);\n+\t  pp_left_paren (pp);\n+\t  pp_string (pp, name);\n+\t  if (mode != E_BLKmode)\n+\t    {\n+\t      pp_colon (pp);\n+\t      pp_string (pp, GET_MODE_NAME (mode));\n+\t    }\n+\t  pp_right_paren (pp);\n+\t}\n+    }\n+  else if (is_reg ())\n+    {\n+      pp_space (pp);\n+      pp_left_paren (pp);\n+      if (mode != E_BLKmode)\n+\t{\n+\t  pp_string (pp, GET_MODE_NAME (mode));\n+\t  pp_space (pp);\n+\t}\n+      pp_string (pp, \"pseudo\");\n+      pp_right_paren (pp);\n+    }\n+}\n+\n+// See the comment above the declaration.\n+void\n+resource_info::print (pretty_printer *pp) const\n+{\n+  print_identifier (pp);\n+  print_context (pp);\n+}\n+\n+// Some properties can naturally be described using adjectives that attach\n+// to nouns like \"use\" or \"definition\".  Print such adjectives to PP.\n+void\n+access_info::print_prefix_flags (pretty_printer *pp) const\n+{\n+  if (m_is_temp)\n+    pp_string (pp, \"temporary \");\n+  if (m_has_been_superceded)\n+    pp_string (pp, \"superceded \");\n+}\n+\n+// Print properties not handled by print_prefix_flags to PP, putting\n+// each property on a new line indented by two extra spaces.\n+void\n+access_info::print_properties_on_new_lines (pretty_printer *pp) const\n+{\n+  if (m_is_pre_post_modify)\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"set by a pre/post-modify\");\n+      pp_indentation (pp) -= 2;\n+    }\n+  if (m_includes_address_uses)\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"appears inside an address\");\n+      pp_indentation (pp) -= 2;\n+    }\n+  if (m_includes_read_writes)\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"appears in a read/write context\");\n+      pp_indentation (pp) -= 2;\n+    }\n+  if (m_includes_subregs)\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"appears inside a subreg\");\n+      pp_indentation (pp) -= 2;\n+    }\n+}\n+\n+// Return true if there are no known issues with the integrity of the\n+// link information.\n+inline bool\n+use_info::check_integrity ()\n+{\n+  auto subsequence_id = [](use_info *use)\n+    {\n+      if (use->is_in_nondebug_insn ())\n+\treturn 1;\n+      if (use->is_in_debug_insn ())\n+\treturn 2;\n+      return 3;\n+    };\n+\n+  use_info *prev = prev_use ();\n+  use_info *next = next_use ();\n+\n+  if (prev && subsequence_id (prev) > subsequence_id (this))\n+    return false;\n+  if (next && subsequence_id (next) < subsequence_id (this))\n+    return false;\n+  if (m_is_last_nondebug_insn_use != calculate_is_last_nondebug_insn_use ())\n+    return false;\n+\n+  if (!prev && last_use ()->next_use ())\n+    return false;\n+  if (!next)\n+    if (use_info *use = last_nondebug_insn_use ())\n+      if (!use->m_is_last_nondebug_insn_use)\n+\treturn false;\n+\n+  return true;\n+}\n+\n+// See the comment above the declaration.\n+void\n+use_info::print_location (pretty_printer *pp) const\n+{\n+  if (is_in_phi ())\n+    pp_access (pp, phi (), PP_ACCESS_INCLUDE_LOCATION);\n+  else\n+    insn ()->print_identifier_and_location (pp);\n+}\n+\n+// See the comment above the declaration.\n+void\n+use_info::print_def (pretty_printer *pp) const\n+{\n+  if (const set_info *set = def ())\n+    pp_access (pp, set, 0);\n+  else\n+    {\n+      pp_string (pp, \"undefined \");\n+      resource ().print (pp);\n+    }\n+}\n+\n+// See the comment above the declaration.\n+void\n+use_info::print (pretty_printer *pp, unsigned int flags) const\n+{\n+  print_prefix_flags (pp);\n+\n+  const set_info *set = def ();\n+  if (set && set->mode () != mode ())\n+    {\n+      pp_string (pp, GET_MODE_NAME (mode ()));\n+      pp_space (pp);\n+    }\n+\n+  pp_string (pp, \"use of \");\n+  print_def (pp);\n+  if (flags & PP_ACCESS_INCLUDE_LOCATION)\n+    {\n+      pp_string (pp, \" by \");\n+      print_location (pp);\n+    }\n+  if (set && (flags & PP_ACCESS_INCLUDE_LINKS))\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"defined in \");\n+      set->insn ()->print_location (pp);\n+      pp_indentation (pp) -= 2;\n+    }\n+  if (flags & PP_ACCESS_INCLUDE_PROPERTIES)\n+    print_properties_on_new_lines (pp);\n+}\n+\n+// See the comment above the declaration.\n+void\n+def_info::print_identifier (pretty_printer *pp) const\n+{\n+  resource ().print_identifier (pp);\n+  pp_colon (pp);\n+  insn ()->print_identifier (pp);\n+  resource ().print_context (pp);\n+}\n+\n+// See the comment above the declaration.\n+void\n+def_info::print_location (pretty_printer *pp) const\n+{\n+  insn ()->print_identifier_and_location (pp);\n+}\n+\n+// See the comment above the declaration.\n+void\n+clobber_info::print (pretty_printer *pp, unsigned int flags) const\n+{\n+  print_prefix_flags (pp);\n+  if (is_call_clobber ())\n+    pp_string (pp, \"call \");\n+  pp_string (pp, \"clobber \");\n+  print_identifier (pp);\n+  if (flags & PP_ACCESS_INCLUDE_LOCATION)\n+    {\n+      pp_string (pp, \" in \");\n+      insn ()->print_location (pp);\n+    }\n+  if (flags & PP_ACCESS_INCLUDE_PROPERTIES)\n+    print_properties_on_new_lines (pp);\n+}\n+\n+// See the comment above the declaration.\n+void\n+set_info::print_uses_on_new_lines (pretty_printer *pp) const\n+{\n+  for (const use_info *use : all_uses ())\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      if (use->is_live_out_use ())\n+\t{\n+\t  pp_string (pp, \"live out from \");\n+\t  use->insn ()->print_location (pp);\n+\t}\n+      else\n+\t{\n+\t  pp_string (pp, \"used by \");\n+\t  use->print_location (pp);\n+\t}\n+      pp_indentation (pp) -= 2;\n+    }\n+  if (m_use_tree)\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"splay tree:\");\n+      pp_newline_and_indent (pp, 2);\n+      auto print_use = [](pretty_printer *pp,\n+\t\t\t  splay_tree_node<use_info *> *node)\n+\t{\n+\t  pp_string (pp, \"use by \");\n+\t  node->value ()->print_location (pp);\n+\t};\n+      m_use_tree.print (pp, m_use_tree.root (), print_use);\n+      pp_indentation (pp) -= 4;\n+    }\n+}\n+\n+// See the comment above the declaration.\n+void\n+set_info::print (pretty_printer *pp, unsigned int flags) const\n+{\n+  print_prefix_flags (pp);\n+  pp_string (pp, \"set \");\n+  print_identifier (pp);\n+  if (flags & PP_ACCESS_INCLUDE_LOCATION)\n+    {\n+      pp_string (pp, \" in \");\n+      insn ()->print_location (pp);\n+    }\n+  if (flags & PP_ACCESS_INCLUDE_PROPERTIES)\n+    print_properties_on_new_lines (pp);\n+  if (flags & PP_ACCESS_INCLUDE_LINKS)\n+    print_uses_on_new_lines (pp);\n+}\n+\n+// See the comment above the declaration.\n+void\n+phi_info::print (pretty_printer *pp, unsigned int flags) const\n+{\n+  print_prefix_flags (pp);\n+  pp_string (pp, \"phi node \");\n+  print_identifier (pp);\n+  if (flags & PP_ACCESS_INCLUDE_LOCATION)\n+    {\n+      pp_string (pp, \" in \");\n+      insn ()->print_location (pp);\n+    }\n+\n+  if (flags & PP_ACCESS_INCLUDE_PROPERTIES)\n+    print_properties_on_new_lines (pp);\n+\n+  if (flags & PP_ACCESS_INCLUDE_LINKS)\n+    {\n+      basic_block cfg_bb = bb ()->cfg_bb ();\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"inputs:\");\n+      unsigned int i = 0;\n+      for (const use_info *input : inputs ())\n+\t{\n+\t  basic_block pred_cfg_bb = EDGE_PRED (cfg_bb, i)->src;\n+\t  pp_newline_and_indent (pp, 2);\n+\t  pp_string (pp, \"bb\");\n+\t  pp_decimal_int (pp, pred_cfg_bb->index);\n+\t  pp_colon (pp);\n+\t  pp_space (pp);\n+\t  input->print_def (pp);\n+\t  pp_indentation (pp) -= 2;\n+\t  i += 1;\n+\t}\n+      pp_indentation (pp) -= 2;\n+\n+      print_uses_on_new_lines (pp);\n+    }\n+}\n+\n+// See the comment above the declaration.\n+void\n+set_node::print (pretty_printer *pp) const\n+{\n+  pp_access (pp, first_def ());\n+}\n+\n+// See the comment above the declaration.\n+void\n+clobber_group::print (pretty_printer *pp) const\n+{\n+  auto print_clobber = [](pretty_printer *pp, const def_info *clobber)\n+    {\n+      pp_access (pp, clobber);\n+    };\n+  pp_string (pp, \"grouped clobber\");\n+  for (const def_info *clobber : clobbers ())\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      print_clobber (pp, clobber);\n+      pp_indentation (pp) -= 2;\n+    }\n+  pp_newline_and_indent (pp, 2);\n+  pp_string (pp, \"splay tree\");\n+  pp_newline_and_indent (pp, 2);\n+  m_clobber_tree.print (pp, print_clobber);\n+  pp_indentation (pp) -= 4;\n+}\n+\n+// Return a clobber_group for CLOBBER, creating one if CLOBBER doesn't\n+// already belong to a group.\n+clobber_group *\n+function_info::need_clobber_group (clobber_info *clobber)\n+{\n+  if (clobber->is_in_group ())\n+    return clobber->group ();\n+  return allocate<clobber_group> (clobber);\n+}\n+\n+// Return a def_node for inserting DEF into the associated resource's\n+// splay tree.  Use a clobber_group if DEF is a clobber and a set_node\n+// otherwise.\n+def_node *\n+function_info::need_def_node (def_info *def)\n+{\n+  if (auto *clobber = dyn_cast<clobber_info *> (def))\n+    return need_clobber_group (clobber);\n+  return allocate<set_node> (as_a<set_info *> (def));\n+}\n+\n+// LAST is the last thing to define LAST->resource (), and is where any\n+// splay tree root for LAST->resource () is stored.  Require such a splay tree\n+// to exist, creating a new one if necessary.  Return the root of the tree.\n+//\n+// The caller must call LAST->set_splay_root after it has finished with\n+// the splay tree.\n+def_splay_tree\n+function_info::need_def_splay_tree (def_info *last)\n+{\n+  if (def_node *root = last->splay_root ())\n+    return root;\n+\n+  // Use a left-spine rooted at the last node.\n+  def_node *root = need_def_node (last);\n+  def_node *parent = root;\n+  while (def_info *prev = first_def (parent)->prev_def ())\n+    {\n+      def_node *node = need_def_node (prev);\n+      def_splay_tree::insert_child (parent, 0, node);\n+      parent = node;\n+    }\n+  return root;\n+}\n+\n+// Search TREE for either:\n+//\n+// - a set_info at INSN or\n+// - a clobber_group whose range includes INSN\n+//\n+// If such a node exists, install it as the root of TREE and return 0.\n+// Otherwise arbitrarily choose between:\n+//\n+// (1) Installing the closest preceding node as the root and returning 1.\n+// (2) Installing the closest following node as the root and returning -1.\n+//\n+// Note that this routine should not be used to check whether INSN\n+// itself defines a resource; that can be checked more cheaply using\n+// find_access_index.\n+int\n+rtl_ssa::lookup_def (def_splay_tree &tree, insn_info *insn)\n+{\n+  auto go_left = [&](def_node *node)\n+    {\n+      return *insn < *first_def (node)->insn ();\n+    };\n+  auto go_right = [&](def_node *node)\n+    {\n+      return *insn > *last_def (node)->insn ();\n+    };\n+  return tree.lookup (go_left, go_right);\n+}\n+\n+// Search TREE for a clobber in INSN.  If such a clobber exists, install\n+// it as the root of TREE and return 0.  Otherwise arbitrarily choose between:\n+//\n+// (1) Installing the closest preceding clobber as the root and returning 1.\n+// (2) Installing the closest following clobber as the root and returning -1.\n+int\n+rtl_ssa::lookup_clobber (clobber_tree &tree, insn_info *insn)\n+{\n+  auto compare = [&](clobber_info *clobber)\n+    {\n+      return insn->compare_with (clobber->insn ());\n+    };\n+  return tree.lookup (compare);\n+}\n+\n+// Search for a definition of RESOURCE at INSN and return the result of\n+// the search as a def_lookup.  See the comment above the class for more\n+// details.\n+def_lookup\n+function_info::find_def (resource_info resource, insn_info *insn)\n+{\n+  def_info *first = m_defs[resource.regno + 1];\n+  if (!first)\n+    // There are no nodes.  The comparison result is pretty meaningless\n+    // in this case.\n+    return { nullptr, -1 };\n+\n+  // See whether the first node matches.\n+  auto first_result = clobber_group_or_single_def (first);\n+  if (*insn <= *last_def (first_result)->insn ())\n+    {\n+      int comparison = (*insn >= *first->insn () ? 0 : -1);\n+      return { first_result, comparison };\n+    }\n+\n+  // See whether the last node matches.\n+  def_info *last = first->last_def ();\n+  auto last_result = clobber_group_or_single_def (last);\n+  if (*insn >= *first_def (last_result)->insn ())\n+    {\n+      int comparison = (*insn <= *last->insn () ? 0 : 1);\n+      return { last_result, comparison };\n+    }\n+\n+  // Resort to using a splay tree to search for the result.\n+  def_splay_tree tree = need_def_splay_tree (last);\n+  int comparison = lookup_def (tree, insn);\n+  last->set_splay_root (tree.root ());\n+  return { tree.root (), comparison };\n+}\n+\n+// Add DEF to the function's list of definitions of DEF->resource (),\n+// inserting DEF immediately before BEFORE.  DEF is not currently in the list.\n+void\n+function_info::insert_def_before (def_info *def, def_info *before)\n+{\n+  gcc_checking_assert (!def->has_def_links ()\n+\t\t       && *before->insn () > *def->insn ());\n+\n+  def->copy_prev_from (before);\n+  if (def_info *prev = def->prev_def ())\n+    {\n+      gcc_checking_assert (*prev->insn () < *def->insn ());\n+      prev->set_next_def (def);\n+    }\n+  else\n+    m_defs[def->regno () + 1] = def;\n+\n+  def->set_next_def (before);\n+  before->set_prev_def (def);\n+}\n+\n+// Add DEF to the function's list of definitions of DEF->resource (),\n+// inserting DEF immediately after AFTER.  DEF is not currently in the list.\n+void\n+function_info::insert_def_after (def_info *def, def_info *after)\n+{\n+  gcc_checking_assert (!def->has_def_links ()\n+\t\t       && *after->insn () < *def->insn ());\n+\n+  def->copy_next_from (after);\n+  if (def_info *next = def->next_def ())\n+    {\n+      gcc_checking_assert (*next->insn () > *def->insn ());\n+      next->set_prev_def (def);\n+    }\n+  else\n+    m_defs[def->regno () + 1]->set_last_def (def);\n+\n+  def->set_prev_def (after);\n+  after->set_next_def (def);\n+}\n+\n+// Remove DEF from the function's list of definitions of DEF->resource ().\n+void\n+function_info::remove_def_from_list (def_info *def)\n+{\n+  def_info *prev = def->prev_def ();\n+  def_info *next = def->next_def ();\n+\n+  if (next)\n+    next->copy_prev_from (def);\n+  else\n+    m_defs[def->regno () + 1]->set_last_def (prev);\n+\n+  if (prev)\n+    prev->copy_next_from (def);\n+  else\n+    m_defs[def->regno () + 1] = next;\n+\n+  def->clear_def_links ();\n+}\n+\n+// Add CLOBBER to GROUP and insert it into the function's list of\n+// accesses to CLOBBER->resource ().  CLOBBER is not currently part\n+// of an active group and is not currently in the list.\n+void\n+function_info::add_clobber (clobber_info *clobber, clobber_group *group)\n+{\n+  // Search for either the previous or next clobber in the group.\n+  // The result is less than zero if CLOBBER should come before NEIGHBOR\n+  // or greater than zero if CLOBBER should come after NEIGHBOR.\n+  int comparison = lookup_clobber (group->m_clobber_tree, clobber->insn ());\n+  gcc_checking_assert (comparison != 0);\n+  clobber_info *neighbor = group->m_clobber_tree.root ();\n+\n+  // Since HEIGHBOR is now the root of the splay tree, its group needs\n+  // to be up-to-date.\n+  neighbor->update_group (group);\n+\n+  // If CLOBBER comes before NEIGHBOR, insert CLOBBER to NEIGHBOR's left,\n+  // otherwise insert CLOBBER to NEIGHBOR's right.\n+  clobber_info::splay_tree::insert_child (neighbor, comparison > 0, clobber);\n+  clobber->set_group (group);\n+\n+  // Insert the clobber into the function-wide list and update the\n+  // bounds of the group.\n+  if (comparison > 0)\n+    {\n+      insert_def_after (clobber, neighbor);\n+      if (neighbor == group->last_clobber ())\n+\tgroup->set_last_clobber (clobber);\n+    }\n+  else\n+    {\n+      insert_def_before (clobber, neighbor);\n+      if (neighbor == group->first_clobber ())\n+\tgroup->set_first_clobber (clobber);\n+    }\n+}\n+\n+// Remove CLOBBER from GROUP, given that GROUP contains other clobbers too.\n+// Also remove CLOBBER from the function's list of accesses to\n+// CLOBBER->resource ().\n+void\n+function_info::remove_clobber (clobber_info *clobber, clobber_group *group)\n+{\n+  if (clobber == group->first_clobber ())\n+    {\n+      auto *new_first = as_a<clobber_info *> (clobber->next_def ());\n+      group->set_first_clobber (new_first);\n+      new_first->update_group (group);\n+    }\n+  else if (clobber == group->last_clobber ())\n+    {\n+      auto *new_last = as_a<clobber_info *> (clobber->prev_def ());\n+      group->set_last_clobber (new_last);\n+      new_last->update_group (group);\n+    }\n+\n+  clobber_info *replacement = clobber_info::splay_tree::remove_node (clobber);\n+  if (clobber == group->m_clobber_tree.root ())\n+    {\n+      group->m_clobber_tree = replacement;\n+      replacement->update_group (group);\n+    }\n+  clobber->set_group (nullptr);\n+\n+  remove_def_from_list (clobber);\n+}\n+\n+// Add CLOBBER immediately before the first clobber in GROUP, given that\n+// CLOBBER is not currently part of any group.\n+void\n+function_info::prepend_clobber_to_group (clobber_info *clobber,\n+\t\t\t\t\t clobber_group *group)\n+{\n+  clobber_info *next = group->first_clobber ();\n+  clobber_info::splay_tree::insert_child (next, 0, clobber);\n+  group->set_first_clobber (clobber);\n+  clobber->set_group (group);\n+}\n+\n+// Add CLOBBER immediately after the last clobber in GROUP, given that\n+// CLOBBER is not currently part of any group.\n+void\n+function_info::append_clobber_to_group (clobber_info *clobber,\n+\t\t\t\t\tclobber_group *group)\n+{\n+  clobber_info *prev = group->last_clobber ();\n+  clobber_info::splay_tree::insert_child (prev, 1, clobber);\n+  group->set_last_clobber (clobber);\n+  clobber->set_group (group);\n+}\n+\n+// Put CLOBBER1 and CLOBBER2 into the same clobber_group, given that\n+// CLOBBER1 occurs immediately before CLOBBER2 and that the two clobbers\n+// are not currently in the same group.  LAST is the last definition of\n+// the associated resource, and is where any splay tree is stored.\n+void\n+function_info::merge_clobber_groups (clobber_info *clobber1,\n+\t\t\t\t     clobber_info *clobber2,\n+\t\t\t\t     def_info *last)\n+{\n+  if (clobber1->is_in_group () && clobber2->is_in_group ())\n+    {\n+      clobber_group *group1 = clobber1->group ();\n+      clobber_group *group2 = clobber2->group ();\n+      gcc_checking_assert (clobber1 == group1->last_clobber ()\n+\t\t\t   && clobber2 == group2->first_clobber ());\n+\n+      if (def_splay_tree tree = last->splay_root ())\n+\t{\n+\t  // Remove GROUP2 from the splay tree.\n+\t  int comparison = lookup_def (tree, clobber2->insn ());\n+\t  gcc_checking_assert (comparison == 0);\n+\t  tree.remove_root ();\n+\t  last->set_splay_root (tree.root ());\n+\t}\n+\n+      // Splice the trees together.\n+      group1->m_clobber_tree.splice_next_tree (group2->m_clobber_tree);\n+\n+      // Bring the two extremes of GROUP2 under GROUP1.  Any other\n+      // clobbers in the group are updated lazily on demand.\n+      clobber2->set_group (group1);\n+      group2->last_clobber ()->set_group (group1);\n+      group1->set_last_clobber (group2->last_clobber ());\n+\n+      // Record that GROUP2 is no more.\n+      group2->set_first_clobber (nullptr);\n+      group2->set_last_clobber (nullptr);\n+      group2->m_clobber_tree = nullptr;\n+    }\n+  else\n+    {\n+      // In this case there can be no active splay tree.\n+      gcc_assert (!last->splay_root ());\n+      if (clobber2->is_in_group ())\n+\tprepend_clobber_to_group (clobber1, clobber2->group ());\n+      else\n+\tappend_clobber_to_group (clobber2, need_clobber_group (clobber1));\n+    }\n+}\n+\n+// GROUP spans INSN, and INSN now sets the resource that GROUP clobbers.\n+// Split GROUP around INSN and return the clobber that comes immediately\n+// before INSN.\n+clobber_info *\n+function_info::split_clobber_group (clobber_group *group, insn_info *insn)\n+{\n+  // Search for either the previous or next clobber in the group.\n+  // The result is less than zero if CLOBBER should come before NEIGHBOR\n+  // or greater than zero if CLOBBER should come after NEIGHBOR.\n+  int comparison = lookup_clobber (group->m_clobber_tree, insn);\n+  gcc_checking_assert (comparison != 0);\n+  clobber_info *neighbor = group->m_clobber_tree.root ();\n+\n+  clobber_tree tree1, tree2;\n+  clobber_info *prev;\n+  clobber_info *next;\n+  if (comparison > 0)\n+    {\n+      // NEIGHBOR is the last clobber in what will become the first group.\n+      tree1 = neighbor;\n+      tree2 = tree1.split_after_root ();\n+      prev = neighbor;\n+      next = as_a<clobber_info *> (prev->next_def ());\n+    }\n+  else\n+    {\n+      // NEIGHBOR is the first clobber in what will become the second group.\n+      tree2 = neighbor;\n+      tree1 = tree2.split_before_root ();\n+      next = neighbor;\n+      prev = as_a<clobber_info *> (next->prev_def ());\n+    }\n+\n+  // Use GROUP to hold PREV and earlier clobbers.  Create a new group for\n+  // NEXT onwards.\n+  clobber_info *last_clobber = group->last_clobber ();\n+  clobber_group *group1 = group;\n+  clobber_group *group2 = allocate<clobber_group> (next);\n+\n+  // Finish setting up GROUP1, making sure that the roots and extremities\n+  // have a correct group pointer.  Leave the rest to be updated lazily.\n+  group1->set_last_clobber (prev);\n+  tree1->set_group (group1);\n+  prev->set_group (group1);\n+\n+  // Finish setting up GROUP2, with the same approach as for GROUP1.\n+  group2->set_first_clobber (next);\n+  group2->set_last_clobber (last_clobber);\n+  next->set_group (group2);\n+  tree2->set_group (group2);\n+  last_clobber->set_group (group2);\n+\n+  return prev;\n+}\n+\n+// Add DEF to the end of the function's list of definitions of\n+// DEF->resource ().  There is known to be no associated splay tree yet.\n+void\n+function_info::append_def (def_info *def)\n+{\n+  gcc_checking_assert (!def->has_def_links ());\n+  def_info **head = &m_defs[def->regno () + 1];\n+  def_info *first = *head;\n+  if (!first)\n+    {\n+      // This is the only definition of the resource.\n+      def->set_last_def (def);\n+      *head = def;\n+      return;\n+    }\n+\n+  def_info *prev = first->last_def ();\n+  gcc_checking_assert (!prev->splay_root ());\n+\n+  // Maintain the invariant that two clobbers must not appear in\n+  // neighboring nodes of the splay tree.\n+  auto *clobber = dyn_cast<clobber_info *> (def);\n+  auto *prev_clobber = dyn_cast<clobber_info *> (prev);\n+  if (clobber && prev_clobber)\n+    append_clobber_to_group (clobber, need_clobber_group (prev_clobber));\n+\n+  prev->set_next_def (def);\n+  def->set_prev_def (prev);\n+  first->set_last_def (def);\n+}\n+\n+// Add DEF to the function's list of definitions of DEF->resource ().\n+// Also insert it into the associated splay tree, if there is one.\n+// DEF is not currently part of the list and is not in the splay tree.\n+void\n+function_info::add_def (def_info *def)\n+{\n+  gcc_checking_assert (!def->has_def_links ()\n+\t\t       && !def->m_is_temp\n+\t\t       && !def->m_has_been_superceded);\n+  def_info **head = &m_defs[def->regno () + 1];\n+  def_info *first = *head;\n+  if (!first)\n+    {\n+      // This is the only definition of the resource.\n+      def->set_last_def (def);\n+      *head = def;\n+      return;\n+    }\n+\n+  def_info *last = first->last_def ();\n+  insn_info *insn = def->insn ();\n+\n+  int comparison;\n+  def_node *root = nullptr;\n+  def_info *prev = nullptr;\n+  def_info *next = nullptr;\n+  if (*insn > *last->insn ())\n+    {\n+      // This definition comes after all other definitions.\n+      comparison = 1;\n+      if (def_splay_tree tree = last->splay_root ())\n+\t{\n+\t  tree.splay_max_node ();\n+\t  root = tree.root ();\n+\t  last->set_splay_root (root);\n+\t}\n+      prev = last;\n+    }\n+  else if (*insn < *first->insn ())\n+    {\n+      // This definition comes before all other definitions.\n+      comparison = -1;\n+      if (def_splay_tree tree = last->splay_root ())\n+\t{\n+\t  tree.splay_min_node ();\n+\t  root = tree.root ();\n+\t  last->set_splay_root (root);\n+\t}\n+      next = first;\n+    }\n+  else\n+    {\n+      // Search the splay tree for an insertion point.\n+      def_splay_tree tree = need_def_splay_tree (last);\n+      comparison = lookup_def (tree, insn);\n+      root = tree.root ();\n+      last->set_splay_root (root);\n+\n+      // Deal with cases in which we found an overlapping live range.\n+      if (comparison == 0)\n+\t{\n+\t  auto *group = as_a<clobber_group *> (tree.root ());\n+\t  if (auto *clobber = dyn_cast<clobber_info *> (def))\n+\t    {\n+\t      add_clobber (clobber, group);\n+\t      return;\n+\t    }\n+\t  prev = split_clobber_group (group, insn);\n+\t  next = prev->next_def ();\n+\t}\n+      // COMPARISON is < 0 if DEF comes before ROOT or > 0 if DEF comes\n+      // after ROOT.\n+      else if (comparison < 0)\n+\t{\n+\t  next = first_def (root);\n+\t  prev = next->prev_def ();\n+\t}\n+      else\n+\t{\n+\t  prev = last_def (root);\n+\t  next = prev->next_def ();\n+\t}\n+    }\n+\n+  // See if we should merge CLOBBER with a neighboring clobber.\n+  auto *clobber = dyn_cast<clobber_info *> (def);\n+  auto *prev_clobber = safe_dyn_cast<clobber_info *> (prev);\n+  auto *next_clobber = safe_dyn_cast<clobber_info *> (next);\n+  // We shouldn't have consecutive clobber_groups.\n+  gcc_checking_assert (!(clobber && prev_clobber && next_clobber));\n+  if (clobber && prev_clobber)\n+    append_clobber_to_group (clobber, need_clobber_group (prev_clobber));\n+  else if (clobber && next_clobber)\n+    prepend_clobber_to_group (clobber, need_clobber_group (next_clobber));\n+  else if (root)\n+    {\n+      // If DEF comes before ROOT, insert DEF to ROOT's left,\n+      // otherwise insert DEF to ROOT's right.\n+      def_node *node = need_def_node (def);\n+      def_splay_tree::insert_child (root, comparison >= 0, node);\n+    }\n+  if (prev)\n+    insert_def_after (def, prev);\n+  else\n+    insert_def_before (def, next);\n+}\n+\n+// Remove DEF from the function's list of definitions of DEF->resource ().\n+// Also remove DEF from the associated splay tree, if there is one.\n+void\n+function_info::remove_def (def_info *def)\n+{\n+  def_info **head = &m_defs[def->regno () + 1];\n+  def_info *first = *head;\n+  gcc_checking_assert (first);\n+  if (first->is_last_def ())\n+    {\n+      // DEF is the only definition of the resource.\n+      gcc_checking_assert (first == def);\n+      *head = nullptr;\n+      def->clear_def_links ();\n+      return;\n+    }\n+\n+  // If CLOBBER belongs to a clobber_group that contains other clobbers\n+  // too, then we need to update the clobber_group and the list, but any\n+  // splay tree that contains the clobber_group is unaffected.\n+  if (auto *clobber = dyn_cast<clobber_info *> (def))\n+    if (clobber->is_in_group ())\n+      {\n+\tclobber_group *group = clobber->group ();\n+\tif (group->first_clobber () != group->last_clobber ())\n+\t  {\n+\t    remove_clobber (clobber, group);\n+\t    return;\n+\t  }\n+      }\n+\n+  // If we've created a splay tree for this resource, remove the entry\n+  // for DEF.\n+  def_info *last = first->last_def ();\n+  if (def_splay_tree tree = last->splay_root ())\n+    {\n+      int comparison = lookup_def (tree, def->insn ());\n+      gcc_checking_assert (comparison == 0);\n+      tree.remove_root ();\n+      last->set_splay_root (tree.root ());\n+    }\n+\n+  // If the definition came between two clobbers, merge them into a single\n+  // group.\n+  auto *prev_clobber = safe_dyn_cast<clobber_info *> (def->prev_def ());\n+  auto *next_clobber = safe_dyn_cast<clobber_info *> (def->next_def ());\n+  if (prev_clobber && next_clobber)\n+    merge_clobber_groups (prev_clobber, next_clobber, last);\n+\n+  remove_def_from_list (def);\n+}\n+\n+// Require DEF to have a splay tree that contains all non-phi uses.\n+void\n+function_info::need_use_splay_tree (set_info *def)\n+{\n+  if (!def->m_use_tree)\n+    for (use_info *use : def->all_insn_uses ())\n+      {\n+\tauto *use_node = allocate<splay_tree_node<use_info *>> (use);\n+\tdef->m_use_tree.insert_max_node (use_node);\n+      }\n+}\n+\n+// Compare two instructions by their position in a use splay tree.  Return >0\n+// if INSN1 comes after INSN2, <0 if INSN1 comes before INSN2, or 0 if they are\n+// the same instruction.\n+static inline int\n+compare_use_insns (insn_info *insn1, insn_info *insn2)\n+{\n+  // Debug instructions go after nondebug instructions.\n+  int diff = insn1->is_debug_insn () - insn2->is_debug_insn ();\n+  if (diff != 0)\n+    return diff;\n+  return insn1->compare_with (insn2);\n+}\n+\n+// Search TREE for a use in INSN.  If such a use exists, install it as\n+// the root of TREE and return 0.  Otherwise arbitrarily choose between:\n+//\n+// (1) Installing the closest preceding use as the root and returning 1.\n+// (2) Installing the closest following use as the root and returning -1.\n+int\n+rtl_ssa::lookup_use (splay_tree<use_info *> &tree, insn_info *insn)\n+{\n+  auto compare = [&](splay_tree_node<use_info *> *node)\n+    {\n+      return compare_use_insns (insn, node->value ()->insn ());\n+    };\n+  return tree.lookup (compare);\n+}\n+\n+// Add USE to USE->def ()'s list of uses. inserting USE immediately before\n+// BEFORE.  USE is not currently in the list.\n+//\n+// This routine should not be used for inserting phi uses.\n+void\n+function_info::insert_use_before (use_info *use, use_info *before)\n+{\n+  gcc_checking_assert (!use->has_use_links () && use->is_in_any_insn ());\n+\n+  set_info *def = use->def ();\n+\n+  use->copy_prev_from (before);\n+  use->set_next_use (before);\n+\n+  if (use_info *prev = use->prev_use ())\n+    prev->set_next_use (use);\n+  else\n+    use->def ()->set_first_use (use);\n+\n+  before->set_prev_use (use);\n+  if (use->is_in_nondebug_insn () && before->is_in_debug_insn_or_phi ())\n+    def->last_use ()->set_last_nondebug_insn_use (use);\n+\n+  gcc_checking_assert (use->check_integrity () && before->check_integrity ());\n+}\n+\n+// Add USE to USE->def ()'s list of uses. inserting USE immediately after\n+// AFTER.  USE is not currently in the list.\n+//\n+// This routine should not be used for inserting phi uses.\n+void\n+function_info::insert_use_after (use_info *use, use_info *after)\n+{\n+  set_info *def = use->def ();\n+  gcc_checking_assert (after->is_in_any_insn ()\n+\t\t       && !use->has_use_links ()\n+\t\t       && use->is_in_any_insn ());\n+\n+  use->set_prev_use (after);\n+  use->copy_next_from (after);\n+\n+  after->set_next_use (use);\n+\n+  if (use_info *next = use->next_use ())\n+    {\n+      // The last node doesn't change, but we might need to update its\n+      // last_nondebug_insn_use record.\n+      if (use->is_in_nondebug_insn () && next->is_in_debug_insn_or_phi ())\n+\tdef->last_use ()->set_last_nondebug_insn_use (use);\n+      next->set_prev_use (use);\n+    }\n+  else\n+    {\n+      // USE is now the last node.\n+      if (use->is_in_nondebug_insn ())\n+\tuse->set_last_nondebug_insn_use (use);\n+      def->first_use ()->set_last_use (use);\n+    }\n+\n+  gcc_checking_assert (use->check_integrity () && after->check_integrity ());\n+}\n+\n+// If USE has a known definition, add USE to that definition's list of uses.\n+// Also update the associated splay tree, if any.\n+void\n+function_info::add_use (use_info *use)\n+{\n+  gcc_checking_assert (!use->has_use_links ()\n+\t\t       && !use->m_is_temp\n+\t\t       && !use->m_has_been_superceded);\n+\n+  set_info *def = use->def ();\n+  if (!def)\n+    return;\n+\n+  use_info *first = def->first_use ();\n+  if (!first)\n+    {\n+      // This is the only use of the definition.\n+      use->set_last_use (use);\n+      if (use->is_in_nondebug_insn ())\n+\tuse->set_last_nondebug_insn_use (use);\n+\n+      def->set_first_use (use);\n+\n+      gcc_checking_assert (use->check_integrity ());\n+      return;\n+    }\n+\n+  if (use->is_in_phi ())\n+    {\n+      // Add USE at the end of the list, as the new first phi.\n+      use_info *last = first->last_use ();\n+\n+      use->set_prev_use (last);\n+      use->copy_next_from (last);\n+\n+      last->set_next_use (use);\n+      first->set_last_use (use);\n+\n+      gcc_checking_assert (use->check_integrity ());\n+      return;\n+    }\n+\n+  // If there is currently no splay tree for this definition, see if can\n+  // get away with a pure list-based update.\n+  insn_info *insn = use->insn ();\n+  auto quick_path = [&]()\n+    {\n+      // Check if USE should come before all current uses.\n+      if (first->is_in_phi () || compare_use_insns (insn, first->insn ()) < 0)\n+\t{\n+\t  insert_use_before (use, first);\n+\t  return true;\n+\t}\n+\n+      // Check if USE should come after all current uses in the same\n+      // subsequence (i.e. the list of nondebug insn uses or the list\n+      // of debug insn uses).\n+      use_info *last = first->last_use ();\n+      if (use->is_in_debug_insn ())\n+\t{\n+\t  if (last->is_in_phi ())\n+\t    return false;\n+\t}\n+      else\n+\tlast = last->last_nondebug_insn_use ();\n+\n+      if (compare_use_insns (insn, last->insn ()) > 0)\n+\t{\n+\t  insert_use_after (use, last);\n+\t  return true;\n+\t}\n+\n+      return false;\n+    };\n+  if (!def->m_use_tree && quick_path ())\n+    return;\n+\n+  // Search the splay tree for an insertion point.  COMPARISON is less\n+  // than zero if USE should come before NEIGHBOR, or greater than zero\n+  // if USE should come after NEIGHBOR.\n+  need_use_splay_tree (def);\n+  int comparison = lookup_use (def->m_use_tree, insn);\n+  gcc_checking_assert (comparison != 0);\n+  splay_tree_node<use_info *> *neighbor = def->m_use_tree.root ();\n+\n+  // If USE comes before NEIGHBOR, insert USE to NEIGHBOR's left,\n+  // otherwise insert USE to NEIGHBOR's right.\n+  auto *use_node = allocate<splay_tree_node<use_info *>> (use);\n+  def->m_use_tree.insert_child (neighbor, comparison > 0, use_node);\n+  if (comparison > 0)\n+    insert_use_after (use, neighbor->value ());\n+  else\n+    insert_use_before (use, neighbor->value ());\n+}\n+\n+// If USE has a known definition, remove USE from that definition's list\n+// of uses.  Also remove if it from the associated splay tree, if any.\n+void\n+function_info::remove_use (use_info *use)\n+{\n+  set_info *def = use->def ();\n+  if (!def)\n+    return;\n+\n+  // Remove USE from the splay tree.\n+  if (def->m_use_tree && use->is_in_any_insn ())\n+    {\n+      int comparison = lookup_use (def->m_use_tree, use->insn ());\n+      gcc_checking_assert (comparison == 0);\n+      def->m_use_tree.remove_root ();\n+    }\n+\n+  use_info *prev = use->prev_use ();\n+  use_info *next = use->next_use ();\n+\n+  use_info *first = def->first_use ();\n+  use_info *last = first->last_use ();\n+  if (last->last_nondebug_insn_use () == use)\n+    last->set_last_nondebug_insn_use (prev);\n+\n+  if (next)\n+    next->copy_prev_from (use);\n+  else\n+    first->set_last_use (prev);\n+\n+  if (prev)\n+    prev->copy_next_from (use);\n+  else\n+    def->set_first_use (next);\n+\n+  use->clear_use_links ();\n+  gcc_checking_assert ((!prev || prev->check_integrity ())\n+\t\t       && (!next || next->check_integrity ()));\n+}\n+\n+// Allocate a temporary clobber_info for register REGNO in insn INSN,\n+// including it in the region of the obstack governed by WATERMARK.\n+// Return a new def_array that contains OLD_DEFS and the new clobber.\n+//\n+// OLD_DEFS is known not to define REGNO.\n+def_array\n+function_info::insert_temp_clobber (obstack_watermark &watermark,\n+\t\t\t\t    insn_info *insn, unsigned int regno,\n+\t\t\t\t    def_array old_defs)\n+{\n+  gcc_checking_assert (watermark == &m_temp_obstack);\n+  auto *clobber = allocate_temp<clobber_info> (insn, regno);\n+  clobber->m_is_temp = true;\n+  return insert_access (watermark, clobber, old_defs);\n+}\n+\n+// A subroutine of make_uses_available.  Try to make USE's definition\n+// available at the head of BB.  On success:\n+//\n+// - If the use would have the same def () as USE, return USE.\n+//\n+// - If BB already has a degenerate phi for the same definition,\n+//   return a temporary use of that phi.\n+//\n+// - Otherwise, the use would need a new degenerate phi.  Allocate a\n+//   temporary phi and return a temporary use of it.\n+//\n+// Return null on failure.\n+use_info *\n+function_info::make_use_available (use_info *use, bb_info *bb)\n+{\n+  set_info *def = use->def ();\n+  if (!def)\n+    return use;\n+\n+  if (is_single_dominating_def (def))\n+    return use;\n+\n+  // FIXME: Deliberately limited for fwprop compatibility testing.\n+  basic_block cfg_bb = bb->cfg_bb ();\n+  bb_info *use_bb = use->bb ();\n+  if (single_pred_p (cfg_bb)\n+      && single_pred (cfg_bb) == use_bb->cfg_bb ()\n+      && remains_available_on_exit (def, use_bb))\n+    {\n+      if (def->ebb () == bb->ebb ())\n+\treturn use;\n+\n+      resource_info resource = use->resource ();\n+      set_info *ultimate_def = look_through_degenerate_phi (def);\n+\n+      // See if there is already a (degenerate) phi for DEF.\n+      insn_info *phi_insn = bb->ebb ()->phi_insn ();\n+      phi_info *phi;\n+      def_lookup dl = find_def (resource, phi_insn);\n+      if (set_info *set = dl.matching_set ())\n+\t{\n+\t  // There is an existing phi.\n+\t  phi = as_a<phi_info *> (set);\n+\t  gcc_checking_assert (phi->input_value (0) == ultimate_def);\n+\t}\n+      else\n+\t{\n+\t  // Create a temporary placeholder phi.  This will become\n+\t  // permanent if the change is later committed.\n+\t  phi = allocate_temp<phi_info> (phi_insn, resource, 0);\n+\t  auto *input = allocate<use_info> (phi, resource, ultimate_def);\n+\t  input->m_is_temp = true;\n+\t  phi->m_is_temp = true;\n+\t  phi->make_degenerate (input);\n+\t  if (def_info *prev = dl.prev_def ())\n+\t    phi->set_prev_def (prev);\n+\t  if (def_info *next = dl.next_def ())\n+\t    phi->set_next_def (next);\n+\t}\n+\n+      // Create a temporary use of the phi at the head of the first\n+      // block, since we know for sure that it's available there.\n+      insn_info *use_insn = bb->ebb ()->first_bb ()->head_insn ();\n+      auto *new_use = allocate_temp<use_info> (use_insn, resource, phi);\n+      new_use->m_is_temp = true;\n+      return new_use;\n+    }\n+  return nullptr;\n+}\n+\n+// See the comment above the declaration.\n+use_array\n+function_info::make_uses_available (obstack_watermark &watermark,\n+\t\t\t\t    use_array uses, bb_info *bb)\n+{\n+  unsigned int num_uses = uses.size ();\n+  if (num_uses == 0)\n+    return uses;\n+\n+  auto **new_uses = XOBNEWVEC (watermark, access_info *, num_uses);\n+  for (unsigned int i = 0; i < num_uses; ++i)\n+    {\n+      use_info *use = make_use_available (uses[i], bb);\n+      if (!use)\n+\treturn use_array (access_array::invalid ());\n+      new_uses[i] = use;\n+    }\n+  return use_array (new_uses, num_uses);\n+}\n+\n+// Return true if ACCESS1 can represent ACCESS2 and if ACCESS2 can\n+// represent ACCESS1.\n+static bool\n+can_merge_accesses (access_info *access1, access_info *access2)\n+{\n+  if (access1 == access2)\n+    return true;\n+\n+  auto *use1 = dyn_cast<use_info *> (access1);\n+  auto *use2 = dyn_cast<use_info *> (access2);\n+  return use1 && use2 && use1->def () == use2->def ();\n+}\n+\n+// See the comment above the declaration.\n+access_array\n+rtl_ssa::merge_access_arrays_base (obstack_watermark &watermark,\n+\t\t\t\t   access_array accesses1,\n+\t\t\t\t   access_array accesses2)\n+{\n+  if (accesses1.empty ())\n+    return accesses2;\n+  if (accesses2.empty ())\n+    return accesses1;\n+\n+  auto i1 = accesses1.begin ();\n+  auto end1 = accesses1.end ();\n+  auto i2 = accesses2.begin ();\n+  auto end2 = accesses2.end ();\n+\n+  access_array_builder builder (watermark);\n+  builder.reserve (accesses1.size () + accesses2.size ());\n+\n+  while (i1 != end1 && i2 != end2)\n+    {\n+      access_info *access1 = *i1;\n+      access_info *access2 = *i2;\n+\n+      unsigned int regno1 = access1->regno ();\n+      unsigned int regno2 = access2->regno ();\n+      if (regno1 == regno2)\n+\t{\n+\t  if (!can_merge_accesses (access1, access2))\n+\t    return access_array::invalid ();\n+\n+\t  builder.quick_push (access1);\n+\t  ++i1;\n+\t  ++i2;\n+\t}\n+      else if (regno1 < regno2)\n+\t{\n+\t  builder.quick_push (access1);\n+\t  ++i1;\n+\t}\n+      else\n+\t{\n+\t  builder.quick_push (access2);\n+\t  ++i2;\n+\t}\n+    }\n+  for (; i1 != end1; ++i1)\n+    builder.quick_push (*i1);\n+  for (; i2 != end2; ++i2)\n+    builder.quick_push (*i2);\n+\n+  return builder.finish ();\n+}\n+\n+// See the comment above the declaration.\n+access_array\n+rtl_ssa::insert_access_base (obstack_watermark &watermark,\n+\t\t\t     access_info *access1, access_array accesses2)\n+{\n+  access_array_builder builder (watermark);\n+  builder.reserve (1 + accesses2.size ());\n+\n+  unsigned int regno1 = access1->regno ();\n+  auto i2 = accesses2.begin ();\n+  auto end2 = accesses2.end ();\n+  while (i2 != end2)\n+    {\n+      access_info *access2 = *i2;\n+\n+      unsigned int regno2 = access2->regno ();\n+      if (regno1 == regno2)\n+\t{\n+\t  if (!can_merge_accesses (access1, access2))\n+\t    return access_array::invalid ();\n+\n+\t  builder.quick_push (access1);\n+\t  access1 = nullptr;\n+\t  ++i2;\n+\t  break;\n+\t}\n+      else if (regno1 < regno2)\n+\t{\n+\t  builder.quick_push (access1);\n+\t  access1 = nullptr;\n+\t  break;\n+\t}\n+      else\n+\t{\n+\t  builder.quick_push (access2);\n+\t  ++i2;\n+\t}\n+    }\n+  if (access1)\n+    builder.quick_push (access1);\n+  for (; i2 != end2; ++i2)\n+    builder.quick_push (*i2);\n+\n+  return builder.finish ();\n+}\n+\n+// See the comment above the declaration.\n+access_array\n+rtl_ssa::remove_note_accesses_base (obstack_watermark &watermark,\n+\t\t\t\t    access_array accesses)\n+{\n+  for (access_info *access : accesses)\n+    if (access->only_occurs_in_notes ())\n+      {\n+\taccess_array_builder builder (watermark);\n+\tbuilder.reserve (accesses.size ());\n+\tfor (access_info *access2 : accesses)\n+\t  if (!access2->only_occurs_in_notes ())\n+\t    builder.quick_push (access2);\n+\treturn builder.finish ();\n+      }\n+  return accesses;\n+}\n+\n+// Print RESOURCE to PP.\n+void\n+rtl_ssa::pp_resource (pretty_printer *pp, resource_info resource)\n+{\n+  resource.print (pp);\n+}\n+\n+// Print ACCESS to PP.  FLAGS is a bitmask of PP_ACCESS_* flags.\n+void\n+rtl_ssa::pp_access (pretty_printer *pp, const access_info *access,\n+\t\t    unsigned int flags)\n+{\n+  if (!access)\n+    pp_string (pp, \"<null>\");\n+  else if (auto *phi = dyn_cast<const phi_info *> (access))\n+    phi->print (pp, flags);\n+  else if (auto *set = dyn_cast<const set_info *> (access))\n+    set->print (pp, flags);\n+  else if (auto *clobber = dyn_cast<const clobber_info *> (access))\n+    clobber->print (pp, flags);\n+  else if (auto *use = dyn_cast<const use_info *> (access))\n+    use->print (pp, flags);\n+  else\n+    pp_string (pp, \"??? Unknown access\");\n+}\n+\n+// Print ACCESSES to PP.  FLAGS is a bitmask of PP_ACCESS_* flags.\n+void\n+rtl_ssa::pp_accesses (pretty_printer *pp, access_array accesses,\n+\t\t      unsigned int flags)\n+{\n+  if (accesses.empty ())\n+    pp_string (pp, \"none\");\n+  else\n+    {\n+      bool is_first = true;\n+      for (access_info *access : accesses)\n+\t{\n+\t  if (is_first)\n+\t    is_first = false;\n+\t  else\n+\t    pp_newline_and_indent (pp, 0);\n+\t  pp_access (pp, access, flags);\n+\t}\n+    }\n+}\n+\n+// Print NODE to PP.\n+void\n+rtl_ssa::pp_def_node (pretty_printer *pp, const def_node *node)\n+{\n+  if (!node)\n+    pp_string (pp, \"<null>\");\n+  else if (auto *group = dyn_cast<const clobber_group *> (node))\n+    group->print (pp);\n+  else if (auto *set = dyn_cast<const set_node *> (node))\n+    set->print (pp);\n+  else\n+    pp_string (pp, \"??? Unknown def node\");\n+}\n+\n+// Print MUX to PP.\n+void\n+rtl_ssa::pp_def_mux (pretty_printer *pp, def_mux mux)\n+{\n+  if (auto *node = mux.dyn_cast<def_node *> ())\n+    pp_def_node (pp, node);\n+  else\n+    pp_access (pp, mux.as_a<def_info *> ());\n+}\n+\n+// Print DL to PP.\n+void\n+rtl_ssa::pp_def_lookup (pretty_printer *pp, def_lookup dl)\n+{\n+  pp_string (pp, \"comparison result of \");\n+  pp_decimal_int (pp, dl.comparison);\n+  pp_string (pp, \" for \");\n+  pp_newline_and_indent (pp, 0);\n+  pp_def_mux (pp, dl.mux);\n+}\n+\n+// Dump RESOURCE to FILE.\n+void\n+dump (FILE *file, resource_info resource)\n+{\n+  dump_using (file, pp_resource, resource);\n+}\n+\n+// Dump ACCESS to FILE.  FLAGS is a bitmask of PP_ACCESS_* flags.\n+void\n+dump (FILE *file, const access_info *access, unsigned int flags)\n+{\n+  dump_using (file, pp_access, access, flags);\n+}\n+\n+// Dump ACCESSES to FILE.  FLAGS is a bitmask of PP_ACCESS_* flags.\n+void\n+dump (FILE *file, access_array accesses, unsigned int flags)\n+{\n+  dump_using (file, pp_accesses, accesses, flags);\n+}\n+\n+// Print NODE to FILE.\n+void\n+dump (FILE *file, const def_node *node)\n+{\n+  dump_using (file, pp_def_node, node);\n+}\n+\n+// Print MUX to FILE.\n+void\n+dump (FILE *file, def_mux mux)\n+{\n+  dump_using (file, pp_def_mux, mux);\n+}\n+\n+// Print RESULT to FILE.\n+void\n+dump (FILE *file, def_lookup result)\n+{\n+  dump_using (file, pp_def_lookup, result);\n+}\n+\n+// Debug interfaces to the dump routines above.\n+void debug (const resource_info &x) { dump (stderr, x); }\n+void debug (const access_info *x) { dump (stderr, x); }\n+void debug (const access_array &x) { dump (stderr, x); }\n+void debug (const def_node *x) { dump (stderr, x); }\n+void debug (const def_mux &x) { dump (stderr, x); }\n+void debug (const def_lookup &x) { dump (stderr, x); }"}, {"sha": "fdb4a6461833e0d51296be34e19e05f2ba58a71e", "filename": "gcc/rtl-ssa/accesses.h", "status": "added", "additions": 1032, "deletions": 0, "changes": 1032, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Faccesses.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Faccesses.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Faccesses.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,1032 @@\n+// Access-related classes for RTL SSA                               -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// Forward declarations.\n+class bb_info;\n+class clobber_group;\n+class def_node;\n+class ebb_info;\n+class insn_info;\n+class phi_info;\n+class set_info;\n+\n+// Used as a boolean argunent to certain routines.\n+enum class ignore_clobbers { NO, YES };\n+\n+// Represents something that the SSA form tracks: either a register\n+// or memory.\n+class resource_info\n+{\n+public:\n+  // Return true if this resource represents memory.\n+  bool is_mem () const { return regno == MEM_REGNO; }\n+\n+  // Return true if this resource represents a register.\n+  bool is_reg () const { return regno != MEM_REGNO; }\n+\n+  // Print the name of the resource to PP.\n+  void print_identifier (pretty_printer *pp) const;\n+\n+  // Possibly print additional information about the resource to PP.\n+  void print_context (pretty_printer *pp) const;\n+\n+  // A combination of print_identifier and print_context.\n+  void print (pretty_printer *pp) const;\n+\n+  // The mode with which the resource is being defined or used.  This is\n+  // always BLKmode for memory.  It can also be BLKmode for registers if\n+  // we don't yet know the real mode, or if the mode is not relevant for\n+  // some reason.\n+  machine_mode mode;\n+\n+  // The pseudo register or single hard register that the resource represents,\n+  // or MEM_REGNO for memory.\n+  unsigned int regno;\n+};\n+\n+// For simplicity, we treat memory as a single unified entity.\n+const resource_info memory = { E_BLKmode, MEM_REGNO };\n+\n+// Flags used when printing access_infos.\n+//\n+// Print the location at which the access occurs.  This is redundant\n+// when the access is being printed as part of the instruction or phi node\n+// that contains the access.\n+const unsigned int PP_ACCESS_INCLUDE_LOCATION = 1U << 0;\n+//\n+// Print links to other accesses: the definition that defines a use,\n+// the uses of a definition, and the inputs of a phi node.\n+const unsigned int PP_ACCESS_INCLUDE_LINKS = 1U << 1;\n+//\n+// Print additional properties about the access.\n+const unsigned int PP_ACCESS_INCLUDE_PROPERTIES = 1U << 2;\n+//\n+// The usual flags when printing an access in isolation.\n+const unsigned int PP_ACCESS_DEFAULT = (PP_ACCESS_INCLUDE_LOCATION\n+\t\t\t\t\t| PP_ACCESS_INCLUDE_LINKS\n+\t\t\t\t\t| PP_ACCESS_INCLUDE_PROPERTIES);\n+//\n+// The usual flags when printing a def_info from its defining instruction.\n+const unsigned int PP_ACCESS_SETTER = (PP_ACCESS_INCLUDE_LINKS\n+\t\t\t\t       | PP_ACCESS_INCLUDE_PROPERTIES);\n+//\n+// The usual flags when printing a use_info from its user.\n+const unsigned int PP_ACCESS_USER = PP_ACCESS_INCLUDE_PROPERTIES;\n+\n+// The various ways of accessing a resource.  The two range checks that\n+// we need to perform are [SET, PHI] (for set_info) and [SET, CLOBBER]\n+// (for def_info), so the ordering tries to make those tests as\n+// efficient as possible.\n+enum class access_kind : uint8_t\n+{\n+  // Set the resource to a useful value.\n+  SET,\n+\n+  // A form of SET that collects the possible incoming values of the\n+  // resource using a phi node; the resource does not actually change value.\n+  PHI,\n+\n+  // Set the resource to a value that is both unknown and not useful.\n+  CLOBBER,\n+\n+  // Use the current value of the resource.\n+  USE\n+};\n+\n+// A base class that represents an access to a resource.\n+class access_info\n+{\n+  // Size: 1 LP64 word\n+  friend class function_info;\n+\n+public:\n+  // Return the resource that is being accessed.\n+  resource_info resource () const { return { m_mode, m_regno }; }\n+\n+  // Return true if the access is to memory.\n+  bool is_mem () const { return m_regno == MEM_REGNO; }\n+\n+  // Return true if the access is to a register.\n+  bool is_reg () const { return m_regno != MEM_REGNO; }\n+\n+  // If the access is to a register, return the register number,\n+  // otherwise return MEM_REGNO.\n+  unsigned int regno () const { return m_regno; }\n+\n+  // For sets, return the mode of the value to which the resource is being set.\n+  // For uses, return the mode in which the resource is being used (which for\n+  // hard registers might be different from the mode in which the resource\n+  // was set).\n+  //\n+  // When accessing memory, the mode is always BLKmode.  When accessing\n+  // pseudo registers, the mode is always the mode of the pseudo register\n+  // (and so doesn't, for example, take subregs into account).\n+  machine_mode mode () const { return m_mode; }\n+\n+  // Return the kind of access that this is.\n+  access_kind kind () const { return m_kind; }\n+\n+  // Return true if the access occurs in a phi node or an \"artificial\"\n+  // instruction (see insn_info), false if it occurs in a real instruction.\n+  bool is_artificial () const { return m_is_artificial; }\n+\n+  // Return the opposite of is_artificial.\n+  bool is_real () const { return !m_is_artificial; }\n+\n+  // Return true if this access is a set_info whose result is used by at least\n+  // one nondebug instruction.\n+  bool is_set_with_nondebug_insn_uses () const;\n+\n+  // Return true if the access describes a set_info and if the value\n+  // is defined by an RTX_AUTOINC rtx.\n+  bool is_pre_post_modify () const { return m_is_pre_post_modify; }\n+\n+  // Return true if the access is a clobber_info that describes the effect\n+  // of a called function.  This kind of clobber is added for -fipa-ra\n+  // functions that clobber only a strict subset of the normal ABI set.\n+  bool is_call_clobber () const { return m_is_call_clobber; }\n+\n+  // Return true if the access is a use_info that simply marks a point in\n+  // the live range of a set_info at which the value is live out from\n+  // the containing EBB.\n+  bool is_live_out_use () const { return m_is_live_out_use; }\n+\n+  // Return true if the access is a use_info for an instruction and if\n+  // at least some of the uses occur within a MEM address.\n+  //\n+  // There shouldn't be a need to check whether *all* uses occur within\n+  // a MEM address, since in principle:\n+  //\n+  // A: (set (reg:SI R1) (mem:SI (post_inc:SI (reg:SI R2))))\n+  //\n+  // should be semantically equivalent to:\n+  //\n+  // B: (parallel [(set (reg:SI R1) (mem:SI (reg:SI R2)))\n+  //               (set (reg:SI R2) (plus:SI (reg:SI R2) (const_int 4)))])\n+  //\n+  // even though R2 occurs only in MEMs for A but occurs outside MEMs for B.\n+  bool includes_address_uses () const { return m_includes_address_uses; }\n+\n+  // Return true if the access occurs in an instruction and if at least\n+  // some accesses to resource () occur in a read-modify-write context.\n+  // This is equivalent to the DF_REF_READ_WRITE flag.\n+  bool includes_read_writes () const { return m_includes_read_writes; }\n+\n+  // Return true if the access occurs in an instruction and if at least\n+  // some accesses to resource () occur in a subreg context.\n+  bool includes_subregs () const { return m_includes_subregs; }\n+\n+  // Return true if the access occurs in an instruction and if at least\n+  // some accesses to resource () occur in a multi-register REG.\n+  // This implies that resource () is a hard register.\n+  bool includes_multiregs () const { return m_includes_multiregs; }\n+\n+  // Return true if the access occurs in a real nondebug instruction\n+  // and if all accesses to resource () occur in notes, rather than\n+  // in the main instruction pattern.\n+  bool only_occurs_in_notes () const { return m_only_occurs_in_notes; }\n+\n+protected:\n+  access_info (resource_info, access_kind);\n+\n+  void print_prefix_flags (pretty_printer *) const;\n+  void print_properties_on_new_lines (pretty_printer *) const;\n+\n+private:\n+  void set_mode (machine_mode mode) { m_mode = mode; }\n+\n+  // The values returned by the accessors above.\n+  unsigned int m_regno;\n+  access_kind m_kind : 8;\n+\n+protected:\n+  // The value returned by the accessors above.\n+  unsigned int m_is_artificial : 1;\n+  unsigned int m_is_set_with_nondebug_insn_uses : 1;\n+  unsigned int m_is_pre_post_modify : 1;\n+  unsigned int m_is_call_clobber : 1;\n+  unsigned int m_is_live_out_use : 1;\n+  unsigned int m_includes_address_uses : 1;\n+  unsigned int m_includes_read_writes : 1;\n+  unsigned int m_includes_subregs : 1;\n+  unsigned int m_includes_multiregs : 1;\n+  unsigned int m_only_occurs_in_notes : 1;\n+\n+  // True if this access is a use_insn that occurs in a nondebug instruction,\n+  // and if there are no following uses by nondebug instructions.  The next use\n+  // is null, a use_info for a debug instruction, or a use_info for a phi node.\n+  //\n+  // Providing this helps to optimize use_info::next_nondebug_insn_use.\n+  unsigned int m_is_last_nondebug_insn_use : 1;\n+\n+  // True if this access is a use_info for a debug instruction or\n+  // a phi node.\n+  unsigned int m_is_in_debug_insn_or_phi : 1;\n+\n+private:\n+  // Used as a flag during various update routines; has no long-lasting\n+  // meaning.\n+  unsigned int m_has_been_superceded : 1;\n+\n+  // Indicates that this access has been allocated on the function_info's\n+  // temporary obstack and so is not (yet) part of the proper SSA form.\n+  unsigned int m_is_temp : 1;\n+\n+  // Bits for future expansion.\n+  unsigned int m_spare : 2;\n+\n+  // The value returned by the accessor above.\n+  machine_mode m_mode : 8;\n+};\n+\n+// A contiguous array of access_info pointers.  Used to represent a\n+// (mostly small) number of definitions and/or uses.\n+using access_array = array_slice<access_info *const>;\n+\n+// A class for building an access_array on an obstack.  It automatically\n+// frees any in-progress array if the build attempt fails before finish ()\n+// has been called.\n+class access_array_builder : public obstack_watermark\n+{\n+public:\n+  using obstack_watermark::obstack_watermark;\n+\n+  // Make sure that the array has enough for NUM_ACCESSES accesses.\n+  void reserve (unsigned int num_accesses);\n+\n+  // Add ACCESS to the end of the array that we're building, given that\n+  // reserve () has already made room.\n+  void quick_push (access_info *access);\n+\n+  // Finish and return the new array.  The array survives the destruction\n+  // of the builder.\n+  array_slice<access_info *> finish ();\n+};\n+\n+// An access_info that represents the use of a resource in either a phi node\n+// or an instruction.  It records which set_info (if any) provides the\n+// resource's value.\n+class use_info : public access_info\n+{\n+  // Overall size: 5 LP64 words.\n+  friend class set_info;\n+  friend class function_info;\n+\n+public:\n+  // Return true if the access occurs in an instruction rather than a phi node.\n+  // The instruction might be a debug instruction or a nondebug instruction.\n+  bool is_in_any_insn () const { return m_insn_or_phi.is_first (); }\n+\n+  // Return true if the access occurs in a nondebug instruction,\n+  // false if it occurs in a debug instruction or a phi node.\n+  bool is_in_nondebug_insn () const { return !m_is_in_debug_insn_or_phi; }\n+\n+  // Return true if the instruction occurs in a debug instruction.\n+  bool is_in_debug_insn () const;\n+\n+  // Return true if the access occurs in a phi node rather than in an\n+  // instruction.\n+  bool is_in_phi () const { return m_insn_or_phi.is_second (); }\n+\n+  // Return true if the access occurs in a debug instruction or a phi node,\n+  // false if it occurs in a nondebug instruction.\n+  bool is_in_debug_insn_or_phi () const { return m_is_in_debug_insn_or_phi; }\n+\n+  // Return the instruction that uses the resource.  Only valid is\n+  // is_in_any_insn ().\n+  insn_info *insn () const { return m_insn_or_phi.known_first (); }\n+\n+  // Return the phi node that uses the resource.  Only valid if is_in_phi ().\n+  phi_info *phi () const { return m_insn_or_phi.known_second (); }\n+\n+  // Return the basic block that contains the access.\n+  bb_info *bb () const;\n+\n+  // Return the extended basic block that contains the access.\n+  ebb_info *ebb () const;\n+\n+  // Return the set_info whose result the access uses, or null if the\n+  // value of the resource is completely undefined.\n+  //\n+  // The value is undefined if the use is completely upwards exposed\n+  // (i.e. has no preceding definition) or if the preceding definition\n+  // is a clobber rather than a set.\n+  //\n+  // The mode of the definition can be different from the mode of the use;\n+  // for example, a hard register might be set in DImode and used in SImode.\n+  set_info *def () const { return m_def; }\n+\n+  // Return the previous and next uses of the definition.  See set_info\n+  // for details about the ordering.\n+  //\n+  // These routines are only meaningful when def () is nonnull.\n+  use_info *prev_use () const;\n+  use_info *next_use () const;\n+\n+  // Return the next use by a nondebug instruction, or null if none.\n+  //\n+  // This is only valid if is_in_nondebug_insn ().  It is equivalent to,\n+  // but more efficient than:\n+  //\n+  //    next_use () && next_use ()->is_in_nondebug_insn ()\n+  //    ? next_use () : nullptr\n+  use_info *next_nondebug_insn_use () const;\n+\n+  // Return the next use by an instruction, or null if none.  The use might\n+  // be by a debug instruction or a nondebug instruction.\n+  //\n+  // This is only valid if is_in_any_insn ().  It is equivalent to:\n+  //\n+  //    next_use () && next_use ()->is_in_any_insn () ? next_use () : nullptr\n+  use_info *next_any_insn_use () const;\n+\n+  // Return the previous use by a phi node in the list, or null if none.\n+  //\n+  // This is only valid if is_in_phi ().  It is equivalent to:\n+  //\n+  //    prev_use () && prev_use ()->is_in_phi () ? prev_use () : nullptr\n+  use_info *prev_phi_use () const;\n+\n+  // Return true if this is the first use of the definition.  See set_info\n+  // for details about the ordering.\n+  //\n+  // This routine is only meaningful when def () is nonnull.\n+  bool is_first_use () const;\n+\n+  // Return true if this is the last use of the definition.  See set_info\n+  // for details about the ordering.\n+  //\n+  // This routine is only meaningful when def () is nonnull.\n+  bool is_last_use () const;\n+\n+  // Print a description of def () to PP.\n+  void print_def (pretty_printer *pp) const;\n+\n+  // Print a description of the location of the use to PP.\n+  void print_location (pretty_printer *pp) const;\n+\n+  // Print a description of the use to PP under the control of\n+  // PP_ACCESS_* flags FLAGS.\n+  void print (pretty_printer *pp,\n+\t      unsigned int flags = PP_ACCESS_DEFAULT) const;\n+\n+private:\n+  // If we only create a set_info splay tree for sets that are used by\n+  // three instructions or more, then only about 16% of uses need to be in\n+  // a splay tree.  It is therefore more memory-efficient to use separate\n+  // nodes for the splay tree, instead of storing the child nodes\n+  // directly in the use_info.\n+\n+  // Make insn_info the first (and thus directly-encoded) choice since\n+  // insn () is read much more often than phi ().\n+  using insn_or_phi = pointer_mux<insn_info, phi_info>;\n+\n+  // The use belongs to a list that is partitioned into three sections:\n+  //\n+  // (1) all uses in nondebug instructions, in reverse postorder\n+  //\n+  // (2) all uses in debug instructions, in reverse postorder\n+  //\n+  // (3) all phi nodes, in no particular order.\n+  //\n+  // In order to preserve memory:\n+  //\n+  // - The set_info just has a pointer to the first use.\n+  //\n+  // - The first use's \"prev\" pointer points to the last use.\n+  //\n+  // - The last use's \"next\" pointer points to the last use in a nondebug\n+  //   instruction, or null if there are no such uses.\n+  using last_use_or_prev_use = pointer_mux<use_info>;\n+  using last_nondebug_insn_use_or_next_use = pointer_mux<use_info>;\n+\n+  use_info (insn_or_phi, resource_info, set_info *);\n+\n+  use_info *last_use () const;\n+  use_info *last_nondebug_insn_use () const;\n+  bool calculate_is_last_nondebug_insn_use () const;\n+\n+  void record_reference (rtx_obj_reference, bool);\n+  void set_insn (insn_info *);\n+  void set_def (set_info *set) { m_def = set; }\n+  void set_is_live_out_use (bool value) { m_is_live_out_use = value; }\n+  void copy_prev_from (use_info *);\n+  void copy_next_from (use_info *);\n+  void set_last_use (use_info *);\n+  void set_prev_use (use_info *);\n+  void set_last_nondebug_insn_use (use_info *);\n+  void set_next_use (use_info *);\n+  void clear_use_links ();\n+  bool has_use_links ();\n+  bool check_integrity ();\n+\n+  // The location of the use.\n+  insn_or_phi m_insn_or_phi;\n+\n+  // The overloaded \"prev\" and \"next\" pointers, as described above.\n+  last_use_or_prev_use m_last_use_or_prev_use;\n+  last_nondebug_insn_use_or_next_use m_last_nondebug_insn_use_or_next_use;\n+\n+  // The value of def ().\n+  set_info *m_def;\n+};\n+\n+// Iterators for lists of uses.\n+using use_iterator = list_iterator<use_info, &use_info::next_use>;\n+using reverse_use_iterator = list_iterator<use_info, &use_info::prev_use>;\n+\n+// Like use_iterator, but specifically for uses by nondebug instructions,\n+// uses by any kind of instruction, and uses by phi nodes respectively.\n+// These iterators allow a nullptr end point even if there are other types\n+// of use in the same definition.\n+using nondebug_insn_use_iterator\n+  = list_iterator<use_info, &use_info::next_nondebug_insn_use>;\n+using any_insn_use_iterator\n+  = list_iterator<use_info, &use_info::next_any_insn_use>;\n+using phi_use_iterator = list_iterator<use_info, &use_info::prev_phi_use>;\n+\n+// A view of an access_array in which every entry is known to be a use_info.\n+using use_array = const_derived_container<use_info *, access_array>;\n+\n+// An access_info that describes a definition of a resource.  The definition\n+// can be a set or a clobber; the difference is that a set provides a known\n+// and potentially useful value, while a clobber provides an unknown and\n+// unusable value.\n+//\n+// Every definition is associated with an insn_info.  All definitions of\n+// a given resource are stored in a linked list, maintained in reverse\n+// postorder.\n+class def_info : public access_info\n+{\n+  // Overall size: 4 LP64 words\n+  friend class function_info;\n+  friend class clobber_group;\n+\n+public:\n+  // Return the instruction that contains the definition.\n+  insn_info *insn () const { return m_insn; }\n+\n+  // Return the basic block that contains the definition.\n+  bb_info *bb () const;\n+\n+  // Return the extended basic block that contains the access.\n+  ebb_info *ebb () const;\n+\n+  // Return the previous and next definitions of the same resource,\n+  // in reverse postorder, or null if no such definition exists.\n+  def_info *prev_def () const;\n+  def_info *next_def () const;\n+\n+  // Return true if this is the first definition in the list.\n+  bool is_first_def () const;\n+\n+  // Return true if this is the last definition in the list.\n+  bool is_last_def () const;\n+\n+  // Print the location of the definition to PP.\n+  void print_location (pretty_printer *pp) const;\n+\n+  // Print a unique identifier for this definition to PP.  The identifier has\n+  // the form <resource>:<insn uid>.\n+  void print_identifier (pretty_printer *pp) const;\n+\n+protected:\n+  def_info (insn_info *insn, resource_info resource, access_kind kind);\n+\n+private:\n+  // In order to preserve memory, the list head only points to the first\n+  // definition in the list.  The \"prev\" entry of the first definition\n+  // then points to the last definition.\n+  using last_def_or_prev_def = pointer_mux<def_info>;\n+\n+  // For similar memory-saving reasons, if we want to create a splay tree\n+  // of accesses to a resource, we hang the root off the \"next\" entry of\n+  // the last definition in the list.\n+  using splay_root_or_next_def = pointer_mux<def_node, def_info>;\n+\n+  void set_insn (insn_info *insn) { m_insn = insn; }\n+\n+  def_info *last_def () const;\n+  def_node *splay_root () const;\n+\n+  void record_reference (rtx_obj_reference, bool);\n+  void copy_prev_from (def_info *);\n+  void copy_next_from (def_info *);\n+  void set_last_def (def_info *);\n+  void set_prev_def (def_info *);\n+  void set_splay_root (def_node *);\n+  void set_next_def (def_info *);\n+  void clear_def_links ();\n+  bool has_def_links ();\n+\n+  // The location of the definition.\n+  insn_info *m_insn;\n+\n+  // The overloaded \"prev\" and \"next\" pointers, as described above.\n+  last_def_or_prev_def m_last_def_or_prev_def;\n+  splay_root_or_next_def m_splay_root_or_next_def;\n+};\n+\n+// Iterators for lists of definitions.\n+using def_iterator = list_iterator<def_info, &def_info::next_def>;\n+using reverse_def_iterator = list_iterator<def_info, &def_info::prev_def>;\n+\n+// A view of an access_array in which every entry is known to be a\n+// def_info.\n+using def_array = const_derived_container<def_info *, access_array>;\n+\n+// A def_info that sets the resource to a value that is both\n+// unknown and not useful.  This is only ever used for registers,\n+// since memory always has some useful contents.\n+//\n+// Neighboring clobbers are grouped into clobber_groups, so that it's\n+// possibly to skip over all neighboring clobbers in a single step.\n+class clobber_info : public def_info\n+{\n+  // Overall size: 8 LP64 words\n+  friend class default_splay_tree_accessors<clobber_info *>;\n+  friend class default_splay_tree_accessors_with_parent<clobber_info *>;\n+  friend class function_info;\n+  friend class clobber_group;\n+\n+public:\n+  using splay_tree = default_rootless_splay_tree<clobber_info *>;\n+\n+  // Return true if the clobber belongs to a clobber_group, false if it\n+  // is standalone.\n+  bool is_in_group () const { return m_group; }\n+\n+  // Return the group that the clobber is in, or null if none.\n+  //\n+  // Complexity: amortized O(1), worst case O(N), where N is the number\n+  // of clobbers in the containing clobber_group.\n+  clobber_group *group () const;\n+\n+  // Print a description of the clobber to PP under the control of\n+  // PP_ACCESS_* flags FLAGS.\n+  void print (pretty_printer *pp,\n+\t      unsigned int flags = PP_ACCESS_DEFAULT) const;\n+\n+private:\n+  // Once normal call clobbers are taken out of the equation by\n+  // insn_call_clobbers_notes, clobber_infos account for roughly 6% of all\n+  // def_infos, with the rest being set_infos.  clobber_infos are\n+  // therefore much less size-sensitive than set_infos are.\n+  //\n+  // As noted above, we want to group neighboring clobbers together so that\n+  // we can quickly step over them to find the previous or next \"real\" set.\n+  // We also want to be able to split the group in sublinear time,\n+  // for example when inserting a set/use pair between two clobbers\n+  // in a group.\n+  //\n+  // So:\n+  //\n+  // - Clobbers need to have ready access to their group, so that we\n+  //   can cheaply skip over the whole group.  This means that they\n+  //   need a group pointer.\n+  //\n+  // - We need to be able to update the group pointer lazily, so that\n+  //   the cost of updating it is counted against accesses to the clobbers\n+  //   that need updating.\n+  //\n+  // We also want to be able to insert clobbers into a group in\n+  // amortized logarithmic time.\n+  //\n+  // We therefore use a splay tree to represent the clobbers in a group,\n+  // with the nodes storing their parent node.  It is then possible to\n+  // perform splay operations without first getting hold of the root.\n+  // The root of the splay tree always has a valid, up-to-date group,\n+  // so lazy group updates can get the new group from there.\n+  //\n+  // Roughly 90% of clobbers have a neighboring definition in the same\n+  // block, which means that most need to be stored in a splay tree.\n+  // We therefore store the splay tree fields directly in the clobber_info\n+  // rather than using a separate node object.\n+\n+  clobber_info (insn_info *, unsigned int);\n+\n+  void set_group (clobber_group *group) { m_group = group; }\n+  void update_group (clobber_group *);\n+  clobber_group *recompute_group ();\n+\n+  // The child and parent nodes in the splay tree.\n+  clobber_info *m_children[2];\n+  clobber_info *m_parent;\n+\n+  // The last known value of group (), which might now be out of date.\n+  clobber_group *m_group;\n+};\n+\n+using clobber_tree = clobber_info::splay_tree::rooted;\n+\n+// A def_info that sets the resource to a useful value.  It records\n+// all uses of the value in a linked list.  The list is partitioned\n+// into three sections:\n+//\n+// (1) all uses by nondebug instructions, in reverse postorder, followed by\n+// (2) all uses by debug instructions, in reverse postorder, followed by\n+// (3) all uses by phi nodes, in no particular order.\n+//\n+// There are two cases:\n+//\n+// - If we know in advance that there is a single definition of a resource R\n+//   and therefore decide not to use phi nodes for R, (1) and (2) contain\n+//   all uses of R, regardless of which blocks contain the uses.  (3) is\n+//   then empty.\n+//\n+// - Otherwise, (1) only contains uses in the same extended basic block\n+//   as the definition, and it is terminated by a use that marks the end\n+//   of the live range for the EBB.  In other words, if the resource dies\n+//   in the EBB, the last use by a nondebug instruction marks the point at\n+//   which it dies, otherwise there is a fake live-out use at the end of\n+//   the EBB.\n+//\n+// Since debug instructions should not affect codegen, they opportunisticly\n+// attach to the same set_info as nondebug instructions where possible.\n+// If a nondebug instruction would attach to a degenerate phi and if no\n+// such phi exists, debug instructions instead attach to whichever set_info\n+// provides the value, regardless of where that set_info is.\n+class set_info : public def_info\n+{\n+  // Overall size: 6 LP64 words.\n+  friend class function_info;\n+  using use_splay_tree = splay_tree<use_info *>;\n+\n+public:\n+  // Return the first and last uses of the set, or null if the list is empty.\n+  // See the comment above for details about the order.\n+  use_info *first_use () const { return m_first_use; }\n+  use_info *last_use () const;\n+\n+  // Return the first and last uses of the set by nondebug instructions,\n+  // or null if there are no such uses.  The uses are in reverse postorder.\n+  use_info *first_nondebug_insn_use () const;\n+  use_info *last_nondebug_insn_use () const;\n+\n+  // Return the first use of the set by any kind of instruction, or null\n+  // if there are no such uses.  The uses are in the order described above.\n+  use_info *first_any_insn_use () const;\n+\n+  // Return the last use of the set by phi inputs, or null if there are no\n+  // such uses.  The phi input uses are in no particular order.\n+  use_info *last_phi_use () const;\n+\n+  // Return true if at least one nondebug instruction or phi node uses\n+  // the set's result.  This is equivalent to testing whether the set is\n+  // ever live.\n+  bool has_nondebug_uses () const;\n+\n+  // Return true if anything uses the set's result.  Note that this includes\n+  // uses by debug instructions, so it should not be used for optimization\n+  // decisions.\n+  bool has_any_uses () const { return m_first_use; }\n+\n+  // Return true if at least one nondebug instruction uses the set's result.\n+  bool has_nondebug_insn_uses () const;\n+\n+  // Return true if at least one phi node uses the set's result.\n+  bool has_phi_uses () const;\n+\n+  // Return true if the set and its uses are contained within a single\n+  // extended basic block, with the set coming first.  This implies\n+  // that all uses are by instructions rather than phi nodes.\n+  bool is_local_to_ebb () const;\n+\n+  // List all the uses of the set, in the order described above.\n+  iterator_range<use_iterator> all_uses () const;\n+\n+  // Return uses () in reverse order.\n+  iterator_range<reverse_use_iterator> reverse_all_uses () const;\n+\n+  // List the uses of the set by nondebug instructions, in reverse postorder.\n+  iterator_range<nondebug_insn_use_iterator> nondebug_insn_uses () const;\n+\n+  // Return nondebug_insn_uses () in reverse order.\n+  iterator_range<reverse_use_iterator> reverse_nondebug_insn_uses () const;\n+\n+  // List the uses of the set by any kind of instruction.  The list follows\n+  // the order described above.\n+  iterator_range<any_insn_use_iterator> all_insn_uses () const;\n+\n+  // List the uses of the set by phi nodes, in no particular order.\n+  // There is therefore no reversed equivalent of this list.\n+  iterator_range<phi_use_iterator> phi_uses () const;\n+\n+  // Print a description of the set to PP under the control of\n+  // PP_ACCESS_* flags FLAGS.\n+  void print (pretty_printer *pp,\n+\t      unsigned int flags = PP_ACCESS_DEFAULT) const;\n+\n+protected:\n+  set_info (insn_info *, resource_info, access_kind);\n+\n+  // Print information about uses () to PP, continuing information printed\n+  // about the set itself.\n+  void print_uses_on_new_lines (pretty_printer *pp) const;\n+\n+private:\n+  // Sets (including phis) account for about 94% of all definitions\n+\n+  set_info (insn_info *, resource_info);\n+\n+  void set_first_use (use_info *);\n+\n+  // The first use in the list.\n+  use_info *m_first_use;\n+\n+  // The root of a splay tree of all uses, built lazily when we first\n+  // think it's needed.\n+  use_splay_tree m_use_tree;\n+};\n+\n+// A set_info for an on-the-side phi node.  The phi node is attached\n+// to an extended basic block EBB and has one input for each incoming edge.\n+// The inputs are represented as an array of use_infos, with input I\n+// corresponding to EDGE_PRED (EBB->first_bb ()->cfg_bb (), I).\n+//\n+// Each phi node has a densely-allocated unique identifier, which is intended\n+// to be suitable for bitmaps or sbitmaps.\n+//\n+// All the phi nodes in an extended basic block are chained together\n+// into a linked list.  The list has no particular order.\n+class phi_info : public set_info\n+{\n+  // Overall size: 8 LP64 words\n+  friend class function_info;\n+\n+public:\n+  // Return the previous and next phi nodes in the extended basic block's list,\n+  // or null if none.\n+  phi_info *prev_phi () const { return m_prev_phi; }\n+  phi_info *next_phi () const { return m_next_phi; }\n+\n+  // Return the number of phi inputs.  This is 1 for degenerate phis,\n+  // otherwise it is equal to the number of incoming edges.\n+  unsigned int num_inputs () const { return m_num_inputs; }\n+\n+  // Return true if the phi node is degenerate, i.e. if it has only a\n+  // single input.\n+  bool is_degenerate () const { return m_num_inputs == 1; }\n+\n+  // Return the phi node's unique identifier.\n+  unsigned int uid () const { return m_uid; }\n+\n+  // Return the array of inputs.  For degenerate phi nodes, this array contains\n+  // a single element, otherwise it has one input per incoming edge,\n+  // with element E corresponding to incoming edge E.\n+  use_array inputs () const;\n+\n+  // Return the use_info that describes the phi input for incoming edge E.\n+  use_info *input_use (unsigned int e) const;\n+\n+  // Return the value of resource () on incoming edge E, or null if the\n+  // value is completely undefined for that edge.\n+  set_info *input_value (unsigned int e) const;\n+\n+  // Print a description of the phi node to PP under the control of\n+  // PP_ACCESS_* flags FLAGS.\n+  void print (pretty_printer *pp,\n+\t      unsigned int flags = PP_ACCESS_DEFAULT) const;\n+\n+private:\n+  phi_info (insn_info *insn, resource_info resource, unsigned int uid);\n+\n+  void make_degenerate (use_info *);\n+  void set_inputs (use_array inputs);\n+  void set_prev_phi (phi_info *prev_phi) { m_prev_phi = prev_phi; }\n+  void set_next_phi (phi_info *next_phi) { m_next_phi = next_phi; }\n+  void clear_phi_links () { m_prev_phi = m_next_phi = nullptr; }\n+  bool has_phi_links () { return m_prev_phi || m_next_phi; }\n+\n+  // The values returned by the accessors above.\n+  unsigned int m_uid;\n+  unsigned int m_num_inputs;\n+  union\n+  {\n+    access_info *const *m_inputs;\n+    access_info *m_single_input;\n+  };\n+  phi_info *m_prev_phi;\n+  phi_info *m_next_phi;\n+};\n+\n+// An iterator for lists of phi nodes.\n+using phi_iterator = list_iterator<phi_info, &phi_info::next_phi>;\n+\n+// One node in a splay tree of definitions.  This base class represents\n+// a single def_info, but it is structured to allow derived classes\n+// to add a range.\n+class def_node\n+{\n+  // Size: 3 LP64 words.\n+  friend class function_info;\n+  friend class default_splay_tree_accessors<def_node *>;\n+\n+public:\n+  // Return the first definition that the node represents.\n+  def_info *first_def () const;\n+\n+  // Return which type of access first_def () is.\n+  bool contains_clobber () const { return m_clobber_or_set.is_first (); }\n+  bool contains_set () const { return m_clobber_or_set.is_second (); }\n+\n+protected:\n+  // More nodes are clobbers rather than sets, so put clobbers first.\n+  // Neither choice can be null.\n+  using clobber_or_set = pointer_mux<clobber_info, set_info>;\n+\n+  // Construct a node that represents FIRST_DEF (and possibly later\n+  // definitions too, if called from a derived class).\n+  def_node (clobber_or_set first_def);\n+\n+  // The first definition in the node.\n+  clobber_or_set m_clobber_or_set;\n+\n+private:\n+  // The splay tree child nodes.\n+  def_node *m_children[2];\n+};\n+\n+// One node in a splay tree of def_infos, representing a single set_info.\n+class set_node : public def_node\n+{\n+  // Overall size: 3 LP64 words.\n+  friend class function_info;\n+\n+public:\n+  // Return the set that the node contains.\n+  set_info *set () const { return m_clobber_or_set.known_second (); }\n+\n+  // Print a description of the node to PP.\n+  void print (pretty_printer *pp) const;\n+\n+private:\n+  // Construct a node for SET.\n+  set_node (set_info *set) : def_node (set) {}\n+};\n+\n+// One node in a splay tree of def_infos.  This class represents\n+// a list of contiguous clobber_infos, in execution order.\n+class clobber_group : public def_node\n+{\n+  // Overall size: 5 LP64 words.\n+  friend class function_info;\n+\n+public:\n+  // Return the first and last clobbers in the group.  The results are\n+  // always nonnull.\n+  clobber_info *first_clobber () const;\n+  clobber_info *last_clobber () const { return m_last_clobber; }\n+\n+  // Return true if this group has been replaced by new clobber_groups.\n+  bool has_been_superceded () const { return !m_last_clobber; }\n+\n+  // Return a list of the clobbers in the group, in execution order.\n+  iterator_range<def_iterator> clobbers () const;\n+\n+  // Print a description of the group to PP.\n+  void print (pretty_printer *pp) const;\n+\n+private:\n+  clobber_group (clobber_info *clobber);\n+\n+  // Set the values of first_clobber () and last_clobber ().\n+  void set_first_clobber (clobber_info *c) { m_clobber_or_set = c; }\n+  void set_last_clobber (clobber_info *c) { m_last_clobber = c; }\n+\n+  // The value returned by last_clobber ().\n+  clobber_info *m_last_clobber;\n+\n+  // A splay tree that contains all the clobbers in the group.\n+  // The root of the splay tree always has an up-to-date group\n+  // pointer, but the other clobbers in the tree might not.\n+  clobber_tree m_clobber_tree;\n+};\n+\n+// A splay tree in which one node represents a standalone set_info or a\n+// range of consecutive clobber_infos.  The nodes follow execution order\n+// and maintain the invariant that no two groups of clobber_infos appear\n+// next to each other (instead, the groups are merged).\n+using def_splay_tree = default_splay_tree<def_node *>;\n+\n+// This type represents a choice between:\n+//\n+// (1) a single definition of a resource\n+// (2) a node in a def_splay_tree that represents either a single\n+//     set or a group of clobbers.\n+class def_mux : public pointer_mux<def_info, def_node>\n+{\n+  using parent = pointer_mux<def_info, def_node>;\n+\n+  // Provide the same constructors as the pointer_mux.\n+  using parent::parent;\n+\n+public:\n+  // Return the first definition associated with this mux.  If the mux holds\n+  // a single definition, the result is that definition.  If the mux holds\n+  // a clobber_group, the result is the first clobber in the group.\n+  def_info *first_def () const;\n+\n+  // Return the last definition associated with this mux.  If the mux holds\n+  // a single definition, the result is that definition.  If the mux holds\n+  // a clobber_group, the result is the last clobber in the group.\n+  def_info *last_def () const;\n+\n+  // If the pointer represents a set_info, return that set_info,\n+  // otherwise return null.\n+  set_info *set () const;\n+};\n+\n+// This class represents the result of looking up the definition of a\n+// resource at a particular point, here referred to as point P.\n+// There are four states:\n+//\n+// - MUX is null if there were no definitions to search.\n+//\n+// - Otherwise, COMPARISON is 0 if we found a definition at P or a\n+//   clobber_group that spans P.  MUX then contains this definition\n+//   or clobber_group.\n+//\n+// - Otherwise, COMPARISON is less than 0 if we found the definition\n+//   that precedes P or the group of clobbers that precedes P.  MUX then\n+//   contains this definition or clobber_group.\n+//\n+// - Otherwise, COMPARISON is greater than zero and we found the\n+//   definition that follows P, or the group of clobbers that follows P.\n+//   MUX then contains this definition or clobber_group.\n+class def_lookup\n+{\n+public:\n+  // If we found a clobber_group that spans P, return the definition\n+  // that precedes the start of the group, or null if none.\n+  //\n+  // Otherwise, return the last definition that occurs before P,\n+  // or null if none.\n+  def_info *prev_def () const;\n+\n+  // If we found a clobber_group that spans P, return the definition\n+  // that follows the end of the group, or null if none.\n+  //\n+  // Otherwise, return the first definition that occurs after P,\n+  // or null if none.\n+  def_info *next_def () const;\n+\n+  // If we found a set_info at P, return that set_info, otherwise return null.\n+  set_info *matching_set () const;\n+\n+  // If we found a set_info at P, return that set_info, otherwise return\n+  // prev_def ().\n+  def_info *matching_or_prev_def () const;\n+\n+  // If we found a set_info at P, return that set_info, otherwise return\n+  // next_def ().\n+  def_info *matching_or_next_def () const;\n+\n+  def_mux mux;\n+  int comparison;\n+};\n+\n+void pp_resource (pretty_printer *, resource_info);\n+void pp_access (pretty_printer *, const access_info *,\n+\t\tunsigned int flags = PP_ACCESS_DEFAULT);\n+void pp_accesses (pretty_printer *, access_array,\n+\t\t  unsigned int flags = PP_ACCESS_DEFAULT);\n+void pp_def_node (pretty_printer *, const def_node *);\n+void pp_def_mux (pretty_printer *, def_mux);\n+void pp_def_lookup (pretty_printer *, def_lookup);\n+\n+}\n+\n+void dump (FILE *, rtl_ssa::resource_info);\n+void dump (FILE *, const rtl_ssa::access_info *,\n+\t   unsigned int flags = rtl_ssa::PP_ACCESS_DEFAULT);\n+void dump (FILE *, rtl_ssa::access_array,\n+\t   unsigned int flags = rtl_ssa::PP_ACCESS_DEFAULT);\n+void dump (FILE *, const rtl_ssa::def_node *);\n+void dump (FILE *, rtl_ssa::def_mux);\n+void dump (FILE *, rtl_ssa::def_lookup);\n+\n+void DEBUG_FUNCTION debug (const rtl_ssa::resource_info *);\n+void DEBUG_FUNCTION debug (const rtl_ssa::access_info *);\n+void DEBUG_FUNCTION debug (const rtl_ssa::access_array);\n+void DEBUG_FUNCTION debug (const rtl_ssa::def_node *);\n+void DEBUG_FUNCTION debug (const rtl_ssa::def_mux &);\n+void DEBUG_FUNCTION debug (const rtl_ssa::def_lookup &);"}, {"sha": "5436305b11ce1fc2245b3381ae78d3ba5990b314", "filename": "gcc/rtl-ssa/blocks.cc", "status": "added", "additions": 1146, "deletions": 0, "changes": 1146, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fblocks.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fblocks.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Fblocks.cc?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,1146 @@\n+// Implementation of basic-block-related functions for RTL SSA      -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#define INCLUDE_ALGORITHM\n+#define INCLUDE_FUNCTIONAL\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"rtl.h\"\n+#include \"df.h\"\n+#include \"rtl-ssa.h\"\n+#include \"rtl-ssa/internals.inl\"\n+#include \"cfganal.h\"\n+#include \"cfgrtl.h\"\n+#include \"predict.h\"\n+\n+using namespace rtl_ssa;\n+\n+// See the comment above the declaration.\n+void\n+bb_info::print_identifier (pretty_printer *pp) const\n+{\n+  char tmp[3 * sizeof (index ()) + 3];\n+  snprintf (tmp, sizeof (tmp), \"bb%d\", index ());\n+  pp_string (pp, tmp);\n+  if (ebb_info *ebb = this->ebb ())\n+    {\n+      pp_space (pp);\n+      pp_left_bracket (pp);\n+      ebb->print_identifier (pp);\n+      pp_right_bracket (pp);\n+    }\n+}\n+\n+// See the comment above the declaration.\n+void\n+bb_info::print_full (pretty_printer *pp) const\n+{\n+  pp_string (pp, \"basic block \");\n+  print_identifier (pp);\n+  pp_colon (pp);\n+\n+  auto print_insn = [pp](const char *header, const insn_info *insn)\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, header);\n+      pp_newline_and_indent (pp, 2);\n+      if (insn)\n+\tpp_insn (pp, insn);\n+      else\n+\tpp_string (pp, \"<uninitialized>\");\n+      pp_indentation (pp) -= 4;\n+    };\n+\n+  print_insn (\"head:\", head_insn ());\n+\n+  pp_newline (pp);\n+  pp_newline_and_indent (pp, 2);\n+  pp_string (pp, \"contents:\");\n+  if (!head_insn ())\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"<uninitialized>\");\n+      pp_indentation (pp) -= 2;\n+    }\n+  else if (auto insns = real_insns ())\n+    {\n+      bool is_first = true;\n+      for (const insn_info *insn : insns)\n+\t{\n+\t  if (is_first)\n+\t    is_first = false;\n+\t  else\n+\t    pp_newline (pp);\n+\t  pp_newline_and_indent (pp, 2);\n+\t  pp_insn (pp, insn);\n+\t  pp_indentation (pp) -= 2;\n+\t}\n+    }\n+  else\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"none\");\n+      pp_indentation (pp) -= 2;\n+    }\n+  pp_indentation (pp) -= 2;\n+\n+  pp_newline (pp);\n+  print_insn (\"end:\", end_insn ());\n+}\n+\n+// See the comment above the declaration.\n+void\n+ebb_call_clobbers_info::print_summary (pretty_printer *pp) const\n+{\n+  pp_string (pp, \"call clobbers for ABI \");\n+  if (m_abi)\n+    pp_decimal_int (pp, m_abi->id ());\n+  else\n+    pp_string (pp, \"<null>\");\n+}\n+\n+// See the comment above the declaration.\n+void\n+ebb_call_clobbers_info::print_full (pretty_printer *pp) const\n+{\n+  print_summary (pp);\n+  pp_colon (pp);\n+  pp_newline_and_indent (pp, 2);\n+  auto print_node = [](pretty_printer *pp,\n+\t\t       const insn_call_clobbers_note *note)\n+    {\n+      if (insn_info *insn = note->insn ())\n+\tinsn->print_identifier_and_location (pp);\n+      else\n+\tpp_string (pp, \"<null>\");\n+    };\n+  print (pp, root (), print_node);\n+  pp_indentation (pp) -= 2;\n+}\n+\n+// See the comment above the declaration.\n+void\n+ebb_info::print_identifier (pretty_printer *pp) const\n+{\n+  // first_bb is populated by the constructor and so should always\n+  // be nonnull.\n+  auto index = first_bb ()->index ();\n+  char tmp[3 * sizeof (index) + 4];\n+  snprintf (tmp, sizeof (tmp), \"ebb%d\", index);\n+  pp_string (pp, tmp);\n+}\n+\n+// See the comment above the declaration.\n+void\n+ebb_info::print_full (pretty_printer *pp) const\n+{\n+  pp_string (pp, \"extended basic block \");\n+  print_identifier (pp);\n+  pp_colon (pp);\n+\n+  pp_newline_and_indent (pp, 2);\n+  if (insn_info *phi_insn = this->phi_insn ())\n+    {\n+      phi_insn->print_identifier_and_location (pp);\n+      pp_colon (pp);\n+      if (auto phis = this->phis ())\n+\t{\n+\t  bool is_first = true;\n+\t  for (const phi_info *phi : phis)\n+\t    {\n+\t      if (is_first)\n+\t\tis_first = false;\n+\t      else\n+\t\tpp_newline (pp);\n+\t      pp_newline_and_indent (pp, 2);\n+\t      pp_access (pp, phi, PP_ACCESS_SETTER);\n+\t      pp_indentation (pp) -= 2;\n+\t    }\n+\t}\n+      else\n+\t{\n+\t  pp_newline_and_indent (pp, 2);\n+\t  pp_string (pp, \"no phi nodes\");\n+\t  pp_indentation (pp) -= 2;\n+\t}\n+    }\n+  else\n+    pp_string (pp, \"no phi insn\");\n+  pp_indentation (pp) -= 2;\n+\n+  for (const bb_info *bb : bbs ())\n+    {\n+      pp_newline (pp);\n+      pp_newline_and_indent (pp, 2);\n+      pp_bb (pp, bb);\n+      pp_indentation (pp) -= 2;\n+    }\n+\n+  for (ebb_call_clobbers_info *ecc : call_clobbers ())\n+    {\n+      pp_newline (pp);\n+      pp_newline_and_indent (pp, 2);\n+      pp_ebb_call_clobbers (pp, ecc);\n+      pp_indentation (pp) -= 2;\n+    }\n+}\n+\n+// Add a dummy use to mark that DEF is live out of BB's EBB at the end of BB.\n+void\n+function_info::add_live_out_use (bb_info *bb, set_info *def)\n+{\n+  // There is nothing to do if DEF is an artificial definition at the end\n+  // of BB.  In that case the definitino is rooted at the end of the block\n+  // and we wouldn't gain anything by inserting a use immediately after it.\n+  // If we did want to insert a use, we'd need to associate it with a new\n+  // instruction that comes after bb->end_insn ().\n+  if (def->insn () == bb->end_insn ())\n+    return;\n+\n+  // If the end of the block already has an artificial use, that use\n+  // acts to make DEF live at the appropriate point.\n+  unsigned int regno = def->regno ();\n+  if (find_access (bb->end_insn ()->uses (), regno))\n+    return;\n+\n+  // Currently there is no need to maintain a backward link from the end\n+  // instruction to the list of live-out uses.  Such a list would be\n+  // expensive to update if it was represented using the usual insn_info\n+  // access arrays.\n+  use_info *use = allocate<use_info> (bb->end_insn (), def->resource (), def);\n+  use->set_is_live_out_use (true);\n+  add_use (use);\n+}\n+\n+// Return true if all nondebug uses of DEF are live-out uses.\n+static bool\n+all_uses_are_live_out_uses (set_info *def)\n+{\n+  for (use_info *use : def->all_uses ())\n+    if (!use->is_in_debug_insn () && !use->is_live_out_use ())\n+      return false;\n+  return true;\n+}\n+\n+// SET, if nonnull, is a definition of something that is live out from BB.\n+// Return the live-out value itself.\n+set_info *\n+function_info::live_out_value (bb_info *bb, set_info *set)\n+{\n+  // Degenerate phis only exist to provide a definition for uses in the\n+  // same EBB.  The live-out value is the same as the live-in value.\n+  if (auto *phi = safe_dyn_cast<phi_info *> (set))\n+    if (phi->is_degenerate ())\n+      {\n+\tset = phi->input_value (0);\n+\n+\t// Remove the phi if it turned out to be useless.  This is\n+\t// mainly useful for memory, because we don't know ahead of time\n+\t// whether a block will use memory or not.\n+\tif (bb == bb->ebb ()->last_bb () && all_uses_are_live_out_uses (phi))\n+\t  replace_phi (phi, set);\n+      }\n+\n+  return set;\n+}\n+\n+// Add PHI to EBB and enter it into the function's hash table.\n+void\n+function_info::append_phi (ebb_info *ebb, phi_info *phi)\n+{\n+  phi_info *first_phi = ebb->first_phi ();\n+  if (first_phi)\n+    first_phi->set_prev_phi (phi);\n+  phi->set_next_phi (first_phi);\n+  ebb->set_first_phi (phi);\n+  add_def (phi);\n+}\n+\n+// Remove PHI from its current position in the SSA graph.\n+void\n+function_info::remove_phi (phi_info *phi)\n+{\n+  phi_info *next = phi->next_phi ();\n+  phi_info *prev = phi->prev_phi ();\n+\n+  if (next)\n+    next->set_prev_phi (prev);\n+\n+  if (prev)\n+    prev->set_next_phi (next);\n+  else\n+    phi->ebb ()->set_first_phi (next);\n+\n+  remove_def (phi);\n+  phi->clear_phi_links ();\n+}\n+\n+// Remove PHI from the SSA graph and free its memory.\n+void\n+function_info::delete_phi (phi_info *phi)\n+{\n+  gcc_assert (!phi->has_any_uses ());\n+\n+  // Remove the inputs to the phi.\n+  for (use_info *input : phi->inputs ())\n+    remove_use (input);\n+\n+  remove_phi (phi);\n+\n+  phi->set_next_phi (m_free_phis);\n+  m_free_phis = phi;\n+}\n+\n+// If possible, remove PHI and replace all uses with NEW_VALUE.\n+void\n+function_info::replace_phi (phi_info *phi, set_info *new_value)\n+{\n+  auto update_use = [&](use_info *use)\n+    {\n+      remove_use (use);\n+      use->set_def (new_value);\n+      add_use (use);\n+    };\n+\n+  if (new_value)\n+    for (use_info *use : phi->nondebug_insn_uses ())\n+      if (!use->is_live_out_use ())\n+\t{\n+\t  // We need to keep the phi around for its local uses.\n+\t  // Turn it into a degenerate phi, if it isn't already.\n+\t  use_info *use = phi->input_use (0);\n+\t  if (use->def () != new_value)\n+\t    update_use (use);\n+\n+\t  if (phi->is_degenerate ())\n+\t    return;\n+\n+\t  phi->make_degenerate (use);\n+\n+\t  // Redirect all phi users to NEW_VALUE.\n+\t  while (use_info *phi_use = phi->last_phi_use ())\n+\t    update_use (phi_use);\n+\n+\t  return;\n+\t}\n+\n+  // Replace the uses.  We can discard uses that only existed for the\n+  // sake of marking live-out values, since the resource is now transparent\n+  // in the phi's EBB.\n+  while (use_info *use = phi->last_use ())\n+    if (use->is_live_out_use ())\n+      remove_use (use);\n+    else\n+      update_use (use);\n+\n+  delete_phi (phi);\n+}\n+\n+// Create and return a phi node for EBB.  RESOURCE is the resource that\n+// the phi node sets (and thus that all the inputs set too).  NUM_INPUTS\n+// is the number of inputs, which is 1 for a degenerate phi.  INPUTS[I]\n+// is a set_info that gives the value of input I, or null if the value\n+// is either unknown or uninitialized.  If NUM_INPUTS > 1, this array\n+// is allocated on the main obstack and can be reused for the use array.\n+//\n+// Add the created phi node to its basic block and enter it into the\n+// function's hash table.\n+phi_info *\n+function_info::create_phi (ebb_info *ebb, resource_info resource,\n+\t\t\t   access_info **inputs, unsigned int num_inputs)\n+{\n+  phi_info *phi = m_free_phis;\n+  if (phi)\n+    {\n+      m_free_phis = phi->next_phi ();\n+      *phi = phi_info (ebb->phi_insn (), resource, phi->uid ());\n+    }\n+  else\n+    {\n+      phi = allocate<phi_info> (ebb->phi_insn (), resource, m_next_phi_uid);\n+      m_next_phi_uid += 1;\n+    }\n+\n+  // Convert the array of set_infos into an array of use_infos.  Also work\n+  // out what mode the phi should have.\n+  machine_mode new_mode = resource.mode;\n+  for (unsigned int i = 0; i < num_inputs; ++i)\n+    {\n+      auto *input = safe_as_a<set_info *> (inputs[i]);\n+      auto *use = allocate<use_info> (phi, resource, input);\n+      add_use (use);\n+      inputs[i] = use;\n+      if (input)\n+\tnew_mode = combine_modes (new_mode, input->mode ());\n+    }\n+\n+  phi->set_inputs (use_array (inputs, num_inputs));\n+  phi->set_mode (new_mode);\n+\n+  append_phi (ebb, phi);\n+\n+  return phi;\n+}\n+\n+// Create and return a degenerate phi for EBB whose input comes from DEF.\n+// This is used in cases where DEF is known to be available on entry to\n+// EBB but was not previously used within it.  If DEF is for a register,\n+// there are two cases:\n+//\n+// (1) DEF was already live on entry to EBB but was previously transparent\n+//     within it.\n+//\n+// (2) DEF was not previously live on entry to EBB and is being made live\n+//     by this update.\n+//\n+// At the moment, this function only handles the case in which EBB has a\n+// single predecessor block and DEF is defined in that block's EBB.\n+phi_info *\n+function_info::create_degenerate_phi (ebb_info *ebb, set_info *def)\n+{\n+  access_info *input = def;\n+  phi_info *phi = create_phi (ebb, def->resource (), &input, 1);\n+  if (def->is_reg ())\n+    {\n+      unsigned int regno = def->regno ();\n+\n+      // Find the single predecessor mentioned above.\n+      basic_block pred_cfg_bb = single_pred (ebb->first_bb ()->cfg_bb ());\n+      bb_info *pred_bb = this->bb (pred_cfg_bb);\n+\n+      if (!bitmap_set_bit (DF_LR_IN (ebb->first_bb ()->cfg_bb ()), regno))\n+\t{\n+\t  // The register was not previously live on entry to EBB and\n+\t  // might not have been live on exit from PRED_BB either.\n+\t  if (bitmap_set_bit (DF_LR_OUT (pred_cfg_bb), regno))\n+\t    add_live_out_use (pred_bb, def);\n+\t}\n+      else\n+\t{\n+\t  // The register was previously live in to EBB.  Add live-out uses\n+\t  // at the appropriate points.\n+\t  insn_info *next_insn = nullptr;\n+\t  if (def_info *next_def = phi->next_def ())\n+\t    next_insn = next_def->insn ();\n+\t  for (bb_info *bb : ebb->bbs ())\n+\t    {\n+\t      if ((next_insn && *next_insn <= *bb->end_insn ())\n+\t\t  || !bitmap_bit_p (DF_LR_OUT (bb->cfg_bb ()), regno))\n+\t\tbreak;\n+\t      add_live_out_use (bb, def);\n+\t    }\n+\t}\n+    }\n+  return phi;\n+}\n+\n+// Create a bb_info for CFG_BB, given that no such structure currently exists.\n+bb_info *\n+function_info::create_bb_info (basic_block cfg_bb)\n+{\n+  bb_info *bb = allocate<bb_info> (cfg_bb);\n+  gcc_checking_assert (!m_bbs[cfg_bb->index]);\n+  m_bbs[cfg_bb->index] = bb;\n+  return bb;\n+}\n+\n+// Add BB to the end of the list of blocks.\n+void\n+function_info::append_bb (bb_info *bb)\n+{\n+  if (m_last_bb)\n+    m_last_bb->set_next_bb (bb);\n+  else\n+    m_first_bb = bb;\n+  bb->set_prev_bb (m_last_bb);\n+  m_last_bb = bb;\n+}\n+\n+// Called while building SSA form using BI, with BI.current_bb being\n+// the entry block.\n+//\n+// Create the entry block instructions and their definitions.  The only\n+// useful instruction is the end instruction, which carries definitions\n+// for the values that are live on entry to the function.  However, it\n+// seems simpler to create a head instruction too, rather than force all\n+// users of the block information to treat the entry block as a special case.\n+void\n+function_info::add_entry_block_defs (build_info &bi)\n+{\n+  bb_info *bb = bi.current_bb;\n+  basic_block cfg_bb = bi.current_bb->cfg_bb ();\n+  auto *lr_info = DF_LR_BB_INFO (cfg_bb);\n+\n+  bb->set_head_insn (append_artificial_insn (bb));\n+  insn_info *insn = append_artificial_insn (bb);\n+  bb->set_end_insn (insn);\n+\n+  start_insn_accesses ();\n+\n+  // Using LR to derive the liveness information means that we create an\n+  // entry block definition for upwards exposed registers.  These registers\n+  // are sometimes genuinely uninitialized.  However, some targets also\n+  // create a pseudo PIC base register and only initialize it later.\n+  // Handling that case correctly seems more important than optimizing\n+  // uninitialized uses.\n+  unsigned int regno;\n+  bitmap_iterator in_bi;\n+  EXECUTE_IF_SET_IN_BITMAP (&lr_info->out, 0, regno, in_bi)\n+    {\n+      auto *set = allocate<set_info> (insn, full_register (regno));\n+      append_def (set);\n+      m_temp_defs.safe_push (set);\n+      bi.record_reg_def (regno, set);\n+    }\n+\n+  // Create a definition that reflects the state of memory on entry to\n+  // the function.\n+  auto *set = allocate<set_info> (insn, memory);\n+  append_def (set);\n+  m_temp_defs.safe_push (set);\n+  bi.record_mem_def (set);\n+\n+  finish_insn_accesses (insn);\n+}\n+\n+// Called while building SSA form using BI.  Create phi nodes for the\n+// current EBB, leaving backedge inputs to be filled in later.  Set\n+// bi.last_access to the values that are live on entry to the EBB,\n+// regardless of whether or not they are phi nodes.\n+void\n+function_info::add_phi_nodes (build_info &bi)\n+{\n+  ebb_info *ebb = bi.current_ebb;\n+  basic_block cfg_bb = ebb->first_bb ()->cfg_bb ();\n+  auto *lr_info = DF_LR_BB_INFO (cfg_bb);\n+\n+  // Get a local cache of the predecessor blocks' live out values.\n+  unsigned int num_preds = EDGE_COUNT (cfg_bb->preds);\n+  auto_vec<const bb_live_out_info *, 16> pred_live_outs (num_preds);\n+  bool has_backedge = false;\n+  bool has_eh_edge = false;\n+  edge e;\n+  edge_iterator ei;\n+  FOR_EACH_EDGE (e, ei, cfg_bb->preds)\n+    {\n+      bb_info *pred_bb = this->bb (e->src);\n+      const bb_live_out_info *live_out = &bi.bb_live_out[e->src->index];\n+\n+      // In LR (but not LIVE), the registers live on entry to a block must\n+      // normally be a subset of the registers live on exit from any\n+      // given predecessor block.  The exceptions are EH edges, which\n+      // implicitly clobber all registers in eh_edge_abi.full_reg_clobbers ().\n+      // Thus if a register is upwards exposed in an EH handler, it won't\n+      // be propagated across the EH edge.\n+      //\n+      // Excluding that special case, all registers live on entry to\n+      // EBB are also live on exit from PRED_BB and were (or will be)\n+      // considered when creating LIVE_OUT.\n+      gcc_checking_assert ((e->flags & EDGE_EH)\n+\t\t\t   || !bitmap_intersect_compl_p (&lr_info->in,\n+\t\t\t\t\t\t\t DF_LR_OUT (e->src)));\n+      if (!pred_bb || !pred_bb->head_insn ())\n+\t{\n+\t  has_backedge = true;\n+\t  live_out = nullptr;\n+\t}\n+      has_eh_edge |= (e->flags & EDGE_EH);\n+      pred_live_outs.quick_push (live_out);\n+    }\n+\n+  // PRED_REG_INDICES[I] tracks the index into PRED_LIVE_OUTS[I]->reg_values\n+  // of the first unused entry.\n+  auto_vec<unsigned int, 16> pred_reg_indices (num_preds);\n+  pred_reg_indices.quick_grow_cleared (num_preds);\n+\n+  // Use this array to build up the list of inputs to each phi.\n+  m_temp_defs.safe_grow (num_preds);\n+\n+  // Return true if the current phi is degenerate, i.e. if all its inputs\n+  // are the same.\n+  auto is_degenerate_phi = [&]()\n+    {\n+      if (has_backedge)\n+\treturn false;\n+\n+      for (unsigned int i = 1; i < num_preds; ++i)\n+\tif (m_temp_defs[i] != m_temp_defs[0])\n+\t  return false;\n+\n+      return true;\n+    };\n+\n+  // Finish calculating the live-in value for RESOURCE.  Decide how to\n+  // represent the value of RESOURCE on entry to EBB and return its definition.\n+  auto finish_phi = [&](resource_info resource) -> set_info *\n+    {\n+      access_info **inputs;\n+      unsigned int num_inputs;\n+      if (is_degenerate_phi ())\n+\t{\n+\t  auto *input = safe_as_a<set_info *> (m_temp_defs[0]);\n+\t  if (!input)\n+\t    // The live-in value is completely uninitialized.\n+\t    return nullptr;\n+\n+\t  unsigned int regno = input->regno ();\n+\t  if (input->is_reg () && !bitmap_bit_p (bi.ebb_use, regno))\n+\t    // The live-in value comes from a single source and there\n+\t    // are no uses of it within the EBB itself.  We therefore\n+\t    // don't need a phi node.\n+\t    return input;\n+\n+\t  // The live-in value comes from a single source and might be\n+\t  // used by the EBB itself.  Create a degenerate phi for it.\n+\t  inputs = m_temp_defs.begin ();\n+\t  num_inputs = 1;\n+\t}\n+      else\n+\t{\n+\t  obstack_grow (&m_obstack, m_temp_defs.address (),\n+\t\t\tnum_preds * sizeof (access_info *));\n+\t  inputs = static_cast<access_info **> (obstack_finish (&m_obstack));\n+\t  num_inputs = num_preds;\n+\t}\n+      return create_phi (ebb, resource, inputs, num_inputs);\n+    };\n+\n+  if (bi.ebb_live_in_for_debug)\n+    bitmap_clear (bi.ebb_live_in_for_debug);\n+\n+  // Get the definition of each live input register, excluding registers\n+  // that are known to have a single definition that dominates all uses.\n+  unsigned int regno;\n+  bitmap_iterator in_bi;\n+  EXECUTE_IF_AND_IN_BITMAP (&lr_info->in, m_potential_phi_regs,\n+\t\t\t    0, regno, in_bi)\n+    {\n+      for (unsigned int pred_i = 0; pred_i < num_preds; ++pred_i)\n+\t{\n+\t  set_info *input = nullptr;\n+\t  if (const bb_live_out_info *pred_live_out = pred_live_outs[pred_i])\n+\t    {\n+\t      // Skip over registers that aren't live on entry to this block.\n+\t      unsigned int reg_i = pred_reg_indices[pred_i];\n+\t      while (reg_i < pred_live_out->num_reg_values\n+\t\t     && pred_live_out->reg_values[reg_i]->regno () < regno)\n+\t\treg_i += 1;\n+\n+\t      // As we asserted above, REGNO is live out from the predecessor\n+\t      // block, at least by the LR reckoning.  But there are three\n+\t      // cases:\n+\t      //\n+\t      // (1) The live-out value is well-defined (the normal case),\n+\t      //     with the definition coming either from the block itself\n+\t      //     or from a predecessor block.  In this case reg_values\n+\t      //     has a set_info entry for the register.\n+\t      //\n+\t      // (2) The live-out value was not modified by the predecessor\n+\t      //     EBB and did not have a defined value on input to that\n+\t      //     EBB either.  In this case reg_values has no entry for\n+\t      //     the register.\n+\t      //\n+\t      // (3) The live-out value was modified by the predecessor EBB,\n+\t      //     but the final modification was a clobber rather than\n+\t      //     a set.  In this case reg_values again has no entry for\n+\t      //     the register.\n+\t      //\n+\t      // The phi input for (2) and (3) is undefined, which we\n+\t      // represent as a null set_info.\n+\t      if (reg_i < pred_live_out->num_reg_values)\n+\t\t{\n+\t\t  set_info *set = pred_live_out->reg_values[reg_i];\n+\t\t  if (set->regno () == regno)\n+\t\t    {\n+\t\t      input = set;\n+\t\t      reg_i += 1;\n+\t\t    }\n+\t\t}\n+\n+\t      // Fully call-clobbered values do not survive across EH edges.\n+\t      // In particular, if a call that normally sets a result register\n+\t      // throws an exception, the set of the result register should\n+\t      // not be treated as live on entry to the EH handler.\n+\t      if (has_eh_edge\n+\t\t  && HARD_REGISTER_NUM_P (regno)\n+\t\t  && eh_edge_abi.clobbers_full_reg_p (regno)\n+\t\t  && (EDGE_PRED (cfg_bb, pred_i)->flags & EDGE_EH))\n+\t\tinput = nullptr;\n+\n+\t      pred_reg_indices[pred_i] = reg_i;\n+\t    }\n+\t  m_temp_defs[pred_i] = input;\n+\t}\n+      // Later code works out the correct mode of the phi.  Use BLKmode\n+      // as a placeholder for now.\n+      bi.record_reg_def (regno, finish_phi ({ E_BLKmode, regno }));\n+      if (bi.ebb_live_in_for_debug)\n+\tbitmap_set_bit (bi.ebb_live_in_for_debug, regno);\n+    }\n+\n+  // Repeat the process above for memory.\n+  for (unsigned int pred_i = 0; pred_i < num_preds; ++pred_i)\n+    {\n+      set_info *input = nullptr;\n+      if (const bb_live_out_info *pred_live_out = pred_live_outs[pred_i])\n+\tinput = pred_live_out->mem_value;\n+      m_temp_defs[pred_i] = input;\n+    }\n+  bi.record_mem_def (finish_phi (memory));\n+\n+  m_temp_defs.truncate (0);\n+}\n+\n+// Called while building SSA form using BI.\n+//\n+// If FLAGS is DF_REF_AT_TOP, create the head insn for BI.current_bb\n+// and populate its uses and definitions.  If FLAGS is 0, do the same\n+// for the end insn.\n+void\n+function_info::add_artificial_accesses (build_info &bi, df_ref_flags flags)\n+{\n+  bb_info *bb = bi.current_bb;\n+  basic_block cfg_bb = bb->cfg_bb ();\n+  auto *lr_info = DF_LR_BB_INFO (cfg_bb);\n+  df_ref ref;\n+\n+  insn_info *insn;\n+  if (flags == DF_REF_AT_TOP)\n+    {\n+      if (cfg_bb->index == EXIT_BLOCK)\n+\tinsn = append_artificial_insn (bb);\n+      else\n+\tinsn = append_artificial_insn (bb, bb_note (cfg_bb));\n+      bb->set_head_insn (insn);\n+    }\n+  else\n+    {\n+      insn = append_artificial_insn (bb);\n+      bb->set_end_insn (insn);\n+    }\n+\n+  start_insn_accesses ();\n+\n+  FOR_EACH_ARTIFICIAL_USE (ref, cfg_bb->index)\n+    if ((DF_REF_FLAGS (ref) & DF_REF_AT_TOP) == flags)\n+      {\n+\tunsigned int regno = DF_REF_REGNO (ref);\n+\tmachine_mode mode = GET_MODE (DF_REF_REAL_REG (ref));\n+\tresource_info resource { mode, regno };\n+\n+\t// A definition must be available.\n+\tgcc_checking_assert (bitmap_bit_p (&lr_info->in, regno)\n+\t\t\t     || (flags != DF_REF_AT_TOP\n+\t\t\t\t && bitmap_bit_p (&lr_info->def, regno)));\n+\tset_info *def = bi.current_reg_value (regno);\n+\tauto *use = allocate<use_info> (insn, resource, def);\n+\tadd_use (use);\n+\tm_temp_uses.safe_push (use);\n+      }\n+\n+  // Track the return value of memory by adding an artificial use of\n+  // memory at the end of the exit block.\n+  if (flags == 0 && cfg_bb->index == EXIT_BLOCK)\n+    {\n+      auto *use = allocate<use_info> (insn, memory, bi.current_mem_value ());\n+      add_use (use);\n+      m_temp_uses.safe_push (use);\n+    }\n+\n+  FOR_EACH_ARTIFICIAL_DEF (ref, cfg_bb->index)\n+    if ((DF_REF_FLAGS (ref) & DF_REF_AT_TOP) == flags)\n+      {\n+\tunsigned int regno = DF_REF_REGNO (ref);\n+\tmachine_mode mode = GET_MODE (DF_REF_REAL_REG (ref));\n+\tresource_info resource { mode, regno };\n+\n+\t// If the value isn't used later in the block and isn't live\n+\t// on exit, we could instead represent the definition as a\n+\t// clobber_info.  However, that case should be relatively\n+\t// rare and set_info is any case more compact than clobber_info.\n+\tset_info *def = allocate<set_info> (insn, resource);\n+\tappend_def (def);\n+\tm_temp_defs.safe_push (def);\n+\tbi.record_reg_def (regno, def);\n+      }\n+\n+  // Model the effect of a memory clobber on an incoming edge by adding\n+  // a fake definition of memory at the start of the block.  We don't need\n+  // to add a use of the phi node because memory is implicitly always live.\n+  if (flags == DF_REF_AT_TOP && has_abnormal_call_or_eh_pred_edge_p (cfg_bb))\n+    {\n+      set_info *def = allocate<set_info> (insn, memory);\n+      append_def (def);\n+      m_temp_defs.safe_push (def);\n+      bi.record_mem_def (def);\n+    }\n+\n+  finish_insn_accesses (insn);\n+}\n+\n+// Called while building SSA form using BI.  Create insn_infos for all\n+// relevant instructions in BI.current_bb.\n+void\n+function_info::add_block_contents (build_info &bi)\n+{\n+  basic_block cfg_bb = bi.current_bb->cfg_bb ();\n+  rtx_insn *insn;\n+  FOR_BB_INSNS (cfg_bb, insn)\n+    if (INSN_P (insn))\n+      add_insn_to_block (bi, insn);\n+}\n+\n+// Called while building SSA form using BI.  Use BI.bb_live_out to record\n+// the values that are live out from BI.current_bb.\n+void\n+function_info::record_block_live_out (build_info &bi)\n+{\n+  bb_info *bb = bi.current_bb;\n+  ebb_info *ebb = bi.current_ebb;\n+  basic_block cfg_bb = bb->cfg_bb ();\n+  bb_live_out_info *live_out = &bi.bb_live_out[bb->index ()];\n+  auto *lr_info = DF_LR_BB_INFO (bb->cfg_bb ());\n+\n+  // Calculate which subset of m_potential_phi_regs is live out from EBB\n+  // at the end of BB.\n+  auto_bitmap live_out_from_ebb;\n+  edge e;\n+  edge_iterator ei;\n+  FOR_EACH_EDGE (e, ei, cfg_bb->succs)\n+    {\n+      bb_info *dest_bb = this->bb (e->dest);\n+      if (!dest_bb || dest_bb->ebb () != ebb)\n+\tbitmap_ior_and_into (live_out_from_ebb, DF_LR_IN (e->dest),\n+\t\t\t     m_potential_phi_regs);\n+    }\n+\n+  // Record the live-out register values.\n+  unsigned int regno;\n+  bitmap_iterator out_bi;\n+  EXECUTE_IF_AND_IN_BITMAP (&lr_info->out, m_potential_phi_regs,\n+\t\t\t    0, regno, out_bi)\n+    if (set_info *value = live_out_value (bb, bi.current_reg_value (regno)))\n+      {\n+\tif (value->ebb () == ebb && bitmap_bit_p (live_out_from_ebb, regno))\n+\t  add_live_out_use (bb, value);\n+\tobstack_ptr_grow (&m_temp_obstack, value);\n+      }\n+\n+  live_out->num_reg_values = (obstack_object_size (&m_temp_obstack)\n+\t\t\t      / sizeof (set_info *));\n+  auto *data = obstack_finish (&m_temp_obstack);\n+  live_out->reg_values = static_cast<set_info **> (data);\n+\n+  live_out->mem_value = live_out_value (bb, bi.current_mem_value ());\n+}\n+\n+// Called while building SSA form using BI.  Check if BI.current_bb has\n+// any outgoing backedges.  If so, use the up-to-date contents of\n+// BI.bb_live_out to populate the associated inputs of any phi nodes.\n+void\n+function_info::populate_backedge_phis (build_info &bi)\n+{\n+  bb_info *bb = bi.current_bb;\n+  basic_block cfg_bb = bb->cfg_bb ();\n+  const bb_live_out_info *live_out = &bi.bb_live_out[bb->index ()];\n+\n+  edge e;\n+  edge_iterator ei;\n+  FOR_EACH_EDGE (e, ei, cfg_bb->succs)\n+    {\n+      // Check if this edge counts as a backedge in the current traversal.\n+      bb_info *succ_bb = this->bb (e->dest);\n+      if (!succ_bb || !succ_bb->head_insn ())\n+\tcontinue;\n+\n+      // Although the phis do not keep a defined order long-term, they are\n+      // still in reverse regno order at this point.  We can therefore use\n+      // a merge operation on the phis and the live-out values.\n+      unsigned int input_i = e->dest_idx;\n+      int reg_i = live_out->num_reg_values - 1;\n+      for (phi_info *phi : succ_bb->ebb ()->phis ())\n+\t{\n+\t  set_info *input = nullptr;\n+\t  if (phi->is_mem ())\n+\t    input = live_out->mem_value;\n+\t  else\n+\t    {\n+\t      // Skip over any intervening live-out values.\n+\t      unsigned int regno = phi->regno ();\n+\t      while (reg_i >= 0)\n+\t\t{\n+\t\t  set_info *reg_value = live_out->reg_values[reg_i];\n+\t\t  if (reg_value->regno () < regno)\n+\t\t    break;\n+\t\t  reg_i -= 1;\n+\t\t  if (reg_value->regno () == regno)\n+\t\t    {\n+\t\t      input = reg_value;\n+\t\t      break;\n+\t\t    }\n+\t\t}\n+\t    }\n+\t  if (input)\n+\t    {\n+\t      use_info *use = phi->input_use (input_i);\n+\t      gcc_assert (!use->def ());\n+\t      use->set_def (input);\n+\t      add_use (use);\n+\t    }\n+\t}\n+    }\n+}\n+\n+// Return true if it would be better to continue an EBB across NEW_EDGE\n+// rather than across OLD_EDGE, given that both edges are viable candidates.\n+// This is not a total ordering.\n+static bool\n+better_ebb_edge_p (edge new_edge, edge old_edge)\n+{\n+  // Prefer the likeliest edge.\n+  if (new_edge->probability.initialized_p ()\n+      && old_edge->probability.initialized_p ()\n+      && !(old_edge->probability == new_edge->probability))\n+    return old_edge->probability < new_edge->probability;\n+\n+  // If both edges are equally likely, prefer a fallthru edge.\n+  if (new_edge->flags & EDGE_FALLTHRU)\n+    return true;\n+  if (old_edge->flags & EDGE_FALLTHRU)\n+    return false;\n+\n+  // Otherwise just stick with OLD_EDGE.\n+  return false;\n+}\n+\n+// Pick and return the next basic block in an EBB that currently ends with BB.\n+// Return null if the EBB must end with BB.\n+static basic_block\n+choose_next_block_in_ebb (basic_block bb)\n+{\n+  // Although there's nothing in principle wrong with having an EBB that\n+  // starts with the entry block and includes later blocks, there's not\n+  // really much point either.  Keeping the entry block separate means\n+  // that uses of arguments consistently occur through phi nodes, rather\n+  // than the arguments sometimes appearing to come from an EBB-local\n+  // definition instead.\n+  if (bb->index == ENTRY_BLOCK)\n+    return nullptr;\n+\n+  bool optimize_for_speed_p = optimize_bb_for_speed_p (bb);\n+  edge best_edge = nullptr;\n+  edge e;\n+  edge_iterator ei;\n+  FOR_EACH_EDGE (e, ei, bb->succs)\n+    if (!(e->flags & EDGE_COMPLEX)\n+\t&& e->dest->index != EXIT_BLOCK\n+\t&& single_pred_p (e->dest)\n+\t&& optimize_for_speed_p == optimize_bb_for_speed_p (e->dest)\n+\t&& (!best_edge || better_ebb_edge_p (e, best_edge)))\n+      best_edge = e;\n+\n+  return best_edge ? best_edge->dest : nullptr;\n+}\n+\n+// Partition the function's blocks into EBBs and build SSA form for all\n+// EBBs in the function.\n+void\n+function_info::process_all_blocks ()\n+{\n+  auto temps = temp_watermark ();\n+  unsigned int num_bb_indices = last_basic_block_for_fn (m_fn);\n+\n+  // Compute the starting reverse postorder.  We tweak this later to try\n+  // to get better EBB assignments.\n+  auto *postorder = new int[n_basic_blocks_for_fn (m_fn)];\n+  unsigned int postorder_num\n+    = pre_and_rev_post_order_compute (nullptr, postorder, true);\n+  gcc_assert (int (postorder_num) <= n_basic_blocks_for_fn (m_fn));\n+\n+  // Construct the working state for this function and its subroutines.\n+  build_info bi;\n+  bi.last_access = XOBNEWVEC (&m_temp_obstack, access_info *, m_num_regs + 1);\n+  memset (bi.last_access, 0, (m_num_regs + 1) * sizeof (set_info *));\n+\n+  // The bb_live_out array shouldn't need to be initialized, since we'll\n+  // always write to an entry before reading from it.  But poison the\n+  // contents when checking, just to make sure we don't accidentally use\n+  // an uninitialized value.\n+  bi.bb_live_out = XOBNEWVEC (&m_temp_obstack, bb_live_out_info,\n+\t\t\t      num_bb_indices);\n+  if (flag_checking)\n+    memset (bi.bb_live_out, 0xaf,\n+\t    num_bb_indices * sizeof (bb_live_out_info));\n+\n+  // Only pay the overhead of recording a separate live-in bitmap if\n+  // there are debug instructions that might need it.\n+  auto_bitmap ebb_live_in;\n+  if (MAY_HAVE_DEBUG_INSNS)\n+    {\n+      bi.ebb_live_in_for_debug = ebb_live_in;\n+      // The bitmap is tested using individual bit operations, so optimize\n+      // for that case.\n+      bitmap_tree_view (ebb_live_in);\n+    }\n+  else\n+    bi.ebb_live_in_for_debug = nullptr;\n+\n+  // Iterate over the blocks in reverse postorder.  In cases where\n+  // multiple possible orders exist, prefer orders that chain blocks\n+  // together into EBBs.  If multiple possible EBBs exist, try to pick\n+  // the ones that are most likely to be profitable.\n+  auto_vec<bb_info *, 16> ebb;\n+  auto_bitmap ebb_use_tmp;\n+  auto_bitmap ebb_def_tmp;\n+  for (unsigned int i = 0; i < postorder_num; ++i)\n+    if (!m_bbs[postorder[i]])\n+      {\n+\t// Choose and create the blocks that should form the next EBB,\n+\t// and calculate the set of registers that the EBB uses and defines\n+\t// Only do actual bitmap operations if the EBB contains multiple\n+\t// blocks.\n+\tbasic_block cfg_bb = BASIC_BLOCK_FOR_FN (m_fn, postorder[i]);\n+\tbi.ebb_use = &DF_LR_BB_INFO (cfg_bb)->use;\n+\tbi.ebb_def = &DF_LR_BB_INFO (cfg_bb)->def;\n+\tebb.safe_push (create_bb_info (cfg_bb));\n+\tcfg_bb = choose_next_block_in_ebb (cfg_bb);\n+\tif (cfg_bb)\n+\t  {\n+\t    // An EBB with two blocks.\n+\t    bitmap_ior (ebb_use_tmp, bi.ebb_use, &DF_LR_BB_INFO (cfg_bb)->use);\n+\t    bitmap_ior (ebb_def_tmp, bi.ebb_def, &DF_LR_BB_INFO (cfg_bb)->def);\n+\t    bi.ebb_use = ebb_use_tmp;\n+\t    bi.ebb_def = ebb_def_tmp;\n+\t    ebb.safe_push (create_bb_info (cfg_bb));\n+\t    cfg_bb = choose_next_block_in_ebb (cfg_bb);\n+\t    while (cfg_bb)\n+\t      {\n+\t\t// An EBB with three or more blocks.\n+\t\tbitmap_ior_into (bi.ebb_use, &DF_LR_BB_INFO (cfg_bb)->use);\n+\t\tbitmap_ior_into (bi.ebb_def, &DF_LR_BB_INFO (cfg_bb)->def);\n+\t\tebb.safe_push (create_bb_info (cfg_bb));\n+\t\tcfg_bb = choose_next_block_in_ebb (cfg_bb);\n+\t      }\n+\t  }\n+\n+\t// Create the EBB itself.\n+\tbi.current_ebb = allocate<ebb_info> (ebb[0], ebb.last ());\n+\tfor (bb_info *bb : ebb)\n+\t  {\n+\t    bb->set_ebb (bi.current_ebb);\n+\t    append_bb (bb);\n+\t  }\n+\n+\t// Populate the contents of the EBB.\n+\tbi.current_ebb->set_phi_insn (append_artificial_insn (ebb[0]));\n+\tif (ebb[0]->index () == ENTRY_BLOCK)\n+\t  {\n+\t    gcc_assert (ebb.length () == 1);\n+\t    bi.current_bb = ebb[0];\n+\t    add_entry_block_defs (bi);\n+\t    record_block_live_out (bi);\n+\t  }\n+\telse if (EDGE_COUNT (ebb[0]->cfg_bb ()->preds) == 0)\n+\t  // Leave unreachable blocks empty, since there is no useful\n+\t  // liveness information for them, and anything they do will\n+\t  // be wasted work.  In a cleaned-up cfg, the only unreachable\n+\t  // block we should see is the exit block of a noreturn function.\n+\t  for (bb_info *bb : ebb)\n+\t    {\n+\t      bb->set_head_insn (append_artificial_insn (bb));\n+\t      bb->set_end_insn (append_artificial_insn (bb));\n+\t    }\n+\telse\n+\t  {\n+\t    add_phi_nodes (bi);\n+\t    for (bb_info *bb : ebb)\n+\t      {\n+\t\tbi.current_bb = bb;\n+\t\tadd_artificial_accesses (bi, DF_REF_AT_TOP);\n+\t\tif (bb->index () != EXIT_BLOCK)\n+\t\t  add_block_contents (bi);\n+\t\tadd_artificial_accesses (bi, df_ref_flags ());\n+\t\trecord_block_live_out (bi);\n+\t\tpopulate_backedge_phis (bi);\n+\t      }\n+\t  }\n+\tebb.truncate (0);\n+      }\n+\n+  delete[] postorder;\n+}\n+\n+// Print a description of CALL_CLOBBERS to PP.\n+void\n+rtl_ssa::pp_ebb_call_clobbers (pretty_printer *pp,\n+\t\t\t       const ebb_call_clobbers_info *call_clobbers)\n+{\n+  if (!call_clobbers)\n+    pp_string (pp, \"<null>\");\n+  else\n+    call_clobbers->print_full (pp);\n+}\n+\n+// Print a description of BB to PP.\n+void\n+rtl_ssa::pp_bb (pretty_printer *pp, const bb_info *bb)\n+{\n+  if (!bb)\n+    pp_string (pp, \"<null>\");\n+  else\n+    bb->print_full (pp);\n+}\n+\n+// Print a description of EBB to PP\n+void\n+rtl_ssa::pp_ebb (pretty_printer *pp, const ebb_info *ebb)\n+{\n+  if (!ebb)\n+    pp_string (pp, \"<null>\");\n+  else\n+    ebb->print_full (pp);\n+}\n+\n+// Print a description of CALL_CLOBBERS to FILE.\n+void\n+dump (FILE *file, const ebb_call_clobbers_info *call_clobbers)\n+{\n+  dump_using (file, pp_ebb_call_clobbers, call_clobbers);\n+}\n+\n+// Print a description of BB to FILE.\n+void\n+dump (FILE *file, const bb_info *bb)\n+{\n+  dump_using (file, pp_bb, bb);\n+}\n+\n+// Print a description of EBB to FILE.\n+void\n+dump (FILE *file, const ebb_info *ebb)\n+{\n+  dump_using (file, pp_ebb, ebb);\n+}\n+\n+// Debug interfaces to the dump routines above.\n+void debug (const ebb_call_clobbers_info *x) { dump (stderr, x); }\n+void debug (const bb_info *x) { dump (stderr, x); }\n+void debug (const ebb_info *x) { dump (stderr, x); }"}, {"sha": "f173e6ff8dac8248eb2f9992238443b3525d8890", "filename": "gcc/rtl-ssa/blocks.h", "status": "added", "additions": 301, "deletions": 0, "changes": 301, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fblocks.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fblocks.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Fblocks.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,301 @@\n+// Basic-block-related classes for RTL SSA                          -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// SSA-related information about a basic block.  Each block contains\n+// the following, which are conceptually executed in order:\n+//\n+// - an artificial \"head\" insn_info that holds artificial uses and definitions\n+//   for the start of the block.\n+//\n+// - one insn_info for each \"real\" instruction in the block\n+//   (i.e. those that have an RTL pattern).\n+//\n+// - an artificial \"end\" insn_info that holds artificial uses and definitions\n+//   for the end of the block.\n+//\n+// Blocks are grouped together into extended basic blocks.  In cases where\n+// multiple EBBs exist (such as in a full diamond), we try to pick the one\n+// that's most frequently executed.\n+//\n+// Blocks are chained together in reverse postorder.  (Rather than use a\n+// list, we could instead have stored the index of the block in the overall\n+// postorder.  However, using lists should make it cheaper to update the\n+// information after trivial CFG manipulations.)\n+class bb_info\n+{\n+  // Size: 6 LP64 words.\n+  friend class function_info;\n+\n+public:\n+  // Return the previous basic block in reverse postorder, or null if this\n+  // is the entry block.\n+  bb_info *prev_bb () const { return m_prev_bb; }\n+\n+  // Return the next basic block in reverse postorder, or null if this\n+  // is the exit block.\n+  bb_info *next_bb () const { return m_next_bb; }\n+\n+  // Return true if this block is the function's entry block.\n+  bool is_entry_block () const { return !m_prev_bb; }\n+\n+  // Return true if this block is the function's exit block.\n+  bool is_exit_block () const { return !m_next_bb; }\n+\n+  // Return the underlying basic_block structure.\n+  basic_block cfg_bb () const { return m_cfg_bb; }\n+\n+  // Return the unique identifier of the underlying basic_block.  These uids\n+  // do not follow any particular order.\n+  unsigned int index () const { return m_cfg_bb->index; }\n+\n+  // Return the EBB that contains this block.\n+  ebb_info *ebb () const { return m_ebb; }\n+\n+  // Return a list of all the instructions in the block, in execution order.\n+  // The list includes the head and end instructions described above.\n+  //\n+  // Iterations over the list will pick up any new instructions that are\n+  // inserted after the iterator's current instruction.\n+  iterator_range<any_insn_iterator> all_insns () const;\n+\n+  // Like all_insns (), except that the instructions are in reverse order.\n+  //\n+  // Iterations over the list will pick up any new instructions that are\n+  // inserted before the iterator's current instruction.\n+  iterator_range<reverse_any_insn_iterator> reverse_all_insns () const;\n+\n+  // Like all_insns (), but without the debug instructions.\n+  iterator_range<nondebug_insn_iterator> nondebug_insns () const;\n+\n+  // Like reverse_all_insns (), but without the debug instructions.\n+  iterator_range<reverse_nondebug_insn_iterator>\n+    reverse_nondebug_insns () const;\n+\n+  // Like all_insns (), but without the artificial instructions.\n+  iterator_range<any_insn_iterator> real_insns () const;\n+\n+  // Like reverse_all_insns (), but without the artificial instructions.\n+  iterator_range<reverse_any_insn_iterator> reverse_real_insns () const;\n+\n+  // Like real_insns (), but without the debug instructions.\n+  iterator_range<nondebug_insn_iterator> real_nondebug_insns () const;\n+\n+  // Like reverse_real_insns (), but without the debug instructions.\n+  iterator_range<reverse_nondebug_insn_iterator>\n+    reverse_real_nondebug_insns () const;\n+\n+  // Return the instruction that holds the artificial uses and\n+  // definitions at the head of the block.  The associated RTL insn\n+  // is the block head note.\n+  //\n+  // This instruction always exists, even if it has no uses and definitions.\n+  insn_info *head_insn () const { return m_head_insn; }\n+\n+  // Return the instruction that holds the artificial uses and definitions\n+  // at the end of the block.  There is no associated RTL insn.\n+  //\n+  // This instruction always exists, even if it has no uses and definitions.\n+  insn_info *end_insn () const { return m_end_insn; }\n+\n+  // Print \"bb\" + index () to PP.\n+  void print_identifier (pretty_printer *pp) const;\n+\n+  // Print a full description of the block to PP.\n+  void print_full (pretty_printer *) const;\n+\n+private:\n+  bb_info (basic_block);\n+\n+  void set_prev_bb (bb_info *bb) { m_prev_bb = bb; }\n+  void set_next_bb (bb_info *bb) { m_next_bb = bb; }\n+  void set_cfg_bb (basic_block cfg_bb) { m_cfg_bb = cfg_bb; }\n+  void set_ebb (ebb_info *ebb) { m_ebb = ebb; }\n+  void set_head_insn (insn_info *insn) { m_head_insn = insn; }\n+  void set_end_insn (insn_info *insn) { m_end_insn = insn; }\n+\n+  // The values returned by the functions above.\n+  bb_info *m_prev_bb;\n+  bb_info *m_next_bb;\n+  basic_block m_cfg_bb;\n+  ebb_info *m_ebb;\n+  insn_info *m_head_insn;\n+  insn_info *m_end_insn;\n+};\n+\n+// Iterators for lists of basic blocks.\n+using bb_iterator = list_iterator<bb_info, &bb_info::next_bb>;\n+using reverse_bb_iterator = list_iterator<bb_info, &bb_info::prev_bb>;\n+\n+// This class collects together instructions for which has_call_clobbers ()\n+// is true, storing them in a splay tree that follows reverse postorder.\n+// Instances of the class form a singly-linked list, with one instance\n+// per predefined_function_abi.\n+class ebb_call_clobbers_info : public insn_call_clobbers_tree\n+{\n+  // Size 3 LP64 words.\n+  friend class function_info;\n+\n+public:\n+  // Return the next group in the list.\n+  ebb_call_clobbers_info *next () const { return m_next; }\n+\n+  // Return the function abi used by all the calls in the group.\n+  const predefined_function_abi *abi () const { return m_abi; }\n+\n+  // Return true if at least one call in the group should conservatively\n+  // be assumed to clobber RESOURCE.\n+  bool clobbers (resource_info) const;\n+\n+  // Print a summary of what the class describes to PP, without printing\n+  // the actual instructions.\n+  void print_summary (pretty_printer *pp) const;\n+\n+  // Print a full description of the object to PP, including the\n+  // instructions it contains.\n+  void print_full (pretty_printer *) const;\n+\n+private:\n+  ebb_call_clobbers_info (const predefined_function_abi *);\n+\n+  // The values returned by the accessors above.\n+  ebb_call_clobbers_info *m_next;\n+  const predefined_function_abi *m_abi;\n+};\n+\n+// A list of ebb_call_clobbers_infos.\n+using ebb_call_clobbers_iterator\n+  = list_iterator<ebb_call_clobbers_info, &ebb_call_clobbers_info::next>;\n+\n+// Information about an extended basic block.\n+//\n+// Each EBB has a list of phi nodes and starts with an artificial phi\n+// instruction that conceptually \"executes\" the phi nodes.  The phi\n+// nodes are independent of one another and so can be executed in any\n+// order.  The order of the phi nodes in the list is not significant.\n+//\n+// Each EBB also maintains a list of ebb_call_clobbers_info structures\n+// that describe all instructions for which has_call_clobbers () is true.\n+// See the comment above that class for details.\n+class ebb_info\n+{\n+  // Size: 5 LP64 words.\n+  friend class function_info;\n+\n+public:\n+  // Return the previous EBB in reverse postorder, or null if this EBB\n+  // contains the entry block.\n+  ebb_info *prev_ebb () const;\n+\n+  // Return the next EBB in reverse postorder, or null if this EBB contains\n+  // the exit block.\n+  ebb_info *next_ebb () const;\n+\n+  // Return the instruction that holds the EBB's phi nodes (and does\n+  // nothing else).  There is no associated RTL insn.\n+  //\n+  // This instruction always exists, even if the EBB does not currently\n+  // need any phi nodes.\n+  insn_info *phi_insn () const { return m_phi_insn; }\n+\n+  // Return the first and last blocks in the EBB.\n+  bb_info *first_bb () const { return m_first_bb; }\n+  bb_info *last_bb () const { return m_last_bb; }\n+\n+  // Return the first of the EBB's phi nodes.\n+  phi_info *first_phi () const { return m_first_phi; }\n+\n+  // Return the head of the list of ebb_call_clobbers_infos.\n+  ebb_call_clobbers_info *first_call_clobbers () const;\n+\n+  // Return the list of ebb_call_clobbers_infos.\n+  iterator_range<ebb_call_clobbers_iterator> call_clobbers () const;\n+\n+  // Return a list of the EBB's phi nodes, in arbitrary order.\n+  iterator_range<phi_iterator> phis () const;\n+\n+  // Return a list of the blocks in the EBB, in execution order.\n+  iterator_range<bb_iterator> bbs () const;\n+\n+  // Return a list of the blocks in the EBB, in reverse execution order.\n+  iterator_range<reverse_bb_iterator> reverse_bbs () const;\n+\n+  // Return a list of all the instructions in the EBB, in execution order.\n+  // The list includes phi_insn (), the head and end of each block,\n+  // and the real instructions in each block.\n+  //\n+  // Iterations over the list will pick up any new instructions that are\n+  // inserted after the iterator's current instruction.\n+  iterator_range<any_insn_iterator> all_insns () const;\n+\n+  // Like all_insns (), except that the instructions are in reverse order.\n+  //\n+  // Iterations over the list will pick up any new instructions that are\n+  // inserted before the iterator's current instruction.\n+  iterator_range<reverse_any_insn_iterator> reverse_all_insns () const;\n+\n+  // Like all_insns (), but without the debug instructions.\n+  iterator_range<nondebug_insn_iterator> nondebug_insns () const;\n+\n+  // Like reverse_all_insns (), but without the debug instructions.\n+  iterator_range<reverse_nondebug_insn_iterator>\n+    reverse_nondebug_insns () const;\n+\n+  // Return an insn_range that covers the same instructions as all_insns ().\n+  insn_range_info insn_range () const;\n+\n+  // Print \"ebb\" + first_bb ()->index () to PP.\n+  void print_identifier (pretty_printer *pp) const;\n+\n+  // Print a full description of the EBB to PP.\n+  void print_full (pretty_printer *pp) const;\n+\n+private:\n+  ebb_info (bb_info *, bb_info *);\n+\n+  void set_first_phi (phi_info *phi) { m_first_phi = phi; }\n+  void set_phi_insn (insn_info *insn) { m_phi_insn = insn; }\n+  void set_first_call_clobbers (ebb_call_clobbers_info *);\n+\n+  // The values returned by the functions above.\n+  phi_info *m_first_phi;\n+  insn_info *m_phi_insn;\n+  bb_info *m_first_bb;\n+  bb_info *m_last_bb;\n+  ebb_call_clobbers_info *m_first_call_clobbers;\n+};\n+\n+// Iterators for lists of extended basic blocks.\n+using ebb_iterator = list_iterator<ebb_info, &ebb_info::next_ebb>;\n+using reverse_ebb_iterator = list_iterator<ebb_info, &ebb_info::prev_ebb>;\n+\n+void pp_bb (pretty_printer *, const bb_info *);\n+void pp_ebb_call_clobbers (pretty_printer *, const ebb_call_clobbers_info *);\n+void pp_ebb (pretty_printer *, const ebb_info *);\n+\n+}\n+\n+void dump (FILE *, const rtl_ssa::bb_info *);\n+void dump (FILE *, const rtl_ssa::ebb_call_clobbers_info *);\n+void dump (FILE *, const rtl_ssa::ebb_info *);\n+\n+void DEBUG_FUNCTION debug (const rtl_ssa::bb_info *);\n+void DEBUG_FUNCTION debug (const rtl_ssa::ebb_call_clobbers_info *);\n+void DEBUG_FUNCTION debug (const rtl_ssa::ebb_info *);"}, {"sha": "824533076e91fe7f4479cdc7d502ab419f8d8010", "filename": "gcc/rtl-ssa/change-utils.h", "status": "added", "additions": 137, "deletions": 0, "changes": 137, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fchange-utils.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fchange-utils.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Fchange-utils.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,137 @@\n+// RTL SSA utility functions for changing instructions              -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// Return true if INSN is one of the instructions being changed by CHANGES.\n+inline bool\n+insn_is_changing (array_slice<insn_change *const> changes,\n+\t\t  const insn_info *insn)\n+{\n+  for (const insn_change *change : changes)\n+    if (change->insn () == insn)\n+      return true;\n+  return false;\n+}\n+\n+// Return a closure of insn_is_changing, for use as a predicate.\n+// This could be done using local lambdas instead, but the predicate is\n+// used often enough that having a class should be more convenient and allow\n+// reuse of template instantiations.\n+//\n+// We don't use std::bind because it would involve an indirect function call,\n+// whereas this function is used in relatively performance-critical code.\n+inline insn_is_changing_closure\n+insn_is_changing (array_slice<insn_change *const> changes)\n+{\n+  return insn_is_changing_closure (changes);\n+}\n+\n+// Restrict CHANGE.move_range so that the changed instruction can perform\n+// all its definitions and uses.  Assume that if:\n+//\n+// - CHANGE contains an access A1 of resource R;\n+// - an instruction I2 contains another access A2 to R; and\n+// - IGNORE (I2) is true\n+//\n+// then either:\n+//\n+// - A2 will be removed; or\n+// - something will ensure that A1 and A2 maintain their current order,\n+//   without this having to be enforced by CHANGE's move range.\n+//\n+// IGNORE should return true for CHANGE.insn ().\n+//\n+// Return true on success, otherwise leave CHANGE.move_range in an invalid\n+// state.\n+//\n+// This function only works correctly for instructions that remain within\n+// the same extended basic block.\n+template<typename IgnorePredicate>\n+bool\n+restrict_movement_ignoring (insn_change &change, IgnorePredicate ignore)\n+{\n+  // Uses generally lead to failure quicker, so test those first.\n+  return (restrict_movement_for_uses_ignoring (change.move_range,\n+\t\t\t\t\t       change.new_uses, ignore)\n+\t  && restrict_movement_for_defs_ignoring (change.move_range,\n+\t\t\t\t\t\t  change.new_defs, ignore)\n+\t  && canonicalize_move_range (change.move_range, change.insn ()));\n+}\n+\n+// Like restrict_movement_ignoring, but ignore only the instruction\n+// that is being changed.\n+inline bool\n+restrict_movement (insn_change &change)\n+{\n+  return restrict_movement_ignoring (change, insn_is (change.insn ()));\n+}\n+\n+using add_regno_clobber_fn = std::function<bool (insn_change &,\n+\t\t\t\t\t\t unsigned int)>;\n+bool recog_internal (insn_change &, add_regno_clobber_fn);\n+\n+// Try to recognize the new instruction pattern for CHANGE, potentially\n+// tweaking the pattern or adding extra clobbers in order to make it match.\n+//\n+// When adding an extra clobber for register R, restrict CHANGE.move_range\n+// to a range of instructions for which R is not live.  When determining\n+// whether R is live, ignore accesses made by an instruction I if\n+// IGNORE (I) is true.  The caller then assumes the responsibility\n+// of ensuring that CHANGE and I are placed in a valid order.\n+//\n+// IGNORE should return true for CHANGE.insn ().\n+//\n+// Return true on success.  Leave CHANGE unmodified on failure.\n+template<typename IgnorePredicate>\n+inline bool\n+recog_ignoring (obstack_watermark &watermark, insn_change &change,\n+\t\tIgnorePredicate ignore)\n+{\n+  auto add_regno_clobber = [&](insn_change &change, unsigned int regno)\n+    {\n+      return crtl->ssa->add_regno_clobber (watermark, change, regno, ignore);\n+    };\n+  return recog_internal (change, add_regno_clobber);\n+}\n+\n+// As for recog_ignoring, but ignore only the instruction that is being\n+// changed.\n+inline bool\n+recog (obstack_watermark &watermark, insn_change &change)\n+{\n+  return recog_ignoring (watermark, change, insn_is (change.insn ()));\n+}\n+\n+// Check whether insn costs indicate that the net effect of the changes\n+// in CHANGES is worthwhile.  Require a strict improvement if STRICT_P,\n+// otherwise allow the new instructions to be the same cost as the old\n+// instructions.\n+bool changes_are_worthwhile (array_slice<insn_change *const> changes,\n+\t\t\t     bool strict_p = false);\n+\n+// Like changes_are_worthwhile, but for a single change.\n+inline bool\n+change_is_worthwhile (insn_change &change, bool strict_p = false)\n+{\n+  insn_change *changes[] = { &change };\n+  return changes_are_worthwhile (changes, strict_p);\n+}\n+\n+}"}, {"sha": "1885a80e2e95152a98c07c9e5b92d1f222da0526", "filename": "gcc/rtl-ssa/changes.cc", "status": "added", "additions": 1025, "deletions": 0, "changes": 1025, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fchanges.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fchanges.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Fchanges.cc?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,1025 @@\n+// RTL SSA routines for changing instructions                       -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#define INCLUDE_ALGORITHM\n+#define INCLUDE_FUNCTIONAL\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"rtl.h\"\n+#include \"df.h\"\n+#include \"rtl-ssa.h\"\n+#include \"rtl-ssa/internals.inl\"\n+#include \"target.h\"\n+#include \"predict.h\"\n+#include \"memmodel.h\" // Needed by emit-rtl.h\n+#include \"emit-rtl.h\"\n+#include \"cfghooks.h\"\n+#include \"cfgrtl.h\"\n+\n+using namespace rtl_ssa;\n+\n+// See the comment above the declaration.\n+void\n+insn_change::print (pretty_printer *pp) const\n+{\n+  if (m_is_deletion)\n+    {\n+      pp_string (pp, \"deletion of \");\n+      pp_insn (pp, m_insn);\n+    }\n+  else\n+    {\n+      pp_string (pp, \"change to \");\n+      pp_insn (pp, m_insn);\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"~~~~~~~\");\n+\n+      pp_newline_and_indent (pp, 0);\n+      pp_string (pp, \"new cost: \");\n+      pp_decimal_int (pp, new_cost);\n+\n+      pp_newline_and_indent (pp, 0);\n+      pp_string (pp, \"new uses:\");\n+      pp_newline_and_indent (pp, 2);\n+      pp_accesses (pp, new_uses);\n+      pp_indentation (pp) -= 2;\n+\n+      pp_newline_and_indent (pp, 0);\n+      pp_string (pp, \"new defs:\");\n+      pp_newline_and_indent (pp, 2);\n+      pp_accesses (pp, new_defs);\n+      pp_indentation (pp) -= 2;\n+\n+      pp_newline_and_indent (pp, 0);\n+      pp_string (pp, \"first insert-after candidate: \");\n+      move_range.first->print_identifier_and_location (pp);\n+\n+      pp_newline_and_indent (pp, 0);\n+      pp_string (pp, \"last insert-after candidate: \");\n+      move_range.last->print_identifier_and_location (pp);\n+    }\n+}\n+\n+// Return a copy of access_array ACCESSES, allocating it on the\n+// temporary obstack.\n+access_array\n+function_info::temp_access_array (access_array accesses)\n+{\n+  if (accesses.empty ())\n+    return accesses;\n+\n+  gcc_assert (obstack_object_size (&m_temp_obstack) == 0);\n+  obstack_grow (&m_temp_obstack, accesses.begin (), accesses.size_bytes ());\n+  return { static_cast<access_info **> (obstack_finish (&m_temp_obstack)),\n+\t   accesses.size () };\n+}\n+\n+// See the comment above the declaration.\n+bool\n+function_info::verify_insn_changes (array_slice<insn_change *const> changes)\n+{\n+  HARD_REG_SET defined_hard_regs, clobbered_hard_regs;\n+  CLEAR_HARD_REG_SET (defined_hard_regs);\n+  CLEAR_HARD_REG_SET (clobbered_hard_regs);\n+\n+  insn_info *min_insn = m_first_insn;\n+  for (insn_change *change : changes)\n+    if (!change->is_deletion ())\n+      {\n+\t// Make sure that the changes can be kept in their current order\n+\t// while honoring all of the move ranges.\n+\tmin_insn = later_insn (min_insn, change->move_range.first);\n+\twhile (min_insn != change->insn () && !can_insert_after (min_insn))\n+\t  min_insn = min_insn->next_nondebug_insn ();\n+\tif (*min_insn > *change->move_range.last)\n+\t  {\n+\t    if (dump_file && (dump_flags & TDF_DETAILS))\n+\t      fprintf (dump_file, \"no viable insn position assignment\\n\");\n+\t    return false;\n+\t  }\n+\n+\t// If recog introduced new clobbers of a register as part of\n+\t// the matching process, make sure that they don't conflict\n+\t// with any other new definitions or uses of the register.\n+\t// (We have already checked that they don't conflict with\n+\t// unchanging definitions and uses.)\n+\tfor (use_info *use : change->new_uses)\n+\t  {\n+\t    unsigned int regno = use->regno ();\n+\t    if (HARD_REGISTER_NUM_P (regno)\n+\t\t&& TEST_HARD_REG_BIT (clobbered_hard_regs, regno))\n+\t      {\n+\t\tif (dump_file && (dump_flags & TDF_DETAILS))\n+\t\t  fprintf (dump_file, \"register %d would be clobbered\"\n+\t\t\t   \" while it is still live\\n\", regno);\n+\t\treturn false;\n+\t      }\n+\t  }\n+\tfor (def_info *def : change->new_defs)\n+\t  {\n+\t    unsigned int regno = def->regno ();\n+\t    if (HARD_REGISTER_NUM_P (regno))\n+\t      {\n+\t\tif (def->m_is_temp)\n+\t\t  {\n+\t\t    // This is a clobber introduced by recog.\n+\t\t    gcc_checking_assert (is_a<clobber_info *> (def));\n+\t\t    if (TEST_HARD_REG_BIT (defined_hard_regs, regno))\n+\t\t      {\n+\t\t\tif (dump_file && (dump_flags & TDF_DETAILS))\n+\t\t\t  fprintf (dump_file, \"conflicting definitions of\"\n+\t\t\t\t   \" register %d\\n\", regno);\n+\t\t\treturn false;\n+\t\t      }\n+\t\t    SET_HARD_REG_BIT (clobbered_hard_regs, regno);\n+\t\t  }\n+\t\telse if (is_a<set_info *> (def))\n+\t\t  {\n+\t\t    // REGNO now has a defined value.\n+\t\t    SET_HARD_REG_BIT (defined_hard_regs, regno);\n+\t\t    CLEAR_HARD_REG_BIT (clobbered_hard_regs, regno);\n+\t\t  }\n+\t      }\n+\t  }\n+      }\n+  return true;\n+}\n+\n+// See the comment above the declaration.\n+bool\n+rtl_ssa::changes_are_worthwhile (array_slice<insn_change *const> changes,\n+\t\t\t\t bool strict_p)\n+{\n+  unsigned int old_cost = 0;\n+  unsigned int new_cost = 0;\n+  for (insn_change *change : changes)\n+    {\n+      old_cost += change->old_cost ();\n+      if (!change->is_deletion ())\n+\t{\n+\t  basic_block cfg_bb = change->bb ()->cfg_bb ();\n+\t  change->new_cost = insn_cost (change->rtl (),\n+\t\t\t\t\toptimize_bb_for_speed_p (cfg_bb));\n+\t  new_cost += change->new_cost;\n+\t}\n+    }\n+  bool ok_p = (strict_p ? new_cost < old_cost : new_cost <= old_cost);\n+  if (dump_file && (dump_flags & TDF_DETAILS))\n+    {\n+      fprintf (dump_file, \"original cost\");\n+      char sep = '=';\n+      for (const insn_change *change : changes)\n+\t{\n+\t  fprintf (dump_file, \" %c %d\", sep, change->old_cost ());\n+\t  sep = '+';\n+\t}\n+      fprintf (dump_file, \", replacement cost\");\n+      sep = '=';\n+      for (const insn_change *change : changes)\n+\tif (!change->is_deletion ())\n+\t  {\n+\t    fprintf (dump_file, \" %c %d\", sep, change->new_cost);\n+\t    sep = '+';\n+\t  }\n+      fprintf (dump_file, \"; %s\\n\",\n+\t       ok_p ? \"keeping replacement\" : \"rejecting replacement\");\n+    }\n+  if (!ok_p)\n+    return false;\n+\n+  return true;\n+}\n+\n+// Update the REG_NOTES of INSN, whose pattern has just been changed.\n+static void\n+update_notes (rtx_insn *insn)\n+{\n+  for (rtx *note_ptr = &REG_NOTES (insn); *note_ptr; )\n+    {\n+      rtx note = *note_ptr;\n+      bool keep_p = true;\n+      switch (REG_NOTE_KIND (note))\n+\t{\n+\tcase REG_EQUAL:\n+\tcase REG_EQUIV:\n+\tcase REG_NOALIAS:\n+\t  keep_p = (single_set (insn) != nullptr);\n+\t  break;\n+\n+\tcase REG_UNUSED:\n+\tcase REG_DEAD:\n+\t  // These notes are stale.  We'll recompute REG_UNUSED notes\n+\t  // after the update.\n+\t  keep_p = false;\n+\t  break;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+      if (keep_p)\n+\tnote_ptr = &XEXP (*note_ptr, 1);\n+      else\n+\t{\n+\t  *note_ptr = XEXP (*note_ptr, 1);\n+\t  free_EXPR_LIST_node (note);\n+\t}\n+    }\n+}\n+\n+// Pick a location for CHANGE's instruction and return the instruction\n+// after which it should be placed.\n+static insn_info *\n+choose_insn_placement (insn_change &change)\n+{\n+  gcc_checking_assert (change.move_range);\n+\n+  insn_info *insn = change.insn ();\n+  insn_info *first = change.move_range.first;\n+  insn_info *last = change.move_range.last;\n+\n+  // Quick(ish) exit if there is only one possible choice.\n+  if (first == last)\n+    return first;\n+  if (first == insn->prev_nondebug_insn () && last == insn)\n+    return insn;\n+\n+  // For now just use the closest valid choice to the original instruction.\n+  // If the register usage has changed significantly, it might instead be\n+  // better to try to take register pressure into account.\n+  insn_info *closest = change.move_range.clamp_insn_to_range (insn);\n+  while (closest != insn && !can_insert_after (closest))\n+    closest = closest->next_nondebug_insn ();\n+  return closest;\n+}\n+\n+// Record any changes related to CHANGE that need to be queued for later.\n+void\n+function_info::possibly_queue_changes (insn_change &change)\n+{\n+  insn_info *insn = change.insn ();\n+  rtx_insn *rtl = insn->rtl ();\n+\n+  // If the instruction could previously throw, we eventually need to call\n+  // purge_dead_edges to check whether things have changed.\n+  if (find_reg_note (rtl, REG_EH_REGION, nullptr))\n+    bitmap_set_bit (m_need_to_purge_dead_edges, insn->bb ()->index ());\n+\n+  auto needs_pending_update = [&]()\n+    {\n+      // If an instruction became a no-op without the pass explicitly\n+      // deleting it, queue the deletion for later.  Removing the\n+      // instruction on the fly would require an update to all instructions\n+      // that use the result of the move, which would be a potential source\n+      // of quadraticness.  Also, definitions shouldn't disappear under\n+      // the pass's feet.\n+      if (INSN_CODE (rtl) == NOOP_MOVE_INSN_CODE)\n+\treturn true;\n+\n+      // If any jumps got turned into unconditional jumps or nops, we need\n+      // to update the CFG accordingly.\n+      if (JUMP_P (rtl)\n+\t  && (returnjump_p (rtl) || any_uncondjump_p (rtl))\n+\t  && !single_succ_p (insn->bb ()->cfg_bb ()))\n+\treturn true;\n+\n+      // If a previously conditional trap now always fires, execution\n+      // terminates at that point.\n+      rtx pattern = PATTERN (rtl);\n+      if (GET_CODE (pattern) == TRAP_IF\n+\t  && XEXP (pattern, 0) == const1_rtx)\n+\treturn true;\n+\n+      return false;\n+    };\n+\n+  if (needs_pending_update ()\n+      && bitmap_set_bit (m_queued_insn_update_uids, insn->uid ()))\n+    {\n+      gcc_assert (!change.is_deletion ());\n+      m_queued_insn_updates.safe_push (insn);\n+    }\n+}\n+\n+// Remove the instruction described by CHANGE from the underlying RTL\n+// and from the insn_info list.\n+static void\n+delete_insn (insn_change &change)\n+{\n+  insn_info *insn = change.insn ();\n+  rtx_insn *rtl = change.rtl ();\n+  if (dump_file && (dump_flags & TDF_DETAILS))\n+    fprintf (dump_file, \"deleting insn %d\\n\", insn->uid ());\n+  set_insn_deleted (rtl);\n+}\n+\n+// Move the RTL instruction associated with CHANGE so that it comes\n+// immediately after AFTER.\n+static void\n+move_insn (insn_change &change, insn_info *after)\n+{\n+  rtx_insn *rtl = change.rtl ();\n+  rtx_insn *after_rtl = after->rtl ();\n+  if (dump_file && (dump_flags & TDF_DETAILS))\n+    fprintf (dump_file, \"moving insn %d after insn %d\\n\",\n+\t     INSN_UID (rtl), INSN_UID (after_rtl));\n+\n+  // At the moment we don't support moving instructions between EBBs,\n+  // but this would be worth adding if it's useful.\n+  insn_info *insn = change.insn ();\n+  gcc_assert (after->ebb () == insn->ebb ());\n+  bb_info *bb = after->bb ();\n+  basic_block cfg_bb = bb->cfg_bb ();\n+\n+  if (insn->bb () != bb)\n+    // Force DF to mark the old block as dirty.\n+    df_insn_delete (rtl);\n+  ::remove_insn (rtl);\n+  ::add_insn_after (rtl, after_rtl, cfg_bb);\n+}\n+\n+// The instruction associated with CHANGE is being changed in-place.\n+// Update the DF information for its new pattern.\n+static void\n+update_insn_in_place (insn_change &change)\n+{\n+  insn_info *insn = change.insn ();\n+  if (dump_file && (dump_flags & TDF_DETAILS))\n+    fprintf (dump_file, \"updating insn %d in-place\\n\", insn->uid ());\n+  df_insn_rescan (change.rtl ());\n+}\n+\n+// Finalize the new list of definitions and uses in CHANGE, removing\n+// any uses and definitions that are no longer needed, and converting\n+// pending clobbers into actual definitions.\n+void\n+function_info::finalize_new_accesses (insn_change &change)\n+{\n+  insn_info *insn = change.insn ();\n+\n+  // Get a list of all the things that the instruction now references.\n+  vec_rtx_properties properties;\n+  properties.add_insn (insn->rtl (), true);\n+\n+  // Build up the new list of definitions.\n+  for (rtx_obj_reference ref : properties.refs ())\n+    if (ref.is_write ())\n+      {\n+\tdef_info *def = find_access (change.new_defs, ref.regno);\n+\tgcc_assert (def);\n+\tif (def->m_is_temp)\n+\t  {\n+\t    // At present, the only temporary instruction definitions we\n+\t    // create are clobbers, such as those added during recog.\n+\t    gcc_assert (is_a<clobber_info *> (def));\n+\t    def = allocate<clobber_info> (change.insn (), ref.regno);\n+\t  }\n+\telse if (!def->m_has_been_superceded)\n+\t  {\n+\t    // This is a second or subsequent definition.\n+\t    // See function_info::record_def for a discussion of when\n+\t    // this can happen.\n+\t    def->record_reference (ref, false);\n+\t    continue;\n+\t  }\n+\telse\n+\t  {\n+\t    def->m_has_been_superceded = false;\n+\n+\t    // Clobbers can move around, so remove them from their current\n+\t    // position and them back in their final position.\n+\t    //\n+\t    // At the moment, we don't allow sets to move relative to other\n+\t    // definitions of the same resource, so we can leave those where\n+\t    // they are.  It might be useful to relax this in future.\n+\t    // The main complication is that removing a set would potentially\n+\t    // fuse two adjoining clobber_groups, and adding the set back\n+\t    // would require the group to be split again.\n+\t    if (is_a<clobber_info *> (def))\n+\t      remove_def (def);\n+\t    else if (ref.is_reg ())\n+\t      def->set_mode (ref.mode);\n+\t    def->set_insn (insn);\n+\t  }\n+\tdef->record_reference (ref, true);\n+\tm_temp_defs.safe_push (def);\n+      }\n+\n+  // Also keep any explicitly-recorded call clobbers, which are deliberately\n+  // excluded from the vec_rtx_properties.\n+  for (def_info *def : change.new_defs)\n+    if (def->m_has_been_superceded && def->is_call_clobber ())\n+      {\n+\tdef->m_has_been_superceded = false;\n+\tdef->set_insn (insn);\n+\tm_temp_defs.safe_push (def);\n+      }\n+\n+  // Install the new list of definitions in CHANGE.\n+  sort_accesses (m_temp_defs);\n+  access_array accesses = temp_access_array (m_temp_defs);\n+  change.new_defs = def_array (accesses);\n+  m_temp_defs.truncate (0);\n+\n+  // Create temporary copies of use_infos that are already attached to\n+  // other insns, which could happen if the uses come from unchanging\n+  // insns or if they have been used by earlier changes.  Doing this\n+  // makes it easier to detect multiple reads below.\n+  auto *unshared_uses_base = XOBNEWVEC (&m_temp_obstack, access_info *,\n+\t\t\t\t\tchange.new_uses.size ());\n+  unsigned int i = 0;\n+  for (use_info *use : change.new_uses)\n+    {\n+      if (!use->m_has_been_superceded)\n+\t{\n+\t  use = allocate_temp<use_info> (insn, use->resource (), use->def ());\n+\t  use->m_has_been_superceded = true;\n+\t  use->m_is_temp = true;\n+\t}\n+      unshared_uses_base[i++] = use;\n+    }\n+  auto unshared_uses = use_array (unshared_uses_base, change.new_uses.size ());\n+\n+  // Add (possibly temporary) uses to m_temp_uses for each resource.\n+  // If there are multiple references to the same resource, aggregate\n+  // information in the modes and flags.\n+  for (rtx_obj_reference ref : properties.refs ())\n+    if (ref.is_read ())\n+      {\n+\tunsigned int regno = ref.regno;\n+\tmachine_mode mode = ref.is_reg () ? ref.mode : BLKmode;\n+\tuse_info *use = find_access (unshared_uses, ref.regno);\n+\tgcc_assert (use);\n+\tif (use->m_has_been_superceded)\n+\t  {\n+\t    // This is the first reference to the resource.\n+\t    bool is_temp = use->m_is_temp;\n+\t    *use = use_info (insn, resource_info { mode, regno }, use->def ());\n+\t    use->m_is_temp = is_temp;\n+\t    use->record_reference (ref, true);\n+\t    m_temp_uses.safe_push (use);\n+\t  }\n+\telse\n+\t  {\n+\t    // Record the mode of the largest use.  The choice is arbitrary if\n+\t    // the instruction (unusually) references the same register in two\n+\t    // different but equal-sized modes.\n+\t    if (HARD_REGISTER_NUM_P (regno)\n+\t\t&& partial_subreg_p (use->mode (), mode))\n+\t      use->set_mode (mode);\n+\t    use->record_reference (ref, false);\n+\t  }\n+      }\n+\n+  // Replace any temporary uses and definitions with real ones.\n+  for (unsigned int i = 0; i < m_temp_uses.length (); ++i)\n+    {\n+      auto *use = as_a<use_info *> (m_temp_uses[i]);\n+      if (use->m_is_temp)\n+\t{\n+\t  m_temp_uses[i] = use = allocate<use_info> (*use);\n+\t  use->m_is_temp = false;\n+\t  set_info *def = use->def ();\n+\t  // Handle cases in which the value was previously not used\n+\t  // within the block.\n+\t  if (def && def->m_is_temp)\n+\t    {\n+\t      phi_info *phi = as_a<phi_info *> (def);\n+\t      gcc_assert (phi->is_degenerate ());\n+\t      phi = create_degenerate_phi (phi->ebb (), phi->input_value (0));\n+\t      use->set_def (phi);\n+\t    }\n+\t}\n+    }\n+\n+  // Install the new list of definitions in CHANGE.\n+  sort_accesses (m_temp_uses);\n+  change.new_uses = use_array (temp_access_array (m_temp_uses));\n+  m_temp_uses.truncate (0);\n+\n+  // Record the new instruction-wide properties.\n+  insn->set_properties (properties);\n+}\n+\n+// Copy information from CHANGE to its underlying insn_info, given that\n+// the insn_info has already been placed appropriately.\n+void\n+function_info::apply_changes_to_insn (insn_change &change)\n+{\n+  insn_info *insn = change.insn ();\n+  if (change.is_deletion ())\n+    {\n+      insn->set_accesses (nullptr, 0, 0);\n+      return;\n+    }\n+\n+  // Copy the cost.\n+  insn->set_cost (change.new_cost);\n+\n+  // Add all clobbers.  Sets never moved relative to other definitions,\n+  // so are OK as-is.\n+  for (def_info *def : change.new_defs)\n+    if (is_a<clobber_info *> (def))\n+      add_def (def);\n+\n+  // Add all uses, now that their position is final.\n+  for (use_info *use : change.new_uses)\n+    add_use (use);\n+\n+  // Copy the uses and definitions.\n+  unsigned int num_defs = change.new_defs.size ();\n+  unsigned int num_uses = change.new_uses.size ();\n+  if (num_defs + num_uses <= insn->num_defs () + insn->num_uses ())\n+    insn->copy_accesses (change.new_defs, change.new_uses);\n+  else\n+    {\n+      access_array_builder builder (&m_obstack);\n+      builder.reserve (num_defs + num_uses);\n+\n+      for (def_info *def : change.new_defs)\n+\tbuilder.quick_push (def);\n+      for (use_info *use : change.new_uses)\n+\tbuilder.quick_push (use);\n+\n+      insn->set_accesses (builder.finish ().begin (), num_defs, num_uses);\n+    }\n+\n+  add_reg_unused_notes (insn);\n+}\n+\n+// Add a temporary placeholder instruction after AFTER.\n+insn_info *\n+function_info::add_placeholder_after (insn_info *after)\n+{\n+  insn_info *insn = allocate_temp<insn_info> (after->bb (), nullptr, -1);\n+  add_insn_after (insn, after);\n+  return insn;\n+}\n+\n+// See the comment above the declaration.\n+void\n+function_info::change_insns (array_slice<insn_change *> changes)\n+{\n+  auto watermark = temp_watermark ();\n+\n+  insn_info *min_insn = m_first_insn;\n+  for (insn_change *change : changes)\n+    {\n+      // Tentatively mark all the old uses and definitions for deletion.\n+      for (use_info *use : change->old_uses ())\n+\t{\n+\t  use->m_has_been_superceded = true;\n+\t  remove_use (use);\n+\t}\n+      for (def_info *def : change->old_defs ())\n+\tdef->m_has_been_superceded = true;\n+\n+      if (!change->is_deletion ())\n+\t{\n+\t  // Remove any notes that are no longer relevant.\n+\t  update_notes (change->rtl ());\n+\n+\t  // Make sure that the placement of this instruction would still\n+\t  // leave room for previous instructions.\n+\t  change->move_range = move_later_than (change->move_range, min_insn);\n+\t  if (!canonicalize_move_range (change->move_range, change->insn ()))\n+\t    // verify_insn_changes is supposed to make sure that this holds.\n+\t    gcc_unreachable ();\n+\t  min_insn = later_insn (min_insn, change->move_range.first);\n+\t}\n+    }\n+\n+  // Walk backwards through the changes, allocating specific positions\n+  // to each one.  Update the underlying RTL and its associated DF\n+  // information.\n+  insn_info *following_insn = nullptr;\n+  auto_vec<insn_info *, 16> placeholders;\n+  placeholders.safe_grow_cleared (changes.size ());\n+  for (unsigned int i = changes.size (); i-- > 0;)\n+    {\n+      insn_change &change = *changes[i];\n+      insn_info *placeholder = nullptr;\n+      possibly_queue_changes (change);\n+      if (change.is_deletion ())\n+\tdelete_insn (change);\n+      else\n+\t{\n+\t  // Make sure that this instruction comes before later ones.\n+\t  if (following_insn)\n+\t    {\n+\t      change.move_range = move_earlier_than (change.move_range,\n+\t\t\t\t\t\t     following_insn);\n+\t      if (!canonicalize_move_range (change.move_range,\n+\t\t\t\t\t    change.insn ()))\n+\t\t// verify_insn_changes is supposed to make sure that this\n+\t\t// holds.\n+\t\tgcc_unreachable ();\n+\t    }\n+\n+\t  // Decide which instruction INSN should go after.\n+\t  insn_info *after = choose_insn_placement (change);\n+\n+\t  // If INSN is moving, insert a placeholder insn_info at the\n+\t  // new location.  We can't move INSN itself yet because it\n+\t  // might still be referenced by earlier move ranges.\n+\t  insn_info *insn = change.insn ();\n+\t  if (after == insn || after == insn->prev_nondebug_insn ())\n+\t    {\n+\t      update_insn_in_place (change);\n+\t      following_insn = insn;\n+\t    }\n+\t  else\n+\t    {\n+\t      move_insn (change, after);\n+\t      placeholder = add_placeholder_after (after);\n+\t      following_insn = placeholder;\n+\t    }\n+\n+\t  // Finalize the new list of accesses for the change.  Don't install\n+\t  // them yet, so that we still have access to the old lists below.\n+\t  finalize_new_accesses (change);\n+\t}\n+      placeholders[i] = placeholder;\n+    }\n+\n+  // Remove all definitions that are no longer needed.  After the above,\n+  // such definitions should no longer have any registered users.\n+  //\n+  // In particular, this means that consumers must handle debug\n+  // instructions before removing a set.\n+  for (insn_change *change : changes)\n+    for (def_info *def : change->old_defs ())\n+      if (def->m_has_been_superceded)\n+\t{\n+\t  auto *set = dyn_cast<set_info *> (def);\n+\t  gcc_assert (!set || !set->has_any_uses ());\n+\t  remove_def (def);\n+\t}\n+\n+  // Move the insn_infos to their new locations.\n+  for (unsigned int i = 0; i < changes.size (); ++i)\n+    {\n+      insn_change &change = *changes[i];\n+      insn_info *insn = change.insn ();\n+      if (change.is_deletion ())\n+\tremove_insn (insn);\n+      else if (insn_info *placeholder = placeholders[i])\n+\t{\n+\t  // Check if earlier movements turned a move into a no-op.\n+\t  if (placeholder->prev_nondebug_insn () == insn\n+\t      || placeholder->next_nondebug_insn () == insn)\n+\t    {\n+\t      remove_insn (placeholder);\n+\t      placeholders[i] = nullptr;\n+\t    }\n+\t  else\n+\t    {\n+\t      // Remove the placeholder first so that we have a wider range of\n+\t      // program points when inserting INSN.\n+\t      insn_info *after = placeholder->prev_any_insn ();\n+\t      remove_insn (insn);\n+\t      remove_insn (placeholder);\n+\t      insn->set_bb (after->bb ());\n+\t      add_insn_after (insn, after);\n+\t    }\n+\t}\n+    }\n+\n+  // Finally apply the changes to the underlying insn_infos.\n+  for (insn_change *change : changes)\n+    apply_changes_to_insn (*change);\n+}\n+\n+// See the comment above the declaration.\n+void\n+function_info::change_insn (insn_change &change)\n+{\n+  insn_change *changes[] = { &change };\n+  return change_insns (changes);\n+}\n+\n+// Try to adjust CHANGE so that its pattern can include clobber rtx CLOBBER.\n+// Return true on success.\n+//\n+// ADD_REGNO_CLOBBER is a specialization of function_info::add_regno_clobber\n+// for a specific caller-provided predicate.\n+static bool\n+add_clobber (insn_change &change, add_regno_clobber_fn add_regno_clobber,\n+\t     rtx clobber)\n+{\n+  rtx pat = PATTERN (change.rtl ());\n+  gcc_assert (GET_CODE (clobber) == CLOBBER);\n+  rtx dest = XEXP (clobber, 0);\n+  if (GET_CODE (dest) == SCRATCH)\n+    {\n+      if (reload_completed)\n+\t{\n+\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t    {\n+\t      // ??? Maybe we could try to do some RA here?\n+\t      fprintf (dump_file, \"instruction requires a scratch\"\n+\t\t       \" after reload:\\n\");\n+\t      print_rtl_single (dump_file, pat);\n+\t    }\n+\t  return false;\n+\t}\n+      return true;\n+    }\n+\n+  gcc_assert (REG_P (dest));\n+  for (unsigned int regno = REGNO (dest); regno != END_REGNO (dest); ++regno)\n+    if (!add_regno_clobber (change, regno))\n+      {\n+\tif (dump_file && (dump_flags & TDF_DETAILS))\n+\t  {\n+\t    fprintf (dump_file, \"cannot clobber live register %d in:\\n\",\n+\t\t     regno);\n+\t    print_rtl_single (dump_file, pat);\n+\t  }\n+\treturn false;\n+      }\n+  return true;\n+}\n+\n+// Try to recognize the new form of the insn associated with CHANGE,\n+// adding any clobbers that are necessary to make the instruction match\n+// an .md pattern.  Return true on success.\n+//\n+// ADD_REGNO_CLOBBER is a specialization of function_info::add_regno_clobber\n+// for a specific caller-provided predicate.\n+static bool\n+recog_level2 (insn_change &change, add_regno_clobber_fn add_regno_clobber)\n+{\n+  insn_change_watermark insn_watermark;\n+  rtx_insn *rtl = change.rtl ();\n+  rtx pat = PATTERN (rtl);\n+  int num_clobbers = 0;\n+  int icode = -1;\n+  bool asm_p = asm_noperands (pat) >= 0;\n+  if (asm_p)\n+    {\n+      if (!check_asm_operands (pat))\n+\t{\n+\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t    {\n+\t      fprintf (dump_file, \"failed to match this asm instruction:\\n\");\n+\t      print_rtl_single (dump_file, pat);\n+\t    }\n+\t  return false;\n+\t}\n+    }\n+  else if (noop_move_p (rtl))\n+    {\n+      INSN_CODE (rtl) = NOOP_MOVE_INSN_CODE;\n+      if (dump_file && (dump_flags & TDF_DETAILS))\n+\t{\n+\t  fprintf (dump_file, \"instruction becomes a no-op:\\n\");\n+\t  print_rtl_single (dump_file, pat);\n+\t}\n+      insn_watermark.keep ();\n+      return true;\n+    }\n+  else\n+    {\n+      icode = ::recog (pat, rtl, &num_clobbers);\n+      if (icode < 0)\n+\t{\n+\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t    {\n+\t      fprintf (dump_file, \"failed to match this instruction:\\n\");\n+\t      print_rtl_single (dump_file, pat);\n+\t    }\n+\t  return false;\n+\t}\n+    }\n+\n+  auto prev_new_defs = change.new_defs;\n+  auto prev_move_range = change.move_range;\n+  if (num_clobbers > 0)\n+    {\n+      // ??? It would be good to have a way of recycling the rtxes on failure,\n+      // but any attempt to cache old PARALLELs would at best be a half\n+      // measure, since add_clobbers would still generate fresh clobbers\n+      // each time.  It would be better to have a more general recycling\n+      // mechanism that all rtx passes can use.\n+      rtvec newvec;\n+      int oldlen;\n+      if (GET_CODE (pat) == PARALLEL)\n+\t{\n+\t  oldlen = XVECLEN (pat, 0);\n+\t  newvec = rtvec_alloc (num_clobbers + oldlen);\n+\t  for (int i = 0; i < oldlen; ++i)\n+\t    RTVEC_ELT (newvec, i) = XVECEXP (pat, 0, i);\n+\t}\n+      else\n+\t{\n+\t  oldlen = 1;\n+\t  newvec = rtvec_alloc (num_clobbers + oldlen);\n+\t  RTVEC_ELT (newvec, 0) = pat;\n+\t}\n+      rtx newpat = gen_rtx_PARALLEL (VOIDmode, newvec);\n+      add_clobbers (newpat, icode);\n+      validate_change (rtl, &PATTERN (rtl), newpat, true);\n+      for (int i = 0; i < num_clobbers; ++i)\n+\tif (!add_clobber (change, add_regno_clobber,\n+\t\t\t  XVECEXP (newpat, 0, oldlen + i)))\n+\t  {\n+\t    change.new_defs = prev_new_defs;\n+\t    change.move_range = prev_move_range;\n+\t    return false;\n+\t  }\n+\n+      pat = newpat;\n+    }\n+\n+  INSN_CODE (rtl) = icode;\n+  if (reload_completed)\n+    {\n+      extract_insn (rtl);\n+      if (!constrain_operands (1, get_preferred_alternatives (rtl)))\n+\t{\n+\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t    {\n+\t      if (asm_p)\n+\t\tfprintf (dump_file, \"asm does not match its constraints:\\n\");\n+\t      else if (const char *name = get_insn_name (icode))\n+\t\tfprintf (dump_file, \"instruction does not match the\"\n+\t\t\t \" constraints for %s:\\n\", name);\n+\t      else\n+\t\tfprintf (dump_file, \"instruction does not match its\"\n+\t\t\t \" constraints:\\n\");\n+\t      print_rtl_single (dump_file, pat);\n+\t    }\n+\t  change.new_defs = prev_new_defs;\n+\t  change.move_range = prev_move_range;\n+\t  return false;\n+\t}\n+    }\n+\n+  if (dump_file && (dump_flags & TDF_DETAILS))\n+    {\n+      const char *name;\n+      if (!asm_p && (name = get_insn_name (icode)))\n+\tfprintf (dump_file, \"successfully matched this instruction \"\n+\t\t \"to %s:\\n\", name);\n+      else\n+\tfprintf (dump_file, \"successfully matched this instruction:\\n\");\n+      print_rtl_single (dump_file, pat);\n+    }\n+\n+  insn_watermark.keep ();\n+  return true;\n+}\n+\n+// Try to recognize the new form of the insn associated with CHANGE,\n+// adding and removing clobbers as necessary to make the instruction\n+// match an .md pattern.  Return true on success, otherwise leave\n+// CHANGE as it was on entry.\n+//\n+// ADD_REGNO_CLOBBER is a specialization of function_info::add_regno_clobber\n+// for a specific caller-provided predicate.\n+bool\n+rtl_ssa::recog_internal (insn_change &change,\n+\t\t\t add_regno_clobber_fn add_regno_clobber)\n+{\n+  // Accept all changes to debug instructions.\n+  insn_info *insn = change.insn ();\n+  if (insn->is_debug_insn ())\n+    return true;\n+\n+  rtx_insn *rtl = insn->rtl ();\n+  rtx pat = PATTERN (rtl);\n+  if (GET_CODE (pat) == PARALLEL && asm_noperands (pat) < 0)\n+    {\n+      // Try to remove trailing (clobber (scratch)) rtxes, since the new form\n+      // of the instruction might not need those scratches.  recog will add\n+      // back any that are needed.\n+      int len = XVECLEN (pat, 0);\n+      int new_len = len;\n+      while (new_len > 0\n+\t     && GET_CODE (XVECEXP (pat, 0, new_len - 1)) == CLOBBER\n+\t     && GET_CODE (XEXP (XVECEXP (pat, 0, new_len - 1), 0)) == SCRATCH)\n+\tnew_len -= 1;\n+\n+      int old_num_changes = num_validated_changes ();\n+      validate_change_xveclen (rtl, &PATTERN (rtl), new_len, true);\n+      if (recog_level2 (change, add_regno_clobber))\n+\treturn true;\n+      cancel_changes (old_num_changes);\n+\n+      // Try to remove all trailing clobbers.  For example, a pattern that\n+      // used to clobber the flags might no longer need to do so.\n+      int prev_len = new_len;\n+      while (new_len > 0\n+\t     && GET_CODE (XVECEXP (pat, 0, new_len - 1)) == CLOBBER)\n+\tnew_len -= 1;\n+      if (new_len != prev_len)\n+\t{\n+\t  validate_change_xveclen (rtl, &PATTERN (rtl), new_len, true);\n+\t  if (recog_level2 (change, add_regno_clobber))\n+\t    return true;\n+\t  cancel_changes (old_num_changes);\n+\t}\n+      return false;\n+    }\n+\n+  return recog_level2 (change, add_regno_clobber);\n+}\n+\n+// See the comment above the declaration.\n+bool\n+function_info::perform_pending_updates ()\n+{\n+  bool changed_cfg = false;\n+  bool changed_jumps = false;\n+  for (insn_info *insn : m_queued_insn_updates)\n+    {\n+      rtx_insn *rtl = insn->rtl ();\n+      if (JUMP_P (rtl))\n+\t{\n+\t  if (INSN_CODE (rtl) == NOOP_MOVE_INSN_CODE)\n+\t    {\n+\t      ::delete_insn (rtl);\n+\t      bitmap_set_bit (m_need_to_purge_dead_edges,\n+\t\t\t      insn->bb ()->index ());\n+\t    }\n+\t  else if (returnjump_p (rtl) || any_uncondjump_p (rtl))\n+\t    {\n+\t      mark_jump_label (PATTERN (rtl), rtl, 0);\n+\t      update_cfg_for_uncondjump (rtl);\n+\t      changed_cfg = true;\n+\t      changed_jumps = true;\n+\t    }\n+\t}\n+      else if (INSN_CODE (rtl) == NOOP_MOVE_INSN_CODE)\n+\t::delete_insn (rtl);\n+      else\n+\t{\n+\t  rtx pattern = PATTERN (rtl);\n+\t  if (GET_CODE (pattern) == TRAP_IF\n+\t      && XEXP (pattern, 0) == const1_rtx)\n+\t    {\n+\t      remove_edge (split_block (BLOCK_FOR_INSN (rtl), rtl));\n+\t      emit_barrier_after_bb (BLOCK_FOR_INSN (rtl));\n+\t      changed_cfg = true;\n+\t    }\n+\t}\n+    }\n+\n+  unsigned int index;\n+  bitmap_iterator bi;\n+  EXECUTE_IF_SET_IN_BITMAP (m_need_to_purge_dead_edges, 0, index, bi)\n+    if (purge_dead_edges (BASIC_BLOCK_FOR_FN (m_fn, index)))\n+      changed_cfg = true;\n+\n+  if (changed_jumps)\n+    // This uses its own timevar internally, so we don't need to push\n+    // one ourselves.\n+    rebuild_jump_labels (get_insns ());\n+\n+  bitmap_clear (m_need_to_purge_dead_edges);\n+  bitmap_clear (m_queued_insn_update_uids);\n+  m_queued_insn_updates.truncate (0);\n+\n+  if (changed_cfg)\n+    {\n+      free_dominance_info (CDI_DOMINATORS);\n+      free_dominance_info (CDI_POST_DOMINATORS);\n+    }\n+\n+  return changed_cfg;\n+}\n+\n+// Print a description of CHANGE to PP.\n+void\n+rtl_ssa::pp_insn_change (pretty_printer *pp, const insn_change &change)\n+{\n+  change.print (pp);\n+}\n+\n+// Print a description of CHANGE to FILE.\n+void\n+dump (FILE *file, const insn_change &change)\n+{\n+  dump_using (file, pp_insn_change, change);\n+}\n+\n+// Debug interface to the dump routine above.\n+void debug (const insn_change &x) { dump (stderr, x); }"}, {"sha": "308c5edc4094a551a49b896064c90379f48982d2", "filename": "gcc/rtl-ssa/changes.h", "status": "added", "additions": 118, "deletions": 0, "changes": 118, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fchanges.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fchanges.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Fchanges.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,118 @@\n+// RTL SSA classes related to changing instructions                 -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// A class that describes a change that we're considering making to an\n+// instruction.  There are three choices:\n+//\n+// (1) delete the instruction\n+// (2) replace the instruction with a new instruction in-place\n+// (3) replace the instruction with a new instruction at a different location\n+//\n+// Anything related to the \"new instruction\" is irrelevant for (1).\n+//\n+// The class doesn't actually change anything itself, it simply records\n+// something that we might do.\n+class insn_change\n+{\n+public:\n+  enum delete_action { DELETE };\n+\n+  // Construct a possible change to INSN.\n+  insn_change (insn_info *insn);\n+\n+  // Construct a possible deletion of INSN.\n+  insn_change (insn_info *insn, delete_action);\n+\n+  // The instruction that we would change.\n+  insn_info *insn () const { return m_insn; }\n+\n+  // The rtx_insn of the instruction that we would change.\n+  rtx_insn *rtl () const { return m_insn->rtl (); }\n+\n+  // The basic block that contains insn ().\n+  bb_info *bb () const { return m_insn->bb (); }\n+\n+  // The extended basic block that contains insn ().\n+  ebb_info *ebb () const { return m_insn->ebb (); }\n+\n+  // The uid of the instruction that we would change.\n+  unsigned int insn_uid () const { return m_insn->uid (); }\n+\n+  // The list of things that the original instruction defined and used.\n+  def_array old_defs () const { return m_insn->defs (); }\n+  use_array old_uses () const { return m_insn->uses (); }\n+\n+  // The cost of the original instruction, as calculated by the target.\n+  unsigned int old_cost () const { return m_insn->cost (); }\n+\n+  // Return true if the original instruction would simply be deleted,\n+  // rather than being replaced by a new instruction.\n+  bool is_deletion () const { return m_is_deletion; }\n+\n+  // Print a description of the change to PP.\n+  void print (pretty_printer *pp) const;\n+\n+  // Return an insn_change for deleting INSN.\n+  static insn_change delete_insn (insn_info *insn) { return { insn, DELETE }; }\n+\n+private:\n+  // The value returned by insn ().\n+  insn_info *m_insn;\n+\n+public:\n+  // The list of things that the new instruction would define and use.\n+  def_array new_defs;\n+  use_array new_uses;\n+\n+  // The range of instructions after which the instruction could be placed.\n+  // The range can include INSN itself: placing the instruction after either\n+  // INSN or INSN->prev_nondebug_insn () is equivalent to not moving the\n+  // instruction.\n+  insn_range_info move_range;\n+\n+  // The cost that the new instruction would have, as calculated by the target.\n+  unsigned int new_cost;\n+\n+private:\n+  // The value returned by is_deletion ().\n+  bool m_is_deletion;\n+};\n+\n+// A class that represents a closure of the two-argument form of\n+// insn_is_changing.  See the comment above the one-argument form\n+// for details.\n+class insn_is_changing_closure\n+{\n+public:\n+  insn_is_changing_closure (array_slice<insn_change *const> changes);\n+  bool operator() (const insn_info *) const;\n+\n+private:\n+  array_slice<insn_change *const> m_changes;\n+};\n+\n+void pp_insn_change (pretty_printer *, const insn_change &);\n+\n+}\n+\n+void dump (FILE *, const rtl_ssa::insn_change &);\n+\n+void DEBUG_FUNCTION debug (const rtl_ssa::insn_change &);"}, {"sha": "50595ac8ed61b2e08594053c38a0b84afb739f9b", "filename": "gcc/rtl-ssa/functions.cc", "status": "added", "additions": 325, "deletions": 0, "changes": 325, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Ffunctions.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Ffunctions.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Ffunctions.cc?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,325 @@\n+// Implementation of function-related RTL SSA functions             -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#define INCLUDE_ALGORITHM\n+#define INCLUDE_FUNCTIONAL\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"rtl.h\"\n+#include \"df.h\"\n+#include \"rtl-ssa.h\"\n+#include \"rtl-ssa/internals.inl\"\n+\n+using namespace rtl_ssa;\n+\n+function_info::function_info (function *fn)\n+  : m_fn (fn)\n+{\n+  // Force the alignment to be obstack_alignment.  Everything else is normal.\n+  obstack_specify_allocation (&m_obstack, OBSTACK_CHUNK_SIZE,\n+\t\t\t      obstack_alignment, obstack_chunk_alloc,\n+\t\t\t      obstack_chunk_free);\n+  obstack_specify_allocation (&m_temp_obstack, OBSTACK_CHUNK_SIZE,\n+\t\t\t      obstack_alignment, obstack_chunk_alloc,\n+\t\t\t      obstack_chunk_free);\n+\n+  // Record the start of the obstacks.\n+  m_obstack_start = XOBNEWVAR (&m_obstack, char, 0);\n+  m_temp_obstack_start = XOBNEWVAR (&m_temp_obstack, char, 0);\n+\n+  init_function_data ();\n+  process_all_blocks ();\n+  simplify_phis ();\n+}\n+\n+function_info::~function_info ()\n+{\n+  // Anything using the temporary obstack should free it afterwards,\n+  // preferably via temp_watermark ().\n+  gcc_assert (XOBNEWVAR (&m_temp_obstack, char, 0) == m_temp_obstack_start);\n+\n+  obstack_free (&m_temp_obstack, nullptr);\n+  obstack_free (&m_obstack, nullptr);\n+}\n+\n+// See the comment above the declaration.\n+void\n+function_info::print (pretty_printer *pp) const\n+{\n+  pp_string (pp, \"Function: \");\n+  pp_string (pp, function_name (m_fn));\n+  for (ebb_info *ebb : ebbs ())\n+    {\n+      pp_newline (pp);\n+      pp_newline_and_indent (pp, 0);\n+      pp_ebb (pp, ebb);\n+    }\n+}\n+\n+// Calculate m_potential_phi_regs.\n+void\n+function_info::calculate_potential_phi_regs ()\n+{\n+  auto *lr_info = DF_LR_BB_INFO (ENTRY_BLOCK_PTR_FOR_FN (m_fn));\n+  for (unsigned int regno = 0; regno < m_num_regs; ++regno)\n+    if (regno >= DF_REG_SIZE (DF)\n+\t// Exclude registers that have a single definition that dominates\n+\t// all uses.  If the definition does not dominate all uses,\n+\t// the register will be exposed upwards to the entry block but\n+\t// will not be defined by the entry block.\n+\t|| DF_REG_DEF_COUNT (regno) > 1\n+\t|| (!bitmap_bit_p (&lr_info->def, regno)\n+\t    && bitmap_bit_p (&lr_info->out, regno)))\n+      bitmap_set_bit (m_potential_phi_regs, regno);\n+}\n+\n+// Initialize all member variables in preparation for (re)building\n+// SSA form from scratch.\n+void\n+function_info::init_function_data ()\n+{\n+  m_next_artificial_uid = -1;\n+  m_next_phi_uid = 0;\n+  m_num_regs = max_reg_num ();\n+  m_defs.safe_grow_cleared (m_num_regs + 1);\n+  m_bbs.safe_grow_cleared (last_basic_block_for_fn (m_fn));\n+  m_first_bb = nullptr;\n+  m_last_bb = nullptr;\n+  m_first_insn = nullptr;\n+  m_last_insn = nullptr;\n+  m_last_nondebug_insn = nullptr;\n+  m_free_phis = nullptr;\n+\n+  calculate_potential_phi_regs ();\n+}\n+\n+// The initial phase of the phi simplification process.  The cumulative\n+// effect of the initial phase is to set up ASSUMED_VALUES such that,\n+// for a phi P with uid ID:\n+//\n+// - if we think all inputs to P have the same value, ASSUMED_VALUES[ID]\n+//   is that value\n+//\n+// - otherwise, ASSUMED_VALUES[ID] is P.\n+//\n+// This has already been done for phis with a lower uid than PHI,\n+// initially making optimistic assumptions about backedge inputs.\n+// Now do the same for PHI.  If this might invalidate any assumptions\n+// made for earlier phis, add the uids of those phis to WORKLIST.\n+void\n+function_info::simplify_phi_setup (phi_info *phi, set_info **assumed_values,\n+\t\t\t\t   bitmap worklist)\n+{\n+  // If all non-backedge inputs have the same value, set NEW_VALUE\n+  // to that value.  Otherwise set NEW_VALUE to PHI, to indicate\n+  // that PHI cannot be simplified.\n+  unsigned int phi_uid = phi->uid ();\n+  bool is_first_input = true;\n+  set_info *new_value = nullptr;\n+  machine_mode phi_mode = phi->mode ();\n+  for (use_info *input : phi->inputs ())\n+    {\n+      set_info *def = input->def ();\n+\n+      if (auto *input_phi = safe_dyn_cast<phi_info *> (def))\n+\t{\n+\t  // Ignore backedges for now.\n+\t  unsigned int input_phi_uid = input_phi->uid ();\n+\t  if (phi_uid <= input_phi_uid)\n+\t    continue;\n+\n+\t  def = assumed_values[input_phi_uid];\n+\t}\n+\n+      // Compare this definition with previous ones.\n+      if (is_first_input)\n+\t{\n+\t  new_value = def;\n+\t  is_first_input = false;\n+\t}\n+      else if (new_value != def)\n+\tnew_value = phi;\n+\n+      // If the input has a known mode (i.e. not BLKmode), make sure\n+      // that the phi's mode is at least as large.\n+      if (def)\n+\tphi_mode = combine_modes (phi_mode, def->mode ());\n+    }\n+  if (phi->mode () != phi_mode)\n+    phi->set_mode (phi_mode);\n+\n+  // Since we use a reverse postorder traversal, no phi can consist\n+  // entirely of backedges.\n+  gcc_checking_assert (!is_first_input);\n+  assumed_values[phi_uid] = new_value;\n+\n+  // See whether any assumptions for earlier phis are now invalid.\n+  simplify_phi_propagate (phi, assumed_values, nullptr, worklist);\n+}\n+\n+// The propagation phase of the phi simplification process, with\n+// ASSUMED_VALUES as described above simplify_phi_setup.  Iteratively\n+// update the phis that use PHI based on PHI's entry in ASSUMED_VALUES.\n+// If CURR_WORKLIST is null, consider only phi uses with a lower uid\n+// than PHI, otherwise consider all phi uses.\n+//\n+// If a phi with a higher uid than PHI needs updating, add its uid to\n+// CURR_WORKLIST; if a phi with a lower uid than PHI needs updating,\n+// add its uid to NEXT_WORKLIST.\n+void\n+function_info::simplify_phi_propagate (phi_info *phi,\n+\t\t\t\t       set_info **assumed_values,\n+\t\t\t\t       bitmap curr_worklist,\n+\t\t\t\t       bitmap next_worklist)\n+{\n+  // Go through each phi user of PHI to see whether it needs updating.\n+  unsigned int phi_uid = phi->uid ();\n+  machine_mode phi_mode = phi->mode ();\n+  set_info *phi_value = assumed_values[phi_uid];\n+  for (use_info *use : phi->phi_uses ())\n+    {\n+      phi_info *user_phi = use->phi ();\n+\n+      // Propagate the phi's new mode to all phi users.  Insn uses should\n+      // not be updated, since their modes reflect a property of the insns\n+      // rather than the phi.\n+      if (use->mode () != phi_mode)\n+\tuse->set_mode (phi_mode);\n+\n+      if (user_phi == phi)\n+\tcontinue;\n+\n+      // If this is a phi we should be looking at, see whether it needs\n+      // an update.\n+      unsigned int user_phi_uid = user_phi->uid ();\n+      if (user_phi_uid < phi_uid || curr_worklist)\n+\t{\n+\t  bool needs_update = false;\n+\n+\t  // Make sure that USER_PHI's mode is at least as big as PHI_MODE.\n+\t  machine_mode user_phi_mode = user_phi->mode ();\n+\t  machine_mode new_mode = combine_modes (user_phi_mode, phi_mode);\n+\t  if (user_phi_mode != new_mode)\n+\t    {\n+\t      user_phi->set_mode (new_mode);\n+\t      needs_update = true;\n+\t    }\n+\n+\t  // If USER_PHI optimistically assumed an incorrect value,\n+\t  // adjust it now.\n+\t  if (assumed_values[user_phi_uid] != user_phi\n+\t      && assumed_values[user_phi_uid] != phi_value)\n+\t    {\n+\t      assumed_values[user_phi_uid] = user_phi;\n+\t      needs_update = true;\n+\t    }\n+\n+\t  if (needs_update)\n+\t    {\n+\t      if (user_phi_uid < phi_uid)\n+\t\tbitmap_set_bit (next_worklist, user_phi_uid);\n+\t      else\n+\t\tbitmap_set_bit (curr_worklist, user_phi_uid);\n+\t    }\n+\t}\n+    }\n+}\n+\n+// Update the modes of all phis so that they are at least as big as\n+// all inputs.  Remove any non-degenerate phis whose inputs are all equal.\n+void\n+function_info::simplify_phis ()\n+{\n+  auto temps = temp_watermark ();\n+\n+  // See the comment above simplify_phi_setup for details about this array.\n+  auto *assumed_values = XOBNEWVEC (&m_temp_obstack, set_info *,\n+\t\t\t\t    m_next_phi_uid);\n+\n+  // An array of all phis, indexed by uid.\n+  auto *phis = XOBNEWVEC (&m_temp_obstack, phi_info *, m_next_phi_uid);\n+\n+  // Which phi uids are actually in use.\n+  auto_sbitmap valid_phi_uids (m_next_phi_uid);\n+  bitmap_clear (valid_phi_uids);\n+\n+  // Bitmaps used for the main double-queue propagation phase.\n+  auto_bitmap worklist1;\n+  auto_bitmap worklist2;\n+  bitmap curr_worklist = worklist1;\n+  bitmap next_worklist = worklist2;\n+\n+  // Perform the set-up phase; see simplify_phi_setup for details.\n+  for (ebb_info *ebb : ebbs ())\n+    for (phi_info *phi : ebb->phis ())\n+      {\n+\tbitmap_set_bit (valid_phi_uids, phi->uid ());\n+\tphis[phi->uid ()] = phi;\n+\tsimplify_phi_setup (phi, assumed_values, curr_worklist);\n+      }\n+\n+  // Iteratively process any phis that need updating; see\n+  // simplify_phi_propagate for details.  Using a double queue\n+  // should reduce the number of times that any given phi node\n+  // needs to be revisited.\n+  while (!bitmap_empty_p (curr_worklist))\n+    {\n+      do\n+\t{\n+\t  unsigned int uid = bitmap_first_set_bit (curr_worklist);\n+\t  bitmap_clear_bit (curr_worklist, uid);\n+\t  simplify_phi_propagate (phis[uid], assumed_values,\n+\t\t\t\t  curr_worklist, next_worklist);\n+\t}\n+      while (!bitmap_empty_p (curr_worklist));\n+      std::swap (next_worklist, curr_worklist);\n+    }\n+\n+  // Make sure that assumed_values is a transitive closure.  This ensures\n+  // that each use_info is only updated once.\n+  if (flag_checking)\n+    for (unsigned int i = 0; i < m_next_phi_uid; ++i)\n+      if (bitmap_bit_p (valid_phi_uids, i))\n+\tif (auto *new_phi = safe_dyn_cast<phi_info *> (assumed_values[i]))\n+\t  gcc_assert (assumed_values[new_phi->uid ()] == new_phi);\n+\n+  // Update any phis that turned out to be equivalent to a single input.\n+  for (unsigned int i = 0; i < m_next_phi_uid; ++i)\n+    if (bitmap_bit_p (valid_phi_uids, i) && phis[i] != assumed_values[i])\n+      replace_phi (phis[i], assumed_values[i]);\n+}\n+\n+// Print a description of FUNCTION to PP.\n+void\n+rtl_ssa::pp_function (pretty_printer *pp, const function_info *function)\n+{\n+  function->print (pp);\n+}\n+\n+// Print a description of FUNCTION to FILE.\n+void\n+dump (FILE *file, const function_info *function)\n+{\n+  dump_using (file, pp_function, function);\n+}\n+\n+// Debug interface to the dump routine above.\n+void debug (const function_info *x) { dump (stderr, x); }"}, {"sha": "b09d50e86b03e68676bf2da04c82a3a6bba5362a", "filename": "gcc/rtl-ssa/functions.h", "status": "added", "additions": 433, "deletions": 0, "changes": 433, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Ffunctions.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Ffunctions.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Ffunctions.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,433 @@\n+// Function-related RTL SSA classes                                 -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// SSA-related information about a function.  It contains three levels\n+// of information, each in reverse postorder:\n+//\n+// - a list of extended basic blocks\n+// - a list of basic blocks\n+// - a list of instructions\n+//\n+// It also maintains a list of definitions of memory, and a list of\n+// definitions of each register.\n+//\n+// See doc/rtl.texi for more details about the way this information\n+// is organized and how changes to it are made.\n+class function_info\n+{\n+  // The default obstack alignment takes long double into account.\n+  // Since we have no use for that here, and since we allocate many\n+  // relatively small objects, it's better to specify an alignment\n+  // explicitly.  The allocation routines assert that the alignment\n+  // is enough for the objects being allocated.\n+  //\n+  // Because various structures use pointer_mux, we need at least 2 bytes\n+  // of alignment.\n+  static const size_t obstack_alignment = sizeof (void *);\n+\n+public:\n+  // Construct SSA form for function FN.\n+  function_info (function *fn);\n+  ~function_info ();\n+\n+  // Return a list of all the extended basic blocks in the function, in reverse\n+  // postorder.  The list includes the entry and exit blocks.\n+  iterator_range<ebb_iterator> ebbs () const;\n+\n+  // Like ebbs (), but in the reverse order.\n+  iterator_range<reverse_ebb_iterator> reverse_ebbs () const;\n+\n+  // Return a list of all the basic blocks in the function, in reverse\n+  // postorder.  The list includes the entry and exit blocks.\n+  iterator_range<bb_iterator> bbs () const;\n+\n+  // Like bbs (), but in the reverse order.\n+  iterator_range<reverse_bb_iterator> reverse_bbs () const;\n+\n+  // Return the SSA information for the basic block with index INDEX.\n+  bb_info *bb (unsigned int index) const { return m_bbs[index]; }\n+\n+  // Return the SSA information for CFG_BB.\n+  bb_info *bb (basic_block cfg_bb) const { return m_bbs[cfg_bb->index]; }\n+\n+  // Return a list of all the instructions in the function, in reverse\n+  // postorder.  The list includes both real and artificial instructions.\n+  //\n+  // Iterations over the list will pick up any new instructions that are\n+  // inserted after the iterator's current instruction.\n+  iterator_range<any_insn_iterator> all_insns () const;\n+\n+  // Like all_insns (), but in the reverse order.\n+  //\n+  // Iterations over the list will pick up any new instructions that are\n+  // inserted before the iterator's current instruction.\n+  iterator_range<reverse_any_insn_iterator> reverse_all_insns () const;\n+\n+  // Like all_insns (), but without the debug instructions.\n+  iterator_range<nondebug_insn_iterator> nondebug_insns () const;\n+\n+  // Like reverse_all_insns (), but without the debug instructions.\n+  iterator_range<reverse_nondebug_insn_iterator>\n+    reverse_nondebug_insns () const;\n+\n+  // Return the first and last instructions in insns ().\n+  insn_info *first_insn () const { return m_first_insn; }\n+  insn_info *last_insn () const { return m_last_insn; }\n+\n+  // Return a list of all definitions of memory, in reverse postorder.\n+  // This includes both real stores by instructions and artificial\n+  // definitions by things like phi nodes.\n+  iterator_range<def_iterator> mem_defs () const;\n+\n+  // Return a list of all definitions of register REGNO, in reverse postorder.\n+  // This includes both real stores by instructions and artificial\n+  // definitions by things like phi nodes.\n+  iterator_range<def_iterator> ref_defs (unsigned int regno) const;\n+\n+  // Check if all uses of register REGNO are either unconditionally undefined\n+  // or use the same single dominating definition.  Return the definition\n+  // if so, otherwise return null.\n+  set_info *single_dominating_def (unsigned int regno) const;\n+\n+  // Look for a definition of RESOURCE at INSN.  Return the result of the\n+  // search as a def_lookup; see the comments there for more details.\n+  def_lookup find_def (resource_info resource, insn_info *insn);\n+\n+  // Return an RAII object that owns all temporary RTL SSA memory\n+  // allocated during a change attempt.  The object should remain in\n+  // scope until the change has been aborted or successfully completed.\n+  obstack_watermark new_change_attempt () { return &m_temp_obstack; }\n+\n+  // Make a best attempt to check whether the values used by USES are\n+  // available on entry to BB, without solving a full dataflow problem.\n+  // If all the values are already live on entry to BB or can be made\n+  // available there, return a use_array that describes the uses as\n+  // if they occured at the start of BB.  These uses are purely temporary,\n+  // and will not become permanent unless applied using change_insns.\n+  //\n+  // If the operation fails, return an invalid use_array.\n+  //\n+  // WATERMARK is a watermark returned by new_change_attempt ().\n+  use_array make_uses_available (obstack_watermark &watermark,\n+\t\t\t\t use_array uses, bb_info *bb);\n+\n+  // If CHANGE doesn't already clobber REGNO, try to add such a clobber,\n+  // limiting the movement range in order to make the clobber valid.\n+  // When determining whether REGNO is live, ignore accesses made by an\n+  // instruction I if IGNORE (I) is true.  The caller then assumes the\n+  // responsibility of ensuring that CHANGE and I are placed in a valid order.\n+  //\n+  // Return true on success.  Leave CHANGE unmodified when returning false.\n+  //\n+  // WATERMARK is a watermark returned by new_change_attempt ().\n+  template<typename IgnorePredicate>\n+  bool add_regno_clobber (obstack_watermark &watermark, insn_change &change,\n+\t\t\t  unsigned int regno, IgnorePredicate ignore);\n+\n+  // Return true if change_insns will be able to perform the changes\n+  // described by CHANGES.\n+  bool verify_insn_changes (array_slice<insn_change *const> changes);\n+\n+  // Perform all the changes in CHANGES, keeping the instructions in the\n+  // order specified by the CHANGES array.  On return, the SSA information\n+  // remains up-to-date.  The same is true for instruction-level DF\n+  // information, although the block-level DF information might be\n+  // marked dirty.\n+  void change_insns (array_slice<insn_change *> changes);\n+\n+  // Like change_insns, but for a single change CHANGE.\n+  void change_insn (insn_change &change);\n+\n+  // If the changes that have been made to instructions require updates\n+  // to the CFG, perform those updates now.  Return true if something changed.\n+  // If it did:\n+  //\n+  // - The SSA information is now invalid and needs to be recomputed.\n+  //\n+  // - Dominance information is no longer available (in either direction).\n+  //\n+  // - The caller will need to call cleanup_cfg at some point.\n+  //\n+  // ??? We could probably update the SSA information for simple updates,\n+  // but currently nothing would benefit.  These late CFG changes are\n+  // relatively rare anyway, since gimple optimisers should remove most\n+  // unnecessary control flow.\n+  bool perform_pending_updates ();\n+\n+  // Print the contents of the function to PP.\n+  void print (pretty_printer *pp) const;\n+\n+private:\n+  // Information about the values that are live on exit from a basic block.\n+  // This class is only used when constructing the SSA form, it isn't\n+  // designed for being kept up-to-date.\n+  class bb_live_out_info\n+  {\n+  public:\n+    // REG_VALUES contains all the registers that live out from the block,\n+    // in order of increasing register number.  There are NUM_REG_VALUES\n+    // in total.  Registers do not appear here if their values are known\n+    // to be completely undefined; in that sense, the information is\n+    // closer to DF_LIVE than to DF_LR.\n+    unsigned int num_reg_values;\n+    set_info **reg_values;\n+\n+    // The memory value that is live on exit from the block.\n+    set_info *mem_value;\n+  };\n+\n+  // Information used while constructing the SSA form and discarded\n+  // afterwards.\n+  class build_info\n+  {\n+  public:\n+    set_info *current_reg_value (unsigned int) const;\n+    set_info *current_mem_value () const;\n+\n+    void record_reg_def (unsigned int, def_info *);\n+    void record_mem_def (def_info *);\n+\n+    // The block that we're currently processing.\n+    bb_info *current_bb;\n+\n+    // The EBB that contains CURRENT_BB.\n+    ebb_info *current_ebb;\n+\n+    // Except for the local exception noted below:\n+    //\n+    // - If register R has been defined in the current EBB, LAST_ACCESS[R + 1]\n+    //   is the last definition of R in the EBB.\n+    //\n+    // - If register R is currently live but has not yet been defined\n+    //   in the EBB, LAST_ACCESS[R + 1] is the current value of R,\n+    //   or null if the register's value is completely undefined.\n+    //\n+    // - The contents are not meaningful for other registers.\n+    //\n+    // Similarly:\n+    //\n+    // - If the current EBB has defined memory, LAST_ACCESS[0] is the last\n+    //   definition of memory in the EBB.\n+    //\n+    // - Otherwise LAST_ACCESS[0] is the value of memory that is live on\n+    // - entry to the EBB.\n+    //\n+    // The exception is that while building instructions, LAST_ACCESS[I]\n+    // can temporarily be the use of regno I - 1 by that instruction.\n+    access_info **last_access;\n+\n+    // A bitmap of registers that are live on entry to this EBB, with a tree\n+    // view for quick lookup.  Only used if MAY_HAVE_DEBUG_INSNS.\n+    bitmap ebb_live_in_for_debug;\n+\n+    // A conservative superset of the registers that are used by\n+    // instructions in CURRENT_EBB.  That is, all used registers\n+    // are in the set, but some unused registers might be too.\n+    bitmap ebb_use;\n+\n+    // A similarly conservative superset of the registers that are defined\n+    // by instructions in CURRENT_EBB.\n+    bitmap ebb_def;\n+\n+    // BB_LIVE_OUT[BI] gives the live-out values for the basic block\n+    // with index BI.\n+    bb_live_out_info *bb_live_out;\n+  };\n+\n+  // Return an RAII object that owns all objects allocated by\n+  // allocate_temp during its lifetime.\n+  obstack_watermark temp_watermark () { return &m_temp_obstack; }\n+\n+  template<typename T, typename... Ts>\n+  T *allocate (Ts... args);\n+\n+  template<typename T, typename... Ts>\n+  T *allocate_temp (Ts... args);\n+\n+  access_array temp_access_array (access_array accesses);\n+\n+  clobber_group *need_clobber_group (clobber_info *);\n+  def_node *need_def_node (def_info *);\n+  def_splay_tree need_def_splay_tree (def_info *);\n+\n+  use_info *make_use_available (use_info *, bb_info *);\n+  def_array insert_temp_clobber (obstack_watermark &, insn_info *,\n+\t\t\t\t unsigned int, def_array);\n+\n+  void insert_def_before (def_info *, def_info *);\n+  void insert_def_after (def_info *, def_info *);\n+  void remove_def_from_list (def_info *);\n+\n+  void add_clobber (clobber_info *, clobber_group *);\n+  void remove_clobber (clobber_info *, clobber_group *);\n+  void prepend_clobber_to_group (clobber_info *, clobber_group *);\n+  void append_clobber_to_group (clobber_info *, clobber_group *);\n+  void merge_clobber_groups (clobber_info *, clobber_info *,\n+\t\t\t     def_info *);\n+  clobber_info *split_clobber_group (clobber_group *, insn_info *);\n+\n+  void append_def (def_info *);\n+  void add_def (def_info *);\n+  void remove_def (def_info *);\n+\n+  void need_use_splay_tree (set_info *);\n+\n+  static void insert_use_before (use_info *, use_info *);\n+  static void insert_use_after (use_info *, use_info *);\n+\n+  void add_use (use_info *);\n+  void remove_use (use_info *);\n+\n+  insn_info::order_node *need_order_node (insn_info *);\n+\n+  void add_insn_after (insn_info *, insn_info *);\n+  void append_insn (insn_info *);\n+  void remove_insn (insn_info *);\n+\n+  insn_info *append_artificial_insn (bb_info *, rtx_insn * = nullptr);\n+\n+  void start_insn_accesses ();\n+  void finish_insn_accesses (insn_info *);\n+\n+  void record_use (build_info &, insn_info *, rtx_obj_reference);\n+  void record_call_clobbers (build_info &, insn_info *, rtx_call_insn *);\n+  void record_def (build_info &, insn_info *, rtx_obj_reference);\n+  void add_insn_to_block (build_info &, rtx_insn *);\n+\n+  void add_reg_unused_notes (insn_info *);\n+\n+  void add_live_out_use (bb_info *, set_info *);\n+  set_info *live_out_value (bb_info *, set_info *);\n+\n+  void append_phi (ebb_info *, phi_info *);\n+  void remove_phi (phi_info *);\n+  void delete_phi (phi_info *);\n+  void replace_phi (phi_info *, set_info *);\n+  phi_info *create_phi (ebb_info *, resource_info, access_info **,\n+\t\t\tunsigned int);\n+  phi_info *create_degenerate_phi (ebb_info *, set_info *);\n+\n+  bb_info *create_bb_info (basic_block);\n+  void append_bb (bb_info *);\n+  void calculate_potential_phi_regs ();\n+\n+  insn_info *add_placeholder_after (insn_info *);\n+  void possibly_queue_changes (insn_change &);\n+  void finalize_new_accesses (insn_change &);\n+  void apply_changes_to_insn (insn_change &);\n+\n+  void init_function_data ();\n+  void add_entry_block_defs (build_info &);\n+  void add_phi_nodes (build_info &);\n+  void add_artificial_accesses (build_info &, df_ref_flags);\n+  void add_block_contents (build_info &);\n+  void record_block_live_out (build_info &);\n+  void populate_backedge_phis (build_info &);\n+  void process_all_blocks ();\n+\n+  void simplify_phi_setup (phi_info *, set_info **, bitmap);\n+  void simplify_phi_propagate (phi_info *, set_info **, bitmap, bitmap);\n+  void simplify_phis ();\n+\n+  // The function that this object describes.\n+  function *m_fn;\n+\n+  // The lowest (negative) in-use artificial insn uid minus one.\n+  int m_next_artificial_uid;\n+\n+  // The highest in-use phi uid plus one.\n+  unsigned int m_next_phi_uid;\n+\n+  // The highest in-use register number plus one.\n+  unsigned int m_num_regs;\n+\n+  // M_DEFS[R] is the first definition of register R - 1 in a reverse\n+  // postorder traversal of the function, or null if the function has\n+  // no definition of R.  Applying last () gives the last definition of R.\n+  //\n+  // M_DEFS[0] is for memory; MEM_REGNO + 1 == 0.\n+  auto_vec<def_info *> m_defs;\n+\n+  // M_BBS[BI] gives the SSA information about the block with index BI.\n+  auto_vec<bb_info *> m_bbs;\n+\n+  // An obstack used to allocate the main RTL SSA information.\n+  obstack m_obstack;\n+\n+  // An obstack used for temporary work, such as while building up a list\n+  // of possible instruction changes.\n+  obstack m_temp_obstack;\n+\n+  // The start of each obstack, so that all memory in them can be freed.\n+  char *m_obstack_start;\n+  char *m_temp_obstack_start;\n+\n+  // The entry and exit blocks.\n+  bb_info *m_first_bb;\n+  bb_info *m_last_bb;\n+\n+  // The first and last instructions in a reverse postorder traversal\n+  // of the function.\n+  insn_info *m_first_insn;\n+  insn_info *m_last_insn;\n+\n+  // The last nondebug instruction in the list of instructions.\n+  // This is only different from m_last_insn when building the initial\n+  // SSA information; after that, the last instruction is always a\n+  // BB end instruction.\n+  insn_info *m_last_nondebug_insn;\n+\n+  // Temporary working state when building up lists of definitions and uses.\n+  // Keeping them around should reduce the number of unnecessary reallocations.\n+  auto_vec<access_info *> m_temp_defs;\n+  auto_vec<access_info *> m_temp_uses;\n+\n+  // The set of registers that might need to have phis associated with them.\n+  // Registers outside this set are known to have a single definition that\n+  // dominates all uses.\n+  //\n+  // Before RA, about 5% of registers are typically in the set.\n+  auto_bitmap m_potential_phi_regs;\n+\n+  // A list of phis that are no longer in use.  Their uids are still unique\n+  // and so can be recycled.\n+  phi_info *m_free_phis;\n+\n+  // A list of instructions that have been changed in ways that need\n+  // further processing later, such as removing dead instructions or\n+  // altering the CFG.\n+  auto_vec<insn_info *> m_queued_insn_updates;\n+\n+  // The INSN_UIDs of all instructions in M_QUEUED_INSN_UPDATES.\n+  auto_bitmap m_queued_insn_update_uids;\n+\n+  // A basic_block is in this bitmap if we need to call purge_dead_edges\n+  // on it.  As with M_QUEUED_INSN_UPDATES, these updates are queued until\n+  // a convenient point.\n+  auto_bitmap m_need_to_purge_dead_edges;\n+};\n+\n+void pp_function (pretty_printer *, const function_info *);\n+}\n+\n+void dump (FILE *, const rtl_ssa::function_info *);\n+\n+void DEBUG_FUNCTION debug (const rtl_ssa::function_info *);"}, {"sha": "d7705e96ac819103294cfa3863496febabc6261f", "filename": "gcc/rtl-ssa/insn-utils.h", "status": "added", "additions": 46, "deletions": 0, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Finsn-utils.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Finsn-utils.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Finsn-utils.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,46 @@\n+// Instruction-related utilities for RTL SSA                        -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// Return whichever of INSN1 and INSN2 occurs earlier in the function's\n+// reverse postorder.\n+inline insn_info *\n+earlier_insn (insn_info *insn1, insn_info *insn2)\n+{\n+  return *insn1 < *insn2 ? insn1 : insn2;\n+}\n+\n+// Return whichever of INSN1 and INSN2 occurs later in the function's\n+// reverse postorder.\n+inline insn_info *\n+later_insn (insn_info *insn1, insn_info *insn2)\n+{\n+  return *insn1 < *insn2 ? insn2 : insn1;\n+}\n+\n+// Return a closure of operator== for INSN.  See insn_is_changing for\n+// the rationale for defining the function this way.\n+inline insn_is_closure\n+insn_is (const insn_info *insn)\n+{\n+  return insn_is_closure (insn);\n+}\n+\n+}"}, {"sha": "b8e08ff043d1a03b351d876dfb1bb15cc6cb1e25", "filename": "gcc/rtl-ssa/insns.cc", "status": "added", "additions": 718, "deletions": 0, "changes": 718, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Finsns.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Finsns.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Finsns.cc?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,718 @@\n+// Implementation of instruction-related RTL SSA functions          -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+#define INCLUDE_ALGORITHM\n+#define INCLUDE_FUNCTIONAL\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"rtl.h\"\n+#include \"df.h\"\n+#include \"rtl-ssa.h\"\n+#include \"rtl-ssa/internals.inl\"\n+#include \"predict.h\"\n+#include \"print-rtl.h\"\n+#include \"rtl-iter.h\"\n+\n+using namespace rtl_ssa;\n+\n+// The gap to leave between program points when building up the list\n+// of instructions for the first time.  Using 2 allows an instruction\n+// to be inserted between two others without resorting to splay tree\n+// ordering.  Using 0 is useful as a debugging aid to stress the\n+// splay tree code.\n+static const unsigned int POINT_INCREASE = 2;\n+\n+// Calculate and record the cost of the instruction, based on the\n+// form it had before any in-progress changes were made.\n+void\n+insn_info::calculate_cost () const\n+{\n+  basic_block cfg_bb = BLOCK_FOR_INSN (m_rtl);\n+  temporarily_undo_changes (0);\n+  m_cost_or_uid = insn_cost (m_rtl, optimize_bb_for_speed_p (cfg_bb));\n+  redo_changes (0);\n+}\n+\n+// Add NOTE to the instruction's notes.\n+void\n+insn_info::add_note (insn_note *note)\n+{\n+  insn_note **ptr = &m_first_note;\n+  // Always put the order node first, since it's the one that's likely\n+  // to be used most often.\n+  if (*ptr && (*ptr)->kind () == insn_note_kind::ORDER_NODE)\n+    ptr = &(*ptr)->m_next_note;\n+  note->m_next_note = *ptr;\n+  *ptr = note;\n+}\n+\n+// Implement compare_with for the case in which this insn and OTHER\n+// have the same program point.\n+int\n+insn_info::slow_compare_with (const insn_info &other) const\n+{\n+  return order_splay_tree::compare_nodes (get_known_order_node (),\n+\t\t\t\t\t  other.get_known_order_node ());\n+}\n+\n+// Print insn uid UID to PP, where UID has the same form as insn_info::uid.\n+void\n+insn_info::print_uid (pretty_printer *pp, int uid)\n+{\n+  char tmp[3 * sizeof (uid) + 2];\n+  if (uid < 0)\n+    // An artificial instruction.\n+    snprintf (tmp, sizeof (tmp), \"a%d\", -uid);\n+  else\n+    // A real RTL instruction.\n+    snprintf (tmp, sizeof (tmp), \"i%d\", uid);\n+  pp_string (pp, tmp);\n+}\n+\n+// See comment above declaration.\n+void\n+insn_info::print_identifier (pretty_printer *pp) const\n+{\n+  print_uid (pp, uid ());\n+}\n+\n+// See comment above declaration.\n+void\n+insn_info::print_location (pretty_printer *pp) const\n+{\n+  if (bb_info *bb = this->bb ())\n+    {\n+      ebb_info *ebb = bb->ebb ();\n+      if (ebb && is_phi ())\n+\tebb->print_identifier (pp);\n+      else\n+\tbb->print_identifier (pp);\n+      pp_string (pp, \" at point \");\n+      pp_decimal_int (pp, m_point);\n+    }\n+  else\n+    pp_string (pp, \"<unknown location>\");\n+}\n+\n+// See comment above declaration.\n+void\n+insn_info::print_identifier_and_location (pretty_printer *pp) const\n+{\n+  if (m_is_asm)\n+    pp_string (pp, \"asm \");\n+  if (m_is_debug_insn)\n+    pp_string (pp, \"debug \");\n+  pp_string (pp, \"insn \");\n+  print_identifier (pp);\n+  pp_string (pp, \" in \");\n+  print_location (pp);\n+}\n+\n+// See comment above declaration.\n+void\n+insn_info::print_full (pretty_printer *pp) const\n+{\n+  print_identifier_and_location (pp);\n+  pp_colon (pp);\n+  if (is_real ())\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      if (has_been_deleted ())\n+\tpp_string (pp, \"deleted\");\n+      else\n+\t{\n+\t  // Print the insn pattern to a temporary printer.\n+\t  pretty_printer sub_pp;\n+\t  print_insn_with_notes (&sub_pp, rtl ());\n+\t  const char *text = pp_formatted_text (&sub_pp);\n+\n+\t  // Calculate the length of the maximum line in the pattern.\n+\t  unsigned int max_len = 0;\n+\t  const char *start = text;\n+\t  while (const char *end = strchr (start, '\\n'))\n+\t    {\n+\t      max_len = MAX (max_len, (unsigned int) (end - start));\n+\t      start = end + 1;\n+\t    }\n+\n+\t  // Print a separator before or after the pattern.\n+\t  auto print_top_bottom = [&]()\n+\t    {\n+\t      pp_character (pp, '+');\n+\t      for (unsigned int i = 0; i < max_len + 2; ++i)\n+\t\tpp_character (pp, '-');\n+\t    };\n+\n+\t  print_top_bottom ();\n+\t  start = text;\n+\t  while (const char *end = strchr (start, '\\n'))\n+\t    {\n+\t      pp_newline_and_indent (pp, 0);\n+\t      pp_character (pp, '|');\n+\t      // Each line of the pattern already starts with a space.\n+\t      // so we don't need to add another one here.\n+\t      pp_append_text (pp, start, end);\n+\t      start = end + 1;\n+\t    }\n+\t  pp_newline_and_indent (pp, 0);\n+\t  print_top_bottom ();\n+\n+\t  if (m_cost_or_uid != UNKNOWN_COST)\n+\t    {\n+\t      pp_newline_and_indent (pp, 0);\n+\t      pp_string (pp, \"cost: \");\n+\t      pp_decimal_int (pp, m_cost_or_uid);\n+\t    }\n+\t  if (m_has_pre_post_modify)\n+\t    {\n+\t      pp_newline_and_indent (pp, 0);\n+\t      pp_string (pp, \"has pre/post-modify operations\");\n+\t    }\n+\t  if (m_has_volatile_refs)\n+\t    {\n+\t      pp_newline_and_indent (pp, 0);\n+\t      pp_string (pp, \"has volatile refs\");\n+\t    }\n+\t}\n+      pp_indentation (pp) -= 2;\n+    }\n+\n+  auto print_accesses = [&](const char *heading, access_array accesses,\n+\t\t\t    unsigned int flags)\n+    {\n+      if (!accesses.empty ())\n+\t{\n+\t  pp_newline_and_indent (pp, 2);\n+\t  pp_string (pp, heading);\n+\t  pp_newline_and_indent (pp, 2);\n+\t  pp_accesses (pp, accesses, flags);\n+\t  pp_indentation (pp) -= 4;\n+\t}\n+    };\n+\n+  print_accesses (\"uses:\", uses (), PP_ACCESS_USER);\n+  auto *call_clobbers_note = find_note<insn_call_clobbers_note> ();\n+  if (call_clobbers_note)\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"has call clobbers for ABI \");\n+      pp_decimal_int (pp, call_clobbers_note->abi_id ());\n+      pp_indentation (pp) -= 2;\n+    }\n+  print_accesses (\"defines:\", defs (), PP_ACCESS_SETTER);\n+  if (num_uses () == 0 && !call_clobbers_note && num_defs () == 0)\n+    {\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"has no uses or defs\");\n+      pp_indentation (pp) -= 2;\n+    }\n+\n+  if (order_node *node = get_order_node ())\n+    {\n+      while (node->m_parent)\n+\tnode = node->m_parent;\n+\n+      pp_newline_and_indent (pp, 2);\n+      pp_string (pp, \"insn order: \");\n+      pp_newline_and_indent (pp, 2);\n+      auto print_order = [](pretty_printer *pp, order_node *node)\n+\t{\n+\t  print_uid (pp, node->uid ());\n+\t};\n+      order_splay_tree::print (pp, node, print_order);\n+      pp_indentation (pp) -= 4;\n+    }\n+}\n+\n+// Return an insn_info::order_node for INSN, creating one if necessary.\n+insn_info::order_node *\n+function_info::need_order_node (insn_info *insn)\n+{\n+  insn_info::order_node *order = insn->get_order_node ();\n+  if (!order)\n+    {\n+      order = allocate<insn_info::order_node> (insn->uid ());\n+      insn->add_note (order);\n+    }\n+  return order;\n+}\n+\n+// Add instruction INSN immediately after AFTER in the reverse postorder list.\n+// INSN is not currently in the list.\n+void\n+function_info::add_insn_after (insn_info *insn, insn_info *after)\n+{\n+  gcc_checking_assert (!insn->has_insn_links ());\n+\n+  insn->copy_next_from (after);\n+  after->set_next_any_insn (insn);\n+\n+  // The prev link is easy if AFTER and INSN are the same type.\n+  // Handle the other cases below.\n+  if (after->is_debug_insn () == insn->is_debug_insn ())\n+    insn->set_prev_sametype_insn (after);\n+\n+  if (insn_info *next = insn->next_any_insn ())\n+    {\n+      if (insn->is_debug_insn () == next->is_debug_insn ())\n+\t{\n+\t  // INSN might now be the start of the subsequence of debug insns,\n+\t  // and so its prev pointer might point to the end of the subsequence\n+\t  // instead of AFTER.\n+\t  insn->copy_prev_from (next);\n+\t  next->set_prev_sametype_insn (insn);\n+\t}\n+      else if (insn->is_debug_insn ()) // && !next->is_debug_insn ()\n+\t{\n+\t  // INSN ends a subsequence of debug instructions.  Find the\n+\t  // first debug instruction in the subsequence, which might\n+\t  // be INSN itself.  (If it isn't, then AFTER is also a debug\n+\t  // instruction and we updated INSN's prev link above.)\n+\t  insn_info *first = next->prev_nondebug_insn ()->next_any_insn ();\n+\t  first->set_last_debug_insn (insn);\n+\t}\n+      else // !insn->is_debug_insn () && next->is_debug_insn ()\n+\t// At present we don't (need to) support inserting a nondebug\n+\t// instruction between two existing debug instructions.\n+\tgcc_assert (!after->is_debug_insn ());\n+\n+      // If AFTER and NEXT are separated by at least two points, we can\n+      // use a unique point number for INSN.  Otherwise INSN will have\n+      // the same point number as AFTER.\n+      insn->set_point ((next->point () + after->point ()) / 2);\n+    }\n+  else\n+    {\n+      if (!insn->is_debug_insn ())\n+\t{\n+\t  insn->set_prev_sametype_insn (m_last_nondebug_insn);\n+\t  m_last_nondebug_insn = insn;\n+\t}\n+      else\n+\t// There is now at least one debug instruction after\n+\t// m_last_nondebug_insn: either INSN itself, or the start of\n+\t// a longer subsequence of debug insns that now ends with AFTER\n+\t// followed by INSN.\n+\tm_last_nondebug_insn->next_any_insn ()->set_last_debug_insn (insn);\n+      m_last_insn = insn;\n+\n+      insn->set_point (after->point () + POINT_INCREASE);\n+    }\n+\n+  // If INSN's program point is the same as AFTER's, we need to use the\n+  // splay tree to record their relative order.\n+  if (insn->point () == after->point ())\n+    {\n+      insn_info::order_node *after_node = need_order_node (after);\n+      insn_info::order_node *insn_node = need_order_node (insn);\n+      insn_info::order_splay_tree::insert_child (after_node, 1, insn_node);\n+    }\n+}\n+\n+// Remove INSN from the function's list of instructions.\n+void\n+function_info::remove_insn (insn_info *insn)\n+{\n+  if (insn_info::order_node *order = insn->get_order_node ())\n+    insn_info::order_splay_tree::remove_node (order);\n+\n+  if (auto *note = insn->find_note<insn_call_clobbers_note> ())\n+    {\n+      ebb_call_clobbers_info *ecc = insn->ebb ()->first_call_clobbers ();\n+      while (ecc->abi ()->id () != note->abi_id ())\n+\tecc = ecc->next ();\n+      int comparison = lookup_call_clobbers (*ecc, insn);\n+      gcc_assert (comparison == 0);\n+      ecc->remove_root ();\n+    }\n+\n+  insn_info *prev = insn->prev_any_insn ();\n+  insn_info *next = insn->next_any_insn ();\n+  insn_info *prev_nondebug = insn->prev_nondebug_insn ();\n+  insn_info *next_nondebug = insn->next_nondebug_insn ();\n+\n+  // We should never remove the entry or exit block's instructions.\n+  // At present we also don't remove entire blocks, so should never\n+  // remove debug instructions.\n+  gcc_checking_assert (prev_nondebug\n+\t\t       && next_nondebug\n+\t\t       && !insn->is_debug_insn ());\n+\n+  if (prev->is_debug_insn () && next->is_debug_insn ())\n+    {\n+      // We need to stitch together two subsequences of debug insns.\n+      insn_info *last = next->last_debug_insn ();\n+      next->set_prev_sametype_insn (prev);\n+      prev_nondebug->next_any_insn ()->set_last_debug_insn (last);\n+    }\n+  prev->set_next_any_insn (next);\n+  next_nondebug->set_prev_sametype_insn (prev_nondebug);\n+\n+  insn->clear_insn_links ();\n+}\n+\n+// Create an artificial instruction for BB, associating it with RTL (which can\n+// be null).  Add the new instruction to the end of the function's list and\n+// return the new instruction.\n+insn_info *\n+function_info::append_artificial_insn (bb_info *bb, rtx_insn *rtl)\n+{\n+  insn_info *insn = allocate<insn_info> (bb, rtl, m_next_artificial_uid);\n+  m_next_artificial_uid -= 1;\n+  append_insn (insn);\n+  return insn;\n+}\n+\n+// Finish building a new list of uses and definitions for instruction INSN.\n+void\n+function_info::finish_insn_accesses (insn_info *insn)\n+{\n+  unsigned int num_defs = m_temp_defs.length ();\n+  unsigned int num_uses = m_temp_uses.length ();\n+  obstack_make_room (&m_obstack, num_defs + num_uses);\n+  if (num_defs)\n+    {\n+      sort_accesses (m_temp_defs);\n+      obstack_grow (&m_obstack, m_temp_defs.address (),\n+\t\t    num_defs * sizeof (access_info *));\n+      m_temp_defs.truncate (0);\n+    }\n+  if (num_uses)\n+    {\n+      sort_accesses (m_temp_uses);\n+      obstack_grow (&m_obstack, m_temp_uses.address (),\n+\t\t    num_uses * sizeof (access_info *));\n+      m_temp_uses.truncate (0);\n+    }\n+  void *addr = obstack_finish (&m_obstack);\n+  insn->set_accesses (static_cast<access_info **> (addr), num_defs, num_uses);\n+}\n+\n+// Called while building SSA form using BI.  Record that INSN contains\n+// read reference REF.  If this requires new entries to be added to\n+// INSN->uses (), add those entries to the list we're building in\n+// m_temp_uses.\n+void\n+function_info::record_use (build_info &bi, insn_info *insn,\n+\t\t\t   rtx_obj_reference ref)\n+{\n+  unsigned int regno = ref.regno;\n+  machine_mode mode = ref.is_reg () ? ref.mode : BLKmode;\n+  access_info *access = bi.last_access[ref.regno + 1];\n+  use_info *use = safe_dyn_cast<use_info *> (access);\n+  if (!use)\n+    {\n+      set_info *value = safe_dyn_cast<set_info *> (access);\n+      // In order to ensure that -g doesn't affect codegen, uses in debug\n+      // instructions do not affect liveness, either in DF or here.\n+      // This means that there might be no correct definition of the resource\n+      // available (e.g. if it would require a phi node that the nondebug\n+      // code doesn't need).  Perhaps we could have \"debug phi nodes\" as\n+      // well as \"debug instructions\", but that would require a method\n+      // of building phi nodes that didn't depend on DF liveness information,\n+      // and so might be significantly more expensive.\n+      //\n+      // Therefore, the only value we try to attach to a use by a debug\n+      // instruction is VALUE itself (as we would for nondebug instructions).\n+      // We then need to make a conservative check for whether VALUE is\n+      // actually correct.\n+      auto value_is_valid = [&]()\n+\t{\n+\t  // Memmory always has a valid definition.\n+\t  if (ref.is_mem ())\n+\t    return true;\n+\n+\t  // If VALUE would lead to an uninitialized use anyway, there's\n+\t  // nothing to check.\n+\t  if (!value)\n+\t    return false;\n+\n+\t  // If the previous definition occurs in the same EBB then it\n+\t  // is certainly correct.\n+\t  if (value->ebb () == bi.current_ebb)\n+\t    return true;\n+\n+\t  // If the register is live on entry to the EBB but not used\n+\t  // within it, VALUE is the correct live-in value.\n+\t  if (bitmap_bit_p (bi.ebb_live_in_for_debug, regno))\n+\t    return true;\n+\n+\t  // Check if VALUE is the function's only definition of REGNO\n+\t  // and if it dominates the use.\n+\t  if (regno != MEM_REGNO\n+\t      && regno < DF_REG_SIZE (DF)\n+\t      && DF_REG_DEF_COUNT (regno) == 1\n+\t      && dominated_by_p (CDI_DOMINATORS, insn->bb ()->cfg_bb (),\n+\t\t\t\t value->bb ()->cfg_bb ()))\n+\t    return true;\n+\n+\t  // Punt for other cases.\n+\t  return false;\n+\t};\n+      if (insn->is_debug_insn () && !value_is_valid ())\n+\tvalue = nullptr;\n+\n+      use = allocate<use_info> (insn, resource_info { mode, regno }, value);\n+      add_use (use);\n+      m_temp_uses.safe_push (use);\n+      bi.last_access[ref.regno + 1] = use;\n+      use->record_reference (ref, true);\n+    }\n+  else\n+    {\n+      // Record the mode of the largest use.  The choice is arbitrary if\n+      // the instruction (unusually) references the same register in two\n+      // different but equal-sized modes.\n+      gcc_checking_assert (use->insn () == insn);\n+      if (HARD_REGISTER_NUM_P (regno)\n+\t  && partial_subreg_p (use->mode (), mode))\n+\tuse->set_mode (mode);\n+      use->record_reference (ref, false);\n+    }\n+}\n+\n+// Called while building SSA form for INSN using BI.  Record the effect\n+// of call clobbers in RTL.  We have already added the explicit sets and\n+// clobbers for RTL, which have priority over any call clobbers.\n+void\n+function_info::record_call_clobbers (build_info &bi, insn_info *insn,\n+\t\t\t\t     rtx_call_insn *rtl)\n+{\n+  // See whether we should record this call in the EBB's list of\n+  // call clobbers.  Three things affect this choice:\n+  //\n+  // (1) The list is the only way we have of recording partial clobbers.\n+  //     All calls that only partially clobber registers must therefore\n+  //     be in the list.\n+  //\n+  // (2) Adding calls to the list is much more memory-efficient than\n+  //     creating a long list of clobber_infos.\n+  //\n+  // (3) Adding calls to the list limits the ability to move definitions\n+  //     of registers that are normally fully or partially clobbered\n+  //     by the associated predefined ABI.  So adding calls to the list\n+  //     can hamper optimization if (thanks to -fipa-ra) the number of\n+  //     clobbers is much smaller than the usual set.\n+  //\n+  // The trade-off that we currently take is to use the list if there\n+  // are some registers that the call only partially clobbers or if\n+  // the set of clobbers is the standard set.\n+  function_abi abi = insn_callee_abi (rtl);\n+  if (abi.base_abi ().full_reg_clobbers () == abi.full_reg_clobbers ()\n+      || abi.full_and_partial_reg_clobbers () != abi.full_reg_clobbers ())\n+    {\n+      // Find an entry for this predefined ABI, creating one if necessary.\n+      ebb_call_clobbers_info *ecc = bi.current_ebb->first_call_clobbers ();\n+      while (ecc && ecc->abi () != &abi.base_abi ())\n+\tecc = ecc->next ();\n+      if (!ecc)\n+\t{\n+\t  ecc = allocate<ebb_call_clobbers_info> (&abi.base_abi ());\n+\t  ecc->m_next = bi.current_ebb->first_call_clobbers ();\n+\t  bi.current_ebb->set_first_call_clobbers (ecc);\n+\t}\n+\n+      auto abi_id = abi.base_abi ().id ();\n+      auto *insn_clobbers = allocate<insn_call_clobbers_note> (abi_id, insn);\n+      insn->add_note (insn_clobbers);\n+\n+      ecc->insert_max_node (insn_clobbers);\n+    }\n+  else\n+    for (unsigned int regno = 0; regno < FIRST_PSEUDO_REGISTER; ++regno)\n+      if (TEST_HARD_REG_BIT (abi.full_reg_clobbers (), regno))\n+\t{\n+\t  def_info *def = m_defs[regno + 1];\n+\t  if (!def || def->last_def ()->insn () != insn)\n+\t    {\n+\t      def = allocate<clobber_info> (insn, regno);\n+\t      def->m_is_call_clobber = true;\n+\t      append_def (def);\n+\t      m_temp_defs.safe_push (def);\n+\t      bi.last_access[regno + 1] = def;\n+\t    }\n+\t}\n+}\n+\n+// Called while building SSA form using BI.  Record that INSN contains\n+// write reference REF.  Add associated def_infos to the list of accesses\n+// that we're building in m_temp_defs.  Record the register's new live\n+// value in BI.\n+void\n+function_info::record_def (build_info &bi, insn_info *insn,\n+\t\t\t   rtx_obj_reference ref)\n+{\n+  // Punt if we see multiple definitions of the same resource.\n+  // This can happen for several reasons:\n+  //\n+  // - An instruction might store two values to memory at once, giving two\n+  //   distinct memory references.\n+  //\n+  // - An instruction might assign to multiple pieces of a wide pseudo\n+  //   register.  For example, on 32-bit targets, an instruction might\n+  //   assign to both the upper and lower halves of a 64-bit pseudo register.\n+  //\n+  // - It's possible for the same register to be clobbered by the\n+  //   CALL_INSN_FUNCTION_USAGE and to be set by the main instruction\n+  //   pattern as well.  In that case, the clobber conceptually happens\n+  //   before the set and can essentially be ignored.\n+  //\n+  // - Similarly, global registers are implicitly set by a call but can\n+  //   be explicitly set or clobbered as well.  In that situation, the sets\n+  //   are listed first and should win over a clobber.\n+  unsigned int regno = ref.regno;\n+  machine_mode mode = ref.is_reg () ? ref.mode : BLKmode;\n+  def_info *def = safe_dyn_cast<def_info *> (bi.last_access[ref.regno + 1]);\n+  if (def && def->insn () == insn)\n+    {\n+      if (!ref.is_clobber ())\n+\t{\n+\t  gcc_checking_assert (!is_a<clobber_info *> (def));\n+\t  def->record_reference (ref, false);\n+\t}\n+      return;\n+    }\n+\n+  // Memory is always well-defined, so only use clobber_infos for registers.\n+  if (ref.is_reg () && ref.is_clobber ())\n+    def = allocate<clobber_info> (insn, regno);\n+  else\n+    def = allocate<set_info> (insn, resource_info { mode, regno });\n+  def->record_reference (ref, true);\n+  append_def (def);\n+  m_temp_defs.safe_push (def);\n+  bi.last_access[ref.regno + 1] = def;\n+}\n+\n+// Called while building SSA form using BI.  Add an insn_info for RTL\n+// to the block that we're current building.\n+void\n+function_info::add_insn_to_block (build_info &bi, rtx_insn *rtl)\n+{\n+  insn_info *insn = allocate<insn_info> (bi.current_bb, rtl, UNKNOWN_COST);\n+  append_insn (insn);\n+\n+  vec_rtx_properties properties;\n+  properties.add_insn (rtl, true);\n+  insn->set_properties (properties);\n+\n+  start_insn_accesses ();\n+\n+  // Record the uses.\n+  for (rtx_obj_reference ref : properties.refs ())\n+    if (ref.is_read ())\n+      record_use (bi, insn, ref);\n+\n+  // Restore the contents of bi.last_access, which we used as a cache\n+  // when assembling the uses.\n+  for (access_info *access : m_temp_uses)\n+    {\n+      unsigned int regno = access->regno ();\n+      gcc_checking_assert (bi.last_access[regno + 1] == access);\n+      bi.last_access[regno + 1] = as_a<use_info *> (access)->def ();\n+    }\n+\n+  // Record the definitions.\n+  for (rtx_obj_reference ref : properties.refs ())\n+    if (ref.is_write ())\n+      record_def (bi, insn, ref);\n+\n+  // Logically these happen before the explicit definitions, but if the\n+  // explicit definitions and call clobbers reference the same register,\n+  // the explicit definition should win.\n+  if (auto *call_rtl = dyn_cast<rtx_call_insn *> (rtl))\n+    record_call_clobbers (bi, insn, call_rtl);\n+\n+  finish_insn_accesses (insn);\n+}\n+\n+// Check whether INSN sets any registers that are never subsequently used.\n+// If so, add REG_UNUSED notes for them.  The caller has already removed\n+// any previous REG_UNUSED notes.\n+void\n+function_info::add_reg_unused_notes (insn_info *insn)\n+{\n+  rtx_insn *rtl = insn->rtl ();\n+\n+  auto handle_potential_set = [&](rtx pattern)\n+    {\n+      if (GET_CODE (pattern) != SET)\n+\treturn;\n+\n+      rtx dest = SET_DEST (pattern);\n+      if (!REG_P (dest))\n+\treturn;\n+\n+      def_array defs = insn->defs ();\n+      unsigned int index = find_access_index (defs, REGNO (dest));\n+      for (unsigned int i = 0; i < REG_NREGS (dest); ++i)\n+\t{\n+\t  def_info *def = defs[index + i];\n+\t  gcc_checking_assert (def->regno () == REGNO (dest) + i);\n+\t  set_info *set = dyn_cast<set_info *> (def);\n+\t  if (set && set->has_nondebug_uses ())\n+\t    return;\n+\t}\n+      add_reg_note (rtl, REG_UNUSED, dest);\n+    };\n+\n+  rtx pattern = PATTERN (rtl);\n+  if (GET_CODE (pattern) == PARALLEL)\n+    for (int i = 0; i < XVECLEN (pattern, 0); ++i)\n+      handle_potential_set (XVECEXP (pattern, 0, i));\n+  else\n+    handle_potential_set (pattern);\n+}\n+\n+// Search TREE for call clobbers at INSN.  Return:\n+//\n+// - less than zero if INSN occurs before the root of TREE\n+// - 0 if INSN is the root of TREE\n+// - greater than zero if INSN occurs after the root of TREE\n+int\n+rtl_ssa::lookup_call_clobbers (insn_call_clobbers_tree &tree, insn_info *insn)\n+{\n+  auto compare = [&](insn_call_clobbers_note *clobbers)\n+    {\n+      return insn->compare_with (clobbers->insn ());\n+    };\n+  return tree.lookup (compare);\n+}\n+\n+// Print a description of INSN to PP.\n+void\n+rtl_ssa::pp_insn (pretty_printer *pp, const insn_info *insn)\n+{\n+  if (!insn)\n+    pp_string (pp, \"<null>\");\n+  else\n+    insn->print_full (pp);\n+}\n+\n+// Print a description of INSN to FILE.\n+void\n+dump (FILE *file, const insn_info *insn)\n+{\n+  dump_using (file, pp_insn, insn);\n+}\n+\n+// Debug interface to the dump routine above.\n+void debug (const insn_info *x) { dump (stderr, x); }"}, {"sha": "a663103c1d91df7d952323bb3a497dead3b27597", "filename": "gcc/rtl-ssa/insns.h", "status": "added", "additions": 505, "deletions": 0, "changes": 505, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Finsns.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Finsns.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Finsns.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,505 @@\n+// Instruction-related RTL SSA classes                              -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// A fake cost for instructions that we haven't costed yet.\n+const int UNKNOWN_COST = INT_MAX;\n+\n+// Enumerates the kinds of note that can be added to an instruction.\n+// See the comment above insn_info for details.\n+enum class insn_note_kind : uint8_t\n+{\n+  ORDER_NODE,\n+  CALL_CLOBBERS\n+};\n+\n+// The base class for notes that can be added to an instruction.\n+// See the comment above insn_info for details.\n+class insn_note\n+{\n+  // Size: 2 LP64 words.\n+  friend class insn_info;\n+  friend class function_info;\n+\n+public:\n+  // Return what kind of note this is.\n+  insn_note_kind kind () const { return m_kind; }\n+\n+  // Return the next note in the list, or null if none.\n+  insn_note *next_note () const { return m_next_note; }\n+\n+  // Used with T = Derived *, where Derived is derived from insn_note.\n+  // Convert the note to Derived, asserting that it has the right kind.\n+  template<typename T>\n+  T as_a ();\n+\n+  // Used with T = Derived *, where Derived is derived from insn_note.\n+  // If the note is a Derived note, return it in that form, otherwise\n+  // return null.\n+  template<typename T>\n+  T dyn_cast ();\n+\n+protected:\n+  // Construct a note with the given kind.\n+  insn_note (insn_note_kind);\n+\n+private:\n+  // The next note in the list, or null if none.\n+  insn_note *m_next_note;\n+\n+  // The kind of note this is.\n+  insn_note_kind m_kind : 8;\n+\n+protected:\n+  // Fill in the remaining LP64 word with data that derived classes can use.\n+  unsigned int m_data8 : 8;\n+  unsigned int m_data16 : 16;\n+  unsigned int m_data32 : 32;\n+};\n+\n+// Instructions have one of these notes if insn_info::has_call_clobbers ()\n+// is true.  All such instructions in an EBB are first grouped together\n+// by the predefined_function_abis of the functions that they call.\n+// Then, for each such predefined ABI, the call_clobbers notes are put\n+// into a splay tree whose nodes follow execution order.\n+class insn_call_clobbers_note : public insn_note\n+{\n+  friend class function_info;\n+  friend class default_splay_tree_accessors<insn_call_clobbers_note *>;\n+\n+public:\n+  static const insn_note_kind kind = insn_note_kind::CALL_CLOBBERS;\n+\n+  // Return the identifier of the predefined_function_abi.\n+  unsigned int abi_id () const { return m_data32; }\n+\n+  // Return the instruction to which the note is attached.\n+  insn_info *insn () const { return m_insn; }\n+\n+protected:\n+  insn_call_clobbers_note (unsigned int abi_id, insn_info *insn);\n+\n+  // The splay tree pointers.\n+  insn_call_clobbers_note *m_children[2];\n+\n+  // The value returned by insn ().\n+  insn_info *m_insn;\n+};\n+\n+// A splay tree of insn_call_clobbers_notes.\n+using insn_call_clobbers_tree = default_splay_tree<insn_call_clobbers_note *>;\n+\n+// SSA-related information about an instruction.  It also represents\n+// artificial instructions that are added to make the dataflow correct;\n+// these artificial instructions fall into three categories:\n+//\n+// - Instructions that hold the phi nodes for an extended basic block (is_phi).\n+//\n+// - Instructions that represent the head of a basic block and that hold\n+//   all the associated artificial uses and definitions.\n+//\n+// - Instructions that represent the end of a basic block and that again\n+//   hold all the associated artificial uses and definitions.\n+//\n+// Dataflow-wise, each instruction goes through three stages:\n+//\n+// (1) Use all the values in uses ().\n+//\n+// (2) If has_call_clobbers (), clobber the registers indicated by\n+//     insn_callee_abi.\n+//\n+// (3) Define all the values in defs ().\n+//\n+// Having stage (2) is a trade-off: it makes processing the instructions\n+// more complicated, but it saves having to allocate memory for every\n+// individual call clobber.  Without it, clobbers for calls would often\n+// make up a large proportion of the total definitions in a function.\n+//\n+// All the instructions in a function are chained together in a list\n+// that follows a reverse postorder traversal of the CFG.  The list\n+// contains both debug and nondebug instructions, but it is possible\n+// to hop from one nondebug instruction to the next with constant complexity.\n+//\n+// Instructions can have supplemental information attached in the form\n+// of \"notes\", a bit like REG_NOTES for the underlying RTL insns.\n+class insn_info\n+{\n+  // Size: 8 LP64 words.\n+  friend class ebb_info;\n+  friend class function_info;\n+\n+public:\n+  // Compare instructions by their positions in the function list described\n+  // above.  Thus for two instructions in the same basic block, I1 < I2 if\n+  // I1 comes before I2 in the block.\n+  bool operator< (const insn_info &) const;\n+  bool operator<= (const insn_info &) const;\n+  bool operator>= (const insn_info &) const;\n+  bool operator> (const insn_info &) const;\n+\n+  // Return -1 if this instruction comes before INSN in the reverse\n+  // postorder, 0 if this instruction is INSN, or 1 if this instruction\n+  // comes after INSN in the reverse postorder.\n+  int compare_with (const insn_info *insn) const;\n+\n+  // Return the previous and next instructions in the list described above,\n+  // or null if there are no such instructions.\n+  insn_info *prev_any_insn () const;\n+  insn_info *next_any_insn () const;\n+\n+  // Only valid if !is_debug_insn ().  Return the previous and next\n+  // nondebug instructions in the list described above, skipping over\n+  // any intervening debug instructions.  These are constant-time operations.\n+  insn_info *prev_nondebug_insn () const;\n+  insn_info *next_nondebug_insn () const;\n+\n+  // Return the underlying RTL insn.  This instruction is null if is_phi ()\n+  // or is_bb_end () are true.  The instruction is a basic block note if\n+  // is_bb_head () is true.\n+  rtx_insn *rtl () const { return m_rtl; }\n+\n+  // Return true if the instruction is a real insn with an rtl pattern.\n+  // Return false if it is an artificial instruction that represents the\n+  // phi nodes in an extended basic block or the head or end of a basic block.\n+  bool is_real () const { return m_cost_or_uid >= 0; }\n+\n+  // Return the opposite of is_real ().\n+  bool is_artificial () const { return m_cost_or_uid < 0; }\n+\n+  // Return true if the instruction was a real instruction but has now\n+  // been deleted.  In this case the instruction is no longer part of\n+  // the SSA information.\n+  bool has_been_deleted () const { return m_rtl && !INSN_P (m_rtl); }\n+\n+  // Return true if the instruction is a debug instruction (and thus\n+  // also a real instruction).\n+  bool is_debug_insn () const { return m_is_debug_insn; }\n+\n+  // Return true if the instruction is something that we can optimize.\n+  // This implies that it is a real instruction that contains an asm\n+  // or that contains something that matches an .md define_insn pattern.\n+  bool can_be_optimized () const { return m_can_be_optimized; }\n+\n+  // Return true if the instruction is a call instruction.\n+  //\n+  // ??? We could cache this information, but since most callers would\n+  // go on to access PATTERN (rtl ()), a cache might not be helpful and\n+  // could even be counterproductive.\n+  bool is_call () const { return CALL_P (m_rtl); }\n+\n+  // Return true if the instruction is a jump instruction.\n+  //\n+  // ??? See is_call for the reason we don't cache this.\n+  bool is_jump () const { return JUMP_P (m_rtl); }\n+\n+  // Return true if the instruction is real and contains an inline asm.\n+  bool is_asm () const { return m_is_asm; }\n+\n+  // Return true if the instruction is real and includes an RTX_AUTOINC\n+  // operation.\n+  bool has_pre_post_modify () const { return m_has_pre_post_modify; }\n+\n+  // Return true if the instruction is real and has volatile references,\n+  // in the sense of volatile_refs_p.  This includes volatile memory,\n+  // volatile asms and UNSPEC_VOLATILEs.\n+  bool has_volatile_refs () const { return m_has_volatile_refs; }\n+\n+  // Return true if the instruction is aritificial and if its (sole)\n+  // purpose is to hold the phi nodes in an extended basic block.\n+  bool is_phi () const;\n+\n+  // Return true if the instruction is artificial and if it represents\n+  // the head of a basic block.  If so, the instruction conceptually\n+  // executes before the real instructions in the block.  The uses\n+  // and definitions represent the df_get_artificial_uses and\n+  // df_get_artificial_defs entries for the head of the block.\n+  bool is_bb_head () const;\n+\n+  // Return true if the instruction is artificial and if it represents\n+  // the end of a basic block.  The uses and definitions represent the\n+  // the df_get_artificial_uses and df_get_artificial_defs entries for\n+  // the end of the block.\n+  bool is_bb_end () const;\n+\n+  // Return the basic block that the instruction is in.\n+  bb_info *bb () const { return m_bb; }\n+\n+  // Return the extended basic block that the instruction is in;\n+  // see bb_info for details.\n+  ebb_info *ebb () const;\n+\n+  // If the instruction is real, return the unique identifier of the\n+  // underlying RTL insn.  If the instruction is artificial, return\n+  // a unique negative identifier for the instructions.\n+  //\n+  // Note that the identifiers are not linear: it can be the case that\n+  // an instruction with a higher uid comes earlier in a block than an\n+  // instruction with a lower uid.  The identifiers are however persistent;\n+  // the identifier remains the same after the instruction has been moved\n+  // or changed.\n+  int uid () const;\n+\n+  // Return the list of things that this instruction uses.  Registers\n+  // come first, in register number order, followed by memory.\n+  use_array uses () const;\n+\n+  // Return true if the instruction is a call and if the clobbers\n+  // described by insn_callee_abi have been omitted from the list\n+  // of definitions.\n+  bool has_call_clobbers () const;\n+\n+  // Return the list of things that this instruction sets or clobbers.\n+  // Registers come first, in register number order, followed by memory.\n+  //\n+  // If has_call_clobbers () is true, the list omits both the full and\n+  // partial register clobbers described by insn_callee_abi.\n+  def_array defs () const;\n+\n+  // The number of entries in uses ().\n+  unsigned int num_uses () const { return m_num_uses; }\n+\n+  // The number of entries in defs ().\n+  unsigned int num_defs () const { return m_num_defs; }\n+\n+  // Return the cost of the instruction, as calculated by the target.\n+  // For performance reasons, the cost is evaluated lazily on first use.\n+  //\n+  // Artificial instructions have a cost of 0.\n+  unsigned int cost () const;\n+\n+  // Return the first insn_note attached to the instruction, or null\n+  // if none.\n+  insn_note *first_note () const { return m_first_note; }\n+\n+  // See if a note of type T is attached to the instruction.  Return it\n+  // if so, otherwise return null.\n+  template<typename T>\n+  const T *find_note () const;\n+\n+  // Print \"i\" + uid () for real instructions and \"a\" + -uid () for\n+  // artificial instructions.\n+  void print_identifier (pretty_printer *) const;\n+\n+  // Print a short(ish) description of where the instruction is.\n+  void print_location (pretty_printer *) const;\n+\n+  // Combine print_identifier and print_location.\n+  void print_identifier_and_location (pretty_printer *) const;\n+\n+  // Print a full description of the instruction.\n+  void print_full (pretty_printer *) const;\n+\n+private:\n+  // The first-order way of representing the order between instructions\n+  // is to assign \"program points\", with higher point numbers coming\n+  // later in the reverse postorder than lower point numbers.  However,\n+  // after a sequence of instruction movements, we may end up in a situation\n+  // that adjacent instructions have the same program point.\n+  //\n+  // When that happens, we put the instructions into a splay tree that\n+  // records their relative order.  Each node of the splay tree is an\n+  // order_node note that is attached to its respective instruction.\n+  // The root of the splay tree is not stored, since the only thing\n+  // we need the tree for is to compare two nodes.\n+  class order_node : public insn_note\n+  {\n+  public:\n+    static const insn_note_kind kind = insn_note_kind::ORDER_NODE;\n+\n+    order_node (int uid);\n+\n+    // Return the uid of the instruction that this node describes.\n+    int uid () const { return m_data32; }\n+\n+    // The splay tree pointers.\n+    order_node *m_children[2];\n+    order_node *m_parent;\n+  };\n+  using order_splay_tree = default_rootless_splay_tree<order_node *>;\n+\n+  // prev_insn_or_last_debug_insn represents a choice between two things:\n+  //\n+  // (1) A pointer to the previous instruction in the list that has the\n+  //     same is_debug_insn () value, or null if no such instruction exists.\n+  //\n+  // (2) A pointer to the end of a sublist of debug instructions.\n+  //\n+  // (2) is used if this instruction is a debug instruction and the\n+  // previous instruction is not.  (1) is used otherwise.\n+  //\n+  // next_nondebug_or_debug_insn points to the next instruction but also\n+  // records whether that next instruction is a debug instruction or a\n+  // nondebug instruction.\n+  //\n+  // Thus the list is chained as follows:\n+  //\n+  //         ---->        ---->     ---->     ---->     ---->\n+  // NONDEBUG     NONDEBUG     DEBUG     DEBUG     DEBUG     NONDEBUG ...\n+  //         <----    ^     +--     <----     <----  ^    +--\n+  //                  |     |                        |    |\n+  //                  |     +------------------------+    |\n+  //                  |                                   |\n+  //                  +-----------------------------------+\n+  using prev_insn_or_last_debug_insn = pointer_mux<insn_info>;\n+  using next_nondebug_or_debug_insn = pointer_mux<insn_info>;\n+\n+  insn_info (bb_info *bb, rtx_insn *rtl, int cost_or_uid);\n+\n+  static void print_uid (pretty_printer *, int);\n+\n+  void calculate_cost () const;\n+  void set_properties (const rtx_properties &);\n+  void set_accesses (access_info **, unsigned int, unsigned int);\n+  void copy_accesses (access_array, access_array);\n+  void set_cost (unsigned int cost) { m_cost_or_uid = cost; }\n+  void set_bb (bb_info *bb) { m_bb = bb; }\n+\n+  void add_note (insn_note *note);\n+\n+  order_node *get_order_node () const;\n+  order_node *get_known_order_node () const;\n+  int slow_compare_with (const insn_info &) const;\n+\n+  insn_info *last_debug_insn () const;\n+\n+  unsigned int point () const { return m_point; }\n+  void copy_prev_from (insn_info *);\n+  void copy_next_from (insn_info *);\n+  void set_prev_sametype_insn (insn_info *);\n+  void set_last_debug_insn (insn_info *);\n+  void set_next_any_insn (insn_info *);\n+  void set_point (unsigned int point) { m_point = point; }\n+  void clear_insn_links ();\n+  bool has_insn_links ();\n+\n+  // The values returned by the accessors above.\n+  prev_insn_or_last_debug_insn m_prev_insn_or_last_debug_insn;\n+  next_nondebug_or_debug_insn m_next_nondebug_or_debug_insn;\n+  bb_info *m_bb;\n+  rtx_insn *m_rtl;\n+\n+  // The list of definitions followed by the list of uses.\n+  access_info **m_accesses;\n+\n+  // The number of definitions and the number uses.  FIRST_PSEUDO_REGISTER + 1\n+  // is the maximum number of accesses to hard registers and memory, and\n+  // MAX_RECOG_OPERANDS is the maximum number of pseudos that can be\n+  // defined by an instruction, so the number of definitions should fit\n+  // easily in 16 bits.\n+  unsigned int m_num_uses;\n+  unsigned int m_num_defs : 16;\n+\n+  // Flags returned by the accessors above.\n+  unsigned int m_is_debug_insn : 1;\n+  unsigned int m_can_be_optimized : 1;\n+  unsigned int m_is_asm : 1;\n+  unsigned int m_has_pre_post_modify : 1;\n+  unsigned int m_has_volatile_refs : 1;\n+\n+  // For future expansion.\n+  unsigned int m_spare : 11;\n+\n+  // The program point at which the instruction occurs.\n+  //\n+  // Note that the values of the program points are influenced by -g\n+  // and so should not used to make codegen decisions.\n+  unsigned int m_point;\n+\n+  // Negative if the instruction is artificial, nonnegative if it is real.\n+  //\n+  // For real instructions: the cost of the instruction, or UNKNOWN_COST\n+  // if we haven't measured it yet.\n+  //\n+  // For artificial instructions: the (negative) unique identifier of the\n+  // instruction.\n+  mutable int m_cost_or_uid;\n+\n+  // The list of notes that have been attached to the instruction.\n+  insn_note *m_first_note;\n+};\n+\n+// Iterators for unfiltered lists of instructions.\n+using any_insn_iterator = list_iterator<insn_info, &insn_info::next_any_insn>;\n+using reverse_any_insn_iterator\n+  = list_iterator<insn_info, &insn_info::prev_any_insn>;\n+\n+// Iterators for nondebug instructions only.\n+using nondebug_insn_iterator\n+  = list_iterator<insn_info, &insn_info::next_nondebug_insn>;\n+using reverse_nondebug_insn_iterator\n+  = list_iterator<insn_info, &insn_info::prev_nondebug_insn>;\n+\n+// A class that describes an inclusive range of instructions.\n+class insn_range_info\n+{\n+public:\n+  insn_range_info () = default;\n+\n+  // Create a range that contains a singleton instruction.\n+  insn_range_info (insn_info *insn) : first (insn), last (insn) {}\n+\n+  // Create a range [FIRST, LAST], given that *FIRST <= *LAST.\n+  insn_range_info (insn_info *first, insn_info *last);\n+\n+  // Return true if the range contains at least one instruction.\n+  explicit operator bool () const { return *first <= *last; }\n+\n+  bool operator== (const insn_range_info &) const;\n+  bool operator!= (const insn_range_info &) const;\n+\n+  // If the range contains a single instruction, return that instruction,\n+  // otherwise return null.\n+  insn_info *singleton () const;\n+\n+  // Return true if the range includes INSN.\n+  bool includes (insn_info *insn) const;\n+\n+  // If INSN is inside the range, return INSN, otherwise return the\n+  // nearest in-range instruction.\n+  insn_info *clamp_insn_to_range (insn_info *insn) const;\n+\n+  // Return true if this range is a subrange of OTHER, i.e. if OTHER\n+  // includes every instruction that this range does.\n+  bool is_subrange_of (const insn_range_info &other) const;\n+\n+  // The lower and upper bounds of the range.\n+  insn_info *first;\n+  insn_info *last;\n+};\n+\n+// A class that represents a closure of operator== for instructions.\n+// This is used by insn_is; see there for details.\n+class insn_is_closure\n+{\n+public:\n+  insn_is_closure (const insn_info *insn) : m_insn (insn) {}\n+  bool operator() (const insn_info *other) const { return m_insn == other; }\n+\n+private:\n+  const insn_info *m_insn;\n+};\n+\n+void pp_insn (pretty_printer *, const insn_info *);\n+\n+}\n+\n+void dump (FILE *, const rtl_ssa::insn_info *);\n+\n+void DEBUG_FUNCTION debug (const rtl_ssa::insn_info *);"}, {"sha": "00ad6422ee83f18c31d90c35850b2b88606297d9", "filename": "gcc/rtl-ssa/internals.inl", "status": "added", "additions": 682, "deletions": 0, "changes": 682, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Finternals.inl", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Finternals.inl", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Finternals.inl?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,682 @@\n+// Implementation of private inline member functions for RTL SSA    -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// Construct a new access with the given resource () and kind () values.\n+inline access_info::access_info (resource_info resource, access_kind kind)\n+  : m_regno (resource.regno),\n+    m_kind (kind),\n+    m_is_artificial (false),\n+    m_is_set_with_nondebug_insn_uses (false),\n+    m_is_pre_post_modify (false),\n+    m_is_call_clobber (false),\n+    m_is_live_out_use (false),\n+    m_includes_address_uses (false),\n+    m_includes_read_writes (false),\n+    m_includes_subregs (false),\n+    m_includes_multiregs (false),\n+    m_only_occurs_in_notes (false),\n+    m_is_last_nondebug_insn_use (false),\n+    m_is_in_debug_insn_or_phi (false),\n+    m_has_been_superceded (false),\n+    m_is_temp (false),\n+    m_spare (0),\n+    m_mode (resource.mode)\n+{\n+}\n+\n+// Construct a use of RESOURCE in LOCATION.  The resource's value is provided\n+// by DEF, or is completely undefined if DEF is null.\n+inline use_info::use_info (insn_or_phi location, resource_info resource,\n+\t\t\t   set_info *definition)\n+  : access_info (resource, access_kind::USE),\n+    m_insn_or_phi (location),\n+    m_last_use_or_prev_use (nullptr),\n+    m_last_nondebug_insn_use_or_next_use (nullptr),\n+    m_def (definition)\n+{\n+  if (m_insn_or_phi.is_second ())\n+    {\n+      m_is_in_debug_insn_or_phi = true;\n+      m_is_artificial = true;\n+    }\n+  else\n+    {\n+      insn_info *insn = m_insn_or_phi.known_first ();\n+      m_is_in_debug_insn_or_phi = insn->is_debug_insn ();\n+      m_is_artificial = insn->is_artificial ();\n+    }\n+}\n+\n+// Return the correct (uncached) value of m_is_last_nondebug_insn_use.\n+inline bool\n+use_info::calculate_is_last_nondebug_insn_use () const\n+{\n+  use_info *next = next_use ();\n+  return is_in_nondebug_insn () && (!next || next->is_in_debug_insn_or_phi ());\n+}\n+\n+// Accumulate any properties about REF that are also stored in use_infos.\n+// IS_FIRST is true if REF is the first access to resource () that we have\n+// recorded in this way, false if we have already recorded previous\n+// references.\n+inline void\n+use_info::record_reference (rtx_obj_reference ref, bool is_first)\n+{\n+  if (is_first)\n+    {\n+      m_includes_address_uses = ref.in_address ();\n+      m_includes_read_writes = ref.is_write ();\n+      m_includes_subregs = ref.in_subreg ();\n+      m_includes_multiregs = ref.is_multireg ();\n+      m_only_occurs_in_notes = ref.in_note ();\n+    }\n+  else\n+    {\n+      m_includes_address_uses |= ref.in_address ();\n+      m_includes_read_writes |= ref.is_write ();\n+      m_includes_subregs |= ref.in_subreg ();\n+      m_includes_multiregs |= ref.is_multireg ();\n+      m_only_occurs_in_notes &= ref.in_note ();\n+    }\n+}\n+\n+// Change the value of insn () to INSN.\n+inline void\n+use_info::set_insn (insn_info *insn)\n+{\n+  m_insn_or_phi = insn;\n+  m_is_artificial = insn->is_artificial ();\n+}\n+\n+// Copy the overloaded prev link from OTHER.\n+inline void\n+use_info::copy_prev_from (use_info *other)\n+{\n+  m_last_use_or_prev_use = other->m_last_use_or_prev_use;\n+}\n+\n+// Copy the overloaded next link from OTHER.\n+inline void\n+use_info::copy_next_from (use_info *other)\n+{\n+  m_last_nondebug_insn_use_or_next_use\n+    = other->m_last_nondebug_insn_use_or_next_use;\n+  m_is_last_nondebug_insn_use = calculate_is_last_nondebug_insn_use ();\n+}\n+\n+// Record that this use is the first in the list and that the last use is LAST.\n+inline void\n+use_info::set_last_use (use_info *last_use)\n+{\n+  m_last_use_or_prev_use.set_first (last_use);\n+}\n+\n+// Record that this use is not the first in the list and that the previous\n+// use is PREV.\n+inline void\n+use_info::set_prev_use (use_info *prev_use)\n+{\n+  m_last_use_or_prev_use.set_second (prev_use);\n+}\n+\n+// Record that this use is the last use in the list.  If USE is nonnull,\n+// record that USE is the last use in the list by a nondebug instruction,\n+// otherwise record that there are no uses by nondebug instructions\n+// in the list.\n+inline void\n+use_info::set_last_nondebug_insn_use (use_info *use)\n+{\n+  m_last_nondebug_insn_use_or_next_use.set_first (use);\n+  m_is_last_nondebug_insn_use = (use == this);\n+}\n+\n+// Record that this use is not the last in the list and that the next\n+// use is NEXT_USE.\n+inline void\n+use_info::set_next_use (use_info *next_use)\n+{\n+  m_last_nondebug_insn_use_or_next_use.set_second (next_use);\n+  m_is_last_nondebug_insn_use = calculate_is_last_nondebug_insn_use ();\n+}\n+\n+// Clear any information relating to the position of the use in its\n+// definition's list.\n+inline void\n+use_info::clear_use_links ()\n+{\n+  m_last_use_or_prev_use = nullptr;\n+  m_last_nondebug_insn_use_or_next_use = nullptr;\n+  m_is_last_nondebug_insn_use = false;\n+}\n+\n+// Return true if the use has any links to other uses.  This is mostly\n+// for assert checking.\n+inline bool\n+use_info::has_use_links ()\n+{\n+  return (m_last_use_or_prev_use\n+\t  || m_last_nondebug_insn_use_or_next_use\n+\t  || m_is_last_nondebug_insn_use);\n+}\n+\n+// Construct a definition of RESOURCE in INSN, giving it kind KIND.\n+inline def_info::def_info (insn_info *insn, resource_info resource,\n+\t\t\t   access_kind kind)\n+  : access_info (resource, kind),\n+    m_insn (insn),\n+    m_last_def_or_prev_def (nullptr),\n+    m_splay_root_or_next_def (nullptr)\n+{\n+  m_is_artificial = insn->is_artificial ();\n+}\n+\n+// Record any properties about REF that are also stored in def_infos.\n+// IS_FIRST is true if REF is the first access to resource () that we have\n+// recorded in this way, false if we have already recorded previous\n+// references.\n+inline void\n+def_info::record_reference (rtx_obj_reference ref, bool is_first)\n+{\n+  if (is_first)\n+    {\n+      m_is_pre_post_modify = ref.is_pre_post_modify ();\n+      m_includes_read_writes = ref.is_read ();\n+      m_includes_subregs = ref.in_subreg ();\n+      m_includes_multiregs = ref.is_multireg ();\n+    }\n+  else\n+    {\n+      m_is_pre_post_modify |= ref.is_pre_post_modify ();\n+      m_includes_read_writes |= ref.is_read ();\n+      m_includes_subregs |= ref.in_subreg ();\n+      m_includes_multiregs |= ref.is_multireg ();\n+    }\n+}\n+\n+// Return the last definition in the list.  Only valid when is_first ()\n+// is true.\n+inline def_info *\n+def_info::last_def () const\n+{\n+  return m_last_def_or_prev_def.known_first ();\n+}\n+\n+// Return the root of the splay tree of definitions of resource (),\n+// or null if no splay tree has been created for this resource.\n+// Only valid when is_last () is true.\n+inline def_node *\n+def_info::splay_root () const\n+{\n+  return m_splay_root_or_next_def.known_first ();\n+}\n+\n+// Copy the overloaded prev link from OTHER.\n+inline void\n+def_info::copy_prev_from (def_info *other)\n+{\n+  m_last_def_or_prev_def\n+    = other->m_last_def_or_prev_def;\n+}\n+\n+// Copy the overloaded next link from OTHER.\n+inline void\n+def_info::copy_next_from (def_info *other)\n+{\n+  m_splay_root_or_next_def = other->m_splay_root_or_next_def;\n+}\n+\n+// Record that this definition is the first in the list and that the last\n+// definition is LAST.\n+inline void\n+def_info::set_last_def (def_info *last_def)\n+{\n+  m_last_def_or_prev_def.set_first (last_def);\n+}\n+\n+// Record that this definition is not the first in the list and that the\n+// previous definition is PREV.\n+inline void\n+def_info::set_prev_def (def_info *prev_def)\n+{\n+  m_last_def_or_prev_def.set_second (prev_def);\n+}\n+\n+// Record that this definition is the last in the list and that the root\n+// of the splay tree associated with resource () is ROOT.\n+inline void\n+def_info::set_splay_root (def_node *root)\n+{\n+  m_splay_root_or_next_def = root;\n+}\n+\n+// Record that this definition is not the last in the list and that the\n+// next definition is NEXT.\n+inline void\n+def_info::set_next_def (def_info *next_def)\n+{\n+  m_splay_root_or_next_def = next_def;\n+}\n+\n+// Clear the prev and next links\n+inline void\n+def_info::clear_def_links ()\n+{\n+  m_last_def_or_prev_def = nullptr;\n+  m_splay_root_or_next_def = nullptr;\n+}\n+\n+// Return true if the definition has any links to other definitions.\n+// This is mostly for assert checking.\n+inline bool\n+def_info::has_def_links ()\n+{\n+  return m_last_def_or_prev_def || m_splay_root_or_next_def;\n+}\n+\n+// Construct a clobber of register REGNO in insn INSN.\n+inline clobber_info::clobber_info (insn_info *insn, unsigned int regno)\n+  : def_info (insn, { E_BLKmode, regno }, access_kind::CLOBBER),\n+    m_children (),\n+    m_parent (nullptr),\n+    m_group (nullptr)\n+{\n+}\n+\n+// Set the containing group to GROUP, if it isn't already.  The main\n+// use of this function is to update the new root of GROUP's splay tree.\n+inline void\n+clobber_info::update_group (clobber_group *group)\n+{\n+  if (__builtin_expect (m_group != group, 0))\n+    m_group = group;\n+}\n+\n+// Cconstruct a set_info for a store to RESOURCE in INSN, giving it\n+// kind KIND.\n+inline set_info::set_info (insn_info *insn, resource_info resource,\n+\t\t\t   access_kind kind)\n+  : def_info (insn, resource, kind),\n+    m_first_use (nullptr)\n+{\n+}\n+\n+// Cconstruct a set_info for a store to RESOURCE in INSN.\n+inline set_info::set_info (insn_info *insn, resource_info resource)\n+  : set_info (insn, resource, access_kind::SET)\n+{\n+}\n+\n+// Record that USE is the first use of this definition.\n+inline void\n+set_info::set_first_use (use_info *first_use)\n+{\n+  m_first_use = first_use;\n+  m_is_set_with_nondebug_insn_uses\n+    = (first_use && first_use->is_in_nondebug_insn ());\n+}\n+\n+// Construct a phi for RESOURCE in INSN, giving it identifier UID.\n+inline phi_info::phi_info (insn_info *insn, resource_info resource,\n+\t\t\t   unsigned int uid)\n+  : set_info (insn, resource, access_kind::PHI),\n+    m_uid (uid),\n+    m_num_inputs (0),\n+    m_prev_phi (nullptr),\n+    m_next_phi (nullptr)\n+{\n+}\n+\n+// Turn the phi into a degenerate phi, with INPUT representing the\n+// value of the resource on all incoming edges.\n+inline void\n+phi_info::make_degenerate (use_info *input)\n+{\n+  m_num_inputs = 1;\n+  m_single_input = input;\n+}\n+\n+// Set the inputs of the phi to INPUTS.\n+inline void\n+phi_info::set_inputs (use_array inputs)\n+{\n+  m_num_inputs = inputs.size ();\n+  if (inputs.size () == 1)\n+    m_single_input = inputs[0];\n+  else\n+    m_inputs = access_array (inputs).begin ();\n+}\n+\n+// Construct a definition splay tree node for FIRST_DEF, which is either\n+// the first clobber_info in a group or a standalone set_info.\n+inline def_node::def_node (clobber_or_set first_def)\n+  : m_clobber_or_set (first_def),\n+    m_children ()\n+{\n+}\n+\n+// Construct a new group of clobber_infos that initially contains just CLOBBER.\n+inline clobber_group::clobber_group (clobber_info *clobber)\n+  : def_node (clobber),\n+    m_last_clobber (clobber),\n+    m_clobber_tree (clobber)\n+{\n+  clobber->m_group = this;\n+}\n+\n+// Construct a node for the instruction with uid UID.\n+inline insn_info::order_node::order_node (int uid)\n+  : insn_note (kind),\n+    m_children (),\n+    m_parent (nullptr)\n+{\n+  m_data32 = uid;\n+}\n+\n+// Construct a note for instruction INSN, giving it abi_id () value ABI_ID.\n+inline insn_call_clobbers_note::insn_call_clobbers_note (unsigned int abi_id,\n+\t\t\t\t\t\t\t insn_info *insn)\n+  : insn_note (kind),\n+    m_children (),\n+    m_insn (insn)\n+{\n+  m_data32 = abi_id;\n+}\n+\n+// Construct an instruction with the given bb () and rtl () values.\n+// If the instruction is real, COST_OR_UID is the value of cost (),\n+// otherwise it is the value of uid ().\n+inline insn_info::insn_info (bb_info *bb, rtx_insn *rtl, int cost_or_uid)\n+  : m_prev_insn_or_last_debug_insn (nullptr),\n+    m_next_nondebug_or_debug_insn (nullptr),\n+    m_bb (bb),\n+    m_rtl (rtl),\n+    m_accesses (nullptr),\n+    m_num_uses (0),\n+    m_num_defs (0),\n+    m_is_debug_insn (rtl && DEBUG_INSN_P (rtl)),\n+    m_can_be_optimized (false),\n+    m_is_asm (false),\n+    m_has_pre_post_modify (false),\n+    m_has_volatile_refs (false),\n+    m_spare (0),\n+    m_point (0),\n+    m_cost_or_uid (cost_or_uid),\n+    m_first_note (nullptr)\n+{\n+}\n+\n+// Copy any insn properties from PROPERTIES that are also stored in an\n+// insn_info.\n+inline void\n+insn_info::set_properties (const rtx_properties &properties)\n+{\n+  m_is_asm = properties.has_asm;\n+  m_has_pre_post_modify = properties.has_pre_post_modify;\n+  m_has_volatile_refs = properties.has_volatile_refs;\n+  // Not strictly related to the properties we've been given, but it's\n+  // a convenient location to do this.\n+  m_can_be_optimized = (NONDEBUG_INSN_P (m_rtl)\n+\t\t\t& (GET_CODE (PATTERN (m_rtl)) != USE)\n+\t\t\t& (GET_CODE (PATTERN (m_rtl)) != CLOBBER));\n+}\n+\n+// Change the list of instruction accesses to ACCESSES, which contains\n+// NUM_DEFS definitions followed by NUM_USES uses.\n+inline void\n+insn_info::set_accesses (access_info **accesses,\n+\t\t\t unsigned int num_defs, unsigned int num_uses)\n+{\n+  m_accesses = accesses;\n+  m_num_defs = num_defs;\n+  gcc_assert (num_defs == m_num_defs);\n+  m_num_uses = num_uses;\n+}\n+\n+// Change defs () and uses () to DEFS and USES respectively, given that\n+// the existing m_accesses array has enough room for them.\n+inline void\n+insn_info::copy_accesses (access_array defs, access_array uses)\n+{\n+  gcc_assert (defs.size () + uses.size () <= m_num_defs + m_num_uses);\n+  memcpy (m_accesses, defs.begin (), defs.size_bytes ());\n+  memcpy (m_accesses + defs.size (), uses.begin (), uses.size_bytes ());\n+  m_num_defs = defs.size ();\n+  gcc_assert (m_num_defs == defs.size ());\n+  m_num_uses = uses.size ();\n+}\n+\n+// If the instruction has an insn_info::order_node, return the node,\n+// otherwise return null.\n+inline insn_info::order_node *\n+insn_info::get_order_node () const\n+{\n+  // The order_node always comes first.\n+  if (insn_note *note = first_note ())\n+    return note->dyn_cast<insn_info::order_node *> ();\n+  return nullptr;\n+}\n+\n+// Like get_order_node (), but the node is known to exist.\n+inline insn_info::order_node *\n+insn_info::get_known_order_node () const\n+{\n+  // The order_node always comes first.\n+  return first_note ()->as_a<insn_info::order_node *> ();\n+}\n+\n+// Copy the overloaded prev link from OTHER.\n+inline void\n+insn_info::copy_prev_from (insn_info *other)\n+{\n+  m_prev_insn_or_last_debug_insn = other->m_prev_insn_or_last_debug_insn;\n+}\n+\n+// Copy the overloaded next link from OTHER.\n+inline void\n+insn_info::copy_next_from (insn_info *other)\n+{\n+  m_next_nondebug_or_debug_insn = other->m_next_nondebug_or_debug_insn;\n+}\n+\n+// If this is a nondebug instruction, record that the previous nondebug\n+// instruction is PREV.  (There might be intervening debug instructions.)\n+//\n+// If this is a debug instruction, record that the previous instruction\n+// is debug instruction PREV.\n+inline void\n+insn_info::set_prev_sametype_insn (insn_info *prev)\n+{\n+  m_prev_insn_or_last_debug_insn.set_first (prev);\n+}\n+\n+// Only valid for debug instructions.  Record that this instruction starts\n+// a subsequence of debug instructions that ends with LAST.\n+inline void\n+insn_info::set_last_debug_insn (insn_info *last)\n+{\n+  m_prev_insn_or_last_debug_insn.set_second (last);\n+}\n+\n+// Record that the next instruction of any kind is NEXT.\n+inline void\n+insn_info::set_next_any_insn (insn_info *next)\n+{\n+  if (next && next->is_debug_insn ())\n+    m_next_nondebug_or_debug_insn.set_second (next);\n+  else\n+    m_next_nondebug_or_debug_insn.set_first (next);\n+}\n+\n+// Clear the list links and point number for this instruction.\n+inline void\n+insn_info::clear_insn_links ()\n+{\n+  m_prev_insn_or_last_debug_insn = nullptr;\n+  m_next_nondebug_or_debug_insn = nullptr;\n+  m_point = 0;\n+}\n+\n+// Return true if the instruction contains any list information.\n+// This is used by assert checking.\n+inline bool\n+insn_info::has_insn_links ()\n+{\n+  return (m_prev_insn_or_last_debug_insn\n+\t  || m_next_nondebug_or_debug_insn\n+\t  || m_point);\n+}\n+\n+// Construct a representation of basic block CFG_BB.\n+inline bb_info::bb_info (basic_block cfg_bb)\n+  : m_prev_bb (nullptr),\n+    m_next_bb (nullptr),\n+    m_cfg_bb (cfg_bb),\n+    m_ebb (nullptr),\n+    m_head_insn (nullptr),\n+    m_end_insn (nullptr)\n+{\n+}\n+\n+// Construct a tree of call clobbers for the given ABI.\n+inline ebb_call_clobbers_info::\n+ebb_call_clobbers_info (const predefined_function_abi *abi)\n+  : m_next (nullptr),\n+    m_abi (abi)\n+{\n+}\n+\n+// Construct an EBB whose first block is FIRST_BB and whose last block\n+// is LAST_BB.\n+inline ebb_info::ebb_info (bb_info *first_bb, bb_info *last_bb)\n+  : m_first_phi (nullptr),\n+    m_phi_insn (nullptr),\n+    m_first_bb (first_bb),\n+    m_last_bb (last_bb),\n+    m_first_call_clobbers (nullptr)\n+{\n+}\n+\n+// Set the contents of last_access for register REGNO to DEF.\n+inline void\n+function_info::build_info::record_reg_def (unsigned int regno, def_info *def)\n+{\n+  last_access[regno + 1] = def;\n+}\n+\n+// Set the contents of last_access for memory to DEF.\n+inline void\n+function_info::build_info::record_mem_def (def_info *def)\n+{\n+  last_access[0] = def;\n+}\n+\n+// Return the current value of live register REGNO, or null if the register's\n+// value is completedly undefined.\n+inline set_info *\n+function_info::build_info::current_reg_value (unsigned int regno) const\n+{\n+  return safe_dyn_cast<set_info *> (last_access[regno + 1]);\n+}\n+\n+// Return the current value of memory.\n+inline set_info *\n+function_info::build_info::current_mem_value () const\n+{\n+  return as_a<set_info *> (last_access[0]);\n+}\n+\n+// Allocate a T on the function's main obstack, passing ARGS\n+// to its constructor.\n+template<typename T, typename... Ts>\n+inline T *\n+function_info::allocate (Ts... args)\n+{\n+  static_assert (std::is_trivially_destructible<T>::value,\n+\t\t \"destructor won't be called\");\n+  static_assert (alignof (T) <= obstack_alignment,\n+\t\t \"too much alignment required\");\n+  void *addr = obstack_alloc (&m_obstack, sizeof (T));\n+  return new (addr) T (std::forward<Ts> (args)...);\n+}\n+\n+// Allocate a T on the function's temporary obstack, passing ARGS\n+// to its constructor.\n+template<typename T, typename... Ts>\n+inline T *\n+function_info::allocate_temp (Ts... args)\n+{\n+  static_assert (std::is_trivially_destructible<T>::value,\n+\t\t \"destructor won't be called\");\n+  static_assert (alignof (T) <= obstack_alignment,\n+\t\t \"too much alignment required\");\n+  void *addr = obstack_alloc (&m_temp_obstack, sizeof (T));\n+  return new (addr) T (std::forward<Ts> (args)...);\n+}\n+\n+// Add INSN to the end of the function's list of instructions.\n+inline void\n+function_info::append_insn (insn_info *insn)\n+{\n+  gcc_checking_assert (!insn->has_insn_links ());\n+  if (insn_info *after = m_last_insn)\n+    add_insn_after (insn, after);\n+  else\n+    // The first instruction is for the entry block and is always a nondebug\n+    // insn\n+    m_first_insn = m_last_insn = m_last_nondebug_insn = insn;\n+}\n+\n+// Start building a new list of uses and definitions for an instruction.\n+inline void\n+function_info::start_insn_accesses ()\n+{\n+  gcc_checking_assert (m_temp_defs.is_empty ()\n+\t\t       && m_temp_uses.is_empty ());\n+}\n+\n+// Return a mode that encapsulates two distinct references to a register,\n+// one with mode MODE1 and one with mode MODE2.  Treat BLKmode as a\n+// \"don't know\" wildcard.\n+inline machine_mode\n+combine_modes (machine_mode mode1, machine_mode mode2)\n+{\n+  if (mode1 == E_BLKmode)\n+    return mode2;\n+\n+  if (mode2 == E_BLKmode)\n+    return mode1;\n+\n+  return wider_subreg_mode (mode1, mode2);\n+}\n+\n+// PRINTER (PP, ARGS...) prints ARGS... to a pretty_printer PP.  Use it\n+// to print ARGS... to FILE.\n+template<typename Printer, typename... Args>\n+inline void\n+dump_using (FILE *file, Printer printer, Args... args)\n+{\n+  pretty_printer pp;\n+  printer (&pp, args...);\n+  pp_newline (&pp);\n+  fprintf (file, \"%s\", pp_formatted_text (&pp));\n+}\n+\n+}"}, {"sha": "14e1316b6c02ee71f7f812f88437379705881eae", "filename": "gcc/rtl-ssa/is-a.inl", "status": "added", "additions": 98, "deletions": 0, "changes": 98, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fis-a.inl", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fis-a.inl", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Fis-a.inl?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,98 @@\n+// is_a<> support for RTL SSA classes                               -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+template<>\n+struct is_a_helper<rtl_ssa::def_info *>\n+  : static_is_a_helper<rtl_ssa::def_info *>\n+{\n+  static inline bool\n+  test (const rtl_ssa::access_info *ref)\n+  {\n+    return (ref->kind () == rtl_ssa::access_kind::SET\n+\t    || ref->kind () == rtl_ssa::access_kind::PHI\n+\t    || ref->kind () == rtl_ssa::access_kind::CLOBBER);\n+  }\n+};\n+\n+template<>\n+struct is_a_helper<rtl_ssa::clobber_info *>\n+  : static_is_a_helper<rtl_ssa::clobber_info *>\n+{\n+  static inline bool\n+  test (const rtl_ssa::access_info *ref)\n+  {\n+    return ref->kind () == rtl_ssa::access_kind::CLOBBER;\n+  }\n+};\n+\n+template<>\n+struct is_a_helper<rtl_ssa::use_info *>\n+  : static_is_a_helper<rtl_ssa::use_info *>\n+{\n+  static inline bool\n+  test (const rtl_ssa::access_info *ref)\n+  {\n+    return ref->kind () == rtl_ssa::access_kind::USE;\n+  }\n+};\n+\n+template<>\n+struct is_a_helper<rtl_ssa::set_info *>\n+  : static_is_a_helper<rtl_ssa::set_info *>\n+{\n+  static inline bool\n+  test (const rtl_ssa::access_info *ref)\n+  {\n+    return (ref->kind () == rtl_ssa::access_kind::SET\n+\t    || ref->kind () == rtl_ssa::access_kind::PHI);\n+  }\n+};\n+\n+template<>\n+struct is_a_helper<rtl_ssa::phi_info *>\n+  : static_is_a_helper<rtl_ssa::phi_info *>\n+{\n+  static inline bool\n+  test (const rtl_ssa::access_info *ref)\n+  {\n+    return ref->kind () == rtl_ssa::access_kind::PHI;\n+  }\n+};\n+\n+template<>\n+struct is_a_helper<rtl_ssa::set_node *>\n+  : static_is_a_helper<rtl_ssa::set_node *>\n+{\n+  static inline bool\n+  test (const rtl_ssa::def_node *node)\n+  {\n+    return node->contains_set ();\n+  }\n+};\n+\n+template<>\n+struct is_a_helper<rtl_ssa::clobber_group *>\n+  : static_is_a_helper<rtl_ssa::clobber_group *>\n+{\n+  static inline bool\n+  test (const rtl_ssa::def_node *node)\n+  {\n+    return node->contains_clobber ();\n+  }\n+};"}, {"sha": "4f3bb2e151870e32a0bdef2228e4e41848aebe39", "filename": "gcc/rtl-ssa/member-fns.inl", "status": "added", "additions": 928, "deletions": 0, "changes": 928, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fmember-fns.inl", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fmember-fns.inl", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Fmember-fns.inl?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,928 @@\n+// Implementation of public inline member functions for RTL SSA     -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+// This file contains inline implementations of public member functions that\n+// are too large to be written in the class definition.  It also contains\n+// some non-inline template definitions of public member functions.\n+// See the comments above the function declarations for details.\n+//\n+// The file also contains the bare minimum of private and protected inline\n+// member functions that are needed to make the public functions compile.\n+namespace rtl_ssa {\n+\n+inline void\n+access_array_builder::reserve (unsigned int num_accesses)\n+{\n+  obstack_make_room (m_obstack, num_accesses * sizeof (access_info *));\n+}\n+\n+inline void\n+access_array_builder::quick_push (access_info *access)\n+{\n+  obstack_ptr_grow_fast (m_obstack, access);\n+}\n+\n+inline array_slice<access_info *>\n+access_array_builder::finish ()\n+{\n+  auto num_accesses = obstack_object_size (m_obstack) / sizeof (access_info *);\n+  if (num_accesses == 0)\n+    return {};\n+\n+  auto **base = static_cast<access_info **> (obstack_finish (m_obstack));\n+  keep ();\n+  return { base, num_accesses };\n+}\n+\n+inline bool\n+access_info::is_set_with_nondebug_insn_uses () const\n+{\n+  return m_is_set_with_nondebug_insn_uses;\n+}\n+\n+inline bool\n+use_info::is_in_debug_insn () const\n+{\n+  return m_insn_or_phi.is_first () && m_is_in_debug_insn_or_phi;\n+}\n+\n+inline bb_info *\n+use_info::bb () const\n+{\n+  if (m_insn_or_phi.is_first ())\n+    return m_insn_or_phi.known_first ()->bb ();\n+  return m_insn_or_phi.known_second ()->bb ();\n+}\n+\n+inline ebb_info *\n+use_info::ebb () const\n+{\n+  return bb ()->ebb ();\n+}\n+\n+inline use_info *\n+use_info::prev_use () const\n+{\n+  return m_last_use_or_prev_use.second_or_null ();\n+}\n+\n+inline use_info *\n+use_info::next_use () const\n+{\n+  return m_last_nondebug_insn_use_or_next_use.second_or_null ();\n+}\n+\n+inline bool\n+use_info::is_first_use () const\n+{\n+  return m_last_use_or_prev_use.is_first ();\n+}\n+\n+inline bool\n+use_info::is_last_use () const\n+{\n+  return m_last_nondebug_insn_use_or_next_use.is_first ();\n+}\n+\n+inline use_info *\n+use_info::next_nondebug_insn_use () const\n+{\n+  if (m_is_last_nondebug_insn_use)\n+    return nullptr;\n+  return m_last_nondebug_insn_use_or_next_use.known_second ();\n+}\n+\n+inline use_info *\n+use_info::next_any_insn_use () const\n+{\n+  // This is used less often than next_nondebug_insn_use, so it doesn't\n+  // seem worth having an m_is_last_nondebug_insn_use-style end marker.\n+  if (use_info *use = next_use ())\n+    if (use->is_in_any_insn ())\n+      return use;\n+  return nullptr;\n+}\n+\n+inline use_info *\n+use_info::prev_phi_use () const\n+{\n+  // This is used less often than next_nondebug_insn_use, so it doesn't\n+  // seem worth having an m_is_last_nondebug_insn_use-style end marker.\n+  if (use_info *use = prev_use ())\n+    if (use->is_in_phi ())\n+      return use;\n+  return nullptr;\n+}\n+\n+// Return the last use of any kind in the list.  Only valid when is_first ()\n+// is true.\n+inline use_info *\n+use_info::last_use () const\n+{\n+  return m_last_use_or_prev_use.known_first ();\n+}\n+\n+// Return the last nondebug insn use in the list, or null if none.  Only valid\n+// when is_last_use () is true.\n+inline use_info *\n+use_info::last_nondebug_insn_use () const\n+{\n+  return m_last_nondebug_insn_use_or_next_use.known_first ();\n+}\n+\n+inline def_info *\n+def_info::prev_def () const\n+{\n+  return m_last_def_or_prev_def.second_or_null ();\n+}\n+\n+inline def_info *\n+def_info::next_def () const\n+{\n+  return m_splay_root_or_next_def.second_or_null ();\n+}\n+\n+inline bool\n+def_info::is_first_def () const\n+{\n+  return m_last_def_or_prev_def.is_first ();\n+}\n+\n+inline bool\n+def_info::is_last_def () const\n+{\n+  return m_splay_root_or_next_def.is_first ();\n+}\n+\n+inline bb_info *\n+def_info::bb () const\n+{\n+  return m_insn->bb ();\n+}\n+\n+inline ebb_info *\n+def_info::ebb () const\n+{\n+  return m_insn->ebb ();\n+}\n+\n+inline clobber_group *\n+clobber_info::group () const\n+{\n+  if (!m_group || !m_group->has_been_superceded ())\n+    return m_group;\n+  return const_cast<clobber_info *> (this)->recompute_group ();\n+}\n+\n+inline use_info *\n+set_info::last_use () const\n+{\n+  return m_first_use ? m_first_use->last_use () : nullptr;\n+}\n+\n+inline use_info *\n+set_info::first_nondebug_insn_use () const\n+{\n+  if (m_is_set_with_nondebug_insn_uses)\n+    return m_first_use;\n+  return nullptr;\n+}\n+\n+inline use_info *\n+set_info::last_nondebug_insn_use () const\n+{\n+  if (m_is_set_with_nondebug_insn_uses)\n+    return m_first_use->last_use ()->last_nondebug_insn_use ();\n+  return nullptr;\n+}\n+\n+inline use_info *\n+set_info::first_any_insn_use () const\n+{\n+  if (m_first_use->is_in_any_insn ())\n+    return m_first_use;\n+  return nullptr;\n+}\n+\n+inline use_info *\n+set_info::last_phi_use () const\n+{\n+  if (m_first_use)\n+    {\n+      use_info *last = m_first_use->last_use ();\n+      if (last->is_in_phi ())\n+\treturn last;\n+    }\n+  return nullptr;\n+}\n+\n+inline bool\n+set_info::has_nondebug_uses () const\n+{\n+  return has_nondebug_insn_uses () || has_phi_uses ();\n+}\n+\n+inline bool\n+set_info::has_nondebug_insn_uses () const\n+{\n+  return m_is_set_with_nondebug_insn_uses;\n+}\n+\n+inline bool\n+set_info::has_phi_uses () const\n+{\n+  return m_first_use && m_first_use->last_use ()->is_in_phi ();\n+}\n+\n+inline bool\n+set_info::is_local_to_ebb () const\n+{\n+  if (!m_first_use)\n+    return true;\n+\n+  use_info *last = m_first_use->last_use ();\n+  if (last->is_in_phi ())\n+    return false;\n+\n+  last = last->last_nondebug_insn_use ();\n+  return !last || last->ebb () == ebb ();\n+}\n+\n+inline iterator_range<use_iterator>\n+set_info::all_uses () const\n+{\n+  return { m_first_use, nullptr };\n+}\n+\n+inline iterator_range<reverse_use_iterator>\n+set_info::reverse_all_uses () const\n+{\n+  return { last_use (), nullptr };\n+}\n+\n+inline iterator_range<nondebug_insn_use_iterator>\n+set_info::nondebug_insn_uses () const\n+{\n+  return { first_nondebug_insn_use (), nullptr };\n+}\n+\n+inline iterator_range<reverse_use_iterator>\n+set_info::reverse_nondebug_insn_uses () const\n+{\n+  return { last_nondebug_insn_use (), nullptr };\n+}\n+\n+inline iterator_range<any_insn_use_iterator>\n+set_info::all_insn_uses () const\n+{\n+  return { first_any_insn_use (), nullptr };\n+}\n+\n+inline iterator_range<phi_use_iterator>\n+set_info::phi_uses () const\n+{\n+  return { last_phi_use (), nullptr };\n+}\n+\n+inline use_array\n+phi_info::inputs () const\n+{\n+  if (m_num_inputs == 1)\n+    return use_array (&m_single_input, 1);\n+  return use_array (m_inputs, m_num_inputs);\n+}\n+\n+inline use_info *\n+phi_info::input_use (unsigned int i) const\n+{\n+  if (m_num_inputs == 1)\n+    return as_a<use_info *> (m_single_input);\n+  return as_a<use_info *> (m_inputs[i]);\n+}\n+\n+inline set_info *\n+phi_info::input_value (unsigned int i) const\n+{\n+  return input_use (i)->def ();\n+}\n+\n+inline def_info *\n+def_node::first_def () const\n+{\n+  // This should get optimized into an AND with -2.\n+  if (m_clobber_or_set.is_first ())\n+    return m_clobber_or_set.known_first ();\n+  return m_clobber_or_set.known_second ();\n+}\n+\n+inline clobber_info *\n+clobber_group::first_clobber () const\n+{\n+  return m_clobber_or_set.known_first ();\n+}\n+\n+inline iterator_range<def_iterator>\n+clobber_group::clobbers () const\n+{\n+  return { first_clobber (), m_last_clobber->next_def () };\n+}\n+\n+inline def_info *\n+def_mux::first_def () const\n+{\n+  if (is_first ())\n+    return known_first ();\n+  return known_second ()->first_def ();\n+}\n+\n+inline def_info *\n+def_mux::last_def () const\n+{\n+  if (is_first ())\n+    return known_first ();\n+\n+  def_node *node = known_second ();\n+  if (auto *clobber = ::dyn_cast<clobber_group *> (node))\n+    return clobber->last_clobber ();\n+\n+  return node->first_def ();\n+}\n+\n+inline set_info *\n+def_mux::set () const\n+{\n+  if (is_first ())\n+    return ::safe_dyn_cast<set_info *> (known_first ());\n+  return ::dyn_cast<set_info *> (known_second ()->first_def ());\n+}\n+\n+inline def_info *\n+def_lookup::prev_def () const\n+{\n+  if (!mux)\n+    return nullptr;\n+\n+  if (comparison > 0)\n+    return mux.last_def ();\n+\n+  return mux.first_def ()->prev_def ();\n+}\n+\n+inline def_info *\n+def_lookup::next_def () const\n+{\n+  if (!mux)\n+    return nullptr;\n+\n+  if (comparison < 0)\n+    return mux.first_def ();\n+\n+  return mux.last_def ()->next_def ();\n+}\n+\n+inline set_info *\n+def_lookup::matching_set () const\n+{\n+  if (comparison == 0)\n+    return mux.set ();\n+  return nullptr;\n+}\n+\n+inline def_info *\n+def_lookup::matching_or_prev_def () const\n+{\n+  if (set_info *set = matching_set ())\n+    return set;\n+  return prev_def ();\n+}\n+\n+inline def_info *\n+def_lookup::matching_or_next_def () const\n+{\n+  if (set_info *set = matching_set ())\n+    return set;\n+  return next_def ();\n+}\n+\n+inline insn_note::insn_note (insn_note_kind kind)\n+  : m_next_note (nullptr),\n+    m_kind (kind),\n+    m_data8 (0),\n+    m_data16 (0),\n+    m_data32 (0)\n+{\n+}\n+\n+template<typename T>\n+inline T\n+insn_note::as_a ()\n+{\n+  using deref_type = decltype (*std::declval<T> ());\n+  using derived = typename std::remove_reference<deref_type>::type;\n+  gcc_checking_assert (m_kind == derived::kind);\n+  return static_cast<T> (this);\n+}\n+\n+template<typename T>\n+inline T\n+insn_note::dyn_cast ()\n+{\n+  using deref_type = decltype (*std::declval<T> ());\n+  using derived = typename std::remove_reference<deref_type>::type;\n+  if (m_kind == derived::kind)\n+    return static_cast<T> (this);\n+  return nullptr;\n+}\n+\n+inline bool\n+insn_info::operator< (const insn_info &other) const\n+{\n+  if (this == &other)\n+    return false;\n+\n+  if (__builtin_expect (m_point != other.m_point, 1))\n+    return m_point < other.m_point;\n+\n+  return slow_compare_with (other) < 0;\n+}\n+\n+inline bool\n+insn_info::operator> (const insn_info &other) const\n+{\n+  return other < *this;\n+}\n+\n+inline bool\n+insn_info::operator<= (const insn_info &other) const\n+{\n+  return !(other < *this);\n+}\n+\n+inline bool\n+insn_info::operator>= (const insn_info &other) const\n+{\n+  return !(*this < other);\n+}\n+\n+inline int\n+insn_info::compare_with (const insn_info *other) const\n+{\n+  if (this == other)\n+    return 0;\n+\n+  if (__builtin_expect (m_point != other->m_point, 1))\n+    // Assume that points remain in [0, INT_MAX].\n+    return m_point - other->m_point;\n+\n+  return slow_compare_with (*other);\n+}\n+\n+inline insn_info *\n+insn_info::prev_nondebug_insn () const\n+{\n+  gcc_checking_assert (!is_debug_insn ());\n+  return m_prev_insn_or_last_debug_insn.known_first ();\n+}\n+\n+inline insn_info *\n+insn_info::next_nondebug_insn () const\n+{\n+  gcc_checking_assert (!is_debug_insn ());\n+  const insn_info *from = this;\n+  if (insn_info *first_debug = m_next_nondebug_or_debug_insn.second_or_null ())\n+    from = first_debug->last_debug_insn ();\n+  return from->m_next_nondebug_or_debug_insn.known_first ();\n+}\n+\n+inline insn_info *\n+insn_info::prev_any_insn () const\n+{\n+  const insn_info *from = this;\n+  if (insn_info *last_debug = m_prev_insn_or_last_debug_insn.second_or_null ())\n+    // This instruction is the first in a subsequence of debug instructions.\n+    // Move to the following nondebug instruction.\n+    from = last_debug->m_next_nondebug_or_debug_insn.known_first ();\n+  return from->m_prev_insn_or_last_debug_insn.known_first ();\n+}\n+\n+inline insn_info *\n+insn_info::next_any_insn () const\n+{\n+  // This should get optimized into an AND with -2.\n+  if (m_next_nondebug_or_debug_insn.is_first ())\n+    return m_next_nondebug_or_debug_insn.known_first ();\n+  return m_next_nondebug_or_debug_insn.known_second ();\n+}\n+\n+inline bool\n+insn_info::is_phi () const\n+{\n+  return this == ebb ()->phi_insn ();\n+}\n+\n+inline bool\n+insn_info::is_bb_head () const\n+{\n+  return this == m_bb->head_insn ();\n+}\n+\n+inline bool\n+insn_info::is_bb_end () const\n+{\n+  return this == m_bb->end_insn ();\n+}\n+\n+inline ebb_info *\n+insn_info::ebb () const\n+{\n+  return m_bb->ebb ();\n+}\n+\n+inline int\n+insn_info::uid () const\n+{\n+  return m_cost_or_uid < 0 ? m_cost_or_uid : INSN_UID (m_rtl);\n+}\n+\n+inline use_array\n+insn_info::uses () const\n+{\n+  return use_array (m_accesses + m_num_defs, m_num_uses);\n+}\n+\n+inline bool\n+insn_info::has_call_clobbers () const\n+{\n+  return find_note<insn_call_clobbers_note> ();\n+}\n+\n+inline def_array\n+insn_info::defs () const\n+{\n+  return def_array (m_accesses, m_num_defs);\n+}\n+\n+inline unsigned int\n+insn_info::cost () const\n+{\n+  if (m_cost_or_uid < 0)\n+    return 0;\n+  if (m_cost_or_uid == UNKNOWN_COST)\n+    calculate_cost ();\n+  return m_cost_or_uid;\n+}\n+\n+template<typename T>\n+inline const T *\n+insn_info::find_note () const\n+{\n+  // We could break if the note kind is > T::kind, but since the number\n+  // of notes should be very small, the check is unlikely to pay for itself.\n+  for (const insn_note *note = first_note (); note; note = note->next_note ())\n+    if (note->kind () == T::kind)\n+      return static_cast<const T *> (note);\n+  return nullptr;\n+}\n+\n+// Only valid for debug instructions that come after a nondebug instruction,\n+// and so start a subsequence of debug instructions.  Return the last debug\n+// instruction in the subsequence.\n+inline insn_info *\n+insn_info::last_debug_insn () const\n+{\n+  return m_prev_insn_or_last_debug_insn.known_second ();\n+}\n+\n+inline insn_range_info::insn_range_info (insn_info *first, insn_info *last)\n+  : first (first), last (last)\n+{\n+}\n+\n+inline bool\n+insn_range_info::operator== (const insn_range_info &other) const\n+{\n+  return first == other.first && last == other.last;\n+}\n+\n+inline bool\n+insn_range_info::operator!= (const insn_range_info &other) const\n+{\n+  return first != other.first || last != other.last;\n+}\n+\n+inline insn_info *\n+insn_range_info::singleton () const\n+{\n+  return first == last ? last : nullptr;\n+}\n+\n+inline bool\n+insn_range_info::includes (insn_info *insn) const\n+{\n+  return *insn >= *first && *insn <= *last;\n+}\n+\n+inline insn_info *\n+insn_range_info::clamp_insn_to_range (insn_info *insn) const\n+{\n+  if (*first > *insn)\n+    return first;\n+  if (*last < *insn)\n+    return last;\n+  return insn;\n+}\n+\n+inline bool\n+insn_range_info::is_subrange_of (const insn_range_info &other) const\n+{\n+  return *first >= *other.first && *last <= *other.last;\n+}\n+\n+inline iterator_range<any_insn_iterator>\n+bb_info::all_insns () const\n+{\n+  return { m_head_insn, m_end_insn->next_any_insn () };\n+}\n+\n+inline iterator_range<reverse_any_insn_iterator>\n+bb_info::reverse_all_insns () const\n+{\n+  return { m_end_insn, m_head_insn->prev_any_insn () };\n+}\n+\n+inline iterator_range<nondebug_insn_iterator>\n+bb_info::nondebug_insns () const\n+{\n+  return { m_head_insn, m_end_insn->next_nondebug_insn () };\n+}\n+\n+inline iterator_range<reverse_nondebug_insn_iterator>\n+bb_info::reverse_nondebug_insns () const\n+{\n+  return { m_end_insn, m_head_insn->prev_nondebug_insn () };\n+}\n+\n+inline iterator_range<any_insn_iterator>\n+bb_info::real_insns () const\n+{\n+  return { m_head_insn->next_any_insn (), m_end_insn };\n+}\n+\n+inline iterator_range<reverse_any_insn_iterator>\n+bb_info::reverse_real_insns () const\n+{\n+  return { m_end_insn->prev_any_insn (), m_head_insn };\n+}\n+\n+inline iterator_range<nondebug_insn_iterator>\n+bb_info::real_nondebug_insns () const\n+{\n+  return { m_head_insn->next_nondebug_insn (), m_end_insn };\n+}\n+\n+inline iterator_range<reverse_nondebug_insn_iterator>\n+bb_info::reverse_real_nondebug_insns () const\n+{\n+  return { m_end_insn->prev_nondebug_insn (), m_head_insn };\n+}\n+\n+inline bool\n+ebb_call_clobbers_info::clobbers (resource_info resource) const\n+{\n+  // Only register clobbers are tracked this way.  Other clobbers are\n+  // recorded explicitly.\n+  return (resource.is_reg ()\n+\t  && m_abi->clobbers_reg_p (resource.mode, resource.regno));\n+}\n+\n+inline ebb_info *\n+ebb_info::prev_ebb () const\n+{\n+  if (bb_info *prev_bb = m_first_bb->prev_bb ())\n+    return prev_bb->ebb ();\n+  return nullptr;\n+}\n+\n+inline ebb_info *\n+ebb_info::next_ebb () const\n+{\n+  if (bb_info *next_bb = m_last_bb->next_bb ())\n+    return next_bb->ebb ();\n+  return nullptr;\n+}\n+\n+inline iterator_range<phi_iterator>\n+ebb_info::phis () const\n+{\n+  return { m_first_phi, nullptr };\n+}\n+\n+inline iterator_range<bb_iterator>\n+ebb_info::bbs () const\n+{\n+  return { m_first_bb, m_last_bb->next_bb () };\n+}\n+\n+inline iterator_range<reverse_bb_iterator>\n+ebb_info::reverse_bbs () const\n+{\n+  return { m_last_bb, m_first_bb->prev_bb () };\n+}\n+\n+inline iterator_range<any_insn_iterator>\n+ebb_info::all_insns () const\n+{\n+  return { m_phi_insn, m_last_bb->end_insn ()->next_any_insn () };\n+}\n+\n+inline iterator_range<reverse_any_insn_iterator>\n+ebb_info::reverse_all_insns () const\n+{\n+  return { m_last_bb->end_insn (), m_phi_insn->prev_any_insn () };\n+}\n+\n+inline iterator_range<nondebug_insn_iterator>\n+ebb_info::nondebug_insns () const\n+{\n+  return { m_phi_insn, m_last_bb->end_insn ()->next_nondebug_insn () };\n+}\n+\n+inline iterator_range<reverse_nondebug_insn_iterator>\n+ebb_info::reverse_nondebug_insns () const\n+{\n+  return { m_last_bb->end_insn (), m_phi_insn->prev_nondebug_insn () };\n+}\n+\n+inline insn_range_info\n+ebb_info::insn_range () const\n+{\n+  return { m_phi_insn, m_last_bb->end_insn () };\n+}\n+\n+inline void\n+ebb_info::set_first_call_clobbers (ebb_call_clobbers_info *call_clobbers)\n+{\n+  m_first_call_clobbers = call_clobbers;\n+}\n+\n+inline ebb_call_clobbers_info *\n+ebb_info::first_call_clobbers () const\n+{\n+  return m_first_call_clobbers;\n+}\n+\n+inline iterator_range<ebb_call_clobbers_iterator>\n+ebb_info::call_clobbers () const\n+{\n+  return { m_first_call_clobbers, nullptr };\n+}\n+\n+inline insn_change::insn_change (insn_info *insn)\n+  : m_insn (insn),\n+    new_defs (insn->defs ()),\n+    new_uses (insn->uses ()),\n+    move_range (insn),\n+    new_cost (UNKNOWN_COST),\n+    m_is_deletion (false)\n+{\n+}\n+\n+inline insn_change::insn_change (insn_info *insn, delete_action)\n+  : m_insn (insn),\n+    new_defs (),\n+    new_uses (),\n+    move_range (insn),\n+    new_cost (0),\n+    m_is_deletion (true)\n+{\n+}\n+\n+inline insn_is_changing_closure::\n+insn_is_changing_closure (array_slice<insn_change *const> changes)\n+  : m_changes (changes)\n+{\n+}\n+\n+inline bool\n+insn_is_changing_closure::operator() (const insn_info *insn) const\n+{\n+  for (const insn_change *change : m_changes)\n+    if (change->insn () == insn)\n+      return true;\n+  return false;\n+}\n+\n+inline iterator_range<bb_iterator>\n+function_info::bbs () const\n+{\n+  return { m_first_bb, nullptr };\n+}\n+\n+inline iterator_range<reverse_bb_iterator>\n+function_info::reverse_bbs () const\n+{\n+  return { m_last_bb, nullptr };\n+}\n+\n+inline iterator_range<ebb_iterator>\n+function_info::ebbs () const\n+{\n+  return { m_first_bb->ebb (), nullptr };\n+}\n+\n+inline iterator_range<reverse_ebb_iterator>\n+function_info::reverse_ebbs () const\n+{\n+  return { m_last_bb->ebb (), nullptr };\n+}\n+\n+inline iterator_range<any_insn_iterator>\n+function_info::all_insns () const\n+{\n+  return { m_first_insn, nullptr };\n+}\n+\n+inline iterator_range<reverse_any_insn_iterator>\n+function_info::reverse_all_insns () const\n+{\n+  return { m_last_insn, nullptr };\n+}\n+\n+inline iterator_range<nondebug_insn_iterator>\n+function_info::nondebug_insns () const\n+{\n+  return { m_first_insn, nullptr };\n+}\n+\n+inline iterator_range<reverse_nondebug_insn_iterator>\n+function_info::reverse_nondebug_insns () const\n+{\n+  return { m_last_insn, nullptr };\n+}\n+\n+inline iterator_range<def_iterator>\n+function_info::mem_defs () const\n+{\n+  return { m_defs[0], nullptr };\n+}\n+\n+inline iterator_range<def_iterator>\n+function_info::ref_defs (unsigned int regno) const\n+{\n+  return { m_defs[regno + 1], nullptr };\n+}\n+\n+inline set_info *\n+function_info::single_dominating_def (unsigned int regno) const\n+{\n+  if (set_info *set = safe_dyn_cast<set_info *> (m_defs[regno + 1]))\n+    if (is_single_dominating_def (set))\n+      return set;\n+  return nullptr;\n+}\n+\n+template<typename IgnorePredicate>\n+bool\n+function_info::add_regno_clobber (obstack_watermark &watermark,\n+\t\t\t\t  insn_change &change, unsigned int regno,\n+\t\t\t\t  IgnorePredicate ignore)\n+{\n+  // Check whether CHANGE already clobbers REGNO.\n+  if (find_access (change.new_defs, regno))\n+    return true;\n+\n+  // Get the closest position to INSN at which the new instruction\n+  // could be placed.\n+  insn_info *insn = change.move_range.clamp_insn_to_range (change.insn ());\n+  def_array new_defs = insert_temp_clobber (watermark, insn, regno,\n+\t\t\t\t\t    change.new_defs);\n+  if (!new_defs.is_valid ())\n+    return false;\n+\n+  // Find a definition at or neighboring INSN.\n+  insn_range_info move_range = change.move_range;\n+  if (!restrict_movement_for_dead_range (move_range, regno, insn, ignore))\n+    return false;\n+\n+  change.new_defs = new_defs;\n+  change.move_range = move_range;\n+  return true;\n+}\n+\n+}"}, {"sha": "3b0cbf9d41178804fab94d171e81ff1ce7b3b418", "filename": "gcc/rtl-ssa/movement.h", "status": "added", "additions": 335, "deletions": 0, "changes": 335, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fmovement.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Frtl-ssa%2Fmovement.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl-ssa%2Fmovement.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -0,0 +1,335 @@\n+// RTL SSA utilities relating to instruction movement               -*- C++ -*-\n+// Copyright (C) 2020 Free Software Foundation, Inc.\n+//\n+// This file is part of GCC.\n+//\n+// GCC is free software; you can redistribute it and/or modify it under\n+// the terms of the GNU General Public License as published by the Free\n+// Software Foundation; either version 3, or (at your option) any later\n+// version.\n+//\n+// GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+// WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+// for more details.\n+//\n+// You should have received a copy of the GNU General Public License\n+// along with GCC; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+namespace rtl_ssa {\n+\n+// Restrict movement range RANGE so that the instruction is placed later\n+// than INSN.  (The movement range is the range of instructions after which\n+// an instruction can be placed.)\n+inline insn_range_info\n+move_later_than (insn_range_info range, insn_info *insn)\n+{\n+  return { later_insn (range.first, insn), range.last };\n+}\n+\n+// Restrict movement range RANGE so that the instruction is placed no earlier\n+// than INSN.  (The movement range is the range of instructions after which\n+// an instruction can be placed.)\n+inline insn_range_info\n+move_no_earlier_than (insn_range_info range, insn_info *insn)\n+{\n+  insn_info *first = later_insn (range.first, insn->prev_nondebug_insn ());\n+  return { first, range.last };\n+}\n+\n+// Restrict movement range RANGE so that the instruction is placed no later\n+// than INSN.  (The movement range is the range of instructions after which\n+// an instruction can be placed.)\n+inline insn_range_info\n+move_no_later_than (insn_range_info range, insn_info *insn)\n+{\n+  return { range.first, earlier_insn (range.last, insn) };\n+}\n+\n+// Restrict movement range RANGE so that the instruction is placed earlier\n+// than INSN.  (The movement range is the range of instructions after which\n+// an instruction can be placed.)\n+inline insn_range_info\n+move_earlier_than (insn_range_info range, insn_info *insn)\n+{\n+  insn_info *last = earlier_insn (range.last, insn->prev_nondebug_insn ());\n+  return { range.first, last };\n+}\n+\n+// Return true if it is possible to insert a new instruction after INSN.\n+inline bool\n+can_insert_after (insn_info *insn)\n+{\n+  return insn->is_bb_head () || (insn->is_real () && !insn->is_jump ());\n+}\n+\n+// Try to restrict move range MOVE_RANGE so that it is possible to\n+// insert INSN after both of the end points.  Return true on success,\n+// otherwise leave MOVE_RANGE in an invalid state.\n+inline bool\n+canonicalize_move_range (insn_range_info &move_range, insn_info *insn)\n+{\n+  while (move_range.first != insn && !can_insert_after (move_range.first))\n+    move_range.first = move_range.first->next_nondebug_insn ();\n+  while (move_range.last != insn && !can_insert_after (move_range.last))\n+    move_range.last = move_range.last->prev_nondebug_insn ();\n+  return bool (move_range);\n+}\n+\n+// Try to restrict movement range MOVE_RANGE of INSN so that it can set\n+// or clobber REGNO.  Assume that if:\n+//\n+// - an instruction I2 contains another access A to REGNO; and\n+// - IGNORE (I2) is true\n+//\n+// then either:\n+//\n+// - A will be removed; or\n+// - something will ensure that the new definition of REGNO does not\n+//   interfere with A, without this having to be enforced by I1's move range.\n+//\n+// Return true on success, otherwise leave MOVE_RANGE in an invalid state.\n+//\n+// This function only works correctly for instructions that remain within\n+// the same extended basic block.\n+template<typename IgnorePredicate>\n+bool\n+restrict_movement_for_dead_range (insn_range_info &move_range,\n+\t\t\t\t  unsigned int regno, insn_info *insn,\n+\t\t\t\t  IgnorePredicate ignore)\n+{\n+  // Find a definition at or neighboring INSN.\n+  resource_info resource = full_register (regno);\n+  def_lookup dl = crtl->ssa->find_def (resource, insn);\n+\n+  def_info *prev = dl.prev_def ();\n+  ebb_info *ebb = insn->ebb ();\n+  if (!prev || prev->ebb () != ebb)\n+    {\n+      // REGNO is not defined or used in EBB before INSN, but it\n+      // might be live on entry.  To keep complexity under control,\n+      // handle only these cases:\n+      //\n+      // - If the register is not live on entry to EBB, the register is\n+      //   free from the start of EBB to the first definition in EBB.\n+      //\n+      // - Otherwise, if the register is live on entry to BB, refuse\n+      //   to allocate the register.  We could in principle try to move\n+      //   the instruction to later blocks in the EBB, but it's rarely\n+      //   worth the effort, and could lead to linear complexity.\n+      //\n+      // - Otherwise, don't allow INSN to move earlier than its current\n+      //   block.  Again, we could in principle look backwards to find where\n+      //   REGNO dies, but it's rarely worth the effort.\n+      bb_info *bb = insn->bb ();\n+      insn_info *limit;\n+      if (!bitmap_bit_p (DF_LR_IN (ebb->first_bb ()->cfg_bb ()), regno))\n+\tlimit = ebb->phi_insn ();\n+      else if (bitmap_bit_p (DF_LR_IN (bb->cfg_bb ()), regno))\n+\treturn false;\n+      else\n+\tlimit = bb->head_insn ();\n+      move_range = move_later_than (move_range, limit);\n+    }\n+  else\n+    {\n+      // Stop the instruction moving beyond the previous relevant access\n+      // to REGNO.\n+      access_info *prev_access\n+\t= last_access_ignoring (prev, ignore_clobbers::YES, ignore);\n+      if (prev_access)\n+\tmove_range = move_later_than (move_range, access_insn (prev_access));\n+    }\n+\n+  // Stop the instruction moving beyond the next relevant definition of REGNO.\n+  def_info *next = first_def_ignoring (dl.matching_or_next_def (),\n+\t\t\t\t       ignore_clobbers::YES, ignore);\n+  if (next)\n+    move_range = move_earlier_than (move_range, next->insn ());\n+\n+  return canonicalize_move_range (move_range, insn);\n+}\n+\n+// Try to restrict movement range MOVE_RANGE so that it is possible for the\n+// instruction being moved (\"instruction I1\") to perform all the definitions\n+// in DEFS while still preserving dependencies between those definitions\n+// and surrounding instructions.  Assume that if:\n+//\n+// - DEFS contains a definition D of resource R;\n+// - an instruction I2 contains another access A to R; and\n+// - IGNORE (I2) is true\n+//\n+// then either:\n+//\n+// - A will be removed; or\n+// - something will ensure that D and A maintain their current order,\n+//   without this having to be enforced by I1's move range.\n+//\n+// Return true on success, otherwise leave MOVE_RANGE in an invalid state.\n+//\n+// This function only works correctly for instructions that remain within\n+// the same extended basic block.\n+template<typename IgnorePredicate>\n+bool\n+restrict_movement_for_defs_ignoring (insn_range_info &move_range,\n+\t\t\t\t     def_array defs, IgnorePredicate ignore)\n+{\n+  for (def_info *def : defs)\n+    {\n+      // If the definition is a clobber, we can move it with respect\n+      // to other clobbers.\n+      //\n+      // ??? We could also do this if a definition and all its uses\n+      // are being moved at once.\n+      bool is_clobber = is_a<clobber_info *> (def);\n+\n+      // Search back for the first unfiltered use or definition of the\n+      // same resource.\n+      access_info *access;\n+      access = prev_access_ignoring (def, ignore_clobbers (is_clobber),\n+\t\t\t\t     ignore);\n+      if (access)\n+\tmove_range = move_later_than (move_range, access_insn (access));\n+\n+      // Search forward for the first unfiltered use of DEF,\n+      // or the first unfiltered definition that follows DEF.\n+      //\n+      // We don't need to consider uses of following definitions, since\n+      // if IGNORE (D->insn ()) is true for some definition D, the caller\n+      // is guarantees that either\n+      //\n+      // - D will be removed, and thus its uses will be removed; or\n+      // - D will occur after DEF, and thus D's uses will also occur\n+      //   after DEF.\n+      //\n+      // This is purely a simplification: we could also process D's uses,\n+      // but we don't need to.\n+      access = next_access_ignoring (def, ignore_clobbers (is_clobber),\n+\t\t\t\t     ignore);\n+      if (access)\n+\tmove_range = move_earlier_than (move_range, access_insn (access));\n+\n+      // If DEF sets a hard register, take any call clobbers\n+      // into account.\n+      unsigned int regno = def->regno ();\n+      if (!HARD_REGISTER_NUM_P (regno) || is_clobber)\n+\tcontinue;\n+\n+      ebb_info *ebb = def->ebb ();\n+      for (ebb_call_clobbers_info *call_group : ebb->call_clobbers ())\n+\t{\n+\t  if (!call_group->clobbers (def->resource ()))\n+\t    continue;\n+\n+\t  // Exit now if we've already failed, and if the splay accesses\n+\t  // below would be wasted work.\n+\t  if (!move_range)\n+\t    return false;\n+\n+\t  insn_info *insn;\n+\t  insn = prev_call_clobbers_ignoring (*call_group, def->insn (),\n+\t\t\t\t\t      ignore);\n+\t  if (insn)\n+\t    move_range = move_later_than (move_range, insn);\n+\n+\t  insn = next_call_clobbers_ignoring (*call_group, def->insn (),\n+\t\t\t\t\t      ignore);\n+\t  if (insn)\n+\t    move_range = move_earlier_than (move_range, insn);\n+\t}\n+    }\n+\n+  // Make sure that we don't move stores between basic blocks, since we\n+  // don't have enough information to tell whether it's safe.\n+  if (def_info *def = memory_access (defs))\n+    {\n+      move_range = move_later_than (move_range, def->bb ()->head_insn ());\n+      move_range = move_earlier_than (move_range, def->bb ()->end_insn ());\n+    }\n+\n+  return bool (move_range);\n+}\n+\n+// Like restrict_movement_for_defs_ignoring, but for the uses in USES.\n+template<typename IgnorePredicate>\n+bool\n+restrict_movement_for_uses_ignoring (insn_range_info &move_range,\n+\t\t\t\t     use_array uses, IgnorePredicate ignore)\n+{\n+  for (const use_info *use : uses)\n+    {\n+      // Ignore uses of undefined values.\n+      set_info *set = use->def ();\n+      if (!set)\n+\tcontinue;\n+\n+      // Ignore uses by debug instructions.  Debug instructions are\n+      // never supposed to move, and uses by debug instructions are\n+      // never supposed to be transferred elsewhere, so we know that\n+      // the caller must be changing the uses on the debug instruction\n+      // and checking whether all new uses are available at the debug\n+      // instruction's original location.\n+      if (use->is_in_debug_insn ())\n+\tcontinue;\n+\n+      // If the used value is defined by an instruction I2 for which\n+      // IGNORE (I2) is true, the caller guarantees that I2 will occur\n+      // before change.insn ().  Otherwise, make sure that the use occurs\n+      // after the definition.\n+      insn_info *insn = set->insn ();\n+      if (!ignore (insn))\n+\tmove_range = move_later_than (move_range, insn);\n+\n+      // Search forward for the first unfiltered definition that follows SET.\n+      //\n+      // We don't need to consider the uses of these definitions, since\n+      // if IGNORE (D->insn ()) is true for some definition D, the caller\n+      // is guarantees that either\n+      //\n+      // - D will be removed, and thus its uses will be removed; or\n+      // - D will occur after USE, and thus D's uses will also occur\n+      //   after USE.\n+      //\n+      // This is purely a simplification: we could also process D's uses,\n+      // but we don't need to.\n+      def_info *def;\n+      def = first_def_ignoring (set->next_def (), ignore_clobbers::NO,\n+\t\t\t\tignore);\n+      if (def)\n+\tmove_range = move_earlier_than (move_range, def->insn ());\n+\n+      // If USE uses a hard register, take any call clobbers into account too.\n+      // SET will necessarily occur after any previous call clobber, so we\n+      // only need to check for later clobbers.\n+      unsigned int regno = use->regno ();\n+      if (!HARD_REGISTER_NUM_P (regno))\n+\tcontinue;\n+\n+      ebb_info *ebb = use->ebb ();\n+      for (ebb_call_clobbers_info *call_group : ebb->call_clobbers ())\n+\t{\n+\t  if (!call_group->clobbers (use->resource ()))\n+\t    continue;\n+\n+\t  if (!move_range)\n+\t    return false;\n+\n+\t  insn_info *insn = next_call_clobbers_ignoring (*call_group,\n+\t\t\t\t\t\t\t use->insn (), ignore);\n+\t  if (insn)\n+\t    move_range = move_earlier_than (move_range, insn);\n+\t}\n+    }\n+\n+  // Make sure that we don't move loads into an earlier basic block.\n+  //\n+  // ??? It would be good to relax this for loads that can be safely\n+  // speculated.\n+  if (use_info *use = memory_access (uses))\n+    move_range = move_later_than (move_range, use->bb ()->head_insn ());\n+\n+  return bool (move_range);\n+}\n+\n+}"}, {"sha": "5b428252dd55927e77872c773b9be4c9e7925676", "filename": "gcc/system.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Fsystem.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73b7582775254b764fd92ddb252a33dc15872c69/gcc%2Fsystem.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsystem.h?ref=73b7582775254b764fd92ddb252a33dc15872c69", "patch": "@@ -235,6 +235,9 @@ extern int errno;\n #ifdef INCLUDE_ARRAY\n # include <array>\n #endif\n+#ifdef INCLUDE_FUNCTIONAL\n+# include <functional>\n+#endif\n # include <cstring>\n # include <new>\n # include <utility>"}]}