{"sha": "aadb52ad00db5dc2945b805e006713f091095b10", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWFkYjUyYWQwMGRiNWRjMjk0NWI4MDVlMDA2NzEzZjA5MTA5NWIxMA==", "commit": {"author": {"name": "DJ Delorie", "email": "dj@redhat.com", "date": "2013-09-12T23:12:49Z"}, "committer": {"name": "DJ Delorie", "email": "dj@gcc.gnu.org", "date": "2013-09-12T23:12:49Z"}, "message": "rl78-virt.md: Change from | to \\; for asm line separators.\n\n* config/rl78/rl78-virt.md: Change from | to \\; for asm line\nseparators.\n\nFrom-SVN: r202545", "tree": {"sha": "3f7d68245a8f7374a55bb20d4817381f363287e5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3f7d68245a8f7374a55bb20d4817381f363287e5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/aadb52ad00db5dc2945b805e006713f091095b10", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/aadb52ad00db5dc2945b805e006713f091095b10", "html_url": "https://github.com/Rust-GCC/gccrs/commit/aadb52ad00db5dc2945b805e006713f091095b10", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/aadb52ad00db5dc2945b805e006713f091095b10/comments", "author": null, "committer": null, "parents": [{"sha": "90ae701920bb7a9d8888f0df757a1354e1e8d70a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/90ae701920bb7a9d8888f0df757a1354e1e8d70a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/90ae701920bb7a9d8888f0df757a1354e1e8d70a"}], "stats": {"total": 111, "additions": 58, "deletions": 53}, "files": [{"sha": "57c9417614407543d455497b0c2893d49a96962e", "filename": "gcc/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aadb52ad00db5dc2945b805e006713f091095b10/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aadb52ad00db5dc2945b805e006713f091095b10/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=aadb52ad00db5dc2945b805e006713f091095b10", "patch": "@@ -1,3 +1,8 @@\n+2013-09-12  DJ Delorie  <dj@redhat.com>\n+\n+\t* config/rl78/rl78-virt.md: Change from | to \\; for asm line\n+\tseparators.\n+\n 2013-09-12  Brooks Moses  <bmoses@google.com>\n \n \tPR driver/42955"}, {"sha": "dc50e3b34e5ea18530801b0f58c0f370785e1394", "filename": "gcc/config/rl78/rl78-virt.md", "status": "modified", "additions": 53, "deletions": 53, "changes": 106, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aadb52ad00db5dc2945b805e006713f091095b10/gcc%2Fconfig%2Frl78%2Frl78-virt.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aadb52ad00db5dc2945b805e006713f091095b10/gcc%2Fconfig%2Frl78%2Frl78-virt.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frl78%2Frl78-virt.md?ref=aadb52ad00db5dc2945b805e006713f091095b10", "patch": "@@ -177,30 +177,30 @@\n    \"@\n     ; ashrsi %0, 0\n \n-   movw ax,%H1 | sarw ax,1 | movw %H0,ax | mov a,%Q1 | rorc a,1 | mov %Q0,a | mov a,%q1 | rorc a,1 | mov %q0,a\n-   movw ax,%H1 | sarw ax,1 | movw %H0,ax | mov a,%Q1 | rorc a,1 | mov %Q0,a | mov a,%q1 | rorc a,1 | mov %q0,a\n+   movw ax,%H1 \\; sarw ax,1 \\; movw %H0,ax \\; mov a,%Q1 \\; rorc a,1 \\; mov %Q0,a \\; mov a,%q1 \\; rorc a,1 \\; mov %q0,a\n+   movw ax,%H1 \\; sarw ax,1 \\; movw %H0,ax \\; mov a,%Q1 \\; rorc a,1 \\; mov %Q0,a \\; mov a,%q1 \\; rorc a,1 \\; mov %q0,a\n \n-   movw ax,%1 | shlw ax,%r2 | mov %0,a             | mov x,%Q1 | mov a,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | sarw ax,%u2 | movw %H0,ax\n-   movw ax,%1 | shlw ax,%r2 | mov %0,a             | mov x,%Q1 | mov a,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | sarw ax,%u2 | movw %H0,ax\n-   movw ax,%1 | shlw ax,%r2 | mov %0,a | mov a,%Q1 | mov x,a   | mov a,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | sarw ax,%u2 | movw %H0,ax\n+   movw ax,%1 \\; shlw ax,%r2 \\; mov %0,a             \\; mov x,%Q1 \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; sarw ax,%u2 \\; movw %H0,ax\n+   movw ax,%1 \\; shlw ax,%r2 \\; mov %0,a             \\; mov x,%Q1 \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; sarw ax,%u2 \\; movw %H0,ax\n+   movw ax,%1 \\; shlw ax,%r2 \\; mov %0,a \\; mov a,%Q1 \\; mov x,a   \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; sarw ax,%u2 \\; movw %H0,ax\n \n-   mov x,%Q1            | mov a,%H1 | movw %0,ax | movw ax,%H1 | sarw ax,8 | movw %H0,ax\n-   mov a,%Q1 | mov x, a | mov a,%H1 | movw %0,ax | movw ax,%H1 | sarw ax,8 | movw %H0,ax\n+   mov x,%Q1            \\; mov a,%H1 \\; movw %0,ax \\; movw ax,%H1 \\; sarw ax,8 \\; movw %H0,ax\n+   mov a,%Q1 \\; mov x, a \\; mov a,%H1 \\; movw %0,ax \\; movw ax,%H1 \\; sarw ax,8 \\; movw %H0,ax\n \n-   mov x,%Q1           | mov a,%H1 | shlw ax,%r2 | mov %0,a | movw ax,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | sarw ax,%u2 | movw %H0,ax\n-   mov x,%Q1           | mov a,%H1 | shlw ax,%r2 | mov %0,a | movw ax,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | sarw ax,%u2 | movw %H0,ax\n-   mov a,%Q1 | mov x,a | mov a,%H1 | shlw ax,%r2 | mov %0,a | movw ax,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | sarw ax,%u2 | movw %H0,ax\n+   mov x,%Q1           \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %0,a \\; movw ax,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; sarw ax,%u2 \\; movw %H0,ax\n+   mov x,%Q1           \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %0,a \\; movw ax,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; sarw ax,%u2 \\; movw %H0,ax\n+   mov a,%Q1 \\; mov x,a \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %0,a \\; movw ax,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; sarw ax,%u2 \\; movw %H0,ax\n \n-   movw ax,%H1 | movw %0,ax | sarw ax,15 | movw %H0,ax\n+   movw ax,%H1 \\; movw %0,ax \\; sarw ax,15 \\; movw %H0,ax\n \n-   movw ax,%H1 | sarw ax,%S2 | movw %0,ax | sarw ax,15 | movw %H0,ax\n-   movw ax,%H1 | sarw ax,%S2 | movw %0,ax | sarw ax,15 | movw %H0,ax\n+   movw ax,%H1 \\; sarw ax,%S2 \\; movw %0,ax \\; sarw ax,15 \\; movw %H0,ax\n+   movw ax,%H1 \\; sarw ax,%S2 \\; movw %0,ax \\; sarw ax,15 \\; movw %H0,ax\n \n-   movw ax,%H1 | mov %0,a | sarw ax,15 | movw %H0,ax | mov %Q0,a\n+   movw ax,%H1 \\; mov %0,a \\; sarw ax,15 \\; movw %H0,ax \\; mov %Q0,a\n \n-   movw ax,%H1 | sar a,%s2 | mov %0,a | sarw ax,15 | movw %H0,ax | mov %Q0,a\n+   movw ax,%H1 \\; sar a,%s2 \\; mov %0,a \\; sarw ax,15 \\; movw %H0,ax \\; mov %Q0,a\n \n-   mov b,%2 | cmp0 b | bz $2f | 1: | movw ax,%H1 | sarw ax,1 | movw %H0,ax | mov a,%Q1 | rorc a,1 | mov %Q0,a | mov a,%q1 | rorc a,1 | mov %q0,a | dec b | bnz $1b | 2:\"\n+   mov b,%2 \\; cmp0 b \\; bz $2f \\; 1: \\; movw ax,%H1 \\; sarw ax,1 \\; movw %H0,ax \\; mov a,%Q1 \\; rorc a,1 \\; mov %Q0,a \\; mov a,%q1 \\; rorc a,1 \\; mov %q0,a \\; dec b \\; bnz $1b \\; 2:\"\n   [(set_attr \"valloc\" \"macax\")]\n )\n \n@@ -215,30 +215,30 @@\n   \"@\n    ; lshrsi %0, 0\n \n-   movw ax,%H1 | shrw ax,1 | movw %H0,ax | mov a,%Q1 | rorc a,1 | mov %Q0,a | mov a,%q1 | rorc a,1 | mov %q0,a\n-   movw ax,%H1 | shrw ax,1 | movw %H0,ax | mov a,%Q1 | rorc a,1 | mov %Q0,a | mov a,%q1 | rorc a,1 | mov %q0,a\n+   movw ax,%H1 \\; shrw ax,1 \\; movw %H0,ax \\; mov a,%Q1 \\; rorc a,1 \\; mov %Q0,a \\; mov a,%q1 \\; rorc a,1 \\; mov %q0,a\n+   movw ax,%H1 \\; shrw ax,1 \\; movw %H0,ax \\; mov a,%Q1 \\; rorc a,1 \\; mov %Q0,a \\; mov a,%q1 \\; rorc a,1 \\; mov %q0,a\n \n-   movw ax,%1 | shlw ax,%r2 | mov %0,a             | mov x,%Q1 | mov a,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | shrw ax,%u2 | movw %H0,ax\n-   movw ax,%1 | shlw ax,%r2 | mov %0,a             | mov x,%Q1 | mov a,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | shrw ax,%u2 | movw %H0,ax\n-   movw ax,%1 | shlw ax,%r2 | mov %0,a | mov a,%Q1 | mov x,a   | mov a,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | shrw ax,%u2 | movw %H0,ax\n+   movw ax,%1 \\; shlw ax,%r2 \\; mov %0,a             \\; mov x,%Q1 \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; shrw ax,%u2 \\; movw %H0,ax\n+   movw ax,%1 \\; shlw ax,%r2 \\; mov %0,a             \\; mov x,%Q1 \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; shrw ax,%u2 \\; movw %H0,ax\n+   movw ax,%1 \\; shlw ax,%r2 \\; mov %0,a \\; mov a,%Q1 \\; mov x,a   \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; shrw ax,%u2 \\; movw %H0,ax\n \n-   mov x,%Q1            | mov a,%H1 | movw %0,ax | movw ax,%H1 | shrw ax,8 | movw %H0,ax\n-   mov a,%Q1 | mov x, a | mov a,%H1 | movw %0,ax | movw ax,%H1 | shrw ax,8 | movw %H0,ax\n+   mov x,%Q1            \\; mov a,%H1 \\; movw %0,ax \\; movw ax,%H1 \\; shrw ax,8 \\; movw %H0,ax\n+   mov a,%Q1 \\; mov x, a \\; mov a,%H1 \\; movw %0,ax \\; movw ax,%H1 \\; shrw ax,8 \\; movw %H0,ax\n \n-   mov x,%Q1           | mov a,%H1 | shlw ax,%r2 | mov %0,a | movw ax,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | shrw ax,%u2 | movw %H0,ax\n-   mov x,%Q1           | mov a,%H1 | shlw ax,%r2 | mov %0,a | movw ax,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | shrw ax,%u2 | movw %H0,ax\n-   mov a,%Q1 | mov x,a | mov a,%H1 | shlw ax,%r2 | mov %0,a | movw ax,%H1 | shlw ax,%r2 | mov %Q0,a | movw ax,%H1 | shrw ax,%u2 | movw %H0,ax\n+   mov x,%Q1           \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %0,a \\; movw ax,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; shrw ax,%u2 \\; movw %H0,ax\n+   mov x,%Q1           \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %0,a \\; movw ax,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; shrw ax,%u2 \\; movw %H0,ax\n+   mov a,%Q1 \\; mov x,a \\; mov a,%H1 \\; shlw ax,%r2 \\; mov %0,a \\; movw ax,%H1 \\; shlw ax,%r2 \\; mov %Q0,a \\; movw ax,%H1 \\; shrw ax,%u2 \\; movw %H0,ax\n \n-   movw ax,%H1 | movw %0,ax | movw ax,#0 | movw %H0,ax\n+   movw ax,%H1 \\; movw %0,ax \\; movw ax,#0 \\; movw %H0,ax\n \n-   movw ax,%H1 | shrw ax,%S2 | movw %0,ax | movw ax,#0 | movw %H0,ax\n-   movw ax,%H1 | shrw ax,%S2 | movw %0,ax | movw ax,#0 | movw %H0,ax\n+   movw ax,%H1 \\; shrw ax,%S2 \\; movw %0,ax \\; movw ax,#0 \\; movw %H0,ax\n+   movw ax,%H1 \\; shrw ax,%S2 \\; movw %0,ax \\; movw ax,#0 \\; movw %H0,ax\n \n-   movw ax,%H1 | mov %0,a | movw ax,#0 | movw %H0,ax | mov %Q0,a\n+   movw ax,%H1 \\; mov %0,a \\; movw ax,#0 \\; movw %H0,ax \\; mov %Q0,a\n \n-   movw ax,%H1 | shr a,%s2 | mov %0,a | movw ax,#0 | movw %H0,ax | mov %Q0,a\n+   movw ax,%H1 \\; shr a,%s2 \\; mov %0,a \\; movw ax,#0 \\; movw %H0,ax \\; mov %Q0,a\n \n-   mov b,%2 | cmp0 b | bz $2f | 1: | movw ax,%H1 | shrw ax,1 | movw %H0,ax | mov a,%Q1 | rorc a,1 | mov %Q0,a | mov a,%q1 | rorc a,1 | mov %q0,a | dec b | bnz $1b | 2:\"\n+   mov b,%2 \\; cmp0 b \\; bz $2f \\; 1: \\; movw ax,%H1 \\; shrw ax,1 \\; movw %H0,ax \\; mov a,%Q1 \\; rorc a,1 \\; mov %Q0,a \\; mov a,%q1 \\; rorc a,1 \\; mov %q0,a \\; dec b \\; bnz $1b \\; 2:\"\n   [(set_attr \"valloc\" \"macax\")]\n )\n \n@@ -253,35 +253,35 @@\n   \"@\n    ; lshrsi %0, 0\n \n-   movw ax,%1 | shlw ax,1 | movw %0,ax | movw ax,%H1 | rolwc ax,1 | movw %H0,ax\n-   movw ax,%1 | shlw ax,1 | movw %0,ax | movw ax,%H1 | rolwc ax,1 | movw %H0,ax\n+   movw ax,%1 \\; shlw ax,1 \\; movw %0,ax \\; movw ax,%H1 \\; rolwc ax,1 \\; movw %H0,ax\n+   movw ax,%1 \\; shlw ax,1 \\; movw %0,ax \\; movw ax,%H1 \\; rolwc ax,1 \\; movw %H0,ax\n \n-   movw ax,%H1 | shlw ax,%u2 | mov %E0,a | mov x,%Q1           | mov a, %H1 | shlw ax,%S2 | mov %H0,a | movw ax,%1 | shlw ax,%u2 | movw %0,ax\n-   movw ax,%H1 | shlw ax,%u2 | mov %E0,a | mov x,%Q1           | mov a, %H1 | shlw ax,%S2 | mov %H0,a | movw ax,%1 | shlw ax,%u2 | movw %0,ax\n-   movw ax,%H1 | shlw ax,%u2 | mov %E0,a | mov a,%Q1 | mov x,a | mov a, %H1 | shlw ax,%S2 | mov %H0,a | movw ax,%1 | shlw ax,%u2 | movw %0,ax\n+   movw ax,%H1 \\; shlw ax,%u2 \\; mov %E0,a \\; mov x,%Q1           \\; mov a, %H1 \\; shlw ax,%S2 \\; mov %H0,a \\; movw ax,%1 \\; shlw ax,%u2 \\; movw %0,ax\n+   movw ax,%H1 \\; shlw ax,%u2 \\; mov %E0,a \\; mov x,%Q1           \\; mov a, %H1 \\; shlw ax,%S2 \\; mov %H0,a \\; movw ax,%1 \\; shlw ax,%u2 \\; movw %0,ax\n+   movw ax,%H1 \\; shlw ax,%u2 \\; mov %E0,a \\; mov a,%Q1 \\; mov x,a \\; mov a, %H1 \\; shlw ax,%S2 \\; mov %H0,a \\; movw ax,%1 \\; shlw ax,%u2 \\; movw %0,ax\n \n-   mov x,%Q1           | mov a,%H1 | movw %H0,ax | movw ax,%1 | shlw ax,8 | movw %0,ax\n-   mov a,%Q1 | mov x,a | mov a,%H1 | movw %H0,ax | movw ax,%1 | shlw ax,8 | movw %0,ax\n+   mov x,%Q1           \\; mov a,%H1 \\; movw %H0,ax \\; movw ax,%1 \\; shlw ax,8 \\; movw %0,ax\n+   mov a,%Q1 \\; mov x,a \\; mov a,%H1 \\; movw %H0,ax \\; movw ax,%1 \\; shlw ax,8 \\; movw %0,ax\n \n-   mov x,%Q1           | mov a,%H1 | shlw ax,%s2 | movw %H0,ax | movw ax,%1 | shlw ax,%s2 | mov %H0,a | movw ax,%1 | shlw ax,%u2 | movw %0,ax\n-   mov x,%Q1           | mov a,%H1 | shlw ax,%s2 | movw %H0,ax | movw ax,%1 | shlw ax,%s2 | mov %H0,a | movw ax,%1 | shlw ax,%u2 | movw %0,ax\n-   mov a,%Q1 | mov x,a | mov a,%H1 | shlw ax,%s2 | movw %H0,ax | movw ax,%1 | shlw ax,%s2 | mov %H0,a | movw ax,%1 | shlw ax,%u2 | movw %0,ax\n+   mov x,%Q1           \\; mov a,%H1 \\; shlw ax,%s2 \\; movw %H0,ax \\; movw ax,%1 \\; shlw ax,%s2 \\; mov %H0,a \\; movw ax,%1 \\; shlw ax,%u2 \\; movw %0,ax\n+   mov x,%Q1           \\; mov a,%H1 \\; shlw ax,%s2 \\; movw %H0,ax \\; movw ax,%1 \\; shlw ax,%s2 \\; mov %H0,a \\; movw ax,%1 \\; shlw ax,%u2 \\; movw %0,ax\n+   mov a,%Q1 \\; mov x,a \\; mov a,%H1 \\; shlw ax,%s2 \\; movw %H0,ax \\; movw ax,%1 \\; shlw ax,%s2 \\; mov %H0,a \\; movw ax,%1 \\; shlw ax,%u2 \\; movw %0,ax\n \n-   movw ax,%1 | movw %H0,ax | movw %0,#0\n-   movw ax,%1 | movw %H0,ax | movw ax,#0 | movw %0,ax\n+   movw ax,%1 \\; movw %H0,ax \\; movw %0,#0\n+   movw ax,%1 \\; movw %H0,ax \\; movw ax,#0 \\; movw %0,ax\n \n-   movw ax,%1 | shlw ax,%S2 | movw %H0,ax | movw %0,#0\n-   movw ax,%1 | shlw ax,%S2 | movw %H0,ax | movw ax,#0 | movw %0,ax\n+   movw ax,%1 \\; shlw ax,%S2 \\; movw %H0,ax \\; movw %0,#0\n+   movw ax,%1 \\; shlw ax,%S2 \\; movw %H0,ax \\; movw ax,#0 \\; movw %0,ax\n \n-   mov a,%1 | movw %H0,ax | mov %H0,#0 | movw %0,#0\n-   mov a,%1 | movw %H0,ax | movw ax,#0 | mov %H0,a | movW %0,ax\n+   mov a,%1 \\; movw %H0,ax \\; mov %H0,#0 \\; movw %0,#0\n+   mov a,%1 \\; movw %H0,ax \\; movw ax,#0 \\; mov %H0,a \\; movW %0,ax\n \n-   mov a,%1 | shl a,%s2 | movw %H0,ax | mov %H0,#0 | movw %0,#0\n-   mov a,%1 | shl a,%s2 | movw %H0,ax | movw ax,#0 | mov %H0,a | movW %0,ax\n+   mov a,%1 \\; shl a,%s2 \\; movw %H0,ax \\; mov %H0,#0 \\; movw %0,#0\n+   mov a,%1 \\; shl a,%s2 \\; movw %H0,ax \\; movw ax,#0 \\; mov %H0,a \\; movW %0,ax\n \n-   mov a,%2 | cmp0 a | bz $2f | mov d,a | movw ax,%H1 | movw bc,%1 | 1: | shlw bc,1 | rolwc ax,1 | dec d | bnz $1b | movw %H0,ax | movw ax,bc | movw %0,ax | 2:\n-   mov a,%2 | mov d,a | movw ax,%H1 | movw bc,%1 | cmp0 0xFFEFD | bz $2f | 1: | shlw bc,1 | rolwc ax,1 | dec d | bnz $1b | 2: | movw %H0,ax | movw ax,bc | movw %0,ax\n-   mov a,%2 | mov d,a | movw ax,%1 | movw bc,ax | movw ax,%H1 | cmp0 0xFFEFD | bz $2f | 1: | shlw bc,1 | rolwc ax,1 | dec d | bnz $1b | 2: | movw %H0,ax | movw ax,bc | movw %0,ax\"\n+   mov a,%2 \\; cmp0 a \\; bz $2f \\; mov d,a \\; movw ax,%H1 \\; movw bc,%1 \\; 1: \\; shlw bc,1 \\; rolwc ax,1 \\; dec d \\; bnz $1b \\; movw %H0,ax \\; movw ax,bc \\; movw %0,ax \\; 2:\n+   mov a,%2 \\; mov d,a \\; movw ax,%H1 \\; movw bc,%1 \\; cmp0 0xFFEFD \\; bz $2f \\; 1: \\; shlw bc,1 \\; rolwc ax,1 \\; dec d \\; bnz $1b \\; 2: \\; movw %H0,ax \\; movw ax,bc \\; movw %0,ax\n+   mov a,%2 \\; mov d,a \\; movw ax,%1 \\; movw bc,ax \\; movw ax,%H1 \\; cmp0 0xFFEFD \\; bz $2f \\; 1: \\; shlw bc,1 \\; rolwc ax,1 \\; dec d \\; bnz $1b \\; 2: \\; movw %H0,ax \\; movw ax,bc \\; movw %0,ax\"\n    [(set_attr \"valloc\" \"macax\")]\n  )\n "}]}