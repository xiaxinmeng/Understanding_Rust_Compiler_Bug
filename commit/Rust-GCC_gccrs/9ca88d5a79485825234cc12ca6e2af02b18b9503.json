{"sha": "9ca88d5a79485825234cc12ca6e2af02b18b9503", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OWNhODhkNWE3OTQ4NTgyNTIzNGNjMTJjYTZlMmFmMDJiMThiOTUwMw==", "commit": {"author": {"name": "Daniel Berlin", "email": "dberlin@dberlin.org", "date": "2002-01-05T14:31:45Z"}, "committer": {"name": "Daniel Berlin", "email": "dberlin@gcc.gnu.org", "date": "2002-01-05T14:31:45Z"}, "message": "lcm.c: Revert change...\n\n2002-01-05  Daniel Berlin  <dan@dberlin.org>\n\n\t* lcm.c: Revert change, due to performance regression it causes on\n\tSPEC because it's slightly more conservative (sigh, I hate\n\tedge-based LCM).\n\nFrom-SVN: r48566", "tree": {"sha": "baf31a22c31877eaaee3041dcbee103abf0a2a33", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/baf31a22c31877eaaee3041dcbee103abf0a2a33"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/9ca88d5a79485825234cc12ca6e2af02b18b9503", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9ca88d5a79485825234cc12ca6e2af02b18b9503", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9ca88d5a79485825234cc12ca6e2af02b18b9503", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9ca88d5a79485825234cc12ca6e2af02b18b9503/comments", "author": {"login": "dberlin", "id": 324715, "node_id": "MDQ6VXNlcjMyNDcxNQ==", "avatar_url": "https://avatars.githubusercontent.com/u/324715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dberlin", "html_url": "https://github.com/dberlin", "followers_url": "https://api.github.com/users/dberlin/followers", "following_url": "https://api.github.com/users/dberlin/following{/other_user}", "gists_url": "https://api.github.com/users/dberlin/gists{/gist_id}", "starred_url": "https://api.github.com/users/dberlin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dberlin/subscriptions", "organizations_url": "https://api.github.com/users/dberlin/orgs", "repos_url": "https://api.github.com/users/dberlin/repos", "events_url": "https://api.github.com/users/dberlin/events{/privacy}", "received_events_url": "https://api.github.com/users/dberlin/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "1c570418339af7cc16a4ec01ccfbdd1a96568c21", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1c570418339af7cc16a4ec01ccfbdd1a96568c21", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1c570418339af7cc16a4ec01ccfbdd1a96568c21"}], "stats": {"total": 145, "additions": 96, "deletions": 49}, "files": [{"sha": "35cb8e9b9239a237121740485bfe7655bcf521d7", "filename": "gcc/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9ca88d5a79485825234cc12ca6e2af02b18b9503/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9ca88d5a79485825234cc12ca6e2af02b18b9503/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=9ca88d5a79485825234cc12ca6e2af02b18b9503", "patch": "@@ -1,3 +1,9 @@\n+2002-01-05  Daniel Berlin  <dan@dberlin.org>\n+\n+\t* lcm.c: Revert change, due to performance regression it causes on\n+\tSPEC because it's slightly more conservative (sigh, I hate\n+\tedge-based LCM).\n+\t\n Sat Jan  5 11:52:05 CET 2002  Jan Hubicka  <jh@suse.cz>\n \n \t* cfgcleanup.c (try_forward_edges): Allow multiple jump threading."}, {"sha": "a1e6845757c0d035f2fc42056cb24db21aa2872d", "filename": "gcc/lcm.c", "status": "modified", "additions": 90, "deletions": 49, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9ca88d5a79485825234cc12ca6e2af02b18b9503/gcc%2Flcm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9ca88d5a79485825234cc12ca6e2af02b18b9503/gcc%2Flcm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flcm.c?ref=9ca88d5a79485825234cc12ca6e2af02b18b9503", "patch": "@@ -60,7 +60,6 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"recog.h\"\n #include \"basic-block.h\"\n #include \"tm_p.h\"\n-#include \"df.h\"\n \n /* We want target macros for the mode switching code to be able to refer\n    to instruction attribute values.  */\n@@ -93,11 +92,9 @@ static void compute_rev_insert_delete\tPARAMS ((struct edge_list *edge_list,\n \t\t\t\t\t\t sbitmap *, sbitmap *,\n \t\t\t\t\t\t sbitmap *, sbitmap *,\n \t\t\t\t\t\t sbitmap *));\n-\n-static void available_transfer_function PARAMS ((int, int *, sbitmap, sbitmap, \n-\t\t\t\t\t\t sbitmap, sbitmap, void *));\n \f\n /* Edge based lcm routines.  */\n+\n /* Compute expression anticipatability at entrance and exit of each block.\n    This is done based on the flow graph, and not on the pred-succ lists.\n    Other than that, its pretty much identical to compute_antinout.  */\n@@ -113,6 +110,7 @@ compute_antinout_edge (antloc, transp, antin, antout)\n   edge e;\n   basic_block *worklist, *qin, *qout, *qend;\n   unsigned int qlen;\n+\n   /* Allocate a worklist array/queue.  Entries are only added to the\n      list if they were not already on the list.  So the size is\n      bounded by the number of basic blocks.  */\n@@ -147,6 +145,7 @@ compute_antinout_edge (antloc, transp, antin, antout)\n       basic_block b = *qout++;\n       bb = b->index;\n       qlen--;\n+\n       if (qout >= qend)\n         qout = worklist;\n \n@@ -488,48 +487,90 @@ pre_edge_lcm (file, n_exprs, transp, avloc, antloc, kill, insert, delete)\n \n   return edge_list;\n }\n-/* Availability transfer function */\n-static void\n-available_transfer_function (bb, changed, in, out, gen, kill, data)\n-     int bb ATTRIBUTE_UNUSED;\n-     int *changed;\n-     sbitmap in,out,gen,kill;\n-     void *data ATTRIBUTE_UNUSED;\n-{\n-  *changed = sbitmap_union_of_diff (out, gen, in, kill);\n-}\n-/* Compute the AVIN and AVOUT vectors from the AVLOC and KILL\n-   vectors.  */\n+\n+/* Compute the AVIN and AVOUT vectors from the AVLOC and KILL vectors.\n+   Return the number of passes we performed to iterate to a solution.  */\n+\n void\n compute_available (avloc, kill, avout, avin)\n-     sbitmap *avloc;\n-     sbitmap *kill;\n-     sbitmap *avout;\n-     sbitmap *avin;\n+     sbitmap *avloc, *kill, *avout, *avin;\n {\n-  int *dfs_order;\n-  int *rc_order;\n-  bitmap blocks;\n-  int *inverse_rc_map;\n-  int i;\n-  dfs_order = xmalloc (sizeof (int) * n_basic_blocks);\n-  rc_order = xmalloc (sizeof (int) * n_basic_blocks);\n-  inverse_rc_map = xmalloc (sizeof (int) * n_basic_blocks);\n-  flow_depth_first_order_compute (dfs_order, rc_order);\n-  blocks = BITMAP_XMALLOC ();\n-  for (i = 0; i < n_basic_blocks; i ++)\n-   {\n-     inverse_rc_map[rc_order[i]] = i;\n-     bitmap_set_bit (blocks, i);\n-   }\n+  int bb;\n+  edge e;\n+  basic_block *worklist, *qin, *qout, *qend;\n+  unsigned int qlen;\n+\n+  /* Allocate a worklist array/queue.  Entries are only added to the\n+     list if they were not already on the list.  So the size is\n+     bounded by the number of basic blocks.  */\n+  qin = qout = worklist\n+    = (basic_block *) xmalloc (sizeof (basic_block) * n_basic_blocks);\n+\n+  /* We want a maximal solution.  */\n   sbitmap_vector_ones (avout, n_basic_blocks);\n-  iterative_dataflow_sbitmap (avin, avout, avloc, kill, blocks, \n-\t\t\t      FORWARD, INTERSECTION, \n-\t\t\t      available_transfer_function, inverse_rc_map, 0);\n-  BITMAP_XFREE (blocks);\n-  free (dfs_order);\n-  free (rc_order);\n-  free (inverse_rc_map);\n+\n+  /* Put every block on the worklist; this is necessary because of the\n+     optimistic initialization of AVOUT above.  */\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n+    {\n+      *qin++ = BASIC_BLOCK (bb);\n+      BASIC_BLOCK (bb)->aux = BASIC_BLOCK (bb);\n+    }\n+\n+  qin = worklist;\n+  qend = &worklist[n_basic_blocks];\n+  qlen = n_basic_blocks;\n+\n+  /* Mark blocks which are successors of the entry block so that we\n+     can easily identify them below.  */\n+  for (e = ENTRY_BLOCK_PTR->succ; e; e = e->succ_next)\n+    e->dest->aux = ENTRY_BLOCK_PTR;\n+\n+  /* Iterate until the worklist is empty.  */\n+  while (qlen)\n+    {\n+      /* Take the first entry off the worklist.  */\n+      basic_block b = *qout++;\n+      bb = b->index;\n+      qlen--;\n+\n+      if (qout >= qend)\n+        qout = worklist;\n+\n+      /* If one of the predecessor blocks is the ENTRY block, then the\n+\t intersection of avouts is the null set.  We can identify such blocks\n+\t by the special value in the AUX field in the block structure.  */\n+      if (b->aux == ENTRY_BLOCK_PTR)\n+\t/* Do not clear the aux field for blocks which are successors of the\n+\t   ENTRY block.  That way we never add then to the worklist again.  */\n+\tsbitmap_zero (avin[bb]);\n+      else\n+\t{\n+\t  /* Clear the aux field of this block so that it can be added to\n+\t     the worklist again if necessary.  */\n+\t  b->aux = NULL;\n+\t  sbitmap_intersection_of_preds (avin[bb], avout, bb);\n+\t}\n+\n+      if (sbitmap_union_of_diff (avout[bb], avloc[bb], avin[bb], kill[bb]))\n+\t/* If the out state of this block changed, then we need\n+\t   to add the successors of this block to the worklist\n+\t   if they are not already on the worklist.  */\n+\tfor (e = b->succ; e; e = e->succ_next)\n+\t  if (!e->dest->aux && e->dest != EXIT_BLOCK_PTR)\n+\t    {\n+\t      *qin++ = e->dest;\n+\t      e->dest->aux = e;\n+\t      qlen++;\n+\n+\t      if (qin >= qend)\n+\t        qin = worklist;\n+\t    }\n+    }\n+\n+  clear_aux_for_edges ();\n+  clear_aux_for_blocks ();\n+  free (worklist);\n }\n \n /* Compute the farthest vector for edge based lcm.  */\n@@ -835,7 +876,7 @@ struct seginfo\n   HARD_REG_SET regs_live;\n };\n \n-struct lcm_bb_info\n+struct bb_info\n {\n   struct seginfo *seginfo;\n   int computing;\n@@ -851,7 +892,7 @@ static sbitmap *delete;\n static sbitmap *insert;\n \n static struct seginfo * new_seginfo PARAMS ((int, rtx, int, HARD_REG_SET));\n-static void add_seginfo PARAMS ((struct lcm_bb_info *, struct seginfo *));\n+static void add_seginfo PARAMS ((struct bb_info *, struct seginfo *));\n static void reg_dies PARAMS ((rtx, HARD_REG_SET));\n static void reg_becomes_live PARAMS ((rtx, rtx, void *));\n static void make_preds_opaque PARAMS ((basic_block, int));\n@@ -885,7 +926,7 @@ new_seginfo (mode, insn, bb, regs_live)\n \n static void\n add_seginfo (head, info)\n-     struct lcm_bb_info *head;\n+     struct bb_info *head;\n      struct seginfo *info;\n {\n   struct seginfo *ptr;\n@@ -984,7 +1025,7 @@ optimize_mode_switching (file)\n   static const int num_modes[] = NUM_MODES_FOR_MODE_SWITCHING;\n #define N_ENTITIES (sizeof num_modes / sizeof (int))\n   int entity_map[N_ENTITIES];\n-  struct lcm_bb_info *bb_info[N_ENTITIES];\n+  struct bb_info *bb_info[N_ENTITIES];\n   int i, j;\n   int n_entities;\n   int max_num_modes = 0;\n@@ -1000,7 +1041,7 @@ optimize_mode_switching (file)\n       {\n \t/* Create the list of segments within each basic block.  */\n \tbb_info[n_entities]\n-\t  = (struct lcm_bb_info *) xcalloc (n_basic_blocks, sizeof **bb_info);\n+\t  = (struct bb_info *) xcalloc (n_basic_blocks, sizeof **bb_info);\n \tentity_map[n_entities++] = e;\n \tif (num_modes[e] > max_num_modes)\n \t  max_num_modes = num_modes[e];\n@@ -1039,7 +1080,7 @@ optimize_mode_switching (file)\n     {\n       int e = entity_map[j];\n       int no_mode = num_modes[e];\n-      struct lcm_bb_info *info = bb_info[j];\n+      struct bb_info *info = bb_info[j];\n \n       /* Determine what the first use (if any) need for a mode of entity E is.\n \t This will be the mode that is anticipatable for this block.\n@@ -1141,7 +1182,7 @@ optimize_mode_switching (file)\n       for (j = n_entities - 1; j >= 0; j--)\n \t{\n \t  int m = current_mode[j] = MODE_PRIORITY_TO_MODE (entity_map[j], i);\n-\t  struct lcm_bb_info *info = bb_info[j];\n+\t  struct bb_info *info = bb_info[j];\n \n \t  for (bb = 0 ; bb < n_basic_blocks; bb++)\n \t    {"}]}