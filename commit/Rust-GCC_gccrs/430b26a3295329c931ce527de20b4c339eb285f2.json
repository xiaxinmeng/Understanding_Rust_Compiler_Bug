{"sha": "430b26a3295329c931ce527de20b4c339eb285f2", "node_id": "C_kwDOANBUbNoAKDQzMGIyNmEzMjk1MzI5YzkzMWNlNTI3ZGUyMGI0YzMzOWViMjg1ZjI", "commit": {"author": {"name": "Pierre-Emmanuel Patry", "email": "pierre-emmanuel.patry@embecosm.com", "date": "2023-05-31T10:52:16Z"}, "committer": {"name": "Philip Herron", "email": "philip.herron@embecosm.com", "date": "2023-06-01T15:23:35Z"}, "message": "converter: Convert back Locations from spans\n\nUse spans to get locations of expanded tokens instead of using unknown\nlocations.\n\ngcc/rust/ChangeLog:\n\n\t* lex/rust-lex.h: Make build_token method public.\n\t* lex/rust-token.h: Add a setter for a token location.\n\t* util/rust-token-converter.cc (convert): Add the function to\n\tconvert from a Span to a Location.\n\t(from_ident): Convert Ident span to a Location.\n\t(from_literal): Convert Literal span to a Location.\n\t(from_punct): Convert Punct span to a Location.\n\t(from_group): Convert Group span to a Location.\n\nSigned-off-by: Pierre-Emmanuel Patry <pierre-emmanuel.patry@embecosm.com>", "tree": {"sha": "5beb68993e6cecfcf125237c574a6048e144caa8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/5beb68993e6cecfcf125237c574a6048e144caa8"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/430b26a3295329c931ce527de20b4c339eb285f2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/430b26a3295329c931ce527de20b4c339eb285f2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/430b26a3295329c931ce527de20b4c339eb285f2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/430b26a3295329c931ce527de20b4c339eb285f2/comments", "author": {"login": "P-E-P", "id": 32375388, "node_id": "MDQ6VXNlcjMyMzc1Mzg4", "avatar_url": "https://avatars.githubusercontent.com/u/32375388?v=4", "gravatar_id": "", "url": "https://api.github.com/users/P-E-P", "html_url": "https://github.com/P-E-P", "followers_url": "https://api.github.com/users/P-E-P/followers", "following_url": "https://api.github.com/users/P-E-P/following{/other_user}", "gists_url": "https://api.github.com/users/P-E-P/gists{/gist_id}", "starred_url": "https://api.github.com/users/P-E-P/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/P-E-P/subscriptions", "organizations_url": "https://api.github.com/users/P-E-P/orgs", "repos_url": "https://api.github.com/users/P-E-P/repos", "events_url": "https://api.github.com/users/P-E-P/events{/privacy}", "received_events_url": "https://api.github.com/users/P-E-P/received_events", "type": "User", "site_admin": false}, "committer": {"login": "philberty", "id": 84585, "node_id": "MDQ6VXNlcjg0NTg1", "avatar_url": "https://avatars.githubusercontent.com/u/84585?v=4", "gravatar_id": "", "url": "https://api.github.com/users/philberty", "html_url": "https://github.com/philberty", "followers_url": "https://api.github.com/users/philberty/followers", "following_url": "https://api.github.com/users/philberty/following{/other_user}", "gists_url": "https://api.github.com/users/philberty/gists{/gist_id}", "starred_url": "https://api.github.com/users/philberty/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/philberty/subscriptions", "organizations_url": "https://api.github.com/users/philberty/orgs", "repos_url": "https://api.github.com/users/philberty/repos", "events_url": "https://api.github.com/users/philberty/events{/privacy}", "received_events_url": "https://api.github.com/users/philberty/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f35d52ce69df89401bde47f648868fb227a7de40", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f35d52ce69df89401bde47f648868fb227a7de40", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f35d52ce69df89401bde47f648868fb227a7de40"}], "stats": {"total": 53, "additions": 32, "deletions": 21}, "files": [{"sha": "6f89be4bddb770c95b7342322745d2a4fd7ff34c", "filename": "gcc/rust/lex/rust-lex.h", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/430b26a3295329c931ce527de20b4c339eb285f2/gcc%2Frust%2Flex%2Frust-lex.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/430b26a3295329c931ce527de20b4c339eb285f2/gcc%2Frust%2Flex%2Frust-lex.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-lex.h?ref=430b26a3295329c931ce527de20b4c339eb285f2", "patch": "@@ -126,9 +126,6 @@ class Lexer\n   // Classifies keyword (i.e. gets id for keyword).\n   TokenId classify_keyword (const std::string &str);\n \n-  // Builds a token from the input queue.\n-  TokenPtr build_token ();\n-\n   std::tuple<std::string, int, bool> parse_in_decimal ();\n   std::pair<std::string, int> parse_in_exponent_part ();\n   std::pair<PrimitiveCoreType, int> parse_in_type_suffix ();\n@@ -187,6 +184,9 @@ class Lexer\n   // Peeks the current token.\n   const_TokenPtr peek_token () { return peek_token (0); }\n \n+  // Builds a token from the input queue.\n+  TokenPtr build_token ();\n+\n   // Advances current token to n + 1 tokens ahead of current position.\n   void skip_token (int n);\n   // Skips the current token."}, {"sha": "7c6bcae906b58883232cffc86b385f8e2f21d7d3", "filename": "gcc/rust/lex/rust-token.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/430b26a3295329c931ce527de20b4c339eb285f2/gcc%2Frust%2Flex%2Frust-token.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/430b26a3295329c931ce527de20b4c339eb285f2/gcc%2Frust%2Flex%2Frust-token.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-token.h?ref=430b26a3295329c931ce527de20b4c339eb285f2", "patch": "@@ -386,6 +386,9 @@ class Token\n   // Gets location of the token.\n   Location get_locus () const { return locus; }\n \n+  // Set location of the token.\n+  void set_locus (Location locus) { this->locus = locus; }\n+\n   // Gets string description of the token.\n   const std::string &\n   get_str () const; /*{"}, {"sha": "d8b9090c8d2dc2ec2a17f53a4204c34f52a55b06", "filename": "gcc/rust/util/rust-token-converter.cc", "status": "modified", "additions": 26, "deletions": 18, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/430b26a3295329c931ce527de20b4c339eb285f2/gcc%2Frust%2Futil%2Frust-token-converter.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/430b26a3295329c931ce527de20b4c339eb285f2/gcc%2Frust%2Futil%2Frust-token-converter.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Futil%2Frust-token-converter.cc?ref=430b26a3295329c931ce527de20b4c339eb285f2", "patch": "@@ -57,6 +57,12 @@ convert (Location location)\n   return ProcMacro::Span::make_span (location.gcc_location (), 0);\n }\n \n+static Location\n+convert (ProcMacro::Span span)\n+{\n+  return Location (span.start);\n+}\n+\n static void\n handle_suffix (ProcMacro::TokenStream &ts, const const_TokenPtr &token,\n \t       ProcMacro::LitKind kind)\n@@ -275,10 +281,10 @@ from_ident (const ProcMacro::Ident &ident, std::vector<const_TokenPtr> &result)\n   if (ident.is_raw)\n     value = \"r#\" + value;\n \n-  // TODO: Inject span -> for now spans are not stored in Ident, once changed\n-  // the span should be injected in the built token below.\n   Lexer lexer (value);\n-  result.push_back (lexer.peek_token ());\n+  auto token = lexer.build_token ();\n+  token->set_locus (convert (ident.span));\n+  result.push_back (token);\n }\n \n /**\n@@ -292,34 +298,33 @@ from_literal (const ProcMacro::Literal &literal,\n \t      std::vector<const_TokenPtr> &result)\n {\n   auto lookup = suffixes.lookup (literal.suffix.to_string ());\n+  auto loc = convert (literal.span);\n   auto suffix\n     = suffixes.is_iter_ok (lookup) ? lookup->second : CORETYPE_UNKNOWN;\n   // FIXME: Add spans instead of empty locations\n   switch (literal.kind.tag)\n     {\n     case ProcMacro::BYTE:\n       result.push_back (\n-\tToken::make_byte_char (Location (), literal.text.to_string ()[0]));\n+\tToken::make_byte_char (loc, literal.text.to_string ()[0]));\n       break;\n     case ProcMacro::CHAR:\n-      result.push_back (\n-\tToken::make_char (Location (), literal.text.to_string ()[0]));\n+      result.push_back (Token::make_char (loc, literal.text.to_string ()[0]));\n       break;\n     case ProcMacro::INTEGER:\n       result.push_back (\n-\tToken::make_int (Location (), literal.text.to_string (), suffix));\n+\tToken::make_int (loc, literal.text.to_string (), suffix));\n       break;\n     case ProcMacro::FLOAT:\n       result.push_back (\n-\tToken::make_float (Location (), literal.text.to_string (), suffix));\n+\tToken::make_float (loc, literal.text.to_string (), suffix));\n       break;\n     case ProcMacro::STR:\n-      result.push_back (\n-\tToken::make_string (Location (), literal.text.to_string ()));\n+      result.push_back (Token::make_string (loc, literal.text.to_string ()));\n       break;\n     case ProcMacro::BYTE_STR:\n       result.push_back (\n-\tToken::make_byte_string (Location (), literal.text.to_string ()));\n+\tToken::make_byte_string (loc, literal.text.to_string ()));\n       break;\n     // FIXME: Handle raw string\n     case ProcMacro::STR_RAW:\n@@ -347,7 +352,9 @@ from_punct (const ProcMacro::Punct &punct, std::vector<std::uint32_t> &acc,\n       // TODO: UTF-8 string\n       std::string whole (acc.begin (), acc.end ());\n       auto lexer = Lexer (whole);\n-      result.push_back (lexer.peek_token ());\n+      auto token = lexer.build_token ();\n+      token->set_locus (convert (punct.span));\n+      result.push_back (token);\n       acc.clear ();\n     }\n }\n@@ -362,22 +369,23 @@ from_punct (const ProcMacro::Punct &punct, std::vector<std::uint32_t> &acc,\n static void\n from_group (const ProcMacro::Group &g, std::vector<const_TokenPtr> &result)\n {\n+  auto loc = convert (g.span);\n   switch (g.delimiter)\n     {\n     case ProcMacro::PARENTHESIS:\n-      result.push_back (Token::make (LEFT_PAREN, Location ()));\n+      result.push_back (Token::make (LEFT_PAREN, loc));\n       from_tokenstream (g.stream, result);\n-      result.push_back (Token::make (RIGHT_PAREN, Location ()));\n+      result.push_back (Token::make (RIGHT_PAREN, loc));\n       break;\n     case ProcMacro::BRACE:\n-      result.push_back (Token::make (LEFT_CURLY, Location ()));\n+      result.push_back (Token::make (LEFT_CURLY, loc));\n       from_tokenstream (g.stream, result);\n-      result.push_back (Token::make (RIGHT_CURLY, Location ()));\n+      result.push_back (Token::make (RIGHT_CURLY, loc));\n       break;\n     case ProcMacro::BRACKET:\n-      result.push_back (Token::make (LEFT_SQUARE, Location ()));\n+      result.push_back (Token::make (LEFT_SQUARE, loc));\n       from_tokenstream (g.stream, result);\n-      result.push_back (Token::make (RIGHT_SQUARE, Location ()));\n+      result.push_back (Token::make (RIGHT_SQUARE, loc));\n       break;\n     case ProcMacro::NONE:\n       from_tokenstream (g.stream, result);"}]}