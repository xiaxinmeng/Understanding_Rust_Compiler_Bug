{"sha": "46e778c4f5a3c93deaf16faeacd4628823f5efb0", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDZlNzc4YzRmNWEzYzkzZGVhZjE2ZmFlYWNkNDYyODgyM2Y1ZWZiMA==", "commit": {"author": {"name": "James Greenhalgh", "email": "james.greenhalgh@arm.com", "date": "2013-11-26T10:03:14Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2013-11-26T10:03:14Z"}, "message": "[AArch64] [3/4 Fix vtbx1]Implement bsl intrinsics using builtins\n\ngcc/\n\t* config/aarch64/aarch64-builtins.c\n\t(aarch64_types_bsl_p_qualifiers): New.\n\t(aarch64_types_bsl_s_qualifiers): Likewise.\n\t(aarch64_types_bsl_u_qualifiers): Likewise.\n\t(TYPES_BSL_P): Likewise.\n\t(TYPES_BSL_S): Likewise.\n\t(TYPES_BSL_U): Likewise.\n\t(BUILTIN_VALLDIF): Likewise.\n\t(BUILTIN_VDQQH): Likewise.\n\t* config/aarch64/aarch64-simd-builtins.def (simd_bsl): New.\n\t* config/aarch64/aarch64-simd.md\n\t(aarch64_simd_bsl<mode>_internal): Handle more modes.\n\t(aarch64_simd_bsl<mode>): Likewise.\n\t* config/aarch64/arm_neon.h\n\t(vbsl<q>_<fpsu><8,16,32,64): Implement using builtins.\n\t* config/aarch64/iterators.md (VALLDIF): New.\n\t(Vbtype): Handle more modes.\n\nFrom-SVN: r205385", "tree": {"sha": "b2fa6662c10162f57cba60f6459f47e49c4d4064", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b2fa6662c10162f57cba60f6459f47e49c4d4064"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/46e778c4f5a3c93deaf16faeacd4628823f5efb0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/46e778c4f5a3c93deaf16faeacd4628823f5efb0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/46e778c4f5a3c93deaf16faeacd4628823f5efb0", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/46e778c4f5a3c93deaf16faeacd4628823f5efb0/comments", "author": {"login": "jgreenhalgh-arm", "id": 6104025, "node_id": "MDQ6VXNlcjYxMDQwMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/6104025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgreenhalgh-arm", "html_url": "https://github.com/jgreenhalgh-arm", "followers_url": "https://api.github.com/users/jgreenhalgh-arm/followers", "following_url": "https://api.github.com/users/jgreenhalgh-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jgreenhalgh-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgreenhalgh-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgreenhalgh-arm/subscriptions", "organizations_url": "https://api.github.com/users/jgreenhalgh-arm/orgs", "repos_url": "https://api.github.com/users/jgreenhalgh-arm/repos", "events_url": "https://api.github.com/users/jgreenhalgh-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jgreenhalgh-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "6db1ec948e8c7220d7c8c01d74d6c6a7db00adb7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6db1ec948e8c7220d7c8c01d74d6c6a7db00adb7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6db1ec948e8c7220d7c8c01d74d6c6a7db00adb7"}], "stats": {"total": 464, "additions": 201, "deletions": 263}, "files": [{"sha": "52c507d7ba604608eb3c8052b1167e6990481cb5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=46e778c4f5a3c93deaf16faeacd4628823f5efb0", "patch": "@@ -1,3 +1,23 @@\n+2013-11-26  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/aarch64/aarch64-builtins.c\n+\t(aarch64_types_bsl_p_qualifiers): New.\n+\t(aarch64_types_bsl_s_qualifiers): Likewise.\n+\t(aarch64_types_bsl_u_qualifiers): Likewise.\n+\t(TYPES_BSL_P): Likewise.\n+\t(TYPES_BSL_S): Likewise.\n+\t(TYPES_BSL_U): Likewise.\n+\t(BUILTIN_VALLDIF): Likewise.\n+\t(BUILTIN_VDQQH): Likewise.\n+\t* config/aarch64/aarch64-simd-builtins.def (simd_bsl): New.\n+\t* config/aarch64/aarch64-simd.md\n+\t(aarch64_simd_bsl<mode>_internal): Handle more modes.\n+\t(aarch64_simd_bsl<mode>): Likewise.\n+\t* config/aarch64/arm_neon.h\n+\t(vbsl<q>_<fpsu><8,16,32,64): Implement using builtins.\n+\t* config/aarch64/iterators.md (VALLDIF): New.\n+\t(Vbtype): Handle more modes.\n+\n 2013-11-26  James Greenhalgh  <james.greenhalgh@arm.com>\n \n \t* config/aarch64/aarch64-builtins.c"}, {"sha": "1bc3cc5e96dda9f1d0a557c9c665c92037b02f86", "filename": "gcc/config/aarch64/aarch64-builtins.c", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c?ref=46e778c4f5a3c93deaf16faeacd4628823f5efb0", "patch": "@@ -181,6 +181,22 @@ aarch64_types_load1_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n #define TYPES_LOAD1 (aarch64_types_load1_qualifiers)\n #define TYPES_LOADSTRUCT (aarch64_types_load1_qualifiers)\n \n+static enum aarch64_type_qualifiers\n+aarch64_types_bsl_p_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n+  = { qualifier_poly, qualifier_unsigned,\n+      qualifier_poly, qualifier_poly };\n+#define TYPES_BSL_P (aarch64_types_bsl_p_qualifiers)\n+static enum aarch64_type_qualifiers\n+aarch64_types_bsl_s_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n+  = { qualifier_none, qualifier_unsigned,\n+      qualifier_none, qualifier_none };\n+#define TYPES_BSL_S (aarch64_types_bsl_s_qualifiers)\n+static enum aarch64_type_qualifiers\n+aarch64_types_bsl_u_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n+  = { qualifier_unsigned, qualifier_unsigned,\n+      qualifier_unsigned, qualifier_unsigned };\n+#define TYPES_BSL_U (aarch64_types_bsl_u_qualifiers)\n+\n /* The first argument (return type) of a store should be void type,\n    which we represent with qualifier_void.  Their first operand will be\n    a DImode pointer to the location to store to, so we must use\n@@ -255,6 +271,9 @@ aarch64_types_store1_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n #define BUILTIN_VALLDI(T, N, MAP) \\\n   VAR11 (T, N, MAP, v8qi, v16qi, v4hi, v8hi, v2si, \\\n \t v4si, v2di, v2sf, v4sf, v2df, di)\n+#define BUILTIN_VALLDIF(T, N, MAP) \\\n+  VAR12 (T, N, MAP, v8qi, v16qi, v4hi, v8hi, v2si, \\\n+\t v4si, v2di, v2sf, v4sf, v2df, di, df)\n #define BUILTIN_VB(T, N, MAP) \\\n   VAR2 (T, N, MAP, v8qi, v16qi)\n #define BUILTIN_VD(T, N, MAP) \\\n@@ -279,6 +298,8 @@ aarch64_types_store1_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n   VAR6 (T, N, MAP, v8qi, v16qi, v4hi, v8hi, v2si, v4si)\n #define BUILTIN_VDQV(T, N, MAP) \\\n   VAR5 (T, N, MAP, v8qi, v16qi, v4hi, v8hi, v4si)\n+#define BUILTIN_VDQQH(T, N, MAP) \\\n+  VAR4 (T, N, MAP, v8qi, v16qi, v4hi, v8hi)\n #define BUILTIN_VDQ_BHSI(T, N, MAP) \\\n   VAR6 (T, N, MAP, v8qi, v16qi, v4hi, v8hi, v2si, v4si)\n #define BUILTIN_VDQ_I(T, N, MAP) \\"}, {"sha": "1dc3c1fe33fdb8148d2ff9c7198e4d85d5dac5d7", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=46e778c4f5a3c93deaf16faeacd4628823f5efb0", "patch": "@@ -362,3 +362,8 @@\n   /* Implemented by fma<mode>4.  */\n   BUILTIN_VDQF (TERNOP, fma, 4)\n \n+  /* Implemented by aarch64_simd_bsl<mode>.  */\n+  BUILTIN_VDQQH (BSL_P, simd_bsl, 0)\n+  BUILTIN_VSDQ_I_DI (BSL_U, simd_bsl, 0)\n+  BUILTIN_VALLDIF (BSL_S, simd_bsl, 0)\n+"}, {"sha": "158b3dca6da12322de0af80d35f593039d716de6", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=46e778c4f5a3c93deaf16faeacd4628823f5efb0", "patch": "@@ -1662,15 +1662,15 @@\n ;;     bif op0, op1, mask\n \n (define_insn \"aarch64_simd_bsl<mode>_internal\"\n-  [(set (match_operand:VALL 0 \"register_operand\"\t\t\"=w,w,w\")\n-\t(ior:VALL\n-\t   (and:VALL\n+  [(set (match_operand:VALLDIF 0 \"register_operand\"\t\t\"=w,w,w\")\n+\t(ior:VALLDIF\n+\t   (and:VALLDIF\n \t     (match_operand:<V_cmp_result> 1 \"register_operand\"\t\" 0,w,w\")\n-\t     (match_operand:VALL 2 \"register_operand\"\t\t\" w,w,0\"))\n-\t   (and:VALL\n+\t     (match_operand:VALLDIF 2 \"register_operand\"\t\" w,w,0\"))\n+\t   (and:VALLDIF\n \t     (not:<V_cmp_result>\n \t\t(match_dup:<V_cmp_result> 1))\n-\t     (match_operand:VALL 3 \"register_operand\"\t\t\" w,0,w\"))\n+\t     (match_operand:VALLDIF 3 \"register_operand\"\t\" w,0,w\"))\n \t))]\n   \"TARGET_SIMD\"\n   \"@\n@@ -1681,10 +1681,10 @@\n )\n \n (define_expand \"aarch64_simd_bsl<mode>\"\n-  [(match_operand:VALL 0 \"register_operand\")\n+  [(match_operand:VALLDIF 0 \"register_operand\")\n    (match_operand:<V_cmp_result> 1 \"register_operand\")\n-   (match_operand:VALL 2 \"register_operand\")\n-   (match_operand:VALL 3 \"register_operand\")]\n+   (match_operand:VALLDIF 2 \"register_operand\")\n+   (match_operand:VALLDIF 3 \"register_operand\")]\n  \"TARGET_SIMD\"\n {\n   /* We can't alias operands together if they have different modes.  */"}, {"sha": "6826ffb827c4589fe375393a44d32c360e3fa78c", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 140, "deletions": 253, "changes": 393, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=46e778c4f5a3c93deaf16faeacd4628823f5efb0", "patch": "@@ -4839,259 +4839,6 @@ vaddlvq_u32 (uint32x4_t a)\n   return result;\n }\n \n-__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n-vbsl_f32 (uint32x2_t a, float32x2_t b, float32x2_t c)\n-{\n-  float32x2_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n-vbsl_p8 (uint8x8_t a, poly8x8_t b, poly8x8_t c)\n-{\n-  poly8x8_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n-vbsl_p16 (uint16x4_t a, poly16x4_t b, poly16x4_t c)\n-{\n-  poly16x4_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n-vbsl_s8 (uint8x8_t a, int8x8_t b, int8x8_t c)\n-{\n-  int8x8_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n-vbsl_s16 (uint16x4_t a, int16x4_t b, int16x4_t c)\n-{\n-  int16x4_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n-vbsl_s32 (uint32x2_t a, int32x2_t b, int32x2_t c)\n-{\n-  int32x2_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n-vbsl_s64 (uint64x1_t a, int64x1_t b, int64x1_t c)\n-{\n-  int64x1_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n-vbsl_u8 (uint8x8_t a, uint8x8_t b, uint8x8_t c)\n-{\n-  uint8x8_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n-vbsl_u16 (uint16x4_t a, uint16x4_t b, uint16x4_t c)\n-{\n-  uint16x4_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n-vbsl_u32 (uint32x2_t a, uint32x2_t b, uint32x2_t c)\n-{\n-  uint32x2_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n-vbsl_u64 (uint64x1_t a, uint64x1_t b, uint64x1_t c)\n-{\n-  uint64x1_t result;\n-  __asm__ (\"bsl %0.8b, %2.8b, %3.8b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n-vbslq_f32 (uint32x4_t a, float32x4_t b, float32x4_t c)\n-{\n-  float32x4_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n-vbslq_f64 (uint64x2_t a, float64x2_t b, float64x2_t c)\n-{\n-  float64x2_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n-vbslq_p8 (uint8x16_t a, poly8x16_t b, poly8x16_t c)\n-{\n-  poly8x16_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n-vbslq_p16 (uint16x8_t a, poly16x8_t b, poly16x8_t c)\n-{\n-  poly16x8_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n-vbslq_s8 (uint8x16_t a, int8x16_t b, int8x16_t c)\n-{\n-  int8x16_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n-vbslq_s16 (uint16x8_t a, int16x8_t b, int16x8_t c)\n-{\n-  int16x8_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n-vbslq_s32 (uint32x4_t a, int32x4_t b, int32x4_t c)\n-{\n-  int32x4_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n-vbslq_s64 (uint64x2_t a, int64x2_t b, int64x2_t c)\n-{\n-  int64x2_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n-vbslq_u8 (uint8x16_t a, uint8x16_t b, uint8x16_t c)\n-{\n-  uint8x16_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n-vbslq_u16 (uint16x8_t a, uint16x8_t b, uint16x8_t c)\n-{\n-  uint16x8_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n-vbslq_u32 (uint32x4_t a, uint32x4_t b, uint32x4_t c)\n-{\n-  uint32x4_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n-vbslq_u64 (uint64x2_t a, uint64x2_t b, uint64x2_t c)\n-{\n-  uint64x2_t result;\n-  __asm__ (\"bsl %0.16b, %2.16b, %3.16b\"\n-           : \"=w\"(result)\n-           : \"0\"(a), \"w\"(b), \"w\"(c)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vcls_s8 (int8x8_t a)\n {\n@@ -15793,6 +15540,146 @@ vaddvq_f64 (float64x2_t __a)\n   return vgetq_lane_f64 (__t, __LANE0 (2));\n }\n \n+/* vbsl  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vbsl_f32 (uint32x2_t __a, float32x2_t __b, float32x2_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv2sf_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n+vbsl_p8 (uint8x8_t __a, poly8x8_t __b, poly8x8_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv8qi_pupp (__a, __b, __c);\n+}\n+\n+__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n+vbsl_p16 (uint16x4_t __a, poly16x4_t __b, poly16x4_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv4hi_pupp (__a, __b, __c);\n+}\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vbsl_s8 (uint8x8_t __a, int8x8_t __b, int8x8_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv8qi_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vbsl_s16 (uint16x4_t __a, int16x4_t __b, int16x4_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv4hi_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vbsl_s32 (uint32x2_t __a, int32x2_t __b, int32x2_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv2si_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n+vbsl_s64 (uint64x1_t __a, int64x1_t __b, int64x1_t __c)\n+{\n+  return __builtin_aarch64_simd_bsldi_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vbsl_u8 (uint8x8_t __a, uint8x8_t __b, uint8x8_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv8qi_uuuu (__a, __b, __c);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vbsl_u16 (uint16x4_t __a, uint16x4_t __b, uint16x4_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv4hi_uuuu (__a, __b, __c);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vbsl_u32 (uint32x2_t __a, uint32x2_t __b, uint32x2_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv2si_uuuu (__a, __b, __c);\n+}\n+\n+__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n+vbsl_u64 (uint64x1_t __a, uint64x1_t __b, uint64x1_t __c)\n+{\n+  return __builtin_aarch64_simd_bsldi_uuuu (__a, __b, __c);\n+}\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vbslq_f32 (uint32x4_t __a, float32x4_t __b, float32x4_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv4sf_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vbslq_f64 (uint64x2_t __a, float64x2_t __b, float64x2_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv2df_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n+vbslq_p8 (uint8x16_t __a, poly8x16_t __b, poly8x16_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv16qi_pupp (__a, __b, __c);\n+}\n+\n+__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n+vbslq_p16 (uint16x8_t __a, poly16x8_t __b, poly16x8_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv8hi_pupp (__a, __b, __c);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vbslq_s8 (uint8x16_t __a, int8x16_t __b, int8x16_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv16qi_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vbslq_s16 (uint16x8_t __a, int16x8_t __b, int16x8_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv8hi_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vbslq_s32 (uint32x4_t __a, int32x4_t __b, int32x4_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv4si_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n+vbslq_s64 (uint64x2_t __a, int64x2_t __b, int64x2_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv2di_suss (__a, __b, __c);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vbslq_u8 (uint8x16_t __a, uint8x16_t __b, uint8x16_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv16qi_uuuu (__a, __b, __c);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vbslq_u16 (uint16x8_t __a, uint16x8_t __b, uint16x8_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv8hi_uuuu (__a, __b, __c);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vbslq_u32 (uint32x4_t __a, uint32x4_t __b, uint32x4_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv4si_uuuu (__a, __b, __c);\n+}\n+\n+__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n+vbslq_u64 (uint64x2_t __a, uint64x2_t __b, uint64x2_t __c)\n+{\n+  return __builtin_aarch64_simd_bslv2di_uuuu (__a, __b, __c);\n+}\n+\n /* vcage  */\n \n __extension__ static __inline uint32_t __attribute__ ((__always_inline__))"}, {"sha": "43279ad2c0cd222d9754e8dc4b0c7a82fbf0f0a5", "filename": "gcc/config/aarch64/iterators.md", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46e778c4f5a3c93deaf16faeacd4628823f5efb0/gcc%2Fconfig%2Faarch64%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fiterators.md?ref=46e778c4f5a3c93deaf16faeacd4628823f5efb0", "patch": "@@ -107,6 +107,10 @@\n ;; All vector modes and DI.\n (define_mode_iterator VALLDI [V8QI V16QI V4HI V8HI V2SI V4SI V2DI V2SF V4SF V2DF DI])\n \n+;; All vector modes and DI and DF.\n+(define_mode_iterator VALLDIF [V8QI V16QI V4HI V8HI V2SI V4SI\n+\t\t\t       V2DI V2SF V4SF V2DF DI DF])\n+\n ;; Vector modes for Integer reduction across lanes.\n (define_mode_iterator VDQV [V8QI V16QI V4HI V8HI V4SI V2DI])\n \n@@ -363,7 +367,8 @@\n \t\t\t  (V4HI \"8b\") (V8HI  \"16b\")\n \t\t\t  (V2SI \"8b\") (V4SI  \"16b\")\n \t\t\t  (V2DI \"16b\") (V2SF  \"8b\")\n-\t\t\t  (V4SF \"16b\") (V2DF  \"16b\")])\n+\t\t\t  (V4SF \"16b\") (V2DF  \"16b\")\n+\t\t\t  (DI   \"8b\")  (DF    \"8b\")])\n \n ;; Define element mode for each vector mode.\n (define_mode_attr VEL [(V8QI \"QI\") (V16QI \"QI\")"}]}