{"sha": "6991c6c926a5909c438c0ea92d98175b41014598", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Njk5MWM2YzkyNmE1OTA5YzQzOGMwZWE5MmQ5ODE3NWI0MTAxNDU5OA==", "commit": {"author": {"name": "Jeff Sturm", "email": "jsturm@gcc.gnu.org", "date": "2003-07-28T03:46:07Z"}, "committer": {"name": "Jeff Sturm", "email": "jsturm@gcc.gnu.org", "date": "2003-07-28T03:46:07Z"}, "message": "Initial revision\n\nFrom-SVN: r69872", "tree": {"sha": "c698ff9b5618f81b32dbda3a94016046ef2e1a48", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c698ff9b5618f81b32dbda3a94016046ef2e1a48"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/6991c6c926a5909c438c0ea92d98175b41014598", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6991c6c926a5909c438c0ea92d98175b41014598", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6991c6c926a5909c438c0ea92d98175b41014598", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6991c6c926a5909c438c0ea92d98175b41014598/comments", "author": null, "committer": null, "parents": [{"sha": "b4acb5ef4bb1cbe6e41ef20adcf4317ef118ee6f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b4acb5ef4bb1cbe6e41ef20adcf4317ef118ee6f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b4acb5ef4bb1cbe6e41ef20adcf4317ef118ee6f"}], "stats": {"total": 5739, "additions": 5739, "deletions": 0}, "files": [{"sha": "d8ac3454af9036ed989b6706773b1b89b5a6b841", "filename": "boehm-gc/aix_irix_threads.c", "status": "added", "additions": 693, "deletions": 0, "changes": 693, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Faix_irix_threads.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Faix_irix_threads.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Faix_irix_threads.c?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,693 @@\n+/* \n+ * Copyright (c) 1991-1995 by Xerox Corporation.  All rights reserved.\n+ * Copyright (c) 1996-1999 by Silicon Graphics.  All rights reserved.\n+ * Copyright (c) 1999-2003 by Hewlett-Packard Company. All rights reserved.\n+ *\n+ * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n+ * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n+ *\n+ * Permission is hereby granted to use or copy this program\n+ * for any purpose,  provided the above notices are retained on all copies.\n+ * Permission to modify the code and to distribute modified code is granted,\n+ * provided the above notices are retained, and a notice that the code was\n+ * modified is included with the above copyright notice.\n+ */\n+/*\n+ * Support code for Irix (>=6.2) Pthreads and for AIX pthreads.\n+ * This relies on properties\n+ * not guaranteed by the Pthread standard.  It may or may not be portable\n+ * to other implementations.\n+ *\n+ * Note that there is a lot of code duplication between this file and\n+ * (pthread_support.c, pthread_stop_world.c).  They should be merged.\n+ * Pthread_support.c should be directly usable.\n+ *\n+ * Please avoid adding new ports here; use the generic pthread support\n+ * as a base instead.\n+ */\n+\n+# if defined(GC_IRIX_THREADS) || defined(GC_AIX_THREADS)\n+\n+# include \"private/gc_priv.h\"\n+# include <pthread.h>\n+# include <assert.h>\n+# include <semaphore.h>\n+# include <time.h>\n+# include <errno.h>\n+# include <unistd.h>\n+# include <sys/mman.h>\n+# include <sys/time.h>\n+\n+#undef pthread_create\n+#undef pthread_sigmask\n+#undef pthread_join\n+\n+#if defined(GC_IRIX_THREADS) && !defined(MUTEX_RECURSIVE_NP)\n+#define MUTEX_RECURSIVE_NP PTHREAD_MUTEX_RECURSIVE\n+#endif\n+\n+void GC_thr_init();\n+\n+#if 0\n+void GC_print_sig_mask()\n+{\n+    sigset_t blocked;\n+    int i;\n+\n+    if (pthread_sigmask(SIG_BLOCK, NULL, &blocked) != 0)\n+    \tABORT(\"pthread_sigmask\");\n+    GC_printf0(\"Blocked: \");\n+    for (i = 1; i <= MAXSIG; i++) {\n+        if (sigismember(&blocked, i)) { GC_printf1(\"%ld \",(long) i); }\n+    }\n+    GC_printf0(\"\\n\");\n+}\n+#endif\n+\n+/* We use the allocation lock to protect thread-related data structures. */\n+\n+/* The set of all known threads.  We intercept thread creation and \t*/\n+/* joins.  We never actually create detached threads.  We allocate all \t*/\n+/* new thread stacks ourselves.  These allow us to maintain this\t*/\n+/* data structure.\t\t\t\t\t\t\t*/\n+/* Protected by GC_thr_lock.\t\t\t\t\t\t*/\n+/* Some of this should be declared volatile, but that's incosnsistent\t*/\n+/* with some library routine declarations.  \t\t \t\t*/\n+typedef struct GC_Thread_Rep {\n+    struct GC_Thread_Rep * next;  /* More recently allocated threads\t*/\n+\t\t\t\t  /* with a given pthread id come \t*/\n+\t\t\t\t  /* first.  (All but the first are\t*/\n+\t\t\t\t  /* guaranteed to be dead, but we may  */\n+\t\t\t\t  /* not yet have registered the join.) */\n+    pthread_t id;\n+    word stop;\n+#\tdefine NOT_STOPPED 0\n+#\tdefine PLEASE_STOP 1\n+#\tdefine STOPPED 2\n+    word flags;\n+#\tdefine FINISHED 1   \t/* Thread has exited.\t*/\n+#\tdefine DETACHED 2\t/* Thread is intended to be detached.\t*/\n+    ptr_t stack_cold;\t\t/* cold end of the stack\t\t*/\n+    ptr_t stack_hot;  \t\t/* Valid only when stopped. */\n+\t\t\t\t/* But must be within stack region at\t*/\n+\t\t\t\t/* all times.\t\t\t\t*/\n+    void * status;\t\t/* Used only to avoid premature \t*/\n+\t\t\t\t/* reclamation of any data it might \t*/\n+\t\t\t\t/* reference.\t\t\t\t*/\n+} * GC_thread;\n+\n+GC_thread GC_lookup_thread(pthread_t id);\n+\n+/*\n+ * The only way to suspend threads given the pthread interface is to send\n+ * signals.  Unfortunately, this means we have to reserve\n+ * a signal, and intercept client calls to change the signal mask.\n+ */\n+#if 0 /* DOB: 6.1 */\n+# if defined(GC_AIX_THREADS)\n+#   define SIG_SUSPEND SIGUSR1\n+# else\n+#   define SIG_SUSPEND (SIGRTMIN + 6)\n+# endif\n+#endif\n+\n+pthread_mutex_t GC_suspend_lock = PTHREAD_MUTEX_INITIALIZER;\n+\t\t\t\t/* Number of threads stopped so far\t*/\n+pthread_cond_t GC_suspend_ack_cv = PTHREAD_COND_INITIALIZER;\n+pthread_cond_t GC_continue_cv = PTHREAD_COND_INITIALIZER;\n+\n+void GC_suspend_handler(int sig)\n+{\n+    int dummy;\n+    GC_thread me;\n+    sigset_t all_sigs;\n+    sigset_t old_sigs;\n+    int i;\n+\n+    if (sig != SIG_SUSPEND) ABORT(\"Bad signal in suspend_handler\");\n+    me = GC_lookup_thread(pthread_self());\n+    /* The lookup here is safe, since I'm doing this on behalf  */\n+    /* of a thread which holds the allocation lock in order\t*/\n+    /* to stop the world.  Thus concurrent modification of the\t*/\n+    /* data structure is impossible.\t\t\t\t*/\n+    if (PLEASE_STOP != me -> stop) {\n+\t/* Misdirected signal.\t*/\n+\tpthread_mutex_unlock(&GC_suspend_lock);\n+\treturn;\n+    }\n+    pthread_mutex_lock(&GC_suspend_lock);\n+    me -> stack_hot = (ptr_t)(&dummy);\n+    me -> stop = STOPPED;\n+    pthread_cond_signal(&GC_suspend_ack_cv);\n+    pthread_cond_wait(&GC_continue_cv, &GC_suspend_lock);\n+    pthread_mutex_unlock(&GC_suspend_lock);\n+    /* GC_printf1(\"Continuing 0x%x\\n\", pthread_self()); */\n+}\n+\n+\n+GC_bool GC_thr_initialized = FALSE;\n+\n+\n+# define THREAD_TABLE_SZ 128\t/* Must be power of 2\t*/\n+volatile GC_thread GC_threads[THREAD_TABLE_SZ];\n+\n+void GC_push_thread_structures GC_PROTO((void))\n+{\n+    GC_push_all((ptr_t)(GC_threads), (ptr_t)(GC_threads)+sizeof(GC_threads));\n+}\n+\n+/* Add a thread to GC_threads.  We assume it wasn't already there.\t*/\n+/* Caller holds allocation lock.\t\t\t\t\t*/\n+GC_thread GC_new_thread(pthread_t id)\n+{\n+    int hv = ((word)id) % THREAD_TABLE_SZ;\n+    GC_thread result;\n+    static struct GC_Thread_Rep first_thread;\n+    static GC_bool first_thread_used = FALSE;\n+    \n+    GC_ASSERT(I_HOLD_LOCK());\n+    if (!first_thread_used) {\n+    \tresult = &first_thread;\n+    \tfirst_thread_used = TRUE;\n+    \t/* Dont acquire allocation lock, since we may already hold it. */\n+    } else {\n+        result = (struct GC_Thread_Rep *)\n+        \t GC_generic_malloc_inner(sizeof(struct GC_Thread_Rep), NORMAL);\n+    }\n+    if (result == 0) return(0);\n+    result -> id = id;\n+    result -> next = GC_threads[hv];\n+    GC_threads[hv] = result;\n+    /* result -> flags = 0;     */\n+    /* result -> stop = 0;\t*/\n+    return(result);\n+}\n+\n+/* Delete a thread from GC_threads.  We assume it is there.\t*/\n+/* (The code intentionally traps if it wasn't.)\t\t\t*/\n+/* Caller holds allocation lock.\t\t\t\t*/\n+/* We explicitly pass in the GC_thread we're looking for, since */\n+/* if a thread has been joined, but we have not yet\t\t*/\n+/* been notified, then there may be more than one thread \t*/\n+/* in the table with the same pthread id.\t\t\t*/\n+/* This is OK, but we need a way to delete a specific one.\t*/\n+void GC_delete_gc_thread(pthread_t id, GC_thread gc_id)\n+{\n+    int hv = ((word)id) % THREAD_TABLE_SZ;\n+    register GC_thread p = GC_threads[hv];\n+    register GC_thread prev = 0;\n+\n+    GC_ASSERT(I_HOLD_LOCK());\n+    while (p != gc_id) {\n+        prev = p;\n+        p = p -> next;\n+    }\n+    if (prev == 0) {\n+        GC_threads[hv] = p -> next;\n+    } else {\n+        prev -> next = p -> next;\n+    }\n+}\n+\n+/* Return a GC_thread corresponding to a given thread_t.\t*/\n+/* Returns 0 if it's not there.\t\t\t\t\t*/\n+/* Caller holds  allocation lock or otherwise inhibits \t\t*/\n+/* updates.\t\t\t\t\t\t\t*/\n+/* If there is more than one thread with the given id we \t*/\n+/* return the most recent one.\t\t\t\t\t*/\n+GC_thread GC_lookup_thread(pthread_t id)\n+{\n+    int hv = ((word)id) % THREAD_TABLE_SZ;\n+    register GC_thread p = GC_threads[hv];\n+    \n+    /* I either hold the lock, or i'm being called from the stop-the-world\n+     * handler. */\n+#if defined(GC_AIX_THREADS)\n+    GC_ASSERT(I_HOLD_LOCK()); /* no stop-the-world handler needed on AIX */\n+#endif\n+    while (p != 0 && !pthread_equal(p -> id, id)) p = p -> next;\n+    return(p);\n+}\n+\n+#if defined(GC_AIX_THREADS)\n+void GC_stop_world()\n+{\n+    pthread_t my_thread = pthread_self();\n+    register int i;\n+    register GC_thread p;\n+    register int result;\n+    struct timespec timeout;\n+\n+    GC_ASSERT(I_HOLD_LOCK());\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+        if (p -> id != my_thread) {\n+          pthread_suspend_np(p->id);\n+        }\n+      }\n+    }\n+    /* GC_printf1(\"World stopped 0x%x\\n\", pthread_self()); */\n+}\n+\n+void GC_start_world()\n+{\n+    GC_thread p;\n+    unsigned i;\n+    pthread_t my_thread = pthread_self();\n+\n+    /* GC_printf0(\"World starting\\n\"); */\n+    GC_ASSERT(I_HOLD_LOCK());\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+        if (p -> id != my_thread) {\n+          pthread_continue_np(p->id);\n+        }\n+      }\n+    }\n+}\n+\n+#else /* GC_AIX_THREADS */\n+\n+/* Caller holds allocation lock.\t*/\n+void GC_stop_world()\n+{\n+    pthread_t my_thread = pthread_self();\n+    register int i;\n+    register GC_thread p;\n+    register int result;\n+    struct timespec timeout;\n+    \n+    GC_ASSERT(I_HOLD_LOCK());\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+        if (p -> id != my_thread) {\n+            if (p -> flags & FINISHED) {\n+\t\tp -> stop = STOPPED;\n+\t\tcontinue;\n+\t    }\n+\t    p -> stop = PLEASE_STOP;\n+            result = pthread_kill(p -> id, SIG_SUSPEND);\n+\t    /* GC_printf1(\"Sent signal to 0x%x\\n\", p -> id); */\n+\t    switch(result) {\n+                case ESRCH:\n+                    /* Not really there anymore.  Possible? */\n+                    p -> stop = STOPPED;\n+                    break;\n+                case 0:\n+                    break;\n+                default:\n+                    ABORT(\"pthread_kill failed\");\n+            }\n+        }\n+      }\n+    }\n+    pthread_mutex_lock(&GC_suspend_lock);\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+        while (p -> id != my_thread && p -> stop != STOPPED) {\n+\t    clock_gettime(CLOCK_REALTIME, &timeout);\n+            timeout.tv_nsec += 50000000; /* 50 msecs */\n+            if (timeout.tv_nsec >= 1000000000) {\n+                timeout.tv_nsec -= 1000000000;\n+                ++timeout.tv_sec;\n+            }\n+            result = pthread_cond_timedwait(&GC_suspend_ack_cv,\n+\t\t\t\t\t    &GC_suspend_lock,\n+                                            &timeout);\n+            if (result == ETIMEDOUT) {\n+                /* Signal was lost or misdirected.  Try again.      */\n+                /* Duplicate signals should be benign.              */\n+                result = pthread_kill(p -> id, SIG_SUSPEND);\n+\t    }\n+\t}\n+      }\n+    }\n+    pthread_mutex_unlock(&GC_suspend_lock);\n+    /* GC_printf1(\"World stopped 0x%x\\n\", pthread_self()); */\n+}\n+\n+/* Caller holds allocation lock.\t*/\n+void GC_start_world()\n+{\n+    GC_thread p;\n+    unsigned i;\n+\n+    /* GC_printf0(\"World starting\\n\"); */\n+    GC_ASSERT(I_HOLD_LOCK());\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+\tp -> stop = NOT_STOPPED;\n+      }\n+    }\n+    pthread_mutex_lock(&GC_suspend_lock);\n+    /* All other threads are at pthread_cond_wait in signal handler.\t*/\n+    /* Otherwise we couldn't have acquired the lock.\t\t\t*/\n+    pthread_mutex_unlock(&GC_suspend_lock);\n+    pthread_cond_broadcast(&GC_continue_cv);\n+}\n+\n+#endif /* GC_AIX_THREADS */\n+\n+\n+/* We hold allocation lock.  Should do exactly the right thing if the\t*/\n+/* world is stopped.  Should not fail if it isn't.\t\t\t*/\n+void GC_push_all_stacks()\n+{\n+    register int i;\n+    register GC_thread p;\n+    register ptr_t hot, cold;\n+    pthread_t me = pthread_self();\n+    \n+    /* GC_init() should have been called before GC_push_all_stacks is\n+     * invoked, and GC_init calls GC_thr_init(), which sets\n+     * GC_thr_initialized. */\n+    GC_ASSERT(GC_thr_initialized);\n+\n+    /* GC_printf1(\"Pushing stacks from thread 0x%x\\n\", me); */\n+    GC_ASSERT(I_HOLD_LOCK());\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+        if (p -> flags & FINISHED) continue;\n+\tcold = p->stack_cold;\n+\tif (!cold) cold=GC_stackbottom; /* 0 indicates 'original stack' */\n+        if (pthread_equal(p -> id, me)) {\n+\t    hot = GC_approx_sp();\n+\t} else {\n+#        ifdef GC_AIX_THREADS\n+          /* AIX doesn't use signals to suspend, so we need to get an */\n+\t  /* accurate hot stack pointer.\t\t\t      */\n+\t  /* See http://publib16.boulder.ibm.com/pseries/en_US/libs/basetrf1/pthread_getthrds_np.htm */\n+          pthread_t id = p -> id;\n+          struct __pthrdsinfo pinfo;\n+          int regbuf[64];\n+          int val = sizeof(regbuf);\n+          int retval = pthread_getthrds_np(&id, PTHRDSINFO_QUERY_ALL, &pinfo,\n+\t\t\t  \t\t   sizeof(pinfo), regbuf, &val);\n+          if (retval != 0) {\n+\t    printf(\"ERROR: pthread_getthrds_np() failed in GC\\n\");\n+\t    abort();\n+\t  }\n+\t  /* according to the AIX ABI, \n+\t     \"the lowest possible valid stack address is 288 bytes (144 + 144)\n+\t     less than the current value of the stack pointer.  Functions may\n+\t     use this stack space as volatile storage which is not preserved\n+\t     across function calls.\"\n+\t     ftp://ftp.penguinppc64.org/pub/people/amodra/PPC-elf64abi.txt.gz\n+\t  */\n+          hot = (ptr_t)(unsigned long)pinfo.__pi_ustk-288;\n+\t  cold = (ptr_t)pinfo.__pi_stackend; /* more precise */\n+          /* push the registers too, because they won't be on stack */\n+          GC_push_all_eager((ptr_t)&pinfo.__pi_context,\n+\t\t\t    (ptr_t)((&pinfo.__pi_context)+1));\n+          GC_push_all_eager((ptr_t)regbuf, ((ptr_t)regbuf)+val);\n+#\t else\n+              hot = p -> stack_hot;\n+#\t endif\n+\t}\n+#\tifdef STACK_GROWS_UP\n+          GC_push_all_stack(cold, hot);\n+#\telse\n+ /* printf(\"thread 0x%x: hot=0x%08x cold=0x%08x\\n\", p -> id, hot, cold); */\n+          GC_push_all_stack(hot, cold);\n+#\tendif\n+      }\n+    }\n+}\n+\n+\n+/* We hold the allocation lock.\t*/\n+void GC_thr_init()\n+{\n+    GC_thread t;\n+    struct sigaction act;\n+\n+    if (GC_thr_initialized) return;\n+#if 0\n+    /* unfortunately, GC_init_inner calls us without the lock, so\n+     * this assertion is not always true. */\n+    /* Why doesn't GC_init_inner hold the lock? - HB\t\t*/\n+    GC_ASSERT(I_HOLD_LOCK());\n+#endif\n+    GC_thr_initialized = TRUE;\n+#ifndef GC_AIX_THREADS\n+    (void) sigaction(SIG_SUSPEND, 0, &act);\n+    if (act.sa_handler != SIG_DFL)\n+    \tABORT(\"Previously installed SIG_SUSPEND handler\");\n+    /* Install handler.\t*/\n+\tact.sa_handler = GC_suspend_handler;\n+\tact.sa_flags = SA_RESTART;\n+\t(void) sigemptyset(&act.sa_mask);\n+        if (0 != sigaction(SIG_SUSPEND, &act, 0))\n+\t    ABORT(\"Failed to install SIG_SUSPEND handler\");\n+#endif\n+    /* Add the initial thread, so we can stop it.\t*/\n+      t = GC_new_thread(pthread_self());\n+      /* use '0' to indicate GC_stackbottom, since GC_init() has not\n+       * completed by the time we are called (from GC_init_inner()) */\n+      t -> stack_cold = 0; /* the original stack. */\n+      t -> stack_hot = (ptr_t)(&t);\n+      t -> flags = DETACHED;\n+}\n+\n+int GC_pthread_sigmask(int how, const sigset_t *set, sigset_t *oset)\n+{\n+    sigset_t fudged_set;\n+    \n+#ifdef GC_AIX_THREADS\n+    return(pthread_sigmask(how, set, oset));\n+#endif\n+\n+    if (set != NULL && (how == SIG_BLOCK || how == SIG_SETMASK)) {\n+        fudged_set = *set;\n+        sigdelset(&fudged_set, SIG_SUSPEND);\n+        set = &fudged_set;\n+    }\n+    return(pthread_sigmask(how, set, oset));\n+}\n+\n+struct start_info {\n+    void *(*start_routine)(void *);\n+    void *arg;\n+    word flags;\n+    pthread_mutex_t registeredlock;\n+    pthread_cond_t registered;     \n+    int volatile registereddone;\n+};\n+\n+void GC_thread_exit_proc(void *arg)\n+{\n+    GC_thread me;\n+\n+    LOCK();\n+    me = GC_lookup_thread(pthread_self());\n+    me -> flags |= FINISHED;\n+    /* reclaim DETACHED thread right away; otherwise wait until join() */\n+    if (me -> flags & DETACHED) {\n+\tGC_delete_gc_thread(pthread_self(), me);\n+    }\n+    UNLOCK();\n+}\n+\n+int GC_pthread_join(pthread_t thread, void **retval)\n+{\n+    int result;\n+    GC_thread thread_gc_id;\n+    \n+    LOCK();\n+    thread_gc_id = GC_lookup_thread(thread);\n+    /* This is guaranteed to be the intended one, since the thread id\t*/\n+    /* cant have been recycled by pthreads.\t\t\t\t*/\n+    UNLOCK();\n+    GC_ASSERT(!(thread_gc_id->flags & DETACHED));\n+    result = pthread_join(thread, retval);\n+    /* Some versions of the Irix pthreads library can erroneously \t*/\n+    /* return EINTR when the call succeeds.\t\t\t\t*/\n+\tif (EINTR == result) result = 0;\n+    GC_ASSERT(thread_gc_id->flags & FINISHED);\n+    LOCK();\n+    /* Here the pthread thread id may have been recycled. */\n+    GC_delete_gc_thread(thread, thread_gc_id);\n+    UNLOCK();\n+    return result;\n+}\n+\n+void * GC_start_routine(void * arg)\n+{\n+    int dummy;\n+    struct start_info * si = arg;\n+    void * result;\n+    GC_thread me;\n+    pthread_t my_pthread;\n+    void *(*start)(void *);\n+    void *start_arg;\n+\n+    my_pthread = pthread_self();\n+    /* If a GC occurs before the thread is registered, that GC will\t*/\n+    /* ignore this thread.  That's fine, since it will block trying to  */\n+    /* acquire the allocation lock, and won't yet hold interesting \t*/\n+    /* pointers.\t\t\t\t\t\t\t*/\n+    LOCK();\n+    /* We register the thread here instead of in the parent, so that\t*/\n+    /* we don't need to hold the allocation lock during pthread_create. */\n+    /* Holding the allocation lock there would make REDIRECT_MALLOC\t*/\n+    /* impossible.  It probably still doesn't work, but we're a little  */\n+    /* closer ...\t\t\t\t\t\t\t*/\n+    /* This unfortunately means that we have to be careful the parent\t*/\n+    /* doesn't try to do a pthread_join before we're registered.\t*/\n+    me = GC_new_thread(my_pthread);\n+    me -> flags = si -> flags;\n+    me -> stack_cold = (ptr_t) &dummy; /* this now the 'start of stack' */\n+    me -> stack_hot = me->stack_cold;/* this field should always be sensible */\n+    UNLOCK();\n+    start = si -> start_routine;\n+    start_arg = si -> arg;\n+\n+    pthread_mutex_lock(&(si->registeredlock));\n+    si->registereddone = 1;\n+    pthread_cond_signal(&(si->registered));\n+    pthread_mutex_unlock(&(si->registeredlock));\n+    /* si went away as soon as we did this unlock */\n+\n+    pthread_cleanup_push(GC_thread_exit_proc, 0);\n+    result = (*start)(start_arg);\n+    me -> status = result;\n+    pthread_cleanup_pop(1);\n+\t/* This involves acquiring the lock, ensuring that we can't exit */\n+\t/* while a collection that thinks we're alive is trying to stop  */\n+\t/* us.\t\t\t\t\t\t\t\t */\n+    return(result);\n+}\n+\n+int\n+GC_pthread_create(pthread_t *new_thread,\n+\t\t  const pthread_attr_t *attr,\n+                  void *(*start_routine)(void *), void *arg)\n+{\n+    int result;\n+    GC_thread t;\n+    int detachstate;\n+    word my_flags = 0;\n+    struct start_info * si;\n+    \t/* This is otherwise saved only in an area mmapped by the thread */\n+    \t/* library, which isn't visible to the collector.\t\t */\n+\n+    LOCK();\n+    /* GC_INTERNAL_MALLOC implicitly calls GC_init() if required */\n+    si = (struct start_info *)GC_INTERNAL_MALLOC(sizeof(struct start_info),\n+\t\t\t\t\t\t NORMAL);\n+    GC_ASSERT(GC_thr_initialized); /* initialized by GC_init() */\n+    UNLOCK();\n+    if (0 == si) return(ENOMEM);\n+    pthread_mutex_init(&(si->registeredlock), NULL);\n+    pthread_cond_init(&(si->registered),NULL);\n+    pthread_mutex_lock(&(si->registeredlock));\n+    si -> start_routine = start_routine;\n+    si -> arg = arg;\n+\n+    pthread_attr_getdetachstate(attr, &detachstate);\n+    if (PTHREAD_CREATE_DETACHED == detachstate) my_flags |= DETACHED;\n+    si -> flags = my_flags;\n+    result = pthread_create(new_thread, attr, GC_start_routine, si); \n+\n+    /* Wait until child has been added to the thread table.\t\t*/\n+    /* This also ensures that we hold onto si until the child is done\t*/\n+    /* with it.  Thus it doesn't matter whether it is otherwise\t\t*/\n+    /* visible to the collector.\t\t\t\t\t*/\n+\n+    if (0 == result) {\n+      si->registereddone = 0;\n+      while (!si->registereddone) \n+        pthread_cond_wait(&(si->registered), &(si->registeredlock));\n+    }\n+    pthread_mutex_unlock(&(si->registeredlock));\n+\n+    pthread_cond_destroy(&(si->registered));\n+    pthread_mutex_destroy(&(si->registeredlock));\n+    LOCK();\n+    GC_INTERNAL_FREE(si);\n+    UNLOCK();\n+\n+    return(result);\n+}\n+\n+/* For now we use the pthreads locking primitives on HP/UX */\n+\n+VOLATILE GC_bool GC_collecting = 0; /* A hint that we're in the collector and       */\n+                        /* holding the allocation lock for an           */\n+                        /* extended period.                             */\n+\n+/* Reasonably fast spin locks.  Basically the same implementation */\n+/* as STL alloc.h.\t\t\t\t\t\t  */\n+\n+#define SLEEP_THRESHOLD 3\n+\n+volatile unsigned int GC_allocate_lock = 0;\n+#define GC_TRY_LOCK() !GC_test_and_set(&GC_allocate_lock)\n+#define GC_LOCK_TAKEN GC_allocate_lock\n+\n+void GC_lock()\n+{\n+#   define low_spin_max 30  /* spin cycles if we suspect uniprocessor */\n+#   define high_spin_max 1000 /* spin cycles for multiprocessor */\n+    static unsigned spin_max = low_spin_max;\n+    unsigned my_spin_max;\n+    static unsigned last_spins = 0;\n+    unsigned my_last_spins;\n+    volatile unsigned junk;\n+#   define PAUSE junk *= junk; junk *= junk; junk *= junk; junk *= junk\n+    int i;\n+\n+    if (GC_TRY_LOCK()) {\n+        return;\n+    }\n+    junk = 0;\n+    my_spin_max = spin_max;\n+    my_last_spins = last_spins;\n+    for (i = 0; i < my_spin_max; i++) {\n+        if (GC_collecting) goto yield;\n+        if (i < my_last_spins/2 || GC_LOCK_TAKEN) {\n+            PAUSE; \n+            continue;\n+        }\n+        if (GC_TRY_LOCK()) {\n+\t    /*\n+             * got it!\n+             * Spinning worked.  Thus we're probably not being scheduled\n+             * against the other process with which we were contending.\n+             * Thus it makes sense to spin longer the next time.\n+\t     */\n+            last_spins = i;\n+            spin_max = high_spin_max;\n+            return;\n+        }\n+    }\n+    /* We are probably being scheduled against the other process.  Sleep. */\n+    spin_max = low_spin_max;\n+yield:\n+    for (i = 0;; ++i) {\n+        if (GC_TRY_LOCK()) {\n+            return;\n+        }\n+        if (i < SLEEP_THRESHOLD) {\n+            sched_yield();\n+\t} else {\n+\t    struct timespec ts;\n+\t\n+\t    if (i > 26) i = 26;\n+\t\t\t/* Don't wait for more than about 60msecs, even\t*/\n+\t\t\t/* under extreme contention.\t\t\t*/\n+\t    ts.tv_sec = 0;\n+\t    ts.tv_nsec = 1 << i;\n+\t    nanosleep(&ts, 0);\n+\t}\n+    }\n+}\n+\n+# else  /* !GC_IRIX_THREADS && !GC_AIX_THREADS */\n+\n+#ifndef LINT\n+  int GC_no_Irix_threads;\n+#endif\n+\n+# endif /* IRIX_THREADS */\n+"}, {"sha": "53547307a5d1d9aee0c6513a2dd9ada02ccc45ce", "filename": "boehm-gc/alpha_mach_dep.S", "status": "added", "additions": 87, "deletions": 0, "changes": 87, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Falpha_mach_dep.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Falpha_mach_dep.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Falpha_mach_dep.S?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,87 @@\n+ # $Id: alpha_mach_dep.s,v 1.2 1993/01/18 22:54:51 dosser Exp $\n+\t.arch ev6\n+\n+        .text\n+        .align  4\n+        .globl  GC_push_regs\n+        .ent    GC_push_regs 2\n+GC_push_regs:\n+\tldgp    $gp, 0($27)\n+\tlda     $sp, -16($sp)\n+\tstq     $26, 0($sp)\n+        .mask   0x04000000, 0\n+        .frame  $sp, 16, $26, 0\n+\n+ # $0\t\tinteger result\n+ # $1-$8\ttemp regs - not preserved cross calls\n+ # $9-$15\tcall saved regs\n+ # $16-$21\targument regs - not preserved cross calls\n+ # $22-$28\ttemp regs - not preserved cross calls\n+ # $29\t\tglobal pointer - not preserved cross calls\n+ # $30\t\tstack pointer\n+\n+# define call_push(x)\t\t\t\\\n+\tmov   x, $16;\t\t\t\\\n+\tjsr   $26, GC_push_one;\t\t\\\n+\tldgp  $gp, 0($26)\n+\t\n+        call_push($9)\n+        call_push($10)\n+        call_push($11)\n+        call_push($12)\n+        call_push($13)\n+        call_push($14)\n+        call_push($15)\n+\n+ # $f0-$f1\tfloating point results\n+ # $f2-$f9\tcall saved regs\n+ # $f10-$f30\ttemp regs - not preserved cross calls\n+\n+\t# Use the most efficient transfer method for this hardware.\n+\t# Bit 1 detects the FIX extension, which includes ftoit.\n+\tamask\t2, $0\n+\tbne\t$0, $use_stack\n+\n+#undef call_push\n+#define call_push(x)\t\t\t\\\n+\tftoit\tx, $16;\t\t\t\\\n+\tjsr\t$26, GC_push_one;\t\\\n+\tldgp\t$gp, 0($26)\n+\n+\tcall_push($f2)\n+\tcall_push($f3)\n+\tcall_push($f4)\n+\tcall_push($f5)\n+\tcall_push($f6)\n+\tcall_push($f7)\n+\tcall_push($f8)\n+\tcall_push($f9)\n+\n+\tldq     $26, 0($sp)\n+\tlda     $sp, 16($sp)\n+\tret     $31, ($26), 1\n+\n+\t.align\t4\n+$use_stack:\n+\n+#undef call_push\n+#define call_push(x)\t\t\t\\\n+\tstt\tx, 8($sp);\t\t\\\n+\tldq\t$16, 8($sp);\t\t\\\n+\tjsr\t$26, GC_push_one;\t\\\n+\tldgp\t$gp, 0($26)\n+\n+\tcall_push($f2)\n+\tcall_push($f3)\n+\tcall_push($f4)\n+\tcall_push($f5)\n+\tcall_push($f6)\n+\tcall_push($f7)\n+\tcall_push($f8)\n+\tcall_push($f9)\n+\n+\tldq     $26, 0($sp)\n+\tlda     $sp, 16($sp)\n+\tret     $31, ($26), 1\n+\n+\t.end    GC_push_regs"}, {"sha": "bc2247fa4e72fbd3aba6314848a245ffc37cd886", "filename": "boehm-gc/darwin_stop_world.c", "status": "added", "additions": 209, "deletions": 0, "changes": 209, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdarwin_stop_world.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdarwin_stop_world.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdarwin_stop_world.c?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,209 @@\n+#include \"private/pthread_support.h\"\n+\n+# if defined(GC_DARWIN_THREADS)\n+\n+#define DEBUG_THREADS 0\n+\n+/* From \"Inside Mac OS X - Mach-O Runtime Architecture\" published by Apple\n+   Page 49:\n+   \"The space beneath the stack pointer, where a new stack frame would normally\n+   be allocated, is called the red zone. This area as shown in Figure 3-2 may\n+   be used for any purpose as long as a new stack frame does not need to be\n+   added to the stack.\"\n+   \n+   Page 50: \"If a leaf procedure's red zone usage would exceed 224 bytes, then\n+   it must set up a stack frame just like routines that call other routines.\"\n+*/\n+#define PPC_RED_ZONE_SIZE 224\n+\n+void GC_push_all_stacks() {\n+    int i;\n+    kern_return_t r;\n+    GC_thread p;\n+    pthread_t me;\n+    ptr_t lo, hi;\n+#\tif defined(POWERPC)\n+        ppc_thread_state_t state;\n+#\telse\n+#\t\terror FIXME for non-ppc OS X\n+#\tendif\n+    mach_msg_type_number_t thread_state_count = MACHINE_THREAD_STATE_COUNT;\n+    \n+    me = pthread_self();\n+    if (!GC_thr_initialized) GC_thr_init();\n+    \n+    for(i=0;i<THREAD_TABLE_SZ;i++) {\n+        for(p=GC_threads[i];p!=0;p=p->next) {\n+            if(p -> flags & FINISHED) continue;\n+            if(pthread_equal(p->id,me)) {\n+                lo = GC_approx_sp();\n+            } else {\n+                /* Get the thread state (registers, etc) */\n+                r = thread_get_state(\n+                    p->stop_info.mach_thread,\n+                    MACHINE_THREAD_STATE,\n+                    (natural_t*)&state,\n+                    &thread_state_count);\n+                if(r != KERN_SUCCESS) ABORT(\"thread_get_state failed\");\n+    \n+                #ifdef POWERPC\n+                    lo = (void*)(state.r1 - PPC_RED_ZONE_SIZE);\n+                    \n+                    GC_push_one(state.r0); \n+                    GC_push_one(state.r2); \n+                    GC_push_one(state.r3); \n+                    GC_push_one(state.r4); \n+                    GC_push_one(state.r5); \n+                    GC_push_one(state.r6); \n+                    GC_push_one(state.r7); \n+                    GC_push_one(state.r8); \n+                    GC_push_one(state.r9); \n+                    GC_push_one(state.r10); \n+                    GC_push_one(state.r11); \n+                    GC_push_one(state.r12); \n+                    GC_push_one(state.r13); \n+                    GC_push_one(state.r14); \n+                    GC_push_one(state.r15); \n+                    GC_push_one(state.r16); \n+                    GC_push_one(state.r17); \n+                    GC_push_one(state.r18); \n+                    GC_push_one(state.r19); \n+                    GC_push_one(state.r20); \n+                    GC_push_one(state.r21); \n+                    GC_push_one(state.r22); \n+                    GC_push_one(state.r23); \n+                    GC_push_one(state.r24); \n+                    GC_push_one(state.r25); \n+                    GC_push_one(state.r26); \n+                    GC_push_one(state.r27); \n+                    GC_push_one(state.r28); \n+                    GC_push_one(state.r29); \n+                    GC_push_one(state.r30); \n+                    GC_push_one(state.r31);\n+                #else\n+                #\terror FIXME for non-PPC darwin\n+                #endif /* !POWERPC */\n+            } /* p != me */\n+            if(p->flags & MAIN_THREAD)\n+                hi = GC_stackbottom;\n+            else\n+                hi = p->stack_end;\n+            #if DEBUG_THREADS\n+                GC_printf3(\"Darwin: Stack for thread 0x%lx = [%lx,%lx)\\n\",\n+                    (unsigned long) p -> id,\n+                    (unsigned long) lo,\n+                    (unsigned long) hi\n+                );\n+            #endif\n+            GC_push_all_stack(lo,hi);\n+        } /* for(p=GC_threads[i]...) */\n+    } /* for(i=0;i<THREAD_TABLE_SZ...) */\n+}\n+\n+/* Caller holds allocation lock.\t*/\n+void GC_stop_world()\n+{\n+    int i;\n+    GC_thread p;\n+    pthread_t my_thread = pthread_self();\n+    kern_return_t kern_result;\n+    \n+    #if DEBUG_THREADS\n+    GC_printf1(\"Stopping the world from 0x%lx\\n\", pthread_self());\n+    #endif\n+       \n+    /* Make sure all free list construction has stopped before we start. */\n+    /* No new construction can start, since free list construction is\t*/\n+    /* required to acquire and release the GC lock before it starts,\t*/\n+    /* and we have the lock.\t\t\t\t\t\t*/\n+#   ifdef PARALLEL_MARK\n+      GC_acquire_mark_lock();\n+      GC_ASSERT(GC_fl_builder_count == 0);\n+      /* We should have previously waited for it to become zero. */\n+#   endif /* PARALLEL_MARK */\n+\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+        for (p = GC_threads[i]; p != 0; p = p -> next) {\n+            if (p -> id == my_thread) continue;\n+            if (p -> flags & FINISHED) continue;\n+            if (p -> thread_blocked) /* Will wait */ continue;\n+            \n+            #if DEBUG_THREADS\n+            GC_printf1(\"Suspending thread 0x%lx\\n\", p -> id);\n+            #endif\n+            \n+            /* Suspend the thread */\n+            kern_result = thread_suspend(p->stop_info.mach_thread);\n+            if(kern_result != KERN_SUCCESS) ABORT(\"thread_suspend failed\");\n+            \n+            /* This is only needed if we are modifying the threads \n+               state. thread_abort_safely should also be used\n+               if this code is ever added in again.\n+               \n+               kern_result = thread_abort(p->stop_info.mach_thread);\n+               if(kern_result != KERN_SUCCESS)\n+                   ABORT(\"thread_abort failed (%ul)\",kern_result);\n+            */\n+        }\n+    }\n+    \n+#   ifdef MPROTECT_VDB\n+    if(GC_incremental) {\n+        extern void GC_mprotect_stop();\n+        GC_mprotect_stop();\n+    }\n+#   endif\n+    \n+#   ifdef PARALLEL_MARK\n+      GC_release_mark_lock();\n+#   endif\n+    #if DEBUG_THREADS\n+      GC_printf1(\"World stopped from 0x%lx\\n\", pthread_self());\n+    #endif\n+}\n+\n+/* Caller holds allocation lock, and has held it continuously since\t*/\n+/* the world stopped.\t\t\t\t\t\t\t*/\n+void GC_start_world()\n+{\n+    pthread_t my_thread = pthread_self();\n+    int i;\n+    GC_thread p;\n+    kern_return_t kern_result;\n+\n+#   if DEBUG_THREADS\n+      GC_printf0(\"World starting\\n\");\n+#   endif\n+\n+#   ifdef MPROTECT_VDB\n+    if(GC_incremental) {\n+        extern void GC_mprotect_resume();\n+        GC_mprotect_resume();\n+    }\n+#   endif\n+\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+        for (p = GC_threads[i]; p != 0; p = p -> next) {\n+            if (p -> id == my_thread) continue;\n+            if (p -> flags & FINISHED) continue;\n+            if (p -> thread_blocked) continue;\n+    \n+            #if DEBUG_THREADS\n+            GC_printf1(\"Resuming 0x%lx\\n\", p -> id);\n+            #endif\n+            \n+            /* Resume the thread */\n+            kern_result = thread_resume(p->stop_info.mach_thread);\n+            if(kern_result != KERN_SUCCESS) ABORT(\"thread_resume failed\");\n+        }\n+    }\n+    #if DEBUG_THREADS\n+      GC_printf0(\"World started\\n\");\n+    #endif\n+}\n+\n+void GC_stop_init() {\n+\n+}\n+\n+#endif"}, {"sha": "3480ce4e96d431f9d70162fd1cd79366c714996b", "filename": "boehm-gc/depcomp", "status": "added", "additions": 436, "deletions": 0, "changes": 436, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdepcomp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdepcomp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdepcomp?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,436 @@\n+#! /bin/sh\n+\n+# depcomp - compile a program generating dependencies as side-effects\n+# Copyright 1999, 2000 Free Software Foundation, Inc.\n+\n+# This program is free software; you can redistribute it and/or modify\n+# it under the terms of the GNU General Public License as published by\n+# the Free Software Foundation; either version 2, or (at your option)\n+# any later version.\n+\n+# This program is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+# GNU General Public License for more details.\n+\n+# You should have received a copy of the GNU General Public License\n+# along with this program; if not, write to the Free Software\n+# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n+# 02111-1307, USA.\n+\n+# As a special exception to the GNU General Public License, if you\n+# distribute this file as part of a program that contains a\n+# configuration script generated by Autoconf, you may include it under\n+# the same distribution terms that you use for the rest of that program.\n+\n+# Originally written by Alexandre Oliva <oliva@dcc.unicamp.br>.\n+\n+if test -z \"$depmode\" || test -z \"$source\" || test -z \"$object\"; then\n+  echo \"depcomp: Variables source, object and depmode must be set\" 1>&2\n+  exit 1\n+fi\n+# `libtool' can also be set to `yes' or `no'.\n+\n+if test -z \"$depfile\"; then\n+   base=`echo \"$object\" | sed -e 's,^.*/,,' -e 's,\\.\\([^.]*\\)$,.P\\1,'`\n+   dir=`echo \"$object\" | sed 's,/.*$,/,'`\n+   if test \"$dir\" = \"$object\"; then\n+      dir=\n+   fi\n+   # FIXME: should be _deps on DOS.\n+   depfile=\"$dir.deps/$base\"\n+fi\n+\n+tmpdepfile=${tmpdepfile-`echo \"$depfile\" | sed 's/\\.\\([^.]*\\)$/.T\\1/'`}\n+\n+rm -f \"$tmpdepfile\"\n+\n+# Some modes work just like other modes, but use different flags.  We\n+# parameterize here, but still list the modes in the big case below,\n+# to make depend.m4 easier to write.  Note that we *cannot* use a case\n+# here, because this file can only contain one case statement.\n+if test \"$depmode\" = hp; then\n+  # HP compiler uses -M and no extra arg.\n+  gccflag=-M\n+  depmode=gcc\n+fi\n+\n+if test \"$depmode\" = dashXmstdout; then\n+   # This is just like dashmstdout with a different argument.\n+   dashmflag=-xM\n+   depmode=dashmstdout\n+fi\n+\n+case \"$depmode\" in\n+gcc3)\n+## gcc 3 implements dependency tracking that does exactly what\n+## we want.  Yay!  Note: for some reason libtool 1.4 doesn't like\n+## it if -MD -MP comes after the -MF stuff.  Hmm.\n+  \"$@\" -MT \"$object\" -MD -MP -MF \"$tmpdepfile\"\n+  stat=$?\n+  if test $stat -eq 0; then :\n+  else\n+    rm -f \"$tmpdepfile\"\n+    exit $stat\n+  fi\n+  mv \"$tmpdepfile\" \"$depfile\"\n+  ;;\n+\n+gcc)\n+## There are various ways to get dependency output from gcc.  Here's\n+## why we pick this rather obscure method:\n+## - Don't want to use -MD because we'd like the dependencies to end\n+##   up in a subdir.  Having to rename by hand is ugly.\n+##   (We might end up doing this anyway to support other compilers.)\n+## - The DEPENDENCIES_OUTPUT environment variable makes gcc act like\n+##   -MM, not -M (despite what the docs say).\n+## - Using -M directly means running the compiler twice (even worse\n+##   than renaming).\n+  if test -z \"$gccflag\"; then\n+    gccflag=-MD,\n+  fi\n+  \"$@\" -Wp,\"$gccflag$tmpdepfile\"\n+  stat=$?\n+  if test $stat -eq 0; then :\n+  else\n+    rm -f \"$tmpdepfile\"\n+    exit $stat\n+  fi\n+  rm -f \"$depfile\"\n+  echo \"$object : \\\\\" > \"$depfile\"\n+  alpha=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n+## The second -e expression handles DOS-style file names with drive letters.\n+  sed -e 's/^[^:]*: / /' \\\n+      -e 's/^['$alpha']:\\/[^:]*: / /' < \"$tmpdepfile\" >> \"$depfile\"\n+## This next piece of magic avoids the `deleted header file' problem.\n+## The problem is that when a header file which appears in a .P file\n+## is deleted, the dependency causes make to die (because there is\n+## typically no way to rebuild the header).  We avoid this by adding\n+## dummy dependencies for each header file.  Too bad gcc doesn't do\n+## this for us directly.\n+  tr ' ' '\n+' < \"$tmpdepfile\" |\n+## Some versions of gcc put a space before the `:'.  On the theory\n+## that the space means something, we add a space to the output as\n+## well.\n+## Some versions of the HPUX 10.20 sed can't process this invocation\n+## correctly.  Breaking it into two sed invocations is a workaround.\n+    sed -e 's/^\\\\$//' -e '/^$/d' -e '/:$/d' | sed -e 's/$/ :/' >> \"$depfile\"\n+  rm -f \"$tmpdepfile\"\n+  ;;\n+\n+hp)\n+  # This case exists only to let depend.m4 do its work.  It works by\n+  # looking at the text of this script.  This case will never be run,\n+  # since it is checked for above.\n+  exit 1\n+  ;;\n+\n+sgi)\n+  if test \"$libtool\" = yes; then\n+    \"$@\" \"-Wp,-MDupdate,$tmpdepfile\"\n+  else\n+    \"$@\" -MDupdate \"$tmpdepfile\"\n+  fi\n+  stat=$?\n+  if test $stat -eq 0; then :\n+  else\n+    rm -f \"$tmpdepfile\"\n+    exit $stat\n+  fi\n+  rm -f \"$depfile\"\n+\n+  if test -f \"$tmpdepfile\"; then  # yes, the sourcefile depend on other files\n+    echo \"$object : \\\\\" > \"$depfile\"\n+\n+    # Clip off the initial element (the dependent).  Don't try to be\n+    # clever and replace this with sed code, as IRIX sed won't handle\n+    # lines with more than a fixed number of characters (4096 in\n+    # IRIX 6.2 sed, 8192 in IRIX 6.5).  We also remove comment lines;\n+    # the IRIX cc adds comments like `#:fec' to the end of the\n+    # dependency line.\n+    tr ' ' '\n+' < \"$tmpdepfile\" \\\n+    | sed -e 's/^.*\\.o://' -e 's/#.*$//' -e '/^$/ d' | \\\n+    tr '\n+' ' ' >> $depfile\n+    echo >> $depfile\n+\n+    # The second pass generates a dummy entry for each header file.\n+    tr ' ' '\n+' < \"$tmpdepfile\" \\\n+   | sed -e 's/^.*\\.o://' -e 's/#.*$//' -e '/^$/ d' -e 's/$/:/' \\\n+   >> $depfile\n+  else\n+    # The sourcefile does not contain any dependencies, so just\n+    # store a dummy comment line, to avoid errors with the Makefile\n+    # \"include basename.Plo\" scheme.\n+    echo \"#dummy\" > \"$depfile\"\n+  fi\n+  rm -f \"$tmpdepfile\"\n+  ;;\n+\n+aix)\n+  # The C for AIX Compiler uses -M and outputs the dependencies\n+  # in a .u file.  This file always lives in the current directory.\n+  # Also, the AIX compiler puts `$object:' at the start of each line;\n+  # $object doesn't have directory information.\n+  stripped=`echo \"$object\" | sed -e 's,^.*/,,' -e 's/\\(.*\\)\\..*$/\\1/'`\n+  tmpdepfile=\"$stripped.u\"\n+  outname=\"$stripped.o\"\n+  if test \"$libtool\" = yes; then\n+    \"$@\" -Wc,-M\n+  else\n+    \"$@\" -M\n+  fi\n+\n+  stat=$?\n+  if test $stat -eq 0; then :\n+  else\n+    rm -f \"$tmpdepfile\"\n+    exit $stat\n+  fi\n+\n+  if test -f \"$tmpdepfile\"; then\n+    # Each line is of the form `foo.o: dependent.h'.\n+    # Do two passes, one to just change these to\n+    # `$object: dependent.h' and one to simply `dependent.h:'.\n+    sed -e \"s,^$outname:,$object :,\" < \"$tmpdepfile\" > \"$depfile\"\n+    sed -e \"s,^$outname: \\(.*\\)$,\\1:,\" < \"$tmpdepfile\" >> \"$depfile\"\n+  else\n+    # The sourcefile does not contain any dependencies, so just\n+    # store a dummy comment line, to avoid errors with the Makefile\n+    # \"include basename.Plo\" scheme.\n+    echo \"#dummy\" > \"$depfile\"\n+  fi\n+  rm -f \"$tmpdepfile\"\n+  ;;\n+\n+tru64)\n+   # The Tru64 compiler uses -MD to generate dependencies as a side\n+   # effect.  `cc -MD -o foo.o ...' puts the dependencies into `foo.o.d'.\n+   # At least on Alpha/Redhat 6.1, Compaq CCC V6.2-504 seems to put \n+   # dependencies in `foo.d' instead, so we check for that too.\n+   # Subdirectories are respected.\n+\n+   base=`echo \"$object\" | sed -e 's/\\.o$//' -e 's/\\.lo$//'`\n+   tmpdepfile1=\"$base.o.d\"\n+   tmpdepfile2=\"$base.d\"\n+   if test \"$libtool\" = yes; then\n+      \"$@\" -Wc,-MD\n+   else\n+      \"$@\" -MD\n+   fi\n+\n+   stat=$?\n+   if test $stat -eq 0; then :\n+   else\n+      rm -f \"$tmpdepfile1\" \"$tmpdepfile2\"\n+      exit $stat\n+   fi\n+\n+   if test -f \"$tmpdepfile1\"; then\n+      tmpdepfile=\"$tmpdepfile1\"\n+   else\n+      tmpdepfile=\"$tmpdepfile2\"\n+   fi\n+   if test -f \"$tmpdepfile\"; then\n+      sed -e \"s,^.*\\.[a-z]*:,$object:,\" < \"$tmpdepfile\" > \"$depfile\"\n+      # That's a space and a tab in the [].\n+      sed -e 's,^.*\\.[a-z]*:[ \t]*,,' -e 's,$,:,' < \"$tmpdepfile\" >> \"$depfile\"\n+   else\n+      echo \"#dummy\" > \"$depfile\"\n+   fi\n+   rm -f \"$tmpdepfile\"\n+   ;;\n+\n+#nosideeffect)\n+  # This comment above is used by automake to tell side-effect\n+  # dependency tracking mechanisms from slower ones.\n+\n+dashmstdout)\n+  # Important note: in order to support this mode, a compiler *must*\n+  # always write the proprocessed file to stdout, regardless of -o,\n+  # because we must use -o when running libtool.\n+  test -z \"$dashmflag\" && dashmflag=-M\n+  ( IFS=\" \"\n+    case \" $* \" in\n+    *\" --mode=compile \"*) # this is libtool, let us make it quiet\n+      for arg\n+      do # cycle over the arguments\n+        case \"$arg\" in\n+\t\"--mode=compile\")\n+\t  # insert --quiet before \"--mode=compile\"\n+\t  set fnord \"$@\" --quiet\n+\t  shift # fnord\n+\t  ;;\n+\tesac\n+\tset fnord \"$@\" \"$arg\"\n+\tshift # fnord\n+\tshift # \"$arg\"\n+      done\n+      ;;\n+    esac\n+    \"$@\" $dashmflag | sed 's:^[^:]*\\:[ \t]*:'\"$object\"'\\: :' > \"$tmpdepfile\"\n+  ) &\n+  proc=$!\n+  \"$@\"\n+  stat=$?\n+  wait \"$proc\"\n+  if test \"$stat\" != 0; then exit $stat; fi\n+  rm -f \"$depfile\"\n+  cat < \"$tmpdepfile\" > \"$depfile\"\n+  tr ' ' '\n+' < \"$tmpdepfile\" | \\\n+## Some versions of the HPUX 10.20 sed can't process this invocation\n+## correctly.  Breaking it into two sed invocations is a workaround.\n+    sed -e 's/^\\\\$//' -e '/^$/d' -e '/:$/d' | sed -e 's/$/ :/' >> \"$depfile\"\n+  rm -f \"$tmpdepfile\"\n+  ;;\n+\n+dashXmstdout)\n+  # This case only exists to satisfy depend.m4.  It is never actually\n+  # run, as this mode is specially recognized in the preamble.\n+  exit 1\n+  ;;\n+\n+makedepend)\n+  # X makedepend\n+  (\n+    shift\n+    cleared=no\n+    for arg in \"$@\"; do\n+      case $cleared in no)\n+        set \"\"; shift\n+\tcleared=yes\n+      esac\n+      case \"$arg\" in\n+        -D*|-I*)\n+\t  set fnord \"$@\" \"$arg\"; shift;;\n+\t-*)\n+\t  ;;\n+\t*)\n+\t  set fnord \"$@\" \"$arg\"; shift;;\n+      esac\n+    done\n+    obj_suffix=\"`echo $object | sed 's/^.*\\././'`\"\n+    touch \"$tmpdepfile\"\n+    ${MAKEDEPEND-makedepend} 2>/dev/null -o\"$obj_suffix\" -f\"$tmpdepfile\" \"$@\"\n+  ) &\n+  proc=$!\n+  \"$@\"\n+  stat=$?\n+  wait \"$proc\"\n+  if test \"$stat\" != 0; then exit $stat; fi\n+  rm -f \"$depfile\"\n+  cat < \"$tmpdepfile\" > \"$depfile\"\n+  sed '1,2d' \"$tmpdepfile\" | tr ' ' '\n+' | \\\n+## Some versions of the HPUX 10.20 sed can't process this invocation\n+## correctly.  Breaking it into two sed invocations is a workaround.\n+    sed -e 's/^\\\\$//' -e '/^$/d' -e '/:$/d' | sed -e 's/$/ :/' >> \"$depfile\"\n+  rm -f \"$tmpdepfile\" \"$tmpdepfile\".bak\n+  ;;\n+\n+cpp)\n+  # Important note: in order to support this mode, a compiler *must*\n+  # always write the proprocessed file to stdout, regardless of -o,\n+  # because we must use -o when running libtool.\n+  ( IFS=\" \"\n+    case \" $* \" in\n+    *\" --mode=compile \"*)\n+      for arg\n+      do # cycle over the arguments\n+        case $arg in\n+\t\"--mode=compile\")\n+\t  # insert --quiet before \"--mode=compile\"\n+\t  set fnord \"$@\" --quiet\n+\t  shift # fnord\n+\t  ;;\n+\tesac\n+\tset fnord \"$@\" \"$arg\"\n+\tshift # fnord\n+\tshift # \"$arg\"\n+      done\n+      ;;\n+    esac\n+    \"$@\" -E |\n+    sed -n '/^# [0-9][0-9]* \"\\([^\"]*\\)\".*/ s:: \\1 \\\\:p' |\n+    sed '$ s: \\\\$::' > \"$tmpdepfile\"\n+  ) &\n+  proc=$!\n+  \"$@\"\n+  stat=$?\n+  wait \"$proc\"\n+  if test \"$stat\" != 0; then exit $stat; fi\n+  rm -f \"$depfile\"\n+  echo \"$object : \\\\\" > \"$depfile\"\n+  cat < \"$tmpdepfile\" >> \"$depfile\"\n+  sed < \"$tmpdepfile\" '/^$/d;s/^ //;s/ \\\\$//;s/$/ :/' >> \"$depfile\"\n+  rm -f \"$tmpdepfile\"\n+  ;;\n+\n+msvisualcpp)\n+  # Important note: in order to support this mode, a compiler *must*\n+  # always write the proprocessed file to stdout, regardless of -o,\n+  # because we must use -o when running libtool.\n+  ( IFS=\" \"\n+    case \" $* \" in\n+    *\" --mode=compile \"*)\n+      for arg\n+      do # cycle over the arguments\n+        case $arg in\n+\t\"--mode=compile\")\n+\t  # insert --quiet before \"--mode=compile\"\n+\t  set fnord \"$@\" --quiet\n+\t  shift # fnord\n+\t  ;;\n+\tesac\n+\tset fnord \"$@\" \"$arg\"\n+\tshift # fnord\n+\tshift # \"$arg\"\n+      done\n+      ;;\n+    esac\n+    for arg\n+    do\n+      case \"$arg\" in\n+      \"-Gm\"|\"/Gm\"|\"-Gi\"|\"/Gi\"|\"-ZI\"|\"/ZI\")\n+\tset fnord \"$@\"\n+\tshift\n+\tshift\n+\t;;\n+      *)\n+\tset fnord \"$@\" \"$arg\"\n+\tshift\n+\tshift\n+\t;;\n+      esac\n+    done\n+    \"$@\" -E |\n+    sed -n '/^#line [0-9][0-9]* \"\\([^\"]*\\)\"/ s::echo \"`cygpath -u \\\\\"\\1\\\\\"`\":p' | sort | uniq > \"$tmpdepfile\"\n+  ) &\n+  proc=$!\n+  \"$@\"\n+  stat=$?\n+  wait \"$proc\"\n+  if test \"$stat\" != 0; then exit $stat; fi\n+  rm -f \"$depfile\"\n+  echo \"$object : \\\\\" > \"$depfile\"\n+  . \"$tmpdepfile\" | sed 's% %\\\\ %g' | sed -n '/^\\(.*\\)$/ s::\t\\1 \\\\:p' >> \"$depfile\"\n+  echo \"\t\" >> \"$depfile\"\n+  . \"$tmpdepfile\" | sed 's% %\\\\ %g' | sed -n '/^\\(.*\\)$/ s::\\1\\::p' >> \"$depfile\"\n+  rm -f \"$tmpdepfile\"\n+  ;;\n+\n+none)\n+  exec \"$@\"\n+  ;;\n+\n+*)\n+  echo \"Unknown depmode $depmode\" 1>&2\n+  exit 1\n+  ;;\n+esac\n+\n+exit 0"}, {"sha": "91446305581d47665e67c3ae90f4e0cac0c517ea", "filename": "boehm-gc/doc/Makefile.am", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FMakefile.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FMakefile.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdoc%2FMakefile.am?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,27 @@\n+# \n+# \n+# THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n+# OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n+# \n+# Permission is hereby granted to use or copy this program\n+# for any purpose,  provided the above notices are retained on all copies.\n+# Permission to modify the code and to distribute modified code is granted,\n+# provided the above notices are retained, and a notice that the code was\n+# modified is included with the above copyright notice.\n+#\n+# Modified by: Grzegorz Jakacki <jakacki at acm dot org>\n+\n+## Process this file with automake to produce Makefile.in.\n+\n+# installed documentation\n+#\n+dist_pkgdata_DATA = barrett_diagram debugging.html gc.man \\\n+    gcdescr.html README README.amiga README.arm.cross \\\n+    README.autoconf README.changes README.contributors \\\n+    README.cords README.DGUX386 README.dj README.environment \\\n+    README.ews4800 README.hp README.linux README.Mac \\\n+    README.MacOSX README.macros README.OS2 README.rs6000 \\\n+    README.sgi README.solaris2 README.uts README.win32 \\\n+    tree.html leak.html gcinterface.html scale.html \\\n+    README.darwin\n+"}, {"sha": "9bf1ff5feadb63c512cd7b5042f6854487b5ccda", "filename": "boehm-gc/doc/Makefile.in", "status": "added", "additions": 282, "deletions": 0, "changes": 282, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdoc%2FMakefile.in?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,282 @@\n+# Makefile.in generated by automake 1.6.3 from Makefile.am.\n+# @configure_input@\n+\n+# Copyright 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002\n+# Free Software Foundation, Inc.\n+# This Makefile.in is free software; the Free Software Foundation\n+# gives unlimited permission to copy and/or distribute it,\n+# with or without modifications, as long as this notice is preserved.\n+\n+# This program is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY, to the extent permitted by law; without\n+# even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n+# PARTICULAR PURPOSE.\n+\n+@SET_MAKE@\n+\n+# \n+# \n+# THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n+# OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n+# \n+# Permission is hereby granted to use or copy this program\n+# for any purpose,  provided the above notices are retained on all copies.\n+# Permission to modify the code and to distribute modified code is granted,\n+# provided the above notices are retained, and a notice that the code was\n+# modified is included with the above copyright notice.\n+#\n+# Modified by: Grzegorz Jakacki <jakacki at acm dot org>\n+SHELL = @SHELL@\n+\n+srcdir = @srcdir@\n+top_srcdir = @top_srcdir@\n+VPATH = @srcdir@\n+prefix = @prefix@\n+exec_prefix = @exec_prefix@\n+\n+bindir = @bindir@\n+sbindir = @sbindir@\n+libexecdir = @libexecdir@\n+datadir = @datadir@\n+sysconfdir = @sysconfdir@\n+sharedstatedir = @sharedstatedir@\n+localstatedir = @localstatedir@\n+libdir = @libdir@\n+infodir = @infodir@\n+mandir = @mandir@\n+includedir = @includedir@\n+oldincludedir = /usr/include\n+pkgdatadir = $(datadir)/@PACKAGE@\n+pkglibdir = $(libdir)/@PACKAGE@\n+pkgincludedir = $(includedir)/@PACKAGE@\n+top_builddir = ..\n+\n+ACLOCAL = @ACLOCAL@\n+AUTOCONF = @AUTOCONF@\n+AUTOMAKE = @AUTOMAKE@\n+AUTOHEADER = @AUTOHEADER@\n+\n+am__cd = CDPATH=\"$${ZSH_VERSION+.}$(PATH_SEPARATOR)\" && cd\n+INSTALL = @INSTALL@\n+INSTALL_PROGRAM = @INSTALL_PROGRAM@\n+INSTALL_DATA = @INSTALL_DATA@\n+install_sh_DATA = $(install_sh) -c -m 644\n+install_sh_PROGRAM = $(install_sh) -c\n+install_sh_SCRIPT = $(install_sh) -c\n+INSTALL_SCRIPT = @INSTALL_SCRIPT@\n+INSTALL_HEADER = $(INSTALL_DATA)\n+transform = @program_transform_name@\n+NORMAL_INSTALL = :\n+PRE_INSTALL = :\n+POST_INSTALL = :\n+NORMAL_UNINSTALL = :\n+PRE_UNINSTALL = :\n+POST_UNINSTALL = :\n+host_alias = @host_alias@\n+host_triplet = @host@\n+\n+EXEEXT = @EXEEXT@\n+OBJEXT = @OBJEXT@\n+PATH_SEPARATOR = @PATH_SEPARATOR@\n+AMTAR = @AMTAR@\n+AR = @AR@\n+AS = @AS@\n+AWK = @AWK@\n+CC = @CC@\n+CCAS = @CCAS@\n+CCASFLAGS = @CCASFLAGS@\n+CFLAGS = @CFLAGS@\n+CXX = @CXX@\n+CXXFLAGS = @CXXFLAGS@\n+CXXINCLUDES = @CXXINCLUDES@\n+DEPDIR = @DEPDIR@\n+DLLTOOL = @DLLTOOL@\n+ECHO = @ECHO@\n+EXTRA_TEST_LIBS = @EXTRA_TEST_LIBS@\n+GC_CFLAGS = @GC_CFLAGS@\n+GC_VERSION = @GC_VERSION@\n+INCLUDES = @INCLUDES@\n+INSTALL_STRIP_PROGRAM = @INSTALL_STRIP_PROGRAM@\n+LIBTOOL = @LIBTOOL@\n+LN_S = @LN_S@\n+MAINT = @MAINT@\n+MY_CFLAGS = @MY_CFLAGS@\n+OBJDUMP = @OBJDUMP@\n+PACKAGE = @PACKAGE@\n+RANLIB = @RANLIB@\n+STRIP = @STRIP@\n+THREADLIBS = @THREADLIBS@\n+VERSION = @VERSION@\n+addincludes = @addincludes@\n+addlibs = @addlibs@\n+addobjs = @addobjs@\n+addtests = @addtests@\n+am__include = @am__include@\n+am__quote = @am__quote@\n+install_sh = @install_sh@\n+target_all = @target_all@\n+\n+# installed documentation\n+#\n+dist_pkgdata_DATA = barrett_diagram debugging.html gc.man \\\n+    gcdescr.html README README.amiga README.arm.cross \\\n+    README.autoconf README.changes README.contributors \\\n+    README.cords README.DGUX386 README.dj README.environment \\\n+    README.ews4800 README.hp README.linux README.Mac \\\n+    README.MacOSX README.macros README.OS2 README.rs6000 \\\n+    README.sgi README.solaris2 README.uts README.win32 \\\n+    tree.html leak.html gcinterface.html scale.html \\\n+    README.darwin\n+\n+subdir = doc\n+mkinstalldirs = $(SHELL) $(top_srcdir)/mkinstalldirs\n+CONFIG_CLEAN_FILES =\n+DIST_SOURCES =\n+DATA = $(dist_pkgdata_DATA)\n+\n+DIST_COMMON = README $(dist_pkgdata_DATA) Makefile.am Makefile.in\n+all: all-am\n+\n+.SUFFIXES:\n+$(srcdir)/Makefile.in: @MAINTAINER_MODE_TRUE@ Makefile.am  $(top_srcdir)/configure.in $(ACLOCAL_M4)\n+\tcd $(top_srcdir) && \\\n+\t  $(AUTOMAKE) --gnu  doc/Makefile\n+Makefile: @MAINTAINER_MODE_TRUE@ $(srcdir)/Makefile.in  $(top_builddir)/config.status\n+\tcd $(top_builddir) && $(SHELL) ./config.status $(subdir)/$@ $(am__depfiles_maybe)\n+\n+mostlyclean-libtool:\n+\t-rm -f *.lo\n+\n+clean-libtool:\n+\t-rm -rf .libs _libs\n+\n+distclean-libtool:\n+\t-rm -f libtool\n+uninstall-info-am:\n+dist_pkgdataDATA_INSTALL = $(INSTALL_DATA)\n+install-dist_pkgdataDATA: $(dist_pkgdata_DATA)\n+\t@$(NORMAL_INSTALL)\n+\t$(mkinstalldirs) $(DESTDIR)$(pkgdatadir)\n+\t@list='$(dist_pkgdata_DATA)'; for p in $$list; do \\\n+\t  if test -f \"$$p\"; then d=; else d=\"$(srcdir)/\"; fi; \\\n+\t  f=\"`echo $$p | sed -e 's|^.*/||'`\"; \\\n+\t  echo \" $(dist_pkgdataDATA_INSTALL) $$d$$p $(DESTDIR)$(pkgdatadir)/$$f\"; \\\n+\t  $(dist_pkgdataDATA_INSTALL) $$d$$p $(DESTDIR)$(pkgdatadir)/$$f; \\\n+\tdone\n+\n+uninstall-dist_pkgdataDATA:\n+\t@$(NORMAL_UNINSTALL)\n+\t@list='$(dist_pkgdata_DATA)'; for p in $$list; do \\\n+\t  f=\"`echo $$p | sed -e 's|^.*/||'`\"; \\\n+\t  echo \" rm -f $(DESTDIR)$(pkgdatadir)/$$f\"; \\\n+\t  rm -f $(DESTDIR)$(pkgdatadir)/$$f; \\\n+\tdone\n+tags: TAGS\n+TAGS:\n+\n+DISTFILES = $(DIST_COMMON) $(DIST_SOURCES) $(TEXINFOS) $(EXTRA_DIST)\n+\n+top_distdir = ..\n+distdir = $(top_distdir)/$(PACKAGE)-$(VERSION)\n+\n+distdir: $(DISTFILES)\n+\t@list='$(DISTFILES)'; for file in $$list; do \\\n+\t  if test -f $$file || test -d $$file; then d=.; else d=$(srcdir); fi; \\\n+\t  dir=`echo \"$$file\" | sed -e 's,/[^/]*$$,,'`; \\\n+\t  if test \"$$dir\" != \"$$file\" && test \"$$dir\" != \".\"; then \\\n+\t    dir=\"/$$dir\"; \\\n+\t    $(mkinstalldirs) \"$(distdir)$$dir\"; \\\n+\t  else \\\n+\t    dir=''; \\\n+\t  fi; \\\n+\t  if test -d $$d/$$file; then \\\n+\t    if test -d $(srcdir)/$$file && test $$d != $(srcdir); then \\\n+\t      cp -pR $(srcdir)/$$file $(distdir)$$dir || exit 1; \\\n+\t    fi; \\\n+\t    cp -pR $$d/$$file $(distdir)$$dir || exit 1; \\\n+\t  else \\\n+\t    test -f $(distdir)/$$file \\\n+\t    || cp -p $$d/$$file $(distdir)/$$file \\\n+\t    || exit 1; \\\n+\t  fi; \\\n+\tdone\n+check-am: all-am\n+check: check-am\n+all-am: Makefile $(DATA)\n+\n+installdirs:\n+\t$(mkinstalldirs) $(DESTDIR)$(pkgdatadir)\n+\n+install: install-am\n+install-exec: install-exec-am\n+install-data: install-data-am\n+uninstall: uninstall-am\n+\n+install-am: all-am\n+\t@$(MAKE) $(AM_MAKEFLAGS) install-exec-am install-data-am\n+\n+installcheck: installcheck-am\n+install-strip:\n+\t$(MAKE) $(AM_MAKEFLAGS) INSTALL_PROGRAM=\"$(INSTALL_STRIP_PROGRAM)\" \\\n+\t  INSTALL_STRIP_FLAG=-s \\\n+\t  `test -z '$(STRIP)' || \\\n+\t    echo \"INSTALL_PROGRAM_ENV=STRIPPROG='$(STRIP)'\"` install\n+mostlyclean-generic:\n+\n+clean-generic:\n+\n+distclean-generic:\n+\t-rm -f Makefile $(CONFIG_CLEAN_FILES)\n+\n+maintainer-clean-generic:\n+\t@echo \"This command is intended for maintainers to use\"\n+\t@echo \"it deletes files that may require special tools to rebuild.\"\n+clean: clean-am\n+\n+clean-am: clean-generic clean-libtool mostlyclean-am\n+\n+distclean: distclean-am\n+\n+distclean-am: clean-am distclean-generic distclean-libtool\n+\n+dvi: dvi-am\n+\n+dvi-am:\n+\n+info: info-am\n+\n+info-am:\n+\n+install-data-am: install-dist_pkgdataDATA\n+\n+install-exec-am:\n+\n+install-info: install-info-am\n+\n+install-man:\n+\n+installcheck-am:\n+\n+maintainer-clean: maintainer-clean-am\n+\n+maintainer-clean-am: distclean-am maintainer-clean-generic\n+\n+mostlyclean: mostlyclean-am\n+\n+mostlyclean-am: mostlyclean-generic mostlyclean-libtool\n+\n+uninstall-am: uninstall-dist_pkgdataDATA uninstall-info-am\n+\n+.PHONY: all all-am check check-am clean clean-generic clean-libtool \\\n+\tdistclean distclean-generic distclean-libtool distdir dvi \\\n+\tdvi-am info info-am install install-am install-data \\\n+\tinstall-data-am install-dist_pkgdataDATA install-exec \\\n+\tinstall-exec-am install-info install-info-am install-man \\\n+\tinstall-strip installcheck installcheck-am installdirs \\\n+\tmaintainer-clean maintainer-clean-generic mostlyclean \\\n+\tmostlyclean-generic mostlyclean-libtool uninstall uninstall-am \\\n+\tuninstall-dist_pkgdataDATA uninstall-info-am\n+\n+# Tell versions [3.59,3.63) of GNU make to not export all variables.\n+# Otherwise a system limit (for SysV at least) may be exceeded.\n+.NOEXPORT:"}, {"sha": "9d6d84788ef4219e8779cc4711377914962be09b", "filename": "boehm-gc/doc/README.DGUX386", "status": "added", "additions": 215, "deletions": 0, "changes": 215, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FREADME.DGUX386", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FREADME.DGUX386", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdoc%2FREADME.DGUX386?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,215 @@\n+    Garbage Collector (parallel iversion) for ix86 DG/UX Release R4.20MU07\n+\n+\n+     *READ* the file README.QUICK.\n+\n+     You need the GCC-3.0.3 rev (DG/UX) compiler to build this tree.\n+     This compiler has the new \"dgux386\" threads package implemented.\n+     It also supports the switch \"-pthread\" needed to link correctly\n+     the DG/UX's -lrte -lthread with -lgcc and the system's -lc. \n+     Finally we support parralleli-mark for the SMP DG/UX machines.\n+     To build the garbage collector do:\n+      \n+      ./configure --enable-parallel-mark\n+      make\n+      make gctest\n+\n+     Before you run \"gctest\" you need to set your LD_LIBRARY_PATH\n+     correctly so that \"gctest\" can find the shared library libgc.\n+     Alternatively you can do a configuration\n+\n+      ./configure --enable-parallel-mark --disable-shared\n+  \n+     to build only the static version of libgc.\n+  \n+     To enable debugging messages please do:\n+     1) Add the \"--enable-full-debug\" flag during configuration. \n+     2) Edit the file linux-threads.c and uncommnect the line:\n+\n+     /* #define DEBUG_THREADS 1 */ to ---> \n+\n+     #define DEBUG_THREADS 1\n+\n+     Then give \"make\" as usual.\n+    \n+     In a machine with 4 CPUs (my own machine) the option parallel\n+     mark (aka --enable-parallel-mark) makes a BIG difference.\n+\n+     Takis Psarogiannakopoulos\n+     University of Cambridge\n+     Centre for Mathematical Sciences\n+     Department of Pure Mathematics\n+     Wilberforce Road\n+     Cambridge CB3 0WB ,UK , <takis@XFree86.Org>\n+     January 2002\n+\n+\n+Note (HB):\n+     The integration of this patch is currently not complete.\n+     The following patches against 6.1alpha3 where hard to move\n+     to alpha4, and are not integrated.  There may also be minor\n+     problems with stylistic corrections made by me.\n+\n+\n+--- ltconfig.ORIG\tMon Jan 28 20:22:18 2002\n++++ ltconfig\tMon Jan 28 20:44:00 2002\n+@@ -689,6 +689,11 @@\n+        pic_flag=-Kconform_pic\n+     fi\n+     ;;\n++  dgux*)\n++    pic_flag='-fPIC'\n++    link_static='-Bstatic'\n++    wl='-Wl,'\n++    ;;\n+   *)\n+     pic_flag='-fPIC'\n+     ;;\n+@@ -718,6 +723,12 @@\n+     # We can build DLLs from non-PIC.\n+     ;;\n+ \n++  dgux*)\n++    pic_flag='-KPIC'\n++    link_static='-Bstatic'\n++    wl='-Wl,'\n++    ;;\n++\n+   osf3* | osf4* | osf5*)\n+     # All OSF/1 code is PIC.\n+     wl='-Wl,'\n+@@ -1154,6 +1165,22 @@\n+     fi\n+     ;;\n+ \n++  dgux*)\n++    ld_shlibs=yes\n++    # For both C/C++ ommit the deplibs. This is because we relying on the fact\n++    # that compilation of execitables will put them in correct order\n++    # in any case and sometimes are wrong when listed as deplibs (or missing some deplibs)\n++    # However when GNU ld and --whole-archive needs to be used we have the problem\n++    # that if the -fPIC *_s.a archive is linked through deplibs list we ommiting crucial\n++    # .lo/.o files from the created shared lib. This I think is not the case here.\n++    archive_cmds='$CC -shared -h $soname -o $lib $libobjs $linkopts'\n++    thread_safe_flag_spec='-pthread'\n++    wlarc=\n++    hardcode_libdir_flag_spec='-L$libdir'\n++    hardcode_shlibpath_var=no\n++    ac_cv_archive_cmds_needs_lc=no\n++    ;;\n++\n+   cygwin* | mingw*)\n+     # hardcode_libdir_flag_spec is actually meaningless, as there is\n+     # no search path for DLLs.\n+@@ -1497,7 +1524,7 @@\n+     ;;\n+ \n+   dgux*)\n+-    archive_cmds='$LD -G -h $soname -o $lib $libobjs $deplibs $linkopts'\n++    archive_cmds='$CC -shared -h $soname -o $lib $libobjs $linkopts'\n+     hardcode_libdir_flag_spec='-L$libdir'\n+     hardcode_shlibpath_var=no\n+     ;;\n+@@ -2092,12 +2119,17 @@\n+   ;;\n+ \n+ dgux*)\n+-  version_type=linux\n++  version_type=dgux\n+   need_lib_prefix=no\n+   need_version=no\n+-  library_names_spec='${libname}${release}.so$versuffix ${libname}${release}.so$major $libname.so'\n+-  soname_spec='${libname}${release}.so$major'\n++  library_names_spec='$libname.so$versuffix'\n++  soname_spec='$libname.so$versuffix'\n+   shlibpath_var=LD_LIBRARY_PATH\n++  thread_safe_flag_spec='-pthread'\n++  wlarc=\n++  hardcode_libdir_flag_spec='-L$libdir'\n++  hardcode_shlibpath_var=no\n++  ac_cv_archive_cmds_needs_lc=no\n+   ;;\n+ \n+ sysv4*MP*)\n+\n+\n+--- ltmain.sh.ORIG\tMon Jan 28 20:31:18 2002\n++++ ltmain.sh\tTue Jan 29 00:11:29 2002\n+@@ -1072,11 +1072,38 @@\n+ \tesac\n+ \t;;\n+ \n++      -thread*)\n++\t# DG/UX GCC 2.95.x, 3.x.x rev (DG/UX) links -lthread\n++\t# with the switch -threads\n++\tif test \"$arg\" = \"-threads\"; then\n++\t  case \"$host\" in\n++\t  i[3456]86-*-dgux*)\n++\t    deplibs=\"$deplibs $arg\"\n++\t    continue\n++\t    ;;\n++\t  esac\n++\tfi\n++\t;;\n++\n++      -pthread*)\n++\t# DG/UX GCC 2.95.x, 3.x.x rev (DG/UX) links -lthread\n++\t# with the switch -pthread\n++\tif test \"$arg\" = \"-pthread\"; then\n++\t  case \"$host\" in\n++\t  i[3456]86-*-dgux*)\n++\t    deplibs=\"$deplibs $arg\"\n++\t    continue\n++\t    ;;\n++\t  esac\n++\tfi\n++\t;;\n++\n+       -l*)\n+ \tif test \"$arg\" = \"-lc\"; then\n+ \t  case \"$host\" in\n+-\t  *-*-cygwin* | *-*-mingw* | *-*-os2* | *-*-beos*)\n++\t  *-*-cygwin* | *-*-mingw* | *-*-os2* | *-*-beos* | i[3456]86-*-dgux*)\n+ \t    # These systems don't actually have c library (as such)\n++\t    # It is wrong in DG/UX to add -lc when creating shared/dynamic objs/libs\n+ \t    continue\n+ \t    ;;\n+ \t  esac\n+@@ -1248,6 +1275,12 @@\n+ \t  temp_deplibs=\n+ \t  for deplib in $dependency_libs; do\n+ \t    case \"$deplib\" in\n++\t    -thread*)\n++\t\t temp_deplibs=\"$temp_deplibs $deplib\"\n++\t\t ;;\n++\t    -pthread)\n++\t\t temp_deplibs=\"$temp_deplibs $deplib\"\n++\t\t ;;\n+ \t    -R*) temp_xrpath=`$echo \"X$deplib\" | $Xsed -e 's/^-R//'`\n+ \t\t case \" $rpath $xrpath \" in\n+ \t\t *\" $temp_xrpath \"*) ;;\n+@@ -1709,6 +1742,13 @@\n+ \t  done\n+ \t  ;;\n+ \n++\tdgux)\n++\t  # Leave mostly blank for DG/UX\n++\t  major=\n++\t  versuffix=\".$current.$revision\";\n++\t  verstring=\n++\t  ;;\n++\n+ \tlinux)\n+ \t  major=.`expr $current - $age`\n+ \t  versuffix=\"$major.$age.$revision\"\n+@@ -1792,8 +1832,9 @@\n+ \n+ \tdependency_libs=\"$deplibs\"\n+ \tcase \"$host\" in\n+-\t*-*-cygwin* | *-*-mingw* | *-*-os2* | *-*-beos*)\n++\t*-*-cygwin* | *-*-mingw* | *-*-os2* | *-*-beos* | i[3456]86-*-dgux*)\n+ \t  # these systems don't actually have a c library (as such)!\n++\t  # It is wrong in DG/UX to add -lc when creating shared/dynamic objs/libs\n+ \t  ;;\n+ \t*)\n+ \t  # Add libc to deplibs on all other systems."}, {"sha": "96744edaf67e930ddf693675997549df7edde458", "filename": "boehm-gc/doc/README.arm.cross", "status": "added", "additions": 68, "deletions": 0, "changes": 68, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FREADME.arm.cross", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FREADME.arm.cross", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdoc%2FREADME.arm.cross?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,68 @@\n+From: Margaret Fleck\n+\n+Here's the key details of what worked for me, in case anyone else needs them.\n+There may well be better ways to do some of this, but ....\n+   -- Margaret\n+\n+\n+The badge4 has a StrongArm-1110 processor and a StrongArm-1111 coprocessor.  \n+\n+Assume that the garbage collector distribution is unpacked into /home/arm/gc6.0,\n+which is visible to both the ARM machine and a linux desktop (e.g. via NFS mounting).\n+\n+Assume that you have a file /home/arm/config.site with contents something like the\n+example attached below.  Notice that our local ARM toolchain lives in\n+/skiff/local.\n+\n+Go to /home/arm/gc6.0 directory.  Do\n+  CONFIG_SITE=/home/arm/config.site ./configure --target=arm-linux\n+--prefix=/home/arm/gc6.0\n+\n+On your desktop, do:\n+   make\n+   make install\n+The main garbage collector library should now be in ../gc6.0/lib/libgc.so.  \n+\n+To test the garbage collector, first do the following on your desktop\n+   make gctest\n+   ./gctest\n+Then do the following on the ARM machine\n+   cd .libs\n+   ./lt-gctest\n+\n+Do not try to do \"make test\" (the usual way of running the test\n+program).  This does not work and seems to erase some of the important\n+files.\n+\n+The gctest program claims to have succeeded.  Haven't run any further tests\n+with it, though I'll be doing so in the near future.\n+\n+-------------------------------\n+# config.site for configure\n+\n+# Modified from the one provided by Bradley D. LaRonde\n+# Edited by Andrej Cedilnik <acedil1@csee.umbc.edu>\n+# Used some of solutions by Tilman Vogel <Tilman.Vogel@web.de>\n+# Ported for iPAQ Familiar by Oliver Kurth <oliver.kurth@innominate.com>\n+# Further modified by Margaret Fleck for the badge4\n+\n+HOSTCC=gcc\n+\n+# Names of the cross-compilers\n+CC=/skiff/local/bin/arm-linux-gcc\n+CXX=/skiff/local/bin/arm-linux-gcc\n+\n+# The cross compiler specific options\n+CFLAGS=\"-O2 -fno-exceptions\"\n+CXXFLAGS=\"-O2 -fno-exceptions\"\n+CPPFLAGS=\"-O2 -fno-exceptions\"\n+LDFLAGS=\"\"\n+\n+# Some other programs\n+AR=/skiff/local/bin/arm-linux-ar\n+RANLIB=/skiff/local/bin/arm-linux-ranlib\n+NM=/skiff/local/bin/arm-linux-nm\n+ac_cv_path_NM=/skiff/local/bin/arm-linux-nm\n+ac_cv_func_setpgrp_void=yes\n+x_includes=/skiff/local/arm-linux/include/X11\n+x_libraries=/skiff/local/arm-linux/lib/X11"}, {"sha": "3cd1b818b196badbf4269cfe29353223a66f772c", "filename": "boehm-gc/doc/README.darwin", "status": "added", "additions": 106, "deletions": 0, "changes": 106, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FREADME.darwin", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2FREADME.darwin", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdoc%2FREADME.darwin?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,106 @@\n+Darwin/MacOSX Support - July 22, 2003\n+====================================\n+\n+Important Usage Notes\n+=====================\n+\n+GC_init() MUST be called before calling any other GC functions. This \n+is necessary to properly register segments in dynamic libraries. This\n+call is required even if you code does not use dynamic libraries as the\n+dyld code handles registering all data segments.\n+\n+When your use of the garbage collector is confined to dylibs and you\n+cannot call GC_init() before your libraries' static initializers have\n+run and perhaps called GC_malloc(), create an initialization routine\n+for each library to call GC_init():\n+\n+#include <gc/gc.h>\n+void my_library_init() { GC_init(); }\n+\n+Compile this code into a my_library_init.o, and link it into your\n+dylib. When you link the dylib, pass the -init argument with\n+_my_library_init (e.g. gcc -dynamiclib -o my_library.dylib a.o b.o c.o\n+my_library_init.o -init _my_library_init). This causes\n+my_library_init() to be called before any static initializers, and\n+will initialize the garbage collector properly. \n+\n+Note: It doesn't hurt to call GC_init() more than once, so it's best,\n+if you have an application or set of libraries that all use the\n+garbage collector, to create an initialization routine for each of\n+them that calls GC_init(). Better safe than sorry. \n+\n+The incremental collector is still a bit flaky on darwin. It seems to \n+work reliably with workarounds for a few possible bugs in place however\n+these workaround may not work correctly in all cases. There may also\n+be additional problems that I have not found. \n+\n+Implementation Information\n+==========================\n+Darwin/MacOSX support is nearly complete. Thread support is reliable on \n+Darwin 6.x (MacOSX 10.2) and there have been reports of success on older\n+Darwin versions (MacOSX 10.1). Shared library support had also been\n+added and the gc can be run from a shared library. There is currently only\n+support for Darwin/PPC although adding x86 support should be trivial.\n+\n+Thread support is implemented in terms of mach thread_suspend and \n+thread_resume calls. These provide a very clean interface to thread\n+suspension. This implementation doesn't rely on pthread_kill so the\n+code works on Darwin < 6.0 (MacOSX 10.1). All the code to stop the\n+world is located in darwin_stop_world.c.\n+\n+The original incremental collector support unfortunatelly no longer works\n+on recent Darwin versions. It also relied on some undocumented kernel\n+structures. Mach, however, does have a very clean interface to exception\n+handing. The current implementation uses Mach's exception handling. \n+\n+Much thanks goes to Andrew Stone, Dietmar Planitzer, Andrew Begel, \n+Jeff Sturm, and Jesse Rosenstock for all their work on the \n+Darwin/OS X port.\n+\n+-Brian Alliet\n+brian@brianweb.net\n+\n+\n+Older Information (Most of this no longer applies to the current code)\n+======================================================================\n+\n+While the GC should work on MacOS X Server, MacOS X and Darwin, I only tested\n+it on MacOS X Server.\n+I've added a PPC assembly version of GC_push_regs(), thus the setjmp() hack is\n+no longer necessary. Incremental collection is supported via mprotect/signal.\n+The current solution isn't really optimal because the signal handler must decode\n+the faulting PPC machine instruction in order to find the correct heap address.\n+Further, it must poke around in the register state which the kernel saved away\n+in some obscure register state structure before it calls the signal handler -\n+needless to say the layout of this structure is no where documented.\n+Threads and dynamic libraries are not yet supported (adding dynamic library\n+support via the low-level dyld API shouldn't be that hard).\n+\n+The original MacOS X port was brought to you by Andrew Stone.\n+\n+\n+June, 1 2000\n+\n+Dietmar Planitzer\n+dave.pl@ping.at\n+\n+Note from Andrew Begel:\n+\n+One more fix to enable gc.a to link successfully into a shared library for\n+MacOS X. You have to add -fno-common to the CFLAGS in the Makefile. MacOSX\n+disallows common symbols in anything that eventually finds its way into a\n+shared library. (I don't completely understand why, but -fno-common seems to\n+work and doesn't mess up the garbage collector's functionality).\n+\n+Feb 26, 2003\n+\n+Jeff Sturm and Jesse Rosenstock provided a patch that adds thread support.\n+GC_MACOSX_THREADS should be defined in the build and in clients.  Real\n+dynamic library support is still missing, i.e. dynamic library data segments\n+are still not scanned.  Code that stores pointers to the garbage collected\n+heap in statically allocated variables should not reside in a dynamic\n+library.  This still doesn't appear to be 100% reliable.  \n+\n+Mar 10, 2003\n+Brian Alliet contributed dynamic library support for MacOSX.  It could also\n+use more testing."}, {"sha": "7b336ec811ba6f040cfe46d155629c4561a7d1da", "filename": "boehm-gc/doc/gcinterface.html", "status": "added", "additions": 203, "deletions": 0, "changes": 203, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2Fgcinterface.html", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2Fgcinterface.html", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdoc%2Fgcinterface.html?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,203 @@\n+<!DOCTYPE HTML>\n+<HEAD>\n+<TITLE>Garbage Collector Interface</TITLE>\n+</HEAD>\n+<BODY>\n+<H1>C Interface</h1>\n+On many platforms, a single-threaded garbage collector library can be built\n+to act as a plug-in malloc replacement.  (Build with -DREDIRECT_MALLOC=GC_malloc\n+-DIGNORE_FREE.)  This is often the best way to deal with third-party libraries\n+which leak or prematurely free objects.  -DREDIRECT_MALLOC is intended\n+primarily as an easy way to adapt old code, not for new development.\n+<P>\n+New code should use the interface discussed below.\n+<P>\n+Code must be linked against the GC library.  On most UNIX platforms,\n+this will be gc.a.\n+<P>\n+The following describes the standard C interface to the garbage collector.\n+It is not a complete definition of the interface.  It describes only the\n+most commonly used functionality, approximately in decreasing order of\n+frequency of use.  The description assumes an ANSI C compiler.\n+The full interface is described in\n+<A HREF=\"http://hpl.hp.com/personal/Hans_Boehm/gc/gc_source/gch.txt\">gc.h</a>\n+or <TT>gc.h</tt> in the distribution.\n+<P>\n+Clients should include gc.h.\n+<P>\n+In the case of multithreaded code,\n+gc.h should be included after the threads header file, and\n+after defining the appropriate GC_XXXX_THREADS macro.\n+(For 6.2alpha4 and later, simply defining GC_THREADS should suffice.)\n+Gc.h must be included\n+in files that use either GC or threads primitives, since threads primitives\n+will be redefined to cooperate with the GC on many platforms.\n+<DL>\n+<DT> <B>void * GC_MALLOC(size_t <I>nbytes</i>)</b>\n+<DD>\n+Allocates and clears <I>nbytes</i> of storage.\n+Requires (amortized) time proportional to <I>nbytes</i>.\n+The resulting object will be automatically deallocated when unreferenced.\n+References from objects allocated with the system malloc are usually not\n+considered by the collector.  (See GC_MALLOC_UNCOLLECTABLE, however.)\n+GC_MALLOC is a macro which invokes GC_malloc by default or, if GC_DEBUG\n+is defined before gc.h is included, a debugging version that checks\n+occasionally for overwrite errors, and the like.\n+<DT> <B>void * GC_MALLOC_ATOMIC(size_t <I>nbytes</i>)</b>\n+<DD>\n+Allocates <I>nbytes</i> of storage.\n+Requires (amortized) time proportional to <I>nbytes</i>.\n+The resulting object will be automatically deallocated when unreferenced.\n+The client promises that the resulting object will never contain any pointers.\n+The memory is not cleared.\n+This is the preferred way to allocate strings, floating point arrays,\n+bitmaps, etc.\n+More precise information about pointer locations can be communicated to the\n+collector using the interface in\n+<A HREF=\"http://www.hpl.hp.com/personal/Hans_Boehm/gc/gc_source/gc_typedh.txt\">gc_typed.h</a> in the distribution.\n+<DT> <B>void * GC_MALLOC_UNCOLLECTABLE(size_t <I>nbytes</i>)</b>\n+<DD>\n+Identical to GC_MALLOC, except that the resulting object is not automatically\n+deallocated.  Unlike the system-provided malloc, the collector does\n+scan the object for pointers to garbage-collectable memory, even if the\n+block itself does not appear to be reachable.  (Objects allocated in this way\n+are effectively treated as roots by the collector.)\n+<DT> <B> void * GC_REALLOC(void *old, size_t new_size) </b>\n+<DD>\n+Allocate a new object of the indicated size and copy (a prefix of) the\n+old object into the new object.  The old object is reused in place if\n+convenient.  If the original object was allocated with GC_malloc_atomic,\n+the new object is subject to the same constraints.  If it was allocated\n+as an uncollectable object, then the new object is uncollectable, and\n+the old object (if different) is deallocated.\n+(Use GC_REALLOC with GC_MALLOC, etc.)\n+<DT> <B> void GC_FREE(void *dead) </b>\n+<DD>\n+Explicitly deallocate an object.  Typically not useful for small\n+collectable objects.  (Use GC_FREE with GC_MALLOC, etc.)\n+<DT> <B> void * GC_MALLOC_IGNORE_OFF_PAGE(size_t <I>nbytes</i>) </b>\n+<DD>\n+<DT> <B> void * GC_MALLOC_ATOMIC_IGNORE_OFF_PAGE(size_t <I>nbytes</i>) </b>\n+<DD>\n+Analogous to GC_MALLOC and GC_MALLOC_ATOMIC, except that the client\n+guarantees that as long\n+as the resulting object is of use, a pointer is maintained to someplace\n+inside the first 512 bytes of the object.  This pointer should be declared\n+volatile to avoid interference from compiler optimizations.\n+(Other nonvolatile pointers to the object may exist as well.)\n+This is the\n+preferred way to allocate objects that are likely to be > 100KBytes in size.\n+It greatly reduces the risk that such objects will be accidentally retained\n+when they are no longer needed.  Thus space usage may be significantly reduced.\n+<DT> <B> void GC_gcollect(void) </b>\n+<DD>\n+Explicitly force a garbage collection.\n+<DT> <B> void GC_enable_incremental(void) </b>\n+<DD>\n+Cause the garbage collector to perform a small amount of work\n+every few invocations of GC_malloc or the like, instead of performing\n+an entire collection at once.  This is likely to increase total\n+running time.  It will improve response on a platform that either has\n+suitable support in the garbage collector (Irix and most other Unix\n+versions, win32 if the collector was suitably built) or if \"stubborn\"\n+allocation is used (see <A HREF=\"http://www.hpl.hp.com/personal/Hans_Boehm/gc/gc_source/gch.txt\">gc.h</a>).\n+On many platforms this interacts poorly with system calls \n+that write to the garbage collected heap.\n+<DT> <B> GC_warn_proc GC_set_warn_proc(GC_warn_proc p) </b>\n+<DD>\n+Replace the default procedure used by the collector to print warnings.\n+The collector\n+may otherwise write to sterr, most commonly because GC_malloc was used\n+in a situation in which GC_malloc_ignore_off_page would have been more\n+appropriate.  See <A HREF=\"http://www.hpl.hp.com/personal/Hans_Boehm/gc/gc_source/gch.txt\">gc.h</a> for details.\n+<DT> <B> void GC_register_finalizer(...) </b>\n+<DD>\n+Register a function to be called when an object becomes inaccessible.\n+This is often useful as a backup method for releasing system resources\n+(<I>e.g.</i> closing files) when the object referencing them becomes\n+inaccessible.\n+It is not an acceptable method to perform actions that must be performed\n+in a timely fashion.\n+See <A HREF=\"http://www.hpl.hp.com/personal/Hans_Boehm/gc/gc_source/gch.txt\">gc.h</a> for details of the interface.\n+See <A HREF=\"http://www.hpl.hp.com/personal/Hans_Boehm/gc/finalization.html\">here</a> for a more detailed discussion\n+of the design.\n+<P>\n+Note that an object may become inaccessible before client code is done\n+operating on its fields.  Suitable synchronization is usually required.\n+See <A HREF=\"http://portal.acm.org/citation.cfm?doid=604131.604153\">here</a>\n+or <A HREF=\"http://www.hpl.hp.com/techreports/2002/HPL-2002-335.html\">here</a>\n+for details.\n+</dl>\n+<P>\n+If you are concerned with multiprocessor performance and scalability,\n+you should consider enabling and using thread local allocation (<I>e.g.</i>\n+GC_LOCAL_MALLOC, see <TT>gc_local_alloc.h</tt>.  If your platform\n+supports it, you should build the collector with parallel marking support\n+(-DPARALLEL_MARK, or --enable-parallel-mark).\n+<P>\n+If the collector is used in an environment in which pointer location\n+information for heap objects is easily available, this can be passed on\n+to the colllector using the interfaces in either <TT>gc_typed.h</tt>\n+or <TT>gc_gcj.h</tt>.\n+<P>\n+The collector distribution also includes a <B>string package</b> that takes\n+advantage of the collector.  For details see\n+<A HREF=\"http://www.hpl.hp.com/personal/Hans_Boehm/gc/gc_source/cordh.txt\">cord.h</a>\n+\n+<H1>C++ Interface</h1>\n+There are three distinct ways to use the collector from C++:\n+<DL>\n+<DT> <B> STL allocators </b>\n+<DD>\n+Users of the <A HREF=\"http://www.sgi.com/tech/stl\">SGI extended STL</a>\n+can include <TT>new_gc_alloc.h</tt> before including\n+STL header files.\n+(<TT>gc_alloc.h</tt> corresponds to now obsolete versions of the\n+SGI STL.)\n+This defines SGI-style allocators\n+<UL>\n+<LI> alloc\n+<LI> single_client_alloc\n+<LI> gc_alloc\n+<LI> single_client_gc_alloc\n+</ul>\n+which may be used either directly to allocate memory or to instantiate\n+container templates.  The first two allocate uncollectable but traced\n+memory, while the second two allocate collectable memory.\n+The single_client versions are not safe for concurrent access by\n+multiple threads, but are faster.\n+<P>\n+For an example, click <A HREF=\"http://hpl.hp.com/personal/Hans_Boehm/gc/gc_alloc_exC.txt\">here</a>.\n+<P>\n+Recent versions of the collector also include a more standard-conforming\n+allocator implemention in <TT>gc_allocator.h</tt>.  It defines\n+<UL>\n+<LI> traceable_allocator\n+<LI> gc_allocator\n+</ul>\n+Again the former allocates uncollectable but traced memory.\n+This should work with any fully standard-conforming C++ compiler.\n+<DT> <B> Class inheritance based interface </b>\n+<DD>\n+Users may include gc_cpp.h and then cause members of certain classes to\n+be allocated in garbage collectable memory by inheriting from class gc.\n+For details see <A HREF=\"http://hpl.hp.com/personal/Hans_Boehm/gc/gc_source/gc_cpph.txt\">gc_cpp.h</a>.\n+<DT> <B> C interface </b>\n+<DD>\n+It is also possible to use the C interface from \n+<A HREF=\"http://hpl.hp.com/personal/Hans_Boehm/gc/gc_source/gch.txt\">gc.h</a> directly.\n+On platforms which use malloc to implement ::new, it should usually be possible\n+to use a version of the collector that has been compiled as a malloc\n+replacement.  It is also possible to replace ::new and other allocation\n+functions suitably.\n+<P>\n+Note that user-implemented small-block allocation often works poorly with\n+an underlying garbage-collected large block allocator, since the collector\n+has to view all objects accessible from the user's free list as reachable.\n+This is likely to cause problems if GC_malloc is used with something like\n+the original HP version of STL.\n+This approach works with the SGI versions of the STL only if the\n+<TT>malloc_alloc</tt> allocator is used.\n+</dl>\n+</body>\n+</html>"}, {"sha": "91fa8ea840236fa3f6b76e2ba9dbf25f78cbda0b", "filename": "boehm-gc/doc/leak.html", "status": "added", "additions": 197, "deletions": 0, "changes": 197, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2Fleak.html", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2Fleak.html", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdoc%2Fleak.html?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,197 @@\n+<HTML>\n+<HEAD>\n+<TITLE>Using the Garbage Collector as Leak Detector</title>\n+</head>\n+<BODY>\n+<H1>Using the Garbage Collector as Leak Detector</h1>\n+The garbage collector may be used as a leak detector.\n+In this case, the primary function of the collector is to report\n+objects that were allocated (typically with <TT>GC_MALLOC</tt>),\n+not deallocated (normally with <TT>GC_FREE</tt>), but are\n+no longer accessible.  Since the object is no longer accessible,\n+there in normally no way to deallocate the object at a later time;\n+thus it can safely be assumed that the object has been \"leaked\".\n+<P>\n+This is substantially different from counting leak detectors,\n+which simply verify that all allocated objects are eventually\n+deallocated.  A garbage-collector based leak detector can provide\n+somewhat more precise information when an object was leaked.\n+More importantly, it does not report objects that are never\n+deallocated because they are part of \"permanent\" data structures.\n+Thus it does not require all objects to be deallocated at process\n+exit time, a potentially useless activity that often triggers\n+large amounts of paging.\n+<P>\n+All non-ancient versions of the garbage collector provide\n+leak detection support.  Version 5.3 adds the following\n+features:\n+<OL>\n+<LI> Leak detection mode can be initiated at run-time by\n+setting GC_find_leak instead of building the collector with FIND_LEAK\n+defined.  This variable should be set to a nonzero value\n+at program startup.\n+<LI> Leaked objects should be reported and then correctly garbage collected.\n+Prior versions either reported leaks or functioned as a garbage collector.\n+</ol>\n+For the rest of this description we will give instructions that work\n+with any reasonable version of the collector.\n+<P>\n+To use the collector as a leak detector, follow the following steps:\n+<OL>\n+<LI> Build the collector with -DFIND_LEAK.  Otherwise use default\n+build options.\n+<LI> Change the program so that all allocation and deallocation goes\n+through the garbage collector.\n+<LI> Arrange to call <TT>GC_gcollect</tt> at appropriate points to check\n+for leaks.\n+(For sufficiently long running programs, this will happen implicitly,\n+but probably not with sufficient frequency.)\n+</ol>\n+The second step can usually be accomplished with the\n+<TT>-DREDIRECT_MALLOC=GC_malloc</tt> option when the collector is built,\n+or by defining <TT>malloc</tt>, <TT>calloc</tt>,\n+<TT>realloc</tt> and <TT>free</tt>\n+to call the corresponding garbage collector functions.\n+But this, by itself, will not yield very informative diagnostics,\n+since the collector does not keep track of information about\n+how objects were allocated.  The error reports will include\n+only object addresses.\n+<P>\n+For more precise error reports, as much of the program as possible\n+should use the all uppercase variants of these functions, after\n+defining <TT>GC_DEBUG</tt>, and then including <TT>gc.h</tt>.\n+In this environment <TT>GC_MALLOC</tt> is a macro which causes\n+at least the file name and line number at the allocation point to\n+be saved as part of the object.  Leak reports will then also include\n+this information.\n+<P>\n+Many collector features (<I>e.g</i> stubborn objects, finalization,\n+and disappearing links) are less useful in this context, and are not\n+fully supported.  Their use will usually generate additional bogus\n+leak reports, since the collector itself drops some associated objects.\n+<P>\n+The same is generally true of thread support.  However, as of 6.0alpha4,\n+correct leak reports should be generated with linuxthreads.\n+<P>\n+On a few platforms (currently Solaris/SPARC, Irix, and, with -DSAVE_CALL_CHAIN,\n+Linux/X86), <TT>GC_MALLOC</tt>\n+also causes some more information about its call stack to be saved\n+in the object.  Such information is reproduced in the error\n+reports in very non-symbolic form, but it can be very useful with the\n+aid of a debugger.\n+<H2>An Example</h2>\n+The following header file <TT>leak_detector.h</tt> is included in the\n+\"include\" subdirectory of the distribution:\n+<PRE>\n+#define GC_DEBUG\n+#include \"gc.h\"\n+#define malloc(n) GC_MALLOC(n)\n+#define calloc(m,n) GC_MALLOC((m)*(n))\n+#define free(p) GC_FREE(p)\n+#define realloc(p,n) GC_REALLOC((p),(n))\n+#define CHECK_LEAKS() GC_gcollect()\n+</pre>\n+<P>\n+Assume the collector has been built with -DFIND_LEAK.  (For very\n+new versions of the collector, we could instead add the statement\n+<TT>GC_find_leak = 1</tt> as the first statement in <TT>main</tt>.\n+<P>\n+The program to be tested for leaks can then look like:\n+<PRE>\n+#include \"leak_detector.h\"\n+\n+main() {\n+    int *p[10];\n+    int i;\n+    /* GC_find_leak = 1; for new collector versions not \t*/\n+    /* compiled with -DFIND_LEAK.\t\t\t\t*/\n+    for (i = 0; i < 10; ++i) {\n+\tp[i] = malloc(sizeof(int)+i);\n+    }\n+    for (i = 1; i < 10; ++i) {\n+\tfree(p[i]);\n+    }\n+    for (i = 0; i < 9; ++i) {\n+\tp[i] = malloc(sizeof(int)+i);\n+    }\n+    CHECK_LEAKS();\n+}\t\n+</pre>\n+<P>\n+On an Intel X86 Linux system this produces on the stderr stream:\n+<PRE>\n+Leaked composite object at 0x806dff0 (leak_test.c:8, sz=4)\n+</pre>\n+(On most unmentioned operating systems, the output is similar to this.\n+If the collector had been built on Linux/X86 with -DSAVE_CALL_CHAIN,\n+the output would be closer to the Solaris example. For this to work,\n+the program should not be compiled with -fomit_frame_pointer.)\n+<P>\n+On Irix it reports\n+<PRE>\n+Leaked composite object at 0x10040fe0 (leak_test.c:8, sz=4)\n+        Caller at allocation:\n+                ##PC##= 0x10004910\n+</pre>\n+and on Solaris the error report is\n+<PRE>\n+Leaked composite object at 0xef621fc8 (leak_test.c:8, sz=4)\n+        Call chain at allocation:\n+                args: 4 (0x4), 200656 (0x30FD0)\n+                ##PC##= 0x14ADC\n+                args: 1 (0x1), -268436012 (0xEFFFFDD4)\n+                ##PC##= 0x14A64\n+</pre>\n+In the latter two cases some additional information is given about\n+how malloc was called when the leaked object was allocated.  For\n+Solaris, the first line specifies the arguments to <TT>GC_debug_malloc</tt>\n+(the actual allocation routine), The second the program counter inside\n+main, the third the arguments to <TT>main</tt>, and finally the program\n+counter inside the caller to main (i.e. in the C startup code).\n+<P>\n+In the Irix case, only the address inside the caller to main is given.\n+<P>\n+In many cases, a debugger is needed to interpret the additional information.\n+On systems supporting the \"adb\" debugger, the <TT>callprocs</tt> script\n+can be used to replace program counter values with symbolic names.\n+As of version 6.1, the collector tries to generate symbolic names for\n+call stacks if it knows how to do so on the platform.  This is true on\n+Linux/X86, but not on most other platforms.\n+<H2>Simplified leak detection under Linux</h2>\n+Since version 6.1, it should be possible to run the collector in leak\n+detection mode on a program a.out under Linux/X86 as follows:\n+<OL>\n+<LI> Ensure that a.out is a single-threaded executable.  This doesn't yet work\n+for multithreaded programs.\n+<LI> If possible, ensure that the addr2line program is installed in\n+/usr/bin.  (It comes with RedHat Linux.)\n+<LI> If possible, compile a.out with full debug information.\n+This will improve the quality of the leak reports.  With this approach, it is\n+no longer necessary to call GC_ routines explicitly, though that can also\n+improve the quality of the leak reports.\n+<LI> Build the collector and install it in directory <I>foo</i> as follows:\n+<UL>\n+<LI> configure --prefix=<I>foo</i> --enable-full-debug --enable-redirect-malloc\n+--disable-threads\n+<LI> make\n+<LI> make install\n+</ul>\n+<LI> Set environment variables as follows:\n+<UL>\n+<LI> LD_PRELOAD=<I>foo</i>/lib/libgc.so\n+<LI> GC_FIND_LEAK\n+<LI> You may also want to set GC_PRINT_STATS (to confirm that the collector\n+is running) and/or GC_LOOP_ON_ABORT (to facilitate debugging from another\n+window if something goes wrong).\n+</ul\n+<LI> Simply run a.out as you normally would.  Note that if you run anything\n+else (<I>e.g.</i> your editor) with those environment variables set,\n+it will also be leak tested.  This may or may not be useful and/or\n+embarrassing.  It can generate\n+mountains of leak reports if the application wasn't designed to avoid leaks,\n+<I>e.g.</i> because it's always short-lived.\n+</ol>\n+This has not yet been thropughly tested on large applications, but it's known\n+to do the right thing on at least some small ones.\n+</body>\n+</html>"}, {"sha": "2e70148dfb782fa877e75034368a8cbd3123c3b6", "filename": "boehm-gc/doc/scale.html", "status": "added", "additions": 210, "deletions": 0, "changes": 210, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2Fscale.html", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fdoc%2Fscale.html", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fdoc%2Fscale.html?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,210 @@\n+<HTML>\n+<HEAD>\n+<TITLE>Garbage collector scalability</TITLE>\n+</HEAD>\n+<BODY>\n+<H1>Garbage collector scalability</h1>\n+In its default configuration, the Boehm-Demers-Weiser garbage collector\n+is not thread-safe.  It can be made thread-safe for a number of environments\n+by building the collector with the appropriate\n+<TT>-D</tt><I>XXX</i><TT>-THREADS</tt> compilation\n+flag.  This has primarily two effects:\n+<OL>\n+<LI> It causes the garbage collector to stop all other threads when\n+it needs to see a consistent memory state.\n+<LI> It causes the collector to acquire a lock around essentially all\n+allocation and garbage collection activity.\n+</ol>\n+Since a single lock is used for all allocation-related activity, only one\n+thread can be allocating or collecting at one point.  This inherently\n+limits performance of multi-threaded applications on multiprocessors.\n+<P>\n+On most platforms, the allocator/collector lock is implemented as a\n+spin lock with exponential back-off.  Longer wait times are implemented\n+by yielding and/or sleeping.  If a collection is in progress, the pure\n+spinning stage is skipped.  This has the advantage that uncontested and\n+thus most uniprocessor lock acquisitions are very cheap.  It has the\n+disadvantage that the application may sleep for small periods of time\n+even when there is work to be done.  And threads may be unnecessarily\n+woken up for short periods.  Nonetheless, this scheme empirically\n+outperforms native queue-based mutual exclusion implementations in most\n+cases, sometimes drastically so.\n+<H2>Options for enhanced scalability</h2>\n+Version 6.0 of the collector adds two facilities to enhance collector\n+scalability on multiprocessors.  As of 6.0alpha1, these are supported \n+only under Linux on X86 and IA64 processors, though ports to other\n+otherwise supported Pthreads platforms should be straightforward.\n+They are intended to be used together.\n+<UL>\n+<LI>\n+Building the collector with <TT>-DPARALLEL_MARK</tt> allows the collector to\n+run the mark phase in parallel in multiple threads, and thus on multiple\n+processors.  The mark phase typically consumes the large majority of the\n+collection time.  Thus this largely parallelizes the garbage collector\n+itself, though not the allocation process.  Currently the marking is\n+performed by the thread that triggered the collection, together with\n+<I>N</i>-1 dedicated\n+threads, where <I>N</i> is the number of processors detected by the collector.\n+The dedicated threads are created once at initialization time.\n+<P>\n+A second effect of this flag is to switch to a more concurrent\n+implementation of <TT>GC_malloc_many</tt>, so that free lists can be\n+built, and memory can be cleared, by more than one thread concurrently.\n+<LI>\n+Building the collector with -DTHREAD_LOCAL_ALLOC adds support for thread\n+local allocation.  It does not, by itself, cause thread local allocation\n+to be used.  It simply allows the use of the interface in \n+<TT>gc_local_alloc.h</tt>.\n+<P>\n+Memory returned from thread-local allocators is completely interchangeable\n+with that returned by the standard allocators.  It may be used by other\n+threads.  The only difference is that, if the thread allocates enough\n+memory of a certain kind, it will build a thread-local free list for\n+objects of that kind, and allocate from that.  This greatly reduces\n+locking.  The thread-local free lists are refilled using \n+<TT>GC_malloc_many</tt>.\n+<P>\n+An important side effect of this flag is to replace the default\n+spin-then-sleep lock to be replace by a spin-then-queue based implementation.\n+This <I>reduces performance</i> for the standard allocation functions,\n+though it usually improves performance when thread-local allocation is\n+used heavily, and thus the number of short-duration lock acquisitions\n+is greatly reduced.\n+</ul>\n+<P>\n+The easiest way to switch an application to thread-local allocation is to\n+<OL>\n+<LI> Define the macro <TT>GC_REDIRECT_TO_LOCAL</tt>,\n+and then include the <TT>gc.h</tt>\n+header in each client source file.\n+<LI> Invoke <TT>GC_thr_init()</tt> before any allocation.\n+<LI> Allocate using <TT>GC_MALLOC</tt>, <TT>GC_MALLOC_ATOMIC</tt>,\n+and/or <TT>GC_GCJ_MALLOC</tt>.\n+</ol>\n+<H2>The Parallel Marking Algorithm</h2>\n+We use an algorithm similar to\n+<A HREF=\"http://www.yl.is.s.u-tokyo.ac.jp/gc/\">that developed by\n+Endo, Taura, and Yonezawa</a> at the University of Tokyo.\n+However, the data structures and implementation are different,\n+and represent a smaller change to the original collector source,\n+probably at the expense of extreme scalability.  Some of\n+the refinements they suggest, <I>e.g.</i> splitting large\n+objects, were also incorporated into out approach.\n+<P>\n+The global mark stack is transformed into a global work queue.\n+Unlike the usual case, it never shrinks during a mark phase.\n+The mark threads remove objects from the queue by copying them to a\n+local mark stack and changing the global descriptor to zero, indicating\n+that there is no more work to be done for this entry.\n+This removal\n+is done with no synchronization.  Thus it is possible for more than\n+one worker to remove the same entry, resulting in some work duplication.\n+<P>\n+The global work queue grows only if a marker thread decides to\n+return some of its local mark stack to the global one.  This\n+is done if the global queue appears to be running low, or if\n+the local stack is in danger of overflowing.  It does require\n+synchronization, but should be relatively rare.\n+<P>\n+The sequential marking code is reused to process local mark stacks.\n+Hence the amount of additional code required for parallel marking\n+is minimal.\n+<P>\n+It should be possible to use generational collection in the presence of the\n+parallel collector, by calling <TT>GC_enable_incremental()</tt>.\n+This does not result in fully incremental collection, since parallel mark\n+phases cannot currently be interrupted, and doing so may be too\n+expensive.\n+<P>\n+Gcj-style mark descriptors do not currently mix with the combination\n+of local allocation and incremental collection.  They should work correctly\n+with one or the other, but not both.\n+<P>\n+The number of marker threads is set on startup to the number of\n+available processors (or to the value of the <TT>GC_NPROCS</tt>\n+environment variable).  If only a single processor is detected,\n+parallel marking is disabled.\n+<P>\n+Note that setting GC_NPROCS to 1 also causes some lock acquisitions inside\n+the collector to immediately yield the processor instead of busy waiting\n+first.  In the case of a multiprocessor and a client with multiple\n+simultaneously runnable threads, this may have disastrous performance\n+consequences (e.g. a factor of 10 slowdown). \n+<H2>Performance</h2>\n+We conducted some simple experiments with a version of\n+<A HREF=\"gc_bench.html\">our GC benchmark</a> that was slightly modified to\n+run multiple concurrent client threads in the same address space.\n+Each client thread does the same work as the original benchmark, but they share\n+a heap.\n+This benchmark involves very little work outside of memory allocation.\n+This was run with GC 6.0alpha3 on a dual processor Pentium III/500 machine\n+under Linux 2.2.12.\n+<P>\n+Running with a thread-unsafe collector,  the benchmark ran in 9\n+seconds.  With the simple thread-safe collector,\n+built with <TT>-DLINUX_THREADS</tt>, the execution time\n+increased to 10.3 seconds, or 23.5 elapsed seconds with two clients.\n+(The times for the <TT>malloc</tt>/i<TT>free</tt> version\n+with glibc <TT>malloc</tt>\n+are 10.51 (standard library, pthreads not linked),\n+20.90 (one thread, pthreads linked),\n+and 24.55 seconds respectively. The benchmark favors a\n+garbage collector, since most objects are small.)\n+<P>\n+The following table gives execution times for the collector built\n+with parallel marking and thread-local allocation support\n+(<TT>-DGC_LINUX_THREADS -DPARALLEL_MARK -DTHREAD_LOCAL_ALLOC</tt>).  We tested\n+the client using either one or two marker threads, and running\n+one or two client threads.  Note that the client uses thread local\n+allocation exclusively.  With -DTHREAD_LOCAL_ALLOC the collector\n+switches to a locking strategy that is better tuned to less frequent\n+lock acquisition.  The standard allocation primitives thus peform\n+slightly worse than without -DTHREAD_LOCAL_ALLOC, and should be\n+avoided in time-critical code.\n+<P>\n+(The results using <TT>pthread_mutex_lock</tt>\n+directly for allocation locking would have been worse still, at\n+least for older versions of linuxthreads.\n+With THREAD_LOCAL_ALLOC, we first repeatedly try to acquire the\n+lock with pthread_mutex_try_lock(), busy_waiting between attempts.\n+After a fixed number of attempts, we use pthread_mutex_lock().)\n+<P>\n+These measurements do not use incremental collection, nor was prefetching\n+enabled in the marker.  We used the C version of the benchmark.\n+All measurements are in elapsed seconds on an unloaded machine.\n+<P>\n+<TABLE BORDER ALIGN=\"CENTER\">\n+<TR><TH>Number of threads</th><TH>1 marker thread (secs.)</th>\n+<TH>2 marker threads (secs.)</th></tr>\n+<TR><TD>1 client</td><TD ALIGN=\"CENTER\">10.45</td><TD ALIGN=\"CENTER\">7.85</td>\n+<TR><TD>2 clients</td><TD ALIGN=\"CENTER\">19.95</td><TD ALIGN=\"CENTER\">12.3</td>\n+</table>\n+<PP>\n+The execution time for the single threaded case is slightly worse than with\n+simple locking.  However, even the single-threaded benchmark runs faster than\n+even the thread-unsafe version if a second processor is available.\n+The execution time for two clients with thread local allocation time is\n+only 1.4 times the sequential execution time for a single thread in a\n+thread-unsafe environment, even though it involves twice the client work.\n+That represents close to a\n+factor of 2 improvement over the 2 client case with the old collector.\n+The old collector clearly\n+still suffered from some contention overhead, in spite of the fact that the\n+locking scheme had been fairly well tuned.\n+<P>\n+Full linear speedup (i.e. the same execution time for 1 client on one\n+processor as 2 clients on 2 processors)\n+is probably not achievable on this kind of\n+hardware even with such a small number of processors,\n+since the memory system is\n+a major constraint for the garbage collector,\n+the processors usually share a single memory bus, and thus\n+the aggregate memory bandwidth does not increase in\n+proportion to the number of processors. \n+<P>\n+These results are likely to be very sensitive to both hardware and OS\n+issues.  Preliminary experiments with an older Pentium Pro machine running\n+an older kernel were far less encouraging.\n+\n+</body>\n+</html>"}, {"sha": "87c85099381a79f872d62d99f816886f99d080e8", "filename": "boehm-gc/include/gc_allocator.h", "status": "added", "additions": 232, "deletions": 0, "changes": 232, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fgc_allocator.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fgc_allocator.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Finclude%2Fgc_allocator.h?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,232 @@\n+/*\n+ * Copyright (c) 1996-1997\n+ * Silicon Graphics Computer Systems, Inc.\n+ *\n+ * Permission to use, copy, modify, distribute and sell this software\n+ * and its documentation for any purpose is hereby granted without fee,\n+ * provided that the above copyright notice appear in all copies and\n+ * that both that copyright notice and this permission notice appear\n+ * in supporting documentation.  Silicon Graphics makes no\n+ * representations about the suitability of this software for any\n+ * purpose.  It is provided \"as is\" without express or implied warranty.\n+ *\n+ * Copyright (c) 2002\n+ * Hewlett-Packard Company\n+ *\n+ * Permission to use, copy, modify, distribute and sell this software\n+ * and its documentation for any purpose is hereby granted without fee,\n+ * provided that the above copyright notice appear in all copies and\n+ * that both that copyright notice and this permission notice appear\n+ * in supporting documentation.  Hewlett-Packard Company makes no\n+ * representations about the suitability of this software for any\n+ * purpose.  It is provided \"as is\" without express or implied warranty.\n+ */\n+\n+/*\n+ * This implements standard-conforming allocators that interact with\n+ * the garbage collector.  Gc_alloctor<T> allocates garbage-collectable\n+ * objects of type T.  Traceable_allocator<T> allocates objects that\n+ * are not temselves garbage collected, but are scanned by the\n+ * collector for pointers to collectable objects.  Traceable_alloc\n+ * should be used for explicitly managed STL containers that may\n+ * point to collectable objects.\n+ *\n+ * This code was derived from an earlier version of the GNU C++ standard\n+ * library, which itself was derived from the SGI STL implementation.\n+ */\n+\n+#include \"gc.h\" \t// For size_t\n+\n+/* First some helpers to allow us to dispatch on whether or not a type\n+ * is known to be pointerfree.\n+ * These are private, except that the client may invoke the\n+ * GC_DECLARE_PTRFREE macro.\n+ */\n+\n+struct GC_true_type {};\n+struct GC_false_type {};\n+\n+template <class GC_tp>\n+struct GC_type_traits {\n+  GC_false_type GC_is_ptr_free;\n+};\n+\n+# define GC_DECLARE_PTRFREE(T) \\\n+template<> struct GC_type_traits<T> { GC_true_type GC_is_ptr_free; }\n+\n+GC_DECLARE_PTRFREE(signed char);\n+GC_DECLARE_PTRFREE(unsigned char);\n+GC_DECLARE_PTRFREE(signed short);\n+GC_DECLARE_PTRFREE(unsigned short);\n+GC_DECLARE_PTRFREE(signed int);\n+GC_DECLARE_PTRFREE(unsigned int);\n+GC_DECLARE_PTRFREE(signed long);\n+GC_DECLARE_PTRFREE(unsigned long);\n+GC_DECLARE_PTRFREE(float);\n+GC_DECLARE_PTRFREE(double);\n+/* The client may want to add others.\t*/\n+\n+// In the following GC_Tp is GC_true_type iff we are allocating a\n+// pointerfree object.\n+template <class GC_Tp>\n+inline void * GC_selective_alloc(size_t n, GC_Tp) {\n+    return GC_MALLOC(n);\n+}\n+\n+template <>\n+inline void * GC_selective_alloc<GC_true_type>(size_t n, GC_true_type) {\n+    return GC_MALLOC_ATOMIC(n);\n+}\n+\n+/* Now the public gc_allocator<T> class:\n+ */\n+template <class GC_Tp>\n+class gc_allocator {\n+public:\n+  typedef size_t     size_type;\n+  typedef ptrdiff_t  difference_type;\n+  typedef GC_Tp*       pointer;\n+  typedef const GC_Tp* const_pointer;\n+  typedef GC_Tp&       reference;\n+  typedef const GC_Tp& const_reference;\n+  typedef GC_Tp        value_type;\n+\n+  template <class GC_Tp1> struct rebind {\n+    typedef gc_allocator<GC_Tp1> other;\n+  };\n+\n+  gc_allocator()  {}\n+# ifndef _MSC_VER\n+    // I'm not sure why this is needed here in addition to the following.\n+    // The standard specifies it for the standard allocator, but VC++ rejects\n+    // it.\t-HB\n+    gc_allocator(const gc_allocator&) throw() {}\n+# endif\n+  template <class GC_Tp1> gc_allocator(const gc_allocator<GC_Tp1>&) throw() {}\n+  ~gc_allocator() throw() {}\n+\n+  pointer address(reference GC_x) const { return &GC_x; }\n+  const_pointer address(const_reference GC_x) const { return &GC_x; }\n+\n+  // GC_n is permitted to be 0.  The C++ standard says nothing about what\n+  // the return value is when GC_n == 0.\n+  GC_Tp* allocate(size_type GC_n, const void* = 0) {\n+    GC_type_traits<GC_Tp> traits;\n+    return static_cast<GC_Tp *>\n+\t    (GC_selective_alloc(GC_n * sizeof(GC_Tp),\n+\t\t\t        traits.GC_is_ptr_free));\n+  }\n+\n+  // __p is not permitted to be a null pointer.\n+  void deallocate(pointer __p, size_type GC_n)\n+    { GC_FREE(__p); }\n+\n+  size_type max_size() const throw()\n+    { return size_t(-1) / sizeof(GC_Tp); }\n+\n+  void construct(pointer __p, const GC_Tp& __val) { new(__p) GC_Tp(__val); }\n+  void destroy(pointer __p) { __p->~GC_Tp(); }\n+};\n+\n+template<>\n+class gc_allocator<void> {\n+  typedef size_t      size_type;\n+  typedef ptrdiff_t   difference_type;\n+  typedef void*       pointer;\n+  typedef const void* const_pointer;\n+  typedef void        value_type;\n+\n+  template <class GC_Tp1> struct rebind {\n+    typedef gc_allocator<GC_Tp1> other;\n+  };\n+};\n+\n+\n+template <class GC_T1, class GC_T2>\n+inline bool operator==(const gc_allocator<GC_T1>&, const gc_allocator<GC_T2>&)\n+{\n+  return true;\n+}\n+\n+template <class GC_T1, class GC_T2>\n+inline bool operator!=(const gc_allocator<GC_T1>&, const gc_allocator<GC_T2>&)\n+{\n+  return false;\n+}\n+\n+/*\n+ * And the public traceable_allocator class.\n+ */\n+\n+// Note that we currently don't specialize the pointer-free case, since a\n+// pointer-free traceable container doesn't make that much sense,\n+// though it could become an issue due to abstraction boundaries.\n+template <class GC_Tp>\n+class traceable_allocator {\n+public:\n+  typedef size_t     size_type;\n+  typedef ptrdiff_t  difference_type;\n+  typedef GC_Tp*       pointer;\n+  typedef const GC_Tp* const_pointer;\n+  typedef GC_Tp&       reference;\n+  typedef const GC_Tp& const_reference;\n+  typedef GC_Tp        value_type;\n+\n+  template <class GC_Tp1> struct rebind {\n+    typedef traceable_allocator<GC_Tp1> other;\n+  };\n+\n+  traceable_allocator() throw() {}\n+# ifndef _MSC_VER\n+    traceable_allocator(const traceable_allocator&) throw() {}\n+# endif\n+  template <class GC_Tp1> traceable_allocator\n+\t  (const traceable_allocator<GC_Tp1>&) throw() {}\n+  ~traceable_allocator() throw() {}\n+\n+  pointer address(reference GC_x) const { return &GC_x; }\n+  const_pointer address(const_reference GC_x) const { return &GC_x; }\n+\n+  // GC_n is permitted to be 0.  The C++ standard says nothing about what\n+  // the return value is when GC_n == 0.\n+  GC_Tp* allocate(size_type GC_n, const void* = 0) {\n+    return static_cast<GC_Tp*>(GC_MALLOC_UNCOLLECTABLE(GC_n * sizeof(GC_Tp)));\n+  }\n+\n+  // __p is not permitted to be a null pointer.\n+  void deallocate(pointer __p, size_type GC_n)\n+    { GC_FREE(__p); }\n+\n+  size_type max_size() const throw()\n+    { return size_t(-1) / sizeof(GC_Tp); }\n+\n+  void construct(pointer __p, const GC_Tp& __val) { new(__p) GC_Tp(__val); }\n+  void destroy(pointer __p) { __p->~GC_Tp(); }\n+};\n+\n+template<>\n+class traceable_allocator<void> {\n+  typedef size_t      size_type;\n+  typedef ptrdiff_t   difference_type;\n+  typedef void*       pointer;\n+  typedef const void* const_pointer;\n+  typedef void        value_type;\n+\n+  template <class GC_Tp1> struct rebind {\n+    typedef traceable_allocator<GC_Tp1> other;\n+  };\n+};\n+\n+\n+template <class GC_T1, class GC_T2>\n+inline bool operator==(const traceable_allocator<GC_T1>&, const traceable_allocator<GC_T2>&)\n+{\n+  return true;\n+}\n+\n+template <class GC_T1, class GC_T2>\n+inline bool operator!=(const traceable_allocator<GC_T1>&, const traceable_allocator<GC_T2>&)\n+{\n+  return false;\n+}\n+"}, {"sha": "0c836d876c85b81e70a273d2dbbf90b9143b57ac", "filename": "boehm-gc/include/gc_config_macros.h", "status": "added", "additions": 147, "deletions": 0, "changes": 147, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fgc_config_macros.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fgc_config_macros.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Finclude%2Fgc_config_macros.h?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,147 @@\n+/*\n+ * This should never be included directly.  It is included only from gc.h.\n+ * We separate it only to make gc.h more suitable as documentation.\n+ * \n+ * Some tests for old macros.  These violate our namespace rules and will\n+ * disappear shortly.  Use the GC_ names.\n+ */\n+#if defined(SOLARIS_THREADS) || defined(_SOLARIS_THREADS)\n+# define GC_SOLARIS_THREADS\n+#endif\n+#if defined(_SOLARIS_PTHREADS)\n+# define GC_SOLARIS_PTHREADS\n+#endif\n+#if defined(IRIX_THREADS)\n+# define GC_IRIX_THREADS\n+#endif\n+#if defined(DGUX_THREADS)\n+# if !defined(GC_DGUX386_THREADS)\n+#  define GC_DGUX386_THREADS\n+# endif\n+#endif\n+#if defined(AIX_THREADS)\n+# define GC_AIX_THREADS\n+#endif\n+#if defined(HPUX_THREADS)\n+# define GC_HPUX_THREADS\n+#endif\n+#if defined(OSF1_THREADS)\n+# define GC_OSF1_THREADS\n+#endif\n+#if defined(LINUX_THREADS)\n+# define GC_LINUX_THREADS\n+#endif\n+#if defined(WIN32_THREADS)\n+# define GC_WIN32_THREADS\n+#endif\n+#if defined(USE_LD_WRAP)\n+# define GC_USE_LD_WRAP\n+#endif\n+\n+#if !defined(_REENTRANT) && (defined(GC_SOLARIS_THREADS) \\\n+\t\t             || defined(GC_SOLARIS_PTHREADS) \\\n+\t\t\t     || defined(GC_HPUX_THREADS) \\\n+\t\t\t     || defined(GC_AIX_THREADS) \\\n+\t\t\t     || defined(GC_LINUX_THREADS))\n+# define _REENTRANT\n+\t/* Better late than never.  This fails if system headers that\t*/\n+\t/* depend on this were previously included.\t\t\t*/\n+#endif\n+\n+#if defined(GC_DGUX386_THREADS) && !defined(_POSIX4A_DRAFT10_SOURCE)\n+# define _POSIX4A_DRAFT10_SOURCE 1\n+#endif\n+\n+# if defined(GC_SOLARIS_PTHREADS) || defined(GC_FREEBSD_THREADS) || \\\n+\tdefined(GC_IRIX_THREADS) || defined(GC_LINUX_THREADS) || \\\n+\tdefined(GC_HPUX_THREADS) || defined(GC_OSF1_THREADS) || \\\n+\tdefined(GC_DGUX386_THREADS) || defined(GC_DARWIN_THREADS) || \\\n+\tdefined(GC_AIX_THREADS) || \\\n+        (defined(GC_WIN32_THREADS) && defined(__CYGWIN32__))\n+#   define GC_PTHREADS\n+# endif\n+\n+#if defined(GC_THREADS) && !defined(GC_PTHREADS)\n+# if defined(__linux__)\n+#   define GC_LINUX_THREADS\n+#   define GC_PTHREADS\n+# endif\n+# if !defined(LINUX) && (defined(_PA_RISC1_1) || defined(_PA_RISC2_0) \\\n+                         || defined(hppa) || defined(__HPPA))\n+#   define GC_HPUX_THREADS\n+#   define GC_PTHREADS\n+# endif\n+# if !defined(__linux__) && (defined(__alpha) || defined(__alpha__))\n+#   define GC_OSF1_THREADS\n+#   define GC_PTHREADS\n+# endif\n+# if defined(__mips) && !defined(__linux__)\n+#   define GC_IRIX_THREADS\n+#   define GC_PTHREADS\n+# endif\n+# if defined(__sparc) && !defined(__linux__)\n+#   define GC_SOLARIS_PTHREADS\n+#   define GC_PTHREADS\n+# endif\n+# if defined(__APPLE__) && defined(__MACH__) && defined(__ppc__)\n+#   define GC_DARWIN_THREADS\n+#   define GC_PTHREADS\n+# endif\n+# if !defined(GC_PTHREADS) && defined(__FreeBSD__)\n+#   define GC_FREEBSD_THREADS\n+#   define GC_PTHREADS\n+# endif\n+# if defined(DGUX) && (defined(i386) || defined(__i386__))\n+#   define GC_DGUX386_THREADS\n+#   define GC_PTHREADS\n+# endif\n+#endif /* GC_THREADS */\n+\n+#if defined(GC_THREADS) && !defined(GC_PTHREADS) && defined(MSWIN32)\n+# define GC_WIN32_THREADS\n+#endif\n+\n+#if defined(GC_SOLARIS_PTHREADS) && !defined(GC_SOLARIS_THREADS)\n+#   define GC_SOLARIS_THREADS\n+#endif\n+\n+# define __GC\n+# include <stddef.h>\n+# ifdef _WIN32_WCE\n+/* Yet more kluges for WinCE */\n+#   include <stdlib.h>\t\t/* size_t is defined here */\n+    typedef long ptrdiff_t;\t/* ptrdiff_t is not defined */\n+# endif\n+\n+#if defined(_DLL) && !defined(GC_NOT_DLL) && !defined(GC_DLL)\n+# define GC_DLL\n+#endif\n+\n+#if defined(__MINGW32__) && defined(GC_DLL)\n+# ifdef GC_BUILD\n+#   define GC_API __declspec(dllexport)\n+# else\n+#   define GC_API __declspec(dllimport)\n+# endif\n+#endif\n+\n+#if (defined(__DMC__) || defined(_MSC_VER)) && defined(GC_DLL)\n+# ifdef GC_BUILD\n+#   define GC_API extern __declspec(dllexport)\n+# else\n+#   define GC_API __declspec(dllimport)\n+# endif\n+#endif\n+\n+#if defined(__WATCOMC__) && defined(GC_DLL)\n+# ifdef GC_BUILD\n+#   define GC_API extern __declspec(dllexport)\n+# else\n+#   define GC_API extern __declspec(dllimport)\n+# endif\n+#endif\n+\n+#ifndef GC_API\n+#define GC_API extern\n+#endif\n+"}, {"sha": "0f43982d5c1e1b3af86126400ab5b281aecfcd20", "filename": "boehm-gc/include/private/darwin_semaphore.h", "status": "added", "additions": 68, "deletions": 0, "changes": 68, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fprivate%2Fdarwin_semaphore.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fprivate%2Fdarwin_semaphore.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Finclude%2Fprivate%2Fdarwin_semaphore.h?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,68 @@\n+#ifndef GC_DARWIN_SEMAPHORE_H\n+#define GC_DARWIN_SEMAPHORE_H\n+\n+#if !defined(GC_DARWIN_THREADS)\n+#error darwin_semaphore.h included with GC_DARWIN_THREADS not defined\n+#endif\n+\n+/*\n+   This is a very simple semaphore implementation for darwin. It\n+   is implemented in terms of pthreads calls so it isn't async signal\n+   safe. This isn't a problem because signals aren't used to\n+   suspend threads on darwin.\n+*/\n+   \n+typedef struct {\n+    pthread_mutex_t mutex;\n+    pthread_cond_t cond;\n+    int value;\n+} sem_t;\n+\n+static int sem_init(sem_t *sem, int pshared, int value) {\n+    int ret;\n+    if(pshared)\n+        GC_abort(\"sem_init with pshared set\");\n+    sem->value = value;\n+    \n+    ret = pthread_mutex_init(&sem->mutex,NULL);\n+    if(ret < 0) return -1;\n+    ret = pthread_cond_init(&sem->cond,NULL);\n+    if(ret < 0) return -1;\n+    return 0;\n+}\n+\n+static int sem_post(sem_t *sem) {\n+    if(pthread_mutex_lock(&sem->mutex) < 0)\n+        return -1;\n+    sem->value++;\n+    if(pthread_cond_signal(&sem->cond) < 0) {\n+        pthread_mutex_unlock(&sem->mutex);\n+        return -1;\n+    }\n+    if(pthread_mutex_unlock(&sem->mutex) < 0)\n+        return -1;\n+    return 0;\n+}\n+\n+static int sem_wait(sem_t *sem) {\n+    if(pthread_mutex_lock(&sem->mutex) < 0)\n+        return -1;\n+    while(sem->value == 0) {\n+        pthread_cond_wait(&sem->cond,&sem->mutex);\n+    }\n+    sem->value--;\n+    if(pthread_mutex_unlock(&sem->mutex) < 0)\n+        return -1;    \n+    return 0;\n+}\n+\n+static int sem_destroy(sem_t *sem) {\n+    int ret;\n+    ret = pthread_cond_destroy(&sem->cond);\n+    if(ret < 0) return -1;\n+    ret = pthread_mutex_destroy(&sem->mutex);\n+    if(ret < 0) return -1;\n+    return 0;\n+}\n+\n+#endif"}, {"sha": "9924297ec77f7d1c2addfd4662348e3cd8bc4e85", "filename": "boehm-gc/include/private/darwin_stop_world.h", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fprivate%2Fdarwin_stop_world.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fprivate%2Fdarwin_stop_world.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Finclude%2Fprivate%2Fdarwin_stop_world.h?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,15 @@\n+#ifndef GC_DARWIN_STOP_WORLD_H\n+#define GC_DARWIN_STOP_WORLD_H\n+\n+#if !defined(GC_DARWIN_THREADS)\n+#error darwin_stop_world.h included without GC_DARWIN_THREADS defined\n+#endif\n+\n+#include <mach/mach.h>\n+#include <mach/thread_act.h>\n+\n+struct thread_stop_info {\n+    mach_port_t mach_thread;\n+};\n+\n+#endif"}, {"sha": "054c7a0eacd7c14d6c0cd40e6082c4a1d547afb4", "filename": "boehm-gc/include/private/pthread_stop_world.h", "status": "added", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fprivate%2Fpthread_stop_world.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fprivate%2Fpthread_stop_world.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Finclude%2Fprivate%2Fpthread_stop_world.h?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,12 @@\n+#ifndef GC_PTHREAD_STOP_WORLD_H\n+#define GC_PTHREAD_STOP_WORLD_H\n+\n+struct thread_stop_info {\n+    int\tsignal;\n+    word last_stop_count;\t/* GC_last_stop_count value when thread\t*/\n+    \t\t\t\t/* last successfully handled a suspend\t*/\n+    \t\t\t\t/* signal.\t\t\t\t*/\n+    ptr_t stack_ptr;  \t\t/* Valid only when stopped.      \t*/\n+};\n+    \n+#endif"}, {"sha": "0ef917e7ef048f81be4b97ce82abdc09ab84ad45", "filename": "boehm-gc/include/private/pthread_support.h", "status": "added", "additions": 97, "deletions": 0, "changes": 97, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fprivate%2Fpthread_support.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Finclude%2Fprivate%2Fpthread_support.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Finclude%2Fprivate%2Fpthread_support.h?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,97 @@\n+#ifndef GC_PTHREAD_SUPPORT_H\n+#define GC_PTHREAD_SUPPORT_H\n+\n+# include \"private/gc_priv.h\"\n+\n+# if defined(GC_PTHREADS) && !defined(GC_SOLARIS_THREADS) \\\n+     && !defined(GC_IRIX_THREADS) && !defined(GC_WIN32_THREADS)\n+     \n+#if defined(GC_DARWIN_THREADS)\n+# include \"private/darwin_stop_world.h\"\n+#else\n+# include \"private/pthread_stop_world.h\"\n+#endif\n+\n+/* We use the allocation lock to protect thread-related data structures. */\n+\n+/* The set of all known threads.  We intercept thread creation and \t*/\n+/* joins.\t\t\t\t\t\t\t\t*/\n+/* Protected by allocation/GC lock.\t\t\t\t\t*/\n+/* Some of this should be declared volatile, but that's inconsistent\t*/\n+/* with some library routine declarations.  \t\t \t\t*/\n+typedef struct GC_Thread_Rep {\n+    struct GC_Thread_Rep * next;  /* More recently allocated threads\t*/\n+\t\t\t\t  /* with a given pthread id come \t*/\n+\t\t\t\t  /* first.  (All but the first are\t*/\n+\t\t\t\t  /* guaranteed to be dead, but we may  */\n+\t\t\t\t  /* not yet have registered the join.) */\n+    pthread_t id;\n+    /* Extra bookkeeping information the stopping code uses */\n+    struct thread_stop_info stop_info;\n+    \n+    short flags;\n+#\tdefine FINISHED 1   \t/* Thread has exited.\t*/\n+#\tdefine DETACHED 2\t/* Thread is intended to be detached.\t*/\n+#\tdefine MAIN_THREAD 4\t/* True for the original thread only.\t*/\n+    short thread_blocked;\t/* Protected by GC lock.\t\t*/\n+    \t\t\t\t/* Treated as a boolean value.  If set,\t*/\n+    \t\t\t\t/* thread will acquire GC lock before\t*/\n+    \t\t\t\t/* doing any pointer manipulations, and\t*/\n+    \t\t\t\t/* has set its sp value.  Thus it does\t*/\n+    \t\t\t\t/* not need to be sent a signal to stop\t*/\n+    \t\t\t\t/* it.\t\t\t\t\t*/\n+    ptr_t stack_end;\t\t/* Cold end of the stack.\t\t*/\n+#   ifdef IA64\n+\tptr_t backing_store_end;\n+\tptr_t backing_store_ptr;\n+#   endif\n+    void * status;\t\t/* The value returned from the thread.  */\n+    \t\t\t\t/* Used only to avoid premature \t*/\n+\t\t\t\t/* reclamation of any data it might \t*/\n+\t\t\t\t/* reference.\t\t\t\t*/\n+#   ifdef THREAD_LOCAL_ALLOC\n+#\tif CPP_WORDSZ == 64 && defined(ALIGN_DOUBLE)\n+#\t    define GRANULARITY 16\n+#\t    define NFREELISTS 49\n+#\telse\n+#\t    define GRANULARITY 8\n+#\t    define NFREELISTS 65\n+#\tendif\n+\t/* The ith free list corresponds to size i*GRANULARITY */\n+#\tdefine INDEX_FROM_BYTES(n) ((ADD_SLOP(n) + GRANULARITY - 1)/GRANULARITY)\n+#\tdefine BYTES_FROM_INDEX(i) ((i) * GRANULARITY - EXTRA_BYTES)\n+#\tdefine SMALL_ENOUGH(bytes) (ADD_SLOP(bytes) <= \\\n+\t\t\t\t    (NFREELISTS-1)*GRANULARITY)\n+\tptr_t ptrfree_freelists[NFREELISTS];\n+\tptr_t normal_freelists[NFREELISTS];\n+#\tifdef GC_GCJ_SUPPORT\n+\t  ptr_t gcj_freelists[NFREELISTS];\n+#\tendif\n+\t\t/* Free lists contain either a pointer or a small count */\n+\t\t/* reflecting the number of granules allocated at that\t*/\n+\t\t/* size.\t\t\t\t\t\t*/\n+\t\t/* 0 ==> thread-local allocation in use, free list\t*/\n+\t\t/*       empty.\t\t\t\t\t\t*/\n+\t\t/* > 0, <= DIRECT_GRANULES ==> Using global allocation,\t*/\n+\t\t/*       too few objects of this size have been\t\t*/\n+\t\t/* \t allocated by this thread.\t\t\t*/\n+\t\t/* >= HBLKSIZE  => pointer to nonempty free list.\t*/\n+\t\t/* > DIRECT_GRANULES, < HBLKSIZE ==> transition to\t*/\n+\t\t/*    local alloc, equivalent to 0.\t\t\t*/\n+#\tdefine DIRECT_GRANULES (HBLKSIZE/GRANULARITY)\n+\t\t/* Don't use local free lists for up to this much \t*/\n+\t\t/* allocation.\t\t\t\t\t\t*/\n+#   endif\n+} * GC_thread;\n+\n+# define THREAD_TABLE_SZ 128\t/* Must be power of 2\t*/\n+extern volatile GC_thread GC_threads[THREAD_TABLE_SZ];\n+\n+extern GC_bool GC_thr_initialized;\n+\n+GC_thread GC_lookup_thread(pthread_t id);\n+\n+void GC_stop_init();\n+\n+#endif /* GC_PTHREADS && !GC_SOLARIS_THREADS.... etc */\n+#endif /* GC_PTHREAD_SUPPORT_H */"}, {"sha": "dd583709f535918128e0f8d3b6a4fddf64c87cec", "filename": "boehm-gc/missing", "status": "added", "additions": 336, "deletions": 0, "changes": 336, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fmissing", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fmissing", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fmissing?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,336 @@\n+#! /bin/sh\n+# Common stub for a few missing GNU programs while installing.\n+# Copyright 1996, 1997, 1999, 2000 Free Software Foundation, Inc.\n+# Originally by Fran,cois Pinard <pinard@iro.umontreal.ca>, 1996.\n+\n+# This program is free software; you can redistribute it and/or modify\n+# it under the terms of the GNU General Public License as published by\n+# the Free Software Foundation; either version 2, or (at your option)\n+# any later version.\n+\n+# This program is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+# GNU General Public License for more details.\n+\n+# You should have received a copy of the GNU General Public License\n+# along with this program; if not, write to the Free Software\n+# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n+# 02111-1307, USA.\n+\n+# As a special exception to the GNU General Public License, if you\n+# distribute this file as part of a program that contains a\n+# configuration script generated by Autoconf, you may include it under\n+# the same distribution terms that you use for the rest of that program.\n+\n+if test $# -eq 0; then\n+  echo 1>&2 \"Try \\`$0 --help' for more information\"\n+  exit 1\n+fi\n+\n+run=:\n+\n+# In the cases where this matters, `missing' is being run in the\n+# srcdir already.\n+if test -f configure.ac; then\n+  configure_ac=configure.ac\n+else\n+  configure_ac=configure.in\n+fi\n+\n+case \"$1\" in\n+--run)\n+  # Try to run requested program, and just exit if it succeeds.\n+  run=\n+  shift\n+  \"$@\" && exit 0\n+  ;;\n+esac\n+\n+# If it does not exist, or fails to run (possibly an outdated version),\n+# try to emulate it.\n+case \"$1\" in\n+\n+  -h|--h|--he|--hel|--help)\n+    echo \"\\\n+$0 [OPTION]... PROGRAM [ARGUMENT]...\n+\n+Handle \\`PROGRAM [ARGUMENT]...' for when PROGRAM is missing, or return an\n+error status if there is no known handling for PROGRAM.\n+\n+Options:\n+  -h, --help      display this help and exit\n+  -v, --version   output version information and exit\n+  --run           try to run the given command, and emulate it if it fails\n+\n+Supported PROGRAM values:\n+  aclocal      touch file \\`aclocal.m4'\n+  autoconf     touch file \\`configure'\n+  autoheader   touch file \\`config.h.in'\n+  automake     touch all \\`Makefile.in' files\n+  bison        create \\`y.tab.[ch]', if possible, from existing .[ch]\n+  flex         create \\`lex.yy.c', if possible, from existing .c\n+  help2man     touch the output file\n+  lex          create \\`lex.yy.c', if possible, from existing .c\n+  makeinfo     touch the output file\n+  tar          try tar, gnutar, gtar, then tar without non-portable flags\n+  yacc         create \\`y.tab.[ch]', if possible, from existing .[ch]\"\n+    ;;\n+\n+  -v|--v|--ve|--ver|--vers|--versi|--versio|--version)\n+    echo \"missing 0.4 - GNU automake\"\n+    ;;\n+\n+  -*)\n+    echo 1>&2 \"$0: Unknown \\`$1' option\"\n+    echo 1>&2 \"Try \\`$0 --help' for more information\"\n+    exit 1\n+    ;;\n+\n+  aclocal*)\n+    if test -z \"$run\" && ($1 --version) > /dev/null 2>&1; then\n+       # We have it, but it failed.\n+       exit 1\n+    fi\n+\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is missing on your system.  You should only need it if\n+         you modified \\`acinclude.m4' or \\`${configure_ac}'.  You might want\n+         to install the \\`Automake' and \\`Perl' packages.  Grab them from\n+         any GNU archive site.\"\n+    touch aclocal.m4\n+    ;;\n+\n+  autoconf)\n+    if test -z \"$run\" && ($1 --version) > /dev/null 2>&1; then\n+       # We have it, but it failed.\n+       exit 1\n+    fi\n+\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is missing on your system.  You should only need it if\n+         you modified \\`${configure_ac}'.  You might want to install the\n+         \\`Autoconf' and \\`GNU m4' packages.  Grab them from any GNU\n+         archive site.\"\n+    touch configure\n+    ;;\n+\n+  autoheader)\n+    if test -z \"$run\" && ($1 --version) > /dev/null 2>&1; then\n+       # We have it, but it failed.\n+       exit 1\n+    fi\n+\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is missing on your system.  You should only need it if\n+         you modified \\`acconfig.h' or \\`${configure_ac}'.  You might want\n+         to install the \\`Autoconf' and \\`GNU m4' packages.  Grab them\n+         from any GNU archive site.\"\n+    files=`sed -n 's/^[ ]*A[CM]_CONFIG_HEADER(\\([^)]*\\)).*/\\1/p' ${configure_ac}`\n+    test -z \"$files\" && files=\"config.h\"\n+    touch_files=\n+    for f in $files; do\n+      case \"$f\" in\n+      *:*) touch_files=\"$touch_files \"`echo \"$f\" |\n+\t\t\t\t       sed -e 's/^[^:]*://' -e 's/:.*//'`;;\n+      *) touch_files=\"$touch_files $f.in\";;\n+      esac\n+    done\n+    touch $touch_files\n+    ;;\n+\n+  automake*)\n+    if test -z \"$run\" && ($1 --version) > /dev/null 2>&1; then\n+       # We have it, but it failed.\n+       exit 1\n+    fi\n+\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is missing on your system.  You should only need it if\n+         you modified \\`Makefile.am', \\`acinclude.m4' or \\`${configure_ac}'.\n+         You might want to install the \\`Automake' and \\`Perl' packages.\n+         Grab them from any GNU archive site.\"\n+    find . -type f -name Makefile.am -print |\n+\t   sed 's/\\.am$/.in/' |\n+\t   while read f; do touch \"$f\"; done\n+    ;;\n+\n+  autom4te)\n+    if test -z \"$run\" && ($1 --version) > /dev/null 2>&1; then\n+       # We have it, but it failed.\n+       exit 1\n+    fi\n+\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is needed, and you do not seem to have it handy on your\n+         system.  You might have modified some files without having the\n+         proper tools for further handling them.\n+         You can get \\`$1Help2man' as part of \\`Autoconf' from any GNU\n+         archive site.\"\n+\n+    file=`echo \"$*\" | sed -n 's/.*--output[ =]*\\([^ ]*\\).*/\\1/p'`\n+    test -z \"$file\" && file=`echo \"$*\" | sed -n 's/.*-o[ ]*\\([^ ]*\\).*/\\1/p'`\n+    if test -f \"$file\"; then\n+\ttouch $file\n+    else\n+\ttest -z \"$file\" || exec >$file\n+\techo \"#! /bin/sh\"\n+\techo \"# Created by GNU Automake missing as a replacement of\"\n+\techo \"#  $ $@\"\n+\techo \"exit 0\"\n+\tchmod +x $file\n+\texit 1\n+    fi\n+    ;;\n+\n+  bison|yacc)\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is missing on your system.  You should only need it if\n+         you modified a \\`.y' file.  You may need the \\`Bison' package\n+         in order for those modifications to take effect.  You can get\n+         \\`Bison' from any GNU archive site.\"\n+    rm -f y.tab.c y.tab.h\n+    if [ $# -ne 1 ]; then\n+        eval LASTARG=\"\\${$#}\"\n+\tcase \"$LASTARG\" in\n+\t*.y)\n+\t    SRCFILE=`echo \"$LASTARG\" | sed 's/y$/c/'`\n+\t    if [ -f \"$SRCFILE\" ]; then\n+\t         cp \"$SRCFILE\" y.tab.c\n+\t    fi\n+\t    SRCFILE=`echo \"$LASTARG\" | sed 's/y$/h/'`\n+\t    if [ -f \"$SRCFILE\" ]; then\n+\t         cp \"$SRCFILE\" y.tab.h\n+\t    fi\n+\t  ;;\n+\tesac\n+    fi\n+    if [ ! -f y.tab.h ]; then\n+\techo >y.tab.h\n+    fi\n+    if [ ! -f y.tab.c ]; then\n+\techo 'main() { return 0; }' >y.tab.c\n+    fi\n+    ;;\n+\n+  lex|flex)\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is missing on your system.  You should only need it if\n+         you modified a \\`.l' file.  You may need the \\`Flex' package\n+         in order for those modifications to take effect.  You can get\n+         \\`Flex' from any GNU archive site.\"\n+    rm -f lex.yy.c\n+    if [ $# -ne 1 ]; then\n+        eval LASTARG=\"\\${$#}\"\n+\tcase \"$LASTARG\" in\n+\t*.l)\n+\t    SRCFILE=`echo \"$LASTARG\" | sed 's/l$/c/'`\n+\t    if [ -f \"$SRCFILE\" ]; then\n+\t         cp \"$SRCFILE\" lex.yy.c\n+\t    fi\n+\t  ;;\n+\tesac\n+    fi\n+    if [ ! -f lex.yy.c ]; then\n+\techo 'main() { return 0; }' >lex.yy.c\n+    fi\n+    ;;\n+\n+  help2man)\n+    if test -z \"$run\" && ($1 --version) > /dev/null 2>&1; then\n+       # We have it, but it failed.\n+       exit 1\n+    fi\n+\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is missing on your system.  You should only need it if\n+\t you modified a dependency of a manual page.  You may need the\n+\t \\`Help2man' package in order for those modifications to take\n+\t effect.  You can get \\`Help2man' from any GNU archive site.\"\n+\n+    file=`echo \"$*\" | sed -n 's/.*-o \\([^ ]*\\).*/\\1/p'`\n+    if test -z \"$file\"; then\n+\tfile=`echo \"$*\" | sed -n 's/.*--output=\\([^ ]*\\).*/\\1/p'`\n+    fi\n+    if [ -f \"$file\" ]; then\n+\ttouch $file\n+    else\n+\ttest -z \"$file\" || exec >$file\n+\techo \".ab help2man is required to generate this page\"\n+\texit 1\n+    fi\n+    ;;\n+\n+  makeinfo)\n+    if test -z \"$run\" && (makeinfo --version) > /dev/null 2>&1; then\n+       # We have makeinfo, but it failed.\n+       exit 1\n+    fi\n+\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is missing on your system.  You should only need it if\n+         you modified a \\`.texi' or \\`.texinfo' file, or any other file\n+         indirectly affecting the aspect of the manual.  The spurious\n+         call might also be the consequence of using a buggy \\`make' (AIX,\n+         DU, IRIX).  You might want to install the \\`Texinfo' package or\n+         the \\`GNU make' package.  Grab either from any GNU archive site.\"\n+    file=`echo \"$*\" | sed -n 's/.*-o \\([^ ]*\\).*/\\1/p'`\n+    if test -z \"$file\"; then\n+      file=`echo \"$*\" | sed 's/.* \\([^ ]*\\) *$/\\1/'`\n+      file=`sed -n '/^@setfilename/ { s/.* \\([^ ]*\\) *$/\\1/; p; q; }' $file`\n+    fi\n+    touch $file\n+    ;;\n+\n+  tar)\n+    shift\n+    if test -n \"$run\"; then\n+      echo 1>&2 \"ERROR: \\`tar' requires --run\"\n+      exit 1\n+    fi\n+\n+    # We have already tried tar in the generic part.\n+    # Look for gnutar/gtar before invocation to avoid ugly error\n+    # messages.\n+    if (gnutar --version > /dev/null 2>&1); then\n+       gnutar ${1+\"$@\"} && exit 0\n+    fi\n+    if (gtar --version > /dev/null 2>&1); then\n+       gtar ${1+\"$@\"} && exit 0\n+    fi\n+    firstarg=\"$1\"\n+    if shift; then\n+\tcase \"$firstarg\" in\n+\t*o*)\n+\t    firstarg=`echo \"$firstarg\" | sed s/o//`\n+\t    tar \"$firstarg\" ${1+\"$@\"} && exit 0\n+\t    ;;\n+\tesac\n+\tcase \"$firstarg\" in\n+\t*h*)\n+\t    firstarg=`echo \"$firstarg\" | sed s/h//`\n+\t    tar \"$firstarg\" ${1+\"$@\"} && exit 0\n+\t    ;;\n+\tesac\n+    fi\n+\n+    echo 1>&2 \"\\\n+WARNING: I can't seem to be able to run \\`tar' with the given arguments.\n+         You may want to install GNU tar or Free paxutils, or check the\n+         command line arguments.\"\n+    exit 1\n+    ;;\n+\n+  *)\n+    echo 1>&2 \"\\\n+WARNING: \\`$1' is needed, and you do not seem to have it handy on your\n+         system.  You might have modified some files without having the\n+         proper tools for further handling them.  Check the \\`README' file,\n+         it often tells you about the needed prerequirements for installing\n+         this package.  You may also peek at any GNU archive site, in case\n+         some other package would contain this missing \\`$1' program.\"\n+    exit 1\n+    ;;\n+esac\n+\n+exit 0"}, {"sha": "92f2c93ca8d7ead98539a97f5a688c0affa5537e", "filename": "boehm-gc/powerpc_darwin_mach_dep.s", "status": "added", "additions": 84, "deletions": 0, "changes": 84, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fpowerpc_darwin_mach_dep.s", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fpowerpc_darwin_mach_dep.s", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fpowerpc_darwin_mach_dep.s?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,84 @@\n+\n+; GC_push_regs function. Under some optimization levels GCC will clobber\n+; some of the non-volatile registers before we get a chance to save them\n+; therefore, this can't be inline asm.\n+\n+.text\n+\t.align 2\n+\t.globl _GC_push_regs\n+_GC_push_regs:\n+    \n+    ; Prolog\n+\tmflr r0\n+\tstw r0,8(r1)\n+\tstwu r1,-80(r1)\n+\n+\t; Push r13-r31\n+\tmr r3,r13\n+\tbl L_GC_push_one$stub\n+\tmr r3,r14\n+\tbl L_GC_push_one$stub\n+\tmr r3,r15\n+\tbl L_GC_push_one$stub\n+\tmr r3,r16\n+\tbl L_GC_push_one$stub\n+\tmr r3,r17\n+\tbl L_GC_push_one$stub\n+\tmr r3,r18\n+\tbl L_GC_push_one$stub\n+\tmr r3,r19\n+\tbl L_GC_push_one$stub\n+\tmr r3,r20\n+\tbl L_GC_push_one$stub\n+\tmr r3,r21\n+\tbl L_GC_push_one$stub\n+\tmr r3,r22\n+\tbl L_GC_push_one$stub\n+\tmr r3,r23\n+\tbl L_GC_push_one$stub\n+\tmr r3,r24\n+\tbl L_GC_push_one$stub\n+\tmr r3,r25\n+\tbl L_GC_push_one$stub\n+\tmr r3,r26\n+\tbl L_GC_push_one$stub\n+\tmr r3,r27\n+\tbl L_GC_push_one$stub\n+\tmr r3,r28\n+\tbl L_GC_push_one$stub\n+\tmr r3,r29\n+\tbl L_GC_push_one$stub\n+\tmr r3,r30\n+\tbl L_GC_push_one$stub\n+\tmr r3,r31\n+\tbl L_GC_push_one$stub\n+\n+    ; \n+    lwz r0,88(r1)\n+    addi r1,r1,80\n+\tmtlr r0\n+    \t\n+\t; Return\n+\tblr\n+\n+; PIC stuff, generated by GCC\n+\n+.data\n+.picsymbol_stub\n+L_GC_push_one$stub:\n+\t.indirect_symbol _GC_push_one\n+\tmflr r0\n+\tbcl 20,31,L0$_GC_push_one\n+L0$_GC_push_one:\n+\tmflr r11\n+\taddis r11,r11,ha16(L_GC_push_one$lazy_ptr-L0$_GC_push_one)\n+\tmtlr r0\n+\tlwz r12,lo16(L_GC_push_one$lazy_ptr-L0$_GC_push_one)(r11)\n+\tmtctr r12\n+\taddi r11,r11,lo16(L_GC_push_one$lazy_ptr-L0$_GC_push_one)\n+\tbctr\n+.data\n+.lazy_symbol_pointer\n+L_GC_push_one$lazy_ptr:\n+\t.indirect_symbol _GC_push_one\n+\t.long dyld_stub_binding_helper"}, {"sha": "5dfd26d319a3f54f6acf4c2f921583606ce34c30", "filename": "boehm-gc/pthread_stop_world.c", "status": "added", "additions": 445, "deletions": 0, "changes": 445, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fpthread_stop_world.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fpthread_stop_world.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fpthread_stop_world.c?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,445 @@\n+#include \"private/pthread_support.h\"\n+\n+#if defined(GC_PTHREADS) && !defined(GC_SOLARIS_THREADS) \\\n+     && !defined(GC_IRIX_THREADS) && !defined(GC_WIN32_THREADS) \\\n+     && !defined(GC_DARWIN_THREADS) && !defined(GC_AIX_THREADS)\n+\n+#include <signal.h>\n+#include <semaphore.h>\n+#include <errno.h>\n+#include <unistd.h>\n+\n+#if DEBUG_THREADS\n+\n+#ifndef NSIG\n+# if defined(MAXSIG)\n+#  define NSIG (MAXSIG+1)\n+# elif defined(_NSIG)\n+#  define NSIG _NSIG\n+# elif defined(__SIGRTMAX)\n+#  define NSIG (__SIGRTMAX+1)\n+# else\n+  --> please fix it\n+# endif\n+#endif\n+\n+void GC_print_sig_mask()\n+{\n+    sigset_t blocked;\n+    int i;\n+\n+    if (pthread_sigmask(SIG_BLOCK, NULL, &blocked) != 0)\n+    \tABORT(\"pthread_sigmask\");\n+    GC_printf0(\"Blocked: \");\n+    for (i = 1; i < NSIG; i++) {\n+        if (sigismember(&blocked, i)) { GC_printf1(\"%ld \",(long) i); }\n+    }\n+    GC_printf0(\"\\n\");\n+}\n+\n+#endif\n+\n+word GC_stop_count;\t/* Incremented at the beginning of GC_stop_world. */\n+\n+#ifdef GC_OSF1_THREADS\n+  GC_bool GC_retry_signals = TRUE;\n+#else\n+  GC_bool GC_retry_signals = FALSE;\n+#endif\n+\n+/*\n+ * We use signals to stop threads during GC.\n+ * \n+ * Suspended threads wait in signal handler for SIG_THR_RESTART.\n+ * That's more portable than semaphores or condition variables.\n+ * (We do use sem_post from a signal handler, but that should be portable.)\n+ *\n+ * The thread suspension signal SIG_SUSPEND is now defined in gc_priv.h.\n+ * Note that we can't just stop a thread; we need it to save its stack\n+ * pointer(s) and acknowledge.\n+ */\n+\n+#ifndef SIG_THR_RESTART\n+#  if defined(GC_HPUX_THREADS) || defined(GC_OSF1_THREADS)\n+#    ifdef _SIGRTMIN\n+#      define SIG_THR_RESTART _SIGRTMIN + 5\n+#    else\n+#      define SIG_THR_RESTART SIGRTMIN + 5\n+#    endif\n+#  else\n+#   define SIG_THR_RESTART SIGXCPU\n+#  endif\n+#endif\n+\n+sem_t GC_suspend_ack_sem;\n+\n+void GC_suspend_handler(int sig)\n+{\n+    int dummy;\n+    pthread_t my_thread = pthread_self();\n+    GC_thread me;\n+    sigset_t mask;\n+#   ifdef PARALLEL_MARK\n+\tword my_mark_no = GC_mark_no;\n+\t/* Marker can't proceed until we acknowledge.  Thus this is\t*/\n+\t/* guaranteed to be the mark_no correspending to our \t\t*/\n+\t/* suspension, i.e. the marker can't have incremented it yet.\t*/\n+#   endif\n+    word my_stop_count = GC_stop_count;\n+\n+    if (sig != SIG_SUSPEND) ABORT(\"Bad signal in suspend_handler\");\n+\n+#if DEBUG_THREADS\n+    GC_printf1(\"Suspending 0x%lx\\n\", my_thread);\n+#endif\n+\n+    me = GC_lookup_thread(my_thread);\n+    /* The lookup here is safe, since I'm doing this on behalf  */\n+    /* of a thread which holds the allocation lock in order\t*/\n+    /* to stop the world.  Thus concurrent modification of the\t*/\n+    /* data structure is impossible.\t\t\t\t*/\n+    if (me -> stop_info.last_stop_count == my_stop_count) {\n+\t/* Duplicate signal.  OK if we are retrying.\t*/\n+\tif (!GC_retry_signals) {\n+\t    WARN(\"Duplicate suspend signal in thread %lx\\n\",\n+\t\t pthread_self());\n+\t}\n+\treturn;\n+    }\n+#   ifdef SPARC\n+\tme -> stop_info.stack_ptr = (ptr_t)GC_save_regs_in_stack();\n+#   else\n+\tme -> stop_info.stack_ptr = (ptr_t)(&dummy);\n+#   endif\n+#   ifdef IA64\n+\tme -> backing_store_ptr = (ptr_t)GC_save_regs_in_stack();\n+#   endif\n+\n+    /* Tell the thread that wants to stop the world that this   */\n+    /* thread has been stopped.  Note that sem_post() is  \t*/\n+    /* the only async-signal-safe primitive in LinuxThreads.    */\n+    sem_post(&GC_suspend_ack_sem);\n+    me -> stop_info.last_stop_count = my_stop_count;\n+\n+    /* Wait until that thread tells us to restart by sending    */\n+    /* this thread a SIG_THR_RESTART signal.\t\t\t*/\n+    /* SIG_THR_RESTART should be masked at this point.  Thus there\t*/\n+    /* is no race.\t\t\t\t\t\t*/\n+    if (sigfillset(&mask) != 0) ABORT(\"sigfillset() failed\");\n+    if (sigdelset(&mask, SIG_THR_RESTART) != 0) ABORT(\"sigdelset() failed\");\n+#   ifdef NO_SIGNALS\n+      if (sigdelset(&mask, SIGINT) != 0) ABORT(\"sigdelset() failed\");\n+      if (sigdelset(&mask, SIGQUIT) != 0) ABORT(\"sigdelset() failed\");\n+      if (sigdelset(&mask, SIGTERM) != 0) ABORT(\"sigdelset() failed\");\n+      if (sigdelset(&mask, SIGABRT) != 0) ABORT(\"sigdelset() failed\");\n+#   endif\n+    do {\n+\t    me->stop_info.signal = 0;\n+\t    sigsuspend(&mask);             /* Wait for signal */\n+    } while (me->stop_info.signal != SIG_THR_RESTART);\n+    /* If the RESTART signal gets lost, we can still lose.  That should be  */\n+    /* less likely than losing the SUSPEND signal, since we don't do much   */\n+    /* between the sem_post and sigsuspend.\t   \t\t\t    */\n+    /* We'd need more handshaking to work around that, since we don't want  */\n+    /* to accidentally leave a RESTART signal pending, thus causing us to   */\n+    /* continue prematurely in a future round.\t\t\t\t    */ \n+\n+#if DEBUG_THREADS\n+    GC_printf1(\"Continuing 0x%lx\\n\", my_thread);\n+#endif\n+}\n+\n+void GC_restart_handler(int sig)\n+{\n+    pthread_t my_thread = pthread_self();\n+    GC_thread me;\n+\n+    if (sig != SIG_THR_RESTART) ABORT(\"Bad signal in suspend_handler\");\n+\n+    /* Let the GC_suspend_handler() know that we got a SIG_THR_RESTART. */\n+    /* The lookup here is safe, since I'm doing this on behalf  */\n+    /* of a thread which holds the allocation lock in order\t*/\n+    /* to stop the world.  Thus concurrent modification of the\t*/\n+    /* data structure is impossible.\t\t\t\t*/\n+    me = GC_lookup_thread(my_thread);\n+    me->stop_info.signal = SIG_THR_RESTART;\n+\n+    /*\n+    ** Note: even if we didn't do anything useful here,\n+    ** it would still be necessary to have a signal handler,\n+    ** rather than ignoring the signals, otherwise\n+    ** the signals will not be delivered at all, and\n+    ** will thus not interrupt the sigsuspend() above.\n+    */\n+\n+#if DEBUG_THREADS\n+    GC_printf1(\"In GC_restart_handler for 0x%lx\\n\", pthread_self());\n+#endif\n+}\n+\n+# ifdef IA64\n+#   define IF_IA64(x) x\n+# else\n+#   define IF_IA64(x)\n+# endif\n+/* We hold allocation lock.  Should do exactly the right thing if the\t*/\n+/* world is stopped.  Should not fail if it isn't.\t\t\t*/\n+void GC_push_all_stacks()\n+{\n+    int i;\n+    GC_thread p;\n+    ptr_t lo, hi;\n+    /* On IA64, we also need to scan the register backing store. */\n+    IF_IA64(ptr_t bs_lo; ptr_t bs_hi;)\n+    pthread_t me = pthread_self();\n+    \n+    if (!GC_thr_initialized) GC_thr_init();\n+    #if DEBUG_THREADS\n+        GC_printf1(\"Pushing stacks from thread 0x%lx\\n\", (unsigned long) me);\n+    #endif\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+        if (p -> flags & FINISHED) continue;\n+        if (pthread_equal(p -> id, me)) {\n+#  \t    ifdef SPARC\n+\t        lo = (ptr_t)GC_save_regs_in_stack();\n+#  \t    else\n+ \t        lo = GC_approx_sp();\n+#           endif\n+\t    IF_IA64(bs_hi = (ptr_t)GC_save_regs_in_stack();)\n+\t} else {\n+\t    lo = p -> stop_info.stack_ptr;\n+\t    IF_IA64(bs_hi = p -> backing_store_ptr;)\n+\t}\n+        if ((p -> flags & MAIN_THREAD) == 0) {\n+\t    hi = p -> stack_end;\n+\t    IF_IA64(bs_lo = p -> backing_store_end);\n+        } else {\n+            /* The original stack. */\n+            hi = GC_stackbottom;\n+\t    IF_IA64(bs_lo = BACKING_STORE_BASE;)\n+        }\n+        #if DEBUG_THREADS\n+            GC_printf3(\"Stack for thread 0x%lx = [%lx,%lx)\\n\",\n+    \t        (unsigned long) p -> id,\n+\t\t(unsigned long) lo, (unsigned long) hi);\n+        #endif\n+\tif (0 == lo) ABORT(\"GC_push_all_stacks: sp not set!\\n\");\n+#       ifdef STACK_GROWS_UP\n+\t  /* We got them backwards! */\n+          GC_push_all_stack(hi, lo);\n+#       else\n+          GC_push_all_stack(lo, hi);\n+#\tendif\n+#\tifdef IA64\n+          if (pthread_equal(p -> id, me)) {\n+\t    GC_push_all_eager(bs_lo, bs_hi);\n+\t  } else {\n+\t    GC_push_all_stack(bs_lo, bs_hi);\n+\t  }\n+#\tendif\n+      }\n+    }\n+}\n+\n+/* There seems to be a very rare thread stopping problem.  To help us  */\n+/* debug that, we save the ids of the stopping thread. */\n+pthread_t GC_stopping_thread;\n+int GC_stopping_pid;\n+\n+/* We hold the allocation lock.  Suspend all threads that might\t*/\n+/* still be running.  Return the number of suspend signals that\t*/\n+/* were sent. */\n+int GC_suspend_all()\n+{\n+    int n_live_threads = 0;\n+    int i;\n+    GC_thread p;\n+    int result;\n+    pthread_t my_thread = pthread_self();\n+    \n+    GC_stopping_thread = my_thread;    /* debugging only.      */\n+    GC_stopping_pid = getpid();                /* debugging only.      */\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+        if (p -> id != my_thread) {\n+            if (p -> flags & FINISHED) continue;\n+            if (p -> stop_info.last_stop_count == GC_stop_count) continue;\n+\t    if (p -> thread_blocked) /* Will wait */ continue;\n+            n_live_threads++;\n+\t    #if DEBUG_THREADS\n+\t      GC_printf1(\"Sending suspend signal to 0x%lx\\n\", p -> id);\n+\t    #endif\n+        \n+        result = pthread_kill(p -> id, SIG_SUSPEND);\n+\t    switch(result) {\n+                case ESRCH:\n+                    /* Not really there anymore.  Possible? */\n+                    n_live_threads--;\n+                    break;\n+                case 0:\n+                    break;\n+                default:\n+                    ABORT(\"pthread_kill failed\");\n+            }\n+        }\n+      }\n+    }\n+    return n_live_threads;\n+}\n+\n+/* Caller holds allocation lock.\t*/\n+void GC_stop_world()\n+{\n+    int i;\n+    int n_live_threads;\n+    int code;\n+\n+    #if DEBUG_THREADS\n+    GC_printf1(\"Stopping the world from 0x%lx\\n\", pthread_self());\n+    #endif\n+       \n+    /* Make sure all free list construction has stopped before we start. */\n+    /* No new construction can start, since free list construction is\t*/\n+    /* required to acquire and release the GC lock before it starts,\t*/\n+    /* and we have the lock.\t\t\t\t\t\t*/\n+#   ifdef PARALLEL_MARK\n+      GC_acquire_mark_lock();\n+      GC_ASSERT(GC_fl_builder_count == 0);\n+      /* We should have previously waited for it to become zero. */\n+#   endif /* PARALLEL_MARK */\n+    ++GC_stop_count;\n+    n_live_threads = GC_suspend_all();\n+\n+      if (GC_retry_signals) {\n+\t  unsigned long wait_usecs = 0;  /* Total wait since retry.\t*/\n+#\t  define WAIT_UNIT 3000\n+#\t  define RETRY_INTERVAL 100000\n+\t  for (;;) {\n+\t      int ack_count;\n+\n+\t      sem_getvalue(&GC_suspend_ack_sem, &ack_count);\n+\t      if (ack_count == n_live_threads) break;\n+\t      if (wait_usecs > RETRY_INTERVAL) {\n+\t\t  int newly_sent = GC_suspend_all();\n+\n+#                 ifdef CONDPRINT\n+\t\t    if (GC_print_stats) {\n+\t\t      GC_printf1(\"Resent %ld signals after timeout\\n\",\n+\t\t\t\t newly_sent);\n+\t\t    }\n+#                 endif\n+\t\t  sem_getvalue(&GC_suspend_ack_sem, &ack_count);\n+\t\t  if (newly_sent < n_live_threads - ack_count) {\n+\t\t      WARN(\"Lost some threads during GC_stop_world?!\\n\",0);\n+\t\t      n_live_threads = ack_count + newly_sent;\n+\t\t  }\n+\t\t  wait_usecs = 0;\n+\t      }\n+\t      usleep(WAIT_UNIT);\n+\t      wait_usecs += WAIT_UNIT;\n+\t  }\n+      }\n+    for (i = 0; i < n_live_threads; i++) {\n+\t  if (0 != (code = sem_wait(&GC_suspend_ack_sem))) {\n+\t      GC_err_printf1(\"Sem_wait returned %ld\\n\", (unsigned long)code);\n+\t      ABORT(\"sem_wait for handler failed\");\n+\t  }\n+    }\n+#   ifdef PARALLEL_MARK\n+      GC_release_mark_lock();\n+#   endif\n+    #if DEBUG_THREADS\n+      GC_printf1(\"World stopped from 0x%lx\\n\", pthread_self());\n+    #endif\n+    GC_stopping_thread = 0;  /* debugging only */\n+}\n+\n+/* Caller holds allocation lock, and has held it continuously since\t*/\n+/* the world stopped.\t\t\t\t\t\t\t*/\n+void GC_start_world()\n+{\n+    pthread_t my_thread = pthread_self();\n+    register int i;\n+    register GC_thread p;\n+    register int n_live_threads = 0;\n+    register int result;\n+\n+#   if DEBUG_THREADS\n+      GC_printf0(\"World starting\\n\");\n+#   endif\n+\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+        if (p -> id != my_thread) {\n+            if (p -> flags & FINISHED) continue;\n+\t    if (p -> thread_blocked) continue;\n+            n_live_threads++;\n+\t    #if DEBUG_THREADS\n+\t      GC_printf1(\"Sending restart signal to 0x%lx\\n\", p -> id);\n+\t    #endif\n+        \n+        result = pthread_kill(p -> id, SIG_THR_RESTART);\n+\t    switch(result) {\n+                case ESRCH:\n+                    /* Not really there anymore.  Possible? */\n+                    n_live_threads--;\n+                    break;\n+                case 0:\n+                    break;\n+                default:\n+                    ABORT(\"pthread_kill failed\");\n+            }\n+        }\n+      }\n+    }\n+    #if DEBUG_THREADS\n+      GC_printf0(\"World started\\n\");\n+    #endif\n+}\n+\n+void GC_stop_init() {\n+    struct sigaction act;\n+    \n+    if (sem_init(&GC_suspend_ack_sem, 0, 0) != 0)\n+        ABORT(\"sem_init failed\");\n+\n+    act.sa_flags = SA_RESTART;\n+    if (sigfillset(&act.sa_mask) != 0) {\n+    \tABORT(\"sigfillset() failed\");\n+    }\n+#   ifdef NO_SIGNALS\n+      if (sigdelset(&act.sa_mask, SIGINT) != 0\n+\t  || sigdelset(&act.sa_mask, SIGQUIT != 0)\n+\t  || sigdelset(&act.sa_mask, SIGABRT != 0)\n+\t  || sigdelset(&act.sa_mask, SIGTERM != 0)) {\n+        ABORT(\"sigdelset() failed\");\n+      }\n+#   endif\n+\n+    /* SIG_THR_RESTART is unmasked by the handler when necessary. \t*/\n+    act.sa_handler = GC_suspend_handler;\n+    if (sigaction(SIG_SUSPEND, &act, NULL) != 0) {\n+    \tABORT(\"Cannot set SIG_SUSPEND handler\");\n+    }\n+\n+    act.sa_handler = GC_restart_handler;\n+    if (sigaction(SIG_THR_RESTART, &act, NULL) != 0) {\n+    \tABORT(\"Cannot set SIG_THR_RESTART handler\");\n+    }\n+\n+    /* Check for GC_RETRY_SIGNALS.\t*/\n+      if (0 != GETENV(\"GC_RETRY_SIGNALS\")) {\n+\t  GC_retry_signals = TRUE;\n+      }\n+      if (0 != GETENV(\"GC_NO_RETRY_SIGNALS\")) {\n+\t  GC_retry_signals = FALSE;\n+      }\n+#     ifdef CONDPRINT\n+          if (GC_print_stats && GC_retry_signals) {\n+              GC_printf0(\"Will retry suspend signal if necessary.\\n\");\n+\t  }\n+#     endif\n+}\n+\n+#endif"}, {"sha": "b302817bfdf46a4efa74d834d1f9947d66543058", "filename": "boehm-gc/pthread_support.c", "status": "added", "additions": 1570, "deletions": 0, "changes": 1570, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fpthread_support.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6991c6c926a5909c438c0ea92d98175b41014598/boehm-gc%2Fpthread_support.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Fpthread_support.c?ref=6991c6c926a5909c438c0ea92d98175b41014598", "patch": "@@ -0,0 +1,1570 @@\n+/* \n+ * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.\n+ * Copyright (c) 1996 by Silicon Graphics.  All rights reserved.\n+ * Copyright (c) 1998 by Fergus Henderson.  All rights reserved.\n+ * Copyright (c) 2000-2001 by Hewlett-Packard Company.  All rights reserved.\n+ *\n+ * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY EXPRESSED\n+ * OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.\n+ *\n+ * Permission is hereby granted to use or copy this program\n+ * for any purpose,  provided the above notices are retained on all copies.\n+ * Permission to modify the code and to distribute modified code is granted,\n+ * provided the above notices are retained, and a notice that the code was\n+ * modified is included with the above copyright notice.\n+ */\n+/*\n+ * Support code for LinuxThreads, the clone()-based kernel\n+ * thread package for Linux which is included in libc6.\n+ *\n+ * This code relies on implementation details of LinuxThreads,\n+ * (i.e. properties not guaranteed by the Pthread standard),\n+ * though this version now does less of that than the other Pthreads\n+ * support code.\n+ *\n+ * Note that there is a lot of code duplication between linux_threads.c\n+ * and thread support for some of the other Posix platforms; any changes\n+ * made here may need to be reflected there too.\n+ */\n+ /* DG/UX ix86 support <takis@xfree86.org> */\n+/*\n+ * Linux_threads.c now also includes some code to support HPUX and\n+ * OSF1 (Compaq Tru64 Unix, really).  The OSF1 support is based on Eric Benson's\n+ * patch.\n+ *\n+ * Eric also suggested an alternate basis for a lock implementation in\n+ * his code:\n+ * + #elif defined(OSF1)\n+ * +    unsigned long GC_allocate_lock = 0;\n+ * +    msemaphore GC_allocate_semaphore;\n+ * + #  define GC_TRY_LOCK() \\\n+ * +    ((msem_lock(&GC_allocate_semaphore, MSEM_IF_NOWAIT) == 0) \\\n+ * +     ? (GC_allocate_lock = 1) \\\n+ * +     : 0)\n+ * + #  define GC_LOCK_TAKEN GC_allocate_lock\n+ */\n+\n+/*#define DEBUG_THREADS 1*/\n+/*#define GC_ASSERTIONS*/\n+\n+# include \"private/pthread_support.h\"\n+\n+# if defined(GC_PTHREADS) && !defined(GC_SOLARIS_THREADS) \\\n+     && !defined(GC_IRIX_THREADS) && !defined(GC_WIN32_THREADS) \\\n+     && !defined(GC_AIX_THREADS)\n+\n+# if defined(GC_HPUX_THREADS) && !defined(USE_PTHREAD_SPECIFIC) \\\n+     && !defined(USE_HPUX_TLS)\n+#   define USE_HPUX_TLS\n+# endif\n+\n+# if (defined(GC_DGUX386_THREADS) || defined(GC_OSF1_THREADS) || \\\n+      defined(GC_DARWIN_THREADS)) && !defined(USE_PTHREAD_SPECIFIC)\n+#   define USE_PTHREAD_SPECIFIC\n+# endif\n+\n+# if defined(GC_DGUX386_THREADS) && !defined(_POSIX4A_DRAFT10_SOURCE)\n+#   define _POSIX4A_DRAFT10_SOURCE 1\n+# endif\n+\n+# if defined(GC_DGUX386_THREADS) && !defined(_USING_POSIX4A_DRAFT10)\n+#   define _USING_POSIX4A_DRAFT10 1\n+# endif\n+\n+# ifdef THREAD_LOCAL_ALLOC\n+#   if !defined(USE_PTHREAD_SPECIFIC) && !defined(USE_HPUX_TLS)\n+#     include \"private/specific.h\"\n+#   endif\n+#   if defined(USE_PTHREAD_SPECIFIC)\n+#     define GC_getspecific pthread_getspecific\n+#     define GC_setspecific pthread_setspecific\n+#     define GC_key_create pthread_key_create\n+      typedef pthread_key_t GC_key_t;\n+#   endif\n+#   if defined(USE_HPUX_TLS)\n+#     define GC_getspecific(x) (x)\n+#     define GC_setspecific(key, v) ((key) = (v), 0)\n+#     define GC_key_create(key, d) 0\n+      typedef void * GC_key_t;\n+#   endif\n+# endif\n+# include <stdlib.h>\n+# include <pthread.h>\n+# include <sched.h>\n+# include <time.h>\n+# include <errno.h>\n+# include <unistd.h>\n+# include <sys/mman.h>\n+# include <sys/time.h>\n+# include <sys/types.h>\n+# include <sys/stat.h>\n+# include <fcntl.h>\n+\n+#if defined(GC_DARWIN_THREADS)\n+# include \"private/darwin_semaphore.h\"\n+#else\n+# include <semaphore.h>\n+#endif /* !GC_DARWIN_THREADS */\n+\n+#if defined(GC_DARWIN_THREADS)\n+# include <sys/sysctl.h>\n+#endif /* GC_DARWIN_THREADS */\n+\n+\n+\n+#if defined(GC_DGUX386_THREADS)\n+# include <sys/dg_sys_info.h>\n+# include <sys/_int_psem.h>\n+  /* sem_t is an uint in DG/UX */\n+  typedef unsigned int  sem_t;\n+#endif /* GC_DGUX386_THREADS */\n+\n+#ifndef __GNUC__\n+#   define __inline__\n+#endif\n+\n+#ifdef GC_USE_LD_WRAP\n+#   define WRAP_FUNC(f) __wrap_##f\n+#   define REAL_FUNC(f) __real_##f\n+#else\n+#   define WRAP_FUNC(f) GC_##f\n+#   if !defined(GC_DGUX386_THREADS)\n+#     define REAL_FUNC(f) f\n+#   else /* GC_DGUX386_THREADS */\n+#     define REAL_FUNC(f) __d10_##f\n+#   endif /* GC_DGUX386_THREADS */\n+#   undef pthread_create\n+#   if !defined(GC_DARWIN_THREADS)\n+#     undef pthread_sigmask\n+#   endif\n+#   undef pthread_join\n+#   undef pthread_detach\n+#   if defined(GC_OSF1_THREADS) && defined(_PTHREAD_USE_MANGLED_NAMES_) \\\n+       && !defined(_PTHREAD_USE_PTDNAM_)\n+/* Restore the original mangled names on Tru64 UNIX.  */\n+#     define pthread_create __pthread_create\n+#     define pthread_join __pthread_join\n+#     define pthread_detach __pthread_detach\n+#   endif\n+#endif\n+\n+void GC_thr_init();\n+\n+static GC_bool parallel_initialized = FALSE;\n+\n+void GC_init_parallel();\n+\n+# if defined(THREAD_LOCAL_ALLOC) && !defined(DBG_HDRS_ALL)\n+\n+/* We don't really support thread-local allocation with DBG_HDRS_ALL */\n+\n+#ifdef USE_HPUX_TLS\n+  __thread\n+#endif\n+GC_key_t GC_thread_key;\n+\n+static GC_bool keys_initialized;\n+\n+/* Recover the contents of the freelist array fl into the global one gfl.*/\n+/* Note that the indexing scheme differs, in that gfl has finer size\t*/\n+/* resolution, even if not all entries are used.\t\t\t*/\n+/* We hold the allocator lock.\t\t\t\t\t\t*/\n+static void return_freelists(ptr_t *fl, ptr_t *gfl)\n+{\n+    int i;\n+    ptr_t q, *qptr;\n+    size_t nwords;\n+\n+    for (i = 1; i < NFREELISTS; ++i) {\n+\tnwords = i * (GRANULARITY/sizeof(word));\n+        qptr = fl + i;\t\n+\tq = *qptr;\n+\tif ((word)q >= HBLKSIZE) {\n+\t  if (gfl[nwords] == 0) {\n+\t    gfl[nwords] = q;\n+\t  } else {\n+\t    /* Concatenate: */\n+\t    for (; (word)q >= HBLKSIZE; qptr = &(obj_link(q)), q = *qptr);\n+\t    GC_ASSERT(0 == q);\n+\t    *qptr = gfl[nwords];\n+\t    gfl[nwords] = fl[i];\n+\t  }\n+\t}\n+\t/* Clear fl[i], since the thread structure may hang around.\t*/\n+\t/* Do it in a way that is likely to trap if we access it.\t*/\n+\tfl[i] = (ptr_t)HBLKSIZE;\n+    }\n+}\n+\n+/* We statically allocate a single \"size 0\" object. It is linked to\t*/\n+/* itself, and is thus repeatedly reused for all size 0 allocation\t*/\n+/* requests.  (Size 0 gcj allocation requests are incorrect, and\t*/\n+/* we arrange for those to fault asap.)\t\t\t\t\t*/\n+static ptr_t size_zero_object = (ptr_t)(&size_zero_object);\n+\n+/* Each thread structure must be initialized.\t*/\n+/* This call must be made from the new thread.\t*/\n+/* Caller holds allocation lock.\t\t*/\n+void GC_init_thread_local(GC_thread p)\n+{\n+    int i;\n+\n+    if (!keys_initialized) {\n+\tif (0 != GC_key_create(&GC_thread_key, 0)) {\n+\t    ABORT(\"Failed to create key for local allocator\");\n+        }\n+\tkeys_initialized = TRUE;\n+    }\n+    if (0 != GC_setspecific(GC_thread_key, p)) {\n+\tABORT(\"Failed to set thread specific allocation pointers\");\n+    }\n+    for (i = 1; i < NFREELISTS; ++i) {\n+\tp -> ptrfree_freelists[i] = (ptr_t)1;\n+\tp -> normal_freelists[i] = (ptr_t)1;\n+#\tifdef GC_GCJ_SUPPORT\n+\t  p -> gcj_freelists[i] = (ptr_t)1;\n+#\tendif\n+    }   \n+    /* Set up the size 0 free lists.\t*/\n+    p -> ptrfree_freelists[0] = (ptr_t)(&size_zero_object);\n+    p -> normal_freelists[0] = (ptr_t)(&size_zero_object);\n+#   ifdef GC_GCJ_SUPPORT\n+        p -> gcj_freelists[0] = (ptr_t)(-1);\n+#   endif\n+}\n+\n+#ifdef GC_GCJ_SUPPORT\n+  extern ptr_t * GC_gcjobjfreelist;\n+#endif\n+\n+/* We hold the allocator lock.\t*/\n+void GC_destroy_thread_local(GC_thread p)\n+{\n+    /* We currently only do this from the thread itself or from\t*/\n+    /* the fork handler for a child process.\t\t\t*/\n+#   ifndef HANDLE_FORK\n+      GC_ASSERT(GC_getspecific(GC_thread_key) == (void *)p);\n+#   endif\n+    return_freelists(p -> ptrfree_freelists, GC_aobjfreelist);\n+    return_freelists(p -> normal_freelists, GC_objfreelist);\n+#   ifdef GC_GCJ_SUPPORT\n+   \treturn_freelists(p -> gcj_freelists, GC_gcjobjfreelist);\n+#   endif\n+}\n+\n+extern GC_PTR GC_generic_malloc_many();\n+\n+GC_PTR GC_local_malloc(size_t bytes)\n+{\n+    if (EXPECT(!SMALL_ENOUGH(bytes),0)) {\n+        return(GC_malloc(bytes));\n+    } else {\n+\tint index = INDEX_FROM_BYTES(bytes);\n+\tptr_t * my_fl;\n+\tptr_t my_entry;\n+#\tif defined(REDIRECT_MALLOC) && !defined(USE_PTHREAD_SPECIFIC)\n+\tGC_key_t k = GC_thread_key;\n+#\tendif\n+\tvoid * tsd;\n+\n+#\tif defined(REDIRECT_MALLOC) && !defined(USE_PTHREAD_SPECIFIC)\n+\t    if (EXPECT(0 == k, 0)) {\n+\t\t/* This can happen if we get called when the world is\t*/\n+\t\t/* being initialized.  Whether we can actually complete\t*/\n+\t\t/* the initialization then is unclear.\t\t\t*/\n+\t\tGC_init_parallel();\n+\t\tk = GC_thread_key;\n+\t    }\n+#\tendif\n+\ttsd = GC_getspecific(GC_thread_key);\n+#\tifdef GC_ASSERTIONS\n+\t  LOCK();\n+\t  GC_ASSERT(tsd == (void *)GC_lookup_thread(pthread_self()));\n+\t  UNLOCK();\n+#\tendif\n+\tmy_fl = ((GC_thread)tsd) -> normal_freelists + index;\n+\tmy_entry = *my_fl;\n+\tif (EXPECT((word)my_entry >= HBLKSIZE, 1)) {\n+\t    ptr_t next = obj_link(my_entry);\n+\t    GC_PTR result = (GC_PTR)my_entry;\n+\t    *my_fl = next;\n+\t    obj_link(my_entry) = 0;\n+\t    PREFETCH_FOR_WRITE(next);\n+\t    return result;\n+\t} else if ((word)my_entry - 1 < DIRECT_GRANULES) {\n+\t    *my_fl = my_entry + index + 1;\n+            return GC_malloc(bytes);\n+\t} else {\n+\t    GC_generic_malloc_many(BYTES_FROM_INDEX(index), NORMAL, my_fl);\n+\t    if (*my_fl == 0) return GC_oom_fn(bytes);\n+\t    return GC_local_malloc(bytes);\n+\t}\n+    }\n+}\n+\n+GC_PTR GC_local_malloc_atomic(size_t bytes)\n+{\n+    if (EXPECT(!SMALL_ENOUGH(bytes), 0)) {\n+        return(GC_malloc_atomic(bytes));\n+    } else {\n+\tint index = INDEX_FROM_BYTES(bytes);\n+\tptr_t * my_fl = ((GC_thread)GC_getspecific(GC_thread_key))\n+\t\t        -> ptrfree_freelists + index;\n+\tptr_t my_entry = *my_fl;\n+    \n+\tif (EXPECT((word)my_entry >= HBLKSIZE, 1)) {\n+\t    GC_PTR result = (GC_PTR)my_entry;\n+\t    *my_fl = obj_link(my_entry);\n+\t    return result;\n+\t} else if ((word)my_entry - 1 < DIRECT_GRANULES) {\n+\t    *my_fl = my_entry + index + 1;\n+        return GC_malloc_atomic(bytes);\n+\t} else {\n+\t    GC_generic_malloc_many(BYTES_FROM_INDEX(index), PTRFREE, my_fl);\n+\t    /* *my_fl is updated while the collector is excluded;\t*/\n+\t    /* the free list is always visible to the collector as \t*/\n+\t    /* such.\t\t\t\t\t\t\t*/\n+\t    if (*my_fl == 0) return GC_oom_fn(bytes);\n+\t    return GC_local_malloc_atomic(bytes);\n+\t}\n+    }\n+}\n+\n+#ifdef GC_GCJ_SUPPORT\n+\n+#include \"include/gc_gcj.h\"\n+\n+#ifdef GC_ASSERTIONS\n+  extern GC_bool GC_gcj_malloc_initialized;\n+#endif\n+\n+extern int GC_gcj_kind;\n+\n+GC_PTR GC_local_gcj_malloc(size_t bytes,\n+\t\t\t   void * ptr_to_struct_containing_descr)\n+{\n+    GC_ASSERT(GC_gcj_malloc_initialized);\n+    if (EXPECT(!SMALL_ENOUGH(bytes), 0)) {\n+        return GC_gcj_malloc(bytes, ptr_to_struct_containing_descr);\n+    } else {\n+\tint index = INDEX_FROM_BYTES(bytes);\n+\tptr_t * my_fl = ((GC_thread)GC_getspecific(GC_thread_key))\n+\t                -> gcj_freelists + index;\n+\tptr_t my_entry = *my_fl;\n+\tif (EXPECT((word)my_entry >= HBLKSIZE, 1)) {\n+\t    GC_PTR result = (GC_PTR)my_entry;\n+\t    GC_ASSERT(!GC_incremental);\n+\t    /* We assert that any concurrent marker will stop us.\t*/\n+\t    /* Thus it is impossible for a mark procedure to see the \t*/\n+\t    /* allocation of the next object, but to see this object \t*/\n+\t    /* still containing a free list pointer.  Otherwise the \t*/\n+\t    /* marker might find a random \"mark descriptor\".\t\t*/\n+\t    *(volatile ptr_t *)my_fl = obj_link(my_entry);\n+\t    /* We must update the freelist before we store the pointer.\t*/\n+\t    /* Otherwise a GC at this point would see a corrupted\t*/\n+\t    /* free list.\t\t\t\t\t\t*/\n+\t    /* A memory barrier is probably never needed, since the \t*/\n+\t    /* action of stopping this thread will cause prior writes\t*/\n+\t    /* to complete.\t\t\t\t\t\t*/\n+\t    GC_ASSERT(((void * volatile *)result)[1] == 0); \n+\t    *(void * volatile *)result = ptr_to_struct_containing_descr; \n+\t    return result;\n+\t} else if ((word)my_entry - 1 < DIRECT_GRANULES) {\n+\t    if (!GC_incremental) *my_fl = my_entry + index + 1;\n+\t    \t/* In the incremental case, we always have to take this */\n+\t    \t/* path.  Thus we leave the counter alone.\t\t*/\n+            return GC_gcj_malloc(bytes, ptr_to_struct_containing_descr);\n+\t} else {\n+\t    GC_generic_malloc_many(BYTES_FROM_INDEX(index), GC_gcj_kind, my_fl);\n+\t    if (*my_fl == 0) return GC_oom_fn(bytes);\n+\t    return GC_local_gcj_malloc(bytes, ptr_to_struct_containing_descr);\n+\t}\n+    }\n+}\n+\n+#endif /* GC_GCJ_SUPPORT */\n+\n+# else  /* !THREAD_LOCAL_ALLOC  && !DBG_HDRS_ALL */\n+\n+#   define GC_destroy_thread_local(t)\n+\n+# endif /* !THREAD_LOCAL_ALLOC */\n+\n+#if 0\n+/*\n+To make sure that we're using LinuxThreads and not some other thread\n+package, we generate a dummy reference to `pthread_kill_other_threads_np'\n+(was `__pthread_initial_thread_bos' but that disappeared),\n+which is a symbol defined in LinuxThreads, but (hopefully) not in other\n+thread packages.\n+\n+We no longer do this, since this code is now portable enough that it might\n+actually work for something else.\n+*/\n+void (*dummy_var_to_force_linux_threads)() = pthread_kill_other_threads_np;\n+#endif /* 0 */\n+\n+long GC_nprocs = 1;\t/* Number of processors.  We may not have\t*/\n+\t\t\t/* access to all of them, but this is as good\t*/\n+\t\t\t/* a guess as any ...\t\t\t\t*/\n+\n+#ifdef PARALLEL_MARK\n+\n+# ifndef MAX_MARKERS\n+#   define MAX_MARKERS 16\n+# endif\n+\n+static ptr_t marker_sp[MAX_MARKERS] = {0};\n+\n+void * GC_mark_thread(void * id)\n+{\n+  word my_mark_no = 0;\n+\n+  marker_sp[(word)id] = GC_approx_sp();\n+  for (;; ++my_mark_no) {\n+    /* GC_mark_no is passed only to allow GC_help_marker to terminate\t*/\n+    /* promptly.  This is important if it were called from the signal\t*/\n+    /* handler or from the GC lock acquisition code.  Under Linux, it's\t*/\n+    /* not safe to call it from a signal handler, since it uses mutexes\t*/\n+    /* and condition variables.  Since it is called only here, the \t*/\n+    /* argument is unnecessary.\t\t\t\t\t\t*/\n+    if (my_mark_no < GC_mark_no || my_mark_no > GC_mark_no + 2) {\n+\t/* resynchronize if we get far off, e.g. because GC_mark_no\t*/\n+\t/* wrapped.\t\t\t\t\t\t\t*/\n+\tmy_mark_no = GC_mark_no;\n+    }\n+#   ifdef DEBUG_THREADS\n+\tGC_printf1(\"Starting mark helper for mark number %ld\\n\", my_mark_no);\n+#   endif\n+    GC_help_marker(my_mark_no);\n+  }\n+}\n+\n+extern long GC_markers;\t\t/* Number of mark threads we would\t*/\n+\t\t\t\t/* like to have.  Includes the \t\t*/\n+\t\t\t\t/* initiating thread.\t\t\t*/\n+\n+pthread_t GC_mark_threads[MAX_MARKERS];\n+\n+#define PTHREAD_CREATE REAL_FUNC(pthread_create)\n+\n+static void start_mark_threads()\n+{\n+    unsigned i;\n+    pthread_attr_t attr;\n+\n+    if (GC_markers > MAX_MARKERS) {\n+\tWARN(\"Limiting number of mark threads\\n\", 0);\n+\tGC_markers = MAX_MARKERS;\n+    }\n+    if (0 != pthread_attr_init(&attr)) ABORT(\"pthread_attr_init failed\");\n+\t\n+    if (0 != pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED))\n+\tABORT(\"pthread_attr_setdetachstate failed\");\n+\n+#   if defined(HPUX) || defined(GC_DGUX386_THREADS)\n+      /* Default stack size is usually too small: fix it. */\n+      /* Otherwise marker threads or GC may run out of\t  */\n+      /* space.\t\t\t\t\t\t  */\n+#     define MIN_STACK_SIZE (8*HBLKSIZE*sizeof(word))\n+      {\n+\tsize_t old_size;\n+\tint code;\n+\n+        if (pthread_attr_getstacksize(&attr, &old_size) != 0)\n+\t  ABORT(\"pthread_attr_getstacksize failed\\n\");\n+\tif (old_size < MIN_STACK_SIZE) {\n+\t  if (pthread_attr_setstacksize(&attr, MIN_STACK_SIZE) != 0)\n+\t\t  ABORT(\"pthread_attr_setstacksize failed\\n\");\n+\t}\n+      }\n+#   endif /* HPUX || GC_DGUX386_THREADS */\n+#   ifdef CONDPRINT\n+      if (GC_print_stats) {\n+\tGC_printf1(\"Starting %ld marker threads\\n\", GC_markers - 1);\n+      }\n+#   endif\n+    for (i = 0; i < GC_markers - 1; ++i) {\n+      if (0 != PTHREAD_CREATE(GC_mark_threads + i, &attr,\n+\t\t\t      GC_mark_thread, (void *)(word)i)) {\n+\tWARN(\"Marker thread creation failed, errno = %ld.\\n\", errno);\n+      }\n+    }\n+}\n+\n+#else  /* !PARALLEL_MARK */\n+\n+static __inline__ void start_mark_threads()\n+{\n+}\n+\n+#endif /* !PARALLEL_MARK */\n+\n+/* Defining INSTALL_LOOPING_SEGV_HANDLER causes SIGSEGV and SIGBUS to \t*/\n+/* result in an infinite loop in a signal handler.  This can be very\t*/\n+/* useful for debugging, since (as of RH7) gdb still seems to have\t*/\n+/* serious problems with threads.\t\t\t\t\t*/\n+#ifdef INSTALL_LOOPING_SEGV_HANDLER\n+void GC_looping_handler(int sig)\n+{\n+    GC_printf3(\"Signal %ld in thread %lx, pid %ld\\n\",\n+\t       sig, pthread_self(), getpid());\n+    for (;;);\n+}\n+#endif\n+\n+GC_bool GC_thr_initialized = FALSE;\n+\n+volatile GC_thread GC_threads[THREAD_TABLE_SZ];\n+\n+void GC_push_thread_structures GC_PROTO((void))\n+{\n+    GC_push_all((ptr_t)(GC_threads), (ptr_t)(GC_threads)+sizeof(GC_threads));\n+#   if defined(THREAD_LOCAL_ALLOC) && !defined(DBG_HDRS_ALL)\n+      GC_push_all((ptr_t)(&GC_thread_key),\n+\t  (ptr_t)(&GC_thread_key)+sizeof(&GC_thread_key));\n+#   endif\n+}\n+\n+#ifdef THREAD_LOCAL_ALLOC\n+/* We must explicitly mark ptrfree and gcj free lists, since the free \t*/\n+/* list links wouldn't otherwise be found.  We also set them in the \t*/\n+/* normal free lists, since that involves touching less memory than if\t*/\n+/* we scanned them normally.\t\t\t\t\t\t*/\n+void GC_mark_thread_local_free_lists(void)\n+{\n+    int i, j;\n+    GC_thread p;\n+    ptr_t q;\n+    \n+    for (i = 0; i < THREAD_TABLE_SZ; ++i) {\n+      for (p = GC_threads[i]; 0 != p; p = p -> next) {\n+\tfor (j = 1; j < NFREELISTS; ++j) {\n+\t  q = p -> ptrfree_freelists[j];\n+\t  if ((word)q > HBLKSIZE) GC_set_fl_marks(q);\n+\t  q = p -> normal_freelists[j];\n+\t  if ((word)q > HBLKSIZE) GC_set_fl_marks(q);\n+#\t  ifdef GC_GCJ_SUPPORT\n+\t    q = p -> gcj_freelists[j];\n+\t    if ((word)q > HBLKSIZE) GC_set_fl_marks(q);\n+#\t  endif /* GC_GCJ_SUPPORT */\n+\t}\n+      }\n+    }\n+}\n+#endif /* THREAD_LOCAL_ALLOC */\n+\n+static struct GC_Thread_Rep first_thread;\n+\n+/* Add a thread to GC_threads.  We assume it wasn't already there.\t*/\n+/* Caller holds allocation lock.\t\t\t\t\t*/\n+GC_thread GC_new_thread(pthread_t id)\n+{\n+    int hv = ((word)id) % THREAD_TABLE_SZ;\n+    GC_thread result;\n+    static GC_bool first_thread_used = FALSE;\n+    \n+    if (!first_thread_used) {\n+    \tresult = &first_thread;\n+    \tfirst_thread_used = TRUE;\n+    } else {\n+        result = (struct GC_Thread_Rep *)\n+        \t GC_INTERNAL_MALLOC(sizeof(struct GC_Thread_Rep), NORMAL);\n+    }\n+    if (result == 0) return(0);\n+    result -> id = id;\n+    result -> next = GC_threads[hv];\n+    GC_threads[hv] = result;\n+    GC_ASSERT(result -> flags == 0 && result -> thread_blocked == 0);\n+    return(result);\n+}\n+\n+/* Delete a thread from GC_threads.  We assume it is there.\t*/\n+/* (The code intentionally traps if it wasn't.)\t\t\t*/\n+/* Caller holds allocation lock.\t\t\t\t*/\n+void GC_delete_thread(pthread_t id)\n+{\n+    int hv = ((word)id) % THREAD_TABLE_SZ;\n+    register GC_thread p = GC_threads[hv];\n+    register GC_thread prev = 0;\n+    \n+    while (!pthread_equal(p -> id, id)) {\n+        prev = p;\n+        p = p -> next;\n+    }\n+    if (prev == 0) {\n+        GC_threads[hv] = p -> next;\n+    } else {\n+        prev -> next = p -> next;\n+    }\n+    GC_INTERNAL_FREE(p);\n+}\n+\n+/* If a thread has been joined, but we have not yet\t\t*/\n+/* been notified, then there may be more than one thread \t*/\n+/* in the table with the same pthread id.\t\t\t*/\n+/* This is OK, but we need a way to delete a specific one.\t*/\n+void GC_delete_gc_thread(pthread_t id, GC_thread gc_id)\n+{\n+    int hv = ((word)id) % THREAD_TABLE_SZ;\n+    register GC_thread p = GC_threads[hv];\n+    register GC_thread prev = 0;\n+\n+    while (p != gc_id) {\n+        prev = p;\n+        p = p -> next;\n+    }\n+    if (prev == 0) {\n+        GC_threads[hv] = p -> next;\n+    } else {\n+        prev -> next = p -> next;\n+    }\n+    GC_INTERNAL_FREE(p);\n+}\n+\n+/* Return a GC_thread corresponding to a given thread_t.\t*/\n+/* Returns 0 if it's not there.\t\t\t\t\t*/\n+/* Caller holds  allocation lock or otherwise inhibits \t\t*/\n+/* updates.\t\t\t\t\t\t\t*/\n+/* If there is more than one thread with the given id we \t*/\n+/* return the most recent one.\t\t\t\t\t*/\n+GC_thread GC_lookup_thread(pthread_t id)\n+{\n+    int hv = ((word)id) % THREAD_TABLE_SZ;\n+    register GC_thread p = GC_threads[hv];\n+    \n+    while (p != 0 && !pthread_equal(p -> id, id)) p = p -> next;\n+    return(p);\n+}\n+\n+#ifdef HANDLE_FORK\n+/* Remove all entries from the GC_threads table, except the\t*/\n+/* one for the current thread.  We need to do this in the child\t*/\n+/* process after a fork(), since only the current thread \t*/\n+/* survives in the child.\t\t\t\t\t*/\n+void GC_remove_all_threads_but_me(void)\n+{\n+    pthread_t self = pthread_self();\n+    int hv;\n+    GC_thread p, next, me;\n+\n+    for (hv = 0; hv < THREAD_TABLE_SZ; ++hv) {\n+      me = 0;\n+      for (p = GC_threads[hv]; 0 != p; p = next) {\n+\tnext = p -> next;\n+\tif (p -> id == self) {\n+\t  me = p;\n+\t  p -> next = 0;\n+\t} else {\n+#\t  ifdef THREAD_LOCAL_ALLOC\n+\t    if (!(p -> flags & FINISHED)) {\n+\t      GC_destroy_thread_local(p);\n+\t    }\n+#\t  endif /* THREAD_LOCAL_ALLOC */\n+\t  if (p != &first_thread) GC_INTERNAL_FREE(p);\n+\t}\n+      }\n+      GC_threads[hv] = me;\n+    }\n+}\n+#endif /* HANDLE_FORK */\n+\n+#ifdef USE_PROC_FOR_LIBRARIES\n+int GC_segment_is_thread_stack(ptr_t lo, ptr_t hi)\n+{\n+    int i;\n+    GC_thread p;\n+    \n+#   ifdef PARALLEL_MARK\n+      for (i = 0; i < GC_markers; ++i) {\n+\tif (marker_sp[i] > lo & marker_sp[i] < hi) return 1;\n+      }\n+#   endif\n+    for (i = 0; i < THREAD_TABLE_SZ; i++) {\n+      for (p = GC_threads[i]; p != 0; p = p -> next) {\n+\tif (0 != p -> stack_end) {\n+#\t  ifdef STACK_GROWS_UP\n+            if (p -> stack_end >= lo && p -> stack_end < hi) return 1;\n+#\t  else /* STACK_GROWS_DOWN */\n+            if (p -> stack_end > lo && p -> stack_end <= hi) return 1;\n+#\t  endif\n+\t}\n+      }\n+    }\n+    return 0;\n+}\n+#endif /* USE_PROC_FOR_LIBRARIES */\n+\n+#ifdef GC_LINUX_THREADS\n+/* Return the number of processors, or i<= 0 if it can't be determined.\t*/\n+int GC_get_nprocs()\n+{\n+    /* Should be \"return sysconf(_SC_NPROCESSORS_ONLN);\" but that\t*/\n+    /* appears to be buggy in many cases.\t\t\t\t*/\n+    /* We look for lines \"cpu<n>\" in /proc/stat.\t\t\t*/\n+#   define STAT_BUF_SIZE 4096\n+#   define STAT_READ read\n+\t/* If read is wrapped, this may need to be redefined to call \t*/\n+\t/* the real one.\t\t\t\t\t\t*/\n+    char stat_buf[STAT_BUF_SIZE];\n+    int f;\n+    word result = 1;\n+\t/* Some old kernels only have a single \"cpu nnnn ...\"\t*/\n+\t/* entry in /proc/stat.  We identify those as \t\t*/\n+\t/* uniprocessors.\t\t\t\t\t*/\n+    size_t i, len = 0;\n+\n+    f = open(\"/proc/stat\", O_RDONLY);\n+    if (f < 0 || (len = STAT_READ(f, stat_buf, STAT_BUF_SIZE)) < 100) {\n+\tWARN(\"Couldn't read /proc/stat\\n\", 0);\n+\treturn -1;\n+    }\n+    for (i = 0; i < len - 100; ++i) {\n+        if (stat_buf[i] == '\\n' && stat_buf[i+1] == 'c'\n+\t    && stat_buf[i+2] == 'p' && stat_buf[i+3] == 'u') {\n+\t    int cpu_no = atoi(stat_buf + i + 4);\n+\t    if (cpu_no >= result) result = cpu_no + 1;\n+\t}\n+    }\n+    close(f);\n+    return result;\n+}\n+#endif /* GC_LINUX_THREADS */\n+\n+/* We hold the GC lock.  Wait until an in-progress GC has finished.\t*/\n+/* Repeatedly RELEASES GC LOCK in order to wait.\t\t\t*/\n+/* If wait_for_all is true, then we exit with the GC lock held and no\t*/\n+/* collection in progress; otherwise we just wait for the current GC\t*/\n+/* to finish.\t\t\t\t\t\t\t\t*/\n+extern GC_bool GC_collection_in_progress();\n+void GC_wait_for_gc_completion(GC_bool wait_for_all)\n+{\n+    if (GC_incremental && GC_collection_in_progress()) {\n+\tint old_gc_no = GC_gc_no;\n+\n+\t/* Make sure that no part of our stack is still on the mark stack, */\n+\t/* since it's about to be unmapped.\t\t\t\t   */\n+\twhile (GC_incremental && GC_collection_in_progress()\n+\t       && (wait_for_all || old_gc_no == GC_gc_no)) {\n+\t    ENTER_GC();\n+            GC_collect_a_little_inner(1);\n+\t    EXIT_GC();\n+\t    UNLOCK();\n+\t    sched_yield();\n+\t    LOCK();\n+\t}\n+    }\n+}\n+\n+#ifdef HANDLE_FORK\n+/* Procedures called before and after a fork.  The goal here is to make */\n+/* it safe to call GC_malloc() in a forked child.  It's unclear that is\t*/\n+/* attainable, since the single UNIX spec seems to imply that one \t*/\n+/* should only call async-signal-safe functions, and we probably can't\t*/\n+/* quite guarantee that.  But we give it our best shot.  (That same\t*/\n+/* spec also implies that it's not safe to call the system malloc\t*/\n+/* between fork() and exec().  Thus we're doing no worse than it.\t*/\n+\n+/* Called before a fork()\t\t*/\n+void GC_fork_prepare_proc(void)\n+{\n+    /* Acquire all relevant locks, so that after releasing the locks\t*/\n+    /* the child will see a consistent state in which monitor \t\t*/\n+    /* invariants hold.\t Unfortunately, we can't acquire libc locks\t*/\n+    /* we might need, and there seems to be no guarantee that libc\t*/\n+    /* must install a suitable fork handler.\t\t\t\t*/\n+    /* Wait for an ongoing GC to finish, since we can't finish it in\t*/\n+    /* the (one remaining thread in) the child.\t\t\t\t*/\n+      LOCK();\n+#     if defined(PARALLEL_MARK) || defined(THREAD_LOCAL_ALLOC)\n+        GC_wait_for_reclaim();\n+#     endif\n+      GC_wait_for_gc_completion(TRUE);\n+#     if defined(PARALLEL_MARK) || defined(THREAD_LOCAL_ALLOC)\n+        GC_acquire_mark_lock();\n+#     endif\n+}\n+\n+/* Called in parent after a fork()\t*/\n+void GC_fork_parent_proc(void)\n+{\n+#   if defined(PARALLEL_MARK) || defined(THREAD_LOCAL_ALLOC)\n+      GC_release_mark_lock();\n+#   endif\n+    UNLOCK();\n+}\n+\n+/* Called in child after a fork()\t*/\n+void GC_fork_child_proc(void)\n+{\n+    /* Clean up the thread table, so that just our thread is left. */\n+#   if defined(PARALLEL_MARK) || defined(THREAD_LOCAL_ALLOC)\n+      GC_release_mark_lock();\n+#   endif\n+    GC_remove_all_threads_but_me();\n+#   ifdef PARALLEL_MARK\n+      /* Turn off parallel marking in the child, since we are probably \t*/\n+      /* just going to exec, and we would have to restart mark threads.\t*/\n+        GC_markers = 1;\n+        GC_parallel = FALSE;\n+#   endif /* PARALLEL_MARK */\n+    UNLOCK();\n+}\n+#endif /* HANDLE_FORK */\n+\n+#if defined(GC_DGUX386_THREADS)\n+/* Return the number of processors, or i<= 0 if it can't be determined. */\n+int GC_get_nprocs()\n+{\n+    /* <takis@XFree86.Org> */\n+    int numCpus;\n+    struct dg_sys_info_pm_info pm_sysinfo;\n+    int status =0;\n+\n+    status = dg_sys_info((long int *) &pm_sysinfo,\n+\tDG_SYS_INFO_PM_INFO_TYPE, DG_SYS_INFO_PM_CURRENT_VERSION);\n+    if (status < 0)\n+       /* set -1 for error */\n+       numCpus = -1;\n+    else\n+      /* Active CPUs */\n+      numCpus = pm_sysinfo.idle_vp_count;\n+\n+#  ifdef DEBUG_THREADS\n+    GC_printf1(\"Number of active CPUs in this system: %d\\n\", numCpus);\n+#  endif\n+    return(numCpus);\n+}\n+#endif /* GC_DGUX386_THREADS */\n+\n+/* We hold the allocation lock.\t*/\n+void GC_thr_init()\n+{\n+#\tifndef GC_DARWIN_THREADS\n+        int dummy;\n+#\tendif\n+    GC_thread t;\n+\n+    if (GC_thr_initialized) return;\n+    GC_thr_initialized = TRUE;\n+    \n+#   ifdef HANDLE_FORK\n+      /* Prepare for a possible fork.\t*/\n+        pthread_atfork(GC_fork_prepare_proc, GC_fork_parent_proc,\n+\t  \t       GC_fork_child_proc);\n+#   endif /* HANDLE_FORK */\n+    /* Add the initial thread, so we can stop it.\t*/\n+      t = GC_new_thread(pthread_self());\n+#     ifdef GC_DARWIN_THREADS\n+         t -> stop_info.mach_thread = mach_thread_self();\n+#     else\n+         t -> stop_info.stack_ptr = (ptr_t)(&dummy);\n+#     endif\n+      t -> flags = DETACHED | MAIN_THREAD;\n+\n+    GC_stop_init();\n+\n+    /* Set GC_nprocs.  */\n+      {\n+\tchar * nprocs_string = GETENV(\"GC_NPROCS\");\n+\tGC_nprocs = -1;\n+\tif (nprocs_string != NULL) GC_nprocs = atoi(nprocs_string);\n+      }\n+      if (GC_nprocs <= 0) {\n+#       if defined(GC_HPUX_THREADS)\n+\t  GC_nprocs = pthread_num_processors_np();\n+#       endif\n+#\tif defined(GC_OSF1_THREADS)\n+\t  GC_nprocs = sysconf(_SC_NPROCESSORS_ONLN);\n+\t  if (GC_nprocs <= 0) GC_nprocs = 1;\n+#\tendif\n+#       if defined(GC_FREEBSD_THREADS)\n+          GC_nprocs = 1;\n+#       endif\n+#       if defined(GC_DARWIN_THREADS)\n+\t  int ncpus = 1;\n+\t  size_t len = sizeof(ncpus);\n+\t  sysctl((int[2]) {CTL_HW, HW_NCPU}, 2, &ncpus, &len, NULL, 0);\n+\t  GC_nprocs = ncpus;\n+#       endif\n+#\tif defined(GC_LINUX_THREADS) || defined(GC_DGUX386_THREADS)\n+          GC_nprocs = GC_get_nprocs();\n+#\tendif\n+      }\n+      if (GC_nprocs <= 0) {\n+\tWARN(\"GC_get_nprocs() returned %ld\\n\", GC_nprocs);\n+\tGC_nprocs = 2;\n+#\tifdef PARALLEL_MARK\n+\t  GC_markers = 1;\n+#\tendif\n+      } else {\n+#\tifdef PARALLEL_MARK\n+          {\n+\t    char * markers_string = GETENV(\"GC_MARKERS\");\n+\t    if (markers_string != NULL) {\n+\t      GC_markers = atoi(markers_string);\n+\t    } else {\n+\t      GC_markers = GC_nprocs;\n+\t    }\n+          }\n+#\tendif\n+      }\n+#   ifdef PARALLEL_MARK\n+#     ifdef CONDPRINT\n+        if (GC_print_stats) {\n+          GC_printf2(\"Number of processors = %ld, \"\n+\t\t \"number of marker threads = %ld\\n\", GC_nprocs, GC_markers);\n+\t}\n+#     endif\n+      if (GC_markers == 1) {\n+\tGC_parallel = FALSE;\n+#\tifdef CONDPRINT\n+\t  if (GC_print_stats) {\n+\t    GC_printf0(\"Single marker thread, turning off parallel marking\\n\");\n+\t  }\n+#\tendif\n+      } else {\n+\tGC_parallel = TRUE;\n+\t/* Disable true incremental collection, but generational is OK.\t*/\n+\tGC_time_limit = GC_TIME_UNLIMITED;\n+      }\n+#   endif\n+}\n+\n+\n+/* Perform all initializations, including those that\t*/\n+/* may require allocation.\t\t\t\t*/\n+/* Called without allocation lock.\t\t\t*/\n+/* Must be called before a second thread is created.\t*/\n+/* Called without allocation lock.\t\t\t*/\n+void GC_init_parallel()\n+{\n+    if (parallel_initialized) return;\n+    parallel_initialized = TRUE;\n+\n+    /* GC_init() calls us back, so set flag first.\t*/\n+    if (!GC_is_initialized) GC_init();\n+    /* If we are using a parallel marker, start the helper threads.  */\n+#     ifdef PARALLEL_MARK\n+        if (GC_parallel) start_mark_threads();\n+#     endif\n+    /* Initialize thread local free lists if used.\t*/\n+#   if defined(THREAD_LOCAL_ALLOC) && !defined(DBG_HDRS_ALL)\n+      LOCK();\n+      GC_init_thread_local(GC_lookup_thread(pthread_self()));\n+      UNLOCK();\n+#   endif\n+}\n+\n+\n+#if !defined(GC_DARWIN_THREADS)\n+int WRAP_FUNC(pthread_sigmask)(int how, const sigset_t *set, sigset_t *oset)\n+{\n+    sigset_t fudged_set;\n+    \n+    if (set != NULL && (how == SIG_BLOCK || how == SIG_SETMASK)) {\n+        fudged_set = *set;\n+        sigdelset(&fudged_set, SIG_SUSPEND);\n+        set = &fudged_set;\n+    }\n+    return(REAL_FUNC(pthread_sigmask)(how, set, oset));\n+}\n+#endif /* !GC_DARWIN_THREADS */\n+\n+/* Wrappers for functions that are likely to block for an appreciable\t*/\n+/* length of time.  Must be called in pairs, if at all.\t\t\t*/\n+/* Nothing much beyond the system call itself should be executed\t*/\n+/* between these.\t\t\t\t\t\t\t*/\n+\n+void GC_start_blocking(void) {\n+#   define SP_SLOP 128\n+    GC_thread me;\n+    LOCK();\n+    me = GC_lookup_thread(pthread_self());\n+    GC_ASSERT(!(me -> thread_blocked));\n+#   ifdef SPARC\n+\tme -> stop_info.stack_ptr = (ptr_t)GC_save_regs_in_stack();\n+#   else\n+#   ifndef GC_DARWIN_THREADS\n+\tme -> stop_info.stack_ptr = (ptr_t)GC_approx_sp();\n+#   endif\n+#   endif\n+#   ifdef IA64\n+\tme -> backing_store_ptr = (ptr_t)GC_save_regs_in_stack() + SP_SLOP;\n+#   endif\n+    /* Add some slop to the stack pointer, since the wrapped call may \t*/\n+    /* end up pushing more callee-save registers.\t\t\t*/\n+#   ifndef GC_DARWIN_THREADS\n+#   ifdef STACK_GROWS_UP\n+\tme -> stop_info.stack_ptr += SP_SLOP;\n+#   else\n+\tme -> stop_info.stack_ptr -= SP_SLOP;\n+#   endif\n+#   endif\n+    me -> thread_blocked = TRUE;\n+    UNLOCK();\n+}\n+\n+void GC_end_blocking(void) {\n+    GC_thread me;\n+    LOCK();   /* This will block if the world is stopped.\t*/\n+    me = GC_lookup_thread(pthread_self());\n+    GC_ASSERT(me -> thread_blocked);\n+    me -> thread_blocked = FALSE;\n+    UNLOCK();\n+}\n+    \n+#if defined(GC_DGUX386_THREADS)\n+#define __d10_sleep sleep\n+#endif /* GC_DGUX386_THREADS */\n+\n+/* A wrapper for the standard C sleep function\t*/\n+int WRAP_FUNC(sleep) (unsigned int seconds)\n+{\n+    int result;\n+\n+    GC_start_blocking();\n+    result = REAL_FUNC(sleep)(seconds);\n+    GC_end_blocking();\n+    return result;\n+}\n+\n+struct start_info {\n+    void *(*start_routine)(void *);\n+    void *arg;\n+    word flags;\n+    sem_t registered;   \t/* 1 ==> in our thread table, but \t*/\n+\t\t\t\t/* parent hasn't yet noticed.\t\t*/\n+};\n+\n+/* Called at thread exit.\t\t\t\t*/\n+/* Never called for main thread.  That's OK, since it\t*/\n+/* results in at most a tiny one-time leak.  And \t*/\n+/* linuxthreads doesn't reclaim the main threads \t*/\n+/* resources or id anyway.\t\t\t\t*/\n+void GC_thread_exit_proc(void *arg)\n+{\n+    GC_thread me;\n+\n+    LOCK();\n+    me = GC_lookup_thread(pthread_self());\n+    GC_destroy_thread_local(me);\n+    if (me -> flags & DETACHED) {\n+    \tGC_delete_thread(pthread_self());\n+    } else {\n+\tme -> flags |= FINISHED;\n+    }\n+#   if defined(THREAD_LOCAL_ALLOC) && !defined(USE_PTHREAD_SPECIFIC) \\\n+       && !defined(USE_HPUX_TLS) && !defined(DBG_HDRS_ALL)\n+      GC_remove_specific(GC_thread_key);\n+#   endif\n+    GC_wait_for_gc_completion(FALSE);\n+    UNLOCK();\n+}\n+\n+int WRAP_FUNC(pthread_join)(pthread_t thread, void **retval)\n+{\n+    int result;\n+    GC_thread thread_gc_id;\n+    \n+    LOCK();\n+    thread_gc_id = GC_lookup_thread(thread);\n+    /* This is guaranteed to be the intended one, since the thread id\t*/\n+    /* cant have been recycled by pthreads.\t\t\t\t*/\n+    UNLOCK();\n+    result = REAL_FUNC(pthread_join)(thread, retval);\n+# if defined (GC_FREEBSD_THREADS)\n+    /* On FreeBSD, the wrapped pthread_join() sometimes returns (what\n+       appears to be) a spurious EINTR which caused the test and real code\n+       to gratuitously fail.  Having looked at system pthread library source\n+       code, I see how this return code may be generated.  In one path of\n+       code, pthread_join() just returns the errno setting of the thread\n+       being joined.  This does not match the POSIX specification or the\n+       local man pages thus I have taken the liberty to catch this one\n+       spurious return value properly conditionalized on GC_FREEBSD_THREADS. */\n+    if (result == EINTR) result = 0;\n+# endif\n+    if (result == 0) {\n+        LOCK();\n+        /* Here the pthread thread id may have been recycled. */\n+        GC_delete_gc_thread(thread, thread_gc_id);\n+        UNLOCK();\n+    }\n+    return result;\n+}\n+\n+int\n+WRAP_FUNC(pthread_detach)(pthread_t thread)\n+{\n+    int result;\n+    GC_thread thread_gc_id;\n+    \n+    LOCK();\n+    thread_gc_id = GC_lookup_thread(thread);\n+    UNLOCK();\n+    result = REAL_FUNC(pthread_detach)(thread);\n+    if (result == 0) {\n+      LOCK();\n+      thread_gc_id -> flags |= DETACHED;\n+      /* Here the pthread thread id may have been recycled. */\n+      if (thread_gc_id -> flags & FINISHED) {\n+        GC_delete_gc_thread(thread, thread_gc_id);\n+      }\n+      UNLOCK();\n+    }\n+    return result;\n+}\n+\n+void * GC_start_routine(void * arg)\n+{\n+    int dummy;\n+    struct start_info * si = arg;\n+    void * result;\n+    GC_thread me;\n+    pthread_t my_pthread;\n+    void *(*start)(void *);\n+    void *start_arg;\n+\n+    my_pthread = pthread_self();\n+#   ifdef DEBUG_THREADS\n+        GC_printf1(\"Starting thread 0x%lx\\n\", my_pthread);\n+        GC_printf1(\"pid = %ld\\n\", (long) getpid());\n+        GC_printf1(\"sp = 0x%lx\\n\", (long) &arg);\n+#   endif\n+    LOCK();\n+    me = GC_new_thread(my_pthread);\n+#ifdef GC_DARWIN_THREADS\n+    me -> stop_info.mach_thread = mach_thread_self();\n+#else\n+    me -> stop_info.stack_ptr = 0;\n+#endif\n+    me -> flags = si -> flags;\n+    /* me -> stack_end = GC_linux_stack_base(); -- currently (11/99)\t*/\n+    /* doesn't work because the stack base in /proc/self/stat is the \t*/\n+    /* one for the main thread.  There is a strong argument that that's\t*/\n+    /* a kernel bug, but a pervasive one.\t\t\t\t*/\n+#   ifdef STACK_GROWS_DOWN\n+      me -> stack_end = (ptr_t)(((word)(&dummy) + (GC_page_size - 1))\n+\t\t                & ~(GC_page_size - 1));\n+#\t  ifndef GC_DARWIN_THREADS\n+        me -> stop_info.stack_ptr = me -> stack_end - 0x10;\n+#\t  endif\n+\t/* Needs to be plausible, since an asynchronous stack mark\t*/\n+\t/* should not crash.\t\t\t\t\t\t*/\n+#   else\n+      me -> stack_end = (ptr_t)((word)(&dummy) & ~(GC_page_size - 1));\n+      me -> stop_info.stack_ptr = me -> stack_end + 0x10;\n+#   endif\n+    /* This is dubious, since we may be more than a page into the stack, */\n+    /* and hence skip some of it, though it's not clear that matters.\t */\n+#   ifdef IA64\n+      me -> backing_store_end = (ptr_t)\n+\t\t\t(GC_save_regs_in_stack() & ~(GC_page_size - 1));\n+      /* This is also < 100% convincing.  We should also read this \t*/\n+      /* from /proc, but the hook to do so isn't there yet.\t\t*/\n+#   endif /* IA64 */\n+    UNLOCK();\n+    start = si -> start_routine;\n+#   ifdef DEBUG_THREADS\n+\tGC_printf1(\"start_routine = 0x%lx\\n\", start);\n+#   endif\n+    start_arg = si -> arg;\n+    sem_post(&(si -> registered));\t/* Last action on si.\t*/\n+    \t\t\t\t\t/* OK to deallocate.\t*/\n+    pthread_cleanup_push(GC_thread_exit_proc, 0);\n+#   if defined(THREAD_LOCAL_ALLOC) && !defined(DBG_HDRS_ALL)\n+ \tLOCK();\n+        GC_init_thread_local(me);\n+\tUNLOCK();\n+#   endif\n+    result = (*start)(start_arg);\n+#if DEBUG_THREADS\n+        GC_printf1(\"Finishing thread 0x%x\\n\", pthread_self());\n+#endif\n+    me -> status = result;\n+    pthread_cleanup_pop(1);\n+    /* Cleanup acquires lock, ensuring that we can't exit\t\t*/\n+    /* while a collection that thinks we're alive is trying to stop     */\n+    /* us.\t\t\t\t\t\t\t\t*/\n+    return(result);\n+}\n+\n+int\n+WRAP_FUNC(pthread_create)(pthread_t *new_thread,\n+\t\t  const pthread_attr_t *attr,\n+                  void *(*start_routine)(void *), void *arg)\n+{\n+    int result;\n+    int detachstate;\n+    word my_flags = 0;\n+    struct start_info * si; \n+\t/* This is otherwise saved only in an area mmapped by the thread */\n+\t/* library, which isn't visible to the collector.\t\t */\n+ \n+    /* We resist the temptation to muck with the stack size here,\t*/\n+    /* even if the default is unreasonably small.  That's the client's\t*/\n+    /* responsibility.\t\t\t\t\t\t\t*/\n+\n+    LOCK();\n+    si = (struct start_info *)GC_INTERNAL_MALLOC(sizeof(struct start_info),\n+\t\t\t\t\t\t NORMAL);\n+    UNLOCK();\n+    if (!parallel_initialized) GC_init_parallel();\n+    if (0 == si) return(ENOMEM);\n+    sem_init(&(si -> registered), 0, 0);\n+    si -> start_routine = start_routine;\n+    si -> arg = arg;\n+    LOCK();\n+    if (!GC_thr_initialized) GC_thr_init();\n+#   ifdef GC_ASSERTIONS\n+      {\n+\tint stack_size;\n+\tif (NULL == attr) {\n+\t   pthread_attr_t my_attr;\n+\t   pthread_attr_init(&my_attr);\n+\t   pthread_attr_getstacksize(&my_attr, &stack_size);\n+\t} else {\n+\t   pthread_attr_getstacksize(attr, &stack_size);\n+\t}\n+\tGC_ASSERT(stack_size >= (8*HBLKSIZE*sizeof(word)));\n+\t/* Our threads may need to do some work for the GC.\t*/\n+\t/* Ridiculously small threads won't work, and they\t*/\n+\t/* probably wouldn't work anyway.\t\t\t*/\n+      }\n+#   endif\n+    if (NULL == attr) {\n+\tdetachstate = PTHREAD_CREATE_JOINABLE;\n+    } else { \n+        pthread_attr_getdetachstate(attr, &detachstate);\n+    }\n+    if (PTHREAD_CREATE_DETACHED == detachstate) my_flags |= DETACHED;\n+    si -> flags = my_flags;\n+    UNLOCK();\n+#   ifdef DEBUG_THREADS\n+        GC_printf1(\"About to start new thread from thread 0x%X\\n\",\n+\t\t   pthread_self());\n+#   endif\n+\n+    result = REAL_FUNC(pthread_create)(new_thread, attr, GC_start_routine, si);\n+\n+#   ifdef DEBUG_THREADS\n+        GC_printf1(\"Started thread 0x%X\\n\", *new_thread);\n+#   endif\n+    /* Wait until child has been added to the thread table.\t\t*/\n+    /* This also ensures that we hold onto si until the child is done\t*/\n+    /* with it.  Thus it doesn't matter whether it is otherwise\t\t*/\n+    /* visible to the collector.\t\t\t\t\t*/\n+    if (0 == result) {\n+\twhile (0 != sem_wait(&(si -> registered))) {\n+            if (EINTR != errno) ABORT(\"sem_wait failed\");\n+\t}\n+    }\n+    sem_destroy(&(si -> registered));\n+    LOCK();\n+    GC_INTERNAL_FREE(si);\n+    UNLOCK();\n+\n+    return(result);\n+}\n+\n+#ifdef GENERIC_COMPARE_AND_SWAP\n+  pthread_mutex_t GC_compare_and_swap_lock = PTHREAD_MUTEX_INITIALIZER;\n+\n+  GC_bool GC_compare_and_exchange(volatile GC_word *addr,\n+  \t\t\t          GC_word old, GC_word new_val)\n+  {\n+    GC_bool result;\n+    pthread_mutex_lock(&GC_compare_and_swap_lock);\n+    if (*addr == old) {\n+      *addr = new_val;\n+      result = TRUE;\n+    } else {\n+      result = FALSE;\n+    }\n+    pthread_mutex_unlock(&GC_compare_and_swap_lock);\n+    return result;\n+  }\n+  \n+  GC_word GC_atomic_add(volatile GC_word *addr, GC_word how_much)\n+  {\n+    GC_word old;\n+    pthread_mutex_lock(&GC_compare_and_swap_lock);\n+    old = *addr;\n+    *addr = old + how_much;\n+    pthread_mutex_unlock(&GC_compare_and_swap_lock);\n+    return old;\n+  }\n+\n+#endif /* GENERIC_COMPARE_AND_SWAP */\n+/* Spend a few cycles in a way that can't introduce contention with\t*/\n+/* othre threads.\t\t\t\t\t\t\t*/\n+void GC_pause()\n+{\n+    int i;\n+#\tifndef __GNUC__\n+        volatile word dummy = 0;\n+#\tendif\n+\n+    for (i = 0; i < 10; ++i) { \n+#     ifdef __GNUC__\n+        __asm__ __volatile__ (\" \" : : : \"memory\");\n+#     else\n+\t/* Something that's unlikely to be optimized away. */\n+\tGC_noop(++dummy);\n+#     endif\n+    }\n+}\n+    \n+#define SPIN_MAX 1024\t/* Maximum number of calls to GC_pause before\t*/\n+\t\t\t/* give up.\t\t\t\t\t*/\n+\n+VOLATILE GC_bool GC_collecting = 0;\n+\t\t\t/* A hint that we're in the collector and       */\n+                        /* holding the allocation lock for an           */\n+                        /* extended period.                             */\n+\n+#if !defined(USE_SPIN_LOCK) || defined(PARALLEL_MARK)\n+/* If we don't want to use the below spinlock implementation, either\t*/\n+/* because we don't have a GC_test_and_set implementation, or because \t*/\n+/* we don't want to risk sleeping, we can still try spinning on \t*/\n+/* pthread_mutex_trylock for a while.  This appears to be very\t\t*/\n+/* beneficial in many cases.\t\t\t\t\t\t*/\n+/* I suspect that under high contention this is nearly always better\t*/\n+/* than the spin lock.  But it's a bit slower on a uniprocessor.\t*/\n+/* Hence we still default to the spin lock.\t\t\t\t*/\n+/* This is also used to acquire the mark lock for the parallel\t\t*/\n+/* marker.\t\t\t\t\t\t\t\t*/\n+\n+/* Here we use a strict exponential backoff scheme.  I don't know \t*/\n+/* whether that's better or worse than the above.  We eventually \t*/\n+/* yield by calling pthread_mutex_lock(); it never makes sense to\t*/\n+/* explicitly sleep.\t\t\t\t\t\t\t*/\n+\n+void GC_generic_lock(pthread_mutex_t * lock)\n+{\n+#ifndef NO_PTHREAD_TRYLOCK\n+    unsigned pause_length = 1;\n+    unsigned i;\n+    \n+    if (0 == pthread_mutex_trylock(lock)) return;\n+    for (; pause_length <= SPIN_MAX; pause_length <<= 1) {\n+\tfor (i = 0; i < pause_length; ++i) {\n+\t    GC_pause();\n+\t}\n+        switch(pthread_mutex_trylock(lock)) {\n+\t    case 0:\n+\t\treturn;\n+\t    case EBUSY:\n+\t\tbreak;\n+\t    default:\n+\t\tABORT(\"Unexpected error from pthread_mutex_trylock\");\n+        }\n+    }\n+#endif /* !NO_PTHREAD_TRYLOCK */\n+    pthread_mutex_lock(lock);\n+}\n+\n+#endif /* !USE_SPIN_LOCK || PARALLEL_MARK */\n+\n+#if defined(USE_SPIN_LOCK)\n+\n+/* Reasonably fast spin locks.  Basically the same implementation */\n+/* as STL alloc.h.  This isn't really the right way to do this.   */\n+/* but until the POSIX scheduling mess gets straightened out ...  */\n+\n+volatile unsigned int GC_allocate_lock = 0;\n+\n+\n+void GC_lock()\n+{\n+#   define low_spin_max 30  /* spin cycles if we suspect uniprocessor */\n+#   define high_spin_max SPIN_MAX /* spin cycles for multiprocessor */\n+    static unsigned spin_max = low_spin_max;\n+    unsigned my_spin_max;\n+    static unsigned last_spins = 0;\n+    unsigned my_last_spins;\n+    int i;\n+\n+    if (!GC_test_and_set(&GC_allocate_lock)) {\n+        return;\n+    }\n+    my_spin_max = spin_max;\n+    my_last_spins = last_spins;\n+    for (i = 0; i < my_spin_max; i++) {\n+        if (GC_collecting || GC_nprocs == 1) goto yield;\n+        if (i < my_last_spins/2 || GC_allocate_lock) {\n+            GC_pause();\n+            continue;\n+        }\n+        if (!GC_test_and_set(&GC_allocate_lock)) {\n+\t    /*\n+             * got it!\n+             * Spinning worked.  Thus we're probably not being scheduled\n+             * against the other process with which we were contending.\n+             * Thus it makes sense to spin longer the next time.\n+\t     */\n+            last_spins = i;\n+            spin_max = high_spin_max;\n+            return;\n+        }\n+    }\n+    /* We are probably being scheduled against the other process.  Sleep. */\n+    spin_max = low_spin_max;\n+yield:\n+    for (i = 0;; ++i) {\n+        if (!GC_test_and_set(&GC_allocate_lock)) {\n+            return;\n+        }\n+#       define SLEEP_THRESHOLD 12\n+\t\t/* Under Linux very short sleeps tend to wait until\t*/\n+\t\t/* the current time quantum expires.  On old Linux\t*/\n+\t\t/* kernels nanosleep(<= 2ms) just spins under Linux.    */\n+\t\t/* (Under 2.4, this happens only for real-time\t\t*/\n+\t\t/* processes.)  We want to minimize both behaviors\t*/\n+\t\t/* here.\t\t\t\t\t\t*/\n+        if (i < SLEEP_THRESHOLD) {\n+            sched_yield();\n+\t} else {\n+\t    struct timespec ts;\n+\t\n+\t    if (i > 24) i = 24;\n+\t\t\t/* Don't wait for more than about 15msecs, even\t*/\n+\t\t\t/* under extreme contention.\t\t\t*/\n+\t    ts.tv_sec = 0;\n+\t    ts.tv_nsec = 1 << i;\n+\t    nanosleep(&ts, 0);\n+\t}\n+    }\n+}\n+\n+#else  /* !USE_SPINLOCK */\n+void GC_lock()\n+{\n+#ifndef NO_PTHREAD_TRYLOCK\n+    if (1 == GC_nprocs || GC_collecting) {\n+\tpthread_mutex_lock(&GC_allocate_ml);\n+    } else {\n+        GC_generic_lock(&GC_allocate_ml);\n+    }\n+#else  /* !NO_PTHREAD_TRYLOCK */\n+    pthread_mutex_lock(&GC_allocate_ml);\n+#endif /* !NO_PTHREAD_TRYLOCK */\n+}\n+\n+#endif /* !USE_SPINLOCK */\n+\n+#if defined(PARALLEL_MARK) || defined(THREAD_LOCAL_ALLOC)\n+\n+#ifdef GC_ASSERTIONS\n+  pthread_t GC_mark_lock_holder = NO_THREAD;\n+#endif\n+\n+#if 0\n+  /* Ugly workaround for a linux threads bug in the final versions      */\n+  /* of glibc2.1.  Pthread_mutex_trylock sets the mutex owner           */\n+  /* field even when it fails to acquire the mutex.  This causes        */\n+  /* pthread_cond_wait to die.  Remove for glibc2.2.                    */\n+  /* According to the man page, we should use                           */\n+  /* PTHREAD_ERRORCHECK_MUTEX_INITIALIZER_NP, but that isn't actually   */\n+  /* defined.                                                           */\n+  static pthread_mutex_t mark_mutex =\n+        {0, 0, 0, PTHREAD_MUTEX_ERRORCHECK_NP, {0, 0}};\n+#else\n+  static pthread_mutex_t mark_mutex = PTHREAD_MUTEX_INITIALIZER;\n+#endif\n+\n+static pthread_cond_t builder_cv = PTHREAD_COND_INITIALIZER;\n+\n+void GC_acquire_mark_lock()\n+{\n+/*\n+    if (pthread_mutex_lock(&mark_mutex) != 0) {\n+\tABORT(\"pthread_mutex_lock failed\");\n+    }\n+*/\n+    GC_generic_lock(&mark_mutex);\n+#   ifdef GC_ASSERTIONS\n+\tGC_mark_lock_holder = pthread_self();\n+#   endif\n+}\n+\n+void GC_release_mark_lock()\n+{\n+    GC_ASSERT(GC_mark_lock_holder == pthread_self());\n+#   ifdef GC_ASSERTIONS\n+\tGC_mark_lock_holder = NO_THREAD;\n+#   endif\n+    if (pthread_mutex_unlock(&mark_mutex) != 0) {\n+\tABORT(\"pthread_mutex_unlock failed\");\n+    }\n+}\n+\n+/* Collector must wait for a freelist builders for 2 reasons:\t\t*/\n+/* 1) Mark bits may still be getting examined without lock.\t\t*/\n+/* 2) Partial free lists referenced only by locals may not be scanned \t*/\n+/*    correctly, e.g. if they contain \"pointer-free\" objects, since the\t*/\n+/*    free-list link may be ignored.\t\t\t\t\t*/\n+void GC_wait_builder()\n+{\n+    GC_ASSERT(GC_mark_lock_holder == pthread_self());\n+#   ifdef GC_ASSERTIONS\n+\tGC_mark_lock_holder = NO_THREAD;\n+#   endif\n+    if (pthread_cond_wait(&builder_cv, &mark_mutex) != 0) {\n+\tABORT(\"pthread_cond_wait failed\");\n+    }\n+    GC_ASSERT(GC_mark_lock_holder == NO_THREAD);\n+#   ifdef GC_ASSERTIONS\n+\tGC_mark_lock_holder = pthread_self();\n+#   endif\n+}\n+\n+void GC_wait_for_reclaim()\n+{\n+    GC_acquire_mark_lock();\n+    while (GC_fl_builder_count > 0) {\n+\tGC_wait_builder();\n+    }\n+    GC_release_mark_lock();\n+}\n+\n+void GC_notify_all_builder()\n+{\n+    GC_ASSERT(GC_mark_lock_holder == pthread_self());\n+    if (pthread_cond_broadcast(&builder_cv) != 0) {\n+\tABORT(\"pthread_cond_broadcast failed\");\n+    }\n+}\n+\n+#endif /* PARALLEL_MARK || THREAD_LOCAL_ALLOC */\n+\n+#ifdef PARALLEL_MARK\n+\n+static pthread_cond_t mark_cv = PTHREAD_COND_INITIALIZER;\n+\n+void GC_wait_marker()\n+{\n+    GC_ASSERT(GC_mark_lock_holder == pthread_self());\n+#   ifdef GC_ASSERTIONS\n+\tGC_mark_lock_holder = NO_THREAD;\n+#   endif\n+    if (pthread_cond_wait(&mark_cv, &mark_mutex) != 0) {\n+\tABORT(\"pthread_cond_wait failed\");\n+    }\n+    GC_ASSERT(GC_mark_lock_holder == NO_THREAD);\n+#   ifdef GC_ASSERTIONS\n+\tGC_mark_lock_holder = pthread_self();\n+#   endif\n+}\n+\n+void GC_notify_all_marker()\n+{\n+    if (pthread_cond_broadcast(&mark_cv) != 0) {\n+\tABORT(\"pthread_cond_broadcast failed\");\n+    }\n+}\n+\n+#endif /* PARALLEL_MARK */\n+\n+# endif /* GC_LINUX_THREADS and friends */\n+"}]}