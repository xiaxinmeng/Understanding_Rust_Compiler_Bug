{"sha": "09eb042a8a8ee16e8f23085a175be25c8ef68820", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDllYjA0MmE4YThlZTE2ZThmMjMwODVhMTc1YmUyNWM4ZWY2ODgyMA==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2019-11-08T08:32:19Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2019-11-08T08:32:19Z"}, "message": "Generalise gather and scatter optabs\n\nThe gather and scatter optabs required the vector offset to be\nthe integer equivalent of the vector mode being loaded or stored.\nThis patch generalises them so that the two vectors can have different\nelement sizes, although they still need to have the same number of\nelements.\n\nOne consequence of this is that it's possible (if unlikely)\nfor two IFN_GATHER_LOADs to have the same arguments but different\nreturn types.  E.g. the same scalar base and vector of 32-bit offsets\ncould be used to load 8-bit elements and to load 16-bit elements.\nFrom just looking at the arguments, we could wrongly deduce that\nthey're equivalent.\n\nI know we saw this happen at one point with IFN_WHILE_ULT,\nand we dealt with it there by passing a zero of the return type\nas an extra argument.  Doing the same here also makes the load\nand store functions have the same argument assignment.\n\nFor now this patch should be a no-op, but later SVE patches take\nadvantage of the new flexibility.\n\n2019-11-08  Richard Sandiford  <richard.sandiford@arm.com>\n\ngcc/\n\t* optabs.def (gather_load_optab, mask_gather_load_optab)\n\t(scatter_store_optab, mask_scatter_store_optab): Turn into\n\tconversion optabs, with the offset mode given explicitly.\n\t* doc/md.texi: Update accordingly.\n\t* config/aarch64/aarch64-sve-builtins-base.cc\n\t(svld1_gather_impl::expand): Likewise.\n\t(svst1_scatter_impl::expand): Likewise.\n\t* internal-fn.c (gather_load_direct, scatter_store_direct): Likewise.\n\t(expand_scatter_store_optab_fn): Likewise.\n\t(direct_gather_load_optab_supported_p): Likewise.\n\t(direct_scatter_store_optab_supported_p): Likewise.\n\t(expand_gather_load_optab_fn): Likewise.  Expect the mask argument\n\tto be argument 4.\n\t(internal_fn_mask_index): Return 4 for IFN_MASK_GATHER_LOAD.\n\t(internal_gather_scatter_fn_supported_p): Replace the offset sign\n\targument with the offset vector type.  Require the two vector\n\ttypes to have the same number of elements but allow their element\n\tsizes to be different.  Treat the optabs as conversion optabs.\n\t* internal-fn.h (internal_gather_scatter_fn_supported_p): Update\n\tprototype accordingly.\n\t* optabs-query.c (supports_at_least_one_mode_p): Replace with...\n\t(supports_vec_convert_optab_p): ...this new function.\n\t(supports_vec_gather_load_p): Update accordingly.\n\t(supports_vec_scatter_store_p): Likewise.\n\t* tree-vectorizer.h (vect_gather_scatter_fn_p): Take a vec_info.\n\tReplace the offset sign and bits parameters with a scalar type tree.\n\t* tree-vect-data-refs.c (vect_gather_scatter_fn_p): Likewise.\n\tPass back the offset vector type instead of the scalar element type.\n\tAllow the offset to be wider than the memory elements.  Search for\n\tan offset type that the target supports, stopping once we've\n\treached the maximum of the element size and pointer size.\n\tUpdate call to internal_gather_scatter_fn_supported_p.\n\t(vect_check_gather_scatter): Update calls accordingly.\n\tWhen testing a new scale before knowing the final offset type,\n\tcheck whether the scale is supported for any signed or unsigned\n\toffset type.  Check whether the target supports the source and\n\ttarget types of a conversion before deciding whether to look\n\tthrough the conversion.  Record the chosen offset_vectype.\n\t* tree-vect-patterns.c (vect_get_gather_scatter_offset_type): Delete.\n\t(vect_recog_gather_scatter_pattern): Get the scalar offset type\n\tdirectly from the gs_info's offset_vectype instead.  Pass a zero\n\tof the result type to IFN_GATHER_LOAD and IFN_MASK_GATHER_LOAD.\n\t* tree-vect-stmts.c (check_load_store_masking): Update call to\n\tinternal_gather_scatter_fn_supported_p, passing the offset vector\n\ttype recorded in the gs_info.\n\t(vect_truncate_gather_scatter_offset): Update call to\n\tvect_check_gather_scatter, leaving it to search for a valid\n\toffset vector type.\n\t(vect_use_strided_gather_scatters_p): Convert the offset to the\n\telement type of the gs_info's offset_vectype.\n\t(vect_get_gather_scatter_ops): Get the offset vector type directly\n\tfrom the gs_info.\n\t(vect_get_strided_load_store_ops): Likewise.\n\t(vectorizable_load): Pass a zero of the result type to IFN_GATHER_LOAD\n\tand IFN_MASK_GATHER_LOAD.\n\t* config/aarch64/aarch64-sve.md (gather_load<mode>): Rename to...\n\t(gather_load<mode><v_int_equiv>): ...this.\n\t(mask_gather_load<mode>): Rename to...\n\t(mask_gather_load<mode><v_int_equiv>): ...this.\n\t(scatter_store<mode>): Rename to...\n\t(scatter_store<mode><v_int_equiv>): ...this.\n\t(mask_scatter_store<mode>): Rename to...\n\t(mask_scatter_store<mode><v_int_equiv>): ...this.\n\nFrom-SVN: r277949", "tree": {"sha": "3642ab9cc004670e3d3e8263db46861bfc11363d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3642ab9cc004670e3d3e8263db46861bfc11363d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/09eb042a8a8ee16e8f23085a175be25c8ef68820", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/09eb042a8a8ee16e8f23085a175be25c8ef68820", "html_url": "https://github.com/Rust-GCC/gccrs/commit/09eb042a8a8ee16e8f23085a175be25c8ef68820", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/09eb042a8a8ee16e8f23085a175be25c8ef68820/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "47cc2d4917c7cb351e561dba5768deaa2d42bf8b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/47cc2d4917c7cb351e561dba5768deaa2d42bf8b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/47cc2d4917c7cb351e561dba5768deaa2d42bf8b"}], "stats": {"total": 406, "additions": 230, "deletions": 176}, "files": [{"sha": "ab690afa222591ae2436e0cab0503e32ffd3c681", "filename": "gcc/ChangeLog", "status": "modified", "additions": 66, "deletions": 0, "changes": 66, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -1,3 +1,69 @@\n+2019-11-08  Richard Sandiford  <richard.sandiford@arm.com>\n+\n+\t* optabs.def (gather_load_optab, mask_gather_load_optab)\n+\t(scatter_store_optab, mask_scatter_store_optab): Turn into\n+\tconversion optabs, with the offset mode given explicitly.\n+\t* doc/md.texi: Update accordingly.\n+\t* config/aarch64/aarch64-sve-builtins-base.cc\n+\t(svld1_gather_impl::expand): Likewise.\n+\t(svst1_scatter_impl::expand): Likewise.\n+\t* internal-fn.c (gather_load_direct, scatter_store_direct): Likewise.\n+\t(expand_scatter_store_optab_fn): Likewise.\n+\t(direct_gather_load_optab_supported_p): Likewise.\n+\t(direct_scatter_store_optab_supported_p): Likewise.\n+\t(expand_gather_load_optab_fn): Likewise.  Expect the mask argument\n+\tto be argument 4.\n+\t(internal_fn_mask_index): Return 4 for IFN_MASK_GATHER_LOAD.\n+\t(internal_gather_scatter_fn_supported_p): Replace the offset sign\n+\targument with the offset vector type.  Require the two vector\n+\ttypes to have the same number of elements but allow their element\n+\tsizes to be different.  Treat the optabs as conversion optabs.\n+\t* internal-fn.h (internal_gather_scatter_fn_supported_p): Update\n+\tprototype accordingly.\n+\t* optabs-query.c (supports_at_least_one_mode_p): Replace with...\n+\t(supports_vec_convert_optab_p): ...this new function.\n+\t(supports_vec_gather_load_p): Update accordingly.\n+\t(supports_vec_scatter_store_p): Likewise.\n+\t* tree-vectorizer.h (vect_gather_scatter_fn_p): Take a vec_info.\n+\tReplace the offset sign and bits parameters with a scalar type tree.\n+\t* tree-vect-data-refs.c (vect_gather_scatter_fn_p): Likewise.\n+\tPass back the offset vector type instead of the scalar element type.\n+\tAllow the offset to be wider than the memory elements.  Search for\n+\tan offset type that the target supports, stopping once we've\n+\treached the maximum of the element size and pointer size.\n+\tUpdate call to internal_gather_scatter_fn_supported_p.\n+\t(vect_check_gather_scatter): Update calls accordingly.\n+\tWhen testing a new scale before knowing the final offset type,\n+\tcheck whether the scale is supported for any signed or unsigned\n+\toffset type.  Check whether the target supports the source and\n+\ttarget types of a conversion before deciding whether to look\n+\tthrough the conversion.  Record the chosen offset_vectype.\n+\t* tree-vect-patterns.c (vect_get_gather_scatter_offset_type): Delete.\n+\t(vect_recog_gather_scatter_pattern): Get the scalar offset type\n+\tdirectly from the gs_info's offset_vectype instead.  Pass a zero\n+\tof the result type to IFN_GATHER_LOAD and IFN_MASK_GATHER_LOAD.\n+\t* tree-vect-stmts.c (check_load_store_masking): Update call to\n+\tinternal_gather_scatter_fn_supported_p, passing the offset vector\n+\ttype recorded in the gs_info.\n+\t(vect_truncate_gather_scatter_offset): Update call to\n+\tvect_check_gather_scatter, leaving it to search for a valid\n+\toffset vector type.\n+\t(vect_use_strided_gather_scatters_p): Convert the offset to the\n+\telement type of the gs_info's offset_vectype.\n+\t(vect_get_gather_scatter_ops): Get the offset vector type directly\n+\tfrom the gs_info.\n+\t(vect_get_strided_load_store_ops): Likewise.\n+\t(vectorizable_load): Pass a zero of the result type to IFN_GATHER_LOAD\n+\tand IFN_MASK_GATHER_LOAD.\n+\t* config/aarch64/aarch64-sve.md (gather_load<mode>): Rename to...\n+\t(gather_load<mode><v_int_equiv>): ...this.\n+\t(mask_gather_load<mode>): Rename to...\n+\t(mask_gather_load<mode><v_int_equiv>): ...this.\n+\t(scatter_store<mode>): Rename to...\n+\t(scatter_store<mode><v_int_equiv>): ...this.\n+\t(mask_scatter_store<mode>): Rename to...\n+\t(mask_scatter_store<mode><v_int_equiv>): ...this.\n+\n 2019-11-08  Kewen Lin  <linkw@gcc.gnu.org>\n \n \tPR target/92132"}, {"sha": "e12882ff3995541064204dfc1eb1b83a7d04c11d", "filename": "gcc/config/aarch64/aarch64-sve-builtins-base.cc", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Fconfig%2Faarch64%2Faarch64-sve-builtins-base.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Fconfig%2Faarch64%2Faarch64-sve-builtins-base.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-sve-builtins-base.cc?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -1076,7 +1076,9 @@ class svld1_gather_impl : public full_width_access\n     /* Put the predicate last, as required by mask_gather_load_optab.  */\n     e.rotate_inputs_left (0, 5);\n     machine_mode mem_mode = e.memory_vector_mode ();\n-    insn_code icode = direct_optab_handler (mask_gather_load_optab, mem_mode);\n+    machine_mode int_mode = aarch64_sve_int_mode (mem_mode);\n+    insn_code icode = convert_optab_handler (mask_gather_load_optab,\n+\t\t\t\t\t     mem_mode, int_mode);\n     return e.use_exact_insn (icode);\n   }\n };\n@@ -2043,8 +2045,10 @@ class svst1_scatter_impl : public full_width_access\n     e.prepare_gather_address_operands (1);\n     /* Put the predicate last, as required by mask_scatter_store_optab.  */\n     e.rotate_inputs_left (0, 6);\n-    insn_code icode = direct_optab_handler (mask_scatter_store_optab,\n-\t\t\t\t\t    e.memory_vector_mode ());\n+    machine_mode mem_mode = e.memory_vector_mode ();\n+    machine_mode int_mode = aarch64_sve_int_mode (mem_mode);\n+    insn_code icode = convert_optab_handler (mask_scatter_store_optab,\n+\t\t\t\t\t     mem_mode, int_mode);\n     return e.use_exact_insn (icode);\n   }\n };"}, {"sha": "51e876aaa74180468c1907c161e9c09e5ac4189b", "filename": "gcc/config/aarch64/aarch64-sve.md", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -1336,7 +1336,7 @@\n ;; -------------------------------------------------------------------------\n \n ;; Unpredicated gather loads.\n-(define_expand \"gather_load<mode>\"\n+(define_expand \"gather_load<mode><v_int_equiv>\"\n   [(set (match_operand:SVE_SD 0 \"register_operand\")\n \t(unspec:SVE_SD\n \t  [(match_dup 5)\n@@ -1354,7 +1354,7 @@\n \n ;; Predicated gather loads for 32-bit elements.  Operand 3 is true for\n ;; unsigned extension and false for signed extension.\n-(define_insn \"mask_gather_load<mode>\"\n+(define_insn \"mask_gather_load<mode><v_int_equiv>\"\n   [(set (match_operand:SVE_S 0 \"register_operand\" \"=w, w, w, w, w, w\")\n \t(unspec:SVE_S\n \t  [(match_operand:VNx4BI 5 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl, Upl\")\n@@ -1376,7 +1376,7 @@\n \n ;; Predicated gather loads for 64-bit elements.  The value of operand 3\n ;; doesn't matter in this case.\n-(define_insn \"mask_gather_load<mode>\"\n+(define_insn \"mask_gather_load<mode><v_int_equiv>\"\n   [(set (match_operand:SVE_D 0 \"register_operand\" \"=w, w, w, w\")\n \t(unspec:SVE_D\n \t  [(match_operand:VNx2BI 5 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n@@ -1395,7 +1395,7 @@\n )\n \n ;; Likewise, but with the offset being sign-extended from 32 bits.\n-(define_insn \"*mask_gather_load<mode>_sxtw\"\n+(define_insn \"*mask_gather_load<mode><v_int_equiv>_sxtw\"\n   [(set (match_operand:SVE_D 0 \"register_operand\" \"=w, w\")\n \t(unspec:SVE_D\n \t  [(match_operand:VNx2BI 5 \"register_operand\" \"Upl, Upl\")\n@@ -1417,7 +1417,7 @@\n )\n \n ;; Likewise, but with the offset being zero-extended from 32 bits.\n-(define_insn \"*mask_gather_load<mode>_uxtw\"\n+(define_insn \"*mask_gather_load<mode><v_int_equiv>_uxtw\"\n   [(set (match_operand:SVE_D 0 \"register_operand\" \"=w, w\")\n \t(unspec:SVE_D\n \t  [(match_operand:VNx2BI 5 \"register_operand\" \"Upl, Upl\")\n@@ -2054,7 +2054,7 @@\n ;; -------------------------------------------------------------------------\n \n ;; Unpredicated scatter stores.\n-(define_expand \"scatter_store<mode>\"\n+(define_expand \"scatter_store<mode><v_int_equiv>\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n \t  [(match_dup 5)\n@@ -2072,7 +2072,7 @@\n \n ;; Predicated scatter stores for 32-bit elements.  Operand 2 is true for\n ;; unsigned extension and false for signed extension.\n-(define_insn \"mask_scatter_store<mode>\"\n+(define_insn \"mask_scatter_store<mode><v_int_equiv>\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n \t  [(match_operand:VNx4BI 5 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl, Upl\")\n@@ -2094,7 +2094,7 @@\n \n ;; Predicated scatter stores for 64-bit elements.  The value of operand 2\n ;; doesn't matter in this case.\n-(define_insn \"mask_scatter_store<mode>\"\n+(define_insn \"mask_scatter_store<mode><v_int_equiv>\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n \t  [(match_operand:VNx2BI 5 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n@@ -2113,7 +2113,7 @@\n )\n \n ;; Likewise, but with the offset being sign-extended from 32 bits.\n-(define_insn_and_rewrite \"*mask_scatter_store<mode>_sxtw\"\n+(define_insn_and_rewrite \"*mask_scatter_store<mode><v_int_equiv>_sxtw\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n \t  [(match_operand:VNx2BI 5 \"register_operand\" \"Upl, Upl\")\n@@ -2139,7 +2139,7 @@\n )\n \n ;; Likewise, but with the offset being zero-extended from 32 bits.\n-(define_insn \"*mask_scatter_store<mode>_uxtw\"\n+(define_insn \"*mask_scatter_store<mode><v_int_equiv>_uxtw\"\n   [(set (mem:BLK (scratch))\n \t(unspec:BLK\n \t  [(match_operand:VNx2BI 5 \"register_operand\" \"Upl, Upl\")"}, {"sha": "87bbeb4bfc957a8a06bd67fcef74d9f754e8db3c", "filename": "gcc/doc/md.texi", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Fdoc%2Fmd.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Fdoc%2Fmd.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fmd.texi?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -4959,12 +4959,12 @@ for (j = 0; j < GET_MODE_NUNITS (@var{n}); j++)\n \n This pattern is not allowed to @code{FAIL}.\n \n-@cindex @code{gather_load@var{m}} instruction pattern\n-@item @samp{gather_load@var{m}}\n+@cindex @code{gather_load@var{m}@var{n}} instruction pattern\n+@item @samp{gather_load@var{m}@var{n}}\n Load several separate memory locations into a vector of mode @var{m}.\n-Operand 1 is a scalar base address and operand 2 is a vector of\n-offsets from that base.  Operand 0 is a destination vector with the\n-same number of elements as the offset.  For each element index @var{i}:\n+Operand 1 is a scalar base address and operand 2 is a vector of mode @var{n}\n+containing offsets from that base.  Operand 0 is a destination vector with\n+the same number of elements as @var{n}.  For each element index @var{i}:\n \n @itemize @bullet\n @item\n@@ -4981,20 +4981,20 @@ load the value at that address into element @var{i} of operand 0.\n The value of operand 3 does not matter if the offsets are already\n address width.\n \n-@cindex @code{mask_gather_load@var{m}} instruction pattern\n-@item @samp{mask_gather_load@var{m}}\n-Like @samp{gather_load@var{m}}, but takes an extra mask operand as\n+@cindex @code{mask_gather_load@var{m}@var{n}} instruction pattern\n+@item @samp{mask_gather_load@var{m}@var{n}}\n+Like @samp{gather_load@var{m}@var{n}}, but takes an extra mask operand as\n operand 5.  Bit @var{i} of the mask is set if element @var{i}\n of the result should be loaded from memory and clear if element @var{i}\n of the result should be set to zero.\n \n-@cindex @code{scatter_store@var{m}} instruction pattern\n-@item @samp{scatter_store@var{m}}\n+@cindex @code{scatter_store@var{m}@var{n}} instruction pattern\n+@item @samp{scatter_store@var{m}@var{n}}\n Store a vector of mode @var{m} into several distinct memory locations.\n-Operand 0 is a scalar base address and operand 1 is a vector of offsets\n-from that base.  Operand 4 is the vector of values that should be stored,\n-which has the same number of elements as the offset.  For each element\n-index @var{i}:\n+Operand 0 is a scalar base address and operand 1 is a vector of mode\n+@var{n} containing offsets from that base.  Operand 4 is the vector of\n+values that should be stored, which has the same number of elements as\n+@var{n}.  For each element index @var{i}:\n \n @itemize @bullet\n @item\n@@ -5011,9 +5011,9 @@ store element @var{i} of operand 4 to that address.\n The value of operand 2 does not matter if the offsets are already\n address width.\n \n-@cindex @code{mask_scatter_store@var{m}} instruction pattern\n-@item @samp{mask_scatter_store@var{m}}\n-Like @samp{scatter_store@var{m}}, but takes an extra mask operand as\n+@cindex @code{mask_scatter_store@var{m}@var{n}} instruction pattern\n+@item @samp{mask_scatter_store@var{m}@var{n}}\n+Like @samp{scatter_store@var{m}@var{n}}, but takes an extra mask operand as\n operand 5.  Bit @var{i} of the mask is set if element @var{i}\n of the result should be stored to memory.\n "}, {"sha": "6a878bde24d65c84938ac6e6880aff4efe847784", "filename": "gcc/internal-fn.c", "status": "modified", "additions": 22, "deletions": 19, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Finternal-fn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Finternal-fn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Finternal-fn.c?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -103,11 +103,11 @@ init_internal_fns ()\n #define mask_load_direct { -1, 2, false }\n #define load_lanes_direct { -1, -1, false }\n #define mask_load_lanes_direct { -1, -1, false }\n-#define gather_load_direct { -1, -1, false }\n+#define gather_load_direct { 3, 1, false }\n #define mask_store_direct { 3, 2, false }\n #define store_lanes_direct { 0, 0, false }\n #define mask_store_lanes_direct { 0, 0, false }\n-#define scatter_store_direct { 3, 3, false }\n+#define scatter_store_direct { 3, 1, false }\n #define unary_direct { 0, 0, true }\n #define binary_direct { 0, 0, true }\n #define ternary_direct { 0, 0, true }\n@@ -2785,7 +2785,8 @@ expand_scatter_store_optab_fn (internal_fn, gcall *stmt, direct_optab optab)\n       create_input_operand (&ops[i++], mask_rtx, TYPE_MODE (TREE_TYPE (mask)));\n     }\n \n-  insn_code icode = direct_optab_handler (optab, TYPE_MODE (TREE_TYPE (rhs)));\n+  insn_code icode = convert_optab_handler (optab, TYPE_MODE (TREE_TYPE (rhs)),\n+\t\t\t\t\t   TYPE_MODE (TREE_TYPE (offset)));\n   expand_insn (icode, i, ops);\n }\n \n@@ -2813,11 +2814,12 @@ expand_gather_load_optab_fn (internal_fn, gcall *stmt, direct_optab optab)\n   create_integer_operand (&ops[i++], scale_int);\n   if (optab == mask_gather_load_optab)\n     {\n-      tree mask = gimple_call_arg (stmt, 3);\n+      tree mask = gimple_call_arg (stmt, 4);\n       rtx mask_rtx = expand_normal (mask);\n       create_input_operand (&ops[i++], mask_rtx, TYPE_MODE (TREE_TYPE (mask)));\n     }\n-  insn_code icode = direct_optab_handler (optab, TYPE_MODE (TREE_TYPE (lhs)));\n+  insn_code icode = convert_optab_handler (optab, TYPE_MODE (TREE_TYPE (lhs)),\n+\t\t\t\t\t   TYPE_MODE (TREE_TYPE (offset)));\n   expand_insn (icode, i, ops);\n }\n \n@@ -3084,11 +3086,11 @@ multi_vector_optab_supported_p (convert_optab optab, tree_pair types,\n #define direct_mask_load_optab_supported_p direct_optab_supported_p\n #define direct_load_lanes_optab_supported_p multi_vector_optab_supported_p\n #define direct_mask_load_lanes_optab_supported_p multi_vector_optab_supported_p\n-#define direct_gather_load_optab_supported_p direct_optab_supported_p\n+#define direct_gather_load_optab_supported_p convert_optab_supported_p\n #define direct_mask_store_optab_supported_p direct_optab_supported_p\n #define direct_store_lanes_optab_supported_p multi_vector_optab_supported_p\n #define direct_mask_store_lanes_optab_supported_p multi_vector_optab_supported_p\n-#define direct_scatter_store_optab_supported_p direct_optab_supported_p\n+#define direct_scatter_store_optab_supported_p convert_optab_supported_p\n #define direct_while_optab_supported_p convert_optab_supported_p\n #define direct_fold_extract_optab_supported_p direct_optab_supported_p\n #define direct_fold_left_optab_supported_p direct_optab_supported_p\n@@ -3513,8 +3515,6 @@ internal_fn_mask_index (internal_fn fn)\n       return 2;\n \n     case IFN_MASK_GATHER_LOAD:\n-      return 3;\n-\n     case IFN_MASK_SCATTER_STORE:\n       return 4;\n \n@@ -3546,27 +3546,30 @@ internal_fn_stored_value_index (internal_fn fn)\n    IFN.  For loads, VECTOR_TYPE is the vector type of the load result,\n    while for stores it is the vector type of the stored data argument.\n    MEMORY_ELEMENT_TYPE is the type of the memory elements being loaded\n-   or stored.  OFFSET_SIGN is the sign of the offset argument, which is\n-   only relevant when the offset is narrower than an address.  SCALE is\n-   the amount by which the offset should be multiplied *after* it has\n-   been extended to address width.  */\n+   or stored.  OFFSET_VECTOR_TYPE is the vector type that holds the\n+   offset from the shared base address of each loaded or stored element.\n+   SCALE is the amount by which these offsets should be multiplied\n+   *after* they have been extended to address width.  */\n \n bool\n internal_gather_scatter_fn_supported_p (internal_fn ifn, tree vector_type,\n \t\t\t\t\ttree memory_element_type,\n-\t\t\t\t\tsignop offset_sign, int scale)\n+\t\t\t\t\ttree offset_vector_type, int scale)\n {\n   if (!tree_int_cst_equal (TYPE_SIZE (TREE_TYPE (vector_type)),\n \t\t\t   TYPE_SIZE (memory_element_type)))\n     return false;\n+  if (maybe_ne (TYPE_VECTOR_SUBPARTS (vector_type),\n+\t\tTYPE_VECTOR_SUBPARTS (offset_vector_type)))\n+    return false;\n   optab optab = direct_internal_fn_optab (ifn);\n-  insn_code icode = direct_optab_handler (optab, TYPE_MODE (vector_type));\n+  insn_code icode = convert_optab_handler (optab, TYPE_MODE (vector_type),\n+\t\t\t\t\t   TYPE_MODE (offset_vector_type));\n   int output_ops = internal_load_fn_p (ifn) ? 1 : 0;\n+  bool unsigned_p = TYPE_UNSIGNED (TREE_TYPE (offset_vector_type));\n   return (icode != CODE_FOR_nothing\n-\t  && insn_operand_matches (icode, 2 + output_ops,\n-\t\t\t\t   GEN_INT (offset_sign == UNSIGNED))\n-\t  && insn_operand_matches (icode, 3 + output_ops,\n-\t\t\t\t   GEN_INT (scale)));\n+\t  && insn_operand_matches (icode, 2 + output_ops, GEN_INT (unsigned_p))\n+\t  && insn_operand_matches (icode, 3 + output_ops, GEN_INT (scale)));\n }\n \n /* Expand STMT as though it were a call to internal function FN.  */"}, {"sha": "389241a8a0679b991a30ae34d6ca590c4fda515b", "filename": "gcc/internal-fn.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Finternal-fn.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Finternal-fn.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Finternal-fn.h?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -220,7 +220,7 @@ extern bool internal_gather_scatter_fn_p (internal_fn);\n extern int internal_fn_mask_index (internal_fn);\n extern int internal_fn_stored_value_index (internal_fn);\n extern bool internal_gather_scatter_fn_supported_p (internal_fn, tree,\n-\t\t\t\t\t\t    tree, signop, int);\n+\t\t\t\t\t\t    tree, tree, int);\n \n extern void expand_internal_call (gcall *);\n extern void expand_internal_call (internal_fn, gcall *);"}, {"sha": "6465b5cf6c55819121428ba39b0ba1e2a3c3774e", "filename": "gcc/optabs-query.c", "status": "modified", "additions": 10, "deletions": 6, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Foptabs-query.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Foptabs-query.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs-query.c?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -698,14 +698,18 @@ lshift_cheap_p (bool speed_p)\n   return cheap[speed_p];\n }\n \n-/* Return true if optab OP supports at least one mode.  */\n+/* Return true if vector conversion optab OP supports at least one mode,\n+   given that the second mode is always an integer vector.  */\n \n static bool\n-supports_at_least_one_mode_p (optab op)\n+supports_vec_convert_optab_p (optab op)\n {\n   for (int i = 0; i < NUM_MACHINE_MODES; ++i)\n-    if (direct_optab_handler (op, (machine_mode) i) != CODE_FOR_nothing)\n-      return true;\n+    if (VECTOR_MODE_P ((machine_mode) i))\n+      for (int j = MIN_MODE_VECTOR_INT; j < MAX_MODE_VECTOR_INT; ++j)\n+\tif (convert_optab_handler (op, (machine_mode) i,\n+\t\t\t\t   (machine_mode) j) != CODE_FOR_nothing)\n+\t  return true;\n \n   return false;\n }\n@@ -722,7 +726,7 @@ supports_vec_gather_load_p ()\n   this_fn_optabs->supports_vec_gather_load_cached = true;\n \n   this_fn_optabs->supports_vec_gather_load\n-    = supports_at_least_one_mode_p (gather_load_optab);\n+    = supports_vec_convert_optab_p (gather_load_optab);\n \n   return this_fn_optabs->supports_vec_gather_load;\n }\n@@ -739,7 +743,7 @@ supports_vec_scatter_store_p ()\n   this_fn_optabs->supports_vec_scatter_store_cached = true;\n \n   this_fn_optabs->supports_vec_scatter_store\n-    = supports_at_least_one_mode_p (scatter_store_optab);\n+    = supports_vec_convert_optab_p (scatter_store_optab);\n \n   return this_fn_optabs->supports_vec_scatter_store;\n }"}, {"sha": "90e177a5cc093fda7dee0274fb27456f04ad8dbd", "filename": "gcc/optabs.def", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Foptabs.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Foptabs.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.def?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -91,6 +91,10 @@ OPTAB_CD(vec_cmpu_optab, \"vec_cmpu$a$b\")\n OPTAB_CD(vec_cmpeq_optab, \"vec_cmpeq$a$b\")\n OPTAB_CD(maskload_optab, \"maskload$a$b\")\n OPTAB_CD(maskstore_optab, \"maskstore$a$b\")\n+OPTAB_CD(gather_load_optab, \"gather_load$a$b\")\n+OPTAB_CD(mask_gather_load_optab, \"mask_gather_load$a$b\")\n+OPTAB_CD(scatter_store_optab, \"scatter_store$a$b\")\n+OPTAB_CD(mask_scatter_store_optab, \"mask_scatter_store$a$b\")\n OPTAB_CD(vec_extract_optab, \"vec_extract$a$b\")\n OPTAB_CD(vec_init_optab, \"vec_init$a$b\")\n \n@@ -425,11 +429,6 @@ OPTAB_D (atomic_xor_optab, \"atomic_xor$I$a\")\n OPTAB_D (get_thread_pointer_optab, \"get_thread_pointer$I$a\")\n OPTAB_D (set_thread_pointer_optab, \"set_thread_pointer$I$a\")\n \n-OPTAB_D (gather_load_optab, \"gather_load$a\")\n-OPTAB_D (mask_gather_load_optab, \"mask_gather_load$a\")\n-OPTAB_D (scatter_store_optab, \"scatter_store$a\")\n-OPTAB_D (mask_scatter_store_optab, \"mask_scatter_store$a\")\n-\n OPTAB_DC (vec_duplicate_optab, \"vec_duplicate$a\", VEC_DUPLICATE)\n OPTAB_DC (vec_series_optab, \"vec_series$a\", VEC_SERIES)\n OPTAB_D (vec_shl_insert_optab, \"vec_shl_insert_$a\")"}, {"sha": "36639b697f1367eeb0bea466ea329996f0252a66", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 58, "deletions": 43, "changes": 101, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -3660,28 +3660,22 @@ vect_prune_runtime_alias_test_list (loop_vec_info loop_vinfo)\n /* Check whether we can use an internal function for a gather load\n    or scatter store.  READ_P is true for loads and false for stores.\n    MASKED_P is true if the load or store is conditional.  MEMORY_TYPE is\n-   the type of the memory elements being loaded or stored.  OFFSET_BITS\n-   is the number of bits in each scalar offset and OFFSET_SIGN is the\n-   sign of the offset.  SCALE is the amount by which the offset should\n+   the type of the memory elements being loaded or stored.  OFFSET_TYPE\n+   is the type of the offset that is being applied to the invariant\n+   base address.  SCALE is the amount by which the offset should\n    be multiplied *after* it has been converted to address width.\n \n-   Return true if the function is supported, storing the function\n-   id in *IFN_OUT and the type of a vector element in *ELEMENT_TYPE_OUT.  */\n+   Return true if the function is supported, storing the function id in\n+   *IFN_OUT and the vector type for the offset in *OFFSET_VECTYPE_OUT.  */\n \n bool\n-vect_gather_scatter_fn_p (bool read_p, bool masked_p, tree vectype,\n-\t\t\t  tree memory_type, unsigned int offset_bits,\n-\t\t\t  signop offset_sign, int scale,\n-\t\t\t  internal_fn *ifn_out, tree *element_type_out)\n+vect_gather_scatter_fn_p (vec_info *vinfo, bool read_p, bool masked_p,\n+\t\t\t  tree vectype, tree memory_type, tree offset_type,\n+\t\t\t  int scale, internal_fn *ifn_out,\n+\t\t\t  tree *offset_vectype_out)\n {\n   unsigned int memory_bits = tree_to_uhwi (TYPE_SIZE (memory_type));\n   unsigned int element_bits = tree_to_uhwi (TYPE_SIZE (TREE_TYPE (vectype)));\n-  if (offset_bits > element_bits)\n-    /* Internal functions require the offset to be the same width as\n-       the vector elements.  We can extend narrower offsets, but it isn't\n-       safe to truncate wider offsets.  */\n-    return false;\n-\n   if (element_bits != memory_bits)\n     /* For now the vector elements must be the same width as the\n        memory elements.  */\n@@ -3694,14 +3688,28 @@ vect_gather_scatter_fn_p (bool read_p, bool masked_p, tree vectype,\n   else\n     ifn = masked_p ? IFN_MASK_SCATTER_STORE : IFN_SCATTER_STORE;\n \n-  /* Test whether the target supports this combination.  */\n-  if (!internal_gather_scatter_fn_supported_p (ifn, vectype, memory_type,\n-\t\t\t\t\t       offset_sign, scale))\n-    return false;\n+  for (;;)\n+    {\n+      tree offset_vectype = get_vectype_for_scalar_type (vinfo, offset_type);\n+      if (!offset_vectype)\n+\treturn false;\n \n-  *ifn_out = ifn;\n-  *element_type_out = TREE_TYPE (vectype);\n-  return true;\n+      /* Test whether the target supports this combination.  */\n+      if (internal_gather_scatter_fn_supported_p (ifn, vectype, memory_type,\n+\t\t\t\t\t\t  offset_vectype, scale))\n+\t{\n+\t  *ifn_out = ifn;\n+\t  *offset_vectype_out = offset_vectype;\n+\t  return true;\n+\t}\n+\n+      if (TYPE_PRECISION (offset_type) >= POINTER_SIZE\n+\t  && TYPE_PRECISION (offset_type) >= element_bits)\n+\treturn false;\n+\n+      offset_type = build_nonstandard_integer_type\n+\t(TYPE_PRECISION (offset_type) * 2, TYPE_UNSIGNED (offset_type));\n+    }\n }\n \n /* STMT_INFO is a call to an internal gather load or scatter store function.\n@@ -3744,7 +3752,7 @@ vect_check_gather_scatter (stmt_vec_info stmt_info, loop_vec_info loop_vinfo,\n   machine_mode pmode;\n   int punsignedp, reversep, pvolatilep = 0;\n   internal_fn ifn;\n-  tree element_type;\n+  tree offset_vectype;\n   bool masked_p = false;\n \n   /* See whether this is already a call to a gather/scatter internal function.\n@@ -3905,13 +3913,18 @@ vect_check_gather_scatter (stmt_vec_info stmt_info, loop_vec_info loop_vinfo,\n \t    {\n \t      int new_scale = tree_to_shwi (op1);\n \t      /* Only treat this as a scaling operation if the target\n-\t\t supports it.  */\n+\t\t supports it for at least some offset type.  */\n \t      if (use_ifn_p\n-\t\t  && !vect_gather_scatter_fn_p (DR_IS_READ (dr), masked_p,\n-\t\t\t\t\t\tvectype, memory_type, 1,\n-\t\t\t\t\t\tTYPE_SIGN (TREE_TYPE (op0)),\n+\t\t  && !vect_gather_scatter_fn_p (loop_vinfo, DR_IS_READ (dr),\n+\t\t\t\t\t\tmasked_p, vectype, memory_type,\n+\t\t\t\t\t\tsigned_char_type_node,\n+\t\t\t\t\t\tnew_scale, &ifn,\n+\t\t\t\t\t\t&offset_vectype)\n+\t\t  && !vect_gather_scatter_fn_p (loop_vinfo, DR_IS_READ (dr),\n+\t\t\t\t\t\tmasked_p, vectype, memory_type,\n+\t\t\t\t\t\tunsigned_char_type_node,\n \t\t\t\t\t\tnew_scale, &ifn,\n-\t\t\t\t\t\t&element_type))\n+\t\t\t\t\t\t&offset_vectype))\n \t\tbreak;\n \t      scale = new_scale;\n \t      off = op0;\n@@ -3925,21 +3938,23 @@ vect_check_gather_scatter (stmt_vec_info stmt_info, loop_vec_info loop_vinfo,\n \t  if (!POINTER_TYPE_P (TREE_TYPE (op0))\n \t      && !INTEGRAL_TYPE_P (TREE_TYPE (op0)))\n \t    break;\n+\n+\t  /* Don't include the conversion if the target is happy with\n+\t     the current offset type.  */\n+\t  if (use_ifn_p\n+\t      && vect_gather_scatter_fn_p (loop_vinfo, DR_IS_READ (dr),\n+\t\t\t\t\t   masked_p, vectype, memory_type,\n+\t\t\t\t\t   TREE_TYPE (off), scale, &ifn,\n+\t\t\t\t\t   &offset_vectype))\n+\t    break;\n+\n \t  if (TYPE_PRECISION (TREE_TYPE (op0))\n \t      == TYPE_PRECISION (TREE_TYPE (off)))\n \t    {\n \t      off = op0;\n \t      continue;\n \t    }\n \n-\t  /* The internal functions need the offset to be the same width\n-\t     as the elements of VECTYPE.  Don't include operations that\n-\t     cast the offset from that width to a different width.  */\n-\t  if (use_ifn_p\n-\t      && (int_size_in_bytes (TREE_TYPE (vectype))\n-\t\t  == int_size_in_bytes (TREE_TYPE (off))))\n-\t    break;\n-\n \t  if (TYPE_PRECISION (TREE_TYPE (op0))\n \t      < TYPE_PRECISION (TREE_TYPE (off)))\n \t    {\n@@ -3966,10 +3981,9 @@ vect_check_gather_scatter (stmt_vec_info stmt_info, loop_vec_info loop_vinfo,\n \n   if (use_ifn_p)\n     {\n-      if (!vect_gather_scatter_fn_p (DR_IS_READ (dr), masked_p, vectype,\n-\t\t\t\t     memory_type, TYPE_PRECISION (offtype),\n-\t\t\t\t     TYPE_SIGN (offtype), scale, &ifn,\n-\t\t\t\t     &element_type))\n+      if (!vect_gather_scatter_fn_p (loop_vinfo, DR_IS_READ (dr), masked_p,\n+\t\t\t\t     vectype, memory_type, offtype, scale,\n+\t\t\t\t     &ifn, &offset_vectype))\n \treturn false;\n     }\n   else\n@@ -3989,17 +4003,18 @@ vect_check_gather_scatter (stmt_vec_info stmt_info, loop_vec_info loop_vinfo,\n \treturn false;\n \n       ifn = IFN_LAST;\n-      element_type = TREE_TYPE (vectype);\n+      /* The offset vector type will be read from DECL when needed.  */\n+      offset_vectype = NULL_TREE;\n     }\n \n   info->ifn = ifn;\n   info->decl = decl;\n   info->base = base;\n   info->offset = off;\n   info->offset_dt = vect_unknown_def_type;\n-  info->offset_vectype = NULL_TREE;\n+  info->offset_vectype = offset_vectype;\n   info->scale = scale;\n-  info->element_type = element_type;\n+  info->element_type = TREE_TYPE (vectype);\n   info->memory_type = memory_type;\n   return true;\n }"}, {"sha": "8ebbcd76b64b83764511ecbe9996568d2fabca74", "filename": "gcc/tree-vect-patterns.c", "status": "modified", "additions": 6, "deletions": 27, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Ftree-vect-patterns.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Ftree-vect-patterns.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-patterns.c?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -4498,28 +4498,6 @@ vect_get_load_store_mask (stmt_vec_info stmt_info)\n   gcc_unreachable ();\n }\n \n-/* Return the scalar offset type that an internal gather/scatter function\n-   should use.  GS_INFO describes the gather/scatter operation.  */\n-\n-static tree\n-vect_get_gather_scatter_offset_type (gather_scatter_info *gs_info)\n-{\n-  tree offset_type = TREE_TYPE (gs_info->offset);\n-  unsigned int element_bits = tree_to_uhwi (TYPE_SIZE (gs_info->element_type));\n-\n-  /* Enforced by vect_check_gather_scatter.  */\n-  unsigned int offset_bits = TYPE_PRECISION (offset_type);\n-  gcc_assert (element_bits >= offset_bits);\n-\n-  /* If the offset is narrower than the elements, extend it according\n-     to its sign.  */\n-  if (element_bits > offset_bits)\n-    return build_nonstandard_integer_type (element_bits,\n-\t\t\t\t\t   TYPE_UNSIGNED (offset_type));\n-\n-  return offset_type;\n-}\n-\n /* Return MASK if MASK is suitable for masking an operation on vectors\n    of type VECTYPE, otherwise convert it into such a form and return\n    the result.  Associate any conversion statements with STMT_INFO's\n@@ -4604,7 +4582,7 @@ vect_recog_gather_scatter_pattern (stmt_vec_info stmt_info, tree *type_out)\n   /* Get the invariant base and non-invariant offset, converting the\n      latter to the same width as the vector elements.  */\n   tree base = gs_info.base;\n-  tree offset_type = vect_get_gather_scatter_offset_type (&gs_info);\n+  tree offset_type = TREE_TYPE (gs_info.offset_vectype);\n   tree offset = vect_add_conversion_to_pattern (offset_type, gs_info.offset,\n \t\t\t\t\t\tstmt_info);\n \n@@ -4613,12 +4591,13 @@ vect_recog_gather_scatter_pattern (stmt_vec_info stmt_info, tree *type_out)\n   gcall *pattern_stmt;\n   if (DR_IS_READ (dr))\n     {\n+      tree zero = build_zero_cst (gs_info.element_type);\n       if (mask != NULL)\n-\tpattern_stmt = gimple_build_call_internal (gs_info.ifn, 4, base,\n-\t\t\t\t\t\t   offset, scale, mask);\n+\tpattern_stmt = gimple_build_call_internal (gs_info.ifn, 5, base,\n+\t\t\t\t\t\t   offset, scale, zero, mask);\n       else\n-\tpattern_stmt = gimple_build_call_internal (gs_info.ifn, 3, base,\n-\t\t\t\t\t\t   offset, scale);\n+\tpattern_stmt = gimple_build_call_internal (gs_info.ifn, 4, base,\n+\t\t\t\t\t\t   offset, scale, zero);\n       tree load_lhs = vect_recog_temp_ssa_var (gs_info.element_type, NULL);\n       gimple_call_set_lhs (pattern_stmt, load_lhs);\n     }"}, {"sha": "2bbc783ffe085d6b624bcdfb7262a0d2125aedc5", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 27, "deletions": 43, "changes": 70, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -1910,10 +1910,9 @@ check_load_store_masking (loop_vec_info loop_vinfo, tree vectype,\n       internal_fn ifn = (is_load\n \t\t\t ? IFN_MASK_GATHER_LOAD\n \t\t\t : IFN_MASK_SCATTER_STORE);\n-      tree offset_type = TREE_TYPE (gs_info->offset);\n       if (!internal_gather_scatter_fn_supported_p (ifn, vectype,\n \t\t\t\t\t\t   gs_info->memory_type,\n-\t\t\t\t\t\t   TYPE_SIGN (offset_type),\n+\t\t\t\t\t\t   gs_info->offset_vectype,\n \t\t\t\t\t\t   gs_info->scale))\n \t{\n \t  if (dump_enabled_p ())\n@@ -2046,35 +2045,33 @@ vect_truncate_gather_scatter_offset (stmt_vec_info stmt_info,\n       if (!wi::multiple_of_p (wi::to_widest (step), scale, SIGNED, &factor))\n \tcontinue;\n \n-      /* See whether we can calculate (COUNT - 1) * STEP / SCALE\n-\t in OFFSET_BITS bits.  */\n+      /* Determine the minimum precision of (COUNT - 1) * STEP / SCALE.  */\n       widest_int range = wi::mul (count, factor, SIGNED, &overflow);\n       if (overflow)\n \tcontinue;\n       signop sign = range >= 0 ? UNSIGNED : SIGNED;\n-      if (wi::min_precision (range, sign) > element_bits)\n-\t{\n-\t  overflow = wi::OVF_UNKNOWN;\n-\t  continue;\n-\t}\n+      unsigned int min_offset_bits = wi::min_precision (range, sign);\n \n-      /* See whether the target supports the operation.  */\n+      /* Find the narrowest viable offset type.  */\n+      unsigned int offset_bits = 1U << ceil_log2 (min_offset_bits);\n+      tree offset_type = build_nonstandard_integer_type (offset_bits,\n+\t\t\t\t\t\t\t sign == UNSIGNED);\n+\n+      /* See whether the target supports the operation with an offset\n+\t no narrower than OFFSET_TYPE.  */\n       tree memory_type = TREE_TYPE (DR_REF (dr));\n-      if (!vect_gather_scatter_fn_p (DR_IS_READ (dr), masked_p, vectype,\n-\t\t\t\t     memory_type, element_bits, sign, scale,\n-\t\t\t\t     &gs_info->ifn, &gs_info->element_type))\n+      if (!vect_gather_scatter_fn_p (loop_vinfo, DR_IS_READ (dr), masked_p,\n+\t\t\t\t     vectype, memory_type, offset_type, scale,\n+\t\t\t\t     &gs_info->ifn, &gs_info->offset_vectype))\n \tcontinue;\n \n-      tree offset_type = build_nonstandard_integer_type (element_bits,\n-\t\t\t\t\t\t\t sign == UNSIGNED);\n-\n       gs_info->decl = NULL_TREE;\n       /* Logically the sum of DR_BASE_ADDRESS, DR_INIT and DR_OFFSET,\n \t but we don't need to store that here.  */\n       gs_info->base = NULL_TREE;\n+      gs_info->element_type = TREE_TYPE (vectype);\n       gs_info->offset = fold_convert (offset_type, step);\n       gs_info->offset_dt = vect_constant_def;\n-      gs_info->offset_vectype = NULL_TREE;\n       gs_info->scale = scale;\n       gs_info->memory_type = memory_type;\n       return true;\n@@ -2104,22 +2101,12 @@ vect_use_strided_gather_scatters_p (stmt_vec_info stmt_info,\n     return vect_truncate_gather_scatter_offset (stmt_info, loop_vinfo,\n \t\t\t\t\t\tmasked_p, gs_info);\n \n-  scalar_mode element_mode = SCALAR_TYPE_MODE (gs_info->element_type);\n-  unsigned int element_bits = GET_MODE_BITSIZE (element_mode);\n-  tree offset_type = TREE_TYPE (gs_info->offset);\n-  unsigned int offset_bits = TYPE_PRECISION (offset_type);\n+  tree old_offset_type = TREE_TYPE (gs_info->offset);\n+  tree new_offset_type = TREE_TYPE (gs_info->offset_vectype);\n \n-  /* Enforced by vect_check_gather_scatter.  */\n-  gcc_assert (element_bits >= offset_bits);\n-\n-  /* If the elements are wider than the offset, convert the offset to the\n-     same width, without changing its sign.  */\n-  if (element_bits > offset_bits)\n-    {\n-      bool unsigned_p = TYPE_UNSIGNED (offset_type);\n-      offset_type = build_nonstandard_integer_type (element_bits, unsigned_p);\n-      gs_info->offset = fold_convert (offset_type, gs_info->offset);\n-    }\n+  gcc_assert (TYPE_PRECISION (new_offset_type)\n+\t      >= TYPE_PRECISION (old_offset_type));\n+  gs_info->offset = fold_convert (new_offset_type, gs_info->offset);\n \n   if (dump_enabled_p ())\n     dump_printf_loc (MSG_NOTE, vect_location,\n@@ -2963,7 +2950,6 @@ vect_get_gather_scatter_ops (class loop *loop, stmt_vec_info stmt_info,\n \t\t\t     gather_scatter_info *gs_info,\n \t\t\t     tree *dataref_ptr, tree *vec_offset)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n   gimple_seq stmts = NULL;\n   *dataref_ptr = force_gimple_operand (gs_info->base, &stmts, true, NULL_TREE);\n   if (stmts != NULL)\n@@ -2973,10 +2959,8 @@ vect_get_gather_scatter_ops (class loop *loop, stmt_vec_info stmt_info,\n       new_bb = gsi_insert_seq_on_edge_immediate (pe, stmts);\n       gcc_assert (!new_bb);\n     }\n-  tree offset_type = TREE_TYPE (gs_info->offset);\n-  tree offset_vectype = get_vectype_for_scalar_type (vinfo, offset_type);\n   *vec_offset = vect_get_vec_def_for_operand (gs_info->offset, stmt_info,\n-\t\t\t\t\t      offset_vectype);\n+\t\t\t\t\t      gs_info->offset_vectype);\n }\n \n /* Prepare to implement a grouped or strided load or store using\n@@ -3009,8 +2993,7 @@ vect_get_strided_load_store_ops (stmt_vec_info stmt_info,\n   /* The offset given in GS_INFO can have pointer type, so use the element\n      type of the vector instead.  */\n   tree offset_type = TREE_TYPE (gs_info->offset);\n-  tree offset_vectype = get_vectype_for_scalar_type (loop_vinfo, offset_type);\n-  offset_type = TREE_TYPE (offset_vectype);\n+  offset_type = TREE_TYPE (gs_info->offset_vectype);\n \n   /* Calculate X = DR_STEP / SCALE and convert it to the appropriate type.  */\n   tree step = size_binop (EXACT_DIV_EXPR, DR_STEP (dr),\n@@ -3019,7 +3002,7 @@ vect_get_strided_load_store_ops (stmt_vec_info stmt_info,\n   step = force_gimple_operand (step, &stmts, true, NULL_TREE);\n \n   /* Create {0, X, X*2, X*3, ...}.  */\n-  *vec_offset = gimple_build (&stmts, VEC_SERIES_EXPR, offset_vectype,\n+  *vec_offset = gimple_build (&stmts, VEC_SERIES_EXPR, gs_info->offset_vectype,\n \t\t\t      build_zero_cst (offset_type), step);\n   if (stmts)\n     gsi_insert_seq_on_edge_immediate (loop_preheader_edge (loop), stmts);\n@@ -9442,16 +9425,17 @@ vectorizable_load (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n \n \t\t    if (memory_access_type == VMAT_GATHER_SCATTER)\n \t\t      {\n+\t\t\ttree zero = build_zero_cst (vectype);\n \t\t\ttree scale = size_int (gs_info.scale);\n \t\t\tgcall *call;\n \t\t\tif (loop_masks)\n \t\t\t  call = gimple_build_call_internal\n-\t\t\t    (IFN_MASK_GATHER_LOAD, 4, dataref_ptr,\n-\t\t\t     vec_offset, scale, final_mask);\n+\t\t\t    (IFN_MASK_GATHER_LOAD, 5, dataref_ptr,\n+\t\t\t     vec_offset, scale, zero, final_mask);\n \t\t\telse\n \t\t\t  call = gimple_build_call_internal\n-\t\t\t    (IFN_GATHER_LOAD, 3, dataref_ptr,\n-\t\t\t     vec_offset, scale);\n+\t\t\t    (IFN_GATHER_LOAD, 4, dataref_ptr,\n+\t\t\t     vec_offset, scale, zero);\n \t\t\tgimple_call_set_nothrow (call, true);\n \t\t\tnew_stmt = call;\n \t\t\tdata_ref = NULL_TREE;"}, {"sha": "96eb1f52927c8e208ee60e6c55cc6bfb776da043", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/09eb042a8a8ee16e8f23085a175be25c8ef68820/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=09eb042a8a8ee16e8f23085a175be25c8ef68820", "patch": "@@ -1678,8 +1678,8 @@ extern opt_result vect_verify_datarefs_alignment (loop_vec_info);\n extern bool vect_slp_analyze_and_verify_instance_alignment (slp_instance);\n extern opt_result vect_analyze_data_ref_accesses (vec_info *);\n extern opt_result vect_prune_runtime_alias_test_list (loop_vec_info);\n-extern bool vect_gather_scatter_fn_p (bool, bool, tree, tree, unsigned int,\n-\t\t\t\t      signop, int, internal_fn *, tree *);\n+extern bool vect_gather_scatter_fn_p (vec_info *, bool, bool, tree, tree,\n+\t\t\t\t      tree, int, internal_fn *, tree *);\n extern bool vect_check_gather_scatter (stmt_vec_info, loop_vec_info,\n \t\t\t\t       gather_scatter_info *);\n extern opt_result vect_find_stmt_data_reference (loop_p, gimple *,"}]}