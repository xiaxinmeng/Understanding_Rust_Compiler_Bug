{"sha": "977e83a3edc1a58077e33143ad3cc1f9349d6197", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTc3ZTgzYTNlZGMxYTU4MDc3ZTMzMTQzYWQzY2MxZjkzNDlkNjE5Nw==", "commit": {"author": {"name": "Kirill Yukhin", "email": "kirill.yukhin@intel.com", "date": "2011-08-22T13:57:18Z"}, "committer": {"name": "H.J. Lu", "email": "hjl@gcc.gnu.org", "date": "2011-08-22T13:57:18Z"}, "message": "Add support for AVX2 builtin functions.\n\n2011-08-22  Kirill Yukhin  <kirill.yukhin@intel.com>\n\n\t* config/i386/avx2intrin.h: New file.\n\t* config/i386/i386-builtin-types.def (PCINT, PCINT64, PV4SI,\n\tPV8SI, V32QI_FTYPE_V32QI, V32QI_FTYPE_V16QI, V16HI_FTYPE_V16HI,\n\tV16HI_FTYPE_V8HI, V8SI_FTYPE_V8SI, V16HI_FTYPE_V16QI,\n\tV8SI_FTYPE_V16QI, V4DI_FTYPE_V16QI, V8SI_FTYPE_V8HI,\n\tV4DI_FTYPE_V8HI, V4DI_FTYPE_V4SI, V4DI_FTYPE_PV4DI,\n\tV4DI_FTYPE_V2DI, V2DI_FTYPE_PCV2DI_V2DI, V4SI_FTYPE_PCV4SI_V4SI,\n\tV32QI_FTYPE_V16HI_V16HI, V16HI_FTYPE_V8SI_V8SI,\n\tV32QI_FTYPE_V32QI_V32QI, V16HI_FTYPE_V32QI_V32QI,\n\tV16HI_FTYPE_V16HI_V8HI, V16HI_FTYPE_V16HI_V16HI,\n\tV16HI_FTYPE_V16HI_INT, V16HI_FTYPE_V16HI_SI,\n\tV16HI_FTYPE_V16HI_V16HI_INT, V32QI_FTYPE_V32QI_V32QI_INT,\n\tV8SI_FTYPE_V8SI_V4SI, V8SI_FTYPE_V8SI_V8SI,\n\tV8SI_FTYPE_V16HI_V16HI, V8SI_FTYPE_V8SI_INT, V8SI_FTYPE_V8SI_SI,\n\tV8SI_FTYPE_PCV8SI_V8SI, V4DI_FTYPE_V4DI_V4DI,\n\tV4DI_FTYPE_V8SI_V8SI, V4DI_FTYPE_V4DI_V2DI,\n\tV4DI_FTYPE_PCV4DI_V4DI, V4DI_FTYPE_V4DI_INT,\n\tV2DI_FTYPE_V4DI_INT, V4DI_FTYPE_V4DI_V4DI_INT,\n\tV4DI_FTYPE_V4DI_V2DI_INT, VOID_FTYPE_PV2DI_V2DI_V2DI,\n\tVOID_FTYPE_PV4DI_V4DI_V4DI, VOID_FTYPE_PV4SI_V4SI_V4SI,\n\tVOID_FTYPE_PV8SI_V8SI_V8SI,\n\tV2DF_FTYPE_V2DF_PCDOUBLE_V4SI_V2DF_INT,\n\tV4DF_FTYPE_V4DF_PCDOUBLE_V4SI_V4DF_INT,\n\tV2DF_FTYPE_V2DF_PCDOUBLE_V2DI_V2DF_INT,\n\tV4DF_FTYPE_V4DF_PCDOUBLE_V4DI_V4DF_INT,\n\tV4SF_FTYPE_V4SF_PCFLOAT_V4SI_V4SF_INT,\n\tV8SF_FTYPE_V8SF_PCFLOAT_V8SI_V8SF_INT,\n\tV4SF_FTYPE_V4SF_PCFLOAT_V2DI_V4SF_INT,\n\tV4SF_FTYPE_V4SF_PCFLOAT_V4DI_V4SF_INT,\n\tV2DI_FTYPE_V2DI_PCINT64_V4SI_V2DI_INT,\n\tV4DI_FTYPE_V4DI_PCINT64_V4SI_V4DI_INT,\n\tV2DI_FTYPE_V2DI_PCINT64_V2DI_V2DI_INT,\n\tV4DI_FTYPE_V4DI_PCINT64_V4DI_V4DI_INT,\n\tV4SI_FTYPE_V4SI_PCINT_V4SI_V4SI_INT,\n\tV8SI_FTYPE_V8SI_PCINT_V8SI_V8SI_INT,\n\tV4SI_FTYPE_V4SI_PCINT_V2DI_V4SI_INT,\n\tV4SI_FTYPE_V4SI_PCINT_V4DI_V4SI_INT,\n\tV16HI_FTYPE_V16HI_SI_COUNT, V16HI_FTYPE_V16HI_V8HI_COUNT,\n\tV8SI_FTYPE_V8SI_SI_COUNT, V8SI_FTYPE_V8SI_V4SI_COUNT,\n\tV4DI_FTYPE_V4DI_INT_COUNT, V4DI_FTYPE_V4DI_V2DI_COUNT,\n\tV4DI_FTYPE_V4DI_INT_CONVERT,\n\tV4DI_FTYPE_V4DI_V4DI_INT_CONVERT): New.\n\t* config/i386/i386.c (ix86_builtins): Add IX86_BUILTIN_MPSADBW256,\n\tIX86_BUILTIN_PABSB256, IX86_BUILTIN_PABSW256,\n\tIX86_BUILTIN_PABSD256, IX86_BUILTIN_PACKSSDW256,\n\tIX86_BUILTIN_PACKSSWB256, IX86_BUILTIN_PACKUSDW256,\n\tIX86_BUILTIN_PACKUSWB256, IX86_BUILTIN_PADDB256,\n\tIX86_BUILTIN_PADDW256, IX86_BUILTIN_PADDD256,\n\tIX86_BUILTIN_PADDQ256, IX86_BUILTIN_PADDSB256,\n\tIX86_BUILTIN_PADDSW256, IX86_BUILTIN_PADDUSB256,\n\tIX86_BUILTIN_PADDUSW256, IX86_BUILTIN_PALIGNR256,\n\tIX86_BUILTIN_AND256I, IX86_BUILTIN_ANDNOT256I,\n\tIX86_BUILTIN_PAVGB256, IX86_BUILTIN_PAVGW256,\n\tIX86_BUILTIN_PBLENDVB256, IX86_BUILTIN_PBLENDVW256,\n\tIX86_BUILTIN_PCMPEQB256, IX86_BUILTIN_PCMPEQW256,\n\tIX86_BUILTIN_PCMPEQD256, IX86_BUILTIN_PCMPEQQ256,\n\tIX86_BUILTIN_PCMPGTB256, IX86_BUILTIN_PCMPGTW256,\n\tIX86_BUILTIN_PCMPGTD256, IX86_BUILTIN_PCMPGTQ256,\n\tIX86_BUILTIN_PHADDW256, IX86_BUILTIN_PHADDD256,\n\tIX86_BUILTIN_PHADDSW256, IX86_BUILTIN_PHSUBW256,\n\tIX86_BUILTIN_PHSUBD256, IX86_BUILTIN_PHSUBSW256,\n\tIX86_BUILTIN_PMADDUBSW256, IX86_BUILTIN_PMADDWD256,\n\tIX86_BUILTIN_PMAXSB256, IX86_BUILTIN_PMAXSW256,\n\tIX86_BUILTIN_PMAXSD256, IX86_BUILTIN_PMAXUB256,\n\tIX86_BUILTIN_PMAXUW256, IX86_BUILTIN_PMAXUD256,\n\tIX86_BUILTIN_PMINSB256, IX86_BUILTIN_PMINSW256,\n\tIX86_BUILTIN_PMINSD256, IX86_BUILTIN_PMINUB256,\n\tIX86_BUILTIN_PMINUW256, IX86_BUILTIN_PMINUD256,\n\tIX86_BUILTIN_PMOVMSKB256, IX86_BUILTIN_PMOVSXBW256,\n\tIX86_BUILTIN_PMOVSXBD256, IX86_BUILTIN_PMOVSXBQ256,\n\tIX86_BUILTIN_PMOVSXWD256, IX86_BUILTIN_PMOVSXWQ256,\n\tIX86_BUILTIN_PMOVSXDQ256, IX86_BUILTIN_PMOVZXBW256,\n\tIX86_BUILTIN_PMOVZXBD256, IX86_BUILTIN_PMOVZXBQ256,\n\tIX86_BUILTIN_PMOVZXWD256, IX86_BUILTIN_PMOVZXWQ256,\n\tIX86_BUILTIN_PMOVZXDQ256, IX86_BUILTIN_PMULDQ256,\n\tIX86_BUILTIN_PMULHRSW256, IX86_BUILTIN_PMULHUW256,\n\tIX86_BUILTIN_PMULHW256, IX86_BUILTIN_PMULLW256,\n\tIX86_BUILTIN_PMULLD256, IX86_BUILTIN_PMULUDQ256,\n\tIX86_BUILTIN_POR256, IX86_BUILTIN_PSADBW256,\n\tIX86_BUILTIN_PSHUFB256, IX86_BUILTIN_PSHUFD256,\n\tIX86_BUILTIN_PSHUFHW256, IX86_BUILTIN_PSHUFLW256,\n\tIX86_BUILTIN_PSIGNB256, IX86_BUILTIN_PSIGNW256,\n\tIX86_BUILTIN_PSIGND256, IX86_BUILTIN_PSLLDQI256,\n\tIX86_BUILTIN_PSLLWI256, IX86_BUILTIN_PSLLW256,\n\tIX86_BUILTIN_PSLLDI256, IX86_BUILTIN_PSLLD256,\n\tIX86_BUILTIN_PSLLQI256, IX86_BUILTIN_PSLLQ256,\n\tIX86_BUILTIN_PSRAWI256, IX86_BUILTIN_PSRAW256,\n\tIX86_BUILTIN_PSRADI256, IX86_BUILTIN_PSRAD256,\n\tIX86_BUILTIN_PSRLDQI256, IX86_BUILTIN_PSRLWI256,\n\tIX86_BUILTIN_PSRLW256, IX86_BUILTIN_PSRLDI256,\n\tIX86_BUILTIN_PSRLD256, IX86_BUILTIN_PSRLQI256,\n\tIX86_BUILTIN_PSRLQ256, IX86_BUILTIN_PSUBB256,\n\tIX86_BUILTIN_PSUBW256, IX86_BUILTIN_PSUBD256,\n\tIX86_BUILTIN_PSUBQ256, IX86_BUILTIN_PSUBSB256,\n\tIX86_BUILTIN_PSUBSW256, IX86_BUILTIN_PSUBUSB256,\n\tIX86_BUILTIN_PSUBUSW256, IX86_BUILTIN_PUNPCKHBW256,\n\tIX86_BUILTIN_PUNPCKHWD256, IX86_BUILTIN_PUNPCKHDQ256,\n\tIX86_BUILTIN_PUNPCKHQDQ256, IX86_BUILTIN_PUNPCKLBW256,\n\tIX86_BUILTIN_PUNPCKLWD256, IX86_BUILTIN_PUNPCKLDQ256,\n\tIX86_BUILTIN_PUNPCKLQDQ256, IX86_BUILTIN_PXOR256,\n\tIX86_BUILTIN_MOVNTDQA256, IX86_BUILTIN_VBROADCASTSS_PS,\n\tIX86_BUILTIN_VBROADCASTSS_PS256,\n\tIX86_BUILTIN_VBROADCASTSD_PD256,\n\tIX86_BUILTIN_VBROADCASTSI256, IX86_BUILTIN_PBLENDD256,\n\tIX86_BUILTIN_PBLENDD128, IX86_BUILTIN_PBROADCASTB256,\n\tIX86_BUILTIN_PBROADCASTW256, IX86_BUILTIN_PBROADCASTD256,\n\tIX86_BUILTIN_PBROADCASTQ256, IX86_BUILTIN_PBROADCASTB128,\n\tIX86_BUILTIN_PBROADCASTW128, IX86_BUILTIN_PBROADCASTD128,\n\tIX86_BUILTIN_PBROADCASTQ128, IX86_BUILTIN_VPERMVARSI256,\n\tIX86_BUILTIN_VPERMDF256, IX86_BUILTIN_VPERMVARSF256,\n\tIX86_BUILTIN_VPERMDI256, IX86_BUILTIN_VPERMTI256,\n\tIX86_BUILTIN_VEXTRACT128I256, IX86_BUILTIN_VINSERT128I256,\n\tIX86_BUILTIN_MASKLOADD, IX86_BUILTIN_MASKLOADQ,\n\tIX86_BUILTIN_MASKLOADD256, IX86_BUILTIN_MASKLOADQ256,\n\tIX86_BUILTIN_MASKSTORED, IX86_BUILTIN_MASKSTOREQ,\n\tIX86_BUILTIN_MASKSTORED256, IX86_BUILTIN_MASKSTOREQ256,\n\tIX86_BUILTIN_PSLLVV4DI, IX86_BUILTIN_PSLLVV2DI,\n\tIX86_BUILTIN_PSLLVV8SI, IX86_BUILTIN_PSLLVV4SI,\n\tIX86_BUILTIN_PSRAVV8SI, IX86_BUILTIN_PSRAVV4SI,\n\tIX86_BUILTIN_PSRLVV4DI, IX86_BUILTIN_PSRLVV2DI,\n\tIX86_BUILTIN_PSRLVV8SI, IX86_BUILTIN_PSRLVV4SI,\n\tIX86_BUILTIN_GATHERSIV2DF, IX86_BUILTIN_GATHERSIV4DF,\n\tIX86_BUILTIN_GATHERDIV2DF, IX86_BUILTIN_GATHERDIV4DF,\n\tIX86_BUILTIN_GATHERSIV4SF, IX86_BUILTIN_GATHERSIV8SF,\n\tIX86_BUILTIN_GATHERDIV4SF, IX86_BUILTIN_GATHERDIV8SF,\n\tIX86_BUILTIN_GATHERSIV2DI, IX86_BUILTIN_GATHERSIV4DI,\n\tIX86_BUILTIN_GATHERDIV2DI, IX86_BUILTIN_GATHERDIV4DI,\n\tIX86_BUILTIN_GATHERSIV4SI, IX86_BUILTIN_GATHERSIV8SI,\n\tIX86_BUILTIN_GATHERDIV4SI, IX86_BUILTIN_GATHERDIV8SI.\n\t(bdesc_special_args): Add IX86_BUILTIN_MOVNTDQA256,\n\tIX86_BUILTIN_MASKLOADD, IX86_BUILTIN_MASKLOADQ,\n\tIX86_BUILTIN_MASKLOADD256, IX86_BUILTIN_MASKLOADQ256,\n\tIX86_BUILTIN_MASKSTORED, IX86_BUILTIN_MASKSTOREQ,\n\tIX86_BUILTIN_MASKSTORED256, IX86_BUILTIN_MASKSTOREQ256.\n\t(bdesc_args): Add  IX86_BUILTIN_MPSADBW256,\n\tIX86_BUILTIN_PABSB256, IX86_BUILTIN_PABSW256,\n\tIX86_BUILTIN_PABSD256, IX86_BUILTIN_PACKSSDW256,\n\tIX86_BUILTIN_PACKSSWB256, IX86_BUILTIN_PACKUSDW256,\n\tIX86_BUILTIN_PACKUSWB256, IX86_BUILTIN_PADDB256,\n\tIX86_BUILTIN_PADDW256, IX86_BUILTIN_PADDD256,\n\tIX86_BUILTIN_PADDQ256, IX86_BUILTIN_PADDSB256,\n\tIX86_BUILTIN_PADDSW256, IX86_BUILTIN_PADDUSB256,\n\tIX86_BUILTIN_PADDUSW256, IX86_BUILTIN_PALIGNR256,\n\tIX86_BUILTIN_AND256I, IX86_BUILTIN_ANDNOT256I,\n\tIX86_BUILTIN_PAVGB256, IX86_BUILTIN_PAVGW256,\n\tIX86_BUILTIN_PBLENDVB256, IX86_BUILTIN_PBLENDVW256,\n\tIX86_BUILTIN_PCMPEQB256, IX86_BUILTIN_PCMPEQW256,\n\tIX86_BUILTIN_PCMPEQD256, IX86_BUILTIN_PCMPEQQ256,\n\tIX86_BUILTIN_PCMPGTB256, IX86_BUILTIN_PCMPGTW256,\n\tIX86_BUILTIN_PCMPGTD256, IX86_BUILTIN_PCMPGTQ256,\n\tIX86_BUILTIN_PHADDW256, IX86_BUILTIN_PHADDD256,\n\tIX86_BUILTIN_PHADDSW256, IX86_BUILTIN_PHSUBW256,\n\tIX86_BUILTIN_PHSUBD256, IX86_BUILTIN_PHSUBSW256,\n\tIX86_BUILTIN_PMADDUBSW256, IX86_BUILTIN_PMADDWD256,\n\tIX86_BUILTIN_PMAXSB256, IX86_BUILTIN_PMAXSW256,\n\tIX86_BUILTIN_PMAXSD256, IX86_BUILTIN_PMAXUB256,\n\tIX86_BUILTIN_PMAXUW256, IX86_BUILTIN_PMAXUD256,\n\tIX86_BUILTIN_PMINSB256, IX86_BUILTIN_PMINSW256,\n\tIX86_BUILTIN_PMINSD256, IX86_BUILTIN_PMINUB256,\n\tIX86_BUILTIN_PMINUW256, IX86_BUILTIN_PMINUD256,\n\tIX86_BUILTIN_PMOVMSKB256, IX86_BUILTIN_PMOVSXBW256,\n\tIX86_BUILTIN_PMOVSXBD256, IX86_BUILTIN_PMOVSXBQ256,\n\tIX86_BUILTIN_PMOVSXWD256, IX86_BUILTIN_PMOVSXWQ256,\n\tIX86_BUILTIN_PMOVSXDQ256, IX86_BUILTIN_PMOVZXBW256,\n\tIX86_BUILTIN_PMOVZXBD256, IX86_BUILTIN_PMOVZXBQ256,\n\tIX86_BUILTIN_PMOVZXWD256, IX86_BUILTIN_PMOVZXWQ256,\n\tIX86_BUILTIN_PMOVZXDQ256, IX86_BUILTIN_PMULDQ256,\n\tIX86_BUILTIN_PMULHRSW256, IX86_BUILTIN_PMULHUW256,\n\tIX86_BUILTIN_PMULHW256, IX86_BUILTIN_PMULLW256,\n\tIX86_BUILTIN_PMULLD256, IX86_BUILTIN_PMULUDQ256,\n\tIX86_BUILTIN_POR256, IX86_BUILTIN_PSADBW256,\n\tIX86_BUILTIN_PSHUFB256, IX86_BUILTIN_PSHUFD256,\n\tIX86_BUILTIN_PSHUFHW256, IX86_BUILTIN_PSHUFLW256,\n\tIX86_BUILTIN_PSIGNB256, IX86_BUILTIN_PSIGNW256,\n\tIX86_BUILTIN_PSIGND256, IX86_BUILTIN_PSLLDQI256,\n\tIX86_BUILTIN_PSLLWI256, IX86_BUILTIN_PSLLW256,\n\tIX86_BUILTIN_PSLLDI256, IX86_BUILTIN_PSLLD256,\n\tIX86_BUILTIN_PSLLQI256, IX86_BUILTIN_PSLLQ256,\n\tIX86_BUILTIN_PSRAWI256, IX86_BUILTIN_PSRAW256,\n\tIX86_BUILTIN_PSRADI256, IX86_BUILTIN_PSRAD256,\n\tIX86_BUILTIN_PSRLDQI256, IX86_BUILTIN_PSRLWI256,\n\tIX86_BUILTIN_PSRLW256, IX86_BUILTIN_PSRLDI256,\n\tIX86_BUILTIN_PSRLD256, IX86_BUILTIN_PSRLQI256,\n\tIX86_BUILTIN_PSRLQ256, IX86_BUILTIN_PSUBB256,\n\tIX86_BUILTIN_PSUBW256, IX86_BUILTIN_PSUBD256,\n\tIX86_BUILTIN_PSUBQ256, IX86_BUILTIN_PSUBSB256,\n\tIX86_BUILTIN_PSUBSW256, IX86_BUILTIN_PSUBUSB256,\n\tIX86_BUILTIN_PSUBUSW256, IX86_BUILTIN_PUNPCKHBW256,\n\tIX86_BUILTIN_PUNPCKHWD256, IX86_BUILTIN_PUNPCKHDQ256,\n\tIX86_BUILTIN_PUNPCKHQDQ256, IX86_BUILTIN_PUNPCKLBW256,\n\tIX86_BUILTIN_PUNPCKLWD256, IX86_BUILTIN_PUNPCKLDQ256,\n\tIX86_BUILTIN_PUNPCKLQDQ256, IX86_BUILTIN_PXOR256,\n\tIX86_BUILTIN_VBROADCASTSS_PS, IX86_BUILTIN_VBROADCASTSS_PS256,\n\tIX86_BUILTIN_VBROADCASTSD_PD256,\n\tIX86_BUILTIN_VBROADCASTSI256, IX86_BUILTIN_PBLENDD256,\n\tIX86_BUILTIN_PBLENDD128, IX86_BUILTIN_PBROADCASTB256,\n\tIX86_BUILTIN_PBROADCASTW256, IX86_BUILTIN_PBROADCASTD256,\n\tIX86_BUILTIN_PBROADCASTQ256, IX86_BUILTIN_PBROADCASTB128,\n\tIX86_BUILTIN_PBROADCASTW128, IX86_BUILTIN_PBROADCASTD128,\n\tIX86_BUILTIN_PBROADCASTQ128, IX86_BUILTIN_VPERMVARSI256,\n\tIX86_BUILTIN_VPERMDF256, IX86_BUILTIN_VPERMVARSF256,\n\tIX86_BUILTIN_VPERMDI256, IX86_BUILTIN_VPERMTI256,\n\tIX86_BUILTIN_VEXTRACT128I256, IX86_BUILTIN_VINSERT128I256,\n\tIX86_BUILTIN_PSLLVV4DI, IX86_BUILTIN_PSLLVV2DI,\n\tIX86_BUILTIN_PSLLVV8SI, IX86_BUILTIN_PSLLVV4SI,\n\tIX86_BUILTIN_PSRAVV8SI, IX86_BUILTIN_PSRAVV4SI,\n\tIX86_BUILTIN_PSRLVV4DI, IX86_BUILTIN_PSRLVV2DI,\n\tIX86_BUILTIN_PSRLVV8SI, IX86_BUILTIN_PSRLVV4SI.\n\t(ix86_init_mmx_sse_builtins): Add IX86_BUILTIN_GATHERSIV2DF,\n\tIX86_BUILTIN_GATHERSIV4DF, IX86_BUILTIN_GATHERDIV2DF,\n\tIX86_BUILTIN_GATHERDIV4DF, IX86_BUILTIN_GATHERSIV4SF,\n\tIX86_BUILTIN_GATHERSIV8SF, IX86_BUILTIN_GATHERDIV4SF,\n\tIX86_BUILTIN_GATHERDIV8SF, IX86_BUILTIN_GATHERSIV2DI,\n\tIX86_BUILTIN_GATHERSIV4DI, IX86_BUILTIN_GATHERDIV2DI,\n\tIX86_BUILTIN_GATHERDIV4DI, IX86_BUILTIN_GATHERSIV4SI,\n\tIX86_BUILTIN_GATHERSIV8SI, IX86_BUILTIN_GATHERDIV4SI,\n\tIX86_BUILTIN_GATHERDIV8SI.\n\t(ix86_preferred_simd_mode): Support AVX2 modes.\n\t(ix86_expand_args_builtin): Support AVX2 built-ins.\n\t(ix86_expand_special_args_builtin): Likewise.\n\t(ix86_expand_builtin): Likewise.\n\t* config/i386/i386.md (UNSPEC_VPERMSI): New.\n\t(UNSPEC_VPERMDF): Likewise.\n\t(UNSPEC_VPERMSF): Likewise.\n\t(UNSPEC_VPERMDI): Likewise.\n\t(UNSPEC_VPERMTI): Likewise.\n\t(UNSPEC_GATHER): Likewise.\n\t(ssemodesuffix): Extend.\n\t* config/i386/immintrin.h: Include avx2intrin.h when __AVX2__\n\tis defined.\n\t* config/i386/predicates.md (const1248_operand): New.\n\t* config/i386/sse.md (VI_AVX2):\n\t(VI1_AVX2): Likewise.\n\t(VI2_AVX2): Likewise.\n\t(VI4_AVX2): Likewise.\n\t(VI8_AVX2): Likewise.\n\t(VIMAX_AVX2): Likewise.\n\t(SSESCALARMODE): Likewise.\n\t(VI12_AVX2): Likewise.\n\t(VI24_AVX2): Likewise.\n\t(VI124_AVX2): Likeuse_submit_for_speed = 1\n\twise.\n\t(VI248_AVX2): Likewise.\n\t(VI48_AVX2): Likewise.\n\t(VI4SD_AVX2): Likewise.\n\t(V48_AVX2): Likewise.\n\t(avx2modesuffix): Likewise.\n\t(sse_avx2): Likewise.\n\t(sse2_avx2): Likewise.\n\t(ssse3_avx2): Likewise.\n\t(sse4_1_avx2): Likewise.\n\t(avx_avx2): Likewise.\n\t(lshift)<code_oterator>: Likewise.\n\t(lshift_insn): Likewise.\n\t(lshift)<code_attr>: Likewise.\n\t(SSESHORTMODE): Likewise.\n\t(SSELONGMODE): Likewise.\n\t(SSEBYTEMODE): Likewise.\n\t(AVXTOSSEMODE): Likewise.\n\t(shortmode): Likewise.\n\t(ssescalarmodesuffix): Update.\n\t(sseunpackmode): Likewise.\n\t(ssepackmode): Likewise.\n\t(AVX256MODEI): New.\n\t(AVX256MODE124): Likewise.\n\t(AVX256MODE1248): Likewise.\n\t(AVX256MODE248): Likewise.\n\t(AVXMODE48P_SI): Likewise.\n\t(AVXMODE48P_SI): Likewise.\n\t(AVXMODE48P_DI): Likewise.\n\t(AVXMODE48P_DI): Likewise.\n\t(gthrfirstp): Likewise.\n\t(gthrlastp): Likewise.\n\t(avx2): Likwise.\n\t(ssevecsize): Likewise.\n\t(ssedoublesizemode): Likewise.\n\t(avxvecmode): Likewise.\n\t(avxvecsize): Likewise.\n\t(avxhalfvecmode): Likewise.\n\t(avxscalarmode): Likewise.\n\t(avxpermvecmode): Likewise.\n\t(avxmodesuffixp): Likewise.\n\t(avxmodesuffix): Likewise.\n\t(avx2_vec_dupv4sf): New.\n\t(avx2_vec_dupv8sf): Likewise.\n\t(avx2_interleave_highv4di): Likewise.\n\t(avx2_interleave_lowv4di): Likewise.\n\t(<plusminus_insn><mode>3): Update.\n\t(*<plusminus_insn><mode>3): Likewise.\n\t(sse2_<plusminus_insn><mode>3): Rename to ...\n\t(\"<sse2_avx2>_<plusminus_insn><mode>3): ... this. updated.\n\t(*sse2_<plusminus_insn><mode>3): Likewise.\n\t(*<sse2_avx2>_<plusminus_insn><mode>3): Likewise.\n\t(mulv8hi3): Likewise.\n\t(mul<mode>3): Likewise.\n\t(*mulv8hi3): Likewise.\n\t(*mul<mode>3): Likewise.\n\t(<s>mulv8hi3_highpart): Likewise.\n\t(<s>mul<mode>3_highpart): Likewise.\n\t(*<s>mulv8hi3_highpart): Likewise.\n\t(*<s>mul<mode>3_highpart): Likewise.\n\t(avx2_umulv4siv4di3): Likewise.\n\t(*avx_umulv4siv4di3): Likewise.\n\t(sse4_1_mulv2siv2di3): Likewise.\n\t(<sse4_1_avx2>_mul<shortmode><mode>3): Likewise.\n\t(*sse4_1_mulv2siv2di3): Likewise.\n\t(*<sse4_1_avx2>_mulv2siv2di3): Likewise.\n\t(avx2_pmaddwd): New.\n\t(*avx2_pmaddwd): Likewise.\n\t(mulv4si3): Rename to ...\n\t(mul<mode>3): ... this. Update.\n\t(*sse4_1_mulv4si3): Likewise.\n\t(*<sse4_1_avx2>_mul<mode>3): Likewise.\n\t(ashr<mode>3): Update.\n\t(avx2_lshrqv4di3): New.\n\t(lshr<mode>3): Update.\n\t(avx2_lshlqv4di3): New.\n\t(avx2_lshl<mode>3): Likewise.\n\t(sse2_ashlv1ti3): Rename to ...\n\t(<sse2_avx2>_ashl<mode>3): ... this. Update.\n\t(avx2_<code><mode>3)<umaxmin>: New.\n\t(*avx2_<code><mode>3)<umaxmin>: Likewise.\n\t(avx2_<code><mode>3)<smaxmin>: New.\n\t(*avx2_<code><mode>3)<smaxmin>: Likewise.\n\t(avx2_eq<mode>3): Likewise.\n\t(*avx2_eq<mode>3): Likewise.\n\t(avx2_gt<mode>3): Likewise.\n\t(sse2_andnot<mode>3): Rename to ...\n\t(<sse2_avx2>_andnot<mode>3): ... this. Update.\n\t(*andnot<mode>3): Update.\n\t(<code><mode>3)<any_logic>: Update.\n\t(*<code><mode>3)<any_logic>: Likewise.\n\t(sse2_packsswb): Rename to ...\n\t(<sse2_avx2>_packsswb): ... this. Update.\n\t(sse2_packssdw): Likewise.\n\t(<sse2_avx2>_packssdw): Likewise.\n\t(sse2_packuswb): Likewise.\n\t(<sse2_avx2>_packuswb): Likewise.\n\t(avx2_interleave_highv32qi): New.\n\t(avx2_interleave_lowv32qi): Likewise.\n\t(avx2_interleave_highv16hi): Likewise.\n\t(avx2_interleave_lowv16hi): Likewise.\n\t(avx2_interleave_highv8si): Likewise.\n\t(avx2_interleave_lowv8si): Likewise.\n\t(avx2_pshufd): New\n\t(avx2_pshufd_1): Likewise.\n\t(avx2_pshuflwv3): Likewise.\n\t(avx2_pshuflw_1): Likewise.\n\t(avx2_pshufhwv3): Likewise.\n\t(avx2_pshufhw_1): Likewise.\n\t(avx2_uavgv32qi3): Likewise.\n\t(*avx2_uavgv32qi3): Likewise.\n\t(avx2_uavgv16hi3): Likewise.\n\t(*avx2_uavgv16hi3): Likewise.\n\t(sse2_psadbw): Rename to ...\n\t(<sse2_avx2>_psadbw): ... this. Update.\n\t(avx2_pmovmskb): New.\n\t(avx2_phaddwv16hi3): Likewise.\n\t(avx2_phadddv8si3): Likewise.\n\t(avx2_phaddswv16hi3): Likewise.\n\t(avx2_phsubwv16hi3): Likewise.\n\t(avx2_phsubdv8si3): Likewise.\n\t(avx2_phsubswv16hi3): Likewise.\n\t(avx2_pmaddubsw256): Likewise.\n\t(avx2_umulhrswv16hi3): Likewise.\n\t(*avx2_umulhrswv16hi3): Likewise.\n\t(ssse3_pshufbv16qi3): Rename to ...\n\t(<ssse3_avx2>_pshufb<mode>3): ... this. Update.\n\t(ssse3_psign<mode>3): Likewise.\n\t(<ssse3_avx2>_psign<mode>3): Likewise.\n\t(ssse3_palignrti): Likewise.\n\t(<ssse3_avx2>_palignr<mode>): Likewise.\n\t(abs<mode>2): Likewise.\n\t(sse4_1_movntdqa): Rename to ...\n\t(<sse4_1_avx2>_movntdqa): ... this. Update.\n\t(sse4_1_mpsadbw): Likewise.\n\t(<sse4_1_avx2>_mpsadbw): Likewise.\n\t(avx2_packusdw): New.\n\t(sse4_1_pblendvb): Rename to ...\n\t(<sse4_1_avx2>_pblendvb): ... this. Update.\n\t(sse4_1_pblendw): Likewise.\n\t(<sse4_1_avx2>_pblendw): Likewise.\n\t(avx2_pblendd<mode>): New.\n\t(avx2_<code>v16qiv16hi2): Likewise.\n\t(avx2_<code>v8qiv8si2): Likewise.\n\t(avx2_<code>v8hiv8si2): Likewise.\n\t(avx2_<code>v4qiv4di2): Likewise.\n\t(avx2_<code>v4hiv4di2): Likewise.\n\t(avx2_<code>v4siv4di2): Likewise.\n\t(avx2_pbroadcast<mode>): Likewise.\n\t(avx2_permvarv8si): Likewise.\n\t(avx2_permv4df): Likewise.\n\t(avx2_permvarv8sf): Likewise.\n\t(avx2_permv4di): Likewise.\n\t(avx2_permv2ti): Likewise.\n\t(avx2_vec_dupv4df): Likewise.\n\t(avx2_vbroadcasti128_<mode>): Likewise.\n\t(avx2_vec_set_lo_v4di): Likewise.\n\t(avx2_vec_set_hi_v4di): Likewise.\n\t(avx_maskload<ssemodesuffix><avxsizesuffix>): Rename to ...\n\t(<avx_avx2>_maskload<avx2modesuffix><avxmodesuffix>): ... this.\n\tUpdate.\n\t(avx_maskstore<ssemodesuffix><avxsizesuffix>): Likewise.\n\t(<avx_avx2>_maskstore<avx2modesuffix><avxmodesuffix>): Likewise.\n\t(*avx2_maskmov<avx2modesuffix><avxmodesuffix>): New.\n\t(avx2_extracti128): Likewise.\n\t(avx2_inserti128): Likewise.\n\t(avx2_ashrvv8si): Likewise.\n\t(avx2_ashrvv4si): Likewise.\n\t(avx2_<lshift>vv8si): Likewise.\n\t(avx2_<lshift>v<mode>): Likewise.\n\t(avx2_<lshift>vv2di): Likewise.\n\t(avx2_gathersi<mode>): Likewise.\n\t(*avx2_gathersi<mode>): Likewise.\n\t(avx2_gatherdi<mode>): Likewise.\n\t(*avx2_gatherdi<mode>): Likewise.\n\t(avx2_gatherdi<mode>256): Likewise.\n\t(*avx2_gatherdi<mode>256): Likewise.\n\t* doc/extend.texi: Document AVX2 built-in functions.\n\t* doc/invoke.texi: Document -mavx2.\n\nFrom-SVN: r177955", "tree": {"sha": "af60ab13d7a0d5ccfb359b7d30574fe0ddeb89db", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/af60ab13d7a0d5ccfb359b7d30574fe0ddeb89db"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/977e83a3edc1a58077e33143ad3cc1f9349d6197", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/977e83a3edc1a58077e33143ad3cc1f9349d6197", "html_url": "https://github.com/Rust-GCC/gccrs/commit/977e83a3edc1a58077e33143ad3cc1f9349d6197", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/977e83a3edc1a58077e33143ad3cc1f9349d6197/comments", "author": null, "committer": null, "parents": [{"sha": "bdb7daebd20c38495ae1640a00e23d11d0f8ebee", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bdb7daebd20c38495ae1640a00e23d11d0f8ebee", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bdb7daebd20c38495ae1640a00e23d11d0f8ebee"}], "stats": {"total": 5682, "additions": 5419, "deletions": 263}, "files": [{"sha": "15c4e3ba24c84fb52f5fce3bc50390c188c7096b", "filename": "gcc/ChangeLog", "status": "modified", "additions": 423, "deletions": 0, "changes": 423, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -1,3 +1,426 @@\n+2011-08-22  Kirill Yukhin  <kirill.yukhin@intel.com>\n+\n+\t* config/i386/avx2intrin.h: New file.\n+\t* config/i386/i386-builtin-types.def (PCINT, PCINT64, PV4SI,\n+\tPV8SI, V32QI_FTYPE_V32QI, V32QI_FTYPE_V16QI, V16HI_FTYPE_V16HI,\n+\tV16HI_FTYPE_V8HI, V8SI_FTYPE_V8SI, V16HI_FTYPE_V16QI,\n+\tV8SI_FTYPE_V16QI, V4DI_FTYPE_V16QI, V8SI_FTYPE_V8HI,\n+\tV4DI_FTYPE_V8HI, V4DI_FTYPE_V4SI, V4DI_FTYPE_PV4DI,\n+\tV4DI_FTYPE_V2DI, V2DI_FTYPE_PCV2DI_V2DI, V4SI_FTYPE_PCV4SI_V4SI,\n+\tV32QI_FTYPE_V16HI_V16HI, V16HI_FTYPE_V8SI_V8SI,\n+\tV32QI_FTYPE_V32QI_V32QI, V16HI_FTYPE_V32QI_V32QI,\n+\tV16HI_FTYPE_V16HI_V8HI, V16HI_FTYPE_V16HI_V16HI,\n+\tV16HI_FTYPE_V16HI_INT, V16HI_FTYPE_V16HI_SI,\n+\tV16HI_FTYPE_V16HI_V16HI_INT, V32QI_FTYPE_V32QI_V32QI_INT,\n+\tV8SI_FTYPE_V8SI_V4SI, V8SI_FTYPE_V8SI_V8SI,\n+\tV8SI_FTYPE_V16HI_V16HI, V8SI_FTYPE_V8SI_INT, V8SI_FTYPE_V8SI_SI,\n+\tV8SI_FTYPE_PCV8SI_V8SI, V4DI_FTYPE_V4DI_V4DI,\n+\tV4DI_FTYPE_V8SI_V8SI, V4DI_FTYPE_V4DI_V2DI,\n+\tV4DI_FTYPE_PCV4DI_V4DI, V4DI_FTYPE_V4DI_INT,\n+\tV2DI_FTYPE_V4DI_INT, V4DI_FTYPE_V4DI_V4DI_INT,\n+\tV4DI_FTYPE_V4DI_V2DI_INT, VOID_FTYPE_PV2DI_V2DI_V2DI,\n+\tVOID_FTYPE_PV4DI_V4DI_V4DI, VOID_FTYPE_PV4SI_V4SI_V4SI,\n+\tVOID_FTYPE_PV8SI_V8SI_V8SI,\n+\tV2DF_FTYPE_V2DF_PCDOUBLE_V4SI_V2DF_INT,\n+\tV4DF_FTYPE_V4DF_PCDOUBLE_V4SI_V4DF_INT,\n+\tV2DF_FTYPE_V2DF_PCDOUBLE_V2DI_V2DF_INT,\n+\tV4DF_FTYPE_V4DF_PCDOUBLE_V4DI_V4DF_INT,\n+\tV4SF_FTYPE_V4SF_PCFLOAT_V4SI_V4SF_INT,\n+\tV8SF_FTYPE_V8SF_PCFLOAT_V8SI_V8SF_INT,\n+\tV4SF_FTYPE_V4SF_PCFLOAT_V2DI_V4SF_INT,\n+\tV4SF_FTYPE_V4SF_PCFLOAT_V4DI_V4SF_INT,\n+\tV2DI_FTYPE_V2DI_PCINT64_V4SI_V2DI_INT,\n+\tV4DI_FTYPE_V4DI_PCINT64_V4SI_V4DI_INT,\n+\tV2DI_FTYPE_V2DI_PCINT64_V2DI_V2DI_INT,\n+\tV4DI_FTYPE_V4DI_PCINT64_V4DI_V4DI_INT,\n+\tV4SI_FTYPE_V4SI_PCINT_V4SI_V4SI_INT,\n+\tV8SI_FTYPE_V8SI_PCINT_V8SI_V8SI_INT,\n+\tV4SI_FTYPE_V4SI_PCINT_V2DI_V4SI_INT,\n+\tV4SI_FTYPE_V4SI_PCINT_V4DI_V4SI_INT,\n+\tV16HI_FTYPE_V16HI_SI_COUNT, V16HI_FTYPE_V16HI_V8HI_COUNT,\n+\tV8SI_FTYPE_V8SI_SI_COUNT, V8SI_FTYPE_V8SI_V4SI_COUNT,\n+\tV4DI_FTYPE_V4DI_INT_COUNT, V4DI_FTYPE_V4DI_V2DI_COUNT,\n+\tV4DI_FTYPE_V4DI_INT_CONVERT,\n+\tV4DI_FTYPE_V4DI_V4DI_INT_CONVERT): New.\n+\t* config/i386/i386.c (ix86_builtins): Add IX86_BUILTIN_MPSADBW256,\n+\tIX86_BUILTIN_PABSB256, IX86_BUILTIN_PABSW256,\n+\tIX86_BUILTIN_PABSD256, IX86_BUILTIN_PACKSSDW256,\n+\tIX86_BUILTIN_PACKSSWB256, IX86_BUILTIN_PACKUSDW256,\n+\tIX86_BUILTIN_PACKUSWB256, IX86_BUILTIN_PADDB256,\n+\tIX86_BUILTIN_PADDW256, IX86_BUILTIN_PADDD256,\n+\tIX86_BUILTIN_PADDQ256, IX86_BUILTIN_PADDSB256,\n+\tIX86_BUILTIN_PADDSW256, IX86_BUILTIN_PADDUSB256,\n+\tIX86_BUILTIN_PADDUSW256, IX86_BUILTIN_PALIGNR256,\n+\tIX86_BUILTIN_AND256I, IX86_BUILTIN_ANDNOT256I,\n+\tIX86_BUILTIN_PAVGB256, IX86_BUILTIN_PAVGW256,\n+\tIX86_BUILTIN_PBLENDVB256, IX86_BUILTIN_PBLENDVW256,\n+\tIX86_BUILTIN_PCMPEQB256, IX86_BUILTIN_PCMPEQW256,\n+\tIX86_BUILTIN_PCMPEQD256, IX86_BUILTIN_PCMPEQQ256,\n+\tIX86_BUILTIN_PCMPGTB256, IX86_BUILTIN_PCMPGTW256,\n+\tIX86_BUILTIN_PCMPGTD256, IX86_BUILTIN_PCMPGTQ256,\n+\tIX86_BUILTIN_PHADDW256, IX86_BUILTIN_PHADDD256,\n+\tIX86_BUILTIN_PHADDSW256, IX86_BUILTIN_PHSUBW256,\n+\tIX86_BUILTIN_PHSUBD256, IX86_BUILTIN_PHSUBSW256,\n+\tIX86_BUILTIN_PMADDUBSW256, IX86_BUILTIN_PMADDWD256,\n+\tIX86_BUILTIN_PMAXSB256, IX86_BUILTIN_PMAXSW256,\n+\tIX86_BUILTIN_PMAXSD256, IX86_BUILTIN_PMAXUB256,\n+\tIX86_BUILTIN_PMAXUW256, IX86_BUILTIN_PMAXUD256,\n+\tIX86_BUILTIN_PMINSB256, IX86_BUILTIN_PMINSW256,\n+\tIX86_BUILTIN_PMINSD256, IX86_BUILTIN_PMINUB256,\n+\tIX86_BUILTIN_PMINUW256, IX86_BUILTIN_PMINUD256,\n+\tIX86_BUILTIN_PMOVMSKB256, IX86_BUILTIN_PMOVSXBW256,\n+\tIX86_BUILTIN_PMOVSXBD256, IX86_BUILTIN_PMOVSXBQ256,\n+\tIX86_BUILTIN_PMOVSXWD256, IX86_BUILTIN_PMOVSXWQ256,\n+\tIX86_BUILTIN_PMOVSXDQ256, IX86_BUILTIN_PMOVZXBW256,\n+\tIX86_BUILTIN_PMOVZXBD256, IX86_BUILTIN_PMOVZXBQ256,\n+\tIX86_BUILTIN_PMOVZXWD256, IX86_BUILTIN_PMOVZXWQ256,\n+\tIX86_BUILTIN_PMOVZXDQ256, IX86_BUILTIN_PMULDQ256,\n+\tIX86_BUILTIN_PMULHRSW256, IX86_BUILTIN_PMULHUW256,\n+\tIX86_BUILTIN_PMULHW256, IX86_BUILTIN_PMULLW256,\n+\tIX86_BUILTIN_PMULLD256, IX86_BUILTIN_PMULUDQ256,\n+\tIX86_BUILTIN_POR256, IX86_BUILTIN_PSADBW256,\n+\tIX86_BUILTIN_PSHUFB256, IX86_BUILTIN_PSHUFD256,\n+\tIX86_BUILTIN_PSHUFHW256, IX86_BUILTIN_PSHUFLW256,\n+\tIX86_BUILTIN_PSIGNB256, IX86_BUILTIN_PSIGNW256,\n+\tIX86_BUILTIN_PSIGND256, IX86_BUILTIN_PSLLDQI256,\n+\tIX86_BUILTIN_PSLLWI256, IX86_BUILTIN_PSLLW256,\n+\tIX86_BUILTIN_PSLLDI256, IX86_BUILTIN_PSLLD256,\n+\tIX86_BUILTIN_PSLLQI256, IX86_BUILTIN_PSLLQ256,\n+\tIX86_BUILTIN_PSRAWI256, IX86_BUILTIN_PSRAW256,\n+\tIX86_BUILTIN_PSRADI256, IX86_BUILTIN_PSRAD256,\n+\tIX86_BUILTIN_PSRLDQI256, IX86_BUILTIN_PSRLWI256,\n+\tIX86_BUILTIN_PSRLW256, IX86_BUILTIN_PSRLDI256,\n+\tIX86_BUILTIN_PSRLD256, IX86_BUILTIN_PSRLQI256,\n+\tIX86_BUILTIN_PSRLQ256, IX86_BUILTIN_PSUBB256,\n+\tIX86_BUILTIN_PSUBW256, IX86_BUILTIN_PSUBD256,\n+\tIX86_BUILTIN_PSUBQ256, IX86_BUILTIN_PSUBSB256,\n+\tIX86_BUILTIN_PSUBSW256, IX86_BUILTIN_PSUBUSB256,\n+\tIX86_BUILTIN_PSUBUSW256, IX86_BUILTIN_PUNPCKHBW256,\n+\tIX86_BUILTIN_PUNPCKHWD256, IX86_BUILTIN_PUNPCKHDQ256,\n+\tIX86_BUILTIN_PUNPCKHQDQ256, IX86_BUILTIN_PUNPCKLBW256,\n+\tIX86_BUILTIN_PUNPCKLWD256, IX86_BUILTIN_PUNPCKLDQ256,\n+\tIX86_BUILTIN_PUNPCKLQDQ256, IX86_BUILTIN_PXOR256,\n+\tIX86_BUILTIN_MOVNTDQA256, IX86_BUILTIN_VBROADCASTSS_PS,\n+\tIX86_BUILTIN_VBROADCASTSS_PS256,\n+\tIX86_BUILTIN_VBROADCASTSD_PD256,\n+\tIX86_BUILTIN_VBROADCASTSI256, IX86_BUILTIN_PBLENDD256,\n+\tIX86_BUILTIN_PBLENDD128, IX86_BUILTIN_PBROADCASTB256,\n+\tIX86_BUILTIN_PBROADCASTW256, IX86_BUILTIN_PBROADCASTD256,\n+\tIX86_BUILTIN_PBROADCASTQ256, IX86_BUILTIN_PBROADCASTB128,\n+\tIX86_BUILTIN_PBROADCASTW128, IX86_BUILTIN_PBROADCASTD128,\n+\tIX86_BUILTIN_PBROADCASTQ128, IX86_BUILTIN_VPERMVARSI256,\n+\tIX86_BUILTIN_VPERMDF256, IX86_BUILTIN_VPERMVARSF256,\n+\tIX86_BUILTIN_VPERMDI256, IX86_BUILTIN_VPERMTI256,\n+\tIX86_BUILTIN_VEXTRACT128I256, IX86_BUILTIN_VINSERT128I256,\n+\tIX86_BUILTIN_MASKLOADD, IX86_BUILTIN_MASKLOADQ,\n+\tIX86_BUILTIN_MASKLOADD256, IX86_BUILTIN_MASKLOADQ256,\n+\tIX86_BUILTIN_MASKSTORED, IX86_BUILTIN_MASKSTOREQ,\n+\tIX86_BUILTIN_MASKSTORED256, IX86_BUILTIN_MASKSTOREQ256,\n+\tIX86_BUILTIN_PSLLVV4DI, IX86_BUILTIN_PSLLVV2DI,\n+\tIX86_BUILTIN_PSLLVV8SI, IX86_BUILTIN_PSLLVV4SI,\n+\tIX86_BUILTIN_PSRAVV8SI, IX86_BUILTIN_PSRAVV4SI,\n+\tIX86_BUILTIN_PSRLVV4DI, IX86_BUILTIN_PSRLVV2DI,\n+\tIX86_BUILTIN_PSRLVV8SI, IX86_BUILTIN_PSRLVV4SI,\n+\tIX86_BUILTIN_GATHERSIV2DF, IX86_BUILTIN_GATHERSIV4DF,\n+\tIX86_BUILTIN_GATHERDIV2DF, IX86_BUILTIN_GATHERDIV4DF,\n+\tIX86_BUILTIN_GATHERSIV4SF, IX86_BUILTIN_GATHERSIV8SF,\n+\tIX86_BUILTIN_GATHERDIV4SF, IX86_BUILTIN_GATHERDIV8SF,\n+\tIX86_BUILTIN_GATHERSIV2DI, IX86_BUILTIN_GATHERSIV4DI,\n+\tIX86_BUILTIN_GATHERDIV2DI, IX86_BUILTIN_GATHERDIV4DI,\n+\tIX86_BUILTIN_GATHERSIV4SI, IX86_BUILTIN_GATHERSIV8SI,\n+\tIX86_BUILTIN_GATHERDIV4SI, IX86_BUILTIN_GATHERDIV8SI.\n+\t(bdesc_special_args): Add IX86_BUILTIN_MOVNTDQA256,\n+\tIX86_BUILTIN_MASKLOADD, IX86_BUILTIN_MASKLOADQ,\n+\tIX86_BUILTIN_MASKLOADD256, IX86_BUILTIN_MASKLOADQ256,\n+\tIX86_BUILTIN_MASKSTORED, IX86_BUILTIN_MASKSTOREQ,\n+\tIX86_BUILTIN_MASKSTORED256, IX86_BUILTIN_MASKSTOREQ256.\n+\t(bdesc_args): Add  IX86_BUILTIN_MPSADBW256,\n+\tIX86_BUILTIN_PABSB256, IX86_BUILTIN_PABSW256,\n+\tIX86_BUILTIN_PABSD256, IX86_BUILTIN_PACKSSDW256,\n+\tIX86_BUILTIN_PACKSSWB256, IX86_BUILTIN_PACKUSDW256,\n+\tIX86_BUILTIN_PACKUSWB256, IX86_BUILTIN_PADDB256,\n+\tIX86_BUILTIN_PADDW256, IX86_BUILTIN_PADDD256,\n+\tIX86_BUILTIN_PADDQ256, IX86_BUILTIN_PADDSB256,\n+\tIX86_BUILTIN_PADDSW256, IX86_BUILTIN_PADDUSB256,\n+\tIX86_BUILTIN_PADDUSW256, IX86_BUILTIN_PALIGNR256,\n+\tIX86_BUILTIN_AND256I, IX86_BUILTIN_ANDNOT256I,\n+\tIX86_BUILTIN_PAVGB256, IX86_BUILTIN_PAVGW256,\n+\tIX86_BUILTIN_PBLENDVB256, IX86_BUILTIN_PBLENDVW256,\n+\tIX86_BUILTIN_PCMPEQB256, IX86_BUILTIN_PCMPEQW256,\n+\tIX86_BUILTIN_PCMPEQD256, IX86_BUILTIN_PCMPEQQ256,\n+\tIX86_BUILTIN_PCMPGTB256, IX86_BUILTIN_PCMPGTW256,\n+\tIX86_BUILTIN_PCMPGTD256, IX86_BUILTIN_PCMPGTQ256,\n+\tIX86_BUILTIN_PHADDW256, IX86_BUILTIN_PHADDD256,\n+\tIX86_BUILTIN_PHADDSW256, IX86_BUILTIN_PHSUBW256,\n+\tIX86_BUILTIN_PHSUBD256, IX86_BUILTIN_PHSUBSW256,\n+\tIX86_BUILTIN_PMADDUBSW256, IX86_BUILTIN_PMADDWD256,\n+\tIX86_BUILTIN_PMAXSB256, IX86_BUILTIN_PMAXSW256,\n+\tIX86_BUILTIN_PMAXSD256, IX86_BUILTIN_PMAXUB256,\n+\tIX86_BUILTIN_PMAXUW256, IX86_BUILTIN_PMAXUD256,\n+\tIX86_BUILTIN_PMINSB256, IX86_BUILTIN_PMINSW256,\n+\tIX86_BUILTIN_PMINSD256, IX86_BUILTIN_PMINUB256,\n+\tIX86_BUILTIN_PMINUW256, IX86_BUILTIN_PMINUD256,\n+\tIX86_BUILTIN_PMOVMSKB256, IX86_BUILTIN_PMOVSXBW256,\n+\tIX86_BUILTIN_PMOVSXBD256, IX86_BUILTIN_PMOVSXBQ256,\n+\tIX86_BUILTIN_PMOVSXWD256, IX86_BUILTIN_PMOVSXWQ256,\n+\tIX86_BUILTIN_PMOVSXDQ256, IX86_BUILTIN_PMOVZXBW256,\n+\tIX86_BUILTIN_PMOVZXBD256, IX86_BUILTIN_PMOVZXBQ256,\n+\tIX86_BUILTIN_PMOVZXWD256, IX86_BUILTIN_PMOVZXWQ256,\n+\tIX86_BUILTIN_PMOVZXDQ256, IX86_BUILTIN_PMULDQ256,\n+\tIX86_BUILTIN_PMULHRSW256, IX86_BUILTIN_PMULHUW256,\n+\tIX86_BUILTIN_PMULHW256, IX86_BUILTIN_PMULLW256,\n+\tIX86_BUILTIN_PMULLD256, IX86_BUILTIN_PMULUDQ256,\n+\tIX86_BUILTIN_POR256, IX86_BUILTIN_PSADBW256,\n+\tIX86_BUILTIN_PSHUFB256, IX86_BUILTIN_PSHUFD256,\n+\tIX86_BUILTIN_PSHUFHW256, IX86_BUILTIN_PSHUFLW256,\n+\tIX86_BUILTIN_PSIGNB256, IX86_BUILTIN_PSIGNW256,\n+\tIX86_BUILTIN_PSIGND256, IX86_BUILTIN_PSLLDQI256,\n+\tIX86_BUILTIN_PSLLWI256, IX86_BUILTIN_PSLLW256,\n+\tIX86_BUILTIN_PSLLDI256, IX86_BUILTIN_PSLLD256,\n+\tIX86_BUILTIN_PSLLQI256, IX86_BUILTIN_PSLLQ256,\n+\tIX86_BUILTIN_PSRAWI256, IX86_BUILTIN_PSRAW256,\n+\tIX86_BUILTIN_PSRADI256, IX86_BUILTIN_PSRAD256,\n+\tIX86_BUILTIN_PSRLDQI256, IX86_BUILTIN_PSRLWI256,\n+\tIX86_BUILTIN_PSRLW256, IX86_BUILTIN_PSRLDI256,\n+\tIX86_BUILTIN_PSRLD256, IX86_BUILTIN_PSRLQI256,\n+\tIX86_BUILTIN_PSRLQ256, IX86_BUILTIN_PSUBB256,\n+\tIX86_BUILTIN_PSUBW256, IX86_BUILTIN_PSUBD256,\n+\tIX86_BUILTIN_PSUBQ256, IX86_BUILTIN_PSUBSB256,\n+\tIX86_BUILTIN_PSUBSW256, IX86_BUILTIN_PSUBUSB256,\n+\tIX86_BUILTIN_PSUBUSW256, IX86_BUILTIN_PUNPCKHBW256,\n+\tIX86_BUILTIN_PUNPCKHWD256, IX86_BUILTIN_PUNPCKHDQ256,\n+\tIX86_BUILTIN_PUNPCKHQDQ256, IX86_BUILTIN_PUNPCKLBW256,\n+\tIX86_BUILTIN_PUNPCKLWD256, IX86_BUILTIN_PUNPCKLDQ256,\n+\tIX86_BUILTIN_PUNPCKLQDQ256, IX86_BUILTIN_PXOR256,\n+\tIX86_BUILTIN_VBROADCASTSS_PS, IX86_BUILTIN_VBROADCASTSS_PS256,\n+\tIX86_BUILTIN_VBROADCASTSD_PD256,\n+\tIX86_BUILTIN_VBROADCASTSI256, IX86_BUILTIN_PBLENDD256,\n+\tIX86_BUILTIN_PBLENDD128, IX86_BUILTIN_PBROADCASTB256,\n+\tIX86_BUILTIN_PBROADCASTW256, IX86_BUILTIN_PBROADCASTD256,\n+\tIX86_BUILTIN_PBROADCASTQ256, IX86_BUILTIN_PBROADCASTB128,\n+\tIX86_BUILTIN_PBROADCASTW128, IX86_BUILTIN_PBROADCASTD128,\n+\tIX86_BUILTIN_PBROADCASTQ128, IX86_BUILTIN_VPERMVARSI256,\n+\tIX86_BUILTIN_VPERMDF256, IX86_BUILTIN_VPERMVARSF256,\n+\tIX86_BUILTIN_VPERMDI256, IX86_BUILTIN_VPERMTI256,\n+\tIX86_BUILTIN_VEXTRACT128I256, IX86_BUILTIN_VINSERT128I256,\n+\tIX86_BUILTIN_PSLLVV4DI, IX86_BUILTIN_PSLLVV2DI,\n+\tIX86_BUILTIN_PSLLVV8SI, IX86_BUILTIN_PSLLVV4SI,\n+\tIX86_BUILTIN_PSRAVV8SI, IX86_BUILTIN_PSRAVV4SI,\n+\tIX86_BUILTIN_PSRLVV4DI, IX86_BUILTIN_PSRLVV2DI,\n+\tIX86_BUILTIN_PSRLVV8SI, IX86_BUILTIN_PSRLVV4SI.\n+\t(ix86_init_mmx_sse_builtins): Add IX86_BUILTIN_GATHERSIV2DF,\n+\tIX86_BUILTIN_GATHERSIV4DF, IX86_BUILTIN_GATHERDIV2DF,\n+\tIX86_BUILTIN_GATHERDIV4DF, IX86_BUILTIN_GATHERSIV4SF,\n+\tIX86_BUILTIN_GATHERSIV8SF, IX86_BUILTIN_GATHERDIV4SF,\n+\tIX86_BUILTIN_GATHERDIV8SF, IX86_BUILTIN_GATHERSIV2DI,\n+\tIX86_BUILTIN_GATHERSIV4DI, IX86_BUILTIN_GATHERDIV2DI,\n+\tIX86_BUILTIN_GATHERDIV4DI, IX86_BUILTIN_GATHERSIV4SI,\n+\tIX86_BUILTIN_GATHERSIV8SI, IX86_BUILTIN_GATHERDIV4SI,\n+\tIX86_BUILTIN_GATHERDIV8SI.\n+\t(ix86_preferred_simd_mode): Support AVX2 modes.\n+\t(ix86_expand_args_builtin): Support AVX2 built-ins.\n+\t(ix86_expand_special_args_builtin): Likewise.\n+\t(ix86_expand_builtin): Likewise.\n+\t* config/i386/i386.md (UNSPEC_VPERMSI): New.\n+\t(UNSPEC_VPERMDF): Likewise.\n+\t(UNSPEC_VPERMSF): Likewise.\n+\t(UNSPEC_VPERMDI): Likewise.\n+\t(UNSPEC_VPERMTI): Likewise.\n+\t(UNSPEC_GATHER): Likewise.\n+\t(ssemodesuffix): Extend.\n+\t* config/i386/immintrin.h: Include avx2intrin.h when __AVX2__\n+\tis defined.\n+\t* config/i386/predicates.md (const1248_operand): New.\n+\t* config/i386/sse.md (VI_AVX2):\n+\t(VI1_AVX2): Likewise.\n+\t(VI2_AVX2): Likewise.\n+\t(VI4_AVX2): Likewise.\n+\t(VI8_AVX2): Likewise.\n+\t(VIMAX_AVX2): Likewise.\n+\t(SSESCALARMODE): Likewise.\n+\t(VI12_AVX2): Likewise.\n+\t(VI24_AVX2): Likewise.\n+\t(VI124_AVX2): Likeuse_submit_for_speed = 1\n+\twise.\n+\t(VI248_AVX2): Likewise.\n+\t(VI48_AVX2): Likewise.\n+\t(VI4SD_AVX2): Likewise.\n+\t(V48_AVX2): Likewise.\n+\t(avx2modesuffix): Likewise.\n+\t(sse_avx2): Likewise.\n+\t(sse2_avx2): Likewise.\n+\t(ssse3_avx2): Likewise.\n+\t(sse4_1_avx2): Likewise.\n+\t(avx_avx2): Likewise.\n+\t(lshift)<code_oterator>: Likewise.\n+\t(lshift_insn): Likewise.\n+\t(lshift)<code_attr>: Likewise.\n+\t(SSESHORTMODE): Likewise.\n+\t(SSELONGMODE): Likewise.\n+\t(SSEBYTEMODE): Likewise.\n+\t(AVXTOSSEMODE): Likewise.\n+\t(shortmode): Likewise.\n+\t(ssescalarmodesuffix): Update.\n+\t(sseunpackmode): Likewise.\n+\t(ssepackmode): Likewise.\n+\t(AVX256MODEI): New.\n+\t(AVX256MODE124): Likewise.\n+\t(AVX256MODE1248): Likewise.\n+\t(AVX256MODE248): Likewise.\n+\t(AVXMODE48P_SI): Likewise.\n+\t(AVXMODE48P_SI): Likewise.\n+\t(AVXMODE48P_DI): Likewise.\n+\t(AVXMODE48P_DI): Likewise.\n+\t(gthrfirstp): Likewise.\n+\t(gthrlastp): Likewise.\n+\t(avx2): Likwise.\n+\t(ssevecsize): Likewise.\n+\t(ssedoublesizemode): Likewise.\n+\t(avxvecmode): Likewise.\n+\t(avxvecsize): Likewise.\n+\t(avxhalfvecmode): Likewise.\n+\t(avxscalarmode): Likewise.\n+\t(avxpermvecmode): Likewise.\n+\t(avxmodesuffixp): Likewise.\n+\t(avxmodesuffix): Likewise.\n+\t(avx2_vec_dupv4sf): New.\n+\t(avx2_vec_dupv8sf): Likewise.\n+\t(avx2_interleave_highv4di): Likewise.\n+\t(avx2_interleave_lowv4di): Likewise.\n+\t(<plusminus_insn><mode>3): Update.\n+\t(*<plusminus_insn><mode>3): Likewise.\n+\t(sse2_<plusminus_insn><mode>3): Rename to ...\n+\t(\"<sse2_avx2>_<plusminus_insn><mode>3): ... this. updated.\n+\t(*sse2_<plusminus_insn><mode>3): Likewise.\n+\t(*<sse2_avx2>_<plusminus_insn><mode>3): Likewise.\n+\t(mulv8hi3): Likewise.\n+\t(mul<mode>3): Likewise.\n+\t(*mulv8hi3): Likewise.\n+\t(*mul<mode>3): Likewise.\n+\t(<s>mulv8hi3_highpart): Likewise.\n+\t(<s>mul<mode>3_highpart): Likewise.\n+\t(*<s>mulv8hi3_highpart): Likewise.\n+\t(*<s>mul<mode>3_highpart): Likewise.\n+\t(avx2_umulv4siv4di3): Likewise.\n+\t(*avx_umulv4siv4di3): Likewise.\n+\t(sse4_1_mulv2siv2di3): Likewise.\n+\t(<sse4_1_avx2>_mul<shortmode><mode>3): Likewise.\n+\t(*sse4_1_mulv2siv2di3): Likewise.\n+\t(*<sse4_1_avx2>_mulv2siv2di3): Likewise.\n+\t(avx2_pmaddwd): New.\n+\t(*avx2_pmaddwd): Likewise.\n+\t(mulv4si3): Rename to ...\n+\t(mul<mode>3): ... this. Update.\n+\t(*sse4_1_mulv4si3): Likewise.\n+\t(*<sse4_1_avx2>_mul<mode>3): Likewise.\n+\t(ashr<mode>3): Update.\n+\t(avx2_lshrqv4di3): New.\n+\t(lshr<mode>3): Update.\n+\t(avx2_lshlqv4di3): New.\n+\t(avx2_lshl<mode>3): Likewise.\n+\t(sse2_ashlv1ti3): Rename to ...\n+\t(<sse2_avx2>_ashl<mode>3): ... this. Update.\n+\t(avx2_<code><mode>3)<umaxmin>: New.\n+\t(*avx2_<code><mode>3)<umaxmin>: Likewise.\n+\t(avx2_<code><mode>3)<smaxmin>: New.\n+\t(*avx2_<code><mode>3)<smaxmin>: Likewise.\n+\t(avx2_eq<mode>3): Likewise.\n+\t(*avx2_eq<mode>3): Likewise.\n+\t(avx2_gt<mode>3): Likewise.\n+\t(sse2_andnot<mode>3): Rename to ...\n+\t(<sse2_avx2>_andnot<mode>3): ... this. Update.\n+\t(*andnot<mode>3): Update.\n+\t(<code><mode>3)<any_logic>: Update.\n+\t(*<code><mode>3)<any_logic>: Likewise.\n+\t(sse2_packsswb): Rename to ...\n+\t(<sse2_avx2>_packsswb): ... this. Update.\n+\t(sse2_packssdw): Likewise.\n+\t(<sse2_avx2>_packssdw): Likewise.\n+\t(sse2_packuswb): Likewise.\n+\t(<sse2_avx2>_packuswb): Likewise.\n+\t(avx2_interleave_highv32qi): New.\n+\t(avx2_interleave_lowv32qi): Likewise.\n+\t(avx2_interleave_highv16hi): Likewise.\n+\t(avx2_interleave_lowv16hi): Likewise.\n+\t(avx2_interleave_highv8si): Likewise.\n+\t(avx2_interleave_lowv8si): Likewise.\n+\t(avx2_pshufd): New\n+\t(avx2_pshufd_1): Likewise.\n+\t(avx2_pshuflwv3): Likewise.\n+\t(avx2_pshuflw_1): Likewise.\n+\t(avx2_pshufhwv3): Likewise.\n+\t(avx2_pshufhw_1): Likewise.\n+\t(avx2_uavgv32qi3): Likewise.\n+\t(*avx2_uavgv32qi3): Likewise.\n+\t(avx2_uavgv16hi3): Likewise.\n+\t(*avx2_uavgv16hi3): Likewise.\n+\t(sse2_psadbw): Rename to ...\n+\t(<sse2_avx2>_psadbw): ... this. Update.\n+\t(avx2_pmovmskb): New.\n+\t(avx2_phaddwv16hi3): Likewise.\n+\t(avx2_phadddv8si3): Likewise.\n+\t(avx2_phaddswv16hi3): Likewise.\n+\t(avx2_phsubwv16hi3): Likewise.\n+\t(avx2_phsubdv8si3): Likewise.\n+\t(avx2_phsubswv16hi3): Likewise.\n+\t(avx2_pmaddubsw256): Likewise.\n+\t(avx2_umulhrswv16hi3): Likewise.\n+\t(*avx2_umulhrswv16hi3): Likewise.\n+\t(ssse3_pshufbv16qi3): Rename to ...\n+\t(<ssse3_avx2>_pshufb<mode>3): ... this. Update.\n+\t(ssse3_psign<mode>3): Likewise.\n+\t(<ssse3_avx2>_psign<mode>3): Likewise.\n+\t(ssse3_palignrti): Likewise.\n+\t(<ssse3_avx2>_palignr<mode>): Likewise.\n+\t(abs<mode>2): Likewise.\n+\t(sse4_1_movntdqa): Rename to ...\n+\t(<sse4_1_avx2>_movntdqa): ... this. Update.\n+\t(sse4_1_mpsadbw): Likewise.\n+\t(<sse4_1_avx2>_mpsadbw): Likewise.\n+\t(avx2_packusdw): New.\n+\t(sse4_1_pblendvb): Rename to ...\n+\t(<sse4_1_avx2>_pblendvb): ... this. Update.\n+\t(sse4_1_pblendw): Likewise.\n+\t(<sse4_1_avx2>_pblendw): Likewise.\n+\t(avx2_pblendd<mode>): New.\n+\t(avx2_<code>v16qiv16hi2): Likewise.\n+\t(avx2_<code>v8qiv8si2): Likewise.\n+\t(avx2_<code>v8hiv8si2): Likewise.\n+\t(avx2_<code>v4qiv4di2): Likewise.\n+\t(avx2_<code>v4hiv4di2): Likewise.\n+\t(avx2_<code>v4siv4di2): Likewise.\n+\t(avx2_pbroadcast<mode>): Likewise.\n+\t(avx2_permvarv8si): Likewise.\n+\t(avx2_permv4df): Likewise.\n+\t(avx2_permvarv8sf): Likewise.\n+\t(avx2_permv4di): Likewise.\n+\t(avx2_permv2ti): Likewise.\n+\t(avx2_vec_dupv4df): Likewise.\n+\t(avx2_vbroadcasti128_<mode>): Likewise.\n+\t(avx2_vec_set_lo_v4di): Likewise.\n+\t(avx2_vec_set_hi_v4di): Likewise.\n+\t(avx_maskload<ssemodesuffix><avxsizesuffix>): Rename to ...\n+\t(<avx_avx2>_maskload<avx2modesuffix><avxmodesuffix>): ... this.\n+\tUpdate.\n+\t(avx_maskstore<ssemodesuffix><avxsizesuffix>): Likewise.\n+\t(<avx_avx2>_maskstore<avx2modesuffix><avxmodesuffix>): Likewise.\n+\t(*avx2_maskmov<avx2modesuffix><avxmodesuffix>): New.\n+\t(avx2_extracti128): Likewise.\n+\t(avx2_inserti128): Likewise.\n+\t(avx2_ashrvv8si): Likewise.\n+\t(avx2_ashrvv4si): Likewise.\n+\t(avx2_<lshift>vv8si): Likewise.\n+\t(avx2_<lshift>v<mode>): Likewise.\n+\t(avx2_<lshift>vv2di): Likewise.\n+\t(avx2_gathersi<mode>): Likewise.\n+\t(*avx2_gathersi<mode>): Likewise.\n+\t(avx2_gatherdi<mode>): Likewise.\n+\t(*avx2_gatherdi<mode>): Likewise.\n+\t(avx2_gatherdi<mode>256): Likewise.\n+\t(*avx2_gatherdi<mode>256): Likewise.\n+\t* doc/extend.texi: Document AVX2 built-in functions.\n+\t* doc/invoke.texi: Document -mavx2.\n+\n 2011-08-22  Matthias Klose <doko@debian.org>\n \n \tRevert:"}, {"sha": "b8addaf64572aca9e7889baa326cb8d63bc9ba6e", "filename": "gcc/config.gcc", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -352,7 +352,7 @@ i[34567]86-*-*)\n \t\t       nmmintrin.h bmmintrin.h fma4intrin.h wmmintrin.h\n \t\t       immintrin.h x86intrin.h avxintrin.h xopintrin.h\n \t\t       ia32intrin.h cross-stdarg.h lwpintrin.h popcntintrin.h\n-\t\t       lzcntintrin.h bmiintrin.h tbmintrin.h\"\n+\t\t       lzcntintrin.h bmiintrin.h tbmintrin.h avx2intrin.h\"\n \t;;\n x86_64-*-*)\n \tcpu_type=i386\n@@ -364,7 +364,7 @@ x86_64-*-*)\n \t\t       nmmintrin.h bmmintrin.h fma4intrin.h wmmintrin.h\n \t\t       immintrin.h x86intrin.h avxintrin.h xopintrin.h\n \t\t       ia32intrin.h cross-stdarg.h lwpintrin.h popcntintrin.h\n-\t\t       lzcntintrin.h bmiintrin.h tbmintrin.h\"\n+\t\t       lzcntintrin.h bmiintrin.h tbmintrin.h avx2intrin.h\"\n \tneed_64bit_hwint=yes\n \t;;\n ia64-*-*)"}, {"sha": "3c8f3600d6830c8702bb78213b981bcf1f6daef3", "filename": "gcc/config/i386/avx2intrin.h", "status": "added", "additions": 1874, "deletions": 0, "changes": 1874, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Favx2intrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Favx2intrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx2intrin.h?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -0,0 +1,1874 @@\n+/* Copyright (C) 2011\n+   Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify\n+   it under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful,\n+   but WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+   GNU General Public License for more details.\n+\n+   Under Section 7 of GPL version 3, you are granted additional\n+   permissions described in the GCC Runtime Library Exception, version\n+   3.1, as published by the Free Software Foundation.\n+\n+   You should have received a copy of the GNU General Public License and\n+   a copy of the GCC Runtime Library Exception along with this program;\n+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#ifndef _IMMINTRIN_H_INCLUDED\n+# error \"Never use <avx2intrin.h> directly; include <immintrin.h> instead.\"\n+#endif\n+\n+/* Sum absolute 8-bit integer difference of adjacent groups of 4\n+   byte integers in the first 2 operands.  Starting offsets within\n+   operands are determined by the 3rd mask operand.  */\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mpsadbw_epu8 (__m256i __X, __m256i __Y, const int __M)\n+{\n+  return (__m256i) __builtin_ia32_mpsadbw256 ((__v32qi)__X,\n+\t\t\t\t\t      (__v32qi)__Y, __M);\n+}\n+#else\n+#define _mm256_mpsadbw_epu8(X, Y, M)\t\t\t\t\t\\\n+  ((__m256i) __builtin_ia32_mpsadbw256 ((__v32qi)(__m256i)(X),\t\t\\\n+\t\t\t\t\t(__v32qi)(__m256i)(Y), (int)(M)))\n+#endif\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_abs_epi8 (__m256i __A)\n+{\n+  return (__m256i)__builtin_ia32_pabsb256 ((__v32qi)__A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_abs_epi16 (__m256i __A)\n+{\n+  return (__m256i)__builtin_ia32_pabsw256 ((__v16hi)__A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_abs_epi32 (__m256i __A)\n+{\n+  return (__m256i)__builtin_ia32_pabsd256 ((__v8si)__A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_packs_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_packssdw256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_packs_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_packsswb256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_packus_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_packusdw256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_packus_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_packuswb256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_add_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_paddb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_add_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_paddw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_add_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_paddd256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_add_epi64 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_paddq256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_adds_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_paddsb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_adds_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_paddsw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_adds_epu8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_paddusb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_adds_epu16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_paddusw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_alignr_epi8 (__m256i __A, __m256i __B, const int __N)\n+{\n+  return (__m256i) __builtin_ia32_palignr256 ((__v4di)__A,\n+\t\t\t\t\t      (__v4di)__B,\n+\t\t\t\t\t      __N * 8);\n+}\n+#else\n+/* In that case (__N*8) will be in vreg, and insn will not be matched. */\n+/* Use define instead */\n+#define _mm256_alignr_epi8(A, B, N)\t\t\t\t   \\\n+  ((__m256i) __builtin_ia32_palignr256 ((__v4di)(__m256i)(A),\t   \\\n+\t\t\t\t\t(__v4di)(__m256i)(B),\t   \\\n+\t\t\t\t\t(int)(N) * 8))\n+#endif\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_and_si256 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i) __builtin_ia32_andsi256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_andnot_si256 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i) __builtin_ia32_andnotsi256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_avg_epu8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pavgb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_avg_epu16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pavgw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_blendv_epi8 (__m256i __X, __m256i __Y, __m256i __M)\n+{\n+  return (__m256i) __builtin_ia32_pblendvb256 ((__v32qi)__X,\n+\t\t\t\t\t       (__v32qi)__Y,\n+\t\t\t\t\t       (__v32qi)__M);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_blend_epi16 (__m256i __X, __m256i __Y, const int __M)\n+{\n+  return (__m256i) __builtin_ia32_pblendw256 ((__v16hi)__X,\n+\t\t\t\t\t      (__v16hi)__Y,\n+\t\t\t\t\t       __M);\n+}\n+#else\n+#define _mm256_blend_epi16(X, Y, M)\t\t\t\t\t\\\n+  ((__m256i) __builtin_ia32_pblendw256 ((__v16hi)(__m256i)(X),\t\t\\\n+\t\t\t\t\t(__v16hi)(__m256i)(Y), (int)(M)))\n+#endif\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cmpeq_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pcmpeqb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cmpeq_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pcmpeqw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cmpeq_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pcmpeqd256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cmpeq_epi64 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pcmpeqq256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cmpgt_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pcmpgtb256 ((__v32qi)__A,\n+\t\t\t\t\t     (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cmpgt_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pcmpgtw256 ((__v16hi)__A,\n+\t\t\t\t\t     (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cmpgt_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pcmpgtd256 ((__v8si)__A,\n+\t\t\t\t\t     (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cmpgt_epi64 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pcmpgtq256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_hadd_epi16 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_phaddw256 ((__v16hi)__X,\n+\t\t\t\t\t     (__v16hi)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_hadd_epi32 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_phaddd256 ((__v8si)__X, (__v8si)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_hadds_epi16 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_phaddsw256 ((__v16hi)__X,\n+\t\t\t\t\t      (__v16hi)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_hsub_epi16 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_phsubw256 ((__v16hi)__X,\n+\t\t\t\t\t     (__v16hi)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_hsub_epi32 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_phsubd256 ((__v8si)__X, (__v8si)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_hsubs_epi16 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_phsubsw256 ((__v16hi)__X,\n+\t\t\t\t\t      (__v16hi)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maddubs_epi16 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_pmaddubsw256 ((__v32qi)__X,\n+\t\t\t\t\t\t(__v32qi)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_madd_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmaddwd256 ((__v16hi)__A,\n+\t\t\t\t\t     (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_max_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmaxsb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_max_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmaxsw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_max_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmaxsd256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_max_epu8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmaxub256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_max_epu16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmaxuw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_max_epu32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmaxud256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_min_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pminsb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_min_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pminsw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_min_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pminsd256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_min_epu8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pminub256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_min_epu16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pminuw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_min_epu32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pminud256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline int\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_movemask_epi8 (__m256i __A)\n+{\n+  return __builtin_ia32_pmovmskb256 ((__v32qi)__A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepi8_epi16 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovsxbw256 ((__v16qi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepi8_epi32 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovsxbd256 ((__v16qi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepi8_epi64 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovsxbq256 ((__v16qi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepi16_epi32 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovsxwd256 ((__v8hi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepi16_epi64 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovsxwq256 ((__v8hi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepi32_epi64 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovsxdq256 ((__v4si)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepu8_epi16 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovzxbw256 ((__v16qi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepu8_epi32 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovzxbd256 ((__v16qi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepu8_epi64 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovzxbq256 ((__v16qi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepu16_epi32 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovzxwd256 ((__v8hi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepu16_epi64 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovzxwq256 ((__v8hi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtepu32_epi64 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pmovzxdq256 ((__v4si)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mul_epi32 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_pmuldq256 ((__v8si)__X, (__v8si)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mulhrs_epi16 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_pmulhrsw256 ((__v16hi)__X,\n+\t\t\t\t\t       (__v16hi)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mulhi_epu16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmulhuw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mulhi_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmulhw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mullo_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmullw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mullo_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmulld256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mul_epu32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pmuludq256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_or_si256 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_por256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sad_epu8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psadbw256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_shuffle_epi8 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_pshufb256 ((__v32qi)__X,\n+\t\t\t\t\t     (__v32qi)__Y);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_shuffle_epi32 (__m256i __A, const int __mask)\n+{\n+  return (__m256i)__builtin_ia32_pshufd256 ((__v8si)__A, __mask);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_shufflehi_epi16 (__m256i __A, const int __mask)\n+{\n+  return (__m256i)__builtin_ia32_pshufhw256 ((__v16hi)__A, __mask);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_shufflelo_epi16 (__m256i __A, const int __mask)\n+{\n+  return (__m256i)__builtin_ia32_pshuflw256 ((__v16hi)__A, __mask);\n+}\n+#else\n+#define _mm256_shuffle_epi32(A, N) \\\n+  ((__m256i)__builtin_ia32_pshufd256 ((__v8si)(__m256i)(A), (int)(N)))\n+#define _mm256_shufflehi_epi16(A, N) \\\n+  ((__m256i)__builtin_ia32_pshufhw256 ((__v16hi)(__m256i)(A), (int)(N)))\n+#define _mm256_shufflelo_epi16(A, N) \\\n+  ((__m256i)__builtin_ia32_pshuflw256 ((__v16hi)(__m256i)(A), (int)(N)))\n+#endif\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sign_epi8 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_psignb256 ((__v32qi)__X, (__v32qi)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sign_epi16 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_psignw256 ((__v16hi)__X, (__v16hi)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sign_epi32 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_psignd256 ((__v8si)__X, (__v8si)__Y);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_slli_si256 (__m256i __A, const int __N)\n+{\n+  return (__m256i)__builtin_ia32_pslldqi256 (__A, __N * 8);\n+}\n+#else\n+#define _mm256_slli_si256(A, N) \\\n+  ((__m256i)__builtin_ia32_pslldqi256 ((__m256i)(A), (int)(N) * 8))\n+#endif\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_slli_epi16 (__m256i __A, int __B)\n+{\n+  return (__m256i)__builtin_ia32_psllwi256 ((__v16hi)__A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sll_epi16 (__m256i __A, __m128i __B)\n+{\n+  return (__m256i)__builtin_ia32_psllw256((__v16hi)__A, (__v8hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_slli_epi32 (__m256i __A, int __B)\n+{\n+  return (__m256i)__builtin_ia32_pslldi256 ((__v8si)__A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sll_epi32 (__m256i __A, __m128i __B)\n+{\n+  return (__m256i)__builtin_ia32_pslld256((__v8si)__A, (__v4si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_slli_epi64 (__m256i __A, int __B)\n+{\n+  return (__m256i)__builtin_ia32_psllqi256 ((__v4di)__A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sll_epi64 (__m256i __A, __m128i __B)\n+{\n+  return (__m256i)__builtin_ia32_psllq256((__v4di)__A, (__v2di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srai_epi16 (__m256i __A, int __B)\n+{\n+  return (__m256i)__builtin_ia32_psrawi256 ((__v16hi)__A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sra_epi16 (__m256i __A, __m128i __B)\n+{\n+  return (__m256i)__builtin_ia32_psraw256 ((__v16hi)__A, (__v8hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srai_epi32 (__m256i __A, int __B)\n+{\n+  return (__m256i)__builtin_ia32_psradi256 ((__v8si)__A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sra_epi32 (__m256i __A, __m128i __B)\n+{\n+  return (__m256i)__builtin_ia32_psrad256 ((__v8si)__A, (__v4si)__B);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srli_si256 (__m256i __A, const int __N)\n+{\n+  return (__m256i)__builtin_ia32_psrldqi256 (__A, __N * 8);\n+}\n+#else\n+#define _mm256_srli_si256(A, N) \\\n+  ((__m256i)__builtin_ia32_psrldqi256 ((__m256i)(A), (int)(N) * 8))\n+#endif\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srli_epi16 (__m256i __A, int __B)\n+{\n+  return (__m256i)__builtin_ia32_psrlwi256 ((__v16hi)__A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srl_epi16 (__m256i __A, __m128i __B)\n+{\n+  return (__m256i)__builtin_ia32_psrlw256((__v16hi)__A, (__v8hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srli_epi32 (__m256i __A, int __B)\n+{\n+  return (__m256i)__builtin_ia32_psrldi256 ((__v8si)__A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srl_epi32 (__m256i __A, __m128i __B)\n+{\n+  return (__m256i)__builtin_ia32_psrld256((__v8si)__A, (__v4si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srli_epi64 (__m256i __A, int __B)\n+{\n+  return (__m256i)__builtin_ia32_psrlqi256 ((__v4di)__A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srl_epi64 (__m256i __A, __m128i __B)\n+{\n+  return (__m256i)__builtin_ia32_psrlq256((__v4di)__A, (__v2di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sub_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psubb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sub_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psubw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sub_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psubd256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sub_epi64 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psubq256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_subs_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psubsb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_subs_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psubsw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_subs_epu8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psubusb256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_subs_epu16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_psubusw256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_unpackhi_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_punpckhbw256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_unpackhi_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_punpckhwd256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_unpackhi_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_punpckhdq256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_unpackhi_epi64 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_punpckhqdq256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_unpacklo_epi8 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_punpcklbw256 ((__v32qi)__A, (__v32qi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_unpacklo_epi16 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_punpcklwd256 ((__v16hi)__A, (__v16hi)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_unpacklo_epi32 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_punpckldq256 ((__v8si)__A, (__v8si)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_unpacklo_epi64 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_punpcklqdq256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_xor_si256 (__m256i __A, __m256i __B)\n+{\n+  return (__m256i)__builtin_ia32_pxor256 ((__v4di)__A, (__v4di)__B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_stream_load_si256 (__m256i const *__X)\n+{\n+  return (__m256i) __builtin_ia32_movntdqa256 ((__v4di *) __X);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_broadcastss_ps (__m128 __X)\n+{\n+  return (__m128) __builtin_ia32_vbroadcastss_ps ((__v4sf)__X);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcastss_ps (__m128 __X)\n+{\n+  return (__m256) __builtin_ia32_vbroadcastss_ps256 ((__v4sf)__X);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcastsd_pd (__m128d __X)\n+{\n+  return (__m256d) __builtin_ia32_vbroadcastsd_pd256 ((__v2df)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_broadcastsi128_si256 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_vbroadcastsi256 ((__v2di)__X);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_blend_epi32 (__m128i __X, __m128i __Y, const int __M)\n+{\n+  return (__m128i) __builtin_ia32_pblendd128 ((__v4si)__X,\n+\t\t\t\t\t      (__v4si)__Y,\n+\t\t\t\t\t      __M);\n+}\n+#else\n+#define _mm_blend_epi32(X, Y, M)\t\t\t\t\t\\\n+  ((__m128i) __builtin_ia32_pblendd128 ((__v4si)(__m128i)(X),\t\t\\\n+\t\t\t\t\t(__v4si)(__m128i)(Y), (int)(M)))\n+#endif\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_blend_epi32 (__m256i __X, __m256i __Y, const int __M)\n+{\n+  return (__m256i) __builtin_ia32_pblendd256 ((__v8si)__X,\n+\t\t\t\t\t      (__v8si)__Y,\n+\t\t\t\t\t      __M);\n+}\n+#else\n+#define _mm256_blend_epi32(X, Y, M)\t\t\t\t\t\\\n+  ((__m256i) __builtin_ia32_pblendd256 ((__v8si)(__m256i)(X),\t\t\\\n+\t\t\t\t\t(__v8si)(__m256i)(Y), (int)(M)))\n+#endif\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcastb_epi8 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pbroadcastb256 ((__v16qi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcastw_epi16 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pbroadcastw256 ((__v8hi)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcastd_epi32 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pbroadcastd256 ((__v4si)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_broadcastq_epi64 (__m128i __X)\n+{\n+  return (__m256i) __builtin_ia32_pbroadcastq256 ((__v2di)__X);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_broadcastb_epi8 (__m128i __X)\n+{\n+  return (__m128i) __builtin_ia32_pbroadcastb128 ((__v16qi)__X);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_broadcastw_epi16 (__m128i __X)\n+{\n+  return (__m128i) __builtin_ia32_pbroadcastw128 ((__v8hi)__X);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_broadcastd_epi32 (__m128i __X)\n+{\n+  return (__m128i) __builtin_ia32_pbroadcastd128 ((__v4si)__X);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_broadcastq_epi64 (__m128i __X)\n+{\n+  return (__m128i) __builtin_ia32_pbroadcastq128 ((__v2di)__X);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_permutevar8x32_epi32 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_permvarsi256 ((__v8si)__X, (__v8si)__Y);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_permute4x64_pd (__m256d __X, const int __M)\n+{\n+  return (__m256d) __builtin_ia32_permdf256 ((__v4df)__X, __M);\n+}\n+#else\n+#define _mm256_permute4x64_pd(X, M)\t\t\t       \\\n+  ((__m256d) __builtin_ia32_permdf256 ((__v4df)(__m256d)(X), (int)(M)))\n+#endif\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_permutevar8x32_ps (__m256 __X, __m256 __Y)\n+{\n+  return (__m256) __builtin_ia32_permvarsf256 ((__v8sf)__X,(__v8sf)__Y);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_permute4x64_epi64 (__m256i __X, const int __M)\n+{\n+  return (__m256i) __builtin_ia32_permdi256 ((__v4di)__X, __M);\n+}\n+#else\n+#define _mm256_permute4x64_epi64(X, M)\t\t\t       \\\n+  ((__m256i) __builtin_ia32_permdi256 ((__v4di)(__m256i)(X), (int)(M)))\n+#endif\n+\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_permute2x128_si256 (__m256i __X, __m256i __Y, const int __M)\n+{\n+  return (__m256i) __builtin_ia32_permti256 ((__v4di)__X, (__v4di)__Y, __M);\n+}\n+#else\n+#define _mm256_permute2x128_si256(X, Y, M)\t\t\t\t\\\n+  ((__m256i) __builtin_ia32_permti256 ((__v4di)(__m256i)(X), (__v4di)(__m256i)(Y), (int)(M)))\n+#endif\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_extracti128_si256 (__m256i __X, const int __M)\n+{\n+  return (__m128i) __builtin_ia32_extract128i256 ((__v4di)__X, __M);\n+}\n+#else\n+#define _mm256_extracti128_si256(X, M)\t\t\t\t\\\n+  ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(X), (int)(M)))\n+#endif\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_inserti128_si256 (__m256i __X, __m128i __Y, const int __M)\n+{\n+  return (__m256i) __builtin_ia32_insert128i256 ((__v4di)__X, (__v2di)__Y, __M);\n+}\n+#else\n+#define _mm256_inserti128_si256(X, Y, M)\t\t\t \\\n+  ((__m256i) __builtin_ia32_insert128i256 ((__v4di)(__m256i)(X), \\\n+\t\t\t\t\t   (__v2di)(__m128i)(Y), \\\n+\t\t\t\t\t   (int)(M)))\n+#endif\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskload_epi32 (int const *__X, __m256i __M )\n+{\n+  return (__m256i) __builtin_ia32_maskloadd256 ((const __v8si *)__X,\n+\t\t\t\t\t\t(__v8si)__M);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskload_epi64 (long long const *__X, __m256i __M )\n+{\n+  return (__m256i) __builtin_ia32_maskloadq256 ((const __v4di *)__X,\n+\t\t\t\t\t\t(__v4di)__M);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskload_epi32 (int const *__X, __m128i __M )\n+{\n+  return (__m128i) __builtin_ia32_maskloadd ((const __v4si *)__X,\n+\t\t\t\t\t     (__v4si)__M);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskload_epi64 (long long const *__X, __m128i __M )\n+{\n+  return (__m128i) __builtin_ia32_maskloadq ((const __v2di *)__X,\n+\t\t\t\t\t     (__v2di)__M);\n+}\n+\n+extern __inline void\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskstore_epi32 (int *__X, __m256i __M, __m256i __Y )\n+{\n+  __builtin_ia32_maskstored256 ((__v8si *)__X, (__v8si)__M, (__v8si)__Y);\n+}\n+\n+extern __inline void\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskstore_epi64 (long long *__X, __m256i __M, __m256i __Y )\n+{\n+  __builtin_ia32_maskstoreq256 ((__v4di *)__X, (__v4di)__M, (__v4di)__Y);\n+}\n+\n+extern __inline void\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskstore_epi32 (int *__X, __m128i __M, __m128i __Y )\n+{\n+  __builtin_ia32_maskstored ((__v4si *)__X, (__v4si)__M, (__v4si)__Y);\n+}\n+\n+extern __inline void\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskstore_epi64 (long long *__X, __m128i __M, __m128i __Y )\n+{\n+  __builtin_ia32_maskstoreq (( __v2di *)__X, (__v2di)__M, (__v2di)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sllv_epi32 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_psllv8si ((__v8si)__X, (__v8si)__Y);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_sllv_epi32 (__m128i __X, __m128i __Y)\n+{\n+  return (__m128i) __builtin_ia32_psllv4si ((__v4si)__X, (__v4si)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_sllv_epi64 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_psllv4di ((__v4di)__X, (__v4di)__Y);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_sllv_epi64 (__m128i __X, __m128i __Y)\n+{\n+  return (__m128i) __builtin_ia32_psllv2di ((__v2di)__X, (__v2di)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srav_epi32 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_psrav8si ((__v8si)__X, (__v8si)__Y);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_srav_epi32 (__m128i __X, __m128i __Y)\n+{\n+  return (__m128i) __builtin_ia32_psrav4si ((__v4si)__X, (__v4si)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srlv_epi32 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_psrlv8si ((__v8si)__X, (__v8si)__Y);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_srlv_epi32 (__m128i __X, __m128i __Y)\n+{\n+  return (__m128i) __builtin_ia32_psrlv4si ((__v4si)__X, (__v4si)__Y);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_srlv_epi64 (__m256i __X, __m256i __Y)\n+{\n+  return (__m256i) __builtin_ia32_psrlv4di ((__v4di)__X, (__v4di)__Y);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_srlv_epi64 (__m128i __X, __m128i __Y)\n+{\n+  return (__m128i) __builtin_ia32_psrlv2di ((__v2di)__X, (__v2di)__Y);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_i32gather_pd (double const *base, __m128i index, const int scale)\n+{\n+  __v2df src = _mm_setzero_pd ();\n+  __v2df mask = _mm_cmpeq_pd (src, src);\n+\n+  return (__m128d) __builtin_ia32_gathersiv2df (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_i32gather_pd (__m128d src, double const *base, __m128i index,\n+\t\t       __m128d mask, const int scale)\n+{\n+  return (__m128d) __builtin_ia32_gathersiv2df ((__v2df)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\t(__v2df)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_i32gather_pd (double const *base, __m128i index, const int scale)\n+{\n+  __v4df src = _mm256_setzero_pd ();\n+  __v4df mask = _mm256_set1_pd((double)(long long int) -1);\n+\n+  return (__m256d) __builtin_ia32_gathersiv4df (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_i32gather_pd (__m256d src, double const *base,\n+\t\t\t  __m128i index, __m256d mask, const int scale)\n+{\n+  return (__m256d) __builtin_ia32_gathersiv4df ((__v4df)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\t(__v4df)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_i64gather_pd (double const *base, __m128i index, const int scale)\n+{\n+  __v2df src = _mm_setzero_pd ();\n+  __v2df mask = _mm_cmpeq_pd (src, src);\n+\n+  return (__m128d) __builtin_ia32_gatherdiv2df (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v2di)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_i64gather_pd (__m128d src, double const *base, __m128i index,\n+\t\t       __m128d mask, const int scale)\n+{\n+  return (__m128d) __builtin_ia32_gatherdiv2df ((__v2df)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v2di)index,\n+\t\t\t\t\t\t(__v2df)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_i64gather_pd (double const *base, __m256i index, const int scale)\n+{\n+  __v4df src = _mm256_setzero_pd ();\n+  __v4df mask = _mm256_set1_pd((double)(long long int) -1);\n+\n+  return (__m256d) __builtin_ia32_gatherdiv4df (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4di)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256d\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_i64gather_pd (__m256d src, double const *base,\n+\t\t\t  __m256i index, __m256d mask, const int scale)\n+{\n+  return (__m256d) __builtin_ia32_gatherdiv4df ((__v4df)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4di)index,\n+\t\t\t\t\t\t(__v4df)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_i32gather_ps (float const *base, __m128i index, const int scale)\n+{\n+  __v4sf src = _mm_setzero_ps ();\n+  __v4sf mask = _mm_cmpeq_ps (src, src);\n+\n+  return (__m128) __builtin_ia32_gathersiv4sf (src,\n+\t\t\t\t\t       base,\n+\t\t\t\t\t       (__v4si)index,\n+\t\t\t\t\t       mask,\n+\t\t\t\t\t       scale);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_i32gather_ps (__m128 src, float const *base, __m128i index,\n+\t\t       __m128 mask, const int scale)\n+{\n+  return (__m128) __builtin_ia32_gathersiv4sf ((__v4sf)src,\n+\t\t\t\t\t       base,\n+\t\t\t\t\t       (__v4si)index,\n+\t\t\t\t\t       (__v4sf)mask,\n+\t\t\t\t\t       scale);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_i32gather_ps (float const *base, __m256i index, const int scale)\n+{\n+  __v8sf src = _mm256_setzero_ps ();\n+  __v8sf mask = _mm256_set1_ps((float)(int) -1);\n+\n+  return (__m256) __builtin_ia32_gathersiv8sf (src,\n+\t\t\t\t\t       base,\n+\t\t\t\t\t       (__v8si)index,\n+\t\t\t\t\t       mask,\n+\t\t\t\t\t       scale);\n+}\n+\n+extern __inline __m256\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_i32gather_ps (__m256 src, float const *base,\n+\t\t\t  __m256i index, __m256 mask, const int scale)\n+{\n+  return (__m256) __builtin_ia32_gathersiv8sf ((__v8sf)src,\n+\t\t\t\t\t       base,\n+\t\t\t\t\t       (__v8si)index,\n+\t\t\t\t\t       (__v8sf)mask,\n+\t\t\t\t\t       scale);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_i64gather_ps (float const *base, __m128i index, const int scale)\n+{\n+  __v4sf src = _mm_setzero_ps ();\n+  __v4sf mask = _mm_cmpeq_ps (src, src);\n+\n+  return (__m128) __builtin_ia32_gatherdiv4sf (src,\n+\t\t\t\t\t       base,\n+\t\t\t\t\t       (__v2di)index,\n+\t\t\t\t\t       mask,\n+\t\t\t\t\t       scale);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_i64gather_ps (__m128 src, float const *base, __m128i index,\n+\t\t       __m128 mask, const int scale)\n+{\n+  return (__m128) __builtin_ia32_gatherdiv4sf ((__v4sf)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v2di)index,\n+\t\t\t\t\t\t(__v4sf)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_i64gather_ps (float const *base, __m256i index, const int scale)\n+{\n+  __v4sf src = _mm_setzero_ps ();\n+  __v4sf mask = _mm_cmpeq_ps (src, src);\n+\n+  return (__m128) __builtin_ia32_gatherdiv4sf256 (src,\n+\t\t\t\t\t\t  base,\n+\t\t\t\t\t\t  (__v4di)index,\n+\t\t\t\t\t\t  mask,\n+\t\t\t\t\t\t  scale);\n+}\n+\n+extern __inline __m128\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_i64gather_ps (__m128 src, float const *base,\n+\t\t\t  __m256i index, __m128 mask, const int scale)\n+{\n+  return (__m128) __builtin_ia32_gatherdiv4sf256 ((__v4sf)src,\n+\t\t\t\t\t\t  base,\n+\t\t\t\t\t\t  (__v4di)index,\n+\t\t\t\t\t\t  (__v4sf)mask,\n+\t\t\t\t\t\t  scale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_i32gather_epi64 (long long int const *base,\n+\t\t     __m128i index, const int scale)\n+{\n+  __v2di src = __extension__ (__v2di){ 0, 0 };\n+  __v2di mask = __extension__ (__v2di){ ~0, ~0 };\n+\n+  return (__m128i) __builtin_ia32_gathersiv2di (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_i32gather_epi64 (__m128i src, long long int const *base,\n+\t\t\t  __m128i index, __m128i mask, const int scale)\n+{\n+  return (__m128i) __builtin_ia32_gathersiv2di ((__v2di)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\t(__v2di)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_i32gather_epi64 (long long int const *base,\n+\t\t\t__m128i index, const int scale)\n+{\n+  __v4di src = __extension__ (__v4di){ 0, 0, 0, 0 };\n+  __v4di mask = __extension__ (__v4di){ ~0, ~0, ~0, ~0 };\n+\n+  return (__m256i) __builtin_ia32_gathersiv4di (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_i32gather_epi64 (__m256i src, long long int const *base,\n+\t\t\t     __m128i index, __m256i mask, const int scale)\n+{\n+  return (__m256i) __builtin_ia32_gathersiv4di ((__v4di)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\t(__v4di)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_i64gather_epi64 (long long int const *base,\n+\t\t     __m128i index, const int scale)\n+{\n+  __v2di src = __extension__ (__v2di){ 0, 0 };\n+  __v2di mask = __extension__ (__v2di){ ~0, ~0 };\n+\n+  return (__m128i) __builtin_ia32_gatherdiv2di (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v2di)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_i64gather_epi64 (__m128i src, long long int const *base, __m128i index,\n+\t\t\t  __m128i mask, const int scale)\n+{\n+  return (__m128i) __builtin_ia32_gatherdiv2di ((__v2di)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v2di)index,\n+\t\t\t\t\t\t(__v2di)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_i64gather_epi64 (long long int const *base,\n+\t\t\t__m256i index, const int scale)\n+{\n+  __v4di src = __extension__ (__v4di){ 0, 0, 0, 0 };\n+  __v4di mask = __extension__ (__v4di){ ~0, ~0, ~0, ~0 };\n+\n+  return (__m256i) __builtin_ia32_gatherdiv4di (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4di)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_i64gather_epi64 (__m256i src, long long int const *base,\n+\t\t\t     __m256i index, __m256i mask, const int scale)\n+{\n+  return (__m256i) __builtin_ia32_gatherdiv4di ((__v4di)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4di)index,\n+\t\t\t\t\t\t(__v4di)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_i32gather_epi32 (int const *base, __m128i index, const int scale)\n+{\n+  __v4si src = __extension__ (__v4si){ 0, 0, 0, 0 };\n+  __v4si mask = __extension__ (__v4si){ ~0, ~0, ~0, ~0 };\n+\n+  return (__m128i) __builtin_ia32_gathersiv4si (src,\n+\t\t\t\t\t       base,\n+\t\t\t\t\t       (__v4si)index,\n+\t\t\t\t\t       mask,\n+\t\t\t\t\t       scale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_i32gather_epi32 (__m128i src, int const *base, __m128i index,\n+\t\t\t  __m128i mask, const int scale)\n+{\n+  return (__m128i) __builtin_ia32_gathersiv4si ((__v4si)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v4si)index,\n+\t\t\t\t\t\t(__v4si)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_i32gather_epi32 (int const *base, __m256i index, const int scale)\n+{\n+  __v8si src = __extension__ (__v8si){ 0, 0, 0, 0, 0, 0, 0, 0 };\n+  __v8si mask = __extension__ (__v8si){ ~0, ~0, ~0, ~0, ~0, ~0, ~0, ~0 };\n+\n+  return (__m256i) __builtin_ia32_gathersiv8si (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v8si)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_i32gather_epi32 (__m256i src, int const *base,\n+\t\t\t     __m256i index, __m256i mask, const int scale)\n+{\n+  return (__m256i) __builtin_ia32_gathersiv8si ((__v8si)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v8si)index,\n+\t\t\t\t\t\t(__v8si)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_i64gather_epi32 (int const *base, __m128i index, const int scale)\n+{\n+  __v4si src = __extension__ (__v4si){ 0, 0, 0, 0 };\n+  __v4si mask = __extension__ (__v4si){ ~0, ~0, ~0, ~0 };\n+\n+  return (__m128i) __builtin_ia32_gatherdiv4si (src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v2di)index,\n+\t\t\t\t\t\tmask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_i64gather_epi32 (__m128i src, int const *base, __m128i index,\n+\t\t\t  __m128i mask, const int scale)\n+{\n+  return (__m128i) __builtin_ia32_gatherdiv4si ((__v4si)src,\n+\t\t\t\t\t\tbase,\n+\t\t\t\t\t\t(__v2di)index,\n+\t\t\t\t\t\t(__v4si)mask,\n+\t\t\t\t\t\tscale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_i64gather_epi32 (int const *base, __m256i index, const int scale)\n+{\n+  __v4si src = __extension__ (__v4si){ 0, 0, 0, 0 };\n+  __v4si mask = __extension__ (__v4si){ ~0, ~0, ~0, ~0 };\n+\n+  return (__m128i) __builtin_ia32_gatherdiv4si256 (src,\n+\t\t\t\t\t\t  base,\n+\t\t\t\t\t\t  (__v4di)index,\n+\t\t\t\t\t\t  mask,\n+\t\t\t\t\t\t  scale);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_i64gather_epi32 (__m128i src, int const *base,\n+\t\t\t     __m256i index, __m128i mask, const int scale)\n+{\n+  return (__m128i) __builtin_ia32_gatherdiv4si256 ((__v4si)src,\n+\t\t\t\t\t\t   base,\n+\t\t\t\t\t\t   (__v4di)index,\n+\t\t\t\t\t\t   (__v4si)mask,\n+\t\t\t\t\t\t   scale);\n+}\n+#else /* __OPTIMIZE__ */\n+#define _mm_i32gather_pd(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128d) __builtin_ia32_gathersiv2df ((__v2df) _mm_setzero_pd (),\t\\\n+\t\t\t\t\t (double const *)BASE,\t\t\\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (__v2df)_mm_set1_pd(\t\t\\\n+\t\t\t\t\t   (double)(long long int) -1), \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_mask_i32gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \\\n+  (__m128d) __builtin_ia32_gathersiv2df ((__v2df)(__m128d)SRC,\t \\\n+\t\t\t\t\t (double const *)BASE,\t \\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX, \\\n+\t\t\t\t\t (__v2df)(__m128d)MASK,\t \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_i32gather_pd(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m256d) __builtin_ia32_gathersiv4df ((__v4df) _mm256_setzero_pd (),\t\\\n+\t\t\t\t\t (double const *)BASE,\t\t\\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (__v4df)_mm256_set1_pd(\t\\\n+\t\t\t\t\t   (double)(long long int) -1), \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_mask_i32gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \\\n+  (__m256d) __builtin_ia32_gathersiv4df ((__v4df)(__m256d)SRC,\t \\\n+\t\t\t\t\t (double const *)BASE,\t \\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX, \\\n+\t\t\t\t\t (__v4df)(__m256d)MASK,\t \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_i64gather_pd(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128d) __builtin_ia32_gatherdiv2df ((__v2df) _mm_setzero_pd (),\t\\\n+\t\t\t\t\t (double const *)BASE,\t\t\\\n+\t\t\t\t\t (__v2di)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (__v2df)_mm_set1_pd(\t\t\\\n+\t\t\t\t\t   (double)(long long int) -1), \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_mask_i64gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \\\n+  (__m128d) __builtin_ia32_gatherdiv2df ((__v2df)(__m128d)SRC,\t \\\n+\t\t\t\t\t (double const *)BASE,\t \\\n+\t\t\t\t\t (__v2di)(__m128i)INDEX, \\\n+\t\t\t\t\t (__v2df)(__m128d)MASK,\t \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_i64gather_pd(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m256d) __builtin_ia32_gatherdiv4df ((__v4df) _mm256_setzero_pd (),\t\\\n+\t\t\t\t\t (double const *)BASE,\t\t\\\n+\t\t\t\t\t (__v4di)(__m256i)INDEX,\t\\\n+\t\t\t\t\t (__v4df)_mm256_set1_pd(\t\\\n+\t\t\t\t\t   (double)(long long int) -1), \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_mask_i64gather_pd(SRC, BASE, INDEX, MASK, SCALE)\t \\\n+  (__m256d) __builtin_ia32_gatherdiv4df ((__v4df)(__m256d)SRC,\t \\\n+\t\t\t\t\t (double const *)BASE,\t \\\n+\t\t\t\t\t (__v4di)(__m256i)INDEX, \\\n+\t\t\t\t\t (__v4df)(__m256d)MASK,\t \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_i32gather_ps(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128) __builtin_ia32_gathersiv4sf ((__v4sf) _mm_setzero_ps (),\t\\\n+\t\t\t\t\t(float const *)BASE,\t\t\\\n+\t\t\t\t\t(__v4si)(__m128i)INDEX,\t\t\\\n+\t\t\t\t\t_mm_set1_ps ((float)(int) -1),\t\\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm_mask_i32gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t \\\n+  (__m128) __builtin_ia32_gathersiv4sf ((__v4sf)(__m128d)SRC,\t \\\n+\t\t\t\t\t(float const *)BASE,\t \\\n+\t\t\t\t\t(__v4si)(__m128i)INDEX,\t \\\n+\t\t\t\t\t(__v4sf)(__m128d)MASK,\t \\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm256_i32gather_ps(BASE, INDEX, SCALE)\t\t\t       \\\n+  (__m256) __builtin_ia32_gathersiv8sf ((__v8sf) _mm256_setzero_ps (), \\\n+\t\t\t\t\t(float const *)BASE,\t       \\\n+\t\t\t\t\t(__v8si)(__m256i)INDEX,\t       \\\n+\t\t\t\t\t(__v8sf)_mm256_set1_ps (       \\\n+\t\t\t\t\t  (float)(int) -1),\t       \\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm256_mask_i32gather_ps(SRC, BASE, INDEX, MASK, SCALE) \\\n+  (__m256) __builtin_ia32_gathersiv8sf ((__v8sf)(__m256)SRC,\t\\\n+\t\t\t\t\t(float const *)BASE,\t\\\n+\t\t\t\t\t(__v8si)(__m256i)INDEX, \\\n+\t\t\t\t\t(__v8sf)(__m256d)MASK,\t\\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm_i64gather_ps(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128) __builtin_ia32_gatherdiv4sf ((__v4sf) _mm_setzero_pd (),\t\\\n+\t\t\t\t\t(float const *)BASE,\t\t\\\n+\t\t\t\t\t(__v2di)(__m128i)INDEX,\t\t\\\n+\t\t\t\t\t(__v4sf)_mm_set1_ps (\t\t\\\n+\t\t\t\t\t  (float)(int) -1),\t\t\\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm_mask_i64gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t \\\n+  (__m128) __builtin_ia32_gatherdiv4sf ((__v4sf)(__m128)SRC,\t \\\n+\t\t\t\t\t(float const *)BASE,\t \\\n+\t\t\t\t\t(__v2di)(__m128i)INDEX,\t \\\n+\t\t\t\t\t(__v4sf)(__m128d)MASK,\t \\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm256_i64gather_ps(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128) __builtin_ia32_gatherdiv4sf256 ((__v4sf) _mm_setzero_ps (),\t\\\n+\t\t\t\t\t   (float const *)BASE,\t\t\\\n+\t\t\t\t\t   (__v4di)(__m256i)INDEX,\t\\\n+\t\t\t\t\t   (__v4sf)_mm_set1_ps(\t\t\\\n+\t\t\t\t\t     (float)(int) -1),\t\t\\\n+\t\t\t\t\t   (int)SCALE)\n+\n+#define _mm256_mask_i64gather_ps(SRC, BASE, INDEX, MASK, SCALE)\t   \\\n+  (__m128) __builtin_ia32_gatherdiv4sf256 ((__v4sf)(__m128)SRC,\t   \\\n+\t\t\t\t\t   (float const *)BASE,\t   \\\n+\t\t\t\t\t   (__v4di)(__m256i)INDEX, \\\n+\t\t\t\t\t   (__v4sf)(__m128)MASK,   \\\n+\t\t\t\t\t   (int)SCALE)\n+\n+#define _mm_i32gather_epi64(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128i) __builtin_ia32_gathersiv2di ((__v2di) _mm_setzero_si128 (), \\\n+\t\t\t\t\t (long long const *)BASE,\t\\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (__v2di)_mm_set1_epi64x (-1),\t\\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_mask_i32gather_epi64(SRC, BASE, INDEX, MASK, SCALE)\t  \\\n+  (__m128i) __builtin_ia32_gathersiv2di ((__v2di)(__m128i)SRC,\t  \\\n+\t\t\t\t\t (long long const *)BASE, \\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX,  \\\n+\t\t\t\t\t (__v2di)(__m128i)MASK,\t  \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_i32gather_epi64(BASE, INDEX, SCALE)\t\t\t   \\\n+  (__m256i) __builtin_ia32_gathersiv4di ((__v4di) _mm256_setzero_si256 (), \\\n+\t\t\t\t\t (long long const *)BASE,\t   \\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX,\t   \\\n+\t\t\t\t\t (__v4di)_mm256_set1_epi64x (-1),  \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_mask_i32gather_epi64(SRC, BASE, INDEX, MASK, SCALE) \\\n+  (__m256i) __builtin_ia32_gathersiv4di ((__v4di)(__m256i)SRC,\t   \\\n+\t\t\t\t\t (long long const *)BASE,  \\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX,   \\\n+\t\t\t\t\t (__v4di)(__m256i)MASK,\t   \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_i64gather_epi64(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128i) __builtin_ia32_gatherdiv2di ((__v2di) _mm_setzero_si128 (), \\\n+\t\t\t\t\t (long long const *)BASE,\t\\\n+\t\t\t\t\t (__v2di)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (__v2di)_mm_set1_epi64x (-1),\t\\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_mask_i64gather_epi64(SRC, BASE, INDEX, MASK, SCALE)\t  \\\n+  (__m128i) __builtin_ia32_gatherdiv2di ((__v2di)(__m128i)SRC,\t  \\\n+\t\t\t\t\t (long long const *)BASE, \\\n+\t\t\t\t\t (__v2di)(__m128i)INDEX,  \\\n+\t\t\t\t\t (__v2di)(__m128i)MASK,\t  \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_i64gather_epi64(BASE, INDEX, SCALE)\t\t\t   \\\n+  (__m256i) __builtin_ia32_gatherdiv4di ((__v4di) _mm256_setzero_si256 (), \\\n+\t\t\t\t\t (long long const *)BASE,\t   \\\n+\t\t\t\t\t (__v4di)(__m256i)INDEX,\t   \\\n+\t\t\t\t\t (__v4di)_mm256_set1_epi64x (-1),  \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_mask_i64gather_epi64(SRC, BASE, INDEX, MASK, SCALE) \\\n+  (__m256i) __builtin_ia32_gatherdiv4di ((__v4di)(__m256i)SRC,\t   \\\n+\t\t\t\t\t (long long const *)BASE,  \\\n+\t\t\t\t\t (__v4di)(__m256i)INDEX,   \\\n+\t\t\t\t\t (__v4di)(__m256i)MASK,\t   \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_i32gather_epi32(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128i) __builtin_ia32_gathersiv4si ((__v4si) _mm_setzero_si128 (),\t\\\n+\t\t\t\t\t (int const *)BASE,\t\t\\\n+\t\t\t\t\t (__v4si)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (__v4si)_mm_set1_epi32 (-1),\t\\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_mask_i32gather_epi32(SRC, BASE, INDEX, MASK, SCALE) \\\n+  (__m128i) __builtin_ia32_gathersiv4si ((__v4si)(__m128i)SRC,\t\\\n+\t\t\t\t\t(int const *)BASE,\t\\\n+\t\t\t\t\t(__v4si)(__m128i)INDEX, \\\n+\t\t\t\t\t(__v4si)(__m128i)MASK,\t\\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm256_i32gather_epi32(BASE, INDEX, SCALE)\t\t\t   \\\n+  (__m256i) __builtin_ia32_gathersiv8si ((__v8si) _mm256_setzero_si256 (), \\\n+\t\t\t\t\t (int const *)BASE,\t\t   \\\n+\t\t\t\t\t (__v8si)(__m256i)INDEX,\t   \\\n+\t\t\t\t\t (__v8si)_mm256_set1_epi32 (-1),   \\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm256_mask_i32gather_epi32(SRC, BASE, INDEX, MASK, SCALE) \\\n+  (__m256i) __builtin_ia32_gathersiv8si ((__v8si)(__m256i)SRC,\t   \\\n+\t\t\t\t\t(int const *)BASE,\t   \\\n+\t\t\t\t\t(__v8si)(__m256i)INDEX,\t   \\\n+\t\t\t\t\t(__v8si)(__m256i)MASK,\t   \\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm_i64gather_epi32(BASE, INDEX, SCALE)\t\t\t\t\\\n+  (__m128i) __builtin_ia32_gatherdiv4si ((__v4si) _mm_setzero_si128 (),\t\\\n+\t\t\t\t\t (int const *)BASE,\t\t\\\n+\t\t\t\t\t (__v2di)(__m128i)INDEX,\t\\\n+\t\t\t\t\t (__v4si)_mm_set1_epi32 (-1),\t\\\n+\t\t\t\t\t (int)SCALE)\n+\n+#define _mm_mask_i64gather_epi32(SRC, BASE, INDEX, MASK, SCALE) \\\n+  (__m128i) __builtin_ia32_gatherdiv4si ((__v4si)(__m128i)SRC,\t\\\n+\t\t\t\t\t(int const *)BASE,\t\\\n+\t\t\t\t\t(__v2di)(__m128i)INDEX, \\\n+\t\t\t\t\t(__v4si)(__m128i)MASK,\t\\\n+\t\t\t\t\t(int)SCALE)\n+\n+#define _mm256_i64gather_epi32(BASE, INDEX, SCALE)\t\t\t   \\\n+  (__m128i) __builtin_ia32_gatherdiv4si256 ((__v4si) _mm_setzero_si128 (), \\\n+\t\t\t\t\t    (int const *)BASE,\t\t   \\\n+\t\t\t\t\t    (__v4di)(__m256i)INDEX,\t   \\\n+\t\t\t\t\t    (__v4si)_mm_set1_epi32(-1),\t   \\\n+\t\t\t\t\t    (int)SCALE)\n+\n+#define _mm256_mask_i64gather_epi32(SRC, BASE, INDEX, MASK, SCALE) \\\n+  (__m128i) __builtin_ia32_gatherdiv4si256 ((__v4si)(__m128i)SRC,  \\\n+\t\t\t\t\t   (int const *)BASE,\t   \\\n+\t\t\t\t\t   (__v4di)(__m256i)INDEX, \\\n+\t\t\t\t\t   (__v4si)(__m128i)MASK,  \\\n+\t\t\t\t\t   (int)SCALE)\n+#endif  /* __OPTIMIZE__ */"}, {"sha": "c4070e49fe55ebfcdc9cbf9d6f9c495a5f62a6b8", "filename": "gcc/config/i386/i386-builtin-types.def", "status": "modified", "additions": 78, "deletions": 0, "changes": 78, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -102,6 +102,8 @@ DEF_VECTOR_TYPE (V32QI, QI)\n DEF_POINTER_TYPE (PCCHAR, CHAR, CONST)\n DEF_POINTER_TYPE (PCDOUBLE, DOUBLE, CONST)\n DEF_POINTER_TYPE (PCFLOAT, FLOAT, CONST)\n+DEF_POINTER_TYPE (PCINT, INT, CONST)\n+DEF_POINTER_TYPE (PCINT64, INT64, CONST)\n DEF_POINTER_TYPE (PCHAR, CHAR)\n DEF_POINTER_TYPE (PCVOID, VOID, CONST)\n DEF_POINTER_TYPE (PVOID, VOID)\n@@ -119,13 +121,20 @@ DEF_POINTER_TYPE (PV4DF, V4DF)\n DEF_POINTER_TYPE (PV4DI, V4DI)\n DEF_POINTER_TYPE (PV4SF, V4SF)\n DEF_POINTER_TYPE (PV8SF, V8SF)\n+DEF_POINTER_TYPE (PV4SI, V4SI)\n+DEF_POINTER_TYPE (PV8SI, V8SI)\n \n DEF_POINTER_TYPE (PCV2DF, V2DF, CONST)\n DEF_POINTER_TYPE (PCV2SF, V2SF, CONST)\n DEF_POINTER_TYPE (PCV4DF, V4DF, CONST)\n DEF_POINTER_TYPE (PCV4SF, V4SF, CONST)\n DEF_POINTER_TYPE (PCV8SF, V8SF, CONST)\n \n+DEF_POINTER_TYPE (PCV2DI, V2DI, CONST)\n+DEF_POINTER_TYPE (PCV4SI, V4SI, CONST)\n+DEF_POINTER_TYPE (PCV4DI, V4DI, CONST)\n+DEF_POINTER_TYPE (PCV8SI, V8SI, CONST)\n+\n DEF_FUNCTION_TYPE (FLOAT128)\n DEF_FUNCTION_TYPE (UINT64)\n DEF_FUNCTION_TYPE (UNSIGNED)\n@@ -141,6 +150,7 @@ DEF_FUNCTION_TYPE (INT, V4DF)\n DEF_FUNCTION_TYPE (INT, V4SF)\n DEF_FUNCTION_TYPE (INT, V8QI)\n DEF_FUNCTION_TYPE (INT, V8SF)\n+DEF_FUNCTION_TYPE (INT, V32QI)\n DEF_FUNCTION_TYPE (INT64, INT64)\n DEF_FUNCTION_TYPE (INT64, V2DF)\n DEF_FUNCTION_TYPE (INT64, V4SF)\n@@ -199,13 +209,26 @@ DEF_FUNCTION_TYPE (V8SF, V8SI)\n DEF_FUNCTION_TYPE (V8SF, V8HI)\n DEF_FUNCTION_TYPE (V8SI, V4SI)\n DEF_FUNCTION_TYPE (V8SI, V8SF)\n+DEF_FUNCTION_TYPE (V32QI, V32QI)\n+DEF_FUNCTION_TYPE (V32QI, V16QI)\n+DEF_FUNCTION_TYPE (V16HI, V16HI)\n+DEF_FUNCTION_TYPE (V16HI, V8HI)\n+DEF_FUNCTION_TYPE (V8SI, V8SI)\n DEF_FUNCTION_TYPE (VOID, PCVOID)\n DEF_FUNCTION_TYPE (VOID, PVOID)\n DEF_FUNCTION_TYPE (VOID, UINT64)\n DEF_FUNCTION_TYPE (VOID, UNSIGNED)\n DEF_FUNCTION_TYPE (INT, PUSHORT)\n DEF_FUNCTION_TYPE (INT, PUNSIGNED)\n DEF_FUNCTION_TYPE (INT, PULONGLONG)\n+DEF_FUNCTION_TYPE (V16HI, V16QI)\n+DEF_FUNCTION_TYPE (V8SI, V16QI)\n+DEF_FUNCTION_TYPE (V4DI, V16QI)\n+DEF_FUNCTION_TYPE (V8SI, V8HI)\n+DEF_FUNCTION_TYPE (V4DI, V8HI)\n+DEF_FUNCTION_TYPE (V4DI, V4SI)\n+DEF_FUNCTION_TYPE (V4DI, PV4DI)\n+DEF_FUNCTION_TYPE (V4DI, V2DI)\n \n DEF_FUNCTION_TYPE (DI, V2DI, INT)\n DEF_FUNCTION_TYPE (DOUBLE, V2DF, INT)\n@@ -252,6 +275,7 @@ DEF_FUNCTION_TYPE (V2DI, V2DI, SI)\n DEF_FUNCTION_TYPE (V2DI, V2DI, V16QI)\n DEF_FUNCTION_TYPE (V2DI, V2DI, V2DI)\n DEF_FUNCTION_TYPE (V2DI, V4SI, V4SI)\n+DEF_FUNCTION_TYPE (V2DI, PCV2DI, V2DI)\n DEF_FUNCTION_TYPE (V2SF, V2SF, V2SF)\n DEF_FUNCTION_TYPE (V2SI, INT, INT)\n DEF_FUNCTION_TYPE (V2SI, V2SF, V2SF)\n@@ -284,6 +308,7 @@ DEF_FUNCTION_TYPE (V4SI, V4SI, SI)\n DEF_FUNCTION_TYPE (V4SI, V4SI, V4SI)\n DEF_FUNCTION_TYPE (V4SI, V8HI, V8HI)\n DEF_FUNCTION_TYPE (V4SI, V8SI, INT)\n+DEF_FUNCTION_TYPE (V4SI, PCV4SI, V4SI)\n DEF_FUNCTION_TYPE (V8HI, V16QI, V16QI)\n DEF_FUNCTION_TYPE (V8HI, V4SI, V4SI)\n DEF_FUNCTION_TYPE (V8HI, V8HI, INT)\n@@ -297,6 +322,28 @@ DEF_FUNCTION_TYPE (V8SF, PCV8SF, V8SI)\n DEF_FUNCTION_TYPE (V8SF, V8SF, INT)\n DEF_FUNCTION_TYPE (V8SF, V8SF, V8SF)\n DEF_FUNCTION_TYPE (V8SF, V8SF, V8SI)\n+DEF_FUNCTION_TYPE (V32QI, V16HI, V16HI)\n+DEF_FUNCTION_TYPE (V16HI, V8SI, V8SI)\n+DEF_FUNCTION_TYPE (V32QI, V32QI, V32QI)\n+DEF_FUNCTION_TYPE (V16HI, V32QI, V32QI)\n+DEF_FUNCTION_TYPE (V16HI, V16HI, V8HI)\n+DEF_FUNCTION_TYPE (V16HI, V16HI, V16HI)\n+DEF_FUNCTION_TYPE (V16HI, V16HI, INT)\n+DEF_FUNCTION_TYPE (V16HI, V16HI, SI)\n+DEF_FUNCTION_TYPE (V16HI, V16HI, V16HI, INT)\n+DEF_FUNCTION_TYPE (V32QI, V32QI, V32QI, INT)\n+DEF_FUNCTION_TYPE (V8SI, V8SI, V4SI)\n+DEF_FUNCTION_TYPE (V8SI, V8SI, V8SI)\n+DEF_FUNCTION_TYPE (V8SI, V16HI, V16HI)\n+DEF_FUNCTION_TYPE (V8SI, V8SI, INT)\n+DEF_FUNCTION_TYPE (V8SI, V8SI, SI)\n+DEF_FUNCTION_TYPE (V8SI, PCV8SI, V8SI)\n+DEF_FUNCTION_TYPE (V4DI, V4DI, V4DI)\n+DEF_FUNCTION_TYPE (V4DI, V8SI, V8SI)\n+DEF_FUNCTION_TYPE (V4DI, V4DI, V2DI)\n+DEF_FUNCTION_TYPE (V4DI, PCV4DI, V4DI)\n+DEF_FUNCTION_TYPE (V4DI, V4DI, INT)\n+DEF_FUNCTION_TYPE (V2DI, V4DI, INT)\n DEF_FUNCTION_TYPE (VOID, PCHAR, V16QI)\n DEF_FUNCTION_TYPE (VOID, PCHAR, V32QI)\n DEF_FUNCTION_TYPE (VOID, PDOUBLE, V2DF)\n@@ -351,11 +398,17 @@ DEF_FUNCTION_TYPE (V8SF, V8SF, V8SF, V8SI, INT)\n DEF_FUNCTION_TYPE (V8SI, V8SI, V4SI, INT)\n DEF_FUNCTION_TYPE (V8SI, V8SI, V8SI, INT)\n DEF_FUNCTION_TYPE (V8SI, V8SI, V8SI, V8SI)\n+DEF_FUNCTION_TYPE (V4DI, V4DI, V4DI, INT)\n+DEF_FUNCTION_TYPE (V4DI, V4DI, V2DI, INT)\n DEF_FUNCTION_TYPE (VOID, PCVOID, UNSIGNED, UNSIGNED)\n DEF_FUNCTION_TYPE (VOID, PV2DF, V2DI, V2DF)\n DEF_FUNCTION_TYPE (VOID, PV4DF, V4DI, V4DF)\n DEF_FUNCTION_TYPE (VOID, PV4SF, V4SI, V4SF)\n DEF_FUNCTION_TYPE (VOID, PV8SF, V8SI, V8SF)\n+DEF_FUNCTION_TYPE (VOID, PV2DI, V2DI, V2DI)\n+DEF_FUNCTION_TYPE (VOID, PV4DI, V4DI, V4DI)\n+DEF_FUNCTION_TYPE (VOID, PV4SI, V4SI, V4SI)\n+DEF_FUNCTION_TYPE (VOID, PV8SI, V8SI, V8SI)\n DEF_FUNCTION_TYPE (VOID, UINT, UINT, UINT)\n DEF_FUNCTION_TYPE (VOID, UINT64, UINT, UINT)\n DEF_FUNCTION_TYPE (VOID, V16QI, V16QI, PCHAR)\n@@ -377,6 +430,23 @@ DEF_FUNCTION_TYPE (V16QI, V16QI, INT, V16QI, INT, INT)\n \n DEF_FUNCTION_TYPE (V8QI, QI, QI, QI, QI, QI, QI, QI, QI)\n \n+DEF_FUNCTION_TYPE (V2DF, V2DF, PCDOUBLE, V4SI, V2DF, INT)\n+DEF_FUNCTION_TYPE (V4DF, V4DF, PCDOUBLE, V4SI, V4DF, INT)\n+DEF_FUNCTION_TYPE (V2DF, V2DF, PCDOUBLE, V2DI, V2DF, INT)\n+DEF_FUNCTION_TYPE (V4DF, V4DF, PCDOUBLE, V4DI, V4DF, INT)\n+DEF_FUNCTION_TYPE (V4SF, V4SF, PCFLOAT, V4SI, V4SF, INT)\n+DEF_FUNCTION_TYPE (V8SF, V8SF, PCFLOAT, V8SI, V8SF, INT)\n+DEF_FUNCTION_TYPE (V4SF, V4SF, PCFLOAT, V2DI, V4SF, INT)\n+DEF_FUNCTION_TYPE (V4SF, V4SF, PCFLOAT, V4DI, V4SF, INT)\n+DEF_FUNCTION_TYPE (V2DI, V2DI, PCINT64, V4SI, V2DI, INT)\n+DEF_FUNCTION_TYPE (V4DI, V4DI, PCINT64, V4SI, V4DI, INT)\n+DEF_FUNCTION_TYPE (V2DI, V2DI, PCINT64, V2DI, V2DI, INT)\n+DEF_FUNCTION_TYPE (V4DI, V4DI, PCINT64, V4DI, V4DI, INT)\n+DEF_FUNCTION_TYPE (V4SI, V4SI, PCINT, V4SI, V4SI, INT)\n+DEF_FUNCTION_TYPE (V8SI, V8SI, PCINT, V8SI, V8SI, INT)\n+DEF_FUNCTION_TYPE (V4SI, V4SI, PCINT, V2DI, V4SI, INT)\n+DEF_FUNCTION_TYPE (V4SI, V4SI, PCINT, V4DI, V4SI, INT)\n+\n DEF_FUNCTION_TYPE_ALIAS (V2DF_FTYPE_V2DF, ROUND)\n DEF_FUNCTION_TYPE_ALIAS (V4DF_FTYPE_V4DF, ROUND)\n DEF_FUNCTION_TYPE_ALIAS (V4SF_FTYPE_V4SF, ROUND)\n@@ -404,11 +474,19 @@ DEF_FUNCTION_TYPE_ALIAS (V2SI_FTYPE_V2SI_V2SI, COUNT)\n DEF_FUNCTION_TYPE_ALIAS (V4HI_FTYPE_V4HI_V4HI, COUNT)\n DEF_FUNCTION_TYPE_ALIAS (V4SI_FTYPE_V4SI_V4SI, COUNT)\n DEF_FUNCTION_TYPE_ALIAS (V8HI_FTYPE_V8HI_V8HI, COUNT)\n+DEF_FUNCTION_TYPE_ALIAS (V16HI_FTYPE_V16HI_SI, COUNT)\n+DEF_FUNCTION_TYPE_ALIAS (V16HI_FTYPE_V16HI_V8HI, COUNT)\n+DEF_FUNCTION_TYPE_ALIAS (V8SI_FTYPE_V8SI_SI, COUNT)\n+DEF_FUNCTION_TYPE_ALIAS (V8SI_FTYPE_V8SI_V4SI, COUNT)\n+DEF_FUNCTION_TYPE_ALIAS (V4DI_FTYPE_V4DI_INT, COUNT)\n+DEF_FUNCTION_TYPE_ALIAS (V4DI_FTYPE_V4DI_V2DI, COUNT)\n \n DEF_FUNCTION_TYPE_ALIAS (V2DF_FTYPE_V2DF_V2DF, SWAP)\n DEF_FUNCTION_TYPE_ALIAS (V4SF_FTYPE_V4SF_V4SF, SWAP)\n \n+DEF_FUNCTION_TYPE_ALIAS (V4DI_FTYPE_V4DI_INT, CONVERT)\n DEF_FUNCTION_TYPE_ALIAS (V2DI_FTYPE_V2DI_INT, CONVERT)\n+DEF_FUNCTION_TYPE_ALIAS (V4DI_FTYPE_V4DI_V4DI_INT, CONVERT)\n DEF_FUNCTION_TYPE_ALIAS (V2DI_FTYPE_V2DI_V2DI_INT, CONVERT)\n DEF_FUNCTION_TYPE_ALIAS (V1DI_FTYPE_V1DI_V1DI_INT, CONVERT)\n "}, {"sha": "ef02673bf8659593f88559c630b5ced4bcd59547", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 555, "deletions": 7, "changes": 562, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -23867,6 +23867,180 @@ enum ix86_builtins\n   IX86_BUILTIN_MOVMSKPD256,\n   IX86_BUILTIN_MOVMSKPS256,\n \n+  /* AVX2 */\n+  IX86_BUILTIN_MPSADBW256,\n+  IX86_BUILTIN_PABSB256,\n+  IX86_BUILTIN_PABSW256,\n+  IX86_BUILTIN_PABSD256,\n+  IX86_BUILTIN_PACKSSDW256,\n+  IX86_BUILTIN_PACKSSWB256,\n+  IX86_BUILTIN_PACKUSDW256,\n+  IX86_BUILTIN_PACKUSWB256,\n+  IX86_BUILTIN_PADDB256,\n+  IX86_BUILTIN_PADDW256,\n+  IX86_BUILTIN_PADDD256,\n+  IX86_BUILTIN_PADDQ256,\n+  IX86_BUILTIN_PADDSB256,\n+  IX86_BUILTIN_PADDSW256,\n+  IX86_BUILTIN_PADDUSB256,\n+  IX86_BUILTIN_PADDUSW256,\n+  IX86_BUILTIN_PALIGNR256,\n+  IX86_BUILTIN_AND256I,\n+  IX86_BUILTIN_ANDNOT256I,\n+  IX86_BUILTIN_PAVGB256,\n+  IX86_BUILTIN_PAVGW256,\n+  IX86_BUILTIN_PBLENDVB256,\n+  IX86_BUILTIN_PBLENDVW256,\n+  IX86_BUILTIN_PCMPEQB256,\n+  IX86_BUILTIN_PCMPEQW256,\n+  IX86_BUILTIN_PCMPEQD256,\n+  IX86_BUILTIN_PCMPEQQ256,\n+  IX86_BUILTIN_PCMPGTB256,\n+  IX86_BUILTIN_PCMPGTW256,\n+  IX86_BUILTIN_PCMPGTD256,\n+  IX86_BUILTIN_PCMPGTQ256,\n+  IX86_BUILTIN_PHADDW256,\n+  IX86_BUILTIN_PHADDD256,\n+  IX86_BUILTIN_PHADDSW256,\n+  IX86_BUILTIN_PHSUBW256,\n+  IX86_BUILTIN_PHSUBD256,\n+  IX86_BUILTIN_PHSUBSW256,\n+  IX86_BUILTIN_PMADDUBSW256,\n+  IX86_BUILTIN_PMADDWD256,\n+  IX86_BUILTIN_PMAXSB256,\n+  IX86_BUILTIN_PMAXSW256,\n+  IX86_BUILTIN_PMAXSD256,\n+  IX86_BUILTIN_PMAXUB256,\n+  IX86_BUILTIN_PMAXUW256,\n+  IX86_BUILTIN_PMAXUD256,\n+  IX86_BUILTIN_PMINSB256,\n+  IX86_BUILTIN_PMINSW256,\n+  IX86_BUILTIN_PMINSD256,\n+  IX86_BUILTIN_PMINUB256,\n+  IX86_BUILTIN_PMINUW256,\n+  IX86_BUILTIN_PMINUD256,\n+  IX86_BUILTIN_PMOVMSKB256,\n+  IX86_BUILTIN_PMOVSXBW256,\n+  IX86_BUILTIN_PMOVSXBD256,\n+  IX86_BUILTIN_PMOVSXBQ256,\n+  IX86_BUILTIN_PMOVSXWD256,\n+  IX86_BUILTIN_PMOVSXWQ256,\n+  IX86_BUILTIN_PMOVSXDQ256,\n+  IX86_BUILTIN_PMOVZXBW256,\n+  IX86_BUILTIN_PMOVZXBD256,\n+  IX86_BUILTIN_PMOVZXBQ256,\n+  IX86_BUILTIN_PMOVZXWD256,\n+  IX86_BUILTIN_PMOVZXWQ256,\n+  IX86_BUILTIN_PMOVZXDQ256,\n+  IX86_BUILTIN_PMULDQ256,\n+  IX86_BUILTIN_PMULHRSW256,\n+  IX86_BUILTIN_PMULHUW256,\n+  IX86_BUILTIN_PMULHW256,\n+  IX86_BUILTIN_PMULLW256,\n+  IX86_BUILTIN_PMULLD256,\n+  IX86_BUILTIN_PMULUDQ256,\n+  IX86_BUILTIN_POR256,\n+  IX86_BUILTIN_PSADBW256,\n+  IX86_BUILTIN_PSHUFB256,\n+  IX86_BUILTIN_PSHUFD256,\n+  IX86_BUILTIN_PSHUFHW256,\n+  IX86_BUILTIN_PSHUFLW256,\n+  IX86_BUILTIN_PSIGNB256,\n+  IX86_BUILTIN_PSIGNW256,\n+  IX86_BUILTIN_PSIGND256,\n+  IX86_BUILTIN_PSLLDQI256,\n+  IX86_BUILTIN_PSLLWI256,\n+  IX86_BUILTIN_PSLLW256,\n+  IX86_BUILTIN_PSLLDI256,\n+  IX86_BUILTIN_PSLLD256,\n+  IX86_BUILTIN_PSLLQI256,\n+  IX86_BUILTIN_PSLLQ256,\n+  IX86_BUILTIN_PSRAWI256,\n+  IX86_BUILTIN_PSRAW256,\n+  IX86_BUILTIN_PSRADI256,\n+  IX86_BUILTIN_PSRAD256,\n+  IX86_BUILTIN_PSRLDQI256,\n+  IX86_BUILTIN_PSRLWI256,\n+  IX86_BUILTIN_PSRLW256,\n+  IX86_BUILTIN_PSRLDI256,\n+  IX86_BUILTIN_PSRLD256,\n+  IX86_BUILTIN_PSRLQI256,\n+  IX86_BUILTIN_PSRLQ256,\n+  IX86_BUILTIN_PSUBB256,\n+  IX86_BUILTIN_PSUBW256,\n+  IX86_BUILTIN_PSUBD256,\n+  IX86_BUILTIN_PSUBQ256,\n+  IX86_BUILTIN_PSUBSB256,\n+  IX86_BUILTIN_PSUBSW256,\n+  IX86_BUILTIN_PSUBUSB256,\n+  IX86_BUILTIN_PSUBUSW256,\n+  IX86_BUILTIN_PUNPCKHBW256,\n+  IX86_BUILTIN_PUNPCKHWD256,\n+  IX86_BUILTIN_PUNPCKHDQ256,\n+  IX86_BUILTIN_PUNPCKHQDQ256,\n+  IX86_BUILTIN_PUNPCKLBW256,\n+  IX86_BUILTIN_PUNPCKLWD256,\n+  IX86_BUILTIN_PUNPCKLDQ256,\n+  IX86_BUILTIN_PUNPCKLQDQ256,\n+  IX86_BUILTIN_PXOR256,\n+  IX86_BUILTIN_MOVNTDQA256,\n+  IX86_BUILTIN_VBROADCASTSS_PS,\n+  IX86_BUILTIN_VBROADCASTSS_PS256,\n+  IX86_BUILTIN_VBROADCASTSD_PD256,\n+  IX86_BUILTIN_VBROADCASTSI256,\n+  IX86_BUILTIN_PBLENDD256,\n+  IX86_BUILTIN_PBLENDD128,\n+  IX86_BUILTIN_PBROADCASTB256,\n+  IX86_BUILTIN_PBROADCASTW256,\n+  IX86_BUILTIN_PBROADCASTD256,\n+  IX86_BUILTIN_PBROADCASTQ256,\n+  IX86_BUILTIN_PBROADCASTB128,\n+  IX86_BUILTIN_PBROADCASTW128,\n+  IX86_BUILTIN_PBROADCASTD128,\n+  IX86_BUILTIN_PBROADCASTQ128,\n+  IX86_BUILTIN_VPERMVARSI256,\n+  IX86_BUILTIN_VPERMDF256,\n+  IX86_BUILTIN_VPERMVARSF256,\n+  IX86_BUILTIN_VPERMDI256,\n+  IX86_BUILTIN_VPERMTI256,\n+  IX86_BUILTIN_VEXTRACT128I256,\n+  IX86_BUILTIN_VINSERT128I256,\n+  IX86_BUILTIN_MASKLOADD,\n+  IX86_BUILTIN_MASKLOADQ,\n+  IX86_BUILTIN_MASKLOADD256,\n+  IX86_BUILTIN_MASKLOADQ256,\n+  IX86_BUILTIN_MASKSTORED,\n+  IX86_BUILTIN_MASKSTOREQ,\n+  IX86_BUILTIN_MASKSTORED256,\n+  IX86_BUILTIN_MASKSTOREQ256,\n+  IX86_BUILTIN_PSLLVV4DI,\n+  IX86_BUILTIN_PSLLVV2DI,\n+  IX86_BUILTIN_PSLLVV8SI,\n+  IX86_BUILTIN_PSLLVV4SI,\n+  IX86_BUILTIN_PSRAVV8SI,\n+  IX86_BUILTIN_PSRAVV4SI,\n+  IX86_BUILTIN_PSRLVV4DI,\n+  IX86_BUILTIN_PSRLVV2DI,\n+  IX86_BUILTIN_PSRLVV8SI,\n+  IX86_BUILTIN_PSRLVV4SI,\n+\n+  IX86_BUILTIN_GATHERSIV2DF,\n+  IX86_BUILTIN_GATHERSIV4DF,\n+  IX86_BUILTIN_GATHERDIV2DF,\n+  IX86_BUILTIN_GATHERDIV4DF,\n+  IX86_BUILTIN_GATHERSIV4SF,\n+  IX86_BUILTIN_GATHERSIV8SF,\n+  IX86_BUILTIN_GATHERDIV4SF,\n+  IX86_BUILTIN_GATHERDIV8SF,\n+  IX86_BUILTIN_GATHERSIV2DI,\n+  IX86_BUILTIN_GATHERSIV4DI,\n+  IX86_BUILTIN_GATHERDIV2DI,\n+  IX86_BUILTIN_GATHERDIV4DI,\n+  IX86_BUILTIN_GATHERSIV4SI,\n+  IX86_BUILTIN_GATHERSIV8SI,\n+  IX86_BUILTIN_GATHERDIV4SI,\n+  IX86_BUILTIN_GATHERDIV8SI,\n+\n   /* TFmode support builtins.  */\n   IX86_BUILTIN_INFQ,\n   IX86_BUILTIN_HUGE_VALQ,\n@@ -24362,6 +24536,17 @@ static const struct builtin_description bdesc_special_args[] =\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_maskstorepd256, \"__builtin_ia32_maskstorepd256\", IX86_BUILTIN_MASKSTOREPD256, UNKNOWN, (int) VOID_FTYPE_PV4DF_V4DI_V4DF },\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_maskstoreps256, \"__builtin_ia32_maskstoreps256\", IX86_BUILTIN_MASKSTOREPS256, UNKNOWN, (int) VOID_FTYPE_PV8SF_V8SI_V8SF },\n \n+  /* AVX2 */\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_movntdqa, \"__builtin_ia32_movntdqa256\", IX86_BUILTIN_MOVNTDQA256, UNKNOWN, (int) V4DI_FTYPE_PV4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_maskloadd, \"__builtin_ia32_maskloadd\", IX86_BUILTIN_MASKLOADD, UNKNOWN, (int) V4SI_FTYPE_PCV4SI_V4SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_maskloadq, \"__builtin_ia32_maskloadq\", IX86_BUILTIN_MASKLOADQ, UNKNOWN, (int) V2DI_FTYPE_PCV2DI_V2DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_maskloadd256, \"__builtin_ia32_maskloadd256\", IX86_BUILTIN_MASKLOADD256, UNKNOWN, (int) V8SI_FTYPE_PCV8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_maskloadq256, \"__builtin_ia32_maskloadq256\", IX86_BUILTIN_MASKLOADQ256, UNKNOWN, (int) V4DI_FTYPE_PCV4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_maskstored, \"__builtin_ia32_maskstored\", IX86_BUILTIN_MASKSTORED, UNKNOWN, (int) VOID_FTYPE_PV4SI_V4SI_V4SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_maskstoreq, \"__builtin_ia32_maskstoreq\", IX86_BUILTIN_MASKSTOREQ, UNKNOWN, (int) VOID_FTYPE_PV2DI_V2DI_V2DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_maskstored256, \"__builtin_ia32_maskstored256\", IX86_BUILTIN_MASKSTORED256, UNKNOWN, (int) VOID_FTYPE_PV8SI_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_maskstoreq256, \"__builtin_ia32_maskstoreq256\", IX86_BUILTIN_MASKSTOREQ256, UNKNOWN, (int) VOID_FTYPE_PV4DI_V4DI_V4DI },\n+\n   { OPTION_MASK_ISA_LWP, CODE_FOR_lwp_llwpcb, \"__builtin_ia32_llwpcb\", IX86_BUILTIN_LLWPCB, UNKNOWN, (int) VOID_FTYPE_PVOID },\n   { OPTION_MASK_ISA_LWP, CODE_FOR_lwp_slwpcb, \"__builtin_ia32_slwpcb\", IX86_BUILTIN_SLWPCB, UNKNOWN, (int) PVOID_FTYPE_VOID },\n   { OPTION_MASK_ISA_LWP, CODE_FOR_lwp_lwpvalsi3, \"__builtin_ia32_lwpval32\", IX86_BUILTIN_LWPVAL32, UNKNOWN, (int) VOID_FTYPE_UINT_UINT_UINT },\n@@ -25026,6 +25211,154 @@ static const struct builtin_description bdesc_args[] =\n   { OPTION_MASK_ISA_AVX, CODE_FOR_copysignv8sf3,  \"__builtin_ia32_copysignps256\", IX86_BUILTIN_CPYSGNPS256, UNKNOWN, (int) V8SF_FTYPE_V8SF_V8SF },\n   { OPTION_MASK_ISA_AVX, CODE_FOR_copysignv4df3,  \"__builtin_ia32_copysignpd256\", IX86_BUILTIN_CPYSGNPD256, UNKNOWN, (int) V4DF_FTYPE_V4DF_V4DF },\n \n+  /* AVX2 */\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_mpsadbw, \"__builtin_ia32_mpsadbw256\", IX86_BUILTIN_MPSADBW256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_absv32qi2, \"__builtin_ia32_pabsb256\", IX86_BUILTIN_PABSB256, UNKNOWN, (int) V32QI_FTYPE_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_absv16hi2, \"__builtin_ia32_pabsw256\", IX86_BUILTIN_PABSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_absv8si2, \"__builtin_ia32_pabsd256\", IX86_BUILTIN_PABSD256, UNKNOWN, (int) V8SI_FTYPE_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_packssdw, \"__builtin_ia32_packssdw256\",  IX86_BUILTIN_PACKSSDW256, UNKNOWN, (int) V16HI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_packsswb, \"__builtin_ia32_packsswb256\",  IX86_BUILTIN_PACKSSWB256, UNKNOWN, (int) V32QI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_packusdw, \"__builtin_ia32_packusdw256\",  IX86_BUILTIN_PACKUSDW256, UNKNOWN, (int) V16HI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_packuswb, \"__builtin_ia32_packuswb256\",  IX86_BUILTIN_PACKUSWB256, UNKNOWN, (int) V32QI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_addv32qi3, \"__builtin_ia32_paddb256\", IX86_BUILTIN_PADDB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_addv16hi3, \"__builtin_ia32_paddw256\", IX86_BUILTIN_PADDW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_addv8si3, \"__builtin_ia32_paddd256\", IX86_BUILTIN_PADDD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_addv4di3, \"__builtin_ia32_paddq256\", IX86_BUILTIN_PADDQ256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_ssaddv32qi3, \"__builtin_ia32_paddsb256\", IX86_BUILTIN_PADDSB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_ssaddv16hi3, \"__builtin_ia32_paddsw256\", IX86_BUILTIN_PADDSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_usaddv32qi3, \"__builtin_ia32_paddusb256\", IX86_BUILTIN_PADDUSB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_usaddv16hi3, \"__builtin_ia32_paddusw256\", IX86_BUILTIN_PADDUSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_palignrv4di, \"__builtin_ia32_palignr256\", IX86_BUILTIN_PALIGNR256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI_INT_CONVERT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_andv4di3, \"__builtin_ia32_andsi256\", IX86_BUILTIN_AND256I, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_andnotv4di3, \"__builtin_ia32_andnotsi256\", IX86_BUILTIN_ANDNOT256I, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_uavgv32qi3, \"__builtin_ia32_pavgb256\",  IX86_BUILTIN_PAVGB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_uavgv16hi3, \"__builtin_ia32_pavgw256\",  IX86_BUILTIN_PAVGW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pblendvb, \"__builtin_ia32_pblendvb256\", IX86_BUILTIN_PBLENDVB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pblendw, \"__builtin_ia32_pblendw256\", IX86_BUILTIN_PBLENDVW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_eqv32qi3, \"__builtin_ia32_pcmpeqb256\", IX86_BUILTIN_PCMPEQB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_eqv16hi3, \"__builtin_ia32_pcmpeqw256\", IX86_BUILTIN_PCMPEQW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_eqv8si3, \"__builtin_ia32_pcmpeqd256\", IX86_BUILTIN_PCMPEQD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI  },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_eqv4di3, \"__builtin_ia32_pcmpeqq256\", IX86_BUILTIN_PCMPEQQ256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI  },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_gtv32qi3, \"__builtin_ia32_pcmpgtb256\", IX86_BUILTIN_PCMPGTB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_gtv16hi3, \"__builtin_ia32_pcmpgtw256\", IX86_BUILTIN_PCMPGTW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_gtv8si3, \"__builtin_ia32_pcmpgtd256\", IX86_BUILTIN_PCMPGTD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI  },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_gtv4di3, \"__builtin_ia32_pcmpgtq256\", IX86_BUILTIN_PCMPGTQ256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI  },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_phaddwv16hi3, \"__builtin_ia32_phaddw256\", IX86_BUILTIN_PHADDW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_phadddv8si3, \"__builtin_ia32_phaddd256\", IX86_BUILTIN_PHADDD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_phaddswv16hi3, \"__builtin_ia32_phaddsw256\", IX86_BUILTIN_PHADDSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_phsubwv16hi3, \"__builtin_ia32_phsubw256\", IX86_BUILTIN_PHSUBW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_phsubdv8si3, \"__builtin_ia32_phsubd256\", IX86_BUILTIN_PHSUBD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_phsubswv16hi3, \"__builtin_ia32_phsubsw256\", IX86_BUILTIN_PHSUBSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pmaddubsw256, \"__builtin_ia32_pmaddubsw256\", IX86_BUILTIN_PMADDUBSW256, UNKNOWN, (int) V16HI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pmaddwd, \"__builtin_ia32_pmaddwd256\", IX86_BUILTIN_PMADDWD256, UNKNOWN, (int) V8SI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_smaxv32qi3, \"__builtin_ia32_pmaxsb256\", IX86_BUILTIN_PMAXSB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_smaxv16hi3, \"__builtin_ia32_pmaxsw256\", IX86_BUILTIN_PMAXSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_smaxv8si3 , \"__builtin_ia32_pmaxsd256\", IX86_BUILTIN_PMAXSD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_umaxv32qi3, \"__builtin_ia32_pmaxub256\", IX86_BUILTIN_PMAXUB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_umaxv16hi3, \"__builtin_ia32_pmaxuw256\", IX86_BUILTIN_PMAXUW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_umaxv8si3 , \"__builtin_ia32_pmaxud256\", IX86_BUILTIN_PMAXUD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sminv32qi3, \"__builtin_ia32_pminsb256\", IX86_BUILTIN_PMINSB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sminv16hi3, \"__builtin_ia32_pminsw256\", IX86_BUILTIN_PMINSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sminv8si3 , \"__builtin_ia32_pminsd256\", IX86_BUILTIN_PMINSD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_uminv32qi3, \"__builtin_ia32_pminub256\", IX86_BUILTIN_PMINUB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_uminv16hi3, \"__builtin_ia32_pminuw256\", IX86_BUILTIN_PMINUW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_uminv8si3 , \"__builtin_ia32_pminud256\", IX86_BUILTIN_PMINUD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pmovmskb, \"__builtin_ia32_pmovmskb256\", IX86_BUILTIN_PMOVMSKB256, UNKNOWN, (int) INT_FTYPE_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sign_extendv16qiv16hi2, \"__builtin_ia32_pmovsxbw256\", IX86_BUILTIN_PMOVSXBW256, UNKNOWN, (int) V16HI_FTYPE_V16QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sign_extendv8qiv8si2  , \"__builtin_ia32_pmovsxbd256\", IX86_BUILTIN_PMOVSXBD256, UNKNOWN, (int) V8SI_FTYPE_V16QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sign_extendv4qiv4di2  , \"__builtin_ia32_pmovsxbq256\", IX86_BUILTIN_PMOVSXBQ256, UNKNOWN, (int) V4DI_FTYPE_V16QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sign_extendv8hiv8si2  , \"__builtin_ia32_pmovsxwd256\", IX86_BUILTIN_PMOVSXWD256, UNKNOWN, (int) V8SI_FTYPE_V8HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sign_extendv4hiv4di2  , \"__builtin_ia32_pmovsxwq256\", IX86_BUILTIN_PMOVSXWQ256, UNKNOWN, (int) V4DI_FTYPE_V8HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sign_extendv4siv4di2  , \"__builtin_ia32_pmovsxdq256\", IX86_BUILTIN_PMOVSXDQ256, UNKNOWN, (int) V4DI_FTYPE_V4SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_zero_extendv16qiv16hi2, \"__builtin_ia32_pmovzxbw256\", IX86_BUILTIN_PMOVZXBW256, UNKNOWN, (int) V16HI_FTYPE_V16QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_zero_extendv8qiv8si2  , \"__builtin_ia32_pmovzxbd256\", IX86_BUILTIN_PMOVZXBD256, UNKNOWN, (int) V8SI_FTYPE_V16QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_zero_extendv4qiv4di2  , \"__builtin_ia32_pmovzxbq256\", IX86_BUILTIN_PMOVZXBQ256, UNKNOWN, (int) V4DI_FTYPE_V16QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_zero_extendv8hiv8si2  , \"__builtin_ia32_pmovzxwd256\", IX86_BUILTIN_PMOVZXWD256, UNKNOWN, (int) V8SI_FTYPE_V8HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_zero_extendv4hiv4di2  , \"__builtin_ia32_pmovzxwq256\", IX86_BUILTIN_PMOVZXWQ256, UNKNOWN, (int) V4DI_FTYPE_V8HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_zero_extendv4siv4di2  , \"__builtin_ia32_pmovzxdq256\", IX86_BUILTIN_PMOVZXDQ256, UNKNOWN, (int) V4DI_FTYPE_V4SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_mulv4siv4di3  , \"__builtin_ia32_pmuldq256\"  , IX86_BUILTIN_PMULDQ256  , UNKNOWN, (int) V4DI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_umulhrswv16hi3 , \"__builtin_ia32_pmulhrsw256\", IX86_BUILTIN_PMULHRSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_umulv16hi3_highpart, \"__builtin_ia32_pmulhuw256\" , IX86_BUILTIN_PMULHUW256 , UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_smulv16hi3_highpart, \"__builtin_ia32_pmulhw256\"  , IX86_BUILTIN_PMULHW256  , UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_mulv16hi3, \"__builtin_ia32_pmullw256\"  , IX86_BUILTIN_PMULLW256  , UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_mulv8si3, \"__builtin_ia32_pmulld256\"  , IX86_BUILTIN_PMULLD256  , UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_umulv4siv4di3  , \"__builtin_ia32_pmuludq256\" , IX86_BUILTIN_PMULUDQ256 , UNKNOWN, (int) V4DI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_iorv4di3, \"__builtin_ia32_por256\", IX86_BUILTIN_POR256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_psadbw, \"__builtin_ia32_psadbw256\", IX86_BUILTIN_PSADBW256, UNKNOWN, (int) V16HI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pshufbv32qi3, \"__builtin_ia32_pshufb256\", IX86_BUILTIN_PSHUFB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pshufdv3, \"__builtin_ia32_pshufd256\", IX86_BUILTIN_PSHUFD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pshufhwv3, \"__builtin_ia32_pshufhw256\", IX86_BUILTIN_PSHUFHW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pshuflwv3, \"__builtin_ia32_pshuflw256\", IX86_BUILTIN_PSHUFLW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_psignv32qi3, \"__builtin_ia32_psignb256\", IX86_BUILTIN_PSIGNB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_psignv16hi3, \"__builtin_ia32_psignw256\", IX86_BUILTIN_PSIGNW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_psignv8si3 , \"__builtin_ia32_psignd256\", IX86_BUILTIN_PSIGND256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlqv4di3, \"__builtin_ia32_pslldqi256\", IX86_BUILTIN_PSLLDQI256, UNKNOWN, (int) V4DI_FTYPE_V4DI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlv16hi3, \"__builtin_ia32_psllwi256\", IX86_BUILTIN_PSLLWI256 , UNKNOWN, (int) V16HI_FTYPE_V16HI_SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlv16hi3, \"__builtin_ia32_psllw256\", IX86_BUILTIN_PSLLW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V8HI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlv8si3, \"__builtin_ia32_pslldi256\", IX86_BUILTIN_PSLLDI256, UNKNOWN, (int) V8SI_FTYPE_V8SI_SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlv8si3, \"__builtin_ia32_pslld256\", IX86_BUILTIN_PSLLD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V4SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlv4di3, \"__builtin_ia32_psllqi256\", IX86_BUILTIN_PSLLQI256, UNKNOWN, (int) V4DI_FTYPE_V4DI_INT_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlv4di3, \"__builtin_ia32_psllq256\", IX86_BUILTIN_PSLLQ256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V2DI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_ashrv16hi3, \"__builtin_ia32_psrawi256\", IX86_BUILTIN_PSRAWI256, UNKNOWN, (int) V16HI_FTYPE_V16HI_SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_ashrv16hi3, \"__builtin_ia32_psraw256\", IX86_BUILTIN_PSRAW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V8HI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_ashrv8si3, \"__builtin_ia32_psradi256\", IX86_BUILTIN_PSRADI256, UNKNOWN, (int) V8SI_FTYPE_V8SI_SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_ashrv8si3, \"__builtin_ia32_psrad256\", IX86_BUILTIN_PSRAD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V4SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshrqv4di3, \"__builtin_ia32_psrldqi256\", IX86_BUILTIN_PSRLDQI256, UNKNOWN, (int) V4DI_FTYPE_V4DI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_lshrv16hi3, \"__builtin_ia32_psrlwi256\", IX86_BUILTIN_PSRLWI256 , UNKNOWN, (int) V16HI_FTYPE_V16HI_SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_lshrv16hi3, \"__builtin_ia32_psrlw256\", IX86_BUILTIN_PSRLW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V8HI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_lshrv8si3, \"__builtin_ia32_psrldi256\", IX86_BUILTIN_PSRLDI256, UNKNOWN, (int) V8SI_FTYPE_V8SI_SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_lshrv8si3, \"__builtin_ia32_psrld256\", IX86_BUILTIN_PSRLD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V4SI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_lshrv4di3, \"__builtin_ia32_psrlqi256\", IX86_BUILTIN_PSRLQI256, UNKNOWN, (int) V4DI_FTYPE_V4DI_INT_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_lshrv4di3, \"__builtin_ia32_psrlq256\", IX86_BUILTIN_PSRLQ256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V2DI_COUNT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_subv32qi3, \"__builtin_ia32_psubb256\", IX86_BUILTIN_PSUBB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_subv16hi3, \"__builtin_ia32_psubw256\", IX86_BUILTIN_PSUBW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_subv8si3, \"__builtin_ia32_psubd256\", IX86_BUILTIN_PSUBD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_subv4di3, \"__builtin_ia32_psubq256\", IX86_BUILTIN_PSUBQ256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sssubv32qi3, \"__builtin_ia32_psubsb256\", IX86_BUILTIN_PSUBSB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_sssubv16hi3, \"__builtin_ia32_psubsw256\", IX86_BUILTIN_PSUBSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_ussubv32qi3, \"__builtin_ia32_psubusb256\", IX86_BUILTIN_PSUBUSB256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_ussubv16hi3, \"__builtin_ia32_psubusw256\", IX86_BUILTIN_PSUBUSW256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_interleave_highv32qi, \"__builtin_ia32_punpckhbw256\", IX86_BUILTIN_PUNPCKHBW256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_interleave_highv16hi, \"__builtin_ia32_punpckhwd256\", IX86_BUILTIN_PUNPCKHWD256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI  },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_interleave_highv8si, \"__builtin_ia32_punpckhdq256\", IX86_BUILTIN_PUNPCKHDQ256, UNKNOWN,  (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_interleave_highv4di, \"__builtin_ia32_punpckhqdq256\", IX86_BUILTIN_PUNPCKHQDQ256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_interleave_lowv32qi, \"__builtin_ia32_punpcklbw256\", IX86_BUILTIN_PUNPCKLBW256, UNKNOWN, (int) V32QI_FTYPE_V32QI_V32QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_interleave_lowv16hi, \"__builtin_ia32_punpcklwd256\", IX86_BUILTIN_PUNPCKLWD256, UNKNOWN, (int) V16HI_FTYPE_V16HI_V16HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_interleave_lowv8si, \"__builtin_ia32_punpckldq256\", IX86_BUILTIN_PUNPCKLDQ256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_interleave_lowv4di, \"__builtin_ia32_punpcklqdq256\", IX86_BUILTIN_PUNPCKLQDQ256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_xorv4di3, \"__builtin_ia32_pxor256\", IX86_BUILTIN_PXOR256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_vec_dupv4sf, \"__builtin_ia32_vbroadcastss_ps\", IX86_BUILTIN_VBROADCASTSS_PS, UNKNOWN, (int) V4SF_FTYPE_V4SF },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_vec_dupv8sf, \"__builtin_ia32_vbroadcastss_ps256\", IX86_BUILTIN_VBROADCASTSS_PS256, UNKNOWN, (int) V8SF_FTYPE_V4SF },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_vec_dupv4df, \"__builtin_ia32_vbroadcastsd_pd256\", IX86_BUILTIN_VBROADCASTSD_PD256, UNKNOWN, (int) V4DF_FTYPE_V2DF },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_vbroadcasti128_v4di, \"__builtin_ia32_vbroadcastsi256\", IX86_BUILTIN_VBROADCASTSI256, UNKNOWN, (int) V4DI_FTYPE_V2DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pblenddv4si, \"__builtin_ia32_pblendd128\", IX86_BUILTIN_PBLENDD128, UNKNOWN, (int) V4SI_FTYPE_V4SI_V4SI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pblenddv8si, \"__builtin_ia32_pblendd256\", IX86_BUILTIN_PBLENDD256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pbroadcastv32qi, \"__builtin_ia32_pbroadcastb256\", IX86_BUILTIN_PBROADCASTB256, UNKNOWN, (int) V32QI_FTYPE_V16QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pbroadcastv16hi, \"__builtin_ia32_pbroadcastw256\", IX86_BUILTIN_PBROADCASTW256, UNKNOWN, (int) V16HI_FTYPE_V8HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pbroadcastv8si, \"__builtin_ia32_pbroadcastd256\", IX86_BUILTIN_PBROADCASTD256, UNKNOWN, (int) V8SI_FTYPE_V4SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pbroadcastv4di, \"__builtin_ia32_pbroadcastq256\", IX86_BUILTIN_PBROADCASTQ256, UNKNOWN, (int) V4DI_FTYPE_V2DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pbroadcastv16qi, \"__builtin_ia32_pbroadcastb128\", IX86_BUILTIN_PBROADCASTB128, UNKNOWN, (int) V16QI_FTYPE_V16QI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pbroadcastv8hi, \"__builtin_ia32_pbroadcastw128\", IX86_BUILTIN_PBROADCASTW128, UNKNOWN, (int) V8HI_FTYPE_V8HI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pbroadcastv4si, \"__builtin_ia32_pbroadcastd128\", IX86_BUILTIN_PBROADCASTD128, UNKNOWN, (int) V4SI_FTYPE_V4SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_pbroadcastv2di, \"__builtin_ia32_pbroadcastq128\", IX86_BUILTIN_PBROADCASTQ128, UNKNOWN, (int) V2DI_FTYPE_V2DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_permvarv8si, \"__builtin_ia32_permvarsi256\", IX86_BUILTIN_VPERMVARSI256, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_permv4df, \"__builtin_ia32_permdf256\", IX86_BUILTIN_VPERMDF256, UNKNOWN, (int) V4DF_FTYPE_V4DF_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_permvarv8sf, \"__builtin_ia32_permvarsf256\", IX86_BUILTIN_VPERMVARSF256, UNKNOWN, (int) V8SF_FTYPE_V8SF_V8SF },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_permv4di, \"__builtin_ia32_permdi256\", IX86_BUILTIN_VPERMDI256, UNKNOWN, (int) V4DI_FTYPE_V4DI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_permv2ti, \"__builtin_ia32_permti256\", IX86_BUILTIN_VPERMTI256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_extracti128, \"__builtin_ia32_extract128i256\", IX86_BUILTIN_VEXTRACT128I256, UNKNOWN, (int) V2DI_FTYPE_V4DI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_inserti128, \"__builtin_ia32_insert128i256\", IX86_BUILTIN_VINSERT128I256, UNKNOWN, (int) V4DI_FTYPE_V4DI_V2DI_INT },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlvv4di, \"__builtin_ia32_psllv4di\", IX86_BUILTIN_PSLLVV4DI, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlvv2di, \"__builtin_ia32_psllv2di\", IX86_BUILTIN_PSLLVV2DI, UNKNOWN, (int) V2DI_FTYPE_V2DI_V2DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlvv8si, \"__builtin_ia32_psllv8si\", IX86_BUILTIN_PSLLVV8SI, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshlvv4si, \"__builtin_ia32_psllv4si\", IX86_BUILTIN_PSLLVV4SI, UNKNOWN, (int) V4SI_FTYPE_V4SI_V4SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_ashrvv8si, \"__builtin_ia32_psrav8si\", IX86_BUILTIN_PSRAVV8SI, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_ashrvv4si, \"__builtin_ia32_psrav4si\", IX86_BUILTIN_PSRAVV4SI, UNKNOWN, (int) V4SI_FTYPE_V4SI_V4SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshrvv4di, \"__builtin_ia32_psrlv4di\", IX86_BUILTIN_PSRLVV4DI, UNKNOWN, (int) V4DI_FTYPE_V4DI_V4DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshrvv2di, \"__builtin_ia32_psrlv2di\", IX86_BUILTIN_PSRLVV2DI, UNKNOWN, (int) V2DI_FTYPE_V2DI_V2DI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshrvv8si, \"__builtin_ia32_psrlv8si\", IX86_BUILTIN_PSRLVV8SI, UNKNOWN, (int) V8SI_FTYPE_V8SI_V8SI },\n+  { OPTION_MASK_ISA_AVX2, CODE_FOR_avx2_lshrvv4si, \"__builtin_ia32_psrlv4si\", IX86_BUILTIN_PSRLVV4SI, UNKNOWN, (int) V4SI_FTYPE_V4SI_V4SI },\n+\n   { OPTION_MASK_ISA_LZCNT, CODE_FOR_clzhi2_lzcnt,   \"__builtin_clzs\",   IX86_BUILTIN_CLZS,    UNKNOWN,     (int) UINT16_FTYPE_UINT16 },\n \n   /* BMI */\n@@ -25415,6 +25748,71 @@ ix86_init_mmx_sse_builtins (void)\n \t       \"__builtin_ia32_rdrand64_step\", INT_FTYPE_PULONGLONG,\n \t       IX86_BUILTIN_RDRAND64_STEP);\n \n+  /* AVX2 */\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gathersiv2df\",\n+\t       V2DF_FTYPE_V2DF_PCDOUBLE_V4SI_V2DF_INT,\n+\t       IX86_BUILTIN_GATHERSIV2DF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gathersiv4df\",\n+\t       V4DF_FTYPE_V4DF_PCDOUBLE_V4SI_V4DF_INT,\n+\t       IX86_BUILTIN_GATHERSIV4DF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatherdiv2df\",\n+\t       V2DF_FTYPE_V2DF_PCDOUBLE_V2DI_V2DF_INT,\n+\t       IX86_BUILTIN_GATHERDIV2DF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatherdiv4df\",\n+\t       V4DF_FTYPE_V4DF_PCDOUBLE_V4DI_V4DF_INT,\n+\t       IX86_BUILTIN_GATHERDIV4DF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gathersiv4sf\",\n+\t       V4SF_FTYPE_V4SF_PCFLOAT_V4SI_V4SF_INT,\n+\t       IX86_BUILTIN_GATHERSIV4SF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gathersiv8sf\",\n+\t       V8SF_FTYPE_V8SF_PCFLOAT_V8SI_V8SF_INT,\n+\t       IX86_BUILTIN_GATHERSIV8SF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatherdiv4sf\",\n+\t       V4SF_FTYPE_V4SF_PCFLOAT_V2DI_V4SF_INT,\n+\t       IX86_BUILTIN_GATHERDIV4SF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatherdiv4sf256\",\n+\t       V4SF_FTYPE_V4SF_PCFLOAT_V4DI_V4SF_INT,\n+\t       IX86_BUILTIN_GATHERDIV8SF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gathersiv2di\",\n+\t       V2DI_FTYPE_V2DI_PCINT64_V4SI_V2DI_INT,\n+\t       IX86_BUILTIN_GATHERSIV2DI);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gathersiv4di\",\n+\t       V4DI_FTYPE_V4DI_PCINT64_V4SI_V4DI_INT,\n+\t       IX86_BUILTIN_GATHERSIV4DI);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatherdiv2di\",\n+\t       V2DI_FTYPE_V2DI_PCINT64_V2DI_V2DI_INT,\n+\t       IX86_BUILTIN_GATHERDIV2DI);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatherdiv4di\",\n+\t       V4DI_FTYPE_V4DI_PCINT64_V4DI_V4DI_INT,\n+\t       IX86_BUILTIN_GATHERDIV4DI);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gathersiv4si\",\n+\t       V4SI_FTYPE_V4SI_PCINT_V4SI_V4SI_INT,\n+\t       IX86_BUILTIN_GATHERSIV4SI);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gathersiv8si\",\n+\t       V8SI_FTYPE_V8SI_PCINT_V8SI_V8SI_INT,\n+\t       IX86_BUILTIN_GATHERSIV8SI);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatherdiv4si\",\n+\t       V4SI_FTYPE_V4SI_PCINT_V2DI_V4SI_INT,\n+\t       IX86_BUILTIN_GATHERDIV4SI);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatherdiv4si256\",\n+\t       V4SI_FTYPE_V4SI_PCINT_V4DI_V4SI_INT,\n+\t       IX86_BUILTIN_GATHERDIV8SI);\n+\n   /* MMX access to the vec_init patterns.  */\n   def_builtin_const (OPTION_MASK_ISA_MMX, \"__builtin_ia32_vec_init_v2si\",\n \t\t     V2SI_FTYPE_INT_INT, IX86_BUILTIN_VEC_INIT_V2SI);\n@@ -26364,6 +26762,7 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case INT_FTYPE_V4DF:\n     case INT_FTYPE_V4SF:\n     case INT_FTYPE_V2DF:\n+    case INT_FTYPE_V32QI:\n     case V16QI_FTYPE_V16QI:\n     case V8SI_FTYPE_V8SF:\n     case V8SI_FTYPE_V4SI:\n@@ -26407,6 +26806,18 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case V2SI_FTYPE_V2DF:\n     case V2SF_FTYPE_V2SF:\n     case V2SF_FTYPE_V2SI:\n+    case V32QI_FTYPE_V32QI:\n+    case V32QI_FTYPE_V16QI:\n+    case V16HI_FTYPE_V16HI:\n+    case V16HI_FTYPE_V8HI:\n+    case V8SI_FTYPE_V8SI:\n+    case V16HI_FTYPE_V16QI:\n+    case V8SI_FTYPE_V16QI:\n+    case V4DI_FTYPE_V16QI:\n+    case V8SI_FTYPE_V8HI:\n+    case V4DI_FTYPE_V8HI:\n+    case V4DI_FTYPE_V4SI:\n+    case V4DI_FTYPE_V2DI:\n       nargs = 1;\n       break;\n     case V4SF_FTYPE_V4SF_VEC_MERGE:\n@@ -26454,6 +26865,15 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case V1DI_FTYPE_V1DI_V1DI:\n     case V1DI_FTYPE_V8QI_V8QI:\n     case V1DI_FTYPE_V2SI_V2SI:\n+    case V32QI_FTYPE_V16HI_V16HI:\n+    case V16HI_FTYPE_V8SI_V8SI:\n+    case V32QI_FTYPE_V32QI_V32QI:\n+    case V16HI_FTYPE_V32QI_V32QI:\n+    case V16HI_FTYPE_V16HI_V16HI:\n+    case V8SI_FTYPE_V8SI_V8SI:\n+    case V8SI_FTYPE_V16HI_V16HI:\n+    case V4DI_FTYPE_V4DI_V4DI:\n+    case V4DI_FTYPE_V8SI_V8SI:\n       if (comparison == UNKNOWN)\n \treturn ix86_expand_binop_builtin (icode, exp, target);\n       nargs = 2;\n@@ -26464,6 +26884,12 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n       nargs = 2;\n       swap = true;\n       break;\n+    case V16HI_FTYPE_V16HI_V8HI_COUNT:\n+    case V16HI_FTYPE_V16HI_SI_COUNT:\n+    case V8SI_FTYPE_V8SI_V4SI_COUNT:\n+    case V8SI_FTYPE_V8SI_SI_COUNT:\n+    case V4DI_FTYPE_V4DI_V2DI_COUNT:\n+    case V4DI_FTYPE_V4DI_INT_COUNT:\n     case V8HI_FTYPE_V8HI_V8HI_COUNT:\n     case V8HI_FTYPE_V8HI_SI_COUNT:\n     case V4SI_FTYPE_V4SI_V4SI_COUNT:\n@@ -26505,6 +26931,10 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case V2DI_FTYPE_V2DI_INT:\n     case V2DF_FTYPE_V2DF_INT:\n     case V2DF_FTYPE_V4DF_INT:\n+    case V16HI_FTYPE_V16HI_INT:\n+    case V8SI_FTYPE_V8SI_INT:\n+    case V4DI_FTYPE_V4DI_INT:\n+    case V2DI_FTYPE_V4DI_INT:\n       nargs = 2;\n       nargs_constant = 1;\n       break;\n@@ -26513,9 +26943,13 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case V4DF_FTYPE_V4DF_V4DF_V4DF:\n     case V4SF_FTYPE_V4SF_V4SF_V4SF:\n     case V2DF_FTYPE_V2DF_V2DF_V2DF:\n+    case V32QI_FTYPE_V32QI_V32QI_V32QI:\n       nargs = 3;\n       break;\n+    case V32QI_FTYPE_V32QI_V32QI_INT:\n+    case V16HI_FTYPE_V16HI_V16HI_INT:\n     case V16QI_FTYPE_V16QI_V16QI_INT:\n+    case V4DI_FTYPE_V4DI_V4DI_INT:\n     case V8HI_FTYPE_V8HI_V8HI_INT:\n     case V8SI_FTYPE_V8SI_V8SI_INT:\n     case V8SI_FTYPE_V8SI_V4SI_INT:\n@@ -26526,10 +26960,16 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case V4DF_FTYPE_V4DF_V2DF_INT:\n     case V4SF_FTYPE_V4SF_V4SF_INT:\n     case V2DI_FTYPE_V2DI_V2DI_INT:\n+    case V4DI_FTYPE_V4DI_V2DI_INT:\n     case V2DF_FTYPE_V2DF_V2DF_INT:\n       nargs = 3;\n       nargs_constant = 1;\n       break;\n+    case V4DI_FTYPE_V4DI_V4DI_INT_CONVERT:\n+      nargs = 3;\n+      rmode = V4DImode;\n+      nargs_constant = 1;\n+      break;\n     case V2DI_FTYPE_V2DI_V2DI_INT_CONVERT:\n       nargs = 3;\n       rmode = V2DImode;\n@@ -26606,6 +27046,11 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n \t  if (!match)\n \t    switch (icode)\n \t      {\n+\t      case CODE_FOR_avx2_inserti128:\n+\t      case CODE_FOR_avx2_extracti128:\n+\t\terror (\"the last argument must be an 1-bit immediate\");\n+\t\treturn const0_rtx;\n+\n \t      case CODE_FOR_sse4_1_roundpd:\n \t      case CODE_FOR_sse4_1_roundps:\n \t      case CODE_FOR_sse4_1_roundsd:\n@@ -26759,6 +27204,7 @@ ix86_expand_special_args_builtin (const struct builtin_description *d,\n       break;\n     case UINT64_FTYPE_PUNSIGNED:\n     case V2DI_FTYPE_PV2DI:\n+    case V4DI_FTYPE_PV4DI:\n     case V32QI_FTYPE_PCCHAR:\n     case V16QI_FTYPE_PCCHAR:\n     case V8SF_FTYPE_PCV4SF:\n@@ -26798,6 +27244,10 @@ ix86_expand_special_args_builtin (const struct builtin_description *d,\n     case V4DF_FTYPE_PCV4DF_V4DI:\n     case V4SF_FTYPE_PCV4SF_V4SI:\n     case V2DF_FTYPE_PCV2DF_V2DI:\n+    case V8SI_FTYPE_PCV8SI_V8SI:\n+    case V4DI_FTYPE_PCV4DI_V4DI:\n+    case V4SI_FTYPE_PCV4SI_V4SI:\n+    case V2DI_FTYPE_PCV2DI_V2DI:\n       nargs = 2;\n       klass = load;\n       memory = 0;\n@@ -26806,6 +27256,10 @@ ix86_expand_special_args_builtin (const struct builtin_description *d,\n     case VOID_FTYPE_PV4DF_V4DI_V4DF:\n     case VOID_FTYPE_PV4SF_V4SI_V4SF:\n     case VOID_FTYPE_PV2DF_V2DI_V2DF:\n+    case VOID_FTYPE_PV8SI_V8SI_V8SI:\n+    case VOID_FTYPE_PV4DI_V4DI_V4DI:\n+    case VOID_FTYPE_PV4SI_V4SI_V4SI:\n+    case VOID_FTYPE_PV2DI_V2DI_V2DI:\n       nargs = 2;\n       klass = store;\n       /* Reserve memory operand for target.  */\n@@ -27062,9 +27516,9 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n   size_t i;\n   enum insn_code icode;\n   tree fndecl = TREE_OPERAND (CALL_EXPR_FN (exp), 0);\n-  tree arg0, arg1, arg2;\n-  rtx op0, op1, op2, pat;\n-  enum machine_mode mode0, mode1, mode2;\n+  tree arg0, arg1, arg2, arg3, arg4;\n+  rtx op0, op1, op2, op3, op4, pat;\n+  enum machine_mode mode0, mode1, mode2, mode3, mode4;\n   unsigned int fcode = DECL_FUNCTION_CODE (fndecl);\n \n   /* Determine whether the builtin function is available under the current ISA.\n@@ -27333,6 +27787,100 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n \t\t\t      gen_rtx_IF_THEN_ELSE (SImode, pat, op2, op1)));\n       return target;\n \n+    case IX86_BUILTIN_GATHERSIV2DF:\n+      icode = CODE_FOR_avx2_gathersiv2df;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERSIV4DF:\n+      icode = CODE_FOR_avx2_gathersiv4df;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERDIV2DF:\n+      icode = CODE_FOR_avx2_gatherdiv2df;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERDIV4DF:\n+      icode = CODE_FOR_avx2_gatherdiv4df;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERSIV4SF:\n+      icode = CODE_FOR_avx2_gathersiv4sf;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERSIV8SF:\n+      icode = CODE_FOR_avx2_gathersiv8sf;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERDIV4SF:\n+      icode = CODE_FOR_avx2_gatherdiv4sf;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERDIV8SF:\n+      icode = CODE_FOR_avx2_gatherdiv4sf256;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERSIV2DI:\n+      icode = CODE_FOR_avx2_gathersiv2di;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERSIV4DI:\n+      icode = CODE_FOR_avx2_gathersiv4di;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERDIV2DI:\n+      icode = CODE_FOR_avx2_gatherdiv2di;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERDIV4DI:\n+      icode = CODE_FOR_avx2_gatherdiv4di;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERSIV4SI:\n+      icode = CODE_FOR_avx2_gathersiv4si;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERSIV8SI:\n+      icode = CODE_FOR_avx2_gathersiv8si;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERDIV4SI:\n+      icode = CODE_FOR_avx2_gatherdiv4si;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERDIV8SI:\n+      icode = CODE_FOR_avx2_gatherdiv4si256;\n+\n+    gather_gen:\n+      arg0 = CALL_EXPR_ARG (exp, 0);\n+      arg1 = CALL_EXPR_ARG (exp, 1);\n+      arg2 = CALL_EXPR_ARG (exp, 2);\n+      arg3 = CALL_EXPR_ARG (exp, 3);\n+      arg4 = CALL_EXPR_ARG (exp, 4);\n+      op0 = expand_normal (arg0);\n+      op1 = expand_normal (arg1);\n+      op2 = expand_normal (arg2);\n+      op3 = expand_normal (arg3);\n+      op4 = expand_normal (arg4);\n+      /* Note the arg order is different from the operand order.  */\n+      mode0 = insn_data[icode].operand[1].mode;\n+      mode1 = insn_data[icode].operand[2].mode;\n+      mode2 = insn_data[icode].operand[3].mode;\n+      mode3 = insn_data[icode].operand[4].mode;\n+      mode4 = insn_data[icode].operand[5].mode;\n+\n+      if (target == NULL_RTX)\n+\ttarget = gen_reg_rtx (insn_data[icode].operand[0].mode);\n+\n+      /* Force memory operand only with base register here.  But we\n+\t don't want to do it on memory operand for other builtin\n+\t functions.  */\n+      op1 = force_reg (Pmode, op1);\n+      op1 = gen_rtx_MEM (mode1, op1);\n+\n+      if (!insn_data[icode].operand[1].predicate (op0, mode0))\n+\top0 = copy_to_mode_reg (mode0, op0);\n+      if (!insn_data[icode].operand[2].predicate (op1, mode1))\n+\top1 = copy_to_mode_reg (mode1, op1);\n+      if (!insn_data[icode].operand[3].predicate (op2, mode2))\n+\top2 = copy_to_mode_reg (mode2, op2);\n+      if (!insn_data[icode].operand[4].predicate (op3, mode3))\n+\top3 = copy_to_mode_reg (mode3, op3);\n+      if (!insn_data[icode].operand[5].predicate (op4, mode4))\n+\t{\n+          error (\"last argument must be scale 1, 2, 4, 8\");\n+          return const0_rtx;\n+\t}\n+      pat = GEN_FCN (icode) (target, op0, op1, op2, op3, op4);\n+      if (! pat)\n+\treturn const0_rtx;\n+      emit_insn (pat);\n+      return target;\n+\n     default:\n       break;\n     }\n@@ -35044,13 +35592,13 @@ ix86_preferred_simd_mode (enum machine_mode mode)\n   switch (mode)\n     {\n     case QImode:\n-      return V16QImode;\n+      return TARGET_AVX2 ? V32QImode : V16QImode;\n     case HImode:\n-      return V8HImode;\n+      return TARGET_AVX2 ? V16HImode : V8HImode;\n     case SImode:\n-      return V4SImode;\n+      return TARGET_AVX2 ? V8SImode : V4SImode;\n     case DImode:\n-      return V2DImode;\n+      return TARGET_AVX2 ? V4DImode : V2DImode;\n \n     case SFmode:\n       if (TARGET_AVX && !TARGET_PREFER_AVX128)"}, {"sha": "d343fc2a036223d1eb475fcc063e2d899bbfdd85", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -231,6 +231,14 @@\n   UNSPEC_VCVTPH2PS\n   UNSPEC_VCVTPS2PH\n \n+  ;; For AVX2 support\n+  UNSPEC_VPERMSI\n+  UNSPEC_VPERMDF\n+  UNSPEC_VPERMSF\n+  UNSPEC_VPERMDI\n+  UNSPEC_VPERMTI\n+  UNSPEC_GATHER\n+\n   ;; For BMI support\n   UNSPEC_BEXTR\n \n@@ -930,7 +938,8 @@\n   [(SF \"ss\") (DF \"sd\")\n    (V8SF \"ps\") (V4DF \"pd\")\n    (V4SF \"ps\") (V2DF \"pd\")\n-   (V16QI \"b\") (V8HI \"w\") (V4SI \"d\") (V2DI \"q\")])\n+   (V16QI \"b\") (V8HI \"w\") (V4SI \"d\") (V2DI \"q\")\n+   (V32QI \"b\") (V16HI \"w\") (V8SI \"d\") (V4DI \"q\")])\n \n ;; SSE vector suffix for floating point modes\n (define_mode_attr ssevecmodesuffix [(SF \"ps\") (DF \"pd\")])"}, {"sha": "3704df72c07fc0ece8fdd3b0ad94cde519ab732c", "filename": "gcc/config/i386/immintrin.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fimmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fimmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fimmintrin.h?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -56,6 +56,10 @@\n #include <avxintrin.h>\n #endif\n \n+#ifdef __AVX2__\n+#include <avx2intrin.h>\n+#endif\n+\n #ifdef __RDRND__\n extern __inline int\n __attribute__((__gnu_inline__, __always_inline__, __artificial__))"}, {"sha": "b4fa04e2c4d4d4205a797538a901b3b5dae15572", "filename": "gcc/config/i386/predicates.md", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fpredicates.md?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -611,6 +611,14 @@\n   return i == 2 || i == 4 || i == 8;\n })\n \n+;; Match 1, 2, 4, or 8\n+(define_predicate \"const1248_operand\"\n+  (match_code \"const_int\")\n+{\n+  HOST_WIDE_INT i = INTVAL (op);\n+  return i == 1 || i == 2 || i == 4 || i == 8;\n+})\n+\n ;; Match 3, 5, or 9.  Used for leal multiplicands.\n (define_predicate \"const359_operand\"\n   (match_code \"const_int\")"}, {"sha": "5bc85861b36b36cb639731e560d098522eb2ad97", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 2287, "deletions": 253, "changes": 2540, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197"}, {"sha": "29c02b8354d679bdfc9e8d45ecfe9045da742935", "filename": "gcc/doc/extend.texi", "status": "modified", "additions": 178, "deletions": 0, "changes": 178, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fdoc%2Fextend.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/977e83a3edc1a58077e33143ad3cc1f9349d6197/gcc%2Fdoc%2Fextend.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fextend.texi?ref=977e83a3edc1a58077e33143ad3cc1f9349d6197", "patch": "@@ -9455,6 +9455,184 @@ v4df __builtin_ia32_xorpd256 (v4df,v4df)\n v8sf __builtin_ia32_xorps256 (v8sf,v8sf)\n @end smallexample\n \n+The following built-in functions are available when @option{-mavx2} is\n+used. All of them generate the machine instruction that is part of the\n+name.\n+\n+@smallexample\n+v32qi __builtin_ia32_mpsadbw256 (v32qi,v32qi,v32qi,int)\n+v32qi __builtin_ia32_pabsb256 (v32qi)\n+v16hi __builtin_ia32_pabsw256 (v16hi)\n+v8si __builtin_ia32_pabsd256 (v8si)\n+v16hi builtin_ia32_packssdw256 (v8si,v8si)\n+v32qi __builtin_ia32_packsswb256 (v16hi,v16hi)\n+v16hi __builtin_ia32_packusdw256 (v8si,v8si)\n+v32qi __builtin_ia32_packuswb256 (v16hi,v16hi)\n+v32qi__builtin_ia32_paddb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_paddw256 (v16hi,v16hi)\n+v8si __builtin_ia32_paddd256 (v8si,v8si)\n+v4di __builtin_ia32_paddq256 (v4di,v4di)\n+v32qi __builtin_ia32_paddsb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_paddsw256 (v16hi,v16hi)\n+v32qi __builtin_ia32_paddusb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_paddusw256 (v16hi,v16hi)\n+v4di __builtin_ia32_palignr256 (v4di,v4di,int)\n+v4di __builtin_ia32_andsi256 (v4di,v4di)\n+v4di __builtin_ia32_andnotsi256 (v4di,v4di)\n+v32qi__builtin_ia32_pavgb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_pavgw256 (v16hi,v16hi)\n+v32qi __builtin_ia32_pblendvb256 (v32qi,v32qi,v32qi)\n+v16hi __builtin_ia32_pblendw256 (v16hi,v16hi,int)\n+v32qi __builtin_ia32_pcmpeqb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_pcmpeqw256 (v16hi,v16hi)\n+v8si __builtin_ia32_pcmpeqd256 (c8si,v8si)\n+v4di __builtin_ia32_pcmpeqq256 (v4di,v4di)\n+v32qi __builtin_ia32_pcmpgtb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_pcmpgtw256 (16hi,v16hi)\n+v8si __builtin_ia32_pcmpgtd256 (v8si,v8si)\n+v4di __builtin_ia32_pcmpgtq256 (v4di,v4di)\n+v16hi __builtin_ia32_phaddw256 (v16hi,v16hi)\n+v8si __builtin_ia32_phaddd256 (v8si,v8si)\n+v16hi __builtin_ia32_phaddsw256 (v16hi,v16hi)\n+v16hi __builtin_ia32_phsubw256 (v16hi,v16hi)\n+v8si __builtin_ia32_phsubd256 (v8si,v8si)\n+v16hi __builtin_ia32_phsubsw256 (v16hi,v16hi)\n+v32qi __builtin_ia32_pmaddubsw256 (v32qi,v32qi)\n+v16hi __builtin_ia32_pmaddwd256 (v16hi,v16hi)\n+v32qi __builtin_ia32_pmaxsb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_pmaxsw256 (v16hi,v16hi)\n+v8si __builtin_ia32_pmaxsd256 (v8si,v8si)\n+v32qi __builtin_ia32_pmaxub256 (v32qi,v32qi)\n+v16hi __builtin_ia32_pmaxuw256 (v16hi,v16hi)\n+v8si __builtin_ia32_pmaxud256 (v8si,v8si)\n+v32qi __builtin_ia32_pminsb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_pminsw256 (v16hi,v16hi)\n+v8si __builtin_ia32_pminsd256 (v8si,v8si)\n+v32qi __builtin_ia32_pminub256 (v32qi,v32qi)\n+v16hi __builtin_ia32_pminuw256 (v16hi,v16hi)\n+v8si __builtin_ia32_pminud256 (v8si,v8si)\n+int __builtin_ia32_pmovmskb256 (v32qi)\n+v16hi __builtin_ia32_pmovsxbw256 (v16qi)\n+v8si __builtin_ia32_pmovsxbd256 (v16qi)\n+v4di __builtin_ia32_pmovsxbq256 (v16qi)\n+v8si __builtin_ia32_pmovsxwd256 (v8hi)\n+v4di __builtin_ia32_pmovsxwq256 (v8hi)\n+v4di __builtin_ia32_pmovsxdq256 (v4si)\n+v16hi __builtin_ia32_pmovzxbw256 (v16qi)\n+v8si __builtin_ia32_pmovzxbd256 (v16qi)\n+v4di __builtin_ia32_pmovzxbq256 (v16qi)\n+v8si __builtin_ia32_pmovzxwd256 (v8hi)\n+v4di __builtin_ia32_pmovzxwq256 (v8hi)\n+v4di __builtin_ia32_pmovzxdq256 (v4si)\n+v4di __builtin_ia32_pmuldq256 (v8si,v8si)\n+v16hi __builtin_ia32_pmulhrsw256 (v16hi, v16hi)\n+v16hi __builtin_ia32_pmulhuw256 (v16hi,v16hi)\n+v16hi __builtin_ia32_pmulhw256 (v16hi,v16hi)\n+v16hi __builtin_ia32_pmullw256 (v16hi,v16hi)\n+v8si __builtin_ia32_pmulld256 (v8si,v8si)\n+v4di __builtin_ia32_pmuludq256 (v8si,v8si)\n+v4di __builtin_ia32_por256 (v4di,v4di)\n+v16hi __builtin_ia32_psadbw256 (v32qi,v32qi)\n+v32qi __builtin_ia32_pshufb256 (v32qi,v32qi)\n+v8si __builtin_ia32_pshufd256 (v8si,int)\n+v16hi __builtin_ia32_pshufhw256 (v16hi,int)\n+v16hi __builtin_ia32_pshuflw256 (v16hi,int)\n+v32qi __builtin_ia32_psignb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_psignw256 (v16hi,v16hi)\n+v8si __builtin_ia32_psignd256 (v8si,v8si)\n+v4di __builtin_ia32_pslldqi256 (v4di,int)\n+v16hi __builtin_ia32_psllwi256 (16hi,int)\n+v16hi __builtin_ia32_psllw256(v16hi,v8hi)\n+v8si __builtin_ia32_pslldi256 (v8si,int)\n+v8si __builtin_ia32_pslld256(v8si,v4si)\n+v4di __builtin_ia32_psllqi256 (v4di,int)\n+v4di __builtin_ia32_psllq256(v4di,v2di)\n+v16hi __builtin_ia32_psrawi256 (v16hi,int)\n+v16hi __builtin_ia32_psraw256 (v16hi,v8hi)\n+v8si __builtin_ia32_psradi256 (v8si,int)\n+v8si __builtin_ia32_psrad256 (v8si,v4si)\n+v4di __builtin_ia32_psrldqi256 (v4di, int)\n+v16hi __builtin_ia32_psrlwi256 (v16hi,int)\n+v16hi __builtin_ia32_psrlw256 (v16hi,v8hi)\n+v8si __builtin_ia32_psrldi256 (v8si,int)\n+v8si __builtin_ia32_psrld256 (v8si,v4si)\n+v4di __builtin_ia32_psrlqi256 (v4di,int)\n+v4di __builtin_ia32_psrlq256(v4di,v2di)\n+v32qi __builtin_ia32_psubb256 (v32qi,v32qi)\n+v32hi __builtin_ia32_psubw256 (v16hi,v16hi)\n+v8si __builtin_ia32_psubd256 (v8si,v8si)\n+v4di __builtin_ia32_psubq256 (v4di,v4di)\n+v32qi __builtin_ia32_psubsb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_psubsw256 (v16hi,v16hi)\n+v32qi __builtin_ia32_psubusb256 (v32qi,v32qi)\n+v16hi __builtin_ia32_psubusw256 (v16hi,v16hi)\n+v32qi __builtin_ia32_punpckhbw256 (v32qi,v32qi)\n+v16hi __builtin_ia32_punpckhwd256 (v16hi,v16hi)\n+v8si __builtin_ia32_punpckhdq256 (v8si,v8si)\n+v4di __builtin_ia32_punpckhqdq256 (v4di,v4di)\n+v32qi __builtin_ia32_punpcklbw256 (v32qi,v32qi)\n+v16hi __builtin_ia32_punpcklwd256 (v16hi,v16hi)\n+v8si __builtin_ia32_punpckldq256 (v8si,v8si)\n+v4di __builtin_ia32_punpcklqdq256 (v4di,v4di)\n+v4di __builtin_ia32_pxor256 (v4di,v4di)\n+v4di __builtin_ia32_movntdqa256 (pv4di)\n+v4sf __builtin_ia32_vbroadcastss_ps (v4sf)\n+v8sf __builtin_ia32_vbroadcastss_ps256 (v4sf)\n+v4df __builtin_ia32_vbroadcastsd_pd256 (v2df)\n+v4di __builtin_ia32_vbroadcastsi256 (v2di)\n+v4si __builtin_ia32_pblendd128 (v4si,v4si)\n+v8si __builtin_ia32_pblendd256 (v8si,v8si)\n+v32qi __builtin_ia32_pbroadcastb256 (v16qi)\n+v16hi __builtin_ia32_pbroadcastw256 (v8hi)\n+v8si __builtin_ia32_pbroadcastd256 (v4si)\n+v4di __builtin_ia32_pbroadcastq256 (v2di)\n+v16qi __builtin_ia32_pbroadcastb128 (v16qi)\n+v8hi __builtin_ia32_pbroadcastw128 (v8hi)\n+v4si __builtin_ia32_pbroadcastd128 (v4si)\n+v2di __builtin_ia32_pbroadcastq128 (v2di)\n+v8si __builtin_ia32_permvarsi256 (v8si,v8si)\n+v4df __builtin_ia32_permdf256 (v4df,int)\n+v8sf __builtin_ia32_permvarsf256 (v8sf,v8sf)\n+v4di __builtin_ia32_permdi256 (v4di,int)\n+v4di __builtin_ia32_permti256 (v4di,v4di,int)\n+v4di __builtin_ia32_extract128i256 (v4di,int)\n+v4di __builtin_ia32_insert128i256 (v4di,v2di,int)\n+v8si __builtin_ia32_maskloadd256 (pcv8si,v8si)\n+v4di __builtin_ia32_maskloadq256 (pcv4di,v4di)\n+v4si __builtin_ia32_maskloadd (pcv4si,v4si)\n+v2di __builtin_ia32_maskloadq (pcv2di,v2di)\n+void __builtin_ia32_maskstored256 (pv8si,v8si,v8si)\n+void __builtin_ia32_maskstoreq256 (pv4di,v4di,v4di)\n+void __builtin_ia32_maskstored (pv4si,v4si,v4si)\n+void __builtin_ia32_maskstoreq (pv2di,v2di,v2di)\n+v8si __builtin_ia32_psllv8si (v8si,v8si)\n+v4si __builtin_ia32_psllv4si (v4si,v4si)\n+v4di __builtin_ia32_psllv4di (v4di,v4di)\n+v2di __builtin_ia32_psllv2di (v2di,v2di)\n+v8si __builtin_ia32_psrav8si (v8si,v8si)\n+v4si __builtin_ia32_psrav4si (v4si,v4si)\n+v8si __builtin_ia32_psrlv8si (v8si,v8si)\n+v4si __builtin_ia32_psrlv4si (v4si,v4si)\n+v4di __builtin_ia32_psrlv4di (v4di,v4di)\n+v2di __builtin_ia32_psrlv2di (v2di,v2di)\n+v2df __builtin_ia32_gathersiv2df (v2df, pcdouble,v4si,v2df,int)\n+v4df __builtin_ia32_gathersiv4df (v4df, pcdouble,v4si,v4df,int)\n+v2df __builtin_ia32_gatherdiv2df (v2df, pcdouble,v2di,v2df,int)\n+v4df __builtin_ia32_gatherdiv4df (v4df, pcdouble,v4di,v4df,int)\n+v4sf __builtin_ia32_gathersiv4sf (v4sf, pcfloat,v4si,v4sf,int)\n+v8sf __builtin_ia32_gathersiv8sf (v8sf, pcfloat,v8si,v8sf,int)\n+v4sf __builtin_ia32_gatherdiv4sf (v4sf, pcfloat,v2di,v4sf,int)\n+v4sf __builtin_ia32_gatherdiv4sf256 (v4sf, pcfloat,v4di,v4sf,int)\n+v2di __builtin_ia32_gathersiv2di (v2di, pcint64,v4si,v2di,int)\n+v4di __builtin_ia32_gathersiv4di (v4di, pcint64,v4si,v4di,int)\n+v2di __builtin_ia32_gatherdiv2di (v2di, pcint64,v2di,v2di,int)\n+v4di __builtin_ia32_gatherdiv4di (v4di, pcint64,v4di,v4di,int)\n+v4si __builtin_ia32_gathersiv4si (v4si, pcint,v4si,v4si,int)\n+v8si __builtin_ia32_gathersiv8si (v8si, pcint,v8si,v8si,int)\n+v4si __builtin_ia32_gatherdiv4si (v4si, pcint,v2di,v4si,int)\n+v4si __builtin_ia32_gatherdiv4si256 (v4si, pcint,v4di,v4si,int)\n+@end smallexample\n+\n The following built-in functions are available when @option{-maes} is\n used.  All of them generate the machine instruction that is part of the\n name."}]}