{"sha": "ede1820d2148b9bc41de2a22485b7608c9521eb2", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZWRlMTgyMGQyMTQ4YjliYzQxZGUyYTIyNDg1Yjc2MDhjOTUyMWViMg==", "commit": {"author": {"name": "liuhongt", "email": "hongtao.liu@intel.com", "date": "2019-03-21T03:25:58Z"}, "committer": {"name": "liuhongt", "email": "hongtao.liu@intel.com", "date": "2021-09-18T07:00:11Z"}, "message": "AVX512FP16: Add FP16 fma instructions.\n\nAdd vfmadd[132,213,231]ph/vfnmadd[132,213,231]ph/vfmsub[132,213,231]ph/\nvfnmsub[132,213,231]ph.\n\ngcc/ChangeLog:\n\n\t* config/i386/avx512fp16intrin.h (_mm512_mask_fmadd_ph):\n\tNew intrinsic.\n\t(_mm512_mask3_fmadd_ph): Likewise.\n\t(_mm512_maskz_fmadd_ph): Likewise.\n\t(_mm512_fmadd_round_ph): Likewise.\n\t(_mm512_mask_fmadd_round_ph): Likewise.\n\t(_mm512_mask3_fmadd_round_ph): Likewise.\n\t(_mm512_maskz_fmadd_round_ph): Likewise.\n\t(_mm512_fnmadd_ph): Likewise.\n\t(_mm512_mask_fnmadd_ph): Likewise.\n\t(_mm512_mask3_fnmadd_ph): Likewise.\n\t(_mm512_maskz_fnmadd_ph): Likewise.\n\t(_mm512_fnmadd_round_ph): Likewise.\n\t(_mm512_mask_fnmadd_round_ph): Likewise.\n\t(_mm512_mask3_fnmadd_round_ph): Likewise.\n\t(_mm512_maskz_fnmadd_round_ph): Likewise.\n\t(_mm512_fmsub_ph): Likewise.\n\t(_mm512_mask_fmsub_ph): Likewise.\n\t(_mm512_mask3_fmsub_ph): Likewise.\n\t(_mm512_maskz_fmsub_ph): Likewise.\n\t(_mm512_fmsub_round_ph): Likewise.\n\t(_mm512_mask_fmsub_round_ph): Likewise.\n\t(_mm512_mask3_fmsub_round_ph): Likewise.\n\t(_mm512_maskz_fmsub_round_ph): Likewise.\n\t(_mm512_fnmsub_ph): Likewise.\n\t(_mm512_mask_fnmsub_ph): Likewise.\n\t(_mm512_mask3_fnmsub_ph): Likewise.\n\t(_mm512_maskz_fnmsub_ph): Likewise.\n\t(_mm512_fnmsub_round_ph): Likewise.\n\t(_mm512_mask_fnmsub_round_ph): Likewise.\n\t(_mm512_mask3_fnmsub_round_ph): Likewise.\n\t(_mm512_maskz_fnmsub_round_ph): Likewise.\n\t* config/i386/avx512fp16vlintrin.h (_mm256_fmadd_ph):\n\tNew intrinsic.\n\t(_mm256_mask_fmadd_ph): Likewise.\n\t(_mm256_mask3_fmadd_ph): Likewise.\n\t(_mm256_maskz_fmadd_ph): Likewise.\n\t(_mm_fmadd_ph): Likewise.\n\t(_mm_mask_fmadd_ph): Likewise.\n\t(_mm_mask3_fmadd_ph): Likewise.\n\t(_mm_maskz_fmadd_ph): Likewise.\n\t(_mm256_fnmadd_ph): Likewise.\n\t(_mm256_mask_fnmadd_ph): Likewise.\n\t(_mm256_mask3_fnmadd_ph): Likewise.\n\t(_mm256_maskz_fnmadd_ph): Likewise.\n\t(_mm_fnmadd_ph): Likewise.\n\t(_mm_mask_fnmadd_ph): Likewise.\n\t(_mm_mask3_fnmadd_ph): Likewise.\n\t(_mm_maskz_fnmadd_ph): Likewise.\n\t(_mm256_fmsub_ph): Likewise.\n\t(_mm256_mask_fmsub_ph): Likewise.\n\t(_mm256_mask3_fmsub_ph): Likewise.\n\t(_mm256_maskz_fmsub_ph): Likewise.\n\t(_mm_fmsub_ph): Likewise.\n\t(_mm_mask_fmsub_ph): Likewise.\n\t(_mm_mask3_fmsub_ph): Likewise.\n\t(_mm_maskz_fmsub_ph): Likewise.\n\t(_mm256_fnmsub_ph): Likewise.\n\t(_mm256_mask_fnmsub_ph): Likewise.\n\t(_mm256_mask3_fnmsub_ph): Likewise.\n\t(_mm256_maskz_fnmsub_ph): Likewise.\n\t(_mm_fnmsub_ph): Likewise.\n\t(_mm_mask_fnmsub_ph): Likewise.\n\t(_mm_mask3_fnmsub_ph): Likewise.\n\t(_mm_maskz_fnmsub_ph): Likewise.\n\t* config/i386/i386-builtin.def: Add corresponding new builtins.\n\t* config/i386/sse.md\n\t(<avx512>_fmadd_<mode>_maskz<round_expand_name>): Adjust to\n\tsupport HF vector modes.\n\t(<sd_mask_codefor>fma_fmadd_<mode><sd_maskz_name><round_name>):\n\tDitto.\n\t(*<sd_mask_codefor>fma_fmadd_<mode><sd_maskz_name>_bcst_1): Ditto.\n\t(*<sd_mask_codefor>fma_fmadd_<mode><sd_maskz_name>_bcst_2): Ditto.\n\t(*<sd_mask_codefor>fma_fmadd_<mode><sd_maskz_name>_bcst_3): Ditto.\n\t(<avx512>_fmadd_<mode>_mask<round_name>): Ditto.\n\t(<avx512>_fmadd_<mode>_mask3<round_name>): Ditto.\n\t(<avx512>_fmsub_<mode>_maskz<round_expand_name>): Ditto.\n\t(<sd_mask_codefor>fma_fmsub_<mode><sd_maskz_name><round_name>):\n\tDitto.\n\t(*<sd_mask_codefor>fma_fmsub_<mode><sd_maskz_name>_bcst_1): Ditto.\n\t(*<sd_mask_codefor>fma_fmsub_<mode><sd_maskz_name>_bcst_2): Ditto.\n\t(*<sd_mask_codefor>fma_fmsub_<mode><sd_maskz_name>_bcst_3): Ditto.\n\t(<avx512>_fmsub_<mode>_mask<round_name>): Ditto.\n\t(<avx512>_fmsub_<mode>_mask3<round_name>): Ditto.\n\t(<sd_mask_codefor>fma_fnmadd_<mode><sd_maskz_name><round_name>):\n\tDitto.\n\t(*<sd_mask_codefor>fma_fnmadd_<mode><sd_maskz_name>_bcst_1): Ditto.\n\t(*<sd_mask_codefor>fma_fnmadd_<mode><sd_maskz_name>_bcst_2): Ditto.\n\t(*<sd_mask_codefor>fma_fnmadd_<mode><sd_maskz_name>_bcst_3): Ditto.\n\t(<avx512>_fnmadd_<mode>_mask<round_name>): Ditto.\n\t(<avx512>_fnmadd_<mode>_mask3<round_name>): Ditto.\n\t(<avx512>_fnmsub_<mode>_maskz<round_expand_name>): Ditto.\n\t(<sd_mask_codefor>fma_fnmsub_<mode><sd_maskz_name><round_name>):\n\tDitto.\n\t(*<sd_mask_codefor>fma_fnmsub_<mode><sd_maskz_name>_bcst_1): Ditto.\n\t(*<sd_mask_codefor>fma_fnmsub_<mode><sd_maskz_name>_bcst_2): Ditto.\n\t(*<sd_mask_codefor>fma_fnmsub_<mode><sd_maskz_name>_bcst_3): Ditto.\n\t(<avx512>_fnmsub_<mode>_mask<round_name>): Ditto.\n\t(<avx512>_fnmsub_<mode>_mask3<round_name>): Ditto.\n\ngcc/testsuite/ChangeLog:\n\n\t* gcc.target/i386/avx-1.c: Add test for new builtins.\n\t* gcc.target/i386/sse-13.c: Ditto.\n\t* gcc.target/i386/sse-23.c: Ditto.\n\t* gcc.target/i386/sse-14.c: Add test fot new intrinsics.\n\t* gcc.target/i386/sse-22.c: Ditto.", "tree": {"sha": "6b24e8ae809533708127bdc82a9344b5be0298f8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6b24e8ae809533708127bdc82a9344b5be0298f8"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ede1820d2148b9bc41de2a22485b7608c9521eb2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ede1820d2148b9bc41de2a22485b7608c9521eb2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ede1820d2148b9bc41de2a22485b7608c9521eb2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ede1820d2148b9bc41de2a22485b7608c9521eb2/comments", "author": {"login": "algebra84", "id": 22926165, "node_id": "MDQ6VXNlcjIyOTI2MTY1", "avatar_url": "https://avatars.githubusercontent.com/u/22926165?v=4", "gravatar_id": "", "url": "https://api.github.com/users/algebra84", "html_url": "https://github.com/algebra84", "followers_url": "https://api.github.com/users/algebra84/followers", "following_url": "https://api.github.com/users/algebra84/following{/other_user}", "gists_url": "https://api.github.com/users/algebra84/gists{/gist_id}", "starred_url": "https://api.github.com/users/algebra84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/algebra84/subscriptions", "organizations_url": "https://api.github.com/users/algebra84/orgs", "repos_url": "https://api.github.com/users/algebra84/repos", "events_url": "https://api.github.com/users/algebra84/events{/privacy}", "received_events_url": "https://api.github.com/users/algebra84/received_events", "type": "User", "site_admin": false}, "committer": {"login": "algebra84", "id": 22926165, "node_id": "MDQ6VXNlcjIyOTI2MTY1", "avatar_url": "https://avatars.githubusercontent.com/u/22926165?v=4", "gravatar_id": "", "url": "https://api.github.com/users/algebra84", "html_url": "https://github.com/algebra84", "followers_url": "https://api.github.com/users/algebra84/followers", "following_url": "https://api.github.com/users/algebra84/following{/other_user}", "gists_url": "https://api.github.com/users/algebra84/gists{/gist_id}", "starred_url": "https://api.github.com/users/algebra84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/algebra84/subscriptions", "organizations_url": "https://api.github.com/users/algebra84/orgs", "repos_url": "https://api.github.com/users/algebra84/repos", "events_url": "https://api.github.com/users/algebra84/events{/privacy}", "received_events_url": "https://api.github.com/users/algebra84/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b6c24eab08d9649b4229b4b0396ce91f97f88dfb", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b6c24eab08d9649b4229b4b0396ce91f97f88dfb", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b6c24eab08d9649b4229b4b0396ce91f97f88dfb"}], "stats": {"total": 1092, "additions": 996, "deletions": 96}, "files": [{"sha": "9ccbc463a4752325ef411c2a1f9cd2a28d6b32d9", "filename": "gcc/config/i386/avx512fp16intrin.h", "status": "modified", "additions": 432, "deletions": 0, "changes": 432, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Fconfig%2Fi386%2Favx512fp16intrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Fconfig%2Fi386%2Favx512fp16intrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512fp16intrin.h?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -5271,6 +5271,438 @@ _mm512_maskz_fmsubadd_round_ph (__mmask32 __U, __m512h __A, __m512h __B,\n \n #endif /* __OPTIMIZE__ */\n \n+/* Intrinsics vfmadd[132,213,231]ph.  */\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+  _mm512_fmadd_ph (__m512h __A, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfmaddph512_mask ((__v32hf) __A,\n+\t\t\t\t     (__v32hf) __B,\n+\t\t\t\t     (__v32hf) __C,\n+\t\t\t\t     (__mmask32) -1,\n+\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fmadd_ph (__m512h __A, __mmask32 __U, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfmaddph512_mask ((__v32hf) __A,\n+\t\t\t\t     (__v32hf) __B,\n+\t\t\t\t     (__v32hf) __C,\n+\t\t\t\t     (__mmask32) __U,\n+\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask3_fmadd_ph (__m512h __A, __m512h __B, __m512h __C, __mmask32 __U)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfmaddph512_mask3 ((__v32hf) __A,\n+\t\t\t\t      (__v32hf) __B,\n+\t\t\t\t      (__v32hf) __C,\n+\t\t\t\t      (__mmask32) __U,\n+\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_fmadd_ph (__mmask32 __U, __m512h __A, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfmaddph512_maskz ((__v32hf) __A,\n+\t\t\t\t      (__v32hf) __B,\n+\t\t\t\t      (__v32hf) __C,\n+\t\t\t\t      (__mmask32) __U,\n+\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fmadd_round_ph (__m512h __A, __m512h __B, __m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfmaddph512_mask ((__v32hf) __A,\n+\t\t\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t\t\t       (__mmask32) -1, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fmadd_round_ph (__m512h __A, __mmask32 __U, __m512h __B,\n+\t\t\t       __m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfmaddph512_mask ((__v32hf) __A,\n+\t\t\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t\t\t       (__mmask32) __U, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask3_fmadd_round_ph (__m512h __A, __m512h __B, __m512h __C,\n+\t\t\t\t__mmask32 __U, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfmaddph512_mask3 ((__v32hf) __A,\n+\t\t\t\t\t\t\t(__v32hf) __B,\n+\t\t\t\t\t\t\t(__v32hf) __C,\n+\t\t\t\t\t\t\t(__mmask32) __U, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_fmadd_round_ph (__mmask32 __U, __m512h __A, __m512h __B,\n+\t\t\t\t__m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfmaddph512_maskz ((__v32hf) __A,\n+\t\t\t\t\t\t\t(__v32hf) __B,\n+\t\t\t\t\t\t\t(__v32hf) __C,\n+\t\t\t\t\t\t\t(__mmask32) __U, __R);\n+}\n+\n+#else\n+#define _mm512_fmadd_round_ph(A, B, C, R)\t\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfmaddph512_mask ((A), (B), (C), -1, (R)))\n+\n+#define _mm512_mask_fmadd_round_ph(A, U, B, C, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfmaddph512_mask ((A), (B), (C), (U), (R)))\n+\n+#define _mm512_mask3_fmadd_round_ph(A, B, C, U, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfmaddph512_mask3 ((A), (B), (C), (U), (R)))\n+\n+#define _mm512_maskz_fmadd_round_ph(U, A, B, C, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfmaddph512_maskz ((A), (B), (C), (U), (R)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n+/* Intrinsics vfnmadd[132,213,231]ph.  */\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fnmadd_ph (__m512h __A, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfnmaddph512_mask ((__v32hf) __A,\n+\t\t\t\t      (__v32hf) __B,\n+\t\t\t\t      (__v32hf) __C,\n+\t\t\t\t      (__mmask32) -1,\n+\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fnmadd_ph (__m512h __A, __mmask32 __U, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfnmaddph512_mask ((__v32hf) __A,\n+\t\t\t\t      (__v32hf) __B,\n+\t\t\t\t      (__v32hf) __C,\n+\t\t\t\t      (__mmask32) __U,\n+\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask3_fnmadd_ph (__m512h __A, __m512h __B, __m512h __C, __mmask32 __U)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfnmaddph512_mask3 ((__v32hf) __A,\n+\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t       (__mmask32) __U,\n+\t\t\t\t       _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_fnmadd_ph (__mmask32 __U, __m512h __A, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfnmaddph512_maskz ((__v32hf) __A,\n+\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t       (__mmask32) __U,\n+\t\t\t\t       _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fnmadd_round_ph (__m512h __A, __m512h __B, __m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfnmaddph512_mask ((__v32hf) __A,\n+\t\t\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t\t\t       (__mmask32) -1, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fnmadd_round_ph (__m512h __A, __mmask32 __U, __m512h __B,\n+\t\t\t       __m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfnmaddph512_mask ((__v32hf) __A,\n+\t\t\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t\t\t       (__mmask32) __U, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask3_fnmadd_round_ph (__m512h __A, __m512h __B, __m512h __C,\n+\t\t\t\t__mmask32 __U, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfnmaddph512_mask3 ((__v32hf) __A,\n+\t\t\t\t\t\t\t(__v32hf) __B,\n+\t\t\t\t\t\t\t(__v32hf) __C,\n+\t\t\t\t\t\t\t(__mmask32) __U, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_fnmadd_round_ph (__mmask32 __U, __m512h __A, __m512h __B,\n+\t\t\t\t__m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfnmaddph512_maskz ((__v32hf) __A,\n+\t\t\t\t\t\t\t(__v32hf) __B,\n+\t\t\t\t\t\t\t(__v32hf) __C,\n+\t\t\t\t\t\t\t(__mmask32) __U, __R);\n+}\n+\n+#else\n+#define _mm512_fnmadd_round_ph(A, B, C, R)\t\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfnmaddph512_mask ((A), (B), (C), -1, (R)))\n+\n+#define _mm512_mask_fnmadd_round_ph(A, U, B, C, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfnmaddph512_mask ((A), (B), (C), (U), (R)))\n+\n+#define _mm512_mask3_fnmadd_round_ph(A, B, C, U, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfnmaddph512_mask3 ((A), (B), (C), (U), (R)))\n+\n+#define _mm512_maskz_fnmadd_round_ph(U, A, B, C, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfnmaddph512_maskz ((A), (B), (C), (U), (R)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n+/* Intrinsics vfmsub[132,213,231]ph.  */\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fmsub_ph (__m512h __A, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfmsubph512_mask ((__v32hf) __A,\n+\t\t\t\t     (__v32hf) __B,\n+\t\t\t\t     (__v32hf) __C,\n+\t\t\t\t     (__mmask32) -1,\n+\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fmsub_ph (__m512h __A, __mmask32 __U, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfmsubph512_mask ((__v32hf) __A,\n+\t\t\t\t     (__v32hf) __B,\n+\t\t\t\t     (__v32hf) __C,\n+\t\t\t\t     (__mmask32) __U,\n+\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask3_fmsub_ph (__m512h __A, __m512h __B, __m512h __C, __mmask32 __U)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfmsubph512_mask3 ((__v32hf) __A,\n+\t\t\t\t      (__v32hf) __B,\n+\t\t\t\t      (__v32hf) __C,\n+\t\t\t\t      (__mmask32) __U,\n+\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_fmsub_ph (__mmask32 __U, __m512h __A, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfmsubph512_maskz ((__v32hf) __A,\n+\t\t\t\t      (__v32hf) __B,\n+\t\t\t\t      (__v32hf) __C,\n+\t\t\t\t      (__mmask32) __U,\n+\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fmsub_round_ph (__m512h __A, __m512h __B, __m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfmsubph512_mask ((__v32hf) __A,\n+\t\t\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t\t\t       (__mmask32) -1, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fmsub_round_ph (__m512h __A, __mmask32 __U, __m512h __B,\n+\t\t\t       __m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfmsubph512_mask ((__v32hf) __A,\n+\t\t\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t\t\t       (__mmask32) __U, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask3_fmsub_round_ph (__m512h __A, __m512h __B, __m512h __C,\n+\t\t\t\t__mmask32 __U, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfmsubph512_mask3 ((__v32hf) __A,\n+\t\t\t\t\t\t\t(__v32hf) __B,\n+\t\t\t\t\t\t\t(__v32hf) __C,\n+\t\t\t\t\t\t\t(__mmask32) __U, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_fmsub_round_ph (__mmask32 __U, __m512h __A, __m512h __B,\n+\t\t\t\t__m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfmsubph512_maskz ((__v32hf) __A,\n+\t\t\t\t\t\t\t(__v32hf) __B,\n+\t\t\t\t\t\t\t(__v32hf) __C,\n+\t\t\t\t\t\t\t(__mmask32) __U, __R);\n+}\n+\n+#else\n+#define _mm512_fmsub_round_ph(A, B, C, R)\t\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfmsubph512_mask ((A), (B), (C), -1, (R)))\n+\n+#define _mm512_mask_fmsub_round_ph(A, U, B, C, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfmsubph512_mask ((A), (B), (C), (U), (R)))\n+\n+#define _mm512_mask3_fmsub_round_ph(A, B, C, U, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfmsubph512_mask3 ((A), (B), (C), (U), (R)))\n+\n+#define _mm512_maskz_fmsub_round_ph(U, A, B, C, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfmsubph512_maskz ((A), (B), (C), (U), (R)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n+/* Intrinsics vfnmsub[132,213,231]ph.  */\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fnmsub_ph (__m512h __A, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfnmsubph512_mask ((__v32hf) __A,\n+\t\t\t\t      (__v32hf) __B,\n+\t\t\t\t      (__v32hf) __C,\n+\t\t\t\t      (__mmask32) -1,\n+\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fnmsub_ph (__m512h __A, __mmask32 __U, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfnmsubph512_mask ((__v32hf) __A,\n+\t\t\t\t      (__v32hf) __B,\n+\t\t\t\t      (__v32hf) __C,\n+\t\t\t\t      (__mmask32) __U,\n+\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask3_fnmsub_ph (__m512h __A, __m512h __B, __m512h __C, __mmask32 __U)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfnmsubph512_mask3 ((__v32hf) __A,\n+\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t       (__mmask32) __U,\n+\t\t\t\t       _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_fnmsub_ph (__mmask32 __U, __m512h __A, __m512h __B, __m512h __C)\n+{\n+  return (__m512h)\n+    __builtin_ia32_vfnmsubph512_maskz ((__v32hf) __A,\n+\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t       (__mmask32) __U,\n+\t\t\t\t       _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_fnmsub_round_ph (__m512h __A, __m512h __B, __m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfnmsubph512_mask ((__v32hf) __A,\n+\t\t\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t\t\t       (__mmask32) -1, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_fnmsub_round_ph (__m512h __A, __mmask32 __U, __m512h __B,\n+\t\t\t       __m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfnmsubph512_mask ((__v32hf) __A,\n+\t\t\t\t\t\t       (__v32hf) __B,\n+\t\t\t\t\t\t       (__v32hf) __C,\n+\t\t\t\t\t\t       (__mmask32) __U, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask3_fnmsub_round_ph (__m512h __A, __m512h __B, __m512h __C,\n+\t\t\t\t__mmask32 __U, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfnmsubph512_mask3 ((__v32hf) __A,\n+\t\t\t\t\t\t\t(__v32hf) __B,\n+\t\t\t\t\t\t\t(__v32hf) __C,\n+\t\t\t\t\t\t\t(__mmask32) __U, __R);\n+}\n+\n+extern __inline __m512h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_fnmsub_round_ph (__mmask32 __U, __m512h __A, __m512h __B,\n+\t\t\t\t__m512h __C, const int __R)\n+{\n+  return (__m512h) __builtin_ia32_vfnmsubph512_maskz ((__v32hf) __A,\n+\t\t\t\t\t\t\t(__v32hf) __B,\n+\t\t\t\t\t\t\t(__v32hf) __C,\n+\t\t\t\t\t\t\t(__mmask32) __U, __R);\n+}\n+\n+#else\n+#define _mm512_fnmsub_round_ph(A, B, C, R)\t\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfnmsubph512_mask ((A), (B), (C), -1, (R)))\n+\n+#define _mm512_mask_fnmsub_round_ph(A, U, B, C, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfnmsubph512_mask ((A), (B), (C), (U), (R)))\n+\n+#define _mm512_mask3_fnmsub_round_ph(A, B, C, U, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfnmsubph512_mask3 ((A), (B), (C), (U), (R)))\n+\n+#define _mm512_maskz_fnmsub_round_ph(U, A, B, C, R)\t\t\t\\\n+  ((__m512h)__builtin_ia32_vfnmsubph512_maskz ((A), (B), (C), (U), (R)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n #ifdef __DISABLE_AVX512FP16__\n #undef __DISABLE_AVX512FP16__\n #pragma GCC pop_options"}, {"sha": "1292c02a4dc442e2605173fc150a1170bf2668ba", "filename": "gcc/config/i386/avx512fp16vlintrin.h", "status": "modified", "additions": 364, "deletions": 0, "changes": 364, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Fconfig%2Fi386%2Favx512fp16vlintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Fconfig%2Fi386%2Favx512fp16vlintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512fp16vlintrin.h?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -2451,6 +2451,370 @@ _mm_maskz_fmsubadd_ph (__mmask8 __U, __m128h __A, __m128h __B,\n \t\t\t\t\t\t\t__U);\n }\n \n+/* Intrinsics vfmadd[132,213,231]ph.  */\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_fmadd_ph (__m256h __A, __m256h __B, __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfmaddph256_mask ((__v16hf) __A,\n+\t\t\t\t\t\t       (__v16hf) __B,\n+\t\t\t\t\t\t       (__v16hf) __C,\n+\t\t\t\t\t\t       (__mmask16) -1);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_fmadd_ph (__m256h __A, __mmask16 __U, __m256h __B,\n+\t\t\t __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfmaddph256_mask ((__v16hf) __A,\n+\t\t\t\t\t\t       (__v16hf) __B,\n+\t\t\t\t\t\t       (__v16hf) __C,\n+\t\t\t\t\t\t       (__mmask16) __U);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask3_fmadd_ph (__m256h __A, __m256h __B, __m256h __C,\n+\t\t\t  __mmask16 __U)\n+{\n+  return (__m256h) __builtin_ia32_vfmaddph256_mask3 ((__v16hf) __A,\n+\t\t\t\t\t\t\t(__v16hf) __B,\n+\t\t\t\t\t\t\t(__v16hf) __C,\n+\t\t\t\t\t\t\t(__mmask16)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_fmadd_ph (__mmask16 __U, __m256h __A, __m256h __B,\n+\t\t\t  __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfmaddph256_maskz ((__v16hf) __A,\n+\t\t\t\t\t\t\t(__v16hf) __B,\n+\t\t\t\t\t\t\t(__v16hf) __C,\n+\t\t\t\t\t\t\t(__mmask16)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_fmadd_ph (__m128h __A, __m128h __B, __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfmaddph128_mask ((__v8hf) __A,\n+\t\t\t\t\t\t       (__v8hf) __B,\n+\t\t\t\t\t\t       (__v8hf) __C,\n+\t\t\t\t\t\t       (__mmask8) -1);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_fmadd_ph (__m128h __A, __mmask8 __U, __m128h __B,\n+\t\t      __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfmaddph128_mask ((__v8hf) __A,\n+\t\t\t\t\t\t       (__v8hf) __B,\n+\t\t\t\t\t\t       (__v8hf) __C,\n+\t\t\t\t\t\t       (__mmask8) __U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask3_fmadd_ph (__m128h __A, __m128h __B, __m128h __C,\n+\t\t       __mmask8 __U)\n+{\n+  return (__m128h) __builtin_ia32_vfmaddph128_mask3 ((__v8hf) __A,\n+\t\t\t\t\t\t\t(__v8hf) __B,\n+\t\t\t\t\t\t\t(__v8hf) __C,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_fmadd_ph (__mmask8 __U, __m128h __A, __m128h __B,\n+\t\t       __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfmaddph128_maskz ((__v8hf) __A,\n+\t\t\t\t\t\t\t(__v8hf) __B,\n+\t\t\t\t\t\t\t(__v8hf) __C,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+/* Intrinsics vfnmadd[132,213,231]ph.  */\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_fnmadd_ph (__m256h __A, __m256h __B, __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfnmaddph256_mask ((__v16hf) __A,\n+\t\t\t\t\t\t       (__v16hf) __B,\n+\t\t\t\t\t\t       (__v16hf) __C,\n+\t\t\t\t\t\t       (__mmask16) -1);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_fnmadd_ph (__m256h __A, __mmask16 __U, __m256h __B,\n+\t\t\t __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfnmaddph256_mask ((__v16hf) __A,\n+\t\t\t\t\t\t       (__v16hf) __B,\n+\t\t\t\t\t\t       (__v16hf) __C,\n+\t\t\t\t\t\t       (__mmask16) __U);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask3_fnmadd_ph (__m256h __A, __m256h __B, __m256h __C,\n+\t\t\t  __mmask16 __U)\n+{\n+  return (__m256h) __builtin_ia32_vfnmaddph256_mask3 ((__v16hf) __A,\n+\t\t\t\t\t\t\t(__v16hf) __B,\n+\t\t\t\t\t\t\t(__v16hf) __C,\n+\t\t\t\t\t\t\t(__mmask16)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_fnmadd_ph (__mmask16 __U, __m256h __A, __m256h __B,\n+\t\t\t  __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfnmaddph256_maskz ((__v16hf) __A,\n+\t\t\t\t\t\t\t(__v16hf) __B,\n+\t\t\t\t\t\t\t(__v16hf) __C,\n+\t\t\t\t\t\t\t(__mmask16)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_fnmadd_ph (__m128h __A, __m128h __B, __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfnmaddph128_mask ((__v8hf) __A,\n+\t\t\t\t\t\t       (__v8hf) __B,\n+\t\t\t\t\t\t       (__v8hf) __C,\n+\t\t\t\t\t\t       (__mmask8) -1);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_fnmadd_ph (__m128h __A, __mmask8 __U, __m128h __B,\n+\t\t      __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfnmaddph128_mask ((__v8hf) __A,\n+\t\t\t\t\t\t       (__v8hf) __B,\n+\t\t\t\t\t\t       (__v8hf) __C,\n+\t\t\t\t\t\t       (__mmask8) __U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask3_fnmadd_ph (__m128h __A, __m128h __B, __m128h __C,\n+\t\t       __mmask8 __U)\n+{\n+  return (__m128h) __builtin_ia32_vfnmaddph128_mask3 ((__v8hf) __A,\n+\t\t\t\t\t\t\t(__v8hf) __B,\n+\t\t\t\t\t\t\t(__v8hf) __C,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_fnmadd_ph (__mmask8 __U, __m128h __A, __m128h __B,\n+\t\t       __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfnmaddph128_maskz ((__v8hf) __A,\n+\t\t\t\t\t\t\t(__v8hf) __B,\n+\t\t\t\t\t\t\t(__v8hf) __C,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+/* Intrinsics vfmsub[132,213,231]ph.  */\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_fmsub_ph (__m256h __A, __m256h __B, __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfmsubph256_mask ((__v16hf) __A,\n+\t\t\t\t\t\t       (__v16hf) __B,\n+\t\t\t\t\t\t       (__v16hf) __C,\n+\t\t\t\t\t\t       (__mmask16) -1);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_fmsub_ph (__m256h __A, __mmask16 __U, __m256h __B,\n+\t\t\t __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfmsubph256_mask ((__v16hf) __A,\n+\t\t\t\t\t\t       (__v16hf) __B,\n+\t\t\t\t\t\t       (__v16hf) __C,\n+\t\t\t\t\t\t       (__mmask16) __U);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask3_fmsub_ph (__m256h __A, __m256h __B, __m256h __C,\n+\t\t\t  __mmask16 __U)\n+{\n+  return (__m256h) __builtin_ia32_vfmsubph256_mask3 ((__v16hf) __A,\n+\t\t\t\t\t\t\t(__v16hf) __B,\n+\t\t\t\t\t\t\t(__v16hf) __C,\n+\t\t\t\t\t\t\t(__mmask16)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_fmsub_ph (__mmask16 __U, __m256h __A, __m256h __B,\n+\t\t\t  __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfmsubph256_maskz ((__v16hf) __A,\n+\t\t\t\t\t\t\t(__v16hf) __B,\n+\t\t\t\t\t\t\t(__v16hf) __C,\n+\t\t\t\t\t\t\t(__mmask16)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_fmsub_ph (__m128h __A, __m128h __B, __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfmsubph128_mask ((__v8hf) __A,\n+\t\t\t\t\t\t       (__v8hf) __B,\n+\t\t\t\t\t\t       (__v8hf) __C,\n+\t\t\t\t\t\t       (__mmask8) -1);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_fmsub_ph (__m128h __A, __mmask8 __U, __m128h __B,\n+\t\t      __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfmsubph128_mask ((__v8hf) __A,\n+\t\t\t\t\t\t       (__v8hf) __B,\n+\t\t\t\t\t\t       (__v8hf) __C,\n+\t\t\t\t\t\t       (__mmask8) __U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask3_fmsub_ph (__m128h __A, __m128h __B, __m128h __C,\n+\t\t       __mmask8 __U)\n+{\n+  return (__m128h) __builtin_ia32_vfmsubph128_mask3 ((__v8hf) __A,\n+\t\t\t\t\t\t\t(__v8hf) __B,\n+\t\t\t\t\t\t\t(__v8hf) __C,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_fmsub_ph (__mmask8 __U, __m128h __A, __m128h __B,\n+\t\t       __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfmsubph128_maskz ((__v8hf) __A,\n+\t\t\t\t\t\t\t(__v8hf) __B,\n+\t\t\t\t\t\t\t(__v8hf) __C,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+/* Intrinsics vfnmsub[132,213,231]ph.  */\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_fnmsub_ph (__m256h __A, __m256h __B, __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfnmsubph256_mask ((__v16hf) __A,\n+\t\t\t\t\t\t       (__v16hf) __B,\n+\t\t\t\t\t\t       (__v16hf) __C,\n+\t\t\t\t\t\t       (__mmask16) -1);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_fnmsub_ph (__m256h __A, __mmask16 __U, __m256h __B,\n+\t\t\t __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfnmsubph256_mask ((__v16hf) __A,\n+\t\t\t\t\t\t       (__v16hf) __B,\n+\t\t\t\t\t\t       (__v16hf) __C,\n+\t\t\t\t\t\t       (__mmask16) __U);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask3_fnmsub_ph (__m256h __A, __m256h __B, __m256h __C,\n+\t\t\t  __mmask16 __U)\n+{\n+  return (__m256h) __builtin_ia32_vfnmsubph256_mask3 ((__v16hf) __A,\n+\t\t\t\t\t\t\t(__v16hf) __B,\n+\t\t\t\t\t\t\t(__v16hf) __C,\n+\t\t\t\t\t\t\t(__mmask16)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m256h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_fnmsub_ph (__mmask16 __U, __m256h __A, __m256h __B,\n+\t\t\t  __m256h __C)\n+{\n+  return (__m256h) __builtin_ia32_vfnmsubph256_maskz ((__v16hf) __A,\n+\t\t\t\t\t\t\t(__v16hf) __B,\n+\t\t\t\t\t\t\t(__v16hf) __C,\n+\t\t\t\t\t\t\t(__mmask16)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_fnmsub_ph (__m128h __A, __m128h __B, __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfnmsubph128_mask ((__v8hf) __A,\n+\t\t\t\t\t\t       (__v8hf) __B,\n+\t\t\t\t\t\t       (__v8hf) __C,\n+\t\t\t\t\t\t       (__mmask8) -1);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_fnmsub_ph (__m128h __A, __mmask8 __U, __m128h __B,\n+\t\t      __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfnmsubph128_mask ((__v8hf) __A,\n+\t\t\t\t\t\t       (__v8hf) __B,\n+\t\t\t\t\t\t       (__v8hf) __C,\n+\t\t\t\t\t\t       (__mmask8) __U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask3_fnmsub_ph (__m128h __A, __m128h __B, __m128h __C,\n+\t\t       __mmask8 __U)\n+{\n+  return (__m128h) __builtin_ia32_vfnmsubph128_mask3 ((__v8hf) __A,\n+\t\t\t\t\t\t\t(__v8hf) __B,\n+\t\t\t\t\t\t\t(__v8hf) __C,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n+extern __inline __m128h\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_fnmsub_ph (__mmask8 __U, __m128h __A, __m128h __B,\n+\t\t       __m128h __C)\n+{\n+  return (__m128h) __builtin_ia32_vfnmsubph128_maskz ((__v8hf) __A,\n+\t\t\t\t\t\t\t(__v8hf) __B,\n+\t\t\t\t\t\t\t(__v8hf) __C,\n+\t\t\t\t\t\t\t(__mmask8)\n+\t\t\t\t\t\t\t__U);\n+}\n+\n #ifdef __DISABLE_AVX512FP16VL__\n #undef __DISABLE_AVX512FP16VL__\n #pragma GCC pop_options"}, {"sha": "56d23b02658c9c83b1cfa2f19018faadad484b46", "filename": "gcc/config/i386/i386-builtin.def", "status": "modified", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Fconfig%2Fi386%2Fi386-builtin.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Fconfig%2Fi386%2Fi386-builtin.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-builtin.def?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -2887,6 +2887,30 @@ BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_\n BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmsubadd_v8hf_mask, \"__builtin_ia32_vfmsubaddph128_mask\", IX86_BUILTIN_VFMSUBADDPH128_MASK, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmsubadd_v8hf_mask3, \"__builtin_ia32_vfmsubaddph128_mask3\", IX86_BUILTIN_VFMSUBADDPH128_MASK3, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmsubadd_v8hf_maskz, \"__builtin_ia32_vfmsubaddph128_maskz\", IX86_BUILTIN_VFMSUBADDPH128_MASKZ, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fmadd_v16hf_mask, \"__builtin_ia32_vfmaddph256_mask\", IX86_BUILTIN_VFMADDPH256_MASK, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fmadd_v16hf_mask3, \"__builtin_ia32_vfmaddph256_mask3\", IX86_BUILTIN_VFMADDPH256_MASK3, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fmadd_v16hf_maskz, \"__builtin_ia32_vfmaddph256_maskz\", IX86_BUILTIN_VFMADDPH256_MASKZ, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmadd_v8hf_mask, \"__builtin_ia32_vfmaddph128_mask\", IX86_BUILTIN_VFMADDPH128_MASK, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmadd_v8hf_mask3, \"__builtin_ia32_vfmaddph128_mask3\", IX86_BUILTIN_VFMADDPH128_MASK3, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmadd_v8hf_maskz, \"__builtin_ia32_vfmaddph128_maskz\", IX86_BUILTIN_VFMADDPH128_MASKZ, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fnmadd_v16hf_mask, \"__builtin_ia32_vfnmaddph256_mask\", IX86_BUILTIN_VFNMADDPH256_MASK, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fnmadd_v16hf_mask3, \"__builtin_ia32_vfnmaddph256_mask3\", IX86_BUILTIN_VFNMADDPH256_MASK3, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fnmadd_v16hf_maskz, \"__builtin_ia32_vfnmaddph256_maskz\", IX86_BUILTIN_VFNMADDPH256_MASKZ, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fnmadd_v8hf_mask, \"__builtin_ia32_vfnmaddph128_mask\", IX86_BUILTIN_VFNMADDPH128_MASK, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fnmadd_v8hf_mask3, \"__builtin_ia32_vfnmaddph128_mask3\", IX86_BUILTIN_VFNMADDPH128_MASK3, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fnmadd_v8hf_maskz, \"__builtin_ia32_vfnmaddph128_maskz\", IX86_BUILTIN_VFNMADDPH128_MASKZ, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fmsub_v16hf_mask, \"__builtin_ia32_vfmsubph256_mask\", IX86_BUILTIN_VFMSUBPH256_MASK, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fmsub_v16hf_mask3, \"__builtin_ia32_vfmsubph256_mask3\", IX86_BUILTIN_VFMSUBPH256_MASK3, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fmsub_v16hf_maskz, \"__builtin_ia32_vfmsubph256_maskz\", IX86_BUILTIN_VFMSUBPH256_MASKZ, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmsub_v8hf_mask, \"__builtin_ia32_vfmsubph128_mask\", IX86_BUILTIN_VFMSUBPH128_MASK, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmsub_v8hf_mask3, \"__builtin_ia32_vfmsubph128_mask3\", IX86_BUILTIN_VFMSUBPH128_MASK3, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fmsub_v8hf_maskz, \"__builtin_ia32_vfmsubph128_maskz\", IX86_BUILTIN_VFMSUBPH128_MASKZ, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fnmsub_v16hf_mask, \"__builtin_ia32_vfnmsubph256_mask\", IX86_BUILTIN_VFNMSUBPH256_MASK, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fnmsub_v16hf_mask3, \"__builtin_ia32_vfnmsubph256_mask3\", IX86_BUILTIN_VFNMSUBPH256_MASK3, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_fnmsub_v16hf_maskz, \"__builtin_ia32_vfnmsubph256_maskz\", IX86_BUILTIN_VFNMSUBPH256_MASKZ, UNKNOWN, (int) V16HF_FTYPE_V16HF_V16HF_V16HF_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fnmsub_v8hf_mask, \"__builtin_ia32_vfnmsubph128_mask\", IX86_BUILTIN_VFNMSUBPH128_MASK, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fnmsub_v8hf_mask3, \"__builtin_ia32_vfnmsubph128_mask3\", IX86_BUILTIN_VFNMSUBPH128_MASK3, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_fnmsub_v8hf_maskz, \"__builtin_ia32_vfnmsubph128_maskz\", IX86_BUILTIN_VFNMSUBPH128_MASKZ, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n \n /* Builtins with rounding support.  */\n BDESC_END (ARGS, ROUND_ARGS)\n@@ -3158,6 +3182,18 @@ BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmaddsub_v32hf_maskz_ro\n BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmsubadd_v32hf_mask_round, \"__builtin_ia32_vfmsubaddph512_mask\", IX86_BUILTIN_VFMSUBADDPH512_MASK, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmsubadd_v32hf_mask3_round, \"__builtin_ia32_vfmsubaddph512_mask3\", IX86_BUILTIN_VFMSUBADDPH512_MASK3, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmsubadd_v32hf_maskz_round, \"__builtin_ia32_vfmsubaddph512_maskz\", IX86_BUILTIN_VFMSUBADDPH512_MASKZ, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmadd_v32hf_mask_round, \"__builtin_ia32_vfmaddph512_mask\", IX86_BUILTIN_VFMADDPH512_MASK, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmadd_v32hf_mask3_round, \"__builtin_ia32_vfmaddph512_mask3\", IX86_BUILTIN_VFMADDPH512_MASK3, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmadd_v32hf_maskz_round, \"__builtin_ia32_vfmaddph512_maskz\", IX86_BUILTIN_VFMADDPH512_MASKZ, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fnmadd_v32hf_mask_round, \"__builtin_ia32_vfnmaddph512_mask\", IX86_BUILTIN_VFNMADDPH512_MASK, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fnmadd_v32hf_mask3_round, \"__builtin_ia32_vfnmaddph512_mask3\", IX86_BUILTIN_VFNMADDPH512_MASK3, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fnmadd_v32hf_maskz_round, \"__builtin_ia32_vfnmaddph512_maskz\", IX86_BUILTIN_VFNMADDPH512_MASKZ, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmsub_v32hf_mask_round, \"__builtin_ia32_vfmsubph512_mask\", IX86_BUILTIN_VFMSUBPH512_MASK, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmsub_v32hf_mask3_round, \"__builtin_ia32_vfmsubph512_mask3\", IX86_BUILTIN_VFMSUBPH512_MASK3, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fmsub_v32hf_maskz_round, \"__builtin_ia32_vfmsubph512_maskz\", IX86_BUILTIN_VFMSUBPH512_MASKZ, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fnmsub_v32hf_mask_round, \"__builtin_ia32_vfnmsubph512_mask\", IX86_BUILTIN_VFNMSUBPH512_MASK, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fnmsub_v32hf_mask3_round, \"__builtin_ia32_vfnmsubph512_mask3\", IX86_BUILTIN_VFNMSUBPH512_MASK3, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_fnmsub_v32hf_maskz_round, \"__builtin_ia32_vfnmsubph512_maskz\", IX86_BUILTIN_VFNMSUBPH512_MASKZ, UNKNOWN, (int) V32HF_FTYPE_V32HF_V32HF_V32HF_USI_INT)\n \n BDESC_END (ROUND_ARGS, MULTI_ARG)\n "}, {"sha": "baf464214b1dc8c284846656e5c70b9ed725b083", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 96, "deletions": 96, "changes": 192, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -4689,10 +4689,10 @@\n \t    (match_operand:FMAMODE_AVX512 3 \"nonimmediate_operand\"))))])\n \n (define_expand \"<avx512>_fmadd_<mode>_maskz<round_expand_name>\"\n-  [(match_operand:VF_AVX512VL 0 \"register_operand\")\n-   (match_operand:VF_AVX512VL 1 \"<round_expand_nimm_predicate>\")\n-   (match_operand:VF_AVX512VL 2 \"<round_expand_nimm_predicate>\")\n-   (match_operand:VF_AVX512VL 3 \"<round_expand_nimm_predicate>\")\n+  [(match_operand:VFH_AVX512VL 0 \"register_operand\")\n+   (match_operand:VFH_AVX512VL 1 \"<round_expand_nimm_predicate>\")\n+   (match_operand:VFH_AVX512VL 2 \"<round_expand_nimm_predicate>\")\n+   (match_operand:VFH_AVX512VL 3 \"<round_expand_nimm_predicate>\")\n    (match_operand:<avx512fmaskmode> 4 \"register_operand\")]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n {\n@@ -4732,11 +4732,11 @@\n    DF V8DF (V4DF \"TARGET_AVX512VL\") (V2DF \"TARGET_AVX512VL\")])\n \n (define_insn \"<sd_mask_codefor>fma_fmadd_<mode><sd_maskz_name><round_name>\"\n-  [(set (match_operand:VF_SF_AVX512VL 0 \"register_operand\" \"=v,v,v\")\n-\t(fma:VF_SF_AVX512VL\n-\t  (match_operand:VF_SF_AVX512VL 1 \"<bcst_round_nimm_predicate>\" \"%0,0,v\")\n-\t  (match_operand:VF_SF_AVX512VL 2 \"<bcst_round_nimm_predicate>\" \"<bcst_round_constraint>,v,<bcst_round_constraint>\")\n-\t  (match_operand:VF_SF_AVX512VL 3 \"<bcst_round_nimm_predicate>\" \"v,<bcst_round_constraint>,0\")))]\n+  [(set (match_operand:VFH_SF_AVX512VL 0 \"register_operand\" \"=v,v,v\")\n+\t(fma:VFH_SF_AVX512VL\n+\t  (match_operand:VFH_SF_AVX512VL 1 \"<bcst_round_nimm_predicate>\" \"%0,0,v\")\n+\t  (match_operand:VFH_SF_AVX512VL 2 \"<bcst_round_nimm_predicate>\" \"<bcst_round_constraint>,v,<bcst_round_constraint>\")\n+\t  (match_operand:VFH_SF_AVX512VL 3 \"<bcst_round_nimm_predicate>\" \"v,<bcst_round_constraint>,0\")))]\n   \"TARGET_AVX512F && <sd_mask_mode512bit_condition> && <round_mode512bit_condition>\"\n   \"@\n    vfmadd132<ssemodesuffix>\\t{<round_sd_mask_op4>%2, %3, %0<sd_mask_op4>|%0<sd_mask_op4>, %3, %2<round_sd_mask_op4>}\n@@ -4769,12 +4769,12 @@\n })\n \n (define_insn \"<avx512>_fmadd_<mode>_mask<round_name>\"\n-  [(set (match_operand:VF_AVX512VL 0 \"register_operand\" \"=v,v\")\n-\t(vec_merge:VF_AVX512VL\n-\t  (fma:VF_AVX512VL\n-\t    (match_operand:VF_AVX512VL 1 \"register_operand\" \"0,0\")\n-\t    (match_operand:VF_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>,v\")\n-\t    (match_operand:VF_AVX512VL 3 \"<round_nimm_predicate>\" \"v,<round_constraint>\"))\n+  [(set (match_operand:VFH_AVX512VL 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VFH_AVX512VL\n+\t  (fma:VFH_AVX512VL\n+\t    (match_operand:VFH_AVX512VL 1 \"register_operand\" \"0,0\")\n+\t    (match_operand:VFH_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>,v\")\n+\t    (match_operand:VFH_AVX512VL 3 \"<round_nimm_predicate>\" \"v,<round_constraint>\"))\n \t  (match_dup 1)\n \t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"Yk,Yk\")))]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n@@ -4785,12 +4785,12 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<avx512>_fmadd_<mode>_mask3<round_name>\"\n-  [(set (match_operand:VF_AVX512VL 0 \"register_operand\" \"=v\")\n-\t(vec_merge:VF_AVX512VL\n-\t  (fma:VF_AVX512VL\n-\t    (match_operand:VF_AVX512VL 1 \"<round_nimm_predicate>\" \"%v\")\n-\t    (match_operand:VF_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>\")\n-\t    (match_operand:VF_AVX512VL 3 \"register_operand\" \"0\"))\n+  [(set (match_operand:VFH_AVX512VL 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VFH_AVX512VL\n+\t  (fma:VFH_AVX512VL\n+\t    (match_operand:VFH_AVX512VL 1 \"<round_nimm_predicate>\" \"%v\")\n+\t    (match_operand:VFH_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>\")\n+\t    (match_operand:VFH_AVX512VL 3 \"register_operand\" \"0\"))\n \t  (match_dup 3)\n \t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"Yk\")))]\n   \"TARGET_AVX512F\"\n@@ -4817,10 +4817,10 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_expand \"<avx512>_fmsub_<mode>_maskz<round_expand_name>\"\n-  [(match_operand:VF_AVX512VL 0 \"register_operand\")\n-   (match_operand:VF_AVX512VL 1 \"<round_expand_nimm_predicate>\")\n-   (match_operand:VF_AVX512VL 2 \"<round_expand_nimm_predicate>\")\n-   (match_operand:VF_AVX512VL 3 \"<round_expand_nimm_predicate>\")\n+  [(match_operand:VFH_AVX512VL 0 \"register_operand\")\n+   (match_operand:VFH_AVX512VL 1 \"<round_expand_nimm_predicate>\")\n+   (match_operand:VFH_AVX512VL 2 \"<round_expand_nimm_predicate>\")\n+   (match_operand:VFH_AVX512VL 3 \"<round_expand_nimm_predicate>\")\n    (match_operand:<avx512fmaskmode> 4 \"register_operand\")]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n {\n@@ -4831,12 +4831,12 @@\n })\n \n (define_insn \"<sd_mask_codefor>fma_fmsub_<mode><sd_maskz_name><round_name>\"\n-  [(set (match_operand:VF_SF_AVX512VL 0 \"register_operand\" \"=v,v,v\")\n-\t(fma:VF_SF_AVX512VL\n-\t  (match_operand:VF_SF_AVX512VL   1 \"<bcst_round_nimm_predicate>\" \"%0,0,v\")\n-\t  (match_operand:VF_SF_AVX512VL   2 \"<bcst_round_nimm_predicate>\" \"<bcst_round_constraint>,v,<bcst_round_constraint>\")\n-\t  (neg:VF_SF_AVX512VL\n-\t    (match_operand:VF_SF_AVX512VL 3 \"<bcst_round_nimm_predicate>\" \"v,<bcst_round_constraint>,0\"))))]\n+  [(set (match_operand:VFH_SF_AVX512VL 0 \"register_operand\" \"=v,v,v\")\n+\t(fma:VFH_SF_AVX512VL\n+\t  (match_operand:VFH_SF_AVX512VL   1 \"<bcst_round_nimm_predicate>\" \"%0,0,v\")\n+\t  (match_operand:VFH_SF_AVX512VL   2 \"<bcst_round_nimm_predicate>\" \"<bcst_round_constraint>,v,<bcst_round_constraint>\")\n+\t  (neg:VFH_SF_AVX512VL\n+\t    (match_operand:VFH_SF_AVX512VL 3 \"<bcst_round_nimm_predicate>\" \"v,<bcst_round_constraint>,0\"))))]\n   \"TARGET_AVX512F && <sd_mask_mode512bit_condition> && <round_mode512bit_condition>\"\n   \"@\n    vfmsub132<ssemodesuffix>\\t{<round_sd_mask_op4>%2, %3, %0<sd_mask_op4>|%0<sd_mask_op4>, %3, %2<round_sd_mask_op4>}\n@@ -4870,13 +4870,13 @@\n })\n \n (define_insn \"<avx512>_fmsub_<mode>_mask<round_name>\"\n-  [(set (match_operand:VF_AVX512VL 0 \"register_operand\" \"=v,v\")\n-\t(vec_merge:VF_AVX512VL\n-\t  (fma:VF_AVX512VL\n-\t    (match_operand:VF_AVX512VL 1 \"register_operand\" \"0,0\")\n-\t    (match_operand:VF_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>,v\")\n-\t    (neg:VF_AVX512VL\n-\t      (match_operand:VF_AVX512VL 3 \"<round_nimm_predicate>\" \"v,<round_constraint>\")))\n+  [(set (match_operand:VFH_AVX512VL 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VFH_AVX512VL\n+\t  (fma:VFH_AVX512VL\n+\t    (match_operand:VFH_AVX512VL 1 \"register_operand\" \"0,0\")\n+\t    (match_operand:VFH_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>,v\")\n+\t    (neg:VFH_AVX512VL\n+\t      (match_operand:VFH_AVX512VL 3 \"<round_nimm_predicate>\" \"v,<round_constraint>\")))\n \t  (match_dup 1)\n \t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"Yk,Yk\")))]\n   \"TARGET_AVX512F\"\n@@ -4887,13 +4887,13 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<avx512>_fmsub_<mode>_mask3<round_name>\"\n-  [(set (match_operand:VF_AVX512VL 0 \"register_operand\" \"=v\")\n-\t(vec_merge:VF_AVX512VL\n-\t  (fma:VF_AVX512VL\n-\t    (match_operand:VF_AVX512VL 1 \"<round_nimm_predicate>\" \"%v\")\n-\t    (match_operand:VF_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>\")\n-\t    (neg:VF_AVX512VL\n-\t      (match_operand:VF_AVX512VL 3 \"register_operand\" \"0\")))\n+  [(set (match_operand:VFH_AVX512VL 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VFH_AVX512VL\n+\t  (fma:VFH_AVX512VL\n+\t    (match_operand:VFH_AVX512VL 1 \"<round_nimm_predicate>\" \"%v\")\n+\t    (match_operand:VFH_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>\")\n+\t    (neg:VFH_AVX512VL\n+\t      (match_operand:VFH_AVX512VL 3 \"register_operand\" \"0\")))\n \t  (match_dup 3)\n \t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"Yk\")))]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n@@ -4920,10 +4920,10 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_expand \"<avx512>_fnmadd_<mode>_maskz<round_expand_name>\"\n-  [(match_operand:VF_AVX512VL 0 \"register_operand\")\n-   (match_operand:VF_AVX512VL 1 \"<round_expand_nimm_predicate>\")\n-   (match_operand:VF_AVX512VL 2 \"<round_expand_nimm_predicate>\")\n-   (match_operand:VF_AVX512VL 3 \"<round_expand_nimm_predicate>\")\n+  [(match_operand:VFH_AVX512VL 0 \"register_operand\")\n+   (match_operand:VFH_AVX512VL 1 \"<round_expand_nimm_predicate>\")\n+   (match_operand:VFH_AVX512VL 2 \"<round_expand_nimm_predicate>\")\n+   (match_operand:VFH_AVX512VL 3 \"<round_expand_nimm_predicate>\")\n    (match_operand:<avx512fmaskmode> 4 \"register_operand\")]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n {\n@@ -4934,12 +4934,12 @@\n })\n \n (define_insn \"<sd_mask_codefor>fma_fnmadd_<mode><sd_maskz_name><round_name>\"\n-  [(set (match_operand:VF_SF_AVX512VL 0 \"register_operand\" \"=v,v,v\")\n-\t(fma:VF_SF_AVX512VL\n-\t  (neg:VF_SF_AVX512VL\n-\t    (match_operand:VF_SF_AVX512VL 1 \"<bcst_round_nimm_predicate>\" \"%0,0,v\"))\n-\t  (match_operand:VF_SF_AVX512VL   2 \"<bcst_round_nimm_predicate>\" \"<bcst_round_constraint>,v,<bcst_round_constraint>\")\n-\t  (match_operand:VF_SF_AVX512VL   3 \"<bcst_round_nimm_predicate>\" \"v,<bcst_round_constraint>,0\")))]\n+  [(set (match_operand:VFH_SF_AVX512VL 0 \"register_operand\" \"=v,v,v\")\n+\t(fma:VFH_SF_AVX512VL\n+\t  (neg:VFH_SF_AVX512VL\n+\t    (match_operand:VFH_SF_AVX512VL 1 \"<bcst_round_nimm_predicate>\" \"%0,0,v\"))\n+\t  (match_operand:VFH_SF_AVX512VL   2 \"<bcst_round_nimm_predicate>\" \"<bcst_round_constraint>,v,<bcst_round_constraint>\")\n+\t  (match_operand:VFH_SF_AVX512VL   3 \"<bcst_round_nimm_predicate>\" \"v,<bcst_round_constraint>,0\")))]\n   \"TARGET_AVX512F && <sd_mask_mode512bit_condition> && <round_mode512bit_condition>\"\n   \"@\n    vfnmadd132<ssemodesuffix>\\t{<round_sd_mask_op4>%2, %3, %0<sd_mask_op4>|%0<sd_mask_op4>, %3, %2<round_sd_mask_op4>}\n@@ -4973,13 +4973,13 @@\n })\n \n (define_insn \"<avx512>_fnmadd_<mode>_mask<round_name>\"\n-  [(set (match_operand:VF_AVX512VL 0 \"register_operand\" \"=v,v\")\n-\t(vec_merge:VF_AVX512VL\n-\t  (fma:VF_AVX512VL\n-\t    (neg:VF_AVX512VL\n-\t      (match_operand:VF_AVX512VL 1 \"register_operand\" \"0,0\"))\n-\t    (match_operand:VF_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>,v\")\n-\t    (match_operand:VF_AVX512VL 3 \"<round_nimm_predicate>\" \"v,<round_constraint>\"))\n+  [(set (match_operand:VFH_AVX512VL 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VFH_AVX512VL\n+\t  (fma:VFH_AVX512VL\n+\t    (neg:VFH_AVX512VL\n+\t      (match_operand:VFH_AVX512VL 1 \"register_operand\" \"0,0\"))\n+\t    (match_operand:VFH_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>,v\")\n+\t    (match_operand:VFH_AVX512VL 3 \"<round_nimm_predicate>\" \"v,<round_constraint>\"))\n \t  (match_dup 1)\n \t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"Yk,Yk\")))]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n@@ -4990,13 +4990,13 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<avx512>_fnmadd_<mode>_mask3<round_name>\"\n-  [(set (match_operand:VF_AVX512VL 0 \"register_operand\" \"=v\")\n-\t(vec_merge:VF_AVX512VL\n-\t  (fma:VF_AVX512VL\n-\t    (neg:VF_AVX512VL\n-\t      (match_operand:VF_AVX512VL 1 \"<round_nimm_predicate>\" \"%v\"))\n-\t    (match_operand:VF_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>\")\n-\t    (match_operand:VF_AVX512VL 3 \"register_operand\" \"0\"))\n+  [(set (match_operand:VFH_AVX512VL 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VFH_AVX512VL\n+\t  (fma:VFH_AVX512VL\n+\t    (neg:VFH_AVX512VL\n+\t      (match_operand:VFH_AVX512VL 1 \"<round_nimm_predicate>\" \"%v\"))\n+\t    (match_operand:VFH_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>\")\n+\t    (match_operand:VFH_AVX512VL 3 \"register_operand\" \"0\"))\n \t  (match_dup 3)\n \t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"Yk\")))]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n@@ -5024,10 +5024,10 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_expand \"<avx512>_fnmsub_<mode>_maskz<round_expand_name>\"\n-  [(match_operand:VF_AVX512VL 0 \"register_operand\")\n-   (match_operand:VF_AVX512VL 1 \"<round_expand_nimm_predicate>\")\n-   (match_operand:VF_AVX512VL 2 \"<round_expand_nimm_predicate>\")\n-   (match_operand:VF_AVX512VL 3 \"<round_expand_nimm_predicate>\")\n+  [(match_operand:VFH_AVX512VL 0 \"register_operand\")\n+   (match_operand:VFH_AVX512VL 1 \"<round_expand_nimm_predicate>\")\n+   (match_operand:VFH_AVX512VL 2 \"<round_expand_nimm_predicate>\")\n+   (match_operand:VFH_AVX512VL 3 \"<round_expand_nimm_predicate>\")\n    (match_operand:<avx512fmaskmode> 4 \"register_operand\")]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n {\n@@ -5038,13 +5038,13 @@\n })\n \n (define_insn \"<sd_mask_codefor>fma_fnmsub_<mode><sd_maskz_name><round_name>\"\n-  [(set (match_operand:VF_SF_AVX512VL 0 \"register_operand\" \"=v,v,v\")\n-\t(fma:VF_SF_AVX512VL\n-\t  (neg:VF_SF_AVX512VL\n-\t    (match_operand:VF_SF_AVX512VL 1 \"<bcst_round_nimm_predicate>\" \"%0,0,v\"))\n-\t  (match_operand:VF_SF_AVX512VL 2 \"<bcst_round_nimm_predicate>\" \"<bcst_round_constraint>,v,<bcst_round_constraint>\")\n-\t  (neg:VF_SF_AVX512VL\n-\t    (match_operand:VF_SF_AVX512VL 3 \"<bcst_round_nimm_predicate>\" \"v,<bcst_round_constraint>,0\"))))]\n+  [(set (match_operand:VFH_SF_AVX512VL 0 \"register_operand\" \"=v,v,v\")\n+\t(fma:VFH_SF_AVX512VL\n+\t  (neg:VFH_SF_AVX512VL\n+\t    (match_operand:VFH_SF_AVX512VL 1 \"<bcst_round_nimm_predicate>\" \"%0,0,v\"))\n+\t  (match_operand:VFH_SF_AVX512VL 2 \"<bcst_round_nimm_predicate>\" \"<bcst_round_constraint>,v,<bcst_round_constraint>\")\n+\t  (neg:VFH_SF_AVX512VL\n+\t    (match_operand:VFH_SF_AVX512VL 3 \"<bcst_round_nimm_predicate>\" \"v,<bcst_round_constraint>,0\"))))]\n   \"TARGET_AVX512F && <sd_mask_mode512bit_condition> && <round_mode512bit_condition>\"\n   \"@\n    vfnmsub132<ssemodesuffix>\\t{<round_sd_mask_op4>%2, %3, %0<sd_mask_op4>|%0<sd_mask_op4>, %3, %2<round_sd_mask_op4>}\n@@ -5079,14 +5079,14 @@\n })\n \n (define_insn \"<avx512>_fnmsub_<mode>_mask<round_name>\"\n-  [(set (match_operand:VF_AVX512VL 0 \"register_operand\" \"=v,v\")\n-\t(vec_merge:VF_AVX512VL\n-\t  (fma:VF_AVX512VL\n-\t    (neg:VF_AVX512VL\n-\t      (match_operand:VF_AVX512VL 1 \"register_operand\" \"0,0\"))\n-\t    (match_operand:VF_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>,v\")\n-\t    (neg:VF_AVX512VL\n-\t      (match_operand:VF_AVX512VL 3 \"<round_nimm_predicate>\" \"v,<round_constraint>\")))\n+  [(set (match_operand:VFH_AVX512VL 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VFH_AVX512VL\n+\t  (fma:VFH_AVX512VL\n+\t    (neg:VFH_AVX512VL\n+\t      (match_operand:VFH_AVX512VL 1 \"register_operand\" \"0,0\"))\n+\t    (match_operand:VFH_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>,v\")\n+\t    (neg:VFH_AVX512VL\n+\t      (match_operand:VFH_AVX512VL 3 \"<round_nimm_predicate>\" \"v,<round_constraint>\")))\n \t  (match_dup 1)\n \t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"Yk,Yk\")))]\n   \"TARGET_AVX512F && <round_mode512bit_condition>\"\n@@ -5097,14 +5097,14 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<avx512>_fnmsub_<mode>_mask3<round_name>\"\n-  [(set (match_operand:VF_AVX512VL 0 \"register_operand\" \"=v\")\n-\t(vec_merge:VF_AVX512VL\n-\t  (fma:VF_AVX512VL\n-\t    (neg:VF_AVX512VL\n-\t      (match_operand:VF_AVX512VL 1 \"<round_nimm_predicate>\" \"%v\"))\n-\t    (match_operand:VF_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>\")\n-\t    (neg:VF_AVX512VL\n-\t      (match_operand:VF_AVX512VL 3 \"register_operand\" \"0\")))\n+  [(set (match_operand:VFH_AVX512VL 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VFH_AVX512VL\n+\t  (fma:VFH_AVX512VL\n+\t    (neg:VFH_AVX512VL\n+\t      (match_operand:VFH_AVX512VL 1 \"<round_nimm_predicate>\" \"%v\"))\n+\t    (match_operand:VFH_AVX512VL 2 \"<round_nimm_predicate>\" \"<round_constraint>\")\n+\t    (neg:VFH_AVX512VL\n+\t      (match_operand:VFH_AVX512VL 3 \"register_operand\" \"0\")))\n \t  (match_dup 3)\n \t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"Yk\")))]\n   \"TARGET_AVX512F\""}, {"sha": "8e2428a2476d01ec0d399f9a4500411b3952feab", "filename": "gcc/testsuite/gcc.target/i386/avx-1.c", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx-1.c?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -763,6 +763,18 @@\n #define __builtin_ia32_vfmsubaddph512_mask(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_mask(A, B, C, D, 8)\n #define __builtin_ia32_vfmsubaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_mask3(A, B, C, D, 8)\n #define __builtin_ia32_vfmsubaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_mask(A, B, C, D, E) __builtin_ia32_vfmaddph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfmaddph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfmaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_mask(A, B, C, D, E) __builtin_ia32_vfnmaddph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfnmaddph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfnmaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_mask(A, B, C, D, E) __builtin_ia32_vfmsubph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_mask3(A, B, C, D, E) __builtin_ia32_vfmsubph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_maskz(A, B, C, D, E) __builtin_ia32_vfmsubph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_mask(A, B, C, D, E) __builtin_ia32_vfnmsubph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_mask3(A, B, C, D, E) __builtin_ia32_vfnmsubph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_maskz(A, B, C, D, E) __builtin_ia32_vfnmsubph512_maskz(A, B, C, D, 8)\n \n /* avx512fp16vlintrin.h */\n #define __builtin_ia32_cmpph128_mask(A, B, C, D) __builtin_ia32_cmpph128_mask(A, B, 1, D)"}, {"sha": "7f4b2a3b28587f38d5322a17ad5cc24587d5818a", "filename": "gcc/testsuite/gcc.target/i386/sse-13.c", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -780,6 +780,18 @@\n #define __builtin_ia32_vfmsubaddph512_mask(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_mask(A, B, C, D, 8)\n #define __builtin_ia32_vfmsubaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_mask3(A, B, C, D, 8)\n #define __builtin_ia32_vfmsubaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_mask(A, B, C, D, E) __builtin_ia32_vfmaddph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfmaddph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfmaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_mask(A, B, C, D, E) __builtin_ia32_vfnmaddph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfnmaddph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfnmaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_mask(A, B, C, D, E) __builtin_ia32_vfmsubph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_mask3(A, B, C, D, E) __builtin_ia32_vfmsubph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_maskz(A, B, C, D, E) __builtin_ia32_vfmsubph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_mask(A, B, C, D, E) __builtin_ia32_vfnmsubph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_mask3(A, B, C, D, E) __builtin_ia32_vfnmsubph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_maskz(A, B, C, D, E) __builtin_ia32_vfnmsubph512_maskz(A, B, C, D, 8)\n \n /* avx512fp16vlintrin.h */\n #define __builtin_ia32_cmpph128_mask(A, B, C, D) __builtin_ia32_cmpph128_mask(A, B, 1, D)"}, {"sha": "9151e50afd2ba720c5388253e3260e1f30a6ec9b", "filename": "gcc/testsuite/gcc.target/i386/sse-14.c", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -838,6 +838,10 @@ test_3 (_mm_maskz_cvt_roundss_sh, __m128h, __mmask8, __m128h, __m128, 8)\n test_3 (_mm_maskz_cvt_roundsd_sh, __m128h, __mmask8, __m128h, __m128d, 8)\n test_3 (_mm512_fmaddsub_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n test_3 (_mm512_fmsubadd_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n+test_3 (_mm512_fmadd_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n+test_3 (_mm512_fnmadd_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n+test_3 (_mm512_fmsub_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n+test_3 (_mm512_fnmsub_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n test_3x (_mm512_mask_cmp_round_ph_mask, __mmask32, __mmask32, __m512h, __m512h, 1, 8)\n test_3x (_mm_mask_cmp_round_sh_mask, __mmask8, __mmask8, __m128h, __m128h, 1, 8)\n test_3x (_mm512_mask_reduce_round_ph, __m512h, __m512h, __mmask32, __m512h, 123, 8)\n@@ -876,6 +880,18 @@ test_4 (_mm512_maskz_fmaddsub_round_ph, __m512h, __mmask32, __m512h, __m512h, __\n test_4 (_mm512_mask3_fmsubadd_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n test_4 (_mm512_mask_fmsubadd_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n test_4 (_mm512_maskz_fmsubadd_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n+test_4 (_mm512_mask_fmadd_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n+test_4 (_mm512_mask3_fmadd_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n+test_4 (_mm512_maskz_fmadd_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n+test_4 (_mm512_mask_fnmadd_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n+test_4 (_mm512_mask3_fnmadd_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n+test_4 (_mm512_maskz_fnmadd_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n+test_4 (_mm512_mask_fmsub_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n+test_4 (_mm512_mask3_fmsub_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n+test_4 (_mm512_maskz_fmsub_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n+test_4 (_mm512_mask_fnmsub_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n+test_4 (_mm512_mask3_fnmsub_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n+test_4 (_mm512_maskz_fnmsub_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n test_4x (_mm_mask_reduce_round_sh, __m128h, __m128h, __mmask8, __m128h, __m128h, 123, 8)\n test_4x (_mm_mask_roundscale_round_sh, __m128h, __m128h, __mmask8, __m128h, __m128h, 123, 8)\n test_4x (_mm_mask_getmant_sh, __m128h, __m128h, __mmask8, __m128h, __m128h, 1, 1)"}, {"sha": "892b6334ae2dc29e8061b802224a87ab18c8cfa9", "filename": "gcc/testsuite/gcc.target/i386/sse-22.c", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-22.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-22.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-22.c?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -941,6 +941,10 @@ test_3 (_mm_maskz_cvt_roundss_sh, __m128h, __mmask8, __m128h, __m128, 8)\n test_3 (_mm_maskz_cvt_roundsd_sh, __m128h, __mmask8, __m128h, __m128d, 8)\n test_3 (_mm512_fmaddsub_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n test_3 (_mm512_fmsubadd_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n+test_3 (_mm512_fmadd_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n+test_3 (_mm512_fnmadd_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n+test_3 (_mm512_fmsub_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n+test_3 (_mm512_fnmsub_round_ph, __m512h, __m512h, __m512h, __m512h, 9)\n test_3x (_mm512_mask_cmp_round_ph_mask, __mmask32, __mmask32, __m512h, __m512h, 1, 8)\n test_3x (_mm_mask_cmp_round_sh_mask, __mmask8, __mmask8, __m128h, __m128h, 1, 8)\n test_3x (_mm512_mask_reduce_round_ph, __m512h, __m512h, __mmask32, __m512h, 123, 8)\n@@ -978,6 +982,18 @@ test_4 (_mm512_maskz_fmaddsub_round_ph, __m512h, __mmask32, __m512h, __m512h, __\n test_4 (_mm512_mask3_fmsubadd_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n test_4 (_mm512_mask_fmsubadd_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n test_4 (_mm512_maskz_fmsubadd_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n+test_4 (_mm512_mask_fmadd_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n+test_4 (_mm512_mask3_fmadd_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n+test_4 (_mm512_maskz_fmadd_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n+test_4 (_mm512_mask_fnmadd_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n+test_4 (_mm512_mask3_fnmadd_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n+test_4 (_mm512_maskz_fnmadd_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n+test_4 (_mm512_mask_fmsub_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n+test_4 (_mm512_mask3_fmsub_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n+test_4 (_mm512_maskz_fmsub_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n+test_4 (_mm512_mask_fnmsub_round_ph, __m512h, __m512h, __mmask32, __m512h, __m512h, 9)\n+test_4 (_mm512_mask3_fnmsub_round_ph, __m512h, __m512h, __m512h, __m512h, __mmask32, 9)\n+test_4 (_mm512_maskz_fnmsub_round_ph, __m512h, __mmask32, __m512h, __m512h, __m512h, 9)\n test_4x (_mm_mask_reduce_round_sh, __m128h, __m128h, __mmask8, __m128h, __m128h, 123, 8)\n test_4x (_mm_mask_roundscale_round_sh, __m128h, __m128h, __mmask8, __m128h, __m128h, 123, 8)\n test_4x (_mm_mask_getmant_sh, __m128h, __m128h, __mmask8, __m128h, __m128h, 1, 1)"}, {"sha": "2eb5a649fe43fded6d3cd80754d55eb35746c121", "filename": "gcc/testsuite/gcc.target/i386/sse-23.c", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-23.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ede1820d2148b9bc41de2a22485b7608c9521eb2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-23.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-23.c?ref=ede1820d2148b9bc41de2a22485b7608c9521eb2", "patch": "@@ -781,6 +781,18 @@\n #define __builtin_ia32_vfmsubaddph512_mask(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_mask(A, B, C, D, 8)\n #define __builtin_ia32_vfmsubaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_mask3(A, B, C, D, 8)\n #define __builtin_ia32_vfmsubaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfmsubaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_mask(A, B, C, D, E) __builtin_ia32_vfmaddph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfmaddph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfmaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfmaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_mask(A, B, C, D, E) __builtin_ia32_vfnmaddph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_mask3(A, B, C, D, E) __builtin_ia32_vfnmaddph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmaddph512_maskz(A, B, C, D, E) __builtin_ia32_vfnmaddph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_mask(A, B, C, D, E) __builtin_ia32_vfmsubph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_mask3(A, B, C, D, E) __builtin_ia32_vfmsubph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfmsubph512_maskz(A, B, C, D, E) __builtin_ia32_vfmsubph512_maskz(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_mask(A, B, C, D, E) __builtin_ia32_vfnmsubph512_mask(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_mask3(A, B, C, D, E) __builtin_ia32_vfnmsubph512_mask3(A, B, C, D, 8)\n+#define __builtin_ia32_vfnmsubph512_maskz(A, B, C, D, E) __builtin_ia32_vfnmsubph512_maskz(A, B, C, D, 8)\n \n /* avx512fp16vlintrin.h */\n #define __builtin_ia32_cmpph128_mask(A, B, C, D) __builtin_ia32_cmpph128_mask(A, B, 1, D)"}]}