{"sha": "df0f21028edd919421080f52a99a9b400ba8ba08", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZGYwZjIxMDI4ZWRkOTE5NDIxMDgwZjUyYTk5YTliNDAwYmE4YmEwOA==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2020-01-09T16:24:15Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2020-01-09T16:24:15Z"}, "message": "[AArch64] Add banner comments to aarch64-sve2.md\n\nThis patch imposes the same sort of structure on aarch64-sve2.md\nas we already have for aarch64-sve.md, before it grows a lot more\npatterns.\n\n2020-01-09  Richard Sandiford  <richard.sandiford@arm.com>\n\ngcc/\n\t* config/aarch64/aarch64-sve2.md: Add banner comments.\n\t(<su>mulh<r>s<mode>3): Move further up file.\n\t(<su>mull<bt><Vwide>, <r>shrnb<mode>, <r>shrnt<mode>)\n\t(*aarch64_sve2_sra<mode>): Move further down file.\n\t* config/aarch64/t-aarch64 (s-check-sve-md): Check aarch64-sve2.md too.\n\nFrom-SVN: r280058", "tree": {"sha": "1d08c4f3f797c7b2df94f375b1137f4ad3816eb3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1d08c4f3f797c7b2df94f375b1137f4ad3816eb3"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/df0f21028edd919421080f52a99a9b400ba8ba08", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/df0f21028edd919421080f52a99a9b400ba8ba08", "html_url": "https://github.com/Rust-GCC/gccrs/commit/df0f21028edd919421080f52a99a9b400ba8ba08", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/df0f21028edd919421080f52a99a9b400ba8ba08/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "c1b10d6d4954aef8ce52c3729bef6dd2b800c20c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c1b10d6d4954aef8ce52c3729bef6dd2b800c20c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c1b10d6d4954aef8ce52c3729bef6dd2b800c20c"}], "stats": {"total": 273, "additions": 194, "deletions": 79}, "files": [{"sha": "8910d8622bf2269e76eeaf4855ba5a777a000f40", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/df0f21028edd919421080f52a99a9b400ba8ba08/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/df0f21028edd919421080f52a99a9b400ba8ba08/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=df0f21028edd919421080f52a99a9b400ba8ba08", "patch": "@@ -1,3 +1,11 @@\n+2020-01-09  Richard Sandiford  <richard.sandiford@arm.com>\n+\n+\t* config/aarch64/aarch64-sve2.md: Add banner comments.\n+\t(<su>mulh<r>s<mode>3): Move further up file.\n+\t(<su>mull<bt><Vwide>, <r>shrnb<mode>, <r>shrnt<mode>)\n+\t(*aarch64_sve2_sra<mode>): Move further down file.\n+\t* config/aarch64/t-aarch64 (s-check-sve-md): Check aarch64-sve2.md too.\n+\n 2020-01-09  Richard Sandiford  <richard.sandiford@arm.com>\n \n \t* config/aarch64/iterators.md (SVE_WHILE): Add UNSPEC_WHILERW"}, {"sha": "1b2b6b2959b90ad9c2b15ecdf99c1546946b79c7", "filename": "gcc/config/aarch64/aarch64-sve2.md", "status": "modified", "additions": 182, "deletions": 78, "changes": 260, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/df0f21028edd919421080f52a99a9b400ba8ba08/gcc%2Fconfig%2Faarch64%2Faarch64-sve2.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/df0f21028edd919421080f52a99a9b400ba8ba08/gcc%2Fconfig%2Faarch64%2Faarch64-sve2.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-sve2.md?ref=df0f21028edd919421080f52a99a9b400ba8ba08", "patch": "@@ -18,6 +18,75 @@\n ;; along with GCC; see the file COPYING3.  If not see\n ;; <http://www.gnu.org/licenses/>.\n \n+;; The file is organised into the following sections (search for the full\n+;; line):\n+;;\n+;; == Uniform binary arithmnetic\n+;; ---- [INT] Scaled high-part multiplication\n+;; ---- [INT] General binary arithmetic that maps to unspecs\n+;;\n+;; == Uniform ternary arithmnetic\n+;; ---- [INT] Ternary logic operations\n+;; ---- [INT] Shift-and-accumulate operations\n+;;\n+;; == Extending arithmetic\n+;; ---- [INT] Long binary arithmetic\n+;;\n+;; == Narrowing arithnetic\n+;; ---- [INT] Narrowing right shifts\n+;;\n+;; == General\n+;; ---- Check for aliases between pointers\n+\n+;; =========================================================================\n+;; == Uniform binary arithmnetic\n+;; =========================================================================\n+\n+;; -------------------------------------------------------------------------\n+;; ---- [INT] Scaled high-part multiplication\n+;; -------------------------------------------------------------------------\n+;; The patterns in this section are synthetic.\n+;; -------------------------------------------------------------------------\n+\n+;; Unpredicated integer multiply-high-with-(round-and-)scale.\n+(define_expand \"<su>mulh<r>s<mode>3\"\n+  [(set (match_operand:SVE_FULL_BHSI 0 \"register_operand\")\n+\t(unspec:SVE_FULL_BHSI\n+\t  [(match_dup 3)\n+\t   (unspec:SVE_FULL_BHSI\n+\t     [(match_operand:SVE_FULL_BHSI 1 \"register_operand\")\n+\t      (match_operand:SVE_FULL_BHSI 2 \"register_operand\")]\n+\t     MULHRS)]\n+\t  UNSPEC_PRED_X))]\n+  \"TARGET_SVE2\"\n+  {\n+    operands[3] = aarch64_ptrue_reg (<VPRED>mode);\n+\n+    rtx prod_b = gen_reg_rtx (<VWIDE>mode);\n+    rtx prod_t = gen_reg_rtx (<VWIDE>mode);\n+    emit_insn (gen_<su>mullb<Vwide> (prod_b, operands[1], operands[2]));\n+    emit_insn (gen_<su>mullt<Vwide> (prod_t, operands[1], operands[2]));\n+\n+    rtx shift = GEN_INT (GET_MODE_UNIT_BITSIZE (<MODE>mode) - 1);\n+    emit_insn (gen_<r>shrnb<mode> (operands[0], prod_b, shift));\n+    emit_insn (gen_<r>shrnt<mode> (operands[0], operands[0], prod_t, shift));\n+\n+    DONE;\n+  }\n+)\n+\n+;; -------------------------------------------------------------------------\n+;; ---- [INT] General binary arithmetic that maps to unspecs\n+;; -------------------------------------------------------------------------\n+;; Includes:\n+;; - SHADD\n+;; - SHSUB\n+;; - SRHADD\n+;; - UHADD\n+;; - UHSUB\n+;; - URHADD\n+;; -------------------------------------------------------------------------\n+\n ;; Integer average (floor).\n (define_expand \"<u>avg<mode>3_floor\"\n   [(set (match_operand:SVE_FULL_I 0 \"register_operand\")\n@@ -67,85 +136,20 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n-;; Multiply long top / bottom.\n-(define_insn \"<su>mull<bt><Vwide>\"\n-  [(set (match_operand:<VWIDE> 0 \"register_operand\" \"=w\")\n-\t(unspec:<VWIDE>\n-\t  [(match_operand:SVE_FULL_BHSI 1 \"register_operand\" \"w\")\n-\t   (match_operand:SVE_FULL_BHSI 2 \"register_operand\" \"w\")]\n-\t  MULLBT))]\n-  \"TARGET_SVE2\"\n-  \"<su>mull<bt>\\t%0.<Vewtype>, %1.<Vetype>, %2.<Vetype>\"\n-)\n-\n-;; (Rounding) Right shift narrow bottom.\n-(define_insn \"<r>shrnb<mode>\"\n-  [(set (match_operand:SVE_FULL_BHSI 0 \"register_operand\" \"=w\")\n-        (unspec:SVE_FULL_BHSI\n-\t  [(match_operand:<VWIDE> 1 \"register_operand\" \"w\")\n-\t   (match_operand 2 \"aarch64_simd_shift_imm_offset_<Vel>\" \"\")]\n-\t  SHRNB))]\n-  \"TARGET_SVE2\"\n-  \"<r>shrnb\\t%0.<Vetype>, %1.<Vewtype>, #%2\"\n-)\n-\n-;; (Rounding) Right shift narrow top.\n-(define_insn \"<r>shrnt<mode>\"\n-  [(set (match_operand:SVE_FULL_BHSI 0 \"register_operand\" \"=w\")\n-\t(unspec:SVE_FULL_BHSI\n-\t  [(match_operand:SVE_FULL_BHSI 1 \"register_operand\" \"0\")\n-\t   (match_operand:<VWIDE> 2 \"register_operand\" \"w\")\n-\t   (match_operand 3 \"aarch64_simd_shift_imm_offset_<Vel>\" \"i\")]\n-\t  SHRNT))]\n-  \"TARGET_SVE2\"\n-  \"<r>shrnt\\t%0.<Vetype>, %2.<Vewtype>, #%3\"\n-)\n-\n-;; Unpredicated integer multiply-high-with-(round-and-)scale.\n-(define_expand \"<su>mulh<r>s<mode>3\"\n-  [(set (match_operand:SVE_FULL_BHSI 0 \"register_operand\")\n-\t(unspec:SVE_FULL_BHSI\n-\t  [(match_dup 3)\n-\t   (unspec:SVE_FULL_BHSI\n-\t     [(match_operand:SVE_FULL_BHSI 1 \"register_operand\")\n-\t      (match_operand:SVE_FULL_BHSI 2 \"register_operand\")]\n-\t     MULHRS)]\n-\t  UNSPEC_PRED_X))]\n-  \"TARGET_SVE2\"\n-  {\n-    operands[3] = aarch64_ptrue_reg (<VPRED>mode);\n-\n-    rtx prod_b = gen_reg_rtx (<VWIDE>mode);\n-    rtx prod_t = gen_reg_rtx (<VWIDE>mode);\n-    emit_insn (gen_<su>mullb<Vwide> (prod_b, operands[1], operands[2]));\n-    emit_insn (gen_<su>mullt<Vwide> (prod_t, operands[1], operands[2]));\n-\n-    rtx shift = GEN_INT (GET_MODE_UNIT_BITSIZE (<MODE>mode) - 1);\n-    emit_insn (gen_<r>shrnb<mode> (operands[0], prod_b, shift));\n-    emit_insn (gen_<r>shrnt<mode> (operands[0], operands[0], prod_t, shift));\n+;; =========================================================================\n+;; == Uniform ternary arithmnetic\n+;; =========================================================================\n \n-    DONE;\n-  }\n-)\n-\n-;; Unpredicated signed / unsigned shift-right accumulate.\n-(define_insn_and_rewrite \"*aarch64_sve2_sra<mode>\"\n-  [(set (match_operand:SVE_FULL_I 0 \"register_operand\" \"=w\")\n-\t(plus:SVE_FULL_I\n-\t  (unspec:SVE_FULL_I\n-\t    [(match_operand 4)\n-\t     (SHIFTRT:SVE_FULL_I\n-\t       (match_operand:SVE_FULL_I 2 \"register_operand\" \"w\")\n-\t       (match_operand:SVE_FULL_I 3 \"aarch64_simd_rshift_imm\" \"Dr\"))]\n-\t    UNSPEC_PRED_X)\n-\t (match_operand:SVE_FULL_I 1 \"register_operand\" \"0\")))]\n-  \"TARGET_SVE2\"\n-  \"<sra_op>sra\\t%0.<Vetype>, %2.<Vetype>, #%3\"\n-  \"&& !CONSTANT_P (operands[4])\"\n-  {\n-    operands[4] = CONSTM1_RTX (<VPRED>mode);\n-  }\n-)\n+;; -------------------------------------------------------------------------\n+;; ---- [INT] Ternary logic operations\n+;; -------------------------------------------------------------------------\n+;; Includes:\n+;; - BSL\n+;; - BSL1N\n+;; - BSL2N\n+;; - EOR3\n+;; - NBSL\n+;; -------------------------------------------------------------------------\n \n ;; Unpredicated 3-way exclusive OR.\n (define_insn \"*aarch64_sve2_eor3<mode>\"\n@@ -332,6 +336,106 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+;; -------------------------------------------------------------------------\n+;; ---- [INT] Shift-and-accumulate operations\n+;; -------------------------------------------------------------------------\n+;; Includes:\n+;; - SSRA\n+;; - USRA\n+;; -------------------------------------------------------------------------\n+\n+;; Unpredicated signed / unsigned shift-right accumulate.\n+(define_insn_and_rewrite \"*aarch64_sve2_sra<mode>\"\n+  [(set (match_operand:SVE_FULL_I 0 \"register_operand\" \"=w\")\n+\t(plus:SVE_FULL_I\n+\t  (unspec:SVE_FULL_I\n+\t    [(match_operand 4)\n+\t     (SHIFTRT:SVE_FULL_I\n+\t       (match_operand:SVE_FULL_I 2 \"register_operand\" \"w\")\n+\t       (match_operand:SVE_FULL_I 3 \"aarch64_simd_rshift_imm\" \"Dr\"))]\n+\t    UNSPEC_PRED_X)\n+\t (match_operand:SVE_FULL_I 1 \"register_operand\" \"0\")))]\n+  \"TARGET_SVE2\"\n+  \"<sra_op>sra\\t%0.<Vetype>, %2.<Vetype>, #%3\"\n+  \"&& !CONSTANT_P (operands[4])\"\n+  {\n+    operands[4] = CONSTM1_RTX (<VPRED>mode);\n+  }\n+)\n+\n+;; =========================================================================\n+;; == Extending arithmetic\n+;; =========================================================================\n+\n+;; -------------------------------------------------------------------------\n+;; ---- [INT] Long binary arithmetic\n+;; -------------------------------------------------------------------------\n+;; Includes:\n+;; - SMULLB\n+;; - SMULLT\n+;; - UMULLB\n+;; - UMULLT\n+;; -------------------------------------------------------------------------\n+\n+;; Multiply long top / bottom.\n+(define_insn \"<su>mull<bt><Vwide>\"\n+  [(set (match_operand:<VWIDE> 0 \"register_operand\" \"=w\")\n+\t(unspec:<VWIDE>\n+\t  [(match_operand:SVE_FULL_BHSI 1 \"register_operand\" \"w\")\n+\t   (match_operand:SVE_FULL_BHSI 2 \"register_operand\" \"w\")]\n+\t  MULLBT))]\n+  \"TARGET_SVE2\"\n+  \"<su>mull<bt>\\t%0.<Vewtype>, %1.<Vetype>, %2.<Vetype>\"\n+)\n+\n+;; =========================================================================\n+;; == Narrowing arithnetic\n+;; =========================================================================\n+\n+;; -------------------------------------------------------------------------\n+;; ---- [INT] Narrowing right shifts\n+;; -------------------------------------------------------------------------\n+;; Includes:\n+;; - RSHRNB\n+;; - RSHRNT\n+;; - SHRNB\n+;; - SHRNT\n+;; -------------------------------------------------------------------------\n+\n+;; (Rounding) Right shift narrow bottom.\n+(define_insn \"<r>shrnb<mode>\"\n+  [(set (match_operand:SVE_FULL_BHSI 0 \"register_operand\" \"=w\")\n+        (unspec:SVE_FULL_BHSI\n+\t  [(match_operand:<VWIDE> 1 \"register_operand\" \"w\")\n+\t   (match_operand 2 \"aarch64_simd_shift_imm_offset_<Vel>\" \"\")]\n+\t  SHRNB))]\n+  \"TARGET_SVE2\"\n+  \"<r>shrnb\\t%0.<Vetype>, %1.<Vewtype>, #%2\"\n+)\n+\n+;; (Rounding) Right shift narrow top.\n+(define_insn \"<r>shrnt<mode>\"\n+  [(set (match_operand:SVE_FULL_BHSI 0 \"register_operand\" \"=w\")\n+\t(unspec:SVE_FULL_BHSI\n+\t  [(match_operand:SVE_FULL_BHSI 1 \"register_operand\" \"0\")\n+\t   (match_operand:<VWIDE> 2 \"register_operand\" \"w\")\n+\t   (match_operand 3 \"aarch64_simd_shift_imm_offset_<Vel>\" \"i\")]\n+\t  SHRNT))]\n+  \"TARGET_SVE2\"\n+  \"<r>shrnt\\t%0.<Vetype>, %2.<Vewtype>, #%3\"\n+)\n+\n+;; =========================================================================\n+;; == General\n+;; =========================================================================\n+\n+;; -------------------------------------------------------------------------\n+;; ---- Check for aliases between pointers\n+;; -------------------------------------------------------------------------\n+;; The patterns in this section are synthetic: WHILERW and WHILEWR are\n+;; defined in aarch64-sve.md instead.\n+;; -------------------------------------------------------------------------\n+\n ;; Use WHILERW and WHILEWR to accelerate alias checks.  This is only\n ;; possible if the accesses we're checking are exactly the same size\n ;; as an SVE vector."}, {"sha": "2bdb4a922fe2e9ccc1ba32b1e503c81aa9683087", "filename": "gcc/config/aarch64/t-aarch64", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/df0f21028edd919421080f52a99a9b400ba8ba08/gcc%2Fconfig%2Faarch64%2Ft-aarch64", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/df0f21028edd919421080f52a99a9b400ba8ba08/gcc%2Fconfig%2Faarch64%2Ft-aarch64", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Ft-aarch64?ref=df0f21028edd919421080f52a99a9b400ba8ba08", "patch": "@@ -147,7 +147,10 @@ MULTILIB_DIRNAMES   = $(subst $(comma), ,$(TM_MULTILIB_CONFIG))\n \n insn-conditions.md: s-check-sve-md\n s-check-sve-md: $(srcdir)/config/aarch64/check-sve-md.awk \\\n-\t\t$(srcdir)/config/aarch64/aarch64-sve.md\n+\t\t$(srcdir)/config/aarch64/aarch64-sve.md \\\n+\t\t$(srcdir)/config/aarch64/aarch64-sve2.md\n \t$(AWK) -f $(srcdir)/config/aarch64/check-sve-md.awk \\\n \t  $(srcdir)/config/aarch64/aarch64-sve.md\n+\t$(AWK) -f $(srcdir)/config/aarch64/check-sve-md.awk \\\n+\t  $(srcdir)/config/aarch64/aarch64-sve2.md\n \t$(STAMP) s-check-sve-md"}]}