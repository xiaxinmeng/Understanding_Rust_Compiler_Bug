{"sha": "be8749f939a933bca6de19d9cf1a510d5954c2fa", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YmU4NzQ5ZjkzOWE5MzNiY2E2ZGUxOWQ5Y2YxYTUxMGQ1OTU0YzJmYQ==", "commit": {"author": {"name": "Uros Bizjak", "email": "ubizjak@gmail.com", "date": "2021-07-05T19:05:10Z"}, "committer": {"name": "Uros Bizjak", "email": "ubizjak@gmail.com", "date": "2021-07-05T19:05:10Z"}, "message": "i386: Implement 4-byte vector (V4QI/V2HI) constant permutations\n\n2021-07-05  Uro\u0161 Bizjak  <ubizjak@gmail.com>\n\ngcc/\n\t* config/i386/i386-expand.c (ix86_split_mmx_punpck):\n\tHandle V4QI and V2HI modes.\n\t(expand_vec_perm_blend): Allow 4-byte vector modes with TARGET_SSE4_1.\n\tHandle V4QI mode. Emit mmx_pblendvb32 for 4-byte modes.\n\t(expand_vec_perm_pshufb): Rewrite to use switch statemets.\n\tHandle 4-byte dual operands with TARGET_XOP and single operands\n\twith TARGET_SSSE3.  Emit mmx_ppermv32 for TARGET_XOP and\n\tmmx_pshufbv4qi3 for TARGET_SSSE3.\n\t(expand_vec_perm_pblendv): Allow 4-byte vector modes with TARGET_SSE4_1.\n\t(expand_vec_perm_interleave2): Allow 4-byte vector modes.\n\t(expand_vec_perm_pshufb2): Allow 4-byte vector modes with TARGET_SSSE3.\n\t(expand_vec_perm_even_odd_1): Handle V4QI mode.\n\t(expand_vec_perm_broadcast_1): Handle V4QI mode.\n\t(ix86_vectorize_vec_perm_const): Handle V4QI mode.\n\t* config/i386/mmx.md (mmx_ppermv32): New insn pattern.\n\t(mmx_pshufbv4qi3): Ditto.\n\t(*mmx_pblendw32): Ditto.\n\t(*mmx_pblendw64): Rename from *mmx_pblendw.\n\t(mmx_punpckhbw_low): New insn_and_split pattern.\n\t(mmx_punpcklbw_low): Ditto.", "tree": {"sha": "18ebc0b345a465057784661a80cbd102b3ec34d4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/18ebc0b345a465057784661a80cbd102b3ec34d4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/be8749f939a933bca6de19d9cf1a510d5954c2fa", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/be8749f939a933bca6de19d9cf1a510d5954c2fa", "html_url": "https://github.com/Rust-GCC/gccrs/commit/be8749f939a933bca6de19d9cf1a510d5954c2fa", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/be8749f939a933bca6de19d9cf1a510d5954c2fa/comments", "author": {"login": "ubizjak", "id": 55479990, "node_id": "MDQ6VXNlcjU1NDc5OTkw", "avatar_url": "https://avatars.githubusercontent.com/u/55479990?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ubizjak", "html_url": "https://github.com/ubizjak", "followers_url": "https://api.github.com/users/ubizjak/followers", "following_url": "https://api.github.com/users/ubizjak/following{/other_user}", "gists_url": "https://api.github.com/users/ubizjak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ubizjak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ubizjak/subscriptions", "organizations_url": "https://api.github.com/users/ubizjak/orgs", "repos_url": "https://api.github.com/users/ubizjak/repos", "events_url": "https://api.github.com/users/ubizjak/events{/privacy}", "received_events_url": "https://api.github.com/users/ubizjak/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ubizjak", "id": 55479990, "node_id": "MDQ6VXNlcjU1NDc5OTkw", "avatar_url": "https://avatars.githubusercontent.com/u/55479990?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ubizjak", "html_url": "https://github.com/ubizjak", "followers_url": "https://api.github.com/users/ubizjak/followers", "following_url": "https://api.github.com/users/ubizjak/following{/other_user}", "gists_url": "https://api.github.com/users/ubizjak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ubizjak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ubizjak/subscriptions", "organizations_url": "https://api.github.com/users/ubizjak/orgs", "repos_url": "https://api.github.com/users/ubizjak/repos", "events_url": "https://api.github.com/users/ubizjak/events{/privacy}", "received_events_url": "https://api.github.com/users/ubizjak/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8e0b3827bbab6bf92d88d00909ecf8fb43365f39", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8e0b3827bbab6bf92d88d00909ecf8fb43365f39", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8e0b3827bbab6bf92d88d00909ecf8fb43365f39"}], "stats": {"total": 555, "additions": 370, "deletions": 185}, "files": [{"sha": "58c208e166bfd5f48b295c68f91143d04943f576", "filename": "gcc/config/i386/i386-expand.c", "status": "modified", "additions": 286, "deletions": 183, "changes": 469, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/be8749f939a933bca6de19d9cf1a510d5954c2fa/gcc%2Fconfig%2Fi386%2Fi386-expand.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/be8749f939a933bca6de19d9cf1a510d5954c2fa/gcc%2Fconfig%2Fi386%2Fi386-expand.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-expand.c?ref=be8749f939a933bca6de19d9cf1a510d5954c2fa", "patch": "@@ -933,6 +933,7 @@ ix86_split_mmx_punpck (rtx operands[], bool high_p)\n \n   switch (mode)\n     {\n+    case E_V4QImode:\n     case E_V8QImode:\n       sse_mode = V16QImode;\n       double_sse_mode = V32QImode;\n@@ -949,6 +950,7 @@ ix86_split_mmx_punpck (rtx operands[], bool high_p)\n       break;\n \n     case E_V4HImode:\n+    case E_V2HImode:\n       sse_mode = V8HImode;\n       double_sse_mode = V16HImode;\n       mask = gen_rtx_PARALLEL (VOIDmode,\n@@ -991,7 +993,7 @@ ix86_split_mmx_punpck (rtx operands[], bool high_p)\n   rtx insn = gen_rtx_SET (dest, op2);\n   emit_insn (insn);\n \n-  /* Move bits 64:127 to bits 0:63.  */\n+  /* Move high bits to low bits.  */\n   if (high_p)\n     {\n       if (sse_mode == V4SFmode)\n@@ -1004,9 +1006,19 @@ ix86_split_mmx_punpck (rtx operands[], bool high_p)\n \t}\n       else\n \t{\n-\t  mask = gen_rtx_PARALLEL (VOIDmode,\n-\t\t\t\t   gen_rtvec (4, GEN_INT (2), GEN_INT (3),\n-\t\t\t\t\t      GEN_INT (0), GEN_INT (1)));\n+\t  int sz = GET_MODE_SIZE (mode);\n+\n+\t  if (sz == 4)\n+\t    mask = gen_rtx_PARALLEL (VOIDmode,\n+\t\t\t\t     gen_rtvec (4, GEN_INT (1), GEN_INT (0),\n+\t\t\t\t\t\tGEN_INT (0), GEN_INT (1)));\n+\t  else if (sz == 8)\n+\t    mask = gen_rtx_PARALLEL (VOIDmode,\n+\t\t\t\t     gen_rtvec (4, GEN_INT (2), GEN_INT (3),\n+\t\t\t\t\t\tGEN_INT (0), GEN_INT (1)));\n+\t  else\n+\t    gcc_unreachable ();\n+\n \t  dest = lowpart_subreg (V4SImode, dest, GET_MODE (dest));\n \t  op1 = gen_rtx_VEC_SELECT (V4SImode, dest, mask);\n \t}\n@@ -17331,7 +17343,8 @@ expand_vec_perm_blend (struct expand_vec_perm_d *d)\n   else if (TARGET_AVX && (vmode == V4DFmode || vmode == V8SFmode))\n     ;\n   else if (TARGET_SSE4_1 && (GET_MODE_SIZE (vmode) == 16\n-\t\t\t     || GET_MODE_SIZE (vmode) == 8))\n+\t\t\t     || GET_MODE_SIZE (vmode) == 8\n+\t\t\t     || GET_MODE_SIZE (vmode) == 4))\n     ;\n   else\n     return false;\n@@ -17408,7 +17421,9 @@ expand_vec_perm_blend (struct expand_vec_perm_d *d)\n \t    vperm = gen_rtx_CONST_VECTOR (vmode, gen_rtvec_v (nelt, rperm));\n \t    vperm = force_reg (vmode, vperm);\n \n-\t    if (GET_MODE_SIZE (vmode) == 8)\n+\t    if (GET_MODE_SIZE (vmode) == 4)\n+\t      emit_insn (gen_mmx_pblendvb32 (target, op0, op1, vperm));\n+\t    else if (GET_MODE_SIZE (vmode) == 8)\n \t      emit_insn (gen_mmx_pblendvb64 (target, op0, op1, vperm));\n \t    else if (GET_MODE_SIZE (vmode) == 16)\n \t      emit_insn (gen_sse4_1_pblendvb (target, op0, op1, vperm));\n@@ -17440,6 +17455,16 @@ expand_vec_perm_blend (struct expand_vec_perm_d *d)\n       vmode = V4HImode;\n       goto do_subreg;\n \n+    case E_V4QImode:\n+      for (i = 0; i < 4; i += 2)\n+\tif (d->perm[i] + 1 != d->perm[i + 1])\n+\t  goto use_pblendvb;\n+\n+      for (i = 0; i < 2; ++i)\n+\tmask |= (d->perm[i * 2] >= 4) << i;\n+      vmode = V2HImode;\n+      goto do_subreg;\n+\n     case E_V32QImode:\n       /* See if bytes move in pairs.  If not, vpblendvb must be used.  */\n       for (i = 0; i < 32; i += 2)\n@@ -17697,163 +17722,176 @@ expand_vec_perm_pshufb (struct expand_vec_perm_d *d)\n   nelt = d->nelt;\n \n   if (!d->one_operand_p)\n-    {\n-      if (GET_MODE_SIZE (d->vmode) == 8)\n-\t{\n-\t  if (!TARGET_XOP)\n-\t    return false;\n-\t  vmode = V8QImode;\n-\t}\n-      else if (GET_MODE_SIZE (d->vmode) == 16)\n-\t{\n-\t  if (!TARGET_XOP)\n-\t    return false;\n-\t}\n-      else if (GET_MODE_SIZE (d->vmode) == 32)\n-\t{\n-\t  if (!TARGET_AVX2)\n-\t    return false;\n+    switch (GET_MODE_SIZE (d->vmode))\n+      {\n+      case 4:\n+\tif (!TARGET_XOP)\n+\t  return false;\n+\tvmode = V4QImode;\n+\tbreak;\n \n-\t  if (valid_perm_using_mode_p (V2TImode, d))\n-\t    {\n-\t      if (d->testing_p)\n-\t\treturn true;\n+      case 8:\n+\tif (!TARGET_XOP)\n+\t  return false;\n+\tvmode = V8QImode;\n+\tbreak;\n \n-\t      /* Use vperm2i128 insn.  The pattern uses\n-\t\t V4DImode instead of V2TImode.  */\n-\t      target = d->target;\n-\t      if (d->vmode != V4DImode)\n-\t\ttarget = gen_reg_rtx (V4DImode);\n-\t      op0 = gen_lowpart (V4DImode, d->op0);\n-\t      op1 = gen_lowpart (V4DImode, d->op1);\n-\t      rperm[0]\n-\t\t= GEN_INT ((d->perm[0] / (nelt / 2))\n-\t\t\t   | ((d->perm[nelt / 2] / (nelt / 2)) * 16));\n-\t      emit_insn (gen_avx2_permv2ti (target, op0, op1, rperm[0]));\n-\t      if (target != d->target)\n-\t\temit_move_insn (d->target, gen_lowpart (d->vmode, target));\n-\t      return true;\n-\t    }\n+      case 16:\n+\tif (!TARGET_XOP)\n \t  return false;\n-\t}\n-      else\n+\tbreak;\n+\n+      case 32:\n+\tif (!TARGET_AVX2)\n+\t  return false;\n+\n+\tif (valid_perm_using_mode_p (V2TImode, d))\n+\t  {\n+\t    if (d->testing_p)\n+\t      return true;\n+\n+\t    /* Use vperm2i128 insn.  The pattern uses\n+\t       V4DImode instead of V2TImode.  */\n+\t    target = d->target;\n+\t    if (d->vmode != V4DImode)\n+\t      target = gen_reg_rtx (V4DImode);\n+\t    op0 = gen_lowpart (V4DImode, d->op0);\n+\t    op1 = gen_lowpart (V4DImode, d->op1);\n+\t    rperm[0]\n+\t      = GEN_INT ((d->perm[0] / (nelt / 2))\n+\t\t\t | ((d->perm[nelt / 2] / (nelt / 2)) * 16));\n+\t    emit_insn (gen_avx2_permv2ti (target, op0, op1, rperm[0]));\n+\t    if (target != d->target)\n+\t      emit_move_insn (d->target, gen_lowpart (d->vmode, target));\n+\t    return true;\n+\t  }\n+\t/* FALLTHRU */\n+\n+      default:\n \treturn false;\n-    }\n+      }\n   else\n-    {\n-      if (GET_MODE_SIZE (d->vmode) == 8)\n-\t{\n-\t  if (!TARGET_SSSE3)\n-\t    return false;\n-\t  vmode = V8QImode;\n-\t}\n-      else if (GET_MODE_SIZE (d->vmode) == 16)\n-\t{\n-\t  if (!TARGET_SSSE3)\n-\t    return false;\n-\t}\n-      else if (GET_MODE_SIZE (d->vmode) == 32)\n-\t{\n-\t  if (!TARGET_AVX2)\n-\t    return false;\n+    switch (GET_MODE_SIZE (d->vmode))\n+      {\n+      case 4:\n+\tif (!TARGET_SSSE3)\n+\t  return false;\n+\tvmode = V4QImode;\n+\tbreak;\n \n-\t  /* V4DImode should be already handled through\n-\t     expand_vselect by vpermq instruction.  */\n-\t  gcc_assert (d->vmode != V4DImode);\n+      case 8:\n+\tif (!TARGET_SSSE3)\n+\t  return false;\n+\tvmode = V8QImode;\n+\tbreak;\n \n-\t  vmode = V32QImode;\n-\t  if (d->vmode == V8SImode\n-\t      || d->vmode == V16HImode\n-\t      || d->vmode == V32QImode)\n-\t    {\n-\t      /* First see if vpermq can be used for\n-\t\t V8SImode/V16HImode/V32QImode.  */\n-\t      if (valid_perm_using_mode_p (V4DImode, d))\n-\t\t{\n-\t\t  for (i = 0; i < 4; i++)\n-\t\t    perm[i] = (d->perm[i * nelt / 4] * 4 / nelt) & 3;\n-\t\t  if (d->testing_p)\n+      case 16:\n+\tif (!TARGET_SSSE3)\n+\t  return false;\n+\tbreak;\n+\n+      case 32:\n+\tif (!TARGET_AVX2)\n+\t  return false;\n+\n+\t/* V4DImode should be already handled through\n+\t   expand_vselect by vpermq instruction.  */\n+\tgcc_assert (d->vmode != V4DImode);\n+\n+\tvmode = V32QImode;\n+\tif (d->vmode == V8SImode\n+\t    || d->vmode == V16HImode\n+\t    || d->vmode == V32QImode)\n+\t  {\n+\t    /* First see if vpermq can be used for\n+\t       V8SImode/V16HImode/V32QImode.  */\n+\t    if (valid_perm_using_mode_p (V4DImode, d))\n+\t      {\n+\t\tfor (i = 0; i < 4; i++)\n+\t\t  perm[i] = (d->perm[i * nelt / 4] * 4 / nelt) & 3;\n+\t\tif (d->testing_p)\n+\t\t  return true;\n+\t\ttarget = gen_reg_rtx (V4DImode);\n+\t\tif (expand_vselect (target, gen_lowpart (V4DImode, d->op0),\n+\t\t\t\t    perm, 4, false))\n+\t\t  {\n+\t\t    emit_move_insn (d->target,\n+\t\t\t\t    gen_lowpart (d->vmode, target));\n \t\t    return true;\n-\t\t  target = gen_reg_rtx (V4DImode);\n-\t\t  if (expand_vselect (target, gen_lowpart (V4DImode, d->op0),\n-\t\t\t\t      perm, 4, false))\n-\t\t    {\n-\t\t      emit_move_insn (d->target,\n-\t\t\t\t      gen_lowpart (d->vmode, target));\n-\t\t      return true;\n-\t\t    }\n-\t\t  return false;\n-\t\t}\n+\t\t  }\n+\t\treturn false;\n+\t      }\n \n-\t      /* Next see if vpermd can be used.  */\n-\t      if (valid_perm_using_mode_p (V8SImode, d))\n-\t\tvmode = V8SImode;\n-\t    }\n-\t  /* Or if vpermps can be used.  */\n-\t  else if (d->vmode == V8SFmode)\n-\t    vmode = V8SImode;\n+\t    /* Next see if vpermd can be used.  */\n+\t    if (valid_perm_using_mode_p (V8SImode, d))\n+\t      vmode = V8SImode;\n+\t  }\n+\t/* Or if vpermps can be used.  */\n+\telse if (d->vmode == V8SFmode)\n+\t  vmode = V8SImode;\n \n-\t  if (vmode == V32QImode)\n-\t    {\n-\t      /* vpshufb only works intra lanes, it is not\n-\t\t possible to shuffle bytes in between the lanes.  */\n-\t      for (i = 0; i < nelt; ++i)\n-\t\tif ((d->perm[i] ^ i) & (nelt / 2))\n-\t\t  return false;\n-\t    }\n-\t}\n-      else if (GET_MODE_SIZE (d->vmode) == 64)\n-\t{\n-\t  if (!TARGET_AVX512BW)\n-\t    return false;\n+\tif (vmode == V32QImode)\n+\t  {\n+\t    /* vpshufb only works intra lanes, it is not\n+\t       possible to shuffle bytes in between the lanes.  */\n+\t    for (i = 0; i < nelt; ++i)\n+\t      if ((d->perm[i] ^ i) & (nelt / 2))\n+\t\treturn false;\n+\t  }\n+\tbreak;\n \n-\t  /* If vpermq didn't work, vpshufb won't work either.  */\n-\t  if (d->vmode == V8DFmode || d->vmode == V8DImode)\n-\t    return false;\n+      case 64:\n+\tif (!TARGET_AVX512BW)\n+\t  return false;\n \n-\t  vmode = V64QImode;\n-\t  if (d->vmode == V16SImode\n-\t      || d->vmode == V32HImode\n-\t      || d->vmode == V64QImode)\n-\t    {\n-\t      /* First see if vpermq can be used for\n-\t\t V16SImode/V32HImode/V64QImode.  */\n-\t      if (valid_perm_using_mode_p (V8DImode, d))\n-\t\t{\n-\t\t  for (i = 0; i < 8; i++)\n-\t\t    perm[i] = (d->perm[i * nelt / 8] * 8 / nelt) & 7;\n-\t\t  if (d->testing_p)\n+\t/* If vpermq didn't work, vpshufb won't work either.  */\n+\tif (d->vmode == V8DFmode || d->vmode == V8DImode)\n+\t  return false;\n+\n+\tvmode = V64QImode;\n+\tif (d->vmode == V16SImode\n+\t    || d->vmode == V32HImode\n+\t    || d->vmode == V64QImode)\n+\t  {\n+\t    /* First see if vpermq can be used for\n+\t       V16SImode/V32HImode/V64QImode.  */\n+\t    if (valid_perm_using_mode_p (V8DImode, d))\n+\t      {\n+\t\tfor (i = 0; i < 8; i++)\n+\t\t  perm[i] = (d->perm[i * nelt / 8] * 8 / nelt) & 7;\n+\t\tif (d->testing_p)\n+\t\t  return true;\n+\t\ttarget = gen_reg_rtx (V8DImode);\n+\t\tif (expand_vselect (target, gen_lowpart (V8DImode, d->op0),\n+\t\t\t\t    perm, 8, false))\n+\t\t  {\n+\t\t    emit_move_insn (d->target,\n+\t\t\t\t    gen_lowpart (d->vmode, target));\n \t\t    return true;\n-\t\t  target = gen_reg_rtx (V8DImode);\n-\t\t  if (expand_vselect (target, gen_lowpart (V8DImode, d->op0),\n-\t\t\t\t      perm, 8, false))\n-\t\t    {\n-\t\t      emit_move_insn (d->target,\n-\t\t\t\t      gen_lowpart (d->vmode, target));\n-\t\t      return true;\n-\t\t    }\n-\t\t  return false;\n-\t\t}\n+\t\t  }\n+\t\treturn false;\n+\t      }\n \n-\t      /* Next see if vpermd can be used.  */\n-\t      if (valid_perm_using_mode_p (V16SImode, d))\n-\t\tvmode = V16SImode;\n-\t    }\n-\t  /* Or if vpermps can be used.  */\n-\t  else if (d->vmode == V16SFmode)\n-\t    vmode = V16SImode;\n-\t  if (vmode == V64QImode)\n-\t    {\n-\t      /* vpshufb only works intra lanes, it is not\n-\t\t possible to shuffle bytes in between the lanes.  */\n-\t      for (i = 0; i < nelt; ++i)\n-\t\tif ((d->perm[i] ^ i) & (3 * nelt / 4))\n-\t\t  return false;\n-\t    }\n-\t}\n-      else\n+\t    /* Next see if vpermd can be used.  */\n+\t    if (valid_perm_using_mode_p (V16SImode, d))\n+\t      vmode = V16SImode;\n+\t  }\n+\t/* Or if vpermps can be used.  */\n+\telse if (d->vmode == V16SFmode)\n+\t  vmode = V16SImode;\n+\tif (vmode == V64QImode)\n+\t  {\n+\t    /* vpshufb only works intra lanes, it is not\n+\t       possible to shuffle bytes in between the lanes.  */\n+\t    for (i = 0; i < nelt; ++i)\n+\t      if ((d->perm[i] ^ i) & (3 * nelt / 4))\n+\t\treturn false;\n+\t  }\n+\tbreak;\n+\n+      default:\n \treturn false;\n-    }\n+      }\n \n   if (d->testing_p)\n     return true;\n@@ -17893,23 +17931,28 @@ expand_vec_perm_pshufb (struct expand_vec_perm_d *d)\n \n   machine_mode vpmode = vmode;\n \n-  if (vmode == V8QImode)\n+  if (vmode == V4QImode\n+      || vmode == V8QImode)\n     {\n       rtx m128 = GEN_INT (-128);\n \n       /* Remap elements from the second operand, as we have to\n-\t account for inactive top 8 elements from the first operand.  */\n+\t account for inactive top elements from the first operand.  */\n       if (!d->one_operand_p)\n-\tfor (i = 0; i < nelt; ++i)\n-\t  {\n-\t    int ival = INTVAL (rperm[i]);\n-\t    if (ival >= 8)\n-\t      ival += 8;\n-\t    rperm[i] = GEN_INT (ival);\n-\t  }\n+\t{\n+\t  int sz = GET_MODE_SIZE (vmode);\n \n-      /* V8QI is emulated with V16QI instruction, fill inactive\n-\t elements in the top 8 positions with zeros.  */\n+\t  for (i = 0; i < nelt; ++i)\n+\t    {\n+\t      int ival = INTVAL (rperm[i]);\n+\t      if (ival >= sz)\n+\t\tival += 16-sz;\n+\t      rperm[i] = GEN_INT (ival);\n+\t    }\n+\t}\n+\n+      /* V4QI/V8QI is emulated with V16QI instruction, fill inactive\n+\t elements in the top positions with zeros.  */\n       for (i = nelt; i < 16; ++i)\n \trperm[i] = m128;\n \n@@ -17931,7 +17974,9 @@ expand_vec_perm_pshufb (struct expand_vec_perm_d *d)\n     {\n       rtx (*gen) (rtx, rtx, rtx);\n \n-      if (vmode == V8QImode)\n+      if (vmode == V4QImode)\n+\tgen = gen_mmx_pshufbv4qi3;\n+      else if (vmode == V8QImode)\n \tgen = gen_mmx_pshufbv8qi3;\n       else if (vmode == V16QImode)\n \tgen = gen_ssse3_pshufbv16qi3;\n@@ -17958,7 +18003,9 @@ expand_vec_perm_pshufb (struct expand_vec_perm_d *d)\n \n       op1 = gen_lowpart (vmode, d->op1);\n \n-      if (vmode == V8QImode)\n+      if (vmode == V4QImode)\n+\tgen = gen_mmx_ppermv32;\n+      else if (vmode == V8QImode)\n \tgen = gen_mmx_ppermv64;\n       else if (vmode == V16QImode)\n \tgen = gen_xop_pperm;\n@@ -18405,7 +18452,8 @@ expand_vec_perm_pblendv (struct expand_vec_perm_d *d)\n     ;\n   else if (TARGET_AVX && (vmode == V4DFmode || vmode == V8SFmode))\n     ;\n-  else if (TARGET_SSE4_1 && (GET_MODE_SIZE (vmode) == 8\n+  else if (TARGET_SSE4_1 && (GET_MODE_SIZE (vmode) == 4\n+\t\t\t     || GET_MODE_SIZE (vmode) == 8\n \t\t\t     || GET_MODE_SIZE (vmode) == 16))\n     ;\n   else\n@@ -18485,7 +18533,8 @@ expand_vec_perm_interleave2 (struct expand_vec_perm_d *d)\n   rtx_insn *seq;\n   bool ok, same_halves = false;\n \n-  if (GET_MODE_SIZE (d->vmode) == 8\n+  if (GET_MODE_SIZE (d->vmode) == 4\n+      || GET_MODE_SIZE (d->vmode) == 8\n       || GET_MODE_SIZE (d->vmode) == 16)\n     {\n       if (d->one_operand_p)\n@@ -18521,7 +18570,8 @@ expand_vec_perm_interleave2 (struct expand_vec_perm_d *d)\n   memset (remap, 0xff, sizeof (remap));\n   dremap = *d;\n \n-  if (GET_MODE_SIZE (d->vmode) == 8)\n+  if (GET_MODE_SIZE (d->vmode) == 4\n+      || GET_MODE_SIZE (d->vmode) == 8)\n     {\n       unsigned HOST_WIDE_INT h1, h2, h3, h4;\n \n@@ -19269,7 +19319,8 @@ expand_vec_perm_2perm_pblendv (struct expand_vec_perm_d *d, bool two_insn)\n   else if (TARGET_AVX && (vmode == V4DFmode || vmode == V8SFmode))\n     ;\n   else if (TARGET_SSE4_1 && (GET_MODE_SIZE (vmode) == 16\n-\t\t\t     || GET_MODE_SIZE (vmode) == 8))\n+\t\t\t     || GET_MODE_SIZE (vmode) == 8\n+\t\t\t     || GET_MODE_SIZE (vmode) == 4))\n     ;\n   else\n     return false;\n@@ -19530,7 +19581,8 @@ expand_vec_perm_pshufb2 (struct expand_vec_perm_d *d)\n   rtx (*gen) (rtx, rtx, rtx);\n \n   if (!TARGET_SSSE3 || (GET_MODE_SIZE (d->vmode) != 16\n-\t\t\t&& GET_MODE_SIZE (d->vmode) != 8))\n+\t\t\t&& GET_MODE_SIZE (d->vmode) != 8\n+\t\t\t&& GET_MODE_SIZE (d->vmode) != 4))\n     return false;\n   gcc_assert (!d->one_operand_p);\n \n@@ -19539,6 +19591,10 @@ expand_vec_perm_pshufb2 (struct expand_vec_perm_d *d)\n \n   switch (GET_MODE_SIZE (d->vmode))\n     {\n+    case 4:\n+      mode = V4QImode;\n+      gen = gen_mmx_pshufbv4qi3;\n+      break;\n     case 8:\n       mode = V8QImode;\n       gen = gen_mmx_pshufbv8qi3;\n@@ -20025,6 +20081,26 @@ expand_vec_perm_even_odd_1 (struct expand_vec_perm_d *d, unsigned odd)\n \treturn false;\n       break;\n \n+    case E_V4QImode:\n+      if (TARGET_SSSE3 && !TARGET_SLOW_PSHUFB)\n+\treturn expand_vec_perm_pshufb2 (d);\n+      else\n+\t{\n+\t  if (d->testing_p)\n+\t    break;\n+\t  /* We need 2*log2(N)-1 operations to achieve odd/even\n+\t     with interleave. */\n+\t  t1 = gen_reg_rtx (V4QImode);\n+\t  emit_insn (gen_mmx_punpckhbw_low (t1, d->op0, d->op1));\n+\t  emit_insn (gen_mmx_punpcklbw_low (d->target, d->op0, d->op1));\n+\t  if (odd)\n+\t    t2 = gen_mmx_punpckhbw_low (d->target, d->target, t1);\n+\t  else\n+\t    t2 = gen_mmx_punpcklbw_low (d->target, d->target, t1);\n+\t  emit_insn (t2);\n+\t}\n+      break;\n+\n     case E_V4HImode:\n       if (TARGET_SSE4_1)\n \treturn expand_vec_perm_even_odd_pack (d);\n@@ -20214,6 +20290,7 @@ expand_vec_perm_broadcast_1 (struct expand_vec_perm_d *d)\n {\n   unsigned elt = d->perm[0], nelt2 = d->nelt / 2;\n   machine_mode vmode = d->vmode;\n+  rtx (*gen) (rtx, rtx, rtx);\n   unsigned char perm2[4];\n   rtx op0 = d->op0, dest;\n   bool ok;\n@@ -20238,24 +20315,48 @@ expand_vec_perm_broadcast_1 (struct expand_vec_perm_d *d)\n       /* These are always implementable using standard shuffle patterns.  */\n       gcc_unreachable ();\n \n+    case E_V4QImode:\n+      /* This can be implemented via interleave and pshuflw.  */\n+      if (d->testing_p)\n+\treturn true;\n+\n+      if (elt >= nelt2)\n+\t{\n+\t  gen = gen_mmx_punpckhbw_low;\n+\t  elt -= nelt2;\n+\t}\n+      else\n+\tgen = gen_mmx_punpcklbw_low;\n+\n+      dest = gen_reg_rtx (vmode);\n+      emit_insn (gen (dest, op0, op0));\n+      vmode = get_mode_wider_vector (vmode);\n+      op0 = gen_lowpart (vmode, dest);\n+\n+      memset (perm2, elt, 2);\n+      dest = gen_reg_rtx (vmode);\n+      ok = expand_vselect (dest, op0, perm2, 2, d->testing_p);\n+      gcc_assert (ok);\n+\n+      emit_move_insn (d->target, gen_lowpart (d->vmode, dest));\n+      return true;\n+\n     case E_V8QImode:\n-      /* These can be implemented via interleave.  We save one insn by\n+      /* This can be implemented via interleave.  We save one insn by\n \t stopping once we have promoted to V2SImode and then use pshufd.  */\n       if (d->testing_p)\n \treturn true;\n       do\n \t{\n-\t  rtx dest;\n-\t  rtx (*gen) (rtx, rtx, rtx)\n-\t    = vmode == V8QImode ? gen_mmx_punpcklbw\n-\t\t\t\t: gen_mmx_punpcklwd;\n-\n \t  if (elt >= nelt2)\n \t    {\n \t      gen = vmode == V8QImode ? gen_mmx_punpckhbw\n \t\t\t\t      : gen_mmx_punpckhwd;\n \t      elt -= nelt2;\n \t    }\n+\t  else\n+\t    gen = vmode == V8QImode ? gen_mmx_punpcklbw\n+\t\t\t\t    : gen_mmx_punpcklwd;\n \t  nelt2 /= 2;\n \n \t  dest = gen_reg_rtx (vmode);\n@@ -20266,11 +20367,11 @@ expand_vec_perm_broadcast_1 (struct expand_vec_perm_d *d)\n       while (vmode != V2SImode);\n \n       memset (perm2, elt, 2);\n-      dest = gen_reg_rtx (V2SImode);\n+      dest = gen_reg_rtx (vmode);\n       ok = expand_vselect (dest, op0, perm2, 2, d->testing_p);\n       gcc_assert (ok);\n-      if (!d->testing_p)\n-\temit_move_insn (d->target, gen_lowpart (d->vmode, dest));\n+\n+      emit_move_insn (d->target, gen_lowpart (d->vmode, dest));\n       return true;\n \n     case E_V8HImode:\n@@ -20281,17 +20382,15 @@ expand_vec_perm_broadcast_1 (struct expand_vec_perm_d *d)\n \treturn true;\n       do\n \t{\n-\t  rtx dest;\n-\t  rtx (*gen) (rtx, rtx, rtx)\n-\t    = vmode == V16QImode ? gen_vec_interleave_lowv16qi\n-\t\t\t\t : gen_vec_interleave_lowv8hi;\n-\n \t  if (elt >= nelt2)\n \t    {\n \t      gen = vmode == V16QImode ? gen_vec_interleave_highv16qi\n \t\t\t\t       : gen_vec_interleave_highv8hi;\n \t      elt -= nelt2;\n \t    }\n+\t  else\n+\t    gen = vmode == V16QImode ? gen_vec_interleave_lowv16qi\n+\t\t\t\t     : gen_vec_interleave_lowv8hi;\n \t  nelt2 /= 2;\n \n \t  dest = gen_reg_rtx (vmode);\n@@ -20302,11 +20401,11 @@ expand_vec_perm_broadcast_1 (struct expand_vec_perm_d *d)\n       while (vmode != V4SImode);\n \n       memset (perm2, elt, 4);\n-      dest = gen_reg_rtx (V4SImode);\n+      dest = gen_reg_rtx (vmode);\n       ok = expand_vselect (dest, op0, perm2, 4, d->testing_p);\n       gcc_assert (ok);\n-      if (!d->testing_p)\n-\temit_move_insn (d->target, gen_lowpart (d->vmode, dest));\n+\n+      emit_move_insn (d->target, gen_lowpart (d->vmode, dest));\n       return true;\n \n     case E_V64QImode:\n@@ -20787,6 +20886,10 @@ ix86_vectorize_vec_perm_const (machine_mode vmode, rtx target, rtx op0,\n       if (d.testing_p)\n \treturn true;\n       break;\n+    case E_V4QImode:\n+      if (!TARGET_SSE2)\n+\treturn false;\n+      break;\n     case E_V2DImode:\n     case E_V2DFmode:\n       if (!TARGET_SSE)"}, {"sha": "4ead8beff509945c86626647d6d3248b29c97394", "filename": "gcc/config/i386/mmx.md", "status": "modified", "additions": 84, "deletions": 2, "changes": 86, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/be8749f939a933bca6de19d9cf1a510d5954c2fa/gcc%2Fconfig%2Fi386%2Fmmx.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/be8749f939a933bca6de19d9cf1a510d5954c2fa/gcc%2Fconfig%2Fi386%2Fmmx.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fmmx.md?ref=be8749f939a933bca6de19d9cf1a510d5954c2fa", "patch": "@@ -2362,6 +2362,18 @@\n   [(set_attr \"type\" \"sse4arg\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn \"mmx_ppermv32\"\n+  [(set (match_operand:V4QI 0 \"register_operand\" \"=x\")\n+\t(unspec:V4QI\n+\t  [(match_operand:V4QI 1 \"register_operand\" \"x\")\n+\t   (match_operand:V4QI 2 \"register_operand\" \"x\")\n+\t   (match_operand:V16QI 3 \"nonimmediate_operand\" \"xm\")]\n+\t  UNSPEC_XOP_PERMUTE))]\n+  \"TARGET_XOP\"\n+  \"vpperm\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"type\" \"sse4arg\")\n+   (set_attr \"mode\" \"TI\")])\n+\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;;\n ;; Parallel integral logical operations\n@@ -2550,6 +2562,23 @@\n    (set_attr \"type\" \"mmxcvt,sselog,sselog\")\n    (set_attr \"mode\" \"DI,TI,TI\")])\n \n+(define_insn_and_split \"mmx_punpckhbw_low\"\n+  [(set (match_operand:V4QI 0 \"register_operand\" \"=x,Yw\")\n+\t(vec_select:V4QI\n+\t  (vec_concat:V8QI\n+\t    (match_operand:V4QI 1 \"register_operand\" \"0,Yw\")\n+\t    (match_operand:V4QI 2 \"register_operand\" \"x,Yw\"))\n+          (parallel [(const_int 2) (const_int 6)\n+                     (const_int 3) (const_int 7)])))]\n+  \"TARGET_SSE2\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n+  \"ix86_split_mmx_punpck (operands, true); DONE;\"\n+  [(set_attr \"isa\" \"noavx,avx\")\n+   (set_attr \"type\" \"sselog\")\n+   (set_attr \"mode\" \"TI\")])\n+\n (define_insn_and_split \"mmx_punpcklbw\"\n   [(set (match_operand:V8QI 0 \"register_operand\" \"=y,x,Yw\")\n \t(vec_select:V8QI\n@@ -2573,6 +2602,23 @@\n    (set_attr \"type\" \"mmxcvt,sselog,sselog\")\n    (set_attr \"mode\" \"DI,TI,TI\")])\n \n+(define_insn_and_split \"mmx_punpcklbw_low\"\n+  [(set (match_operand:V4QI 0 \"register_operand\" \"=x,Yw\")\n+\t(vec_select:V4QI\n+\t  (vec_concat:V8QI\n+\t    (match_operand:V4QI 1 \"register_operand\" \"0,Yw\")\n+\t    (match_operand:V4QI 2 \"register_operand\" \"x,Yw\"))\n+          (parallel [(const_int 0) (const_int 4)\n+                     (const_int 1) (const_int 5)])))]\n+  \"TARGET_SSE2\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n+  \"ix86_split_mmx_punpck (operands, false); DONE;\"\n+  [(set_attr \"isa\" \"noavx,avx\")\n+   (set_attr \"type\" \"sselog\")\n+   (set_attr \"mode\" \"TI\")])\n+\n (define_insn_and_split \"mmx_punpckhwd\"\n   [(set (match_operand:V4HI 0 \"register_operand\" \"=y,x,Yw\")\n \t(vec_select:V4HI\n@@ -2930,6 +2976,24 @@\n    (set_attr \"btver2_decode\" \"vector\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn \"mmx_pshufbv4qi3\"\n+  [(set (match_operand:V4QI 0 \"register_operand\" \"=x,Yw\")\n+\t(unspec:V4QI\n+\t  [(match_operand:V4QI 1 \"register_operand\" \"0,Yw\")\n+\t   (match_operand:V16QI 2 \"vector_operand\" \"xBm,Ywm\")]\n+\t  UNSPEC_PSHUFB))]\n+  \"TARGET_SSSE3\"\n+  \"@\n+   pshufb\\t{%2, %0|%0, %2}\n+   vpshufb\\t{%2, %1, %0|%0, %1, %2}\"\n+  [(set_attr \"isa\" \"noavx,avx\")\n+   (set_attr \"type\" \"sselog1\")\n+   (set_attr \"prefix_data16\" \"1,*\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"prefix\" \"orig,maybe_evex\")\n+   (set_attr \"btver2_decode\" \"vector\")\n+   (set_attr \"mode\" \"TI\")])\n+\n (define_expand \"mmx_pshufw\"\n   [(match_operand:V4HI 0 \"register_operand\")\n    (match_operand:V4HI 1 \"register_mmxmem_operand\")\n@@ -3002,12 +3066,12 @@\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"*mmx_pblendw\"\n+(define_insn \"*mmx_pblendw64\"\n   [(set (match_operand:V4HI 0 \"register_operand\" \"=Yr,*x,x\")\n \t(vec_merge:V4HI\n \t  (match_operand:V4HI 2 \"register_operand\" \"Yr,*x,x\")\n \t  (match_operand:V4HI 1 \"register_operand\" \"0,0,x\")\n-\t  (match_operand:SI 3 \"const_0_to_63_operand\" \"n,n,n\")))]\n+\t  (match_operand:SI 3 \"const_0_to_15_operand\" \"n,n,n\")))]\n   \"TARGET_SSE4_1 && TARGET_MMX_WITH_SSE\"\n   \"@\n    pblendw\\t{%3, %2, %0|%0, %2, %3}\n@@ -3020,6 +3084,24 @@\n    (set_attr \"prefix\" \"orig,orig,vex\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn \"*mmx_pblendw32\"\n+  [(set (match_operand:V2HI 0 \"register_operand\" \"=Yr,*x,x\")\n+\t(vec_merge:V2HI\n+\t  (match_operand:V2HI 2 \"register_operand\" \"Yr,*x,x\")\n+\t  (match_operand:V2HI 1 \"register_operand\" \"0,0,x\")\n+\t  (match_operand:SI 3 \"const_0_to_7_operand\" \"n,n,n\")))]\n+  \"TARGET_SSE4_1\"\n+  \"@\n+   pblendw\\t{%3, %2, %0|%0, %2, %3}\n+   pblendw\\t{%3, %2, %0|%0, %2, %3}\n+   vpblendw\\t{%3, %2, %1, %0|%0, %1, %2, %3}\"\n+  [(set_attr \"isa\" \"noavx,noavx,avx\")\n+   (set_attr \"type\" \"ssemov\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"length_immediate\" \"1\")\n+   (set_attr \"prefix\" \"orig,orig,vex\")\n+   (set_attr \"mode\" \"TI\")])\n+\n ;; Optimize V2SImode load from memory, swapping the elements and\n ;; storing back into the memory into DImode rotate of the memory by 32.\n (define_split"}]}