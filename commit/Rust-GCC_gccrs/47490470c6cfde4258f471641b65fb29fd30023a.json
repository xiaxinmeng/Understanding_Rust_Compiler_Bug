{"sha": "47490470c6cfde4258f471641b65fb29fd30023a", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDc0OTA0NzBjNmNmZGU0MjU4ZjQ3MTY0MWI2NWZiMjlmZDMwMDIzYQ==", "commit": {"author": {"name": "Alexander Ivchenko", "email": "alexander.ivchenko@intel.com", "date": "2013-11-13T08:21:57Z"}, "committer": {"name": "Kirill Yukhin", "email": "kyukhin@gcc.gnu.org", "date": "2013-11-13T08:21:57Z"}, "message": "i386.c (ix86_print_operand): Support z-masking.\n\n\t* config/i386/i386.c (ix86_print_operand): Support z-masking.\n\t* config/i386/predicate.md (const_0_to_4_operand): New.\n\t(const_0_to_5_operand): Ditto.\n\t* config/i386/sse.md (UNSPEC_COMPRESS): New.\n\t(UNSPEC_COMPRESS_STORE): Ditto.\n\t(UNSPEC_EXPAND): Ditto.\n\t(UNSPEC_EMBEDDED_ROUNDING): Ditto.\n\t(define_mode_attr ssescalarsize): Ditto.\n\t(avx512f_load<mode>_mask): Ditto.\n\t(avx512f_store<mode>_mask): Ditto.\n\t(avx512f_storedqu<mode>_mask): Ditto.\n\t(avx512f_vmcmp<mode>3_mask): Ditto.\n\t(avx512f_fmadd_<mode>_mask): Ditto.\n\t(avx512f_fmadd_<mode>_mask3): Ditto.\n\t(avx512f_fmsub_<mode>_mask): Ditto.\n\t(avx512f_fmsub_<mode>_mask3): Ditto.\n\t(avx512f_fnmadd_<mode>_mask): Ditto.\n\t(avx512f_fnmadd_<mode>_mask3): Ditto.\n\t(avx512f_fnmsub_<mode>_mask): Ditto.\n\t(avx512f_fnmsub_<mode>_mask3): Ditto.\n\t(avx512f_fmaddsub_<mode>_mask): Ditto.\n\t(avx512f_fmaddsub_<mode>_mask3): Ditto.\n\t(avx512f_fmsubadd_<mode>_mask): Ditto.\n\t(avx512f_fmsubadd_<mode>_mask3): Ditto.\n\t(vec_unpacku_float_lo_v16si): Ditto.\n\t(avx512f_vextract<shuffletype>32x4_mask): Ditto.\n\t(avx512f_vextract<shuffletype>32x4_1_maskm): Ditto.\n\t(avx512f_vextract<shuffletype>64x4_mask): Ditto.\n\t(vec_extract_lo_<mode>_maskm): Ditto.\n\t(vec_extract_hi_<mode>_maskm): Ditto.\n\t(avx512f_vternlog<mode>_mask): Ditto.\n\t(avx512f_shufps512_mask): Ditto.\n\t(avx512f_fixupimm<mode>_mask): Ditto.\n\t(avx512f_shufpd512_mask): Ditto.\n\t(avx512f_<code><pmov_src_lower><mode>2_mask): Ditto.\n\t(avx512f_<code>v8div16qi2_mask/trunc): Ditto.\n\t(*avx512f_<code>v8div16qi2_store_mask): Ditto.\n\t(ashr<mode>3<mask_name>): Ditto.\n\t(avx512f_vinsert<shuffletype>32x4_mask): Ditto.\n\t(avx512f_vinsert<shuffletype>64x4_mask): Ditto.\n\t(avx512f_shuf_<shuffletype>64x2_mask): Ditto.\n\t(avx512f_shuf_<shuffletype>32x4_mask): Ditto.\n\t(avx512f_pshufdv3_mask): Ditto.\n\t(avx512f_perm<mode>_mask): Ditto.\n\t(avx512f_vpermi2var<mode>3_mask): Ditto.\n\t(avx512f_vpermt2var<mode>3_mask): Ditto.\n\t(avx512f_compress<mode>_mask): Ditto.\n\t(avx512f_compressstore<mode>_mask): Ditto.\n\t(avx512f_expand<mode>_mask): Ditto.\n\t(<sse>_loadu<ssemodesuffix><avxsizesuffix><mask_name>): Extend\n\tto support masking.\n\t(avx512f_storeu<ssemodesuffix>512_mask): Ditto.\n\t(<plusminus_insn><mode>3<mask_name>): Ditto.\n\t(*<plusminus_insn><mode>3<mask_name>): Ditto.\n\t(mul<mode>3<mask_name>): Ditto.\n\t(*mul<mode>3<mask_name>): Ditto.\n\t(<sse>_div<mode>3<mask_name>): Ditto.\n\t(<mask_codefor>rcp14<mode><mask_name>): Ditto.\n\t(<sse>_sqrt<mode>2<mask_name>): Ditto.\n\t(<mask_codefor>rsqrt14<mode><mask_name>): Ditto.\n\t(<code><mode>3<mask_name>/smaxmin): Ditto.\n\t(*<code><mode>3_finite<mask_name>/smaxmin): Ditto.\n\t(*<code><mode>3<mask_name>/smaxmin): Ditto.\n\t(float<sseintvecmodelower><mode>2<mask_name>): Ditto.\n\t(ufloatv16siv16sf2<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_fix_notruncv16sfv16si<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_ufix_notruncv16sfv16si<mask_name>): Ditto.\n\t(<fixsuffix>fix_truncv16sfv16si2<mask_name>): Ditto.\n\t(float<si2dfmodelower><mode>2<mask_name>): Ditto.\n\t(ufloatv8siv8df<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_cvtpd2dq512<mask_name>): Ditto.\n\t(avx512f_ufix_notruncv8dfv8si<mask_name>): Ditto.\n\t(<fixsuffix>fix_truncv8dfv8si2<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_cvtpd2ps512<mask_name>): Ditto.\n\t(<sse2_avx_avx512f>_cvtps2pd<avxsizesuffix><mask_name>): Ditto.\n\t(<mask_codefor>avx512f_unpckhps512<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_unpcklps512<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_movshdup512<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_movsldup512<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_vextract<shuffletype>32x4_1<mask_name>): Ditto.\n\t(vec_extract_lo_<mode><mask_name>): Ditto.\n\t(vec_extract_hi_<mode><mask_name>): Ditto.\n\t(<mask_codefor>avx512f_unpckhpd512<mask_name>): Ditto.\n\t(avx512f_movddup512<mask_name>): Ditto.\n\t(avx512f_unpcklpd512<mask_name>): Ditto.\n\t(*avx512f_unpcklpd512<mask_name>): Ditto.\n\t(*avx512f_vmscalef<mode>): Ditto.\n\t(avx512f_scalef<mode><mask_name>): Ditto.\n\t(avx512f_getexp<mode><mask_name>): Ditto.\n\t(<mask_codefor>avx512f_align<mode><mask_name>): Ditto.\n\t(avx512f_rndscale<mode><mask_name>): Ditto.\n\t(avx512f_shufps512_1<mask_name>): Ditto.\n\t(avx512f_shufpd512_1<mask_name>): Ditto.\n\t(<plusminus_insn><mode>3<mask_name>): Ditto.\n\t(*<plusminus_insn><mode>3<mask_name>): Ditto.\n\t(vec_widen_umult_even_v16si<mask_name>): Ditto.\n\t(*vec_widen_umult_even_v16si<mask_name>): Ditto.\n\t(vec_widen_smult_even_v16si<mask_name>): Ditto.\n\t(*vec_widen_smult_even_v16si<mask_name>): Ditto.\n\t(mul<mode>3<mask_name>): Ditto.\n\t(*<sse4_1_avx2>_mul<mode>3<mask_name>): Ditto.\n\t(<shift_insn><mode>3<mask_name>): Ditto.\n\t(avx512f_<rotate>v<mode><mask_name>/rotate): Ditto.\n\t(avx512f_<rotate><mode><mask_name>): Ditto.\n\t(<code><mode>3<mask_name>/maxmin): Ditto.\n\t(*avx2_<code><mode>3<mask_name>/maxmin): Ditto.\n\t(<sse2_avx2>_andnot<mode>3<mask_name>): Ditto.\n\t(*andnot<mode>3<mask_name>): Ditto.\n\t(<mask_codefor><code><mode>3<mask_name>/any_logic): Ditto.\n\t(<mask_codefor>avx512f_interleave_highv16si<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_interleave_lowv16si<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_vinsert<shuffletype>32x4_1<mask_name>): Ditto.\n\t(vec_set_lo_<mode><mask_name>): Ditto.\n\t(vec_set_hi_<mode><mask_name>): Ditto.\n\t(avx512f_shuf_<shuffletype>64x2_1<mask_name>): Ditto.\n\t(avx512f_shuf_<shuffletype>32x4_1<mask_name>): Ditto.\n\t(avx512f_pshufd_1<mask_name>): Ditto.\n\t(<mask_codefor>abs<mode>2<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_<code>v16qiv16si2<mask_name>): Ditto.\n\t(avx512f_<code>v16hiv16si2<mask_name>/any_extend): Ditto.\n\t(avx512f_<code>v8qiv8di2<mask_name>/any_extend): Ditto.\n\t(avx512f_<code>v8hiv8di2<mask_name>/any_extend): Ditto.\n\t(avx512f_<code>v8siv8di2<mask_name>/any_extend): Ditto.\n\t(avx512er_exp2<mode><mask_name>): Ditto.\n\t(<mask_codefor>avx512er_rcp28<mode><mask_name>): Ditto.\n\t(<mask_codefor>avx512er_rsqrt28<mode><mask_name>): Ditto.\n\t(<avx2_avx512f>_permvar<mode><mask_name>): Ditto.\n\t(<avx2_avx512f>_perm<mode>_1<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_vec_dup<mode><mask_name>): Ditto.\n\t(<mask_codefor>avx512f_broadcast<mode><mask_name>/V16FI): Ditto.\n\t(<mask_codefor>avx512f_broadcast<mode><mask_name>/V8FI): Ditto.\n\t(<mask_codefor>avx512f_vec_dup_gpr<mode><mask_name>): Ditto.\n\t(<mask_codefor>avx512f_vec_dup_mem<mode><mask_name>): Ditto.\n\t(<sse2_avx_avx512f>_vpermil<mode><mask_name>/VF2): Ditto.\n\t(<sse2_avx_avx512f>_vpermil<mode><mask_name>/VF1): Ditto.\n\t(*<sse2_avx_avx512f>_vpermilp<mode><mask_name>): Ditto.\n\t(<sse2_avx_avx512f>_vpermilvar<mode>3<mask_name>): Ditto.\n\t(<avx2_avx512f>_ashrv<mode><mask_name>): Ditto.\n\t(<avx2_avx512f>_<shift_insn>v<mode><mask_name>): Ditto.\n\t(<mask_codefor>avx512f_vcvtph2ps512<mask_name>): Ditto.\n\t(<mask_codefor>avx512f_vcvtps2ph512<mask_name>): Ditto.\n\t(avx512f_getmant<mode><mask_name>): Ditto.\n\t(clz<mode>2<mask_name>): Ditto.\n\t(<mask_codefor>conflict<mode><mask_name>): Ditto.\n\t(*srcp14<mode>): Remove visibility.\n\t(*rsqrt14<mode>): Ditto.\n\t(*fma_fmsub_<mode>): Ditto.\n\t(*fma_fnmadd_<mode>): Ditto.\n\t(*avx512f_rndscale<mode>): Ditto.\n\t* config/i386/subst.md: New file.\n\n\nCo-Authored-By: Andrey Turetskiy <andrey.turetskiy@intel.com>\nCo-Authored-By: Anna Tikhonova <anna.tikhonova@intel.com>\nCo-Authored-By: Ilya Tocar <ilya.tocar@intel.com>\nCo-Authored-By: Ilya Verbin <ilya.verbin@intel.com>\nCo-Authored-By: Kirill Yukhin <kirill.yukhin@intel.com>\nCo-Authored-By: Maxim Kuznetsov <maxim.kuznetsov@intel.com>\nCo-Authored-By: Michael Zolotukhin <michael.v.zolotukhin@intel.com>\nCo-Authored-By: Sergey Lega <sergey.s.lega@intel.com>\n\nFrom-SVN: r204734", "tree": {"sha": "db50cf004742e7b122bbd9808e753a9c05c12b82", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/db50cf004742e7b122bbd9808e753a9c05c12b82"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/47490470c6cfde4258f471641b65fb29fd30023a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/47490470c6cfde4258f471641b65fb29fd30023a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/47490470c6cfde4258f471641b65fb29fd30023a", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/47490470c6cfde4258f471641b65fb29fd30023a/comments", "author": null, "committer": null, "parents": [{"sha": "34eebd2a99ece6b86c409813c23275e209d17d76", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/34eebd2a99ece6b86c409813c23275e209d17d76", "html_url": "https://github.com/Rust-GCC/gccrs/commit/34eebd2a99ece6b86c409813c23275e209d17d76"}], "stats": {"total": 1672, "additions": 1410, "deletions": 262}, "files": [{"sha": "eb69f2a53203eb88c51e43247336df380dfba2c3", "filename": "gcc/ChangeLog", "status": "modified", "additions": 161, "deletions": 0, "changes": 161, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=47490470c6cfde4258f471641b65fb29fd30023a", "patch": "@@ -1,3 +1,164 @@\n+2013-11-13  Alexander Ivchenko  <alexander.ivchenko@intel.com>\n+\t    Maxim Kuznetsov  <maxim.kuznetsov@intel.com>\n+\t    Sergey Lega  <sergey.s.lega@intel.com>\n+\t    Anna Tikhonova  <anna.tikhonova@intel.com>\n+\t    Ilya Tocar  <ilya.tocar@intel.com>\n+\t    Andrey Turetskiy  <andrey.turetskiy@intel.com>\n+\t    Ilya Verbin  <ilya.verbin@intel.com>\n+\t    Kirill Yukhin  <kirill.yukhin@intel.com>\n+\t    Michael Zolotukhin  <michael.v.zolotukhin@intel.com>\n+\n+\t* config/i386/i386.c (ix86_print_operand): Support z-masking\n+\t* config/i386/predicate.md (const_0_to_4_operand): New.\n+\t(const_0_to_5_operand): Ditto.\n+\t* config/i386/sse.md (UNSPEC_COMPRESS): New.\n+\t(UNSPEC_COMPRESS_STORE): Ditto.\n+\t(UNSPEC_EXPAND): Ditto.\n+\t(UNSPEC_EMBEDDED_ROUNDING): Ditto.\n+\t(define_mode_attr ssescalarsize): Ditto.\n+\t(avx512f_load<mode>_mask): Ditto.\n+\t(avx512f_store<mode>_mask): Ditto.\n+\t(avx512f_storedqu<mode>_mask): Ditto.\n+\t(avx512f_vmcmp<mode>3_mask): Ditto.\n+\t(avx512f_fmadd_<mode>_mask): Ditto.\n+\t(avx512f_fmadd_<mode>_mask3): Ditto.\n+\t(avx512f_fmsub_<mode>_mask): Ditto.\n+\t(avx512f_fmsub_<mode>_mask3): Ditto.\n+\t(avx512f_fnmadd_<mode>_mask): Ditto.\n+\t(avx512f_fnmadd_<mode>_mask3): Ditto.\n+\t(avx512f_fnmsub_<mode>_mask): Ditto.\n+\t(avx512f_fnmsub_<mode>_mask3): Ditto.\n+\t(avx512f_fmaddsub_<mode>_mask): Ditto.\n+\t(avx512f_fmaddsub_<mode>_mask3): Ditto.\n+\t(avx512f_fmsubadd_<mode>_mask): Ditto.\n+\t(avx512f_fmsubadd_<mode>_mask3): Ditto.\n+\t(vec_unpacku_float_lo_v16si): Ditto.\n+\t(avx512f_vextract<shuffletype>32x4_mask): Ditto.\n+\t(avx512f_vextract<shuffletype>32x4_1_maskm): Ditto.\n+\t(avx512f_vextract<shuffletype>64x4_mask): Ditto.\n+\t(vec_extract_lo_<mode>_maskm): Ditto.\n+\t(vec_extract_hi_<mode>_maskm): Ditto.\n+\t(avx512f_vternlog<mode>_mask): Ditto.\n+\t(avx512f_shufps512_mask): Ditto.\n+\t(avx512f_fixupimm<mode>_mask): Ditto.\n+\t(avx512f_shufpd512_mask): Ditto.\n+\t(avx512f_<code><pmov_src_lower><mode>2_mask): Ditto.\n+\t(avx512f_<code>v8div16qi2_mask/trunc): Ditto.\n+\t(*avx512f_<code>v8div16qi2_store_mask): Ditto.\n+\t(ashr<mode>3<mask_name>): Ditto.\n+\t(avx512f_vinsert<shuffletype>32x4_mask): Ditto.\n+\t(avx512f_vinsert<shuffletype>64x4_mask): Ditto.\n+\t(avx512f_shuf_<shuffletype>64x2_mask): Ditto.\n+\t(avx512f_shuf_<shuffletype>32x4_mask): Ditto.\n+\t(avx512f_pshufdv3_mask): Ditto.\n+\t(avx512f_perm<mode>_mask): Ditto.\n+\t(avx512f_vpermi2var<mode>3_mask): Ditto.\n+\t(avx512f_vpermt2var<mode>3_mask): Ditto.\n+\t(avx512f_compress<mode>_mask): Ditto.\n+\t(avx512f_compressstore<mode>_mask): Ditto.\n+\t(avx512f_expand<mode>_mask): Ditto.\n+\t(<sse>_loadu<ssemodesuffix><avxsizesuffix><mask_name>): Extend\n+\tto support masking.\n+\t(avx512f_storeu<ssemodesuffix>512_mask): Ditto.\n+\t(<plusminus_insn><mode>3<mask_name>): Ditto.\n+\t(*<plusminus_insn><mode>3<mask_name>): Ditto.\n+\t(mul<mode>3<mask_name>): Ditto.\n+\t(*mul<mode>3<mask_name>): Ditto.\n+\t(<sse>_div<mode>3<mask_name>): Ditto.\n+\t(<mask_codefor>rcp14<mode><mask_name>): Ditto.\n+\t(<sse>_sqrt<mode>2<mask_name>): Ditto.\n+\t(<mask_codefor>rsqrt14<mode><mask_name>): Ditto.\n+\t(<code><mode>3<mask_name>/smaxmin): Ditto.\n+\t(*<code><mode>3_finite<mask_name>/smaxmin): Ditto.\n+\t(*<code><mode>3<mask_name>/smaxmin): Ditto.\n+\t(float<sseintvecmodelower><mode>2<mask_name>): Ditto.\n+\t(ufloatv16siv16sf2<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_fix_notruncv16sfv16si<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_ufix_notruncv16sfv16si<mask_name>): Ditto.\n+\t(<fixsuffix>fix_truncv16sfv16si2<mask_name>): Ditto.\n+\t(float<si2dfmodelower><mode>2<mask_name>): Ditto.\n+\t(ufloatv8siv8df<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_cvtpd2dq512<mask_name>): Ditto.\n+\t(avx512f_ufix_notruncv8dfv8si<mask_name>): Ditto.\n+\t(<fixsuffix>fix_truncv8dfv8si2<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_cvtpd2ps512<mask_name>): Ditto.\n+\t(<sse2_avx_avx512f>_cvtps2pd<avxsizesuffix><mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_unpckhps512<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_unpcklps512<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_movshdup512<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_movsldup512<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_vextract<shuffletype>32x4_1<mask_name>): Ditto.\n+\t(vec_extract_lo_<mode><mask_name>): Ditto.\n+\t(vec_extract_hi_<mode><mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_unpckhpd512<mask_name>): Ditto.\n+\t(avx512f_movddup512<mask_name>): Ditto.\n+\t(avx512f_unpcklpd512<mask_name>): Ditto.\n+\t(*avx512f_unpcklpd512<mask_name>): Ditto.\n+\t(*avx512f_vmscalef<mode>): Ditto.\n+\t(avx512f_scalef<mode><mask_name>): Ditto.\n+\t(avx512f_getexp<mode><mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_align<mode><mask_name>): Ditto.\n+\t(avx512f_rndscale<mode><mask_name>): Ditto.\n+\t(avx512f_shufps512_1<mask_name>): Ditto.\n+\t(avx512f_shufpd512_1<mask_name>): Ditto.\n+\t(<plusminus_insn><mode>3<mask_name>): Ditto.\n+\t(*<plusminus_insn><mode>3<mask_name>): Ditto.\n+\t(vec_widen_umult_even_v16si<mask_name>): Ditto.\n+\t(*vec_widen_umult_even_v16si<mask_name>): Ditto.\n+\t(vec_widen_smult_even_v16si<mask_name>): Ditto.\n+\t(*vec_widen_smult_even_v16si<mask_name>): Ditto.\n+\t(mul<mode>3<mask_name>): Ditto.\n+\t(*<sse4_1_avx2>_mul<mode>3<mask_name>): Ditto.\n+\t(<shift_insn><mode>3<mask_name>): Ditto.\n+\t(avx512f_<rotate>v<mode><mask_name>/rotate): Ditto.\n+\t(avx512f_<rotate><mode><mask_name>): Ditto.\n+\t(<code><mode>3<mask_name>/maxmin): Ditto.\n+\t(*avx2_<code><mode>3<mask_name>/maxmin): Ditto.\n+\t(<sse2_avx2>_andnot<mode>3<mask_name>): Ditto.\n+\t(*andnot<mode>3<mask_name>): Ditto.\n+\t(<mask_codefor><code><mode>3<mask_name>/any_logic): Ditto.\n+\t(<mask_codefor>avx512f_interleave_highv16si<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_interleave_lowv16si<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_vinsert<shuffletype>32x4_1<mask_name>): Ditto.\n+\t(vec_set_lo_<mode><mask_name>): Ditto.\n+\t(vec_set_hi_<mode><mask_name>): Ditto.\n+\t(avx512f_shuf_<shuffletype>64x2_1<mask_name>): Ditto.\n+\t(avx512f_shuf_<shuffletype>32x4_1<mask_name>): Ditto.\n+\t(avx512f_pshufd_1<mask_name>): Ditto.\n+\t(<mask_codefor>abs<mode>2<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_<code>v16qiv16si2<mask_name>): Ditto.\n+\t(avx512f_<code>v16hiv16si2<mask_name>/any_extend): Ditto.\n+\t(avx512f_<code>v8qiv8di2<mask_name>/any_extend): Ditto.\n+\t(avx512f_<code>v8hiv8di2<mask_name>/any_extend): Ditto.\n+\t(avx512f_<code>v8siv8di2<mask_name>/any_extend): Ditto.\n+\t(avx512er_exp2<mode><mask_name>): Ditto.\n+\t(<mask_codefor>avx512er_rcp28<mode><mask_name>): Ditto.\n+\t(<mask_codefor>avx512er_rsqrt28<mode><mask_name>): Ditto.\n+\t(<avx2_avx512f>_permvar<mode><mask_name>): Ditto.\n+\t(<avx2_avx512f>_perm<mode>_1<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_vec_dup<mode><mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_broadcast<mode><mask_name>/V16FI): Ditto.\n+\t(<mask_codefor>avx512f_broadcast<mode><mask_name>/V8FI): Ditto.\n+\t(<mask_codefor>avx512f_vec_dup_gpr<mode><mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_vec_dup_mem<mode><mask_name>): Ditto.\n+\t(<sse2_avx_avx512f>_vpermil<mode><mask_name>/VF2): Ditto.\n+\t(<sse2_avx_avx512f>_vpermil<mode><mask_name>/VF1): Ditto.\n+\t(*<sse2_avx_avx512f>_vpermilp<mode><mask_name>): Ditto.\n+\t(<sse2_avx_avx512f>_vpermilvar<mode>3<mask_name>): Ditto.\n+\t(<avx2_avx512f>_ashrv<mode><mask_name>): Ditto.\n+\t(<avx2_avx512f>_<shift_insn>v<mode><mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_vcvtph2ps512<mask_name>): Ditto.\n+\t(<mask_codefor>avx512f_vcvtps2ph512<mask_name>): Ditto.\n+\t(avx512f_getmant<mode><mask_name>): Ditto.\n+\t(clz<mode>2<mask_name>): Ditto.\n+\t(<mask_codefor>conflict<mode><mask_name>): Ditto.\n+\t(*srcp14<mode>): Remove visibility.\n+\t(*rsqrt14<mode>): Ditto.\n+\t(*fma_fmsub_<mode>): Ditto.\n+\t(*fma_fnmadd_<mode>): Ditto.\n+\t(*avx512f_rndscale<mode>): Ditto.\n+\t* config/i386/subst.md: New file.\n+\n 2013-11-13  Joseph Myers  <joseph@codesourcery.com>\n \n \t* doc/extend.texi (Statement Exprs, Typeof): Discuss __auto_type."}, {"sha": "8716571346918d73e437744f4ffd7ab23546b057", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=47490470c6cfde4258f471641b65fb29fd30023a", "patch": "@@ -14855,6 +14855,11 @@ ix86_print_operand (FILE *file, rtx x, int code)\n \t  /* We do not want to print value of the operand.  */\n \t  return;\n \n+\tcase 'N':\n+\t  if (x == const0_rtx || x == CONST0_RTX (GET_MODE (x)))\n+\t    fputs (\"{z}\", file);\n+\t  return;\n+\n \tcase '*':\n \t  if (ASSEMBLER_DIALECT == ASM_ATT)\n \t    putc ('*', file);"}, {"sha": "66ac52fd8c4188da516cddb8292141d9a06ca067", "filename": "gcc/config/i386/predicates.md", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2Fconfig%2Fi386%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2Fconfig%2Fi386%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fpredicates.md?ref=47490470c6cfde4258f471641b65fb29fd30023a", "patch": "@@ -687,6 +687,16 @@\n   (and (match_code \"const_int\")\n        (match_test \"IN_RANGE (INTVAL (op), 0, 3)\")))\n \n+;; Match 0 to 4.\n+(define_predicate \"const_0_to_4_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"IN_RANGE (INTVAL (op), 0, 4)\")))\n+\n+;; Match 0 to 5.\n+(define_predicate \"const_0_to_5_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"IN_RANGE (INTVAL (op), 0, 5)\")))\n+\n ;; Match 0 to 7.\n (define_predicate \"const_0_to_7_operand\"\n   (and (match_code \"const_int\")"}, {"sha": "6d6e16efcc8fc1b6a47d74bebe76041d4188e2d1", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 1178, "deletions": 262, "changes": 1440, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=47490470c6cfde4258f471641b65fb29fd30023a", "patch": "@@ -87,6 +87,7 @@\n   ;; For AVX512F support\n   UNSPEC_VPERMI2\n   UNSPEC_VPERMT2\n+  UNSPEC_VPERMI2_MASK\n   UNSPEC_UNSIGNED_FIX_NOTRUNC\n   UNSPEC_UNSIGNED_PCMP\n   UNSPEC_TESTM\n@@ -101,9 +102,15 @@\n   UNSPEC_GETMANT\n   UNSPEC_ALIGN\n   UNSPEC_CONFLICT\n+  UNSPEC_COMPRESS\n+  UNSPEC_COMPRESS_STORE\n+  UNSPEC_EXPAND\n   UNSPEC_MASKED_EQ\n   UNSPEC_MASKED_GT\n \n+  ;; For embed. rounding feature\n+  UNSPEC_EMBEDDED_ROUNDING\n+\n   ;; For AVX512PF support\n   UNSPEC_GATHER_PREFETCH\n   UNSPEC_SCATTER_PREFETCH\n@@ -551,6 +558,12 @@\n    (V8SF \"7\") (V4DF \"3\")\n    (V4SF \"3\") (V2DF \"1\")])\n \n+(define_mode_attr ssescalarsize\n+  [(V8DI  \"64\") (V4DI  \"64\") (V2DI  \"64\")\n+   (V32HI \"16\") (V16HI \"16\") (V8HI \"16\")\n+   (V16SI \"32\") (V8SI \"32\") (V4SI \"32\")\n+   (V16SF \"32\") (V8DF \"64\")])\n+\n ;; SSE prefix for integer vector modes\n (define_mode_attr sseintprefix\n   [(V2DI  \"p\") (V2DF  \"\")\n@@ -607,6 +620,9 @@\n (define_mode_attr bcstscalarsuff\n   [(V16SI \"d\") (V16SF \"ss\") (V8DI \"q\") (V8DF \"sd\")])\n \n+;; Include define_subst patterns for instructions with mask\n+(include \"subst.md\")\n+\n ;; Patterns whose name begins with \"sse{,2,3}_\" are invoked by intrinsics.\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n@@ -746,6 +762,28 @@\n \t      ]\n \t      (const_string \"<sseinsnmode>\")))])\n \n+(define_insn \"avx512f_load<mode>_mask\"\n+  [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VI48F_512\n+\t  (match_operand:VI48F_512 1 \"nonimmediate_operand\" \"v,m\")\n+\t  (match_operand:VI48F_512 2 \"vector_move_operand\" \"0C,0C\")\n+\t  (match_operand:<avx512fmaskmode> 3 \"register_operand\" \"k,k\")))]\n+  \"TARGET_AVX512F\"\n+{\n+  switch (MODE_<sseinsnmode>)\n+    {\n+    case MODE_V8DF:\n+    case MODE_V16SF:\n+      return \"vmova<ssemodesuffix>\\t{%1, %0%{%3%}%N2|%0%{%3%}%N2, %1}\";\n+    default:\n+      return \"vmovdqa<ssescalarsize>\\t{%1, %0%{%3%}%N2|%0%{%3%}%N2, %1}\";\n+    }\n+}\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"memory\" \"none,load\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n (define_insn \"avx512f_blendm<mode>\"\n   [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v\")\n \t(vec_merge:VI48F_512\n@@ -758,6 +796,28 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+(define_insn \"avx512f_store<mode>_mask\"\n+  [(set (match_operand:VI48F_512 0 \"memory_operand\" \"=m\")\n+\t(vec_merge:VI48F_512\n+\t  (match_operand:VI48F_512 1 \"register_operand\" \"v\")\n+\t  (match_dup 0)\n+\t  (match_operand:<avx512fmaskmode> 2 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+{\n+  switch (MODE_<sseinsnmode>)\n+    {\n+    case MODE_V8DF:\n+    case MODE_V16SF:\n+      return \"vmova<ssemodesuffix>\\t{%1, %0%{%2%}|%0%{%2%}, %1}\";\n+    default:\n+      return \"vmovdqa<ssescalarsize>\\t{%1, %0%{%2%}|%0%{%2%}, %1}\";\n+    }\n+}\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n (define_insn \"sse2_movq128\"\n   [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n \t(vec_concat:V2DI\n@@ -852,21 +912,21 @@\n   DONE;\n })\n \n-(define_insn \"<sse>_loadu<ssemodesuffix><avxsizesuffix>\"\n+(define_insn \"<sse>_loadu<ssemodesuffix><avxsizesuffix><mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=v\")\n \t(unspec:VF\n \t  [(match_operand:VF 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_LOADU))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && <mask_mode512bit_condition>\"\n {\n   switch (get_attr_mode (insn))\n     {\n     case MODE_V16SF:\n     case MODE_V8SF:\n     case MODE_V4SF:\n-      return \"%vmovups\\t{%1, %0|%0, %1}\";\n+      return \"%vmovups\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n     default:\n-      return \"%vmovu<ssemodesuffix>\\t{%1, %0|%0, %1}\";\n+      return \"%vmovu<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n     }\n }\n   [(set_attr \"type\" \"ssemov\")\n@@ -913,12 +973,36 @@\n \t      ]\n \t      (const_string \"<MODE>\")))])\n \n-(define_insn \"<sse2_avx_avx512f>_loaddqu<mode>\"\n+(define_insn \"avx512f_storeu<ssemodesuffix>512_mask\"\n+  [(set (match_operand:VF_512 0 \"memory_operand\" \"=m\")\n+\t(vec_merge:VF_512\n+\t  (unspec:VF_512\n+\t    [(match_operand:VF_512 1 \"register_operand\" \"v\")]\n+\t    UNSPEC_STOREU)\n+\t  (match_dup 0)\n+\t  (match_operand:<avx512fmaskmode> 2 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+{\n+  switch (get_attr_mode (insn))\n+    {\n+    case MODE_V16SF:\n+      return \"vmovups\\t{%1, %0%{%2%}|%0%{%2%}, %1}\";\n+    default:\n+      return \"vmovu<ssemodesuffix>\\t{%1, %0%{%2%}|%0%{%2%}, %1}\";\n+    }\n+}\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"movu\" \"1\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"<sse2_avx_avx512f>_loaddqu<mode><mask_name>\"\n   [(set (match_operand:VI_UNALIGNED_LOADSTORE 0 \"register_operand\" \"=v\")\n \t(unspec:VI_UNALIGNED_LOADSTORE\n \t  [(match_operand:VI_UNALIGNED_LOADSTORE 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_LOADU))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE2 && <mask_mode512bit_condition>\"\n {\n   switch (get_attr_mode (insn))\n     {\n@@ -927,9 +1011,9 @@\n       return \"%vmovups\\t{%1, %0|%0, %1}\";\n     case MODE_XI:\n       if (<MODE>mode == V8DImode)\n-\treturn \"vmovdqu64\\t{%1, %0|%0, %1}\";\n+\treturn \"vmovdqu64\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n       else\n-\treturn \"vmovdqu32\\t{%1, %0|%0, %1}\";\n+\treturn \"vmovdqu32\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n     default:\n       return \"%vmovdqu\\t{%1, %0|%0, %1}\";\n     }\n@@ -992,6 +1076,27 @@\n \t      ]\n \t      (const_string \"<sseinsnmode>\")))])\n \n+(define_insn \"avx512f_storedqu<mode>_mask\"\n+  [(set (match_operand:VI48_512 0 \"memory_operand\" \"=m\")\n+\t(vec_merge:VI48_512\n+\t  (unspec:VI48_512\n+\t    [(match_operand:VI48_512 1 \"register_operand\" \"v\")]\n+\t    UNSPEC_STOREU)\n+\t  (match_dup 0)\n+\t  (match_operand:<avx512fmaskmode> 2 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+{\n+  if (<MODE>mode == V8DImode)\n+    return \"vmovdqu64\\t{%1, %0%{%2%}|%0%{%2%}, %1}\";\n+  else\n+    return \"vmovdqu32\\t{%1, %0%{%2%}|%0%{%2%}, %1}\";\n+}\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"movu\" \"1\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n (define_insn \"<sse3>_lddqu<avxsizesuffix>\"\n   [(set (match_operand:VI1 0 \"register_operand\" \"=x\")\n \t(unspec:VI1 [(match_operand:VI1 1 \"memory_operand\" \"m\")]\n@@ -1119,26 +1224,26 @@\n }\n   [(set_attr \"isa\" \"noavx,noavx,avx,avx\")])\n \n-(define_expand \"<plusminus_insn><mode>3\"\n+(define_expand \"<plusminus_insn><mode>3<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\")\n \t(plusminus:VF\n \t  (match_operand:VF 1 \"nonimmediate_operand\")\n \t  (match_operand:VF 2 \"nonimmediate_operand\")))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && <mask_mode512bit_condition>\"\n   \"ix86_fixup_binary_operands_no_copy (<CODE>, <MODE>mode, operands);\")\n \n-(define_insn \"*<plusminus_insn><mode>3\"\n+(define_insn \"*<plusminus_insn><mode>3<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=x,v\")\n \t(plusminus:VF\n \t  (match_operand:VF 1 \"nonimmediate_operand\" \"<comm>0,v\")\n \t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,vm\")))]\n-  \"TARGET_SSE && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)\"\n+  \"TARGET_SSE && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands) && <mask_mode512bit_condition>\"\n   \"@\n    <plusminus_mnemonic><ssemodesuffix>\\t{%2, %0|%0, %2}\n-   v<plusminus_mnemonic><ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+   v<plusminus_mnemonic><ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sseadd\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<sse>_vm<plusminus_insn><mode>3\"\n@@ -1158,26 +1263,26 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"<ssescalarmode>\")])\n \n-(define_expand \"mul<mode>3\"\n+(define_expand \"mul<mode>3<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\")\n \t(mult:VF\n \t  (match_operand:VF 1 \"nonimmediate_operand\")\n \t  (match_operand:VF 2 \"nonimmediate_operand\")))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && <mask_mode512bit_condition>\"\n   \"ix86_fixup_binary_operands_no_copy (MULT, <MODE>mode, operands);\")\n \n-(define_insn \"*mul<mode>3\"\n+(define_insn \"*mul<mode>3<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=x,v\")\n \t(mult:VF\n \t  (match_operand:VF 1 \"nonimmediate_operand\" \"%0,v\")\n \t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,vm\")))]\n-  \"TARGET_SSE && ix86_binary_operator_ok (MULT, <MODE>mode, operands)\"\n+  \"TARGET_SSE && ix86_binary_operator_ok (MULT, <MODE>mode, operands) && <mask_mode512bit_condition>\"\n   \"@\n    mul<ssemodesuffix>\\t{%2, %0|%0, %2}\n-   vmul<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+   vmul<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"ssemul\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set_attr \"btver2_decode\" \"direct,double\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n@@ -1195,7 +1300,7 @@\n    v<multdiv_mnemonic><ssescalarmodesuffix>\\t{%2, %1, %0|%0, %1, %<iptr>2}\"\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sse<multdiv_mnemonic>\")\n-   (set_attr \"prefix\" \"orig,maybe_evex\")\n+   (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"btver2_decode\" \"direct,double\")\n    (set_attr \"mode\" \"<ssescalarmode>\")])\n \n@@ -1225,18 +1330,18 @@\n     }\n })\n \n-(define_insn \"<sse>_div<mode>3\"\n+(define_insn \"<sse>_div<mode>3<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=x,v\")\n \t(div:VF\n \t  (match_operand:VF 1 \"register_operand\" \"0,v\")\n \t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,vm\")))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && <mask_mode512bit_condition>\"\n   \"@\n    div<ssemodesuffix>\\t{%2, %0|%0, %2}\n-   vdiv<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+   vdiv<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"ssediv\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<sse>_rcp<mode>2\"\n@@ -1269,18 +1374,18 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"SF\")])\n \n-(define_insn \"rcp14<mode>\"\n+(define_insn \"<mask_codefor>rcp14<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n \t(unspec:VF_512\n \t  [(match_operand:VF_512 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_RCP14))]\n   \"TARGET_AVX512F\"\n-  \"vrcp14<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"vrcp14<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"sse\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"srcp14<mode>\"\n+(define_insn \"*srcp14<mode>\"\n   [(set (match_operand:VF_128 0 \"register_operand\" \"=v\")\n \t(vec_merge:VF_128\n \t  (unspec:VF_128\n@@ -1316,11 +1421,11 @@\n     }\n })\n \n-(define_insn \"<sse>_sqrt<mode>2\"\n+(define_insn \"<sse>_sqrt<mode>2<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=v\")\n \t(sqrt:VF (match_operand:VF 1 \"nonimmediate_operand\" \"vm\")))]\n-  \"TARGET_SSE\"\n-  \"%vsqrt<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"TARGET_SSE && <mask_mode512bit_condition>\"\n+  \"%vsqrt<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"sse\")\n    (set_attr \"atom_sse_attr\" \"sqrt\")\n    (set_attr \"btver2_sse_attr\" \"sqrt\")\n@@ -1341,8 +1446,8 @@\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sse\")\n    (set_attr \"atom_sse_attr\" \"sqrt\")\n-   (set_attr \"btver2_sse_attr\" \"sqrt\")\n    (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"btver2_sse_attr\" \"sqrt\")\n    (set_attr \"mode\" \"<ssescalarmode>\")])\n \n (define_expand \"rsqrt<mode>2\"\n@@ -1365,18 +1470,18 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"rsqrt14<mode>\"\n+(define_insn \"<mask_codefor>rsqrt14<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n \t(unspec:VF_512\n \t  [(match_operand:VF_512 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_RSQRT14))]\n   \"TARGET_AVX512F\"\n-  \"vrsqrt14<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"vrsqrt14<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"sse\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"rsqrt14<mode>\"\n+(define_insn \"*rsqrt14<mode>\"\n   [(set (match_operand:VF_128 0 \"register_operand\" \"=v\")\n \t(vec_merge:VF_128\n \t  (unspec:VF_128\n@@ -1411,47 +1516,49 @@\n ;; isn't really correct, as those rtl operators aren't defined when\n ;; applied to NaNs.  Hopefully the optimizers won't get too smart on us.\n \n-(define_expand \"<code><mode>3\"\n+(define_expand \"<code><mode>3<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\")\n \t(smaxmin:VF\n \t  (match_operand:VF 1 \"nonimmediate_operand\")\n \t  (match_operand:VF 2 \"nonimmediate_operand\")))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && <mask_mode512bit_condition>\"\n {\n   if (!flag_finite_math_only)\n     operands[1] = force_reg (<MODE>mode, operands[1]);\n   ix86_fixup_binary_operands_no_copy (<CODE>, <MODE>mode, operands);\n })\n \n-(define_insn \"*<code><mode>3_finite\"\n+(define_insn \"*<code><mode>3_finite<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=x,v\")\n \t(smaxmin:VF\n \t  (match_operand:VF 1 \"nonimmediate_operand\" \"%0,v\")\n \t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,vm\")))]\n   \"TARGET_SSE && flag_finite_math_only\n-   && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)\"\n+   && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)\n+   && <mask_mode512bit_condition>\"\n   \"@\n    <maxmin_float><ssemodesuffix>\\t{%2, %0|%0, %2}\n-   v<maxmin_float><ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+   v<maxmin_float><ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sseadd\")\n    (set_attr \"btver2_sse_attr\" \"maxmin\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"*<code><mode>3\"\n+(define_insn \"*<code><mode>3<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=x,v\")\n \t(smaxmin:VF\n \t  (match_operand:VF 1 \"register_operand\" \"0,v\")\n \t  (match_operand:VF 2 \"nonimmediate_operand\" \"xm,vm\")))]\n-  \"TARGET_SSE && !flag_finite_math_only\"\n+  \"TARGET_SSE && !flag_finite_math_only\n+   && <mask_mode512bit_condition>\"\n   \"@\n    <maxmin_float><ssemodesuffix>\\t{%2, %0|%0, %2}\n-   v<maxmin_float><ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+   v<maxmin_float><ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sseadd\")\n    (set_attr \"btver2_sse_attr\" \"maxmin\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"<sse>_vm<code><mode>3\"\n@@ -2029,6 +2136,24 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<ssescalarmode>\")])\n \n+(define_insn \"avx512f_vmcmp<mode>3_mask\"\n+  [(set (match_operand:<avx512fmaskmode> 0 \"register_operand\" \"=k\")\n+\t(and:<avx512fmaskmode>\n+\t  (unspec:<avx512fmaskmode>\n+\t    [(match_operand:VF_128 1 \"register_operand\" \"v\")\n+\t     (match_operand:VF_128 2 \"nonimmediate_operand\" \"vm\")\n+\t     (match_operand:SI 3 \"const_0_to_31_operand\" \"n\")]\n+\t    UNSPEC_PCMP)\n+\t  (and:<avx512fmaskmode>\n+\t    (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")\n+\t    (const_int 1))))]\n+  \"TARGET_AVX512F\"\n+  \"vcmp<ssescalarmodesuffix>\\t{%3, %2, %1, %0%{%4%}|%0%{%4%}, %1, %2, %3}\"\n+  [(set_attr \"type\" \"ssecmp\")\n+   (set_attr \"length_immediate\" \"1\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<ssescalarmode>\")])\n+\n (define_insn \"avx512f_maskcmp<mode>3\"\n   [(set (match_operand:<avx512fmaskmode> 0 \"register_operand\" \"=k\")\n \t(match_operator:<avx512fmaskmode> 3 \"sse_comparison_operator\"\n@@ -2583,7 +2708,39 @@\n    (set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"fma_fmsub_<mode>\"\n+(define_insn \"avx512f_fmadd_<mode>_mask\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VF_512\n+\t  (fma:VF_512\n+\t    (match_operand:VF_512 1 \"register_operand\" \"0,0\")\n+\t    (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm,v\")\n+\t    (match_operand:VF_512 3 \"nonimmediate_operand\" \"v,vm\"))\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k,k\")))]\n+  \"TARGET_AVX512F\"\n+  \"@\n+   vfmadd132<ssemodesuffix>\\t{%2, %3, %0%{%4%}|%0%{%4%}, %3, %2}\n+   vfmadd213<ssemodesuffix>\\t{%3, %2, %0%{%4%}|%0%{%4%}, %2, %3}\"\n+  [(set_attr \"isa\" \"fma_avx512f,fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"avx512f_fmadd_<mode>_mask3\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=x\")\n+\t(vec_merge:VF_512\n+\t  (fma:VF_512\n+\t    (match_operand:VF_512 1 \"register_operand\" \"x\")\n+\t    (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")\n+\t    (match_operand:VF_512 3 \"register_operand\" \"0\"))\n+\t  (match_dup 3)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vfmadd231<ssemodesuffix>\\t{%2, %1, %0%{%4%}|%0%{%4%}, %1, %2}\"\n+  [(set_attr \"isa\" \"fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"*fma_fmsub_<mode>\"\n   [(set (match_operand:FMAMODE 0 \"register_operand\" \"=v,v,v,x,x\")\n \t(fma:FMAMODE\n \t  (match_operand:FMAMODE   1 \"nonimmediate_operand\" \"%0, 0, v, x,x\")\n@@ -2601,7 +2758,41 @@\n    (set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"fma_fnmadd_<mode>\"\n+(define_insn \"avx512f_fmsub_<mode>_mask\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VF_512\n+\t  (fma:VF_512\n+\t    (match_operand:VF_512 1 \"register_operand\" \"0,0\")\n+\t    (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm,v\")\n+\t    (neg:VF_512\n+\t      (match_operand:VF_512 3 \"nonimmediate_operand\" \"v,vm\")))\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k,k\")))]\n+  \"TARGET_AVX512F\"\n+  \"@\n+   vfmsub132<ssemodesuffix>\\t{%2, %3, %0%{%4%}|%0%{%4%}, %3, %2}\n+   vfmsub213<ssemodesuffix>\\t{%3, %2, %0%{%4%}|%0%{%4%}, %2, %3}\"\n+  [(set_attr \"isa\" \"fma_avx512f,fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"avx512f_fmsub_<mode>_mask3\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VF_512\n+\t  (fma:VF_512\n+\t    (match_operand:VF_512 1 \"register_operand\" \"v\")\n+\t    (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")\n+\t    (neg:VF_512\n+\t      (match_operand:VF_512 3 \"register_operand\" \"0\")))\n+\t  (match_dup 3)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vfmsub231<ssemodesuffix>\\t{%2, %1, %0%{%4%}|%0%{%4%}, %1, %2}\"\n+  [(set_attr \"isa\" \"fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"*fma_fnmadd_<mode>\"\n   [(set (match_operand:FMAMODE 0 \"register_operand\" \"=v,v,v,x,x\")\n \t(fma:FMAMODE\n \t  (neg:FMAMODE\n@@ -2619,6 +2810,40 @@\n    (set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n+(define_insn \"avx512f_fnmadd_<mode>_mask\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VF_512\n+\t  (fma:VF_512\n+\t    (neg:VF_512\n+\t      (match_operand:VF_512 1 \"register_operand\" \"0,0\"))\n+\t    (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm,v\")\n+\t    (match_operand:VF_512 3 \"nonimmediate_operand\" \"v,vm\"))\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k,k\")))]\n+  \"TARGET_AVX512F\"\n+  \"@\n+   vfnmadd132<ssemodesuffix>\\t{%2, %3, %0%{%4%}|%0%{%4%}, %3, %2}\n+   vfnmadd213<ssemodesuffix>\\t{%3, %2, %0%{%4%}|%0%{%4%}, %2, %3}\"\n+  [(set_attr \"isa\" \"fma_avx512f,fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"avx512f_fnmadd_<mode>_mask3\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VF_512\n+\t  (fma:VF_512\n+\t    (neg:VF_512\n+\t      (match_operand:VF_512 1 \"register_operand\" \"v\"))\n+\t    (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")\n+\t    (match_operand:VF_512 3 \"register_operand\" \"0\"))\n+\t  (match_dup 3)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vfnmadd231<ssemodesuffix>\\t{%2, %1, %0%{%4%}|%0%{%4%}, %1, %2}\"\n+  [(set_attr \"isa\" \"fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n (define_insn \"*fma_fnmsub_<mode>\"\n   [(set (match_operand:FMAMODE 0 \"register_operand\" \"=v,v,v,x,x\")\n \t(fma:FMAMODE\n@@ -2638,6 +2863,42 @@\n    (set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n+(define_insn \"avx512f_fnmsub_<mode>_mask\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VF_512\n+\t  (fma:VF_512\n+\t    (neg:VF_512\n+\t      (match_operand:VF_512 1 \"register_operand\" \"0,0\"))\n+\t    (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm,v\")\n+\t    (neg:VF_512\n+\t      (match_operand:VF_512 3 \"nonimmediate_operand\" \"v,vm\")))\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k,k\")))]\n+  \"TARGET_AVX512F\"\n+  \"@\n+   vfnmsub132<ssemodesuffix>\\t{%2, %3, %0%{%4%}|%0%{%4%}, %3, %2}\n+   vfnmsub213<ssemodesuffix>\\t{%3, %2, %0%{%4%}|%0%{%4%}, %2, %3}\"\n+  [(set_attr \"isa\" \"fma_avx512f,fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"avx512f_fnmsub_<mode>_mask3\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VF_512\n+\t  (fma:VF_512\n+\t    (neg:VF_512\n+\t      (match_operand:VF_512 1 \"register_operand\" \"v\"))\n+\t    (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")\n+\t    (neg:VF_512\n+\t      (match_operand:VF_512 3 \"register_operand\" \"0\")))\n+\t  (match_dup 3)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vfnmsub231<ssemodesuffix>\\t{%2, %1, %0%{%4%}|%0%{%4%}, %1, %2}\"\n+  [(set_attr \"isa\" \"fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n ;; FMA parallel floating point multiply addsub and subadd operations.\n \n ;; It would be possible to represent these without the UNSPEC as\n@@ -2676,6 +2937,40 @@\n    (set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n+(define_insn \"avx512f_fmaddsub_<mode>_mask\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VF_512\n+\t  (unspec:VF_512\n+\t    [(match_operand:VF_512 1 \"register_operand\" \"0,0\")\n+\t     (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm,v\")\n+\t     (match_operand:VF_512 3 \"nonimmediate_operand\" \"v,vm\")]\n+\t    UNSPEC_FMADDSUB)\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k,k\")))]\n+  \"TARGET_AVX512F\"\n+  \"@\n+   vfmaddsub132<ssemodesuffix>\\t{%2, %3, %0%{%4%}|%0%{%4%}, %3, %2}\n+   vfmaddsub213<ssemodesuffix>\\t{%3, %2, %0%{%4%}|%0%{%4%}, %2, %3}\"\n+  [(set_attr \"isa\" \"fma_avx512f,fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"avx512f_fmaddsub_<mode>_mask3\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VF_512\n+\t  (unspec:VF_512\n+\t    [(match_operand:VF_512 1 \"register_operand\" \"v\")\n+\t     (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")\n+\t     (match_operand:VF_512 3 \"register_operand\" \"0\")]\n+\t    UNSPEC_FMADDSUB)\n+\t  (match_dup 3)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vfmaddsub231<ssemodesuffix>\\t{%2, %1, %0%{%4%}|%0%{%4%}, %1, %2}\"\n+  [(set_attr \"isa\" \"fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n (define_insn \"*fma_fmsubadd_<mode>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=v,v,v,x,x\")\n \t(unspec:VF\n@@ -2695,6 +2990,42 @@\n    (set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n+(define_insn \"avx512f_fmsubadd_<mode>_mask\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v,v\")\n+\t(vec_merge:VF_512\n+\t  (unspec:VF_512\n+\t    [(match_operand:VF_512 1 \"register_operand\" \"0,0\")\n+\t     (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm,v\")\n+\t     (neg:VF_512\n+\t       (match_operand:VF_512 3 \"nonimmediate_operand\" \"v,vm\"))]\n+\t    UNSPEC_FMADDSUB)\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k,k\")))]\n+  \"TARGET_AVX512F\"\n+  \"@\n+   vfmsubadd132<ssemodesuffix>\\t{%2, %3, %0%{%4%}|%0%{%4%}, %3, %2}\n+   vfmsubadd213<ssemodesuffix>\\t{%3, %2, %0%{%4%}|%0%{%4%}, %2, %3}\"\n+  [(set_attr \"isa\" \"fma_avx512f,fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n+(define_insn \"avx512f_fmsubadd_<mode>_mask3\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VF_512\n+\t  (unspec:VF_512\n+\t    [(match_operand:VF_512 1 \"register_operand\" \"v\")\n+\t     (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")\n+\t     (neg:VF_512\n+\t       (match_operand:VF_512 3 \"register_operand\" \"0\"))]\n+\t    UNSPEC_FMADDSUB)\n+\t  (match_dup 3)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vfmsubadd231<ssemodesuffix>\\t{%2, %1, %0%{%4%}|%0%{%4%}, %1, %2}\"\n+  [(set_attr \"isa\" \"fma_avx512f\")\n+   (set_attr \"type\" \"ssemuladd\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n ;; FMA3 floating point scalar intrinsics. These merge result with\n ;; high-order elements from the destination register.\n \n@@ -3018,7 +3349,7 @@\n   [(set (match_operand:DI 0 \"register_operand\" \"=r,r\")\n \t(fix:DI\n \t  (vec_select:SF\n-\t    (match_operand:V4SF 1 \"nonimmediate_operand\" \"v,m\")\n+\t    (match_operand:V4SF 1 \"nonimmediate_operand\" \"v,vm\")\n \t    (parallel [(const_int 0)]))))]\n   \"TARGET_SSE && TARGET_64BIT\"\n   \"%vcvttss2si{q}\\t{%1, %0|%0, %k1}\"\n@@ -3058,22 +3389,22 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<ssescalarmode>\")])\n \n-(define_insn \"float<sseintvecmodelower><mode>2\"\n+(define_insn \"float<sseintvecmodelower><mode>2<mask_name>\"\n   [(set (match_operand:VF1 0 \"register_operand\" \"=v\")\n \t(float:VF1\n \t  (match_operand:<sseintvecmode> 1 \"nonimmediate_operand\" \"vm\")))]\n-  \"TARGET_SSE2\"\n-  \"%vcvtdq2ps\\t{%1, %0|%0, %1}\"\n+  \"TARGET_SSE2 && <mask_mode512bit_condition>\"\n+  \"%vcvtdq2ps\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"ufloatv16siv16sf2\"\n+(define_insn \"ufloatv16siv16sf2<mask_name>\"\n   [(set (match_operand:V16SF 0 \"register_operand\" \"=v\")\n \t(unsigned_float:V16SF\n \t  (match_operand:V16SI 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vcvtudq2ps\\t{%1, %0|%0, %1}\"\n+  \"vcvtudq2ps\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V16SF\")])\n@@ -3108,34 +3439,34 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_fix_notruncv16sfv16si\"\n+(define_insn \"<mask_codefor>avx512f_fix_notruncv16sfv16si<mask_name>\"\n   [(set (match_operand:V16SI 0 \"register_operand\" \"=v\")\n \t(unspec:V16SI\n \t  [(match_operand:V16SF 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_FIX_NOTRUNC))]\n   \"TARGET_AVX512F\"\n-  \"vcvtps2dq\\t{%1, %0|%0, %1}\"\n+  \"vcvtps2dq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n \n-(define_insn \"avx512f_ufix_notruncv16sfv16si\"\n+(define_insn \"<mask_codefor>avx512f_ufix_notruncv16sfv16si<mask_name>\"\n   [(set (match_operand:V16SI 0 \"register_operand\" \"=v\")\n \t(unspec:V16SI\n \t  [(match_operand:V16SF 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_UNSIGNED_FIX_NOTRUNC))]\n   \"TARGET_AVX512F\"\n-  \"vcvtps2udq\\t{%1, %0|%0, %1}\"\n+  \"vcvtps2udq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n \n-(define_insn \"<fixsuffix>fix_truncv16sfv16si2\"\n+(define_insn \"<fixsuffix>fix_truncv16sfv16si2<mask_name>\"\n   [(set (match_operand:V16SI 0 \"register_operand\" \"=v\")\n \t(any_fix:V16SI\n \t  (match_operand:V16SF 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vcvttps2<fixsuffix>dq\\t{%1, %0|%0, %1}\"\n+  \"vcvttps2<fixsuffix>dq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -3465,20 +3796,21 @@\n (define_mode_attr si2dfmodelower\n   [(V8DF \"v8si\") (V4DF \"v4si\")])\n \n-(define_insn \"float<si2dfmodelower><mode>2\"\n+(define_insn \"float<si2dfmodelower><mode>2<mask_name>\"\n   [(set (match_operand:VF2_512_256 0 \"register_operand\" \"=v\")\n \t(float:VF2_512_256 (match_operand:<si2dfmode> 1 \"nonimmediate_operand\" \"vm\")))]\n-  \"TARGET_AVX\"\n-  \"vcvtdq2pd\\t{%1, %0|%0, %1}\"\n+  \"TARGET_AVX && <mask_mode512bit_condition>\"\n+  \"vcvtdq2pd\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"ufloatv8siv8df\"\n+(define_insn \"ufloatv8siv8df<mask_name>\"\n   [(set (match_operand:V8DF 0 \"register_operand\" \"=v\")\n-\t(unsigned_float:V8DF (match_operand:V8SI 1 \"nonimmediate_operand\" \"vm\")))]\n+\t(unsigned_float:V8DF\n+\t  (match_operand:V8SI 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vcvtudq2pd\\t{%1, %0|%0, %1}\"\n+  \"vcvtudq2pd\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V8DF\")])\n@@ -3523,12 +3855,13 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"V2DF\")])\n \n-(define_insn \"avx512f_cvtpd2dq512\"\n+(define_insn \"<mask_codefor>avx512f_cvtpd2dq512<mask_name>\"\n   [(set (match_operand:V8SI 0 \"register_operand\" \"=v\")\n-\t(unspec:V8SI [(match_operand:V8DF 1 \"nonimmediate_operand\" \"vm\")]\n-\t\t     UNSPEC_FIX_NOTRUNC))]\n+\t(unspec:V8SI\n+\t  [(match_operand:V8DF 1 \"nonimmediate_operand\" \"vm\")]\n+\t  UNSPEC_FIX_NOTRUNC))]\n   \"TARGET_AVX512F\"\n-  \"vcvtpd2dq\\t{%1, %0|%0, %1}\"\n+  \"vcvtpd2dq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"OI\")])\n@@ -3596,22 +3929,23 @@\n    (set_attr \"athlon_decode\" \"vector\")\n    (set_attr \"bdver1_decode\" \"double\")])\n \n-(define_insn \"avx512f_ufix_notruncv8dfv8si\"\n+(define_insn \"avx512f_ufix_notruncv8dfv8si<mask_name>\"\n   [(set (match_operand:V8SI 0 \"register_operand\" \"=v\")\n \t(unspec:V8SI\n \t  [(match_operand:V8DF 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_UNSIGNED_FIX_NOTRUNC))]\n   \"TARGET_AVX512F\"\n-  \"vcvtpd2udq\\t{%1, %0|%0, %1}\"\n+  \"vcvtpd2udq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"OI\")])\n \n-(define_insn \"<fixsuffix>fix_truncv8dfv8si2\"\n+(define_insn \"<fixsuffix>fix_truncv8dfv8si2<mask_name>\"\n   [(set (match_operand:V8SI 0 \"register_operand\" \"=v\")\n-\t(any_fix:V8SI (match_operand:V8DF 1 \"nonimmediate_operand\" \"vm\")))]\n+\t(any_fix:V8SI\n+\t  (match_operand:V8DF 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vcvttpd2<fixsuffix>dq\\t{%1, %0|%0, %1}\"\n+  \"vcvttpd2<fixsuffix>dq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"OI\")])\n@@ -3717,12 +4051,12 @@\n    (set_attr \"prefix\" \"orig,orig,vex\")\n    (set_attr \"mode\" \"DF\")])\n \n-(define_insn \"avx512f_cvtpd2ps512\"\n+(define_insn \"<mask_codefor>avx512f_cvtpd2ps512<mask_name>\"\n   [(set (match_operand:V8SF 0 \"register_operand\" \"=v\")\n \t(float_truncate:V8SF\n \t  (match_operand:V8DF 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vcvtpd2ps\\t{%1, %0|%0, %1}\"\n+  \"vcvtpd2ps\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V8SF\")])\n@@ -3772,12 +4106,12 @@\n (define_mode_attr sf2dfmode\n   [(V8DF \"V8SF\") (V4DF \"V4SF\")])\n \n-(define_insn \"<sse2_avx_avx512f>_cvtps2pd<avxsizesuffix>\"\n+(define_insn \"<sse2_avx_avx512f>_cvtps2pd<avxsizesuffix><mask_name>\"\n   [(set (match_operand:VF2_512_256 0 \"register_operand\" \"=v\")\n \t(float_extend:VF2_512_256\n \t  (match_operand:<sf2dfmode> 1 \"nonimmediate_operand\" \"vm\")))]\n-  \"TARGET_AVX\"\n-  \"vcvtps2pd\\t{%1, %0|%0, %1}\"\n+  \"TARGET_AVX && <mask_mode512bit_condition>\"\n+  \"vcvtps2pd\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"<MODE>\")])\n@@ -4126,6 +4460,30 @@\n   DONE;\n })\n \n+(define_expand \"vec_unpacku_float_lo_v16si\"\n+  [(match_operand:V8DF 0 \"register_operand\")\n+   (match_operand:V16SI 1 \"nonimmediate_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  REAL_VALUE_TYPE TWO32r;\n+  rtx k, x, tmp[3];\n+\n+  real_ldexp (&TWO32r, &dconst1, 32);\n+  x = const_double_from_real_value (TWO32r, DFmode);\n+\n+  tmp[0] = force_reg (V8DFmode, CONST0_RTX (V8DFmode));\n+  tmp[1] = force_reg (V8DFmode, ix86_build_const_vector (V8DFmode, 1, x));\n+  tmp[2] = gen_reg_rtx (V8DFmode);\n+  k = gen_reg_rtx (QImode);\n+\n+  emit_insn (gen_avx512f_cvtdq2pd512_2 (tmp[2], operands[1]));\n+  emit_insn (gen_rtx_SET (VOIDmode, k,\n+\t\t\t  gen_rtx_LT (QImode, tmp[2], tmp[0])));\n+  emit_insn (gen_addv8df3_mask (tmp[2], tmp[2], tmp[1], tmp[2], k));\n+  emit_move_insn (operands[0], tmp[2]);\n+  DONE;\n+})\n+\n (define_expand \"vec_pack_trunc_<mode>\"\n   [(set (match_dup 3)\n \t(float_truncate:<sf2dfmode>\n@@ -4415,7 +4773,7 @@\n    (set_attr \"prefix\" \"orig,vex,orig,vex,maybe_vex\")\n    (set_attr \"mode\" \"V4SF,V4SF,V2SF,V2SF,V2SF\")])\n \n-(define_insn \"avx512f_unpckhps512\"\n+(define_insn \"<mask_codefor>avx512f_unpckhps512<mask_name>\"\n   [(set (match_operand:V16SF 0 \"register_operand\" \"=v\")\n \t(vec_select:V16SF\n \t  (vec_concat:V32SF\n@@ -4430,7 +4788,7 @@\n \t\t     (const_int 14) (const_int 30)\n \t\t     (const_int 15) (const_int 31)])))]\n   \"TARGET_AVX512F\"\n-  \"vunpckhps\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vunpckhps\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V16SF\")])\n@@ -4503,7 +4861,7 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"V4SF\")])\n \n-(define_insn \"avx512f_unpcklps512\"\n+(define_insn \"<mask_codefor>avx512f_unpcklps512<mask_name>\"\n   [(set (match_operand:V16SF 0 \"register_operand\" \"=v\")\n \t(vec_select:V16SF\n \t  (vec_concat:V32SF\n@@ -4518,7 +4876,7 @@\n \t\t     (const_int 12) (const_int 28)\n \t\t     (const_int 13) (const_int 29)])))]\n   \"TARGET_AVX512F\"\n-  \"vunpcklps\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vunpcklps\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V16SF\")])\n@@ -4626,7 +4984,7 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"V4SF\")])\n \n-(define_insn \"avx512f_movshdup512\"\n+(define_insn \"<mask_codefor>avx512f_movshdup512<mask_name>\"\n   [(set (match_operand:V16SF 0 \"register_operand\" \"=v\")\n \t(vec_select:V16SF\n \t  (vec_concat:V32SF\n@@ -4641,7 +4999,7 @@\n \t\t     (const_int 13) (const_int 13)\n \t\t     (const_int 15) (const_int 15)])))]\n   \"TARGET_AVX512F\"\n-  \"vmovshdup\\t{%1, %0|%0, %1}\"\n+  \"vmovshdup\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"sse\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V16SF\")])\n@@ -4679,7 +5037,7 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"V4SF\")])\n \n-(define_insn \"avx512f_movsldup512\"\n+(define_insn \"<mask_codefor>avx512f_movsldup512<mask_name>\"\n   [(set (match_operand:V16SF 0 \"register_operand\" \"=v\")\n \t(vec_select:V16SF\n \t  (vec_concat:V32SF\n@@ -4694,7 +5052,7 @@\n \t\t     (const_int 12) (const_int 12)\n \t\t     (const_int 14) (const_int 14)])))]\n   \"TARGET_AVX512F\"\n-  \"vmovsldup\\t{%1, %0|%0, %1}\"\n+  \"vmovsldup\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"sse\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V16SF\")])\n@@ -5228,8 +5586,71 @@\n   operands[1] = adjust_address (operands[1], SFmode, INTVAL (operands[2]) * 4);\n })\n \n-(define_insn \"avx512f_vextract<shuffletype>32x4_1\"\n-  [(set (match_operand:<ssequartermode> 0 \"nonimmediate_operand\" \"=vm\")\n+(define_expand \"avx512f_vextract<shuffletype>32x4_mask\"\n+  [(match_operand:<ssequartermode> 0 \"nonimmediate_operand\")\n+   (match_operand:V16FI 1 \"register_operand\")\n+   (match_operand:SI 2 \"const_0_to_3_operand\")\n+   (match_operand:<ssequartermode> 3 \"nonimmediate_operand\")\n+   (match_operand:QI 4 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  if (MEM_P (operands[0]) && GET_CODE (operands[3]) == CONST_VECTOR)\n+    operands[0] = force_reg (<ssequartermode>mode, operands[0]);\n+  switch (INTVAL (operands[2]))\n+    {\n+    case 0:\n+      emit_insn (gen_avx512f_vextract<shuffletype>32x4_1_mask (operands[0],\n+          operands[1], GEN_INT (0), GEN_INT (1), GEN_INT (2),\n+          GEN_INT (3), operands[3], operands[4]));\n+      break;\n+    case 1:\n+      emit_insn (gen_avx512f_vextract<shuffletype>32x4_1_mask (operands[0],\n+          operands[1], GEN_INT (4), GEN_INT (5), GEN_INT (6),\n+          GEN_INT (7), operands[3], operands[4]));\n+      break;\n+    case 2:\n+      emit_insn (gen_avx512f_vextract<shuffletype>32x4_1_mask (operands[0],\n+          operands[1], GEN_INT (8), GEN_INT (9), GEN_INT (10),\n+          GEN_INT (11), operands[3], operands[4]));\n+      break;\n+    case 3:\n+      emit_insn (gen_avx512f_vextract<shuffletype>32x4_1_mask (operands[0],\n+          operands[1], GEN_INT (12), GEN_INT (13), GEN_INT (14),\n+          GEN_INT (15), operands[3], operands[4]));\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+  DONE;\n+})\n+\n+(define_insn \"avx512f_vextract<shuffletype>32x4_1_maskm\"\n+  [(set (match_operand:<ssequartermode> 0 \"memory_operand\" \"=m\")\n+\t(vec_merge:<ssequartermode>\n+\t  (vec_select:<ssequartermode>\n+\t    (match_operand:V16FI 1 \"register_operand\" \"v\")\n+\t    (parallel [(match_operand 2  \"const_0_to_15_operand\")\n+\t      (match_operand 3  \"const_0_to_15_operand\")\n+\t      (match_operand 4  \"const_0_to_15_operand\")\n+\t      (match_operand 5  \"const_0_to_15_operand\")]))\n+\t  (match_operand:<ssequartermode> 6 \"memory_operand\" \"0\")\n+\t  (match_operand:QI 7 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F && (INTVAL (operands[2]) = INTVAL (operands[3]) - 1)\n+  && (INTVAL (operands[3]) = INTVAL (operands[4]) - 1)\n+  && (INTVAL (operands[4]) = INTVAL (operands[5]) - 1)\"\n+{\n+  operands[2] = GEN_INT ((INTVAL (operands[2])) >> 2);\n+  return \"vextract<shuffletype>32x4\\t{%2, %1, %0%{%7%}|%0%{%7%}, %1, %2}\";\n+}\n+  [(set_attr \"type\" \"sselog\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"length_immediate\" \"1\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"<mask_codefor>avx512f_vextract<shuffletype>32x4_1<mask_name>\"\n+  [(set (match_operand:<ssequartermode> 0 \"<store_mask_predicate>\" \"=<store_mask_constraint>\")\n \t(vec_select:<ssequartermode>\n \t  (match_operand:V16FI 1 \"register_operand\" \"v\")\n \t  (parallel [(match_operand 2  \"const_0_to_15_operand\")\n@@ -5241,7 +5662,7 @@\n   && (INTVAL (operands[4]) = INTVAL (operands[5]) - 1)\"\n {\n   operands[2] = GEN_INT ((INTVAL (operands[2])) >> 2);\n-  return \"vextract<shuffletype>32x4\\t{%2, %1, %0|%0, %1, %2}\";\n+  return \"vextract<shuffletype>32x4\\t{%2, %1, %0<mask_operand6>|%0<mask_operand6>, %1, %2}\";\n }\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -5253,6 +5674,35 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+(define_expand \"avx512f_vextract<shuffletype>64x4_mask\"\n+  [(match_operand:<ssehalfvecmode> 0 \"nonimmediate_operand\")\n+   (match_operand:V8FI 1 \"register_operand\")\n+   (match_operand:SI 2 \"const_0_to_1_operand\")\n+   (match_operand:<ssehalfvecmode> 3 \"nonimmediate_operand\")\n+   (match_operand:QI 4 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  rtx (*insn)(rtx, rtx, rtx, rtx);\n+\n+  if (MEM_P (operands[0]) && GET_CODE (operands[3]) == CONST_VECTOR)\n+    operands[0] = force_reg (<ssequartermode>mode, operands[0]);\n+\n+  switch (INTVAL (operands[2]))\n+    {\n+    case 0:\n+      insn = gen_vec_extract_lo_<mode>_mask;\n+      break;\n+    case 1:\n+      insn = gen_vec_extract_hi_<mode>_mask;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  emit_insn (insn (operands[0], operands[1], operands[3], operands[4]));\n+  DONE;\n+})\n+\n (define_split\n   [(set (match_operand:<ssehalfvecmode> 0 \"nonimmediate_operand\")\n \t(vec_select:<ssehalfvecmode>\n@@ -5272,14 +5722,36 @@\n   DONE;\n })\n \n-(define_insn \"vec_extract_lo_<mode>\"\n-  [(set (match_operand:<ssehalfvecmode> 0 \"nonimmediate_operand\" \"=vm\")\n+(define_insn \"vec_extract_lo_<mode>_maskm\"\n+  [(set (match_operand:<ssehalfvecmode> 0 \"memory_operand\" \"=m\")\n+\t(vec_merge:<ssehalfvecmode>\n+\t  (vec_select:<ssehalfvecmode>\n+\t    (match_operand:V8FI 1 \"register_operand\" \"v\")\n+\t    (parallel [(const_int 0) (const_int 1)\n+\t      (const_int 2) (const_int 3)]))\n+\t  (match_operand:<ssehalfvecmode> 2 \"memory_operand\" \"0\")\n+\t  (match_operand:QI 3 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+\"vextract<shuffletype>64x4\\t{$0x0, %1, %0%{%3%}|%0%{%3%}, %1, 0x0}\"\n+  [(set_attr \"type\" \"sselog\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"length_immediate\" \"1\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"vec_extract_lo_<mode><mask_name>\"\n+  [(set (match_operand:<ssehalfvecmode> 0 \"<store_mask_predicate>\" \"=<store_mask_constraint>\")\n \t(vec_select:<ssehalfvecmode>\n \t  (match_operand:V8FI 1 \"nonimmediate_operand\" \"vm\")\n \t  (parallel [(const_int 0) (const_int 1)\n             (const_int 2) (const_int 3)])))]\n   \"TARGET_AVX512F && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n-  \"#\"\n+{\n+  if (<mask_applied>)\n+    return \"vextract<shuffletype>64x4\\t{$0x0, %1, %0<mask_operand2>|%0<mask_operand2>, %1, 0x0}\";\n+  else\n+    return \"#\";\n+}\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix_extra\" \"1\")\n    (set_attr \"length_immediate\" \"1\")\n@@ -5290,14 +5762,32 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"vec_extract_hi_<mode>\"\n-  [(set (match_operand:<ssehalfvecmode> 0 \"nonimmediate_operand\" \"=vm\")\n+(define_insn \"vec_extract_hi_<mode>_maskm\"\n+  [(set (match_operand:<ssehalfvecmode> 0 \"memory_operand\" \"=m\")\n+\t(vec_merge:<ssehalfvecmode>\n+\t  (vec_select:<ssehalfvecmode>\n+\t    (match_operand:V8FI 1 \"register_operand\" \"v\")\n+\t    (parallel [(const_int 4) (const_int 5)\n+\t      (const_int 6) (const_int 7)]))\n+\t  (match_operand:<ssehalfvecmode> 2 \"memory_operand\" \"0\")\n+\t  (match_operand:QI 3 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vextract<shuffletype>64x4\\t{$0x1, %1, %0%{%3%}|%0%{%3%}, %1, 0x1}\"\n+  [(set_attr \"type\" \"sselog\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"length_immediate\" \"1\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"vec_extract_hi_<mode><mask_name>\"\n+  [(set (match_operand:<ssehalfvecmode> 0 \"<store_mask_predicate>\" \"=<store_mask_constraint>\")\n \t(vec_select:<ssehalfvecmode>\n \t  (match_operand:V8FI 1 \"register_operand\" \"v\")\n \t  (parallel [(const_int 4) (const_int 5)\n             (const_int 6) (const_int 7)])))]\n   \"TARGET_AVX512F\"\n-  \"vextract<shuffletype>64x4\\t{$0x1, %1, %0|%0, %1, 0x1}\"\n+  \"vextract<shuffletype>64x4\\t{$0x1, %1, %0<mask_operand2>|%0<mask_operand2>, %1, 0x1}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix_extra\" \"1\")\n    (set_attr \"length_immediate\" \"1\")\n@@ -5643,7 +6133,7 @@\n ;;\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_insn \"avx512f_unpckhpd512\"\n+(define_insn \"<mask_codefor>avx512f_unpckhpd512<mask_name>\"\n   [(set (match_operand:V8DF 0 \"register_operand\" \"=v\")\n \t(vec_select:V8DF\n \t  (vec_concat:V16DF\n@@ -5654,7 +6144,7 @@\n \t\t     (const_int 5) (const_int 13)\n \t\t     (const_int 7) (const_int 15)])))]\n   \"TARGET_AVX512F\"\n-  \"vunpckhpd\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vunpckhpd\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V8DF\")])\n@@ -5739,7 +6229,7 @@\n    (set_attr \"prefix\" \"orig,vex,maybe_vex,orig,vex,maybe_vex\")\n    (set_attr \"mode\" \"V2DF,V2DF,DF,V1DF,V1DF,V1DF\")])\n \n-(define_expand \"avx512f_movddup512\"\n+(define_expand \"avx512f_movddup512<mask_name>\"\n   [(set (match_operand:V8DF 0 \"register_operand\")\n \t(vec_select:V8DF\n \t  (vec_concat:V16DF\n@@ -5751,7 +6241,7 @@\n \t\t     (const_int 6) (const_int 14)])))]\n   \"TARGET_AVX512F\")\n \n-(define_expand \"avx512f_unpcklpd512\"\n+(define_expand \"avx512f_unpcklpd512<mask_name>\"\n   [(set (match_operand:V8DF 0 \"register_operand\")\n \t(vec_select:V8DF\n \t  (vec_concat:V16DF\n@@ -5763,7 +6253,7 @@\n \t\t     (const_int 6) (const_int 14)])))]\n   \"TARGET_AVX512F\")\n \n-(define_insn \"*avx512f_unpcklpd512\"\n+(define_insn \"*avx512f_unpcklpd512<mask_name>\"\n   [(set (match_operand:V8DF 0 \"register_operand\" \"=v,v\")\n \t(vec_select:V8DF\n \t  (vec_concat:V16DF\n@@ -5775,8 +6265,8 @@\n \t\t     (const_int 6) (const_int 14)])))]\n   \"TARGET_AVX512F\"\n   \"@\n-   vmovddup\\t{%1, %0|%0, %1}\n-   vunpcklpd\\t{%2, %1, %0|%0, %1, %2}\"\n+   vmovddup\\t{%1, %0<mask_operand3>|%0<mask_operand3>, %1}\n+   vunpcklpd\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V8DF\")])\n@@ -5913,26 +6403,28 @@\n   operands[1] = adjust_address (operands[1], DFmode, INTVAL (operands[2]) * 8);\n })\n \n-(define_insn \"avx512f_vmscalef<mode>\"\n+(define_insn \"*avx512f_vmscalef<mode>\"\n   [(set (match_operand:VF_128 0 \"register_operand\" \"=v\")\n \t(vec_merge:VF_128\n-\t  (unspec:VF_128 [(match_operand:VF_128 1 \"register_operand\" \"v\")\n-\t\t\t  (match_operand:VF_128 2 \"nonimmediate_operand\" \"vm\")]\n-\t\t\t UNSPEC_SCALEF)\n+\t  (unspec:VF_128\n+\t    [(match_operand:VF_128 1 \"register_operand\" \"v\")\n+\t     (match_operand:VF_128 2 \"nonimmediate_operand\" \"vm\")]\n+\t    UNSPEC_SCALEF)\n \t  (match_dup 1)\n \t  (const_int 1)))]\n   \"TARGET_AVX512F\"\n   \"%vscalef<ssescalarmodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\"  \"<ssescalarmode>\")])\n \n-(define_insn \"avx512f_scalef<mode>\"\n+(define_insn \"avx512f_scalef<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n-\t(unspec:VF_512 [(match_operand:VF_512 1 \"register_operand\" \"v\")\n-\t\t\t(match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")]\n-\t\t       UNSPEC_SCALEF))]\n+\t(unspec:VF_512\n+\t  [(match_operand:VF_512 1 \"register_operand\" \"v\")\n+\t   (match_operand:VF_512 2 \"nonimmediate_operand\" \"vm\")]\n+\t  UNSPEC_SCALEF))]\n   \"TARGET_AVX512F\"\n-  \"%vscalef<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"%vscalef<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\"  \"<MODE>\")])\n \n@@ -5950,39 +6442,88 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_getexp<mode>\"\n+(define_insn \"avx512f_vternlog<mode>_mask\"\n+  [(set (match_operand:VI48_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VI48_512\n+\t  (unspec:VI48_512\n+\t    [(match_operand:VI48_512 1 \"register_operand\" \"0\")\n+\t     (match_operand:VI48_512 2 \"register_operand\" \"v\")\n+\t     (match_operand:VI48_512 3 \"nonimmediate_operand\" \"vm\")\n+\t     (match_operand:SI 4 \"const_0_to_255_operand\")]\n+\t    UNSPEC_VTERNLOG)\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 5 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vpternlog<ssemodesuffix>\\t{%4, %3, %2, %0%{%5%}|%0%{%5%}, %2, %3, %4}\"\n+  [(set_attr \"type\" \"sselog\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"avx512f_getexp<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n         (unspec:VF_512 [(match_operand:VF_512 1 \"nonimmediate_operand\" \"vm\")]\n                         UNSPEC_GETEXP))]\n    \"TARGET_AVX512F\"\n-   \"vgetexp<ssemodesuffix>\\t{%1, %0|%0, %1}\";\n+   \"vgetexp<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\";\n     [(set_attr \"prefix\" \"evex\")\n      (set_attr \"mode\" \"<MODE>\")])\n \n (define_insn \"avx512f_sgetexp<mode>\"\n   [(set (match_operand:VF_128 0 \"register_operand\" \"=v\")\n \t(vec_merge:VF_128\n-\t  (unspec:VF_128 [(match_operand:VF_128 1 \"register_operand\" \"v\")\n-\t\t\t  (match_operand:VF_128 2 \"nonimmediate_operand\" \"vm\")]\n-\t\t\t UNSPEC_GETEXP)\n+\t  (unspec:VF_128\n+\t    [(match_operand:VF_128 1 \"register_operand\" \"v\")\n+\t     (match_operand:VF_128 2 \"nonimmediate_operand\" \"vm\")]\n+\t    UNSPEC_GETEXP)\n \t  (match_dup 1)\n \t  (const_int 1)))]\n    \"TARGET_AVX512F\"\n    \"vgetexp<ssescalarmodesuffix>\\t{%2, %1, %0|%0, %1, %2}\";\n     [(set_attr \"prefix\" \"evex\")\n      (set_attr \"mode\" \"<ssescalarmode>\")])\n \n-(define_insn \"avx512f_align<mode>\"\n+(define_insn \"<mask_codefor>avx512f_align<mode><mask_name>\"\n   [(set (match_operand:VI48_512 0 \"register_operand\" \"=v\")\n         (unspec:VI48_512 [(match_operand:VI48_512 1 \"register_operand\" \"v\")\n \t\t\t  (match_operand:VI48_512 2 \"nonimmediate_operand\" \"vm\")\n \t\t\t  (match_operand:SI 3 \"const_0_to_255_operand\")]\n \t\t\t UNSPEC_ALIGN))]\n   \"TARGET_AVX512F\"\n-  \"valign<ssemodesuffix>\\t{%3, %2, %1, %0|%0, %1, %2, %3}\";\n+  \"valign<ssemodesuffix>\\t{%3, %2, %1, %0<mask_operand4>|%0<mask_operand4>, %1, %2, %3}\";\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+(define_expand \"avx512f_shufps512_mask\"\n+  [(match_operand:V16SF 0 \"register_operand\")\n+   (match_operand:V16SF 1 \"register_operand\")\n+   (match_operand:V16SF 2 \"nonimmediate_operand\")\n+   (match_operand:SI 3 \"const_0_to_255_operand\")\n+   (match_operand:V16SF 4 \"register_operand\")\n+   (match_operand:HI 5 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  int mask = INTVAL (operands[3]);\n+  emit_insn (gen_avx512f_shufps512_1_mask (operands[0], operands[1], operands[2],\n+\t\t\t\t\t  GEN_INT ((mask >> 0) & 3),\n+\t\t\t\t\t  GEN_INT ((mask >> 2) & 3),\n+\t\t\t\t\t  GEN_INT (((mask >> 4) & 3) + 16),\n+\t\t\t\t\t  GEN_INT (((mask >> 6) & 3) + 16),\n+\t\t\t\t\t  GEN_INT (((mask >> 0) & 3) + 4),\n+\t\t\t\t\t  GEN_INT (((mask >> 2) & 3) + 4),\n+\t\t\t\t\t  GEN_INT (((mask >> 4) & 3) + 20),\n+\t\t\t\t\t  GEN_INT (((mask >> 6) & 3) + 20),\n+\t\t\t\t\t  GEN_INT (((mask >> 0) & 3) + 8),\n+\t\t\t\t\t  GEN_INT (((mask >> 2) & 3) + 8),\n+\t\t\t\t\t  GEN_INT (((mask >> 4) & 3) + 24),\n+\t\t\t\t\t  GEN_INT (((mask >> 6) & 3) + 24),\n+\t\t\t\t\t  GEN_INT (((mask >> 0) & 3) + 12),\n+\t\t\t\t\t  GEN_INT (((mask >> 2) & 3) + 12),\n+\t\t\t\t\t  GEN_INT (((mask >> 4) & 3) + 28),\n+\t\t\t\t\t  GEN_INT (((mask >> 6) & 3) + 28),\n+\t\t\t\t\t  operands[4], operands[5]));\n+  DONE;\n+})\n+\n (define_insn \"avx512f_fixupimm<mode>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n         (unspec:VF_512\n@@ -5996,6 +6537,22 @@\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n+(define_insn \"avx512f_fixupimm<mode>_mask\"\n+  [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VF_512\n+          (unspec:VF_512\n+            [(match_operand:VF_512 1 \"register_operand\" \"0\")\n+\t     (match_operand:VF_512 2 \"register_operand\" \"v\")\n+             (match_operand:<sseintvecmode> 3 \"nonimmediate_operand\" \"vm\")\n+             (match_operand:SI 4 \"const_0_to_255_operand\")]\n+             UNSPEC_FIXUPIMM)\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 5 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vfixupimm<ssemodesuffix>\\t{%4, %3, %2, %0%{%5%}|%0%{%5%}, %2, %3, %4}\";\n+  [(set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<MODE>\")])\n+\n (define_insn \"avx512f_sfixupimm<mode>\"\n   [(set (match_operand:VF_128 0 \"register_operand\" \"=v\")\n \t(vec_merge:VF_128\n@@ -6012,19 +6569,38 @@\n    [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<ssescalarmode>\")])\n \n-(define_insn \"avx512f_rndscale<mode>\"\n+(define_insn \"avx512f_sfixupimm<mode>_mask\"\n+  [(set (match_operand:VF_128 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VF_128\n+\t  (vec_merge:VF_128\n+\t    (unspec:VF_128\n+\t       [(match_operand:VF_128 1 \"register_operand\" \"0\")\n+\t\t(match_operand:VF_128 2 \"register_operand\" \"v\")\n+\t\t(match_operand:<sseintvecmode> 3 \"nonimmediate_operand\" \"vm\")\n+\t\t(match_operand:SI 4 \"const_0_to_255_operand\")]\n+\t       UNSPEC_FIXUPIMM)\n+\t    (match_dup 1)\n+\t    (const_int 1))\n+\t  (match_dup 1)\n+\t  (match_operand:<avx512fmaskmode> 5 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vfixupimm<ssescalarmodesuffix>\\t{%4, %3, %2, %0%{%5%}|%0%{%5%}, %2, %3, %4}\";\n+  [(set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<ssescalarmode>\")])\n+\n+(define_insn \"avx512f_rndscale<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n \t(unspec:VF_512\n \t  [(match_operand:VF_512 1 \"nonimmediate_operand\" \"vm\")\n \t   (match_operand:SI 2 \"const_0_to_255_operand\")]\n \t  UNSPEC_ROUND))]\n   \"TARGET_AVX512F\"\n-  \"vrndscale<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vrndscale<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"length_immediate\" \"1\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"avx512f_rndscale<mode>\"\n+(define_insn \"*avx512f_rndscale<mode>\"\n   [(set (match_operand:VF_128 0 \"register_operand\" \"=v\")\n \t(vec_merge:VF_128\n \t  (unspec:VF_128\n@@ -6041,7 +6617,7 @@\n    (set_attr \"mode\" \"<MODE>\")])\n \n ;; One bit in mask selects 2 elements.\n-(define_insn \"avx512f_shufps512_1\"\n+(define_insn \"avx512f_shufps512_1<mask_name>\"\n   [(set (match_operand:V16SF 0 \"register_operand\" \"=v\")\n \t(vec_select:V16SF\n \t  (vec_concat:V32SF\n@@ -6084,14 +6660,37 @@\n   mask |= (INTVAL (operands[6]) - 16) << 6;\n   operands[3] = GEN_INT (mask);\n \n-  return \"vshufps\\t{%3, %2, %1, %0|%0, %1, %2, %3}\";\n+  return \"vshufps\\t{%3, %2, %1, %0<mask_operand19>|%0<mask_operand19>, %1, %2, %3}\";\n }\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V16SF\")])\n \n-(define_insn \"avx512f_shufpd512_1\"\n+(define_expand \"avx512f_shufpd512_mask\"\n+  [(match_operand:V8DF 0 \"register_operand\")\n+   (match_operand:V8DF 1 \"register_operand\")\n+   (match_operand:V8DF 2 \"nonimmediate_operand\")\n+   (match_operand:SI 3 \"const_0_to_255_operand\")\n+   (match_operand:V8DF 4 \"register_operand\")\n+   (match_operand:QI 5 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  int mask = INTVAL (operands[3]);\n+  emit_insn (gen_avx512f_shufpd512_1_mask (operands[0], operands[1], operands[2],\n+\t\t\t\t\tGEN_INT (mask & 1),\n+\t\t\t\t\tGEN_INT (mask & 2 ? 9 : 8),\n+\t\t\t\t\tGEN_INT (mask & 4 ? 3 : 2),\n+\t\t\t\t\tGEN_INT (mask & 8 ? 11 : 10),\n+\t\t\t\t\tGEN_INT (mask & 16 ? 5 : 4),\n+\t\t\t\t\tGEN_INT (mask & 32 ? 13 : 12),\n+\t\t\t\t\tGEN_INT (mask & 64 ? 7 : 6),\n+\t\t\t\t\tGEN_INT (mask & 128 ? 15 : 14),\n+\t\t\t\t\toperands[4], operands[5]));\n+  DONE;\n+})\n+\n+(define_insn \"avx512f_shufpd512_1<mask_name>\"\n   [(set (match_operand:V8DF 0 \"register_operand\" \"=v\")\n \t(vec_select:V8DF\n \t  (vec_concat:V16DF\n@@ -6118,7 +6717,7 @@\n   mask |= (INTVAL (operands[10]) - 14) << 7;\n   operands[3] = GEN_INT (mask);\n \n-  return \"vshufpd\\t{%3, %2, %1, %0|%0, %1, %2, %3}\";\n+  return \"vshufpd\\t{%3, %2, %1, %0<mask_operand11>|%0<mask_operand11>, %1, %2, %3}\";\n }\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"length_immediate\" \"1\")\n@@ -6198,7 +6797,7 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"OI\")])\n \n-(define_insn \"avx512f_interleave_highv8di\"\n+(define_insn \"<mask_codefor>avx512f_interleave_highv8di<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\" \"=v\")\n \t(vec_select:V8DI\n \t  (vec_concat:V16DI\n@@ -6209,7 +6808,7 @@\n \t\t     (const_int 5) (const_int 13)\n \t\t     (const_int 7) (const_int 15)])))]\n   \"TARGET_AVX512F\"\n-  \"vpunpckhqdq\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vpunpckhqdq\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -6248,7 +6847,7 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"OI\")])\n \n-(define_insn \"avx512f_interleave_lowv8di\"\n+(define_insn \"<mask_codefor>avx512f_interleave_lowv8di<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\" \"=v\")\n \t(vec_select:V8DI\n \t  (vec_concat:V16DI\n@@ -6259,7 +6858,7 @@\n \t\t     (const_int 4) (const_int 12)\n \t\t     (const_int 6) (const_int 14)])))]\n   \"TARGET_AVX512F\"\n-  \"vpunpcklqdq\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vpunpcklqdq\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -6630,6 +7229,20 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+(define_insn \"avx512f_<code><pmov_src_lower><mode>2_mask\"\n+  [(set (match_operand:PMOV_DST_MODE 0 \"nonimmediate_operand\" \"=v,m\")\n+    (vec_merge:PMOV_DST_MODE\n+      (any_truncate:PMOV_DST_MODE\n+        (match_operand:<pmov_src_mode> 1 \"register_operand\" \"v,v\"))\n+      (match_operand:PMOV_DST_MODE 2 \"vector_move_operand\" \"0C,0\")\n+      (match_operand:<avx512fmaskmode> 3 \"register_operand\" \"k,k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vpmov<trunsuffix><pmov_suff>\\t{%1, %0%{%3%}%N2|%0%{%3%}%N2, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"memory\" \"none,store\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n (define_insn \"*avx512f_<code>v8div16qi2\"\n   [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n \t(vec_concat:V16QI\n@@ -6663,6 +7276,55 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn \"avx512f_<code>v8div16qi2_mask\"\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n+    (vec_concat:V16QI\n+      (vec_merge:V8QI\n+        (any_truncate:V8QI\n+          (match_operand:V8DI 1 \"register_operand\" \"v\"))\n+        (vec_select:V8QI\n+          (match_operand:V16QI 2 \"vector_move_operand\" \"0C\")\n+          (parallel [(const_int 0) (const_int 1)\n+                     (const_int 2) (const_int 3)\n+                     (const_int 4) (const_int 5)\n+                     (const_int 6) (const_int 7)]))\n+        (match_operand:QI 3 \"register_operand\" \"k\"))\n+      (const_vector:V8QI [(const_int 0) (const_int 0)\n+                          (const_int 0) (const_int 0)\n+                          (const_int 0) (const_int 0)\n+                          (const_int 0) (const_int 0)])))]\n+  \"TARGET_AVX512F\"\n+  \"vpmov<trunsuffix>qb\\t{%1, %0%{%3%}%N2|%0%{%3%}%N2, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"TI\")])\n+\n+(define_insn \"*avx512f_<code>v8div16qi2_store_mask\"\n+  [(set (match_operand:V16QI 0 \"memory_operand\" \"=m\")\n+    (vec_concat:V16QI\n+      (vec_merge:V8QI\n+        (any_truncate:V8QI\n+          (match_operand:V8DI 1 \"register_operand\" \"v\"))\n+        (vec_select:V8QI\n+          (match_dup 0)\n+          (parallel [(const_int 0) (const_int 1)\n+                     (const_int 2) (const_int 3)\n+                     (const_int 4) (const_int 5)\n+                     (const_int 6) (const_int 7)]))\n+        (match_operand:QI 2 \"register_operand\" \"k\"))\n+      (vec_select:V8QI\n+        (match_dup 0)\n+        (parallel [(const_int 8) (const_int 9)\n+                   (const_int 10) (const_int 11)\n+                   (const_int 12) (const_int 13)\n+                   (const_int 14) (const_int 15)]))))]\n+  \"TARGET_AVX512F\"\n+  \"vpmov<trunsuffix>qb\\t{%1, %0%{%2%}|%0%{%2%}, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"TI\")])\n+\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;;\n ;; Parallel integral arithmetic\n@@ -6677,27 +7339,27 @@\n   \"TARGET_SSE2\"\n   \"operands[2] = force_reg (<MODE>mode, CONST0_RTX (<MODE>mode));\")\n \n-(define_expand \"<plusminus_insn><mode>3\"\n+(define_expand \"<plusminus_insn><mode>3<mask_name>\"\n   [(set (match_operand:VI_AVX2 0 \"register_operand\")\n \t(plusminus:VI_AVX2\n \t  (match_operand:VI_AVX2 1 \"nonimmediate_operand\")\n \t  (match_operand:VI_AVX2 2 \"nonimmediate_operand\")))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE2 && <mask_mode512bit_condition>\"\n   \"ix86_fixup_binary_operands_no_copy (<CODE>, <MODE>mode, operands);\")\n \n-(define_insn \"*<plusminus_insn><mode>3\"\n+(define_insn \"*<plusminus_insn><mode>3<mask_name>\"\n   [(set (match_operand:VI_AVX2 0 \"register_operand\" \"=x,v\")\n \t(plusminus:VI_AVX2\n \t  (match_operand:VI_AVX2 1 \"nonimmediate_operand\" \"<comm>0,v\")\n \t  (match_operand:VI_AVX2 2 \"nonimmediate_operand\" \"xm,vm\")))]\n-  \"TARGET_SSE2 && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)\"\n+  \"TARGET_SSE2 && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands) && <mask_mode512bit_condition>\"\n   \"@\n    p<plusminus_mnemonic><ssemodesuffix>\\t{%2, %0|%0, %2}\n-   vp<plusminus_mnemonic><ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+   vp<plusminus_mnemonic><ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sseiadd\")\n    (set_attr \"prefix_data16\" \"1,*\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n (define_expand \"<sse2_avx2>_<plusminus_insn><mode>3\"\n@@ -6787,7 +7449,7 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_expand \"vec_widen_umult_even_v16si\"\n+(define_expand \"vec_widen_umult_even_v16si<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\")\n         (mult:V8DI\n           (zero_extend:V8DI\n@@ -6807,7 +7469,7 @@\n   \"TARGET_AVX512F\"\n   \"ix86_fixup_binary_operands_no_copy (MULT, V16SImode, operands);\")\n \n-(define_insn \"*vec_widen_umult_even_v16si\"\n+(define_insn \"*vec_widen_umult_even_v16si<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\" \"=v\")\n         (mult:V8DI\n           (zero_extend:V8DI\n@@ -6825,7 +7487,7 @@\n                          (const_int 8) (const_int 10)\n                          (const_int 12) (const_int 14)])))))]\n   \"TARGET_AVX512F && ix86_binary_operator_ok (MULT, V16SImode, operands)\"\n-  \"vpmuludq\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vpmuludq\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"avx512f\")\n    (set_attr \"type\" \"sseimul\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -6902,7 +7564,7 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_expand \"vec_widen_smult_even_v16si\"\n+(define_expand \"vec_widen_smult_even_v16si<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\")\n         (mult:V8DI\n           (sign_extend:V8DI\n@@ -6922,7 +7584,7 @@\n   \"TARGET_AVX512F\"\n   \"ix86_fixup_binary_operands_no_copy (MULT, V16SImode, operands);\")\n \n-(define_insn \"*vec_widen_smult_even_v16si\"\n+(define_insn \"*vec_widen_smult_even_v16si<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\" \"=v\")\n         (mult:V8DI\n           (sign_extend:V8DI\n@@ -6940,7 +7602,7 @@\n                          (const_int 8) (const_int 10)\n                          (const_int 12) (const_int 14)])))))]\n   \"TARGET_AVX512F && ix86_binary_operator_ok (MULT, V16SImode, operands)\"\n-  \"vpmuldq\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vpmuldq\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"avx512f\")\n    (set_attr \"type\" \"sseimul\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -7150,12 +7812,12 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_expand \"mul<mode>3\"\n+(define_expand \"mul<mode>3<mask_name>\"\n   [(set (match_operand:VI4_AVX512F 0 \"register_operand\")\n \t(mult:VI4_AVX512F\n \t  (match_operand:VI4_AVX512F 1 \"general_vector_operand\")\n \t  (match_operand:VI4_AVX512F 2 \"general_vector_operand\")))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE2 && <mask_mode512bit_condition>\"\n {\n   if (TARGET_SSE4_1)\n     {\n@@ -7172,19 +7834,19 @@\n     }\n })\n \n-(define_insn \"*<sse4_1_avx2>_mul<mode>3\"\n+(define_insn \"*<sse4_1_avx2>_mul<mode>3<mask_name>\"\n   [(set (match_operand:VI4_AVX512F 0 \"register_operand\" \"=x,v\")\n \t(mult:VI4_AVX512F\n \t  (match_operand:VI4_AVX512F 1 \"nonimmediate_operand\" \"%0,v\")\n \t  (match_operand:VI4_AVX512F 2 \"nonimmediate_operand\" \"xm,vm\")))]\n-  \"TARGET_SSE4_1 && ix86_binary_operator_ok (MULT, <MODE>mode, operands)\"\n+  \"TARGET_SSE4_1 && ix86_binary_operator_ok (MULT, <MODE>mode, operands) && <mask_mode512bit_condition>\"\n   \"@\n    pmulld\\t{%2, %0|%0, %2}\n-   vpmulld\\t{%2, %1, %0|%0, %1, %2}\"\n+   vpmulld\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"noavx,avx\")\n    (set_attr \"type\" \"sseimul\")\n    (set_attr \"prefix_extra\" \"1\")\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set_attr \"btver2_decode\" \"vector,vector\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n@@ -7297,6 +7959,20 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+(define_insn \"ashr<mode>3<mask_name>\"\n+  [(set (match_operand:VI48_512 0 \"register_operand\" \"=v,v\")\n+\t(ashiftrt:VI48_512\n+\t  (match_operand:VI48_512 1 \"nonimmediate_operand\" \"v,vm\")\n+\t  (match_operand:SI 2 \"nonmemory_operand\" \"v,N\")))]\n+  \"TARGET_AVX512F && <mask_mode512bit_condition>\"\n+  \"vpsra<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n+  [(set_attr \"type\" \"sseishft\")\n+   (set (attr \"length_immediate\")\n+     (if_then_else (match_operand 2 \"const_int_operand\")\n+       (const_string \"1\")\n+       (const_string \"0\")))\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n (define_insn \"<shift_insn><mode>3\"\n   [(set (match_operand:VI248_AVX2 0 \"register_operand\" \"=x,x\")\n \t(any_lshift:VI248_AVX2\n@@ -7316,13 +7992,13 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"<shift_insn><mode>3\"\n+(define_insn \"<shift_insn><mode>3<mask_name>\"\n   [(set (match_operand:VI48_512 0 \"register_operand\" \"=v,v\")\n \t(any_lshift:VI48_512\n \t  (match_operand:VI48_512 1 \"register_operand\" \"v,m\")\n \t  (match_operand:SI 2 \"nonmemory_operand\" \"vN,N\")))]\n-  \"TARGET_AVX512F\"\n-  \"vp<vshift><ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"TARGET_AVX512F && <mask_mode512bit_condition>\"\n+  \"vp<vshift><ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"isa\" \"avx512f\")\n    (set_attr \"type\" \"sseishft\")\n    (set (attr \"length_immediate\")\n@@ -7332,6 +8008,7 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+\n (define_expand \"vec_shl_<mode>\"\n   [(set (match_dup 3)\n \t(ashift:V1TI\n@@ -7411,41 +8088,42 @@\n    (set_attr \"prefix\" \"orig,vex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_<rotate>v<mode>\"\n+(define_insn \"avx512f_<rotate>v<mode><mask_name>\"\n   [(set (match_operand:VI48_512 0 \"register_operand\" \"=v\")\n \t(any_rotate:VI48_512\n \t  (match_operand:VI48_512 1 \"register_operand\" \"v\")\n \t  (match_operand:VI48_512 2 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vp<rotate>v<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vp<rotate>v<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_<rotate><mode>\"\n+(define_insn \"avx512f_<rotate><mode><mask_name>\"\n   [(set (match_operand:VI48_512 0 \"register_operand\" \"=v\")\n \t(any_rotate:VI48_512\n \t  (match_operand:VI48_512 1 \"nonimmediate_operand\" \"vm\")\n \t  (match_operand:SI 2 \"const_0_to_255_operand\")))]\n   \"TARGET_AVX512F\"\n-  \"vp<rotate><ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vp<rotate><ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_expand \"<code><mode>3\"\n+(define_expand \"<code><mode>3<mask_name>\"\n   [(set (match_operand:VI124_256_48_512 0 \"register_operand\")\n \t(maxmin:VI124_256_48_512\n \t  (match_operand:VI124_256_48_512 1 \"nonimmediate_operand\")\n \t  (match_operand:VI124_256_48_512 2 \"nonimmediate_operand\")))]\n-  \"TARGET_AVX2\"\n+  \"TARGET_AVX2 && <mask_mode512bit_condition>\"\n   \"ix86_fixup_binary_operands_no_copy (<CODE>, <MODE>mode, operands);\")\n \n-(define_insn \"*avx2_<code><mode>3\"\n+(define_insn \"*avx2_<code><mode>3<mask_name>\"\n   [(set (match_operand:VI124_256_48_512 0 \"register_operand\" \"=v\")\n \t(maxmin:VI124_256_48_512\n \t  (match_operand:VI124_256_48_512 1 \"nonimmediate_operand\" \"%v\")\n \t  (match_operand:VI124_256_48_512 2 \"nonimmediate_operand\" \"vm\")))]\n-  \"TARGET_AVX2 && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)\"\n-  \"vp<maxmin_int><ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"TARGET_AVX2 && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)\n+   && <mask_mode512bit_condition>\"\n+  \"vp<maxmin_int><ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sseiadd\")\n    (set_attr \"prefix_extra\" \"1\")\n    (set_attr \"prefix\" \"maybe_evex\")\n@@ -7981,19 +8659,19 @@\n   operands[2] = force_reg (<MODE>mode, gen_rtx_CONST_VECTOR (<MODE>mode, v));\n })\n \n-(define_expand \"<sse2_avx2>_andnot<mode>3\"\n+(define_expand \"<sse2_avx2>_andnot<mode>3<mask_name>\"\n   [(set (match_operand:VI_AVX2 0 \"register_operand\")\n \t(and:VI_AVX2\n \t  (not:VI_AVX2 (match_operand:VI_AVX2 1 \"register_operand\"))\n \t  (match_operand:VI_AVX2 2 \"nonimmediate_operand\")))]\n-  \"TARGET_SSE2\")\n+  \"TARGET_SSE2 && <mask_mode512bit_condition>\")\n \n-(define_insn \"*andnot<mode>3\"\n+(define_insn \"*andnot<mode>3<mask_name>\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=x,v\")\n \t(and:VI\n \t  (not:VI (match_operand:VI 1 \"register_operand\" \"0,v\"))\n \t  (match_operand:VI 2 \"nonimmediate_operand\" \"xm,vm\")))]\n-  \"TARGET_SSE\"\n+  \"TARGET_SSE && <mask_mode512bit_condition>\"\n {\n   static char buf[64];\n   const char *ops;\n@@ -8033,7 +8711,7 @@\n       ops = \"%s\\t{%%2, %%0|%%0, %%2}\";\n       break;\n     case 1:\n-      ops = \"v%s\\t{%%2, %%1, %%0|%%0, %%1, %%2}\";\n+      ops = \"v%s\\t{%%2, %%1, %%0<mask_operand3_1>|%%0<mask_operand3_1>, %%1, %%2}\";\n       break;\n     default:\n       gcc_unreachable ();\n@@ -8050,7 +8728,7 @@\n \t    (eq_attr \"mode\" \"TI\"))\n        (const_string \"1\")\n        (const_string \"*\")))\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set (attr \"mode\")\n \t(cond [(match_test \"TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\")\n \t\t (const_string \"<ssePSmode>\")\n@@ -8078,12 +8756,12 @@\n   DONE;\n })\n \n-(define_insn \"*<code><mode>3\"\n+(define_insn \"<mask_codefor><code><mode>3<mask_name>\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=x,v\")\n \t(any_logic:VI\n \t  (match_operand:VI 1 \"nonimmediate_operand\" \"%0,v\")\n \t  (match_operand:VI 2 \"nonimmediate_operand\" \"xm,vm\")))]\n-  \"TARGET_SSE\n+  \"TARGET_SSE && <mask_mode512bit_condition>\n    && ix86_binary_operator_ok (<CODE>, <MODE>mode, operands)\"\n {\n   static char buf[64];\n@@ -8125,7 +8803,7 @@\n       ops = \"%s\\t{%%2, %%0|%%0, %%2}\";\n       break;\n     case 1:\n-      ops = \"v%s\\t{%%2, %%1, %%0|%%0, %%1, %%2}\";\n+      ops = \"v%s\\t{%%2, %%1, %%0<mask_operand3_1>|%%0<mask_operand3_1>, %%1, %%2}\";\n       break;\n     default:\n       gcc_unreachable ();\n@@ -8142,7 +8820,7 @@\n \t    (eq_attr \"mode\" \"TI\"))\n        (const_string \"1\")\n        (const_string \"*\")))\n-   (set_attr \"prefix\" \"orig,vex\")\n+   (set_attr \"prefix\" \"<mask_prefix3>\")\n    (set (attr \"mode\")\n \t(cond [(match_test \"TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\")\n \t\t (const_string \"<ssePSmode>\")\n@@ -8450,7 +9128,7 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"OI\")])\n \n-(define_insn \"avx512f_interleave_highv16si\"\n+(define_insn \"<mask_codefor>avx512f_interleave_highv16si<mask_name>\"\n   [(set (match_operand:V16SI 0 \"register_operand\" \"=v\")\n \t(vec_select:V16SI\n \t  (vec_concat:V32SI\n@@ -8465,7 +9143,7 @@\n \t\t     (const_int 14) (const_int 30)\n \t\t     (const_int 15) (const_int 31)])))]\n   \"TARGET_AVX512F\"\n-  \"vpunpckhdq\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vpunpckhdq\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -8505,7 +9183,7 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"OI\")])\n \n-(define_insn \"avx512f_interleave_lowv16si\"\n+(define_insn \"<mask_codefor>avx512f_interleave_lowv16si<mask_name>\"\n   [(set (match_operand:V16SI 0 \"register_operand\" \"=v\")\n \t(vec_select:V16SI\n \t  (vec_concat:V32SI\n@@ -8520,7 +9198,7 @@\n \t\t     (const_int 12) (const_int 28)\n \t\t     (const_int 13) (const_int 29)])))]\n   \"TARGET_AVX512F\"\n-  \"vpunpckldq\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vpunpckldq\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -8645,7 +9323,45 @@\n    (set_attr \"prefix\" \"orig,orig,vex,vex\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"avx512f_vinsert<shuffletype>32x4_1\"\n+(define_expand \"avx512f_vinsert<shuffletype>32x4_mask\"\n+  [(match_operand:V16FI 0 \"register_operand\")\n+   (match_operand:V16FI 1 \"register_operand\")\n+   (match_operand:<ssequartermode> 2 \"nonimmediate_operand\")\n+   (match_operand:SI 3 \"const_0_to_3_operand\")\n+   (match_operand:V16FI 4 \"register_operand\")\n+   (match_operand:<avx512fmaskmode> 5 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  switch (INTVAL (operands[3]))\n+    {\n+    case 0:\n+      emit_insn (gen_avx512f_vinsert<shuffletype>32x4_1_mask (operands[0],\n+          operands[1], operands[2], GEN_INT (0xFFF), operands[4],\n+\t  operands[5]));\n+      break;\n+    case 1:\n+      emit_insn (gen_avx512f_vinsert<shuffletype>32x4_1_mask (operands[0],\n+          operands[1], operands[2], GEN_INT (0xF0FF), operands[4],\n+\t  operands[5]));\n+      break;\n+    case 2:\n+      emit_insn (gen_avx512f_vinsert<shuffletype>32x4_1_mask (operands[0],\n+          operands[1], operands[2], GEN_INT (0xFF0F), operands[4],\n+\t  operands[5]));\n+      break;\n+    case 3:\n+      emit_insn (gen_avx512f_vinsert<shuffletype>32x4_1_mask (operands[0],\n+          operands[1], operands[2], GEN_INT (0xFFF0), operands[4],\n+\t  operands[5]));\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+  DONE;\n+\n+})\n+\n+(define_insn \"<mask_codefor>avx512f_vinsert<shuffletype>32x4_1<mask_name>\"\n   [(set (match_operand:V16FI 0 \"register_operand\" \"=v\")\n \t(vec_merge:V16FI\n \t  (match_operand:V16FI 1 \"register_operand\" \"v\")\n@@ -8668,14 +9384,35 @@\n \n   operands[3] = GEN_INT (mask);\n \n-  return \"vinsert<shuffletype>32x4\\t{%3, %2, %1, %0|%0, %1, %2, %3}\";\n+  return \"vinsert<shuffletype>32x4\\t{%3, %2, %1, %0<mask_operand4>|%0<mask_operand4>, %1, %2, %3}\";\n }\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"vec_set_lo_<mode>\"\n+(define_expand \"avx512f_vinsert<shuffletype>64x4_mask\"\n+  [(match_operand:V8FI 0 \"register_operand\")\n+   (match_operand:V8FI 1 \"register_operand\")\n+   (match_operand:<ssehalfvecmode> 2 \"nonimmediate_operand\")\n+   (match_operand:SI 3 \"const_0_to_1_operand\")\n+   (match_operand:V8FI 4 \"register_operand\")\n+   (match_operand:<avx512fmaskmode> 5 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  int mask = INTVAL (operands[3]);\n+  if (mask == 0)\n+    emit_insn (gen_vec_set_lo_<mode>_mask\n+      (operands[0], operands[1], operands[2],\n+       operands[4], operands[5]));\n+  else\n+    emit_insn (gen_vec_set_hi_<mode>_mask\n+      (operands[0], operands[1], operands[2],\n+       operands[4], operands[5]));\n+  DONE;\n+})\n+\n+(define_insn \"vec_set_lo_<mode><mask_name>\"\n   [(set (match_operand:V8FI 0 \"register_operand\" \"=v\")\n \t(vec_concat:V8FI\n \t  (match_operand:<ssehalfvecmode> 2 \"nonimmediate_operand\" \"vm\")\n@@ -8684,13 +9421,13 @@\n \t    (parallel [(const_int 4) (const_int 5)\n               (const_int 6) (const_int 7)]))))]\n   \"TARGET_AVX512F\"\n-  \"vinsert<shuffletype>64x4\\t{$0x0, %2, %1, %0|%0, %1, %2, $0x0}\"\n+  \"vinsert<shuffletype>64x4\\t{$0x0, %2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2, $0x0}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n \n-(define_insn \"vec_set_hi_<mode>\"\n+(define_insn \"vec_set_hi_<mode><mask_name>\"\n   [(set (match_operand:V8FI 0 \"register_operand\" \"=v\")\n \t(vec_concat:V8FI\n \t  (match_operand:<ssehalfvecmode> 2 \"nonimmediate_operand\" \"vm\")\n@@ -8699,13 +9436,37 @@\n \t    (parallel [(const_int 0) (const_int 1)\n               (const_int 2) (const_int 3)]))))]\n   \"TARGET_AVX512F\"\n-  \"vinsert<shuffletype>64x4\\t{$0x1, %2, %1, %0|%0, %1, %2, $0x1}\"\n+  \"vinsert<shuffletype>64x4\\t{$0x1, %2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2, $0x1}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n \n-(define_insn \"avx512f_shuf_<shuffletype>64x2_1\"\n+(define_expand \"avx512f_shuf_<shuffletype>64x2_mask\"\n+  [(match_operand:V8FI 0 \"register_operand\")\n+   (match_operand:V8FI 1 \"register_operand\")\n+   (match_operand:V8FI 2 \"nonimmediate_operand\")\n+   (match_operand:SI 3 \"const_0_to_255_operand\")\n+   (match_operand:V8FI 4 \"register_operand\")\n+   (match_operand:QI 5 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  int mask = INTVAL (operands[3]);\n+  emit_insn (gen_avx512f_shuf_<shuffletype>64x2_1_mask\n+      (operands[0], operands[1], operands[2],\n+       GEN_INT (((mask >> 0) & 3) * 2),\n+       GEN_INT (((mask >> 0) & 3) * 2 + 1),\n+       GEN_INT (((mask >> 2) & 3) * 2),\n+       GEN_INT (((mask >> 2) & 3) * 2 + 1),\n+       GEN_INT (((mask >> 4) & 3) * 2 + 8),\n+       GEN_INT (((mask >> 4) & 3) * 2 + 9),\n+       GEN_INT (((mask >> 6) & 3) * 2 + 8),\n+       GEN_INT (((mask >> 6) & 3) * 2 + 9),\n+       operands[4], operands[5]));\n+  DONE;\n+})\n+\n+(define_insn \"avx512f_shuf_<shuffletype>64x2_1<mask_name>\"\n   [(set (match_operand:V8FI 0 \"register_operand\" \"=v\")\n \t(vec_select:V8FI\n \t  (vec_concat:<ssedoublemode>\n@@ -8732,14 +9493,46 @@\n   mask |= (INTVAL (operands[9]) - 8) / 2 << 6;\n   operands[3] = GEN_INT (mask);\n \n-  return \"vshuf<shuffletype>64x2\\t{%3, %2, %1, %0|%0, %1, %2, %3}\";\n+  return \"vshuf<shuffletype>64x2\\t{%3, %2, %1, %0<mask_operand11>|%0<mask_operand11>, %1, %2, %3}\";\n }\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_shuf_<shuffletype>32x4_1\"\n+(define_expand \"avx512f_shuf_<shuffletype>32x4_mask\"\n+  [(match_operand:V16FI 0 \"register_operand\")\n+   (match_operand:V16FI 1 \"register_operand\")\n+   (match_operand:V16FI 2 \"nonimmediate_operand\")\n+   (match_operand:SI 3 \"const_0_to_255_operand\")\n+   (match_operand:V16FI 4 \"register_operand\")\n+   (match_operand:HI 5 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  int mask = INTVAL (operands[3]);\n+  emit_insn (gen_avx512f_shuf_<shuffletype>32x4_1_mask\n+      (operands[0], operands[1], operands[2],\n+       GEN_INT (((mask >> 0) & 3) * 4),\n+       GEN_INT (((mask >> 0) & 3) * 4 + 1),\n+       GEN_INT (((mask >> 0) & 3) * 4 + 2),\n+       GEN_INT (((mask >> 0) & 3) * 4 + 3),\n+       GEN_INT (((mask >> 2) & 3) * 4),\n+       GEN_INT (((mask >> 2) & 3) * 4 + 1),\n+       GEN_INT (((mask >> 2) & 3) * 4 + 2),\n+       GEN_INT (((mask >> 2) & 3) * 4 + 3),\n+       GEN_INT (((mask >> 4) & 3) * 4 + 16),\n+       GEN_INT (((mask >> 4) & 3) * 4 + 17),\n+       GEN_INT (((mask >> 4) & 3) * 4 + 18),\n+       GEN_INT (((mask >> 4) & 3) * 4 + 19),\n+       GEN_INT (((mask >> 6) & 3) * 4 + 16),\n+       GEN_INT (((mask >> 6) & 3) * 4 + 17),\n+       GEN_INT (((mask >> 6) & 3) * 4 + 18),\n+       GEN_INT (((mask >> 6) & 3) * 4 + 19),\n+       operands[4], operands[5]));\n+  DONE;\n+})\n+\n+(define_insn \"avx512f_shuf_<shuffletype>32x4_1<mask_name>\"\n   [(set (match_operand:V16FI 0 \"register_operand\" \"=v\")\n \t(vec_select:V16FI\n \t  (vec_concat:<ssedoublemode>\n@@ -8782,14 +9575,44 @@\n   mask |= (INTVAL (operands[15]) - 16) / 4 << 6;\n   operands[3] = GEN_INT (mask);\n \n-  return \"vshuf<shuffletype>32x4\\t{%3, %2, %1, %0|%0, %1, %2, %3}\";\n+  return \"vshuf<shuffletype>32x4\\t{%3, %2, %1, %0<mask_operand19>|%0<mask_operand19>, %1, %2, %3}\";\n }\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_pshufd_1\"\n+(define_expand \"avx512f_pshufdv3_mask\"\n+  [(match_operand:V16SI 0 \"register_operand\")\n+   (match_operand:V16SI 1 \"nonimmediate_operand\")\n+   (match_operand:SI 2 \"const_0_to_255_operand\")\n+   (match_operand:V16SI 3 \"register_operand\")\n+   (match_operand:HI 4 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  int mask = INTVAL (operands[2]);\n+  emit_insn (gen_avx512f_pshufd_1_mask (operands[0], operands[1],\n+\t\t\t\t       GEN_INT ((mask >> 0) & 3),\n+\t\t\t\t       GEN_INT ((mask >> 2) & 3),\n+\t\t\t\t       GEN_INT ((mask >> 4) & 3),\n+\t\t\t\t       GEN_INT ((mask >> 6) & 3),\n+\t\t\t\t       GEN_INT (((mask >> 0) & 3) + 4),\n+\t\t\t\t       GEN_INT (((mask >> 2) & 3) + 4),\n+\t\t\t\t       GEN_INT (((mask >> 4) & 3) + 4),\n+\t\t\t\t       GEN_INT (((mask >> 6) & 3) + 4),\n+\t\t\t\t       GEN_INT (((mask >> 0) & 3) + 8),\n+\t\t\t\t       GEN_INT (((mask >> 2) & 3) + 8),\n+\t\t\t\t       GEN_INT (((mask >> 4) & 3) + 8),\n+\t\t\t\t       GEN_INT (((mask >> 6) & 3) + 8),\n+\t\t\t\t       GEN_INT (((mask >> 0) & 3) + 12),\n+\t\t\t\t       GEN_INT (((mask >> 2) & 3) + 12),\n+\t\t\t\t       GEN_INT (((mask >> 4) & 3) + 12),\n+\t\t\t\t       GEN_INT (((mask >> 6) & 3) + 12),\n+\t\t\t\t       operands[3], operands[4]));\n+  DONE;\n+})\n+\n+(define_insn \"avx512f_pshufd_1<mask_name>\"\n   [(set (match_operand:V16SI 0 \"register_operand\" \"=v\")\n \t(vec_select:V16SI\n \t  (match_operand:V16SI 1 \"nonimmediate_operand\" \"vm\")\n@@ -8830,7 +9653,7 @@\n   mask |= INTVAL (operands[5]) << 6;\n   operands[2] = GEN_INT (mask);\n \n-  return \"vpshufd\\t{%2, %1, %0|%0, %1, %2}\";\n+  return \"vpshufd\\t{%2, %1, %0<mask_operand18>|%0<mask_operand18>, %1, %2}\";\n }\n   [(set_attr \"type\" \"sselog1\")\n    (set_attr \"prefix\" \"evex\")\n@@ -10281,12 +11104,12 @@\n    (set (attr \"prefix_rex\") (symbol_ref \"x86_extended_reg_mentioned_p (insn)\"))\n    (set_attr \"mode\" \"DI\")])\n \n-(define_insn \"*abs<mode>2\"\n+(define_insn \"<mask_codefor>abs<mode>2<mask_name>\"\n   [(set (match_operand:VI124_AVX2_48_AVX512F 0 \"register_operand\" \"=v\")\n \t(abs:VI124_AVX2_48_AVX512F\n \t  (match_operand:VI124_AVX2_48_AVX512F 1 \"nonimmediate_operand\" \"vm\")))]\n-  \"TARGET_SSSE3\"\n-  \"%vpabs<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"TARGET_SSSE3 && <mask_mode512bit_condition>\"\n+  \"%vpabs<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"sselog1\")\n    (set_attr \"prefix_data16\" \"1\")\n    (set_attr \"prefix_extra\" \"1\")\n@@ -10640,12 +11463,12 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"avx512f_<code>v16qiv16si2\"\n+(define_insn \"<mask_codefor>avx512f_<code>v16qiv16si2<mask_name>\"\n   [(set (match_operand:V16SI 0 \"register_operand\" \"=v\")\n \t(any_extend:V16SI\n \t  (match_operand:V16QI 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vpmov<extsuffix>bd\\t{%1, %0|%0, %q1}\"\n+  \"vpmov<extsuffix>bd\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %q1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -10680,12 +11503,12 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"avx512f_<code>v16hiv16si2\"\n+(define_insn \"avx512f_<code>v16hiv16si2<mask_name>\"\n   [(set (match_operand:V16SI 0 \"register_operand\" \"=v\")\n \t(any_extend:V16SI\n \t  (match_operand:V16HI 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vpmov<extsuffix>wd\\t{%1, %0|%0, %1}\"\n+  \"vpmov<extsuffix>wd\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -10715,7 +11538,7 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"avx512f_<code>v8qiv8di2\"\n+(define_insn \"avx512f_<code>v8qiv8di2<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\" \"=v\")\n \t(any_extend:V8DI\n \t  (vec_select:V8QI\n@@ -10725,7 +11548,7 @@\n \t\t       (const_int 4) (const_int 5)\n \t\t       (const_int 6) (const_int 7)]))))]\n   \"TARGET_AVX512F\"\n-  \"vpmov<extsuffix>bq\\t{%1, %0|%0, %k1}\"\n+  \"vpmov<extsuffix>bq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %k1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -10757,12 +11580,12 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"avx512f_<code>v8hiv8di2\"\n+(define_insn \"avx512f_<code>v8hiv8di2<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\" \"=v\")\n \t(any_extend:V8DI\n \t  (match_operand:V8HI 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vpmov<extsuffix>wq\\t{%1, %0|%0, %q1}\"\n+  \"vpmov<extsuffix>wq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %q1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -10794,12 +11617,12 @@\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"avx512f_<code>v8siv8di2\"\n+(define_insn \"avx512f_<code>v8siv8di2<mask_name>\"\n   [(set (match_operand:V8DI 0 \"register_operand\" \"=v\")\n \t(any_extend:V8DI\n \t  (match_operand:V8SI 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"vpmov<extsuffix>dq\\t{%1, %0|%0, %1}\"\n+  \"vpmov<extsuffix>dq\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n@@ -11582,33 +12405,33 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"XI\")])\n \n-(define_insn \"*avx512er_exp2<mode>\"\n+(define_insn \"avx512er_exp2<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n \t(unspec:VF_512\n \t  [(match_operand:VF_512 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_EXP2))]\n   \"TARGET_AVX512ER\"\n-  \"vexp2<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"vexp2<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"*avx512er_rcp28<mode>\"\n+(define_insn \"<mask_codefor>avx512er_rcp28<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n \t(unspec:VF_512\n \t  [(match_operand:VF_512 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_RCP28))]\n   \"TARGET_AVX512ER\"\n-  \"vrcp28<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"vrcp28<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n-(define_insn \"avx512er_rsqrt28<mode>\"\n+(define_insn \"<mask_codefor>avx512er_rsqrt28<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n \t(unspec:VF_512\n \t  [(match_operand:VF_512 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_RSQRT28))]\n   \"TARGET_AVX512ER\"\n-  \"vrsqrt28<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"vrsqrt28<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n@@ -12658,16 +13481,16 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"<avx2_avx512f>_permvar<mode>\"\n+(define_insn \"<avx2_avx512f>_permvar<mode><mask_name>\"\n   [(set (match_operand:VI48F_256_512 0 \"register_operand\" \"=v\")\n \t(unspec:VI48F_256_512\n \t  [(match_operand:VI48F_256_512 1 \"nonimmediate_operand\" \"vm\")\n \t   (match_operand:<sseintvecmode> 2 \"register_operand\" \"v\")]\n \t  UNSPEC_VPERMVAR))]\n-  \"TARGET_AVX2\"\n-  \"vperm<ssemodesuffix>\\t{%1, %2, %0|%0, %2, %1}\"\n+  \"TARGET_AVX2 && <mask_mode512bit_condition>\"\n+  \"vperm<ssemodesuffix>\\t{%1, %2, %0<mask_operand3>|%0<mask_operand3>, %2, %1}\"\n   [(set_attr \"type\" \"sselog\")\n-   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"prefix\" \"<mask_prefix2>\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n (define_expand \"<avx2_avx512f>_perm<mode>\"\n@@ -12678,33 +13501,51 @@\n {\n   int mask = INTVAL (operands[2]);\n   emit_insn (gen_<avx2_avx512f>_perm<mode>_1 (operands[0], operands[1],\n-\t\t\t\t\t    GEN_INT ((mask >> 0) & 3),\n-\t\t\t\t\t    GEN_INT ((mask >> 2) & 3),\n-\t\t\t\t\t    GEN_INT ((mask >> 4) & 3),\n-\t\t\t\t\t    GEN_INT ((mask >> 6) & 3)));\n+\t\t\t\t\t      GEN_INT ((mask >> 0) & 3),\n+\t\t\t\t\t      GEN_INT ((mask >> 2) & 3),\n+\t\t\t\t\t      GEN_INT ((mask >> 4) & 3),\n+\t\t\t\t\t      GEN_INT ((mask >> 6) & 3)));\n+  DONE;\n+})\n+\n+(define_expand \"avx512f_perm<mode>_mask\"\n+  [(match_operand:V8FI 0 \"register_operand\")\n+   (match_operand:V8FI 1 \"nonimmediate_operand\")\n+   (match_operand:SI 2 \"const_0_to_255_operand\")\n+   (match_operand:V8FI 3 \"vector_move_operand\")\n+   (match_operand:<avx512fmaskmode> 4 \"register_operand\")]\n+  \"TARGET_AVX512F\"\n+{\n+  int mask = INTVAL (operands[2]);\n+  emit_insn (gen_<avx2_avx512f>_perm<mode>_1_mask (operands[0], operands[1],\n+\t\t\t\t\t\t   GEN_INT ((mask >> 0) & 3),\n+\t\t\t\t\t\t   GEN_INT ((mask >> 2) & 3),\n+\t\t\t\t\t\t   GEN_INT ((mask >> 4) & 3),\n+\t\t\t\t\t\t   GEN_INT ((mask >> 6) & 3),\n+\t\t\t\t\t\t   operands[3], operands[4]));\n   DONE;\n })\n \n-(define_insn \"<avx2_avx512f>_perm<mode>_1\"\n+(define_insn \"<avx2_avx512f>_perm<mode>_1<mask_name>\"\n   [(set (match_operand:VI8F_256_512 0 \"register_operand\" \"=v\")\n \t(vec_select:VI8F_256_512\n \t  (match_operand:VI8F_256_512 1 \"nonimmediate_operand\" \"vm\")\n \t  (parallel [(match_operand 2 \"const_0_to_3_operand\")\n \t\t     (match_operand 3 \"const_0_to_3_operand\")\n \t\t     (match_operand 4 \"const_0_to_3_operand\")\n \t\t     (match_operand 5 \"const_0_to_3_operand\")])))]\n-  \"TARGET_AVX2\"\n+  \"TARGET_AVX2 && <mask_mode512bit_condition>\"\n {\n   int mask = 0;\n   mask |= INTVAL (operands[2]) << 0;\n   mask |= INTVAL (operands[3]) << 2;\n   mask |= INTVAL (operands[4]) << 4;\n   mask |= INTVAL (operands[5]) << 6;\n   operands[2] = GEN_INT (mask);\n-  return \"vperm<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\";\n+  return \"vperm<ssemodesuffix>\\t{%2, %1, %0<mask_operand6>|%0<mask_operand6>, %1, %2}\";\n }\n   [(set_attr \"type\" \"sselog\")\n-   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"prefix\" \"<mask_prefix2>\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n (define_insn \"avx2_permv2ti\"\n@@ -12751,58 +13592,58 @@\n    (set_attr \"isa\" \"*,avx2,noavx2\")\n    (set_attr \"mode\" \"V8SF\")])\n \n-(define_insn \"avx512f_vec_dup<mode>\"\n+(define_insn \"<mask_codefor>avx512f_vec_dup<mode><mask_name>\"\n   [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v\")\n \t(vec_duplicate:VI48F_512\n \t  (vec_select:<ssescalarmode>\n \t    (match_operand:<ssexmmmode> 1 \"nonimmediate_operand\" \"vm\")\n \t    (parallel [(const_int 0)]))))]\n   \"TARGET_AVX512F\"\n-  \"v<sseintprefix>broadcast<bcstscalarsuff>\\t{%1, %0|%0, %1}\"\n+  \"v<sseintprefix>broadcast<bcstscalarsuff>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_broadcast<mode>\"\n+(define_insn \"<mask_codefor>avx512f_broadcast<mode><mask_name>\"\n   [(set (match_operand:V16FI 0 \"register_operand\" \"=v,v\")\n \t(vec_duplicate:V16FI\n \t  (match_operand:<ssexmmmode> 1 \"nonimmediate_operand\" \"v,m\")))]\n   \"TARGET_AVX512F\"\n   \"@\n-   vshuf<shuffletype>32x4\\t{$0x0, %g1, %g1, %0|%0, %g1, %g1, 0x0}\n-   vbroadcast<shuffletype>32x4\\t{%1, %0|%0, %1}\"\n+   vshuf<shuffletype>32x4\\t{$0x0, %g1, %g1, %0<mask_operand2>|%0<mask_operand2>, %g1, %g1, 0x0}\n+   vbroadcast<shuffletype>32x4\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_broadcast<mode>\"\n+(define_insn \"<mask_codefor>avx512f_broadcast<mode><mask_name>\"\n   [(set (match_operand:V8FI 0 \"register_operand\" \"=v,v\")\n \t(vec_duplicate:V8FI\n \t  (match_operand:<ssehalfvecmode> 1 \"nonimmediate_operand\" \"v,m\")))]\n   \"TARGET_AVX512F\"\n   \"@\n-   vshuf<shuffletype>64x2\\t{$0x44, %g1, %g1, %0|%0, %g1, %g1, 0x44}\n-   vbroadcast<shuffletype>64x4\\t{%1, %0|%0, %1}\"\n+   vshuf<shuffletype>64x2\\t{$0x44, %g1, %g1, %0<mask_operand2>|%0<mask_operand2>, %g1, %g1, 0x44}\n+   vbroadcast<shuffletype>64x4\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_vec_dup_gpr<mode>\"\n+(define_insn \"<mask_codefor>avx512f_vec_dup_gpr<mode><mask_name>\"\n   [(set (match_operand:VI48_512 0 \"register_operand\" \"=v\")\n \t(vec_duplicate:VI48_512\n \t  (match_operand:<ssescalarmode> 1 \"register_operand\" \"r\")))]\n   \"TARGET_AVX512F && (<MODE>mode != V8DImode || TARGET_64BIT)\"\n-  \"vpbroadcast<bcstscalarsuff>\\t{%1, %0|%0, %1}\"\n+  \"vpbroadcast<bcstscalarsuff>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_vec_dup_mem<mode>\"\n+(define_insn \"<mask_codefor>avx512f_vec_dup_mem<mode><mask_name>\"\n   [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v\")\n \t(vec_duplicate:VI48F_512\n \t  (match_operand:<ssescalarmode> 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512F\"\n-  \"v<sseintprefix>broadcast<bcstscalarsuff>\\t{%1, %0|%0, %1}\"\n+  \"v<sseintprefix>broadcast<bcstscalarsuff>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n@@ -12942,12 +13783,12 @@\n \t\t\t\telt * GET_MODE_SIZE (<ssescalarmode>mode));\n })\n \n-(define_expand \"<sse2_avx_avx512f>_vpermil<mode>\"\n+(define_expand \"<sse2_avx_avx512f>_vpermil<mode><mask_name>\"\n   [(set (match_operand:VF2 0 \"register_operand\")\n \t(vec_select:VF2\n \t  (match_operand:VF2 1 \"nonimmediate_operand\")\n \t  (match_operand:SI 2 \"const_0_to_255_operand\")))]\n-  \"TARGET_AVX\"\n+  \"TARGET_AVX && <mask_mode512bit_condition>\"\n {\n   int mask = INTVAL (operands[2]);\n   rtx perm[<ssescalarnum>];\n@@ -12963,12 +13804,12 @@\n     = gen_rtx_PARALLEL (VOIDmode, gen_rtvec_v (<ssescalarnum>, perm));\n })\n \n-(define_expand \"<sse2_avx_avx512f>_vpermil<mode>\"\n+(define_expand \"<sse2_avx_avx512f>_vpermil<mode><mask_name>\"\n   [(set (match_operand:VF1 0 \"register_operand\")\n \t(vec_select:VF1\n \t  (match_operand:VF1 1 \"nonimmediate_operand\")\n \t  (match_operand:SI 2 \"const_0_to_255_operand\")))]\n-  \"TARGET_AVX\"\n+  \"TARGET_AVX && <mask_mode512bit_condition>\"\n {\n   int mask = INTVAL (operands[2]);\n   rtx perm[<ssescalarnum>];\n@@ -12986,37 +13827,37 @@\n     = gen_rtx_PARALLEL (VOIDmode, gen_rtvec_v (<ssescalarnum>, perm));\n })\n \n-(define_insn \"*<sse2_avx_avx512f>_vpermilp<mode>\"\n+(define_insn \"*<sse2_avx_avx512f>_vpermilp<mode><mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=v\")\n \t(vec_select:VF\n \t  (match_operand:VF 1 \"nonimmediate_operand\" \"vm\")\n \t  (match_parallel 2 \"\"\n \t    [(match_operand 3 \"const_int_operand\")])))]\n-  \"TARGET_AVX\n+  \"TARGET_AVX && <mask_mode512bit_condition>\n    && avx_vpermilp_parallel (operands[2], <MODE>mode)\"\n {\n   int mask = avx_vpermilp_parallel (operands[2], <MODE>mode) - 1;\n   operands[2] = GEN_INT (mask);\n-  return \"vpermil<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\";\n+  return \"vpermil<ssemodesuffix>\\t{%2, %1, %0<mask_operand4>|%0<mask_operand4>, %1, %2}\";\n }\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix_extra\" \"1\")\n    (set_attr \"length_immediate\" \"1\")\n-   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"prefix\" \"<mask_prefix>\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"<sse2_avx_avx512f>_vpermilvar<mode>3\"\n+(define_insn \"<sse2_avx_avx512f>_vpermilvar<mode>3<mask_name>\"\n   [(set (match_operand:VF 0 \"register_operand\" \"=v\")\n \t(unspec:VF\n \t  [(match_operand:VF 1 \"register_operand\" \"v\")\n \t   (match_operand:<sseintvecmode> 2 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_VPERMIL))]\n-  \"TARGET_AVX\"\n-  \"vpermil<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"TARGET_AVX && <mask_mode512bit_condition>\"\n+  \"vpermil<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix_extra\" \"1\")\n    (set_attr \"btver2_decode\" \"vector\")\n-   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"prefix\" \"<mask_prefix>\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n (define_insn \"avx512f_vpermi2var<mode>3\"\n@@ -13032,6 +13873,22 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+(define_insn \"avx512f_vpermi2var<mode>3_mask\"\n+  [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VI48F_512\n+\t  (unspec:VI48F_512\n+\t    [(match_operand:VI48F_512 1 \"register_operand\" \"v\")\n+\t    (match_operand:<sseintvecmode> 2 \"register_operand\" \"0\")\n+\t    (match_operand:VI48F_512 3 \"nonimmediate_operand\" \"vm\")]\n+\t    UNSPEC_VPERMI2_MASK)\n+\t  (match_dup 0)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vpermi2<ssemodesuffix>\\t{%3, %1, %0%{%4%}|%0%{%4%}, %1, %3}\"\n+  [(set_attr \"type\" \"sselog\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n (define_insn \"avx512f_vpermt2var<mode>3\"\n   [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v\")\n \t(unspec:VI48F_512\n@@ -13045,6 +13902,22 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n+(define_insn \"avx512f_vpermt2var<mode>3_mask\"\n+  [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v\")\n+\t(vec_merge:VI48F_512\n+\t  (unspec:VI48F_512\n+\t    [(match_operand:<sseintvecmode> 1 \"register_operand\" \"v\")\n+\t    (match_operand:VI48F_512 2 \"register_operand\" \"0\")\n+\t    (match_operand:VI48F_512 3 \"nonimmediate_operand\" \"vm\")]\n+\t    UNSPEC_VPERMT2)\n+\t  (match_dup 2)\n+\t  (match_operand:<avx512fmaskmode> 4 \"register_operand\" \"k\")))]\n+  \"TARGET_AVX512F\"\n+  \"vpermt2<ssemodesuffix>\\t{%3, %1, %0%{%4%}|%0%{%4%}, %1, %3}\"\n+  [(set_attr \"type\" \"sselog\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n (define_expand \"avx_vperm2f128<mode>3\"\n   [(set (match_operand:AVX256MODE2P 0 \"register_operand\")\n \t(unspec:AVX256MODE2P\n@@ -13435,24 +14308,24 @@\n   DONE;\n })\n \n-(define_insn \"<avx2_avx512f>_ashrv<mode>\"\n+(define_insn \"<avx2_avx512f>_ashrv<mode><mask_name>\"\n   [(set (match_operand:VI48_AVX512F 0 \"register_operand\" \"=v\")\n \t(ashiftrt:VI48_AVX512F\n \t  (match_operand:VI48_AVX512F 1 \"register_operand\" \"v\")\n \t  (match_operand:VI48_AVX512F 2 \"nonimmediate_operand\" \"vm\")))]\n-  \"TARGET_AVX2\"\n-  \"vpsrav<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"TARGET_AVX2 && <mask_mode512bit_condition>\"\n+  \"vpsrav<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n    (set_attr \"prefix\" \"maybe_evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"<avx2_avx512f>_<shift_insn>v<mode>\"\n+(define_insn \"<avx2_avx512f>_<shift_insn>v<mode><mask_name>\"\n   [(set (match_operand:VI48_AVX2_48_AVX512F 0 \"register_operand\" \"=v\")\n \t(any_lshift:VI48_AVX2_48_AVX512F\n \t  (match_operand:VI48_AVX2_48_AVX512F 1 \"register_operand\" \"v\")\n \t  (match_operand:VI48_AVX2_48_AVX512F 2 \"nonimmediate_operand\" \"vm\")))]\n-  \"TARGET_AVX2\"\n-  \"vp<vshift>v<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"TARGET_AVX2 && <mask_mode512bit_condition>\"\n+  \"vp<vshift>v<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n    (set_attr \"prefix\" \"maybe_evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n@@ -13535,12 +14408,13 @@\n    (set_attr \"btver2_decode\" \"double\")\n    (set_attr \"mode\" \"V8SF\")])\n \n-(define_insn \"avx512f_vcvtph2ps512\"\n+(define_insn \"<mask_codefor>avx512f_vcvtph2ps512<mask_name>\"\n   [(set (match_operand:V16SF 0 \"register_operand\" \"=v\")\n-\t(unspec:V16SF [(match_operand:V16HI 1 \"nonimmediate_operand\" \"vm\")]\n-\t\t      UNSPEC_VCVTPH2PS))]\n+\t(unspec:V16SF\n+\t  [(match_operand:V16HI 1 \"nonimmediate_operand\" \"vm\")]\n+\t  UNSPEC_VCVTPH2PS))]\n   \"TARGET_AVX512F\"\n-  \"vcvtph2ps\\t{%1, %0|%0, %1}\"\n+  \"vcvtph2ps\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V16SF\")])\n@@ -13591,13 +14465,14 @@\n    (set_attr \"btver2_decode\" \"vector\")\n    (set_attr \"mode\" \"V8SF\")])\n \n-(define_insn \"avx512f_vcvtps2ph512\"\n+(define_insn \"<mask_codefor>avx512f_vcvtps2ph512<mask_name>\"\n   [(set (match_operand:V16HI 0 \"nonimmediate_operand\" \"=vm\")\n-\t(unspec:V16HI [(match_operand:V16SF 1 \"register_operand\" \"v\")\n-\t\t      (match_operand:SI 2 \"const_0_to_255_operand\" \"N\")]\n-\t\t     UNSPEC_VCVTPS2PH))]\n+\t(unspec:V16HI\n+\t  [(match_operand:V16SF 1 \"register_operand\" \"v\")\n+\t   (match_operand:SI 2 \"const_0_to_255_operand\" \"N\")]\n+\t  UNSPEC_VCVTPS2PH))]\n   \"TARGET_AVX512F\"\n-  \"vcvtps2ph\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"vcvtps2ph\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\"\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"V16SF\")])\n@@ -13987,14 +14862,55 @@\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"avx512f_getmant<mode>\"\n+(define_insn \"avx512f_compress<mode>_mask\"\n+  [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v\")\n+\t(unspec:VI48F_512\n+\t  [(match_operand:VI48F_512 1 \"register_operand\" \"v\")\n+\t   (match_operand:VI48F_512 2 \"vector_move_operand\" \"0C\")\n+\t   (match_operand:<avx512fmaskmode> 3 \"register_operand\" \"k\")]\n+\t  UNSPEC_COMPRESS))]\n+  \"TARGET_AVX512F\"\n+  \"v<sseintprefix>compress<ssemodesuffix>\\t{%1, %0%{%3%}%N2|%0%{%3%}%N2, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"avx512f_compressstore<mode>_mask\"\n+  [(set (match_operand:VI48F_512 0 \"memory_operand\" \"=m\")\n+\t(unspec:VI48F_512\n+\t  [(match_operand:VI48F_512 1 \"register_operand\" \"x\")\n+\t   (match_dup 0)\n+\t   (match_operand:<avx512fmaskmode> 2 \"register_operand\" \"k\")]\n+\t  UNSPEC_COMPRESS_STORE))]\n+  \"TARGET_AVX512F\"\n+  \"v<sseintprefix>compress<ssemodesuffix>\\t{%1, %0%{%2%}|%0%{%2%}, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"avx512f_expand<mode>_mask\"\n+  [(set (match_operand:VI48F_512 0 \"register_operand\" \"=v,v\")\n+\t(unspec:VI48F_512\n+\t  [(match_operand:VI48F_512 1 \"nonimmediate_operand\" \"v,m\")\n+\t   (match_operand:VI48F_512 2 \"vector_move_operand\" \"0C,0C\")\n+\t   (match_operand:<avx512fmaskmode> 3 \"register_operand\" \"k,k\")]\n+\t  UNSPEC_EXPAND))]\n+  \"TARGET_AVX512F\"\n+  \"v<sseintprefix>expand<ssemodesuffix>\\t{%1, %0%{%3%}%N2|%0%{%3%}%N2, %1}\"\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"memory\" \"none,load\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n+(define_insn \"avx512f_getmant<mode><mask_name>\"\n   [(set (match_operand:VF_512 0 \"register_operand\" \"=v\")\n \t(unspec:VF_512\n \t  [(match_operand:VF_512 1 \"nonimmediate_operand\" \"vm\")\n \t   (match_operand:SI 2 \"const_0_to_15_operand\")]\n \t  UNSPEC_GETMANT))]\n   \"TARGET_AVX512F\"\n-  \"vgetmant<ssemodesuffix>\\t{%2, %1, %0|%0, %1, %2}\";\n+  \"vgetmant<ssemodesuffix>\\t{%2, %1, %0<mask_operand3>|%0<mask_operand3>, %1, %2}\";\n   [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n@@ -14013,23 +14929,23 @@\n    [(set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<ssescalarmode>\")])\n \n-(define_insn \"clz<mode>2\"\n+(define_insn \"clz<mode>2<mask_name>\"\n   [(set (match_operand:VI48_512 0 \"register_operand\" \"=v\")\n \t(clz:VI48_512\n \t  (match_operand:VI48_512 1 \"nonimmediate_operand\" \"vm\")))]\n   \"TARGET_AVX512CD\"\n-  \"vplzcnt<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"vplzcnt<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"sse\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])\n \n-(define_insn \"conflict<mode>\"\n+(define_insn \"<mask_codefor>conflict<mode><mask_name>\"\n   [(set (match_operand:VI48_512 0 \"register_operand\" \"=v\")\n \t(unspec:VI48_512\n \t  [(match_operand:VI48_512 1 \"nonimmediate_operand\" \"vm\")]\n \t  UNSPEC_CONFLICT))]\n   \"TARGET_AVX512CD\"\n-  \"vpconflict<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+  \"vpconflict<ssemodesuffix>\\t{%1, %0<mask_operand2>|%0<mask_operand2>, %1}\"\n   [(set_attr \"type\" \"sse\")\n    (set_attr \"prefix\" \"evex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])"}, {"sha": "6b45d058f2251d86856558a475bf20515ba4a1d9", "filename": "gcc/config/i386/subst.md", "status": "added", "additions": 56, "deletions": 0, "changes": 56, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2Fconfig%2Fi386%2Fsubst.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/47490470c6cfde4258f471641b65fb29fd30023a/gcc%2Fconfig%2Fi386%2Fsubst.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsubst.md?ref=47490470c6cfde4258f471641b65fb29fd30023a", "patch": "@@ -0,0 +1,56 @@\n+;; GCC machine description for AVX512F instructions\n+;; Copyright (C) 2013 Free Software Foundation, Inc.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+;; Some iterators for extending subst as much as possible\n+;; All vectors (Use it for destination)\n+(define_mode_iterator SUBST_V\n+  [V16QI\n+   V16HI V8HI\n+   V16SI V8SI  V4SI\n+   V8DI  V4DI  V2DI\n+   V16SF V8SF  V4SF\n+   V8DF  V4DF  V2DF])\n+\n+(define_subst_attr \"mask_name\" \"mask\" \"\" \"_mask\")\n+(define_subst_attr \"mask_applied\" \"mask\" \"false\" \"true\")\n+(define_subst_attr \"mask_operand2\" \"mask\" \"\" \"%{%3%}%N2\")\n+(define_subst_attr \"mask_operand3\" \"mask\" \"\" \"%{%4%}%N3\")\n+(define_subst_attr \"mask_operand3_1\" \"mask\" \"\" \"%%{%%4%%}%%N3\") ;; for sprintf\n+(define_subst_attr \"mask_operand4\" \"mask\" \"\" \"%{%5%}%N4\")\n+(define_subst_attr \"mask_operand6\" \"mask\" \"\" \"%{%7%}%N6\")\n+(define_subst_attr \"mask_operand11\" \"mask\" \"\" \"%{%12%}%N11\")\n+(define_subst_attr \"mask_operand18\" \"mask\" \"\" \"%{%19%}%N18\")\n+(define_subst_attr \"mask_operand19\" \"mask\" \"\" \"%{%20%}%N19\")\n+(define_subst_attr \"mask_codefor\" \"mask\" \"*\" \"\")\n+(define_subst_attr \"mask_mode512bit_condition\" \"mask\" \"1\" \"(GET_MODE_SIZE (GET_MODE (operands[0])) == 64)\")\n+(define_subst_attr \"store_mask_constraint\" \"mask\" \"vm\" \"v\")\n+(define_subst_attr \"store_mask_predicate\" \"mask\" \"nonimmediate_operand\" \"register_operand\")\n+(define_subst_attr \"mask_prefix\" \"mask\" \"vex\" \"evex\")\n+(define_subst_attr \"mask_prefix2\" \"mask\" \"maybe_vex\" \"evex\")\n+(define_subst_attr \"mask_prefix3\" \"mask\" \"orig,vex\" \"evex\")\n+\n+(define_subst \"mask\"\n+  [(set (match_operand:SUBST_V 0)\n+        (match_operand:SUBST_V 1))]\n+  \"TARGET_AVX512F\"\n+  [(set (match_dup 0)\n+        (vec_merge:SUBST_V\n+\t  (match_dup 1)\n+\t  (match_operand:SUBST_V 2 \"vector_move_operand\" \"0C\")\n+\t  (match_operand:<avx512fmaskmode> 3 \"register_operand\" \"k\")))])"}]}