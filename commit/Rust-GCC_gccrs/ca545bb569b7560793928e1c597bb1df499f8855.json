{"sha": "ca545bb569b7560793928e1c597bb1df499f8855", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Y2E1NDViYjU2OWI3NTYwNzkzOTI4ZTFjNTk3YmIxZGY0OTlmODg1NQ==", "commit": {"author": {"name": "Bob Manson", "email": "manson@charmed.cygnus.com", "date": "1999-02-02T21:22:52Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "1999-02-02T21:22:52Z"}, "message": "Bob Manson <manson@charmed.cygnus.com>\n\nBob Manson  <manson@charmed.cygnus.com>\n        * resource.c, resource.h: New files.\n        * haifa-sched.c (regno_use_in): Moved to rtlanal.c.\n        (split_block_insns): Moved to recog.c.\n        (update_flow_info): Make public.\n        * reorg.c: Moved the functions dealing with computing resource\n        usage to resource.c.\n        * sched.c (regno_use_in): Moved to rtlanal.c.\n        (update_flow_info): Make public.\n        (schedule_insns): Use split_block_insns.\n        * recog.c (split_block_insns): New function.\n\nFrom-SVN: r24982", "tree": {"sha": "bf741c1416516d6d4b65f9e54691a31b98962066", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/bf741c1416516d6d4b65f9e54691a31b98962066"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ca545bb569b7560793928e1c597bb1df499f8855", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca545bb569b7560793928e1c597bb1df499f8855", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ca545bb569b7560793928e1c597bb1df499f8855", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca545bb569b7560793928e1c597bb1df499f8855/comments", "author": null, "committer": null, "parents": [{"sha": "ee0d2cf3227a2bddf6a1ff20971284e8e6823d78", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ee0d2cf3227a2bddf6a1ff20971284e8e6823d78", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ee0d2cf3227a2bddf6a1ff20971284e8e6823d78"}], "stats": {"total": 2768, "additions": 1403, "deletions": 1365}, "files": [{"sha": "c95413e879fdc8e59904beb4ad59c9b17dffebbb", "filename": "gcc/ChangeLog", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ca545bb569b7560793928e1c597bb1df499f8855", "patch": "@@ -1,3 +1,20 @@\n+Fri Jan 29 21:00:56 1999  Bob Manson  <manson@charmed.cygnus.com>\n+\n+\t* resource.c, resource.h: New files.\n+\n+\t* haifa-sched.c (regno_use_in): Moved to rtlanal.c.\n+\t(split_block_insns): Moved to recog.c.\n+\t(update_flow_info): Make public.\n+\n+\t* reorg.c: Moved the functions dealing with computing resource\n+\tusage to resource.c.\n+\n+\t* sched.c (regno_use_in): Moved to rtlanal.c.\n+\t(update_flow_info): Make public.\n+\t(schedule_insns): Use split_block_insns.\n+\n+\t* recog.c (split_block_insns): New function.\n+\n Tue Feb  2 22:03:26 1999  David Edelsohn  <edelsohn@mhpcc.edu>\n \n \t* rs6000/linux.h (LINK_START_DEFAULT_SPEC): Delete, unused."}, {"sha": "b0d34b6f67d1f7cacd8bcfe0e024f57a823a5f7d", "filename": "gcc/haifa-sched.c", "status": "modified", "additions": 2, "deletions": 111, "changes": 113, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Fhaifa-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Fhaifa-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhaifa-sched.c?ref=ca545bb569b7560793928e1c597bb1df499f8855", "patch": "@@ -448,11 +448,9 @@ static void attach_deaths_insn PROTO ((rtx));\n static int new_sometimes_live PROTO ((struct sometimes *, int, int));\n static void finish_sometimes_live PROTO ((struct sometimes *, int));\n static int schedule_block PROTO ((int, int));\n-static rtx regno_use_in PROTO ((int, rtx));\n static void split_hard_reg_notes PROTO ((rtx, rtx, rtx));\n static void new_insn_dead_notes PROTO ((rtx, rtx, rtx, rtx));\n static void update_n_sets PROTO ((rtx, int));\n-static void update_flow_info PROTO ((rtx, rtx, rtx, rtx));\n static char *safe_concat PROTO ((char *, char *, char *));\n static int insn_issue_delay PROTO ((rtx));\n static int birthing_insn_p PROTO ((rtx));\n@@ -765,7 +763,6 @@ static rtx group_leader PROTO ((rtx));\n static int set_priorities PROTO ((int));\n static void init_rtx_vector PROTO ((rtx **, rtx *, int, int));\n static void schedule_region PROTO ((int));\n-static void split_block_insns PROTO ((int));\n \n #endif /* INSN_SCHEDULING */\n \f\n@@ -7699,39 +7696,6 @@ schedule_region (rgn)\n   FREE_REG_SET (reg_pending_sets);\n }\n \n-/* Subroutine of split_hard_reg_notes.  Searches X for any reference to\n-   REGNO, returning the rtx of the reference found if any.  Otherwise,\n-   returns 0.  */\n-\n-static rtx\n-regno_use_in (regno, x)\n-     int regno;\n-     rtx x;\n-{\n-  register char *fmt;\n-  int i, j;\n-  rtx tem;\n-\n-  if (GET_CODE (x) == REG && REGNO (x) == regno)\n-    return x;\n-\n-  fmt = GET_RTX_FORMAT (GET_CODE (x));\n-  for (i = GET_RTX_LENGTH (GET_CODE (x)) - 1; i >= 0; i--)\n-    {\n-      if (fmt[i] == 'e')\n-\t{\n-\t  if ((tem = regno_use_in (regno, XEXP (x, i))))\n-\t    return tem;\n-\t}\n-      else if (fmt[i] == 'E')\n-\tfor (j = XVECLEN (x, i) - 1; j >= 0; j--)\n-\t  if ((tem = regno_use_in (regno, XVECEXP (x, i, j))))\n-\t    return tem;\n-    }\n-\n-  return 0;\n-}\n-\n /* Subroutine of update_flow_info.  Determines whether any new REG_NOTEs are\n    needed for the hard register mentioned in the note.  This can happen\n    if the reference to the hard register in the original insn was split into\n@@ -7918,7 +7882,7 @@ update_n_sets (x, inc)\n    the insns from FIRST to LAST inclusive that were created by splitting\n    ORIG_INSN.  NOTES are the original REG_NOTES.  */\n \n-static void\n+void\n update_flow_info (notes, first, last, orig_insn)\n      rtx notes;\n      rtx first, last;\n@@ -8409,79 +8373,6 @@ update_flow_info (notes, first, last, orig_insn)\n   }\n }\n \n-/* Do the splitting of insns in the block b.  */\n-\n-static void\n-split_block_insns (b)\n-     int b;\n-{\n-  rtx insn, next;\n-\n-  for (insn = BLOCK_HEAD (b);; insn = next)\n-    {\n-      rtx set, last, first, notes;\n-\n-      /* Can't use `next_real_insn' because that\n-         might go across CODE_LABELS and short-out basic blocks.  */\n-      next = NEXT_INSN (insn);\n-      if (GET_CODE (insn) != INSN)\n-\t{\n-\t  if (insn == BLOCK_END (b))\n-\t    break;\n-\n-\t  continue;\n-\t}\n-\n-      /* Don't split no-op move insns.  These should silently disappear\n-         later in final.  Splitting such insns would break the code\n-         that handles REG_NO_CONFLICT blocks.  */\n-      set = single_set (insn);\n-      if (set && rtx_equal_p (SET_SRC (set), SET_DEST (set)))\n-\t{\n-\t  if (insn == BLOCK_END (b))\n-\t    break;\n-\n-\t  /* Nops get in the way while scheduling, so delete them now if\n-\t     register allocation has already been done.  It is too risky\n-\t     to try to do this before register allocation, and there are\n-\t     unlikely to be very many nops then anyways.  */\n-\t  if (reload_completed)\n-\t    {\n-\t      PUT_CODE (insn, NOTE);\n-\t      NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;\n-\t      NOTE_SOURCE_FILE (insn) = 0;\n-\t    }\n-\n-\t  continue;\n-\t}\n-\n-      /* Split insns here to get max fine-grain parallelism.  */\n-      first = PREV_INSN (insn);\n-      notes = REG_NOTES (insn);\n-      last = try_split (PATTERN (insn), insn, 1);\n-      if (last != insn)\n-\t{\n-\t  /* try_split returns the NOTE that INSN became.  */\n-\t  first = NEXT_INSN (first);\n-\t  update_flow_info (notes, first, last, insn);\n-\n-\t  PUT_CODE (insn, NOTE);\n-\t  NOTE_SOURCE_FILE (insn) = 0;\n-\t  NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;\n-\t  if (insn == BLOCK_HEAD (b))\n-\t    BLOCK_HEAD (b) = first;\n-\t  if (insn == BLOCK_END (b))\n-\t    {\n-\t      BLOCK_END (b) = last;\n-\t      break;\n-\t    }\n-\t}\n-\n-      if (insn == BLOCK_END (b))\n-\tbreak;\n-    }\n-}\n-\n /* The one entry point in this file.  DUMP_FILE is the dump file for\n    this pass.  */\n \n@@ -8535,7 +8426,7 @@ schedule_insns (dump_file)\n \n   /* do the splitting first for all blocks */\n   for (b = 0; b < n_basic_blocks; b++)\n-    split_block_insns (b);\n+    split_block_insns (b, 1);\n \n   max_uid = (get_max_uid () + 1);\n "}, {"sha": "a62027db0b74882873a26c6fd89ca8d8684ffc72", "filename": "gcc/recog.c", "status": "modified", "additions": 81, "deletions": 0, "changes": 81, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Frecog.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Frecog.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frecog.c?ref=ca545bb569b7560793928e1c597bb1df499f8855", "patch": "@@ -32,6 +32,7 @@ Boston, MA 02111-1307, USA.  */\n #include \"flags.h\"\n #include \"real.h\"\n #include \"toplev.h\"\n+#include \"basic-block.h\"\n \n #ifndef STACK_PUSH_CODE\n #ifdef STACK_GROWS_DOWNWARD\n@@ -2596,3 +2597,83 @@ reg_fits_class_p (operand, class, offset, mode)\n }\n \n #endif /* REGISTER_CONSTRAINTS */\n+\f\n+/* Do the splitting of insns in the block B. Only try to actually split if\n+   DO_SPLIT is true; otherwise, just remove nops. */ \n+\n+void\n+split_block_insns (b, do_split)\n+     int b;\n+     int do_split;\n+{\n+  rtx insn, next;\n+\n+  for (insn = BLOCK_HEAD (b);; insn = next)\n+    {\n+      rtx set;\n+\n+      /* Can't use `next_real_insn' because that\n+         might go across CODE_LABELS and short-out basic blocks.  */\n+      next = NEXT_INSN (insn);\n+      if (GET_CODE (insn) != INSN)\n+\t{\n+\t  if (insn == BLOCK_END (b))\n+\t    break;\n+\n+\t  continue;\n+\t}\n+\n+      /* Don't split no-op move insns.  These should silently disappear\n+         later in final.  Splitting such insns would break the code\n+         that handles REG_NO_CONFLICT blocks.  */\n+      set = single_set (insn);\n+      if (set && rtx_equal_p (SET_SRC (set), SET_DEST (set)))\n+\t{\n+\t  if (insn == BLOCK_END (b))\n+\t    break;\n+\n+\t  /* Nops get in the way while scheduling, so delete them now if\n+\t     register allocation has already been done.  It is too risky\n+\t     to try to do this before register allocation, and there are\n+\t     unlikely to be very many nops then anyways.  */\n+\t  if (reload_completed)\n+\t    {\n+\n+\t      PUT_CODE (insn, NOTE);\n+\t      NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;\n+\t      NOTE_SOURCE_FILE (insn) = 0;\n+\t    }\n+\n+\t  continue;\n+\t}\n+\n+      if (do_split)\n+\t{\n+\t  /* Split insns here to get max fine-grain parallelism.  */\n+\t  rtx first = PREV_INSN (insn);\n+\t  rtx notes = REG_NOTES (insn);\n+\t  rtx last = try_split (PATTERN (insn), insn, 1);\n+\n+\t  if (last != insn)\n+\t    {\n+\t      /* try_split returns the NOTE that INSN became.  */\n+\t      first = NEXT_INSN (first);\n+\t      update_flow_info (notes, first, last, insn);\n+\t      \n+\t      PUT_CODE (insn, NOTE);\n+\t      NOTE_SOURCE_FILE (insn) = 0;\n+\t      NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;\n+\t      if (insn == BLOCK_HEAD (b))\n+\t\tBLOCK_HEAD (b) = first;\n+\t      if (insn == BLOCK_END (b))\n+\t\t{\n+\t\t  BLOCK_END (b) = last;\n+\t\t  break;\n+\t\t}\n+\t    }\n+\t}\n+\n+      if (insn == BLOCK_END (b))\n+\tbreak;\n+    }\n+}"}, {"sha": "a8f52f955c95a6e046e73bd92c786ef9e4d355fc", "filename": "gcc/reorg.c", "status": "modified", "additions": 16, "deletions": 1146, "changes": 1162, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Freorg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Freorg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freorg.c?ref=ca545bb569b7560793928e1c597bb1df499f8855", "patch": "@@ -134,6 +134,7 @@ Boston, MA 02111-1307, USA.  */\n #include \"output.h\"\n #include \"obstack.h\"\n #include \"insn-attr.h\"\n+#include \"resource.h\"\n \n \n #ifdef DELAY_SLOTS\n@@ -164,67 +165,17 @@ static rtx *unfilled_firstobj;\n   ((rtx *) obstack_next_free (&unfilled_slots_obstack))\n \n /* This structure is used to indicate which hardware resources are set or\n-   needed by insns so far.  */\n-\n-struct resources\n-{\n-  char memory;\t\t\t/* Insn sets or needs a memory location.  */\n-  char unch_memory;\t\t/* Insn sets of needs a \"unchanging\" MEM.  */\n-  char volatil;\t\t\t/* Insn sets or needs a volatile memory loc.  */\n-  char cc;\t\t\t/* Insn sets or needs the condition codes.  */\n-  HARD_REG_SET regs;\t\t/* Which registers are set or needed.  */\n-};\n-\n-/* Macro to clear all resources.  */\n-#define CLEAR_RESOURCE(RES)\t\\\n- do { (RES)->memory = (RES)->unch_memory = (RES)->volatil = (RES)->cc = 0; \\\n-      CLEAR_HARD_REG_SET ((RES)->regs); } while (0)\n-\n-/* Indicates what resources are required at the beginning of the epilogue.  */\n-static struct resources start_of_epilogue_needs;\n-\n-/* Indicates what resources are required at function end.  */\n-static struct resources end_of_function_needs;\n \n /* Points to the label before the end of the function.  */\n static rtx end_of_function_label;\n \n-/* This structure is used to record liveness information at the targets or\n-   fallthrough insns of branches.  We will most likely need the information\n-   at targets again, so save them in a hash table rather than recomputing them\n-   each time.  */\n-\n-struct target_info\n-{\n-  int uid;\t\t\t/* INSN_UID of target.  */\n-  struct target_info *next;\t/* Next info for same hash bucket.  */\n-  HARD_REG_SET live_regs;\t/* Registers live at target.  */\n-  int block;\t\t\t/* Basic block number containing target.  */\n-  int bb_tick;\t\t\t/* Generation count of basic block info.  */\n-};\n-\n-#define TARGET_HASH_PRIME 257\n-\n-/* Define the hash table itself.  */\n-static struct target_info **target_hash_table;\n-\n-/* For each basic block, we maintain a generation number of its basic\n-   block info, which is updated each time we move an insn from the\n-   target of a jump.  This is the generation number indexed by block\n-   number.  */\n-\n-static int *bb_ticks;\n-\n /* Mapping between INSN_UID's and position in the code since INSN_UID's do\n    not always monotonically increase.  */\n static int *uid_to_ruid;\n \n /* Highest valid index in `uid_to_ruid'.  */\n static int max_uid;\n \n-static void mark_referenced_resources\tPROTO((rtx, struct resources *, int));\n-static void mark_set_resources\t\tPROTO((rtx, struct resources *,\n-\t\t\t\t\t       int, int));\n static int stop_search_p\t\tPROTO((rtx, int));\n static int resource_conflicts_p\t\tPROTO((struct resources *,\n \t\t\t\t\t       struct resources *));\n@@ -242,6 +193,9 @@ static int rare_destination\t\tPROTO((rtx));\n static int mostly_true_jump\t\tPROTO((rtx, rtx));\n static rtx get_branch_condition\t\tPROTO((rtx, rtx));\n static int condition_dominates_p\tPROTO((rtx, rtx));\n+static int redirect_with_delay_slots_safe_p PROTO ((rtx, rtx, rtx));\n+static int redirect_with_delay_list_safe_p PROTO ((rtx, rtx, rtx));\n+static int check_annul_list_true_false\tPROTO ((int, rtx));\n static rtx steal_delay_list_from_target PROTO((rtx, rtx, rtx, rtx,\n \t\t\t\t\t       struct resources *,\n \t\t\t\t\t       struct resources *,\n@@ -252,443 +206,20 @@ static rtx steal_delay_list_from_fallthrough PROTO((rtx, rtx, rtx, rtx,\n \t\t\t\t\t\t    struct resources *,\n \t\t\t\t\t\t    struct resources *,\n \t\t\t\t\t\t    int, int *, int *));\n-static rtx find_dead_or_set_registers PROTO ((rtx, struct resources *, rtx *,\n-\t\t\t\t\t      int, struct resources,\n-\t\t\t\t\t      struct resources));\n static void try_merge_delay_insns\tPROTO((rtx, rtx));\n static rtx redundant_insn\t\tPROTO((rtx, rtx, rtx));\n static int own_thread_p\t\t\tPROTO((rtx, rtx, int));\n-static int find_basic_block\t\tPROTO((rtx));\n static void update_block\t\tPROTO((rtx, rtx));\n static int reorg_redirect_jump\t\tPROTO((rtx, rtx));\n static void update_reg_dead_notes\tPROTO((rtx, rtx));\n static void fix_reg_dead_note\t\tPROTO((rtx, rtx));\n static void update_reg_unused_notes\tPROTO((rtx, rtx));\n-static void update_live_status\t\tPROTO((rtx, rtx));\n-static rtx next_insn_no_annul\t\tPROTO((rtx));\n-static void mark_target_live_regs\tPROTO((rtx, struct resources *));\n static void fill_simple_delay_slots\tPROTO((int));\n static rtx fill_slots_from_thread\tPROTO((rtx, rtx, rtx, rtx, int, int,\n \t\t\t\t\t       int, int, int *, rtx));\n static void fill_eager_delay_slots\tPROTO((void));\n static void relax_delay_slots\t\tPROTO((rtx));\n static void make_return_insns\t\tPROTO((rtx));\n-static int redirect_with_delay_slots_safe_p PROTO ((rtx, rtx, rtx));\n-static int redirect_with_delay_list_safe_p PROTO ((rtx, rtx, rtx));\n-static int check_annul_list_true_false\tPROTO ((int, rtx));\n-\f\n-/* Given X, some rtl, and RES, a pointer to a `struct resource', mark\n-   which resources are references by the insn.  If INCLUDE_DELAYED_EFFECTS\n-   is TRUE, resources used by the called routine will be included for\n-   CALL_INSNs.  */\n-\n-static void\n-mark_referenced_resources (x, res, include_delayed_effects)\n-     register rtx x;\n-     register struct resources *res;\n-     register int include_delayed_effects;\n-{\n-  register enum rtx_code code = GET_CODE (x);\n-  register int i, j;\n-  register char *format_ptr;\n-\n-  /* Handle leaf items for which we set resource flags.  Also, special-case\n-     CALL, SET and CLOBBER operators.  */\n-  switch (code)\n-    {\n-    case CONST:\n-    case CONST_INT:\n-    case CONST_DOUBLE:\n-    case PC:\n-    case SYMBOL_REF:\n-    case LABEL_REF:\n-      return;\n-\n-    case SUBREG:\n-      if (GET_CODE (SUBREG_REG (x)) != REG)\n-\tmark_referenced_resources (SUBREG_REG (x), res, 0);\n-      else\n-\t{\n-\t  int regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n-\t  int last_regno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n-\t  for (i = regno; i < last_regno; i++)\n-\t    SET_HARD_REG_BIT (res->regs, i);\n-\t}\n-      return;\n-\n-    case REG:\n-      for (i = 0; i < HARD_REGNO_NREGS (REGNO (x), GET_MODE (x)); i++)\n-\tSET_HARD_REG_BIT (res->regs, REGNO (x) + i);\n-      return;\n-\n-    case MEM:\n-      /* If this memory shouldn't change, it really isn't referencing\n-\t memory.  */\n-      if (RTX_UNCHANGING_P (x))\n-\tres->unch_memory = 1;\n-      else\n-\tres->memory = 1;\n-      res->volatil = MEM_VOLATILE_P (x);\n-\n-      /* Mark registers used to access memory.  */\n-      mark_referenced_resources (XEXP (x, 0), res, 0);\n-      return;\n-\n-    case CC0:\n-      res->cc = 1;\n-      return;\n-\n-    case UNSPEC_VOLATILE:\n-    case ASM_INPUT:\n-      /* Traditional asm's are always volatile.  */\n-      res->volatil = 1;\n-      return;\n-\n-    case TRAP_IF:\n-      res->volatil = 1;\n-      break;\n-\n-    case ASM_OPERANDS:\n-      res->volatil = MEM_VOLATILE_P (x);\n-\n-      /* For all ASM_OPERANDS, we must traverse the vector of input operands.\n-\t We can not just fall through here since then we would be confused\n-\t by the ASM_INPUT rtx inside ASM_OPERANDS, which do not indicate\n-\t traditional asms unlike their normal usage.  */\n-      \n-      for (i = 0; i < ASM_OPERANDS_INPUT_LENGTH (x); i++)\n-\tmark_referenced_resources (ASM_OPERANDS_INPUT (x, i), res, 0);\n-      return;\n-\n-    case CALL:\n-      /* The first operand will be a (MEM (xxx)) but doesn't really reference\n-\t memory.  The second operand may be referenced, though.  */\n-      mark_referenced_resources (XEXP (XEXP (x, 0), 0), res, 0);\n-      mark_referenced_resources (XEXP (x, 1), res, 0);\n-      return;\n-\n-    case SET:\n-      /* Usually, the first operand of SET is set, not referenced.  But\n-\t registers used to access memory are referenced.  SET_DEST is\n-\t also referenced if it is a ZERO_EXTRACT or SIGN_EXTRACT.  */\n-\n-      mark_referenced_resources (SET_SRC (x), res, 0);\n-\n-      x = SET_DEST (x);\n-      if (GET_CODE (x) == SIGN_EXTRACT || GET_CODE (x) == ZERO_EXTRACT)\n-\tmark_referenced_resources (x, res, 0);\n-      else if (GET_CODE (x) == SUBREG)\n-\tx = SUBREG_REG (x);\n-      if (GET_CODE (x) == MEM)\n-\tmark_referenced_resources (XEXP (x, 0), res, 0);\n-      return;\n-\n-    case CLOBBER:\n-      return;\n-\n-    case CALL_INSN:\n-      if (include_delayed_effects)\n-\t{\n-\t  /* A CALL references memory, the frame pointer if it exists, the\n-\t     stack pointer, any global registers and any registers given in\n-\t     USE insns immediately in front of the CALL.\n-\n-\t     However, we may have moved some of the parameter loading insns\n-\t     into the delay slot of this CALL.  If so, the USE's for them\n-\t     don't count and should be skipped.  */\n-\t  rtx insn = PREV_INSN (x);\n-\t  rtx sequence = 0;\n-\t  int seq_size = 0;\n-\t  rtx next = NEXT_INSN (x);\n-\t  int i;\n-\n-\t  /* If we are part of a delay slot sequence, point at the SEQUENCE.  */\n-\t  if (NEXT_INSN (insn) != x)\n-\t    {\n-\t      next = NEXT_INSN (NEXT_INSN (insn));\n-\t      sequence = PATTERN (NEXT_INSN (insn));\n-\t      seq_size = XVECLEN (sequence, 0);\n-\t      if (GET_CODE (sequence) != SEQUENCE)\n-\t\tabort ();\n-\t    }\n-\n-\t  res->memory = 1;\n-\t  SET_HARD_REG_BIT (res->regs, STACK_POINTER_REGNUM);\n-\t  if (frame_pointer_needed)\n-\t    {\n-\t      SET_HARD_REG_BIT (res->regs, FRAME_POINTER_REGNUM);\n-#if FRAME_POINTER_REGNUM != HARD_FRAME_POINTER_REGNUM\n-\t      SET_HARD_REG_BIT (res->regs, HARD_FRAME_POINTER_REGNUM);\n-#endif\n-\t    }\n-\n-\t  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-\t    if (global_regs[i])\n-\t      SET_HARD_REG_BIT (res->regs, i);\n-\n-\t  /* Check for a NOTE_INSN_SETJMP.  If it exists, then we must\n-\t     assume that this call can need any register.\n-\n-\t     This is done to be more conservative about how we handle setjmp.\n-\t     We assume that they both use and set all registers.  Using all\n-\t     registers ensures that a register will not be considered dead\n-\t     just because it crosses a setjmp call.  A register should be\n-\t     considered dead only if the setjmp call returns non-zero.  */\n-\t  if (next && GET_CODE (next) == NOTE\n-\t      && NOTE_LINE_NUMBER (next) == NOTE_INSN_SETJMP)\n-\t    SET_HARD_REG_SET (res->regs);\n-\n-\t  {\n-\t    rtx link;\n-\n-\t    for (link = CALL_INSN_FUNCTION_USAGE (x);\n-\t\t link;\n-\t\t link = XEXP (link, 1))\n-\t      if (GET_CODE (XEXP (link, 0)) == USE)\n-\t\t{\n-\t\t  for (i = 1; i < seq_size; i++)\n-\t\t    {\n-\t\t      rtx slot_pat = PATTERN (XVECEXP (sequence, 0, i));\n-\t\t      if (GET_CODE (slot_pat) == SET\n-\t\t\t  && rtx_equal_p (SET_DEST (slot_pat),\n-\t\t\t\t\t  SET_DEST (XEXP (link, 0))))\n-\t\t\tbreak;\n-\t\t    }\n-\t\t  if (i >= seq_size)\n-\t\t    mark_referenced_resources (SET_DEST (XEXP (link, 0)),\n-\t\t\t\t\t       res, 0);\n-\t\t}\n-\t  }\n-\t}\n-\n-      /* ... fall through to other INSN processing ...  */\n-\n-    case INSN:\n-    case JUMP_INSN:\n-\n-#ifdef INSN_REFERENCES_ARE_DELAYED\n-      if (! include_delayed_effects\n-\t  && INSN_REFERENCES_ARE_DELAYED (x))\n-\treturn;\n-#endif\n-\n-      /* No special processing, just speed up.  */\n-      mark_referenced_resources (PATTERN (x), res, include_delayed_effects);\n-      return;\n-\n-    default:\n-      break;\n-    }\n-\n-  /* Process each sub-expression and flag what it needs.  */\n-  format_ptr = GET_RTX_FORMAT (code);\n-  for (i = 0; i < GET_RTX_LENGTH (code); i++)\n-    switch (*format_ptr++)\n-      {\n-      case 'e':\n-\tmark_referenced_resources (XEXP (x, i), res, include_delayed_effects);\n-\tbreak;\n-\n-      case 'E':\n-\tfor (j = 0; j < XVECLEN (x, i); j++)\n-\t  mark_referenced_resources (XVECEXP (x, i, j), res,\n-\t\t\t\t     include_delayed_effects);\n-\tbreak;\n-      }\n-}\n-\f\n-/* Given X, a part of an insn, and a pointer to a `struct resource',\n-   RES, indicate which resources are modified by the insn. If\n-   INCLUDE_DELAYED_EFFECTS is nonzero, also mark resources potentially\n-   set by the called routine.\n-\n-   If IN_DEST is nonzero, it means we are inside a SET.  Otherwise,\n-   objects are being referenced instead of set.\n-\n-   We never mark the insn as modifying the condition code unless it explicitly\n-   SETs CC0 even though this is not totally correct.  The reason for this is\n-   that we require a SET of CC0 to immediately precede the reference to CC0.\n-   So if some other insn sets CC0 as a side-effect, we know it cannot affect\n-   our computation and thus may be placed in a delay slot.   */\n-\n-static void\n-mark_set_resources (x, res, in_dest, include_delayed_effects)\n-     register rtx x;\n-     register struct resources *res;\n-     int in_dest;\n-     int include_delayed_effects;\n-{\n-  register enum rtx_code code;\n-  register int i, j;\n-  register char *format_ptr;\n-\n- restart:\n-\n-  code = GET_CODE (x);\n-\n-  switch (code)\n-    {\n-    case NOTE:\n-    case BARRIER:\n-    case CODE_LABEL:\n-    case USE:\n-    case CONST_INT:\n-    case CONST_DOUBLE:\n-    case LABEL_REF:\n-    case SYMBOL_REF:\n-    case CONST:\n-    case PC:\n-      /* These don't set any resources.  */\n-      return;\n-\n-    case CC0:\n-      if (in_dest)\n-\tres->cc = 1;\n-      return;\n-\n-    case CALL_INSN:\n-      /* Called routine modifies the condition code, memory, any registers\n-\t that aren't saved across calls, global registers and anything\n-\t explicitly CLOBBERed immediately after the CALL_INSN.  */\n-\n-      if (include_delayed_effects)\n-\t{\n-\t  rtx next = NEXT_INSN (x);\n-\t  rtx prev = PREV_INSN (x);\n-\t  rtx link;\n-\n-\t  res->cc = res->memory = 1;\n-\t  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-\t    if (call_used_regs[i] || global_regs[i])\n-\t      SET_HARD_REG_BIT (res->regs, i);\n-\n-\t  /* If X is part of a delay slot sequence, then NEXT should be\n-\t     the first insn after the sequence.  */\n-\t  if (NEXT_INSN (prev) != x)\n-\t    next = NEXT_INSN (NEXT_INSN (prev));\n-\n-\t  for (link = CALL_INSN_FUNCTION_USAGE (x);\n-\t       link; link = XEXP (link, 1))\n-\t    if (GET_CODE (XEXP (link, 0)) == CLOBBER)\n-\t      mark_set_resources (SET_DEST (XEXP (link, 0)), res, 1, 0);\n-\n-\t  /* Check for a NOTE_INSN_SETJMP.  If it exists, then we must\n-\t     assume that this call can clobber any register.  */\n-\t  if (next && GET_CODE (next) == NOTE\n-\t      && NOTE_LINE_NUMBER (next) == NOTE_INSN_SETJMP)\n-\t    SET_HARD_REG_SET (res->regs);\n-\t}\n-\n-      /* ... and also what its RTL says it modifies, if anything.  */\n-\n-    case JUMP_INSN:\n-    case INSN:\n-\n-\t/* An insn consisting of just a CLOBBER (or USE) is just for flow\n-\t   and doesn't actually do anything, so we ignore it.  */\n-\n-#ifdef INSN_SETS_ARE_DELAYED\n-      if (! include_delayed_effects\n-\t  && INSN_SETS_ARE_DELAYED (x))\n-\treturn;\n-#endif\n-\n-      x = PATTERN (x);\n-      if (GET_CODE (x) != USE && GET_CODE (x) != CLOBBER)\n-\tgoto restart;\n-      return;\n-\n-    case SET:\n-      /* If the source of a SET is a CALL, this is actually done by\n-\t the called routine.  So only include it if we are to include the\n-\t effects of the calling routine.  */\n-\n-      mark_set_resources (SET_DEST (x), res,\n-\t\t\t  (include_delayed_effects\n-\t\t\t   || GET_CODE (SET_SRC (x)) != CALL),\n-\t\t\t  0);\n-\n-      mark_set_resources (SET_SRC (x), res, 0, 0);\n-      return;\n-\n-    case CLOBBER:\n-      mark_set_resources (XEXP (x, 0), res, 1, 0);\n-      return;\n-      \n-    case SEQUENCE:\n-      for (i = 0; i < XVECLEN (x, 0); i++)\n-\tif (! (INSN_ANNULLED_BRANCH_P (XVECEXP (x, 0, 0))\n-\t       && INSN_FROM_TARGET_P (XVECEXP (x, 0, i))))\n-\t  mark_set_resources (XVECEXP (x, 0, i), res, 0,\n-\t\t\t      include_delayed_effects);\n-      return;\n-\n-    case POST_INC:\n-    case PRE_INC:\n-    case POST_DEC:\n-    case PRE_DEC:\n-      mark_set_resources (XEXP (x, 0), res, 1, 0);\n-      return;\n-\n-    case ZERO_EXTRACT:\n-      mark_set_resources (XEXP (x, 0), res, in_dest, 0);\n-      mark_set_resources (XEXP (x, 1), res, 0, 0);\n-      mark_set_resources (XEXP (x, 2), res, 0, 0);\n-      return;\n-\n-    case MEM:\n-      if (in_dest)\n-\t{\n-\t  res->memory = 1;\n-\t  res->unch_memory = RTX_UNCHANGING_P (x);\n-\t  res->volatil = MEM_VOLATILE_P (x);\n-\t}\n-\n-      mark_set_resources (XEXP (x, 0), res, 0, 0);\n-      return;\n-\n-    case SUBREG:\n-      if (in_dest)\n-\t{\n-\t  if (GET_CODE (SUBREG_REG (x)) != REG)\n-\t    mark_set_resources (SUBREG_REG (x), res,\n-\t\t\t\tin_dest, include_delayed_effects);\n-\t  else\n-\t    {\n-\t      int regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n-\t      int last_regno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n-\t      for (i = regno; i < last_regno; i++)\n-\t\tSET_HARD_REG_BIT (res->regs, i);\n-\t    }\n-\t}\n-      return;\n-\n-    case REG:\n-      if (in_dest)\n-        for (i = 0; i < HARD_REGNO_NREGS (REGNO (x), GET_MODE (x)); i++)\n-\t  SET_HARD_REG_BIT (res->regs, REGNO (x) + i);\n-      return;\n-\n-    default:\n-      break;\n-    }\n-\n-  /* Process each sub-expression and flag what it needs.  */\n-  format_ptr = GET_RTX_FORMAT (code);\n-  for (i = 0; i < GET_RTX_LENGTH (code); i++)\n-    switch (*format_ptr++)\n-      {\n-      case 'e':\n-\tmark_set_resources (XEXP (x, i), res, in_dest, include_delayed_effects);\n-\tbreak;\n-\n-      case 'E':\n-\tfor (j = 0; j < XVECLEN (x, i); j++)\n-\t  mark_set_resources (XVECEXP (x, i, j), res, in_dest,\n-\t\t\t      include_delayed_effects);\n-\tbreak;\n-      }\n-}\n \f\n /* Return TRUE if this insn should stop the search for insn to fill delay\n    slots.  LABELS_P indicates that labels should terminate the search.\n@@ -988,16 +519,7 @@ add_to_delay_list (insn, delay_list)\n \n   if (delay_list == 0)\n     {\n-      struct target_info *tinfo;\n-      \n-      for (tinfo = target_hash_table[INSN_UID (insn) % TARGET_HASH_PRIME];\n-\t   tinfo; tinfo = tinfo->next)\n-\tif (tinfo->uid == INSN_UID (insn))\n-\t  break;\n-\n-      if (tinfo)\n-\ttinfo->block = -1;\n-\n+      clear_hashed_info_for_insn (insn);\n       return gen_rtx_INSN_LIST (VOIDmode, insn, NULL_RTX);\n     }\n \n@@ -2324,41 +1846,6 @@ own_thread_p (thread, label, allow_fallthrough)\n   return 1;\n }\n \f\n-/* Find the number of the basic block that starts closest to INSN.  Return -1\n-   if we couldn't find such a basic block.  */\n-\n-static int\n-find_basic_block (insn)\n-     rtx insn;\n-{\n-  int i;\n-\n-  /* Scan backwards to the previous BARRIER.  Then see if we can find a\n-     label that starts a basic block.  Return the basic block number.  */\n-\n-  for (insn = prev_nonnote_insn (insn);\n-       insn && GET_CODE (insn) != BARRIER;\n-       insn = prev_nonnote_insn (insn))\n-    ;\n-\n-  /* The start of the function is basic block zero.  */\n-  if (insn == 0)\n-    return 0;\n-\n-  /* See if any of the upcoming CODE_LABELs start a basic block.  If we reach\n-     anything other than a CODE_LABEL or note, we can't find this code.  */\n-  for (insn = next_nonnote_insn (insn);\n-       insn && GET_CODE (insn) == CODE_LABEL;\n-       insn = next_nonnote_insn (insn))\n-    {\n-      for (i = 0; i < n_basic_blocks; i++)\n-\tif (insn == BLOCK_HEAD (i))\n-\t  return i;\n-    }\n-\n-  return -1;\n-}\n-\f\n /* Called when INSN is being moved from a location near the target of a jump.\n    We leave a marker of the form (use (INSN)) immediately in front\n    of WHERE for mark_target_live_regs.  These markers will be deleted when\n@@ -2373,8 +1860,6 @@ update_block (insn, where)\n      rtx insn;\n      rtx where;\n {\n-  int b;\n-\n   /* Ignore if this was in a delay slot and it came from the target of \n      a branch.  */\n   if (INSN_FROM_TARGET_P (insn))\n@@ -2385,9 +1870,7 @@ update_block (insn, where)\n   /* INSN might be making a value live in a block where it didn't use to\n      be.  So recompute liveness information for this block.  */\n \n-  b = find_basic_block (insn);\n-  if (b != -1)\n-    bb_ticks[b]++;\n+  incr_ticks_for_insn (insn);\n }\n \n /* Similar to REDIRECT_JUMP except that we update the BB_TICKS entry for\n@@ -2398,11 +1881,7 @@ reorg_redirect_jump (jump, nlabel)\n      rtx jump;\n      rtx nlabel;\n {\n-  int b = find_basic_block (jump);\n-\n-  if (b != -1)\n-    bb_ticks[b]++;\n-\n+  incr_ticks_for_insn (jump);\n   return redirect_jump (jump, nlabel);\n }\n \n@@ -2502,549 +1981,6 @@ update_reg_unused_notes (insn, redundant_insn)\n     }\n }\n \f\n-/* Marks registers possibly live at the current place being scanned by\n-   mark_target_live_regs.  Used only by next two function.    */\n-\n-static HARD_REG_SET current_live_regs;\n-\n-/* Marks registers for which we have seen a REG_DEAD note but no assignment.\n-   Also only used by the next two functions.  */\n-\n-static HARD_REG_SET pending_dead_regs;\n-\n-/* Utility function called from mark_target_live_regs via note_stores.\n-   It deadens any CLOBBERed registers and livens any SET registers.  */\n-\n-static void\n-update_live_status (dest, x)\n-     rtx dest;\n-     rtx x;\n-{\n-  int first_regno, last_regno;\n-  int i;\n-\n-  if (GET_CODE (dest) != REG\n-      && (GET_CODE (dest) != SUBREG || GET_CODE (SUBREG_REG (dest)) != REG))\n-    return;\n-\n-  if (GET_CODE (dest) == SUBREG)\n-    first_regno = REGNO (SUBREG_REG (dest)) + SUBREG_WORD (dest);\n-  else\n-    first_regno = REGNO (dest);\n-\n-  last_regno = first_regno + HARD_REGNO_NREGS (first_regno, GET_MODE (dest));\n-\n-  if (GET_CODE (x) == CLOBBER)\n-    for (i = first_regno; i < last_regno; i++)\n-      CLEAR_HARD_REG_BIT (current_live_regs, i);\n-  else\n-    for (i = first_regno; i < last_regno; i++)\n-      {\n-\tSET_HARD_REG_BIT (current_live_regs, i);\n-\tCLEAR_HARD_REG_BIT (pending_dead_regs, i);\n-      }\n-}\n-\n-/* Similar to next_insn, but ignores insns in the delay slots of\n-   an annulled branch.  */\n-\n-static rtx\n-next_insn_no_annul (insn)\n-     rtx insn;\n-{\n-  if (insn)\n-    {\n-      /* If INSN is an annulled branch, skip any insns from the target\n-\t of the branch.  */\n-      if (INSN_ANNULLED_BRANCH_P (insn)\n-\t  && NEXT_INSN (PREV_INSN (insn)) != insn)\n-\twhile (INSN_FROM_TARGET_P (NEXT_INSN (insn)))\n-\t  insn = NEXT_INSN (insn);\n-\n-      insn = NEXT_INSN (insn);\n-      if (insn && GET_CODE (insn) == INSN\n-\t  && GET_CODE (PATTERN (insn)) == SEQUENCE)\n-\tinsn = XVECEXP (PATTERN (insn), 0, 0);\n-    }\n-\n-  return insn;\n-}\n-\f\n-/* A subroutine of mark_target_live_regs.  Search forward from TARGET\n-   looking for registers that are set before they are used.  These are dead. \n-   Stop after passing a few conditional jumps, and/or a small\n-   number of unconditional branches.  */\n-\n-static rtx\n-find_dead_or_set_registers (target, res, jump_target, jump_count, set, needed)\n-     rtx target;\n-     struct resources *res;\n-     rtx *jump_target;\n-     int jump_count;\n-     struct resources set, needed;\n-{\n-  HARD_REG_SET scratch;\n-  rtx insn, next;\n-  rtx jump_insn = 0;\n-  int i;\n-\n-  for (insn = target; insn; insn = next)\n-    {\n-      rtx this_jump_insn = insn;\n-\n-      next = NEXT_INSN (insn);\n-      switch (GET_CODE (insn))\n-\t{\n-\tcase CODE_LABEL:\n-\t  /* After a label, any pending dead registers that weren't yet\n-\t     used can be made dead.  */\n-\t  AND_COMPL_HARD_REG_SET (pending_dead_regs, needed.regs);\n-\t  AND_COMPL_HARD_REG_SET (res->regs, pending_dead_regs);\n-\t  CLEAR_HARD_REG_SET (pending_dead_regs);\n-\n-\t  continue;\n-\n-\tcase BARRIER:\n-\tcase NOTE:\n-\t  continue;\n-\n-\tcase INSN:\n-\t  if (GET_CODE (PATTERN (insn)) == USE)\n-\t    {\n-\t      /* If INSN is a USE made by update_block, we care about the\n-\t\t underlying insn.  Any registers set by the underlying insn\n-\t\t are live since the insn is being done somewhere else.  */\n-\t      if (GET_RTX_CLASS (GET_CODE (XEXP (PATTERN (insn), 0))) == 'i')\n-\t\tmark_set_resources (XEXP (PATTERN (insn), 0), res, 0, 1);\n-\n-\t      /* All other USE insns are to be ignored.  */\n-\t      continue;\n-\t    }\n-\t  else if (GET_CODE (PATTERN (insn)) == CLOBBER)\n-\t    continue;\n-\t  else if (GET_CODE (PATTERN (insn)) == SEQUENCE)\n-\t    {\n-\t      /* An unconditional jump can be used to fill the delay slot\n-\t\t of a call, so search for a JUMP_INSN in any position.  */\n-\t      for (i = 0; i < XVECLEN (PATTERN (insn), 0); i++)\n-\t\t{\n-\t\t  this_jump_insn = XVECEXP (PATTERN (insn), 0, i);\n-\t\t  if (GET_CODE (this_jump_insn) == JUMP_INSN)\n-\t\t    break;\n-\t\t}\n-\t    }\n-\n-\tdefault:\n-\t  break;\n-\t}\n-\n-      if (GET_CODE (this_jump_insn) == JUMP_INSN)\n-\t{\n-\t  if (jump_count++ < 10)\n-\t    {\n-\t      if (simplejump_p (this_jump_insn)\n-\t\t  || GET_CODE (PATTERN (this_jump_insn)) == RETURN)\n-\t\t{\n-\t\t  next = JUMP_LABEL (this_jump_insn);\n-\t\t  if (jump_insn == 0)\n-\t\t    {\n-\t\t      jump_insn = insn;\n-\t\t      if (jump_target)\n-\t\t\t*jump_target = JUMP_LABEL (this_jump_insn);\n-\t\t    }\n-\t\t}\n-\t      else if (condjump_p (this_jump_insn)\n-\t\t       || condjump_in_parallel_p (this_jump_insn))\n-\t\t{\n-\t\t  struct resources target_set, target_res;\n-\t\t  struct resources fallthrough_res;\n-\n-\t\t  /* We can handle conditional branches here by following\n-\t\t     both paths, and then IOR the results of the two paths\n-\t\t     together, which will give us registers that are dead\n-\t\t     on both paths.  Since this is expensive, we give it\n-\t\t     a much higher cost than unconditional branches.  The\n-\t\t     cost was chosen so that we will follow at most 1\n-\t\t     conditional branch.  */\n-\n-\t\t  jump_count += 4;\n-\t\t  if (jump_count >= 10)\n-\t\t    break;\n-\n-\t\t  mark_referenced_resources (insn, &needed, 1);\n-\n-\t\t  /* For an annulled branch, mark_set_resources ignores slots\n-\t\t     filled by instructions from the target.  This is correct\n-\t\t     if the branch is not taken.  Since we are following both\n-\t\t     paths from the branch, we must also compute correct info\n-\t\t     if the branch is taken.  We do this by inverting all of\n-\t\t     the INSN_FROM_TARGET_P bits, calling mark_set_resources,\n-\t\t     and then inverting the INSN_FROM_TARGET_P bits again.  */\n-\n-\t\t  if (GET_CODE (PATTERN (insn)) == SEQUENCE\n-\t\t      && INSN_ANNULLED_BRANCH_P (this_jump_insn))\n-\t\t    {\n-\t\t      for (i = 1; i < XVECLEN (PATTERN (insn), 0); i++)\n-\t\t\tINSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i))\n-\t\t\t  = ! INSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i));\n-\n-\t\t      target_set = set;\n-\t\t      mark_set_resources (insn, &target_set, 0, 1);\n-\n-\t\t      for (i = 1; i < XVECLEN (PATTERN (insn), 0); i++)\n-\t\t\tINSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i))\n-\t\t\t  = ! INSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i));\n-\n-\t\t      mark_set_resources (insn, &set, 0, 1);\n-\t\t    }\n-\t\t  else\n-\t\t    {\n-\t\t      mark_set_resources (insn, &set, 0, 1);\n-\t\t      target_set = set;\n-\t\t    }\n-\n-\t\t  target_res = *res;\n-\t\t  COPY_HARD_REG_SET (scratch, target_set.regs);\n-\t\t  AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n-\t\t  AND_COMPL_HARD_REG_SET (target_res.regs, scratch);\n-\n-\t\t  fallthrough_res = *res;\n-\t\t  COPY_HARD_REG_SET (scratch, set.regs);\n-\t\t  AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n-\t\t  AND_COMPL_HARD_REG_SET (fallthrough_res.regs, scratch);\n-\n-\t\t  find_dead_or_set_registers (JUMP_LABEL (this_jump_insn),\n-\t\t\t\t\t      &target_res, 0, jump_count,\n-\t\t\t\t\t      target_set, needed);\n-\t\t  find_dead_or_set_registers (next,\n-\t\t\t\t\t      &fallthrough_res, 0, jump_count,\n-\t\t\t\t\t      set, needed);\n-\t\t  IOR_HARD_REG_SET (fallthrough_res.regs, target_res.regs);\n-\t\t  AND_HARD_REG_SET (res->regs, fallthrough_res.regs);\n-\t\t  break;\n-\t\t}\n-\t      else\n-\t\tbreak;\n-\t    }\n-\t  else\n-\t    {\n-\t      /* Don't try this optimization if we expired our jump count\n-\t\t above, since that would mean there may be an infinite loop\n-\t\t in the function being compiled.  */\n-\t      jump_insn = 0;\n-\t      break;\n-\t    }\n-\t}\n-\n-      mark_referenced_resources (insn, &needed, 1);\n-      mark_set_resources (insn, &set, 0, 1);\n-\n-      COPY_HARD_REG_SET (scratch, set.regs);\n-      AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n-      AND_COMPL_HARD_REG_SET (res->regs, scratch);\n-    }\n-\n-  return jump_insn;\n-}\n-\n-/* Set the resources that are live at TARGET.\n-\n-   If TARGET is zero, we refer to the end of the current function and can\n-   return our precomputed value.\n-\n-   Otherwise, we try to find out what is live by consulting the basic block\n-   information.  This is tricky, because we must consider the actions of\n-   reload and jump optimization, which occur after the basic block information\n-   has been computed.\n-\n-   Accordingly, we proceed as follows::\n-\n-   We find the previous BARRIER and look at all immediately following labels\n-   (with no intervening active insns) to see if any of them start a basic\n-   block.  If we hit the start of the function first, we use block 0.\n-\n-   Once we have found a basic block and a corresponding first insns, we can\n-   accurately compute the live status from basic_block_live_regs and\n-   reg_renumber.  (By starting at a label following a BARRIER, we are immune\n-   to actions taken by reload and jump.)  Then we scan all insns between\n-   that point and our target.  For each CLOBBER (or for call-clobbered regs\n-   when we pass a CALL_INSN), mark the appropriate registers are dead.  For\n-   a SET, mark them as live.\n-\n-   We have to be careful when using REG_DEAD notes because they are not\n-   updated by such things as find_equiv_reg.  So keep track of registers\n-   marked as dead that haven't been assigned to, and mark them dead at the\n-   next CODE_LABEL since reload and jump won't propagate values across labels.\n-\n-   If we cannot find the start of a basic block (should be a very rare\n-   case, if it can happen at all), mark everything as potentially live.\n-\n-   Next, scan forward from TARGET looking for things set or clobbered\n-   before they are used.  These are not live.\n-\n-   Because we can be called many times on the same target, save our results\n-   in a hash table indexed by INSN_UID.  */\n-\n-static void\n-mark_target_live_regs (target, res)\n-     rtx target;\n-     struct resources *res;\n-{\n-  int b = -1;\n-  int i;\n-  struct target_info *tinfo;\n-  rtx insn;\n-  rtx jump_insn = 0;\n-  rtx jump_target;\n-  HARD_REG_SET scratch;\n-  struct resources set, needed;\n-\n-  /* Handle end of function.  */\n-  if (target == 0)\n-    {\n-      *res = end_of_function_needs;\n-      return;\n-    }\n-\n-  /* We have to assume memory is needed, but the CC isn't.  */\n-  res->memory = 1;\n-  res->volatil = res->unch_memory = 0;\n-  res->cc = 0;\n-\n-  /* See if we have computed this value already.  */\n-  for (tinfo = target_hash_table[INSN_UID (target) % TARGET_HASH_PRIME];\n-       tinfo; tinfo = tinfo->next)\n-    if (tinfo->uid == INSN_UID (target))\n-      break;\n-\n-  /* Start by getting the basic block number.  If we have saved information,\n-     we can get it from there unless the insn at the start of the basic block\n-     has been deleted.  */\n-  if (tinfo && tinfo->block != -1\n-      && ! INSN_DELETED_P (BLOCK_HEAD (tinfo->block)))\n-    b = tinfo->block;\n-\n-  if (b == -1)\n-    b = find_basic_block (target);\n-\n-  if (tinfo)\n-    {\n-      /* If the information is up-to-date, use it.  Otherwise, we will\n-\t update it below.  */\n-      if (b == tinfo->block && b != -1 && tinfo->bb_tick == bb_ticks[b])\n-\t{\n-\t  COPY_HARD_REG_SET (res->regs, tinfo->live_regs);\n-\t  return;\n-\t}\n-    }\n-  else\n-    {\n-      /* Allocate a place to put our results and chain it into the \n-\t hash table.  */\n-      tinfo = (struct target_info *) oballoc (sizeof (struct target_info));\n-      tinfo->uid = INSN_UID (target);\n-      tinfo->block = b;\n-      tinfo->next = target_hash_table[INSN_UID (target) % TARGET_HASH_PRIME];\n-      target_hash_table[INSN_UID (target) % TARGET_HASH_PRIME] = tinfo;\n-    }\n-\n-  CLEAR_HARD_REG_SET (pending_dead_regs);\n-\n-  /* If we found a basic block, get the live registers from it and update\n-     them with anything set or killed between its start and the insn before\n-     TARGET.  Otherwise, we must assume everything is live.  */\n-  if (b != -1)\n-    {\n-      regset regs_live = basic_block_live_at_start[b];\n-      int j;\n-      int regno;\n-      rtx start_insn, stop_insn;\n-\n-      /* Compute hard regs live at start of block -- this is the real hard regs\n-\t marked live, plus live pseudo regs that have been renumbered to\n-\t hard regs.  */\n-\n-      REG_SET_TO_HARD_REG_SET (current_live_regs, regs_live);\n-\n-      EXECUTE_IF_SET_IN_REG_SET\n-\t(regs_live, FIRST_PSEUDO_REGISTER, i,\n-\t {\n-\t   if ((regno = reg_renumber[i]) >= 0)\n-\t     for (j = regno;\n-\t\t  j < regno + HARD_REGNO_NREGS (regno,\n-\t\t\t\t\t\tPSEUDO_REGNO_MODE (i));\n-\t\t  j++)\n-\t       SET_HARD_REG_BIT (current_live_regs, j);\n-\t });\n-\n-      /* Get starting and ending insn, handling the case where each might\n-\t be a SEQUENCE.  */\n-      start_insn = (b == 0 ? get_insns () : BLOCK_HEAD (b));\n-      stop_insn = target;\n-\n-      if (GET_CODE (start_insn) == INSN\n-\t  && GET_CODE (PATTERN (start_insn)) == SEQUENCE)\n-\tstart_insn = XVECEXP (PATTERN (start_insn), 0, 0);\n-\n-      if (GET_CODE (stop_insn) == INSN\n-\t  && GET_CODE (PATTERN (stop_insn)) == SEQUENCE)\n-\tstop_insn = next_insn (PREV_INSN (stop_insn));\n-\n-      for (insn = start_insn; insn != stop_insn;\n-\t   insn = next_insn_no_annul (insn))\n-\t{\n-\t  rtx link;\n-\t  rtx real_insn = insn;\n-\n-\t  /* If this insn is from the target of a branch, it isn't going to\n-\t     be used in the sequel.  If it is used in both cases, this\n-\t     test will not be true.  */\n-\t  if (INSN_FROM_TARGET_P (insn))\n-\t    continue;\n-\n-\t  /* If this insn is a USE made by update_block, we care about the\n-\t     underlying insn.  */\n-\t  if (GET_CODE (insn) == INSN && GET_CODE (PATTERN (insn)) == USE\n-\t      && GET_RTX_CLASS (GET_CODE (XEXP (PATTERN (insn), 0))) == 'i')\n-\t      real_insn = XEXP (PATTERN (insn), 0);\n-\n-\t  if (GET_CODE (real_insn) == CALL_INSN)\n-\t    {\n-\t      /* CALL clobbers all call-used regs that aren't fixed except\n-\t\t sp, ap, and fp.  Do this before setting the result of the\n-\t\t call live.  */\n-\t      for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-\t\tif (call_used_regs[i]\n-\t\t    && i != STACK_POINTER_REGNUM && i != FRAME_POINTER_REGNUM\n-\t\t    && i != ARG_POINTER_REGNUM\n-#if HARD_FRAME_POINTER_REGNUM != FRAME_POINTER_REGNUM\n-\t\t    && i != HARD_FRAME_POINTER_REGNUM\n-#endif\n-#if ARG_POINTER_REGNUM != FRAME_POINTER_REGNUM\n-\t\t    && ! (i == ARG_POINTER_REGNUM && fixed_regs[i])\n-#endif\n-#ifdef PIC_OFFSET_TABLE_REGNUM\n-\t\t    && ! (i == PIC_OFFSET_TABLE_REGNUM && flag_pic)\n-#endif\n-\t\t    )\n-\t\t  CLEAR_HARD_REG_BIT (current_live_regs, i);\n-\n-\t      /* A CALL_INSN sets any global register live, since it may\n-\t\t have been modified by the call.  */\n-\t      for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-\t\tif (global_regs[i])\n-\t\t  SET_HARD_REG_BIT (current_live_regs, i);\n-\t    }\n-\n-\t  /* Mark anything killed in an insn to be deadened at the next\n-\t     label.  Ignore USE insns; the only REG_DEAD notes will be for\n-\t     parameters.  But they might be early.  A CALL_INSN will usually\n-\t     clobber registers used for parameters.  It isn't worth bothering\n-\t     with the unlikely case when it won't.  */\n-\t  if ((GET_CODE (real_insn) == INSN\n-\t       && GET_CODE (PATTERN (real_insn)) != USE\n-\t       && GET_CODE (PATTERN (real_insn)) != CLOBBER)\n-\t      || GET_CODE (real_insn) == JUMP_INSN\n-\t      || GET_CODE (real_insn) == CALL_INSN)\n-\t    {\n-\t      for (link = REG_NOTES (real_insn); link; link = XEXP (link, 1))\n-\t\tif (REG_NOTE_KIND (link) == REG_DEAD\n-\t\t    && GET_CODE (XEXP (link, 0)) == REG\n-\t\t    && REGNO (XEXP (link, 0)) < FIRST_PSEUDO_REGISTER)\n-\t\t  {\n-\t\t    int first_regno = REGNO (XEXP (link, 0));\n-\t\t    int last_regno\n-\t\t      = (first_regno\n-\t\t\t + HARD_REGNO_NREGS (first_regno,\n-\t\t\t\t\t     GET_MODE (XEXP (link, 0))));\n-\t\t\t \n-\t\t    for (i = first_regno; i < last_regno; i++)\n-\t\t      SET_HARD_REG_BIT (pending_dead_regs, i);\n-\t\t  }\n-\n-\t      note_stores (PATTERN (real_insn), update_live_status);\n-\n-\t      /* If any registers were unused after this insn, kill them.\n-\t\t These notes will always be accurate.  */\n-\t      for (link = REG_NOTES (real_insn); link; link = XEXP (link, 1))\n-\t\tif (REG_NOTE_KIND (link) == REG_UNUSED\n-\t\t    && GET_CODE (XEXP (link, 0)) == REG\n-\t\t    && REGNO (XEXP (link, 0)) < FIRST_PSEUDO_REGISTER)\n-\t\t  {\n-\t\t    int first_regno = REGNO (XEXP (link, 0));\n-\t\t    int last_regno\n-\t\t      = (first_regno\n-\t\t\t + HARD_REGNO_NREGS (first_regno,\n-\t\t\t\t\t     GET_MODE (XEXP (link, 0))));\n-\t\t\t \n-\t\t    for (i = first_regno; i < last_regno; i++)\n-\t\t      CLEAR_HARD_REG_BIT (current_live_regs, i);\n-\t\t  }\n-\t    }\n-\n-\t  else if (GET_CODE (real_insn) == CODE_LABEL)\n-\t    {\n-\t      /* A label clobbers the pending dead registers since neither\n-\t\t reload nor jump will propagate a value across a label.  */\n-\t      AND_COMPL_HARD_REG_SET (current_live_regs, pending_dead_regs);\n-\t      CLEAR_HARD_REG_SET (pending_dead_regs);\n-\t    }\n-\n-\t  /* The beginning of the epilogue corresponds to the end of the\n-\t     RTL chain when there are no epilogue insns.  Certain resources\n-\t     are implicitly required at that point.  */\n-\t  else if (GET_CODE (real_insn) == NOTE\n- \t\t   && NOTE_LINE_NUMBER (real_insn) == NOTE_INSN_EPILOGUE_BEG)\n-\t    IOR_HARD_REG_SET (current_live_regs, start_of_epilogue_needs.regs);\n-\t}\n-\n-      COPY_HARD_REG_SET (res->regs, current_live_regs);\n-      tinfo->block = b;\n-      tinfo->bb_tick = bb_ticks[b];\n-    }\n-  else\n-    /* We didn't find the start of a basic block.  Assume everything\n-       in use.  This should happen only extremely rarely.  */\n-    SET_HARD_REG_SET (res->regs);\n-\n-  CLEAR_RESOURCE (&set);\n-  CLEAR_RESOURCE (&needed);\n-\n-  jump_insn = find_dead_or_set_registers (target, res, &jump_target, 0,\n-\t\t\t\t\t  set, needed);\n-\n-  /* If we hit an unconditional branch, we have another way of finding out\n-     what is live: we can see what is live at the branch target and include\n-     anything used but not set before the branch.  The only things that are\n-     live are those that are live using the above test and the test below.  */\n-\n-  if (jump_insn)\n-    {\n-      struct resources new_resources;\n-      rtx stop_insn = next_active_insn (jump_insn);\n-\n-      mark_target_live_regs (next_active_insn (jump_target), &new_resources);\n-      CLEAR_RESOURCE (&set);\n-      CLEAR_RESOURCE (&needed);\n-\n-      /* Include JUMP_INSN in the needed registers.  */\n-      for (insn = target; insn != stop_insn; insn = next_active_insn (insn))\n-\t{\n-\t  mark_referenced_resources (insn, &needed, 1);\n-\n-\t  COPY_HARD_REG_SET (scratch, needed.regs);\n-\t  AND_COMPL_HARD_REG_SET (scratch, set.regs);\n-\t  IOR_HARD_REG_SET (new_resources.regs, scratch);\n-\n-\t  mark_set_resources (insn, &set, 0, 1);\n-\t}\n-\n-      AND_HARD_REG_SET (res->regs, new_resources.regs);\n-    }\n-\n-  COPY_HARD_REG_SET (tinfo->live_regs, res->regs);\n-}\n-\f\n /* Scan a function looking for insns that need a delay slot and find insns to\n    put into the delay slot.\n \n@@ -3317,9 +2253,11 @@ fill_simple_delay_slots (non_jumps_p)\n \t\t    break;\n \t\t  else if (JUMP_LABEL (trial_delay) != target)\n \t\t    {\n-\t\t      mark_target_live_regs\n-\t\t\t(next_active_insn (JUMP_LABEL (trial_delay)),\n-\t\t\t &needed_at_jump);\n+\t\t      rtx ninsn = \n+\t\t\tnext_active_insn (JUMP_LABEL (trial_delay));\n+\n+\t\t      mark_target_live_regs (get_insns (), ninsn,\n+\t\t\t\t\t     &needed_at_jump);\n \t\t      needed.memory |= needed_at_jump.memory;\n \t\t      needed.unch_memory |= needed_at_jump.unch_memory;\n \t\t      IOR_HARD_REG_SET (needed.regs, needed_at_jump.regs);\n@@ -3505,7 +2443,7 @@ fill_simple_delay_slots (non_jumps_p)\n \t      current_function_epilogue_delay_list\n \t\t= gen_rtx_INSN_LIST (VOIDmode, trial,\n \t\t\t\t     current_function_epilogue_delay_list);\n-\t      mark_referenced_resources (trial, &end_of_function_needs, 1);\n+\t      mark_end_of_function_resources (trial, 1);\n \t      update_block (trial, trial);\n \t      delete_insn (trial);\n \n@@ -3587,7 +2525,7 @@ fill_slots_from_thread (insn, condition, thread, opposite_thread, likely,\n   if (condition == const_true_rtx)\n     CLEAR_RESOURCE (&opposite_needed);\n   else\n-    mark_target_live_regs (opposite_thread, &opposite_needed);\n+    mark_target_live_regs (get_insns (), opposite_thread, &opposite_needed);\n \n   /* If the insn at THREAD can be split, do it here to avoid having to\n      update THREAD and NEW_THREAD if it is done in the loop below.  Also\n@@ -4623,80 +3561,11 @@ dbr_schedule (first, file)\n \tredirect_jump (insn, target);\n     }\n \n-  /* Indicate what resources are required to be valid at the end of the current\n-     function.  The condition code never is and memory always is.  If the\n-     frame pointer is needed, it is and so is the stack pointer unless\n-     EXIT_IGNORE_STACK is non-zero.  If the frame pointer is not needed, the\n-     stack pointer is.  Registers used to return the function value are\n-     needed.  Registers holding global variables are needed.  */\n-\n-  end_of_function_needs.cc = 0;\n-  end_of_function_needs.memory = 1;\n-  end_of_function_needs.unch_memory = 0;\n-  CLEAR_HARD_REG_SET (end_of_function_needs.regs);\n-\n-  if (frame_pointer_needed)\n-    {\n-      SET_HARD_REG_BIT (end_of_function_needs.regs, FRAME_POINTER_REGNUM);\n-#if HARD_FRAME_POINTER_REGNUM != FRAME_POINTER_REGNUM\n-      SET_HARD_REG_BIT (end_of_function_needs.regs, HARD_FRAME_POINTER_REGNUM);\n-#endif\n-#ifdef EXIT_IGNORE_STACK\n-      if (! EXIT_IGNORE_STACK\n-\t  || current_function_sp_is_unchanging)\n-#endif\n-\tSET_HARD_REG_BIT (end_of_function_needs.regs, STACK_POINTER_REGNUM);\n-    }\n-  else\n-    SET_HARD_REG_BIT (end_of_function_needs.regs, STACK_POINTER_REGNUM);\n-\n-  if (current_function_return_rtx != 0)\n-    mark_referenced_resources (current_function_return_rtx,\n-\t\t\t       &end_of_function_needs, 1);\n-\n-  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-    if (global_regs[i]\n-#ifdef EPILOGUE_USES\n-\t|| EPILOGUE_USES (i)\n-#endif\n-\t)\n-      SET_HARD_REG_BIT (end_of_function_needs.regs, i);\n-\n-  /* The registers required to be live at the end of the function are\n-     represented in the flow information as being dead just prior to\n-     reaching the end of the function.  For example, the return of a value\n-     might be represented by a USE of the return register immediately\n-     followed by an unconditional jump to the return label where the\n-     return label is the end of the RTL chain.  The end of the RTL chain\n-     is then taken to mean that the return register is live.\n-\n-     This sequence is no longer maintained when epilogue instructions are\n-     added to the RTL chain.  To reconstruct the original meaning, the\n-     start of the epilogue (NOTE_INSN_EPILOGUE_BEG) is regarded as the\n-     point where these registers become live (start_of_epilogue_needs).\n-     If epilogue instructions are present, the registers set by those\n-     instructions won't have been processed by flow.  Thus, those\n-     registers are additionally required at the end of the RTL chain\n-     (end_of_function_needs).  */\n-\n-  start_of_epilogue_needs = end_of_function_needs;\n-\n-  while ((epilogue_insn = next_nonnote_insn (epilogue_insn)))\n-    mark_set_resources (epilogue_insn, &end_of_function_needs, 0, 1);\n+  init_resource_info (epilogue_insn);\n \n   /* Show we haven't computed an end-of-function label yet.  */\n   end_of_function_label = 0;\n \n-  /* Allocate and initialize the tables used by mark_target_live_regs.  */\n-  target_hash_table\n-    = (struct target_info **) alloca ((TARGET_HASH_PRIME\n-\t\t\t\t       * sizeof (struct target_info *)));\n-  bzero ((char *) target_hash_table,\n-\t TARGET_HASH_PRIME * sizeof (struct target_info *));\n-\n-  bb_ticks = (int *) alloca (n_basic_blocks * sizeof (int));\n-  bzero ((char *) bb_ticks, n_basic_blocks * sizeof (int));\n-\n   /* Initialize the statistics for this function.  */\n   bzero ((char *) num_insns_needing_delays, sizeof num_insns_needing_delays);\n   bzero ((char *) num_filled_delays, sizeof num_filled_delays);\n@@ -4800,5 +3669,6 @@ dbr_schedule (first, file)\n \t\t\t\t\t    GEN_INT (pred_flags),\n \t\t\t\t\t    REG_NOTES (insn));\n     }\n+  free_resource_info ();\n }\n #endif /* DELAY_SLOTS */"}, {"sha": "020212c21fe5511bcbc86393f22bb068219617f3", "filename": "gcc/resource.c", "status": "added", "additions": 1239, "deletions": 0, "changes": 1239, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Fresource.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Fresource.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fresource.c?ref=ca545bb569b7560793928e1c597bb1df499f8855", "patch": "@@ -0,0 +1,1239 @@\n+#include \"config.h\"\n+#include \"rtl.h\"\n+#include \"hard-reg-set.h\"\n+#include \"system.h\"\n+#include \"basic-block.h\"\n+#include \"regs.h\"\n+#include \"flags.h\"\n+#include \"output.h\"\n+#include \"resource.h\"\n+\n+/* This structure is used to record liveness information at the targets or\n+   fallthrough insns of branches.  We will most likely need the information\n+   at targets again, so save them in a hash table rather than recomputing them\n+   each time.  */\n+\n+struct target_info\n+{\n+  int uid;\t\t\t/* INSN_UID of target.  */\n+  struct target_info *next;\t/* Next info for same hash bucket.  */\n+  HARD_REG_SET live_regs;\t/* Registers live at target.  */\n+  int block;\t\t\t/* Basic block number containing target.  */\n+  int bb_tick;\t\t\t/* Generation count of basic block info.  */\n+};\n+\n+#define TARGET_HASH_PRIME 257\n+\n+/* Indicates what resources are required at the beginning of the epilogue.  */\n+static struct resources start_of_epilogue_needs;\n+\n+/* Indicates what resources are required at function end.  */\n+static struct resources end_of_function_needs;\n+\n+/* Define the hash table itself.  */\n+static struct target_info **target_hash_table = NULL;\n+\n+/* For each basic block, we maintain a generation number of its basic\n+   block info, which is updated each time we move an insn from the\n+   target of a jump.  This is the generation number indexed by block\n+   number.  */\n+\n+static int *bb_ticks;\n+\n+/* Marks registers possibly live at the current place being scanned by\n+   mark_target_live_regs.  Used only by next two function.    */\n+\n+static HARD_REG_SET current_live_regs;\n+\n+/* Marks registers for which we have seen a REG_DEAD note but no assignment.\n+   Also only used by the next two functions.  */\n+\n+static HARD_REG_SET pending_dead_regs;\n+\n+/* Utility function called from mark_target_live_regs via note_stores.\n+   It deadens any CLOBBERed registers and livens any SET registers.  */\n+\n+static void\n+update_live_status (dest, x)\n+     rtx dest;\n+     rtx x;\n+{\n+  int first_regno, last_regno;\n+  int i;\n+\n+  if (GET_CODE (dest) != REG\n+      && (GET_CODE (dest) != SUBREG || GET_CODE (SUBREG_REG (dest)) != REG))\n+    return;\n+\n+  if (GET_CODE (dest) == SUBREG)\n+    first_regno = REGNO (SUBREG_REG (dest)) + SUBREG_WORD (dest);\n+  else\n+    first_regno = REGNO (dest);\n+\n+  last_regno = first_regno + HARD_REGNO_NREGS (first_regno, GET_MODE (dest));\n+\n+  if (GET_CODE (x) == CLOBBER)\n+    for (i = first_regno; i < last_regno; i++)\n+      CLEAR_HARD_REG_BIT (current_live_regs, i);\n+  else\n+    for (i = first_regno; i < last_regno; i++)\n+      {\n+\tSET_HARD_REG_BIT (current_live_regs, i);\n+\tCLEAR_HARD_REG_BIT (pending_dead_regs, i);\n+      }\n+}\n+/* Find the number of the basic block that starts closest to INSN.  Return -1\n+   if we couldn't find such a basic block.  */\n+\n+static int\n+find_basic_block (insn)\n+     rtx insn;\n+{\n+  int i;\n+\n+  /* Scan backwards to the previous BARRIER.  Then see if we can find a\n+     label that starts a basic block.  Return the basic block number.  */\n+\n+  for (insn = prev_nonnote_insn (insn);\n+       insn && GET_CODE (insn) != BARRIER;\n+       insn = prev_nonnote_insn (insn))\n+    ;\n+\n+  /* The start of the function is basic block zero.  */\n+  if (insn == 0)\n+    return 0;\n+\n+  /* See if any of the upcoming CODE_LABELs start a basic block.  If we reach\n+     anything other than a CODE_LABEL or note, we can't find this code.  */\n+  for (insn = next_nonnote_insn (insn);\n+       insn && GET_CODE (insn) == CODE_LABEL;\n+       insn = next_nonnote_insn (insn))\n+    {\n+      for (i = 0; i < n_basic_blocks; i++)\n+\tif (insn == BLOCK_HEAD (i))\n+\t  return i;\n+    }\n+\n+  return -1;\n+}\n+\f\n+/* Similar to next_insn, but ignores insns in the delay slots of\n+   an annulled branch.  */\n+\n+static rtx\n+next_insn_no_annul (insn)\n+     rtx insn;\n+{\n+  if (insn)\n+    {\n+      /* If INSN is an annulled branch, skip any insns from the target\n+\t of the branch.  */\n+      if (INSN_ANNULLED_BRANCH_P (insn)\n+\t  && NEXT_INSN (PREV_INSN (insn)) != insn)\n+\twhile (INSN_FROM_TARGET_P (NEXT_INSN (insn)))\n+\t  insn = NEXT_INSN (insn);\n+\n+      insn = NEXT_INSN (insn);\n+      if (insn && GET_CODE (insn) == INSN\n+\t  && GET_CODE (PATTERN (insn)) == SEQUENCE)\n+\tinsn = XVECEXP (PATTERN (insn), 0, 0);\n+    }\n+\n+  return insn;\n+}\n+\f\n+/* Given X, some rtl, and RES, a pointer to a `struct resource', mark\n+   which resources are references by the insn.  If INCLUDE_DELAYED_EFFECTS\n+   is TRUE, resources used by the called routine will be included for\n+   CALL_INSNs.  */\n+\n+void\n+mark_referenced_resources (x, res, include_delayed_effects)\n+     register rtx x;\n+     register struct resources *res;\n+     register int include_delayed_effects;\n+{\n+  register enum rtx_code code = GET_CODE (x);\n+  register int i, j;\n+  register char *format_ptr;\n+\n+  /* Handle leaf items for which we set resource flags.  Also, special-case\n+     CALL, SET and CLOBBER operators.  */\n+  switch (code)\n+    {\n+    case CONST:\n+    case CONST_INT:\n+    case CONST_DOUBLE:\n+    case PC:\n+    case SYMBOL_REF:\n+    case LABEL_REF:\n+      return;\n+\n+    case SUBREG:\n+      if (GET_CODE (SUBREG_REG (x)) != REG)\n+\tmark_referenced_resources (SUBREG_REG (x), res, 0);\n+      else\n+\t{\n+\t  int regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n+\t  int last_regno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+\t  for (i = regno; i < last_regno; i++)\n+\t    SET_HARD_REG_BIT (res->regs, i);\n+\t}\n+      return;\n+\n+    case REG:\n+      for (i = 0; i < HARD_REGNO_NREGS (REGNO (x), GET_MODE (x)); i++)\n+\tSET_HARD_REG_BIT (res->regs, REGNO (x) + i);\n+      return;\n+\n+    case MEM:\n+      /* If this memory shouldn't change, it really isn't referencing\n+\t memory.  */\n+      if (RTX_UNCHANGING_P (x))\n+\tres->unch_memory = 1;\n+      else\n+\tres->memory = 1;\n+      res->volatil = MEM_VOLATILE_P (x);\n+\n+      /* Mark registers used to access memory.  */\n+      mark_referenced_resources (XEXP (x, 0), res, 0);\n+      return;\n+\n+    case CC0:\n+      res->cc = 1;\n+      return;\n+\n+    case UNSPEC_VOLATILE:\n+    case ASM_INPUT:\n+      /* Traditional asm's are always volatile.  */\n+      res->volatil = 1;\n+      return;\n+\n+    case TRAP_IF:\n+      res->volatil = 1;\n+      break;\n+\n+    case ASM_OPERANDS:\n+      res->volatil = MEM_VOLATILE_P (x);\n+\n+      /* For all ASM_OPERANDS, we must traverse the vector of input operands.\n+\t We can not just fall through here since then we would be confused\n+\t by the ASM_INPUT rtx inside ASM_OPERANDS, which do not indicate\n+\t traditional asms unlike their normal usage.  */\n+      \n+      for (i = 0; i < ASM_OPERANDS_INPUT_LENGTH (x); i++)\n+\tmark_referenced_resources (ASM_OPERANDS_INPUT (x, i), res, 0);\n+      return;\n+\n+    case CALL:\n+      /* The first operand will be a (MEM (xxx)) but doesn't really reference\n+\t memory.  The second operand may be referenced, though.  */\n+      mark_referenced_resources (XEXP (XEXP (x, 0), 0), res, 0);\n+      mark_referenced_resources (XEXP (x, 1), res, 0);\n+      return;\n+\n+    case SET:\n+      /* Usually, the first operand of SET is set, not referenced.  But\n+\t registers used to access memory are referenced.  SET_DEST is\n+\t also referenced if it is a ZERO_EXTRACT or SIGN_EXTRACT.  */\n+\n+      mark_referenced_resources (SET_SRC (x), res, 0);\n+\n+      x = SET_DEST (x);\n+      if (GET_CODE (x) == SIGN_EXTRACT || GET_CODE (x) == ZERO_EXTRACT)\n+\tmark_referenced_resources (x, res, 0);\n+      else if (GET_CODE (x) == SUBREG)\n+\tx = SUBREG_REG (x);\n+      if (GET_CODE (x) == MEM)\n+\tmark_referenced_resources (XEXP (x, 0), res, 0);\n+      return;\n+\n+    case CLOBBER:\n+      return;\n+\n+    case CALL_INSN:\n+      if (include_delayed_effects)\n+\t{\n+\t  /* A CALL references memory, the frame pointer if it exists, the\n+\t     stack pointer, any global registers and any registers given in\n+\t     USE insns immediately in front of the CALL.\n+\n+\t     However, we may have moved some of the parameter loading insns\n+\t     into the delay slot of this CALL.  If so, the USE's for them\n+\t     don't count and should be skipped.  */\n+\t  rtx insn = PREV_INSN (x);\n+\t  rtx sequence = 0;\n+\t  int seq_size = 0;\n+\t  rtx next = NEXT_INSN (x);\n+\t  int i;\n+\n+\t  /* If we are part of a delay slot sequence, point at the SEQUENCE.  */\n+\t  if (NEXT_INSN (insn) != x)\n+\t    {\n+\t      next = NEXT_INSN (NEXT_INSN (insn));\n+\t      sequence = PATTERN (NEXT_INSN (insn));\n+\t      seq_size = XVECLEN (sequence, 0);\n+\t      if (GET_CODE (sequence) != SEQUENCE)\n+\t\tabort ();\n+\t    }\n+\n+\t  res->memory = 1;\n+\t  SET_HARD_REG_BIT (res->regs, STACK_POINTER_REGNUM);\n+\t  if (frame_pointer_needed)\n+\t    {\n+\t      SET_HARD_REG_BIT (res->regs, FRAME_POINTER_REGNUM);\n+#if FRAME_POINTER_REGNUM != HARD_FRAME_POINTER_REGNUM\n+\t      SET_HARD_REG_BIT (res->regs, HARD_FRAME_POINTER_REGNUM);\n+#endif\n+\t    }\n+\n+\t  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+\t    if (global_regs[i])\n+\t      SET_HARD_REG_BIT (res->regs, i);\n+\n+\t  /* Check for a NOTE_INSN_SETJMP.  If it exists, then we must\n+\t     assume that this call can need any register.\n+\n+\t     This is done to be more conservative about how we handle setjmp.\n+\t     We assume that they both use and set all registers.  Using all\n+\t     registers ensures that a register will not be considered dead\n+\t     just because it crosses a setjmp call.  A register should be\n+\t     considered dead only if the setjmp call returns non-zero.  */\n+\t  if (next && GET_CODE (next) == NOTE\n+\t      && NOTE_LINE_NUMBER (next) == NOTE_INSN_SETJMP)\n+\t    SET_HARD_REG_SET (res->regs);\n+\n+\t  {\n+\t    rtx link;\n+\n+\t    for (link = CALL_INSN_FUNCTION_USAGE (x);\n+\t\t link;\n+\t\t link = XEXP (link, 1))\n+\t      if (GET_CODE (XEXP (link, 0)) == USE)\n+\t\t{\n+\t\t  for (i = 1; i < seq_size; i++)\n+\t\t    {\n+\t\t      rtx slot_pat = PATTERN (XVECEXP (sequence, 0, i));\n+\t\t      if (GET_CODE (slot_pat) == SET\n+\t\t\t  && rtx_equal_p (SET_DEST (slot_pat),\n+\t\t\t\t\t  SET_DEST (XEXP (link, 0))))\n+\t\t\tbreak;\n+\t\t    }\n+\t\t  if (i >= seq_size)\n+\t\t    mark_referenced_resources (SET_DEST (XEXP (link, 0)),\n+\t\t\t\t\t       res, 0);\n+\t\t}\n+\t  }\n+\t}\n+\n+      /* ... fall through to other INSN processing ...  */\n+\n+    case INSN:\n+    case JUMP_INSN:\n+\n+#ifdef INSN_REFERENCES_ARE_DELAYED\n+      if (! include_delayed_effects\n+\t  && INSN_REFERENCES_ARE_DELAYED (x))\n+\treturn;\n+#endif\n+\n+      /* No special processing, just speed up.  */\n+      mark_referenced_resources (PATTERN (x), res, include_delayed_effects);\n+      return;\n+\n+    default:\n+      break;\n+    }\n+\n+  /* Process each sub-expression and flag what it needs.  */\n+  format_ptr = GET_RTX_FORMAT (code);\n+  for (i = 0; i < GET_RTX_LENGTH (code); i++)\n+    switch (*format_ptr++)\n+      {\n+      case 'e':\n+\tmark_referenced_resources (XEXP (x, i), res, include_delayed_effects);\n+\tbreak;\n+\n+      case 'E':\n+\tfor (j = 0; j < XVECLEN (x, i); j++)\n+\t  mark_referenced_resources (XVECEXP (x, i, j), res,\n+\t\t\t\t     include_delayed_effects);\n+\tbreak;\n+      }\n+}\n+\f\n+/* A subroutine of mark_target_live_regs.  Search forward from TARGET\n+   looking for registers that are set before they are used.  These are dead. \n+   Stop after passing a few conditional jumps, and/or a small\n+   number of unconditional branches.  */\n+\n+static rtx\n+find_dead_or_set_registers (target, res, jump_target, jump_count, set, needed)\n+     rtx target;\n+     struct resources *res;\n+     rtx *jump_target;\n+     int jump_count;\n+     struct resources set, needed;\n+{\n+  HARD_REG_SET scratch;\n+  rtx insn, next;\n+  rtx jump_insn = 0;\n+  int i;\n+\n+  for (insn = target; insn; insn = next)\n+    {\n+      rtx this_jump_insn = insn;\n+\n+      next = NEXT_INSN (insn);\n+      switch (GET_CODE (insn))\n+\t{\n+\tcase CODE_LABEL:\n+\t  /* After a label, any pending dead registers that weren't yet\n+\t     used can be made dead.  */\n+\t  AND_COMPL_HARD_REG_SET (pending_dead_regs, needed.regs);\n+\t  AND_COMPL_HARD_REG_SET (res->regs, pending_dead_regs);\n+\t  CLEAR_HARD_REG_SET (pending_dead_regs);\n+\n+\t  continue;\n+\n+\tcase BARRIER:\n+\tcase NOTE:\n+\t  continue;\n+\n+\tcase INSN:\n+\t  if (GET_CODE (PATTERN (insn)) == USE)\n+\t    {\n+\t      /* If INSN is a USE made by update_block, we care about the\n+\t\t underlying insn.  Any registers set by the underlying insn\n+\t\t are live since the insn is being done somewhere else.  */\n+\t      if (GET_RTX_CLASS (GET_CODE (XEXP (PATTERN (insn), 0))) == 'i')\n+\t\tmark_set_resources (XEXP (PATTERN (insn), 0), res, 0, 1);\n+\n+\t      /* All other USE insns are to be ignored.  */\n+\t      continue;\n+\t    }\n+\t  else if (GET_CODE (PATTERN (insn)) == CLOBBER)\n+\t    continue;\n+\t  else if (GET_CODE (PATTERN (insn)) == SEQUENCE)\n+\t    {\n+\t      /* An unconditional jump can be used to fill the delay slot\n+\t\t of a call, so search for a JUMP_INSN in any position.  */\n+\t      for (i = 0; i < XVECLEN (PATTERN (insn), 0); i++)\n+\t\t{\n+\t\t  this_jump_insn = XVECEXP (PATTERN (insn), 0, i);\n+\t\t  if (GET_CODE (this_jump_insn) == JUMP_INSN)\n+\t\t    break;\n+\t\t}\n+\t    }\n+\n+\tdefault:\n+\t  break;\n+\t}\n+\n+      if (GET_CODE (this_jump_insn) == JUMP_INSN)\n+\t{\n+\t  if (jump_count++ < 10)\n+\t    {\n+\t      if (simplejump_p (this_jump_insn)\n+\t\t  || GET_CODE (PATTERN (this_jump_insn)) == RETURN)\n+\t\t{\n+\t\t  next = JUMP_LABEL (this_jump_insn);\n+\t\t  if (jump_insn == 0)\n+\t\t    {\n+\t\t      jump_insn = insn;\n+\t\t      if (jump_target)\n+\t\t\t*jump_target = JUMP_LABEL (this_jump_insn);\n+\t\t    }\n+\t\t}\n+\t      else if (condjump_p (this_jump_insn)\n+\t\t       || condjump_in_parallel_p (this_jump_insn))\n+\t\t{\n+\t\t  struct resources target_set, target_res;\n+\t\t  struct resources fallthrough_res;\n+\n+\t\t  /* We can handle conditional branches here by following\n+\t\t     both paths, and then IOR the results of the two paths\n+\t\t     together, which will give us registers that are dead\n+\t\t     on both paths.  Since this is expensive, we give it\n+\t\t     a much higher cost than unconditional branches.  The\n+\t\t     cost was chosen so that we will follow at most 1\n+\t\t     conditional branch.  */\n+\n+\t\t  jump_count += 4;\n+\t\t  if (jump_count >= 10)\n+\t\t    break;\n+\n+\t\t  mark_referenced_resources (insn, &needed, 1);\n+\n+\t\t  /* For an annulled branch, mark_set_resources ignores slots\n+\t\t     filled by instructions from the target.  This is correct\n+\t\t     if the branch is not taken.  Since we are following both\n+\t\t     paths from the branch, we must also compute correct info\n+\t\t     if the branch is taken.  We do this by inverting all of\n+\t\t     the INSN_FROM_TARGET_P bits, calling mark_set_resources,\n+\t\t     and then inverting the INSN_FROM_TARGET_P bits again.  */\n+\n+\t\t  if (GET_CODE (PATTERN (insn)) == SEQUENCE\n+\t\t      && INSN_ANNULLED_BRANCH_P (this_jump_insn))\n+\t\t    {\n+\t\t      for (i = 1; i < XVECLEN (PATTERN (insn), 0); i++)\n+\t\t\tINSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i))\n+\t\t\t  = ! INSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i));\n+\n+\t\t      target_set = set;\n+\t\t      mark_set_resources (insn, &target_set, 0, 1);\n+\n+\t\t      for (i = 1; i < XVECLEN (PATTERN (insn), 0); i++)\n+\t\t\tINSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i))\n+\t\t\t  = ! INSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i));\n+\n+\t\t      mark_set_resources (insn, &set, 0, 1);\n+\t\t    }\n+\t\t  else\n+\t\t    {\n+\t\t      mark_set_resources (insn, &set, 0, 1);\n+\t\t      target_set = set;\n+\t\t    }\n+\n+\t\t  target_res = *res;\n+\t\t  COPY_HARD_REG_SET (scratch, target_set.regs);\n+\t\t  AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n+\t\t  AND_COMPL_HARD_REG_SET (target_res.regs, scratch);\n+\n+\t\t  fallthrough_res = *res;\n+\t\t  COPY_HARD_REG_SET (scratch, set.regs);\n+\t\t  AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n+\t\t  AND_COMPL_HARD_REG_SET (fallthrough_res.regs, scratch);\n+\n+\t\t  find_dead_or_set_registers (JUMP_LABEL (this_jump_insn),\n+\t\t\t\t\t      &target_res, 0, jump_count,\n+\t\t\t\t\t      target_set, needed);\n+\t\t  find_dead_or_set_registers (next,\n+\t\t\t\t\t      &fallthrough_res, 0, jump_count,\n+\t\t\t\t\t      set, needed);\n+\t\t  IOR_HARD_REG_SET (fallthrough_res.regs, target_res.regs);\n+\t\t  AND_HARD_REG_SET (res->regs, fallthrough_res.regs);\n+\t\t  break;\n+\t\t}\n+\t      else\n+\t\tbreak;\n+\t    }\n+\t  else\n+\t    {\n+\t      /* Don't try this optimization if we expired our jump count\n+\t\t above, since that would mean there may be an infinite loop\n+\t\t in the function being compiled.  */\n+\t      jump_insn = 0;\n+\t      break;\n+\t    }\n+\t}\n+\n+      mark_referenced_resources (insn, &needed, 1);\n+      mark_set_resources (insn, &set, 0, 1);\n+\n+      COPY_HARD_REG_SET (scratch, set.regs);\n+      AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n+      AND_COMPL_HARD_REG_SET (res->regs, scratch);\n+    }\n+\n+  return jump_insn;\n+}\n+\f\n+/* Given X, a part of an insn, and a pointer to a `struct resource',\n+   RES, indicate which resources are modified by the insn. If\n+   INCLUDE_DELAYED_EFFECTS is nonzero, also mark resources potentially\n+   set by the called routine.\n+\n+   If IN_DEST is nonzero, it means we are inside a SET.  Otherwise,\n+   objects are being referenced instead of set.\n+\n+   We never mark the insn as modifying the condition code unless it explicitly\n+   SETs CC0 even though this is not totally correct.  The reason for this is\n+   that we require a SET of CC0 to immediately precede the reference to CC0.\n+   So if some other insn sets CC0 as a side-effect, we know it cannot affect\n+   our computation and thus may be placed in a delay slot.   */\n+\n+void\n+mark_set_resources (x, res, in_dest, include_delayed_effects)\n+     register rtx x;\n+     register struct resources *res;\n+     int in_dest;\n+     int include_delayed_effects;\n+{\n+  register enum rtx_code code;\n+  register int i, j;\n+  register char *format_ptr;\n+\n+ restart:\n+\n+  code = GET_CODE (x);\n+\n+  switch (code)\n+    {\n+    case NOTE:\n+    case BARRIER:\n+    case CODE_LABEL:\n+    case USE:\n+    case CONST_INT:\n+    case CONST_DOUBLE:\n+    case LABEL_REF:\n+    case SYMBOL_REF:\n+    case CONST:\n+    case PC:\n+      /* These don't set any resources.  */\n+      return;\n+\n+    case CC0:\n+      if (in_dest)\n+\tres->cc = 1;\n+      return;\n+\n+    case CALL_INSN:\n+      /* Called routine modifies the condition code, memory, any registers\n+\t that aren't saved across calls, global registers and anything\n+\t explicitly CLOBBERed immediately after the CALL_INSN.  */\n+\n+      if (include_delayed_effects)\n+\t{\n+\t  rtx next = NEXT_INSN (x);\n+\t  rtx prev = PREV_INSN (x);\n+\t  rtx link;\n+\n+\t  res->cc = res->memory = 1;\n+\t  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+\t    if (call_used_regs[i] || global_regs[i])\n+\t      SET_HARD_REG_BIT (res->regs, i);\n+\n+\t  /* If X is part of a delay slot sequence, then NEXT should be\n+\t     the first insn after the sequence.  */\n+\t  if (NEXT_INSN (prev) != x)\n+\t    next = NEXT_INSN (NEXT_INSN (prev));\n+\n+\t  for (link = CALL_INSN_FUNCTION_USAGE (x);\n+\t       link; link = XEXP (link, 1))\n+\t    if (GET_CODE (XEXP (link, 0)) == CLOBBER)\n+\t      mark_set_resources (SET_DEST (XEXP (link, 0)), res, 1, 0);\n+\n+\t  /* Check for a NOTE_INSN_SETJMP.  If it exists, then we must\n+\t     assume that this call can clobber any register.  */\n+\t  if (next && GET_CODE (next) == NOTE\n+\t      && NOTE_LINE_NUMBER (next) == NOTE_INSN_SETJMP)\n+\t    SET_HARD_REG_SET (res->regs);\n+\t}\n+\n+      /* ... and also what its RTL says it modifies, if anything.  */\n+\n+    case JUMP_INSN:\n+    case INSN:\n+\n+\t/* An insn consisting of just a CLOBBER (or USE) is just for flow\n+\t   and doesn't actually do anything, so we ignore it.  */\n+\n+#ifdef INSN_SETS_ARE_DELAYED\n+      if (! include_delayed_effects\n+\t  && INSN_SETS_ARE_DELAYED (x))\n+\treturn;\n+#endif\n+\n+      x = PATTERN (x);\n+      if (GET_CODE (x) != USE && GET_CODE (x) != CLOBBER)\n+\tgoto restart;\n+      return;\n+\n+    case SET:\n+      /* If the source of a SET is a CALL, this is actually done by\n+\t the called routine.  So only include it if we are to include the\n+\t effects of the calling routine.  */\n+\n+      mark_set_resources (SET_DEST (x), res,\n+\t\t\t  (include_delayed_effects\n+\t\t\t   || GET_CODE (SET_SRC (x)) != CALL),\n+\t\t\t  0);\n+\n+      mark_set_resources (SET_SRC (x), res, 0, 0);\n+      return;\n+\n+    case CLOBBER:\n+      mark_set_resources (XEXP (x, 0), res, 1, 0);\n+      return;\n+      \n+    case SEQUENCE:\n+      for (i = 0; i < XVECLEN (x, 0); i++)\n+\tif (! (INSN_ANNULLED_BRANCH_P (XVECEXP (x, 0, 0))\n+\t       && INSN_FROM_TARGET_P (XVECEXP (x, 0, i))))\n+\t  mark_set_resources (XVECEXP (x, 0, i), res, 0,\n+\t\t\t      include_delayed_effects);\n+      return;\n+\n+    case POST_INC:\n+    case PRE_INC:\n+    case POST_DEC:\n+    case PRE_DEC:\n+      mark_set_resources (XEXP (x, 0), res, 1, 0);\n+      return;\n+\n+    case ZERO_EXTRACT:\n+      mark_set_resources (XEXP (x, 0), res, in_dest, 0);\n+      mark_set_resources (XEXP (x, 1), res, 0, 0);\n+      mark_set_resources (XEXP (x, 2), res, 0, 0);\n+      return;\n+\n+    case MEM:\n+      if (in_dest)\n+\t{\n+\t  res->memory = 1;\n+\t  res->unch_memory = RTX_UNCHANGING_P (x);\n+\t  res->volatil = MEM_VOLATILE_P (x);\n+\t}\n+\n+      mark_set_resources (XEXP (x, 0), res, 0, 0);\n+      return;\n+\n+    case SUBREG:\n+      if (in_dest)\n+\t{\n+\t  if (GET_CODE (SUBREG_REG (x)) != REG)\n+\t    mark_set_resources (SUBREG_REG (x), res,\n+\t\t\t\tin_dest, include_delayed_effects);\n+\t  else\n+\t    {\n+\t      int regno = REGNO (SUBREG_REG (x)) + SUBREG_WORD (x);\n+\t      int last_regno = regno + HARD_REGNO_NREGS (regno, GET_MODE (x));\n+\t      for (i = regno; i < last_regno; i++)\n+\t\tSET_HARD_REG_BIT (res->regs, i);\n+\t    }\n+\t}\n+      return;\n+\n+    case REG:\n+      if (in_dest)\n+        for (i = 0; i < HARD_REGNO_NREGS (REGNO (x), GET_MODE (x)); i++)\n+\t  SET_HARD_REG_BIT (res->regs, REGNO (x) + i);\n+      return;\n+\n+    default:\n+      break;\n+    }\n+\n+  /* Process each sub-expression and flag what it needs.  */\n+  format_ptr = GET_RTX_FORMAT (code);\n+  for (i = 0; i < GET_RTX_LENGTH (code); i++)\n+    switch (*format_ptr++)\n+      {\n+      case 'e':\n+\tmark_set_resources (XEXP (x, i), res, in_dest, include_delayed_effects);\n+\tbreak;\n+\n+      case 'E':\n+\tfor (j = 0; j < XVECLEN (x, i); j++)\n+\t  mark_set_resources (XVECEXP (x, i, j), res, in_dest,\n+\t\t\t      include_delayed_effects);\n+\tbreak;\n+      }\n+}\n+\f\n+/* Set the resources that are live at TARGET.\n+\n+   If TARGET is zero, we refer to the end of the current function and can\n+   return our precomputed value.\n+\n+   Otherwise, we try to find out what is live by consulting the basic block\n+   information.  This is tricky, because we must consider the actions of\n+   reload and jump optimization, which occur after the basic block information\n+   has been computed.\n+\n+   Accordingly, we proceed as follows::\n+\n+   We find the previous BARRIER and look at all immediately following labels\n+   (with no intervening active insns) to see if any of them start a basic\n+   block.  If we hit the start of the function first, we use block 0.\n+\n+   Once we have found a basic block and a corresponding first insns, we can\n+   accurately compute the live status from basic_block_live_regs and\n+   reg_renumber.  (By starting at a label following a BARRIER, we are immune\n+   to actions taken by reload and jump.)  Then we scan all insns between\n+   that point and our target.  For each CLOBBER (or for call-clobbered regs\n+   when we pass a CALL_INSN), mark the appropriate registers are dead.  For\n+   a SET, mark them as live.\n+\n+   We have to be careful when using REG_DEAD notes because they are not\n+   updated by such things as find_equiv_reg.  So keep track of registers\n+   marked as dead that haven't been assigned to, and mark them dead at the\n+   next CODE_LABEL since reload and jump won't propagate values across labels.\n+\n+   If we cannot find the start of a basic block (should be a very rare\n+   case, if it can happen at all), mark everything as potentially live.\n+\n+   Next, scan forward from TARGET looking for things set or clobbered\n+   before they are used.  These are not live.\n+\n+   Because we can be called many times on the same target, save our results\n+   in a hash table indexed by INSN_UID.  This is only done if the function\n+   init_resource_info () was invoked before we are called.  */\n+\n+void\n+mark_target_live_regs (insns, target, res)\n+     rtx insns;\n+     rtx target;\n+     struct resources *res;\n+{\n+  int b = -1;\n+  int i;\n+  struct target_info *tinfo = NULL;\n+  rtx insn;\n+  rtx jump_insn = 0;\n+  rtx jump_target;\n+  HARD_REG_SET scratch;\n+  struct resources set, needed;\n+\n+  /* Handle end of function.  */\n+  if (target == 0)\n+    {\n+      *res = end_of_function_needs;\n+      return;\n+    }\n+\n+  /* We have to assume memory is needed, but the CC isn't.  */\n+  res->memory = 1;\n+  res->volatil = res->unch_memory = 0;\n+  res->cc = 0;\n+\n+  /* See if we have computed this value already.  */\n+  if (target_hash_table != NULL)\n+    {\n+      for (tinfo = target_hash_table[INSN_UID (target) % TARGET_HASH_PRIME];\n+\t   tinfo; tinfo = tinfo->next)\n+\tif (tinfo->uid == INSN_UID (target))\n+\t  break;\n+\n+      /* Start by getting the basic block number.  If we have saved\n+\t information, we can get it from there unless the insn at the\n+\t start of the basic block has been deleted.  */\n+      if (tinfo && tinfo->block != -1\n+\t  && ! INSN_DELETED_P (BLOCK_HEAD (tinfo->block)))\n+\tb = tinfo->block;\n+    }\n+\n+  if (b == -1)\n+    b = find_basic_block (target);\n+\n+  if (target_hash_table != NULL)\n+    {\n+      if (tinfo)\n+\t{\n+\t  /* If the information is up-to-date, use it.  Otherwise, we will\n+\t     update it below.  */\n+\t  if (b == tinfo->block && b != -1 && tinfo->bb_tick == bb_ticks[b])\n+\t    {\n+\t      COPY_HARD_REG_SET (res->regs, tinfo->live_regs);\n+\t      return;\n+\t    }\n+\t}\n+      else\n+\t{\n+\t  /* Allocate a place to put our results and chain it into the \n+\t     hash table.  */\n+\t  tinfo = (struct target_info *) oballoc (sizeof (struct target_info));\n+\t  tinfo->uid = INSN_UID (target);\n+\t  tinfo->block = b;\n+\t  tinfo->next = target_hash_table[INSN_UID (target) % TARGET_HASH_PRIME];\n+\t  target_hash_table[INSN_UID (target) % TARGET_HASH_PRIME] = tinfo;\n+\t}\n+    }\n+\n+  CLEAR_HARD_REG_SET (pending_dead_regs);\n+\n+  /* If we found a basic block, get the live registers from it and update\n+     them with anything set or killed between its start and the insn before\n+     TARGET.  Otherwise, we must assume everything is live.  */\n+  if (b != -1)\n+    {\n+      regset regs_live = basic_block_live_at_start[b];\n+      int j;\n+      int regno;\n+      rtx start_insn, stop_insn;\n+\n+      /* Compute hard regs live at start of block -- this is the real hard regs\n+\t marked live, plus live pseudo regs that have been renumbered to\n+\t hard regs.  */\n+\n+      REG_SET_TO_HARD_REG_SET (current_live_regs, regs_live);\n+\n+      EXECUTE_IF_SET_IN_REG_SET\n+\t(regs_live, FIRST_PSEUDO_REGISTER, i,\n+\t {\n+\t   if ((regno = reg_renumber[i]) >= 0)\n+\t     for (j = regno;\n+\t\t  j < regno + HARD_REGNO_NREGS (regno,\n+\t\t\t\t\t\tPSEUDO_REGNO_MODE (i));\n+\t\t  j++)\n+\t       SET_HARD_REG_BIT (current_live_regs, j);\n+\t });\n+\n+      /* Get starting and ending insn, handling the case where each might\n+\t be a SEQUENCE.  */\n+      start_insn = (b == 0 ? insns : BLOCK_HEAD (b));\n+      stop_insn = target;\n+\n+      if (GET_CODE (start_insn) == INSN\n+\t  && GET_CODE (PATTERN (start_insn)) == SEQUENCE)\n+\tstart_insn = XVECEXP (PATTERN (start_insn), 0, 0);\n+\n+      if (GET_CODE (stop_insn) == INSN\n+\t  && GET_CODE (PATTERN (stop_insn)) == SEQUENCE)\n+\tstop_insn = next_insn (PREV_INSN (stop_insn));\n+\n+      for (insn = start_insn; insn != stop_insn;\n+\t   insn = next_insn_no_annul (insn))\n+\t{\n+\t  rtx link;\n+\t  rtx real_insn = insn;\n+\n+\t  /* If this insn is from the target of a branch, it isn't going to\n+\t     be used in the sequel.  If it is used in both cases, this\n+\t     test will not be true.  */\n+\t  if (INSN_FROM_TARGET_P (insn))\n+\t    continue;\n+\n+\t  /* If this insn is a USE made by update_block, we care about the\n+\t     underlying insn.  */\n+\t  if (GET_CODE (insn) == INSN && GET_CODE (PATTERN (insn)) == USE\n+\t      && GET_RTX_CLASS (GET_CODE (XEXP (PATTERN (insn), 0))) == 'i')\n+\t      real_insn = XEXP (PATTERN (insn), 0);\n+\n+\t  if (GET_CODE (real_insn) == CALL_INSN)\n+\t    {\n+\t      /* CALL clobbers all call-used regs that aren't fixed except\n+\t\t sp, ap, and fp.  Do this before setting the result of the\n+\t\t call live.  */\n+\t      for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+\t\tif (call_used_regs[i]\n+\t\t    && i != STACK_POINTER_REGNUM && i != FRAME_POINTER_REGNUM\n+\t\t    && i != ARG_POINTER_REGNUM\n+#if HARD_FRAME_POINTER_REGNUM != FRAME_POINTER_REGNUM\n+\t\t    && i != HARD_FRAME_POINTER_REGNUM\n+#endif\n+#if ARG_POINTER_REGNUM != FRAME_POINTER_REGNUM\n+\t\t    && ! (i == ARG_POINTER_REGNUM && fixed_regs[i])\n+#endif\n+#ifdef PIC_OFFSET_TABLE_REGNUM\n+\t\t    && ! (i == PIC_OFFSET_TABLE_REGNUM && flag_pic)\n+#endif\n+\t\t    )\n+\t\t  CLEAR_HARD_REG_BIT (current_live_regs, i);\n+\n+\t      /* A CALL_INSN sets any global register live, since it may\n+\t\t have been modified by the call.  */\n+\t      for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+\t\tif (global_regs[i])\n+\t\t  SET_HARD_REG_BIT (current_live_regs, i);\n+\t    }\n+\n+\t  /* Mark anything killed in an insn to be deadened at the next\n+\t     label.  Ignore USE insns; the only REG_DEAD notes will be for\n+\t     parameters.  But they might be early.  A CALL_INSN will usually\n+\t     clobber registers used for parameters.  It isn't worth bothering\n+\t     with the unlikely case when it won't.  */\n+\t  if ((GET_CODE (real_insn) == INSN\n+\t       && GET_CODE (PATTERN (real_insn)) != USE\n+\t       && GET_CODE (PATTERN (real_insn)) != CLOBBER)\n+\t      || GET_CODE (real_insn) == JUMP_INSN\n+\t      || GET_CODE (real_insn) == CALL_INSN)\n+\t    {\n+\t      for (link = REG_NOTES (real_insn); link; link = XEXP (link, 1))\n+\t\tif (REG_NOTE_KIND (link) == REG_DEAD\n+\t\t    && GET_CODE (XEXP (link, 0)) == REG\n+\t\t    && REGNO (XEXP (link, 0)) < FIRST_PSEUDO_REGISTER)\n+\t\t  {\n+\t\t    int first_regno = REGNO (XEXP (link, 0));\n+\t\t    int last_regno\n+\t\t      = (first_regno\n+\t\t\t + HARD_REGNO_NREGS (first_regno,\n+\t\t\t\t\t     GET_MODE (XEXP (link, 0))));\n+\t\t\t \n+\t\t    for (i = first_regno; i < last_regno; i++)\n+\t\t      SET_HARD_REG_BIT (pending_dead_regs, i);\n+\t\t  }\n+\n+\t      note_stores (PATTERN (real_insn), update_live_status);\n+\n+\t      /* If any registers were unused after this insn, kill them.\n+\t\t These notes will always be accurate.  */\n+\t      for (link = REG_NOTES (real_insn); link; link = XEXP (link, 1))\n+\t\tif (REG_NOTE_KIND (link) == REG_UNUSED\n+\t\t    && GET_CODE (XEXP (link, 0)) == REG\n+\t\t    && REGNO (XEXP (link, 0)) < FIRST_PSEUDO_REGISTER)\n+\t\t  {\n+\t\t    int first_regno = REGNO (XEXP (link, 0));\n+\t\t    int last_regno\n+\t\t      = (first_regno\n+\t\t\t + HARD_REGNO_NREGS (first_regno,\n+\t\t\t\t\t     GET_MODE (XEXP (link, 0))));\n+\t\t\t \n+\t\t    for (i = first_regno; i < last_regno; i++)\n+\t\t      CLEAR_HARD_REG_BIT (current_live_regs, i);\n+\t\t  }\n+\t    }\n+\n+\t  else if (GET_CODE (real_insn) == CODE_LABEL)\n+\t    {\n+\t      /* A label clobbers the pending dead registers since neither\n+\t\t reload nor jump will propagate a value across a label.  */\n+\t      AND_COMPL_HARD_REG_SET (current_live_regs, pending_dead_regs);\n+\t      CLEAR_HARD_REG_SET (pending_dead_regs);\n+\t    }\n+\n+\t  /* The beginning of the epilogue corresponds to the end of the\n+\t     RTL chain when there are no epilogue insns.  Certain resources\n+\t     are implicitly required at that point.  */\n+\t  else if (GET_CODE (real_insn) == NOTE\n+ \t\t   && NOTE_LINE_NUMBER (real_insn) == NOTE_INSN_EPILOGUE_BEG)\n+\t    IOR_HARD_REG_SET (current_live_regs, start_of_epilogue_needs.regs);\n+\t}\n+\n+      COPY_HARD_REG_SET (res->regs, current_live_regs);\n+      if (tinfo != NULL)\n+\t{\n+\t  tinfo->block = b;\n+\t  tinfo->bb_tick = bb_ticks[b];\n+\t}\n+    }\n+  else\n+    /* We didn't find the start of a basic block.  Assume everything\n+       in use.  This should happen only extremely rarely.  */\n+    SET_HARD_REG_SET (res->regs);\n+\n+  CLEAR_RESOURCE (&set);\n+  CLEAR_RESOURCE (&needed);\n+\n+  jump_insn = find_dead_or_set_registers (target, res, &jump_target, 0,\n+\t\t\t\t\t  set, needed);\n+\n+  /* If we hit an unconditional branch, we have another way of finding out\n+     what is live: we can see what is live at the branch target and include\n+     anything used but not set before the branch.  The only things that are\n+     live are those that are live using the above test and the test below.  */\n+\n+  if (jump_insn)\n+    {\n+      struct resources new_resources;\n+      rtx stop_insn = next_active_insn (jump_insn);\n+\n+      mark_target_live_regs (insns, next_active_insn (jump_target),\n+\t\t\t     &new_resources);\n+      CLEAR_RESOURCE (&set);\n+      CLEAR_RESOURCE (&needed);\n+\n+      /* Include JUMP_INSN in the needed registers.  */\n+      for (insn = target; insn != stop_insn; insn = next_active_insn (insn))\n+\t{\n+\t  mark_referenced_resources (insn, &needed, 1);\n+\n+\t  COPY_HARD_REG_SET (scratch, needed.regs);\n+\t  AND_COMPL_HARD_REG_SET (scratch, set.regs);\n+\t  IOR_HARD_REG_SET (new_resources.regs, scratch);\n+\n+\t  mark_set_resources (insn, &set, 0, 1);\n+\t}\n+\n+      AND_HARD_REG_SET (res->regs, new_resources.regs);\n+    }\n+\n+  if (tinfo != NULL)\n+    {\n+      COPY_HARD_REG_SET (tinfo->live_regs, res->regs);\n+    }\n+}\n+\f\n+/* Initialize the resources required by mark_target_live_regs ().\n+   This should be invoked before the first call to mark_target_live_regs.  */\n+\n+void\n+init_resource_info (epilogue_insn)\n+     rtx epilogue_insn;\n+{\n+  int i;\n+\n+  /* Indicate what resources are required to be valid at the end of the current\n+     function.  The condition code never is and memory always is.  If the\n+     frame pointer is needed, it is and so is the stack pointer unless\n+     EXIT_IGNORE_STACK is non-zero.  If the frame pointer is not needed, the\n+     stack pointer is.  Registers used to return the function value are\n+     needed.  Registers holding global variables are needed.  */\n+\n+  end_of_function_needs.cc = 0;\n+  end_of_function_needs.memory = 1;\n+  end_of_function_needs.unch_memory = 0;\n+  CLEAR_HARD_REG_SET (end_of_function_needs.regs);\n+\n+  if (frame_pointer_needed)\n+    {\n+      SET_HARD_REG_BIT (end_of_function_needs.regs, FRAME_POINTER_REGNUM);\n+#if HARD_FRAME_POINTER_REGNUM != FRAME_POINTER_REGNUM\n+      SET_HARD_REG_BIT (end_of_function_needs.regs, HARD_FRAME_POINTER_REGNUM);\n+#endif\n+#ifdef EXIT_IGNORE_STACK\n+      if (! EXIT_IGNORE_STACK\n+\t  || current_function_sp_is_unchanging)\n+#endif\n+\tSET_HARD_REG_BIT (end_of_function_needs.regs, STACK_POINTER_REGNUM);\n+    }\n+  else\n+    SET_HARD_REG_BIT (end_of_function_needs.regs, STACK_POINTER_REGNUM);\n+\n+  if (current_function_return_rtx != 0)\n+    mark_referenced_resources (current_function_return_rtx,\n+\t\t\t       &end_of_function_needs, 1);\n+\n+  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+    if (global_regs[i]\n+#ifdef EPILOGUE_USES\n+\t|| EPILOGUE_USES (i)\n+#endif\n+\t)\n+      SET_HARD_REG_BIT (end_of_function_needs.regs, i);\n+\n+  /* The registers required to be live at the end of the function are\n+     represented in the flow information as being dead just prior to\n+     reaching the end of the function.  For example, the return of a value\n+     might be represented by a USE of the return register immediately\n+     followed by an unconditional jump to the return label where the\n+     return label is the end of the RTL chain.  The end of the RTL chain\n+     is then taken to mean that the return register is live.\n+\n+     This sequence is no longer maintained when epilogue instructions are\n+     added to the RTL chain.  To reconstruct the original meaning, the\n+     start of the epilogue (NOTE_INSN_EPILOGUE_BEG) is regarded as the\n+     point where these registers become live (start_of_epilogue_needs).\n+     If epilogue instructions are present, the registers set by those\n+     instructions won't have been processed by flow.  Thus, those\n+     registers are additionally required at the end of the RTL chain\n+     (end_of_function_needs).  */\n+\n+  start_of_epilogue_needs = end_of_function_needs;\n+\n+  while ((epilogue_insn = next_nonnote_insn (epilogue_insn)))\n+    mark_set_resources (epilogue_insn, &end_of_function_needs, 0, 1);\n+\n+  /* Allocate and initialize the tables used by mark_target_live_regs.  */\n+  target_hash_table\n+    = (struct target_info **) xmalloc ((TARGET_HASH_PRIME\n+\t\t\t\t       * sizeof (struct target_info *)));\n+  bzero ((char *) target_hash_table,\n+\t TARGET_HASH_PRIME * sizeof (struct target_info *));\n+\n+  bb_ticks = (int *) xmalloc (n_basic_blocks * sizeof (int));\n+  bzero ((char *) bb_ticks, n_basic_blocks * sizeof (int));\n+}\n+\f\n+/* Free up the resources allcated to mark_target_live_regs ().  This\n+   should be invoked after the last call to mark_target_live_regs ().  */\n+\n+void\n+free_resource_info ()\n+{\n+  if (target_hash_table != NULL)\n+    {\n+      free (target_hash_table);\n+      target_hash_table = NULL;\n+    }\n+\n+  if (bb_ticks != NULL)\n+    {\n+      free (bb_ticks);\n+      bb_ticks = NULL;\n+    }\n+}\n+\f\n+/* Clear any hashed information that we have stored for INSN.  */\n+\n+void\n+clear_hashed_info_for_insn (insn)\n+     rtx insn;\n+{\n+  struct target_info *tinfo;\n+      \n+  if (target_hash_table != NULL)\n+    {\n+      for (tinfo = target_hash_table[INSN_UID (insn) % TARGET_HASH_PRIME];\n+\t   tinfo; tinfo = tinfo->next)\n+\tif (tinfo->uid == INSN_UID (insn))\n+\t  break;\n+\n+      if (tinfo)\n+\ttinfo->block = -1;\n+    }\n+}\n+\f\n+/* Increment the tick count for the basic block that contains INSN.  */\n+\n+void\n+incr_ticks_for_insn (insn)\n+     rtx insn;\n+{\n+  int b = find_basic_block (insn);\n+\n+  if (b != -1)\n+    bb_ticks[b]++;\n+}\n+\f\n+/* Add TRIAL to the set of resources used at the end of the current\n+   function. */\n+void\n+mark_end_of_function_resources (trial, include_delayed_effects)\n+     rtx trial;\n+     int include_delayed_effects;\n+{\n+  mark_referenced_resources (trial, &end_of_function_needs,\n+\t\t\t     include_delayed_effects);\n+}\n+\f\n+/* Try to find an available hard register of mode MODE at\n+   CURRENT_INSN, matching the register class in CLASS_STR. Registers\n+   that already have bits set in REG_SET will not be considered.\n+\n+   If an appropriate register is available, it will be returned and the\n+   corresponding bit(s) in REG_SET will be set; otherwise, NULL_RTX is\n+   returned.  */\n+\n+rtx\n+find_free_register (current_insn, class_str, mode, reg_set)\n+     rtx current_insn;\n+     char *class_str;\n+     int mode;\n+     HARD_REG_SET *reg_set;\n+{\n+  int i, j;\n+  struct resources used;\n+  unsigned char clet = class_str[0];\n+  enum reg_class class\n+    = (clet == 'r' ? GENERAL_REGS :  REG_CLASS_FROM_LETTER (clet));\n+\n+  mark_target_live_regs (get_insns (), current_insn, &used);\n+\n+  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+    {\n+      int success = 1;\n+\n+      if (! TEST_HARD_REG_BIT (reg_class_contents[class], i))\n+\tcontinue;\n+      for (j = HARD_REGNO_NREGS (i, mode) - 1; j >= 0; j--)\n+\t{\n+\t  if (TEST_HARD_REG_BIT (*reg_set, i + j)\n+\t      || TEST_HARD_REG_BIT (used.regs, i + j))\n+\t    {\n+\t      success = 0;\n+\t      break;\n+\t    }\n+\t}\n+      if (success)\n+\t{\n+\t  for (j = HARD_REGNO_NREGS (i, mode) - 1; j >= 0; j--)\n+\t    {\n+\t      SET_HARD_REG_BIT (*reg_set, i + j);\n+\t    }\n+\t  return gen_rtx_REG (mode, i);\n+\t}\n+    }\n+  return NULL_RTX;\n+}"}, {"sha": "d3a8e2c7088716cbde2e8b159280c9bf3dc7e58e", "filename": "gcc/resource.h", "status": "added", "additions": 46, "deletions": 0, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Fresource.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Fresource.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fresource.h?ref=ca545bb569b7560793928e1c597bb1df499f8855", "patch": "@@ -0,0 +1,46 @@\n+/* Definitions for computing resource usage of specific insns.\n+   Copyright (C) 1999 Free Software Foundation, Inc.\n+\n+This file is part of GNU CC.\n+\n+GNU CC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GNU CC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 59 Temple Place - Suite 330,\n+Boston, MA 02111-1307, USA.  */\n+\n+/* Macro to clear all resources.  */\n+#define CLEAR_RESOURCE(RES)\t\\\n+ do { (RES)->memory = (RES)->unch_memory = (RES)->volatil = (RES)->cc = 0; \\\n+      CLEAR_HARD_REG_SET ((RES)->regs); } while (0)\n+\n+/* The resources used by a given insn. */\n+struct resources\n+{\n+  char memory;\t\t/* Insn sets or needs a memory location.  */\n+  char unch_memory;\t/* Insn sets of needs a \"unchanging\" MEM.  */\n+  char volatil;\t\t/* Insn sets or needs a volatile memory loc.  */\n+  char cc;\t\t/* Insn sets or needs the condition codes.  */\n+  HARD_REG_SET regs;\t/* Which registers are set or needed.  */\n+};\n+\n+extern void mark_target_live_regs \tPROTO((rtx, rtx, struct resources *));\n+extern void mark_set_resources\t\tPROTO((rtx, struct resources *, int,\n+\t\t\t\t\t       int));\n+extern void mark_referenced_resources\tPROTO((rtx, struct resources *, int));\n+extern void clear_hashed_info_for_insn\tPROTO((rtx));\n+extern void incr_ticks_for_insn\t\tPROTO((rtx));\n+extern void mark_end_of_function_resources PROTO ((rtx, int));\n+extern void init_resource_info\t\tPROTO((rtx));\n+extern void free_resource_info\t\tPROTO((void));\n+extern rtx find_free_register\t\tPROTO((rtx, char *, int,\n+\t\t\t\t\t       HARD_REG_SET *));"}, {"sha": "a8bcaf7437c57afed9ea514db9cc05d7778e25e3", "filename": "gcc/sched.c", "status": "modified", "additions": 2, "deletions": 108, "changes": 110, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Fsched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ca545bb569b7560793928e1c597bb1df499f8855/gcc%2Fsched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched.c?ref=ca545bb569b7560793928e1c597bb1df499f8855", "patch": "@@ -342,11 +342,9 @@ static int new_sometimes_live\t\tPROTO((struct sometimes *, int, int));\n static void finish_sometimes_live\tPROTO((struct sometimes *, int));\n static rtx reemit_notes\t\t\tPROTO((rtx, rtx));\n static void schedule_block\t\tPROTO((int, FILE *));\n-static rtx regno_use_in\t\t\tPROTO((int, rtx));\n static void split_hard_reg_notes\tPROTO((rtx, rtx, rtx));\n static void new_insn_dead_notes\t\tPROTO((rtx, rtx, rtx, rtx));\n static void update_n_sets\t\tPROTO((rtx, int));\n-static void update_flow_info\t\tPROTO((rtx, rtx, rtx, rtx));\n \n /* Main entry point of this file.  */\n void schedule_insns\tPROTO((FILE *));\n@@ -3533,39 +3531,6 @@ schedule_block (b, file)\n   return;\n }\n \f\n-/* Subroutine of split_hard_reg_notes.  Searches X for any reference to\n-   REGNO, returning the rtx of the reference found if any.  Otherwise,\n-   returns 0.  */\n-\n-static rtx\n-regno_use_in (regno, x)\n-     int regno;\n-     rtx x;\n-{\n-  register char *fmt;\n-  int i, j;\n-  rtx tem;\n-\n-  if (GET_CODE (x) == REG && REGNO (x) == regno)\n-    return x;\n-\n-  fmt = GET_RTX_FORMAT (GET_CODE (x));\n-  for (i = GET_RTX_LENGTH (GET_CODE (x)) - 1; i >= 0; i--)\n-    {\n-      if (fmt[i] == 'e')\n-\t{\n-\t  if ((tem = regno_use_in (regno, XEXP (x, i))))\n-\t    return tem;\n-\t}\n-      else if (fmt[i] == 'E')\n-\tfor (j = XVECLEN (x, i) - 1; j >= 0; j--)\n-\t  if ((tem = regno_use_in (regno , XVECEXP (x, i, j))))\n-\t    return tem;\n-    }\n-\n-  return 0;\n-}\n-\n /* Subroutine of update_flow_info.  Determines whether any new REG_NOTEs are\n    needed for the hard register mentioned in the note.  This can happen\n    if the reference to the hard register in the original insn was split into\n@@ -3760,7 +3725,7 @@ update_n_sets (x, inc)\n    the insns from FIRST to LAST inclusive that were created by splitting\n    ORIG_INSN.  NOTES are the original REG_NOTES.  */\n \n-static void\n+void\n update_flow_info (notes, first, last, orig_insn)\n      rtx notes;\n      rtx first, last;\n@@ -4366,78 +4331,7 @@ schedule_insns (dump_file)\n \n       note_list = 0;\n \n-      for (insn = BLOCK_HEAD (b); ; insn = next)\n-\t{\n-\t  rtx prev;\n-\t  rtx set;\n-\n-\t  /* Can't use `next_real_insn' because that\n-\t     might go across CODE_LABELS and short-out basic blocks.  */\n-\t  next = NEXT_INSN (insn);\n-\t  if (GET_CODE (insn) != INSN)\n-\t    {\n-\t      if (insn == BLOCK_END (b))\n-\t\tbreak;\n-\n-\t      continue;\n-\t    }\n-\n-\t  /* Don't split no-op move insns.  These should silently disappear\n-\t     later in final.  Splitting such insns would break the code\n-\t     that handles REG_NO_CONFLICT blocks.  */\n-\t  set = single_set (insn);\n-\t  if (set && rtx_equal_p (SET_SRC (set), SET_DEST (set)))\n-\t    {\n-\t      if (insn == BLOCK_END (b))\n-\t\tbreak;\n-\n-\t      /* Nops get in the way while scheduling, so delete them now if\n-\t\t register allocation has already been done.  It is too risky\n-\t\t to try to do this before register allocation, and there are\n-\t\t unlikely to be very many nops then anyways.  */\n-\t      if (reload_completed)\n-\t\t{\n-\t\t  PUT_CODE (insn, NOTE);\n-\t\t  NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;\n-\t\t  NOTE_SOURCE_FILE (insn) = 0;\n-\t\t}\n-\n-\t      continue;\n-\t    }\n-\n-\t  /* Split insns here to get max fine-grain parallelism.  */\n-\t  prev = PREV_INSN (insn);\n-\t  /* It is probably not worthwhile to try to split again in the\n-\t     second pass.  However, if flag_schedule_insns is not set,\n-\t     the first and only (if any) scheduling pass is after reload.  */\n-\t  if (reload_completed == 0 || ! flag_schedule_insns)\n-\t    {\n-\t      rtx last, first = PREV_INSN (insn);\n-\t      rtx notes = REG_NOTES (insn);\n-\n-\t      last = try_split (PATTERN (insn), insn, 1);\n-\t      if (last != insn)\n-\t\t{\n-\t\t  /* try_split returns the NOTE that INSN became.  */\n-\t\t  first = NEXT_INSN (first);\n-\t\t  update_flow_info (notes, first, last, insn);\n-\n-\t\t  PUT_CODE (insn, NOTE);\n-\t\t  NOTE_SOURCE_FILE (insn) = 0;\n-\t\t  NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;\n-\t\t  if (insn == BLOCK_HEAD (b))\n-\t\t    BLOCK_HEAD (b) = first;\n-\t\t  if (insn == BLOCK_END (b))\n-\t\t    {\n-\t\t      BLOCK_END (b) = last;\n-\t\t      break;\n-\t\t    }\n-\t\t}\n-\t    }\n-\n-\t  if (insn == BLOCK_END (b))\n-\t    break;\n-\t}\n+      split_block_insns (b, reload_completed == 0 || ! flag_schedule_insns);\n \n       schedule_block (b, dump_file);\n "}]}