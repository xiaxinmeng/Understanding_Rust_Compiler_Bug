{"sha": "1d3d27032b489c5237434fbc2623e87db9b08985", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWQzZDI3MDMyYjQ4OWM1MjM3NDM0ZmJjMjYyM2U4N2RiOWIwODk4NQ==", "commit": {"author": {"name": "Bill Schmidt", "email": "wschmidt@linux.ibm.com", "date": "2018-10-25T20:14:40Z"}, "committer": {"name": "William Schmidt", "email": "wschmidt@gcc.gnu.org", "date": "2018-10-25T20:14:40Z"}, "message": "emmintrin.h (_mm_sll_epi16): Replace comparison operators with vec_cmp* for compatibility due to unfortunate...\n\n2018-10-25  Bill Schmidt  <wschmidt@linux.ibm.com>\n\t    Jinsong Ji <jji@us.ibm.com>\n\n\t* gcc/config/rs6000/emmintrin.h (_mm_sll_epi16): Replace\n\tcomparison operators with vec_cmp* for compatibility due to\n\tunfortunate history; clean up formatting and use types more\n\tappropriately.\n\t(_mm_sll_epi32): Likewise.\n\t(_mm_sll_epi64): Likewise.\n\t(_mm_srl_epi16): Likewise.\n\t(_mm_srl_epi32): Likewise.\n\t(_mm_srl_epi64): Likewise.\n\n\nCo-Authored-By: Jinsong Ji <jji@us.ibm.com>\n\nFrom-SVN: r265507", "tree": {"sha": "6a9c6affdddbe8a32be43e2bcb3b86f8e6a4d8d8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6a9c6affdddbe8a32be43e2bcb3b86f8e6a4d8d8"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1d3d27032b489c5237434fbc2623e87db9b08985", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1d3d27032b489c5237434fbc2623e87db9b08985", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1d3d27032b489c5237434fbc2623e87db9b08985", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1d3d27032b489c5237434fbc2623e87db9b08985/comments", "author": null, "committer": null, "parents": [{"sha": "71c3949eeae32f0c242fa00c48be998b13cfdd7a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/71c3949eeae32f0c242fa00c48be998b13cfdd7a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/71c3949eeae32f0c242fa00c48be998b13cfdd7a"}], "stats": {"total": 75, "additions": 47, "deletions": 28}, "files": [{"sha": "35139d3606a5bcb9f0b2e46b5ad94dd208cf7987", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1d3d27032b489c5237434fbc2623e87db9b08985/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1d3d27032b489c5237434fbc2623e87db9b08985/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=1d3d27032b489c5237434fbc2623e87db9b08985", "patch": "@@ -1,3 +1,16 @@\n+2018-10-25  Bill Schmidt  <wschmidt@linux.ibm.com>\n+\t    Jinsong Ji <jji@us.ibm.com>\n+\n+\t* gcc/config/rs6000/emmintrin.h (_mm_sll_epi16): Replace\n+\tcomparison operators with vec_cmp* for compatibility due to\n+\tunfortunate history; clean up formatting and use types more\n+\tappropriately.\n+\t(_mm_sll_epi32): Likewise.\n+\t(_mm_sll_epi64): Likewise.\n+\t(_mm_srl_epi16): Likewise.\n+\t(_mm_srl_epi32): Likewise.\n+\t(_mm_srl_epi64): Likewise.\n+\n 2018-10-25  Bill Schmidt  <wschmidt@linux.ibm.com>\n \t    Jinsong Ji <jji@us.ibm.com>\n "}, {"sha": "a4264d143f3be7e342155bcdc8095e9b0d49a7f5", "filename": "gcc/config/rs6000/emmintrin.h", "status": "modified", "additions": 34, "deletions": 28, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1d3d27032b489c5237434fbc2623e87db9b08985/gcc%2Fconfig%2Frs6000%2Femmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1d3d27032b489c5237434fbc2623e87db9b08985/gcc%2Fconfig%2Frs6000%2Femmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Femmintrin.h?ref=1d3d27032b489c5237434fbc2623e87db9b08985", "patch": "@@ -1725,36 +1725,38 @@ _mm_srli_epi64 (__m128i __A, int __B)\n extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_sll_epi16 (__m128i __A, __m128i __B)\n {\n-  __v8hu lshift, shmask;\n+  __v8hu lshift;\n+  __vector __bool short shmask;\n   const __v8hu shmax = { 15, 15, 15, 15, 15, 15, 15, 15 };\n   __v8hu result;\n \n #ifdef __LITTLE_ENDIAN__\n-  lshift = vec_splat ((__v8hu)__B, 0);\n+  lshift = vec_splat ((__v8hu) __B, 0);\n #elif __BIG_ENDIAN__\n-  lshift = vec_splat ((__v8hu)__B, 3);\n+  lshift = vec_splat ((__v8hu) __B, 3);\n #endif\n-  shmask = lshift <= shmax;\n+  shmask = vec_cmple (lshift, shmax);\n   result = vec_vslh ((__v8hu) __A, lshift);\n-  result = vec_sel (shmask, result, shmask);\n+  result = vec_sel ((__v8hu) shmask, result, shmask);\n \n   return (__m128i) result;\n }\n \n extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_sll_epi32 (__m128i __A, __m128i __B)\n {\n-  __v4su lshift, shmask;\n+  __v4su lshift;\n+  __vector __bool int shmask;\n   const __v4su shmax = { 32, 32, 32, 32 };\n   __v4su result;\n #ifdef __LITTLE_ENDIAN__\n-  lshift = vec_splat ((__v4su)__B, 0);\n+  lshift = vec_splat ((__v4su) __B, 0);\n #elif __BIG_ENDIAN__\n-  lshift = vec_splat ((__v4su)__B, 1);\n+  lshift = vec_splat ((__v4su) __B, 1);\n #endif\n-  shmask = lshift < shmax;\n+  shmask = vec_cmplt (lshift, shmax);\n   result = vec_vslw ((__v4su) __A, lshift);\n-  result = vec_sel (shmask, result, shmask);\n+  result = vec_sel ((__v4su) shmask, result, shmask);\n \n   return (__m128i) result;\n }\n@@ -1763,14 +1765,15 @@ _mm_sll_epi32 (__m128i __A, __m128i __B)\n extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_sll_epi64 (__m128i __A, __m128i __B)\n {\n-  __v2du lshift, shmask;\n+  __v2du lshift;\n+  __vector __bool long long shmask;\n   const __v2du shmax = { 64, 64 };\n   __v2du result;\n \n-  lshift = (__v2du) vec_splat ((__v2du)__B, 0);\n-  shmask = lshift < shmax;\n+  lshift = vec_splat ((__v2du) __B, 0);\n+  shmask = vec_cmplt (lshift, shmax);\n   result = vec_vsld ((__v2du) __A, lshift);\n-  result = (__v2du) vec_sel ((__v2df) shmask, (__v2df) result, shmask);\n+  result = vec_sel ((__v2du) shmask, result, shmask);\n \n   return (__m128i) result;\n }\n@@ -1815,37 +1818,39 @@ _mm_sra_epi32 (__m128i __A, __m128i __B)\n extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_srl_epi16 (__m128i __A, __m128i __B)\n {\n-  __v8hu rshift, shmask;\n+  __v8hu rshift;\n+  __vector __bool short shmask;\n   const __v8hu shmax = { 15, 15, 15, 15, 15, 15, 15, 15 };\n   __v8hu result;\n \n #ifdef __LITTLE_ENDIAN__\n-  rshift = vec_splat ((__v8hu)__B, 0);\n+  rshift = vec_splat ((__v8hu) __B, 0);\n #elif __BIG_ENDIAN__\n-  rshift = vec_splat ((__v8hu)__B, 3);\n+  rshift = vec_splat ((__v8hu) __B, 3);\n #endif\n-  shmask = rshift <= shmax;\n+  shmask = vec_cmple (rshift, shmax);\n   result = vec_vsrh ((__v8hu) __A, rshift);\n-  result = vec_sel (shmask, result, shmask);\n+  result = vec_sel ((__v8hu) shmask, result, shmask);\n \n   return (__m128i) result;\n }\n \n extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_srl_epi32 (__m128i __A, __m128i __B)\n {\n-  __v4su rshift, shmask;\n+  __v4su rshift;\n+  __vector __bool int shmask;\n   const __v4su shmax = { 32, 32, 32, 32 };\n   __v4su result;\n \n #ifdef __LITTLE_ENDIAN__\n-  rshift = vec_splat ((__v4su)__B, 0);\n+  rshift = vec_splat ((__v4su) __B, 0);\n #elif __BIG_ENDIAN__\n-  rshift = vec_splat ((__v4su)__B, 1);\n+  rshift = vec_splat ((__v4su) __B, 1);\n #endif\n-  shmask = rshift < shmax;\n+  shmask = vec_cmplt (rshift, shmax);\n   result = vec_vsrw ((__v4su) __A, rshift);\n-  result = vec_sel (shmask, result, shmask);\n+  result = vec_sel ((__v4su) shmask, result, shmask);\n \n   return (__m128i) result;\n }\n@@ -1854,14 +1859,15 @@ _mm_srl_epi32 (__m128i __A, __m128i __B)\n extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))\n _mm_srl_epi64 (__m128i __A, __m128i __B)\n {\n-  __v2du rshift, shmask;\n+  __v2du rshift;\n+  __vector __bool long long shmask;\n   const __v2du shmax = { 64, 64 };\n   __v2du result;\n \n-  rshift = (__v2du) vec_splat ((__v2du)__B, 0);\n-  shmask = rshift < shmax;\n+  rshift = vec_splat ((__v2du) __B, 0);\n+  shmask = vec_cmplt (rshift, shmax);\n   result = vec_vsrd ((__v2du) __A, rshift);\n-  result = (__v2du)vec_sel ((__v2du)shmask, (__v2du)result, (__v2du)shmask);\n+  result = vec_sel ((__v2du) shmask, result, shmask);\n \n   return (__m128i) result;\n }"}]}