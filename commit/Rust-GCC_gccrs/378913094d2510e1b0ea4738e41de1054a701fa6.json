{"sha": "378913094d2510e1b0ea4738e41de1054a701fa6", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Mzc4OTEzMDk0ZDI1MTBlMWIwZWE0NzM4ZTQxZGUxMDU0YTcwMWZhNg==", "commit": {"author": {"name": "Ramana Radhakrishnan", "email": "ramana.radhakrishnan@linaro.org", "date": "2012-07-05T16:45:18Z"}, "committer": {"name": "Ramana Radhakrishnan", "email": "ramana@gcc.gnu.org", "date": "2012-07-05T16:45:18Z"}, "message": "re PR rtl-optimization/49891 (ICE in redirect_jump_1)\n\n2012-07-05  Ramana Radhakrishnan  <ramana.radhakrishnan@linaro.org>\n\n        PR target/49891\n        PR target/51980\n        * gcc/testsuite/gcc.target/arm/neon/vtrnf32.c: Update.\n        * gcc/testsuite/gcc.target/arm/neon/vtrns32.c: Update.\n        * gcc/testsuite/gcc.target/arm/neon/vtrnu32.c: Update.\n        * gcc/testsuite/gcc.target/arm/neon/vzipf32.c: Update.\n        * gcc/testsuite/gcc.target/arm/neon/vzips32.c: Update.\n        * gcc/testsuite/gcc.target/arm/neon/vzipu32.c: Update.\n\n\n2012-07-05  Ramana Radhakrishnan  <ramana.radhakrishnan@linaro.org>\n\t    Julian Brown  <julian@codesourcery.com>\n\n        PR target/49891\n        PR target/51980\n        * config/arm/neon-gen.ml (return_by_ptr): Delete.\n        (print_function): Handle empty strings.\n        (return): Delete use of return_by_ptr.\n        (mask_shape_for_shuffle): New function.\n        (mask_elems): Likewise.\n        (shuffle_fn): Likewise.\n        (params): Simplify and remove use of return_by_ptr.\n        (get_shuffle): New function.\n        (print_variant): Update.\n        * config/arm/neon.ml (rev_elems): New function.\n        (permute_range): Likewise.\n        (zip_range): Likewise.\n        (uzip_range): Likewise.\n        (trn_range): Likewise.\n        (zip_elems): Likewise.\n        (uzip_elems): Likewise.\n        (trn_elems): Likewise.\n        (features): New enumeration Use_shuffle. Delete ReturnPtr.\n        (pf_su_8_16): New.\n        (suf_32): New.\n        (ops): Update entries for Vrev64, Vrev32, Vrev16, Vtr, Vzip, Vuzp.\n        * config/arm/arm_neon.h: Regenerate.\n\n\n\n\nCo-Authored-By: Julian Brown <julian@codesourcery.com>\n\nFrom-SVN: r189294", "tree": {"sha": "83768642a32f11702e2e8fe8e741cd07d1838947", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/83768642a32f11702e2e8fe8e741cd07d1838947"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/378913094d2510e1b0ea4738e41de1054a701fa6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/378913094d2510e1b0ea4738e41de1054a701fa6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/378913094d2510e1b0ea4738e41de1054a701fa6", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/378913094d2510e1b0ea4738e41de1054a701fa6/comments", "author": null, "committer": null, "parents": [{"sha": "573234ac8bd662ec1d9d5a235f13b39312c6cc03", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/573234ac8bd662ec1d9d5a235f13b39312c6cc03", "html_url": "https://github.com/Rust-GCC/gccrs/commit/573234ac8bd662ec1d9d5a235f13b39312c6cc03"}], "stats": {"total": 568, "additions": 376, "deletions": 192}, "files": [{"sha": "1adf15bf70921d3c8ffdf9c269364c7626d0bc1c", "filename": "gcc/ChangeLog", "status": "modified", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -1,3 +1,31 @@\n+2012-07-05  Ramana Radhakrishnan  <ramana.radhakrishnan@linaro.org>\n+\t    Julian Brown  <julian@codesourcery.com>\n+\n+        PR target/49891\n+        PR target/51980\n+        * config/arm/neon-gen.ml (return_by_ptr): Delete.\n+        (print_function): Handle empty strings.\n+        (return): Delete use of return_by_ptr.\n+        (mask_shape_for_shuffle): New function.\n+        (mask_elems): Likewise.\n+        (shuffle_fn): Likewise.\n+        (params): Simplify and remove use of return_by_ptr.\n+        (get_shuffle): New function.\n+        (print_variant): Update.\n+        * config/arm/neon.ml (rev_elems): New function.\n+        (permute_range): Likewise.\n+        (zip_range): Likewise.\n+        (uzip_range): Likewise.\n+        (trn_range): Likewise.\n+        (zip_elems): Likewise.\n+        (uzip_elems): Likewise.\n+        (trn_elems): Likewise.\n+        (features): New enumeration Use_shuffle. Delete ReturnPtr.\n+        (pf_su_8_16): New.\n+        (suf_32): New.\n+        (ops): Update entries for Vrev64, Vrev32, Vrev16, Vtr, Vzip, Vuzp.\n+        * config/arm/arm_neon.h: Regenerate.\n+\n 2012-07-05  Richard Guenther  <rguenther@suse.de>\n \n \t* tree-pretty-print.c (dump_generic_node): Properly test"}, {"sha": "b486d57be9ccedc2fa3d762472e7942bef5071da", "filename": "gcc/config/arm/arm_neon.h", "status": "modified", "additions": 186, "deletions": 132, "changes": 318, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Fconfig%2Farm%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Fconfig%2Farm%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm_neon.h?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -7047,217 +7047,217 @@ vextq_p16 (poly16x8_t __a, poly16x8_t __b, const int __c)\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vrev64_s8 (int8x8_t __a)\n {\n-  return (int8x8_t)__builtin_neon_vrev64v8qi (__a, 1);\n+  return (int8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 7, 6, 5, 4, 3, 2, 1, 0 });\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vrev64_s16 (int16x4_t __a)\n {\n-  return (int16x4_t)__builtin_neon_vrev64v4hi (__a, 1);\n+  return (int16x4_t) __builtin_shuffle (__a, (uint16x4_t) { 3, 2, 1, 0 });\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vrev64_s32 (int32x2_t __a)\n {\n-  return (int32x2_t)__builtin_neon_vrev64v2si (__a, 1);\n+  return (int32x2_t) __builtin_shuffle (__a, (uint32x2_t) { 1, 0 });\n }\n \n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vrev64_f32 (float32x2_t __a)\n {\n-  return (float32x2_t)__builtin_neon_vrev64v2sf (__a, 3);\n+  return (float32x2_t) __builtin_shuffle (__a, (uint32x2_t) { 1, 0 });\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vrev64_u8 (uint8x8_t __a)\n {\n-  return (uint8x8_t)__builtin_neon_vrev64v8qi ((int8x8_t) __a, 0);\n+  return (uint8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 7, 6, 5, 4, 3, 2, 1, 0 });\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vrev64_u16 (uint16x4_t __a)\n {\n-  return (uint16x4_t)__builtin_neon_vrev64v4hi ((int16x4_t) __a, 0);\n+  return (uint16x4_t) __builtin_shuffle (__a, (uint16x4_t) { 3, 2, 1, 0 });\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vrev64_u32 (uint32x2_t __a)\n {\n-  return (uint32x2_t)__builtin_neon_vrev64v2si ((int32x2_t) __a, 0);\n+  return (uint32x2_t) __builtin_shuffle (__a, (uint32x2_t) { 1, 0 });\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n vrev64_p8 (poly8x8_t __a)\n {\n-  return (poly8x8_t)__builtin_neon_vrev64v8qi ((int8x8_t) __a, 2);\n+  return (poly8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 7, 6, 5, 4, 3, 2, 1, 0 });\n }\n \n __extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n vrev64_p16 (poly16x4_t __a)\n {\n-  return (poly16x4_t)__builtin_neon_vrev64v4hi ((int16x4_t) __a, 2);\n+  return (poly16x4_t) __builtin_shuffle (__a, (uint16x4_t) { 3, 2, 1, 0 });\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vrev64q_s8 (int8x16_t __a)\n {\n-  return (int8x16_t)__builtin_neon_vrev64v16qi (__a, 1);\n+  return (int8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 7, 6, 5, 4, 3, 2, 1, 0, 15, 14, 13, 12, 11, 10, 9, 8 });\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vrev64q_s16 (int16x8_t __a)\n {\n-  return (int16x8_t)__builtin_neon_vrev64v8hi (__a, 1);\n+  return (int16x8_t) __builtin_shuffle (__a, (uint16x8_t) { 3, 2, 1, 0, 7, 6, 5, 4 });\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vrev64q_s32 (int32x4_t __a)\n {\n-  return (int32x4_t)__builtin_neon_vrev64v4si (__a, 1);\n+  return (int32x4_t) __builtin_shuffle (__a, (uint32x4_t) { 1, 0, 3, 2 });\n }\n \n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vrev64q_f32 (float32x4_t __a)\n {\n-  return (float32x4_t)__builtin_neon_vrev64v4sf (__a, 3);\n+  return (float32x4_t) __builtin_shuffle (__a, (uint32x4_t) { 1, 0, 3, 2 });\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vrev64q_u8 (uint8x16_t __a)\n {\n-  return (uint8x16_t)__builtin_neon_vrev64v16qi ((int8x16_t) __a, 0);\n+  return (uint8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 7, 6, 5, 4, 3, 2, 1, 0, 15, 14, 13, 12, 11, 10, 9, 8 });\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vrev64q_u16 (uint16x8_t __a)\n {\n-  return (uint16x8_t)__builtin_neon_vrev64v8hi ((int16x8_t) __a, 0);\n+  return (uint16x8_t) __builtin_shuffle (__a, (uint16x8_t) { 3, 2, 1, 0, 7, 6, 5, 4 });\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vrev64q_u32 (uint32x4_t __a)\n {\n-  return (uint32x4_t)__builtin_neon_vrev64v4si ((int32x4_t) __a, 0);\n+  return (uint32x4_t) __builtin_shuffle (__a, (uint32x4_t) { 1, 0, 3, 2 });\n }\n \n __extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n vrev64q_p8 (poly8x16_t __a)\n {\n-  return (poly8x16_t)__builtin_neon_vrev64v16qi ((int8x16_t) __a, 2);\n+  return (poly8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 7, 6, 5, 4, 3, 2, 1, 0, 15, 14, 13, 12, 11, 10, 9, 8 });\n }\n \n __extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n vrev64q_p16 (poly16x8_t __a)\n {\n-  return (poly16x8_t)__builtin_neon_vrev64v8hi ((int16x8_t) __a, 2);\n+  return (poly16x8_t) __builtin_shuffle (__a, (uint16x8_t) { 3, 2, 1, 0, 7, 6, 5, 4 });\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vrev32_s8 (int8x8_t __a)\n {\n-  return (int8x8_t)__builtin_neon_vrev32v8qi (__a, 1);\n+  return (int8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 3, 2, 1, 0, 7, 6, 5, 4 });\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vrev32_s16 (int16x4_t __a)\n {\n-  return (int16x4_t)__builtin_neon_vrev32v4hi (__a, 1);\n+  return (int16x4_t) __builtin_shuffle (__a, (uint16x4_t) { 1, 0, 3, 2 });\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vrev32_u8 (uint8x8_t __a)\n {\n-  return (uint8x8_t)__builtin_neon_vrev32v8qi ((int8x8_t) __a, 0);\n+  return (uint8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 3, 2, 1, 0, 7, 6, 5, 4 });\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vrev32_u16 (uint16x4_t __a)\n {\n-  return (uint16x4_t)__builtin_neon_vrev32v4hi ((int16x4_t) __a, 0);\n+  return (uint16x4_t) __builtin_shuffle (__a, (uint16x4_t) { 1, 0, 3, 2 });\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n vrev32_p8 (poly8x8_t __a)\n {\n-  return (poly8x8_t)__builtin_neon_vrev32v8qi ((int8x8_t) __a, 2);\n+  return (poly8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 3, 2, 1, 0, 7, 6, 5, 4 });\n }\n \n __extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n vrev32_p16 (poly16x4_t __a)\n {\n-  return (poly16x4_t)__builtin_neon_vrev32v4hi ((int16x4_t) __a, 2);\n+  return (poly16x4_t) __builtin_shuffle (__a, (uint16x4_t) { 1, 0, 3, 2 });\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vrev32q_s8 (int8x16_t __a)\n {\n-  return (int8x16_t)__builtin_neon_vrev32v16qi (__a, 1);\n+  return (int8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 3, 2, 1, 0, 7, 6, 5, 4, 11, 10, 9, 8, 15, 14, 13, 12 });\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vrev32q_s16 (int16x8_t __a)\n {\n-  return (int16x8_t)__builtin_neon_vrev32v8hi (__a, 1);\n+  return (int16x8_t) __builtin_shuffle (__a, (uint16x8_t) { 1, 0, 3, 2, 5, 4, 7, 6 });\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vrev32q_u8 (uint8x16_t __a)\n {\n-  return (uint8x16_t)__builtin_neon_vrev32v16qi ((int8x16_t) __a, 0);\n+  return (uint8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 3, 2, 1, 0, 7, 6, 5, 4, 11, 10, 9, 8, 15, 14, 13, 12 });\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vrev32q_u16 (uint16x8_t __a)\n {\n-  return (uint16x8_t)__builtin_neon_vrev32v8hi ((int16x8_t) __a, 0);\n+  return (uint16x8_t) __builtin_shuffle (__a, (uint16x8_t) { 1, 0, 3, 2, 5, 4, 7, 6 });\n }\n \n __extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n vrev32q_p8 (poly8x16_t __a)\n {\n-  return (poly8x16_t)__builtin_neon_vrev32v16qi ((int8x16_t) __a, 2);\n+  return (poly8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 3, 2, 1, 0, 7, 6, 5, 4, 11, 10, 9, 8, 15, 14, 13, 12 });\n }\n \n __extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n vrev32q_p16 (poly16x8_t __a)\n {\n-  return (poly16x8_t)__builtin_neon_vrev32v8hi ((int16x8_t) __a, 2);\n+  return (poly16x8_t) __builtin_shuffle (__a, (uint16x8_t) { 1, 0, 3, 2, 5, 4, 7, 6 });\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vrev16_s8 (int8x8_t __a)\n {\n-  return (int8x8_t)__builtin_neon_vrev16v8qi (__a, 1);\n+  return (int8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 1, 0, 3, 2, 5, 4, 7, 6 });\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vrev16_u8 (uint8x8_t __a)\n {\n-  return (uint8x8_t)__builtin_neon_vrev16v8qi ((int8x8_t) __a, 0);\n+  return (uint8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 1, 0, 3, 2, 5, 4, 7, 6 });\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n vrev16_p8 (poly8x8_t __a)\n {\n-  return (poly8x8_t)__builtin_neon_vrev16v8qi ((int8x8_t) __a, 2);\n+  return (poly8x8_t) __builtin_shuffle (__a, (uint8x8_t) { 1, 0, 3, 2, 5, 4, 7, 6 });\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vrev16q_s8 (int8x16_t __a)\n {\n-  return (int8x16_t)__builtin_neon_vrev16v16qi (__a, 1);\n+  return (int8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14 });\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vrev16q_u8 (uint8x16_t __a)\n {\n-  return (uint8x16_t)__builtin_neon_vrev16v16qi ((int8x16_t) __a, 0);\n+  return (uint8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14 });\n }\n \n __extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n vrev16q_p8 (poly8x16_t __a)\n {\n-  return (poly8x16_t)__builtin_neon_vrev16v16qi ((int8x16_t) __a, 2);\n+  return (poly8x16_t) __builtin_shuffle (__a, (uint8x16_t) { 1, 0, 3, 2, 5, 4, 7, 6, 9, 8, 11, 10, 13, 12, 15, 14 });\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n@@ -7396,431 +7396,485 @@ __extension__ static __inline int8x8x2_t __attribute__ ((__always_inline__))\n vtrn_s8 (int8x8_t __a, int8x8_t __b)\n {\n   int8x8x2_t __rv;\n-  __builtin_neon_vtrnv8qi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 8, 2, 10, 4, 12, 6, 14 });\n+  __rv.val[1] = (int8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 1, 9, 3, 11, 5, 13, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline int16x4x2_t __attribute__ ((__always_inline__))\n vtrn_s16 (int16x4_t __a, int16x4_t __b)\n {\n   int16x4x2_t __rv;\n-  __builtin_neon_vtrnv4hi (&__rv.val[0], __a, __b);\n-  return __rv;\n-}\n-\n-__extension__ static __inline int32x2x2_t __attribute__ ((__always_inline__))\n-vtrn_s32 (int32x2_t __a, int32x2_t __b)\n-{\n-  int32x2x2_t __rv;\n-  __builtin_neon_vtrnv2si (&__rv.val[0], __a, __b);\n-  return __rv;\n-}\n-\n-__extension__ static __inline float32x2x2_t __attribute__ ((__always_inline__))\n-vtrn_f32 (float32x2_t __a, float32x2_t __b)\n-{\n-  float32x2x2_t __rv;\n-  __builtin_neon_vtrnv2sf (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 4, 2, 6 });\n+  __rv.val[1] = (int16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 1, 5, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline uint8x8x2_t __attribute__ ((__always_inline__))\n vtrn_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n   uint8x8x2_t __rv;\n-  __builtin_neon_vtrnv8qi ((int8x8_t *) &__rv.val[0], (int8x8_t) __a, (int8x8_t) __b);\n+  __rv.val[0] = (uint8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 8, 2, 10, 4, 12, 6, 14 });\n+  __rv.val[1] = (uint8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 1, 9, 3, 11, 5, 13, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline uint16x4x2_t __attribute__ ((__always_inline__))\n vtrn_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n   uint16x4x2_t __rv;\n-  __builtin_neon_vtrnv4hi ((int16x4_t *) &__rv.val[0], (int16x4_t) __a, (int16x4_t) __b);\n-  return __rv;\n-}\n-\n-__extension__ static __inline uint32x2x2_t __attribute__ ((__always_inline__))\n-vtrn_u32 (uint32x2_t __a, uint32x2_t __b)\n-{\n-  uint32x2x2_t __rv;\n-  __builtin_neon_vtrnv2si ((int32x2_t *) &__rv.val[0], (int32x2_t) __a, (int32x2_t) __b);\n+  __rv.val[0] = (uint16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 4, 2, 6 });\n+  __rv.val[1] = (uint16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 1, 5, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline poly8x8x2_t __attribute__ ((__always_inline__))\n vtrn_p8 (poly8x8_t __a, poly8x8_t __b)\n {\n   poly8x8x2_t __rv;\n-  __builtin_neon_vtrnv8qi ((int8x8_t *) &__rv.val[0], (int8x8_t) __a, (int8x8_t) __b);\n+  __rv.val[0] = (poly8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 8, 2, 10, 4, 12, 6, 14 });\n+  __rv.val[1] = (poly8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 1, 9, 3, 11, 5, 13, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline poly16x4x2_t __attribute__ ((__always_inline__))\n vtrn_p16 (poly16x4_t __a, poly16x4_t __b)\n {\n   poly16x4x2_t __rv;\n-  __builtin_neon_vtrnv4hi ((int16x4_t *) &__rv.val[0], (int16x4_t) __a, (int16x4_t) __b);\n+  __rv.val[0] = (poly16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 4, 2, 6 });\n+  __rv.val[1] = (poly16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 1, 5, 3, 7 });\n+  return __rv;\n+}\n+\n+__extension__ static __inline int32x2x2_t __attribute__ ((__always_inline__))\n+vtrn_s32 (int32x2_t __a, int32x2_t __b)\n+{\n+  int32x2x2_t __rv;\n+  __rv.val[0] = (int32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (int32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n+  return __rv;\n+}\n+\n+__extension__ static __inline float32x2x2_t __attribute__ ((__always_inline__))\n+vtrn_f32 (float32x2_t __a, float32x2_t __b)\n+{\n+  float32x2x2_t __rv;\n+  __rv.val[0] = (float32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (float32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n+  return __rv;\n+}\n+\n+__extension__ static __inline uint32x2x2_t __attribute__ ((__always_inline__))\n+vtrn_u32 (uint32x2_t __a, uint32x2_t __b)\n+{\n+  uint32x2x2_t __rv;\n+  __rv.val[0] = (uint32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (uint32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n   return __rv;\n }\n \n __extension__ static __inline int8x16x2_t __attribute__ ((__always_inline__))\n vtrnq_s8 (int8x16_t __a, int8x16_t __b)\n {\n   int8x16x2_t __rv;\n-  __builtin_neon_vtrnv16qi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 16, 2, 18, 4, 20, 6, 22, 8, 24, 10, 26, 12, 28, 14, 30 });\n+  __rv.val[1] = (int8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 1, 17, 3, 19, 5, 21, 7, 23, 9, 25, 11, 27, 13, 29, 15, 31 });\n   return __rv;\n }\n \n __extension__ static __inline int16x8x2_t __attribute__ ((__always_inline__))\n vtrnq_s16 (int16x8_t __a, int16x8_t __b)\n {\n   int16x8x2_t __rv;\n-  __builtin_neon_vtrnv8hi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 8, 2, 10, 4, 12, 6, 14 });\n+  __rv.val[1] = (int16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 1, 9, 3, 11, 5, 13, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline int32x4x2_t __attribute__ ((__always_inline__))\n vtrnq_s32 (int32x4_t __a, int32x4_t __b)\n {\n   int32x4x2_t __rv;\n-  __builtin_neon_vtrnv4si (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 4, 2, 6 });\n+  __rv.val[1] = (int32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 1, 5, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline float32x4x2_t __attribute__ ((__always_inline__))\n vtrnq_f32 (float32x4_t __a, float32x4_t __b)\n {\n   float32x4x2_t __rv;\n-  __builtin_neon_vtrnv4sf (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (float32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 4, 2, 6 });\n+  __rv.val[1] = (float32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 1, 5, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline uint8x16x2_t __attribute__ ((__always_inline__))\n vtrnq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n   uint8x16x2_t __rv;\n-  __builtin_neon_vtrnv16qi ((int8x16_t *) &__rv.val[0], (int8x16_t) __a, (int8x16_t) __b);\n+  __rv.val[0] = (uint8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 16, 2, 18, 4, 20, 6, 22, 8, 24, 10, 26, 12, 28, 14, 30 });\n+  __rv.val[1] = (uint8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 1, 17, 3, 19, 5, 21, 7, 23, 9, 25, 11, 27, 13, 29, 15, 31 });\n   return __rv;\n }\n \n __extension__ static __inline uint16x8x2_t __attribute__ ((__always_inline__))\n vtrnq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n   uint16x8x2_t __rv;\n-  __builtin_neon_vtrnv8hi ((int16x8_t *) &__rv.val[0], (int16x8_t) __a, (int16x8_t) __b);\n+  __rv.val[0] = (uint16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 8, 2, 10, 4, 12, 6, 14 });\n+  __rv.val[1] = (uint16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 1, 9, 3, 11, 5, 13, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline uint32x4x2_t __attribute__ ((__always_inline__))\n vtrnq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n   uint32x4x2_t __rv;\n-  __builtin_neon_vtrnv4si ((int32x4_t *) &__rv.val[0], (int32x4_t) __a, (int32x4_t) __b);\n+  __rv.val[0] = (uint32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 4, 2, 6 });\n+  __rv.val[1] = (uint32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 1, 5, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline poly8x16x2_t __attribute__ ((__always_inline__))\n vtrnq_p8 (poly8x16_t __a, poly8x16_t __b)\n {\n   poly8x16x2_t __rv;\n-  __builtin_neon_vtrnv16qi ((int8x16_t *) &__rv.val[0], (int8x16_t) __a, (int8x16_t) __b);\n+  __rv.val[0] = (poly8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 16, 2, 18, 4, 20, 6, 22, 8, 24, 10, 26, 12, 28, 14, 30 });\n+  __rv.val[1] = (poly8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 1, 17, 3, 19, 5, 21, 7, 23, 9, 25, 11, 27, 13, 29, 15, 31 });\n   return __rv;\n }\n \n __extension__ static __inline poly16x8x2_t __attribute__ ((__always_inline__))\n vtrnq_p16 (poly16x8_t __a, poly16x8_t __b)\n {\n   poly16x8x2_t __rv;\n-  __builtin_neon_vtrnv8hi ((int16x8_t *) &__rv.val[0], (int16x8_t) __a, (int16x8_t) __b);\n+  __rv.val[0] = (poly16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 8, 2, 10, 4, 12, 6, 14 });\n+  __rv.val[1] = (poly16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 1, 9, 3, 11, 5, 13, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline int8x8x2_t __attribute__ ((__always_inline__))\n vzip_s8 (int8x8_t __a, int8x8_t __b)\n {\n   int8x8x2_t __rv;\n-  __builtin_neon_vzipv8qi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 8, 1, 9, 2, 10, 3, 11 });\n+  __rv.val[1] = (int8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 4, 12, 5, 13, 6, 14, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline int16x4x2_t __attribute__ ((__always_inline__))\n vzip_s16 (int16x4_t __a, int16x4_t __b)\n {\n   int16x4x2_t __rv;\n-  __builtin_neon_vzipv4hi (&__rv.val[0], __a, __b);\n-  return __rv;\n-}\n-\n-__extension__ static __inline int32x2x2_t __attribute__ ((__always_inline__))\n-vzip_s32 (int32x2_t __a, int32x2_t __b)\n-{\n-  int32x2x2_t __rv;\n-  __builtin_neon_vzipv2si (&__rv.val[0], __a, __b);\n-  return __rv;\n-}\n-\n-__extension__ static __inline float32x2x2_t __attribute__ ((__always_inline__))\n-vzip_f32 (float32x2_t __a, float32x2_t __b)\n-{\n-  float32x2x2_t __rv;\n-  __builtin_neon_vzipv2sf (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 4, 1, 5 });\n+  __rv.val[1] = (int16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 2, 6, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline uint8x8x2_t __attribute__ ((__always_inline__))\n vzip_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n   uint8x8x2_t __rv;\n-  __builtin_neon_vzipv8qi ((int8x8_t *) &__rv.val[0], (int8x8_t) __a, (int8x8_t) __b);\n+  __rv.val[0] = (uint8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 8, 1, 9, 2, 10, 3, 11 });\n+  __rv.val[1] = (uint8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 4, 12, 5, 13, 6, 14, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline uint16x4x2_t __attribute__ ((__always_inline__))\n vzip_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n   uint16x4x2_t __rv;\n-  __builtin_neon_vzipv4hi ((int16x4_t *) &__rv.val[0], (int16x4_t) __a, (int16x4_t) __b);\n-  return __rv;\n-}\n-\n-__extension__ static __inline uint32x2x2_t __attribute__ ((__always_inline__))\n-vzip_u32 (uint32x2_t __a, uint32x2_t __b)\n-{\n-  uint32x2x2_t __rv;\n-  __builtin_neon_vzipv2si ((int32x2_t *) &__rv.val[0], (int32x2_t) __a, (int32x2_t) __b);\n+  __rv.val[0] = (uint16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 4, 1, 5 });\n+  __rv.val[1] = (uint16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 2, 6, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline poly8x8x2_t __attribute__ ((__always_inline__))\n vzip_p8 (poly8x8_t __a, poly8x8_t __b)\n {\n   poly8x8x2_t __rv;\n-  __builtin_neon_vzipv8qi ((int8x8_t *) &__rv.val[0], (int8x8_t) __a, (int8x8_t) __b);\n+  __rv.val[0] = (poly8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 8, 1, 9, 2, 10, 3, 11 });\n+  __rv.val[1] = (poly8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 4, 12, 5, 13, 6, 14, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline poly16x4x2_t __attribute__ ((__always_inline__))\n vzip_p16 (poly16x4_t __a, poly16x4_t __b)\n {\n   poly16x4x2_t __rv;\n-  __builtin_neon_vzipv4hi ((int16x4_t *) &__rv.val[0], (int16x4_t) __a, (int16x4_t) __b);\n+  __rv.val[0] = (poly16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 4, 1, 5 });\n+  __rv.val[1] = (poly16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 2, 6, 3, 7 });\n+  return __rv;\n+}\n+\n+__extension__ static __inline int32x2x2_t __attribute__ ((__always_inline__))\n+vzip_s32 (int32x2_t __a, int32x2_t __b)\n+{\n+  int32x2x2_t __rv;\n+  __rv.val[0] = (int32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (int32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n+  return __rv;\n+}\n+\n+__extension__ static __inline float32x2x2_t __attribute__ ((__always_inline__))\n+vzip_f32 (float32x2_t __a, float32x2_t __b)\n+{\n+  float32x2x2_t __rv;\n+  __rv.val[0] = (float32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (float32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n+  return __rv;\n+}\n+\n+__extension__ static __inline uint32x2x2_t __attribute__ ((__always_inline__))\n+vzip_u32 (uint32x2_t __a, uint32x2_t __b)\n+{\n+  uint32x2x2_t __rv;\n+  __rv.val[0] = (uint32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (uint32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n   return __rv;\n }\n \n __extension__ static __inline int8x16x2_t __attribute__ ((__always_inline__))\n vzipq_s8 (int8x16_t __a, int8x16_t __b)\n {\n   int8x16x2_t __rv;\n-  __builtin_neon_vzipv16qi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 16, 1, 17, 2, 18, 3, 19, 4, 20, 5, 21, 6, 22, 7, 23 });\n+  __rv.val[1] = (int8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 8, 24, 9, 25, 10, 26, 11, 27, 12, 28, 13, 29, 14, 30, 15, 31 });\n   return __rv;\n }\n \n __extension__ static __inline int16x8x2_t __attribute__ ((__always_inline__))\n vzipq_s16 (int16x8_t __a, int16x8_t __b)\n {\n   int16x8x2_t __rv;\n-  __builtin_neon_vzipv8hi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 8, 1, 9, 2, 10, 3, 11 });\n+  __rv.val[1] = (int16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 4, 12, 5, 13, 6, 14, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline int32x4x2_t __attribute__ ((__always_inline__))\n vzipq_s32 (int32x4_t __a, int32x4_t __b)\n {\n   int32x4x2_t __rv;\n-  __builtin_neon_vzipv4si (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 4, 1, 5 });\n+  __rv.val[1] = (int32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 2, 6, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline float32x4x2_t __attribute__ ((__always_inline__))\n vzipq_f32 (float32x4_t __a, float32x4_t __b)\n {\n   float32x4x2_t __rv;\n-  __builtin_neon_vzipv4sf (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (float32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 4, 1, 5 });\n+  __rv.val[1] = (float32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 2, 6, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline uint8x16x2_t __attribute__ ((__always_inline__))\n vzipq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n   uint8x16x2_t __rv;\n-  __builtin_neon_vzipv16qi ((int8x16_t *) &__rv.val[0], (int8x16_t) __a, (int8x16_t) __b);\n+  __rv.val[0] = (uint8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 16, 1, 17, 2, 18, 3, 19, 4, 20, 5, 21, 6, 22, 7, 23 });\n+  __rv.val[1] = (uint8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 8, 24, 9, 25, 10, 26, 11, 27, 12, 28, 13, 29, 14, 30, 15, 31 });\n   return __rv;\n }\n \n __extension__ static __inline uint16x8x2_t __attribute__ ((__always_inline__))\n vzipq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n   uint16x8x2_t __rv;\n-  __builtin_neon_vzipv8hi ((int16x8_t *) &__rv.val[0], (int16x8_t) __a, (int16x8_t) __b);\n+  __rv.val[0] = (uint16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 8, 1, 9, 2, 10, 3, 11 });\n+  __rv.val[1] = (uint16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 4, 12, 5, 13, 6, 14, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline uint32x4x2_t __attribute__ ((__always_inline__))\n vzipq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n   uint32x4x2_t __rv;\n-  __builtin_neon_vzipv4si ((int32x4_t *) &__rv.val[0], (int32x4_t) __a, (int32x4_t) __b);\n+  __rv.val[0] = (uint32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 4, 1, 5 });\n+  __rv.val[1] = (uint32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 2, 6, 3, 7 });\n   return __rv;\n }\n \n __extension__ static __inline poly8x16x2_t __attribute__ ((__always_inline__))\n vzipq_p8 (poly8x16_t __a, poly8x16_t __b)\n {\n   poly8x16x2_t __rv;\n-  __builtin_neon_vzipv16qi ((int8x16_t *) &__rv.val[0], (int8x16_t) __a, (int8x16_t) __b);\n+  __rv.val[0] = (poly8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 16, 1, 17, 2, 18, 3, 19, 4, 20, 5, 21, 6, 22, 7, 23 });\n+  __rv.val[1] = (poly8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 8, 24, 9, 25, 10, 26, 11, 27, 12, 28, 13, 29, 14, 30, 15, 31 });\n   return __rv;\n }\n \n __extension__ static __inline poly16x8x2_t __attribute__ ((__always_inline__))\n vzipq_p16 (poly16x8_t __a, poly16x8_t __b)\n {\n   poly16x8x2_t __rv;\n-  __builtin_neon_vzipv8hi ((int16x8_t *) &__rv.val[0], (int16x8_t) __a, (int16x8_t) __b);\n+  __rv.val[0] = (poly16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 8, 1, 9, 2, 10, 3, 11 });\n+  __rv.val[1] = (poly16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 4, 12, 5, 13, 6, 14, 7, 15 });\n   return __rv;\n }\n \n __extension__ static __inline int8x8x2_t __attribute__ ((__always_inline__))\n vuzp_s8 (int8x8_t __a, int8x8_t __b)\n {\n   int8x8x2_t __rv;\n-  __builtin_neon_vuzpv8qi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 2, 4, 6, 8, 10, 12, 14 });\n+  __rv.val[1] = (int8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 1, 3, 5, 7, 9, 11, 13, 15 });\n   return __rv;\n }\n \n __extension__ static __inline int16x4x2_t __attribute__ ((__always_inline__))\n vuzp_s16 (int16x4_t __a, int16x4_t __b)\n {\n   int16x4x2_t __rv;\n-  __builtin_neon_vuzpv4hi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 2, 4, 6 });\n+  __rv.val[1] = (int16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 1, 3, 5, 7 });\n   return __rv;\n }\n \n __extension__ static __inline int32x2x2_t __attribute__ ((__always_inline__))\n vuzp_s32 (int32x2_t __a, int32x2_t __b)\n {\n   int32x2x2_t __rv;\n-  __builtin_neon_vuzpv2si (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (int32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n   return __rv;\n }\n \n __extension__ static __inline float32x2x2_t __attribute__ ((__always_inline__))\n vuzp_f32 (float32x2_t __a, float32x2_t __b)\n {\n   float32x2x2_t __rv;\n-  __builtin_neon_vuzpv2sf (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (float32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (float32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n   return __rv;\n }\n \n __extension__ static __inline uint8x8x2_t __attribute__ ((__always_inline__))\n vuzp_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n   uint8x8x2_t __rv;\n-  __builtin_neon_vuzpv8qi ((int8x8_t *) &__rv.val[0], (int8x8_t) __a, (int8x8_t) __b);\n+  __rv.val[0] = (uint8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 2, 4, 6, 8, 10, 12, 14 });\n+  __rv.val[1] = (uint8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 1, 3, 5, 7, 9, 11, 13, 15 });\n   return __rv;\n }\n \n __extension__ static __inline uint16x4x2_t __attribute__ ((__always_inline__))\n vuzp_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n   uint16x4x2_t __rv;\n-  __builtin_neon_vuzpv4hi ((int16x4_t *) &__rv.val[0], (int16x4_t) __a, (int16x4_t) __b);\n+  __rv.val[0] = (uint16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 2, 4, 6 });\n+  __rv.val[1] = (uint16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 1, 3, 5, 7 });\n   return __rv;\n }\n \n __extension__ static __inline uint32x2x2_t __attribute__ ((__always_inline__))\n vuzp_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n   uint32x2x2_t __rv;\n-  __builtin_neon_vuzpv2si ((int32x2_t *) &__rv.val[0], (int32x2_t) __a, (int32x2_t) __b);\n+  __rv.val[0] = (uint32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 0, 2 });\n+  __rv.val[1] = (uint32x2_t) __builtin_shuffle (__a, __b, (uint32x2_t) { 1, 3 });\n   return __rv;\n }\n \n __extension__ static __inline poly8x8x2_t __attribute__ ((__always_inline__))\n vuzp_p8 (poly8x8_t __a, poly8x8_t __b)\n {\n   poly8x8x2_t __rv;\n-  __builtin_neon_vuzpv8qi ((int8x8_t *) &__rv.val[0], (int8x8_t) __a, (int8x8_t) __b);\n+  __rv.val[0] = (poly8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 0, 2, 4, 6, 8, 10, 12, 14 });\n+  __rv.val[1] = (poly8x8_t) __builtin_shuffle (__a, __b, (uint8x8_t) { 1, 3, 5, 7, 9, 11, 13, 15 });\n   return __rv;\n }\n \n __extension__ static __inline poly16x4x2_t __attribute__ ((__always_inline__))\n vuzp_p16 (poly16x4_t __a, poly16x4_t __b)\n {\n   poly16x4x2_t __rv;\n-  __builtin_neon_vuzpv4hi ((int16x4_t *) &__rv.val[0], (int16x4_t) __a, (int16x4_t) __b);\n+  __rv.val[0] = (poly16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 0, 2, 4, 6 });\n+  __rv.val[1] = (poly16x4_t) __builtin_shuffle (__a, __b, (uint16x4_t) { 1, 3, 5, 7 });\n   return __rv;\n }\n \n __extension__ static __inline int8x16x2_t __attribute__ ((__always_inline__))\n vuzpq_s8 (int8x16_t __a, int8x16_t __b)\n {\n   int8x16x2_t __rv;\n-  __builtin_neon_vuzpv16qi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30 });\n+  __rv.val[1] = (int8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31 });\n   return __rv;\n }\n \n __extension__ static __inline int16x8x2_t __attribute__ ((__always_inline__))\n vuzpq_s16 (int16x8_t __a, int16x8_t __b)\n {\n   int16x8x2_t __rv;\n-  __builtin_neon_vuzpv8hi (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 2, 4, 6, 8, 10, 12, 14 });\n+  __rv.val[1] = (int16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 1, 3, 5, 7, 9, 11, 13, 15 });\n   return __rv;\n }\n \n __extension__ static __inline int32x4x2_t __attribute__ ((__always_inline__))\n vuzpq_s32 (int32x4_t __a, int32x4_t __b)\n {\n   int32x4x2_t __rv;\n-  __builtin_neon_vuzpv4si (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (int32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 2, 4, 6 });\n+  __rv.val[1] = (int32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 1, 3, 5, 7 });\n   return __rv;\n }\n \n __extension__ static __inline float32x4x2_t __attribute__ ((__always_inline__))\n vuzpq_f32 (float32x4_t __a, float32x4_t __b)\n {\n   float32x4x2_t __rv;\n-  __builtin_neon_vuzpv4sf (&__rv.val[0], __a, __b);\n+  __rv.val[0] = (float32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 2, 4, 6 });\n+  __rv.val[1] = (float32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 1, 3, 5, 7 });\n   return __rv;\n }\n \n __extension__ static __inline uint8x16x2_t __attribute__ ((__always_inline__))\n vuzpq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n   uint8x16x2_t __rv;\n-  __builtin_neon_vuzpv16qi ((int8x16_t *) &__rv.val[0], (int8x16_t) __a, (int8x16_t) __b);\n+  __rv.val[0] = (uint8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30 });\n+  __rv.val[1] = (uint8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31 });\n   return __rv;\n }\n \n __extension__ static __inline uint16x8x2_t __attribute__ ((__always_inline__))\n vuzpq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n   uint16x8x2_t __rv;\n-  __builtin_neon_vuzpv8hi ((int16x8_t *) &__rv.val[0], (int16x8_t) __a, (int16x8_t) __b);\n+  __rv.val[0] = (uint16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 2, 4, 6, 8, 10, 12, 14 });\n+  __rv.val[1] = (uint16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 1, 3, 5, 7, 9, 11, 13, 15 });\n   return __rv;\n }\n \n __extension__ static __inline uint32x4x2_t __attribute__ ((__always_inline__))\n vuzpq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n   uint32x4x2_t __rv;\n-  __builtin_neon_vuzpv4si ((int32x4_t *) &__rv.val[0], (int32x4_t) __a, (int32x4_t) __b);\n+  __rv.val[0] = (uint32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 0, 2, 4, 6 });\n+  __rv.val[1] = (uint32x4_t) __builtin_shuffle (__a, __b, (uint32x4_t) { 1, 3, 5, 7 });\n   return __rv;\n }\n \n __extension__ static __inline poly8x16x2_t __attribute__ ((__always_inline__))\n vuzpq_p8 (poly8x16_t __a, poly8x16_t __b)\n {\n   poly8x16x2_t __rv;\n-  __builtin_neon_vuzpv16qi ((int8x16_t *) &__rv.val[0], (int8x16_t) __a, (int8x16_t) __b);\n+  __rv.val[0] = (poly8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30 });\n+  __rv.val[1] = (poly8x16_t) __builtin_shuffle (__a, __b, (uint8x16_t) { 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31 });\n   return __rv;\n }\n \n __extension__ static __inline poly16x8x2_t __attribute__ ((__always_inline__))\n vuzpq_p16 (poly16x8_t __a, poly16x8_t __b)\n {\n   poly16x8x2_t __rv;\n-  __builtin_neon_vuzpv8hi ((int16x8_t *) &__rv.val[0], (int16x8_t) __a, (int16x8_t) __b);\n+  __rv.val[0] = (poly16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 0, 2, 4, 6, 8, 10, 12, 14 });\n+  __rv.val[1] = (poly16x8_t) __builtin_shuffle (__a, __b, (uint16x8_t) { 1, 3, 5, 7, 9, 11, 13, 15 });\n   return __rv;\n }\n "}, {"sha": "29679aaca0f5c3644c6fea4dd5d8de05ec790a43", "filename": "gcc/config/arm/neon-gen.ml", "status": "modified", "additions": 81, "deletions": 31, "changes": 112, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Fconfig%2Farm%2Fneon-gen.ml", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Fconfig%2Farm%2Fneon-gen.ml", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fneon-gen.ml?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -91,15 +91,14 @@ let print_function arity fnname body =\n   end;\n   open_braceblock ffmt;\n   let rec print_lines = function\n-    [] -> ()\n+    []       -> ()\n+  | \"\" :: lines -> print_lines lines\n   | [line] -> Format.printf \"%s\" line\n-  | line::lines -> Format.printf \"%s@,\" line; print_lines lines in\n+  | line::lines -> Format.printf \"%s@,\" line ; print_lines lines in\n   print_lines body;\n   close_braceblock ffmt;\n   end_function ffmt\n \n-let return_by_ptr features = List.mem ReturnPtr features\n-\n let union_string num elts base =\n   let itype = inttype_for_array num elts in\n   let iname = string_of_inttype itype\n@@ -141,29 +140,76 @@ let cast_for_return to_ty = \"(\" ^ (string_of_vectype to_ty) ^ \")\"\n \n (* Return a tuple of a list of declarations to go at the start of the function,\n    and a list of statements needed to return THING.  *)\n-let return arity return_by_ptr thing =\n+let return arity thing =\n   match arity with\n     Arity0 (ret) | Arity1 (ret, _) | Arity2 (ret, _, _) | Arity3 (ret, _, _, _)\n   | Arity4 (ret, _, _, _, _) ->\n-    match ret with\n-      T_arrayof (num, vec) ->\n-        if return_by_ptr then\n-          let sname = string_of_vectype ret in\n-          [Printf.sprintf \"%s __rv;\" sname],\n-          [thing ^ \";\"; \"return __rv;\"]\n-        else\n+      begin match ret with\n+\tT_arrayof (num, vec) ->\n           let uname = union_string num vec \"__rv\" in\n           [uname ^ \";\"], [\"__rv.__o = \" ^ thing ^ \";\"; \"return __rv.__i;\"]\n-    | T_void -> [], [thing ^ \";\"]\n-    | _ ->\n-        [], [\"return \" ^ (cast_for_return ret) ^ thing ^ \";\"]\n+      | T_void ->\n+\t  [], [thing ^ \";\"]\n+      | _ ->\n+\t  [], [\"return \" ^ (cast_for_return ret) ^ thing ^ \";\"]\n+      end\n+\n+let mask_shape_for_shuffle = function\n+    All (num, reg) -> All (num, reg)\n+  | Pair_result reg -> All (2, reg)\n+  | _ -> failwith \"mask_for_shuffle\"\n+\n+let mask_elems shuffle shape elttype part =\n+  let elem_size = elt_width elttype in\n+  let num_elems =\n+    match regmap shape 0 with\n+      Dreg -> 64 / elem_size\n+    | Qreg -> 128 / elem_size\n+    | _ -> failwith \"mask_elems\" in\n+  shuffle elem_size num_elems part\n+\n+(* Return a tuple of a list of declarations 0and a list of statements needed\n+   to implement an intrinsic using __builtin_shuffle.  SHUFFLE is a function\n+   which returns a list of elements suitable for using as a mask.  *)\n+\n+let shuffle_fn shuffle shape arity elttype =\n+  let mshape = mask_shape_for_shuffle shape in\n+  let masktype = type_for_elt mshape (unsigned_of_elt elttype) 0 in\n+  let masktype_str = string_of_vectype masktype in\n+  let shuffle_res = type_for_elt mshape elttype 0 in\n+  let shuffle_res_str = string_of_vectype shuffle_res in\n+  match arity with\n+    Arity0 (ret) | Arity1 (ret, _) | Arity2 (ret, _, _) | Arity3 (ret, _, _, _)\n+  | Arity4 (ret, _, _, _, _) ->\n+      begin match ret with\n+        T_arrayof (num, vec) ->\n+\t  let elems1 = mask_elems shuffle mshape elttype `lo\n+\t  and elems2 = mask_elems shuffle mshape elttype `hi in\n+\t  let mask1 = (String.concat \", \" (List.map string_of_int elems1))\n+\t  and mask2 = (String.concat \", \" (List.map string_of_int elems2)) in\n+\t  let shuf1 = Printf.sprintf\n+\t    \"__rv.val[0] = (%s) __builtin_shuffle (__a, __b, (%s) { %s });\"\n+\t    shuffle_res_str masktype_str mask1\n+\t  and shuf2 = Printf.sprintf\n+\t    \"__rv.val[1] = (%s) __builtin_shuffle (__a, __b, (%s) { %s });\"\n+\t    shuffle_res_str masktype_str mask2 in\n+\t  [Printf.sprintf \"%s __rv;\" (string_of_vectype ret);],\n+\t  [shuf1; shuf2; \"return __rv;\"]\n+      | _ ->\n+          let elems = mask_elems shuffle mshape elttype `lo in\n+          let mask =  (String.concat \", \" (List.map string_of_int elems)) in\n+\t  let shuf = Printf.sprintf\n+\t    \"return (%s) __builtin_shuffle (__a, (%s) { %s });\" shuffle_res_str masktype_str mask in\n+\t  [\"\"],\n+\t  [shuf]\n+      end\n \n let rec element_type ctype =\n   match ctype with\n     T_arrayof (_, v) -> element_type v\n   | _ -> ctype\n \n-let params return_by_ptr ps =\n+let params ps =\n   let pdecls = ref [] in\n   let ptype t p =\n     match t with\n@@ -180,13 +226,7 @@ let params return_by_ptr ps =\n   | Arity3 (_, t1, t2, t3) -> [ptype t1 \"__a\"; ptype t2 \"__b\"; ptype t3 \"__c\"]\n   | Arity4 (_, t1, t2, t3, t4) ->\n       [ptype t1 \"__a\"; ptype t2 \"__b\"; ptype t3 \"__c\"; ptype t4 \"__d\"] in\n-  match ps with\n-    Arity0 ret | Arity1 (ret, _) | Arity2 (ret, _, _) | Arity3 (ret, _, _, _)\n-  | Arity4 (ret, _, _, _, _) ->\n-      if return_by_ptr then\n-        !pdecls, add_cast (T_ptrto (element_type ret)) \"&__rv.val[0]\" :: plist\n-      else\n-        !pdecls, plist\n+  !pdecls, plist\n \n let modify_params features plist =\n   let is_flipped =\n@@ -239,17 +279,27 @@ let rec mode_suffix elttype shape =\n     and srcmode = mode_of_elt src shape in\n     string_of_mode dstmode ^ string_of_mode srcmode\n \n+let get_shuffle features =\n+  try\n+    match List.find (function Use_shuffle _ -> true | _ -> false) features with\n+      Use_shuffle fn -> Some fn\n+    | _ -> None\n+  with Not_found -> None\n+\n let print_variant opcode features shape name (ctype, asmtype, elttype) =\n   let bits = infoword_value elttype features in\n   let modesuf = mode_suffix elttype shape in\n-  let return_by_ptr = return_by_ptr features in\n-  let pdecls, paramlist = params return_by_ptr ctype in\n-  let paramlist' = modify_params features paramlist in\n-  let paramlist'' = extra_word shape features paramlist' bits in\n-  let parstr = String.concat \", \" paramlist'' in\n-  let builtin = Printf.sprintf \"__builtin_neon_%s%s (%s)\"\n-                  (builtin_name features name) modesuf parstr in\n-  let rdecls, stmts = return ctype return_by_ptr builtin in\n+  let pdecls, paramlist = params ctype in\n+  let rdecls, stmts =\n+    match get_shuffle features with\n+      Some shuffle -> shuffle_fn shuffle shape ctype elttype\n+    | None ->\n+\tlet paramlist' = modify_params features paramlist in\n+\tlet paramlist'' = extra_word shape features paramlist' bits in\n+\tlet parstr = String.concat \", \" paramlist'' in\n+\tlet builtin = Printf.sprintf \"__builtin_neon_%s%s (%s)\"\n+                \t(builtin_name features name) modesuf parstr in\n+\treturn ctype builtin in\n   let body = pdecls @ rdecls @ stmts\n   and fnname = (intrinsic_name name) ^ \"_\" ^ (string_of_elt elttype) in\n   print_function ctype fnname body"}, {"sha": "24829f2d5014352acecbb6593afe77c115cc7ed0", "filename": "gcc/config/arm/neon.ml", "status": "modified", "additions": 64, "deletions": 23, "changes": 87, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Fconfig%2Farm%2Fneon.ml", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Fconfig%2Farm%2Fneon.ml", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fneon.ml?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -201,6 +201,42 @@ type opcode =\n   (* Reinterpret casts.  *)\n   | Vreinterp\n \n+let rev_elems revsize elsize nelts _ =\n+  let mask = (revsize / elsize) - 1 in\n+  let arr = Array.init nelts\n+    (fun i -> i lxor mask) in\n+  Array.to_list arr\n+\n+let permute_range i stride nelts increment =\n+  let rec build i = function\n+    0 -> []\n+  | nelts -> i :: (i + stride) :: build (i + increment) (pred nelts) in\n+  build i nelts\n+\n+(* Generate a list of integers suitable for vzip.  *)\n+let zip_range i stride nelts = permute_range i stride nelts 1\n+\n+(* Generate a list of integers suitable for vunzip.  *)\n+let uzip_range i stride nelts = permute_range i stride nelts 4\n+\n+(* Generate a list of integers suitable for trn.  *)\n+let trn_range i stride nelts = permute_range i stride nelts 2\n+\n+let zip_elems _ nelts part =\n+  match part with\n+    `lo -> zip_range 0 nelts (nelts / 2)\n+  | `hi -> zip_range (nelts / 2) nelts (nelts / 2)\n+\n+let uzip_elems _ nelts part =\n+  match part with\n+    `lo -> uzip_range 0 2 (nelts / 2)\n+  | `hi -> uzip_range 1 2 (nelts / 2)\n+\n+let trn_elems _ nelts part =\n+  match part with\n+    `lo -> trn_range 0 nelts (nelts / 2)\n+  | `hi -> trn_range 1 nelts (nelts / 2)\n+\n (* Features used for documentation, to distinguish between some instruction\n    variants, and to signal special requirements (e.g. swapping arguments).  *)\n \n@@ -214,7 +250,10 @@ type features =\n   | Flipped of string  (* Builtin name to use with flipped arguments.  *)\n   | InfoWord  (* Pass an extra word for signage/rounding etc. (always passed\n                  for All _, Long, Wide, Narrow shape_forms.  *)\n-  | ReturnPtr  (* Pass explicit pointer to return value as first argument.  *)\n+    (* Implement builtin as shuffle.  The parameter is a function which returns\n+       masks suitable for __builtin_shuffle: arguments are (element size,\n+       number of elements, high/low part selector).  *)\n+  | Use_shuffle of (int -> int -> [`lo|`hi] -> int list)\n     (* A specification as to the shape of instruction expected upon\n        disassembly, used if it differs from the shape used to build the\n        intrinsic prototype.  Multiple entries in the constructor's argument\n@@ -706,8 +745,10 @@ let u_8_32 = [U8; U16; U32]\n let su_8_32 = [S8; S16; S32; U8; U16; U32]\n let su_8_64 = S64 :: U64 :: su_8_32\n let su_16_64 = [S16; S32; S64; U16; U32; U64]\n+let pf_su_8_16 = [P8; P16; S8; S16; U8; U16]\n let pf_su_8_32 = P8 :: P16 :: F32 :: su_8_32\n let pf_su_8_64 = P8 :: P16 :: F32 :: su_8_64\n+let suf_32 = [S32; U32; F32]\n \n let ops =\n   [\n@@ -1317,12 +1358,18 @@ let ops =\n       pf_su_8_64;\n \n     (* Reverse elements.  *)\n-    Vrev64, [], All (2, Dreg), \"vrev64\", bits_1, P8 :: P16 :: F32 :: su_8_32;\n-    Vrev64, [], All (2, Qreg), \"vrev64Q\", bits_1, P8 :: P16 :: F32 :: su_8_32;\n-    Vrev32, [], All (2, Dreg), \"vrev32\", bits_1, [P8; P16; S8; U8; S16; U16];\n-    Vrev32, [], All (2, Qreg), \"vrev32Q\", bits_1, [P8; P16; S8; U8; S16; U16];\n-    Vrev16, [], All (2, Dreg), \"vrev16\", bits_1, [P8; S8; U8];\n-    Vrev16, [], All (2, Qreg), \"vrev16Q\", bits_1, [P8; S8; U8];\n+    Vrev64, [Use_shuffle (rev_elems 64)], All (2, Dreg), \"vrev64\", bits_1,\n+      P8 :: P16 :: F32 :: su_8_32;\n+    Vrev64, [Use_shuffle (rev_elems 64)], All (2, Qreg), \"vrev64Q\", bits_1,\n+      P8 :: P16 :: F32 :: su_8_32;\n+    Vrev32, [Use_shuffle (rev_elems 32)], All (2, Dreg), \"vrev32\", bits_1,\n+      [P8; P16; S8; U8; S16; U16];\n+    Vrev32, [Use_shuffle (rev_elems 32)], All (2, Qreg), \"vrev32Q\", bits_1,\n+      [P8; P16; S8; U8; S16; U16];\n+    Vrev16, [Use_shuffle (rev_elems 16)], All (2, Dreg), \"vrev16\", bits_1,\n+      [P8; S8; U8];\n+    Vrev16, [Use_shuffle (rev_elems 16)], All (2, Qreg), \"vrev16Q\", bits_1,\n+      [P8; S8; U8];\n \n     (* Bit selection.  *)\n     Vbsl,\n@@ -1336,25 +1383,19 @@ let ops =\n       Use_operands [| Qreg; Qreg; Qreg; Qreg |], \"vbslQ\", bit_select,\n       pf_su_8_64;\n \n-    (* Transpose elements.  **NOTE** ReturnPtr goes some of the way towards\n-       generating good code for intrinsics which return structure types --\n-       builtins work well by themselves (and understand that the values being\n-       stored on e.g. the stack also reside in registers, so can optimise the\n-       stores away entirely if the results are used immediately), but\n-       intrinsics are very much less efficient. Maybe something can be improved\n-       re: inlining, or tweaking the ABI used for intrinsics (a special call\n-       attribute?).\n-    *)\n-    Vtrn, [ReturnPtr], Pair_result Dreg, \"vtrn\", bits_2, pf_su_8_32;\n-    Vtrn, [ReturnPtr], Pair_result Qreg, \"vtrnQ\", bits_2, pf_su_8_32;\n-\n+    Vtrn, [Use_shuffle trn_elems], Pair_result Dreg, \"vtrn\", bits_2, pf_su_8_16;\n+    Vtrn, [Use_shuffle trn_elems; Instruction_name [\"vuzp\"]], Pair_result Dreg, \"vtrn\", bits_2, suf_32;\n+    Vtrn, [Use_shuffle trn_elems], Pair_result Qreg, \"vtrnQ\", bits_2, pf_su_8_32;\n     (* Zip elements.  *)\n-    Vzip, [ReturnPtr], Pair_result Dreg, \"vzip\", bits_2, pf_su_8_32;\n-    Vzip, [ReturnPtr], Pair_result Qreg, \"vzipQ\", bits_2, pf_su_8_32;\n+    Vzip, [Use_shuffle zip_elems], Pair_result Dreg, \"vzip\", bits_2, pf_su_8_16;\n+    Vzip, [Use_shuffle zip_elems; Instruction_name [\"vuzp\"]], Pair_result Dreg, \"vzip\", bits_2, suf_32;\n+    Vzip, [Use_shuffle zip_elems], Pair_result Qreg, \"vzipQ\", bits_2, pf_su_8_32; \n \n     (* Unzip elements.  *)\n-    Vuzp, [ReturnPtr], Pair_result Dreg, \"vuzp\", bits_2, pf_su_8_32;\n-    Vuzp, [ReturnPtr], Pair_result Qreg, \"vuzpQ\", bits_2, pf_su_8_32;\n+    Vuzp, [Use_shuffle uzip_elems], Pair_result Dreg, \"vuzp\", bits_2,\n+      pf_su_8_32;\n+    Vuzp, [Use_shuffle uzip_elems], Pair_result Qreg, \"vuzpQ\", bits_2,\n+      pf_su_8_32;\n \n     (* Element/structure loads.  VLD1 variants.  *)\n     Vldx 1,"}, {"sha": "6ed14ab7979ea304238ce0c840b8d95582ce9da6", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -1,3 +1,14 @@\n+2012-07-05  Ramana Radhakrishnan  <ramana.radhakrishnan@linaro.org>\n+\n+        PR target/49891\n+        PR target/51980\n+        * gcc/testsuite/gcc.target/arm/neon/vtrnf32.c: Update.\n+        * gcc/testsuite/gcc.target/arm/neon/vtrns32.c: Update.\n+        * gcc/testsuite/gcc.target/arm/neon/vtrnu32.c: Update.\n+        * gcc/testsuite/gcc.target/arm/neon/vzipf32.c: Update.\n+        * gcc/testsuite/gcc.target/arm/neon/vzips32.c: Update.\n+        * gcc/testsuite/gcc.target/arm/neon/vzipu32.c: Update.\n+\n 2012-07-05  Mikael Morin  <mikael@gcc.gnu.org>\n \n \tPR fortran/53732"}, {"sha": "c5a301b993a89a6b161b5c8cbefc38e039a910e6", "filename": "gcc/testsuite/gcc.target/arm/neon/vtrnf32.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrnf32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrnf32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrnf32.c?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -17,5 +17,5 @@ void test_vtrnf32 (void)\n   out_float32x2x2_t = vtrn_f32 (arg0_float32x2_t, arg1_float32x2_t);\n }\n \n-/* { dg-final { scan-assembler \"vtrn\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n+/* { dg-final { scan-assembler \"vuzp\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n /* { dg-final { cleanup-saved-temps } } */"}, {"sha": "f01047497a5e2945a4a771a1902fffc8976ad2ec", "filename": "gcc/testsuite/gcc.target/arm/neon/vtrns32.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrns32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrns32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrns32.c?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -17,5 +17,5 @@ void test_vtrns32 (void)\n   out_int32x2x2_t = vtrn_s32 (arg0_int32x2_t, arg1_int32x2_t);\n }\n \n-/* { dg-final { scan-assembler \"vtrn\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n+/* { dg-final { scan-assembler \"vuzp\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n /* { dg-final { cleanup-saved-temps } } */"}, {"sha": "74f5cace6b68d1843a66cf774714114436594530", "filename": "gcc/testsuite/gcc.target/arm/neon/vtrnu32.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrnu32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrnu32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvtrnu32.c?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -17,5 +17,5 @@ void test_vtrnu32 (void)\n   out_uint32x2x2_t = vtrn_u32 (arg0_uint32x2_t, arg1_uint32x2_t);\n }\n \n-/* { dg-final { scan-assembler \"vtrn\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n+/* { dg-final { scan-assembler \"vuzp\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n /* { dg-final { cleanup-saved-temps } } */"}, {"sha": "6c13a07ad2a6d928b2c388927bd1b9282192d844", "filename": "gcc/testsuite/gcc.target/arm/neon/vzipf32.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzipf32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzipf32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzipf32.c?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -17,5 +17,5 @@ void test_vzipf32 (void)\n   out_float32x2x2_t = vzip_f32 (arg0_float32x2_t, arg1_float32x2_t);\n }\n \n-/* { dg-final { scan-assembler \"vzip\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n+/* { dg-final { scan-assembler \"vuzp\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n /* { dg-final { cleanup-saved-temps } } */"}, {"sha": "663985ebe6c63f442f400cdc625fcf76bb61f79c", "filename": "gcc/testsuite/gcc.target/arm/neon/vzips32.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzips32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzips32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzips32.c?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -17,5 +17,5 @@ void test_vzips32 (void)\n   out_int32x2x2_t = vzip_s32 (arg0_int32x2_t, arg1_int32x2_t);\n }\n \n-/* { dg-final { scan-assembler \"vzip\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n+/* { dg-final { scan-assembler \"vuzp\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n /* { dg-final { cleanup-saved-temps } } */"}, {"sha": "d9a280bf4e0e9a54e7cd942e866429e7cc9b57ed", "filename": "gcc/testsuite/gcc.target/arm/neon/vzipu32.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzipu32.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/378913094d2510e1b0ea4738e41de1054a701fa6/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzipu32.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fneon%2Fvzipu32.c?ref=378913094d2510e1b0ea4738e41de1054a701fa6", "patch": "@@ -17,5 +17,5 @@ void test_vzipu32 (void)\n   out_uint32x2x2_t = vzip_u32 (arg0_uint32x2_t, arg1_uint32x2_t);\n }\n \n-/* { dg-final { scan-assembler \"vzip\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n+/* { dg-final { scan-assembler \"vuzp\\.32\\[ \t\\]+\\[dD\\]\\[0-9\\]+, \\[dD\\]\\[0-9\\]+!?\\(\\[ \t\\]+@\\[a-zA-Z0-9 \\]+\\)?\\n\" } } */\n /* { dg-final { cleanup-saved-temps } } */"}]}